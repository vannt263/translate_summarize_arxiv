{
  "article_text": [
    "projective clustering for a set @xmath0 of @xmath11 points in @xmath1 space is to find a set @xmath2 of @xmath3 lower dimensional @xmath4-flats so that the average distance ( by certain distance measure ) from points in @xmath0 to their closest flats is minimized .",
    "depending on the choices of @xmath4 and @xmath3 , the problem has quite a few different variants .",
    "for instance , when @xmath12 , the problem is to find a @xmath4-flat to fit a set of points and is often called shape fitting problem . on the contrary , when @xmath13 , the problem is to find @xmath3 lines to cluster a point set , and thus is called @xmath3-line clustering . in this paper , we mainly consider the @xmath14 sense projective clustering , i.e. , minimizing the average squared distances to the resulting flats .",
    "we also consider extensions to regular projective clustering and @xmath5 sense projective clustering for any integer @xmath9 , where the regular projective clustering is for points whose projection on its optimal fitting flat have bounded coefficient of variation along any direction .",
    "* previous results : * projective clustering is related to many theoretical problems such as shape fitting , matrix approximation , etc .",
    ", as well as numerous applications in applied domains . due to its importance in both theory and applications , in recent years",
    ", a great deal of effort has devoted to solving this challenging problem and a number of promising techniques have been developed @xcite . from methodology point of view ,",
    "agarwal _ et al . _",
    "@xcite first introduced a structure called _ kernel set _ for capturing the extent of a point set and used it to derive a number of algorithms related to the projective clustering problem .",
    "har - peled _ et al . _",
    "@xcite presented algorithms for shape fitting problem based on kernel set and core - sets .",
    "the core - set concept has also been extended to more general projective clustering problems @xcite , and has proved to be effective for many other problems @xcite .",
    "another main approach for projective clustering is dimension reduction through adaptive sampling @xcite . from time",
    "efficiency point of view , most of the existing algorithms for projective clustering problems have super - linear dependency on the size @xmath11 of the point set . several linear or near linear time ( on @xmath11 ) algorithms were also previously presented . in @xcite ,",
    "agarwal _ et al .",
    "_ presented a near linear time algorithm for @xmath3-line clustering with @xmath15 sense objective . in @xcite",
    ", edwards and varadarajan introduced a near linear time algorithm for integer points and with @xmath15 sense objective . in @xcite , varadarajan and xiao",
    "designed a near linear time algorithm for @xmath3-line clustering and general projective clustering on integer points with @xmath16 sense objective . furthermore ,",
    "@xcite present a linear time bicriteria approximation algorithm with @xmath17 , @xmath18 and @xmath19 sense .    * relations with subspace approximation : * a problem closely related to @xmath4-flat fitting is the low rank matrix approximation problem whose objective is to find a lower dimensional subspace , rather than a flat , to approximate the original matrix ( which is basically a set of column points ) . for this problem ,",
    "introduced an elegant method based on random sampling @xcite .",
    "their method additively approximates the original matrix , but unfortunately is not exact ptas . to achieve a ptas , deshpande _",
    "presented a volume sampling based approach to generate @xmath4-subspaces @xcite .",
    "their algorithm works well for the single @xmath4-flat / subspace fitting problem , and can also be extended to projective clustering problem ( but with relatively high time complexity ) .",
    "_ present an algorithm for subspace approximation with any @xmath20 sense objective , for @xmath21 @xcite .",
    "[ def - pc ] given a point set @xmath0 in @xmath1 space , and three integers @xmath22 , @xmath23 and @xmath24 , an @xmath5 sense @xmath25-projective clustering is to find @xmath3 @xmath4-dimensional flats @xmath26 in @xmath1 space such that @xmath27 is minimized . when @xmath12 , it is a @xmath4-flat fitting problem .    in this paper , we assume both @xmath3 and @xmath4 are constant .",
    "@xmath28 is the closest distance from @xmath29 to @xmath30 .      in this paper",
    ", we mainly focus on the case of @xmath31 on arbitrary points ( i.e. , general projective clustering ) , and then extend the ideas to two other cases , regular projective clustering and @xmath5 sense projective clustering for any integer @xmath9 .",
    "we present a uniform approach , purely based on random sampling , to achieve linear time solutions for all three cases .    * * general @xmath25-projective clustering : * for arbitrary point set @xmath0 and small constant numbers @xmath32 , our approach leaves out a small portion ( i.e. , @xmath33 ) of the input points as outliers , and finds , in @xmath34 time , @xmath3 @xmath4-flats to cluster the remaining points so that their objective value is no more than @xmath8 times of the optimal value on the whole set @xmath0 .",
    "our result relies on several novel techniques , such as symmetric sampling , slab partition , @xmath10-rotation , and recursive projection . * * regular projective clustering : * when the input point set @xmath0 has regular distribution on its clusters , our approach yields a ptas solution for the whole point set @xmath0 in the same time bound .",
    "the regularity of @xmath0 is measured based on the coefficient of variation ( cv ) on the projection of its points along any direction on their optimal fitting flat .",
    "@xmath0 is regular if cv has a bounded value .",
    "since many commonly encountered distributions , which are often used to model various data or noises in experiments , are regular ( such as gaussian distribution , erlang distribution , etc ) , our result , thus , has a wide range of potential applications . *",
    "* @xmath5 sense projective clustering : * our approach can also be extended to @xmath5 sense projective clustering for any @xmath35 and with the same time bound .",
    "we show that each technique used for the general and regular projective clustering ( i.e. , the case of @xmath31 ) can be extended to achieve similar results .",
    "* comparsons with previous results : * as mentioned earlier , existing works on projective clustering can be classified into two categories : ( a ) adaptive sampling ( or volume sampling ) based approaches @xcite and ( b ) core - sets based approaches @xcite .",
    "often , ( a ) can efficiently solve the single flat fitting problem ( i.e. , subspace approximation ) , but its extension to projective clustering requires a running time ( i.e. , @xmath36 ) much higher than the desired ( near ) linear time .",
    "( b ) can solve projective clustering in near linear time , but the input must be integer points and within a polynomial range ( i.e. , @xmath37 ) in any coordinate .",
    "the main advantages of our approach are : ( 1 ) its linear time complexity , ( 2 ) do not need to have any assumption on its input ( if a small fraction of outliers is allowed ) , ( 3 ) achieve linear time ptas for regular points , ( 4 ) simple and can be easily implemented for applications .      our approach is based on a key result in @xcite , which estimates the mean point of large point set by a small random sample whose size is independent of the size and dimensionality of the original set .",
    "this result is widely used in many areas , especially in @xmath3-means clustering @xcite . since",
    "projective clustering is a generalization of @xmath3-means clustering , where the mean point is simply a @xmath38-dimensional flat , it is desirable to generalize this uniform random sampling technique to the more general flat fitting and projective clustering problems ( without relying on adaptive or volume sampling or core - sets techniques ) .    to address this issue ,",
    "we show that after taking a random sample @xmath39 , it is impossible to generate a proper fitting flat if we simply compute the mean of @xmath39 as in @xcite .",
    "our key idea is to use _ symmetric sampling _ technique to consider not only @xmath39 , but also @xmath40 , which is the symmetric point set of @xmath39 with respect to the mean point @xmath41 of the input set @xmath0 . intuitively ,",
    "if we enumerate the mean point of every subset of @xmath42 , there must exist one such point @xmath29 that not only locates close to the optimal fitting flat , but also is far away from @xmath41 .",
    "this means that @xmath29 can define one dimension of the fitting flat , and thus we can reduce the @xmath4-flat fitting problem to a @xmath43-flat fitting problem by projecting all points to some @xmath44 dimensional subspace .",
    "if recursively use the strategy @xmath4 times , which is called _ * recursive projection * _ , we can get one proper flat . with this flat fitting technique",
    ", we can naturally extend it to projective clustering .",
    "in this section , we present two standalone results , _ hyperbox lemma _ and _ slab partition _ , which are used for proving our key theorem ( i.e. , theorem [ the - alg1 ] ) in section [ sec - symmetric ] .",
    "[ def - sa ] let @xmath41 and @xmath45 be two points in @xmath46 , and @xmath47 and @xmath48 be the two hyperplanes perpendicular to vector @xmath49 and passing through @xmath45 and @xmath50 respectively , where @xmath50 is @xmath45 s symmetric point about @xmath41 .",
    "the region bounded by @xmath47 and @xmath48 is called the slab determined by @xmath49 ( denoted as @xmath51 ) .",
    "further , let @xmath52 be a point collinear with @xmath41 and @xmath45 with @xmath53 .",
    "then the slab @xmath54 determined by @xmath55 is called an amplification of @xmath51 by a factor @xmath56 ( see figure [ fig - defslab ] ) .",
    ".,height=115 ]    .,height=134 ]    [ lem - cuboid ] let @xmath57 be a hyperbox in @xmath58 , and @xmath41 be its center .",
    "let @xmath59 be @xmath4 facets ( i.e. , @xmath43-dimensional faces ) of @xmath57 with different normal directions ( i.e. , no pair are parallel to each other ) , and @xmath60 be @xmath4 points with each @xmath61 , @xmath62 , incident to @xmath63 .",
    "then there exists one point @xmath64 such that the slab determined by @xmath65 contains @xmath57 after amplifying by a factor no more than @xmath66 .",
    "let @xmath67 be the @xmath4 side lengths of @xmath57 .",
    "for each @xmath68 , denote the slab determined by @xmath69 as @xmath70 ( with two bounding hyperplanes @xmath71 and @xmath72 ) , and its minimal amplification , which is barely enough to contain @xmath57 , as @xmath73 ( i.e. , its two bounding hyperplanes @xmath74 and @xmath75 support @xmath57 ) .",
    "let @xmath76 be a point in @xmath77 ( i.e. , a point on the ( possibly @xmath38-dimensional ) touching face of @xmath78 and @xmath57 ) , and @xmath79 be the intersection point of @xmath78 and the supporting line of @xmath41 and @xmath80 ( see figure [ fig - cuboid ] ) .",
    "then we have @xmath81 , and @xmath82 .",
    "thus , we know that the amplification factor @xmath83 . let @xmath84 , then we have @xmath85 .",
    "thus the lemma is true .",
    "[ def - slab ] let @xmath41 be the origin of @xmath58 , and @xmath86 be the @xmath4 orthogonal vectors defining the coordinate system of @xmath58 .",
    "the following partition is called slab partition on @xmath58 : @xmath87 for @xmath88 , where @xmath89 , @xmath70 is the slab determined by @xmath90 , and @xmath91 is some point on the ray of @xmath92 ( see figure [ fig - slab ] ) .",
    ".,height=124 ]    .,height=124 ]    [ lem - slab ] let @xmath93 be a slab partition in @xmath58 , and @xmath94 be the corresponding partitioning slabs .",
    "let @xmath95 be the @xmath4 points such that @xmath96 for @xmath88 , where @xmath97 is the bounding hyperplane of @xmath70 .",
    "then there exists a point @xmath98 , such that the slab determined by @xmath65 contains @xmath99 after amplified by a factor of @xmath66 .",
    "it is easy to see that @xmath100 , which is a hyperbox in @xmath58 .",
    "thus , it is natural to use lemma [ lem - cuboid ] to prove the lemma . for this purpose ,",
    "we let @xmath101 , @xmath68 , be one of the bounding hyperplanes of @xmath70 with @xmath102 incident to it . for any @xmath103 , from slab partition we know that the whole @xmath104 locates inside @xmath105 .",
    "thus , @xmath102 also locates inside @xmath105 .",
    "let @xmath106 .",
    "thus the @xmath4 facets @xmath59 of @xmath99 point ( i.e. , their normal directions ) to different directions .",
    "note that since @xmath107 is only a subregion of @xmath101 , @xmath102 is possibly outside of @xmath107 .",
    "thus we consider the following two cases , ( a ) every @xmath102 locates inside @xmath107 for @xmath88 and ( b ) there exists some @xmath102 locates outside of @xmath107 .    for case ( a ) , the lemma follows from lemma [ lem - cuboid ] after replacing @xmath57 by @xmath108 . for case",
    "( b ) , our idea is to reduce it to case ( a ) through the following procedure .    1",
    ".   initialize a set of points @xmath109 with @xmath110 for @xmath88 .",
    "2 .   set @xmath111 .",
    "do the following steps until @xmath112",
    ". 1 .   set @xmath113 .",
    "do the following steps until @xmath114 .",
    "if @xmath115 is outside of @xmath116 , first amplify @xmath105 until it touches @xmath115 ( see fig .",
    "[ fig - enlarge ] ) , and then set @xmath117 .",
    "2 .   @xmath118 .",
    "2 .   @xmath119 .    after the above procedure",
    ", @xmath109 becomes a case ( a ) set with respect to the amplified @xmath100 .",
    "to show this claim , we observe that there are two loops in the procedure . in the first loop ,",
    "each @xmath120-th round guarantees that @xmath115 locates inside ( or on the boundary ) of the @xmath120-th facet of the enlarged @xmath99 .",
    "note that @xmath115 is always inside of @xmath105 for @xmath121 .",
    "thus the second loop only starts from @xmath113 .",
    "after amplifying @xmath105 , the original @xmath122 will no longer be on @xmath123 . thus replacing @xmath122 by @xmath115",
    "will keep it on the boundary of @xmath123 .",
    "thus , after finishing the two loops , @xmath109 will become a case ( a ) set with respect to the new @xmath99 .    * note * that in case ( b ) , the resulting @xmath109 is actually a subset of the original @xmath95 .",
    "thus , we do not really need to perform the procedure to complete the reduction .",
    "we only need to find the desired @xmath98 whose existence is ensured by lemma [ lem - cuboid ] .",
    "thus , the lemma holds .",
    "this section introduces several key techniques used in our algorithms .",
    "let @xmath30 be a @xmath4-dimensional flat and @xmath0 be a set of @xmath1 points .",
    "we denote the average squared distance from @xmath0 to @xmath30 as @xmath124 @xmath125 , where @xmath126 is the closest distance from @xmath29 to @xmath30 .      in this section , we discuss flat rotation , and how it affects single flat fitting .",
    ".,height=96 ]    .,height=86 ]    [ def - rotate ] let @xmath30 be a @xmath4-dimensional flat in @xmath46 , @xmath41 be a point on @xmath30 , and @xmath127 be any given point in @xmath46 .",
    "let @xmath128 denote the orthogonal projection of @xmath127 on @xmath30 , and @xmath129 denote the @xmath130-dimensional face of @xmath30 which is perpendicular to the vector @xmath131 .",
    "then the flat @xmath132 spanned by @xmath129 and the vector @xmath133 is a rotation of @xmath30 induced by the vector @xmath133 , and the rotation angle @xmath134 is the angle between @xmath133 and @xmath131 ( see fig .",
    "[ fig - rotate ] ) .    in the above definition ,",
    "when there is no ambiguity about @xmath41 , we also call the rotation is induced by @xmath127 .",
    "[ def - delta ] let @xmath0 be a point set and @xmath30 be a @xmath4-dimensional flat in @xmath46 .",
    "let @xmath41 be a point on @xmath30 , @xmath127 be any given point in @xmath46 , and @xmath135 , where @xmath128 is the orthogonal projection of @xmath127 on @xmath30 , and @xmath136 denotes the inner product of @xmath137 and @xmath138 .",
    "let @xmath132 be a rotation of @xmath30 induced by the vector @xmath133 with angle @xmath134 .",
    "then it is a @xmath10-rotation with respect to @xmath0 if @xmath139 .    in the above definition",
    ", @xmath140 is the average squared projection length of each @xmath141 along the direction of @xmath131 .",
    "figure [ fig - delta ] shows an example of @xmath10-rotation .",
    "the following lemma shows how the average squared distance @xmath142 from @xmath0 to @xmath30 ( i.e. , @xmath143 @xmath125 ) changes after a @xmath10-rotation .",
    "[ lem - delta ] let @xmath0 be a point set in @xmath1 , @xmath30 be a @xmath4-dimensional flat , and @xmath127 be a point in @xmath46 . if @xmath132 is a @xmath10-rotation ( with respect to @xmath0 ) of @xmath30 induced by the vector @xmath133 for some point @xmath144 , then @xmath145 .",
    "we use the same notations as in definition [ def - delta ] . for any @xmath146 , we let @xmath147 denote @xmath148 , and @xmath149 denote its orthogonal projection on @xmath30 . then by triangle inequality , we have meanwhile , since the rotation angle from @xmath30 to @xmath132 is @xmath150 , we have @xmath151 . plugging this into inequality ( [ for-1 ] ) ,",
    "we get where the first inequality follows from @xmath152 , and the second inequality follows from the fact that @xmath153 for any pair of real numbers @xmath137 and @xmath138 . summing both sides of ( [ for-2 ] ) over @xmath29 , we have since @xmath154 , @xmath155 , and @xmath156 .",
    "( [ for-3 ] ) becomes thus , the lemma is true .",
    "* algorithm symmetric - sampling * * input : * a set @xmath157 of @xmath1 points and a single point @xmath41 in @xmath1 . *",
    "output : * a new point set @xmath158 .    1 .",
    "initialize @xmath159 .",
    "2 .   construct a new point set @xmath160 , which is the set of symmetric points of @xmath39 ( i.e. , symmetric about @xmath41 ) .",
    "3 .   for each subset of @xmath42 , add its mean point into @xmath158 .",
    "below is the main theorem about algorithm symmetric - sampling .",
    "[ the - alg1 ] let @xmath0 be a set of @xmath46 points , and @xmath39 be its random sample of size @xmath161 , where @xmath162 and @xmath163 are two small numbers .",
    "let @xmath30 be a @xmath4-dimensional flat , @xmath41 be a given point on @xmath30 , and @xmath158 be the set of points returned by algorithm symmetric - sampling on @xmath39 and @xmath41 .",
    "then with probability @xmath164 , @xmath158 contains one point @xmath45 such that the hyperplane @xmath132 rotated from @xmath30 and induced by @xmath49 satisfies the following inequality , @xmath165 , where @xmath166 is a subset of @xmath0 with size @xmath167 .    before proving theorem [ the - alg1 ]",
    ", we first introduce the following two lemmas .",
    "[ lem - select ] let @xmath168 be a set of @xmath11 elements , and @xmath169 be a subset of @xmath168 with size @xmath170 . if randomly select @xmath171 elements from @xmath168 , with probability at least @xmath172 , the sample contains at least @xmath173 elements from @xmath169 ( see appendix for proof ) .",
    "the following lemma has been proved in @xcite .",
    "[ lem - dis ]",
    "let @xmath168 be a set of @xmath11 points in @xmath46 space , and @xmath174 be a subset with cardinality @xmath175 randomly selected from @xmath168 .",
    "let @xmath176 and @xmath177 be the mean points of @xmath168 and @xmath174 respectively . with probability @xmath172 , @xmath178 , where @xmath179 @xmath180 .",
    "first , imagine that if we can show the existence of ( 1 ) a subset @xmath181 with size @xmath167 and ( 2 ) a @xmath4-flat @xmath132 which is a @xmath10-rotation ( with @xmath182 ) of @xmath30 with respect to @xmath166 , then by lemma [ lem - delta ] , we have @xmath183 . meanwhile , since @xmath184 and @xmath167 , we have @xmath185 . combining the two inequalities , we have @xmath186 .",
    "this means that we only need to focus on proving the existence of such @xmath166 and @xmath132 . without loss of generality ,",
    "we assume that the given point @xmath41 is the origin . to prove the theorem",
    ", we first assume that all points of @xmath0 locate on @xmath30 , which would be the case if project all points of @xmath0 onto @xmath30 or equivalently each point in this case can be viewed as the projection of some point of @xmath0 in @xmath1 .",
    "now we consider the case that @xmath0 is in @xmath30 .",
    "first , we construct a slab partition @xmath93 for the @xmath4-dimensional subspace spanned by @xmath30 with @xmath94 being the corresponding slabs such that @xmath187 .",
    "clearly , this can be easily obtained by iteratively ( starting from @xmath111 ) selecting the slab @xmath188 as the one which exclude the @xmath189 points whose @xmath120-th coordinate have the largest absolute value . from the slab partition ,",
    "it is easy to see that for any @xmath190 , @xmath191 , and @xmath192 .",
    "thus , if we set @xmath193 and @xmath194 , and use lemma [ lem - select ] to take a random sample from @xmath0 of size @xmath195 , with probability @xmath196 , the sample contains at least @xmath197 points from each @xmath198 .",
    "also , if we set @xmath199 , and use lemma [ lem - select ] to take a random sample from @xmath0 of size @xmath200 , with probability @xmath196 , the sample contains at least @xmath201 point from each @xmath202 .",
    "this means that if we take a random sample @xmath39 of size @xmath203 , then with probability @xmath204 , we have @xmath205 and @xmath206 for any @xmath120 ( by the fact that @xmath207 ) , where @xmath208 .",
    "let @xmath209 be the @xmath120-th coordinate of a point @xmath29 , @xmath210 , and @xmath102 be the mean point of @xmath211 for @xmath88 .",
    "note that @xmath102 is contained in the output of algorithm symmetric - sampling .",
    "we define another sequence of slabs @xmath212 , where each @xmath73 is the slab axis parallel to @xmath70 and with @xmath102 incident to one of its bounding hyperplanes .",
    "these slabs induce another slab partition on @xmath30 with @xmath213 . by lemma [ lem - slab ] , we know that there exists one point @xmath98 such that the slab determined by @xmath65 contains @xmath214 after amplified by a factor of @xmath66 .    by the fact that @xmath215 and the symmetric property of @xmath216 , we know that @xmath217 .",
    "denote the width of @xmath104 and @xmath218 in the @xmath120-th dimension as @xmath219 and @xmath220 respectively .",
    "then , @xmath221 ( note that @xmath222 ) .",
    "let @xmath223 .",
    "then , @xmath104 and @xmath218 differ in width ( in the @xmath120-th dimension ) by a factor no more than @xmath224 .",
    "thus , by the slab partition procedure , the difference of the width between @xmath99 and @xmath214 is no more than a factor of @xmath224 in any direction on @xmath30 . as a result ,",
    "the slab determined by @xmath65 contains @xmath99 after amplified by a factor of @xmath225 .",
    "now , we come back to the case that @xmath0 locates in @xmath46 rather than @xmath30",
    ". first we let @xmath226 .",
    "then , we have @xmath167 . note that we can always use the projection of @xmath0 whenever it is not in @xmath30 .",
    "thus we can still select @xmath166 by using slab partition on @xmath30 .",
    "this ensures the existence of @xmath166 .",
    "next , we prove the existence of @xmath132 . in this case",
    ", @xmath98 may not be in @xmath30 .",
    "we will prove the rotation induced by @xmath65 is a @xmath10-rotation of @xmath30 with respect to @xmath227 .",
    "we let @xmath228 denote the projection of @xmath98 on @xmath30 , @xmath229 , and @xmath230 . by the way how @xmath98 is generated",
    ", we know that @xmath231 . thus , in order to prove it is a @xmath232-rotation , we just need to prove @xmath233 . recall that @xmath98 is the mean point of @xmath234 , and @xmath235 .",
    "then we have the following claim ( see appendix for proof ) .    with probability @xmath204 , @xmath236 .",
    "claim ( 1 ) implies that @xmath237 , which means that the hyperplane @xmath232-rotated from @xmath30 is the desired @xmath132 .    as for success probability ,",
    "since the success probability of containing @xmath98 is @xmath204 as shown in previous analysis , and the success probability for claim ( 1 ) is also @xmath204 , the success probability for theorem [ the - alg1 ] is thus @xmath164 .",
    "this section presents a @xmath8-approximation algorithm for the projective clustering problem . for ease of understanding",
    ", we first give an outline of the algorithm .",
    "as mentioned in previous section , the objective of our approximation algorithm for the projective clustering problem is to determine @xmath3 @xmath4-dimensional flats such that @xmath238 of the input points in @xmath0 can be fit into the obtained @xmath3 flats , and the total objective value is no more than @xmath239 , where @xmath240 is the objective value of an optimal solution for all points in @xmath0 . let @xmath241 be the @xmath3 clusters in an optimal solution for @xmath0 .",
    "our approach only consider those clusters ( called _ large clusters _ ) in @xmath242 with size at least @xmath243 , since the union of the remaining clusters has a total size no more than @xmath244 .",
    "also , for each large cluster @xmath245 , our approach generates a flat to fit @xmath246 of its points .",
    "thus , in total we fit at least @xmath247 of points to the resulting @xmath3 flats .",
    "consider a large cluster @xmath245 .",
    "let @xmath248 be its optimal fitting flat .",
    "it is easy to see that @xmath248 passes through the mean point @xmath249 of @xmath250 .",
    "let @xmath251 be the optimal objective value of @xmath245 . to emulate the behavior of @xmath245",
    ", we first assume that we know the exact position of @xmath252 .",
    "if we run algorithm symmetric - sampling on @xmath252 and a random sample of @xmath245 ( note that since @xmath245 is a large cluster , by lemma [ lem - select ] , we can obtain enough points from @xmath245 by randomly sampling @xmath0 directly ) , by theorem [ the - alg1 ] , we can get a point @xmath45 , such that @xmath253 induces a @xmath10-rotation for @xmath248 with respect to a subset of @xmath245 with at least @xmath254 points , where @xmath255 .",
    "if we recursively run algorithm symmetric - sampling @xmath4 times , we obtain a sequence of @xmath10-rotations and @xmath4 vectors which form a @xmath4-dimensional flat @xmath256 such that @xmath257 ( i.e. , @xmath256 induces a @xmath258-approximation for @xmath245 ) , where @xmath259 is a subset of @xmath250 with at least @xmath260 points .",
    "since algorithm symmetric - sampling enumerates all subsets of @xmath261 , the above recursive procedure ( called _ algorithm recursive - projection _ ; see section [ sec - rpa ] . )",
    "forms a hierarchical tree .    from the proof of theorem [ the - rpa ]",
    ", we will know that the approximation ratio ( i.e. , @xmath262 ) is solely determined by the @xmath10-rotation .",
    "in other words , if we could reduce the value of @xmath10 from @xmath263 to @xmath264 , the approximation ratio would be reduced to @xmath265 . to achieve this ,",
    "our idea is to find a point closer to @xmath248 to induce the desired @xmath10-rotation .",
    "our idea is to draw a ball @xmath266 centered at every candidate point which induces the @xmath10-rotation , and build a grid inside @xmath266 .",
    "the grid ensures the existence of one grid point close enough to @xmath248 . by using the linear time dimension reduction technique in @xcite",
    ", we can reduce the dimensionality of the projective clustering problem from @xmath267 to @xmath268 .",
    "this enables us to reduce the complexity of the grid .",
    "thus , the approximation ratio can be reduced to @xmath269 in linear time .",
    "now , the only remaining issue is how to find the exact position of @xmath252 . from lemmas [ lem - dis ] and [ lem - select ]",
    ", we can find an approximate mean point @xmath270 for @xmath252 .",
    "thus , by translating @xmath248 to pass though @xmath270 , we can show that @xmath271 . combining this with the following lemma [ lem - translate ] ,",
    "we can obtain a good approximation @xmath272 for @xmath248 .",
    "[ lem - translate ] let @xmath0 be a point set , @xmath30 be a @xmath4-dimensional flat , and @xmath273 be a translation of @xmath30 in @xmath46 . then",
    ", @xmath274      * algorithm recursive - projection * * input : * a point set @xmath0 and a single point @xmath275 , @xmath276 , and @xmath23 .",
    "* output : * a tree @xmath277 of height @xmath4 with each node @xmath278 associated with a point @xmath279 and a flat @xmath280 in @xmath46 .    1",
    ".   initialize @xmath277 as a tree with a single root node associated with no point",
    ". the flat associated by the root is @xmath46 .",
    "2 .   starting from the root , for each node @xmath278 , grow it in the following way 1 .   if the height of @xmath278 is @xmath4 , it is a leaf node .",
    "2 .   otherwise , 1",
    "project @xmath0 onto @xmath280 , and denote the projection as @xmath281 .",
    "2 .   take a random sample @xmath282 from @xmath281 with size @xmath283 , and run algorithm symmetric - sampling on @xmath282 and @xmath41 to obtain @xmath284 points @xmath285 as the output .",
    "3 .   create @xmath284 children for @xmath278 , with each child associated with one point in @xmath285 .",
    "4 .   let @xmath41 be the mean point of @xmath282 .",
    "for each child @xmath127 , let @xmath286 be its associated point ; associate @xmath127 the flat which is the subspace of @xmath280 perpendicular to @xmath287 and with one less dimension than @xmath280 .",
    "* running time * : it is easy to see that there are @xmath288 nodes in the output tree @xmath277 .",
    "each node costs @xmath289 time .",
    "thus , the total running time is @xmath290 .",
    "[ the - rpa ] with probability @xmath164 , the output @xmath277 from algorithm recursive - projection contains one root - to - leaf path such that the @xmath4 points associated with the path determine a flat @xmath30 satisfying inequality @xmath291 where @xmath166 is a subset of @xmath0 with at least @xmath238 points and @xmath292 is the optimal fitting flat for @xmath0 among all @xmath4-dimensional flats passing through @xmath41 .    without loss of generality , we assume that @xmath41 is the origin of @xmath46 . since all the related flats in the algorithm",
    "pass through @xmath41 , we can view each flat as a subspace in @xmath46 .    from the algorithm , we know",
    "that for any node @xmath278 at level @xmath120 of @xmath277 , @xmath88 , there is a corresponding implicit point set @xmath281 , which is the projection of @xmath0 on @xmath293 .",
    "there is also an implicit flat @xmath294 in @xmath293 . by theorem [ the - alg1 ] , we know that there is one child of @xmath278 , denoted as @xmath295 , such that the rotation for @xmath294 induced by @xmath296 is a @xmath10-rotation with respect to a subset @xmath297 of @xmath281 with size @xmath298 , where @xmath299 .",
    "thus , if we always select such children ( satisfying the above condition ) from root to leaf , we have a path with nodes @xmath300 , where @xmath301 is the root , and @xmath302 is the child of @xmath303 . correspondingly , a sequence of implicit point sets @xmath304 and a sequence of flats @xmath305 can also be obtained , which have the following properties .    1 .",
    "initially , @xmath306 , @xmath307 .",
    "2 .   for any @xmath88",
    ", @xmath308 is the rotation of @xmath309 induced by @xmath310 , @xmath311 is a subset of the projection of @xmath312 on @xmath313 with size at least @xmath314 , and @xmath308 is a @xmath10-rotation with respect to @xmath315 ( see figure [ fig - project ] ) .",
    "note that since both @xmath308 and @xmath309 locate on @xmath313 , they are all perpendicular to @xmath316 .",
    "the following claim reveals the dimensionality of each @xmath308 ( see appendix for proof ) .",
    "evolves into @xmath308.,height=115 ]    for @xmath88 , @xmath308 is a @xmath317-dimensional subspace .    by lemma [ lem - delta ] , we can easily have the following claim .",
    "for any @xmath88 , @xmath318 .",
    "we construct as follows two other sequences , @xmath319 and @xmath320 , for point sets and flats respectively",
    ".    1 .   initially , @xmath321 , @xmath322 .",
    "2 .   for any @xmath323 , @xmath324 , and @xmath325 is the corresponding point set of @xmath315 mapped back from @xmath326 to @xmath46 .    from the above construction for @xmath327",
    ", we have the following claim .    for any point @xmath328 ,",
    "let @xmath29 denote the corresponding point in @xmath46",
    ". then @xmath329 .    from claim ( * 2 * ) , we know that each @xmath327 is a @xmath4-dimensional subspace . from the algorithm , we know that @xmath330 ( see fig . [ fig - project ] ) , which implies @xmath331 @xmath332 . then by claim ( * 3 * ) and ( * 4 * ) , we have the following inequality by the definition of @xmath325 , we have @xmath333 . thus , combining ( [ for-9 ] ) and ( [ for-10 ] ) , we have recursively using the above inequality , we have @xmath334 . from the definition of @xmath335 , we know that @xmath336 . furthermore , by claim ( * 2 * ) , we know that @xmath337 is a @xmath201-dimension flat ( i.e. , the single line spanned by @xmath338 ) , hence @xmath339 . thus , if setting @xmath340 , and @xmath341 , we have @xmath342 .",
    "* success probability : * each time we use theorem [ the - alg1 ] , the success probability is @xmath343 ( we replace @xmath344 by @xmath345 to increase the sample size ) .",
    "thus , the total success probability is @xmath346 .      * algorithm projective - clustering * * input : * a set of points @xmath0 in @xmath46 , positive integers @xmath3 , @xmath4 , and two positive numbers @xmath347 . *",
    "output : * an approximate solution for @xmath25-projective clustering    1 .",
    "use the dimension reduction technique in @xcite to reduce the dimensionality from @xmath267 to @xmath348 .",
    "2 .   set the sample size @xmath349 , where @xmath350 .",
    "3 .   running algorithm recursive - project @xmath3 time with sample size @xmath224 .",
    "denote the @xmath3 output trees as @xmath351 .",
    "4 .   enumerate the combinations of all @xmath3 flats from the @xmath3 trees : select one flat yielded by a root - to - leaf path from each @xmath352 for @xmath353 , and compute the objective value of these @xmath3 flats .",
    "let @xmath354 be the smallest objective value among all the combinations .",
    "re - run algorithm recursive - projection @xmath3 time with the following modification : in step @xmath355 , for each point @xmath29 of the @xmath284 points returned by algorithm symmetric - sampling , build a ball @xmath266 centered at @xmath29 and with radius @xmath356 , and construct a grid inside @xmath266 . for each grid point , create a node , associate it with the grid point , and make it as a sibling of the node containing @xmath29 .",
    "enumerate the combinations of all @xmath3 flats from the @xmath3 output trees of the above step . find the @xmath3 flats with the smallest objective value for @xmath0 and output them as the solution .    in the above algorithm ,",
    "the radius @xmath356 and the density of the grid are chosen in a way so that there exists a grid point which induces a @xmath357-rotation for the clustering points .",
    "thus , we can further reduce the approximation ratio to @xmath8 , and have the following theorem .",
    "detailed analysis on the algorithm and the theorem is left in section [ sec - parameter ] of the appendix .",
    "[ the - ptas ] let @xmath0 be a set of @xmath1 points in a @xmath25-projective clustering instance .",
    "let @xmath358 be the optimal objective value on @xmath0 . with constant probability and in @xmath34 time ,",
    "algorithm projective - clustering outputs an approximate solution @xmath359 such that each @xmath327 is a @xmath4-flat , and @xmath360 , where @xmath166 is a subset of @xmath0 with at least @xmath238 points .",
    "we present two main extensions .",
    "see appendix for details . * linear time ptas for regular projective clustering : * for points with bounded coefficient of variation ( cv ) ( we call such problem as regular projective clustering )",
    ", we show that our approach leads to a linear time ptas solution .",
    "the main idea is that since the cv is bounded , the point from symmetric sampling algorithm is far enough to @xmath41 .",
    "this implies that the each @xmath10-rotation from algorithm recursive - projection is for the whole set @xmath0 rather than a subset @xmath166 .",
    "thus we can fit all points of @xmath0 into the resulting @xmath3 flats within the same approximate ratio .    * @xmath20 sense projective clustering : * we show that our approach can be extended to @xmath20 sense projective clustering for any integer @xmath24 and achieve similar results for both general and regular projective clustering .",
    "the key idea is to define the @xmath20 sense @xmath10-rotation , and prove a result similar to lemma [ lem - delta ] .",
    "in other words , the symmetric sampling technique can also yield a @xmath20 sense @xmath10-rotation with    7    pankaj k. agarwal , sariel har - peled , kasturi r. varadarajan ,  approximating extent measures of points .  _ j. acm 51(4):606 - 635 _ , 2004    p.k .",
    "agarwal , s. har - peled , and k. r. varadarajan ,",
    " geometric approximation via coresets \" , combinatorial and computational geometry , msri publications volume 52 , pp .  130 , 2005 .",
    "pankaj k. agarwal , cecilia magdalena procopiuc , kasturi r. varadarajan ,  approximation algorithms for a k - line center  .",
    "_ algorithmica 42(3 - 4 ) : 221 - 230 ( 2005 ) _    pankaj k. agarwal and nabil h. mustafa ,  k - meansprojective clustering  .",
    "_ in proceedings of the twenty - third acm sigmod - sigact - sigart symposiumon principles of database systems , pods 04 , pages155 - 165 , new york , ny , usa , 2004 .",
    "_    n. alon and j. h. spencer ,  the probabilistic method .",
    "john wiley and sons  , 1992 .",
    "charu c. aggarwal , joel l. wolf , philip s. yu , cecilia procopiuc , and jong soo park .  fast algorithms for projected clustering  .",
    "_ in proceedings of the 1999 acm sigmod international conference on management of data , sigmod 99 , pages 61 - 72 , new york , ny , usa , 1999 .",
    "_    charu c. aggarwal and philip s. yu .",
    " finding gener- alized projected clusters in high dimensional spaces  . _ in proceedings of the 2000 acm sigmod interna- tional conference on management of data , sigmod 00 , pages 70 - 81 , new york , ny , usa , 2000 .",
    "_    m.badoiu , k.clarkson ,  smaller core - sets for balls \" , _ proceedings of the fourteenth annual acm - siam symposium on discrete algorithms _ , pp .  801802 , 2003 .",
    "m.badoiu , s.har-peled , p.indyk ,  approximate clustering via core - sets \" , _ proceedings of the 34th symposium on theory of computing _ , pp .  250257 , 2002 .",
    "k. clarkson ,  coresets , sparse greedy approximation , and the frank - wolfe algorithm \" , _ proceedings of the nineteenth annual acm - siam symposium on discrete algorithms _ , pp .",
    "922 - 931 , 2008    amit deshpande , kasturi r. varadarajan ,  sampling - based dimension reduction for subspace approximation  .",
    "_ stoc 2007 : 641 - 650 _    amit deshpande , luis rademacher , santosh vempala , grant wang ,  matrix approximation and projective clustering via volume sampling  .",
    "_ soda 2006 : 1117 - 1126 _",
    "michael edwards , kasturi r. varadarajan ,  no coreset , no cry : ii  . _",
    "fsttcs 2005 : 107 - 115 _    dan feldman , amos fiat , micha sharir , danny segev : bi - criteria linear - time approximations for generalized k - mean / median / center .",
    "symposium on computational geometry 2007 : 19 - 26    alan m. frieze , ravi kannan , santosh vempala : fast monte - carlo algorithms for finding low - rank approximations",
    ". j. acm 51(6 ) : 1025 - 1041 ( 2004 )    dan feldman , michael langberg : a unified framework for approximating and clustering data .",
    "stoc 2011 : 569 - 578    sariel har - peled , dan roth , dav zimak ,  maximum margin coresets for active and noise tolerant learning .",
    " _ ijcai 2007 : 836 - 841 _    p.kumar , j.mitchell , a.yildirim ,  computing core - sets and approximate smallest enclosing hyperspheres in high dimensions \" , manuscript , 2002 .",
    "sariel har - peled , yusu wang ,  shape fitting with outliers  .",
    "_ siam j. comput .",
    "( siamcomp ) 33(2):269 - 285 ( 2004 ) _",
    "sariel har - peled , kasturi r. varadarajan ,  high - dimensional shape fitting in linear time  .",
    "_ socg 2003:39 - 47 _    sariel har - peled , kasturi r. varadarajan ,  projective clustering in high dimensions using core - sets  . _ symposium on computational geometry 2002 : 312 - 318 _    mary inaba , naoki katoh , hiroshi imai ,  applications of weighted voronoi diagrams and randomization to variance - based k - clustering ( extended abstract )  .",
    "_ symposium on computational geometry 1994 : 332 - 339 _    amit kumar , yogish sabharwal , sandeep sen : a simple linear time @xmath8-approximation algorithm for k - means clustering in any dimensions .",
    "focs 2004 : 454 - 462    amit kumar , yogish sabharwal , sandeep sen : linear time algorithms for clustering problems in any dimensions .",
    "icalp 2005 : 1374 - 1385    amit kumar , yogish sabharwal , sandeep sen : linear - time approximation schemes for clustering problems in any dimensions .",
    "j. acm 57(2 ) : ( 2010 )    cecilia m. procopiuc , michael jones , pankaj k. agar- wal , and t. m. murali .  a monte carlo algorithm for fast projective clustering  .",
    "_ in proceedings of the 2002 acm sigmod international conference on manage- ment of data , sigmod 02 , pages 418 - 427 , new york , ny , usa , 2002 .",
    "_    nariankadu d. shyamalkumar , kasturi r. varadarajan ,  efficient subspace approximation algorithms ",
    ". _ soda 2007 : 532 - 540 _    kasturi varadarajan , xin xiao ,  a near - linear algorihtms for projective clustering integer points  , _ soda 2012 _",
    "if we randomly select @xmath361 elements from @xmath168 , then it is easy to know that with probability @xmath362 , there is at least one element from the sample belonging to @xmath169 .",
    "if we want the probability @xmath362 equal to @xmath363 , @xmath361 has to be @xmath364 .",
    "thus if we perform @xmath173 rounds of random sampling with each round selecting @xmath365 elements , we get at least @xmath173 elements from @xmath169 with probability at least @xmath366 .      for simplicity , we let @xmath412 denote @xmath413 . by triangle inequality , for any @xmath146 , we have @xmath414 . thus , @xmath415    let @xmath416 . then",
    ", we have @xmath417    combining ( [ for-11 ] ) and ( [ for-12 ] ) , we have @xmath418 thus , the lemma is true .",
    "we first reduce the space from @xmath46 to @xmath367 , which is a @xmath368-dimensional subspace . for simplicity",
    ", we use the same notations for points in @xmath367 as in @xmath46 .",
    "it is easy to know that during the space reduction from @xmath46 to @xmath367 , @xmath228 is projected to the origin , and @xmath369 is equal to @xmath370 in the subspace .",
    "we let @xmath371 , and @xmath372 . correspondingly , we let @xmath373 denote the symmetric point set of @xmath374 with respect to @xmath41 . without loss of generality , we assume that @xmath375 .",
    "let @xmath376 and @xmath377 be the mean points of @xmath374 and @xmath378 respectively , and @xmath379 and @xmath380 . since @xmath98 is the mean point of @xmath234 , we have @xmath381 .",
    "thus , @xmath382 where the last inequality follows from triangle inequality .",
    "note that @xmath383 is the mean point of @xmath373 , @xmath384 is the mean point of @xmath385 , and @xmath385 is a sample from @xmath0 of size at least @xmath197 .",
    "let @xmath386 be the mean point of @xmath0 , and @xmath387 ( note that the current space is @xmath367 ) . then by lemma [ lem - dis ] , we know that with probability @xmath172 , @xmath388",
    ". similarly , since @xmath373 is a sample from @xmath0 with size at least @xmath389 ( by @xmath375 ) , we have @xmath390 with probability @xmath172 . since ,",
    "@xmath391 , with a total probability @xmath392 , we have @xmath393    where the first inequality follows from triangle inequality , and the last inequality follows from the fact that @xmath394 for any four real numbers @xmath395 .    setting @xmath396 , by ( [ for-7 ] ) and ( [ for-8 ] ) , we have @xmath397 , with probability @xmath204 .",
    "we prove this claim by induction . for the base case ( i.e. , @xmath111 ) , @xmath398 has the same dimensionality as @xmath399 ( note that @xmath400 ) .",
    "hence @xmath398 is a @xmath4-dimensional subspace .",
    "then we assume that @xmath401 is a @xmath402-dimensional subspace for any @xmath121 ( i.e. , induction hypothesis ) .",
    "now , we consider the case of @xmath403 . since @xmath404 is only a rotation of @xmath405 , they have the same dimensionality . also , from the algorithm , we know that @xmath405 is the subspace in @xmath406 which is perpendicular to @xmath407 , where @xmath408 is the projection of @xmath409 on @xmath406 .",
    "thus , @xmath405 is a @xmath410-dimensional subspace , which implies that @xmath404 is also a @xmath411-dimensional subspace .",
    "hence , claim ( * 2 * ) is proved .",
    "* sample size and success probability : * theorem [ the - rpa ] enables us to find a good flat for the whole point set @xmath0 . to find @xmath3 good flats , one for each cluster",
    ", we need to increase the probability from @xmath164 to @xmath419 , and replace @xmath420 by @xmath421 .",
    "thus , for each cluster , we need @xmath350 points . by lemma [ lem - select ] , we know that if we want a random sample containing at least @xmath173 points from one cluster with probability @xmath422 , we need to sample @xmath423 points from @xmath0 , where @xmath424 is the fraction of the cluster in @xmath0 .",
    "note that since our algorithm only focuses on emulating the behavior of large clusters , @xmath425 .",
    "this means that it is sufficient to set the sample size @xmath224 to be @xmath426 .",
    "the total success probability is therefore @xmath427 .",
    "* radius and grid density : * let @xmath358 be the optimal objective value of projective clustering on @xmath0 . by theorem [ the - rpa ] , we know that step @xmath428 in the algorithm outputs an objective value @xmath429 . from the proof of theorem [ the - rpa ] , we know that on the path generating the resulting flat , if each node incurs a @xmath357-rotation rather than a @xmath10-rotation , the approximation ratio will become @xmath430 ( instead of @xmath262 ) . thus , to reduce @xmath431 to @xmath357 , we can build a grid around the point associated with each node @xmath278 in the tree @xmath277 generated by algorithm recursive - projection .",
    "for each grid point , add a node as a new sibling of @xmath278 ( see step @xmath432 ) and associate it with the grid point .",
    "the problem is how to determine the density of the grid so as to generate the desired approximation ratio .    to determine the density of the grid ,",
    "we first have @xmath433    we use the same notations as in theorem [ the - rpa ] .",
    "let @xmath434 be the current node in algorithm recursive - projection , and @xmath435 be the projection of @xmath436 on @xmath437 .",
    "further , let @xmath438 , and @xmath439 . by definition [ def - delta ]",
    ", we have @xmath440 combining ( [ for-6 ] ) and ( [ for-27 ] ) , we have @xmath441 by lemma [ lem - slab ] , we know that @xmath442 ( note that @xmath350 , as discussed previously ) . hence , we can set the radius @xmath356 of @xmath266 to be @xmath443 .",
    "thus , @xmath444 , which implies that @xmath445 locates inside @xmath266 .",
    "if we set @xmath446 , and construct a grid inside @xmath266 with grid length @xmath447 , then there is one grid point @xmath386 satisfying the following inequality .",
    "@xmath448 where the last inequality follows from ( [ for-6 ] )",
    ". combining inequalities ( [ for-30 ] ) and @xmath449 , we have @xmath450 , which implies that it induces a @xmath357-rotation .",
    "* running time .",
    "* the dimension reduction step costs @xmath451poly@xmath452 time , and resulting problem has diemsion @xmath453poly@xmath454 .",
    "step @xmath455 and @xmath428 take @xmath456 time .",
    "note that in step @xmath432 , the complexity of the grid inside @xmath266 is @xmath457 .",
    "thus , the complexity of each @xmath352 will increase to @xmath458 .",
    "hence , the total running time is @xmath459 .",
    "this section first introduces the _ regular _ projective clustering problem , and then presents a ptas for it .",
    "we start our discussion with a concept used in statistics .",
    "[ def - cv ] let @xmath460 be a random variable , and @xmath461 $ ] be its expection .",
    "the coefficient of variation of @xmath460 is denoted as @xmath462}}{e[|x-\\mu|]}$ ] .",
    "cv of a single variable aims to measure the dispersion of the variable in a way that does not depend on the variable s actual value .",
    "the higher the cv , the greater the dispersion is in the variable .",
    "distributions with @xmath463 ( such as an erlang distribution ) are considered as low - variance , while those with @xmath464 ( such as a hyper - exponential distribution ) are considered as high - variance .",
    "note that many commonly encountered distributions has constant cv ( e.g. , gaussian distribution be any gaussian distribution with mean point at the origin .",
    "then , @xmath465=\\int_{-\\infty}^{+\\infty}|x|\\frac{1}{\\sqrt{2\\pi\\delta^2}}e^{-\\frac{x^2}{2\\delta^2 } } \\,dx = 2\\int_{0}^{+\\infty } x\\frac{1}{\\sqrt{2\\pi\\delta^2}}e^{-\\frac{x^2}{2\\delta^2}}\\ , dx=\\frac{2\\delta}{\\sqrt{2\\pi}}.$ ] since @xmath466=\\delta^2 $ ] , we have @xmath467}}{e[|x|]}=\\sqrt{\\frac{\\pi}{2}}$ ] . ] ) .",
    "[ lem - bound ] let @xmath468 be a set of @xmath11 numbers with coefficient of variation @xmath469 , and @xmath470 be a random sample of @xmath471 .",
    "then , for any positve constant @xmath472 , @xmath473 where @xmath474 and @xmath475",
    ".    let @xmath476 .",
    "then , from the definition of cv , we know that @xmath477 , which implies @xmath478 .",
    "since the variance of @xmath479 is @xmath480 , and @xmath168 is the random sample from @xmath471 with size @xmath175 , we know that the expected value and variance of @xmath481 are @xmath482 and @xmath483 respectively . by markov inequality",
    ", we know @xmath484 meanwhile , since @xmath485    combining ( [ for-33 ] ) and ( [ for-34 ] ) , we have @xmath486    recall that @xmath478 .",
    "if we replace @xmath482 by @xmath487 , the above inequality becomes @xmath488    using coefficient of variation , we introduce the regular projective clustering problem .",
    "let @xmath0 be a point set in @xmath46 , @xmath292 be its optimal @xmath4-dimensional flat fitting , and @xmath41 be its mean point .",
    "it is easy to see that @xmath41 locates on @xmath292 .",
    "[ def - rff ] a single @xmath4-flat fitting problem with input point set @xmath0 is regular if for any direction @xmath489 , the coefficient of variation of @xmath490 is bounded by some constant @xmath469 .",
    "@xmath469 is called the regular factor of @xmath0 .",
    "[ def - rpc ] a @xmath25-projective clustering problem with input point set @xmath0 and optimal clusters @xmath491 is regular if each @xmath245 is a regular single @xmath4-flat fitting problem .",
    "the following theorem is a counterpart of theorem [ the - alg1 ] for regular projective clustering .",
    "[ the - ralg1 ] let @xmath492 be the @xmath1 input point set of a regular single @xmath4-flat fitting problem with mean point @xmath41 and regular factor @xmath469 , and @xmath39 be its random sample of size @xmath493 , where @xmath494 is a small constant .",
    "let @xmath292 be a @xmath4-dimensional flat , and @xmath158 is the set of points returned by algorithm symmetric - sampling on @xmath39 and @xmath41 .",
    "then with probability @xmath495 , @xmath158 contains one point @xmath45 such that the flat @xmath132 rotated from @xmath292 and induced by @xmath49 satisfies the following inequality , @xmath496    , height=172 ]    without loss of generality , we assume that @xmath41 is the origin .",
    "since @xmath292 passes through @xmath41 , @xmath292 passes through the origin .",
    "thus , we can assume @xmath292 is the @xmath4-dimensional subspace spanned by the first @xmath4 dimensions .",
    "let @xmath497 be the coordinates of each point @xmath498 , and @xmath499 for @xmath88 .",
    "we consider the division @xmath500 ( see fig . [ fig - symmetric ] ) , where @xmath501 and @xmath502 .",
    "let @xmath503 .",
    "consider the point set @xmath504 .",
    "since @xmath0 is regular with a regular factor @xmath469 ( which is a positive constant ) and the mean of @xmath505 is @xmath38 ( due to the fact that the mean point of @xmath0 is the origin ) , the coefficient of variation of @xmath505 is no more than @xmath469 , for all @xmath88 .    for the sample set @xmath39",
    ", we define a subset @xmath174 of @xmath261 as @xmath506 . since @xmath507 , it is easy to see that @xmath508 .",
    "let @xmath509 be the mean point of @xmath174 with coordinates @xmath510 .",
    "since algorithm symmetric - sampling enumerates the mean points of all subsets of @xmath261 , @xmath509 is clearly in @xmath158 . if we denote the projection of @xmath509 on @xmath292 as @xmath511 , then it is easy to know that @xmath512",
    ". let @xmath489 be the unit vector @xmath513 .",
    "let @xmath514 .",
    "below , we prove that @xmath509 is the desired point which induces a @xmath10-rotation for @xmath292 with @xmath515 .    by definition [ def - delta ]",
    ", we know that in order to prove that @xmath509 induces a @xmath516-rotation , we just need to show that @xmath517 . in other words , we need to prove two things : ( a ) @xmath518 is larger than certain value , and ( b ) @xmath519 is smaller than certain value .    in order to prove ( a )",
    ", we have @xmath520 where the inequality follows from the fact that @xmath521 for any real numbers @xmath522 and @xmath523 .",
    "meanwhile , since @xmath524 , by ( [ for-35 ] ) we have    @xmath525    without loss of generality , we assume that @xmath526 .",
    "then we have @xmath527 . combining this with ( [ for-36 ] )",
    ", we have @xmath528    since @xmath509 is the mean point of @xmath174 with @xmath529 , and @xmath530 , we have    @xmath531    further , since @xmath532 has average value zero , and its cv is bounded by @xmath469 , by lemma [ lem - bound ] , we know that @xmath533 . thus , with ( [ for-37 ] ) , we have the following result for ( a ) ,    @xmath534    for ( b ) , following the same approach given in the proof of claim ( 1 ) , we can easily get a similar result as claim ( 1 ) : @xmath535 with probability @xmath536 .    combining the above results for ( a ) and ( b ) , and setting the sample size @xmath493 and @xmath537",
    ", we have the following inequality , with probability @xmath495 , @xmath538 this means that @xmath509 induces a @xmath10-rotation for @xmath292 , where @xmath515 .",
    "by lemma [ lem - delta ] , we get the desired result , i.e. , @xmath539",
    ".    by theorem [ the - ralg1 ] and a similar idea with theorem [ the - rpa ] , we obtain the following theorem for regular single @xmath4-flat fitting problem .    [ the - rrpa ] let @xmath0 be the point set of a regular @xmath4-flat fitting problem in @xmath46 with regular factor @xmath469 . then if run algorithm recursive - projection on @xmath0 with sample size @xmath540 , with probability @xmath495 , the output @xmath277 contains a root - to - leaf path such that the @xmath4 points associated with the path determine a flat @xmath30 satisfying inequality @xmath541    without loss of generality , we assume that @xmath41 is the origin of @xmath46 .",
    "since all related flats in algorithm recursive - projection pass through @xmath41 , we can view every flat as a subspace in @xmath46 .    from the algorithm , we know",
    "that for any node @xmath278 at level @xmath120 of @xmath277 , @xmath88 , there is a corresponding implicit point set @xmath542 , which is the projection of @xmath0 on @xmath293 .",
    "there is also an implicit flat @xmath294 in @xmath293 . by theorem [ the - ralg1 ] ,",
    "we know that there is one child of @xmath278 , denoted as @xmath295 , such that the rotation of @xmath294 induced by @xmath296 forms a @xmath10-rotation with respect to @xmath542 , where @xmath543 .",
    "thus , if we always select such children ( i.e. , satisfying the above condition ) from root to leaf , we get a path with nodes @xmath300 , where @xmath301 is the root and @xmath302 is the child of @xmath303 .",
    "correspondingly , a sequence of implicit point sets @xmath304 and a sequence of flats @xmath305 also be obtained , which have the following properties .    1 .   initially , @xmath306 , and @xmath307 .",
    "2 .   for any @xmath88 , @xmath308 is the @xmath10-rotation of @xmath309 induced by @xmath310 , and @xmath311 is the projection of @xmath312 on @xmath313 ( see figure [ fig - project ] )    note that since both @xmath308 and @xmath309 locate on @xmath313 , they are all perpendicular to @xmath316 .",
    "the following claim reveals the dimensionality of each @xmath308 .    for @xmath88 , @xmath308 is a @xmath317-dimensional subspace .",
    "we prove the claim by induction . for the base case ( i.e. , @xmath111 )",
    ", @xmath398 has the same dimensionality as @xmath399 ( note @xmath400 ) .",
    "hence , @xmath398 is a @xmath4-dimensional subspace .",
    "then we assume that @xmath401 is a @xmath402-dimensional subspace for @xmath121 .",
    "now we consider the case of @xmath403 .",
    "since @xmath404 is a rotation of @xmath405 , they have the same dimensionality . also , from the algorithm , we know that @xmath405 is the subspace in @xmath406 which is perpendicular to @xmath407 , where @xmath408 is the projection of @xmath409 on @xmath406 .",
    "thus , @xmath405 is a @xmath410-dimensional subspace , which implies that @xmath404 is also a @xmath411-dimensional subspace .",
    "hence , claim ( * 5 * ) is proved .    by lemma [ lem - delta ] , we have the following claim .    for any @xmath88 , @xmath544 .",
    "we construct another sequence of flats @xmath320 as follows .    1 .   initially , @xmath321 .",
    "2 .   for any @xmath323 , @xmath324 .    from the above construction for @xmath327 , we have the following claim .    for any point @xmath328 ,",
    "let @xmath29 be the corresponding point when @xmath545 is mapped back to @xmath46 .",
    "then , @xmath329 .    from claim (",
    "* 5 * ) , we know that each @xmath327 is a @xmath4-dimensional subspace . from the algorithm , we know that @xmath330 ( see fig . [ fig - project ] ) , which implies @xmath546 @xmath332 .",
    "then by claim ( * 6 * ) and ( * 7 * ) , we have the following inequality .",
    "recursively using inequality ( [ for-39 ] ) , we have @xmath548 .",
    "meanwhile , we have @xmath549 .",
    "thus , @xmath550    by claim ( * 5 * ) , we know that @xmath337 is a @xmath201-dimension flat ( i.e. , the single line spanned by @xmath338 ) .",
    "hence , @xmath339 . thus",
    "if setting @xmath341 , we have @xmath541    * success probability : * each time we use theorem [ the - ralg1 ] , the success probability is @xmath551 ( we replace @xmath344 by @xmath345 tp increase the sample size from @xmath552 to @xmath553 ) .",
    "thus , the total success probability is @xmath554 .    with the above theorem",
    ", we can easily have the following theorem ( using the approach similar to theorem [ the - ptas ] ) .    [ the - rptas ]",
    "let @xmath0 be the point set of a regular @xmath25-projective clustering problem in @xmath46 with regular factor @xmath469 . if each optimal cluster has at least @xmath555 points from @xmath0 for some constant @xmath556 , algorithm projective - clustering yields a ptas with constant probability , where the running time of the ptas is @xmath557",
    "we first introduce the @xmath20 sense @xmath10-rotation .",
    "[ def - ldelta ] let @xmath0 be a points set , @xmath30 be a @xmath4-dimensional flat , and @xmath133 be a vector in @xmath46 with @xmath558 .",
    "further , let @xmath559 , and @xmath132 be a rotation of @xmath30 induced by @xmath127 with angle @xmath134 , where @xmath128 is the projection of @xmath127 on @xmath30 . then , @xmath132 is a @xmath10-rotation of @xmath30 ( with respect to @xmath0 ) if @xmath560 .",
    "[ lem - ldelta ] let @xmath0 be a point set , @xmath30 be a @xmath4-dimensional flat , and @xmath127 be a point in @xmath46 .",
    "if @xmath132 is a @xmath5 sense @xmath10-rotation ( with respect to @xmath0 ) of @xmath30 induced by the vector @xmath133 for some point @xmath558 , then for any integer @xmath24 , @xmath562        we prove this lemma by mathematical induction on @xmath566 . + * base case : * for @xmath567 , it is easy to see that @xmath568 .",
    "thus , base case holds .",
    "+ * induction step : * assume that the inequality holds for @xmath569 for some @xmath570 ( i.e. , induction hypothesis ) . now consider the case of @xmath571 . by the induction hypothesis , we have @xmath572    since both @xmath460 and @xmath509 are positive , we have @xmath573 . also , it is easy to know that @xmath574 thus , if replacing @xmath575 by @xmath576 in ( [ for-47 ] ) , we have @xmath577 @xmath578 hence , the inequality holds for @xmath571 .          since the rotation angle from @xmath30 to @xmath132 is @xmath582 , we have @xmath583 .",
    "let @xmath584 .",
    "then , we have @xmath585 using lemma [ lem - inequal ] with @xmath586 , @xmath587 , and @xmath588 , we have @xmath589 ) over @xmath29 , we have @xmath590 since @xmath591 and @xmath592 , the above inequality becomes @xmath593 thus the lemma is true .",
    "[ the - lptas ] let @xmath0 be the point set of an @xmath20 sense @xmath25-projective clustering problem in @xmath46 for integer @xmath24 .",
    "let @xmath358 be the optimal objective value . with constant probability and in @xmath34 time , algorithm projective - clustering outputs an approximation solution @xmath594 @xmath595 such that each @xmath327 is a @xmath4-flat , and @xmath596 , where @xmath166 is a subset of @xmath0 with at least @xmath238 points .",
    "[ lem - lbound ]",
    "let @xmath468 be a set of @xmath11 numbers with coefficient of variation @xmath469 , and @xmath470 be a random sample of @xmath471 .",
    "also , let @xmath474 and @xmath598 .",
    "then , for any positive constant @xmath472 and integer @xmath24 , @xmath599    [ the - lrptas ] let @xmath0 be the point set of an @xmath20 sense regular @xmath25-projective clustering problem in @xmath46 with regular factor @xmath469 , where @xmath24 is an integer .",
    "if each optimal cluster has size at least @xmath555 . then algorithm projective - clustering yields a ptas with constant probability , where the running time of the ptas is @xmath557 ."
  ],
  "abstract_text": [
    "<S> projective clustering is a problem with both theoretical and practical importance and has received a great deal of attentions in recent years . given a set of points @xmath0 in @xmath1 space , projective clustering is to find a set @xmath2 of @xmath3 lower dimensional @xmath4-flats so that the average distance ( or squared distance ) from points in @xmath0 to their closest flats is minimized . </S>",
    "<S> existing approaches for this problem are mainly based on adaptive / volume sampling or core - sets techniques which suffer from several limitations . in this paper , we present the first uniform random sampling based approach for this challenging problem and achieve linear time solutions for three cases , general projective clustering , regular projective clustering , and @xmath5 sense projective clustering . for the general projective clustering problem , </S>",
    "<S> we show that for any given small numbers @xmath6 , our approach first removes @xmath7 points as outliers and then determines @xmath3 @xmath4-flats to cluster the remaining points into @xmath3 clusters with an objective value no more than @xmath8 times of the optimal for all points . for regular projective clustering , </S>",
    "<S> we demonstrate that when the input points satisfy some reasonable assumption on its input , our approach for the general case can be extended to yield a ptas for all points . for @xmath5 sense projective clustering , </S>",
    "<S> we show that our techniques for both the general and regular cases can be naturally extended to the @xmath5 sense projective clustering problem for any @xmath9 . </S>",
    "<S> our results are based on several novel techniques , such as slab partition , @xmath10-rotation , symmetric sampling , and recursive projection , and can be easily implemented for applications . </S>"
  ]
}