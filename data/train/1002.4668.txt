{
  "article_text": [
    "the entire hardware industry has been moving to multi - core , which nowadays equips the large majority of computing platforms . the rapid shift toward multi - core technology",
    "has many drivers that are likely to sustain this trend for several years to come . in turn",
    ", software technology is also responding to this pressure @xcite .",
    "certainly , in the long term , writing parallel programs that are efficient , portable , and correct must be no more onerous than writing such programs for sequential computers .",
    "to date , however , parallel programming has not embraced much more than low - level communication and synchronization libraries . in the hierarchy of abstractions , it is only slightly above toggling absolute binary in the front panel of the machine .",
    "we believe that , among many , one of the reasons for such failure is the fact that programming multi - core is still perceived as a branch of high - performance computing with the consequent excessive focus on absolute performance measures . by definition ,",
    "the raison dtre for high - performance computing is high performance , but mips , flops and speedup need not be the only measure .",
    "human productivity , total cost and time to solution are equally , if not more , important @xcite .",
    "while a substantial methodological change will be required to allow effective design of parallel applications from scratch , the shift to multi - core is required to be graceful in the short term : existing applications should be ported to multi - core systems with moderate effort ( despite the fact that they could be redesigned with larger effort and larger performance gain ) .",
    "in this paper we present the _",
    "fastflow accelerator _ ,",
    "i.e. a software accelerator based on _ fastflow _ lock - free programming technology , and a methodology enabling programmers to seamlessly ( and semi - automatically ) transform a broad class of existing c / c++ program to parallel programs . the fastflow software accelerator , in contrast with classic hardware accelerators , allows execution of streams of tasks on unused cores of the cpu(s ) .",
    "the fastflow accelerator is build on top of the _ fastflow _ programming environment , which is a stack of c++ template libraries that , conceptually , progressively abstract the shared memory parallelism at the level of cores up to the definition of useful programming constructs and patterns ( skeletons ) @xcite .",
    "skeletons subsume a well - defined parallel semantics , which is used to ensure the correctness of the program when offloading tasks from a possibly sequential framework to a parallel one .",
    "fastflow is discussed in sec .",
    "[ sec : fastflow ] .    as we shall see in sec .",
    "[ sec : fastflow : acc ] , the fastflow accelerator ultimately consists in a specific usage of the fastflow framework .",
    "however , while fastflow , in the general case , _ requires _ redesign of the application , the fastflow accelerator suggests an easy and rapid way to improve the performance of existing c++ applications .",
    "this is further reinforced by the relative popularity ( especially among non - specialists ) of accelerator apis , such as _ opencl _ , _ cuda _ , ibm s dynamic application virtualization @xcite , and annotation languages such as _ openmp_. as we shall see in sec .",
    "[ sec : perf ] and sec .",
    "[ sec : exp ] , one of the advantages of the fastflow accelerator with respect to these environments is the tiny overhead introduced by the non - blocking lock - free synchronization mechanism which enables the parallelization of very fine grain activities , and thus broadens the applicability of the technique to legacy codes . finally , in sec .",
    "[ sec : exp ] we report on experiments with the proposed technique using a couple of simple yet significant examples : the c++ mandelbrot set application from nokia trolltech s qt examples @xcite , and a heavily hand - tuned c - based n - queens solver @xcite .",
    "as fig .  [",
    "fig : ff : architecture ] shows , fastflow is conceptually designed as a stack of layers that progressively abstract the shared memory parallelism at the level of cores up to the definition of useful programming constructs and patterns .",
    "the abstraction process has two main goals : 1 ) to promote high - level parallel programming , and in particular skeletal programming , i.e. pattern - based explicit parallel programming ; 2 ) to promote efficient programming for multi - core .    ]",
    "fastflow is specifically designed for cache - coherent multiprocessors , and in particular commodity homogenous multi - core ( e.g. intel core , amd k10 , etc . ) .",
    "it supports multiprocessors exploiting any memory consistency , including very weak consistency models .",
    "fastflow implementation is always lock - free , and for several memory consistency models is also memory fence - free ( e.g. , sequential consistency , total store ordering , and the x86 model ) . on other models ( e.g. , itanium and power4 , 5 , and 6 ) , a store fence before an enqueue is needed @xcite . at the current development status , fastflow does not include any specific optimization targeting cc - numa platforms , although their support is planned and under design .",
    "also , it currently does not automatically generate code running on gpus ( and other accelerators ) , even if it admits and supports the linking of code running on hardware accelerators .",
    "the full support of heterogenous platforms is currently under evaluation .",
    "[ 2 ]    bool push(void * const data ) if ( ! data ) return false ; if ( buf[pwrite]==null ) // writefence ( ) ; ( e.g. for non x86 cpu ) buf[pwrite ] = data ; pwrite+=(pwrite+1 > = size ) ? ( 1-size ) : 1 ; return true ; return false ; bool pop(void * * data ) if ( ! data || ( buf[pread]==null ) ) return false ; * data = buf[pread ] ; buf[pread]=null ; pread + = ( pread+1 > = size)?(1-size ) : 1 ; return true ;    taking inspiration from fastforward queues @xcite and lamport s wait - free protocols @xcite , the second tier provides mechanisms to define simple streaming networks whose _ run - time support _ is implemented through correct and efficient lock - free single - producer - single - consumer ( spsc ) queues .",
    "the fastflow run - time support layer realizes the two basic features : _ parallelism exploitation _ ,",
    "i.e. the creation , destruction and life cycle control of different flows of control sharing the memory , and _ asynchronous one - to - one communication channels _ , supporting the synchronization of different flows of control",
    ". they are implemented by way of lock - free single - producer - single - consumer ( spsc ) queue equipped with non - blocking ` push ` and ` pop ` operations .    while the former point can be addressed using quite standard technology ( i.e. the wrapping of existing threading libraries , such as posix threads ) ,",
    "the second exhibits a number of performance pitfalls on commodity shared - memory cache - coherent multiprocessors ( as many commodity multi - core are ) .",
    "in particular , traditional lock - free implementations ( such as lamport s solution @xcite ) of spsc queues are correct under sequential consistency only , where none of the current multi - cores implement sequential consistency . also , some correct queue implementations induce a very high invalidation rate  and thus reduced performance  because they exhibit the sharing of locations that are subject to alternative invalidations from communication partners ( e.g. head and tail of a circular buffers )",
    ". the implementation does not suffer from the aba problem @xcite , and it remains correct also in the case that only a reference instead of the full message is communicated using the queues .",
    "the fastflow spsc queue implementation ( shown in fig .",
    "[ fig : spsc ] ) is largely inspired by fastforward queues @xcite . as with fastforward queues , the ` push ` operation ( issued by the producer ) always reads and writes ` pwrite ` ( i.e. tail pointer ) only , and the ` push ` ( issued by the consumer ) always reads and writes ` pread ` ( i.e. head pointer ) only .",
    "this approach substantially differs from the traditional one ( e.g. in lamport s queues ) where both the producer and the consumer access both the head and tail pointers causing the continuous invalidation of cache lines holding head and tail pointers .",
    "one small , but significant , abstraction step is evident in the _ low - level programming _ layer , which provides one - to - many , many - to - one , and many - to - many synchronizations and data flows . in the fastflow approach these forms of communication are supported by spmc ( single - producer - multiple - consumer ) , mpsc ( multiple - producer - single - consumer ) , mpmc ( multiple - producer - multiple - consumer ) queues , respectively .",
    "they can be directly used as general asymmetric asynchronous channels among threads .",
    "clearly , messages flowing through these channels may carry memory pointers ( that behave also as synchronization tokens ) , since we are exploiting the underlying hardware cache - coherent shared memory .",
    "abstractly , these queues realize a general message passing api on top of a hardware shared memory layer .",
    "spmc , mpsc , and mpmc queues can be realized in several different ways , for example using locks , or in a lock - free fashion in order to avoid lock overhead ( which is a non - negligible overhead in multi - core architectures ) .",
    "however , these queues could not be _ directly _ programmed in a lock - free fashion without using at least one atomic operation , which is typically used to enforce the correct serialization of updates from either many producers or many consumers at the same end of the queue . these operations",
    ", however , induce a memory fence , thus a cache invalidation / update , which can seriously impair the performance of parallel programs exhibiting frequent synchronizations ( e.g. for fine - grain parallelism ) .",
    "with fastflow we advocate a different approach to the implementation of these queues , which require neither locks nor atomic operations .",
    "spmc , mpsc , and mpmc queues are realized by using only spsc queues and an arbiter thread , which enforce the correct serialization of producers and consumers . as shown in fig .",
    "[ fig : ff : architecture ] , this arbiter thread is called _ emitter _ ( e ) when it is used to dispatch data from one channel to many channels , _ collector _ ( c ) when it is used to gather data from many channels and push the messages into one channel , and _ collector - emitter _ ( ce ) when it behaves both as collector and emitter ( a.k.a .",
    "master - workers pattern ) .",
    "notice that , at this level , fastflow does not make any decision about thread scheduling and their mapping onto the core ; the programmer should be fully aware of all programming aspects and their potential performance drawback , such as load - balancing and memory alignment and hot - spots .      the next layer up , i.e. _ high - level programming _ , provides a programming framework based on parallelism exploitation patterns ( _ skeletons _ @xcite )",
    "they are usually categorized in three main classes : task , data , and stream parallelism .",
    "fastflowspecifically focuses on stream parallelism , and in particular provides : _ farm _ , _ farm - with - feedback _",
    "( i.e. divide&conquer ) , _ pipeline _ , and their arbitrary nesting and composition .",
    "the set of skeletons provided by fastflow could be further extended by building new c++ templates .",
    "stream parallelism can be used when there exists a partial or total order in a computation . by processing data elements in order , local state",
    "may be maintained in each filter .",
    "the set of skeletons provided by fastflow could be further extended by building new c++ templates on top of the fastflow low - level programming layer .",
    "task parallelism is explicit in the algorithm and consists of running the same or different code on different executors ( cores , processors , machines , etc . ) .",
    "different flows - of - control ( threads , processes , etc . )",
    "may communicate with one another as they work .",
    "communication usually takes place to pass data from one thread to the next as part of the same data - flow graph .",
    "data parallelism is a method for parallelizing a single task by processing independent data elements of this task in parallel .",
    "the flexibility of the technique relies upon stateless processing routines implying that the data elements must be fully independent .",
    "data parallelism also supports loop - level parallelism where successive iterations of a loop working on independent or read - only data are parallelized in different flows - of - control and concurrently executed .    while many of the programming frameworks mentioned in sec .",
    "[ sec : relwork ] offer data and task parallel skeletons , only few of them offer stream parallel skeletons ( such as tbb s _ pipeline _ ) .",
    "none of them offers the _ farm _ skeleton , which exploits functional replication of a set of _ workers _ and abstracts out the parallel filtering of successive _ independent _ items of the stream under the control of a scheduler , as a first - class concept .",
    "we refer to @xcite for implementation details and to @xcite for a performance comparison against posix locks , cilk , openmp , and tbb .",
    "fastflowis available at http://sourceforge.net/projects/mc-fastflow/ under gpl .",
    "regions marked with white circled figures , , , are copy - pasted .",
    "the region marked with black circled figure ( ) has been selected to be accelerated with a farm .",
    "it is copied with renaming of variables that are concurrently changed , e.g. automatic variables in a loop .",
    "a stream of task_t variables is used to keep all different values of these variables .",
    "grey boxes create and run the accelerator ; they are pre - determined according to the accelerator type .",
    "the code marked with executes the offloading onto the accelerator ; the target of the offloading is the svc method of the worker class .",
    "a _ fastflow accelerator _ is a software device wrapping a high - level fastflowprogram , i.e. a skeleton or a composition of skeletons , and providing the application programmer with a functional _ self - offloading _ feature , since the offload happens on the same hardware device , i.e. cpu cores .",
    "the primary aim of self - offloading is to provide the programmer with an easy and semi - automatic path to introducing parallelism into a c / c++ sequential code by moving or copying parts of the original code into the body of c++ methods , which will be executed in parallel according to a fastflowskeleton ( or skeleton composition ) .",
    "this requires limited programming effort and it may speed up the original code by exploiting unused cores .",
    "a fastflow accelerator provides the programmer with one ( untyped ) streaming input channel and one ( untyped ) streaming output channel that can be dynamically _ created _ ( and _ destroyed _ ) from a c++ code ( either sequential or multi - threaded ) as a c++ object ( fig .",
    "[ code : bench ] lines 2630 ) .",
    "thanks to the underlying shared memory architecture , messages flowing into these channels may carry both values and pointers to data structures .",
    "an accelerator , which is a collection of threads , has a global lifecycle with two stable states : _ running _ and _ frozen _ , plus several transient states .",
    "the running state happens when all threads are logically able to run ( i.e. they are ready or running at the o.s .",
    "the frozen state happens when all threads are suspended ( at the o.s .",
    "transitions from these two states involve calls to the underlying threading library ( and to the o.s . ) .",
    "once created , an accelerator can be run ( line 31 ) , making it capable of accepting tasks on the input channel .",
    "when running , the threads belonging to an accelerator might fall into an _ active waiting _ state .",
    "these state transitions exhibit a very low overhead and do not involve the o.s .",
    "threads not belonging to the accelerator could _ wait _ for an accelerator , i.e. suspend until the accelerator completes its input tasks ( receives the _ end - of - stream _ , unique is propagated in transient states of the lifecycle to all threads ) and then put it in the frozen state . at creation time , the accelerator is configured and its threads are bound into one or more cores . since the fastflow run - time is implemented via non - blocking threads , they will , if not frozen , fully load the cores in which they are placed , no matter whether they are actually processing something or not . because of this , the accelerator is usually configured to use `` spare '' cores ( although over - provisioning could be forced ) . if necessary",
    ", output tasks could be popped from the accelerator output channel .",
    "a fastflowaccelerator is defined by a fastflow skeletal composition augmented with an input stream and an output stream that can be , respectively , pushed and popped from outside the accelerator .",
    "both the functional and extra - functional behaviour of the accelerator is fully determined by the chosen skeletal composition .",
    "for example , the _ farm _ skeleton provides the parallel execution of the same code ( within a _ worker _",
    "object ) on independent items of the input stream .",
    "the _ pipeline _ skeleton provides the parallel execution of filters ( or stages ) exhibiting a direct data dependency . more complex behaviours can be defined by creating compositions of skeletons @xcite ;",
    "whose behaviour could be described using ( acyclic or cyclic ) data flow graphs .",
    "as we will see , clear knowledge of accelerator behaviour makes it possible to correctly parallelize segments of code .",
    "the use of a farm accelerator is exemplified in fig .",
    "[ code : bench ] .",
    "the code in the left column of the figure ( lines 117 ) shows a sequential program including three loops : a simple matrix multiplication .",
    "its accelerated version is shown on the right column ( lines 2059 ) .",
    "the accelerated version can be semi - automatically derived from the sequential by copy - pasting pieces of code into placeholders on a code template ( parts in white background in the left column ) : for example , code marked with , , , and are copied from left to right .",
    "the code that has been selected for the offloading , in this case the body of a loop marked with , is copied into the worker body after a suitable _ renaming _ of variables . because it is composed of threads",
    ", the accelerator shares the memory with its caller ( and other threads of the same process ) . as is well - known , transforming a sequential program into a parallel one requires regulation of possibly concurrent memory accesses . in low - level programming models",
    "this is usually done by using critical sections and monitors under the responsibility of the programmer .",
    "fastflow does not prohibit these mechanisms , but promotes a methodology to avoid them .",
    "in very general terms , the sequential code statement can be correctly accelerated with fastflowonly mechanisms if the offloaded code and the offloading code ( e.g. main thread ) instances do not break any data dependency , according to bernstein s conditions .",
    "fastflowhelps the programmer in enforcing these conditions in two ways : _ skeletons _ and _",
    "streams_.    the _ skeletal _ structure of the accelerator induces a well - defined partial ordering among offloaded parts of code .",
    "for example , no - order for farm , a chain of dependencies for pipeline , a directed acyclic graph for farm - pipeline nesting / composition , and a graph for a farm - with - feedback .",
    "the synchronization among threads is enforced by _ streams _ along the paths of the particular skeleton composition , as in a data - flow graph .",
    "true dependencies ( read - after - write ) are admissible only along these paths .",
    "streams can carry values or pointers , which act as synchronization tokens for indirect access to the shared memory .    pragmatically , streams couple quite well with the needs of sequential code parallelisation .",
    "in fact the creation of a stream to be offloaded on the accelerator can be effectively used to resolve anti - dependency ( write - after - read ) on variables since the stream can carry a copy of the values .",
    "for example , this happens when an iteration variable of an accelerated loop is updated after the ( asynchronous ) offload .",
    "this case naturally generalizes to all variables exhibiting a larger scope with respect to the accelerated code .",
    "the same argument can be used for output dependency ( write - after - write ) .",
    "fastflowaccelerator templates accommodate all variables of this kind in one or more structs or c++ classes ( e.g. ` task_t ` , lines 4446 ) representing the input , and , if present , the output stream data type .",
    "all other data accesses can be resolved by just relying on the underlying shared memory ( e.g. read - only , as a at line 54 , and single assignment as c at line 55 ) . the general methodology to accelerate existing c++ codes using the fastflowaccelerator",
    "is described in table  [ tab : methodology ] .    ' '' ''    it is worth noticing that the fastflowacceleration methodology may not be fully automated .",
    "it has been conceived to ease the task of parallelisation by providing the programmer with a methodology that helps in dealing with several common cases . however , many tasks require the programmer to make decisions , e.g. the selection of the code to be accelerated . in the example code in fig .  [",
    "code : bench ] there are several choices with different computation granularity : offload only the index @xmath0 or the indexes @xmath0 and @xmath1 , or all three indexes .",
    "also , the correctness of the final code depends on the programmer : they should ensure that the accelerated code is thread safe , streams have a suitable type and their pointers are correctly cast , memory accesses are properly renamed , etc .",
    "fastflow , like c / c++ itself , gives to the programmer much flexibility that should be used with great care .",
    "the fastflowaccelerator aims to provide good speedup with moderate effort .",
    "applications accelerated with fastflow , in contrast with fully - fledged fastflowapplications , are not _ fully _ parallel . as with the other accelerators , amdahl s law applies .",
    "thus , the maximum speedup of an accelerated application depends primarily on which parts of the code have been offloaded , and on what fraction of the overall execution time is spent in that code . equally important for performance",
    "is the quality of the parallel code running on the accelerator in terms of computation vs communication size , load balancing , memory alignment , data locality and avoidance of false - sharing . for these problems fastflowprovides the programmer with specific tools to tune the performance : a parallel memory allocator , mechanisms to control task scheduling , and a mechanism to trace the execution of the workers threads .",
    "a description of these tools goes beyond this paper : we refer to the fastflowdocumentation for further details @xcite .",
    "a significant advantage of the fastflowaccelerator with respect to other tools is the low latency of the run - time and the high flexibility of the framework .",
    "this , in turn , widens the parallelization possibilities to a broader class of applications , and especially those programs performing frequent synchronizations ( e.g. fine - grain parallelism ) .",
    "in this section we show the performance of the fastflow accelerator using two well - known applications : a mandelbrot set explorer and an n - queens solver . in both cases",
    "the code is third party and has been designed as sequential code ; then it has been made parallel with the fastflowfarm accelerator .",
    "all experiments reported in the following sections have been executed on two platforms :    andromeda : :    intel workstation with 2 quad - core xeon e5520 nehalem ( 16    hyperthreads ) @2.26ghz with 8 mb l3 cache and 24 gbytes of main memory .",
    "ottavinareale : :    intel workstation with 2 quad - core xeon e5420 harpertown @2.5ghz with    6 mb l2 cache and 8 gbytes of main memory .    with the exception of very long runs ,",
    "all presented experimental results are taken as an average of 5 runs exhibiting very low variance .",
    "all tested codes are available at the fastflowwebsite @xcite .      ' '' ''     +   + , title=\"fig : \" ] , title=\"fig : \" ]    ' '' ''     +   + , title=\"fig : \" ] , title=\"fig : \" ]    the `` qt mandelbrot '' is an interactive application that computes the mandelbrot set @xcite .",
    "it is part of the trolltech qt examples and it consists of two classes : ` renderthread.cpp ` , i.e. a ` qthread ` subclass that renders the mandelbrot set , and ` mandelbrotwidget.cpp ` , a ` qwidget ` subclass that shows the mandelbrot set on screen and lets the user zoom and scroll .",
    "the application is multi - threaded ( the two classes are run as qt threads ) but threads are not used to speed the computation up since the whole computation is done within a single thread ; rather they are used to decouple two different activities and to enhance responsiveness . during the time when the worker thread is recomputing the fractal to reflect the new zoom factor position , the main thread scales the previously rendered pixmap to provide immediate feedback .",
    "this use of threads is quite common in real life applications , where the user interface must remain responsive while some heavy operation is taking place .",
    "although it is a well - understood problem , the fully - fledged parallelization of the whole application is not trivial .",
    "the two threads synchronise with each other via qt events ; to guarantee responsiveness the ` mandelbrotwidget ` thread may start , restart , and abort the activity of ` renderthread ` .",
    "this kind of behavior , as well as the integration of qt threads with other threading libraries , makes porting to frameworks such as tbb and openmp non - trivial .",
    "the fastflowaccelerated version makes parallel the ` renderthread ` by using a farm accelerator on the outer loop that traverses the pixmap of the mandelbrot set .",
    "the farm accelerator is created once , then run and frozen each time a compute and interrupt signal is raised from ` mandelbrotwidget ` .",
    "the accelerated version can be easily derived by applying the methodology in sec .",
    "[ sec : selfoffloading ] . figure  [ fig : mandelbrot ] presents experimental results obtained by running the original code and the fastflowaccelerated version for 2 , 4 , 8 and 16 threads .",
    "as shown in the figure , the application has been tested for 8 refinement passes of the pixmap ( according to the original algorithm ) in 4 different regions of the plane exhibiting different execution times ( and different regularity ) ; in terms of amdahl s law , the smaller this time , the smaller the fraction of the application that can be made parallel , the smaller the maximum speedup .",
    "as is clear from the figure , the fastflowaccelerator is able to boost the sequential application close to ideal speedup in almost all cases .",
    "the n - queens problem is a generalization of the well - known 8-queens problem .",
    "n - queens have to be placed on an nxn sized chessboard such that no queen can attack any of the others .",
    "the objective is to count all possible solutions .",
    "one of the fastest sequential implementations available for solving the problem is the heavily optimised c code written by jeff somers @xcite .",
    "somer s algorithm calculates one half of the solutions ( considering one half of the columns ) , then flips the results over the `` y axis '' of the board .",
    "every solution can be reflected that way to generate another unique solution .",
    "that is because a solution can not be symmetrical across the y axis .",
    "we attempted to accelerate the execution time of the sequential code using fastflow .",
    "the fastflow version uses the farm construct without the collector entity .",
    "a stream of independent tasks , each corresponding to an initial placement of a number of queens on the board , is produced and offloaded into the farm accelerator .",
    "the placement of the remaining queens in a task is handled by one of the accelerator s worker threads . in order to speed up the code",
    ", we simply applied the methodology described in sec .",
    "[ sec : selfoffloading ] .",
    "we copied the part of code that we wished to accelerate into the _ svc _",
    "method of the worker class ; defined the stream type in such a way that it contained all the local variables that must be passed to the worker thread for the computation ; and produced the stream of tasks from the initial placement of a given number of queens .",
    "no additional data structure or optimization has been added to the new code version .    [",
    "fig : nqueentable ]    table [ tab : nqueens ] shows the execution times for the original sequential and the fastflow accelerated versions for different board sizes . in all the tests we used 16 worker threads and",
    "the stream has been produced from the initial placement of 4 queens ( the resulting number of tasks is shown in the table ) . as can be seen ,",
    "more than 10x speedup in the execution time has been obtained without any particular code optimization .",
    "in computing the word accelerator is used to refer to mechanisms that are used to speed up computation .",
    "the most widespread accelerators are hardware ones : the standard cpu is coupled with dedicated hardware optimized for a specific kind of computation .",
    "examples include cryptographic accelerators , which have been developed to perform processor - intensive decryption / encryption ; tcp / ip offload engines , which process the entire tcp / ip stack ; and finally the well - known graphics processing units ( gpus ) , which initially targeted graphics computations and are now increasingly used for a wider range of computationally intensive applications . usually accelerators feature a different architecture with respect to standard cpus and thus , in order to ease exploitation of their computational power , specific libraries are developed . in the case of gpus",
    "those libraries include _ brook _ , nvidia _ cuda _ and _",
    "opencl_.    brook @xcite provides extensions to the c language with single program multiple data ( spmd ) operations on streams .",
    "it abstracts the stream hardware as a coprocessor to the host system .",
    "user defined functions operating on stream elements are called _ kernels _ and can be executed in parallel .",
    "brook kernels feature blocking behaviour : the execution of a kernel must complete before the next kernel can execute .",
    "a similar execution model is available on gpus via the opencl framework @xcite and cuda @xcite .",
    "fastflowaccelerator differs from that of the previous libraries because it does not target specific accelerators ; instead it make possible the usage of some of the cores as a virtual accelerator .",
    "a recent work @xcite , using the charm++ programming model @xcite , has demonstrated that accelerator extensions are able to obtain good performance .",
    "furthermore , code written with these extensions is portable without changing the application s source code .",
    "however , in order to exploit the accelerator features , the application has to be entirely rewritten using the charm++ framework ; this is not necessary in fastflow .",
    "stream processing is extensively discussed in literature .",
    "stream languages are often motivated by the application style used in image processing , networking , media processing , and a wide and growing number of problems in finance .",
    "streamit @xcite is an explicitly parallel programming language based on the synchronous data flow model .",
    "a program is represented as a set of filters , i.e. autonomous actors ( containing java - like code ) that communicate through first - in first - out ( fifo ) data channels .",
    "filters can be assembled in _ pipeline _",
    ", possibly with a",
    "_ feedbackloop _ , or according to a _ splitjoin _",
    "data - parallel schema .",
    "s - net @xcite is a coordination language to describe the communications of asynchronous sequential components ( a.k.a .",
    "boxes ) written in a sequential language ( e.g. c , c++ , java ) through typed streams .",
    "the overall design of s - net is geared towards facilitating the composition of components developed in isolation .",
    "streaming applications are also targeted by tbb @xcite through the _ pipeline _ construct .",
    "however , tbb does not support any kind of non - linear streaming network , which therefore has to be embedded in a pipeline with significant drawbacks in terms of expressivity and performance . as an example",
    ", a streaming network structured a workflow ( a direct acyclic graph , actually ) can be embedded in pipeline but this require pipeline stages to bypass data in which they have no interest .",
    "this clearly requires to change both the interfaces of the stages and their business logic and can be hardly made parametric .",
    "in addition , artificial data dependencies are ( uselessly ) introduced in the application with the consequent performance drawback .",
    "@xcite is a very popular thread - based framework for multi - core architectures .",
    "it mostly targets data parallel programming and provides means to easily incorporate threads into sequential applications at a relatively high level . in an openmp program data needs to be labeled as shared or private , and compiler directives have to be used to annotate the code .",
    "both openmp and tbb can be used to accelerate serial c / c++ programs in specific portions of code , even if they do not natively include farm skeletons , which are instead realised by using lower - level features such as the _ task _ annotation in openmp and the _ parallel_for _ construct in tbb .",
    "openmp does not require restructuring of the sequential program , while with tbb , which provides thread - safe containers and some parallel algorithms , it is not always possible to accelerate the program without some refactoring of the sequential code .",
    "in our vision , fastflow falls between the easy programming of openmp and the powerful mechanisms provided by tbb .",
    "the fastflow accelerator allows one to speed - up execution of a wide class of existing c / c++ serial programs with just minor modifications to the code . to the best of our knowledge none of the mentioned frameworks",
    "supports lock - free ( and cas - free ) synchronizations .",
    "in this paper we introduced the fastflowaccelerator which represents a further evolution of the fastflowframework specifically designed to support the semi - automatic parallelization of existing sequential c / c++ applications on multi - cores .",
    "the fastflowaccelerator exhibits well - defined functional and extra - functional behaviour represented by a skeleton composition ; this helps in ensuring the correctness of the parallelization process .",
    "the main vehicle of parallelization is offloading of code kernels onto a number of additional threads on the same cpu ; we call this technique _ self - offloading_.    all in all , the work addresses an increasingly crucial problem for modern software engineering : how to make existing applications capable of effectively using modern multi - core systems with limited human effort . in this",
    "the fastflowaccelerator is supported by a semi - formal methodology and by the unique ability of fastflowto support very fine grain tasks on standard multi - cores .",
    "the effectiveness of the proposed methodology has been demonstrated by simple but challenging applications .",
    "the fastflowlibrary and the code for all the applications in sec .",
    "[ sec : exp ] are available under gpl at the fastflowwebsite  @xcite .",
    "m.  aldinucci , m.  danelutto , and p.  kilpatrick .",
    "autonomic management of non - functional concerns in distributed and parallel application programming . in _ proc . of intl .",
    "parallel & distributed processing symposium ( ipdps )",
    "_ , pages 112 , rome , italy , may 2009 .",
    "m.  aldinucci , m.  danelutto , m.  meneghin , p.  kilpatrick , and m.  torquati .",
    "efficient streaming applications on multi - core with fastflow : the biosequence alignment test - bed . in _ proc . of parallel computing ( parco )",
    "_ , lyon , france , sept .",
    "m.  aldinucci , m.  meneghin , and m.  torquati .",
    "efficient smith - waterman on multi - core with fastflow . in _ proc . of intl .",
    "euromicro pdp 2010 : parallel distributed and network - based processing _ , pisa , italy , feb .",
    "ieee .",
    "k.  asanovic , r.  bodik , j.  demmel , t.  keaveny , k.  keutzer , j.  kubiatowicz , n.  morgan , d.  patterson , k.  sen , j.  wawrzynek , d.  wessel , and k.  yelick .",
    "a view of the parallel computing landscape .",
    ", 52(10):5667 , 2009 .",
    "i.  buck , t.  foley , d.  horn , j.  sugerman , k.  fatahalian , m.  houston , and p.  hanrahan .",
    "brook for gpus : stream computing on graphics hardware . in _",
    "acm siggraph 04 papers _ , pages 777786 , new york , ny , usa , 2004 .",
    "acm press .",
    "j.  giacomoni , t.  moseley , and m.  vachharajani .",
    "fastforward for efficient pipeline parallelism : a cache - optimized concurrent lock - free queue . in _ proc . of the 13th acm sigplan symposium on principles and practice of parallel programming ( ppopp ) _ , pages 4352 , new york , ny , usa , 2008 .",
    "acm .",
    "l.  v. kal .",
    "performance and productivity in parallel programming via processor virtualization . in _ proc . of the 1st intl .",
    "workshop on productivity and performance in high - end computing ( at hpca 10 ) _ , madrid , spain , feb . 2004 .",
    "d.  m. kunzman and l.  v. kal . towards a framework for abstracting accelerators in parallel applications : experience with cell . in _",
    "sc 09 : proc . of the conference on high performance computing networking , storage and analysis _ , pages 112 , new york , ny , usa , 2009 .",
    "acm .",
    "a.  shafarenko , c.  grelck , and s .- b .",
    "semantics and type theory of s - net . in _ proc . of the 18th intl .",
    "symposium on implementation and application of functional languages ( ifl06 ) _ , tr 2006-s01 , pages 146166 .",
    "etvs lornd university , faculty of informatics , budapest , hungary , 2006 .",
    "w.  thies , m.  karczmarek , and s.  p. amarasinghe . : a language for streaming applications . in _ proc . of the 11th intl .",
    "conference on compiler construction ( cc ) _ , pages 179196 , london , uk , 2002 .",
    "springer - verlag ."
  ],
  "abstract_text": [
    "<S> fastflow is a programming environment specifically targeting cache - coherent shared - memory multi - cores . </S>",
    "<S> fastflow is implemented as a stack of c++ template libraries built on top of lock - free ( fence - free ) synchronization mechanisms . in this paper </S>",
    "<S> we present a further evolution of fastflow enabling programmers to offload part of their workload on a dynamically created software accelerator running on unused cpus . </S>",
    "<S> the offloaded function can be easily derived from pre - existing sequential code . </S>",
    "<S> we emphasize in particular the effective trade - off between human productivity and execution efficiency of the approach .    </S>",
    "<S> [ [ keywords ] ] keywords + + + + + + + +    multi - core , parallel programming , streaming , skeletons , accelerator , non - blocking , synchronization , lock - free , function offload . </S>"
  ]
}