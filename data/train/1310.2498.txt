{
  "article_text": [
    "non - dominated sorting is a combinatorial problem that is fundamental in multiobjective optimization , which is ubiquitous is scientific and engineering contexts  @xcite .",
    "the sorting can be viewed as arranging a finite set of points in euclidean space into layers according to the componentwise partial order .",
    "the layers are obtained by repeated removal of the set of minimal elements .",
    "more formally , given a set @xmath0 of @xmath1 points equipped with the componentwise partial order @xmath2 for @xmath3 .",
    "] , the first layer , often called the first pareto front and denoted @xmath4 , is the set of minimal elements in @xmath5 .",
    "the second pareto front @xmath6 is the set of minimal elements in @xmath7 , and in general the @xmath8 pareto front @xmath9 is given by @xmath10 in the context of multiobjective optimization , the @xmath11 coordinates of each point in @xmath5 are the values of the @xmath11 objective functions evaluated on a given feasible solution . in this way",
    ", each point in @xmath5 corresponds to a feasible solution and the layers provide an effective ranking of all feasible solutions with respect to the given optimization problem .",
    "rankings obtained in this way are at the heart of genetic and evolutionary algorithms for multiobjective optimization , which have proven to be valuable tools for finding solutions numerically  @xcite .",
    "figure [ fig : example - fronts ] gives a visual illustration of pareto fronts for randomly generated points .",
    "it is important to note that non - dominated sorting is equivalent to the longest chain problem in combinatorics , which has a long history beginning with ulam s famous problem of finding the length of a longest increasing subsequence in a sequence of numbers ( see  @xcite and the references therein ) .",
    "the longest chain problem is then intimately related to problems in combinatorics and graph theory  @xcite , materials science  @xcite , and molecular biology  @xcite . to see this connection ,",
    "let @xmath12 denote the length of a longest chain . ] in @xmath5 consisting of points less than or equal to @xmath13 with respect to @xmath2 .",
    "if all points in @xmath5 are distinct , then a point @xmath14 is a member of @xmath4 if and only if @xmath15 . by peeling off @xmath4 and making the same argument",
    ", we see that @xmath16 is a member of @xmath6 if and only if @xmath17 . in general , for any @xmath14 we have @xmath18 this is a fundamental observation .",
    "it says that studying the shapes of the pareto fronts is equivalent to studying the longest chain function @xmath19 .",
    "the longest chain problem has well - understood asymptotics as @xmath20 . in this context , we assume that @xmath21 where @xmath22 are _ i.i.d . _  random variables in @xmath23 and let @xmath24 denote the length of a longest chain in @xmath5 .",
    "the seminal work on the problem was done by hammersley  @xcite , who studied the problem for @xmath22 _ i.i.d .",
    "_  uniform on @xmath25 ^ 2 $ ] .",
    "he utilized subadditive ergodic theory to show that @xmath26 in probability , where @xmath27 .",
    "he conjectured that @xmath28 , and this was later proven by vershik and kerov  @xcite and logan and shepp  @xcite .",
    "hammersley s results were generalized to higher dimensions by bollobs and winkler  @xcite , who showed that @xmath29 almost surely , where @xmath30 are constants tending to @xmath31 as @xmath32 .",
    "the only known values of @xmath33 are @xmath34 and @xmath35 .",
    "deuschel and zeitouni  @xcite provided another generalization of hammersley s results ; for @xmath22 _ i.i.d .",
    "_  on @xmath25 ^ 2 $ ] with @xmath36 density function @xmath37 ^ 2 \\to { \\mathbb{r}}$ ] , bounded away from zero , they showed that @xmath38 in probability , where @xmath39 is the supremum of the energy @xmath40 over all @xmath41\\to[0,1]$ ] nondecreasing and right continuous .    in  @xcite",
    ", we studied the longest chain problem for @xmath22 _ i.i.d . _  on @xmath42 with density function @xmath43 . under general assumptions on @xmath44",
    ", we showed that @xmath45 in @xmath46 almost surely , where @xmath47 is the viscosity solution of the hamilton ",
    "jacobi equation @xmath48 here @xmath49 and @xmath50 .",
    "in this paper we study a fast numerical scheme for ( p ) , first proposed in  @xcite , and prove convergence of this scheme .",
    "we then show how the scheme can be used to design a fast approximate non - dominated sorting algorithm , which requires access to only a fraction of the datapoints @xmath22 , and we evaluate the sorting accuracy of the new algorithm on both synthetic and real data . a fast approximate algorithm for non - dominated sorting has the potential to be a valuable tool for multiobjective optimization , especially in evolutionary algorithms which require frequent non - dominated sorting  @xcite .",
    "there are also potential applications in polynuclear growth of crystals in materials science  @xcite . here , the scheme for ( p ) could be used to simulate polynuclear growth in the presence of a macroscopically inhomogeneous growth rate .",
    "this paper is organized as follows . in section",
    "[ sec : convergence ] we prove that the numerical solutions converge to the viscosity solution of ( p ) .",
    "we also prove a regularity result for the numerical solutions ( see lemma [ lem : holder ] ) and other important properties . in section [ sec : num ] we demonstrate the numerical scheme on several density functions , and in section [ sec : fast ] we propose a fast algorithm for approximate non - dominated sorting that is based on numerical solving ( p ) .",
    "let us first fix some notation . given @xmath51 we write @xmath52 if @xmath53 and @xmath54 .",
    "we write @xmath55 when @xmath56 for all @xmath57 . for",
    "@xmath58 , @xmath59 and @xmath60 will retain their usual definitions .",
    "for @xmath53 we define @xmath61 = \\{z \\in { \\mathbb{r}}^d \\ , : \\ , x \\leqq z \\leqq y\\ } , \\ \\ ( x , y ] = \\{z \\in { \\mathbb{r}}^d \\ , : \\ , x <",
    "z \\leqq y\\},\\ ] ] and make similar definitions for @xmath62 and @xmath63 . for any @xmath64 and @xmath65 , there exists unique @xmath66 and @xmath67 such that @xmath68",
    ". we will denote @xmath69 by @xmath70 so that @xmath71 .",
    "we also denote @xmath72 and @xmath73 . for @xmath74 , we denote by @xmath75 $ ] the projection mapping @xmath42 onto @xmath76 $ ] . for @xmath77 this mapping",
    "is given explicitly by @xmath78 we say a function @xmath79 is pareto - monotone if @xmath80    we now recall the numerical scheme from  @xcite .",
    "let @xmath65 . for a given @xmath77 ,",
    "the domain of dependence for ( p ) is @xmath81 .",
    "this can be seen from the connection to non - dominated sorting and the longest chain problem .",
    "it is thus natural to consider a scheme for ( p ) based on backward difference quotients , yielding @xmath82 where @xmath83 is the numerical solution of ( p ) and @xmath84 are the standard basis vectors in @xmath42 . under reasonable hypotheses on @xmath44 , described in section [ sec : convergence - proof ] , there exists a unique pareto - monotone viscosity solution of ( p ) .",
    "as we wish to numerically approximate this pareto - monotone solution we may assume that @xmath85 for all @xmath57 .",
    "given that @xmath44 is non - negative , for any @xmath86 , there is a unique @xmath87 with @xmath88 satisfying .",
    "hence the numerical solution @xmath89 can be computed by visiting each grid point exactly once via any sweeping pattern that respects the partial order @xmath2 .",
    "the scheme therefore has linear complexity in the number of gridpoints . at each grid point",
    ", the scheme can be solved numerically by either a binary search and/or newton s method restricted to the interval @xmath90.\\ ] ] in the case of @xmath91 , we can solve the scheme explicitly via the quadratic formula @xmath92    now extend @xmath89 to a function @xmath93 by setting @xmath94 .",
    "defining @xmath95 we see that @xmath89 is a pareto - monotone solution of the discrete scheme @xmath96 where @xmath97 is defined by @xmath98 here , @xmath99 is the space of functions @xmath100 . in the next section",
    "we will study properties of solutions @xmath89 of ( s ) .",
    "in this section we prove that the numerical solutions @xmath89 defined by ( s ) converge uniformly to the viscosity solution of ( p ) . as in  @xcite , we place the following assumption on @xmath101 :    * there exists an open and bounded set @xmath102 with lipschitz boundary such that @xmath103 is lipschitz and @xmath104 .",
    "it is worthwhile to take a moment to motivate the hypothesis ( h ) .",
    "consider the following multi - objective optimization problem @xmath105 where @xmath106 with @xmath107 for all @xmath57 , and @xmath108 is the set of feasible solutions .",
    "this formulation includes many types of constrained optimization problems , where the constraints are implicitly encoded into @xmath108 .",
    "if @xmath109 are feasible solutions in @xmath108 , then these solutions are ranked , with respect to the optimization problem , by performing non - dominated sorting on @xmath110 .",
    "thus the domain @xmath111 of @xmath22 is given by @xmath112 .",
    "supposing that @xmath109 are , say , uniformly distributed on @xmath108 , then the induced density @xmath44 of @xmath22 on @xmath42 will be nonzero on @xmath111 and identically zero on @xmath113 .",
    "thus , the constraint that feasible solutions must lie in @xmath108 directly induces a discontinuity in @xmath44 along @xmath114 .    in  @xcite",
    "we showed that , under hypothesis ( h ) , there exists a unique pareto - monotone viscosity solution @xmath47 of ( p ) satisfying the additional boundary condition @xmath115 the boundary condition is natural for this problem . indeed , since @xmath116 , there are almost surely no random variables drawn outside of @xmath117 .",
    "hence , for any @xmath77 we can write @xmath118^d \\ , : \\ ,   y\\leqq x } u_n(y).\\ ] ] since @xmath19 is pareto - monotone , the maximum above is attained at @xmath119 , and hence @xmath120 .    for completeness ,",
    "let us now give a brief outline of the proof of uniqueness for ( p ) .",
    "for more details , we refer the reader to  @xcite . the proof is based on the auxiliary function technique , now standard in the theory of viscosity solutions  @xcite .",
    "however , the technique must be modified to account for the fact that @xmath44 is possibly discontinuous on @xmath114 , and hence does not possess the required uniform continuity .",
    "a commonly employed technique is to modify the auxiliary function so that only a type of one - sided uniform continuity is required of @xmath44  @xcite .",
    "this allows @xmath44 to , for example , have a discontinuity along a lipschitz curve , provided the jump in @xmath44 is locally in the same direction ( see @xcite for more details ) .",
    "we can not directly use these results because they require coercivity or uniform continuity of the hamiltonian and/or lipschitzness of solutions ",
    "none of which hold for ( p ) . our technique for proving uniqueness for ( p ) employs instead an important property of viscosity solutions of ( p)namely that for any @xmath121 , @xmath122 is a viscosity subsolution of ( p ) .",
    "this property , called _ truncatability _ in  @xcite , follows immediately from the variational principle  @xcite @xmath123 this allows us to prove a comparison principle with no additional assumptions on the hamiltonian .",
    "a general framework for proving convergence of a finite - difference scheme to the viscosity solution of a non - linear second order pde was developed by barles and souganidis  @xcite .",
    "their framework requires that the scheme be stable , monotone , consistent , and that the pde satisfy a _ strong uniqueness property",
    "_  @xcite .",
    "the monotonicity condition is equivalent to ellipticity for second order equations , and plays a similar role for first order equations , enabling one to prove maximum and/or comparison principles for the discrete scheme .",
    "the strong uniqueness property refers to a comparison principle that holds for semicontinuous viscosity sub- and supersolutions .    the numerical scheme ( s )",
    "is easily seen to be consistent ; this simply means that @xmath124 for all @xmath125 .",
    "the scheme is stable  @xcite if the numerical solutions @xmath89 are uniformly bounded in @xmath126 , independent of @xmath127 .",
    "it is not immediately obvious that ( s ) is stable ; stability follows from the discrete comparison principle for ( s ) ( lemma [ lem : discrete - comp ] ) and is proved in lemma [ lem : holder ] .",
    "the monotonicity property requires the following : @xmath128 it is straightforward to verify that ( s ) is monotone when restricted to pareto - monotone @xmath129 .",
    "this is sufficient since we are only interested in the pareto - monotone viscosity solution of ( p ) .",
    "all that is left is to establish a strong uniqueness result for ( p ) .",
    "unfortunately such a result is not available under the hypothesis ( h ) .",
    "since @xmath44 may be discontinuous along @xmath114 , we can only establish a comparison principle for continuous viscosity sub- and supersolutions ( see ( * ? ? ?",
    "* theorem 4 ) ) .",
    "one way to rectify this situation is to break the proof into two steps .",
    "first prove convergence of the numerical scheme for @xmath44 lipschitz on @xmath130 .",
    "it is straightforward in this case to establish a strong uniqueness result for ( p ) .",
    "second , extend the result to @xmath44 satisfying ( h ) by an approximation argument using inf and sup convolutions .",
    "although this approach is fruitful , we take an alternative approach as it yields an interesting regularity property for the numerical solutions . in particular , in lemma [ lem : holder ] we establish approximate hlder regularity of @xmath89 of the form latexmath:[\\[\\label{eq : holder - est }    verify in appendix a , the approximate hlder estimate along with the stability of ( s ) allows us to apply the arzel - ascoli theorem , with a slightly modified proof , to the sequence @xmath89 .",
    "this allows us to substitute the ordinary uniqueness result from  @xcite in place of strong uniqueness .",
    "we first prove a discrete comparison principle for the scheme ( s ) .",
    "this comparison principle is essential in proving stability of ( s ) and the approximate hlder regularity result in lemma [ lem : holder ] .",
    "for the remainder of this section , we fix @xmath65 .",
    "[ lem : discrete - comp ] let @xmath132 and suppose @xmath133 are pareto - monotone and satisfy @xmath134.\\ ] ] then @xmath135 on @xmath136 $ ] implies that @xmath135 on @xmath76 $ ] .",
    "suppose that @xmath137 } ( u - v ) > 0 $ ] and set @xmath138 and @xmath139\\}.\\ ] ] since @xmath135 on @xmath140 and @xmath137 } ( u - v ) > 0 $ ] , we must have @xmath141 $ ] , where @xmath142 . by the definition of @xmath143",
    ", there exists @xmath144 $ ] and @xmath145 such that @xmath146 since @xmath145 , we have @xmath135 on @xmath147 $ ] and hence @xmath148 the second inequality above follows from pareto - monotonicity of @xmath149 .",
    "since @xmath150 and @xmath149 are pareto - monotone and @xmath151 we have @xmath152 hence @xmath153 , contradicting the hypothesis .    using the comparison principle",
    ", we can establish that numerical solutions of ( s ) satisfy the boundary condition at infinity .",
    "[ prop : boundary_condition ] let @xmath154 be pareto - monotone with @xmath155 on @xmath156 .",
    "suppose that for some @xmath132 we have @xmath157.\\ ] ] then we have @xmath158 .",
    "define @xmath159 and fix @xmath77 .",
    "since @xmath150 is pareto - monotone and @xmath160 , we have @xmath161 .",
    "hence @xmath162 .",
    "since @xmath163 on @xmath76 $ ] we have @xmath164\\setminus \\gamma_h.\\ ] ] for @xmath165\\cup \\gamma_h$ ] we have @xmath166 by assumption .",
    "since @xmath149 is pareto - monotone we have @xmath167 for such @xmath13 , and hence @xmath168 for all @xmath169 .",
    "since @xmath170 on @xmath156 we can apply lemma [ lem : discrete - comp ] to find that @xmath171 on @xmath172 , and hence @xmath173 .",
    "an important consequence of the comparison principle is the following approximate hlder regularity result .",
    "[ lem : holder ] let @xmath174 be pareto - monotone with @xmath155 on @xmath156 .",
    "then for any @xmath175 we have @xmath176^d$ ] .",
    "let @xmath175 and @xmath177^d$ ] .",
    "we first deal with the case where @xmath178 .",
    "set @xmath179 and define @xmath180 by @xmath181 by the concavity of @xmath182 we have @xmath183 for any @xmath184 and hence @xmath185 by the translation invariance of @xmath186 and we have @xmath187 set @xmath188 . for @xmath77 set @xmath189^d)}\\sum_{i=1}^d \\psi(x - b^i),\\ ] ] and note that @xmath190 is pareto - monotone .",
    "let @xmath191 $ ] . then for some @xmath192 we have @xmath193 , and hence @xmath194 .",
    "we therefore have @xmath195^d ) } ( \\psi(x - b^k ) - \\psi(x - b^k - h e_i))\\bigg ) \\\\ & { } \\geq{}s(h , x,{\\widehat}{u } ) +   \\|s(h,\\cdot , u)\\|_{l^\\infty((h , r]^d ) } s(h , x,\\psi(\\cdot - b^k))\\\\ & { } \\hspace{-2.4mm}\\stackrel{\\eqref{eq : h - super}}{\\geq } { } \\hspace{-2.4mm}s(h , x,{\\widehat}{u } ) +   \\|s(h,\\cdot , u)\\|_{l^\\infty((h , r]^d ) } \\\\ & { } \\geq { } s(h , x , u).\\end{aligned}\\ ] ] suppose now that @xmath196 $ ] .",
    "then since @xmath197 on @xmath198 $ ] we have @xmath199 and hence @xmath200 .",
    "since @xmath201 on @xmath202^d$ ] , we can apply lemma [ lem : discrete - comp ] to obtain @xmath203 on @xmath204^d$ ] , which yields @xmath205^d)}^\\frac{1}{d } \\sum_{i=1}^d \\psi(y_0 - b^i ) \\notag \\\\ & { } \\leq { } dr^\\frac{d-1}{d}\\|s(h,\\cdot , u)\\|_{l^\\infty((h , r]^d)}^\\frac{1}{d } \\sum_{i=1}^d ( y_{0,i } - x_{0,i } + h)^\\frac{1}{d}\\notag \\\\ & { } \\leq { } d^2r^\\frac{d-1}{d}\\|s(h,\\cdot , u)\\|_{l^\\infty((h , r]^d)}^\\frac{1}{d } ( |x_0 - y_0|^\\frac{1}{d } +   h^\\frac{1}{d}).\\end{aligned}\\ ] ] noting that @xmath206 we have @xmath207 , which completes the proof for the case that @xmath178 .",
    "suppose now that @xmath177^d$ ] such that @xmath208 .",
    "set @xmath209 then @xmath210 , @xmath211 , @xmath212 , and @xmath213 . it follows that @xmath214^d)}^\\frac{1}{d } ( |x_0 - y_0|^\\frac{1}{d } + h^\\frac{1}{d}),\\end{aligned}\\ ] ] which completes the proof .",
    "our main result is the following convergence statement for the scheme ( s ) .",
    "[ thm : conv ] let @xmath44 be nonnegative and satisfy ( h ) .",
    "let @xmath47 be the unique pareto - monotone viscosity solution of ( p ) satisfying .",
    "for every @xmath65 let @xmath93 be the unique pareto - monotone solution of ( s ) . then @xmath215 uniformly on @xmath172 as @xmath216 .",
    "by ( h ) we have that @xmath217 for @xmath218 , and hence @xmath219^d$ ] .",
    "therefore , by proposition [ prop : boundary_condition ] , we have that @xmath89 satisfies . combining this with lemma [ lem : holder ]",
    "we have @xmath220 for all @xmath65 .",
    "similarly , combining with lemma [ lem : holder ] we have latexmath:[\\[\\label{eq : holder }    for every @xmath65 . the estimates in and show uniform boundedness , and a type of equicontinuity , respectively , for the sequence @xmath89 .",
    "by an argument similar to the proof of the arzel - ascoli theorem ( see the appendix ) , there exists a subsequence @xmath222 and @xmath223 such that @xmath224 uniformly on compact sets in @xmath172 . by",
    ", we actually have @xmath224 uniformly on @xmath172 .",
    "since the scheme ( s ) is monotone and consistent , it is a standard result that @xmath150 is a viscosity solution of ( p )  @xcite .",
    "note that @xmath89 is pareto - monotone , @xmath225 on @xmath156 , and @xmath89 satisfies .",
    "since @xmath224 uniformly , it follows that @xmath150 is pareto - monotone , @xmath155 on @xmath226 , and @xmath150 satisfies . by uniqueness for ( p )  ( * ? ? ?",
    "* theorem 5 ) we have @xmath227 . since we can apply the same argument to any subsequence of @xmath89 , it follows that @xmath215 uniformly on @xmath172 .    in section [ sec : num ] , we observe that the numerical scheme provides a fairly consistent underestimate of the exact solution of ( p ) .",
    "the following lemma shows that this is indeed the case whenever the solution @xmath47 of ( p ) is concave .",
    "[ lem : conv - below ] let @xmath44 be nonnegative and satisfy ( h ) .",
    "let @xmath47 be the unique pareto - monotone viscosity solution of ( p ) satisfying .",
    "for every @xmath65 let @xmath93 be the unique pareto - monotone solution of ( s ) . if @xmath47 is concave on @xmath172 then @xmath228 for every @xmath65 .",
    "fix @xmath65 . since @xmath47 is concave , it is differentiable almost everywhere .",
    "is pareto - monotone also implies differentiability almost everywhere .",
    "] let @xmath184 be a point at which @xmath47 is differentiable and @xmath44 is continuous .",
    "since @xmath47 is concave we have @xmath229 since @xmath47 is a viscosity solution of ( p ) and @xmath44 is continuous at @xmath13 we have @xmath230 since @xmath231 is continuous , we see that @xmath232 for all @xmath233 $ ]",
    ". now define @xmath234 .",
    "then we have @xmath235,\\ ] ] and @xmath236 on @xmath156 .",
    "it follows from lemma [ lem : discrete - comp ] that @xmath237 .",
    "since @xmath47 is pareto - monotone , we have @xmath238 , which completes the proof .",
    "we now present some numerical results using the scheme ( s ) to approximate the viscosity solution of ( p ) .",
    "we consider four special cases where the exact solution of ( p ) can be expressed in analytical form .",
    "let @xmath239 , @xmath240 , @xmath241^d}(x ) \\ \\ \\",
    "\\text{and } \\ \\ \\ f_4(x ) { } = { } \\left(\\sum_{i=1}^d x_i^9\\right)^{1-d } \\prod_{i=1}^d \\left ( 9 x_i^9 + \\sum_{i=1}^d x_i^9\\right).\\end{aligned}\\ ] ] here , @xmath242 denotes the characteristic function of the set @xmath243 .",
    "the corresponding solutions of ( p ) are @xmath244 , @xmath245 , and @xmath246 where @xmath247 is the error function defined by @xmath248 , and @xmath249 . the solutions @xmath250 and @xmath251 are special cases of the formula @xmath252 } f(y ) \\ , dy\\right)^\\frac{1}{d},\\ ] ] which holds when @xmath44 is separable , i.e. , @xmath253  @xcite .",
    "the solution @xmath254 can be obtained by the method of characteristics .",
    "we chose to evaluate the proposed numerical scheme for @xmath255 because it has non - convex level sets , and then computed @xmath256 via ( p ) . in the probabilistic interpretation of ( p ) as the continuum limit of",
    "non - dominated sorting , non - convex pareto fronts play an important role  @xcite .",
    "we computed the numerical solutions for @xmath91 and @xmath257 .",
    "for @xmath91 we used a @xmath258 grid , and for @xmath257 , we used a @xmath259 grid and solved the scheme at each grid point via a binary search with precision @xmath260 .",
    "figures [ fig:2d - sim ] and [ fig:3d - sim ] compare the level sets of the exact solutions to those of the numerical solutions for @xmath91 and @xmath257 , respectively . in figure [ fig:2d - sim ] , the thin lines correspond to the exact solution while the thick lines correspond to the numerical solutions , with the exception of [ fig : nonconvex-2d ] where both are thin lines for increased visibility . in figure",
    "[ fig:3d - sim ] , the darker surfaces correspond to the numerical solution while the lighter surfaces represent the exact solution . for both @xmath91 and @xmath257 , we can see that the level sets of the numerical solutions consistently overestimate the true solution , indicating that the numerical solutions are converging from below to the exact solutions .",
    "we proved in lemma [ lem : conv - below ] that @xmath261 whenever @xmath47 is concave , so this observation is to be expected .",
    "note however , that @xmath254 is not convex , yet the overestimation is still present , indicating that lemma [ lem : conv - below ] may hold under more general hypotheses on @xmath47 .",
    "we also observe that @xmath254 has a shock , which is resolved reasonably well for @xmath91 and @xmath257 , given the grid sizes used .",
    "we show here the results of some numerical experiments concerning the rate of convergence of @xmath215 and @xmath262 .",
    "figure [ fig : pde - rates ] shows @xmath263 ^ 2)}$ ] and @xmath264 versus @xmath127 for the density @xmath265^d}(x)$ ] from the beginning of section [ sec : num ] .",
    "both norms appear to have convergence rates on the order of @xmath266 , and a regression analysis yields @xmath267 for the @xmath126 norm and @xmath268 for the @xmath269 norm .",
    "thus , it is reasonable to suspect an @xmath126 convergence rate of the form @xmath270 for some constant @xmath271 .",
    "we intend to investigate this in a future work .",
    "it is quite natural that the convergence rate for the @xmath269 norm is substantially better than the @xmath126 norm , due to the non - differentiability of @xmath254 at the boundary @xmath272 .",
    "this induces a large error near @xmath272 which has a more significant impact on the @xmath126 norm .    to measure the rate of convergence of @xmath273",
    ", we consider the following two norms @xmath274 shows and versus @xmath1 for the same density @xmath275 .",
    "for each @xmath1 the values of and were computed by taking the average over @xmath276 independent realizations .",
    "it appears that both norms decay on the order of @xmath277 , and a regression analysis yields @xmath278 for the @xmath269 norm and @xmath279 for the @xmath126 norm .",
    "these results are in line with the known convergence rates for the longest chain problem with a uniform distribution on @xmath25^d$ ]  @xcite .",
    "the results for the other densities @xmath280 and @xmath256 are similar .",
    "we demonstrated the convergence rates on @xmath275 due to the fact that it has many important features ; namely , it is discontinuous , yields non - convex pareto - fronts , and induces a shock in the viscosity solution @xmath254 of ( p ) .",
    "we demonstrate now how the numerical scheme ( s ) can be used for fast approximate non - dominated sorting , and give a real - world application to anomaly detection in section [ sec : real ] .",
    "we assume here that the given data @xmath22 are drawn _ i.i.d . _  from a reasonably smooth density function @xmath44 , and that @xmath1 is large enough so that @xmath281 is well approximated by @xmath282 . in this regime , it is reasonable to consider an approximate non - dominated sorting algorithm based on numerically solving ( p ) .",
    "a natural algorithm is as follows .",
    "since the density @xmath44 is rarely known in practice , the first step is to form an estimate @xmath283 of @xmath44 using the samples @xmath22 . in the large sample regime , this can be done very accurately using , for example , a kernel density estimator  @xcite or a @xmath192-nearest neighbor estimator  @xcite . to keep the algorithm as simple as possible , we opt for a simple histogram to estimate @xmath44 , aligned with the same grid used for numerically solving ( p ) .",
    "when @xmath1 is large , the estimation of @xmath44 can be done with only a random subset of @xmath22 of cardinality @xmath284 , which avoids considering all @xmath1 samples .",
    "the second step is to use the numerical scheme ( s ) to solve ( p ) on a fixed grid of size @xmath127 , using the estimated density @xmath283 on the right hand side of ( p ) .",
    "this yields an estimate @xmath285 of @xmath47 , and the final step is to evaluate @xmath285 at each sample @xmath22 to yield approximate pareto ranks for each point .",
    "the final evaluation step can be viewed as an interpolation ; we know the values of @xmath285 on each grid point and wish to evaluate @xmath285 at an arbitrary point .",
    "a simple linear interpolation is sufficient for this step .",
    "however , in the spirit of utilizing the pde ( p ) , we solve the scheme ( s ) at each point @xmath22 using the values of @xmath285 at neighboring grid points , i.e. , given @xmath286 for all @xmath57 , and @xmath287 $ ] , we compute @xmath288 by solving @xmath289 where @xmath290 . in",
    "we compute @xmath291 by linear interpolation using adjacent grid points .",
    "figure [ fig : subgrid ] illustrates the grid used for computing @xmath288 .",
    "according to .",
    "the values of @xmath292 and @xmath293 are computed by linear interpolation using adjacent grid points , i.e. , @xmath292 is computed via linearly interpolating between @xmath294 and @xmath295.,scaledwidth=45.0% ]    the entire algorithm is summarized in algorithm [ alg : ndom ] .",
    "[ alg : ndom ] fast approximate non - dominated sorting    1 .",
    "select @xmath192 points from @xmath22 at random . call them @xmath296 .",
    "2 .   select a grid spacing @xmath127 for solving the pde and estimate @xmath44 with a histogram aligned to the grid @xmath297 , i.e. , @xmath298 3 .",
    "compute the numerical solution @xmath285 on @xmath299^d$ ] via ( s ) .",
    "4 .   evaluate @xmath300 for @xmath301 via interpolation .    for simplicity of discussion",
    ", we have assumed that @xmath22 are drawn from @xmath25^d$ ] , but this is not essential as the scheme ( s ) can be easily adapted to any hypercube in @xmath42 , and this is in fact what we do in our implementation of algorithm [ alg : ndom ] .",
    "it is important to understand how the parameters @xmath192 and @xmath127 in algorithm [ alg : ndom ] affect the accuracy of the estimate @xmath302 .",
    "we first consider the estimate @xmath303 . by",
    ", we can write @xmath304}(y_i).\\ ] ] hence @xmath305 is the average of _ i.i.d . _  bernoulli random variables with parameter @xmath306 } f(y ) \\ , dy.\\ ] ] by the central limit theorem , the fluctuations of @xmath307 about its mean satisfy @xmath308 with high probability .",
    "let us suppose now that @xmath44 is globally lipschitz .",
    "the following can be easily modified for @xmath44 more or less regular , yielding similar results . then by we",
    "have @xmath309 combining this with we have @xmath310^d\\cap h{\\mathbb{n}}^d ) } \\leq c\\left ( \\frac{1}{\\sqrt{k}h^d } + h\\right),\\ ] ] with high probability . by the discrete comparison principle ( lemma [ lem : discrete - comp ] ) and we have that @xmath311^d ) } \\leq d\\|{\\widehat}{f}_h - f\\|^\\frac{1}{d}_{l^\\infty([0,1]^d\\cap h{\\mathbb{n}}^d ) } \\leq c\\left(k^{-\\frac{1}{2d}}h^{-1 } + h^\\frac{1}{d}\\right),\\ ] ] with high probability . based on the numerical evidence presented in section [ sec : pde - rates ] ,",
    "it is reasonable to suspect that @xmath312^d ) } \\leq ch^\\frac{1}{d}$ ] . if this is indeed the case , then in light of we have @xmath313^d ) } \\leq c\\left(k^{-\\frac{1}{2d}}h^{-1 } + h^\\frac{1}{d}\\right),\\ ] ] with high probability .",
    "the right side of the inequality is composed of two competing additive terms . the first term @xmath314 captures the effect of random errors ( variance ) due to an insufficient number @xmath192 of samples .",
    "the second term @xmath315 captures the effect of non - random errors ( bias ) due to insufficient resolution @xmath127 of the proposed numerical scheme ( s ) .",
    "this decomposition into random and non - random errors is analogous to the mean integrated squared error decomposition in the theory of non - parametric regression and image reconstruction  @xcite .",
    "similarly to  @xcite we can use the bound in to obtain rules of thumb on how to choose @xmath192 and @xmath127 .",
    "for example , we may first choose some value for @xmath192 , and then choose @xmath127 so as to equate the two competing terms in .",
    "this yields @xmath316 and becomes @xmath317^d ) } \\leq ck^{-\\frac{1}{2d(d+1 ) } } = ch^\\frac{1}{d},\\ ] ] with high probability .",
    "notice that steps 1 - 3 in algorithm [ alg : ndom ] , i.e. , computing @xmath302 , require @xmath318 operations . if we choose the equalizing value @xmath316 , then we find that computing @xmath302 has complexity @xmath319 .",
    "thus algorithm [ alg : ndom ] is sublinear in the following sense . given @xmath320 , we can choose @xmath192 large enough so that @xmath321^d ) } \\leq \\frac{{\\varepsilon}}{2c_d},\\ ] ] with high probability .",
    "the @xmath269 sorting accuracy of using @xmath302 in place of @xmath19 is then given by @xmath322 with high probability . by the stochastic convergence @xmath323 , and the rates presented in section [ sec : pde - rates ]",
    ", there exists @xmath324 such that for all @xmath325 we have @xmath326 with high probability .",
    "thus , for any @xmath320 there exists @xmath327 and @xmath127 such that @xmath302 is an @xmath328 approximation of @xmath19 for all @xmath325 , and @xmath302 can be computed in constant time with respect to @xmath1 .",
    "we emphasize that the sublinear nature of the algorithm lies in the computation of @xmath302 .",
    "ranking all samples , i.e. , evaluating @xmath302 at each of @xmath22 , and computing the @xmath269 error in of course requires @xmath329 operations . in practice , it is often the case that one need not rank all @xmath1 samples ( e.g. , in a streaming application  @xcite ) , and in such cases the entire algorithm is constant or sublinear in @xmath1 in the sense described above .",
    "we evaluated our proposed algorithm in dimension @xmath91 for a uniform density and a mixture of gaussians given by @xmath330 , where each @xmath331 is a multivariate gaussian density with covariance matrix @xmath332 and mean @xmath333 .",
    "we write the covariance matrix in the form @xmath334 , where @xmath335 denotes a rotation matrix , and @xmath336 , @xmath337 are the eigenvalues .",
    "the values for @xmath338 and @xmath339 are given in table [ tab : param ] , and the density is illustrated in figure [ fig : gauss - den ] .",
    ".parameter values for mixture of gaussians density [ cols=\"<,<,<,<,<\",options=\"header \" , ]     it is important to evaluate the accuracy of the approximate sorting obtained by algorithm [ alg : ndom ] . in practice ,",
    "the numerical ranks assigned to each point are largely irrelevant , provided the relative orderings between samples are correct . hence a natural accuracy measure for a given ranking",
    "is the fraction of pairs @xmath340 that are ordered correctly . recalling that the true pareto rank is given by @xmath341 , this can be expressed as @xmath342 where @xmath343 if @xmath344 and @xmath345 otherwise .",
    "it turns out that the accuracy scores for our algorithm are often very close to 1 . in order to make the plots easier to interpret visually ,",
    "we have chosen to plot @xmath346 instead of accuracy in _ all _ plots .",
    "unfortunately , the complexity of computing the accuracy score via is @xmath347 , which is intractable for even moderate values of @xmath1 .",
    "we note however that is , at least formally , a monte - carlo approximation of @xmath348 hence it is natural to use a truncated monte - carlo approximation to estimate .",
    "this is done by selecting @xmath1 pairs @xmath349 at random and computing @xmath350 the complexity of the monte - carlo approximation is @xmath329 . in all plots in the paper , we computed the monte - carlo approximation @xmath276 times and plotted means and error bars corresponding to a @xmath351 confidence interval . in all of the figures ,",
    "the confidence intervals are sufficiently small so that they are contained within the data point itself .",
    "we can see in figure [ fig : acc ] that we can achieve excellent accuracy while maintaining a fixed grid and subsample size as a function of @xmath1 .",
    "we also see that , as expected , the accuracy increases when one uses more grid points for solving the pde and/or more subsamples for estimating the density .",
    "we also see that the algorithm works better on uniformly distributed samples than on the mixture of gaussians .",
    "indeed , it is quite natural to expect the density estimation and numerical scheme to be less accurate when @xmath44 changes rapidly .    we compared the performance of our algorithm against the fast two dimensional non - dominated sorting algorithm presented in  @xcite , which takes @xmath352 operations to sort @xmath1 points .",
    "the code for both algorithms was written in c++ and was compiled on the same architecture with the same compiler optimization flags .",
    "figure [ fig : cputime ] shows a comparison of the cpu time used by each algorithm . for our fast approximate sorting , we show the cpu time required to solve the pde ( steps 1 - 3 in algorithm [ alg : ndom ] ) separately from the cpu time required to execute all of algorithm [ alg : ndom ] , since the former is sublinear in @xmath1 .",
    "it is also interesting to consider the relationship between the grid size and the number of subsamples @xmath192 . in figure",
    "[ fig : grid ] , we show accuracy versus grid size for @xmath353 and @xmath354 subsamples for non - dominated sorting of @xmath355 points . notice that for @xmath353 subsamples , it is not beneficial to use a finer grid than approximately @xmath356 .",
    "this is quite natural in light of the error estimate on algorithm [ alg : ndom ]  .",
    "there are certainly other ways one may think of to perform fast approximate sorting without invoking the pde ( p ) .",
    "one natural idea would be to perform non - dominated sorting on a random subset of @xmath22 , and then rank all @xmath1 points via some form of interpolation .",
    "we will call such an algorithm _ subset ranking _ ( in contrast to the pde - based ranking we have proposed ) .",
    "although such an approach is quite intuitive , it is important to note that there is , at present , no theoretical justification for such an approach .",
    "nonetheless , it is important to compare the performance of our algorithm against such an algorithm .",
    "let us describe how one might implement a subset ranking algorithm .",
    "as described above , the first step is to select a random subset of size @xmath192 from @xmath22 .",
    "let us call the subset @xmath296 .",
    "we then apply non - dominated sorting to @xmath296 , which generates pareto rankings @xmath357 for each @xmath358 .",
    "the final step is to rank @xmath22 via interpolation .",
    "there are many ways one might approach this . in similar spirit to our pde - based ranking ( algorithm 1 ) , we use grid interpolation , using the same grid size as used to solve the pde .",
    "we compute a ranking at each grid point by averaging the ranks of all samples from @xmath296 that fall inside the corresponding grid cell .",
    "the ranking of an arbitrary sample @xmath359 is then computed by linear interpolation using the ranks of neighboring grid points . in this way ,",
    "the rank of @xmath359 is an average of the ranks of nearby samples from @xmath296 , and there is a grid size parameter which allows a meaningful comparison with pde - based ranking ( algorithm 1 ) .",
    "figure [ fig : subsample ] shows the accuracy scores for pde - based ranking ( algorithm 1 ) and subset ranking of @xmath360 samples drawn from the uniform and mixture of gaussians distributions .",
    "a grid size of @xmath361 was used for both algorithms , and we varied the number of subsamples from @xmath362 to @xmath363 . notice a consistent accuracy improvement when using pde - based ranking versus subset ranking , when the number of subsamples is significantly less than @xmath1 .",
    "it is somewhat surprising to note that subset ranking has much better than expected performance .",
    "as mentioned previously , to our knowledge there is no theoretical justification for such a performance when @xmath192 is small .",
    "we now demonstrate algorithm [ alg : ndom ] on a large scale real data application of anomaly detection  @xcite .",
    "the data consists of thousands of pedestrian trajectories , captured from an overhead camera , and the goal is to differentiate nominal from anomalous pedestrian behavior in an unsupervised setting .",
    "the data is part of the edinburgh informatics forum pedestrian database and was captured in the main building of the school of informatics at the university of edinburgh  @xcite .",
    "figure [ fig : traj ] shows 100 of the over 100,000 trajectories captured from the overhead camera .",
    "the approach to anomaly detection employed in  @xcite utilizes multiple criteria to measure the dissimilarity between trajectories , and combines the information using a pareto - front method , and in particular , non - dominated sorting .",
    "the database consists of a collection of trajectories @xmath364 , where @xmath365 , and the criteria used in  @xcite are a walking speed dissimilarity , and a trajectory shape dissimilarity . given two trajectories",
    "@xmath366 \\to [ 0,1]^2 $ ] , the walking speed dissimilarity @xmath367 is the @xmath368 distance between velocity histograms of each trajectory , and the trajectory shape dissimilarity is the @xmath368 distance between the trajectories themselves , i.e. , @xmath369 .",
    "there is then a pareto point @xmath370 for every pair of trajectories @xmath371 , yielding @xmath372 pareto points .",
    "figure [ fig : points ] shows an example of 50000 pareto points and figure [ fig : fronts ] shows the respective pareto fronts . in  @xcite , only 1666 trajectories from one day were used , due to the computational complexity of computing the dissimilarities and non - dominated sorting .",
    "the anomaly detection algorithm from  @xcite performs non - dominated sorting on the pareto points @xmath373 , and uses this sorting to define an anomaly score for every trajectory @xmath374 .",
    "let @xmath375 and let @xmath376 denote the longest chain function corresponding to this non - dominated sorting .",
    "the anomaly score for a particular trajectory @xmath374 is defined as @xmath377 and trajectories with an anomaly score higher than a predefined threshold @xmath378 are deemed anomalous .    using algorithm [ alg : ndom ] , we can approximate @xmath19 using only a small fraction of the pareto points @xmath379 , thus alleviating the computational burden of computing all pairwise dissimilarities .",
    "figure [ fig : acc - real ] shows the accuracy scores for algorithm [ alg : ndom ] and subset ranking versus the number of subsamples @xmath192 used in each algorithm . due to the memory requirements for non - dominated sorting , we can not sort datasets significantly larger than than @xmath380 points .",
    "although there is no such limitation on algorithm 1 , it is important to have a ground truth sorting to compare against . therefore we have used only @xmath381 out of @xmath382 trajectories , yielding approximately @xmath380 pareto points . for both algorithms ,",
    "a @xmath383 grid was used for solving the pde and interpolation . notice the accuracy scores are similar to those obtained for the test data in figure [ fig : acc ] .",
    "this is an intriguing observation in light of the fact that @xmath384 are _ not _ _ i.i.d .",
    "_ , since they are elements of a euclidean dissimilarity matrix .",
    "we have provided theory that demonstrates that , when @xmath22 are _ i.i.d .",
    "_  in @xmath385 with a nicely behaved density function @xmath44 , the numerical scheme ( s ) for ( p ) can be utilized to perform fast approximate non - dominated sorting with a high degree of accuracy .",
    "we have also shown that in a real world example with non-_i.i.d .",
    "_  data , the scheme ( s ) still obtains excellent sorting accuracy .",
    "we expect the same algorithm to be useful in dimensions @xmath257 and @xmath386 as well , but of course the complexity of solving ( p ) on a grid increases exponentially fast in @xmath11 . in higher dimensions , one could explore other numerical techniques for solving ( p ) which do not utilize a fixed grid  @xcite . at present , there is also no good algorithm for non - dominated sorting in high dimensions .",
    "the fastest known algorithm is @xmath387  @xcite , which becomes intractable when @xmath1 and @xmath11 are large .",
    "this algorithm has the potential to be particularly useful in the context of big data streaming problems  @xcite , where it would be important to be able to construct an approximation of the pareto depth function @xmath19 without visiting all the datapoints @xmath22 , as they may be arriving in a data stream and it may be impossible to keep a history of all samples .",
    "in such a setting , one could slightly modify algorithm [ alg : ndom ] so that upon receiving a new sample , the estimate @xmath303 is updated , and every so often the scheme ( s ) is applied to recompute the estimate of @xmath302 .",
    "there are certainly many situations in practice where the samples @xmath22 are not _ i.i.d .",
    "_ , or the density @xmath44 is not nicely behaved . in these cases , there is no reason to expect our algorithm to have much success , and hence we make no claim of universal applicability .",
    "however , there are many cases of practical interest where these assumptions are valid , and hence this algorithm can be used to perform fast non - dominated sorting in these cases . furthermore , as we have demonstrated in section [ sec : real ] , there are situations in practice where the _ i.i.d . _  assumption is violated , yet our proposed algorithm maintains excellent accuracy and performance .",
    "we proposed a simple _ subset ranking _ algorithm based on sorting a small subset of size @xmath192 and then performing interpolation to rank all @xmath1 samples .",
    "although there is currently no theoretical basis for such an algorithm , we showed that subset ranking achieves surprisingly high accuracy scores and is only narrowly outperformed by our proposed pde - based ranking .",
    "the simplicity of subset ranking makes it particularly appealing , but more research is needed to prove that it will always achieve such high accuracy scores for moderate values of @xmath192 .",
    "we should note that there are many obvious ways to improve our algorithm .",
    "histogram approximation to probability densities is quite literally the most basic density estimation algorithm , and one would expect to obtain better results with more sophisticated estimators .",
    "it would also be natural to perform some sort of histogram equalization to @xmath22 prior to applying our algorithm in order to spread the samples out more uniformly and smooth out the effective density @xmath44 .",
    "provided such a transformation preserves the partial order @xmath2 it would not affect the non - dominated sorting of @xmath22 . in the case that @xmath44 is separable ( a product density ) , one can perform histogram equalization on each coordinate independently to obtain uniformly distributed samples .",
    "we leave these and other potential improvements to future work ; our purpose in this paper has been to demonstrate that one can obtain excellent results with a very basic algorithm .",
    "we thank ko - jen hsiao for providing code for manipulating the pedestrian trajectory database .",
    "we use the following minor extension of the arzel - ascoli theorem in section [ sec : convergence - proof ] .",
    "let @xmath99 be a compact metric space .",
    "we say that a sequence @xmath388 of real - valued functions on @xmath99 is _ approximately equicontinuous _ if for every @xmath320 there exists @xmath389 such that @xmath390 for every @xmath391 .",
    "let @xmath397 . since @xmath388 is approximately equicontinuous there exists @xmath398 such that for all @xmath1 we have @xmath399 forms an open cover of @xmath99 .",
    "since @xmath99 is compact , there exists a finite subcover @xmath400 for some integer @xmath401 . without loss of generality",
    "we may assume that @xmath402 .",
    "now let @xmath403 .",
    "by we have @xmath404 for some @xmath405 and any @xmath406 .",
    "hence we have @xmath407 it follows that @xmath394 is cauchy in @xmath126 , which completes the proof ."
  ],
  "abstract_text": [
    "<S> non - dominated sorting is a fundamental combinatorial problem in multiobjective optimization , and is equivalent to the longest chain problem in combinatorics and random growth models for crystals in materials science . in a previous work  @xcite </S>",
    "<S> , we showed that non - dominated sorting has a continuum limit that corresponds to solving a hamilton  </S>",
    "<S> jacobi equation . in this work we present and analyze a fast numerical scheme for this hamilton  </S>",
    "<S> jacobi equation , and show how it can be used to design a fast algorithm for approximate non - dominated sorting . </S>"
  ]
}