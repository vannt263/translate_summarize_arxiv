{
  "article_text": [
    "the modelling of neuronal activity has a long and rich history whose first successes date back to the 50 s and the seminal work of @xcite .",
    "a few years later , a simpler probabilistic model based on the passage times of a random walk was introduced by @xcite , known as the perfect integrate - and - fire ( pif ) model .",
    "it is quite amusing that the second author is also at the origin of the theory of fractals and long - range dependence , but never applied these concepts to neuroscience .",
    "the activity of a neuron is characterised by the electrical potential of its membrane , and more precisely by bursts whose amplitude and duration are very similar to one another .",
    "therefore , this is rather the sequence of times at which these spikes occur which is believed to carry the neuronal information . while temporal ( and spatial ) correlations between interspike intervals ( isis ) have been observed for a long time ( see @xcite and references therein ) , the presence of fractal behaviour ( @xcite , @xcite ) and _ long - memory _ phenomena in the spiking activity of neurons has been acknowledged for only two decades : see @xcite , @xcite , @xcite , @xcite , including artificially grown neuronal networks in @xcite , etc .",
    "( see the introduction of @xcite for a very comprehensive list of references ) .",
    "this long memory phenomenon is ubiquitous in nature , and takes the form of power - law correlations between interspike intervals rather than exponentially decaying correlations . in particular",
    ", long memory implies that the present neuronal activity is correlated with a very distant past .    until recently in the neuroscience literature , long memory , also called long - range dependence ( lrd ) ,",
    "has been quantified mostly by the fano factor . in @xcite , temporal and spatial lrd of _ in vivo _ human hippocampal neurons is detected relying on statistics like the detrended fluctuation analysis @xcite .",
    "we shall adopt a similar approach , which has also been used to detect lrd in ion channels @xcite .",
    "interestingly , long - range correlations may be due to the influence of presynaptic neurons , as well as intrinsic factors such as fluctuations in ion channel activity ( producing long - range dependence in neurotransmitter exocytosis , as described by @xcite ) .",
    "@xcite also mention several possible sources of lrd : neural refractoriness , bursting and adaptation .",
    "early attempts to replicate the lrd property of isis were based on point processes models and were proposed by @xcite , @xcite , and more recently @xcite . instead , we focus here on integrate - and - fire models , especially because they allow to preserve the aforementioned interpretation on the origin of lrd .",
    "besides , it is commonly accepted that they provide a good compromise between biologically complex and realistic models such as the hodgkin - huxley model , and more simple and amenable ones to perform statistical computations with .",
    "@xcite and @xcite noticed that an additional differential equation for the synaptic current , coupled with the membrane potential equation of a simple if model , introduces temporal correlations in the dynamics . assuming that the pre - synaptic excitation is modelled by a poisson noise , it is natural by diffusion approximation to write the synaptic equation as a stochastic differential equation driven by white noise .",
    "an interesting feature of this model is that it is simple enough to compute ( or approximate ) some isi statistics : for example , @xcite focused on the isi density , power spectral density and fano factor of the pif , @xcite on serial correlation coefficients of the pif , @xcite on the isi density , coefficient of variation , fano factor of the leaky integrate - and - fire ( lif ) model , etc .",
    "we also refer to @xcite for a mathematical and statistical treatment of markovian if models .",
    "the purpose of this paper is to explain that an if model with markovian noise , even enhanced with a synaptic variable , has exponentially decaying correlations which can not produce long - range dependent isis . to account for different correlation patterns observed on real data",
    ", we introduce an if model with fractional brownian noise .",
    "the fractional brownian motion ( fbm ) is a stochastic process whose increments ( the noise process ) are long - range dependent and stationary .",
    "it naturally appears in modelling as a limit of more simple processes : for instance , the fbm appears as the limit of high - dimensional orstein - uhlenbeck processes @xcite , see also @xcite for other constructions .",
    "however , it is non - markovian , which makes it a challenge to study and compute all the aforementioned statistics of spike trains .",
    "a similar point of view is developed in @xcite , where general gaussian processes are proxied by finite - dimensional markov processes and serve as input in an if model .",
    "we also discuss the approach of @xcite which is based on @xmath0 noise .",
    "in addition to modelling , our contribution is also methodological : we compare several measures of lrd and stationarity . indeed , testing stationarity is important in the attempt to measure lrd , as we shall see that non - stationary spike trains from markovian models can give the illusion of lrd .",
    "we refer to @xcite and @xcite on these questions , as well as the collection of review articles edited by @xcite on modelling long - range dependent phenomena in various fields ranging from economy , biology , neuroscience to internet traffic .",
    "the terminology `` long memory '' or `` long - range dependence '' appeared in the early work of mandelbrot and coauthors in the 60 s ( @xcite , @xcite , etc . ) , in an attempt to describe the phenomenon observed by h. hurst on the flows of the nile river .",
    "if @xmath1 is a random variable or a stochastic process , we say that @xmath2 is a realization ( or an observation ) of @xmath1 for the outcome @xmath3 in the probability space @xmath4 of all possible outcomes .",
    "a sequence of random variables @xmath5 has the _ long - range dependence ( lrd ) _ property if it satisfies : @xmath6 = + \\infty .\\ ] ] observe that the lrd property is obtained by averaging over all possible outcomes . in practical situations",
    "though , where we might have access to very few realizations ( or even a single one ) of the same phenomenon , at least two limitations appear : the length of the sequence is finite , and we do not know the law of the @xmath7 s ( in fact when dealing with spike trains , we only have one sample of the sequence ) . to detect long - range dependence ,",
    "we will use two estimators : the detrended fluctuation analysis ( dfa ) and the rescaled range statistics ( @xmath8 ) .",
    "they are among the two most efficient and popular methods to measure long - range dependence @xcite , and the latter is the only statistics for which it has been possible to prove convergence to the hurst parameter rigorously in some non - trivial cases @xcite .",
    "+ to prove convergence of the @xmath8 statistics , it is usually required that the sequence @xmath5 is @xmath9-stationary , in the sense that @xmath10 although there are examples of such convergence for non - stationary data ( @xcite and @xcite ) . verifying this requirement",
    "is often eluded in practical situations , although non - stationarity may have important consequences on the interpretation of statistical analysis of data .",
    "we will see that indeed in our numerical experiments , our model can produce non - stationary spike trains .",
    "nevertheless , the @xmath8 and dfa statistics seem to converge even without this condition .",
    "we emphasize that measuring ( non-)stationarity and long - range dependence is usually a tricky question .",
    "let us insist on the type of data we shall be dealing with : these are ( finite ) sequences @xmath11 ( we now use this notation both for the probabilistic model and a realization of it ) .",
    "we aim at obtaining the hurst parameter of the data from a single sequence ( i.e. not from averaging several realizations ) , to cope with biological constraints .      for a sequence @xmath12 of random variables ,",
    "let @xmath13 denote the sequence of the cumulated sums , and let the rescaled - range statistics be defined as : @xmath14 if for some @xmath15 , @xmath16 converges towards some positive random variable denoted by @xmath17 , we call @xmath18 the hurst parameter of the model . in the most simple example , where the @xmath7 s are independent and identically distributed ( _ iid _ ) with finite variance , the convergence occurs with @xmath19 .",
    "we consider that data have long - term memory when @xmath20 ( the reverse case @xmath21 is often called anti - persistence , but we will not encounter it here ) .",
    "let us recall that @xmath22 denotes the length of the sequence of data @xmath11 .",
    "a simple way to estimate @xmath18 is to fit the following linear model for various values of @xmath22 : @xmath23 however this is not the robust way to proceed in practice ( see @xcite ) .",
    "instead , we divide the data into @xmath24 blocks of length @xmath25 ( @xmath26 ) and compute the @xmath8 statistics on each block @xmath27 for @xmath28 .",
    "then we average over all blocks for fixed @xmath24 to obtain @xmath29 .",
    "finally we let @xmath25 take integer values between @xmath30 and @xmath22 and estimate the slope of the function @xmath31 .",
    "this slope gives the estimated hurst parameter of @xmath32 , frequently denoted by @xmath33 in the rest of this paper .",
    "let us conclude this paragraph with several insightful examples :    * if the @xmath7 s are iid and @xmath34 , then standard convergence results imply that @xmath35 converges to @xmath36 , where @xmath36 is an explicit functional of the brownian bridge .",
    "* if the @xmath7 s are mixing and stationary , then @xmath37 ( see section [ subsec : heuristics ] ) .",
    "* if the @xmath7 s are the increments of a fractional brownian motion with hurst parameter @xmath18 ( _ fbm _ , see section [ subsec : noise ] ) , then @xmath18 is also the rate of convergence of @xmath38 , i.e. @xmath39 converges .",
    "* there are examples of sequences of random variables with infinite variance such that @xmath35 converges ( @xcite ) .",
    "* there are examples of non - stationary random sequences for which the @xmath8 statistics converges at prescribed rate @xmath40 , see @xcite .",
    "this method was introduced by @xcite in genetics .",
    "we merely rephrase @xcite to present it .",
    "see also @xcite where it is called residuals of regression method and where it is compared to other methods .",
    "like in the @xmath8 analysis , the data are divided into @xmath24 blocks of length @xmath25 . for @xmath41 and @xmath42 , we denote the partial sum on block @xmath43 by @xmath44 . on each block , a linear regression is applied to determine coefficients @xmath45 such that @xmath46 is the least - square approximation of @xmath47 .",
    "then , the empirical standard deviation of the error is computed : @xmath48 finally , the mean of these standard deviations is @xmath49 .",
    "the analysis performed with @xmath50 can now be reproduced with @xmath51 ( ie the heuristics is that @xmath51 behaves asymptotically as a constant times @xmath52 ) . the slope computed from the log - log plot",
    "is again denoted by @xmath33 .",
    "another popular method we did not implement ( as it was unnecessary to our analysis , see @xcite for comparison with the two previous methods ) is the periodogram method .",
    "it consists in estimating the spectral density of @xmath53 and fitting it to a function of the form @xmath54 , where @xmath55 will be the estimated hurst parameter .",
    "+ we mention also the whittle estimator which gives excellent results in @xcite , but assuming prior analytical knowledge on the shape of the spectral density , which is irrelevant here as we have no such information .",
    "it is in general a difficult problem to decide whether data are issued from a stationary distribution or not .",
    "various tests exist in the literature on time series analysis , in particular based on unit root testing . like the measurement of long - range dependence , part of the difficulty here arises from the fact that we want to decide whether biological data are stationary relying on a single observation ( i.e. a single sequence of spikes ) ) . ] .    here",
    "we present several tests for stationarity : a simple windowed kolmogorov - smirnov ( ks ) test , the kwiatkowski - phillips - schmidt - shin ( kpss ) test , the priestley - subbha rao ( psr ) test and a wavelet - based test . in this section",
    ", we briefly describe these tests and their underlying assumptions on the data ( gaussian , square - integrable , etc . )",
    ". then we apply them on simple simulated data whose stationarity is known theoretically .",
    "the notion of stationarity itself must be clarified : the first two tests ( ks and kpss ) evaluate _ strong stationarity _",
    ", i.e. whether the law of the process is invariant by any time shift .",
    "the psr and wavelet - based test consider a weaker form of stationarity that we shall refer to as _",
    "a process @xmath1 is @xmath9-stationary if it satisfies ( [ eq : l2stat ] ) .    like for the hurst estimation of the previous section",
    ", all these tests are designed to be run on a single realization of the process ( said otherwise , no averaging is needed ) .    in section [ sec : results ] , we apply these tests on some data that are simulated from the models presented in section [ sec : models ] , according to the following methodology :    _ methodology for stationarity tests _ :",
    "for each sequence of data ( i.e. each sample ) following the same probabilistic law , we obtain from the considered stationarity test a p - value .",
    "the experiment is repeated @xmath56 times and a boxplot of the p - values is plotted . if a significant number of p - values are below @xmath57 , then we consider that the law we tested is not stationary . in any case",
    ", it is important to remember that the best test to use in a given situation depends strongly on the type of non - stationarity of the data ( see for instance table 2 in @xcite ) . since we do not know _ a priori _",
    "what type of non - stationarity may appear , we must apply several tests .    additional comments on non - stationary models in relation with the @xmath8 statistics can be found in @xcite .      based on the usual kolmogorov - smirnov ( _ ks _ ) test , we designed a windowed ks test . in this test , the isi series are split in windows of fixed time length .",
    "each block is tested against the others to see if they are described by the same distribution , using the non - parametric ks test .",
    "for each pair , the p - value is then represented in a two - dimensional table .",
    "the null hypothesis is that the two samples are drawn from the same distribution .",
    "hence , small p - values indicate that the data may be non - stationary . in this way",
    ", a visual map is obtained in which one can easily detect portions of the time series that do not follow the same distribution as the others .",
    "the kpss test @xcite complements the ( augmented ) dickey - fuller test in the context of time series analysis .",
    "_ assumptions on the data _ : the underlying hypotheses are quite strong as the data must be of the form @xmath58 where @xmath59 is a deterministic trend and @xmath60 is a stationary noise .",
    "the kpss test considers the null hypothesis : data are stationary ( hence small p - values indicate non - stationarity ) . + we mention this test because it is very frequently used in the literature , but we will not apply it to our data since it gave low p - values when tested on fractional noise ( which is stationary ) .    _",
    "r _ package : ` tseries ` ( function ` kpss.test ` , also available in python ) .",
    "let @xmath61 be a centred stochastic process with finite variance .",
    "it is known that if @xmath1 is @xmath9-stationary , then @xmath62 where @xmath63 is a random measure on @xmath64 and @xmath65 is the spectral density function .",
    "a natural generalization of the definition of @xmath66 is to let @xmath65 depend in time .",
    "the psr test @xcite evaluates the time dependence of @xmath67 , thus a test is proposed with the following null hypothesis : @xmath68 is constant in time .",
    "_ assumptions on the data _ : zero mean ( data can be centered in practice ) , finite variance , `` almost '' gaussian .",
    "more precisely , if @xmath69 denotes the spectral measure associated to @xmath70 ( i.e. @xmath71 for any borel set @xmath36 of @xmath64 ) , the evolutionary spectral density of @xmath1 is @xmath72 .",
    "an approximation of @xmath73 can be computed from the data , and is denoted by @xmath74 for discrete values @xmath75 and @xmath76 .    a two - factor analysis of variance is performed .",
    "first the interaction sum of square is tested : if the @xmath77-value is small , then the test can stop here , since the data are non - uniformly modulated , and thus are non - stationary ( see @xcite ) . otherwise , the data are uniformly modulated and one can proceed to test the stationarity . under each null hypothesis , the test statistics are simple chi - square distributions ( with different degrees of freedom ) .    _",
    "r _ package : ` fractal ` , function ` stationarity ` .",
    "this test @xcite is designed for a large class of processes called locally stationary wavelet processes ( lswp ) , which can be written : @xmath78 where @xmath79 is a wavelet basis , @xmath80 is an array of iid random variables with mean @xmath81 and variance @xmath30 , and @xmath82 are the ( deterministic ) wavelet coefficients of @xmath1",
    ". + first compute the discrete wavelet coefficients @xmath83 and the wavelet periodogram @xmath84 .",
    "the quantity of interest is then the @xmath85-spectrum defined by the family of coefficients @xmath86 , which form intuitively the evolutionary wavelet spectrum ( up to a linear transform ) of the signal . since we do not have access to the mathematical expectation directly from the data , an approximation of @xmath85 is proposed in @xcite .",
    "the process @xmath87 is stationary if and only if for all @xmath88 , @xmath89 is constant . we refer to @xcite , @xcite and references therein for intermediate results and methodology of the analysis of the @xmath89 .",
    "_ r _ package : ` bootwptos ` .    the psr test and this wavelet test",
    "give excellent results when applied to fractional noise , in the sense that they repeatedly give large p - values , as expected .",
    "we describe a large class of noisy integrate - and - fire models with adaptation .",
    "integrate - and - fire models have two regimes .",
    "the _ subthreshold regime _ is characterized by the stochastic differential system @xmath90 the process @xmath91 models the membrane potential and @xmath92 corresponds to an extrinsic synaptic current with adaptation .",
    "we call @xmath70 the adaptation variable / process , even though in several cases we remove the adaptation part .",
    "@xmath93 , @xmath94 , @xmath95 , @xmath96 , @xmath97 , @xmath98 and @xmath18 are parameters of the model .",
    "we detail the role of @xmath99 in the next paragraph .",
    "@xmath93 is the input current or voltage offset ; @xmath94 is the relaxation rate of the voltage ( the inverse of membrane time constant ) ; @xmath96 is the coupling factor between the adaptation variable @xmath100 and @xmath101 ; @xmath95 is the relaxation rate of the adaptation ( inverse of time constant ) ; @xmath97 and @xmath98 are the intensities of the noises @xmath102 and @xmath103  random noises called fractional brownian motions and described further in paragraph [ subsec : noise ] .",
    "@xmath99 is an offset factor for @xmath70 .",
    "we will either consider that @xmath99 is constant in time ( @xmath104 ) or that it varies during 1 ms only after a spike ( @xmath105 ) . in both cases , let us remark that the law of @xmath91 remains invariant by the modification of parameters @xmath106 .",
    "so , to reduce the number of parameters to estimate , we assume that @xmath107 . in the second case ( adaptation ) , we thus have @xmath108 , where @xmath109 is positive during 1 ms after a spike and @xmath81 otherwise .",
    "the _ firing regime _ is activated at the times @xmath110 when the membrane potential hits a fixed ( deterministic ) threshold @xmath111 .",
    "we call such a time @xmath110 a firing time . just after @xmath110",
    ", the membrane potential is _ reset _ to a fixed value @xmath112 , the rest potential . at the same time",
    ", we recall that @xmath99 can be incremented due to adaptation .",
    "this puts a natural limit to @xmath70 , mimicking the behavior of a finite population of ion channels @xcite . the sequence of firing times is formally defined for @xmath113 as @xmath114 and @xmath115 .",
    "the sequence of interspike intervals is @xmath116 , consistently with the notations of section  [ sec : stats ] .    from a mathematical point of view",
    ", the membrane potential is a cdlg process , like the adaptation process @xmath70 ( which is even continuous ) , meaning essentially that these processes are right - continuous in time .",
    "this is the most commonly used framework to enable the definition of solutions @xmath117 to equation ( [ eq : generallif ] ) .",
    "[ rem : multidimou ] more hidden states like @xmath70 can be added in ( [ eq : generallif ] ) to approximate gaussian processes which have long - range correlations ( see @xcite where this idea is fully developed ) .      in equation ( [ eq : generallif ] ) , the noises @xmath118 and @xmath119 are fractional brownian motions ( fbm ) of parameter @xmath15 . by definition ,",
    "they are gaussian centered processes with covariance function @xmath120 = \\frac{1}{2 } \\left(|t|^{2h}+|s|^{2h}-|t - s|^{2h}\\right).\\ ] ] the case @xmath37 corresponds to the standard brownian motion ( integral of white noise ) .",
    "this stochastic process has already been applied in various fields of physics and more recently , biology : in the context of biological dynamics ( cell movement in crowded environment , so - called anomalous diffusions ) , see for instance @xcite , @xcite and @xcite . more generally , fractional",
    "brownian motion provides a good , mathematically tractable , model of so - called @xmath0 noise , see e.g. @xcite .",
    "@xmath0 noise has been successfully applied to describe many phenomena , from heartbeat @xcite to internet traffic @xcite , including neuronal fractal dynamics @xcite .",
    "contrary to standard brownian motion , the fbm with @xmath121 is not markovian , which makes the computation of even basic statistics of isis a very difficult problem .",
    "however when @xmath20 , the increments of the fbm ( i.e. the fractional noise ) have positive correlations decaying very slowly , according to a power law : @xmath122 & = \\frac{1}{2 } \\left((n+1)^{2h } + ( n-1)^{2h } - 2n^{2h}\\right ) \\\\ & \\sim 2h(2h-1 ) n^{2h-2 } .\\end{aligned}\\ ] ] this is the long - range dependence property we shall include in our models . the case @xmath21 also yields power - law correlations , but negative , which is not useful here .",
    "+ very little is known on the first - passage time ( equivalent here to spiking time ) of models such as ( [ eq : generallif ] ) driven by fractional brownian motion : for the passage - time of fbm itself , see @xcite for simulations and formal estimation of the density when @xmath18 is close to @xmath123 and @xcite for inequalities on its laplace transform , and on the general model see @xcite for inequalities on laplace transforms .",
    "+ besides , there is no simple and efficient algorithm to simulate fractional brownian motion . for our simulations , we chose the most efficient _ exact _ algorithm . ] , namely the davis - harte algorithm ( explained for example in @xcite ) .",
    "we used t. dieker @xcite s ` c ` code for this algorithm .",
    "when @xmath124 , ( [ eq : generallif ] ) is a noisy leaky integrate - and - fire ( lif ) model .",
    "the particular case @xmath125 corresponds to the noisy perfect integrate - and - fire ( pif ) model .",
    "the membrane potential is solution of a linear stochastic differential equation . in the white noise setting @xmath37 , the interspike intervals are independent and identically distributed , so in particular such sequences are stationary .    1 .",
    "compared with multidimensional markov models ( which produce short - term memory ) , this model is also more compact .",
    "this can be interesting when one needs to estimate the parameters from real data ( see @xcite ) .",
    "we have also chosen to consider a model without any refractory period .",
    "the results seem to be interesting even in this simplified case .      despite the numerous articles emphasizing the presence of fractal and/or long - range dependence of the spiking activity of some neurons ( see introduction ) , we merely identified two streams of papers proposing a model reflecting these characteristics .",
    "+ in @xcite ( see references therein from related previous works from the 90 s , including in particular @xcite and coworkers ) , an integrate - and - fire model is used in conjunction with various point processes modelling a random input into the neuron .",
    "if the point process is a renewal process , then it may produce long - range dependence only if it has infinite variance ( ( * ? ? ?",
    "* theorem 2 ) ) .",
    "this condition being biologically unrealistic , a more sophisticated point process , the fractional - gaussian - noise - driven poisson process ( fgndp ) , is used in @xcite .",
    "the fgndp is a doubly stochastic poisson process , whose ( stochastic ) rate function is a nonlinear function of a fractional gaussian noise . when injected in an if model , this model is successful in producing spike trains with long - range dependence ( as measured with the fano factor )",
    "the idea is to consider that each jump of the fgndp is due to a spike in a presynaptic neuron .",
    "however , the use of such process seems less mathematically tractable than our approach with a fractional noise .",
    "in fact , the fbm is itself the scaling limit of discrete processes @xcite , is statistically self - similar and with stationary increments , which makes it a natural candidate as input noise .",
    "the second approach to model lrd is an integrate - and - fire model with 1/f noise proposed by @xcite .",
    "the link between fractional brownian motion and 1/f noise is explained in @xcite .",
    "we compare this approach with ours further in section [ sec : discussion ] .      in classical markovian models ( e.g. pif model with multidimensional ornstein - uhlenbeck noise , @xmath19 )",
    ", the correlation between interspike @xmath126 and @xmath127 decays exponentially in @xmath25 , even though having high - dimensional ou process is intended to produce large time constants .",
    "we assert that the isis of this model are mixing , i.e. that @xmath128 , for some @xmath129 such that @xmath130 .",
    "we also believe , based on mathematical arguments and some numerical evidence ( see the next section ) , that such model produces isis which converge to a stationary regime .    from @xcite ,",
    "chapter 1.5 , it is known that any stationary and mixing sequence satisfies an invariance principle .",
    "this is enough to apply theorem 4 of @xcite , which gives the convergence of @xmath131 to a non - trivial random variable .",
    "therefore we conjecture the following result that we plan to prove in a separate work :    if @xmath19 , the sequence of interspike intervals generated by the pif / lif model ( [ eq : generallif ] ) has a stationary regime , and @xmath132 converges to a non - degenerate random variable ( i.e. @xmath133 ) .",
    "our second heuristics is about the approximation of the fractional brownian motion by a sequence of @xmath25-dimensional ornstein - uhlenbeck processes , as @xmath25 increases . in @xcite ,",
    "the general idea is that the covariance of a general gaussian process can be approximated by an ornstein - uhlenbeck with sufficiently many components . in @xcite",
    ", it is proved that the fbm is indeed an infinite - dimensional ornstein - uhlenbeck process .",
    "therefore , we can consider our model with fractional noise as a natural limit to the model proposed in @xcite .",
    "although this is not the only possible limit in their approach , the fbm is the most sensible choice to obtain long - range dependence .",
    "we simulated a series of spikes using a perfect integrate - and - fire ( pif ) model , i.e. with @xmath134 .",
    "the voltage dynamic is deterministic ( @xmath135 ) and the slow adaptation variable ( @xmath70 ) has an additive noise ( @xmath136 ) . in this case , @xmath137 , meaning the noise is standard white noise ( no correlation ) .    [",
    "[ surrogate - data . ] ] surrogate data .",
    "+ + + + + + + + + + + + + + +    for each simulated spike train , we produce @xmath138 sequences of spikes by shuffling randomly the interspike intervals of our initial simulated spike train ( a procedure called bootstrapping with replacement ) .",
    "this way we obtain @xmath138 new spike trains having the same interspike interval distribution , but no special correlation structure between spikes .",
    "the lrd analysis is applied to these new data and we plot @xmath33 as a function of @xmath22 for each of them .",
    "the mean is plotted ( see figure  [ fig - results1]d ) in solid line , the five most extreme values are removed and a shadow region with the 95 remaining plots is drawn . in general , it appears clearly that the shadow region is centred around @xmath139 , meaning no long correlations .",
    "if the plot of @xmath33 of the initial spike train enters this shadow region , then it is doubtful that the data have the lrd property .",
    "figure [ fig - results1]a shows the spikes and the intervals obtained in a 500 @xmath140-long realization of the model , which yielded 15,164 spikes for a firing rate of approximately @xmath141 spikes / sec ( and a mean isi of 33ms with standard deviation of @xmath142 ) .",
    "the rescaled range statistics and detrended fluctuation analyses were first applied to a shorter sequence of intervals , the first 100 @xmath140 ( 3,023 spikes ) of simulation .",
    "figure [ fig - results1]b shows that the common linear regression between @xmath143 and @xmath144 or @xmath145 yields a @xmath18 value near 0.75 in both cases , suggesting a long - range dependency of the isi sequence .",
    "however , this data was generated with a model that is of markovian nature .     and",
    "dfa analysis of pif model with noisy adaptation . * a * isi sequence analyzed .",
    "parameters are @xmath146 , @xmath134 , @xmath147 , @xmath135 , @xmath148 , @xmath136 . the vertical segmented line shows the limit of the data analyzed in ( b ) . * b * rescaled range ( left ) and detrended fluctuation analysis ( right ) for the isis in the first 100 seconds of simulation ( 3023 spikes ) . h value is the slope of the best fit of @xmath143 vs. @xmath144 or @xmath149 points to a straight line ( segmented line over the data points ) . * c * @xmath8 and dfa analysis of the full isi sequence ( 15164 spikes ) .",
    "the @xmath18 values indicated in the top left corner , and the segmented lines correspond to the fit of the full set of points to the data as in ( b ) .",
    "the shorter , continuous lines depict the best fit of a subset of the points . *",
    "d * slope values calculated at different @xmath25 values ( with a moving window of 7 points ) , for the @xmath8 ( left ) and dfa analysis ( right ) .",
    "the continuous line shows the mean slope calculated with 100 surrogate series and the shadow region shows the empirical standard deviation of the surrogate data slopes . ]",
    "visual inspection of the plots reveals that the slope calculated is far from being the asymptotic slope , and that the curve ` bends ' toward the right end .",
    "when we included the full sequence to the @xmath8 and dfa analyses ( figure  [ fig - results1]c ) , it is evident that the points are not following a linear relationship and the calculated slopes are lower . to characterize better the non - asymptotic nature of the slope",
    ", we repeated the fit in sliding windows of 15 points .",
    "three of such fits are shown as continuous lines in figure [ fig - results1]c ( note that in figure  [ fig - results1]c every other point has been omitted ) and figure  [ fig - results1]d depicts a plot of the slopes found as a function of the length of the sequence . from this figure , it is clear that for both @xmath8 and dfa the actual asymptotic behavior is a slope of 0.5 . as the sequence length @xmath25 increases , the slope approaches the 0.5 value and , moreover , gets into the standard deviation range calculated from surrogate data ( the same values with shuffled sequence ) .",
    "thus , only the analysis of a very large sequence of data probably discarding the shorter sequences in the analysis will reveal that what appears to be long - range dependence has only a limited time span and that the phenomena underlying it is ultimately markovian .",
    "nevertheless , even on reasonably large sequences , we see that the hurst estimator @xmath33 is decreasing with @xmath22 in the markovian model ( figures [ fig - results2 ] and [ fig - results3 ] ) , while it is relatively stable in the fractional case , as we shall see later ( figure [ fig - results4 ] ) .",
    "this apparent long - range dependence of the data is largely related to the stochastic nature of the adaptation .",
    "figure [ fig - results2]a shows that the apparent lrd is lost when the noise is present only in the voltage equation ( @xmath150 ) but not in the adaptation ( @xmath151 ) .",
    "when the noise is present in both equations , the apparent lrd is somewhat reduced for high values of @xmath97 ( figure [ fig - results2]b ) . also , figure [ fig - results2]b shows an interesting case where visually the straight line seems to be a good fit of the @xmath143 versus @xmath149 data ( and the associated @xmath152 coefficient seems also good ) . however , the bottom plot shows how the @xmath153 situation is only transitory for the shorter sequences and the asymptotic value actually falls within the standard deviation for the shuffled data . on the other hand",
    ", the magnitude of the noise seems not to affect much this behavior ( figure [ fig - results2]c and d ) .    .",
    "panels are as described in figure [ fig - results1]c and [ fig - results1]d ( right ) . ]",
    "the lrd is also linked to the rate constant for slow adaptation , @xmath95 .",
    "figure [ fig - results3 ] shows that a large rate ( or a small time constant @xmath154 ) is associated with the loss of apparent lrd ( figure [ fig - results3]a ) , while a smaller value produces a lrd that is maintained for longer sequence lengths and also a higher @xmath18 value ( figure [ fig - results3]b ) .",
    "further parameter explorations revealed that in order to observe the apparent lrd , the time constant for slow adaptation has to be at least twice the mean interval between spikes ( not shown ) .    ) . *",
    "b. * effect of a longer time constant . * c. * long - range dependence analysis in the absence of adaptation , i.e. the @xmath70 variable is not affected by the occurrence of spikes . ]",
    "figure [ fig - results3]c explores the situation where the adaptation variable @xmath70 is no longer updated at each spike ( i.e. , @xmath155 for every @xmath156 ) . in this case , @xmath100 can be understood as a correlated noise ( in the form of an ornstein - uhlenbeck process ) added to the variable @xmath157 . although the adaptation effect is lost and the firing rate is increased ( not shown ) , the apparent lrd is still present , showing that it is the correlated nature of the stochastic variable that causes this effect .",
    "this is very much in line with what has been described for other statistics of firing in the presence of different forms of correlated noise @xcite .",
    "we base our stationarity analysis of the spike trains on the ks , psr and wavelet tests . for the psr and wavelet tests ,",
    "we apply the methodology described in section [ sec : stats ] : hence in figure  [ fig - results4](a ) , the left bar is a boxplot of 50 p - values from the psr test computed from 50 independent spike trains generated by the same model ; the right bar does the same with the wavelet test .",
    "same for figures  [ fig - results4](b ) , ( c ) and ( d ) with different models .    in the pif model with stochastic adaptation , a lower adaptation rate @xmath95 ( longer adaptation time constant ) is associated with a loss of stationarity , i.e. the data windows are no longer described by the same distribution , see figures [ fig : psrwvlt ] and [ fig : resultsks]a for the psr , wavelet and ks tests ( see description of these tests in section [ sec : stats ] ) .",
    "it seems that a lower adaptation rate @xmath95 ( corresponding to a larger relaxation time @xmath158 ) produces a sequence of isis farther from stationarity , and that @xmath158 not only characterizes the speed of convergence of @xmath100 to its stationary regime , but also the speed of convergence of the law of the isis to theirs .    on the other hand , adding only white noise to the dynamics of @xmath157 produces stationary data .",
    "= 0.005 analyses the same data as in figure [ fig - results1 ] , while panels for @xmath95=0.05 and @xmath95=0.0005 use the same data as in figure [ fig - results3]a and b , respectively .",
    "the panel with @xmath97=0.0001 , @xmath98=0 corresponds to figure [ fig - results2]a . in b , three values of @xmath18",
    "are shown . at the top of each panel , a sample sequence of 60 s long ( around 1800 spikes )",
    "the isi sequence analyzed in the windowed ks test is of 300 s ( 9000 spikes ) , with 20 windows of 15 s. blue colors ( p - value < 0.05 ) indicate that the series compared are likely to be described by different distributions . ]",
    "we decided to compare the behavior of the markovian pif model with adaptation to a non - markovian pif model without adaptation .",
    "therefore we set @xmath124 , @xmath134 and explored values of @xmath18 above @xmath139 . @xmath97 and",
    "@xmath159 were adjusted in order to obtain similar mean and variance of the isis obtained in the previous simulations .",
    "figure [ fig - results4 ] shows that adding a fractional gaussian noise indeed produces a long - term dependence in the series of isis , as evidenced by both rescaled range statistics and detrended fluctuation analysis .",
    "in contrast to the pif model with stochastic adaptation , however , the high slope in the @xmath143 versus @xmath144 or @xmath149 plots is maintained and does not decay as @xmath25 increases .",
    "in other words , the @xmath33 value obtained by these analyses appears to be rapidly close to its true asymptotic value .",
    "this behavior is observed at different values of @xmath18 ( figure [ fig - results5 ] ) .",
    "+ furthermore , we see in figure [ fig : boxplot_hurst ] that estimated hurst parameter @xmath33 is very close to the input value @xmath18 .",
    "hence we can safely assert that @xmath33 converges to @xmath18 .    ) and parameters @xmath160 , @xmath134 , @xmath124 , @xmath161 , @xmath162 .",
    "the @xmath70 variable was not taken into account . *",
    "b * , @xmath8 and dfa analyses for the full sequence of 14,500 spikes .",
    "the three continuous lines that depict local slopes are overlapping a segmented line that represents the best fit for all the data points . as in figure",
    "[ fig - results1]c , every other point has been omitted .",
    "* c * , plot of best - fit slopes in moving windows of 15 points .",
    "the continuous line and the shadowed region are the mean and standard deviation , respectively , of the fits with surrogate data . ]    . * a. * @xmath163 , @xmath164 , @xmath165 * b. * @xmath166 , @xmath160 , @xmath167 .",
    "parameters were calibrated in order to obtain a similar mean variance of the intervals as in figure [ fig - results1 ] . ]     of the fpif model .",
    "for each @xmath168 , we simulated @xmath56 independent sequences of isis from a fpif with parameter @xmath18 ( and with @xmath159 and @xmath97 chosen so that the isis @xmath7 have the following moments @xmath169\\approx 32.9 \\text{ms}$ ] and @xmath170\\approx 20 $ ] ) .",
    "the hurst parameter was estimated by the @xmath8 ( blue plot ) and dfa ( red plot ) methods for each simulation , and for each underlying @xmath18 parameter , the result has been aggregated in a boxplot .",
    "we see that the estimated hurst parameter of the isis is very close to the value of the hurst parameter of the fbm used in the simulations .",
    "the dfa method seems to perform better . ]",
    "results concerning stationarity of this model are shown in figure [ fig : resultsks]b for the ks test , and in figure [ fig : boxplotstat ]  for the psr and wavelet tests .",
    "+ we conclude unquestionably that the isis are stationary when @xmath137 ( figure [ fig : boxplotstat](a ) ) .",
    "this agrees with the theoretical result in this simple framework .",
    "the conclusion from the case @xmath162 - figure  [ fig : boxplotstat](b)- is less straightforward , since the psr test clearly rejects stationarity , unlike the wavelet - based test .",
    "however , we doubt that there will be a phase transition in the stationarity property for some @xmath171 ( meaning that the isis would be stationary for @xmath172 and not stationary for @xmath173 ) . hence the stationarity property must be the same for any @xmath174 . unlike the markovian model , we have no mathematical reason to believe that the isis generated from the fractional pif model may reach a stationary regime . since the plots in figure  [ fig : boxplotstat](c ) encourage us to reject stationarity",
    ", we conclude that for any @xmath153 , the fpif generates non - stationary isis .",
    "considering remark [ rem : multidimou ] and the heuristics from section [ subsec : heuristics ] , one is tempted to consider the following model : @xmath175 this model may allow for more complex behaviours , e.g. observations from simulations on the previous model display several firing regimes :    * if @xmath176 and for @xmath177 , the estimated hurst parameter of the isis , @xmath33 , remains close to the hurst parameter @xmath18 of the model . * if @xmath178 and @xmath179 , the isis are almost independent and @xmath33 is close to @xmath123 . *",
    "if @xmath180 and @xmath181 , then similarly to the biological data , @xmath33 increases with @xmath22 towards the value @xmath18 ( see figure [ fig : hincreases ] ) .",
    "the isi histogram seems to deviate from the inverse gaussian distribution ( see bottom left plot in figure [ fig : hincreases ] ) .",
    "furthermore , it would be interesting to see if this model shares the multiple time scale adaptation observed by @xcite and modelled by fractional differentiation or cascade processes @xcite .    ) with parameters : @xmath182 and @xmath183 .",
    "the hurst estimator @xmath33 seems to start from lower value and increase with @xmath22 . ]",
    "the leaky integrate - and - fire model corresponds to @xmath184 in equation ( [ eq : generallif ] ) , instead of @xmath134 for the pif .",
    "we draw the same conclusions on the lrd property for the lif ( not shown ) .",
    "see section [ subsec : summary ] below for a summary of the properties of the pif and lif models .",
    "the results of our numerical experiments ( see figures [ fig - results5 ] , [ fig : boxplot_hurst ] and [ fig : hincreases ] ) are the following :    1 .",
    "any sequence of isis generated by a fractional ( @xmath185 ) pif / lif with no adaptation variable ( @xmath124 ) , has a hurst parameter equal to the hurst parameter of the underlying fbm , i.e. @xmath186 as @xmath187 .",
    "2 .   any sequence of isis generated by a brownian ( @xmath19 ) pif / lif with adaptation ( @xmath188 ) , has a hurst parameter equal to @xmath123 , i.e. @xmath133 as @xmath187 .",
    "the case of pif / lif with a fractional stochastic adaptation variable is less straightforward , and @xmath33 depends strongly on the parameters of the model .",
    "see the discussion below equation ( [ eq : flif_adaptation ] ) .    in this paragraph",
    ", let us denote by @xmath189 ( resp .",
    "@xmath190 ) the hurst parameter computed from the @xmath8 statistics ( resp .",
    "detrended fluctuation analysis ) .",
    "we see from figure [ fig : boxplot_hurst ] that the dfa method gives better result than the @xmath8 on this set of data .",
    "indeed , the case @xmath137 ( leftmost column ) corresponds to the simplest case where the isis are independent and identically distributed , with finite moments .",
    "thus we know that @xmath189 must converge to @xmath123 .",
    "hence it appears clearly that @xmath189 is strongly biased , unlike @xmath190 .",
    "a correction is proposed in @xcite but it is only consistent with @xmath137 .",
    "the stationarity in the markovian case was addressed in section [ subsec : heuristics ] from a theoretical point of view .",
    "the numerical results seem to confirm our analysis ( figures [ fig : psrwvlt ] and [ fig : resultsks]a ) : the sequence is likely to have a stationary regime , but it may be far from it , the rate of convergence to this regime being somehow related to @xmath191 .",
    "this has practical consequences , since non - stationary time series can not be analysed , in general , with the same methods as stationary time series .",
    "we concluded in section [ subsec : resultsfpif ] , based on observations from figures [ fig : resultsks]b and [ fig : boxplotstat ] , that the isis from the fractional pif model with @xmath153 are non - stationary .",
    "in this paper , we modelled the _ long - range _ temporal correlations sometimes called memory effect observed in the spike trains of certain neurons ( see in particular @xcite and our introduction for more details ) .",
    "our model is of the integrate - and - fire type , with a stochastic input called fractional brownian motion . to the best of our knowledge ,",
    "this is the first time this stochastic process is used in an if model , and we showed that it is very well suited to produce long - range dependent spike trains . besides , this type of stationary gaussian noise emerges naturally as a scaling limit of discrete noises ( see sections [ subsec : other_models ] and [ subsec : heuristics ] ) which can originate either from the fractal behaviour of ion channels or from the cumulated inputs of the neuronal network .    to measure the long - range dependence of spike trains",
    ", we followed a well - established procedure ( @xcite ) , which neuroscience has already benefited from ( dfa analysis of isis in @xcite , @xmath8 analysis for ion channels in @xcite ) . in the literature to date , we have identified several types of if models aimed at producing correlated spike trains : those with colored noise input , i.e. ornstein - uhlenbeck noise ( @xcite ) , non - renewal point processes input ( @xcite ) , those with @xmath0 noise input @xcite and very recently pif with high - dimensional ornstein - uhlenbeck noise @xcite .",
    "the first conclusion of our study is that the isis generated from _",
    "integrate - and - fire models such as the one proposed in @xcite do not have long memory _ stricto sensu _ , and produce instead isis whose correlations are exponentially decaying . however , as seen in all figures [ fig - results1 ] to [ fig - results3 ] , these markovian integrate - and - fire models ( whether perfect of leaky ) can replicate a memory effect for sequences of spikes with a given length ( see figure [ fig - results1 ] ) , if the adaptation variable is noisy and its time constant @xmath158 is chosen adequately .",
    "nonetheless , plots of the estimated hurst parameter as a function of the sequence length are always decreasing .",
    "this contrasts with fractional integrate - and - fire models , for which this function appears constant at a value @xmath55 ( see figure [ fig - results4 ] ) .",
    "this provides a simple criterion to discriminate between markovian and fractional if models .",
    "this becomes more and more obvious as the length of the spike train increases .",
    "moreover , we see in figures [ fig - results5 ] and [ fig : boxplot_hurst ] that @xmath55 , the estimated hurst index of the spike trains , is exactly the hurst parameter @xmath18 of the fractional brownian motion injected in the model .    on a more theoretical side , we presented and compared the effectiveness of several stationarity tests suited to time series analysis .",
    "unlike the classical lrd treatment used here , the methodology for testing stationarity we propose seems relatively new to the neuroscience literature .",
    "stationarity is often believed to hold for isis @xcite , yet it produced surprising results since we observed that sequences of isis can be non - stationary ( figures [ fig : psrwvlt ] and [ fig : resultsks ] ) , even when generated from a simple lif model with ornstein - uhlenbeck noise .",
    "however , we believe that a stationary regime exists for such models , and that we may have observed transitory regime with very large time constants . the case with presence of an adaptation mechanism is less clear .",
    "meanwhile , the isis obtained from the fractional lif are not stationary . + this stationarity property has important consequences : if a sequence of isis has a stationary regime and its correlations decay exponentially fast , then the estimated hurst of the @xmath8 statistic must be @xmath123 .",
    "altogether the present discussion on stationarity leaves several questions unanswered and should be the purpose of future work .",
    "our model is strongly related to the if model with 1/f noise of @xcite .",
    "the link between fractional brownian motion and 1/f noise is explained in @xcite .",
    "an advantage of using fbm is that it can be simulated exactly , which ensures that all frequencies are present in its spectrum and that lrd holds , while a simulated 1/f noise is an approximate 1/f noise with limited bandwidth .",
    "besides , a 1/f noise does not uniquely defines a random mathematical object , or @xmath192 for some @xmath193 , spectrum for all frequencies .",
    "] , unlike the fbm which is the only gaussian process with given self - similarity parameter @xmath18 and with stationary increments .",
    "nevertheless , the approach of @xcite is complementary to ours since this study focuses on the dispersion of spike trains in time windows @xmath194 $ ] for various times @xmath156 ( as measured by the fano factor ) .",
    "a very interesting and important problem that we may also be the content of future work is _ calibration_. consider the following situation : given an observed spike train with measured hurst parameter @xmath195 , we want to calibrate either the parameters @xmath196 and @xmath18 of a fractional pif ) but this would go beyond the content of the present discussion . ] or the parameters @xmath197 of a markovian ( @xmath19 ) pif with an adaptation variable . in the first case , it results from figure [ fig : boxplot_hurst ] that we must choose @xmath198 .",
    "we only have two more parameters to fix , and the mean of the isis is given by @xmath199 ( assuming implicitly that the threshold is @xmath30 ) .",
    "we can then try to compute @xmath97 from the variance of the isis and @xmath18 .",
    "on the other hand , we have seen from figure [ fig - results3 ] that the @xmath55 value can be replicated by adjusting @xmath94 : a larger @xmath94 yields smaller @xmath55 parameter , but also impacts the first two moments of the isis .",
    "hence it may be easier to fix first the hurst parameter of the noise , rather than having additional parameters just to replicate the correlations of the isis .",
    "then we can focus on additional properties that adaptation can bring to integrate - and - fire models .",
    "j.  bhattacharya , j.  edwards , a.n .",
    "mamelak , and e.  m. schuman .",
    "long - range temporal correlations in the spontaneous spiking of neurons in the hippocampal - amygdala complex of humans .",
    "_ neuroscience _ , 131:0 547555 , 2005 .",
    "campos de  oliveira , c.t.f .",
    "barbosa , l.h.a consoni , a.r.a rodrigues , w.a .",
    "varanda , and r.a . nogueira .",
    "long - term correlation in single calcium - activated potassium channel kinetics .",
    "_ physica a : statistical mechanics and its applications _ , 364:0 1322 , 2006 .",
    "chacron , k.  pakdaman , and a.  longtin .",
    "interspike interval correlations , memory , adaptation , and refractoriness in a leaky integrate - and - fire model with threshold fatigue .",
    "_ neural computation _ , 150 ( 2):0 253278 , 2003 .",
    "s.  b. lowen , tsuyoshi .",
    "ozaki , e.  kaplan , b.  e.a .",
    "saleh , and m.  c. teich .",
    "fractal features of dark , maintained , and driven neural discharges in the cat visual system .",
    "_ methods _ , 240 ( 4):0 377394 , 2001 .",
    "r.  metzler and j.  klafter . the restaurant at the end of the random walk : recent developments in the description of anomalous transport by fractional dynamics . _ journal of physics a : mathematical and general _ , 370 ( 31):0 r161 , 2004 .",
    "g.  nason . a test for second - order stationarity and approximate confidence intervals for localized autocovariances for locally stationary time series . _ journal of the royal statistical society : series b ( statistical methodology ) _ , 750 ( 5):0 879904 , 2013 .",
    "r.  segev , m.  benveniste , e.  hulata , n.  cohen , a.  palevski , e.  kapon , y.  shapira , and e.  ben - jacob . long term behavior of lithographically prepared _ in vitro _",
    "neuronal networks .",
    "_ physical review letters _ , 880 ( 11):0 118102 , 2002 .                m.  c. teich , c.  heneghan , s.  b. lowen , t.  ozaki , and e.  kaplan .",
    "fractal character of the neural spike train in the visual system of the cat .",
    "_ journal of the optical society of america a _ , 140 ( 3):0 529546 , 1997 ."
  ],
  "abstract_text": [
    "<S> we consider a new model of individual neuron of integrate - and - fire ( if ) type with fractional noise . </S>",
    "<S> the correlations of its spike trains are studied and proved to have long memory , unlike classical if models . to measure correctly long - range dependence , </S>",
    "<S> it is often necessary to know if the data are stationary . </S>",
    "<S> thus , a methodology to evaluate stationarity of the interspike intervals ( isis ) is presented and applied to various if models . </S>",
    "<S> it appears that the spike trains of our fractional model have the long - range dependence property , while those from classical markovian models do not . </S>",
    "<S> however they may seem to have it because of non - stationarities . </S>"
  ]
}