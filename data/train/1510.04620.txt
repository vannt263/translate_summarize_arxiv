{
  "article_text": [
    "the acoustic characteristics of a room have been shown to be important to predict the speech quality and intelligibility , which is relevant to speech enhancement  @xcite as well as for automatic speech recognition  ( asr )  @xcite .",
    "the reverberation time  @xmath0 and the direct - to - reverberation ratio  ( @xmath1 ) are two important acoustic parameters .",
    "traditionally , @xmath0 and @xmath1 can be obtained from a measured room impuls response  ( rir )  @xcite .",
    "however , it is not practical or not even possible to measure the corresponding rirs in most applications . consequently , the demand of blind @xmath0 and @xmath1 estimation directly from speech and audio signals is increasing .    a number of approaches for blind estimation have been proposed earlier : based on the spectral decay distribution of the reverberant signal , @xmath0 is determined in  @xcite by estimating the decay rate in each frequency band .",
    "a noise - robust version is presented in  @xcite . in",
    "@xcite a blind @xmath0 estimation is achieved by a statistical model of the sound decay characteristics of reverberant speech .",
    "inspired by this , @xcite uses a pre - selection mechanism to detect plausible decays and a subsequent application of a maximum - likelihood criterion to estimate @xmath0 with a low computational complexity .",
    "alternatively , motivated by the progress that has been achieved using artificial neural networks in machine learning tasks , @xcite  proposed a method to estimate @xmath0 blindly from reverberant speech using trained neural networks , for which short - term root - mean square values of speech signals were used as the network input .",
    "the approach in  @xcite was also extended to estimate various acoustic room parameters in  @xcite using the low frequency envelope spectrum .",
    "our work  @xcite proposed a multi - layer perceptron using spectro - temporal modulation features to estimate @xmath0 .",
    "a comparison of energies at high and low modulation frequencies , the so - called speech - to - reverberation modulation energy ratio  ( srmr ) , which is highly correlated to @xmath0 and @xmath1 , is evaluated in  @xcite .",
    "the approaches mentioned so far use a single audio channel for obtaining the estimate , however , the majority of blind off - the - shelf @xmath1 estimators rely on multi - channel data .",
    "an approach to estimate @xmath1 based on a binaural input signal from which the direct component is eliminated by an equalization - cancellation operation was proposed in  @xcite .",
    "another method using an octagonal microphone array has been presented in  @xcite , where a spatial coherence matrix for the mixture of a direct and diffuse sound field was employed to estimate @xmath1 using a least - squares criterion . in  @xcite ,",
    "an analytical expression was derived for the relationship between the @xmath1 and the binaural magnitude - squared coherence function .",
    "a null - steering beamformer is employed in  @xcite to estimate the @xmath1 with a two - element microphone array .",
    "motivated by the fact that the amount of perceived reverberation depends on both @xmath0 and @xmath1 , we propose a novel approach to simultaneously and blindly estimate these parameters . in our previous work",
    "@xcite , we found spectro - temporal modulation features obtained by a 2d gabor filterbank to be strongly and non - linearly correlated with reverberation parameters .",
    "we refer to these features as _ auditory _",
    "gabor features , since the filters used for extraction resemble the spectro - temporal receptive fields in the auditory cortex of mammals  @xcite , i.e. , it is likely that our auditory system is explicitly tuned to such patterns .",
    "the gabor features are used as input to an artificial neural network , i.e.  a multi - layer perceptron  ( mlp ) , which is trained for blind estimation of the parameters pair @xmath2 .",
    "the evaluation of performance focuses on the acoustic characterization of environments  ( ace ) challenge  @xcite evaluation test set in fullband mode with a single microphone .",
    "the remainder of this paper is organized as follows : section  [ sec : method ] introduces the blind @xmath2 estimator based on the 2d gabor features and an mlp classifier .",
    "the detailed experimental procedure is described in section  [ sec : expm ] according to the ace challenge regulations .",
    "the results and discussion are presented in section  [ sec : result ] for the proposed @xmath2 estimator with the ace evaluation test set , and section  [ sec : conclu ] concludes the paper .",
    "an overview of the estimation process is presented in figure  [ fig : mlp ] : in a first step , reverberant signals are converted to spectro - temporal gabor filterbank features  @xcite to capture information relevant for room parameters estimation .",
    "an mlp is trained to map the input pattern to pairs of parameters @xmath2 , where the label information is according to @xmath2 from the available rirs .",
    "since the mlp generates one estimate per time step , we obtain an _ utterance_-based estimate by simple temporal averaging and subsequent selection of the output neuron with the highest average activation ( _ winner - takes - all _ ) , as shown in figure  [ fig : mlp_label ] for instance .",
    "the noisy reverberant speech signal @xmath3 $ ] is constructed from clean ( anechoic ) speech @xmath4 $ ] convolved with measured rirs @xmath5 $ ] and an additive noise @xmath6 $ ] , denoted as @xmath3 = s[k ] \\ast h[k ] + n[k]$ ] with time index @xmath7 .",
    "[ c][c]@xmath3 $ ] [ c][c]@xmath6 $ ] [ c][c]@xmath4 $ ] [ c][c]@xmath5 $ ] [ c][c]available [ c][c]rirs [ c][c]anechoic [ c][c]speech [ c][c]noise [ c][c]gabor features [ c][c]feature [ c][c]extraction [ c][c]mlp [ c][c]label [ c][c]temporal [ c][c]average [ c][c]@xmath2     estimation . ]",
    "[ r][r]100 [ r][r]80 [ r][r]60 [ r][r]40 [ r][r]20 [ c][c]0.1 [ c][c]0.3 [ c][c]0 [ c][c]0.8 [ c][c]0.6 [ c][c]0.4 [ c][c]0.2 [ c][c]frames in time slot [ c][c]mean probability [ c][c]labels [ c][c](a ) mlp output [ c][c](b ) mean value across frames    gabor features are generated by 2d gabor filters @xmath8 applied to filter log - mel - spectrograms .",
    "the filters @xmath8 are localized spectro - temporal patterns that are with a high sensitivity towards amplitude modulations , as defined by @xmath9   & = & { s}_\\mathrm{carr } [ m , \\ell ] \\cdot { h}_{\\mathrm{env } } [ m , \\ell ]   \\ , , \\label{eqn : gabor}\\\\ { s}_\\mathrm{carr } [ m , \\ell ]   & = & \\exp{(i \\omega_m(m - m_0 ) + i \\omega_\\ell(\\ell-\\ell_0 ) ) } \\label{eqn : gabor_carr }   \\ , , \\\\ { h}_{\\mathrm{env } } [ m,\\ell ]   & = & 0.5 - 0.5 \\cdot \\cos\\left ( \\frac{2\\pi(m - m_0)}{w_m+1 } \\right )   \\nonumber \\\\                  & &    \\hspace{37.6pt }         \\cdot \\cos\\left ( \\frac{2\\pi(\\ell-\\ell_0)}{w_\\ell+1 } \\right )   \\ , , \\label{eqn : gabor_env}\\end{aligned}\\ ] ] with @xmath10 and @xmath11 denoting the ( mel-)spectral and temporal frame indices , and @xmath12 the hann - envelope @xmath13 window lengths with the center indices @xmath14 , respectively . the periodicity of the sinusoidal - carrier function @xmath15 is defined by the radian frequencies @xmath16 , which allow the gabor filters to be tuned to particular directions of spectro - temporal modulation .",
    "the purely diagonal gabor filters as shown in figure  [ fig : gbfb_2d ] , were found to result in the maximal sensitivity to the reverberation effect  @xcite and thus , are used here to construct the gabor features for the @xmath2 estimator .",
    "each log - mel - spectrogram is filtered with these 48 filters in the filterbank that cover temporal modulations from 2.4 to 25  hz  and spectral modulations from -0.25 to 0.25  cycles / channel , respectively .",
    "[ c][c]25.0 [ c][c]15.7 [ c][c]9.9 [ c][c]6.2 [ c][c]3.9 [ c][c]2.4 [ c][c]0.0 [ l][l]0.25 [ l][l]0.12 [ l][l]0.06 [ l][l]0.03 [ l][l]0.0 [ l][l]-0.25 [ l][l]-0.12 [ l][l]-0.06 [ l][l]-0.03 [ c][c]diagonal gabor filters [ c][c]temporal modulation frequency [ hz ] [ c][c]spectral modulation frequency [ cycl./chan . ]",
    "the ace challenge provides a development  ( dev )  dataset for algorithm fine - tuning and an evaluation  ( eval )  dataset for the final algorithm test .",
    "the task is aiming at blindly estimating two acoustic parameters , i.e.  @xmath0 and @xmath1 , from noisy and reverberant speech .",
    "two different modes i.e.  fullband and subband ( 1/3-octave iso  @xcite since @xmath0 and @xmath1 are both frequency dependent parameters ) , and six microphone configurations , i.e.  a single microphone  ( single ) and microphone arrays with two  ( laptop ) , three  ( mobile ) , five  ( cruciform ) , eight  ( linear ) , and thirty - two  ( spherical ) microphones , were introduced . the dataset was generated using anechoic speech convolved with rirs measured from real rooms with additive noise recorded under the same conditions .",
    "also , three types of noise signals , i.e.  ambient , babble and fan noises , were added to generate the noisy reverberant dataset . for dev dataset , the signal - to - noise ratios  ( snrs )",
    "were chosen to be 0 , 10 and 20  db , while for eval , the snrs were -1 , 12 and 18  db .",
    "the dev dataset is approximately 120  h length from all multi - microphone scenarios .",
    "each test set from eval contains 4500 utterances categorized by these 3  noise types and 3  snrs . for this paper",
    ", we focus on the tasks in the fullband mode of @xmath0 and @xmath1 estimation in the single microphone scenarios .",
    "our approach is also applicable to multi - microphone scenarios by selecting any channel of the speech data .",
    "the ground truth values of @xmath0 and @xmath1 were provided by the ace challenge .",
    "the ground truth @xmath0 is based on the energy decay curve computed from the rirs using the schroeder integral  @xcite , to which the method proposed in  @xcite is used to estimate @xmath0 .",
    "this method is shown to be more reliable under all conditions than the standard method according to iso3382  @xcite .",
    "the ground truth @xmath1 is estimated using the method of  @xcite , where the direct path is determined by the @xmath178  ms around the maximum found using an equalization filter  @xcite .",
    "the mlp shown in figure  [ fig : mlp ] was implemented with the open - source kaldi asr toolkit  @xcite compiled with a tesla k20c nvidia gpu with 5  gb memory size .",
    "it had 3  layers : the number of neurons in the input layer is 600 , i.e.  dimension of the 2d diagonal gabor features ( cf .",
    "figure  [ fig : gbfb_2d ] ) calculated in matlab . the temporal context considered by the mlp",
    "is limited to 1  frame , i.e.  no splicing is applied .",
    "the number of hidden units is a free parameter that was optimized given the amount of training data and set to 8192 units , and the number of output neurons corresponds to the amount of @xmath2 pairs , i.e.  100 as defined in the following ( also cf .",
    "figure  [ fig : mlp_label ] ) .",
    "ace database was recorded by different individuals who were reading different text materials in english . here , we applied timit corpus  @xcite to generate the training data for mlp , since timit contains recordings of phonetically - balanced prompted english speech and a total of 6300  sentences ( approximately 5.4  h ) . to avoid a strong mismatch between training and test data ( which is likely to hurt mlp classification performance ) we added the ace dev dataset to the training data . in order to match the amount of the dev dataset ( approximately 120  h ) , thereby balancing the two sets , timit utterances were convolved with the collected rirs circularly , which resulted in approximately 117  h timit training data .",
    "the sampling rate of all signals is 16  khz .",
    "[ c][c]-6 [ c][c]-5 [ c][c]-4 [ c][c]-3 [ c][c]-2 [ c][c]-1 [ c][c]0 [ c][c]1 [ c][c]2 [ c][c]3 [ c][c]4 [ c][c]5 [ c][c]6 [ c][c]7 [ c][c]8 [ c][c]9 [ c][c]10 [ c][c]11 [ c][c]12 [ c][c]13 [ c][c]14 [ c][c]15 [ r][r]1350 [ r][r]1250 [ r][r]1150 [ r][r]850 [ r][r]750 [ r][r]650 [ r][r]550 [ r][r]450 [ r][r]350 [ r][r]250 [ r][r]150 [ c][c]@xmath0 / ms [ c][c]@xmath1 / db [ c][c]@xmath2 distribution [ l][l]collected rirs [ l][l]ace dev [ l][l]ace eval    , as well as the ground truth values of the ace dev and eval datasets . ]    to cover a wide range of rirs that occur in real life scenarios , we use several open - source rir databases such as mardy  @xcite , air database  @xcite , reverb challenge  @xcite and smard  @xcite .",
    "further , we also recorded several rirs in two regular office rooms in our group .",
    "figure  [ fig : rir_distru ] shows the distribution of @xmath2 values from the collected rirs , as well as the ace dev and eval datasets .",
    "@xmath2 ground truth values of the collected rirs were calculated based on the methods described in section  [ ssec : ace ] . due to the lack of the corresponding equalization filters for the source ,",
    "the absolute peak position is considered as the maximum to determine the direct path for the @xmath1 calculations .",
    "an mlp has a limited number of output neurons , which limits the resolution for the target estimate .",
    "we chose a resolution based on the distribution of training rirs , with the aim of obtaining a sufficient number of @xmath2 observations for each pair , which is 100  ms for @xmath0 and 1  db for @xmath1 ( cf .",
    "figure  [ fig : rir_distru ] where one bounding box represents one class ) .",
    "the boundaries of @xmath0 are 100  ms and 900  ms , with @xmath1 ranging from -6  db to 15  db .",
    "with these boundaries and the chosen resolution , 76  classes are obtained for the collected rirs ( light blue boxes ) , and 51  classes are obtained from the ace dev dataset ( light red boxes ) .",
    "these classes are partially overlapping ( light yellow boxes ) and result in a total of 100  classes .",
    "the ace noise signals were recorded in the same acoustic conditions as the rir measurement ,  i.e. , the noise captured by the microphone is reverberated .",
    "hence , the noise signals combined with our extended rirs should be reverberated as well . since the original noise signals were not available in the context of the challenge , we created noise signals with similar characteristics as the original ambient , babble and fan noise .",
    "* ambient noise was created by mixing recorded car noise and pink noise to obtain a colored noise with high energy in the low frequencies ( as the original ambient noise ) .",
    "* to create babble noise , we mixed clean speech signals ( two male , two female speakers ) from the wsjcam0  @xcite corpus . *",
    "a fan noise was recorded in an almost anechoic chamber to obtain the last noise type .",
    "subsequently , the noise signals were added to the anechoic speech at snrs of 0 , 10 and 20  db ( mimicking the procedure for the ace dev dataset ) , which were then convolved with the collected rirs .",
    "the estimation error is used for analysis and is defined as the difference between the estimated value and the ground truth value , i.e.  @xmath18 in  s for @xmath0 and @xmath19 in  db for @xmath1 . for comparison ,",
    "the methods proposed in  @xcite and in  @xcite are employed as baseline to blindly estimate @xmath0 and @xmath1 , respectively .",
    "note that the blind @xmath1 estimator in  @xcite requires a mapping function between the overall srmr from 5th to 8th channel and the @xmath1 ( both expressed in  db ) , which is obtained by the ace dev single dataset .",
    "[ c][c]ambient [ c][c]babble [ c][c]fan [ c][c]@xmath20 / s [ c][c]@xmath21 / db [ c][c]snr / db [ l][l]baseline [ l][l]proposed     estimation for ace eval single dataset . on each box ,",
    "the central mark is the median , the edges are the 25th and 75th percentiles , the whiskers show extreme values and the outliers are plotted individually . ]",
    "[ l][l]laptop [ l][l]mobile [ l][l]cruciform [ l][l]linear [ l][l]spherical [ c][c]ambient [ c][c]babble [ c][c]fan [ c][c]@xmath20 / s [ c][c]@xmath21 / db [ c][c]snr / db        as seen in figure  [ fig : t60_single_comp ] , in general , the proposed method outperforms the baseline approaches . for @xmath0 ,",
    "the baseline method works better in slightly noisy environments with an snr of 18  db , while the performances degrade with lower snrs .",
    "the proposed method has a higher robustness with respect to additive noise , presumably because the statistical model is trained on noisy reverberant speech with various snrs .",
    "the median values of @xmath20 are close to 0  ms for all conditions ( 3  noise types and 3  snrs ) , and the upper and lower percentiles are within @xmath17250  ms , which indicates that the proposed method is capable of providing accurate blind @xmath0 estimation .",
    "in addition , far less outliers are obtained compared to the baseline method .",
    "the same trend can be observed for @xmath21 , for which the baseline produces large errors for both median and percentiles , particularly in the low snr situations .",
    "the @xmath1 is underestimated by approximately -1.5  db . this could be explained by the limited resolution of estimates ( 100  ms for @xmath20 , 1  db for @xmath21 ) and the mismatch of data range for training data on the one hand , and for eval dataset on the other : as shown in figure  [ fig : rir_distru ] , @xmath0 values from 1100  ms to 1400  ms are not covered by the training data at all .",
    "a detailed post analysis showed that underestimates of @xmath0 that arise from this mismatch go along with underestimates of @xmath1 ; for instance , a test sample with ground truth of ( 1293  ms ,  4.96  db ) was estimated to be ( 750  ms ,  1  db ) .",
    "it appears that the underestimated reverberation effect caused by an underestimate of @xmath0 is somehow compensated by the corresponding underestimate of @xmath1 .",
    "further , the mismatches of the snrs and the noise signals might also lead to estimation errors , and it seems that such mismatches affect the @xmath1 estimate stronger than the @xmath0 estimate .",
    "additionally , the proposed @xmath2 estimator is tested with the ace multi - microphone data , but only one channel ( here the first channel _ ch1 _ ) is selected to perform the same estimation process .",
    "the overall trend of the estimation results as shown in  figure  [ fig : multi_ch1 ] is similar to previous results , which serves as verification of our approach on a different ( and larger ) test set .",
    "again , the median values of @xmath20 are near to 0  ms and the percentiles are within @xmath17250  ms , and the median values of @xmath21 are between -1  db and -2  db with @xmath172.5  db percentiles .",
    "consistent performances across noise types and snrs indicate the importance of exploiting training data with a high amount of variability for a discriminative model in order to achieve robustness in adverse conditions .",
    "the computational cost of our approach is quantified in terms of the real - time factor  ( rtf ) , defined as the ratio between the time taken to process a sentence and the length of the sentence .",
    "two components in our approach contribute most to the overall complexity , i.e. , the calculation of gabor features and the forward - run of the neural net ( cf .",
    "figure  [ fig : rir_distru ] ) . for optimization of the first component ,",
    "the 2d convolution of spectrograms with gabor filters was replaced by multiplication with a universal matrix . since the proposed mlp estimator operates on a gpu ( cf .",
    "section  [ ssec : plat ] ) , the computational complexity is measured in frames per second  ( fps ) with the frame length of 25  ms and overlapping of 10  ms . a rough transfer from fps to rtf",
    "can be computed by @xmath22 . with an average gpu speed of 23736  fps ,",
    "an average rtf of 0.0042 is obtained . in summary ,",
    "the average rtf of the proposed estimator for the single - microphone scenario ( 4500 utterances ) is @xmath23 ( providing both @xmath24 and @xmath25 ) , while the rtfs of baseline @xmath0 estimator  @xcite and @xmath1 estimator  @xcite are 0.0483 and 0.3101 , respectively .",
    "this contribution presented a novel method for @xmath0 and @xmath1 in a blind and joint way using an mlp for classification .",
    "it has been shown that the proposed method is capable of accurately estimating @xmath0 and @xmath1 in the context of the ace challenge using single - microphone , fullband speech signals .",
    "the estimation errors of @xmath0 and @xmath1 cover a relatively small range of @xmath17250  ms and @xmath172.5  db with corresponding median values of nearly 0  ms and -1.5  db on average , respectively .",
    "furthermore , compared to the baseline approaches that only estimate either @xmath0 or @xmath1 estimation at a time , the computational complexity of the proposed estimator is significantly lower since the signal processing for feature extraction and the forward - run of the neural net are not very demanding in terms of computational cost , and since the @xmath0 and @xmath1 are estimated simultaneously ."
  ],
  "abstract_text": [
    "<S> blind estimation of acoustic room parameters such as the reverberation time  @xmath0 and the direct - to - reverberation ratio  ( @xmath1 ) is still a challenging task , especially in case of blind estimation from reverberant speech signals . in this work , </S>",
    "<S> a novel approach is proposed for joint estimation of @xmath0 and @xmath1 from wideband speech in noisy conditions . </S>",
    "<S> 2d gabor filters arranged in a filterbank are exploited for extracting features , which are then used as input to a multi - layer perceptron  ( mlp ) . </S>",
    "<S> the mlp output neurons correspond to specific pairs of @xmath2 estimates ; the output is integrated over time , and a simple decision rule results in our estimate . </S>",
    "<S> the approach is applied to single - microphone fullband speech signals provided by the acoustic characterization of environments  ( ace ) challenge . </S>",
    "<S> our approach outperforms the baseline systems with median errors of close - to - zero and -1.5  db for the @xmath0 and @xmath1 estimates , respectively , while the calculation of estimates is 5.8 times faster compared to the baseline .    </S>",
    "<S> reverberation time , direct - to - reverberation ratio , 2d gabor features , multi - layer perceptron , ace challenge </S>"
  ]
}