{
  "article_text": [
    "a quantum computer will need to be engineered to reduce the effect of errors to acceptable levels .",
    "there are a number of techniques that can be applied together to achieve fault tolerance , including decoherence free subsystems , dynamical decoupling , and error - correcting codes @xcite . here",
    "we concentrate on engineering an efficient code correction procedure .    for noise below a certain threshold error rate , multiply concatenated coding allows the effective logical error rate to be reduced so arbitrarily long computations can be performed .",
    "this threshold , which depends on the error model , is a good benchmark for an error correction scheme .",
    "it is a fundamental theoretical and engineering task to devise schemes to increase the threshold .",
    "estimates of the threshold with previous schemes have varied widely .",
    "aharonov and ben - or @xcite estimate a noise threshold of @xmath0 for a scheme with no classical computation .",
    "using measurement together with fast and accurate classical computation increases the threshold .",
    "gottesman and preskill @xcite estimate a threshold between @xmath1 and @xmath2 .",
    "zalka @xcite gives a scheme for which he optimistically estimates a gate noise threshold of @xmath3 .",
    "steane @xcite recently gave a further optimized error correction procedure which increases the noise threshold to almost @xmath4 .",
    "in this paper , we give new optimizations to maximize the efficiency of the hamming @xmath5 $ ] quantum error correcting code .",
    "we design an encoded ancilla preparation procedure which increases the fault - tolerant threshold to almost @xmath6 ( in a particular error model ) , nearly a factor of three improvement . at a noise rate of @xmath4 , the new procedure increases efficiency by two orders of magnitude .",
    "efficient classical simulations of the quantum error process demonstrate these results .",
    "besides exhibiting this one procedure , a broader goal of this paper is to show how carefully engineering the error correction procedure has the potential to dramatically increase its efficiency .",
    "in section  [ s : csscodes ] we focus on css codes , and summarize the error correction and ancilla preparation methods of steane developed incrementally over a series of papers .",
    "in section  [ s : rejectancilla ] we present our improved ancilla preparation scheme , which increases the number of checks an ancilla must pass in order to be used in error correction .    in section  [ s :",
    "analysis ] , we use simulations to analyze the performance of the improved ancilla preparation scheme together with a slightly modified error correction scheme . we also analyze the efficiency of the new scheme  how much time , or how much parallelism , it takes to prepare an ancilla .",
    "in section  [ s : ideal ] , we ask by how much could similar optimizations increase the error correction threshold .",
    "we simulate idealized models to speculatively upper bound the increases possible using optimizations of this type .",
    "a conceptual diagram of the error correction procedure is shown in fig .  [",
    "f : errorcorrection ] . here , each wire represents a logical bit , encoded perhaps recursively with the hamming @xmath5 $ ] code .",
    "the logical cnot gates correspond to physical cnot gates acting transversely .",
    "after every fault - tolerant logical operation , we correct for errors  first @xmath7 bit flip errors , then @xmath8 phase flip errors . to correct for @xmath7 errors ,",
    "we prepare an ancilla in the encoded @xmath9 state ( logical @xmath7 @xmath10 eigenstate ) .",
    "we then apply a transverse cnot gate from data to ancilla , moving @xmath7 errors from the data to the ancilla .",
    "we measure each bit of the ancilla in the @xmath8 eigenbasis .",
    "the obtained syndrome allows us to locate the @xmath7 errors just as for the classical hamming code .",
    "notice that 1 .",
    "@xmath8 errors from the ancilla move to the data , and 2 .",
    "@xmath7 errors in the ancilla will lead to an incorrect syndrome diagnosis .",
    "steane gives an error correction procedure tailored to address these two problems @xcite . to address the first problem",
    ", steane takes care to prepare the ancilla with as few @xmath8 errors as possible . then to avoid basing a correction on an incorrect syndrome , he uses repeated syndrome extraction ( not shown ) .",
    "if the first syndrome extracted is nontrivial , he extracts two more syndromes and only applies a correction if at least two syndromes agree .",
    "if no two syndromes agree , he does not try to extract more syndromes ",
    "after all , @xmath8 errors may be accumulating in the data . instead , in the next round of @xmath7 error correction he will extract one more syndrome and ( if it is nontrivial ) he looks for agreement with one of the previous syndromes before applying a correction .",
    "@xmath8 error correction is entirely symmetrical .",
    "full details of the procedure can be found in @xcite .",
    "for example , if the data block is the control of a logical cnot gate , steane corrects for @xmath8 errors , then @xmath7 errors before the logical gate ",
    "this makes it less likely for @xmath7 errors to propagate across the gate from one data block to another .",
    "it remains to describe how steane prepares the encoded ancilla @xmath11 .",
    "the basic idea , described in @xcite for general css codes , is to maximize parallelism while generating the ancilla , and then to verify the @xmath7 stabilizers to minimize @xmath8 errors .",
    "moreover , the verification process is designed so that @xmath8 errors of weight @xmath12 occur with probability at most order @xmath13 ( despite correlations introduced in the generation step ) .",
    "steane s procedure to prepare @xmath11 with minimal @xmath8 errors for the hamming code is shown in fig .",
    "[ f : ancillapreparation ] .",
    "the boxes indicate error correction ",
    "@xmath7 then @xmath8 , or @xmath8 then @xmath7  at the next lower level of concatenation , if applicable . the verification of the @xmath7 stabilizers is shown in fig .",
    "[ f : ancillaverification ] .",
    "many ancillas are generated and verified in parallel .",
    "only those passing the verification are used for error correction .",
    "we implement a single optimization to steane s ancilla preparation procedure .",
    "we prepare the ancilla as in fig .",
    "[ f : ancillapreparation ] . however , every error correction step is replaced by an error _ detection _ step .",
    "if a nonzero syndrome is detected , all 49 bits of the ancilla are discarded , and we start anew .",
    "this changes the probability of a logical error from a second - order to a third - order event . for efficiency",
    ", we do not bother with the logical checks of fig .",
    "[ f : ancillaverification ] .",
    "( the error detection uses 7 bit ancillas prepared as by steane . )    in order to take advantage of the improved ancillas , we also simplify steane s error correction procedure .",
    "we extract only a single syndrome , and correct for it considering the concatenated code as a @xmath14 $ ] code ( i.e. , correcting up to four errors ) .",
    "we do not extract multiple syndromes to check for mistakes .",
    "we do not correct at the 7-bit code level .",
    "we work with a simple depolarization error model which lends itself to experimentation . when an error occurs on a bit , that bit is depolarized  replaced by the uniform density matrix . to implement this , we record with equal probabilities @xmath15 either @xmath16 ( no error ) , @xmath7 , @xmath17 or @xmath8",
    ".    there are four basic operations : preparation of fresh bits ( as either @xmath18 or @xmath19 ) , single bit gates , two bit cnot gates , and destructive measurement .",
    "each of these operations has probability @xmath20 of failure , in which case the affected bits are depolarized . in the case of a two bit gate failure",
    ", both bits are depolarized .",
    "we do not consider memory errors ( and therefore available gate parallelism is irrelevant ) .",
    "we also do not consider the physical location of bits within the computer  so cnot gates can couple arbitrary bits , not just nearest neighbors .",
    "our simpler error model facilitates experimentation with different error correction procedures . by developing an understanding of this simple model ,",
    "we are better prepared for optimizing error correction for complicated quantum computer engineering tasks , for example a 3-dimensional lattice ion trap computer with lower - level encoding ( like a dfs or code against qubit loss @xcite ) .",
    "steane s error correction procedure @xcite was developed in a model where memory errors might be significant ; he ran simulations with a memory error rate from @xmath21 to @xmath20 . for a more fair comparison",
    ", we evaluated several small optimizations to his procedure effective in the low memory error rate regime .",
    "steane extracts one syndrome , aborting error correction if that syndrome is trivial . otherwise , he extracts two more syndromes , and looks for two agreeing syndromes .",
    "we modify this to always extract one syndrome at a time , and to always abort after retrieving a trivial syndrome ",
    "i.e. , if the first two syndromes agree or if the second syndrome is trivial , do nt extract a third one .",
    "we largely follow the simulation method and statistical procedures as described by steane @xcite .",
    "the simulator is fast and efficiently scalable since for each bit it only needs to store either @xmath16 , @xmath7 , @xmath17 or @xmath8 . although ancilla states are stabilizer states , there is no need to keep track of the stabilizer with a simulator like chp @xcite because the stabilizer is always well known . even though data blocks may have arbitrary encoded states , there is no need to keep track of the exact , exponentially large quantum state with a simulator like quiddpro / d @xcite , because we only care about the error correction part of the circuit .    to increase the credibility of steane s simulation method , we additionally track errors between 49-bit data blocks . this is important because even blocks which have just been corrected still have some errors .",
    "every round we apply a transverse cnot gate to or from another data block .",
    "we then correct @xmath7 and @xmath8 errors in a random order which determines whether the block will be the control or target of the next round s transverse cnot gate . to implement this ,",
    "if a block has not crashed we save it in a list for later use . as a detail ,",
    "we only save blocks after the third round , to allow the distribution of errors to converge .",
    "figure  [ f : physicalancillaerrors ] shows that the physical error rate is reduced slightly .",
    "this slight reduction is largely because of the dramatic reduction in the logical error rate ( 2 or 3 bit physical errors within a block ) shown in fig .",
    "[ f : logicalancillaerrors ] .",
    "figure  [ f : effectonthreshold ] shows the effect of the new error correction procedure on the crash rate compared to steane s procedure .",
    "( a crash is defined as a set of physical errors which perfect error correction would project to a logical error . ) to read off an approximate threshold from the figure , we take the intersection of the crash rate curve with the line of slope @xmath22 ( the rate at which @xmath7 , @xmath17 or @xmath8 physical errors occur is @xmath22 the depolarization rate ) .",
    "this is only an approximate result , since the error model at the next higher level is not the same as the physical depolarization error model .",
    "in particular @xmath7 and @xmath8 logical errors are less correlated than @xmath7 and @xmath8 physical errors .",
    "there is a loss of efficiency at higher error rates , but at rates at or below the old threshold , the efficiency is actually just as good or better .",
    "see fig .",
    "[ f : timetoprepareencodedancilla ] , where preparing a steane ancilla at zero error rate is defined to take one unit of time . since the error rate drops rapidly with concatenation below the threshold , the efficiency loss will show up in practice only at the lowest concatenation levels .    further optimization could reduce this overhead .",
    "its exponential dependence on the error rate makes it sensitive to small changes to which the threshold itself is insensitive .",
    "for example , we found that modifying the 7-bit ancilla verification to only check only three of the four relevant stabilizers",
    " an idea from @xcite  reduced the overhead by about a factor of four at 1% error rate .",
    "however , the poor efficiency at high error rates probably rules out some generalizations of this ancilla preparation scheme .",
    "for example , we expect it will be impractical to apply the scheme to the 343 bit code gotten by concatenating the hamming code twice , or to the @xmath23 $ ] golay code concatenated with itself .",
    "how much more can optimizations of this type gain us ? we ran the same simulations with a 49-bit ancilla perfectly prepared , except each bit was subject to a single possibility of error , then each block was checked for x and z errors . if an error was detected , the entire ancilla was rejected .",
    "for this ideal ancilla , logical errors are much less correlated than in our preparation procedure .",
    "the simulations showed almost no improvement whatsoever in the threshold .",
    "our ancilla preparation procedure is already quite well optimized , and the crashes that still occur can not generally be blamed on a faulty ancilla .",
    "hence further optimizations of the error correction procedure for the @xmath14 $ ] code will need to do more than improve ancilla preparation .",
    "we are not able to simulate rejection ancilla preparation for the golay code concatenated with itself ; too many ancillas must be thrown away for every good ancilla .",
    "( a crude estimate puts the overhead at  @xmath24 , although optimizations can reduce this enormously . )",
    "we instead simulated preparation of ideal ancillas as above for the hamming code , with the expectation that results would be close to the actual ancilla preparation procedure .",
    "we found that the threshold increases to about @xmath25 . while @xmath24 is impractically large , it is still a constant .",
    "theoretically , it is of interest how much higher the threshold can be increased by using different codes , more concatenation , or improved syndrome interpretation .",
    "for quantum computers to become a reality , highly efficient coding against errors is essential .",
    "we have proposed an optimized encoded ancilla preparation scheme for the concatenated hamming code .",
    "simulations show that the improved scheme decreases the crash rate by almost two orders of magnitude , and increases the fault - tolerant threshold significantly .",
    "there is however a loss of efficiency at higher error rates .    very recent independent work by knill @xcite uses a similar idea to increase the threshold .",
    "further research is needed to make these schemes more practical : still more efficient , and applicable to more general error models .",
    "george  f. viamontes , igor  l. markov , and john  p. hayes .",
    "graph - based simulation of quantum computation in the density matrix representation . in _ proc . of quantum information and computation , spie defense and security symp .",
    "_ , 2004 , quant - ph/0403114 ."
  ],
  "abstract_text": [
    "<S> we demonstrate an improved concatenated encoded ancilla preparation procedure . </S>",
    "<S> simulations show that this procedure significantly increases the error threshold beneath which arbitrarily long quantum computations are possible . </S>"
  ]
}