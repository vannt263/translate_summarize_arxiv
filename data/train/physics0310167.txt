{
  "article_text": [
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ for every complex problem , there is a solution that is simple , neat , and wrong .",
    "mencken _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the complex problem considered here is goodness - of - fit ( g.o.f . )  for unbinned maximum likelihood fits in cases when binned g.o.f .",
    "methods and kolmogorov - smirnov are not well suited :    a physicist , having fit a complicated model to his multi dimensional data to obtain estimates of the values of certain parameters , is also expected to check how well the data match his model . in the sections that follow , we discuss a g.o.f .",
    "method , still occasionally used in high energy physics ( hep ) , that is simple , neat , and wrong .",
    "we start with a brief description of the method .",
    "( a true derivation , for obvious reasons , is not available . )",
    "observation : : :    maximum likelihood fits are performed by maximizing the likelihood    @xmath0 with respect to the ( unknown )    parameters @xmath1 for fixed data    @xmath2 .",
    "faulty intuition : : :    thus , the value of the likelihood provides the g.o.f .  between the data    and the probability density function ( p.d.f . ) : the value of the    likelihood at the maximum ,    @xmath3 corresponds    to the best fit ",
    "the smaller the likelihood , the worse the g.o.f . , ",
    "obstacle : : :    to calculate this `` g.o.f . ''",
    "p - value , we need the distribution of    @xmath4 for an ensemble of random    @xmath2 deviates from the p.d.f .  using the true ( but    unknown ) parameters @xmath5 .",
    "faulty resolution : : :    we approximate this by replacing @xmath5 with the    parameter estimate obtained from the fit to the actual data .",
    "this method has a long history of use in high energy physics .",
    "it s recommended by several excellent statistical data analysis texts written by ( and for ) high energy particle physicists .",
    "consequently , and because the method is `` obvious '' , it s still being used in ( some ) hep analyses .",
    "reference @xcite , written by a statistician and four physicists , describes the method , but criticizes :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ the likelihood of the data would appear to be a good [ g.o.f . ]",
    "candidate at first sight .",
    "unfortunately , this carries little information as a test statistic , as we shall see  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    since this was ignored , maybe its warning was not strong enough .",
    "i have found no mention of the method in texts written ( solely ) by statisticians .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ always test your general reasoning against simple models . _",
    "john s.  bell _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    reference @xcite , following the above advice , tests the method against the p.d.f . @xmath6 where @xmath7 ( we have in mind the decay - time of a particle ) follows an exponential distribution , and @xmath8 ( the mean lifetime ) is a parameter whose value , being unknown , is estimated from data .",
    "the likelihood for @xmath9 observations @xmath10 is given by @xmath11\\ ] ] the value ( @xmath12 ) of @xmath8 that maximizes the likelihood , and the value ( @xmath4 ) of the likelihood at its maximum , are given by @xmath13      the value of the likelihood at its maximum ( in this test case ) is just a simple function of @xmath12all samples with the same mean obtain the same `` g.o.f . ''  value",
    "this is a disaster for g.o.f . even if the true value of @xmath8call it @xmath14were known in advance , so that we could calculate the p - value associated with the observed @xmath12 , merely comparing the @xmath12 of the data with @xmath14 is not sufficient to show that the observed data are modeled well by the exponential distribution .      since under this method ,",
    "our p - value ensemble is actually based on the value of @xmath12 computed from the data ( not knowing the true value @xmath14 ) , we _ always _ obtain a p - value of about 50% , _ for any data whatsoever_. this is a second disaster for g.o.f . by construction ,",
    "the distribution of @xmath4 from our ensemble of @xmath9-event pseudo experiments tracks the @xmath4 observed from the data .",
    "the fact that the method yields `` reasonable '' p - values has undoubtedly contributed to its longevity in practice : p - values very near 0 or 100% would have triggered further investigation .      in this example , g.o.f .",
    "is equivalent to testing the single hypothesis : `` the data are from an exponential distribution of unspecified mean . ''",
    "@xmath4 provided no information with respect to this hypothesis .",
    "what went wrong ?",
    "in our test case , the likelihood could be expressed as a function of just the parameter and its maximum likelihood estimator ( m.l.e . ) : @xmath15 . _ all _ data samples with the same m.l.e",
    ".  gave the same `` g.o.f . ''",
    "exactly the same thing happens in the gaussian ( normal ) case  the likelihood can be written using solely the 2 parameters and their estimators : @xmath16 .",
    "other `` textbook '' distributions ",
    "scaled gamma , beta , log - normal , geometric  also fail in the same way .",
    "geometric is a discrete distribution , so the problem is not restricted to the continuous case .",
    "returning to our exponential example , suppose we make the substitution @xmath17 .",
    "the p.d.f .",
    "transforms as @xmath18 and the g.o.f .",
    "statistic is now calculated as @xmath19 \\qquad { \\hat\\tau={1\\over n}\\sum_{i=1}^nx_i^2}\\ ] ] @xmath20 that is , the `` g.o.f . ''",
    "statistic is not invariant under change of variable in the continuous p.d.f",
    "( the value of the m.l.e .  is , of course , invariant . )    under change of variable , the `` g.o.f . ''",
    "statistic picks up an extra term from the jacobian ",
    "an extra function of the data .",
    "we re free to choose any transformation , so we can make the `` g.o.f . ''",
    "statistic more or less anything at all  a serious pathology .    at this point ,",
    "experts point out that _ ratios _ of likelihoods have the desired invariance under change of variable , but , while the likelihood ratio is a useful test statistic in certain special cases , it is not at all clear how to obtain a useful g.o.f .",
    "statistic from the likelihood ratio in the general , unbinned , case .",
    "since we now lack an intuitive understanding , we need a replacement intuition for what is going on .",
    "i propose this model :    denote by @xmath21 the hypothesis that the data are from the p.d.f .  in question .",
    "specify an alternative hypothesis @xmath22 that the data are from a uniform p.d.f .",
    "( flat in the variables that we happen to have chosen ) .",
    "at least , the @xmath22 p.d.f .",
    "is flat over the region where we have data  outside that region it can be cut off .    performing a classic neyman - pearson hypothesis test of @xmath21 vs @xmath22",
    ", we use the ratio of their likelihoods as our test statistic : @xmath23 so , the `` g.o.f . ''",
    "statistic can be re - interpreted as suitable for a hypothesis test that indicates which of @xmath21 ( our p.d.f . )  and @xmath22 ( a flat p.d.f . )",
    "is more favored by the data  a well established statistical practice .",
    "the benefit of the new interpretation is that it explains behaviors that were baffling under the g.o.f .",
    "interpretation : neyman - pearson hypothesis tests and g.o.f .",
    "tests behave quite differently .    for example , a reasonable g.o.f .",
    "statistic should be at least approximately distribution independent , but @xmath24 is often highly correlated with the m.l.e.s ( 100% in our exponential case ) .",
    "this high correlation was confirmed in the example contributed by k.  kinoshita@xcite to the 2002 durham conference .",
    "not knowing the true value of the parameters then makes it difficult , or impossible , to use @xmath24 as g.o.f .",
    ", since we do nt know what @xmath24 _ should _ be .",
    "of the estimated value of a parameter , one would be justified in concluding `` good fit '' ( assuming the g.o.f.statistic used had the right properties in other respects ) . ]",
    "the behavior of these correlations is natural and obvious in the hypothesis test picture : changing the parameters changes the `` flatness '' of the @xmath21 p.d.f . , and",
    "@xmath24 reflects this .",
    "reference @xcite pointed out that , with no unknown parameters , one can always transform the p.d.f .  to a flat distribution .",
    "then @xmath24 becomes constant independent of the data  bad news for g.o.f . in the hypothesis test picture , this becomes a comparison between two identical hypotheses , and the result is what we would expect .",
    "take the @xmath21 p.d.f .  to be @xmath25",
    "this distribution is fully specified  no unknown parameters .",
    "our `` g.o.f . ''",
    "statistic is then @xmath26 whose mean is @xmath27 , and variance is @xmath28 , for an ensemble of data sets from the @xmath21 p.d.f .",
    "a data set with @xmath29 close enough to 1 will be claimed to be a good fit to the @xmath21 p.d.f .    but say , unknown to us , the data are really from a triangular p.d.f .",
    ": @xmath30 the mean and variance of @xmath31 will be @xmath9 and @xmath32 respectively , for data from the triangular distribution .",
    "so , although the exponential and triangular p.d.f.s are quite different , the triangular data will be more likely to pass the g.o.f .",
    "test than exponential data for which it was intended .",
    "statisticians refer to this situation as a case of `` test bias '' .",
    "we conclude that , even with no free parameters , the `` g.o.f . ''",
    "test is biased : there exist `` impostor '' p.d.f.s that should produce bad fits , but instead pass the `` g.o.f . ''  test with greater probability then the p.d.f .  for which the test was designed .",
    "reference @xcite gives additional examples of this behavior .    from the hypothesis test point of view",
    ", this behavior makes sense .",
    "the exponential and triangular data have the same `` distance '' from the flat distribution , on the average , with the triangular data being less susceptible to fluctuations .",
    "the hypothesis test does nt tell us when the data are inconsistent with both @xmath21 and @xmath22 .",
    "here we try to find an example p.d.f .",
    "( with a free parameter ) that the method in question can handle well .",
    "we use the insight provided by the hypothesis test picture .",
    "we want to keep the correlation between the free parameter and the g.o.f .",
    "statistic @xmath4 to a minimum . in the hypothesis test picture",
    ", this is achieved when the `` flatness '' of the p.d.f .",
    "is independent of the parameter .",
    "a location parameter has this property .",
    "additionally , we want the p.d.f .  to be easily distinguishable from a flat p.d.f .",
    "so we choose the gaussian @xmath33 where @xmath34 is unknown , but @xmath35 is specified in advance . the likelihood is given by @xmath36\\ ] ] when @xmath34 and @xmath35 are both unknown , their m.l.e.s are @xmath37    using these expressions , we can rewrite the likelihood in the form @xmath16 : @xmath38\\ ] ] when only @xmath34 is unspecified , its m.l.e .",
    "is @xmath39 as above , and the value of the maximized likelihood is @xmath40\\ ] ]    our victory is that @xmath4 only depends on @xmath41 , which is an ancillary statistic for @xmath34 .",
    "that is , we do nt need to know the true value of @xmath34 in order to calculate the distribution of our g.o.f .",
    "statistic in this carefully chosen example .",
    "in fact , a convenient form for the g.o.f .  statistic is @xmath42 which is well known to have the distribution ( under the null hypothesis ) of a @xmath43 with @xmath44 degrees of freedom .",
    "before we declare that the method performs well in this example , there are several ugly facts to consider :    * data that match the null hypothesis well yield @xmath45 .",
    "much larger or much smaller values of the g.o.f .",
    "statistic imply poor g.o.f .",
    "this is in contrast to pearson s @xmath43 ( binned @xmath43 ) , for example , where smaller @xmath43 is always better g.o.f .",
    "so we must interpret this statistic differently than how we are used to . * the g.o.f .",
    "in this example simply reduces to a comparison between the sample variance and @xmath46 .",
    "any distribution with variance approximately equal to @xmath46 will usually generate data that `` pass the test '' , even distributions that look nothing like a gaussian .",
    "this is the same kind of problem that we first saw in section  [ s1 ] . * a construction similar to that of section  [ bias ]",
    "will produce `` impostor '' p.d.f.s that pass the `` g.o.f . ''",
    "test with greater frequency than the null hypothesis .",
    "so , we have not eliminated the test bias problem .    in this example , the g.o.f .",
    "method in question will be able to flag some , but not all , of data samples that poorly match the null hypothesis .",
    "in answer to the question `` are the data from a gaussian with unspecified mean , and variance equal to @xmath46 ? '' , this g.o.f .",
    "method can only answer `` no '' or `` maybe '' : it checks the variance part of the question , but does nothing to check the gaussian part .",
    "* this `` g.o.f . ''",
    "method is fatally flawed in the unbinned case .",
    "do nt use it .",
    "complain when you see it used . * with fixed p.d.f.s ,",
    "the method suffers from test bias , and is not invariant with respect to change of variables .",
    "these problems persist when there are floating parameters . * with floating parameters ,",
    "the method is often circular : `` g.o.f . ''",
    "becomes a comparison between the measured values and the true ( but unknown ) values of the parameters  * the misbehavior of this `` g.o.f . ''",
    "statistic is understandable when reinterpreted as the ratio between the likelihood in question and a uniform likelihood , and used to distinguish between these two specific hypotheses .",
    "dual - hypothesis tests are not g.o.f .  tests",
    ".            k.  kinoshita , `` evaluating quality of fit in unbinned maximum likelihood fitting '' , in _ proceedings of the conference on advanced techniques in particle physics _ , edited by m.  whalley and l.  lyons , p 176 , ( 2002 ) ."
  ],
  "abstract_text": [
    "<S> the value of the likelihood is occasionally used by high energy physicists as a statistic to measure goodness - of - fit in unbinned maximum likelihood fits . </S>",
    "<S> simple examples are presented that illustrate why this ( seemingly intuitive ) method fails in practice to achieve the desired goal . </S>"
  ]
}