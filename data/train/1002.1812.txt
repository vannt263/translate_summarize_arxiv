{
  "article_text": [
    "consider a controlled dynamical system , affected by some exogenous noises , say uncertain parameters for instance .",
    "stochastic optimal control consists in driving this system , having at each time step partial or total observations of those noises , so as to minimize some expected cost integrated through time and while satisfying a number of constraints .",
    "many applications can be handled through such a model .",
    "for instance , think of a power producer that has to plan the use of a set of power plants ( the control would be the production of the plants at each time step ) in order to supply an uncertain power demand ( the noises ) while minimizing a production cost over a certain time period .",
    "we here consider discrete and finite time horizon .",
    "we are hence looking for feedback functions which , at each time step and for each possible observation of the system , provide a decision to be taken .",
    "we consider the laws of the random variables involved to be continuous ; consequently this is an infinite - dimensional optimization problem . in most situations ,",
    "no analytic solution can be found and one has to consider approximations of the original problem to be able to solve it numerically .    in the manner of the monte carlo approach for computing the expectation of a random variable",
    ", we seek a tractable approximation of the probabilistic structure of the original problem based on samples of some noise scenarios .",
    "a scenario consists in a sample of the noises along the whole time horizon .",
    "note that such a resolution method is stochastic in itself .",
    "indeed , the solution given by such a method is a random variable in the sense that it depends on the scenarios sampled and used in the resolution .",
    "therefore , when studying the performance of an algorithm based on such an approach , a variance term naturally appears , representing the sensitivity of the solution regarding these scenarios .",
    "this variance term is added to the squared bias term which arises from the necessity to approximate the solution in feedback by a function in a predefined space .",
    "note that it is also present in the performance evaluation of deterministic techniques , like dynamic programming  @xcite for instance .    for stochastic optimal control problems ,",
    "it is common to represent the diffusion of `` likely futures '' using a scenario tree structure , leading to so - called multi - stage stochastic programs .",
    "this kind of representation goes back to  @xcite and has been widely studied within the stochastic programming community  ( see * ? ? ?",
    "* ; * ? ? ?",
    "* for a broad overview of this approach ) .",
    "this methodology consists in discretizing the probabilistic structure of the problem , then rewriting the constraints and objective function of the original problem on this discrete structure and finally solving it using a well - suited mathematical programming technique .",
    "in other words , the problem is solved for a particular sample of the random variables ( a scenario tree ) and the solution is hence a random variable in itself .",
    "we have to keep this fact in mind while evaluating the error .",
    "the main interest of such a methodology is that it leads back to a deterministic problem , on which we can apply classical tools of numerical optimization  @xcite . for instance , one may then try to solve large - scale problems using decomposition techniques  ( see * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "despite the benefits of this methodology , it has been already observed that , in order to obtain a given precision , the number of scenarios needed to build the scenario tree has to grow exponentially with the time horizon of the problem .",
    "one of the aims of this paper is to highlight and to quantify this practical observation on an example .",
    "thus , we start in section  [ sec : mathform ] by introducing the mean squared error , that is the distance between the strategy obtained using scenario trees and the ( supposedly unique ) optimal strategy .",
    "this is the indicator we use to estimate the performance of the method .",
    "then , in section  [ sec : scenariotrees ] , we study on a numerical example the relation linking the mean squared error to the number of scenarios used for the discretization .",
    "@xcite obtains similar conclusions by working on the performance regarding the objective function and using large deviations tools .",
    "we show that this negative observation is to be attributed to the scenario tree approach rather than to be considered as a feature of the original problem .",
    "indeed , when using the particle method  @xcite , in section  [ sec : particles ] on the same example , we show that the number of scenarios needed to obtain a given precision does not grow when the time horizon gets longer .",
    "this methodology , which mixes ideas from stochastic programming and dynamic programming , is a variational technique which consists in writing the optimality conditions of the optimization problem first , and then solving them using sampling techniques .",
    "this is a gradient - like method that builds an adaptive mesh over the state space as gradient iterations progress towards the solution .",
    "this mesh aims at discretizing the space in the regions mostly visited by the state vector at the optimum .",
    "according to the results obtained on the example we present here , the algorithm seems to be well - suited for multi - stage problems .",
    "however , with this approach , it seems that the difficulties arising from the dimension of the state space remain ; this point is discussed in section  [ sec : dimension ] .",
    "consider a controlled dynamic system , affected by random variables called noises .",
    "we aim to find strategies that minimize some expected cost over a finite time horizon , while satisfying a number of constraints .",
    "we suppose that the problem has a unique solution and propose to compare the approximate strategies using the mean squared error ( mse ) .",
    "we denote by  @xmath1 the finite time horizon of the problem and consider discrete time  @xmath2 .",
    "let @xmath3 be a probability space .",
    "three kinds of random variables on this space are involved in the problem ) . ] :    * the state can only be considered as the state variable when assumption  [ hyp : indpdt ] is made later on in   [ ssec : mse ] . until then , our use of this terminology is somewhat abusive . ]",
    "@xmath4 , the values of which lie in a finite - dimensional vector space  @xmath5 ; * the control  @xmath6 , the values of which lie in a finite - dimensional vector space  @xmath7 ; * the noise  @xmath8 , the values of which lie in a finite - dimensional vector space  @xmath9 , equipped with the  @xmath10-field  @xmath11 and the probability  @xmath12 , which is the transport of the probability  @xmath13 by  @xmath14 .",
    "since some of the numerical methods we use in the following are gradient - based , it is natural to assume that the state and control lie in a hilbert space .",
    "hence we assume all three random variables are in  @xmath15 .",
    "the noise variable  @xmath14 is given , i.e. its probability law is known , while the state and control variables are optimization variables .",
    "we here suppose that the information structure has perfect memory : at each time step  @xmath16 , the noise  @xmath17 is observed and kept in memory , in such a way that the decision at time  @xmath16 is based on the knowledge of  @xmath18 . hence we introduce the @xmath10-field  @xmath19 that represents the information available at time  @xmath16 , the associated filtration  @xmath20 , and require the control at time  @xmath16 to be measurable with respect to  @xmath21 .",
    "this constraint will be written :  @xmath22 .    at time",
    "@xmath23 , we assume that the value of the state is the realization of some random variable  @xmath24 . then , at each time step @xmath16 , based on the available information , a decision  @xmath25 is taken , a cost  @xmath26 is incurred and the state evolves according to  @xmath27 . at the end of the time period , a final cost  @xmath28 is incurred .",
    "the aim is to find a pair  @xmath29 that minimizes the expected sum of the costs over the time horizon while satisfying the dynamics and measurability constraints .",
    "mathematically speaking , the problem we consider may be formulated as follows :    [ eqn : p ] @xmath30    equations   and describe the dynamics of the state variable and are  @xmath13-almost sure relations .",
    "equation   states the information structure of the problem : it is the measurability constraint that forces the decision to be a function of all the past noises , and to be independent of future noise values .",
    "hence we refer to this relation as the non - anticipativity constraint .",
    "now suppose that problem   has a unique solution denoted by  @xmath31 .",
    "suppose that we also have a numerical method , based on a scenario discretization , that gives us an approximate solution of   that we denote by  @xmath32 .",
    "since this approximate solution given by the numerical method depends on , say ,  @xmath33 samples , the pair  @xmath32 lies in the probability space associated with these samples , that is  @xmath34 .",
    "for instance , scenario tree - based methods compute values of the optimal decision for a finite number of state values that depend on the samples used for building the tree structure .",
    "we make the following assumption :    [ hyp : indpdt ] random variables  @xmath35 are independent .    under this assumption ,",
    "the problem lies in the framework of dynamic programming  ( dp ) .",
    "in particular , we know that optimal controls can be expressed as feedback functions depending only on the state variable  @xmath36 .",
    "in other words , there exists some sequence of functions  @xmath37 such that  @xmath38 .    in order to be able to compare the optimal and approximate solutions",
    ", we need to produce a solution of the same nature as the optimal solution , that is a feedback function such as  @xmath37 out of  @xmath32 .",
    "we hence suppose that we have such an interpolation / regression operator that gives us a feedback function  @xmath39 out of the approximate solution  @xmath32 .",
    "more details on the interpolation / regression operators we use are given in ",
    "[ ssec : treescasestudy ] .",
    "note that the approximate strategy  @xmath40 is a random variable that lies in the samples probability space introduced earlier , that is  @xmath34 .",
    "we are interested in evaluating the efficiency of our numerical method for solving problem   by computing the distance between the approximate strategy @xmath41 and the optimal one @xmath37 .",
    "since those functions take values over the state space , we need to define some measure on this space . in our context , the measure that seems the most natural is the one corresponding to the density of the optimal state  @xmath42 . indeed , using this measure , we allocate more weight to regions which are often `` visited '' by the optimal state and we do not take into account decisions in regions that are never `` visited '' by the optimal state , since those decisions are unlikely to be used in practice .",
    "we denote by  @xmath43 the density of the optimal state at time  @xmath16 .    we can now introduce the mse associated with strategy  @xmath41 , which is our performance indicator in this study : @xmath44 note that the expectation in the mse is taken over all possible samples ; in other words , it lies on the samples probability space  @xmath34 .",
    "the mse is thus the expected distance between the optimal strategy and the approximate strategy .",
    "recall that this expectation is taken with respect to the drawings used by the algorithm to produce strategy  @xmath41 .",
    "it is common to decompose the mse using the so - called variance and squared bias . for this purpose",
    ", we introduce the expectation  @xmath45 of the approximate feedback function  @xmath41 .",
    "then @xmath46 the squared bias is the square of the distance between the optimal strategy and the expected approximate strategy , while the variance is the expected square of the distance between the approximate strategy and the expected approximate strategy .",
    "both are real values .",
    "another relevant choice as a performance indicator would have been the following :    1 .",
    "having the approximate strategy  @xmath41 , build the``true '' state and control obtained while simulating this strategy , that is the pair  @xmath47 that satisfies the dynamics   and  : @xmath48 2 .   since the optimal decision  @xmath49 is a random variable on  @xmath3 and the decision",
    "@xmath50 is a random variable that lies on the tensor product of  @xmath3 and the samples probability space  @xmath34 , compute the expectation : @xmath51 where the expectation lies on the tensor product of the probability spaces  @xmath3 and  @xmath34 .",
    "note that this quantity may also be written  @xmath52 , where the expectation now lies on the samples probability space only .",
    "this quantity is another relevant performance indicator since it is positive and it equals zero if and only if  @xmath50 equals  @xmath49 almost surely .",
    "moreover , we note that the choice of  @xmath50 for evaluating the performance of the numerical method is the one made by  @xcite , even though the comparison is performed using the objective function rather than the strategies .      for computing the squared bias and the variance as defined in equation  , we must face two main issues .    1 .",
    "at each time step  @xmath16 , we must compute integrals over the whole state space with respect to the density  @xmath43 . in the following example",
    ", we are able to explicitly compute the optimal control strategy . we can then numerically integrate the fokker - planck equation to derive the density of the optimal state on a sufficiently dense grid and perform the integration by quadrature techniques .",
    "however , this technique suffers for the same _ curse of dimensionality _ as dp .",
    "for this reason we choose to perform the integration using a quasi - monte carlo technique .",
    "this sampling method aims at distributing the samples associated with density  @xmath43 equally over the state space using so - called low - discrepancy quasi - random sequences .",
    "this provides a very efficient convergence speed for the numerical computation of expectations .",
    "there exist numerous methods of quasi - monte carlo sampling  ( see * ? ? ?",
    "* for a survey of these methods ) .",
    "2 .   we must be able to compute the expectation in the variance term .",
    "this expectation is taken over the samples used during the algorithm to produce the approximate strategy , e.g. the scenarios in the case of a scenario tree technique .",
    "we approximate this expectation by monte carlo , by performing the experiment a great number of times independently one from another . in our case ,  @xmath53 experiments were enough to precisely evaluate the variance .",
    "we are now able to estimate the efficiency of numerical methods using the mse .",
    "we point out the relation between the error and the parameters of the methods , namely the number of scenarios used to discretize randomness .",
    "in the context of discrete time and finite horizon stochastic optimal control problems , a popular and widely used resolution technique consists in approximating the information structure of problem   using scenario trees .",
    "this methodology has been widely studied by the stochastic programming community .",
    "we do not detail this method and refer to  @xcite for a more in depth presentation of stochastic programming .",
    "because of the measurability constraints in problem  , and since there is no reason for the noise probability densities to have finite support , decision variables  @xmath54 and  @xmath55 are in general infinite - dimensional . hence , except for some very particular cases where an explicit solution can be found , solving the underlying optimization problem directly is intractable .",
    "scenario trees provide a way to approximate filtrations using noise samples to produce finite support approximations .",
    "let  @xmath56 be the set of all nodes in the tree ,  @xmath57 be the set of the root nodes and  @xmath58 the set of the leaves . building a scenario tree consists in defining the following functions :    * the time function  @xmath59 which , with every node , associates the corresponding time step and the corresponding multi - application  @xmath60 which , to every time step  @xmath61 , associates the set of all nodes at time  @xmath16 ; * the function  @xmath62 which , with each non - root node , associates the preceding node in the tree ; * the weight function  @xmath63 $ ] which , with every node in the tree , associates the probability to go through that node ( the sum of all  @xmath64 , with @xmath65 is equal to @xmath66 , for each @xmath16 ) ; * the multi - application  @xmath67 which , with every node  @xmath68 in the tree , associates the set of its successors ( we impose the convention that  @xmath69 ) ; * the function  @xmath70 which , with each node  @xmath68 , associates the whole sub - tree starting from  @xmath68 : @xmath71 .",
    "we consider a regularly branching tree , i.e. with a constant branching factor denoted by  @xmath72 , so that  @xmath73 , for every node @xmath74 . at time",
    "@xmath75 , we draw a  @xmath72-sample of the random variable  @xmath24 , that we denote by  @xmath76 . for each root node",
    "@xmath68 , we draw at time  @xmath77 a  @xmath72-sample of the random variable  @xmath78 knowing the value of the preceding noises , that is  @xmath24 . because of assumption  [ hyp : indpdt ] , this is not needed here .",
    "] , that we denote by  @xmath79 .",
    "samples of the random variable  @xmath78 are drawn independently root node per root node .",
    "this procedure continues until final time  @xmath80 , so that we have  @xmath81 leaves to the tree .",
    "hence one can note that this can reveal a heavy procedure when  @xmath1 becomes large , since we need to draw  @xmath81 samples of  @xmath82 .    with this material we can now define a discretized version of problem  :    [ eqn : pdiscret ] @xmath83    the expectation in the objective function   has been replaced in   by a discrete weighted sum of costs on the tree nodes .",
    "equations   and   correspond to equations   and  . the only constraint that seems to be missing is equation  .",
    "actually , it is now reflected in the structure of the tree . indeed ,",
    "starting from any node in the tree , there is only one possibility for going back to the root ( we know exactly the values of all past noises ) , but there is a whole sub - tree that goes to the set of leaves , corresponding to the final time step ( we only know the laws of future noises ) . in other words ,",
    "the non - anticipativity constraint is coded in the structure of the tree .    in most cases ,",
    "the scenario tree is not drawn directly .",
    "one draws a number of scenarios independently from one another , and then one builds a tree structure .",
    "building such a tree in an efficient way ( regarding the implied discretization error ) is a challenging task .",
    "there exists a large literature on the way one can build scenario trees in a reasonable way  @xcite , as well as on stability of the underlying optimization problem regarding this discretization  @xcite .",
    "we will not focus on this point here .",
    "as it has already been mentioned , we suppose that the tree has been built using a branching factor  @xmath72 , which does not depend on time , leading to  @xmath81 leaves .",
    "recall that this procedure requires the drawing of  @xmath84 different scenarios .",
    "we apply this methodology to a simple instance where problems   and   can be solved analytically .",
    "then , we apply the methodology described in  [ ssec : compmse ] in order to compute the mse and to point out its relation with the number of scenarios  @xmath33 used to discretize the original problem .",
    "let  @xmath85 be some positive real number , the problem we consider is the following :    [ eqn : example ] @xmath86    the state and control variables lie in  @xmath87 .",
    "noise variables  @xmath24 , @xmath88 , @xmath82 are i.i.d .",
    "random variables with uniform law on  @xmath89 $ ] .",
    "one easily shows that the optimal control for problem   reads  @xmath38 with : @xmath90    we now solve the problem on the tree . on each node",
    "@xmath68 , one has a noise sample  @xmath91 and solving the problem on the tree leads to values  @xmath92 and  @xmath93 for the state and control , respectively .",
    "one easily shows that : @xmath94 we now need to build a feedback function from these state and control values .",
    "this can be performed using a interpolation / regression operator .",
    "we here use the simplest one , which is the nearest neighbour interpolation operator  ( see * ? ? ?",
    "* , for a rigorous study of this operator and its possible implementations ) .",
    "at each time step  @xmath16 , we build the voronoi diagram of the set of state values  @xmath95 .",
    "we denote by  @xmath96 the cell for which  @xmath92 is the center .",
    "this cell is a random variable in itself , because it depends on the random variables drawn to build the scenario tree . on this cell ,",
    "the feedback function will be constant , equal to  @xmath93 .",
    "thus we obtain the following strategy at time t : @xmath97    the fact that the voronoi cells  @xmath96 are random variables , depending on the scenarios , makes the theoretical study of the error associated with strategy  @xmath41 intricate . indeed , in order to compute the expected approximate strategy  @xmath45 , as well as to evaluate the variance term in equation",
    ", we have to compute expectations over all possible scenario drawings , leading through equation   to expectations over all possible voronoi cells .",
    "this is generally a challenging task .",
    "this is the reason why we here appeal to numerical experiments to study the behaviour of the error with respect to the number of scenarios .",
    "the results for this approach are presented in figure  [ fig : stratexampletrees ] for  @xmath98 and a branching factor of  @xmath99 .",
    "the approximate strategy  @xmath100 for the first time step is hence a piecewise constant function with  @xmath101 pieces . on the right - hand side of figure  [ fig : stratexampletrees ] , we draw  @xmath102 samples of this strategy ( dashed curves ) to emphasize that the scenario - tree method is stochastic : each sample  @xmath100 is derived from a different scenario tree .",
    "we also draw the averaged strategy  @xmath103 over the  @xmath53 scenarios ( dotted curve ) .",
    "one can remark that even if sample strategies are not continuous functions , the average strategy seems to be continuous , even smooth . on the left - hand side of figure  [ fig : stratexampletrees ] , we draw the exact strategy ( solid curve ) obtained using equation   and the same average approximate strategy as on the right - hand side ( dotted curve )",
    ".    we can observe both the variance and the bias terms of the mse on figure  [ fig : stratexampletrees ] : the variance term is the average @xmath0-distance between the dashed curves  ( of course if there were  @xmath53 of them ) and the dotted curve on the right hand - side , whereas the bias term is the @xmath0-distance between the solid curve and the dotted curve on the left hand - side . from equation  ,",
    "the density of the optimal state , under which we compute the @xmath0-distances cited above , equals the density of  @xmath24 , which follows a uniform law on  @xmath89 $ ] .",
    "[ cols=\"^,^ \" , ]     note that the squared bias , on the left - hand side , now prevails over the variance term , on the right - hand side .",
    "a careful inspection of the latter shows that the term leads experimentally to a convergence that is slightly less than  @xmath104 .",
    "the variance itself also seems to decrease at a lower rate than in the one - dimensional case .",
    "both of these observations indicate that the performance of the method could benefit from a better regression operator than the nearest neighbour that we used here .",
    "note that , for computational time reasons , we can not produce such experimental results for higher dimensions .",
    "hence we are not able to make a thorough study of the relation between the dimension of the state space and the convergence rate of both the squared bias and the variance .",
    "on the other hand , when dealing with large state space dimensions , a clever idea is to make use of decomposition schemes in order to replace the solving of a high dimensional problem by the iterative solving of several smaller problems .",
    "this is indeed a common and powerful technique when using scenario trees  ( see * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "3 ) . both the improvement of the regression operator and the use of a decomposition scheme are the subject of ongoing research .",
    "we presented a numerical study concerning the comparison of two scenario - based approaches for solving stochastic optimal control problems with a discrete finite horizon . in the first section",
    ", we introduced the performance indicator that was used to compare both methods , namely the mean squared error ( mse ) .",
    "the first approach we considered was scenario tree modeling .",
    "we observed that the number of scenarios needed to obtain a given accuracy grew exponentially with the time horizon , making the implementation for multi - stage problems hardly tractable .",
    "the second approach we considered was particle methods . in this case",
    ", we observed that the associated mse does not depend on time .",
    "thus , this recent approach seems to be well - suited for multi - stage problems .",
    "unfortunately , it seems that its performance deteriorates rapidly when the dimension of the state space increases .",
    "however , this method is quite new and as such has received little attention .",
    "its implementation and hence performance would certainly benefit from computational studies .",
    "future works will be concerned with this topic .",
    "carpentier p , cohen g , culioli jc ( 1995 ) stochastic optimal control and decomposition - coordination methods . in : durier",
    "r , michelot c ( eds ) recent developments in optimization .",
    "lecture notes in economics and mathematical systems , 429 , springer verlag , berlin , pp 72103"
  ],
  "abstract_text": [
    "<S> in this paper , we compare the performance of two scenario - based numerical methods to solve stochastic optimal control problems : scenario trees and particles . </S>",
    "<S> the problem consists in finding strategies to control a dynamical system perturbed by exogenous noises so as to minimize some expected cost along a discrete and finite time horizon . </S>",
    "<S> we introduce the mean squared error ( mse ) which is the expected @xmath0-distance between the strategy given by the algorithm and the optimal strategy , as a performance indicator for the two models . </S>",
    "<S> we study the behaviour of the mse with respect to the number of scenarios used for discretization . </S>",
    "<S> the first model , widely studied in the stochastic programming community , consists in approximating the noise diffusion using a scenario tree representation . on a numerical example </S>",
    "<S> , we observe that the number of scenarios needed to obtain a given precision grows exponentially with the time horizon . in that sense , </S>",
    "<S> our conclusion on scenario trees is equivalent to the one in the work by  @xcite and has been widely noticed by practitioners . </S>",
    "<S> however , in the second part , we show using the same example that , by mixing stochastic programming and dynamic programming ideas , the particle method described by  @xcite copes with this numerical difficulty : the number of scenarios needed to obtain a given precision now does not depend on the time horizon . </S>",
    "<S> unfortunately , we also observe that serious obstacles still arise from the system state space dimension . </S>"
  ]
}