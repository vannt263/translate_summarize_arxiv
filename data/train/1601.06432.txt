{
  "article_text": [
    "let @xmath4 and @xmath5 be independent random variables .",
    "we are interested in estimating the probability density function @xmath6 of @xmath4 . however ,",
    "in real world , due to measurement error @xmath5 with _ known _ density @xmath7 , we have only @xmath0 independent and identically distributed observations @xmath8 having the same density @xmath9 as that of @xmath10 in the additive measurement error model .",
    "the data contaminated with additive measurement errors are common in application of statistics .",
    "a simple example is the round - off errors with known uninform distribution on @xmath11 $ ] for some integer @xmath12 . usually in this case",
    "the errors are ignored if @xmath12 is large . however , in some situations , ignoring the measurement errors can result in serious bias in statistical inference .    in the additive measurement error model",
    ", @xmath9 is the convolution of @xmath6 and @xmath7 , i.e. , @xmath13 so the contaminated data @xmath8 is a sample from a compound distribution @xmath9 or a mixture of the translated @xmath14 with unknown mixing density @xmath15 . based on the contaminated data a nonparametric estimator @xmath16 , also known as deconvolution kernel density estimator , of @xmath6 ( see * ? ? ? * ; * ? ? ? * ; * ? ? ? * for examples ) is obtained by the inverse fourier transform with the aid of the kernel density estimation .",
    "briefly , let @xmath17 be a kernel density estimate of @xmath9 based on @xmath8 .",
    "let @xmath18 denote the fourier transform of @xmath19 .",
    "since @xmath20 , one can estimate @xmath21 by @xmath22 and obtain an @xmath16 by inverse fourier transform .",
    "the properties of the above deconvolution method have been extensively studied by , among others , @xcite . @xcite",
    "considered the kernel density deconvolution with heteroscedastic errors , i.e. , @xmath23 s have different densities @xmath24 .",
    "the optimal rates of convergence for nonparametric deconvolution are extremely slow especially for supersmooth error distributions including normal distribution ( see * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* for example ) .",
    "specifically , if errors have a super - smooth error distribution such as normal distribution and @xmath6 satisfies some smooth conditions but _ without assuming a compact support and a positive lower bound _ , then the optimal convergence rate of the pointwise mean squared error for a nonparametric estimator of @xmath6 based on the contaminated data @xmath8 is @xmath25 for some @xmath26 which can be attained by a kernel density estimator @xmath16 .",
    "although it has been shown by @xcite that nonparametric deconvolution with normal errors can be as good as the kernel density estimate based on uncontaminated data if the noise level is not too high , an accelerated denconvolution is still much desirable .",
    "recently @xcite proposed an improved kernel method upon @xmath16 to speed up the convergence assisted by a `` close to being correct '' parametric guess of @xmath6 .    without measurement errors the kernel density",
    "@xmath27 has expectation @xmath28 .",
    "so @xmath27 is an `` unbiased '' estimator of the _ convolution _ of @xmath6 and the scaled kernel @xmath29 .",
    "no matter how the kernel @xmath30 and the bandwidth @xmath31 are chosen , there is always trade - off between the bias and the variance . in this context",
    ", @xcite proposed a new nonparametric maximum likelihod estimate for a density which is assumed to be smooth function with a positive lower bound on a known compact support .",
    "this method approximately parametrizes the underlying density @xmath6 , after truncation and transformation to @xmath32 $ ] , by the bernstein type polynomials which is actual a mixture of beta densities @xmath33 ( @xmath34 ) with shape parameters @xmath35 , i.e. , @xmath36 .",
    "@xcite suggested a change - point detection method to choose an optimal degree @xmath37 .",
    "it has been shown that this new estimate enjoys an almost parametric rate of convergence in mean integrated squared error .",
    "therefore under the same assumptions an accelerated density deconvolution by using the bernstein polynomial density estimation can be expected .",
    "the assumption of a known error density @xmath7 was discussed by @xcite .",
    "we will show that in the additive measurement error model the convolution density @xmath9 can be approximated by a mixture model of known components but unknown mixture proportions .",
    "consequently , we can deconvolute for @xmath6 using an approximate maximum likelihood method .",
    "the resulting density estimate could attain a much better convergence rate .",
    "this method is totally different from those in the literature . it does not use the fourier transforms and can be viewed as a nearly parametric approach to the nonparametric density deconvolution . like any finite mixture model",
    ", this approximate model is different from the classical parametric models because the number of the parameters , the degree of the polynomial , is unknown .",
    "assume that the density @xmath6 is continuous on its support @xmath32 $ ] .",
    "then we have @xcite @xmath38 where @xmath39 @xmath40 . the best degree of approximation of @xmath6 by @xmath41 is @xmath42 no matter how smooth @xmath6 is .",
    "let @xmath43 $ ] be the class of functions which have @xmath44th continuous derivative @xmath45 on @xmath32 $ ] .",
    "we denote the @xmath37-simplex by @xmath46 the bernstein polynomial model is supported by the following mathematical result which is a consequence of theorem 1 of @xcite .",
    "[ thm : approx of poly w pos coeff ] if density @xmath47 $ ] and @xmath48 on its support @xmath32 $ ] , then there exists a sequence of bernstein type polynomials @xmath49 with @xmath50 , such that @xmath51 where @xmath52 depends on @xmath44 , @xmath53 , @xmath54 , and @xmath55 @xmath56 only .",
    "the best approximation is unique@xcite .",
    "so we have a parametric approximate model for an arbitrary density @xmath47 $ ] @xmath57 with positive lower bound on support @xmath32 $ ] .",
    "thus the density @xmath9 can be approximated by @xmath58 where @xmath59 @xmath40 .",
    "therefore the convolution @xmath9 is approximately parameterized as a mixture of @xmath60 @xmath40 .      for a given @xmath37 , the bernstein likelihood of @xmath8",
    "is defined as @xmath61 so the bernstein loglikelihood is @xmath62 the maximizer @xmath63 of @xmath64 is called the maximum bernstein likelihood estimator of @xmath65 , the unknown mixture proportions .",
    "then we obtain an estimate of @xmath6 , @xmath66 , for an optimal degree @xmath37 .",
    "the consequent density estimator @xmath67 is an approximately parametric density estimator .",
    "so it is not surprising that @xmath68 performs much better than a totally nonparametric density estimator such as kernel density estimators which do not take advantage of the conditions imposed on @xmath6 in this paper .",
    "the expectation - maximization algorithm @xcite applies to find @xmath69 and leads to the following simple iteration : @xmath70 @xcite proved the convergence of @xmath71 to @xmath63 as @xmath72 . if @xmath6 is continuous on a support @xmath73 different from @xmath74 $ ] and we can find a finite interval @xmath75\\subset s$ ] such that @xmath76\\subset [ a , b]$ ] and @xmath77 , then we let @xmath78 , where @xmath79 and @xmath80 . the densities of @xmath81 and @xmath82 are @xmath83 and @xmath84 respectively .",
    "let @xmath85 be an estimate of @xmath86 based on @xmath87 s .",
    "then we can estimate @xmath6 by @xmath88 .",
    "since the error distribution is known , we can choose @xmath89 by properly extending @xmath90 . because @xmath91 , we can choose @xmath92 , for some @xmath93 , where @xmath94 is the standard deviation of the error @xmath5 .      denote the sample mean and variance of @xmath95 , respectively , by @xmath96 and @xmath97 .",
    "since @xmath98 and @xmath99 are known , we can estimate @xmath100 and @xmath101 by @xmath102 and @xmath103 , respectively . as in @xcite",
    "we can estimate the lower bound @xmath104 for @xmath37 by @xmath105 based on @xmath106 we choose an appropriate @xmath107 and a large positive integer @xmath108 to form @xmath109 .",
    "denote @xmath110 @xmath111 . because @xmath112 is nested in @xmath113 @xcite ,",
    "so is @xmath114 in @xmath115 .",
    "thus @xmath116 @xmath111 are nonnegative . from some real data analysis and extensive simulation study",
    "we learned that for large @xmath108 the optimal degree @xmath117 corresponds such a change - point @xmath118 that @xmath119 have smaller mean and variance than @xmath120 .",
    "we can treat @xmath121 as they were exponential observations .",
    "the change - point @xmath118 can be estimated ( see  14 of * ? ? ?",
    "* ) by @xmath122 , where @xmath123 having obtained @xmath124 , we can use @xmath125 @xmath126 as the initial guess for the iteration ( [ eq : em iteration for p ] ) for @xmath127 .",
    "we will show our asymptotic results assuming @xmath128 as an approximate model instead of an exact parametric model . for a given @xmath129",
    ", we define @xmath130 it is clear that @xmath131 , where the square matrix @xmath132_{\\{0\\le i , j\\le m\\}}$ ] has entries @xmath133 we need the following assumptions for the asymptotic properties of @xmath68 which will be proved in the appendix :    [ a1 ] @xmath134 $ ] for some @xmath135 , and @xmath136 on its support @xmath32 $ ] .    [ a2 ] @xmath137 dx\\le c$ ] for all @xmath50 and @xmath138 .",
    "the generalized normal distribution has density @xmath139 @xmath140 where @xmath141 , and @xmath142 is the gamma function .",
    "we have the following result .",
    "[ remark 1 ] the generalized normal density @xmath143 satisfies assumption [ a2 ] .",
    "the generalized normal distribution has mean zero and variance @xmath144 .",
    "special cases are the supper smooth normal distribution n@xmath145 with @xmath146 and the ordinary smooth laplace distribution l@xmath147 with mean @xmath148 , variance @xmath149 , and @xmath150 . as @xmath151",
    ", @xmath152 converges to the uniform @xmath153 .",
    "[ thm : convergence rate for contaminated data ] under assumptions [ a1 ] and [ a2 ] , as @xmath154 , with probability one the maximum value of @xmath64 with @xmath155 is attained at @xmath63 in the interior of @xmath156 , where @xmath157 and @xmath158 makes @xmath159 the unique best approximation and the mean weighted integrated squared error of @xmath160 satisfies @xmath161    [ remark 2 ] if @xmath162 , the dirac delta , which satisfies assumption [ a2 ] , then under assumption [ a1 ] , with @xmath155 , ( [ eq : convergence rate for contaminated data ] ) is true for @xmath163 and @xmath164 .    as a consequence of theorem [ thm : convergence rate for contaminated data ] and a necessary condition for maximum likelihood estimator @xmath165 ( see ( 3@xmath1668 ) on page 209 of",
    "* ) we have the following much faster convergence rate of @xmath68 than that of @xmath16 .",
    "[ thm : convergence rate for contaminated data in mise ] under the conditions of theorem [ thm : convergence rate for contaminated data ] with @xmath3 the mean integrated squared error of @xmath68 satisfies @xmath167",
    "in order to exam the finite sample performance of the proposed method , we conduct simution studies to compare the estimator @xmath68 with the _ surreal _ parametric deconvolution @xmath168 , the fourier transform estimator @xmath16 , and the kernel density @xmath169 based on the uncontaminated simulated data @xmath170 . as in @xcite",
    "we generated samples @xmath170 of size @xmath171 from two distributions : ( i ) unimodal n@xmath172 truncated by @xmath75=[-7,7]$ ] , and ( ii ) bimodal @xmath173n@xmath174n@xmath175 truncated by @xmath75=[-7,7]$ ] .",
    "the errors @xmath5 were generated from normal n@xmath176 and l@xmath177 , with @xmath178 .",
    "only when @xmath179 , compared with the standard deviation @xmath180 of @xmath4 , is `` small '' one can obtain an applicable estimate of @xmath6 even for parametric deconvolution .",
    "for instance , if both @xmath4 and @xmath5 are normal , then the maximum likelihood estimates of @xmath100 and @xmath101 are , respectively , @xmath102 and @xmath181 , where @xmath96 and @xmath97 are the sample mean and sample variance of @xmath95",
    ". if @xmath182 and @xmath0 is not large , then @xmath183 could also be zero because @xmath184 $ ] is not small .",
    "so the parametric deconvolution @xmath185 may be degenerate because @xmath183 could be zero even if @xmath186 . in the simulation shown in table [ tbl-1 ]",
    ", @xmath185 is the parametric estimate of the density of n@xmath187 and @xmath188 n@xmath189n@xmath190 with known variances @xmath149 , @xmath191 and @xmath192 but unknown @xmath193 and @xmath194 .",
    "the rate of convergence in mean integrated squared error of such parametric estimator is @xmath195 .",
    "the ( mixture ) normal density @xmath6 has continuous @xmath196-th derivative @xmath197 for all @xmath196 . in real world problem",
    ", a random variable may just have an approximate normal distribution supported by the central limit theorem and some goodness - of - fit test . in another simulation study presented by table [ tbl-2 ] , we generated sample @xmath170 from a `` nearly normal '' distribution nn@xmath198 , @xmath199 , which is the distribution of the sample mean of @xmath200 from uniform(0 , 1 ) .",
    "clearly nn@xmath201 n@xmath202 for large @xmath12 .",
    "let @xmath203 be the density of nn@xmath198 .",
    "if @xmath204 , then @xmath205 $ ] but @xmath206 $ ] .",
    "let @xmath207 denote the probability that the shapiro - test based on a sample of size @xmath0 rejects the normality of @xmath208 with significance level @xmath209 .",
    "based on 5,000 monte carlo runs @xmath207 is estimated to be @xmath210 , @xmath211 , and @xmath212 , respectively , for @xmath213 , and @xmath214 . the parametric estimate @xmath168 in this simulation is based on the normal model n@xmath187 with known @xmath215 .",
    "the errors @xmath216 were generated from n@xmath176 and l@xmath217 , where @xmath218 and @xmath199 .",
    "so @xmath219 .",
    "although @xmath220 $ ] ( @xmath221 ) and the condition @xmath3 of theorem [ thm : convergence rate for contaminated data in mise ] is not fulfilled , the proposed estimator @xmath68 still performs better than @xmath16 in such bad scenario . in this case",
    "@xmath68 performs worse than @xmath169 because the latter is based on uncontaminated data and has a rate of @xmath222 .",
    "we used the r package @xcite which implements the methods of @xcite and @xcite for calculating @xmath16 .",
    "the `` dboot2 '' method was used for choosing an optimal bandwidth @xmath31 ( see * ? ? ?",
    "* ; * ? ? ?",
    "* for details ) .    for an estimator @xmath223 ,",
    "after @xmath224 monte carlo runs , we obtained estimates @xmath225 .",
    "we then approximate the point - wise mean squared error at @xmath226 $ ] , @xmath227 by @xmath228 ^ 2 , $ ] where @xmath229 and @xmath230 are the sample mean and the sample variance of @xmath231 . in order to compare in details the proposed estimator @xmath68 with @xmath16 , @xmath168 and @xmath169",
    ", we plot the point - wise mean squared error in figure [ fig : pmse n=200 sig0=0.6 ] from which we see that @xmath68 almost uniformly outperforms @xmath16 for both unimodal and bimodal @xmath6 .",
    "we also see that if @xmath6 is unimodal and smooth enough so that @xmath196 is large as in theorem [ thm : convergence rate for contaminated data in mise ] then @xmath68 even almost uniformly outperforms @xmath169 which is based on uncontaminated data .     the simulated point - wise mse s of the parametric estimator @xmath168(dashed ) , the proposed estimator @xmath68(solid ) , the inverse fourier estimator @xmath16(dotted ) , and the kernel density estimator based on the simulated uncontaminated data @xmath169(dotdash ) , at @xmath232 , @xmath233 , @xmath234 .",
    "the sample size is @xmath235 .",
    "the truncation interval is @xmath75=[-7,7]$ ] . in the parametric models all the variances",
    "are assumed to be known .",
    "upper panels : the error distribution is n@xmath176 with @xmath237 ; lower panels : the error distribution is laplace l@xmath217 with @xmath237 . ,",
    "width=576 ]    the mean integrated squared error @xmath238 ^ 2dx$ ] is approximated by @xmath239 where @xmath240 , @xmath241 @xmath242 , and @xmath234 .",
    "so @xmath243 can be estimated by @xmath244    tables [ tbl-1 ] and [ tbl-2 ] show that the proposed @xmath68 is much better than the fourier transform method @xmath16 . in some cases , especially when @xmath179 is much smaller than @xmath180 , @xmath68 is even as triple efficient as @xmath169 in terms of the square root of the mean integrated squared error .",
    "although the simulation setup prefers the parametric methods the results show that in most cases the proposed approach has mean integrated squared error that leans toward the surreal parametric one . moreover the proposed method performs better than the kernel estimate based on the uncontaminated data for unimodal model or if the magnitude of error variance is not too large . because of the involvement of @xmath169 in the comparison it is unnecessary to include any other kernel methods improving upon @xmath16 in the simulation .",
    "the framingham data is from a study on coronary heart disease @xcite and consist of measurements of systolic blood pressure in 1,615 males , @xmath245 taken at an examination and @xmath246 at an 8-year follow - up examination after the first . at the @xmath247th examination , the systolic blood pressure was measured twice , @xmath248 and @xmath249 ( @xmath250 ) , for each individual .",
    "we used the data in the r package @xcite which contain four variables , @xmath251 ( @xmath252 ) .",
    "as in @xcite , the error is assumed to be @xmath253 with @xmath254 8369 estimated using the systolic blood pressures @xmath255 at the first examination .",
    "the density of the systolic blood pressure @xmath256 at the second examination is to be deconvolved .",
    "we truncate the distribution by @xmath75=[80 , 270]$ ] and selected the optimal degree @xmath257 from @xmath258 .",
    "figure [ fig : framingham - data ] shows that the density deconvolutions @xmath68 , @xmath16 , and @xmath259 ignoring measurement errors are quite different .",
    "upper left panel : the increments of loglikelihood vs the model degree @xmath260 ; upper right panel : the likelihood ratio of the change point , @xmath261 and @xmath262 ; lower panel : density deconvolution of sbp2 based on framingham data , @xmath263 is the inverse fourier transform estimate(solid ) ; @xmath264 is the proposed estimate using bernstein polynomial with @xmath265(dashed ) ; @xmath259 is the kernel estimate ignoring measurement errors ( dotted ) . , width=576 ]",
    "as shown by theorem [ thm : convergence rate for contaminated data in mise ] and convinced by the simulation results , the performance of the proposed method leans to that of the parametric approach when the correct parametric model is specified .",
    "the classical _ exact _ parametric method is subject to model misspecification .",
    "our approach is an approximate parametric solution to a nonparametric problem and speeds up the density deconvolution very much with the computation cost paid for searching an optimal model degree @xmath37 , of course , under the assumption that the underlying unknown density has a positive lower bound on a known compact support .",
    "the condition imposed on the error distribution is satisfied by the family of generalized normal distributions which include the supper smooth normal distribution and the ordinary smooth laplace distribution .",
    "the technical argument used in the proof of theorem [ thm : convergence rate for contaminated data ] appears to be new and may be of independent interest . as commented in remark [ remark 2 ] , the special case of this theorem is an enhancement of theorem 41 of @xcite with @xmath162 which is proved by the traditional delta method . from the simulation studies we see that there seem rooms for improving the result of theorem [ thm : convergence rate for contaminated data in mise ] .",
    "the author would like to thank professor jianqing fan who brought the density deconvolution to his attention .",
    "under the conditions of the proposition , by theorem 1 of @xcite there are polynomials , @xmath266 ( @xmath267 ) with nonnegative coefficients @xmath268 such that @xmath269 ( @xmath270 ) , where @xmath271 $ ] and @xmath272 depends on @xmath273 , and @xmath6 only .",
    "it is clear @xmath279 . by jensen s inequality @xmath280 .",
    "it is evident @xmath281 thus by the @xmath282-inequality @xmath283\\}^2\\le & 2|\\log g(0)|^2 + 2\\sum_{i=0}^m p_i\\int_0 ^ 1\\left(\\frac{|y - x|}{\\alpha}\\right)^{2\\gamma}\\beta_{mi}(x)dx\\\\ \\le&2|\\log g(0)|^2+\\frac{2c_{2\\gamma}}{\\alpha^{2\\gamma}}\\left(|y|^{2\\gamma } + 1\\right),\\end{aligned}\\ ] ] where @xmath284 .",
    "applying the @xmath282-inequality again we have @xmath285      let @xmath134 $ ] and @xmath286 be the unique best approximation of degree @xmath37 for @xmath6 @xcite . by proposition [ thm : approx of poly",
    "w pos coeff ] we have @xmath287 .",
    "because @xmath288 , we have , uniformly in @xmath37 , @xmath289}\\frac{f_{m0}(x)}{f(x)}=1+{\\cal o}(m^{-k}).\\ ] ] let @xmath290 be iid uniform(0,1 ) random variables . for each @xmath247 , if @xmath291 , then , by the acceptance - rejection argument used in simulation modeling , @xmath292 ( @xmath293 ) can be treated and used as if it were from @xmath294 ( @xmath295 ) .",
    "let @xmath296 and @xmath297 be the number of observations that can be treated and used as if they were from @xmath298 .",
    "it follows from the law of iterated logarithm that @xmath299 almost surely .",
    "so we have @xmath300 where @xmath301 is an `` almost complete '' likelihood and @xmath302 .",
    "it is clear that @xmath303 are iid with mean @xmath304 and variance @xmath305 . by ( [ eq : max ratio of fm to f ] ) and the conditions of the theorem we have @xmath306 and @xmath307 . by the law of iterated logarithm @xmath308 , almost surely .",
    "the proportion of the observations that can be treated as if they were from @xmath298 is @xmath309 , almost surely .",
    "taylor expansions of @xmath310 at @xmath311 yield that , for @xmath312 , @xmath313+\\tilde r_{mn},\\ ] ] where @xmath314 , almost surely .",
    "let @xmath315 be a point on the boundary of @xmath316 , i.e. , @xmath317 . by the law of iterated logarithm we have , almost surely , @xmath318 and that there exists an @xmath26 such that @xmath319 therefore we have , almost surely , @xmath320+o(nr_n^2)\\\\ & = \\tilde\\ell(\\bm{p}_m^{(0)})- \\frac{1}{2}\\eta nr_n^2+\\mathcal{o}\\{r_n^2(n\\log\\log n)^{1/2}\\}+\\mathcal{o}\\{r_n(n\\log\\log n)^{1/2}\\}+o(nr_n^2).\\ ] ] since @xmath155 , @xmath321 .",
    "so there exists an @xmath322 such that @xmath323 . since @xmath324",
    ", the maximum value of @xmath325 is attained by some @xmath326 with @xmath63 being in the interior of @xmath316 .",
    "then the assertion ( [ eq : convergence rate for contaminated data ] ) follows easily from ( [ eq : max ratio of fm to f ] ) .",
    "the proof of theorem [ thm : convergence rate for contaminated data ] is complete .",
    "[ [ proof - of - theorem - thm - convergence - rate - for - contaminated - data - in - mise ] ] proof of theorem [ thm : convergence rate for contaminated data in mise ] ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~      by the law of iterated logarithm and proposition [ thm : approx of poly w pos coeff ] , almost surely , @xmath332 define , for @xmath333 , @xmath334 where @xmath335 is the floor of @xmath336 .",
    "it follows from the schwartz inequality and theorem [ thm : convergence rate for contaminated data ] that , almost surely , @xmath337    by stirling s approximation we have , for some constants @xmath338 , @xmath339\\\\          & < & ( m+1)\\left(2 + c\\sum_{i=1}^{m-1 } \\frac{1}{i } \\right )     = \\frac{1}{k}\\mathcal{o}(n^{1/k}\\log n).\\end{aligned}\\ ] ] thus we have @xmath340 under the conditions of the theorem , by proposition [ thm : approx of poly w pos coeff ] , we obtain @xmath341 and the proof is complete .",
    "delaigle , a. and hall , p. ( 2014 ) .",
    "`` parametrically assisted nonparametric estimation of a density in the deconvolution problem . ''",
    "journal of the american statistical association , vol ."
  ],
  "abstract_text": [
    "<S> a new maximum likelihood method for deconvoluting a continuous density with a positive lower bound on a known compact support in additive measurement error models with known error distribution using the approximate bernstein type polynomial model , a finite mixture of specific beta distributions , is proposed . </S>",
    "<S> the change - point detection method is used to choose an optimal model degree . </S>",
    "<S> based on a contaminated sample of size @xmath0 , under an assumption which is satisfied , among others , by the generalized normal error distribution , the optimal rate of convergence of the mean integrated squared error is proved to be @xmath1 if the underlying unknown density has continuous @xmath2th derivative with @xmath3 . </S>",
    "<S> simulation shows that small sample performance of our estimator is better than the deconvolution kernel density estimator . </S>",
    "<S> the proposed method is illustrated by a real data application .    </S>",
    "<S> * key words and phrases : * bernstein polynomial model , beta mixture model ; deconvolution ; density estimation ; kernel density ; measurement error model ; model selection . </S>"
  ]
}