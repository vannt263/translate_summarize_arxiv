{
  "article_text": [
    "the method of likelihood introduced by fisher is certainly one of the most commonly used techniques for parametric models .",
    "the likelihood has been also shown to be very useful in non - parametric context .",
    "more concretely owen ( 1988 , 1990 , 1991 ) introduced the empirical likelihood ratio statistics for non - parametric problems .",
    "two sample problems are frequently encountered in many areas of statistics , generally performed under the assumption of normality .",
    "the most commonly used test in this connection is the two sample @xmath0-test for the equality of means , performed under the assumption of equality of variances .",
    "if the variances are unknown , we have the so - called behrens - fisher problem .",
    "it is well - known that the two sample @xmath0-test has cone major drawback ; it is highly sensitive to deviations from the ideal conditions , and may perform miserably under model misspecification and the presence of outliers .",
    "recently basu et al .",
    "( 2014 ) presented a new family of test statistics to overcome the problem of non - robustness of the @xmath0-statistic .",
    "empirical likelihood methods for two - sample problems have been studied by different researchers since owen ( 1988 ) introduced the empirical likelihood as a non - parametric likelihood - based alternative approach to inference on the mean of a single population .",
    "the monograph of owen ( 2001 ) is an excellent overview of developments on empirical likelihood and considers a multi - sample empirical likelihood theorem , which includes the two - sample problem as a special case .",
    "some important contributions for the two - sample problem are given in owen ( 1991 ) , adimiri ( 1995 ) , jin ( 1995 ) , qin ( 1994 , 1998 ) , qin and zhao ( 2000 ) , zhang ( 2000 ) , liu et al .",
    "( 2008 ) , baklizi and kibria ( 2009 ) , wu and yan ( 2012 ) and references therein .",
    "consider two independent unidimensional random variables @xmath1 with unknown mean @xmath2 and variance @xmath3 and @xmath4 with unknown mean @xmath5 and variance @xmath6 .",
    "let @xmath7 be a random sample of size @xmath8 from the population denoted by @xmath1 , with distribution function @xmath9 , and @xmath10 be a random sample of size @xmath11 from the population denoted by @xmath4 , with distribution function @xmath12 .",
    "we shall assume that @xmath9 and @xmath12 are unknown , therefore we are interested in a non - parametric approach , more concretely we shall use empirical likelihood methods .",
    "if we denote @xmath13 and @xmath14 , our interest will be in testing @xmath15 being @xmath16 a known real number .",
    "since @xmath17 becomes the parameter of interest , apart from testing ( [ 1 ] ) , we might also be interested in constructing the confidence interval for @xmath18 .    in this paper",
    "we are going to introduce a new family of empirical test statistics for the two - sample problem introduced in ( [ 1 ] ) : empirical phi - divergence test statistics .",
    "this family of test statistics is based on phi - divergence measures and it contains the empirical log - likelihood ratio test statistic as a particular case . in this sense , we can think that the family of empirical phi - divergence test statistics presented and studied in this paper is a generalization of the empirical log - likelihood ratio statistic .",
    "let @xmath19 , assume that@xmath20 and @xmath21 , @xmath22 a realization of @xmath7 , @xmath10 .",
    "we denote@xmath23 and @xmath24 with @xmath25 , @xmath26 and @xmath27 , @xmath28 .    the empirical log - likelihood ratio statistic for testing ( [ 1 ] )",
    "is given by @xmath29 using the standard lagrange multiplier method we might obtain @xmath30 , as well as @xmath31 . for @xmath32 ,",
    "taking derivatives on @xmath33 we obtain @xmath34 and @xmath35 therefore , the empirical maximum likelihood estimates @xmath36 , @xmath37 and @xmath38 of @xmath39 , @xmath40 and @xmath41 , under @xmath42 , are obtained as the solution of the equations@xmath43{l}\\dfrac{1}{m}{\\textstyle\\sum\\limits_{i=1}^{m } } \\frac{1}{1+\\lambda_{1}\\left (   x_{i}-\\mu\\right )   } = 1\\\\ \\dfrac{1}{n}{\\textstyle\\sum\\limits_{j=1}^{n } } \\frac{1}{1+\\lambda_{2}\\left (   y_{j}-\\mu-\\delta_{0}\\right )   } = 1\\\\ m\\lambda_{1}+n\\lambda_{2}=0 \\end{array } \\right .   , \\label{3bis}\\ ] ] and@xmath44 in relation @xmath45 , taking derivatives on@xmath46 we have @xmath47 and@xmath48 therefore , the empirical log - likelihood ratio statistic ( [ c ] ) , for testing ( [ 1 ] ) , can be written as @xmath49 under some regularity conditions , jing ( 1995 ) established that @xmath50 where @xmath51 is the @xmath52-th percentile of the @xmath53 distribution .    our interest in this paper is to study the problem of testing given in ( [ 1 ] ) and at the same time to construct confidence intervals for @xmath18 on the basis of the empirical phi - divergence test statistics .",
    "empirical phi - divergence test statistics in the context of the empirical likelihood have studied by baggerly ( 1998 ) , broniatowski and keizou ( 2012 ) , balakhrishnan et al .",
    "( 2013 ) , felipe et al .",
    "( 2015 ) and references therein .",
    "the family of empirical phi - divergence test statistics , considered in this paper , contains the classical empirical log - likelihood ratio statistic as a particular case . in section [ sec2 ] ,",
    "the empirical phi - divergence test statistics are introduced and the corresponding asymptotic distributions are obtained .",
    "a simulation study is carried out in section [ sec4 ] .",
    "section [ sec3 ] is devoted to develop a numerical example . in section [ sec5 ] the previous results , devoted to univariate populations , are extended to @xmath54-dimensional populations .",
    "for the hypothesis testing considered in ( [ 1 ] ) , in this section the family of empirical phi - divergence test statistics are introduced as a natural extension of the empirical log - likelihood ratio statistic given in ( [ c ] ) .",
    "we consider the @xmath55-dimensional probability vectors @xmath56 and @xmath57 where @xmath58 @xmath59 , @xmath60 @xmath61 were defined in ( [ 2 ] ) and ( [ 3 ] ) , respectively , and @xmath62  in ( [ ass ] ) .",
    "let @xmath63 be the @xmath55-dimensional vector obtained from @xmath64 with @xmath65 , @xmath66  replaced by the corresponding empirical maximum likelihood estimators @xmath67 , @xmath68 and @xmath62 by @xmath69 .",
    "the kullback - leibler divergence between the probability vectors @xmath70 and @xmath63 is given by @xmath71 where@xmath72 therefore , the relationship between @xmath73 and @xmath74 is@xmath75 based on ( [ 11 ] ) , in this paper the empirical phi - divergence test statistics for ( [ 1 ] ) are introduced for the first time .",
    "this family of empirical phi - divergence test statistics is obtained replacing the kullback - leibler divergence by a phi - divergence measure in ( [ 11 ] ) , i.e. , @xmath76 where @xmath77 with @xmath78 being any convex function such that at @xmath79 , @xmath80 , @xmath81 and at @xmath82 , @xmath83 and @xmath84 . for more details",
    "see cressie and pardo ( 2002 ) and pardo ( 2006 ) .",
    "therefore , ( [ 11bis ] ) can be rewritten as@xmath85 if @xmath86 is chosen in @xmath87 , we get the kullback - leibler divergence and @xmath88 coincides with the empirical log - likelihood ratio statistic @xmath89 given in ( [ 11 ] ) .",
    "let @xmath90 be the optimal estimator of @xmath41 under the assumption of having the known values of @xmath3 , @xmath6 , i.e. it is given by the shape @xmath91 and has minimum variance .",
    "it is well - known that@xmath92 similarly , an asymptotically optimal estimator of @xmath41 having unknown values of @xmath3 , @xmath6 , is given by@xmath93 where @xmath94 , @xmath95 are consistent estimators of @xmath3 , @xmath6 respectively .",
    "in the following lemma an important relationship is established , useful to get the asymptotic distribution of @xmath88 .",
    "[ lem]let @xmath38 the empirical likelihood estimator of @xmath41 . then",
    ", we have @xmath96    see appendix [ ap1 ] .",
    "[ th1]suppose that @xmath97 , @xmath98 and ( [ ass ] )",
    ". then,@xmath99    see appendix [ ap2 ] .",
    "[ r3]a @xmath100-level confidence interval on @xmath18 can be constructed as @xmath101 the lower and upper bounds of the interval @xmath102 require a bisection search algorithm .",
    "this is a computationally challenging task , because for every selected grid point on @xmath18 , one needs to maximize the empirical phi - divergence @xmath103 over the nuisance parameter , @xmath41 , and there is no closed - form solution to the maximum point @xmath104 for any given @xmath18 .",
    "the computational difficulties under the standard two - sample empirical likelihood formulation are due to the fact that the involved lagrange multipliers , which are determined through the set of equations ( [ 3bis ] ) , have to be computed based on two separate samples with an added nuisance parameter @xmath41 .",
    "such difficulties can be avoided through an alternative formulation of the empirical likelihood function , for which computation procedures are virtually identical to those for one - sample of size @xmath19  empirical likelihood problems . through the transformations@xmath105 ( [ p ] ) and ( [ q ] )",
    "can be alternatively obtained as@xmath106 where the estimates of the lagrange multipliers @xmath107 are the solution in @xmath108  of @xmath109    [ r4]in the particular case that @xmath110 , the two samples might be understood as a random sample of size @xmath11 from a unique bidimensional population . in this",
    "setting the two sample problem can be considered to be a particular case of balakrishnan et al .",
    "( 2015 ) .",
    "[ r5]fu et al . (",
    "2009 ) , yan ( 2010 ) and wu and yan ( 2012 ) pointed out that empirical log - likelihood ratio statistic , @xmath111 , given in ( [ 8 ] ) for testing ( [ 1 ] ) , does not perform well when the distribution associated to the samples are quite skewed or samples sizes are not large or sample sizes from each population are quite different . to overcome this problem fu et al .",
    "( 2009 ) considered the weighted empirical log - likelihood function defined by@xmath112 with @xmath113 , and obtained the weighted empirical likelihood ( wel ) estimator as well as the weighted empirical log - likelihood ratio statistic . in order to get the wel estimator ,",
    "it is necessary to maximize ( [ r1 ] ) subject to@xmath114 they obtained that the wel estimates of @xmath65 and @xmath66 are given by@xmath115 where @xmath116 and @xmath117 are the same transformations given in remark [ r3 ] with @xmath118  and the estimates of the lagrange multipliers @xmath119 are the solution in @xmath120  of @xmath121 now , if we define the probability vectors @xmath122 the weighted empirical log - likelihood ratio test @xmath123 presented in wu and yan ( 2012 ) can be written as @xmath124 the weighted empirical log - likelihood ratio test can be extended by defining the family of weighted empirical phi - divergence test statistics as @xmath125 where @xmath126 is the phi - divergence measure between the probability vectors @xmath127 and @xmath128 , i.e.,@xmath129 taking into account @xmath130 where@xmath131 and based on theorem 2.2 . in wu and yan ( 2012 ) , we have that@xmath132 where @xmath133 is the second diagonal element of the matrix @xmath134 .",
    "the square of the classical @xmath135-test statistic for two sample problems,@xmath136 has asymptotically @xmath53 distribution , the same as the empirical phi - divergence test statistics , according to theorem [ th1 ] . in order to compare the finite sample performance of the confidence interval ( ci ) of @xmath18  based on @xmath103 with respect to the ones based on @xmath137 as well as",
    "the empirical log - likelihood ratio test - statistic @xmath138 given in ( [ c ] ) ,  we count on a subfamily of phi - divergence measures , the so - called power divergence measures @xmath139 , dependent of tuning parameter @xmath140 , i.e.@xmath141{ll}\\dfrac{2}{\\gamma(\\gamma+1)}\\left ( { \\displaystyle\\sum\\limits_{i=1}^{m } } ( m\\widetilde{p}_{i})^{-\\gamma}+{\\displaystyle\\sum\\limits_{j=1}^{n } } ( n\\widetilde{q}_{j})^{-\\gamma}-n\\right )   , & \\gamma\\in\\mathbb{r } -\\{0,-1\\},\\\\ -2\\left (   m\\log m+n\\log n+m{\\displaystyle\\sum\\limits_{i=1}^{m } } \\log\\widetilde{p}_{i}+n{\\displaystyle\\sum\\limits_{j=1}^{n } } \\log\\widetilde{q}_{j}\\right )   , & \\gamma=0,\\\\ 2\\left (   m\\log m+n\\log n+m{\\displaystyle\\sum\\limits_{i=1}^{m } } \\widetilde{p}_{i}\\log\\widetilde{p}_{i}+n{\\displaystyle\\sum\\limits_{j=1}^{n } } \\widetilde{q}_{j}\\log\\widetilde{q}_{j}\\right )   , & \\gamma=-1 , \\end{array } \\right.\\ ] ] where @xmath67 and @xmath68  can be obtained from ( [ p2])-([q2 ] ) .",
    "we analyzed five new test - statistics , the empirical power - divergence test statistics taking @xmath142 .",
    "the case of @xmath143 is not new , since the empirical log - likelihood ratio test - statistic @xmath138 is a member of the empirical power - divergence test statistics , i.e. @xmath144 . the ci of @xmath145  based on @xmath146  with @xmath147 confidence level is essentially the ci of @xmath135-test statistic , @xmath148 . for @xmath149 , @xmath150 , as mentioned in remark [ r3 ] , since there is no explicit expression for @xmath151 the bisection method should be followed .",
    "the simulated coverage probabilities of the ci of @xmath18  based on @xmath152 were obtained with @xmath153 replications by@xmath154 with @xmath155 being the indicator function .",
    "the simulated expected width of the ci of @xmath18  based on @xmath156 were obtained with @xmath157 replications by@xmath158 the reason why two different values of @xmath159 were followed is twofold .",
    "on one hand calculating @xmath160 is much more time consuming than @xmath161 and on the other hand for the designed simulation experiment the replications needed to obtain a good precision is less for the expected width than for the coverage probability .    the simulation experiment is designed in a similar manner as in wu and yan ( 2012 ) .",
    "the true distributions , unknown in practice , are generated from :    i ) : :    @xmath162 ,    @xmath163 , with @xmath164 ,    @xmath165 ,    @xmath166 ; ii ) : :    @xmath167 ,    @xmath168 , with    @xmath169 , @xmath170 ,    @xmath171 , @xmath172 .",
    "notice that in case ii ) @xmath166 since @xmath173=e[y]$ ] .",
    "depending on the sample sizes , six scenarios were considered , @xmath174 . table [ table1 ] summarizes the results of the described simulation experiment with @xmath175 . in all the cases and scenarios the narrower width is obtained with @xmath176 , but the coverage probabilities closest to @xmath177 depends on the case or scenario .",
    "for the case of the lognormal distribution the ci based on @xmath137 test - statistic has the closest coverage probability to @xmath177 , but for the case of the normal distribution @xmath178 and @xmath179 power divergence based tend to have the closest coverage probability to @xmath177 .    in order to complement this study , the power functions have been drawn through @xmath153 replications and taking @xmath18 as abscissa .",
    "for case i ) the power functions exhibit a symmetric shape with respect to the center and also a parallel shape , in such a way that the test statistics with better approximation of the size have worse power . for case ii ) , fixing the values of the two parameters of @xmath1 and changing the two parameter of @xmath4 as@xmath180 @xmath18 is displaced from @xmath166 to the right when @xmath181 and from @xmath166 to the left when @xmath182 ( @xmath183 ) .",
    "unlike case i ) , the power function of case ii ) exhibits a different shape on both sides from the center of abscissa , and the most prominent differences are on the left hand size . clearly in case",
    "ii ) , even though the approximated size for @xmath146 is the best one , it has the worst approximated power function , in particular there is an area of the approximated power function on the left hand side of @xmath184  with smaller value than the approximated size .",
    "hence , in case ii ) the power functions of @xmath185 are more acceptable than the power function of @xmath186 . taking into account the strong and weak point of @xmath146 in case ii )",
    ", @xmath187 could be a good choice for moderate sample sizes and @xmath188 for small sample sizes .",
    "2.8pt @xmath189{ccccc}\\hline \\multicolumn{5}{c}{case",
    "i ) : normal populations}\\\\\\hline $ ] m@xmath190n@xmath190ci@xmath19115@xmath19030@xmath19292.1@xmath19315@xmath19030@xmath19492.6@xmath1901.60@xmath19515@xmath19030@xmath19693.0@xmath1901.64@xmath19515@xmath19030@xmath19793.2@xmath1901.65@xmath19515@xmath19030@xmath19893.2@xmath1901.65@xmath19515@xmath19030@xmath19992.6@xmath1901.63@xmath19515@xmath19030@xmath2001.66@xmath20130@xmath19015@xmath19292.8@xmath20230@xmath19015@xmath19493.3@xmath1901.43@xmath19530@xmath19015@xmath19693.6@xmath1901.45@xmath19530@xmath19015@xmath2031.46@xmath19530@xmath19015@xmath2041.47@xmath19530@xmath19015@xmath19993.6@xmath1901.46@xmath19530@xmath19015@xmath2051.46@xmath20130@xmath19030@xmath19293.8@xmath20630@xmath19030@xmath19494.3@xmath1901.29@xmath19530@xmath19030@xmath19694.5@xmath1901.28@xmath19530@xmath19030@xmath19794.8@xmath1901.30@xmath19530@xmath19030@xmath2071.29@xmath19530@xmath19030@xmath19994.7@xmath1901.29@xmath19530@xmath19030@xmath20894.7@xmath2091.28@xmath20130@xmath19060@xmath19293.4@xmath21030@xmath19060@xmath19493.8@xmath1901.16@xmath19530@xmath19060@xmath19694.1@xmath1901.18@xmath19530@xmath19060@xmath2111.20@xmath19530@xmath19060@xmath2121.20@xmath19530@xmath19060@xmath19994.1@xmath1901.19@xmath19530@xmath19060@xmath20894.2@xmath2091.18@xmath20160@xmath19030@xmath19294.4@xmath21360@xmath19030@xmath19494.6@xmath1901.03@xmath19560@xmath19030@xmath19694.8@xmath1901.04@xmath19560@xmath19030@xmath2141.04@xmath19560@xmath19030@xmath2151.05@xmath19560@xmath19030@xmath19994.9@xmath1901.05@xmath19560@xmath19030@xmath20894.8@xmath2091.04@xmath20160@xmath19060@xmath19294.3@xmath21660@xmath19060@xmath19494.5@xmath1900.90@xmath19560@xmath19060@xmath19694.7@xmath1900.91@xmath19560@xmath19060@xmath2170.92@xmath19560@xmath19060@xmath2070.92@xmath19560@xmath19060@xmath2180.92@xmath19560@xmath19060@xmath20894.8@xmath2090.91@xmath219{ccccc}\\hline \\multicolumn{5}{c}{case",
    "ii ) : lognormal populations}\\\\\\hline $ ] m@xmath190n@xmath190ci@xmath19115@xmath19030@xmath19290.0@xmath22015@xmath19030@xmath19490.6@xmath1902.66@xmath19515@xmath19030@xmath19691.0@xmath1902.77@xmath19515@xmath19030@xmath19790.8@xmath1902.82@xmath19515@xmath19030@xmath19890.6@xmath1902.87@xmath19515@xmath19030@xmath19989.2@xmath1902.86@xmath19515@xmath19030@xmath2212.76@xmath20130@xmath19015@xmath19292.2@xmath22230@xmath19015@xmath19492.5@xmath1902.46@xmath19530@xmath19015@xmath19692.7@xmath1902.52@xmath19530@xmath19015@xmath19792.5@xmath1902.60@xmath19530@xmath19015@xmath19892.3@xmath1902.62@xmath19530@xmath19015@xmath19991.2@xmath1902.68@xmath19530@xmath19015@xmath2232.48@xmath20130@xmath19030@xmath19292.4@xmath22430@xmath19030@xmath19492.7@xmath1902.14@xmath19530@xmath19030@xmath19693.0@xmath1902.24@xmath19530@xmath19030@xmath19793.0@xmath1902.31@xmath19530@xmath19030@xmath19892.9@xmath1902.33@xmath19530@xmath19030@xmath19992.1@xmath1902.39@xmath19530@xmath19030@xmath2252.16@xmath20130@xmath19060@xmath19292.0@xmath22630@xmath19060@xmath19492.5@xmath1901.97@xmath19530@xmath19060@xmath19692.8@xmath1902.03@xmath19530@xmath19060@xmath19792.8@xmath1902.11@xmath19530@xmath19060@xmath19892.8@xmath1902.12@xmath19530@xmath19060@xmath19991.9@xmath1902.18@xmath19530@xmath19060@xmath2001.98@xmath20160@xmath19030@xmath19292.9@xmath22760@xmath19030@xmath19493.3@xmath1901.78@xmath19560@xmath19030@xmath19693.5@xmath1901.83@xmath19560@xmath19030@xmath19793.6@xmath1901.87@xmath19560@xmath19030@xmath19893.5@xmath1901.91@xmath19560@xmath19030@xmath19993.0@xmath1901.95@xmath19560@xmath19030@xmath2281.77@xmath20160@xmath19060@xmath19293.6@xmath22960@xmath19060@xmath19493.9@xmath1901.55@xmath19560@xmath19060@xmath19694.1@xmath1901.59@xmath19560@xmath19060@xmath19794.2@xmath1901.65@xmath19560@xmath19060@xmath19894.2@xmath1901.66@xmath19560@xmath19060@xmath19993.6@xmath1901.70@xmath19560@xmath19060@xmath2231.54@xmath230    [ c]l +    [ c]l +",
    "yu et al . ( 2002 ) presented a data set on evaluating gasoline quality based on what is known as reid vapor pressure , collected by the environmental protection agency of the united states .",
    "two types of reid vapor pressure measurements @xmath1 and @xmath4 are included in the data set .",
    "values of @xmath1 are obtained by an agency inspector who visits gas pumps in a city , takes samples of gasoline of a particular brand , and measures the reid vapor pressure right on the spot ; values of @xmath4 , on the other hand , are produced by shipping gasoline samples to the laboratory for measurements of presumably higher precision at a high cost .",
    "the original data set has a double sampling structure , with a subset of the sample units having measurements on both @xmath1 and @xmath4 .",
    "table [ table2 ] contains two independent samples of a new reformulated gasoline , one related to @xmath1 with sample size 30 and the other , to @xmath4 with sample size 15 .",
    "2.8pt @xmath189{ccccccccccc}\\hline $ ] x@xmath2318.09@xmath1908.46@xmath1907.37@xmath1908.80@xmath1907.59@xmath1908.62@xmath2097.88@xmath1907.98@xmath1907.47@xmath1908.90@xmath2328.51@xmath1908.69@xmath1907.93@xmath1907.96@xmath1907.45@xmath1908.02@xmath1907.32@xmath1907.45@xmath2097.86@xmath1907.88@xmath2327.39@xmath1908.03@xmath1907.31@xmath1907.44@xmath1907.95@xmath1907.92@xmath1907.53@xmath1908.01@xmath2097.16@xmath1907.31@xmath201y@xmath2338.28@xmath1908.63@xmath1909.28@xmath1907.85@xmath1908.62@xmath1909.14@xmath2097.86@xmath1907.90@xmath1908.52@xmath1907.92@xmath2327.89@xmath1908.48@xmath1907.95@xmath1908.32@xmath1907.60@xmath234    one of the assumptions of yu et al .",
    "( 2002 ) is that the field measurement @xmath1 and the lab measurement @xmath4 have common mean @xmath235 .",
    "the two types of measurements differ , however , in terms of precision .",
    "yu et al . (",
    "2002 ) also assumed that @xmath236 , @xmath237 was bivariate normal , which would not be required under our proposed empirical likelihood approach . in tsao and wu ( 2006 )",
    "this example was studied on the basis of the empirical log - likelihood ratio test .",
    "the @xmath177 cis of @xmath18  based on @xmath238 are summarized in table [ table3 ] . as in the simulation study ,",
    "the narrowest ci width is obtained with @xmath176 . in all the test - statistics",
    "used to construct the cis @xmath166 is not contained , so the null hypothesis of equal means is rejected with @xmath239 significance level .",
    "2.8pt @xmath189{cccc}\\hline $ ] ci@xmath2400.122@xmath1900.703@xmath2410.581@xmath2420.121@xmath2090.712@xmath1900.591@xmath2430.121@xmath1900.718@xmath2410.598@xmath2440.123@xmath2090.724@xmath1900.602@xmath2450.124@xmath1900.726@xmath2410.601@xmath2460.133@xmath1900.725@xmath2410.592@xmath2470.101@xmath1900.712@xmath2090.611@xmath248",
    "let @xmath249 and @xmath250 be two mutually independent random samples with common distribution function @xmath9 and @xmath12 respectively . assuming that @xmath251 and @xmath252 take values in @xmath253 and @xmath254    &   = \\boldsymbol{\\mu}_{1},\\text { } cov\\left [   \\boldsymbol{x}_{i}\\right ]   = \\boldsymbol{\\sigma}_{1}\\text { , } i=1, ... ,m,\\\\ e\\left [   \\boldsymbol{y}_{j}\\right ]    &   = \\boldsymbol{\\mu}_{2},\\text { } cov\\left [   \\boldsymbol{y}_{j}\\right ]   = \\boldsymbol{\\sigma}_{2}\\text { , } j=1, ... ,n,\\end{aligned}\\ ] ] with @xmath255 and @xmath256 , our interest is in testing @xmath257 where @xmath258 @xmath253 and known .",
    "the empirical likelihood under @xmath42 is@xmath259 and in the whole parameter space,@xmath260 with @xmath261 , @xmath262 and @xmath263 , @xmath264 .",
    "the empirical log - likelihood ratio statistic for testing ( [ 5.1 ] ) is given by @xmath265 based on lagrange multiplier methods , @xmath266 is obtained for @xmath267@xmath268 where @xmath269 .",
    "the empirical maximum likelihood estimates @xmath270 , @xmath271 and @xmath272 of @xmath273 , @xmath274 and @xmath275 , under @xmath42 , can be obtained as the solution of@xmath43{l}\\frac{1}{m}{\\textstyle\\sum\\limits_{i=1}^{m } } \\frac{(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu})}{1+\\boldsymbol{\\lambda}_{1}^{t}(\\boldsymbol{x}_{i}-\\boldsymbol{\\mu})}=\\boldsymbol{0}_{k}\\\\ \\frac{1}{n}{\\textstyle\\sum\\limits_{j=1}^{n } } \\frac{\\left (   \\boldsymbol{y}_{j}-\\boldsymbol{\\mu}-\\boldsymbol{\\delta}\\right ) } { 1+\\boldsymbol{\\lambda}_{2}^{t}\\left (   \\boldsymbol{y}_{j}-\\boldsymbol{\\mu } -\\boldsymbol{\\delta}\\right )   } = \\boldsymbol{0}_{k}\\\\ m\\boldsymbol{\\lambda}_{1}^{t}+n\\boldsymbol{\\lambda}_{2}^{t}=\\boldsymbol{0}_{k}\\end{array } \\right .   .\\",
    "] ] on the other hand @xmath45 is obtained for @xmath276 after some algebra , we obtain @xmath277 under some regularity conditions , it follows that @xmath278 where @xmath279 is the @xmath280-th order quantile of the @xmath281 distribution .",
    "let @xmath282 be the estimate the probability vector@xmath283 where @xmath67 and @xmath68 are obtained from ( [ 5.2 ] ) and ( [ 5.3 ] ) replacing @xmath273 , @xmath274 and @xmath275 by @xmath270 , @xmath271 and @xmath272 , respectively . in this @xmath54-dimensional case ,",
    "the kullback - leibler divergence between the probability vectors @xmath70 and @xmath63 is given by @xmath284 therefore , the relationship between @xmath285 and the kullback - leibler divergence is@xmath286 based on ( [ 5.6 ] ) the family of empirical phi - divergence test statistics are defined as@xmath287 with @xmath288 therefore the expression of @xmath289 is@xmath290    a result similar to the one given in lemma 1 for the @xmath54-dimensional case is @xmath291 where @xmath292  and @xmath293 . finally , based in this result",
    "it is possible to establish@xmath294      rnyi ( 1961 ) introduced the rnyi s divergence measure as an extension of the kullback - leibler divergence .",
    "unfortunately this divergence measure is not a member of the family of phi - divergence measures considered in this paper .",
    "menndez et al .",
    "( 1995 , 1997 ) introduced and studied the ( h , phi)-divergence measures in order to have a family of divergence measures in which the phi - divergence measures as well as the rnyi divergence measure are included .",
    "but not only the rnyi divergence measure is included in this new family but another important divergence measures not include in the family of phi - divergence measures are included . for more details about the different divergence measures included in the ( h , phi)-divergence",
    "see for instance , pardo ( 2006 ) . based on the ( h , phi)-divergence measures between the probability vectors @xmath70 and @xmath64 , defined in ( [ 9 ] ) and ( [ 10 ] ) respectively , we can consider the following family of empirical ( h , phi)-divergence test statistics for the two - sample problem considered in ( [ 1 ] ) @xmath295 where @xmath296 is a differentiable increasing function from @xmath297 onto @xmath298 with @xmath299 and @xmath300 .",
    "if we consider @xmath301 in ( [ a ] ) , and @xmath302 we get @xmath303 i.e. , the empirical rnyi s divergence test statistics for testing ( [ 1 ] ) . for @xmath304 and @xmath305 , we get @xmath306 and @xmath307 it is clear that @xmath308 therefore@xmath309 in the same way can be established for the problem considered in ( [ 5.1 ] ) that @xmath310 where @xmath311 with @xmath289 defined in ( [ 5.7 ] )",
    ".    * acknowledgement .",
    "* this research is partially supported by grants mtm2012 - 33740 from ministerio de economia y competitividad ( spain ) .",
    "99    adimari , g. ( 1995 ) .",
    "empirical likelihood confidence intervals for the difference between means _ statistica _ , * 55 * , 8794    baggerly , k. a. ( 1998 ) .",
    "empirical likelihood as a goodness - of - fit measure .",
    "_ biometrika _ , * 85 * , 535547 .",
    "baklizi , a. and kibria , b.m .",
    "g. ( 2009 ) .",
    "one and two sample confidence intervals for estimating the mean of skewed populations : an empirical comparative study .",
    "_ journal of applied statistics , _ * 36 , * 6 , 601 - 609 .",
    "balakrishnan , n , martin , n. and pardo , l. ( 2015 ) .",
    "empirical phi - divergence test statistics for testing simple and composite null hypotheses .",
    "_ statistics _ , * 49 * , 951977 .",
    "basu , a. , mandal , a. martin , n. and pardo , l. ( 2015 ) .",
    "robust tests for the equality of two normal means based on the density power divergence .",
    "_ metrika _ , * 78 * , 611634 .",
    "bhattacharyya , a. ( 1943 ) . on a measure of divergence between two statistical populations defined by their probability distributions .",
    "_ bulletin of the calcutta mathematical society _",
    ", 35 , 99109 .",
    "broniatowski , m. and keziou , a. ( 2012 ) .",
    "divergences and duality for estimating and test under moment condition models . _ journal of statistical planning and inference , _ * 142 * , 25542573 .",
    "cressie , n. and pardo , l. ( 2002 ) .",
    "phi - divergence statisitcs . in : elshaarawi ,",
    "plegorich , w.w . editors .",
    "_ encyclopedia of environmetrics",
    "* 13*. pp : 15511555 , john wiley and sons , new york .",
    "cressie , n. and read , t. r. c. ( 1984 ) .",
    "multinomial goodness - of - fit tests .",
    "_ journal of the royal statistical society , _ series b , * 46 * , 440464 .",
    "felipe , a. martn ,  n. , miranda , p. and pardo , l. ( 2015 ) .",
    "empirical phi - divergence test statistics for testing simple null hypotheses based on exponentially tilted empirical likelihood estimators .",
    "_ arxiv _ preprint arxiv:1503.00994    fu , y. , wang , x. and wu , c. ( 2008 ) . weighted empirical likelihood inference for multiple samples .. _journal of statistical planning and inference , _ * 139 * , 14621473 .",
    "jing , b. y. ( 1995 ) .",
    "two - sample empirical likelihood method . _ statistics and probability letters , _ * 24 * , 315319__. _ _    liu , y. , c. zou , and zhang , r. ( 2008 ) . _ statistics and probability letters , _ * 78 * , 548556__. _ _    menndez , m. l. , morales , d. , pardo , l. and salicr , m. ( 1995 ) .",
    "asymptotic behavior and statistical applications of divergence measures in multinomial populations : a unified study .",
    "_ statistical papers , _ * 36 , * 129 .",
    "menndez , m. l. , pardo , j. a. , pardo , l. and pardo , m. c. ( 1997 ) .",
    "asymptotic approximations for the distributions of the @xmath312-divergence goodness - of - fit statistics : applications to rnyi s statistic .",
    "_ kybernetes , _ * 26 , * 442452",
    ".    owen , a. b. ( 1988 ) .",
    "empirical likelihood ratio confidence interval for a single functional .",
    "_ biometrika _ , * 75 * , 308313 .",
    "owen , a. b. ( 1990 ) .",
    "empirical likelihood confidence regions . _",
    "the annals of statistics _ , * 18 * , 90120 .",
    "owen , a. b. ( 1991 ) .",
    "empirical likelihood for linear models .",
    "_ the annals of statistics _ , * 19 * , 17251747 .",
    "owen , a. b. ( 2001 ) .",
    "_ empirical likelihood , _ chapman and hall / crc .    pardo , l. ( 2006 ) .",
    "_ statistical inference based on divergence measures_. chapman & hall/ crc press , boca raton , florida .",
    "qin , j. ( 1994 ) .",
    "semi - parametric likelihood ratio confidence intervals for the difference of two sample means . _ annals of the institute of statitical mathematics , _ * 46 * , 117126 .",
    "qin , j. ( 1998 ) .",
    "inferences for case - control and semiparametric two - sample densisty ratio models .",
    "_ biometrika , _ * 85 * , 619630 .",
    "qin , j. and lawless , j. ( 1994 ) .",
    "empirical likelihood and general estimating equations .",
    "_ the annals of statistics _ , * 22 * , 300325 .",
    "qin , y. and zhao , l. ( 2000 ) .",
    "empirical likelihood ratio intervals for various differences of two populations . _",
    "chinese systems sci . math .",
    ", _ * 13 , * 2330 .",
    "rnyi , a. ( 1961 ) . on measures of entropy and information .",
    "_ proceedings of the fourth berkeley symposium on mathematical statistics and probability , _ * 1 * , 547561__. _ _    sharma , b. d. and mittal , d. p. ( 1997 ) .",
    "new non - additive measures of relative information .",
    "_ journal of combinatorics , information & systems science , _ * * 2 * * _ _ , _ _ 122133__. _ _    tsao , m. and wu , c. ( 2006 ) .",
    "empirical likelihood inference for a common mean in the presence of heteroscedasticity . _ the canadian journal of statistics _ , * 34 * , 1 , 4559 .",
    "yan , y. ( 2010 ) .",
    "empirical likelihood inference for two - sample problems .",
    "unpublished master s thesis , department of statisticsd and actuarial science , university of waterloo , canada .",
    "yu ,  p.l.h .",
    ", su , y. and sinha , b. ( 2002 ) .",
    "estimation of the common mean of a bivariate normal population .",
    "_ annals of the institute of statistical mathematics _ , * 54 * , 861878 .",
    "wu , c. and yan , y. ( 2012 ) empirical likelihood inference for two - sample probllems .",
    "_ statistics and its inference , _ * 5 * , 345354 .",
    "zhang , b. ( 2000 ) .",
    "estimating the treatment effect in the two - sample problem with auxiliary information . _ nonparametric statistics , _ * 12 , * 377389 .",
    "first we are going to establish @xmath316@xmath317 if we denote @xmath318 we have @xmath319 .",
    "a taylor expansion gives @xmath320 on the other hand @xmath321 then@xmath322 but@xmath323 @xmath324@xmath325 , because @xmath326 ( see page 220 in owen ( 2001 ) ) , and @xmath327 applying the strong law of large numbers.@xmath323 @xmath328 , because @xmath329 by lemma 11.3 in page 218 in owen ( 2001).@xmath323 @xmath330.@xmath323 @xmath331 because @xmath332 applying lemma 11.2 in page 218 in owen ( 2001).@xmath323 @xmath333 .",
    "therefore@xmath334 in a similar way we can get @xmath335 therefore , @xmath336 applying ( [ 14 ] ) , @xmath337 and @xmath338 from ( [ muhat ] ) we have@xmath339 therefore,@xmath340 now we have,@xmath341 and@xmath342 where is such that ( [ ass ] ) . hence @xmath343 from which is obtained@xmath344 and now the result follows ."
  ],
  "abstract_text": [
    "<S> empirical phi - divergence test - statistics have demostrated to be a useful technique for the simple null hypothesis to improve the finite sample behaviour of the classical likelihood ratio test - statistic , as well as for model misspecification problems , in both cases for the one population problem . </S>",
    "<S> this paper introduces this methodology for two sample problems . </S>",
    "<S> a simulation study illustrates situations in which the new test - statistics become a competitive tool with respect to the classical z - test and the likelihood ratio test - statistic .    </S>",
    "<S> * ams 2001 subject classification : * 62f03 , 62f25 .    * keywords and phrases : * empirical likelihood , empirical phi - divergence test statistics , phi - divergence measures , power function . </S>"
  ]
}