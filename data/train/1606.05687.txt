{
  "article_text": [
    "in this paper we consider the estimation of the extreme value index @xmath0 and tail probabilities @xmath1 for @xmath2 large , on the basis of independent and identically distributed observations @xmath3 which follow a pareto - type distribution with right tail function ( rtf ) given by @xmath4 where @xmath5 is a slowly varying function at infinity , _",
    "i.e. _ @xmath6 the most famous estimator of @xmath0 was first derived by hill ( 1975 ) as a maximum likelihood ( ml ) estimator using the approximation @xmath7 to the rtf of the excesses @xmath8 over a large threshold @xmath9 by a simple pareto distribution with rtf @xmath10 , and setting @xmath11 where @xmath12 : @xmath13 a simple estimator of a tail probability @xmath1 with @xmath2 large , introduced in weissman ( 1978 ) , + is then obtained from setting @xmath14 and estimating @xmath15 by the empirical proportion @xmath16 : @xmath17 in practice , a way to verify the validity of model is to check whether the hill estimates are stable as a function of @xmath18 .",
    "however in most cases the stability is not visible , which can be explained by slow convergence in .",
    "for this reason bias reduced estimators have been proposed which lead to plots that are much more horizontal in @xmath18 which facilitates the analysis of a practical case to a great extent . here",
    "we can refer to peng ( 1998 ) , beirlant _ et al . _",
    "( 1999 , 2008 ) , feuerverger and hall ( 1999 ) , caeiro _ et al . _",
    "( 2005 , 2009 ) and gomes _ et al . _",
    "( 2007 ) for bias - reduced estimators based on functions of the top @xmath18 order statistics .",
    "several of these methods focus on the distribution of log - spacings of high order statistics .",
    "+   + beirlant _ et al . _",
    "( 2009 ) proposed to build a more flexible model capable of capturing the deviation between the true excess rtf @xmath19 and the asymptotic pareto model . for a heavy tailed distribution",
    ", this deviation can be parametrized using a power series expansion ( hall , 1982 ) , or more generally via second - order slow variation ( bingham _ et al . _ , 1987 ) . more specifically in beirlant _ et al . _",
    "( 2009 ) the subclass @xmath20 of the pareto - type tails was considered satisfying @xmath21 with @xmath22 eventually nonzero and of constant sign such that @xmath23 with @xmath24 and @xmath25 slowly varying .",
    "it was shown that under @xmath20 one has as @xmath26 @xmath27 with @xmath28 the rtf of the extended pareto distribution ( epd ) @xmath29 with @xmath30 and @xmath31 .",
    "this shows that the epd improves the approximation with an order of magnitude .",
    "then maximum likelihood ( ml ) estimation of the parameters ( @xmath32 ) based on a set of excesses @xmath33 was used to obtain a bias reduced estimator of @xmath0 .",
    "bias reduction of the weissman estimator of tail probabilities can analogously be obtained using @xmath34 where @xmath35 denote the ml estimators based on the epd model , and where @xmath36 is a consistent estimator of @xmath37 , to be specified below , which was shown not to affect the asymptotic distribution of @xmath38 .    here",
    "we investigate the possibilities of using the bayesian methodology when modelling the distribution of the vector of excesses @xmath39 with an epd . in section 2",
    "we show that a normal prior on @xmath40 with zero mean and variance @xmath41 , depending in an appropriate way on @xmath18 and @xmath42 , leads to interesting mse results of the posterior mode estimators for @xmath0 and of the corresponding estimators of @xmath1 following . in section 3",
    "we discuss the implementation of the bayesian estimates . in section 4",
    "we consider the finite sample behaviour of this bayesian approach and consider some practical cases .",
    "ml estimation of the epd parameters ( @xmath32 ) , given a value of @xmath37 , follows by maximizing the log - likelihood @xmath43 + { 1 \\over k}\\sum_{j=1}^k\\log\\left(1+\\delta\\{1-(1+\\tau)y_{j , k}^{\\tau}\\}\\right ) .",
    "\\label{logl}\\ ] ] in the bayesian framework , the log - posterior can be written as @xmath44 where @xmath45 denotes the prior density . here",
    "we assign a maximal data information ( mdi ) prior to @xmath0 , which for a general parameter @xmath46 is defined as @xmath47 .",
    "( 2004 ) derived that the mdi for a pareto distribution is given by @xmath48 + next , the prior on @xmath40 is taken to be a normal distribution with mean 0 and variance @xmath41 , depending on @xmath18 , and left truncated in order to comply with the restriction @xmath31 : @xmath49    if @xmath50 satisfies @xmath20 , it is shown in beirlant _ et al . _ ( 2009 ) that @xmath51 ( @xmath52 ) , with @xmath53 ( @xmath54 ) , satisfies @xmath55 with @xmath56 as @xmath57 .",
    "in particular @xmath58 is eventually nonzero and of constant sign and @xmath59 with @xmath60 slowly varying and @xmath61",
    ".    then it was shown that if @xmath50 satisfies @xmath20 , and @xmath62 and @xmath63 as @xmath64 and @xmath65 , the following asymptotic results hold for the epd - ml estimator @xmath66 and @xmath67 : @xmath68 from these results it follows that for the smallest values of @xmath18 ( _ i.e. _ @xmath69 ) the hill estimator is asymptotically unbiased , while for increasing values of @xmath18 ( _ i.e. _ @xmath70 ) it is biased . in this region",
    "the bias reduced estimator @xmath71 still has asymptotic bias 0 , but its variance is increased by a factor @xmath72 compared to @xmath67 .",
    "+   + in the appendix we derive that the first order approximations ( @xmath73 ) of the bayesian estimators are given by @xmath74 where @xmath75 and @xmath76 these expressions are identical to the asymptotic epd - ml estimators derived in beirlant _ et al . _",
    "( 2009 ) except for the extra term @xmath77 in the expression of @xmath78 . as an external estimator of @xmath37",
    "we use @xmath79 where @xmath80 is a consistent estimator of @xmath81 ( see for instance @xmath82 from fraga alves _ et al . _ , 2003 ) .",
    "the following result is derived in the appendix",
    ". +   + * theorem . * _ let @xmath83 and assume @xmath84 as @xmath64 , @xmath65 and @xmath85",
    ". then @xmath86 is asymptotically normal with asymptotic mean and variance given by @xmath87 _",
    "minimizing @xmath88 with respect to @xmath89 leads to @xmath90 from which , with @xmath91 , @xmath92 hence , we are lead to choosing @xmath93 for the prior variance since @xmath94 and @xmath95 .",
    "+   + note that using , one obtains from and that @xmath96 from which @xmath97 + 2 \\xi^2\\rho^4\\lambda^2(1 - 2\\rho)[\\xi^2]+\\lambda^4\\rho^8 [ \\xi^2{(1-\\rho)^2\\over \\rho^2 } ] } { \\xi^4(1 - 2\\rho)^2 + 2 \\xi^2\\rho^4\\lambda^2(1 - 2\\rho)+   \\lambda^4\\rho^8 } \\label{wavg } \\\\ & = & \\xi^2 + \\xi^2\\rho^2{(1 - 2\\rho)\\over ( 1-\\rho)^2}\\ , \\lambda^2 \\ , \\frac{\\left(\\xi^2(1 - 2\\rho)+ \\lambda^2\\rho^4(1-\\rho)^2 \\right)}{(\\xi^2(1 - 2\\rho)+\\lambda^2\\rho^4)^2}. \\label{xisqdiff}\\end{aligned}\\ ] ] from it follows that the asymptotic mse of this optimal bayesian estimator is a weighted average of the asymptotic mses of the hill and epd - ml estimators .",
    "moreover , since the right hand side of is an increasing function in @xmath98 it follows that @xmath99 also , expanding the the right hand side of for @xmath100 leads to @xmath101 we can conclude that the asymptotic mse of the optimal bayes estimator is uniformly smaller than the mse of the epd - ml estimator as given in , while for smaller @xmath102 this asymptotic mse follows the asymptotic mse of the hill estimator , given in , up to terms of order @xmath98 . hence with the choice the bayesian estimator automatically follows the better of the two existing estimators as a function of @xmath102 or @xmath18 .",
    "+   + replacing ( @xmath103 ) by ( @xmath104 ) in @xmath105 , it follows from the proof of theorem 5.2 in beirlant _ et al . _",
    "( 2009 ) that the resulting tail probability estimator @xmath106 satisfies the following asymptotic result under the conditions of the theorem : + when @xmath107 satisfies @xmath108 and @xmath109 , then @xmath110 is asymptotically normal with the same limit distribution as in the theorem .",
    "hence the asymptotic mse behaviour for the tail probability estimator has the same characteristics as the tail index estimator . +   + in the popular special case which contains most pareto - type distributions ( hall , 1982 ) where for some constant @xmath111 @xmath112",
    "the limit @xmath111 can be incorporated in @xmath102 so that under the variance of the normal prior on @xmath40 can be taken as @xmath113 this is the choice of @xmath41 we will use throughout in practice , with @xmath81 estimated by the method proposed in fraga alves ( 2003 ) .",
    "we will also study the sensitivity of the method when replacing @xmath81 by @xmath114 , as used for instance in beirlant _ et al . _",
    "+   + denoting the bayesian estimators of ( @xmath32 ) using by @xmath115 , as in we then find the corresponding estimator for tail probabilities @xmath1 : @xmath116",
    "bayesian inference has a great advantage of incorporating in a unified way , any meaningful piece of information in describing our model parameters . here",
    "we use the objective mathematical information that with decreasing @xmath18 ( or increasing threshold @xmath9 ) the @xmath40 parameter becomes smaller , expressed by the variance of the normal prior on this parameter which is taken to be of order @xmath117 .",
    "we rely on modern markov chain monte carlo ( mcmc ) methods to assist in approximating posterior distributions . in order to make inference on @xmath38 we take the mode of the posterior samples , and the accuracy of this inference",
    "is described by the posterior distribution itself through the highest posterior density ( hpd ) region .",
    "the hpd for @xmath0 represents a set of most probable values of the @xmath118 , constituting @xmath119 of the posterior mass .",
    "the hpd also has the characteristic that the density within the hpd region is never lower than the values outside .",
    "the bayesian estimations are implemented via openbugs ( an open source version of bugs ) in the * r * ( r core team , 2014 ) statistical software .",
    "+   + in openbugs we need to specify the epd model likelihood , the parameter priors and starting values , then a markov chain simulation is automatically implemented for the resulting posterior distribution given in ( [ logpost ] ) .",
    "the epd is however not included in the standard distributions list available in openbugs , and we therefore indirectly implement the epd model likelihood using a poisson distribution .",
    "+   + let @xmath120 , where @xmath121 is the epd log - likelihood defined in ( [ logl ] ) .",
    "the epd model likelihood can be written as@xmath122 the resulting density @xmath123 therefore is a product of poisson distributed pseudo random variables with mean equal to the epd log - likelihood and with all observed values set equal to zero .",
    "this is known as the ` zero trick ' ( lunn _ et al .",
    "_ , 2012 ) .",
    "a positive constant @xmath111 is added to the mean to ensure that the mean of the pseudo random variables is positive .",
    "the resulting likelihood becomes@xmath124where @xmath111 is chosen such that @xmath125 .",
    "+   + in bugs the full probability model needs to be defined and hence all prior distributions need to be proper ( _ i.e. _ integrate to 1 ) .",
    "the left truncated normal prior on @xmath40 is proper and can be specified directly in openbugs .",
    "to ensure the mdi pareto prior on @xmath0 is proper , we write it as @xmath126and specify it in openbugs using a gamma distribution with a scale parameter equal to 1 and a shape parameter equal to 0.0001 .",
    "+   + values of @xmath81 close to 0 have to be avoided , and so we put a restriction on @xmath82 in our implementation , using @xmath127 .",
    "finally we also smooth the bayesian estimates as a function of @xmath18 with a moving average with a window width of 5 .",
    "we performed a simulation study , taking 1000 repetitions of samples of size @xmath128 studying the finite sample behaviour of @xmath129 and @xmath130 with @xmath131 for different distributions , using the estimator @xmath132 proposed by fraga alves _ et al . _",
    "( 2003 ) and the results are shown in figures 1 to 3 .",
    "the bias , variance and mse are plotted as a function of @xmath18 . in case of the tail probability estimators we consider the relative error in the variance and mse .",
    "+   + we compute the hpd using a direct approach of taking the shortest probability interval , given a @xmath133 coverage based on the simulations .",
    "we do this by ordering the @xmath134 simulation draws and then taking the shortest interval that contains @xmath135 of the draws .",
    "+ the following distributions are used :    * _ the frchet distribution _ with @xmath136 taking @xmath137 in which case @xmath138 . * _ the burr distribution _ with @xmath139 so that @xmath140 and @xmath141 . * _ the loggamma distribution _ with @xmath142 so that @xmath137 , which does not belong to the class @xmath20 .",
    "0.47   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * frchet * distribution with @xmath144 and @xmath138.,title=\"fig:\",width=302 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * frchet * distribution with @xmath144 and @xmath138.,title=\"fig:\",width=321 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * frchet * distribution with @xmath144 and @xmath138.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * frchet * distribution with @xmath144 and @xmath138.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * frchet * distribution with @xmath144 and @xmath138.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * frchet * distribution with @xmath144 and @xmath138.,title=\"fig:\",width=283 ]    0.47   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * burr * distribution with @xmath145 and @xmath141.,title=\"fig:\",width=302 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * burr * distribution with @xmath145 and @xmath141.,title=\"fig:\",width=321 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * burr * distribution with @xmath145 and @xmath141.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * burr * distribution with @xmath145 and @xmath141.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * burr * distribution with @xmath145 and @xmath141.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * burr * distribution with @xmath145 and @xmath141.,title=\"fig:\",width=283 ]    0.47   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * loggamma * distribution with @xmath144 and @xmath146.,title=\"fig:\",width=302 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * loggamma * distribution with @xmath144 and @xmath146.,title=\"fig:\",width=321 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * loggamma * distribution with @xmath144 and @xmath146.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * loggamma * distribution with @xmath144 and @xmath146.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * loggamma * distribution with @xmath144 and @xmath146.,title=\"fig:\",width=283 ]    0.45   ( left ) and estimates of the exceedance probability ( right ) using the bayesian estimates with @xmath143 and @xmath138 , the classical hill - weissman approach , and the epd - ml approach , in the case of a * loggamma * distribution with @xmath144 and @xmath146.,title=\"fig:\",width=283 ]    we conclude that the finite sample behaviour of the proposed estimators follows the characteristics predicted by the asymptotic analysis to a great extent . for small @xmath18 the bayesian estimators @xmath147 and",
    "@xmath148 show a similar behaviour as the hill and weissman estimators , while for larger @xmath18 the proposed estimators tend to follow the characteristics of the bias reduced epd - ml estimator .",
    "the mse of the bayesian estimator of @xmath1 is smallest , uniformly over the whole @xmath18 range and in all cases presented .",
    "concerning the estimation of @xmath0 , only in the frchet case and for small @xmath18 does the hill estimator show a smaller mse than the bayesian estimator , while @xmath149 then still shows a much smaller mse than the epd - ml estimator .",
    "+ also note that the version where the parameter @xmath81 is set to -1 does not differ too much from the use of the fraga alves _ et al . _",
    "( 2003 ) estimator . in case of the frchet distribution with @xmath138 , fixing this second order parameter at the correct value naturally yields some improvement in mse , especially at large values of @xmath18 . similarly , fixing @xmath81 at an incorrect value , as in the case of the selected burr distribution , yields larger mse values at large values of @xmath18 . + finally the results in case of the loggamma distribution are quite good .",
    "hence it appears that the proposed method exhibits some robustness against deviations from the underlying model .",
    "+   + in order to illustrate the use of the proposed method we consider the weekly negative log - returns for barclays plc as studied in reynkens _",
    "this data is divided in two sets , before and after the 2007 financial crisis :    * pre - crisis : from january 1,1994 to august 7 , 2007 , * post - crisis : from august 8,2007 to september 23 , 2014 .",
    "we consider the estimation of @xmath150 in both periods .",
    "whereas daily return data may suffer from serial dependence such as volatility clustering , such dependence is at least much weaker in weekly returns .",
    "we here use the proposed technique as a data analytic tool in order to assist the user in finding the relevant level of the estimate as a function of @xmath18 .",
    "up to the start of the crisis an 18% loss or higher appears to return on average once in 400 weeks ( one - sided exceedance probability 0.005 ) based on @xmath151 , while as from the start of the crisis this return level decreases to close to once in 50 weeks ( one - sided exceedance probability 0.04 ) based on @xmath152 .    1",
    "we proposed a simple adaptation to the bias reduction technique in tail estimation based on the epd , which yields interesting mse behaviour .",
    "in fact for larger thresholds the proposed estimators follow the behaviour of the classical hill and weissman estimators with small bias and minimal variance , while the new estimators are never worse than the ml estimators based on the epd approximation .",
    "in contrast to existing minimum variance bias reduced estimators which use third order tail conditions , the conditions can be kept minimal .",
    "in fact , setting the second order parameter @xmath153 at @xmath114 still yields acceptable results .    in future work extensions of this approach to other tail estimation problems will be investigated .",
    "* acknowledgment .",
    "* the authors take pleasure in thanking s. van der merwe for his valuable advice concerning the bayesian implementations .",
    "99    beirlant , j. , dierckx , g. , goegebeur , y. and matthys , g. , 1999 .",
    "tail index estimation and an exponential regression model .",
    "extremes , 2(2 ) , pp.177 - 200 .",
    "beirlant , j. , dierckx , g. , guillou , a. and starica , c. , 2002 . on exponential representations of log - spacings of extreme order statistics .",
    "_ extremes _ , 5(2 ) , pp.157 - 180 .",
    "beirlant , j. , goegebeur , y. , segers , j. and teugels , j. , 2004 .",
    "statistics of extremes : theory and applications . _",
    "wiley , chichester_.    beirlant , j. , figueiredo , f. , gomes , m.i . and vandewalle , b. , 2008 .",
    "improved reduced - bias tail index and quantile estimators .",
    "_ journal of statistical planning and inference _ , 138(6 ) , pp.1851 - 1870 .",
    "beirlant , j. , joossens , e. , segers , j. , 2009 .",
    "second - order refined peaks - over - threshold modelling for heavy - tailed distribution .",
    "_ journal of statistical planning and inference _ 139 , 2800 - 2815 .",
    "bingham , n.h . ,",
    "goldie , c.m . and teugels , j.l . , 1987 .",
    "regular variation .",
    "_ cambridge university press_.    caeiro , f. , gomes , m.i . and pestana , d. , 2005",
    ". direct reduction of bias of the classical hill estimator .",
    "_ revstat _ , 3(2 ) , pp.113 - 136 .",
    "caeiro , f. , gomes , m.i . and rodrigues , l.h . , 2009 .",
    "reduced - bias tail index estimators under a third - order framework . _",
    "communications in statistics  theory and methods _ , 38(7 ) , pp.1019 - 1040 .",
    "feuerverger , a. and hall , p. , 1999 .",
    "estimating a tail exponent by modelling departure from a pareto distribution . _",
    "the annals of statistics _ , 27(2 ) , pp.760 - 781 .",
    "fraga alves , m.i . , gomes , m.i . and",
    "de haan , l. , 2003 . a new class of semi - parametric estimators of the second order parameter .",
    "_ portugaliae mathematica _ , 60(2 ) , pp.193 - 214 .",
    "gomes , m.i . , martins , m.j . and",
    "neves , m. , 2007 . improving",
    "second order reduced bias extreme value index estimation .",
    "_ revstat _ , 5(2 ) , pp.177 - 207 .",
    "hall , p. , 1982 . on some simple estimates of an exponent of regular variation .",
    "_ journal of the royal statistical society .",
    "series b ( methodological ) _ , pp.37 - 42 .",
    "hill , b.m . , 1975 .",
    "a simple general approach to inference about the tail of a distribution . _ the annals of statistics _",
    ", 3(5 ) , pp.1163 - 1174 .",
    "lunn , d. , jackson , c. , best , n. , thomas , a. and spiegelhalter , d. , 2012 . _ the bugs book : a practical introduction to bayesian analysis_. crc press .",
    "peng , l. , 1998 .",
    "asymptotically unbiased estimators for the extreme - value index . _",
    "statistics & probability letters _ , 38(2 ) , pp.107 - 115 .",
    "reynkens , t. , beirlant , j. , de spiegeleer , j. , herrmann , k. , schoutens , w. ( 2015 ) . hunting for black swans in the european banking sector using extreme value analysis .",
    "9th international eva conference . ann arbor , mi , 14 - 19 june 2015 .",
    "weissman , i. , 1978 .",
    "estimation of parameters and large quantiles based on the k largest observations .",
    "_ journal of the american statistical association _ , 73(364 ) , pp.812 - 815 .",
    "_ derivation of the expressions of ( @xmath73 ) .",
    "_ first consider the asymptotic approximations of the mode - posterior estimator of @xmath0 based on maximization of with and . from - using expansions in @xmath154",
    "we obtain @xmath155 where @xmath156 is a constant only depending on @xmath157 and @xmath37 . also note that @xmath158",
    ". then @xmath159    _ derivation of theorem .",
    "_ assuming @xmath84 as @xmath64 , @xmath65 and @xmath85 we find using @xmath160 ( see theorem a.1 in beirlant et al . , 2009 ) that @xmath161 then , proceeding as in the proof of theorem 3.1 in beirlant et al .",
    "( 2009 ) , we obtain with @xmath162 , @xmath163 ( @xmath164 ) , that @xmath165 where @xmath166 . using theorem a.1 in beirlant et al .",
    "( 2009 ) , and follow under @xmath85 ."
  ],
  "abstract_text": [
    "<S> bias reduction in tail estimation has received considerable interest in extreme value analysis . </S>",
    "<S> estimation methods that minimize the bias while keeping the mean squared error ( mse ) under control , are especially useful when applying classical methods such as the hill ( 1975 ) estimator . in caeiro _ </S>",
    "<S> et al . _ </S>",
    "<S> ( 2005 ) minimum variance reduced bias estimators of the pareto tail index were first proposed where the bias is reduced without increasing the variance with respect to the hill estimator . </S>",
    "<S> this method is based on adequate external estimation of a pair of second - order parameters . here </S>",
    "<S> we revisit this problem from a bayesian point of view starting from the extended pareto distribution ( epd ) approximation to excesses over a high threshold , as developed in beirlant _ et al . _ </S>",
    "<S> ( 2009 ) using maximum likelihood ( ml ) estimation . </S>",
    "<S> using asymptotic considerations , we derive an appropriate choice of priors leading to a bayes estimator for which the mse curve is a weighted average of the hill and epd - ml mse curves for a large range of thresholds , under the same conditions as in beirlant _ et al . _ </S>",
    "<S> ( 2009 ) . </S>",
    "<S> a similar result is obtained for tail probability estimation . </S>",
    "<S> simulations show surprisingly good mse performance with respect to the existing estimators .    </S>",
    "<S> * keywords : *  extended pareto distribution , peaks over threshold , extreme value index , bayesian parameter estimation , bias reduction , posterior simulation . </S>"
  ]
}