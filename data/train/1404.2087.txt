{
  "article_text": [
    "to describe the static or dynamic properties of a macroscopic quantum system , typically only a few observables @xmath0 are deemed relevant  for example , the system s constants of the motion ( if static ) , slow observables ( if dynamic ) , or observables pertaining to some subsystem of interest . in statistical mechanics the system",
    "is then assigned that quantum state which , while reproducing the observed values @xmath1 of the relevant observables , maximizes the _ von neumann entropy _ @xmath2:=-\\mbox{tr}(\\mu\\ln\\mu )      ; \\label{vonneumann}\\ ] ] i.e. , its state  which i shall denote by @xmath3  is determined by the maximization @xmath4      , \\ ] ] where @xmath5 is short for the constraints @xmath6 .",
    "it has the _ gibbs form _",
    "@xmath7 with lagrange parameters @xmath8 and a constant of proportionality ( the inverse of the partition function ) chosen to ensure state normalization , @xmath9 .",
    "for ease of notation i adopted here the einstein convention that identical upper and lower indices are to be summed over . in the special case",
    "that only the system s energy is relevant , the set @xmath0 contains just the hamiltonian , and the associated lagrange parameter is the inverse temperature ; the gibbs state is then a canonical state . while they first arose in the context of statistical mechanics ,",
    "gibbs states nowadays play an important role also on smaller scales .",
    "for instance , they have been employed successfully in nanoscale thermodynamics @xcite , high energy physics @xcite , or incomplete quantum - state tomography @xcite",
    ".    why entropy maximization , and hence the use of the gibbs form , should be the proper paradigm for constructing the quantum state has been the subject of much debate . the classic textbook argument in statistical mechanics relies on an idealization , the thermodynamic limit : the system of interest is viewed as but one member of a fictitious infinite ensemble of identically prepared systems . if the global state of this fictitious ensemble is constrained by sharp values ( not expectation values ) for the totals of the relevant observables then the reduced state of any single member of the ensemble has the gibbs form @xcite .",
    "recent research suggests that one can do without such fictitious ensembles and derive the gibbs form just as well directly from a few generic assumptions , as long as the state in question pertains to a subsystem coupled to a sufficiently large environment @xcite .",
    "another popular argument invokes the intimate connection between entropy and information : by maximizing entropy , gibbs states discard to a maximal extent all information ( and thus retain no spurious bias ) as to irrelevant degrees of freedom ; so they carry information solely about the relevant ones .",
    "this insight is at the heart of the information - theoretic approach to statistical mechanics @xcite .",
    "yet another line of reasoning , going back to boltzmann s @xmath10 theorem @xcite , brings into play the system s effective dynamics on some coarse - grained level of description , in particular its tendency to increase entropy @xcite .",
    "such arguments rely on the existence of disparate time scales in the system @xcite .",
    "finally , some authors in both the statistics @xcite and physics @xcite communities have argued ( for the classical case only ) that the maximum entropy paradigm is mandated by logical consistency ; but this point of view remains controversial @xcite .    in the present paper",
    "i wish to add a different perspective .",
    "state construction via maximum entropy is a special instance of a much broader task : estimating a quantum state on the basis of imperfect data .",
    "experimental data are in fact never perfect , not even for simple systems , because the investigated samples have finite size , measurement devices have limited accuracy , and possibly  as is the case in statistical mechanics  the observables measured are not informationally complete .",
    "so in practice , data _ never _ specify a unique quantum state .",
    "rather , among the many states compatible with the data one must infer the most probable one , using suitable statistical estimation techniques .",
    "such techniques have become an indispensable tool for data analysis in modern quantum physics experiments and go by the name of _ quantum - state tomography _ @xcite .",
    "if the maximum entropy paradigm may be thus subsumed under the broader framework of quantum - state tomography then perhaps the latter can shed some light on the question as to when and how gibbs states arise .",
    "exploring the extent to which this is indeed possible , is the purpose of the present paper .",
    "consequently , i shall tackle the issue of gibbs states solely with the help of statistical methods from quantum - state tomography _ and nothing else ; _ in particular , without any recourse to the thermodynamic limit , environments , the concept of information , or dynamics .",
    "the remainder of the present paper is organized as follows . in sec .",
    "[ tomography ] , i will review some basic concepts of quantum - state tomography . in sec .",
    "[ sanov ] , i will focus on the situation where the experimental data come in the form of sample means of some informationally incomplete set of observables .",
    "i will show that in this case one can apply the quantum sanov theorem to find the asymptotics of the pertinent likelihood function . the subsequent sec .",
    "[ relevance ] is then crucial for the understanding of gibbs states : i will argue that the use of the gibbs form is tantamount to a statistical `` relevance hypothesis '' , for which i shall give a precise mathematical formulation . in sec .",
    "[ modelselection ] , i will discuss how the likelihood of this hypothesis and of possible rival hypotheses may be assessed in the light of experimental data . finally , in sec .",
    "[ discussion ] , i shall conclude with a brief summary and a few additional remarks .",
    "it is possible to know the precise state of an individual quantum system _ after _ a measurement : for instance , if measurement of some observable returns one of its non - degenerate eigenvalues then after the measurement , the system is known with certainty to be in the associated eigenstate .",
    "( precise knowledge of the post - measurement state hinges thus on precise knowledge of the measured observable . strictly speaking ,",
    "the latter presupposes additional preceding measurements . ) yet it is impossible to reconstruct , based on measurements on the individual system alone , its state _ before _ the measurement @xcite .",
    "such a reconstruction requires instead measurements on many identically prepared copies ; and even then , as the number of copies is always finite ( let alone the limited accuracy of measurement devices ) , can never be perfect .",
    "thus in practice , measurement never yields a unique quantum state .",
    "indeed , current experiments that implement quantum circuits or probe fundamental aspects of quantum information in many - body systems work with typical sample sizes of several hundreds or thousands , leading to statistical errors of up to @xmath11% @xcite . under these circumstances",
    "one can only aspire to identify among the many states compatible with the data the _ most probable _ one .",
    "this requires the use of suitable statistical estimation techniques and is the subject of _ quantum - state tomography _ @xcite .",
    "identical preparation of copies means that these form an _ exchangeable sequence _ @xcite .",
    "such a sequence has finite length @xmath12 , which may be chosen freely .",
    "it can be thought of as drawn randomly from a fictitious infinite sequence of systems whose order is irrelevant ( fig .",
    "[ exchangeable ] ) .",
    "exchangeability entails two basic properties for the @xmath12-body state @xmath13 of the sequence : ( i ) it is symmetric under permutation of the constituents ; and ( ii ) since the exchangeable sequence of length @xmath12 can always be considered a subsequence of a longer , equally exchangeable sequence of length @xmath14 , the state @xmath13 can be written as a marginal of @xmath15 .",
    "quantum systems by drawing randomly @xmath12 systems from a fictitious infinite symmetric sequence . ,",
    "width=321 ]    exchangeability is more than mere symmetry .",
    "for example , the @xmath16-body density matrix @xmath17 associated with the bell state @xmath18 is invariant under permutation of the constituents and hence meets the symmetry criterion ; yet it can not be written as the marginal of an equally symmetric @xmath19-body state and thus fails to meet the second criterion for exchangeability .",
    "exchangeable is also not the same as independent and identically distributed ( i.i.d . ) : in general , it is @xmath20 .",
    "rather , by a quantum generalization @xcite of the classical de finetti theorem @xcite , the state of an exchangeable sequence can always be represented as an incoherent mixture of i.i.d .",
    "sequences @xmath21 ,",
    "@xmath22 with respective weights @xmath23 , where the integral is over all normalized single - particle states .",
    "conversely , any state of this form describes an exchangeable sequence .",
    "the de finetti representation shows that an exchangeable sequence may well exhibit classical correlations .",
    "however , it never exhibits entanglement .",
    "exchangeable sequences are the `` raw material '' of quantum - state tomography .",
    "the uncertainty about the state of an individual constituent is reflected in the density function @xmath23 ; the latter may be considered ( in somewhat loose terminology @xcite ) the probability distribution for the unknown single - constituent state . to learn more about this state , a sample of size @xmath24 ( @xmath25 )",
    "is taken from the exchangeable sequence and a measurement performed on it , yielding data @xmath26 . afterwards",
    "the remaining @xmath27 systems ( i.e. , the original sequence minus the sample ) still form an exchangeable sequence whose state has the above de finetti representation ; yet the probability distribution featuring in this de finetti representation must be updated according to a quantum generalization of _ bayes rule _",
    "@xcite , @xmath28 where the probabilities denote ( from left to right ) the posterior , likelihood function , and prior , respectively , and the constant of proportionality is independent of @xmath29 .",
    "this bayesian update encapsulates the process of _ learning _ from sample data ( fig .",
    "[ learning ] ) .    upon investigation of additional samples",
    ", bayes rule is iterated , leading to consecutive updates of the posterior . as more and more data accumulate  by investigating more samples or increasing their sizes  the posterior narrows until eventually its width falls below some desired error bound . then within this error ,",
    "the location of the posterior peak is the best estimate for the unknown quantum state .",
    "in the hypothetical limit of infinite sample size , informationally complete measurements and perfectly accurate measurement devices the posterior converges towards the likelihood function , which in turn approaches a delta function .",
    "the state estimate is then determined  to perfect accuracy  by experimental data only and becomes independent of the prior .",
    "( it is the fact that this is possible , at least in principle , which gives operational meaning to the notion of `` state '' . ) against this backdrop many state estimation techniques focus from the outset on the likelihood function , equating the location of its peak with the most plausible state estimate ; such techniques fall into the class of _ maximum likelihood _",
    "methods @xcite .",
    "in contrast , methods that take into account the residual influence of the prior ( which in practice is always present and for small samples may be quite significant ) are termed _ bayesian _ @xcite .    strictly speaking , even in the above hypothetical limit the posterior coincides with the likelihood function only if the prior has support on the entire state space .",
    "the prior reflects any theoretical constraint or bias that one may have , prior to measurement , as to the parametric form or parameter values of the quantum state .",
    "as long as one knows nothing or little about the state _ a priori _ , this prior is broad and indeed has full support . but as soon as one has advance knowledge that constrains the quantum state to some finite region or proper submanifold of state space , the prior has support on this region or submanifold only ; and so will the posterior , _ regardless of the data _ @xcite . in sec .",
    "[ relevance ] , i shall argue that such _ a priori _ restrictions play an important role in the understanding of gibbs states .     in single - constituent state space .",
    "if , say , on theoretical grounds one expects the members of the sequence to be in a state close to @xmath30 then this prior will be peaked around @xmath30 .",
    "it has a finite width reflecting the finite degree of confidence in this prior bias .",
    "( 2 ) investigation of a sample yields data @xmath26 . associated with these data",
    "is a likelihood function @xmath31 , typically peaked around some other state which might be close to , but is usually not equal to @xmath30 .",
    "the likelihood function , too , has a finite width , reflecting the finite size @xmath24 of the sample ( and possibly other sources of error ) .",
    "( 3 ) according to bayes rule , multiplying the prior with the likelihood function yields the posterior @xmath32 .",
    "the latter is typically narrower than the prior , reflecting the growing confidence in the state estimate as experimental data accumulate .",
    "the center of the posterior has shifted from the original bias @xmath30 to a new state interpolating between @xmath30 and the center of the likelihood function .",
    ", width=302 ]",
    "i suppose that the experimental data consist in a set of sample means @xmath33 gleaned from a sample of large but finite size @xmath24 .",
    "these sample means may have been obtained directly by measurement of the pertinent observables @xmath34 , or inferred indirectly from other data @xmath26  a possibility which is particularly relevant when the sample means pertain to observables that do not commute . in the latter case",
    "i shall say that the observed data @xmath26 `` encompass '' sample means @xmath33 if and only if the set of states compatible with the data , @xmath35 ( up to some finite error parameter @xmath36 , @xmath37 , which is independent of sample size ) , _ contains _ the set of states yielding expectation values @xmath38 ; in short , @xmath39 .",
    "when the set @xmath40 is large , the data might encompass not just @xmath33 but also different values @xmath41 for the sample means ( fig .",
    "[ compatible ] ) . on the other hand ,",
    "if the set @xmath40 contains only @xmath42 but no other @xmath43 , and is moreover the smallest set to do so , then i shall say that the data _ amount to _ having measured the sample means @xmath42 . with this understanding",
    ", the likelihood of measuring sample means @xmath42 reads @xmath44     contains all states compatible ( up to some error @xmath36 ) with observed data @xmath26 ( shaded area ) . in order to encompass sample means",
    "@xmath33 this set must contain all states yielding @xmath45 ( solid line ) . in the above example",
    ", @xmath40 is so large that it also encompasses other values @xmath41 for the sample means ( dashed line ) .",
    ", width=302 ]    defined in the above way , the likelihood generally depends on the error parameter @xmath36 . for large sample sizes",
    "@xmath24 , however , the infimum on the right - hand side behaves asymptotically as @xmath46\\ ] ] and hence loses its dependence on @xmath36 ; this follows from the quantum generalization @xcite of the classical sanov theorem @xcite . here",
    "@xmath47 denotes the relative entropy of the two states @xmath48 and @xmath29 @xcite . in other words , for large @xmath24",
    "the likelihood function behaves as @xmath49 \\label{likelihood}\\ ] ] with @xmath50 independently of @xmath36 . due to its close connection to the quantum sanov theorem",
    ", i shall call this asymptotic likelihood the _",
    "sanov likelihood_. the state @xmath51 which , under given constraints on the expectation values @xmath52 , minimizes the relative entropy with respect to the `` reference state '' @xmath29 has the generalized gibbs form @xcite @xmath53 \\label{generalized_gibbs}\\ ] ] with lagrange parameters @xmath54 and the constant of proportionality again chosen to ensure @xmath55 .",
    "there is the special case where the sample means @xmath33 are informationally complete . in this case",
    "the data determine a unique tomographic image ( i.e. , center of the likelihood function ) @xmath48 , the sole state to yield @xmath38 .",
    "the quantum sanov theorem then reduces to the quantum stein lemma @xcite , and the asymptotic likelihood function becomes @xmath56      .",
    "\\label{stein_likelihood}\\ ] ] i call this the _ stein likelihood_. thanks to a mixing rule for the relative entropy @xcite , the stein likelihood satisfies @xmath57 with a constant of proportionality that does not depend on the state @xmath29 .",
    "so for the purposes of bayesian updating via eq .",
    "( [ bayesrule ] ) , obtaining first a tomographic image @xmath48 from a sample of size @xmath24 and subsequently a tomographic image @xmath58 from another sample of size @xmath59 is tantamount to obtaining the weighted average of @xmath48 and @xmath58 from the combined sample of size @xmath60 ; sequential or joint processing of the data both yield the same posterior . in other words , in the asymptotic limit",
    "considered here it does not matter how the system copies under investigation are grouped into samples .",
    "the statement : `` the observables @xmath0 are relevant '' entails two distinct assertions : ( i ) the expectation values of the @xmath0 completely determine the state estimate ( and all predictions following from it ) ; and ( ii ) any update of this state estimate is determined by additional data pertaining to the @xmath0 only , and not by any other data .",
    "( this notion of `` relevance '' is similar to the notion of `` consistency '' invoked  in the classical case and for one special set of observables only  in ref .",
    "@xcite . ) in this section , i shall prove that the relevance hypothesis imposes on the state estimate the gibbs form ( [ canonical ] ) .",
    "the first assertion implies that there must exist an algorithm @xmath61 assigning to any set of expectation values @xmath62 a unique state @xmath29 .",
    "this algorithm need not necessarily be the maximum entropy algorithm . more generally , when the expectation values @xmath1 are not known exactly but only their probability distribution @xmath63 then there must exist an algorithm assigning to this probability distribution a unique probability distribution of states , @xmath64 .",
    "i will now show that the second , logically independent assertion singles out the maximum entropy algorithm , and hence the gibbs form ( [ canonical ] ) . in my proof",
    "i will invoke various states and sets of states which are illustrated in fig .",
    "[ relevance ] .",
    "let a tomographic measurement on a sample of large but finite size @xmath24 come in two versions , one informationally complete and the other informationally incomplete . whereas the complete version returns a unique tomographic image @xmath48 , the incomplete version merely returns sample means @xmath1 for the observables @xmath0 .",
    "the latter are consistent with the former , @xmath65 .",
    "if indeed the observables @xmath0 are the relevant ones then by the second assertion , it must not make a difference which of the two data sets , complete or incomplete , is processed in the bayesian update ( [ bayesrule ] ) . both must yield the same posterior , and so it must hold that @xmath66 with a constant of proportionality that does not depend on @xmath29 .",
    "this requirement can only be met if either the prior @xmath23 vanishes or else , by eqs .",
    "( [ likelihood ] ) ( with @xmath67 ) and ( [ stein_likelihood ] ) , the difference of relative entropies @xmath68 $ ] is independent of @xmath29 . by the law of pythagoras for the relative entropy @xcite , this difference is itself a relative entropy , @xmath69 it ought to have the same value for all @xmath29 that have a non - vanishing prior probability .",
    "let @xmath30 be one specific such state with non - vanishing prior probability .",
    "then for all other @xmath29 , it must hold that @xmath70 in the special case @xmath71 it is @xmath72 and hence also @xmath73 , so the left - hand side vanishes .",
    "then so must the right - hand side , and therefore @xmath74 regardless of the experimental data , the admissible states ( @xmath75 ) are restricted _ a priori _ to gibbs states of the generalized form ( [ generalized_gibbs ] ) , with reference state @xmath30 and @xmath76 .    ; whereas the incomplete version merely returns sample means @xmath77 for the informationally incomplete set of observables @xmath0 .",
    "the state @xmath48 is one out of the many states yielding @xmath78 ( left black line ) .",
    "an arbitrary state @xmath29 yields expectation values @xmath79 , as do all other states that lie on the right black line .",
    "states which minimize the relative entropy with respect to @xmath29 , while satisfying given constraints on the expectation values @xmath80 , form a proper submanifold of state space ( upper grey line ) ; for @xmath78 , the pertinent state is @xmath81 . according to bayes rule ,",
    "the posterior state estimate depends not only on the data but also on the prior .",
    "in particular , any estimate must be among the states with a non - vanishing prior probability ( dotted line ) .",
    "let the latter include some specific state @xmath30 .",
    "states which minimize the relative entropy with respect to this @xmath30 , while satisfying constraints on the @xmath80 , form another submanifold ( lower grey line ) ; for @xmath78 and @xmath82 the pertinent states are @xmath83 and @xmath84 , respectively .",
    "if the relevance hypothesis holds then this last submanifold contains all states with non - vanishing prior probability ; so the lower grey line in fact covers the dotted line .",
    ", width=302 ]    the reference state @xmath30 may be any state that has a non - vanishing prior probability . among the states with non - vanishing prior probability",
    "there is usually ( albeit not necessarily always ) the totally mixed state .",
    "if so , it will be most convenient to choose @xmath30 to be the totally mixed state .",
    "with the totally mixed state as the reference state , minimizing the relative entropy becomes equivalent to maximizing the ordinary von neumann entropy ; and then the generalized gibbs form ( [ generalized_gibbs ] ) reduces to the ordinary gibbs form ( [ canonical ] ) , q.e.d .",
    "the relevance hypothesis has significant implications for quantum - state tomography .",
    "it affects both the location ( in state space ) and the accuracy of the posterior state estimate : given the same data , different choices for the set of relevant observables generally lead to different state estimates with different degrees of confidence .",
    "this can be illustrated with the simple example of state tomography on an exchangeable sequence of qubits .",
    "the state space of a single qubit is the bloch sphere , with the totally mixed state at its origin .",
    "let an incomplete tomographic measurement probe the pauli spin component @xmath85 , yielding sample mean @xmath86 .",
    "associated with this data is a likelihood function on the bloch sphere .",
    "it is broad on the two - dimensional plane containing states that yield @xmath87 and narrowly peaked in the direction perpendicular to this plane , the latter width decreasing with increasing sample size .",
    "considering solely this likelihood function would lead to a maximum - likelihood state estimate equal or close to @xmath88 .",
    "however , as i discussed in sec . [ tomography ]",
    ", one must take into account also the prior ; and in particular , whether the prior has support on the entire bloch sphere or on some subspace only .",
    "for the present example i shall consider three cases : ( i ) all observables are relevant in the sense defined above ; ( ii ) only @xmath85 is relevant ( say , because the physical qubit is a spin in a ferromagnet which is strongly anisotropic in the @xmath89 direction ) ; or ( iii ) only @xmath90 is relevant .",
    "whereas in the first case the prior has support on the entire bloch sphere , in the other two cases it has support only on the @xmath89 or @xmath91 axis , respectively . on the respective support , in the absence of further information ,",
    "the prior is some broad symmetric distribution around the origin of the bloch sphere .",
    "multiplying the respective priors with the likelihood function yields the respective posteriors .",
    "these posteriors vary strongly from case to case ; they are depicted schematically in fig .",
    "[ fig_blochsphere ] .    ) of the bloch sphere .",
    "the dashed line at @xmath92 indicates states yielding @xmath87 , the observed sample mean .",
    "the shaded areas indicate location and width of the posterior when the relevant observables comprise ( 1 ) all observables ; ( 2 ) only @xmath85 ; or ( 3 ) only @xmath90 . in the first two cases",
    "the resultant state estimate ( center of the posterior ) lies somewhere between initial bias ( totally mixed state ) and data , the precise location depending on the size of the sample .",
    "the two cases differ in the degree of confidence as to the unmeasured observable @xmath90 . in the third case",
    "the posterior equals the prior because the data carry no information about the then relevant observable @xmath90 .",
    ", width=302 ]",
    "in the preceding section i have shown how the relevance hypothesis constrains state estimates _ a priori _ to the gibbs form ( [ canonical ] ) , and how this affects quantum - state estimation .",
    "one may wonder what in turn justifies the relevance hypothesis , and to which set of observables it should apply .",
    "first of all , it is important to note that the relevant observables do not necessarily coincide with the observables which are being measured in an experiment ; an observable is not relevant simply because one happens to measure it . in the example considered above the observable @xmath85",
    "was measured . and",
    "if the physical qubit was a spin in a strongly anisotropic ferromagnet with preferred direction along the @xmath89 axis then indeed , the observable @xmath85 would also be the relevant one .",
    "but if the preferred direction of the ferromagnet was along the @xmath91 axis , the relevant observable would be @xmath90 rather than @xmath85  even though @xmath85 was measured . rather than the experimental setup ,",
    "the relevance hypothesis reflects prior knowledge about the _ physics _ of the system .",
    "as is familiar from statistical mechanics , the choice of relevant observables is usually linked to time scales : if the system is in equilibrium then the relevant observables comprise the system s constants of the motion ; or else , provided the system s degrees of freedom evolve on two or more disparate time scales , the slow observables @xcite .",
    "the above warning notwithstanding , identifying measured with relevant observables is precisely what is being done  implicitly  in maximum - entropy quantum state estimation @xcite .",
    "this shortcut ( which is usually not spelt out as such ) actually often works because for an observable to be measurable in practice , it must vary slowly ; and as long as the system exhibits a clear hierarchy of time scales , `` slow '' means indeed `` relevant '' .    yet when one investigates a hitherto unknown substance , a hierarchy of time scales or other clues as to the relevant observables are not available _ a priori ; _ nor is there any assurance that the shortcut `` measured = relevant '' is warranted .",
    "in such a situation one can only formulate conjectures as to the set of relevant observables . the relevance hypothesis",
    "then becomes truly a _ hypothesis _ in the statistical sense , subject to experimental scrutiny and possibly refutation .",
    "there might be several competing hypotheses , perhaps even including the hypothesis that the system can not be described by gibbs states at all  that is , unless the set of relevant observables is extended to become informationally complete , in which case _ all _ observables would be relevant .",
    "every proposal as to the set of relevant observables constitutes a _ statistical model , _ in the sense that state estimates are constrained to a certain parametric form ( gibbs form ) with a certain number of adjustable parameters ( lagrange parameters ) . choosing among rival proposals in the light of the experimental data then becomes an instance of statistical _",
    "model selection_. it is this scenario on which i shall focus in the present section .    first , some general remarks about statistical model selection may be in order .",
    "in general , rival statistical models for the same experimental data differ in the number and type of adjustable parameters . on the one hand ,",
    "a model ought to be in good agreement with the data , which is best achieved with a large number of adjustable parameters ; yet on the other hand , excessive complexity must be avoided ( `` occam s razor '' ) . the purpose of model selection is to render this trade - off quantitative .",
    "how this works in practice can be illustrated with a simple textbook example @xcite .",
    "let @xmath93 be a simple model without adjustable parameter and @xmath94 a more complex model with one adjustable parameter @xmath95 .",
    "which model is to be preferred on the basis of data @xmath26 will be determined by the ratio of their respective posterior probabilities .",
    "due to bayes rule , this ratio is given by @xmath96 as long as one does not have any strong _ a priori _ preference for either of the models the right - hand side will be dominated by the first factor , the ratio of likelihoods . by the law of total probability ,",
    "the likelihood function of model @xmath94 reads @xmath97 let @xmath98 be that value of the adjustable parameter which yields the best fit with the experimental data .",
    "then the first factor in the integral , considered as a function of @xmath95 , will be peaked around a maximum at @xmath98 ; a typical shape is a gaussian @xmath99\\ ] ] of some width @xmath100 .",
    "this width indicates the accuracy to which the parameter @xmath95 is known after processing the experimental data .",
    "in contrast , the second factor in the integral describes the distribution of @xmath95 _ prior _ to processing the data ; this _ a priori _ distribution has a larger width @xmath101 . provided the best fit @xmath98 lies within the _ a priori _ expected range , the ratio of likelihoods will scale as @xmath102 the first ratio on the right - hand side is typically smaller than one , favoring the more complex model @xmath94 because thanks to its adjustable parameter , @xmath94 can achieve a better fit with the data .",
    "in contrast , the second ratio @xmath103 is larger than one , favoring the simpler model @xmath93 ; this is the quantitative manifestation of occam s razor .",
    "it is thus the relative size of these two ratios which will tip the balance in favor of one specific model .",
    "the same logic applies to the identification of the most plausible set of relevant observables on the basis of experimental data .",
    "details of the pertinent statistical analysis have been spelt out by the author ( in a different context ) in previous publications for two basic scenarios . in the first scenario @xcite ,",
    "different hypotheses as to the set of relevant observables are formulated _ prior _ to experiment , and subsequently the experiment is performed on a single sample only . in the second scenario @xcite , which resembles more closely the way an unknown substance is investigated in practice , measurements are performed first , before formulating any hypotheses .",
    "moreover , measurements are performed not just on a single sample but on multiple samples of the same unknown substance .",
    "these samples need not  in fact , ought not  be in the same state .",
    "yet it is hypothesized that for all these samples the _ same _ set of observables is relevant .",
    "their respective states should therefore all lie in the same submanifold of gibbs states , possibly with varying values for the associated lagrange parameters .",
    "for instance , the samples might all have been brought into contact with heat baths at different temperatures .",
    "then one hypothesis might say that they are now all in canonical states , the hamiltonian ( identical for all samples ) being the sole relevant observable , with only the temperature varying across samples .",
    "another hypothesis might say that beyond the hamiltonian there are further constants of the motion ( again identical for all samples ) which need to be added to the set of relevant observables , increasing the number of adjustable lagrange parameters . and",
    "a third , extreme hypothesis might claim that the samples have not thermalized fully , and that hence a gibbs form is not justified and _ all _ observables remain relevant . as in the textbook example above , increasing thus the number of adjustable parameters will lead to a successively better fit with the experimental data , yet at the expense of simplicity .",
    "again , goodness - of - fit has to be traded off against simplicity in a quantitative fashion .",
    "the optimal trade - off yields the most plausible set of relevant observables .    here",
    "i briefly summarize the key findings of the quantitative analysis ; details have been reported in ref .",
    "various differently prepared samples are subjected to the same tomography which , if not complete , must encompass at least all candidates for relevancy .",
    "let the @xmath104-th sample have large but finite size @xmath105 , and let tomography on this sample render the tomographic image @xmath106 .",
    "( in case the tomography is not complete , the image @xmath106 is constructed via ordinary maximum - entropy state estimation . ) assuming that the finite sample size is the principal source of noise , error bars on the measurements are of the order @xmath107 .",
    "as before , let @xmath30 be a reference state ( usually the totally mixed state ) with non - vanishing prior probability , and let @xmath108 denote the hypothesis that for all samples the @xmath109 observables @xmath110 are the relevant ones in the sense defined above . given this hypothesis , states are constrained _ a priori _ to gibbs states of the generalized form @xmath111 . for a tomographic image @xmath106 the closest such state is the state @xmath112 , where @xmath113 ( fig .",
    "[ assess ] ) . in terms of these variables , and under certain reasonable additional assumptions spelt out in ref .",
    "@xcite , the log - likelihood of the hypothesis @xmath108 behaves asymptotically as @xmath114 modulo additive constants that do not depend on the choice of relevant observables . here",
    "@xmath26 is short for the totality of experimental data .",
    "as long as there is no strong _ a priori _ preference for a specific set of relevant observables , the difference of log - likelihoods of rival hypotheses dominates their relative posterior probabilities .",
    "the above formula for the log - likelihood reflects in a quantitative fashion the expected trade - off between goodness - of - fit and simplicity .",
    "on the right - hand side there are two contributions , both with a negative sign and thus `` penalizing ''  in terms of likelihood  the hypothesis @xmath108 .",
    "the first contribution penalizes a bad fit to the data : the further the gibbs states @xmath115 are away from the original tomographic images @xmath106 , the larger the relative entropies @xmath116 , and hence the larger the penalty . to avoid this penalty , the set of relevant observables",
    "should be chosen sufficiently large .",
    "in contrast , the second contribution embodies occam s razor , penalizing excessive complexity : the larger the number @xmath109 of relevant observables , the larger the penalty . in order to avoid the latter penalty , the set of relevant observables",
    "should be kept as small as possible .",
    "so in line with our general considerations , one must trade off these two penalties in order to find the most likely set of relevant observables .    .",
    "the relevance hypothesis , which is to be tested , claims that all data can be modelled on a joint manifold of gibbs states ( grey line ) with reference state @xmath30 .",
    "if so , the gibbs state closest to a tomographic image @xmath106 is the state @xmath115 ( open dot ) .",
    "both states yield for the relevant observables the same expectation values @xmath117 , i.e. , they both belong to the set of states yielding @xmath118 ( black line ) . ,",
    "width=302 ]    in sum , in the absence of any prior knowledge about time scales or other clues as to the set of relevant observables , the most likely set can be determined via the above statistical analysis .",
    "the use of the associated gibbs form is then corroborated by the tomographic data only .",
    "in the preceding sections i explored the extent to which the use of gibbs states can be understood with the help of methods from quantum - state tomography .",
    "these methods apply to systems that are finite and isolated ; hence they require neither the limit @xmath119 nor auxiliary concepts such as infinite ensembles or large environments .",
    "( however , i did assume that sample sizes are large enough to justify the use of the asymptotic sanov likelihood to good accuracy .",
    ") moreover , they refrain from invoking information - theoretical arguments or exploiting the system s dynamics .    without any knowledge of the system s dynamics or other clues as to the relevant observables , of course",
    ", it is impossible to derive a gibbs form from first principles .",
    "rather , in this situation the gibbs form constitutes a statistical _ hypothesis _ that can be supported or refuted only by data . in sec .",
    "[ relevance ] , i gave a precise formulation of the relevance hypothesis which is behind the use of the gibbs form . and",
    "in sec . [ modelselection ] , i outlined the statistical tools needed to test this hypothesis in the light of experimental data .",
    "taken together , the statistical methods discussed in this paper comprise a toolbox which can be used to ascertain ( i ) whether a hitherto unknown substance , of which in particular the dynamics and the constants of the motion are not known , can be described by gibbs states at all ; and if so , ( ii ) which observables are most likely the relevant ones .",
    "the pertinent statistical analysis is based entirely on the tomographic data gleaned from a collection of differently prepared , finite samples .",
    "it focuses on the relative likelihoods rather than posterior probabilities of rival hypotheses .",
    "the former are a good proxy for the latter as long as there is no prior knowledge , and hence no _ a priori _ bias in favor of any particular hypothesis .",
    "once the set of relevant observables , valid for the entire collection of samples , has been established , there remains the statistical task of estimating the values of the pertinent lagrange parameters for any given _",
    "individual _ sample .",
    "this is an interesting subject in itself , which has been dealt with elsewhere @xcite .",
    "61ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ]  + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty link:\\doibase 10.1080/09500340408231829 [ * * ,   ( ) ] link:\\doibase 10.1209/epl / i2004 - 10101 - 2 [ * * ,   ( ) ] link:\\doibase 10.1007/s10955 - 005 - 8015 - 9 [ * * ,   ( ) ] link:\\doibase 10.1140/epjc / s10052 - 008 - 0671-x [ * * ,   ( ) ] link:\\doibase    10.1080/09500349708231905 [ * * ,   ( ) ]",
    "link:\\doibase    10.1006/aphy.1998.5802 [ * * ,   ( ) ] link:\\doibase    10.1016/s0960 - 0779(98)00144 - 1 [ * * ,   ( ) ] link:\\doibase 10.1080/09500340008232199 [ * * ,   ( ) ] link:\\doibase 10.1007/978 - 3 - 540 - 44481 - 7_6 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.65.053410 [ * * ,   ( ) ] link:\\doibase    10.1038/nature07288 [ * * ,   ( ) ] link:\\doibase 10.1016/s0003 - 4916(87)80006 - 4 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.96.050403 [ * * ,   ( ) ] link:\\doibase 10.1038/nphys444 [ * * ,   ( ) ] link:\\doibase 10.1103/physrev.106.620 [ * * , ( ) ] link:\\doibase 10.1103/physrev.108.171 [ * * , ( ) ] @noop _ _  ( ,  ) @noop _ _  ( ,  ) @noop * * ,   ( ) link:\\doibase 10.1103/physrevlett.101.190403 [ * * ,   ( ) ] link:\\doibase 10.1103/physreve.79.061103 [ * * ,   ( ) ] link:\\doibase 10.1088/1367 - 2630/13/5/053009 [ * * ,   ( ) ] link:\\doibase 10.1103/physrevlett.108.080402 [ * * ,   ( ) ] link:\\doibase 10.1016/0370 - 1573(95)00077 - 1 [ * * ,   ( ) ] @noop * * ,   ( ) in  @noop _ _ ,  ( ,  )  pp .",
    "link:\\doibase 10.1103/physrevlett.52.1357 [ * * ,   ( ) ] link:\\doibase 10.1016/1355 - 2198(95)00015 - 1 [ * * ,   ( ) ] link:\\doibase 10.1016/1355 - 2198(95)00022 - 4 [ * * ,   ( ) ] link:\\doibase 10.1007/b98673 [ * * ,   ( ) ] link:\\doibase 10.1088/1367 - 2630/15/12/125020 [ * * ,   ( ) ] @noop * * ,   ( ) link:\\doibase 10.1038/nature04279 [ * * ,   ( ) ] @noop * * ,   ( ) @noop _ _  ( ,  ) link:\\doibase 10.1103/physreva.64.014305 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.55.r1561 [ * * , ( ) ] link:\\doibase 10.1103/physreva.64.052312 [ * * ,   ( ) ] link:\\doibase 10.1007/b98673 [ * * ,   ( ) ] link:\\doibase 10.1088/1367 - 2630/11/2/023028 [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.82.012104 [ * * , ( ) ] link:\\doibase 10.1103/physreva.84.012101 [ * * , ( ) ] link:\\doibase 10.1063/1.3109948 [ * * , ( ) ] link:\\doibase 10.1088/0305 - 4470/35/50/307 [ * * ,   ( ) ] link:\\doibase 10.1007/s00220 - 005 - 1426 - 2 [ * * ,   ( ) ] link:\\doibase 10.1007/s00220 - 008 - 0417 - 5 [ * * ,   ( ) ] @noop * * ,   ( ) @noop _ _ ,  ed .",
    "( , ) @noop _ _ ( ,  ) link:\\doibase 10.1016/0034 - 4877(76)90050 - 1 [ * * ,   ( ) ] link:\\doibase 10.1103/revmodphys.50.221 [ * * , ( ) ] link:\\doibase 10.1007/bf01212339 [ * * ,   ( ) ] link:\\doibase 10.1103/revmodphys.74.197 [ * * , ( ) ] link:\\doibase 10.1016/0034 - 4877(88)90009 - 2 [ * * ,   ( ) ] link:\\doibase 10.1007/bf02100287 [ * * , ( ) ] link:\\doibase 10.1109/18.887855 [ * * ,   ( ) ] link:\\doibase 10.1007/s00220 - 010 - 1005-z [ * * ,   ( ) ] link:\\doibase 10.1103/physreva.84.052101 [ * * , ( ) ] link:\\doibase 10.1007/978 - 3 - 540 - 74636 - 2 [ _ _ ]  ( ,  ) link:\\doibase 10.1016/0167 - 2789(93)90241-r [ * * ,   ( ) ] @noop _ _  ( ,  )"
  ],
  "abstract_text": [
    "<S> i investigate the extent to which the description of quantum systems by gibbs states can be justified purely on the basis of tomographic data , without recourse to theoretical concepts such as infinite ensembles , environments , information , or to the systems dynamics . </S>",
    "<S> i show that the use of gibbs states amounts to a relevance hypothesis , which i spell out in detail . </S>",
    "<S> this hypothesis can be subjected to statistical hypothesis testing and hence assessed on the basis of the experimental data . </S>"
  ]
}