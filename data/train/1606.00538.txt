{
  "article_text": [
    "in robotics , automating the grasping of ordinary objects is an important open problem  @xcite .",
    "much progress has been made both on the hardware side ( the gripper itself ) and on the perception side .",
    "the development of compliant or under - actuated mechanical grippers  often referred to as `` mechanical intelligence ''  which passively adapt their shape to the grasped object has greatly simplified the problem  @xcite .",
    "however , determining good grasping locations still requires an efficient perception system .",
    "the advent of microsoft kinect inexpensive 3d camera opened the door to rapid deployment of new and robust approaches in identifying such locations .",
    "its market accessibility and ease - of - use provided a straightforward solution for incorporating depth and rgb information ( called rgbd images ) into deployed systems of various industrial settings .    ) , width , height and its angle @xmath0 from the x - axis .",
    "the blue edges indicate the gripper plate location and the red edges show the gripper opening , prior to grasping . ]    in this paper , we look at identifying grasping locations for two plates parallel grippers , by employing such rgbd images . as representation of a grasping location ,",
    "we use jiang _ et al .",
    "_ 5-dimensional _ grasp rectangle _",
    "@xcite from which the 7-dimensional gripper configuration can be easily computed .",
    "the 2d oriented rectangle , shown in fig .",
    "[ fig : grasping_rectangle ] , indicates the gripper s location , orientation and physical limitations : @xmath1 using the grasp rectangle representation makes grasp recognition analogous to object recognition ( bounding box approaches ) , and soon for detection . for grasp recognition ,",
    "the goal is to determine whether a grasp rectangle @xmath2 is a good or bad candidate . for grasp detection ,",
    "the goal is to predict the configuration of the best rectangle @xmath3 . in this particular",
    "setting , identifying grasping locations can then be seen as a vision problem .",
    "this is particularly advantageous because several break - through works on similar vision - oriented problems have been proposed in past decades , and can thus be exploited for detecting grasping locations .",
    "although compelling due to its small cost and ease - of - use , the microsoft kinect ( and most structured - light devices ) has some drawbacks .",
    "one is the presence of two types of noise in depth information : the axial and lateral noise model of the object distance to the camera , and the mask noise model of missing 3d information . while vision - based approaches can reasonably deal with the former",
    ", the latter can be particularly cumbersome .",
    "objects with shiny surfaces often cause structured - light 3d cameras to fail which results in absence of information . to cope with this phenomenon ,  @xcite had to develop different mask - based regularization terms to solve their multi - layer neural network convergence problems caused by using zeros as masked - out entry values . with our approach",
    ", we seek to create a theoretically founded grasp localization model which can address the kinect mask noise inherently , without resorting to a custom regularization .",
    "the second drawback of microsoft kinect is the lack of available large scale rgbd grasp datasets , which makes training high - dimensional models cumbersome . as an example ,  @xcite previously applied a convolutional neural network ( cnn ) for detecting grasp candidates that contained more than a million parameters . due to the relative small amount of rgbd images in their grasp dataset ( the cornell dataset )",
    ", they had to pre - train the cnn for several days on imagenet ( a rgb image dataset ) and fine - tune for several hours on the cornell one . in an industrial context where datasets are small and new objects are regularly added ,",
    "a fast and robust training phase is essential . in particular ,",
    "an efficient strategy to make objects easier to grasp is to add more images from different viewpoints and retrain , hence the importance of fast training phase .    to satisfy the aforementioned requirements",
    ", we looked at employing dictionary learning and sparse representations ( dlsr ) .",
    "sparse modeling of data is a biologically - inspired and theoretically founded approach in which observations are represented as linear combinations of few atoms from a dictionary . as previously shown in the context of object recognition and image restoration , dlsr is well - suited to deal with masked - out entries , has a significantly faster training phase than cnn and can work with small datasets  @xcite .",
    "a standard dlsr method is divided into a _ dictionary learning _",
    "phase , where a dictionary is trained to capture the latent structure of the data , and a _ feature coding _",
    "phase , where the dictionary is used to transform raw observations into features .",
    "representing observations by learning how to extract features from them makes dlsr particularly interesting in the actual context , as it steers clear of relying on expert knowledge brought by hand - designed feature engineering .",
    "is a good or a bad candidate . for grasp detection ,",
    "the goal is to predict the configuration of the best grasp rectangle @xmath3 . ]",
    "our contribution with this paper is twofold .",
    "first , we propose a dlsr - based framework for learning and extracting useful information from rgbd images that is rapidly trainable , can work with a small dataset and inherently deals with masked - out entries . the goal is to demonstrate the applicability of such an approach for grasp recognition and detection , and to compare it with other ones in the literature on the standard cornell task ( shown in fig .",
    "[ fig : cornell_dataset ] ) .",
    "second , we present an empirical evaluations of several dictionary learning and feature coding approach combinations .",
    "since dlsr has been around for some years , more than one variant exists for dictionary training and feature extraction .",
    "the large quantity of available methods makes choosing one particular combination troublesome , as few indications can guide our choice . by understanding the relationship between dictionary learning and feature coding ,",
    "our goal is to ascertain which combinations are best suited for the task at hand by comparing performance , speed of training and parallelizability ( either on cpu or gpu ) .",
    "the rest of this paper is divided as follows .",
    "we make an overview of related works in section  [ sec : related_work ] .",
    "all dictionary learning approaches and encoders are detailed in section  [ sec : learning_framework ] , along with explanations concerning data preprocessing and the overall feature extraction process .",
    "we elaborate on the experimental framework in section  [ sec : experimental_framework ] and report the results in section  [ sec : experimental_results ] .",
    "finally , we discuss the pros and cons of the approaches in section  [ sec : discussion ] and conclude in section  [ sec : conclusion ] .",
    "one of the fundamental concept in grasping is its representation , which has undergone significant evolution over the years . for example ,  @xcite proposed in 2006 a 2d grasping point representation , while more recently ,  @xcite proposed a pair of points .",
    "however , these representations did not faithfully represent the 7-dimensional gripper configuration and its inherent mechanical constraints , which led to the formulation of the grasp rectangle of  @xcite in 2011 .    for identification , several previous approaches used 3d simulations to learn good grasping regions  @xcite .",
    "a strong limitation for them is the need to know all 3d physical models _ a priori _ , which severely reduces the applicability for general purpose robots .",
    "better approaches for performing grasp identification without building complex models prior to the execution would certainly be more adequate .",
    "other works have shown the importance of depth information  @xcite and image processing for representing the image inputs  @xcite .",
    "they often rely on hand - designed features  @xcite , making them possibly brittle or hard to tune .",
    "while there has been some work on applying neural network for learning rgbd image features  @xcite , robotic grasping using neural networks research is still in its infancy  @xcite .",
    "the literature on unsupervised feature learning ( ufl ) is vast .",
    "dlsr - based approaches like  @xcite achieved impressive results on vision - related tasks such as object recognition  @xcite , face recognition  @xcite , scene analysis  @xcite and image restoration  @xcite .",
    "conversely , not as much work has been done to evaluate the performance of dictionary learning approaches on rgbd images  @xcite . by applying such a paradigm for identifying grasping locations ,",
    "one contribution of this paper is to present a comparative study of several dlsr approach combinations which is currently lacking in grasping literature .",
    "in this section , we detail the dictionary learning approaches that are used for unsupervised feature learning . we also elaborate on the data preprocessing , the overall feature extraction process , the classifier for grasp recognition and the regressor for grasp detection .           of 300 atoms ( each square is an atom @xmath4 ) learned using the cornell dataset shown in four distinct parts : k ( gray ) , rgb , d ( depth ) and @xmath5 ( depth normals ) .",
    "most squares ( atoms ) show localized and oriented gabor - like filters.,title=\"fig : \" ] @xmath6     of 300 atoms ( each square is an atom @xmath4 ) learned using the cornell dataset shown in four distinct parts : k ( gray ) , rgb , d ( depth ) and @xmath5 ( depth normals ) .",
    "most squares ( atoms ) show localized and oriented gabor - like filters.,title=\"fig : \" ] @xmath7     of 300 atoms ( each square is an atom @xmath4 ) learned using the cornell dataset shown in four distinct parts : k ( gray ) , rgb , d ( depth ) and @xmath5 ( depth normals ) .",
    "most squares ( atoms ) show localized and oriented gabor - like filters.,title=\"fig : \" ] @xmath8     of 300 atoms ( each square is an atom @xmath4 ) learned using the cornell dataset shown in four distinct parts : k ( gray ) , rgb , d ( depth ) and @xmath5 ( depth normals ) .",
    "most squares ( atoms ) show localized and oriented gabor - like filters . ]",
    "we first compute the gray channel ( k ) and estimate the depth normal coordinates @xmath9 , @xmath10 and @xmath11 for each rgbd kinect image , as done in  @xcite .",
    "each image now contains eight channels .",
    "then , we preprocess each grasp rectangle image by rotating it to match the global image orientation and by rescaling it to a @xmath12 size with aspect - ratio preserved . fig .",
    "[ fig : imgaspectratioall ] shows an example of a grasp rectangle image that is preprocessed in such a way .    in order to learn a set of features , we first collect a batch ( 100,000 in our experiments ) of small @xmath13 patches , extracted at random from the @xmath12 images , that are then channel - wise standardized and zca whitened  @xcite . given a set of these patch vectors @xmath14 ,",
    "we apply a dictionary learning approach to learn a dictionary @xmath15 , where each column @xmath4 is one atom that represents the latent structure of the patches .",
    "[ fig : dictionary ] shows an example of a dictionary learned with cornell database , the same we used in our tests .",
    "most squares ( atoms ) show localized and oriented gabor - like filters that are known to be relevant features for representing raw images  @xcite .",
    "we now elaborate on the dictionary learning algorithms that we chose for learning a dictionary @xmath8 .",
    "specifically , we tested the following approaches :      we train the dictionary by optimizing a @xmath16-regularized sparse coding formulation : @xmath17 using the online dictionary learning ( odl ) algorithm of  @xcite .",
    "odl minimizes   alternatively over the sparse weights @xmath18 and the dictionary @xmath8 , making it a fast and scalable approach for large datasets .",
    "we used least angle regression ( lars )  @xcite to solve for the sparse weights . in our experiments , we cross - validated the sparsity parameter @xmath19 with @xmath20 .      in this case , the @xmath16 penalty is replaced by a @xmath21 one , and optimization follows a formulation similar to sc : @xmath22 we again used odl  @xcite to learn the dictionary , but this time solved the sparse weights with orthogonal matching pursuit ( omp )  @xcite . in our experiments , we cross - validated the sparsity parameter @xmath23 with @xmath24 .",
    "the idea is to represent a vector by separating its gain ( euclidean norm ) from its shape ( orientation )  @xcite .",
    "gsvq has a similar formulation to omp where @xmath25 .",
    "specifically , it computes @xmath26 , the atom index that is most correlated with @xmath27 , then sets @xmath28 and @xmath29 for @xmath30 . using these fixed weight vectors , it is then straightforward to find the locally optimal dictionary @xmath8 in using an iterative procedure as in kmeans .",
    "@xcite showed that the centroids learned by a standard kmeans algorithm make good dictionary atoms .",
    "we thus clustered the patches and used the normalized centroids as dictionary atoms .      here",
    ", we used the heuristic proposed by  @xcite to populate the dictionary .",
    "we uniformly sampled @xmath31 patches from the dataset and used the normalized vectors as the dictionary atoms .",
    "it has been shown previously that completely random weights can achieve surprisingly good results  @xcite .",
    "therefore , we also tested _ learning _ the dictionary by sampling @xmath31 times the uniform distribution @xmath32^n \\right)$ ] and used the normalized vectors as dictionary atoms .",
    "executing any dictionary learning approaches presented in the previous section gives a dictionary @xmath8 representing the latent structure of the data . to actually extract features from them",
    ", we use an _ encoder _ that maps an observation @xmath27 to its feature representation @xmath33 .",
    "the first approach is based on the sparse coding formulation of .",
    "given a dictionary learned with any of section  [ ssec : dl ] methods ( not necessarily sc ) , we solve for the sparse weights assuming a fixed @xmath8 : @xmath34 using lars  @xcite .",
    "it is important to note that @xmath19 ( also @xmath23 and @xmath35 ) may have a different value during feature coding than dictionary learning .",
    "we then apply _ polarity splitting _",
    "@xcite , that is , we split the positive weights from the negative ones : @xmath36 this technique allows the classifier to model positive and negative weights differently , thus improving its flexibility  @xcite . in our experiments ,",
    "we cross - validated with @xmath37 .      with this approach",
    ", we explicitly deal with masked - out entries arising from either the preservation of the aspect ratio during grasp rectangle rescaling or noisy kinect depth sensor .",
    "let @xmath38 be the mask vector of observation @xmath27 where @xmath39 implies that @xmath40 indicates a masked entry ( similarly , @xmath41 indicates that @xmath42 is not a masked entry ) .",
    "we then remove the penalty induced by the masked entries in giving the following formulation , @xmath43 : @xmath44 to solve , we again used lars  @xcite , this time with the mask . as in sc , we apply polarity splitting . in our experiments ,",
    "we cross - validated with @xmath45 .",
    "this approach is based on the formulation of . assuming a fixed dictionary , we applied omp  @xcite to solve for the sparse weights : @xmath46 we again used polarity splitting as in sc .",
    "we cross - validated with @xmath24 .",
    "similarly to msc , we remove the penalty of the masked entries from giving the following formulation @xmath47 which we solved using omp  @xcite but this time with the mask .",
    "we used polarity splitting and cross - validated with @xmath24 .",
    "soft - thresholding  @xcite ( also known as marginal regression  @xcite ) is a fast alternative to finding the optimal solution of .",
    "it is based on the ( strong ) hypothesis that all weights @xmath48 are independent .",
    "this enables solving for the sparse weights marginally ( each @xmath48 individually ) thus giving a simple analytical solution : @xmath49 where @xmath35 is the sparsity parameter . similar to sc and omp , we applied polarity splitting on @xmath18 .",
    "we cross - validated with @xmath50 .",
    "finally , we define a _",
    "natural _ encoder as whichever approach was used for solving the sparse weights during dictionary learning .",
    "for instance , the natural encoder of sc dictionary learning is sc feature coding with the same sparsity parameter @xmath19 .",
    "similarly , the natural encoder of omp dictionary learning is omp feature coding with the same @xmath23 .",
    "we used a different approach for the other dictionary learning algorithms , since they do not require a sparsity parameter .",
    "specifically , for gsvq we used omp with @xmath51 . for r and rp we used st with @xmath52 which corresponds to a random linear projection",
    "finally , for nkm we did not normalize the centroids ( as in standard kmeans ) and used the kmeans - tri feature coding of  @xcite .          given a learned dictionary @xmath8 and a choice of encoder , a patch vector @xmath27 can now be transformed into its feature representation @xmath33 . here",
    "we describe how to transform a full grasp rectangle image into a feature representation usable by the classifier for grasp recognition .",
    "our feature extraction process follows the spatial pyramid matching framework proposed by  @xcite .",
    "the entire process is shown in fig .",
    "[ fig : pipeline_feature_coding ] .",
    "specifically , we extract a batch of @xmath13 patches @xmath27 in a convolutional way with a stride of one pixel .",
    "these patches are channel - wise standardized and zca whitened .",
    "then , we map each patch to its feature representation @xmath33 using the dictionary @xmath8 and the encoder . after , we divide the image into four quadrants and perform sum pooling over the feature vectors @xmath33 of each quadrant respectively .",
    "finally , the pooled feature vectors from all quadrants are concatenated into a single vector that is used as input to the classifier .      for classification , we optimized a @xmath53-linear svm using a standard l - bfgs solver from schmidt s _ minfunc _ toolbox  @xcite .",
    "we cross - validated the regularization parameter @xmath54 with @xmath55 .",
    "although performing grasp recognition is straightforward with a svm because it is a binary classification problem , grasp detection is more cumbersome .",
    "directly predicting the best @xmath56-dimensional grasp rectangle from the very high - dimensional inputs ( @xmath57 kinect images ) would not be realistic with our current framework .",
    "a naive application of the feature extraction process described in section  [ ssec : feature_extraction_process ] on an entire kinect image would extract an unreasonably high - dimensional feature vector with little discriminative power .",
    "we instead opted for a standard grid - search in grasp rectangle space .",
    "we first performed background removal and identified the smallest region containing the object .",
    "then , we extracted , in a convolutional way with a stride of 10 pixels , grasp rectangles from the image with varying sizes and orientations .",
    "we varied the size of the rectangle from 10 pixels to 90 pixels with a stride of 10 pixels , and varied the orientation from 0 degree to 180 degrees with a stride of 15 degrees .",
    "for each of these grasp rectangle images , we performed feature extraction and inputed them to the svm .",
    "the rectangle having the highest classification score was chosen as the candidate grasp .",
    "the cornell grasping dataset  @xcite contains 885 rgbd images of 240 distinct objects ( available at http://pr.cs.cornell.edu/deepgrasping/ ) .",
    "each image has multiple positively- and negatively - labeled grasp rectangles , specifically selected for parallel plate grippers .",
    "the labeled rectangles are varied in terms of size , orientation and position , but are by no means exhaustive of every grasp scenarios ( some image have graspable regions that are not labeled ) .      for grasp recognition",
    ", we performed the following three experiments :      previous works on the cornell dataset reported their results using a 5-fold cross - validation @xcite .",
    "they optimized for the hyper - parameters using a separate set of grasp examples ( which we call the validation set ) .",
    "however , exactly comparing our results to theirs is impossible because they did not report which examples they selected for validation .",
    "therefore , we instead report our recognition accuracies using a 5 - 5 folds nested cross - validation .",
    "the advantages are that this removes the need to specify the validation set and reduces the bias induced by choosing which examples to put in it . moreover , our results are still comparable to the previous ones and , most importantly , allows future works on the dataset to report results based on the same evaluation framework .",
    "the number @xmath31 of atoms has a direct influence on the performance of the classifier .",
    "on one side , a too small dictionary @xmath8 does not capture enough structure to correctly represent the raw data . on the contrary ,",
    "a too big dictionary @xmath8 contains noisy atoms which are never activated in the sparse weight vectors @xmath18 .",
    "these unused atoms slow down the weight extraction process and make the resulting feature vector @xmath33 unnecessarily long and noisy .",
    "we therefore evaluate the correlation between the recognition accuracy and the dictionary size @xmath31 to later guide our choice of it during grasp detection .",
    "previous works on dictionary learning applied to rgb object recognition have already shown that whitening improves the accuracy of the classifier  @xcite .",
    "we therefore wanted to validate that it is still the case when applying dlsr approaches for grasp recognition in rgbd images .",
    "for grasp detection , we performed the following two experiments :      to evaluate the quality of a grasp candidate , we used the _ rectangle metric _ as in  @xcite . specifically ,",
    "if the rectangle metric of any of the ground truth rectangles with the candidate is positive , the regression is a success . in more detail ,",
    "the metric is positive if : _ 1 ) _ the candidate orientation is within @xmath58 of the ground truth rectangle , and _ 2 ) _ the jaccard index between the candidate and the ground truth is greater than @xmath59 , where the jaccard index between two rectangles @xmath60 and @xmath61 is defined as : @xmath62    unlike grasp recognition , we performed a standard 5 folds cross - validation for the detection problem .",
    "we did not optimize for the hyper - parameters , but instead used those that were the most often selected in the nested ( second layer ) cross - validation during grasp recognition .",
    "we also used two learning scenarios  @xcite :    * image - wise splitting : where we split the images randomly . * object - wise splitting : where we split the objects randomly , gathering all the image of the object in the same fold .",
    "image - wise splitting studies the ability to generalize to new positions and orientations of an object that has already been seen . object - wise splitting examine the capability to generalize to novel , unseen objects . while the first scenario is more suitable in an industrial context , because the set of objects is known beforehand , the second one is more difficult but also more realistic . since training on all possible objects is almost impossible , this help asserting the viability of the approach to perform everyday grasping .",
    "one of the most appealing advantage of unsupervised feature learning is the possibility of using unlabeled data for learning the dictionary @xmath8 .",
    "we therefore evaluated the approaches on the problem of _ self - taught learning _",
    "specifically , we randomly subsampled 30 objects from the washington rgbd dataset , which also contains kinect images of everyday objects  @xcite .",
    "we then randomly selected 25 images per object , giving 750 images in total . from these images",
    ", we further extracted 100,000 @xmath13 patches and added them to the 100,000 patches extracted from the cornell dataset images .",
    "we then learned the dictionary @xmath8 using the patches from both datasets .",
    "this test examined the capacity of learning useful features from images taken from another distribution that will never be tested on .",
    ".cross - validation results of all combinations of dictionary learning and feature coding , for cornell dataset .",
    "numbers are grasp recognition accuracies , in percent ( % ) , from 5 - 5 folds nested cross validation where hyper - parameter maximization is performed on the nested folds . [",
    "cols=\"^,^,^,^,^,^,^ \" , ]     [ tab : detection_results_selftaught ]    the cross - validation accuracies ( in % ) for grasp detection of the five selected approaches using a dictionary of 300 atoms and patches from both cornell and washington datasets are reported in table  [ tab : detection_results_selftaught ] .",
    "even tough we see both a performance improvement ( nkm - sc and nkm - natural ) and decrease ( gsvq - st , omp - natural and rp - natural ) , the variations are small ( around @xmath63 ) and not significant .",
    "this suggests that the dictionary learning approaches were able to extract all the necessary features from the cornell images , and the additional features extracted from the washington dataset were not helpful .",
    "this is further reflected in fig .",
    "[ fig : dictionary ] by the presence of some weakly structured atoms ( blank squares ) . indeed",
    ", a dictionary learning approach normally use all available atoms to well represent highly structured data . here , it could achieve that by using only a subset of the atoms , thus showing that it did not need additional patches to learned all the relevant features .",
    "to obtain table  [ tab : detection_results ] high accuracy results in detection , we had to pay a computational price .",
    "even though feature coding approaches have reasonable low computational complexity ( sc is @xmath64 , omp is @xmath65 and st is @xmath66 ) , the exhaustive grid search in grasp rectangle space is computationally demanding .",
    "this translates into several minutes to complete a detection which is higher than redmon _",
    "s cnn with @xmath67 ms per image .",
    "however , since we used a standard cpu and they used a high - end gpu , a dlsr gpu implementation would make a fairer time computation comparison .",
    "while implementing st would be simple , this is not straightforward for sc and omp due to their recursive nature . a possible avenue for a useful gpu implementation may be to parallelize grid search by exploiting grasp rectangle candidate independence , i.e. by extracting and scoring all candidates in parallel . however , grid search in grasp rectangle space being more cumbersome than spatial convolutions , the computational time of such a parallelization would still be higher than cnn .    while dlsr is fairly slow during detection ,",
    "the training phase is significantly faster than cnn . training a cnn ( as the one used by  @xcite )",
    "take several days with parallel high - end gpus , and fine - tuning on cornell dataset takes several hours . in comparison",
    ", it took approximatively ten minutes to train our @xmath68 atoms dictionaries on a standard cpu .",
    "while fast training phase is irrelevant in real - time test scenarios , it could be useful to train a cnn directly on rgbd images .",
    "@xcite pre - training on imagenet could be avoided by greedily stacking dictionaries learned on rgbd images , as previously proposed by  @xcite with auto - encoders in the context of rgb images .",
    "such a dlsr and cnn combination would bring the best of both approaches , in which dlsr would improve training while cnn would provide fast detection .",
    "we intend to investigate this avenue in future works .",
    "even though it achieved the lowest detection accuracies , the rp - natural combination is appealing because training the dictionary is instantaneous , feature coding requires only a matrix multiplication , and there is no hyper - parameters . due to its simplicity , integrating the approach to a grasp localization system in its early deployment phase is straightforward and can give a good glimpse of the overall system performance in later deployment phases .",
    "one interesting avenue for future work is to understand the reason why input decorrelation allows randomly sampled patches to make such good dictionaries .",
    "for instance , is linear independence sufficient , or better dictionaries could be recovered with non - linear independence ?",
    "these are several avenues worth investigating .",
    "a perception system that determines good grasping positions from microsoft kinect rgbd images is a key element toward automating the grasping of ordinary objects . in this paper",
    ", we proposed a dlsr framework to recognize and detect grasp rectangles on images of object to be held by two - plates parallel grippers .",
    "our comparative study of various dictionary learning and feature coding approach combinations on cornell dataset have shown that the proposed dlsr framework outperformed previous neural network - based approaches .",
    "as opposed to cnn , the best dlsr combination obtained a greater accuracy in both grasp recognition and detection task despite training only on small amount of images .",
    "in addition to having a substantially fast training phase , dlsr can inherently deal with masked - out entries in noisy depth maps and do not rely on sophisticated regularization terms . as discussed in section  [ sec : discussion ] ,",
    "exploiting dlsr fast training phase may be a suitable research avenue for future work .",
    "stacking dictionaries learned on rgbd images to pre - train a cnn would bring the best of both approaches , in which dlsr improve training while cnn provide fast detection ."
  ],
  "abstract_text": [
    "<S> the ability to grasp ordinary and potentially never - seen objects is an important feature in both domestic and industrial robotics . for a system to accomplish this , </S>",
    "<S> it must autonomously identify grasping locations by using information from various sensors , such as microsoft kinect 3d camera . despite numerous progress , </S>",
    "<S> significant work still remains to be done in this field . to this effect </S>",
    "<S> , we propose a dictionary learning and sparse representation ( dlsr ) framework for representing rgbd images from 3d sensors in the context of determining such good grasping locations . </S>",
    "<S> in contrast to previously proposed approaches that relied on sophisticated regularization or very large datasets , the derived perception system has a fast training phase and can work with small datasets . </S>",
    "<S> it is also theoretically founded for dealing with masked - out entries , which are common with 3d sensors . </S>",
    "<S> we contribute by presenting a comparative study of several dlsr approach combinations for recognizing and detecting grasp candidates on the standard cornell dataset . </S>",
    "<S> importantly , experimental results show a performance improvement of 1.69% in detection and 3.16% in recognition over current state - of - the - art convolutional neural network ( cnn ) . </S>",
    "<S> even though nowadays most popular vision - based approach is cnn , this suggests that dlsr is also a viable alternative with interesting advantages that cnn has not . </S>"
  ]
}