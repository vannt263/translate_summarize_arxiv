{
  "article_text": [
    "when xml is used for data - centric applications such as integration , there may be no order constraint among siblings  @xcite",
    ". meanwhile , the relative order within siblings may be still important .",
    "for example , consider a ticket system with two ticket machines , where there are two bunches of tourists lining up waiting to buy tickets .",
    "each group has two tourists .",
    "we can then define the unordered schema for the ticket system .",
    "the ordered groups preserve only the relative order of their members .",
    "this not only allows individual tourists to insert themselves within a group , but also lets two groups interleave their members .",
    "the exact xml schema definition ( xsd ) for the purchasing sequence can be essentially represented as @xmath1 @xmath2 @xmath3 @xmath4 @xmath5 , where @xmath6 means the @xmath7th member in the @xmath8th group can buy zero or more tickets .",
    "it shows the length of the exact regular expression can be exponential when compared to the number of members in sequences .",
    "actually , @xmath9 is used in practice  @xcite instead of the minimal ones , which may permit invalid xml documents ( i.e. , over - permissive ) . for example , it may permit the second member in the sequence of the first group to purchase tickets before the first member .",
    "there are many negative consequences of over - permissive  @xcite .",
    "thus it is necessary to study how to infer an unordered minimal schema for this kind of xml documents .",
    "previous researches on xml schema inference have been done mainly in the context of ordered xml , which can be reduced to learn regular expressions .",
    "gold  @xcite showed the class of regular expressions is not identifiable in the limit .",
    "therefore numerous papers  ( e.g. ) studied inference algorithms of restricted classes of regular expressions .",
    "most of them were based on properties of automata .",
    "bex et al .",
    "@xcite proposed learning algorithms for single occurrence regular expressions ( sores ) and chain regular expressions ( chares ) .",
    "freydenberger and ktzing  @xcite gave more efficient algorithms learning a minimal generalization for the above classes .",
    "the approach is based on descriptive generalization  @xcite which is a natural extension of gold - style learning .    however , there is no such kind of automata for regular expressions with interleaving since they do not preserve the total order among symbols .",
    "thus we have to explore new techniques . while ciucanu  @xcite proposed learning algorithms for two unordered schema formalisms : disjunctive multiplicity schemas ( dms ) and its restriction , disjunction - free multiplicity schemas ( ms ) , both of them disallow concatenation within siblings .",
    "thus they are less expressive than ours .",
    "moreover , the ordering information in our schema formalism can not be fully captured by the three characterizing triples used to construct a dms or ms .",
    "inference algorithms in this paper use some similar techniques with algorithms mining global partial orders from sequence data  @xcite .",
    "however , the semantic concepts there are typically quite different from ours .",
    "mannila et al .",
    "@xcite tried to find mixture models of parallel partial orders .",
    "however , to learn unordered regular expressions , series parallel orders may not be sufficient since they can conflict with some data in the whole data set .",
    "another restriction in the above method is that it can only be applied to strings where each symbol occurs at most once .",
    "particularly , gionis et al .",
    "@xcite emphasised on recovering the underlying ordering of the attributes in high - dimensional collections of 0 - 1 data .",
    "an implicit assumption is that attribute can also occur at most once . for learning regular expressions with interleaving",
    ", symbols in strings can present any times and partial orders among siblings are independent with no violations .",
    "hence many techniques from data mining are not directly applicable .",
    "therefore , learning restricted regular expressions with interleaving remains a challenging problem .    in this paper",
    ", we address the problem of discovering a minimal regular expression with interleaving from positive examples .",
    "the main contributions of the paper are listed as follows :    1 .",
    "we propose a better and more suitable formalism to specify precise unordered xml : the subset of regular expressions with interleaving ( sires ) .",
    "sires can express the content models succinctly and concisely .",
    "for example , the above example can be depicted as @xmath10 .",
    "we introduce the notion of sire - minimal in the terminology of  @xcite and some properties of sire - minimal .",
    "we prove the problem of finding a minimal sire is np - hard and develop an approximation algorithm conminer to find solutions with worst - case quality guarantees and a heuristic algorithm condag that mostly finds solutions of better quality as compared to the approximation algorithm conminer .",
    "4 .   we conduct experiments comparing our methods with trang  @xcite on real world data , incorporating small and large data sets .",
    "our experiments show that conminer and condag outperform existing systems on such data .",
    "the rest of the paper is organized as follows .",
    "section  [ sect : pre ] contains basic definitions . in section  [",
    "sect : des ] we discuss properties of minimal - sire . in section  [ sect : infer ] an approximation algorithm conminer and a heuristic algorithm condag are proposed .",
    "section  [ sect : expre ] gives the empirical results .",
    "conclusions are drawn in section  [ sect : conwk ] .",
    "let @xmath11 and @xmath12 be two arbitrary strings . by @xmath13",
    "we denote the set of strings that is obtained by interleaving of @xmath11 and @xmath12 in every possible way .",
    "that is , @xmath14 , @xmath15 .",
    "if both @xmath11 and @xmath12 are non - empty let @xmath16 , @xmath17 and @xmath18 are single symbols , then @xmath19 .",
    "let @xmath20 be an alphabet of symbols .",
    "the regular expressions with interleaving over @xmath20 are defined as : @xmath21 or @xmath22 is a regular expression , @xmath23 , @xmath24 , @xmath25 , @xmath26 , @xmath27 , or @xmath28 is a regular expression for regular expressions @xmath29 and @xmath30 .",
    "they are denoted as re ( & ) .",
    "the language described by @xmath31 is defined as follows : @xmath32 @xmath33 @xmath34 @xmath35 @xmath36 @xmath37 @xmath38 @xmath39 @xmath40 .",
    "we consider the subset of regular expressions with interleaving ( sires ) defined by the following grammar .    the restricted class of regular expressions with interleaving ( rres )",
    "are @xmath41 over @xmath20 by the following grammar for any @xmath22 : @xmath42    the subset of regular expressions with interleaving ( sires ) are those rres in which every symbol can occur at most once .",
    "since sires disallow repetitions of symbols , they are certainly deterministic and satisfy the upa constraint required by the xml specification .",
    "a partial order @xmath43 for a string @xmath44 is a binary relation that is reflexive , antisymmetric and transitive .",
    "we write @xmath45 if @xmath17 is before @xmath18 in the partial order . for string @xmath46 , the _ transitive closure _ of @xmath44",
    "is denoted by @xmath47 , where @xmath48 is the length of @xmath44 .",
    "for example @xmath49 , @xmath50 .",
    "a partial - order set @xmath51 is a set of symbols together with a partial ordering .",
    "we say @xmath52 if @xmath17 precedes @xmath18 in every string in a string collection .",
    "consistent partial order set ( cpos ) @xmath53 is a set which contains all the disjoint partial - order sets @xmath54 of the given examples .",
    "for example , consider @xmath55 .",
    "obviously , @xmath56 , @xmath57 .",
    "the connection between cpos and sire is directly .",
    "that is , given a cpos , we can write it to the form of sire by combining all the elements in cpos with @xmath58 .",
    "for example , in this case the corresponding sire @xmath59 .",
    "therefore , the problem of finding a minimal sire can be reduced to the problem of finding a minimal cpos .",
    "this section introduces the notion of minimal expressions . roughly speaking minimal is the greatest lower bound of a language @xmath60 within a class of expressions , which is conceptually similar with @xmath61 in the terminology of mathematics .",
    "let @xmath62 be a class of regular expressions over some alphabet @xmath20 .",
    "a @xmath63 is called @xmath62-minimal of non - empty language @xmath64 if @xmath65 , and there is no @xmath66 such that @xmath67 .",
    "[ pro : num ] let @xmath68 be the number of alphabet symbols .",
    "the number of pairwise non - equivalent @xmath69 is @xmath70 .",
    "disregarding operators ?",
    ", + , * , the number of sires over a finite @xmath20 is equivalent to the number of ordered partitioning @xmath71 symbols .",
    "the number of these partitions is given by the @xmath71th ordered bell numbers  @xcite .",
    "for instance , if @xmath72 , the @xmath73th ordered bell number @xmath74 , and the ordered partitions of @xmath75 is @xmath76 .",
    "they are also distinct partitions of sires over @xmath20 .",
    "the ordered bell number  @xcite can be approximated as @xmath77 . since every symbol @xmath17 in @xmath20 has four forms which can be represented as @xmath78 , the number of sires over @xmath20 is @xmath79 .",
    "then @xmath80 .",
    "we can then prove the existence of minimal regular expressions for sire .",
    "[ pro : everyhas ] let @xmath20 be a finite alphabet . for every language @xmath81 , there exists a sire - minimal sire @xmath82 .",
    "assume there is a language @xmath60 over @xmath20 such that no expression @xmath83 is sire - minimal .",
    "this implies that there is an infinite sequence @xmath84 of expressions from sire with @xmath85 and @xmath86 for all @xmath87 .",
    "this contradicts the fact that there are only a finite number of non - equivalent sires over @xmath20 by proposition  [ pro : num ] .",
    "[ pro : minimal ] for any example string set @xmath31 over @xmath88 , let @xmath89 be a sire such that @xmath90 .",
    "@xmath91 is a minimal sire if and only if : + ( 1 ) the number of @xmath92 is minimized and + ( 2 ) the size of each @xmath92 is as large as possible .",
    "the proof was omitted for space reasons .    in other words ,",
    "a minimal sire is the most specific sire that consistent with the given example strings .",
    "for instance , all of @xmath93 , @xmath94 and @xmath95 can accept @xmath96 .",
    "however , since @xmath97 , we can get @xmath98 which means @xmath99 is not minimal . as for @xmath100 and @xmath101 , since @xmath102 and @xmath103 , this means @xmath101 is not minimal . as we shall see , @xmath100 is a better approximation of e. in fact , @xmath100 can be verified to be a minimal by referring to proposition  [ pro : minimal ] .",
    "in this section , we first prove finding a minimal sire for a given set of strings is np - hard by reducing from finding a maximum independent set of a graph , which is a well - known np - hard graph problem  @xcite",
    ". then we present learning algorithms that construct approximatively minimal sires .",
    "first , we introduce the notion of maximum independent set of a graph  @xcite .",
    "consider an undirected graph @xmath104 , an independent set ( is ) is a set @xmath105 such that @xmath106 . the maximum independent set ( mis ) problem consists in computing an is of the largest size .",
    "next , we define the problem ` all_mis ` which takes a graph @xmath107 as input , finding a mis @xmath108 of g by applying function ` max_independent_set ` , and repeating the step for subgraph @xmath109 $ ] until there exists no vertex in the subgraph . in other words , `",
    "all_mis ` is to divide @xmath110 into disjoint subsets by ` max_independent_set ` .",
    "clearly , problem ` all_mis ` is np - hard .    the main idea of finding a minimal sire is based on the observation that there are sets of conflicting siblings that can not be divided into the same subset of cpos .",
    "a pair @xmath111 is called forbid pair in a string database if both @xmath111 and @xmath112 exists in the transitive closure of strings .",
    "the set of forbid pairs is called a @xmath113 . by proposition",
    "[ pro : minimal ] , if we split the set of symbols in a @xmath113 into several subsets @xmath114 such that @xmath68 is minimized and for each @xmath115 $ ] , @xmath54 is the longest of its alternatives .",
    "then the set of @xmath54 where @xmath115 $ ] , is a minimal cpos which can be transformed to a minimal sire .",
    "minimal sire finding problem is np - hard .",
    "we demonstrate that ` all_mis ` can be reduced in polynomial time to minimal sire finding problem .",
    "given an instance of ` all_mis ` , we can generate a corresponding instance of minimal sire finding as follows .",
    "for the graph @xmath107 in ` all_mis ` , the reduction algorithm computes the @xmath113 set by adding all edges in @xmath107 to @xmath113 , which is easily obtained in polynomial time .",
    "the output of the reduction algorithm is the instance set @xmath113 of minimal sire finding problem .",
    "@xmath54 in cpos is the longest of its alternatives if and only if ` all_mis ` computes a maximum independent set at the @xmath8th step .",
    "thus , minimal sire finding problem is equivalent to the original ` all_mis ` . since ` all_mis ` is np - hard , minimal sire finding problem is np - hard .",
    "the process of this approach is formalized in algorithm  [ alg : consi ] .",
    "algorithm  [ alg : consi ] works in four steps and we illustrate them on the sample @xmath116 . the first step ( lines 1 - 2 ) computes the non - constraint and constraint set using the function ` tran_reduction ` . the transitive  closure of @xmath31 is @xmath117 .",
    "add @xmath118 to @xmath113 if @xmath119 .",
    "add @xmath118 to @xmath120 otherwise .",
    "we get @xmath121 and @xmath122 .",
    "construct an undirected graph @xmath107 using element in @xmath113 as edges .",
    "the second step ( lines 3 - 7 ) is to select a mis of @xmath107 , add it to list @xmath123 and delete the mis and their related edges from @xmath107 .",
    "the process is repeated until there exists no nodes in @xmath107 .",
    "the problem of finding a maximum independent set is an np - hard optimization problem . as such",
    ", it is unlikely that there exists an efficient algorithm for finding a maximum independent set of a graph .",
    "however , we can find a mis in polynomial time with a approximation algorithm , e.g. the ` clique_removal ` algorithm proposed in  @xcite that finds the approximation of maximum independent set with performance guarantee @xmath124 by excluding subgraphs . for graph @xmath107",
    ", we obtain @xmath125 .",
    "next , we add the non - constraint symbols to the first mis",
    ". then we have @xmath126 .",
    "the third step ( lines 8 - 10 ) computes the topological sort for all subgraphs induced by subset of @xmath120 and add the result to @xmath53 .",
    "for the sample , it returns @xmath57 . finally , the algorithm returns the sire whose corresponding counting operators @xmath127 can be inferred using technique in algorithm ` crx `  @xcite . for the sample , it returns @xmath128 .",
    "set of words @xmath129 a minimal sire",
    "@xmath53 @xmath130 @xmath131 @xmath132 @xmath133 @xmath134 @xmath135=allmis[0].union(alphabet(l2)-alphabet(constraint))$ ] @xmath136 @xmath137",
    "@xmath138 )      although a number of approximation algorithms and heuristic algorithms have been developed for the maximum independent set problem , on any given instance , they may produce a sire that is very far from optimal .",
    "we introduce a heuristic directed acyclic graph construction algorithm directly computing a minimal sire .",
    "the main idea is to cluster the vertices of the existing directed graph into several disconnected subgraphs .",
    "the graph is constructed incrementally to preserve cpos within each vertex using a greedy approach .",
    "the pseudocode of algorithm ` condag ` is given in algorithm  [ alg : consis ] .",
    "the input to this algorithm is the same as the input of the ` conminer ` .",
    "the algorithm maintains lists @xmath139 as records to keep track of pairs violating the partial order constraint and lists @xmath140 to record pairs violating the partial order constraint of the string under reading .",
    "note that @xmath141 violating the partial order constraint means there exist some @xmath142 such that @xmath143 in @xmath144 and @xmath145 in @xmath146 .",
    "let @xmath147 be two adjacent symbols in a word @xmath148 .",
    "the ` add_or_break ` function checks whether edge @xmath147 is added to the present graph g. if there exists no path from @xmath18 to @xmath17 , no path from @xmath17 to @xmath18 in g and edge @xmath147 will not make a connection between some @xmath149 $ ] and @xmath150 $ ] , we add edge @xmath151 in g. self - loops such as @xmath152 are always ignored since they have no influence on the partial order constraints .",
    "however , if there exist paths from @xmath18 to @xmath17 in @xmath107 , @xmath153,q[i]),(q[i],p[i])$ ] and @xmath154 are not in @xmath149,q[i]$ ] at the same time for all @xmath155 , we should break all paths from @xmath18 to @xmath17 .",
    "the breakpoint can be found as below .",
    "suppose there exists a path @xmath156 , @xmath157 in @xmath107 , and substring of @xmath148 over @xmath158 is @xmath159 , then we delete edge @xmath160 , add edge @xmath161 for all nodes @xmath162 that @xmath163 , and add edge @xmath164 for all nodes @xmath165 that @xmath166 . in the end , add @xmath167 to @xmath168,@xmath44 and add @xmath159 to @xmath169,@xmath51 .",
    "example in figure  [ fig : addorbreak.pdf ] shows how the function works .",
    "@xmath170 , initialize empty list @xmath168,@xmath169,@xmath44,@xmath51 and empty graph @xmath107 .",
    "after reading @xmath144 , list @xmath168,@xmath169,@xmath44,@xmath51 are still empty .",
    "when reading @xmath171 , there already exists a path @xmath172 and @xmath173,q[i]),(q[i],p[i])$ ] .",
    "we should break @xmath172 .",
    "since @xmath174 , breakpoint is @xmath175 .",
    "then we delete edge @xmath176 , and add edges @xmath177,@xmath178 . in the end , add @xmath147 to @xmath168,@xmath44 and add @xmath179 to @xmath169,@xmath51 .",
    "the ` consistent ` function scans the whole string @xmath148 by sequence to execute ` add_or_break ` function .",
    "each time after reading two adjacent symbols @xmath147 , for all pairs @xmath180 or @xmath181 , handle @xmath182 likewise . because @xmath180 or @xmath181 declare @xmath183 and @xmath184 are in @xmath148 , if @xmath143 in @xmath148 , @xmath185 is also in @xmath148 . consider @xmath186 as an example ,",
    "@xmath175 and @xmath17 have been two parts after reading @xmath187 , @xmath17 has been added to @xmath168 and @xmath44 and @xmath175 added to @xmath169 and @xmath51 . after reading the next two symbols @xmath147 , add edge @xmath151 .",
    "next we should consider @xmath182 since @xmath188,c\\in s[0]$ ] , thus add edge @xmath189 .",
    "the ` topological_sort(g ) ` construct a topological ordering of dag in linear time .",
    "the ` learner_oper ` is used to infer operators @xmath190 for each vertex .",
    "the ` condag ` algorithm combines all the functions .",
    "the constructed graph is denoted by @xmath107 and the corresponding set of partitions by @xmath191 . in each iteration",
    ", it invokes ` consistent ` to update @xmath107 using the @xmath8th string",
    ". then it adds all the paths from the set of vertices of in - degree zero to the set of vertices of out - degree zero . to be able to calculate the largest independent partial - order plans ,",
    "a preprocessing phase is implemented .",
    "first , we consider the elements of @xmath191 in decreasing order of size . in each iteration",
    ", whenever we find two elements that the one contains elements of @xmath149 $ ] and the other one contains elements of @xmath150 $ ] , we updates the shorter one by removing the common elements .",
    "next , we merge all the lists in @xmath191 that share common elements . the preprocess terminates when every symbol is included in one and only one list .",
    "the following steps of the algorithm are the same as the third and the forth step of the ` conminer ` .",
    "@xmath192 , @xmath193 @xmath194,w[i+1],p , q , s , t)$ ] @xmath195),w[i+1],p , q , s , t)$ ] @xmath196),w[i+1],p , q , s , t)$ ] @xmath197    set of unordered words @xmath129 a minimal sire @xmath130 initialize graph g , @xmath198 @xmath199 @xmath200 remove the common elements from the shorter of @xmath201 if @xmath202+c_j[n]\\in constraint$ ] .",
    "merge all lists that share common elements in @xmath191 @xmath203 @xmath137 @xmath138 )    the time complexity analysis of this algorithm is straightforward .",
    "@xmath204 can find all possible paths between two given nodes by modifying the dfs which needs @xmath205 steps . breaking a circle",
    "requires @xmath206 .",
    "therefore , an overall time complexity for @xmath207 is @xmath208 , where @xmath175 is number of paths between the given nodes in the graph . when there exist @xmath209 inconsistent terms in w , every two symbols are not in a group , which is the worst case . when tackling of @xmath210 , @xmath211 , deciding whether @xmath212,q[j]),(q[j],p[j])$ ] needs @xmath213 time . deciding whether @xmath214,t[j]$ ] needs @xmath215 time .",
    "there is only one path between two nodes , thus @xmath216 .",
    "so the total time of @xmath217 is @xmath218 where @xmath219 , and @xmath220 is @xmath221 according to the analysis above .",
    "the @xmath222 computation requires @xmath223 time , where @xmath68 is the number of distinct symbols .",
    "each iteration requires @xmath224 time to maintain the graph .",
    "computing all paths from source to destination can be done in @xmath223 time , and @xmath225 constructs a topological ordering of dag in linear time , thus @xmath205 steps are sufficient .",
    "inference of operators @xmath190 needs time @xmath226 .",
    "hence the time complexity of the algorithm is @xmath227 , where @xmath228 is the sum of length of the input example strings , @xmath68 the number of alphabet symbols and @xmath51 the number of strings .    to illustrate our algorithm ,",
    "consider the example @xmath116 , @xmath121 , @xmath122 in the above section .",
    "a directed graph which consists of vertex @xmath229 and edges @xmath230 can be obtained .",
    "@xmath231 and @xmath232 .",
    "all paths from source to destination are @xmath233 .",
    "since @xmath234 , @xmath235 $ ] is updated by removing the common elements between @xmath236 $ ] and @xmath235 $ ] .",
    "@xmath235 $ ] is @xmath237 .",
    "the final @xmath191 is @xmath238 .",
    "the following steps are the same .",
    "in this section , we validate our approaches on real - life dtds , and compare them with that of trang  @xcite .",
    "all experiments were conducted on an ibm t400 laptop computer with a intel core 2 duo cpu(2.4ghz ) and 2 g memory .",
    "all codes were written in python .",
    "the number of corpora of xml documents with an interesting schema is rather limited .",
    "we obtained our real - life dtds from the xml data repository maintained by miklau  @xcite .",
    "unfortunately , most of them are either not data - centric or not with a dtd . specifically , we chose the dblp computer science bibliography corpus , a data - centric database of information on major computer science journals and proceedings",
    ".    2.5pt     name & exact minimal dtd + sample & result of conminer + size & result of condag + & result of trang + number of&simplified exact minimal dtd + interleaving&simplified result of conminer + & simplified result of condag + * inproceedings*&@xmath239 + @xmath240&@xmath241 + @xmath240&@xmath242 + @xmath240&@xmath243 + @xmath240&@xmath244 + 5&6&3&1&1&1&1 + 6 & 3&3&2&2&1&1&1 + 5 & 5&4&1&1&1&1 + * article*&@xmath239 + 111608&@xmath245 + 111608&@xmath246 + 111608&@xmath247 + 111608&latexmath:[$a_2?(a_1|a_3|a_5|a_6|a_8|a_9|a_{10}|a_{11}|a_{12}|a_{13 }    6 & 5&3&1&1&1&1&1 + 7 & 4&3&1&1&1&1&1&1 + 6 & 4&4&1&1&1&1&1 + * proceedings*&@xmath239 + @xmath249&@xmath250 + @xmath249&@xmath251 + @xmath249&@xmath252 + @xmath249&@xmath253 + 5&12&1&1&1&1&1 + 5&7&4&3&1&1&1 + 5&11&2&1&1&1&1 + * incollection*&@xmath239 + @xmath254&@xmath255 + @xmath254&@xmath256 + @xmath254&@xmath257 + @xmath254&latexmath:[$(a_1|a_3|a_4|a_5|a_6|a_{11}|a_{13}|a_{16}|a_{17 }    3&9&2&1&1 + 4&4&4&2&2&1 + 4&7&2&2&1&1 + * phdthesis*&@xmath239 + @xmath259&@xmath260 + @xmath259&@xmath261 + @xmath259&@xmath262 + @xmath259&@xmath263 + 1&9&1 + 1&8&2 + 1&9&1 +    * www*&@xmath239 + @xmath264&@xmath265 + @xmath264&@xmath265 + @xmath264&@xmath265 + @xmath264&@xmath266 + 0&6 + 0&6 + 0&6 +    table  [ tab : schema ] lists the non - trivial element definitions in the above mentioned dtd together with the results derived by exact algorithm , heuristic algorithm conminer , approximation algorithm condag , and trang .",
    "we implement the exact algorithm using conminer by replacing function ` clique_removal ` with an exponential time algorithm proposed by s. tsukiyama  @xcite .",
    "we also list the number of interleavings used and the simplified of our results to have a clear view of their relationship .",
    "the numbers in the first column the first five rows in each element refer to the element name and the sample size respectively .",
    "the numbers in the first column the last three rows in each element refer to the number of interleavings used by the result of exact algorithm , conminer and condag , respectively",
    ". it can be verified that all expressions learned by exact algorithm , condag and conminer are more strict than that of trang and the original dtds which indicates there exists much more over - permissive in both the original dtds and the results of trang .",
    "we note that there may exist many minimal expressions given a set of unordered strings .",
    "for instance , for ` phdthesis ` , the form of the result of condag is the same with the exact minimal expression .",
    "the orders among symbols of their first siblings , however , differ widely .",
    "this is due to the fact that a diagraph may have several different topological sorts .",
    "therefore , we ignore the sequel in the symbols and only compare their simplified form .",
    "the table shows clearly that condag yields concise super - approximations to the exact minimal expressions .",
    "although for ` proceedings , incollection and phdthesis ` , the expressions produced by conminer and condag have the same number of interleavings , condag yields longer length of siblings and thus finds solutions of better quality as compared to the solutions found by the approximation algorithm .",
    "this paper proposes a strategy for learning a class of regular expressions with interleaving : first , compute consistent partial order @xmath53 , then equip each factor with counting operators . as future work",
    ", we will investigate several interesting problems inspired by this study .",
    "first , we would like to extend our algorithms for more expressive schemas , for example schemas allow disjunction @xmath267 within siblings .",
    "second , how to extend algorithms to mine all independent frequent closed partial orders  @xcite is also an attractive topic .",
    "we thank the users of stack overflow  @xcite , for reminding us the maximum independent set problem .",
    "99 s. abiteboul , p. bourhis and v.vianu : highly expressive query languages for unordered data trees . in : proceedings of the 15th international conference on database theory , pp",
    ". 46 - 60 ( 2012 ) g. j. bex , w. gelade , w. martens and f. neven : simplifying xml schema : effortless handling of nondeterministic regular expressions . in : proceedings of the 2009 acm",
    "sigmod international conference on management of data , pp .",
    "731 - 744 ( 2009 ) i. boneva , r. ciucanu and s. staworko : simple schemas for unordered xml .",
    "arxiv preprint arxiv:1303.4277 ( 2013 ) g. j. bex , f. neven , t. schwentick and s.vansummeren : inference of concise dtds from xml data . in : proceedings of the 32nd international conference on very large data bases , pp .",
    "115 - 126 .",
    "vldb endowment ( 2006 ,",
    "september ) g. j. bex , f. neven and s. vansummeren : inferring xml schema definitions from xml data . in : proceedings of the 33rd international conference on very large data bases , pp .",
    "998 - 1009 .",
    "vldb endowment ( 2007 ,",
    "september ) g. j. bex , g. wouter , f. neven and s. vansummeren : learning deterministic regular expressions for the inference of schemas from xml data .",
    "acm transactions on the web ( tweb ) 4.4:14 ( 2010 ) i. alexey , m. antonio and j. marques - silva : on reducing maximum independent set to minimum satisfiability . theory and applications of satisfiability testing  sat 2014 .",
    "springer international publishing , 103 - 120 ( 2014 ) j. clark .",
    "trang : multi - format schema converter based on relax ng , http://www.thaiopensource.com/relaxng/trang.html e. m. gold : language identification in the limit .",
    "information and control .",
    "10(5 ) , pp .",
    "447 - 474 ( 1967 ) r. w. bailey : the number of weak orderings of a finite set .",
    "social choice and welfare .",
    "15(4 ) , pp . 559 - 562 ( 1998 ) j. m. de koninck : those fascinating numbers .",
    "american mathematical soc ( 2009 ) d. d. freydenberger and t. ktzing : fast learning of restricted regular expressions and dtds . in : proceedings of the 16th international conference on database theory , pp.45 - 56 ( 2013 ) r. ciucanu and s. staworko : learning schemas for unordered xml .",
    "arxiv preprint arxiv:1307.6348 ( 2013 ) a. gionis , t. kujala and h. mannila : fragments of order . in : proceedings of",
    "the ninth acm sigkdd international conference on knowledge discovery and data mining , pp .",
    "129 - 136 ( 2003 ) h. mannila and c. meek : global partial orders from sequential data . in : proceedings of",
    "the sixth acm sigkdd international conference on knowledge discovery and data mining , pp .",
    "161 - 168 ( 2000 ) r. agrawal and r. srikant : fast algorithms for mining association rules .",
    "very large data bases , vol . 1215 , pp .",
    "487 - 499 .",
    "vldb ( 1994 ) j. pei , h. wang , j. liu , k. wang and et al . : discovering frequent closed partial orders from strings .",
    "knowledge and data engineering , ieee transactions on 18.11 , pp.1467 - 1481 ( 2006 ) g. miklau .",
    "xmldata repository , nov .",
    "2002 , http://www.cs.washington.edu/research/xmldatasets/ r. boppana and m. m. halld@xmath268rsson : approximating maximum independent sets by excluding subgraphs . bit numerical mathematics 32.2 : 180 - 196 ( 1992 ) s. tsukiyama , m. ide , h. ariyoshi and i. shirakawa : a new algorithm for generating all the maximal independent sets .",
    "siam journal on computing 6.3 : 505 - 517 ( 1977 ) algorithm to divide a set of symbols with constraints into minimun number of subsets , http://stackoverflow.com/q/29117747/4684328"
  ],
  "abstract_text": [
    "<S> discovering a concise schema from given xml documents is an important problem in xml applications . in this paper </S>",
    "<S> , we focus on the problem of learning an unordered schema from a given set of xml examples , which is actually a problem of learning a restricted regular expression with interleaving using positive example strings . schemas with interleaving could present meaningful knowledge that can not be disclosed by previous inference techniques . moreover , </S>",
    "<S> inference of the @xmath0 schema with interleaving is challenging . </S>",
    "<S> the problem of finding a @xmath0 schema with interleaving is shown to be np - hard . </S>",
    "<S> therefore , we develop an approximation algorithm and a heuristic solution to tackle the problem using techniques different from known inference algorithms . </S>",
    "<S> we do experiments on real - world data sets to demonstrate the effectiveness of our approaches . our heuristic algorithm is shown to produce results that are very close to optimal .    </S>",
    "<S> inference , interleaving , partial orders , descriptivity </S>"
  ]
}