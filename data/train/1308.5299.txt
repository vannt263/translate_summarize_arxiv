{
  "article_text": [
    "apart from a substantial kinematical dipole , the cosmic microwave background ( cmb ) radiation is observed to be isotropic to around one part in @xmath1 . below this level , there are random fluctuations over a wide range of angular scales",
    ". the prevailing ` concordance ' cosmological model explains these anisotropies as the imprints of gaussian - distributed , statistically - isotropic perturbations of spacetime that were generated during an inflationary epoch in the early universe .",
    "correlations between the fluctuations provide a wealth of information about inflation and the subsequent growth of structure , and so being able to accurately measure and characterize them is of paramount importance to modern cosmology .",
    "as detector technology has improved , it has become possible to probe smaller and smaller angular scales with ever - increasing noise sensitivities .",
    "the resulting improvement in resolution and signal - to - noise ratio presents a formidable computational challenge , as one must now reliably reconstruct the cmb sky to high accuracy over tens of millions of pixels , while simultaneously taking into account complexities of the data such as inhomogeneous noise , foreground contamination , and regions of missing / masked data .",
    "consider an observed map of the cmb , for instance similar to those provided by the wmap @xcite and planck @xcite experiments .",
    "the ideal cmb map would consist of an error - free value at every single position on the sky . in reality",
    "this is of course not possible , because of instrumental imperfections ( such as noise and beam smoothing ) and strong foreground contamination from astrophysical sources ; there will always be uncertainties in a real cmb map .",
    "therefore , rather than aiming to extract `` a single true cmb sky map '' , a more realistic solution is to compute an ensemble of many possible cmb skies , each of which is both noise - free , full - sky , and _ statistically consistent _ with the observed data .",
    "this idea has already been implemented for cmb analysis purposes in terms of a gibbs sampling framework , as described by @xcite .",
    "an underlying assumption in this line of work is that both the cmb sky and instrumental noise are random gaussian fields with covariance matrices @xmath2 and @xmath3 , respectively . in most applications  following the basic inflationary prediction ",
    "one additionally assumes that the cmb field is isotropic , so that the cmb covariance matrix can be specified in terms of a simple angular power spectrum , @xmath4 .",
    "of course , this power spectrum is not known _ a priori _ , but must instead be estimated from the data , and indeed , this is usually the main goal for most cmb experiments .",
    "the gibbs sampling framework provides a well - structured mathematical solution to this power spectrum estimation problem , by establishing the full joint bayesian posterior distribution of the cmb sky and cmb power spectrum .",
    "this is found by iteratively sampling from the ( more tractable ) conditional distributions according to a simple algorithm : 1 ) make an arbitrary initial ` guess ' for the cmb power spectrum ; 2 ) draw a cmb sky map compatible with the data and the assumed power spectrum ; 3 ) draw a power spectrum compatible with the sky sample that was just drawn ; and 4 ) iterate .",
    "the resulting set of sky and power spectrum samples will ( after some burn - in period ) converge to the true joint posterior distribution .",
    "although simple to write down , this algorithm is also computationally rather expensive due to step ( 2 ) , which essentially amounts to solving a large linear system with one or more random terms on the right - hand side , corresponding to different realizations .",
    "we will refer to this system as the _ constrained realization _ ( cr ) system . the same linear system can also be solved for the maximum likelihood cmb sky map estimate , which is sometimes referred to as the _ wiener - filtered map_. since the degrees of freedom of the cr system scale with the number of pixels , brute force solutions are out of bounds except for very low - resolution data sets . however , it is computationally feasible to multiply an arbitrary vector with the system matrix by repeatedly changing basis functions ( i.e. spherical harmonic transforms ) , so that the system can be solved using iterative linear equation solvers .",
    "the main problem is to optimize the convergence rate of these solvers to produce a solution in a timely manner .",
    "commander @xcite , the cmb gibbs sampler mentioned above , solves the cr system through the conjugate gradient ( cg ) method , using a combination of a block preconditioner on large angular scales and a diagonal preconditioner on small angular scales . while this approach was successful for analyzing wmap observations @xcite , the higher signal - to - noise level of data from more recent experiments like planck effectively halts convergence of the solver . indeed , as we will see in section [ sec : conditioning ]",
    ", the number of cg iterations intrinsically scales with the signal - to - noise ratio of a given data set , limiting the utility of cg for data sets such as these . to produce the low-@xmath5 power spectrum likelihood for the planck mission , for example , the data had to be downgraded to low angular resolution and a substantial amount of regularization noise added @xcite .",
    "even then , several thousands of cg iterations were required for convergence . to go to full angular resolution with this scheme",
    "is simply not computationally feasible .",
    "a somewhat better approach was described by @xcite , who applied the cg method recursively , such that a cg solution on a coarse grid was used as the preconditioner for cg on a finer grid .",
    "we are not aware of any head - to - head comparisons of this method versus the one described by @xcite , but our understanding is that , although it is faster , it still scales with the signal - to - noise ratio of the data set , and therefore does not inherently fix the fundamental convergence problems for high - sensitivity , high - resolution analysis .",
    "more recently , @xcite introduced a stationary iterative method for solving the cr equation .",
    "they did not quote the usual statistics for convergence , such as total reduction in residual and error , however . not knowing the accuracy of their solution , we are unable to compare the efficiency of their method directly to ours . while they do quote the change in the @xmath6 statistic of the posterior probability density _ between successive iterations _",
    ", iterative methods ( and stationary methods in particular ) are vulnerable to breaking down in terms of convergence rate well before reaching true convergence .",
    "also , the @xmath6 explicitly ignores large scales under the mask .",
    "while there certainly are applications where this is acceptable , cmb gibbs sampling is not one of them , since it explicitly iterates between considering the cmb signal a sample from the posterior , which mostly ignores the masked area , and a sample from the prior , which gives equal weight to the masked area .",
    "in this paper we present a new solver for the cr system that is radically different from the cg approach , and instead builds on the multi - level ( or multi - grid ) framework .",
    "these algorithms are best known in the astrophysics community as solvers for elliptical partial differential equations ( pdes ) , although they are in fact more generally applicable to solving many types of linear systems @xcite .",
    "we apply multi - level theory to the cr equation ( although the algorithm is not entirely traditional ) , and show that the resulting algorithm converges to the exact solution with only a handful of iterations even for the most sensitive planck channel . most importantly , and contrary to the cg solver ,",
    "the convergence rate is nearly independent of the signal - to - noise ratio of the data set .",
    "multi - level methods have been explored before in the cmb community for the purposes of map - making .",
    "@xcite described a standard multi - grid method for map - making , although it was eventually unable to compete with standard cg and approximate map - makers .",
    "@xcite also presented a promising two - level cg preconditioner for map - making based on the domain - decomposition method in @xcite .",
    "the map - making equation is different from cr equation , however , in that one does not solve for the cmb signal under a mask . as we will see in section [ sec : conditioning ] , it is this feature in particular that makes convergence difficult to achieve on the cr system .",
    "the details of changing between pixel domain and spherical harmonic domain are usually glossed over in the literature . since we will be solving a large linear system that couples signals on all scales  from individual pixels to the full sky",
    " it is of the utmost importance to be precise about how these conversions are performed .",
    "if implemented incorrectly , even small pixel - scale errors can lead to overall divergence of the entire method .",
    "there is no perfect grid on the sphere , and in choosing a particular one , a number of trade - offs must be considered . in our current implementation",
    "we adopt both the healpix pixelization @xcite and the gauss - legendre spherical grid ( * ? ? ?",
    "* and references therein ) .",
    "the healpix software package contains routines that are useful for our pixel domain computations , while the latter is required for accurate evaluation of equation below .",
    "given such a grid on the sphere ( by which we mean a set of positions @xmath7 on the sky ) , we can use _ spherical harmonic synthesis _ to transform a field expressed in spherical harmonic basis , with coefficients @xmath8 , to a field sampled on the sphere , @xmath9 we will write this operation in matrix form as @xmath10 , where @xmath11 encodes the value of the spherical harmonics evaluated at each @xmath7 of the chosen grid . note that @xmath11 is not a square matrix , as spherical grids need to over - sample the signal to faithfully represent it up to some bandlimit @xmath12 . in typical applications",
    "there are between @xmath13 and @xmath14 more pixels along the rows of @xmath11 than there are spherical harmonic coefficients along the columns .",
    "for the purposes of our method , it will turn out that we need to under - pixelize the signal instead , so there will be more columns than rows in @xmath11 .",
    "the opposite action of converting from pixel basis to harmonic basis is _ spherical harmonic analysis _ , which generally takes the quadrature form @xmath15 where @xmath16 combines quadrature weights and pixel area .",
    "similar to the synthesis case , this operation can be written in matrix form as @xmath17 , where @xmath18 .",
    "a crucial feature of our method is the ability to ( for the most part ) avoid spherical harmonic analysis , however .",
    "instead , we will rely on _ adjoint spherical harmonic synthesis _",
    ", @xmath19 , which simply appears algebraically as the transpose of @xmath11 .",
    "note that , unlike in the case of the more famous discrete fourier transform , @xmath11 is not a square orthogonal matrix , and synthesis and analysis differ by more than transposition and a scale factor .",
    "one may in some situations have that @xmath20 , but this depends on both @xmath12 , @xmath21 and the spherical grid .",
    "the action of applying @xmath11 , @xmath19 , @xmath22 or @xmath23 to a vector is in general referred to as a _ spherical harmonic transform _ ( sht ) .",
    "carefully - optimized libraries are available that perform shts in @xmath24 time ; we use the ` libsharp ` library @xcite .",
    "we now define our data model , and assume from the beginning that the cmb is gaussian and isotropic ( e.g. * ? ? ?",
    "* ) . following the notation of @xcite",
    ", it is convenient to define the cmb signal to be a vector @xmath25 of spherical harmonic coefficients , in which case the associated covariance matrix @xmath26 is given by @xmath27 where @xmath28 is the cmb power spectrum .    using the notation of the previous section , the model for the observed sky map pixel vector , @xmath29 , is @xmath30 where @xmath31 denotes beam - smoothing and the pixel window function , @xmath32 is gaussian instrumental noise , and the subscript of @xmath33 indicates projection to the pixelization of the map @xmath29 .",
    "we assume a symmetric instrumental beam , so that the beam matrix @xmath31 is a diagonal matrix given by @xmath34 , where @xmath35 is the instrumental beam and @xmath36 the pixel window function of the observed grid .",
    "we also assume white instrumental noise , such that the noise covariance matrix , @xmath37 , is diagonal .",
    "we discuss the likely impact of asymmetric beams and correlated noise in section [ sec : discussion ] .",
    "discretization of the model is done simply by picking some @xmath12 for the @xmath25 vector .",
    "the noise vector @xmath32 is related to the map - making process , averaging the noise of time - ordered data ( tod ) that fall within the same pixel , and so is inherently discrete rather than being a discretization of any underlying field . as already mentioned above , no spherical harmonic analysis of @xmath29 ( and therefore @xmath32 )",
    "is required when solving the cr system ; rather , one solves for the projected @xmath25 , and so the noise treatment is always perfectly consistent with the assumed model .",
    "given the data model above , we are interested in exploring the bayesian posterior distribution @xmath38 , the cmb signal given the data and cmb power spectrum .",
    "let us first define @xmath39 where in what follows we will refer to the first term as the _ prior term _ , and the second as the _ inverse - noise term_. it can be shown that if we now solve the _ cr system _",
    "@xmath40 the solution @xmath41 will be the maximum likelihood estimate of @xmath25 .",
    "alternatively , if particular random fluctuation terms are added to the right - hand side of eq . , the solution @xmath41 will instead be samples from the posterior @xcite .",
    "since @xmath42 as @xmath5 increases , the diagonal prior term will at some point dominate the dense inverse - noise term , so that truncation at sufficiently high @xmath12 does not affect the solution of the system .     for the 143 ghz planck channel with a mask covering 40% of the sky , smoothed with a 5.6@xmath43 fwhm beam and truncated at @xmath44 .",
    "_ bottom panel : _ a selection of eigenvectors corresponding to very low eigenvalues .",
    "the structure of the mask ( bottom ) is clearly visible in the eigenvectors.,title=\"fig : \" ]   for the 143 ghz planck channel with a mask covering 40% of the sky , smoothed with a 5.6@xmath43 fwhm beam and truncated at @xmath44 . _",
    "bottom panel : _ a selection of eigenvectors corresponding to very low eigenvalues .",
    "the structure of the mask ( bottom ) is clearly visible in the eigenvectors.,title=\"fig : \" ]   for the 143 ghz planck channel with a mask covering 40% of the sky , smoothed with a 5.6@xmath43 fwhm beam and truncated at @xmath44 .",
    "_ bottom panel : _ a selection of eigenvectors corresponding to very low eigenvalues .",
    "the structure of the mask ( bottom ) is clearly visible in the eigenvectors.,title=\"fig : \" ]    as stressed in section [ sec : sht ] , @xmath45 denotes spherical harmonic _ adjoint synthesis _ , and not spherical harmonic analysis .",
    "pixels that are masked out , typically due to strong foreground contamination , are simply missing from the data vector @xmath29 , and so the corresponding rows are not present in @xmath33 .",
    "this means @xmath33 is not an orthogonal matrix , but that is not a concern since we never perform spherical harmonic analysis of pixels on the observation grid .",
    "the solution @xmath41 is still well - defined everywhere on the sky due to the prior term @xmath46 .",
    "this is typically implemented by introducing zeroes in @xmath47 rather than removing rows of @xmath33 , which has the statistical interpretation of giving those pixels infinite variance .",
    "the two interpretations are algebraically equivalent .",
    "the cr system in equation is symmetric and positive definite , which suggests the use of the conjugate gradient ( cg ) algorithm . for the behavior of cg and other krylov methods ,",
    "we are primarily interested in the eigenspectrum after preconditioning ( * ? ? ?",
    "* and references therein ) , i.e. the eigenspectrum of @xmath48 , where @xmath49 . to illustrate the fundamental problem with the cg algorithm for the application considered here , we show in figure [ fig : eigen ] the eigenspectrum of a low - resolution setup , using a diagonal preconditioner",
    "this case corresponds to a simulation of the 143 ghz planck frequency map @xcite , downgraded to an angular resolution of @xmath50 , bandwidth - limited at @xmath51 , and with a mask applied that removes 40% of the sky .",
    "the overall shape of the spectrum appears to be mostly independent of the resolution , with a significant fraction of degrees of freedom found in the tails .",
    "this behavior is representative of that found in real - world cases .",
    "the problematic feature is the exponential drop in the eigenvalues seen to the left of the figure .",
    "theoretical results indicate that the cg search needs at least one iteration per eigenvalue located in exponentially increasing parts of the eigenspectrum @xcite .",
    "this leads to extreme degradation of cg performance , which is indeed what has been observed with commander on high - resolution , high - sensitivity data .",
    "the exponential spectral feature is due to large - scale modes under the mask . for all but the smallest angular scales",
    ", the @xmath47 term dominates by many orders of magnitude , so that the @xmath46 term is hardly seen at all .",
    "however , vectors that only build - up signal under the mask after beam - smoothing will only see the @xmath46 term of the matrix , as the @xmath47 term vanishes in that case .",
    "the eigenvectors corresponding to the smallest eigenvalues are therefore characterized by having large scales localized within the mask . moreover ,",
    "the solution under the mask is constrained by the values at the mask edge , meaning the @xmath47 term takes effect , and this constraint is harder closer to the edges .",
    "the result is an exponentially - falling eigenspectrum , rather than separated clusters of eigenvalues that cg could more easily deal with .",
    "phrased differently , for data having a high signal - to - noise ratio , the pixels near the edge of the mask carry a large predictive power on the signal inside the mask  a signal that must be reconstructed by the cg algorithm by navigating through a nearly degenerate system . in total , the cg convergence rate is determined by a combination of the overall signal - to - noise ratio and the size and shape of the mask .",
    "we have been unable to achieve proper convergence with this method for the signal - to - noise ratio of a planck - like experiment , for example , independent of preconditioners or number of iterations ; downgrading and adding regularization noise is required to produce robust results .",
    "_ top : _ relative error @xmath52 . for each iteration , the error smoother developed in section [ sec : smoother ] is applied on a healpix @xmath53 grid . the error smoother is only able to get closer to the solution for some part of the frequency spectrum , and quickly stagnates since no improvement is made to the larger or smaller scales . _",
    "bottom : _ the left patch shows the initial error when starting at @xmath54 , while the right patch shows the error after the first iteration .",
    "the remaining large scale errors can be represented on a coarser grid .",
    "this observation leads to the multi - level algorithm . ]",
    "+      the matrix @xmath55 of equation is defined in spherical harmonic domain , and describes the coupling strength between pairs of @xmath56 and @xmath57 . except in unrealistic scenarios with very simple instrumental noise and mask",
    ", we have found no pattern in the magnitudes of the matrix coefficients @xmath58 that is consistent enough to be exploited in a solver .    by moving to pixel domain",
    ", however , we can _ create _ such an exploitable pattern in the magnitudes of the matrix coefficients . in section [ sec : localization ] we will construct a corresponding pixel - domain matrix @xmath59 that is _ localized _ , in the sense that @xmath60 has small magnitude ( less than @xmath61 of @xmath62 ) unless pixels @xmath63 and @xmath64 are very close together on the sphere .",
    "it is no surprise that the @xmath47 term of equation enjoys this property , since we have assumed that instrumental noise is uncorrelated between pixels .",
    "when it comes to the @xmath46 term , we note that @xmath65 is roughly proportional to @xmath66 , at least for @xmath67 .",
    "these are the eigenvalues of the laplacian on the sphere , with @xmath11 being the corresponding eigenbasis .",
    "therefore we can hope that a projection of @xmath46 to pixel domain should be close to a laplacian .",
    "the laplacian is often approximated with a matrix where @xmath68 unless pixel @xmath63 and @xmath64 are neighbors or @xmath69 . while our case will be less perfect , it still suggests that multi - level methods can be very efficient , since those are highly successful for pdes involving the laplacian .    in section [ sec : smoother ]",
    ", we exploit the localization properties in pixel domain to develop an approximate inverse @xmath70 .",
    "figure [ fig : smoother ] demonstrates the use of this approximate solver as part of a simple stationary method @xmath71 where we initialize @xmath72 and then iteratively update the solution . note that if we replace @xmath73 with @xmath74 , eq . represents what are known as jacobi iterations .",
    "the problem that is evident from figure [ fig : smoother ] is that @xmath73 will only make improvements to one part of the frequency spectrum  namely , the highest frequencies that can be represented on the grid used .",
    "this is the typical case when multi - level methods are applied ; iterations of the form of equation are usually only efficient at resolving the relations between pixels / elements that are strongly coupled , which , when @xmath59 is localized , translates to resolving the solution at highest frequencies .",
    "little or no improvement is made between pixels that are weakly or indirectly coupled in @xmath59 , so that no improvement is made to the coarser scales .",
    "put another way , the error , @xmath75 , has its high - frequency components reduced , while the low frequencies are left relatively unaffected .",
    "the approximate inverse @xmath73 is therefore dubbed a _ smoother _ in multi - level terminology .",
    "we will use the term _ error smoother _ to distinguish it from the act of applying a low - pass filter ( which is instead called _ restriction _ in this context ) .",
    "the key is now to project the matrix @xmath55 to pixel grids at different resolutions , producing a set of matrices @xmath76 , where @xmath77 is a level indicator . for each @xmath76",
    "we construct a corresponding error smoother @xmath78 that resolves the errors in one region of the frequency spectrum only . using these levels together",
    ", we arrive at a method that converges very well over the entire frequency spectrum .      , starting from the original system of equation at the top , we plot the transfer filter @xmath79 ( dotted blue ) , the filtered prior @xmath80 ( solid black ) , and an approximation to the diagonal of the inverse - noise term ( dashed red ) .",
    "functions are normalized to an arbitrary scale ( see figure [ fig : level - overview - ell - log ] for the absolute scale ) .",
    "note how the prior term on the pixel levels looks superficially similar to wavelets / needlets in harmonic domain ( * ? ? ? * and references therein ) .",
    "the real - space transform is also similar to wavelets / needlets ( not plotted ) . ]    , but all levels plotted together with a logarithmic scale and with absolute normalization .",
    "we plot the filtered prior @xmath80 ( solid ) , and the diagonal of the inverse - noise term for 26 @xmath81k constant rms and no mask ( dashed ) .",
    "this noise level corresponds to the average of the rms map of the 143 ghz planck band .",
    "the levels are : the original system ( black ) , @xmath82 ( red ) , @xmath83 ( blue ) , @xmath84 ( orange ) , and @xmath85 ( green ) .",
    "note the effect of the filters on the signal - to - noise ratio ; harmonic scales go from being data - dominated to noise - dominated at the point where the solid and dashed lines intersect . ]    in this section we give a brief overview of multi - level theory , together with the specification of our algorithm . for",
    "a more detailed introduction to multi - grid methods , consult one of the number of standard texts ( e.g. * ? ? ?",
    ". ingredients of multi - level algorithms are :    1 .   a set of bases to project the linear system into in order to work on different parts of the solution .",
    "usually these form a hierarchy of levels from finest to coarsest , so that each level solves for different frequencies of the solution .",
    "it is customary to label levels relatively , using @xmath77 for the current level and @xmath86 for the coarser level .",
    "2 .   a way to transfer vectors between the different levels .",
    "the _ restriction _",
    "operator , @xmath87 , takes a vector from a finer level to a coarser level , while the _ interpolation _ operator @xmath88 works in the opposite direction . for symmetric systems",
    ", one often takes @xmath89 .",
    "one linear operator ( left - hand - side matrix ) for each level . for the case where interpolation is chosen",
    "to be transposed restriction , these are often defined recursively as @xmath90 for the projection of a fine matrix @xmath91 to a coarser matrix @xmath92 .",
    "an _ error smoother _",
    "@xmath93 for each @xmath91 that removes the higher frequencies of the error on level @xmath77 , as discussed in the previous section .",
    "multi - level algorithms are often implemented on a grid or a tessellation in real space , with a sparse linear operator , and using averages of neighboring points as the restriction operator @xmath87 . in our case ,",
    "@xmath76 on each level is not sparse , and , at least without approximations , multiplying @xmath94 with a vector would be computationally very expensive on the coarser levels as it would require interpolating back to the highest - resolution grid .",
    "to avoid this cost , we instead define our levels in spherical harmonic domain .",
    "let @xmath95 be a spherical harmonic low - pass filter that emphasizes one part of the frequency spectrum , and define @xmath96 to be a diagonal matrix with elements @xmath95 .",
    "we then define @xmath97 where the prior term @xmath98 is diagonal with entries given by @xmath99 and the modified beam matrix @xmath100 is diagonal with elements given by @xmath101 .",
    "in this case , the system is bandlimited by some @xmath102 , above which @xmath103 .",
    "figures [ fig : level - overview - ell ] and [ fig : level - overview - ell - log ] show the filters used in our setup ; we discuss the choice of filters further in section [ sec : localization ] .    with this choice , we can clearly satisfy the multi - level hierarchy of equation by choosing the restriction operator @xmath87 as an @xmath104-by-@xmath105 block matrix , where the block for @xmath106 is diagonal with entries @xmath107 and the block for @xmath108 is zero .",
    "l @xmath109 : + * inputs : * + @xmath77  the current level + @xmath41  starting vector + @xmath110  right - hand side +   + @xmath86 denotes the coarser level relative to @xmath77 . +",
    "* output : * + improved solution vector @xmath41 +   +    [ cols= \" < , < \" , ]",
    "so far we have not specified the exact form of the low - pass filters @xmath95 required for every level .",
    "it turns out that careful selection of these filters is essential to ensure that the pixel projection of @xmath91 is localized , and hence that the construction of an efficient error smoother is possible .    as indicated in eq .",
    ", the spherical harmonic system @xmath91 on each level @xmath77 is projected to pixel domain with @xmath111 where the prior and pixelized beam terms are this time given by ( respectively ) @xmath112 note that the pixelization along the rows of @xmath113 is the observational grid , while the pixelization down the columns is that of the current level .",
    "the matrices @xmath114 and @xmath113 are both rotationally invariant . by the addition theorem of spherical harmonics ,",
    "the coupling strength between two points on the sphere separated by angular distance @xmath115 is given by @xmath116 where we insert @xmath117 for @xmath114 and @xmath118 for @xmath113 .",
    "the pixel - domain localization of such matrices depends entirely on @xmath119 . in our experience ,",
    "the @xmath119 that lead to localized matrices in pixel domain tend to be flat or polynomially increasing before an exponential drop .",
    "since @xmath35 already describes a localized beam , and @xmath65 increases non - exponentially , crafting a localized system @xmath76 at each level is indeed possible .    selecting the filters @xmath79 ,",
    "whose products form @xmath120 and @xmath96 for each level , is a non - trivial matter .",
    "the main characteristic the filters must have is that each @xmath120 falls off quickly enough in real space to avoid strong couplings between the edge of the mask and the interior .",
    "figure [ fig : ringing ] shows what happens if this is not controlled correctly  the long - range couplings make the construction of an error smoother @xmath73 impossible .",
    "in contrast , figure [ fig : maskeffect ] shows the behavior of the operators in the well - tuned case .",
    "a filter that we found to work very well is given by squaring the exponent of a gaussian , @xmath121 the scale parameter @xmath122 is simply chosen from the scale behavior that we want . in our test runs , we chose the constraints @xmath123 at the @xmath124 level and @xmath125 at the @xmath83 level .",
    "this filter has the following advantages over a simple gaussian :    * it decays much more quickly in @xmath5 , while in real space it decays almost as quickly in the tails as the gaussian .",
    "this allows us to avoid increasing the bandlimit of the original system beyond @xmath126 .",
    "* the rapid decay with @xmath5 is also beneficial to counter the behavior of @xmath65 . in the range @xmath127",
    ", @xmath65 follows a rather steep trajectory ( between @xmath128 and @xmath129 ) which , when only countered by a gaussian , causes some ringing and less locality . *",
    "using gaussian filters shapes the @xmath47 term so that couplings around a given pixel are similar to a gaussian with fwhm of 4 pixels .",
    "that is , the couplings between neighboring pixels are rather strong .",
    "the filter defined above produces much weaker couplings between neighbors .",
    "this is not currently an advantage , because we let every pixel `` see '' a radius of @xmath130 pixels around itself anyway in the error smoother .",
    "however , it could become an advantage in the future if @xmath131 is chosen adaptively for each pixel .",
    "despite these features , the simple gaussian filter behaved better at the coarser levels with very high signal - to - noise , as can be seen by comparing the second panel of figure [ fig : maskeffect ] with the first panel of figure [ fig : resolution - effect ] . in our tests we chose a gaussian filter @xmath132 for levels @xmath133 , tuned so that the cumulative filter @xmath95 on each level roughly corresponds to a gaussian with fwhm of 2 pixels .",
    "figure [ fig : bandlimit ] shows the effect of choosing the bandlimit @xmath135 too low . on the coarser levels , ringing from the inverse - noise term causes strong non - local couplings unless the bandlimit is set as high as @xmath136 .",
    "this limit depends on the signal - to - noise ratio , and @xmath137 is sufficient on the @xmath53 level .",
    "the healpix grid can only represent a field accurately up to @xmath138 , and will in fact see different scales on different parts of the sphere , due to the necessary irregularities in the pixelization .",
    "this is the primary reason for the non - traditional level traversal structure chosen in section [ sec : mg ] .",
    "the pixel projection operator @xmath139 removes some parts of the projected field that the grid can not represent , but this is after all how a multi - level restriction normally works , and so poses no problems .",
    "the filter @xmath95 allows us to set @xmath135 much lower than the full @xmath12 .",
    "the two shts involved in @xmath140 still involve an @xmath141 grid , however , so the coarsest levels are still almost as computationally expensive as the finest levels .",
    "to work around this , the key is to note that the operator @xmath142 does not `` see '' scales in the inverse - noise map beyond @xmath143 .",
    "this follows from an expansion into wigner 3j - symbols @xcite .",
    "simply degrading the inverse - noise map to a coarser resolution healpix grid was found to be far too inaccurate , so more care is needed .",
    "first , we rewrite the operator as @xmath144 where @xmath145 denotes the quadrature weights of the healpix @xmath141 grid , so that @xmath146 corresponds to spherical harmonic analysis , as described in section [ sec : sht ] .",
    "then , we write @xmath147 for the pixels on the diagonal of @xmath148 , and @xmath149 for the same map expanded into spherical harmonics . since the operator of equation does not see coefficients beyond @xmath143 , we can truncate @xmath149 and project it onto a gauss - legendre grid of the same order , which ( unlike healpix grids ) allows spherical harmonic analysis that is accurate to almost machine precision .",
    "using this re - weighted and downgraded inverse - noise map as the diagonal of a new inverse - noise matrix @xmath150 , we have that @xmath151 where @xmath152 and @xmath153 indicate spherical harmonic synthesis and analysis on the gauss - legendre grid .",
    "a simple diagonal error smoother does not converge in our setup , primarily because pixels on the edge of the mask can have a very strong influence on the solution in the interior of the mask , as seen in figure [ fig : maskeffect ] .",
    "also , when applying gaussian filters , the couplings between neighboring pixels are rather strong , preventing the use of a diagonal error smoother even far from the mask .",
    "the basic strategy for our error smoother is to make sure that every pixel `` sees '' neighboring pixels in some radius @xmath131 around it . in our case",
    "we let @xmath130 on all levels , although improvements on this may be possible , especially in cases with lower signal - to - noise than ours .",
    "we start by dividing the sphere into tiles of size @xmath131-by-@xmath131 .",
    "then , we include the couplings between pixels in the same and neighboring tiles while ignoring any couplings between pixels further apart , so that couplings are included in a radius of at least @xmath131 pixels around every pixel .",
    "the result is a block sparse matrix , as shown in fig .",
    "[ fig : smoother - structure ] .",
    "next , we explicitly compute the parts of @xmath114 ( eq . ) and @xmath113 ( eq . ) that fall within the sparsity pattern by evaluating the sum over legendre polynomials from equation . after preparing the block sparse matrix approximations , we use matrix multiplication without fill - in to compute @xmath154  that is , we neglect resulting blocks outside of the same sparsity pattern .",
    "the approximant for @xmath114 can then be added directly . finally , we perform a zero - fill - in incomplete cholesky factorization ( icc ) , i.e. we perform in - place cholesky factorization of the block sparse approximant as usual , but ignore any element updates outside of the sparsity pattern during the factorization process .    without modification ,",
    "the factorization process usually fails , either due to the sparse approximant of the full dense matrix ending up non - positive - definite , or because of elements dropped during the icc .",
    "when this happens , we do a binary search for the lowest ridge adjustment @xmath155 that , when added to the diagonal , makes the factorization procedure succeed , and scale this @xmath155 by a factor of @xmath156 for the final factorization .",
    "typical ridge values @xmath155 are in the range @xmath157 to @xmath158 times the maximum element of @xmath91 .",
    "after factorization , applying the smoother is simply a matter of doing the usual triangular solve .",
    "this is an inherently sequential process , and the smoother therefore currently runs on a single cpu core .",
    "since an error smoother only needs to work locally , we expect to be able to apply domain decomposition techniques , partitioning the sphere into large domains that overlap by @xmath131 or @xmath159 pixels , and applying one error smoother on each domain .",
    "proper parallelization of the error smoother is left for future work , however .",
    "also note that the process described above is the very simplest incomplete factorization algorithm , and more sophisticated incomplete factorization algorithms are standard in the literature .    in section [ sec : results ] , we quote numbers for the execution time and memory usage of the smoother .",
    "one possibility for reducing memory consumption in the future is to let @xmath131 be adaptive , as it can be made smaller away from the edges of the mask .",
    "all error smoother computations are done in single precision . in the current implementation",
    ", computing @xmath160 is very expensive , as we sample it directly on the @xmath141 grid .",
    "this is not a fundamental scaling problem , but rather an issue of implementation , as the degraded inverse - noise map on the gauss - legendre grid described in section [ sec : bandlimit ] could also be used in this setting .",
    "healpix grid in ring - ordering .",
    "_ bottom panel _ : the blocks of @xmath161 corresponding to the red rectangle in the top panel .",
    "the blocks on the diagonal contain within - tile couplings , while off - diagonal blocks are couplings between pixels in neighboring tiles .",
    "each block is rectangular because @xmath33 samples on a grid with @xmath162 more pixels than the grid sampled by @xmath139.,title=\"fig : \" ]   healpix grid in ring - ordering . _",
    "bottom panel _ : the blocks of @xmath161 corresponding to the red rectangle in the top panel .",
    "the blocks on the diagonal contain within - tile couplings , while off - diagonal blocks are couplings between pixels in neighboring tiles .",
    "each block is rectangular because @xmath33 samples on a grid with @xmath162 more pixels than the grid sampled by @xmath139.,title=\"fig : \" ]",
    "( black circles , left axis ) , as well as the largest error across all pixels ( red triangles , right axis ) . ]    , @xmath163 ( black circles ) , and similarly scaled residuals , @xmath164 ( red triangles ) . both are normalized with respect to the initial error / residual .",
    "the two quantities behave very similarly , implying that the residual is an excellent proxy for the true error . ]",
    "lcccccc @xmath126 & 3000 & 1 &  & 6 @xmath165 2.8 &  & 16.8 + @xmath166 & 3000 & 1 & 4 @xmath165 1.2 & 4 @xmath165 2.8 & 2 @xmath165 11 & 38.0 + @xmath53 & 2048 & 2 & 8 @xmath165 0.3 & 10 @xmath165 1.3 & 4 @xmath165 2.3 & 24.6 + @xmath167 & 1280 & 4 & 16 @xmath165 0.07 & 20 @xmath165 0.40 & 8 @xmath165 0.57 & 13.7 + @xmath168 & 768 & 8 & 32 @xmath165 0.016 & 40 @xmath165 0.10 & 16 @xmath165 0.14 & 6.75 + @xmath169 & 384 & 16 & 64 @xmath165 0.004 & 80 @xmath165 0.03 & 32 @xmath165 0.035 & 3.78 + @xmath170 & 224 & 32 & 128 @xmath165 0.002 & 160 @xmath165 0.008 & 64 @xmath165 0.009 & 2.11 +    @xmath171 & 40 & 32 &  &  & 32 @xmath165 0.028 & 0.90 +    other work & & & & & & 8 + full w - cycle & & & & & & 114    the basic assumptions for our experimental setup have already been laid out in section [ sec : data - model ] .",
    "we choose for our example the rms map and symmetric beam approximation of the 143 ghz channel of planck , as provided in the planck 2013 data release @xcite .",
    "we tried running both with the 40%-sky , 80%-sky and 97%-sky masks used in the planck analysis , in all cases together with the 143 ghz point source mask .",
    "the mask has some impact on speed of convergence , but not enough to warrant attention , and we therefore only present the results from the 80%-sky mask , which was the _",
    "slowest _ to converge .    for the power spectrum , @xmath28",
    ", we use the standard best - fit planck+wp+high-@xmath5 6-parameter @xmath172cdm spectrum @xcite , but set @xmath173 and @xmath174 to the value of @xmath175 as a wide prior for any residual monopole or dipole component .",
    "statistically , the prior for the monopole and dipole is of little relevance , since the data so strongly constrain these components .",
    "note that the present algorithm will not let us condition on a given monopole and dipole ( i.e. set @xmath176 ) , at least without modifications .",
    "to produce the right - hand side , @xmath110 , corresponding to a random test realization , we draw a simulated @xmath177 from the prior @xmath178 , and multiply it with @xmath55 of equation . this synthetic setup allows us to track the true error , @xmath179 . in a real setting the right hand side",
    "is of course generated from observed data , and in this case one can only track the residual , @xmath180 .",
    "the error smoothers are least efficient on the largest scales . at the same time , these are much cheaper to process than the small - scale smoothers due to the @xmath181 scaling of the spherical harmonic transforms . we therefore choose a partial w - cycle , where the levels for @xmath182 participate in a w - cycle ( @xmath183 in figure [ code : mg ] ) , but the very expensive error smoother of the @xmath82 level , as well as shts at @xmath126 , are only run once on the way down and once on the way up ( a v - cycle ) .    in figure",
    "[ fig : errors ] we plot the resulting convergence , in terms of absolute error as a function of w - cycle iteration count . here",
    "we see that the error falls exponentially with cycle count , at the rate of roughly one order of magnitude per iteration .",
    "the largest error anywhere on the sky is smaller than @xmath184 after only 3 w - cycles , and approaches the numerical precision limit after 8 cycles .",
    "as mentioned above , since we know what the true solution is for the simulated data , we are also able to trace the absolute error , @xmath185 , although only the residual , @xmath180 , is available in real - world applications . figure [ fig : residuals ] shows that these have qualitatively very similar behavior as a function of w - cycle count , which implies that the residual can be used as a robust proxy for the actual error for the multi - level algorithm .",
    "the same is not true for the cg method , for which the error can flatten earlier than the residual due to the presence of the nearly singular modes in @xmath55 .",
    "finally , in figure [ fig : errors - by - scale ] we show the relative error as a function of multipole moment and w - cycle count .",
    "this plot highlights the problematic angular scales , and is therefore particularly useful during the debugging and tuning phase of the analysis ; for example , the use of a v - cycle rather than a w - cycle would make the large scales noticeably lag behind in convergence on this plot .",
    "another example is that , if the filters @xmath186 are poorly - tuned ( potentially causing the method to diverge ) , the responsible level can often be picked out on this plot .",
    "the total run - time for this setup was 114 seconds wall time per w - cycle on 16 cpu cores ( amd 6282 running at 2.6 ghz ) .",
    "table [ tab : cycle - cost ] breaks this cost down further to the individual levels and actions .",
    "the bulk of the memory use is by the error smoothers , which consume about 20 gib of memory ( see table [ tab : smoother - cost ] ) .",
    "the total process footprint was around 30 gib , although unnecessary temporary arrays abound in the current implementation .    table [ tab : smoother - cost ] presents the cost of the necessary precomputations .",
    "for every new combination of instrumental beam , noise map and mask , or for a new choice of multi - level filters @xmath132 , one needs to precompute an approximation to @xmath187 for every solver level .",
    "these precomputations required a total of 44 cpu hours in our tests , but are trivially parallel .",
    "we also expect that one will usually load the results from disk .",
    "the approximation for @xmath114 must be recomputed every time @xmath28 changes , which in the case of gibbs sampling means every time one wants to run the solver . fortunately",
    ", this computation is much cheaper and only requires around 100 cpu minutes of trivially parallel work , plus 2 minutes of non - parallel work .",
    "we argue in section [ sec : discussion ] that it should be possible to greatly decrease precomputation time in future .",
    "rcccc 1024 & 727 & 85 & 1.15 & 15 + 512 & 509 & 15 & 0.35 & 3.7 + 256 & 340 & 2.4 & 0.10 & 0.93 + 128 & 230 & 0.36 & 0.02 & 0.23 + 64 & 452 & 0.05 & 0.007 & 0.058 + 32 & 363 & 0.01 & 0.002 & 0.014 + total & 2621 & 103 & 1.6 & 20    the main weakness in the current implementation is the lack of parallelization in the error smoothers .",
    "not only does the code need to be run on a single node , but the 40 seconds spent on error smoothing runs on a single cpu core , with the 15 other cores idling .",
    "parallelization of the smoother would bring the wall time much closer to 80 seconds , as well as allowing the distribution of the 20 gib of smoother data among several cluster nodes .",
    "the cr solver is part of commander 2 , which is made available as open source software under the bsd license ( core code ) and the gpl license ( full software when including dependencies ) . for more information , see ` http://commander.bitbucket.org/ ` .",
    "commander 2 is implemented in a mixture of python ( using numpy and scipy ) , cython @xcite , fortran 90 , and c. for shts we use ` libsharp ` @xcite . for our benchmarks",
    "we have used openblas @xcite for linear algebra .",
    "the main computation time is spent in ` libsharp ` or openblas , and as such is already highly optimized .",
    "the computation of equation benefited greatly from being structured as described in the appendix of @xcite .",
    "in addition to what is mentioned there , we made use of the avx and fma4 instruction sets .",
    "also , note that all the computations for the error smoother could be performed in single precision .",
    "we have presented a new algorithm for solving the gaussian constrained realization system for high - resolution cmb data .",
    "this method is based on ideas from multi - grid ( or multi - level ) theory , and is fundamentally different from the conjugate gradient methods traditionally used for this problem .",
    "being only weakly dependent on the signal - to - noise ratio of the data set under consideration , our new method converges exponentially to numerical precision when properly tuned , and is capable of producing constrained realizations for the full resolution of a planck - like data set within minutes . for comparison",
    ", we have yet to achieve robust full - sky convergence with cg methods for the same data set . indeed , this particular issue was the single most important obstacle preventing a full - resolution analysis of the planck 2013 data release with the commander code .",
    "the ultimate goal of this line of work is to perform an exact global bayesian analysis of the high - resolution , high - sensitivity observations now being produced by cmb experiments , including component separation as described by @xcite . for this to be successful",
    ", multi - frequency and multi - component analysis must be added to the algorithm .",
    "other complications , such as the possible asymmetry of the cmb on large scales ( e.g. * ? ? ?",
    "* ) , will also need to be taken into account .",
    "as such , the present paper represents only the first step towards a complete solution .",
    "we also emphasize that the algorithm as presented here is only the first implementation of a more general framework , and we expect that many improvements with respect to computational speed , application to more general cases , overall robustness and stability , and even user interfaces , will be introduced in the near future . before concluding this paper , we will mention a few relevant ideas , but leave all details for future publications .",
    "firstly , as is evident from figure [ fig : maskeffect ] , our method is quite sensitive to the behavior of the tails of the instrumental beams extending as far out as the @xmath188 level , as these formally constrain the solution inside the mask .",
    "these tails are not realistically known to such high accuracy , and so this issue is therefore a modeling problem as well as a numerical problem . in practice",
    ", it seems that in the absence of other options , one should just choose a form for the tails that falls quickly enough to not have an effect on the solution , and that allows a small computational bandlimit , @xmath12 .",
    "in short , optimally tuning the tails of the beam profile may render a more stable solution at a lower computational cost .",
    "for an exact analysis of data from current and forthcoming cmb experiments , one would ideally like to account for the effect of asymmetric beams . with the above in mind ,",
    "we envision two solutions for this .",
    "one option is to modify the algorithm so that the beams are defined in pixel space , as is done in febecop @xcite for instance , and then carry the febecop beams through to the computation of the smoother .",
    "the main challenge in this scenario is how to avoid very expensive matrix - vector multiplications at the coarse levels .",
    "alternatively , and perhaps more simply , one could use the multi - level solver for perfect symmetric beams described here as a preconditioner for a cg search , which then accounts for the beam asymmetries in its own internal matrix multiplications .",
    "correlated noise is another significant complication for current cmb observations .",
    "while these correlations have a complicated morphology in pixel space , being convolved with the scanning strategy of the experiment , they are simple to describe in the time - domain . with the vastly improved convergence rate of the multi - level method presented here",
    " requiring only a handful of iterations to reach sub-@xmath81k errors  it may for the first time be realistic to define the constrained realization system in time - domain , rather than map - domain .",
    "as for asymmetric beams , this can either be done by defining the multi - level scheme directly in time - domain , or , if that does not succeed , by using the multi - level solver for uncorrelated noise as a preconditioner for a time - domain cg search .",
    "going to time - domain also provides a direct route to handling beam asymmetries and optical sidelobes by full - sky convolution @xcite .",
    "the current computational bottleneck in our implementation is the time needed to precompute the error smoothers .",
    "the time is spent almost exclusively on sampling rotationally - invariant operators at every position on the sphere by brute force evaluation of equation . while the code for this computation is already highly optimized , as mentioned above , we do not exploit any symmetries from pixel to pixel .",
    "the grid used within the multi - level process is arbitrary , and not necessarily related to the grid of the inverse - noise map , @xmath37 , or data vector , @xmath29 . a future implementation of the algorithm will therefore employ a different grid with greater symmetry than the healpix grid , which will only require evaluation of the smoother blocks 37 times per pixel ring , thus reducing the computational scaling from @xmath189 to @xmath190 .    finally , the error smoother evaluation is currently not parallelized , and only executes on a single cpu core . as the error smoothers only need to work well for the local couplings , we expect to be able to partition the sphere into multiple partially - overlapping domains , and apply an error smoother on each domain in parallel , at the cost of some extra computation on the domain borders . assuming that this approach is successful",
    ", the spherical harmonic transforms will once again become the bottleneck of the overall algorithm .",
    "we thank mikolaj szydlarski and martin reinecke for useful discussions .",
    "dss , hke and pb are supported by european research council grant stg2010 - 257080 .",
    "kam is supported by the research council of norway through a centre of excellence grant to the centre for biomedical computing at simula research laboratory ."
  ],
  "abstract_text": [
    "<S> we present a multi - level solver for drawing constrained gaussian realizations or finding the maximum likelihood estimate of the cmb sky , given noisy sky maps with partial sky coverage . </S>",
    "<S> the method converges substantially faster than existing conjugate gradient ( cg ) methods for the same problem . </S>",
    "<S> for instance , for the 143 ghz planck frequency channel , only 3 multi - level w - cycles result in an absolute error smaller than 1@xmath0 in any pixel . using 16 cpu cores , this translates to a computational expense of 6 minutes wall time per realization , plus 8 minutes wall time for a power spectrum - dependent precomputation . </S>",
    "<S> each additional w - cycle reduces the error by more than an order of magnitude , at an additional computational cost of 2 minutes . for comparison </S>",
    "<S> , we have never been able to achieve similar absolute convergence with conventional cg methods for this high signal - to - noise data set , even after thousands of cg iterations and employing expensive preconditioners . </S>",
    "<S> the solver is part of the commander 2 code , which is available with an open source license at ` http://commander.bitbucket.org/ ` . </S>"
  ]
}