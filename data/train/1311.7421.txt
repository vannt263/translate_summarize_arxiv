{
  "article_text": [
    "the fast growth of internet bandwidth usage , mainly due to the exponential increase in internet videos ( youtube ) and iptv , has put the internet infrastructure under high pressure . according to a cisco survey  @xcite , by 2014",
    "the network traffic is expected to approach 64 exabytes per month , with videos accounting for more than 91% of global traffic .",
    "redundancy elimination ( re ) techniques have been proposed to handle the huge amount of data in the access networks .",
    "their main aim is to remove requests and/or responses of redundant data in the network , reducing the traffic and costs in the access network .",
    "re techniques can be classified into two kinds : ( a ) caching to remove transfers , and ( b ) data replacement with a shim header .",
    "former relies on caching network - level objects and storing them temporarily in the network .",
    "caching techniques rely on redundancy of the traffic  @xcite , implying that a large portion of the network traffic is duplicated and could be cached for later requests .",
    "another incentive is that storage prices have decreased faster than bandwidth costs @xcite .",
    "the second approach replaces redundant data with a shim header in an upstream middlebox ( usually close to the server ) and reconstructing it in a downstream middlebox before delivering it to the client .",
    "commercial products provide wan optimization mechanisms through re in enterprise networks @xcite .",
    "recently , re has received considerable attention from the research community  @xcite . in  @xcite ,",
    "the authors propose a network - wide approach for redundancy elimination through deployment of routers that are able to remove redundant data in ingress routers and reconstruct it in egress routers .",
    "however , they also require tight synchronization between ingress and egress routers in order to correctly reconstruct the packet and they also require a centralized entity to compute the redundancy profiles . in  @xcite , the authors propose to use caches in the local host and use prediction mechanisms to inform servers that they have already the following redundant data .",
    "however , they are not able to share the cached data among other nodes due to the local characteristic of the cache .    although both caching and re have been around in the research community , there has not been any thorough comparison in the effectiveness of the two above - mentioned strategies : in - network caching vs. redundancy elimination .",
    "work in  @xcite combines in - network caching and re , but limiting the applicability of the solution to a single content source only .    in this paper",
    ", we perform a comparison between an in - network caching architecture ( inca ) and state - of - the - art re solutions .",
    "although inca models a generic network caching architecture , it is effectively ccn - like  @xcite . however , as we want to understand the performance differences between caching and re , we do consider low - level protocol details .",
    "we perform an extensive comparison , using real network topologies from rocketfuel , between inca and re .",
    "we have implemented the different solutions on our testbed and compare them by running them on real network topologies .",
    "we consider the position of a single isp interested in reducing its traffic both within and outside of its own network .",
    "our key findings can be summarized as follows :    * in terms of reducing external network traffic , inca is always superior when compared to isp - internal re solutions  @xcite .",
    "end - to - end re solutions  @xcite can reduce external traffic , but are outside the control of the isp ; furthermore , they are not as effective as inca . * in terms of reducing internal network traffic ,",
    "inca is in most cases clearly superior to state - of - the - art re solutions@xcite , with at least 5065% improvements in internal traffic reduction .",
    "the organization of this paper is as follows .",
    "section [ s : background ] presents the background information and related work about in - network caching and redundancy elimination solutions .",
    "section [ s : architecture ] introduces the in - network caching architecture ( inca ) , describing its main features .",
    "section [ s : evaluation ] presents the evaluation methodology , and the comparison results between inca and re solutions .",
    "finally , section  [ s : conclusion ] summarizes the paper .",
    "recently , information - centric networking ( icn ) , e.g.,@xcite has emerged as a more general , network - wide caching solution . in icn ,",
    "content caches in the network ( e.g. , in routers ) store content that passes through them and if they see requests for the same content , they are able to serve it from their cache .",
    "inca is essentially an icn architecture , but our intention is not to provide yet - another - icn - architecture .",
    "instead , inca simply considers the key features of icn architectures , namely caching and routing towards some point of origin for content , and ignores practical , low - level protocol details .",
    "inca draws inspiration from ccn  @xcite and our previous work  @xcite , but does not specify low - level behavior .",
    "other caching proposals also exist .",
    "cache - and - forward ( cnf ) @xcite is an in - network caching architecture where routers have a large amount of storage . these routers perform content - aware caching , routing and forwarding _ packet _ requests based on location - independent identifiers , similar to ccn .",
    "modern re schemes use a fingerprint - based data stripping model .",
    "nodes generate a set of fingerprints for each packet in transit , where each fingerprint can be generated over a pre - defined block size . upon detecting a cached fingerprint ,",
    "the upstream node replaces the data by a fingerprint and the downstream node replaces the fingerprint with the original data , reducing the overall data transmission over the network . as described in  @xcite ,",
    "both upstream and downstream nodes need to be strongly synchronized in order to work correctly .",
    "a similar approach is presented in  @xcite .",
    "work in  @xcite proposes to extend the re technique to the whole network , i.e. , to make re as a basic primitive for internet.the main idea is to collect redundancy profiles from the network and use a centralized entity to compute paths between destinations within an isp with higher re capabilities .",
    "therefore , data going through these networks have higher re footprint reduction than going to other paths in the network . despite the improved re capacity",
    ", it still requires strong synchronization between the upstream and downstream routers in order to work properly .",
    "a third re approach  @xcite was recently proposed to overcome the synchronization issue in order to be deployed in data - center networks .",
    "as cloud elasticity favors the migration and distribution of work among a set of nodes , it is hard to set up the synchronization between two fixed nodes .",
    "therefore , the main idea of  @xcite is to create a local cache together with a predictive mechanism to acknowledge already cached data to the server . in this scenario",
    ", the service sends a predictive acknowledgement to the server informing that the requested data is already present in the client , thus , removing the redundant data . despite the improvement over the fixed node requirement , the use of local storage prevents the sharing among other nodes , increasing the overall sharing capacity and hit ratio .",
    "therefore , the re is not network wide , but for redundant data that may be requested again in the local node .",
    "inca focuses on the following key aspects of icn architectures : routing requests for content towards a known point , caching of content , and forwarding responses back to the requesting entity .",
    "this model is similar to ccn  @xcite .",
    "the basic in - network caching mechanism is performed by a _ content router _ ( cr ) .",
    "a cr is a data forwarder similar to a regular router , but has some internal memory that can be used to store data in transit .",
    "each piece of content has a _",
    "chunk i d _ as its permanent identifier from a cryptographic hash function .",
    "any cr on the path between a server and clients caches the data in its memory .",
    "further requests can be served by the local copy in the cr . for a further discussion on this model and its limitations ,",
    "we refer the reader to  @xcite .      as in  @xcite",
    ", we use three admission policies for deciding which content a cr caches .    * * all * admits all objects into the storage at the cr . in other words ,",
    "every object that transits through the cr is taken into storage and another object is possibly evicted .",
    "this is the typical behavior of web caches . *",
    "* cachedbit *  @xcite sets one bit in the cr header to indicate whether a given piece of content has already been cached or not , preventing duplicated content along the same path .",
    "if the path between the client and server is @xmath0 hops , then a cr will cache the content with probability @xmath1 and once the content is cached , downstream crs will not cache it , with the exception of the last cr on the path which will always cache it ( see section  [ ss : experimental - results ] for an explanation ) . * * neighbor search ( nbsc ) *  @xcite works like _ cachedbit _ , but if a cr encounters a miss , it will query neighboring crs for that piece of content .",
    "crs periodically exchange bloom filters of their contents with their neighbor crs .",
    "please see  @xcite for details about the size of bloom filters , exchange frequency , and query radius .",
    "we use least recently used policy to decide what to evict when the storage at the cr is full .",
    "the results in  @xcite showed that a cachedbit - like admission policy is needed to get good caching performance , but that the addition of nbsc gives a considerable boost in reducing network traffic .",
    "we chose 4 real - world networks from rocketfuel  @xcite : exodus , sprint , at&t and ntt , and performed a set of experiments using different cooperative caching strategies .",
    "table  [ tab : topologies ] shows an overview of the networks .",
    "all the experiments are performed on our department cluster consisting of dell poweredge m610 nodes .",
    "each node is equipped with 2 quad - core cpus , 32 gb memory , and connected to 10-gbit network .",
    "all the nodes run ubuntu smp with 2.6.32 kernel .",
    ".topologies used in experiments [ cols=\"^,^,^,^\",options=\"header \" , ]     -5 mm    figure  [ fig : footprint ] shows the internal traffic reduction as measured by the network footprint reduction .",
    "the y - axis shows the fraction of internal traffic that was reduced by the caches in the crs . as with the other metrics ,",
    "the differences between the three admission policies are small .",
    "again , nbsc is clearly superior to cachedbit which , in turn , is clearly superior to the all policy .",
    "footprint reduction is the reason why we tweaked cachedbit to create a copy of the chunk at the cr closest to the client . without the additional copy ,",
    "all - policy is better at footprint reduction than cachedbit .",
    "we observed that this additional copying drops the hit rate by a negligible amount , but raises the footprint reduction considerably .",
    "contrasting the numbers in table  [ tab : smartre - footprint - ideal ] with the inca footprint reductions in figure  [ fig : footprint ] , we see that they are similar in value . for small inca cache sizes , smartre yields a higher reduction , whereas for larger cache sizes , inca has the upper hand . however , even for very modest cache sizes , nbsc is able to achieve an equal footprint reduction to smartre and for large cache sizes , the footprint reduction is improved by 5065% .",
    "cooperative caching is therefore much more efficient at reducing internal traffic than smartre .",
    "recall that our inca experiments considered one chunk to represent one file , whereas in the smartre experiments , a chunk is one packet .",
    "this means that the footprint reduction numbers can not be directly compared since traffic is different in the two cases .",
    "however , based on the numbers presented in  @xcite , we can infer a mapping between smartre and inca experiments . in",
    "@xcite it is shown that smartre gets close to its ideal performance with 6  gb of storage per router .",
    "assuming the same 6  gb of storage per cr , the case of 1024 chunks of storage , where 1 chunk equals 1 file , would imply the average file size to be about 6  mb .",
    "if the content is a mixture of text , images , and short videos , this seems like a reasonable , if not even conservative , number .",
    "( for content consisting mainly of larger videos , this would not be sufficient . )",
    "we ran experiments with smartre where we took the ideal cache size used to obtain the numbers for table  [ tab : smartre - footprint - ideal ] , and set it to @xmath2 , @xmath3 , and @xmath4 of that value . for each case , we then ran the experiment to obtain the reduction in footprint .",
    "this allows us to plot the inca and smartre footprint reductions on the same x - axis , shown in figure  [ fig : footprint ] .",
    "this confirms that inca is more efficient in reducing internal traffic in the network .",
    "the additional reduction in traffic varies between almost 200% for small caches and 50% for large caches .",
    "-5 mm    cachedbit is similar to the heuristic `` heur1 '' from  @xcite in how it attempts to place the content . in  @xcite ,",
    "the performance of these two heuristics was found lacking when compared to the smartre algorithm with its centralized controller deciding on what to cache where .",
    "if the same translates to an inca caching network , a centralized controller deciding on placement of chunks in crs would be a superior choice .",
    "however , similar placement problems are often np - complete  @xcite , although some simplifications are likely to yield a linear program .",
    "we have not considered a central placement agent in inca , although it could be included in future work .",
    "an important difference is that inca is able to share cache space between clients , whereas smartre has fixed buckets for each ingress - egress flow .",
    "this gives inca more possibilities in exploiting the cached data , thus reducing footprint and improving hit rate .",
    "_ we believe this sharing of cache space between all client and server pairs is what gives inca an advantage over smartre . _",
    "contrasting our results to the single server case presented in  @xcite is part of our future work .    comparing inca with smartre , we come to the following conclusions :    * for external traffic reduction , inca is always superior , because smartre has no effect on external traffic .",
    "* for internal traffic reduction , performance of inca ( with neighbor search ) is in most cases clearly superior , up to 5065% more reduction in internal traffic . however , the differences depend on how the mapping between cache sizes is done and the file size distribution , thus in different environments the results could be different",
    ".    however , in our experimental environment inca with neighbor search is far more effective in reducing both internal and external traffic .",
    "+    -5 mm    figure [ fig : inca - vs - endre ] shows the bandwidth savings of both inca and endre  @xcite on three different networks .",
    "we show cache sizes of 128 and 256 chunks .",
    "the bandwidth savings of endre remains the same on three networks because it is end - to - end solution .",
    "the network topology does not affect its performance .",
    "we can clearly see that inca is superior to endre .",
    "even the all strategy is slightly better than endre in all three networks .",
    "pack  @xcite is another end - to - end re solution , but according to  @xcite , its performance is about 2% worse than endre .",
    "larger cache sizes improve inca s performance ; figures not shown due to space limitations .",
    "note that inca s savings are a combination of results shown in figures  [ fig : hitrate ] and  [ fig : footprint ] .",
    "anand et al .",
    "@xcite have evaluated real trace captures and their results suggest that a middlebox - based solution ( i.e. , something akin to inca ) has an advantage over end - to - end re solutions in saving network bandwidth .",
    "inca does have a definite advantage in not requiring synchronization between the server and client and since some content can be served from crs along the path , we avoid having to do a round - trip to the origin of the content , possibly speeding up the transfer .",
    "in this paper we have compared in - network caching with standard redundancy elimination solutions in terms of their effectiveness at reducing network traffic load . as an example of in - network caching ,",
    "we have presented inca , a caching architecture which aims at capturing the salient features of information - centric networks . we have kept the design of inca minimal and only consider simple solutions for the problems of caching and routing .",
    "our comparison on rocketfuel topologies shows that inca is superior to smartre in the ability to reduce external and internal network traffic , with additional reductions of up to 65% in internal traffic .",
    "similar results hold for comparisons against end - to - end re solutions ."
  ],
  "abstract_text": [
    "<S> network - level redundancy elimination ( re ) techniques have been proposed to reduce the amount of traffic in the internet . and the costs of the wan access in the internet . </S>",
    "<S> re middleboxes are usually placed in the network access gateways and strip off the repeated data from the packets . </S>",
    "<S> more recently , generic network - level caching architectures have been proposed as alternative to reduce the redundant data traffic in the network , presenting benefits and drawbacks compared to re . in this paper </S>",
    "<S> , we compare a generic in - network caching architecture against state - of - the - art redundancy elimination ( re ) solutions on real network topologies , presenting the advantages of each technique . </S>",
    "<S> our results show that in - network caching architectures outperform state - of - the - art re solutions across a wide range of traffic characteristics and parameters . </S>"
  ]
}