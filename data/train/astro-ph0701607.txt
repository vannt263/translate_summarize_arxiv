{
  "article_text": [
    "while the radial velocity method has brought a harvest of @xmath0 200 extrasolar planets since 1995 , the transit method has been presented as the most promising way to detect earth - like planets around solar - type stars @xcite , and as sensitive enough to easily detect hundreds of hot jupiters using small telescopes operating from the ground ( hornes 2003 ) .",
    "its capacity of detecting earth twins from space is the key assumption of the kepler mission @xcite , the most ambitious transit survey planned so far , scheduled for launch in 2008 . with this mission and other ambitious surveys such as corot @xcite",
    ", the future of the method seems very bright .",
    "nevertheless , one should worry that the harvest obtained so far from the ground is ( very ) far from the expected one : only 14 transiting exoplanets are known , from which 3 have been detected first by radial velocity measurements .",
    "this discrepancy between great expectations and an interesting but modest harvest is mainly due to previous over - optimistic estimations of the achieved photometric accuracies ( see pont et al .",
    ", this volume ) .",
    "as outlined by pont , zucker & queloz @xcite , all transit surveys suffer from the presence of residual correlated noises in their light curves .",
    "these red noises are due to the influence of external ( atmosphere , detector ) and topological ( crowding ) parameters on the measured photometry .",
    "they were not taken into account in previous expected harvest computations , as it was assumed that their influence could be easily corrected by differential photometry . recently",
    ", clever post - reduction methods dedicated to a better correction of these red noises have been proposed like sysrem ( tamuz et al . 2005 ) and tfa ( kovcs et al . 2005 ) .",
    "these detrending methods allow indeed to reduce drastically the covariant noises , but not to the level that we can neglect them .",
    "these methods are well suited to remove a large fraction of the red noise due to the external parameters , but are less efficient to remove the topological red noise due to the blends .",
    "this part of the red noise should in fact be removed efficiently by the reduction method , not by a post - reduction algorithm . in this context , we have developed a new reduction method able to perform optimal photometry even in very crowded fields .",
    "we present this method called decphot in sect . 2 and show some efficient applications in sect .",
    "3 . we give our conclusions in sect .",
    "the mcs algorithm ( magain et al . 1998 ) is a deconvolution method specially adapted to astronomical images containing point sources , which allows to achieve ( 1 ) an increase of the angular resolution , ( 2 ) a high accuracy determination of the positions ( astrometry ) and the intensities ( photometry ) of the objects lying on the image .",
    "many algorithms have been proposed to deconvolve images , but generally with rather modest success .",
    "it has been outlined by magain et al .",
    "that the main problem with most of these methods is that they try to recover the light distribution at full resolution , i.e. they attempt to perform a total deconvolution . as the observed light distribution is represented on a pixel grid , with finite pixel size @xmath1 , the sampling theorem ( shannon 1949 ; press et al . 1989 ) implies that components of frequency above the nyquist frequency @xmath2 are mixed up with lower frequency components by aliasing , giving rise to so - called deconvolution artifacts ( e.g.   gibbs oscillations ) and leading to very poor astrometric and photometric accuracies .",
    "the main principle of the mcs algorithm is thus to perform a partial deconvolution in order to recover the light distribution at an improved but finite resolution compatible with the spatial sampling of the resulting image .",
    "thus , the total psf @xmath3 can be represented as the convolution of the psf in the deconvolved image @xmath4 by a partial psf @xmath5 : @xmath6 where @xmath7 stands for the convolution operator .",
    "the algorithm thus performs the deconvolution of the image by the partial psf @xmath5 in order to obtain a final psf @xmath4 chosen in such a way that the final result complies to the shannon theorem ( i.e.   is well sampled ) .",
    "an algorithm performing this task was presented in magain et al .",
    "( 1998 ) , but the determination of the partial psf @xmath5 was not thoroughly addressed .",
    "when an image contains sufficiently isolated point sources , their shape can be used to determine an accurate psf . however",
    ", this simple psf determination is not generally possible in crowded fields , where no star is sufficiently isolated to provide a suitable measurement of @xmath3 .",
    "we have thus developed a method allowing to simultaneously perform a deconvolution and determine an accurate psf in fields containing point sources , even if no isolated star can be found @xcite .",
    "it relies on the minimization of the following merit function : @xmath8_i)^2 + \\lambda h(s)\\ ] ] where @xmath9 is the number of pixels within the image , @xmath10 and @xmath11 are the measured intensity and standard deviation in pixel @xmath12 , @xmath13 is the _ unknown _ value of the psf and @xmath14 is the intensity of the deconvolved image in pixel @xmath12 .",
    "@xmath15 is a smoothing constraint on the psf which is introduced to regularize the solution and @xmath16 is a lagrange parameter . in the absence of a diffuse background ( thus in a field containing only point sources ) , the deconvolved light distribution @xmath17 may be written : @xmath18 where @xmath19 is the number of point sources in the image , while @xmath20 and @xmath21 are free parameters corresponding to the intensity and position of point source number @xmath22 .",
    "note that the right - hand side of the equation represents only point sources , so the sky background is supposed to be removed beforehand .    in eq .",
    "( 2 ) , the smoothing constraint on the psf @xmath15 is given by : @xmath23_i)\\ ] ] where @xmath24 is a gaussian function ; its width , together with the lagrange parameter @xmath16 , are adjusted in order to obtain a correct smoothing of the partial psf @xmath5 , i.e. to prevent fitting too high frequencies .    in order to avoid local minima during the minimization process",
    ", the algorithm proceeds in several steps which are described in magain et al .",
    "the final result is ( 1 ) an accurate psf and ( 2 ) a higher resolution image containing only point sources , for which intensities and positions are provided by the algorithm , which thus allows high accuracy astrometry and photometry .    from this method designed to obtain accurate psf in crowded fields",
    ", we have developed a new method , decphot ( deconvolution photometry ) , with one major goal in mind : to reach the highest photometric accuracy possible , even in very tricky cases .",
    "the first improvement brought to develop decphot concerned the computational time .",
    "indeed , the classical mcs algorithm is very time consuming , and this problem is partially solved in decphot by a linearisation made possible by the fact that we want to treat hundreds if not thousands of images of the same field @xcite .",
    "we treat a reference high resolution high sn image with the standard iterative algorithm , determine the astrometric transformation connecting this reference image to the others , than fix the astrometry and do several cycles composed of matrix inversion ( to get the photometry and the sky background ) and iterative determination of the psf ( necessary as it is not an analytical function ) .",
    "another improvement is the implementation of the sky background determination into the problem , instead of determining or subtracting it in a previous step . indeed , fitting a rather smooth surface through seemingly ",
    "empty \" areas may lead to seeing - dependent systematic errors .",
    "a much more robust method consists in determining the sky background level so that the shape of all point sources remains the same , irrespective of their intensities .",
    "a wrong sky level would affect weaker sources much more strongly than brighter ones .",
    "forcing all point sources to have the same psf shape thus allows an accurate determination of the sky intensity .    to fit",
    "the sky background with the other unknowns , the observed light distribution @xmath25 is now written as : @xmath26 where the sky background is represented by the function @xmath27 , chosen to be relatively smooth . in practice , a second order polynomial ( 6 free parameters ) has been found suitable for images obtained in the optical .    for the deconvolution of the reference image , we have now to minimize the following merit function : @xmath28_i)^2 + \\lambda h(s)\\ ] ] where @xmath29 is the sky level in pixel @xmath12 , computed through a second - order polynomial whose coefficients are determined as follows :",
    "in the context of the precise determination of the parameters of the ogle planets , we observed with the vlt and the ntt telescopes transits of the planets ogle - tr-10 and ogle - tr-56 @xcite , ogle - tr-113 ( gillon et al .",
    "2006 ) and ogle - tr-132 ( gillon et al .",
    "each photometric reduction was done with decphot .",
    "the resulting light curves obtained for ogle - tr-113@xmath30 are shown in fig . 1 .    ) and the second ( @xmath31 ) observed transits of ogle - tr-113b , with the best - fit transit curve superimposed . for the second transit ,",
    "the variations of the flux before the transit are due to a bad column of the ccd located close to the psf cores of ogle - tr-113 and a bright reference star ( open symbols ) .",
    "[ ogle113],width=302 ]    for the first night , the @xmath32 of the light curve of ogle - tr-113 before the transit is 1.20 mmag , while the mean photon noise is 0.95 mmag . for the second night , the @xmath32 of the light curve after the transit is 1.26 mmag , for the same mean photon noise ( 0.95 mmag ) .",
    "the slight difference between the photon noise and the observed @xmath32 can be explained by the fact that ogle - tr-113 has a 0.4 mag brighter visual companion about 3@xmath33 to the south ( see fig .",
    "2 ) . when a star s psf is blended with another one , a part of the noise of the contaminating star is added to its own noise , resulting in a decrease of the maximal photometric accuracy attainable .",
    "this effect is of course very dependent on the seeing , and may have a large impact on the final harvest of a transit survey ( gillon et al .",
    "the higher seeing during the second transit explains the higher dispersion compared to the first transit .",
    "256 pixels sub - image ( 0.7 @xmath34 @xmath35 0.7 @xmath34 ) from the worst ( _ left _ ) and best ( _ middle _ ) seeing ntt / susi2 image of our run ( @xmath36 = north , @xmath37 = east ) . the nearby star just south of ogle - tr-113 is about 0.4 mag brighter .",
    "_ right _ : deconvolved image .",
    "[ ogle113_2],width=377 ]",
    "our new photometric reduction method based on the deconvolution of the analyzed images has a high potential for performing optimal photometry in all cases , even in highly crowded fields , as shown by the results obtained in the case of the ogle planets follow - up .",
    "such an optimal method could increase the potential of the transit surveys , as it appears now clearly that their present potential is still low compared to past expectations , despite the use of sophisticate detrending algorithms .",
    "indeed , the use of decphot should ( 1 ) improve the accuracy of the flux measurement , and ( 2 ) decrease the topological red noise , a major part of the red noise remaining in the light curves after post - reduction . furthermore ,",
    "as decphot allows the user to model the partial psf with a better sampling than the one of the data , it should give optimal results even in the case of under - sampled data , a frequent case in shallow transit surveys .",
    "the existing version of decphot has a major drawback compared to the other existing reduction method : it is much slower . extrapolating the processing times obtained in the case of ogle planets",
    "follow - up to transit surveys data , i.e. to thousands of images with a much larger number of pixels ( @xmath38 to @xmath39 ) and sources leads to overwhelming processing times .",
    "the problem does not come only from the slowness of the deconvolution of all the images , but also from the preliminary treatment of a reference image to obtain a global solution .",
    "this step requires the detection of blended objects undetected in the original image , and this is manually done by the user and should be automatized .",
    "we are now working on an improved version of the method which will iterate much faster to the solution and which will incorporate an algorithm able to automatically detect objects hidden in the psfs in the original image ."
  ],
  "abstract_text": [
    "<S> a high accuracy photometric reduction method is needed to take full advantage of the potential of the transit method for the detection and characterization of exoplanets , especially in deep crowded fields . in this context , we present decphot , a new deconvolution - based photometry algorithm able to deal with a very high level of crowding and large variations of seeing . </S>",
    "<S> it also increases the resolution of astronomical images , an important advantage for the discrimination of false positives in transit photometry . </S>"
  ]
}