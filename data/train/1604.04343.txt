{
  "article_text": [
    "markov decision processes ( mdps ) are widely adopted to model the dynamic decision problem in stochastic systems @xcite .",
    "the fundamental matrix @xmath13 plays a key role in the performance optimization of mdps . with the fundamental matrix",
    ", we can further study the properties of markov systems .",
    "for example , we can use it to compute the performance potential ( or called relative value function ) of mdps under the average criterion , i.e. , @xmath14 .",
    "the concept of the fundamental matrix was first proposed by j. g. kemeny in his book  _ finite markov chains _ \" coauthored with l. j. snell in 1960 @xcite . in this book , the fundamental matrix is defined as @xmath15 . many analysis , such as the mean passage time and the variance of passage time , can be conducted by using this fundamental matrix .",
    "the fundamental matrix also plays a key role in the performance sensitivity analysis of markov systems .",
    "the original work about the sensitivity analysis of the steady state distribution and the fundamental matrix with respect to the stochastic matrix of markov systems can be referred backward to p. schweitzer s work in 1968 @xcite .",
    "p. schweitzer presented a perturbation formalism that shows how the stationary distribution and the fundamental matrix of a markov chain containing a single irreducible set of states change as the transition probabilities vary .",
    "the sensitivity information can be represented in a series of rayleigh perturbation expansions of the fundamental matrix and other parameters .",
    "this is the main target of the perturbation analysis of markov chains at the early stage .",
    "e. seneta and c. d. meyer did a lot of work @xcite to study the relation between the eigenvalues of stochastic matrix @xmath1 and the condition number ( @xmath16 ) of group generalized inverse ( @xmath17 ) of matrix @xmath18 , where @xmath19 is the element of matrix @xmath20 .",
    "some inequalities are derived to quantify the sensitivity of the steady state distribution when @xmath1 is perturbed to @xmath21 .",
    "therefore , the sensitivity of the steady state distribution can be analyzed through studying the eigenvalues of stochastic matrix @xmath1 .",
    "this is the main idea of the perturbation analysis of markov chains at that period .",
    "more than the sensitivity analysis of the steady state distribution , x. r. cao proposed the sensitivity - based optimization theory that focuses on the sensitivity analysis of the system performance with respect to the perturbed transition probabilities or policies @xcite .",
    "this approach works well for different system settings , including the average or discounted criterion , the unichain or multichain , markov or semi - markov systems .",
    "performance potential @xmath5 is a fundamental quantity in mdps .",
    "we have to compute or estimate its value before we conduct the policy iteration or sensitivity - based optimization . for an mdp under the discounted criterion ,",
    "we can directly compute it as @xmath22 since the matrix @xmath23 is invertible @xcite , where @xmath24 is the discount factor and @xmath25 .",
    "for an mdp under the average criterion , the fundamental matrix is used to compute the value of performance potentials and it has the form @xmath26 .",
    "since the fundamental matrix can be decomposed as @xmath27 , we can rewrite the definition of the performance potential as @xmath28 , where @xmath29 is the long - run average performance .",
    "that is , we can derive the following sample path version of the performance potential as @xmath30 , where @xmath31 is the system state at time @xmath32 , @xmath33 is the estimated value of the long - run average performance , @xmath34 is a state of the state space @xmath35 , and @xmath36 is a proper integer that is to control the estimation variance @xcite .",
    "however , we see that when we compute @xmath37 , we have to pre - compute the value of @xmath3 first .",
    "this issue was also pointed out by j. g. kemeny when he studied the computation of the fundamental matrix @xmath38 .",
    "it also suffers from the difficulty that one must compute @xmath39 ( solving @xmath32 equations ) before one can compute @xmath40 \" @xcite , where @xmath39 is the steady state distribution @xmath3 in our paper .    in this paper , we study another form of the fundamental matrix as @xmath41 , where @xmath9 is any row vector satisfying @xmath10 . using this generalized fundamental matrix",
    ", we can compute the value of performance potentials as @xmath42 , where all the parameters are known and no pre - computation is required . the traditional approach",
    "@xmath43 is a special case where we choose @xmath44 .",
    "we can also choose @xmath9 as other vectors .",
    "this formula can also be used to compute the value of @xmath45 as @xmath46 , where the kernel computation remains the same as the generalized fundamental matrix @xmath47 .",
    "there exist two works about the generalization of the fundamental matrix in the literature . after proposing the concept of the fundamental matrix , j. g. kemeny",
    "further studied a generalized form @xcite .",
    "a special case for ergodic markov chains is that he defined @xmath48 , @xmath49 , where @xmath50 is a row vector . in kemeny",
    "s work , it is shown that the above matrix can be used to compute the stationary distribution as @xmath51 .",
    "similar result was later reported in j. j. hunter s book @xcite , which has the form @xmath52 , @xmath53 , where @xmath54 is a row vector .",
    "after that , j. j. hunter further gave a thorough study on varied forms of general inverse of markovian kernel @xmath55 in his recent works @xcite .",
    "one form of the general inverse is written as @xmath56 with condition @xmath57 and @xmath53 , where @xmath58 is a column vector .",
    "obviously , @xmath59 is more general than the above results .",
    "although these works have a similar result to ours , they focus on the computation of the steady state distribution or the mean first passage time .",
    "there is no study on the computation of performance potentials or relative value functions . compared with the widely - adopted form @xmath60 , our new formula @xmath61 does not require the pre - computation of @xmath3 .",
    "it may shed some light on how to efficiently compute or estimate the value of @xmath5 , which is an essential procedure for the policy iteration in mdps .",
    "moreover , we also study the generalization of the fundamental matrix not only for a discrete time markov chain , but also for a continuous time markov process .",
    "we further extend the similar idea to the representation and computation of q - factors that are fundamental quantities for reinforcement learning and artificial intelligence @xcite .",
    "we focus on the discussion of a markov chain with finite states .",
    "the state space is denoted as @xmath62 .",
    "the transition probability matrix is denoted as @xmath1 and its element is @xmath63 indicating the probability of which the system transits from the current state @xmath64 to the next state @xmath65 , where @xmath66 .",
    "the steady state distribution of this markov chain is denoted as an @xmath67-dimensional row vector @xmath3 and its element @xmath68 is the probability of the system staying at state @xmath64 , @xmath69 . obviously , we have @xmath70 where @xmath2 is an @xmath67-dimensional column vector with all elements 1 .    first , we give the following lemma about shifting the eigenvalues of a general matrix .",
    "[ lemma1 ] suppose that @xmath71 is a square matrix for which @xmath72 is an eigenvalue having multiplicity 1 , and the associated column eigenvector is @xmath73 .",
    "let @xmath74 be the other eigenvalues of @xmath71 and @xmath75 be the associated row eigenvectors .",
    "then , for any row vector @xmath9 , @xmath76 is an eigenvalue of @xmath77 and the associated column eigenvector is @xmath73 ; other eigenvalues of @xmath77 are given by @xmath74 with the associated row eigenvectors @xmath75 .",
    "since @xmath75 is a _ row eigenvector _ of @xmath71 associated with eigenvalue @xmath74 , we have @xmath78 on the other hand , since @xmath73 is a _ column eigenvector _ of @xmath71 , we have @xmath79 since @xmath72 has multiplicity 1 , @xmath74 is not equal to @xmath72 . comparing the above two equations , we directly have @xmath80 below , we further study the eigenvalue of matrix @xmath81 . using ( [ eq_phiv ] )",
    ", we have @xmath82 therefore , @xmath83 continues to be an eigenvalue of @xmath84 and @xmath75 continues to be the associated row eigenvector of @xmath85 .",
    "moreover , we have @xmath86 therefore , @xmath87 is a new eigenvalue of @xmath88 and @xmath73 continues to be the associated column eigenvector of @xmath89 . the lemma is proved .    for the eigenvalues of the transition probability matrix of a markov chain , we have the following lemma .    [ lemma2 ]",
    "if @xmath1 is the stochastic matrix of an irreducible and aperiodic markov chain , its spectral radius @xmath90 and @xmath91 for @xmath92 , where @xmath93 is the eigenvalues of @xmath1 descendingly sorted by their modulus .",
    "moreover , @xmath94 is a simple eigenvalue and the associated column eigenvector is @xmath95 .",
    "this lemma can be obtained directly from the _ perron - frobeniu theorem _ that was separately proposed by oskar perron in 1907 @xcite and georg frobenius in 1908 @xcite .",
    "the original perron - frobeniu theorem aims to study the eigenvalues and eigenvectors of nonnegative matrix .",
    "since the stochastic matrix is a special case of nonnegative matrix , we can obtain more specific properties of stochastic matrix , such as the statement in the above lemma .",
    "the proof of this lemma is ignored and interested readers can find it from reference books @xcite .    with the above lemmas , we derive the following theorem about the eigenvalues of matrix @xmath96 .",
    "[ theorem1 ] assume that @xmath1 is the stochastic matrix of an irreducible and aperiodic markov chain .",
    "denote @xmath74 as the eigenvalues of @xmath1 in descending order of their modulus , @xmath75 and @xmath97 are the associated row and column eigenvectors , respectively .",
    "then , for any row vector @xmath9 , the matrix @xmath98 has the following property : one eigenvalue is @xmath99 and the associated column eigenvector is @xmath2 ; other eigenvalues are @xmath100 for @xmath92 , the associated row eigenvectors are @xmath75 , and the associated column eigenvectors are @xmath101 if @xmath102 .    with lemma  [ lemma2 ] , we see that @xmath103 and @xmath91 for @xmath92 .",
    "we denote @xmath104 .",
    "it is easy to verify that the eigenvalues of @xmath71 are @xmath100 and the associated row eigenvectors are the same as @xmath75 .",
    "that is , @xmath105 is an eigenvalue of @xmath71 with simplicity 1 and the associated column eigenvector is @xmath2 .",
    "therefore , by applying lemma  [ lemma1 ] , we see that @xmath99 is an eigenvalue of matrix @xmath96 and the associated column vector is @xmath2 ; other eigenvalues are @xmath100 with the associated row eigenvector @xmath75 for @xmath92 .",
    "the column eigenvectors of @xmath96 can be verified as follows .",
    "@xmath106 therefore , the theorem is proved .",
    "the eigenvalue of a matrix may be a complex number .",
    "with lemma  [ lemma2 ] , we can see that the eigenvalues of @xmath1 have @xmath107 for @xmath92 and they are located in the unit circle in the complex plane , as illustrated by the left sub - figure of fig  [ fig_circlep ] . with theorem  [ theorem1 ]",
    ", we can see that the eigenvalues of @xmath96 are @xmath100 for @xmath92 and they are also located in the unit circle illustrated by the right sub - figure of fig .",
    "[ fig_circlep ] .     and @xmath96 , i.e. , @xmath74 and @xmath100 for @xmath92 . ]",
    "therefore , we can directly derive the following theorem .",
    "[ theorem2 ] the matrix @xmath108 is not singular if and only if @xmath10 , where @xmath1 is the stochastic matrix of an irreducible and aperiodic markov chain .",
    "the proof of this theorem is very straightforward .",
    "based on theorem  [ theorem1 ] and lemma  [ lemma2 ] , we see that the eigenvalues of @xmath96 are either @xmath109 or @xmath100 for @xmath92 .",
    "since @xmath10 and @xmath107 for @xmath92 , we can easily verify that @xmath105 is not the eigenvalue of @xmath96 .",
    "therefore , the matrix is invertible and the theorem is proved .    with theorem  [ theorem2 ] , we see that @xmath110 is invertible if @xmath10 .",
    "therefore , we define a _ generalized fundamental matrix _ as below . @xmath111",
    "compared with the fundamental matrix @xmath112 defined in the literature @xcite , @xmath113 can be viewed as a special case of @xmath114 with @xmath115 .",
    "the generalized fundamental matrix @xmath114 is an important quantity of markov chains and it can be utilized to compute the performance potential and the steady state distribution , as we will discuss in the following subsections .",
    "as we know , the value function ( or performance potential ) is an very important quantity of markov decision processes . in a standard policy iteration procedure",
    ", we have to compute the value function for the current policy , which is called the _ policy evaluation _",
    "step @xcite . in the approximate dynamic programming",
    ", we study various approximation approaches to simplify the computation of the value function to alleviate the curse of dimensionality @xcite .",
    "therefore , the efficient computation of the value function is an very important topic in the field of mdps .",
    "note that the computation of value functions under the discount criterion is easy , because the associated poisson equation has a unique solution .",
    "we focus on the value function under the long - run average criterion of mdps .",
    "the _ performance potential _ is an alias of the value function and it has a special physical meaning from the perspective of the perturbation analysis and the sensitivity - based optimization @xcite . in the following content",
    ", we will use the term of performance potential to study how to compute or estimate it .",
    "we denote the performance potential as an @xmath67-dimensional column vector @xmath5 and its element @xmath116 , @xmath34 , is defined as below .",
    "@xmath117 | x_0 = i \\right\\},\\ ] ] where @xmath118 is the system state at time @xmath119 , @xmath120 is the system reward at state @xmath118 , and @xmath121 is the long - run average performance defined as below . @xmath122 where the second equality holds when the markov chain is a unichain .",
    "extending the right - hand side of ( [ eq_g ] ) at time @xmath123 and recursively substituting ( [ eq_g ] ) , we can obtain @xmath124 rewriting the above equation in a matrix form , we obtain the _ poisson equation _ as below .",
    "@xmath125 the above equation can be rewritten as below .",
    "@xmath126 however , as we know from lemma  [ lemma2 ] , the matrix @xmath127 has an eigenvalue with value 0 and it is not invertible . noticing the fact that @xmath128 is still a solution to ( [ eq_poisson ] ) for any constant @xmath129 , we can properly choose @xmath129 to let @xmath130 .",
    "therefore , we have @xmath131 with theorem  [ theorem2 ] , we see that matrix @xmath132 is invertible . the inverse matrix is called the fundamental matrix defined in the literature @xcite and it has @xmath133 therefore , the solution to the poisson equation ( [ eq_poisson ] ) can be written as below .",
    "@xmath134    the above formula widely exists in the literature @xcite and we can use it to numerically compute the value of @xmath5 for a specific mdp . note that the value of @xmath5 computed with ( [ eq_g3 ] ) satisfies the condition @xmath130 .",
    "however , @xmath3 is not a given parameter in the above equation .",
    "we have to compute the value of @xmath3 before we can use ( [ eq_g3 ] ) to compute @xmath5 .",
    "this increases the computation burden .",
    "moreover , if we conduct online estimation , the estimation error of @xmath3 may increase the estimation variance of @xmath5 .",
    "fortunately , we have another way to numerically compute @xmath5 without the extra computation for @xmath3 . since @xmath128 is still a solution to ( [ eq_poisson ] ) for any constant @xmath129 , for any @xmath67-dimensional row vector @xmath9 satisfying @xmath135",
    ", we can choose a proper @xmath129 to let @xmath136 .",
    "therefore , we can rewrite ( [ eq_poisson ] ) as below .",
    "@xmath137 since matrix @xmath138 is always invertible as proved in theorem  [ theorem2 ] , the above equation can be further rewritten as    1 @xmath139    where @xmath9 is any @xmath67-dimensional row vector @xmath9 satisfying @xmath10 .",
    "we can see that all the parameters in ( [ eq_g4 ] ) are given and we can directly compute @xmath5 with ( [ eq_g4 ] ) without any pre - computation .",
    "* remark 1 .",
    "* both ( [ eq_g3 ] ) and ( [ eq_g4 ] ) are solutions to the poisson equation ( [ eq_poisson ] ) and they have difference only with a constant column vector @xmath140 .",
    "the value of @xmath5 in ( [ eq_g3 ] ) satisfies @xmath130 , while the value of @xmath5 in ( [ eq_g4 ] ) satisfies @xmath141 .",
    "* remark 2 . *",
    "( [ eq_g3 ] ) can be viewed as a special case of ( [ eq_g4 ] ) if we choose @xmath44 . with ( [ eq_g4 ] )",
    ", we have more flexibility to choose different @xmath142 s , which may give some insights on the computation or estimation of @xmath5 .",
    "the fundamental matrix can also be used to compute the steady state distribution of markov chains .",
    "we also assume that the markov chain is irreducible and aperiodic . we know that @xmath3 can be determined by the following set of linear equations @xmath143 we can rewrite the above equations according to the standard form of linear equations as below . @xmath144",
    "that is , @xmath145 \\left ( \\begin{array}{c } \\pi_1 \\\\ \\pi_2 \\\\ \\pi_3 \\\\ \\vdots \\\\ \\pi_s \\\\ \\end{array } \\right ) = \\left ( \\begin{array}{c } 0 \\\\ 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ \\end{array } \\right).\\ ] ] @xmath146 for any @xmath67-dimensional row vector @xmath9 satisfying @xmath147 , we multiply @xmath148 on both sides of ( [ eq5 ] ) and summate this equation to the @xmath64th equation of ( [ eq4 ] ) , @xmath149 .",
    "we can obtain @xmath150    with theorem  [ theorem2 ] , we know that @xmath151 is invertible and @xmath152 . therefore , we have @xmath153 or    1 @xmath154    from the above equation , we can see that the computation of @xmath45 has the same key part as the computation of @xmath5 with ( [ eq_g4 ] ) , i.e. , the computation of the generalized fundamental matrix @xmath155 .",
    "therefore , @xmath114 plays a key role in the analysis of markov chains .      in this subsection",
    ", we discuss the properties of the generalized fundamental matrix @xmath114 and the effect on the computation of performance potentials .",
    "if the spectral radius of @xmath156 is smaller than 1 , we can rewrite the generalized fundamental matrix as follows .",
    "@xmath157 according to lemma  [ lemma1 ] , we see that the eigenvalues of @xmath158 are @xmath159 and @xmath74 for @xmath92 , where @xmath74 are the eigenvalues of @xmath1 sorted in the descending order of their modulus . with lemma  [ lemma2 ] , we see that @xmath103 and @xmath107 for @xmath92 .",
    "therefore , we have @xmath160 furthermore , we can verify that ( [ eq_zr2 ] ) can be rewritten as below .",
    "@xmath161 , \\qquad 0<\\bm r \\bm e < 2.\\ ] ] if we choose @xmath9",
    "such that @xmath162 , then we can further simplify the above equation as below .",
    "@xmath163 , \\qquad \\bm r \\bm e = 1,\\ ] ] where we define @xmath164 when @xmath165 . if we choose @xmath9 stochastic , then the @xmath166th entry of @xmath167 has the interpretation that it is a sum over @xmath32 in which the @xmath32th term ( for @xmath168 ) is @xmath169 having initial distribution @xmath142 ) .",
    "if we manipulate the terms in the summation of ( [ eq_zr3 ] ) , we can obtain @xmath170 + \\lim\\limits_{n \\rightarrow \\infty}\\bm e \\bm r \\bm p^n , \\qquad \\bm r \\bm e = 1.\\ ] ] since the markov chain is irreducible , aperiodic , and finite , the limiting probability exists and it equals the steady state distribution . that is ,",
    "@xmath171 therefore , the above equation ( [ eq_zr4 ] ) can be rewritten as below .",
    "@xmath172 + \\bm e \\bm \\pi , \\qquad \\bm r \\bm e = 1.\\ ] ] therefore , neglecting the steady distribution @xmath173 for simplicity , we can see that the @xmath32th term of the above summation is @xmath174 having initial distribution @xmath9 ) .",
    "this interpretation can help develop online estimation algorithms for quantities related to @xmath114 from a viewpoint of sample paths .",
    "substituting ( [ eq_zr5 ] ) into ( [ eq_g4 ] ) , we have @xmath175 \\bm f + \\bm e \\bm",
    "\\pi \\bm f \\nonumber\\\\ & = & \\sum_{n=0}^{\\infty } \\bm p^n \\bm f - \\bm e \\bm r \\sum_{n=0}^{\\infty } \\bm p^{n } \\bm f + \\eta \\bm e,\\end{aligned}\\ ] ] where @xmath162 and @xmath136 . since @xmath176 is still a performance potential for any constant @xmath129 , we can neglect the term @xmath177 in the above equation and rewrite it as below .",
    "@xmath178 where @xmath162 and @xmath179 .    from the above equation",
    ", we can see that @xmath180 equals the expectation of the accumulated rewards along the sample path , i.e. , @xmath181 .",
    "we denote @xmath182 or @xmath183 for a large constant @xmath184 . we can rewrite ( [ eq_42 ] ) as below .",
    "@xmath185 when @xmath9 is a probability distribution , the physical meaning of the above equation is that : we sum all the rewards along the sample path , then we use a weighting vector @xmath9 to obtain a _ reference level _ @xmath186 , the gap between @xmath187 and the reference level @xmath186 is exactly the performance potential ( this is also the reason that we call it _ relative _ value function ) .",
    "the insight for the estimation algorithm is that we can just sum all the rewards along the sample path , then we choose an arbitrary reference level determined by a combination of elements of @xmath187 , the gap between them is the estimate of performance potentials .",
    "this can help to simplify the online estimation procedure .",
    "@xmath44 is one of the special cases .",
    "for example , we can also set @xmath188 , which lets @xmath189 as the reference level .    instead of numerically computing @xmath5 with ( [ eq_g4 ] )",
    ", we can further develop an iterative algorithm to estimate the value of @xmath190 based on ( [ eq_g4 ] ) . with ( [ eq_g4 ] )",
    ", we have @xmath191 suppose @xmath192 is an unbiased estimate of @xmath5 , i.e. , @xmath193 .",
    "we have @xmath194 rewriting the above equation as a _ sample path version _ , we derive the following equation that holds from the sense of statistics @xmath195 & = & e[f(x_t ) - \\bm r \\hat{\\bm g } + \\hat{g}(x_{t+1 } ) ] \\nonumber\\\\ & = & e[f(x_t ) ] - \\sum_{i \\in \\mathcal s}r(i)e[\\hat{g}(i ) ] + e[\\hat{g}(x_{t+1})].\\end{aligned}\\ ] ]    based on the above equation , we develop a _ least - squares _ algorithm that can online estimate @xmath5 based on sample paths .",
    "define a quantity @xmath196 as below , which can be viewed as the new information learned from the current feedback of the system .",
    "@xmath197 with a stochastic approximation framework , we have the following formula to update the value of @xmath198 @xmath199 where @xmath200 is a positive step - size that satisfies the convergence condition of robbins - monro stochastic approximation , i.e. , @xmath201 or @xmath200 satisfies an even looser condition as below @xcite .",
    "@xmath202    the name of least - squares of update formula ( [ eq_lsg ] ) comes from the fact that we aim to obtain the following estimate of @xmath190 that can obtain the least squares of @xmath203 in statistics , i.e. , @xmath204    the idea of least - squares update formula ( [ eq_lsg ] ) is similar to that of temporal - difference ( td ) algorithm in reinforcement learning @xcite .",
    "below , we give a procedure framework of the online estimation algorithm as illustrated in fig .",
    "[ fig_algo ] . in fig .",
    "[ fig_algo ] , the algorithm stopping criterion can be set as the norm of two successive estimates is smaller than a given small threshold @xmath205 , i.e. , @xmath206 , or just simply stop the algorithm after reaching a large step number @xmath184 , i.e. , @xmath207",
    ".    1    * initialize @xmath208 arbitrarily , e.g. , set @xmath209 for all @xmath210 .",
    "* repeat ( for each time step @xmath119 ) : + observe the current state @xmath211 , the current reward @xmath212 , and the next state @xmath213 + calculate @xmath214 + update @xmath215 + @xmath216 ; @xmath217 * until a stopping criterion is satisfied .",
    "in the previous section , we discuss the generalized fundamental matrix for the discrete time markov chain . in this section , we extend the result to other cases , including the continuous time markov process and the q - factors in reinforcement learning .",
    "consider a continuous time markov process with transition rate matrix @xmath218 .",
    "assume the markov process is ergodic , we can similarly prove    [ theorem5 ] the eigenvalue of matrix @xmath218 has the following property : @xmath219 is a simple eigenvalue and the associated column eigenvector is @xmath220 ; @xmath221 for @xmath92 , where @xmath24 is any constant satisfying @xmath222 .    by using the uniformization technique in mdps",
    ", we can define a matrix @xmath1 as below .",
    "@xmath223 obviously , @xmath1 is a stochastic matrix since it satisfies @xmath224 and all of its elements are nonnegative . the statistical behavior of the markov chain with transition probability matrix @xmath1 is equivalent to that of the markov process with transition rate matrix @xmath218 @xcite .",
    "we have @xmath225 since the markov process with @xmath218 is ergodic , the equivalent markov chain with @xmath1 is also ergodic .",
    "therefore , @xmath1 is an ergodic stochastic matrix .",
    "with lemma  [ lemma2 ] , we know that the eigenvalue of @xmath1 has @xmath226 therefore , with ( [ eq28 ] ) , we see that the eigenvalue of @xmath218 is @xmath227 and the column eigenvector is @xmath228 , @xmath229 .",
    "we have @xmath230 the theorem is proved .    with the above theorem , we know that the eigenvalue of @xmath218 is either @xmath105 or distributed inside of the dotted circle in fig .  [ fig_circleb ] .",
    "when @xmath24 is smaller , we can obtain a tighter area describing the distribution area of @xmath231 .",
    "obviously , the smallest value of @xmath24 is @xmath232    , i.e. , @xmath231 for @xmath92 . ]",
    "furthermore , we study the eigenvalue of matrix @xmath233 and we can similarly obtain the following theorem .",
    "[ theorem6 ] the eigenvalue of matrix @xmath234 has the following property : @xmath235 is a simple eigenvalue and the associated column eigenvector is @xmath236 ; @xmath237 and the associated column eigenvector is @xmath238 for @xmath92 and @xmath239 .",
    "the proof of this theorem is similar to that of theorem  [ theorem1 ] .",
    "we only need to verify whether the eigenvalue and eigenvector satisfy the equation @xmath240 .",
    "such verification is easy and we ignore the details for simplicity .",
    "[ theorem7 ] for any row vector @xmath9 satisfying @xmath10 , the matrix @xmath234 is invertible , where @xmath218 is the transition rate matrix of an ergodic markov process .",
    "based on theorem  [ theorem5 ] and theorem  [ theorem6 ] , we can easily verify that the eigenvalues of @xmath241 satisfy : @xmath242 therefore , @xmath105 is not the eigenvalue of the matrix @xmath241 and @xmath243 is invertible .    with theorem  [ theorem7 ] , we can also simplify the computation of the steady state distribution and the performance potential ( value function ) of markov processes .",
    "first , we discuss how to compute the steady state distribution @xmath45 in markov processes .",
    "it is known that @xmath3 can be determined by the following equations @xmath244 multiplying @xmath148 on both sides of the second equation and adding it to the @xmath64th row of the first equation , we can obtain the following equation after proper manipulations @xmath245 with theorem  [ theorem7 ] , for any @xmath67-dimensional row vector @xmath142 satisfying @xmath10 , @xmath246 is invertible and we have    1 @xmath247    second , we discuss how to compute the performance potential of markov processes . in a continuous time markov process , the performance potential @xmath5 is defined as below .",
    "x_0=i \\right\\}.\\ ] ] we also have the poisson equation for the above definition @xmath249 in the literature , it is widely adopted that @xmath5 can be numerically computed by the following equation @xcite @xmath250 the above equation includes the condition @xmath130 .",
    "similar to the case of discrete time markov chain , we can also derive @xmath251 where the condition @xmath136 is required . with theorem  [ theorem7 ] , for any @xmath67-dimensional row vector @xmath9 satisfying @xmath10",
    ", @xmath246 is invertible and we have    1 @xmath252    therefore , we can directly compute the value of @xmath5 using the above equation , without the pre - computation of @xmath3 required by ( [ eq37 ] ) .    on the other hand",
    ", we can also develop an online least - squares algorithm to estimate @xmath5 based on sample paths , which is similar to the algorithm described in fig .",
    "[ fig_algo ] for the case of discrete time markov chains . for simplicity , we ignore the details .",
    "it is well known that we have poisson equation for the performance potential or the value function in mdps .",
    "similar to the performance potential quantifying the effect of the initial state on the average performance , the q - factor is an important quantity in reinforcement learning and it quantifies the effect of the state - action pair on the system average performance .",
    "below , we give a poisson equation for q - factors in an mdp under the time average criterion .",
    "suppose the current policy is @xmath253 .",
    "in this subsection , all the quantities of mdps are assumed for the policy @xmath253 by default , unless we have specific other notations .",
    "the q - factor of the markov system under this policy @xmath253 is defined as below .",
    "@xmath254 where @xmath255 is the probability of which the system transits from the current state @xmath211 to the next state @xmath213 if the action @xmath256 is adopted .    for a randomized policy",
    ", @xmath253 is a mapping @xmath257 , where @xmath258 is the set of probability measurements over the action space @xmath259 .",
    "that is , @xmath260 is the probability of which action @xmath256 is adopted at state @xmath211 , @xmath210 and @xmath261 . for the deterministic case , @xmath253 is a mapping @xmath262 , i.e. , @xmath263 indicates the action adopted at state @xmath211",
    ". we can rewrite ( [ eq_q1 ] ) in a recursive form as below . @xmath264",
    "the above equation is a fixed - point equation for q - factors , which is similar to the poisson equation for the performance potential or the value function in the classical mdp theory .    by sorting the element @xmath265 in a vector form",
    ", we define an @xmath266-dimensional column vector @xmath267 as below .",
    "@xmath268 , \\ \\forall s \\in",
    "\\mathcal s. \\qquad \\bm q^{\\mathcal l } : = \\left [ \\begin{array}{c } \\bm q^{\\mathcal l}(1)\\\\ \\bm q^{\\mathcal l}(2)\\\\ \\vdots\\\\",
    "\\bm q^{\\mathcal l}(s ) \\end{array } \\right].\\ ] ]    with the same order to sort the element @xmath269 , we can rewrite ( [ eq_qpoisson ] ) in a matrix form as below .",
    "@xmath270 where @xmath267 and @xmath9 are column vectors with size @xmath266 , @xmath2 is a column vector of ones with a proper size ( here the size is @xmath266 ) , @xmath1 is a stochastic matrix with size @xmath271 @xmath272_{sa \\times s } , \\quad \\bm p((s , a),s')=p(s , a , s ' ) , \\",
    "\\forall s , s ' \\in \\mathcal s , \\ a \\in \\mathcal a,\\ ] ] @xmath273 is a stochastic matrix with size @xmath274 @xmath275_{s \\times sa } , \\quad \\bm l(s',(s',a'))=\\mathcal l(s',a ' ) , \\",
    "\\forall s ' \\in \\mathcal s , \\ a ' \\in \\mathcal a,\\ ] ] where @xmath276 if @xmath277 .",
    "therefore , most of the elements of @xmath273 is 0 and @xmath273 is a sparse matrix like below @xmath278_{s \\times sa}.\\ ] ] if we write @xmath279 as an @xmath280 matrix as below .",
    "@xmath281_{s \\times a}.\\ ] ] then matrix @xmath273 equals the block diagonal of _ kronecker product _",
    "( matrix form of tensor - product ) of vector @xmath282 and matrix @xmath279 , where @xmath282 is an @xmath67-dimensional row vector of ones .",
    "that is , we have @xmath283_{s \\times sa}.\\ ] ] it is easy to verify that @xmath284 therefore , @xmath285 and @xmath286 is still a stochastic matrix that can be denoted as matrix @xmath287 with size @xmath288 .",
    "that is , @xmath289 therefore , we obtain a linear form of ( [ eq_qpoisson2 ] ) as below .",
    "1 @xmath290    we can see that for any solution of @xmath267 satisfying ( [ eq_qpoisson3 ] ) , @xmath291 is still a solution to ( [ eq_qpoisson3 ] ) , where @xmath129 is any constant .",
    "therefore , we can let @xmath267 satisfy @xmath292 where @xmath9 is any @xmath266-dimensional row vector satisfying @xmath293 . substituting the above equation into ( [ eq_qpoisson3 ] ) ,",
    "we obtain @xmath294    since @xmath295 is a stochastic matrix , with theorem  [ theorem2 ] , we know that @xmath296 is invertible . therefore , we have the following solution of q - factors    1 @xmath297    therefore , we obtain the poisson equation ( [ eq_qpoisson3 ] ) for q - factors , which is a fixed point equation to solve q - factors .",
    "the closed - form solution of q - factors is also obtained in ( [ eq_qpoisson5 ] ) .",
    "based on these equations , we may also develop numerical computation algorithms or online estimation algorithms for q - factors , similar to the discussion and algorithms in subsection  [ subsection_alg ] .",
    "recently , the deep reinforcement learning , such as the alphago of google , is becoming a promising direction of artificial intelligence @xcite and the q - factors are fundamental quantities in reinforcement learning @xcite , how to efficiently compute , estimate or even represent the q - factors is an interesting topic that deserves further research efforts .",
    "in this paper , we study a generalized fundamental matrix in markov systems .",
    "different from the fundamental matrix in the classical mdp theory , the generalized fundamental matrix does not require the pre - computation of @xmath3 and it can provide a more concise form for the computation of some fundamental quantities in markov systems . based on the generalized fundamental matrix ,",
    "we give a closed - form solution to the poisson equation and represent the values of performance potentials , steady state distribution , and q - factors of markov systems .",
    "the new representation of these solutions may shed some light on efficiently computing or estimating these fundamental quantities from a new perspective , which is very important for the performance optimization of markov decision processes .",
    "the first author was supported in part by the national natural science foundation of china ( 61573206 , 61203039 , u1301254 ) and would like to thank x. r. cao , j. j. hunter , c. d. meyer , and m. l. puterman for their helpful discussions and comments .",
    "a. berman and r. j. plemmons , _ nonnegative matrices in the mathematical sciences _ , siam , 1994 .",
    "d. p. bertsekas , _ dynamic programming and optimal control , vol .",
    "ii , 4th edition : approximate dynamic programming _ , athena scientific , 2012 . x. r. cao and h. f. chen , ",
    "potentials , perturbation realization , and sensitivity analysis of markov processes , \" _ ieee transactions on automatic control _ , vol .",
    "1382 - 1393 , 1997 .",
    "x. r. cao , _",
    "stochastic learning and optimization  a sensitivity - based approach _",
    ", new york : springer , 2007 .",
    "h. f. chen and w. x. zhao , _ recursive identification and parameter estimation _ , crc press , 2014 .",
    "g. frobenius ,  uber matrizen aus nicht negativen elementen , \" _ sitzungsber .",
    "456 - 477 , 1912 . j. j. hunter , _ mathematical techniques of applied probability , volume 2  discrete time models : techniques and applications _ , academic press , 1983 .",
    "j. j. hunter , ",
    "simple procedures for finding mean first passage times in markov chains , \" _ asia - pacific journal operational research _ , vol .",
    "813 - 829 , 2007 . j. j. hunter , ",
    "generalized inverses of markovian kernels in terms of properties of the markov chain , \" _ linear algebra and its applications _ , vol .",
    "38 - 55 , 2014 .",
    "j. g. kemeny ,  generalization of a fundamental matrix , \" _ linear algebra and its applications _ , vol 38 , pp .",
    "192 - 206 , 1981 .",
    "j. g. kemeny and l. j. snell , _ finite markov chains _ , van nostrand , new jersey , 1960 .",
    "c. d. meyer ,  sensitivity of the stationary distribution of a markov chain , \" _ journal siam journal on matrix analysis and applications _ , vol 15 , pp .",
    "715 - 728 , 1994 .",
    "o. perron ,  zur theorie der uber matrizen , \" _ mathematische annalen _ , vol .",
    "248 - 263 , doi:10.1007/bf01449896 , 1907 .",
    "m. l. puterman , _ markov decision processes : discrete stochastic dynamic programming _ , new york : john wiley & sons , 1994 .",
    "p. j. schweitzer ,  perturbation theory and finite markov chains , \" _ journal of applied probability _ vol 5 , pp .",
    "401 - 413 , 1968 .",
    "j. schweitzer and k. w. kindle ,  an iterative aggregation - disaggregation algorithm for solving linear equations , \" _ journal applied mathematics and computation _ , vol .",
    "313 - 353 , 1986 .",
    "e. seneta ,  sensitivity of finite markov chains under perturbation , \" _ statistics & probability letters _ 17 ( 1993 ) 163 - 168 .",
    "d. silver , a. huang , et al .",
    ",  mastering the game of go with deep neural networks and tree search , \" _ nature _ , vol .",
    "484 - 489 , 2016 .",
    "r. s. sutton and a. g. barto , _ reinforcement learning , an introduction _ , the mit press , 1998 ."
  ],
  "abstract_text": [
    "<S> as is well known , the fundamental matrix @xmath0 plays an important role in the performance analysis of markov systems , where @xmath1 is the transition probability matrix , @xmath2 is the column vector of ones , and @xmath3 is the row vector of the steady state distribution . it is used to compute the performance potential ( relative value function ) of markov decision processes under the average criterion , such as @xmath4 where @xmath5 is the column vector of performance potentials and @xmath6 is the column vector of reward functions . </S>",
    "<S> however , we need to pre - compute @xmath3 before we can compute @xmath7 . in this paper , we derive a generalization version of the fundamental matrix as @xmath8 , where @xmath9 can be any given row vector satisfying @xmath10 . with this generalized fundamental matrix </S>",
    "<S> , we can compute @xmath11 . </S>",
    "<S> the steady state distribution is computed as @xmath12 . </S>",
    "<S> the q - factors at every state - action pair can also be computed in a similar way . </S>",
    "<S> these formulas may give some insights on further understanding how to efficiently compute or estimate the values of @xmath5 , @xmath3 , and q - factors in markov systems , which are fundamental quantities for the performance optimization of markov systems .    </S>",
    "<S> * keywords * : fundamental matrix , performance potential , steady state distribution , q - factors , stochastic matrix </S>"
  ]
}