{
  "article_text": [
    "hyperlinks and other relations between concepts and instances in wikipedia have been successfully used in semantic tasks @xcite .",
    "still , many questions about the best way to leverage those links remain unanswered . for instance",
    ", methods using direct hyperlinks alone would wrongly disambiguate _",
    "lions _ in figure [ fig : example - show - disamb ] to ` b&i_lions ` , a rugby team from britain and ireland , as it shares two direct links to potential referents in the context ( _ darrel fletcher _ , a british football player , and _ cape town _ , the city where the team suffered some memorable defeats ) , while ` highveld_lions ` , a cricket team from south africa , has only one .",
    "when considering the whole graph of hyperlinks we find that the cricket team is related to two cricketers named _ alan kourie _ and _ duncan fletcher _ and could thus pick the right entity for _ lions _ in this context . in this paper",
    "we will study this and other questions about the use of hyperlinks in word relatedness @xcite and named - entity disambiguation , ned @xcite .",
    "previous work on this area has typically focused on novel algorithms which work on a specific mix of resource , information source , task and test dataset ( cf .",
    "[ sec : comp - relat - work ] ) . in the case of ned",
    ", the evaluation of the disambiguation component is confounded by interactions with mention spotting and candidate generation . with very few exceptions ,",
    "there is little analysis of components and alternatives , and it is very difficult to learn any insight beyond the fact that the mix under study attained certain performance on the target dataset . the number of algorithms and datasets is growing by the day , with no well - established single benchmark , and the fact that some systems are developed on test data , coupled with reproducibility problems ( * ? ? ?",
    "* on word relatedness ) , makes it very difficult to know where the area stands .",
    "there is a need for clear points of reference which allow to understand where each information source and algorithm stands with respect to other alternatives .",
    "we thus depart from previous work , seeking to set such a point of reference , and focus on a single knowledge source ( hyperlinks in wikipedia ) with a clear research objective : given a well - established random walk algorithm ( personalized pagerank  @xcite ) we explore sources of links and filtering methods , and contrast the use of the full graph with respect to using just direct links .",
    "we follow a clear development / test / analysis methodology , evaluating on a extensive range of both relatedness and ned datasets .",
    "the results are confirmed in both tasks , yielding more support to the findings in this research .",
    "all software and data are publicly available , with instructions to obtain out - of - the - box replicability .",
    "the contributions of our research are the following : ( 1 ) we show for the first time that performing random walks over the full graph is preferable than considering only direct links .",
    "( 2 ) we study several sources of links , showing that non - reciprocal links hurt and that the contribution of the category structure and links in infoboxes is residual .",
    "( 3 ) we set the new state - of - the - art for systems based on wikipedia links for _ both _ word relatedness and named - entity disambiguation .",
    "the results are close to the best systems to date , which use several information sources and/or supervised machine learning techniques , and specialize on either relatedness or disambiguation .",
    "our work shows that a careful analysis of varieties of graphs using a well - known random walk algorithm pays off more than most ad - hoc algorithms .",
    "the article is structured as follows .",
    "we first present previous work , followed by the different options to build hyperlink graphs .",
    "[ sec : pager - pers - pager ] reviews random walks for relatedness and ned .",
    "[ sec : note - exper - meth ] sets the experimental methodology , followed by the analysis and results on development data ( sect .",
    "[ sec : studying - graph ] ) and the comparison to the state of the art ( sect .",
    "[ sec : comp - relat - work ] ) . finally , sect .",
    "[ sec : concl - future - work ] draws the conclusions .",
    "the irruption of wikipedia has opened up enormous opportunities for natural language processing @xcite , with many derived knowledge - bases , including dbpedia @xcite , freebase @xcite , and babelnet @xcite , to name a few .",
    "these resources have been successfully used on semantic processing tasks like word relatedness , named - entity disambiguation ( ned ) , also known as entity linking , and the closely related wikification . broadly speaking , wikipedia - based approaches to those tasks",
    "can be split between those using the text in the articles ( e.g. , gabrilovich and markovitch , 2007 ) and those using the links between articles ( e.g. , guo et al . , 2011 ) .",
    "relatedness systems take two words and return a high number if the two words are similar or closely related ( e.g. _ professor _ - _ student _ ) , and a low number otherwise ( e.g. _ professor _ - _ cucumber _ ) .",
    "evaluation is performed comparing the returned values to those by humans @xcite .    in ned @xcite",
    "the input is a mention of a named - entity in context and the output is the appropriate instance from wikipedia , dbpedia or freebase ( cf .",
    "figure [ fig : example - show - disamb ] ) .",
    "wikification is similar @xcite , but target terms include common nouns and only relevant terms are disambiguated .",
    "note that the disambiguation component in wikification and ned can be the same .",
    "our work focuses on relatedness and ned .",
    "we favored ned over wikification because of the larger number of systems and evaluation datasets , but our conclusions are applicable to wikification , as well as other wikipedia - derived resources .    in this section",
    "we will focus on previous work using wikipedia links for relatedness , ned and wikification .",
    "although relatedness and disambiguation are closely related ( relatedness to context terms is an important disambiguation clue for ned ) , most of the systems are evaluated in either relatedness or ned , with few exceptions , like wikiminer @xcite , kore @xcite and the one presented in this paper .",
    "milne and witten are the first to use hyperlinks between articles for relatedness .",
    "they compare two articles according to the number of incoming links that they have in common ( i.e. overlap of direct - links ) based on normalized google distance ( ngd ) , combined with several heuristics and collocation strength . in later work @xcite",
    ", they incorporated machine learning .",
    "the authors also apply their technique to ned @xcite , using their relatedness measures to train a supervised classifier .",
    "unfortunately they do not present results of their link - based method alone , so we decided to reimplement it ( cf .",
    "[ sec : studying - graph ] ) .",
    "we show that , under the same conditions , using the full - graph is more effective in both tasks .",
    "we also run their out - of - the - box system on the same datasets as ours ( cf .",
    "[ sec : comp - relat - work ] ) , with results below ours .",
    "apart from hyperlinks between articles , other works on relatedness use the category structure @xcite to run path - based relatedness algorithms which had been successful on wordnet @xcite , or use relations in infoboxes @xcite . in all cases ,",
    "they obtain performance figures well below hyperlink - based systems ( cf .",
    "[ sec : comp - relat - work ] ) .",
    "we will explore the contribution of such relations ( cf .",
    "[ subsec : build - wikip - graphs ] ) , incorporating them to the hyperlink graph .",
    "attempts to use the whole graph of hyperlinks for relatedness have been reported before .",
    "yeh et al . obtained very low results on relatedness using an algorithm based on random walks similar to ours .",
    "similar in spirit , yazdani and popescu - belis built a graph derived from the freebase wikipedia extraction dataset , which is derived but richer than wikipedia .",
    "even if they mix hyperlinks with textual similarity , their results are lower than ours .",
    "one of the key differences with these systems is that we remove non - reciprocal links ( cf .",
    "[ subsec : build - wikip - graphs ] ) .",
    "regarding link - based methods for ned , there is only one system which relies exclusively on hyperlinks .",
    "guo et al .",
    "use direct hyperlinks between the target entity and the mentions in the context , counting the number of such links .",
    "we show that the use of the full graph produces better results .",
    "the rest of ned systems present complex combinations .",
    "lemahnn et al .",
    "present a supervised system combining features based on hyperlinks , categories , text similarity and relations from infoboxes . despite their complex and rich system",
    ", we will show that they perform worse than our system .",
    "explored hyperlinks beyond direct links for ned , building subgraphs for each context using paths of length two departing from the context terms , combined with text - based relatedness .",
    "we will show that the full graph is more effective than limiting the distance to two , and report better results than their system .",
    "several authors have included direct links using the aforementioned ngd in their combined systems @xcite .",
    "unfortunately , they do no report separate results for the ngd component . in very recent work compare ngd with several other algorithms using direct links , but do not explore the full graph , or try to characterize links .",
    "we will see that their results are well below ours ( cf .",
    "[ sec : comp - relat - work ] ) .",
    "graph - based algorithms for relatedness and disambiguation have been successfully used on other resources , particularly wordnet .",
    "hughes and ramage were the first presenting a random walk algorithm over the wordnet graph .",
    "agirre et al .",
    "improved over their results using a similar random walk algorithm on several variations of wordnet relations , reporting the best results to date among wordnet - based algorithms .",
    "the same algorithm was used for word sense disambiguation @xcite , also reporting state - of - the - art results .",
    "we use the same open source software in our experiments . as an alternative to random walks ,",
    "tsatsaronis et al .",
    "use a path - based system over the wordnet relation graph .    in more recent work @xcite , the authors present two relatedness algorithms for babelnet , an enriched version of wordnet including articles from wikipedia , hyperlinks and cross - lingual relations from non - english wikipedias . in related work ,",
    "moro et al .",
    "present a multi - step ned algorithm on babelnet , building semantic graphs for each context .",
    "we will show that wikipedia hyperlinks alone are able to provide similar performance on both tasks .",
    "wikipedia pages can be classified into main articles , category pages , redirects and disambiguation pages . given a wikipedia dump ( a snapshot from april 4 , 2013 ) , we mine",
    "links between articles , between articles and category pages , as well as the links between category pages ( the category structure ) .",
    "our graphs include a directed edge from one article to another iff the text of the first article contains a hyperlink to the second article .",
    "in addition , we also include hyperlinks in infoboxes .",
    "the graph contains two types of nodes ( articles and categories ) and three types of directed edges : hyperlinks from article to article ( * h * ) , infobox links from article to article ( * i * ) , links from article to category and links from category to category ( * c * ) .",
    "we constructed several graphs using different combinations of nodes and edges .",
    "in addition to the directed versions ( * d * ) we also constructed an undirected version ( * u * ) , and a reduced graph which only contains links which are reciprocal ( * r * ) , that is , we add a pair of edges between @xmath0 and @xmath1 if and only if there exists a hyperlink from @xmath0 to @xmath1 and from @xmath1 to @xmath0 . *",
    "reciprocal * links capture the intuition that both articles are relevant to each other , and tackle issues with links to low relevance articles , e.g. links to articles on specific years like 1984 . some authors weight links according to their relevance @xcite .",
    "our heuristic to keep only reciprocal links can be seen as a simpler , yet effective , method to avoid low relevance links .",
    ".statistics for selected graphs and results on development data for relatedness ( rg , spearman ) and ned ( tac09@xmath2 , accuracy ) with default parameters ( see text ) .",
    "[ subsec : uniform - graph - based ] for abbreviations .",
    "@xmath3 for stat .",
    "significant differences with hr in either rg or tac09@xmath2 .",
    "@xmath4 for stat .",
    "signif . when comparing on all relatedness or ned datasets .",
    "[ cols=\">,>,>,<,<\",options=\"header \" , ]     * how important is the wikipedia version ? *",
    "table [ table : wiki - versions ] shows that the versions we tested are not affecting the results dramatically , and that using the last version does not yield better results in ned .",
    "perhaps the larger size and number of hyperlinks of newer versions would only affect new articles and rare articles , but not the ones present in tac09@xmath2 .",
    "we kept using 2013 for test .    *",
    "what is the efficiency of the algorithm ? * the initialization takes around 5 minutes , where most of the time is spent loading the dictionary into memory , 4m50s . using a database instead",
    ", initialization takes 10s .",
    "memory requirements for hr were 4.7 gb , down to 1.1 gb when using the database .",
    "the main bottleneck of our system is the computation of personalized pagerank , each iteration taking around 0.60 seconds .",
    "we are currently checking fast approximations for pagerank , and plan to improve efficiency .",
    "in the previous section we presented several results on the same experimental conditions .",
    "we now use the graph and parametrization which yield the best results on development ( default parameters with hr ) .",
    "comparison to the state of the art is complicated by many systems reporting results on different datasets , which causes the tables in this section to be rather sparse .",
    "the comparison for relatedness is straightforward , but , in ned , it is not possible to factor out the impact of the candidate generation step .",
    "given the fact that our candidate generation procedure is not particularly sophisticated , we do nt think this is a decisive factor in favour of our results .",
    "table [ table : simsota ] and [ table : ned_testresults ] report the results of the best systems on both tasks .",
    "given that several systems were developed on test data , we also report our results on rg and tac2009 , marking all such results ( see caption of tables for details ) .",
    "we split the results in both tables in three sets : top rows for systems using link and graph information alone , middle rows for link- and graph - based systems using wordnet and/or wikipedia , and bottom rows for more complex systems .",
    "we report the results of our system repeatedly in each set of rows , for easier comparison .",
    "our main focus is on the top rows , which show the superiority of our results with respect to other systems using wikipedia links and graphs .",
    "the middle and bottom rows show the relation to the state of the art .    for easier exposition , we will examine the results by row section simultaneously on relatedness and ned .",
    "the * top rows * in table [ table : simsota ] report four relatedness systems which have already been presented in sect .",
    "[ sec : previous - work ] , showing that our system is best in all five datasets .",
    "note that the @xcite row was obtained running their publicly available system with the supervised machine learning component turned off ( see below for the results using sup ) .",
    "the top rows of table [ table : ned_testresults ] report the most frequent baseline ( as produced by our dictionary ) and three link - based systems ( cf .",
    "[ sec : previous - work ] ) , showing that our method is best in all five datasets .",
    "these results show that the use of the full graph as devised in this paper is a winning strategy .",
    "the relatedness results in the * middle rows * of table [ table : simsota ] include several systems using wordnet and/or wikipedia ( cf .",
    "[ sec : previous - work ] ) , including the system in @xcite , which we run out - of - the - box with default values . to date ,",
    "link - based systems using wordnet had reported stronger results than their counterparts on wikipedia , but the table shows that our wikipedia - based results are the strongest on all relatedness datasets but one ( mc , the smallest dataset , with only 30 pairs ) . in addition , the table shows our results when combining random walks on wikipedia and wordnet , which yields improvements in most datasets . in the counterpart for ned in table [ table : ned_testresults ] , moro et al . outperform our system , specially in the smaller kore ( 143 instances ) , but note that they use a richer graph which combines wordnet , the english wikipedia and hyperlinks from other language wikipedias .    finally , the * bottom rows * in both tables report the best systems to date . for lack of space , we can not review systems not using wikipedia links . regarding relatedness",
    ", we can see that our combination of wordnet and wikipedia would rank second in all datasets , with only one single system ( based on corpora ) beating our system in more than one dataset @xcite .",
    "regarding ned , our system ranks first in the tac datasets , including the best systems that participated in the tac competitions @xcite , and second to @xcite on aida and kore .",
    "this work departs from previous work based on wikipedia and derived resources , as it focuses on a single knowledge source ( links in wikipedia ) with a clear research objective : given a well - established random walk algorithm we explored which sources of links and filtering methods are useful , contrasting the use of the full graph with respect to using just direct links .",
    "we follow a clear development / test / analysis methodology , evaluating on a extensive range of both relatedness and ned datasets .",
    "all software and data are publicly available , with instructions to obtain out - of - the - box replicability .",
    "we show for the first time that random walks over the full graph of links improve over direct links .",
    "we studied several variations of sources of links , showing that non - reciprocal links hurt and that the contribution of the category structure and relations in infoboxes is residual .",
    "this paper sets a new state - of - the - art for systems based on wikipedia links on both word relatedness and named - entity disambiguation datasets .",
    "the results are close to those of the best combined systems , which specialize on either relatedness or disambiguation , use several information sources and/or supervised machine learning techniques .",
    "this work shows that a careful analysis of varieties of graphs using a well - known random walk algorithm pays off more than most ad - hoc algorithms proposed up to date .    for the future",
    ", we would like to explore ways to filter out informative hyperlinks , perhaps weighting edges according to their relevance , and would also like to speed up the random - walk computations .",
    "this article showed the potential of the graph of hyperlinks .",
    "we would like to explore combinations with other sources of information and algorithms , perhaps using supervised machine learning .",
    "for relatedness , we already showed improvement when combining with random walks over wordnet , but would like to explore tighter integration @xcite . for ned",
    ", local methods @xcite , global optimization strategies based on keyphrases in context like kore @xcite and doing ned jointly with word sense disambiguation @xcite , all are complementary to our method and thus promising directions .",
    "this work was partially funded by mineco ( chist - era readers project ",
    "pcin-2013 - 002- c02 - 01 ) and the european commission ( qtleap  fp7-ict-2013.4.1 - 610516 ) .",
    "ander barrena is supported by a phd grant from the university of the basque country .",
    "e.  agirre , a.  soroa , e.  alfonseca , k.  hall , j.  kravalova , and m.  pasca .",
    "2009 . . in _ proceedings of annual meeting of the north american chapter of the association of computational linguistics ( naac ) _ , boulder , usa , june",
    "e.  agirre , m.  cuadros , g.  rigau , and a.  soroa .",
    "2010 . . in _ proceedings of the seventh conference on international language resources and evaluation ( lrec10 )",
    "_ , valletta , malta , may .",
    "european language resources association ( elra ) .",
    "christian bizer , jens lehmann , georgi kobilarov , sren auer , christian becker , richard cyganiak , and sebastian hellmann .",
    "dbpedia - a crystallization point for the web of data .",
    ", 7(3):154165 , september .",
    "kurt bollacker , colin evans , praveen paritosh , tim sturge , and jamie taylor .",
    "freebase : a collaboratively created graph database for structuring human knowledge . in _ proceedings of the 2008 acm",
    "sigmod international conference on management of data _ , sigmod 08 , pages 12471250 , new york , ny , usa . acm .",
    "s.  brin and l.  page .",
    "in _ proceedings of the seventh international conference on world wide web 7 _ , www7 , pages 107117 , amsterdam , the netherlands , the netherlands .",
    "elsevier science publishers b. v.      marco cornolti , paolo ferragina , and massimiliano ciaramita .",
    "a framework for benchmarking entity - annotation systems . in _ proceedings of the 22nd international conference on world wide web _ , www 13 ,",
    "page 249260 , republic and canton of geneva , switzerland",
    ". international world wide web conferences steering committee .",
    "silviu cucerzan and avirup sil .",
    "the msr systems for entity linking and temporal slot filling at tac 2013 . in _ proceedings of the sixth text analysis conference ( tac 2013 ) _",
    ", page  10 .",
    "national institute of standards and technology ( nist ) .",
    "antske fokkens , marieke van erp , marten postma , ted pedersen , piek vossen , and nuno freire .",
    "offspring from reproduction problems : what replication failure teaches us . in _ proceedings of the 51st annual meeting of the association for computational linguistics ( volume 1 : long papers ) _ , pages 16911701 , sofia , bulgaria , august .",
    "association for computational linguistics .",
    "yuhang guo , wanxiang che , ting liu , and sheng li .",
    "a graph - based method for entity linking . in _ proceedings of 5th international joint conference on natural language processing _",
    ", page 10101018 , chiang mai , thailand , november .",
    "asian federation of natural language processing .",
    "b.  hachey , w.  radford , and j.r . curran .",
    "2011 . . in _ proceedings of the 12th international conference on web information system engineering",
    ", wise11 , pages 213226 , berlin , heidelberg .",
    "springer - verlag .",
    "j.  hoffart , m.a .",
    "yosef , i.  bordino , h.  frstenau , m.  pinkal , m.  spaniol , b.  taneva , s.  thater , and g.  weikum .",
    "2011 . . in _ conference on empirical methods in natural language processing , edinburgh , scotland , united kingdom 2011 _ , pages 782792",
    "johannes hoffart , stephan seufert , dat  ba nguyen , martin theobald , and gerhard weikum .",
    "kore : keyphrase overlap relatedness for entity disambiguation . in _ proceedings of the 21st acm international conference on information and knowledge management _",
    ", page 545554 .",
    "a.  islam and d.  inkpen",
    "second order co - occurrence pmi for determining the semantic similarity of words . in _ proceedings of the international conference on language resources and evaluation ( lrec 2006 ) _ , pages 10331038 .",
    "rada mihalcea and andras csomai",
    "wikify ! : linking documents to encyclopedic knowledge . in _ proceedings of the sixteenth acm conference on conference on information and knowledge management _ , pages 233242 .",
    "acm .",
    "ted pedersen , siddharth patwardhan , and jason michelizzi .",
    "wordnet::similarity : measuring the relatedness of concepts . in _ demonstration papers at hlt - naacl",
    "2004 _ , hlt - naacl ",
    "demonstrations 04 , pages 3841 , stroudsburg , pa , usa . association for computational linguistics .",
    "mohammad  taher pilehvar , david jurgens , and roberto navigli .",
    "lign , disambiguate and walk : a unified approach for measuring semantic similarity . in _ proceedings of the 51st annual meeting of the association for computational linguistics _ , pages 13411351 , sofia , bulgaria .",
    "kira radinsky , eugene agichtein , evgeniy gabrilovich , and shaul markovitch .",
    "2011 . a word at a time : computing word relatedness using temporal semantic analysis . in _ proceedings of the 20th international conference on world wide web _ , www 11 , pages 337346 , new york , ny , usa . acm .    l.a .",
    "ratinov , d.  roth , d.  downey , and m.  anderson .",
    "in _ the 49th annual meeting of the association for computational linguistics : human language technologies , proceedings of the conference , 19 - 24 june , 2011 , portland , oregon , usa _ , pages 13751384 .",
    "the association for computer linguistics .",
    "michael strube and simone  paolo ponzetto .",
    "wikirelate ! computing semantic relatedness using wikipedia . in _ proceedings of the national conference on artificial intelligence _ , volume  21 , pages 14191424 .",
    "menlo park , ca ; cambridge , ma ; london ; aaai press .",
    "e.  yeh , d.  ramage , c.d .",
    "manning , e.  agirre , and a.  soroa .",
    "in _ proceedings of the 2009 workshop on graph - based methods for natural language processing ( textgraphs-4 ) _ , pages 4149 , suntec , singapore , august .",
    "association for computational linguistics ."
  ],
  "abstract_text": [
    "<S> hyperlinks and other relations in wikipedia are a extraordinary resource which is still not fully understood . in this paper we study the different types of links in wikipedia , and contrast the use of the full graph with respect to just direct links . we apply a well - known random walk algorithm on two tasks , word relatedness and named - entity disambiguation . we show that using the full graph is more effective than just direct links by a large margin , that non - reciprocal links harm performance , and that there is no benefit from categories and infoboxes , with coherent results on both tasks . </S>",
    "<S> we set new state - of - the - art figures for systems based on wikipedia links , comparable to systems exploiting several information sources and/or supervised machine learning . </S>",
    "<S> our approach is open source , with instruction to reproduce results , and amenable to be integrated with complementary text - based methods . </S>"
  ]
}