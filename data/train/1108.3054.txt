{
  "article_text": [
    "the problem of how to efficiently perform arithmetic in @xmath0 is a very natural one , with numerous applications in computational mathematics and number theory , such as primality proving  @xcite , factoring  @xcite , and coding theory  @xcite , for example .",
    "it is also of central importance to nearly all public - key cryptographic systems , including the digital signature algorithm  @xcite , rsa  @xcite , and elliptic curve cryptography ( ecc )  @xcite . as such , from both a theoretical and a practical perspective it is interesting and essential to have efficient algorithms for working in this ring , for either arbitrary or special moduli , with the application determining whether generality ( essential for rsa for instance ) , or efficiency ( desirable for ecc ) takes precedence .",
    "two intimately related factors need consideration when approaching this problem .",
    "first , how should one represent residues ? and",
    "second , how should one perform arithmetic on these representatives ?",
    "a basic answer to the first question is to use the canonical representation @xmath1 . with regard to modular multiplication for example ,",
    "an obvious answer to the second question is to perform integer multiplication of residues , followed by reduction of the result modulo @xmath2 , in order to obtain a canonical representative once again . using this approach , the two components needed for efficient modular arithmetic are clearly fast integer arithmetic , and fast modular reduction .    at bitlengths for which schoolbook multiplication is optimal , research on fast modular multiplication",
    "has naturally tended to focus on reducing the cost of the reduction step . for arbitrary moduli ,",
    "montgomery s celebrated algorithm  @xcite enables reduction to be performed for approximately the cost of a residue by residue multiplication . for the mersenne numbers",
    "@xmath3 , efficient modular multiplication consists of integer residue multiplication to produce a @xmath4-bit product @xmath5 , with @xmath6 of at most @xmath7-bits , followed by a single modular addition @xmath8 to effect the reduction , as is well known . in 1999",
    "solinas proposed an extension of this method to a larger class of integers : the generalised mersenne numbers ( gmns )  @xcite .",
    "as they are a superset , gmns are more numerous than the mersenne numbers and hence contain more primes , yet incur little additional overhead in terms of performance  @xcite . in 2000",
    ", nist recommended ten fields for use in the ecdsa : five binary fields and five prime fields , and due to their performance characteristics the latter of these are all gmns  @xcite , which range from @xmath9 to @xmath10 bits in size .",
    "the standards for efficient cryptography group also recommended the same five prime fields in 2010  @xcite .",
    "for the gmns recommended by nist , there is no interplay between the residue multiplication and reduction algorithms , each step being treated separately with respect to optimisation . on the other hand , at asymptotic bitlengths the form of the modulus",
    "may be effectively exploited to speed up the residue multiplication step . for the mersenne numbers",
    "@xmath11 in particular , modular multiplication can be performed for any @xmath7 using a cyclic convolution effected by an irrational - base discrete weighted transform ( ibdwt )  @xcite ( see also  @xcite for an excellent overview of discrete fourier transform - based multiplication methods , convolution theory and ibdwts ) . as such , multiplication modulo mersenne numbers",
    "is approximately twice as fast as multiplication of integers of the same bitlength , for which a linear convolution is required , as each multiplicand must be padded with @xmath7 zeros before a cyclic convolution of length @xmath4 can be performed . for montgomery multiplication at asymptotic bitlengths",
    ", the reduction step can be made @xmath12 cheaper , again by using a cyclic rather than a linear convolution for one of the required multiplications  @xcite . however , since the multiplication step is oblivious to the form of the modulus , it seems unlikely to possess the same efficiency benefits that the mersenne numbers enjoy .",
    "these considerations raise the natural question of whether there exists a similar residue multiplication speed - up at bitlengths for which schoolbook multiplication is optimal ? certainly for the modulus @xmath13 , such a speed - up can be achieved , since the upper half words of the product can simply be ignored . however , this modulus is unfortunately not at all useful for ecc .    in this work",
    "we answer the above question affirmatively , using an alternative generalisation of mersenne numbers , which has several desirable features :    @xmath14=1.2em    * simple . *",
    "our proposed family is arguably a far more natural generalisation of mersenne numbers than solinas , and gives rise to beautiful multiplication and reduction algorithms .",
    "* abundant . *",
    "our primes are significantly more numerous than the set of prime gmns and are abundant for all tested bitlengths ; indeed their number can be estimated using bateman and horn s quantitative version  @xcite of schinzel and sierpiski s `` hypothesis h ''  @xcite",
    ".    * fast multiplication . *",
    "our residue multiplication is nearly twice as fast as multiplication of integer residues .",
    "* fast reduction . *",
    "our reduction has linear complexity and is particularly efficient for specialised parameters , although such specialisation comes at the cost of reducing the number of primes available .",
    "* parallelisable . *",
    "both multiplication and reduction can be easily parallelised , making our arithmetic particularly suitable for hardware implementation",
    ".    * side - channel secure . *",
    "our representation naturally protects against well - known side - channel attacks on ecc ( see  ( * ? ? ?",
    "iv ) for an overview ) , in contrast to the nist gmns , see  @xcite and  @xcite .",
    "this includes timing attacks  @xcite , simple power analysis  @xcite and differential power analysis  @xcite .",
    "this article provides an introductory ( and comprehensive ) theoretical framework for the use of our proposed moduli .",
    "it thus serves as a foundation for a new approach to the secure and efficient implementation of prime fields for ecc , both in software and in hardware . at a high level",
    ", our proposal relies on the combination of a remarkable algebraic identity used by nogami , saito , and morikawa in the context of extension fields  @xcite , together with the residue representation and optimisation of the reduction method proposed by chung and hasan  @xcite , which models suitable prime fields as the quotient of an integer lattice by a particular equivalence relation . to verify the validity of our approach",
    ", we also provide a proof - of - concept implementation that is already competitive with the current fastest modular multiplication algorithms at contemporary ecc security levels  @xcite .",
    "the sequel is organised as follows . in ",
    "[ sec : definitions ] we present some definitions and recall related work . in ",
    "[ sec : mrcpfieldrep ] we describe the basis of our arithmetic , then in  [ sec : multiplication]-[sec : representation ] we present details of our residue multiplication , reduction and representation respectively . in  [ sec : stability ] we show how to ensure i / o stability for modular multiplication , then in  [ sec : fullmul ] we put everything together into a full modular multiplication algorithm .",
    "we then address other arithmetic operations and give a brief treatment of side - channel secure ecc in  [ sec : otherops ] , and in  [ sec : paramgen ] show how to generate suitable parameters . in  [ sec : results ] we present our implementation results and finally , in ",
    "[ sec : conclusion ] we draw some conclusions .",
    "in this section we introduce the cyclotomic primes and provide a summary of related work .",
    "we begin with the following definition .    for @xmath15 let @xmath16 be a primitive @xmath17-th root of unity .",
    "the @xmath17-th cyclotomic polynomial is defined by @xmath18 where @xmath19 is the mbius function .",
    "two basic properties of the cyclotomic polynomials are that they have integer coefficients , and are irreducible over @xmath20 .",
    "these two properties ensure that the evaluation of a cyclotomic polynomial at an integer argument will also be an integer , and that this integer will not inherit a factorisation from one in @xmath21 $ ] .",
    "one can therefore ask whether or not these polynomials ever assume prime values at integer arguments , which leads to our next definition .    for @xmath15 and @xmath22 ,",
    "if @xmath23 is prime , we call @xmath24 an @xmath17-th cyclotomic prime , or simply a cyclotomic prime .    note that for all primes @xmath24 , we have @xmath25 , and so trivially all primes are cyclotomic primes .",
    "these instances are also trivial in the context of the algorithms we present for performing arithmetic modulo these primes , since in both cases the cyclotomic polynomials are linear and our algorithms reduce to ordinary montgomery arithmetic .",
    "hence for the remainder of the article we assume @xmath26 .",
    "in addition to being prime - evaluations of cyclotomic polynomials , note that for a cyclotomic prime @xmath27 , the field @xmath28 can be modelled as the quotient of the ring of integers of the @xmath17-th cyclotomic field @xmath29 , by the prime ideal @xmath30 .",
    "this is precisely how one would represent @xmath28 when applying the special number field sieve to solve discrete logarithms in @xmath28 , for example  @xcite .",
    "hence our nomenclature for these primes seems apt .",
    "this interpretation of @xmath28 for @xmath24 a cyclotomic prime is implicit within the arithmetic we develop here , albeit only insofar as it provides a theoretical context for it ; this perspective offers no obvious insight into how to perform arithmetic efficiently and the algorithms we develop make no use of it at all .",
    "similarly , the method of chung and hasan  @xcite upon which our residue representation is based can be seen as arising in exactly the same way for the much larger set of primes they consider , with the field modelled as a quotient of the ring of integers of a suitable number field by a degree one prime ideal , just as for the cyclotomic primes .",
    "the goal of the present work is to provide efficient algorithms for performing @xmath28 arithmetic , for @xmath23 a cyclotomic prime . as will become clear from our exposition , in order to exploit the available cyclic structure  for both multiplication and reduction",
    " we do not use the field @xmath31 , but instead embed into the slightly larger ring @xmath32 if @xmath17 is odd , and @xmath33 if @xmath17 is even . in each case , using the larger ring potentially introduces an expansion factor @xmath34 into the residue representation .",
    "one can alternatively view this in terms of a redundancy measure @xmath35 , where @xmath36 . since using a larger ring for arithmetic",
    "will potentially be slower , we now identify three families of cyclotomic polynomials for which the above embeddings have low redundancy .    for @xmath17 even , there is a family of cases for which the above embedding does not introduce any redundancy , namely for @xmath37 , since @xmath38 , and hence @xmath39 and @xmath40 .",
    "when @xmath41 these are of course the fermat numbers , and for general @xmath42 these integers are known as generalised fermat numbers ( gfns ) .",
    "it is expected that for each @xmath7 there are infinitely many @xmath42 for which @xmath43 is prime  @xcite .",
    "if @xmath44 for @xmath24 prime , then @xmath45 and in this case @xmath46 and @xmath47 . the primality of these numbers was studied in  @xcite , and while they apparently do not have a designation in the literature , one can see that by substituting @xmath42 with @xmath48 in the third family below produces this one . for general",
    "even @xmath17 we have @xmath49 and @xmath50 , with @xmath51 euler s totient function , which is the degree of @xmath52 .",
    "hence amongst those even @xmath17 which are not a power of @xmath53 , this family produces the successive local minima of @xmath54 .    for odd @xmath17",
    ", we have @xmath55 and @xmath56",
    ". the successive local minima of @xmath54 occur at @xmath57 for @xmath24 prime , in which case @xmath58 , also with @xmath47 .",
    "when @xmath41 these are of course the mersenne numbers , and in analogy with the case of fermat numbers , it would be natural to refer to these integers for general @xmath42 as generalised mersenne numbers , particularly as one can show they share the aforementioned asymptotic efficiency properties of the mersenne numbers , while solinas gmns do not , unless they are of mersenne s form .",
    "however , this family of numbers is known in the literature as generalised repunits  @xcite , since their base-@xmath42 expansion consists entirely of @xmath59 s .",
    "therefore for the sake of uniform nomenclature , we use the following definition .    for @xmath60 an odd prime let @xmath61 we call such an integer a _ generalised repunit ( gr ) _ ; when @xmath24 is prime we call it a _ generalised repunit prime ( grp)_.    we have developed modular multiplication algorithms for both grps and gfns . in terms of efficiency , for grps and gfns of the same bitlength",
    "the respective multiplication algorithms require exactly the same number of word - by - word multiplications .",
    "also , our reduction algorithms for both grps and gfns are virtually identical . however , the multiplication algorithm for gfns is far less elegant , is not perfectly parallelisable and contains more additions .",
    "furthermore , for a given bitlength there are fewer efficient gfn primes than there are grps  as the bitlength of gfns doubles as @xmath7 is incremented  and the i / o stability analysis for multiplication modulo a grp is far simpler .",
    "therefore in this exposition we focus on algorithms for performing arithmetic modulo grps and their analysis only .",
    "note that the studies of grps  @xcite consider only very small @xmath42 and large @xmath62 , whereas we will be interested in @xmath42 approximately the word base of the target architecture , and @xmath62 the number of words in the prime whose field arithmetic we are to implement .",
    "hence one expects ( and finds ) there to be very many grps for any given relevant bitlength , see  [ sec : paramgen ] .      in the context of extension fields ,",
    "let @xmath60 be prime and let @xmath24 be a primitive root modulo @xmath60 .",
    "then @xmath63/(\\phi_{m+1}(x){\\mathbb{f}}_p[x])$ ] . in the binary case , i.e. , @xmath64 ,",
    "several authors have proposed the use of this polynomial  also known as the all - one polynomial ( aop )  to obtain efficient multiplication algorithms  @xcite .",
    "all of these rely on the observation that the field @xmath65/(\\phi_{m+1}(x){\\mathbb{f}}_{2}[x])$ ] embeds into the ring @xmath65/((x^{m+1 } + 1){\\mathbb{f}}_{2}[x])$ ]  referred to by silverman  @xcite as the `` ghost bit '' basis  which possesses a particularly nice cyclic structure , but introduces some redundancy .",
    "similarly , this idea applies to any cyclotomic polynomial , and several authors have investigated this strategy , embedding suitably defined extension fields into the ring @xmath65/((x^{n } + 1){\\mathbb{f}}_{2}[x])$ ]  @xcite .    for odd characteristic extension fields ,",
    "silverman noted that the `` ghost bit '' basis for @xmath64 extends easily to larger @xmath24  @xcite , while kwon  _ et al . _",
    "have explored this idea further  @xcite .",
    "central to our application is the work of nogami , saito and morikawa  @xcite , who used the aop to obtain a very fast multiplication algorithm , see   [ sec : multiplication ] .",
    "the use of cyclotomic polynomials in extension field arithmetic is therefore well studied . in the context of prime fields",
    "however , the present work appears to be the first to transfer ideas for cyclotomic polynomials from the domain of extension field arithmetic to prime field arithmetic , at least for the relatively small bitlengths for which schoolbook multiplication is optimal .    with regard to the embedding of a prime field into a larger integer ring ,",
    "the idea of operand scaling was introduced by walter in order to obtain a desired representation in the higher - order bits  @xcite , which aids in the estimation of the quotient when using barrett reduction  @xcite .",
    "similarly , ozturk  _ et al . _",
    "proposed using fields with characteristics dividing integers of the form @xmath66 , with particular application to ecc  @xcite . as stated in the introduction ,",
    "there are numerous very efficient prime field ecc implementations  @xcite .",
    "while the moduli used in these instances permit fast reduction algorithms , and the implementations are highly optimised , it would appear that none of them permit the same residue multiplication speed - up that we present here , which is one of the central distinguishing features of the present work .",
    "in this section we present a sequence of representations of @xmath28 , with @xmath24 a grp , the final one being the target representation which we use for our arithmetic .",
    "we recall the mathematical framework of chung - hasan arithmetic , in both the general setting and as specialised to grps , focusing here on the underlying theory , deferring explicit algorithms for residue multiplication , reduction and representation until  [ sec : multiplication]-[sec : representation ] .",
    "we now describe the ideas behind chung - hasan arithmetic  @xcite .",
    "the arithmetic was developed for a class of integers they term low - weight polynomial form integers ( lwpfis ) , whose definition we now recall .",
    "an integer @xmath24 is a low - weight polynomial form integer ( lwpfi ) , if it can be represented by a monic polynomial @xmath67 , where @xmath42 is a positive integer and @xmath68 for some small positive integer @xmath69 .",
    "note that if for a given lwpfi each @xmath70 and @xmath71 , then it is a gmn , as defined by solinas  @xcite .",
    "the key idea of chung and hasan is to perform arithmetic modulo @xmath24 using representatives from the polynomial ring @xmath72/(f(t){\\mathbb{z}}[t])$ ] .",
    "to do so , one uses the natural embedding @xmath73/(f(t){\\mathbb{z}}[t])$ ] obtained by taking the base @xmath42 expansion of an element of @xmath28 in the canonical representation @xmath74 , and substituting @xmath75 for @xmath42 . to compute",
    "@xmath76 one simply makes the inverse substitution and evaluates the expression modulo @xmath24 .",
    "the reason for using this ring is straightforward : since @xmath76 is a homomorphism , when one computes @xmath77 in @xmath72 $ ] , reducing the result modulo @xmath78 to give @xmath79 does not change the element of @xmath28 represented by @xmath80 , i.e. , if @xmath81 , then @xmath82 , since @xmath83 .",
    "furthermore , since @xmath78 has very small coefficients , @xmath79 can be computed from @xmath80 using only additions and subtractions .",
    "hence given the degree @xmath84 product of two degree @xmath85 polynomials in @xmath72 $ ] , its degree @xmath85 representation in @xmath72/(f(t){\\mathbb{z}}[t])$ ] can be computed very efficiently .",
    "note that for non - low - weight polynomials this would no longer be the case .",
    "the only problem with this approach is that when computing @xmath80 as above , the coefficients of @xmath80 , and hence @xmath79 , will be approximately twice the size of the inputs coefficients , and if further operations are performed the representatives will continue to expand .",
    "since for i / o stability one requires that the coefficients be approximately the size of @xmath42 after each modular multiplication or squaring , one must somehow reduce the coefficients of @xmath79 to obtain a standard , or reduced representative , while ensuring that @xmath86 remains unchanged .",
    "chung and hasan refer to this issue as the _ coefficient reduction problem _ ( crp ) , and developed three solutions in their series of papers on lwpfi arithmetic  @xcite .",
    "each of these solutions is based on an underlying lattice , although this was only made explicit in  @xcite .",
    "since the lattice interpretation is the most elegant and simplifies the exposition , in the sequel we opt to develop the necessary theory for grp arithmetic in this setting .",
    "let @xmath87 be a grp .",
    "our goal is to develop arithmetic for @xmath28 , and we begin with the canonical representation @xmath88 . as stated in  [ subsec : lrcp ] ,",
    "the first map in our chain of representations takes the canonical ring and embeds it into @xmath89 , for which the identity map suffices . to map back",
    ", one reduces a representative modulo @xmath24 .",
    "we then apply the chung - hasan transformation of  [ subsec : charithmetic ] , which embeds the second ring into @xmath72/(t^{m+1}-1){\\mathbb{z}}[t]$ ] , by taking the base @xmath42 expansion of a canonical residue representative in @xmath89 , and substituting @xmath75 for @xmath42 .",
    "we call this map @xmath90 . to compute @xmath76 one simply makes the inverse substitution and evaluates the expression modulo @xmath91 .",
    "note that the codomain of @xmath90 may be regarded as an @xmath92-dimensional vector space over @xmath20 , equipped with the natural basis @xmath93 .",
    "in particular , for @xmath94/(t^{m+1}-1){\\mathbb{z}}[t]$ ] , where @xmath95 one can consider @xmath96 to be a vector @xmath97 \\in { \\mathbb{z}}^{m+1}$ ] . since @xmath98 has elements whose components are naturally unbounded , for each @xmath99 there are infinitely many elements of @xmath98 that map via @xmath76 to @xmath100 . therefore in order to obtain a useful isomorphism directly between @xmath89 and @xmath98 , we identify two elements of @xmath98 whenever they map via @xmath76 to the same element of @xmath89 , i.e. , @xmath101 and take the image of @xmath90 to be the quotient of @xmath98 by this equivalence relation .",
    "pictorially , we thus have : @xmath102    as mentioned in  [ subsec : charithmetic ] , for each coset in @xmath103",
    ", we should like to use a minimal , or in some sense ` small ' representative , in order to facilitate efficient arithmetic after a multiplication or a squaring , for example .",
    "since we know that the base-@xmath42 expansion of every @xmath99 gives one such representative for each coset in @xmath103 , for a reduction algorithm we just need to be able to find it , or at least one whose components are of approximately the same size .",
    "chung and hasan related finding such ` nice ' or reduced coset representatives to solving a computational problem in an underlying lattice , which we now recall .      given an input vector @xmath104 , which is the output of a multiplication or a squaring , a coefficient reduction algorithm should output a vector @xmath105 such that @xmath106 , in the sense of  ( [ eq : lattice_mod ] ) , whose components are approximately the same size as @xmath42 . as observed in  @xcite , the equivalence relation  ( [ eq : lattice_mod ] ) is captured by an underlying lattice , and finding @xmath105 is tantamount to solving an instance of the _ closest vector problem _ ( cvp ) in this lattice . to see why this is , we first fix some notation as in  @xcite .",
    "let @xmath107 and @xmath108 be vectors in @xmath98 such that the following condition is satisfied : @xmath109 \\cdot { \\overline{\\mathbf{u}}}^t \\equiv [ t^{m } , \\ldots , t , 1 ] \\cdot { \\overline{\\mathbf{v}}}^t \\pmod { t^{m+1}-1}\\ ] ] then we say that _ @xmath107 is congruent to @xmath108 modulo @xmath110 _ and write this as @xmath111 .",
    "note that this is exactly the same as saying @xmath112 , and so @xmath113 .",
    "similarly , but abusing notation slightly , for any integer @xmath114 ( where @xmath115 is typically a power of the word base of the target architecture ) , we write @xmath116 for some integer @xmath117 satisfying @xmath118 \\cdot { \\overline{\\mathbf{u}}}^t \\equiv v \\pmod { b}$ ] , and say _ @xmath107 is congruent to @xmath117 modulo @xmath115 _ , in this case .",
    "we reserve the use of ` @xmath119 ' to express a component - wise congruence relation , i.e. , @xmath120 .",
    "finally , we denote by @xmath121 the component - wise modular reduction of @xmath107 by @xmath115 .",
    "the lattice underlying the equivalence relation  ( [ eq : lattice_mod ] ) can now enter the frame .",
    "let @xmath122 be a set of @xmath60 linearly independent vectors in @xmath98 such that @xmath123 , the all zero vector , for @xmath124 .",
    "then the set of all integer combinations of elements of @xmath125 forms an integral lattice , @xmath126 , with the property that for all @xmath127 , and all @xmath128 , we have @xmath129 in particular , the equivalence relation  ( [ eq : lattice_mod ] ) is captured by the lattice @xmath130 , in the sense that @xmath131 therefore if one selects basis vectors for @xmath130 that have infinity - norm approximately @xmath42 , then for a given @xmath127 , finding the closest vector @xmath128 to @xmath104 ( with respect to the @xmath132-norm ) , means the vector @xmath133 is in the fundamental domain of @xmath130 , and so has components of the desired size .",
    "furthermore , since @xmath133 , by  ( [ eq : no_sum ] ) we have @xmath134 and hence solving the cvp in this lattice solves the crp . in general solving the cvp is np - hard , but since we can exhibit a good ( near - othogonal ) lattice basis for lwpfis , and an excellent lattice basis for grps , solving it is straightforward in our case .      for grps , we use the following basis for @xmath130 : @xmath135\\ ] ]    observe that the infinity - norm of each basis vector is @xmath42 , so elements in the fundamental domain will have components of the desired size , and that each basis vector is orthogonal to all others except the two adjacent vectors ( considered cyclically ) . in order to perform a simple reduction that reduces the size of components by approximately @xmath136 bits ,",
    "write each component of @xmath104 in base @xmath42 : @xmath137 . if we define @xmath138 to be : @xmath139 + \\left [ \\begin{array}{cccccc } 1   & 0 & \\cdots & 0 & 0 & -t \\\\ -t & 1 & \\cdots & 0 & 0 & 0    \\\\ 0 & -t & \\cdots & 0 & 0 & 0    \\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots \\\\ 0 & 0 & \\cdots & -t & 1 & 0 \\\\ 0 & 0 & \\cdots & 0 & -t & 1 \\end{array } \\right ] \\left [ \\begin{array}{c }      z_{m-1,1}\\\\      z_{m-2,1}\\\\      \\vdots\\\\      \\vdots\\\\      z_{0,1}\\\\      z_{m,1}\\\\      \\end{array } \\right],\\ ] ] then @xmath140 and each @xmath141 , assuming @xmath142 .",
    "this was the method of reduction described in  @xcite , which requires integer division .",
    "the idea described in  @xcite was based on an analogue of barrett reduction  @xcite .",
    "the method we shall use , from  @xcite , is based on montgomery reduction  @xcite and for @xmath42 not a power of @xmath53 is the most efficient of the three chung - hasan methods .      in ordinary montgomery reduction",
    "@xcite , one has an integer @xmath143 which is to be reduced modulo @xmath24 , an odd prime , where here @xmath144 is the smallest power of the word base @xmath115 larger than @xmath24 .",
    "the central idea is to add a multiple of @xmath24 to @xmath145 such that the result is divisible by @xmath144 . upon dividing by @xmath144 , which is a simple right shift of words , the result is congruent to @xmath146 , and importantly is less than @xmath147 .",
    "in the context of grps , let @xmath148 be the smallest power of @xmath115 greater than @xmath42 .",
    "the input to the reduction algorithm is a vector @xmath127 for which each component is approximately @xmath149 .",
    "the natural analogue of montgomery reduction is to add to @xmath104 a vector @xmath128 whose components are also bounded by @xmath149 , such that @xmath150 \\pmod{r}$ ] .",
    "then upon the division of each component by @xmath144 , the result will be a vector @xmath105 which satisfies @xmath151 and which has components of the desired size .",
    "while this introduces an @xmath152 term into the congruence , as with montgomery arithmetic , one circumvents this simply by altering the original coset representation of @xmath89 , via the map @xmath153 , which is bijective since @xmath154 , assuming @xmath42 is even , see   [ sec : reduction ] .",
    "how then does one find a suitable lattice point @xmath107 ?",
    "for this one use the lattice basis  ( [ eq : latticebasis ] ) , which from here on in we call @xmath155 .",
    "proposition 3 of  @xcite proves that @xmath156 , and so @xmath157 .",
    "one can therefore compute @xmath158 giving @xmath105 with the required properties .",
    "observe that the form of these two operations is identical to montgomery reduction , the only difference being that integer multiplication is replaced by matrix by vector multiplication .",
    "it is easy to see that this is what one requires , since for any @xmath159 , we have @xmath160 , and so @xmath161 furthermore , modulo @xmath144 we have @xmath162^t,\\ ] ] ensuring the division of each component by @xmath144 is exact .",
    "hence @xmath163 , as claimed .    in  @xcite ,",
    "an algorithm was given for computing @xmath107 and @xmath105 in  ( [ basic_mont1 ] ) and  ( [ basic_mont2 ] ) respectively , for an arbitrary lwpfi @xmath164 . the number of word - by - word multiply instructions in the algorithm  which is the dominant cost  is @xmath165 , where @xmath17 is the degree of @xmath164 , and @xmath166 .",
    "in comparison , for ordinary montgomery reduction modulo an integer of equivalent size this number is @xmath167 , making the former approach potentially very attractive . for our choice of primes  the grps  our specialisation of this algorithm is extremely efficient , as we show in  [ sec : reduction ] .      for extension fields ,",
    "there exists a natural separation between the polynomial arithmetic of the extension , and the prime subfield arithmetic , which makes respective optimisation considerations for each almost orthogonal . on the other hand ,",
    "if for an lwpfi one naively attempts to use efficient techniques that are valid for extension fields , then one encounters an inherent obstruction , namely that there is no such separation between the polynomial arithmetic and the coefficient arithmetic , which leads to coefficient expansion upon performing arithmetic operations .",
    "chung - hasan arithmetic can be viewed as a tool to overcome this obstruction , since it provides an efficient solution to the coefficent reduction problem . in practice therefore any efficient techniques for extension field arithmetic can be ported to prime fields , whenever the prime is an lwpfi , which is precisely what we do in  [ sec : multiplication ] .",
    "in this section we detail algorithms for performing multiplication of grp residue representatives .",
    "while for the reduction and residue representation we consider elements to be in @xmath98 , the multiplication algorithm arises from the arithmetic of the polynomial ring @xmath72/(t^{m+1}-1){\\mathbb{z}}[t]$ ] , and so here we use this ring to derive the multiplication formulae .",
    "let @xmath168/(t^{m+1}-1){\\mathbb{z}}[t]$ ] , and let @xmath97 $ ] and @xmath169 $ ] be elements in @xmath170 . then in @xmath170 the product @xmath171 is equal to @xmath172 $ ] , where @xmath173 where the subscript @xmath174 denotes @xmath175 .",
    "this follows from the trivial property @xmath176 , and that for @xmath177 and @xmath178 , we have : @xmath179 this is of course just the cyclic convolution of @xmath180 and @xmath181 .",
    "nogami , saito and morikawa proposed the use of all - one polynomials ( aops ) to define extensions of prime fields  @xcite . in this section",
    "we will first describe their algorithm in this context , and then show how it fits into the framework developed in   [ sec : mrcpfieldrep ] .",
    "let @xmath28 be a prime field and let @xmath182 be irreducible over @xmath28 , i.e. , @xmath60 is prime and @xmath24 is a primitive root modulo @xmath60",
    ". then @xmath183/(f(\\omega){\\mathbb{f}}_p[\\omega])$ ] . using the polynomial basis @xmath184",
    " rather than the more conventional @xmath185  elements of @xmath186 are represented as vectors of length @xmath62 over @xmath28 : @xmath187 = x_m\\omega^m + x_{m-1}\\omega^{m-1 } + \\cdots + x_1\\omega.\\ ] ] let @xmath188 $ ] and @xmath189 $ ] be two elements to be multiplied . for @xmath190 , let @xmath191 where the subscript @xmath174 here , as in  [ subsec : mulordinary ] , denotes @xmath175 .",
    "one then has : @xmath192 nogami _ et al .",
    "_ refer to these coefficient formulae as the _ cyclic vector multiplication algorithm _",
    "( cvma ) formulae .",
    "the cvma formulae are remarkable , since the number of @xmath28 multiplications is reduced relative to the schoolbook method from @xmath193 to @xmath194 , but at the cost of increasing the number of @xmath28 additions from @xmath195 to @xmath196 .",
    "as alluded to in  [ subsec : highlevel ] , a basic insight of the present work is the observation that one may apply the expressions in  ( [ nogami_mul ] ) to grp multiplication , provided that one uses the chung - hasan representation and reduction methodology of  [ sec : mrcpfieldrep ] , to give a full modular multiplication algorithm .",
    "note that karatsuba - ofman multiplication  @xcite offers a similar trade - off for extension field arithmetic .",
    "crucially however , as we show in  [ subsec : costcomparison ] , when we apply these formulae to grps the number of additions required is in fact reduced .",
    "one thus expects the cvma to be significantly more efficient at contemporary ecc bitlengths .",
    "the original proof of  ( [ eq : nogami_state ] ) given in  @xcite excludes some intermediate steps and so for the sake of clarity we give a full proof in   [ subsec : derivation ] , beginning with the following motivation .",
    "observe that in the set of equations  ( [ nogami_mul ] ) , each of the @xmath197 coefficients @xmath198 is featured @xmath60 times , and so there is a nice symmetry and balance to the formulae .",
    "however due to the choice of basis , both @xmath199 and @xmath200 are implicitly assumed to be zero .",
    "the output @xmath104 naturally has this property also , and indeed if one extends the multiplication algorithm to compute @xmath201 we see that it equals @xmath202 .    at first sight ,",
    "the expression @xmath203 may seem a little unnatural .",
    "it is easy to change the basis from @xmath204 to @xmath185 : for @xmath205 $ ] and @xmath206 $ ] , we have : @xmath207 resulting in the expressions @xmath208 , with @xmath209 as given before .",
    "this change of basis relies on the relation @xmath210 note that in using this basis we have implicitly ensured that @xmath211 in  ( [ nogami_mul ] ) , rather than @xmath212 , and again the above formula is consistent since @xmath213 .",
    "more generally if one excludes @xmath214 from the basis , then @xmath215 and @xmath216 .",
    "one may infer from these observations that the most natural choice of basis would seem to be @xmath217 , and that the expressions for @xmath209 arise from the arithmetic in the quotient ring @xmath218/((\\omega^{m+1}-1){\\mathbb{f}}_p[\\omega])$ ] , rather than @xmath183/(f(\\omega){\\mathbb{f}}_p[\\omega])$ ] . in this case multiplication",
    "becomes @xmath219 where for the last equality we have again used equation  ( [ eliminate ] ) .",
    "we now derive the cvma formulae of  ( [ nogami_mul ] ) .",
    "let @xmath220 = \\sum_{i=0}^{m } x_i \\omega^i$ ] , and @xmath221 = \\sum_{i=0}^{m } y_i \\omega^i$ ] . then in the ring @xmath222 , as in  ( [ eq : convolution ] ) the product @xmath171 is equal to @xmath223 , where @xmath224 of crucial importance is the following identity .",
    "for @xmath190 we have : @xmath225 to verify this identity observe that when one expands the terms in the right - hand side , the two negative sums cancel with the second term on the left - hand side , since both are over a complete set of residues modulo @xmath60 .",
    "similarly the two positive sums are equal and therefore cancel with the convolutions in the first term on the left - hand side .",
    "we now observe that there is some redundancy in the right - hand side of  ( [ identity ] ) , in the following sense .",
    "first , observe that @xmath226 one can therefore rewrite the right - hand side of  ( [ identity ] ) as : @xmath227 noting that the @xmath228 term of expression  ( [ trick ] ) is zero , we rewrite it as : @xmath229 which in turn becomes @xmath230 and then upon negating the two terms in the second summation , we finally have @xmath231 hence  ( [ identity ] ) becomes @xmath232 equation  ( [ cyclicidentity ] ) gives an expression for the coefficients of the product @xmath104 of elements @xmath180 and @xmath181 , in the ring @xmath222 .",
    "assuming these are computed using the more efficient right - hand side , in order to restrict back to @xmath233/(f(\\omega){\\mathbb{f}}_p[\\omega])$ ] , one can reduce the resulting polynomial @xmath104 by @xmath234 .",
    "note however that one does not need to use a smaller basis  la nogami _ et al .",
    "_ in   [ subsec : mulnogami ] or   [ bases ] , but can reduce by @xmath234 _ implicitly _ , without performing any computation .",
    "indeed , letting @xmath235 , we have : @xmath236 therefore the first term on the right - hand side of  ( [ cyclicidentity ] ) vanishes , so that one need not even compute it . thus using the arithmetic in @xmath222 but implicitly working modulo @xmath234 is more efficient than performing arithmetic in @xmath222 alone .",
    "this is somewhat fortuitous as it means that while the multiply operation in  ( [ cheap ] ) is not correct in @xmath222 , nevertheless , when one maps back to @xmath233/(f(\\omega){\\mathbb{f}}_p[\\omega])$ ] , it is correct .",
    "since equation  ( [ identity ] ) is an algebraic identity , it is easy to see that exactly the same argument applies in the context of grps , and we can replace the formulae  ( [ eq : convolution ] ) with the cvma formulae  ( [ nogami_mul ] ) . since reduction in the ring @xmath168/(t^{m+1}-1){\\mathbb{z}}[t]$ ] has a particularly nice form for grps , we choose to use the full basis for @xmath170 and hence do not reduce _ explicitly _ modulo @xmath237 to obtain a smaller basis .",
    "this also has the effect of eliminating the need to perform the addition of @xmath238 ( or @xmath239 , or whichever term one wants to eliminate when one reduces modulo @xmath237 ) , simplifying the multiplication algorithm further . absorbing the minus sign into the @xmath209 , algorithm  [ alg : mrcpmul ] details how to multiply residue representatives .    observe that each component of @xmath104 may be computed entirely independently of the others .",
    "hence using @xmath60 processors rather than @xmath59 , it would be possible to speed up the execution time of algorithm  [ alg : mrcpmul ] by a factor of @xmath60 , making it particularly suitable for hardware implementation . in   [ sec : reduction ] we consider the parallelisation of our reduction algorithms as well .",
    "grp multiplication @xmath240 , { \\overline{\\mathbf{y } } } = [ y_{m},\\ldots , y_{0 } ] \\in { \\mathbb{z}}^{m+1}$ ] @xmath241 \\in { \\mathbb{z}}^{m+1}$ ] + where @xmath242[alg : mrcpmul ] ' .for @xmath243 to @xmath244 do : + ' . @xmath245 +   ' .return @xmath104      we here use a simple cost model to provide a measure of the potential performance improvement achieved by using algorithm  [ alg : mrcpmul ] , rather than schoolbook multiplication of residues . we assume the inputs to the multiplication algorithm have coefficients bounded by @xmath246 , i.e. , they each consist of @xmath247 words .",
    "let @xmath248 be the cost of a @xmath247-word by @xmath247-word schoolbook multiplication , and let @xmath249 be the cost of an ition of two @xmath247-word values .",
    "we assume that @xmath250 and that there is no overflow beyond @xmath251 words in the resulting vector components , which one can ensure by selecting appropriate grps , see   [ sec : stability ] .",
    "the cost of the multiplication using each method is as follows .",
    "working modulo @xmath252 and using a basis consisting of @xmath62 terms only , the number of coefficient multiplications is @xmath193 , while the number of double - length additions is also @xmath193 .",
    "hence the total cost is simply @xmath253 note that computing the convolution  ( [ eq : convolution ] ) costs @xmath254 which is costlier since it requires embedding into @xmath170 , which introduces some redundancy .      for each @xmath255",
    "computing each term in the sum costs @xmath256 , and so computing all these terms costs @xmath257 .",
    "the cost of adding these is @xmath258 .",
    "for all the @xmath60 terms @xmath255 the total cost is therefore @xmath259 therefore by using the cvma formulae , we reduce not only the number of multiplications , but also the number of additions ( by @xmath53 ) , contrary to the case of field extensions , for which the cvma formulae increases the number of additions by nearly @xmath260 .",
    "we have thus found an analogue of the asymptotic cyclic versus linear convolution speed - up for multiplication modulo mersenne numbers ( see eq .",
    "( 6.1 ) of  @xcite , for example ) at small bitlengths for which schoolbook multiplication is optimal , for grps .",
    "in this section we detail reduction algorithms for two types of grps . the first , algorithm  [ alg : red1 ] ,",
    "assumes only that @xmath42 is even , which provides the minimum possible restriction on the form of the resulting grps for any given bitlength .",
    "all such grps can therefore be implemented with code parametrised by the single variable @xmath42 , which may be beneficial for some applications .",
    "supposing that @xmath261 , then as with montgomery reduction , it is more efficient to reduce components not by @xmath144 as in  ( [ basic_mont1 ] ) and  ( [ basic_mont2 ] ) , but by @xmath115 sequentially @xmath247 times . in algorithm  [ alg : red1 ] each reduction therefore reduces the input s components by approximately @xmath262 bits .    the second reduction method as detailed in algorithm  [ alg : red2 ] is a specialisation of algorithm  [ alg : red1 ] .",
    "it assumes that @xmath263 for some @xmath264 , and each application of the reduction function reduces the input s components by approximately @xmath265 bits .",
    "algorithm  [ alg : red2 ] is potentially far more efficient than algorithm  [ alg : red1 ] , depending on the form of @xmath42 .",
    "ideally one should choose a @xmath42 for which @xmath266 so that two applications of the reduction function are sufficient in order to produce components of the desired size , which is minimal .",
    "in general for other values of @xmath265 a larger number of reductions may be needed , which we consider in  [ sec : stability ] . in constrast",
    "to algorithm  [ alg : red1 ] , which is designed for generality , algorithm  [ alg : red2 ] is geared towards high - speed reduction .",
    "the trade - off arising here is that there will naturally be far fewer grps of this restricted form .",
    "we also present a modification of algorithm  [ alg : red2 ] , which is slightly more efficient in practice , in algorithm  [ alg : red3 ] .      following  [ subsec : montlattice ] , in equation  ( [ basic_mont1 ] ) we need the matrix @xmath267 : @xmath268.\\ ] ] the form of @xmath155 and @xmath267 allows one to compute @xmath269 and @xmath270 , computed in equation  ( [ basic_mont2 ] ) , very efficiently .",
    "since @xmath42 is even , the following vector may be computed .",
    "let @xmath271 $ ] be the least significant digit of @xmath42 , written in base @xmath115 , and let @xmath272^{m+1}-1}[t[0]^{m } , t[0]^{m-1},\\ldots , t[0],1 ] \\bmod b.\\ ] ] algorithm  [ alg : red1 ] details how to reduce a given an input vector @xmath104 by @xmath115 , modulo @xmath110 , given the precomputed vector @xmath273 .",
    "observe that algorithm  [ alg : red1 ] greatly simplifies the reduction algorithm originally given in  @xcite .",
    "this is possible since for @xmath110 one can interleave the computation of the vectors @xmath107 and @xmath105 defined in  ( [ basic_mont1 ] ) and  ( [ basic_mont2 ] ) respectively .",
    "this has two benefits .",
    "first , as one computes each component of @xmath105 sequentially , one need only store a single component of @xmath107 , rather than @xmath60 .",
    "second , since when one computes @xmath270 one needs to compute @xmath274 for @xmath275 ( in line 3 ) , one obtains @xmath271 \\cdot u_i$ ] ( the first term on right - hand side of line 4 ) for free by computing the full product @xmath276 first . one therefore avoids recomputing the least significant digit of @xmath276 in each loop iteration .",
    "in fact one can do this for    @xmath277 @xmath241 \\in { \\mathbb{z}}^{m+1}$ ] @xmath278 where @xmath279 [ alg : red1 ] ' .set @xmath280 ) \\bmod b$ ] +   ' .for @xmath243 to @xmath244 do : + ' .@xmath281 + ' .@xmath282 - z_{i}[0 ] ) \\bmod b$ ] + ' .@xmath283 +   ' .return @xmath105    any polynomial @xmath284 , with exactly the same algorithm , the only difference being in the definition of @xmath273 , where @xmath285 becomes the denominator . for polynomials with other non - zero coefficients ,",
    "this does not seem possible , and so algorithm  [ alg : red1 ] seems likely to be the most efficient chung - hasan reduction possible with this minimal restriction on the form of @xmath42 .",
    "it is straightforward to verify that algorithm  [ alg : red1 ] correctly produces an output vector in the correct congruency class , via a sequence of simple transformations of  ( * ? ? ?",
    "* algorithm 3 ) .",
    "however we do not do so here , since we are mainly interested in the more efficient algorithms  [ alg : red2 ] and  [ alg : red3 ] .",
    "note that in the final loop iteration , @xmath286 from line 1 is recomputed , which is therefore unnecessary .",
    "however , we chose to write the algorithm in this form to emphasise its cyclic structure . indeed , there is no need to compute @xmath286 first ; if one cyclically rotates @xmath273 by @xmath287 places to the left , then the vector @xmath105 to be added to @xmath104 in  ( [ basic_mont2 ] ) is rotated @xmath287 places to the left also .",
    "one can therefore compute each coefficient of @xmath288 independently of the others using a rotated definition for @xmath273 ( or equivalently by rotating the input @xmath104 ) .",
    "this demonstrates that a parallelised version of the reduction algorithm with @xmath60 processors is feasible .",
    "however , as each processor requires the least significant word of each component of @xmath104 , this necessitates a synchronised broadcast before each invocation of the reduction function . in this scenario",
    "the reduction time would be proportional to the number of such broadcasts and reductions required , independently of @xmath60 .",
    "in the ideal case that @xmath290 , we see that such a grp would be a gmn . in this case",
    ", one can use the reduction method detailed in  [ subsec : latticereduction ] without resorting to using its montgomery version at all .",
    "multiplication would also be faster thanks to nogami s formulae .",
    "unfortunately , such grps seem to be very rare .",
    "it is easy to show that if @xmath291 with @xmath292 and @xmath293 is prime , then @xmath294 .",
    "testing the first few cases , we find prime grps for @xmath295 but no others for prime @xmath296 .",
    "note that these primes contradict dubner s assertion that no such grps exist  @xcite . since for @xmath297 the corresponding grp has @xmath298 bits , this is already out of our target range for ecc , so we need not worry about such grps .",
    "hoping not to cause confusion , in this subsection we now let @xmath299 where @xmath265 is not necessarily and usually not the word size of the target architecture . we denote the cofactor of @xmath115 in @xmath42 by @xmath300 ( which by the above discussion we assume is @xmath301 ) , so that @xmath302 . algorithm  [ alg : red2 ] details how to reduce a given an input vector @xmath104 by @xmath115 , modulo @xmath110 .",
    "@xmath303 @xmath241 \\in { \\mathbb{z}}^{m+1}$ ] @xmath278 where @xmath304 [ alg : red2 ] ' .for @xmath243 to @xmath244 do : + ' . @xmath305",
    "+   ' .return @xmath105",
    "a simple proof of correctness of algorithm  [ alg : red2 ] comes from the specialisation of algorithm  [ alg : red1 ] .",
    "since @xmath306 , writing @xmath42 in base @xmath115 , the vector @xmath273 becomes @xmath307 \\bmod b.\\ ] ] hence for line 1 of algorithm  [ alg : red1 ] we have @xmath308 \\bmod{b}.\\ ] ] since in line 4 of algorithm  [ alg : red1 ] , we have @xmath309 , we deduce that @xmath310 , and hence we can eliminate @xmath311 altogether .",
    "each loop iteration then simplifies to @xmath312 upon expanding  ( [ linez ] ) , we obtain @xmath313 as required .",
    "however since we did not provide a proof of correctness of algorithm  [ alg : red1 ] , we also give a direct proof as follows .",
    "observe that modulo @xmath91 , we have @xmath314t^i\\\\ \\nonumber & \\equiv & \\sum_{i=0}^{m } ( z_i / b)t^i   + \\sum_{i=0}^{m } ( -z_i \\bmod{b}))/b)t^i - \\sum_{i=0}^{m } ( ( -z_{\\langle i+1 \\rangle } \\bmod{b})/b)t^{i+1}\\\\ \\nonumber & \\equiv & \\sum_{i=0}^{m}z_it^i / b \\pmod{t^{m+1}-1}\\end{aligned}\\ ] ] as required . in terms of operations that may be performed very efficiently , we alter algorithm  [ alg : red2 ] slightly to give algorithm  [ alg : red3 ] , which has virtually the same proof of correctness as the one just given .",
    "@xmath315 @xmath241 \\in { \\mathbb{z}}^{m+1}$ ] @xmath278 where @xmath304 [ alg : red3 ] '",
    ".for @xmath243 to @xmath244 do : + ' . @xmath316 +   ' .return @xmath105    note that the first term in line 2 of algorithm  [ alg : red2 ] has been replaced by a division by @xmath115 , which can be effected as a simple shift , while now the second term needs the positive residue modulo @xmath115 , which can be extracted more efficiently . hence algorithm  [ alg : red3 ] is the one we use . by our previous discussion",
    ", @xmath300 necessarily has hamming weight at least two for grps in our desired range . by using @xmath300 that have very low hamming weight , one can effect the multiplication by @xmath300 by shifts and adds , rather than a multiply ( or imulq ) instruction .",
    "hence for such grps , assuming only two invocations of algorithm  [ alg : red3 ] are needed , reduction will be extremely efficient .",
    "regarding parallelisation , observe that for @xmath60 processors , only the least significant word of @xmath317 is passed to processor @xmath318 , thus reducing the broadcast requirement in comparison with algorithm  [ alg : red1 ] .",
    "so far in our treatment of both multiplication and reduction , for the sake of generality we have assumed arbitrary precision when representing grp residues in @xmath98 . in this section",
    "we specialise to fixed precision and develop a residue representation that ensures that our chosen algorithms are efficient .",
    "our decisions are informed purely by our chosen multiplication and reduction algorithms  algorithms  [ alg : mrcpmul ] and  [ alg : red3 ]  which we believe offer the best performance for grps for the relatively small bitlengths which are relevant to ecc . in other scenarios or if considering asymptotic performance , one would need to redesign the residue representation and multiplication algorithm accordingly .",
    "for @xmath319 we write @xmath97 $ ] for its base-@xmath42 expansion , i.e. , @xmath320 .",
    "the base-@xmath42 representation has positive coefficients , however algorithm  [ alg : mrcpmul ] makes use of negative coefficients , so we prefer to incorporate these . we therefore replace the mod function in the conversion with mods , the least absolute residue function , to obtain a residue in the interval @xmath321 $ ] : @xmath322 using this function , algorithm  [ alg : map2poly ] converts residues modulo @xmath91 into the required form  ( * ? ? ?",
    "* algorithm 1 ) .",
    "base-@xmath42 conversion @xmath90 an integer @xmath323 @xmath324 $ ] such that @xmath325 + and @xmath326[alg : map2poly ]",
    "+   ' .for @xmath318 from @xmath244 to @xmath62 do : + ' .@xmath327 + ' .@xmath328 +   ' .@xmath329 +   ' .return @xmath97 $ ]    the reason for line 4 in algorithm  [ alg : map2poly ] is to reduce modulo @xmath91 the coefficient of @xmath330 possibly arising in the expansion .",
    "note that in this addition , @xmath331 , and hence @xmath325 for each @xmath190 . by construction",
    ", we in fact have @xmath332 for @xmath333 while only @xmath199 can attain the upper bound of @xmath334 .",
    "there are therefore @xmath335 representatives in this format , thus introducing a very small additional redundancy .",
    "letting @xmath336 , if we assume @xmath337 , so that @xmath338 \\subset [ -2^k/2,2^k/2 - 1]$ ] , then the coefficients as computed above can be represented in two s complement in @xmath7 bits . in terms of efficiency ,",
    "algorithm  [ alg : map2poly ] contains divisions by @xmath42 , which requires not only time , but also space , which on some platforms may be at a premium . writing @xmath339 as in  [ sec : redfast ] , then if the cofactor @xmath340 with @xmath341 very small , then division by @xmath42 consists of a shift right by @xmath265 bits and a division by @xmath300 , which can be performed efficiently using algorithm 1 of  @xcite .",
    "following this conversion , it might seem desirable to define vectors whose components are in @xmath342 $ ] to be reduced , or canonical residue representatives .",
    "however , for efficiency purposes it is preferable to have a reduction function which , when performed sufficiently many times , outputs an element for which one does not have to perform any modular additions or subtractions to make reduced , as this eliminates data - dependent branching .",
    "a control - flow invariant reduction function is also essential to defend against side - channel attacks , see  [ sec : otherops ] . to obtain such a function , observe that the second term in line 2 of algorithm  [ alg : red3 ] , namely @xmath343 , is positive , and in the worst case is @xmath7 bits long .",
    "the first term , @xmath344 , is clearly @xmath345 bits shorter than @xmath255 .",
    "since one adds these the resulting value may be @xmath346 bits , or larger , depending on the initial length of the inputs components . furthermore , since we wish to allow negative components , in two s complement the output requires a further bit , giving a minimal requirement of @xmath347 bits .",
    "we therefore choose not to use minimally reduced elements as coset representatives in @xmath103 , as output by algorithm  [ alg : map2poly ] , but slightly larger elements , which we now define .",
    "we define the following set of elements of @xmath98 to be _ reduced _ : @xmath348 \\in { \\mathbb{z}}^{m+1 } \\mid - 2^{k+1 } \\leq x_i < 2^{k+1}\\}.\\ ] ]    note that the redundancy inherent in this representation depends on how close @xmath42 is to @xmath349 . for a modular multiplication",
    ", we assume that the inputs are reduced .",
    "we must therefore ensure that the output is reduced also .",
    "this naturally leads one to consider i / o stability , as we do in  [ sec : stability ] .",
    "once we have a reduced representative @xmath350 we also need to convert to the montgomery domain . while one can do this in @xmath89 before applying @xmath90 , it is more convenient to do so in @xmath103 . assuming @xmath247 reductions by @xmath115 are sufficient to ensure i / o modular multiplication stability , we precompute @xmath351 and then using algorithms  [ alg : mrcpmul ] and  [ alg : red3 ] compute @xmath352 similarly , to get back from the montgomery domain , again using algorithms  [ alg : mrcpmul ] and  [ alg : red3 ] , we compute @xmath353 with regard to mapping back from @xmath97 \\in { \\mathbb{i}}^{m+1}$ ] to canonical residues in @xmath354 , one has @xmath355 which can be computed efficiently by first using horner s rule and then mapped to @xmath356 by repeated additions or subtractions . in terms of operations required for ecc ,",
    "we assume that the conversions are one - time computations only , with all other operations taking place in the ( montgomery ) chung - hasan representation .",
    "in this section we analyse algorithms  [ alg : mrcpmul ] and  [ alg : red3 ] with a view to ensuring i / o stability for modular multiplication .",
    "we assume the following : @xmath299 , @xmath357 where @xmath358 ( and hence @xmath359 ) , and that reduced elements have the form  ( [ reduced ] ) .",
    "input elements therefore have components in @xmath360 $ ] , and these are representable in @xmath347 bits in two s complement . for simplicity and in order for our analysis to be as general as possible , we use the term single precision to mean a word base large enough to contain @xmath42  even if this in fact requires multiprecision on a given architecture  and double precision to mean twice this size .",
    "we assume that for this single precision word size @xmath361 , the components of @xmath104 output by algorithm  [ alg : mrcpmul ] are double precision . in practice one",
    "prefers to specialise to actual single precision @xmath42 on a given architecture , since this obviates the need for multiprecision arithmetic ; utilising the native double precision multipliers that most cpus possess is more efficient , and reduction is also faster for smaller @xmath42 since fewer iterations need be performed .",
    "we note that in constrained environments however , multiprecision may however be unavoidable .    during the multiplication , terms of the form @xmath362",
    "are computed , which are bounded by @xmath363 and which therefore fit into @xmath364 bits in two s complement .",
    "the product of two such elements is performed , giving a result @xmath365 which fits into @xmath366 bits in two s complement .",
    "one then adds @xmath367 of these terms , giving a possible expansion of up to @xmath368 bits , which must be double precision .",
    "we therefore have a constraint on the size of @xmath42 ( in addition to the constraint @xmath359 ) in terms of @xmath62 : @xmath369 this inequality determines a constraint on the size of @xmath42 , given @xmath62 and @xmath361 .",
    "assuming  ( [ constraint ] ) is satisfied , one then needs to find the minimum value of @xmath370 such that the result of the multiplication step , when reduced by @xmath115 a specified number of times , say @xmath247 , outputs a reduced element .",
    "this needs to be done for each @xmath371 found in the procedure above .",
    "any power of @xmath53 larger than this minimum will obviously be satisfactory also , however minimising @xmath115 maximises the set of prime - producing cofactors @xmath300 , which as stated in ",
    "[ sec : reduction ] may be useful in some scenarios .    in   [ sec : representation ] , we showed that one application of algorithm  [ alg : red3 ] shortened an input s components by @xmath372 bits , unless the components were already shorter than @xmath373 bits . therefore stipulating that @xmath247 reductions suffice to produce a reduced output , we obtain a bound on @xmath265 in the following manner .",
    "let @xmath374 then after one reduction , the maximum length of a component is @xmath375 .",
    "similarly after @xmath247 reductions , the maximum length is @xmath376 , and we need this to be at most @xmath347 .",
    "hence our desired condition is @xmath377 solving for @xmath265 , we have @xmath378    using these inequalities it is an easy matter to generate triples @xmath379 which ensure multiplication stability for any @xmath361 and @xmath247 .",
    "for example , for @xmath380 , tables  [ stableparameters1 ] and  [ stableparameters2 ] give sets of stable parameters for @xmath381 and @xmath382 respectively .",
    ".stable parameters : @xmath380 , @xmath381 [ cols=\"^,^,^,^,^\",options=\"header \" , ]     as stated in ",
    "[ estimateparams ] , the closest size of field to curve25519 that we can implement using @xmath383 is only @xmath384-bits .",
    "this small reduction in field size is compensated by an increase in performance , requiring only @xmath385 of the curve25519 cycles per multiplication . using the specialised reduction function for the @xmath386-bit grp @xmath387",
    ", this figure improves to @xmath388 .",
    "since the results for the first line of table  [ mrcp ] apply also to hamming weight @xmath53 grps smaller than @xmath389 , we obtain the same modular multiplication performance , while utilising the acquired slack in the representation to ensure atomic point doublings / additions as per  [ sec : secure ] , in particular for the @xmath390-bit grp @xmath391 . at bitlength @xmath392 with general @xmath300 ,",
    "compared to montgomery multiplication , grp multiplication costs only @xmath393 as many cycles . at bitlength @xmath394 , this proportion would naturally be even smaller , however at this size karatsuba multiplication may be faster than schoolbook arithmetic .",
    "we thus expect that point multiplications at @xmath395-bits and @xmath392-bits using grps to be competitive with the state - of - the - art in the literature .",
    "we freely admit that our proof - of concept implementation has not been optimised , and therefore believe that one could obtain significantly better performance figures . by comparing our arithmetic with the modular multiplication used in  @xcite , which is the benchmark for point multiplication at the @xmath396-bit security level , one gains an idea of the potential performance of arithmetic mod @xmath391 for example . in  @xcite , residues are also represented by five @xmath397-bit words .",
    "residue multiplication requires @xmath398 mul instructions , as well as some imul , add and adc instructions . in comparison , to multiply @xmath180 and @xmath181 in our representation , the cvma formulae are as follows : @xmath399 requiring only @xmath400 mul , @xmath398 add and @xmath401 adc instructions .",
    "since the respective reduction algorithms are quite similar with both requiring two rounds of shifts , masks and additions , one expects the grp modular multiplication to be considerably faster , when optimsed .",
    "it is also possible that an optimised implementation of multiplication mod the @xmath402 grps listed in table  [ fastparams ] may be faster than  @xcite , since it requires @xmath403 mul instructions , rather than @xmath398 .",
    "however , since this paper is predominantly expositional , we leave such optimisations as open research .",
    "we have proposed efficient algorithms for performing arithmetic modulo a large family of primes , namely the generalised repunit primes .",
    "the algorithms are simple to implement , are fast , are easily parallelisable , can be made side - channel secure , and all across a wide range of field sizes .",
    "the central contribution of this work is the development of the necessary theory , covering field and residue representation , as well as novel algorithms for performing efficient multiplication and reduction in these fields .",
    "we have also presented proof - of - concept implementation results which provide an empirical comparison with other results in the literature , ensuring a fair comparison by reusing the same benchmarking procedure . against montgomery arithmetic",
    "we show an approximate three - fold increase in performance , and expect optimised implementations of point multiplications using our proposed family to be competitive with the state - of - the - art in the literature .",
    "we thus present a compelling argument in favour of a new approach to the secure and efficient implementation of ecc .",
    "the authors would like to thank dan page for making several very useful comments and suggestions , and the referees for their comments .",
    "p. barrett . implementing the rivest shamir and adleman public key encryption algorithm on a standard digital signal processor , in _ advances in cryptology ",
    "crypto 86 _ springer - verlag , lncs 263 , 311323 , 1987",
    ".      d.j .",
    "bernstein . a software implementation of nist p-224 .",
    "presentation at the 5th workshop on elliptic curve cryptography ( ecc 2001 ) , university of waterloo , october 29 - 31 , 2001 .",
    "slides available from http://cr.yp.to/talks.html .",
    "blake , r.m .",
    "roth and g. seroussi .",
    "efficient arithmetic in @xmath404 through palindromic representation .",
    "technical report hpl-98 - 134 , 1998 .",
    "available from http://www.hpl.hp.com/techreports/98/hpl-98-134.html .",
    "g. hachez and j.j .",
    "montgomery exponentiation with no final subtractions : improved results . in _ cryptographic hardware and embedded systems ( ches ) _ , springer - verlag lncs 1965 , pp .",
    "293301 , 2000 .",
    "d. hankerson , a. menezes , and s. vanstone .",
    "software implementation of pairings technical report available from http://www.cacr.math.uwaterloo.ca http://citeseer.ist.psu.edu[http://www.cacr.math.uwaterloo.ca http://citeseer.ist.psu.edu ]          j. jonsson and b. kaliski .",
    "public - key cryptography standards ( pkcs ) # 1 : rsa cryptography specification version 2.1 http://citeseer.ist.psu.edu/jonsson03publickey.html [ http://citeseer.ist.psu.edu/jonsson03publickey.html ]                s. kwon , c.h .",
    "kim and c.p .",
    "gauss period , sparse polynomial , redundant basis , and efficient exponentiation for a class of finite fields with small characteristic . in _",
    "isaac 2003 _ , lncs 2906 , pp . 736745 , 2003 .",
    "y. nogami , a. saito , and y. morikawa .",
    "finite extension field with modulus of all - one polynomial and representation of its elements for fast arithmetic operations . in _",
    "ieice transactions on fundamentals of electronics , communications and computer sciences _",
    "vol.e86-a no.9 , 23762387 , 2003 .          y. sakai and k. sakurai",
    ". simple power analysis on fast modular reduction with generalized mersenne prime for elliptic curve cryptosystems . in _",
    "ieice transactions - ieice _ ,",
    "89-a , no .",
    "1 , pp . 231237 , 2006 .",
    "generalized mersenne numbers . technical report corr-39 , dept . of c&o ,",
    "university of waterloo , 1999 .",
    "available from http://www.cacr.math.uwaterloo.ca http://citeseer.ist.psu.edu/solinas99generalized.html[http://www.cacr.math.uwaterloo.ca http://citeseer.ist.psu.edu/solinas99generalized.html ]"
  ],
  "abstract_text": [
    "<S> generalised mersenne numbers ( gmns ) were defined by solinas in 1999 and feature in the nist ( fips 186 - 2 ) and secg standards for use in elliptic curve cryptography . </S>",
    "<S> their form is such that modular reduction is extremely efficient , thus making them an attractive choice for modular multiplication implementation . </S>",
    "<S> however , the issue of residue multiplication efficiency seems to have been overlooked . </S>",
    "<S> asymptotically , using a cyclic rather than a linear convolution , residue multiplication modulo a mersenne number is twice as fast as integer multiplication ; this property does not hold for prime gmns , unless they are of mersenne s form . in this work </S>",
    "<S> we exploit an alternative generalisation of mersenne numbers for which an analogue of the above property  and hence the same efficiency ratio  holds , even at bitlengths for which schoolbook multiplication is optimal , while also maintaining very efficient reduction </S>",
    "<S> . moreover , our proposed primes are abundant at any bitlength , whereas gmns are extremely rare . </S>",
    "<S> our multiplication and reduction algorithms can also be easily parallelised , making our arithmetic particularly suitable for hardware implementation . </S>",
    "<S> furthermore , the field representation we propose also naturally protects against side - channel attacks , including timing attacks , simple power analysis and differential power analysis , which is essential in many cryptographic scenarios , in constrast to gmns . </S>"
  ]
}