{
  "article_text": [
    "animal life is characterized by the emergence of robust control mechanisms used in a large variety of environments . beyond evolution which selects the life forms which make the most of their environment",
    ", it seems that some animals have the ability to quickly learn to interact constructively with new environments .",
    "most probably , it means that the nervous systems of such animals can perform a sort of blind control of their environments : control is achieved without previous knowledge of the environment .",
    "it would surely be of great help to uncover such a mechanism , not only from a biological viewpoint , but also to replicate it for engineering tasks .",
    "control theory has been a vivid field of research for decades which has provided many useful applications .",
    "however , although linear systems are well understood @xcite , non - linear systems still require a significant effort to be dealt with @xcite .",
    "in particular , the control system is often assumed to have some explicit knowledge about the system to be controlled .",
    "a recent axis of research focuses on design of control schemes when there is a lot a uncertainties about the system to be controled @xcite .",
    "when nothing is known about the system to be controlled , the most widespread method is to use a proportional - integral - derivative controller @xcite , although some sophisticated methods have been proposed , see @xcite for a review . indeed ,",
    "computing the best inverse model @xcite from an unknown environment is a very difficult task which has received no universal answer so far .",
    "neural networks are bio - inspired mathematical object which have good learning capacities @xcite .",
    "a large number of control algorithms have used their adaptability to model some aspect of the environment and / or to design adaptive controllers .",
    "the challenge is to be able to internally predict the outcomes of a potential movement so that the best motor commands can be chosen @xcite .",
    "typically , neural networks are used for two purposes : identification of the environment and the actual control which can be computed once a good estimate of the environment has been designed @xcite .",
    "a main drawback of feedforward neural networks is their inability to take time dependencies into account .",
    "although the usual work - around is to use tapped delay lines , a more natural approach would be to use recurrent neural networks ( rnn ) which are more suited to dynamical systems approximation .",
    "based on the two steps of identification and control , various rnn have been proposed as controllers e.g. @xcite . however , rnn learning is notoriously known to be slow and to be subject to problematic bifurcations @xcite . to circumvent this problem recent algorithms @xcite have been based on a reservoir computing architecture and more precisely echo state networks ( esn ) .",
    "they are recurrent networks where only the read - out form a random reservoir of neurons is learned @xcite . in these networks , the slow convergence and",
    "the bifurcation issues due to the tuning of the weights are bypassed .",
    "however , efficient optimization procedures for the hyper parameters and the overall mathematical understanding of esns are still lacking .",
    "nonetheless , esn have proved to be very good at handling time dependencies and at predicting time series @xcite .",
    "therefore , they provide a solid basis upon which this paper will design a novel control architecture .",
    "most neural networks for control used so far have been based on two networks : one for the estimation of the state of the environment ( which can be called perception ) , and another for the design of the control ( which can be called action ) . in this paper , i will introduce a somewhat different architecture , since it will only be made of a single recurrent neural network from which two read - outs are drawn and fed back .",
    "this is actually a fundamental feature of the approach , which resonates with the field of psychology called ideomotor theory @xcite .",
    "this theory argues that perception and action are tightly linked and even represented in a single `` domain '' .",
    "more precisely a fundamental concept is that actions do not aim at changing the world directly , they rather aim at changing the perception of the world .",
    "thus action and perception are deeply entangled and one could say that when the neural network `` thinks '' or predicts a future for its stimuli , then the corresponding action follows @xcite . in a way , the active inference perspective presented by friston and colleagues @xcite could be regarded as a modern theory compatible with ideomotor approach , where the underlying imperative for both action and perception is to minimise prediction errors ( or variational free energy ) .",
    "alternatively , the conceptual difference from traditional feedback loop algorithms can be seen in the structure of the controller in figure [ fig : setup ] : at the level of the controller information flows in both directions , what is usually called the output of the controller is also fed - back to the central network .    in this paper , i introduce an ideomotor recurrent neural network ( idrnn ) together with a learning procedure in order to control an unknown environment .",
    "this paper intends to be a proof of concept that such a neural network can successfully learn to control fairly complicated dynamical systems . in section [ sec : model ] , i introduce the network and the notations .",
    "section [ sec : ideomotor principles ] will be devoted to explaining the computational principles underlying ideomotor learning and section [ sec : algo ] describes the corresponding algorithm .",
    "numerical experiments for various environments and a short comparison with the esn based method in @xcite will be presented in section [ sec : numerical simus ] .",
    "finally , i will discuss the properties of such neural networks , in particular their biological plausibility , in section [ sec : discussion ] .",
    "the model details the dynamics of a recurrent neural networks interacting with an unknown environment .",
    "the way the environment interacts with the agent ( through sensors and actuators ) is also formally unknown .",
    "it is the role of the agent to understand this interaction through statistical observations .",
    "* notations and conventions * : several elements of the neural network and the environment are time - dependent multidimensional functions which will be written with lower - case bold letters , e.g. @xmath0 . the value of these functions at time @xmath1 will be written as an index to the function s notation , e.g. @xmath2 .",
    "most of these functions will be described by recurrence equations which are assumed to start from @xmath3 ( for negative time the functions return zero ) .",
    "the matrices are written in upper case bold , e.g. @xmath4 .",
    "we now detail the different parts of the neural network and the environment :    * * environment * : + the environment possibly has a complicated non - linear and/or stochastic dynamics which we know nothing about . from the controller perspective , only some measures of the environment state are known .",
    "they are sometimes called observations but we refer to them as _ stimuli _ not to confuse them with the states of the reservoir which could also be called observations in the framework of online least mean square problems .",
    "+ the @xmath5 neurons of the perceptive area receive information from the environment through the input vector @xmath6 at time @xmath7 ( where @xmath5 is the dimension of the perceptive area ) . * * network activity * : + we assume the controller is made of a neural network , which is decomposed in three parts : a _ perceptive area _ , a _ reservoir _ and a _ motor area _",
    "see , figure [ fig : setup ] . the variables describing the activity of these subsets of the neural network are respectively @xmath8 called _ perception _ , @xmath9 called _ reservoir states _ and @xmath10 called _ action _ , where @xmath11 are the number of neurons in the respective area . note that the letters p , r , a will always stand for perceptive area , reservoir and motor area respectively .",
    "we also define the variable gathering the entire network activity : @xmath12 .",
    "+ the full connectivity matrix of the network is @xmath13 where the second superscript ( e.g. b in @xmath14 ) is the origin of the connection and the first superscript ( e.g. a in @xmath14 ) is the destination , consistently with usual matrix notations . note that the structure of @xmath4 means that there are no connections between and within the perceptive and motor areas .",
    "+ we also define @xmath15 corresponding to all the connections to the reservoir . + a main idea in echo state networks @xcite from which this work is inspired , it that the connections within and to the reservoir are randomly drawn .",
    "this means that the components of @xmath16 , @xmath17 and @xmath18 are i.i.d .",
    "constants along @xmath19 , @xmath20 and @xmath21 .",
    "albeit surprising , this choice leads to relevant prediction results and cheap algorithms .",
    "+ for simplicity , perception and action are considered to be linearly related to the reservoir activity .",
    "the reservoir follows a leaky integrator neural network equation @xcite , where a time constant @xmath22 controls the speed of the dynamics .",
    "note that the contributions from perceptive and motor areas to the reservoir dynamics are linear ( which will be important in the following ) .",
    "the perceptive area is stimulated by a weighted mean between the stimuli and the current prediction of the network . with the notations introduced before",
    ", this reads @xmath23 where @xmath24 is an element - wise sigmoidal function , @xmath25 is a decay constant and @xmath26 $ ] balances the contribution two terms : the stimuli @xmath27 and the term @xmath28 which we call",
    "_ prediction_. note that if prediction and stimuli are identical then the perception @xmath29 becomes the same as the stimuli . *",
    "* target trajectory * : + the role of the neural network is to control the environment so that it follows a _ target _",
    "trajectory which we write @xmath30 , where @xmath31 .",
    "the target corresponds to ( at least ) one neuron in the perceptive area : if learning is successful , the stimuli to this subset of the perceptive neurons will be driven along the target trajectory . in the present formalism , the neural network can only control its stimuli ( as opposed to an unobserved environment state ) . * * learning * corresponds to tuning the connections in the network .",
    "we assume that not all the connections are learnable : only the connections in red in figure [ fig : setup ] are learnable .",
    "in other words , and in a reservoir computing spirit , the connections to and within the reservoir @xmath32 are fixed .",
    "we call _ perceptive learning _ the tuning of the connectivity @xmath33 and _ motor learning _",
    "the tuning of the connectivity @xmath34 .",
    "in this paper , ideomotor learning is defined by the combination of two principles : ( i ) perceptive learning aims at minimizing the distance between internal predictions @xmath35 and stimuli @xmath27 , and , ( ii ) motor learning aims at minimizing the distance between internal predictions @xmath35 and target @xmath36 .",
    "a control task is said to be successful when stimuli and target are equal .",
    "this can be a difficult task to achieve , in particular when the environment is unknown .",
    "the idea behind ideomotor learning is that having a good predictor of the stimuli may help designing an intelligent control . a controller which would be able to faithfully reproduce the stimuli , without needing to `` see '' them ,",
    "would also know how to perturb the environment to reach a desired target .",
    "this idea is very similar to the good regulator hypothesis ( every controller of its environment must possess a model of that environment ) that underpins early work in self - organisation and cybernetics @xcite ) .",
    "therefore , one needs to learn a model of the world ( principle ( i ) above ) and , at the same time , make sure this model is going in the desired direction ( principle ( ii ) above ) .",
    "more formally , ideomotor learning can be seen as adding a third variable , the prediction , in the distance between stimuli and target and using the triangular inequality to break the minimization of this distance into two sub - tasks .",
    "the fact that motor learning makes no reference to the stimuli @xmath27 has important functional consequences . indeed",
    ", the actions exclusively aims at modifying the reservoir dynamics so that the perception matches the target . the impact on the actions on the world and the stimuli",
    "@xmath27 is simply a byproduct of the method .",
    "in fact , the actions only want to control the internal model of the world that perceptive learning tries to build .",
    "mathematically , it is possible to formalise the two principles of ideomotor learning as the minimisation of prediction errors by perception and action respectively : @xmath37 where @xmath38 is a solution of system defined for given @xmath33 and @xmath34 .",
    "the matrix @xmath39 is the restriction of the perceptive matrix @xmath33 to the dimensions which are to be controlled along the trajectory @xmath40 , ( i.e. to create @xmath41 some rows of @xmath33 have been removed ) .",
    "if learning is perfect , i.e. both sums in are @xmath42 for all @xmath1 such that @xmath43 is on a limit cycle , then it is clear that the task is reached : @xmath44 .",
    "we restrict our analysis to the case where such a limit cycle exists ( which typically excludes non - controllable , non - observable environments ) .",
    "note that equation effectively computes a path integral or time average of squared prediction error or free energy . as such , equation expresses a principle of least action ; where action is the time average of energy .",
    "designing an online algorithm reaching this limit cycle reveals a fundamental problem : at time step @xmath1 the network has to figure out new matrices @xmath33 and @xmath34 based on the potential impact they would have had in the past .",
    "but it can not really know what this impact would have been since it would need to re - experience the past with these new matrices .",
    "this is impossible since the network has to update the matrices exclusively based on the available quantities .",
    "another way to see this is to observe that the values of @xmath45 and @xmath46 depend on @xmath33 and @xmath34 , and , therefore , learning is not a simple least square problem , where observations @xmath46 and target @xmath45 are independent weight vector .",
    "however , simple greedy algorithms can , in certain cases , converge to a perfect solution .",
    "a greedy algorithm roughly ignores the dependencies of @xmath45 and @xmath46 on @xmath33 and @xmath34 , and corresponds to using a traditional least square approach for learning .",
    "this is the approach we take in the rest of the paper .",
    "this is formally similar to the mean field approximation that is used in variational formulations of active inference ; in other words , minimizing prediction errors under the assumption of conditional independence between the unknown states ( and parameters ) .",
    "in this paper , a greedy recursive least square ( rls ) approach to solve the least square problems is considered .",
    "it corresponds to dynamically updating the connections based on a rls algorithm performing the online minimization of the following problem : @xmath47 where @xmath48 $ ] are forgetting factors and @xmath27 and @xmath49 are the solution of system with time dependent connection matrices @xmath50 and @xmath51 .",
    "if @xmath52 is close to @xmath42 , then the sum simply involves very recent observations .",
    "the additional terms involving the squared norm of @xmath33 and @xmath34 correspond to the usual tikhonov regularization and the numbers @xmath53 control the amount of regularization .",
    "the notation @xmath54 is the pseudoinverse of @xmath55 .",
    "the slight modification of the motor criterion in due to the inversion of @xmath56 simply corresponds to taking a different norm for the minimization .",
    "it is necessary to turn motor learning into a classical weighted least square problem .",
    "indeed , one can unravel the dynamics of the reservoir for one time step to let the connection explicitly appear in the criterion .",
    "this corresponds to injecting the first row of into @xmath57 which leads to @xmath58 where @xmath59 . as a consequence",
    ", @xmath57 appears as a linear function of @xmath34 which will make it possible to use classical algorithms for minimization .",
    "note that the particular dynamics of the reservoir in was chosen such that such a linear problem would appear .",
    "it also explains why we can not unravel the dynamics for more time steps : the reformulation into a least square problem would be impossible . from this formulation , it becomes clear that pre - multiplying the factor @xmath57 by @xmath54 for the motor learning with the rls algorithm in equation is useful .",
    "indeed , motor learning becomes the minimization of @xmath60 which takes the form of a classic weighted least square problem which can directly be solved by a rls algorithm .",
    "note that matrix @xmath56 has the size of the number of controlled dimensions ( spatial dimension of the target ) times the number of dimension for action , which is likely to be small enough to enable a computationally cheap inversion at each time step .",
    "the greedy rls algorithm consists in implementing with a rls algorithm which quickly forgets the past .",
    "indeed , to circumvent the dependency of @xmath27 and @xmath35 on @xmath34 the choice of the forgetting factors @xmath61 is crucial .",
    "when the network starts from an uninformed state ( e.g. the null state ) , it is important for them to have small values , typically @xmath62 .",
    "a rule of thumb @xcite to tune them is that the memory of the algorithm roughly corresponds to @xmath63 time steps .",
    "[ [ the - regularized - rls - algo ] ] the regularized rls algo + + + + + + + + + + + + + + + + + + + + + + + +    is recalled in this paragraph .",
    "it is an algorithm which recursively solves the following generic problem @xmath64 it can be solved by iterating the following regularized rls step @xcite as new targets @xmath65 and new observation @xmath66 arrive .",
    "this algorithm has already been successfully used for echo state networks @xcite . in this paper",
    ", we use a version of the algorithm with non - fading regularization @xcite , which provides good stability properties even when the forgetting factor @xmath52 is small .",
    "the algorithm corresponding to one step of the considered rls algorithm is given in algorithm [ alg : rls step ] .",
    "@xmath67 @xmath68 @xmath69 return @xmath70 , @xmath4    in this algorithm , @xmath71 is the inverse correlation matrix of the observations , which correspond to the reservoir activity in this paper .",
    "[ [ pseudo - code ] ] pseudo - code + + + + + + + + + + +    therefore , the algorithm summarizing the update of the greedy rls neural network is described in algorithm [ alg : full rls agent ] .",
    "@xmath72 initialization : @xmath73 @xmath74 @xmath75 @xmath72 main loop : # motor learning : @xmath76 @xmath77 # reservoir update : @xmath78 # perceptive learning : @xmath79 # perception and action update : @xmath80 @xmath81 is the action which controls the environment .",
    "in this section , i show on different examples that the proposed architecture can effectively control an unknown environment along a desired trajectory .",
    "it is important to realize that the following numerical simulations correspond to a neural network which learns to control the environment : at time @xmath82 the neural network has no clue about what system it is dealing with .",
    "thus the results are not to be compared to a classical control setup where the controller was previously tuned to the specific environment .      as toy models of the environment",
    ", i first choose randomly connected neural networks from which a linear read - out is to be controlled along a sinus function .",
    "it has been argued that this class of systems is very rich since it can approximate any dynamical system @xcite .",
    "i do not claim that the idrnn can control any such random neural network since they can become very complicated , but it performs well on reasonably complicated instances of such networks .",
    "i will consider neural networks made of @xmath83 neurons from which a one - dimensional linear readout is computed .",
    "the equation governing these driven random neural networks is : @xmath84 where matrix @xmath85 and the vectors @xmath86 have components which are drawn i.i.d .",
    "@xmath87 , @xmath88 and @xmath89 respectively .    with different choices of parameters",
    ", one can get very different resulting dynamics as shown in figures [ fig : rnn conv free ] , [ fig : rnn osc free ] , [ fig : rnn div free ] .",
    "even with identical parameters the different realizations of the connections can lead to qualitatively different dynamics .",
    "i chose three cases corresponding to converging ( figure [ fig : rnn conv ] ) , oscillatory ( figure [ fig : rnn osc ] ) and diverging ( figure [ fig : rnn div ] ) situations .",
    "for all the simulations , i chose the same parameters for the idrnn : @xmath90 , @xmath91 , @xmath92 , @xmath93 , @xmath94 , @xmath95 , @xmath96 , @xmath97 , @xmath98 , @xmath99 , @xmath100 , @xmath101 , @xmath102 .",
    "the motivation for the choice of @xmath103 and @xmath104 is to have a reservoir with spontaneous activity and no equilibrium point at @xmath105 when no stimulation comes in .",
    "the parameters of the environment are reported in the figures .",
    "in each situation , the very same neural network has managed to control qualitatively different environments it knew nothing about along the same trajectory @xmath106 . the @xmath107 error between stimuli and target over the last @xmath108 time steps ( corresponding to a period of the target )",
    "is respectively @xmath109 , @xmath110 and @xmath111 for converging , oscillatory and diverging situations , meaning that the control is successful .    in each case",
    ", the first few hundred time steps display an extremely variable behavior .",
    "the network has difficulties choosing relevant actions since its perception is not fully developed yet .",
    "although the variations look completely unstructured the network still manages to calm down and converges to the desired trajectory .",
    "unfortunately , this is not always the case : the search period can bring the environment to an undesired location in the state space leading to a failure of the control .",
    "for instance , controlling a quickly diverging environment ( not shown ) can fail when the environment diverges faster than the network can learn .",
    "the two important parameters to control the behavior of the network in the beginning are the initial values of @xmath33 and @xmath112 .",
    "if the value of @xmath113 is to small then the pseudo - inversion of @xmath56 in the algorithm can lead to extremely large control values in the very beginning of the simulation .",
    "similarly , choosing large initial values for @xmath114 or @xmath115 induces a large variability at the beginning of the simulation @xcite which can lead to poor results .",
    "observe in figure [ fig : rnn div contr ] that the hidden variables in the environment @xmath65 are not displayed . indeed , although the network is controlling properly the environment read - out @xmath27 it does not necessarily prevent these hidden variables from diverging .",
    "this leads to a numerical overflow in the simulation after a certain time and an increased variability due to numerical round - offs . to prevent",
    "this one would need to ask the idrnn to control also the states @xmath65 .",
    "actually , the idrnn in its current form fails at controlling delayed systems or even some instantaneous systems which for which the impact of an action may take some time steps to reveal itself .",
    "this is not a surprise since the network only tries to control what it happening from one time step to the other .",
    "a simple extension of the algorithm [ alg : full rls agent ] makes the idrnn able of controlling such delayed systems .",
    "the idea is to learn to predict the future of the stimuli at @xmath116 time steps with @xmath117 .",
    "this corresponds to adding a third readout matrix @xmath118 to the network in figure [ fig : setup ] .",
    "the predicted value @xmath119 should be a approximation of @xmath120 and is not fed back to the network . in practice ,",
    "learning such a future prediction matrix can be done by applying an rls algorithm to approximate @xmath45 based on the observation @xmath121 .",
    "this implies to store the history of the reservoir during @xmath122 time steps .",
    "once this prediction is set - up it suffices to replace @xmath41 by @xmath118 in algorithm [ alg : full rls agent ] .",
    "this leads to a delayed version of the idrnn detailed in algorithm [ alg : delayed rls agent ] which does have a time window similar to @xcite .",
    "@xmath72 initialization : @xmath123 @xmath124 @xmath125 @xmath72 main loop : # motor learning : @xmath126 @xmath77 # reservoir update : @xmath78 @xmath127 $ ] # perceptive learning : @xmath79 @xmath128 # perception , future and action update : @xmath80 @xmath129 is a proxy of the future inputs .",
    "@xmath81 is the action which controls the environment .    with this new algorithm , it is possible to control systems for which the instantaneous idrnn failed . here",
    "i consider two examples of such systems : first a linear oscillatory system with a single control variable and , second , a random neural network with delayed action .    in a first time",
    ", we consider the following environment to control @xmath130 this corresponds to a linear oscillatory system as shown in figure [ fig : linear osc free ] somewhat similar to the first system studied in @xcite .",
    "the negative terms on the diagonal compensate for the tendency of the euler algorithm to diverge when simulating linear systems and can be disregarded for the interpretation . actually , the difficulty to control the system comes from the control vector @xmath131 which is positive for both components . to understand intuitively the problem it is useful to see that one dimension is excitatory while the second is inhibitory .",
    "when the control variable only makes it possible to positively stimulate both dimensions , it is not clear what will be the situation in a few time steps : although the excitatory dimension is directly stimulated by the inputs , the inhibitory dimension will suppress this excitation ( even more since it is stimulated by the excitatory dimension ) . in the end",
    ", one needs to see a bit more in the future to understand the impact of the action .",
    "this is precisely why adding the time window @xmath122 to the prediction makes the task much more simple .",
    "indeed , the idrnn can effectively control the system as shown in figure [ fig : linear osc contr ] .",
    "the parameters used are the same as previously with the addition of @xmath132 , @xmath133 and @xmath134 .",
    "the second environment is governed by a random neural network as previously but with a delayed command : @xmath135 the parameters of the idrnn are identical to before except that @xmath136 , @xmath137 and @xmath138 which explains the great variability at the beginning of the simulation .    the control performed by the idrnn is displayed in figure [ fig : rnn del ] . although the control takes more time ( @xmath139 time steps instead of @xmath140 ) , it finally manages to bring the system along the desired trajectory .",
    "although an extensive comparison between the idrnn and the double reservoir architecture ( dra ) @xcite is beyond the scope of this paper , i show here that they perform similarly on the task of controlling a heating tank .    the system to control ,",
    "a heating tank , is the same as the second example in @xcite and the interested reader should refer to this paper for the implementation details ( i took the same parameters ) .",
    "briefly , the system is a non - linear state - delayed system where the delay depends on the action .",
    "it corresponds to controlling a heating tank whose input is a stream of cold water .",
    "the water is heated in the tank and is then channeled through a tube to a destination where the output temperature is measured . when the water throughput ( corresponding to the action @xmath141 ) is increased the output temperature decreases , but it takes less time to get out of the tube .",
    "it is shown in @xcite , that the dra outperforms another algorithm , called nepsac @xcite , on this task .    in this paper , there are two differences from the heating tank used in @xcite : first , the stimuli to the network are scaled to meet the networks dynamics .",
    "i take as input @xmath142 where @xmath143 is the output of the heating tank simulation .",
    "second , the target trajectory is different , see figure [ fig : target ] .",
    "it is much faster so that the results of the control algorithm do not look as good as in the original paper presenting the dra .",
    "i have not tried to tune the parameters to get the best results , since i only intended to show that both algorithm would perform similarly on this task with naive parameter tuning .    actually , the idrnn failed to control the system when it is randomly initialized .",
    "interestingly the dra could control the system although i did not use any babbling initialization as discussed in @xcite . to get good results with the idrnn i had to properly initialize the network .",
    "indeed , a useful property of the idrnn is its ability to be initialized along any prexisting control scheme .",
    "the initialization procedure consists in recording both perceptions and actions ( more commonly named inputs and outputs ) of another control scheme ( here i took the dra ) during a long time ( here i took @xmath144 time steps ) .",
    "then a simple esn procedure can be used to reproduce the recorded trajectories by learning the appropriate feedback connections @xmath33 and @xmath34 . after learning , when the very same environment is presented again to the neural network",
    ", it will reproduce both predictions and actions of the learned control scheme .",
    "however , if the learning time was to small or the environment variable enough , then there may be some discrepancies between recorded and reproduced trajectories , which is the case in this application : at the end of initialization the system had a behavior which was very different from the dra , see figure [ fig : idrnn init ] .",
    "nonetheless it was sufficient for the coupled system to be in an attractor basin and the control did work .",
    "i simulated the idrnn and the dra control for @xmath145 time steps and obtained a performance displayed in figure [ fig : heating tank perf ] .",
    "it appears that the dra converges faster to a good control behavior , see [ fig : double res traj ] but its performance slowly deteriorates with time . on the contrary ,",
    "the idrnn converged more slowly but its performance improves with time . eventually , the system behavior ( see [ fig : idrnn traj ] ) is similar to the best case for the dra , although a bit worse .",
    "the parameters used are the same as in the previous section with the addition of @xmath132 , @xmath146 , @xmath147 .",
    "the reason why i take the forgetting parameters @xmath148 to be so large is because an initializing method is used and i want the network not to forget immediately the initialization .",
    "i also reset the matrix @xmath115 to @xmath149 at the end of the initialization to slow learning down to stay close to initialization at first .",
    "the parameters for the dra are identical to that of the idrnn .",
    "distance between the target @xmath150 and @xmath151 over a siding window of size @xmath152 is used for this performance index .",
    "the two dots correspond to figure [ fig : heating tank control ] . ]    to summarize , the two methods seem to roughly give similar results at their optimum .",
    "however , they seem to differ in the evolution of the performance with time .",
    "beyond the proof of concept supported by the previous numerical experiments , idrnn has some notable properties which are discussed in this section .",
    "an important characteristic of idrnn ( and also dra ) is its universality , in the sense that it can embed any existing control schemes . indeed , as detailed in the previous section , it is possible to initialize these networks , using traditional esn algorithms .",
    "the procedure is , first , to record the inputs ( perception ) and ( output ) of a preexisting control scheme for a given environment ; and , second , to use traditional esn algorithms on the idrnn architecture in order to reproduce these trajectories when exposed to a similar environment .",
    "sontag has proven that , in theory , recurrent neural networks could reproduce any dynamical systems @xcite .",
    "thus , there exists an idrnn , possibly with a very large number of neurons , which can emulate a given control scheme arbitrarily accurately . naturally in applications , the number of neurons is limited and the reproduction is not necessarily accurate , even more if the recorded trajectories were not long enough ( see previous section ) .",
    "nonetheless , this method can be used as a precious initialization procedure in order to design incremental control schemes .",
    "although the present version of idrnn is explicitly designed for a supervised learning framework , it possible to extend the approach to a reinforcment learning framework .",
    "the first step is to include a reward in the present model ( which the neural network will try to maximize ) .",
    "this can be easily done by adding a stimulus neuron exclusively excited when a reward in presented .",
    "thus , implementing a reinforcment learning approach would simply correspond to maximizing the activity of this reward neuron instead of minimizing the distance between such a neuron and a target trajectory . in the mathematical formalism , this can be immediately implemented by replacing the target @xmath40 by @xmath42 in and asking the motor learning to maximize ( rather than minimize ) its criterion .",
    "thus , motor learning aims at increasing the current and future rewards .",
    "besides , the network can also handle a variety of hybrid approaches corresponding for instance to a mix of supervised / reinforcment learning .",
    "more precisely , an interesting situation is to design an agent with a lot of stimuli ( including a reward ) all of which perceptive learning aims at predicting , while motor learning exclusively aims at increasing the reward .",
    "this would correspond to a common reinforcment learning situation where there is no target , while making sure the network can behave coherently and in context with its environment .",
    "the idrnn approach has , in principle , no problem handling rare or intermittent rewards .",
    "indeed , it still produces behavior when the rewards are very sparse .",
    "the idrnn network activity is always running and not directly influenced by the presence of a reward . only learning",
    "is directly boosted when a reward is presented . in my opinion , this provides a notable advantage of idrnn over dra which can not be extended to reinforcment learning so easily because the activity of the network is directly influenced by the target / reward . thus with rare rewards , i.e. sparse target",
    ", the dra approach would not work .",
    "the proper handling of distal rewards @xcite by the idrnn is still an open question , but the machinery introduced here for prediction of the future in several time steps seems to be an appropriate way to treat this difficult problem .",
    "nonetheless , this stands as a perspective to be investigated .       of course",
    ", i do not claim the full biological plausibility for the idrnn approach because such simple networks can never represent the incredible complexity found in neuroscience .",
    "however , i would argue that this approach is biologically more plausible than the dra .",
    "indeed , the latter approach uses two reservoirs with exactly the same recurrent and output weights .",
    "this clearly breaks the locality requirement of biologically plausible algorithms @xcite : to modify the connection between neurons @xmath153 and @xmath154 , learning rules should only include information available at neurons @xmath153 and @xmath154 . on the other hand ,",
    "the idrnn approach is based on a single reservoir and there is no sharing of the weights .",
    "thus , contrary to dra , it is not biologically implausible by construction .     although this paper is based on rls implementation of the ideomotor principles ( for efficiency reason )",
    ", it is also possible to design of lms implementation which is more biologically plausible . indeed , rls is not local since is involves computing the inverse of the global correlation matrix .",
    "lms corresponds to a simple stochastic gradient descent of the ideomotor principles in .",
    "it leads to slower convergence times , but more robustness , than the rls algorithm @xcite , but both aim at solving the same problem .",
    "the ideomotor lms algorithm can be derived from the modified ideomotor principles under the same greedy assumption that @xmath27 and @xmath49 do not depend on @xmath33 and @xmath34 .",
    "it comes as the gradient descent of @xmath155 and @xmath156 . assuming that we consider the reinforcment learning case detailed above , where @xmath157 and motor learning is a maximization , it can be written as @xmath158 where @xmath159 and @xmath160 have been re - parametrized to absorb constants .     in this form ,",
    "perceptive learning is local .",
    "indeed , the modification of the connection @xmath161 only depends on the stimulus @xmath162 , the prediction @xmath163 and the reservoir state @xmath164 which are locally available quantities between reservoir and perceptive area .",
    "motor learning can also be said to be plausible , if we slightly nuance the locality requirement by the experimental fact that a few modulatory synapses can bring some additional information to distant connections as shown in figure [ fig : biological plausibility ] .",
    "indeed , the modification of the connection @xmath165 depends on the reservoir state @xmath166 , but also on the @xmath167 which is not available between reservoir and motor area . thus there is a need for a modulatory synapse , involved mainly in learning , from the perceptive area to the motor connections to biologically implement this algorithm .",
    "interestingly , lms and rls can be shown to be equivalent if the reservoir has a temporal correlation matrix proportional to the identity @xcite .",
    "this regime has been often observed in biology , where in vivo cortical tissues are said to be in an asynchronous irregular state @xcite .",
    "this would support the fact that such a biological lms implementation of the ideomotor principle can be efficient , although showing this rigorously stands as a perspective .    besides , one might ask how the current scheme differs from active inference that uses explicit forward or generative models of predicted stimuli .",
    "they key difference is the simplicity of the current scheme - that just involves optimising connection weights from the reservoir to action and perception states .",
    "heuristically , this can be regarded as equipping an agent with a vast repertoire of generative models and then optimising the weights to select the model with the greatest evidence ( least free energy or prediction error ) .",
    "the connection between the current scheme and active inference may be important from the point of view of biological implementation : there is now a literature on biological schemes for minimising prediction error using hierarchical predictive coding and bayesian filtering schemes .",
    "of particular interest here is the role of reflexes in mediating action .",
    "the current scheme can be regarded as selecting a forward model of sensations .",
    "in active inference , these forward models also predict kinaesthetic or proprioceptive sensations .",
    "this means that the prediction errors minimised by action can be resolved very simply - through peripheral reflex arcs @xcite .",
    "on the whole , this theory driven approach may contribute to the debate about the computational role of several parts of the brain . a rigorous link with the brain clearly stands as a long term perspective .",
    "yet , i think it is interesting to note the ingredients this architecture needs in order to design what could considered as a simplistic embodied agent .",
    "the first ingredient is the combination of a central recurrent network and two types of read - out , as can be observed in the spinal chord @xcite with the dorsal root for perception and the ventral root for action .",
    "the second ingredient is the modulation of motor connections by reward neurons which seems to be handled in the brain by a variety of neurotransmitters @xcite .",
    "i believe that the study of basic vertebrate nervous system may , in the long term , benefit from such constructive approaches .",
    "this paper defines a recurrent neural network which blindly learns to control an unknown environment .",
    "based on a randomly connected reservoir it learns on the fly two read - outs which correspond to perception and action .",
    "these read - outs are learned according to two principles : perceptive learning corresponds to maintaining good predictions of the incoming stimuli ; motor learning tries to change the dynamics of the reservoir so that the stimuli predictions match a target trajectory . actually , the control of the environment is just a byproduct of the behavior of the neural network which only cares about its own predictions .",
    "this algorithm is closely related to the ideomotor theory and active inference , providing an efficient computational implementation of these concepts .",
    "an implementation of the proposed method to robotics may highlight the similarities with more classical approaches in this field @xcite .",
    "several numerical simulations have established a proof of concept for this neural network .",
    "it manages to control fairly complicated dynamical systems and properly handles non - linearities and delays .",
    "the robustness of the approach with respect to most parameters is supported by the fact that a single set of parameters ( with little tuning ) was used to control all environments in this paper .",
    "several challenges can be foreseen for the future development of such algorithm .",
    "first , a extensive benchmarking of idrnn , dra and competitors on real world environments is needed .",
    "second , the development of a mathematical theory explaining the power of such random networks would be useful .",
    "third , extending the ideomotor approach presented here to a fully connected neural network ( e.g. with connections from perceptive to motor area ) can be done straightforwardly , and may prove more efficient in certain cases . finally , building architectures with building blocks such as the network presented here could prove interesting , not only for designing even more intelligent agents , but also to shed light on possible information hierarchies which might be implemented by the brain .",
    "yang , c. , ge , s.  s. , xiang , c. , chai , t. , and lee , t.  h. ( 2008 ) .",
    "output feedback nn control for two classes of discrete - time systems with unknown control directions in a unified approach .",
    ", 19(11):18731886 ."
  ],
  "abstract_text": [
    "<S> the architecture of a neural network controlling an unknown environment is presented . </S>",
    "<S> it is based on a randomly connected recurrent neural network from which both perception and action are simultaneously read and fed back . </S>",
    "<S> there are two concurrent learning rules implementing a sort of ideomotor control : ( i ) perception is learned along the principle that the network should predict reliably its incoming stimuli ; ( ii ) action is learned along the principle that the prediction of the network should match a target time series . </S>",
    "<S> the coherent behavior of the neural network in its environment is a consequence of the interaction between the two principles . </S>",
    "<S> numerical simulations show a promising performance of the approach , which can be turned into a local , and better `` biologically plausible '' , algorithm . </S>"
  ]
}