{
  "article_text": [
    "in the context of nonlinear optimal control , we are interested in the inverse problem of lagrangian identification from given trajectories .",
    "this identification should be carried out such that solving the direct optimal control problem with the identified lagrangian would allow to recover the given trajectories .",
    "inverse problems of calculus of variations are old topics that have attracted a renewal of interest in the context of optimal control , especially in humanoid robotics @xcite .",
    "relevant aspects of the problem are not well understood and many issues still need to be addressed to propose a tool that could be used in experimental settings .",
    "the work presented here constitutes a step in this direction .",
    "a preliminary conference version @xcite originally introduced our optimization framework as a tool to solve the inverse problem numerically .",
    "the current paper extends this work in many ways .",
    "in particular , by using the ( quite general ) concept of _ occupation measures _ we can propose a broad definition of inverse optimality and we also rigorously justify most of the approximations behind the numerical results reported in @xcite .",
    "many aspects of this work parallel the results of @xcite about _ direct _ optimal control with polynomial data .",
    "the principle of optimality ( or stationarity ) is very important as a conceptual tool to describe laws of phenomenon are observed in nature ( _ e.g. _ fermat s principle in optics , lagrangian dynamics in mechanics ) . beyond physics , similar tools and arguments",
    "are used to describe and model the behaviour of living systems in biology @xcite or decision making agents in economics @xcite .",
    "of more important interest to us is the application of the optimality principle to model the motion of living organisms @xcite . in our technological context",
    ", this constitutes a hot topic .",
    "promising expectations for these types of model include :    * the conceptual understanding of general laws that govern decision taking processes related to living organism motion , including human motion @xcite . * the ability to use these general laws to reproduce and synthetise motion behaviours for new tasks with unknown space configuration .    in this context , the principle of optimality only constitutes one possible conceptual tool to understand motion .",
    "there is a debate regarding its validity @xcite or its direct applicability in robotics applications @xcite .",
    "these illustrate the fact that this idea constitutes an active subject of research , with a strong connextion with applications .    in many situations",
    "however , the cost related to the motion of a system is unknown or does not correspond to direct intuition . in these cases , as clearly emphasized in @xcite : `` it would be very useful to have a general data analysis procedure that infers the cost function given experimental data and a biomechanical model '' .",
    "our contribution is to investigate the mathematical meaning of `` inferring cost function from data '' and we propose a numerical method to address problems of this type based on inverse optimality .",
    "we emphasize that this paper is `` only '' concerned with this question .",
    "in particular we do not address the issue of interpreting the inferred cost function or solving direct problems for new unseen conditions .",
    "we solely focus on the task of inferring a cost function from data .",
    "this constitutes a nontrivial shift in term of point of view compared to usual questions arising when dealing with direct optimal control problems .",
    "we hope to convince the reader that there are crucial differences between inverse and direct optimal control and that it is worth investigating the former within an appropriate context with somewhat different questions in mind .",
    "the backbone of the proposed approach and its relation with the direct problem of optimal control is presented in figure [ fig : directillustr ] .",
    "it is important to understand the symmetric role of the lagrangian and the occupation measure representing the input trajectories . as a matter of fact , since the input of the inverse problem is a set of trajectories ( supposedly optimal for a certain lagrangian ) , many aspects of the existence of minimizers that are crucial in direct optimal control , are not relevant for inverse problems since the  optimal \" trajectories are given .",
    "for example , there is no need to recompute optimal trajectories for direct problems with initial conditions already considered in the input data since by inverse optimality , the input trajectories are optimal with respect to the identified lagrangian .    ;    ( box1 )  ( box2 ) ; ( box2 )  ( box3 ) ; ( box21 )  ( box22 ) ; ( box22 )  ( box23 ) ;      since its introduction by kalman @xcite , the inverse problem of optimal control has been studied in linear settings @xcite leading to many nonlinear variations @xcite . in these",
    "works the input data of the problem is a characteristic of a class of trajectories often given in the form of a control law .",
    "this contrasts with the setting we propose to study , for which the input is a set of trajectories which could come from physical experiments .",
    "this motivates the work of @xcite and @xcite about well - posedness of the inverse problem , both in the context of unicycle dynamics in robotics and strictly convex positive lagrangians .    on the other hand , to treat the inverse problem several authors have proposed numerical methods based on the ability to solve the direct problem @xcite , also in the context of markov decision process @xcite or based on a discretized version of the direct problem @xcite .    our approach is different and based on occupation measures , an abstract and quite general tool to handle trajectories ( and their weak limits ) of feasible solutions of classical control problems . formulating the ( direct ) control problem on appropriate spaces of measures amounts to relaxing the original problem . in most applications ,",
    "both relaxed and original problems have same optimal value @xcite . however the relaxed formulation has the crucial advantage that compactness holds in a certain weak sense : as a matter of fact , many optimization problems over appropriate spaces of measures attain their optimum , whereas most optimization problems over smaller functional spaces ( e.g. continuous functions , or lebesgue integrable functions ) typically have _ no _ optimal solution . at last but not least , for control problems with polynomial data ,",
    "the relaxed problem can be formulated as an optimization problem on _ moments _ of occupation measures . by combining this with relatively recent advances in real algebraic geometry @xcite and in numerical optimization @xcite one",
    "may thus provide a systematic numerical scheme to approximate effectively relaxed solutions of optimal control problems @xcite .",
    "we choose the setting of free terminal time optimal control which is consistent with many physical experiments that one can think of .",
    "but the same approach with _",
    "ad hoc _ modifications is also valid in the fixed terminal time setting .",
    "@xmath0 in our opinion , occupation measures are the perfect abstract tool to formally express the fact that we consider a ( possibly uncountably infinite ) superposition of trajectories as input data of the inverse control problem .",
    "we then propose a general formulation of the inverse problem based on occupation measures and complementarity in linear programming . a relaxation of the well known hamilton - jacobi - bellman ( hjb ) sufficient optimality condition appears in our formulation as for the usual direct optimal control problem @xcite .",
    "this formulation is shown to be consistent with what is commonly expected regarding inverse optimality .",
    "it is worth noting that when using the hjb optimality conditions , the situation is completely symmetric for the direct and inverse control problems . in both cases",
    "the hjb optimality conditions are used to _ certify the global optimality of trajectories_. but in the former the lagrangian is known and hjb provide conditions on the optimal state - control trajectories ( to be determined ) whereas in the latter the  optimal \" state - control trajectories are known and hjb provide conditions on the lagrangian ( to be determined ) for the given trajectories to be optimal .",
    "( in both cases the optimal value function is considered as an auxiliary  variable \" . )",
    "@xmath0 furthermore , this framework allows to further characterize the space of solutions associated with a given inverse optimal control problem .",
    "this viewpoint is different from what has been proposed in previous ( theoretical and numerical ) contributions to this problem @xcite which , implicitly or explicitly , involve strong ( and , in our opinion , overly restrictive ) constraints on the class of functions in which the candidate lagrangians are searched .",
    "@xmath0 the weak formulation of direct optimal control problems via occupation measures is elegant and powerful but also involves difficult technical questions regarding potential gaps between classical and generalized control problems . using inverse optimality , we justify _ a posteriori _ that this discussion can be partially mitigated for the inverse problem .",
    "this striking difference between direct and inverse problems is due to the symmetric roles of the lagrangian and occupation measure and the fact that the occupation measure is given and fixed for the inverse problem .",
    "@xmath0 remarkably , despite the abstract setting of occupation measures , the proposed formulation is amenable to explicit numerical approximations via a hierarchy of semi - definite programs . indeed in the context of polynomial dynamics and semi - algebraic constraints , both the optimal value function and lagrangian used in the ( relaxed ) hjb optimality conditions",
    "can be approximated with polynomials .",
    "we show that such a reinforcement is coherent in the sense that no polynomial solution to the inverse problem is lost .",
    "@xmath0 finally , in usual experimental settings one does not have access to complete trajectories . instead one is rather given finitely many data points sampled from trajectories .",
    "but results from probability applied to our occupation measures allow to formalize the fact that we only work with `` samples '' .",
    "in addition , in this framework one may use empirical processes and statistical learning theory @xcite to provide bounds on the error made when working with samples instead of original trajectories .",
    "[ [ organization - of - the - paper . ] ] organization of the paper .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    in section [ sec : prelim ] we provide the context and background on optimal control and occupation measures . in section [ sec : iocp ] , we present our characterization of solutions to the inverse optimal control problem and illustrate how it allows to further discuss about the set of solutions and links with the direct optimal control problem . numerical approximations via polynomials and statistical approximations via finite samples are provided and discussed in section [ sec : practical ] . the resulting numerical scheme ( with proven strong theoretical guarantees )",
    "can be implemented with off - the - shelf software on a standard computer .",
    "finally , section [ sec : numerics ] describes numerical results on academic examples .",
    "if @xmath1 is a compact subset of a finite - dimensional euclidean space , let @xmath2 resp .",
    "@xmath3 denote the set of continuous resp .",
    "continuously differentiable functions from @xmath1 to @xmath4 .",
    "let @xmath5 denote the space of borel measures on @xmath1 , the topological dual of @xmath2 with duality bracket denoted by @xmath6 , i.e. @xmath7 is the integration on @xmath1 of a function @xmath8 with respect to a measure @xmath9 .",
    "let @xmath10 resp .",
    "@xmath11 denote the cone of non - negative borel measures resp .",
    "non - negative continuous functions on @xmath1 .",
    "the support of a measure @xmath12 is denoted by @xmath13 .",
    "an element @xmath12 such that @xmath14 is called a probability measure .",
    "let @xmath15 denote the dirac measure concentrated on @xmath16 and let @xmath17 denote the indicator function of an event @xmath18 , equal to @xmath19 if @xmath18 is true , and @xmath20 otherwise .",
    "let @xmath21 denote the state space and @xmath22 denote the control space which are supposed to be compact subsets of euclidean spaces .",
    "system dynamics are given by a continuously differentiable vector field @xmath23 .",
    "terminal state constraints are modeled by a set @xmath24 which is also given .",
    "let @xmath25 denote the unit ball of the euclidean norm in @xmath26 , and let @xmath27 denote the boundary of set @xmath28 in the euclidean space .",
    "let @xmath29 $ ] denote the set of multivariate polynomials with real coefficients with variables @xmath30 and let @xmath31 $ ] denote the set of such polynomials with degree at most @xmath32 .",
    "for a polynomial @xmath33 $ ] , we denote by @xmath34 the sum of the absolute values of the coefficients of @xmath35 when expanded in the monomial basis .",
    "we consider direct optimal control problems of the form : @xmath36,\\\\      & & x(0 ) = z , \\,x(t ) \\in x_t,\\\\      & & t \\in [ 0,t_m ] \\end{array}\\ ] ] with lagrangian @xmath37 and free final time @xmath38 with a given upper bound @xmath39 which ensures that the value function @xmath40 is bounded below .",
    "dynamics @xmath41 are given , as well as the sets @xmath42 , @xmath43 and @xmath24 .",
    "we assume that a set @xmath44 is given such that the following assumption is satisfied :    [ ass : feasibility ] for all initial conditions @xmath45 , problem ( [ eq : pdirect0 ] ) is feasible .      in this section",
    "we describe how to construct an occupation measure from a feasible trajectory of ( [ eq : pdirect0 ] ) and then from a set of such trajectories .",
    "the content of this section was already described in the litterature ( see for example @xcite ) and we include these notions here for completeness .",
    "let @xmath45 be an initial point .",
    "we use assumption [ ass : feasibility ] to fix a trajectory starting from @xmath30 .",
    "that is , a terminal time @xmath46 , a measurable control @xmath47 \\to u$ ] and an absolutely continuous trajectory @xmath48 \\to x$ ] such that @xmath49    the occupation measure of the corresponding trajectory is denoted by @xmath50 and is defined by @xmath51 for every borel sets @xmath52 and @xmath53 .",
    "we now turn to the construction of _ occupation measure _ and _ terminal measure _ of a set of trajectories by taking a measurable combination of occupation measures of single trajectories    .",
    "consider a probability measure @xmath54 and an upper bound on terminal time @xmath39 .",
    "thanks to assumption [ ass : feasibility ] , for each @xmath55 , we fix a terminal time @xmath56 $ ] , a measurable control @xmath47 \\to u$ ] and an absolutely continuous trajectory @xmath48 \\to x$ ] such that ( [ eq : supperpos1 ] ) holds .",
    "that is , for each @xmath55 , we have an occupation measure @xmath50 as described in ( [ eq : supperpos1.1 ] ) . the occupation measure @xmath57 and terminal measure @xmath58 of the set of trajectories @xmath59}$",
    "] are then defined by tacking a convex combination of each @xmath50 according to @xmath60 ( see also ( * ? ? ?",
    "* chapter 5 ) and ( * ? ? ?",
    "* section 3 ) ) .",
    "we obtain the following definition : @xmath61 for every borel sets @xmath52 and @xmath53 . with the previous definition , @xmath62 in particular @xmath63 furthermore for every @xmath64 , @xmath65 where ",
    "@xmath66 \" denotes the gradient vector of first order derivatives of @xmath67 , and the  dot \" denotes the inner product between vectors . equation ( [ eq : liouville1 ] ) is known as liouville s equation and is also written as @xmath68 where the divergence is to be interpreted in the weak sense and a change of sign comes from integration by part .",
    "as we have seen , occupation and terminal measures as defined in ( [ eq : supperpos2 ] ) satisfy the liouville equation ( [ eq : liouville2 ] ) .",
    "this motivate the following broader definition .",
    "[ def : occmeasure ] a general occupation measure is a measure that satisfies liouville s equation ( [ eq : liouville2 ] ) , for some terminal measure @xmath58 , in the weak sense described in ( [ eq : liouville1 ] ) .",
    "we have seen in this section how to construct an occupation measure from a set of feasible trajectories of ( [ eq : pdirect ] ) .",
    "however the set of all occupation measures is in general much bigger than the set of measures arising in this way .      for inverse optimal control ,",
    "we suppose that the trajectories are given .",
    "moreover , the liouville equation and positivity constraints are sufficient to develop all the aspects of our analysis of inverse optimality .",
    "_ therefore , independently of how it is constructed , the input data of our inverse control problem is a general occupation measure as given by definition [ def : occmeasure ] .",
    "_    this restriction is made without loss of generality regarding classical trajectories because , from the construction in ( [ eq : supperpos2 ] ) , we consider an input set that contains all of them .",
    "all the results will in particular apply to situations when the occupation measure is a superposition of classical trajectories as described in ( [ eq : supperpos2 ] ) .",
    "the results will also hold if this is not the case and the input measure involves generalized control .",
    "finally and most importantly , this construction allows to formally treat cases for which we are given a possibly uncountably infinite number of trajectories as input data and is therefore much more general than considering one or a few classical trajectories .      using the formalism of occupation measures , given a continuous lagrangian @xmath69 , an initial measure @xmath60 and a maximal terminal time @xmath39 , we consider direct optimal control problems of the form @xmath70",
    "@xmath71 is the set of measures @xmath72 solving problem ( [ eq : pdirect ] ) .",
    "note that by lemma [ lem : duality ] and assumption [ ass : feasibility ] , set @xmath73 is not empty .",
    "the link between problems ( [ eq : pdirect0 ] ) and ( [ eq : pdirect ] ) is far from trivial . .",
    "it is possible to construct problems for which measures considered in problem ( [ eq : pdirect ] ) do not arise in this way which may introduce spurious minimizers which are far from classical trajectories of problem ( [ eq : pdirect0 ] ) , see for example ( * ? ? ?",
    "* appendix c ) .",
    "these problems are usually overly constrained and not physically relevant , and in most practical settings , we have @xmath74 which we could see as an assumption on the inverse problem data .    in this",
    "constrained setting , sufficient conditions for this property to hold are those that ensure the applicability of the filippov - waewski theorem , see @xcite and the discussion around ( * ? ? ?",
    "* assumption i ) , ( * ? ? ?",
    "* assumption 2 ) , ( * ? ? ?",
    "* assumption 1 ) . under such sufficient conditions",
    ", it can be shown using ( * ? ? ?",
    "* theorem 2.3 ) that the equality holds .",
    "however , as we argued in the introduction , the link between ( [ eq : pdirect0 ] ) and ( [ eq : pdirect ] ) is much less problematic when considering inverse optimality .",
    "the main reason is that we consider that the input of the inverse problem is a measure , which is therefore given and fixed .",
    "it could arise as in ( [ eq : supperpos2 ] ) but not necessarily ( see figure [ fig : directillustr ] ) .",
    "we would like to emphasize the following :    * if the input occupation measure does not satisfy ( [ eq : supperpos2 ] ) , then it does not make sense to consider ( [ eq : pdirect0 ] ) as a basis for inverse optimality since the input of the problem itself is more general than the classical controls considered in ( [ eq : pdirect0 ] ) . in this case",
    ", it is more relevant to focus on ( [ eq : pdirect ] ) only . *",
    "if the input occupation satisfy ( [ eq : supperpos2 ] ) , then , the analysis is still valid . in this case , since the input of the inverse problem involves classical controls , the question of the link between ( [ eq : pdirect0 ] ) and ( [ eq : pdirect ] ) is a real issue for direct optimal control .",
    "but in the context of inverse optimality , a partial answer is given _ a posteriori _ by corollary [ cor : nogap ] .",
    "it is shown that , even in this case , considering ( [ eq : pdirect ] ) as a basis for inverse optimality does not allow to identify lagrangians for which there is a gap between ( [ eq : pdirect0 ] ) and ( [ eq : pdirect ] ) for all considered initial conditions in @xmath75 , except for a @xmath60-negligible subset .    for these reasons we adopt the following convention +    _ all our analysis refers to direct control problems of the form of ( [ eq : pdirect ] ) .",
    "_    the corresponding conic dual can be written as @xmath76 the first two constraints @xmath77 and @xmath78 of ( [ eq : pdirectdual ] ) are relaxations of the well - known hamilton - jacobi - bellman ( hjb ) sufficient condition of optimality @xcite .",
    "conic duality provides the following link between the problems ( [ eq : pdirect ] ) and ( [ eq : pdirectdual ] ) .",
    "[ lem : duality ] the infimum in ( [ eq : pdirect ] ) is attained and there exists a maximizing sequence in ( [ eq : pdirectdual ] ) .",
    "in addition , for any feasible primal pair @xmath72 and any sequence of dual variables @xmath79 and @xmath80 , @xmath81 , the following assertions are equivalent    * @xmath72 is optimal for ( [ eq : pdirect ] ) and @xmath82 is a maximizing sequence for ( [ eq : pdirectdual ] ) ; * strong duality : @xmath83 * complementarity : @xmath84    we only sketch the proof here , for more details see @xcite . observe that ( [ eq : pdirect ] ) is feasible thanks to assumption [ ass : feasibility ] and ( [ eq : pdirectdual ] ) is feasible with @xmath85 and @xmath86 .",
    "moreover , the cone @xmath87 is closed for the weak topology @xmath88 ( by using banach - alaoglu s theorem ) . therefore there is no duality gap between ( [ eq : pdirect ] ) and ( [ eq : pdirectdual ] ) and the optimum is attained in the primal , see e.g. ( * ? ? ?",
    "* theorem iv.7.2 ) .",
    "condition ( [ eq : pdirectslack1 ] ) is just a reformulation of strong duality in this context .",
    "equivalence with ( [ eq : pdirectslack2 ] ) follows by noticing that for any primal feasible pair @xmath72 and dual feasible pair @xmath89 , @xmath90    if the lagrangian @xmath69 is strictly positive on @xmath91 , then lemma [ lem : duality ] holds without the constraint @xmath92 and without the dual variable @xmath93 .",
    "given a `` set '' of trajectories and model constraints , the inverse problem of optimal control consists of finding a lagrangian for which the trajectories are optimal .",
    "thanks to the framework exposed in the previous section , it is now easy to define what is a solution to the inverse optimal control problem .",
    "@xmath0 firstly , the `` set '' of trajectories will be represented by measures satisfying liouville equation ( [ eq : liouville2 ] ) which are part of the data of the inverse problem .",
    "@xmath0 secondly , a lagrangian @xmath69 solution to the inverse problem is a continuous function such that @xmath94 for some @xmath38 such that @xmath73 is feasible .    in this section ,",
    "we propose a rigorous definition of inverse optimality and prove an equivalence result between direct and inverse optimality . to do so",
    ", we use lemma [ lem : duality ] which ensures that @xmath73 is non empty as long as @xmath95 .",
    "furthermore , it provides a certificate of ( sub)optimality .",
    "we can now formally define what is meant by a solution to the inverse optimal control problem :    [ def : solution ] for @xmath96 , given measures @xmath97 and @xmath58 such that @xmath98 , denote by @xmath99 the set of @xmath100-optimal solutions to the inverse optimal control problem , namely the set of functions @xmath101 such that there exists a function @xmath64 satisfying @xmath102 then the set @xmath103 of solutions to the inverse optimal control is defined by : @xmath104    intuitively , definition [ def : solution ] states that we can find differentiable suboptimality certificate for any arbitrary precision ( see in remark [ rem : aproxsolution ] ) .",
    "in addition , the positivity constraint on @xmath105 ensures that these certificates provide lower bounds on the value of the direct problem ( [ eq : pdirect0 ] ) for arbitrary initial conditions , even not in @xmath75 .",
    "the main motivation behind this definition of inverse optimality is the following :    [ th : solution ] given @xmath97 and @xmath58 , the set @xmath106 is a convex cone , closed for the supremum norm .",
    "moreover , the following two assertions are equivalent :    * @xmath107 , @xmath108 ; * @xmath109 , @xmath110 .",
    "convexity follows from convexity of the constraints of definition [ def : solution ] .",
    "there exists a constant @xmath111 such that for any pair @xmath112 that satisfies constraints of definition [ def : solution ] for a certain @xmath113 , then it holds for any lagrangian @xmath69 that @xmath114 and @xmath115 on @xmath116 , which is sufficient to prove closedness .    for the first implication , suppose that @xmath107 and @xmath117 . then for any @xmath118 , the pair @xmath72 is feasible for @xmath73 .",
    "lemma [ lem : duality ] holds and the definition of @xmath106 allows to construct a dual sequence that is feasible for @xmath73 and that satisfies the complementarity condition with the pair @xmath72 .",
    "we now turn to the last implication .",
    "suppose that @xmath94 and @xmath119 .",
    "in particular , @xmath72 is feasible for @xmath73 and lemma [ lem : duality ] holds .",
    "consider the dual maximizing sequence @xmath120 given by lemma [ lem : duality ] .",
    "complementarity ensures that @xmath121 .",
    "furthermore , it holds that @xmath122 , @xmath123 on @xmath116 , @xmath124 and @xmath125 on @xmath126 which shows that @xmath107 .",
    "[ rem : aproxsolution ] another motivation behind definition [ def : solution ] of inverse optimality is the following .",
    "suppose that @xmath127 , then for any @xmath128 , @xmath72 is close to optimal for the problem @xmath73 . indeed , suppose that @xmath129 .",
    "then there exists @xmath67 such that @xmath130 and @xmath131 as well as @xmath132 .",
    "in addition , @xmath133 and @xmath134 . therefore @xmath135 .    at first sight the introduction of @xmath38 in theorem [ th : solution ] may look artificial whereas in fact it carries important information .",
    "the second part in the equivalence states that @xmath72 is a solution to some direct problem and does not saturate one of the constraints .",
    "this allows to avoid direct problems for which , for any value of @xmath38 , any solution would saturate the constraint on the mass of the occupation measure ; for example this happens in direct problems with free terminal time tending to infinity .",
    "such problems should be avoided since then an occupation measure with finite mass can not be optimal . given a lagrangian @xmath69 , there is no guarantee that there exists a triplet @xmath136 which satisfies the second point of theorem [ th : solution ] . however , checking that a lagrangian @xmath69 meets our criterion for inverse optimality ensures that this is the case .",
    "an interesting corollary is that if the input of the optimal control is given by classical trajectories , then inverse optimality ensures that the value of ( [ eq : pdirect0 ] ) is attained by classical trajectories for almost all the initial values considered .",
    "this leaves aside many of the technical issues when working with classical trajectories for direct optimal control .",
    "[ cor : nogap ] if @xmath107 and @xmath137 is a superposition of classical trajectories as defined in equation [ eq : supperpos2 ] in section [ sec : om ] , then @xmath60-a.a .",
    "( almost all ) of these trajectories must be optimal for the corresponding direct problem .",
    "in particular , @xmath138 given by ( [ eq : pdirect0 ] ) is attained and there is no relaxation gap between ( [ eq : pdirect0 ] ) with initial condition @xmath30 and ( [ eq : pdirect ] ) with initial measure @xmath139 for @xmath60-a.a .",
    "initial conditions @xmath30 in @xmath140 .    as a consequence ,",
    "the focus on ( [ eq : pdirect ] ) instead of ( [ eq : pdirect0 ] ) in section [ sec : ocp ] is _ a posteriori _ justified by corollary [ cor : nogap ] .",
    "the question of absence of such a gap for initial conditions @xmath141 can not be treated by this approach .",
    "this question is much less relevant for inverse optimality since it does not involve initial conditions that are related to input data of the inverse problem .",
    "we claim that definition [ def : solution ] is a powerful tool to analyze inverse optimality in the context of optimal control .",
    "to go beyond theorem [ th : solution ] , we next describe results and comments that stem from definition [ def : solution ] of inverse optimality .      theorem [ th : solution ] justifies the idea that if trajectories realize the minimum of some optimal control process then the corresponding lagrangian meets our criterion .",
    "this requirement is necessary for any  inverse problem \" ( and not only for inverse optimal control ) .",
    "however in general there could be many candidate solutions as illustrated in this section . in what follows",
    ", we assume that the triplet @xmath137 satisfies liouville s equation ( [ eq : liouville2 ] ) .",
    "[ [ conserved - values . ] ] conserved values .",
    "+ + + + + + + + + + + + + + + + +    suppose that there exists a function @xmath142 such that @xmath143 for all @xmath144",
    ". then @xmath145 . in practical examples",
    "there might be many such conserved values .",
    "for instance this is the case when @xmath16 or @xmath146 or both remain on a manifold or when there exists a continuous mapping @xmath147 .",
    "[ [ total - variations . ] ] total variations .",
    "+ + + + + + + + + + + + + + + + +    consider any function @xmath148 .",
    "all lagrangians of the form @xmath149 belong to @xmath106 , independently of @xmath137 .",
    "[ [ convex - conic - combinations - and - uniform - limits - of - solutions . ] ] convex conic combinations and uniform limits of solutions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    as stated in theorem [ th : solution ] , the set of solutions to the inverse problem is a convex cone , closed for the supremum norm . for example , let @xmath150 and consider a lagrangian @xmath101",
    ". then @xmath151 for every @xmath152 and therefore both lagrangians @xmath69 and @xmath153 are solutions to the inverse optimal control problem .",
    "all the above examples illustrate that many solutions to the inverse problem may exist .",
    "although these solutions are valid from a theoretical point of view , they do not correspond to what is commonly expected from a solution .",
    "indeed , they do not arise from an optimal physical process that would have generated trajectories , but rather from mathematical artifacts .",
    "intuitively , the more information is contained in @xmath154 , the smaller is the space of solutions to the inverse problem .",
    "we next discuss two factors that impact the size of @xmath106 .",
    "[ [ direct - problem - constraints . ] ] direct problem constraints .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + +    denote by @xmath155 ( resp .",
    "@xmath156 ) the feasible set of problem ( [ eq : pdirect ] ) and by @xmath157 ( resp .",
    "@xmath158 ) the set of solutions to the inverse problem ( as described in definition [ def : solution ] ) when the state , control and dynamical constraints are given by @xmath159 ( resp .",
    "@xmath160 ) .    if @xmath161 then @xmath162 . in other words",
    ", there is a kind of duality between the space of feasible solutions for the direct problem and the space of solutions to the inverse problem .",
    "an extreme instance is when the feasible space of the direct problem is a singleton ( @xmath41 does not depend on the control @xmath146 ) , in which case any lagrangian is a solution to the inverse problem .    [ [ range - of - the - occupation - measure . ] ] range of the occupation measure .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    suppose that @xmath163 where @xmath164 and @xmath165",
    ". then @xmath166 . as a consequence ,",
    "maximizing the support of the initial measure @xmath60 reduces the space of solutions to the inverse problem . when the occupation measure @xmath167 is a superposition of trajectories as detailed in section [ sec : om ] , the larger is the  space \" occupied by trajectories , the smaller is the space of potential solutions to the inverse problem .      to illustrate the proposed framework we consider a simple uni - dimensional example .",
    "we emphasize that his example is very simple in the sense that the direct problem is easy .",
    "however , inspecting the solution of the inverse problem leads to non trivial behaviors .",
    "let @xmath168 $ ] with @xmath169 and let @xmath170 with @xmath171 $ ] . consider the family of lagrangians @xmath172 .",
    "suppose that we are given a triplet @xmath137 which consists of a superposition of trajectories as described in section [ sec : om ] .",
    "we wish to find a candidate lagrangian in the family @xmath173 .",
    "then we have the following alternatives .",
    "* @xmath174 .",
    "* @xmath175 .",
    "* @xmath176 is a singleton , @xmath177 , @xmath178 .",
    "* @xmath179 .",
    "we should comment on case 1 latter .",
    "if the support of @xmath167 is empty , which means that @xmath180 , then we are in case 2 .",
    "assume now that the support of @xmath167 is non - empty and we are not in case 1 .",
    "then there exists @xmath181 such that @xmath182 .",
    "consider a sequence of decreasing positive numbers @xmath183 and the corresponding certificates functions @xmath184 that allow to verify that @xmath185 .",
    "since @xmath186 , we may assume ( up to an addition ) that @xmath187 which simplifies the problem .",
    "in addition , one must have @xmath188 , @xmath167 almost every where ( recall that the support of @xmath167 is non empty and this concerns a non empty subset of @xmath42 and @xmath43 ) .",
    "furthermore , for any @xmath16 , one must have @xmath189 , for @xmath190 $ ] .    *",
    "suppose that @xmath191 .",
    "then for any @xmath32 , @xmath192 .",
    "since @xmath193 goes to @xmath20 and @xmath191 , for @xmath32 sufficiently large , has @xmath194 .",
    "taking @xmath195 gives @xmath196 .",
    "it must hold @xmath167 almost everywhere that @xmath197 and @xmath198 . *",
    "suppose that @xmath199 .",
    "it must hold @xmath167 almost every where that @xmath200 .",
    "this implies that @xmath201 and @xmath202 , @xmath167 almost every where .",
    "it can be verified that for @xmath203 , this is a strictly decreasing function of @xmath204 for @xmath205 .",
    "therefore , it holds that @xmath206 , @xmath167 almost every where .",
    "since we have @xmath192 , it holds that @xmath207 and therefore @xmath208 , @xmath167 almost everywhere . in this case , it is easy to construct alternative sequences @xmath209 for @xmath210 to show that @xmath211 is also a member of @xmath106",
    ".    to conclude , we are in case @xmath19 when the trajectories that generate @xmath167 are not optimal with respect to any lagrangian in @xmath173 , in particular when @xmath204 is not @xmath167 almost everywhere constant .",
    "if this is not the case and @xmath167 is not degenerate , we have a unique solution or a set of solutions depending on @xmath167 and its relation with the constraint on @xmath146 .",
    "as discussed in section [ sec : searchspace ] , the space of solutions to the inverse problem can be very large .",
    "many of these solutions are of little interest for practitioners because they lack some physical meaning . however , from a formal point of view ",
    "valid \" solutions exist and ideally they should be the only solutions of a _ practical inverse optimal control problem _ to be defined .",
    "one may invoke some heuristics to reduce the space of solutions and to enforce prior knowledge in the treatment of the inverse problem .",
    "this is commonly achieved by imposing constraints on the candidate lagrangian solution .",
    "such heuristics include :    * restricting the dependence on certain variables ; * shape conditions ( e.g. , convexity ) ; * conic constraints such as positivity ; * parametric constraints ( e.g. , considering a finite dimensional family of candidate lagrangians ) ; * constraints relating the dependence between the candidate lagrangian and the corresponding value function .    notice that definition [ def : solution ] refers to the large class of continuous lagrangians with conic constraints . from a theoretical perspective , this allows to characterize inverse optimality in full generality .",
    "however this is not amenable to numerical computation yet and so we also describe tractable numerical approximations in the context of inverse optimality",
    ".    finally , according to definition [ def : solution ] , the input of the inverse problem is an occupation measure .",
    "again , this is a convenient tool for theoretical purposes but in most practical cases such an occupation measure is not available . in fact , roughly speaking , only some realizations of an experiment are available and these realizations form a data set which is an approximation of an hypothetical occupation measure . therefore in practice the input of the inverse problem is only an approximation of an ideal input , and correctness of this approximation is justified under certain experimental assumptions at the end of this section .",
    "the trivial lagrangian is solution to the inverse problem independently of the input occupation measures . as we have seen in section [ sec : searchspace ] , total variations share the same property .",
    "even though these are solutions to the inverse problem , it is important to avoid them in practice because they do not depend on the input occupation measure and therefore carry no information about it . as illustrated in example [ sec : toyexample ] , one way to avoid these spurious solutions is to consider only very restricted families of lagrangians that can not contain such solutions",
    ". this might be quite restrictive in practice and therefore we provide an alternative .",
    "we need the following assumption :    [ as : controlability ] there exists @xmath212 and a compact set @xmath213 with smooth boundary and @xmath214 , such that for any @xmath215 , there exists @xmath216 $ ] , a bounded function @xmath217 \\to u$ ] and an absolutely continuous trajectory @xmath218",
    "\\to x$ ] such that @xmath219 , @xmath220 and @xmath221 for all @xmath222 $ ] .    under assumption",
    "[ as : controlability ] we have the following result .",
    "[ prop : normalization ] if in definition [ def : solution ] one includes the normalization @xmath223 then @xmath224 .",
    "this is due to the following contradiction .",
    "suppose that @xmath225 .",
    "choose a decreasing sequence @xmath226 as @xmath227 , and construct a sequence @xmath184 of differentiable functions that satisfy conditions of definition [ def : solution ] for the chosen @xmath193 . then @xmath228 . because of assumption [ ass : feasibility ] , @xmath229 for every @xmath230 .",
    "therefore , by integration , @xmath231 . furthermore , @xmath232 .",
    "finally , @xmath233 and @xmath234 .",
    "in addition , by assumption [ as : controlability ] , we also have @xmath235 for every @xmath215 .",
    "since @xmath214 , this implies that @xmath236 uniformly on @xmath237 , as @xmath227 .",
    "in addition , @xmath238 as @xmath227 . next , with the polynomial vector field @xmath239 stokes theorem yields @xmath240 where @xmath241 is the outward pointing normal to the boundary at @xmath16 .",
    "because of the uniform convergence of @xmath236 on @xmath237 as @xmath227 , and boundedness of @xmath242 and @xmath243 on @xmath42 , the left - hand side converges to @xmath19 while the right - hand side converges to @xmath20 , which is a contradiction .    the conditions on @xmath237 may be relaxed . indeed , the only important point is to be able to apply stokes s theorem . in particular ,",
    "the set @xmath237 could be a box or an open set whose boundary does not have too many non - smooth points , see e.g. ( * ? ? ?",
    "* theorem iii.14a ) .",
    "the normalization given in proposition [ prop : normalization ] obviously ensures that lagrangians in the form of a total variation are excluded .",
    "assumption [ as : controlability ] may look very strong regarding the result of proposition [ prop : normalization ] .",
    "however the next example shows that it can not be excluded .",
    "consider the direct control problem with @xmath244 $ ] , @xmath245 , @xmath246 and @xmath247 .",
    "these data are obviously not compatible with assumption [ as : controlability ] .",
    "choose @xmath248 and @xmath249 so that the couple @xmath250 and @xmath251 , solves the problem @xmath252 indeed , for any differentiable @xmath67 , @xmath253 furthermore , the function @xmath254 ensures that @xmath255 is an optimal solution .",
    "indeed @xmath256 consider a sequence of differentiable functions @xmath257 , @xmath258 , such that @xmath259 for @xmath260 and @xmath261 otherwise . for @xmath262 $ ] , we have @xmath263 , @xmath264 , @xmath265 , @xmath266 , @xmath267",
    ". therefore even if we enforce the normalization @xmath268 , we can not prevent the trivial lagrangian @xmath269 from being an optimal solution to the inverse problem .    regarding proposition [ prop : normalization ]",
    ", one could argue that simple linear constraints such as @xmath270 or conic constraints such as @xmath271 would be sufficient to avoid the trivial lagrangian .",
    "however , this does not allow to avoid total variations which are equivalent to the trivial lagrangian in terms of solutions to the direct problem",
    ".    denote by @xmath272 the subset of @xmath273 with the normalization constraint of proposition [ prop : normalization ] added to the constraints of definition [ def : solution ] .",
    "one important feature of this normalization is that it can be thought of as a way to intersect the cone of solutions to the inverse problem with an affine subspace .",
    "therefore @xmath272 is still closed and convex .",
    "furthermore , if we restrict the set of candidate lagrangians to be finite - dimensional , one may look for minimum norm - like solutions which will prove to be useful in numerical experiments .",
    "indeed , @xmath272 being closed and convex and all norms being equivalent in finite dimensions , optimization problems over @xmath272 , if bounded , have an optimal solution . finally , as @xmath274 , one may minimize any norm - like function to enforce specific prior structure and avoid the trivial lagrangian .      until now",
    ", all the results that we have presented involve continuous and differentiable functions , in full generality .",
    "however , for practical computation one has to approximate such functions and of course , _ polynomials _ are obvious natural candidates .",
    "but in our context they are also of particular interest for mainly three reasons :    * for fixed degree , polynomials belong to finite - dimensional spaces and are therefore amenable to computation ; * when varying the degree , the class of polynomials is rich enough to approximate a wide class of functions ; * _ positivity certificates _ from real algebraic geometry allow to express positivity constraints in a computationally tractable way .    from now on ,",
    "we make the following assumption :    [ ass : poly ] @xmath41 is a polynomial and @xmath42 , @xmath126 and @xmath43 are basic semi - algebraic sets .    as proposed in definition [ def : solution ] , checking that a polynomial is a solution of the inverse problem involves the construction of a sequence of continuously differentiable functions .",
    "these functions can also be approximated by polynomials . in this section",
    "we describe some tools required for such an approximation and we also prove the correctness of the approximations .",
    "let @xmath275 $ ] be polynomials in the variable @xmath276 and consider the basic semi - algebraic set @xmath277 let @xmath278 and let @xmath279 $ ] denotes the set of sums - of - squares ( sos ) polynomials , i.e. , @xmath280 if it can be written as a sum of squares of other polynomials .",
    "let @xmath281 denote the convex cone of polynomials that can be written as @xmath282 where the degree of @xmath283 , @xmath284 , is at most @xmath285 .",
    "if @xmath286 we say that @xmath35 has a putinar positivity certificate .",
    "it is immediate to check that any element of @xmath281 is non - negative on @xmath287 .",
    "a remarkable property of such certificates is that a partial converse is true .",
    "[ prop : putinar ] suppose that the polynomial super - level set @xmath288 is compact for some @xmath289 .",
    "if @xmath290 on @xmath287 then there exists @xmath291 such that @xmath286 .    furthermore and importantly from a computational viewpoint , checking whether @xmath280 reduces to checking whether a set of lmis @xcite involving the coefficients of @xmath35 has a solution .",
    "therefore a more precise definition of inverse optimality in the context of polynomial lagrangians is as follows ( compare with definition [ def : solution ] ) .",
    "[ def : polysolution ] for @xmath96 , given measures @xmath97 and @xmath58 such that @xmath292 , denote by @xmath293 the set of polynomials @xmath294_{2k}$ ] ( i.e. , of degree at most @xmath285 ) such that : @xmath295 for some polynomial @xmath296_{2k}$ ] .",
    "denote also by @xmath297 the set of polynomial solutions to the inverse optimal control problem : that is , @xmath298 if for any @xmath96 there exists @xmath299 such that @xmath300 .",
    "in other words , @xmath293 is the set of polynomial @xmath100-solutions with degree bound @xmath285 , to the inverse optimal control problem .",
    "the advantage of the previous definition , is that , provided that one has the possibility to compute the linear functionals @xmath301^*$ ] and @xmath302^*$ ] , checking whether @xmath303 for @xmath32 and @xmath100 given reduces to solving a convex lmi problem @xcite .",
    "furthermore , under a compactness assumption , in the asymptotic regime this definition is equivalent to definition [ def : solution ] .",
    "suppose that one of the polynomials defining the basic semi - algebraic set @xmath42 ( resp .",
    "@xmath43 ) has a compact super - level set",
    ". then @xmath304.\\ ] ]    the direct inclusion is trivial . for the reverse inclusion , suppose that @xmath305 $ ] .",
    "fix @xmath96 , and take for @xmath67 a certificate that @xmath306 as given by definition [ def : solution ] . since we consider compact sets in finite dimensional spaces , both @xmath67 and its gradient @xmath307 can be simultaneously approximated uniformly by a polynomial up to an arbitrary precision .",
    "therefore as @xmath41 is bounded on @xmath91 , there exists a polynomial @xmath184 of degree @xmath32 such that @xmath308 and @xmath309 .",
    "hence @xmath310 on @xmath91 and @xmath311 on @xmath126 .",
    "using proposition [ prop : putinar ] , there exists @xmath312 and @xmath313 such that @xmath314 and @xmath315 .",
    "then @xmath303 whenever @xmath316 and finally , @xmath298 because @xmath100 was arbitrary ( fixed ) .",
    "all properties of lagrangians in definition [ def : solution ] hold for the lagrangians in definition [ def : polysolution ] .",
    "for example , as stated in remark [ rem : aproxsolution ] , if @xmath303 , then @xmath72 is close to optimal for @xmath73 .",
    "in particular , if we the moments of @xmath167 and @xmath317 are available then the latter property can be checked numerically by solving a semi - definite program .      for practical numerical computation in the context of definition [ def : polysolution ] , we still must be able to integrate polynomials with respect to @xmath167 and @xmath317 .",
    "this is easy provided that we know the moments of @xmath167 and @xmath317 .",
    "however , exact computation of such moments cane be complicated in practice , especially when @xmath167 is a superposition of trajectories .",
    "usually , data sets from experiments consist of samples of trajectories which can be seen as realizations of a random sampling process .    in this section",
    "we first describe how the framework of occupation measures can formally describe the process of sampling trajectories and we justify the replacement of measures @xmath72 by their empirical counterparts when considering empirical samples as input data for inverse control problems . in the context of polynomial certificates in definition [ def : polysolution ] ,",
    "this amounts to replacing the moments of the measures @xmath72 by their empirical counterparts .",
    "consider the probability measure @xmath60 on @xmath318 and the measures @xmath72 in equations ( [ eq : supperpos1 ] ) and ( [ eq : supperpos2 ] ) .",
    "one way to interpret these measures is to consider the following random process :    * choose @xmath319 randomly , * choose @xmath320 randomly uniformly on @xmath321 $ ] , * output @xmath322 .",
    "this defines a generative process for the random variable @xmath323 .",
    "if the probability for an initial condition @xmath30 to belong to a borel set @xmath324 is given by @xmath325\\\\      = & p_0(a ) : = \\frac{\\int_a t_z \\mu_0(dz)}{\\int_{x_0 } t_z \\mu_0(dz)},\\end{aligned}\\ ] ] then the probability for a trajectory @xmath323 to belong to a borel hyperrectangle @xmath326 is given by @xmath327 \\\\",
    "= & p_\\mu(a \\times b ) : = \\int_{x_0 } \\left ( \\int_0^{t_z } i(x_z(t ) \\in a)i(u_z(t ) \\in b ) dt\\right ) \\mu_0(dz ) = \\frac{\\mu(a\\times b)}{\\mu(x\\times u)}.\\end{aligned}\\ ] ] a statistical model for points @xmath328 , that are samples of trajectories , is to assume that we repeat the previous process @xmath329 times , independently . in this case",
    ", we say that the database @xmath330 is made of independent realizations of a random variable with underlying distribution @xmath331 .",
    "the process which generates the database being random , we write @xmath332 to stress that all @xmath333 are independent and identically distributed ( _ i.i.d .",
    "_ ) according to @xmath331 ( they are independent copies of the same random variable ) .",
    "similarly , @xmath317 can be seen as the probability distribution describing the following random process :    * choose @xmath319 randomly according to @xmath334 , * output @xmath335 .",
    "we now define what is an approximate solution to the inverse problem when the only information available about @xmath167 is a realization , @xmath330 , of a random process , @xmath336 .",
    "[ def : approxsolution ] for @xmath337 and @xmath330 , let @xmath338 be the set of polynomials @xmath294_{2k}$ ] such that : @xmath339 for some polynomial @xmath296_{2k}$ ] . in other words",
    ", @xmath338 is the set of polynomial @xmath100-optimal solutions ( with degree bound @xmath32 ) of the sampled inverse optimal control problem .",
    ",    one has replaced @xmath167 by its empirical counterpart , added the normalization of proposition [ prop : normalization ] and simplified other conditions ; see also remark [ rem : finalmeasure ] .",
    "_ importantly , membership in @xmath340 can be tested by semi - definite programming . _    using arguments from empirical processes and learning theory , one can quantify the price to pay for this discretization .",
    "of course since we assume that the process that generates the data include some randomness , such a quantification holds probabilitically .",
    "[ prop : unifapprox ] suppose that @xmath330 is a realization of the random process @xmath341 .",
    "then there exist constants @xmath342 , @xmath343 that only depend on ( @xmath344 , and @xmath258 , such that for any @xmath345 and any @xmath346 : @xmath347 where @xmath348 and where the randomness comes from the realization of @xmath349 .",
    "apply lemma [ eq : finitesamplebound ] of appendix [ sec : statlearn ] to the polynomial @xmath350 to get a bound on @xmath351 .",
    "[ rem : finalmeasure ] the conditions detailed in definition [ def : approxsolution ] ensure that @xmath352 on @xmath126 and @xmath353 , for any terminal measure .",
    "this is done in order to avoid to deal with the terminal measure @xmath317 but other alternatives are possible .",
    "for example , when @xmath126 is a single point or a simple algebraic set one may enforce ( as we do in section [ sec : numerics ] ) @xmath354 on @xmath126 instead .",
    "another possibility is to replace @xmath317 by its empirical counterpart .",
    "however in this case we need to provide a lower bound or add constraints on @xmath67 to obtain finite sample bounds as described in proposition [ prop : unifapprox ] .",
    "proposition [ prop : unifapprox ] mixes arguments from measure theory and conic optimization with arguments from empirical process and statistical learning theory .",
    "the implication of this result is that for a fixed degree , provided that the sample size is big enough , with high probability we do not loose much by approximating @xmath167 by an empirical sample .",
    "@xmath0 we would like to emphasize here that it is necessary to restrict the complexity of the class of functions in which the candidate lagrangian is searched .",
    "indeed otherwise for instance , for any fixed sample , the polynomial @xmath355 belongs to @xmath356 , but this clearly does not give much insight on the original control problem !",
    "the degree of the polynomial candidates is one among many possible measures of complexity .",
    "furthermore , although the constants are likely to be sub - optimal , they give a sense of how fast the degree of the polynomial approximation may grow with respect to the sample size in order to maintain accurate approximations of @xmath167 .",
    "building on results of section [ sec : practical ] , we next provide illustrative numerical simulations . in order to fit in the framework of the previous section , we consider examples where @xmath41 is a polynomial and @xmath42 , @xmath43 and @xmath126 are basic semi - algebraic sets .",
    "in addition , the input data of the inverse problem is given by a finite database : @xmath357 .",
    "in the sequel , the candidate lagrangians satisfy definition [ def : approxsolution ] .",
    "to compute such lagrangians , the main idea is to solve an optimization problem with fixed @xmath258 , where :    * @xmath358_{2k},v\\in{\\mathbb{r}}[x]_{2k}$ ] and @xmath113 are the decision variables , * @xmath100 is the criterion to minimize , * @xmath359 is the projection on @xmath360 of the set of feasible solutions @xmath361 .",
    "in addition , we also include a sparsity inducing term in the criterion that will prove to be useful in numerical experiments .",
    "we consider the following optimization problem : @xmath362 where @xmath358_{2k}$ ] , @xmath363_{2k}$ ] , @xmath100 is a real , @xmath364 ( fixed ) is a given regularization parameter , and @xmath365 denotes the @xmath366 norm of a polynomial , _ i.e. _ the sum of absolute values of its coefficients when expanded in the monomial basis .",
    "the first constraints come from definition [ def : approxsolution ] and the last affine constraint is meant to avoid the trivial solution ; see proposition [ prop : normalization ] .",
    "the @xmath366 norm is not differentiable around sparse vectors ( with entries equal to zero ) and has the sparsity promoting role to bias solutions of the problem towards polynomial lagrangian solutions with few nonzero coefficients .",
    "this regularization affects problem well - posedness and will prove to be essential in numerical experiments .",
    "linear constraints are easily expressed in term of polynomial coefficients .",
    "a classical lifting allows to express the @xmath366 norm as a linear program : for @xmath367 , @xmath368 subject to @xmath369 and @xmath370 , for all @xmath371 .",
    "the putinar positivity certificates can be expressed as lmis @xcite whose size depends on the degree bound @xmath32 .",
    "we use the sos module of the ` yalmip ` toolbox @xcite to manipulate and express polynomial constraints at a high level in ` matlab ` .",
    "the size of the corresponding lmi grows as @xmath372 where @xmath329 is the number of variables and @xmath32 the degree bound in putinar certificates .",
    "thus it is reasonable to consider relatively small problems .",
    "as shown in the numerical results section , we could handle problems with 5 variables and degree 10 with a reasonable amount of time and memory . to handle larger size problems , specific heuristics and techniques beyond the scope of this paper",
    "must be implemented .",
    "we consider several direct problems of the same form as ( [ eq : pdirect0 ] ) .",
    "that is , we give ourselves compact basic semi - algebraic sets @xmath42 , @xmath43 , @xmath126 , the dynamics @xmath41 , and a lagrangian @xmath373 .",
    "we take known examples for which the ( direct ) optimal control law can be computed and try to vary their degree of difficulty .",
    "given these optimal state - control trajectories , we generate randomly @xmath329 data points @xmath374 according to the random process described in section [ def : approxsolution ] . for a given value of @xmath375 and @xmath32",
    ", we compute a solution @xmath376 of problem ( [ eq : primal1 ] ) . then we measure how @xmath69 is close to @xmath373 by computing the following quantity ( in the monomial basis ) : @xmath377 we also report the value of @xmath100 in program ( [ eq : primal1 ] )",
    ". a larger value of @xmath100 means less reliable numerical certificates ; see remark [ rem : aproxsolution ] .      .",
    "see section [ sec : pb1 ] for problem details and comments .",
    "the first column is the distribution of the error @xmath100 .",
    "it represents the value of @xmath378 as a function of @xmath16 where @xmath379 is the optimal control .",
    "the second column is a representation of the value function @xmath380 and the third column is a representation of its derivative for solutions of problem ( [ eq : primal1 ] ) with and without regularization .",
    "we take 100 points on the segment .",
    "lagrangian @xmath376 and value function @xmath380 are both polynomials of degree 16 . ]    first consider the eikonal problem of minimum exit time from the unit ball in the one - dimensional case .",
    "the data of the problem are @xmath381 the optimal law for this problem is @xmath382 and the value function is @xmath383 .",
    "we sample 100 points uniformly in @xmath42 and solve problem ( [ eq : primal1 ] ) .",
    "we compare the choices @xmath384 ( no regularization ) and @xmath385 .",
    "results are presented in figure [ fig : onedexit ] which displays the distribution of the error @xmath100 , the estimated value function @xmath67 as well as its first derivative . despite the simplicity of the problem , it is quite representative of the difficulties that arise in the context of inverse optimality .",
    "the first difficulty is the size of the set of solutions to the inverse problem :    * given any symmetric differentiable concave function @xmath380 vanishing on @xmath386 , the pair @xmath387 solves problem ( [ eq : primal1 ] ) with @xmath388 ; * any positive polynomial on @xmath91 vanishing if @xmath208 solves problem ( [ eq : primal1 ] ) with @xmath388 ; * any lagrangian of the form @xmath389 solves problem ( [ eq : primal1 ] ) with @xmath388 ; * any convex combination of solutions of the types mentioned above also solves problem ( [ eq : primal1 ] ) .",
    "even though formally accurate , these solutions form a relatively large set and do not carry any physical meaning . in the absence of any additional form of prior knowledge , it is impossible to discriminate between these solutions and the one that we wish to recover , namely @xmath373",
    ". this is illustrated in figure [ fig : onedexit ] where the red line ( @xmath384 ) displays an example of value function @xmath67 obtained with a very low value of @xmath100 .",
    "this is a very good certificate that our database @xmath349 is close to optimal for the corresponding lagrangian @xmath69 .",
    "however , the estimated lagrangian is far from the original one , namely @xmath390 .",
    "moreover , the shape of the value function is quite uncommon .",
    "this motivates the use of prior knowledge to bias the solutions of problem ( [ eq : primal1 ] ) toward a certain set of solutions .",
    "we use the @xmath366 norm which tends to promote lagrangians with few non - zero coefficients .    when @xmath385 , the sparsity inducing effect of @xmath366-norm regularization allows to recover the true lagrangian ( @xmath390 ) which is indeed sparse .",
    "the solution of problem ( [ eq : primal1 ] ) involves a polynomial function @xmath67 which should in principle be close to the true value function @xmath383 . the @xmath67 function displayed in figure",
    "@xmath19 is close to @xmath40 .",
    "however , @xmath40 is not smooth around the origin and therefore its derivative is harder to approximate by polynomials around this point .",
    "hence the value of the error is higher around the origin .      .",
    "problems details are given in the main text .",
    "estimation error ( est ) is given in ( [ eq : metric ] ) .",
    "epsilon error ( eps ) is the value of @xmath100 in program ( [ eq : primal1 ] ) .",
    "trajectory sample size : 20 for a , a and b , 50 for c. degrees of @xmath376 and @xmath67 are 4 and 10 respectively.,scaledwidth=90.0% ]    these simulations are taken from @xcite .",
    "we consider the following free terminal time direct problems :    [ [ minimum - exit - time - in - dimension-2 ] ] minimum exit time in dimension 2 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath391    the optimal law is @xmath392 and the value function is @xmath393 .",
    "[ [ minimum - exit - norm - in - dimension-2 ] ] minimum exit norm in dimension 2 : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath394    the optimal law is @xmath395 and the value function is @xmath396 .",
    "[ [ minimum - time - brockett - integrator ] ] minimum time brockett integrator : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xmath397    recall that the brockett integrator of nonlinear systems control is also known ( up to a change of coordinates ) as the unicycle or dubins system , one of the simplest instance of a non - holonomic system in robotics , see e.g. @xcite for the connection .",
    "the optimal law and value function are described in @xcite .",
    "complementary details are found in appendix b of @xcite .",
    "[ [ data - generation ] ] data generation : + + + + + + + + + + + + + + + +    we consider the following settings :    * problem ( [ sec : pb2 ] ) with samples from @xmath398 ; * problem ( [ sec : pb2 ] ) with samples from @xmath399 ; * problem ( [ sec : pb3 ] ) with samples from @xmath398 ; * problem ( [ sec : pb4 ] ) with samples from @xmath400 .    in all cases",
    "we fix the degree of @xmath376 to @xmath401 and that of @xmath380 to @xmath402 .",
    "[ [ results ] ] results : + + + + + + + +    the results for the four problems are presented in figure [ fig : deterministic ] . for all problems",
    ", @xmath376 is of degree 4 .",
    "therefore , @xmath69 is to be found in a space of dimension 70 for problems a , a and 126 for problem @xmath403 .",
    "when the estimation error is close to 1 , we estimate a lagrangian @xmath376 that is orthogonal to @xmath373 ( in the monomial basis ) , and when it is close to @xmath20 , they are colinear .",
    "we also display the @xmath100 value of ( [ eq : primal1 ] ) .",
    "we consider that the estimation is reasonable , when both estimation error and @xmath100 values are low .",
    "@xmath0 for all problems we are able to recover the true lagrangian with good accuracy for some value of the regularization parameter @xmath375 . in the absence of regularization",
    ", we do not recover the true lagrangian at all .",
    "this highlights the important role of @xmath366 regularization which allows to bias the estimation toward _",
    "sparse polynomials_. the choice of @xmath375 in practical settings is subject to heuristics : numerical simulations or cross - validation which consists in keeping a portion of the input data as a validation set .",
    "@xmath0 for all four problems , when the estimation error is minimal , the value of @xmath100 is reasonably low , depending on how the value function can be approximated by a polynomial .",
    "for example , a shows lower @xmath100 value because we avoid sampling database points close to the non - differentiable point of the true value function .",
    "in example d , the value function is known to be harder to approximate by polynomials and the value of @xmath100 is a bit larger .",
    "the estimation accuracy is still very reasonable .",
    "the main contribution of this paper is to propose a general framework to analyze the inverse problem of optimal control .",
    "the analysis is based on the weak formulation of direct optimal control problems using occupation measures , relaxed hamilton - jacobi - bellman optimality conditions , and duality of infinite - dimensional linear programs .",
    "the proposed formulation is powerful enough to ensure that there is no gap between solutions of the direct and inverse problem ( theorem [ th : solution ] ) . to the best of our knowledge",
    "this is the first result of this kind .",
    "in addition , in principle the proposed methodology is applicable to practical problems where we only have access to sample trajectories .",
    "we have also proposed numerical and statistical approximation procedures from which solid theoretical guaranties can be obtained .",
    "finally we have illustrated our results on relatively simple ( but not trivial ) numerical examples of modest size .",
    "one of the most striking aspects of the inverse problem is its set of valid solutions . indeed , even for the simplest problems it is difficult to discriminate between physically meaningful lagrangians and spurious mathematical solutions .",
    "for this reason , formulating the inverse problem as a well - posed problem ( in particular with a unique solution ) requires the introduction of strong prior knowledge  sometimes arguably too restrictive  about the nature of the lagrangian to be recovered ; see for example @xcite .",
    "however the proposed formulation based on relaxed hjb - optimality conditions , allows to get intuitions about characteristics that affect well - posedness of the problem .",
    "this work is to be seen as a first step toward a theoretical and practical framework for the resolution of inverse problems in a variety of contexts .",
    "further aspects of the problem have to be investigated within this realm .",
    "first , we only deal with deterministic trajectories . for practical purposes",
    "it is essential to consider the effect of experimental noise , both from theoretical and practical perspectives , and to determine to which extent and how the problem can be solved in this more difficult context .",
    "second , we have proposed a numerical scheme to approximate solutions and show that it is effective on academic examples of modest size .",
    "experimental validation of such approximations should be carried out on real world examples of larger size .",
    "this involves a lot of data processing and fine tuning for each specific example .",
    "in this perspective , humanoid robotics provides an active and attractive field of application @xcite .",
    "this work was partly funded by an award of the _ simone and cino del duca foundation _ of institut de france , a grant of the gaspard monge program ( pgmo ) of the _ fondation mathmatique jacques hadamard_. most of this work was carried out during edouard pauwels postdoctoral stay at laas - cnrs .",
    "the authors would like to thank frdric jean , jean - paul laumond , nicolas mansard and ulysse serres for fruitful discussions .",
    "we develop uniform finite sample bounds that hold with high probability for arbitrary probability distribution in the context of polynomial functions .",
    "these are in particular useful to derive bounds for the random process described by occupation measures as exposed in section [ sec : discrete ] .",
    "the techniques used have become fairly standard in empirical process theory and statistical learning theory , see for example @xcite for a nice introduction .    in what follows",
    ", we consider a compact set @xmath404 with non empty interior . for",
    "a polynomial @xmath405 $ ] of degree @xmath406 , @xmath407 denotes its coefficients in the monomial basis ( of size @xmath408 ) .",
    "similarly for a point @xmath409 , @xmath410 denotes the @xmath408 dimensional vector representing the evaluation of the corresponding monomials at @xmath30 such that @xmath411 with the dot denoting the inner product .",
    "we consider the following set of polynomials @xmath412,\\ , q \\geq 0 \\:\\:\\text{on}\\:\\:z,\\ , \\int_{\\tilde{z } } q = 1 \\}$ ] where @xmath413 is a closed subset of @xmath414 with nonempty interior .",
    "we fix an arbitrary probability distribution @xmath415 on @xmath414 .",
    "we denote by @xmath416 the linear functional on the space @xmath417 such that @xmath418 similarly for a sample of size @xmath329 , @xmath419 , drawn _ iid _ from @xmath415 , we denote by @xmath420 the linear functional on the space @xmath417 such that @xmath421 for any function @xmath41 continuous on @xmath414 .",
    "the proof combines standard arguments from statistical learning which we describe here for completeness . in the sequel , given a probability distribution @xmath415 on @xmath414",
    ", we use the notation @xmath427 = \\int_a p(dz_1 ) \\ldots p(dz_n ) , \\quad { \\mathbb{e}}_z[f ] = \\int_a f(z_1,\\ldots , z_n ) p(dz_1 ) \\ldots p(dz_n)\\ ] ] and we rely on the following concentration result :    assume for all i = 1 ,  , n , @xmath428 then , for all @xmath429 , when @xmath430 is drawn iid from a probability distribution @xmath415 on @xmath414 , we have @xmath431| \\geq \\epsilon \\right ] \\leq 2 \\exp\\left ( - \\frac{2 \\epsilon^2}{n\\alpha^2 } \\right),\\ ] ] where the expectation is taken over the random sample .",
    "an equivalent formulation is that for @xmath422 , with probability @xmath424 , it holds that @xmath432 + \\alpha \\sqrt{\\frac{n}{2 } \\ln \\frac{2}{\\delta}}.\\ ] ] [ eq : thmcdiarmid ]    we consider the following quantity @xmath433 observe that @xmath434 is a subset of a finite dimensional space and that for @xmath435 , we have @xmath436 . since all norms are equivalent , @xmath434 is bounded in any given norm on polynomials , in particular , the supremum norm .",
    "therefore , the quantity @xmath437 is finite .",
    "we have that for all @xmath371 , and any @xmath438 and any @xmath435 @xmath439 therefore mcdiarmid s inequality of lemma [ eq : thmcdiarmid ] applies to function @xmath440 with @xmath441 , and , for any @xmath442 , with probability @xmath424 , it holds that @xmath443 + m_\\infty^d(z ) \\sqrt{\\frac{1}{2n } \\ln \\frac{2}{\\delta}}.           \\label{eq : intermediate1 }      \\end{aligned}\\ ] ] the left hand side depends on the random draw of the sample @xmath430 , but the right hand side is deterministic .",
    "we use a standard symmetrization argument to bound the expectation in the right hand side . using the definition of @xmath416 and @xmath420 , the convexity of the supremum and jensen s inequality , we have that @xmath444 & = { \\mathbb{e}}_z\\left[\\sup_{p \\in k_d(z ) } { \\mathbb{e}}_{z'}\\left[\\left\\langle \\ell_n',p\\right\\rangle\\right ] - \\left\\langle \\ell_n , p \\right\\rangle\\right]\\\\           & \\leq { \\mathbb{e}}_{z , z'}\\left[\\sup_{p \\in k_d(z ) } \\left\\langle \\ell_n ' - \\ell_n , p\\right\\rangle\\right ] \\nonumber\\\\          & = { \\mathbb{e}}_{z , z'}\\left[\\sup_{p \\in k_d(z ) } \\frac{1}{n } \\sum_{i=1}^n p(z_i ' ) - p(z_i)\\right]\\nonumber      \\end{aligned}\\ ] ] where the notation @xmath445 refers to any other sample @xmath446 drawn from @xmath415 and @xmath447 is the corresponding empirical measure .",
    "the _ iid _",
    "assumption allows to flip @xmath448 and @xmath449 in the expectation .",
    "let @xmath333 be rademacher variables , i.e. random variables which take values in @xmath386 , each with probability one half .",
    "we have @xmath450 \\\\           = & { \\mathbb{e}}_{z , z',\\xi}\\left[\\sup_{p \\in k_d(z ) } \\frac{1}{n } \\sum_{i=1}^n \\xi_i(p(z_i ' ) - p(z_i))\\right]\\nonumber\\\\          \\leq & { \\mathbb{e}}_{z , z',\\xi}\\left[\\sup_{p \\in k_d(z ) } \\frac{1}{n } \\sum_{i=1}^n \\xi_i p(z_i ' ) + \\sup_{p \\in k_d(z ) } \\frac{1}{n } \\sum_{i=1}^n -\\xi_i p(z_i)\\right ] \\nonumber\\\\          = & 2 { \\mathbb{e}}_{z,\\xi}\\left[\\sup_{p \\in k_d(z ) } \\frac{1}{n } \\sum_{i=1}^n \\xi_i p(z_i)\\right ] \\nonumber \\\\",
    "= & 2 { \\mathbb{e}}_{z,\\xi}\\left[\\sup_{p \\in k_d(z ) } \\frac{1}{n } c(p ) \\cdot \\sum_{i=1}^n \\xi_i v(z_i)\\right ] .",
    "\\nonumber      \\end{aligned}\\ ] ] the quantity on the right hand side is known as the rademacher complexity of the function class @xmath434 .",
    "intuitively , it measures to which extent elements of a function class correlate with random noise in a worst case scenario .",
    "the function @xmath451 is a norm on polynomials and since @xmath434 is bounded , the quantity @xmath452 is finite .",
    "moreover , since @xmath414 is compact , the quantity @xmath453 is also finite and attained .",
    "we have that @xmath454 moreover , @xmath455 = \\sum_{i=1}^n v(z_i)^2 $ ] ( @xmath456 = i(i = j)$ ] ) .",
    "therefore , using jensen s inequality ( with concavity of the square root ) , we obtain @xmath457 \\leq \\frac{m_c^d(x)}{n } \\sqrt{\\sum_{i=1}^n ||v(x_i)||_2 ^ 2 } \\leq \\frac{m_c^d(x ) m_v^d(x)}{\\sqrt{n}}.\\ ] ] putting things together , using inequalities ( [ eq : intermediate1 ] ) , ( [ eq : intermediate2 ] ) , ( [ eq : intermediate3 ] ) , we have that with probability @xmath424 , it holds @xmath458                                                                                a.s .",
    "puydupin - jamin , m.  johnson , and t.  bretl . a convex approach to inverse optimal control and its application to modeling human locomotion . international conference on robotics and automation , ieee , 2012 ."
  ],
  "abstract_text": [
    "<S> we address the inverse problem of lagrangian identification based on trajectories in the context of nonlinear optimal control . we propose a general formulation of the inverse problem based on occupation measures and complementarity in linear programming . </S>",
    "<S> the use of occupation measures in this context offers several advantages from the theoretical , numerical and statistical points of view . </S>",
    "<S> we propose an approximation procedure for which strong theoretical guarantees are available . </S>",
    "<S> finally , the relevance of the method is illustrated on academic examples . </S>"
  ]
}