{
  "article_text": [
    "future wireless systems should offer connectivity almost everywhere .",
    "this objective represents an ambitiously engineering challenge in scenarios where the direct link between two nodes does not have the desired quality , e.g. due to shadowing or distance . on that score , multi - hop communication for coverage extension and meshed network architectures",
    "are currently discussed or scheduled in all wireless networks standards of the next generation .",
    "therefore , the relay channel experiences a revival recently .",
    "the problem was introduced by van der meulen in @xcite in the early seventies .",
    "a few years later , cover and el gamal obtained the capacities of the physically degraded and reversely degraded relay channels and upper and lower bounds on the capacity of the general relay channel in @xcite .",
    "the general problem is still unsolved .",
    "fundamental insights about the general problem and recent development can be found in @xcite and references therein .",
    "we consider a three - node network where one node acts as a relay to enable the bidirectional communication between two other nodes .",
    "the two - way communication problem without a relay node was introduced by shannon in @xcite in 1961 already .",
    "therein , he obtained the capacity region for the average error for the restricted two - way channel , i.e. a feedback between the two nodes is not allowed . nowadays ,",
    "this is regarded as the first network information theory problem .    in information",
    "theory it is often assumed that the nodes can transmit and receive at the same time , i.e. full - duplex nodes .",
    "this assumption is in wireless communication hard to fulfill , since it is practically difficult to isolate a simultaneously received and transmitted signal using the same frequency sufficiently .",
    "therefore , in this work we assume half - duplex nodes . as a natural consequence of this assumption",
    "is that relay communication is performed in phases .",
    "often the relay communication should be integrated in existing infrastructures and most protocol proposals base usually on orthogonal components which require exclusive resources for each link . as a consequence",
    "they suffer from an inherent loss in spectral efficiency .",
    "this loss can be significantly reduced if bidirectional relay communication is desired .",
    "because then the communication can be efficiently performed in two phases . in the first phase , the multiple access phase ( mac ) , the information is transmitted to the relay node . in the succeeding broadcast phase ( bc ) , the relay node forwards the information to its destinations . in @xcite and @xcite , where gaussian channels are considered , the relay performs superposition encoding in the second phase .",
    "the knowledge of the first phase allows the receiving nodes to perform interference cancellation before decoding so that effectively we achieve interference - free transmission in the second phase .",
    "another interesting approach @xcite , @xcite is based on the network coding principle @xcite , @xcite where the relay node performs an xor operation on the decoded bit streams .",
    "but since network coding is originally a multi - terminal source coding problem , such an approach operates on the decoded data and therefore does not deal with channel coding aspects .",
    "because of our practical motivation , we apply time - division to separate the bidirectional relay communication into two phases .",
    "the optimal coding strategy and capacity region of the general multiple access channel is known . in this work ,",
    "we present the optimal broadcast coding strategy of the two - phase bidirectional relay channel based on classical channel coding .",
    "it shows that all rate pairs in the capacity region can be achieved using an auxiliary random variable taking two values , i.e. we achieve the capacity region by the principle of time - sharing .",
    "thereby , we see an interesting connection to a joint source and channel coding approach for the broadcast channel based on slepian - wolf coding @xcite .    in a multi - terminal system",
    "the average and maximal error capacity region can be different , even in the case of asymptotically vanishing errors as is shown by dueck in @xcite .",
    "while for single - user channels it is of no importance whether we use vanishing average or maximal probabilities of error in the definition of achievable rates , the choice of the error criterion makes a big difference if we pass to the consideration of the strong converses for one - way channels .",
    "indeed ahlswede demonstrated in @xcite that the strong converse does not hold for the compound channels if we use the average probability of error for the definition of @xmath3-achievable rates but it is well known that the strong converse is valid if we use maximal error probabilities as was shown by wolfowitz @xcite . for these reasons , we will pay a lot of attention to the consideration of the maximal and average error probabilities and the relation between them in the main part of the paper and in the proofs .",
    "the paper is organized as follows : in the following two subsections we present the two - phase bidirectional relay model , which describes the context of the bidirectional broadcast channel and after that we briefly restate the mac capacity region for completeness . in section [ sec : bccap ] we prove a coding theorem and a weak converse for the maximum error probability .",
    "the proof shows that the capacity region is independent of whether we use asymptotically vanishing average or maximum probability of error . in section [ sec : strongconv ] we prove the strong converse for the maximum error probability using the blowing - up lemma @xcite . finally , from this we can deduce that the @xmath0$]-capacity region in terms of average probability of error is constant for all @xmath0\\in ( 0,\\frac{1}{2})\\times ( 0,\\frac{1}{4})$ ] or @xmath4 and equals the @xmath0$]-capacity region defined with respect to maximum error probability in that range of values of @xmath0 $ ] .",
    "based on the capacity regions of the two phases the time - division between mac and bc phase can be optimized .",
    "this gives us the largest achievable rate region for the finite alphabet discrete memoryless bidirectional relay channel under the simplification of time - division into two phases , which will be discussed in section [ sec : discussion ] by means of a binary channel example .",
    "we consider a three - node network with two message sets @xmath5 and @xmath6 . in our bidirectional channel",
    "we want the messages @xmath7 located at node 1 and the message @xmath8 located at node 2 to be known at node 2 and node 1 , respectively .",
    "we assume that there is no direct channel between node 1 and 2 .",
    "therefore , node 1 and 2 need the support of a relay node r.        we simplify the problem by assuming an a priori separation of the communication into two phases .",
    "furthermore , we do not allow cooperation between the encoders at node 1 and node 2 . otherwise , a transmitted symbol could depend on previously received symbols . for a two - way channel",
    "this is known as a restricted two - way channel . with this simplification",
    "we end up with a multiple access phase , where node 1 and 2 transmit messages @xmath9 and @xmath10 to the relay node , and a broadcast phase , where the relay forwards the messages to node 2 and 1 , respectively .",
    "we look at the two phases separately . after that we will briefly consider the optimal time - division between the two phases .    in the multiple access phase ( mac )",
    "we have a classical multiple access channel , where the optimal coding strategy and capacity region @xmath11 is known @xcite , @xcite .",
    "we will restate the capacity region in the next subsection .",
    "thereby , let @xmath12 and @xmath13 denote the achievable rates between node 1 and 2 and the relay node in the mac phase .    for the broadcast phase ( bc )",
    ", we assume that the relay node has successfully decoded the messages @xmath9 and @xmath10 in the multiple access phase . from the union",
    "bound we know that the error probability of the two - phase protocol is at most the sum of the error probability of each phase .",
    "therefore , an error - free mac phase is reasonable if we assume rates within the mac capacity region and a sufficient coding length . from this",
    "we have a broadcast channel where the message @xmath9 is known at node 1 and the relay node and the message @xmath10 is known at node 2 and the relay node , as depicted in figure [ fig : model ] .",
    "thereby , let @xmath14 , @xmath15 and @xmath16 denote the input and @xmath17 , @xmath18 and @xmath19 the output symbols of node 1 , node 2 , and the relay node , respectively .",
    "furthermore , let @xmath20 and @xmath21 denote the achievable rates between the relay node and node 1 and 2 in the bc phase .",
    "the mission of the relay node is to broadcast a message to node 1 and 2 which allows them to recover the unknown source .",
    "this means that node 1 wants to recover message @xmath10 and node 2 wants to recover message @xmath9 .",
    "we will present an information theoretic optimal coding strategy and the capacity region of the bidirectional broadcast channel in section [ sec : bccap ] .      in this subsection",
    ", we restate the capacity region of the multiple access channel , which was found by ahlswede @xcite and liao @xcite and is part of any textbook on multiuser information theory , e.g. @xcite .    a _ discrete memoryless multiple access channel _ is the family @xmath22 with finite input alphabets @xmath23 , @xmath24 , and the finite output alphabet @xmath25 where the probability transition functions are given by @xmath26 for a given probability transition function @xmath27 .",
    "the capacity region @xmath11 of the memoryless multiple access channel is the set of all rate pairs @xmath28 $ ] satisfying @xmath29 for random variables @xmath30 $ ] with values in @xmath31 and joint distribution @xmath32 .",
    "furthermore , the range @xmath33 of the auxiliary random variable @xmath34 has a cardinality bounded by @xmath35 .",
    "in this section we present our main result , the capacity region of a broadcast channel where the receiving nodes have perfect knowledge about the message which should be transmitted to the other node .",
    "the capacity region can be achieved by classical channel coding principles .",
    "first we need to introduce some standard notation .",
    "let @xmath36 and @xmath37 , @xmath24 , be finite sets .",
    "a _ discrete memoryless broadcast channel _ is defined by a family @xmath38 of probability transition functions given by @xmath39 for a probability transition function @xmath40 , i.e. @xmath41 is a stochastic matrix .    in what follows",
    "we will suppress the super - index @xmath42 in the definition of the @xmath42-th extension of the channel @xmath43 , i.e. we will write simply @xmath43 instead of @xmath44 .",
    "this should cause no confusion since it will be always clear from the context which block length is under consideration .",
    "in addition , we will use the abbreviation @xmath45 , where @xmath46 and @xmath47 denote the message sets .    a @xmath48-code for the _ bidirectional broadcast channel _ consists of one encoder at the relay node @xmath49 and a decoder at node one and two @xmath50 the element @xmath51 in the definition of the decoders is included for convenience only and plays the role of an erasure symbol .",
    "when the relay node sends the message @xmath52 $ ] , the receiver of node one is in error if @xmath53 .",
    "the probability of this event is denoted by @xmath54.\\ ] ] accordingly , we denote the probability that the receiver of node two is in error by @xmath55.\\ ] ] hereby , @xmath56 and @xmath57 denote the random outputs at nodes @xmath58 and @xmath59 given that the sequence @xmath60 has been sent down the channel .",
    "this allows us to introduce the notation for the maximum and average probability of error for the @xmath61-th node @xmath62    a rate pair @xmath63 $ ] is said to be _ achievable _ for the bidirectional broadcast channel if for any @xmath64 there is an @xmath65 and a sequence of @xmath48-codes such that for all @xmath66 we have @xmath67 and @xmath68 while @xmath69 when @xmath70 .",
    "the set of all achievable rate pairs is the _ capacity region _ of the bidirectional broadcast channel and is denoted by @xmath71 .",
    "achievable rate pairs and a capacity region can be also defined for average probability of error .",
    "[ theorem : capacity ] the capacity region @xmath71 of the bidirectional memoryless broadcast channel is the set of all rate pairs @xmath63 $ ] satisfying @xmath72 for random variables @xmath73 $ ] with values in @xmath74 and joint probability distribution @xmath75 .",
    "the cardinality of the range of @xmath34 can be bounded by @xmath35 .",
    "the theorem is proved in the following three subsections . in the first subsection",
    "we prove the achievability , i.e. a coding theorem .",
    "we prove a weak converse with respect to the maximum probability of error in the second subsection .",
    "then the theorem is proved with the third subsection where we show that a cardinality of two is enough for the range of the auxiliary random variable .      here",
    ", we adapt the random coding proof for the degraded broadcast channel of @xcite to our context . first , we prove the achievability of all rate pairs @xmath63 $ ] satisfying @xmath76 for some probability function @xmath77 .",
    "then , we extend this to prove that all points in the closure of the convex hull of are achievable , which we will see is exactly the region stated in theorem [ theorem : capacity ] .",
    "we generate @xmath78 independent codewords @xmath79 , @xmath52 $ ] of length @xmath42 with @xmath80 and @xmath81 according to @xmath82 .      to send the pair @xmath52 $ ] with @xmath83 , @xmath24 , the relay sends the corresponding codeword @xmath60 .",
    "the receiving nodes use typical set decoding .",
    "first , we characterize the decoding sets . for the decoder at node @xmath24 let @xmath84 with average mutual information",
    "@xmath85 $ ] .",
    "this gives the decoding set @xmath86 and indicator function @xmath87 when @xmath60 with @xmath52 $ ] has been sent , and @xmath88 and @xmath89 have been received we say that the decoder at node @xmath61 makes an error if either @xmath60 is not in @xmath90 ( occurring with probability @xmath91 ) or if at node one @xmath92 with @xmath93 is in @xmath94 or at node two @xmath95 with @xmath96 is in @xmath97 ( occurring with @xmath98 ) . if there is no or more than one codeword @xmath99 or @xmath100 , the decoders map on the erasure symbol @xmath51 .      from the union",
    "bound we have @xmath101 with @xmath102 and @xmath103    for uniformly distributed messages @xmath104 and @xmath105 we define @xmath106 for @xmath107 so that @xmath108 .",
    "next , we average over all codebooks , i.e. @xmath109 \\leq{{\\mathbbm{e}}}_{x^n}[p_{e , k}^{(1)}+p_{e , k}^{(2)}]$ ] .    in the following ,",
    "we show that if @xmath110 for any @xmath111 , we have @xmath112\\rightarrow 0 $ ] when @xmath113 .",
    "we have @xmath114= & \\frac{1}{|{{\\cal{w}}}_1|\\,|{{\\cal{w}}}_2|}\\sum_{v\\in{{\\cal{w}}}_1\\times{{\\cal{w}}}_2 } { { \\mathbbm{e}}}_{x^n}[p_{e , k}^{(1)}(v)]\\\\ \\underset{\\text{fixed } v}{\\overset{\\text{for any}}{= } } & \\sum\\limits_{y_k^n\\in{{\\cal{y}}}^n_k } { { \\mathbbm{e}}}_{x^n}[p(y_k^n|x^n(v))\\,d(x^n(v),y_k^n)]\\\\ = & \\sum\\limits_{y_k^n\\in{{\\cal{y}}}^n_k}\\sum\\limits_{x^n\\in{{\\cal{x}}}^n } p(x^n)p(y_k^n|x^n)\\,d(x^n , y_k^n)\\\\ = & { { \\mathbbm{e}}}_{x^n , y_k^n}[d(x^n , y_k^n)]={{\\mathbbm{p}}}[d(x^n , y_k^n)=1]\\\\ = & { { \\mathbbm{p}}}\\left [ i(x^n;y_k^n)\\leq\\tfrac{r_{\\overrightarrow{\\mathrm{r}k}}+i(x;y_k)}{2 } \\right]\\\\ \\leq&{{\\mathbbm{p}}}\\left [ i(x^n;y_k^n)\\leq i(x;y_k)-{{\\varepsilon}}\\right]\\underset{n\\to\\infty}{\\longrightarrow } 0 \\end{split}\\ ] ] exponentially fast by the law of large numbers . for the calculation of @xmath115",
    "$ ] we have to distinguish between the receiving nodes .",
    "we present the analysis for @xmath116 , the case @xmath117 follows accordingly .",
    "thereby , we use the fact that for @xmath52\\neq[w_1,\\hat{w}_2]$ ] the random variables @xmath118 and @xmath119 are independent for each choice of @xmath120",
    ". @xmath121= \\frac{1}{|{{\\cal{w}}}_1|\\,|{{\\cal{w}}}_2|}\\sum_{v\\in{{\\cal{w}}}_1\\times{{\\cal{w}}}_2 } { { \\mathbbm{e}}}_{x^n}[p_{e,1}^{(2)}(v)]\\\\ & \\underset{\\text{fixed } v}{\\overset{\\text{for any}}{= } } \\sum\\limits_{y_1^n\\in{{\\cal{y}}}^n_1 } \\!\\!\\!{{\\mathbbm{e}}}_{x^n}\\!\\big [ p(y_1^n|x^n(v))\\!\\!\\ ! \\sum\\limits_{\\substack{\\hat{w}_2=1\\\\\\hat{w}_2\\neq w_2}}^{|{{\\cal{w}}}_2| } \\big(1-d(x^n(w_1,\\hat{w}_2),y_1^n)\\big ) \\big]\\\\ & = \\sum\\limits_{y_1^n\\in{{\\cal{y}}}^n_1}\\!\\ ! \\sum\\limits_{\\substack{\\hat{w}_2=1\\\\\\hat{w}_2\\neq w_2}}^{|{{\\cal{w}}}_2|}\\!\\ ! { { \\mathbbm{e}}}_{x^n}\\!\\!\\big[p(y_1^n|x^n(v))\\big ] { { \\mathbbm{e}}}_{x^n}\\!\\!\\big[1-d(x^n(w_1,\\hat{w}_2),y_1^n ) \\big]\\\\ & \\;=\\sum\\limits_{y_1^n\\in{{\\cal{y}}}^n_1 } \\sum\\limits_{\\substack{\\hat{w}_2=1\\\\\\hat{w}_2\\neq w_2}}^{|{{\\cal{w}}}_2| } p(y_1^n ) { { \\mathbbm{e}}}_{x^n}\\big[1-d(x^n(w_1,\\hat{w}_2),y_1^n ) \\big ] \\end{split}\\ ] ] @xmath122 whenever @xmath123 , we have @xmath124 or @xmath125 .",
    "consequently , @xmath126&<|{{\\cal{w}}}_2|\\sum\\limits_{y_1^n\\in{{\\cal{y}}}^n_1 } \\sum\\limits_{x^n\\in{{\\cal{s}}}(y_1^n)}p(x^n)p(y_1^n|x^n)2^{-\\frac{n}{2}({r_{\\mathrm{\\overrightarrow{\\mathrm{r}1}}}}+i(x;y_1))}\\\\ & \\leq2^{n{r_{\\mathrm{\\overrightarrow{\\mathrm{r}1}}}}}2^{{-n}(\\frac{1}{2}{r_{\\mathrm{\\overrightarrow{\\mathrm{r}1}}}}+\\frac{1}{2}i(x;y_1 ) ) } = 2^{{n}(\\frac{1}{2}{r_{\\mathrm{\\overrightarrow{\\mathrm{r}1}}}}-\\frac{1}{2}i(x;y_1))}\\leq2^{-n{{\\varepsilon}}}\\underset{n\\to\\infty}{\\longrightarrow } 0 \\end{split}\\ ] ] hence , if @xmath127 , @xmath24 , the average probability of error , averaged over codebooks and codewords , gets arbitrary small for sufficiently large block length @xmath42 .",
    "if @xmath128 and @xmath129 we can choose @xmath111 and @xmath130 so that we have @xmath131<{{\\varepsilon}}$ ] . since the average probabilities of error over the codebooks is small , there exists at least one codebook @xmath132 with a small average probabilities of error @xmath133 .",
    "this implies that we have @xmath134 and @xmath135 .",
    "we define sets @xmath136 since @xmath137 , we can bound the cardinality @xmath138 for @xmath24 .",
    "then from @xmath139 it follows @xmath140    now , let @xmath141 be the set of @xmath9 having the property that for each @xmath9 there are at least @xmath142 choices of @xmath10 so that @xmath143\\in{{\\cal{q}}}$ ] .",
    "therefore , for @xmath144 there are at most @xmath145 choices @xmath146 and for @xmath147 there are less than @xmath148 choices @xmath146 such that @xmath143\\in{{\\cal{q}}}$ ] .",
    "accordingly , we have @xmath149 so that it follows that @xmath150 using @xmath151 .",
    "this means that there exists an index set @xmath152 with @xmath153 indices @xmath9 , to each of which we can find an index set @xmath154 with @xmath148 indices @xmath10 so that we have for each @xmath155 and @xmath156 a maximum error @xmath157 , @xmath24 .",
    "it follows that there exist one - to - one mappings @xmath158 , @xmath159 , @xmath160 for each @xmath155 with @xmath161 $ ] with sets @xmath162 , @xmath163 for @xmath24 , @xmath164\\in{{\\cal{v}}}:w_1\\in{{\\cal{q}}}_1^\\star , w_2\\in{{\\cal{q}}}_2^\\star(w_1)\\}\\subset{{\\cal{q}}}$ ] .",
    "accordingly , there exist mappings @xmath165 , @xmath24 , with @xmath166 $ ] .",
    "this allows us finally to define a @xmath167-code with an encoder @xmath168 with @xmath169 and decoders @xmath170 and @xmath171 with @xmath172 and @xmath173 where we use the mappings @xmath174 given by @xmath175 for @xmath24 .",
    "the idea is that the encoder uses only codewords @xmath176 of the code @xmath177 with an index @xmath178 , which have a maximum error @xmath179 , @xmath24 .",
    "since the decoders use the typical set decoder of the code @xmath177 , they could erroneously find an @xmath176 with @xmath180 . in this case",
    ", the mapping @xmath181 decides on the erasure symbol @xmath51 .",
    "it was already a wrong decision by the decoder @xmath182 , since the encoder chooses only codewords @xmath176 with @xmath178 .",
    "therefore , this does not add any error to the decoding .",
    "the code has a rate pair @xmath183 $ ] , which can be made arbitrary close to @xmath63 $ ] when @xmath70 .",
    "this proves the achievability of any rate pair satisfying the equation .",
    "let @xmath184 denote the set of rates which we can achieve with the input distribution @xmath185 .",
    "since the cardinality of the input set @xmath36 is finite , the rate region @xmath186 is bounded .    for @xmath24 , we can rewrite the right hand side of as follows @xmath187 where in @xmath188 we choose a specific input distribution @xmath189 according to the auxiliary random variable @xmath34 . for the input distribution",
    "@xmath189 we know from the first part of the proof that any rate pair @xmath190 is achievable . therefore , for any convex combination @xmath191 we can regard the weights as probability mass function with @xmath192 and @xmath193 and choose for any @xmath194 an input distribution @xmath189 that achieves the rate pair @xmath195 .",
    "for that reason , the conditional mutual informations given by the right hand sides of are also achievable rates .",
    "the coding theorem usually offers a hint how to design a good channel code practically .",
    "accordingly , in @xcite an interesting coset coding strategy for symmetric channels is discussed",
    ".    in general in multi - terminal system the average and maximal error capacity region can be different .",
    "ahlswede has shown for the two - way channel in @xcite that `` one can not reduce a code with average errors to a code with maximal errors without an essential loss in code length or error probability , whereas for one - way channels it is unessential whether one uses average or maximal errors . ''",
    "the problem in the two - way channel is to find a maximal error sub - code with a cartesian product structure .",
    "this problem is equivalent to a combinatorial problem by zarankiewicz and arises since the transmitter and receiver have partial knowledge only . here",
    ", the relay node has full knowledge so that for the code construction with arbitrarily small maximum probability of error we need not require a sub - code with cartesian product structure .    in the next subsection",
    "we prove the weak converse for the maximal error .",
    "since the fano s inequalities apply for the average error as well , the weak converse for the average error follows analogously .",
    "we have to show that any given sequence of @xmath48-codes with @xmath69 must satisfy @xmath196 and @xmath197 for a joint probability distribution @xmath198 @xmath199 . for a fixed block length @xmath42",
    "we define the joint probability distribution @xmath200 @xmath201 on @xmath202 where the conditional distribution @xmath203 if @xmath204 is the codeword corresponding to @xmath205 or is equal to @xmath51 else . in what follows we consider for @xmath24",
    "uniformly distributed random variables @xmath206 with values in @xmath207 .",
    "[ lemma : fano ] for our context we have the fano s inequality @xmath208 with @xmath209 for @xmath70 as @xmath210 .    from @xmath56 and @xmath104 node 1",
    "estimates the index @xmath105 from the sent codeword @xmath211 .",
    "we define the event of an error at node 1 as @xmath212 so that we have for the mean probability of error @xmath213\\leq\\lambda_1^{(n)}$ ] . from the chain rule for entropies we have @xmath214",
    "since @xmath215 is a function of @xmath216 and @xmath56 , we have @xmath217 .",
    "further , since @xmath215 is a binary - valued random variable , we get @xmath218 . so that finally with the next inequality @xmath219h(w_2|y_1^n , w_1,e_1=0 ) + { { \\mathbbm{p}}}[e_1=1]h(w_2|y_1^n , w_1,e_1=1)\\nonumber\\\\ & \\leq(1-\\mu_1^{(n)})0+\\mu_1^{(n)}\\log(|{{\\cal{w}}}_2|-1 ) \\leq\\lambda_1^{(n ) } \\log|{{\\cal{w}}}_2|\\nonumber\\end{aligned}\\ ] ] we get fano s inequality for our context .",
    "therewith , we can bound the entropy @xmath220 as follows @xmath221 where the equations and inequalities follow from the independence of @xmath104 and @xmath105 , the definition of mutual information , lemma 1 , the chain rule for mutual information , the positivity of mutual information , and the data processing inequality .",
    "if we divide the inequality by @xmath42 we get the rate @xmath222 using the memoryless property and again standard arguments .",
    "a similar derivation for the source rate @xmath223 gives us the bound @xmath224 with @xmath225 for @xmath226 as @xmath227 .",
    "this means that the entropies @xmath228 and @xmath220 are bounded by averages of the mutual informations calculated at the empirical distribution in column @xmath229 of the codebook .",
    "therefore , we can rewrite these inequalities with an auxiliary random variable @xmath34 , where @xmath230 with probability @xmath231 .",
    "we finish the proof of the converse with the following inequalities @xmath232 and @xmath233 accordingly where @xmath234 , @xmath24 , when @xmath70 .",
    "thereby , @xmath235 and @xmath236 are new random variables whose distribution depend on @xmath34 in the same way as the distributions of @xmath237 and @xmath238 depend on @xmath229 .    up to now the auxiliary random variable @xmath34 is defined on a set @xmath33 with arbitrary cardinality .",
    "next , we will show that @xmath239 is enough .      with fenchel ",
    "bunt s extension of carathodory s theorem it follows that any rate pair in @xmath240 is achievable by time - sharing between two rate pairs from @xmath186 , i.e. @xmath239 is enough .",
    "[ theo : fenchel ] if @xmath241 has no more than @xmath42 connected components ( in particular , if @xmath242 is connected ) , then any @xmath243 can be expressed as a convex combination of @xmath42 elements of @xmath242 .    since for any @xmath244",
    "we have @xmath245\\in{{\\cal{r}}}(p(x))$ ] , the set @xmath186 is connected .",
    "therefore , any rate pair in @xmath246 can be expressed as a convex combination of @xmath247 rate pairs of @xmath186 .",
    "this finishes the proof of the capacity region of the bidirectional broadcast channel .    since the coding theorem includes the achievability of rate pairs in terms of the average probability of error and the proof of the weak converse for the average error works analogously",
    ", @xmath71 is also the capacity region in terms of average probability of error .",
    "the characterization of the bidirectional broadcast capacity region for gaussian channels is analogous .",
    "we would have to deal with discrete channels with gaussian channel transfer distributions and would have to add an input power constraints but the arguments are similar to the arguments considered here .",
    "in the next section we present the strong converse in the case of maximum probability error . therefore , we will refine the achievability definition to @xmath0$]-achievable rate pairs .",
    "then it follows from the strong converse for the maximum probability of error that the @xmath0$]-capacity region is equal @xmath71 .",
    "finally , from this we can deduce on the @xmath0$]-capacity region in terms of average probability of error for sufficiently small average error .",
    "here , we derive a sharper converse to the coding theorem for the bidirectional broadcast channel .",
    "we prove the full strong converse for the capacity region defined with respect to the maximum error probability , i.e. @xmath248 for all @xmath249 .",
    "additionally , we show that the @xmath0$]-capacity region @xmath250 defined by using average error probability coincides with @xmath71 for _ small values _ of @xmath249 .    the main tool we will use is the powerful blowing - up technique introduced by ahlswede , gcs and krner in @xcite based on the blowing - up lemma ( cf .",
    "paper @xcite for a simpler information - theoretic proof ) .",
    "the basic idea developed in @xcite is that blowing - up the decoding sets in conjunction with a variant of fano s inequality allows us to convert the weak converse into the strong converse to the coding theorem .    before entering the proof we recall the essential blowing - up notations and results which we need in the sequel : for a finite set @xmath251 , @xmath252 and @xmath253 we define the _ hamming l - neighborhood _ by @xmath254 where @xmath255 denotes the non - normalized hamming metric and @xmath256 .",
    "[ blowing - up ] let @xmath257 and @xmath251 be finite sets",
    ".    1 .   for any sequence of positive integers @xmath258 with @xmath259 there exists a sequence @xmath260 with @xmath261 such that for any @xmath262 @xmath263 2 .",
    "( blowing - up lemma ) to any sequence @xmath264 with @xmath265 there exist a sequence of positive integers @xmath266 with @xmath259 and a sequence @xmath267 with @xmath268 such that for every probability transition function @xmath269 and every @xmath270 , @xmath271 @xmath272 where @xmath273 denotes the @xmath42-th memoryless extension of @xmath43 .",
    "the second part of theorem [ blowing - up ] is the _ uniform version _ of the blowing - up lemma according to csiszar / krner @xcite chap .",
    "1.5 .    since blowing up",
    "is an operation on the subsets of the output alphabet it is convenient to describe the decoding functions @xmath274 and @xmath275 by decoding sets .",
    "this equivalent description is obtained as follows ; for each fixed @xmath276 the map @xmath277 induces a partition @xmath278 of @xmath279 . in a similar fashion for each @xmath280",
    "we obtain , using the decoder @xmath275 , a partition @xmath281 of the output set @xmath282 . now",
    "if we are given the corresponding encoder @xmath283 , the probabilities of error can be expressed by @xmath284 and @xmath285 in what follows @xmath286 , @xmath24 , denotes the maximum probability of error for a given code .",
    "a pair of non - negative reals @xmath63 $ ] is said to be @xmath0$]-achievable , @xmath249 , if for each @xmath287 there is a sequence of @xmath288-codes such that for all sufficiently large @xmath42 the following statements are fulfilled    1 .",
    "@xmath289 and @xmath290 .",
    "2 .   @xmath291 for @xmath24 .",
    "the set of all @xmath0$]-achievable rates with respect to the maximum probability of error is denoted by @xmath292 .",
    "it is clear that @xmath293 and @xmath294 hold .",
    "the content of the strong converse is that @xmath71 can not be a proper subset of @xmath292 for @xmath249 :    [ strong - converse - max - error ] for memoryless bidirectional broadcast channel we have @xmath295 for all @xmath249 .",
    "let @xmath63 $ ] be an @xmath0$]-achievable rate pair , thus , by definition , for any @xmath287 we can find a sequence of @xmath288-codes and @xmath65 such that for all @xmath66 following conditions are satisfied :    1 .",
    "@xmath289 and @xmath290 .",
    "2 .   @xmath291 for @xmath24 .    for those @xmath42",
    "we consider the families of partitions associated with the decoder maps , i.e. for each @xmath276 we have a partition @xmath296 of @xmath279 and analogously for each @xmath8 a partition @xmath297 of @xmath282 such that for all @xmath298 and @xmath146 we have @xmath299 and @xmath300 where @xmath301 .",
    "according to the second part of theorem [ blowing - up ] we can find a sequence of positive integers @xmath258 with @xmath259 such that for the sets @xmath302 we have @xmath303 and @xmath304 with @xmath268 .",
    "the sets @xmath305 are not necessarily disjoint for different values of @xmath10 .",
    "the same applies to the sets @xmath306 .",
    "nevertheless , we show now that for any given @xmath276 each @xmath307 is contained in at most sub - exponentially many @xmath308 . to this end , for any given @xmath309 and @xmath7 we define the set @xmath310 and claim that @xmath311 holds . the proof is given in @xcite .",
    "we reproduce the full argument for convenience .",
    "it is obvious that @xmath312 if and only if @xmath313 .",
    "therefore , since the sets @xmath314 are disjoint , we have @xmath315 with @xmath316 by the first part of theorem [ blowing - up ] .",
    "a similar result holds for the analogously defined set @xmath317 .",
    "let us consider two independent , uniformly distributed random variables @xmath104 and @xmath105 taking values in the sets @xmath5 and @xmath6 and a random variable @xmath318 with values in @xmath319 such that @xmath320 then the probability distribution of the whole system is given by @xmath321 for @xmath322 , @xmath323 , @xmath324 and @xmath24 .",
    "furthermore , for given @xmath307 and @xmath276 let us define @xmath325 as in the proof of the weak converse one can show that @xmath326 holds .",
    "now , we need a variant of fano s inequality which incorporates the quantity defined in ( [ sc-2 ] ) . therefore , we use the following elementary entropy inequality : for a probability distribution @xmath43 on a finite set @xmath327 and an arbitrary @xmath328 we have @xmath329 then for given @xmath17 and @xmath9 we set @xmath330 and obtain @xmath331 where we have applied eq .",
    "( [ sc-4 ] ) to each sum and then used eq .",
    "( [ sc-1 ] ) with the abbreviation @xmath332 .",
    "@xmath333 denotes the entropy of the distribution @xmath334 . averaging with respect to @xmath335 and using the concavity of the entropy we arrive at @xmath336 with @xmath337 .",
    "note that by ( [ sc-2 ] ) , our definition of @xmath318 in eq .",
    "( [ sc - x ] ) and ( [ sc - y ] ) we have @xmath338 where the third equality holds since @xmath339 iff @xmath340 and the last inequality is by eq .",
    "( [ sc-0 ] ) . thus ( [ sc-3 ] ) , ( [ sc-6 ] ) and ( [ sc-7 ] ) show that @xmath341 similar reasoning shows that @xmath342 also holds .",
    "it is obvious that as in the proof of the weak converse the mutual informations on the right hand sides of ( [ sc-8 ] ) and ( [ sc-9 ] ) can be written as @xmath343 and @xmath344 for a suitable random variable @xmath345 taking values in @xmath346 .",
    "note that by the proof of the coding theorem with the weak converse the rates @xmath347 and @xmath348 are achievable .",
    "thus , we can conclude our proof by noting that for sufficiently large @xmath42 we have @xmath349 and @xmath350 and that @xmath71 is closed .",
    "this shows that @xmath351 and we are done .",
    "we give now the partial extension of theorem [ strong - converse - max - error ] to the capacity region @xmath250 which is defined similarly to @xmath292 the difference being only that we use the average probability of error .",
    "our strategy will be to reduce the statement to the theorem [ strong - converse - max - error ] for sufficiently small @xmath249 .    for memoryless",
    "bidirectional broadcast channel it holds that @xmath352 for all @xmath353 and @xmath354 or @xmath355 and @xmath356 .",
    "let @xmath63\\in { { { \\cal{c}}}_{\\mathrm{bc , av}}}({{\\varepsilon}}_1,{{\\varepsilon}}_2)$ ] with @xmath353 and @xmath354 .",
    "thus , for each @xmath287 there is a sequence of @xmath357-codes and @xmath358 with    1 .",
    "@xmath289 and @xmath290 .",
    "2 .   @xmath359 for @xmath24 ,    for all @xmath66 where @xmath360 denotes the average error probability .",
    "it is clear that @xmath361 iff @xmath362 and @xmath363 iff @xmath364 . therefore , we can choose real numbers @xmath365 with @xmath366 and @xmath367 with @xmath368 .",
    "let us consider the reals @xmath369 for @xmath24 .",
    "if we define the sets @xmath370 for @xmath24 , from the markov s inequality it is clear that @xmath371 with @xmath372 for @xmath24 .",
    "for the set @xmath373 we obtain the following cardinality bound by ( [ sc - av-1 ] ) : @xmath374 let @xmath375 our goal now is to find a lower bound on the cardinality of @xmath376 .",
    "to this end , note that for @xmath377 there are at most @xmath378 message indices @xmath280 with @xmath379 and for @xmath380 there are at most @xmath381 message indices @xmath8 with @xmath379 .",
    "thus by ( [ sc - av-2 ] ) @xmath382 and therefore @xmath383 the first factor on the right hand side of ( [ sc - av-3 ] ) is positive due to our restriction to @xmath353 and @xmath384 .",
    "indeed , it is easily seen that @xmath385 iff @xmath386 and this last relation is true by our choice of @xmath387 which is possible due to our restriction to @xmath353 .",
    "similarly , we have @xmath388 iff @xmath389 which is satisfied since @xmath354 .",
    "now we set @xmath390 and @xmath391 as in the proof of the direct part of the coding theorem we can construct a sequence of @xmath392-codes from the given sequence of codes but with the additional property that the new sequence has the _ maximum _ error probabilities bounded by @xmath393 and @xmath394 .",
    "the new sequence of codes achieves the rate pair @xmath63 $ ] .",
    "thus , we can apply our theorem [ strong - converse - max - error ] to conclude that for @xmath353 and @xmath395 @xmath63\\in { { { \\cal{c}}}_{\\mathrm{bc}}}$ ] .",
    "if we interchange the roles of @xmath5 and @xmath6 in definition of the set @xmath376 in ( [ sc - av - t ] ) and at the same time swap the numbers @xmath393 and @xmath394 , we can conclude in a similar fashion that @xmath396 for @xmath355 and @xmath356 .",
    "the coding principles of the bidirectional broadcast are similar to the network coding approach where we would have implemented a bitwise xor operation on the decoded messages at the relay node @xcite , @xcite .",
    "but since network coding @xcite , @xcite is originally a multi - terminal source coding problem , the achievable rates in the broadcast phase using the network coding approach are limited by the worst receiver .",
    "this means that with a network coding approach we can achieve @xmath397 for some common input distribution @xmath185 .",
    "the achievable rates depend on the common input distribution and _ both _ channel transfer distributions . for our coding scheme",
    "each achievable rate depends on the common input distribution and its own channel transfer distribution only . for each channel",
    "we can separately find the optimal input distribution which achieves the maximal achievable rate for this link ( equal to the single link capacity ) , but the optimal input distribution for one channel needs not be optimal for the other channel .",
    "accordingly , we see that the network coding approach using xor on the decoded messages at the relay is in general inferior , but it achieves the capacity of the bidirectional broadcast if and only if for the maximizing input distribution @xmath398 we have @xmath399 .    in the following we will discuss the bidirectional broadcast for a binary symmetric broadcast channel and the achievable rate region of two - phase bidirectional relaying protocol .      for the binary symmetric broadcast channel , let @xmath400 and @xmath401 denote the probability that a relay input @xmath402 is complemented at the output @xmath403 and @xmath404 of node 1 and 2 respectively . from (",
    "* chapter 8.1.4 ) we know that a uniform input distribution maximizes the binary symmetric channel .",
    "therefore , the broadcast capacity region for the binary symmetric channel is given by @xmath405\\times [ 0,1-h(p_1 ) ] , \\label{eq : bsbc}\\ ] ] which includes the region @xmath406\\times[0,1-\\max\\{h(p_1),h(p_2)\\}]$ ] achievable using xor at the relay node according to @xcite .",
    "we will now look at the achievable bidirectional rate region where we use in each phase the optimal strategies .",
    "thereby , we optimize the time - division between the mac phase with memoryless multiple access channel @xmath407 and bc phase with memoryless broadcast channel @xmath199 . of course ,",
    "due to the a priori separation into two phases , this strategy need not be the optimal strategy for the bidirectional relay channel .",
    "let @xmath408 and @xmath409 denote the achievable rates for transmitting a messages @xmath9 from node 1 to node 2 and a message @xmath10 from node 2 to node 1 with the support of the relay node . in more detail , node 1 wants to transmit message @xmath9 with rate @xmath410 in @xmath42 channel uses of the bidirectional relay channel to node 2 .",
    "simultaneously , node 2 wants to transmit message @xmath10 with rate @xmath411 in @xmath42 channel uses to node 1 .",
    "then let @xmath412 and @xmath413 denote the number of channel uses in the mac phase and bc phase with the property @xmath414 $ ] and @xmath415 when @xmath70 , respectively .",
    "we call @xmath416 the time - division factor between multiple access and broadcast phase . with a sufficient block length @xmath42 ( respectively @xmath412 and @xmath417 ) we can achieve a bidirectional transmission of messages @xmath9 and @xmath10 with arbitrary small decoding error if rate pairs @xmath28\\in{{{\\cal{c}}}_{\\mathrm{mac}}}$ ] and @xmath63\\in{{{\\cal{c}}}_{\\mathrm{bc}}}$ ] exist so that we have @xmath418 thus , the achievable rate region of the bidirectional relay channel using time - division is given by the set of all rate pairs @xmath419 $ ] which are achievable with any time - division factor @xmath420 $ ] as @xmath70 .",
    "we collect the previous consideration in the following proposition .",
    "the achievable rate region @xmath421 of the two - phase bidirectional relay channel is given by @xmath422\\in{{\\mathbbm{r}}}^2 : r_1\\leq \\min\\{\\alpha { r_{\\mathrm{\\overrightarrow{1\\mathrm{r}}}}},(1-\\alpha ) { r_{\\mathrm{\\overrightarrow{\\mathrm{r}2}}}}\\},\\\\ & r_2\\leq \\min\\{\\alpha { r_{\\mathrm{\\overrightarrow{2\\mathrm{r}}}}},(1-\\alpha ) { r_{\\mathrm{\\overrightarrow{\\mathrm{r}1}}}}\\ } \\text { with } \\;\\alpha\\in ( 0,1),\\\\ & [ { r_{\\mathrm{\\overrightarrow{1\\mathrm{r}}}}},{r_{\\mathrm{\\overrightarrow{2\\mathrm{r}}}}}]\\in{{{\\cal{c}}}_{\\mathrm{mac}}},\\text { and } \\;[{r_{\\mathrm{\\overrightarrow{\\mathrm{r}2}}}},{r_{\\mathrm{\\overrightarrow{\\mathrm{r}1}}}}]\\in{{{\\cal{c}}}_{\\mathrm{bc}}}\\big\\}.\\end{aligned}\\ ] ]    since @xmath71 is larger than the region of the broadcast phase achieved by applying interference cancellation @xcite and xor on the decoded messages at the relay node @xcite , the achievable rate region @xmath421 includes the region which can be achieved by interference cancellation and network coding approaches .",
    "( dotted line ) and @xmath71 ( dashed line ) , the right figure shows the corresponding achievable rate region @xmath421 ( solid line ) .",
    "the dashed - dotted line exemplarily shows for one angle @xmath423 the achievable rate pair ( @xmath424 ) on the boundary of @xmath421 with the optimal time - division between the two rate pairs ( @xmath425 ) on the boundary of @xmath11 and @xmath71.,width=302 ]    finally , we briefly look at an example with binary channels . in figure",
    "[ fig : capreg ] we depicted the capacity region @xmath11 and @xmath71 and the achievable rate region @xmath421 with a symmetric binary erasure multiple access channel ( * ? ? ?",
    "* example 14.3.3 ) and a binary symmetric broadcast channel , cf . equation .",
    "the boundary of the achievable rate region can be obtained geometrically if one takes for any angle @xmath426 $ ] half of the arithmetical mean between the boundary rate pairs of the capacity regions where we have @xmath427 .",
    "in this work we present the broadcast capacity region of the two - phase bidirectional relay channel . thereby , each receiving node has perfect knowledge about the message intended for the other node .",
    "furthermore , the proposed achievable rate region of the two - phase bidirectional relay channel is in general larger than the rate region which can be achieved by applying the network coding principle on the decoded data .",
    "the coding theorem and weak converse are easily extended to gaussian channels with input power constraints .",
    "we have also shown the strong converse with respect to the maximum error criterion for the broadcast phase .",
    "this result implies then that the capacity region defined with respect to the average error probability remains constant for all error parameters @xmath0\\in ( 0,\\frac{1}{2})\\times ( 0,\\frac{1}{4})$ ] or @xmath0\\in ( 0,\\frac{1}{4})\\times ( 0,\\frac{1}{2})$ ] .",
    "t.  j. oechtering and h.  boche , `` optimal resource allocation for a bidirectional regenerative half - duplex relaying , '' in _ ieee international symposium on information theory and its applications ( isita 06 ) _ ,",
    "seoul , korea , 2006 , pp .",
    "528  533 .",
    "y.  wu , p.  a. chou , and s.  y. kung , `` information exchange in wireless networks with network coding and physical - layer broadcast , '' in _ proceedings of the 39th annual conference on information sciences and systems ( ciss ) _ , march 2005 .",
    "c.  schnurr , t.  j. oechtering , and s.  staczak , `` on coding for the broadcast phase in the two - way relay channel , '' in _ proceedings of the 41st annual conference on information sciences and systems _ , 2007 .",
    "r.  ahlswede , `` on two - way communication channels and a problem by zarankiewicz , '' in _",
    "sixth prague conf . on inf .",
    "fct s and rand .",
    "proc.__1em plus 0.5em minus 0.4empubl .",
    "house chechosl .",
    "academy of sc . , sept ."
  ],
  "abstract_text": [
    "<S> in a three - node network a half - duplex relay node enables bidirectional communication between two nodes with a spectral efficient two phase protocol . in the first phase , </S>",
    "<S> two nodes transmit their message to the relay node , which decodes the messages and broadcast a re - encoded composition in the second phase . in this work </S>",
    "<S> we determine the capacity region of the broadcast phase . in this scenario </S>",
    "<S> each receiving node has perfect information about the message that is intended for the other node . </S>",
    "<S> the resulting set of achievable rates of the two - phase bidirectional relaying includes the region which can be achieved by applying xor on the decoded messages at the relay node . </S>",
    "<S> we also prove the strong converse for the maximum error probability and show that this implies that the @xmath0$]-capacity region defined with respect to the average error probability is constant for small values of error parameters @xmath1 , @xmath2 . </S>"
  ]
}