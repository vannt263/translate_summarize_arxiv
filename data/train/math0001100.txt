{
  "article_text": [
    "there are many problems in classical mechanics where what can be computed is limited by the simultaneous presence of both fast and slow motion : some variables oscillate rapidly while others change slowly , so standard numerical methods can require a large number of time steps to give accurate answers .",
    "stiffness of this type limits calculations of planetary motion , drift in high - frequency electronic oscillators , and the dynamics or large molecules  @xcite .",
    "for instance , in molecular dynamics it is standard  @xcite to model the motion of many atoms as a mechanical system with a hamiltonian of the form @xmath0 where @xmath1 are the coordinates and momenta of the atoms and @xmath2 is the number of atoms , commonly in the range @xmath3 to @xmath4 . here",
    "@xmath5 denotes a smoothly - varying potential energy of interaction among coordinates , the @xmath6 s are bond angles or interatomic spacings ( functions of the coordinates ) , the @xmath7 s are masses , and @xmath8 is a matrix of spring constants .",
    "such models are used to describe both the large - scale motion that takes place over milliseconds and also the rapid vibrational motions at chemical bonds which are measured in terahertz .    in a recent paper@xcite ,",
    "stuart and warren considered a particular stiff hamiltonian problem of the form  ( [ cmdh ] ) that was originally meant to model a particle interacting with a heat bath  @xcite , and they constructed numerical schemes that worked well with large time steps .",
    "they were able to compute the motion of slowly - varying quantities accurately , even when most of the dynamics was grossly underresolved in time ( i.e. , even when their time step was much longer than the periods of most normal modes of oscillation ) .",
    "this observation , that a scheme may be optimized to work well even when the resolution is poor , is similar to the results of optimal prediction  @xcite ; optimal prediction is a method for reducing the resolution required to solve a large system of equations .",
    "a smaller system is constructed , designed to yield expectations of solutions of the larger system and to be computationally practical even when the larger system is not . since",
    "stuart and warren have found schemes for some large , stiff systems that work with big time steps , it is natural to ask whether there are smaller systems of differential equations ( just describing the slower modes ) that would work at these big time steps .    in this paper",
    "we show how optimal prediction may be applied to a class of large , stiff hamiltonian systems like  ( [ cmdh ] ) to yield effective equations which are smaller and slower .",
    "we demonstrate the method on the stuart - warren model and on a generalization of it that more closely approximates realistic models of molecular dynamics .",
    "the benefits are longer time steps , lower dimensionality ( hence fewer force evaluations per time step ) , and a systematic approach that may may be broadly applied .",
    "optimal prediction is a method that takes a large system of differential equations together with a probability distribution for the dependent variables , and produces a smaller system of equations for the expectations of some selected variables while averaging over all the others .",
    "the method is described in  @xcite .",
    "error bounds for the method can be found in  @xcite .",
    "suppose we are given a large dynamical system @xmath9 for dependent variables @xmath10 , and we are also given a normalized probability density @xmath11 which is invariant under  ( [ dynamicalsystem ] ) , @xmath12    the first step in the optimal prediction procedure is to identify `` collective variables , '' meaning a small number of functions of the dependent variables whose evolution we would like to predict .",
    "we denote these collective variables by @xmath13 where @xmath14 .",
    "the idea in optimal prediction is to treat the @xmath15 s as random , treat their combinations in the @xmath16 s as known , and to estimate the rates of change of the @xmath16 s by conditional expectations .",
    "one writes out a formula for the rate of change of the @xmath16 s induced by  ( [ dynamicalsystem ] ) , @xmath17 then one uses @xmath18 to compute the expectation of this expression subject to conditions that @xmath19 for some @xmath20 numbers @xmath21 , @xmath22 finally , one hypothesizes that the mean evolution of the @xmath16 s is approximated by the solutions @xmath23 of the new system , @xmath24 the new system  ( [ hypothesis ] ) is a closed system of equations for the @xmath25 s , and it is @xmath20-dimensional instead of @xmath2-dimensional .    equation  ( [ hypothesis ] ) approximates the evolution of the mean values of the @xmath16 s .",
    "the idea of the approximation is that at every moment in time , the @xmath15 s are distributed according to their invariant probability density subject to conditions on the values of collective variables .",
    "all that changes in time is the conditions , according to our hypothesis  ( [ hypothesis ] ) .",
    "actually , if the @xmath16 s were given and the @xmath15 s were distributed according to a conditioned invariant distribution at time @xmath26 , then at a future time @xmath27 the @xmath16 s would be indeterminate and the @xmath15 s would become distributed in some more general way .",
    "average values of the @xmath16 s at all times @xmath27 would still be well - defined though , and they would be determined by the values of the @xmath16 s at @xmath26 .",
    "the system  ( [ hypothesis ] ) is meant to approximate such exact mean evolutions of collective variables from initial values .",
    "although equation  ( [ hypothesis ] ) is conjectural , some general results are known about its accuracy .",
    "first , it clearly gives an asymptotically exact prediction of mean futures for short times .",
    "second , it appears in an exact formula for mean futures due to zwanzig  @xcite ( recently studied by others  @xcite ) which reveals corrections in terms of history integrals and noise - like functions which are statistically uncorrelated with the collective variables .",
    "third , error bounds for the method have been established in the case of hamiltonian dynamical systems  @xcite .",
    "there are two technical challenges in the application of  ( [ hypothesis ] ) : collective variables must be selected , and the conditional expectations on the right - hand side must be explicitly evaluated , usually requiring approximations of the integrals in equation  ( [ integrals ] ) . both steps are critical to accuracy",
    ". in complex problems , therefore , the best way to determine the usefulness of the approximation  ( [ hypothesis ] ) is empirically : one generates large random ensembles of initial conditions for  ( [ dynamicalsystem ] ) , integrates each initial condition , then averages the results to determine a mean future .",
    "one then compares the answer to an integral of  ( [ hypothesis ] ) .    in the present paper",
    ", we will consider hamiltonian equations where the dependent variables are canonical coordinate pairs @xmath28 .",
    "hamiltonian equations preserve the canonical probability density , @xmath29 , so we will use this as our probability density .",
    "we assume that the first @xmath20 coordinate pairs @xmath30 are of interest , and we will take the remaining dynamical variables as random .    the optimal prediction procedure is to take the full system of hamilton s equations , @xmath31 discard the equations with indices @xmath32 , and replace the right - hand sides of the remaining equations with their expectations with respect to @xmath29 conditioned by the selected variables : @xmath33 where @xmath34 denotes the conditioned expectation , @xmath35 with @xmath36 a normalization constant . for any function @xmath37 of the canonical variables ,",
    "@xmath38 is a function of @xmath39 , @xmath40 only , so the @xmath41-dimensional system of equations  ( [ opeqns ] ) is closed .    the reduced system  ( [ opeqns ] )",
    ", the first approximation in optimal prediction , defines an approximate solution to a liouville problem for the evolution of a probability measure on phase space . at least for short times , the system  ( [ opeqns ] ) is guaranteed to give the expectations of the selected variables , averaging over all possible initial data for the discarded variables .",
    "we need to evaluate the conditional expectations in  ( [ opeqns ] ) .",
    "this is easy if @xmath29 is a gaussian distribution ( i.e. , if @xmath42 is quadratic , or equivalently if the equations of motion are linear ) .",
    "if @xmath29 is not gaussian , perturbative techniques are available to approximate its expectations by gaussian expectations .",
    "thus the following results for gaussian distributions will be sufficient for our purposes , see  @xcite for details .",
    "let @xmath43 be gaussian random variables distributed with density @xmath44 we denote expectations with respect to this density by @xmath45 , and @xmath46 .",
    "now suppose that @xmath47 are given for all @xmath48 .",
    "the conditional expectations of @xmath49 conditioned by @xmath47 are denoted @xmath50 , @xmath51 and are given explicitly by @xmath52 where @xmath53 for @xmath54 and @xmath55 is the inverse of the @xmath56 ( not @xmath57 ) matrix @xmath58 .",
    "the conditioned covariances , @xmath59 are given in terms of the unconditioned expectations @xmath60 by @xmath61    the conditioned expectation of any polynomial in @xmath62 may be found from these formulae by wick s theorem .",
    "stuart and warren  @xcite ( see also  @xcite ,  @xcite , and  @xcite ) considered a one - dimensional collection of particles connected by springs .",
    "there was one distinguished particle with mass @xmath63 , coordinate @xmath64 and momentum @xmath65 .",
    "the distinguished particle was connected by springs of spring constant @xmath66 to @xmath2 other particles with masses @xmath67 , coordinates @xmath68 and momenta @xmath69 , @xmath70 , representing a heat bath .",
    "the motion of this collection of particles and springs is defined by the hamiltonian @xmath71 \\label{originalh}\\end{gathered}\\ ] ] where @xmath72 and @xmath1 are canonically conjugate dynamical variables for @xmath73 and @xmath74 .",
    "the equations of motion are @xmath75 \\dot{q } & = p & \\dot{p } & = - v'(q ) + k \\sum_{j=1}^n ( q_j - q ) \\\\",
    "\\dot{q}_j & = p_j / m_j \\quad & \\dot{p}_j & = k ( q - q_j ) , \\quad j=1,\\ldots , n \\end{aligned } \\label{original}\\ ] ]    this system is of the form  ( [ cmdh ] ) ( with an extra pair of coordinates @xmath72 ) , and it is chosen so that fast and slow motion are separated : lighter particles will move faster , heavier particles will move slower , and the mass @xmath76 goes down as @xmath77 goes up .",
    "a central result of  @xcite is that if all the heat bath particles start out randomly , with statistics determined by the canonical distribution , then in the limit @xmath78 the coordinate of the distinguished particle obeys the stochastic equation , @xmath79 where @xmath80 is a stochastic process related to white noise .",
    "this equation for @xmath64 is remarkable because it makes no reference to the history of @xmath64it is a differential equation , not an integro - differential equation . in a general hamiltonian problem ,",
    "if one variable @xmath64 is fixed initially and the others are random , at future times there is no time - invariant relationship among the expectation of @xmath64 and its time derivatives  @xcite .",
    "the first approximation of optimal prediction  ( [ opeqns ] ) may be characterized as the assumption that the values of the selected variables do determine their own future expectations . in general",
    "this assumption is not exactly true , but in the stuart - warren model it is true exactly in the @xmath78 limit .",
    "stuart and warren proceeded to integrate their model with large time steps .",
    "if @xmath64 were fixed , then each @xmath68 would oscillate harmonically with frequency @xmath81 .",
    "this implies that a discretization of the @xmath82 equations  ( [ original ] ) would be resolved in time if @xmath83 .",
    "if this condition on @xmath84 were violated , then the result of the computation would depend on how the equations were discretized .",
    "the intriguing result of  @xcite is that some schemes will give the right evolution for @xmath64 and @xmath65 when @xmath85 and others will not .",
    "for instance , if the scheme is @xmath75 \\frac{q^{n+1}-q^n}{\\delta t } & = p^{n+1 } & \\frac{p^{n+1}-p^n}{\\delta t } & = - v(q^n ) + k \\sum_{j=1}^n ( q_j^{n+\\sigma}-q^n ) \\\\",
    "\\frac{q_j^{n+1}-q_j^n}{\\delta t } & = p_j^{n+1 } / m_j \\quad & \\frac{p_j^{n+1}-p_j^n}{\\delta t } & = k(q^n - q_j^n ) \\quad j=1,\\ldots , n \\end{aligned } \\label{swscheme}\\ ] ] then @xmath86 ( a symplectic method ) gives the right answer for @xmath64 and @xmath65 , but @xmath87 ( another convergent method ) does not .",
    "for concreteness , we pick @xmath88 . since @xmath42 in  ( [ originalh ] )",
    "is then quadratic , the canonical probability density is gaussian , and formula  ( [ constrainedav ] ) gives the conditioned expectations as @xmath89 taking the conditional expectations of the right - hand sides of  ( [ original ] ) and evaluating them using these results , we find that the equations of optimal prediction are @xmath75 \\dot{q } & = p & \\dot{p } & = - q + k \\sum_{\\mu=1}^n ( q_\\mu - q ) \\\\",
    "\\dot{q}_\\mu & = p_\\mu / m_\\mu \\quad & \\dot{p}_\\mu & = k ( q - q_\\mu ) , \\quad \\mu=1,\\ldots , n \\end{aligned } \\label{originalop}\\ ] ] these are identical in form to the original equations  ( [ original ] ) .",
    "it comes as no surprise , therefore , that the motion of @xmath64 can be computed with large @xmath84 : pick the @xmath84 desired , find an @xmath90 such that @xmath91 , and perform a resolved integration of  ( [ originalop ] ) with this @xmath20 and @xmath84 .",
    "reasonable approximations for the selected variables are guaranteed , at least for short times .",
    "figure  [ f1 ] shows a fully - resolved calculation ( @xmath92 ) of @xmath93 starting from @xmath94 , @xmath95 , with @xmath96 and @xmath97 chosen randomly from the canonical ensemble ( i.e. , chosen with probability density @xmath29 ) conditioned by @xmath98 and @xmath99 .",
    "it also shows the solution to the same problem as computed by a resolved integration of  ( [ originalop ] ) , which was achieved with @xmath100 .",
    "the optimal prediction calculation accurately duplicates the low - frequency behavior of the exact solution , and it does so in fewer dimensions with a larger time step . in this case , with @xmath101 and @xmath102 , the optimal prediction curve was about @xmath103 times faster to compute than the resolved solution .",
    "the optimal prediction has the further advantage that it did not use the initial data @xmath104 , @xmath105 and may claim to be an average answer over all possible values of these data .",
    "realistic applications , such as molecular dynamics , involve more complex interactions than are present in the model  ( [ original ] ) .",
    "in particular , we may expect that every particle would interact with every other , and that the interactions would be nonlinear .",
    "we therefore consider a generalization of the model  ( [ original ] ) where every @xmath106 is coupled to every other @xmath106 by a spring , and the springs are nonlinear : @xmath107 @xmath108 this model makes no reference to a distinguished particle ; each one of the @xmath2 particles interacts with all of the others through the same potential energy , which is parameterized by the new spring constants @xmath109 and @xmath110 .",
    "we derive the optimal prediction equations of the system  ( [ new ] ) for @xmath111 , @xmath112 by averaging over @xmath113 , @xmath114 . since the interactions are now nonlinear , the probability density @xmath29 is no longer gaussian , so we must work harder to evaluate the conditioned expectations .",
    "hald has observed , as reported in  @xcite , that optimal prediction equations of the form  ( [ opeqns ] ) are always hamiltonian , and that their hamiltonian is @xmath115 we may therefore approximate the conditioned expectations of  ( [ opeqns ] ) by first approximating @xmath116 , and then deriving  ( [ opeqns ] ) by differentiation : @xmath117 we decompose @xmath42 into its quadratic part plus its higher - order part , @xmath118 and proceed by determining @xmath116 perturbatively as a power series in @xmath110 . an alternate method for perturbative treatment of optimal prediction is described in  @xcite .",
    "hald s formula  ( [ effh ] ) implies @xmath119 where the new average , @xmath120 denotes an average with respect to the conditioned _ gaussian _ measure , defined just as in the definition  ( [ conddiff ] ) but with @xmath121 replacing @xmath42 .",
    "the `` ( @xmath121-part ) '' term would be the effective hamiltonian if @xmath122 were zero , and it contributes linear terms to the equations of motion which are easily evaluated by the regression formula  ( [ constrainedav ] ) .",
    "the other term in  ( [ haldimplies ] ) is equal to a power series in @xmath110 , @xmath123 where @xmath124 denotes the @xmath7-th cumulant of @xmath122 with respect to the conditioned gaussian measure .",
    "each cumulant in this series may be evaluated by wick s theorem , where only `` connected '' pairings ( in the sense of perturbation theory in physics ) are included .",
    "to first order in @xmath110 , we need to evaluate @xmath125     + \\text{(constant ) } \\end{aligned}\\ ] ] where `` @xmath126 '' denotes terms that are independent of @xmath127 and @xmath128 ( and therefore do not affect equations of motion ) .",
    "the average @xmath120 may be deduced from the expectations , @xmath129 together with wick s theorem .",
    "the result for @xmath116 , to first order in @xmath110 , is @xmath130 where the coupling constants to this order in @xmath110 are @xmath131 we differentiate  ( [ answer ] ) to obtain the optimal prediction equations for the new system  ( [ new ] ) to @xmath132 , @xmath133 \\end{aligned } \\qquad \\mu=1,\\ldots , n .",
    "\\label{reduced}\\ ] ]    we performed a more rigorous test of this new model , comparing it to an actual mean evolution .",
    "the results are shown in figure  [ f2 ] .",
    "we once again picked @xmath134 , @xmath112 ( @xmath135 ) from the canonical distribution @xmath29 for @xmath2 particles ( @xmath136 at @xmath137 and @xmath138 ) .",
    "we then generated an ensemble of @xmath139 sets of values for @xmath113 , @xmath114 from the canonical distribution conditioned by @xmath140 , @xmath141 , and for each set integrated the equations  ( [ new ] ) .",
    "averaging over all @xmath139 solutions yielded the solid curve for @xmath142 .",
    "we then discarded the ensemble and used the original @xmath134 , @xmath112 as initial conditions for the reduced system  ( [ reduced ] ) , which we integrated with @xmath143 .",
    "this @xmath84 is small enough to resolve the reduced dynamics but much too large to resolve the original dynamics .",
    "the solution for @xmath142 from  ( [ reduced ] ) is the dashed curve .",
    "finally , for comparison we performed the naive experiment of simply truncating the big system  ( [ new ] ) to @xmath20 degrees of freedom , effectively ignoring the lighter particles without changing the interactions .",
    "this produced the dot - dashed curve .",
    "the figure shows that the reduced system accurately predicts the average evolution of @xmath142 , and it does so with @xmath63 percent of the degrees of freedom and time steps that are @xmath139 times larger .",
    "the naive experiment shows that the new couplings are critical to the answer .",
    "since forces must be evaluated @xmath144 times per time step for @xmath2 particles , optimal prediction speeds up the calculation of @xmath142 in this case by about a factor of about @xmath145 .",
    "we have shown that optimal prediction may be applied to large , stiff hamiltonian systems of differential equations to make new systems that are smaller , better - conditioned , and approximate the original equations in the mean .",
    "we have demonstrated that the method gives accurate answers while allowing larger time steps and requiring fewer force evaluations .",
    "the author thanks profs .",
    "a.  chorin , o. hald , r. kupferman , and a.  stuart for helpful discussions .",
    "chorin , a.j . ,",
    "kast , a. and kupferman , r. ( 1999 ) in _ nonlinear partial differential equations : international conference on nonlinear partial differential equations and aplications _ ,",
    "chen , g .- q .  and",
    "dibenedetto , e. ( american mathematical society , providence ) , pp ."
  ],
  "abstract_text": [
    "<S> we consider many - body problems in classical mechanics where a wide range of time scales limits what can be computed . </S>",
    "<S> we apply the method of optimal prediction to obtain equations which are easier to solve numerically . </S>",
    "<S> we demonstrate by examples that optimal prediction can reduce the amount of computation needed to obtain a solution by several orders of magnitude . </S>"
  ]
}