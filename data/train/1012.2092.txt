{
  "article_text": [
    "consider a controlled dynamical system over a discrete and finite time horizon .",
    "this system may be influenced by exogenous noises that affect its behaviour .",
    "we suppose that , at every instant , the decision maker is able to observe these noises and to keep these observations in memory . since it is generally profitable to take available observations into account when designing future decisions , we are looking for strategies rather than simple decisions .",
    "such strategies  ( or policies ) are feedback functions that map every instant and every possible history of the system to a decision to be made .",
    "more precisely , we are here interested in optimization problems with a large number of variables .",
    "the typical application we have in mind is the following .",
    "consider a power producer that owns a certain number of power units .",
    "each unit has its own local characteristics such as physical constraints that restrain the set of feasible decisions , and production costs that depend on the type of fuel that is used to produce power .",
    "the power producer has to control the power units so that a global power demand is met at every instant .",
    "the power demand , as well as other parameters such as inflows in water reservoirs or unit breakdowns , are random .",
    "naturally , he is looking for strategies that make the production cost minimal , over a given time horizon .",
    "in such a problem , both the number of power units and the number of time steps are usually large .",
    "one classical approach when dealing with stochastic dynamic optimization problems is to discretize the random inputs of the problem using scenario trees .",
    "such an approach has been widely studied within the stochastic programming community  ( see the book by * ? ? ? * for an overview of this methodology ) .",
    "one of the advantages of such a technique is that as soon as the scenario tree is drawn , the derived problem can be treated by classical mathematical programming techniques .",
    "thus , a number of decomposition methodologies have been proposed  ( * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* chapter  3 ) and even applied to energy planning problems  @xcite . a general theoteric point of view concerning the way to combine the discretization of expectation together with the discretization of information is given by  @xcite .",
    "however , in a multi - stage setting , this methodology suffers from the drawbacks that arise with scenario trees .",
    "as it was pointed out by  @xcite , the number of scenarios needed to achieve a given accuracy grows exponentially with the number of time steps of the problem .",
    "the other natural approach to solve soc problems is to rely on the dynamic programming  ( dp ) principle  ( see * ? ? ?",
    "* ; * ? ? ?",
    "the core of the dp approach is the definition of a state variable that is , roughly speaking , the variable that , in conjunction with the time variable , is sufficient to take an optimal decision at every instant .",
    "it does not have the drawback of the scenario trees concerning the number of time steps since strategies are , in this context , depending on a state variable whose space dimension usually does not grow with time .",
    "however , dp suffers from another drawback which is the so - called _ curse of dimensionality _ : the complexity of solving the dp equation grows exponentially with the state space dimension .",
    "hence , brutally solving the dp equation is generally intractable when the state space dimension goes beyond several units .",
    "recently , @xcite were able to solve it on a  @xmath0-state - variables energy management problem , using parallel computation coupled with adequate data distribution .",
    "another popular idea is to represent the value functions  ( solutions of the dp equation ) as a linear combination of a priori chosen basis functions  ( see among others * ? ? ?",
    "* ; * ? ? ?",
    "this approach , called approximate dynamic programming or often least - squares monte - carlo , has also become very popular in the context of american option pricing through the work of  @xcite .",
    "this approximation reduces the complexity of solving the dp equation drastically .",
    "however , in order to be practically efficient , such an approach requires some a priori information about the problem , in order to define a well suited functional subspace .",
    "indeed , there is no systematic means to choose the basis functions and several choices have been proposed in the literature  @xcite .",
    "when dealing with large - scale optimization problems , the decomposition / coordination approach aims at finding a solution to the original problem by iteratively solving smaller - dimensional subproblems . in the deterministic case ,",
    "several types of decomposition have been proposed ( e.g. by prices or by quantities ) and unified in a general framework using the auxiliary problem principle by @xcite . in the open - loop stochastic case , i.e. when controls do not rely on any observation , @xcite proposed to take advantage of both decomposition techniques and stochastic gradient algorithms .",
    "these techniques have been extended in the closed - loop stochastic case by @xcite , but so far they fail to provide decomposed state dependent strategies in the markovian case .",
    "this is because a subproblem optimal strategy depends on the state of the whole system , not only on the local state . in other words ,",
    "decomposition approaches are meant to decompose the control space , namely the range of the strategy , but the numerical complexity of the problems we consider here also arises because of the dimensionality of the state space , that is to say the domain of the strategy .",
    "we here propose a way to use price decomposition within the closed - loop stochastic case .",
    "the coupling constraints , namely the constraints preventing the problem from being naturally decomposed , are dualized using a lagrange multiplier ( price ) . at each iteration",
    ", the price decomposition algorithm solves each subproblem using the current price , then uses the solutions to update the price . in the stochastic context , price is a random process whose dynamics is not available , so the subproblems do not in general fall into the markovian setting .",
    "however , in a specific instance of this problem , @xcite exhibited a dynamics for the optimal multiplier , and he showed that these dynamics were independent with respect to the decision variables .",
    "hence it was possible to come down to the markovian framework and to use dp to solve the subproblems in this case .",
    "following this idea , @xcite proposed to choose a parametrized dynamics for these multipliers in such a way that solving subproblems using dp becomes possible .",
    "while the approach , called dual approximate dynamic programming  ( dadp ) , showed promising results on numerical examples , it suffers from the fact that the induced restrained dual space is non - convex .",
    "this led to some numerical instabilities and , probably more important , it was not possible to give convergence results for the algorithm .",
    "we here propose to extend dadp in a more general way that allows us to derive convergence results and solves the problem of numerical instabilities .",
    "the paper is organized as follows . in section  [ sec : math ] , we present the general soc problem and the dp principle",
    ". then we concentrate on a more specific class of problems , that we call decomposable problems , and recall the previous version of the dadp algorithm . in section  [ sec : sspb ] , we present the new version we propose and give convergence results for the algorithm .",
    "finally , in section  [ sec : num ] , we apply dadp to two numerical examples , the first being the one from the previous paper by @xcite and the second one being a more realistic power management example .",
    "all along the paper , random variables are denoted using * bold * letters . consider a discrete and finite time horizon  @xmath1 and a probability space  @xmath2 . to define a stochastic dynamical system ,",
    "we need :    * a stock process  @xmath3 which represents the physical states of the system through time , the value of  @xmath4 lying , at every instant  @xmath5 , in a hilbert space  @xmath6 ; * a control process  @xmath7 , the value of  @xmath8 lying , at every instant  @xmath5 , in a hilbert space  @xmath9 ; * a noise process  @xmath10 , the value of  @xmath11 lying , at every instant  @xmath5 , in a hilbert space  @xmath12 .",
    "the spaces  @xmath6 , @xmath9 and  @xmath12 are generally finite - dimensional spaces . in the sequel",
    ", we suppose  @xmath13 and  @xmath14 .",
    "the decision variable  @xmath8 being a random variable , and our purpose being to use variational techniques that require the notion of gradient , it is natural to suppose that  @xmath8 lies in a hilbert space  @xmath15 , for example  @xmath16 .",
    "the three types of variables are linked together in the following way . at every time step",
    "@xmath5 , there exists a function  @xmath17 ( the dynamics of the system ) that maps the triplet  @xmath18 to the next stock value  @xmath19 .",
    "let  @xmath20 be the filtration associated with the stochastic process  @xmath21 .",
    "we suppose that , at every time step  @xmath5 , the decision maker is able to observe and to keep in memory all the past history of  @xmath21 up to time  @xmath5 .",
    "the causality principle states that the decision  @xmath8 at time  @xmath5 is  @xmath22-measurable , i.e. only depends on past observations .",
    "moreover , at each time step  @xmath5 , a cost  @xmath23 is incurred . finally , at the final time  @xmath24 , a cost  @xmath25 is added .",
    "the stochastic optimal control ( soc ) problem we would like to solve hence reads :    [ eqn : p ] @xmath26    constraints  , , and have to be understood in the  @xmath27-almost sure sense .",
    "we give examples for constraint   in   [ sec : sspb ] . with no further assumptions ,",
    "problem   can not generally be solved analytically , except for quite particular cases among which is , for instance , the linear quadratic gaussian ( lqg ) case .",
    "one has to be aware that , when solving this problem , one is looking for functions that map every possible history of the system to a decision ; the domain of such a function is clearly growing with time and representing it on a computer rapidly becomes intractable .",
    "fortunately enough , control theory helps us reduce the size of the optimal strategy s domain in some cases .",
    "let us first make the following assumption .",
    "[ hyp : indpdt ] noises  @xmath28 are independent over time .    now define functions  @xmath29 , for every time step  @xmath30 , as : @xmath31 subject to the same ] constraints as in problem  .",
    "function  @xmath29 represents the minimal remaining cost of the problem when starting at time  @xmath5 , for every possible stock value  @xmath32 .",
    "under assumption  [ hyp : indpdt ] , the dynamic programming  ( dp ) principle states that the variable  @xmath4 , along with the current noise value  @xmath11 , contains all the information that is sufficient to take the optimal decision at time  @xmath5 , hence the term _ state _ variable . moreover",
    ", it provides a way to compute functions  @xmath29 , that we now call bellman functions  ( or value functions ) , as well as optimal strategy , in a backward manner .",
    "[ eqn : dp ] @xmath33    compared with the original setting where the optimal strategy domain was growing along with time steps , the dp principle drastically reduces the size of the information needed to make an optimal decision .    in the case",
    "when the model is such that noises that affect the system have some sort of correlation through time , one can always explicit the dynamics of the noise variable and add it to the dynamics of  @xmath4 , thus defining a new  ( albeit larger ! ) state variable as well as a new noise variable that is now independent over time .",
    "[ rem : hd ] the reader may have noticed that the way the non - anticipativity constraint in written allows the decision maker at time  @xmath5 to observe the current noise value  @xmath11 before choosing the control  @xmath8 . in such a setting the optimal decision at time  @xmath5 depends on both the state variable  @xmath4 and the noise variable  @xmath11 whereas the value function only depends on the state variable  @xmath4 .",
    "note however that the dimension of the state space  @xmath6 might still be quite large . yet",
    "the complexity of solving the dp equation   grows exponentially with the dimension of  @xmath6 ; this unpleasant feature is well known as the _ curse of dimensionality _ and prevents us from solving this equation by discretization when the state space dimension is , say , greater than  @xmath34 .",
    "let us now present a particular instance of problem   on which we are able to reduce even more the size of the information needed to take a reasonable decision .",
    "we consider a system which consists of  @xmath35 subsystems , whose dynamics and cost functions are independent one from another . more precisely , the state @xmath4  ( respectively the control @xmath8 ) of the global system writes @xmath36 with @xmath37 ( resp .",
    "@xmath38 with @xmath39 ) and @xmath40 ( resp .",
    "@xmath41 ) , so that the global dynamics @xmath42 can be written independently unit by unit : @xmath43 , @xmath44 . in the same way , the global cost @xmath45 is equal to the sum of the local unit costs @xmath46 , @xmath44 . at the end of the time period ,",
    "each unit  @xmath47 causes a cost  @xmath48 that only depends on its final state  @xmath49 .",
    "remark that , without further constraints , the induced soc problem can be stated independently unit by unit , though the same noise variable affects all units ( see appendix  [ app : decomposition ] for a precise proof ) . hence , under assumption",
    "[ hyp : indpdt ] , the solving of the dp equation can be decomposed unit by unit . for each unit ,",
    "the optimal strategy depends only on its local state , which is usually far smaller than the dimension of the global state space .",
    "consider now a static constraint   that couples the units together .",
    "we suppose that such a coupling arises from a set of static @xmath50-valued constraints , the constraint at time step @xmath5 reading @xmath51 .",
    "this kind of coupling constraint is natural in many industrial applications , including the case of a power management problem that we already mentioned in the introduction : the sum of the productions of the power units must meet an uncertain power demand .",
    "the decomposable problem we are interested in solving in the following reads :    [ eqn : pdec ] @xmath52    there are three types of coupling in problem  :    * the first comes from the state dynamics   that induce a temporal coupling . *",
    "the second one arises from the static constraints   that induce a spatial coupling : they link together all the subsystems at each time step  @xmath5 . *",
    "the third type of coupling is informational : it comes from the causality constraint  , which prevents us from decomposing directly scenario by scenario  : if two realizations of the noise process are identical up to time  @xmath5 , then the same control has to be applied at time  @xmath5 on both realizations .",
    "constraints   prevent us from decomposing the optimization problem unit by unit : the solution  @xmath53 for unit  @xmath47 and time  @xmath5 has to be searched as a feedback function  @xmath54 depending on the current noise value and on the whole stock variable  @xmath55 rather than on the local stock variable  @xmath56 ! adding the coupling constraint   drastically changed the structure of the problem .",
    "[ rem : fulldec ] applications we have in mind are power management problems which are completely `` flower - shaped '' , in the following sense .",
    "the noise variable  @xmath11 at time  @xmath5 is composed of two different kinds of noise :    * a _ local _ noise  @xmath57 for every subsystem  @xmath47 , i.e. at every petal of the flower  ( uncertain inflows entering a water reservoir , for instance ) ; * a _ global _ noise  @xmath58 at the center of the flower  ( a total power demand , for instance ) .",
    "in such a setting , only the local noise appears in the cost function and in the dynamics , leading to functions of the form : @xmath59 while the global noise appears only in the coupling constraint as , for instance : @xmath60 keeping this particular case in mind shall give us some insight about how to decompose the global problem as well as possible .",
    "this is explained in more details in   [ ssec : proj ] and such settings are treated in the numerical experiments of   [ sec : num ] .      in a previous study  @xcite , the authors proposed a way of handling problem   by approximate lagrangian decomposition . the proposed algorithm , called dual approximate dynamic programming  ( dadp ) is as follows .",
    "let us introduce the lagrangian of problem  : @xmath61 with  @xmath62 the lagrange multiplier of the coupling constraint   and  @xmath63 .",
    "note that , since the dualized constraint is  @xmath22-measurable , the lagrange multiplier  @xmath64 need only to have the same measurability .",
    "problem   is always equivalent to : @xmath65 where the minimization is subject to all constraints of problem   except constraint  . if  @xmath66 has a saddle point  ( see appendix  [ app : uzawa ] for a definition and a characterization of saddle points ) , then this problem is equivalent to the so - called dual problem : @xmath67 under , once again , the same constraints as in problem   except the coupling constraint  .",
    "the key point of the so - called price decomposition algorithm is that the inner minimization problem can be split into  @xmath35 subproblems , each one involving a single subsystem  ( once again , see appendix  [ app : decomposition ] for more details ) .",
    "one might think that solving these subproblems is much simpler than solving the original global problem .",
    "this is not the case here : because the dual variable  @xmath68 is a stochastic process that depends in general on the whole history of the system , we can not reasonably make the overtime independence assumption that leads to the dp principle and subproblems are just as hard as problem  !    the idea of @xcite is to force the dual process to satisfy a prescribed dynamics :    [ eqn : dynlambda ] @xmath69    where  @xmath70 is an a priori chosen function parametrized by  @xmath71 .",
    "we note  @xmath72 . given a vector  @xmath73 of coefficients at iteration  @xmath74 of the algorithm which defines the current values of the dual variables , the first step of dadp is to solve the  @xmath35 subproblems by dp with state  @xmath75 . in order to update the lagrange multipliers ,",
    "the authors propose to draw  @xmath76 trajectory samples of the noise  @xmath21 and integrate the dynamics   and   using the optimal feedback laws obtained at the first step , thus obtaining  @xmath76 sample trajectories of  @xmath77 , @xmath78 and  @xmath79 . a gradient step",
    "is then performed sample by sample : @xmath80 with  @xmath81 obeying the rules of the step - size choice in uzawa s algorithm  ( see appendix  [ app : uzawa ] ) .",
    "finally , we solve the following regression problem : @xmath82 the last minimization produces coefficients  @xmath83 which define , using equation  , a new process  @xmath84 .",
    "this procedure has several advantages , notably that its complexity is linear with respect to the number  @xmath35 of subproblems and that it may lead , depending on the choice for the dual dynamics  @xmath85 , to tractable approximations of the original problem .",
    "the authors illustrate this fact on a small example on which they are able to compare standard dp and dadp .",
    "still , it has some drawbacks , mainly theoretical .",
    "first of all , the shape of the dynamics introduced for the dual process is arbitrarily and once for all chosen and the quality of the result depends on this choice . moreover ,",
    "this dynamics defines a subspace which is non - convex .",
    "the next iterate  @xmath84 being a projection on this subspace , it is not well defined and some oscillations observed in practice may be due to this fact .",
    "finally , this non - convexity prevents us from obtaining convergence results for this algorithm .",
    "we now propose a new version of the dadp algorithm and show how it overcomes the above mentioned drawbacks encountered with the original algorithm . in this new approach , we do not suppose a given dynamics for the multipliers anymore .",
    "still , we use the standard price decomposition algorithm and perform the update of the multipliers scenario - wise using the classical gradient step : @xmath86 the difficulty is now to solve the subproblems , as explained in   [ ssec : proj ] .",
    "after lagrangian decomposition of problem   with a given multiplier  @xmath68 , the  @xmath47-th subproblem reads :    [ eqn : subp ] @xmath87    as it was already mentioned , since the dual stochastic process  @xmath68 generally depends on the whole history of the process , solving this problem is in general as complex as solving the original problem . in order to bypass this difficulty ,",
    "let us choose at each time step  @xmath5 a random variable  @xmath88 that is measurable with respect to  @xmath22 .",
    "we call  @xmath89 the information process for subsystem  @xmath47 .",
    "the idea is to rely on a short memory process  @xmath90 .",
    "note that we require that this random process is not influenced by controls .",
    "we propose to replace problem   by : @xmath91 subject to constraints  .",
    "let us first examine the special situation in which the information variable  @xmath88 only depends on the current noise  @xmath11 .",
    "the process  @xmath90 does not add memory in the system so that problem   can be solved using the standard dp equation : @xmath92 the expectation quadrature only involves the noise variable  @xmath11 .",
    "remember , as explained in remark  [ rem : hd ] , that we are in the `` hazard - decision '' setting : even though the control at each instant  @xmath5 depends on both  @xmath56 and  @xmath11 , the bellman function only depends on  @xmath56 .",
    "because of the overtime independence of the information variables  @xmath88 , we have to solve dp equations whose dimension is the subsystem dimension  @xmath93 . let us give three examples of choices for  @xmath88 .",
    "one can choose to include in  @xmath88 all the noise at time  @xmath5 .",
    "as already explained in remark  [ rem : fulldec ] , the cost function and dynamics of a subsystem may only depend on a part of the whole noise  @xmath11  ( a kind of _ local _ information denoted by  @xmath57 in remark  [ rem : fulldec ] ) . yet",
    "some _ global _ noise , denoted by  @xmath58 in remark  [ rem : fulldec ] may appear in the coupling constraint  ( e.g. a global power demand ) .",
    "hence this maximal choice for the information variable makes the multiplier depend on both local and global information : this shall improve the subsystem s vision of the rest of the system and hence improves strategies .",
    "note , however , that including all the noise at time  @xmath5 in the information variable is only possible in practice when the noise dimension is not too large .",
    "indeed , the information variable appears in a conditional expectation , whose computation is subject to the curse of dimensionality .",
    "[ ex : mininfo ] on the opposite , one can choose  @xmath94 or any other constant .",
    "the dual stochastic process is then approximated by its expectation at every instant .",
    "compared to the previous example , there is no conditional expectation anymore but one obtains a strategy that corresponds to the vision of an average price .",
    "one can choose  @xmath88 of the form  @xmath95 .",
    "in practice , this choice will be guided by the intuition one has on which information mostly `` explains '' the optimal price of the system .",
    "one has to make a compromise between sufficient information to take reasonable actions and a not too large information variable to be able to compute the conditional expectation in  .",
    "let us move towards the general case where one can choose to keep some information in memory . in other words , one can choose an information variable that has a markovian dynamics , i.e. of the form  @xmath96 . in order to derive a dp equation in this case",
    ", one has to augment the state vector by embedding  @xmath88 , that is the necessary memory to compute the next information variable .",
    "thus , the bellman function associated with the  @xmath47-th subproblem depends , at time  @xmath5 , on both  @xmath56 and  @xmath97 .",
    "the dp equation writes : @xmath98 when solving this equation , one obtains controls as feedback functions on the local stock  @xmath56 , the current noise  @xmath11 and the information variable  @xmath97 of the previous time step .",
    "the index gap between information and stock variables comes from the `` hazard - decision '' setting : at time  @xmath5 , the information that is used to take decisions is the conjunction of the information kept in memory  ( that has index  @xmath99 ) and of the noise observed at the current time step  @xmath11 .",
    "the sketch of the dadp algorithm is depicted in figure  [ fig : decomposition - schema ] .",
    "dual approximate dynamic programming ]    [ ex : maxinfo ] the choice  @xmath100 stands in the markovian case .",
    "we have then  @xmath101 .",
    "this choice hence allows us to model the dual variable perfectly , but the induced dp equation is unsolvable in practice .    in his phd thesis ,",
    "strugarek exhibited a case when an exact model for the dual process can be obtained .",
    "his example is inspired from the kind of power management problem mentioned in the introduction , where  @xmath35 water reservoirs have to contribute to a global power demand , the rest of this demand being produced by fossil fuel .",
    "the noise at each time step  @xmath5 is composed of a scalar inflow  @xmath102 for each reservoir  @xmath44 , and of a scalar power demand  @xmath58 . the problem reads :    [ eqn : pstrug ] @xmath103    let us denote  @xmath104 .",
    "the author then shows the following result .",
    "[ prop : strug ] if random variables  @xmath105 are independent over time , and if there exists  @xmath106 such that  @xmath107 , for all @xmath108 , then the optimal multiplier  @xmath68 associated with the coupling constraints   satisfies the following dynamics : @xmath109 , \\qquad \\forall t=1 , \\dots , t-2 .",
    "\\end{aligned}\\ ] ]    this allows the solving of subproblems using dp in dimension  3 .",
    "note that this example enters our approach if one chooses  @xmath110 as an information variable , with : @xmath111 .",
    "\\end{aligned}\\ ] ] we get back to the particular case when  @xmath112 , with a small dimensional information variable  @xmath88 .",
    "note however that conditions of proposition  [ prop : strug ] , especially the proportionality relation on costs , make little sense in practice .",
    "we now give convergence results about dadp and explain in more details the relation between the strategies it builds and the solution of the original problem  . to make the paper self - contained , we recall in appendix  [ app : uzawa ] the general results concerning duality in optimization , of which the properties of dadp are direct consequences .",
    "the approximation made on the dual process gives us a tractable way of computing strategies for each one of the subsystems .",
    "depending on the choice we make for the information variable , it is quite clear that some strategies will lead to better results than others , concerning the value of the dual problem or the satisfaction of the coupling constraint .",
    "let us here state more precisely these facts .    from now on , we consider a unique information variable for all subsystems .",
    "we denote it by  @xmath113 and define hilbert spaces @xmath114 for every  @xmath115 .",
    "[ prop : solve ] consider the following optimization problem :    [ eqn : pprime ] @xmath116    suppose the lagrangian associated with problem   has a saddle point .",
    "then dadp solves problem  .",
    "the dadp algorithm consists in :    * given a price process , solving subproblems using the projection of this price process on  @xmath117 ; * updating the price process using a gradient formula .",
    "alternatively , one may consider that the gradient formula is composed with the projection operation in the updating formula .",
    "therefore , this algorithm may also be viewed as a projected gradient algorithm which exactly solves the following max - min problem  :    [ eqn : dapprox ] @xmath118    observe that the max operation is restricted to a linear subspace defined by .",
    "now , if within the inner product  @xmath119 , the variable  @xmath120 belongs to a given subspace , then the component of  @xmath121 which is orthogonal to that subspace yields  @xmath122 in the inner product .",
    "hence it is useless .",
    "put in our context , the multiplier  @xmath64 can only control the part of  @xmath123 which has the same measurability as  @xmath64 .",
    "thus , assuming the existence of a saddle point , that is , the max and min operations can be interchanged in problem  , this problem appears as the dual counterpart of problem  .    loosely speaking",
    ", dadp somehow consists in replacing an almost - sure constraint by a constraint involving a conditional expectation with respect to a so - called information variable .",
    "so it is once again clear that if we choose the information variable  @xmath113 to be the whole history of the system , then we come back to the initial constraint and we in fact solve the original problem .",
    "this is the case of example  [ ex : maxinfo ] . on the contrary ,",
    "putting no information at all in  @xmath113 is the same as satisfying the coupling constraint only in expectation .",
    "this is the case of example  [ ex : mininfo ] .",
    "note however that it is generally a poor way of representing an almost - sure constraint .",
    "the main difficulty is to find the information variable  @xmath113 that is going to satisfy the coupling constraint in a fairly good way while keeping the solving process of the subproblems tractable .",
    "we now state the convergence of the dadp algorithm .",
    "let us introduce the objective function  @xmath124 associated with strategy  @xmath125 , i.e. : @xmath126    [ prop : convergence ] if :    1 .",
    "@xmath127 is convex , lower semi - continuous , gteaux differentiable , 2 .",
    "@xmath127 is @xmath128-strongly convex , 3 .",
    "all @xmath129 are linear and @xmath130-lipschitz continuous , 4 .",
    "the lagrangian associated with problem   has a saddle point  @xmath131 , 5 .",
    "the step - size  @xmath132 of the algorithm is such that  @xmath133 ,    then :    1 .   there exists a unique solution  @xmath134 of problem  , 2 .",
    "dadp converges in the sense that  : @xmath135 3 .   the sequence  @xmath136 is bounded and every cluster point  @xmath137 in the weak topology is such that  @xmath131 is a saddle point of the lagrangian associated with problem  .",
    "the convergence of the algorithm is then a direct application of theorem  [ thm : cohen ] , appendix  [ app : uzawa ] .",
    "note that assumptions of proposition  [ prop : convergence ] plus the qualification of constraint   ensure that the lagrangian associated with problem   has a saddle point .",
    "we now show the efficiency of dadp on two numerical examples .",
    "the first one comes from a previous paper  @xcite in which the authors developped a preliminary version of dadp  ( see   [ ssec : previous ] ) .",
    "we show in   [ ssec : expe1 ] the good performance of the new version of dadp .",
    "the second one , in   [ ssec : expe2 ] , is an application to a more realistic power management problem .      within the dadp procedure , at each iteration",
    ", we have to compute conditional expectations in the criteria   of the subproblems . in order to compute these conditional expectations",
    ", we used generalized additive models  ( gams ) , that were introduced by  @xcite .",
    "the estimate takes the form : @xmath138 functions  @xmath139 are splines  ( piecewise polynoms ) whose characteristics are optimized by cross - validation on the input statistical data .",
    "our purpose here is not to explain in details this methodology .",
    "the interested reader will find further explanations about this model and its implementation in the book by  @xcite .",
    "we used an easy - to - use implementation that is available within the free statistical software r  @xcite .",
    "the gam toolkit , called _ mgcv _ , also returns useful indicators concerning the quality of the estimation . in particular , we use the deviance indicator , which takes value  @xmath122 if  @xmath140 is estimated as poorly as by its expectation  @xmath141 and value  @xmath142 if the estimate is exact , i.e. if  @xmath143 .",
    "we chose to use gams to compute conditional expectations after a numerical comparison with the more classical kernel regression methods  @xcite also available in the  r environment .",
    "even though both of them gave similar results , gams appeared to be several times faster than the kernel method on our problem .",
    "we first implement the new version of dadp algorithm on a simple power management problem introduced by @xcite . on this small - scale example , we are able to compare dadp results to those obtained by dp and to illustrate the theoretical results described above .",
    "let us first recall this example . consider a power producer who owns two types of power plants :    * two hydraulic plants that are characterized at each time step @xmath5 by their water stock @xmath56 and power production @xmath53 , and receive water inflows @xmath144 , @xmath145 .",
    "such units are usually cost - free .",
    "we however impose small quadratic costs on the hydraulic power productions in order to ensure strong convexity .",
    "* one thermal unit with a production cost that is quadratic with respect to its production @xmath146 .",
    "there are no dynamics associated with this unit .",
    "using these plants , the power producer must supply a power demand @xmath58 at each time step @xmath5 , over a discrete time horizon of @xmath147 time steps .",
    "all noises , i.e. demand @xmath58 and inflows @xmath148 and @xmath149 are supposed to be overtime independent noise processes .",
    "the interested reader may find more details on this numerical experiment in the previous paper by @xcite .",
    "the problem reads :    [ eqn : ptest ] @xmath150    in this problem , the state @xmath4 is two - dimensional , hence dp remains numerically tractable and we can use the dp solution as a reference .",
    "in order to use dadp , we choose an information variable  @xmath113 at time  @xmath5 that is equal to the power demand  @xmath58 .",
    "this comes from the insight that the power demand is a `` global '' information and has all reasons to be useful to the subproblems .",
    "[ rem : feasibility ] in order to validate the method , it has to be evaluated within a simulation procedure . for the evaluation to be fair",
    ", the strategy must be feasible . yet , as explained in ",
    "[ ssec : convergence ] , dadp does not ensure that the coupling constraint is satisfied . to circumvent this difficulty ,",
    "the thermal unit strategy is chosen in the simulation process so as to ensure feasibility of the coupling constraint , i.e. : @xmath151 that is , dadp returns three strategies , for each of the hydraulic units and for the thermal unit .",
    "however , we use relation for the thermal strategy during simulations in order to ensure demand satisfaction and give an estimation of the cost of the dadp strategy .",
    "we run the algorithm for  20 iterations and depict its behaviour in figure [ fig : dualvalue ] .",
    "primal , dual and optimal costs with respect to the number of iterations ]    we draw the dual cost  ( evaluation of the dual function with the current strategy ) and the primal cost  ( the one with all constraints satisfied ) at each iteration .",
    "each point of the primal and dual curves is computed by monte carlo simulation over  500 scenarios .",
    "we observe the regular increase of the dual function , as expected , and the decrease of the primal function .",
    "the distance between the primal and dual costs is an upper bound for the distance to the optimal value that graphically , in this case , seems quite tight .",
    "moreover , the gam toolkit used to compute the conditional expectations of the form  @xmath152 returns that the deviance , i.e. the quality of the explanation of  @xmath64 by  @xmath58 is  98.5% .",
    "this indicates that the marginal cost of the system is almost perfectly explained by the time variable and the power demand .",
    "otherwise stated , using  @xmath152 instead of using  @xmath64 within problem   does not alter too much the quality of the solution .",
    "we now apply dadp on a real - life power management problem , inspired by a case encountered at edf , which is the major european power producer .",
    "we do not give the exact order of magnitude for costs and productions because of confidentiality issues .",
    "we consider  :    * a power demand on a single node  ( we neglect network issues ) at each instant of a finite time horizon of  163 weeks  ( one time step per week ) ; * 7  ( hydraulic ) stocks which are in fact aggregations of many smaller stocks ; * 122 other  ( thermal ) power units with no stock constraints .",
    "all the thermal power units are aggregated so that the thermal cost  @xmath153 at each time  @xmath5 only depends on the total thermal production  @xmath154 and forms a quadratic cost .",
    "we note  @xmath153 using bold letters , which means that this thermal cost is random , because of the breakdowns that may happen on thermal power plants .",
    "the problem reads :    [ eqn : pedf ] @xmath155    with  @xmath156 being the set of all noises that affect the system at time  @xmath5 .",
    "because we consider  7 stocks , we are unable to use dp directly on this problem . in order to obtain a reference point , we use an aggregation method introduced by @xcite and currently in use at edf .",
    "this numerical method is known to be especially well - suited for the problem under consideration .",
    "it consists in solving  @xmath35 subproblems  ( 7 in our case ) by 2-dimensional dp , each subproblem relying on a particular power unit , instead of one  @xmath35-dimensional dp problem .",
    "the idea is , for every unit , to look for strategies that depend on the stock of the unit and on an aggregation of the remaining stocks .",
    "we then make use of dadp using three different choices for the information variable  @xmath113 .    * in the first setting , we replace the price at each time step by its expectation . in other words , we explain the price only by the time variable  @xmath5 . according to proposition  [ prop : convergence ] , we are in fact solving problem   with constraint   replaced by its expectation .",
    "then we are able to solve each subproblem  @xmath47 by dp in dimension  1  ( the stock variable of unit  @xmath47 ) and we obtain strategies that depend , for each unit  @xmath47 and each instant  @xmath5 , on the stock  @xmath56 and the inflow  @xmath102 .",
    "* in the second setting , we replace the price at each time step by its conditional expectation with respect to the power demand . put differently",
    ", we explain the price by time and demand .",
    "we still have to solve a  1-dimensional dp equation and we obtain for each instant  @xmath5 a strategy that depends on  @xmath56 ,  @xmath102 and  @xmath58 . * in the third setting , we replace the price at each instant by its conditional expectation with respect to the power demand and the thermal availability .",
    "it gives insight on how tense the thermal generation mix is . ]  @xmath157 .",
    "we then obtain a strategy that depends , for every unit  @xmath47 and every instant  @xmath5 , on  @xmath56 ,  @xmath102 ,  @xmath58 and  @xmath157 .",
    "the behaviour of the algorithm in the second setting is depicted in figure  [ fig : exp2_couts ] .",
    "primal and dual costs along with iterations compared to the aggregation method ]    we observe the increase of the dual value and the decrease of the primal value , the latter value stabilizing rapidly to a value close to the one of the aggregation method . even though we are aware that only 10  iterations is generally much too less for this kind of primal - dual algorithm , it seems like the primal cost does not evolve significantly after  10 iterations .    in order to compare the three settings",
    ", we simulate the corresponding strategies ) . ] on a large set of i.i.d .",
    "noise scenarios and compute both the mean cost and confidence interval for each strategy .",
    "the results are presented in table  [ tab : resultats ] .",
    ".[tab : resultats]results for dadp [ cols=\"^,^,^,^\",options=\"header \" , ]     the `` deviance '' column gives the deviance indicator returned by the gam procedure for the estimation of the conditional expectation of the price with respect to the information variable .",
    "we observe that the dadp strategy still benefits from a good choice for the information variable  @xmath113 : it appears from the mean costs comparison that adding information within the estimator improves the quality of the estimation .",
    "the mean costs differences are however not so easy to compare for the two last experiments , because the confidence interval is too large compared to the cost values .",
    "thus we compute for each scenario the gap between costs obtained by two different strategies and draw in figure  [ fig : pdf ]    distribution of cost differences between settings of dadp ]    the associated probability distributions .",
    "it becomes clearer that adding the thermal availability in the information variable improves the strategy : the major part of the probability weight when comparing settings  2 and  3 is negative .    as a last point ,",
    "let us numerically verify that proposition  [ prop : convergence ] holds in our example , for instance in the first setting .",
    "remember that , in this case , our algorithm aims at satisfying the coupling constraint only in expectation .",
    "we draw in figure  [ fig : distgap ] the probability distribution of the production / demand gap at several iterations .",
    "distribution of the production / demand gap for a given time step ]    we observe that , along with iterations , the distribution of this gap becomes symmetric with respect to  @xmath122 , the corresponding expectation hence being equal to zero .",
    "we presented an original algorithm for solving a certain kind of large - scale stochastic optimal control problems .",
    "it is based on an approximate lagrangian decomposition : the lagrange multiplier , which is a stochastic process in this context , is projected using a conditional expectation with respect to another stochastic process called the information process .",
    "this information process is chosen a priori and , when it has a limited memory , the solving of subproblems becomes tractable .",
    "we give theoretical results concerning the convergence of the algorithm and show how it actually solves an approximate problem , whose relation with the original problem is driven by the choice of information variable .",
    "finally , we show on two numerical examples the efficiency of the approach .",
    "future works will be concerned with the application of this algorithm to more general problem structures , like chained subsystems or networks .",
    "the results presented here come from the paper by @xcite .",
    "let  @xmath158 and  @xmath159 be hilbert spaces , and  @xmath160 and  @xmath161 be subsets of  @xmath158 and  @xmath159  ( respectively ) .",
    "moreover , let us define a function  @xmath162 .",
    "we describe here the relations that link the so - called primal problem : @xmath163 to its dual counterpart : @xmath164 @xmath158 is called the primal space while  @xmath159 is called the dual one .",
    "a pair  @xmath165 is called a saddle point of  @xmath166 on  @xmath167 if : @xmath168    let us now concentrate on the case where function  @xmath166 corresponds to the lagrangian of an optimization problem : @xmath169 the uzawa algorithm is defined as follows .",
    "take an initial value  @xmath170 . at each iteration",
    "@xmath171 , compute  @xmath172 by minimizing  @xmath173 , and update  @xmath174 using the following rule : @xmath175 with  @xmath176 some positive value .",
    "the following theorem gives conditions for the sequence  @xmath177 to converge to the optimum of problem  .",
    "[ thm : cohen ] if :    1 .",
    "@xmath127 is convex , lower semi - continuous , gteaux differentiable , 2 .",
    "@xmath127 is @xmath128-strongly convex , 3 .",
    "@xmath178 is linear and @xmath130-lipschitz continuous , 4 .",
    "[ item : saddle ] @xmath166 has at least a saddle point  @xmath179 , 5 .",
    "the step - size  @xmath132 of the algorithm is such that  @xmath133 ,    then :    1 .",
    "@xmath180 is unique and is a solution of problem  , 2 .",
    "uzawa s algorithm converges in the sense that  : @xmath181 3 .   the sequence  @xmath182 is bounded and every cluster point  @xmath183 in the weak topology is such that  @xmath179 is a saddle point of  @xmath166 .",
    "given the other assumptions of the theorem , assumption   is satisfied as long as the dualized constraint satisfies a so - called `` qualification '' condition .",
    "in addition , the latter is always satisfied for affine constraints , which is the case in our application .",
    "we here depict in more details the reasons why a stochastic optimal problem  ( soc ) involving  @xmath35 independent ] subsystems is equivalent , under certain conditions , to  @xmath35 problems where each one involves only one of the subsystems .",
    "though this result may seem trivial at first sight , it is not true in general : the interested reader will find a counter example in the paper by  @xcite .",
    "then , the optimal feedback solution is _ partially decentralized _ , that is , each optimal decision @xmath53 , that may a priori depend on the whole @xmath4 and the whole @xmath11 and @xmath196 according to , indeed only depends on @xmath197 ; the bellman function @xmath198 is additive ( @xmath199 ) and the optimal solution only involves the _ marginal _ probability laws of the pairs @xmath200 but not the _ joint _ probability laws of the pairs @xmath201 .",
    "the proof is by induction over time .",
    "the statement that @xmath202 is additive is true at the final time  @xmath24 since the final cost @xmath203 is additive .",
    "assume this is true from @xmath24 to @xmath204 ( backward ) .",
    "the bellman equation at @xmath5 reads : @xmath205 in which    * the minimization operation is done over an expression is which @xmath32 , @xmath195 and @xmath57 are fixed ( hazard - decision scheme ) and the argmin in @xmath206 parametrically depends on those values ( which yields the optimal feedback function )  ; * the minimization operation is subject to the bound constraints for @xmath207 and for @xmath208  ; * the expectation concerns random variables @xmath209 whereas @xmath32 is still fixed ( @xmath210 and @xmath209 are independent from each other , thus this expectation may be considered as a conditional expectation knowing that @xmath211 ) : this yields a function of @xmath32 , namely @xmath212 .",
    "now observe that , at the minimization stage , each @xmath207 is involved into a separate expression depending only on @xmath213 , @xmath214 and @xmath195 subject also to independent constraints , hence the claimed partially decentralized optimal feedback .",
    "then , at the outer expectation stage , we get a sum of functions of @xmath215 and @xmath216 : thus only the marginal probability law of each pair @xmath216 is involved in the expectation of the corresponding term in this sum , and the result is an additive function of the @xmath213 , which completes the proof by induction .",
    "* if @xmath196 is absent and if @xmath217 and @xmath218 are independent whenever @xmath194 , then the overall problem is obviously made up of @xmath35 independent subproblems ; the optimal feedbacks are fully decentralized ( that is @xmath219 is in closed loop on @xmath220 ) , and the optimal controls @xmath221 and @xmath222 are also independent random variables whenever @xmath194 . *",
    "if we drop the independency assumption about @xmath217 and @xmath218 , then the same subproblems still provide the overall problem solution with decentralized feedbacks , but @xmath221 and @xmath222 are no longer independent . * another `` extreme '' situation is when only the `` shared '' noise @xmath140 is present in all subsystems ( the @xmath223 s are supposed absent for the sake of clarity but now , @xmath140 may be thought as the concatenation of all the @xmath223 s ) .",
    "the conclusions of the lemma are of course still valid , that is , the bellman function is still additive and each term of this sum can be calculated in a separate subproblem , yielding a feedback on @xmath224 .",
    "however the price to be payed for the presence of this shared random variable is that , first , the minimization operation in the bellman function is parametrized by both @xmath213 and @xmath195 , which may be costly if @xmath195 is of large dimension , and , second , the outer expectation in this bellman equation involves a multiple integral over that vector @xmath195 , which may also be costly ."
  ],
  "abstract_text": [
    "<S> we are interested in optimally driving a dynamical system that can be influenced by exogenous noises . </S>",
    "<S> this is generally called a stochastic optimal control  ( soc ) problem and the dynamic programming  ( dp ) principle is the natural way of solving it . </S>",
    "<S> unfortunately , dp faces the so - called curse of dimensionality : the complexity of solving dp equations grows exponentially with the dimension of the information variable that is sufficient to take optimal decisions  ( the state variable ) .    for a large class of soc problems , which includes important practical problems , </S>",
    "<S> we propose an original way of obtaining strategies to drive the system . </S>",
    "<S> the algorithm we introduce is based on lagrangian relaxation , of which the application to decomposition is well - known in the deterministic framework . however , its application to such closed - loop problems is not straightforward and an additional statistical approximation concerning the dual process is needed . </S>",
    "<S> we give a convergence proof , that derives directly from classical results concerning duality in optimization , and enlghten the error made by our approximation . </S>",
    "<S> numerical results are also provided , on a large - scale soc problem . </S>",
    "<S> this idea extends the original dadp algorithm that was presented by @xcite . </S>"
  ]
}