{
  "article_text": [
    "human action detection at real - time has become a topic of increasing interest due to its wide practical use .",
    "applications like human - machine interaction , surveillance and gaming , all require accurate and low - latency action detection .",
    "action detection on raw videos is difficult because it is first needed to localize a person in a scene full of objects and clutter , then try to recognize the type of action being performed . on the other hand , the recent low - cost depth sensors , like microsoft kinect , provided a more convenient way for data capture .",
    "the 3d positions of body joints can be estimated from depth maps at low - latency and with acceptable accuracy .",
    "filtering out background clutter , it is now more adequate to perform action detection based on skeleton data .",
    "recently , skeleton - based approaches to action recognition and detection have been widely adopted .",
    "while action recognition focuses on identifying the action label of pre - segmented video sequences , action detection tackles the more challenging problem of temporally localizing the action in an unsegmented stream of frames .",
    "the main contribution of this paper is a novel approach for action detection from skeleton data , that we refer to as efficient linear search ( els ) .",
    "we show that a combination of simple components and specializing them towards skeleton - based action detection can achieve state - of - the - art results and overcome the limitations of similar approaches .",
    "the proposed approach is flexible : it can be used with a wide class of classifier functions and with different types of action local descriptors . as a byproduct contribution",
    ", we propose a simple skeleton - based local descriptor that , when used in a simple bag - of - features model , produces state - of - the - art results on different datasets .",
    "the proposed framework works online and is suitable for real - time applications .",
    "moreover , it can be used for real - time video segmentation , since it specifies both the start and end frames of the action .",
    "the rest of this paper is organized as follows : section  [ sec : relwork ] gives an overview about recent related work in the literature .",
    "we show the used action representation and our proposed descriptor in section  [ sec : mainidea ] .",
    "we , then , explain our efficient linear search approach in section  [ sec : els ] .",
    "experimental evaluation is presented in  [ sec : experiments ] . and",
    "finally , we conclude in  [ sec : conclusion ] .",
    "forming suitable skeletal - based descriptors for action recognition has been the focus of many recent research works  @xcite .",
    "the objective is to facilitate the recognition task via a discriminative descriptor .",
    "some of these descriptors capture both the pose of the skeleton and the kinematics at the same time on the frame level .",
    "for example , nowozin _ et al . _",
    "@xcite proposed a local descriptor that uses 35 angles between triplets of joints , @xmath0 , along with angular velocity , @xmath1 , to encode joints kinematics .",
    "joints angles are a powerful cue to skeleton pose .",
    "moreover , they are invariant to body translation and rotation .",
    "later , zanfir _ et al . _",
    "@xcite proposed the moving pose descriptor , which captures both the body pose at one frame , as well as the speed and acceleration of body joints within a short time window centered around the current frame .",
    "another class of descriptors is focused on computing a fixed length descriptor for the whole action sequence , like  @xcite .",
    "et al . _",
    "@xcite used a 2d trajectory descriptor , called `` histogram of oriented displacements '' ( hod ) , where each displacement in the trajectory casts a vote , weighted by its length , in a histogram of orientation angles .",
    "et al . _",
    "@xcite modeled human actions as curves in a lie group , since 3d rigid body motions are members of the special euclidean group .",
    "et al . _",
    "@xcite used the 3d joints positions to construct a descriptor of relative positions between joints .",
    "however , descriptors on the whole sequence suffer from much higher dimensionality over those that were designed for the frame level .",
    "this higher dimensionality led sometimes to the need for feature selection as done in  @xcite .    while most of the focus on skeletal data was about action recognition , fewer works focused on the online problem .",
    "the trade - off between latency and accuracy was addressed in recent works  @xcite . in",
    "@xcite the notion of action points was first introduced and the detection problem was cast as a classification problem for every overlapping 35-frames intervals .",
    "the same notion of action points was utilized in the work of  @xcite , but they could handle different scales .",
    "other works , such as  @xcite used the standard sliding window protocol for online action detection .",
    "et al . _",
    "@xcite proposed a feature extraction method , called `` structured streaming skeleton '' ( sss ) , which constructs a feature vector for each frame using a dynamic matching approach .",
    "the sss feature vectors are then used for detecting the start and end of actions .",
    "et al . _",
    "@xciteused a modified knn classifier to detect the start and end of actions",
    ". however , both  @xcite can not handle multi - scale actions , where the same action can be performed at different speeds .",
    "the concept of local features first appeared in object detection in images  @xcite .",
    "the main idea is that each object has a set of discriminative local features that , if appeared together , signify the existence of the object .",
    "same concept applies to actions . for a specific action",
    ", we can identify a set of key frames that best capture the discriminative poses of this action .",
    "however , skeleton poses alone can not distinguish between some actions , e.g. standing up vs.  sitting down , since other information like the direction and speed of motion play an important role in identifying the action .",
    "so , differential quantities that describe joints kinematics must be included in an action s local features .",
    "we then define a _",
    "gesturelet _ to be any general local feature that , for any frame , captures both the skeleton pose and kinematic information of body joints at this point in time . in the following ,",
    "we first introduce our action representation as a bag of gesturelets .",
    "then , we explain our local features descriptor for representing gesturelets .      based on extracted gesturelets from action sequences ,",
    "we make use of a bag - of - gesturelets ( bog ) representation of human actions .",
    "we first extract features at each frame .",
    "resulting descriptors are then clustered to produce a @xmath2-entry codebook .",
    "we then represent any action sequence or sub - sequence by its cluster histogram , where the histogram counts how many local features from each cluster index have occurred . in order to relax the assignment of each gesturelet to its representative cluster in the codebook",
    ", we apply ; letting each gesturelet cast a vote to its @xmath3 nearest clusters .",
    "the vote will be weighted according to the distance between the gesturelet and the corresponding cluster , so that closer clusters get higher weight .",
    "implementation details for soft binning are presented in section  [ sec : implementationdetails ] .",
    "the bog representation is necessary for our approach for action detection , as we show in section  [ sec : els ] .",
    "however , as shown in section  [ sec : exp_recognition ] , it is also very effective for action recognition .",
    "this bog representation is independent of the choice of the local descriptor used to represent a gesturelet .",
    "possible descriptors that capture both pose information and joints kinematics are  @xcite .",
    "the type of local descriptor has a direct impact on the recognition performance .",
    "we experimented with different descriptors , and as a byproduct contribution , we achieved best results with a proposed local descriptor that is a weighted concatenation of the angles descriptor  @xcite and a slight modification of the moving pose descriptor  @xcite .",
    "the angles descriptor uses 35 angles between triplets of joints , @xmath0 , along with angular velocity , @xmath1 . on the other hand ,",
    "the moving pose descriptor relies on joints positions , @xmath4 , relative to a reference joint , namely the hip center . and",
    "to capture kinematic information , it includes the first and second order derivatives ; @xmath5 and @xmath6 . the final form of our descriptor is @xmath7 $ ]  @xmath8  @xmath9 $ ] , where @xmath10 and @xmath11 are parameters defined in  @xcite , and @xmath12 is a weighting parameter to the relative importance of the two concatenated descriptors . in our experiments in section  [ sec : experiments ] , we show that using our simple descriptor and with basic dictionary learning , we can achieve state - of - the - art results over different datasets .",
    "in this section , we first explain our approach on offline action detection .",
    "then , we show how it can be easily extended to work for online detection as well .",
    "figure  [ fig : pipeline ] gives an overview of the approach .",
    "although many successful skeleton - based action recognition systems exist , most of them havent been extended to action detection .",
    "sliding window approaches can be used for this task , evaluating the classifier function over all candidate sub - intervals .",
    "so , for a video sequence s , it will identify the sub - interval , @xmath13 $ ] , for which the classifier function produces the maximum score .",
    "@xmath14 this identifies only one occurrence of the target action in the sequence .",
    "if multiple occurrences are to be found , then we can simply remove sub - intervals corresponding to previously identified actions , and repeat the search for the next @xmath15 .",
    "however , for a sequence of @xmath16 frames , we have @xmath17 candidate sub - intervals , which incurs significant computational complexity .",
    "thanks to lampert _",
    "et al . _",
    "@xcite , an efficient branch - and - bound method was proposed to search for the optimal bounding box of an object in an image .",
    "a limitation to branch - and - bound approaches is that they typically work offline , requiring the whole search space beforehand , as in  @xcite . in  @xcite ,",
    "yuan _ et al .",
    "_ proposed a direct extension of  @xcite on action detection from rgb videos .",
    "they used a bag - of - features model based on spatio - temporal features , and proposed an offline action detection system .",
    "another limitation to  @xcite is that , optimizing equation  [ eq : maxsubwindow ] may not always produce the desired behavior for a detection procedure since the optimal interval may contain multiple consecutive instances of an action .",
    "this problem is less likely to happen in the case of 2d images , for which the original branch - and - bound approach was first introduced  @xcite .    in the following , we present a specialization of the branch - and - bound approach to the case of skeleton - based action detection",
    "this turns out to be easily cast as one of the well - known dynamic programming problems that can be solved in linear time .",
    "next , we show that a greedy approximation can effectively address the offline limitation of the branch - and - bound approach , as well as the problem of combining consecutive actions .",
    "we assume two conditions : ( 1 ) a bag - of - gesturelets representation of action sequences , and ( 2 ) a linear binary classifier with good recognition accuracy trained for a specific target action .",
    "while the linear classifier constraint is not necessary , as we later show , we will use this assumption for simplicity of explanation .",
    "0.43        0.43     0.43        0.43       for any linear classifier , the corresponding scoring and decision functions take the form of : @xmath18 where @xmath19 is a test sequence or sub - sequence , @xmath20 is the feature vector of @xmath19 , @xmath21 is the weight vector learned by the classifier , and @xmath22 is a constant bias . with the linearity of the dot product , @xmath23 , and the fact that @xmath20 is a histogram that counts the occurrence of each cluster index ,",
    "the scoring function  [ eqn : linearclassifier ] can be rewritten as : @xmath24 where , @xmath25 is the cluster index to which gesturelet @xmath26 belongs , and @xmath27 is the total number of gesturelets extracted from sequence @xmath19",
    ".   we can then evaluate the classifier function over any sub - sequence @xmath28 by summing the weights , @xmath29 , of gesturelets @xmath26 that only belong to the sub - sequence @xmath30 .",
    "since we want to identify the sub - sequence @xmath28 that maximizes equation  ( [ eq : svmform2 ] ) , we can safely drop the bias term , @xmath22 .    the offline detection procedure will then be as follows : construct an empty 1d score array , with length equal to the number of frames .",
    "this array will represent the per - point contribution of all extracted features from test sequence @xmath19 .",
    "for each feature @xmath26 , identify its cluster index @xmath25 , then add up its weight , @xmath29 , to the frame index in the score array . finding the start and end frames of the action , @xmath31 $ ] , that satisfy equation  [ eq : maxsubwindow ] can now be mapped to finding the maximum subarray sum in the score array .",
    "thanks to kadane s algorithm  @xcite , this can be done in linear time in the number of frames , using dynamic programming . if @xmath32 , where @xmath33 is a learned threshold for action class @xmath34 , then we specify that action @xmath34 has occurred , and we return the start and end frames of the sub - sequence @xmath15 . to learn the action threshold for each action class , we compute the score of all training sequences , and search for the score threshold , @xmath33 , that minimizes the binary classification error on the training data for class @xmath34 .    to detect different action classes",
    ", we will construct a one - versus - all binary classification model for each action class .",
    "what differs from one action class to another is the classification model weights assigned to each entry in the codebook , along with the learned threshold @xmath33 .",
    "the detection procedure for each of the classes can then be run concurrently on the action sequence with different per - point feature weights for each action class .",
    "it is noted that , while the linearity of the classifier is a sufficient condition , it is not necessary .",
    "any type of classification method that can output a classification score at the frame level can be used with our approach , since we later learn the score threshold , @xmath33 , explicitly .",
    "this gives flexibility to our approach with a wider range of classifiers .      in this section",
    "we extend our approach to handle online action detection . to find the maximum subarray sum",
    ", kadane s algorithm scans through the array . at each position ( frame ) , it identifies the subinterval ending at this position with the maximum sum .",
    "since we only trigger the action if the maximum sum is larger than a learned threshold @xmath33 , then at any time @xmath35 , if the maximum sum ending at frame @xmath36 exceeds @xmath33 , then we know that action @xmath34 is being performed , and our task , then , is to find at which frame the action will end .",
    "we expect that after the action ends , we will encounter a contiguous sequence of frames with negative scores .",
    "so , for the next frames , as long as the maximum sum grows , the action is still on - going . once the subarray sum starts to decrease",
    ", we can assume that the action has ended .",
    "there will be a compromise between latency and confidence .",
    "if we specify the end of action at the first negative point score , this will be very sensitive to noise but it will achieve low latency .",
    "if we wait till we encounter two consecutive points with negative scores , then this will achieve higher confidence at the expense of increased latency , and so on . in our experiments",
    ", we found that triggering the action at the first frame with negative score , after exceeding the threshold @xmath33 , causes a slight decrease of accuracy , while achieving very low latency .",
    "figure [ fig : detection ] shows an example of how online detection works .    as we hinted before , a problem to the offline detection procedure",
    "is that it may combine consecutive repetitions of the same action in one detection .",
    "if an action is repeated twice , with a short pause between them , we expect that each repetition will yield a high positive response , while the pause between them will have a negative response , but not as high .",
    "so , optimizing equation  [ eq : maxsubwindow ] would combine the two repetitions together . to separate the two repetitions ,",
    "the separating negative score must be high .",
    "this problem is solved in online detection with the greedy approach to terminating the action , which only requires consecutive frames with negative scores , without further restrictions on their weight .",
    "section  [ sec : offlinevsonline ] compares offline and online detection to highlight this offline detection limitation .",
    "detecting multiple classes in the online case is similar to the offline case , except that if one action class is detected at time @xmath37 , then the detection procedure for all other classes is reset , and the search for a new detection starts from time @xmath38 .",
    "in this section , we first describe the two datasets used in our experiments .",
    "we then expand on our implementation details .",
    "then , we compare the performance of our approach to the state of the art on both datasets .",
    "we start with the performance on the more classical action recognition task , then , we move to online action detection .",
    "next , we compare offline and online detections . after that , we show how the performance of our approach is affected by changing its main parameters . finally , we demonstrate its real - time performance .      * * msrc-12:**the microsoft research cambridge-12 dataset  @xcite is a large dataset designed for action detection .",
    "it contains more than @xmath39 frames in 594 unsegmented sequences , encompassing @xmath40 gesture instances , recorded for 30 subjects performing 12 different gestures .",
    "the samples consist of the 3d positions of 20 joints of the body skeleton captured using the microsoft kinect sensor at 30 fps .",
    "the msrc-12 dataset is annotated using the notion of an action point , which is a pose within the gesture that clearly identifies its completion . + * * msr - action3d:**msr - action3d dataset  @xcite is a standard dataset for action recognition .",
    "it consists of @xmath41 pre - segmented sequences , with more than @xmath42 frames .",
    "there are 10 subjects performing 20 different action gestures .",
    "similar to msrc-12 , the 3d positions of 20 joints are captured using the microsoft kinect sensor .      for the linear classifier through our experiments",
    ", we use an svm  @xcite with a linear kernel .",
    "the local descriptor has three parameters , @xmath43 , and @xmath12 .",
    "while @xmath43 are inherited from the moving pose descriptor  @xcite , we introduced @xmath12 to weight the relative importance of the two concatenated descriptors .",
    "coarse - grain values for the parameters were learned from the training set , using different combinations of the 3 parameters in a brute - force manner .",
    "trial - and - error was then used to fine - tune the parameters values . for msr - action3d , we split the training set , persons @xmath44 , into training and validation sets , using @xmath45 of the training data ( persons 7 and 9 ) as a validation set . learned parameters ( @xmath46 ) were then fixed for all test experiments on msr - action3d . for msrc-12 , the parameters were learned over one modality ( @xmath47 of the dataset ) , namely the video modality .",
    "learned values ( @xmath48 ) were then used in test experiments over all modalities . for soft - binning , we set the number of neighbors , @xmath3 , to 3 .",
    "the vote to the @xmath49 nearest cluster is weighted by @xmath50 . a control experiment for choosing @xmath3",
    "is shown in section  [ sec : sensitivity ] .",
    "the unsegmented sequences for the msrc-12 dataset contain pauses between consecutive action instances , in which the actor often stands still in a neutral pose .",
    "such a neutral pose also occurs at the beginning and ending of most action instances .",
    "therefore , the neutral pose does not discriminate between different action classes , and hence , the classifier may be tempted to give it a neutral weight , possibly positive in sign .",
    "this would cause a problem for our detection procedure , which relies on having negative scores right before and after an action instance . to overcome this problem , we add hard negatives to the negative training samples used to train our binary classifiers .",
    "each of these hard negatives consists of one positive instance followed by a pause between two consecutive instances . in this way",
    ", the classifier is forced to give strong negative scores to the neutral poses in order to discriminate between those hard negatives and the positive samples , which solves the issue for the detection procedure .",
    "a similar problem occurs in the detection on unsegmented sequences from the msr - action3d dataset .",
    "actions start and end with neutral poses , which could again cause issues in localizing the beginning and ending of action instances . in this case , we include concatenations of two action instances as hard negatives in the binary classifier training .",
    "a weighted moving - average on the frames scores was applied , where the anchor frame had weight equal to number of its neighbors . for msrc-12",
    ", we used a window of 5 frames , anchored at the middle frame ( just as in the local descriptor ) . for msr - action , we used a window of 3 frames , since msr - action3d sequences are much smaller than those of msrc-12 .",
    ".comparative recognition results on msr - action3d . [",
    "cols=\"^,^\",options=\"header \" , ]      the goal of our framework is not only to perform online action detection , but also to do this in real - time .",
    "there are 3 main factors affecting the running time of our approach : 1 ) size of the codebook ; 2 ) size of the local descriptor .",
    "3 ) number of neighbors , @xmath3 , to vote for , in soft binning . for this experiment",
    ", we used a large codebook of size 3000 .",
    "the dimensionality of our descriptor is 250 , and we used @xmath51 .",
    "the average running - time per frame of our matlab implementation was measured to be @xmath52 .",
    "so , our framework can process approximately @xmath53 frames per second .",
    "the running - time was measured on a machine with 2.2 ghz intel quad - core core - i7 processor and 12 gb ram .",
    "we have proposed both a simple skeleton - based descriptor and a novel approach for action detection .",
    "the proposed approach maximizes a binary classifier score over all possible sub - sequences , typically in linear time .",
    "it can be used in conjunction with a large class of classifiers and with any local descriptor .",
    "our proposed approach works online and at real - time with low latency .",
    "it detects a gesture by specifying its start and end frames in an unsegmented video sequence , which makes it suitable for real - time video temporal segmentation .",
    "while the proposed method relies on simple components , we showed that a specialization for skeleton - based action detection can be established which , not only outperforms the state - of - the - art , but also overcomes the limitations of similar approaches .",
    "the authors would like to thank smartci research center for supporting this research ."
  ],
  "abstract_text": [
    "<S> sliding window is one direct way to extend a successful recognition system to handle the more challenging detection problem . while action recognition decides only whether or not an action is present in a pre - segmented video sequence , action detection identifies the time interval where the action occurred in an unsegmented video stream . </S>",
    "<S> sliding window approaches can however be slow as they maximize a classifier score over all possible sub - intervals . </S>",
    "<S> even though new schemes utilize dynamic programming to speed up the search for the optimal sub - interval , they require offline processing on the whole video sequence . in this paper </S>",
    "<S> , we propose a novel approach for online action detection based on 3d skeleton sequences extracted from depth data . </S>",
    "<S> it identifies the sub - interval with the maximum classifier score in linear time . </S>",
    "<S> furthermore , it is suitable for real - time applications with low latency . </S>"
  ]
}