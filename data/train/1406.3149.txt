{
  "article_text": [
    "surface plasmon polaritons ( spps ) are quantized charge density oscillations occurring at the interface between a metal and a dielectric when a photon couples to the free electron gas of the metal .",
    "the emerging field of surface plasmonics has applied spp coupling to a number of new and interesting applications @xcite,@xcite,@xcite , such as surface enhanced raman spectroscopy ( sers ) , photovoltaic devices optimisation , optical filters , photonic band gap structures , biological and chemical sensing , and spp enhanced photodetectors .",
    "some papers appeared in literature simulate and analyse the excitation and propagation of spps on sinusoidal metallic gratings in conical mounting .",
    "researchers working in the emerging field of plasmonics have shown the significant contribution of spps for applications in sensing and optical communication .",
    "one promising solution is to fabricate optical systems at metal - dielectric interfaces , where electromagnetic modes called spps offer unique opportunities to confine and control light at length scales below @xmath0 @xcite,@xcite .",
    "the studies and experiences conducted on spps are well assessed and show that the propagation phenomena are well established by the involved materials in the plasmon structure at large thickness , conversely when it becomes smaller than the wavelength of the exciting wave , investigations are required due to the actual poor understanding  @xcite .",
    "this paper proposes a novel neural netwok ( nn ) topology for the study of the problems of a spp propagating at a metal flat interface separating dielectric medium .",
    "currently , we are using nns to study the inner relation between spps exciting wavelength , metal thickness and spp wavelength and propagation length .",
    "the focus of this paper is on the determination of the dependance of the spp propagation of the metal thickness by recurring to suitable nn schematics . due to the high sensitivity of the neural model to data oscillations",
    "a novel training procedure has been devised in order to avoid polarisations and miscorrections of some nn weights . moreover , since such a training procedure could be expensive in terms of computational power and wall - clock time , a parallel version using an openmp environment , with shared memory , has been developed and optimised to obtain maximum advantage from the available parallel hardware .",
    "a big amount of data has been put into proper use for the investigated nn topology .",
    "such data have been made available by the resolution of 3d maxwell equations with relative boundary conditions performed by comsol multiphysics , which is an efficient and powerful software package to simulate the characteristics of spps .",
    "the field of plasmonics is witnessing a growing interest with an emerging rapid development due to the studies and researches about the behaviour of light at the nanometer scale .",
    "light absorption by solar cells patterned with metallic nanogratings has been recently investigated , however we consider light - excited spps at the metal surface .",
    "the outcomes of our investigation can be used to improve efficient capturing of light in solar energy conversion cells  @xcite .",
    "therefore , our main research interests are toward the properties of spps .",
    "spps are electromagnetic waves propagating along metal - dielectric interfaces and exist over a wide range of frequencies , evanescently decaying in the perpendicular direction .",
    "such electromagnetic surface waves arise via the coupling of the electromagnetic fields to oscillations of the conductor electron s plasma @xcite .",
    "spp is the fundamental excitation mode at a metal - dielectric interface that is coupled to an electromagnetic wave as described by @xcite .",
    "the most simple geometry sustaining spps is that of a single , flat interface ( see fig .  [ s1 ] ) between a dielectric , non - absorbing half space ( @xmath1 ) with positive real dielectric constant @xmath2 and an adjacent conducting half space ( @xmath3 ) described via a dielectric function @xmath4 .",
    "the requirement of metallic character implies that @xmath5 < 0 $ ] .",
    "as shown in @xcite , for metals this condition is fulfilled at frequencies below the bulk plasmon frequency @xmath6 .",
    "we look for propagating wave solutions confined to the interface , i.e. with evanescent decay in the perpendicular z - direction @xcite .",
    "the electromagnetic field of a spp at the dielectric - metal interface is obtained by solving maxwell s equations in each medium with the associated boundary conditions .",
    "the adopted structure is a metal - dielectric interface composed by molybdenum and air as shown in fig .",
    "this structure is the most simple in order to reduce computational effort , as the main purpose of the paper is to investigate the important relation between dispersion and thickness of the metal by means of a proper novel nn architecture .",
    "it should be noted that this relation is not affected by the complexity of the structure .",
    "the basic mathematical equations describing the electromagnetic phenomena concerning spp propagation are listed below :     @xmath7 with boundary condition at @xmath8     @xmath9 as a consequence of the previous equation we have    @xmath10    we consider a system consisting of a dielectric material , characterised by an isotropic , real , positive dielectric constant @xmath11 , and a metal characterised by an isotropic , frequency dependent , complex dielectric function @xmath12 . in order to introduce the main parameters characterising spps assuming the interface is normal to z - axis and the spps propagate along the x direction ( i.e. , @xmath13 ) , the spp wavevector @xmath14 or @xmath15 is related to the optical frequency @xmath16 through the dispersion relation .",
    "@xmath17    @xmath18    we take @xmath16 to be real and allow @xmath14 to be complex , since our main interest is in stationary monochromatic spp fields in a finite area , where    @xmath19    is the wavevector in free space , and @xmath20 is the wavelength in vacuum . for metals , the permittivity is complex , which leads to @xmath14 being complex .",
    "the imaginary part of @xmath14 defines the spp s damping and as it propagates along the surface .",
    "the real part of @xmath14 is connected to the plasmon s wavelength , @xmath21 :    @xmath22 } \\label{eq:7}\\ ] ]    @xmath23 is the spp propagation length , physically the energy dissipated through the metal heating and it is the propagation distance .",
    "@xmath23 is defined as follows :    @xmath24 } \\label{eq:8}\\ ] ]    finally , the following reports the expression of the electric field of plasmon wave :    @xmath25    where @xmath26",
    "by solving the full wave 3d maxwell equations in the simple geometry shown in fig .",
    "[ s2 ] , which separates two media as metal and dielectric , using the finite element method - based software package comsol multiphysics , we have obtained the @xmath23 and @xmath21 data values for different thickness values .",
    "the perfectly matched layer boundary condition was chosen for the external surface of the plasmon structure .",
    "the exciting wave was monochromatic on the visible spectra and ranging from @xmath27 to @xmath28 .",
    "we have performed many numerical simulations while varying the exciting wavelengths for each investigated thickness , hence obtaining the corresponding spp waves .",
    "a spp propagates at the interface dielectric - metal decaying into the metal .",
    "the values of @xmath23 and @xmath21 were computed for the all visible range of wavelength at the following different thickness values @xmath29 of the metal : @xmath30 , @xmath31 , @xmath32 , @xmath33 , @xmath34 , @xmath35 , @xmath36 , @xmath37 and @xmath38 .",
    "the prediction of @xmath39 and @xmath23 from the set of values @xmath40 and @xmath29 is related to the problem of the dependence of @xmath23 from @xmath39 . to obtain a correct prediction of @xmath39 by a neural network - based approach a value of @xmath39 is needed .",
    "although this can be obtained by a cascade process , the traditional means have that the nn cascade is accommodated by separate training sessions for each different dedicated nn . unfortunately , such training sessions would result in very time - consuming computation .    in order to overcome the said complication",
    ", this paper proposes a novel parallel paradigm for training that manages to run a single comprehensive training for the nn cascade as a whole , thus avoiding separate training phases .",
    "this novel solution has been used for the problem at hand , described in section  [ polaritoni ] .",
    "essentially , the adopted topology has been derived from a pair of common two - layer feed - forward neural networks ( ffnns ) @xcite , used to separately predict @xmath39 and @xmath23 , respectively .",
    "the comprehensive structure is similar to a cascade feed - forward , whereby the output of the first neuroprocessing stage is connected with the input of the second stage and form a new extended input vector for the second stage . on the other hand ,",
    "the vector provided as input to the second neuroprocessing stage depends on the predicted values obtained from the first stage , hence it propagates a prediction error .    moreover , during the training phase , while some outputs can be validated for the first neuroprocessing stage , the localised deviation from the correct frequency spectrum could corrupt the training of the second stage .",
    "the behaviour of this novel topology is as a two step processing of the data signal that is comprehensive also of a so called _ second validation _ or _",
    ", described in the following , aiming at avoiding such an error propagation , which would otherwise endanger the correct training of the second neuroprocessing stage .",
    "a given output from the first stage has to be validated on the frequencies domain , by a validation module , before it can be used .",
    "this validation module performs the @xmath41-validation by means of the fourier computation on a delayed gaussian window of the output and training signal .",
    "an intermediate level of data processing requires the implementation of a module performing the fourier transform of the data .",
    "its relative parameters are not _ a priori _ established , however are on - line determined by the novel nn topology and then by its training procedure .",
    "[ fig : cascade ] represents the proposed architecture , which will be detailed in the following .",
    "it is possible to recognise two groups of modules , the first comprising ` iiia ` and ` iva ` , whereas the second ` iiib ` and ` ivb ` , each acting as a ffnn .",
    "the proposed novel topology behaves as a cascade ffnn topology @xcite .",
    "[ fig : recurrent ] depicts a more complex novel topology that performs the prediction as a nonlinear autorecoursive with exogenous inputs ( narx ) recurrent neural network topology @xcite .",
    "such figure shows the implemented delay lines to the blocks performing the neural processing .",
    "it should be noted that we have implemented one neuron as a _",
    "purelin _ while the remaining neurons in the first hidden layer process the input signal .",
    "the performed simulations have shown an increased computational effort , for this recurrent scheme , while the corresponding results have not significantly improved the accuracy on the predicted data .",
    "even though this is a novel recurrent cascade topology this paper fully investigates the scheme shown in fig .",
    "[ fig : cascade ] .",
    "the following provides the details of the proposed nn cascade .",
    "[ [ input - data - analysis . ] ] input data analysis .",
    "+ + + + + + + + + + + + + + + + + + + +    the input layer ( ` i ` ) does not directly provide the input vector ( @xmath42 ) to the first ffnn hidden layer ( ` iiia ` ) , being it firstly processed by an intermediate layer ( ` ii ` ) that is trained to extrapolate a set of parameters necessary to perform the @xmath41-validation , i.e.  the @xmath43 for the gaussian window fourier analysis .",
    "this layer ( ` ii ` ) is also provided with ad adjunct _ purelin _ neuron acting as a transmission line for the following layer ( ` iiia ` ) .",
    "the main purpose of ` ii ` is to characterise the frequency peaks windows on the data spectrum in order to associate , after the training phase , an optimum @xmath43 value to perform gaussian - window fourier analysis on the output data from the second ffnn hidden layer ( ` iva ` ) .",
    "for this reason , the input to the following layers are provided as    @xmath44\\\\ \\\\",
    "\\mathbf{x}^{\\texttt{iiia } } = & \\mathbf{x}^{\\texttt{i}}&~\\\\ \\label{eq : io1 } \\end{array}\\ ] ]    where @xmath45 retains the discrete sample number @xmath46 and both the window size @xmath47 and @xmath43 for the described fourier analysis .",
    "[ [ ffnns - hidden - layers ] ] ffnns hidden layers + + + + + + + + + + + + + + + + + + +    the first neuroprocessing module acts as a fully connected ffnn and consists of two hidden layers , i.e.`iiia ` and ` iva ` .",
    "the first hidden layer ( ` iiia ` ) embeds 10 neurons with _ tansig _ activation function , whereas the second hidden layer ( ` iva ` ) consists of 7 neurons with _ logsig _ activation function .",
    "similarly , the second neuroprocessing module provides the functionalities of a fully connected ffnn , however its two hidden layers , ` iiib ` and ` ivb ` , consist of 8 and 5 neurons with _ tansig _ activation function , respectively .",
    "[ [ ffnn - training - and - validation ] ] ffnn training and validation + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the implemented ffnn neuroprocessing modules are trained by the levenberg - marquardt algorithm with a gradient descent method .",
    "hence , for the @xmath46-esime discrete time step , the variation introduced to the weights are given by @xmath48 where @xmath49 represents the value for the @xmath46-esime step of the connection weight from the @xmath50-esime neuron of the @xmath51 layer to the @xmath52-esime neuron of the @xmath53 layer , @xmath54 is the learning rate parameter , @xmath55 and @xmath56 are respectively the training and output signal from the @xmath51 layer .    [",
    "[ omega - validation ] ] @xmath41-validation + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the output of the first neuroprocessing module comes from the second ffnn hidden layer ( ` iva ` ) and is sent , as valid output , to the last layer of the network and also as input to the validation module ( ` va ` ) .",
    "the validation module consists of a functional unit performing the fast fourier transform on a selected window of the input signals .",
    "moreover , the validation module uses a dynamically allocated buffer to implement a size - varying delay line .",
    "the latter is used to enable real - time online resizing of the fourier window to suit the properties of the investigated signal .",
    "these adjustments are performed starting from the parameters contained in @xmath45 .",
    "once the gaussian windowed fourier transform has been computed , the following values are determined    @xmath57}\\left\\{~\\left\\vert \\hat{f}_\\sigma[\\tilde{\\mathbf{y}^{\\texttt{iva } } } ] - \\hat{f}_\\sigma[\\mathbf{y}^{\\texttt{iva}}]\\right\\vert~\\right\\}\\\\ m(\\tau,\\delta_\\tau,\\sigma ) = & \\min\\limits_{[\\tau:\\tau+\\delta_\\tau]}\\left\\{~\\left\\vert\\hat{f}_\\sigma[\\tilde{\\mathbf{y}^{\\texttt{iva } } } ] - \\hat{f}_\\sigma[\\mathbf{y}^{\\texttt{iva}}]\\right\\vert~\\right\\ } \\end{array } \\label{eq : mm}\\ ] ]    then the module is trained to admit only certain regions of the @xmath58 pairs plan which validate the output signal of the layer ` iva ` .",
    "if the output signal results validated , it is then sent as input for the layer ` iiib ` as    @xmath59\\ ] ]    the first neuroprocessing module takes @xmath60 as input and is trained by all the available patterns , while the second module is trained only by the allowed sequences selected according to the validation procedure . in the other case , i.e.  if the @xmath41-validation is negative , the second module skips the data during the training process and gives a nan flagging , being the relative data for the second variable unavailable .    [",
    "[ final - output ] ] final output + + + + + + + + + + + +    finally , the implemented topology gives a global output with a layer consisting of two neurons _",
    "the neural network architecture proposed above has introduced a sequential validation phase for the results of the first neuroprocessing module .",
    "validation has to be performed before the first module results can be sent as input for the second module .",
    "unfortunately , such sequential operations make the training process expensive in terms of cpu time . in order to shorten training time",
    ", this section describes a parallel implementation of the same neural network architecture , using openmp , that manages to obtain asynchronous training and validation .",
    "generally , when parallelising an application using openmp , processes are forked , joined and synchronised ( e.g.  by means of a barrier ) . such mechanisms , however , introduce a runtime overhead , e.g.  when the processes having produced and communicated their results have to wait until the synchronisation barrier is over .",
    "this is often the case when the computation times of processes are not perfectly balanced @xcite .",
    "therefore , our parallel version aims at reducing such an overhead by avoiding , as much as possible , the fork - join - barrier constructs , and by introducing instead processes that produce and consume data .",
    "the main reason for using openmp is that , by means of a shared memory , communication overhead among processes can be avoided , however , on the other hand , shared memory requires a complex handling of semaphores and locks before accessing some parts of the memory itself .",
    "we have handled the synchronisation concern in such a way that overhead is minimised @xcite .",
    "mainly , the proposed parallel solution is based on the continuous execution of different processes to care for the different phases of training for the above nn cascade . in our experiments",
    "a multi - core processor has been used , however any kind of shared memory system supporting openmp directives can be employed .",
    "the proposed nn cascade has been trained to predict the values of @xmath39 and @xmath23 starting from an input vector    @xmath61\\ ] ]    to evaluate the performance of the nn cascade , two different kinds of error were considered .",
    "we define two _ local errors _ @xmath62 and @xmath63 , as well as a",
    "_ global error _ @xmath64 as follows :    @xmath65    where @xmath66 indicates the training value .               for each training epoch , the outputs from layers ` iva ` , ` ivb ` and ` vi ` ( see fig .  [",
    "fig : cascade ] . ) were used to compute the errors @xmath67 , @xmath68 and @xmath64 as in .",
    "the training has been organised in four different activities , executed on an openmp environment ( see fig .",
    "[ fig : procs ] ) .",
    "the first activity , named , feeds the whole neural network cascade with a training pattern , which has been previously generated .",
    "the second activity , named , and started once the first activity has terminated , uses a gradient descent algorithm to adjust the neural weights of the intermediate layer ` ii ` and the first neuroprocessing ( layers ` iiia ` and ` iva ` ) .",
    "the third activity is the and is started concurrently with , hence after has finished , since the results produced by ` iva ` are needed .",
    "the activity performs the gaussian windowed fast fourier transform of the training set and the predicted signal resulting as output of ` iva ` , then @xmath69 and @xmath70 defined in are computed .",
    "eventually , the values of @xmath69 and @xmath70 are used to decide if the pattern data are usable to train the second neuro - processing module ( ` iiib ` and ` ivb ` ) .    finally , the fourth activity is ` phase b ` performing a further training that adjusts the output weights of layer ` vi ` . for the proposed schema ( see fig .  [",
    "fig : cascade ] ) , module ` vb ` acts as a controller determining whether it is appropriate to merge data from ` iva ` and ` ivb ` before they can be given as input to ` vi ` . the merge is enabled when the has given a positive result , otherwise only data resulting from ` iva ` are used . moreover , all the weights in layer ` vi ` are adjusted when the result of is positive , otherwise only the synaptic weights of the first neuron in ` vi ` is adjusted .",
    "the four activities above are started each as a process ( see fig .  [",
    "fig : procs ] ) . process ` nn simulation ` feeds data and triggers the execution of processes ` phase a ` and ` \\omega - validation ` .",
    "the latter two processes give their outputs to process ` phase b ` , and then _ wait _ for new data , till the training stops .",
    "process ` phase b ` starts as soon as input data are available . at the end of the training epoch",
    "the global network performances are stored for further analysis .",
    "all the measures of performance involved in the training process are given by the mean squared error ( mse ) , though for the global network performances , the formula is adjusted by using the global error @xmath64 of .    fig .  [",
    "fig : procs ] shows in two vertical tiers some rectangles .",
    "each rectangle corresponds to a process that can execute in parallel with another that is on the same row . in the picture",
    ", the time evolves while going down .",
    "the arrows with continuous lines represent a flow of data from a producer to a consumer process , whereas the dotted line the communication of an event .",
    "ellipses show repositories of data .",
    "the said interactions among processes are iterated until the training session stops .",
    "while having devised a parallel solution , our effort has been to optimise the use of computational resources , hence autonomous processes needing as less synchronisation as possible have been implemented as described above .",
    "our proposed solution manages to greatly reduce the wall - clock timeframe needed for the training .",
    "for training and evaluation we have used the global error @xmath71 to compute the mean square error ( mse ) of the network . fig .  [ fig : perf ] shows the performance of the proposed and implemented novel cascade nn architecture in terms of such metrics .",
    "[ fig : out1 ] reports the values of the computed and predicted @xmath39 and @xmath23 .",
    "the obtained results confirm the good predictions obtained by the novel nn schema .",
    "the proposed nn cascade has been mainly derived from a couple of common two - layer feed - forward neural networks used to separately predict @xmath39 and @xmath23 .",
    "the comprehensive structure is similar to a cascade feed - forward , where the output of the first neuroprocessing stage has been connected with the inputs for the second stage to form a new extended input vector .",
    "simulation results for the nn cascade confirm the effectiveness of the developed novel architecture whose performance during the training and evaluation phases show a very low mse .",
    "other complex nn architectures such as pure narx model or advanced wavelet recurrent neural networks  @xcite could not be used because of the prediction instability for the data at hand .",
    "franken , r.h . ,",
    "stolk , r.l . , li , h. , van der werf , c. h m. , rath , j.k . ,",
    "schropp , r. e. i. : understanding light trapping by light scattering textured back electrodes in thin film n - i - p - type silicon solar cells .",
    "journal of applied physics , 102(1 ) , 14503 - 14509 ( 2007 )                          capizzi , g. , napoli , c. , patern , l. : an innovative hybrid neuro - wavelet method for reconstruction of missing data in astronomical photometric surveys . international conference on artificial intelligence and soft computing ( icaisc12 ) , vol i , 21 - 29 ( 2012 ) ."
  ],
  "abstract_text": [
    "<S> surface plasmon polaritons ( spps ) confined along metal - dielectric interface have attracted a relevant interest in the area of ultracompact photonic circuits , photovoltaic devices and other applications due to their strong field confinement and enhancement . </S>",
    "<S> this paper investigates a novel cascade neural network ( nn ) architecture to find the dependance of metal thickness on the spp propagation . </S>",
    "<S> additionally , a novel training procedure for the proposed cascade nn has been developed using an openmp - based framework , thus greatly reducing training time . </S>",
    "<S> the performed experiments confirm the effectiveness of the proposed nn architecture for the problem at hand .    </S>",
    "<S> neural network architectures , surface plasmon polaritons , plasmonics , plasmon structure .    </S>",
    "<S> shell : bare demo of ieeetran.cls for journals    preprint version +    @incollection\\ { + year=\\{2014 } , + isbn=\\{978 - 3 - 319 - 07172 - 5 } , + booktitle=\\{artificial intelligence and soft computing } , + volume=\\{8468 } , + series=\\{lecture notes in artificial intelligence } , + editor=\\{rutkowski , leszek and korytkowski , marcin and scherer , rafa and tadeusiewicz , ryszard and zadeh , lotfia . and </S>",
    "<S> zurada , jacek m. } , + title=\\{a cascade neural network architecture investigating surface plasmon polaritons propagation for thin metals in openmp } , + publisher=\\{springer berlin heidelberg } , + author=\\{bonanno , francesco and capizzi , giacomo and lo sciuto , grazia and napoli , christian and pappalardo , giuseppe and tramontana emiliano } , + pages=\\{22 - 33 } + }    published version copyright   2014 springer + uploaded under self - archiving policies + no copyright infringement intended + </S>"
  ]
}