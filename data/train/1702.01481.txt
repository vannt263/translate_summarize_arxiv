{
  "article_text": [
    "in the ansatz - based approach to electronic structure theory , the capabilities of the method used to optimize the ansatz for a particular system are every bit as important as the flexibility of the ansatz itself .",
    "for example , both the coupled cluster @xcite and matrix product state @xcite ansatzes would be much less useful if we lacked the projected schrdinger equation and density matrix renormalization group methods that allow us to optimize them efficiently . to address unsolved problems in electronic structure",
    " such as catalytic cycles in which many bonds are simultaneously rearranged @xcite , double excitations in large @xmath0-conjugated molecules@xcite , and high - temperature superconductivity @xcite  it is therefore essential that improvements to optimization methods be made alongside innovations in ansatz design .    in few areas",
    "is the need for improved optimization methods more pressing than in quantum monte carlo ( qmc ) . until very recently , optimization methods in this area were limited to a few thousand variational parameters when using a fully ab initio hamiltonian , a constraint that holds back progress in a wide variety of areas . in fixed - node projector monte carlo methods such as diffusion monte carlo ( dmc ) @xcite , the inability to systematically converge the trial function",
    "s nodal surface due to insufficiently flexible ansatzes is responsible for both the fixed node error and the pseudopotential locality error , the latter of which becomes acutely problematic in 3rd - row and heavier elements where the nonlocal part of the pseudopotential can not be ignored . even in variational monte carlo @xcite ( vmc ) itself , recent innovations in ansatz design create a pressing need for expanding the number of variational parameters that can be treated .",
    "examples in this category include the variation after response approach to excited states @xcite , efficient methods for large multi - slater jastrow ( msj ) expansions @xcite , variational analogues of coupled cluster theory @xcite , and wave function stenciling approaches @xcite that tightly couple the optimization of correlation factors and molecular orbitals .",
    "for all of these reasons , and indeed for the simple reason of enabling systematic improvability within a given ansatz , improvements in vmc optimization capabilities are sorely needed .",
    "the linear method @xcite ( lm ) developed by umrigar and coworkers is currently the most effective vmc optimizer for cases in which the number of variables is a few thousand or less . by solving a projected schrdinger equation in the vector space spanned by the current wave function and its first parameter derivatives , a space we will refer to as the self - plus - tangent space , the lm produces update steps that account for",
    "second order couplings between variables and in practice often out - perform newton - raphson steps , a success due in no small part to the fact that these updates satisfy a strong zero variance principle @xcite .",
    "however , the traditional lm s need to explicitly construct the hamiltonian and overlap matrices in the self - plus - tangent space becomes cumbersome when the number of variational parameters exceeds a few thousand due to the large amounts of memory required to store these matrices .",
    "this issue becomes especially fraught when trying to match the lm to modern supercomputing resources , as each parallel markov chain must make space for its own copies of these matrices ( a tall order given typical per - core memory restrictions ) , which must then be communicated and combined prior to diagonalization . while one could use krylov subspace methods to solve the eigenproblem without explicitly constructing the matrices , as was done for the related stochastic reconfiguration method @xcite , our experience in practice",
    "has taught us that finding a preconditioning scheme capable of reducing the condition numbers of the lm matrices to manageable levels is not trivial .",
    "as far as we are aware , these various issues have prevented the lm from being used in regimes beyond about 16,000 variables , which occurred in the context of a ground state msj expansion for the water molecule @xcite .",
    "very recently , booth and coworkers introduced an alternative vmc optimization method that takes advantage of optimal descent theory and a stochastic gradient evaluation in order to produce robust energy minimizations despite avoiding second - derivatives entirely @xcite . impressively",
    ", this method appears capable of handling more than 60,000 variational parameters for ansatzes that support efficient inner products with the slater determinant basis functions of fock space .",
    "however , as the method relies on having fast access to hamiltonian matrix elements between basis functions , it is not immediately obvious how to extend it to the delta - function basis of real space where such matrix elements are ill - defined . nonetheless , promising new directions in vmc optimization are a welcome development .    in the present study",
    ", we seek to retain the advantages of the traditional lm  which include fock space and real space compatibility , robust convergence in a small number of iterations , and access to excited states through our recently introduced @xcite excited state variational principle  while reducing its memory footprint so as to facilitate larger variable sets and better compatibility with modern parallel computers",
    ". our strategy will be to separate the variable space into blocks , within each of which we estimate a small number of important update directions that can then be used to construct a relatively small lm eigenproblem in the overall basis of important directions .",
    "we will demonstrate that this approach drastically reduces memory requirements without significantly affecting the accuracy of the optimization .",
    "in addition to tests on small molecules using our in - house hilbert space software , we will use the implementation that we recently contributed to the open - source qmcpack software package @xcite to demonstrate this method s excited state capabilities in the context of a hydrogen ring s mott - like metal - insulator transition . by evaluating the optical gap for a series of increasingly flexible msj expansions ,",
    "the largest of which contains over 25,000 variational parameters , this study points the way towards a systematically convergent and non - perturbative approach to predicting optical gaps in the mott - insulating regimes of real materials .",
    "the traditional lm works by repeatedly solving the schrdinger equation in the self - plus - tangent subspace of the full hilbert space , defined by the span of the wave function and its first derivatives with respect to its variational parameters . as",
    "the derivatives are not necessarily orthogonal to each other , this approach leads to a generalized eigenvalue problem @xmath1 where @xmath2 and @xmath3 are the derivatives of @xmath4 with respect to the @xmath5th and @xmath6th wave function parameters @xmath7 and @xmath8 , respectively , and @xmath9 . after solving this eigenvalue problem for @xmath10 ,",
    "one updates the parameters by @xmath11 after which the updated @xmath12 will be a good approximation for the subspace eigenfunction @xmath13 so long as the updates @xmath14 are sufficiently small in magnitude .",
    "this requirement can be ensured by applying a diagonal shift to the hamiltonian matrix @xcite , which plays the same role as a trust radius would in a newton - raphson optimization .",
    "the updated ansatz in hand , a new self - plus - tangent space may be constructed and the procedure repeated until convergence is reached .    in practice , the hamiltonian and overlap matrix elements are estimated via monte carlo sampling , @xmath15 where @xmath16 is a set of samples drawn from the probability distribution @xmath17 ( which is typically chosen as @xmath18 ) using markov chain monte carlo .",
    "note that although we have depicted the sampling as running over occupation - number - vector - labeled determinants in fock space , the lm is equally viable if instead the sampling is carried out in real space , where @xmath19 is typically chosen to be @xmath20 .",
    "the lm will thus be efficient ( i.e.  polynomial cost ) for ansatzes that support the efficient evaluation of the derivative ratios @xmath21 and @xmath22 , examples of which include msj expansions @xcite , the jastrow antisymmetric geminal power @xcite ( jagp ) , and amplitude determinant coupled cluster with pairwise doubles @xcite .    while the cost scaling may be polynomial with system size",
    ", the memory required to store the hamiltonian and overlap matrices in the self - plus - tangent space can be a serious impediment to practical computation .",
    "for example , when using 8-byte floating point numbers and an ansatz with 30,000 variational parameters , the traditional lm requires 14.4 gigabytes of memory per markov chain .",
    "such storage requirements create problems with the typical parallelization scheme of running one markov chain per core , as modern supercomputers typically have closer to 2 gigabytes of memory available per core .",
    "one approach to circumventing matrix storage difficulties would be to use a krylov subspace method to solve for @xmath10 without constructing the matrices explicitly . while this strategy has shown promise in the related stochastic reconfiguration method , where it succeeded in working with an ansatz containing half a million variables @xcite , krylov subspace methods are only efficient if the condition numbers of the matrices involved ( the ratio of the magnitudes of their largest and smallest magnitude eigenvectors ) can be brought close to unity through preconditioning .",
    "although we have made some ad - hoc investigations into this area , we have not found preconditioners that can reliably reduce the condition numbers involved below about @xmath23 .",
    "while this does not preclude the existence of an effective preconditioning scheme , it does prompt us to investigate approaches , like the one in the next section , that remain effective even in the face of highly ill - conditioned matrices .      ultimately , the goal of the lm is to find the best update direction and step length within the tangent space of the wave function .",
    "imagine instead holding half the variables fixed and inspecting the tangent space for the other half .",
    "the diagonalization of the linear method eigenproblem within this self - plus - half - tangent space will produce a set of update directions that can be ordered by importance , as measured by their eigenvalues , which inform us as to how much a move along an eigen - direction would decrease or increase the energy .",
    "noting that the optimal direction @xmath24 in the full tangent space , whose dimension is the total number of variational parameters @xmath25 , can be written as a linear combination of @xmath26 orthogonal directions within one half - tangent space and @xmath26 orthogonal directions from the other half - tangent space , it seems intuitive that a very bad update direction in one of the half - tangent spaces is unlikely to be an important component of @xmath24 .",
    "taken further , this logic suggests that it may be possible to construct a close approximation to @xmath24 using a linear combination of only a few update directions from each half - tangent space .",
    "in essence , the blocked linear method ( blm ) is an attempt to systematically exploit this structure by ( a ) dividing the variable space into a number of blocks , ( b ) making intelligent estimates for which directions within those blocks will be most important for constructing @xmath24 , and ( c ) estimating @xmath24 by solving a smaller , more memory - efficient eigenproblem in the basis of these supposedly important block - wise directions .    rather than the traditional lm s expansion of the wave function in its self - plus - tangent space , consider instead the `` one - block '' expansion @xmath27 in the first two terms",
    ", we have a linear expansion of the wave function with respect to the variables belonging to the @xmath28th block , with @xmath29 and @xmath30 the expansion coefficients , @xmath31 the number of variables in the block , and @xmath32 defined as the wave function derivative with respect to the @xmath33th variable of the @xmath28th block .",
    "if we drop the third term for now ( i.e.  set @xmath34 ) , we have a wave function whose energy minimization @xmath35 leads to a generalized eigenvalue problem in the same form as for the traditional lm , eq .",
    "( [ eqn : eigen ] ) , the only difference being that we are now holding the variables outside the chosen block fixed . ( note that while we will develop the discussion here in terms of energy minimization , the blm is equally applicable to the target function used in the direct , variational targeting of excited states @xcite and has been implemented and tested for both cases ) .",
    "each eigenvector will have its own values for the @xmath29 and @xmath30 coefficients and will correspond to an eigenvalue that gives an estimate for what the energy of our original wave function would be if we were to update this block s variables according to @xmath36 .",
    "thus , the eigenvalues of this block s eigenproblem inform us as to which directions in its variable space are expected to be `` good '' update directions ( those with the lowest eigenvalues ) and which are expected to be `` bad '' directions ( those with the highest eigenvalues ) .    having performed this diagonalization within each of our blocks , we are now in a position to construct an approximation to the wave function in its full self - plus - tangent space by retaining from each variable block only a small number of what are expected to be the best update directions . by organizing the best @xmath37 update directions from the @xmath28th block into the rows of a matrix @xmath38",
    ", this self - plus - tangent space approximation can be written as @xmath39 as the elements of the @xmath40 matrices are now held fixed , this expansion is not as flexible as that of the traditional lm , but we hope the fact that it is built out of a linear combination of the best update directions from each block will give it the correct flexibility to closely approximate the optimal update direction in the full tangent space . this direction is now estimated via @xmath41 which again produces a generalized eigenvalue problem , this time of dimension @xmath42 , whose lowest energy eigenvector corresponds to the overall blm update , @xmath43_{bi}}{\\alpha}.\\end{aligned}\\ ] ] crucially , the hamiltonian and overlap matrix elements involved in the eigenvalue problems that stem from eqs .",
    "( [ eqn : block_min ] ) and ( [ eqn : full_min ] ) can be estimated using the same information as in the traditional lm , namely the derivative ratios @xmath21 and @xmath22 , at each sampled configuration @xmath44 ( or position @xmath45 in real space ) .",
    "while the most efficient way to construct these matrices now that the @xmath38 coefficients are known appears to be to re - run the same sample that was used to construct the block - specific matrices , we feel that this second sampling is a price worth paying in order to remove the traditional lm s memory bottleneck .",
    "so far , we have ignored the fact that inter - block variable couplings will affect which directions in a block are optimal for use in constructing an overall update direction .",
    "accounting for such couplings is the purpose of the third term in eq .",
    "( [ eqn : blm_expansion ] ) , in which @xmath46th block that is presumed to correspond to a good update direction for that block . by including a small number @xmath47 of these directions from each other block in the wave function expansion @xmath48 for the current block , we hope to provide the minimization @xmath49 which replaces that of eq .",
    "( [ eqn : block_min ] ) in the overall method outlined above , with the coupling information necessary so that the directions it contributes to @xmath38 are optimal with respect to both intra - block and inter - block variable couplings .",
    "while there are many possible choices for the linear combinations @xmath50 , we thought it natural to derive them from previous iterations blm updates , following the idea that using previous update directions to inform the current direction is a common theme in numerical minimization , occurring for example in both the bfgs @xcite and accelerated descent @xcite methods .",
    "specifically , for the @xmath51th iteration of the blm , we take @xmath50 as the @xmath52th block s component of the @xmath53th iteration s overall update , with @xmath54 . as our results will demonstrate , even relatively short history lengths @xmath47 can be beneficial in accounting for inter - block variable couplings and thereby recovering the performance of the traditional lm .",
    "th block , with each section of the matrix displaying its type of matrix element .",
    "green - shaded sections contain elements that are unique to each block ; for the larger among these , we print the number of elements that must be stored per block .",
    "blue - shaded sections contain elements shared by all blocks ; for the larger among these , we print the total storage requirement across all blocks .",
    "total memory consumption can then be evaluated as blue + @xmath55green . ]    to understand the reduced memory footprint of the blm , it is helpful to consult a visual guide to the structure of the hamiltonian and overlap matrices resulting from eq .",
    "( [ eqn : full_block_min ] ) .",
    "figure [ fig : mat_struct ] shows this structure for the hamiltonian ; the overlap matrix has an analogous structure .",
    "noting that the different blocks eigenproblems can be solved independently , we can see that only one block s matrices need to be fully constructed at a time , which greatly reduces memory requirements by allowing us to store one copy , rather than @xmath56 copies , of the blue elements in figure [ fig : mat_struct ] . for the green elements , however , we must store @xmath56 copies simultaneously , so that each sampled configuration @xmath44 or @xmath45 can efficiently add its unique contribution to each of them . nonetheless , storage requirements are much lower than in the traditional lm , whose hamiltonian matrix contains @xmath57 elements .",
    "although the precise formula for the blm s hamiltonian storage requirement is more longwinded , the terms that dominate , @xmath58 and @xmath59 , are much smaller than the dominant @xmath60 term in the lm .",
    "thus , if no previous updates are being used ( i.e.  @xmath61 ) , the blm reduces memory requirement by a factor of @xmath56 , and although the use of @xmath62 increases the blm s memory requirement somewhat , the savings remain substantial .",
    "for example , when using 8-byte floats and 30,000 variational parameters , the traditional lm requires 14.4 gigabytes of memory per process , while the blm with @xmath63 and @xmath64 requires only 0.5 gigabytes per process .",
    "jagp results for n@xmath65 and h@xmath65o were obtained using hilbert - space sampling via our own vmc software , which extracts one- and two - electron integrals from pyscf @xcite .",
    "msj results for c@xmath65 and the hydrogen ring were obtained using real - space sampling via qmcpack @xcite , with configuration state functions ( csfs ) taken from gamess @xcite . for jagp",
    ", we work exclusively in the symmetrically orthogonalized `` @xmath66 '' one particle basis . the vmc sample size is universally chosen as 2.4@xmath6710@xmath68 , which produces statistical uncertainties whose standard deviations are less than 0.7 kcal / mol ( 0.03 ev ) in all cases .",
    ".comparison of the lm ( @xmath69 ) and blm for the ground state of n@xmath65 using the jagp ansatz with hilbert - space sampling in the 6 - 31 g basis .",
    "[ cols=\"^,^,^,>,<,>,<,^\",options=\"header \" , ]     0.49     0.49     the second observation is that the error behaves as expected for different values of @xmath56 , @xmath37 , and @xmath47 .",
    "increasing the number of blocks @xmath56 , which makes it harder to account for second - order couplings between variables when choosing update directions , increases the deviation from the traditional lm .",
    "also as expected , increasing @xmath37 and @xmath47 tends to decrease the deviation . as hypothesized in the motivation for the blm , only modest values of @xmath37 and @xmath47",
    "are required to produce close approximations to the optimal update direction , and so mitigating deviations from the traditional lm is not difficult .",
    "finally , we note that although the blm typically requires more iterations to converge , the convergence speed remains similar to the traditional lm , especially when taking advantage of both multiple directions @xmath37 per block and some number @xmath47 of previous update directions .",
    "we next switch from sampling in fock space to sampling in real space , with table [ tab : c2 ] giving results for the ground state of c@xmath65 as modeled by a msj ansatz containing 1,100 csfs and 30 spline - based jastrow variables . to construct our csf expansion",
    ", we began with a gamess optimization of an ( 8,8 ) complete active space self - consistent field ( casscf ) ansatz in the cc - pvtz basis @xcite .",
    "the 1,100 largest - coefficient csfs were then selected from a single - reference configuration interaction calculation including up to quadruples ( cisdtq ) performed in the optimized casscf orbital basis .",
    "as before , we see that increasing the number of blocks eventually results in a significant deviation from the traditional lm energy , which is then reduced by increasing the number of old updates used and the number of directions retained from each block . again , while larger , the number of iterations required to converge the blm was similar to that for the traditional lm .",
    "0.49     0.49       having tested our method in settings where it can be easily checked against the traditional lm , we now turn our attention to the metal - insulator transition in a 16-atom hydrogen ring , where we will use the blm in conjunction with our excited state targeting method @xcite to systematically converge the post - transition optical gap via a series of increasingly large msj expansions .",
    "closely related hydrogen chains have been the subject of much attention @xcite due to the mott - like behavior of the metal - insulator transition that occurs as one enlarges the interatomic distance @xmath71 .",
    "as @xmath71 surpasses a certain critical distance @xmath72 , a large number of natural orbitals become degenerate as the electrons transition out of the weakly correlated metallic state and into the strongly correlated and more localized mott - insulator state .    using jagp approximations for the ground state of the 1d chain , sorrela and coworkers @xcite located @xmath72 by evaluating the complex polarization function @xcite @xmath73 where @xmath74 is the component of @xmath75 parallel to the chain axis .",
    "the modulus of @xmath76 can be thought of as a measurement of insulating behavior : @xmath77 as electrons localize about the nuclei , as occurs in the insulating phase , while @xmath78 as the electrons become fully delocalized , as occurs in the metallic phase .",
    "as we are studying a hydrogen ring instead of a periodic chain , we find it appropriate to instead define the complex polarization function as @xmath79 where @xmath80 is the angle around the ring for the @xmath52th electron s position . as for the chain ,",
    "fully localized versus delocalized behavior in the ring will lead to the @xmath77 and @xmath78 limits , respectively .",
    "in addition to probing the locality of its physics , theoretical methods can also offer predictions about an insulator s optical gap .",
    "although this gap was not accessible in the ground - state work of sorella , the blm can directly target an excited state by minimizing the function @xmath81 , which , when the energy shift @xmath82 is placed inside the gap , will have the first excited state as its global minimum @xcite . as this excited state approximates the state at the bottom of the infinite ring s conduction band",
    ", this approach represents a direct , many - body , non - perturbative , and systematically improvable route to estimating the optical gap of a solid . in this study",
    ", we will explore a simple prototype of this approach by converging the gap for the h@xmath70 ring by systematically increasing the number of csfs included in a msj expansion .",
    "although linear combinations of csfs are not natural fits for the strongly correlated physics of a mott transition and will thus require a large number of csfs be employed , they do offer straightforward systematic improvability and anyways allows us to demonstrate that the blm can handle the correspondingly large number of variational parameters .    to construct our msj expansion ,",
    "we begin by using gamess to optimize a ( 6,6 ) state - average casscf ansatz in the cc - pvdz basis @xcite .",
    "we then perform a single - reference cisdtq for each state , after which we truncate this expansion at different coefficient thresholds to produce a series of increasingly large csf expansions . by combining these with qmcpack s standard spline - based , cusp - inducing @xmath83-@xmath83 and @xmath83-@xmath51 two - body jastrow factors",
    ", we produce two sets of msj expansions , on each for the ground and excited state . finally , choosing the value of @xmath82 that is appropriate for each state by adjusting it to find the overall minimum of the target function @xmath84 @xcite , we optimize both the csf coefficients and jastrow variables simultaneously using the blm .",
    "the number of variational parameters in the excited state ansatz . ]    figure [ fig : z_and_gap ] shows the norm of the complex polarization function as well as the optical gap estimate ( defined as the difference between excited and ground state energies ) as functions of interatomic distance @xmath71 for a coefficient truncation threshold of 0.01 . as expected , both @xmath85 and the gap are zero for small @xmath71 , where previous studies have found hydrogen chains to be metallic . as @xmath71 increases , we see an abrupt change in @xmath85 that suggests that by @xmath86 , the ring has transitioned into an insulating state .",
    "being a finite system , the energy gap does not open discontinuously , and we see instead a rapid rise in the gap until it reaches a plateau beyond @xmath86 , thus agreeing with @xmath85 as to the location of the transition .    to ensure we have accurately converged the size of the gap in the insulating plateau region , we have performed our analysis of systematically increasing csf expansion sizes at @xmath87 , where we transition from @xmath69 ( the traditional lm ) to @xmath88 when the number of variables surpasses 5,000 . figure [ fig : energy_convergence ] shows the convergence behavior for the optimization of the largest msj expansions for both the ground and excited states , which involved 21,401 and 25,297 variational parameters , respectively .",
    "note that , as is typical for the traditional lm , the blm converges in a handful of iterations .",
    "it is also important to point out that the total computational cost for evaluating all of the data points in figure [ fig : energy_convergence ] amounted to 8,000 core - hours using the 2.3 ghz intel xeon 12-core haswell processors of berkeley s savio computing cluster .",
    "although this cost is not trivial , it is modest on the scale of modern parallel computation , giving ample room for this approach to be scaled up both to larger systems and larger variational parameter sets .",
    "finally , in figure [ fig : gap_convergence ] , we show the convergence of the energy gap as the variational flexibility of the ansatz is increased , seeing clearly that , to within our statistical uncertainty , the gap has converged with respect to the addition of further csfs into the wave function .",
    "thus , by combining the direct optimization of ansatzes for the ground and conduction edge states with the ability to optimize the large number of parameters inherent to a systematic expansion of ansatz flexibility , we provide an example of how the optical gap of a mott insulator may be converged with respect to the effects of strong , many - body correlations .",
    "we have presented the blocked linear method , a wave function optimization method for variational monte carlo that addresses a crucial memory bottleneck in the highly successful traditional linear method . by dividing ansatz variables into blocks , finding important update directions in each block , and then combining these directions to find an overall update for the current wave function , our method minimizes either the energy or a function suitable for targeting excited states while avoiding both the construction of overly large matrices and any requirement that such matrices be well conditioned . in small molecule tests that employed multiple ansatz types and involved both real space and hilbert space sampling , we showed that the method reproduces the results of the traditional linear method to a very good approximation .    in a demonstration of the method s ability to optimize large variable sets",
    ", we showed that the optical gap of a mott - insulating hydrogen ring could be systematically converged with respect to increasing flexibility in the ansatzes for the ground and conduction band edge states .",
    "although there are many important concerns for real solids that did not appear in this example , such as obtaining molecular orbitals from a density functional starting guess , addressing finite size effects through twist averaging , and ensuring the simulation cell is sufficient to capture excitonic effects , these issues do not present fundamental barriers and indeed have been addressed in other contexts .",
    "we are therefore excited to explore the new opportunities that the blocked linear method creates in real solids and larger molecules , as well as further refinements in methodology to bring even larger sets of variational parameters within the reach of variational monte carlo .",
    "this work was supported by the u.s .",
    "department of energy , office of science , basic energy sciences , materials sciences and engineering division , as part of the computational materials sciences program .",
    "calculations were performed using the berkeley research computing savio cluster .",
    "[ sec : acknowledgments ]"
  ],
  "abstract_text": [
    "<S> we present a modification to variational monte carlo s linear method optimization scheme that addresses a critical memory bottleneck while maintaining compatibility with both the traditional ground state variational principle and our recently - introduced variational principle for excited states . for wave function </S>",
    "<S> ansatzes with tens of thousands of variables , our modification reduces the required memory per parallel process from tens of gigabytes to hundreds of megabytes , making the methodology a much better fit for modern supercomputer architectures in which data communication and per - process memory consumption are primary concerns . </S>",
    "<S> we verify the efficacy of the new optimization scheme in small molecule tests involving both the hilbert space jastrow antisymmetric geminal power ansatz and real space multi - slater jastrow expansions . </S>",
    "<S> satisfied with its performance , we have added the optimizer to the qmcpack software package , with which we demonstrate on a hydrogen ring a prototype approach for making systematically convergent , non - perturbative predictions of mott - insulators optical band gaps . </S>"
  ]
}