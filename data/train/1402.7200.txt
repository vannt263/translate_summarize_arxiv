{
  "article_text": [
    "semantic web ( web 3.0 ) is the proliferation of unstructured documents of the web to a `` web of data '' [ 1 ] . in traditional web architecture",
    "there is less emphasis on meta data of the web document during the data collection phase of the search engine and the concentration is more on classic approaches like information retrieval and natural language processing .",
    "it is difficult to know the context or the role played by the web document designed for such approaches [ 2][3][4 ] .",
    "this is overcome by semantic web where enhanced version of meta data are embedded in the web pages as rdf [ 5 ] and ontology [ 6 ] .",
    "ontology defines the concepts and the relations between these concepts .",
    "rdf ( resource description framework ) describes the web document in the form of triplets .",
    "every rdf triplet is a composition of _ subject _ , _ predicate _ and _ object_. _ subject _ is an entity to be described , _ object _ is an entity which describes the subject and _ predicate _ is a relationship between _ subject _ and _ object _ ; essentially every _ predicate _ describes the different context of the web page playing multiple roles .",
    "both ontologies and rdf are embedded in web pages forming the semantic annotation of a web page .",
    "the existing search engines interpret the keywords of a user query in isolation without considering wholly , the context of the search query .",
    "because of this , most of the results retrieved is irrelevant to the user query .",
    "this hits the performance and accuracy of search engines .",
    "the main purpose of providing multiple keywords is to make search based on a particular context .",
    "it is to say that nothing exists without context or relation . as an example , consider a scenario where a user has submitted the keywords `` ashoka+bangalore+hotel '' with the intention to search for hotel ashoka in bangalore .",
    "traditional web search engines return all the web pages containing the keywords `` ashoka , bangalore and hotel '' without considering the context of the user query .",
    "most of the web pages are irrelevant to the user query ; where some pages may provide information on `` ashoka pillar in bangalore '' , some web pages may provide information on different hotels because of the keyword hotel , and some pages may provide information about bangalore city because of the keyword bangalore.      semantic look processes the semantic annotation embedded in web pages to perform the relevance analysis on the user query to retrieve the related urls .",
    "it constructs the ontology graphs which are eqvivalent to the concept - relation graph of ontolook [ 7 ] .",
    "semantic look is optimized compared to ontolook , where heavy weighted arcs are retained in every sub graph and only half of the number of least weighted arcs are pruned which mitigates the number of sub graphs to be processed .",
    "this section describes the rest of the paper in brief .",
    "section 2 describes a few earlier contributions to the implementation of semantic web based search engines .",
    "section 3 defines the problem considered .",
    "section 4 explains the architecture of semantic look . in section 5 the mathematical model for semantic",
    "look is given by describing the notations used and the equations that result in a more accurate result set being displayed .",
    "section 6 describes the algorithms required in the components of the system architecture .",
    "section 7 gives the experimental results mentioning the data sets considered and a graphical representation of performance evaluation between ontolook and semantic look .",
    "the paper concludes by mentioning the enhancement that can be incorporated in semantic look and the list of references considered by the authors .",
    "traditional search engines return keyword - isolated pages because of which many unrelated pages or web links are returned by them in response to the user s query .",
    "semantic search engines can be categorized into different types of which context based search engine is one .",
    "this is the largest group and the aim here is to add semantic operations for better search results .",
    "_ yufei li et .",
    "_ [ 7 ] have proposed a prototype called ontolook for performing relation based search to derive the context of user query .",
    "concept - relation graphs ( crgs ) are created with vertices representing concepts and edges representing the number of relations between these concepts .",
    "an algorithm generates sub graphs by pruning edges of the crg irrespective of whether they are heavy weighted or less heavy weighted edges and this results in large number of sub graphs to be processed .",
    "[ 8 ] have proposed the theory based on `` efficient crawling through url ordering '' , in order to obtain more `` important '' pages first .",
    "obtaining important pages rapidly can be very useful when a crawler can not visit the entire web in a reasonable amount of time .",
    "they define several important metrics , ordering schemes , and performance evaluation measures for this problem .",
    "they experimentally evaluate the ordering schemes on the stanford university web to prove that a crawler with a good ordering scheme can obtain important pages significantly faster than one without a good ordering scheme .",
    "[ 9 ] have proposed the theory based on `` search on the semantic web '' .",
    "they propose this theory based on the fact that , in order to help human users and software agents find relevant knowledge on the semantic web , swoogle , a search engine , discovers , indexes and analyzes the ontologies and facts that are encoded in semantic web documents .",
    "_ natalya f noy et .",
    "[ 10 ] have proposed the theory on creating `` semantic web contents '' . as researchers continue to create new languages in the hope of developing a semantic web , they still lack consensus on a standard .",
    "they describe how protege-2000 - a tool for ontology development and knowledge acquisition - can be adapted for editing models in different semantic web languages .",
    "semantic web is necessary to express information in a precise , machine interpretable form , so software agents processing the same set of data share an understanding of what the terms describing the data mean . [ 11 ] study the use of semantic web services in order to overcome this challenge .",
    "the use of ontologies and explicit semantics enable performing logical reasoning to infer sufficient knowledge on the classification of processes that machines offer , and on how to execute and compose those processes to carry out manufacturing orchestration autonomously . _",
    "yi jin _ [ 12 ] present an architecture of the semantic search engine and our work shows how the fundamental elements of the semantic search engine can be used in the fundamental task of information retrieval",
    ". an improved version of the _ tf - idf _",
    "( term frequency -inverse document frequency ) algorithm is proposed to guarantee the retrieval of information resources in a more efficient by looking for items in which the the keywords that are searched for are more common than usual .",
    "[ 13 ] have presented an integrated enterprise - knowledge management architecture for implementing an ontology based knowledge management system ( okms ) and have made a study on two critical issues related to working with ontologies in real - world enterprise applications .",
    "_ wang young - gui et .",
    "[ 14 ] have done analysis on application of semantic web to web mining and to build a semantic based web mining model under the framework of the agent .",
    "the authors in [ 15 ] discuss clustering as a method to overcome the problem of searching through the list a search engine displays .",
    "the list that is displayed is extremely inconvenient to the users since it expects them to look into each page sequentially in an exhaustive manner which could result in relevant information being overlooked .",
    "_ mohammad farhan husain et .",
    "al . , _ [ 16 ] discuss how current frameworks do not scale for storing large rdf graphs and describe a framework that is built using hadoop by exploiting the cloud computing paradigm .",
    "given a set of keywords for a search , the main goal is to find the set of web pages related to the user search context by extracting the semantics behind the user query , where the result set contains most relevant web pages with unnecessary pages filtered from it .",
    "it is assumed that every web page consists of embedded rdf ( e - rdf ) and embedded ontology ( e - ontology ) forming the semantic annotation for a web page .",
    "the web pages with e - rdf and e - ontology form the semantic world wide web which is used by the crawler for crawling the e - rdf / e - ontology in the web pages .",
    "semantic look , a variant of ontolook , optimizes this search logic by retaining the high ranked edges in every sub graph , as they are relevant to the user query , and pruning only the least weighted arcs . as an example , if the number of edges in the crg is 7 of which there are 4 less weighted arcs , ontolook produces @xmath0 @xmath1 , 128 sub graphs .",
    "semantic look produces only 6 sub graphs , since it prunes half the number of least weighted arcs @xmath1 , @xmath2 .",
    "the context driven search engine includes semantic crawler , semantic parser , semantic look and ontobase as components for drawing the context of user search , as shown in figure 1 .",
    "the context is drawn for a user query by extracting the relations among the keywords submitted by the user .",
    "the relations are recorded in rdf adhering to a particular ontology , like the travel ontology , and is embedded in every web page as semantic meta data .",
    "semantic web uses these meta data as information for searching the web pages .",
    "the semantic crawler collects the e - rdf / e - ontology present in the web pages and invokes the corresponding parsers depending on the document type .",
    "both rdf and ontology are serialized as xml and embedded in a web page forming semantic meta data for a web page .",
    "the crawler performs the collection of web page contents and maps it to a web page database .",
    "this component of the search engine is responsible for parsing the incoming semantic annotation sent by the crawler .",
    "rdf parser parses the e - rdf documents to generate rdf - triplets and parses the e - ontology to generate ontology triplets .",
    "the generated triplets are mapped to ontobase which is a knowledge base containing semantic information .",
    "the core component of the search engine is the semantic look .",
    "this utilizes the semantic information to develop all possible contexts for the user query .",
    "the context can be developed by extracting the relations between the keywords which are obtained by the corresponding ontology and rdf triplets .",
    "the rdf triplets generated for the user query is used to fetch url set .",
    "the semantic look    * captures keywords and its corresponding concepts to form an ontology graph where vertices represent concepts and edges represent relations between these concepts .",
    "integers on the edges represent the number of relations between the concept pairs . *",
    "forms the less ranked arcs set and decide on the number of arcs to cut , by considering the average number of relations between the arcs .",
    "* cuts only the less ranked arcs to form the ontology sub graph that will optimize the search result * processes the ontology subgraph to produce all possible ontology triplets from ontobase * uses the ontology triplets to form all possible rdf triplets for the user query * submits the rdf triplets to ontobase to fetch url set and sort according to the ranks assigned    the sequence of execution is as shown in figure 2 .",
    "ontobase is a knowledge base containing semantic annotation of web pages which includes both ontology and rdf triplets .",
    "semantic look uses this semantic annotation to obtain all possible rdf triplets defining the context of the user query .",
    "this section describes the mathematical model of semantic look using mathematical concepts and language .",
    "the model helps in explaining the system and to study the effects of different components , to analyse and predict its behaviour .",
    "k & set of keywords submitted + & by the user . + c & set of concepts mapped for + & the keywords given by the + & user + @xmath3 & threshold : minimum + & support count for the occu- + & rences of relations in a web + & page + web & set of urls of web pages + & accessed according to + & web page index + rdf_t & set of rdf triplets + & accessed according to web + & page index + onto_t & set of ontology triplets + & indexed by webpage index + r & set of relation vectors + & between the corresponding + & concept pairs given by the + & user + og & 2-d matrix representing + & concept - relation graph + n & total number of arcs in + & ontology graph + nl & total number of less ranked + & arcs where nl@xmath4n + p(r , w ) & probability of occurrence + & of relation r , r(w ) in a + & web page w. wi is referred + & to as _ predicate frequency _",
    "+ kw & set of keyword vectors + & accessed according to web + & page index + cw & set of concepts vectors + & accessed according to web + & page index + r & set of relations vector + & between the concept pairs + rw & set of relations vector +    table 1 mentions the notations used by the authors and the relevant meanings of the notations used .      * webpage keywords * : it is the set of keywords vectors accessed according to web page index .",
    "it is given by @xmath5=\\{@xmath6 , @xmath7 ... @xmath8}. any @xmath9 vector is defined as @xmath10 where @xmath11 is the @xmath9 web page keyword and @xmath12 is the @xmath13 keyword in @xmath11 . + * web page concepts * : it is the set of concepts vectors accessed according to web page index .",
    "it is given by @xmath14=\\{@xmath15 , @xmath16 ... @xmath17 } .",
    "any @xmath9 vector is defined as @xmath18 where @xmath19 is the @xmath9 vector of web page concepts mapped to the @xmath9 keyword vector , @xmath1 , @xmath11 of web page keywords and @xmath20 is the @xmath13 concept in @xmath19 . +",
    "* web page predicates * : it is the set of relation vectors specifying the relations between the concept pairs in @xmath14 and accessed according to webpage index .",
    "it is given by @xmath21 @xmath22\\{@xmath23 , @xmath24, ... ,@xmath25}. any @xmath9 vector is defined as @xmath26    where @xmath27 is the @xmath9vector of web page predicate with the domain and range concepts interchanged .",
    "+ * ontology triplets of web page * : the ontology triplet consists of subject concept called domain and object concept called range with predicate / relationship specyfying the relation between subject and object concepts .",
    "the ontology triplets is a set on ontology triplets vectors defined as @xmath28=\\{@xmath29 , @xmath30, ... ,@xmath31}. any @xmath9 vector is defined as @xmath32 where @xmath33,@xmath34 are the domain and range concepts and @xmath35 is the @xmath36 relation in the @xmath9 web page specifying the relation between @xmath33 and @xmath34 .",
    "similarly @xmath37 is a relation between @xmath33 and @xmath34 with the domain and range concepts interchanged . + * rdf triplets of web page * : the rdf triplet consists of subject and object with predicate / relationship specifying the relation between corresponding subject and object concepts .",
    "the rdf triplets is a set on rdf triplets vectors defined as @xmath38=\\{@xmath39 , @xmath40, ... ,@xmath41}. any @xmath9 vector is defined as @xmath42 where @xmath43 , @xmath44 are the domain and range concepts and @xmath35 is the @xmath36 relation in the @xmath9 web page specifying the relation between @xmath43 and @xmath44 . similarly @xmath37 is a relation between @xmath43 and @xmath44 with the domain and range concepts interchanged . :",
    "the concepts received from the user are paired to form ontology graph , where the vertices represent the concepts and the edges represent the number of relationships existing between the concept pairs .",
    "the ontology graph is represented as 2-d matrix where the value in @xmath9 row and @xmath36 column is defined as : @xmath45 = \\left \\ { \\begin{array } { l l l } \\infty,\\   if \\",
    "i \\ne j \\   and \\mid r_{ij}\\mid = 0\\\\ 0 < \\mid r_{ij } \\mid   < \\infty , \\   if \\",
    "i \\ne j \\   \\\\ and \\quad\\mid r_{ij } \\mid > 0 \\\\ 0,\\   if   \\",
    "i = j   \\end{array } \\right \\}\\ ] ] where @xmath46 @xmath47 @xmath48 is a vector representing all the possible relations between the concept pairs @xmath49 and @xmath50 and is defined as : @xmath51",
    "semantic look retains the high weighted arcs in the graph and prunes only the less weighted arcs to produce sub graphs from ontology graph to be processed .",
    "the results are , therefore , relevant to the user query .",
    "the rdf triplets generated from the result of sub graph processing is submitted to web page database to fetch url set .",
    "+ * theorem 1:*``the search engine time is reduced by pruning the less ranked arcs and the results are more relevant to user query '' .",
    "let @xmath52 find _ _",
    "l__ra which is the arc with the less weight .",
    "min(og ) returns minimum edge from ontology graph . @xmath53 \\}\\ ] ] where is a set of less ranked arcs and therefore @xmath54 where @xmath55 indicates number of such less ranked arcs and @xmath56 where _ nc _ indicates the number of less ranked arcs to be cut in semantic look .",
    "the average number of arcs are pruned from the ontology graph . since @xmath57 and the total number of sub graphs which are candidates for processing are @xmath58 and actual number of sub graphs processed are @xmath59 .",
    "since high ranked arcs are retained in every sub graph , the result is more relevant to the user query and the search time is reduced by pruning only the less ranked arcs which produces @xmath60 sub graphs which is less than @xmath61 sub graphs produced by not only pruning the less ranked arcs but also high ranked arcs from the ontology graph .",
    "the proposed search engine called semantic look which is a variant of ontolook [ 1 ] optimizes the search engine time by pruning the less ranked arcs from the ontology graph and retaining the high ranked arcs in every sub graph , which mitigates the number of sub graphs to be processed by the search engine .",
    "the _ semantic crawler _ collects the semantic annotations embedded in every web page which includes embedded rdf and its corresponding ontology ( e - rdf / e - ontology ) .",
    "the collected semantics and web page contents are stored in a database which is used by semantic look to perform the search for the user query .",
    "the _ semantic parser _ encapsulates the logic of the ontology and rdf triplets to the database .",
    "* output : * web pages , e - rdf and e - ontology + * process : * + _ _ w__eb = semantic world wide web + * for * each webpage _ w _ of web + * do * + = search@xmath4link@xmath62with type= +  application / rdf+xml ;  + * for each * _ l _ @xmath47 li +   + = new semantica parser ( ) ; + = href of @xmath4link@xmath62 + = url of _ w _",
    "+ = parse the webpage whose + url is set in href of + @xmath4link@xmath62 to fetch the root element . +",
    "* if*__(__roottag = @xmath4ontology@xmath62 ) +   + @xmath63 _ _ o__ntologyparser(href , url ) ; +   + @xmath63 _ _ r__dfparser(href , url ) ; +   + store the contents of w in database . + * done * +     url of web page(wurl ) + * output : * ontology triplets mapped to + the database + * process : * + * step 1 : * + _ i _ @xmath64 0 ; + * for each * _ _ o__bjectproperty as op + _ _",
    "a__nd @xmath65 @xmath66 objectproperty.length * do * + * if * ( op.hasattribute(``rdf:id '' ) ) * then * + = _ _ s__p.getattribute(``rdf : id '' ) ; + * for each * _ _ o__p.childnodes as @xmath67 * do * + ( ch.nodename = `` domain '' ) + = _ _ c__h.getattribute(``rdfs : resource '' ) ; +   + = _ _ c__h.getattribute(``rdfs : resource '' ) ; +   + * done * + * end if * + create + @xmath68 = ( domain , relation , range ) ; + @xmath68 = @xmath69 @xmath70 + @xmath68 ; + * done * + @xmath28 = @xmath28 @xmath70 @xmath68 ; + repeat the above process for _ _ d__ata + _ _ t__ypeproperty and _ _ f__unctionalproperty + insert ontology triplet to database",
    ". +     url of web page ( wurl ) + * output : * rdf_triplets of wurl + @xmath1 , rdf_twurl + * process : * + _ i _",
    "= _ 0 _ ; + rdf : description as _ d _ and + + + i!=rdf : description.length +   + subject = d.getattribute(``rdf:about '' ) ; + d.childnodes as _ c _ +   + relation = c.nodename ; + object = c.getattribute(``rdf:resource '' ) ; +   +   + create rdf_t - wurl u rdf_t_wurli +   + obtain corresponding onto_t_wurl + insert onto_t_wurl and rdf_t_wurl + to the database .",
    "+    the _ semantic crawler _ crawls the web documents from the _ semantic world wide web _",
    "( semantic - www ) and invokes the _ ontology parser _ if the collected document is the ontology document or invokes the rdf - parser if the collected document is the rdf document .",
    "the crawler also stores the web pages in the database for future use as explained in the algorithm given in table 2 .",
    "the ontology parser creates the ontology triplets by fetching the domain and range concepts of _ objectproperty , datatypeproperty _ or _ functionalproperty _ and maps the corresponding triplets to the database as given in the algorithm of table 3 .",
    "the rdf parser looks for the _ @xmath4rdf : descrip tion_@xmath62 element for forming the rdf - triplet and maps it to the corresponding ontology triplets before it is added to the database .",
    "the _ subjects / objects _ are the instances of some ontology concepts defined in the ontology document which are described under the element called _",
    "@xmath4instances@xmath62 _ in rdf - document .",
    "the rdf - parser uses this information to map rdf - triplets to the ontology triplets as explained in the algorithm of table 4 .",
    "_ semantic look _ dynamically constructs the ontology graph from the concepts and corresponding keywords given by the user .",
    "the search engine cuts the less weighted arcs from the graph retaining high ranked arcs .",
    "there is no set criterion for deciding to cut such number of arcs but in this search engine average number of arcs are pruned from the ontology graph to form the sub graphs . since high ranked arcs are retained in every sub graph , the results obtained are relevant to the user query .",
    "the sub graphs are processed to from all possible rdf - triplets which are submitted to the database to retrieve url set . since there is a probability that rdf - triplets are repeated in multiple web pages the final url set is obtained by the intersection of url sets of all rdf - triplets matching the user query as explained in the algorithm of table 5 .",
    "+     concepts set @xmath1 , c + * data store : * semantic world wide web + @xmath1 , web + * output : * url set + * process : * + @xmath71 + lra = @xmath72 + * let * r = r12 , r21 , r23 , r32 , ",
    ", rcncn-1 + i , j @xmath4 cn and i @xmath73 j * do * + @xmath74 = \\mid r_{ij } \\mid$ ] + @xmath75 < lra)$ ] * then * + lra = og[i , j ] +   +   + @xmath76 + i , j @xmath4 cn and i!=j * do * + @xmath75= lra)$ ] * then * + @xmath77 + @xmath78 ; + i = 0 ; + pstack ; + * while * ( @xmath79 @xmath4 @xmath55 ) * do * + k = i + @xmath80push ( ) + ( ! pstack.empty ( ) ) * do * + ( pstack.length = nc ) + osg [ ] ; + @xmath81 $ ] as @xmath82 * do * + copy og [ ] to osg [ ] + [ l , m ] = osg[m , l ] = @xmath83 + generate_rdf_t(osg ) +   + pstack@xmath80pop ( ) + end if + * else * + * do * + ( + + k@xmath73nl ) * then * + @xmath80push ( ) +   + k = @xmath80position(pstack.top ) + pstack@xmath80pop ( ) + * done * + * done * + * done * +     +     /*generate rdf triplets to fetch urls*/ + * procedure * _ generate_rdf_t(osg ) _ + * do * + * url * = @xmath84 + * for * ( i,@xmath85 ) + * do * + @xmath86 if + ( 1 @xmath87 w @xmath88 and + 1 @xmath87 d , r @xmath89 , and + 1 @xmath87 k @xmath90 + and @xmath91 , @xmath92 ) + * for * @xmath93 +   + = @xmath94 + @xmath95 + = url @xmath96 urli +   + * done * + rsort(url ) ; + * done * +",
    "the dataset consists of 40 web pages with embedded 370 rdf and 85 ontology triplets .",
    "the web pages are mapped to the web page database , where rdf and ontology triplets are mapped to ontobase .",
    "the rdf documents , ontology documents and web pages form the semantic world wide web .",
    "the xml serialized ontology and rdf triplets are mapped to the tables in ontobase which has complete information about the triplets such as subject , subject s concept , object , object s concept , predicates and predicates type .",
    "the concept and predicates type are obtained from the ontology document .",
    "semantic look is simulated on the context of the tourism portals .",
    "the search engine is generic but the e - ontology and e - rdf is domain specific .",
    "the semantic crawler crawls the e - ontology and e - rdf without any knowledge on the context where these documents are playing a role .",
    "the search context for a user query is established by extracting the relations among the supplied keyword .",
    "this is performed by _",
    "semantic look_. the entire application is developed on _ lampp _ environment with_php _ as underlying language for business logic . as shown in _ fig 3 _ the semantic look and ontolook is compared with respect to the number of relations to be processed for different sets of keywords and concepts provided by the user.the difference in the number of sub graphs processed by ontolook and semantic look is given in table 7 .    [",
    "cols=\"^,^,^,^,^,^ \" , ]",
    "search engines in the current web architecture will not consider the semantics role played by web pages in different context .",
    "the new generation of web @xmath1 , semantic web ( web 3.0 ) considers this context information by recording the semantic information in the form of ontologies and rdfs .",
    "a proof of concept called semantic look is proposed to produce relevant web pages by filtering unnecessary web documents from the result set .",
    "semantic look extracts the semantics of the user query to know the context of user search .",
    "this work is based on the prototype called ontolook which performs the exhaustive search of all the sub graphs of ontology graph to produce url set .",
    "semantic look is an optimized search engine compared to ontolook which prunes less weighted edges from the ontolook to produce less number of sub graphs for processing . even though the number of sub graphs processed by semantic look is less",
    "as compared with ontolook the number of rdf triplets produced will be huge and therefore in future work semantic look should be designed to run on the clusters of nodes using map - reduce framework .",
    "further optimization is achieved by running the crawler and pruning logic on the cluster . since",
    "semantic information is embedded in the web page by the author and it is assumed to be true there is a chance of misleading the search engine by embedding false semantic information .",
    "li ding , finin , joshi , pan , scott cost , sachs , doshi , reddivari , and y. peng .",
    "swoogle , a search and metadata engine for the semantic web , _ proceedings , @xmath99 acm conference on information and knowledge management ( cikm 2004 ) _ , nov .",
    "2004 .",
    "mohammad farhan husain , james mcglothlin , mohammad mehedy masud , latifur r. khan and bhavani thuraisingham .",
    "heuristics - based query processing for large rdf graphs using cloud computing , _ ieee transactions on knowledge and data engineering _ , 23(9 ) , september 2011 .",
    "is currently an associate professor in the department of computer science , dr .",
    "ambedkar institute of technology , bangalore .",
    "she obtained her bachelor of engineering from sjce , mysore .",
    "she received her m.tech degree in computer science and engi- +   +        received his master s degree from the department computer science and engineering , university visvesvaraya college of engineering , bangalore university , bangalore .",
    "his research interest is in the area of web technology , se- +        is currently the chairman , department of computer science and engineering , university visvesvaraya college of engineering , bangalore university , bangalore .",
    "she obtained her bachelor of engineering and masters degree in computer science and engineering from   +   +    university visvesvaraya college of engineering .",
    "she was awarded ph.d in computer science from dr .",
    "mgr university , chennai .",
    "her research interests are in the field of wireless sensor networks and data mining .",
    "+   +      is currently the principal , university visvesvaraya college of engineering , bangalore university , bangalore .",
    "he obtained his bachelor of engineering from university visvesvaraya college of engineering .",
    "he received his masters degree in computer science and   +   +    automation from indian institute of science bangalore .",
    "he was awarded ph.d in economics from bangalore university and ph.d in computer science from indian institute of technology , madras .",
    "he has a distinguished academic career and has degrees in electronics , economics , law , business finance , public relations , communications , industrial relations , computer science and journalism .",
    "he has authored 39 books on computer science and economics , which include petrodollar and the world economy , c aptitude , mastering c , microprocessor programming , mastering c++ and digital circuits and systems @xmath100 . during his three decades of service at uvce",
    "he has over 350 research papers to his credit .",
    "his research interests include computer networks , wireless sensor networks , parallel and distributed systems , digital signal processing and data mining .",
    "+   +   +      is currently honorary professor , indian institute of science , bangalore , india .",
    "he was a vice chancellor , defense institute of advanced technology , pune , india and was a professor since 1986 with the department of computer science and automation , indian   +   +    institute of science , bangalore . during the past 35 years of his service at the institute he has over 500 research publications in refereed international journals and conference proceedings .",
    "he is a fellow of all the four leading science and engineering academies in india ; fellow of the ieee and the academy of science for the developing world .",
    "he has received twenty national and international awards ; notable among them is the ieee technical achievement award for his significant contributions to high performance computing and soft computing .",
    "his areas of research interest have been parallel and distributed computing , mobile computing , cad for vlsi circuits , soft computing and computational neuroscience ."
  ],
  "abstract_text": [
    "<S> the world wide web ( www ) is a huge conservatory of web pages . </S>",
    "<S> search engines are key applications that fetch web pages for the user query . in the current generation web architecture , </S>",
    "<S> search engines treat keywords provided by the user as isolated keywords without considering the context of the user query . </S>",
    "<S> this results in a lot of unrelated pages or links being displayed to the user . </S>",
    "<S> semantic web is based on the current web with a revised framework to display a more precise result set as response to a user query . </S>",
    "<S> the current web pages need to be annotated by finding relevant meta data to be added to each of them , so that they become useful to semantic web search engines . </S>",
    "<S> semantic look explores the context of user query by processing the semantic information recorded in the web pages . </S>",
    "<S> it is compared with an existing algorithm called ontolook and it is shown that semantic look is a better optimized search engine by being more than twice as fast as ontolook . +   + * keywords :* ontology , rdf , semantic web . </S>"
  ]
}