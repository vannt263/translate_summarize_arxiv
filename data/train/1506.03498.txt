{
  "article_text": [
    "matrix completion is the task of inferring the missing entries of a matrix given a subset of known entries .",
    "typically , this is possible because the matrix to be completed has ( at least approximately ) low rank @xmath0 .",
    "this problem has witnessed a burst of activity , see e.g. @xcite , motivated by many applications such as collaborative filtering @xcite , quantum tomography @xcite in physics , or the analysis of a covariance matrix @xcite.a commonly studied model for matrix completion assumes the matrix to be exactly low rank , with the known entries chosen uniformly at random and observed without noise .",
    "the most widely considered question in this setting is how many entries need to be revealed such that the matrix can be completed exactly in a computationally efficient way @xcite .",
    "while our present paper assumes the same model , the main questions we investigate are different .",
    "the first question we address in this paper is _ detectability _ , i.e. how many random entries do we need to reveal in order to be able to estimate the rank @xmath0 reliably .",
    "this question is motivated by the more generic problem of detecting structure ( in our case , low rank ) hidden in partially observed data .",
    "it is reasonable to expect the existence of a region where exact completion is hard or even impossible yet the rank estimation is tractable .",
    "a second question we address is what is the minimum achievable root - mean - square error ( rmse ) in estimating the unknown elements of the matrix . in practice , even if exact reconstruction is not possible , having a procedure that provides a very small rmse might be quite sufficient .",
    "in this paper we propose an algorithm called macbeth that gives the best known empirical performance for the two tasks above when the rank @xmath0 is small .",
    "the rank in our algorithm is estimated as the number of negative eigenvalues of an associated bethe hessian matrix @xcite , and the corresponding eigenvectors are used as an initial condition for the local optimization of a cost function commonly considered in matrix completion ( see e.g. @xcite ) .",
    "in particular , in the random matrix setting , we show that macbeth detects the rank of a large @xmath1 matrix from @xmath4 entries , where @xmath3 is a small constant , see fig .",
    "[ fig : transition ] , and @xmath5 as @xmath6 .",
    "the corresponding rmse is evaluated empirically , and in the regime close to @xmath4 , it compares very favorably to existing approaches , in particular to optspace @xcite .",
    "this contribution is organized as follows .",
    "first , in sec . [ sec : def ] we define the problem and present generally our approach in the context of existing works . in sec .",
    "[ sec : algo ] we describe our algorithm and motivate its construction via a spectral relaxation of the hopfield model of neural network .",
    "next , in sec .",
    "[ sec : analysis ] we show how the performance of the proposed spectral method can be analyzed using , in parts , results from spin glass theory and phase transitions , and rigorous results on the spectral density of large random matrices . finally , in sec .",
    "[ sec : numerical ] we present numerical simulations that demonstrate the efficiency of macbeth .",
    "let @xmath7 be a rank-@xmath0 matrix such that @xmath8 where @xmath9 and @xmath10 are two ( unknown ) tall matrices .",
    "we observe only a small fraction of the elements of @xmath7 , chosen uniformly at random .",
    "we call @xmath11 the subset of observed entries , and @xmath12 the ( sparse ) matrix supported on @xmath11 whose nonzero elements are the revealed entries of @xmath13 .",
    "the aim is to reconstruct the rank @xmath0 matrix @xmath14 given @xmath12 . an important parameter which controls",
    "the difficulty of the problem is @xmath15 . in the case of a square matrix @xmath12 , this is the average number of revealed entries per line or column .    in our numerical examples and theoretical justifications",
    "we shall generate the low rank matrix @xmath16 , using tall matrices @xmath17 and @xmath18 with iid gaussian elements , we call this the random matrix setting .",
    "the macbeth algorithm is , however , non - parametric and does not use any prior knowledge about @xmath17 and @xmath18 .",
    "the analysis we perform applies to the limit @xmath19 while @xmath20 and @xmath21 .",
    "the matrix completion problem was popularized in @xcite who proposed nuclear norm minimization as a convex relaxation of the problem .",
    "the algorithmic complexity of the associated semidefinite programming is , however , @xmath22 .",
    "a low complexity procedure to solve the problem was later proposed by @xcite and is based on singular value decomposition ( svd ) .",
    "a considerable step towards theoretical understanding of matrix completion from few entries was made in @xcite who proved that with the use of _ trimming _ the performance of svd - based matrix completion can be improved and a rmse proportional to @xmath23 can be achieved . the algorithm of @xcite is referred to as optspace , and empirically it achieves state - of - the - art rmse in the regime of very few revealed entries .",
    "optspace proceeds in three steps @xcite .",
    "first , one trims the observed matrix @xmath12 by setting to zero all rows ( resp .",
    "columns ) with more revealed entries than twice the average number of revealed entries per row ( resp . per column ) .",
    "second , a singular value decompositions is performed on the matrix and only the first @xmath0 components are kept .",
    "when the rank @xmath0 is unknown it is estimated as the index for which the ratio between two consecutive singular values has a minimum .",
    "third , a local minimization of the discrepancy between the observed entries and a low - rank estimate is performed . the initial condition for this minimization",
    "is given by the first @xmath0 left and right singular vectors from the second step .",
    "in this work we improve upon optspace by replacing the first two steps by a different spectral procedure that detects the rank and provides a better initial condition for the discrepancy minimization .",
    "our method leverages on recent progress made in the task of detecting communities in the stochastic block model @xcite with spectral methods .",
    "both in community detection and matrix completion , traditional spectral methods fail in the very sparse regime due to the existence of spurious large eigenvalues ( or singular values ) corresponding to localized eigenvectors @xcite .",
    "the authors of @xcite showed that using the non - backtracking matrix or the closely related bethe hessian as a basis for the spectral method in community detection provides reliable rank estimation and better inference performance .",
    "the present paper provides an analogous improvement for the matrix completion problem .",
    "in particular , we shall analyze the algorithm using tools from spin glass theory in statistical mechanics , and show that there exists a phase transition between a phase where it is able to detect the rank , and a phase where it is unable to do so .",
    "a standard approach to the completion problem ( see e.g.  @xcite ) is to minimize the cost function @xmath24 ^ 2   \\label{costfunction}\\end{aligned}\\ ] ] over @xmath9 and @xmath10 .",
    "this function is non - convex , and global optimization is hard .",
    "one therefore resorts to a local optimization technique with a careful choice of the initial conditions @xmath25 . in our method , given the matrix @xmath12 , we consider a weighted bipartite undirected graph with adjacency matrix @xmath26 @xmath27 we will refer to the graph thus defined as @xmath28 .",
    "we now define the bethe hessian matrix @xmath29 to be the matrix with elements @xmath30 where @xmath31 is a parameter that we will fix to a well - defined value @xmath32 depending on the data , and @xmath33 stands for the neighbors of @xmath34 in the graph @xmath28 .",
    "the macbeth algorithm that is the main subject of this paper is then , given the matrix @xmath35 , which we assume to be centered :    * algorithm ( macbeth ) *    1 .",
    "numerically solve for the value of @xmath36 such that @xmath37 2 .",
    "build the bethe hessian @xmath38 following eq .",
    "( [ bethehessian_def ] ) .",
    "3 .   compute _ all _ its negative eigenvalues @xmath39 and corresponding eigenvectors @xmath40 .",
    "@xmath41 is our estimate for the rank @xmath0",
    ". set @xmath42 ( resp .",
    "@xmath43 ) to be the first @xmath44 lines ( resp . the last @xmath45 lines ) of the matrix @xmath46 $ ] .",
    "4 .   perform local optimization of the cost function ( [ costfunction ] ) with rank @xmath47 and initial condition @xmath25 .    the function @xmath48 , in the first step",
    ", being an increasing function of @xmath31 , @xmath36 can be found efficiently , e.g. by dichotomy .",
    "alternatively , @xmath49 in step 1 can be tuned in such a way that the number of negative eigenvalues of the bethe hessian is the largest possible . in step 2",
    "we could also use the non - backtracking matrix weighted by @xmath50 , it was shown in @xcite that the spectrum of the bethe hessian and the non - backtracking matrix are closely related . in the next section , we will motivate and analyze this algorithm ( in the setting where @xmath7 was generated from elements - wise random @xmath17 and @xmath18 ) and show that in this case macbeth is able to infer the rank whenever @xmath51 .",
    "[ fig : spectrum ] illustrates the spectral properties of the bethe hessian that justify this algorithm : the spectrum is composed of a few informative negative eigenvalues , well separated from the bulk ( which remains positive ) .",
    "this algorithm is computationally efficient as it is based on the eigenvalue decomposition of a sparse , symmetric matrix .    .",
    "the red dots are the result of the direct diagonalisation of the bethe hessian for a rank @xmath52 and @xmath53 matrix , with @xmath54 revealed entries per row on average .",
    "the black curves are the solutions to the recursion ( [ bprec ] ) computed with belief propagation on a graph of size @xmath55 .",
    "we isolated the 5 smallest eigenvalues , represented as small bars for convenience , and the inset is a zoom around these smallest eigenvalues .",
    "for @xmath31 small enough ( top plots ) , the bethe hessian is positive definite , signaling that the paramagnetic state ( [ paramagnetic_state ] ) is a local minimum of the bethe free energy . as @xmath31 increases",
    ", the spectrum is shifted towards the negative region and has 5 negative eigenvalues at the approximate value of @xmath56 ( to be compared to @xmath57 for this case ) evaluated by our algorithm ( lower left plot ) .",
    "these eigenvalues , corresponding to the retrieval states ( [ retrieval_states ] ) , become positive and eventually merge in the bulk as @xmath31 is further increased ( lower right plot ) , while the bulk of uninformative eigenvalues remains at all values of @xmath31 in the positive region .",
    "[ fig : spectrum ] ]      we shall now motivate the construction of the macbeth algorithm from a graphical model perspective and a spectral relaxation .",
    "given the observed matrix @xmath58 from the previous section , we consider the following graphical model @xmath59 where the @xmath60 and @xmath61 are binary variables , and @xmath31 is a parameter controlling the strength of the interactions .",
    "this model is a ( generalized ) hebbian hopfield model @xcite on a bipartite sparse graph . to study it",
    ", we can use the standard bethe approximation which is widely believed to be exact for such problems on large random graphs @xcite . in this approximation the means @xmath62 and moments @xmath63 of each variable are approximated by the parameters @xmath64 and @xmath65 that minimize the so - called bethe free energy @xmath66 that reads @xmath67 where @xmath68 , and @xmath69 are the degrees of nodes @xmath34 and @xmath70 in the graph @xmath28 .",
    "neural networks models such as eq .",
    "( [ jpd ] ) have been extensively studied over the last decades ( see e.g. @xcite and references therein ) and the phenomenology , that we shall review briefly here , is well known . in particular , for @xmath31 small enough , the global minimum of the bethe free energy corresponds to the so - called _ paramagnetic state _ @xmath71",
    "as we increase @xmath31 , above a certain value @xmath72 , the model enters a _ retrieval _ phase , where the free energy has local minima correlated with the factors @xmath17 and @xmath18 .",
    "there are @xmath0 local minima , called _ retrieval states _",
    "@xmath73 indexed by @xmath74 such that , in the large @xmath75 limit , @xmath76 these retrieval states are therefore well - suited as initial conditions for the local optimization of eq .",
    "( [ costfunction ] ) , and we expect their number to tell us the correct rank .",
    "increasing @xmath31 above a critical value @xmath32 the system eventually enters a spin glass phase , marked by the appearance of many spurious minima",
    ". it would be tempting to continue the bethe approach and to derive the belief propagation equations , but we shall here instead consider a simpler spectral relaxation of the problem , following the same strategy as used in @xcite for graph clustering .",
    "first , we use the fact that the paramagnetic state ( [ paramagnetic_state ] ) is always a stationary point of the bethe free energy , for any value of @xmath31 @xcite . in order to detect the retrieval states ,",
    "we thus study its stability by looking for negative eigenvalues of the hessian of the bethe free energy evaluated at the paramagnetic state ( [ paramagnetic_state ] ) . at this point ,",
    "the elements of the hessian involving one derivative with respect to @xmath65 vanish , while the block involving two such derivatives is a diagonal positive definite matrix @xcite .",
    "the remaining part is the matrix called bethe hessian in @xcite , and eigenvectors corresponding to its negative eigenvalues are thus expected to give an approximation of the retrieval states ( [ retrieval_states ] ) .",
    "the picture exposed in this section is summarized in figure [ fig : spectrum ] .",
    "this motivates the use of the macbeth algorithm .",
    "note that a similar approach was used in @xcite to detect the retrieval states of a hopfield model using the weighted non - backtracking matrix @xcite , which linearizes the belief propagation equations rather than the bethe free energy , resulting in a larger , non - symmetric matrix .",
    "the bethe hessian , while mathematically closely related , is also simpler to handle in practice .",
    "we now show how the performance of macbeth can be analyzed , and the spectral properties of the matrix characterized using both tools from statistical mechanics and rigorous arguments .",
    "we start by investigating the phase transition above which our spectral method will detect the correct rank .",
    "let @xmath77 be random vectors with the same empirical distribution as the lines of @xmath17 and @xmath18 respectively . using the statistical mechanics correspondence between the negative eigenvalues of the bethe hessian and the appearance of phase transitions in model ( [ jpd ] )",
    ", we can compute the values @xmath78 and @xmath32 where instabilities towards , respectively , the retrieval states and the spurious glassy states , arise .",
    "we have repeated the computations of @xcite in the case of model ( [ jpd ] ) , using the cavity method @xcite .",
    "we refer the reader interested in the technical details of the statistical mechanics approach to neural networks to @xcite .",
    "following a standard computation for locating phase transitions in the bethe approximation ( see e.g. @xcite ) , the stability of the paramagnetic state ( [ paramagnetic_state ] ) towards these two phases can be monitored in terms of the two following parameters : @xmath79^\\frac{1}{2s}\\ , , \\\\",
    "\\mu(\\beta ) & = \\underset{s\\rightarrow\\infty}{\\lim } \\ { \\mathbb{e}}\\big [ \\overset{s}{\\underset{p=1}{\\prod}}\\tanh\\big(\\beta|x_p^{1}y_p^{1}|+\\beta \\overset{r}{\\underset{l=2}{\\sum}}x_p^{l}y_p^{l}\\big ) \\tanh\\big(\\beta|x_{p+1}^{1}y_p^{1}|+\\beta\\overset{r}{\\underset{l=2}{\\sum}}x_{p+1}^{l}y_p^{l}\\big ) \\big]^\\frac{1}{2s}\\ , , \\label{mu}\\end{aligned}\\ ] ] where the expectation is over the distribution of the vectors @xmath80 .",
    "the parameter @xmath81 controls the sensitivity of the paramagnetic solution to random noise , while @xmath82 measures its sensitivity to a perturbation in the direction of a retrieval state . @xmath32 and @xmath78 are defined implicitly as @xmath83 and @xmath84 , i.e. the value beyond which the perturbation diverges .",
    "the existence of a retrieval phase is equivalent to the condition @xmath85 , so that there exists a range of values of @xmath31 where the retrieval states exist , but not the spurious ones .",
    "if this condition is met , by setting @xmath86 in our algorithm , we ensure the presence of meaningful negative eigenvalues of the bethe hessian .",
    "we define the critical value of @xmath87 such that @xmath85 if and only if @xmath88 . in general , there is no closed - form formula for this critical value , which is defined implicitly in terms of the functions @xmath89 and @xmath90 .",
    "we thus computed @xmath91 numerically using a population dynamics algorithm  @xcite and the results for @xmath92 are presented on figure [ fig : transition ] .",
    "quite remarkably , with the definition @xmath93 , the critical value @xmath94 does not depend on the ratio @xmath95 , only on the rank @xmath0 .    .",
    "macbeth is able to estimate the correct rank from @xmath96 known entries .",
    "we used a population dynamics algorithm with a population of size @xmath97 to compute the functions @xmath89 and @xmath90 from ( [ lambda],[mu ] ) .",
    "the dotted line is a fit suggesting that @xmath98 .",
    "[ fig : transition ] ]    in the limit of large @xmath99 and @xmath0 it is possible to obtain a simple closed - form formula . in this case",
    "the observed entries of the matrix become jointly gaussian distributed , and uncorrelated , and therefore independent .",
    "expression ( [ lambda ] ) then simplifies to @xmath100\\ , .",
    "\\end{aligned}\\ ] ] we stress that the macbeth algorithm uses an empirical estimator ( [ eq : hat_sg ] ) of this quantity to compute an approximation @xmath101 of @xmath32 purely from the revealed entries .    in the large @xmath102 regime , both @xmath103 decay to @xmath104",
    ", so that we can further approximate @xmath105{\\mathbb{e}}[y^2]\\ , , \\\\ 1 & = \\epsilon \\mu(\\beta_{\\rm r } )   \\underset{r,\\epsilon\\to \\infty}{\\sim } \\epsilon \\beta_{\\rm r}\\sqrt{{\\mathbb{e}}[x^2]{\\mathbb{e}}[y^2 ] } \\ , , \\end{aligned}\\ ] ] so that we reach the simple asymptotic expression , in the large @xmath106 limit , that @xmath107 , or equivalently @xmath108 .",
    "it is interesting to note that this result was obtained as the detectability threshold in completion of rank @xmath109 matrices from @xmath110 entries in the bayes optimal setting in @xcite .",
    "notice , however , that _ exact _ completion in the setting of @xcite is only possible for @xmath111 : clearly detection and exact completion are different phenomena .      in this section ,",
    "we show how the spectral density of the bethe hessian can be computed analytically on tree - like graphs such as those generated by picking uniformly at random the observed entries of the matrix @xmath112 .",
    "the spectral density is defined as @xmath113 where the @xmath114 s are the eigenvalues of the bethe hessian .",
    "using again the cavity method , it can be shown @xcite that the spectral density ( in which potential delta peaks have been removed ) is given by @xmath115 where the @xmath116 are complex variables living on the vertices of the graph @xmath28 , which are given by : @xmath117 where @xmath118 is the set of neighbors of @xmath34 .",
    "the @xmath119 are the ( linearly stable ) solution of the following belief propagation recursion : @xmath120 the ingredients to derive this formula are to turn the computation of the spectral density into a marginalization problem for a graphical model on the graph @xmath28 , and then write the belief propagation equations to solve it .",
    "quite remarkably , it has been shown @xcite that this approach leads to an asymptotically exact ( and _ rigorous _ ) description of the spectral density on erds - rnyi random graphs , which are locally tree - like in the limit where @xmath121 .",
    "we can again solve equation ( [ bprec ] ) numerically using the belief propagation algorithm .",
    "the results are shown on fig .",
    "[ fig : spectrum ] : the bulk of the spectrum is always positive .    we now demonstrate that for any value of @xmath122 , there exists an open set around @xmath123 where the spectral density vanishes .",
    "this justifies independently or choice for the parameter @xmath31 .",
    "the proof follows @xcite and begins by noticing that @xmath124 is a fixed point of the recursion ( [ bprec ] ) for @xmath125 .",
    "since this fixed point is real , the corresponding spectral density is @xmath104 .",
    "now consider a small perturbation @xmath126 of this solution such that @xmath127 .",
    "the linearized version of ( [ bprec ] ) writes @xmath128 .",
    "the linear operator thus defined is a weighted version of the non - backtracking matrix of @xcite .",
    "its spectral radius is given by @xmath129 , where @xmath89 is defined in [ lambda ] .",
    "in particular , for @xmath122 , @xmath130 , so that a straightforward application @xcite of the implicit function theorem allows to show that there exists a neighborhood @xmath131 of @xmath104 such that for any @xmath132 , there exists a real , linearly stable fixed point of ( [ bprec ] ) , yielding a spectral density equal to @xmath104 .",
    "the algorithm was implemented in julia @xcite , using the nlopt optimization package @xcite for the minimization of the discrepancy ( [ costfunction ] ) .",
    "a matlab demo using the implementation of the limited - memory bfgs algorithm of @xcite is also available .",
    "both demos can be downloaded from @xcite .    , for different sizes .",
    "each point is averaged over @xmath133 samples of matrices @xmath112 of size @xmath1 , with the entries of @xmath134 drawn from a gaussian distribution of mean @xmath104 and variance  @xmath135 .",
    "the theoretical transition is computed with a population dynamics algorithm ( see section [ analysis ] ) .",
    "the finite size effects are considerable but consistent with the asymptotic prediction .",
    "[ fig : infer_rank ] ]    figure [ fig : infer_rank ] illustrates the ability of the bethe hessian to infer the rank above the critical value  @xmath94 in the limit of large size @xmath75 ( see section [ analysis ] ) . in figure",
    "[ fig : rmse ] , we demonstrate the suitability of the eigenvectors of the bethe hessian as starting point for the minimization of the cost function ( [ costfunction ] ) .",
    "we compare the final rmse achieved on the reconstructed matrix @xmath112 with @xmath136 other initializations of the optimization , including the largest singular vectors of the trimmed matrix @xmath12 @xcite .",
    "macbeth systematically outperforms all the other choices of initial conditions .",
    "remarkably , the performance achieved by macbeth with the inferred rank is essentially the same as the one achieved with an oracle rank .",
    "by contrast , estimating the correct rank from the ( trimmed ) svd is more challenging .",
    "we note that for the choice of parameters we consider , trimming had a negligible effect . along the same lines ,",
    "optspace @xcite uses a different minimization procedure , but from our tests we could not see any difference in performance due to that .",
    ": comparison between different initializations for the optimization of the cost function ( [ costfunction ] ) .",
    "the top row shows the probability that the achieved rmse is smaller than @xmath137 , while the bottom row shows the probability that the final rmse is smaller than @xmath138 .",
    "the probabilities were estimated as the frequency of success over @xmath133 samples of matrices @xmath112 of size @xmath139 , with the entries of @xmath134 drawn from a gaussian distribution of mean @xmath104 and variance  @xmath135 .",
    "all methods optimize the cost function ( [ costfunction ] ) using a limited - memory bfgs algorithm @xcite part of nlopt @xcite , starting from different initial conditions .",
    "the maximum number of iterations was set to @xmath140 .",
    "the initial conditions compared are macbeth with oracle rank ( macbeth or ) or inferred rank ( macbeth ir ) , svd of the observed matrix @xmath12 after trimming , with oracle rank ( tr - svd or ) , or inferred rank ( tr - svd ir , note that this is equivalent to optspace @xcite in this regime ) , and random initial conditions with oracle rank ( random or ) . for the tr - svd ir method , we inferred the rank from the svd by looking for an index for which the ratio between two consecutive eigenvalues is minimized , as suggested in @xcite .",
    "[ fig : rmse ] ]",
    "in this paper , we have presented macbeth , an algorithm for matrix completion that is efficient for two distinct , complementary , tasks : ( i ) it has the ability to estimate a finite rank @xmath0 reliably from fewer random entries than other existing approaches , and ( ii ) it gives lower root - mean - square reconstruction errors than its competitors .",
    "the algorithm is built around the bethe hessian matrix and leverages both on recent progresses in the construction of efficient spectral methods for clustering of sparse networks @xcite , and on the optspace approach @xcite for matrix completion .",
    "demos in julia and matlab are available for download @xcite .",
    "the method presented here offers a number of possible future directions , including replacing the minimization of the cost function by a message - passing type algorithm , the use of different neural network models , or a more theoretical direction involving the computation of information theoretically optimal transitions for detectability .",
    "the research leading to these results has received funding from the european research council under the european union s @xmath141 framework programme ( fp/2007 - 2013/erc grant agreement 307087-sparcs ) ."
  ],
  "abstract_text": [
    "<S> the completion of low rank matrices from few entries is a task with many practical applications . </S>",
    "<S> we consider here two aspects of this problem : detectability , i.e. the ability to estimate the rank @xmath0 reliably from the fewest possible random entries , and performance in achieving small reconstruction error . we propose a spectral algorithm for these two tasks called macbeth ( for matrix completion with the bethe hessian ) . </S>",
    "<S> the rank is estimated as the number of negative eigenvalues of the bethe hessian matrix , and the corresponding eigenvectors are used as initial condition for the minimization of the discrepancy between the estimated matrix and the revealed entries . </S>",
    "<S> we analyze the performance in a random matrix setting using results from the statistical mechanics of the hopfield neural network , and show in particular that macbeth efficiently detects the rank  @xmath0 of a large @xmath1 matrix from @xmath2 entries , where @xmath3 is a constant depicted in fig .  </S>",
    "<S> [ fig : transition ] . </S>",
    "<S> we also evaluate the corresponding root - mean - square error empirically and show that macbeth compares favorably to other existing approaches . </S>"
  ]
}