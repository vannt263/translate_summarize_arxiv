{
  "article_text": [
    "given a set of measured values of a constant and the associated uncertainties , the gauss - markov theorem states that the unbiased minimum - variance estimator of the measurand is the weighted mean @xcite .",
    "the uncertainty of the mean , which is smaller than the smallest uncertainty , does not depend on data spread .",
    "this is a consequence of the assumption that the variance of the sampling distribution of each datum is exactly know . in practice",
    ", this hypothesis is often false and the inconsistency of the data  quantified , for example , by the @xmath0 or the birge - ratio values  suggests that the uncertainties associated with the data are merely lower bounds to the standard deviations of their sampling distributions . in this case , the gauss - markov theorem is of no help and the choice of an optimal measurand value is long debated issue .",
    "the consequences of the assumption that the associated uncertainties are point estimates of the standard deviations are illustrated by dose @xcite , who considers the estimate of the newtonian constant of gravitation .",
    "decision theory and probability calculus help to deal with the discrepancy between the quoted uncertainties and the data scatter . given the measurement results and the lower bounds of the standard deviations , the first step is to find the probabilities of the possible measurand values . as described by sivia @xcite , who solved the related problem of dealing with outliers ,",
    "probabilities are assigned by application of the product rule and marginalization .",
    "next , given the loss due to a wrong decision , the optimal choice of the measurand value minimizes the expected loss over the assigned probabilities .",
    "since foundations are in the probability theory , this method makes it no longer necessary to exclude the data disagreeing with the majority , as well as to scale the uncertainties to make the data consistent . after reviewing the sivia s analysis ,",
    "the procedure is here applied to estimate the value of the planck constant from a set of inconsistent measurement results .",
    "let us consider a set of @xmath1 measured values @xmath2 of a measurand @xmath3 , which have been independently sampled from gaussian distributions having unknown variance @xmath4 , where @xmath5 is the uncertainty associated with the @xmath2 datum .",
    "the problem is to find optimal estimates of the measurand value and of the confidence intervals .",
    "clearly , we can not rely on the weighted mean , because the actual variances of the sampling distributions are not known . on the other hand",
    ", we can not go back to the arithmetic mean , because it leaves out significant information delivered by the associated uncertainties .",
    "given the data and their associated uncertainty , the solution is to assign probabilities to the @xmath3 values and to use probabilities to minimize any given loss function @xcite .",
    "firstly , we make probability assignments to the possible @xmath6 values , for which only the @xmath5 lower bounds are known . in the absence of any additional information , we assume that the probability distribution of @xmath6 is independent of the measurement unit , that is , @xmath7 , where @xmath8 is the sought distribution of the @xmath9 values @xcite .",
    "this implies @xmath10 where the heaviside function @xmath11 is 1 if @xmath12 and zero if @xmath13 and the @xmath14 subscript has been dropped .",
    "the distribution ( [ prior ] ) is improper , but , provided the final measurand distribution is integrable , this is not a serious problem .",
    "anyhow , we can always set a finite upper bound and delay the calculation of the upper bound limit to the infinity until last .",
    "next , having stated @xmath15 , the sampling distribution of each @xmath16 datum can be marginalized to eliminate the unknown variance .",
    "hence , @xmath17}{2(x - h ) } , \\ ] ] where @xmath18 is a normal distribution of the @xmath16 values having @xmath3 mean and @xmath19 variance and erf is the error function .",
    "eventually , we make pre - data probability assignments to the @xmath3 values . in the absence of any additional information",
    ", we assume that they are independent of the unit - scale origin , which implies a uniform distribution .    by application of the product rule of probability ,",
    "the only post - data probability distribution of the measurand values , logically consistent with the pre - data assignments and sampling distributions , is @xmath20 where the @xmath21 function is given in ( [ sampling ] ) , @xmath22 is a normalization factor , @xmath2 and @xmath5 are the @xmath14-th datum and its uncertainty .",
    "the post - data distribution ( [ measurand ] ) is the central to our analysis . given any loss @xmath23 due to a wrong estimate @xmath24 , the optimal choice of the @xmath3 value minimizes @xmath25 with a quadratic loss , the optimal estimate is the mean ; with a linear loss , it is the median . with a loss independent of the error , it is the mode .",
    "confidence intervals are easily calculable from ( [ measurand ] ) .",
    ".values of the planck constant .",
    "the input data are from @xcite and the references therein , with the exception of the last two , that are from @xcite .",
    "the values calculated from the quotient of @xmath3 and the neutron mass , the mass of a particle or of an atom , and the neutron binding energy depend on the same measured value of @xmath26 @xcite . [ cols=\"<,<\",options=\"header \" , ]     [ h_values ]     js of the post - data distribution shown in fig .",
    "[ post].,width=283 ]    figure [ planck - values - plot ] shows the input data used in the analysis .",
    "the values calculated from the measurements of @xmath27 , @xmath28 , and @xmath29 have been averaged , because their uncertainty is mainly affected by the @xmath26 determination and , therefore , they are highly correlated .",
    "the values obtained from nuclear spectroscopy have been averaged because they were obtained by repetitions of the same experiment .",
    "though none of them is totally out of scale , the data are inconsistent .",
    "the weighted mean is @xmath30 j / s with @xmath31 for @xmath32 degrees of freedom and birge ratio @xmath33 . in order to make the data consistent",
    ", it is usually assumed that the quoted uncertainties are wrong by a common scale factor . by multiplying the data uncertainties by the birge ratio ,",
    "the @xmath0 of the weighted mean is 9 and the birge ratio is 1 ; this removes the discrepancy between data spread and uncertainties .",
    "the weighted mean and the final associated uncertainty are given in table [ h_values ] .    .",
    "the input data are shown with their associated uncertainty .",
    "the reference value is the distribution mode , @xmath34 js.,width=264 ]    when assuming that the associated uncertainties are the lower bounds to unknown standard - deviations of the data , the probability calculus , as shown in section [ problem ] , allows a probability to be assigned to each possible @xmath3 value . according to ( [ measurand ] ) ,",
    "the post - data distribution of the @xmath3 values is @xmath35}{2(x_i - h ) } .\\ ] ]    by using the @xmath34 js mode of the post - data distribution ( the actual @xmath3 value is unknown ) , the marginal sampling distributions , @xmath36 and @xmath37 , of the nist 2007 and npl 2010 data are shown in fig .",
    "[ fig - sampling ] . the post - data distribution is shown in fig .",
    "[ post ] ; the most probable @xmath3 value and its mean and median are given in table [ h_values ] .",
    "it is to be noted that all these estimates are smaller than the weighted mean and that the standard deviation of the post - data distribution is significantly greater than that of the weighted mean .",
    "when data do not conform to the hypothesis of a known variance , the probability calculus offers a solution to the problem of fitting a constant to the set of measured values . by assigning probabilities to the possible measurand values , measurand values and confidence intervals can be optimally chosen .",
    "this approach is more rigorous than the search of estimators having optimal distributions for which no guideline exists .",
    "assigning probabilities helps in the choice of a measurand value also when a traveling standard is used to compare the measurement capabilities of different laboratories .",
    "the post data distribution of the measurand values depends on the hypotheses made for the probability density of the unknown standard - deviation of data .",
    "the probability calculus allows different hypotheses to be compared ; this will be the matter of future investigations .",
    "this research received funding from the european community s seventh framework programme , era - net plus , under the imera - plus project - grant agreement no .",
    "99 luemberger d g 1969 optimization by vector space methods ( new york : john wiley & sons , inc . ) dose v 2007 bayesian estimate of the newtonian constant of gravitation _ meas .",
    "technol . _ * 18 * 176 - 82 d sivia and j skilling 2006 data analysis : a bayesian tutorial ( oxford : oxford university press ) jaynes e t 2003 probability theory : the logic of science ( cambridge : cambridge university press ) mc kay d jc 2003 information theory , inference , and learning algorithms ( cambridge : cambridge university press ) gregory p c 2005 bayesian logical data analysis for the physical sciences ( cambridge : cambridge university press ) mohr p j , taylor b n , and newell d b 2008 codata recommended values of the fundamental physical constants : 2006 _ rev .",
    "phys . _ * 80 * 633 - 730 rainville s",
    "_ 2005 a direct test of @xmath38 _ nature _ * 438 * 1096 - 7 andreas b , azuma y , bartl g , becker p , bettin h , borys m , busch i , fuchs p , fujii k , fujimoto h , kessler e , krumrey m , kuetgens u , kuramoto n , mana g , massa e , mizushima s , nicolaus a , picard a , pramann a , rienitz o , schiel d , valkiers s , waseda a , and zakel s 2011 counting the atoms in a @xmath39si crystal for a new kilogram definition _ metrologia _ * 48 * s1-s13"
  ],
  "abstract_text": [
    "<S> when data do not conform to the hypothesis of a known sampling - variance , the fitting of a constant to the set of measured values is a long debated problem . </S>",
    "<S> given the data , the fitting would require to find which measurand value is most probable . </S>",
    "<S> a fitting procedure is here reviewed which assigns probabilities to the possible measurand values , on the assumption that the uncertainty associated with each datum is the lower bound to the standard deviation . </S>",
    "<S> this procedure is applied to derive an estimate of the planck constant . </S>"
  ]
}