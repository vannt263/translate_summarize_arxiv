{
  "article_text": [
    "we begin by recalling the assistive teleoperation model of section  [ sec : background ] : @xmath0 and we list the meaning of each quantity :    * @xmath1 is the trajectory of the robot through some state space . for ground robots ,",
    "a common choice for the state space is @xmath2 $ ] ; for air vehicles the state could be @xmath3.\\ ] ] this trajectory is _ a - priori _ modeled as a random function distributed according to a gaussian process ( @xcite ) , @xmath4 which can be trained offline using input - output examples of the robot s kinematics .",
    "+ online measurements of the state of the robot @xmath5 update the gp to @xmath6 ( assuming that the data @xmath7 has already arrived ) where @xmath8 is the new mean and @xmath9 is the new covariance function of the gp ( by `` new '' , we mean after incorporation of the new data @xmath10 ) .",
    "+ importantly , this model allows nonparametric probabilistic prediction of the trajectory into the future ; that is , @xmath11 \\to \\mathbb ( x , y , \\theta)\\end{aligned}\\ ] ] where @xmath12 .",
    "indeed , @xmath13 can be as large as one likes ( corresponding to how far into the future one predicts ) ; because @xmath14 , a continuous measure of the uncertainty @xmath15 exists , although it grows quite large the further one predicts into the future .",
    "+ we remark on the following : the structure of @xmath16 is such that the individual robot model @xmath17 changes with each new data point @xmath10 ; in particular , since gps are nonparametric models , they have the ability to capture some amount of online nonlinearities ( such as motor failures , terrain changes , etc ) . the extent to which this is true needs to be explored , however . *",
    "@xmath18 is the trajectory of the human operator through some state space . while the state space of the robot can typically be well characterized with physical models , the state space of the human for a more nuanced discussion of learning the human state space . ]",
    "is not immediately clear .",
    "+ as a first step , however , we choose the set of operator commands to the robot to correspond to the state of the human ; accordingly , we treat the operator input as measurements @xmath19 _ of the human trajectory through this input space_. in essence , we are regarding the human state as manifesting via the commands to the robot ; extrapolating , we assume that one can predict where the human will go in the `` command space '' ( appropriately hedged using probability densities ) . + as a simple example , if the human is operating a joystick that sends velocity commands @xmath20 to the robot s actuators , then @xmath21 furthermore , just as for the robot , the human trajectory is _ a - priori _ modeled as a random function distributed according to a gaussian process ( @xcite ) , @xmath22 new measurements of the state of the human @xmath23 update the gp to @xmath24 ( assuming that the data @xmath25 has already arrived ) where @xmath26 is the new mean and @xmath27 is the new covariance function of the gp ( by `` new '' , we mean after incorporation of the new data @xmath28 ) .",
    "+ in this way , we can predict what we expect the operator to do using probabilistic inference ( just as was done with the robot via @xmath17 ) , thereby enabling joint models of the human - robot team that anticipate future situations ( at times @xmath29 ) by making decisions now , at time @xmath30 .",
    "* @xmath31 is the interaction function between the human and the robot . in section  [ sec : background ]",
    ", a particular choice of this function of this choice is discussed .    with this model , control of the remote vehicle",
    "is accomplished in a receding horizon fashion : upon receipt of a measurement @xmath32 , the model @xmath16 is updated , and the new navigation protocol is taken to be @xmath33.\\end{aligned}\\ ] ] we then take @xmath34 as the next action in the path ( where @xmath35 means the next step of the optimal robot trajectory through the joint human - robot space ) . at @xmath35 , we receive observations @xmath36 , update the distribution to @xmath37 , find the map , and choose @xmath38 as the next step .",
    "this process repeats until the human - robot team arrives at the destination .",
    "we focus here on a few particular aspects of the control of a remote vehicle over unreliable networks : because operator commands can often arrive late , be dropped , or be otherwise corrupted across an arbitrary network , velocity commands such as @xmath39 can not be literally interpreted .",
    "imagine that the operator is viewing an onboard video feed that is 1 second old , due to communication constraints .",
    "additionally , imagine that the command @xmath40 takes 1 second to return to the remote vehicle .",
    "thus , the command received onboard the vehicle is 2 seconds old .",
    "clearly , this information is stale , and if interpreted by the vehicle literally , could destabilize control .",
    "however , these commands , while stale , are not devoid of information ; we suggest instead that the inputs be treated as measurements @xmath41 ( if @xmath30 is in seconds ) of the human - machine system .",
    "this suggests that a likelihood be placed on the commands @xmath42 if the current time on the remote vehicle is @xmath30 , then the distribution over the human trajectory gets updated to ( assuming all measurements prior to @xmath43 have been received in a timely fashion ) @xmath44 we now update the navigation distribution to @xmath45 however , because we are modeling _",
    "trajectories _ of the human , the model can naturally incorporate delayed receipt : the data at @xmath43 informs the distribution @xmath46 , but when inference is done at time @xmath30 , additional uncertainty has accumulated .",
    "thus , when we extract the navigation protocol using @xmath47\\end{aligned}\\ ] ] the distribution around the human trajectory at time @xmath30 is less peaked , and so is treated as less informative when evaluating @xmath48 ( which is the actual movement the robot executes at time @xmath30 ) .",
    "lossy networks are treated in an identical manner : indeed , if measurement @xmath49 is missing ( where @xmath50 ) , then our navigation protocol is still @xmath51.\\end{aligned}\\ ] ] again , the effect on the performance of the system is gradual : as more measurements go missing ( or are delayed ) , the less informative @xmath52 is , and the more the onboard autonomy is trusted ( we thus have a natural formulation of sliding autonomy : see section  [ sec : sliding ] ) .",
    "we emphasize that how well this approach performs is tied strongly to the fidelity of the likelihood function @xmath53 ( as is the case with any bayesian approach ) ; an overconfident measurement model can lead to overly confident human trajectory models , which can place too much weight on incorrect human input . under confident models will tend to overtrust the onboard autonomy , thus potentially leading to a robot that does not follow the orders of the operator .",
    "nevertheless , the presence of an uncertain network forces us to treat operator inputs as probabilistic quantities , rather than deterministic ones .",
    "while methods of sliding autonomy have been explored for a wide variety of tasks ( see @xcite ) , the amount of autonomy allocated to the robot ( or robots ) or the operator ( or operators ) is typically implemented in a manner _ independent _ of the human - robot team ; that is , some independent estimation algorithm determines how much control each entity receives , and then that number is fed into an algorithm that mixes a weighted combination of each intelligence .",
    "we argue here that our approach integrates the allocation of autonomy and the actual mixing of the multiple intelligences in a single step .",
    "in particular , we revisit our model of assistive teleoperation @xmath54 this model contains an online model of the human operator @xmath52 and the robot @xmath17 . in section",
    "[ sec : networks ] , we discussed how both the human operator model can respond online to varying network conditions ; in section  [ sec : individual ] we discussed how both the human and robot models can learn , in an online fashion , peculiarities of the individual operator or individual robot ( peculiarities of the individual with respect to general psychological theories or cad based kinematic models , respectively ) .    more generally , these individual models maintain a measure of uncertainty about the current state of operator or robot  this uncertainty can naturally be interpreted as proportional to the inverse of how much autonomy should be allocated to each entity .",
    "the model thus contains an implicit measure of sliding autonomy , which is a natural artifact of the igpmodel .",
    "perhaps more importantly , however , is that this measure of sliding autonomy is incorporated into the final action in a probabilistic fashion : should the uncertainty become large around either intelligence ( due to an unreliable network , uncharacteristic behavior , or any other number of anomalies ) , then the amount of confidence placed in that intelligence becomes reduced upon blending in the function @xmath55 .",
    "mathematically , as @xmath52 ( or @xmath17 ) becomes more diffuse , its effect on @xmath56 becomes less pronounced .",
    "one can only extract so much information from any system , and when both distributions become diffuse , the overall information content is very low , and so navigation should start to degrade . the best we can hope for is a graceful degradation .",
    "succinctly , the final action taken by the remote vehicle is given by @xmath33.\\end{aligned}\\ ] ] effectively , sliding autonomy ( or blended autonomy ) is a natural by - product of our formulation : an implicit measure of blending exists in the individual models , while the uncertainty of those individual models feeds into the interaction function .",
    "current theories of shared autonomy are dominated by anecdotal evidence and heuristic guidelines . in @xcite",
    "the three recognized levels of autonomy are listed : adaptive ( the agent adjudicates ) , adjustable ( the supervisor adjudicates ) , and mixed - initiative ( the agent and supervisor `` collaborate to maintain the best perceived level of autonomy '' ) . in @xcite ,",
    "human robot collaboration schemas are organized around social , organizational and cultural factors , and in @xcite the role of ethological and emotional models in human - robot interaction are examined .",
    "furthermore , actual implementations are typically designed around need , rather than principle ( @xcite ) : either the remote human operator retains complete control of the robot , or the human operator makes online decisions about the amount of autonomy the robot is given .",
    "importantly , the work of @xcite introduces principled user goal inference and prediction methods , combined with an arbitration step to balance user input and robot intelligence .",
    "however , our approach to shared autonomy as an extension of multiple goal interacting gaussian processes ( mgigp ) ( see @xcite ) unifies the three steps of @xcite , thus providing a more straightforward framework in which to understand the fusion of human and machine intelligence .",
    "we also propose that extending mgigpcould provide a novel mathematical formulation of shared autonomy ( which we call _ blended autonomy _ ) .",
    "first , recall the mgigpmodel of @xcite . next , suppose a human operator is controlling the robot from a remote location , so the robot is no longer fully autonomous ( we continue the narrative of a robot navigating through a crowd of @xmath57 individuals @xmath58 ) . however , rather than treating the human commands as system interrupts , we wish to understand the continuum of blended autonomy in a mathematical way . using the navigation protocol derived using @xmath59 as motivation , we could model the joint human operator - robot _ system _ as @xmath60 where @xmath18 is the is the human operator s _ predicted _ interests , modeled with a gaussian process mixture @xmath61 .",
    "the measurement data is now @xmath62 where @xmath63 are the human operator commands sent from time @xmath64 .",
    "additionally , @xmath65 is the interaction function between the human operator , robot , and human crowd .",
    "one concrete instantiation of this interaction function is @xmath66 where @xmath67 is the cooperation function from the model @xmath59 and @xmath68 is an `` attraction '' model between the operator commands and the robot path .",
    "one possible attraction model is @xmath69 thus , the operator s intentionality @xmath18 and the robot s planned path @xmath1 are _",
    "merged_this formulation of @xmath68 gives high weight to paths @xmath18 and @xmath1 that are similar , while the probability of dissimilar paths decreases exponentially .",
    "bear in mind , however , that @xmath67 still gives high weight to paths @xmath70 and @xmath1 that cooperate .",
    "all of this is balanced against the ( predicted ) individual intentionality encoded in the gaussian process mixtures @xmath71 .",
    "as with mgigp , the model @xmath72 suggests a natural way to interpret blended autonomy ( or blended decision making ) : at time @xmath30 , find the map assignment for the posterior @xmath73 and then take @xmath34 as the next robot action . as new measurements arrive , compute a new plan by recalculating the map of the blended autonomy density . by choosing to interpret navigation under the model @xmath74 _ blended autonomy _ in complex environments is modeled in a transparent way :",
    "human commands are statistically weighted against machine intelligence in a receding horizon framework .",
    "the key insight is that by modeling the _ joint _ human - robot system , we can blend human and robot capabilities in a single step to produce a superior system level decision . when the human system and the robot system are modeled independently , it becomes unclear how to fuse the complementary proficiencies of the human and robot agents ."
  ],
  "abstract_text": [
    "<S> we discuss some of the challenges facing shared autonomy . </S>",
    "<S> in particular , we explore ( via the methods of _ interacting gaussian process _ models ( igp ) , @xcite )    1 .   shared autonomy over unreliable networks , 2 .   </S>",
    "<S> how we can model _ individual _ human operators ( in contrast to the `` average '' of a human operator ) , and 3 .   </S>",
    "<S> how igpnaturally models and integrates sliding autonomy into the joint human - machine system .    </S>",
    "<S> we include a background section ( section  [ sec : background ] ) for completeness . </S>"
  ]
}