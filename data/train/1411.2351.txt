{
  "article_text": [
    "despite the availability of numerous standardized formats for semi - structured and semantic web data such as xml , rdf , and json , a very large percentage of data and open data published on the web , remains tabular in nature .",
    "tabular data is most commonly published in the form of comma separated values ( csv ) files because such files are open and therefore processable by numerous tools , and tailored for all sizes of files ranging from a number of kbs to several tbs . despite these advantages , working with csv files is often cumbersome because they are typically not accompanied by a _ schema _ that describes the file s structure ( i.e. , `` the second column is of integer datatype '' , `` columns are delimited by tabs '' ,  ) and captures its intended meaning .",
    "such a description is nevertheless vital for any user trying to interpret the file and execute queries or make changes to it . in other data models ,",
    "the presence of a schema is also important for query optimization ( required for scalable query execution if the file is large ) , as well as other static analysis tasks .",
    "finally , we strongly believe that schemas are a prerequisite for unlocking huge amounts of tabular data to the semantic web . indeed ,",
    "unless we have a satisfactory way of describing the structure of tabular data we can not specify how its contents should be interpreted as rdf .",
    "drawing parallels with relational databases , observe that r2rml mappings  @xcite ( the w3c standard for mapping relational databases to rdf ) inherently need to refer to the schema ( structure ) of the relational database in order to specify how database tuples can be represented as rdf .    in recognition of this problem ,",
    "the _ csv on the web _ working group of the world wide web consortium @xcite argues for the introduction of a schema language for tabular data to ensure higher interoperability when working with datasets using the csv or similar formats .",
    "in particular , their charter states @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ whether converted to other formats or not , there is a need to describe the content of the csv file : its structure , datatypes used in a specific column , language used for text fields , access rights , provenance , etc .",
    "this means that metadata should be available for the dataset , relying on standard vocabulary terms , and giving the necessary information for applications .",
    "the metadata can also be used for the conversion of the csv content to other formats like rdf or json , it can enable automated loading of the data as objects , or it can provide additional information that search engines may use to gain a better understanding of the content of the data . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in the present paper , we introduce as a concept for such a schema language for tabular data .    the critical reader may wonder whether designing such a schema language is nt trivial .",
    "after all , does nt it suffice to be able to specify , for each column , the column s name and the type of data allowed in its cells  similar to how relational database schemas are defined using the sql data definition language ?",
    "the answer is no .",
    "the reason is that there is a lot of variation in the tabular data available on the web and that there are examples abound of tabular data whose structure can not be described by simple rules of the form `` column @xmath0 has datatype @xmath1 '' .",
    "figures  [ ex:1:csv ] , [ ex:2:csv ] , and [ fig : pdb ] , for example , show some tabular data sets drawn from the use cases and requirements document drafted by the w3c csv on the web working group  @xcite .",
    "notice how , in contrast to `` standard '' csv files , figure  [ ex:1:csv ] has a header consisting of multiple lines .",
    "this causes the data in the first column to be non - uniform .",
    "further notice how the ` provenance ` data in the figure  [ ex:2:csv ] is spread among multiple columns .",
    "finally , notice how the shape of the rows in figure  [ fig : pdb ] depends on the label in the first column of the column : ` title ` rows have different structure than ` author ` rows , which have a different structure than ` atom ` rows , and so on .",
    "schemas use the following idea to describe the structure of these tables . at their core ,",
    "schemas consist of rules of the form @xmath2 . here",
    ", @xmath3 selects a _ region _ in the input table ( i.e. , a subset of the table s cells ) and @xmath4 constrains the allowed structure and content of this region .",
    "a table is valid with respect to a schema if , for each rule in the schema , the region selected by @xmath3 satisfies the content constraints specified by @xmath4 .",
    "it is important to note that s expressive power goes well beyond that of classical relational database schemas since s region selectors are not limited to selecting columns .",
    "in particular , the language that we propose for selecting regions is capable of navigating through a table s cells bears much resemblance to the way xpath  @xcite navigates through the nodes of an xml tree .",
    "for tokenizing the content of single cells , we draw inspiration from xml schema simple types ( @xcite , section 2.2 ) . both features combined",
    "will allow us to express the use cases of the w3c csv on the web working group .",
    "we note that the w3c is also working on a schema language for tabular data  @xcite . at the moment , however , that schema language focuses on orthogonal issues like describing , for instance , _ datatypes _ and _ parsing cells_. also , it only provides facilities for the selection of _ columns _ , and is hence not able to express the schema of the more advanced use cases .",
    ", in contrast , draws inspiration from well - established theoretical tools from logic and formal languages , which adds to the robustness of our approach . due to the above mentioned orthogonality we expect that it is not difficult to integrate ideas from this paper in the w3c proposal .    in summary , we make the following contributions .",
    "we illustrate the power of , and its suitability as a schema language for tabular data on the web , by expressing several use cases drafted by the csv on the web w3c working group  @xcite .",
    "( section  [ sec : chisel : examples ] )    we provide a formal model for the core of . a key contribution in this respect",
    "is the introduction of the region selector language .",
    "( section  [ sec : formalmodel ] )    we show that , despite its rather attractive expressiveness , tables can be efficiently validated w.r.t .  schemas .",
    "in particular , when the table is small enough to be materialized in main memory , we show that validation can be done in linear time combined complexity ( section  [ sec : evaluation : linear ] ) . for scenarios where materialization in main memory is not possible , we consider the scenario of streaming ( i.e. , incremental ) validation .",
    "we formally introduce two versions of streaming validation : _ weak streamability _ and _ strong streamability_. ( their differences are described in detail in section  [ sec : streaming - evaluation ] . )",
    "we show in particular that the fragment of where region selectors can only look `` forward '' and never `` backward '' in the csv file is _",
    "weakly streamable_. if we further restrict region selectors to be both forward - looking and _ guarded _",
    "( a notion formalized in section  [ sec : streaming - evaluation ] ) validation becomes _ strongly streamable_. all of the w3c working group use cases considered here can be expressed using forward and guarded region selectors , hence illustrating the practical usefulness of this fragment .    while our focus in this paper is on introducing as a means for specifying the structure of csv files and related formats",
    ", we strongly believe that region selector expressions are a fundamental component in developing other features mentioned in the charter of the w3c csv on the web working group , such as a csv transformation language ( for converting tabular data into other formats such as rdf or json ) , the specification of the language used for text fields ; access rights ; provenance ; etc .",
    "while a full specification of these features is out of this paper s scope , we illustrate by means of example how could be extended to incorporate them .",
    "( section  [ sec : extensions ] )    * note . * due to space restrictions , proofs of formal statements are only sketched .",
    "proofs are provided in the appendix .    * related work . *",
    "the present paper fits in the line of research , historically often published in the www conference , that aims to formalize and study the properties of various w3c working group drafts and standards ( including xml schema  @xcite , sparql  @xcite , and rdf  @xcite ) with the aim of providing feedback and input to the working group s activities .",
    "given the numerous benefits of schemas for data processing , there is a large body of work on the development , expressiveness , and properties of schema languages for virtually all data models , including the relational data model , xml  @xcite , and , more recently , rdf  @xcite .",
    "differs from the schema languages considered for xml and rdf in that it is specifically designed for tabular data , not tree - structured or graph - structured data . nevertheless , the rule - based nature of draws inspiration from our prior work on rule - based and pattern - based schema languages for xml  @xcite .    as already mentioned , while traditional relational database schemas ( formulated in e.g. , the sql data definition language ) are specifically designed for tabular data , they are strictly less expressive than schemas in the sense that relational schemas limit region selection expressions to those that select columns only .",
    "a similar remark holds for other recent proposals of csv schema languages , including the csv schema language proposed by the uk national archives  @xcite , and tabular data package  @xcite .",
    "the remark also applies to the part of google s dataset publishing language ( dspl )  @xcite describing the contents of csv files .",
    "in contrast , dspl also has features to relate data from multiple csv files , which does not yet have .",
    "the problem of streaming schema validation has been investigated in the xml context for dtds and xml schemas @xcite . in this work ,",
    "the focus is on finding algorithms that can validate an xml document in a single pass using constant memory or , if this is not possible , a memory that is bounded by the depth of the document .",
    "our notion of streaming , in contrast , is one where we can use a memory that is not constant but at most logarithmic in the size of the table ( for strong streaming ) , or at most linear in the number of columns and logarithmic in the number of rows ( for weak streaming ) .",
    "this allows us to restrict memory when going from one row to the next and is essential to be able to navigate downwards in region selection expressions .",
    "while streaming validation is undoubtedly an important topic for all of the csv schema languages mentioned above  @xcite ( the national archives schema language mentions it as an explicit design goal ) , no formal streaming validation algorithm has been proposed for them , to the best of our knowledge .",
    "[ sec : examples ]    in this section , we introduce through a number of examples .",
    "the formal semantics of the examples is defined in section  [ sec : formalmodel ] .",
    "the syntax we use here is tuned for making the examples accessible to readers and is , of course , flexible .",
    "schemas operate on _ tabular documents _ , which are text files describing tabular data .",
    "schemas consist of two parts ( cf .",
    "figure  [ fig : climate - schema ] ) .",
    "the first part , _ parsing information _ , defines the row and column delimiters and further describes how words should be tokenized .",
    "this allows to parse the text file and build a table - like structure consisting of rows and columns . in this section",
    "we allow some rows to have fewer columns than others but we require them to be aligned to the left .",
    "that is , non - empty rows always have a first column .",
    "the second part of the schema consists of _ rules _ that interpret the table defined by the first part as a rectangular grid and enforce structure .",
    "in particular , rules are of the form @xmath5 , where @xmath3 selects a _ region _ consisting of cells in the grid while @xmath4 is a regular expression constraining the content of the selected region .",
    "we utilize a so - called _ row - based _ semantics : every row in the region selected by @xmath3 should be of a form allowed by @xmath4 .",
    "we refer to @xmath3 as the _ selector expression _ and to @xmath4 as the _",
    "content expression_.    next , we illustrate the features of the language by means of examples .",
    "all examples are inspired by the use cases and requirements drafted by the csv on the web w3c working group  @xcite .",
    "[ ex : simple ] figure  [ fig : climate ] contains a slightly altered fragment ( we use a comma as a column separator ) of a csv file mentioned in use case 3 , _",
    "`` creation of consolidated global land surface temperature climate databank '' _",
    "the schema , displayed as figure  [ fig : climate - schema ] , starts by describing parsing information indicating that the column delimiter is a comma while the row delimiter is a newline .",
    "lines starting with a % -sign are comments .",
    "tokens are defined based on regular expressions ( regex for short ) . for instance , anything that matches the regex ` [ 0 - 9]{4}.[0 - 9]{2 } ` follows the format _",
    "four digits , dot , two digits _ , and is interpreted by the token ` timestamp ` in the rules of the schema ( similar for temperature ) .",
    "notice that we keep the regexes short ( and sometimes imprecise ) for readability , but they can of course be made arbitrarily precise if desired .    ....         ,    arua ,   bombo , entebbe air 1935.04 , -99.00 , -99.00 ,        27.83 1935.12 , -99.00 , -99.00 ,        25.72 1935.21 , -99.00 , -99.00 ,        26.44 1935.29 , -99.00 , -99.00 ,        25.72 1935.37 , -99.00 , -99.00 ,        24.61 1935.46 , -99.00 , -99.00 ,        24.33 1935.54 , -99.00 , -99.00 ,        24.89 ....    .... %   parsing information % % delimiters col delim",
    "= , row delim = \\n    % % tokens % % left : token name   % % right : regex    timestamp = [ 0 - 9]{4}\".\"[0 - 9]{2 } temperature = ( -)?[0 - 9]{2}\".\"[0 - 9]{2 } arua = arua bombo = bombo entebbe air = entebbe air    % rules    row(1 ) - > empty , arua , bombo , entebbe air col(1 ) - > empty | timestamp col(arua ) - > temperature col(bombo ) - > temperature col(entebbe air ) - > temperature ....",
    "all the xml schema primitive types like , , , etc are pre - defined as tokens in a schema .",
    "there is also a special pre - defined token empty to denote that a certain cell is empty .",
    "notice that the schema in figure  [ fig : climate - schema ] has three token definitions in which the regex defines only one character sequence ( namely : ` aura ` , ` bombo ` , ` entebbe air ` ) . in the sequel",
    ", we will omit such rules for reasons of parsimony .",
    "for the same reason , we omit the explicit definition of column and row delimiters when they are a comma and newline character , respectively .",
    "the rule    ` row(1 ) - > empty , arua , bombo , entebbe air `    selects all cells in the first row and requires that the first is empty , the second contains arua , the third bombo , and the fourth entebbe air .",
    "next , ` col(1 ) ` selects the region consisting of all cells in the first column . as assumes a row - based semantics per default , . ]",
    "the rule    ` col(1 ) - > empty | timestamp `    requires that every row in the selected region ( notice that each such row consists of a single cell ) is either empty ( empty ) or contains data that matches the timestamp token .",
    "the expression ` col(aura ) ` selects all cells in the column below the cell containing arua .",
    "the rule    ` col(arua ) - > temperature `    therefore requires that every row in the selected region matches the temperature token .",
    "the two remaining rules are analogous .",
    "the fragment in figure  [ fig : climate ] satisfies the schema of figure  [ fig : climate - schema ] .",
    "@xmath6    before moving on to some more advanced examples , we discuss in more detail the semantics of selector and content expressions . each cell in a table is identified by its _ coordinate _ , which is a pair @xmath7 where @xmath8 indicates the row number ( @xmath9 ) and @xmath10 the column number ( @xmath11 ) . in each rule",
    "@xmath2 , the selector expression @xmath3 returns a _ set _ of coordinates ( a region ) and @xmath4 is a regular expression defining the allowed structure of each row in the region selected by @xmath3 .",
    "it is important to note that in each such row only the cells which are selected by @xmath3 are considered .",
    "another way to interpret the row - based semantics is that of a ` group by ' on the selected region per row .    ....",
    "qs601ew economic activity 27/03/2011             ,         , count    , count           ,         , person   , person                ,         , activity , activity geoid     , geoarea , all      , part - time e92000001 , england , 38881374 , 27183134 w92000004 , wales   , 2245166 , 1476735 ....    .... % % tokens % % left : token name   % % right : regex    name = qs[0 - 9]*ew ctype = economic activity geo_id = e[0 - 9 ] *    % rules    row(1 ) - > name row(2 ) - > ctype row(3 ) - > date row(4 ) - > empty row(5 ) - > empty , empty , count * row(6 ) - > empty , empty , person * row(7 ) - > empty , empty , activity * row(8 ) - > geoid , geoarea , string * col(geoid ) - > geo_id col(geoarea ) - > string down+(right+(geoarea ) ) - > number * ....    the last rule we discussed in example  [ ex : simple ] uses a symbolic coordinate arua in its selector expression .",
    "its semantics is as follows : a token @xmath12 returns the set of all coordinates @xmath7 whose cell contents matches @xmath12 .",
    "the operator row applied to a coordinate @xmath7 returns the set of coordinates @xmath13 .",
    "this corresponds to the row consisting of all elements to the right of @xmath7 .",
    "note that coordinate @xmath7 itself is not included . applying row to a _ set _",
    "@xmath14 of coordinates amounts to taking the union of all row@xmath15 where @xmath16 .",
    "similarly , the operator col applied to @xmath14 returns the union of the regions @xmath17 for each @xmath7 in @xmath14 , corresponding to columns below elements in @xmath14 . the selector expressions row(1 ) and",
    "col(1 ) that select the `` first row '' and `` first column '' , respectively , use syntactic sugar to improve readability . formally , the notation row(k ) and col(l ) abbreviate row(@xmath18 ) and col(@xmath19",
    ") , respectively .",
    "using the same principle as above , this means that row(k ) selects the cells @xmath20 and col(l ) selects @xmath21 .",
    "notice that we use the convention that the top left coordinate in tabular data bears the coordinate @xmath22  for _ first row _ , _ first column_. while the value 0 does not refer to any cell in the table , it is used to define the semantics of expressions .",
    "the next example illustrates the use of slightly more complex expressions for navigation and content .",
    "[ ex : medium ] figure  [ ex:1:csv ] displays a ( slightly altered ) fragment of a csv - like - file inspired by use case 2 ( _ `` publication of national statistics '' _ ) in @xcite .",
    "this fragment originates from the office for national statistics ( uk ) and refers to the dataset `` qs601ew economic activity '' derived from the 2011 census .",
    "the file starts with three lines of metadata , referring to the name of the file and the census date , continues with a blank line , before listing the actual data separated by commas .",
    "notice that this file is , strictly speaking , not a comma - separated - value file because not all rows have an equal number of columns .",
    "indeed , the first four rows have only ( at most ) one column and the later rows have four columns .",
    "figure  [ ex:1:schema ] depicts the schema describing the structure of such tables .",
    ".... subject   predicate       object   provenance : e4       type            per : e4       mention        \" bart \"    d00124 283 - 286 : e4       mention        \" jojo \"    d00124 145 - 149 0.9 : e4       per : siblings   : e7       d00124 283 - 286 173 - 179 274 - 281 : e4       per : age        \" 10 \"      d00124 180 - 181 173 - 179 182 - 191 0.9 : e4       per : parent     : e9       d00124 180 - 181 381 - 380 399 - 406 d00101 220 - 225 230 - 233 201 - 210 ....    the schema starts by describing parsing information , analogous to example  [ ex : simple ] .",
    "the first four rules are very basic and are similar to those of example  [ ex : simple ] .",
    "we first describe the fifth rule of the schema :    ` row(5 ) - > empty , empty , count * `    selects all cells in the fifth row , requiring the first two to be empty and the remaining non - empty cells to contain count .",
    "we note that the original data fragment from @xcite contains 16 such columns .",
    "the remaining rules constraining rows are similar .",
    "the rule ` col(geoid ) - > geo_id ` selects all cells below cells containing the word geoid .",
    "the content expression says that this column contains values that match the geo_id token .",
    "the last rule is the most interesting one :    ` down+(right+(geoarea ) ) - > number * ` .",
    "this rule selects all cells appearing strictly downward and to the right of geoarea and requires them to be of type number .",
    "more precisely , geoarea is a symbolic coordinate selecting all cells containing the word geoarea .",
    "the navigational operators right and down select cells one step to the right and one step down , respectively , from a given coordinate .",
    "the operator + indicates an arbitrary strictly positive number of applications of the navigational operator to which it is applied . in particular , as on the table given in figure  [ ex:1:csv ] ,",
    "geoarea is the singleton cell with coordinate @xmath23 , right(geoarea ) returns @xmath24 , while right+(geoarea ) is the region @xmath25 . likewise , down(right+(geoarea ) ) is the region @xmath26 and , finally , down+(right+(geoarea ) ) is the region downward and to the right of the geoarea coordinate , that is , @xmath27 and @xmath28 .",
    "@xmath6    example  [ ex : medium ] uses more refined navigation than just selecting a row or a column . has four navigational axes : up , down , left , right which navigate one cell upward , downward , leftward , or rightward .",
    "these axes can be applied to a set @xmath14 of coordinates and add a vector @xmath29 to it .",
    "more formally , an axis @xmath30 , when applied to a set @xmath14 of coordinates , returns @xmath31 . here ,",
    "@xmath32 when @xmath33 ,    @xmath34 when @xmath35 .",
    "@xmath36 when @xmath37 , and    @xmath38 when @xmath39 .",
    "furthermore , there is also an axis cell that does not navigate away from the current cells , i.e. , @xmath40 .",
    "when applying an axis to a set of coordinates , we always return only the coordinates that are valid coordinates in the table .",
    "for example ,",
    "left(\\{1,1 } ) returns the empty set because @xmath41 is not a cell in the table .    while the just discussed features of are sufficient to describe the structure of almost all csv - like data on the web working group use cases  @xcite , we extend in section  [ sec : formalmodel ] to include xpath - like navigation .",
    "these features will be useful for annotations and transformations , see section  [ sec : extensions ] .",
    "we now showcase by illustrating it on the most challenging of the w3c use cases .",
    "figure  [ ex:2:csv ] contains a fragment of a csv - like file , inspired by use case 13 in @xcite ( _ `` representing entities and facts extracted from text '' _ ) .",
    "figure  [ ex:2:schema ] depicts the schema .",
    "compared to the previous examples , the most interesting rule is    ` down+(right*(provenance ) ) `    ` - > ( prov - book , prov - pos * , prov - node ? ) * `    which states that every row that starts with a coordinate of the form @xmath42 ( as provenance only occurs in column 4 ) with @xmath43 should match ` ( prov - book , prov - pos * , prov - node ? ) * ` .",
    "notice that the empty row starting at @xmath44 also matches this expression . here",
    ", denotes an arbitrary number ( including zero ) of applications of the navigational operator .",
    "@xmath6    .... % tokens",
    "% % left : token name   % % right : regex    rdf - id     = [ a - za - z0 - 9]*:[a - za - z0 - 9 ] * rdf - lit    = \" [ a - za - z0 - 9 ] * \" prov - book = d[0 - 9]{5 } prov - pos   = [ 0 - 9]{3}-[0 - 9]{3 } prov - node = [ 0 - 9].[0.9 ] word       = [ a - z ] *    % rules row(1 ) - > subject , predicate , object , provenance col(subject )    - > rdf - id col(predicate ) - > word | rdf - id col(object )     - > rdf - lit | rdf - id down+(right*(provenance ) )            - > ( prov - book , prov - pos * , prov - node ? ) * ....",
    "in this section , we present a formal model for the logical core of .",
    "we refer to this core as and discuss extensions in section  [ sec : extensions ] .",
    "we first define the data model .    * tables . * for a number @xmath45 , we denote the set @xmath46 by @xmath47 $ ] . by @xmath48",
    "we denote a special distinguished null value . for any set @xmath49",
    ", we denote the set @xmath50 by @xmath51 .",
    "the w3c formalizes tabular documents through _ tables _ , which can be defined as follows .",
    "[ def : tabular ] let @xmath49 be a set .",
    "a _ table _ over @xmath49 is an @xmath52 matrix @xmath53 ( for some @xmath54 in which each cell carries a value from @xmath51 .",
    "we say that @xmath53 has @xmath55 _ rows _ and @xmath56 _",
    "columns_. a _ ( table ) coordinate _ is an element of @xmath47\\times[m]$ ] .",
    "a _ cell _ is determined by coordinate @xmath57 \\times [ m]$ ] and its _ content _ is the value @xmath58 at the intersection of row @xmath8 and column @xmath10 .",
    "we denote the _ coordinates _ of @xmath53 by @xmath59 .    * tabular documents .",
    "* notice that tables are always rectangular whereas , in section  [ sec : examples ] , this was not the case for some of the use cases .",
    "we model this by padding shorter rows by @xmath48 .",
    "more precisely , we see the correspondence between _ tabular documents _ ,",
    "i.e. , text files that describe tabular data ( like csv files ) , and tables as follows .",
    "let @xmath60 be a finite alphabet and let @xmath61 be a set of _ delimiters _ , disjoint from @xmath60 .",
    "we assume that @xmath61 contains two designated elements which we call _ row delimiter _ and _ column delimiter _ , which , as the name indicates , separate cells vertically or horizontally.(we discuss other delimiters in section  [ sec : extensions ] . ) therefore , a sequence of symbols in @xmath62 can be seen as a table over @xmath63 : every row delimiter induces a new row in the table , every column delimiter a new column , and the @xmath60-strings between delimiters define the cell contents . in the case",
    "that some rows have fewer columns than others , missing columns are expanded to the right and filled with @xmath48 .",
    "conversely , a table over @xmath63 can also be seen as a string over @xmath62 by concatenating all its cell values in top - down left - to - right order and inserting cell delimiters and row delimiters in the correct places ; we do not insert column delimiters next to @xmath48-cells . as such , when we convert a tabular document into a table and back ; we obtain the original tabular document .",
    "we consider both representations in the remainder of the paper .",
    "in particular we view the table representation as a structure that allows efficient navigation in all directions and the string representation as structure for streaming validation .",
    "* schemas . * abstractly speaking , a schema @xmath14 is a @xmath64-tuple @xmath65 where @xmath61 is the set of delimiters ; @xmath66 is a finite set of tokens ; @xmath67 is a mapping that associates a regular expression over @xmath60 to each token @xmath68 ; and @xmath69 is a _ tabular schema _ , a set of rules that constrain the admissible table contents ( further defined below ) .",
    "checking whether a tabular document @xmath70 in @xmath62 satisfies @xmath14 proceeds conceptually in three phases . in the first phase ,",
    "the delimiters are used to parse @xmath70 into a table @xmath71 over @xmath63 , as described above . in the second phase , the token definitions @xmath67 are used to transform @xmath71 into a _ tokenized _",
    "table @xmath53 , which is a table where each cell contains a set of tokens ( i.e. , each cell contains a subset of @xmath72 , namely those tokens that match the cell ) .",
    "formally , @xmath53 is the table of the same dimension as @xmath71 such that @xmath73 here @xmath74 denotes the language of a regular expression .",
    "finally , the rules in @xmath69 check validity of the tokenized table @xmath53 ( and not of the raw table @xmath71 ) , as explained next .    * tabular schema . *",
    "the _ tabular schema _ @xmath69 describes the structure of the tokenized table .",
    "intuitively , a tabular schema is a set of rules @xmath75 in which @xmath76 _ selects _ a region in the table and @xmath77 describes what the _ content _ of the selected region should be .",
    "more formally , a _ region",
    "_ @xmath78 of an @xmath79 table @xmath53 is a subset of @xmath47 \\times [ m]$ ] .",
    "region selection language @xmath80 _ is a set of expressions such that every @xmath81 defines a region in every table @xmath53 .",
    "more precisely , @xmath82 $ ] is always a ( possibly empty ) region of @xmath53 .",
    "a _ content language _",
    "@xmath83 is a set of expressions such that every @xmath84 maps each region @xmath78 of @xmath53 to true or false .",
    "we denote by @xmath85 that @xmath77 maps @xmath78 to true in @xmath53 and say that @xmath78 _ satisfies _ @xmath77 in @xmath53 .    a _ ( tabular ) schema _",
    "( over @xmath80 and @xmath83 ) is a set @xmath69 of rules @xmath75 for which @xmath86 and @xmath87 .",
    "a table @xmath53 _ satisfies _ @xmath69 , denoted @xmath88 , when for every rule @xmath89 we have that @xmath90\\models c$ ] .",
    "the above definition is very general as it allows arbitrary languages for selecting regions and defining content .",
    "we now propose concrete languages for these purposes .",
    "* region selection expressions.*[sec : selector - expressions ] our region selection language is divided into two sorts of expressions : _ coordinate expressions _",
    "( ranged over by @xmath91 ) and _ navigational expressions _ ( ranged over by @xmath92 , @xmath93 ) , defined by the following syntax : @xmath94 \\mid ( \\alpha \\cdot \\beta ) \\mid ( \\alpha | \\beta )    \\mid ( \\alpha^*)\\end{aligned}\\ ] ] here , @xmath95 ranges over tokens in @xmath72 and is a constant referring to coordinate @xmath22 .",
    "when evaluated over an @xmath79 table @xmath53 over @xmath96 , a coordinate expression @xmath3 defines a region @xmath97 , whereas a navigational expression @xmath92 defines a function @xmath98 , as follows .",
    "@xmath99 \\times [ m ] \\mid a \\in t_{i , j } \\ } \\\\    { \\llbracket \\textsf{root } \\rrbracket}_t & : = \\{(1,1)\\}\\\\    { \\llbracket \\textsf{true } \\rrbracket}_t & : = [ n ] \\times [ m ] \\\\    { \\llbracket ( \\varphi \\lor \\psi )",
    "\\rrbracket}_t & : = { \\llbracket \\varphi \\rrbracket}_{t } \\cup { \\llbracket \\psi \\rrbracket}_{t } \\\\    { \\llbracket ( \\varphi \\land \\psi ) \\rrbracket}_t & : = { \\llbracket \\varphi \\rrbracket}_t \\cap { \\llbracket \\psi \\rrbracket}_t \\\\    { \\llbracket ( \\lnot \\varphi ) \\rrbracket}_t & : = ( [ n ] \\times [ m ] ) \\setminus { \\llbracket \\varphi \\rrbracket}_t \\\\    { \\llbracket \\langle \\alpha \\rangle \\rrbracket}_t & : = \\ { c \\in \\operatorname{coords}(t ) \\mid { \\llbracket \\alpha(\\{c\\ } ) \\rrbracket}_t \\neq    \\emptyset\\ }",
    "\\\\     { \\llbracket \\alpha(\\varphi ) \\rrbracket}_t & : = { \\llbracket \\alpha({\\llbracket \\varphi \\rrbracket}_t ) \\rrbracket}_t\\end{aligned}\\ ] ] furthermore , for every set of coordinates @xmath100 , @xmath101(c ) \\rrbracket}_t & : = c \\cap { \\llbracket \\varphi \\rrbracket}_t \\\\",
    "{ \\llbracket ( \\alpha \\cdot \\beta)(c ) \\rrbracket}_t & : = { \\llbracket \\beta({\\llbracket \\alpha(c ) \\rrbracket}_t ) \\rrbracket}_t\\\\    { \\llbracket ( \\alpha | \\beta)(c ) \\rrbracket}_t & : = { \\llbracket \\alpha(c ) \\rrbracket}_t \\cup { \\llbracket \\beta(c ) \\rrbracket}_t \\\\    { \\llbracket ( \\alpha^*)(c ) \\rrbracket}_t & : = \\bigcup_{i \\geq 0 } { \\llbracket \\alpha^i(c ) \\rrbracket}_t \\end{aligned}\\ ] ] here , @xmath102 abbreviates the @xmath103-fold composition @xmath104 .",
    "we also use this abbreviation in the remainder .",
    "notice that every coordinate @xmath7 of @xmath53 can be expressed as @xmath105 . for navigational expressions",
    "@xmath92 , we abbreviate @xmath106 by @xmath107 and @xmath108 by @xmath109",
    ". one can read @xmath110 as `` apply the regular expression @xmath92 to @xmath3 '' .",
    "the definition of the semantics of @xmath111 is conform with this view .",
    "region selection expressions navigate in tables , similar to how xpath expressions navigate on trees .",
    "for example , assuming to be a token for -99.00 in figure  [ fig : climate ] , the expression @xmath112 selects the top cells of columns that do not contain a dummy value anywhere . in the excerpt of figure",
    "[ fig : climate ] , this expression hence selects the cell containing entebbe air .    assuming the token for cells with quotation marks ( regex ` \\\"[a - za - z0 - 9]\\ \" ` ) in figure  [ ex:2:csv ]",
    ", the expression @xmath113 \\cdot { \\textsf{right}\\xspace}^+ ( \\textsf{object})\\ ] ] selects all provenance information for rows in which the object is between quotes , like `` bart '' , `` jojo '' , and `` 10 '' .",
    "notice in particular that the semantics of the operator `` @xmath114 $ ] '' in navigational expressions is the same as filter - expressions in xpath .",
    "@xmath6    readers familiar with propositional dynamic logic  @xcite ( pdl for short ) will recognize that the above language is nothing more than propositional dynamic logic , tweaked to navigate in tables .",
    "there are some differences between the syntax of and the region selection expressions used in the examples of section  [ sec : chisel : examples ] .",
    "in particular , the latter examples use the following abbreviations .",
    "\\(i ) as already observed , absolute coordinates in section  [ sec : chisel : examples ] are syntactic sugar for navigations that start at the root .",
    "for example , the coordinate @xmath115 would be unfolded to @xmath116 in .",
    "\\(ii ) the keywords row and col in section  [ sec : chisel : examples ] are syntactic sugar for @xmath117 and @xmath118 in , respectively .",
    "so , col((2,2 ) ) , which denotes _ the column below the cell @xmath115 _ in section  [ sec : chisel : examples ] , is syntactic sugar for @xmath119 .",
    "\\(iii ) the only exception to rule ( ii ) above are row and column expressions of the form @xmath120 and @xmath121 .",
    "these abbreviate @xmath122 and @xmath123 , respectively .",
    "( where @xmath124 and @xmath125 need to be further unfolded themselves . )    as an example , the selection expression row(1 ) of figure [ ex:2:schema ] can be written as @xmath126 or , equivalently , @xmath127 and the expression col(subject ) as @xmath128 .",
    "@xmath6    * content expressions . *",
    "[ sec : content - expressions ] a _ content expression _ is simply a regular expression @xmath4 over the set of tokens @xmath72 . to define when a region in a tokenized table @xmath53 is valid with respect to content expression @xmath4 ,",
    "let us first introduce the following order on coordinates .",
    "we say that coordinate @xmath7 precedes coordinate @xmath129 if we visit @xmath7 earlier than @xmath130 in a left - to - right top - down traversal of the cells of @xmath53 , i.e. , it precedes it in lexicographic order .",
    "formally , @xmath131 if @xmath132 or if @xmath133 but @xmath134 .",
    "now , let @xmath53 be a tokenized table , let @xmath78 be a region of @xmath53 , and let @xmath4 be a content expression .",
    "then @xmath135 satisfies the content expression @xmath4 _ under the region - based semantics _",
    ", denoted @xmath136 if there exist tokens @xmath137 such that @xmath138 and @xmath139 , where @xmath140 is the enumeration in table order of all coordinates in @xmath78 .    to define the row - based semantics we used in section  [ sec : examples ]",
    ", we require the following notions .",
    "let @xmath78 be a region of @xmath53 .",
    "we say that subregion @xmath141 is a _ row of _",
    "@xmath78 if there exists some @xmath8 such that @xmath142 .",
    "now , @xmath135 satisfies the content expression @xmath4 _ under the row - based semantics _",
    ", denoted @xmath143 , if for every row @xmath144 of @xmath78 , we have @xmath145 .",
    "recall that , for ease of exposition , we allowed tables to be non - rectangular in section  [ sec : chisel : examples ] whereas in our formal model , tables are always rectangular .",
    "in particular , shorter rows are padded with @xmath48 to obtain rectangularity .",
    "this implies that , some content expressions of section  [ sec : chisel : examples ] need to be adapted in our formal model .",
    "for example , the rule row(1 ) - > name of figure  [ ex:1:schema ] needs to be adapted to @xmath146 to take the padding into account . @xmath6",
    "in this section we consider the _ validation _ ( or _ evaluation _ ) problem for tabular schemas .",
    "this problem asks , given a tokenized table or tabular document @xmath53 and a tabular schema @xmath69 , whether @xmath53 satisfies @xmath69 .",
    "we consider the problem in a _",
    "main - memory _ and _ streaming _ variant .",
    "intuitively , @xmath53 is given as a table in the former and as a tabular document in the latter setting .",
    "when @xmath53 is given as a tokenized table , we can essentially assume that we can navigate from a cell @xmath147 to any of its four neighbours @xmath148 , @xmath149 , @xmath150 , and @xmath151 in constant time .",
    "under these assumptions we show that @xmath53 can be validated against a tabular schema in linear time combined complexity .",
    "the proof strongly relies on the linear time combined complexity for pdl model checking .",
    "[ theo : evaluation][theo : evaluation ] the valuation problem for a tabular document @xmath53 and a schema @xmath69 is in linear time combined complexity , that is , time @xmath152 .",
    "even though theorem  [ theo : evaluation ] implies that schemas can be efficiently validated , the later claim only holds true when the tabular document can be fully loaded in memory and multiple passes can be made through the document .",
    "however , when the input data is large it is sometimes desirable to have a _ streaming validation algorithm _ that makes only a single pass over the input tabular document and uses only limited memory . in this section",
    "we identify several fragments of that admits such streaming validation algorithms .    * streaming model . *",
    "let us begin by defining when an algorithm validates in a streaming fashion .",
    "in this respect , we draw inspiration from the sax streaming api for xml : we can view a tokenized table @xmath53 as a sequence of events generated by visiting the cells of @xmath53 in table order . here",
    ", whenever we visit a new cell , an event @xmath153 is emitted , with @xmath154 the set of tokens in the visited cell . whenever we move to a new row , an event of type @xmath155  is emitted .",
    "note that the tokenized event stream can easily be generated `` on the fly '' when parsing a tabular document : we start reading the tabular document , one character at a time , until we reach a delimiter .",
    "all non - delimiter characters are used as input to , e.g. , a finite state automaton that allows us to check which tokens match the current cell s content . when we reach a delimiter ,",
    "a @xmath153 event is emitted with the corresponding set of matching tokens . if the delimiter is a row delimiter , then also a @xmath155  is emitted .",
    "we repeat this until the end of the file .",
    "consider the tabular document from figure  [ fig : climate ] together with the corresponding schema @xmath14 in figure  [ fig : climate - schema ] .",
    "the tokenized table of this document according to @xmath14 yields the event stream @xmath156    a tabular schema @xmath69 is said to be _ weakly streamable _",
    ", if there exists a turing machine @xmath157 that    can only read its input tape once , from left to right ;    for every tokenized table @xmath53 , when started with the event stream of @xmath53 on its input tape , accepts iff @xmath88 ; and    has an auxiliary work tape that can be used during processing , but it can not use more than @xmath158 of space on this work tape , where @xmath55 is the total number of cells in @xmath53 , and @xmath56 the number of columns .",
    "we say that @xmath69 is _ strongly streamable _ if the turing machine @xmath157 only requires @xmath159 space on its work tape .",
    "here , strong streamability corresponds to the commonly studied notions of streaming evaluation .",
    "we consider weak streamability to be very relevant as well because , based on the w3c use cases , tabular data often seems to be similar in spirit to relational tables and , in these cases , is very narrow and deep .",
    "in particular , @xmath160 in these cases .",
    "* weak streamability . * to enable streaming validation ,",
    "we restrict our attention to so - called _ forward _ coordinate and navigational expressions which are expressions where @xmath161 is not allowed , and we never look @xmath162 or @xmath163 .",
    "that is , a coordinate or navigational expression is _ forward _ if it is generated by the following syntax .",
    "@xmath164 \\mid ( \\alpha \\cdot \\beta ) \\mid ( \\alpha + \\beta )    \\mid ( \\alpha^*)\\end{aligned}\\ ] ] we do not consider the operator @xmath161 in the forward fragment because it can be seen as a backward operator : @xmath165 \\rangle$ ] is equivalent to @xmath166 .",
    "a schema is _ forward _ if it mentions only forward coordinate expressions .",
    "[ theo : weak - stream][theo : weak - stream ] forward is weakly streamable .",
    "consider a rule @xmath167 with @xmath3 a forward coordinate expression and @xmath4 a content expression .",
    "we will show that coordinate expressions @xmath3 can be evaluated in a streaming fashion by constructing a special kind of finite state automaton ( called _ coordinate automaton _ ) that allows us to decide , at each position in the event stream , if the currently visited cell is in @xmath168 . whenever we find that this is the case",
    ", we apply the current cell contents to @xmath4 ( which we also evaluate by means of a finite state automaton ) .",
    "now observe that @xmath169 iff ( 1 ) under the row based semantics , whenever we see @xmath170 , the automaton for @xmath4 is in a final state and ( 2 ) under the region - based semantics , when we reach the end of the event stream , the automaton for @xmath4 is in a final state .",
    "we then obtain weak streamability by showing that coordinate automata for @xmath3 can be simulated in space @xmath158 , whereas it is known that the finite state automaton for @xmath4 can be simulated in constant space .",
    "* strong streamability .",
    "* forward is not strongly streamable as no schema with a rule that contains subexpressions of the form @xmath171 ( which are prevalent in section  [ sec : examples ] ) can be strongly streamable .",
    "this can be seen using a simple argument from communication complexity .",
    "indeed , assume that the first row has @xmath8 cells , some of which have the token @xmath95 and some of which do not .",
    "if we want to evaluate @xmath171 in a streaming fashion , we need to identify the cells in the second row that are in the same columns as the @xmath95-tokens in the first row .",
    "but , this is precisely the equality of two @xmath8-bit strings problem , which requires @xmath172 bits in deterministic communication complexity ( example 1.21 in @xcite ) .",
    "these @xmath172 bits are what we need to store when going from the first to the second row .",
    "since @xmath8 can be @xmath173 , this amount of space is more than we allow for strongly streamable tabular schemas , and hence no schema containing @xmath171 is strongly streamable .    the underlying reason why @xmath171 is not strongly streamable is because , in general , the token @xmath95 can occur arbitrarily often",
    "however , in all such cases in section  [ sec : examples ] and in the w3c use cases , the occurrences of @xmath95 are very restricted .",
    "we could therefore obtain strong streamability for such expressions by adding constructs in the language that restrict how certain tokens can appear :    ` unique(a ) ` ` unique - per - row(a ) `    the former asserts that token @xmath95 should occur only once in the whole table and the latter that @xmath95 occurs at most once in each row .",
    "more formally , the former predicate holds in a table @xmath53 if @xmath174 contains at most one element and the latter holds in table @xmath53 if @xmath174 contains at most one element of the form @xmath175 for each row number @xmath176 .",
    "notice that a strong streaming algorithm can easily check whether these predicates hold .",
    "we use the above predicates to define two notions of _ guardedness _ for region selection expressions .",
    "guarded formulas will be strongly streamable .",
    "we say that token @xmath95 is _ row - guarded _ if unique - per - row(a ) appears in the schema .",
    "if unique(a ) appears in the schema it is , in addition , also _ guarded_. the two notions of guardedness capture the following intuition : if @xmath3 is row - guarded , then @xmath177 is strongly streamable and if it is guarded , then @xmath178 is strongly streamable .",
    "the main idea is that , in both cases , the number of cells we need to remember when going from one row to the next does not depend on the width of the table .",
    "we now define ( row)-guardedness inductively on the forward language :    @xmath179 and @xmath180 are guarded and row - guarded ;    @xmath181 is guarded and row - guarded for every @xmath3 that does not contain a navigational subexpression ;    if @xmath3 , @xmath182 , @xmath110 , @xmath183 are guarded ( resp . , row - guarded ) , then    @xmath184 , @xmath185 , @xmath186 , @xmath177 , @xmath187 ,    @xmath188 , @xmath189 , and @xmath190    are guarded ( resp . , row - guarded ) ;    if @xmath3 and @xmath191 are guarded then @xmath178 and @xmath192 are guarded ; and    if @xmath3 and @xmath191 are row - guarded then @xmath181 and @xmath193 are guarded .    a forward core - schema is _ guarded _ ,",
    "if all region selection expressions that use the @xmath194-operator are row - guarded and all region selection expressions that use @xmath195 are guarded .",
    "notice that guardedness of a schema can be tested in linear time .",
    "furthermore notice that every schemas in this paper becomes strongly streamable if we add the predicates unique(a ) for tokens @xmath95 that we use in expressions using @xmath196 , @xmath194 , or @xmath195 .",
    "[ thm : forward - guarded - strong - streaming ] [ thm : forward - guarded - strong - streaming ] guarded forward core - is strongly streamable .",
    "next , we describe a number of extensions to . these include alternative grouping semantics , types , complex content cells , and a concept for a transformation language .      the examples in section  [ sec : examples ] all use a row - based semantics of where the content expression is matched over every row in the selected region .",
    "that is , the cells in the selected region are ` grouped by ' the row they occur in .",
    "there are of course other ways to group cells , by column , for instance , or by not grouping them at all .",
    "the latter case is already defined in section  [ sec : formalmodel ] as _ region - based semantics_. in , we indicate rules using this semantics with a double arrow = > rather than a single arrow .",
    "notice the difference between the rules col(2 ) - > null | number and col(2 ) = > ( null | number)*. both require each cell in the second column to be empty or a number but express this differently .",
    "( the former way is closer to how one defines the schema of a table in sql , which is why we chose it as a default . )",
    "example  [ ex : pdb ] describes a more realistic application of = > -rules .",
    "this example corresponds to use case 12 in @xcite , is called _ `` chemical structures '' _ and aims to interpret protein data bank ( pdb ) files as tabular data .",
    "this particular use case is interesting because it illustrates that the view of w3c on tabular data is not restricted to traditional comma - separated values files .",
    "we note that theorems  [ theo : evaluation ] , [ theo : weak - stream ] , and [ thm : forward - guarded - strong - streaming ] still hold if schemas contain both rules under row - based and region - based semantics .",
    ".... header     extracellular matrix                     22-jan-98    1a3i title      x - ray crystallographic determination of a collagen - like title     2 peptide with the repeating sequence ( pro - pro - gly ) ...",
    "expdta     x - ray diffraction author     r.z.kramer,l.vitagliano,j.bella,r.berisio,l.mazzarella , author    2 b.brodsky,a.zagari,h.m.berman ... remark 350 biomolecule : 1 remark 350 apply the following to chains : a , b , c remark 350    biomt1    1   1.000000   0.000000   0.000000         0.00000 remark 350    biomt2    1   0.000000   1.000000   0.000000         0.00000 ...",
    "seqres    1 a     9   pro pro gly pro pro gly pro pro gly seqres    1 b     6   pro pro gly pro pro gly seqres    1 c     6   pro pro gly pro pro gly ... atom       1   n    pro a    1        8.316   21.206   21.530   1.00 17.44",
    "n atom       2   ca   pro a    1        7.608   20.729   20.336   1.00 17.44            c atom       3   c    pro a    1        8.487   20.707   19.092   1.00 17.44            c atom       4   o    pro a    1        9.466   21.457   19.005   1.00 17.44            o atom       5   cb   pro a    1        6.460   21.723   20.211   1.00 22.26            c ....    [ ex : pdb ] figure [ fig : pdb ] displays a slightly shortened version of the pdb file mentioned in use case 12 in @xcite .",
    "the corresponding schema could contain the following rules :    .... row(1 ) - > header , type , date , i d col(1 ) = > header , title * , dots , expdata , author * ,             dots , remark * , dots , seqres * , dots , atom *            ....    the last rule employs the region semantics and specifies the order in which tokens in the first column should appear .",
    "the pdb fragment in figure [ fig : pdb ] contains cells that have the same content but seem to have a different meaning .",
    "it can be convenient to differentiate between cells by using _",
    "token types _ as follows :    .... % % token types % % left : name of the token type % % right : region selection expression for token type remark - header < = down*[dots].down[remark ] remark - comment < = down*[dots].down[remark].down remark - rest < =     down*[dots].down[remark].down.(down[remark ] ) * ....    note that we abbreviated rules of the form @xmath197 by @xmath92 .",
    "we denoted the concatenation operator of navigational expressions by `` . '' . `",
    "remark - header ` is the topmost cell containing ` remark ` in figure [ fig : pdb ] , ` remark - comment ` is the one immediately below , and ` remark - rest ` is the rest .",
    "we can now use token types to write rules such as    .... row(remark - header ) - > ... row(remark - comment ) - > ...",
    "row(remark - rest ) - > ... ....    token types do not add additional expressiveness to the language since one can simply replace ` remark - header ` by ` down*[dots].down[remark](root ) ` in the rule .",
    "but the ability to use different names for fields with the same content may be useful for writing more readable schemas . in this case , the names suggest that the block of remarks is divided into a header , some comment , and the rest .      while it is beyond the scope of this document to develop a transformation language for tables",
    ", we argue that region selection expressions can be easily employed as basic building blocks for a transformation language aimed at transforming tables into a variety of formats like , for instance , rdf , json , or xml ( one of the scopes expressed in @xcite ) .",
    "region selection expressions are then used to identify relevant parts of a table .",
    "* basic transformations . *",
    "consider figure  [ fig : climate ] ( of example  [ ex : simple ] ) again , where we see that several columns have the value @xmath198 .",
    "since winter does not get this extreme in uganda , this value is simply a dummy which should not be considered when computing , e.g. , the average temperature in uganda in 1935 .",
    "instead , for the fragment of figure  [ fig : climate ] , it would be desirable to only select the columns that do not contain @xmath198 . to do this , we can simply define a new token and a new token type for the region of the table we are interested in .",
    ".... useless - temp = -99.00     % % token type   useful < = col(1 ) or            ( temperature and not useless - temp ) or            ( row(1 ) and not up*(useless - temp ) ) ....    the region defined by useful contains    ....         , entebbe air 1935.04 ,        27.83 1935.12 ,        25.72 1935.21 ,        26.44 [ ... ] ....    which could then be exported . using simple for - loops we can iterate over rows , columns , or cells , and compute aggregates .",
    "for example ,    .... useful - values < = ( temperature and not useless - temp )    for each column c in useful - values {    print average(c ) } ....    would output 25.65 , the average of the values below entebbe air in figure  [ fig : climate ] .",
    "the region defined by useful - values is a set of table cells , with coordinates .",
    "these coordinates can be used to handle information column - wise in the for - loop : it simply iterates over all column coordinates that are present in the region .",
    "iteration over rows or single cells would work analogously .",
    "* namespaces , annotations and rdf .",
    "* assume that we want to say that certain cells in figure  [ ex:1:csv ] are geographical regions .",
    "to this end , the schema could contain a definition of a default namespace :    ` namespace default = http://foo.org/nationalstats.csv `    ` namespace x = [ ... ] `    region selection expressions can then be used to specify which cells should be treated as objects in which namespace .",
    "for example , the code fragment    .... for each cell c in col(geoarea ) {    c.namespace = default } ....    could express that each cell below geoarea is an entity in namespace http://foo.org/nationalstats.csv .",
    "so , the cell containing england represents the entity     http://foo.org/nationalstats.csv:england ,    similar for the cell containing wales , etc . ( here we assume that .namespace is a predefined operation on cells . )    we can also annotate cells with meta - information ( as is currently being considered in section 2.2 of @xcite ) .",
    "the code fragment    .... for each cell c in col(geoarea ) {    annotate c with \" rdf : type dbpedia - owl : place \"    annotate c with \" owl : sameas fbase : \" + c.content } ....    ( assuming appropriate namespace definitions for rdf , owl , etc . )",
    "could express that each cell below geoarea should be annotated with rdf : type dbpedia - owl : place and , in addition , the england cell with owl : sameas fbase : england , the wales cell with owl : sameas fbase : wales , etc .",
    "we assume that annotate , with , and .content are reserved words or operators in the language .",
    "these ingredients also seem useful for exporting to rdf .",
    "we could write , e.g. ,    ` print @prefix : < http://foo.org/nationalstats.csv > `    .... for each cell c in col(geoarea ) {   print \" : \" + c.content+\"owl:sameas fbase:\"+c.content } ....    to produce an rdf file that says that : england in the default namespace is the same as fbase : england .",
    "looking at figure  [ ex:2:csv ] , one can also imagine constructs like    .... rdf < = col(subject ) or col(predicate ) or col(object )    for each row r in rdf {    print r.cells[1 ] + \" \" + r.cells[2 ] + \" \" + r.cells[3 ]    } ....    to facilitate the construction of rdf triples taking content from several cells .",
    "the csv on the web wg is considering allowing complex content ( such as lists ) in cells ( section 3.8 in @xcite ) . can be easily extended to reason about complex content .",
    "our formal definition of tabular documents already considers ( section  [ sec : formalmodel ] ) a finite set of delimiters , which goes beyond the two delimiters ( row- and column- ) that we used until now .    in a spirit similar to region - based semantics",
    ", one can also imagine a subcell - based semantics , for example , a rule of the form    .... col(1 ) . >",
    "( string ) * ....    could express that each cell in the first column contains a list of strings . notice the use of .",
    "> instead of - > to denote that we specify the contents of each individual cell in the region , instead of each row .",
    "the statement list delim = ; in the beginning of the schema could say that the semicolon is the delimiter for lists within a cell .",
    "we presented the schema language for tabular data on the web and showcased its flexibility and usability through a wide range of examples and use cases . while region selection expressions are at the very center of , we think they can be more broadly applied .",
    "region selection expressions can be used , for instance , as a cornerstone for annotation- and transformation languages for tabular data and thus for a principled approach for integrating such data into the semantic web .",
    "the whole approach of is strongly rooted in theoretical foundations and , at the same time , in well established technology such as xpath . for these reasons",
    ", we expect the language to be very robust and , at the same time , highly accessible for users .",
    "two prominent directions for future work are the following : ( 1 ) expand the usefulness of by further exploring the extensions in section  [ sec : extensions ] ; and , ( 2 ) study static analysis problems related to and region selector expressions leveraging on the diverse box of tools from formal language theory and logic .",
    "we thank marcelo arenas for bringing @xcite to our attention .    10    r.  w. adam  retter , david  underdown .",
    "csv schema 1.0 : a language for defining and validating csv data .",
    "http://digital - preservation.github.io / csv - schema / csv- + schema-1.0.html .",
    "n.  alechina and n.  immerman .",
    "reachability logic : an efficient fragment of transitive closure logic .",
    ", 8(3):325337 , 2000 .",
    "m.  arenas , s.  conca , and j.  prez . counting beyond a yottabyte , or",
    "how sparql 1.1 property paths will prevent adoption of the standard . in _",
    "international world wide web conference ( www ) _ , pages 629638 , 2012 .",
    "a.  berglund , s.  boag , d.  chamberlin , m.  f. fernndez , m.  kay , j.  robie , and j.  simon .",
    "ath language ( xpath ) 2.0 .",
    "technical report , world wide web consortium , january 2007 .",
    "w3c recommendation , http://www.w3.org / tr/2007/rec - xpath20 - 20070123/.    g.  j. bex , w.  gelade , f.  neven , and s.  vansummeren .",
    "learning deterministic regular expressions for the inference of schemas from xml data . in",
    "_ international world wide web conference ( www ) _ , pages 825834 , 2008 .",
    "g.  j. bex , w.  martens , f.  neven , and t.  schwentick .",
    "expressiveness of xsds : from practice to theory , there and back again . in _",
    "international world wide web conference ( www ) _ , pages 712721 , 2005 .",
    "r.  cleaveland and b.  steffen .",
    "a linear - time model - checking algorithm for the alternation - free modal mu - calculus .",
    ", 2(2):121147 , 1993 .",
    "s.  das , s.  sundara , and r.  cyganiak .",
    ": rdb to rdf mapping language .",
    "http://www.w3.org / tr / r2rml/. w3c recommendation 27 september 2012 .",
    "d.  fallside and p.  walmsley .",
    "chema part 0 : primer ( second edition ) .",
    "technical report , world wide web consortium , october 2004 .",
    "/ tr/2004/rec - xmlschema-0 - 20041028/.    m.  j. fischer and r.  e. ladner .",
    "propositional dynamic logic of regular programs .",
    ", 18(2):194211 , 1979 .",
    "j.  e.  f. friedl . .",
    "oreilly media , 3rd edition edition , 2006 .",
    "w.  gelade and f.  neven .",
    "succinctness of pattern - based schema languages for xml .",
    ", 77(3):505519 , 2011 .",
    ": dataset publishing language .",
    "https://developers.google.com / public - data/. last accessed 04/11/2014 .",
    "v.  kumar , p.  madhusudan , and m.  viswanathan .",
    "visibly pushdown automata for streaming xml . in _",
    "international world wide web conference ( www ) _ , pages 10531062 , 2007 .",
    "e.  kushilevitz and n.  nisan . .",
    "cambridge university press , 1997 .",
    "o.  k.  f. labs .",
    "tabular data package .",
    "/ tabular - data - package/. version 1.0-beta-2 .",
    "last accessed 04/11/2014 .",
    "l.  libkin , w.  martens , and d.  vrgoc .",
    "querying graph databases with xpath . in _ international conference on database theory ( icdt ) _ , pages 129140 , 2013 .",
    "k.  losemann and w.  martens .",
    "the complexity of evaluating path expressions in sparql . in _ international symposium on principles of database systems ( pods ) _ , pages 101112 , 2012 .",
    "w.  martens , f.  neven , m.  niewerth , and t.  schwentick . developing and analyzing xsds through bonxai . , 5(12):19941997 , 2012 .",
    "w.  martens , f.  neven , t.  schwentick , and g.  bex .",
    "expressiveness and complexity of xml schema .",
    ", 31(3):770813 , 2006 .    j.  prez , m.  arenas , and c.  gutierrez .",
    "semantics and complexity of sparql . , 34(3 ) , 2009 .",
    "r.  pollock and j.  tennison .",
    "metadata vocabulary for tabular data .",
    "technical report , world wide web consortium ( w3c ) , july 2014 .",
    "/ tr/2014/wd - tabular - metadata-20140710/.    e.  prudhommeaux , j.  e.  l. gayo , and h.  solbrig .",
    "shape expressions : an rdf validation and transformation language . in _ international conference on semantic systems _ , 2014 .",
    "a.  g. ryman , a.  l. hors , and s.  speicher .",
    "resource shape : a language for defining constraints on linked data . in _",
    "www workshop on linked data on the web _ , 2013 .",
    "l.  segoufin and c.  sirangelo .",
    "constant - memory validation of streaming xml documents against dtds . in _ international conference on database theory ( icdt ) _ ,",
    "pages 299313 , 2007 .",
    "l.  segoufin and v.  vianu . validating streaming xml documents . in _ international symposium on principles of database systems ( pods ) _ , pages 5364 , 2002 .",
    "j.  tandy , d.  ceolin , and e.  stephan . on the web : use cases and requirements .",
    "technical report , world wide web consortium ( w3c ) , october 2014 .",
    "http://w3c.github.io / csvw / use - cases - and - requirements/.    j.  tennison .",
    "2014 : the year of csv .",
    "last accessed 04/11/2014 .",
    "j.  tennison and g.  kellogg .",
    "model for tabular data and metadata on the web .",
    "technical report , world wide web consortium ( w3c ) , july 2014 .",
    "/ tr/2014/wd - tabular - data - model-20140710/.    m.  y. vardi . the complexity of relational query languages ( extended abstract ) . in _",
    "acm symposium on theory of computing ( stoc ) _ , pages 137146 , 1982 .",
    "w3c . on the web working group charter .",
    "[ lem : pdl ] for every coordinate expression @xmath3 , we can compute @xmath199 in time @xmath200 .",
    "for every set @xmath201 of coordinates in @xmath53 and every navigational expression @xmath92 , we can compute @xmath202 in time @xmath203 .",
    "as we have already mentioned , our region expressions are essentially a variant of propositional dynamic logic ( pdl ) , tweaked to navigate in tables .",
    "it is known that pdl has linear time combined complexity for global model checking @xcite .",
    "that is , given a pdl formula @xmath3 and a kripke structure ( essentially , a graph ) @xmath204 , one can decide in time @xmath205 whether @xmath206 .",
    "one can simply view our tables as kripke structures that are shaped like a grid .",
    "the result follows by a straightforward adaptation of the algorithm in @xcite .",
    "the crux behind theorem  [ theo : weak - stream ] is the following .",
    "consider a rule @xmath167 with @xmath3 a forward coordinate expression and @xmath4 a content expression .",
    "we will show that we are able to evaluate coordinate expressions @xmath3 in a streaming fashion by constructing a special kind of finite state automaton ( called _ coordinate automaton _ ) that allows us to decide , at each position in the event stream , if the currently visited cell is in @xmath168 .",
    "whenever we find that this is the case , we apply the current cell contents to @xmath4 ( which we also evaluate by means of a finite state automaton ) .",
    "now observe that @xmath207 iff    1 .   under the row based semantics ,",
    "the automaton for @xmath4 is in a final state whenever we see @xmath170 .",
    "2 .   under the region - based semantics ,",
    "when we reach the end of the event stream , the automaton for @xmath4 is in a final state .      let us first introduce the kinds of finite state automata that we will use to evaluate coordinate expressions .",
    "coordinate automaton _",
    "( ca for short ) @xmath30 over @xmath208 is a tuple @xmath209 where :    * @xmath210 is a finite set of states ; * @xmath211 is an initial state ; * @xmath212 is a set of _ final states _ ; * @xmath213 is a finite transition relation consisting of triples , each having one of the forms @xmath214 , @xmath215 ,    q')$ ] , @xmath216 , @xmath217 , @xmath218 , with @xmath3 a _ forward coordinate expression_.    a ca processes event streams of tokenized tables .",
    "it largely behaves like a normal non - deterministice finite state automaton , but has a number of special features .",
    "first , it is equipped with a register that stores the coordinate of the current cell being processed .",
    "second , in each step during execution , the automaton can either be in an _ active _ state , or in a _ suspended state_. only active states can fire new transitions ; suspended states remain dormant until they become active again .",
    "syntactically , a suspended state is simply a pair of the form @xmath219 with @xmath220 and @xmath221 , @xmath222 .",
    "the semantics of a suspended state @xmath223 is that the automaton keeps reading events from the input stream ( updating the coordinate register , but remaining in the suspended state ) until the next time that we visit a cell in column @xmath10 , when the state becomes active again .",
    "this way , the coordinate automaton can simulate moving downwards in the table .",
    "in particular , when following a transition of the form @xmath217 from state @xmath224 , the automaton records the column number of the current position ( say , @xmath10 ) ; moves to state @xmath225 ; but immediately suspends @xmath225 until the following cell in column @xmath10 is visited .",
    "third and finally , a ca can check whether the current cell is selected by a forward coordinate expression @xmath3 by means of a transition of the form @xmath215 , q')$ ] .",
    "the ca moves from @xmath224 to @xmath225 if the corresponding cell in the table is selected by @xmath3 .",
    "( note that the ca can hence use coordinate expressions as oracles . ) in contrast to standard automata , these transitions do not cause the ca to move to the next event , however . moving to the next event",
    "is done by either transitions of the form @xmath216 or @xmath226",
    ".    * note . *",
    "coordinate automata , as defined above , are very general and powerful . obviously , the fact that a coordinate automaton can use coordinate expressions as oracles makes them very powerful . indeed , as we will see below , they are almost trivially able to express the semantics of coordinate expressions . in order to obtain theorem  [ theo : weak - stream",
    "] , however , we will compile coordinate expressions into ca whose oracles are restricted .",
    "* semantics .",
    "* formally , a _ configuration _ of @xmath30 is a tuple @xmath227 where @xmath103 is a pointer to the current event being read from the input tape ; @xmath7 is a coordinate ; and @xmath228 is either an element of @xmath210 ( an active state ) , or a pair of the form @xmath229 with @xmath220 and @xmath230 , @xmath231 ( a suspended state ) .    let @xmath53 be a table and let @xmath232 be an event stream for @xmath53 , each @xmath233 being either @xmath153 with @xmath154 a set of tokens , or @xmath170 .",
    "let @xmath234 be a configuration , with @xmath235 and @xmath7 the coordinate of the cell visited in @xmath53 when @xmath233 is emitted .",
    "@xmath4 of @xmath30 on @xmath76 starting at @xmath236 is a sequence @xmath237 of configurations such that , for all @xmath238 with @xmath239 one of the following holds for @xmath240 and @xmath241 :    * transition from active state : @xmath242 1 .",
    "@xmath243 , @xmath244 , @xmath245 , and @xmath246 ( epsilon transition ) 2 .",
    "@xmath247 , \\varsigma_{j+1 } ) \\in \\delta$ ] , @xmath248 , @xmath244 , @xmath245 , and @xmath246 ( ordinary transition ) 3 .",
    "@xmath249 , @xmath250 , @xmath251 , @xmath245 , and @xmath252 ( move right transition ) 4 .",
    "@xmath253 , @xmath254 , @xmath255 , @xmath256 , and @xmath257 ( new row transition ) 5 .",
    "@xmath258 , @xmath244 , @xmath245 , @xmath246 , and @xmath259 , ( down transition ) * transition from suspended state : @xmath260 for some @xmath220 and @xmath221 with @xmath11 .",
    "1 .   @xmath261 , @xmath251 , @xmath245 , @xmath252 , and either ( a ) @xmath262 and @xmath263 ( suspended right transition ) or ( b ) @xmath264 and @xmath265 ( wake up ) .",
    "2 .   @xmath254 , @xmath266 , @xmath256 , @xmath257 , and either ( a ) @xmath267 and @xmath263 ( suspended new row transition ) or ( b ) @xmath268 and @xmath265 ( wake up ) .",
    "let @xmath53 be a tokenized table .",
    "a ca @xmath30 over @xmath208 is said to _ select _ coordinate @xmath269 , denoted @xmath270 , if , there exists a run @xmath4 of @xmath30 on the event stream for @xmath53 starting from configuration @xmath271 with @xmath272 the initial state of @xmath30 such that there is a configuration @xmath77 in @xmath4 with @xmath273 for some @xmath103 and @xmath228 such that @xmath274 .",
    "( in particular , @xmath228 is not suspended . )",
    "we write @xmath275 for the set of all coordinates selected by @xmath30 on @xmath53 .",
    "the following ca selects the same coordinates as region expression @xmath276    ( init ) at ( 0,0 ) [ state , initial ]  ; ( a ) at ( 2,0 ) [ state ]  ; ( final ) at ( 4,0 ) [ state , accepting ]  ;    ( init ) ",
    "node[above ] @xmath277`aruba`@xmath278 $ ] ( a ) ; ( a ) ",
    "node[above ] @xmath279 ( final ) ;    ( init ) edge[loop above ] node @xmath170 ( init ) ; ( init ) edge[loop below ] node @xmath280 $ ] ( init ) ; ( a ) edge[loop above ] node @xmath194 ( a ) ; ( final ) edge[loop above ] node @xmath279 ( final ) ;    @xmath6    note that , in the definition above , a ca always selects coordinates when started from the root coordinate ( 1,1 ) of the table ( i.e. , the beginning of the event stream ) . in what follows",
    ", it will be convenient for technical reasons to say that a @xmath281 @xmath30 selects coordinate @xmath7 in @xmath53 when started at coordinate @xmath130 .",
    "this is formally defined as follows .",
    "let @xmath232 be the event stream of @xmath53 .",
    "let @xmath233 with @xmath235 be the symbol in this stream that corresponds to the cell in @xmath53 with coordinate @xmath130.events do not corresponds to any cell , so @xmath233 is an event of the form @xmath153 .",
    "] then @xmath30 selects @xmath7 when started from @xmath130 in @xmath53 if there exists a run @xmath4 of @xmath30 on @xmath282 starting with configuration @xmath283 such that there is a configuration @xmath77 in @xmath4 with @xmath284 for some @xmath238 and some @xmath274 .",
    "( in particular , @xmath228 is not suspended . )",
    "we write @xmath285 for the set of all coordinates selected by @xmath30 on @xmath53 when started from coordinate @xmath77 .",
    "coordinate automaton @xmath30 _ expresses _ coordinate expression @xmath3 if @xmath286 , for every tokenized table @xmath53 .",
    "we say that @xmath3 is _ definable _ by means of a ca if there exists a ca that expresses @xmath3 .",
    "similarly , if @xmath92 is a navigational expression , then @xmath30 _ expresses _ @xmath92 if @xmath287 , for every tokenized table @xmath53 and every @xmath288 .",
    "it should be noted that the fact that a coordinate automaton can use coordinate expressions as oracles makes them very powerful .",
    "indeed , they are almost trivially able to express any coordinate or navigational expression . in order to obtain theorem  [ theo : weak - stream",
    "] , however , we will compile coordinate expressions into ca whose oracles are restricted . by restricted here we mean that the oracles are of a different _ level _ than coordinate or navigational expressions that are being expressed .",
    "the level intuitively corresponds to the maximum nesting level of coordinate and navigational expressions .",
    "the formal definition is as follows .",
    "@xmath289 @xmath290 ) & = 1 + \\operatorname{lvl}(\\varphi ) \\\\",
    "\\operatorname{lvl}(\\alpha \\cdot \\beta ) & = \\max(\\operatorname{lvl}(\\alpha ) , \\operatorname{lvl}(\\beta ) ) \\\\",
    "\\operatorname{lvl}(\\alpha + \\beta ) & = \\max(\\operatorname{lvl}(\\alpha ) , \\operatorname{lvl}(\\beta ) ) \\\\",
    "\\operatorname{lvl}(\\alpha^ * ) & = \\operatorname{lvl}(\\alpha ) \\\\   \\end{aligned}\\ ] ]    to illustrate , @xmath291 , @xmath292 \\cdot { \\textsf{right}\\xspace } ) = 1 $ ] , and @xmath293 .",
    "define the _ level _ of a ca to be the maximum level of any coordinate expression occurring in it .",
    "we now establish a number of technical lemmas that relate ca to coordinate and navigational expressions .",
    "[ lem : ca - vs - navexpr ] every forward navigational expression @xmath92 is definable by means of a ca of level @xmath294 .",
    "we construct , by induction on @xmath92 , a ca @xmath30 that expresses @xmath92 and is of level at most @xmath295 .",
    "the construction is essentially the same as the thompson construction for transforming regular expressions into finite state automata .    * if @xmath296 , then @xmath30 is the ca with one state , which is both initial and final , and which does not have any transitions . * if @xmath297 , then @xmath30 is the ca with states @xmath224 and @xmath225 , where @xmath224 is initial and",
    "@xmath225 is final , with the single transition @xmath217 . *",
    "if @xmath298 , then @xmath30 is the ca with states @xmath224 and @xmath225 , where @xmath224 is initial and @xmath225 is final , with the single transition @xmath216 . * if @xmath299 $ ] , then @xmath30 is the ca with states @xmath224 and @xmath225 where @xmath224 is initial and @xmath225 is final , with the single transition @xmath215 , q')$ ] . * if @xmath300 , then let @xmath301 be the ca constructed by induction for @xmath302 , and @xmath303 the ca constructed by induction for @xmath304 . take @xmath305 , the ca obtained by the usual concatenation construction on @xmath301 with @xmath303 .",
    "( that is , we take the disjoint union of @xmath301 and @xmath303 , renaming states where necessary , and link the final states of @xmath301 to the initial state of @xmath303 by means of an @xmath306-transition .",
    "the initial state is the initial state of @xmath301 ; the final states are the final states of @xmath303 . ) * if @xmath307 , then let @xmath301 be the automaton constructed by induction for @xmath302 and @xmath303 the automaton constructed for @xmath304 .",
    "then take @xmath30 to @xmath308 , the automaton obtained by performing the usual union construction on automata .",
    "( take their disjoin union , renaming states where necessary , add a new initial state and add epsilon transition from this state to the initial states of @xmath309 and @xmath310 , respectively .",
    "the final states consists of the final states of @xmath309 and @xmath310 . )",
    "* if @xmath311 , then let @xmath312 be the automaton created for @xmath93 .",
    "let @xmath30 be the automaton we obtain by adding an @xmath306-loop from the final states of @xmath312 to its initial state .    in all cases , it is now routine to check that @xmath30 defines @xmath92 and that @xmath313 .",
    "[ lem : ca - vs - cexpr - alpha - phi ] every forward coordinate expression of the form @xmath110 is definable by means of a ca of level at most @xmath314 .",
    "observe that @xmath110 is equivalent to @xmath315 where @xmath93 is @xmath316 \\cdot \\alpha$ ] . by lemma  [ lem : ca - vs - navexpr ]",
    ", there exist a ca @xmath30 defining @xmath93 of level @xmath317 . now observe that , since @xmath318 , it immediately follows that @xmath30 defines @xmath110 .",
    "( recall that a ca expresses a ca if it gives the same result when evaluation starts from root coordinate ( 1,1 ) . )",
    "[ lem : ca - vs - cexpr ] every forward coordinate expression is definable by a ca of the same level .",
    "note that every forward coordinate expression @xmath3 is equivalent to @xmath315 where @xmath319)$ ] . by lemma  [ lem : ca - vs - navexpr ]",
    ", there exists a ca @xmath30 defining @xmath93 of level @xmath320 .",
    "now observe that , since @xmath321 , it immediately follows that @xmath30 defines @xmath3 .",
    "( recall that a ca expresses a ca if it gives the same result when evaluation starts from root coordinate ( 1,1 ) . )    * convention . * in what follows , by turing machine",
    "we understand a turing machine with a read - only input tape , a read - write work tape , and a write - only output tape where the cursor on the input tape can only advance to the right ( never go left ) .",
    "we say that turing machine @xmath157 _ implements _ ca @xmath30 if , for every tokenized table @xmath53 of dimension @xmath52 and event stream @xmath322 of @xmath53 it is the case that @xmath157 outputs on its output tape the coordinates of the cells selected by @xmath30 on @xmath70 .    [",
    "prop : ca - tm - logspace ] for every ca @xmath30 there exists a turing machine @xmath157 that implements @xmath30 and that uses at most @xmath323 space on its work tape , where @xmath56 is the number of columns and @xmath55 is the number of rows in the input table event stream .",
    "let @xmath324 .",
    "let @xmath325 be the set of all oracles used in transitions of @xmath30 , i.e. , @xmath326 , q ' ) \\in \\delta , q , q'\\in q\\}$ ] .",
    "we construct @xmath157 by induction on the level @xmath327 of @xmath30",
    ".    * base case . *",
    "if the level @xmath327 of @xmath30 is @xmath328 , then @xmath157 operates as follows .",
    "it processes the event stream on its input tape from left to right , one event at a time , starting at the first event . during the processing it maintains on its work tape a tuple @xmath329 , where @xmath7 is the coordinate corresponding to the current event being processed",
    ", @xmath330 is the set of all active states that @xmath30 can be in any run of @xmath30 after having processed the events so far , @xmath331 is the set of all suspended states that @xmath30 can be in in any run after having processed the events so far , and @xmath332 is the set of all oracles in @xmath325 that select the current coordinate @xmath7 . as such",
    ", @xmath157 simulates all possible runs of @xmath30 on the input , similarly to how one normally simulates a non - deterministic finite state automaton by tracking all possible runs at once .",
    "in particular , @xmath157 starts with the tuple @xmath333 on its work tape before processing any event . when processing the next event , @xmath157 checks whether this is of the form @xmath153 or @xmath170 . if it is of the form @xmath153 then it :    increments @xmath10 ;    computes @xmath332 for the new coordinate @xmath7 .",
    "note that this can be done using only the information in @xmath154 ( the tokens of the current event ) and the coordinate @xmath7 . indeed",
    ": since all oracles @xmath334 are forward and level 0 , they can not contain subexpressions of the form @xmath161 or @xmath191 .",
    "therefore , each such @xmath3 is a boolean combinations of literals , where each literal is either ( 1 ) a token @xmath95 , ( 2 ) the constant @xmath180 , or ( 3 ) the root coordinate @xmath335 . checking ( 2 )",
    "is trivial , whereas checking ( 1 ) amounts to checking whether @xmath336 and ( 3 ) amounts to comparing the coordinate @xmath7 with ( 1,1 ) .",
    "it replaces @xmath330 by @xmath337 .",
    "it then adds to @xmath330 all states @xmath338 that can be reached from a state in this new @xmath330 by traversing only @xmath306-transitions or @xmath339$]-transitions , with @xmath340 .",
    "finally , it updates @xmath331 to @xmath341    if the current event is @xmath170 then it :    increments @xmath8 and resets @xmath10 to @xmath342 ;    moves to the next event on the input tape , which must be of the form @xmath153 ;    computes @xmath332 for the new coordinate @xmath7 .",
    "replaces @xmath330 by @xmath343 .",
    "it then adds to @xmath330 all states @xmath338 that can be reached from a state in this new @xmath330 by traversing only @xmath306-transitions or @xmath339$]-transitions , with @xmath340 .",
    "finally , it updates @xmath331 to @xmath341    after updating @xmath344 , @xmath157 checks if @xmath345 .",
    "if so , it outputs @xmath7 .",
    "observe that the space required by @xmath157 is :    * @xmath346 bits to store the coordinate @xmath7 ; * at most @xmath347 bits for storing @xmath330 ; * at most @xmath348 bits for storing @xmath331 ; * at most @xmath349 bits for storing @xmath332    hence , since @xmath347 and @xmath349 are constant , @xmath157 runs in space @xmath323 , as desired .",
    "* induction step . *",
    "if the level @xmath327 of @xmath30 is @xmath350 , then let @xmath351 be the set of all coordinate expressions of the form @xmath110 that occur as a subexpression of some oracle in @xmath325 . by definition ,",
    "each of these @xmath110 is of level at most @xmath327 . by lemma  [ lem :",
    "ca - vs - cexpr - alpha - phi ] , there hence exists for each such @xmath110 a ca @xmath352 of level at most @xmath353 that expresses it . by induction hypothesis",
    ", there hence exists , for each @xmath354 , a turing machine @xmath355 that implements @xmath110 in space @xmath356 .",
    "we then construct the turing machine @xmath157 for @xmath30 as follows .",
    "for ease of exposition , @xmath157 will have multiple ( but a fixed number of ) work tapes . since each of these will use only @xmath323 cells ,",
    "it is standard to transform @xmath157 in a single - tape turing machine that runs in space @xmath323 .",
    "in particular , @xmath157 has a @xmath357 work tapes : a principal work tape and an auxiliary work tape for each @xmath354 . during processing",
    ", @xmath157 simulates @xmath30 on its principal work tape , and , in parallel , the turing machine for @xmath355 on the auxiliary tape for @xmath110 . during the simulation of @xmath355",
    "we take care to never construct any output , but merely checks whether the current cell on the input tape should be output according to @xmath355 .",
    "the simulation of @xmath30 on its principal work tape happens in the exact same way as for the case where @xmath358 .",
    "that is , we maintains a tuple @xmath359 for @xmath30 that simulates all possible runs of @xmath30 .",
    "the only difference is that when we update this tuple in response to reading a new event from the input , we first update all the auxiliary work tapes , and then compute the set @xmath360 of all of @xmath30 s oracles that select the current cell @xmath7 as follows .    since each @xmath361 is forward , each @xmath182 is a boolean combination of _ literals _ , where each literal is either ( 1 ) @xmath95 with @xmath362 ; ( 2 ) @xmath180 ; ( 3 ) @xmath335 ; or ( 4 ) @xmath110 . cases ( 1)(3 ) can be checked as before .",
    "we can check whether current coordinate @xmath7 is selected by @xmath110 simply by looking at the simulation of @xmath355 on the work tape for @xmath110 and verify whether @xmath355 would output the current coordinate . as such",
    ", we can easily compute at any given instant whether the current coordinate is selected by @xmath182 .",
    "as before , after the update of @xmath363 , @xmath157 checks whether @xmath364 and , if so , writes @xmath7 on its output tape .    now note that , as before , @xmath157 uses @xmath323 space on its principal work tape , and ( by induction hypothesis ) @xmath365 on each of its auxiliary work tapes .",
    "it hence uses @xmath366 space in total , as desired .    from this , we derive theorem  [ theo : weak - stream ] as follows .",
    "let @xmath69 be a tabular schema , i.e. a set of rules of the form @xmath367 with @xmath3 a coordinate expression and @xmath368 a content expression .    by lemma  [ lem : ca - vs - cexpr ]",
    "every forward coordinate expression can be expressed by means of a ca which , by proposition  [ prop : ca - tm - logspace ] , can be evaluated by a turing machine in space @xmath323 , where @xmath56 is the number of columns in the input , and @xmath55 the number of rows .    from this , we construct a turing machine @xmath157 that validates its input event stream w.r.t .  @xmath69 as follows .",
    "@xmath157 has a fixed number of work tapes .",
    "in particular , for each coordinate expression @xmath3 serving as the left - hand side of a rule in @xmath69 , @xmath157 has one tape on which it simulates the turing machine that evaluates @xmath3 . here",
    ", @xmath157 prevents any output that may be generated by the turing machine for @xmath3 ; but records when this machine would be doing so .",
    "all of these left - hand - sides are simulated in parallel upon reading the event stream .",
    "in addition , for each right - hand side @xmath77 , @xmath157 has an auxiliary tape on which it simulates a finite state automaton for @xmath77 . for each rule @xmath369 , and in each position in the event stream of the form @xmath153 ,",
    "whenever it finds that @xmath3 would select the current cell , @xmath157 simulates reading @xmath154 in the nfa for @xmath77 : it proceeds from the current state set for @xmath77 according to all @xmath370 .    under the row - based semantics , whenever we encounter a @xmath170",
    ", each @xmath77 must be in a finite state , otherwise the input is invalid w.r.t .",
    "whenever we see @xmath170 , we move each of the nfas for @xmath77 back to their initial state .    under the region - base semantics ,",
    "each @xmath77 has to be in a final state at the end of the input ( and we never need to move @xmath77 back to its initial state upon @xmath170 ) .",
    "theorem  [ thm : forward - guarded - strong - streaming ] . _ guarded forward core - schemas are strongly streamable . _    we can use the algorithm of theorem  [ theo : weak - stream ] for weak streamability with the additional observation that , for guarded schemas , the columns that need to be remembered when going from one row to the next are independent of the width of the table @xmath53 .",
    "more precisely , when going from one row to the next , we can store for each subexpression @xmath3 of a region selection expression a set of pairs @xmath371 of the form @xmath372 where @xmath77 is a column number and @xmath373 .",
    "the semantics is that , on the next row @xmath176 , we need to continue the evaluation of this subexpression in the cells @xmath374 and @xmath375 .",
    "the size of each such set @xmath371 can be bounded by @xmath376 , which is formalized in lemma  [ lem : strong - streaming - columns ] .",
    "a.   if a coordinate expression @xmath3 is row - guarded then , for each table @xmath53 and row coordinate @xmath176 , the set @xmath377 consists of @xmath376 cells plus , optionally , a right - open interval on @xmath176 .",
    "b.   if a coordinate expression @xmath3 is guarded then , for each table @xmath53 and row coordinate @xmath176 , the set @xmath381 consists of @xmath376 cells plus , optionally , a right - open interval on @xmath176 .      for a coordinate expression @xmath3 and a row @xmath176 ,",
    "we denote by @xmath382 the number of coordinates of @xmath383 in row @xmath176 , that is , the number of elements in @xmath384 if it is finite , and @xmath385 otherwise .",
    "\\(a ) we prove this case by induction on the definition of guardedness in forward coordinate expressions .",
    "the induction base cases for coordinate expressions @xmath3 are @xmath386 , @xmath387 , @xmath388 , and @xmath389 .    in the first case ,",
    "if @xmath386 is row - guarded then it only appears at most once per row by definition of the predicate unique - per - row .",
    "therefore , for each row @xmath176 , @xmath390 and ( a ) is fulfilled .",
    "fourth , when @xmath394 , we have that @xmath182 is a boolean combination of @xmath179 , @xmath180 , and tokens . therefore , it can be decided whether a cell @xmath77 is in @xmath395 by looking at the predicates of @xmath77 and by testing whether it is cell @xmath22 or not .",
    "such tests can be made by inspecting @xmath77 alone . for each row @xmath176 , we either have that @xmath396 is empty or not . if it is empty , then @xmath397 is also empty and ( a ) follows .",
    "if it is non - empty , then @xmath398 , where @xmath103 is minimal such that @xmath399 .",
    "since this is a right - open interval , ( a ) follows .      in the first case , for each row @xmath176 , we have that @xmath408 . here",
    "( a ) follows immediately from the inductive hypothesis and the observation that the union of two right - open intervals is again a right - open interval .          in the last case we have @xmath414 and we already know that @xmath191 and @xmath415 are row - guarded . here , we again have that @xmath416 . here , ( a ) follows by induction in a similar way as the first inductive case . however , we need to take a little bit more care about the finite part of @xmath397 .",
    "assume that @xmath417 ( if not , the roles of @xmath92 and @xmath93 can be interchanged in the following ) .",
    "then , the finite part of @xmath397 consists of @xmath418 cells , which is at most @xmath419 cells and which , in turn , is bounded from above by @xmath420 cells , which also proves ( a ) in this case .",
    "\\(b ) we again proceed by induction on the definition of guardedness in forward coordinate expressions . the induction base cases for coordinate expressions @xmath3 are @xmath386 , @xmath387 , @xmath388 , and @xmath389 .",
    "in the first case , if @xmath386 is guarded then it only appears at most once in the table by definition of the predicate unique .",
    "if @xmath383 is empty , then @xmath178 is empty in which case ( b ) is fulfilled . if not , we have that @xmath421 for some @xmath103 and @xmath238 . here",
    ", we have that @xmath422 , which fulfils the conditions of case ( b ) .        in the fourth case , if @xmath425 we can decide for each individual cell @xmath77 whether @xmath426 by only inspecting @xmath77 , analogously as in ( a ) .",
    "also analogously , for each row @xmath176 , we either have that @xmath397 is empty or a right - open interval of the form @xmath398 , where @xmath103 is minimal such that @xmath399 .",
    "therefore , @xmath427 is also empty or a right - open interval on each row @xmath176 .      in the first case",
    ", we have that @xmath431 and @xmath432 are guarded by induction , so they fulfil condition ( b ) .",
    "furthermore , we have that @xmath433 .",
    "this means that , for each row @xmath176 , we also have that @xmath434 . here",
    "( b ) follows immediately from the inductive hypothesis and the observation that the union of two right - open intervals is again a right - open interval .",
    "cases four to eight are similar to case three . in case eight ,",
    "where @xmath414 , we can bound the number of cells per row of @xmath435 that are not in the right - open interval in exactly the same way as for the analogous case in ( a ) .",
    "finally , in the last case , we have @xmath437 , where @xmath191 is row - guarded . due to the row - guardedness of @xmath191 , we know by ( a ) that @xmath438 for each row @xmath176 consists of @xmath376 cells in @xmath176 plus , optionally , a right - open interval on @xmath176 . therefore , @xmath439 on a row @xmath176",
    "is either empty , or a right - open interval . from this",
    ", we immediately have that also @xmath440 , on each row @xmath176 , is either empty or a right - open interval .",
    "this concludes the proof of lemma  [ lem : strong - streaming - columns ] ( b ) ."
  ],
  "abstract_text": [
    "<S> inspired by the recent working effort towards a recommendation by the world wide web consortium ( w3c ) for tabular data and metadata on the web , we present in this paper a concept for a schema language for tabular web data called . </S>",
    "<S> the language consists of rules constraining and defining the structure of regions in the table . </S>",
    "<S> these regions are defined through the novel formalism of region selection expressions . </S>",
    "<S> we present a formal model for and obtain a linear time combined complexity evaluation algorithm . </S>",
    "<S> in addition , we consider weak and strong streaming evaluation for and present a fragment for each of these streaming variants . finally , we discuss several extensions of including alternative semantics , types , complex content , and explore region selection expressions as a basis for a transformation language . </S>"
  ]
}