{
  "article_text": [
    "a major thread of current research is work directed at understanding the origin of galaxies .",
    "there are excellent prospects of achieving this goal by combining endeavours in three distinct areas : observations of galaxy formation taking place at high redshift , numerical simulations of the gravitational aggregation of dark matter and baryons , and studies of the milky way .",
    "the latter field is dominated by a series of major observational programs that started fifteen years ago with esa s hipparcos mission , which returned parallaxes and proper motions for @xmath0 stars @xcite .",
    "hipparcos established a more secure astrometric reference frame , and the ucac-3 catalogue @xcite uses this frame to give proper motions for several million stars .",
    "these enhancements of our astrometric database have been matched by the release of major photometric catalogues denis @xcite , 2mass @xcite , sdss @xcite , segue @xcite , and the accumulation of enormous numbers of stellar spectra , starting with the geneva  copenhagen survey ( * ? ? ?",
    "* ; * ? ? ?",
    "* hereafter gcs ) and continuing with the sdss , segue and rave @xcite surveys .",
    "major programs to obtain low - dispersion stellar spectra are currently underway  on completion the segue and rave surveys will each provide @xmath1 spectra .",
    "these spectra yield good line - of - sight velocities and estimates of @xmath2 errors of @xmath3 and a coarse estimate of @xmath4 .",
    "three surveys ( apogee , eso - gaia and hermes ) are currently being being prepared that will obtain large numbers of spectra with resolutions in the range @xmath5 from which abundances of significant numbers of elements can be determined .",
    "several important photometric surveys are currently under way , including the panstarrs survey @xcite which is obtaining @xmath6 photometry through a large part of the sky , and surveys of the bulge region and the galactic plane in the near - ir with the vista telescope .",
    "the era of great galactic surveys will culminate in esa s gaia mission , which is scheduled for launch in early 2013 and aims to return photometric and astrometric data for @xmath7 stars and low - dispersion spectra for @xmath8 stars .",
    "the galaxy is an inherently complex object , and the task of interpreting observations is made yet more difficult by our location within it .",
    "consequently , the ambitious goals that the community has set itself , of mapping the galaxy s dark - matter content and unravelling how the galaxy was assembled , can probably only be attained by mapping observational data onto sophisticated models .",
    "this paper is the first in a series in which we use a new method of analysing dynamical models to interpret data from surveys of different types .",
    "here we introduce and test the basic principles using mock survey catalogues of the region @xmath9 that contain data of gaia - like quality that progresses in completeness from photometry plus proper motions , through photometry , proper motions , parallaxes and line - of - sight velocities . in subsequent papers",
    "we will extend the formalism to include spectrophotometric data and apply it to real catalogues .",
    "the paper is organised as follows .",
    "section [ sec : why ] explains the fundamental importance of equilibrium dynamical models for the problem in hand .",
    "section [ sec : type ] discusses the feasibility of using n - body models to interpret surveys of the milky way and outlines our preferred strategy .",
    "section [ sec : strategy ] presents the formulae used to calculate the likelihood of a catalogue given a model , while in section [ sec : optimise ] we explain how we find the optimum values of the model s parameters and their statistical uncertainties .",
    "section [ sec : test ] describes how we construct a pseudo - catalogue from a model and a number of tests of our method that we have run using a gaia - like pseudo - catalogue .",
    "section [ sec : discuss ] outlines a number of directions for further work and future developments of our methodology .",
    "section [ sec : conclude ] sums up .",
    "models of the galaxy have a key role to play for several reasons .",
    "first they enable one to understand and compensate for observational biases , which dominate all data sets on account of our location in the galaxy s dust- and gas - rich disc .",
    "second they provide the natural means of tying together data from different surveys  surveys may concentrate on obtaining photometric , astrometric or spectral data and different surveys probe magnitude ranges and therefore constrain the galaxy over complementary distance ranges . a model can assemble this complementary information into a single coherent picture .",
    "in the 1980s bahcall and his collaborators moved galactic astronomy an important step forward by introducing models of the stellar content of the milky way that were inspired by observations of external galaxies ( * ? ? ?",
    "* ; * ? ? ?",
    "* and references therein ) .",
    "although these models included the kinematics of stars , velocities were not required to be consistent with newton s laws of motion . in the besanon model @xcite , newton",
    "s laws are used to connect the vertical structure of the disc to the distribution of vertical velocities , @xmath10 , but the large - scale structure of the besanon model of the galaxy is not constrained by newton s laws .",
    "the most recent incarnation of this type of model is presented by @xcite .",
    "fully dynamical models , that is models in which the distribution of stars is consistent with newton s laws of motion , are now required for several reasons .",
    "most obviously , the distribution of dark matter can be deduced from observations of stars and gas only by assuming that the galaxy is in an approximate steady state , and interpreting observations in the framework of an _ equilibrium _ dynamical model  if we do not assume a steady state ( which strictly speaking must be a false assumption ) , any mass distribution is consistent with any phase - space distribution of the baryonic matter .",
    "inferences about the mass content can only be drawn because a sufficiently large central concentration of mass would imply a rapid collapse of the baryonic component from its observed configuration , and a sufficiently small mass concentration would imply that the baryonic component would fly apart .",
    "we must deduce the actual mass distribution by assuming that the baryonic component is in an approximate steady state , thus ruling out large - scale contraction or expansion .",
    "hence equilibrium dynamical models are fundamental for achieving a major goal of contemporary astronomy .",
    "an attractive feature of equilibrium dynamical models is that they reduce the galaxy from a six - dimensional to a three - dimensional object : without the assumption of dynamical equilibrium , we have to specify the distribution of stars in six - dimensional phase space , while the assumption of equilibrium together with jeans theorem makes it sufficient to specify the distribution of stars in three - dimensional space of isolating integrals . for obvious reasons , objects can be imagined in three dimensions much more easily than they can be imagined in four or higher dimensions , so the reduction in dimensionality from six to three is a major simplification .",
    "this reduction also vastly reduces the amount of information required to specify a model : if we measure each position and velocity with a precision of , say , 1 percent , a six - dimensional model with less than @xmath11 resolution elements will degrade the resolution of the raw data , while a three - dimensional model requires only @xmath12 resolution elements for a faithful representation of the data .",
    "a dynamical model connects objects that we can observe to objects that we have not observed , either because they are distant and therefore faint , or because they are obscured by dust .",
    "for example @xcite showed that if the stellar halo were in virial equilibrium , more than half the stars of the stellar halo would be on orbits that bring them through the solar neighbourhood , so in principle from measurements made in a small volume around the sun we could determine the density of stars on more than half the halo s populated orbits .",
    "the galaxy is certainly not in a steady state .",
    "most obviously because it has a bar inside @xmath13 and spiral arms in the surrounding disc .",
    "these features not only rotate with various pattern speeds , but on longer timescales change their structure and may well decay .",
    "moreover , by scattering stars and dark - matter particles they drive secular evolution of all the galaxy s components .",
    "the resulting secular evolution of the disc has been studied for half a century ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) and has clearly played a major role in determining the observed state of the galaxy .",
    "secular evolution is most readily modelled by adding perturbations to the hamiltonian of an equilibrium model , that cause the model to move through a series of equilibrium states .",
    "hence equilibrium models are the key to modelling secular evolution as well as to determining the distribution of dark matter .",
    "data from the sdss survey revealed that a significant proportion of the stellar halo has yet to phase mix properly , and that it contains numerous tidal streams @xcite .",
    "these streams have considerable potential for mapping the galaxy s gravitational field and distribution of dark matter .",
    "galaxy models of the type we advocate in this paper would seem to offer the best hope of fully exploiting the potential of tidal streams @xcite .",
    "the complexity of the galaxy is such that we can not realistically hope eventually to build a dynamical model that accounts for _ every _ observation in detail .",
    "for example , it is known that stellar discs are highly responsive objects , and much of the galaxy s current spiral structure will represent an ephemeral response to noise driven by star formation and fluctuations in the density of the dark - matter halo .",
    "the galaxy s warp is likely to be driven by such density fluctuations . in these circumstances",
    "we should aim for a sequence of dynamical models of increasing complexity and realism .",
    "we aim first for an axisymmetric , equilibrium model and identify the most prominent features in the data that can not be explained by such a model",
    ". then we aim for a steady - state barred model and see how much more of the data such a model can explain .",
    "next we include either the warp or spiral structure by perturbing our best barred model , and see how much better we can fit the data . by proceeding in this way we can hope to reach the point at which we feel we have a model that provides as good a fit to the data as it is reasonable to expect , and we will have learnt along the way a great deal about the galaxy s contents and manner of operation . in this paper",
    "we are concerned with the first stage in this journey , the construction of axisymmetric models .",
    "the simplest galaxy models to construct are n - body models .",
    "the initial conditions from which an n - body model is integrated are generally not consistent with an equilibrium model because such initial conditions can only be chosen if one is already in possession of the desired model .",
    "therefore the equations of motion must be integrated for some time to allow the model to settle to an equilibrium through relaxation .",
    "this period of relaxation has two unfortunate consequences .",
    "first , equilibrium is reached only asymptotically in time , and in the case of a disc galaxy significant relaxation may continue for an inconveniently long time .",
    "second , it is not clear what initial conditions are required to achieve a given configuration .",
    "recently the `` made - to - measure '' ( m2 m ) technique introduced by @xcite has been sharpened by @xcite , @xcite and others into an effective way to refashion a model that somewhat resembles the target galaxy into a model that represents that galaxy to good accuracy . consequently the dynamical models that currently best approximate the galaxy are m2 m models @xcite .    while m2 m models can be extremely useful , they are less than ideal from a number of perspectives .",
    "first , an m2 m model is specified by @xmath14 phase - space coordinates and particle weights , where @xmath15 is a large number .",
    "this specification is at once cumbersome and non - unique ; at a later time the coordinates will be different while the model will be the same .",
    "an equally good model of the same galaxy made by a different group will use a different mix of orbits so the weights will be different and it will not be evident that the two models are equivalent .",
    "second , when the model s phase space has significant stochastic regions , it is not possible to halt dynamical evolution of the model during the period that orbits are followed in order to optimise their weights .",
    "finally , there is a fundamental problem with any particle - based model of the galaxy that was pointed out by @xcite : important information about the galaxy is contained in observations of low - luminosity stars that can only be observed close to the sun , so such stars must be represented in any complete galaxy model . however , orbiting particles that are at one moment near the sun are some time later far from the sun . if particles are treated as stars , those that represent low - luminosity stars will rarely contribute to observables because the particle will usually to be too far from the sun to be visible .",
    "consequently , the number of particles contributing to observables will be much smaller than the number of particles in the model .",
    "one might hope to circumvent this problem by considering particles to be representatives of a stellar population that has a well defined luminosity function .",
    "then when a particle is far from the sun , one could be sure to draw a representative star luminous enough to be visible from the sun .",
    "but then for consistency _ many _ stars must be drawn from the particle when it is near the sun .",
    "clearly the model s shot noise will be adversely affected if each nearby particle contributes to the observables a host of stars with exactly the same phase - space coordinates , just as it will be if the number of stars is much less than the number of particles .    to escape from this sampling problem we need to be able to sample the solar neighbourhood much more densely than far - flung parts of the galaxy .",
    "that is , our model must yield the probability density of particles rather than a specific realisation of this density  we need to know the phase - space density @xmath16 of stars , for armed with @xmath16 we can populate the solar neighbourhood with large numbers of mostly low - luminosity stars and remote parts of the galaxy with smaller numbers of exclusively luminous stars .    in principle",
    "it _ is _ possible to determine the phase - space density @xmath16 from an n - body model because liouville s theorem assures us that phase - space density is constant along orbits , so the phase - space density is known at the location of every particle provided the initial conditions sampled a well defined sampling density @xmath17 ( e.g.   4.7.1 of * ? ? ?",
    "hence the phase - space density at any point in the phase space of the final model can be estimated by six - dimensional interpolation .",
    "sampling the phase - space density obtained in this way is not easy , but is achievable with the metropolis algorithm for example ( e.g. * ? ? ?",
    "* ) . however , these steps are highly non - trivial and to the best of our knowledge no n - body model has been successfully resampled .",
    "the problem of determining the distribution function ( ) @xmath16 is made more challenging by the fact that we need not one  but a   @xmath18 for each stellar population @xmath19 : as a minimum the model must predict the spatial distribution and kinematics of stars that lie in each of several regions of the @xmath20 plane ( e.g. * ? ? ?",
    "it would not be straightforward to adapt an n - body model so that it yielded several s simultaneously , although ab initio models of galaxy formation can assign stellar parameters to particles ( e.g. * ? ? ? * and references therein ) .      the modelling technique introduced by @xcite",
    "has become the standard tool for analysing the dynamics of early - type galaxies ( e.g * ? ? ?",
    "* ) , especially in connection with searches for central black holes ( e.g. * ? ? ?",
    "this technique involves first integrating a number of orbits in the adopted gravitational potential and then seeking weights for these orbits such that the weighted sum of the orbits reproduces the observational data to acceptable precision .",
    "torus modelling is analogous to schwarzschild modelling except that orbits , which are essentially time series of phase - space points , are replaced by orbital tori , which are analytic expressions for the three - dimensional continuum of phase - space points that are accessible to a star on a given orbit .",
    "whereas an orbit is labelled by its initial conditions , a torus is labelled by its three action integrals @xmath21 ; whereas position on an orbit is determined by the time @xmath22 elapsed since the initial condition , position on a torus is determined by the values of three angle variables @xmath23 , one canonically conjugate to each action @xmath21 . for a list of advantages arising from the replacement of orbits by tori , see @xcite , and for a summary of how orbital tori are constructed and references to the papers in which torus dynamics was developed , see @xcite . note that torus models provide the ideal framework within which to study features such as spiral arms or warps because they come with angle - action variables ; these coordinates were invented for perturbative studies of the solar system and , as @xcite showed , perform spectacularly well when they have been derived by constructing tori .",
    "although it is possible to treat the weights of tori as independent unknowns to be fitted to the data just as in schwarzschild modelling , a better procedure is to derive the weights from the model s . by jeans theorem ,",
    "the  of a steady - state model can be taken to be a function @xmath24 of the action integrals .",
    "following binney ( 2010 ; hereafter b10 ) we make @xmath16 an analytic function of certain parameters @xmath25 in addition to @xmath26 , and we fit the model to the data by varying the @xmath25 .",
    "the impact of shot noise on the model is minimised if all tori have the same weight , and this will be the case if the density of used tori in action space samples the .",
    "we endeavour to ensure that this condition is met , at least to a good approximation .",
    "our modelling strategy is as follows . for each trial",
    "gravitational potential we construct a library of orbital tori that has a known sampling density in action space . for each of the galaxy s identified stellar populations ( such as g - dwarfs or k - giants of given metallicity ) we have a luminosity function @xmath27 and a trial  with parameters that have to be chosen for that population . for given values of these parameters",
    ", we can infer the weight of each of the library s tori from the . given these weights and the numerically - determined mapping from actions and angles to cartesian phase - space variables",
    ", we can find the probability of finding a star of a given absolute magnitude at any point ( @xmath28 ) in phase space , and therefore at any point in the space of observables .",
    "hence for given values of the parameters we can evaluate the likelihood of the data given the model that is defined by the current gravitational potential and the current parameters .",
    "we find the values of the parameters that maximise the likelihood for the given potential , and then repeat the process for a different potential . in this way we determine what range of gravitational potentials and s is consistent with the data .",
    "the galaxy s gravitational potential @xmath29 is generated by the sum of the mass densities of _ all _ the galaxy s populations , including that of its dark - matter particles .",
    "our knowledge of @xmath29 remains quite limited , so in the coming years the challenge is to use the kinematics of stars and gas to constrain @xmath29 more tightly .",
    "then poisson s equation can be used to derive the dark - matter density as the difference between the density that generates @xmath29 and the density of stars and gas .",
    "once the distribution of dark matter is fairly well known , it will be appropriate to seek a  for the dark matter and construct a completely self - consistent model of the galaxy . at the present stage of our understanding",
    "a concern for self - consistency would be premature because many s for dark matter will be consistent with any plausible density distribution of dark matter .",
    "consequently , nothing is to be gained by specifying the dark matter s  until there are kinematic constraints on it , presumably provided by experiments that detect dark - matter particles underground .    in this paper",
    "our focus is on the determination of the  of stars given typical observational data and a trial form for @xmath29 .",
    "we defer to a subsequent paper a study of the effects of changing the assumed form of @xmath29 and thus the extent to which given data allow one to constrain @xmath29 .",
    "we now lay out the formulae that are required to implement the strategy just described .",
    "the data consist of a catalogue that for @xmath14 stars gives accurate values of the galactic coordinates @xmath30 , data such as apparent magnitude @xmath31 , colour @xmath32 , and line - of - sight velocity @xmath33 that have moderate errors , and values of the parallax @xmath34 , proper motion @xmath35 , surface gravity @xmath36 and metallicity @xmath37 that are probably significantly in error .",
    "we group the variables into two sets , the basic variables @xmath38 and additional astrophysical variables @xmath39 note that @xmath40 has seven components , effectively a star s phase - space coordinates @xmath41 and its apparent magnitude @xmath31 .",
    "for now we neglect interstellar extinction .",
    "then the star s absolute magnitude @xmath42 is effectively specified by @xmath40 because the star s distance is fixed by @xmath43 .",
    "we assume that the errors in the observed quantities are independent and can be modelled by gaussian probability distributions @xmath44 we attach primes to the true values of measured quantities to distinguish them from the measured values , so we generically have that the probability of measuring a value @xmath45 is @xmath46 any quantity such as the parallax that is not given in the catalogue can be considered to have a sufficiently large @xmath47 that the gaussian density is effectively constant for all relevant values of the variable .",
    "for brevity we use the notation @xmath48    in this paper we restrict ourselves to the case of a single stellar population .",
    "this assumption ensures that there are no correlations between stellar type and kinematics : the distribution of stars in phase space is independent of their luminosities , colours , metallicities , etc . in this case",
    "we can confine discussion to the components of @xmath40 and neglect @xmath49 .",
    "we assume that the luminosity function @xmath27 satisfies the normalisation condition @xmath50 and that the  @xmath24 is normalised such that @xmath51 note that @xmath52 determines @xmath41 , so the set @xmath53 fixes the true values of a star s observables , @xmath54 .",
    "we require the probability of observing a star with observables in @xmath55 given that the star satisfies the selection criteria of the survey",
    ". if @xmath56 is the probability that a star chosen randomly from the galaxy as a whole lies in @xmath55 around @xmath54 , then @xmath57 but @xmath58 so @xmath59 to take into account observational errors , we fold the probability distribution ( [ eq : noerror ] ) with the gaussian kernel and have that the probability density of stars in the space of observables that is predicted by the  @xmath16 is @xmath60 where @xmath61 is the vector of observables corresponding to the given absolute magnitude and phase - space position .    since @xmath62 is a properly normalised probability density function ( pdf ) , we have @xmath63 where the subscript s on the second integral implies integration through the range of observables encompassed by the survey .",
    "usually , there is no restriction on the velocities , so the gaussian factors in @xmath64 , etc , integrate out to unity .",
    "similarly the parallax will not be restricted a priori , so its gaussian factor will integrate to unity .",
    "we assume that the gaussian factors in @xmath65 and @xmath66 integrate to either zero or unity , depending on whether the true values @xmath67 and @xmath68 lie in the surveyed region because the observational errors in the sky coordinates are so small .",
    "hence only the integral over apparent magnitude @xmath31 need be considered , and in this paper we make the assumption that the errors in @xmath31 are small compared to the width of the luminosity function , so we assume that the remaining integral is zero or unity depending on whether the true apparent magnitude @xmath69 lies within the survey limits .",
    "thus we adopt @xmath70 where @xmath71 is the heliocentric distance of the specified point in phase space and @xmath72 with @xmath73 the limiting apparent magnitude of the survey .",
    "we define the survey s selection function to be @xmath74 then we have @xmath75 and ( [ eq : prelimp ] ) can be written @xmath76 from these individual probabilities we construct the log likelihood of a survey for a given model : @xmath77,\\ ] ] where the sum is over the stars in the survey . in an appendix we demonstrate explicitly that @xmath78 is stationary when the trial  used to evaluate it is equal to the  that was used to produce the catalogue being analysed .",
    "the integrals over @xmath26 in equation ( [ eq : finalp ] ) are most conveniently done by monte - carlo integration .",
    "we arrange that the points at which the integrand is evaluated sample the , so we may replace @xmath79 by @xmath80 : @xmath81 where @xmath82 .",
    "the evaluation of the integral in equation ( [ eq : pru ] ) can be simplified by taking advantage of the fact that the errors in @xmath30 are small so the integrand is non - negligible only when @xmath83 lies close to @xmath30 .",
    "we can approximate the gaussians in these variables as @xmath84-functions and integrate them out analytically : doing so we introduce a jacobian because @xmath85 the evaluation of the jacobian is described in the appendix of @xcite .",
    "now we have @xmath86 where the integration over the true parallax @xmath87 has been transformed into an integration over true heliocentric distance .",
    "the integral over @xmath42 simply returns the fraction of the stellar population that is consistent with the measured apparent magnitude at distance @xmath88 .",
    "we use equation ( [ eq : short ] ) for @xmath62 in equation ( [ eq : trial ] ) when evaluating the likelihood .",
    "we determine @xmath89 as follows . for each value of @xmath26",
    "we choose at random a point @xmath90 in angle space .",
    "the point corresponds to a distance @xmath91 and sky coordinates @xmath30 . if these coordinates lie in the survey volume , stars with brighter absolute magnitudes than the value @xmath92 from equation ( [ eq : defsmcrit ] ) will enter the catalogue . after a large number @xmath14 of values of @xmath93",
    "have been explored , we have @xmath94 since @xmath95 does not depend on @xmath16 , it needs to be evaluated only at the start of the procedure for optimising @xmath16 .",
    "the survey contains no information about the value of @xmath24 at actions for which @xmath96 , so it is immaterial whether we change the value of @xmath16 at these actions .",
    "when we adopt a functional form for @xmath16 , we are in fact varying @xmath16 in these invisible regions , and thus at the end of the process arrive at a prediction for that can be tested by a deeper or wider survey .",
    "the computational cost of evaluating the likelihood of a catalogue scales as the product of the number of stars in the catalogue and the number of tori used to sample the model . even for a catalogue that contains @xmath0 stars , the cost is high .",
    "we now investigate the scope for reducing the cost by binning the data .",
    "the log likelihood ( [ eq : trial ] ) is a sum of the contributions from individual stars .",
    "since the contribution from an individual star is practically unchanged by shifting its point @xmath40 in data space by a small amount within the core of its error ellipsoid , the calculated likelihood of the catalogue will not change much if we group stars with data points that lie within a small cell in data space and attribute to all of them the contribution to @xmath78 from the centre of the bin .",
    "a slightly refined version of this basic idea is as follows .",
    "we establish a cartesian grid in data space , the cell spacing in most dimensions being of order half the typical observational uncertainty of the corresponding observable .",
    "if we applied this criterion to @xmath66 and @xmath65 , we would obtain an absurdly fine grid on the sky .",
    "therefore , in @xmath66 and @xmath65 we take the separation between bins to be comparable to the changes in angle over which we expect the distribution of stars to change significantly  this might be as large as @xmath97 in @xmath66 and a degree or so in @xmath65 at low latitudes and larger increments near the poles .",
    "having established our grid , we assign stars to cells .",
    "finally we evaluate @xmath98 at the centre of each cell and form @xmath78 by adding the logarithm of this value times the number of stars assigned to that cell .",
    "the saving in computation from binning is clearly proportional to the number of stars assigned to each cell , which increases with the adopted bin sizes and decreases with the number of quantities actually observed .",
    "hence binning is most attractive for the sparsest data set , namely measurements of @xmath99 .",
    "however , this is already a five - dimensional space .",
    "for a survey of a third of the sky , it might be possible to get by with 100 bins on the sky .",
    "a few tens of bins would be required for the apparent magnitudes , and for each component of @xmath35 ten bins might suffice .",
    "thus a minimal grid will have @xmath100 bins , so even with the simplest conceivable data , binning first becomes advantageous when the number of stars in the catalogue exceeds a million . in the case of gaia ,",
    "the list of observables must be expanded to include at least @xmath34 , and the number of bins required to do justice to the proper - motion data must be increased by a factor of at least 10 , implying a grid with @xmath101 bins .",
    "in reality one would want to include colour data , and some line - of - sight velocities , and the number of bins would be pushed up to @xmath102 , essentially the number of stars in the catalogue .",
    "thus on account of the high dimensionality of the problem posed by current and future surveys of the galaxy , the prospects for binning reducing the computational cost of fitting models are not bright .",
    "the formulae of the last section are used to evaluate the log likelihood @xmath78 of a catalogue given a particular model . in this section",
    "we explain how we estimate the probability distributions of the parameters that appear in the .",
    "we do this with the markov chain monte - carlo ( mcmc ) algorithm : we choose some plausible set of parameters @xmath103 for the  and evaluate @xmath78 for these parameters .",
    "then we generate a random change @xmath104 in the parameters and evaluate @xmath78 for the  with parameters @xmath105 .",
    "if the new value @xmath106 exceeds the old value @xmath78 , we set @xmath107 , while if @xmath108 we set @xmath107 with probability @xmath109 . after a sufficient time , the resulting sequence of values of @xmath103 sample the underlying of @xmath103 ( e.g.   4.3 of * ? ? ?",
    "thus our approach to model fitting employs monte - carlo sampling in two distinct ways . to evaluate @xmath78 for any given parameters @xmath103 we evaluate the action - space integral by monte - carlo sampling action space , and to determine the  of the parameters of @xmath16 we monte - carlo sample parameter space .",
    "it is useful to keep a record of the individual contributions to the sums over @xmath110 in equation ( [ eq : short ] ) for the following reason .",
    "once the likelihood of the data given the current  @xmath16 has been evaluated , a neighbouring , @xmath111 , is chosen , and the likelihood is re - evaluated .",
    "the new value of any sum over @xmath110 can be obtained by , in equation ( [ eq : short ] ) , making the replacement @xmath112.\\ ] ] consequently , if when we first evaluate the likelihood of the catalogue we record for each star the contribution that each torus makes to the probability of seeing that star , we can evaluate the likelihood of the catalogue for any other  at speed .",
    "the price of this speed is having to record an array of size the number of stars in the catalogue times the number of tori employed . fortunately , the array is somewhat sparse because a significant fraction of tori make a negligible contribution to the likelihood of a given star .",
    "the more precise the data are , the sparser the array becomes .",
    "a key to computational efficiency on the first evaluation of the likelihood of the catalogue is to identify in advance for each star the limited number of tori that contribute significantly to the integral in equation ( [ eq : short ] ) .",
    "to do so efficiently we create , for each torus , a grid in @xmath113 and heliocentric @xmath91 , and store the ranges of possible @xmath114 , @xmath115 and @xmath116 for each bin in the grid that the torus goes through ( found to a good approximation by sampling at many @xmath93 from the torus ) . with this information we can then , for each star , quickly discard tori which are clearly not relevant because the bins associated with the appropriate line of sight are either empty or have @xmath91 and/or velocity ranges which are clearly incompatible with the observations .    for a catalogue of significant size",
    "the extra computational effort required to produce these grids is small compared to the computational effort saved by reducing the number of integrals that need to be performed because a grid only needs to be computed once per torus , rather than once per star per torus . in the examples discussed in section [ sec : test ] the grids reduce the number of line - of - sight integrals which need to be found by between a factor of @xmath117@xmath118 when only @xmath35 is provided , and a factor of @xmath117@xmath119 when @xmath35 , @xmath116 and @xmath34 are provided .",
    "as just explained , estimates of @xmath78 for many different parameter values are obtained with the same set of representative tori , and the final optimum values of the parameter and their uncertainties are usually based on a single set of sampling tori . unless this set is sufficiently rich , the parameter estimates are likely to be biased in the sense that their optimum values differ from the true values by more than the returned uncertainties : the latter reflect both the input observational errors and the statistical uncertainty arising from the finite number of stars in the catalogue we are fitting",
    ". they do not include statistical error associated with the use of a finite number of tori to evaluate integrals over action space .",
    "so , how many tori do we need to use ?",
    "it is evident that at least one torus must yield a point @xmath54 in the space of observables that lies within @xmath120 of the measured location of each star .",
    "stars for which only one torus contributes points to the @xmath121 error ellipsoid tend to bias the parameter values : in order to make such stars probable the computer has to make that torus probable ; if this torus differs significantly from the star s actual torus , the probability associated with that star is being misplaced within action space , and we infer an incorrect . for safety we require several tori to contribute points to the @xmath121 error ellipsoid , for then the greatest weight can be assigned to whichever one of them lies close to the star s true torus .",
    "clearly the higher the quality of the catalogue , the smaller are the error ellipsoids and the more tori are needed to fulfil the criterion that several tori contribute to every @xmath121 error ellipsoid .",
    "we can quantify this idea as follows .",
    "equation ( [ eq : short ] ) gives the probability of finding a star with observables @xmath40 as a sum of contributions from individual tori .",
    "if we define @xmath122 then we have @xmath123 and the contribution of the @xmath110th torus to @xmath62 is proportional to @xmath124 .",
    "the shannon entropy of the probability distribution @xmath125 , @xmath126 is the natural measure of the extent to which the probability @xmath62 is contributed by a large number of terms in the sum or dominated by a single largest contribution : @xmath127 vanishes if there is one dominant contribution , so @xmath128 , and peaks at @xmath129 when @xmath130 for all @xmath110 ; if there are just @xmath131 tori that might plausibly produce the data for a given star , @xmath132 of the @xmath124 will be of order @xmath133 and the rest will vanish , so the entropy will be of order @xmath134 .",
    "hence @xmath135 is quite generally an estimate of the number of tori that are consistent with the star s data .",
    "using too few tori to conduct the sum in equation ( [ eq : short ] ) is signalled by some stars having values of @xmath135 smaller than unity / a few and results in the formal errors on the parameters being too small , with the result that the true parameters lie outside the @xmath136 error ellipsoid .    while having @xmath137 suggests that too few tori are being used , the following argument shows that a larger value of @xmath135 does not guarantee that enough tori are being used to give reliable results .",
    "two small samples of tori drawn from different s can by chance have almost identical distributions in action space .",
    "suppose this distribution happens to fit the data perfectly .",
    "then the two different parent s will appear to maximise the likelihood of the data , depending on which  the tori were in fact drawn from .",
    "the best way to check that enough tori are being used is to draw a new sample of tori from the  that maximises the likelihood with the original sample of tori , and then to repeat the maximisation process using the new tori in the analysis .",
    "if enough tori were used , the new pdf of the  will differ negligibly from the old one .",
    "in this section we test the ability of our procedure to recover from a mock catalogue the  from which the catalogue was obtained .",
    "hence we ( i ) build a dynamical model with known , ( ii ) draw a sample of pseudodata from this model by `` observing '' it from the location of the sun and then add errors to the `` observations '' , and ( iii ) use the algorithm described in section  [ sec : optimise ] to constrain the .",
    "in this final step we assume the correct functional form for the  and enquire how accurately we can recover from the pseudodata the values of the s parameters .",
    "we take the distance from the galactic centre to the sun to be @xmath138 .",
    "since the velocity we infer for a star from its proper motion is proportional to the star s distance , whatever distance information we have is going to be crucial for the model - fitting process . for simplicity",
    ", we are assuming that the galaxy contains a single stellar population , and we are not using colour information .",
    "consequently , it suffices to specify the luminosity function .",
    "we use a simple polynomial approximation to the general @xmath139-band luminosity function described in @xcite table 3.16 : @xmath140 this function is plotted in figure  [ fig : lf ] .",
    "we use the galactic potential which @xcite gives for a `` convenient '' galaxy model .",
    "this axisymmetric model consists of a galactic bulge , thin and thick exponential discs , and a @xcite halo .",
    "the potential defines the local standard of rest ( lsr ) and we assume that the sun s velocity with respect to the lsr is that given by @xcite .",
    "we have run tests using two model galaxies , both based on a `` quasi - isothermal ''  @xcite @xmath141 where @xmath142\\e^{-\\kappa j_r/\\sigma_r^2}.\\ ] ] here @xmath143 is the circular frequency for angular momentum @xmath144 , @xmath145 is the radial epicycle frequency and @xmath146 is its vertical counterpart .",
    "@xmath147 is the ( approximate ) radial surface - density profile and we set @xmath148 , where @xmath149 is the radius of the circular orbit with angular momentum @xmath144 .",
    "the factor @xmath150 in equation ( [ planedf ] ) is there to effectively eliminate stars on counter - rotating orbits ; the value of @xmath151 is unimportant in this study provided it is small compared to the angular momentum of the sun . in equations ( [ totaldf ] ) and ( [ planedf ] ) the functions @xmath152 and @xmath153 control the vertical and radial velocity dispersions .",
    "the observed insensitivity to radius of the scale - heights of extragalactic discs motivates the choices @xmath154 where @xmath155 and @xmath156 and @xmath157 are approximately equal to the radial and vertical velocity dispersions at the sun . for discussion of the value of @xmath158 and these choices of functional form ,",
    "see b10 .",
    "the first distribution function we consider is a single thin quasi - isothermal disc , which was constructed with @xmath148 , @xmath159 and @xmath160 .",
    "this is rather dynamically cold , but we use it as a simple example to demonstrate and test the basic principles of the apparatus .",
    "we have also tested the apparatus on a more realistic model galaxy that has both thin and thick discs , with the thick disc contributing 23 per cent of the total disc surface density at the sun .",
    "table [ tab : df ] gives the values of the parameters in the  of this model .",
    "b10 showed that by superposing a large number of s of a very similar form to these quasi - isothermal s , one can obtain a model that is consistent with the local stellar density and velocity distribution . in this study",
    "we , like @xcite , restrict ourselves to these simple one- or two - disc models in order to provide some straightforward demonstrations of the principles discussed in section  [ sec : strategy ] . extending this work to the more complicated s used by b10",
    "is in principle straightforward .",
    ".the parameters of the  of the model that contains both thin and thick discs [ cols=\"<,^,^,^,^\",options=\"header \" , ]     and table  [ tab : twodisc ] show results for the more realistic case of two discs with realistic velocity dispersions . in all three cases",
    "the catalogue contained @xmath161 stars and @xmath162 tori were used in the analysis .",
    "when only proper motions are available , the correlation between @xmath156 and @xmath157 is now rather strong for both thin and thick discs . adding parallaxes produces a more dramatic improvement in precision than in the case of the single - disc model . adding line - of - sight velocities also produces a material improvement in accuracy , presumably because the errors of @xmath163 in the data are a smaller fraction of typical random velocities than in the case of the pure thin - disc model . in this test",
    "the fraction of the stars in each disc was fixed at its true value .",
    "if this fraction is allowed to vary , the recovered parameters have larger uncertainties because a trade - off is possible between the velocity dispersion of the thicker component and the fraction of the stars it carries : the lower the dispersion , the more stars it can carry . in the real world this degeneracy must be broken by using chemical information : the thick disc is fundamentally the component with high [ @xmath19/fe ] .",
    "in this paper we have laid out the formalism of an approach to the interpretation of data from surveys , and have shown that it works in principle . however , we have only scratched the surface of the overall problem . within the existing framework",
    ", we need to :    * chart the growth in the uncertainties of the parameters as the measurement errors of the observations increase . *",
    "determine the precision to which the galactic potential can be determined by fitting the potential in parallel with the , rather than considering it known .",
    "the only barrier to investigating these questions is computational cost : if we change either the measurement errors or the gravitational potential , we have to re - evaluate the likelihood of the catalogue from scratch rather than by re - using the saved contributions of each torus to each star .",
    "the second of the questions above is of particular interest because upon its answer depends the prospects for pinning down the galaxy s dark - matter density to good precision .",
    "the computational cost of evaluating the likelihood of a catalogue is dominated by the integrals of sight - lines in equation ( [ eq : short ] ) . since there is no dependence between these integrals for different stars , the computation is parallelisable , and we do employ multiple cores .",
    "two other directions requiring urgent exploration are :    * extend the formalism to models that possess more than one stellar population , each population being characterised by its own  and distribution in the colour  luminosity plane . *",
    "extend the formalism to include additional observables , such as colour indices , measures of [ fe / h ] , [ @xmath19/fe ] , etc .",
    "the first of these directions is conceptually straightforward and not especially computationally costly .",
    "it is mandatory in the sense that it would introduce correlations between kinematics , chemistry and the luminosity function that were first identified in the galaxy over half a century ago .",
    "operationally it is easy : one simply takes the  to be a superposition of s with a different colour  luminosity distribution for each component .",
    "the presence of more than one population in the system should sharpen our ability to constrain the gravitational potential from a given catalogue as it does in the simpler context of dwarf spheroidal galaxies @xcite .",
    "one could extend the range of observables considered in a trivial way , but at some point it becomes sensible to widen the scope of the scheme to include both a model of the chemical evolution of the galaxy and the strong constraints on stellar parameters yielded by the theory stellar evolution .",
    "we hope to publish details of such a formalism shortly .",
    "the scope of the exercise is then broadened to diagnosing the history of the galaxy as well as its present state , and the resulting constraints on  and gravitational potential would reflect the information regarding stellar distances that is normally embodied in `` photometric distances '' .    an issue that must at some point be addressed is :    * the impact of using an inappropriate form of the .",
    "the  of the galaxy certainly does not consist of a superposition of the quasi - isothermal s we have employed here , and the question arises as so how accurately the real  can be represented by our functional form ( or some other tractable form ) .",
    "that is , once we have found the best - fitting of our form , we want to answer the question `` is our catalogue statistically consistent with being drawn from the chosen . '' at an elementary level this question is readily addressed by drawing pseudo - catalogues from the model  and for each such catalogue calculating @xmath78 from equation ( [ eq : trial ] )  if the value of @xmath78 obtained from the real catalogue lies within the range of those obtained for the pseudo - catalogues , then the model  is clearly consistent with the data . in reality",
    "this exercise will always reveal that @xmath78 for the real catalogue lies outside the range defined by the pseudo - catalogues , because the galaxy is an extremely complicated system , full of structure that is not included in the model .",
    "before we can pass judgement on our fitted  we have to understand what it fails to represent : are there large - scale discrepancies between the predictions of the  and the observations , or does it merely fail to include small - scale fluctuations that one is not endeavouring to represent at this level ? given the limitations on binning the real catalogue that were described in section [ sec : binning ] , addressing this question will be hard .",
    "an issue in this area that can be more easily addressed is `` what impact the use of an inappropriate form of the  will have on the inferred gravitational potential and dark - matter density . ''",
    "we have to expect that an inappropriate form of the  will distort our perception of the gravitational potential because when the  is wrong , we can not expect the likelihood of the data to be maximised by the true potential .",
    "clearly an erroneous potential will yield an erroneous dark - matter distribution .",
    "this question could be rigorously addressed by drawing catalogues from n - body simulations and comparing the potential and dark - matter densities inferred from the catalogue with the real ones .    a final topic that merits discussion is    * optimising the design of surveys    large resources",
    "are currently being invested in surveying the galaxy , and in principle it would be useful before committing these resources to determine the most cost - effective strategy by asking questions such as  is it more useful to measure @xmath14 line - of - sight velocities with errors of @xmath163 or @xmath164 velocities with errors of @xmath165 ?  would it be more useful to increase by half a magnitude the magnitude limit of a satellite s parallax measurements , or to measure line - of - sight velocities for a tenth of the stars ?",
    "the methods described in this paper make it possible to compute precise answers to such questions .    in this context",
    "an obvious step to take now is to investigate the degeneracies between the various parameters of galaxy models , and ask which combination of data types is most effective at breaking such degeneracies .",
    "in this paper we varied only the velocity scales of the .",
    "ideally we would also vary the other parameters in the , such as the scale lengths @xmath166 and the relative normalisations of the thin and thick discs , and also the parameters of the gravitational potential , the sun s velocity , etc .",
    "the extent to which there are degeneracies between these parameters , will depend on the richness of the data , and it behoves us to understand the relative power of different data sets before we design a survey .",
    "it seems inevitable that we will extract the promised science from current and upcoming surveys of the galaxy by comparing the surveys catalogues with models that have been `` observed '' with biases matched to those of the surveys .",
    "a major goal of the surveys is to map the galaxy s dark - matter distribution , which is possible only in so far as the galaxy can be presumed to be in a steady state .",
    "consequently equilibrium dynamical models are of particular importance",
    ".    the number of variables that are commonly measured for each star is large ",
    "in addition to six phase - space coordinates and the apparent magnitude , one or more colours , the effective temperature , the surface gravity and two measures of metallicity are routinely measured because our ambitions to unravel the star - formation and metal - enrichment histories of the galaxy turn on the availability of such data for millions of stars . in section [ sec : binning ] we saw that even if such data were available for a billion stars , only the crudest estimate of the density of stars in the high - dimensional data space could be obtained by binning the data .",
    "therefore it seems inevitable that models will have to be fitted to the data by maximising the likelihood of the data given a model .",
    "these likelihoods can be calculated only if we have the pdf of the model in data space .",
    "this requirement is a major difficulty for n - body models , for which it is in principle no easier to determine the pdf than it is for the galaxy .    for these reasons",
    "we believe models based on analytic s and orbital tori have unique potential for the scientific exploitation of large surveys of the galaxy . in section [ sec : pseudodata ] we described how to produce a discrete realisation from a torus model , and we have made extensive use of such realisations in our tests .",
    "in section [ sec : strategy ] we developed the formalism required to determine likelihoods for a torus model under some simplifications .",
    "the principal simplification was the neglect of all variables other than sky position , space velocities and apparent magnitude . since in this framework",
    "there is no possibility of distinguishing different types of stars , for example metal - poor ones , or @xmath19-enhanced ones or constrain the age of a star , this level of analysis is only appropriate for a galaxy that consists of a single stellar population .",
    "therefore , this exercise is an artificial one , but nonetheless a vital one from which we can build towards work of greater complexity and realism .",
    "the key equation ( [ eq : trial ] ) expresses the log - likelihood as a sum of integrals down the line - of - sight through individual tori .",
    "since a large number of tori must be used if unbiased results are to be obtained , the computational cost of these integrals is large .",
    "fortunately , once they have been evaluated for a given catalogue and gravitational potential , the likelihood of the data given any  can be quickly computed .",
    "therefore the optimisation of the  in a given potential is straightforward .    in section [ sec : test ]",
    "we tested the algorithm by using it to reconstruct the  from catalogues containing either @xmath167 or @xmath161 stars with gaia - like errors .",
    "we found that it performed as expected .",
    "the irreducible statistical uncertainty in the  scales roughly inversely with the square root of the number of stars in the catalogue , and for @xmath167 stars amounts to @xmath168 per cent on the velocity dispersions , which is @xmath169 per cent of the uncertainty on the  found with only measurements of the proper motion ( with gaia - like uncertainties ) . by adding gaia - like measurements of parallax for @xmath167 stars to those of proper motion",
    ", one can drive the uncertainty in the  almost down to the irreducible statistical uncertainty .",
    "the uncertainties quoted above are remarkably small given the small sizes of the catalogues analysed .",
    "the uncertainties will grow , probably significantly , when the potential is varied alongside the .",
    "they will also grow with the sophistication of the , although one may hope that this growth will be to a large extent countered by enrichment of the data to include spectrophotometric data that must accompany any attempt to decompose the galaxy into several populations with distinct s.    the uncertainties on parameters that we recover include the effects of measurement errors and statistical uncertainty arising from the finite number of stars in the analysed catalogue , but do not make allowance for the use of only a finite number of tori .",
    "an insufficient supply of tori will lead to biases in the results .",
    "the entropy of the probability distribution defined by equation ( [ eq : defspk ] ) being small is a sure sign that too few tori are being used , but the surest check that enough tori are being used is to draw a fresh sample of tori from the final  and to re - determine the pdf of the s parameters using these tori . if the pdf differs materially from the original one , more tori are required .",
    "it is remarkable that the  can be recovered from proper motions alone because with the broad luminosity function used here the data by themselves contain negligible distance information .",
    "the distance information that is required to pin down the  and thus establish the typical velocities of stars is provided by the gravitational potential , which sets a scale - height at any velocity dispersion , and by the solar motion through the logic of traditional secular parallaxes .",
    "since only limited distance information is available when the data are restricted to proper motions , the two velocity scales of the , @xmath156 and @xmath157 have correlated errors .    adding parallaxes to the data set",
    "eliminates this correlation as well as diminishing the scale of the uncertainties .",
    "further adding line - of - sight velocities with uncertainties of @xmath163 has at most a small impact on the results .    in section [ sec : discuss ] we discussed several directions for further work .",
    "one urgent step is to extend the formalism to include the spectral characteristics of stars , such as metallicity , colour , effective temperature and surface gravity .",
    "the main issue here is how best to extend our models to predict their distributions .",
    "there is more than one way that this can be done , so we reserve this topic for a future paper .",
    "a related issue is how best to combine constraints from different surveys , for example an astrometric survey such as gaia with a spectroscopic one such as the eso - gaia survey .",
    "one option is to analyse the catalogues one after the other , using constraints obtained from the first analysis to define the prior used in the second analysis .",
    "alternatively it may be possible to refine the definition of the selection function @xmath89 in such a way that catalogues with different selection criteria can be analysed simultaneously .    in this paper",
    "we have neglected extinction . given a three - dimensional model of the interstellar medium",
    ", it would be straightforward if computationally costly , to allow for reddening and extinction .",
    "ideally , the model of the ism would be refined in parallel with the galaxy model , but it is not yet apparent how this could be accomplished in practice .",
    "a key topic is the extent to which the galaxy s gravitational potential can be constrained by various bodies of data . in principle",
    "this is a trivial extension of the present work , but it is computationally expensive .    computational cost is a real issue .",
    "the cost of analysing a catalogue is proportional to the number of its stars times the mean number of tori @xmath170 that might make a non - negligible contribution to each star s probability .",
    "although the total number of tori needed increases with the precision of the data , @xmath170 should be roughly constant between catalogues , so computational cost should scale with the number of stars in the catalogue .",
    "however , this situation may be improved by binning stars by position on the sky , and evaluating the appropriate line - of - sight integral ( eq .",
    "[ eq : short ] ) simultaneously for all the stars in a bin for a given torus , under the approximation that their position on the sky is that of the centre of the bin . approaches like this which reduce computational effort are likely to prove essential in scaling up this algorithm from working with the pseudo - catalogues of @xmath161 stars used here to analysing surveys such as rave , with @xmath171 stars observed and , looking further ahead , the @xmath117@xmath7 stars in the gaia catalogue .    abazajian k. , et al . , 2009 , apjs , 182 , 543 - 558    amorisco n.c . , evans n.w . , 2011 , mnras accepted , arxiv:1106.1062    bahcall j.n . , soneira r.m . , 1984 , apjs , 55 , 67    bell e.f .",
    "et al . , 2008 , apj , 680 , 295 binney j. , 2010 , mnras , 401 , 2318    binney j. , dowrick n. , fisher a. , newman m.e.j . , 1992 `` the theory of critical phenomena '' , oxford university press , oxford    binney j. , lacey c. , 1988 , mnras , 230 , 597    binney j. , mcmillan p. , 2011",
    ", mnras , 413 , 1889    binney j. , merrifield m. , 1998 , `` galactic astronomy '' , princeton university press , princeton    binney j. , tremaine s. , 2008 , `` galactic dynamics '' , princeton university press , princeton    bissantz n. , debattista v.p .",
    ", gerhard o. , 2004 , apj , 601 , l155    brown a.g.a . , velzquez h.m .",
    ", aguilar l.a . , 2005 , mnras , 359 , 1287    carlberg r.g . , sellwood j.a . , 1985 , apj , 292 , 79    dehnen w. , 2009 , mnras , 395 , 1079    dehnen w. , binney j. , 1998 , mnras , 298 , 387    de lorenzi f. , debattista v.p .",
    ", gerhard o. , sambhus n. , 2007 , mnras , 376 , 71    epchtein n. , simon g. , borsenberger j. , de batz b. , tanguy f. , begon s. , texier p. , derriere s. , and the denis consortium , 2005 , `` denis catalogue third data release '' http://cdsweb.u-strasbg.fr/denis.html    eyre a. , binney j. , 2011 , mnras , 413 , 1852    gebhardt , k. et al , 2003 , apj , 583 , 92    holmberg j. , nordstrm b. , andersen j. , 2007 , a&a 475 , 519    kaasalainen m. , 1994 , mnras , 268 , 1041    kaiser n. et al . , 2002 , `` society of photo - optical instrumentation engineers ( spie ) conference series '' , 4836 , 154    krajnovi d. , cappellari m. , emsellem e. , mcdermid r.m .",
    ", de zeeuw p.t . , 2005 ,",
    "mnras , 357 , 1113    martinez - valpuesta i. , gerhard o. , 2011 , apj , 734 , l20    may a. , binney j. , 1986 , mnras , 221 , 857    mcmillan p. , 2011 ,",
    "mnras , 414 , 2446    mcmillan , p. , binney j. , 2008 , mnras , 390 , 429    navarro j. , frenk c.s .",
    ", white s.d.m . , 1996 ,",
    "apj , 462 , 563    nordstrm b. , mayor m. , andersen j. , holmberg j. , pont f. , jrgensen b.r . , olsen e.h . , udry s. , mowlavi n. , 2004 , a&a , 418 , 989    perryman m.a.c . , 1997 , `` the hipparcos and tycho catalogues '' , ( noordwijk : esa publications )    ratnatunga k.u .",
    ", bahcall j.n . , casertano s. , 1989 , apj , 339 , 106    robin a.c . , reyl c. , derrire s. , picaud , s. , 2003 , a&a , 409 , 523    roman n.g , 1954 , aj , 59 , 307    schnrich r. , binney j. , 2009 , mnras , 399 , 1145    schnrich r. , binney j. , 2011 , mnras , accepted , arxiv:1109.4417    schnrich r. , binney j. & dehnen w. , 2010 , mnras , 403 , 1829    sharma s. , bland - hawthorn j. , johnston k.v . , binney j. , 2011 , apj , 730 3    skrutskie m.f . , et al .",
    ", 2006 , aj , 131 , 1163    schwarzschild m. , 1979 , apj , 232 , 236    siebert a. , et al . , 2011 ,",
    "aj , 141 , 187 simon r. , brook c.b . , martel h. , kawata d. , gibson b.k . , sanchez - blazquez p. , 2010 ,",
    "mnras , 402 , 1489    spitzer l. , schwarzschild m. , 1953 , apj , 118 , 106    steinmetz m. , et al . , 2006 , aj , 132 , 1645    syer d. , tremaine s. , 1996 , mnras , 282 , 223    yanny b. , et al . , 2009 , aj , 137 , 4377    zacharias n. , et al . , 2010 ,",
    "aj , 139 , 2184",
    "by the monte - carlo integration theorem , the sum over @xmath19 in the definition ( [ eq : trial ] ) of the likelihood @xmath78 can be replaced by an integral over @xmath40 times the pdf of the stars in that space , which is @xmath172 , where @xmath173 is the true .",
    "hence @xmath174,\\ ] ] so @xmath175 when @xmath176 the denominator cancels with the pdf on top and we find @xmath177 this vanishes because it is the derivative of @xmath178 ."
  ],
  "abstract_text": [
    "<S> we consider what is the best way to extract science from large surveys of the milky way galaxy . </S>",
    "<S> the diversity of data gathered in these surveys , together with our position within the galaxy , imply that science must be extracted by fitting dynamical models to the data in the space of the observables . </S>",
    "<S> models based on orbital tori promise to be superior for this task than traditional types of models , such as n - body models and schwarzschild models . </S>",
    "<S> a formalism that allows such models to be fitted to data is developed and tested on pseudodata of varying richness drawn from axisymmetric disc models .    </S>",
    "<S> [ firstpage ]    galaxies : evolution  galaxies : kinematics and dynamics  galaxy : disc  solar neighbourhood  methods : data analysis </S>"
  ]
}