{
  "article_text": [
    "we assume that we have @xmath2 samples of unbiased estimators of quantities @xmath3 with @xmath4 .",
    "thus the data set is @xmath5 where @xmath6 .",
    "we assume that the samples @xmath5 are statistically independent versus @xmath7 for fixed @xmath0 but may be correlated in @xmath0 .",
    "such a situation arises in lattice gauge theory calculations where there are @xmath2 independent configurations and @xmath8 green functions ( vacuum expectation values of combinations of quark propagators and/or gauge links ) are measured versus time separation @xmath0 .",
    "an introduction to this topic in the context of lattice gauge theory is provided by toussaint  @xcite .",
    "the aim is to fit a given function @xmath9 which depends on @xmath10 parameters @xmath11 .",
    "this function is to be fitted to the data samples @xmath3 .",
    "thus we require to find the following    * the best values of the parameters @xmath11 .",
    "* the errors associated with these best fit parameters . * the confidence level that the fit represents the data sample",
    ".    a general discussion of this problem has been given  @xcite which has shown that with limited data samples @xmath2 , it may be unrealistic to allow a general form for the @xmath12 correlation matrix describing the correlations among the data at the @xmath8 different @xmath0 values . in particular the estimated @xmath1 was shown to be increased by a factor of @xmath13 .",
    "this led to the conclusion that @xmath14 is needed for a reliable use of @xmath1 as a goodness of fit estimator in a correlated @xmath1 fit .",
    "although this conclusion arose from studying a theoretical distribution which was uncorrelated , the above @xmath1 increase is the same for any true distribution . indeed",
    "the @xmath1 per degree of freedom will have the expected value @xmath15 .",
    "furthermore the distribution of @xmath1 can be evaluated theoretically  @xcite so that confidence levels can be derived .",
    "the major consequence of small sample size is that the eigenvalues of the correlation matrix are modified : in particular very small eigenvalues can arise .",
    "these correspond to a very narrow distribution in the corresponding eigen - direction and so can bias any fit considerably .    in order to cope with this , it is necessary to use some extra theoretical input . in particular , one needs to assume a form of the correlation matrix or of its eigenvalue spectrum .",
    "this has been recognised before , and proposals have been made to truncate the eigenvalues according to the spirit of the svd inverse of a singular matrix  @xcite .",
    "we discuss this proposal and offer our suggestions for an improved treatment .",
    "we believe that our approach is more stable .",
    "another way to attack this problem is to explore the theoretical expectations for the correlation matrix . in the case we are considering",
    ", the correlation between meson operators can be expressed in terms of vacuum expectation values of 4-quark operators  @xcite . these can be estimated and this gives a motivation for a direct parametrization of the correlation matrix in terms of exponentials in @xmath16 . if the normalised correlation is given by one such exponential",
    ", then its inverse is a tridiagonal matrix .",
    "this is a very appealing model since it corresponds to a nearest neighbour linkage in the underlying probability distribution .",
    "this one - parameter model is very stable , but does not always give an accurate description of the data . a natural way to extend",
    "it is to consider a 5-diagonal inverse as an efficient parametrization .",
    "this 2-parameter model corresponds to a correlation matrix given by a specific combination of 2 exponentials and it fits the data well in many cases .",
    "we start by presenting typical data on the hadronic green functions from quenched lattice studies .",
    "this enables us to analyse the behaviour of the correlation matrix which is at the heart of our exploration .",
    "we then compare various methods of modelling the correlation matrix and test their stability in correlated @xmath1 fits .",
    "the data @xmath3 we will consider are green functions which are vacuum expectations of hadronic operators at times 0 and @xmath0 .",
    "such data are often referred to as hadron correlators but we will not use this description here since we wish to concentrate on a different correlation : that between the green functions @xmath3 at different @xmath0 values .    the data sample themselves give a probability distribution @xmath17 we shall be interested in estimates of the probability distribution @xmath18 of the averages @xmath19 of the data @xmath3 . a smooth representation of @xmath18 is needed for determining best fit parameters and to estimate the acceptability of such a fit .",
    "the natural parametrisation for @xmath20 is suggested by the central limit theorem .",
    "provided that the underlying distributions of @xmath3 are sufficiently localised , then for large @xmath2 , @xmath19 will be gaussianly distributed .",
    "we are specifically interested in the case where the different components @xmath3 are statistically correlated . thus a general gaussian surface will be needed .",
    "@xmath21 with @xmath22 @xmath23 @xmath24 to find the best fit parameters then corresponds to maximising @xmath25 with respect to @xmath11 for @xmath26 . this is the usual correlated @xmath1 method . for sufficiently large @xmath2 , this is a stable procedure and the expected value of @xmath1 is the number of degrees of freedom @xmath27 .",
    "but for small @xmath2 , the sampling fluctuation in @xmath28 and hence @xmath29 can give unreasonable fits . in order to avoid this bias",
    ", we aim to make a more stable model for @xmath28 .",
    "let us now study the properties of the correlation matrix @xmath28 .",
    "it is a real symmetric positive - definite matrix for any number of samples @xmath2 but it has rank @xmath30 so will have @xmath31 zero eigenvalues if @xmath32 . in this latter case , its inverse is not defined .",
    "a commonly used prescription in such a case is the singular value decomposition ( svd ) inverse which corresponds to omitting the eigenmodes corresponding to the zero eigenvectors from the inverse .",
    "we will return to discuss the utility of this prescription .    for many purposes ,",
    "it is simpler to study the normalised correlation matrix which we define as @xmath33",
    "in quenched lattice determinations of hadronic spectra and matrix elements , one studies vacuum expectation values of hadronic operators at times 0 and @xmath0 .",
    "thus @xmath3 is the vacuum expectation value of hadronic operators @xmath34 .",
    "these determinations of @xmath3 are extracted from the quark propagators derived from inverting the fermion matrix in the given gauge field sample .",
    "this propagator inversion is very demanding computationally and is usually only evaluated for one source point @xmath35 .",
    "this implies that quark propagators to all values of @xmath0 are equally sensitive to the region around this fixed source site .",
    "thus between different gauge ( vacuum ) samples , all propagators will tend to be large / small as this fixed region is conducive / resistant to quark propagation .",
    "this argument shows that very prominent correlations are expected between hadron green functions to different @xmath0 values .",
    "we analyse some data to substantiate this .",
    "we present results for the normalised correlation @xmath36 in fig  1 . here",
    "the data come from a study of the @xmath37 and @xmath38 mesons using local hadronic operators from a point source at @xmath35 to @xmath39 summed over @xmath40 to give a zero - momentum observable . there are @xmath41 independent configurations using a hopping parameter @xmath42 with the clover improved action  @xcite .",
    "the lattice has size @xmath43 at @xmath44 and , for orientation , @xmath45 at this hopping parameter value .",
    "we use @xmath0 values 5 to 24 for this study .",
    "we find that @xmath46 decreases with @xmath16 but is relatively insensitive to @xmath47 .",
    "the decrease with @xmath16 is illustrated in fig  1 .",
    "an exponential behaviour versus @xmath16 is expected from an analysis in terms of hadronic operators .",
    "let us summarise this argument .",
    "consider the case where @xmath3 is the vacuum expectation value of hadronic operators @xmath34 .",
    "then @xmath48 the first term then will have contributions between @xmath0 and @xmath49 from intermediate states of lowest energy @xmath50 with the quantum numbers created by @xmath51 , the same as those in @xmath3 itself . between 0 and @xmath0 ( for @xmath52 ) , the intermediate state will have the quantum numbers of @xmath53 and so may have a lower energy which we write as @xmath54 . ignoring for the moment the disconnected term , and assuming that one state only dominates in each case , then",
    "@xmath55    for the case of the @xmath38 for example : @xmath56 and @xmath57 since a 2@xmath37 state can couple to @xmath58 ( ie to @xmath59 ) .",
    "thus a small exponential rate of decrease is to be expected with exponent @xmath60 . in this case",
    "the disconnected term in @xmath28 will be relatively unimportant since it decreases faster than the connected term by @xmath61 .",
    "the contribution of excited intermediate states will modify this simple exponential behaviour except at large @xmath16 where the lowest state dominates .",
    "the curve corresponding to the ground state exponential @xmath62 is shown in fig.1 , where it is seen to be a reasonable guide to the large @xmath16 behaviour .",
    "for the case where @xmath63 is a pion observable , then both @xmath50 and @xmath29 are @xmath64 and the correlation @xmath36 would be constant versus @xmath16 . in this case",
    "the disconnected term will be relatively important .",
    "the disconnected part will reduce the magnitude of @xmath65 especially when relatively more disconnected terms are present - such as with a source summed over spatial position .",
    "when the source is at a fixed lattice position @xmath35 , as above , then the disconnected parts will cancel less completely and we expect @xmath65 to remain large for large @xmath16 . indeed it is larger for @xmath37 than @xmath38 correlations as shown in fig .  1 .    for baryon spectra ,",
    "the nucleon is the lowest lying 3 quark state and so @xmath65 will be like the pion case above , while the @xmath66 will behave analogously to the @xmath38 above .",
    "since there is some theoretical justification for an exponential decrease of @xmath36 with @xmath16 , we consider first a simple and robust model with just one exponential .",
    "since @xmath36 is normalised , this results in a one parameter model with parameter @xmath67    @xmath68    in practice the behaviour of @xmath36 is not exactly exponential , so one must choose a reference value of @xmath69 to determine a suitable value of @xmath67 .",
    "we have found that using @xmath70 is a good choice . then @xmath67 is determined by averaging the @xmath71 values of @xmath72 obtained from the sample data .",
    "this averaging along the off - diagonal of @xmath65 also helps to reduce the sampling fluctuations .",
    "the test of the suitability of a model of @xmath36 for our purposes is that its inverse @xmath73 is stable under fluctuations in the data sample used to model @xmath36 .",
    "thus it is appropriate to study the inverse of @xmath36 . for the case of a single exponential",
    ", the inverse is particularly simple : it is tridiagonal .",
    "it is given exactly in terms of @xmath74 by @xmath75 where @xmath76 is the maximum or minimum @xmath0 value in the matrix being inverted .",
    "thus as @xmath77 , the elements of @xmath78 increase as @xmath79 . in the limit of large d , one can estimate the smallest eigenvalue of @xmath36 ( largest of @xmath78 ) which is @xmath80 ( @xmath81 respectively ) as @xmath77 .",
    "thus if @xmath67 is reasonably well determined by the correlated data sample , then the value of @xmath78 will be stable under sample fluctuations .",
    "thus the resultant fits will be stable too .",
    "this method provides a stable one parameter model for @xmath36 .",
    "one drawback of the model is that it does not reproduce very accurately any non - exponential behaviour of @xmath36 .",
    "this can be taken into account in a straightforward way by considering 2-exponential models for @xmath36 .    rather than consider an arbitrary 2-exponential model , we generalise the tri - diagonal feature of @xmath78 and look for 5-diagonal models instead .",
    "the algebra is now somewhat messier , but the conclusion is that a 5-diagonal model for @xmath78 corresponds to a particular 2-exponential model for @xmath36 with : @xmath82 where to have a sensible interpretation we require @xmath83 .",
    "if @xmath84 and @xmath85 are complex , they must be complex conjugates . in this case the behaviour of @xmath36 versus @xmath16 will be a damped oscillation .",
    "although such a behaviour is not strictly excluded , it seems unreasonable to have anti - correlation at larger @xmath0 values so we choose not to allow that possibility .",
    "henceforward , we take @xmath84 and @xmath85 to be real .    thus we obtain @xmath84 and @xmath85 by comparing the above expression for @xmath36 with the sample data .",
    "the two parameters can , for instance , be determined by making a least squares fit to @xmath36 at @xmath86 and @xmath87 .",
    "a fit is needed because in some cases the data may not be reproducible exactly by the expression .",
    "we find that this 2-parameter assignment to the sample correlation is stable when inverted for use in fits .",
    "this is plausible since a 5-diagonal form of the inverse avoids very small eigenvalues of @xmath36 .",
    "we give the explicit formula for the inverse of the 5-diagonal matrix in the appendix .",
    "the essence of the problem is that sample values of @xmath36 may have very small eigenvalues and these influence unreasonably the inverse @xmath78 used in modelling the distribution of the data .",
    "an obvious way to proceed is to modify these unreasonable eigenvalues by hand .",
    "one suggestion  @xcite is to remove the _",
    "largest _ eigenvalues of @xmath36 since they will have least influence on @xmath78 .",
    "this seems hard to justify and later suggestions  @xcite have been to remove the _",
    "smallest _ eigenvalues of @xmath36 .",
    "this latter suggestion is in the spirit of the svd inverse of a singular matrix : only the contributions from the non - zero eigenvalues are retained in the inverse .",
    "this eigenvalue truncation is clearly a rather brutal approximation to @xmath78 : its largest components are being removed .",
    "indeed the gaussian surface modelling the probability distribution will be unconstrained in the direction of the deleted eigenmodes .",
    "a physical argument , for why this may be acceptable in practice , can be based on the observation  @xcite that the smallest eigenvalues of @xmath36 usually correspond to eigenvectors which alternate in sign ( versus @xmath0 ) and so are not very relevant to smooth fit functions .",
    "as we have argued , with a small sample size @xmath2 , the @xmath8 eigenvalues of the sample correlation matrix will be changed from their true values .",
    "the largest relative effect will come when there are several true eigenvalues of similar size - since those eigen directions mix fully .",
    "we find that the eigenvalue spectrum is densest at small eigenvalues .",
    "this again leads to the conclusion that the smallest eigenvalues of the sample correlation matrix are the most strongly affected .",
    "the svd approach replaces the smallest ( or zero ) eigenvalues by very large values ( since this corresponds to ignoring those terms in the inverse ) .",
    "we have explored this situation and found a less discontinuous way to modify the smallest eigenvalues @xmath88 of @xmath36 .",
    "we keep the largest @xmath89 eigenvalues substantially unchanged and then rearrange the remaining smaller eigenvalues to avoid extremely small ones . following from the motivation that like eigenvalues mix most , we propose to redistribute the small eigenvalues by replacing them by their average to avoid very small values .    after some experimentation",
    ", we propose the following explicit scheme to replace the @xmath8 eigenvalues @xmath88 of the sample normalised correlation @xmath36 ( with convention @xmath90 ) with new eigenvalues @xmath91 :    @xmath92 @xmath93 the eigenvectors of @xmath36 and thus of its inverse @xmath78 are retained unchanged .",
    "thus our procedure removes any very small eigenvalues of @xmath36 and replaces them with the average of the @xmath94 smallest eigenvalues while retaining the property that the trace of @xmath36 is @xmath8 .",
    "the procedure also ensures a smooth eigenvalue distribution by allowing eigenvalues larger than this average to be retained .",
    "we tested this assignment with the same data as used above .",
    "of course for @xmath95 , the method is equivalent to an exact inversion of the sample correlation matrix . for @xmath96 ,",
    "this method provides a stable model of the correlation matrix from the sample data .",
    "as @xmath89 is increased , the model reproduces more exactly the sample correlation matrix - but at the expense of including unreasonable fluctuations if the sample size is too small .",
    "a compromise is to retain @xmath97 exact eigenvalues when there are @xmath2 samples .",
    "here we apply the various models described above to some typical real data . since we need a large number of samples to give an accurate data set we chose some ape data  @xcite on @xmath38 meson green functions @xmath98 . here",
    "local - source and local - sink operators @xmath51 are used for creating and destroying a @xmath38 meson .",
    "the data set has @xmath99 samples of @xmath3 with the clover fermionic action at @xmath100 on a @xmath101 lattice at @xmath44 .",
    "the data sample is large enough to allow a full correlated fit to the observed @xmath3 .",
    "an acceptable fit ( @xmath102 ) to @xmath3 with one exponential ( actually a cosh is used ) is found for the @xmath0-range 14 to 24 .",
    "this 2-parameter fit corresponds to requiring a plateau in the effective mass .",
    "the eigenvalues of the normalised correlation matrix for this data set are shown in fig  2 by the continuous line .",
    "here our intention is not to obtain the most precise values of @xmath103 but to illustrate the stability of various fitting prescriptions .",
    "thus we take this full data sample as the true result and explore fits using smaller subsets of the 420 data .",
    "for example we take 14 blocks of 30 data . for each such set of 30",
    ", we perform a fit to the same @xmath0-range .",
    "the intention is to check whether the @xmath104 is similar to the true value from the full data set . as well as the average value of @xmath105",
    ", one may study its distribution so that confidence levels can be extracted .",
    "we do not pursue this here .",
    "a valid criterion for goodness of fit is of importance .",
    "the usual method is to use @xmath1 to decide if a fit is acceptable over a given @xmath0-range .",
    "thus an erroneous @xmath1 value will lead to an increase or decrease in the @xmath0-range chosen as acceptable .",
    "this in turn will bias the fitted parameters such as @xmath103 .",
    "for example , an uncorrelated fit will yield much lower @xmath1 which will then suggest lower @xmath0 values being included .",
    "this will tend to increase @xmath103 since the effective mass is a decreasing function of @xmath0 in this case .",
    "returning now to the comparison : fig  3 shows the results of the average of 14 fits to different samples of size @xmath106 .",
    "the full correlated fit ( @xmath107 ) has a higher @xmath1 on average by 40% than the ` true ' result .",
    "this is entirely expected from the factor @xmath108 increase in @xmath1 predicted  @xcite .",
    "the eigenvalues from one such sample fit to @xmath106 are shown in fig  2 . here",
    "the phenomenon of very small eigenvalues appearing for small sample size is clear .",
    "thus a direct use of a correlated fit to @xmath106 samples is likely to be biassed by those spurious small eigenvalues .",
    "we consider now some of the models introduced above to counter this while retaining a reasonable estimate of the goodness of fit .",
    "as shown in fig  3 , the uncorrelated fit has a very much reduced @xmath1 as expected .",
    "the 1- and 2-exponential models of section 4 do much better in estimating @xmath1 .",
    "the eigenvalue smoothing model of section 5 also does well when 4 to 8 eigenvalues are retained exactly rather than all eigenvalues ( @xmath107 ) .",
    "note that this is indeed consistent with our previous estimate that approximately @xmath109 exact eigenvalues can be relied on .",
    "the modifications to the eigenvalues from the smoothing model are shown in fig  2 for one sample and 6 exact eigenvalues .",
    "indeed the modification does alter the eigenvalues from the sample in the direction of the true values .",
    "also shown in fig  3 are the results using an svd definition of the inverse of @xmath36 in which @xmath7 eigenvalues are retained exactly and the remainder are discarded .",
    "it is possible to estimate the expected value of @xmath1 in this approach  @xcite , yielding @xmath110 which is quite close to the values in fig  3 .",
    "thus a corrected estimator of the goodnes of fit is essential in this approach .",
    "the eigenvalue distribution is not smooth since the deletion of eigenmodes is equivalent to replacing the @xmath111 smallest eigenvalues in fig  2 by infinite values .    for the samples of @xmath106 ,",
    "the situation is that the correlations appear stronger than the true distributions .",
    "this can be understood from the earlier discussion of the eigenvalues of @xmath36 .",
    "the true correlation matrix @xmath65 has 11 eigenvalues with values in the range 0.00438 to 9.82 whereas from subsets of 30 samples the smallest eigenvalue fluctuates between 0.00052 to 0.002844 .",
    "these reductions in the magnitude of the smallest eigenvalues correspond to narrower probability distributions and hence stronger correlations .",
    "the implications of this for the goodness of fit have been discussed , but we also need to check that the fitting procedures do not upset the fitted parameters themselves . for our chosen @xmath0-range",
    "the correlated fit to the full 420 samples yields @xmath112 .",
    "a range of other fits to the same full sample ( ie uncorrelated , 5-diagonal , smoothed , etc ) give essentially the same value of @xmath103 .",
    "thus it is only the goodness of fit that depends on the correlation model used . for the fits to subsets of 30 samples",
    ", we find that an uncorrelated fit does give the same result when averaged over the 14 independent blocks .",
    "the various correlation models all give a result somewhat higher ( @xmath113 ) .",
    "thus we have some evidence that the uncorrelated fit is the most stable for determining the fit parameters when the sample size is reduced .",
    "data appropriate to hadron propagation in lattice gauge theory calculations are very strongly correlated . a full correlated fit to such data",
    "can be biassed unless the sample size ( @xmath2 ) is sufficiently large compared with the number of data points ( @xmath8 ) .",
    "the main effect is the appearance of spurious small eigenvalues of the correlation matrix .",
    "these increase the correlation in the sample .",
    "this increases @xmath1 by a factor of @xmath15 .",
    "it can also bias the fit parameters .    here",
    "we propose models which can ameliorate this .",
    "such models depend , to some extent , on an understanding of the expected form of the correlation matrix .",
    "thus such methods are not completely general . for the applications considered here , we find two promising avenues .",
    "one is to require that the normalised correlation matrix has a tri - diagonal or 5-diagonal inverse .",
    "the other is to average the smallest eigenvalues so that spurious small values are removed .",
    "both of these models give reasonable estimates of the goodness of fit even with quite small sample size .",
    "the goodness of fit is important because it determines the range of data ( eg . the @xmath0-range ) to be fitted .",
    "this then will influence the fitted parameters in turn .    for the actual best determination of the fitted parameters for a small sample , we find that an uncorrelated fit is stable and thus an attractive proposition .    in fitting to hadron green functions , it is preferable to make a simultaneous fit to several operators .",
    "for example smeared or fuzzed operators can be used at either sink or source as well as local ones .",
    "the observables for different operators will be correlated in general .",
    "we have discussed the correlation in @xmath0 , but this correlation among different operators will need somewhat different models . the most attractive route is to use the method of smoothing the eigenvalues of the correlation matrix which is now treated as a @xmath114 matrix if there are @xmath115 @xmath0-values and @xmath10 operators .",
    "we thank our colleagues in the ukqcd collaboration for helpful discussions and for allowing us access to their full data set .",
    "we also thank the ape collaboration for making full data available to us .",
    "consider the matrix given by @xmath82 its inverse @xmath78 is 5-diagonal and is given by the following expressions in terms of @xmath116 and @xmath117 with @xmath118                g. kilcup , nucl .",
    "b ( proc . suppl . )",
    "34 ( 1994 ) 350 .",
    "ukqcd collaboration , c. r. allton et al .",
    "d49 ( 1994 ) 474 .",
    "ape collaboration , c. r. allton et al .",
    "b 326 ( 1994 ) 295 and private communication ."
  ],
  "abstract_text": [
    "<S> we discuss fitting hadronic green functions versus time @xmath0 to extract mass values in quenched lattice qcd . these data are themselves strongly correlated in @xmath0 . with only a limited number of data samples , the method of minimising </S>",
    "<S> correlated @xmath1 is unreliable . </S>",
    "<S> we explore several methods of modelling the correlations among the data set by a few parameters which then give a stable and sensible fit even if the data sample is small . </S>",
    "<S> in particular these models give a reliable estimate of the goodness of fit .    </S>",
    "<S> 2ex    liverpool preprint : lth 342 + hep - lat/9412087 + dec 19 , 1994    * fitting correlated hadron mass spectrum data *   + * c. michael and a. mckerrell * + _ damtp , university of liverpool , liverpool , l69 3bx , u.k . _ </S>"
  ]
}