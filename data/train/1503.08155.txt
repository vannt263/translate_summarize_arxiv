{
  "article_text": [
    "the explosive growth in the number of web pages has drawn much attention to the study of information extraction @xcite in recent decades .",
    "the aim of this is to distill unstructured online texts , so that we can store and exploit the distilled information as structured knowledge .",
    "thanks to the long - term efforts made by experts , crowdsouring and even machine learning techniques , several web - scale knowledge repositories have been built , such as wordnet , freebase and nell , and most of them contain tens of millions of extracted beliefs which are commonly represented by triplets , i.e. @xmath5 .",
    "although we have gathered colossal quantities of beliefs , state of the art work in the literature @xcite reported that in this field , our knowledge bases are far from complete .",
    "for instance , nearly 97% persons in freebase have unknown parents . to populate incomplete knowledge repositories , a large proportion of researchers follow the classical approach by extracting knowledge from texts @xcite .",
    "for example , they explore ideal approaches that can automatically generate a precise belief like @xmath6 from the sentence `` _ madrid is the capital and largest city of spain . _ '' on the web .",
    "however , even cutting - edge research @xcite could not satisfy the demand of web - scale deployment , due to the diversification of natural language expression .",
    "moreover , many implicit relations between two entities which are not recorded by web texts still need to be mined",
    ".    therefore , some recent studies focus on inferring undiscovered beliefs based on the knowledge base itself without using extra web texts .",
    "one representative idea is to consider the whole repository as a graph where entities are nodes and relations are edges .",
    "the canonical approaches @xcite generally conduct _ relation - specific _ random walk inference based on the _ local connectivity patterns _ learnt from the imperfect knowledge graph .",
    "an alternative paradigm aims to perform _ open - relation _ inference via embedding all the elements , including entities and relations , into low - dimensional vector spaces .",
    "the proposed methods @xcite show promising performance , however , by means of learning from ground - truth training knowledge .",
    "this paper thus contributes a probabilistic knowledge embedding model called _ iike _ to measure the probability of each triplet , i.e. @xmath7 , and our objective is to learn a better low - dimensional vector representation for each entity ( @xmath1 and @xmath2 ) and relation ( @xmath3 ) in the process of minimizing the loss of fitting the corresponding confidence given by machine learning ( nell ) or crowdsouring ( freebase ) . to the best of our knowledge , _ iike _ is the first approach that attempts to learn _ global connectivity patterns _ for _ open - relation _ inference on imperfect and incomplete knowledge bases . in order to prove the effectiveness of the model , we conduct experiments on two tasks involved in knowledge inference , _ link prediction _ and _ triplet classification _ , using the two repositories mentioned above .",
    "inexact beliefs are used to train our model , and we test the performance on ground truth beliefs .",
    "results show that _ iike _ outperforms the other cutting - edge approaches on both different types of knowledge bases .",
    "we group recent research work related to self - inferring new beliefs based on knowledge repositories without extra texts into two categories , graph - based inference models @xcite and embedding - based inference models @xcite , and describe the principal differences between them ,    * _ symbolic representation v.s .",
    "distributed representation _ :",
    "graph - based models regard the entities and relations as atomic elements , and represent them in a symbolic framework .",
    "in contrast , embedding - based models explore distributed representations via learning a low - dimensional continuous vector representation for each entity and relation . *",
    "_ relation - specific v.s .",
    "open - relation _ : graph - based models aim to induce rules or paths for a specific relation first , and then infer corresponding new beliefs . on the other hand ,",
    "embedding - based models encode all relations into the same embedding space and conduct inference without any restriction on some specific relation .",
    "graph - based inference models generally learn the representation for specific relations from the knowledge graph .",
    "_ n - foil _",
    "@xcite learns first order horn clause rules to infer new beliefs from the known ones .",
    "so far , it has helped to learn approximately 600 such rules . however , its ability to perform inference over large - scale knowledge repositories is currently still very limited .",
    "@xcite is a data - driven random walk model which follows the paths from the head entity to the tail entity on the local graph structure to generate non - linear feature combinations representing the labeled relation , and uses logistic regression to select the significant features which contribute to classifying other entity pairs belonging to the given relation .",
    "embedding - based inference models usually design various scoring functions @xmath8 to measure the plausibility of a triplet @xmath9 .",
    "the lower the dissimilarity of the scoring function @xmath8 is , the higher the compatibility of the triplet will be .    _ unstructured _",
    "@xcite is a naive model which exploits the occurrence information of the head and the tail entities without considering the relation between them .",
    "it defines a scoring function @xmath10 , and this model obviously can not discriminate a pair of entities involving different relations .",
    "therefore , _ unstructured _ is commonly regarded as the baseline approach .    _ distance model ( se ) _",
    "@xcite uses a pair of matrices @xmath11 , to characterize a relation @xmath3 .",
    "the dissimilarity of a triplet is calculated by @xmath12 . as pointed out by socher et al . , the separating matrices @xmath13 and @xmath14 weaken the capability of capturing correlations between entities and corresponding relations , even though the model takes the relations into consideration .    _ single layer model _ , proposed by socher et al .",
    "thus aims to alleviate the shortcomings of the _ distance model _ by means of the nonlinearity of a single layer neural network @xmath15 , in which @xmath16 .",
    "the linear output layer then gives the scoring function : @xmath17 .",
    "_ bilinear model _",
    "@xcite is another model that tries to fix the issue of weak interaction between the head and tail entities caused by _ distance model _ with a relation - specific bilinear form : @xmath18 .    _",
    "neural tensor network ( ntn ) _",
    "@xcite designs a general scoring function : @xmath19 , which combines the _ single layer model _ and the _",
    "bilinear model_. this model is more expressive as the second - order correlations are also considered into the nonlinear transformation function , but the computational complexity is rather high .",
    "_ transe _ @xcite is a canonical model different from all the other prior arts , which embeds relations into the same vector space of entities by regarding the relation @xmath3 as a translation from @xmath1 to @xmath2 , i.e. @xmath20 .",
    "it works well on the beliefs with one - to - one mapping property but performs badly on multi - mapping beliefs .",
    "given a series of facts associated with a one - to - many relation @xmath3 , e.g. @xmath21 , _ transe _ tends to represent the embeddings of entities on many - side extremely the same with each other and hardly to be discriminated .",
    "@xcite is the state of the art approach as far as we know .",
    "it improves _ transe _ by modeling a relation as a hyperplane , which makes it more flexible with regard to modeling beliefs with multi - mapping properties .    even though the prior arts of knowledge embedding are promising when conducting _ open - relation _ inference on large - scale bases , the stage they stand on",
    "is made of ground - truth beliefs .",
    "the model _ iike _ that we have proposed belongs to the embedding - based community , but firstly tackles the problem with knowledge inference based on imperfect and incomplete repositories . nevertheless , we compare our approach with the methods mentioned above , and assess the performance with both the dataset and the metrics they have used as part of the extensive experiments .",
    "+    the plausibility of a belief @xmath9 can be regarded as the joint probability of the head entity @xmath1 , the relation @xmath3 and the tail entity @xmath2 , namely @xmath22 .",
    "similarly , @xmath23 stands for the conditional probability of predicting @xmath1 given @xmath3 and @xmath2 .",
    "we assume that @xmath22 is collaboratively influenced by @xmath23 , @xmath24 and @xmath25 , and more specifically it equals to the geometric mean of @xmath23@xmath24@xmath25 , which is shown in the subsequent equation , @xmath26{pr(h|r , t)pr(r|h , t)pr(t|h , r)}.\\ ] ]    given @xmath3 and @xmath2 , there are multiple choices of @xmath27 which may appear as the head entity . therefore , if we use @xmath28 to denote the set of all the possible head entities given @xmath3 and @xmath2 , @xmath23 can be defined as @xmath29 the other factors , i.e. @xmath24 and @xmath24 , are defined accordingly by slightly revising the normalization terms as shown in equation ( 3 ) and ( 4 ) , in which @xmath30 and @xmath31 represents the set of relations and tail entities , respectively .",
    "@xmath32 @xmath33    the last function that we do not explain in equation ( 2 ) , ( 3 ) and ( 4 ) is @xmath34 . inspired by somewhat surprising patterns learnt from word embeddings @xcite illustrated by figure 1 , the result of word vector calculation , for instance @xmath35 , is closer to @xmath36 than to any other words @xcite .",
    "if we study the example mentioned above , the most possible reason @xmath37 , is that @xmath38 is the relation between @xmath39 and @xmath40 , and so is @xmath41 and @xmath42 . in other words ,",
    "@xmath43 , if the belief is plausible .",
    "therefore , we define @xmath34 as follows to calculate the dissimilarity between @xmath44 and @xmath45 using @xmath46 or @xmath47 norm , and set @xmath48 as the bias parameter .",
    "so far , we have already modeled the probability of a belief , i.e. @xmath22 . on the other hand , some imperfect repositories , such as nell , which is automatically built by machine learning techniques @xcite , assign a confidence score ( @xmath50 $ ] ) to evaluate the plausibility of the corresponding belief .",
    "therefore , we define the cost function @xmath51 shown in equation ( 6 ) , and our objective is to learn a better low - dimensional vector representation for each entity and relation while continuously minimizing the total loss of fitting each belief @xmath52 in the training set @xmath53 to the corresponding confidence @xmath54 .",
    "@xmath55 - \\log c)\\}^2 .",
    "\\end{split}\\ ] ]",
    "to search for the optimal solution of equation ( 6 ) , we use _ stochastic gradient descent _ ( sgd ) to update the embeddings of entities and relations in iterative fashion .",
    "however , it is cost intensive to directly compute the normalization terms in @xmath23 , @xmath24 and @xmath25 .",
    "enlightened by the work of mikolov et al . , we have found an efficient approach that adopts negative sampling to transform the conditional probability functions , i.e. equation ( 2 ) , ( 3 ) and ( 4 ) , to the binary classification problem , as shown in the subsequent equations , @xmath56 @xmath57 @xmath58 in ( 7 ) , ( 8) , and ( 9 ) , we sample @xmath59 negative beliefs and discriminate them from the positive case .",
    "for the simple binary classification problem mentioned above , we choose the logistic function with the offset @xmath60 shown in equation ( 10 ) to estimate the probability that the given belief @xmath7 is correct : @xmath61    we also display the framework of the learning algorithm of _ iike _ in pseudocode as follows ,     + training set @xmath62 , entity set @xmath63 , relation set @xmath30 ; dimension of embeddings @xmath64 , number of negative samples @xmath59 , learning rate @xmath65 , convergence threshold @xmath66 , maximum epoches @xmath67 . + /*initialization*/",
    "@xmath68 @xmath69 @xmath70 @xmath71/*training*/ @xmath72 negative sampling : @xmath73 /*@xmath74 is the set of @xmath59 negative beliefs replacing @xmath1*/ negative sampling : @xmath75 /*@xmath76 is the set of @xmath59 negative beliefs replacing @xmath3*/ negative sampling : @xmath77 /*@xmath78 is the set of @xmath59 negative beliefs replacing @xmath2*/ @xmath79 /*updating embeddings of @xmath80 with @xmath65 and the batch gradients derived from equation ( 7 ) , ( 8) , ( 9 ) and ( 10).*/ @xmath81++ +   + all the embeddings of @xmath82 and @xmath3 , where @xmath83 and @xmath84 .",
    "embedding the entities and relations into low - dimensional vector spaces facilitates several classical knowledge inference tasks , such as _ link prediction _ and _ triplet classification_. more specifically , link prediction performs inference via predicting a ranked list of missing entities or relations given the other two elements of a triplet . for example , it can predict a series of @xmath2 given @xmath1 and @xmath3 , or a bunch of @xmath1 given @xmath3 and @xmath2 .",
    "and triplet classification is to discriminate whether a triplet @xmath9 is correct or wrong .",
    "several recent research works @xcite reported that they used subsets of freebase ( * fb * ) data to evaluate their models and showed the performance on the above two tasks , respectively . in order to conduct solid experiments , we compare our model ( _ iike _ ) with many related studies including the baseline and cutting - edge approaches mentioned in section 2.2 .",
    "moreover , we use a larger imperfect and incomplete dataset ( * nell * ) to perform comparisons involving the same tasks to show the superior inference capability of _ iike _ , and have released this dataset for others to use .    we are also glad to share all the datasets , the source codes and the learnt embeddings for entities and relations , which can be freely downloaded from http://pan.baidu.com/s/1mgxgbg8 .",
    "one of the benefits of knowledge embedding is that we can apply simple vector calculations to many reasoning tasks , and link prediction is a valuable task that contributes to completing the knowledge graph . with the help of knowledge embeddings ,",
    "if we would like to tell whether the entity @xmath1 has the relation @xmath3 with the entity @xmath2 , we just need to calculate the distance between @xmath85 and @xmath45 .",
    "the closer they are , the more possibility the triplet @xmath9 exists .",
    ".statistics of the datasets used for link prediction task . [ cols=\"^,^,^,^\",options=\"header \" , ]     we use the best combination of parameter settings in the link prediction task : @xmath86 , @xmath87 , @xmath88 , @xmath89 for the * fb15k * dataset , and @xmath90 , @xmath91 , @xmath88 , @xmath92 for the * nell * dataset , to generate the entity and relation embeddings , and learn the best classification threshold @xmath93 for each relation @xmath3 . compared with several of the latest approaches , i.e. _ transh _",
    "@xcite , _ transe _ @xcite and _ neural tensor network ( ntn ) _",
    "@xcite , the proposed _ iike _ approach still outperforms them , as shown in table 5 .",
    "we also drew the precision - recall curves which indicate the capability of global discrimination by ranking the distance of all the testing triplets , and figure 2 shows that the auc ( areas under the curve ) of _ iike _ is much bigger than the other approaches .",
    "we challenge the problem of knowledge inference on imperfect and incomplete repositories in this paper , and have produced an elegant probabilistic embedding model to tackle this issue at the first attempt by measuring the probability of a given belief @xmath9 . to efficiently learn the embeddings for each entity and relation",
    ", we also adopt the negative sampling technique to transform the original model and display the algorithm based on sgd to search the optimal solution .",
    "extensive experiments on knowledge inference including _ link prediction _ and _ triplet classification _ show that our approach achieves significant improvement on two large - scale knowledge bases , compared with state - of - the - art and baseline methods .",
    "we are pleased to see further improvements of the proposed model , which leaves open promising directions for the future work , such as taking advantage of the knowledge embeddings to enhance the studies of text summarization and open - domain question answering .",
    "this work is supported by national program on key basic research project ( 973 program ) under grant 2013cb329304 , national science foundation of china ( nsfc ) under grant no.61373075 .",
    "antoine bordes , nicolas usunier , alberto garcia - duran , jason weston , and oksana yakhnenko . translating embeddings for modeling multi - relational data . in _ advances in neural information processing systems _ ,",
    "pages 27872795 , 2013 .",
    "andrew carlson , justin betteridge , bryan kisiel , burr settles , estevam r.  hruschka jr . , and tom  m. mitchell . toward an architecture for never - ending language learning . in _ proceedings of the twenty - fourth conference on artificial intelligence ( aaai 2010 ) _ , 2010 .",
    "miao fan , deli zhao , qiang zhou , zhiyuan liu , thomas  fang zheng , and edward  y. chang .",
    "distant supervision for relation extraction with matrix completion . in _ proceedings of the 52nd annual meeting of the association for computational linguistics ( volume 1 : long papers ) _ , pages 839849 , baltimore , maryland , june 2014 .",
    "association for computational linguistics .",
    "ni  lao , tom mitchell , and william  w. cohen .",
    "random walk inference and learning in a large scale knowledge base . in _ proceedings of the 2011 conference on empirical methods in natural language processing _ , pages 529539 ,",
    "edinburgh , scotland , uk . ,",
    "july 2011 .",
    "association for computational linguistics .",
    "tomas mikolov , ilya sutskever , kai chen , greg  s corrado , and jeff dean .",
    "distributed representations of words and phrases and their compositionality . in c.j.c .",
    "burges , l.  bottou , m.  welling , z.  ghahramani , and k.q .",
    "weinberger , editors , _ advances in neural information processing systems 26 _ , pages 31113119 .",
    "2013 .",
    "mike mintz , steven bills , rion snow , and dan jurafsky .",
    "distant supervision for relation extraction without labeled data . in _ proceedings of the joint conference of the 47th annual meeting of the acl and the 4th international joint conference on natural language processing of the afnlp : volume 2-volume 2 _ , pages 10031011 .",
    "association for computational linguistics , 2009 .",
    "maximilian nickel , volker tresp , and hans - peter kriegel . a three - way model for collective learning on multi - relational data .",
    "in _ proceedings of the 28th international conference on machine learning ( icml-11 ) _ , pages 809816 , 2011 .",
    "richard socher , danqi chen , christopher  d manning , and andrew ng . reasoning with neural tensor networks for knowledge base completion . in _ advances in neural information processing systems _ ,",
    "pages 926934 , 2013 .",
    "zhen wang , jianwen zhang , jianlin feng , and zheng chen .",
    "knowledge graph embedding by translating on hyperplanes . in _ proceedings of the twenty - eighth aaai conference on artificial intelligence , july 27 -31 , 2014 , qubec city , qubec , canada .",
    "_ , pages 11121119 , 2014 .",
    "guodong zhou , jian su , jie zhang , and min zhang .",
    "exploring various knowledge in relation extraction . in _ proceedings of the 43rd annual meeting of the association for computational linguistics ( acl05 )",
    "_ , pages 427434 , ann arbor , michigan , june 2005 .",
    "association for computational linguistics ."
  ],
  "abstract_text": [
    "<S> this paper considers the problem of knowledge inference on large - scale _ imperfect _ repositories with _ </S>",
    "<S> incomplete _ </S>",
    "<S> coverage by means of embedding entities and relations at the first attempt . </S>",
    "<S> we propose _ iike _ ( imperfect and incomplete knowledge embedding ) , a probabilistic model which measures the probability of each belief , i.e. @xmath0 , in large - scale knowledge bases such as nell and freebase , and our objective is to learn a better low - dimensional vector representation for each entity ( @xmath1 and @xmath2 ) and relation ( @xmath3 ) in the process of minimizing the loss of fitting the corresponding confidence given by machine learning ( nell ) or crowdsouring ( freebase ) , so that we can use @xmath4 to assess the plausibility of a belief when conducting inference . </S>",
    "<S> we use subsets of those inexact knowledge bases to train our model and test the performances of _ link prediction _ and _ triplet classification _ on ground truth beliefs , respectively . </S>",
    "<S> the results of extensive experiments show that _ iike _ achieves significant improvement compared with the baseline and state - of - the - art approaches . </S>"
  ]
}