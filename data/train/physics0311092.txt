{
  "article_text": [
    "the purpose of the babar experiment at the pep - ii accelerator at slac is to study @xmath0 collisions in the 10 gev center - of - mass region , namely the region around @xmath1 threshold .",
    "in particular the program is to investigate extensively @xmath2 violation and rare decays of @xmath3 mesons , as well as topics in charm and tau physics .    here",
    ", babar s approach to statistical issues is summarized .",
    "emphasis is given to areas which are often controversial .",
    "babar is a collaboration of approximately 600 physicists , from @xmath4 institutions in a dozen countries .",
    "thus , managing the production of physics results , from initial analysis to final publication , while maintaining collaboration involvement is a daunting task .",
    "an organizational structure has been established to facilitate this process , as illustrated in fig .",
    "[ fig : physorg ] .    the `` statistics working group '' was appointed by the publications board in order to provide guidelines and advice on statistical matters  @xcite .",
    "this group is advisory ; i ll note how well the guidelines are actually adopted in some cases .",
    "the approach to choosing a statistical procedure is to start by considering the goal .",
    "we adopt the view that there are two broad domains in terms of goal :    * the first goal is that of summarizing the relevant information in a measurement .",
    "this is `` descriptive '' statistics .",
    "it is considered obligatory to report such a description of the result of the experiment .",
    "inherent in this is the view that it is actually useful to do so , a notion that is not uniformly accepted .",
    "the use of frequency statistics is recommended for this purpose .",
    "the choice within the domain of possible frequency statistics is driven by an emphasis on clarity and the facility to compare and combine with other measurements . *",
    "the second goal is that of interpreting the relevant information in the context of making a statement about `` physics '' .",
    "this is regarded as optional , since once the relevant information is available people are in principle able to do this step for themselves . because a statement about physical reality may depend on other information , and on theoretical input , bayesian statistics are recommended .",
    "it may be remarked that there may be other goals , such as making a decision concerning how to spend money for the next experiment .",
    "this would involve , beyond the above interpretive aspects , a consideration of the risks and benefits .",
    "we take the point of view that this is outside the scope of the analysis and reporting of results , and hence do not discuss it further .",
    "we turn now to a review of the specific statistical practices recommended or adopted in babar analyses .",
    "not included are the methods and tools used for optimizing analyses , and pattern recognition , data reduction , and simulation procedures .",
    "these matters are crucial , but here we emphasize instead areas which are traditionally more controversial .",
    "it should be mentioned that the typical products of a babar physics analysis are :    1 .",
    "`` best '' estimates for physical parameters",
    "interval estimates for physical parameters .",
    "significance levels of observations ( e.g. , of a possible discovery ) .",
    "4 .   goodness - of - fit of models to the data .",
    "many babar results are obtained in `` blind analyses '' .",
    "the purpose of a blind analysis is to avoid the introduction of bias , which could occur if the analyst is looking at the results as the analysis is designed .",
    "there is more than one approach to `` blindness '' , see the talk by aaron roodman  @xcite for a summary of babar practice .",
    "we ll give one example here .",
    "for example , consider the measurement of the rare @xmath3 decay @xmath5  @xcite , of interest because of its sensitivity to possible physics beyond the standard model .",
    "the basic idea of the analysis is to look for a signal which peaks in the distribution of two kinematic variables , known as `` @xmath6 '' and `` @xmath7 '' ( fig .",
    "[ fig : kee ] ) .",
    "a fit is performed to this two - dimensional distribution in order to extract the strength of any signal present . however , before performing the fit , an event selection is made in order to suppress backgrounds . in order to avoid biasing the result by looking at the data while tuning the selection , a blind analysis is performed .",
    "the @xmath8 plane is divided into two regions : a region where the fit will be performed , which includes the region where a signal might appear ; and a larger ( `` large sideband '' ) region which excludes the fit region . during the tuning of the analysis",
    ", the data may not be looked at in the fit region , only in the large sideband region .",
    "monte carlo and control sample data ( including a type of data resembling signal ) are used to tune the analysis .",
    "once the selection criteria have been established , the fit region of the data is revealed , and the fit performed to extract the result .     process .",
    "the outside boundaries delimit the `` large sideband region '' ; the intermediate box is the `` fit region '' , and the inner box is the region in which the signal is concentrated ( referred to as the `` signal region '' , but in fact playing no special role in the analysis ) .",
    "the lower plot shows the babar data after unblinding . here",
    ", the outside boundaries demarcate the fit region , and the smaller box is the `` signal region''.,title=\"fig:\",width=294 ]   process . the outside boundaries",
    "delimit the `` large sideband region '' ; the intermediate box is the `` fit region '' , and the inner box is the region in which the signal is concentrated ( referred to as the `` signal region '' , but in fact playing no special role in the analysis ) .",
    "the lower plot shows the babar data after unblinding . here",
    ", the outside boundaries demarcate the fit region , and the smaller box is the `` signal region''.,title=\"fig:\",width=283 ]    as babar is continuing to accumulate data , an issue arises when it is desired to update a blind analysis to include new data . in principle , one could simply add the new data , without changing the analysis . however , this may be impractical , or undesirable .",
    "for example , the entire dataset may be re - reconstructed with improved constants or pattern recognition code . or , there may have been improvements in tools such as particle identification .",
    "one would like to incorporate the benefit from such improvements .",
    "additionally , it might be desirable to work harder to optimize the analysis , or to optimize on different criteria , such as precision instead of sensitivity .",
    "babar often takes a practical compromise approach to incoporate new data , and such improvements .",
    "we have the notion of `` re - blinding '' the data , and re - optimizing .",
    "it is considered safe in this re - optimization to use variables which have not been inspected too carefully in the blind region in the first dataset .",
    "nonetheless , once we have done this , we do not refer to the new result as having been done with a blind analysis .",
    "babar is perhaps the first large hep collaboration to have embraced the blind methodology so enthusiastically .",
    "however , not every babar analysis is blind .",
    "in particular , analyses which may be called exploratory are generally not blinded .",
    "a recent example from babar is the discovery of the @xmath9  @xcite , which was not the result of a blind analysis .",
    "there are many examples of people being led astray by such non - blind exploratory analyses , so extreme caution is warranted .",
    "the exploratory nature of such analyses makes it difficult to apply rigorous methodologies with well - defined statistical properties .",
    "it may not be impossible to do better though @xcite .",
    "the recommendation in babar is to use frequency statistics for summarizing information ( sect .",
    "[ sec : philosophy ] ) .",
    "the goal is to describe what is observed , stressing simplicity and coherence of interpretation , as well as facility in combining with other results . with these criteria ,",
    "we think it can be counter - productive to impose `` physical '' constraints .",
    "there is no reason to obscure the observation of an `` unlikely '' result .",
    "imposing constraints may also complicate combination of results .",
    "generally , the recommendation is to quote two - sided 68% confidence intervals as the primary result .",
    "where there may be doubt , a check for frequency validity ( coverage ) should be performed .      as an example of the construction of a confidence region in a babar analysis , consider the measurement of @xmath10 mixing and doubly cabibbo suppressed @xmath10 decays  @xcite . in this analysis ,",
    "two parameters of interest are to be determined , which may be expressed as @xmath11 and @xmath12 according to the relations : @xmath13 where @xmath14 and @xmath15 are the @xmath10 mass and width , @xmath16 and @xmath17 are the ( small ) differences in masses and widths between the two @xmath10 mass eigenstates , and @xmath18 is an unknown strong phase ( between cabibbo - favored and doubly cabibbo suppressed amplitudes ) .",
    "the measurement is only sensitive to @xmath19 and @xmath20 , and it is possible that the maximum of the likelihood will occur at @xmath21 ( `` unphysical '' region ) . at the current level of sensitivity , we should find a result consistent with @xmath22 , if the standard model is correct .",
    "the construction of a confidence region in the two - dimensional @xmath23 plane , corresponding to 95% confidence level with the frequency interpretation , is performed as follows ( fig .",
    "[ fig : dmixstat ] ) :    1 .",
    "pick a point @xmath24 in the plane .",
    "2 .   form the `` data '' likelihood ratio comparing the observed maximum likelihood with the likelihood at @xmath24 : @xmath25 3 .",
    "simulate many experiments with @xmath24 taken as the true values of the parameters .",
    "4 .   for each monte carlo simulation form",
    "the `` mc '' likelihood ratio : @xmath26 5 .   from the ensemble of simulations ,",
    "determine the probability @xmath27 .",
    "if this probability is greater than 0.95 , then the point @xmath24 is inside the contour ; if less than 0.95 , then the point is outside the contour .",
    "this procedure is repeated for many choices of @xmath24 in order to map out the contour .",
    "[ fig : dmixstat ] shows the result of this algorithm .",
    "the choice was made to stop computng the contour at the border of the `` physical '' region .",
    "the computation could in principle have been carried into the `` unphysical '' region ( up to technical difficulties of the sort we shall discuss anon ) .",
    "it of course makes no difference to the frequency interpretation whether it is extended into the `` unphysical '' region or not .",
    "chosen for a simulation .",
    "the small dots show simulated experiments for which @xmath28 .",
    "the pluses , as well as the arrows pointing offscale , show simulated experiments for which @xmath29 .",
    "the 95% contour resulting from the algorithm described in the text is shown .",
    "the shaded region is the `` unphysical '' region .",
    "note that the evaluation of the maximum likelihood is not restricted to the `` physical '' region.,width=302 ]      issues arise in applying the recommendation of always quoting a two - sided interval for a parameter when the sampling is not from an approximate normal distribution .",
    "most often this involves the low - statistics regime of a counting process .",
    "the first issue is a technical one : it can happen that a search in parameter space wants to go into a region where the probability distribution is undefined .",
    "this is distinct from going into an `` unphysical '' region as in the example above : we ll call it crossing a `` math boundary '' . as a simple example , consider the case of a normal `` signal '' on a flat `` background '' , with pdf ( fig .",
    "[ fig : boundarypdf ] ) : @xmath30 the parameter of interest is the strength of the signal , here expressed as @xmath31 , the probability of sampling a signal event .",
    "an experiment samples @xmath32 events from this distribution , with likelihood function : @xmath33    it is quite possible that the likelihood will be maximal for a value of @xmath34 for which the pdf is not defined .",
    "the function @xmath35 may become negative in some region of @xmath36 .",
    "if there are no events in this region , the likelihood is still `` well - behaved '' .",
    "however , the resulting fit , as a description of the data , will typically look poor even where the pdf is positive .",
    "this is considered unacceptable .",
    ": @xmath37 , and `` unphysical '' ( negative signal ) value @xmath38 .",
    "note that both values are mathematically permissible.,width=245 ]    an illustration of a possible sampled dataset from this distribution is shown in fig .",
    "[ fig : unmathregion ] , displayed as a histogram . an ( unbinned ) maximum likelihood fit to this data gives an estimate for @xmath34 in a region outside the math boundary .",
    "the graph of the `` pdf '' curve for this estimate does not give a good representation of the data . on the other hand , if the fit is constrained to the math region , the graph of the pdf curve looks like a reasonable representation of the data .",
    "-1 cm    thus , we suggest as a practical resolution to this problem to constrain the fit to remain within bounds such that the pdf is everywhere legitimate ( n.b . , parameters may still be `` unphysical '' ) .",
    "experience is that this gives fits which `` look '' like the data , as in the present example , fig .",
    "[ fig : unmathregion ] .",
    "this same practical recommendation applies in interval evaluation ( but coverage should be checked , as always ) .",
    "another issue that arises frequently in low statistics ( poisson ) sampling may be expressed in the form of the following example : a `` cut and count '' analysis for a branching fraction @xmath3 finds @xmath39 events . the mean expected background contribution is estimated as @xmath40 events . the efficiency and parent sample are estimated to give a scale factor ( relating observed signal events to @xmath3 ) of @xmath41 .",
    "the problem is to determine a confidence interval ( at 68% confidence , say ) , in the frequency sense , for @xmath3 .",
    "we ll assume that @xmath39 is sampled from a poisson distribution with mean @xmath42 , that @xmath43 is sampled from a normal distribution , @xmath44 , and that @xmath45 is sampled from a normal distribution , @xmath46 .",
    "thus the likelihood function is : @xmath47 it should be noted that this example is realistic , arising in practice ( to a good approximation ) .",
    "a variant is to assume a normal distribution in @xmath48    several methods have been proposed , and used , for dealing with this problem ( see ref .",
    "@xcite for further discussion of these ) :    1 .",
    "just give @xmath39 , @xmath40 , @xmath41 .",
    "this provides a complete summary of the relevant information , and should be done anyway .",
    "but it is nt a confidence interval for @xmath3 .",
    "2 .   integrate out the nuisance parameters according to @xmath49 this is easy , and often done .",
    "it may be interpreted as a partially bayesian approach , where a uniform prior has been assumed for @xmath50 and @xmath51 .",
    "the frequency properties could be investigated , but usually are nt .",
    "3 .   a very common approach when quoting upper limits is to do the appropriate possion statistical analysis for @xmath39 , but with the scale and background parameters fixed at the estimated values shifted by one standard deviation ( in the direction to make the limit higher than with the central values ) .",
    "this has the benefit of being very easy to do , but it is clearly ad hoc , and the coverage is usually not investigated .    here",
    ", i would like to comment on the possibility of evaluating these confidence intervals in another way .",
    "the method i consider is actually a very common method that seems to have been rather neglected as an approach to the present problem .",
    "the algorithm is as follows : first , find the global maximum of the likelihood function with respect to @xmath52 . then search in the @xmath3 parameter for the point where @xmath53 increases from the minimum by a specified amount ( perhaps by @xmath54 for a 68% confidence interval ) , making sure that the likelihood is re - maximized with respect to @xmath50 and @xmath51 during this search .",
    "the resulting points @xmath55 then give an estimated interval for parameter @xmath3 which we would like to be a confidence interval .",
    "the question , of course , is : does it work ? to answer this , we need to investigate the frequency property of the algorithm . for large statistics ( i.e. , the normal limit ) we know it works  for @xmath54 this method produces a 68% confidence interval for @xmath3 .",
    "we expect that it will fail in the extreme small statistics limit , and the question becomes a quantitative one of how far it can be pushed into the low statistics regime .",
    "we answer this with figs .  [",
    "fig : nm1][fig : nm5 ] .",
    "figure [ fig : nm1 ] shows the dependence of the coverage of this algorithm on the value of @xmath56 , for several values of @xmath3 and an expected background of 1/2 event .",
    "the branching fraction scale is adjusted so that @xmath3 may be interpreted as the mean number of signal events .",
    "it may be seen that @xmath54 gives coverage reasonably close to 68% for @xmath57 .",
    "figure  [ fig : nm2 ] shows the coverage for @xmath58 , for several backgrounds . even at zero branching fraction , the @xmath54 coverage is fairly close to 68% for expected backgrounds @xmath59 .",
    "note that extending this to intervals with higher confidence may result in different conclusions .     for @xmath60 , @xmath61 , @xmath62 , @xmath63 .",
    "there are several curves corresponding to different numbers of expected signal events , @xmath3 .",
    "the smoothest curve is the coverage in the high statistics ( normal ) limit.,width=226 ]     for @xmath58 , @xmath60 , @xmath64 , @xmath63 .",
    "there are several curves corresponding to different numbers of expected background events , @xmath51 .",
    "the smoothest curve is the coverage in the high statistics ( normal ) limit.,width=226 ]    it may be remarked that uncertainties in the background and/or scale factor help to obtain the desired coverage ( figs .",
    "[ fig : nm3 ] and  [ fig : nm4 ] ) .",
    "this is because they smooth out the effect of the discreteness of the poisson sampling space .     for @xmath58 , @xmath60 , @xmath64 , @xmath54 .",
    "there are several curves corresponding to different values of @xmath65 , becoming smoother as @xmath65 increases .",
    "the horizontal line is at 68%.,width=283 ]     and @xmath66 for @xmath67 , @xmath68 , @xmath69 , @xmath54 .",
    "there are several curves corresponding to different values of @xmath66 , becoming smoother as @xmath66 increases .",
    "the horizontal line is at 68%.,width=226 ]    one issue is when the coverage is deemed to be `` good enough '' .",
    "it might be suggested that if the coverage is known to be within some amount , say 5% of 68% , that this is good enough for anything we are going to use those numbers for .",
    "however , one could also decide to take a `` conservative '' approach , and insist that the coverage be at least at the quoted level .",
    "one way to accomplish this is to shift the value of @xmath56 .",
    "[ fig : nm5 ] shows the coverage as a function of expected background ( in the worst - case of zero signal branching fraction and @xmath69 ) for a value of @xmath70 .",
    "we see that at least 68% coverage is guaranteed as long as the mean background is greater than 1.4 .    ,",
    "@xmath58 , @xmath60 , @xmath69 .",
    "there are several curves corresponding to different values of @xmath65 , becoming smoother as @xmath65 increases .",
    "the horizontal line is at 68%.,width=226 ]    we ll conclude this discussion with a few summary remarks : first , it is a good idea to always quote @xmath71 , and @xmath72 .",
    "second , any approach used should be justified with a computation of the coverage .",
    "the likelihood analysis studied here works pretty well even down to rather low statistics for 68% confidence intervals .",
    "it should be kept in mind however that `` good enough '' for 68% intervals does not imply good enough for other purposes , such as tests of significance . finally , if @xmath73 or @xmath74 this is outside the regime studied here ; the normal assumption is likely invalid in this case .",
    "in the interpretation stage , bayesian intervals may be given , as deemed useful to the consumer .",
    "in babar practice , this is typically done when someone wants to give an upper limit , and is usually implemented with the assumption of a uniform prior in the parameter of interest .",
    "babar recognizes the issues surrounding the choice of prior .",
    "the recommendation is to consider it carefully , and to make checks on how sensitive the result is to the choice .",
    "even this recommendation is not routinely adopted however .",
    "the `` significance '' of an observation ( e.g. , of the presence of a signal for some process ) is defined as the probability of the observed deviation ( or larger ) from the null ( no signal ) model , under the null hypothesis .",
    "the recommended procedure in babar is to compute this probability according to the frequentist methodology .",
    "it may be noted that knowing the 68% confidence interval does not always provide much insight into the significance .",
    "the tails of the null sampling distribution may be non - normal . a separate analysis is generally required , in which the tails are appropriately modelled .",
    "no recommendation is tendered for when to label a result as `` significant '' .",
    "we struggled with possible algorithms , but eventually gave up , because such a label implies an interpretation .",
    "no uniform prescription seems to make sense ; judgement is involved .",
    "for example , deciding that the observation of a bizarre new particle is significant may involve a different standard than the claim that an expected decay mode of an established particle is significant .",
    "it is nt really our primary role as experimenters ; it is up to the reader ultimately to decide what they wish to believe .",
    "this is perhaps the least - accepted of the statistics working group s points in babar : people insist on making qualitative statements , e.g. , `` observation of '' , `` evidence for '' , `` discovery of '' , `` not significant '' , `` consistent with '' .",
    "a code exists in which `` observation of '' becomes quantified as @xmath75 significance , and `` evidence for '' means @xmath76 .",
    "this preoccupation with qualitative interpretive terminology is pervasive beyond babar .",
    "for example , the following excerpt appeared in physics today  @xcite , ( italics mine , references deleted ) :    .1 cm    0.3 cm",
    ".2 cm    for another example , some people think a measurement should not be called a `` measurement '' unless the result is significantly different from zero .",
    "an editor at a prominent journal has suggested that `` _ bounds on _ '' might be more appropriate than `` _ measurement _ '' in reference to a cp asymmetry angle which was observed as consistent with zero .",
    "this can lead to amusing ironies : finding @xmath77 would be an exciting contradiction with the standard model .",
    "but it is nt a `` measurement '' ?",
    "a further issue that arises is that many people mix the question of significance with the choice of interval ( i.e. , one - sided vs two - sided ) .",
    "this has a drawback , because basing how one quotes the interval based on the result of the measurement can introduce a bias .",
    "the algorithm of feldman and cousins  @xcite is designed to address this .",
    "however , this methodology is not adopted in babar because of the constraint on the physical region , as discussed earlier .",
    "instead , our recommendation is to always give a two - sided interval ( if otherwise appropriate ) , independent of the significance .",
    "the significance is quoted separately .",
    "quoting a one - sided interval may optionally also be done , and is usually regarded as part of the interpretation ( hence a bayesian approach is suggested ) .",
    "this recommendation is typically followed in babar , but there have been exceptions .",
    "another issue that arises in the quoting of significance has to do with the tradition of quoting significance as @xmath78 .",
    "unfortunately , this is used to mean different things : sometimes it actually means @xmath39 standard deviations .",
    "but sometimes it means the probability content of an @xmath78 fluctuation for a normal distribution .",
    "we recommend to quote directly the probability if the sampling distirbution is not normal .",
    "however , this has met with very limited implementation .",
    "babar makes many checks in a typical analysis .",
    "for the purpose of defining systematic uncertainties , we divide these into two broad categories :    1 .",
    "`` blind checks '' : this is a test for mistakes .",
    "no correction to the data is anticipated .",
    "if the test passes , then there is no contribution to the systematic error .",
    "an example of such a check is dividing the data into two chronological subsets and comparing the results .",
    "`` educated checks '' : this is a measurement of biases or corrections , and may affect the quoted result .",
    "it involves a contribution to the systematic error .",
    "an example is the model dependence of the efficiency calculation .",
    "it is recommended that the systematic uncertainty be quoted separately from the statistical uncertainty .",
    "the sources of systematic uncertainty should be described , and may contain statistical components , for example due to limited monte carlo statistics in the efficiency evaluation .",
    "we return to our earlier example ( sec .",
    "[ sec : dmix ] ) of @xmath10 mixing for an example of the treatment of systematic uncertainties .",
    "the goal here is to produce a two - dimensional confidence contour in the parameter space which incorporates the systematic uncertainites . in this case , the statistical uncertainties are large , and we are willing to accept an approximation in order to keep the procedure simple .",
    "thus , it is decided to use a method which takes the statistics - only contour and scales it uniformly along rays from the best fit value .",
    "the scaling factor is @xmath79 , where @xmath80 is an estimate of systematic uncertainty @xmath81 in units of the statistical uncertainty .",
    "this estimate is obtained by determining the effect of the systematic uncertainty on @xmath82 ( the position of the best fit ) .",
    "figure  [ fig : dmixsyst ] shows the result of this procedure .",
    "this method is conservative ( or lazy ) in the sense that scaling for a given systematic in one ( worst case ) direction is applied uniformly in all directions . on the other hand , by evaluating the error at the best fit position , a linear approximation is being made .     mixing .",
    "the filled dot is the location of the best fit point , @xmath83 , the open circle the best fit point in the physical region . the solid contour ( dotted if restricting to @xmath2 conserving models ) shows the 95% confidence contour according to statistical errors only .",
    "the dot - dash contour ( dash for @xmath2 conserving models ) shows how this contour becomes scaled on incorporating systematic uncertainties.,width=283 ]      there appears to be no perfect general goodness - of - fit test .",
    "given a dataset generated under the null hypothesis , one can usually find a test which rejects the null hypothesis ( and this may be taken as a warning that choosing the test after you see the data is dangerous ) .",
    "given a dataset generated under an alternative hypothesis , one can usually find a test for which the null passes .",
    "it seems advisable to think about what one wants to test for in choosing the test .",
    "for example , fig .",
    "[ fig : cpviol ] shows data used in a measurement of @xmath2 violation by babar . a likelihood ratio ( or a chi - square ) test of the time distribution may be a good test for the lifetime fit to the data , but it may have little sensitivity to testing the goodness - of - fit of the @xmath2 asymmetry , which is a low - fequency question .",
    "violation ( babar )  @xcite .",
    "the upper plot shows the measurement ( points ) of the time distributions for @xmath84 and @xmath85 decays to selected @xmath2 eigenstates .",
    "the curves show the result of a maximum likelihood fit to the data .",
    "the lower plot shows the time - dependent asymmetry between the @xmath84 and @xmath85 decays , again with the fitted curve overlaid",
    ". the asymmetry would be zero in the absence of @xmath2 violation.,width=321 ]    so far , babar generally uses likelihood ratio tests or chi - square tests if appropriate . the kolmogorov - smirnov test is also used .",
    "if a test statistic such as the likelihood ratio is used , then a monte carlo evaluation of the distribution of the statistic is recommended , rather than assuming an asymptotic property .",
    "babar has encountered several times the question of whether a new analysis is consistent with an old analysis . often , the new analysis is a combination of additional data plus changed ( improved ) analysis of original data .",
    "the stickiest issue is handling the correlation in testing for consistency in the overlapping data .",
    "people sometimes have difficulty understanding that statistical differences can arise even comparing results based on the same events , so we expound on this .    given a sampling @xmath86 from a bivariate normal distribution @xmath87 , with @xmath88 , the difference @xmath89 is @xmath90-distributed with @xmath91 .",
    "if the correlation is unknown , all we can say is that the variance of the difference is in the range @xmath92 .",
    "if we at least believe @xmath93 then the maximum variance of the difference is @xmath94 .",
    "suppose we measure a neutrino mass , @xmath14 , in a sample of @xmath95 independent events .",
    "the measurements are @xmath96 .",
    "assume the sampling distribution for @xmath97 is @xmath98 .",
    "we may form _ unbiased _ estimator , @xmath99 , for @xmath14 : @xmath100 the result ( from a monte carlo simulation ) is @xmath101",
    ".    then we notice that we have some further information which might be useful : we know the experimental resolutions , @xmath102 for each measurement .",
    "we form another _ unbiased _ estimator , @xmath103 , for @xmath14 : @xmath104 the result ( from the same simulation , i.e. , from the _ same events _ ) is @xmath105 .",
    "the results are certainly correlated , so the question of consistency arises ( we know the error on the difference is between 0.023 and 0.055 ) . in this example , the difference between the results is @xmath106 , where the @xmath107 error includes the correlation ( @xmath108 ) .",
    "art snyder has developed an approximate formula for evaluating the correlation in a comparison of maximum likelihood analyses .",
    "suppose we perform two maximum likelihood analysis , with event likelihoods @xmath109 , @xmath110 , on the same set of @xmath32 events [ n.b . , we may use different information in each analysis ] .",
    "the results are estimators @xmath111 , @xmath112 for parameter @xmath34 ( restricting to the one - dimensional case for simplicity ) .",
    "the correlation coefficient @xmath113 may be estimated according to :    @xmath114    where ( @xmath115 is an expansion reference point ) : @xmath116\\nonumber \\\\   & & \\hskip-.4cm\\left[1-(\\hat\\theta_2 - \\theta_0 ) { d^2\\ln{\\cal l}_{2i } \\over d\\theta^2}\\vert_{\\theta=\\theta_0}\\bigg/{d\\ln{\\cal l}_{2i } \\over d\\theta}\\vert_{\\theta=\\theta_0 } \\right].\\nonumber\\end{aligned}\\ ] ] if @xmath117 , then @xmath118 where @xmath119 .",
    "let us look at a real example of the consistency question in a babar analysis , the measurement of the @xmath2-violation parameter @xmath120 . in august 2001",
    ", we published a result based on a dataset of @xmath121 pairs  @xcite : @xmath122 an updated result was produced in march 2002 , based on @xmath123 pairs  @xcite : @xmath124 the second result includes the earlier data , re - reconstructed .",
    "the analysis is not simply counting events ; it involves multivariate maximum likelihood fits , reprocessing changes , and relative likelihoods for an event to be signal or background , for example .",
    "the question is , are the two results statistically consistent ?    if these were independent data sets , a difference of @xmath125 would not be a worry .",
    "the issue is the correlation . a specialized analysis deriving from eqn .",
    "[ eqn : consistency ] is performed on the events in common between the two analyses .",
    "a correlation of @xmath126 is deduced , yielding a difference of @xmath127 .",
    "this corresponds to a probability of 3% , which is small enough that we noticed , and looked hard for possible systematic problems , but not so small to be alarming , especially in an experiment with many such tests being made .",
    "there has been some impression that babar may be seeing more diffences between old vs updated results than people are used to , and the question arises whether babar is making mistakes .",
    "the answer to this seems to be , first of all , based on studies such as the above , there is no compelling statistical evidence to support the contention that mistakes are being made .",
    "there should be differences , purely due to statistical fluctuations , among results , and babar sees nothing clearly beyond what might be expected from statistics . the second part of the answer is a speculation to why the impression may exist .",
    "babar is different from most other experiments in that it makes extensive use of the blind methodology .",
    "there is little opportunity to react to observed differences with further changes in analysis . without using the blind methodology",
    ", there is the potential for bias , tending towards making results agree with earlier results better than they should .",
    "it is my observation that statistical sophistication in particle physics ( not specific to babar ) has grown significantly , not so much in the choice of methods , which are often long - established , but in the understanding attached to them .",
    "people now understand that there is a choice of approach between bayesian and frequency statistics , though there is yet no uniform agreement on adoption .",
    "there is also considerable awareness on the issue of biases in analyses , for example , babar now relies heavily on blind methodology .",
    "babar adopts frequency statistics for describing results , and much attention is devoted to monte carlo validation and verification of coverage .",
    "the use of the bayesian approach in high energy physics , including babar , is still not mature : there is no established methodology for choosing the prior distribution , other than to default on a uniform prior .",
    "the justification for this is basically that it usually does nt matter very much .",
    "there are , however , even issues still in frequency statistics .",
    "controversies involve such notions as restricting to the `` physical region '' , or that the presence of backgrounds should `` always '' lead to higher upper limits .",
    "both of these notions are not a concern in the babar recommendations .",
    "i would like to thank louis lyons for organizing an informative and stimulating conference .",
    "i am grateful to my collaborators on babar for many interesting discussions of statistical issues .",
    "work supported in part by department of energy grant de - fg03 - 92er40701 and contract de - ac03 - 76sf00515 ."
  ],
  "abstract_text": [
    "<S> the statistical methods used in deriving physics results in the babar collaboration are reviewed , with especial emphasis on areas where practice is not uniform in particle physics . </S>"
  ]
}