{
  "article_text": [
    "we consider the estimation problem of the unknown response function @xmath1 based on observations from the following noisy convolutions : @xmath2 where @xmath3 $ ] , @xmath4 , and @xmath5 $ ] . here",
    ", @xmath6 is assumed to be a two - dimensional gaussian white noise , that is , a generalized two - dimensional gaussian field with covariance function @xmath7 = \\delta(u_1-u_2 ) \\delta(t_1-t_2),\\ ] ] where @xmath8 denotes the dirac @xmath9-function , @xmath10 is assumed to be a known positive function , and @xmath11 with the blurring ( or kernel ) function @xmath12 in ( [ conv2 ] ) also assumed to be known . note that , since @xmath13 is assumed to be known , both sides of ( [ conv1 ] ) can be divided by @xmath13 leading to the equation @xmath14 where @xmath15 and @xmath16 .",
    "consequently , without loss of generality , we consider only the case when @xmath17 and thus , in what follows , we work with observations from model ( [ convcont ] ) .    the model ( [ convcont ] ) can be viewed as a _ functional deconvolution _ model .",
    "if @xmath18 , it reduces to the standard deconvolution model which attracted attention of a number of researchers . after a rather rapid progress in this problem in late 1980s to early 1990s , authors turned to wavelet solutions of the problem [ see , e.g. , donoho ( @xcite ) , abramovich and silverman ( @xcite ) , kalifa and mallat ( @xcite ) , johnstone , kerkyacharian , picard and raimondo ( @xcite ) , donoho and raimondo ( @xcite ) , johnstone and raimondo ( @xcite ) , neelamani , choi and baraniuk ( @xcite ) and kerkyacharian , picard and raimondo ( @xcite ) ] .",
    "the main effort was spent on producing adaptive wavelet estimators that are asymptotically optimal ( in the minimax sense ) , or near - optimal within a logarithmic factor , in a wide range of besov balls and under mild conditions on the blurring function .",
    "[ for related results on the density deconvolution problem , we refer to , e.g. , pensky and vidakovic ( @xcite ) , walter and shen ( @xcite ) , fan and koo ( @xcite ) . ]    on the other hand , the functional deconvolution model ( [ convcont ] ) can be viewed as a generalization of a multitude of inverse problems in mathematical physics where one needs to recover initial or boundary conditions on the basis of observations of a noisy solution of a partial differential equation .",
    "lattes and lions ( @xcite ) initiated research in the problem of recovering the initial condition for parabolic equations based on observations in a fixed - time strip .",
    "this problem and the problem of recovering the boundary condition for elliptic equations based on observations in an internal domain were studied in golubev and khasminskii ( @xcite ) ; the latter problem was also discussed in golubev ( @xcite ) . these and other specific models are discussed in section [ applic ] .",
    "consider now a discretization of the functional deconvolution model ( [ convcont ] ) when @xmath19 is observed at @xmath20 points @xmath21 , @xmath22 , @xmath23 , that is , @xmath24 where @xmath25 are standard gaussian random variables , independent for different @xmath26 and  @xmath27 . in this case , the functional deconvolution model ( [ convcont ] ) can also be viewed as a multichannel deconvolution problem considered in , for example , casey and walnut ( @xcite ) and de canditiis and pensky ( @xcite , @xcite ) ; this model is also discussed in section [ applic ] .",
    "note that using the same @xmath28 in ( [ convcont ] ) ( continuous model ) and ( [ convdis ] ) ( discrete model ) is not accidental . under the assumptions",
    "( [ cond1 ] ) and ( [ cond2 ] ) , the optimal ( in the minimax sense ) convergence rates in the discrete model are determined by the total number of observations , @xmath28 , and coincide with the optimal convergence rates in the continuous model .    in this paper",
    ", we consider functional deconvolution in a periodic setting , that is , we assume that , for fixed @xmath29 , @xmath1 and @xmath30 are periodic functions with period on the unit interval @xmath31 . note that the periodicity assumption appears naturally in the above mentioned special models which ( [ convcont ] ) and ( [ convdis ] ) generalize , and allows one to explore ideas considered in the above cited papers to the proposed functional deconvolution framework . moreover , not only for theoretical reasons but also for practical convenience",
    "[ see johnstone , kerkyacharian , picard and raimondo ( @xcite ) , sections 2.3 , 3.13.2 ] , we use band - limited wavelet bases , and in particular the periodized meyer wavelet basis for which fast algorithms exist [ see kolaczyk ( @xcite ) and donoho and raimondo ( @xcite ) ] .    in what follows , we derive minimax lower bounds for the @xmath0-risk in models ( [ convcont ] ) and ( [ convdis ] ) when @xmath1 is assumed to belong to a besov ball and @xmath32 is assumed to possess some smoothness properties , including both regular - smooth and super - smooth convolutions .",
    "furthermore , we propose an adaptive wavelet estimator of @xmath1 and show that this estimator is asymptotically optimal ( in the minimax sense ) , or near - optimal within a logarithmic factor , in a wide range of besov balls",
    ". we also compare models ( [ convcont ] ) and ( [ convdis ] ) , and investigate when the availability of continuous data gives advantages over observations at the asymptotically large number of points .    the paper is organized as follows . in section  [ estconstr ] , we describe the construction of a wavelet estimator of @xmath1 for both the continuous model ( [ convcont ] ) and the discrete model ( [ convdis ] ) . in section  [ lowbounds ] , we derive minimax lower bounds for the @xmath0-risk , based on observations from either the continuous model ( [ convcont ] ) or the discrete model ( [ convdis ] ) , when @xmath1 is assumed to belong to a besov ball and @xmath32 is assumed to possess some smoothness properties , including both regular - smooth and super - smooth convolutions . in section  [ upbounds ] , we demonstrate that the wavelet estimator derived in section [ estconstr ] is adaptive and asymptotically optimal ( in the minimax sense ) , or near - optimal within a logarithmic factor , in a wide range of besov balls . in section  [ applic ] ,",
    "we discuss particular examples for both continuous and discrete settings .",
    "we conclude in section  [ discrcont ] with a discussion on the interplay between continuous and discrete models . finally , in section  [ append ] , we provide some auxiliary statements as well as the proofs of the theoretical results obtained in the earlier sections .",
    "let @xmath33 and @xmath34 be the meyer scaling and mother wavelet functions , respectively [ see , e.g. , meyer ( @xcite ) or mallat ( @xcite ) ] . as usual , @xmath35 are , respectively , the dilated and translated meyer scaling and wavelet functions at resolution level @xmath36 and scale position @xmath37 .",
    "( here , and in what follows , @xmath38 refers to the set of integers . ) similarly to section 2.3 in johnstone , kerkyacharian , picard and raimondo ( @xcite ) , we obtain a periodized version of meyer wavelet basis by periodizing the basis functions @xmath39 , that is , @xmath40    in what follows , @xmath41 denotes the inner product in the hilbert space @xmath42 ( the space of squared - integrable functions defined on the unit interval @xmath31 ) , that is , @xmath43 for @xmath44 .",
    "[ here , and in what follows , @xmath45 ( resp .",
    "@xmath46 ) denotes the conjugate of the complex function @xmath47 ( resp .",
    "complex number @xmath48 ) ; @xmath47 ( resp .",
    "@xmath48 ) is real if and only if @xmath49 ( resp .",
    "@xmath50 ) . ]",
    "let @xmath51 , @xmath52 , and , for any ( primary resolution level ) @xmath53 and any @xmath54 , let @xmath55 be the fourier coefficients of @xmath56 , @xmath57 and @xmath1 , respectively .",
    "denote @xmath58 for each @xmath29 , denote the functional fourier coefficients by @xmath59    if we have the continuous model ( [ convcont ] ) , then , by using properties of the fourier transform , for each @xmath29 , we have @xmath60 and @xmath61 where @xmath62 are generalized one - dimensional gaussian processes such that @xmath63 = \\delta_{m_1,m_2 } \\delta(u_1-u_2),\\ ] ] where @xmath64 is kronecker s delta . in order to find the functional fourier coefficients @xmath65 of @xmath1 ,",
    "we multiply both sides of ( [ finaleq ] ) by @xmath66 and integrate over @xmath29 .",
    "the latter yields the following estimators of @xmath65 : @xmath67 [ here , we adopt the convention that when @xmath18 the estimator @xmath68 takes the form @xmath69 . ]",
    "if we have the discrete model ( [ convdis ] ) , then , by using properties of the discrete fourier transform , for each @xmath70 , ( [ finaleq ] ) takes the form @xmath71 where @xmath72 are standard gaussian random variables , independent for different @xmath73 and @xmath26 .",
    "similarly to the continuous case , we multiply both sides of ( [ finaleqdis ] ) by @xmath74 and add them together to obtain the following estimators of @xmath65 : @xmath75 [ here , and in what follows , we abuse notation and @xmath65 refers to both functional fourier coefficients and their discrete counterparts .",
    "note also that @xmath76 , @xmath77 and @xmath72 are , respectively , the discrete versions of the functional fourier coefficients @xmath78 , @xmath79 and @xmath62 . ]    note that , using the periodized meyer wavelet basis described above and for any @xmath53 , any ( periodic ) @xmath80 can be expanded as @xmath81 furthermore , by plancherel s formula , the scaling coefficients , @xmath82 , and the wavelet coefficients , @xmath83 , of @xmath1 can be represented as @xmath84 where @xmath85 and , for any @xmath54 , @xmath86 , both subsets of @xmath87 \\cup [ 2^j , 2^{j+2}]$ ] , due to the fact that meyer wavelets are band - limited [ see , e.g. , johnstone , kerkyacharian , picard and raimondo ( @xcite ) , section 3.1 ] .",
    "we naturally estimate @xmath88 and @xmath89 by substituting @xmath65 in ( [ alkandblk ] ) with ( [ fmexprc ] ) or ( [ fmexprd ] ) , that is , @xmath90    we now construct a block thresholding wavelet estimator of @xmath1 . for this purpose",
    ", we divide the wavelet coefficients at each resolution level into blocks of length @xmath91 .",
    "let @xmath92 and @xmath93 be the following sets of indices : @xmath94 denote @xmath95 finally , for any @xmath53 , we reconstruct @xmath1 as @xmath96 where @xmath97 is the indicator function of the set @xmath98 , and the resolution levels @xmath99 and @xmath100 and the thresholds @xmath101 will be defined in section  [ upbounds ] .    in what follows",
    ", we use the symbol @xmath102 for a generic positive constant , independent of @xmath28 , which may take different values at different places .",
    "among the various characterizations of besov spaces for periodic functions defined on @xmath103 in terms of wavelet bases , we recall that for an @xmath104-regular multiresolution analysis with @xmath105 and for a besov ball @xmath106 of radius @xmath107 with @xmath108 , one has that , with @xmath109 , @xmath110\\\\[-8pt ] & & \\phantom{\\biggl\\ { f(\\cdot ) \\in l^2(t)\\dvtx } { } +   \\biggl ( \\sum_{j = j_0}^{\\infty } 2^{js'q }   \\biggl ( { \\sum_{k=0}^{2^j-1}}|{b_{jk}}|^p   \\biggr)^{q / p }   \\biggr)^{{1/q } } \\leq a   \\biggr\\},\\nonumber\\end{aligned}\\ ] ] with respective sum(s ) replaced by maximum if @xmath111 or @xmath112 [ see , e.g. , johnstone , kerkyacharian , picard and raimondo ( @xcite ) , section 2.4 ] .",
    "( note that , for the meyer wavelet basis , considered in section [ estconstr ] , @xmath113 . )",
    "we construct below minimax lower bounds for the @xmath0-risk , for both the continuous model ( [ convcont ] ) and the discrete model ( [ convdis ] ) . for this purpose",
    ", we define the minimax @xmath0-risk over the set @xmath114 as @xmath115 where @xmath116 is the @xmath0-norm of a function @xmath117 and the infimum is taken over all possible estimators @xmath118 ( measurable functions taking their values in a set containing  @xmath114 ) of @xmath1 , based on observations from either the continuous model ( [ convcont ] ) or the discrete model ( [ convdis ] ) . [ here , and in what follows , the expectation is taken under the true @xmath1 , and it is assumed that the function class @xmath114 contains @xmath1 . ]    in what follows , we shall evaluate a lower bound for @xmath119 .",
    "denote @xmath120 and , for @xmath121 , define @xmath122 [ here , we adopt the convention that when @xmath18 , @xmath123 takes the form @xmath124 , @xmath121 . ]",
    "assume that for some constants @xmath125 , @xmath126 , @xmath127 and @xmath128 , independent of @xmath73 , the choice of @xmath129 and the selection points @xmath130 , @xmath70 , @xmath131 [ following fan ( @xcite ) , we say that the function @xmath32 is _ regular - smooth _ if @xmath132 and is _ super - smooth _ if @xmath133 . ]",
    "the following statement provides the minimax lower bounds for the @xmath0-risk .",
    "[ th : lower ] let @xmath134 be the periodic meyer wavelet basis discussed in section [ estconstr ] .",
    "let @xmath135 , @xmath136 , @xmath137 and @xmath107 . then",
    ", under the assumption ( [ cond1 ] ) , as @xmath138 , @xmath139    the two different lower bounds for @xmath132 in ( [ low1 ] ) refer to the dense case @xmath140 $ ] when the worst functions @xmath1 ( i.e. , the hardest functions to estimate ) are spread uniformly over the unit interval @xmath31 , and the sparse case @xmath141 $ ] when the worst functions @xmath1 have only one nonvanishing wavelet coefficient .",
    "note also that the restriction @xmath142 , @xmath143 and @xmath144 ensures that the corresponding besov spaces are embedded in @xmath42 .",
    "recall ( [ cond1 ] ) from section [ lowbounds ] , and assume further that for the constants @xmath125 , @xmath126 and @xmath127 , and for a constant @xmath145 , independent of @xmath73 , the choice of @xmath129 and the selection points @xmath130 , @xmath70 , with @xmath146 , @xmath147 for any @xmath54 , let @xmath148 be the cardinality of the set @xmath149 ; note that , for meyer wavelets , @xmath150 [ see , e.g. , johnstone , kerkyacharian , picard and raimondo ( @xcite ) , page 565 ] . let also @xmath151^{-2 \\kappa } , \\qquad \\kappa=1,2.\\ ] ] then , direct calculations yield that @xmath152 [ note that since the functional fourier coefficients @xmath153 are known , the positive constants @xmath154 and @xmath155 in ( [ delta1 ] ) can be evaluated explicitly . ]",
    "consider now the two cases @xmath132 ( regular - smooth ) and @xmath133 ( super - smooth ) separately .",
    "choose @xmath156 and @xmath100 such that @xmath157 [ since @xmath158 when @xmath133 , the wavelet estimator ( [ fest ] ) only consists of the first ( linear ) part and , hence , @xmath159 does not need to be selected in this case .",
    "] set , for some positive constant @xmath160 , @xmath161 note that the choices of @xmath156 , @xmath100 and @xmath159 are independent of the parameters , @xmath162 , @xmath163 , @xmath164 and @xmath98 ( that are usually unknown in practical situations ) of the besov ball @xmath106 ; hence , the wavelet estimator ( [ fest ] ) is adaptive with respect to these parameters .",
    "the proof of the minimax upper bounds for the @xmath0-risk is based on the following two lemmas .",
    "[ l : coef ] let the assumption ( [ cond2 ] ) be valid , and let the estimators @xmath165 and @xmath166 of the scaling and wavelet coefficients @xmath88 and @xmath89 , respectively , be given by the formula ( [ coefest ] ) with @xmath68 defined by ( [ fmexprc ] ) in the continuous model and by ( [ fmexprd ] ) in the discrete model . then , for @xmath121 , and for all @xmath54 , @xmath167 moreover , under the assumptions ( [ cond1 ] ) and ( [ cond2 ] ) with @xmath168 , for all @xmath54 , @xmath169 for any @xmath170 .",
    "[ l : deviation ] let the estimators @xmath166 of the wavelet coefficients @xmath89 be given by the formula ( [ coefest ] ) with @xmath68 defined by ( [ fmexprc ] ) in the continuous model and by ( [ fmexprd ] ) in the discrete model . if @xmath171 is a positive constant large enough and @xmath132 in the assumption ( [ cond2 ] ) , then , for all @xmath54 , @xmath172 for any @xmath170",
    ".    lemmas [ l : coef ] and [ l : deviation ] allow to state the following minimax upper bounds for the @xmath0-risk of the wavelet estimator @xmath173 defined by ( [ fest ] ) , with @xmath156 and @xmath100 given by ( [ jpower ] ) ( if @xmath174 ) or ( [ jexp ] ) ( if @xmath133 ) . set @xmath175 , and define @xmath176    [ th : upper ] let @xmath173 be the wavelet estimator defined by ( [ fest ] ) , with @xmath156 and @xmath100 given by ( [ jpower ] ) ( if @xmath174 ) or ( [ jexp ] ) ( if @xmath133 ) .",
    "let @xmath177 , @xmath136 , @xmath178 and @xmath107 . then , under the assumption ( [ cond2 ] ) , as @xmath179 , @xmath180    in the discrete model , assumptions ( [ cond1 ] ) and ( [ cond2 ] ) require the value of @xmath181 to be independent of the choice of @xmath129 and the selection of points @xmath130 , @xmath182 .",
    "if assumptions ( [ cond1 ] ) and ( [ cond2 ] ) hold , then the minimax convergence rates in discrete and continuous models coincide and are independent of the configuration of the points @xmath130 , @xmath183 . moreover , the wavelet estimator ( [ fest ] ) is asymptotically optimal ( in the minimax sense ) no matter what the value of @xmath129 is .",
    "it is quite possible , however , that in the discrete model , conditions ( [ cond1 ] ) and ( [ cond2 ] ) both hold but with different values of @xmath184 , @xmath185 and @xmath186 . in this case , the upper bounds for the risk in the discrete model may not coincide with the lower bounds and with the minimax convergence rates in the continuous model . proposition [ th : condisrates ] in section [ discrcont ] provides sufficient conditions for the minimax convergence rates in discrete and continuous models to coincide and to be independent of @xmath129 and the configuration of the points @xmath130 , @xmath182 .",
    "these conditions also guarantee asymptotical optimality of the wavelet estimator ( [ fest ] ) , and can be viewed as some kind of uniformity conditions .",
    "if conditions of proposition [ th : condisrates ] are violated , then the rates of convergence in the discrete model depend on the choice of @xmath129 and @xmath130 , @xmath182 , and some recommendations on their selection should be given .",
    "furthermore , optimality issues become much more complex when @xmath181 is not uniformly bounded from above and below ( see the discussion in section [ discrcont ] ) .",
    "theorems [ th : lower ] and [ th : upper ] imply that , for the @xmath0-risk , the wavelet estimator @xmath173 defined by ( [ fest ] ) is asymptotically optimal ( in the minimax sense ) , or near - optimal within a logarithmic factor , over a wide range of besov balls @xmath106 of radius @xmath107 with @xmath187 , @xmath136 and @xmath188 . in particular , in the cases when ( 1 ) @xmath189 , ( 2 ) @xmath132 , @xmath190 and @xmath191 , ( 3 )  @xmath132 , @xmath192 , and ( 4 ) @xmath132 , @xmath193 and @xmath194 , the estimator ( [ fest ] ) is asymptotically optimal ( lower and upper bounds coincide up to a multiplicative constant ) , that is , @xmath195 on the other hand , in the case when @xmath132 , @xmath196 and @xmath197 or @xmath132 , @xmath193 and @xmath198 , the wavelet estimator @xmath173 defined by ( [ fest ] ) is asymptotically near - optimal within a logarithmic factor , that is , @xmath199 [ here , and in what follows , @xmath200 denotes @xmath201 as @xmath202 . ]    for the @xmath0-risk , the upper bounds ( [ up ] ) are tighter than those obtained by chesneau ( @xcite ) for the regular - smooth case [ i.e. , @xmath168 in ( [ cond1 ] ) and ( [ cond2 ] ) ] in the case of the standard deconvolution model [ i.e. , when @xmath18 in ( [ convcont ] ) ] , although the difference is only in the logarithmic factors .",
    "more specifically , the following minimax upper bounds obtained in chesneau ( @xcite ) for the @xmath0-risk , as @xmath179 : @xmath203 where @xmath204 [ here , and in what follows , @xmath97 is the indicator function of the set @xmath98 . ]",
    "note that when @xmath205 , @xmath206 , and only the dense case appears ; hence , in this case , the dense cases and the corresponding convergence rates in the minimax upper bounds given by ( [ rovalue])([up ] ) and ( [ eq : chesfff])([rostarvalue ] ) coincide since @xmath207 . on the other hand , when @xmath208 , @xmath209 , both the dense and sparse cases appear ; hence , in this case , both the dense and sparse cases and the corresponding convergence rates in the minimax upper bounds given by ( [ rovalue])([up ] ) and ( [ eq : chesfff])([rostarvalue ] ) coincide .",
    "looking now at ( [ rovalue ] ) and ( [ rostarvalue ] ) , we see that @xmath210 only when @xmath211 .",
    "on the other hand , @xmath212 when @xmath197 and @xmath213 since @xmath214 , and it is obvious that @xmath212 when @xmath215 .",
    "however , we believe that the slight superiority in the minimax convergence rates for the @xmath0-risk obtained in theorems [ th : lower ] and [ th : upper ] is due not to a different construction of the wavelet estimator but to a somewhat different way of evaluating the minimax upper bounds .    unlike chesneau ( @xcite ) who only considered minimax upper bounds for the regular - smooth case [ i.e. , @xmath168 in ( [ cond1 ] ) and ( [ cond2 ] ) ] in the standard deconvolution model [ i.e. , when @xmath18 in ( [ convcont ] ) ] , theorems [ th : lower ] and [ th : upper ] provide minimax lower and upper bounds ( in the @xmath0-risk ) for both regular - smooth and super - smooth convolutions [ i.e. , @xmath216 in ( [ cond1 ] ) and ( [ cond2 ] ) ] , not only for the standard deconvolution model but also for its discrete counterpart [ i.e. , when @xmath217 in ( [ convdis ] ) ] .    the wavelet estimator @xmath173 defined by ( [ fest ] ) is adaptive with respect to the unknown parameters @xmath162 , @xmath163 , @xmath164 and @xmath98 of the besov ball @xmath106 but is not adaptive with respect to the parameters @xmath218 , @xmath186 and @xmath184 in ( [ cond1 ] ) and ( [ cond2 ] ) .",
    "it seems that it is impossible to achieve adaptivity with respect to @xmath186 in the super - smooth case ( @xmath219 ) because of the very fast exponential growth of the variance .",
    "however , in the regular - smooth case ( @xmath132 ) , one can construct a wavelet estimator which is adaptive with respect to the unknown parameter @xmath184 .",
    "choose @xmath156 and @xmath100 such that @xmath220 and @xmath221 , and set @xmath222 , where @xmath223 is large enough .",
    "note that @xmath224 can be calculated whenever the functional fourier coefficients @xmath225 are available .",
    "also , @xmath226 for some positive constants @xmath227 and @xmath228 which depend on the particular values of the constants in the conditions ( [ cond1 ] ) and ( [ cond2 ] ) .",
    "therefore , in this situation , by repeating the proof of theorem [ th : upper ] with these new values of the parameters involved , one can easily verify that the optimal convergence rates in theorem [ th : upper ] still hold as long as @xmath223 is large enough .",
    "how large should be `` large enough '' ?",
    "direct calculations show that @xmath223 should be such that @xmath229 .",
    "since @xmath227 , @xmath228 and @xmath184 are unknown , it is impossible to evaluate the lower bound for @xmath223 .",
    "however , one can replace @xmath223 by a slow - growing function of @xmath28 , say @xmath230 , leading to , at most , an extra @xmath230 factor in the obtained maximal @xmath0-risk .",
    "we finally note that , although we have only considered @xmath0-risks in our analysis , the results obtained in theorems [ th : lower ] and [ th : upper ] can be extended to the case of @xmath231-risks ( @xmath232 ) .",
    "analogous statements to the ones given in theorems [ th : lower ] and [ th : upper ] but for a wider variety of risk functions can be obtained using the unconditionality and temlyakov properties of meyer wavelets [ see , e.g. , johnstone , kerkyacharian , picard and raimondo ( @xcite ) , appendices a and b ] .",
    "the details in the derivation of these statements should , however , be carefully addressed .",
    "the functional deconvolution model ( [ convcont ] ) can be viewed as a generalization of a multitude of inverse problems in mathematical physics where one needs to recover initial or boundary conditions on the basis of observations of a noisy solution of a partial differential equation .",
    "lattes and lions ( @xcite ) initiated research in the problem of recovering the initial condition for parabolic equations based on observations in a fixed - time strip .",
    "this problem and the problem of recovering the boundary condition for elliptic equations based on observations in an internal domain were studied in golubev and khasminskii ( @xcite ) . more specifically , by studying separately the heat conductivity equation or the laplace equation on the unit circle , and assuming that the unknown initial or boundary condition belongs to a sobolev ball , golubev and khasminskii ( @xcite ) obtained some _ linear _ and _ nonadaptive _ solutions to the particular problem at hand ; see also golubev ( @xcite ) for a linear adaptive estimator for the laplace equation on the circle based on the principle of minimization of penalized empirical risk .",
    "we also note that , unlike golubev and khasminskii ( @xcite ) and golubev ( @xcite ) who considered sharp asymptotics , we focus our study on rate optimality results .",
    "[ note that the estimation of the unknown initial condition for the heat conductivity equation , allowing also for missing data , has been recently considered by hesse ( @xcite ) ; however , this latter paper deals with the density deconvolution model and the approach given therein varies from the approach of golubev and khasminskii ( @xcite ) and golubev ( @xcite ) , and it seems to be having a different agenda . ]    in view of the general framework developed in this paper , however , the inverse problems mentioned above can all be expressed as a functional deconvolution problem , so that all techniques studied in sections  [ estconstr][upbounds ] can be directly applied , to obtain _",
    "linear_/_nonlinear _ and _ adaptive _ solutions over a wide range of besov balls . such solutions are provided in examples [ ex1][exam4 ] below which discuss some of the most common inverse problems in mathematical physics which have already been studied as well as some other problems which , to the best of our knowledge , have not yet been addressed .    on the other hand , in the case when the functional deconvolution model ( [ convcont ] ) is observed at a finite number of distinct points [ see ( [ convdis ] ) ] , it can also be viewed as a multichannel deconvolution model studied in de canditiis and pensky ( @xcite , @xcite ) .",
    "example [ ex5 ] below deals with this model , providing the minimax convergence rates ( in the @xmath0-risk ) for regular - smooth [ i.e. , @xmath168 in ( [ cond1 ] ) and ( [ cond2 ] ) ] and super - smooth [ i.e. , @xmath216 in ( [ cond1 ] ) and ( [ cond2 ] ) ] convolutions , and also discussing the case when @xmath129 can increase together with @xmath233 ; both of these aspects were lacking from the theoretical analysis described in de canditiis and pensky ( @xcite ) .    [ ex1 ] let @xmath234 be a solution of the heat conductivity equation @xmath235,\\    t \\in[a , b ] ,",
    "\\    a>0,\\ b < \\infty,\\ ] ] with initial condition @xmath236 and periodic boundary conditions @xmath237    we assume that a noisy solution @xmath238 is observed , where @xmath239 is a generalized two - dimensional gaussian field with covariance function @xmath240 = \\delta(t_1-t_2 ) \\delta(x_1-x_2)$ ] , and the goal is to recover the initial condition @xmath1 on the basis of observations @xmath241 .",
    "this problem was considered by lattes and lions ( @xcite ) and golubev and khasminskii ( @xcite ) .",
    "it is well known [ see , e.g. , strauss ( @xcite ) , page 48 ] that , in a periodic setting , the solution @xmath234 can be written as @xmath242 it is easy to see that ( [ heat ] ) coincides with ( [ funh ] ) with @xmath243 and @xmath244 replaced by @xmath245 and @xmath243 , respectively , and that @xmath246 applying the theory developed in sections  [ estconstr][upbounds ] , we obtain functional fourier coefficients @xmath153 satisfying @xmath247 , and @xmath248 so that @xmath249 , @xmath250 and @xmath251 in both ( [ cond1 ] ) and ( [ cond2 ] ) .    hence , one can construct an adaptive wavelet estimator of the form ( [ fest ] ) , with @xmath156 and @xmath100 given by ( [ jexp ] ) , which achieves minimax ( in the @xmath0-risk ) convergence rate of order @xmath252 over besov balls @xmath253 of radius @xmath107 with @xmath254 , @xmath136 and @xmath137 .    [ ex2 ]",
    "let @xmath255 be a solution of the dirichlet problem of the laplacian on a region @xmath256 on the plane @xmath257 with a boundary @xmath258 and boundary condition @xmath259 consider the situation when @xmath256 is the unit circle .",
    "then , it is advantageous to rewrite the function @xmath260 in polar coordinates as @xmath261 , where @xmath262 $ ] is the polar radius and @xmath263 $ ] is the polar angle .",
    "then , the boundary condition in ( [ eqfffboun ] ) can be presented as @xmath264 , and @xmath265 and @xmath1 are periodic functions of @xmath243 with period @xmath266 .",
    "suppose that only a noisy version @xmath267 is observed , where @xmath268 is as in example [ ex1 ] , and that observations are available only on the interior of the unit circle with @xmath269 $ ] , @xmath270 , that is , @xmath271 , @xmath272 .",
    "the goal is to recover the boundary condition @xmath1 on the basis of observations @xmath19 .",
    "this problem was investigated in golubev and khasminskii ( @xcite ) and golubev ( @xcite ) .",
    "it is well known [ see , e.g. , strauss ( @xcite ) , page 161 ] that the solution @xmath273 can be written as @xmath274 applying the theory developed in sections  [ estconstr][upbounds ] with @xmath275 and @xmath276 we obtain functional fourier coefficients @xmath153 satisfying @xmath277 , and @xmath278 so that @xmath279 , @xmath280 and @xmath281 in both ( [ cond1 ] ) and ( [ cond2 ] ) .    hence , one can construct an adaptive wavelet estimator of the form ( [ fest ] ) , with @xmath156 and @xmath100 given by ( [ jexp ] ) , which achieves minimax ( in the @xmath0-risk ) convergence rate of order @xmath282 over besov balls @xmath253 of radius @xmath107 with @xmath187 , @xmath136 and @xmath283 .",
    "[ ex3 ] consider the problem ( [ laplace])([eqfffboun ] ) in example  [ ex2 ] above , with the region @xmath256 being now a rectangle , that is , @xmath284 \\times[a , b]$ ] , @xmath285 , @xmath286 , and periodic boundary conditions @xmath287 again , suppose that only a noisy version @xmath288 is observed , where @xmath289 is as in example [ ex1 ] , for @xmath290 $ ] , @xmath291 $ ] , and the goal is to recover the boundary condition @xmath1 on the basis of observations @xmath292 .",
    "it is well known [ see , e.g. , strauss ( @xcite ) , pages 188 , 407 ] that , in a periodic setting , the solution @xmath255 can be written as @xmath293 it is easy to see that ( [ fanisex3 ] ) coincides with ( [ funh ] ) with @xmath244 and @xmath294 replaced by @xmath243 and @xmath245 , respectively , and that @xmath295 applying the theory developed in sections  [ estconstr][upbounds ] , we obtain functional fourier coefficients @xmath153 satisfying @xmath296 , and @xmath297 so that @xmath298 , @xmath299 and @xmath281 in both ( [ cond1 ] ) and ( [ cond2 ] ) .    hence , one can construct an adaptive wavelet estimator of the form ( [ fest ] ) , with @xmath156 and @xmath100 given by ( [ jexp ] ) , which achieves minimax ( in the @xmath0-risk ) convergence rate of order @xmath282 over besov balls @xmath253 of radius @xmath107 with @xmath187 , @xmath136 and @xmath283 .    [ exam4 ]",
    "let @xmath234 be a solution of the wave equation @xmath300 with initial ",
    "boundary conditions @xmath301 here , @xmath1 is a function defined on the unit interval @xmath302 $ ] , and the objective is to recover @xmath1 on the basis of observing a noisy solution @xmath238 , where @xmath239 is as in example [ ex1 ] , with @xmath303 $ ] , @xmath304 , @xmath305 .    extending @xmath1 periodically over the real line , it is well known that the solution @xmath234 can then be recovered as [ see , e.g. , strauss ( @xcite ) , page 61 ] @xmath306 so that ( [ wav1 ] ) is of the form ( [ funh ] ) with @xmath307 ( a boxcar - like kernel for each fixed @xmath245 ) , where @xmath245 in ( [ funh ] ) is replaced by @xmath243 in ( [ wav1 ] ) .",
    "applying the theory developed in sections  [ estconstr][upbounds ] , with @xmath243 and @xmath244 replaced by @xmath245 and @xmath243 , respectively , we obtain functional fourier coefficients @xmath153 satisfying @xmath308 , and @xmath309\\\\[-8pt ] & = & \\frac{1}{4\\pi^2 m^2 }   \\biggl(\\frac{b - a}{2 } + \\frac{\\sin(4\\pi m a ) - \\sin(4\\pi m b)}{8 \\pi m } \\biggr).\\nonumber\\end{aligned}\\ ] ] observe that the integral in ( [ ex4 ] ) is always positive , bounded from above by @xmath310 and from below by @xmath311 $ ] , so that @xmath249 and @xmath132 in both ( [ cond1 ] ) and ( [ cond2 ] ) .",
    "hence , one can construct an adaptive block thresholding wavelet estimator of the form ( [ fest ] ) , with @xmath156 and @xmath100 given by ( [ jpower ] ) , which achieves the following minimax upper bounds ( in the @xmath0-risk ) : @xmath312 over besov balls @xmath253 of radius @xmath107 with @xmath177 , @xmath313 and @xmath137 , where @xmath314 if @xmath315 , @xmath316 if @xmath317 and @xmath318 if @xmath319 . [ the minimax lower bounds ( in the @xmath0-risk ) have the same form with @xmath320 . ]    [ ex5 ] consider the problem of recovering @xmath80 on the basis of observing the following noisy convolutions with known blurring functions @xmath321 @xmath322 here , @xmath323 are known positive constants and @xmath324 are independent standard wiener processes .",
    "the problem of considering systems of convolution equations was first considered by casey and walnut ( @xcite ) in order to evade the ill - posedness of the standard deconvolution problem , and was adapted for statistical use ( in the density deconvolution model ) by pensky and zayed ( @xcite ) .",
    "wavelet solutions to the problem ( [ multchan ] ) were investigated by de canditiis and pensky ( @xcite , @xcite ) .    note",
    "that deconvolution is the common problem in many areas of signal and image processing which include , for instance , lidar ( light detection and ranging ) remote sensing and reconstruction of blurred images .",
    "lidar is a laser device which emits pulses , reflections of which are gathered by a telescope aligned with the laser [ see , e.g. , park , dho and kong ( @xcite ) and harsdorf and reuter ( @xcite ) ] .",
    "the return signal is used to determine distance and the position of the reflecting material .",
    "however , if the system response function of the lidar is longer than the time resolution interval , then the measured lidar signal is blurred and the effective accuracy of the lidar decreases . if @xmath129 ( @xmath325 ) lidar devices are used to recover a signal , then we talk about a multichannel deconvolution problem .",
    "note that a discretization of ( [ multchan ] ) ( with @xmath326 for @xmath70 ) leads to the discrete setup ( [ convdis ] ) .",
    "adaptive term by term wavelet thresholding estimators for the model ( [ multchan ] ) were constructed in de canditiis and pensky ( @xcite ) for regular - smooth convolutions [ i.e. , @xmath168 in ( [ cond1 ] ) and ( [ cond2 ] ) ] . however , minimax lower and upper bounds were not obtained by these authors who concentrated instead on upper bounds ( in the @xmath231-risk , @xmath327 ) for the error , for a fixed response function .",
    "moreover , the case of super - smooth convolutions [ i.e. , @xmath216 in ( [ cond1 ] ) and ( [ cond2 ] ) ] and the case when @xmath328 have not been treated in de canditiis and pensky ( @xcite ) .",
    "let us now discuss the regular - smooth convolution case treated in de canditiis and pensky ( @xcite ) , that is , the case when ( in our notation ) @xmath329 with @xmath330 , @xmath70 .",
    "if @xmath129 is fixed , then @xmath331 where @xmath332 and @xmath333 , @xmath70 .",
    "hence , the minimax rates of convergence ( in the @xmath0-risk ) are determined by @xmath334 only , meaning that one can just rely on the best possible channel and disregard all the others .",
    "however , the latter is no longer true if @xmath328 . in this case , the minimax rates of convergence ( in the @xmath0-risk ) are determined by @xmath335 which may not be a function of @xmath334 only .",
    "consider now the adaptive block thresholding wavelet estimator @xmath173 defined by ( [ fest ] ) for the model ( [ multchan ] ) @xmath326 for @xmath70 or its discrete counterpart ( [ convdis ] ) .",
    "then , for the @xmath0-risk , under the assumption ( [ cond1 ] ) , the corresponding minimax lower bounds are given by theorem [ th : lower ] , while , under the assumption ( [ cond2 ] ) , the corresponding minimax upper bounds are given by theorem [ th : upper ] .",
    "thus , the proposed functional deconvolution methodology significantly expands on the theoretical findings in de canditiis and pensky ( @xcite ) .",
    "the minimax convergence rates ( in the @xmath0-risk ) in the discrete model depend on two aspects : the total number of observations @xmath336 and the behavior of @xmath335 defined in ( [ taum ] ) . in the continuous model , the values of @xmath335 are fixed ; however , in the discrete model they may depend on the choice of @xmath129 and the selection of points @xmath130 , @xmath22 . let us now explore when and how this can happen .",
    "assume that there exist points @xmath337 $ ] , @xmath338 ( with @xmath339 in the continuous model while @xmath18 is possible in the discrete model ) , such that @xmath340 and @xmath341 .",
    "( obviously , this is true if the functional fourier coefficients @xmath153 are continuous functions on the compact interval @xmath342 $ ] . ) in this case , we have @xmath343 and @xmath344 , where @xmath345 in the continuous model and @xmath346 in the discrete model .",
    "assume also that we can observe @xmath19 at the points @xmath347 and @xmath348 .",
    "the following statement presents the case when the minimax convergence rates can not be influenced by the choice of @xmath129 and the selection of points @xmath130 , @xmath70 .",
    "[ th : condisrates ] let there exist constants @xmath349 , @xmath350 , @xmath351 , @xmath352 , @xmath353 , @xmath354 , @xmath355 and @xmath356 , independent of @xmath73 , such that @xmath357 where either @xmath358 and @xmath359 or @xmath360 and @xmath361",
    ". then , the minimax convergence rates obtained in theorems [ th : lower ] and [ th : upper ] in the discrete model are independent of the choice of @xmath129 and the selection of points @xmath130 , @xmath70 , and , hence , coincide with the minimax convergence rates obtained in theorems  [ th : lower ]  and  [ th : upper ] in the continuous model .    the validity of proposition [ th : condisrates ] follows trivially from the lower and upper bounds obtained in theorems [ th : lower ] and [ th : upper ] .",
    "proposition [ th : condisrates ] simply states that asymptotically ( up to a constant factor ) it makes absolutely no difference whether one samples ( [ convdis ] ) @xmath28 times at one point , say , @xmath362 or , say , @xmath363 times at @xmath364 points @xmath130 . in other words ,",
    "asymptotically ( up to a constant factor ) each sample value @xmath365 , @xmath22 , @xmath23 , gives the same amount of information and the minimax convergence rates are not sensitive to the choice of @xmath129 and the selection of points @xmath130 , @xmath70 .",
    "the constants in theorem [ th : upper ] will , of course , reflect the difference and will be the smallest if one samples ( [ convdis ] ) @xmath28 times at @xmath348 .    however , conditions ( [ disconfanis])([discon ] ) are not always true .",
    "consider , for example , the case when @xmath366 , that is , the case of a boxcar - type convolution for each @xmath367 $ ] , @xmath368 .",
    "then , @xmath369 and @xmath370 ; indeed , for rational points @xmath371 $ ] , the functional fourier coefficients @xmath372 vanish for any integer @xmath73 multiple of @xmath373 .",
    "this is an example where a careful choice of @xmath130 , @xmath70 , can make a difference .",
    "for example , in the multichannel boxcar deconvolution problem ( see also example [ ex5 ] ) , de canditiis and pensky ( @xcite ) showed that if @xmath129 is finite , @xmath374 , one of the @xmath130 s is a `` badly approximable '' ( ba ) irrational number , and @xmath375 is a ba irrational tuple , then @xmath376 [ for the definitions of the ba irrational number and the ba irrational tuple , see , e.g. , schmidt ( @xcite ) ] .",
    "this implies that , in this case , ( the degree of ill - posedness is ) @xmath377 .",
    "[ the case @xmath217 , corresponding to the standard boxcar deconvolution problem , was considered by johnstone , kerkyacharian , picard and raimondo ( @xcite ) who showed that @xmath378 when @xmath362 is a ba irrational number . ] furthermore , de canditiis and pensky ( @xcite ) obtained asymptotical upper bounds ( in the @xmath231 , @xmath327 ) for the error , for a wavelet estimator , for a fixed response function .",
    "they also showed that these bounds depend on @xmath129 and the larger the @xmath129 , is the higher the asymptotical convergence rates will be .",
    "hence , in the multichannel boxcar deconvolution problem , it is advantageous to take @xmath328 and to choose @xmath379 to be a ba tuple .",
    "however , the theoretical results obtained in theorems [ th : lower ] and [ th : upper ] can not be blindly applied to accommodate the blurring scenario represented by the case of boxcar - type convolution for each fixed @xmath245 , that is , the case when @xmath380 , @xmath381 $ ] , @xmath368 .",
    "a careful treatment of this problem is necessary , since it requires nontrivial results in number theory .",
    "this is currently under investigation by the authors and the results of the analysis will be published elsewhere .",
    "in what follows , for simplicity , we use the notation @xmath382 instead of @xmath117 , for any arbitrary function @xmath117 .",
    "also , @xmath383 refer to the periodized meyer wavelets defined in section [ estconstr ] .",
    "proof of theorem [ th : lower ] the proof of the lower bounds falls into two parts .",
    "first , we consider the lower bounds obtained when the worst functions @xmath384 ( i.e. , the hardest functions to estimate ) are represented by only one term in a wavelet expansion ( sparse case ) , and then when the worst functions @xmath384 are uniformly spread over the unit interval @xmath31 ( dense case )",
    ".      consider the continuous model ( [ convcont ] ) .",
    "let the functions @xmath385 be of the form @xmath386 and let @xmath387 .",
    "note that by ( [ bpqs ] ) , in order @xmath388 , we need @xmath389 . set @xmath390 , where @xmath391 is a positive constant such that @xmath392 , and apply the following classical lemma on lower bounds :    [ korost ] let @xmath393 be a functional space , and let @xmath394 be a distance on @xmath393 .",
    "for @xmath395 , denote by @xmath396 the likelihood ratio @xmath397 , where @xmath398 is the probability distribution of the process @xmath399 when @xmath48 is true .",
    "let @xmath393 contains the functions @xmath400 such that :    @xmath401 for @xmath402 , @xmath403 ,    @xmath404 for some @xmath405 ,    @xmath406 , where @xmath407 are constants and @xmath408 is a random variable such that there exists @xmath409 with @xmath410 ,    @xmath411 .",
    "then , for an arbitrary estimator @xmath412 , @xmath413    let now @xmath414 so that @xmath415",
    ". choose @xmath416 , where @xmath417 is the @xmath0-norm on the unit interval @xmath31 .",
    "then , @xmath418 . let @xmath419 and @xmath420 . now , to apply lemma [ korost ] , we need to show that for some @xmath421 , uniformly for all @xmath422 , we have @xmath423 since , by chebyshev s inequality , @xmath424 we need to find a uniform upper bound for @xmath425 .",
    "let @xmath426 and @xmath427 be wiener sheets on @xmath428 .",
    "let @xmath429 , where @xmath430 and @xmath431 [ i.e. , @xmath426 and @xmath427 are the primitives of @xmath268 and @xmath432 , resp . ] . then , assuming that @xmath433 , by the multiparameter girsanov formula [ see , e.g. , dozzi ( @xcite ) , page 89 ] , we get @xmath434 hence , @xmath435 where @xmath436    since , by jensen s inequality , @xmath437 , we only need to construct an upper bound for @xmath438 .",
    "for this purpose , we denote the fourier coefficients of @xmath439 by @xmath440 , and observe that in the case of meyer wavelets , @xmath441 [ see , e.g. , johnstone , kerkyacharian , picard and raimondo ( @xcite ) , page 565 ] .",
    "therefore , by properties of the fourier transform , we get @xmath442 let @xmath443 be such that @xmath444 then , by applying lemma [ korost ] and chebyshev s inequality , we obtain @xmath445\\\\[-8pt ]   & \\geq&\\tfrac{1}{4 } { \\gamma_j}^{2 } \\pi_0 . \\nonumber\\end{aligned}\\ ] ] thus , we just need to choose the smallest possible @xmath443 satisfying ( [ jn1 ] ) , to calculate @xmath390 , and to plug it into ( [ lowbound1 ] ) . by direct calculations , we derive , under condition ( [ cond1 ] ) , that @xmath446 so that ( [ jn1 ] ) yields @xmath447 if @xmath132 and @xmath448 if @xmath133 .",
    "hence , ( [ lowbound1 ] ) yields @xmath449    the proof in the discrete case is almost identical to that in the continuous case with the only difference that [ compare with ( [ likelihood1 ] ) ]",
    "@xmath450 ^ 2(u_l , t_i ) - y^2 ( u_l , t_i ) \\}\\\\ & = & - v_{jk } - u_{jk},\\end{aligned}\\ ] ] where @xmath451 note that , due to @xmath452 , we have @xmath453 . also ,",
    "by properties of the discrete fourier transform , we get @xmath454 by replacing @xmath438 and @xmath455 with @xmath456 in the proof for the continuous case , and using ( [ cond1 ] ) , we arrive at ( [ lowbousparse ] ) .",
    "consider the continuous model ( [ convcont ] ) .",
    "let @xmath457 be the vector with components @xmath458 , @xmath459 , denote by @xmath460 the set of all possible vectors @xmath457 , and let @xmath461 .",
    "let also @xmath462 be the vector with components @xmath463 for @xmath464 .",
    "note that by ( [ bpqs ] ) , in order @xmath465 , we need @xmath466 . set @xmath467 , where @xmath468 is a positive constant such that @xmath469 , and apply the following lemma on lower bounds :    [ willer ] let @xmath470 be defined as in lemma  [ korost ] , and let @xmath457 and @xmath471 be as described above .",
    "suppose that , for some positive constants @xmath472 and @xmath473 , we have @xmath474 uniformly for all @xmath471 and all @xmath475 .",
    "then , for any arbitrary estimator @xmath476 and for some positive constant @xmath102 , @xmath477    hence , similarly to the sparse case , to obtain the lower bounds it is sufficient to show that @xmath478 for a sufficiently small positive constant @xmath479 . then , by the multiparameter girsanov formula [ see , e.g. , dozzi ( @xcite ) , page 89 ] , we get @xmath480 and recall that @xmath481 . then , @xmath482 where @xmath483 hence , similarly to the sparse case , @xmath437 and ( [ bnval ] ) is valid . according to lemma [ willer ]",
    ", we choose @xmath484 that satisfies the condition @xmath485 . using ( [ err1 ] )",
    ", we derive that @xmath486 if @xmath132 and @xmath448 if @xmath133 .",
    "therefore , lemma [ willer ] and jensen s inequality yield @xmath487 the proof can be now extended to the discrete case in exactly the same manner as in the sparse case .",
    "now , to complete the proof one just needs to note that @xmath488 , and that @xmath489 with the equalities taken place simultaneously , and then to choose the highest of the lower bounds ( [ lowbousparse ] ) and ( [ lowboudense ] ) .",
    "this completes the proof of theorem [ th : lower ] .",
    "proof of lemma [ l : coef ] in what follows , we shall only construct the proof for @xmath89 [ i.e. , the proof of ( [ hb ] ) ] since the proof for @xmath88 [ i.e. , the proof of ( [ ha ] ) ] is very similar .",
    "first , consider the continuous model ( [ convcont ] ) .",
    "note that , by ( [ coefest ] ) , @xmath490 where @xmath491 due to ( [ finaleq ] ) and ( [ fmexprc ] ) . recall",
    "that @xmath62 are gaussian processes with zero mean and covariance function satisfying ( [ zmu ] ) .",
    "hence , it is easy to check that @xmath492 = n^{-1 } [ \\tau_1 ( m_1)]^{-1 } \\delta(m_1 -m_2),\\ ] ] implying that @xmath493^{-1},\\ ] ] where @xmath335 is defined in ( [ taum ] ) ( the continuous case ) . to complete the proof of ( [ hb ] ) in the case of @xmath494 ,",
    "just recall that @xmath495 and @xmath496 . if @xmath497 , then @xmath498 ^ 2 \\biggr ) \\\\",
    "& = & o   \\biggl ( n^{-2 } \\sum_{m \\in c_j } |{\\psi_{mjk}}|^4   \\tau_2 ( m ) [ \\tau_1 ( m)]^{-4 }",
    "\\biggr ) \\\\ & & { } + o   \\biggl ( n^{-2 }   \\biggl [ |c_j|^{-1 } \\sum_{m \\in c_j } [ \\tau_1 ( m)]^{-1 }   \\biggr]^2   \\biggr)\\\\ & = & o ( n^{-2 } 2^{-j } \\delta_2 ( j ) ) + o ( n^{-2 } \\delta_1 ^ 2 ( j ) ) = o ( n^{-2 } \\delta_2 ( j ) ) , \\end{aligned}\\ ] ] since , by the cauchy ",
    "schwarz inequality , @xmath499 .",
    "this completes the proof of ( [ hb ] ) in the continuous case .    in the discrete case ,",
    "formula ( [ conterror ] ) takes the form [ see ( [ fmexprd ] ) ] @xmath500 where @xmath72 are standard gaussian random variables , independent for different @xmath73 and @xmath26 .",
    "therefore , similarly to the continuous case , @xmath501^{-1 } = o   ( n^{-1 } \\delta_1 ( j )   ) .\\ ] ] in the case of @xmath497 , note that @xmath502 by applying again the cauchy ",
    "schwarz inequality .",
    "this completes the proof of ( [ hb ] ) in the discrete case .",
    "the last part of the lemma follows easily from ( [ delt ] ) with @xmath497 , using the assumption ( [ cond1 ] ) and the cauchy ",
    "schwarz inequality , thus completing the proof of lemma [ l : coef ] .",
    "proof of lemma [ l : deviation ] consider the set of vectors @xmath503 and the centered gaussian process defined by @xmath504 the proof of the lemma is based on the following inequality :    [ l : cirel ] let @xmath256 be a subset of @xmath505 , and let @xmath506 be a centered gaussian process .",
    "if   @xmath507 and @xmath508 , then , for all @xmath509 , we have @xmath510    to apply lemma   [ l : cirel ] , we need to find @xmath511 and @xmath512 .",
    "note that , by jensen s inequality , we get @xmath513 & = & { \\mathbb{e}}\\biggl [ { \\sum_{k \\in{u_{jr}}}}|{\\widehat{b}_{jk}}- { b_{jk}}|^2   \\biggr]^{1/2}\\\\    & \\leq & \\biggl [ { \\sum_{k \\in{u_{jr}}}}{\\mathbb{e}}|{\\widehat{b}_{jk}}- { b_{jk}}|^2   \\biggr]^{1/2}\\\\ & \\leq&\\sqrt{c_1 } n^{-1/2 } 2^{\\nu j } \\sqrt{\\ln n}.\\end{aligned}\\ ] ] [ here , @xmath154 is the same positive constant as in ( [ delta1 ] ) with @xmath168 . ] also , by ( [ zmu ] ) and ( [ conterror ] ) or ( [ discerror ] ) , we have @xmath514 = n^{-1 } { \\sum_{m \\in c_j}}{\\psi_{mjk}}\\overline{\\psi_{mjk ' } } [ \\tau_1 ( m)]^{-1},\\ ] ] where @xmath335 is defined in ( [ taum ] ) . hence , @xmath515^{-1 } \\\\ & \\leq &   c_1 n^{-1 } 2^{2 \\nu j } { \\sum_{k \\in{u_{jr}}}}v^2_k \\leq c_1 n^{-1 } 2^{2 \\nu j},\\end{aligned}\\ ] ] by using @xmath516 and ( [ delta1 ] ) for @xmath168 .",
    "therefore , by applying lemma   [ l : cirel ] with @xmath517 , @xmath518 and @xmath519 , we get @xmath520^{1/2 } \\geq\\sqrt { c_1 } n^{-1/2 } 2^{\\nu j } \\sqrt{\\ln n } + x   \\biggr ) \\\\ & & \\qquad \\leq\\exp\\bigl(- ( 2 c_1)^{-1 } \\bigl(0.5 \\mu- \\sqrt{c_1}\\bigr)^2   \\ln n\\bigr ) \\leq n^{-{\\theta}},\\end{aligned}\\ ] ] where @xmath521 , provided that @xmath522 .",
    "this completes the proof of lemma [ l : deviation ] .",
    "proof of theorem [ th : upper ] first , note that in the case of @xmath133 , we have @xmath523 where @xmath524 since @xmath525 .",
    "it is well known [ see , e.g. , johnstone ( @xcite ) , lemma 19.1 ] that if @xmath526 , then for some positive constant @xmath527 , dependent on @xmath163 , @xmath164 , @xmath162 and @xmath98 only , we have @xmath528 thus , @xmath529 . also , using ( [ delta1 ] ) and ( [ ha ] ) , we derive @xmath530 thus completing the proof for @xmath133 .",
    "now , consider the case of @xmath132 . due to the orthonormality of the wavelet basis",
    ", we get @xmath531 where @xmath532 and @xmath533 are defined in ( [ r1r2 ] ) , and @xmath534 , \\\\",
    "r_4 & = & { \\sum_{j = j_0}^{j-1}}{\\sum_{r \\in{a_j}}}{\\sum_{k \\in{u_{jr}}}}{\\mathbb{e}}[{b_{jk}}^2 { \\mathbb{i}}({\\widehat{b}_{jr } } < d n^{-1 } 2^{2\\nu j } \\ln n ) ] , \\end{aligned}\\ ] ] where @xmath535 and @xmath160 are given by ( [ bjr ] ) and ( [ lamj ] ) , respectively .",
    "let us now examine each term in ( [ errtotal ] ) separately .",
    "similarly to the case of @xmath133 , we obtain @xmath536 by direct calculations , one can check that @xmath537 , if @xmath538 , and @xmath539 , if @xmath540 .",
    "hence , @xmath541 also , by ( [ ha ] ) and ( [ delta1 ] ) , we get @xmath542\\\\[-8pt ] & = & o \\bigl(n^{-2s/(2s+2\\nu+1 ) } \\bigr)= o \\bigl ( n^{-2s^*/(2s^*+2\\nu ) } \\bigr ) . \\nonumber\\end{aligned}\\ ] ]    to construct the upper bounds for @xmath543 and @xmath544 , note that simple algebra gets @xmath545 where @xmath546 , \\nonumber\\\\ r_{32 } & = & { \\sum_{j = j_0}^{j-1}}{\\sum_{r \\in{a_j}}}{\\sum_{k \\in{u_{jr}}}}{\\mathbb{e}}[({\\widehat{b}_{jk}}- { b_{jk}})^2   { \\mathbb{i}}({b_{jr } } > 0.25 d n^{-1 } 2^{2 \\nu j } \\ln n   ) ] , \\nonumber\\\\ r_{41 } & = & { \\sum_{j = j_0}^{j-1}}{\\sum_{r \\in{a_j}}}{\\sum_{k \\in{u_{jr}}}}{\\mathbb{e}}\\biggl[{b_{jk}}^2 { \\mathbb{i}}\\biggl ( { \\sum_{k \\in{u_{jr}}}}|{\\widehat{b}_{jk}}- { b_{jk}}|^2 \\geq0.25 d n^{-1 } 2^{2 \\nu j } \\ln n   \\biggr ) \\biggr ] , \\nonumber\\\\ r_{42 } & = & { \\sum_{j = j_0}^{j-1}}{\\sum_{r \\in{a_j}}}{\\sum_{k \\in{u_{jr}}}}{\\mathbb{e}}[{b_{jk}}^2 { \\mathbb{i}}({b_{jr } } < 2.5 d n^{-1 } 2^{2 \\nu j } \\ln n   ) ] , \\nonumber\\end{aligned}\\ ] ] since @xmath547 . then , by ( [ besball ] ) , lemmas [ l : coef ] and [ l : deviation ] , and the cauchy ",
    "schwarz inequality , we derive @xmath548 n^{-(4\\nu- 2 \\nu_1 + 1)/(2\\nu+1 ) } \\biggr)\\\\ & = & o(n^{-1}),\\end{aligned}\\ ] ] provided @xmath549 , where @xmath550 and @xmath154 is the same positive constant as in ( [ delta1 ] ) with @xmath168 . hence , @xmath551    now , consider @xmath552 let @xmath553 be such that @xmath554 where @xmath555 is defined in ( [ rovalue ] ) .",
    "first , let us study the dense case , that is , when @xmath196 .",
    "then , @xmath556 can be partitioned as @xmath557 , where the first component is calculated over the set of indices @xmath558 and the second component over @xmath559 .",
    "hence , using ( [ bjr ] ) and lemma [ l : coef ] , and taking into account that the cardinality of @xmath560 is @xmath561 , we obtain @xmath562   \\biggr ) \\nonumber\\\\[-8pt]\\\\[-8pt ] & = & o \\biggl({\\sum_{j = j_0}^{j_1}}\\biggl [ n^{-1 } 2^{(2\\nu+1)j } + { \\sum_{r \\in{a_j}}}n^{-1 } 2^{2 \\nu j } \\ln n   \\biggr ] \\biggr)\\nonumber\\\\ & = & o \\bigl(n^{-1 } 2^ { ( 2\\nu+1)j_1 } \\bigr)= o \\bigl(n^{-2s/(2s + 2\\nu+1 ) } ( \\ln n)^{{\\varrho}_1 } \\bigr).\\nonumber\\end{aligned}\\ ] ] to obtain an expression for @xmath563 , note that , by ( [ besball ] ) , and for @xmath564 , we have @xmath565   \\biggr)\\nonumber \\\\ & = & o   \\biggl ( { \\sum_{j = j_1 + 1}^{j-1}}{\\sum_{r \\in{a_j}}}{b_{jr}}\\biggr ) = o   \\biggl ( { \\sum_{j = j_1 + 1}^{j-1}}2^{-2js }   \\biggr ) \\\\ & = & o   \\bigl ( n^{-2s/(2s+2\\nu+1 ) }   \\bigr).\\nonumber\\end{aligned}\\ ] ] if @xmath208 , then @xmath566 so that by lemma [ l : coef ] , and since @xmath567 , we obtain @xmath568   \\biggr ) \\\\ & = & o   \\biggl ( { \\sum_{j = j_1 + 1}^{j-1}}{\\sum_{r \\in{a_j } } } [   ( n^{-1 } 2^{2 \\nu j } \\ln n   ) ^{1-p/2 } { b_{jr}}^{p/2 } \\nonumber\\\\   & & \\hspace*{69pt } { } + { b_{jr}}^{p/2 }   ( n^{-1 } 2^{2 \\nu j } \\ln n   ) ^{1-p/2 } ]   \\biggr)\\nonumber \\\\ & = & o \\biggl({\\sum_{j = j_1 + 1}^{j-1 } } ( n^{-1 } 2^{2 \\nu j } \\ln n ) ^{1-p/2 } { \\sum_{r \\in{a_j}}}{\\sum_{k \\in{u_{jr}}}}|{b_{jk}}|^p \\biggr)\\nonumber \\\\ & = & o \\biggl({\\sum_{j = j_1 + 1}^{j-1 } } ( n^{-1 } 2^{2 \\nu j } \\ln n ) ^{1-p/2 } 2^{-pjs^ * } \\biggr)\\nonumber \\\\ & = & o \\biggl({\\sum_{j = j_1 + 1}^{j-1}}(n^{-1 } \\ln n ) ^{1 - p/2 } 2^{(2 \\nu- p\\nu- p s^*)j } \\biggr)\\nonumber \\\\ & = & o \\bigl((n^{-1 } \\ln n ) ^{1 - p/2 }   2^ { ( 2 \\nu- p\\nu- p s^*)j_1 } \\bigr)\\nonumber \\\\ & = & o \\bigl(n^{-2s/(2s+2\\nu+1 ) } ( \\ln n)^{{\\varrho}_1 } \\bigr).\\nonumber\\end{aligned}\\ ] ]    let us now study the sparse case , that is , when @xmath569 .",
    "let @xmath553 be defined by ( [ j1 ] ) with @xmath318 .",
    "hence , if @xmath570 , then @xmath571 , implying that @xmath36 can not exceed @xmath572 such that @xmath573 , where @xmath574 is the same constant as in ( [ besball ] ) .",
    "again , partition @xmath575 , where the first component is calculated over @xmath576 and the second component over @xmath577 .",
    "then , using arguments similar to those in ( [ del22c1 ] ) , and taking into account that @xmath578 , we derive @xmath579 to obtain an upper bound for @xmath563 , recall ( [ del2 ] ) and keep in mind that the portion of @xmath580 corresponding to @xmath581 is just zero . hence , by ( [ besball ] ) , we get @xmath582\\\\[-8pt ] & = & o \\bigl ( ( \\ln n / n   ) ^{2{s^*}/(2s^*+2\\nu ) } \\bigr ) .",
    "\\nonumber\\end{aligned}\\ ] ]    now , in order to complete the proof , we just need to study the case when @xmath193 .",
    "in this situation , we have @xmath583 and @xmath584 . recalling ( [ bpqs ] ) and noting that @xmath585 , we get @xmath586 then , we repeat the calculations in ( [ del21c2 ] ) for all indices @xmath587 . if @xmath588 , then , by hlder s inequality , we get @xmath589^{p / q }   \\biggr ) \\\\ & = & o   \\bigl (   ( \\ln",
    "n / n   ) ^{2{s^*}/(2s^*+2\\nu ) } ( \\ln n)^{1 - p / q }   \\bigr).\\nonumber\\end{aligned}\\ ] ] if @xmath194 , then , by the inclusion @xmath590 , we get @xmath591   \\biggr ) \\\\ & = & o   \\bigl (   ( \\ln n / n   ) ^{2{s^*}/(2s^*+2\\nu)}\\bigr).\\nonumber\\end{aligned}\\ ] ] by combining ( [ r1a])([r2 ] ) , ( [ r3141 ] ) , ( [ del21c1])([del2c4ff ] ) , we complete the proof of theorem [ th : upper ] .",
    "marianna pensky is grateful for the hospitality and financial support of the department of mathematics and statistics at the university of cyprus , cyprus , and theofanis sapatinas is grateful for the hospitality of the department of mathematics at the university of central florida , usa , where parts of the work of this paper were carried out .",
    "the authors would like to thank thomas willer for useful discussions .",
    "finally , we would like to thank an associate editor and two anonymous referees for their suggestions on improvements to this paper .",
    "cirelson , b. s. , ibragimov , i. a. and sudakov , v. n. ( 1976 ) .",
    "norm of gaussian sample function . in _ proceedings of the 3rd japan ",
    "symposium on probability theory_. _ lecture notes in math . _ * 550 * 2041 .",
    "springer , berlin ."
  ],
  "abstract_text": [
    "<S> we extend deconvolution in a periodic setting to deal with functional data . </S>",
    "<S> the resulting functional deconvolution model can be viewed as a generalization of a multitude of inverse problems in mathematical physics where one needs to recover initial or boundary conditions on the basis of observations from a noisy solution of a partial differential equation . in the case </S>",
    "<S> when it is observed at a finite number of distinct points , the proposed functional deconvolution model can also be viewed as a multichannel deconvolution model .    </S>",
    "<S> we derive minimax lower bounds for the @xmath0-risk in the proposed functional deconvolution model when @xmath1 is assumed to belong to a besov ball and the blurring function is assumed to possess some smoothness properties , including both regular - smooth and super - smooth convolutions . </S>",
    "<S> furthermore , we propose an adaptive wavelet estimator of @xmath1 that is asymptotically optimal ( in the minimax sense ) , or near - optimal within a logarithmic factor , in a wide range of besov balls .    in addition , we consider a discretization of the proposed functional deconvolution model and investigate when the availability of continuous data gives advantages over observations at the asymptotically large number of points . as an illustration </S>",
    "<S> , we discuss particular examples for both continuous and discrete settings .    and    .    </S>"
  ]
}