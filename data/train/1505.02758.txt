{
  "article_text": [
    "many natural phenomena and human activities are extremely inhomogeneous in time .",
    "solar flares , earthquakes  @xcite , firing of neurons  @xcite , and human communication  @xcite are just some examples . in all these phenomena events occurring within short time periods , called bursts ,",
    "are alternating with random , long periods of low activity  @xcite .",
    "often the elements behaving in this manner constitute a temporal network  @xcite and then the processes such as spreading on the network are strongly influenced by the burstiness of the time series  @xcite . or burstiness can be influenced by spreading  @xcite .",
    "the natural question raises : how to characterize the highly inhomogeneous dynamics and how to model it ?",
    "this is important for discovering analogies between different processes leading to possible universalities and for understanding the effect of temporal inhomogeneities on the network processes .    at the simplest level ,",
    "the bursty time series is characterized by the heavy - tailed interevent time distribution @xmath0 , where @xmath1 is the time interval between two consecutive events .",
    "@xmath0 has often been described by a power law : @xmath2 however , the interevent time distribution does not provide a complete characterization .",
    "the higher order description of bursts focuses on dependencies between interevent times , i.e. , higher order memory effects .",
    "these can be approached in different ways .",
    "one possibility is to calculate the autocorrelation function . for this approach goh and barabsi",
    "defined a memory coefficient measuring short - range memory effect  @xcite as following : @xmath3 where @xmath4 denotes the @xmath5th interevent time , and @xmath6 and @xmath7 are the average and standard deviation of interevent times .",
    "the aim was to characterize the bursty time series by two quantities , @xmath8 and the burstiness parameter @xmath9 , defined as @xmath10 it was found in many human activities that @xmath8 is close to @xmath11 . to describe long - range memory effects",
    ", one can use the entire autocorrelation function of the time series .",
    "recently , it was shown that the power - law decay of the autocorrelation function is implied by a power - law interevent time distribution even without any correlations between consecutive interevent times .",
    "precisely , the scaling relation @xmath12 was proven with @xmath13 denoting the decaying exponent of the autocorrelation function  @xcite . however , more works need to be done for the validity of the scaling relation , as the effect of dependencies between interevent times in the bursty time series is not yet fully understood .",
    "an approach sensitive to dependencies was recently introduced by using the notion of bursty trains  @xcite .",
    "a bursty train is defined as a set of events , such that any pair of consecutive events in the train is separated by an interevent time within a given time window @xmath14 .",
    "the distribution of the number @xmath15 of events in the trains follows an exponential function if the interevent times are independently and identically distributed .",
    "it was found , however , that in many empirical cases @xmath15 is power - law distributed , i.e. , @xmath16 for a wide range of @xmath14 .",
    "this notion of _ correlated bursts _ was empirically observed in earthquakes , neuronal activities , and human communication patterns  @xcite .",
    "such correlations are clearly due to memory effects .",
    "generative models for correlated bursts have been devised and studied .",
    "_ introduced two - state model with memory function  @xcite : one state is for generating power - law distributed interevent times that are uncorrelated , while the other state is for generating short - timescale bursty trains . for the latter ,",
    "they define a memory function as the probability of generating one more event in the train provided that @xmath17 events have already been generated in the train : @xmath18 here @xmath19 and @xmath20 are directly controlled by parameters for memory functions , e.g. , @xmath21 . in this model , the onset of bursty trains is assumed to be known or at least declared in order to use the above memory function , requiring additional information .",
    "such assumption is not necessarily the case in reality .",
    "thus in this paper we suggest more natural and intuitive mechanism for correlated bursts that does not need declaring bursty trains .",
    "we also investigate the robustness of the scaling relation @xmath12 with respect to the strength of dependencies between interevent times .",
    "we study a generative model for correlated bursts with variable range of memory effect . in our model ,",
    "bursty trains emerge from the stochastic process using a memory function .",
    "note that our memory function has nothing to do with eq .",
    "( [ eq : p_n ] ) . at time",
    "step @xmath22 , the first event occurs , and the @xmath5th event occurs at time step @xmath23 .",
    "the probability that the @xmath24th event occurs at time step @xmath25 is given by @xmath26&=&1-e^{-\\mu m(t)}\\\\    p[m(t)]&=&1-e^{-\\mu m(t)-\\epsilon}\\\\    \\label{eq : memory }    m(t)&=&\\sum_{i=1}^n \\frac{1}{t - t_i}\\ \\textrm{for}\\ t > t_n,\\end{aligned}\\ ] ] where @xmath27 denotes the _ memory function _ that is the time - weighted sum of all the past events .",
    "accordingly , @xmath28 controls the strength of memory effect , such that the larger @xmath28 implies the stronger memory effect .",
    "here we use @xmath29 to indicate spontaneous events taking place with very small probability .",
    "once the @xmath24th event occurs , the memory term due to this event is added to the memory function .",
    "note that @xmath25 is discrete and @xmath30 .",
    "we remark that our model can be considered as a self - exciting point process  @xcite with a power - law kernel .",
    "these processes have been extensively studied for earthquakes  @xcite as well as in application to social systems  @xcite . in such processes ,",
    "the time - varying event rate is given as a function of the past events .",
    "as for the kernel , the omori s law has been widely used , stating that aftershock frequency decreases with an elapsed time after the main shock , e.g. , in a form of @xmath31 with small positive @xmath32  @xcite .",
    "the self - exciting point process with omori s law is called epidemic - type aftershock sequence ( etas ) model . note that our memory function in eq .",
    "( [ eq : memory ] ) corresponds to the case with @xmath33 .",
    "analytic and numerical approaches to the etas model have shown that interevent time distributions are mostly described by a gamma function  @xcite , implying that @xmath34 .",
    "however , one finds evidence for @xmath35 in many other natural and social phenomena  @xcite . despite the similarity between our model and the etas model ,",
    "our model shows different results such as @xmath35 .    as a novel feature compared to the family of etas models ,",
    "we introduce memory loss mechanisms as most systems may lose their memory by various reasons , e.g. , noise , limited memory capacities , or periodic resetting in circadian cycles of humans  @xcite .",
    "we incorporate the _ sequential memory loss _ mechanism by considering only a finite number @xmath36 of terms in eq .",
    "( [ eq : memory ] ) : @xmath37 this implies that once an event occurs , the memory due to the oldest event is immediately lost .",
    "here @xmath38 implies no memory before the latest event . note that without memory loss , i.e. , when @xmath36 is infinite , @xmath27 might diverge as @xmath39 .",
    "we can consider more realistic memory loss mechanisms depending on the systems of interest .",
    "for example , the condition of the fixed @xmath36 can be relaxed by considering variable @xmath36 .",
    "whenever an event occurs , @xmath27 is initialized except for the latest event , i.e. , by setting @xmath38 , with a probability @xmath40=1-\\left[\\frac{l(t)}{l(t)+1}\\right]^\\nu + \\epsilon_l,\\ ] ] where @xmath41 is the number of terms in memory function at time @xmath25 .",
    "this can be called _ preferential memory loss _ mechanism . here",
    "we have introduced the spontaneous initialization of @xmath27 with very small @xmath42 , otherwise if @xmath43 , @xmath44 may be extremely small due to extremely large @xmath41 and vice versa . with this @xmath44 , we expect that the distribution of @xmath36 is proportional to @xmath45 with @xmath46",
    ". we will study both memory loss mechanisms one by one .",
    "we remark that our model is intrinsically non - stationary due to the long - range memory effect .",
    "however , non - stationary periods are limited to timescales of the order of @xmath47 , as to be numerically confirmed by the decaying behavior of autocorrelation function for the delay time of the order of @xmath47 .",
    "in general , the probability of finding an interevent time @xmath1 between events occurred at @xmath48 and @xmath49 is written as @xmath50 \\left[1-e^{-\\mu m(t_n+\\tau)-\\epsilon}\\right].\\ ] ] this formula is exact as the model is defined in the discrete time @xmath25 , while the formula for continuous time can be found in  @xcite .",
    "let us first consider the simplest case when the model has no memory before the latest event , i.e. , @xmath38 . since the distribution does not depend on @xmath48 but only on @xmath51 , we set @xmath52 without loss of generality .",
    "then , we use @xmath53 the numerical result of @xmath27 is depicted in fig .",
    "[ fig : sequentialml_memory](a ) .",
    "this can be related to time - varying priority queuing models studied in  @xcite , where the decaying priority of the task was considered as @xmath54 .",
    "one gets the interevent time distribution : @xmath55 \\left(1-e^{-\\mu/\\tau-\\epsilon}\\right)\\\\    \\nonumber    & \\approx&\\exp\\left[-\\mu\\ln(\\tau-1 ) -\\epsilon(\\tau-1)\\right ] \\left(\\frac{\\mu}{\\tau}+\\epsilon\\right)\\\\    & \\approx&\\left[\\mu\\tau^{-(1+\\mu ) } + \\frac{\\tau^{-\\mu}}{\\tau_c}\\right]e^{-\\tau/\\tau_c},\\ \\tau_c\\equiv\\epsilon^{-1}.\\end{aligned}\\ ] ] in the last line , we have assumed @xmath56 .",
    "this analytic result perfectly fits the numerical results even for small values of @xmath1 , see fig .",
    "[ fig : sequentialml_mu0_1](a ) . for numerical simulations ,",
    "we have generated the event sequence consisting of up to @xmath57 events using @xmath58 for all cases .",
    "the bump observed for large @xmath1 is clearly due to the poisson events with positive @xmath59 .",
    "we find the power - law exponent of interevent time distribution to be @xmath60 when @xmath61 and @xmath58 , the scaling regime with @xmath62 turns out to be almost invisible .",
    "thus the dominant scaling behavior is characterized by @xmath63 .     in the model with sequential memory loss mechanism , where the number of memories is denoted by @xmath36 .",
    "we used @xmath58 , and @xmath38 ( a ) , @xmath64 ( b ) , and @xmath65 ( c ) . ]",
    "since all interevent times are fully uncorrelated , the bursty train distribution is given by  @xcite @xmath66,\\\\    f(\\delta t)&\\equiv & \\sum_{\\tau=1}^{\\delta t}p(\\tau ) .",
    "% f(\\delta t)&\\equiv & \\int_1^{\\delta t}p(\\tau)d\\tau.\\end{aligned}\\ ] ] for @xmath67 , one gets the exponential distribution of bursty trains as @xmath68\\ ] ] with @xmath69^{-1}$ ] , which is numerically confirmed in fig .  [ fig : sequentialml_mu0_1](b ) . in case of @xmath70",
    ", we have @xmath71 for @xmath72 .        in order to calculate the autocorrelation function",
    ", we first denote the event sequence by @xmath73 that has the value of @xmath74 at the moment of event occurred , @xmath11 otherwise .",
    "the autocorrelation function with delay time @xmath75 is defined as @xmath76 for the power - law interevent time distribution , one may find that @xmath77 .",
    "for the uncorrelated interevent times , it has been proved that @xmath12  @xcite .",
    "this scaling relation is numerically confirmed with the estimated value of @xmath13 in fig .",
    "[ fig : sequentialml_mu0_1](c ) .",
    "next , we consider the case of @xmath78 , when the memory function is composed of two terms corresponding to the latest event and the second latest event , respectively . the interevent time between those two events",
    "is denoted by @xmath79 .",
    "again we set @xmath52 in eq .",
    "( [ eq : pt_tau ] ) .",
    "conditional _ memory function reads @xmath80 leading to the _ conditional _ interevent time distribution @xmath81 as @xmath82,\\label{eq : ptautau1}\\\\    f(\\tau|\\tau_1)&\\equiv & \\ln \\tau+\\ln ( \\tau+\\tau_1)-\\ln \\tau_1,\\\\    g(\\tau|\\tau_1)&\\equiv & \\frac{1}{\\tau}+\\frac{1}{\\tau+\\tau_1}.\\end{aligned}\\ ] ] if @xmath83 , we get @xmath84 on the other hand , if @xmath85 , we get @xmath86 e^{-\\tau/\\tau_c}.\\ ] ] then , @xmath0 could be obtained by solving the following self - consistent equation : @xmath87 which is however not trivial .",
    "instead we find that the leading term of eq .",
    "( [ eq : ptautau2 ] ) is not explicitly dependent on @xmath79 , and that @xmath88 appears in eq .",
    "( [ eq : ptautau3 ] ) only as a coefficient . thus we expect that @xmath89 with @xmath79 in eq .",
    "( [ eq : ptautau1 ] ) replaced by a crossover interevent time @xmath90 .",
    "we numerically estimate @xmath91 by fitting @xmath92 to the simulation result of @xmath0 , shown in fig .",
    "[ fig : sequentialml_mu0_1](d ) . in sum , provided that @xmath93 , one can get the power - law exponent : @xmath94    the bursty train distribution can be calculated as @xmath95 with a normalization constant @xmath96 .",
    "an example of event train is shown in fig .",
    "[ fig : event_train ] . here",
    "we decompose the interevent times in eq .",
    "( [ eq : pe_l2 ] ) by assuming that @xmath97 , because @xmath98 will contribute the most .",
    "we get @xmath99 where @xmath100 denotes the previous interevent time .",
    "this approximation is compared to the numerical results in fig .",
    "[ fig : sequentialml_mu0_1](e ) .",
    "in addition , for the autocorrelation function we numerically find @xmath101 in fig .",
    "[ fig : sequentialml_mu0_1](f ) that fits the scaling relation @xmath12 with @xmath102 for the regime of large @xmath1 in eq .",
    "( [ eq : alphal2 ] ) .",
    "it implies that the dependency between consecutive interevent times is not strong enough for leading to the violations of the scaling relation @xmath12 .",
    "events , where @xmath103 and @xmath104 for @xmath105 . ]    in general , we have @xmath36 terms in the memory function : @xmath106 where @xmath107 with @xmath108 denoting the time interval between the @xmath109th latest and @xmath110th latest events .",
    "we straightforwardly get @xmath111,\\nonumber\\\\    \\\\",
    "f(\\tau|\\{\\tau_i\\})&\\equiv & \\ln \\tau+\\sum_{i=1}^{l-1}\\ln \\left(1+\\frac{\\tau}{s_i}\\right),\\\\    g(\\tau|\\{\\tau_i\\})&\\equiv & \\frac{1}{\\tau}+ \\sum_{i=1}^{l-1 } \\frac{1}{\\tau+s_i}.\\end{aligned}\\ ] ] for @xmath112 , we get @xmath113 leading to @xmath114 with @xmath115 . similarly to the case of @xmath78 , one can infer the scaling behavior of @xmath114 as following : @xmath116 with crossover interevent times @xmath117 for @xmath118 , provided that @xmath119 .",
    "this implies that the scaling behavior can not be described by a single value of power - law exponent .",
    "we instead calculate the local exponent @xmath120 , @xmath121 with a proper constant @xmath122",
    ". indeed , such local exponents show gradually increasing behaviors as @xmath1 increases for the cases of large @xmath36 , shown in the insets of fig .",
    "[ fig : sequentialml_mu0_1](g , j ) .",
    "the bursty train distribution can be written as @xmath123 where @xmath124 is a normalization constant and @xmath125 , @xmath126 , @xmath127 are dummy variables once @xmath128 . for small @xmath14 , by assuming that @xmath129 , one gets @xmath130 being proportional to @xmath131 with @xmath132 where @xmath133 denotes the set of @xmath134 previous interevent times .",
    "this result implies the exponential bursty train distribution . for large @xmath14",
    ", we numerically find scaling behaviors @xmath135 with @xmath136 for @xmath137 and @xmath138 for @xmath139 , but limited to the range of @xmath140 as depicted in fig .",
    "[ fig : sequentialml_mu0_1](h , k ) .",
    "@xmath130 has a natural exponential cutoff @xmath141 because @xmath36 directly controls the range of memory effect . the autocorrelation functions for general @xmath36 also show scaling behaviors with @xmath142 for @xmath137 and @xmath143 for @xmath139 in fig .",
    "[ fig : sequentialml_mu0_1](i , l ) .",
    "since interevent time distributions are not described by a single value of power - law exponent , and the memory effect induces dependency between interevent times , we do not expect the scaling relation @xmath12 to hold .     in eq .",
    "( [ eq : burstiness ] ) and memory coefficient @xmath8 in eq .",
    "( [ eq : memorycoeff ] ) for different values of @xmath36 in the model with sequential memory loss mechanism .",
    "we used @xmath58 . ]             in the model with preferential memory loss mechanism .",
    "we used @xmath58 and @xmath144 . ]    finally , let us consider the extreme case of @xmath145 .",
    "as all the past events contribute to the memory function , the fluctuation of @xmath27 must be considerably reduced so that the system eventually shows the memoryless poissonian behavior , as supported by the decreasing fluctuation of @xmath27 as @xmath36 increases in fig .",
    "[ fig : sequentialml_memory ] . in order to test our expectation , we measure burstiness parameter @xmath9 in eq .",
    "( [ eq : burstiness ] ) and memory coefficient @xmath8 in eq .",
    "( [ eq : memorycoeff ] ) for the wide range of @xmath36 . as depicted in fig .",
    "[ fig : sequentialml_mb ] , we find that both @xmath9 and @xmath8 increase and then decrease with increasing @xmath36 , implying that there exists an optimal range of @xmath36 ( @xmath146 ) maximizing burstiness and memory effect between interevent times .",
    "however , such optimal values of @xmath36 , which play the role of cutoff in bursty train distributions , turn out to be too small compared to the empirical observations , e.g. , in  @xcite .      in order to overcome the strong exponential cutoffs due to @xmath36 itself , we study the preferential memory loss mechanism using eq .",
    "( [ eq : q_l ] ) .",
    "the number of past events contributing to the memory function until a new event occurs is now a random variable , denoted by @xmath36 .",
    "the distribution of @xmath36 is given by @xmath147 with @xmath148 .",
    "the interevent time distribution can be obtained from @xmath149 where @xmath150 denotes the interevent time distribution for fixed @xmath36 in the model with sequential memory loss mechanism , i.e. , eq .",
    "( [ eq : ptaul ] ) but with @xmath151 replaced by @xmath152 . numerical results for @xmath58 and for several values of @xmath153",
    "are shown in fig .",
    "[ fig : preferentialml_summary ] , and the estimated values of @xmath19 , @xmath20 , and @xmath13 as functions of @xmath153 are plotted in fig .",
    "[ fig : preferentialml_expo](a , b ) . as @xmath153 increases",
    ", @xmath19 monotonically decreases , while @xmath20 and @xmath13 monotonically increase .",
    "the value of @xmath20 turns out to be larger than that of @xmath154 . since @xmath141 for each @xmath36",
    ", it is expected that @xmath155 .",
    "we also find that the scaling behavior in bursty train distributions is more robust with respect to the value of @xmath14 , hence comparable to the empirical observations .",
    "the empirical values of power - law exponents are plotted in fig .",
    "[ fig : preferentialml_expo](a , b ) for comparison  @xcite .    if @xmath153 is sufficiently large , i.e. , @xmath156 , the term for @xmath38 becomes dominant in eq .",
    "( [ eq : preferentialptau ] ) , leading to @xmath157 with @xmath158 from eq .",
    "( [ eq : alphal1 ] ) .",
    "this is consistent with observations that as @xmath153 increases , @xmath13 approaches @xmath159 and @xmath20 increases considerably , implying that the bursty train distribution becomes exponential .",
    "the values of burstiness parameter @xmath9 and memory coefficient @xmath8 get also closer to those for the model with sequential memory loss mechanism with @xmath38 .    for @xmath160 , as @xmath153 approaches @xmath11 from @xmath161 , we find that the tail of interevent time distribution becomes thinner because @xmath0 in eq .",
    "( [ eq : preferentialptau ] ) is more influenced by the terms of @xmath150 with @xmath162 , which typically have larger values of power - law exponent .",
    "this is evidenced by the increasing behavior of @xmath19 from @xmath163 to @xmath161 in fig .",
    "[ fig : preferentialml_expo](a ) .",
    "since the very small @xmath153 leads to the very small @xmath44 in eq .",
    "( [ eq : q_l ] ) , the memory function is rarely initialized so that some parts of the event sequence can be approximated by the model with the sequential memory loss mechanism for very large @xmath36 .",
    "we indeed observe for @xmath144 that the event sequence is made of dense event clusters spanning relatively long periods separated by long interevent times , as partly depicted in fig .",
    "[ fig : preferentialml_memory ] . in each dense event cluster",
    "@xmath27 overall increases , but such non - stationary periods are limited to the timescale of the order of @xmath164 .",
    "as @xmath27 increases but very slowly , it can be roughly approximated by a poissonian process , supported by the estimation of @xmath165 and @xmath166 in fig .",
    "[ fig : preferentialml_expo ] .",
    "in addition to @xmath165 , the autocorrelation function remains finite for wide range of @xmath75 [ see fig .  [",
    "fig : preferentialml_summary](i ) ] because of the non - stationarity in @xmath27 in dense event clusters .",
    "note that the scaling relation @xmath12 seems to hold for @xmath144 even when @xmath167 and @xmath168 , implying strong dependency between interevent times and strong burstiness effect .",
    "these can be understood as follows .",
    "as bursty trains are mostly measured in dense event clusters , they tend to contain more events , leading to the heavier tail for bursty train distributions and the smaller value of @xmath20 , i.e. , @xmath167 .",
    "relatively few but very large interevent times separating dense event clusters force @xmath9 to get close to @xmath74 .",
    "in order to investigate the underlying mechanism behind correlated bursts widely observed in natural phenomena and human activities , we have devised and studied a simple model that is able to generate correlated bursts using a self - exciting point process with variable range of memory .",
    "our model does not need to declare the bursty trains as compared to the previous two - state model for correlated bursts . in our model ,",
    "a new event can occur depending on the memory function defined as the sum of decaying memories of past events .",
    "for incorporating noise and/or the limited memory capacity of systems , we apply two different memory loss mechanisms : fixed number or variable number of memories , which we call sequential and preferential memory loss mechanisms , respectively . for each case",
    ", we obtain the interevent time distribution , bursty train distribution , and autocorrelation function , all of which are characterized by power - law decaying exponents @xmath19 , @xmath20 , and @xmath13 , respectively , to study scaling relations among them .    for the model with sequential memory loss mechanism ,",
    "the memory function is given by the sum of decaying memories of @xmath36 latest events , where @xmath36 is a control parameter .",
    "the simplest case with @xmath38 has been exactly solved , also satisfying the scaling relation @xmath12  @xcite .",
    "other simple cases could be analytically solved , while the general cases have been numerically studied .",
    "as @xmath36 becomes larger , the bursty train distribution shows scaling behavior for limited range of parameters , implying the emergence of correlated bursts . however , the number of events in bursty trains is strongly limited by @xmath36 .",
    "interestingly , if @xmath36 is extremely large , too much memory effect effectively reduces the model to the poisson process , which is confirmed by both memory coefficient and burstiness parameter approaching @xmath11 , i.e. , no memory effect and no burstiness .    in order to overcome the strong cutoff effect due to the fixed @xmath36",
    ", we have numerically studied the model with preferential memory loss mechanism . here",
    "the number of memories @xmath36 in the memory function increases gradually but is set as @xmath74 , i.e. , memory function initialization , with probability controlled by the exponent @xmath153 . for sufficiently large @xmath153 , the memory function is initialized frequently so that the model can reduce to the case with sequential memory loss mechanism using @xmath38 . on the other hand , for very small @xmath153",
    ", the event sequence is composed of dense event clusters spanning long periods that are separated by very large interevent times .",
    "dense event clusters may correspond to the case with sequential memory loss mechanism using very large @xmath36 , i.e. , close to the poisson process .",
    "for the intermediate range of @xmath153 , we find evidences that our model generates correlated bursts , hence comparable to the empirical findings .    as a followup",
    ", our models can be extended to incorporate a number of complex realistic situations .",
    "for example , we can consider the context of events  @xcite , and a network of interacting individuals , each of which shows activities with correlated bursts .",
    "hj gratefully acknowledges financial support by aalto university postdoctoral program and by mid - career researcher program through the national research foundation of korea ( nrf ) grant funded by the ministry of science , ict and future planning ( 2014030018 ) , and basic science research program through the national research foundation of korea ( nrf ) grant funded by the ministry of science , ict and future planning ( 2014046922 ) .",
    "jip acknowledges support by the academy of finland , project no .",
    "jk acknowledges support from h2020 fetproact-1 - 2014 , grant agreement # 641191 `` cimplex '' ."
  ],
  "abstract_text": [
    "<S> inhomogeneous temporal processes in natural and social phenomena have been described by bursts that are rapidly occurring events within short time - periods alternating with long periods of low activity . </S>",
    "<S> in addition to the analysis of heavy - tailed interevent time distributions , higher - order correlations between interevent times , called _ correlated bursts _ , have been studied only recently . as the underlying mechanism behind such correlated bursts is far from being fully understood , </S>",
    "<S> we devise a simple model for correlated bursts using a self - exciting point process with variable range of memory . whether a new event occurs is stochastically determined by a memory function that is the sum of decaying memories of past events . in order to incorporate the noise and/or limited memory capacity of systems , we apply two memory loss mechanisms : fixed number or variable number of memories . by analysis and numerical simulations , we find that too much memory effect may lead to a poissonian process , implying that there exists an intermediate range of memory effect to generate correlated bursts comparable to empirical findings . </S>",
    "<S> our conclusions provide deeper understanding of how long - range memory affects correlated bursts . </S>"
  ]
}