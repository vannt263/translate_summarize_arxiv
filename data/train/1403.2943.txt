{
  "article_text": [
    "this work , inspired by the multilevel discretization schemes introduced in @xcite , extends the hybrid chernoff tau - leap method @xcite to the multilevel monte carlo setting @xcite .",
    "consider a non - homogeneous poisson process , @xmath2 , taking values in the lattice of non - negative integers , @xmath3 .",
    "we want to estimate the expected value of a given observable , @xmath4 of @xmath2 , at a final time , @xmath5 , _",
    "i.e. _ , @xmath6}$ ] .",
    "for example , in a chemical reaction in thermal equilibrium , the @xmath7-th component of @xmath2 , @xmath8 , could describe the number of particles of species @xmath7 present at time @xmath9 . in the systems modeled here ,",
    "different species undergo reactions at random times by changing the number of particles in at least one of the species .",
    "the probability of a single reaction happening in a small time interval is modeled by a non - negative propensity function that depends on the current state of the system .",
    "we present a formal description of the problem in section [ sec : pjp ] .",
    "pathwise realizations of such pure jump processes ( see , _ e.g. _ , @xcite ) can be simulated exactly using the stochastic simulation algorithm ( ssa ) , introduced by gillespie in @xcite , or the modified next reaction method ( mnrm ) introduced by anderson in @xcite .",
    "although these algorithms generate exact realizations for the markov process , @xmath2 , they are computationally feasible for only relatively low propensities .    for that reason ,",
    "gillespie in @xcite and aparicio and solari in @xcite independently proposed the tau - leap method to approximate the ssa by evolving the process with fixed time steps and by keeping the propensity fixed within each time step .",
    "in fact , the tau - leap method can be seen as a forward euler method for a stochastic differential equation driven by poisson random measures ( see , _ e.g. _ , @xcite ) .",
    "a drawback of the tau - leap method is that the simulated process may take negative values , which is an undesirable consequence of the approximation and not a qualitative feature of the original process . for this purpose , we proposed in @xcite a chernoff - type bound that controls the probability of reaching negative values by adjusting the time steps . also , to avoid extremely small time steps , we proposed switching adaptively between the tau - leap and an exact method , creating a hybrid tau - leap / exact method that combines the strengths of both methods .",
    "more specifically , let @xmath10 be the state of the approximate process at time @xmath9 , and let @xmath11 be given .",
    "the main idea is to compute a time step , @xmath12 , such that the probability that the approximate process reaches an unphysical negative value in @xmath13 is less than @xmath14 .",
    "this allows us to control the probability that a entire hybrid path exits the lattice , @xmath15 . in turn",
    ", this quantity leads to the definition of the global exit error , which is a global error component along with the time discretization error and the statistical error ( see section [ calibration ] for details ) .",
    "the multilevel monte carlo idea goes back at least to @xcite . in that setting ,",
    "the main goal was to solve high - dimensional , parameter - dependent integral equations and to conduct corresponding complexity analyses .",
    "later , in @xcite , giles developed and analyzed multilevel techniques that were used to reduce the computational work when estimating an expected value using monte carlo path simulations of a certain quantity of interest of a stochastic differential equation .",
    "independently , in @xcite , speight introduced a multilevel approach to control variates .",
    "control variates are a widespread variance reduction technique with the main goal of increasing the precision of an estimator or reducing the computational effort .",
    "the main idea is as follows : to reduce the variance of the standard monte carlo estimator of @xmath16}$ ] , @xmath17 we consider another unbiased estimator of @xmath16}$ ] , @xmath18}){\\right)}{,}\\ ] ] where @xmath19 is a random variable correlated with @xmath2 with known mean , @xmath20}$ ] .",
    "the variable @xmath19 is called a control variate . since @xmath21 } { = } { \\mathrm{var}\\left[\\hat \\mu_1\\right ] } { + }   { \\mathrm{var}\\left[y\\right ] } { - } 2{\\mathrm{cov}\\left[x , y\\right]}$ ] , whenever @xmath22}{>}{\\mathrm{var}\\left[y\\right]}/2 $ ] , we have that @xmath21}{\\leq}{\\mathrm{var}\\left[\\hat \\mu_1\\right]}$ ] .",
    "if we assume that the computational work of generating the pair @xmath23 is less than twice the computational work of generating @xmath24 , it is straightforward to conclude that @xmath25 is preferred when @xmath26 , where @xmath27 is the correlation coefficient of the pair @xmath28 .",
    "we observe that @xmath29 can be written as @xmath30 } +   \\frac{1}{m } \\sum_{m=1}^m { \\left(}x - y { \\right)}(\\omega_m){.}\\ ] ] in the case where @xmath20}$ ] is unknown and sampling from @xmath19 is computationally less expensive than sampling from @xmath2 , it is natural to estimate @xmath20}$ ] using monte carlo sampling to yield a two - level monte carlo estimator of @xmath16}$ ] based on the control variate , @xmath19 , _",
    "i.e. _ , @xmath31 see section [ mlmcintro ] for details about the definition of levels in our context .",
    "in this work , we apply giles s multilevel control variates idea to the hybrid chernoff tau - leap approach to reduce the computational cost , which is measured as the amount of time needed for computing an estimate of @xmath6}$ ] , within @xmath0 , with a given level of confidence .",
    "we show that our hybrid mlmc method has the same computational complexity of the pure ssa , _",
    "i.e. _ , order @xmath32 .",
    "from this perspective , our method can be seen as a variance reduction for the ssa since our mlmc method does not change the complexity ; it just reduces the corresponding multiplicative constant .",
    "we note in passing that in @xcite , the authors show that the computational complexity for the pure mlmc tau - leap case has order @xmath33 .",
    "we note also that here our goal is to provide an estimate of @xmath6}$ ] in the probability sense and not in the mean square sense as in @xcite .",
    "the global error arising from our hybrid tau - leap mlmc method can naturally be decomposed into three components : the global exit error , the time discretization error and the statistical error .",
    "this global error should be less than a prescribed tolerance , @xmath0 , with probability larger than a certain confidence level .",
    "the global exit error is controlled by the one - step exit probability bound , @xmath14 @xcite .",
    "the time discretization error , inherent to the tau - leap method , is controlled through the size of the mesh , @xmath34 , @xcite . at this point , it is crucial to stress that , by controlling the exit probability of the set of hybrid paths , we are indirectly turning this event into a rare event .",
    "thus , direct sampling of exit paths is not an affordable way to estimate the probability of such an event .    motivated by the central limit results of collier et al .",
    "@xcite for the multilevel monte carlo estimator ( see appendix a , theorem 1 ) , we approximate the statistical error with a gaussian random variable with zero mean . in our numerical experiments , we tested this hypothesis by employing q - q plots and the shapiro - wilk test @xcite .",
    "there , we did not reject the gaussianity of the statistical error at the 1% significance level .",
    "the variance of the statistical error is a linear combination of the variance at the coarsest level and variances of the difference of two consecutive levels , which we sometimes call strong errors . in section",
    "[ sec : vl ] , motivated by the fact that sample variance and bias estimators are inaccurate on the deepest levels , we develop a novel dual - weighted residual expansion that allows us to estimate those quantities , cf . and .",
    "we also control the statistical error through the number of coupled hybrid paths , @xmath35 , simulated at each level .",
    "we note that our use of duals in this work is different from the use in @xcite .",
    "that earlier work proposed an adaptive , single - level , tau - leap algorithm for error control , choosing the time steps non - uniformly to control the global weak error based on dual - weighted error estimators . in this work",
    ", we do not have an adaptive time step based on dual - weighted error estimators as in @xcite .",
    "we use instead dual - weighted error estimators to reduce the statistical error in our error estimates .      to describe the class of markovian pure jump process , @xmath36\\times \\omega \\to{\\mathbb{z}}_+^d$ ] , that we use in this work",
    ", we consider a system of @xmath37 species interacting through @xmath38 different reaction channels .",
    "for the sake of brevity , we write @xmath39 .",
    "let @xmath8 be the number of particles of species @xmath7 in the system at time @xmath9 .",
    "we want to study the evolution of the state vector , @xmath40 modelled as a continuous - time , discrete - space markov chain starting at some state , @xmath41 .",
    "each reaction can be described by the vector @xmath42 , such that , for a state vector @xmath43 , a single firing of reaction @xmath44 leads to the change @xmath45 the probability that reaction @xmath44 will occur during the small interval @xmath46 is then assumed to be @xmath47 with a given non - negative polynomial propensity function , @xmath48 .",
    "we set @xmath49 for those @xmath50 such that @xmath51 . a process , @xmath2 , that satisfies , is a continuous - time , discrete - space markov chain that admits the following random time change representation @xcite : @xmath52 where @xmath53 are independent unit - rate poisson processes .",
    "hence , @xmath2 is a non - homogeneous poisson process .    in @xcite ,",
    "the authors assume that there exists a vector , @xmath54 , such that @xmath55 , for any reaction @xmath56 .",
    "therefore , every reaction , @xmath56 , must have at least one negative component .",
    "this means that the species can be either transformed into other species or be consumed during the reaction . as a consequence , the space of states is contained in a simplex with vertices in the coordinate axis .",
    "this assumption excludes , for instance , birth processes . in our numerical examples",
    ", we allow the set of possible states of the system to be infinite , but we explicitly avoid cases in which one or more species grows exponentially fast or blows up in the time interval @xmath57 $ ] .    in this setting ,",
    "the solution of the following system of ordinary differential equations , @xmath58 is called mean field solution , where @xmath59 is the matrix with columns @xmath56 and @xmath60 is the column vector of propensities . in section [ eec ]",
    ", we use the mean field path for scaling and preprocessing constants associated with the computational work of the ssa and chernoff tau - leap steps .",
    "the mnrm , introduced in @xcite , based on the next reaction method ( nrm ) @xcite , is an exact simulation algorithm like gillespie s ssa that explicitly uses representation for simulating exact paths and generates only one exponential random variable per iteration .",
    "the reaction times are modeled with firing times of poisson processes , @xmath61 , with internal times given by the integrated propensity functions .",
    "the randomness is now separated from the state of the system and is encapsulated in the @xmath61 s . for each reaction , @xmath44 , the internal time",
    "is defined as @xmath62 .",
    "there are @xmath63 time frames in the system , the absolute one , @xmath9 , and one for each poisson process , @xmath61 .",
    "computing the next reaction and its time is equivalent to computing how much time passes before one of the poisson processes , @xmath61 , fires , and to identifying which process fires at that particular time , by taking the minimum of such times . the nrm and mnrm make use of internal times to reduce the number of simulated random variables by half .",
    "in the following , we describe the mrnm and then we present its implementation in algorithm [ alg : mnr ] .    given @xmath9 , we have the propensity @xmath64 and the internal time @xmath65 .",
    "now , let @xmath66 be the remaining time for the reaction , @xmath44 , to fire , assuming that @xmath67 stays constant over the interval @xmath68 .",
    "then , @xmath69 is the time when the next reaction , @xmath44 , occurs .",
    "the next internal time at which the reaction , @xmath44 , fires is then given by @xmath70 . when simulating the next step , the first reaction that fires occurs after @xmath71 .",
    "we then update the state of the system according to that reaction , add @xmath72 to the global time , @xmath9 , and then update the internal times by adding @xmath73 to each @xmath74 .",
    "we are left to determine the value of @xmath66 , _ i.e. _ , the amount of time until the poisson process , @xmath61 , fires , taking into account that @xmath67 remains constant until the first reaction occurs .",
    "denote by @xmath74 the first firing time of @xmath61 that is strictly larger than @xmath74 , _",
    "i.e. _ , @xmath75 and finally @xmath76 .",
    "@xmath77 , @xmath78 , @xmath79 and @xmath80 generate @xmath38 independent , uniform@xmath81 random numbers , @xmath82 @xmath83 @xmath84 @xmath85 @xmath86 @xmath87 @xmath88 @xmath89 @xmath90 @xmath91 uniform@xmath81 @xmath92 @xmath93 @xmath94    among the advantages already mentioned , we can easily modify algorithm 1 to generate paths in the cases where the rate functions depend on time and also when there are reactions delayed in time . finally , it is possible to simulate correlated exact / tau - leap paths using this algorithm as well as nested tau - leap / tau - leap paths . in @xcite ,",
    "this technique is used to develop a uniform - step , unbiased , multilevel monte carlo ( mlmc ) algorithm . in section [ sec : chp ] , we use this feature for coupling two exact paths .      in this section , we define @xmath95 , the tau - leap approximation of the process , @xmath2 , which follows from applying the forward euler approximation to the integral term in the following random time - change representation of @xmath2 : @xmath96    the tau - leap method was proposed in @xcite to avoid the computational drawback of the exact methods , _",
    "i.e. _ , when many reactions occur during a short time interval . the tau - leap process , @xmath95 , starts from @xmath97 at time @xmath98 , and given that @xmath99 and a time step @xmath100 , we have that @xmath95 at time @xmath101 is generated by @xmath102 where @xmath103 are independent poisson distributed random variables with parameter @xmath104 , used to model the number of times that the reaction @xmath44 fires during the @xmath105 interval .",
    "again , this is nothing other than a forward euler discretization of the stochastic differential equation formulation of the pure jump process , realized by the poisson random measure with state dependent intensity ( see , _",
    "e.g. _ , @xcite ) .    in the limit ,",
    "when @xmath106 tends to zero , the tau - leap method gives the same solution as the exact methods .",
    "the total number of firings in each channel is a poisson - distributed stochastic variable depending only on the initial population , @xmath107 .",
    "the error thus comes from the variation of @xmath108 for @xmath109 .",
    "we observe that the computational work of a tau - leap step involves the generation of @xmath38 independent poisson random variables .",
    "this is in contrast to the computational work of an exact step , which involves only the work of generating two uniform random variables , in the case of the ssa , and only one in the case of mnrm .      in @xcite",
    ", we derived a chernoff - type bound that allows us to guarantee that the one - step exit probability in the tau - leap method is less than a predefined quantity , @xmath110 .",
    "we now briefly summarize the main idea . consider the following pre - leap check problem :",
    "find the largest possible @xmath106 such that , with high probability , in the next step , the approximate process , @xmath111 , will take a value in the lattice , @xmath15 , of non - negative integers .",
    "the solution to that problem can be achieved by solving @xmath37 auxiliary problems , one for each @xmath50-coordinate , @xmath112 , as follows .",
    "find the largest possible @xmath113 , such that @xmath114 where @xmath115 , and @xmath116 is the @xmath7-th coordinate of the @xmath44-th reaction channel , @xmath56 . finally , we let @xmath117 . to find the largest time steps , @xmath118 ,",
    "let @xmath119 .",
    "then , for all @xmath120 , we have the chernoff bound : @xmath121 expressing @xmath118 as a function of @xmath122 , we write @xmath123 where @xmath124 we want to maximize @xmath118 while satisfying condition .",
    "let @xmath125 be this maximum .",
    "we then have the following possibilities : if @xmath126 , for all @xmath44 , then naturally @xmath127 ; otherwise , we have the following three cases :    1 .",
    "[ eq : tsi ] @xmath128 . in this case ,",
    "@xmath129 and @xmath130 is positive and increasing as @xmath131 .",
    "therefore , @xmath132 is equal to the ratio of two positive increasing functions .",
    "the numerator , @xmath133 , is a linear function and the denominator , @xmath130 , grows exponentially fast . then , there exist an upper bound , @xmath125 , and a unique number , @xmath134 , which satisfy @xmath135 .",
    "we developed an algorithm in @xcite for approximating @xmath134 , using the relation @xmath136 .",
    "2 .   if @xmath137 , then @xmath127 .",
    "3 .   if @xmath138 , then @xmath139 .    here",
    "@xmath140 .",
    "in this section , we briefly summarize our previous work , presented in @xcite , on hybrid paths .    the main idea behind the hybrid algorithm is the following .",
    "a path generated by an exact method ( like ssa or mnrm ) never exits the lattice , @xmath15 , although the computational cost may be unaffordable due to many small inter - arrival times typically occurring when the process is `` far '' from the boundary .",
    "a tau - leap path , which may be cheaper than an exact one , could leave the lattice at any step .",
    "the probability of this event depends on the size of the next time step and the current state of the approximate process , @xmath141 .",
    "this one - step exit probability could be large , especially when the approximate process is `` close '' to the boundary .",
    "we developed in @xcite a chernoff - type bound to control the mentioned one - step exit probability .",
    "even more , by construction , the probability that one hybrid path exits the lattice , @xmath15 , can be estimated by @xmath142 } = \\delta { \\mathrm{e}\\left[n_{{\\text{tl}}}\\right ] } - \\frac{\\delta^2}{2}({\\mathrm{e}\\left[n_{{\\text{tl}}}^2\\right ] } - { \\mathrm{e}\\left[n_{{\\text{tl}}}\\right ] } ) + o(\\delta^2),\\end{aligned}\\ ] ] where @xmath143 if and only if the whole hybrid path , @xmath144 , belongs to the lattice , @xmath15 , @xmath145 is the one - step exit probability bound , and @xmath146 is the number of tau - leap steps in a hybrid path . here",
    ", @xmath147 is the complement of the set @xmath148 .    to simulate a hybrid exact / chernoff tau - leap path",
    ", we first developed a one - step switching rule that , given the current state of the approximate process , @xmath141 , adaptively determines whether to use an exact or an approximated method for the next step .",
    "this decision is based on the relative computational cost of taking an exact step ( mnrm ) versus the cost of taking a chernoff tau - leap step .",
    "we show the switching rule in algorithm [ alg : sel ] .",
    "@xmath149 @xmath150 compute chernoff step size ( see section 2.2 in @xcite ) @xmath151 @xmath152 @xmath151    to compare the mentioned computational costs , we define @xmath153 as the ratio between the cost of computing @xmath154 and the cost of computing one step using the mnrm method , and @xmath155 is defined as the cost of taking a chernoff tau - leap step , divided by the cost of taking a mnrm step plus the cost of computing @xmath154 . for further details on the switching rule",
    ", we refer to @xcite .      in this subsection , we briefly summarize the control variates idea developed by giles in @xcite .",
    "let @xmath156}$ ] be a hybrid chernoff tau - leap process with a time mesh of size @xmath157 and a one - step exit probability bound , @xmath14 .",
    "we can simulate paths of @xmath156}$ ] by using algorithm 4 in @xcite .",
    "let @xmath158 .",
    "consider a hierarchy of nested meshes of the time interval @xmath57 $ ] , indexed by @xmath159 .",
    "let @xmath160 be the size of the coarsest time mesh that corresponds to the level @xmath161 .",
    "the size of the time mesh at level @xmath162 is given by @xmath163 , where @xmath164 is a given integer constant .",
    "assume that we are interested in estimating @xmath165}$ ] , and we are able to simulate correlated pairs , @xmath166 for @xmath167 .",
    "then , the following unbiased monte carlo estimator of @xmath165}$ ] uses @xmath168 as a control variate : @xmath169}){\\right)}\\\\         & \\ , = { \\mathrm{e}\\left[g_{l{-}1}\\right ] } +   \\frac{1}{m_l } \\sum_{m_l=1}^{m_l }   ( g_{l}- g_{l{-}1})(\\omega_{m_l}){.}\\end{aligned}\\ ] ] applying this idea recursively and taking into account the following telescopic decomposition : @xmath170 } = { \\mathrm{e}\\left[g_0\\right ] } + \\sum_{{\\ell}=1}^{l } { \\mathrm{e}\\left[g_{\\ell}-g_{\\ell -1}\\right]}$ ] , we arrive at the multilevel monte carlo estimator of @xmath170}$ ] : @xmath171    we have that @xmath172 is unbiased , since @xmath173 } { = } { \\mathrm{e}\\left[g_{l}\\right]}$ ] .",
    "the variance of @xmath172 is given by @xmath174 } = \\frac{{\\mathrm{var}\\left[g_0\\right]}}{m_{0 } } + \\sum_{\\ell=1}^l \\frac{{\\mathrm{var}\\left[g_{\\ell}{-}{g_{\\ell{-}1}}\\right]}}{m_{\\ell}}$ ] .",
    "here , we are assuming independence among the batches between levels .",
    "for highly correlated pairs , @xmath166 , we can expect , for the same computational work , that @xmath174}$ ] is much less than the variance of the standard monte carlo estimator of @xmath170}$ ] .",
    "let us give a close examination of the problem of estimating @xmath175}$ ] for highly correlated pairs , @xmath166 .",
    "this estimation is required to solve the optimization problem , that indicates how to choose the simulation parameters , particularly the number of simulated coupled paths for each pair of consecutive levels , @xmath35 .",
    "when @xmath176 becomes large , due to our coupling strategy developed in section [ sec : couplingpaths ] , we expect to obtain @xmath177 in most of our simulations , while observing differences only in a very small proportion of the simulated coupled paths .    for the sake of illustration , let us assume that the random variable @xmath178 takes values in the set @xmath179 , with respective probabilities @xmath180 , where @xmath181 goes to zero .",
    "the kurtosis of @xmath182 is by definition @xmath183 } { \\right)}^4\\right]}}{{\\left(}{\\mathrm{e}\\left[{\\left(}\\chi_{\\ell } - { \\mathrm{e}\\left[\\chi_{\\ell}\\right]}{\\right)}^2\\right ] } { \\right)}^2}-3{.}\\end{aligned}\\ ] ] simple calculations show that the kurtosis of @xmath182 is @xmath184 , and we observe that @xmath185 .",
    "the maximum likelihood estimator of @xmath186 , @xmath187 , is the sample average of @xmath188 independent and identically distributed ( iid ) values of @xmath189 .",
    "the coefficient of variation of @xmath187 , defined as @xmath190}})^{1/2 } ( { \\mathrm{e}\\left[\\hat{\\theta}_{\\ell}\\right]})^{-1}$ ] , is @xmath191 .",
    "therefore , an accurate estimation of @xmath181 requires a sample of size @xmath192 this lower bound on @xmath188 goes strongly against the spirit of the multilevel monte carlo method , where @xmath188 should be a decreasing function of @xmath176 .    to overcome this difficulty , in section [ sec : vl ]",
    ", we developed a formula based on dual - weighted residuals .",
    "the technique of dual - weighted residuals can be motivated as follows : consider a process @xmath193 , such that its position at time @xmath122 , having departed from the state @xmath50 , at a previous time @xmath9 , is denoted as @xmath194 .",
    "notice that for @xmath195 , we have that @xmath196 .",
    "let us define an auxiliary function @xmath197 , where @xmath198 is an observable scalar function of the final state of the process @xmath193 that started from the state @xmath50 at the initial time , @xmath9 .",
    "if @xmath95 is a process approximating @xmath193 , we want to have a computable approximation for @xmath199 .",
    "consider a time mesh , @xmath200 , and define @xmath201 , @xmath202 and @xmath203 .",
    "observe that @xmath204    we can now write a backward recurrence for the dual weights , @xmath205 : @xmath206    this reasoning evidently works for processes @xmath193 that are pathwise differentiable with respect to the initial condition .",
    "our space state is in general a subset of the lattice , @xmath15 , and for that reason , we can not directly apply this technique . in @xcite ,",
    "the authors show how this dual - weighted residual technique can be adapted to the tau - leap case in regimes close to the mean field or to the stochastic langevin limit . in more general regimes , the formula , which provides accurate estimates of @xmath175}$ ] in our numerical examples ( see for instance figure [ fig : effdec2 ] in section [ sec : examples ] ) , is promising but more research is needed in this direction .",
    "specifically , in section [ sec : vl ] , the formula is deduced from the conditional distribution of the local errors , @xmath207 , conditional on a sigma - algebra , @xmath208 , generated by the sequence , @xmath209 , and applying the tower properties of conditional expectation and conditional variance .",
    "similar comments apply to formula regarding the weak error , @xmath210}$ ] .      in section [ sec : couplingpaths ] , we first show the main idea for coupling two tau - leap paths , which comes from a construction by kurtz @xcite for coupling two poisson random variables . then , inspired by the ideas of anderson and higham in @xcite , we propose an algorithm for coupling two hybrid chernoff tau - leap paths ( see @xcite ) .",
    "this algorithm uses four building blocks that result from the combination of the mnrm and the tau - leap methods . in section [ sec : mlmc ] , we propose a novel hybrid mlmc estimator .",
    "next , we introduce a global error decomposition ; and finally , we develop formulae to efficiently estimate the variance of the difference of two consecutive levels and to estimate the bias based on dual - weighted residuals .",
    "these estimates are particularly useful to addressing the large kurtosis problem , described in section [ sec : highk ] , that appears at the deeper levels and makes standard sample estimators too costly .",
    "next , in section [ eec ] , we show how to control the three error components of the global error and how to obtain the parameters needed for computing the hybrid mlmc estimator to achieve a given tolerance with nearly optimal computational work .",
    "we also show that the computational complexity of our method is of order @xmath32 . in section [ sec : examples ] , the numerical examples illustrate the advantages of the hybrid mlmc method over the single - level approach presented in @xcite and to the ssa .",
    "section [ sec : conclusions ] presents our conclusions and suggestions for future work .",
    "in this section , we present an algorithm that generates coupled hybrid chernoff tau - leap paths , which is an essential ingredient for the multilevel monte carlo estimator .",
    "we first show how to couple two poisson random variables and then we explain how we make use of the two algorithms presented in @xcite as algorithms 2 and 3 and two additional algorithms we developed to create an algorithm that generates coupled hybrid paths .",
    "we motivate our coupling algorithm ( algorithm [ alg : coupled ] ) by first describing how to couple two poisson random variables . in our context , ` coupling ' means that we want to induce a correlation between them that is as strong as possible .",
    "this construction was first proposed by kurtz in @xcite .",
    "suppose that we want to couple @xmath211 and @xmath212 , two poisson random variables , with rates @xmath213 and @xmath214 , respectively .",
    "consider the following decompositions , @xmath215 where @xmath216 , @xmath217 and @xmath218 are three independent poisson random variables .",
    "here , @xmath219 . observe that at least one of the following vanishes : @xmath220 and @xmath218 .",
    "this is because at least one of the rates is zero .",
    "algorithm [ alg : coupled ] implements these ideas .",
    "finally , note that , by construction , we have @xmath221 } & = { \\mathrm{var}\\left[\\mathcal{q}_1(\\lambda_1 -\\lambda_1 \\wedge \\lambda_2 )   - \\mathcal{q}_2(\\lambda_2 - \\lambda_1 \\wedge \\lambda_2 ) \\right]}\\\\   & = { \\left|\\lambda_1 - \\lambda_2\\right| } \\nonumber { .}\\end{aligned}\\ ] ] however , if instead we consider making @xmath211 and @xmath212 independent , then @xmath222 } = \\lambda_1 + \\lambda_2 { , } \\ ] ] which may be a large value even when @xmath213 and @xmath214 are close .      in this section ,",
    "we describe how to generate two coupled hybrid chernoff tau - leap paths , @xmath95 and @xmath223 , corresponding to two nested time discretizations , called coarse and fine , respectively .",
    "assume that the current time is @xmath9 , and we know the states , @xmath107 and @xmath224 .",
    "based on this knowledge , we have to determine a method for each level .",
    "this method can be either the mnrm or the tau - leap one , determining four possible combinations leading to four algorithms , b1 , b2 , b3 and b4 , that we use as building blocks .",
    "table [ tab : algs ] summarizes them .    .building blocks for simulating two coupled hybrid chernoff tau - leap paths .",
    "algorithms b1 and b2 are presented as algorithms 2 and 3 in @xcite .",
    "algorithm b3 can be directly obtained from algorithm b2 .",
    "algorithm b4 is also based on algorithm b2 , but to produce mnrm steps , we update the propensities at the coarse level at the beginning of each time interval defined by the fine level .",
    "[ cols=\"<,^ , < , < \" , ]     we note that the only case in which we use a poisson random variates generator for the tau - leap method is in algorithm b1 . in algorithms b2 and b3",
    ", the poisson random variables are simulated by adding independent exponential random variables with the same rate , @xmath225 , until a given time final time @xmath5 is exceeded .",
    "the rate , @xmath225 , is obtained by freezing the propensity functions , @xmath226 , at time @xmath9 .",
    "more specifically , the poisson random variates are obtained by using the mnrm repeatedly without updating the intensity .",
    "we now briefly describe the chernoff hybrid coupling algorithm , _",
    "i.e. _ , algorithm [ alg : coupled ] .",
    "given the current time , @xmath9 , and the current state of the process at the coarse level , @xmath227 , and the fine level , @xmath228 , this algorithm determines the next time point at which we run the algorithm ( called time `` horizon '' ) .",
    "to fix the idea , let us assume that , based on @xmath227 , the one - step switching rule , _",
    "i.e. _ , algorithm [ alg : sel ] , chooses the tau - leap method at the coarse level , with the corresponding chernoff step size , @xmath229 .",
    "as we mentioned , this @xmath229 is the largest step size such that the probability that the process , in the next time step , takes a value outside @xmath15 , is less than @xmath230 .",
    "this step size plus the current time , @xmath9 , can not be greater than the final time , @xmath5 , and also can not be greater than the next time discretization grid point in the coarse grid , @xmath231 , because the discretization error must be controlled . taking the minimum of all those values , we obtain the next time horizon at the coarse grid , @xmath232 .",
    "note that , if the chosen method is mnrm instead of tau - leap , we do not need to take into account the grid , and the next time horizon will be the minimum between the next reaction time and the final time , @xmath5 .",
    "we now explain algorithm b1 ( tl - tl ) .",
    "assume that tau - leap is chosen at the coarse and at the fine level .",
    "we thus obtain two time horizons , one for the coarse level , @xmath232 , and another for the fine level , @xmath233 . in this case",
    ", the global time horizon will be @xmath234 .",
    "since the chosen method in both grid levels is tau - leap , we need to freeze the propensities at the beginning of the corresponding intervals . in the coarse case , during the interval @xmath235 ( the propensities are equal to @xmath236 ) , and in the fine case during the interval @xmath237 ( the propensities are equal to @xmath238 ) .",
    "suppose that @xmath239 ( see figure [ fig : hh ] ) .    ) , where @xmath240 .",
    "the synchronization horizon @xmath241 , defined as @xmath234 , is equal to @xmath232 in this case .",
    "notice that @xmath242 and @xmath243 ]    then , we couple two poisson random variables at time @xmath244 , using the idea described in section [ sec : couplingpoiss ] .",
    "when time reaches @xmath232 , the decision between which method to use ( and the corresponding step size ) at the coarse level must be made again .",
    "note that the propensities of the process at the fine grid will be kept frozen until @xmath233 .",
    "the case when @xmath245 is analogous to the one we described , but the decisions on the method and step size are made at the finer level , when time reaches @xmath233 .",
    "it can also be possible that @xmath246 .",
    "in that case , the decision between which method to use ( and the corresponding step size ) must be made at the coarse and at the fine level .    in the case of algorithm b2 ( tl - mnrm ) , we assume that tau - leap is chosen at the coarse level , and mnrm at the fine level , obtaining two time horizons , one for the coarse level , @xmath232 , and another for the fine level , @xmath233 . the only difference in how we determine the time horizons between algorithms b1 and b2 is that the time discretization grid points in the fine grid are not taken into account to determine @xmath233 .",
    "algorithm b2 is then applied until the simulation reaches @xmath234 .",
    "suppose that @xmath247 . in this case ,",
    "the process @xmath193 could take more than one step to reach @xmath233 . at each step , the propensity functions @xmath248 are computed , but not the propensities for the coarse level , because in that case the tau - leap method is used .",
    "note that the decision between which algorithm to use ( b2 or another ) is not made at those steps , but only when time reaches @xmath233 .",
    "when time reaches @xmath233 , the decision of which method to use ( and the corresponding step size ) at the fine level must be made again . in this case , the propensities at the coarse grid will be kept frozen until @xmath232 .",
    "the reasoning for the cases @xmath249 and @xmath250 are similar to before .    the other two cases , that is , b3 and b4 , are the same as b2 .",
    "the only difference resides is when to update the propensity values , @xmath251 and @xmath252 .",
    "see algorithm [ alg : coupled ] for more details .",
    "as made clear in the preceding paragraphs , the decision on which algorithm to use for a certain time interval is made only at the horizon points .",
    "[ rem : telescoping][about telescoping ] to ensure the telescoping sum property , the probability law of the hybrid process at level @xmath176 should be the same disregarding whether level @xmath176 is the finer in the pair @xmath253 or the coarser in the pair @xmath254 .",
    "for that reason , each process has its own next horizon as its decision points .",
    "see figure [ fig : hh ] showing the time horizons scheme and figures [ fig : box2 ] and [ fig : box3 ] in section [ sec : examples ] to see that the telescoping sum property is satisfied by our hybrid coupling sampling scheme .",
    "in this section , we present the multilevel monte carlo estimator .",
    "we first show the estimator and its properties and then we analyze and control the computational global error , which is decomposed into three error components : the discretization error , the global exit error , and the monte carlo statistical error .",
    "we give upper bounds for each one of the three components .      in this section ,",
    "we discuss and implement a variation of the multilevel monte carlo estimator for the hybrid chernoff tau - leap case .",
    "the main ingredient of this section is algorithm [ alg : coupled ] , which generates coupled hybrid paths at levels @xmath255 and @xmath176 .",
    "let us now introduce some notation .",
    "let @xmath256 be the event in which the @xmath257-path arrived at the final time , @xmath5 , without exiting the state space of @xmath2 .",
    "let @xmath258 , be the indicator function of an arbitrary set , @xmath148 .",
    "finally , @xmath259 was defined in section [ mlmcintro ] .",
    "consider the following telescopic decomposition : @xmath260 } = { \\mathrm{e}\\left[g_0 { \\mathbf{1}_{a_0}}\\right ] } { + } \\sum_{\\ell=1}^l { \\mathrm{e}\\left[g_\\ell{\\mathbf{1}_{a_\\ell}}-g_{\\ell-1}{\\mathbf{1}_{a_{\\ell-1}}}\\right ] } { , } \\end{aligned}\\ ] ] which motivates the definition of our mlmc estimator of @xmath6}$ ] , @xmath261(\\omega_{m,\\ell } ) { .}\\end{aligned}\\ ] ]      in this section , we define the computational global error , @xmath262 , and show how it can be naturally decomposed into three components : the discretization error , @xmath263 , and the exit error , @xmath264 , both coming from the tau - leap part of the hybrid method and the monte carlo statistical error , @xmath265 .",
    "next , we show how to model and control the global error , @xmath262 , giving upper bounds for each one of the three components .",
    "we define the computational global error , @xmath262 , as @xmath266 } - \\mathcal{m}_l{.}\\ ] ] now , consider the following decomposition of @xmath262 : @xmath267 } - \\mathcal{m}_l & = { \\mathrm{e}\\left[g(x(t))({\\mathbf{1}_{a_l}}+{\\mathbf{1}_{a^c_l}})\\right ] } - { \\mathrm{e}\\left[g_l { \\mathbf{1}_{a_l}}\\right ] } + { \\mathrm{e}\\left[g_l { \\mathbf{1}_{a_l}}\\right ] } - \\mathcal{m}_l\\nonumber \\\\ & = \\underbrace{{\\mathrm{e}\\left[g(x(t ) ) { \\mathbf{1}_{a^c_l}}\\right]}}_{=:{\\mathcal{e}}_{e , l } }    + \\underbrace{{\\mathrm{e}\\left [ { \\left(}g(x(t ) ) { - } g_l { \\right)}{\\mathbf{1}_{a_l}}\\right]}}_{=:{\\mathcal{e}}_{i , l } } + \\underbrace{{\\mathrm{e}\\left[g_l { \\mathbf{1}_{a_l}}\\right]}{-}\\mathcal{m}_l}_{=:{\\mathcal{e}}_{s , l}}{.}\\end{aligned}\\ ] ]    we show in @xcite that by choosing adequately the one - step exit probability bound , @xmath14 , the exit error , @xmath264 , satisfies @xmath268}|\\ , { \\mathrm{p}\\left(a^c_l\\right)}\\leq tol^2 $ ] . an efficient procedure for accurately estimating @xmath263 in the context of the tau - leap method",
    "is described in @xcite .",
    "we adapt this method in algorithm [ alg : weakerror ] for estimating the weak error in the hybrid context .",
    "a brief description follows . for each hybrid path , @xmath269 , we define the sequence of dual weights @xmath270 backwards as follows ( see section [ sec : highk ] ) : @xmath271 where @xmath272 , @xmath273 is the gradient operator and @xmath274_{j , i}$ ] is the jacobian matrix of the propensity function , @xmath67 , for @xmath275 and @xmath276 .",
    "according to this method , @xmath263 is approximated by @xmath277 , where @xmath278 @xmath279 , and , @xmath280 denote the sample mean and the sample variance of the random variable , @xmath2 , respectively .",
    "here , @xmath281 , @xmath282 if and only if , at time @xmath283 , the tau - leap method was used , and we denote by @xmath284 the @xmath285 identity matrix .",
    "it is easy to see that the computational cost per path of the dual computations in is comparable , and possibly smaller than the hybrid path .",
    "indeed , no new random variables , especially poisson ones , which are the most computationally expensive in the forward simulation , need to be sampled and no coupling between levels is needed .",
    "moreover , we use only to determine the discretisation parameters for the actual run ; so is thus used only in a fraction of the realisations .",
    "the variance of the statistical error , @xmath265 , is given by @xmath286 , where @xmath287}$ ] and @xmath288},\\,\\,\\ell \\geq 1 $ ] .",
    "in the next subsection , we show how to estimate @xmath289 efficiently using the duals from .      here",
    ", we derive the formula for estimating the variance , @xmath290 .",
    "it is based on dual - weighted local errors arising from two consecutive tau - leap approximations of the process , @xmath2 . for each level @xmath162 ,",
    "the formula estimates @xmath289 with much smaller statistical error than the standard sample estimator , which is seriously affected by the large kurtosis present at the deepest levels ( see section [ sec : highk ] ) .",
    "let us introduce some notation : @xmath291 here , @xmath292 is the cumulative distribution function of a standard gaussian random variable .",
    "we define our dual - weighted estimator of @xmath289 as @xmath293 where @xmath294 if and only if @xmath295 for all @xmath296 , where @xmath297 is a positive user - defined constant .",
    "first , notice that @xmath289 could be a very small positive number .",
    "in fact , in our numerical experiments , we observe that the standard monte carlo sample estimation of this quantity turns out to be computationally infeasible due to the huge number of simulations required to stabilize its coefficient of variation . for this reason ,",
    "we initially consider the following dual - weighted approximations : @xmath298 } & \\approx { \\mathrm{e}\\left[\\sum_{n } \\varphi_{n+1,\\ell-1 } \\cdot e_{n+1,\\ell-1}\\right ] } { , } \\\\ { \\mathrm{var}\\left[\\ g_{\\ell}-g_{\\ell-1 } \\right ] } & \\approx { \\mathrm{var}\\left[\\sum_{n } \\varphi_{n+1,\\ell-1 } \\cdot e_{n+1,\\ell-1}\\right]}{,}\\nonumber\\end{aligned}\\ ] ] where @xmath299 , defined in , is a sequence of dual weights computed backwards from a simulated path , @xmath300 , and the sequence of local errors , @xmath301 , defined in , is the subject of the next subsection .      for simplicity of analysis",
    ", we make two assumptions : i ) the time mesh associated with the level , @xmath302 , is obtained by halving the intervals of the level @xmath255 ; ii ) we perform the tau - leap at both levels without considering the chernoff bounds described in section [ chernoff_onestep ] .",
    "let @xmath95 and @xmath223 be two tau - leap approximations of @xmath2 based on two consecutive grid levels , for instance , @xmath303 and @xmath304 .",
    "consider two consecutive time - mesh points for @xmath95 , @xmath305 , and three consecutive time - mesh points for @xmath223 , @xmath306 .",
    "let @xmath95 and @xmath223 start from @xmath307 at time @xmath308 .",
    "the first step for coupling @xmath95 and @xmath223 is to define    @xmath309    where @xmath310 are poisson random variables .",
    "to couple the @xmath95 and @xmath223 processes , we first decompose @xmath311 as the sum of two independent poisson random variables , @xmath312 . as a consequence , @xmath95 and @xmath223",
    "coincide in the closed interval @xmath313 $ ] . by applying this decomposition in",
    ", we obtain @xmath314    the second step for coupling @xmath95 and @xmath223 , according to @xcite , is as follows : let @xmath315 , @xmath316 and @xmath317 .",
    "notice that for each @xmath44 , either @xmath318 or @xmath319 is zero ( or both ) .",
    "now , consider the following decompositions : @xmath320 where @xmath321 , @xmath322 and @xmath323 are independent poisson random variables .    by substituting into ,",
    "we define the local error , @xmath324 , as @xmath325 where @xmath326 and @xmath327 is defined in .",
    "note that in not only are @xmath328 and @xmath329 random variables , but @xmath330 is also random because it depends on the random variables @xmath331 . also note that all the mentioned random variables are independent .      at this moment , it is convenient to recall the tower properties of the conditional expectation and the conditional variance : given a random variable , @xmath2 , and a sigma algebra , @xmath208 , defined over the same probability space , we have @xmath332}&={\\mathrm{e}\\left[{\\mathrm{e}\\left[x{\\ , \\big| \\,}\\mathcal{f}\\right]}\\right]}{,}\\nonumber\\\\ \\label{eq : towersv } { \\mathrm{var}\\left[x\\right]}&={\\mathrm{var}\\left[{\\mathrm{e}\\left[x{\\ , \\big| \\,}\\mathcal{f}\\right]}\\right]}+{\\mathrm{e}\\left[{\\mathrm{var}\\left[x{\\ , \\big| \\,}\\mathcal{f}\\right]}\\right]}{.}\\end{aligned}\\ ] ]    hereafter , we fix @xmath176 and , for the sake of brevity , omit it as a subindex .    applying to @xmath333 and conditioning on @xmath208 , we obtain @xmath334}&={\\mathrm{var}\\left[{\\mathrm{e}\\left[\\sum_n \\varphi_{n+1 } \\cdot e_{n+1}\\big|\\mathcal{f}\\right]}\\right]}+ { \\mathrm{e}\\left[{\\mathrm{var}\\left[\\sum_n \\varphi_{n+1 } \\cdot e_{n+1}\\big|\\mathcal{f}\\right]}\\right]}\\nonumber\\\\ & = { \\mathrm{var}\\left[\\sum_n { \\mathrm{e}\\left [ \\varphi_{n+1 } \\cdot e_{n+1}{\\ , \\big| \\,}\\mathcal{f}\\right]}\\right]}+ { \\mathrm{e}\\left[\\sum_n { \\mathrm{var}\\left [ \\varphi_{n+1 } \\cdot e_{n+1}{\\ , \\big| \\,}\\mathcal{f}\\right]}\\right]}{.}\\end{aligned}\\ ] ] the main idea is to generate @xmath188 monte carlo paths , @xmath335 , and to estimate @xmath336}$ ] using @xmath337}(\\bar \\omega)}_{s_e(\\bar\\omega)};m_{\\ell}\\right)}+ { \\mathcal{a}\\left(\\underbrace{\\sum_n { \\mathrm{var}\\left [ \\varphi_{n+1 } \\cdot e_{n+1}{\\ , \\big| \\,}\\mathcal{f}\\right]}(\\bar \\omega)}_{s_v(\\bar\\omega)};m_{\\ell}\\right)}{.}\\end{aligned}\\ ] ]    to avoid nested monte carlo calculations , we develop exact and approximate formulas for computing @xmath338}$ ] and @xmath339}$ ] . to derive those formulas",
    ", we consider a sigma - algebra , @xmath208 , such that @xmath340 , conditioned on @xmath208 , is deterministic , _",
    "i.e. _ , @xmath340 is measurable with respect to @xmath208 . in this way",
    ", the only randomness in @xmath338}$ ] and @xmath339}$ ] comes from the local errors , @xmath341 .      in this section ,",
    "we derive a local error representation that takes into account the fact that the dual is computed backwards and the distribution of the local errors that is relevant to our calculations is therefore not exactly the one given by , but the distribution given by .",
    "consider the sequence @xmath342 defined in .",
    "for fixed @xmath343 , define @xmath344 as the sigma - algebra @xmath345 _ i.e. _ , the information we obtain by observing the randomness used to generate @xmath346 from @xmath347 .",
    "motivated by dual - weighted expansions , we want to express the local error representation conditional on @xmath348 .    at this point , it is convenient to remember a key result for building poissonian bridges .",
    "if @xmath349 and @xmath350 are two independent poisson random variables with parameters @xmath213 and @xmath214 , respectively , we have that @xmath351 is a binomial random variable with parameters @xmath352 and @xmath353 .",
    "applying this observation to the decomposition @xmath354 , we conclude that the conditional distribution of @xmath355 given @xmath344 , _",
    "i.e. _ , @xmath356 , is binomial with parameters @xmath357 and @xmath358 .",
    "define now the sigma - algebra , @xmath359 , as @xmath360 applying the same argument to @xmath329 , defined in , we conclude that @xmath361 from the definition of @xmath362 in , we conclude that @xmath363 notice that , by construction , @xmath364 and @xmath365 are independent random variables . since @xmath366 and @xmath367 , we can express the conditional local error as @xmath368 in the distribution sense .",
    "for instance , we can easily compute the expectation of @xmath369 as follows : @xmath370 } =   \\sum_j \\nu_j   \\delta a_{j , n}{\\left(}\\frac{\\delta t_n}{2}{\\mathbf{1}_{\\{\\delta a_{j , n}\\geq 0\\ } } } +   \\frac{\\mathcal{y}_{j , n}{-}\\mathcal{q}_{j , n}}{a_j(x_n)}{\\mathbf{1}_{\\{\\delta a_{j , n}<0\\}}}{\\right)}{.}\\end{aligned}\\ ] ] taking into account that the joint distribution of @xmath371 is given by @xmath372 we can exactly compute the expected value and the variance of @xmath373 for any given deterministic vector , @xmath374 . notice that given @xmath208 , the sequence @xmath342 is deterministic and , as a consequence , the sequence @xmath375 is also a deterministic sequence of vectors .",
    "we can thus compute @xmath376 } \\text { and } { \\mathrm{var}\\left[\\sum_n \\varphi_{n+1}\\cdot e_{n+1}{\\ , \\big| \\,}\\mathcal{f}\\right]}\\end{aligned}\\ ] ] exactly and proceed as stated at the beginning of this section .",
    "however , trying to develop computable expressions from has two main disadvantages : i ) it may lead to computationally demanding procedures , especially for systems with many reaction channels or in regimes with high activity ; ii ) it may be affected by the variance associated with the randomness in @xmath344 and @xmath359 .      in this section ,",
    "we derive the formula .",
    "our goal is to find computable approximations of , where the underlying sigma - algebra , @xmath208 , is just the information gathered by observing the coarse path , @xmath95 .",
    "this means that our formula should not depend explicitly on the knowledge of the random variables that generate @xmath344 and @xmath359 . at this point",
    ", it is important to recall the comments in section [ sec : vl ] ; that is , the sequence @xmath340 is measurable with respect to @xmath208 .",
    "this implies that , for all @xmath343 , @xmath378 is independent of @xmath359 . hereafter , for notational convenience , we omit writing explicitly the conditioning on @xmath208 in our formulae .",
    "it turns out that the leading order terms of the conditional moments obtained from are essentially the same as those computed from .",
    "we will then derive from . using the notation from section [ sec : vl ] , we have that @xmath379 by the tower property , we obtain @xmath380}={\\mathrm{e}\\left[{\\mathrm{e}\\left[(\\varphi_{n+1 } \\cdot e_{n+1}){\\ , \\big| \\,}\\mathcal{g}_n\\right]}\\right ] } =   \\frac{\\delta t_n}{2}\\sum_j f_{j ,",
    "n } { \\mathrm{e}\\left[\\delta a_{j , n}\\right]}{.}\\end{aligned}\\ ] ] now let us consider the first - order taylor expansion : @xmath381 since @xmath382 , we have that @xmath383 } = \\mu_{j , n}$ ] and @xmath384 } = \\sigma^2_{j , n}$ ] .",
    "@xmath380}\\approx \\frac{\\delta t_n}{2 } \\sum_j f_{j , n}\\,\\mu_{j , n}{.}\\end{aligned}\\ ] ] now , we use again the tower property for the variance : @xmath385 } = { \\mathrm{var}\\left[{\\mathrm{e}\\left[(\\varphi_{n+1 } \\cdot e_{n+1}){\\ , \\big| \\,}\\mathcal{g}_n\\right]}\\right ] } + { \\mathrm{e}\\left[{\\mathrm{var}\\left[(\\varphi_{n+1 } \\cdot e_{n+1}){\\ , \\big| \\,}\\mathcal{g}_n\\right]}\\right]}{.}\\end{aligned}\\ ] ] we then immediately obtain @xmath386}\\right ] } & \\approx \\frac{(\\delta t_n)^3}{8}\\sum_{j , j ' } f_{j , n}f_{j',n } \\sum_i(\\nabla a_j(x_n)\\cdot \\nu_i)(\\nabla a_{j'}(x_n)\\cdot \\nu_i)a_i(x_n){,}\\\\\\nonumber { \\mathrm{e}\\left[{\\mathrm{var}\\left[(\\varphi_{n+1 } \\cdot e_{n+1}){\\ , \\big| \\,}\\mathcal{g}_n\\right]}\\right]}&\\approx \\frac{\\delta t_n}{2 } \\sum_j f^2_{j , n}{\\mathrm{e}\\left[\\delta a_{j , n}\\ , \\text{sgn}(\\delta a_{j , n})\\right]}{.}\\end{aligned}\\ ] ]    let us consider the case where @xmath387 is large enough for all @xmath7 . it is well known that a poisson random variable , @xmath388 , is well approximated by a gaussian random variable , @xmath389 , for moderate values of @xmath225 , say @xmath390 . since @xmath382 , we have that , when @xmath387 is large enough for all @xmath7 , @xmath391 .",
    "consider a gaussian random variable @xmath392 with parameters @xmath393 and @xmath394 .",
    "then , @xmath395 } & = \\mu { \\mathrm{p}\\left(\\mu+\\sigma z>0\\right)}+\\frac{\\sigma}{\\sqrt{2\\pi } } \\int_{-\\mu/\\sigma}^{+\\infty } z\\exp{\\left(-z^2/2\\right)}\\,dz\\\\ \\nonumber & = \\mu(1-\\phi(-\\mu/\\sigma))+ \\frac{\\sigma}{\\sqrt{2\\pi}}\\exp{\\left(-(\\mu/\\sigma)^2/2\\right)}{.}\\end{aligned}\\ ] ] from , we immediately get @xmath396 } & \\approx \\mu_{j , n}{\\left(}1-p_{j , n}{\\right)}+ \\frac{\\sigma_{j , n}}{\\sqrt{2 \\pi } } \\exp{\\left(}-\\frac{q^2_{j , n}}{2}{\\right)}{,}\\\\\\nonumber { \\mathrm{e}\\left[\\delta a_{j , n } { \\mathbf{1}_{\\{\\delta a_{j , n}<0\\}}}\\right ] } & \\approx \\mu_{j , n}\\,p_{j , n } - \\frac{\\sigma_{j , n}}{\\sqrt{2 \\pi } } \\exp{\\left(}-\\frac{q^2_{j , n}}{2}{\\right)}{.}\\end{aligned}\\ ] ] by subtracting the expressions in , we obtain @xmath397}\\right]}&\\approx \\frac{\\delta t_n}{2 } \\sum_j f^2_{j , n } \\left ( \\tilde{\\mu}_{j , n}+\\tilde{\\sigma}_{j , n } \\right){.}\\end{aligned}\\ ] ]",
    "let us now consider the case where @xmath387 is close to zero for some @xmath7 .",
    "we can bound the expression @xmath398}$ ] by @xmath399}$ ] and also @xmath400}}$ ] .",
    "it is easy to see that @xmath399}\\leq{\\bar{\\mu}_{j , n}}$ ] .",
    "regarding @xmath401}$ ] , it can be approximated by @xmath402 } =   \\sum_{i , i ' } ( \\nabla a_j(x_n)\\cdot \\nu_i)\\,(\\nabla a_j(x_n)\\cdot \\nu_{i'})\\,{\\mathrm{e}\\left[\\mathcal{q}_i\\,\\mathcal{q}_{i'}\\right]}{.}\\end{aligned}\\ ] ] since @xmath403 } =   \\frac{(\\delta t_n)^2}{4}a_{i}(x_n)a_{i'}(x_n){\\mathbf{1}_{i\\neq i ' } } + { \\left(}a_i(x_n)\\frac{\\delta t_n}{2 } + { \\left(}a_i(x_n)\\frac{\\delta t_n}{2}{\\right)}^2{\\right)}{\\mathbf{1}_{i= i'}}{,}\\end{aligned}\\ ] ] we can rearrange terms and approximate @xmath401}$ ] by @xmath404 .",
    "we conclude that @xmath398}$ ] can be bounded by @xmath405 , which has been defined as @xmath406 .",
    "formula can be considered as an initial , relatively successful attempt to estimate @xmath289 , but there is still room for improvement .",
    "the main problem is the lack of sharp concentration inequalities for linear combinations of independent poisson random variables . with the numerical examples ,",
    "we show that the efficiency index of the formula is acceptable for our estimation purposes .",
    "we are assuming that only tau - leap steps are taken , but in our hybrid algorithms , some steps can be exact , and , hence , do not contribute to the local error .",
    "for that reason , we include the indicator function of the tau - leap step , @xmath407 , in the estimator , @xmath408 .",
    "the dual - weighted residual approach makes the estimation of @xmath289 feasible . in our numerical experiments",
    ", we found that , using the same number of simulated coupled hybrid paths , the variance of @xmath408 is much smaller than the variance of @xmath409}$ ] , estimated by a standard monte carlo .",
    "note that @xmath408 can be computed using only single - level hybrid paths at level @xmath255 . in the upper right panel of figure [ fig : gtt - diag ]",
    ", we can see that due to the hybrid nature of the simulated paths , it is not possible to predict where the variance of @xmath410 will enter into a superlinear regime .",
    "thus , by extrapolating the @xmath409}$ ] from the coarser levels , we may overestimate the values of @xmath409}$ ] for the deepest levels .",
    "in this section , we present a procedure that estimates @xmath6}$ ] within a given prescribed relative tolerance , @xmath411 , with high probability .",
    "the process contains three phases :    phase i : :    calibration of virtual machine - dependent quantities .",
    "phase ii : :    solution of the work optimization problem : we obtain the total number    of levels , @xmath412 , and the sequences    @xmath413 and    @xmath414 , _ i.e. _ , the one - step exit    probability bounds and the required number of simulations at each    level .",
    "we recall that in section [ mlmcintro ] , we defined    @xmath415 , where    @xmath416 is a given integer constant .",
    "for that reason , to    define the whole sequence of meshes ,    @xmath417 , we simply need to define    the size of the coarsest mesh , @xmath160 .",
    "phase iii : :    estimation of @xmath6}$ ] .      in this section ,",
    "we describe the estimation of several constants , @xmath418 , @xmath419 , @xmath420 and @xmath153 , and functions , @xmath421 and @xmath422 , that allow us to model the expected computational work ( or just work ) , measured in terms of the runtime of hybrid paths , see definitions and .",
    "those quantities are virtual machine dependent ; that is , they are dependent on the computer system used for running the simulations and also on the implementation language .",
    "those quantities are also off - line estimated ; that is , we need to estimate them only once for each virtual machine on which we want to run the hybrid method .",
    "constants @xmath418 , @xmath419 , and @xmath420 reflect the average execution times of each logical path of algorithm [ alg : sel ] .",
    "we have that @xmath418 and @xmath419 reflect the work associated with the two different types of steps in the mnrm .",
    "constant @xmath420 reflects the work needed for computing the chernoff tau - leap size , @xmath154 .",
    "finally , when we perform a tau - leap step , we have the work needed for simulating poisson random variates , which is modeled by the function @xmath421 @xcite .",
    "this function has two constants that are also virtual machine dependent .",
    "the constant , @xmath153 , and the function , @xmath423 , defined through @xmath418 , @xmath419 , and @xmath420 , were introduced in section [ hybrid_algo ] .      in this section",
    ", we set and solve the work optimization problem .",
    "our objective function is the expected total work of the mlmc estimator , @xmath424 , defined in , _",
    "i.e. _ , @xmath425 where @xmath412 is the maximum level ( deepest level ) , @xmath426 is the expected work of a single - level path at level 0 , and @xmath427 , for @xmath428 , is the expected computational work of two coupled paths at levels @xmath429 and @xmath176 .",
    "finally , @xmath430 is the number of single - level paths at level 0 , and @xmath431 , for @xmath428 , is the number of coupled paths at levels @xmath429 and @xmath176 .",
    "let us now describe in detail the quantities , @xmath432 . for @xmath161 , algorithm",
    "[ alg : pathdualscostsl ] generates a single hybrid path",
    ". the building block of a single hybrid path is algorithm [ alg : sel ] , which adaptively determines whether to use an mnrm step or a tau - leap one . according to this algorithm",
    ", there are two ways of taking an mnrm step , depending on the logical conditions , @xmath433 and @xmath434 .",
    "given one particular hybrid path , let @xmath435 be the number of mnrm steps such that @xmath433 is true , and let @xmath436 be the number of mnrm steps such that @xmath437 is false and @xmath434 is true .",
    "when a chernoff tau - leap step is taken , we have constant work , @xmath420 , and variable work computed with the aid of @xmath421 .",
    "then , the expected work of a single hybrid path , at level @xmath438 , is @xmath439 } + c_2 { \\mathrm{e}\\left[{n_{k2}}(\\delta t_0,\\delta_0)\\right ] } + c_3 { \\mathrm{e}\\left[{n_{{\\text{tl}}}}(\\delta t_0,\\delta_0)\\right]}\\\\ & + \\sum_{j=1}^j { \\mathrm{e}\\left[\\int_{[0,t ] } c_p(a_j(\\bar x_0(s))\\tau_{ch}(\\bar x_0(s),\\delta_0)){\\mathbf{1}_{tl}}(\\bar x_0(s ) ) ds\\right ] } \\nonumber { , } \\end{aligned}\\ ] ] where @xmath160 is the size of the time mesh at level 0 and @xmath440 is the exit probability bound at level 0 .",
    "therefore , the expected work at level 0 is @xmath441 , where @xmath430 is the total number of single hybrid paths .    for @xmath162 , we use algorithm [ alg : coupled ] to generate @xmath188-coupled paths that couple the @xmath255 and @xmath176 levels . given two coupled paths , let @xmath442 and @xmath443 be the number of exact steps for level @xmath444 ( coarse mesh ) and @xmath176 ( fine mesh ) , respectively , with associated work @xmath418 .",
    "we define @xmath445 and @xmath446 analogously .",
    "then , the expected work of a pair of coupled hybrid paths at levels @xmath176 and @xmath447 is @xmath448 } + c_2 { \\mathrm{e}\\left[{n_{k2}^{(c)}}(\\ell)\\right ] } + c_3 { \\mathrm{e}\\left[{n_{{\\text{tl}}}^{(c)}}(\\ell)\\right ] } \\\\ \\nonumber & + \\sum_{j=1}^j { \\mathrm{e}\\left[\\int_{[0,t ] } c_p(a_j(\\bar x_\\ell(s))\\tau_{ch}(\\bar x_\\ell(s),\\delta_\\ell)){\\mathbf{1}_{tl}}(\\bar x_\\ell(s ) ) ds\\right]}\\\\ \\nonumber   & + \\sum_{j=1}^j { \\mathrm{e}\\left[\\int_{[0,t ] } c_p(a_j(\\bar x_{\\ell-1}(s))\\tau_{ch}(\\bar x_{\\ell-1}(s),\\delta_{\\ell-1})){\\mathbf{1}_{tl}}(\\bar x_{\\ell-1}(s ) ) ds\\right]}{,}\\end{aligned}\\ ] ] where @xmath449    now , recalling the definitions of the error decomposition , given at the beginning of section [ calibration ] , we have all the elements to formulate the work optimization problem . given a relative tolerance , @xmath411 , we solve @xmath450    it is natural to consider the following family of auxiliary problems indexed on @xmath451 , where we assume for now that the double sequence , @xmath452 , is known : @xmath453 where we have @xmath454 to guarantee an asymptotic confidence level of at least 95% .",
    "let us assume for now that we know @xmath427 , @xmath289 and @xmath455 , for @xmath456 .",
    "let @xmath457 be the smallest value of @xmath412 such that @xmath458 .",
    "this value exists and it is finite since the discretization error , @xmath263 , tends to zero as @xmath412 goes to infinity . for each @xmath459 , define @xmath460 , where the sequence @xmath461 is the solution of the problem .",
    "it is worth mentioning that @xmath461 is quickly obtained as the solution of the following karush - kuhn - tucker problem ( see , _",
    "e.g. _ , @xcite ) : @xmath462 we do not develop here all the calculations , but a pseudo code is given in algorithm [ alg : greedyoptkkt ] .",
    "let us now analyze two extreme cases : i ) for @xmath412 such that @xmath263 is less but very close to @xmath463 , we have that @xmath464 is a very small number . as a consequence ,",
    "we obtain large values of @xmath465 and , hence , a large value of @xmath466 . by adding one more level , _",
    "i.e. _ , @xmath467 , we expect a larger gap between @xmath263 and @xmath468 ; that means that we expect a larger value of @xmath464 that may lead to smaller values of @xmath465 .",
    "we observe that , in spite of adding one more term to @xmath469 , this leads to a smaller value of @xmath469 .",
    "ii ) at the other extreme , a large value of @xmath412 is associated with large values of @xmath470 and therefore with large values of @xmath469 .",
    "this informal ` extreme case analysis ' has been confirmed by our numerical experiments ( see , for instance , figures [ fig : dec2-diag ] and [ fig : gtt - diag ] ( lower - right ) ) , which allow us to conjecture that the sequence @xmath471 is a convex function of @xmath412 and , hence , that it has a unique optimal value achieved at a certain @xmath472 . a pseudo algorithm to find",
    "@xmath472 could be to start computing @xmath473 and @xmath474 .",
    "if @xmath475 , we accept @xmath476 ; otherwise , we proceed to computing the next term of the sequence , @xmath471 .",
    "if , for some @xmath477 , we have @xmath478 , we accept @xmath479 .",
    "of course , we can stop even if @xmath480 , but the difference @xmath481 is sufficiently small . in this last case ,",
    "we accept @xmath482 .      at this point",
    ", we have all the necessary elements to establish a key point of this work , the computational complexity of the multilevel hybrid chernoff tau - leap method .",
    "let us now analyze the optimal amount of work at level @xmath412 , @xmath466 , as a function of the given relative tolerance , @xmath0 . for simplicity ,",
    "let us assume that @xmath483 . in this case",
    ", the optimal number of samples at level @xmath176 is given by @xmath484 for some @xmath485 .",
    "in fact , @xmath486 is the proportion of the tolerance , @xmath0 , that our computational cost optimization algorithm selects for the statistical error , @xmath265 . in our algorithms ,",
    "we impose @xmath487 ; however , our numerical experiments always select a larger value ( see figures [ fig : statdec2 ] and [ fig : statgtt ] ) .    by substituting @xmath465 into the total work formula , @xmath466 ,",
    "we conclude that the optimal expected work , conditional on @xmath486 , is given by @xmath488 } = { \\left(}\\frac{c_a}{\\theta}\\sum_{\\ell=0}^{l(\\theta ) } \\sqrt{{\\mathcal{v}_{\\ell } } \\psi_{\\ell}}{\\right)}^{2 } tol^{-2}{.}\\ ] ] due to the constraint , @xmath487 , we have that @xmath489 let us consider the series @xmath490 .",
    "first , observe that the expected computational work per path at level @xmath176 , @xmath491 , is bounded by a multiple of the expected computational work of the mnrm ( see section [ sec : mnr ] ) , _ i.e. _ , @xmath492 . in our numerical experiments , we observe that taking @xmath493 around @xmath494 is enough .",
    "therefore , @xmath495 .",
    "observe that , by construction , @xmath496 , superlinearly .",
    "more specifically , it satisfies the bound @xmath497 for some positive constant @xmath498 .",
    "therefore , the series @xmath499 is dominated by the geometric series @xmath500 .",
    "we conclude that @xmath501 is bounded and , therefore , the expected computational complexity of the multilevel hybrid chernoff tau - leap method is @xmath502 .      in algorithm",
    "[ alg : cal ] , we propose an iterative method to obtain an approximate solution to the problem .",
    "notice that we are assuming that there are at least two levels in the multilevel hierarchy , _",
    "i.e. _ , @xmath503 .    to solve the problem , we bound the global exit error , @xmath264 , by @xmath504 .",
    "more specifically , we choose @xmath505 to be sufficiently small such that @xmath506 , then we are unnecessarily enforcing a dependence of @xmath507 on @xmath0 .",
    "this dependence may result in very small values of @xmath507 , which in turn may increase the expected number of exact steps and tau - leap steps at level @xmath176 , implying a larger expected computational work at level @xmath176 . in the appendix of @xcite",
    ", we proved that , when @xmath507 tends to zero , the expected values of the number of tau - leap steps at level @xmath176 go to zero , and therefore our hybrid mlmc strategy would converge to the ssa method without the desired reduction in computational work . to avoid the dependence of @xmath508 on @xmath0",
    ", we adopt a different strategy based on the following decomposition : @xmath509 } & = { \\mathrm{var}\\left[g_\\ell - g_{\\ell-1 } { \\ , \\big| \\,}a_{\\ell}\\cap a_{\\ell-1}\\right]}{\\mathrm{p}\\left(a_{\\ell}\\cap a_{\\ell-1}\\right)}\\\\ & + { \\mathrm{var}\\left[g_\\ell{\\ , \\big| \\,}a_{\\ell}\\cap a^c_{\\ell-1}\\right]}{\\mathrm{p}\\left(a_{\\ell}\\cap a^c_{\\ell-1}\\right)}\\\\ & + { \\mathrm{var}\\left[g_{\\ell-1}{\\ , \\big|",
    "\\,}a^c_{\\ell}\\cap a_{\\ell-1}\\right]}{\\mathrm{p}\\left(a^c_{\\ell}\\cap a_{\\ell-1}\\right)}{.}\\end{aligned}\\ ] ] we impose that the first term of the right - hand side dominates the other two .",
    "this is because the conditional variances appearing in the last two terms are of order @xmath510 , while the conditional variance appearing in the first term is of order @xmath511 , and we make our computations with approximations of @xmath289 assuming that @xmath512 is close to one .",
    "we proceed as follows : first , we approximate @xmath512 by @xmath513 ; then , we consider @xmath514 as an approximate upper bound for @xmath515 when @xmath516 .",
    "those considerations lead us to impose @xmath517 } { \\left(}1{-}\\delta_\\ell { \\mathcal{a}\\left({n_{{\\text{tl}}}}(\\delta t_\\ell,\\delta_\\ell);\\cdot\\right)}{\\right)}{\\left(}1{-}\\delta_{\\ell-1 } { \\mathcal{a}\\left({n_{{\\text{tl}}}}(\\delta t_{\\ell-1},\\delta_{\\ell-1});\\cdot\\right)}{\\right)}>\\\\ & { \\mathrm{var}\\left[g_\\ell{\\ , \\big| \\,}{a_{\\ell}}\\cap{a^c_{\\ell-1}}\\right]}\\delta_{\\ell-1 } { \\mathcal{a}\\left({n_{{\\text{tl}}}}(\\delta t_{\\ell-1},\\delta_{\\ell-1});\\cdot\\right ) } +   { \\mathrm{var}\\left[g_{\\ell-1}{\\ , \\big| \\,}{a^c_{\\ell}}\\cap{a_{\\ell-1}}\\right]}\\delta_{\\ell } { \\mathcal{a}\\left({n_{{\\text{tl}}}}(\\delta t_{\\ell},\\delta_{\\ell});\\cdot\\right)}{.}\\nonumber\\end{aligned}\\ ] ] to avoid simultaneous refinements on @xmath507 and @xmath518 , based on , we impose on @xmath507 the following condition : @xmath519    algorithms [ alg : pathdualscostsl ] and [ alg : cal ] provide @xmath520 , @xmath521 and the other required quantities",
    ". condition does not affect the telescoping sum property of our multilevel estimator , @xmath424 , defined in , since each level , @xmath176 , has its own @xmath522 .",
    "[ rem : algcal ] although in algorithm [ alg : cal ] we show that the estimations of @xmath6}$ ] and @xmath523}$ ] are computed using the information from the last level only , in fact we are computing them using a multilevel estimator .",
    "we omit the details in the algorithm for the sake of simplicity . for the case of @xmath524}$ ] , we use the standard mutilevel estimator , and , for the case of @xmath523}$ ] , we use the following telescopic decomposition : @xmath525 } = { \\mathrm{var}\\left[g(\\bar x_0(t))\\right ] } + \\sum_{\\ell=1}^{l}({\\mathrm{var}\\left[g(\\bar x_\\ell(t))\\right]}-{\\mathrm{var}\\left[g(\\bar x_{\\ell-1}(t))\\right]}){,}\\end{aligned}\\ ] ] where @xmath526 is a fixed level . using the usual variance estimators for each level , we obtain an unbiased multilevel estimator of the variance of @xmath527 . we refer to @xcite for details .    algorithm [ alg : coupled ] could compute four types of paths .",
    "it could happen that no approximate process ( the coarse one , @xmath528 , or the fine one , @xmath529 ) exits the lattice , which is the most common case .",
    "it could also happen that one of the approximate processes exits the lattice . and finally , both approximate processes could exit the lattice .",
    "the first case is the most common one and no further explanation is required .",
    "we now explain the case when one of processes exits the lattice .",
    "suppose that the coarse one exits the lattice . in that case , until the fine process reaches time @xmath5 or exits the lattice , we still simulate the coupled process by simulating only the fine path using the single - level hybrid algorithm presented in @xcite . if the fine path reaches @xmath5 , we have that @xmath530 , and @xmath531 .",
    "vice versa , if the fine process exits and the coarse one reaches @xmath5 , we have @xmath532 and @xmath533 .    [ rem : unbiased ] algorithm [ alg : cal ] uses a computational - cost - based stopping criterion .",
    "that is , the algorithm stops refining the time mesh when the estimated total computational cost of the multilevel estimator , @xmath534 , at level @xmath535 , is greater than the corresponding computational cost for level @xmath536 , and only when condition @xmath537 is already satisfied . in that case ,",
    "the latter condition is required for obtaining a solution of the optimization problem .",
    "in our numerical experiments , we observed that the computational cost of two hybrid coupled paths , @xmath427 , may be greater than the computational cost of `` hybrid - exact '' coupled paths ; that is , the computational cost of a hybrid path at level @xmath536 coupled with an exact path at level @xmath535 .",
    "that kind of path , used only at the last level , leads to the following unbiased multilevel estimator : @xmath539(\\omega_{m,\\ell } ) \\\\ & + \\frac{1}{m_{l } } \\sum_{m=1}^{m_l } [ g(x(t ) ) - g_{\\ell-1 } { \\mathbf{1}_{a_{l-1}}}](\\omega_{m , l } )   { .}\\end{aligned}\\ ] ] therefore , it is possible to add another stopping criterion to algorithm [ alg : cal ] related to the comparison between the estimated computational cost of two hybrid coupled paths and the computational cost of hybrid - exact coupled paths",
    ". please note that the condition @xmath540 trivially holds because @xmath541 is zero in such a case . in our numerical examples , there are no significant computational gains in the estimation phase from using that stopping rule and its corresponding estimator .",
    "this alternative hybrid unbiased estimator is inspired by the work of anderson and higham @xcite .      from phase ii",
    ", we found that , to compute our multilevel monte carlo estimator , @xmath424 , for a given tolerance , we have to run @xmath542 single hybrid paths with parameters @xmath543 and @xmath544 coupled hybrid paths with parameters @xmath545 and @xmath546 , for @xmath547 .",
    "but , we will follow a slightly different strategy : we run half of the required simulations and use them to update our estimations of the sequences @xmath548 , @xmath549 , and @xmath550 .",
    "then , we solve the problem again and re - calculate the values of @xmath551 for all @xmath176 .",
    "we proceed iteratively until convergence . in this way",
    ", we take advantage of the information generated by new simulated paths and update the estimations of the sequences of weak errors , computational costs , and variances , obtaining more control over the total work of the method .",
    "in this section , we present two examples to illustrate the performance of our proposed method , and we compare the results with the single - level approach given in @xcite . for bench - marking purposes ,",
    "we use gillespie s stochastic simulation algorithm ( ssa ) instead of the modified next reaction method ( mnrm ) , because the former is widely used in the literature .",
    "the classical radioactive decay model provides a simple and important example for the application of our method .",
    "this model has only one species and one first - order reaction , @xmath552 its stoichiometric matrix , @xmath553 , and the propensity function , @xmath554 , are given by @xmath555 here , we choose @xmath556 , and define @xmath557 as the scalar observable . in this particularly simple example",
    ", we have that @xmath558 } = x_0 \\exp(-c(t{-}t))$ ] .",
    "consider the initial condition @xmath559 and the final time @xmath560 . in this case , the process starts relatively far from the boundary , _",
    "i.e. _ , it is a tau - leap dominated setting .",
    "we now analyze an ensemble of five independent runs of the calibration algorithm ( algorithm [ alg : cal ] ) , using different relative tolerances . in figure",
    "[ fig : dec2-worktime ] , we show , in the left panel , the total predicted work ( runtime ) for the single - level hybrid method , for the multilevel hybrid method and for the ssa method , versus the estimated error bound .",
    "the multilevel method is preferred over the ssa and the single - level hybrid method for all the tolerances .",
    "we also show the estimated asymptotic work of the multilevel method . in the right panel , we show , for different tolerances , the actual work ( runtime ) , using a 20 core intel glnxa64 architecture and matlab version r2014a .    in table",
    "[ tab : dec2 ] , we summarize an ensemble run of the calibration algorithm , where @xmath561 is the average actual computational work of the multilevel estimator ( the sum of all the seconds taken to compute the estimation ) and @xmath562 is the corresponding average actual work of the ssa .",
    "we compare those values with the corresponding estimations , @xmath563 and @xmath564 .",
    "confidence intervals .",
    "the multilevel hybrid method is preferred over the ssa and the single - level method for all the tolerances .",
    "right : actual computational work ( runtime ) versus the estimated error bound .",
    "notice that the computational complexity has order @xmath32 . ]     confidence intervals .",
    "the multilevel hybrid method is preferred over the ssa and the single - level method for all the tolerances .",
    "right : actual computational work ( runtime ) versus the estimated error bound .",
    "notice that the computational complexity has order @xmath32 . ]    in figure [ fig : dec2-diag ] , we can observe how the estimated weak error , @xmath565 , and the estimated variance of the difference of the functional between two consecutive levels , @xmath377 , decrease linearly as we refine the time mesh .",
    "this corresponds to the pure tau - leap case since the process , @xmath2 , remains far from the boundary in @xmath57 $ ] .",
    "as expected , the linear relationship for the variance starts at level @xmath566 .",
    "the estimated total path work , @xmath567 , increases as we refine the mesh .",
    "observe that it increases more slowly than linearly .",
    "this is because the work needed for generating poisson random variables becomes less as we refine the time mesh . in the lower right panel ,",
    "we show the total computational work , only in the cases in which @xmath568 .",
    ", as a function of the time mesh size , @xmath34 , for the simple decay model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]    , as a function of the time mesh size , @xmath34 , for the simple decay model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]    , as a function of the time mesh size , @xmath34 , for the simple decay model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]    , as a function of the time mesh size , @xmath34 , for the simple decay model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]    , it is well above @xmath571 for all the tolerances .",
    "right : @xmath572 as a function of @xmath176 , for the smallest tolerance , which decreases as the level increases .",
    "observe that the contribution of level 0 is less than 50% of the sum of the other levels . ]    , it is well above @xmath571 for all the tolerances .",
    "right : @xmath572 as a function of @xmath176 , for the smallest tolerance , which decreases as the level increases .",
    "observe that the contribution of level 0 is less than 50% of the sum of the other levels . ]    in figure [ fig : dec2-out ] , we show the main outputs of algorithm [ alg : cal ] , @xmath507 and @xmath431 for @xmath573 , for the smallest considered tolerance . in this case , @xmath472 is 12 .",
    "we observe that the number of realizations decreases slower than linearly , from levels @xmath566 to @xmath574 , until it reaches @xmath575 .    , and @xmath431 for @xmath576 , for the smallest tolerance , for the simple decay model . ]    , and @xmath431 for @xmath576 , for the smallest tolerance , for the simple decay model . ]",
    "l|lll|lll|lll @xmath0 & @xmath472 & min & max & @xmath577 & min & max & @xmath578 & min & max + 3.13e-03 & 5 & 5 & 5 & 0.03 & 0.02 & 0.04 & 0.03 & 0.02 & 0.05 + 1.56e-03 & 6 & 6 & 6 & 0.04 & 0.02 & 0.10 & 0.04 & 0.02 & 0.13 + 7.81e-04 & 8 & 8 & 8 & 0.03 & 0.02 & 0.05 & 0.03 & 0.02 & 0.06 + 3.91e-04 & 9.2 & 9 & 10 & 0.02 & 0.02 & 0.03 & 0.02 & 0.01 & 0.03 + 1.95e-04 & 11 & 11 & 11 & 0.02 & 0.02 & 0.03 & 0.02 & 0.02 & 0.04 + 9.77e-05 & 12 & 12 & 12 & 0.03 & 0.02 & 0.03 & 0.03 & 0.02 & 0.03 +    in the left panel of figure [ fig : effdec2 ] , we show the performance of formula , implemented in algorithm [ alg : varggl ] , used to estimate the strong error , @xmath289 , defined in section [ calibration ] .",
    "the quotient of @xmath377 over a standard monte carlo estimate of @xmath289 is almost 1 for the first ten levels . at levels 11 and 12 ,",
    "we obtain 0.99 and 0.91 , respectively .",
    "both quantities are estimated using a coefficient of variation less than 5% , but there is a remarkable difference in terms of computational work in favor of our dual - weighted estimator . in the right panel of the same figure , we show the estimated variance of @xmath289 , computed by dual - weighted estimation and computed by direct sampling . observe that , in this case , the computational savings may be up to order @xmath579 .    .",
    "right : estimated variance of @xmath289 with 95% confidence intervals . ]    .",
    "right : estimated variance of @xmath289 with 95% confidence intervals . ]    , in the simple decay model . also , we performed a shapiro - wilk normality test , and we obtained a p - value of @xmath580 . right : @xmath0 versus the actual computational error .",
    "the numbers above the straight line show the percentage of runs that had errors larger than the required tolerance .",
    "we observe that in all cases , except for the smallest tolerance , the computational error follows the imposed tolerance with the expected confidence of 95% . ]    , in the simple decay model .",
    "also , we performed a shapiro - wilk normality test , and we obtained a p - value of @xmath580 .",
    "right : @xmath0 versus the actual computational error .",
    "the numbers above the straight line show the percentage of runs that had errors larger than the required tolerance .",
    "we observe that in all cases , except for the smallest tolerance , the computational error follows the imposed tolerance with the expected confidence of 95% . ]    in the simulations , we observed that , as we refine @xmath0 , the optimal number of levels approximately increases logarithmically , which is a desirable feature .",
    "we fit the model @xmath581 , obtaining @xmath582 and @xmath583 .",
    "the qq - plot in figure [ fig : qqdec2 ] shows , for the smallest considered @xmath0 , @xmath584 independent realizations of the multilevel estimator , @xmath424 ( defined by ) .",
    "those @xmath584 points are generated using 5 sets of parameters given by an independent run of the calibration algorithm ( algorithm [ alg : cal ] ) .",
    "this plot , complemented with a shapiro - wilk normality test , validates our assumption about the gaussian distribution of the statistical error .",
    "observe that the estimates are concentrated around the theoretical value @xmath585 .",
    "in the same figure , we also show @xmath0 versus the actual computational error .",
    "it can be seen that the prescribed tolerance is achieved with the required confidence of 95% , in all the tolerances .",
    "this model has five reactions , @xmath586 described respectively by the stoichiometric matrix and the propensity function @xmath587 where @xmath588 , and @xmath589 , @xmath590 , @xmath591 , @xmath592 , and @xmath593 . in the simulations ,",
    "the initial condition is @xmath594 and the final time is @xmath595 .",
    "the observable is given by @xmath596 .",
    "we observe that the abundance of the mrna species , represented by @xmath597 , is close to zero for @xmath598 $ ] .",
    "however , as we point out in @xcite , the reduced abundance of one of the species is not enough to ensure that the ssa method should be used .",
    "we now analyze an ensemble of five independent runs of the calibration algorithm ( algorithm [ alg : cal ] ) , using different relative tolerances . in figure",
    "[ fig : gtt - worktimes ] , we show , in the left panel , the total predicted work ( runtime ) for the single - level hybrid method , for the multilevel hybrid method and for the ssa method , versus the estimated error bound .",
    "we also show the estimated asymptotic work of the multilevel method .",
    "again , the multilevel hybrid method outperforms the others and we remark that the observed computational work of the multilevel method is of order @xmath32 .            in figure",
    "[ fig : gtt - diag ] , we can observe how the estimated weak error decreases linearly for the coarser time meshes , but , as we continue refining the time mesh , it quickly decreases towards zero . in the case of the estimated variance , @xmath377",
    ", it decreases faster than linearly , and it also quickly decreases towards zero afterwards .",
    "this is a consequence of the transition from a hybrid regime to a pure exact one .",
    "the estimated total path work , @xmath567 , increases sublinearly as we refine the mesh .",
    "note that @xmath567 reaches a maximum , which corresponds to a ssa - dominant regime .",
    "in the lower right panel , we show the total computational work only in the cases in which @xmath568 .",
    ", as a function of the time mesh size , @xmath34 , for the gene transcription and translation model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]    , as a function of the time mesh size , @xmath34 , for the gene transcription and translation model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]    , as a function of the time mesh size , @xmath34 , for the gene transcription and translation model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]    , as a function of the time mesh size , @xmath34 , for the gene transcription and translation model .",
    "upper right : estimated variance of the difference between two consecutive levels , @xmath377 , as a function of @xmath34 .",
    "lower left : estimated path work , @xmath569 , as a function of @xmath34 .",
    "lower right : estimated total computational work , @xmath570 , as a function of the level , @xmath412 . ]",
    ", it is well above @xmath571 for all the tolerances .",
    "right : @xmath572 as a function of @xmath176 , for the smallest tolerance , which decreases as the level increases .",
    "observe that the contribution of level 0 is almost equal to the sum of the other levels . ]    , it is well above @xmath571 for all the tolerances .",
    "right : @xmath572 as a function of @xmath176 , for the smallest tolerance , which decreases as the level increases .",
    "observe that the contribution of level 0 is almost equal to the sum of the other levels . ]    in figure [ fig : gtt - out ] , we show the main outputs of algorithm [ alg : cal ] , @xmath507 and @xmath431 for @xmath573 , for the smallest tolerance .",
    "we observe that the number of realizations decreases slower than linearly from levels @xmath566 to @xmath599 .    , and @xmath431 for @xmath576 , for the smallest tolerance in the gene transcription and translation model . ]    , and @xmath431 for @xmath576 , for the smallest tolerance in the gene transcription and translation model . ]",
    "l|lll|lll|lll @xmath0 & @xmath472 & min & max & @xmath577 & min & max & @xmath578 & min & max + 1.00e-01 & 3 & 3 & 3 & 0.04 & 0.04 & 0.04 & 0.06 & 0.05 & 0.07 + 5.00e-02 & 4.6 & 4 & 5 & 0.04 & 0.03 & 0.04 & 0.05 & 0.05 & 0.05 + 2.50e-02 & 6 & 6 & 6 & 0.03 & 0.03 & 0.04 & 0.05 & 0.04 & 0.05 + 1.25e-02 & 8 & 8 & 8 & 0.03 & 0.03 & 0.03 & 0.05 & 0.05 & 0.06 + 6.25e-03 & 10 & 10 & 10 & 0.03 & 0.03 & 0.03 & 0.05 & 0.04 & 0.05 + 3.13e-03 & 11.4 & 11 & 13 & 0.03 & 0.03 & 0.03 & 0.05 & 0.04 & 0.05 +    in figure [ fig : effgtt ] , we see that our dual - weighted estimator of the strong error , @xmath289 , gives essentially the same results as the standard monte carlo estimator , but with much less computational work . in this case ,",
    "an accurately empirical estimate of @xmath600 took almost 48 hours , but the dual - based computation of @xmath601 just took few minutes .    .",
    "right : estimated variance of @xmath289 with 95% confidence intervals . ]    .",
    "right : estimated variance of @xmath289 with 95% confidence intervals . ]",
    "estimates for the gene transcription and translation model .",
    "also , we performed a shapiro - wilk normality test and we obtained a p - value of @xmath602 .",
    "right : @xmath0 versus the actual global computational error .",
    "the numbers above the straight line show the percentage of runs that had errors larger than the required tolerance .",
    "we observe that in all cases ( except the second for a very small margin ) the computational error follows the imposed tolerance with the expected confidence of 95% . ]",
    "estimates for the gene transcription and translation model .",
    "also , we performed a shapiro - wilk normality test and we obtained a p - value of @xmath602 .",
    "right : @xmath0 versus the actual global computational error .",
    "the numbers above the straight line show the percentage of runs that had errors larger than the required tolerance .",
    "we observe that in all cases ( except the second for a very small margin ) the computational error follows the imposed tolerance with the expected confidence of 95% . ]    in the simulations , we observed that , as we refine @xmath0 , the optimal number of levels approximately increases logarithmically , which is a desirable feature .",
    "we fit the model @xmath581 , obtaining @xmath603 and @xmath604 .",
    "the qq - plot in the figure [ fig : qqgtt ] , computed in the same way as in the previous example , together with a shapiro - wilk normality test , shows the validity of the gaussian assumption for the statistical errors . in the same figure",
    ", we also show @xmath0 versus the actual global computational error .",
    "it can be seen that the prescribed tolerance is achieved , except for the second smallest tolerance , with the required confidence of 95% , since @xmath605 .",
    "we now analyze an ensemble of @xmath584 independent runs of the multilevel estimator , @xmath424 , for @xmath606 . in this case ,",
    "@xmath607 . in figures [ fig : box1 ] , [ fig : box2 ] and [ fig : box3 ] , we show boxplots corresponding to that ensemble . in each one , we indicate the coupling pair ( on the x - axis ) and the value of @xmath522 ( below the title of the plot ) . in each figure",
    ", the first boxplot starting from the left , corresponds to single - level hybrid simulations at the coarsest level , @xmath161 , with a time mesh of size @xmath160 , and with an exit bound for the one - step exit probability , @xmath608 .",
    "next , we show the boxplots corresponding to coupled hybrid paths , at levels @xmath161 and @xmath609 , generated using time meshes of size @xmath160 and @xmath610 , respectively , and exit probability bounds , @xmath440 and @xmath611 , respectively .",
    "this is indicated under the boxplots with the symbols 1c and 1f , which stand for ` coarse ' and ` fine ' levels in the first coupling , respectively .",
    "we proceed in the same fashion until the final level , @xmath472 . at this point , it is crucial to observe that the probability law for the samples in the boxplots indicated by @xmath612 and @xmath613 should be the same for any @xmath614 ( in the single - level case , we interpret the symbol 0 as 0f ) .",
    "this is because both samples are generated using the same time mesh of size @xmath615 and the same one - step exit probability bound , @xmath616 , see remark [ rem : telescoping ] .",
    "figure [ fig : box1 ] shows the total proportion of chernoff tau - leap steps over the total number of tau - leap steps . here",
    ", we understand that a chernoff tau - leap step is taken when the size of @xmath154 ( see section [ hybrid_algo ] ) is strictly smaller than the distance from the current time to the next mesh point and , therefore , the chernoff bound is acting as an actual constraint for the size of the tau - leap step .",
    "we can see how the chernoff steps are present in the first levels but not in the final ones , where exact steps are preferred according to our computational work criterion .",
    "we observe a small increase of the proportion of the number of chernoff steps from levels 1f/2c to levels 3f/4c ( strictly speaking , a shift in the median and the third quartile ) .",
    "this is due to consecutive refinements in the values of @xmath14 , from @xmath617 to @xmath618 , producing smaller and smaller values of @xmath154 .",
    "this is also because the chernoff step size is , for some time points , still smaller than the grid size and also because the cost of reaching the time horizon using chernoff steps is still preferred over the cost of using exact steps .",
    "the abundance of outliers at all levels up to @xmath619 indicates that the chernoff bound is actively controlling the size of the tau - leap steps .",
    "figures [ fig : box2 ] and [ fig : box3 ] show the total count of tau - leap and exact steps , respectively .",
    "these plots are intended as diagnostic plots with two main objectives : i ) checking the telescoping sum property as stated in remark [ rem : telescoping ] , and ii ) understanding the ` blending ' phenomena in our simulated hybrid paths , that is , the presence of both methods , tau - leap and exact .",
    "it could be useful to think in terms of the domain of each method : given a time mesh , @xmath34 , and a value of the one - step exit probability bound , @xmath14 , we could decompose the interval @xmath57 $ ] into two domains , @xmath620 and @xmath621 , for the tau - leap and exact methods , respectively .",
    "the domain , @xmath621 , should be monotonically increasing with refinements of the time mesh and @xmath14 , since when the size of the time mesh , @xmath622 or @xmath507 , goes to zero , the expected number of tau - leap steps also goes to zero , see @xcite , appendix a. as a consequence , we expect the total count of exact paths to be a monotonically increasing function of the level , @xmath176 .",
    "on the other hand , the domain @xmath620 decreases , but , since the size of the time mesh halves form by passing from one level to the next one , we expect to see also an increasing number of tau - leap steps , at least for no very deep levels .",
    "the blending effect of the hybrid decision rules in algorithm [ alg : coupled ] are depicted in figure [ fig : blending ] , where the proportion of the tau - leap steps over the total number of steps is shown for levels @xmath623 . in the left panel",
    ", we can see that the number of tau - leap steps dominates except close to the origin , where the coarse time - mesh is finer .",
    "remember that in our methodology , our initial mesh can be nonuniform .",
    "we then see how the domain , @xmath621 , increases until it occupies almost 80% of the time interval @xmath57 $ ] .     of each level .",
    "we observe a small increase in the proportion of the number of chernoff steps from levels 1f/2c to levels 3f/4c ( strictly speaking , a shift in the median and the third quartile ) .",
    "this is due to consecutive refinements in the values of @xmath14 , from @xmath617 to @xmath618 , producing smaller and smaller values of @xmath154 . ]     of each level .",
    "the domain @xmath620 of the tau - leap method decreases with refinements , but , since the size of time mesh halves form by passing from one level to the next one , we see an increasing number of tau - leap steps until , at a certain level , there are no more tau - leap steps due to the relative computational cost of the tau - leap method . ]     of each level .",
    "the domain @xmath621 of the exact method is monotonically increasing with refinements of the time mesh and the one - step exit probability bound . as a consequence",
    ", we expect the total count of exact paths to be a monotonically increasing function of the level , @xmath176 . ]                the savings in computational work when generating poisson random variables heavily depend on matlab s performance capabilities .",
    "for example , we do not generate the random variates in batches , as in @xcite , and that could have an impact on the results .",
    "in fact , we should expect better results from our method if we implement our algorithms in more performance - oriented languages or if we sample poisson random variables in batches .",
    "( level 0 time mesh ) in this example , we use an adaptive mesh at level 0 .",
    "this is because this example is mildly stiff .",
    "using a uniform time mesh at level 0 imposes a small time step size requirement for all time which is not needed . moreover ,",
    "this issue is propagated to the finer levels . in all our numerical examples , at level 0 , we use the coarsest possible time mesh such that the forward euler method is numerically stable .",
    "in this work , we developed a multilevel monte carlo version for the single - level hybrid chernoff tau - leap algorithm presented in @xcite .",
    "we showed that the computational complexity of this method is of order @xmath32 and , therefore , that it can be seen as a variance reduction of the ssa method , which has the same complexity .",
    "this represents an important advantage of the hybrid tau - leap with respect to the pure tau - leap in the multilevel context . in our numerical examples , we obtained substantial gains with respect to both the ssa and the single - level hybrid chernoff tau - leap .",
    "the present approach , like the one in @xcite , also provides an approximation of @xmath6}$ ] with prescribed accuracy and confidence level , with nearly optimal computational work . for reaching this optimality , we derived novel formulas based on dual - weighted residual estimations for computing the variance of the difference of the observables between two consecutive levels in coupled hybrid paths and also the bias of the deepest level ( see and ) .",
    "these formulas are particularly relevant in the present context of stochastic reaction networks due to the fact that alternative standard sample estimators become too costly at deep levels because of the presence of large kurtosis .",
    "future extensions may involve better hybridization techniques as well as implicit and higher - order versions of the hybrid mlmc .",
    "the authors would like to thank two anonymous reviewers for their constructive comments that helped us to improve our manuscript .",
    "we also would like to thank prof .",
    "mike giles for very enlightening discussions .",
    "the authors are members of the kaust sri center for uncertainty quantification in the computer , electrical and mathematical sciences and engineering division at king abdullah university of science and technology ( kaust ) .",
    "this work was supported by kaust .",
    "@xmath624 , @xmath625 , @xmath626 @xmath627 next grid point in the coarse grid larger than @xmath9 @xmath628 algorithm [ alg : timehor ] with ( @xmath111,@xmath9,@xmath231,@xmath5,@xmath230,@xmath226 ) @xmath629 next grid point in the fine grid larger than @xmath9 @xmath630 algorithm [ alg : timehor ] with ( @xmath193,@xmath9,@xmath631,@xmath5,@xmath632,@xmath226 ) @xmath633 @xmath634 algorithm [ alg : auxilco2 ] with ( @xmath635 ) @xmath636 ( generate poisson random variates ) @xmath637 @xmath638 @xmath639 initialize internal clocks @xmath640 if needed ( see algorithm [ alg : mnr ] ) @xmath641 @xmath642    @xmath634 algorithm [ alg : auxilco2 ] with ( @xmath643 ) @xmath644 algorithm [ alg : auxilco ] with @xmath645 @xmath627 next grid point in the coarse grid larger than @xmath9 @xmath646 algorithm [ alg : timehor ] with ( @xmath111,@xmath9,@xmath231,@xmath5,@xmath230,@xmath226 ) @xmath629 next grid point in the fine grid larger than @xmath9 @xmath630 algorithm [ alg : timehor ] with ( @xmath193,@xmath9,@xmath631,@xmath5,@xmath632,@xmath226 )            @xmath668 , @xmath669 , @xmath670 set initial meshes @xmath671 and @xmath672 fin - delta @xmath673 @xmath674 algorithm [ alg : pathdualscostsl ] fin - delta @xmath673 refine @xmath675 by a factor of @xmath297 @xmath676 fin @xmath673 fin - delta @xmath673 @xmath677 algorithm [ alg : pathdualscost ]    fin - delta @xmath673 @xmath678 refine @xmath679 by a factor of @xmath297 @xmath680 @xmath681 @xmath682 algorithm [ alg : greedyoptkkt ] with @xmath683 @xmath684 @xmath685 @xmath686 @xmath687 refine meshes @xmath671 and @xmath672 fin @xmath688 @xmath689 @xmath690 algorithm [ alg : pathdualscost ] fin @xmath688 refine @xmath679 by a factor of @xmath297 @xmath686 @xmath691 algorithm [ alg : greedyoptkkt ] with @xmath692 @xmath693    @xmath694 , @xmath695 , @xmath696 generate two coupled paths : @xmath697 algorithm [ alg : coupled ] @xmath698 @xmath699 algorithm [ alg : varggl ] with @xmath700 @xmath701 algorithm [ alg : weakerror ] with @xmath702 estimate @xmath703 , using @xmath704 ( see @xcite ) @xmath705 @xmath706 compute @xmath707 , @xmath708 , @xmath709 , and @xmath710 @xmath711 compute the coefficient of variation @xmath712 and @xmath713 of @xmath714 and @xmath715 , respectively .",
    "@xmath694 , @xmath695 , @xmath696 @xmath748 generate one hybrid path ( see @xcite ) @xmath749 compute @xmath750 @xmath751 algorithm [ alg : weakerror ] with @xmath752 @xmath699 algorithm [ alg : varggl ] with @xmath753 estimate @xmath703 , using @xmath704 ( see @xcite ) @xmath754 @xmath711 estimate the coefficients of variation @xmath712 , @xmath755 and @xmath713 of the estimators of @xmath756}$ ] , @xmath757}$ ] and @xmath758}$ ] , respectively .",
    "@xmath759 @xmath760                c.  bierig and a.  chernov . convergence analysis of multilevel variance estimators in multilevel monte carlo methods and application for random obstacle problems .",
    "preprint 1309 , institute for numerical simulation , university of bonn , 2013 . submitted ."
  ],
  "abstract_text": [
    "<S> in this work , we extend the hybrid chernoff tau - leap method to the multilevel monte carlo ( mlmc ) setting . inspired by the work of anderson and higham on the tau - leap mlmc method with uniform time steps , we develop a novel algorithm that is able to couple two hybrid chernoff tau - leap paths at different levels . using dual - weighted residual expansion techniques , we also develop a new way to estimate the variance of the difference of two consecutive levels and the bias . </S>",
    "<S> this is crucial because the computational work required to stabilize the coefficient of variation of the sample estimators of both quantities is often unaffordable for the deepest levels of the mlmc hierarchy . </S>",
    "<S> our method bounds the global computational error to be below a prescribed tolerance , @xmath0 , within a given confidence level . </S>",
    "<S> this is achieved with nearly optimal computational work . </S>",
    "<S> indeed , the computational complexity of our method is of order @xmath1 , the same as with an exact method , but with a smaller constant . </S>",
    "<S> our numerical examples show substantial gains with respect to the previous single - level approach and the stochastic simulation algorithm .    </S>",
    "<S> stochastic reaction networks , continuous time markov chains , multilevel monte carlo , hybrid simulation methods , chernoff tau - leap , dual - weighted estimation , strong error estimation , global error control , computational complexity    60j75 , 60j27 , 65g20 , 92c40 </S>"
  ]
}