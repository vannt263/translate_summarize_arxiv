{
  "article_text": [
    "convolutional neural networks ( cnns ) have been widely applied in the general problem of object localization and detection .",
    "the task is to detect a target object s location and its spatial coverage in an image in the form of bounding boxes @xcite . to localize objects from images ,",
    "typically a model is given images of category exemplars for training .",
    "critically , these training samples have precise object - level annotations , such as segmentations or bounding boxes . the models can be fine - tuned from a pre - trained network and utilize region proposals for candidate object locations @xcite , or trained end - to - end @xcite .",
    "these models have demonstrated high performance in localizing objects from learned categories , and further fine - tuning is required in order to accommodate novel object categories @xcite .",
    "co - localization is the more challenging problem of localizing objects from only the set of positive image examples of the category without any object - level annotations .",
    "the lack of negative examples and detailed annotations hinders the use of supervised methods for the co - localization task .",
    "recent methods typically utilize existing region proposal methods for generating a number of candidate regions for objects and object parts , followed by matching or selecting the region with the highest confidence score @xcite .",
    "however , region and object proposals are part of a research problem of its own , and have drawbacks such as lack of repeatability , reduced detection performance with a large number of proposals , and lead to difficult balance in precision and recall@xcite .    our method",
    ", however , does not require any object proposals or object detectors to perform co - localization .",
    "the main idea in our work is that objects of the same class share common features or parts .",
    "moreover , these commonalities are central to both , the category representation and the detection and localization of the object . by finding those object categorical features",
    ", their joint locations can act as a single - shot object detector .",
    "this idea is also grounded in human visual learning , where it is suggested that people detect common features from examples of the category , as part of the object - learning process @xcite .",
    "we do this by obtaining the cnn features of the provided set of positive images , in order to select the ones that are highly and consistently activated , which we denote as category - consistent cnn features ( ccfs ) we then use these ccfs to discover the rough object locations , and demonstrate an effective way to co - propagate the feature activations into a stable object for precise co - localization .",
    "figure [ fig : pipeline ] illustrates the pipeline of our proposed framework .    in more detail ,",
    "our approach begins with a cnn that has been pre - trained for image classification on imagenet .",
    "then , the images of the target category are passed through the network .",
    "we identify the last - layer convolutional filters that have highly and consistently activated feature maps as the ccfs .",
    "the ccfs feature maps are combined into a single normalized activation probability map , where the highly activated region directly implies the rough object location , since the ccfs represent object parts or object - associated features .",
    "the ccf step allows us to bypass the need for region proposals .",
    "then , the activation map is partitioned into superpixels and weighted by the superpixel geodesic distance into an object - likelihood map such that the responses of the object - associated features propagate over the region of the entire object .",
    "finally , the precise object location can be obtained by placing a tight bounding box around the thresholded object - likelihood map .",
    "the three main contributions of this work are : * 1 . *",
    "we propose a novel ccf extraction method that can automatically highlight the rough initial object regions , which acts as a single - shot detector .",
    "* we introduce an effective method of feature co - propagation for generating a stable object region using superpixel geodesic distances on the original images .",
    "* our method achieves state - of - the - art performance for object co - localization on the voc 2007 and 2012 datasets @xcite , the object discovery dataset @xcite , and the six held - out imagenet subset categories .",
    "furthermore , our framework is fully unsupervised , objects are discovered using just positive image exemplars .",
    "we are able to accurately localize objects without needing any region proposals .",
    "co - localization is related to work on weakly supervised object localization ( wsol ) @xcite since both share the same objective : to localize objects from an image .",
    "however , since wsol allows the use of negative examples , designing the objective function to discover the information of the object - of - interest is less challenging : wsol - based methods achieve higher performance on the same datasets as compared to co - localization methods , due to the allowed supervised training .",
    "for instance , @xcite uses image labels to evaluate the discrimination of discovered categories in order to localize the objects .",
    "@xcite adopts a discriminative multiple instance learning scheme to compensate the lack of object - level annotations to localize the objects based on the most discriminative instances . because of the supervision that is required by those methods , it is not trivial for wsol approaches to be directly applied to the co - localization scenarios .",
    "one challenge of co - localization is to define the criteria for discovering the objects without any negative examples . to fill the gap , state - of - the - art co - localization methods such as @xcite employ object proposals as part of their object discovery and co - localization pipelines .",
    "@xcite use the measure of objectness  @xcite to generate multiple bounding boxes for each image , followed by an objective function to simultaneously optimize the image - level labels and box - level labels .",
    "such settings allow the use of discriminative cost function  @xcite .",
    "this is also used in the work of co - localization on video frames  @xcite .",
    "@xcite also starts from object proposals , their method shares the same spirit with the deformable part model  @xcite where the objects are discovered and localized by matching common object parts .",
    "most recently , @xcite study the confidence score distribution of a supervised object detector over the set of object proposals to define an objective function , that learns a common object detector with similar confidence score distribution .",
    "all the aforementioned methods heavily depend on the quality of object proposals .",
    "our work approaches the problem from a different perspective . instead of trying to fill in the gap of the negative data and annotations that are unavailable , we find the common features shared by the objects from the positive images .",
    "then , we use the joint locations of those features as our single - shot object detector .",
    "this allows us to bypass the need for utilizing a region or object proposal algorithm as a fist step .",
    "our subsequent step refines the detected object features into a stable object by co - propagating their activations together .",
    "we describe the details of our 2-step approach in the following sections .",
    "our proposed method consists of two main steps . the first step is to find the ccfs of a category , and obtain their combined feature map that contains aggregated ccf activations over the rough object region .",
    "then , the ccf activations are co - propagated into a stable object using superpixel geodesic distances on the original images .",
    "[ sec_ccf_selection ] given a set of @xmath0 object images from the same class and a cnn that has been pre - trained to contain sufficient visual features , we first compute the @xmath1 feature maps from the @xmath2 last - layer convolutional kernels over the @xmath0 images . then , we obtain an @xmath3 activation matrix with each row being the activation vector @xmath4 of a kernel containing the maximum values of the kernel s feature maps .    specifically , for each kernel : @xmath5 , where @xmath6 is the feature map of kernel @xmath7 , given image @xmath8 that has been forward - passed through the cnn .",
    "the activation matrix @xmath9 therefore describes the max - response distributions of all kernels to all category images .",
    "our goal in this step is to identify a subset of representative kernels from the global set of candidate kernels , that contain common features from the positive images of the same class .",
    "this implies that the activation vectors of the kernels should have high values over all vector elements , since there is at least one instance of the object on every image .",
    "conceptually , the kernels that we seek correspond to object parts , or some object - associated features . to find the ccfs , we compute the pair - wise similarities between all pairs of kernels activation vectors , and cluster them using k - means . the kernels from the cluster with the highest mean activation correspond to the ccfs .",
    "the similarity @xmath10 between two cnn kernels @xmath7 and @xmath8 , can be defined as the @xmath11 distance between two activation vectors @xmath12 and @xmath13 .",
    "the sets of positive images are only required for the identification of the ccf kernels .",
    "the ccf kernels can then be used to generate the rough object location in an image in a single - shot : given an image from the target category , the feature maps of the ccfs are combined to form a single activation map .",
    "since each ccf corresponds to an object part of object - associate features , the densely activated area of the activation map indicates the rough location of the target object .",
    "the final activation map is normalized into a probability map that sums to 1 . in figure",
    "[ fig : feature ] we show the identified ccfs for the bus category , where the activated regions describe bus - related features and all fall within the spatial extent of the objects .",
    "the activation probability map from the ccfs automatically points out only the rough location of the object .",
    "it does not ensure a reliable object localization due to : * * 1.**the higher layer of a cnn does not guarantee a kernel s receptive - field size to cover the area of an entire object . * * 2.**while the feature maps contain spatial information , they have unprecise object locations due to previous max - pooling layers . * * 3.**the cnn was trained discriminatively .",
    "hence , only discriminative features of each object may be localized rather than the the whole object .    in order to obtain the complete region that corresponds to the object , we compute geodesic distances between superpixels on the original image .",
    "in essence , the geodesic distance compactly encodes the similarity relationship between the two superpixels image contents .",
    "the similarity is computed via object boundary detection algorithm @xcite .",
    "therefore , the smaller geodesic distance between the two superpixels , the more likely that they belong to the same object . based on this characteristic",
    ", we propose a simple and effective method to highlight the object region from the activation probability map , that is both low - resolution and contains non - smooth feature activations .        given an input image , we oversegment it into superpixels .",
    "the geodesic distance @xmath14 between a pair of superpixels @xmath15 is computed based on the graph built from the boundary probability map , which is done similarly as the method proposed by @xcite .",
    "we take the combined activation map that was obtained in the ccf identification step , and assign an energy value to each superpixel by averaging its corresponding pixel values found in the activation map . for @xmath2 superpixels , we denote the resulting flattened @xmath16 superpixel activation vector as @xmath17 .",
    "vector @xmath17 can be considered as the initial likelihood of each superpixel being within the object .",
    "next , we perform the geodesic distance propagation to localize the object .",
    "the main idea is that if two superpixels are likely to belong to the same object , then they should have similar geodesic distances and activations .",
    "this concept has been similarly adopted by various works in terms of interactive image segmentation and matting @xcite , and we find it to suit specially well for our purpose .",
    "therefore , we seek to obtain a global activation map that has regions of highly boosted or co - propagated activations by superpixels of similar geodesic distances , mediated by some level of consistency by formulating this co - propagating mechanism into a @xmath18 co - propagation matrix @xmath19 , such that @xmath20 is the normalized amount of co - propagation between superpixel @xmath7 and @xmath8 , with a parameter @xmath21 for controlling the amount of activation diffusion :    @xmath22    finally , we apply @xmath23 to the activation vector @xmath24 directly :    @xmath25    where @xmath26 is the co - propagated activation vector of the image , containing the globally boosted activations of the superpixels based on their pair - wise geodesic distances to all other superpixels .",
    "this allows us to fill in each superpixel on the image with their respective values from @xmath26 , and normalize the co - propagated superpixel map by dividing every pixel by the max value of the map .",
    "the result is an object - likelihood map , on which we apply a global threshold to obtain the region as our final object co - localization result .",
    "finally , a tight bounding box is placed around the maximum coverage of the thresholded regions within an image .",
    "figure [ fig : disprop ] illustrates the effects of activation propagation for two selected superpixels .",
    "the top row corresponds to the case of a background superpixel .",
    "this superpixel has small geodesic distances to a large set of other superpixels .",
    "hence , the activation values propagated from this superpixel to others are relatively small . in the second row , we consider a superpixel corresponding to the bird . in this case ,",
    "high activation values are only propagated from this superpixel to other superpixels that also correspond to the bird .",
    "hence , we filter out the undesirable high activation of the background regions surrounding the object , while also balancing the activation of all superpixels that reside within the same object .",
    "the first column of figure [ fig : disprop ] shows the original image and its boundary map .",
    "the second column marks the position and initial activation of the two selected superpixels .",
    "the next columns illustrate the activation propagating from the selected superpixel to all other superpixels with a varying degree of controlling parameter @xmath21 set at @xmath27,@xmath28 and @xmath29 , where warmer values indicate higher activations .",
    "it can be seen from the third column that since the background superpixel has small geodesic distances to many other superpixels , the activations being propagated from this superpixel to others are equally small ; in contrast , the activations propagated from the bottom superpixel mostly fall into its close neighboring superpixels and ones that belong to the object s region . as @xmath21 increases , the amount of propagation is more evenly and widely spread , but with a lower overall magnitude .",
    "we evaluate our proposed 2-step framework with different parameter settings to illustrate different characteristics of our method .",
    "we also evaluate our method on multiple benchmarks , with intermediate and final results to show the localization effects of our proposed method . in all of our experiments",
    ", we used the last convolutional layer of a vgg-19 network @xcite that was pre - trained on imagenet @xcite as our ccf kernel pool .",
    "we used @xmath30 for kmeans clustering in the ccf identification step .",
    "the geodesic distances are computed using the structured forests soft boundary  @xcite .",
    "the control parameter @xmath21 for activation co - propagation was set at @xmath27 .",
    "the final global threshold for obtaining the object region from the object - likelihood map was set at @xmath31 for all images .",
    "we use the conventional corloc metric @xcite to evaluate our co - localization results .",
    "the metric measures the percentage of images that contain correctly localized results . an image is considered correctly localized if there is at least one ground truth bounding box of the object - of - interest having more than 50% intersection - over - union ( iou ) score with the predicted bounding box . to benchmark our method performance ,",
    "we evaluate our method on three commonly used datasets for the problem of co - localization .",
    "these are voc 2007 and 2012 @xcite , and object discovery dataset @xcite . for experiments on voc datasets",
    ", we followed previous works @xcite that used all images on the _ trainval _ set excluding the images that only contain the object instances annotated as _",
    "difficult _ or _",
    "truncated_. for experiments on the object discovery dataset , we used the 100-image subset following @xcite in order to make an appropriate comparison with related methods .",
    "the ground truth bounding box for each image in the object discovery dataset is defined as the smallest bounding box covering all the segmentation ground truth of the object .",
    "max width=1.0    [ cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     table [ selectedset ] reports the co - localization performance of our method on the 6 smaller subsets in comparison with the two state - of - the - art methods .",
    "the table shows that our method outperformed @xcite and @xcite by a large margin on average , and all but one individual classes .",
    "the six subsets of the imagenet dataset , chosen by @xcite @xcite , are held - out categories from the 1000-label classification task , which means they do not overlap with the 1000 classes used to train vgg-19 .",
    "we show that our method is generalizable to truly novel object categories with the six held - out imagenet subset classes .",
    "the images and the corresponding bounding box annotations were downloaded from imagenet website @xcite , and table [ nim ] shows the numbers of images in each class with available bounding box annotations when we accessed the imagenet dataset website .",
    "it is noticeable that paper @xcite used an even smaller set with less images ( table [ nim ] ) . to compare with the methods of @xcite and @xcite",
    ", we first conduct our experiment on the same smaller sets of images that was used in @xcite .",
    "then , we test our method on the full set of imagenet held - out categories that we downloaded from the imagenet dataset .",
    "table [ selectedset ] reports the co - localization of our method compares to @xcite on the smaller imagenet subset , and table [ fullset ] reports the performance of our method on the imagenet full subsets .",
    "the results show that our method significantly outperforms the competing methods in the smaller subset , with even higher accuracies for the full subset in table [ fullset ] .",
    "this result demonstrates that our method is robust to detect and localize truly unseen categories using previously learned cnn features .",
    "we show some examples of our co - localization results in figure [ fig : short ] and [ fig:1 ] .",
    "the results show that the bounding boxes generated by our proposed framework accurately match the ground truth bounding boxes .",
    "it is apparent that our results generate well - covered object regions , that has the potential to well delineate the objects in majority of the cases .",
    "the figures also show that the objects were able to be accurately co - localized with various sizes and locations .",
    "figure [ fig : fail ] illustrates three failure scenarios of our approach . while these three examples did not cover the ground truth bounding box sufficiently , but they were not far off .",
    "some analysis suggests that these failures were due to some ccfs that are shared by multiple categories , and that the object boundaries may not have been strong enough ( i.e. bottle and boat ) .",
    "in this work , we proposed a fully unsupervised 2-step approach for the problem of co - localization , that uses only positive images , and without any region or object proposals .",
    "our method is motivated by human vision , people implicitly detect the common features of category examples to learn the representation of the class .",
    "we show that the identified category - consistent features can also act as an effective first - pass object detector .",
    "this idea is implemented by finding the group of cnn features that are highly and consistently activated by a given positive set of images .",
    "the result of this first step generates a rough but reliable object location , and acts as a single - shot object detector .",
    "then , we aggregate the activations of the identified ccfs , and co - propagate their activations so that the activations over the true object region are boosted , while the activations over the background region are smoothed out .",
    "this effective activation refinement step allowed us to obtain accurately co - localized objects in terms of the standard corloc score with bounding boxes .",
    "we achieved new state - of - the - art performance on the three commonly used benchmarks . in the future",
    ", we plan to extend our method to generate unsupervised object co - segmentations ."
  ],
  "abstract_text": [
    "<S> co - localization is the problem of localizing categorical objects using only positive sets of example images , without any form of further supervision . </S>",
    "<S> this is a challenging task as there is no pixel - level annotations . </S>",
    "<S> motivated by human visual learning , we find the common features of an object category from convolutional kernels of a pre - trained convolutional neural network ( cnn ) . </S>",
    "<S> we call these category - consistent cnn features </S>",
    "<S> . then , we co - propagate their activated spatial regions using superpixel geodesic distances for localization . in our first set of experiments , we show that the proposed method achieves state - of - the - art performance on three related benchmarks : pascal 2007 , pascal-2012 , and the object discovery dataset . </S>",
    "<S> we also show that our method is able to detect and localize truly unseen categories , using six held - out imagnet subset of categories with state - of - the - art accuracies . </S>",
    "<S> our intuitive approach achieves this success without any region proposals or object detectors , and can be based on a cnn that was pre - trained purely on image classification tasks without further fine - tuning . </S>"
  ]
}