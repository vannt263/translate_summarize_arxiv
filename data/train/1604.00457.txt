{
  "article_text": [
    "connected neural networks have been extensively studied , and many applications in different areas have been arising .",
    "such applications heavily depend on the stable dynamical behavior of the networks .",
    "for example , in application for optimisation , convergence of dynamics is fundamental , which has attracting many interests from different fields .",
    "see @xcite-@xcite and the references therein .",
    "therefore , analysis of these behaviors is a necessary step for practical design of neural networks .",
    "this paper focuses on the following dynamical system @xmath0",
    "y = g(\\lambda x),\\\\[2pt ] \\end{cases}\\end{aligned}\\ ] ] where @xmath1 is the state vector , @xmath2 with @xmath3 for all @xmath4 is the self - inhibition matrix , the cost function @xmath5 is an _",
    "analytic _ function and @xmath6 is a constant input vector .",
    "@xmath7 is the output vector with the sigmoid function @xmath8 as nonlinear activation function and the scaling slopes @xmath9 for some @xmath10 for all @xmath4 .",
    "eq . was firstly proposed in @xcite and is a general model of neural network system arising in recent years .",
    "for example , the well - known hopfield neural network @xcite , whose continuous - time version can be formulated as @xmath11 y_{i}=g_{i}(\\lambda_{i}x_{i}),\\\\[2pt ] \\end{cases}\\label{mg0.2}\\end{aligned}\\ ] ] for @xmath4 , where @xmath12 stands for the state of neuron @xmath13 and each activation function @xmath14 is sigmoid . with the symmetric weight condition ( @xmath15 for all @xmath16 ) , eq .",
    "( [ mg0.2 ] ) can be formulated as eq .",
    "( [ mg0.1 ] ) with @xmath17 .",
    "this model has a great variety of applications .",
    "it can be used to search for local minima of the quadratic objective function of @xmath18 over the discrete set @xmath19 @xcite-@xcite , for example , the traveling - sales problem @xcite .",
    "this model can be regarded as a special form of ( [ mg0.1 ] ) with @xmath20 and proved to minimize @xmath21 over the discrete set @xmath19 @xcite .    the linearization technique and the classical lasalle approach for proving stability ( see @xcite ) could be invalid when the system had non - isolated equilibrium points ( e.g. , a manifold of equilibria ) @xcite .",
    "the concept `` absolute stability '' was proposed in @xcite-@xcite to show that each trajectory of the neural network converges to certain equilibrium for any parameters and initial values by proving the finiteness of the trajectory length and the celebrated ojasiewicz inequality @xcite-@xcite .",
    "this idea was also seen in @xcite .",
    "however , in the model ( [ mg0.1 ] ) , the synaptic feedback of each neuron is simultaneous according to the output states of the other neurons , which is costly in practice for a network of a large number of neurons . in recent years , with the development of sensing , communications , and computing equipment , event - triggered control @xcite-@xcite and self - triggered control @xcite-@xcite have been proposed and have remarkable advantages that reduce the frequency of synaptic information exchange significantly . in this paper , we investigate stability of analytic neural networks with event - triggered synaptic feedbacks . here , we present an event - triggered rule to reduce the frequency of receiving synaptic feedbacks . at each neuron ,",
    "the synaptic feedback is a constant determined by the outputs of the neurons at its latest triggering time and changes at the next triggering time of this neuron that is triggered by a criterion via the neurons output states as well .",
    "we prove that the analytic neural network system is _ almost sure stable _ ( see _ definition [ convergence ] _ ) , which was proposed by hirsh @xcite , under the event - triggered rule by the ojasiewicz inequality .",
    "in addition , we further prove that the event - triggered rule is physically viable , owing to the exclusion of zeno behaviors . for the event - triggered rule",
    ", each neuron needs the states of the other neurons and itself , asynchronous .",
    "hence , the neurons are not triggered in a synchronous way , but independent of each other .",
    "it should be highlighted that our results can be extended to a large class of neural networks , for example , the standard cellular networks @xcite-@xcite .    the paper is organized as follows . in section [ sec2 ] ,",
    "the preliminaries are given ; stability and the exclusion of zeno behaviours of analytic neural networks with the event - triggering rules are proved in section [ sec3 ] ; then the discrete - time monitoring scheme is discussed in section [ monitoring ] ; in section [ sec5 ] , numerical examples are provided to show the effectiveness of the theoretical results ; the paper is concluded in section [ sec6 ] .    * notions * : @xmath22 denotes @xmath23-dimensional real space .",
    "@xmath24 represents the euclidean norm for vectors or the induced 2-norm for matrices .",
    "@xmath25 stands for an @xmath23-dimensional ball with center @xmath26 and radius @xmath27 . for a function @xmath28 , @xmath29 stands for its gradient . for a set @xmath30 and a point @xmath26",
    ", @xmath31 indicates the distance from @xmath32 to @xmath33 .",
    "@xmath34 stands for the lebesgue measure in @xmath22 .",
    "in this section , we firstly provide some definitions and preliminary results , which will be used later . with the discontinuous synaptic feedback , we consider eq . in the following form @xmath35_{i}+\\theta_{i}\\\\[5pt ] y_{i}(t)=g_{i}\\big(\\lambda_ix_i(t)\\big)\\\\[3pt ] \\end{cases}\\end{aligned}\\ ] ] for @xmath4 . here , @xmath36 , @xmath3 and @xmath37 .",
    "in particular , let @xmath38 .",
    "@xmath5 is an _",
    "analytic _ cost function function and @xmath39 is the output vector with a scaling parameter @xmath10 and the sigmoid functions @xmath14 as nonlinear activation functions , which we take as the sigmoid function as follows @xmath40 the gradient of the activation function @xmath8 at @xmath1 can be written as @xmath41 .",
    "the strict increasing triggering event time sequence @xmath42 ( to be defined ) are neuron - wise and @xmath43 , for all @xmath4 . at each @xmath44",
    ", each neuron @xmath13 changes the information from the other neurons with respect to an identical time point @xmath45 with @xmath46 . throughout the paper ,",
    "we simplify the notation @xmath45 as @xmath47 unless there is a potential ambiguity .",
    "let @xmath48^{\\top}$ ] be the vector at the right - hand side of , where @xmath49_{i}+\\theta_{i}.\\label{f}\\end{aligned}\\ ] ] denote the set of equilibrium points for as @xmath50 we first recall the definition of almost stability for model proposed in @xcite .",
    "[ convergence ] given an analytic function @xmath51 , the sigmoid function @xmath8 and constants @xmath52 , @xmath53 and @xmath54 , system is said to be _ almost sure stable _ if for any initial values except a set of zero measure , the trajectory @xmath55 of , there exists @xmath56 such that @xmath57    the following lemma shows that all solutions for are bounded and there exists at least one equilibrium point .",
    "[ existence ] given @xmath52 , @xmath53 , @xmath54 , @xmath4 , and two analytic functions @xmath51 and @xmath8 , for any triggering event time sequence @xmath58 , there exists a unique solution for the piece - wise cauchy problem with some initial data @xmath59 .",
    "moreover , the solutions with different initial data are bounded in time interval of its duration .",
    "first , we prove the existence and uniqueness of the solution for the system ( [ mg ] ) .",
    "denotes @xmath60^{\\top}$ ] , where @xmath61 . given a time sequence @xmath58 ordered as @xmath62 ( same items in @xmath63",
    "treat as one ) , there exists a unique solution of in the interval @xmath64 by using @xmath65 as the initial data according to the existence and uniqueness theorem in @xcite ) . for the next interval @xmath66",
    ", @xmath67 can be regarded as the new initial data , which can derive another unique solution in this interval . by induction",
    ", we can conclude that there exists a piecewise unique solution over the whole time interval of the duration .",
    "second , since @xmath68 , there exists a constant @xmath69 such that @xmath70 thus for any @xmath71 , there exists @xmath72 such that @xmath73 f_{i}(x_{t})>\\varepsilon_0,&~\\forall~ x_i(t)\\leqslant -r_0 \\end{cases}\\end{aligned}\\ ] ] where @xmath4 .",
    "one can see that @xmath74 for the whole duration of the solution .",
    "consider now the equilibrium points set @xmath75 .",
    "the following lemma is established in @xcite , which shows that there exists at least one equilibrium point in @xmath75 .",
    "[ nontrivial ] for the equilibrium points set @xmath75 , the following statements hold :    1 .",
    "@xmath75 is not empty .",
    "there exists a constant @xmath27 such that @xmath76 .    to depict the event that triggers the next feedback basing time point",
    ", we introduce the following candidate lyapunov function : @xmath77 -\\theta^{\\top } y,\\label{ly}\\end{aligned}\\ ] ] where @xmath78 $ ] with @xmath79 . the function",
    "@xmath80 generalizes the lyapunov function introduced for in @xcite , and it can also be thought of as the energy function for the hopfield and the cellular neural networks model @xcite . in this paper , we will prove that the candidate lyapunov function is a strict lyapunov function @xcite , defined as follows .",
    "a lyapunov function @xmath81 is said to be strict if @xmath82 , and the derivative of @xmath83 along trajectories @xmath55 , i.e. @xmath84 , satisfies @xmath85 and @xmath86 for @xmath87 .",
    "the next lemma provides the ojasiewicz inequality @xcite , which will be used to prove the finiteness of length for any trajectory @xmath55 of the system , towards convergence of the trajectory of the system .",
    "[ loj ] consider an analytic and continuous function @xmath88 .",
    "let @xmath89 for any @xmath90 , there exist two constants @xmath91 and @xmath92 , such that @xmath93 for @xmath94 .",
    "the definition of trajectory length is given below .",
    "[ def2 ] let @xmath55 on @xmath95 , be some trajectory of .",
    "for any @xmath96 , the length of the trajectory on @xmath97 is given by @xmath98",
    "in this section , we synthesize asynchronous triggers that prescribe when neurons should broadcast its state information and update their control signals .",
    "section [ primary ] presents the evolution of a quadratic function that measures network disagreement to identify a triggering function and discusses the problems that arise in its physical implementation .",
    "these observations are our starting point in section [ continuoussituation ] and section [ alternatesituation ] , where we should overcome these implementation issues , also know as _",
    "zeno behaviors_.    define the state measurement error vector @xmath99^{\\top}$ ] as @xmath100_{i}-\\big[\\nabla f\\big(y(t_{k_{i}(t)}^{i})\\big)\\big]_{i}\\end{aligned}\\ ] ] for @xmath101 with @xmath4 and @xmath61 .      for a constant @xmath102 , denote @xmath103 and @xmath104 the triggering function @xmath105 for the event - triggered rule can be defined as @xmath106where @xmath107 and @xmath108 with @xmath109 the updating rule for the trigger events is given as follow .",
    "[ primaryrule ] given @xmath110 , for each neuron @xmath111 , set @xmath112 with the following updating rule : @xmath113 for all @xmath4 and @xmath61 .",
    "suppose that for a trajectory @xmath55 of system ( [ mg ] ) , @xmath114 holds for all @xmath13 .",
    "then @xmath55 converges to some @xmath115 , namely , @xmath116 .    before the proof",
    ", we have the following remarks .    from ( [ f ] )",
    ", one can see that it is sufficient to monitor the neurons states @xmath117 , @xmath118 , from system , in order to verify rule ( [ primaryrule1 ] ) . and , the coefficient @xmath119 in eq .",
    "can be seen as a parameter from this normalization process .",
    "furthermore , according to ( [ mg ] ) , the evolution of the state ( @xmath12 ) of neuron @xmath111 is in the form @xmath120 with @xmath121_{i}$ ] a constant , before the event is triggered .",
    "thus , we can either continuously monitoring neurons states @xmath117 , @xmath118 , or formulate them as @xmath122i_{i}$ ] .",
    "therefore , we can only monitor the states at the event times instead , which leads a discrete - time monitoring scheme .",
    "we will discuss this scenario in section [ monitoring ] in detail .",
    "the preliminary condition for the convergence of the trajectory of system ( [ mg ] ) is that the existing duration of the solution of the cauchy problem of ( [ mg ] ) should be @xmath123 , or equivalently @xmath124 for all @xmath13 .",
    "we will verify this condition by proving the exclusion of zeno behaviors in sections [ continuoussituation ] and [ alternatesituation ] .",
    "the proof of this theorem comprises of the following propositions .",
    "[ proposition1 ] under the assumptions in theorem [ primaryrule ] , @xmath80 in is a strict lyapunov function for system .",
    "the partial derivative of the candidate lyapunov function @xmath80 along the trajectory @xmath55 can be written as @xmath125_{i}\\nonumber\\\\   & + \\theta_{i}-\\big[\\nabla f\\big(y(t)\\big)\\big]_{i } + \\big[\\nabla f\\big(y(t^{i}_{k_{i}(t)})\\big)\\big]_{i}\\bigg\\}\\nonumber\\\\ = & -\\lambda_{i}g'\\big(\\lambda_{i}x_{i}(t)\\big)\\big[f_{i}(x_{t})-e_i(t)\\big ] , \\label{dlyx}\\end{aligned}\\ ] ] and the time derivative of @xmath126 gives @xmath127f_{i}(x_{t}).\\end{aligned}\\ ] ] consider the inequality @xmath128 for some @xmath102 .",
    "then we have @xmath129\\nonumber\\\\ \\leqslant   & -\\big(1-\\frac{c}{2}\\big)\\sum_{i=1}^{n}\\lambda_{i}g'\\big(\\lambda_{i}x_{i}(t)\\big )   \\big|f_{i}(x_{t})\\big|^{2}\\nonumber\\\\   & + \\frac{1}{2c}\\sum_{i=1}^{n}\\lambda_{i}g'\\big(\\lambda_{i}x_{i}(t)\\big)\\big|e_{i}(t)\\big|^{2}\\nonumber\\\\ \\leqslant   & -\\alpha\\sum_{i=1}^{n}\\big|f_{i}(x_{t})\\big|^{2}+\\beta\\sum_{i=1}^{n}\\big|e_{i}(t)\\big|^{2}\\end{aligned}\\ ] ] from the rule , one can see that @xmath130 holds for all @xmath131 at most except @xmath132 .",
    "this implies @xmath133 for all @xmath61 . for any @xmath87 , there exits @xmath134 such that @xmath135 .",
    "thus @xmath136 .",
    "proposition [ proposition1 ] is proved .    with the lyapunov function @xmath80 for system ( [ mg ] ) and the event triggering condition",
    ", the consequent proof follows @xcite with necessary modifications .",
    "[ proposition2 ] there exist finite different energy levels @xmath137 , such that each set of equilibrium points @xmath138 is not empty .",
    "first of all , it can be seen that @xmath80 in is analytic on @xmath22 .",
    "suppose that there exist infinite different values @xmath139 such that @xmath140 is not empty .",
    "from lemma [ nontrivial ] , it is known that there exists @xmath141 such that outside @xmath142 there are no equilibrium points .",
    "hence @xmath143 for @xmath144 .",
    "consider points @xmath145 for @xmath144 . since @xmath146 , it holds @xmath147 and from eq .",
    ", @xmath148 .",
    "since @xmath149 is a compact set , hence , there exist a point @xmath150 and a subsequence @xmath151 such that @xmath152 for all @xmath153 and @xmath154 as @xmath155 . since @xmath156 is continuous , taking into account that @xmath157 for all @xmath153 , it results @xmath158 .    according to lemma [ loj ] , there exist @xmath159 and @xmath160 such that @xmath161 for @xmath162 .",
    "since @xmath154 as @xmath155 and @xmath163 have different energy levels @xmath164 , we can pick a point @xmath165 such that @xmath166 .",
    "then @xmath167 which is a contradiction .",
    "this completes the proof .",
    "without loss of generality , assume that the energy levels @xmath168 are ordered as @xmath169 .",
    "thus there exists @xmath170 such that @xmath171 , for any @xmath172 .",
    "for any given @xmath173 , define @xmath174 and @xmath175\\big\\}.\\end{aligned}\\ ] ]    [ proposition3 ] for @xmath176 , @xmath177 is a compact set and @xmath178 .    from lemma [ nontrivial ] , @xmath179 is bounded , hence @xmath180 is a compact set and @xmath181\\big\\}$ ] is a closed set .",
    "thus , @xmath182\\big\\}$ ] is a compact set .",
    "then proterty @xmath183 is an immediate consequence of proposition [ proposition2 ] .",
    "[ proposition4 ] for any trajectory @xmath55 of the system and any given time point @xmath184 , let @xmath177 , for some @xmath185 , be a compact set as defined in .",
    "then there exist a constant @xmath186 and an exponent @xmath187 such that @xmath188 for @xmath189 .    recall the notion @xmath190 as @xmath47 with @xmath191",
    "@xmath192 can be rewritten as @xmath193_{i}+\\theta_{i},\\end{aligned}\\ ] ] for @xmath4 . from and , we have @xmath194\\bigg|^{2}\\\\ \\leqslant   & ~\\tilde{\\beta}_{j}^{2}\\sum_{i=1}^{n } \\bigg[f_{i}^{2}(x_{\\tau})+e_{i}^{2}\\big(x(\\tau)\\big)+2\\big|f_{i}(x_{\\tau})e_{i}\\big(x(\\tau)\\big)\\big|\\bigg]\\\\ \\leqslant   & ~\\tilde{\\beta}_{j}^{2}\\sum_{i=1}^{n }    \\bigg[(1+c)f_{i}^{2}(x_{\\tau})+\\bigg(1+\\frac{1}{c}\\bigg)e_{i}^{2}\\big(x(\\tau)\\big)\\bigg]\\\\ \\leqslant   & ~\\tilde{\\beta}_{j}^{2}(1+c)\\sum_{i=1}^{n}\\big|f_{i}(x_{\\tau})\\big|^{2}+    ~\\tilde{\\beta}_{j}^{2}\\bigg(1+\\frac{1}{c}\\bigg)\\gamma^{2}\\sum_{i=1}^{n}\\psi_{i}^{2}(\\tau)\\\\ = & ~\\tilde{\\beta}_{j}^{2}(1+c)\\bigg(1+\\frac{\\gamma^{2}}{c}\\bigg)\\big\\|f(x_{\\tau})\\big\\|^{2},\\end{aligned}\\ ] ] where @xmath195",
    ". then it holds @xmath196 where @xmath197 from eq .",
    ", we have @xmath198    for the point @xmath189 , from eq . , @xmath199 .",
    "there exists @xmath200 , @xmath201 and an exponent @xmath202 such that @xmath203 for @xmath204 . indeed , if @xmath200 is small , we have @xmath205 for @xmath206 .",
    "therefore , it holds @xmath207 & \\geqslant\\big(\\alpha-\\beta\\gamma^{2}\\big)h_{j}c\\big(x(\\tau)\\big)\\big|l\\big(x(\\tau)\\big)-l_{j}\\big|^{v(x(\\tau))}\\\\[3pt ] & \\geqslant~c_{j}\\big|l\\big(x(\\tau)\\big)-l_{j}\\big|^{v_{j}},\\end{aligned}\\ ] ] where @xmath208 and @xmath209 for @xmath210 .",
    "now , we are at the stage to prove that the length of @xmath55 on @xmath211 is finite .",
    "the statement proposition is given as follow .",
    "[ proposition5 ] any trajectory @xmath55 of the systm has a finite length on @xmath211 , i.e. , @xmath212\\end{aligned}\\ ] ]    assume without loss of generality that @xmath213 is not an equilibrium point of eq . .",
    "due to the uniqueness of solutions , we have @xmath214 for @xmath131 , i.e. , @xmath215 for @xmath131 . from proposition [ proposition1 ]",
    ", it is seen that @xmath126 satisfies @xmath216 for @xmath217 , i.e. , @xmath126 strictly decreases for @xmath217 .",
    "thus , since @xmath55 is bounded on @xmath211 and @xmath126 is continuous , @xmath126 will tend to a finite value @xmath218 . from proposition",
    "[ proposition1 ] and the lasalle invariance principle @xcite , @xcite , it also follows that @xmath219 .",
    "thus , from the continuity of @xmath83 , it results @xmath220 for some @xmath185 and @xmath221 .    since @xmath221 and @xmath222",
    ", it follows that there exists @xmath223 such that @xmath224 for @xmath225 . by using proposition [ proposition4 ] , considering that @xmath226 for @xmath131 and @xmath227 for @xmath225 , we have that there exists @xmath186 and @xmath187 such that @xmath228 for @xmath225",
    ". then @xmath229 the change of variable @xmath230 derives @xmath231^{1-v_{j}}\\\\   & -\\big[l\\big(x(t)\\big)-l(+\\infty)\\big]^{1-v_{j}}\\bigg\\}\\\\ \\leqslant&\\,\\frac{1}{c_{j}(1-v_{j})}\\big[l\\big(x(\\widetilde{t})\\big)-l(+\\infty)\\big]^{1-v_{j}},\\end{aligned}\\ ] ] for @xmath225 .",
    "therefore , we have @xmath232^{1-v_{j}}}{c_{j}(1-v_{j})}\\\\ & < + \\infty.\\end{aligned}\\ ] ] this completes the proof of proposition [ proposition5 ] .    in what follows",
    "it remains to address the proof of theorem [ primaryrule ] , which is given in section [ primary ] .",
    "_ proof of theorem [ primaryrule ] : _ suppose that the condition holds .",
    "then from proposition [ proposition5 ] , for any trajectory @xmath55 of the system , we have @xmath233 from cauchy criterion on limit existence , for any @xmath173 , there exists @xmath234 such that when @xmath235 , it results @xmath236 .",
    "thus , @xmath237 it follows that there exists an equilibrium point @xmath238 of , such that @xmath239 .",
    "recalling the definition [ convergence ] , we can conclude that @xmath55 is convergent .",
    "the event - triggered condition implies that the next time interval for neuron @xmath111 depends on states of the neurons @xmath240 that are synaptically linked to neuron @xmath111 we say that neuron @xmath240 is synaptically linked to neuron @xmath111 if @xmath241_{i}$ ] depends on @xmath242 , in other words , @xmath243    when the event triggers , the neuron @xmath111 has to send its current state information @xmath244 to the other neurons immediately in order to avoid having @xmath245 .",
    "however , such a trigger rule would cause the following problems :    1 .",
    "[ p1 ] the triggering function @xmath246 may hold even after neuron @xmath111 sends its new state to the other neurons .",
    "a bad situation is that @xmath247 happens at the same time when @xmath248 .",
    "this may cause the neuron to send its state continuously .",
    "this is called _ continuous triggering situation _ in the zeno behavior .",
    "2 .   [ p2 ] event if @xmath247 and @xmath248 never happen at the same time point .",
    "the zeno behavior may still exist .",
    "for example , one neuron @xmath111 broadcasting its new state to the other neurons may cause the triggering rules for two neurons @xmath249 and @xmath250 are broken alternately .",
    "that is to say , the inter - event time for both @xmath249 and @xmath250 will decrease to zero .",
    "this is called _ alternate triggering situation _ in the zeno behavior .",
    "these observations motivate us to introduce the morse - sard theorem for avoiding the _ continuous triggering situation _",
    "( p[p1 ] ) in subsection [ continuoussituation ] . in subsection",
    "[ alternatesituation ] , we will also prove that for all the neuron , the _ alternate triggering situation _ is absent by the event - triggered rule in theorem [ primaryrule ] .      from the rule , we know that a triggering event happens at a threshold time @xmath47 satisfying @xmath251 for @xmath4 and @xmath61 .",
    "to avoid the situation that @xmath247 and @xmath248 happen at the same triggering time point @xmath47 for some @xmath252 , when the triggering function @xmath246 still holds after the neuron @xmath111 sends the new state to the other neurons , we define a function vector @xmath253\\end{aligned}\\ ] ] where @xmath254 and @xmath255 for @xmath61 , which is the set of all the latest triggering time points before the present time @xmath44 .",
    "denote @xmath256^{\\top}$ ] and the following theorem that comes from the morse - sard theorem @xcite will be used for excluding this continuous triggering .",
    "[ mstheorem]for each initial data @xmath213 , there exists a measure zero subset @xmath257 such that for all the neurons @xmath258 , if @xmath259 and the triggering time point set at the first event @xmath260 is countable , then the set of all the triggering time point on @xmath211 @xmath261 is also a countable set .    to show that the triggering time point set @xmath262 is countable for each @xmath259 , we first prove an equivalent statement that the jacobian matrix @xmath263^{\\top}$ ] has rank @xmath23 at next triggering time point @xmath264 when @xmath265 ( i.e. , the set of all the latest triggering time points before the present time @xmath44 ) is countable .",
    "note @xmath266,\\end{aligned}\\ ] ] where @xmath267 .",
    "the two components in the above equation satisfy @xmath268_{i }    + \\gamma^{2}d_{i}\\delta^{2}(t)\\,{\\rm e}^{-2d_{i}(t - t_{k}^{i})}\\\\ = & ~e_{i}(t)\\frac{{\\rm d}}{{\\rm d}t}\\big[\\nabla f\\big(y(t)\\big)\\big]_{i }    + \\gamma^{2}d_{i}\\psi_{i}^{2}(t)\\end{aligned}\\ ] ] and @xmath269_{i }    -\\gamma^{2}d_{i}\\delta^{2}(t)\\,{\\rm e}^{-2d_{i}(t - t_{k}^{i})}\\\\ = & -e_{i}(t)\\frac{{\\rm d}}{{\\rm d}t_{\\tau}}\\big[\\nabla f\\big(y(t_{\\tau})\\big)\\big]_{i }    -\\gamma^{2}d_{i}\\psi_{i}^{2}(t)\\end{aligned}\\ ] ] when event triggers and @xmath270 resets to @xmath271 in the short time period after the next time point @xmath272 , that is , @xmath273 when @xmath274 , then it holds @xmath275 and @xmath276 define a initial data set by @xmath277 take the initial data @xmath278 , we have @xmath279 which implies @xmath280\\bigg|_{t = t_{k+1}^{i}+\\varepsilon}\\\\ = & ~\\big[\\gamma^{2}d_{i}\\psi_{i}^{2}(t_{k+1}^{i}),-\\gamma^{2}d_{i}\\psi_{i}^{2}(t_{k+1}^{i})\\big]\\\\[2pt ] \\neq&~0.\\end{aligned}\\ ] ] that is , the jacobian matrix @xmath281 has rank @xmath23 at @xmath264 .",
    "then it follows that if @xmath278 and @xmath265 is countable , the next triggering time point @xmath272 is isolated , hence the next triggering time point set for all the neurons @xmath282 is countable .",
    "furthermore , by using the inverse function theorem , it holds @xmath283 for the lebesgue measure @xmath284 .",
    "now , according to the method of induction , we can assert that for each initial data @xmath259 , where @xmath285 the triggering time points set for all the neuron on @xmath211 @xmath286 is countable and moreover @xmath287 under the assumption that @xmath260 is countable .",
    "this theorem is proved .",
    "recalling the triggering function @xmath105 , we have the results that if the initial data @xmath259 and there exist countable number of triggering time points at the first event ( i.e. , @xmath260 is countable ) , then @xmath288 that is to say , @xmath247 and @xmath248 may never happen at the same time at all the triggering time point @xmath47 where @xmath4 and @xmath61 .",
    "therefore , the _ continuous triggering situation _ in the zeno behavior ( p[p1 ] ) is avoided by the rule .",
    "any perturbation on the initial data @xmath213 can help away from the zero measured subset @xmath289 .      after excluding the _ continuous triggering situation _",
    ", we are to prove the absence of the _ alternate triggering situation _ in the zeno behavior . toward this aim",
    ", we will find a common positive lower - bound for the inter - event time @xmath290 , for all @xmath4 and @xmath61 .",
    "[ zeno ] let @xmath289 be a zero measured set as defined in . under two criterions of the event - triggered rule in theorem [ primaryrule ] , for each @xmath259 , the next inter - event interval of every neuron is strictly positive and has a common positive lower - bound .",
    "furthermore , the _ alternate triggering situation _ in the zeno behaviors are excluded .",
    "let us consider the following derivative of the state measurement error for any neuron @xmath258 @xmath291_{ij}\\,\\dot{y_{j}}(t)\\bigg|\\\\[2pt ] = & ~\\bigg|\\sum_{j=1}^{n}\\big[\\nabla^2 f\\big(y(t)\\big)\\big]_{ij }     \\lambda_{j}g'_{j}\\big(\\lambda_{j}x_{j}(t)\\big)f_{j}\\big(x_{t}\\big)\\bigg|\\\\ \\leqslant   & ~\\big\\|\\nabla^{2 } f\\big(y(t)\\big)\\big\\|     \\big\\|\\lambda\\,\\partial g\\big(\\lambda x(t)\\big)\\big\\|     \\sqrt{\\sum_{j=1}^{n}\\big|f_{j}\\big(x_{t}\\big)\\big|^{2}}\\\\ =   & ~\\big\\|\\nabla^{2 } f\\big(y(t)\\big)\\big\\|\\big\\|\\lambda\\big\\|     \\sqrt{\\delta(t)\\sum\\limits_{i=1}^{n}{\\rm e}^{-2d_{i}(t - t_{k}^{i})}}\\\\ \\leqslant   & ~\\mathcal m\\sqrt{\\delta\\big(t\\big)}\\ ] ] where @xmath292 and then it follows @xmath293 where @xmath294 .    for any neuron @xmath258 ,",
    "if there are no events in @xmath295 , the compulsory criterion will be triggered , that is , @xmath296 .",
    "otherwise , if there is a triggering event in @xmath297 , according to the autonomy criterion , it satisfies @xmath298 .",
    "that is to say , it always satisfies @xmath299 .",
    "noting @xmath300 if there is no event occurring at @xmath44 .",
    "then , there exists some @xmath301 such that @xmath302 for all @xmath4 and @xmath61 , with taking @xmath303 .",
    "moreover , since @xmath304 is decreasing on @xmath305 if there are no events occuring during this period , we obtain @xmath306 where @xmath307 , which implies @xmath308 for any @xmath294 . based on the autonomy criterion of the updating rule in theorem [ primaryrule ] , the event will not trigger until @xmath309 at time point @xmath310 . hence , for each @xmath259 , it holds @xmath311 noting that the equation @xmath312 with @xmath313 possesses a positive solution of @xmath314 , we can assert that for all neurons @xmath258 , the next inter - event time has a common positive lower - bound which follows @xmath315 this implies that @xmath309 holds at some @xmath264 , which must satisfy @xmath316 for all @xmath4 and @xmath61 .    since @xmath317 and @xmath318 are uniform for all the neurons , the next triggering time point @xmath272 satisfies @xmath319 for all @xmath4 and @xmath61 .",
    "hence , the next inter - event interval of each neuron is lower bounded by a common positive constant , which means the absence of the _ alternate triggering situation _ in the zeno behavior ( p[p2 ] ) is proved .    to sum up",
    ", we have excluded both the _ continuous triggering situation _ and _ alternate triggering situation _ in the zeno behavior , when the event - triggered rule is taken into account .",
    "therefore , we can claim that there is no zeno behavior for all the neurons .    after proving exclusion of zeno behaviors ,",
    "we are at the stage to conclude @xmath320 for all @xmath4 .",
    "this implies the following summary result .",
    "[ main ] under the event - trigger rule described in theorem [ primaryrule ] , system ( [ mg ] ) is almost sure stable .",
    "in fact , from theorems [ mstheorem ] and [ zeno ] , one can conclude that for all initial values except a set of zero measure , the trajectory of system ( [ mg ] ) possesses discontinuous the trigger events with inter - event interval a positive low bounded .",
    "this implies that the solution of cauchy problem of system ( [ mg ] ) with these initial values exists for the duration @xmath123 and @xmath114 for all @xmath4 . from theorem [ primaryrule ] , it converges to certain equilibrium on @xmath75 .",
    "therefore , we have proved this theorem .",
    "the continuous monitoring strategy for theorem [ primaryrule ] may be costly since the states of the neurons should be observed simultaneously . an alternative method is to predict the triggering time point when inequality does not hold and update the triggering time accordingly .    for any neuron @xmath258",
    ", according to the current event timing @xmath47 , its state can be formulated as    [ stateformula ]    x_i(t)=x_i(t_k^)+ \\{d_ix_i(t_k^)+_i-_i } +   + y_i(t)=g_i(_ix_i(t ) ) +    & &    for @xmath321 , where @xmath322 is the newest timing of all other neurons and @xmath272 is the next triggering time point at which neuron @xmath111 happens the triggering event .",
    "then , solving the following maximization problem @xmath323 we have the following prediction algorithm ( algorithm [ algorithm ] ) for the next triggering time point . with the information of each neuron at time @xmath324 and the proper parameters @xmath325 , search the observation time @xmath326 by at first . if no triggering events occur in all neurons during @xmath327 , the neuron @xmath111 triggers at time @xmath328 and record as the next triggering event time @xmath272 , that is @xmath329 .",
    "renew the neuron @xmath111 s state and send the renewed information to the other neurons .",
    "the prediction of neuron @xmath111 is finished .",
    "if some other neuron triggers at time @xmath330 , update @xmath331 in state formula and go back to find a new observation time @xmath328 by solving the maximization problem .",
    "initialize @xmath170 , @xmath332 input @xmath333 for all @xmath4 @xmath334 search @xmath326 by the strategy @xmath335 @xmath111 triggers at time @xmath336 @xmath111 renew its state information @xmath337 @xmath111 sends the state information to the other neurons @xmath338 update @xmath331 in the state formula    in addition , when neuron @xmath111 updates its observation time @xmath326 , the triggering time predictions of the neurons will be affected .",
    "therefore , besides the state formula and the maximization problem as given before , each neuron should take their triggering event time whenever any of the other neurons renews and broadcasts its state information .",
    "in other word , if one neuron updates its triggering event time , it is mandatory to inform the other neurons .",
    "this monitoring scheme via the state formula may lose the high - level efficiency of the convergence , because it abandons the continuous adjustment on @xmath119 in eq . .",
    "but the advantage is that a discrete - time inspection on @xmath55 can be introduced to ensure the convergence in theorem [ primaryrule ] , which can reduce the monitoring times and costs .",
    "in this section , two numerical examples are given to demonstrate the effectiveness of the presented results and the application .",
    "example 1 is a 5-dimension system which illustrates our theoretical results and example 2 is a 3-dimension system which compares the continuous monitoring with the discrete - time monitoring .",
    "* example 1 : * consider a 5-dimension analytic neural network with @xmath339 where @xmath340 , @xmath341^{\\top}$ ] and @xmath342    by the rule , fig .",
    "[ example1:fig1 ] illustrates the state @xmath55 converges to @xmath343^{\\top}$ ] .",
    "the initial value @xmath344^{\\top}$ ] is randomly selected in the domain @xmath345^{5}$ ] and @xmath346 .",
    "the triggering time points of each neuron are shown in fig .",
    "[ example1:fig2 ] .",
    "take the different values of the parameter @xmath325 from @xmath347 to @xmath348 by step @xmath349 and @xmath350 .",
    "the simulation results under the event - triggered rule are shown in table [ example1:table ] .",
    "@xmath317 is the theoretical lower - bound for the inter - event time of all the neurons calculated by .",
    "@xmath351 is the actual value of the minimal length of inter - event time by simulation .",
    "@xmath352 is the average number of triggering events over the neurons and @xmath353 stands for the first time when @xmath354 .",
    "all the results in the table are average over @xmath355 independent simulations .",
    "it can be seen that the actual minimal inter - event time @xmath356 is always larger than the corresponding theoretical lower - bound @xmath317 .",
    "this implies that we have excluded the zeno behavior with the lower - bound @xmath317 for all the neurons .",
    "moreover , the average number of triggering events @xmath352 decreases while the first convergent time @xmath353 increases with @xmath325 increasing from @xmath347 to @xmath348 by step @xmath349 . +     +   +    c|c|c|c|c    ' '' ''    @xmath325 & @xmath356 & @xmath317 & @xmath352 & @xmath353 + 0.10 & 0.00490 & 0.00443 & 82.9 & 1.948 + 0.15 & 0.00712 & 0.00665 & 68.6 & 1.981 + 0.20 & 0.00908 & 0.00887 & 59.5 & 2.091 + 0.25 & 0.01476 & 0.01108 & 52.9 & 2.152 + 0.30 & 0.01505 & 0.01330 & 47.6 & 2.188 + 0.35 & 0.01789 & 0.01552 & 40.5 & 2.203 + 0.40 & 0.01898 & 0.01774 & 35.9 & 2.362 + 0.45 & 0.02124 & 0.01995 & 32.6 & 2.525 + 0.50 & 0.02351 & 0.02217 & 28.7 & 2.718 +    [ example1:table ]    * example 2 : * consider a 3-dimension neural network with @xmath357 where @xmath340 , @xmath341^{\\top}$ ] and @xmath358    according to the event - triggered rule in theorem [ primaryrule ] , fig .",
    "[ continuousdynamics ] shows that the state @xmath55 converges to the equilibrium by continuous monitoring and fig .",
    "[ discretedynamics ] indicates the convergence by discrete - time monitoring . with @xmath359^{\\top}$ ] and @xmath360 , the equilibrium is @xmath361^{\\top}$ ] .",
    "the time slots of the triggered events of each neuron by continuous - time and discrete - time monitoring are illustrated in figs .",
    "[ continuoustime ] and [ discretetime ] .",
    "+   +   +    we record @xmath356 , @xmath317 , @xmath352 and @xmath353 with different values of @xmath325 by both continuous - time and discrete - time monitoring .",
    "the results shown in table [ example2:table1 ] are average @xmath355 independent simulations .",
    "it can be seen that @xmath356 is larger than the theoretical lower - bound @xmath317 by both continuous - time and discrete - time monitoring , which implies that the zeno behavior is excluded for all the neurons . @xmath352 and @xmath353 from two monitoring are similar to those in example 1 .",
    "@xmath352 decreases and @xmath353 increases with @xmath325 increasing from @xmath347 to @xmath348 by step @xmath349 and @xmath350 .",
    "c|c|c|c|c    ' '' ''    * @xmath325 & & * @xmath317 + & @xmath356 & @xmath352 & @xmath353 & + 0.10 & 0.01320 & 38.3 & 4.356 & 0.00423 + 0.20 & 0.01760 & 36.7 & 4.376 & 0.00846 + 0.30 & 0.01978 & 29.4 & 4.532 & 0.01268 + 0.40 & 0.02756 & 25.8 & 4.608 & 0.01691 + 0.50 & 0.04548 & 20.3 & 4.656 & 0.02114 + * @xmath325 & & * @xmath317 + & @xmath356 & @xmath352 & @xmath353 & + 0.10 & 0.01320 & 37.2 & 4.254 & 0.00423 + 0.20 & 0.01760 & 35.7 & 4.344 & 0.00846 + 0.30 & 0.01978 & 28.1 & 4.513 & 0.01268 + 0.40 & 0.02756 & 23.7 & 4.598 & 0.01691 + 0.50 & 0.04548 & 19.3 & 4.652 & 0.02114 +    [ example2:table1 ]    according to the definition of lyapunov ( or energy ) function , if the input @xmath362 takes a sufficient small value and @xmath363 for @xmath364 , then @xmath365 .",
    "thus , as an application , the system with the event - triggered rule in theorem [ primaryrule ] can be used to seek the local minimum point of @xmath18 over @xmath366 .",
    "denote @xmath367 where @xmath55 is the trajectory of the system .",
    "@xmath368 is the local minimum point of @xmath369 where @xmath370 fig .",
    "[ example2:fig3 ] shows that the limit @xmath368 converges to local minimum points @xmath371^{\\top}$ ] and @xmath372^{\\top}$ ] when @xmath373 .",
    "the initial value @xmath213 for each simulation is chosen randomly in the domain @xmath374^{3}$ ] and @xmath360 .",
    "converges to two local minimum points @xmath371^{\\top}$ ] and @xmath372^{\\top}$ ] with a random input @xmath375 with @xmath376 , @xmath360 , and random initial data in the domain @xmath374^{3}$ ] .",
    "@xmath377 are picked from 0.01 to 100.,scaledwidth=50.0% ]",
    "in this paper , the event - triggering rule for discrete - time synaptic feedbacks in a class of analytic neural network was proposed and proved to guarantee neural networks to be almost sure stable .",
    "in addition , the zeno behaviors can be prove to be excluded . by these asynchronous event - triggering rules ,",
    "the synaptic information exchanging frequency between neurons are significantly reduced .",
    "the main technique of proving almost stability is finite - length of trajectory and the ojasiewicz inequality @xcite .",
    "two numerical examples have been provided to demonstrate the effectiveness of the theoretical results .",
    "it has also been shown by these examples , following the routine in @xcite and the proposed updating rule can reduce the cost of synaptic interactions between neurons .",
    "one step further , our future work will include the self - triggered formulation and event - triggered stability of other more general systems as well as their application in dynamic optimisation .",
    "a. molin and s. hirche , `` suboptimal event - based control of linear systems over lossy channels estimation and control of networked systems , '' in _ proceedings of the 2nd ifac workshop on distributed estimation and control in networked systems _ , annecy , france , sep .",
    "2010 , pp . 5560 .",
    "e. garcia and p. j. antsaklis , `` model - based event - triggered control with time - varying network delays , '' in _ proceedings of the 50th ieee conference on decision and control and european control conference _ , orlando , fl , dec .",
    "2011 , pp .",
    "1650 - 1655 .",
    "j. d. cao and j. wang , `` global asymptotic stability of a general class of recurrent neural networks with time - varying delays , '' _ ieee trans .",
    "circuit syst .",
    "i , fundam .",
    "theory appl .",
    "34 - 44 , jan .",
    "2003 .",
    "k. g. vamvoudakis , `` an online actor / critic algorithm for event - triggered optimal control of continuous - time nonlinear systems , '' in _ proceedings of american control conference _ ,",
    "portland , or , jun .",
    "2014 , pp . 1 - 6 .",
    "m. a. cohen and s. grossberg , `` absolute stability of global pattern formation and parallel memory storage by competitive neural networks , '' _ ieee trans .",
    "syst . , man , cybern .",
    "_ , vol . 13 , pp . 815 - 821 , sep",
    ". 1983 .    m. forti and a. tesi , `` new conditions for global stability of neural networks with application to linear and quadratic programming problems , '' _ ieee trans .",
    "circuits syst .",
    "papers _ , vol .",
    "354 - 366 , jul . 1995 .",
    "m. forti , p. nistri , and m. quincampoix , `` convergence of neural networks for programming problems via a nonsmooth ojasiewicz inequality , '' _ ieee trans .",
    "neural netw .",
    "1471 - 1486 , nov .",
    "2006 .",
    "s. ojasiewicz , `` une propriet@xmath379 topologique des sous - ensembles analy - tiques r@xmath379els , '' in _ colloques internationaux du c.n.r.s .",
    "les @xmath379quations aux d@xmath379rive@xmath379s partielles _ , paris , france , 1963 , pp ."
  ],
  "abstract_text": [
    "<S> in this paper , we investigate stability of a class of analytic neural networks with the synaptic feedback via event - triggered rules . </S>",
    "<S> this model is general and include hopfield neural network as a special case . </S>",
    "<S> these event - trigger rules can efficiently reduces loads of computation and information transmission at synapses of the neurons . </S>",
    "<S> the synaptic feedback of each neuron keeps a constant value based on the outputs of the other neurons at its latest triggering time but changes at its next triggering time , which is determined by certain criterion . </S>",
    "<S> it is proved that every trajectory of the analytic neural network converges to certain equilibrium under this event - triggered rule for all initial values except a set of zero measure . </S>",
    "<S> the main technique of the proof is the ojasiewicz inequality to prove the finiteness of trajectory length . </S>",
    "<S> the realization of this event - triggered rule is verified by the exclusion of zeno behaviors . </S>",
    "<S> numerical examples are provided to illustrate the efficiency of the theoretical results .    analytic neural network , almost stability , event - triggered rule , zenoa behaviors </S>"
  ]
}