{
  "article_text": [
    "a central task in evolutionary biology is the reconstruction of ` phylogenetic ' ( evolutionary ) trees from genetic data sampled from present - day species that describe how these species evolved from a common ancestor .",
    "these trees can be estimated from a variety of different types of data , but a common approach involves data that are based on some measure of ` evolutionary distance ' between species .",
    "a variety of fast ( polynomial - time ) methods have been devised for building a phylogenetic @xmath0-tree from an arbitrary distance function @xmath1 on @xmath0 .",
    "the most popular by far is ` neighbor - joining , ' ( nj ) and the paper @xcite that described this heuristic algorithm has now been cited more than 36,000 times .",
    "a desirable property of such methods is that when a distance function fits exactly on a binary ( fully resolved ) tree with branch lengths , then the method will return that underlying tree ( up to the placement of the root ) and its edge lengths .",
    "moreover , when a distance function @xmath2 is close to an exact fit on some binary tree @xmath3 , many methods also come with a guarantee that they will return @xmath3 when applied to @xmath2 .",
    "how close @xmath2 needs to be to a ` tree metric ' @xmath1 depends crucially on @xmath4 , the smallest interior edge length of @xmath3 ; a distance - based tree reconstruction method is said to have ` safety radius ' @xmath5 if the method is guaranteed to return the underlying binary tree @xmath3 when @xmath2 differs from @xmath1 by less than @xmath6 on each pair of leaves ( a precise definition is given shortly ) .",
    "this notion was introduced by kevin attenson 25 years ago in this journal @xcite , where he established that for nj , this safety radius is @xmath7 ; moreover , this is the largest possible safety radius for any distance - based tree reconstruction method .    while this classical safety radius has provided a precise formal way to compare different tree reconstruction methods , it is not always a good predictor of which method will perform more accurately on simulated ( or real ) data ; for instance , methods that perform well ( e.g. nj ) often have a safety radius that is equivalent to those of methods that perform poorly ( e.g. the buneman tree @xcite ) . in this paper",
    ", we consider a more relaxed , statistically - based version of the purely combinatorial safety radius that treats the differences between observed and expected distances as independent random variables .",
    "we develop and apply this notion of a ` stochastic safety radius ' , derive formal upper and lower bounds , and compare different tree reconstruction methods using it .      for a phylogenetic @xmath0tree @xmath3 with positive edge lengths @xmath8 ,",
    "let @xmath9 denote the associated tree metric on @xmath0 and let @xmath4 denote the minimal interior edge length of @xmath3 .",
    "a method @xmath10 for reconstructing a phylogenetic @xmath0tree from each dissimilarity map @xmath2 on @xmath0 is said to have a _",
    "@xmath11 safety radius _",
    "@xmath12 if , for any binary phylogenetic tree @xmath3 with @xmath13 leaves we have : @xmath14 here @xmath15 refers to the largest difference between @xmath2 and @xmath1 over all pairs from @xmath0 .",
    "beginning with the pioneering work of atteson @xcite it is now well known that no method can have @xmath11 safety radius @xmath16 and that certain methods such as nj and ` balanced minimimum evolution ' ( bme ) @xcite achieve this bound for all @xmath13 @xcite .",
    "however , for other methods , the @xmath11 safety radius is less than @xmath17 and it can even converge to @xmath18 as @xmath13 grows @xcite , @xcite .",
    "we will refer to the following constraint : @xmath19 as the _ atteson @xmath11 bound_.    despite the mathematical elegance of these results , there are two problems associated with the @xmath11 safety radius approach .",
    "firstly , it is a strict combinatorial condition and the @xmath11 metric is extremely sensitive , particularly for large values of @xmath13 , since it takes only one pair of taxa to have a @xmath2 value that conflicts substantially with its @xmath1 value to result in a violation of the safety radius .",
    "a second related point is that simulations show that methods such as nj often return the correct tree even when the safety radius is violated .",
    "one combinatorial approach that goes some way towards addressing this second point was taken in @xcite and developed further in @xcite .",
    "this latter paper also showed that nj has a @xmath20 safety radius @xmath21 for trees with @xmath22 leaves .",
    "a related  edge safety radius \" approach was also pioneered by atteson @xcite , who showed that addtree @xcite is optimal , whereas nj is not .",
    "however , simulations show that nj performs well ( i.e. as well as addtree ) regarding the edge safety radius , which somewhat contradicts the theory .",
    "recent results by bordewich and mihaescu @xcite also indicate that this theory has some shortcomings and produces a ranking among methods ( greedy bme / nj ) which is not observed in practice .",
    "( there are also examples where the standard safety radius produces strange ranking , e.g. upgma / ls methods @xcite ) .",
    "let us regard @xmath2 as differing from @xmath1 by a random ` error ' .",
    "more precisely , we suppose that : @xmath23 where the @xmath24 values are independent normal random variables , each with a mean of @xmath18 and a variance equal to @xmath25 .",
    "we refer to this simple model as the _ random errors model_.    note that in the context of this random errors model , maximum likelihood estimation ( mle ) of a tree is equivalent to the ordinary least squares ( ols ) tree - reconstruction method , since the ols score that this method seeks to minimise is proportional to minus the log of the likelihood function .",
    "several heuristic approaches have been designed to search for the ols tree , starting with the seminal 1967 papers of cavalli - sforza and edwards @xcite and fitch and margoliash @xcite .    throughout this paper , we let @xmath26 denote a normal random variable with mean @xmath27 and variance @xmath25 . thus @xmath24 has the distribution @xmath28 .",
    "the following inequality and asymptotic equality ( as @xmath29 ) are helpful in the results that follow ( their proof is in the appendix ) . for @xmath30 :",
    "@xmath31 where @xmath32 denotes asymptotical equivalence as @xmath33 grows .      with four taxa , most methods ( if not all ) will use the  four - point rule \" @xcite and select the topology @xmath34 if : @xmath35 now , under the random errors model , the three sums @xmath36 constitute three independent normal random variables , each with variance of @xmath37",
    ". moreover , if the tree generating @xmath1 has topology @xmath34 with an interior edge of length @xmath8 , then the second and third sum have the same mean , which is larger than the mean of the first sum by @xmath38 .",
    "in particular @xmath39 and @xmath40 are both equal to @xmath41 consequently , the probability that the correct tree topology @xmath34 is selected from @xmath2 is at least : @xmath42 thus , there will be ( say ) a @xmath43 probability of correctly inferring the tree topology if @xmath44 is @xmath45 ( or less ) .",
    "it is interesting to compare this to the @xmath11 bound of atteson @xcite for methods such as nj .",
    "recall that this holds when @xmath46 for all six pairs @xmath47 .",
    "now , under the random effects model , the probability of these events all holding is exactly : @xmath48 consequently , for @xmath44 set equal to @xmath45 , as above , the probability the @xmath11 bound holds is @xmath49 which is much lower than the 98% probability described previously ; moreover , in order to ensure the @xmath11 bound holds with 98% probability , we would need to reduce @xmath44 to around @xmath50 .      to extend the above analysis from @xmath51 to larger values of @xmath13 ,",
    "it is useful to allow @xmath25 to depend on @xmath13 ( the reason for this becomes clear shortly ) .",
    "specifically , let us write : @xmath52 for some value @xmath53 .",
    "notice that @xmath44 is converging to zero but very slowly ( i.e. larger trees require more accuracy , but not a lot more ) .",
    "first we consider what happens with the @xmath11 bound as @xmath13 grows .",
    "[ attlem ] under the random errors model , the probability that the atteson @xmath11 bound holds for all pairs @xmath47 in a tree with @xmath13 leaves converges to 0 for @xmath54 and converges to 1 for @xmath55 .",
    "let @xmath56 be the minimal interior edge length in @xmath3 . then : @xmath57 where @xmath28 refers to a normal random variable with mean 0 , and variance @xmath25 given by eqn .",
    "( [ eq1 ] ) .",
    "thus : @xmath58 now , the @xmath11 bound is satisfied precisely when @xmath59 for all @xmath47 , and so the probability of this @xmath11 bound occurring  call it @xmath60  is given by : @xmath61 proposition  [ attlem ] now follows from the asymptotic equivalence in ( [ helps ] ) and the observation that , for any sequence @xmath62 with @xmath63 , we have @xmath64 which converges to @xmath18 and @xmath65 when @xmath66 and @xmath67 , respectively , as @xmath13 grows .",
    "@xmath68    we now define a ` stochastic safety radius ' that is scaled in such a way as to allow comparisons that are meaningful even as @xmath13 tends to infinity .",
    "* definition [ stochastic safety radius ] * for any @xmath69 , we will say that a distance - based tree reconstruction method @xmath10 has _",
    "@xmath70-stochastic safety radius _",
    "@xmath71 if for every binary phylogenetic @xmath0-tree @xmath3 on @xmath13 leaves , with minimum interior edge length @xmath4 , and with the distance @xmath2 on @xmath0 described by the random errors model , we have : @xmath72    [ bac ] for any method @xmath10 that has @xmath11 safety radius @xmath73 , and for any @xmath69 , there is a value @xmath74 so that @xmath10 has @xmath70-stochastic radius ( at least ) @xmath75 for all binary trees on @xmath13 leaves",
    ". moreover , as @xmath76 we can take @xmath77 arbitrarily close to @xmath78 .",
    "if @xmath79 then , from the analogue of ( [ pin ] ) ( with @xmath80 replaced by @xmath81 ) , we have : @xmath82 applying the inequality in ( [ helps ] ) gives : @xmath83 and the very last term on the right can be made @xmath84 by selecting @xmath85 sufficiently small .",
    "moreover , as @xmath76 , we can take @xmath77 to approach @xmath78 for any @xmath69 .",
    "@xmath68    notice that this proof just sets a lower bound on the @xmath70-stochastic safety radius .",
    "this shows that any method having non - zero @xmath11 safety radius ( e.g. @xmath86 for nj ) also has non - zero @xmath70-stochastic safety radius , which is roughly equal to half of the @xmath11 safety radius ( i.e. 1/4 with nj ) . in other words ,",
    "our definition provides non - trivial performance criteria for those methods , with a lower bound that is easily computed from the @xmath11 results .",
    "however , the bound in proposition  [ bac ] is very severe in that it requires that the @xmath11 bound to hold for all pairwise distances .",
    "we will see that much better bounds do exist . moreover , the following definition avoids having to consider the effect of @xmath70 , which plays a minor role in all calculations .",
    "* definition [ limiting stochastic safety radius ] * we say that a distance - based tree reconstruction method @xmath10 has a _ limiting stochastic safety radius _ ( lssr ) @xmath87 if for every @xmath88 and every @xmath69 the @xmath70-stochastic safety radius of @xmath10 is at least @xmath75 for all binary trees with sufficiently many leaves .",
    "we first show that the limiting stochastic safety radius of a relatively simple quartet - based approach is considerably larger than the value @xmath89 that is required by proposition  [ bac ] to satisfy the atteson bound ( where @xmath90 ) .",
    "we then present our main theoretical result ( theorem  [ mainthm ] ) , an absolute upper bound on the limiting stochastic safety radius of any distance - based method .",
    "[ pro1 ] there is a distance - based tree reconstruction method which has a limiting stochastic safety radius of @xmath91 .",
    "we use a result from @xcite ( see also @xcite ) which provides a tree reconstruction method that can recover a binary tree with @xmath13 leaves by asking for the topology of @xmath92 quartets ( the questions asked are allowed to depend on the answers obtained up to that point ) .",
    "provided that all these quartet trees are correctly returned , we will infer the correct underlying parent tree . now , suppose we set @xmath93 . from eqn .",
    "( [ quar ] ) , the probability that any particular quartet is correctly inferred is at least : @xmath94 where @xmath8 is the length of the interior path of the quartet in the parent tree . since @xmath95 , boole s inequality implies that the probability that every particular quartet is correctly inferred is at least : @xmath96 where @xmath97 is an upper bound constant in the @xmath92 construction . notice that this holds even though the quartet decisions are not ( stochastically ) independent .",
    "the expression in ( [ ceq ] ) now converges to 1 for any value @xmath98 as @xmath76 , by the asymptotic equivalence in ( [ helps ] ) .",
    "@xmath68    [ mainthm ]    no distance - based tree reconstruction method has a limiting stochastic safety radius greater than 1 .    the idea of the proof is to show that mle ( maximum likelihood estimation ) can not allow a safety radius with @xmath99 on a subset of trees ( with prescribed branch lengths ) , from which it will follow that no other method could do so either on that subclass of trees ( and thereby on all binary trees and with variable edge lengths ) .    consider the binary tree @xmath100 on the leaf set @xmath101 of size @xmath102 , obtained from any fixed binary tree on leaf set @xmath103 by replacing each leaf @xmath104 by the rooted triplet subtree @xmath105 . for @xmath100 assign length 1 to all the interior edges and to the pendant edges that are incident with leaves of type @xmath106 and @xmath107 ( for all @xmath104 ) , and assign the length @xmath108 to the pendant edges that are incident with leaves of type @xmath109 ( for all @xmath104 ) . for a sequence @xmath110 where @xmath111 let @xmath112 be the tree obtained from @xmath100 by interchanging the leaf labels @xmath107 and",
    "@xmath109 precisely for each @xmath104 for which @xmath113 ( leaving all edge lengths unchanged  thus all cherry pendant edges have length 1,while the non - cherry pendant edges have length 2 ) .",
    "thus @xmath114 is a set of @xmath115 binary trees , each with a leaf set @xmath116 of @xmath102 leaves , and with the prescribed branch lengths described ( see fig .",
    "[ fig1 ] ) .",
    ", scaledwidth=75.0% ]    let @xmath117 denote the tree metric induced on @xmath116 by the tree @xmath118 with its associated branch lengths , and let @xmath119 denote the corresponding distances under the random errors model ( so @xmath120 , for a vector @xmath121 of independent gaussians with mean 0 and variance @xmath25 ( and independent of @xmath122 ) ) .",
    "notice that we can partition any vector of distances @xmath2 on @xmath116 into two parts @xmath123 and @xmath124 , where @xmath123 compares leaves between different triplet - subtrees ( @xmath125 ` between ' ) and @xmath124 compares leaves within given triplet - subtrees ( @xmath126 ` within ' ) ; formally :    * @xmath123 is the sequence of @xmath2-values for all pairs @xmath127 where : @xmath128 * @xmath124 is the sequence of @xmath2-values for all pairs @xmath129 , where : @xmath130    it is useful to partition the ` within ' pairs further as follows . for each @xmath131 ,",
    "let @xmath132 and let @xmath133 .",
    "a fundamental observation at this point is that the probability distribution of @xmath119 on all pairs from @xmath134 and the pair in @xmath135 ( for each @xmath136 ) does not depend on @xmath122 at all . moreover , for pairs from @xmath137 , the dependence of @xmath119 on @xmath122 is only via @xmath138 . by this invariance and the independence assumption in the random errors model , for any @xmath2 and @xmath139",
    ", the probability density function for @xmath119 can be written in the following factored way : @xmath140 where , for @xmath141 , the terms in the third product are given by : @xmath142 in which : @xmath143    notice that from our fundamental observation above , the terms in the first two products appearing in ( [ likeq ] ) do not depend at all on @xmath122 .",
    "thus , for any @xmath2 , the maximum likelihood estimate of @xmath122 given @xmath2 is the sequence @xmath144 where , for each @xmath145 @xmath138 maximises the product @xmath146    for such a ml estimate @xmath122 , the following inequality must hold for all @xmath147 : @xmath148    assume now that @xmath149 .",
    "then if we let @xmath150 , application of ( [ feq0 ] ) in ( [ feq ] ) simplifies ( after some algebra ) to the more attractive equation : @xmath151    to this point , @xmath2 has been an arbitrary distance .",
    "now , let us further assume that @xmath2 is generated on @xmath152 under the random errors model ; in other words , @xmath153 for @xmath154 .",
    "we wish to calculate the probability  call it @xmath155  that mle will correctly estimate the generating tree @xmath152 . by ( [ feq ] ) and independence assumptions in the random errors model ,",
    "this probability @xmath155 satisfies : @xmath156 now , from ( [ elegant ] ) , @xmath157 and @xmath158 has a normal distribution with a mean of 2 and a variance of @xmath37 . thus : @xmath159 where @xmath160 is a standard normal random variable .",
    "substituting ( [ eq1 ] ) and ( [ helps ] ) into ( [ del ] ) gives : @xmath161 where @xmath162 applying this to eqn .",
    "( [ feq2 ] ) gives that the probability @xmath155 that mle correctly estimates the generating tree satisfies @xmath163 straightforward calculus now shows that as @xmath164 , the sequence @xmath165 ( and hence @xmath155 ) converges to 0 if @xmath99 .",
    "this shows that we can not recover @xmath152 with an accuracy bounded away from 0 as @xmath13 becomes large , by using mle , if @xmath166 in the definition of the stochastic safety radius ( since the interior edges all have length 1 , we have @xmath167 and so @xmath99 for @xmath166 )",
    ". moreover , by symmetry , the same conclusion applies to any of the @xmath115 trees @xmath118 ( there is nothing ` special ' about @xmath168 ) .",
    "we now invoke a classic result that mle is an estimation method that maximises the average reconstruction accuracy of a discrete parameter when a family of distributions depends on just that parameter ( _ c.f . _",
    "theorem 10.3.1 of @xcite or theorem 17.2 of @xcite )  in our case , the discrete parameter is the vector @xmath122 ( which determines the tree @xmath118 ) .",
    "it follows that for any distance - based reconstruction method , the limiting stochastic safety radius can not be larger than @xmath65 .",
    "we have seen in the previous section that the limiting stochastic safety radius ( lssr ) of any algorithm is at most 1 ( theorem [ mainthm ] ) , and that a simple quartet algorithm @xcite has a lssr value at least @xmath169 ( proposition [ pro1 ] ) .",
    "the gap is relatively small between these two bounds and we expect that more sophisticated algorithms have lssr values that are substantially higher than @xmath91 . in this section",
    ", we turn to simulations to study the accuracy of mainstream distance - based methods under the random errors model , with realistic numbers of taxa ( previous results are asymptotic ) .",
    "our goal is to compare these methods and to check how close they come in practice to the 1 bound prescribed by theorem [ mainthm ] .",
    "notice that this theorem was established using the pronged trees of figure 1 .",
    "these trees are expected to be difficult for two reasons : ( 1 ) all internal branches have the same length and thus no branch is easy ; ( 2 ) a large number ( @xmath170 ) of taxon pairs are separated by a single internal branch and are likely to be wrongly exchanged , when trying to infer these trees from noisy data .",
    "not all tree shapes possess this property ; for example , in a perfectly balanced tree , all non - cherry taxon pairs are separated by at least _ two _ internal edges .",
    "thus , we also compare , using simulations , different tree shapes , to establish if some of them are ( stochastically ) ` harder ' than the others to reconstruct ( depending , perhaps , on the inference method ) , or whether the opposite is true and all tree shapes seem to be equally difficult .    in the following ,",
    "we first describe the methods being compared and the comparison criteria , we then study their performance with pronged and other ( e.g. perfectly balanced ) extreme trees , and , lastly , we use randomly generated tree shapes to obtain average accuracy measures under the random errors model .",
    "we ran four standard algorithms using fastme implementation ( http://www.atgc-montpellier.fr/fastme/ ) :    1 .",
    "gme+ols ( greedy minimum evolution with ordinary least squares ) @xcite is a greedy algorithm that iteratively adds taxa on a growing tree , minimizing at each step the ordinary least squares ( ols ) tree length estimate , in accordance with the ols version of the minimum evolution principle @xcite .",
    "the performance of this algorithm was analysed by @xcite , who showed that its @xmath11 safety radius tends to 0 with increasing @xmath13 .",
    "2 .   unj ( unweighted nj ) @xcite , which is the unweighted ( ols ) version of nj , with an @xmath11 safety radius of @xmath17 @xcite .",
    "gme+bme @xcite which uses the same iterative taxon addition scheme as gme+ols , but optimizes the balanced version of minimum evolution ( bme , @xcite ) and has an optimal @xmath11 safety radius of @xmath17 @xcite .",
    "nj @xcite with @xmath11 safety radius of @xmath17 @xcite .",
    "we showed @xcite that nj greedily minimises bme at each agglomeration step ( and not the ols version of minimum evolution , as was originally suggested ) .",
    "the aim was to see if there is any difference between the algorithmic schemes ( taxon addition versus cherry agglomeration ) , and between the criteria being optimised ( bme vs ols minimum evolution ) . because of the ols - type noise in the random errors model",
    ", better accuracy is expected for ols - based algorithms ( unj and gme+ols ) . on the other hand",
    ", the @xmath11 safety radius differs widely among these algorithms and converges to 0 for gme+ols ; thus the second aim was to check whether atteson s predictions are observed in practice .",
    "in addition , we implemented the quartet method of @xcite using the first algorithm described by @xcite with @xmath171 time complexity and @xmath172 quartet queries .",
    "the usual four - point rule @xcite @xcite was used to answer the quartet queries .",
    "our aim was to compare the accuracy of this simple algorithm , mostly used for theoretical purposes , to that of algorithms being widely used in phylogenetics , and to check how this algorithm behaves regarding our @xmath91 bound of proposition  [ pro1 ] .",
    "two criteria were used to compare algorithm accuracy : ( 1 ) the probability @xmath173 of recovering the entire topology of the simulated tree ; ( 2 ) the normalized bipartition distance ( robinson - foulds ( rf ) @xcite ) between the inferred and simulated trees , which is equal to 0 when both trees define the same bipartitions , and to 1 when they do not share any bipartition in common .",
    "we used pronged trees ( fig .",
    "[ fig1 ] , used in the proof of theorem  [ mainthm ] ) with a number of taxa @xmath174 and @xmath175 .",
    "we also used : caterpillar trees with @xmath176 and @xmath177 ; perfectly balanced trees with @xmath178 and @xmath179 ; and  balanced+pronged \" trees , where each leaf of a perfectly balanced tree is replaced by the same three - taxon tree as in the pronged trees , with @xmath180 and 288 .",
    "caterpillar and perfectly balanced tree shapes are extreme regarding a number of measurements ( e.g. diameter , number of cherries , etc . ) , and the pronged 3-taxon tree is assumed to make tree inference difficult ( see above ) . in all of these trees , all internal branches had an equal length of 1 , which ( again ) makes tree inference difficult .",
    "the length of the external branches was 1 for the caterpillar and balanced trees , and as shown in fig .",
    "[ fig1 ] for the pronged trees .",
    "the pairwise distances were computed and perturbed by an independent and identically distributed normal noise with standard deviation equal to @xmath181 , i.e. the highest possible noise level regarding theorem  [ mainthm ] , beyond which no algorithm can accurately recover every tree correctly as @xmath13 grows .",
    "the goal was to check if , in these especially difficult conditions , the standard algorithms ( e.g. nj ) still show some ability to recover the correct tree .",
    "in these conditions , the quartet method had very poor results that are not shown ( but see below ) .",
    "for each of the tree shapes and @xmath13 values , 500 data - sets were generated to obtain average error estimates .",
    "the results are summarised in table  1 .",
    "we see the following :    [ tab:1 ]    * * pronged trees * are indeed difficult to reconstruct accurately , compared to perfectly balanced trees",
    ". however , for all algorithms , the probability of recovery ( @xmath173 ) increases with @xmath13 . according to this result",
    ", the four tested algorithms could have lssr equal to 1",
    ". however , the algorithms are not equivalent in their performance .",
    "we see a clear advantage of the agglomerative scheme ( nj and unj ) over taxon addition ( gme+ols and gme+bme ) , a finding that has already been observed in other simulation studies ( e.g. @xcite ) . on the other hand",
    ", there is no significant difference ( considering both @xmath173 and rf ) between the algorithms that minimise the ols version of minimum evolution ( gme+ols and unj ) and their bme counterparts ( gme+bme and nj , respectively ) .",
    "notably , we do not see any sign of weakness of gme+ols , as predicted by its limiting @xmath11 safety radius of zero @xcite . * * caterpillar trees * give another view .",
    "again we observe the clear advantage of the agglomeration scheme that obtains nearly perfect results ( @xmath182 ) , especially with unj , which is substantially better than nj regarding both @xmath173 and rf criteria .",
    "this latter finding is expected with such unbalanced trees , where the matrix reduction step is better achieved by unj , which accounts for the number of taxa in both agglomerated subtrees , while nj uses equal weights of @xmath17 .",
    "based on these results , nj and unj seem again to have lssr of ( close to ) 1 .",
    "gme - ols has a lower @xmath173 value , but this increases with @xmath13 . in the opposite , gme - bme not only has low @xmath173 ( @xmath183 ) , but this decreases with @xmath13 .",
    "we have no clear explanation for this poor performance but , based on this result , it is unlikely that gme+bme has lssr equal to 1 .",
    "* * perfectly balanced trees * confirm again the superiority of the agglomeration scheme , compared to taxon addition .",
    "nj and unj are nearly the same , as expected with well - balanced trees ( see above ) .",
    "however , although these trees are relatively easy for all algorithms ( @xmath184 ) , we do not see any improvement with larger @xmath13 values .",
    "this questions our previous assumption that lssr could be equal to 1 for the algorithms tested , unless the convergence towards lssr is slow .",
    "* * balanced+pronged trees * are more difficult than balanced trees , as expected",
    ". however , for all algorithms , the accuracy increases with @xmath13 .",
    "algorithm comparisons are consistent with the previous ones : the agglomeration scheme performs better than taxon addition ; there is little difference between the ols and bme versions of algorithms , especially regarding nj versus unj , which are nearly equivalent with such well - balanced trees .",
    "to summarise , nj and unj have remarkably high accuracy with these difficult trees and conditions .",
    "these results suggest that these two methods might have an lssr equal to the optimal value of 1 .",
    "note , however , that the performance of nj and unj with perfectly balanced trees lags a little behind , as their accuracy does not seem to improve when @xmath13 increases ; although , this may be because the convergence is slow .",
    "the taxon addition scheme is clearly less accurate and the results of gme - bme with caterpillar trees seem to indicate that this algorithm does not have an optimal lssr of 1 .",
    "even though these conclusions are somewhat speculative , as @xmath13 remained relatively moderate in all of our experiments , these results provide directions for future investigations on the lssr of mainstream methods .      up to this point , our experiments have used a limited number of extreme tree shapes . in this subsection ,",
    "we use random trees in the search for other potentially difficult cases and to estimate the average accuracy of tested algorithms under the random errors model .",
    "tree shapes were generated uniformly at random ( the so - called ` proportional - to - distinguishable - arrangements ( pda ) model ' ) and all branch lengths were set to 1 .",
    "the number of taxa was @xmath185 and @xmath175 .",
    "the pairwise distances were perturbed by an i.i.d .",
    "normal noise with standard deviation equal to @xmath181 , as in previous experiments .",
    "again , these noise level and trees ( with equal branch lengths ) make tree inference difficult .",
    "[ tab:2 ]    the average results over 500 data - sets are displayed in table 2 .",
    "nj and unj results are quite consistent with those obtained with extreme tree shapes ( _ cf _ table 1 ) . with moderate values of @xmath13 ,",
    "unj is slightly more accurate than nj , as expected with the ols - type noise used in these simulations .",
    "with large values of @xmath13 , unj and nj are nearly perfect ( @xmath182 ) , and both algorithms become strictly equivalent . again",
    ", the results seem to indicate that both unj and nj could have an optimal lssr of 1 .",
    "we can not exclude that particularly difficult trees do exist , but these must be rare , and in average nj and unj appear to be highly accurate at a noise level that is four times larger than the limit for atteson s approach to apply .    with taxon addition , the picture is different .",
    "gme+ols has low accuracy that drops when @xmath13 increases , a finding which may be seen as consistent with the predictions from @xcite using the @xmath11 safety radius .",
    "gme+bme performs better but its accuracy is not that high and seems to stabilise around 0.8 when @xmath13 increases .",
    "this observation is probably explained by the fact that some trees ( e.g. caterpillars , table 1 ) are difficult for this algorithm . in both cases ,",
    "the results in table 2 seem to indicate that neither gme+bme nor gme+ols has an optimal lssr of 1 .",
    "we also ran simulations where the noise level varied around the limiting value used in previous experiments ( @xmath186 ) , in order to study the sharpness of our bounds with realistic numbers of taxa .",
    "our goal was to check whether the accuracy improves substantially for taxon addition when @xmath87 is less than 1 , and whether the agglomeration algorithms ( nj and unj ) still show some ability to recover the correct tree when @xmath87 is larger than 1 .",
    "we also studied the performance of the quartet method with ( relatively ) low @xmath87 values .",
    "we used the same random trees ( with all branch lengths equal to @xmath187 ) , as in the previous subsection , but used @xmath188 and @xmath189 instead of @xmath190 .",
    "[ tab:3 ]    the average results over 500 data sets are displayed in table 3 for the standard algorithms .",
    "we see that our previous conclusions are confirmed when @xmath87 differs from 1 : the agglomeration scheme performs better than taxon addition ; there is little difference between both minimum evolution versions ; however , unj is slightly better than nj ( e.g. see @xmath191 , with both @xmath173 and rf ) .",
    "we also see that the 1 bound prescribed by theorem 1 is rather sharp with moderate number of taxa : with @xmath192 , both taxon addition algorithms have high accuracy for all @xmath13 values , and nj and unj are nearly perfect .",
    "conversely , with @xmath191 , the accuracy of all algorithms drops dramatically , especially that of the taxon addition scheme where @xmath173 approaches 0 with @xmath193 .",
    "this confirms that the limiting optimal bound of theorem  [ mainthm ] , obtained with special (  pronged \" ) trees , is robust and found again , at least qualitatively , with random trees and realistic @xmath13 values .",
    "[ tab:4 ]    table 4 displays the results of the quartet method for @xmath194 and @xmath195 ( the results with @xmath190 are quite poor and are not shown ) .",
    "again , the stochastic radius framework and our bounds of proposition  [ pro1 ] ( lssr @xmath196 ) and theorem  [ mainthm ] ( lssr @xmath197 ) have a good predictive accuracy . with @xmath194 ,",
    "the accuracy is high and increases with @xmath13 , while we observe the opposite with @xmath192 , which seems to indicate that the quartet method has a lssr close to our @xmath198 bound .",
    "note , however , that when @xmath87 approaches @xmath91 from below ( e.g. @xmath199 or @xmath200 ) , the accuracy is not that high and does not increase with the moderate values of @xmath13 used in these simulations .",
    "this is most likely explained by the very slow convergence of the bound in equation ( [ ceq ] ) , combined with asymptotic equivalence ( [ helps ] ) , when @xmath87 is close to @xmath91 .",
    "our simulation results show that the stochastic radius framework introduced in this paper has a good predictive capacity and seems to be robust .",
    "the optimal bound ( @xmath201 ) of theorem  [ mainthm ] , which was obtained with special  pronged \" trees , seems to apply to a large variety of trees ( no tree is easy or else these are quite rare ) .",
    "moreover , when the noise level decreases below @xmath201 , the accuracy rises for all algorithms and all values of @xmath13 .",
    "the behaviour of the quartet method ( with moderate @xmath13 values ) is also consistent with the ( limiting ) prediction of proposition 3 .",
    "we thus believe that the lssr approach will show a high capacity in predicting algorithm performance in realistic conditions , a property which does not hold in several cases with the @xmath11 safety radius , as noted in the introduction .",
    "an important outcome of the simulations is that the ability to recover single branches may still be high , even when the probability of recovering the entire tree drops due to high noise level ; for example , with @xmath202 and @xmath203 , the probability that any given branch is correct is higher than @xmath204 for all standard algorithms ( table 3 , rf values ) .",
    "this strongly suggests the development of stochastic ` edge radius ' approaches ( analogous to the classical non - stochastic concept considered also by atteson @xcite ) which would account for the length of the branch being considered , and thus will not use the worst - case approach used here in several places , where all branches have the same length .",
    "in other words , the tree @xmath3 may have some very short edges , however , provided a given edge is not too short , then we may be able to recover the corresponding split with high accuracy , even if the entire tree can not be reconstructed .",
    "finer algorithm analyses should follow from such a framework .",
    "our study also suggests two further theoretical questions that would be worth investigating in future .",
    "firstly , it would be of interest to analytically calculate the precise limiting stochastic safety radius of nj and other standard methods ; in particular , to determine if it takes the value 1 or some number less than this .    it would also be of interest to study the stochastic safety radius of distance - based tree reconstruction methods for the more general class of models in which the @xmath24 values have a multivariate normal distribution , with means of @xmath18 and a covariance matrix @xmath205 ( the ols model we considered in this paper assumes that @xmath205 is the diagonal matrix with each diagonal entry equal to @xmath25 ) .",
    "in such models , the variance of @xmath24 would typically increase with the path length between leaves @xmath33 and @xmath206 in the tree ( the weighted least squares ( wls ) assumption @xcite ) , while the covariance for two pairs of taxa would typically increase with the total length of the shared branches that are present in both paths connecting each pair ( the generalized least - squares ( gls ) assumption @xcite ) .",
    "ms thanks the allan wilson centre and the nz marsden fund for supporting this work .",
    "atteson , k. : the performance of neighbor - joining methods of phylogeny reconstruction .",
    "algorithmica 25(23 ) : 251278 ( 1999 )    berry , v. and gascuel , o. : inferring evolutionary trees with strong combinatorial evidence .",
    "240(2 ) : 271298 ( 1997 )    bordewich , m. and mihaescu , r. : accuracy guarantees for phylogeny reconstruction algorithms based on balanced minimum evolution . in moulton , v. and singh , m. ( eds ) proceedings of wabi 2010 , 10th international workshop on algorithms in bioinformatics , volume 6293 of lnbi , pp 250261 .",
    "springer - verlag ( 2010 )    bulmer , m. : use of the method of generalized least - squares in reconstructing phylogenies from sequence data .",
    "evol . 8 : 868883 ( 1991 )    casella , g. and berger , r. l. : statistical inference .",
    "duxbury press , belmont , ca ( 1990 )    cavalli - sforza , l.l . , and edwards , a.w.f . :",
    "phylogenetic analysis : models and estimation procedures .",
    "19 : 223257 ( 1967 )    desper r. , gascuel o. : fast and accurate phylogeny reconstruction algorithms based on the minimum - evolution principle .",
    "j. comput .",
    "biol . 9 : 687706 ( 2002 )    eickmeyer , k. huggins , p. , pachter , l. and yoshida , r. : on the optimality of the neighbor - joining algorithm .",
    "algorithms molec .",
    "biol . 3:5 ( 2008 )",
    "fitch , w.m . , and margoliash , e. : construction of phylogenetic trees .",
    "science 155:279284 ( 1967 )    gascuel o. , concerning the nj algorithm and its unweighted version , unj .",
    "_ in _ mathematical hierarchies and biology , b. mirkin , f.r .",
    "mcmorris , f.s .",
    "roberts and a. rzhetsky ( eds . ) , american mathematical society , providence , 149170 ( 1997 )    gascuel , o. and mckenzie , a. : performance analysis of hierarchical clustering algorithms .",
    "j. classif .",
    "21 : 318 ( 2004 )    gascuel , o. and steel , m. : neighbor - joining revealed .",
    "23(11 ) : 19972000 ( 2006 )    guiasu , s. : information theory with applications . mcgraw - hill , new york ( 1977 )    kannan s.k .",
    ", lawler e.l . , warnow t.j . : determining the evolutionary tree using experiments",
    ". j. algorithms 21:2650 ( 1996 )    mihaescu , r. , levy , d. and pachter , l. : why neighbor - joining works .",
    "algorithmica , 54(1 ) : 124 ( 2009 )    pardi , f. , guillemot , s. and gascuel , o. : robustness of phylogenetic inference based on minimum evolution .",
    "72 , 18201839 ( 2010 )    pearl , j. and tarsi , m. : structuring causal trees .",
    "j. complexity , 2 , 6077 ( 1986 )    pauplin y. : direct calculation of a tree length using a distance matrix , j. molec .",
    "evol . 51:4147 ( 2000 )    robinson d. r. , foulds l. r. : comparison of phylogenetic trees , math .",
    "biosci . 53:131147 ( 1981 )",
    "rzhetsky a. , nei m. : theoretical foundation of the minimum - evolution method of phylogenetic inference .",
    "biol . evol .",
    "10:10731095 , ( 1993 )    saitou , n. , nei , m. : the neighbor - joining method : a new method for reconstructing phylogenetic trees .",
    "biol . evol .",
    "4:406425 ( 1987 )    sattath , s. , and tversky , a. : additive similarity trees , psychometrika , 42 : 319345 ( 1997 )    zarestkii k. : reconstructing a tree from the distances between its leaves ( in russian ) .",
    "uspehi mathematicheskikh nauk 20:9092 ( 1965 )",
    "substituting @xmath207 in @xmath208 gives : @xmath209 where the second inequality is from @xmath210 for all @xmath211 .",
    "since the last term on the right is @xmath17 , we get the inequality in ( [ helps ] ) . turning to the asymptotic relationship , consider : @xmath212 since the numerator and denominator limits are both zero , we can apply lhpital s rule . straightforward calculus ( using the fundamental theorem of calculus for the numerator )",
    "establishes that the limit in ( [ limeq ] ) equals 1 ."
  ],
  "abstract_text": [
    "<S> a variety of algorithms have been proposed for reconstructing trees that show the evolutionary relationships between species by comparing differences in genetic data across present - day taxa . if the leaf - to - leaf distances in a tree can be accurately estimated , then it is possible to reconstruct this tree from these estimated distances , using polynomial - time methods such as the popular ` neighbor - joining ' algorithm . </S>",
    "<S> there is a precise combinatorial condition under which distance - based methods are guaranteed to return a correct tree ( in full or in part ) based on the requirement that the input distances all lie within some ` safety radius ' of the true distances . here </S>",
    "<S> , we explore a stochastic analogue of this condition , and mathematically establish upper and lower bounds on this ` stochastic safety radius ' for distance - based tree reconstruction methods . </S>",
    "<S> using simulations , we show how this notion provides a new way to compare the performance of distance - based tree reconstruction methods . </S>",
    "<S> this may help explain why neighbor - joining performs so well , as its stochastic safety radius appears close to optimal ( while its more classical safety radius is the same as many other less accurate methods ) .    </S>",
    "<S> example.eps gsave newpath 20 20 moveto 20 220 lineto 220 220 lineto 220 20 lineto closepath 2 setlinewidth gsave .4 setgray fill grestore stroke grestore </S>"
  ]
}