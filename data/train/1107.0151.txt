{
  "article_text": [
    "fundamental and crucial to high order strong simulation of stochastic differential equations driven by a multi - dimensional wiener process , is the need to accurately and efficiently simulate the lvy chordal areas when the diffusion vector fields do not commute .",
    "thusfar this has represented a substantial technical difficulty . in the leading implemented methods , for example lvy s normal expansion with a suitable normal approximation of the tail sum",
    ", the number of random variables required to accurately simulate the lvy chordal area in the milstein method , scales like the inverse square - root of the stepsize ( wiktorsson 2001 ) .",
    "here we introduce three new simulation methods for the lvy area based on a new expansion in terms of logistic random variables . beyond a given accuracy threshold ,",
    "all three new simulation methods deliver highly accurate lvy area samples with orders of magnitude less computational effort .",
    "indeed for two of the methods , the accuracy achievable scales logarithmically with the computational effort .",
    "consider the problem of strongly simulating a stochastic differential equations driven by two independent wiener processes @xmath0 and @xmath1 .",
    "assume that the corresponding diffusion vector fields do not commute .",
    "to implement an order one milstein method we must , on each computational timestep of size @xmath2 , generate two independent @xmath3 sample wiener increments , @xmath4 and @xmath5 , and also a sample of the lvy area defined by @xmath6 by stokes theorem this is the area enclosed by the two - dimensional wiener path and the chord joining the endpoints of the path at @xmath7 and @xmath8 ; see figure  [ fig : levyarea ] .",
    "in his seminal 1951 paper , lvy introduced an equivalent definition of the chordal area as follows . using the fourier series representation for the brownian bridges based on",
    "the wiener processes @xmath0 and @xmath1 given @xmath4 and @xmath5 , lvy showed that the chordal area has the series expansion @xmath9 where @xmath10 are independent standard normal random variables .",
    "more generally orthogonal eigenfunction series expansions for wiener processes are referred to as karhunen ",
    "love decompositions after independent work by karhunen ( 1947 ) and love ( 1945 ) . in the same 1951 paper ,",
    "lvy proved that the _ characteristic function _",
    "@xmath11 corresponding to the probability density function @xmath12 for the lvy area @xmath13 , given @xmath4 and @xmath5 , is @xmath14 where @xmath15 .",
    "kloeden , platen & wright ( 1992 ) suggested truncating the lvy s series expansion above to include @xmath16 terms , and using that to generate approximate samples .",
    "the mean - square error associated such a truncation scales like @xmath17 . however in an important advance , wiktorsson ( 2001 ) proposed simulating the tail sum by a matched normal random variable @xmath18 where @xmath19 . with this correction ,",
    "the mean - square error scales like @xmath20 .",
    "in fact wiktorsson achieves much more than this , deriving an effective sampling method for the lvy areas involved in a milstein approximation of a stochastic differential equation driven by any high - dimensional wiener process ; see gilsing & shardlow ( 2007 ) for a practical implementation . in this paper",
    "we will restrict ourselves to a two - dimensional wiener process .",
    "we measure the effectiveness of any such simulation methods as follows . to successfully implement the milstein method",
    ", we must ensure that the mean - square local truncation error is of order @xmath21 .",
    "hence over each computational timestep , if we used wiktorsson s method above , we would need to take @xmath22 .",
    "we will measure the computational effort associated with such an approximation , by the number of uniform random variables @xmath23 that are required to generate such a lvy area sample .",
    "we will call this the _ complexity _ of the simulation method ; also see rydn & wiktorsson ( 2001 ) .",
    "roughly , for wiktorsson s method , the number of uniform samples we require scales like @xmath16 .",
    "note , we ignore : ( 1 ) the negligible effort associated with converting the uniform samples to standard normal samples ; ( 2 ) constant multiplicative factors ( there are four standard normal samples required at each order ) and ( 3 ) the negligible effort associated with sampling the tail . hence for wiktorsson",
    "s method , the complexity required to achieve accuracy of order @xmath21 is @xmath24 .",
    "the smaller the complexity , the more effective is the simulation method .",
    "gaines & lyons ( 1994 ) proposed marsaglia s rectangle - wedge - tail method for generating lvy area samples",
    ". however , wiktorsson ( 2001 ) observes that `` this method is complicated to implement , however , and occasionally requires numerical inversion of the characteristic function '' .",
    "gaines & lyons followed this in 1997 with an approximate simulation method based on replacing the lvy area by its conditional expectation on intervening brownian path information ( also see lord , malham & wiese 2008 and malham & wiese 2008 ) .",
    "the complexity of this latter method is @xmath25 .",
    "rydn & wiktorsson ( 2001 ) developed a method based on an expansion for the lvy area in laplace random variables . observing that the characteristic function @xmath26 is the product of the characteristic function of a logistic random variable and a poisson mix of laplace random variables , they derived the representation @xmath27 where @xmath28 , and for each @xmath29 we have : @xmath30 and for @xmath31 , @xmath32 ; all independent .",
    "note that the expectation of @xmath33 is @xmath34 , independent of @xmath35 . in a practical simulation",
    "we would truncate this series to include all the terms for @xmath36 and simulate the tail sum by the normal random variable @xmath37 where @xmath19 .",
    "this simulation method has complexity @xmath24 .",
    "some related recent papers of interest are as follows . in a promising paper stump & hill ( 2005 )",
    "derived a series expansion for the lvy area density function @xmath12 based on analytically computing the inverse fourier transform of the characteristic function @xmath26 .",
    "the terms in the resulting series expansion decay like @xmath38 with @xmath35 as the summation index ( see page  407 in stump & hill ) .",
    "however they only provide comparisons of the distribution functions and do not implement a sampling method .",
    "levin & wildon ( 2008 ) have developed methods for generating moments of the lvy area utilizing combinatorial shuffle product structures . also , assuming hrmander s ellipticity condition , cruzeiro , malliavin & thalmaier ( 2004 )",
    "have shown how to orthogonally evolve the frame bundle associated with the underlying system to avoid computing the lvy area entirely .",
    "let us now summarize the ideas underlying the simulation methods we propose .",
    "our starting point is rydn & wiktorsson s expansion for the characteristic function @xmath26 of the lvy area .",
    "as already noted , the first factor in the representation for @xmath26 above , is the characteristic function associated with a logistic random variable .",
    "we thus focus on the second factor , and for the moment , the expression in the exponent .",
    "using an elementary hyperbolic function identity which permits indefinite iteration , we derive an infinite series expansion for the exponent with terms of the form @xmath39 where @xmath40 is the summation index . applying the exponential function to this series for",
    "the exponent generates an infinite product of exponentials of such terms .",
    "now we first observe that characteristic functions of exponential form correspond to a poisson mix of random variables whose characteristic function is the exponent . then second we observe that the exponents ( the individual terms from the series ) are characteristic functions corresponding to scaled logistic random variables .",
    "hence we can represent the lvy area , given @xmath4 and @xmath5 , as the following series of logistic random variables ( see theorem  [ th : logisticexpansion ] below ) : @xmath41 where for @xmath42 , the @xmath43 are independent poisson random variables , and for @xmath42 and @xmath44 , @xmath45 are independent identically distributed standard logistic random variables ( mean zero , variance @xmath46 ) .     versus the cpu time required to compute the simulation with @xmath47 independent samples .",
    "here we fixed @xmath48 , so with random wiener increments @xmath4 and @xmath4 for each sample , we set @xmath49.,width=415,height=302 ]    this representation is the basis of the three simulation methods we propose .",
    "the first simulation method is a simple truncation of this series representation together with a tail approximation .",
    "note that at each order @xmath40 , we must on average generate an increasing number , namely @xmath50 uniform random variables .",
    "this means that the complexity of this method is @xmath25 without , and @xmath24 with , the tail approximation .",
    "hence , in principle this does not represent an improvement in complexity over the lvy or rydn  wiktorsson methods , though in practice the computational effort required to achieve a given accuracy is far superior to the rydn  wiktorsson method , and beyond a high accuracy threshold , also superior to the lvy method .",
    "see figure  [ fig : difference ] where we provide an explicit accuracy versus computational effort comparison .",
    "the second method we propose , the _",
    "normal approximation _ , recognises that at each order we must sum an increasing number of logistic random variables . invoking the central limit theorem , we replace sums of logistic random variables over a threshold number by the appropriate normal approximation .",
    "this of course has a dramatic effect on the computational effort required , without in practice seemingly compromising the accuracy of the simulation method  see figure  [ fig : difference ] .",
    "the third method we propose , the _ exponential product approximation _",
    ", recognises that a sum of @xmath51 independent identically distributed standard logistic random variables can be represented by the difference of the logarithms of products of @xmath51 independent standard exponential random variables .",
    "we derive an explicit asymptotic form for the density function for large @xmath51 for the logarithm of the product of @xmath51 exponential random variables , using the method of steepest descents .",
    "we utilize this explicit form to tabulate the inverse distribution function for @xmath52 , @xmath53 , @xmath54 and @xmath55 . combining samples from these tabulated inverse",
    "distribution functions with small sums ( @xmath56 ) of logistic random variables generates the highly effective exponential product approximation shown in figure  [ fig : difference ] .",
    "our paper is structured as follows .",
    "we derive our logistic expansion for the characteristic function for the lvy area in  2 and provide an algorithm for its implementation including a tail approximation .",
    "then in  3 and  4 we respectively derive the normal and exponential product approximations based on the logistic expansion . in both sections",
    "we discuss the complexity of these two methods .",
    "lastly in  5 we provide further simulation details and conclude .",
    "we propose a different expansion to that considered by rydn and wiktorsson ( 2001 ) producing a series representation for @xmath13 with quite different properties .",
    "[ th : logisticexpansion ] the lvy area @xmath13 conditioned on the given wiener increments @xmath4 and @xmath5 is equivalent in distribution to the following series of logistic random variables : @xmath41 where for @xmath42 , the @xmath43 are independent poisson random variables , and for @xmath42 and @xmath44 , @xmath45 are independent identically distributed logistic random variables . any @xmath28 is efficiently simulated by @xmath57 where @xmath58)$ ] .",
    "we begin by observing the following elementary identity for hyperbolic functions , @xmath59 .",
    "iterated @xmath16 times , this generates the identity @xmath60 hence we see that @xmath61 where we set @xmath62 note that @xmath63 as @xmath64 , for all @xmath65 .",
    "we have thus established that for all @xmath66 , setting @xmath67 , we have @xmath68 where @xmath43 and @xmath69 denotes expectation . now note that the expression @xmath70 is the characteristic function corresponding to the random variable @xmath71 .",
    "the result now follows by interpreting the product of two characteristic functions as the sum of two corresponding independent random variables .",
    "hence our proposed simulation method for the lvy area is as follows .",
    "truncate the logistic expansion in theorem  [ th : logisticexpansion ] to include the terms @xmath72 .",
    "hence consider the approximation @xmath73 to the conditioned lvy area @xmath13 given by @xmath74 where for @xmath72 : the @xmath43 are independent poisson random variables , for @xmath44 , @xmath75 and @xmath76 with @xmath77)$ ] independent identically distributed uniform random variables , and @xmath19 is a standard normal random variable .",
    "we now consider how to simulate the tail sum .",
    "[ th : logisticexpansionerror ] the mean - square error of the logistic expansion approximation @xmath73 is exactly given by @xmath78 if we supplement @xmath73 by including the term @xmath79 to simulate the tail sum , where @xmath19 , then the mean - square error in the logistic expansion approximation with tail simulation is @xmath80    we directly compute @xmath81 in order to obtain the error bound for the normal tail sum approximation , we note first that the tail sum has class g distribution . recall that an infinitely divisible random variable has class g distribution , if its characteristic function has the form @xmath82 , where @xmath83 , and @xmath84 for all @xmath40 , see rydn & wiktorsson ( page  163 ) . using that @xmath85 where @xmath86 , and where @xmath87 has a poisson distribution with parameter @xmath88 and where @xmath89 , it follows that the tail sum @xmath90 has the characteristic function ( see lvy 1951 ) @xmath91 hence @xmath90 has class g distribution  see also proposition  5 in rydn & wiktorsson ( 2001 ) .",
    "we can now proceed as in the proof of theorem  7 in rydn & wiktorsson .",
    "the tail sum can be represented as a product of a standard normal random variable @xmath92 and the square root of an independent positive , infinitely divisible variable @xmath93 , i.e. @xmath94 . if @xmath95 denotes the variance of @xmath90 , then the mean - square error when including the normal tail approximation is given by @xmath96 let @xmath97 denote the laplace transform of @xmath93 .",
    "then @xmath98 , and the variance of @xmath93 is given by @xmath99 .",
    "if @xmath100 then we see that @xmath101 thus we see that @xmath102 giving the required result .",
    "note that our expression for the mean - square error of our logistic approximation @xmath73 is _",
    "exact_. our proposed logistic approximation to @xmath13 , including simulation of the tail sum is thus @xmath103 , where @xmath19 . at each order @xmath40 in the logistic approximation we must on average sample @xmath104 uniform random variables .",
    "hence the complexity of the logistic approximation @xmath73 is @xmath25 , while with tail simulation it is @xmath24 .",
    "we have seen that when we measure the complexity of a simulation method in terms of the number of uniform random variables required to achieve a given accuracy , the logistic , laplace ( rydn  wiktorsson ) and lvy expansion simulation methods scale in the same way . here",
    "we attempt to exploit the form of the logistic expansion simulation method to significantly improve its complexity competitiveness .",
    "for each @xmath105 in the logistic expansion we must generate and accumulate @xmath106 uniform independent identically distributed random variables where @xmath106 is a poisson random variable with mean @xmath107 .",
    "thus on average the number of uniform random variables we must generate and accumulate grows exponentially with @xmath40 .",
    "one possibility to achieve enormous reductions in computational effort for large @xmath40 , is to proceed as follows .",
    "suppose we generate @xmath106 and realize @xmath108 for a predetermined @xmath109 to be defined presently .",
    "then in this case we approximate the logistic random variable accumulant by a suitable normal random variable .",
    "more precisely , for each @xmath110 for which @xmath108 we approximate @xmath111 where the @xmath112 are independent standard normal random variables . using the berry  esseen theorem we can derive a uniform estimate of the error in the distribution function due to this replacement .    [",
    "th : normalapprox ] let @xmath113 denote the random variable for some given @xmath114 : @xmath115 and let @xmath116 denote its distribution function .",
    "let @xmath117 denote the distribution function of @xmath73 .",
    "then there exists a constant @xmath118 such that for all @xmath119 , @xmath120    the assertion will follow from the berry  esseen theorem .",
    "indeed , let @xmath121 denote the distribution function of @xmath122 and @xmath123 its probability density function , and let @xmath124 denote the distribution function of @xmath125 and @xmath126 its probability density function .",
    "thus the distribution functions @xmath116 and @xmath117 are given as follows ( here ` @xmath127 ' denotes the usual convolution between probability density functions corresponding to the sum of two random variables ) : @xmath128 where @xmath129 denotes the probability density function of the standard logistic random variable @xmath130 . the distribution function @xmath121 is given by @xmath131 and the distribution function @xmath124 by @xmath132 by applying the central limit theorem and the berry - esseen theorem to the sum of logistic random variables @xmath133 on the right , we know that there exists a constant @xmath118 , independent of @xmath40 , such that for all @xmath134 and for all @xmath135 @xmath136 since @xmath137 is given by @xmath138 it follows that @xmath139 where we have used the following inequality for the convolution product @xmath140 for any probability density functions @xmath141 and @xmath97 , where @xmath142 .",
    "the logistic normal approximation simulation method we propose is the random variable @xmath143 defined in theorem  [ th : normalapprox ] . we can further augment this method by also simulating the tail , i.e. by simulating @xmath144 , where @xmath19 .",
    "theorem  [ th : normalapprox ] demonstrates that the error in the distribution function corresponding to @xmath13 as a result of making the normal replacement @xmath143 , has an upper bound that scales like @xmath145 . in practice ,",
    "as we see from our simulations in figure  [ fig : difference ] , this upper bound is somewhat pessimistic . on the other hand , if we were to be overly optimistic and supposed that this normal replacement ( of the large sum of logistic random variables ) did not impact the accuracy of the simulation , then we would conclude that above a certain computational effort threshold , the complexity of the logistic normal approximation simulation method would be @xmath146we only need one uniform random variable for each normal sample and the terms at each order scale like @xmath147 .",
    "in reality the complexity lies somewhere between @xmath25 ( or @xmath24 when we include the tail approximation ) and @xmath146 .",
    "a logistic random variable can be decomposed as the difference of the logarithms of two independent exponential random variables .",
    "we exploit this result to derive a highly effective sampling method for a large sum of logistic random variables .",
    "indeed , the sum of @xmath51 independent standard logistic random variables can be represented by @xmath148 hence we are left with the question of whether we can efficiently sample from the probability density function associated with the logarithm of the product of @xmath51 standard exponential random variables ( with unit means ) .",
    "in fact the density function for the logarithm of a product of @xmath51 exponential random variables can be computed via the the inverse mellin transform as follows ( see for example nadarajah 2009 ; p.  654 ) .",
    "we briefly recall some basic results on products of random variables and the mellin transform . if two random variables @xmath130 and @xmath149 have densities @xmath129 and @xmath150 , respectively , then their product @xmath151 has density given by the _ product convolution _ @xmath152 the mellin transform of a function has many properties analogous to that for the fourier and laplace transforms  see flajolet , gourdon and dumas ( 1995 ) for more details .",
    "importantly the mellin transform of the product convolution of two functions is given by the real product of their mellin transforms .",
    "hence since the density of the product of @xmath51 exponential random variables is the @xmath51-fold product convolution of the corresponding densities , its mellin transform is the @xmath51-fold real product of the mellin transform of the standard exponential random variable density which is the gamma function .",
    "the probability density function @xmath153 corresponding to product of @xmath51 standard exponential random variables is thus given by the inverse mellin transform of the @xmath51th power of the gamma function defined for all @xmath154 by @xmath155 where @xmath156 is any real constant .",
    "the probability density function @xmath157 corresponding to the _ logarithm _ of such a product of exponential random variables is given by @xmath158 .",
    "in other words we have @xmath159 we can explicitly compute the contour integral above using the theory of residues from complex analysis to derive a series representation for the density @xmath160 ; see [ app : series ] .",
    "unfortunately the coefficients of this series grow so fast with @xmath51 , that its radius of convergence and range of practical evaluation makes it redundant for values of @xmath51 greater than @xmath161 .",
    "we can also derive the leading order asymptotic form for @xmath162 for large @xmath135 .",
    "however again unfortunately , for large @xmath51 , the range of large values of @xmath135 for which this asymptotic form is useful , becomes severely restricted . in practical terms ,",
    "the most useful representation is the leading order asymptotic form for @xmath160 for large @xmath51 , uniform in @xmath135 , derived using the method of steepest descents .",
    "[ th : lped ] for large @xmath51 , uniformly in @xmath135 , the probability density function @xmath157 for logarithm of the product of @xmath114 exponential random variables , has the leading order asymptotic form @xmath163 where @xmath164 is the digamma function .",
    "the next order term is asymptotically smaller than a factor @xmath165 times a functional form similar to the numerator for @xmath160 above ( rather than the factor @xmath166 shown for @xmath160 ) .    to determine the asymptotic behaviour for @xmath160 for large @xmath51",
    ", we apply the method of steepest descents . recall that @xmath157 is given for any real @xmath156 by @xmath167 let @xmath168 denote the exponent function in the integrand . note",
    "that we retain the ratio @xmath169 as we wish to include the possibility that @xmath169 might be order one or even asymptotically large . since @xmath51 and @xmath135 are real , we note that @xmath170 has a unique saddle point given by @xmath171 where @xmath164 is the digamma function .",
    "since the argument in the above contour integral is analytic in the right - half complex plane , we can deform the contour of integration to one of constant phase that passes through @xmath172 on the real axis .",
    "then we apply the usual laplace method arguments .",
    "we shrink the range of the contour of integration to a small interval around @xmath172 , replace @xmath173 by its quadratic taylor expansion , then extend the range of integration out again and utilize standard area estimates for gaussian functions .",
    "this standard procedure reveals that @xmath174 where @xmath175 denotes the second derivative of @xmath2 along the constant phase contour ( orthogonal to the real axis ) at @xmath172 . substituting the form for @xmath170 and that @xmath176 gives the large @xmath51 result of the theorem .    as with the logistic normal approximation ,",
    "the idea here is to more efficiently sample the large sums of logistic random variables , on average @xmath104 , at each order ; especially at higher orders .",
    "hence when the poisson sample @xmath108 at order @xmath40 , for some predetermined @xmath109 , we will instead draw samples from the distribution function @xmath177 for the logarithm of @xmath106 standard exponential random variables  corresponding to the density function @xmath178 . the only practical form for @xmath178 for sampling when @xmath179 is the asymptotic form given in theorem  [ th : lped ]",
    ". however , unfortunately an analytic form for distribution function @xmath177 is not available . to overcome this we proceed as follows .",
    "we tabulate the corresponding inverse distribution function @xmath180 for @xmath181 .",
    "this needs to be done only once and as accurately as we possibly can .",
    "then given any @xmath43 such that @xmath108 , with say @xmath52 , we can decompose @xmath182 . here",
    "@xmath183 are simply the decimal digits of @xmath106 . in the exponential product approximation method",
    "we propose then , for each @xmath40 , when @xmath108 we sample @xmath184 logistic random variables @xmath185 directly . then using interpolation with the table for @xmath186 we sample @xmath187 pairs of random variables @xmath188 and @xmath189 from @xmath190 .",
    "we further sample @xmath191 pairs of random variables @xmath192 and @xmath193 using interpolation from our table for @xmath194 , and so forth .",
    "hence for @xmath108 , we replace the logistic random variable accumulant as follows @xmath195 in practice we restricted @xmath196 .",
    "the only error in this replacement is in the asymptotic approximation of the cumulative distribution function , the accuracy of the tables and the interpolation . above the threshold @xmath51 ,",
    "the number of uniform random we require at each order is two times @xmath197 .",
    "hence , since at each order the logistic accumulant is scaled by the factor @xmath198 , the complexity of our exponential product approximation method is in principle @xmath146 .",
    "we can of course augment this method by simulating the tail sum as before .",
    "we provide here details of our implementation underlying figure  [ fig : difference ] and at the same time explain more carefully what we observe therein .",
    "our lvy and basic logistic simulation are straightforward truncations of the corresponding representations given in the introduction and theorem  [ th : logisticexpansion ] .",
    "note that in all cases we performed @xmath199 simulations  as large as was practically possible .",
    "carlo simulation variance is of order @xmath200 . from our experience and",
    "as can be seen in figure  [ fig : difference ] , there is significant monte  carlo simulation noise roughly below @xmath201 , which we should take into account when intepreting the mean - square errors therein .",
    "note that we measure the error as the absolute value of the sample variance minus the true variance @xmath202 , where with random wiener increments @xmath4 and @xmath4 for each sample , we set @xmath203 .",
    "we see in figure  [ fig : difference ] that the lvy method provides lvy area samples for low accuracies and low computational effort . the slope of the error versus the actual computational effort for the lvy method is @xmath204 as it should be ( the variance of the tail asymptotically decays like @xmath205 ) .",
    "if we also simulate the tail for the lvy method , then the mean - square error should decay like @xmath206 ; see kloeden , platen & wright ( 1992 ) or wiktorsson ( 2001 ) .",
    "note that we do not directly observe this improved accuracy / convergence in figure  [ fig : difference ] as we compute the sample variance for the lvy method with independent tail approximations .",
    "thus we expect to see the error of the lvy method with tail approximation to be similar to the error of the lvy method itself , shifted by the variance of the tail approximation ",
    "an independent computation confirms this .",
    "indeed such a shift is observed for all the methods we implemented when we also simulate the tail , except that the shift is much more dramatic for all the logistic expansion methods . in the case of the basic logistic method",
    ", we can only generate lvy area samples if we re willing to invest computational effort above a ( in principle quantifiable ) threshold . in the basic logistic approximation ,",
    "the order scales exponentially  the terms at each order scale like @xmath207 but we must invest on average a factor @xmath104 amount of effort at each order as well . in figure",
    "[ fig : difference ] , low order basic logistic approximations scale favourably as it s relatively cheap to sum a medium - sized number @xmath208 of logistic random variables ( whilst the terms scale like @xmath207 at each order ) . however eventually , as we can see in figure  [ fig : difference ]",
    ", we reach the asymptotic behaviour we expect with a slope of @xmath204 .",
    "when we also simulate the tail , we get a dramatic improvement in accuracy , so much so that the results lie in the regime where we know there is significant monte ",
    "carlo simulation noise .",
    "note that we did not include in figure  [ fig : difference ] simulations of the rydn  wiktorsson method . the computational effort required to achieve the corresponding accuracies we have indicated in figure  [ fig : difference ] meant that the rydn  wiktorsson method , even including simulating the tail , was not competitive .",
    "note also that for all our logistic expansion based methods , we used the standard algorithm given in knuth ( 1998 ) to simulate the poisson random variable @xmath106 when the mean @xmath209 and the normal approximation otherwise .",
    "standard exponential random variables .",
    "note we have used a log - of - minus - log scale .",
    "the panels on the right give an indication of the error of the the asymptotic approximations compared to the empirical cumulative distribution function ( with the same colour attribution ) .",
    "the magenta curve in the top two panels represents an approximation to the cumulative distribution function constructed by directly numerically computing the contour integral for @xmath160.,width=472,height=604 ]    in figure  [ fig : difference ] we also indicate the performance of our normal approximation and exponential product approximation methods . in the case of the normal approximation , at each order , when the poisson sample @xmath210 we invoked the central limit theorem and replaced the logistic sum by the suitably matched normal random variable as indicated in  [ sec : normalapprox ] .",
    "this effect is strikingly indicated by the sharp downturn in the normal approximation plot in figure  [ fig : difference ] .",
    "we also observe that the accuracy of the method is robustly uncompromised by this normal replacement .",
    "note that including a tail approximation generates a much more accurate sampling method . as we indicated above",
    ", an independent computation demonstrates that the error shown in figure  [ fig : difference ] for the normal approximation with tail is the same as the normal approximation shifted by the variance of the tail approximation .",
    "note that the normal approximation with tail carries us into the regime where the monte ",
    "carlo simulation noise is significant .    to implement the exponential product approximation some preparation is required .",
    "we constructed tables for the inverse distribution functions @xmath211 for the logarithm of the product of @xmath51 exponential random variables for @xmath52 , @xmath53 , @xmath54 and @xmath55 as follows . using the large @xmath51 asymptotic approximation for @xmath160 we derived in theorem  [ th : lped ]",
    ", we constructed @xmath212 by integrating from the left and right ends , respectively , as follows ( we justify this presently ) : @xmath213 we used the trapezium rule with very small stepsizes to approximate these two expressions and the results are given in figure  [ fig : logprodexp ] . in the left set of panels of the figure we plot the distribution functions @xmath212 constructed in this way .",
    "the blue curve corresponds to integrating from the left and the green to integrating from the right .",
    "an empirically computed cumulative distribution function is shown in red .",
    "the accuracy of the integrated asymptotic form is immediately apparent ; as is the reason for independently integrating from either end to minimize the accumulated quadrature error . for the case",
    "@xmath52 , the magenta curve shown corresponds to constructing the distribution function by a quadrature approximation of the contour integral form for @xmath214 for each @xmath135 . for small",
    "@xmath135 this approximation breaks down and for larger values of @xmath51 it becomes impractical . in the right set of panels in figure  [",
    "fig : logprodexp ] we show the difference of the left and right integral approximations to the empirically computed cumulative distribution function which indicate errors less than @xmath215 .",
    "we spliced together the left and right approximations , numerically inverted the result , and then used linear interpolation to construct the inverse @xmath216 cumulative distribution functions using @xmath217 points uniformly spaced on @xmath218 $ ] .",
    "in other words , the tables each contain @xmath217 values for @xmath211 at @xmath219 for @xmath220 . in the tables corresponding to @xmath221 and above",
    ", we crudely set @xmath222 whilst we set @xmath223 .",
    "given the range of values of @xmath211 as @xmath224 we can infer from the left set of panels in figure  [ fig : logprodexp ] this replacement of @xmath225 seems reasonable and in practice from what we observe in figure  [ fig : difference ] this did not affect accuracy .",
    "the tables thus constructed in this way , allow us to rapidly sample from @xmath212 for any of the values of @xmath51 we ve indicated , as follows .",
    "we generate a uniform random variable @xmath226 .",
    "the integer part of @xmath227 immediately indicates the position in the table of interest to us .",
    "we use linear interpolation between that position and the next to generate a sample from @xmath212 .",
    "thus , with these tables and linear interpolation method for sampling from them , we implemented the exponential product approximation as indicated at the end of  [ sec : lped ] .",
    "we can of course also include a tail approximation .",
    "the results shown in figure  [ fig : difference ] are just as dramatic as for the normal approximation , making both these methods with tail simulation the ones of choice for high accuracy simulations .    to conclude we remark that the improved sampling methods for the lvy area we have introduced have important implications for our theoretical work on the algebraic structure of stochastic differential equations and concomitant universally accurate integrators ( see malham & wiese 2009 and ebrahimi  fard _ et .",
    "2011 ) as well as for more practical work on the pricing of financial derivatives ( see malham & wiese 2011 ) .",
    "[ app : series ] applying the theory residues to the contour integral form for the probability density function @xmath160 , corresponding to the logarithm of the product of @xmath51 standard exponential random variables , we can explicitly derive a series representation for it . for convenience ,",
    "we introduce the _ discrete convolution product_. for two sequences @xmath228 and @xmath229 this is the sequence whose @xmath40th term is given by @xmath230 , for @xmath42 .",
    "if @xmath231 and @xmath232 are the coefficients of the corresponding powers in a power series , say @xmath233 and @xmath234 , then the coefficients of the product of these two power series are @xmath235 .",
    "[ th : lpedseries ] for the probability density function @xmath157 for the logarithm of the product of @xmath114 exponential random variables we have the following explicit series representation @xmath236 where @xmath237 here if @xmath238 is the @xmath35th derivative of the gamma function evaluated at one , and if @xmath239 denotes the usual binomial coefficient , @xmath51 choose @xmath35 , then @xmath240    to derive the power series representation for the probability density function @xmath160 , we compute the inverse mellin transform @xmath241 of @xmath242 . here",
    "@xmath153 corresponds to the probability density function of the product of @xmath51 standard exponential random variables .",
    "at the very end we use that @xmath158 .",
    "to analytically compute the inverse mellin transform of @xmath242 we use the theorem of residues for the contour @xmath246 shown in figure  [ fig : contour ] ; we found gajjar ( 2010 , p.  111135 ) very useful here .",
    "note that we have @xmath247 here we have used that the contributions to the contour integral from the components of the contour @xmath243 , @xmath244 and @xmath245 are zero .",
    "our goal now is to determine the residue of @xmath248 at each of its poles @xmath249 for @xmath42 .",
    "note these are poles of order @xmath51 due to @xmath250 have simple poles at these points .",
    "our goal now is thus to derive the laurent series in powers of @xmath251 for @xmath248 centred at each of these poles , and to determine the coefficients of @xmath252 corresponding to the residues . for convenience we set @xmath253 .",
    "the taylor series for @xmath254 centred at @xmath249 is given by @xmath255 where we set @xmath256 for all @xmath257 .",
    "then using the taylor series for @xmath258 centred at @xmath259 , we have @xmath260 taking the @xmath51 power of this expression , and using the definition for the coefficients @xmath261 and @xmath262 given in the theorem , we get @xmath263 thus we are now in a position to compute the laurent series for @xmath248 centred at @xmath264 corresponding to @xmath249 .",
    "directly computing , we have @xmath265 where @xmath266 .",
    "the residue of @xmath248 at @xmath264 is generated by the term @xmath267 , i.e. we have @xmath268 using the explicit sum for the first discrete convolution on the right - hand side , summing over all the residues @xmath269 , and using that @xmath158 , generates the form for the density function @xmath160 given in the theorem .",
    "note that @xmath270 and so @xmath271 .",
    "this explicit series representation is useful and accurate for relatively small values of @xmath51 . in",
    "particular @xmath272 matches the known modified bessel function form @xmath273 for the probability density function when @xmath274 .",
    "further , integration by parts soon generates an analytic series expansion for the corresponding distribution function .",
    "unfortunately however , the coefficients @xmath275 grow factorially with @xmath51 making the series impractical for @xmath51 greater than @xmath161 .    as mentioned in the main text",
    ", we can also derive the leading order asymptotic form for @xmath162 for large @xmath135 .",
    "consider the product convolution form for density of the product of @xmath51 standard exponential random variables given by @xmath276 after using the substitution @xmath277 , we can then apply laplace s method .",
    "noting that the exponent function has a global maximum at @xmath278 in the range of integration , then up to exponentially small errors , we have that @xmath279 the matrix generating the quadratic form in the exponent in the integrand has one eigenvalue equal to @xmath280 with the remaining eigenvalues all equal to one . a linear change of coordinates corresponding to the orthonormal similarity transformation of the matrix generating the quadratic form , and using that @xmath158 generates the asymptotic form @xmath281 for large @xmath51 though , the range of large values of @xmath135 for which this approximation is useful , is severely restricted .",
    "lastly , we remark that an analytical form for the probability density function corresponding to a sum of logistic random variables is given in george and mudholkar ( 1983 ) .",
    "we have not pursued this approach , though one could in principle investigate whether a computationally feasible method to sample a sum of logistic random variables could be derived from this form ."
  ],
  "abstract_text": [
    "<S> lvy area simulation , logistic expansion we present a new representation for the lvy chordal area for a two - dimensional wiener process conditioned on its endpoints . </S>",
    "<S> this is based on an infinite weighted sum of logistic random variables . </S>",
    "<S> we develop a numerical simulation algorithm for the lvy area based on truncating this series and simulating the tail by a suitable normal random variable . </S>",
    "<S> we show how to improve the efficiency of the algorithm by approximating higher order terms , which are large sums of independent identically distributed logistic random variables , by two separate methods : using a suitable normal approximation and , sampling directly from the fixed density function for the logarithm of the product of decimal magnitudes of independent identically distributed exponential random variables . to implement a strong milstein numerical integrator for a stochastic differential equation driven by a multi - dimensional wiener process </S>",
    "<S> , we must maintain a local mean - square error of order the cube of the stepsize . to achieve this prescribed accuracy , the latter two lvy area sampling methods we propose , reduce the number of uniform random variables required to be sampled over each timestep , a measure of the complexity , from reciprocal square - root complexity to logarithmic complexity .    </S>",
    "<S> [ firstpage ] </S>"
  ]
}