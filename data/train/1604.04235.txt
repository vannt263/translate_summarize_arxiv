{
  "article_text": [
    "graph matching is important in many different areas of research @xcite .",
    "it is particularly well studied in the field of computer vision but has many other applications , ranging from circuit design to social network analysis .",
    "exact graph matching consists of trying to find an exact isomorphism from one graph ( or subgraph ) to another . in inexact graph matching one aims to find the best permutation of one of the graphs to make it as similar as possible to the other .",
    "this paper is concerned only with inexact graph matching and we refer to it henceforth simply as graph matching .",
    "a paramount issue with graph matching is the fact that the number of fixed node arrangements for a graph is factorial in the dimension of the graph .",
    "the computation time for optimal accuracy algorithms becomes computationally intractable as dimension increases @xcite .",
    "instead many suboptimal methods have been developed to find a balance between speed and accuracy .",
    "one approach uses spectral methods based on the graph laplacian or adjacency matrix as eigenvalues and eigenvectors of both these matrices are invariant with respect to node permutation @xcite .",
    "it is also possible to work directly with the adjacency matrices themselves , ( e.g. , @xcite and @xcite ) .",
    "@xcite introduces a convex - concave programming approach to give an approximate solution for labelled graph matching , a generalisation of graph matching .",
    "the paper identified that there are many cases where the ` common approach ' of    * relaxing the graph matching problem to find a solution @xmath0 in a superset of the permutation matrices and * projecting to the closest permutation matrix @xmath5 ( minimising frobenius norm ) ,    does not find a satisfactory solution .",
    "instead the approach in @xcite used a gradual updating of the initial solution @xmath0 towards a solution in the set of permutation matrices , following a path calculated by the convex - concave programming approach .",
    "the procedure is known as the path algorithm .",
    "it combats the inefficiency of the previously mentioned approach by updating the relaxed solution @xmath0 . in this paper , by contrast , we look at modifying the common approach by improving the second ( projection ) step .    in barvinok @xcite it was shown how an orthogonal matrix @xmath0 could be approximated as a ` non - commutative convex combination ' of permutation matrices . in his proof",
    "he used the idea of randomised rounding to project @xmath0 onto a permutation matrix @xmath6 so that @xmath0 defines a distribution over the set of permutation matrices ( along with the sampling distribution used for the randomised rounding ) .",
    "this is also briefly mentioned in @xcite .    in this paper",
    "we propose a sampling strategy for projecting matrices over @xmath7 to permutation matrices in the graph matching environment . in sections",
    "[ sec : gmp ] and [ sec.currentmethod ] we briefly discuss the graph matching problem , how it can be relaxed and the standard approach to finding an approximate solution .    in section  [ sec.ourmethod ]",
    "we show how the ideas in @xcite can be used to develop a graph matching strategy .",
    "we transform the problem of sampling in the space of permutation matrices to sampling vectors @xmath8 given a relaxed solution @xmath2 instead of solving @xmath9 we solve @xmath10 for a given @xmath11 .",
    "( here @xmath12 denotes the frobenius norm @xmath13 @xmath14 denotes trace , @xmath15 denotes complex - conjugate ( hermitian ) transpose . ) we say that @xmath16 is in the permutation set @xmath17 if @xmath18 we show that the solution to the ` common approach ' corresponds to minimizing the mean of the squared norm for our method , under uniform distributions on the unit hypersphere or unit cube .",
    "in section  [ sec.roundinggeometry ] we investigate some geometrical properties of our proposal .",
    "we show there is a ` degree of continuity , ' i.e. , given a point @xmath19 , we can find other points close to it that are also in @xmath20 .",
    "the boundaries of the @xmath21 regions are illustrated .",
    "we also solve the ` reversed ' problem : if we have a permutation @xmath5 can we find @xmath16 such that @xmath22 this is a very useful result for our final sampling algorithm .",
    "section  [ subsec : varianceadapt ] describes a procedure for adjusting the variance of our proposal distributions as time progresses , and this is built - in to the full sampling strategy for projecting to permutations in the graph matching problem algorithm which is detailed section  [ subsec : strategy ] .",
    "finally , in section [ sec.results ] , we show how our scheme , ssqcv , performs on qaplib @xcite a popular library of benchmark cases to test against .",
    "we find that ssqcv outperforms path @xcite in two - thirds of the experiments , and the latter is already known to outperform well - known competitors .",
    "we point out that the incorporation of our sampling strategy as a projection step into algorithms such as path itself has the potential to achieve even better results .",
    "an @xmath3-dimensional graph is represented as @xmath23 where @xmath24 is a set of vertices and @xmath25 is a set of edges such that @xmath26 if and only if there is a connection from vertex @xmath27 to vertex @xmath28 .",
    "we consider simple undirected graphs such that there are no self loops and @xmath29 .",
    "the set of edges @xmath30 can be represented by an adjacency matrix @xmath31 such that @xmath32 if @xmath26 and @xmath33 if @xmath34 .",
    "consider two graphs with @xmath35 adjacency matrices @xmath36 and @xmath37 ( weighted or un - weighted ) , then the graph matching problem is concerned with finding @xmath38 where @xmath39 is the set of dimension-@xmath3 permutation matrices",
    ".    an exhaustive search over @xmath40 can be used to solve ( [ eqn.gmp ] ) , but it has complexity @xmath41 and is computationally intractable even for moderately sized @xmath3 .      an alternative approach is to relax the constraints in ( [ eqn.gmp ] ) to first find @xmath42 for some set @xmath43 .",
    "we could use for example @xmath44 , the set of doubly stochastic matrices , i.e. , all matrices with non - negative entries whose rows and columns sum to 1 . in this case , the optimisation in ( [ eqn.gmprelax ] ) is convex and can be efficiently solved by the frank - wolfe algorithm @xcite .",
    "alternatively we could use @xmath45 , the set of orthogonal matrices .",
    "( [ eqn.gmprelax ] ) can then be efficiently solved using the singular value decomposition ( svd ) .",
    "note however there is an unidentifiablity issue in this case and we do not have a unique solution . in the best case",
    ", we have @xmath46 solutions but can have more if the eigenvalues of either of the adjacency matrices @xmath36 and @xmath37 are not distinct .",
    "now @xmath47 is the convex hull of the permutation matrices and intuitively a matrix @xmath48 that is ` close ' to @xmath49 is a good candidate for a solution to ( [ eqn.gmp ] ) .",
    "this suggests we can find a good approximation to a solution of ( [ eqn.gmp ] ) via :    1 .",
    "solve ( [ eqn.gmprelax ] ) , ( which can be done efficiently ) , to get matrix @xmath49 .",
    "2 .   project / round the matrix @xmath50 to the closest matrix @xmath48 .",
    "after finding a suitable @xmath0 for a relaxed version of ( [ eqn.gmp ] ) , i.e. , @xmath0 solving ( [ eqn.gmprelax ] ) , the most common method to project to a permutation is through the intuitive optimisation ( see e.g. , @xcite ) , @xmath51 which can be solved by the hungarian algorithm in @xmath52 time as @xmath53 is simply a linear assignment problem @xcite .",
    "a serious issue with the use of ( [ eqn.matrixroundcurrent ] ) is that it only delivers one candidate solution to ( [ eqn.gmp ] ) and if it is not a good solution it is unclear how to continue . in @xcite",
    "an incremental improvement to their estimate is performed by subsequent concave and convex relaxations , while still using ( [ eqn.matrixroundcurrent ] ) .",
    "we instead propose an adjustment to the projection step in itself as an alternative to ( [ eqn.matrixroundcurrent ] ) .",
    "an important part of our overall algorithm , that we use to replace ( [ eqn.matrixroundcurrent ] ) , involves solving @xmath54 for a given @xmath11 .",
    "the idea is inspired by barvinok in @xcite : to round an orthogonal matrix @xmath0 to a permutation matrix @xmath6 , consider its action on @xmath55 sampled from a gaussian distribution .",
    "consider sample @xmath16 and ordering vector @xmath56 such that @xmath57 where @xmath58 is the @xmath28th smallest value of @xmath16 .",
    "for example : @xmath59 then barvinok argues the permutation @xmath6 such that @xmath60 is ` close ' to @xmath0 with respect to @xmath16 as they both transform @xmath16 in similar ways .",
    "@xmath6 represents a ` rounding ' of @xmath0 .",
    "note also @xmath61 so if @xmath0 is a permutation matrix , it is always rounded to itself .",
    "this therefore provides a way to project / round an orthogonal matrix @xmath0 to a distribution of permutation matrices .",
    "the distribution can be sampled from by drawing a gaussian vector @xmath55 and solving ( [ eqn.barvinok ] ) .",
    "we observe that for barvinok s approach ( i ) @xmath0 need not be orthogonal , and ( ii ) the distribution from which @xmath16 is sampled need not be gaussian . furthermore , we note the following important result :    [ thm.minsort ] given @xmath55 and @xmath62 , any permutation matrix @xmath6 solving ( [ eqn.barvinok ] ) is also a solution to ( [ eqn.matrixroundours ] ) .",
    "this is given in appendix  [ proof : proofminsort ] .",
    "the solution of ( [ eqn.matrixroundours ] ) is invariant to the norm of @xmath63 i.e. , if @xmath64 is the solution and we write @xmath65 in polar coordinates then we can equally write @xmath66 as the solution",
    ".    consider @xmath67 such that @xmath68 and @xmath69 .",
    "then as both the sorting of a vector @xmath55 is unchanged by multiplication by some constant @xmath70 and also @xmath71 is also unchanged with respect to sorting , if @xmath6 solves ( [ eqn.matrixroundours ] ) for a given @xmath0 and @xmath72 , it also solves it for @xmath73 a rescaled version of @xmath74    this means we can always sample @xmath75 on the unit hypersphere .",
    "we can now define a probability distribution over our permutation matrices via a random variable @xmath76 such that for possible sample outcomes @xmath77 @xmath78 where @xmath79 is the cumulative distribution function for the random variable @xmath80 from which @xmath16 is drawn , @xmath62 and @xmath81 any sets of @xmath16 in multiple @xmath82 s are sets of measure zero as we shall show later .",
    "we will drop the @xmath0 from the @xmath83 notation from now on unless it is unclear to which @xmath0 matrix we are referring .",
    "so the distribution of permutation matrices from which we want to sample candidates to solve ( [ eqn.gmp ] ) is affected by both @xmath62 and the distribution @xmath79 from which we sample @xmath84      for @xmath55 we now show that the solution to the ` current method ' of section  [ sec.currentmethod ] corresponds to minimizing the mean squared norm , @xmath85 when @xmath80 is uniformly distributed on the unit hypersphere or in the unit hypercube .",
    "[ prop : meanequiv ] for @xmath80 uniformly distributed on the unit hypersphere @xmath86 , @xmath87    this is given in appendix  [ proof : proofexpectation ] .",
    "[ prop : hypercube ] for @xmath55 with @xmath80 uniformly distributed in the unit hypercube @xmath88^n$ ] for which @xmath89 , @xmath90    this is given in appendix  [ proof : proofhypercube ] .     for uniform sampling of permutations ( light grey ) versus sampling in @xmath91 and corresponding permutation sets ( dark grey ) ; the black is the overlap region . ]      here we compare values of @xmath92 obtained when    * we sample @xmath93 independent outcomes of @xmath94 the components @xmath58 being independent and having the standard normal distribution , and for each @xmath16 solve ( [ eqn.matrixroundours ] ) to obtain the @xmath95 s , and * we randomly sample @xmath93 @xmath95 s uniformly on @xmath40 using the @xmath96 function ` randperm , ' followed by conversion of the permutation sequence to a matrix .",
    "we would like to see that our sampling approach based on some permutation approximation @xmath62 dividing @xmath97 into permutation sets @xmath98 is better than simply randomly sampling permutations uniformly .",
    "we let @xmath36 be a @xmath99-dimensional random symmetric matrix , @xmath6 be a @xmath99-dimensional random permutation matrix and @xmath100 where @xmath101 ( the normal distribution with mean zero and variance one ) and @xmath102 we then find @xmath0 solving ( [ eqn.gmprelax ] ) over @xmath47 .    for this example ,",
    "the histograms of fig .",
    "[ fig : unifvsrnl0 ] show that the distribution of the error norm for permutations sampled by solving ( [ eqn.matrixroundours ] ) is shifted to the left compared with sampling permutations randomly .",
    "here we consider the ` continuity ' ( though not necessarily connectedness ) of the sets @xmath20 .    [ prop.closedset ] for @xmath104 such that @xmath105 and @xmath106 for @xmath107",
    ", we can find @xmath108 such that @xmath109 , whenever @xmath110 .",
    "this is given in appendix  [ app : closedset ] .",
    "this means that given a point @xmath16 inside @xmath20 ( not on its boundary ) , we can find other points close to it that are also in @xmath20 .",
    "we can also see that the boundaries of @xmath20 occur at points where @xmath111 or @xmath112 for @xmath107 .",
    "we may of course have multiple elements becoming equal at the same time , e.g. @xmath113 where @xmath114 for all permutation matrices .",
    "if we are sampling from a purely continuous distribution with @xmath55 defined by random variable @xmath80 , then @xmath115 and @xmath116    in both cases the sets are of measure zero in @xmath103 and hence correspond to zero probability .",
    "so when we are sampling , we do not have to worry about hitting a point of discontinuity between two sets @xmath117 and @xmath118 for @xmath107 .",
    "when we do change from @xmath119 to @xmath120 in moving a ` small ' distance from point @xmath121 to @xmath122 , the difference between @xmath123 and @xmath124 is normally small , ( but not always , considering the case @xmath125 ) , and occurs because for some @xmath27 and @xmath28 , @xmath126 but now @xmath127 . if @xmath27 and @xmath28 are the only entries that have flipped , ( which happens in the majority of cases ) , then this change corresponds to a simple flip in the entries of @xmath123 and @xmath128 e.g. , if @xmath123 sent @xmath129 and @xmath130 , @xmath124 may now send @xmath131 and @xmath132 .",
    "this means @xmath133 ( the minimum such value between two different permutation matrices ) .",
    "there exist boundary hyperplanes between @xmath119 and @xmath120 where @xmath134 for large @xmath135 , so that crossing such hyperplanes results in @xmath123 and @xmath124 being quite dissimilar .",
    "this form of continuity outlined implies we can use a search algorithm based on closeness in @xmath136 which we detail in the next section .      in order to gain further insight into the partitioning of @xmath103 into permutation sets",
    ", we will illustrate the case when @xmath137 .",
    "the boundaries of the permutation sets are defined by the lines on the unit hypersphere given by @xmath111 and @xmath112 for a partition - defining matrix @xmath62 .",
    "we note that in the case @xmath138 for @xmath139 e.g. , @xmath0 a doubly stochastic matrix , all the boundaries of the permutation sets intersect at the point @xmath140 .",
    "the size of each permutation set can then be calculated using the angles between these boundary lines at the point @xmath141 .",
    "the ratio of the area of a permutation set with boundary angle @xmath142 to the whole unit sphere area is then @xmath143 and if we sample a point on the unit sphere , this is the probability of it being from inside the given permutation set .",
    "the angles @xmath142 can be readily found by considering the normal vectors to the planes that form the boundaries of the permutation sets in @xmath144 i.e. , @xmath111 and @xmath145 .",
    "@xmath146 % \\includegraphics[scale=0.6]{sphereds.eps}\\\\ \\includegraphics[scale=0.9]{dsgrayopengl.eps}\\\\ %    \\includegraphics[width=0.5\\textwidth ] % \\includegraphics[scale=0.6]{sphereorth.eps } \\includegraphics[scale=0.9]{orthoggrayopengl.eps } \\end{matrix}$ ]    our figures show the partition boundaries for random symmetric 3d matrices @xmath36 and @xmath37 .",
    "these boundaries are the lines @xmath112 when @xmath147 ( heavy lines ) and    * fig .  [",
    "fig.sphereds](top ) : @xmath0 is the best doubly stochastic matrix solving ( [ eqn.gmprelax ] ) ( thin lines ) . *",
    "[ fig.sphereds](bottom ) : @xmath0 is an orthogonal matrix with an eigenvector @xmath148 ( thin lines ) .",
    "the dashed line is for @xmath149 we make the following observations .",
    "when @xmath147 the lines have a constant angle between them and pass through the point @xmath140 . when @xmath0 is the best doubly stochastic matrix , the lines no longer have a constant angle between them but still pass through the point @xmath141 because @xmath150 .",
    "when @xmath0 is an orthogonal matrix with an eigenvector @xmath148 , the lines have a constant angle between them and pass through the point @xmath141 .",
    "we can think of this case as a rotating of the lines from the @xmath147 case .",
    "our algorithm will make use of the following step : if we have a permutation @xmath5 can we find an @xmath16 that rounds to @xmath6 using ( [ eqn.matrixroundours ] ) ?",
    "the answer is yes , from the following result .",
    "[ thm.reverseperm ] consider @xmath62 and let @xmath151 if @xmath152 is such that @xmath153 , then for any @xmath154 , we can find @xmath55 such that @xmath155 and it is given by @xmath156 where @xmath157 orders @xmath158 in ascending order ( i.e. @xmath159 ) and @xmath160^t$ ] for some @xmath161 .",
    "this is given in appendix  [ app : reverseperm ] .",
    "we make the following observations .",
    "* we can use theorem  [ thm.reverseperm ] to find initial points for our algorithm .",
    "suppose @xmath162 then replace @xmath163 by @xmath123 in theorem  [ thm.reverseperm ] to find an @xmath16 such that @xmath164 * in general we want to choose @xmath165 to be as large as possible while still keeping @xmath166 .",
    "this is because it moves @xmath167 away from @xmath141 which is a large point of discontinuity in our partitioned @xmath103 .",
    "the closer we are to it , the less positive the effect on our algorithm will be from picking a suitable initial point . *",
    "if @xmath0 is a doubly stochastic matrix , it does not satisfy the conditions in theorem  [ thm.reverseperm ] because @xmath168 * if @xmath169 for some @xmath107 , @xmath170 has no distinct ordering and multiple permutations sort @xmath158 into ascending order .",
    "it is possible to slightly perturb doubly stochastic matrix @xmath171 by working instead with matrix @xmath172 where @xmath173 is a matrix such that @xmath174 $ ] .",
    "@xmath175 avoids ( [ eq : problem ] ) and so by theorem  [ thm.reverseperm ] , with probability 1 , every permutation set has non - zero measure  some matching @xmath16 s are guaranteed  and it is therefore possible to sample all permutations in @xmath103 .",
    "@xmath176{spheredspert.eps }    \\includegraphics[scale=0.9]{perturbeddsgrayopengl.eps } \\end{matrix}$ ]    fig .",
    "[ fig.spheredspert ] is of the same form as fig .",
    "[ fig.sphereds ] but now using @xmath177 the lines no longer have a constant angle between them nor pass through the point @xmath141 .",
    "[ fig : unifvsrnl01 ] repeats fig .",
    "[ fig : unifvsrnl0 ] only this time perturbing @xmath0 to @xmath178 using @xmath179 while still outperforming uniform sampling , the advantage has been slightly reduced .     for uniform sampling of permutations ( light grey ) versus sampling in @xmath91 and corresponding permutation sets ( dark grey ) ;",
    "the black is the overlap region . here",
    "before outlining our full sampling strategy , we discuss an important component , namely ` variance adaptation . '",
    "let @xmath181 denote a time step . in our sampling strategy , given @xmath182",
    ", we obtain sample @xmath183 from our proposal distribution @xmath184 the @xmath3-dimensional normal distribution with mean @xmath182 and covariance matrix @xmath185    we then project the sample @xmath183 onto the unit hypersphere using @xmath186 .",
    "the only value we have control over is @xmath187 and we investigate how best to choose this value so that the resultant samples have certain desirable properties .    given a @xmath62 , both @xmath182 and @xmath183 have associated permutation matrices @xmath188 and @xmath189 respectively , from solving ( [ eqn.matrixroundours ] ) . define @xmath190 then @xmath187 should be chosen so that @xmath191 gradually decays toward @xmath192 with increasing iteration step @xmath193    assume that @xmath194 where @xmath195 is a model for @xmath191 and @xmath196 is zero mean noise , so that @xmath197 .",
    "suppose we can supply a target function @xmath198 for @xmath191 to follow .",
    "then , at time @xmath199 , given @xmath198 and @xmath195 we can choose the value for @xmath187 by calculating    @xmath200    i.e. , the variance that minimises the distance between the target function and @xmath201 .",
    "make the substitution @xmath202 since @xmath203 .",
    "let @xmath204 be the maximum value of @xmath205 we then learn an estimator @xmath206 of @xmath207 using the observations @xmath208 and @xmath209 the function @xmath210 is taken to be the logistic curve and is estimated via regression .",
    "consider approximating @xmath191 for very large variance values .",
    "this can be done by randomly sampling @xmath211 points @xmath212 on the unit hypersphere and finding @xmath213 where @xmath214 is the initial original unit hypersphere sample value . from ( [ eq : pdifforig ] ) and ( [ eqn.pdiffest ] ) , @xmath215 is an estimate for the largest value of @xmath216      we need to generate a set of suitable @xmath217 values , which we label @xmath218 called pre - samples . in order to generate pre - samples , we want to sample a number of @xmath217 such that @xmath219 $ ] for some small chosen @xmath108 .",
    "( this is to avoid a regression where all @xmath220 are either in @xmath221 $ ] or @xmath222 $ ] , in which case we are lacking information for accurately learning the logistic relationship . )    to do this we sample from a normal distribution with mean 0 and variance 1 to get our first point @xmath223 such that the corresponding @xmath224.$ ] if it is in this interval , we increase the variance of our sampling distribution and keep trying until we get a suitable @xmath223 .",
    "once we have @xmath223 we then aim to find @xmath225 in a similar manner such that @xmath226/\\pdiff_{\\rm max } \\supset [ \\epsilon , 1 - \\epsilon]$ ] .",
    "we then reorder @xmath223 and @xmath225 such that for simplicity @xmath227 .",
    "we now sample the remaining @xmath217 uniformly on @xmath228 $ ] . if @xmath229 $ ] , we update our sampling interval : if @xmath230 , set @xmath231 else if @xmath232 set @xmath233 .    after generating @xmath234 such @xmath235 s",
    "we call them @xmath236      we start with the @xmath234 ` pre - samples ' @xmath237 and then compute the corresponding @xmath238 and the associated @xmath239 we then learn @xmath206 via the inputs @xmath240 and @xmath241    we can also include a further parameter @xmath242 such that when @xmath243 , we re - learn @xmath244 given our observations up to that point .",
    "e.g. , when @xmath245 we make use of inputs @xmath246 and @xmath247 to re - learn @xmath248    fig .",
    "[ fig.logregfit ] gives an example of the learning of @xmath249 and suggests a logistic model works appropriately .",
    "[ fig.varadjustdecay ] shows that we were able to choose @xmath187 so that @xmath191 does a good job of tracking the target curve @xmath198 defined here as @xmath250.$ ] this figure uses the re - learning step with @xmath251 particularly initially , @xmath191 drifts below @xmath198 but this is corrected .",
    "the circles show @xmath252 ( vertical ) against @xmath253 ( horizontal ) .",
    "the crosses give the fitted logistic curve for @xmath254 ]     ( hashy line ) versus @xmath198 ( thick curve ) , against @xmath193 ]",
    "the algorithm has characteristics in common with simulated annealing . in its purist form , we gradually sample proposal points closer and closer to the current point .",
    "we update to a proposed point if it returns a permutation with a better value for our objective function than the current point .",
    "note we could also randomise the updating process by incorporating acceptance probabilities that are high if the proposal point is better than the current point and vice versa .    before giving the full sampling strategy",
    "we point out that not all steps may be required , these variants are described in the notes that follow .      1",
    ".   initialise ` totaliterations ` .",
    "choose @xmath255 ( see equations ( [ eq : qdash ] ) , ( [ eqn.pmax ] ) , ( [ eq : ypresamps ] ) ) , @xmath256 target function @xmath198 and acceptance probability function @xmath257 ( see note  [ note : one ] below ) .",
    "denote the dimension of the problem by @xmath3 . + preliminary calculations : 2 .   find a relaxed @xmath0 minimising ( [ eqn.gmprelax ] ) ( if @xmath0 is to be doubly stochastic , this can be done using the frank - wolfe algorithm ) .",
    "3 .   if @xmath258 for @xmath259 , where @xmath260 ( i.e. if @xmath0 is doubly stochastic ) , then perturb @xmath0 so that for any permutation @xmath6 , @xmath21 has no zero measure . to do this ,",
    "set @xmath261 [ step.perturb ] .",
    "4 .   find initial point @xmath214 by reversing the permutation @xmath262 solved by the hungarian algorithm .",
    "see the discussion around ( [ eq : plugin ] ) .",
    "[ step.initialise ] 5 .",
    "calculate the associated @xmath263 to give the initial vector @xmath264 .",
    "randomly draw @xmath265 on the unit hpersphere , and calculate @xmath266 via ( [ eqn.pmax ] ) .",
    "7 .   as in section  [ subsec : presamples ] we generate presamples @xmath267 and calculate the associated @xmath268 using ( [ eq : minusis ] ) and hence learn @xmath269 ; rescale to give @xmath216 main iterations : 8 .   [",
    "item : no ] for @xmath270 9 .",
    "if @xmath271 , re - learn @xmath269 based on the new observations ; rescale to give @xmath216 10 . choose @xmath187 minimising @xmath272 .",
    "sample @xmath273 and normalise @xmath274 .",
    "find corresponding permutation representing a ` rounding ' of @xmath5 namely @xmath275 and also @xmath276 .",
    "sample @xmath277 $ ] and if @xmath278 , set ( @xmath182 , @xmath279 , @xmath280 ) to ( @xmath281 , @xmath282 , @xmath283 ) otherwise to ( @xmath284 , @xmath285 , @xmath286 ) .",
    "loop back to ( [ item : no ] ) .",
    "note  :    [ note : one ] the pure strategy choice of @xmath287 would be @xmath288 where @xmath289 is the indicator function .",
    "the effect of ` @xmath290 ' is to avoid getting stuck in the middle of a large permutation set @xmath21 as the algorithm will continue to move around inside it .",
    "the choice of the target function @xmath198 is important .",
    "if it decreases too sharply there will not be a chance to sufficiently explore the space of permutation sets ; too slowly and there will not be time to make the small adjustments necessary to update a good permutation to a better one , ( based on the continuity argument ) , and it becomes too much like random sampling .",
    "the algorithm is suitable for parallelization .",
    "consider the to be one run .",
    "different exploring threads could be initiated within one run of the algorithm that re - align at regular intervals based on the current best thread .    in step [ step.initialise ] , we could also simply use a random value for @xmath214 in @xmath4 as our initialisation but it does not normally perform as well .",
    "here we use our sampling strategy , rather than the standard projection step given by ( [ eqn.matrixroundcurrent ] ) , with the simple method of finding the optimal doubly stochastic matrix @xmath0 solving ( [ eqn.gmprelax ] ) .",
    "we call our overall method ssqcv .    in the results which follow we use @xmath291 to perturb @xmath0 such that @xmath261 where @xmath173 is a matrix of uniform random numbers between @xmath292 $ ] .",
    "we take @xmath293 we use the pure strategy choice of @xmath287 and set @xmath294.$ ]    our sampling strategy is applied to the qaplib benchmark library used also by @xcite . now",
    "@xmath295\\\\   & = & \\min_p \\operatorname{tr } [ a^t a - 2a^tp^tbp + p^tb^tbp ] \\\\ & = & \\max_p \\operatorname{tr}[a^tp^tbp ] , \\end{aligned}\\ ] ] since @xmath296 is a permutation of both the rows and columns of @xmath297 so all elements on the leading diagonal remain on the leading diagonal i.e. , its trace is independent of @xmath6 .",
    "as pointed out in @xcite the quantity @xmath298 $ ] is negative for this class of experiments so that @xmath299= \\min_p \\operatorname{tr}[-a^tp^tbp]$ ] where @xmath300 $ ] values are positive .",
    "it is these latter positive values which are displayed in table  [ tab : qaplib ] .",
    "1 .   qap : the name of the benchmark in qaplib .",
    "min : the true minimum trace value of the benchmark .",
    "3 .   path : the minimum trace value found by the path algorithm .",
    "ssqcv mean : over 20 runs of the algorithm , the mean minimum trace value found . 5 .",
    "ssqcv best : over 20 runs of the algorithm , the best minimum trace value found .",
    "ssqcv time : over 20 runs of the algorithm , the mean execution time taken .",
    "* ssqcv mean outperforms path in two - thirds of the experiments .",
    "we already know from @xcite that path outperforms competitors such as qpb @xcite , grad @xcite , or umeyama s algorithm @xcite . *",
    "the path algorithm tends to perform better at higher dimensions .",
    "this is due to the fact @xmath4 becomes more and more finely partitioned as dimension increases and we need more iterations and a slower decrease in variance in our algorithm to account for this .",
    "this is the point where the benefits of updating of @xmath0 in path begins to outweigh the benefits of the sampling strategy with a fixed @xmath0 .",
    "* while this is a comparison against the path algorithm , we note that the sampling strategy can be integrated with more complex methods to achieve better results , including the path algorithm itself .",
    "as the dimension increases , it becomes clear that the partitioned space generated by @xmath0 does not have enough ` large ' sets @xmath301 where @xmath6 is a good solution to ( [ eqn.gmprelax ] ) .",
    "this suggests that an approach that also iteratively updates @xmath0 ( as in path ) would produce better results with our sampling strategy .",
    "of course , using the sampling strategy with the path algorithm would provide the best of both worlds in terms of performance .",
    "we also know that if @xmath6 is to be an optimal transformation , we must have @xmath311 otherwise we can define @xmath312 such that @xmath313 for @xmath314 but @xmath315 and @xmath316 . clearly if ( [ eqn.sortprop2 ] ) did not hold , @xmath317 , contradictory to @xmath6 being optimal .",
    "combining ( [ eqn.sortprop1 ] ) and ( [ eqn.sortprop2 ] ) gives @xmath318 hence if @xmath319 then we must have @xmath320 .",
    "thus @xmath321 is minimised when @xmath6 sorts @xmath158 to the same ordering as @xmath141 .",
    "letting @xmath322 and @xmath323 in theorem  [ thm.minsort ] gives the result .",
    "firstly , @xmath324 2 .   considering the quantity @xmath325 for some @xmath326 1 .",
    "all off - diagonal terms , i.e. , those of the form @xmath327 for @xmath328 integrate to 0 , 2 .",
    "all diagonal elements @xmath329 integrate to @xmath330 for some constant @xmath331 .",
    "hence @xmath332 is equivalent to maximising @xmath333 which is equivalent to @xmath334 , so the result in ( [ eqn.unifsphere ] ) follows .",
    "now consider @xmath337 writing @xmath16 in terms of hyperspherical coordinates , we have on the unit hypersphere that the volume element is @xmath338 and @xmath339 consider off - diagonal elements of @xmath340 of the form @xmath341 for @xmath107 , we see that @xmath342 contains at least one term of the form @xmath343 for @xmath344 i.e. , when @xmath345 or @xmath346 as we can not have both @xmath347 and @xmath348 as they can not be equal .",
    "hence @xmath349 where @xmath350 is some function , @xmath351 is a vector of all @xmath352 without @xmath353 and @xmath354 is the region over which we are integrating @xmath355 but , @xmath356_0^{\\pi } = 0,\\ ] ] so all off - diagonal elements of @xmath340 integrate to 0 .",
    "now consider diagonal elements of @xmath357 of the form @xmath358 we now require two identities .",
    "firstly , @xmath359 found from integrating by parts with @xmath360 and @xmath361 .",
    "secondly , @xmath362 integrating by parts with @xmath363 and @xmath364 .    for @xmath365",
    ", we see that @xmath366 can be written @xmath367\\nonumber\\\\   \\!\\!\\!\\!\\!\\!\\!\\!\\!\\!&\\times&\\!\\!\\!\\ !",
    "\\sin^{n-2}(\\theta_1 ) \\sin^{n-3}(\\theta_2 ) \\ldots \\sin(\\theta_{n-2 } ) \\dif \\bftheta ,          \\label{eqn.intsquared }      \\end{aligned}\\ ] ] where @xmath368 represents the fact all @xmath352 are to be integrated between these bounds .                              using theorem  [ thm.minsort ] , we know that for the permutation to be the same for @xmath16 and @xmath391 it is sufficient , ( from ( [ eqn.barvinok ] ) ) , that @xmath392 we have @xmath393 such that by definition @xmath394 also , @xmath395 , where @xmath396 @xcite .        now , @xmath403 so @xmath404 so @xmath405 and , similarly , @xmath406 then taking for example @xmath407 ensures that @xmath408 similarly @xmath409 and @xmath410 then taking @xmath411 ensures that @xmath412 hence we can choose @xmath413 completing the proof .",
    "what is @xmath56 ?",
    "since @xmath153 , we can choose @xmath416 sufficiently small such that @xmath417 i.e. , the ordering of @xmath16 is the same as @xmath158 .",
    "note that @xmath418 as both are in ascending order .",
    "what is @xmath419 ?",
    "now @xmath420 as @xmath421 is a constant vector",
    ". we can therefore choose @xmath422 to get @xmath423 then we use ( [ eq : roundstoself ] ) which says that",
    "@xmath424 so @xmath425 where the last step uses ( [ eq : rxrb ] ) .",
    "h.  a.  almohamad and s.  o.  duffuaa , `` a linear programming approach for the weighted graph matching problem , '' _ ieee transactions on pattern analysis and machine intelligence , _ vol .",
    "15 , pp .  522525 , 1993 .",
    "f.  fogel , r.  jenatton , f.  bach and a.  daspremont , `` convex relaxations for permutation problems , '' in _ advances in neural information processing systems 26 _",
    ", c.  burges , l.  bottou , m.  welling , z.  ghahramani and k.  weinberger ( eds ) , pp .  10161024 , curran associates , inc .",
    ", 2013          d.  knossow , a.  sharma , d.  mateus and r.  horaud , `` inexact matching of large and sparse graphs using laplacian eigenvectors , '' in _ graph - based representations in pattern recognition _ , a.  torsello , f.  escolano and l.  brun ( eds . ) .",
    "volume 5534 of the series lecture notes in computer science , pp .  144153 , springer , 2009 .    c.  schellewald , s.  roth and c.  schnrr , `` evaluation of convex optimization techniques for the weighted graph - matching problem in computer vision , '' in _ pattern recognition : 23rd dagm symposium proceedings _ , b.  radig and s.  florczyk ( eds . )",
    "volume 2191 of the series lecture notes in computer science , pp .",
    "361368 , springer , 2001 ."
  ],
  "abstract_text": [
    "<S> in the context of the graph matching problem we propose a novel method for projecting a matrix @xmath0 , which may be a doubly stochastic matrix , to a permutation matrix @xmath1 we observe that there is an intuitve mapping , depending on a given @xmath2 from the set of @xmath3-dimensional permutation matrices to sets of points in @xmath4 . </S>",
    "<S> the mapping has a number of geometrical properties that allow us to succesively sample points in @xmath4 in a manner similar to simulated annealing , where our objective is to minimise the graph matching norm found using the permutation matrix corresponding to each of the points . </S>",
    "<S> our sampling strategy is applied to the qaplib benchmark library and outperforms the path algorithm in two - thirds of cases . instead of using linear assignment , the incorporation of our sampling strategy as a projection step into algorithms such as path itself has the potential to achieve even better results .    </S>",
    "<S> graph matching , permutation matrix , doubly stochastic matrix , sampling strategy . </S>"
  ]
}