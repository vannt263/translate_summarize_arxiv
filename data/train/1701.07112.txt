{
  "article_text": [
    "[ [ improving - upon - the - error - correction - performance - of - reed - solomon - codes . ] ] improving upon the error correction performance of reed - solomon codes .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    reed - solomon codes are among the most extensively used error correcting codes .",
    "it has long been known how to decode them up to half the minimum distance .",
    "this gives a decoding algorithm that is able to correct a fraction @xmath2 of errors in a reed - solomon code of rate @xmath3 .",
    "however , it is only in the late nineties that a breakthrough was obtained in this setting with sudan s algorithm @xcite and its improvement in @xcite who showed how to go beyond this barrier with an algorithm which in its @xcite version decodes any fraction of errors smaller than @xmath4 .",
    "this exceeds the minimum distance bound @xmath2 in the whole region of rates @xmath5 .",
    "later on , it was shown that this decoding algorithm could also be modified a little bit in order to cope with soft information on the errors @xcite .",
    "a few years later , it was also realized by parvaresh and vardy in @xcite that by a slight modification of reed - solomon codes and by an increase of the alphabet size it was possible to beat the @xmath6 decoding radius .",
    "their new family of codes is list decodable beyond this radius for low rate .",
    "then , guruswami and rudra @xcite improved on these codes by presenting a new family of codes , namely _ folded reed - solomon codes _ with a polynomial time decoding algorithm achieving the list decoding capacity @xmath7 for every rate @xmath3 and @xmath8 .",
    "the initial motivation of this paper is to present another modification of reed - solomon codes that improves the fraction of errors that can be corrected .",
    "it consists in using them in a @xmath0 construction .",
    "in other words , we choose in this construction @xmath9 and @xmath10 to be reed - solomon codes .",
    "we will show that , in the low rate regime , this class of codes outperforms a little bit a reed - solomon code decoded with the guruswami and sudan decoder .",
    "the point is that this @xmath0 code can be decoded in two steps :    1 .",
    "first by subtracting the left part @xmath11 to the right part @xmath12 of the received vector @xmath13 and decoding it with respect to @xmath10 .",
    "in such a case , we are left with decoding a reed - solomon code with about twice as many errors .",
    "secondly , once we have recovered the right part @xmath14 of the codeword , we can get a word @xmath15 which should match two copies of a same word @xmath16 of @xmath9 .",
    "we can model this decoding problem by having some soft information on the received word when we have sent @xmath16 .",
    "it turns that this channel error model is much less noisy than the original @xmath17-ary symmetric channel we started with .",
    "this soft information can be used in koetter and vardy s decoding algorithm . by this",
    "means we can choose @xmath9 to be a reed - solomon code of much bigger rate than @xmath10 .",
    "all in all , it turns out that by choosing @xmath9 and @xmath10 with appropriate rates we can beat the @xmath4 bound of reed - solomon codes in the low - rate regime .",
    "it should be noted however that beating this @xmath18 bound comes at the cost of having now an algorithm which does not work as for the aforementioned papers @xcite for every error of a given weight ( the so called adversarial error model ) but with probability @xmath19 for errors of a given weight .",
    "however contrarily to @xcite which results in a significant increase of the alphabet size of the code , our alphabet size actually decreases when compared to a reed - solomon code : it can be half of the code length and can be even smaller when we apply this construction recursively .",
    "indeed , we will show that we can even improve the error correction performances by applying this construction again to the @xmath9 and @xmath10 components , i.e we can choose @xmath9 to be a @xmath20 code and we replace in the same way the reed - solomon code @xmath10 by a @xmath21 code where @xmath22 and @xmath23 are reed - solomon codes ( we will say that these @xmath24 s and @xmath25 s codes are the consituent codes of the iterated @xmath0-construction ) .",
    "this improves slightly the decoding performances again in the low rate regime .",
    "[ [ attaining - the - capacity - by - letting - the - depth - of - the - construction - go - to - infinity - with - an - exponential - decay - of - the - probability - of - error - after - decoding . ] ] attaining the capacity by letting the depth of the construction go to infinity with an exponential decay of the probability of error after decoding .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the first question raised by these results is to understand what happens when we apply this iterative construction a number of times which goes to infinity with the codelength . in this case , the channels faced by the constituent reed - solomon codes polarize : they become either very noisy channels or very clean channels of capacity close to @xmath1 .",
    "this is precisely the polarization phenomenon discovered by arikan in @xcite .",
    "indeed this iterated @xmath0-construction is nothing but a standard polar code when the constituent codes are reed - solomon codes of length @xmath1 ( i.e. just a single symbol ) .",
    "the polarization phenomenon together with a result proving that the koetter - vardy decoder is able to operate sucessfully at rates close to @xmath1 for channels of capacity close to @xmath1 can be used to show that it is possible to choose the rates of the constituent reed - solomon codes in such a way that the code construction together with the koetter - vardy decoder is able to attain the capacity of symmetric channels . on a theoretical level , proceeding in this way would not change however the asymptotics of the decay of the probability of error after decoding : the codes obtained in this way would still behave as polar codes and would in particular have a probability of error which decays exponentially with respect to ( essentially ) the square root of the codelength .",
    "the situation changes completely however when we allow ourself to change the input alphabet of the channel and/or to use algebraic geometry ( ag ) codes .",
    "the first point can be achieved by grouping together the symbols and view them as a symbol of a larger alphabet .",
    "the second point is also relevant here since the koetter and vardy decoder also applies to ag codes ( see @xcite ) with only a rather mild penalty in the error - correction capacity related to the genus of the curve used for constructing the code .",
    "both approaches can be used to overcome the limitation of having constituent codes in the iterated @xmath0-construction whose length is upper - bounded by the alphabet size .",
    "when we are allowed to choose long enough constituent codes the asymptotic behavior changes radically . we will indeed show that if we insist on using reed - solomon codes in the code construction we obtain a quasi - exponential decay of the probability of error in terms of the codelength ( i.e. exponential if we forget about the logarithmc terms in the exponent ) and an exponential decay if we use the right ag codes .",
    "this improves very significantly upon polar codes .",
    "not only are we able to attain the channel capacity with a polynomial time decoding algorithm with this approach but we are also able to do so with an exponential decay of the probability of error after decoding .",
    "in essence , this sharp decay of the probability of error after decoding is due to a result of this paper ( see theorems [ th : exponential ] and [ th : exponentialag ] ) showing that even if the koetter - vardy decoder is not able to attain the capacity with a probability of error going to zero as the codelength goes to infinity its probability of error decays like @xmath26 where @xmath27 is the codelength and @xmath28 is the difference between a quantity which is strictly smaller than the capacity of the channel and the code - rate .",
    "* notation .",
    "* throughout the paper we will use the following notation .    * a linear code of length @xmath27 , dimension @xmath29 and distance @xmath30 over a finite field @xmath31",
    "is referred to as an @xmath32_q$]-code .",
    "* the concatenation of two vectors @xmath33 and @xmath34 is denoted by @xmath35 . * for a vector @xmath33 we either denote by @xmath36 or by @xmath37 the @xmath38-th coordinate of @xmath33 .",
    "we use the first notation when the subscript is already used for other purposes or when there is already a superscript for @xmath33 . * for a vector @xmath39 we denote by @xmath40 the vector @xmath41 . * for a matrix @xmath42 we denote by @xmath43 the @xmath44-th column of @xmath42 . * by some abuse of terminology , we also view a discrete memoryless channel @xmath45 with input alphabet @xmath46 and output alphabet @xmath47 as an @xmath48 matrix whose @xmath49 entry is denoted by @xmath50 which is defined as the probability of receiving @xmath51 given that @xmath52 was sent .",
    "we will identify the channel with this matrix later on .",
    "* iterated @xmath0 codes . *",
    "this section details the code construction we deal with .",
    "it can be seen as a variation of polar codes and is nothing but an iterated @xmath0 code construction .",
    "we first recall the definition of a @xmath0 code .",
    "we refer to ( * ? ? ?",
    "* th.33 ) for the statements on the dimension and minimum distance that are given below .",
    "let @xmath9 and @xmath10 be two codes of the same length and defined over the same finite field @xmath53 .",
    "we define the @xmath54-construction of @xmath9 and @xmath10 as the linear code : @xmath55 the dimension of the @xmath0 code is @xmath56 and its minimum distance is @xmath57 when the dimensions of @xmath9 and @xmath10 are @xmath58 and @xmath59 respectively , the minimum distance of @xmath9 is @xmath60 and the minimum distance of @xmath10 is @xmath61 .",
    "the codes we are going to consider here are iterated @xmath0 constructions defined by    [ def : iterated_uv ] an iterated @xmath0-code @xmath62 of depth @xmath63 is defined from a set of @xmath64 codes @xmath65 which have all the same length and are defined over the same finite field @xmath53 by using the recursive definition @xmath66 the codes @xmath67 for @xmath68 are called the _ constituent codes _ of the construction .    in other words , an iterated @xmath0-code of depth",
    "@xmath1 is nothing but a standard @xmath0-code and an iterated @xmath0-code of depth @xmath69 is a @xmath0-code where @xmath9 and @xmath10 are themselves @xmath0-codes .    *",
    "graphical representation of an iterated @xmath0 code .",
    "* iterated @xmath0-codes can be represented by complete binary trees in which each node has exactly two children except the leaves .",
    "a @xmath0-code is represented by a node with two childs , the left child representing the @xmath9 code and the right child representing the @xmath10 code .",
    "the simplest case is given is given in figure [ fig : uv ] .",
    "another example is given in figure [ fig : example ] and represents an iterated @xmath0-code @xmath62 of depth @xmath70 with a binary tree of depth @xmath70 whose leaves are the @xmath71 constituent codes of this construction .",
    "[ fig : uv],width=151 ]     code of depth @xmath70 .",
    "[ fig : example],width=302 ]    standard polar codes ( i.e. the ones that were constructed by arikan in @xcite ) are clearly a special case of the iterated @xmath0 construction .",
    "indeed such a polar code of length @xmath64 can be viewed as an iterated @xmath0-code of depth @xmath63 where the set @xmath65 of constituent codes are just codes of length @xmath1 . in other words ,",
    "standard polar codes correspond to binary trees where all leaves are just single bits .",
    "* recursive soft decoding of an iterated @xmath0-code .",
    "* as explained in the introduction our approach is to use the same decoding strategy as for arikan polar codes ( that is his successive cancellation decoder ) but by using now leaves that are codes which are much longer than single symbols .",
    "this will have the effect of lowering rather significantly the error probability of error after decoding when compared to standard polar codes .",
    "it will be helpful to change slightly the way the successive cancellation decoder is generally explained .",
    "indeed this decoder can be viewed as an iterated decoder for a @xmath0-code , where decoding the @xmath0-code consists in first decoding the @xmath10 code and then the @xmath9 code with a decoder using soft information in both cases .",
    "this decoder was actually considered before the invention of polar codes and has been considered for decoding for instance reed - muller codes based on the fact that they are @xmath0 codes @xcite .",
    "let us recall how such a @xmath0-decoder works .",
    "suppose we transmit the codeword @xmath72 over a noisy channel and we receive the vector : @xmath73 .",
    "we denote by @xmath74 the probability of receiving @xmath75 when @xmath76 was sent and assume a memoryless channel here .",
    "we also assume that all the codeword symbols @xmath77 and @xmath78 are uniformly distributed .    *",
    "we first decode @xmath10 .",
    "we compute the probabilities @xmath79 for all positions @xmath38 and all @xmath80 in @xmath53 . under the assumption that we use a memoryless channel and that the @xmath77 s and the @xmath78 s are uniformly distributed for all @xmath38 ,",
    "it is straightforward to check that this probability is given by @xmath81 * we use now arikan s successive decoding approach and assume that the @xmath10 decoder was correct and thus we have recovered @xmath82 .",
    "we compute now for all @xmath83 and all coordinates @xmath38 the probabilities @xmath84 by using the formula @xmath85 this can be considered as soft - information on @xmath86 which can be used by a soft information decoder for @xmath9 .",
    "this decoder can then be used recursively for decoding an iterated @xmath0-code .",
    "for instance if we denote by @xmath62 an iterated @xmath0-code of depth @xmath69 derived from the set of codes @xmath87 , the decoding works as follows ( we used here the same notation as in definition [ def : iterated_uv ] ) .    * * decoder for @xmath88*. we first compute the probabilities for decoding @xmath89 , this code is decoded with a soft information decoder .",
    "once we have recovered the @xmath89 part ( we denote the corresponding codeword by @xmath90 ) , we can compute the relevant probabilities for decoding the @xmath91 code .",
    "this code is also decoded with a soft information decoder and we output a codeword @xmath92 .",
    "all this work allows to recover the @xmath93 codeword denoted by @xmath94 by combining the @xmath91 and @xmath89 part as @xmath95 . * * decoder for @xmath96*. once the @xmath93 codeword is recovered we can compute the probabilities for decoding the code @xmath97 and we decode this code in the same way as we decoded the code @xmath93 .",
    "figure [ fig : order ] gives the order in which we recover each codeword during the decoding process .",
    "code of depth @xmath69 .",
    "nodes in red represent codes that are decoded with a soft information decoder , nodes in black correspond to codes that are not decoded directly and whose decoding is accomplished by first recovering the two descendants of the node and then combining them to recover the codeword we are looking for at this node.[fig : order],width=302 ]    when the constituent codes of this recursive @xmath0 construction are just codes of length @xmath1 , it is readily seen that this decoding simply amounts to the successive cancellation decoder of arikan .",
    "we will be interested in the case where these constituent codes are longer than this .",
    "in such a case , we have to use as constituent codes , codes for which we have an efficient but possibly suboptimal decoder which can make use of soft information .",
    "reed - solomon codes or algebraic geometry codes with the koetter vardy decoder are precisely codes with this kind of property",
    ".    * polarization . * the probability computations made during the @xmath0 decoding and correspond in a natural way to changing the channel model for the @xmath9 code and for the @xmath10 code .",
    "these two channels really correspond to the two channel combining models considered for polar codes .",
    "more precisely , if we consider a memoryless channel of input alphabet @xmath53 and output alphabet @xmath47 defined by a transition matrix @xmath98 , then the channel viewed by the @xmath9 decoder , respectively the @xmath10 decoder is a memoryless channel with transition matrix @xmath99 and @xmath100 respectively , which are given by @xmath101 here the @xmath102 s belong to @xmath47 and the @xmath103 s belong to @xmath53 .",
    "if we define the channel @xmath104 for @xmath105 recursively by @xmath106 then the channel viewed by the decoder for one of the constituent codes @xmath107 of an iterated @xmath0 code of depth @xmath27 ( with the notation of definition [ def : iterated_uv ] ) is nothing but the channel @xmath108 .",
    "the key result used for showing that polar codes attain the capacity is that these channels polarize in the following sense    [ ( * ? ? ?",
    "* theorem 1 ) and ( * ? ? ?",
    "* theorem 4.10)][th : polarization ] let @xmath17 be an arbitrary prime . then for a discrete @xmath17-ary input channel @xmath45 of symmetric capacity , where @xmath47 denotes the output alphabet of the channel .",
    "] @xmath109 we have for all @xmath110 @xmath111 where @xmath112 .    here",
    "@xmath113 denotes the bhattacharyya parameter of @xmath45 which is assumed to be a memoryless channel with @xmath17-ary inputs and outputs in an alphabet @xmath47 .",
    "it is given by @xmath114 recall that this bhattacharrya parameter quantifies the amount of noise in the channel .",
    "it is close to @xmath115 for channels with very low noise ( i.e. channels of capacity close to @xmath1 ) whereas it is close to @xmath1 for very noisy channels ( i.e. channels of capacity close to @xmath115 ) .",
    "it has been a long standing open problem to obtain an efficient soft - decision decoding algorithm for reed - solomon codes until koetter and vardy showed in @xcite how to modify appropriately the guruswami - sudan decoding algorithm in order to achieve this purpose .",
    "the complexity of this algorithm is polynomial and we will show here that the probability of error decreases exponentially in the codelength when the noise level is below a certain threshold .",
    "let us first review a few basic facts about this decoding algorithm .",
    "[ [ the - reliability - matrix . ] ] * the reliability matrix . *",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    the koetter - vardy decoder @xcite is based on a _ reliability matrix _ @xmath116 of the codeword symbols @xmath117 computed from the knowledge of the received word @xmath34 and which is defined by @xmath118 recall that the @xmath44-th column of this matrix @xmath116 is denoted by @xmath119 .",
    "it gives the a posteriori probabilities ( app ) that the @xmath44-th codeword symbol is equal to @xmath80 where @xmath80 ranges over @xmath53 .",
    "we will be particularly interested in the @xmath17-ary symmetric channel model .",
    "the @xmath17-ary symmetric channel with error probability @xmath120 , denoted by @xmath121 , takes a @xmath17-ary symbol at its input and outputs either the unchanged symbol , with probability @xmath122 , or any of the other @xmath123 symbols , with probability @xmath124 . therefore ,",
    "if the channel input symbols are uniformly distributed , the reliability matrix @xmath125 for @xmath126 is given by    @xmath127    thus , all columns of @xmath125 are identical up to permutation : @xmath128 with @xmath129 .",
    "this matrix is used by the koetter - vardy decoder to compute a multiplicity matrix that serves as the input to its soft interpolation step . when used in a @xmath0 construction and decoded as mentioned before , we will need to understand how the reliability matrix behaves through the @xmath0 decoding process .",
    "this is what we will do now .",
    "[ [ reliability - matrix - for - the - v - decoder . ] ] * reliability matrix for the @xmath10-decoder .",
    "* + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we denote the reliability matrix of the @xmath10 decoder by @xmath130 when @xmath131 and @xmath132 are the initial reliability matrices corresponding to the two halves of the received word @xmath133 . from the definition of the reliability matrix and we readily obtain that @xmath134    [ [ reliability - matrix - for - the - u - decoder ] ] * reliability matrix for the @xmath9-decoder * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    similarly , by using we see that the reliability matrix of the @xmath9 decoder , that we denote by @xmath135 is given by @xmath136 to simplify notation we will generally avoid the dependency on @xmath34 and @xmath82 and simply write @xmath137 and @xmath138 .    [ [ when - does - the - koetter - vardy - decoding - algorithm - succeed ] ] * when does the koetter - vardy decoding algorithm succeed ? * + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let us recall how the koetter - vardy soft decoder @xcite can be analyzed . by (",
    "* theorem 12 ) their decoding algorithm outputs a list that contains the codeword @xmath139 if @xmath140 as the codelength @xmath27 tends to infinity , where @xmath141 represents a @xmath142 matrix with entries @xmath143 if @xmath144 , and @xmath115 otherwise ; and @xmath145 denotes the inner product of the two @xmath142 matrices @xmath146 and @xmath147 , i.e. @xmath148 the algorithm uses a parameter @xmath149 ( the total number of interpolation points counted with multiplicity ) .",
    "the little - o @xmath150 depends on the choice of this parameter and the parameters @xmath27 and @xmath17 .",
    "we need a more precise formulation of the little - o of ( [ eq : success ] ) to understand that we can get arbitrarily close to the lower bound @xmath151 with polynomial complexity . in order to do so ,",
    "let us provide more details about the koetter vardy decoding algorithm .",
    "basically this algorithm starts by computing with algorithm a of @xcite from the knowledge of the reliability matrix @xmath152 and for the aforementioned integer parameter @xmath149 a @xmath153 nonnegative integer matrix @xmath154 whose entries sum up to @xmath149 .",
    "when @xmath149 goes to infinity @xmath154 becomes proportional to @xmath152 .",
    "the cost of this matrix ( we will drop the dependency in @xmath149 ) @xmath155 is defined as    @xmath156    where @xmath157 denotes the entry of @xmath42 at row @xmath38 and column @xmath44 and @xmath158 is the all - one matrix .",
    "the complexity of the koetter - vardy decoding algorithm is dominated by solving a system of @xmath155 linear equations . then , the number of codewords on the list produced by the koetter - vardy decoder for a given multiplicity matrix @xmath42 does not exceed @xmath159 it is straightforward to obtain from these considerations a soft - decision list decoder with a list which does not exceed some prescribed quantity @xmath160 .",
    "indeed it suffices to increase the value of @xmath149 in ( * ? ? ?",
    "* algorithm a ) until getting a matrix @xmath42 which is such that @xmath161 and to use this multiplicity matrix @xmath42 in the koetter - vardy decoding algorithm . by following the terminology of @xcite",
    "we refer to this decoding procedure as _ algebraic soft - decoding with list size limited to @xmath160_. ( * ? ? ?",
    "* theorem 17 ) explains that convergence to the @xmath151 lower - bound is at least as fast as @xmath162    [ th : loose ] algebraic soft - decoding with list size limited to @xmath160 produces a codeword @xmath163 if @xmath164 where @xmath165 and the constant in @xmath166 depends only on @xmath167 and @xmath17 .    1 .",
    "this theorem shows that the size of the list required to approach the asymptotic performance does not depend ( directly ) on the length of the code , it may depend on the rate of the code and the cardinality of the alphabet though .",
    "as observed in @xcite , this theorem is a very loose bound .",
    "the actual performance of algebraic soft - decoding with list size limited to @xmath160 is usually orders of magnitude better than that predicted by .",
    "a somewhat better bound is given by ( * ? ? ?",
    "* ( 44 ) p. 2819 ) where the condition for successful decoding @xmath163 is @xmath168 where the approximation assumes that @xmath169 which holds for noise levels of practical interest .",
    "note that this strengthens a little bit the constant in @xmath166 that appears in theorem [ th : loose ] , since it would not depend on @xmath17 anymore .",
    "[ [ decoding - capability - of - the - koetter - vardy - decoder - when - the - channel - is - symmetric . ] ] * decoding capability of the koetter - vardy decoder when the channel is symmetric .",
    "* + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the previous formula does not explain directly under which condition on the rate of the reed - solomon code decoding typically succeeds ( in some sense this would be a `` capacity '' result for the koetter - vardy decoder ) .",
    "we will derive now such a result that appears to be new ( but see the discussion at the end of this section )",
    ". it will be convenient to restrict a little bit the class of memoryless channels we will consider- this will simplify formulas a great deal .",
    "the idea underlying this restriction is to make the behavior of the quantity @xmath170 which appears in the condition of successful decoding independent of the codeword @xmath163 which is sent .",
    "this is readily obtained by restricting the channel to be _",
    "weakly symmetric_.    [ def : weakly_symmetric ] a discrete memoryless @xmath45 with input alphabet @xmath46 and output alphabet @xmath47 is said to be weakly symmetric if and only if there is a partition of the output alphabet @xmath171 such that all the submatrices @xmath172 are symmetric .",
    "a matrix is said to be symmetric if all if its rows are permutations of each other , and all its columns are permutations of each other .",
    "_ remarks . _",
    "+    * such a channel is called _ symmetric _ in @xcite .",
    "we avoid using the same terminology as gallager since `` symmetric channel '' is generally used now to denote a channel for which any row is a permutation of each other row and the same property also holds for the columns . *",
    "this notion is a generalization ( when the output alphabet is discrete ) of what is called a binary input symmetric channel in @xcite .",
    "it also generalizes the notion of a cyclic symmetric channel in @xcite . *",
    "it is shown that for such channels ( * ? ? ?",
    "4.5.2 ) a uniform distribution on the inputs maximizes the mutual information between the output and the input of the channel and gives therefore its capacity .",
    "in such a case , linear codes attain the capacity of such a channel . *",
    "this notion captures the notion of symmetry of a channel in a very broad sense .",
    "in particular the erasure channel is weakly symmetric ( for many definitions of `` symmetric channels '' an erasure channel is not symmetric ) .",
    "we denote for such a channel and for a given output @xmath51 by @xmath173 the associated app vector , that is @xmath174 where we denote by @xmath52 the input symbol to the channel .    to compute this app vector we will make throughout the paper the following assumption    the input of the communication channel",
    "is assumed to be uniformly distributed over @xmath53 .",
    "we give now the asymptotic behavior of the koetter - vardy decoder for a weakly symmetric channel , but before doing this we will need a few lemmas .    [",
    "lem : simple_formula ] assume that @xmath52 is the input symbol that was sent and that the communication is weakly symmetric , then by viewing @xmath175 as a function of the random variable @xmath51 we have for any @xmath176 : @xmath177    to prove this result , let us introduce some notation .",
    "let us denote by    * @xmath47 the output alphabet and @xmath178 is a partition of @xmath47 such that all the submatrices @xmath172 are symmetric for @xmath129 . *",
    "@xmath179 and @xmath180 where @xmath51 is arbitrary in @xmath181 ( these quantities do not depend on the element @xmath51 chosen in @xmath181 ) ; * @xmath182 and @xmath183 where @xmath52 is arbitrary in @xmath53 .",
    "we observe now that from the assumption that @xmath52 was uniformly distributed @xmath184 we observe now that @xmath185 where the second equality is due to .    on the other hand @xmath186 where the second equality is due to .    by summing all the elements ( or the square of the elements ) of the symmetric matrix @xmath187",
    "either by columns or by rows and since all these row sums or all these column sums are equal , we obtain that @xmath188 and @xmath189    by using these two equalities in we obtain @xmath190 this yields the same expression as the one for @xmath191 given in .",
    "as we will now show , this quantity @xmath192 turns out to be the limit of the rate for which the koetter - vardy decoder succeeds in decoding when the alphabet gets large .",
    "for this reason , we will denote this quantity by the _ koetter - vardy capacity _ of the channel .    consider a weakly symmetric channel and denote by @xmath175 the associated probability vector .",
    "the koetter - vardy capacity of this channel , which we denote by @xmath193 , is defined by @xmath194    to prove that this quantity captures the rate at which the koetter - vardy is successful ( at least for large lengths and therefore large field size ) let us first prove concentration results around the expectation for the numerator and denominator appearing in the left - hand term of .",
    "[ lem : concentration ] let @xmath195 and @xmath196 .",
    "we have @xmath197    let us first prove .",
    "we can write the left - hand term as a sum of @xmath27 i.i.d .",
    "random variables @xmath198 where @xmath199 .",
    "note that ( i ) @xmath200 , ( ii ) @xmath201 . by using hoeffding s inequality",
    "we obtain that for any @xmath202 we have @xmath203    now can be dealt with in a similar way by writing @xmath204 where @xmath205 . the channel is assumed to be symmetric and we can therefore use lemma [ lem : simple_formula ] from which we deduce that @xmath206 .",
    "we also have @xmath207 and by applying hoeffding s inequality we obtain that for any @xmath202 we have @xmath208    this result can be used to derive a rather tight upper - bound on the probability of error of the koetter - vardy decoder .",
    "[ th : exponential ] consider a weakly symmetric @xmath17-ary input channel of koetter - vardy capacity @xmath193 .",
    "consider a reed - solomon code over @xmath53 of length @xmath27 , dimension @xmath29 such that its rate @xmath209 satisfies @xmath210 .",
    "let @xmath211 the probability that the koetter - vardy decoder with list size bounded by @xmath160 does not output in its list the right codeword is upper - bounded by @xmath212 for some constant @xmath213 .",
    "without loss of generality we can assume that the all - zero codeword @xmath214 was sent . from theorem [ th : loose",
    "] , we know that the koetter - vardy decoder succeeds if and only if the following condition is met @xmath215 notice that the right - hand side satisfies @xmath216    let @xmath28 be a positive constant that we are going to choose afterward . define the events @xmath217 and @xmath218 by @xmath219 note that by lemma [ lem : concentration ] the events @xmath217 and @xmath218 have both probability @xmath220 where @xmath221 .",
    "thus , the probability that event @xmath217 and event @xmath218 both occur is @xmath222 in the case @xmath217 and @xmath218 both hold , we have @xmath223 a straightforward computation shows that for any @xmath224 we have @xmath225 therefore for @xmath226 we have in the aforementioned case @xmath227    let us choose now @xmath28 such that @xmath228 note that @xmath229 .",
    "this choice implies that @xmath230 where we used in the last inequality the bound given in .    in other words , the koetter vardy decoder outputs the codeword @xmath214 in its list .",
    "the probability that this does not happen is at most @xmath231 .",
    "an immediate corollary of this theorem is the following result that gives a ( tight ) lower bound on the error - correction capacity of the koetter - vardy decoding algorithm over a discrete memoryless channel .",
    "[ cor : kvp ] let @xmath232 be an infinite family of reed - solomon codes of rate @xmath233 . denote by @xmath234 the alphabet size of @xmath235 that is assumed to be a non decreasing sequence that goes to infinity with @xmath27 . consider an infinite family of @xmath234-ary weakly symmetric channels with associated probability error vectors @xmath236 such that @xmath237 has a limit as @xmath27 tends to infinity",
    ". denote by @xmath238 the asymptotic koetter - vardy capacity of these channels , i.e. @xmath239 this infinite family of codes can be decoded correctly by the koetter - vardy decoding algorithm with probability @xmath19 as @xmath27 tends to infinity as soon as there exists @xmath8 such that @xmath240    [ rem - uv-1 ] let us observe that for the @xmath121 we have @xmath241 by letting @xmath17 going to infinity , we recover in this way the performance of the guruswami - sudan algorithm which works as soon as @xmath242 .",
    "* link with the results presented in @xcite and @xcite . * in ( * ? ? ?",
    "v.b eq . ( 32 ) ) an arbitrarily small upper bound on the error probability @xmath243 is given , it is namely explained that @xmath244 as soon as the rate @xmath3 and the length @xmath27 of the reed - solomon code satisfy @xmath245 ( where the expectation is taken with respect to the _ a posteriori _ probability distribution of the codeword ) . here",
    "@xmath246 is some function of the multiplicity matrix which itself depends on the received word .",
    "this is not a bound of the same form as the one given in theorem [ th : exponential ] whose upper - bound on the error probability only depends on some well defined quantities which govern the complexity of the algorithm ( such as the size @xmath17 of the field over which the reed - solomon code is defined and a bound on the list - size ) and the koetter - vardy capacity of the channel .",
    "however , many more details are given in the preprint version @xcite of @xcite in section 9 .",
    "there is for instance implicitly in the proof of theorem 27 in ( * ? ? ?",
    "9 ) an upper - bound on the error probability of decoding a reed - solomon code with the koetter - vardy decoder which goes to zero polynomially fast in the length as long as the rate is less than @xmath247 where @xmath45 is the transition probability matrix of the channel and @xmath248 is the @xmath249 matrix which is zero except on the diagonal where the diagonal elements give the probability distribution of the output of the channel when the input is uniformly distributed .",
    "it is readily verified that in the case of a weakly symmetric channel @xmath109 is nothing but the koetter - vardy capacity of the channel defined here .",
    "@xmath109 can be viewed as a more general definition of the `` capacity '' of a channel adapted to the koetter - vardy decoding algorithm .",
    "however it should be said that `` error - probability '' in @xcite should be understood here as `` average error probability of error '' where the average is taken over the set of codewords of the code .",
    "it should be said that this average may vary wildly among the codewords in the case of a non - symmetric channel . in order to avoid this ,",
    "we have chosen a different route here and have assumed some weak form of symmetry for the channel which ensures that the probability of error does not depend on the codeword which is sent .",
    "the authors of @xcite use a second moment method to bound the error probability , this can only give polynomial upper - bounds on the error probability .",
    "this is why we have also used a slightly different route in theorem [ th : exponential ] to obtain stronger ( i.e. exponentially small ) upper - bounds on the error probability .",
    "the problem with reed - solomon codes is that their length is limited by the alphabet size . to overcome this limitation it is possible to proceed as in @xcite and use instead algebraic - geometric codes ( ag codes in short ) which can also be decoded by an extension of the koetter - vardy algorithm and which have more or less a similar error correction capacity as reed - solomon codes under this decoding strategy .",
    "the extension of this decoding algorithm to ag codes is sketched in section [ sec : kv_ag ] .",
    "let us first recall how these codes are defined .",
    "an ag code is constructed from a triple @xmath250 where :    * @xmath46 denotes an algebraic curve over a finite field @xmath53 ( we refer to @xcite for more information about algebraic geometry codes ) ; * @xmath251 denotes a set of @xmath27 distinct points of @xmath46 with coordinates in @xmath53 ; * @xmath252 is a divisor of the curve , here @xmath253 denotes another point in @xmath46 with coordinates in @xmath53 which is not in @xmath254 and @xmath255 is a nonnegative integer .",
    "we define @xmath256 as the vector space of rational functions on @xmath46 that may contain only a pole at @xmath253 and the multiplicity of this pole is at most @xmath255 .",
    "then , the _ algebraic geometry _",
    "code associated to the above triple denoted by @xmath257 is the image of @xmath256 under the evaluation map @xmath258 defined by @xmath259 , i.e. @xmath260 since the evaluation map is linear , the code @xmath257 is a linear code of length @xmath27 over @xmath53 and dimension @xmath261 .",
    "this dimension can be lower bounded by @xmath262 where @xmath263 is the genus of the curve . recall that this quantity is defined by @xmath264 moreover the minimum distance @xmath30 of this code satisfies @xmath265 .",
    "reed - solomon codes are a particular case of the family of ag codes and correspond to the case where @xmath46 is the affine line over @xmath53 , @xmath266 are @xmath27 distinct elements of @xmath53 and @xmath267 is the vector space of polynomials of degree at most @xmath268 and with coefficients in @xmath53 .",
    "recall that it is possible to obtain for any designed rate @xmath269 and any square prime power @xmath17 an infinite family of ag codes over @xmath53 of rate @xmath270 of increasing length @xmath27 and minimum distance @xmath30 meeting `` asymptotically '' the mds bound as @xmath17 goes to infinity @xmath271 this follows directly from the two aforementioned lower bounds @xmath262 and @xmath272 and the well known result of tsfasman , vlduts and zink @xcite    [ th : tvz ] for any number @xmath273 $ ] and any square prime power @xmath17 there exists an infinite family of ag codes over @xmath53 of rate @xmath270 of increasing length @xmath27 such that the normalized genus @xmath274 of the underlying curve satisfies @xmath275    we will call such codes _ tsfasman - vlduts - zink _ ag codes in what follows .    as is done in @xcite , it will be helpful to assume that @xmath276 .",
    "this implies among other things that the dimension of the code is given my @xmath277 .",
    "we will make this assumption from now on . as in @xcite",
    "it is possible to obtain a soft - decision list decoder with a list which does not exceed some prescribed quantity @xmath160 .",
    "similar to the reed- solomon case considered in @xcite , it suffices to increase the value of @xmath149 in @xcite[algorithm a ] until we get a matrix @xmath42 such that @xmath278 , where @xmath279 is a bound on the list of the codewords output by the algorithm which is given in lemma [ ag-1 ] , and then to use this matrix @xmath42 in the koetter vardy decoding algorithm .",
    "the following result is similar to ( * ? ? ?",
    "17 )    [ th : listsize_ag ] algebraic soft - decoding for ag codes with list - size limited to @xmath160 produces a list that contains a codeword @xmath280 if @xmath281 where @xmath282 , @xmath283 and @xmath284 depends only on @xmath285 , @xmath286 and @xmath17 .",
    "the proof of this theorem can be found in section [ sec : kv_ag ] of the appendix .",
    "it heavily relies on results proved in the preprint version @xcite of @xcite .",
    "[ th : exponentialag ] consider a weakly symmetric @xmath17-ary input channel of koetter - vardy capacity @xmath193 where @xmath17 is a square prime power .",
    "consider a tsfasman - vlduts - zink ag code over @xmath53 of length @xmath27 , dimension @xmath29 such that its rate @xmath209 satisfies @xmath287 where @xmath288 .",
    "let @xmath289 the probability that the koetter - vardy decoder with list size bounded by @xmath160 does not output in its list the right codeword is upper - bounded by @xmath290 for some constant @xmath213 .",
    "moreover @xmath291 as @xmath292 tends to zero .",
    "the proof follows word by word the proof of theorem [ th : exponential ] with the only difference that @xmath268 is replaced by @xmath293 .",
    "the only new ingredient is that we use theorem [ th : listsize_ag ] instead of which explains the new form chosen for the list - size @xmath160 . the last part , namely that @xmath291 is a simple consequence of the fact that @xmath294 as @xmath160 tends to infinity .",
    "the purpose of this section is to show that the @xmath0 construction improves significantly the noise level that the koetter - vardy decoder is able to correct . to be more specific ,",
    "consider the @xmath17-ary symmetric channel .",
    "the asymptotic koetter - vardy capacity of a family of @xmath17-ary symmetric channels of crossover probability @xmath120 is equal to @xmath295 .",
    "it turns out that this is also the maximum crossover probability that the guruswami - sudan decoder is able to sustain when the alphabet and the length go to infinity .",
    "we will prove here that the @xmath0 construction with reed - solomon components already performs a bit better than @xmath295 when the rate is small enough . by using iterated @xmath0 constructions we will be able to improve rather significantly the performances and this even for a moderate number of levels .",
    "our analysis of the koetter - vardy decoding is done for weakly symmetric channels .",
    "when we want to analyze a @xmath0 code based on reed - solomon codes used over a channel @xmath45 it will be helpful that the channels @xmath99 and @xmath100 viewed by the decoder of @xmath9 and @xmath10 respectively are also weakly symmetric .",
    "simple examples show that this is not necessarily the case .",
    "however a slight restriction of the notion of weakly symmetric channel considered in @xcite does the job .",
    "it consists in the notion of a cyclic - symmetric channel whose definition is given below .",
    "[ def : strictly_cyclic_symmetric ] we denote for a vector @xmath296 with coordinates indexed by a finite field @xmath53 by @xmath297 the vector @xmath298 , by @xmath299 the number of @xmath263 s in @xmath53 such that @xmath300 and by @xmath301 the set @xmath302 .",
    "a @xmath17-ary input channel is cyclic - symmetric channel if and only there exists a probability function @xmath253 defined over the sets of possible @xmath303 such that for any @xmath304 we have @xmath305    the point about this notion is that @xmath99 and @xmath100 stay cyclic - symmetric when @xmath45 is cyclic - symmetric and that a cyclic - symmetric channel is also weakly symmetric .",
    "this will allow to analyze the asymptotic error correction capacity of iterated @xmath0 constructions .",
    "[ pr : csc ] let @xmath45 be a cylic - symmetric channel . then @xmath45 is weakly symmetric and @xmath99 and @xmath100 are also cyclic - symmetric .",
    "we study here how a @xmath0 code performs when @xmath9 and @xmath10 are both reed - solomon codes decoded with the koetter - vardy decoding algorithm when the communication channel is a @xmath17-ary symmetric channel of error probability @xmath120 .",
    "[ uv-1 ] for any real @xmath120 in @xmath306 $ ] and real @xmath3 such that @xmath307 there exists an infinite family of @xmath0-codes of rate @xmath270 based on reed - solomon codes whose alphabet size @xmath17 increases with the length and whose probability of error on the @xmath126 when decoded by the iterated @xmath0-decoder based on the koetter - vardy decoding algorithm goes to @xmath115 with the alphabet size .",
    "the @xmath308-construction can be decoded correctly by the koetter - vardy decoding algorithm if it decodes correctly @xmath97 and @xmath93 .",
    "let @xmath309 be the app probability vector seen by the decoder for @xmath24 for @xmath310 .",
    "a @xmath126 is clearly a cyclic - symmetric channel and therefore the channel viewed by the @xmath97 decoder and the @xmath93 decoder are also cyclic - symmetric by proposition [ pr : csc ] .",
    "a cyclic - symmetric channel is weakly symmetric and therefore by corollary [ cor : kvp ] , decoding succeeds with probability @xmath19 when we choose the rate @xmath311 of @xmath24 to be any positive number below @xmath312 for @xmath310 .    in section [ appendix - uv ] of the appendix",
    "it is proved in lemmas [ l12 ] and [ l11 ] that @xmath313    since the rate @xmath3 of the @xmath0 construction is equal to @xmath314 decoding succeeds with probabilty @xmath315 if @xmath316    from figure [ twiceuv ] we deduce that the @xmath0 decoder outperforms the rs decoder with guruswami - sudan or koetter - vardy decoders as soon as @xmath317 .",
    "now we will study what happens over a @xmath17-ary symmetric channel with error probability @xmath120 if we apply the iterated @xmath0-construction with reed - solomon codes as constituent codes .",
    "in particular , the following result handles the cases of the iterated @xmath0-construction of depth @xmath69 and @xmath70 .",
    "[ uv-2 - 3 ] for any real @xmath120 in @xmath306 $ ] we define @xmath318 and @xmath319    then , for any real @xmath3 such that @xmath320 ( resp .",
    "@xmath321 ) there exists an infinite family of iterated @xmath0-codes of depth @xmath69 ( resp . of depth @xmath70 ) and rate @xmath322 based on reed - solomon codes whose alphabet size @xmath17 increases with the length and whose probability of error with the koetter - vardy decoding algorithm goes to @xmath115 with the alphabet size .    where    @xmath323    the proof is given in appendix [ appendix - uv2 ] and [ appendix - uv3 ] for iterated @xmath0 construction of depth @xmath69 and @xmath70 , respectively .",
    "figure [ twiceuv ] summarizes the performances of these iterated @xmath0-constructions from this figure we see that if we apply the iterated @xmath0-construction of depth @xmath69 we get better performance than decoding a classical reed - solomon code with the guruswami - sudan decoder for low rate codes , specifically for @xmath324 .",
    "moreover , if we apply the iterated @xmath0-construction of depth @xmath70 we get even better results , we beat the guruswami - sudan for codes of rate @xmath325 .     for four code - constructions",
    "the black line refers to standard reed - solomon codes decoded by the guruswami - sudan algorithm , the red line to the @xmath0-construction , the blue line to the iterated @xmath0-construction of depth @xmath69 and the green line to the iterated @xmath0-construction of depth @xmath70 .",
    "[ fig : infinite ] ]      even if for finite alphabet size @xmath17 the koetter - vardy capacity can not be understood as a capacity in the usual sense : no family of codes is known which could be decoded with the koetter - vardy decoding algorithm and whose probability of error would go to zero as the codelength goes to infinity at any rate below the koetter - vardy capacity .",
    "something like that is only true approximately for ag codes when the size of the alphabet is a square prime power and if we are willing to pay an additional term of @xmath326 in the gap between the koetter - vardy capacity and the actual code rate .",
    "actually , we can even be sure that for certain rates this result can not hold , since the koetter - vardy capacity can be above the shannon capacity for very noisy channels .",
    "consider for instance the `` completely - noisy '' @xmath17-ary symmetric channel of crossover probability @xmath327 .",
    "its capacity is @xmath115 whereas its koetter - vardy capacity is equal to @xmath328 .",
    "nevertheless it is still insightful to consider @xmath329 where @xmath330 is the channel viewed by the constituent @xmath24 code for an iterated-@xmath331 construction of depth @xmath63 for a given noisy channel .",
    "this could be considered as the limit for which we can not hope to have small probabilities of error after decoding when using reed - solomon codes constituent codes and the koetter - vardy decoding algorithm .",
    "we have plotted these functions in figure [ fig : finite_capacity ] for @xmath332 and @xmath333 up to @xmath334 and a @xmath126 .",
    "it can be seen that for @xmath335 we get rather close to the actual capacity of the channel in this way .     for seven code constructions .",
    "the noise model is a a @xmath126 .",
    "[ fig : finite_capacity ] . ]",
    "when the number of levels for which we iterate this construction tends to infinity , we attain the capacity of any @xmath17-ary symmetric channel at least when the cardinality @xmath17 is prime .",
    "this is a straighforward consequence of the fact that polar codes attain the capacity of any @xmath17-ary symmetric channel .",
    "moreover the probability of error after decoding can be made to be almost exponentially small with respect to the overall codelength .",
    "more precisely the aim of this section is to prove the following results about the probability of error .",
    "[ th : errprob1 ] let @xmath45 be a cyclic - symmetric @xmath17-ary channel where @xmath17 is prime .",
    "let @xmath109 be the capacity of this channel .",
    "there exists @xmath336 such that for any @xmath28 in the range @xmath337 and any @xmath338 in the range @xmath339 there exists a sequence of iterated @xmath0 codes with reed - solomon constituent codes of arbitrarily large length which have rate @xmath340 when the codelength is sufficiently large and whose probability of error @xmath243 is upper bounded by @xmath341 when decoded with the iterated @xmath0 decoder based on decoding the constituent codes with the koetter - vardy decoder with listsize bounded by @xmath342 and where @xmath343 is the codelength , @xmath344 , and @xmath345 is some positive function of @xmath28 and @xmath338 .    for the iterated @xmath0-construction with algebraic geometry codes as constituent codes we obtain an even stronger result which is    [ th : errprob2 ] let @xmath45 be a cyclic - symmetric @xmath17-ary channel where @xmath17 is prime .",
    "let @xmath109 be the capacity of this channel .",
    "there exists @xmath336 such that for any @xmath28 in the range @xmath337 there exists a sequence of iterated @xmath0 codes of arbitrarily large length with ag defining codes of rate @xmath340 when the codelength is sufficiently large and whose probability of error @xmath243 is upper bounded by @xmath346 when decoded with the iterated @xmath0 decoder based on the koetter - vardy algorithm with listsize bounded by @xmath342 and where @xmath213 is some positive function of @xmath28 .",
    "_ remarks : _    * in other words",
    "the exponent of the error probability is in the first case ( that is with reed - solomon codes ) almost of the form @xmath347 where @xmath28 is an arbitrary positive constant .",
    "this is significantly better than the concatenation of polar codes with reed - solomon codes ( see ( * ? ? ?",
    "* th . 1 ) and also @xcite for some more practical variation of this construction ) which leads to an exponent of the form @xmath348 . *",
    "the second case leads to a linear exponent and is therefore optimal up to the dependency in @xmath28 . *",
    "both results are heavily based on the fact that when the depth of the construction tends to infinity the channels viewed by the decoders at the leaves of the iterated construction polarize : they have either capacity close to @xmath1 or close to @xmath115 .",
    "this follows from a generalization of arikan s polarization result on binary input channels .",
    "this requires @xmath17 to be prime .",
    "however it is possible to change slightly the @xmath0 structure in order to have polarization for all alphabet sizes .",
    "taking for instance in the case where @xmath17 is a prime power at each node instead of the @xmath0 construction a random @xmath349 where @xmath80 is chosen randomly in @xmath350 would be sufficient here for ensuring polarization of the corresponding channels and would ensure that our results on the probability or error of the iterated construction would also work in this case .",
    "* the reason why these results do not capture the dependency in @xmath28 of the exponent comes from the fact that only rather rough results on polarization are used ( we rely namely on theorem [ th : polarization ] ) .",
    "capturing the dependency on @xmath28 really needs much more precise results on polarization , such as for instance finite length scaling of polar codes .",
    "this will be discussed in the next section .",
    "* overview of the proof of these theorems . *",
    "the proof of these theorems uses four ingredients .    1 .",
    "the first ingredient is the polarization theorem [ th : polarization ] .",
    "it shows that when the number of levels of the recursive @xmath0 construction tends to infinity , the fraction of the decoders of the constituent codes who face an almost noiseless channel tends to the capacity of the original channel . here",
    "the measure for being noisy is the bhattacharyya parameter of the channel .",
    "we then show that when the bhattacharyya parameter is close to @xmath115 the koetter vardy capacity of the channel is close to @xmath1 meaning that we can use reed - solomon codes or ag codes of rate close to @xmath1 for those almost noiseless constituent codes ( see proposition [ pr : bha_kv ] ) .",
    "3 .   when we use tsfasman - vlduts - zink ag codes and if @xmath17 were allowed to be a square prime power , the situation would be really clear .",
    "for the codes in our construction that face an almost noiseless channel , we use as constituent ag codes tsfasman - vlduts - zink ag codes of rate of the form @xmath351 .",
    "this gives an exponentially small ( in the length of the constituent code ) probability of error for each of those constituent codes by using theorem [ th : exponentialag ] .",
    "for the other codes , we just use the zero code ( i.e. the code with only the all - zero codeword ) . now in order to get an exponentially small probability of error , it suffices to take the number of levels to be large ( but fixed ! ) so that the fraction of almost noiseless channels is close enough to capacity and to let the length of the constituent codes go to infinity .",
    "this gives an exponentially small probability of error when the rate is bounded away from capacity by a term of order @xmath326 .",
    "4 .   in order",
    "to get rid of this term , and also in order to be able to use tsfasman - vlduts - zink ag codes for the case we are interested in , namely an alphabet which is prime , we use another argument . instead of using a @xmath17-ary code over a @xmath17-ary input channel we will use a @xmath352-ary code over this @xmath17-ary input channel .",
    "in other words , we are going to group the received symbols by packets of size @xmath255 and view this as a channel with @xmath352-ary input symbols .",
    "this changes the koetter vardy capacity of the channel .",
    "it turns out that the koetter - vardy capacity of this new channel is the koetter - vardy capacity of the original channel raised to the power @xmath255 ( see proposition [ pr : kvm ] ) .",
    "this implies that when the koetter - vardy capacity was close to @xmath353 , the new koetter - vardy capacity is close to @xmath354 and we do not lose much in terms of capacity when moving to a higher alphabet .",
    "this allows to use ag codes over a higher alphabet in order to get arbitrarily close to capacity by still keeping an exponentially small probability of error ( we can indeed take @xmath255 fixed but sufficiently large here ) . for reed - solomon codes ,",
    "the same trick works and allows to use constituent codes of arbitrarily large length by making the alphabet grow with the length of the code .",
    "however in this case , we can not take @xmath255 fixed anymore and this is the reason why we lose a little bit in the behavior of the error exponent . moreover the number of levels is also increasing in the last case in order to make the bhattacharyya parameter sufficiently small at the almost noiseless constituent codes so that the koetter - vardy stays sufficiently small after grouping symbols together .",
    "* link between the bhattacharyya parameter and the koetter - vardy capacity .",
    "* we will provide here a proposition showing that for a fixed alphabet size the koetter vardy capacity of a channel @xmath45 is greater than @xmath355 .",
    "for this purpose , it will be helpful to use an alternate form of the bhattacharyya parameter @xmath356 where @xmath357 is here a uniformly distributed random variable , @xmath358 is the output corresponding to sending @xmath357 over the channel @xmath45 and @xmath359    [ pr : bha_kv ] for a symmetric channel @xmath360    to simplify formula here we will write @xmath361 for @xmath362 , @xmath363 for @xmath364 and @xmath365 for @xmath366 .",
    "the proposition is essentially a consequence of the well known fact that the rnyi entropy which is defined for all @xmath367 , @xmath368 by @xmath369 and @xmath370 ( which turns out to be equal to the usual shannon entropy taken to the base @xmath17 ) is decreasing in @xmath80 .",
    "this also holds of course for the `` conditional '' rnyi entropy which is defined by @xmath371 consider now a random variable @xmath357 which is uniformly distributed over @xmath53 and let @xmath358 be the corresponding output of the memoryless channel @xmath45 . by using the definition of the bhattacharyya parameter given by we can write @xmath372 where @xmath373 we observe that we can relate this quantity to the rnyi entropy of order @xmath374 through @xmath375    on the other hand we know that @xmath376 . recall that @xmath377 using this together with we obtain that @xmath378 let @xmath379 observe that @xmath380    finally by using together with we deduce that @xmath381 which implies that @xmath382 by averaging over all @xmath51 s we get @xmath383 this implies the proposition by noticing that @xmath384    * changing the alphabet . *",
    "the problem with reed - solomon codes is that their length is bounded by their alphabet size",
    ". it would be desirable to have more freedom in choosing their length .",
    "there is a way to overcome this difficulty by grouping together transmitted symbols into packets and to view each packet as a symbol over a larger alphabet . in other words , assume that we have a memoryless communication channel @xmath45 with input alphabet @xmath53 . instead of looking for codes defined over @xmath53 we will group input symbols in packets of size @xmath255 and view them as symbols in the extension field @xmath385 .",
    "this will allow us to consider codes defined over @xmath385 and allows much more freedom in choosing the length of the reed - solomon codes components ( or more generally the ag components ) .",
    "there is one caveat to this approach , it is that we change the channel model . in such a case",
    "the channel is @xmath386 where we define the tensor of two channels by    let @xmath45 and @xmath387 be two memoryless channels with respective input alphabets @xmath46 and @xmath388 and respective output alphabets @xmath47 and @xmath389 .",
    "their tensor product @xmath390 is a memoryless channel with input alphabet @xmath391 and output alphabet @xmath392 where the transitions probabilities are given by @xmath393 for all @xmath394 .",
    "the koetter - vardy capacity of this tensor product is easily related to the koetter - vardy capacity of the initial channel through    [ pr : kvm ] @xmath395 .",
    "if @xmath396 then @xmath397    let @xmath398 be the sent symbol for channel @xmath399 and @xmath400 be the received vector .",
    "let @xmath401 be the app probability vector after receiving @xmath34 , that is @xmath402 .",
    "we denote the @xmath403 component of this vector by @xmath404 .",
    "let @xmath405 be the app vector for the @xmath38-th use of the channel .",
    "we denote by @xmath406 the @xmath80 component of this vector .",
    "observe that @xmath407 this implies that @xmath408 this together with the fact that the channel is memoryless implies that @xmath409 the last statement follows easily from this identity and the convexity inequality @xmath410 which holds for @xmath52 in @xmath306 $ ] and @xmath411 .",
    "* proof of theorem [ th : errprob1 ] . *",
    "we have now all ingredients at hand for proving theorem [ th : errprob1 ] .",
    "we use theorem [ th : polarization ] to claim that there exists a lower bound @xmath412 on the number of levels @xmath63 in a recursive @xmath0 construction such that @xmath413 for all @xmath414 where @xmath112 .",
    "we call the channels that satisfy this condition the _ good channels_. we choose our code to be a recursive @xmath0-code of depth @xmath63 with reed - solomon constituent codes that are of length @xmath352 and defined over @xmath385 . the overall length ( over @xmath53 ) of the recursive @xmath0 code is then @xmath415 the constituent codes @xmath416 that face a good channel @xmath330 are chosen as reed - solomon codes of dimension @xmath29 given by @xmath417 whereas all the other codes are chosen to be zero codes . by using proposition [ pr : bha_kv ] we know that @xmath418 from this we deduce that the koetter - vardy of the channel corresponding to grouping together @xmath255 symbols in @xmath53 has a koetter - vardy capacity that satisfies @xmath419 \\geq 1 -   m(q-1)2^{-n^\\beta}.\\ ] ] now we can invoke theorem [ th : exponential ] and deduce that the probability of error of the reed - solomon codes that face these good channels when decoding them with the koetter - vardy decoding algorithm with list size bounded by @xmath342 is upper - bounded by a quantity of the form @xmath420 . the overall probability of error",
    "is bounded by @xmath421 .",
    "we choose now @xmath27 such that it is the smallest power of two for which the inequality @xmath422 holds .",
    "this implies @xmath423 as @xmath255 tends to infinity .",
    "since @xmath424 as @xmath255 tends to infinity , the rate of the iterated @xmath0 code is of order @xmath425 for @xmath28 sufficiently small and @xmath27 sufficiently large when @xmath426 . when @xmath427 the theorem is obviously true",
    "this together with the previous upper - bound on the probability of a decoding error imply directly our theorem since @xmath428 and @xmath429 imply that @xmath430 as @xmath255 tends to infinity .",
    "* proof of theorem [ th : errprob2 ] .",
    "* theorem [ th : errprob2 ] uses similar arguments , the only difference is that now the number of levels @xmath63 in the construction and the parameter @xmath255 only depend on the gap to capacity we are looking for .",
    "we fix @xmath338 to be an arbitrary constant in @xmath339 and choose @xmath255 to be the smallest even integer @xmath255 for which @xmath431 is smaller than @xmath432 and the number of levels @xmath63 to be the smallest integer such that we have at the same time @xmath433 where @xmath112 .",
    "such an @xmath63 necessarily exists by theorem [ th : polarization ] .",
    "we choose our code to be a recursive @xmath0-code of depth @xmath63 with tsfasman - vlduts - zink ag constituent codes that are of length @xmath434 and defined over @xmath385 .",
    "such codes exist by the tsfasman - vlduts - zink construction for arbitrarily large lengths because @xmath255 is even .",
    "the overall length ( over @xmath53 ) of the recursive @xmath0 code is then @xmath435 for the constituent codes @xmath416 that face a good channel @xmath330 , we choose the rate of the ag code to be @xmath436 where @xmath437 whereas all the other codes are chosen to be zero codes .",
    "the rate of the codes that face a good channel is clearly greater than or equal a quantity of the form @xmath438 as @xmath434 goes to infinity by using and @xmath439 .",
    "the overall rate @xmath3 of the iterated @xmath0 code satisfies therefore @xmath440 for @xmath28 sufficiently small and @xmath434 sufficiently large when @xmath426 .",
    "we can make the assumption @xmath426 from now on , since when @xmath427 the theorem is trivially true .",
    "on the other hand , the error probability of decoding a code @xmath416 facing a good channel @xmath330 with the koetter - vardy decoding algorithm with list size bounded by @xmath342 is upperbounded by a quantity of the form @xmath441 by using theorem [ th : exponentialag ] since the rate @xmath442 of such a code satisfies @xmath443 by using the lower bound on the koetter - vardy capacity of a good channel that follows from propositions [ pr : bha_kv ] and [ pr : kvm ] .",
    "the overall probability of error is therefore bounded by @xmath444 .",
    "this probability is of the form announced in theorem [ th : errprob2 ] since @xmath255 and @xmath27 are quantities that only depend on @xmath17 and @xmath28 .",
    "* a variation on polar codes that is much more flexible .",
    "* we have given here a variation of polar codes that allows to attain capacity with a polynomial - time decoding complexity in a more flexible way than standard polar codes .",
    "it consists in taking an iterated-@xmath0 construction based on reed - solomon codes or more generally ag codes .",
    "decoding consists in computing the app of each position in the same way as polar codes and then to decode the constituent codes with a soft information decoder , the koetter - vardy list decoder in our case .",
    "polar codes are indeed a special case of this construction by taking constituent codes that consist of a single symbol .",
    "however when we take constituent codes which are longer we benefit from the fact that we do not face a binary alternative as for polar codes , i.e. putting information or not in the symbol depending on the noise model for this symbol , but can choose freely the length ( at least in the ag case ) and the rate of the constituent code that face this noise model .    *",
    "an exponentially small probability of error .",
    "* this allows to control the rate and error probability in a much finer way as for standard polar codes .",
    "indeed the failure probability of polar codes is essentially governed by the error probability of an information symbol of the polar code facing the noisiest channel ( among all information symbols ) . in our case , this error probability can be decreased significantly by choosing a long enough code and a rate below the noise value that our decoder is able to sustain ( which is more or less the koetter - vardy capacity of the noisy channel in our case ) . furthermore , now we can also put information in channels that were not used for sending information in the polar code case . when using reed - solomon codes with this approach we obtain a quasi - exponential decay of the error probability which is significantly smaller than for the standard concatenation of an inner polar code with an outer reed - solomon code .",
    "when we use ag codes we even obtain an exponentially fast decay of the probability of error after decoding .",
    "the whole work raises a certain number of intriguing questions .",
    "* dependency of the error probability with respect to the gap to capacity . *",
    "even if the exponential decay with respect to the codelength of the iterated @xmath0-construction is optimal , the result says nothing about the behavior of the exponent in terms of the gap to capacity .",
    "the best we can hope for is a probability of error which behaves as @xmath445 where @xmath28 is the gap to capacity , that is @xmath446 , @xmath109 being the capacity and @xmath3 the code rate .",
    "we may observe that theorem [ th : exponential ] gives a behavior of this kind with the caveat that @xmath28 is not the gap to capacity there but the gap to the koetter - vardy capacity . to obtain a better understanding of the behavior of this exponent",
    ", we need to have a much finer understanding of the speed of polarization than the one given in theorem [ th : polarization ] .",
    "what we really need is indeed a result of the following form @xmath447 which expresses the fraction of `` @xmath28-good '' channels in terms of the gap to capacity with sharp estimates for the `` gap '' function @xmath448 .",
    "the problem in our case is that our understanding of the speed of polarization is far from being complete . even for binary input channels ,",
    "the information we have on the function @xmath448 is only partial as shown by @xcite . a better understanding of the speed of polarization",
    "could then be used in order to get a better understanding of the decay of the error probability in terms of the gap to capacity .",
    "a tantalizing issue is whether or not we get a better scaling than for polar codes .    *",
    "choosing other kernels . *",
    "the iterated @xmath0-construction can be viewed as choosing the original polar codes from arikan associated to the kernel @xmath449 .",
    "taking larger kernels does not improve the error probability after decoding in the binary case for polar codes , unless taking very large kernels as shown in @xcite , however this is not the case for non binary kernels .",
    "even ternary kernels , such as for instance the ternary `` reed - solomon '' kernel @xmath450 results in a better behavior of the probability of error after decoding ( see @xcite ) .",
    "this raises the issue whether other kernels would allow to obtain better results in our case .",
    "in other words , would other generalized concatenated code constructions do better in our case ?",
    "interestingly enough , it is not necessary a reed - solomon kernel which gives the best results in our case .",
    "preliminary results seem to show that it should be better to take the kernel @xmath451 rather than the aforementioned reed - solomon kernel .",
    "the last kernel would correspond to a @xmath452 construction which is defined by @xmath453 one level of concatenation outperforms the @xmath0 construction on the @xmath126 .",
    "in particular it allows to increase the slope at the origin of the `` infinite koetter - vardy capacity curve '' ( when compared to the curve for one level in figure [ fig : infinite ] ) .",
    "this seems to be the key for choosing good kernels .",
    "this issue requires further studies .",
    "* practical constructions .",
    "* we have explored here the theoretical behavior of this coding / decoding strategy .",
    "what is suggested by the experimental evidence shown in subsection [ ss : finite_capacity ] is that these codes do not only have some theoretical significance , but that they should also yield interesting codes for practical applications .",
    "indeed figure [ fig : finite_capacity ] shows that it should be possible to get very close to the channel capacity by using only a construction with a small depth , say @xmath454 together with constituent codes of moderate length that can be chosen to be reed - solomon codes ( say codes of length a hundred / a few hundred at most ) .",
    "this raises many issues that we did not cover here , such as for instance    * to choose appropriately the code rate of each constituent code in order to maximize the overall rate with respect to a certain target error probability ; * choose the multiplicities for each constituent code in order to attain a good overall tradeoff complexity vs. performance ; * choose other constituent codes such as ag codes especially in cases where the channel is an @xmath53-input channel for small values of @xmath17 .",
    "it might also be worthwhile to study the use of subfield subcodes of reed - solomon codes in this setting ( for instance bch codes ) .",
    "the whole strategy leads to use koetter - vardy decoding for reed - solomon / ag codes in a regime where the rate gets either very close to @xmath115 or to @xmath1 .",
    "this could be exploited to lower the complexity of generic koetter - vardy decoding .",
    "melk14    erdal arikan .",
    "channel polarization : a method for constructing capacity - achieving codes for symmetric binary - input memoryless channels .",
    ", 55(7):30513073 , 2009 .",
    "amir bennatan and davis burshtein .",
    "design and analysis of nonbinary ldpc codes over arbitrary discrete - memoryless channels .",
    ", 52(2):549583 , february 2006 .",
    "mayank bakshi , sidharth jaggi , and michelle effros .",
    "concatenated polar codes . in _ proc",
    "symposium inf .",
    "theory - isit  2010 _ , pages 918922 , austin , texas , usa , june 2010 . ieee .    ilya dumer and kirill shabunov .",
    "soft - decision decoding of reed - muller codes : recursive lists .",
    ", 52(3):12601266 , 2006 .",
    "ilya dumer .",
    "soft - decision decoding of reed - muller codes : a simplified algorithm .",
    ", 52(3):954963 , 2006 .",
    "robert  g. gallager . ,",
    "volume  2 .",
    "springer , 1968 .",
    "dina goldin and david burshtein .",
    "improved bounds on the finite length scaling of polar codes .",
    ", 60(11):69666978 , november 2014 .",
    "venkatesan guruswami and atri rudra .",
    "explicit capacity - achieving list - decodable codes . in _ proceedings of the thirty - eighth annual acm symposium on theory of computing _ , stoc 06 , pages 110 , new york , ny , usa , 2006 .",
    "venkatesan guruswami and madhu sudan .",
    "improved decoding of reed - solomon and algebraic - geometry codes .",
    ", 45(6):17571767 , 1999 .",
    "venkatesan guruswami and patrick xia .",
    "polar codes : speed of polarization and polynomial gap to capacity .",
    ", 61(1):316 , january 2015 .",
    "s.  h. hassani , k.  alishahi , and ruediger urbanke .",
    "finite - length scaling for polar codes .",
    ", 60(10):58755898 , october 2014 .",
    "satish  babu korada . .",
    "phd thesis , ecole polytechnique fdrale de lausanne ( epfl ) , july 2009 .",
    "ralf koetter and alexander vardy .",
    "algebraic soft - decision decoding of reed - solomon codes .",
    ", 49(11):28092825 , 2003 .",
    "ralf koetter and alexander vardy .",
    "algebraic soft - decision decoding of reed - solomon codes .",
    "preprint ( long version ) of the journal paper of the same name , 2003 .",
    "hessam mahdavifar , mostafa el - khamy , jungwon lee , and inyup kang .",
    "performance limits and practical decoding of interleaved reed - solomon polar concatenated codes .",
    ", 62(5):14061417 , 2014 .",
    "marco mondelli , s.  hamed hassani , and rdiger  l. urbanke .",
    "unified scaling of polar codes : error exponent , scaling exponent , moderate deviations , and error floors .",
    ", 62(12):66986712 , 2016 .",
    "florence  j. macwilliams and neil j.  a. sloane . .",
    ", amsterdam , fifth edition , 1986 .",
    "ryuhei mori and toshiyuki tanaka .",
    "source and channel polarization over finite fields and reed - solomon matrices .",
    ", 60(5):27202736 , 2014 .",
    "f.  parvaresh and a.  vardy . correcting errors beyond the guruswami - sudan radius in polynomial time . in _",
    "foundations of computer science , 2005 .",
    "focs 2005 .",
    "46th annual ieee symposium on _ , pages 285294 , 2005 .    tom richardson and ruediger urbanke . .",
    "cambridge university press , 2008 .",
    "eren aolu .",
    "polarization and polar codes .",
    ", 8(4):259381 , 2011 .",
    "eren aolu , emre telatar , and erdal arikan . polarization for arbitrary discrete memoryless channels . in _ proc .",
    "theory workshop- itw _ , pages 144149 , october 2009 .",
    "henning stichtenoth . .",
    "springer , 1993 .",
    "madhu sudan .",
    "decoding of reed solomon codes beyond the error - correction bound .",
    ", 13(1):180193 , 1997 .",
    "michael  a tsfasman , sg  vlduts , and th  zink .",
    "modular curves , shimura curves , and goppa codes , better than varshamov - gilbert bound . , 109(1):2128 , 1982 .",
    "throughout the appendix we will use the same notation as in section [ sec : polar ] and denote by @xmath24 a constituent code of an iterated @xmath0 construction of some depth @xmath63 . here",
    "@xmath38 is an @xmath63-bit word .",
    "we assume in the appendix that all the constituent codes are reed - solomon codes and that the model of error is the @xmath17-ary symmetric channel of crossover probability @xmath120 ( @xmath126 ) .",
    "we also denote by @xmath309 the app probability vectors computed for decoding @xmath24 . without loss of generality",
    "we may assume that the codeword which is sent is the @xmath115 codeword . with this assumption , in order to reduce the number of cases to be considered",
    "it will be very convenient to give these app vectors only up to a permutation acting on all positions with the exception of the first one which will always be fixed .",
    "we will namely use the following notation .    for two probability vectors",
    "@xmath455 and @xmath456 in @xmath457 we will write @xmath458 if and only if @xmath459 and @xmath460 is a permutation of @xmath461 .    moreover also in order to simplify the expressions wich will appear in these app vectors we will use the following notation    @xmath462 denotes an arbitrary function of @xmath17 which satisfies @xmath463 .",
    "with the zero codeword assumption , the distribution of the app vector @xmath464 of a @xmath126-channel is as follows @xmath465 with probability @xmath122 and @xmath466 with probability @xmath467 where the term @xmath122 appears in an arbitrary position with the exception of the first one .",
    "we summarize this in table [ tab : level0 ] .",
    ".[tab : level0 ] [ cols=\"^,^,^\",options=\"header \" , ]     let @xmath468 be the app probability vector viewed by the decoder @xmath469 decoder .",
    "for the channel error model of the code @xmath469 we have @xmath470      note that @xmath475 and @xmath476 are distributed like @xmath477 and @xmath478 where @xmath464 and @xmath479 are independent and distributed like @xmath480 which is itself the app vector obtained from transmitting @xmath115 over a @xmath481 with @xmath482 .",
    "we can therefore use directly lemmas [ l12 ] and [ l11 ] and obtain    let @xmath475 and @xmath476 be the app probability vectors viewed by the decoder @xmath483 and @xmath484 , respectively . for the channel error model of the code @xmath483 we have @xmath485",
    "the channel error model for the code @xmath484 is a @xmath486 with @xmath487 @xmath488    note that @xmath489 and @xmath490 are distributed like @xmath477 and @xmath478 where @xmath464 and @xmath479 are independent and distributed like @xmath491 .",
    "we can therefore use directly lemmas [ l21 ] and [ l22 ] and obtain    let @xmath489 and @xmath490 be the app probability vectors viewed by the decoder @xmath492 and @xmath493 , respectively . for the channel error model of the code @xmath492 and @xmath493 we have @xmath494",
    "the koetter - vardy decoding algorithm for reed - solomon codes can be adapted to ag codes as was shown in @xcite . in this appendix",
    ", we give a short description of this algorithm and a review of the main results of @xcite that we need to prove theorem [ th : listsize_ag ] .",
    "this section is essentially nothing but a subset of results presented for ag codes in the preprint version @xcite which we repeat here for the convenience of the reader since the additional material present in the preprint version has not been published as far as we know .",
    "we first begin with the notion of a _ gap _ which will be useful to describe the koetter - vardy soft decoding algorithm for ag codes .",
    "we consider an algebraic curve @xmath46 defined over a finite field @xmath53 of genus @xmath263 .",
    "let @xmath253 be a rational point on @xmath46 .",
    "we also assume that @xmath46 has at least @xmath27 other rational points @xmath495 besides @xmath46 .",
    "a positive integer @xmath38 is called a _ ( weierstrass ) gap _ at @xmath253 if @xmath496 .",
    "otherwise @xmath38 is a _ non - gap _ at @xmath253 .",
    "it is well known that gaps at @xmath253 lie in the interval @xmath497 $ ] and that the number of gaps is equal to @xmath263 .",
    "these gaps at @xmath253 can be used to construct a basis for the space @xmath256 : we fix an arbitrary rational function @xmath498 if @xmath38 is a non - gap at @xmath253 and we set @xmath499 otherwise , for @xmath500",
    ".    the ring of rational functions that have either no pole or just one pole at @xmath253 which is defined by @xmath501 will also be helpful in what follows .",
    "in other words , we can write any polynomial @xmath502 $ ] in a unique way as @xmath503 . this allows to define for a pair @xmath504 of nonnegative real numbers the _",
    "@xmath504-weighted @xmath253-valuation _ of @xmath505 , denoted by @xmath506 , which is the maximum over all numbers @xmath507 such that @xmath508",
    ".    we will also need the notion of the multiplicity of a polynomial in @xmath509 $ ] at a certain point @xmath510 .",
    "for this purpose , it will be convenient to introduce a new basis for @xmath256 .",
    "we define @xmath511 as follows .",
    "if there exists at least one @xmath512 that has multiplicity exactly @xmath38 at @xmath510 we set @xmath513 to be one of these functions ( we make an arbitrary choice if there are several functions of this kind ) . if there is no such function we set @xmath514 . for the case",
    "we are interested in , namely @xmath515 , it is known that there are exactly @xmath263 indices @xmath38 for which @xmath514 .",
    "it is known @xcite that the set of functions among @xmath511 which are non zero form a basis of @xmath509 $ ] .",
    "we write from now on each @xmath516 in @xmath256 in a unique way as @xmath517 when we assume that @xmath518 if @xmath519 .",
    "let @xmath505 be a polynomial in @xmath509 $ ] and consider the shifted polynomial @xmath520 expressed using the above basis , that is , @xmath521 we say that @xmath505 has a _ zero of multiplicity @xmath255 _ at the interpolation point @xmath522 if @xmath523 for @xmath524 and there exists a nonzero coefficient @xmath525 with @xmath526 .",
    "we are ready now for describing the koetter - vardy decoding algorithm for ag codes .",
    "we consider here an ag code @xmath527 of length @xmath27 over @xmath53 defined by a set of @xmath528 distinct @xmath31-rational points : @xmath253 and @xmath529 .",
    "we are also given a multiplicity matrix @xmath530 .",
    "* interpolation step : * it consists in computing the ( nontrivial ) polynomial @xmath531 $ ] of minimal @xmath532-weighted @xmath253-valuation that has a zero of multiplicity at least @xmath533 at the interpolation point @xmath534 .",
    "[ ag-1 ] let @xmath541 denote the cost of the multiplicity matrix @xmath42 .",
    "the list obtained by factoring the interpolation polynomial @xmath535 contains a codeword @xmath542 if @xmath543 we have the following upper bound on @xmath544 : @xmath545      recall that for every @xmath546 there exists a rational function @xmath512 such that @xmath547 for @xmath548 .",
    "given the interpolation polynomial @xmath549 $ ] , we consider the function @xmath550 defined by @xmath551 . by construction",
    ", @xmath535 passes trough the points @xmath552 with multiplicities at least @xmath553 where @xmath554 . then :    * we claim that the function @xmath551 has at least @xmath555 zeros in @xmath254 counted with multiplicities . indeed ,",
    "if @xmath535 passes through the interpolation point @xmath556 with multiplicity at least @xmath553 and we express @xmath535 in the basis of the @xmath557 s we have @xmath558 but , by it is required that @xmath559 if @xmath560 .",
    "we thus get that @xmath561 has a zero of multiplicity @xmath553 at the point @xmath562 since @xmath563 . * since @xmath537 and @xmath564",
    "then @xmath565 has at most @xmath544 poles at @xmath253 . and these are its only poles since @xmath550 .      for the second statement of the theorem ,",
    "let @xmath568 be a bivariate polynomial over @xmath31 and let @xmath569 . in @xcite ,",
    "the @xmath570-weighted degree of @xmath571 is defined as the maximum over all numbers @xmath572 such that @xmath508 .",
    "moreover , the number of monomials of @xmath573-weighted degree at most @xmath292 is denoted in @xcite as @xmath574 .",
    "that is , @xmath575    it is easy to see that @xmath576 indeed , the number of different expressions @xmath577 in @xmath578 is equal to @xmath579 but taking into account that some of the functions @xmath580 are zero .",
    "then , the result follows from the fact that the number of functions @xmath580 that are zero , or equivalent , the number of gaps , is bounded by the genus @xmath263 of the curve @xmath581 ; and the fact that the number of monomials @xmath582 such that @xmath583 is upper bounded by @xmath584 .",
    "[ ag-2 ] the number of codewords on the list produced by the soft - decision decoder for the ag code @xmath527 with a given multiplicity matrix @xmath42 does not exceed @xmath591 where @xmath263 denotes the genus of the curve @xmath46 and @xmath541 the cost of matrix @xmath42 .    similar to (",
    "* lemma 15 ) the number of codewords of the list is upper - bounded by the @xmath592-weight @xmath253-valuation of the interpolation polynomial @xmath535 . by definition of weighted @xmath253-valuation",
    ", we have : @xmath593 where the first inequality follows from the definition of weighted @xmath253-valuation , the second inequality follows from the definition of @xmath594 and the third inequality follows from theorem [ ag-1 ] .",
    "[ ag-3 ] for a given multiplicity matrix @xmath42 , the algebraic soft - decision decoding algorithm outputs a list that contains a codeword @xmath542 if @xmath597 where @xmath263 denotes the genus of the curve @xmath46 and @xmath541 the cost of matrix @xmath42",
    ".      let @xmath152 be a given reliability matrix and @xmath42 be the corresponding multiplicity matrix produced by @xcite[algorithm a ] .",
    "then , by @xcite[lemma 16 ] there exists a positive real number @xmath599 such that @xmath600 where @xmath601 denotes a @xmath142 matrix whose entries are all nonnegative real numbers not exceeding @xmath1 .",
    "then : @xmath602 by definition we have that @xmath603            using the expression for @xmath599 in equation , we can express the previous formula as : @xmath609 with : @xmath610 @xmath611 to obtain the previous inequality we have used the fact that @xmath612 and @xmath613 .",
    "@xmath614 to obtain the previous inequality we have made use of the following two observations :"
  ],
  "abstract_text": [
    "<S> in this paper we show how to attain the capacity of discrete symmetric channels with polynomial time decoding complexity by considering iterated @xmath0 constructions with reed - solomon code or algebraic geometry code components . </S>",
    "<S> these codes are decoded with a recursive computation of the _ a posteriori _ probabilities of the code symbols together with the koetter - vardy soft decoder used for decoding the code components in polynomial time . </S>",
    "<S> we show that when the number of levels of the iterated @xmath0 construction tends to infinity , we attain the capacity of any discrete symmetric channel in this way . </S>",
    "<S> this result follows from the polarization theorem together with a simple lemma explaining how the koetter - vardy decoder behaves for reed - solomon codes of rate close to @xmath1 . </S>",
    "<S> however , even if this way of attaining the capacity of a symmetric channel is essentially the arikan polarization theorem , there are some differences with standard polar codes . </S>",
    "<S> indeed , with this strategy we can operate succesfully close to channel capacity even with a small number of levels of the iterated @xmath0 construction and the probability of error decays quasi - exponentially with the codelength in such a case ( i.e. exponentially if we forget about the logarithmic terms in the exponent ) . </S>",
    "<S> we can even improve on this result by considering the algebraic geometry codes constructed in @xcite . </S>",
    "<S> in such a case , the probability of error decays exponentially in the codelength for any rate below the capacity of the channel . </S>",
    "<S> moreover , when comparing this strategy to reed - solomon codes ( or more generally algebraic geometry codes ) decoded with the koetter - vardy decoding algorithm , it does not only improve the noise level that the code can tolerate , it also results in a significant complexity gain . </S>"
  ]
}