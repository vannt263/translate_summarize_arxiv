{
  "article_text": [
    "teasing out signatures of interactions buried in overwhelming volumes of information is one of the most basic challenges in scientific research .",
    "understanding how information is organized can help us discover its fundamental underlying properties .",
    "researchers do this when they investigate the relationships between diseases , cell functions , chemicals , or particles , and we all learn new concepts and solve problems by understanding the relationships between the various entities present in our everyday lives .",
    "these entities can be represented as networks , or graphs , in which local behaviors can be easily understood , but whose global view is highly complex .",
    "these networks exhibit a long and varied list of global properties , including heavy - tailed degree distributions  @xcite and interesting growth characteristics  @xcite , among others .",
    "recent work has found that these global properties are merely products of a graph s local properties , in particular , graphlet distributions  @xcite .",
    "these small , local substructures often reveal the degree distributions , diameter and other global properties of a graph  @xcite , and have been shown to be a more complete way to measure the similarity between two or more graphs  @xcite . our overall goal , and the goal of structural inference algorithms in general , is to learn the local structures that , in aggregate , help describe the observed interactions and generalize to explain further phenomena .",
    "for example , physicists and chemists have found that many chemical interactions are the result of underlying structural properties of the individual elements .",
    "similarly , biologists have agreed that simple tree structures are useful when organizing the evolutionary history of life , and sociologists find that clique - formation , _",
    "e.g. _ , triadic closure , underlies community development  @xcite .",
    "in other instances , the structural organization of the entities may resemble a ring , a clique , a star , or any number of complex configurations .    in this work ,",
    "we describe a general framework that can discover , from any large network , simple structural forms in order to make predictions about the topological properties of a network .",
    "in addition , this framework is able to extract mechanisms of network generation from small samples of the graph in order to generate networks that satisfy these properties .",
    "our major insight is that a network s _ clique tree _",
    "encodes simple information about the structure of the network .",
    "we use the closely - related formalism of _ hyperedge replacement grammars _ ( hrgs ) as a way to describe the organization of real world networks .",
    "unlike previous models that manually define the space of possible structures  @xcite or define the grammar by extracting frequent subgraphs  @xcite , our framework can automatically discover the necessary forms and use them to recreate the original graph _ exactly _ as well as infer generalizations of the original network .",
    "our approach can handle any type of graph and does not make any assumption about the topology of the data .    after reviewing some of the theoretical foundations of clique trees and hrgs",
    ", we show how to extract an hrg from a graph and use it to reconstruct the original graph .",
    "we then show how to use the extracted grammar to stochastically generate generalizations of the original graph .",
    "finally , we present experimental results that compare the stochastically generated graphs with the original graphs .",
    "we show that these generated graphs exhibit a wide range of properties that are very similar to the properties of the original graphs , and significantly outperform existing graph models at generating subgraph distributions similar to those found in the original  graph .",
    "before we describe our method , some background definitions are needed .",
    "we begin with an arbitrary input _ hypergraph _",
    "@xmath0 , where a _ hyperedge _ @xmath1 can connect multiple vertices @xmath2 .",
    "common _ graphs _ ( _ e.g. _ , social networks , web graphs , information networks ) are a particular case of hypergraphs where each edge connects exactly two vertices . for convenience ,",
    "all of the graphs in this paper will be _ simple _ , _ connected _ and _ undirected _ , although these restrictions are not vital . in the remainder of this section",
    "we refer mainly to previous developments in clique trees and their relationship to hyperedge replacement grammars in order to support the claims made in sections 3 and 4 .",
    "all graphs can be decomposed ( though not uniquely ) into a _ clique tree _ , also known as a tree decomposition , junction tree , join tree , intersection tree , or cluster graph . within the data mining community",
    ", clique trees are best known for their role in exact inference in probabilistic graphical models , so we introduce the preliminary work from a graphical modelling perspective ; for an expanded introduction , we refer the reader to chapters 9 and 10 of koller and friedman s textbook  @xcite .",
    "[ defn : cliquetree ] a _ clique tree _ of a graph @xmath0 is a tree @xmath3 , each of whose nodes @xmath4 is labeled with a @xmath5 and @xmath6 , such that the following properties hold :    1 .",
    "vertex cover : for each @xmath7 , there is a vertex @xmath8 such that @xmath9 .",
    "edge cover : for each hyperedge @xmath10 there is exactly one node @xmath8 such that @xmath11 .",
    "moreover , @xmath12 .",
    "running intersection : for each @xmath7 , the set @xmath13 is connected .",
    "the _ width _ of a clique tree is @xmath14 , and the _ treewidth _ of a graph @xmath15 is the minimal width of any clique tree of @xmath15 .",
    "unfortunately , finding the optimal elimination ordering and corresponding minimal - width clique tree is np - complete @xcite .",
    "fortunately , many reasonable approximations exist for general graphs : in this paper we employ the commonly used maximum cardinality search ( mcs ) heuristic introduced by tarjan and yannikakis  @xcite in order to compute a clique tree with a reasonably - low , but not necessarily minimal , width",
    ".    simply put , a clique tree of any graph ( or any hypergraph ) is a tree , each of whose nodes is labeled with nodes and edges from the original graph , such that _ vertex cover _ , _ edge cover _ and the _ running intersection _ properties hold , and the `` width '' of the clique tree measures how tree - like the graph is . the reason for the interest in finding the clique tree of a graph is because many computationally difficult problems can be solved efficiently when the data is constrained to be a tree .",
    "figure  [ fig : expdtree ] shows a graph and a minimal - width clique tree of the same graph ( showing @xmath16 for each node @xmath4 ) .",
    "nodes are labeled with lowercase latin letters .",
    "we will refer back to this graph and clique tree as a running example throughout this paper .    ; they are shown only for explanatory purposes . ]",
    "the key insight for this task is that a network s clique tree encodes robust and precise information about the network .",
    "an hrg , which is extracted from the clique tree , contains graphical rewriting rules that can match and replace graph fragments similar to how a context free grammar ( cfg ) rewrites characters in a string .",
    "these graph fragments represent a succinct , yet complete description of the building blocks of the network , and the rewriting rules of the hrg represent the instructions on how the graph is pieced together . for a thorough examination of hrgs",
    ", we refer the reader to the survey by drewes _",
    "et al . _",
    "@xcite .",
    "[ defn : tuple ] a _ hyperedge replacement grammar _ is a tuple @xmath17 , where    1 .",
    "@xmath18 is a finite set of nonterminal symbols .",
    "each nonterminal @xmath19 has a nonnegative integer _",
    "rank _ , which we write @xmath20 .",
    "2 .   @xmath3 is a finite set of terminal symbols .",
    "@xmath21 is a distinguished starting nonterminal , and @xmath22 .",
    "4 .   @xmath23 is a finite set of production rules @xmath24 , where * @xmath19 , the left hand side ( lhs ) , is a nonterminal symbol .",
    "* @xmath25 , the right hand side ( rhs ) , is a hypergraph whose edges are labeled by symbols from @xmath26 .",
    "if an edge @xmath27 is labeled by a nonterminal @xmath28 , we must have @xmath29 .",
    "* exactly @xmath20 vertices of @xmath25 are designated _ external vertices_. the other vertices in @xmath25 are called _ internal _ vertices .    when drawing hrg rules , we draw the lhs @xmath19 as a hyperedge labeled @xmath19 with arity @xmath20 .",
    "we draw the rhs as a hypergraph , with the external vertices drawn as solid black circles and the internal vertices as open white circles .    if an hrg rule has no nonterminal symbols in its rhs , we call it a _ terminal rule_.",
    "[ defn : hrg ] let @xmath30 be an hrg and @xmath31 be a production rule of @xmath30 .",
    "we define the relation @xmath32 ( @xmath33 is derived in one step from @xmath34 ) as follows .",
    "@xmath34 must have a hyperedge @xmath27 labeled @xmath19 ; let @xmath35 be the vertices it connects .",
    "let @xmath36 be the external vertices of @xmath25 .",
    "then @xmath37 is the graph formed by removing @xmath27 from @xmath34 , making an isomorphic copy of @xmath25 , and identifying @xmath38 with the copies of @xmath39 for each @xmath40 .",
    "let @xmath41 be the reflexive , transitive closure of @xmath42 .",
    "then we say that @xmath30 generates a graph @xmath15 if there is a production @xmath43 and @xmath44 and @xmath15 has no edges labeled with nonterminal symbols .",
    "in other words , a derivation starts with the symbol @xmath45 , and we repeatedly choose a nonterminal @xmath19 and rewrite it using a production @xmath46 .",
    "the replacement hypergraph fragments @xmath25 can itself have other nonterminal hyperedges , so this process is repeated until there are no more nonterminal hyperedges .",
    "these definitions will be clearly illustrated in the following sections .",
    "clique trees and hyperedge replacement graph grammars have been studied for some time in discrete mathematics and graph theory literature .",
    "hrgs are conventionally used to generate graphs with very specific structures , _ e.g. _ , rings , trees , stars .",
    "a drawback of many current applications of hrgs is that their production rules must be hand drawn to generate some specific graph or class of graphs .",
    "very recently , kemp and tenenbaum developed an inference algorithm that learned probabilities from real world graphs , but still relied on a handful of rather basic hand - drawn production rules ( of a related formalism called vertex replacement grammar ) to which the learned probabilities were assigned  @xcite .",
    "the main contribution of this paper is to combine prior theoretical work on clique trees , tree decomposition and treewidth to automatically learn an hrg for real world graphs .",
    "existing graph generators , like exponential random graphs , small world graphs , kronecker graphs , and so on , learn parameters from some input graph to generate new graphs stochastically .",
    "unlike these previous approaches , our model has the ability to reproduce the exact same graph topology where the new graph is guaranteed to be isomorphic to the original graph .",
    "our model is also able to stochastically generate different - sized graphs that share similar properties to the original graph .",
    "the first step in learning an hrg from a graph is to compute a clique tree from the original graph .",
    "then , this clique tree induces an hrg in a natural way , which we demonstrate in this section .",
    "let @xmath4 be an interior node of the clique tree @xmath3 , let @xmath47 be its parent , and let @xmath48 be its children .",
    "node @xmath4 corresponds to an hrg production rule @xmath46 as follows .",
    "first , @xmath49 . then , @xmath25 is formed by :    * adding an isomorphic copy of the vertices in @xmath16 and the edges in @xmath50 * marking the ( copies of ) vertices in @xmath51 as external vertices * adding , for each @xmath52 , a nonterminal hyperedge connecting the ( copies of ) vertices in @xmath53 .",
    "figure  [ fig : creation ] shows an example of the creation of an hrg rule . in this example , we focus on the middle clique - tree node @xmath54 , outlined in bold .",
    "we choose nonterminal symbol n for the lhs , which must have rank  2 because @xmath4 has 2 vertices in common with its parent .",
    "the rhs is a graph whose vertices are ( copies of ) @xmath55 .",
    "vertices d and e are marked external ( and numbered 1 and 2 , arbitrarily ) because they also appear in the parent node .",
    "the terminal edges are @xmath56 .",
    "there is only one child of @xmath4 , and the nodes they have in common are e and  f , so there is one nonterminal hyperedge connecting e and  f.    next we deal with the special cases of the root and leaves .",
    "* root node . *",
    "if @xmath4 is the root node , then it does not have any parent cliques , but may still have one or more children . because @xmath4 has no parent , the corresponding rule has a lhs with rank 0 and a rhs with no external vertices . in this case",
    ", we use the start nonterminal @xmath45 as the lhs , as shown in figure  [ fig : creation_root ] .",
    "the rhs is computed in the same way as the interior node case .",
    "for the example in fig .",
    "[ fig : creation_root ] , the rhs has vertices that are copies of c , d , and e. in addition , the rhs has two terminal hyperedges , @xmath57 .",
    "the root node has two children , so there are two nonterminal hyperedges on the rhs .",
    "the right child has two vertices in common with @xmath4 , namely , d and e ; so the corresponding vertices in the rhs are attached by a 2-ary nonterminal hyperedge .",
    "the left child has three vertices in common with @xmath4 , namely , c , d , and e , so the corresponding vertices in the rhs are attached by a 3-ary nonterminal hyperedge .",
    "* leaf node . *",
    "if @xmath4 is a leaf node , then the lhs is calculated the same as in the interior node case .",
    "again we return to the running example in fig .",
    "[ fig : creation_leaf ] ( on the next page ) . here , we focus on the leaf node @xmath58 , outlined in bold . the lhs has rank 2 , because @xmath4 has two vertices in common with its parent .",
    "the rhs is computed in the same way as the interior node case , except no new nonterminal hyperedges are added to the rhs .",
    "the vertices of the rhs are ( copies of ) the nodes in @xmath4 , namely , a , b , and e. vertices b and e are external because they also appear in the parent clique .",
    "this rhs has two terminal hyperedges , @xmath59 .",
    "because the leaf clique has no children , it can not produce any nonterminal hyperedges on the rhs ; therefore this rule is a terminal rule .",
    "we induce production rules from the clique tree by applying the above extraction method top down .",
    "because trees are acyclic , the traversal order does not matter , yet there are some interesting observations we can make about traversals of moderately sized graphs .",
    "first , exactly one hrg rule will have the special starting nonterminal @xmath45 on its lhs ; no mention of @xmath45 will ever appear in any rhs .",
    "similarly , the number of terminal rules is equal to the number of leaf nodes in the clique tree .",
    "larger graphs will typically produce larger clique trees , especially sparse graphs because they are more likely to have a larger number of small maximal cliques .",
    "these larger clique trees will produce a large number of hrg rules , one for each clique in the clique tree .",
    "although it is possible to keep track of each rule and its traversal order , we find , and will later show in the experiments section , that the same rules are often repeated many times .",
    "figure  [ fig : production_rules ] shows the 6 rules that are induced from the clique trees illustrated in fig .",
    "[ fig : expdtree ] and used in the running example throughout this section .",
    "the hrg rule induction steps described in this section can be broken into two steps : ( i ) creating a clique tree and ( ii ) the hrg rule extraction process .    unfortunately , finding a clique tree with minimal width _",
    "i.e. _ , the treewidth @xmath60 , is np - complete .",
    "let @xmath61 and @xmath62 be the number of vertices and edges respectively in @xmath15 .",
    "tarjan and yannikakis maximum cardinality search ( mcs ) algorithm finds a usable clique tree  @xcite in linear time @xmath63 , but is not guaranteed to be minimal .",
    "the running time of the hrg rule extraction process is determined exclusively by the size of the clique tree as well as the number of vertices in each clique tree node . from defn .",
    "[ defn : cliquetree ] we have that the number of nodes in the clique tree is @xmath62 . when minimal , the number of vertices in an the largest clique tree node @xmath64 ( minus 1 ) is defined as the treewidth @xmath60 , however , clique trees generated by mcs have @xmath64 bounded by the maximum degree of @xmath15 , denoted as @xmath65  @xcite .",
    "therefore , given an elimination ordering from mcs , the computational complexity of the extraction process is in @xmath66 .",
    "in this section we show how to use the hrg extracted from the original graph @xmath15 ( as described in the previous section ) to generate a new graph @xmath37 .",
    "ideally , @xmath37 will be similar to , or have features that are similar to the original graph @xmath15 .",
    "we present two generation algorithms .",
    "the first generation algorithm is _ exact generation _ , which , as the name implies , creates an isomorphic copy of the original graph @xmath67 .",
    "the second generation algorithm is a fast _ stochastic generation _ technique that generates random graphs with similar characteristics to the original graph .",
    "each generation algorithm starts with @xmath68 containing only the starting nonterminal @xmath45 .",
    "exact generation operates by reversing the hrg extraction process . in order to do this , we must store the hrg rules @xmath23 as well as the clique tree @xmath3 ( or at least the order that the rules were created ) .",
    "the first hrg rule considered is always the rule with the nonterminal labelled @xmath45 as the lhs .",
    "this is because the clique tree traversal starts at the root , and because the root is the only case that results in @xmath45 on the lhs .",
    "the previous section defined an hrg @xmath30 that is constructed from a clique tree @xmath3 of some given hypergraph @xmath15 , and defn .",
    "[ defn : hrg ] defines the application of a production rule @xmath69 that transforms some hypergraph @xmath70 into a new hypergraph @xmath37 . by applying the rules created from the clique tree in order",
    ", we will create an @xmath37 that is isomorphic to the original hypergraph @xmath15 .    in the remainder of this section , we provide a more intuitive look at the exact generation property of the hrg by recreating the graph decomposed in the running example .     with the rhs to create a new graph @xmath37 .",
    "]    using the running example from the previous section , the application of rule 1 illustrated in fig .",
    "[ fig : rule1 ] shows how we transform the starting nonterminal into a new hypergraph , @xmath37 .",
    "this hypergraph now has two nonterminal hyperedges corresponding to the two children that the root clique had in fig .",
    "[ fig : expdtree ] .",
    "the next step is to replace @xmath68 with @xmath37 and then pick a nonterminal corresponding to the leftmost unvisited node of the clique tree .     with the rhs to create a new graph @xmath37 . ]",
    "we proceed down the left hand side of the clique tree , applying rule 2 to @xmath68 as shown in fig .",
    "[ fig : rule2 ] .",
    "the lhs of rule 2 matches the 3-ary hyperedge and replaces it with the rhs , which introduces a new internal vertex , two new terminal edges and a new nonterminal hyperedge .",
    "again we set @xmath68 to be @xmath37 and continue to the leftmost leaf in the example clique tree .     with the rhs to create a new graph @xmath37 .",
    "]    the leftmost leaf in fig .",
    "[ fig : expdtree ] corresponds to the application of rule  3 ; it is the next to be applied to the new nonterminal in @xmath37 and replaced by the rhs as illustrated in figure  [ fig : rule3 ] .",
    "the lhs of rule 3 matches the 2-ary hyperedge shown and replaces it with the rhs , which creates a new internal vertex along with two terminal edges . because rule 3 comes from a leaf node , it is a terminal rule and therefore does not add any nonterminal hyperedges .",
    "this concludes the left subtree traversal from fig .",
    "[ fig : expdtree ] .",
    "that is isomorphic to the original graph @xmath15 . ]",
    "continuing the example , the right subtree in the clique tree illustrated in fig .",
    "[ fig : expdtree ] has three further applications of the rules in @xmath23 . as illustrated in fig .",
    "[ fig : rule456 ] , rule 4 adds the final vertex , two terminal edges and one nonterminal hyperedge to @xmath37 . rule 5 and rule 6 do not create any more terminal edges or internal vertices in @xmath37 , but are still processed because of the way the clique tree is constructed .",
    "after all 6 rules are applied in order , we are guaranteed that @xmath15 and @xmath37 are isomorphic .",
    "there are many cases in which we prefer to create very large graphs in an efficient manner that still exhibit the local and global properties of some given example graph _ without storing the large clique tree _ as required in exact graph generation . here",
    "we describe a simple stochastic hypergraph generator that applies rules from the extracted hrg in order to efficiently create graphs of arbitrary size .    in larger hrgs",
    "we usually find many @xmath24 production rules that are identical .",
    "we can merge these duplicates by matching rule - signatures in a dictionary , and keep a count of the number of times that each distinct rule has been seen .",
    "for example , if there were some additional rule 7 in fig .",
    "[ fig : production_rules ] that was identical to , say , rule 3 , then we would simply note that we saw rule 3 two times .    to generate random graphs from a probabilistic hrg ,",
    "we start with the special starting nonterminal @xmath71 . from this point",
    ", @xmath37 can be generated as follows : ( 1 ) pick any nonterminal @xmath19 in @xmath68 ; ( 2 ) find the set of rules @xmath72 associated with lhs @xmath19 ; ( 3 ) randomly choose one of these rules with probability proportional to its count ; ( 4 ) replace @xmath19 in @xmath68 with @xmath25 to create @xmath37 ; ( 5 ) replace @xmath68 with @xmath37 and repeat until there are no more nonterminal edges .",
    "however , we find that although the sampled graphs have the same mean size as the original graph , the variance is much too high to be useful .",
    "so we want to sample only graphs whose size is the same as the original graph s , or some other user - specified size . naively , we can do this using rejection sampling : sample a graph , and if the size is not right , reject the sample and try again .",
    "however , this would be quite slow .",
    "our implementation uses a dynamic programming approach to do this exactly while using quadratic time and linear space , or approximately while using linear time and space .",
    "we omit the details of this algorithm here , but the source code is available online at https://github.com / nddsg / hrg/.",
    "hrgs contain rules that succinctly represent the global and local structure of the original graph . in this section",
    ", we compare our approach against some of the state - of - the - art graph generators .",
    "we consider the properties that underlie a number of real - world networks and compare the distribution of graphs generated using generators for kronecker graphs , the exponential random graph , chung - lu graphs , and the graphs produced by the stochastic hyperedge replacement graph grammar .    in a manner similar to hrgs ,",
    "the kronecker and exponential random graph models learn parameters that can be used to approximately recreate the original graph @xmath15 or a graph of some other size such that the stochastically generated graph holds many of the same properties as the original graph .",
    "the chung - lu graph model relies on node degree sequences to yield graphs that maintain this distribution . except in the case of exact hrg generation described above",
    ", the stochastically generated graphs are likely not isomorphic to the original graph .",
    "we can , however , still judge how closely the stochastically generated graph resembles the original graph by comparing several of their properties .      in order to get a holistic and varied view of the strengths and weaknesses of hrgs in comparison to the other leading graph generation models , we consider real - world networks that exhibit properties that are both common to many networks across different fields , but also have certain distinctive properties .",
    ".real networks [ cols=\">,^,^\",options=\"header \" , ]     [ tab : realnets ]    the four real world networks considered in this paper are described in table  [ tab : realnets ] .",
    "the networks vary in their number of vertices and edges as indicated , but also vary in clustering coefficient , diameter , degree distribution and many other graph properties .",
    "specifically , the enron graph is the email correspondence graph of the now defunct enron corporation ; the arxiv gr - qc graph is the co - authorship graph extracted from the general relativity and quantum cosmology section of arxiv ; the internet router graph is created from traffic flows through internet peers ; and , finally , dblp is the co - authorship graph from the dblp dataset .",
    "datasets were downloaded from the snap and konect dataset repositories .",
    "we compare several different graph properties from the 4 classes of graph generators ( hrg , kronecker , chung - lu and exponential random graph ( ergm ) models ) to the original graph @xmath15 .",
    "other models , such as the erds - rnyi random graph model , the watts - strogatz small world model , the barabsi - albert generator , etc . are not compared here due to limited space and because kronecker , chung - lu and ergm have been shown to outperform these earlier models when matching network properties in empirical networks .",
    "kronecker graphs operate by learning an initiator matrix and then performing a recursive multiplication of that initiator matrix in order to create an adjacency matrix of the approximate graph . in our case",
    ", we use kronfit  @xcite with default parameters to learn a @xmath73 initiator matrix and then use the recursive kronecker product to generate the graph .",
    "unfortunately , the kronecker product only creates graphs where the number of nodes is a power of 2 , _",
    "i.e. _ , @xmath74 , where we chose @xmath75 , @xmath76 , @xmath77 , and @xmath78 for enron , arxiv , routers and dblp graphs respectively to match the number of nodes as closely as possible .",
    "the chung - lu graph model ( cl ) takes , as input , a degree distribution and generates a new graph of the similar degree distribution and size  @xcite .",
    "exponential random graph models ( ergms ) are a class of probabilistic models used to directly describe several structural features of a graph  @xcite .",
    "we used default parameters in r s ergm package  @xcite to generate graph models for comparison .",
    "in addition to the problem of model degeneracy , ergms do not scale well to large graphs . as a result , dblp and enron",
    "could not be modelled due to their size , and the arxiv graph always resulted in a degenerate model .",
    "therefore ergm results are omitted from this section .    the main strength of hrg is to learn the patterns and rules that generate a large graph from only a few small subgraph - samples of the original graph .",
    "so , in all experiments , we make @xmath79 random samples of size @xmath80 node - induced subgraphs by a breadth first traversal starting from a random node in the graph  @xcite . by default we set @xmath81 and @xmath82 empirically .",
    "we then compute tree decompositions from the @xmath79 samples , learn hrgs @xmath83 , and combine them to create a single grammar @xmath84 . for evaluation purposes , we generate 20 approximate graphs for the hrg , chung - lu , and kronecker models and plot the mean values in the results section .",
    "we did compute the confidence internals for each of the models , but omitted them from the graphs for clarity .",
    "in general , the confidence intervals were very small for hrg , kronecker and cl ( indicating good consistency ) , but very big in the few ergm graphs that we were able to generate because of the model degeneracy problem we encountered .",
    "here we compare and contrast the results of approximate graphs generated from hrg , kronecker product , and chung - lu .",
    "before the results are presented , we briefly introduce the graph properties that we use to compare the similarity between the real networks and their approximate counterparts .",
    "although many properties have been discovered and detailed in related literature , we focus on three of the principal properties from which most others can be derived .    * degree distribution . *",
    "the degree distribution of a graph is the distribution of the number of edges connecting to a particular vertex .",
    "barabsi and albert initially discovered that the degree distribution of many real world graphs follows a power law distribution such that the number of nodes @xmath85 where @xmath86 and @xmath87 is typically between 2 and 3  @xcite .",
    "figure  [ fig : real_degree ] shows the results of the degree distribution property on the four real world graphs ( @xmath88 or @xmath89 as a function of degree @xmath79 ) .",
    "recall that the graph results plotted here and throughout the results section are the mean averages of 20 generated graphs .",
    "each of the generated graphs is slightly different from the original graphs in their own way . as expected , we find that the power law degree distribution is captured by existing graph generators as well as the hrg model",
    ".    * eigenvector centrality . * the principal eigenvector is often associated with the centrality or `` value '' of each vertex in the network , where high values indicate an important or central vertex and lower values indicate the opposite .",
    "a skewed distribution points to a relatively few `` celebrity '' vertices and many common nodes .",
    "the principal eigenvector value for each vertex is also closely associated with the pagerank and degree value for each node .",
    "figure  [ fig : real_eig ] shows the eigenvector scores for each node ranked highest to lowest in each of the four real world graphs . because the x - axis represents individual nodes , fig .",
    "[ fig : real_eig ] also shows the size difference among the generated graphs .",
    "hrg performs consistently well across all four types of graphs , but the log scaling on the y - axis makes this plot difficult to discern .",
    "to more concretely compare the eigenvectors , the pairwise cosine distance between eigenvector centrality of @xmath15 and the mean eigenvector centrality of each model s generated graphs appear at the top of each plot in order .",
    "hrg consistently has the lowest cosine distance followed by chung - lu and kronecker .",
    "* hop plot .",
    "* the hop plot of a graph shows the number of vertex - pairs that are reachable within @xmath90 hops .",
    "the hop plot , therefore , is another way to view how quickly a vertex s neighborhood grows as the number of hops increases . as in related work",
    "@xcite we generate a hop plot by picking 50 random nodes and perform a complete breadth first traversal over each graph .",
    "figure  [ fig : real_hopplot ] demonstrates that hrg graphs produce hop plots that are remarkably similar to the original graph .",
    "chung - lu performs rather well in most cases ; kronecker has poor performance on arxiv and dblp graphs , but still shows the correct hop plot shape .",
    "the previous network properties primarily focus on statistics of the global network . however , there is mounting evidence which argues that the graphlet comparisons are the most complete way measure the similarity between two graphs  @xcite .",
    "the graphlet distribution succinctly describes the number of small , local substructures that compose the overall graph and therefore more completely represents the details of what a graph `` looks like . ''",
    "furthermore , it is possible for two very dissimilar graphs to have the same degree distributions , hop plots , etc . , but it is difficult for two dissimilar graphs to fool a comparison with the graphlet distribution .",
    "* graphlet correlation distance * recent work from systems biology has identified a new metric called the graphlet correlation distance ( gcd ) .",
    "the gcd computes the distance between two graphlet correlation matrices ",
    "one matrix for each graph  @xcite .",
    "it measures the frequency of the various graphlets present in each graph , _",
    "i.e. _ , the number of edges , wedges , triangles , squares , 4-cliques , etc . , and compares the graphlet frequencies between two graphs . because the gcd is a distance metric , lower values are better .",
    "the gcd can range from @xmath91 $ ] , where the gcd is 0 if the two graphs are isomorphic .",
    "we computed the gcd between the original graph and each generated graph .",
    "figure  [ fig : gcd_real ] shows the gcd results .",
    "although they are difficult to see due to their small size , fig .",
    "[ fig : gcd_real ] includes error bars for the 95% confidence interval .",
    "the results here are clear : hrg significantly outperforms the chung - lu and kronecker models .",
    "the gcd opens a whole new line of network comparison methods that stress the graph generators in various ways .",
    "recall that hrg learns the grammar from @xmath81 subgraph - samples from the original graph .",
    "in essence , hrg is extrapolating the learned subgraphs into a full size graph .",
    "this raises the question : if we only had access to a small subset of some larger network , could we use our models to infer a larger ( or smaller ) network with the same local and global properties ?",
    "for example , given the 34-node karate club graph , could we infer what a hypothetical karate franchise might look like ?    using two smaller graphs , zachary s karate club ( 34 nodes , 78 edges ) and the protein - protein interaction network of _ s.  cerevisiae _ yeast ( 1,870 nodes , 2,240 edges ) , we learned an hrg model with @xmath92 and @xmath93 , _ i.e. _ , no sampling , and generated networks of size-@xmath94 = 2x , 3x ,  , 32x . for the protein graph we also sampled down to @xmath95 .",
    "powers of 2 were used because the standard kronecker model can only generate graphs of that size .",
    "the chung - lu model requires a size-@xmath94 degree distribution as input . to create the proper degree distribution we fitted a poisson distribution ( @xmath96 ) and a geometric distribution ( @xmath97 ) to karate and protein graphs respectively and drew @xmath94 degree - samples from their respective distributions . in all cases",
    ", we generated 20 graphs at each size - point .",
    "+    rather than comparing raw numbers of graphlets , the gcd metric compares the _ correlation _ of the resulting graphlet distributions . as a result , gcd is largely immune to changes in graph size .",
    "thus , gcd is a good metric for this extrapolation task .",
    "figure  [ fig : xtrapol ] shows the mean gcd score and 95% confidence intervals for each graph model .",
    "not only does hrg generate good results at @xmath98x , the gcd scores remain mostly level as @xmath94 grows .",
    "we have shown that hrg can generate graphs that match the original graph from @xmath81 samples of @xmath82-node subgraphs .",
    "if we adjust the size of the subgraph , then the size of the clique tree will change causing the grammar to change in size and complexity .",
    "a large clique tree ought to create more rules and a more complex grammar , resulting in a larger model size and better performance ; while a small clique tree ought to create fewer rules and a less complex grammar , resulting in a smaller model size and a lower performance .    to test this hypothesis we generated graphs by varying the number of subgraph samples @xmath79 from 1 to 32 , while also varying the size of the sampled subgraph @xmath80 from 100 to 600 nodes .",
    "again , we generated 20 graphs for each parameter setting .",
    "figure  [ fig : grammarsize ] shows how the model size grows as the sampling procedure changes on the internet routers graph .",
    "plots for other graphs show a similar growth rate and shape , but are omitted due to space constraints .    to test the statistical correlation we calculated pearson s correlation coefficient between the model size and sampling parameters .",
    "we find that the @xmath79 is slightly correlated with the model size on routers ( @xmath99 , @xmath100 ) , enron ( @xmath101 ) , arxiv ( @xmath102 ) , and dblp ( @xmath103 , @xmath104 ) .",
    "furthermore , the choice of @xmath80 affects the size of the clique tree from which the grammars are inferred .",
    "so its not surprising that @xmath80 is highly correlated with the model size on routers ( @xmath105r=0.71 ) , arxiv ( @xmath106 ) , and dblp ( @xmath107 ) all with @xmath108 .    because we merge identical rules when possible , we suspect that the overall growth of the hrg model follows heaps law  @xcite , _",
    "i.e. _ , that the model size of a graph can be predicted from its rules ; although we save a more thorough examination of the grammar rules as a matter for future work .      one of the disadvantages of the hrg model , as indicated in fig .",
    "[ fig : grammarsize ] , is that the model size can grow to be very large .",
    "but this again begs the question : do larger and more complex hrg models result in improved performance ?    to answer this question we computed the gcd distance between the original graph and graphs generated by varying @xmath79 and @xmath80 .",
    "figure  [ fig : size_score ] illustrates the relationship between model size and the gcd .",
    "we use the router and dblp graphs to shows the largest and smallest of our dataset ; other graphs show similar results , but their plots are omitted due to of space .",
    "surprisingly , we find that the performance of models with only 100 rules is similar to the performance of the largest models . in the router results , two very small models with poor performance had only 18 and 20 rules each .",
    "best fit lines are drawn to illustrate the axes relationship where negative slope indicates that larger models generally perform better .",
    "outliers can dramatically affect the outcome of best fit lines , so the faint line in the routers graph shows the best fit line if we remove the two square outlier points . without removing outliers ,",
    "we find only a slightly negative slope on the best fit line indicating only a slight performance improvement between hrg models with 100 rules and hrg models with 1,000 rules .",
    "pearson s correlation coefficient comparing gcd and model size similarly show slightly negative correlations on routers ( @xmath109 , @xmath110 ) , enron ( @xmath111 ) , arxiv ( @xmath112 ) , and dblp ( @xmath113 , @xmath114 )      the overall execution time of the hrg model is best viewed in two parts : ( 1 ) rule extraction , and ( 2 ) graph generation .",
    "we previously identified the runtime complexity of the rule extraction process to be @xmath115 .",
    "however , this did not include @xmath79 samples of size-@xmath80 subgraphs .",
    "so , when sampling with @xmath79 and @xmath80 , we amend the runtime complexity to be @xmath116 where @xmath62 is bounded by the number of hyperedges in the size-@xmath80 subgraph sample and @xmath117 .",
    "graph generation requires a straightforward application of rules and is linear in the number of edges in the output graph .",
    "all experiments were performed on a modern consumer - grade laptop in an unoptimized , unthreaded python implementation .",
    "we recorded the extraction time while generating graphs for the size - to - gcd comparison in the previous section .",
    "although the runtime analysis gives theoretical upper bounds to the rule extraction process , fig .",
    "[ fig : size_time ] shows that the extraction runtime is highly correlated to the size of the model in routers ( @xmath106 ) , arxiv ( @xmath118 ) , enron ( @xmath119 ) , and dblp ( @xmath120 ) all with @xmath108 .",
    "simply put , more rules require more time , but there are diminishing returns .",
    "so it may not be necessary to learn complex models when smaller hrg models tend to perform reasonably well .",
    "lastly , we characterize the robustness of graph generators by introducing a new kind of test we call the _ infinity mirror _  @xcite .",
    "one of the motivating questions behind this idea was to see if hrg holds sufficient information to be used as a reference itself . in this test",
    ", we repeatedly learn a model from a graph generated by the an earlier version of the same model .",
    "for hrg , this means that we learn a set of production rules from the original graph @xmath15 and generate a new graph @xmath37 ; then we set @xmath121 and repeat thereby learning a new model from the generated graph recursively .",
    "we repeat this process ten times , and compare the output of the tenth recurrence with the original graph using gcd .",
    "we expect to see that all models degenerate over 10 recurrences because graph generators , like all machine learning models , are lossy compressors of information .",
    "the question is , how quickly do the models degenerate and how bad do the graphs become ?",
    "figure  [ fig : inf_mir_gcd ] shows the gcd scores for the hrg , chung - lu and kronecker models at each recurrence .",
    "surprisingly , we find that hrg stays steady , and even improves its performance while the kronecker and chung - lu models steadily decrease their performance as expected",
    ". we do not yet know why hrg improves performance in some cases .",
    "because gcd measures the graphlet correlations between two graphs , the improvement in gcd may be because hrg is implicitly honing in on rules that generate the necessary graph patterns .",
    "yet again , further work is needed to study this important phenomenon .",
    "in this paper we have shown how to use clique trees ( also known as junction trees , tree decomposition , intersection trees ) constructed from a simple , general graph to learn a hyperedge replacement grammar ( hrg ) for the original graph .",
    "we have shown that the extracted hrg can be used to reconstruct a new graph that is isomorphic to the original graph if the clique tree is traversed during reconstruction .",
    "more practically , we show that a stochastic application of the grammar rules creates new graphs that have very similar properties to the original graph .",
    "the results of graphlet correlation distance experiments , extrapolation and the infinity mirror are particularly exciting because our results show a stark improvement in performance over existing graph generators .    in the future",
    ", we plan to investigate differences between the grammars extracted from different types of graphs ; we are also interested in exploring the implications of finding two graphs which have a large overlap in their extracted grammars . among the many areas for future work that this study opens , we are particularly interested in learning a grammar from the actual growth of some dynamic or evolving graph . within the computational theory community",
    "there has been a renewed interest in quickly finding clique trees of large real world graphs that are closer to optimal . because of the close relationship of hrg and clique trees shown in this paper , any advancement in clique tree algorithms could directly improve the speed and accuracy of graph generation .",
    "perhaps the most important finding that comes from this work is the ability to interrogate the generation of substructures and subgraphs within the grammar rules that combine to create a holistic graph .",
    "forward applications of the technology described in this work may allow us to identify novel patterns analogous to the previously discovered triadic closure and bridge patterns found in real world social networks .",
    "thus , an investigation in to the nature of the extracted rules and their meaning ( if any ) is a top priority .",
    "we encourage the community to explore further work bringing hrgs to attributed graphs , heterogeneous graphs and developing practical applications of the extracted rules .",
    "given the current limitation related to the growth in the number of extracted rules as well as the encouraging results from small models , we are also looking for sparsification techniques that might limit the model s size while still maintaining performance .",
    "this work is supported by the templeton foundation under grant fp053369-m / o .",
    "s.  aguinaga and t.  weninger . the infinity mirror test for analyzing the robustness of graph generators . in _",
    "acm sigkdd workshop on mining and learning with graphs _ , mlg 16 , new york , ny , usa , 2016 ."
  ],
  "abstract_text": [
    "<S> discovering the underlying structures present in large real world graphs is a fundamental scientific problem . in this paper </S>",
    "<S> we show that a graph s clique tree can be used to extract a hyperedge replacement grammar . </S>",
    "<S> if we store an ordering from the extraction process , the extracted graph grammar is guaranteed to generate an isomorphic copy of the original graph . or , a stochastic application of the graph grammar rules can be used to quickly create random graphs . in experiments on large real world networks , </S>",
    "<S> we show that random graphs , generated from extracted graph grammars , exhibit a wide range of properties that are very similar to the original graphs . in addition to graph properties like degree or eigenvector centrality , what a graph `` looks like '' ultimately depends on small details in local graph substructures that are difficult to define at a global level . we show that our generative graph model is able to preserve these local substructures when generating new graphs and performs well on new and difficult tests of model robustness .    </S>",
    "<S> = [ circle , minimum width=10 , draw , fill = black!5 , inner sep=1.5 ] = [ circle , minimum width=10 , draw = black!40 , fill = black!05 , inner sep=1.5 , text = black!40 ] = [ rounded corners=3pt , draw , minimum height=14pt , inner sep=0 ] = [ itxset , ultra thick ] = [ textnode , circle , draw , fill , text = white ] = [ textnode , circle , draw ] = [ textnode , draw , inner xsep=1.5 ] = [ circle , draw , fill , minimum size=1.0mm , inner sep=0pt , outer sep=0pt ] = [ circle , draw , fill , minimum size=1.2mm , inner sep=0pt , outer sep=0pt ] = [ draw = black!40 , inner sep=1.5 , text = black!40 ] = [ very thin , color = black!50 ] </S>"
  ]
}