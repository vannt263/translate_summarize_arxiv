{
  "article_text": [
    "rare events are processes which happen rapidly , yet infrequently .",
    "specialized techniques are required in order to study these events using computer simulation .",
    "this is because , in `` brute force '' simulations , the vast majority of the computational effort is used in simulating the uninteresting waiting periods between events , so that observing enough events for reliable statistical analysis is generally impossible .",
    "the quantities of interest from the simulation point of view are generally the rate constant for the rare transitions between the initial and final states and the properties of the transition path ensemble ( tpe ) - the ( correctly weighted ) collection of transition trajectories . when computing these quantities , it is very important to know the statistical error in the calculated value , and the likely cost of the computation . in this paper",
    ", we derive approximate expressions for these quantities , for three rare event simulation methods which we proposed in a recent publication @xcite .",
    "these expressions turn out to be surprisingly accurate for simulations of a model rare event problem .",
    "our results allow us to quantify the computational efficiency of the three methods .",
    "the three `` ffs - type '' simulation methods allow the computation of both the rate constant and the transition paths for rare events in equilibrium or non - equilibrium steady - state systems with stochastic dynamics . in all three methods , a series of interfaces",
    "are defined between the initial and final states .",
    "the rate constant is given by the flux of trajectories crossing the first interface , multiplied by the probability that these trajectories subsequently reach b. the latter probability is computed by carrying out a series of `` trial '' runs between successive interfaces ; this procedure also generates transition paths , which are chains of connected successful trial runs .",
    "the methods differ in the way the trial runs are fired and the transition paths are generated . in the `` forward flux sampling '' ( ffs )",
    "method , a collection of points is generated at the first interface and trial runs are used to propagate this collection of points to subsequent interfaces - thus generating many transition paths simultaneously . in the branched growth ( bg ) method , a single point is generated at the first interface and is used as the starting point for multiple trial runs to the next interface .",
    "each successful trial generates a starting point for multiple trials to the following interface , so that a `` branching tree '' of transition paths is generated . in the rosenbluth ( rb )",
    "method , a single starting point is chosen at the first interface , multiple trial runs are carried out , but only one successful trial is used to propagate the path to the next interface - thus unbranched transition paths are generated . in this method , a re - weighting step is needed to ensure correctly weighted transition paths",
    ".    a range of simulation techniques for rare events in soft condensed matter systems are currently available .",
    "in bennett - chandler - type methods , the rate constant is obtained via a computation of a free energy barrier @xcite . in transition path sampling ( tps )",
    "@xcite , transition trajectories ( paths ) are generated by shooting forwards and backwards in time from already existing paths , and are then sampled using a monte carlo procedure .",
    "the rate constant is obtained via the computation of a time correlation function .",
    "bennett - chandler - type methods and tps are suitable for systems with stochastic or deterministic dynamics , but they require knowledge of the steady state phase space density , which means that the system must be in equilibrium . while the ffs - type methods are only suitable for systems with stochastic dynamics , they do not require the phase space density to be known and can therefore be used for non - equilibrium steady states not satisfying detailed balance . to our knowledge ,",
    "the only other path sampling method that is suitable for non - equilibrium systems is that proposed recently by crooks and chandler @xcite , which adopts a `` tps''-type methodology , generating new stochastic paths from old paths by changing the random number history .",
    "the origin of the efficiency of the ffs - type methods is that they use a series of interfaces in phase space between the initial and final states to divide up the transition paths into a series of connected `` partial paths '' .",
    "these partial paths are generated in a ratchet - like manner - _ i.e. _ once a particular interface has been reached , the system configuration is stored and is used to initiate trial runs to the next interface .",
    "many other rare event techniques also use a series of interfaces in phase space . in transition interface sampling ( tis )",
    "@xcite and partial path transition interface sampling ( pptis ) @xcite , interfaces are used to facilitate the generation of transition paths by a tps - like procedure . in milestoning @xcite , trajectories are generated between interfaces assuming a steady - state distribution at each interface , while string methods @xcite use a series of planes in phase space to allow a trajectory connecting the initial and final states to relax to the minimum free energy path .",
    "the advantages of the ffs - type methods over other transition path and rate constant calculation methods are that no assumptions are made about `` loss of memory '' during the transition , no _ a priori _ knowledge is required of the steady state phase space density , and the rate constant is obtained in a simple and straightforward way .",
    "we have recently become aware that the bg method bears resemblance to the restart method , used for simulating telecommunications networks @xcite ( this approach was originally introduced by bayes @xcite ) .",
    "the efficiency of that method has also been analysed @xcite .",
    "a related method , known as weighted ensemble brownian dynamics , has been applied to protein association reactions @xcite .",
    "the key aim of a rare event simulation technique is to calculate the rate constant , or in some cases , obtain the tpe , with enhanced efficiency , compared to brute force simulations .",
    "however , quantifying the efficiency of a particular simulation method is often difficult .",
    "our aim in this paper is to derive simple but accurate expressions for the computational cost and statistical accuracy of the three ffs - type methods .",
    "we define the `` efficiency '' of the methods to be the inverse of the product of the cost and the variance in the calculated rate constant ; our results then allow us to analyse the efficiency of the methods in a systematic way . from a practical point of view",
    ", we expect the expressions derived here to be of use to those carrying out simulations in two ways .",
    "firstly , when faced with a rare event problem , one often has a limited amount of computer time available , and specific requirements as to the desired accuracy of the calculated rate constant .",
    "analytical expressions for the cost and statistical accuracy would allow one to estimate , before beginning the calculation , whether the desired accuracy can be obtained within the available time , and thus to make an informed decision as to which , if any , method to use . secondly , after completing a rate constant calculation , one needs to obtain error bars on the resulting value - this is especially important for rare events , where both experimental and simulation results can be highly inaccurate . in general ,",
    "error estimation requires the calculation to be repeated several times , which is computationally expensive .",
    "however , if analytical expressions were available for the statistical accuracy , in terms of quantities which were already measured during the rate constant calculation , one could obtain the error bars on the predicted rate constant , to within reasonable accuracy , without the need for lengthy additional calculations . in this paper , we derive such analytical expressions .",
    "approximate expressions are derived for the cost , in simulation steps , and for the variance in the calculated rate constant , for the three ffs - type methods .",
    "we initially treat the simple case where all trials fired from one interface have equal probability of succeeding .",
    "we then move on to the more realistic case where the probability of reaching the next interface depends on the identity of the starting point . to this end",
    ", we include in our calculations the `` landscape variance '' - the variance in the probability of reaching the next interface , due to the characteristic `` landscape '' for this particular rare event problem .",
    "our expressions are functions of user - defined parameters , such as the number of trial runs per point at a particular interface , as well as parameters characterizing the rare event problem itself , such as the probability that a trial run succeeds in reaching the next interface .",
    "we analyse the efficiency of the three methods as a function of the parameters , for a `` generalized '' model system .",
    "we find that the optimum efficiency is similar for all three methods , but that the effects of changing the parameter values are very different for the three methods .",
    "in particular , the bg method performs well only within a narrow range of parameter values , while the ffs and rb methods are more robust to changes in the parameters .",
    "the rb method has consistently lower efficiency , due to its requirement for an acceptance / rejection step - however , rb may be more suitable for applications where analysis of transition paths as well as rates is needed , or where storage of configurations is very expensive .    to test the accuracy of our predictions in the context of a real simulation problem",
    ", we then apply the three ffs - type methods to the two - dimensional non - equilibrium rare event problem proposed by maier and stein @xcite .",
    "we measure the computational cost of the methods and the variance in the final value of the rate constant , and we compare these to the cost and variance predicted by the expressions derived earlier .",
    "we find that the expressions give remarkably good predictions , both for the cost and the variance .",
    "this suggests that the expressions can , indeed , be used to give accurate and easy - to - calculate error estimates for real simulation problems .    in section [ ffs_recap ] ,",
    "we briefly describe the three ffs - type methods .",
    "expressions for the computational cost and for the statistical error in the calculated rate constant are derived in section [ efficiency ] . in section [ sec_ms",
    "] , these expressions are shown to be accurate for the two - dimensional non - equilibrium rare event problem proposed by maier and stein . finally , we discuss our conclusions in section [ discuss ] .",
    "the ffs - type methods use the `` effective positive flux '' expression for the rate constant , which was rigorously derived by van erp _",
    "et al _ @xcite .",
    "the rare event consists of a transition between two regions of phase space @xmath0 and @xmath1 , where @xmath2 denotes the coordinates of the phase space .",
    "the transition occurs much faster than the average waiting time in the @xmath3 state .",
    "we assume that a parameter @xmath4 can be defined , such that @xmath5 in @xmath3 and @xmath6 in @xmath7 . a series of values of @xmath8 , @xmath9 ,",
    "are chosen such that @xmath10 , @xmath11 and @xmath12 .",
    "these must constitute a series of non - intersecting surfaces in phase space , such that any transition path leading from @xmath3 to @xmath7 passes through each surface in turn .",
    "this is illustrated in figure [ fig1 ] .",
    "the rate constant @xmath13 can be expressed as @xcite @xmath14 in eq . ( [ eq1 ] ) , @xmath15 is a history - dependent function describing whether the system was more recently in @xmath3 or @xmath7 : @xmath16 if the system was more recently in @xmath3 than in @xmath7 , and @xmath17 otherwise @xcite .",
    "the over - bar denotes a time average .",
    "@xmath18 is the flux of trajectories with @xmath16 that cross @xmath19 for the first time - _ i.e. _ those trajectories that cross @xmath19 , having been in @xmath3 more recently than any previous crossings of @xmath19 .",
    "@xmath20 is the probability that a trajectory that comes from @xmath3 and crosses @xmath21 for the first time will subsequently reach @xmath22 before returning to @xmath3 : thus @xmath23 is the probability that a trajectory that leaves @xmath3 and crosses @xmath24 will subsequently reach @xmath7 before returning to @xmath3 .",
    "eq.([eq1 ] ) states that the flux of trajectories from @xmath3 to @xmath7 can be expressed as the flux leaving @xmath3 and crossing @xmath24 , multiplied by the probability that one of these trajectories will subsequently arrive at @xmath7 rather that returning to @xmath3 .",
    "@xmath23 can be expressed as the product of the probabilities of reaching each successive interface from the previous one , without returning to @xmath3 : @xmath25 for simplicity of notation , in what follows , we define @xmath26 , @xmath27 , @xmath28 and @xmath29 .",
    "we also use the superscript `` @xmath30 '' to indicate an estimated value of a particular quantity .",
    "previously , we described in detail three different approaches - the `` forward flux sampling '' ( ffs ) , `` branched growth '' ( bg ) and `` rosenbluth '' ( rb ) methods - to calculating @xmath13 , based on expressions ( [ eq1 ] ) and ( [ eq2 ] ) @xcite . for completeness , we briefly repeat the description here .      in ffs , the flux @xmath31 is measured using a free simulation in the basin of attraction of region @xmath3 .",
    "when the system leaves @xmath3 and crosses @xmath24 for the first time ( since leaving @xmath3 ) , its phase space coordinates are stored and the run is continued . in this way ,",
    "a collection of @xmath32 points at @xmath24 is generated , after which the simulation run is terminated .",
    "the probabilities @xmath33 are then estimated using a trial run procedure . beginning with the collection of points at @xmath24 , a large number @xmath34 of trials",
    "are carried out .",
    "for each trial , a point is selected at random from the collection at @xmath24 .",
    "this point is used to initiate a simulation run , which is continued until the system either crosses the next interface @xmath35 , or re - enters @xmath3 .",
    "if @xmath35 is reached , the final point of the run is stored in a new collection .",
    "after @xmath34 trials , @xmath36 is given by @xmath37 , where @xmath38 is the number of trials which reached @xmath35 .",
    "the probability @xmath39 is then estimated in the same way : the new collection of points at @xmath35 is used to initiate @xmath40 trial runs to @xmath41 ( or back to @xmath3 ) , generating a new collection of points at @xmath41 , and so on .",
    "finally , the rate constant is obtained using eqs ( [ eq1 ] ) and ( [ eq2 ] ) .",
    "ffs generates transition paths according to their correct weights in the tpe @xcite . in order to analyse these transition paths ,",
    "one begins with the collection of trial runs which arrive at @xmath42 from @xmath43 and traces back the sequence of connected partial paths which link them to region @xmath3 .",
    "the resulting transition paths are branched - _ i.e. _ a single point at @xmath24 can be the starting point of multiple transition paths .      in the bg method , which was inspired by techniques for polymer sampling @xcite , branched transition paths are generated one by one , rather than simultaneously , as in ffs .",
    "the generation of each path begins with a single point at @xmath24 , obtained using a simulation in the basin of attraction of @xmath3 , as in the ffs method .",
    "this point is used to initiate @xmath44 trial runs , which are continued until they either reach @xmath35 , or return to @xmath3 .",
    "each of the @xmath38 end points at @xmath35 becomes a starting point for @xmath45 trial runs to @xmath41 or back to @xmath3 .",
    "each of the @xmath46 successful trial runs to @xmath41 initiates @xmath47 trials to @xmath48 , and so on until @xmath49 is reached .",
    "an estimate @xmath50 of @xmath51 is obtained as the total number of branches that eventually reach @xmath49 , divided by the total possible number : @xmath52 . if , at any interface , no trials were successful , @xmath53 . to generate the next branching path",
    ", we obtain a new starting point at @xmath24 from the simulation in the basin of attraction of @xmath3 .",
    "after many branching paths have been generated , an average is taken over the @xmath50 values of all the paths .",
    "the flux @xmath31 is meanwhile obtained from the simulation run in region @xmath3 .",
    "the branched transition paths that are generated in the bg method are correctly weighted members of the tpe @xcite .",
    "we note that the bg method bears resemblance to methods developed for telecommunication networks @xcite and to a method used for protein association @xcite .",
    "the rb path sampling method is related to the rosenbluth scheme for sampling polymer configurations @xcite .",
    "the rb method generates unbranched transition paths , one at a time . an initial point at @xmath24",
    "is obtained using a simulation in the @xmath3 basin , which is continued until the trajectory crosses @xmath24 for the first time , as in the ffs and bg methods .",
    "this point is used to initiate @xmath44 trials , which are continued until they either reach @xmath35 or return to @xmath3 .",
    "if @xmath54 of these trials reach @xmath35 , one successful trial is selected at random and its end point at @xmath35 is used to initiate @xmath45 trials to @xmath41 or back to @xmath3 .",
    "once again a successful trial is chosen at random and the process is repeated until either no trials are successful or @xmath49 is reached .",
    "the generation of the next path then begins with a new point at @xmath24 , obtained using the simulation run in the @xmath3 basin .",
    "the rosenbluth method as outlined above does not , however , generate paths according to their correct weights in the tpe : for correct sampling , paths must be re - weighted by a `` rosenbluth factor '' .",
    "the rosenbluth factor for a partial path up to interface @xmath55 is given by : @xmath56 note that the re - weighting factor @xmath57 depends on the number of successful trials obtained at all the previous interfaces , while generating the path up to @xmath58 .",
    "the correct re - weighting can be achieved using a metropolis - type acceptance / rejection scheme @xcite , in which a newly generated path is either accepted or rejected based on a comparison of its rosenbluth factor with that of a previously generated path .",
    "ensemble averages of any quantity of interest are then taken over all accepted paths . here , the quantity which we wish to calculate is the probability @xmath33 that a trial run fired from @xmath58 will reach @xmath59 , for each interface @xmath55 .",
    "when we fire @xmath60 trial runs from @xmath58 , we obtain an estimate for @xmath33 : @xmath61 .",
    "we require the correctly weighted ensemble average for @xmath62 at each interface @xmath55 ; we note , however , that the same procedure could also be used to calculate the ensemble average of any other property of the ensemble of paths from @xmath24 to @xmath58 .    from a practical point of view",
    ", each interface has associated with it _ two _ values of @xmath57 and @xmath62 .",
    "the first set of values : @xmath63 and @xmath64 , are associated with the transition path that is currently being generated ( the `` new '' path ) .",
    "@xmath63 depends on the number of successful trials generated in creating this transition path as far as @xmath58 , and @xmath65 depends on the number of successful trials fired from the point at @xmath58 to @xmath59 .",
    "the other set of values , @xmath66 and @xmath67 , are the `` old '' values for this interface .",
    "these values correspond to the last `` acceptance '' event at this interface .",
    "the recipe for obtaining @xmath13 within the rb method is as follows .",
    "transition paths are generated as described above .",
    "when the path generation procedure reaches @xmath58 , we calculate the rosenbluth factor @xmath63 ( using eq.([rfac ] ) ) and we fire @xmath60 trial runs to obtain @xmath65 .",
    "we then calculate the ratio @xmath68 and draw a random number @xmath69 . if @xmath70 , an acceptance event takes place . in this case , the previous values of @xmath66 and @xmath67 are replaced by the newly obtained values @xmath63 and @xmath64 . if , however , @xmath71 , a rejection occurs and @xmath66 and @xmath67 remain unchanged for this interface .",
    "regardless of the outcome of the acceptance / rejection step , the accumulator for the probability @xmath72 is incremented by the current value of @xmath67 - this may be either a newly generated value ( if an acceptance just occurred ) or an old value that may have been already added to the accumulator several times ( if several rejections have happened in a row ) . to proceed to the next interface ,",
    "a successful trial run is chosen out of those that have been newly generated , and its end point at @xmath59 is used as the starting point for @xmath73 trial runs to @xmath74 .",
    "a corresponding acceptance / rejection step is then carried out at @xmath59 .",
    "we note that the `` old '' values @xmath66 and @xmath67 for different interfaces need not correspond to the same transition path .",
    "after many complete transition paths have been generated , @xmath13 is obtained using eq.([eq1 ] ) , where an estimate of the flux @xmath31 is calculated from the simulation run in region @xmath3 .",
    "a `` pseudo - code '' corresponding to the above procedure is given in our previous publication @xcite , together with a description of an alternative , `` waste recycling '' @xcite re - weighting scheme .",
    "in this paper , however , we shall consider only the metropolis acceptance / rejection approach .",
    "in this section , we derive approximate expressions for the computational efficiency of the three methods . following mooij and frenkel @xcite , we use the following definition for the efficiency , @xmath75 : @xmath76 in eq .",
    "( [ eq_mooij ] ) , @xmath77 represents the computational cost , which we define to be the average number of simulation steps , per initial point at @xmath24 . the statistical error in the estimated value @xmath78 of the rate constant",
    "is represented by @xmath79 . denoting the mean ( expectation value ) of variable @xmath80 by @xmath81 $ ] and its variance by @xmath82 $ ]",
    ", we define @xmath79 to be the variance @xmath83 $ ] , per initial point at @xmath24 , divided by the square of the expectation value @xmath84 $ ] : @xmath85}{(e[k_{ab}^e])^2 } = n_0 \\frac{v[k_{ab}^e]}{k_{ab}^2}\\ ] ] where @xmath32 is the number of starting points at @xmath24 used in obtaining the estimate @xmath78 .",
    "the expectation value of @xmath78 is , of course , the true rate constant : @xmath84=k_{ab}$ ] .",
    "the error bar for @xmath78 is given by @xmath86 .",
    "we define the computational cost @xmath77 of a particular method to be the average number of simulation steps required by that method , per starting point at @xmath24 . in making this definition ,",
    "we ignore any other contributions to the cpu time , such as memory storage .",
    "to estimate the value of @xmath77 , we consider a generic system that makes a rare transition between states @xmath3 and @xmath7 .",
    "a parameter @xmath8 and interfaces @xmath9 are chosen as in section [ ffs_recap ] .",
    "there are two contributions to the cost @xmath77 .",
    "the first is the average cost @xmath87 , in simulation steps , of generating one starting point at @xmath24 .",
    "this is related to the flux @xmath31 from the @xmath3 region to @xmath24 by @xmath88 , where @xmath89 is the simulation timestep .",
    "the second contribution to @xmath77 is the cost of the trial run procedure .",
    "we first consider the cost @xmath90 of firing one trial run from interface @xmath58 .",
    "the run is continued until it reaches either the next interface @xmath59 ( with probability @xmath33 ) , or the boundary @xmath91 of region @xmath3 ( with probability @xmath92 ) .",
    "we make the assumption that the average length ( in simulation steps ) of a trajectory from interface @xmath58 to another interface @xmath19 is linearly proportional to @xmath93 , with proportionality constant @xmath94 .",
    "@xmath90 is then given by : @xmath95\\ ] ] the basis for the assumption of linearity in eq.([cost1 ] ) is that we suppose that the system undergoes one - dimensional diffusion along the @xmath8 coordinate in the presence of a `` drift force '' of fixed magnitude . for an equilibrium system ,",
    "the origin of the drift force is the free energy barrier .",
    "farkas and flp have presented analytical solutions @xcite for the mean time to capture for a particle undergoing one - dimensional diffusion with constant drift force , in the presence of two absorbing boundaries . in appendix",
    "[ pl_app ] , we show how these results lead to eq.([cost1 ] ) .",
    "eq.([cost1 ] ) is shown to be valid for the two - dimensional maier - stein problem in section [ sec_ms_params ] ( figure [ ms_udcosts ] ) .      given eq.([cost1 ] ) , we can compute the average cost @xmath77 per starting point at @xmath24 of the three methods .    in ffs",
    ", we make @xmath96 trial runs from interface @xmath55 and , providing at least one of these is successful , we proceed to the next interface @xmath97 . in practice , @xmath96 is expected to be large enough that at least one trial run reaches @xmath59 . in this case , the expected cost per starting point at @xmath24 is : @xmath98 defining @xmath60 such that @xmath99 , eq.([cost_ffs11 ] ) can be rewritten as : @xmath100 if , however , @xmath96 is small , we must take account of the possibility that none of the trial runs from @xmath58 reach @xmath59 . in this case , the ffs procedure is terminated at interface @xmath55 and the cost is accordingly reduced . since the probability of reaching interface @xmath101 is @xmath102 ( this is the probability that at least one trial is successful at all interfaces @xmath103 ) , eq.([cost_ffs21 ] ) is replaced by : @xmath104\\ ] ] although the cost is reduced by failing to reach later interfaces , this of course results in a less accurate prediction of the rate constant , since the terminated ffs calculation makes no contribution to the estimate of @xmath33 for later interfaces .",
    "this will be reflected in our expression for the statistical error in section [ err_sect ] .",
    "we now turn to the bg method .",
    "here , we generate a `` branching tree '' of paths , with @xmath105 points at interface @xmath55 originating from a single point at @xmath24 .",
    "we fire @xmath60 trial runs for each of these @xmath105 points",
    ". the average value of @xmath105 is : @xmath106 of course @xmath107 .",
    "the average cost per starting point at @xmath24 is therefore : @xmath108\\end{aligned}\\ ] ]    finally , we come to the rb method . in this algorithm , we generate unbranched paths by firing @xmath60 trials from interface @xmath55 , choosing one successful trial at random and proceeding to interface @xmath97 .",
    "if no trial runs are successful , we start again with a new point at @xmath24 . the probability of reaching interface @xmath101 is @xmath109 .",
    "the cost of the rb method , per starting point at @xmath24 , is therefore : @xmath110\\ ] ] once again , the `` price '' of failing to reach later interfaces will be paid in the form of an increased variance in the calculated rate constant .",
    "the effect of the metropolis acceptance / rejection step in the rb method appears only in the variance in @xmath78 ( section [ err_sect ] ) , and not in the cost .      for the purposes of illustration , let us consider a hypothetical rare event problem for which @xmath111 and @xmath112 .",
    "we suppose that the interfaces are evenly spaced in @xmath8 , have equal values of @xmath33 , and that the firing parameter @xmath60 is the same at each interface : _",
    "i.e. _ @xmath113 , @xmath114 ( from eq.([eq2 ] ) ) and @xmath115 .",
    "we also suppose that @xmath116 and @xmath117 .",
    "the resulting values of the cost @xmath77 , obtained from eqs ( [ cost_ffs22 ] ) , ( [ cost_bg ] ) and ( [ cost_ros ] ) , are plotted in figure [ cost_fig]a and b as functions of @xmath118 and @xmath119 . in the regime of small @xmath118 or small",
    "@xmath119 ( implying small @xmath120 ) , the bg and rb methods converge , while the cost of the ffs method is higher .",
    "this is because , for bg and rb , the probability of reaching later interfaces is low and the cost is dominated by the trial runs fired from early interfaces .",
    "the ffs procedure is less likely to be terminated at early interfaces ( note the factor of @xmath121 in eq.([cost_ffs22 ] ) as opposed to @xmath122 in eq .",
    "( [ cost_ros ] ) ) , and is therefore more expensive , per initial point at @xmath24 . in the regime of large @xmath118 or large",
    "@xmath119 ( implying large @xmath120 ) , a different scenario emerges . here , the bg method becomes by far the most expensive , with a cost that increases dramatically with increasing @xmath118 or @xmath119 .",
    "this effect is due to the rapidly increasing number of branches per starting point at @xmath24 . in this regime ,",
    "the ffs and rb methods converge to the same cost , since eqs ( [ cost_ffs22 ] ) and ( [ cost_ros ] ) become equivalent when @xmath123 .",
    "we now turn to the relative variance @xmath79 in the estimated value @xmath78 of the rate constant , per starting point at @xmath24 .",
    "@xmath78 is the product of the estimated flux through @xmath24 , multiplied by the estimated probability of subsequently reaching @xmath7 : @xmath124 ( eq.([eq1 ] ) ) .    in this paper",
    ", we shall ignore the error in @xmath125 .",
    "@xmath125 is obtained by carrying out a simulation run in the basin of attraction of @xmath3 and measuring the average number of simulation steps between successive crossings of @xmath24 ( coming directly from @xmath3 ) .",
    "as long as @xmath24 is positioned close enough to the @xmath3 region , the simulation run in @xmath3 can be made long enough to estimate @xmath31 with high accuracy , with a computational cost that is minimal compared to the cost of estimating @xmath51 .",
    "we therefore obtain : @xmath126}{(e[k_{ab}^e])^2 } \\approx n_0\\frac{\\phi^2 v[p_{b}^e]}{(\\phi e[p_{b}^e])^2 } =   n_0\\frac{v[p_{b}^e]}{p_{b}^2}\\ ] ] in eq.([err1 ] ) , we have used the general relation @xcite @xmath127 = a^2v[x]\\ ] ] where @xmath128 is a constant .    in what follows",
    ", we shall make the important assumption that the numbers @xmath129 of successful trial runs at different interfaces @xmath55 are _ uncorrelated _ - _ i.e. _ that if , during the generation of a transition path , one is particularly successful or unsuccessful at interface @xmath55 , this will have no effect on the chances of success at interface @xmath97 .",
    "in reality , of course , there will be correlation between interfaces , especially if the interfaces are closely spaced or the system dynamics have a large degree of `` memory '' .",
    "we expect this assumption to be the major limiting factor in the applicability of our results to real systems ; however , as we shall see in section [ sec_ms ] , the results are surprisingly accurate for the two - dimensional maier - stein problem .",
    "we expect that the expressions derived here could be modified to include the effects of correlations between interfaces ; for highly correlated systems this may prove necessary .",
    "the basis of our analysis is the fact that on firing @xmath60 trial runs from interface @xmath55 , the number of successful trials @xmath129 is binomially distributed @xcite , with mean @xmath130 = k_i p_i\\ ] ] and variance @xmath131 = k_i p_i q_i\\ ] ] for now , we assume that all trial runs fired from interface @xmath58 have equal probability @xmath33 of reaching @xmath59",
    ". this assumption will later be relaxed .",
    "we shall need to express the variance in @xmath50 in terms of the variance @xmath132 $ ] in the estimated values of @xmath33 at each interface . to do this",
    ", we recall that @xmath133 ( eq.([eq2 ] ) ) , and we make use of the following relation @xcite : @xmath134 = \\left(\\frac{\\partial f}{\\partial x}\\right)^2v[x ] + \\left(\\frac{\\partial f}{\\partial y}\\right)^2v[y ] + \\dots\\ ] ] where @xmath135 is a function of multiple uncorrelated variables @xmath136 and the partial derivatives are evaluated with all variables at their mean values . by `` uncorrelated variables '' we mean that the covariance @xmath137=0 $ ] for all pairs of variables @xmath80 and @xmath138 . identifying @xmath139 with @xmath140 and taking @xmath141",
    ", we find that @xmath142/p_i = p_b^e / p_i^e$ ] , so that @xmath143 =   \\sum_{i=0}^{n-1}e\\left[\\frac{p_b^e}{p_i^e}\\right]^2 v[p_i^{e } ] \\approx p_b^2 \\sum_{i=1}^{n}\\frac{v[p_i^{e}]}{p_i^2}\\ ] ]    we now use the above results to calculate @xmath79 for the ffs method . in this method , we begin with a collection of @xmath32 points at @xmath24 . for each interface",
    ", @xmath72 is obtained by firing @xmath144 trial runs : @xmath145 , where @xmath129 is the number of trials which reach @xmath59 . using eq.([veq3 ] ) , @xmath146=v[n_s^{(i)}]/m_i^2 $ ] . using eq.([simp ] ) , we find that @xmath147 = m_i p_i q_i$ ] .",
    "noting also that @xmath148 = p_i$ ] and using eq.([est1 ] ) , we obtain @xmath149 = p_b^2 \\sum_{i=0}^{n-1 } \\frac{q_i}{p_i m_i } = \\frac{p_b^2}{n_0}\\sum_{i=0}^{n-1 } \\frac{q_i}{p_i k_i}\\ ] ] and from eq.([err1 ] ) @xmath150 as for the cost calculation , we have assumed that @xmath96 is large enough that there is always at least one trial run which reaches the next interface .",
    "if this is not the case , we must also take account of the possibility that interfaces @xmath101 may not be reached .",
    "the probability of reaching interface @xmath101 is @xmath102 , so that @xmath151 =   \\frac{p_iq_i\\left(1-q_i^{m_i}\\right)}{m_i\\prod_{j=0}^{i}\\left(1-q_j^{m_j}\\right)}\\end{aligned}\\ ] ] eq.([test1 ] ) is written in this form so that for @xmath152 , we recover @xmath153 =   p_iq_i / m_i$ ] .",
    "eqs ( [ var_ffs1 ] ) and ( [ ffs_imp1 ] ) must then be replaced by : @xmath154 = p_b^2 \\left[\\sum_{i=0}^{n-1 } \\frac{q_i\\left(1-q_i^{m_i}\\right)}{p_i m_i \\prod_{j=0}^{i}\\left(1-q_j^{m_j}\\right)}\\right]\\ ] ] and @xmath155\\ ] ]    we now turn to the bg method . here , we begin with a single point at @xmath24 . from this point , we generate a branching `` tree '' of paths connecting @xmath3 to @xmath7 .",
    "the value of @xmath51 is estimated by @xmath156 where @xmath157 is the total number of trials reaching @xmath158 .",
    "we denote the number of points in the branching tree at interface @xmath55 by @xmath105 . for a given number @xmath159 of points at @xmath43 , the total number of trials fired is @xmath160 and the variance in @xmath157 is @xmath161=n_{n-1}k_{n-1}p_{n-1}q_{n-1}$ ] ( using eq.([simp ] ) ) .",
    "however , the situation is complicated by the fact that @xmath159 itself varies ; in fact , @xmath159 is simply the number of successful trial runs reaching @xmath43 from @xmath162 , and in general : @xmath163\\ ] ]    at this point , we need to calculate the variance in a quantity @xmath164 which is conditional upon the value of another quantity @xmath165 . here , and several times in the rest of the paper , we will use the general relation @xmath166 = e\\left[v[y|x]\\right ] + v\\left[e[y|x]\\right]\\ ] ] where the mean and variance on the r.h.s .",
    "of eq.([veq1 ] ) are taken over the distribution of values of @xmath165 . since @xmath167=n_{n-1 } k_{n-1 } p_{n-1}$ ]",
    ", @xmath168\\right]&=&k_{n-1}^2 p_{n-1}^2 v\\left[n_{n-1}\\right]\\\\\\nonumber & = & k_{n-1}^2 p_{n-1}^2 v\\left[n_s^{(n-2)}\\right ] \\end{aligned}\\ ] ] ( using eqs ( [ veq3 ] ) and ( [ nneq ] ) ) .",
    "we also know that @xmath169\\right]&= & k_{n-1}p_{n-1}q_{n-1}e\\left[n_{n-1}\\right]\\\\\\nonumber & = & k_{n-1}p_{n-1}q_{n-1}\\prod_{i=0}^{n-2}k_i p_i\\end{aligned}\\ ] ] so that @xmath170 = q_{n-1}\\prod_{i=0}^{n-1}k_i p_i + k_{n-1}^2 p_{n-1}^2 v\\left[n_s^{(n-2)}\\right ] \\end{aligned}\\ ] ] using the same arguments , we can generalize eq.([bgvar21 ] ) to @xmath171   & = q_i\\prod_{j=0}^{i}k_jp_j + k_i^2 p_i^2 v[n_s^{(i-1)}]&\\ , [ i>0]\\\\\\nonumber & q_ik_ip_i & \\ , [ i=0]\\end{aligned}\\ ] ] using eq.([bgvar2 ] ) , we can solve eq.([bgvar21 ] ) recursively , to obtain @xmath172 $ ] . using eqs.([pb11 ] ) and ( [ veq3 ] ) , we then arrive at the variance in the estimated value of @xmath51 : @xmath173 = \\frac{p_b^2}{n_0 } \\sum_{i=0}^{n-1 } \\frac{q_i}{\\prod_{j=0}^{i}p_j k_j}\\ ] ] where we have divided by @xmath32 to account for the fact that @xmath50 is calculated by averaging results over @xmath32 starting points at @xmath24 .",
    "we then obtain from eq.([err1 ] ) : @xmath174    finally , let us derive the equivalent expression for the rb method . here , we again use eq.([est1 ] ) .",
    "if we ignore for the moment the effect of the acceptance rejection step , we can use eqs.([simp ] ) and ( [ veq3 ] ) to obtain an expression for the variance in @xmath62 : @xmath175 = \\frac{p_iq_i}{n_0 k_i}\\frac{\\left(1-q_i^{k_i}\\right)}{\\prod_{j=0}^{i}\\left(1-q_j^{k_j}\\right)}\\end{aligned}\\ ] ] where we have taken account of the fact that the probability of reaching interface @xmath101 is @xmath109 , and that the @xmath72 value is averaged over @xmath32 separate path generations .",
    "eq.([ros1111 ] ) is very similar to the ffs result , eq.([test1 ] ) .",
    "the metropolis acceptance / rejection step ( described in section [ ffs_recap ] ) increases the variance in @xmath62 .",
    "on reaching interface @xmath55 , we fire @xmath60 trials and obtain an estimate @xmath176 .",
    "we either accept or reject this estimate . if we reject , @xmath177 makes no contribution to the average value of @xmath72 - instead , the previously accepted estimate , @xmath178 , is added to the average , even though @xmath179 was already added to the average in the previous acceptance / rejection step . if , instead , we accept @xmath177 , it makes a contribution to @xmath72 , and , if the subsequent estimates happen to be rejected , it may repeat this contribution multiple times .",
    "the final estimate , @xmath62 , is therefore an average over all the values of @xmath180 that were generated , weighted by the number of times @xmath181 that each of these values contributed to @xmath62 : @xmath182_l}{n_g^{(i)}}\\ ] ] where the sum is over all generated @xmath180 values and @xmath183 is the total number of these .",
    "in fact , @xmath184 since the number of times we fire trials from @xmath58 is simply the number of times we begin a path generation from @xmath24 and succeed in reaching @xmath58 . using eq.([veq3 ] ) , the variance @xmath72 is then @xmath185 = \\frac{\\sum_{l=1}^{n_g^{(i)}}q_l^2 v\\left[n_s^{(i)}/k_i\\right]_l}{(n_g^{(i)})^2 } = \\frac{v\\left[n_s^{(i)}\\right]}{k_i^2(n_g^{(i)})^2}\\sum_{l=1}^{n_g^{(i)}}q_l^2\\ ] ] ( assuming that the distributions of the stochastic variables @xmath186 and @xmath187_l$ ] are uncorrelated ) .",
    "eq.([test3 ] ) is equivalent to : @xmath188 =   \\frac{v\\left[n_s^{(i)}\\right]}{k_i^2n_g^{(i ) } } \\sum_{q=0}^{\\infty}q^2p(q ) = \\frac{p_i q_i}{k_in_g^{(i)}}\\sum_{q=0}^{\\infty}q^2 p(q)\\ ] ] in order to find the distribution @xmath189 , we define a new variable @xmath190 .",
    "@xmath190 is the probability that we accept a newly generated estimate @xmath176 .",
    "@xmath189 is then : @xmath191 eq.([qdist ] ) can be understood as follows : @xmath192 corresponds to a @xmath177 value that is generated but is immediately rejected and therefore contributes zero times to the average .",
    "this occurs with probability @xmath193 .",
    "@xmath194 corresponds to a @xmath177 value that is generated and accepted ( with probability @xmath190 ) - the next @xmath195 values that are generated are rejected ( with probability @xmath196 ) , then finally a new value is generated which is accepted ( with probability @xmath190 ) , so that the original value ceases to contribute to the average .",
    "the distribution ( [ qdist ] ) has the property that @xcite @xmath197 so that eq.([test2 ] ) for the variance in @xmath72 per point at @xmath58 becomes @xmath198 = \\frac{p_i q_i}{k_in_g^{(i)}}\\left[\\frac{2-\\theta_i}{\\theta_i}\\right]\\ ] ] using eq.([ngeq ] ) , we obtain : @xmath199 = \\frac{p_iq_i}{n_0 k_i}\\left[\\frac{(2-\\theta_i)}{\\theta_i}\\right]\\frac{\\left(1-q_i^{k_i}\\right)}{\\prod_{j=0}^{i}\\left(1-q_j^{k_j}\\right)}\\end{aligned}\\ ] ] comparing to eq.([ros1111 ] ) , we see that the effect of the acceptance / rejection step is to multiply @xmath146 $ ] by a factor @xmath200 . using eq.([est1 ] ) , the relative variance in @xmath50 is : @xmath201 } { p_b^2 } = \\frac{1}{n_0}\\sum_{i=0}^{n-1 } \\frac{q_i}{p_ik_i}\\frac{(2-\\theta_i)}{\\theta_i}\\frac{\\left(1-q_i^{k_i}\\right)}{\\prod_{j=0}^{i}\\left(1-q_j^{k_j}\\right)}\\ ] ] so that using eq.([err1 ] ) , @xmath202 we show in appendix [ app_theta ] that the acceptance probability @xmath190 for @xmath101 [ note that @xmath203 can be approximated as : @xmath204 \\qquad ( i>0)\\ ] ] where @xmath205 is the error function : @xmath206 , and @xmath207 is given by : @xmath208\\ ] ] eqs ( [ theta_1 ] ) and ( [ theta_2 ] ) can be substituted into eq.([rb_imp ] ) to give a complete expression for the relative variance in the estimated rate constant for the rb method .",
    "returning to the hypothetical rare event problem with evenly spaced interfaces introduced above , figure [ var_fig ] shows @xmath79 as a function of @xmath118 ( for @xmath209 ) and of @xmath119 ( for @xmath210 ) , for @xmath211 , @xmath212 , @xmath117 and @xmath213 .",
    "the circles show the limiting form @xmath214 , which is in good agreement with the ffs results , since @xmath215 . for small @xmath118 or small @xmath119 ( small @xmath120 ) , the rb and bg results tend to converge , since the probability of reaching later interfaces is small and the results are dominated by the early interfaces . in this regime ,",
    "the ffs method gives the smallest variance , since the chance of terminating the trial run procedure at early interfaces is lower than for the other methods .",
    "it is interesting to compare expressions ( [ ffs_imp ] ) , ( [ bg_imp ] ) and ( [ rb_imp ] ) .",
    "all three expressions are of the form @xmath216 however , @xmath217 takes different forms for the three methods : @xmath218 @xmath219 and @xmath220 we note that @xmath221 , so that @xmath222 is always less than @xmath223 , even for @xmath224 .",
    "both @xmath225 and @xmath226 are always less than unity : @xmath222 approaches the limiting form @xmath214 from above as @xmath60 increases ( in fact in fig .",
    "[ var_fig]a it takes this form for all @xmath118 ) and @xmath223 approaches @xmath227 . for the bg method , however , @xmath228 can increase indefinitely as @xmath60 increases , so that this method produces the smallest variance for large @xmath60 , as in figure [ var_fig]a .",
    "however , comparing with figure [ cost_fig ] , we see that this is also the regime in which the bg method becomes very expensive .",
    "so far in our analysis , we have assumed that all the points at interface @xmath58 have to same @xmath33 value - _ i.e. _ that on firing a trial run to @xmath59 we have the same probability of success , no matter which point at @xmath58 we start from . in reality , this is not the case ; we expect there to be a distribution of @xmath33 values among the points at each interface @xmath58 .",
    "we call the variance of this distribution the `` landscape variance '' @xmath229 at interface @xmath55 , and we expect it to make a contribution to the variance in @xmath50 .",
    "we now extend our analysis to include the potentially important effect of the landscape variance .",
    "let us suppose that each point @xmath230 at @xmath58 has an associated probability @xmath231 that a trial run fired from that point will reach @xmath59 .",
    "the distribution of @xmath231 values encountered during the rate constant calculation has mean @xmath232=p_i$ ] and variance @xmath233 \\equiv u_i$ ] .",
    "of course , the values of @xmath229 depend on the number and placement of the interfaces .    in appendix [ int_var_inc ] , we re - derive expressions for the relative variance in the estimated rate constant , taking into account the landscape variance .",
    "the final results are : @xmath234\\\\ & & \\times\\frac{\\left(1-q_i^{n_0k_i}\\right ) } { \\prod_{j=0}^{i}\\left(1-q_j^{n_0k_j}\\right)}\\bigg\\}\\end{aligned}\\ ] ] where @xmath235 for @xmath101 and @xmath236 for @xmath152 .",
    "@xmath237\\ ] ] and @xmath238\\\\\\nonumber & & \\times \\left[\\frac{(2-\\theta_i)}{\\theta_i}\\right]\\frac{\\left(1-q_i^{k_i}\\right ) } { \\prod_{j=0}^{i}\\left(1-q_j^{k_j}\\right)}\\bigg\\}\\end{aligned}\\ ] ]    comparing eqs ( [ ffs_imp_int ] ) , ( [ bg_imp_int ] ) and ( [ rb_imp_int ] ) to their equivalent forms without landscape variance , ( [ ffs_imp ] ) , ( [ bg_imp ] ) and ( [ rb_imp ] ) , we see that for each interface the `` binomial '' terms of the form @xmath239 are now supplemented by additional terms describing the landscape variance . in the limit of very large @xmath60",
    ", the relative variance no longer tends to zero .",
    "instead , as @xmath240 ( for all @xmath55 ) , the ffs and bg expressions ( [ ffs_imp_int ] ) and ( [ bg_imp_int ] ) tend to the constant value @xmath241 , while the rb expression ( [ rb_imp_int ] ) tends to @xmath242 .",
    "while the `` binomial '' contribution to the variance can be reduced by firing many trial runs per point , the `` landscape '' contribution can only be reduced by sampling many points . in the ffs and bg methods ,",
    "branching paths are generated .",
    "for very large @xmath60 , each point at @xmath24 generates many points at subsequent interfaces , so that only @xmath243 remains in eqs ( [ ffs_imp_int ] ) and ( [ bg_imp_int ] ) as @xmath240 . in the rb method , however , paths are not branched , so that each point at @xmath24 corresponds to one ( or less than one ) point at each subsequent interface . in this case , as @xmath240 , all the @xmath229 values continue to contribute to @xmath79 .    in figure [ var_fig_int ]",
    ", we revisit the simple model problem of figs [ cost_fig ] and [ var_fig ] , adding in the effects of landscape variance .",
    "we take @xmath229 to be the same for all interfaces : @xmath244 .",
    "we choose , somewhat arbitrarily , @xmath245 or @xmath246 .",
    "these turn out to be quite realistic values for the maier - stein system discussed in section [ sec_ms ] .",
    "figure [ var_fig_int ] shows the relative variance @xmath79 ( as in figure [ var_fig ] ) , calculated with @xmath246 ( upper curves ) , @xmath245 ( middle curves ) and @xmath247 ( lower curves ) .",
    "although the landscape variance does not change the general trend that @xmath79 decreases as @xmath118 or @xmath248 increases , it does have the qualitative effect that @xmath79 no longer tends to zero ( as discussed above ) . depending on the value of @xmath249",
    ", the quantitative effects of the landscape contribution can be very significant , especially as @xmath118 or @xmath248 becomes large .",
    "having calculated the computational cost and the statistical accuracy of the three methods , we are now in a position to assess their overall computational efficiency , as defined by eq.([eq_mooij ] ) .",
    "figure [ eff_fig ] shows the efficiency of the three methods as a function of @xmath118 ( fig . [ eff_fig]a ) and of @xmath119 ( fig .",
    "[ eff_fig]b ) , for the simple model case of figs [ cost_fig ] , [ var_fig ] and [ var_fig_int ] .",
    "note the altered scale on the @xmath119 axis in comparison to figures [ cost_fig ] and [ var_fig ] . for each method",
    ", the upper curve shows the results without the landscape contribution to the variance ( @xmath247 ) and the lower curve includes a landscape contribution of @xmath245 .",
    "firstly , we note that the optimum values of @xmath75 are of the same order of magnitude for all three methods , although @xmath75 is consistently lower for rb , due to the acceptance / rejection step .",
    "however , the dependence of the efficiency on the parameter values @xmath118 and @xmath119 is very different for the three methods . for the bg method",
    ", the efficiency shows a pronounced peak , both as a function of @xmath118 and of @xmath119 .",
    "although for an optimum choice of parameters , this method can be the most efficient , its performance is highly sensitive to the choice of parameters , decreasing sharply for non - optimal values of @xmath118 or @xmath119 .",
    "the ffs and rb methods are much less parameter - sensitive - in fact , as long as @xmath118 or @xmath119 is not too small , the choice of parameters appears not to be at all critical for these methods . in general , fig.[eff_fig ] seems to indicate that the method of choice is ffs , since this method is highly robust to changes in the parameters , is the most efficient method at small @xmath118 or @xmath119 , and remains efficient as @xmath118 and @xmath119 become large .",
    "however , this interpretation must be treated with care , since several important factors are not included in the analysis leading to fig.[eff_fig ] .",
    "firstly , our analysis does not include the effects of correlations between interfaces .",
    "this has the effect that neither the ffs or rb methods shows a maximum in efficiency as a function of @xmath119 in fig.[eff_fig]b . in our simple model",
    ", one can always gain more information by sampling at more closely spaced interfaces - however , in reality , correlations between interfaces are likely to make very closely spaced interfaces computationally inefficient .",
    "another important factor to be considered is the fact that both the ffs and bg methods generate branched transition paths . in ffs , in fact",
    ", an effect analogous to `` genetic drift '' means that if the number of points in the collections at the interfaces is small enough to be of the order of the number of interfaces , then all the paths that finally reach @xmath7 can be expected to originate from a small number of initial points at @xmath24 .",
    "if there is `` memory loss '' - _ i.e. _ no correlations between interfaces , this may be unimportant .",
    "however , if the history of the paths is important , then the rb method may be the method of choice , since this generates independent , unbranched paths . furthermore , the rb method requires much less storage of system configurations than ffs ( for which a whole collection of points must be stored in memory at each interface ) - for some systems , this may be a significant factor in the computational cost .",
    "figure [ eff_fig ] also shows the effects of landscape variance on the efficiency of the three methods . including landscape variance always decreases the efficiency , but produces rather few qualitative effects for this simple model problem .",
    "it is interesting to note , however , that in figure [ eff_fig]a both the ffs and rb methods show a maximum in efficiency as a function of @xmath118 only when the landscape contribution is included . when the landscape contribution is not considered , the equations predict that arbitrarily high accuracy can be obtained by firing an infinitely large number of trials from a single point . in this example",
    ", we took the landscape variance to be the same for all interfaces : @xmath244 .",
    "however , one can easily imagine that for some systems , there is much greater variation among transition paths when they are close to the @xmath3 basin , while for others , paths tend to diverge as they approach @xmath7 . in the former case",
    ", we can expect the rb and bg methods to have an advantage relative to ffs , because in these methods , relatively more points are sampled at early interfaces ( since the probability of failing to complete a transition path is higher ) .",
    "conversely , if the landscape variance is very large close to the @xmath7 basin , the bg method may be advantageous , since it samples many points at later interfaces due to its branching tree of paths .",
    "in this section , we test the expressions derived in section [ efficiency ] for a real rare event simulation problem . as our test case , we simulate the two - dimensional non - equilibrium rare event problem proposed by maier and stein @xcite .",
    "this system has been extensively studied both theoretically and experimentally @xcite and was also used by crooks and chandler @xcite as a test case for their non - equilibrium rare event method .",
    "we hope that the conclusions obtained for this system will also prove to be applicable to more computationally intensive rare event problems .",
    "the maier - stein system consists of a single particle moving with over - damped langevin dynamics in a two - dimensional force field .",
    "the position vector @xmath250 of the particle satisfies the stochastic differential equation : @xmath251 where the force field @xmath252 is given by : @xmath253 and the stochastic force @xmath254 satisfies : @xmath255 this system is bistable , with stable points at @xmath256 and a saddle point at @xmath257 . if @xmath258 , the force field @xmath259 can not be expressed as the gradient of a potential . in this case , the system is intrinsically out of equilibrium and does not satisfy detailed balance .",
    "the parameter @xmath260 controls the magnitude of the stochastic force acting on the particle . for @xmath261 ,",
    "the system makes stochastic transitions between the two stable states , at a rate which decreases as @xmath260 decreases .",
    "figure [ ms_bf ] shows a typical trajectory generated by a brute - force simulation . here , and in the rest of this section , we use @xmath262 , @xmath263 ( following crooks and chandler @xcite ) and @xmath264 .",
    "eq.([bd ] ) is integrated numerically with timestep @xmath265 @xcite . for our calculations using the ffs - type methods , we define @xmath266 , @xmath267 and @xmath268 .      in order to test the expressions of section [ efficiency ] , we must measure the cost parameters @xmath87 and @xmath94 , the probability @xmath51 of reaching @xmath7 and , for a given set of @xmath119 interfaces , the probabilities @xmath269 and the landscape variance values @xmath270 . for most of our calculations",
    ", we used @xmath271 , and the interfaces were positioned as listed in table [ ms_params ] . for the results of figs [ cost_comp]b , [ var_comp]b and [ eff_comp]b , where @xmath119 was varied , we kept the interfaces evenly spaced between @xmath272 and @xmath273 .",
    "@xmath87 , the cost of generating an initial point at @xmath24 , was measured using a simulation in region @xmath3 to be @xmath274 steps . in these calculations , points at @xmath24 were collected upon every @xmath275th crossing of @xmath24 from @xmath3 . to measure @xmath94 ( the proportionality constant in eq.([cost1 ] ) ) , we carried out an ffs run , measuring the average length ( in simulation steps ) of successful and unsuccessful trials from each interface .",
    "the results are shown in figure [ ms_udcosts ] . here",
    ", the filled circles show the average length , in simulation steps , of successful trials from interface @xmath58 ( plotted on the x axis ) to @xmath276 .",
    "since @xmath277 for all these trials , eq.([cost1 ] ) predicts that all the filled circles should have show the same average trial length .",
    "the open circles show the average length of unsuccessful trials , which begin at @xmath58 and end at @xmath278 , so that @xmath279 : eq.([cost1 ] ) predicts that all the open circles should lie on a straight line . combining all the data",
    ", we obtain an average value of @xmath280 steps .",
    "this value is used to plot the solid lines in figure [ ms_udcosts ] .",
    "the very good agreement that is observed between the solid lines and the circles implies that the drift - diffusion approximation , eq.([cost1 ] ) , is reasonable for this problem .",
    "the most significant deviation occurs for the successful trial runs between @xmath281 and @xmath282 ; these are unexpectedly short , perhaps because the `` drift force '' is weaker in this region .",
    ".positions of the interfaces and measured values of @xmath269 and @xmath270 for the maier - stein problem.[ms_params ] [ cols=\"^,^,^,^ \" , ]     using ffs , we obtained @xmath283 \\times 10^{-3}$ ] .",
    "the values of @xmath269 were also measured ( using ffs ) and are given in table [ ms_params ] . the landscape variance @xmath270",
    "was measured using the procedure described in appendix [ int_var_meas ] : after generating a correctly weighted collection of points at interface @xmath58 ( for example using ffs ) , one fires @xmath60 trials from each point @xmath230 and records the number of successes , @xmath284 .",
    "one then calculates the variance among points @xmath147 $ ] .",
    "the intrinsic variance is given by @xmath285/k_i - p_iq_i}{k_i-1}\\ ] ] table [ ms_params ] shows that for this problem @xmath286 is rather small ( a maximum of 0.27 for interface 0 ) , indicating that the landscape variance is unlikely to have important effects in this case .",
    "however , this may not be the case for more complex systems in higher dimensions .",
    "we now measure directly the cost , in simulation steps , the error in the calculated rate constant , and thus the efficiency of the three methods , for the maier - stein problem , and compare our simulation results to the predictions of section [ efficiency ] .",
    "for each method , simulations were carried out in a series of blocks . for ffs ,",
    "a block consists of a complete ffs calculation with @xmath32 starting points .",
    "for the rb and bg methods , a block consists of @xmath32 starting points at @xmath24 .",
    "each block produces a result @xmath50 for the probability of reaching @xmath7 . to find @xmath287 $ ] , we calculate the variance between blocks : @xmath288 = \\overline{(p_b^e)^2}-(\\overline{p_b^e})^2\\ ] ] where the over - line denotes an average over the blocks .",
    "the cost @xmath77 per starting point at @xmath24 is the average number of simulation steps per block , divided by @xmath32 .",
    "figure [ cost_comp ] shows a comparison between the simulation values of @xmath77 and the theoretical predictions ( eqs ( [ cost_ffs22 ] ) , ( [ cost_bg ] ) and ( [ cost_ros ] ) ) , for the three methods , as a functions of @xmath118 ( fig.[cost_comp]a ) and of @xmath119 ( fig.[cost_comp]b ) . in these calculations ,",
    "the same value of @xmath118 was used for all interfaces : @xmath212 for all @xmath55 . to obtain the data in fig.[cost_comp]b , we used interfaces which were evenly spaced in @xmath8 and a fixed value @xmath289 .",
    "we observe remarkably good agreement between the predicted and observed values for the cost , verifying that at least for this problem , eqs ( [ cost_ffs22 ] ) , ( [ cost_bg ] ) and ( [ cost_ros ] ) are very accurate .",
    "the predicted and measured values of @xmath79 are shown in figure [ var_comp ] , for all three methods .",
    "agreement is again excellent , showing that the approximations of section [ err_sect ] are justified , at least for this problem .",
    "the landscape contribution to @xmath79 is included in figure [ var_comp ] for panel ( a ) but not for ( b ) . in figure [ var_comp_ffs ]",
    ", we show the effect of neglecting this contribution ( note the altered scales on both axes ) .",
    "although the landscape contribution is small for this problem , it becomes significant for large @xmath118 as the `` binomial '' contribution decreases .",
    "the efficiency @xmath75 is plotted in figure [ eff_comp ] .",
    "excellent agreement is obtained between simulation and theory .",
    "it is also interesting to note that the trends in @xmath75 as a function of @xmath118 are qualitatively very similar to those obtained for the model problem of fig .",
    "[ eff_fig ] .",
    "the bg method shows high efficiency only within a relatively narrow range of parameter values , while the ffs and rb methods are much more robust to changes in the parameters .",
    "the rb method is consistently less efficient than ffs , due to the acceptance / rejection step .",
    "as the number of interfaces @xmath119 becomes large , we would expect the correlations between interfaces ( which are not included in our analysis ) to have a greater effect , and the theoretical predictions to become less accurate .",
    "this effect is observed to a certain extent : the efficiency of ffs , for example , decreases relative to the predicted value as @xmath119 increases .",
    "however , this is not a dramatic effect , and in fact , even on increasing @xmath119 further , as far as 100 interfaces , we find a decrease of only a few percent in the efficiency of ffs .",
    "it seems therefore , that for ffs at least , one can use any number @xmath119 of interfaces , as long as @xmath119 is not too small or so very large that memory requirements become the limiting factor .",
    "the remarkable agreement between the theoretical predictions and the simulation results shown in figures [ cost_comp ] , [ var_comp ] and [ eff_comp ] perhaps reflects the simplicity of the maier - stein problem .",
    "the main assumption for the calculation of @xmath79 - that the sampling of @xmath33 at different interfaces is uncorrelated - seems to be well justified in this case .",
    "we would expect our theoretical predictions to be less accurate for more complex problems , perhaps with strong correlations between interfaces .",
    "in fact , on investigating the two examples presented in our previous paper @xcite - the flipping of a genetic switch and the translocation of a polymer through a pore - we find that the quantitative estimates of both the cost and variance can differ by a factor of about 10 from the theoretical predictions .",
    "even with this caveat , however , we believe that the expressions of section [ efficiency ] will prove to be of practical use for a wide range of rare event simulation problems .",
    "in this paper , we have derived simple analytical expressions for the computational cost of the three ffs - type rare event simulation methods and the statistical accuracy of the resulting estimate of the rate constant .",
    "the expressions were found to be in remarkably good agreement with simulation results for the two - dimensional non - equilibrium rare event problem proposed by maier and stein @xcite .",
    "our analysis allows us to draw some general conclusions about the relative merits of the three ffs - type methods .",
    "firstly , the optimum efficiencies of the methods are all of the same order of magnitude , at least for the simple test problem studied here .",
    "however , the methods show very different sensitivities to the choice of parameters .",
    "the branched growth method in particular is highly sensitive , performing well only for a narrow range of parameter values . within this range",
    ", however , it performs well in comparison to the other methods .",
    "the ffs method is the most robust to changes in the parameters , performing consistently well , even for parameter values where the other methods are very inefficient .",
    "the rosenbluth method is lower in efficiency than the others , as a consequence of the metropolis acceptance / rejection step which is required in order to obtain paths with the correct weights in the transition path ensemble .",
    "these observations provide a very useful guide for choosing a rate constant calculation method . in general , unless one has a very good idea of the optimum parameters , the bg method carries a risk of being low in efficiency . of course",
    ", strategies could be envisaged to overcome this problem - for example , one could imagine terminating a certain percentage of the branches to avoid the high cost of sampling later interfaces .",
    "the analysis used here could easily be extended to predict the likely success of such approaches .",
    "the rb method appears from this analysis to be of relatively low efficiency .",
    "however , that is not to say that one should not use the rosenbluth method . on the contrary , this is the only method which generates unbranched paths , making it highly suitable for situations where one wishes to analyse the paths , in order to study the transition mechanism .",
    "the rb and bg methods also require much less storage of system configurations than ffs ( for which all @xmath105 points at interface @xmath55 must be stored in memory ) , making them potentially suitable for large systems . as a general conclusion , however ,",
    "the results of this paper show that the ffs method is highly robust to parameter changes and is probably the method of choice for calculations of the rate constant where effects such as the storage of many configurations in memory are not important .",
    "these results could also suggest possible strategies for choosing the parameters for the three methods .",
    "one approach would be to use the analytical expressions derived here in an optimization scheme for finding @xmath290 , @xmath291 and @xmath119 .",
    "this is likely to be useful for the bg method , but may be less essential for the ffs and rb methods , where the choice of parameters is much less critical .",
    "we expect that the predictions of the cost and statistical error derived here will be useful not only for parameter optimization , but also for assessing , before beginning a calculation , which method to use and , indeed , whether to proceed at all .",
    "some preliminary calculation would be needed in order to obtain rough estimates for @xmath87,@xmath94 , @xmath51 , @xmath269 and ( if required ) @xmath270 .",
    "these preliminary calculations are expected to be much cheaper than a full simulation .",
    "while the expressions for the cost and variance will be less accurate if only rough estimates for the parameters are available , we expect the results to be nevertheless accurate enough to be of use .",
    "furthermore , the expressions for @xmath79 can be used , after a rate constant calculation has been completed , to obtain error bars on the calculated value of @xmath13 . in this case , the values of @xmath51 and @xmath269 are known .",
    "the intrinsic variances @xmath270 can also be easily obtained during the rate constant calculation , as explained in appendix [ int_var_meas ] .",
    "these values can be substituted into the expressions to obtain a reliable estimate of the statistical error in the resulting rate constant .    in this work",
    ", we provide a way to compare the efficiency of the three ffs - type methods",
    ". it would also be very useful to compare their efficiency to that of other methods , such as the method of crooks and chandler @xcite for non - equilibrium rare event problems , or tps @xcite or transition interface sampling ( tis ) @xcite for equilibrium problems .",
    "we have carried out preliminary calculations using the crooks - chandler method for the maier - stein system .",
    "we find that the value of the rate constant is in agreement with that of the ffs - type methods , but that the ffs - type methods are much more efficient .",
    "however , a thorough comparison would require a detailed investigation , optimizing the parameter choices of all the methods .",
    "we therefore leave this to a future study .    in conclusion ,",
    "we have presented expressions for the computational cost and statistical accuracy of three recently introduced rare event simulation methods .",
    "we believe that the expressions presented here will be valuable in using these methods to compute rate constants and in evaluating the results of such computations .",
    "the authors thank axel arnold for his careful reading of the manuscript .",
    "this work is part of the research program of the `` stichting voor fundamenteel onderzoek der materie ( fom ) '' , which is financially supported by the \" nederlandse organisatie voor wetenschappelijk onderzoek ( nwo )  .",
    "r.j.a . was funded by the european union marie curie program .",
    "in order to estimate the cost of a trial run , we assume that the system undergoes one - dimensional diffusion along the @xmath8 coordinate , with a constant drift velocity ( the origin of which is a force due to the `` free energy barrier '' ) .",
    "the problem is then equivalent to that of a particle which undergoes diffusion with drift along the @xmath2 axis , after being released between two absorbing boundaries .",
    "we are interested in the mean time @xmath292 or @xmath293 that the particle takes to be captured at the left or right boundary , _ given _ that it is eventually captured at that particular boundary .",
    "farkas and flp have studied the problem of one dimensional diffusion with drift @xcite .",
    "they give analytical expressions for the probabilities @xmath294 and @xmath295 that the particle is absorbed at the left and right boundaries , respectively , and the rates of absorption , @xmath296 and @xmath297 at the left and right boundaries .",
    "the mean first passage time @xmath298 is the average time before the particle is absorbed at one of the boundaries : @xmath299 dt\\ ] ] to compute @xmath292 and @xmath293 , we require integrals similar to eq.([tau1 ] ) , but including only events where the particle reaches the desired boundary .",
    "the integrals must also be normalized by the probability of reaching that boundary : @xmath300 carrying out the integrals ( [ tau2 ] ) using the expressions of farkas and flp for @xmath296 , @xmath297 , @xmath294 and @xmath295 ( eqs ( 3 - 5 ) of their paper @xcite ) , we arrive at : @xmath301\\\\ & & \\tau_\\rightarrow = \\frac{l}{v}\\left[\\coth{\\left(\\frac{lv}{2d}\\right ) } - \\alpha \\coth{\\left(\\frac{\\alpha lv}{2d}\\right)}\\right]\\end{aligned}\\ ] ] where @xmath138 is the drift velocity , @xmath302 is the diffusion constant , the absorbing boundaries are at @xmath303 and @xmath304 and the particle is released at @xmath305 at time @xmath306 . in the limit that the drift velocity is large , @xmath307 }",
    "\\to 1 $ ] and @xmath292 and @xmath293 reduce to : @xmath308 in this case , the average time for a particle to be captured at a specified boundary is linearly proportional to the distance between the starting point of the particle and that boundary , and the proportionality constant is the same for particles moving against or with the drift velocity .",
    "it is therefore appropriate to approximate the cost of a trial run between @xmath58 and @xmath19 by @xmath309 , as in eq.([cost1 ] ) .",
    "this section is concerned with the metropolis acceptance / rejection step in the rosenbluth method .",
    "we derive the approximate expression ( [ theta_1 ] ) for the probability @xmath190 that a newly generated estimate @xmath310 for the probability @xmath33 is accepted . upon reaching interface @xmath55",
    ", we calculate the rosenbluth factor @xmath311 corresponding to the newly generated path leading to interface @xmath55 .",
    "we compare this to the rosenbluth factor @xmath66 corresponding to the previous path to have been accepted at interface @xmath55 .",
    "acceptance occurs if the ratio @xmath312 is greater than a random number @xmath313 . if we know the distribution function @xmath314 , the acceptance probability is given by : @xmath315 we would therefore like to calculate @xmath316 . to obtain this ,",
    "we require the distribution functions for both @xmath63 and @xmath66 .",
    "we begin with @xmath63 , which we can write as @xmath317 } = \\sum_{j=0}^{i-1 } \\log{[n_s^{(j)}]}\\ ] ] we assume that the @xmath318}$ ] for each interface @xmath230 are independent variables ( _ i.e. _ that the sampling at different interfaces is uncorrelated ) .",
    "since we are adding many independent variables , we apply the central limit theorem @xcite to eq.([logw ] ) . in the limit of a large number of interfaces ,",
    "the distribution of @xmath319}$ ] , is : @xmath320}\\ ] ] where @xmath321\\ ] ] and @xmath322\\ ] ] the expectation value @xmath323 $ ] can be found approximately by performing a taylor expansion of @xmath324 about @xmath325 $ ] , to give : @xmath326}+\\frac{\\left(n_s^{(j)}-e[n_s^{(j)}]\\right)}{e[n_s^{(j ) } ] } \\\\\\nonumber & & - \\frac{1}{2}\\frac{\\left(n_s^{(j)}-e[n_s^{(j)}]\\right)^2}{e[n_s^{(j)}]^2}\\end{aligned}\\ ] ] taking the expectation value of eq.([elog1 ] ) , we obtain : @xmath327 & \\approx & \\log{e[n_s^{(j)}]}-\\frac{v[n_s^{(j)}]}{2e[n_s^{(j)}]^2}\\end{aligned}\\ ] ] using the variance relation ( [ veq2 ] ) , we find that @xmath328 \\approx \\frac{1}{e[n_s^{(j)}]^2}v[n_s^{(j)}]\\ ] ] we now need to know @xmath325 $ ] and @xmath329 $ ] . on firing @xmath60 trials from interface @xmath55 , we know that the number of successes follows a binomial distribution",
    ". however , the variable @xmath330 in eqs ( [ elog ] ) and ( [ vlog ] ) refers to the number of successes at interface @xmath230 , given that we know the path subsequently reached interface @xmath331 .",
    "we therefore know that @xmath332 , so that @xmath333 so that @xmath334 @xmath335}{(1-q_j^{k_j})}\\ ] ] and @xmath336 = \\frac{\\left[(1-q_j^{k_j})k_jp_jq_j - k_j^2p_j^2q_j^{k_j}\\right]}{(1-q_j^{k_j})^2}\\ ] ] substituting ( [ ns1 ] ) and ( [ ns2 ] ) into ( [ elog2 ] ) and ( [ vlog2 ] ) , we obtain : @xmath337 & \\approx &   \\log{\\left[\\frac{k_jp_j}{1-q_j^{k_j}}\\right ] } - \\frac{1}{2}\\left[\\frac{(1-q_j^{k_j})q_j}{k_jp_j}-q_j{^k_j}\\right]\\end{aligned}\\ ] ] and @xmath338 \\approx   \\frac{q_j(1-q_j^{k_j})}{k_jp_j } -q_j^{k_j}\\ ] ] substituting ( [ elog ] ) and ( [ vlog ] ) in turn into ( [ muu ] ) and ( [ sigg ] ) leads to @xmath339 } - \\frac{1}{2}\\left[\\frac{(1-q_j^{k_j})q_j}{k_jp_j}-q_j^{k_j}\\right]\\ ] ] and @xmath340 finally , the distribution function @xmath341 for the rosenbluth factor of the newly generated path can be found by making the change of variables @xmath342}$ ] in eq.([py ] ) , to give : @xmath343\\exp{\\left[-\\frac{(\\log{[w_i]}-\\mu_i)^2}{2\\sigma_i^2}\\right]}\\ ] ] we now turn to the distribution function @xmath344 for the rosenbluth factor @xmath66 of the previous path to have been accepted at interface @xmath55 .",
    "@xmath66 does not follow the same distribution as @xmath63 , because the `` previous '' path has survived at least one round of acceptance / rejection .",
    "we know that the acceptance / rejection procedure re - weights paths by a factor proportional to the rosenbluth factor ( see section [ sec_ros ] ) , so if we assume that @xmath66 has been `` fully '' re - weighted ( note that this is an approximation ) , we can say that @xmath345 the denominator of eq.([fw ] ) ensures that @xmath344 is properly normalized . substituting ( [ fw ] ) into ( [ new1 ] ) , we find that : @xmath346}-\\mu_i)^2}{2\\sigma_i^2}\\right]}\\ ] ] where @xmath347}\\ ] ] armed with eqs ( [ new1 ] ) and ( [ old1 ] ) , we can now find the distribution function @xmath314 for the ratio @xmath312 .",
    "this is given by : @xmath348 changing the variable of the second integral to @xmath349 , we obtain @xmath350 substituting ( [ new1 ] ) and ( [ old1 ] ) into ( [ one ] ) , we obtain : @xmath351}-\\mu_i)^2 + ( \\log{[z_iw_i]}-\\mu_i)^2}{2\\sigma_i^2}\\right]}\\end{aligned}\\ ] ] this integral can be carried out analytically @xcite , to give : @xmath352}}{2\\sigma_i z_i \\sqrt{\\pi } } \\exp{\\left[-\\frac{(\\log{z_i})^2}{4\\sigma_i^2}-\\frac{\\log{z_i}}{2}\\right]}\\end{aligned}\\ ] ] we are now finally in a position to calculate the acceptance probability @xmath190 , using eq.([accc1 ] ) . substituting eq.([pz ] ) into ( [ accc1 ] ) and integrating over @xmath353 , we obtain @xcite : @xmath354\\right]\\\\\\nonumber & = & \\frac{1}{2}-\\frac{\\sqrt{\\pi}}{4}\\left[2{\\rm{erf}}\\left(\\frac{\\sigma_i}{2}\\right)-1\\right]\\end{aligned}\\ ] ] where @xmath205 is the error function : @xmath206 .",
    "although eq.([accc2 ] ) is a simple and convenient expression for the acceptance probability @xmath190 , its derivation required several approximations .",
    "we have therefore tested the validity of eq.([accc2 ] ) .",
    "we first carried out a `` simulated simulation '' , in which we defined a series of @xmath355 interfaces , each with the same value of @xmath356 , and `` simulated '' the rosenbluth calculation , each time drawing a random number to determine the outcome of a given `` trial run '' , for a given number of trial runs @xmath212 , taken to be the same for all interfaces .",
    "we measured the acceptance probabilities at each interface after @xmath357 rosenbluth `` path generations '' , and compared these to eq.([accc2 ] ) .",
    "the results are shown in figure [ acc_fig]a , for @xmath358 , @xmath359 and @xmath360 .",
    "the agreement with the `` simulation '' is very reasonable . to compare with real simulation results",
    ", we also measured the acceptance probabilities @xmath190 for the rb simulations of the maier - stein system described in section [ sec_ms ] .",
    "the results are compared with the predictions of eq.([accc2 ] ) in figure [ acc_fig]b . again",
    ", quite good agreement is obtained .",
    "in this section , we include the effects of the `` landscape variance '' in our expressions for the relative variance @xmath79 of @xmath50",
    ". the result will be that expressions ( [ ffs_imp ] ) , ( [ bg_imp ] ) and ( [ rb_imp ] ) are transformed into ( [ ffs_imp_int ] ) , ( [ bg_imp_int ] ) and ( [ rb_imp_int ] ) . as described in section [ efficiency ] , we suppose that point @xmath230 at interface @xmath58 has probability @xmath231 that a trial run fired from it will reach @xmath59 , rather than @xmath91 .",
    "the variance in the @xmath231 values for points at @xmath58 ( sampled according to their expected occurrence in the trial run firing procedure ) is the `` landscape variance '' , @xmath229 .",
    "if we choose a particular point @xmath230 , fire @xmath60 trial runs and measure the number of successes @xmath129 , we expect to obtain a mean value @xmath361=k_ip_i^{(j)}$ ] , and a variance @xmath362=k_ip_i^{(j)}q_i^{(j)}$ ] ( in analogy with eqs ( [ simp_e ] ) and ( [ simp ] ) ) .",
    "we now average over many points @xmath230 at interface @xmath58 , using the general variance relation ( [ veq1 ] ) : @xmath363 & = & e\\left[v\\left[n_s^{(i)}|j\\right]\\right ] + v\\left[e\\left[n_s^{(i)}|j\\right]\\right]\\\\\\nonumber & = & e\\left[k_ip_i^{(j)}q_i^{(j)}\\right ] + v\\left[k_ip_i^{(j)}\\right]\\end{aligned}\\ ] ] where the mean and the variance are taken over the distribution of points @xmath230 .",
    "since @xmath364 = e[p_i^{(j)}-(p_i^{(j)})^2]= e[p_i^{(j)}]-e[(p_i^{(j)})^2]$ ] and @xmath365-(e[p_i^{(j)}])^2 $ ] , we can deduce that @xmath366=k_i(p_i - p_i^2-u_i)=k_i(p_iq_i - u_i)$ ] . using eq.([veq3 ] ) , we have @xmath367=k_i^2v[p_i^{(j)}]=k_i^2u_i$ ] , so that @xmath368 = k_ip_iq_i + u_ik_i^2\\left[1-\\frac{1}{k_i}\\right]\\end{aligned}\\ ] ] this first term on the r.h.s . of eq.([intvar ] ) corresponds to eq.([simp ] ) : the binomial contribution arising from the limited number of trial runs per point .",
    "the second term is an extra contribution , due to the landscape variance .",
    "we now repeat the derivations of section [ pb_sec ] , simply replacing eq.([simp ] ) by eq.([intvar ] ) .",
    "we begin with the rb method , for which eq.([ros111 ] ) becomes @xmath369 & = & \\left[\\frac{1}{n_0}\\right]\\left[\\frac{p_iq_i}{k_i } + u_i\\left(1-\\frac{1}{k_i}\\right)\\right]\\\\\\nonumber & & \\times \\left[\\frac{(2-\\theta_i)}{\\theta_i}\\right]\\frac{\\left(1-q_i^{k_i}\\right ) } { \\prod_{j=0}^{i}\\left(1-q_j^{k_j}\\right)}\\end{aligned}\\ ] ] and eq.([rb_imp ] ) is replaced by eq.([rb_imp_int ] ) : @xmath370\\\\\\nonumber & & \\times \\left[\\frac{(2-\\theta_i)}{\\theta_i}\\right]\\frac{\\left(1-q_i^{k_i}\\right ) } { \\prod_{j=0}^{i}\\left(1-q_j^{k_j}\\right)}\\bigg\\}\\end{aligned}\\ ] ] for the bg method , eq.([bgvar2 ] ) is replaced by : @xmath363 & = \\left[k_i p_i q_i+ u_i \\left(k_i^2-k_i\\right)\\right]\\prod_{j=0}^{i-1}k_jp_j \\\\\\nonumber & + k_i^2 p_i^2 v[n_s^{(i-1)}]&\\qquad ( i>0)\\\\\\nonumber & = k_i p_i q_i+ u_i \\left(k_i^2-k_i\\right ) & \\qquad ( i=0)\\end{aligned}\\ ] ] and eq.([bg_imp ] ) becomes eq.([bg_imp_int ] ) : @xmath371\\ ] ]    for the ffs method , the situation is slightly more complicated , because the number of trials fired from point @xmath230 at interface @xmath55 is not fixed .",
    "we make @xmath96 trials from the @xmath105 points at @xmath58 , each time selecting a starting point at random ( so that the probability a particular point is chosen is @xmath372 ) .",
    "since we no longer assume that all points at interface @xmath55 are identical , we must now take account of the distribution of the number of times @xmath373 that point @xmath230 is selected .",
    "this is in fact a multinomial distribution @xcite , which has average @xmath374=m_i / n_i$ ] and variance @xmath375=m_i\\left[1/n_i ( 1 - 1/n_i)\\right]$ ] .",
    "let us now do a `` thought experiment '' in which we first decide how many trial will be fired from each point - _ i.e. _ we fix the set of values @xmath376 ( of course , @xmath377 ) .",
    "we then fire these trials and measure the total number @xmath378 which reach @xmath59 .",
    "the expectation value for @xmath378 is @xmath379 = \\sum_j m_jp_i^{j } = m_ip_i\\ ] ] and the variance is found using eq.([intvar ] ) , with @xmath60 replaced by @xmath373 , multiplying by @xmath380 and summing over all @xmath230 : @xmath381 = \\sum_j \\left[m_jp_iq_i + u_i\\left[m_j^2-m_j\\right]\\right]\\ ] ] we now imagine that we average the results over many sets of values @xmath376 . using the general relation ( [ veq1 ] ) , we obtain : @xmath382 & = & v\\left[e[n_s^{tot}|\\{m_j\\}]\\right ] + e\\left[v[n_s^{tot}|\\{m_j\\}]\\right ] \\\\\\nonumber & = & v\\left[m_ip_i\\right ] + e\\left[m_ip_iq_i + u_i\\sum_j m_j^2 -u_im_i\\right ] \\\\\\nonumber & = & m_ip_iq_i + u_i\\left[n_ie[m_j^2]-m_i\\right]\\end{aligned}\\ ] ] here , the variance and expectation are with respect to the distribution of @xmath376 values .",
    "the last line follows from the fact that @xmath383=0 $ ] as both @xmath96 and @xmath33 are constants with respect to changes in @xmath376 . since @xmath375=m_i\\left[1/n_i ( 1 - 1/n_i)\\right]=e[m_j^2]-e[m_j]^2 $ ]",
    ", we find that @xmath384=(m_i / n_i)(1 - 1/n_i ) + m_i^2/n_i^2 $ ] . substituting this into eq.([vns1 ] ) , we obtain : @xmath385 = m_ip_iq_i + \\frac{u_i}{n_i}\\left[m_i^2 - m_i]\\right]\\end{aligned}\\ ] ] since @xmath386 , we must divide eq.([vns2 ] ) by @xmath387 to obtain @xmath388^{\\rm{ffs}}$ ] : @xmath389^{\\rm{ffs } } = \\frac{p_iq_i}{m_i } + \\frac{u_i}{n_i}\\left(1-\\frac{1}{m_i}\\right)\\ ] ] this leads to : @xmath390\\\\ & & \\times\\frac{\\left(1-q_i^{m_i}\\right ) } { \\prod_{j=0}^{i}\\left(1-q_j^{m_j}\\right)}\\bigg\\}\\end{aligned}\\ ] ] where @xmath391 for @xmath101 and @xmath236 for @xmath152 . rewriting in terms of @xmath392",
    ", we obtain eq.([ffs_imp_int ] ) : @xmath393\\\\\\nonumber & & \\times\\frac{\\left(1-q_i^{n_0k_i}\\right ) } { \\prod_{j=0}^{i}\\left(1-q_j^{n_0k_j}\\right)}\\bigg\\}\\end{aligned}\\ ] ]",
    "in this section , we describe a simple and computationally cheap procedure for measuring the landscape variance parameters @xmath229 . given a correctly weighted collection of @xmath105 points at interface @xmath58 ( obtained , for example , using ffs )",
    ", we could fire an extremely large number @xmath118 of trial runs from each point and measure the variance among points in the values of @xmath394 - where @xmath394 denotes the number of successful trials from point @xmath230 : @xmath395= \\frac{v[n_s^{(i)}]}{k^2 } = \\frac{1}{k^2}\\left\\{\\sum_{j=1}^{n_i } \\frac{{n_s^{(i , j)}}^2}{n_i } - \\left[\\sum_{j=1}^{n_i } \\frac{n_s^{(i , j)}}{n_i}\\right]^2\\right\\ } \\qquad ( k \\to \\infty)\\ ] ] this is likely to be an expensive procedure .",
    "fortunately , however , it is not necessary to fire a very large number of trial runs from each point . instead",
    ", we make use of expression ( [ intvar ] ) , which can be written as @xmath396-p_iq_i}{k-1 } = \\frac{1}{(k-1)}\\left[\\frac{v[n_s^{(i)}]}{k}-p_iq_i\\right]\\ ] ] where the expression now holds for any value of @xmath118 . in the limit that @xmath397 , eq.([meas_var2 ] )",
    "reduces to ( [ meas_var1 ] ) . as a practical procedure ,",
    "therefore , we generate a collection of @xmath105 points at interface @xmath55 ( using , for example , ffs ) , and fire @xmath118 trials from each point - @xmath118 does not have to be a large number . for each point @xmath230 , we record the number of successful trials @xmath394 .",
    "the variance @xmath147 $ ] of these values is inserted into eq.([meas_var2 ] ) to give a value for @xmath229 .",
    "figure [ lam_1_vint ] shows the results of this procedure for the maier - stein problem of section [ sec_ms ] .",
    "for the first interface ( @xmath272 ) , @xmath229 was calculated using eq.([meas_var2 ] ) , using @xmath118 trials for each of @xmath398 points collected at @xmath24 .",
    "the solid line is the measured value of @xmath147/k^2 $ ] , while the dashed line is the value of @xmath229 obtained from eq.([meas_var2 ] ) .",
    "the two lines converge , of course , for large values of @xmath118 .",
    "figure [ lam_1_vint ] shows that accurate results for @xmath229 can be obtained using eq.([meas_var2 ] ) , using only a small number of trial runs per point ."
  ],
  "abstract_text": [
    "<S> we analyse the efficiency of several simulation methods which we have recently proposed for calculating rate constants for rare events in stochastic dynamical systems , in or out of equilibrium . </S>",
    "<S> we derive analytical expressions for the computational cost of using these methods , and for the statistical error in the final estimate of the rate constant , for a given computational cost . </S>",
    "<S> these expressions can be used to determine which method to use for a given problem , to optimize the choice of parameters , and to evaluate the significance of the results obtained . </S>",
    "<S> we apply the expressions to the two - dimensional non - equilibrium rare event problem proposed by maier and stein . for this problem , </S>",
    "<S> our analysis gives accurate quantitative predictions for the computational efficiency of the three methods . </S>"
  ]
}