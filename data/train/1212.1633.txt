{
  "article_text": [
    "online social networks provide a convenient and ready to use model of relationships between individuals .",
    "relationships representing a wide range of different social interactions in online communities are useful for understanding and analyzing individual attitude and behaviour as a part of a larger society .    while the bulk of research in the structure on social networks tries to analyze a network using the topology of links ( relationships ) in the network @xcite , relationships between members of a network are much richer , and this additional information can be used in many areas of social networks analysis . in this paper we consider signed social networks , which consist of a mixture of both positive and negative relationships . this type of networks has attracted attention of researchers in different fields  @xcite . understanding the interplay of relationships of different signs in the online social network setting is crucial for the design and function of many social computing applications , where we concern about the attitude of their members , trust or distrust they feel , known similarities and dissimilarities .",
    "for example , recommending new connections to their users is a common task in many online social networks . yet , without the understanding of the type of relationships , an enemy can be introduced to a user as a friend .",
    "this framework is also quite natural in recommender systems @xcite where we can exploit similarities as well as dissimilarities between users and products .    over the last several years",
    "there has been a substantial amount of work done studying signed networks , see , e.g.  @xcite . some of the studies focused on a specific online network , such as epinions  @xcite , where users can express trust or distrust to others , a technology news site slashdot  @xcite , whose users can declare others ` friends ' or ` foes ' , and voting results for adminship of wikipedia  @xcite .",
    "others develop a general model that fits several different networks  @xcite .",
    "we build upon these works and attempt to combine the best in the two approaches by designing a general model that nevertheless can be tuned up for specific networks .",
    "[ [ edge - sign - prediction ] ] edge sign prediction + + + + + + + + + + + + + + + + + + + +    following guha et al .",
    "@xcite and kleinberg et al .",
    "@xcite , @xcite we consider a signed network as a directed ( or undirected ) graph , every edge of which has a sign , either positive to indicate friendship , support , approval , or negative to indicate enmity , opposition , disagreement .",
    "the edge sign prediction problem , in which given a snapshot of the signed network , the goal is to predict the sign of a given link using the information provided in the snapshot .",
    "thus , the edge sign problem is similar to the much studied link prediction problem  @xcite , only we need to predict the sign of a link rather than the link itself .",
    "several different approaches have been taken to tackle this problem .",
    "kunegis et al .",
    "@xcite studies the friends and foes on slashdot using network characteristics such as clustering coefficient , centrality and pagerank ; guha et al .",
    "@xcite used propagation algorithms based on exponentiating the adjacency matrix to study how trust and distrust propagate in epinion .",
    "later kleinberg et al .",
    "@xcite took a machine learning approach to identify features , such as local relationship patterns and degree of nodes , and their relative weight and build a general model to predict the sign of a given link .",
    "they would train their predictor on some dataset , to learn the weights of these features by logistic regression . once trained",
    ", the model can be used on different networks .",
    "clearly , one of the most important measures of an approach is the accuracy of prediction it provides .",
    "remarkably , in many cases ( where comparable ) the network independent approach from @xcite provides more accurate predictions than that of previous network specific studies .",
    "this shows certain potential of machine learning techniques .",
    "interestingly , this study is also related to the status and balance theories from social psychology @xcite , as they rely on configurations similar to the features exploited in @xcite .    in this paper",
    "we also take the machine learning approach , only instead of focusing on a particular network or building a general model across different networks , we build a model that is unique to each individual network , yet can be trained automatically on different networks .",
    "such an approach intuitively should be capable of more accurate predictions than network independent methods , and it remain practically feasible .",
    "[ [ trusted - peers - and - influence ] ] trusted peers and influence + + + + + + + + + + + + + + + + + + + + + + + + + + +    the basic assumption of our model is that users attitude can be determined by the opinions of their peers in the network ( compare to the balance and status theories @xcite from social psychology discussed in @xcite ) . intuitively speaking ,",
    "peer opinions are guesses from peers on the sign of the link from a source node to a target node .",
    "also , we assume that peer opinions are only partially known , some of them are hidden .",
    "we introduce three new components into the model : set of trusted peers , influence , and quadratic correlation technique .",
    "when we try to count on peer opinions , not all such opinions are equally reliable , and we therefore choose a set of trusted peers whose opinions are important in determining the user s action .",
    "the set of trusted peers is one of the features our algorithm learns during the training phase .",
    "ideally , it would be good to have a set of trusted peers for each link in the network .",
    "however , considering the sparsity and the enormous size of the network , we can not always afford to determine a set of trusted peers for every possible relationships .",
    "instead , we find a set of trusted peers for each individual node .",
    "the optimal composition of such a set is not quite trivial , because even trusted peers may disagree , and sometimes it is beneficial to have trusted peers who disagree .",
    "thus , to make reliable estimations on all relationships starting at the individual nodes , its set of trusted peers has to form a wide knowledge base on other nodes in the network .    while peer opinions provide very important information , this knowledge is sometimes incomplete .",
    "relying solely on peer opinions implies that the attitude of a user would always agree with the attitude of a peer .",
    "however , in reality , there are often exceptions . what also matters is how this opinion correlates with the opinion of the user we are evaluating . to take this correlation into account we introduce another feature into the model , influence .",
    "suppose the goal is to learn the sign of the link between user @xmath0 and user @xmath1 , and @xmath2 is a peer of @xmath0 .",
    "then if @xmath0 tends to disagree with @xmath2 , then positive attitude of @xmath2 towards @xmath1 should be taken as indication that @xmath3 s attitude towards @xmath1 is less likely to be positive .",
    "the opinion of @xmath2 is then considered to be the product of his attitude towards @xmath1 and his influence on @xmath0 . usually , influence is not given in the snapshot of the network .",
    "for example in the wikipedia adminship dataset the explicit information is a collection of results of voting , while the correlation between the ways members vote is hidden and has to be learned together with other unknown parameters .",
    "we experimented with different ways of defining peer opinion , and found that using relationships and influences together to approximate peer opinions is more effective than using relationships along .",
    "to learn the weights of features providing the best accuracy we have chosen to use the standard quadratic correlation technique from machine learning @xcite .",
    "this method involves finding the optimum of a quadratic polynomial , and while being relatively computationally costly , tends to provide very good accuracy . therefore to solve quadratic programs we resort to three approaches .",
    "firstly , we used an available max - sat solver metslib @xcite based on the tabu search heuristics .",
    "secondly , we also attempted to find the exact optimal solution using the brute force approach .",
    "third , we use off - the - shelf solver cplex @xcite .",
    "clearly , in the latter two approaches it is not feasible to solve the quadratic program arising from a large network , therefore we also used a number of heuristics to split such a program , as described later .",
    "an interesting use of our approach is to apply the quantum annealing devise developed by d - wave @xcite to run our algorithm .",
    "this devise solves large instances of the quadratic unconstrained binary optimization problem ( qubo ) with ( supposedly ) high accuracy and high speed .",
    "however , such experimentation is yet to be done because the device is currently unavailable for experimenting .    [",
    "[ comparison - to - other - work ] ] comparison to other work + + + + + + + + + + + + + + + + + + + + + + + +    similar to @xcite we also use a machine learning approach to build a prediction model based on local features . however , unlike their generalized features , such as the degree of nodes , and local relationship patterns , we use peer opinions from trusted peers which are personalized features",
    "there are two main advantages for using personalized features .",
    "first of all , our model tolerates differences in individual personalities . unlike existing approach , two nodes with the same local features can behave differently by selecting different sets of trusted peers . yet the model of kleinberg et al .",
    "@xcite treats nodes with the same feature values as the same .",
    "secondly , our model accommodates the dynamic nature of online social networks .",
    "personalized features allow us to train a predictor separately for each individual node .",
    "as the network evolves over time , we only need to update individual predictors separately instead of rebuilding the whole model .",
    "although our model does not generalize across different datasets , a new model can be easily trained for different datasets without changing the algorithm .",
    "we build and test our model on three different datasets studied before , epinions , slashdot and wikipedia .",
    "it is difficult , however , to compare our results against the results in other works such as @xcite .",
    "for example @xcite and @xcite use certain ( different ! ) normalization techniques to eliminate the bias of the datasets above toward positive links .",
    "we therefore tried to test our model in all regimes used in the previous papers .",
    "the results shows similar or better prediction accuracy in almost all cases .",
    "when tested on unchanged ( biased ) datasets our model shows nearly perfect prediction . in spite of this , fair comparison is still problematic , because of the lack of data about other approaches .",
    "for example , even the experiment results show that our model has a better prediction accuracy than the model in  @xcite statistically , we could nt simply conclude our model is better because they used some normalization technique on the dataset , and also , it was not specified which edge embeddedness threshold ( widely used in @xcite ) was used for the experiment .",
    "also , we test the model on a different dataset , movielens @xcite , used to recommend users movies to rent .",
    "experiments show that we achieve good prediction accuracy on this dataset as well .",
    "we now describe our method . we start with the underlying model of a network",
    ", then proceed to the machine learning formulation of the edge sign prediction problem , and finally describe the method to solve the resulting quadratic optimization problem .",
    "we are given a snapshot of the current state of a network .",
    "a snapshot of a network is represented by a directed graph @xmath4 , where nodes represent the members of the network and edges the known or explicit links ( relationships ) .",
    "some of the links are signed to indicate positive or negative relationships .",
    "let @xmath5 denote the sign of the relationship from @xmath6 to @xmath7 in the network .",
    "it may take two different values , @xmath8 , indicating negative and positive relationships respectively .",
    "note that nodes of @xmath9 may represent entities of different kinds .",
    "for example , a signed relationship can also indicate the like or dislike of a product from a user , or the vote from a voter to a candidate .    to estimate the sign @xmath5 of a relationship from @xmath6 to @xmath7",
    ", we collect peer opinions . by a peer",
    "we understand a node in the network that we use to estimate @xmath5 . in different versions of the models",
    "a peer can be any node of the network , or any node linked to @xmath6 .",
    "peer opinion is an important unknown parameter of the model .",
    "it is an estimation on the type of the relationship from a peer based on its own knowledge .",
    "let @xmath10 denote the peer opinion of peer @xmath11 on the sign @xmath5 .",
    "when @xmath12 or @xmath13 , it indicates that the @xmath11 believes that @xmath14 or @xmath15 respectively .",
    "when @xmath16 that means @xmath11 does not have enough knowledge to make a valid estimation .",
    "another assumption made in our model is that not every peer can make a reliable estimation .",
    "therefore we divide all peers of a node into two categories , and count the opinions only of the peers from the first category , trusted peers .",
    "the problem of how to select a set of trusted peers and use their opinions for the estimation will be addressed later .",
    "let @xmath17 denote the set of trusted peers of @xmath6 .",
    "we estimate the sign @xmath5 of a relationship from @xmath6 to @xmath7 by collecting the opinions of peers @xmath18 .",
    "if the sum of the opinions is nonnegative , then we say @xmath5 should be @xmath19 , otherwise , it should be @xmath20 .",
    "this can be expressed by a simple equation as , @xmath21    notice that the set of trusted peers @xmath17 for each node @xmath6 is also an unknown parameter .",
    "determining the set of nodes in the set of trusted peers is a nontrivial task .",
    "observe , for example , that the prediction accuracy does not necessarily increase as we add nodes , even nodes of higher trust into the set .",
    "since the estimation are made by collecting opinions from all peers in the set , a correct estimation from one peer can be canceled by the wrong estimation of another . also , it is beneficial to select a set of peers with more diversity without compromising accuracy . as mentioned earlier , the set of trusted peers of a node @xmath6 is crucial for the estimation of all relationships starting from @xmath6 . hence , having a set of peers that make good individual estimation on relationships to different sets of target nodes rather than nodes that make good individual estimation for the same set of target nodes will likely improve the accuracy of prediction .",
    "our approach to selecting an optimal set of trusted peers is to consider the quadratic correlations between each pair of peers .",
    "the overall performance of a set of peers is determined by the sum of the individual performance of each of them together with the sum of their performance in pairs .",
    "the individual performance measures the accuracy of individual estimations , while the pairwise performance measures the degree of difference between the estimations of the pair of peers .",
    "we want to maximize the accuracy of each individual and the diversity of each pair at the same time .",
    "[ [ the - loss - function ] ] the loss function + + + + + + + + + + + + + + + + +    our goal is to use the information in @xmath9 to build a predictor @xmath22 that predicts the sign @xmath23 of an unknown relationship from @xmath24 to @xmath25 with high accuracy . at the same time",
    ", we would also determine the unknown parameters used in the model .",
    "our goal can be expressed by the objective function below , @xmath26 least square loss function is the standard loss function used in measuring the prediction error .",
    "another important reason for us to pick the square loss function is that it helps to capture quadratic correlations between all pairs of nodes in @xmath27 .",
    "the quadratic correlation becomes more clear when the term gets expanded later in the next section .",
    "function @xmath22 is defined as the sign of the sum of peer opinions as follows .",
    "let @xmath28 denote the sum of individual peer opinions .",
    "then we set @xmath29    since @xmath30 is unknown , we introduce a new variable @xmath31 which indicates if a node @xmath32 should be included into set @xmath30 .",
    "hence , we rewrite equation  ( [ eq:0 ] ) using the characteristic function @xmath33 as , @xmath34    [ [ quadratic - optimization - problem ] ] quadratic optimization problem + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we are now ready to set the machine learning problem . a training dataset ( a subset of @xmath9 )",
    "every entry of the training dataset is a known edge along with its sign .",
    "let a training dataset be @xmath35 .",
    "the goal is to minimize the objective function , finding the optimal weight vector @xmath36 , where @xmath37 .",
    "we use machine learning methods @xcite to train the predictor @xmath22 and learn an optimal weight vector such that the objective function  ( [ eq:00 ] ) is minimized . substituting @xmath22 and @xmath38 into the objective function  ( [ eq:00 ] ) we obtain quadratic unconstrained binary optimization ( qubo ) problem described by equation  ( [ eq:2 ] ) .",
    "@xmath39    we want to minimize the amount of error made by @xmath22 , yet at the same time , we could also want to avoid overfitting .",
    "so we introduce the second term which is the regularization function based on the @xmath40-norm .",
    "it ensures that the size of @xmath30 is not too large .",
    "the parameter @xmath41 controls the trade off between the accuracy of the prediction and the complexity of the set @xmath30 .",
    "thus , the final form of the objective function is as follows @xmath42    note that there will be more details on peer opinion terms @xmath43 .",
    "as mentioned earlier , we are going to test our model using different peer opinion formulations .",
    "first , let @xmath44 be extension of @xmath23 to edges with unknown sign and also to pairs of nodes that are not edges defined by @xmath45    [ [ simple - adjacent ] ] simple - adjacent + + + + + + + + + + + + + + +    the simplest option , later referred to as _ simple - adjacent _ , is , based on the given information , to formulate peer opinions using existing relationships from peers to the target node . in other words , in this case we set @xmath43 to be @xmath46 .",
    "however , we also understand that the relationship from a peer to the target node does not always agree with the relationship from the source node to the target node . yet",
    ", peers whose attitudes always disagree with the sources node are as important as these whose attitudes agree with the source node . in order to take the advantage of these disagreements",
    ", we introduced a second parameter , influence , which can be either positive , negative , or neutral .",
    "[ [ standard - pq ] ] standard - pq + + + + + + + + + + +    the second and third options differ in who is considered as a peer . in the _ standard - pq",
    "_ option the influences @xmath47 associated with each pair of vertices @xmath48 is an unknown parameter in the model . in a sense every pair of nodes is assumed to be linked , thus turning @xmath9 into a complete graph .",
    "a positive influence , @xmath49 , indicates that the attitude of @xmath24 affects @xmath25 positively , while a negative influence , @xmath50 indicates that the attitude of @xmath24 affects @xmath25 negatively .",
    "then the we obtain the standard formulation , @xmath51 since the standard formulation gives us the best result in experiments , we use it throughout our discussion . using the standard formulation , we rewrite equation  ( [ eq:01 ] ) as @xmath52    [ [ standard - adjacent ] ] standard - adjacent + + + + + + + + + + + + + + + + +    finally , in the _ standard - adjacent _ option peers of @xmath24 are restricted to the neighbours of @xmath24 . @xmath53",
    "the rest is defined in the same way as for the _ standard - pq _ option .      in our model ,",
    "we are given a directed complete graph @xmath4 .",
    "in equation  ( [ eq:02 ] ) , both @xmath33 and @xmath54 are unknown parameters .",
    "since @xmath55 , we can reduce the number of unknown parameters by considering all possible values of @xmath54 , and rewriting @xmath38 as , @xmath56 where @xmath57 for @xmath58 . if @xmath59 , then @xmath60 and @xmath61 .",
    "similarly , @xmath62 indicates that @xmath60 and @xmath63 . when both @xmath64 and @xmath65 , then @xmath66 .",
    "although @xmath54 can take three possible values , there are only two terms in equation  ( [ eq:02 ] ) since when @xmath67 , the term is also zero regardless of the value of @xmath46 .    now to minimize the objective function , we need to determine the optimal weight vector @xmath36 where @xmath68 such that @xmath69    to find the optimal solution of @xmath70 , we need to solve a qubo of @xmath71 variables which is very difficult since there are usually millions of nodes in a social network . luckily , from the definition , we know @xmath72 and @xmath73 are independent for different nodes @xmath24 and @xmath25 . instead of solving for @xmath74 directly , we can solve @xmath75 for each @xmath76 separately , and then combine their values to get @xmath77 .",
    "@xmath78    now , instead of solving a qubo of size @xmath71 , we could solve @xmath79 qubos of size @xmath80 separately .",
    "it can be solved approximately by a max - sat solver    if we use a different approach ( similar to @xcite ) , the problem should be further simplified , as it is still challenging to solve each of these size @xmath80 qubos exactly .",
    "[ [ breaking - down - the - problem ] ] breaking down the problem + + + + + + + + + + + + + + + + + + + + + + + + +    in order to find a good approximation of the optimal solution to the qubo defined by equation  ( [ eq:21 ] ) , we could break it down to much smaller qubos .",
    "given a subset @xmath81 , let @xmath82 , and define a restricted optimization problem as follows @xmath83    by the definition when @xmath84 , equation  ( [ eq:22 ] ) is exactly the same as  ( [ eq:21 ] ) , however , if we allow @xmath85 to be a subset of much smaller size , then the qubo we need to solve is a much smaller size as well . by decreasing the size of @xmath85",
    ", we are trading the solution accuracy with the computational efficiency .",
    "our intuition is to arrange nodes in @xmath27 according to some order , and then , we break @xmath27 into several smaller subsets . by solving equation  ( [ eq:22 ] ) on each of the subsets @xmath85 , and combining their solutions",
    ", we can get a good approximation to the optimal solution of equation  ( [ eq:21 ] ) . in the next section",
    ", we are going to explain the method used to approximate the optimal value of @xmath72 in detail .",
    "the optimization problem defined by equation  ( [ eq:21 ] ) is a quadratic unconstrained binary optimization problem which is np - hard in general . to solve the optimization problem , we use two approaches .",
    "first , we solve problems of the form ( [ eq:21 ] ) separately using an open source max - sat solver metslib based on the tabu search heuristics .",
    "second , we apply a similar method as described in  @xcite to reduce the size of the problem dramatically .    under the second approach we break the original problem into even smaller subproblems and we obtain an approximate solution by combining the solutions of each subproblems .",
    "algorithm  [ alg:1 ] describes the method we used to solve each subproblems .",
    "algorithm  [ alg:2 ] uses algorithm  [ alg:1 ] as a subroutine and explains how the problem is broken down into subproblems and also how to combine the solutions of subproblems to obtain an approximate solution . during the training process , we need to use graph @xmath9 and dataset @xmath86 .",
    "moreover , @xmath86 is randomly split into two parts , training dataset @xmath87 and validation dataset @xmath88 .",
    "we use @xmath87 to train the predictor @xmath22 and we use @xmath88 to validate the predictors obtained at each step to select the optimal one .    according to algorithm  [ alg:2 ] , we split @xmath27 into smaller subsets in two steps .",
    "first of all , for each @xmath89 and for each @xmath90 , we compute the individual prediction error of @xmath91 for @xmath6 on the dataset @xmath87 as follows : for each data point @xmath92 , we count @xmath93 , the number of instances @xmath94 when @xmath95 , and @xmath96 , the number of instances @xmath94 when @xmath97 separately .",
    "note that since @xmath98 , we can compute this number ; and that if @xmath99 is not a neighbour of @xmath91 then it contributes to both @xmath93 and @xmath96 .",
    "then , we replace @xmath91 by @xmath100 and @xmath101 with individual prediction error , @xmath96 and @xmath93 respectively .",
    "second , using their individual prediction errors , we can sort the nodes in @xmath27 in increasing order of the error .",
    "the subset @xmath85 is iteratively selected by picking the first @xmath102 nodes in the list that are not yet considered .",
    "the value of @xmath102 is an important parameter of the algorithm and is selected manually at the beginning of the algorithm . if @xmath103 , then we are solving the problem defined by equation  ( [ eq:21 ] ) .",
    "the sorting and selecting processes not only reduce the amount of computation , but also allow us to consider the relevant nodes first .",
    "once the subset @xmath85 is selected , we use algorithm  ( [ alg:1 ] ) to solve the subproblem defined by equation  [ eq:22 ] .",
    "the algorithm determines the optimal value of @xmath104 and the set @xmath105 which minimize the amount of prediction errors made by @xmath22 .",
    "it repeatedly solves the qubo for different @xmath106 $ ] ( in our experiments we use @xmath107 and @xmath108 ) .",
    "@xmath109 and @xmath110 bound the possible range for @xmath41 , and the best value of @xmath41 is selected using cross - validation on dataset @xmath88 .",
    "the set @xmath30 together with the weight @xmath104 which produces the lowest prediction errors on @xmath88 is selected as the optimal solution .",
    "notice , when the size of @xmath85 is small , say @xmath111 , we can solve it exactly using brute - force method .",
    "when its size is larger , we use some heuristic methods such as the quadratic optimization solver cplex @xcite to approximate the solution .    the optimal solution determined by algorithm  [ alg:1 ] on subset @xmath85 is used to extend the optimal solution for @xmath72 by algorithm  [ alg:2 ] . to extend the solution , we use a greedy approach similar to adaboost  @xcite .",
    "we would extend the partial solution , as long as extending it by the optimal solution on @xmath85 lowers the prediction error on the validation set @xmath88 .",
    "training dataset : @xmath87 , validation dataset : @xmath88 , a subset of nodes :  @xmath85 values of @xmath70 and @xmath112 @xmath113 @xmath114 = @xmath115 @xmath116 solve the optimization @xmath117",
    "@xmath118 = @xmath119 measure the validation error @xmath120 on @xmath121 using @xmath118 @xmath122 = @xmath123 @xmath114 = @xmath120    training dataset : @xmath87 , validation dataset : @xmath88 , the size of the subset : @xmath102 values of @xmath124 for @xmath32 , and the set of trusted peers @xmath123 @xmath125 = @xmath115 @xmath126 = @xmath115 - 1 @xmath127 @xmath116 sort nodes of @xmath27 by their individual prediction errors in increasing order @xmath85 = the first @xmath102 nodes in @xmath27 @xmath123 = @xmath128 @xmath124 , @xmath118 = algorithm  [ alg:1](@xmath129 , @xmath121 , @xmath85 ) @xmath125=@xmath126 measure the validation error @xmath126 on @xmath121 using @xmath123 update @xmath85 with the next @xmath102 nodes in @xmath27",
    "we use three datasets borrowed from @xcite and a movie rental dataset movielens that we consider separately . in order to make comparison possible the datasets are unchanged rather than updated to their current status .",
    "the dataset statistics is therefore also from @xcite ( see table  [ tab : stat ] ) .",
    "[ [ epinions ] ] epinions + + + + + + + +    this is a web site dedicated to reviews on a variety of topics including product reviews , celebrities , etc .",
    "the feature of epinion interesting to us is that users can express trust or distrust to each other , making it a signed social network .",
    "the dataset contains 119,217 nodes , 841,200 edges , 85% of which are positive and",
    "15% are negative .",
    "[ [ slashdot ] ] slashdot + + + + + + + +    slashdot is another web site for technology news where users are allowed to leave comments .",
    "it also has an additional zoo feature that allows users tag each other as ` friends ' and ` foes ' .",
    "this dataset contains 82,144 nodes , 549,202 edges of which 77.4% are positive and 22.6% are negative .",
    "[ [ wikipedia ] ] wikipedia + + + + + + + + +    this dataset contains wikipedia users and the results of voting among them for adminship .",
    "every link represents a vote of one user for or against another .",
    "a link is positive if the user voted for another and negative otherwise .",
    "it contains 7,118 nodes representing users who casted a vote or been voted for , 103,747 edges , of which 78.7% are positive and 21.2% are negative .",
    "[ tb1 ]    .basic statistics on the datasets [ cols=\"<,^,^,^\",options=\"header \" , ]     observe that since our approach is to train the predictor for a particular dataset rather than finding and tuning up general features as it is done in @xcite and @xcite , and the test datasets are biased toward positive edges , it is natural to expect that predictions are biased toward positive edges as well .",
    "this is clearly seen from table  [ tb5 ] ( see also fig .  [",
    "fig : balanced ] ) .",
    "we therefore think that average error rate does not properly reflect the performance of our algorithm .    in the case of",
    "balanced datasets our predictor does not produce biased results , again as expected .",
    "this , however , is the only case when its performance is worse than some of the previous results .",
    "one way to explain this is to note that density of the dataset is crucial for accurate predictions made by the quadratic correlation approach .",
    "therefore we had to lower the embeddedness threshold used in this part of the experiment to @xmath130 , @xmath131 , while @xcite still tests only edges of embeddedness at least 25 .      to test the versatility of the model",
    ", we also test it on a completely different dataset .",
    "movielens @xcite is a dataset used primarily in the study of recommender systems .",
    "it contains rating of movies given by users who rented movies from a shop or online .",
    "every user gives a rating to some of the movies by assigning a score from 1 to 5 , where higher score corresponds to higher evaluation of the movie .",
    "it therefore can viewed as a bipartite graph with users in one part of the bipartition , and movies in the other .",
    "the version of the dataset we used , movielens-100k , contains approximately 100,000 ratings from 1000 users on 1700 movies .",
    "there are also certain density restriction : every user included in the dataset must rate at least 20 movies .",
    "it is natural to treat users ratings as attitudes of users towards movies .",
    "our model , however , can not work directly with the movielens dataset , because it requires binary attitudes rather ratings between 1 and 5 .",
    "thus , we convert user ratings into positive and negative attitudes , by introducing a negative link every time user s rating is 3 or less , and by introducing a positive link if user s rating is 4 or 5 . under such interpretation of scores",
    "the dataset is almost balanced , 44.625% of its edges are negative .",
    "predictions are , of course , also made in terms of positive and negative links .    with the standard values of the parameters : using _ standard - pq _ option with cplex , and with @xmath132 , @xmath133 , @xmath111 ,",
    "the model makes about 75% correct predictions providing about 20% increase over the random guess .",
    "although there is a very substantial amount of research on recommender systems using movielens as a test dataset ( see e.g.  @xcite , it is not possible to compare our result against the existing ones , because the evaluation measures normally used for recommender systems are quite different ; they measure either the success rate in recommending a group of products ( movies ) or given in terms of estimating user s rating rather than attitude .",
    "nevertheless we can conclude that the method gives a similar advantage over the random choice , as for other datasets .",
    "one interesting feature of the ( internal ) work of our method is that it finds influences and sets of trusted peers between users , although there is no explicit information about such connections .",
    "we have investigated the link sign prediction problem in online social networks with a mixture of both positive and negative relationships .",
    "we have shown that a better prediction accuracy can be achieved using personalized features such as peer opinions . moreover",
    ", the proposed model accommodates the dynamic nature of online social networks by building a predictor for each individual nodes independently .",
    "it enables fast updates as the underlaying network evolves over time .    in the future , we consider possible improvements of the model in two directions .",
    "first of all , we need to find a better formulation for peer opinions .",
    "the current formulation is very simple that it either gives an estimation or it does nt estimate .",
    "ideally , we want a formulation that gives an estimation along with the confidence level of its estimation .",
    "the current choice of the binary representation of the problem was determined by several factors .",
    "firstly , many more existing algorithms , heuristics , and off - the - shelf solvers are available for binary problems .",
    "this includes many readily available max - sat solvers . some solvers , for example , cplex ,",
    "while can be used for non - binary problems , produce good results only if the problem satisfies certain conditions .",
    "we experimented with weights @xmath134 that can take more than just 2 values , but this often leads to instances that are not positive semidefinite , and cplex does not produce any meaningful results . in spite of this we experimented by allowing various variables of the problem to take more values",
    "however , it did not lead to any noticeable improvements of the results .",
    "secondly , we want to build a more sophisticated model that incorporates more information .",
    "the basic assumption of our model is that users actions can be determined by the opinions of their peers in the network . yet , as an independent individual , we also have our own knowledge and belief",
    ". there are also external factors that affects our decision making process , such as mood , weather , location , and so on .",
    "all these information can be used as features for our model in the future .",
    "jrme kunegis , andreas lommatzsch , and christian bauckhage , _ the slashdot zoo : mining a social network with negative edges _ , proceedings of the 18th international conference on world wide web ( new york , ny , usa ) , www 09 , acm , 2009 , pp .",
    "741750 .",
    "david liben - nowell and jon kleinberg , _ the link prediction problem for social networks _ , proceedings of the twelfth international conference on information and knowledge management ( new york , ny , usa ) , cikm 03 , acm , 2003 , pp ."
  ],
  "abstract_text": [
    "<S> the structure of an online social network in most cases can not be described just by links between its members . </S>",
    "<S> we study online social networks , in which members may have certain attitude , positive or negative toward each other , and so the network consists of a mixture of both positive and negative relationships . </S>",
    "<S> our goal is to predict the sign of a given relationship based on the evidences provided in the current snapshot of the network . </S>",
    "<S> more precisely , using machine learning techniques we develop a model that after being trained on a particular network predicts the sign of an unknown or hidden link . </S>",
    "<S> the model uses relationships and influences from peers as evidences for the guess , however , the set of peers used is not predefined but rather learned during the training process </S>",
    "<S> . we use quadratic correlation between peer members to train the predictor . </S>",
    "<S> the model is tested on popular online datasets such as epinions , slashdot , and wikipedia . in many cases </S>",
    "<S> it shows almost perfect prediction accuracy . </S>",
    "<S> moreover , our model can also be efficiently updated as the underlaying social network evolves .    _ </S>",
    "<S> keywords : signed networks , positive link , negative link , machine learning , quadratic optimization _ </S>"
  ]
}