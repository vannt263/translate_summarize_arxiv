{
  "article_text": [
    "we assume that a large sparse matrix @xmath1 has full column rank and let @xmath2 be its singular value decomposition ( svd ) @xcite , where @xmath3 and @xmath4 are @xmath5 and @xmath6 orthogonal matrices , @xmath7 and @xmath8 is diagonal .",
    "@xmath9 , are called the singular values of @xmath0 , @xmath10 s and @xmath11 s are the associated left and right singular vectors , respectively , and @xmath12 s are called singular triplets . in this paper , slightly different from the convention , the singular values are labeled as @xmath13 .    we are concerned with the following problem .",
    "* problem 1*. _ compute numerically the @xmath14 smallest singular triplets @xmath12 of @xmath0 , @xmath15 , where @xmath16 .",
    "_    there are many applications of problem 1 , including determination of numerical rank and of spectral condition number , least squares problems , total least squares problems , regression analysis , image and signal processing , pattern recognition and information retrieval , to name a few .",
    "consider the @xmath17 augmented matrix @xmath18 then , the eigenvalues of @xmath19 are just @xmath20 and @xmath21 zeros , the associated eigenvectors of @xmath22 and @xmath23 are @xmath24 and @xmath25 , respectively , and the eigenvectors associated with zero eigenvalues have the form @xmath26 , where @xmath27 s are orthogonal to all @xmath28 . therefore , we obtain the following formulation of problem 1 .",
    "* problem 2*. _ compute numerically the @xmath14 smallest positive eigenvalues and the associated eigenvectors of @xmath29 .",
    "_    for the @xmath14 smallest eigenpairs of @xmath19 , problem 2 is a symmetric interior eigenvalue problem .",
    "since @xmath30 and @xmath31 are assumed to be large , we can only resort to projection methods .",
    "a typical method is the symmetric lanczos method @xcite .",
    "it and other standard projection methods usually favor the extreme eigenvalues and the associated eigenvectors but are generally very inefficient for computing interior eigenpairs @xcite .",
    "another drawback is that in finite precision the computed eigenvalues do not come in plus - and - minus pairs and the computed eigenvectors do not respect the special structures that the true eigenvectors have .",
    "because of the mentioned drawbacks , we should not work on @xmath19 explicitly for computing the smallest singular triplets of @xmath0 . instead we attempt to solve problem 1 directly by working on @xmath29 implicitly .",
    "it appears that lanczos bidiagonalization type methods @xcite and jacobi - davidson svd type methods @xcite can solve the mentioned problems elegantly .",
    "the lanczos bidiagonalization type methods available have in common that they are all based on the lanczos bidiagonalization process to build up orthonormal bases of certain krylov subspaces . however , their mathematical backgrounds can be fundamentally different . basically , there are three kinds of projection principles that extract different approximate singular triplets with respect to the subspaces .",
    "some methods use the standard projection principle @xcite to extract ritz approximations @xcite , some methods use the harmonic projection principle @xcite to extract harmonic ritz approximations @xcite and some methods use the refined projection principle @xcite to extract refined singular vector approximations @xcite .",
    "jacobi - davidson type svd methods for problem 1 have several versions that are based on the three projection principles as well as their generalizations , respectively .",
    "as observed and claimed in @xcite , the refined extraction version appears to give the best accuracy in general .    for problem 1 , due to the storage requirement and computational cost ,",
    "all the lanczos bidiagonalization type methods as well as jacobi - davidson type methods have to be restarted generally in order to make them converge .",
    "that is , for given projection subspaces , if the methods do not converge , then one repeatedly chooses new better starting vectors , constructs better subspaces and computes new approximate singular triplets until they converge . the implicit restarting technique due to sorensen @xcite is a powerful tool for restarting krylov subspace algorithms in various contexts including large svd problems @xcite .",
    "the success of an implicitly restarted algorithm heavily depends on both the underlying method itself and a proper selection of the shifts involved ; see , e.g. , @xcite .",
    "based on the lanczos bidiagonalization method and one of its harmonic versions , jia and niu @xcite and larsen @xcite have developed an implicitly restarted lanczos bidiagonalization algorithm ( irlb ) , and kokiopoulou _ et al .",
    "_ @xcite have proposed an implicitly restarted harmonic lanczos bidiagonalization algorithm ( irlanb ) for computing the smallest singular triplets .",
    "irlb uses the unwanted ritz values and irlanb uses the unwanted ritz or harmonic ritz values as shifts , respectively .",
    "these shifts are called exact shifts and harmonic shifts . baglama and",
    "reichel @xcite propose a thick restarting technique that explicitly augments small subspaces with certain ritz or harmonic ritz vectors , leading to augmented restarted lanczos bidiagonalization algorithms ( irlba ) .",
    "@xcite analyze a parallel implementation of this algorithm .",
    "based on stewart s work for large eigenproblems @xcite , stoll @xcite presents a krylov - schur type algorithm that is restarted explicitly and is easily implemented .",
    "it is shown in @xcite that the lanczos bidiagonalization method may fail to compute singular vectors though it converges for computing singular values for sufficiently good subspaces . to correct this deficiency , applying the refined projection principle proposed by the first author @xcite ( see also @xcite )",
    ", we have proposed a refined lanczos bidiagonalization method , analyzed its convergence and developed an implicitly restarted refined lanczos bidiagonalization algorithm ( irrlb ) @xcite .",
    "based on the refined approximations to singular vectors , we have proposed refined shifts that are theoretically better than the exact shifts used within irlb .",
    "numerical experiments have demonstrated that irrlb often outperforms irlb @xcite considerably and is more efficient than several other available schemes : propack @xcite , lanso @xcite , the matlab internal function svds and some others when computing the largest and smallest singular triplets .",
    "hochstenbach @xcite shows that for nested subspaces ritz values approach the largest singular values monotonically but approach the smallest ones irregularly .",
    "so the lanczos bidiagonalization method is more suitable for computing the largest singular triplets and may exhibit irregular convergence behavior when computing the smallest singular triplets .",
    "in contrast , the smallest harmonic ritz values converge to the smallest singular values monotonically from above and may be better approximations .",
    "we continue to study how to compute the smallest singular triplets more efficiently in this paper .",
    "based on the lanczos bidiagonalization process , we propose a harmonic lanczos bidiagonalization method by combining it with the harmonic projection principle .",
    "our derivation is different from that in @xcite .",
    "the method is the same as that in @xcite but different from the one in @xcite .",
    "we prove that for good enough projection subspaces harmonic ritz values converge if the columns of @xmath0 are strongly linearly independent . on the other hand",
    ", harmonic ritz values may miss some desired singular values when the columns of @xmath0 are almost linearly dependent .",
    "so harmonic ritz values may not be reliable .",
    "furthermore , harmonic ritz vectors may converge irregularly and even may fail to converge .",
    "these results imply that either implicitly or explicitly restarted algorithms may converge very slowly , converge irregularly or fail to converge . to circumvent these drawbacks , combining the harmonic projection principle with the harmonic projection principle , we propose a refined harmonic lanczos bidiagonalization method that takes the rayleigh quotients of harmonic ritz vectors as more accurate and reliable approximate singular values and extracts the best approximations to the desired singular vectors from the given subspaces that minimize the residuals formed with the rayleigh quotients .",
    "we prove that refined harmonic ritz approximations converge once the krylov subspaces are good enough and the rayleigh quotients converge .",
    "we then develop an implicitly restarted refined harmonic lanczos bidiagonalization algorithm ( irrhlb ) .",
    "based on the refined harmonic ritz approximations to the desired singular vectors , in the spirit of jia s work @xcite , we propose a new shifts scheme , called the refined harmonic shifts , that we show to be theoretically better than the harmonic shifts used within the implicitly restarted harmonic lanczos bidiagonalization algorithm ( irhlb ) and irlanb .",
    "motivated by @xcite , we propose an efficient procedure to compute the refined harmonic shifts accurately .",
    "it is worth noting that kokiopoulou _",
    "_ @xcite also use the refined projection principle to compute the refined harmonic ritz approximations .",
    "they exploit the lower lanczos bidiagonalization process , use the ritz or harmonic ritz values as shifts in the algorithm and compute the smallest singular triplets one by one by exploiting deflation .",
    "they only use the refined projection principle as refinement postprocessing at the end of each restart .",
    "the authors demonstrate that computing refined ( harmonic ) ritz vectors and thus refined ritz values benefits the overall convergence process . in particular ,",
    "they show that while convergence is not apparent in terms of harmonic residual norms , monitoring refined residuals predicts convergence more accurately and safely .",
    "in contrast , based on the upper lanczos bidiagonalization process and the refined projection principle , we propose a truly new method  the refined harmonic lanczos bidiagonalization method that computes refined harmonic ritz vectors as new approximations .",
    "we then develop irrhlb with use of the new better shifts , called refined harmonic shifts , based on refined harmonic ritz approximations .",
    "irrhlb computes all the desired smallest singular triplets simultaneously .",
    "the paper is organized as follows . in  2 , based on the lanczos bidiagonalization process , we derive the harmonic lanczos bidiagonalization method and then present some basic and important properties of approximate singular vectors to be used later . exploiting jia s results in @xcite , we then make a convergence analysis . in ",
    "3 we propose the refined harmonic lanczos bidiagonalization method .",
    "we prove that the refined harmonic ritz approximations converge for good enough subspaces once the rayleigh quotients converge . in  4 , we consider selection of the shifts involved . for irhlb , similar to what is done in @xcite , we use the harmonic ritz values . for irrhlb , by exploiting the available refined harmonic ritz approximations , we propose the refined harmonic shifts that are proved to be theoretically better than the harmonic shifts .",
    "we then present an efficient procedure to compute them .",
    "we show that in finite precision the refined harmonic shifts can be computed accurately .",
    "meanwhile , we extend the adaptive shifting strategy proposed by larsen @xcite and modified by jia and niu @xcite to irhlb and irrhlb . in  5 ,",
    "we report numerical results and compare irrhlb with the five other state of art algorithms : irhlb , irrlb , irlb , irlanb and irlba , indicating that irrhlb is at least competitive with the five other algorithms and can be considerably more efficient when computing the smallest singular triplets .",
    "finally , we conclude the paper with some remarks in  6 .",
    "we introduce some notations to be used .",
    "denote by @xmath32 the spectral norm of a matrix and the vector 2-norm , by @xmath33 , by @xmath34 the @xmath35-dimensional krylov subspace generated by the matrix @xmath36 and the starting @xmath37 , by the superscript ` t ' the transpose of a matrix or vector , by @xmath38 the identity matrix with the order clear from the context and by @xmath39 the @xmath35-th coordinate vector of dimension @xmath35 .",
    "golub _ et al . _ @xcite propose a lanczos bidiagonalization method that can compute either the largest or the smallest singular triplets of @xmath0 .",
    "the method is equivalent to the symmetric lanczos method for the eigenproblem of @xmath19 starting with a special vector @xcite and is based on the lanczos bidiagonalization process @xcite , which satisfies the following relations if it does not break down before step @xmath35 : @xmath40 where the @xmath41 matrix @xmath42 and the columns of @xmath43 and @xmath44 form orthonormal bases of the krylov subspaces @xmath45 and @xmath46 , respectively .",
    "so we have @xmath47    the lanczos bidiagonalization method computes the singular triplets @xmath48 @xmath49 of @xmath50 and then uses some of @xmath51 , called the ritz approximations , to approximate the largest and/or smallest singular triplets of @xmath0 .    in finite precision",
    ", the columns of @xmath52 and of @xmath53 may rapidly lose orthogonality . a partial reorthogonalization strategy",
    "@xcite is an effective technique for maintaining numerical orthogonality .",
    "however , simon and zha @xcite show that it generally suffices to partially reorthogonalize only @xmath52 or @xmath53 rather than reorthogonalizing them simultaneously .",
    "this may reduce the computational cost considerably when only reorthogonalizing the columns of @xmath53 for @xmath54 . in our codes",
    ", we adopt the strategy from @xcite which is based on @xcite .",
    "given the subspace @xmath55 the harmonic projection method of @xmath56 computes @xmath57 satisfying the requirements @xmath58 and uses them as approximations to some eigenpairs of @xmath19 @xcite .",
    "making use of ( [ projmatrix ] ) , we see that ( [ proj ] ) is equivalent to the generalized eigenproblem @xmath59 @xmath50 is nonsingular as @xmath0 has full column rank and its singular values interlace those of @xmath0 @xcite .",
    "this is a symmetric positive definite generalized eigenproblem , so its eigenvalues are all real and nonzero @xcite .",
    "furthermore , we present the following result .",
    "[ th1 ] if @xmath60 satisfies ( [ harmbl ] ) , then @xmath61 or equivalently @xmath62 satisfies ( [ harmbl ] ) too , that is , the eigenvalues of ( [ harmbl ] ) come in plus - and - minus pairs and the eigenvectors have a special structure .",
    "_ equation ( [ harmbl ] ) gives rise to @xmath63 so we can readily see that the assertion holds .",
    "assume that the nonnegative eigenvalues of ( [ harmbl ] ) are ordered as @xmath64 where @xmath65 .",
    "then we use @xmath66 as approximations to the @xmath14 smallest singular triplets @xmath12 .",
    "this method is called the harmonic lanczos bidiagonalization method .",
    "@xmath67 s are called the harmonic ritz values , @xmath68 s and @xmath69 s the ( left and right ) harmonic ritz vectors , and @xmath70 s the harmonic ritz approximations .",
    "it is proved in @xcite that @xmath71    we have the following basic and important properties , which will play a key role in  4.2 .",
    "[ th2 ] for @xmath72 it holds that @xmath73 and @xmath74    _ proof . _ since ( [ harmbl ] ) is a symmetric positive definite generalized eigenproblem , for @xmath75 we have @xmath76 from which it follows that ( [ borth ] ) holds .",
    "( [ borth2 ] ) follows from @xmath77 and ( [ projmatrix ] ) .",
    "we now discuss efficient computation of harmonic ritz approximations .",
    "it is disappointing that ( [ harmbl ] ) is a @xmath78 generalized eigenproblem .",
    "fortunately , we can reduce ( [ harmbl ] ) to a half sized svd problem that can be solved more cheaply and accurately , as shown below .",
    "we get from ( [ harmbl ] ) @xmath79 from which it follows that @xmath80 so , the @xmath81 s are the singular values and right singular vectors of the @xmath82 matrix @xmath83 and the left singular vectors @xmath84 therefore , we can get @xmath81 more accurately and efficiently by computing the svd of the half sized ( [ svd1 ] ) and obtain all the @xmath85 s by solving the bidiagonal linear systems @xmath86 at a total cost of @xmath87 flops .    we comment that , based on the harmonic projection of @xmath88 onto @xmath45 , baglama and reichel @xcite also derive ( [ reduction])([bidiag ] ) .",
    "our method is the same as that in @xcite but is different from the one in @xcite , which is based on the lower lanczos bidiagonalization process .    from ( [ bid11 ] ) and ( [ bid21 ] ) , we have @xmath89 and @xmath90 therefore , if @xmath91 where @xmath92 is a user prescribed accuracy , then the method is accepted as converged for @xmath92 .",
    "we now analyze the convergence .",
    "jia @xcite establishes a general convergence theory of harmonic projection methods for large eigenproblems .",
    "the theory can be adapted here .    from ( [ harmbl ] ) , set the matrices @xmath93 and @xmath94 recall from theorem  [ th1 ] that @xmath95 s are the eigenvalues of @xmath96 .",
    "the following result is direct from theorem 2.1 and corollary 2.2 of @xcite .",
    "[ theo1 ] assume that @xmath97 is a singular triplet of @xmath0 and define @xmath98 to be the distance between the vector @xmath99 and the subspace @xmath100 .",
    "then there exists a perturbation matrix @xmath101 satisfying @xmath102 such that the exact singular value @xmath103 of @xmath0 is an eigenvalue of @xmath104 . furthermore , there exists an eigenvalue @xmath105 of @xmath106 satisfying @xmath107    this theorem shows that if @xmath108 tends to zero and @xmath109 is uniformly bounded then there always exists one harmonic ritz value @xmath105 that converges to the desired singular value @xmath103 . the interlacing theorem of singular values @xcite tells us that @xmath110 is uniformly bounded . as a result ,",
    "if @xmath111 , we should have @xmath112 .",
    "however , the situation is by no means so simple , and it is instructive to see what will happen when only speaking of @xmath108 small . note that @xmath113 so if @xmath114 , that is , the columns of @xmath0 are almost linearly dependent , then @xmath115 may not be near zero , so that @xmath116 may not be small . actually , @xmath117 once the smallest singular value ( ritz value ) of @xmath50 converges to @xmath118 . in this case",
    ", the harmonic lanczos bidiagonalization method may miss @xmath103 .",
    "so the method may not be reliable , and @xmath105 is only guaranteed to be a good approximation to @xmath103 only if @xmath108 is very small and the columns of @xmath0 are strongly linearly independent .",
    "to improve convergence and reliability of the method , we recommend the rayleigh quotient @xmath119 as a new approximation to @xmath22 , as was also done in @xcite .",
    "@xmath120 is more accurate and reliable than @xmath67 .",
    "correspondingly , @xmath67 in ( [ harmstop ] ) is replaced by @xmath120 .",
    "we refer to @xcite for more theoretical results and arguments on such a replacement .",
    "the following result is a direct application of theorem 3.2 of @xcite .",
    "[ theo2 ] let @xmath121 be an eigenpair of @xmath96 , and assume that @xmath122 is such that the square matrix @xmath123 is orthogonal and transforms @xmath96 into @xmath124 then if @xmath125 it holds that @xmath126    theorems  [ theo2 ] states that if the separation @xmath127 of @xmath105 and the other harmonic ritz values is uniformly bounded below by a positive constant then the harmonic ritz approximations @xmath128 converge .",
    "unfortunately , however , for a general @xmath0 , @xmath129 can be arbitrarily near zero , i.e. , @xmath105 can be arbitrarily close to the other harmonic ritz values . as a result",
    ", the upper bounds ( [ vector2 ] ) and ( [ sep ] ) can converge to zero very slowly and irregularly and even fail to do so as @xmath130 .",
    "this means that the approximate singular vectors may converge very slowly and irregularly and even may fail to converge .",
    "the previous analysis shows that the harmonic ritz approximations may converge slowly and irregularly and even may fail to converge . to overcome this intrinsic drawback",
    ", we now combine the harmonic lanczos bidiagonalization method with the refined projection principle and derive a refined harmonic lanczos bidiagonalization method .",
    "recall that @xmath131 .",
    "we use @xmath132 satisfying @xmath133 to replace @xmath134 as a new approximation to an eigenpair of @xmath19 .",
    "the method first uses the harmonic lanczos bidiagonalization method to compute @xmath57 and then forms the rayleigh quotient @xmath135 . with each @xmath136 , it computes @xmath137 by solving the minimization problem .",
    "the following results adapted from @xcite can be used to compute @xmath138 efficiently and accurately .",
    "[ theo4 ] let @xmath139 be the right singular vector of the matrix @xmath140 associated with its smallest singular value @xmath141 .",
    "then @xmath142 @xmath143    with @xmath138 at hand , we define the new left and right approximate singular vectors as @xmath144 and use @xmath145 s to approximate the @xmath14 smallest singular triplets of @xmath0 .",
    "we call @xmath146 a refined harmonic ritz triplet and @xmath147 a refined harmonic ritz approximation .    similar to ( [ harmstop ] ) , @xmath145 is accepted as converged if @xmath148    the following result is taken directly from theorem 4.1 of @xcite .",
    "[ theo5 ] let @xmath97 be a singular triplet of @xmath0 .",
    "then there exist @xmath149 and @xmath150 such that @xmath151 and @xmath152 are orthogonal and @xmath153 where @xmath154 .",
    "set @xmath155 and assume that @xmath156 is approximating @xmath97 . then if @xmath157 we have @xmath158    note that @xmath159 is the gap of @xmath103 and the other singular values of @xmath0 and is a fixed constant",
    ". theorems  [ theo5 ] shows that the refined harmonic ritz approximations converge once @xmath160 and @xmath161 .",
    "therefore , the refined harmonic lanczos bidiagonalization method overcomes , to great extent , the possible non - convergence of the harmonic ritz approximations .",
    "due to the storage requirements and computational cost , in practice , the number of steps can not be large and must be limited . for a relatively small @xmath35",
    ", however , the @xmath35-dimensional subspaces @xmath45 and @xmath162 , in general , do not contain enough information on the desired right and left singular vectors , so that both the harmonic and refined harmonic lanczos bidiagonalization methods do not converge .",
    "therefore , it is necessary to restart the methods . the idea is to repeatedly update new starting vectors based on the information available and construct increasingly better krylov subspaces until the methods converge .",
    "implicit restarting is usually preferable not only because of efficiency of the restart procedure , but also because the implicit procedure is more effective at locking in desired directions and purging unwanted ones .",
    "we briefly review the implicit restarting technique for the lanczos bidiagonalization process @xcite . note that @xmath163 . after running @xmath164 implicit qr iteration steps on @xmath50 using the shifts @xmath165",
    ", we get @xmath166 where @xmath167 and @xmath168 are the accumulations of givens rotations applied to @xmath50 from the left and right , respectively . define @xmath169 and @xmath170 .",
    "this process is achieved implicitly from @xmath171 to @xmath172 by working on @xmath50 directly .    performing the above @xmath164 implicit qr iteration steps",
    "gives the following relations @xcite : @xmath173 where @xmath174 is the entry of @xmath167 in position @xmath175 and the updated starting vector has the form @xmath176 with @xmath177 a factor making @xmath178 . since @xmath179 is orthogonal to @xmath180 , we have obtained a @xmath14-step lanczos bidiagonalization process starting with @xmath181 .",
    "it is then extended to a @xmath35-step lanczos bidiagonalization process in a standard way .",
    "so we avoid restarting the process from scratch and do it from step @xmath182 upwards .",
    "this saves the computational cost of the first @xmath14 steps of the process . applying the implicit restarting technique to the harmonic lanczos bidiagonalization method and its refined version in such a way ,",
    "we have formally sketched an implicitly restarted harmonic lanczos bidiagonalization algorithm ( irhlb ) and an implicitly restarted refined harmonic lanczos bidiagonalization algorithm ( irrhlb ) .",
    "we can run irhlb and irrhlb once the shifts @xmath183 are given .",
    "however , in order to make them work as efficiently as possible , we should select the best possible shifts in some sense for each algorithm . in the same spirit of @xcite",
    ", it has been shown in @xcite that if the shifts are more accurate approximations to some of the unwanted singular values of @xmath0 then the resulting subspaces contain more information on the desired singular vectors .",
    "the better the subspaces are , the faster irhlb and irrhlb may converge . for eigenproblems and svd problems , morgan @xcite and kokiopoulou _",
    "et al_. @xcite suggest using unwanted harmonic ritz values as shifts , called the harmonic shifts here .",
    "these shifts are natural choices as they are the best approximations available to some of the unwanted eigenvalues and the unwanted singular values , respectively .",
    "so , for our irhlb we also use the @xmath164 unwanted harmonic ritz values @xmath184 as shifts .",
    "since the refined harmonic approximations @xmath185 are optimal in the sense of residual minimizations , they are generally more accurate than the harmonic ritz approximations @xmath186 . therefore , based on @xmath187",
    ", it should be possible to find better possible shifts than the harmonic shifts .",
    "the following important result on the harmonic shifts is crucial for us to introduce and understand new better shifts for use within irrhlb .",
    "[ theo6 ] define @xmath188 then the harmonic shifts @xmath184 are the absolute values of the @xmath164 harmonic ritz values of @xmath19 with respect to the subspace @xmath189 .",
    "_ from definition ( [ proj ] ) of the harmonic projection as well as the relationship between ( [ proj ] ) and ( [ harmbl ] ) , it is easily verified that for @xmath190 , if the @xmath191-th column of @xmath192 and that of @xmath193 have the same or opposite @xmath194 sign , then @xmath19 has @xmath67 or @xmath195 as one harmonic ritz value with respect to the subspace @xmath196 .",
    "we see from ( [ borth2 ] ) that @xmath197 and @xmath198    define @xmath199 and @xmath200 , and let @xmath201 be matrices with @xmath202 columns satisfying @xmath203 and @xmath204 where @xmath205 denotes the direct sum .",
    "jia @xcite derives a number of theoretical results that compare refined ritz vectors and ritz vectors . at this moment",
    ", we temporarily regard @xmath19 as a general matrix , and @xmath206 are a ritz and the corresponding refined ritz vector of @xmath19 with respect to a general subspace @xmath100 , respectively .",
    "one of jia s results says that we always have @xmath207 if the left - hand side is not zero and @xmath208 may occur if @xmath120 is close to some @xmath209 for @xmath210 . by standard perturbation theory in terms of residual norms ,",
    "these two results demonstrate that @xmath211 is more accurate and can be much more accurate than @xmath212 . here",
    "we should point out that these claims hold without requiring that @xmath100 is sufficiently good .",
    "jia @xcite constructs a number of symmetric matrices having well separated simple eigenvalues and accurate subspaces to illustrate this .",
    "more precisely , assuming that @xmath120 and @xmath213 are used to approximate the eigenvalue @xmath214 and the eigenvector @xmath215 of @xmath19 and @xmath108 is the distance between @xmath215 and the subspace @xmath100 , jia s examples show that we can indeed have @xmath216 the above results are easily adapted to the harmonic and refined harmonic ritz vectors .",
    "some similar symmetric matrices are constructed by jia in @xcite for which the harmonic ritz vectors have no accuracy at all but refined harmonic ones have accuracy @xmath217 .",
    "coming back to our svd context , the above results and analysis indicate that @xmath218 and @xmath219 are more accurate and can be much more accurate than @xmath68 and @xmath69 without the assumption that projection subspaces are sufficiently good .",
    "based on the above , it is evident that the subspaces @xmath220 and @xmath221 contain ( possibly much ) more accurate approximations to @xmath222 and @xmath223 , @xmath224 than the subspaces @xmath225 and @xmath226 do .",
    "this , in turn , means that the subspace @xmath227 contains ( possibly much ) more accurate approximations to the eigenvectors @xmath228 associated with the eigenvalues @xmath229 , @xmath224 , of @xmath19 than the subspace @xmath189 does .",
    "recall from theorem  [ theo1 ] that a better subspace should generally produce more accurate harmonic ritz values .",
    "hence , combining with theorem  [ theo6 ] , we have come to the following key result .",
    "[ theo9 ] as approximations to some of @xmath230 , the absolute values of the harmonic ritz values @xmath231 of @xmath19 with respect to the subspace @xmath232 are more accurate and can be much more accurate than the harmonic shifts @xmath184 .",
    "this theorem holds without assuming that @xmath233 and @xmath234 are sufficiently good .",
    "it suggests that we use better @xmath235 as shifts for use within irrhlb .",
    "we call them the refined harmonic shifts .",
    "computationally , at first glance , it seems quite complicated and expensive to get the refined harmonic shifts as it involves constructing @xmath201 that are related with the large @xmath19 .",
    "inspired by the tricks in @xcite , however , we can exploit ( [ projmatrix ] ) to propose an efficient procedure for computing them accurately , as shown below .",
    "recall ( [ refinevector ] ) and define @xmath236 and @xmath237 .",
    "we use householder transformations to compute the full qr decompositions @xmath238 which costs @xmath239 flops .",
    "partition @xmath240 where @xmath241 and @xmath242 are the first @xmath14 columns of @xmath243 and @xmath244 , respectively , and",
    "let @xmath245 then it can be readily verified that @xmath246 so @xmath247 and @xmath248 defined in this way meet conditions ( [ aorth ] ) and ( [ sumdecomp ] ) and are just what we need . by ( [ sumdecomp ] ) , we have @xmath249    the harmonic ritz values @xmath231 of @xmath19 with respect to @xmath250 satisfy @xmath251 exploiting ( [ projmatrix ] ) , we get a @xmath252 symmetric positive definite generalized eigenvalue problem @xmath253 the @xmath254 s are computed by the qz algorithm @xcite using @xmath255 flops .",
    "so the total cost of computing the refined harmonic shifts is @xmath239 flops , negligible compared with the harmonic lanczos bidiagonalization method .",
    "we give more details on computation of the refined harmonic shifts .",
    "denote by @xmath256 and @xmath257 the matrices of the left and right - hand sides in ( [ shift ] ) , respectively , and observe that @xmath258 noting that the two matrices in @xmath256 are transposes each other , we only need to form @xmath259 by computing @xmath260 or @xmath261 , and @xmath262 or @xmath263 is then used to form @xmath257 . since @xmath257 is symmetric , we only need to compute its upper triangular part .",
    "the total cost of forming @xmath256 and @xmath257 is @xmath239 flops .",
    "we then compute the eigenvalues @xmath264 s of the symmetric positive definite matrix pencil @xmath265 .",
    "now we show that in finite precision the above procedure is numerically stable and can compute the refined harmonic shifts accurately .",
    "there are three major steps in the procedure : the qr decompositions in ( [ qr ] ) , computation of @xmath256 and @xmath257 and the solution of the eigenvalue problem of @xmath266 by the qz algorithm .",
    "note that the qr decompositions can be computed using householder transformations in a numerically stable way ( we use the matlab built - in code qr in our implementation ) and the qz algorithm are numerically stable .",
    "therefore , omitting details on roundoff errors , we finally compute the eigenvalues @xmath267 s of a perturbed matrix pencil @xmath268 , where @xmath269 and @xmath270 are the matrices of roundoff error accumulations and satisfy @xmath271 with @xmath272 being the machine precision and @xmath273 the frobenius norm .",
    "for an eigenpair @xmath274 of the pencil @xmath265 with @xmath275 , let @xmath276 and @xmath277 , so that @xmath278 is a projective representation of the eigenvalue @xmath279 @xcite .",
    "then it is known @xcite that there is an eigenvalue @xmath280 of the matrix pencil @xmath281 such that the chordal distance @xmath282    it is important to point out that for not too small @xmath283 the choral distance behaves like the ordinary distance @xmath284 ; see a remark in @xcite .",
    "so , how accurate @xmath285 is depends on the @xmath279 s condition number @xmath286 if one of @xmath287 and @xmath288 is not small , @xmath289 is not large and thus by ( [ backerror ] ) the relative error of @xmath285 is @xmath290 if @xmath291 is not very small .",
    "we look at the smallest @xmath291 . by theorem  [ theo9 ] ,",
    "it is known that the absolute values @xmath291 s better approximate some of @xmath230 than @xmath292 .",
    "furthermore , recall from ( [ mono ] ) that @xmath293 .",
    "so the smallest @xmath291 is approximately bounded below by @xmath294 .    in the following , we establish lower bounds for @xmath295 and @xmath296 and an upper bound for @xmath289 rigorously and prove when our proposed procedure can numerically compute the refined harmonic ritz shifts accurately .    [ theo10 ] for any refined harmonic ritz shift @xmath283",
    ", we have @xmath297 and the @xmath279 s condition number is bounded from above : @xmath298 if @xmath294 is not very small , then numerically the procedure described can compute the refined harmonic shifts @xmath299 s with relative accuracy @xmath290 .    _",
    "proof_. we prove ( [ nubound ] ) and ( [ xibound ] ) in turn .",
    "to prove ( [ nubound ] ) , we first estimate @xmath295 and then @xmath296 . from the definition of @xmath256 and @xmath257 , we have @xmath300 where @xmath301 denotes the smallest singular value of a matrix @xmath36 .",
    "note that @xmath302 and @xmath303 form orthogonal bases of the left subspace @xmath304 and the right subspace @xmath305 . exploiting ( [ projmatrix ] ) , ( [ partition ] ) , ( [ perp ] ) and ( [ newbasis ] ) and keeping in mind that @xmath306 and @xmath307 , we obtain from ( [ aorth ] ) that the projection matrix of @xmath0 with respect to @xmath302 and @xmath303 is @xmath308 whose singular values @xmath309 , labeled in increasing order , are the union of the singular values of @xmath310 and @xmath259 and are just the ritz values of @xmath0 with respect to the left and right subspaces @xmath234 and @xmath233 . by the singular value interlacing property",
    ", we have @xmath311 .",
    "furthermore , note that @xmath310 and @xmath312 are the projection matrices of @xmath0 with respect to the left subspaces @xmath313 and @xmath314 and the right subspaces @xmath315 and @xmath316 , respectively .",
    "therefore , the singular values of @xmath317 are @xmath318 and approximate the @xmath14 desired smallest singular values @xmath22 s from above , while the singular values of @xmath319 are @xmath320 and approximate @xmath321 from above too . in particular , we have @xmath322",
    "so it holds that @xmath323    next we estimate @xmath288 .",
    "we obtain from ( [ gm ] ) , ( [ perp ] ) and ( [ projmatrix ] ) @xmath324 observe that @xmath325 and @xmath326 are the projection matrices of @xmath327 and @xmath88 with respect to @xmath328 and @xmath329 , respectively .",
    "so their eigenvalues approximate some of the eigenvalues @xmath330 of @xmath327 and @xmath88 . furthermore ,",
    "since @xmath331 is symmetric nonnegative definite , the smallest eigenvalue of @xmath332 is no less than the smallest eigenvalue @xmath333 of @xmath334 . as a consequence",
    ", it follows from @xmath335 that the smallest eigenvalue of @xmath336 is bounded below by @xmath337 .",
    "similarly , we have @xmath338 which is symmetric nonnegative definite . as a result ,",
    "the smallest eigenvalue of @xmath325 is no less than the smallest eigenvalue @xmath333 of @xmath339 and is bounded below by @xmath337 too .",
    "therefore , we get @xmath340 so it follows from ( [ alphabound ] ) that the @xmath279 s condition number @xmath289 in ( [ condnum ] ) satisfies @xmath341 which is ( [ nubound ] ) .",
    "if @xmath294 is not very small , then @xmath289 is not large and all @xmath283 s are not too small .",
    "keep in mind the comments on ( [ backerror ] ) and ( [ chi ] ) .",
    "it is then clear that numerically the proposed procedure can compute the refined harmonic shifts @xmath299 s with relative accuracy @xmath290 .",
    "we should point out that theorem  [ theo10 ] holds without any assumption on @xmath233 and @xmath234 , as is clearly seen from the proof .",
    "it has been observed @xcite that if the @xmath14-th desired @xmath342 is very near a shift then irlb with the exact shifts ( the unwanted ritz values ) converges very slowly and even stagnates .",
    "this is also the case for irrhlb with the refined harmonic shifts and irhlb with the harmonic shifts .",
    "the reason is that if some shift @xmath343 is very near @xmath342 then the new starting vector @xmath181 will nearly annihilate the component of the desired @xmath344 , so that the new subspace @xmath345 contains very little information on @xmath344 and @xmath346 converges to @xmath342 very slowly or not at all .    in order to overcome this problem , for irlb with the exact shifts , larsen @xcite proposes an adaptive shifting strategy for computing the largest singular triplets .",
    "he simply replaces a bad shift to be defined below by a zero shift .",
    "jia and niu @xcite adapt it to irrlb for computing the largest singular triplets but modify it for computing the smallest singular triplets .",
    "their strategy works for irhlb and irrhlb : define the relative gaps of @xmath346 and all the shifts @xmath347 by @xmath348 where @xmath349 is the residual norm ( [ harmstop ] ) or ( [ refinedstop ] ) .",
    "we should note that @xmath350 is an approximation to @xmath342 .",
    "if @xmath351 , @xmath343 is a bad shift and should be replaced by a suitable quantity .",
    "expand @xmath352 as a linear combination of the right singular vectors @xmath353 : @xmath354 then for the harmonic shifts @xmath355 we have from ( [ update ] ) @xmath356",
    "so if @xmath357 is very near @xmath342 , which is the case that @xmath294 is very near @xmath342 , then @xmath181 has a very small component in the direction of @xmath344 .",
    "a good strategy is to replace @xmath357 by the largest one among all the shifts , as this strategy amplifies the components of @xmath181 in @xmath358 and meanwhile dampens those in @xmath359 .",
    "the above strategy applies to the refined harmonic shifts as well .",
    "we now present irhlb with the harmonic shifts and irrhlb with the refined harmonic shifts , respectively .",
    "* algorithm 1 .",
    "irhlb with the harmonic shifts *    1 .   given a unit length starting vector @xmath352 of dimension @xmath31 , the steps @xmath35 , the number @xmath14 of the desired singular triplets and the convergence tolerance @xmath92 .",
    "2 .   run the @xmath35-step lanczos bidiagonalization process and construct @xmath360 and @xmath361 .",
    "3 .   calculate the triplets @xmath362 , by computing the singular values and right singular vectors of ( [ svd1 ] ) and by solving ( [ bidiag ] ) and normalizing the solutions , and use the rayleigh quotients @xmath363 as approximations to @xmath364 .",
    "4 .   replace @xmath67 by @xmath120 in ( [ harmstop ] ) . for @xmath15 , test if ( [ harmstop ] ) is satisfied .",
    "if yes , compute @xmath68 and @xmath69 explicitly and stop .",
    "5 .   implicitly restart the lanczos bidiagonalization process using the harmonic shifts and the adaptive shifting strategy .",
    "* algorithm 2 .",
    "irrhlb with the refined harmonic shifts *    1 .   given a unit length starting vector @xmath352 of dimension @xmath31 , the steps @xmath35 , the number @xmath14 of the desired singular triplets and the convergence tolerance @xmath92 .",
    "2 .   run the @xmath35-step lanczos bidiagonalization process and construct @xmath360 and @xmath361 .",
    "3 .   calculate the triplets @xmath362 by computing the singular values and right singular vectors of ( [ svd1 ] ) and by solving ( [ bidiag ] ) and normalizing the solutions , and use the rayleigh quotients @xmath365 as approximations to @xmath366 .",
    "4 .   for each @xmath367 , compute @xmath368 and @xmath369 in theorem  [ theo4 ] .",
    "5 .   for @xmath15 , test",
    "if ( [ refinedstop ] ) is satisfied .",
    "if yes , compute @xmath218 and @xmath219 by ( [ refinevector ] ) explicitly and stop .",
    "6 .   implicitly restart the lanczos bidiagonalization process using the refined harmonic shifts and the adaptive shifting strategy .",
    "we have developed the experimental matlab codes of irrhlb , irhlb , irrlb and irlb .",
    "the latter two were named irrbl and irbl in @xcite and were originally developed based on the lower lanczos bidigonalization process .",
    "here we have developed their upper lanczos bidiagonalization versions .",
    "these four codes call the upper lanczos bidiagonalization process in baglama and reichel s code irlba , and some parameters and defaults are the same as those used in irlba .",
    "we compare irrhlb with irrhlb , irrlb , irlb , irlba and irlanb in this section and report numerical results .",
    "numerical experiments were run on an intel core 2 e6320 with cpu 1.86ghz and ram 2 gb under the window xp operating system using matlab 7.1 with @xmath370 .",
    "the stopping criteria are @xmath371 and @xmath372 if @xmath373 then stop .",
    "similar criteria apply to irlb and irrlb as well . in (",
    "[ stop ] ) , @xmath374 is replaced by the maximum of the current largest ( harmonic ) ritz value and the old one obtained at last restart . some parameters in irrhlb , irhlb , irrlb and irlb",
    "are described in table  [ description ] .",
    "[ htp ]    .parameters in irrhlb , irrlb , irhlb and irlb [ cols= \" < , < \" , ]     clearly , for fidap4 and lshp3205 , irrhlb worked well and solved the problem successfully while irrlb only performed well in some cases and was less efficient than irrhlb .",
    "in contrast , irhlb , irlb , irlba and irlanb performed more poorly and they all failed to converge for fidap4 and lshp3205 . for jagmesh8 ,",
    "irrhlb still worked robustly and efficiently , but irrlb succeeded only in a few cases and irhlb , irlb , irlba and irlanb behaved more badly .",
    "they all were considerably less efficient than irrhlb if they worked .",
    "we found that , generally , the bigger @xmath14 was , the more restarts irrhlb and irrlb used for the same @xmath35 .",
    "this should not be surprising as the problem for a bigger @xmath14 is generally more difficult to solve than that for a smaller @xmath14 .",
    "we also observed that all the smallest singular values were computed with relative errors no more than a modest multiple of @xmath375 .",
    "we had more observations on the behavior of irhlb , irlb , irlba and irlanb on these three difficult problems .",
    "for example , the residual norms obtained by them may oscillated but decreased very slowly ; they may have first decreased to some stage and then oscillated ; they might have first decreased , then stabilized and did not decrease further ; they might have decreased to some stage and then increased .",
    "therefore , irrhlb is not only the best but also the unique choice for fidap4 , jagmesh8 and lshp3025 for most of the given @xmath14 s and @xmath35 s .",
    "we tested well1850 , pde2961 , dw2048 and plat1919 for @xmath376 , respectively .",
    "tables  [ tablewell6][tableplat6 ] report the results for @xmath377 .",
    "we do not list the corresponding results for @xmath378 , as will be explained shortly .",
    "@xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 71&2.67&785&43&2.98&692&35&4.18&739 + irrlb & 69&2.51&763&62&4.48&996&35&4.16&739 + irhlb & 168&5.32&1852&83&4.99&1332&51&5.55&1075 + irlb & 183&5.99&2017&91&5.63&1460&55&6.01&1159 + irlba & 191&1.90&2105&93&1.21&1492&57&1.00&1201 + irlanb & 279&7.88&2795&133&6.61&2000&82&6.40&1645 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 80&3.10&726&51&3.53&720&35&4.08&671 + irrlb & 103&4.15&933&63&4.43&888&41&5.16&785 + irhlb & 171&5.85&1545&76&4.51&1070&46&4.47&880 + irlb & 184&4.96&1662&82&4.84&1154&49&4.80&937 + irlba & 189&1.70&1707&83&1.01&1168&50&0.86&956 + irlanb & 259&6.11&2079&109&4.79&1424&63&4.10&1141 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 105&3.18&743&60&4.00&728&43&4.99&739 + irrlb & 161&5.53&1135&70&4.51&848&50&4.64&688 + irhlb & 248&6.43&1744&94&5.14&1136&53&4.06&909 + irlb & 275&6.08&1933&103&4.70&1244&58&4.69&994 + irlba & 292&2.23&2052&108&1.26&1304&60&0.97&1028 + irlanb & 388&7.30&2337&128&4.58&1417&69&3.41&1113 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 114&6.81&811&63&6.56&769&40&6.54&693 + irrlb & 171&9.47&1210&69&7.18&841&42&6.76&727 + irhlb & 194&5.81&1371&77&4.34&937&45&3.94&778 + irlb & 202&5.50&1427&82&4.77&997&47&4.05&812 + irlba & 170&1.61&1196&72&0.98&871&43&0.81&739 + irlanb & 282&5.73&1706&99&3.89&1103&56&3.43&910 +     @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 93&24.8&2242&77&38.1&2776&64&37.7&2948 + irrlb & 156&36.9&4060&52&23.3&1876&46&30.0&2120 + irhlb & 236&59.6&6140&128&57.2&4612&82&47.9&3776 + irlb & 266&67.5&6920&145&62.9&5224&93&57.5&4282 + irlba & 276&9.71&7180&148&7.54&5332&94&6.64&4328 + irlanb & 406&64.2&10155&219&70.0&7670&142&60.4&6395 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 100&22.7&2406&81&34.8&2760&67&40.9&2954 + irrlb & 117&26.2&2814&72&31.5&2454&46&32.8&2030 + irhlb & 209&40.8&5022&110&41.8&3746&71&42.7&3130 + irlb & 230&44.0&5526&120&45.2&4086&78&44.9&3438 + irlba & 238&7.84&5718&124&6.21&4222&80&5.55&3526 + irlanb & 280&29.3&6447&142&42.7&4693&92&35.5&3963 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 107&22.6&2362&80&30.9&2568&69&49.8&2906 + irrlb & 146&32.7&6220&75&35.2&2408&49&33.6&2066 + irhlb & 186&31.5&4100&95&32.7&3048&63&35.1&2654 + irlb & 266&47.0&5860&134&43.0&4296&85&47.8&3578 + irlba & 287&9.27&6321&142&6.79&4552&89&6.06&3746 + irlanb & 224&28.9&4713&114&23.4&3543&73&28.0&3002 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 190&38.9&3243&110&46.2&2983&89&67.7&3306 + irrlb & 246&51.4&4195&136&65.2&3685&68&54.1&2529 + irhlb & 443&63.5&7544&187&59.3&5062&110&56.8&4083 + irlb & 483&69.0&8224&203&63.6&5494&117&60.0&4342 + irlba & 335&9.99&5636&159&7.21&4250&90&5.85&3322 + irlanb & 546&54.7&8750&222&43.7&5786&126&44.2&4550 +     @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 127&44.1&3306&92&41.3&3316&85&78.9&3914 + irrlb & 230&77.7&5984&147&80.3&5296&66&59.7&3040 + irhlb & 371&116&9650&193&106&6952&122&105&5616 + irlb & 425&136&11054&226&133&8140&142&122&6536 + irlba & 463&21.6&12042&238&16.6&8572&148&14.5&6812 + irlanb & 490&100&12255&252&103&8825&157&99.0&7070 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 149&44.7&3582&113&62.2&3848&101&83.1&4450 + irrlb & 254&83.6&6102&149&90.3&5072&85&63.3&3746 + irhlb & 475&137&11406&239&131&8132&146&113&6430 + irlb & 537&143&12894&272&134&9254&167&139&7354 + irlba & 581&27.9&13950&284&19.3&9662&172&16.3&7574 + irlanb & 686&133&15785&339&111&11194&204&97.3&8779 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 161&52.0&3550&127&78.6&4082&100&97.6&4208 + irrlb & 239&65.6&5266&110&66.2&3528&103&99.2&4334 + irhlb & 518&122&11404&248&114&7944&149&111&6266 + irlb & 575&113&12658&278&126&8904&165&116&6938 + irlba & 579&25.1&12745&273&18.2&8743&164&15.2&6895 + irlanb & 604&99.7&12693&284&84.6&8813&169&71.5&6938 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 290&83.7&4943&176&80.7&4765&139&145&5156 + irrlb & 571&145&9720&189&108&5116&144&132&5341 + irhlb & 925&212&15738&373&163&10084&205&150&7598 + irlb & 1004&193&17081&403&157&10894&223&140&8264 + irlba & 601&23.3&10157&258&15.9&6948&145&12.8&5355 + irlanb & 1302&138&20846&502&119&13066&269&106&9698 +     @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 146&8.20&1610&129&15.0&2068&74&12.0&1558 + irrlb & 351&22.7&3865&200&23.0&3204&105&19.0&2209 + irhlb & 605&37.5&6659&286&27.0&4580&163&28.3&3427 + irlb & 671&41.6&7385&313&32.9&5012&183&29.3&3847 + irlba & 727&12.7&8001&337&8.08&5396&191&6.15&4015 + irlanb & 943&33.2&9435&425&27.9&6380&234&29.2&4685 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 214&10.9&1932&209&17.7&2890&153&21.4&2913 + irrlb & 605&30.5&5451&179&15.3&2512&123&16.4&2343 + irhlb & 923&37.2&8313&379&31.9&5312&214&28.4&4072 + irlb & 1089&48.7&9807&451&37.8&6320&253&28.8&4813 + irlba & 1277&17.7&11499&511&10.5&7160&273&8.44&5193 + irlanb & 1428&46.4&11431&545&32.7&7092&286&25.6&5155 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 385&15.3&2703&237&19.7&2582&171&22.2&2915 + irrlb & 1983&86.0&13889&454&40.8&5456&266&35.8&4530 + irhlb & @xmath382&-&-&793&48.2&9524&387&43.7&6587 + irlb & @xmath382&-&-&869&64.0&10436&432&46.7&7352 + irlba & @xmath382&-&-&722&13.5&8647&352&9.77&5983 + irlanb & @xmath382&-&-&1150&54.5&12659&524&45.9&8393 +   + @xmath35 & & & + algorithms & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 & @xmath379 & @xmath380 & @xmath381 + irrhlb & 685&45.1&4808&368&45.5&4429&395&94.9&6728 + irrlb & @xmath382.&-&-&1283&165&15409&490&116&8343 + irhlb & @xmath382.&-&-&1809&192&21721&891&155&15160 + irlb & @xmath382.&-&-&@xmath382.&-&-&1428&209&24289 + irlba & @xmath382.&-&-&1317&26.8&12412&562&17.2&8330 + irlanb & @xmath382.&-&-&@xmath382.&-&-&1039&92.7&16638 +    we found that all the algorithms computed the desired smallest singular values correctly once they converged .",
    "the computed smallest singular values had relative errors no more than a very modest multiple of @xmath383 .",
    "we observed that , in terms of restarts and matrix - vector products , irrhlb was often considerably more efficient and several times faster than the others except irrlb .",
    "irrlb was nearly as efficient as irrhlb in many cases , and it was slightly better than irrhlb in a few cases ; see , e.g. , table  [ tabledw6][tablepde6 ] for the results on dw2048 for @xmath384 and pde2961 for @xmath385 , @xmath384",
    ". however , for the relatively difficult plat1919 , it was less robust than irrhlb and failed to converge for some @xmath14 and @xmath35 ; see table  [ tableplat6 ] .",
    "irhlb , irlb , irlba and irlanb were less robust and efficient than irrlb , as the tables indicate .",
    "in addition , the results demonstrate that the bigger @xmath14 was , the more restarts the algorithms used generally .    for @xmath378 , we observed similar phenomena and had similar findings .",
    "the only essential exception is that for plat1919 and @xmath386 , @xmath387 , irrlb did not converge after 2000 restarts were used .",
    "furthermore , we found that for the four test matrices all the algorithms used more restarts for @xmath378 than those for @xmath377 and they continued converging very smoothly from @xmath377 to @xmath378 , provided they converged .",
    "hence we do not list the results anymore .    to be more illustrative , we draw some typical curves that feature general convergence processes of the six algorithms .",
    "figures  [ fig3][fig4 ] depict absolute residual norms versus restarts for well1850 when @xmath385 and @xmath388 , respectively .",
    "the figures clearly demonstrate that irrhlb is the fastest , irrlb is the second best , irhlb is faster than irlb while irhlb , irlb , irlba and irlanb are comparable and competitive though irlanb may be slightly slower .",
    "the tables tell us that irhlb was faster than irlb .",
    "we see from the figures that after some stages the algorithms started converging quite smoothly and they used more but not too more restarts for the smaller @xmath378 . besides , for irlanb , we see that they computed the smallest singular triplet after many restarts then found the second and third smallest singular triplets very quickly .",
    "this is because after the previous singular triplet(s ) was ( were ) computed the available subspaces had contained rich information on the later desired singular vectors .",
    "we have done more experiments and have similar findings . based on them",
    ", we may conclude that irrhlb is the best and the most robust for general purpose and irrlb is the second best . as far as overall efficiency",
    "is concerned , in terms of restarts and matrix - vector products , irrhlb is the fastest and irrlb is the second best while irhlb , irlb , irlba and irlanb are all comparable each other and no one is considerably superior to the others .",
    "a further observation tells us that irhlb is faster than irlb . that irrhlb is superior to irrlb and irhlb is better than irlb sheds light on the fact argued in the introduction : the refined harmonic projection and the harmonic projection are more suitable for computing the smallest singular triplets than the refined standard projection and the standard projection , respectively .",
    "meanwhile , we find that , as far as cpu timings are concerned , irrhlb can be inferior to irlba",
    ". this may be partly because @xmath0 is not very large or @xmath0 too sparse , so that the savings of the first @xmath389 steps of the lanczos bidiagonalization process can not compensate implicit restarting with @xmath390 shifts , and partly because our code on implicit restarting is not far from optimized . in any event",
    ", as a whole , we can draw an overall conclusion that irrhlb is at least competitive with and can be much more efficient than the five other state of the art algorithms in both robustness and efficiency .",
    "the advantages of irrhlb are twofold : it extracts the best left and right approximate singular vectors from the given subspaces in the sense of residual minimizations ; it uses the better refined harmonic shifts to construct better subspaces at each restart .",
    "each of these two advantages alone may not gain much , but , as restarts proceed , the cumulative effect of their combination may be very striking , so that irrhlb can be much more efficient than the other algorithms , as also noticed and commented on the refined algorithms for the large eigenproblem in @xcite .",
    "we have presented the refined harmonic lanczos bidiagonalization method for computing the smallest singular triplets of large matrices .",
    "we have developed a practical implicitly restarted algorithm with the refined harmonic shifts scheme suggested .",
    "we have done many numerical experiments and have compared the new algorithm with the five other state of the art algorithms .",
    "the results show that the new algorithm is at least competitive with and can be much more efficient than the five other algorithms in both robustness and efficiency .",
    "we have reported the numerical results of computation of the smallest singular triplets .",
    "we have also done many numerical experiments on computation of the largest singular triplets . as indicated in @xcite , irrlb is generally preferable to irlb @xcite , propack @xcite , lanso @xcite and svds as well as some others ; it is the most robust among the restarted algorithms .",
    "note that irlanb is designed to only compute the smallest singular triplets . for computation of the largest singular triplets",
    ", we have found that irrlb is at least competitive with the four other algorithms , in which irlba uses ritz approximations .",
    "however , more observations reveal that irrhlb and irhlb are considerably inferior to irrlb and irlb , respectively .",
    "this suggests that irrlb and irlb are suitable for computing both the largest singular triplets and the smallest ones but irrhlb and irhlb are more suitable for computing the smallest singular triplets .",
    "the matlab codes of irrhlb , irrlb , irhlb and irlb can be obtained from the authors upon request .",
    "we thank two referees very much for their very valuable and helpful suggestions and comments , which made us improve on the presentation considerably .",
    "many thanks also go to kokiopoulou , bekas , gallopoulos and baglama and reichel for generously providing us their irlanb and irlba codes , which made our numerical experiments and comparisons possible .      , _ test matrix collection for non - hermitian eigenvalue problems _ , technical report cs-97 - 355 , university of tennessee , knoxville , 1997 .",
    "lapack note # 123 .",
    "data available at http://math.nist.gov/marketmatrix .                                              , _ lanczos bidiagonalization with partial reorthogonalization _ , chapter of ph.d .",
    "thesis , department of computer science , university of aarhus , danmark , 1998 .",
    "available online from http://soi.standford.edu/@xmath391rmunk ."
  ],
  "abstract_text": [
    "<S> the harmonic lanczos bidiagonalization method can be used to compute the smallest singular triplets of a large matrix @xmath0 . </S>",
    "<S> we prove that for good enough projection subspaces harmonic ritz values converge if the columns of @xmath0 are strongly linearly independent . on the other hand </S>",
    "<S> , harmonic ritz values may miss some desired singular values when the columns of @xmath0 almost linearly dependent . </S>",
    "<S> furthermore , harmonic ritz vectors may converge irregularly and even may fail to converge . based on the refined projection principle for large matrix eigenproblems due to the first author , we propose a refined harmonic lanczos bidiagonalization method that takes the rayleigh quotients of the harmonic ritz vectors as approximate singular values and extracts the best approximate singular vectors , called the refined harmonic ritz approximations , from the given subspaces in the sense of residual minimizations . </S>",
    "<S> the refined approximations are shown to converge to the desired singular vectors once the subspaces are sufficiently good and the rayleigh quotients converge . </S>",
    "<S> an implicitly restarted refined harmonic lanczos bidiagonalization algorithm ( irrhlb ) is developed . </S>",
    "<S> we study how to select the best possible shifts , and suggest refined harmonic shifts that are theoretically better than the harmonic shifts used within the implicitly restarted lanczos bidiagonalization algorithm ( irhlb ) . </S>",
    "<S> we propose a novel procedure that can numerically compute the refined harmonic shifts efficiently and accurately . </S>",
    "<S> numerical experiments are reported that compare irrhlb with five other algorithms based on the lanczos bidiagonalization process . </S>",
    "<S> it appears that irrhlb is at least competitive with them and can be considerably more efficient when computing the smallest singular triplets .    </S>",
    "<S> singular values , singular vectors , svd , lanczos bidiagonalization , refined projection , harmonic , refined harmonic , implicit restart , harmonic shifts , refined harmonic shifts .    65f15 , 15a18 </S>"
  ]
}