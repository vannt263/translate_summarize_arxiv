{
  "article_text": [
    "random synchronous asymmetric neural networks ( rsanns ) with fixed synaptic coupling strengths and fixed neuronal thresholds / inputs tend to have access to a very limited set of different limit cycles ( amari ( 1974 ) , clark , krten & rafelski ( 1988 ) , littlewort , clark & rafelski ( 1988 ) , hasan ( 1989 ) , rand , cohen & holmes ( 1988 ) , clark ( 1990 ) , schreckenberg ( 1992 ) ) .",
    "we will show here , however , that when we add a moderate amount of randomly quenched noise or disorder , by choosing the neural thresholds or inputs to vary within a prescribed gaussian distribution , we can gain controllable , and we believe biologically relevant , access to a wide variety of limit cycles , each displaying dynamical participation by many neurons .",
    "the appearance of limit - cycle behavior in central pattern generators is evidence for cyclic temporal behavior in biological systems ( hasan ( 1989 ) , marder & hooper ( 1985 ) ) .",
    "previous computational models , as discussed above , do not exhibit a diverse repertoire of limit - cycle behaviors , as biological systems often demonstrate ( e.g. , the different gaits of a horse , or the different rhythmic steps of a good human dancer ) .",
    "additonally , it is our belief that the biologically - interesting networks are those in which a significant fraction of the neurons can ( and often do ) participate in the local dynamics . in principle , spatially - sparse neuronal firing patterns can be constructed from a large network of strongly - participatory neurons by self - organized architectural inhibition of selected neuronal assemblies .",
    "this can leave the uninhibited neuronal assemblies able to freely participate in the neural dynamics ( for some time ) , though these uninhibited neurons or neuronal assemblies may be isolated in space from each other , only connected to other active neurons through non - local or indirect connections ( gray & singer ( 1990 ) ) .",
    "therefore , in this paper , we explore the problem of how to produce a computational neural model which possesses a diverse repertoire of strongly - participatory limit - cycle behaviors .    a system which can access",
    "_ many _ limit cycles should always be able to access a novel mode ; hence the system would have the potential to be a ` _ creative _ ' system .",
    "herein , we demonstrate conditions sufficient to allow a simple computational neural system to access creative dynamical behavior .    in section  [ sec : rsann ] we introduce rsanns along with the concept of threshold disorder , as well as a measure to distinguish different limit cycles . in our quantitative investigations",
    "we need to introduce , with some precision , concepts which intuitively are easy to grasp , but which mathematically are somewhat difficult to quantify .",
    "we define ` _ eligibility _ ' in section [ sec : elig ] as an entropy - like measure of the fraction of neurons which actively participate in the dynamics of a limit cycle . in order to quantify the rsann s accessibility to multiple limit - cycle attractors",
    ", we define ` _ diversity _ ' in section  [ sec : div ] as another entropy - like measure , calculated from the probabilities that the rsann converges to each of the different limit cycles .",
    "the difference between eligibility and diversity is that the former applies to a limit cycle observed in a specific network , while the latter applies to the collection of limit cycles that the network can exhibit . to measure the creative potential of a system ,",
    "we introduce the concept of ` _ volatility _ ' as the ability to access a huge number of highly - eligible cyclic modes .",
    "we find that in terms of these diagnostic variables , as the neuronal threshold disorder @xmath0 increases , our rsann exhibits a phase transformation at @xmath1 from a small number to a large number of different _ accessible _ limit - cycle attractors ( section  [ sec : div ] ) , and another phase transformation at @xmath2 from high eligibility to low eligibility ( section  [ sec : elig ] ) .",
    "our main result is that the volatility is high only in the presence of threshold disorder of suitably chosen strength between @xmath3 , thereby allowing access to a diversity of eligible limit - cycle attractors ( section  [ sec : vol ] ) .",
    "symmetric neural networks ( snns ) ( hopfield ( 1982 ) ) became widely used in associative memory applications due to their ability to store a large number of patterns as fixed points of their dynamics ; however , their dynamical behaviour is restricted to fixed points or limit cycles of period 2 .",
    "in contrast , asymmetric neural networks ( rsanns ) show a complicated dynamical behaviour , including limit cycles of large periods or even chaos ( amari ( 1974 ) , clark , rafelski & winston ( 1985 ) , clark , krten & rafelski ( 1988 ) , littlewort , clark & rafelski ( 1988 ) , krten ( 1988 ) , bressloff & taylor ( 1989 ) , clark ( 1990 , 1991 ) , mcguire , littlewort & rafelski ( 1991 ) , mcguire _ et al . _",
    "( 1992 ) , bastolla & parisi ( 1997 ) ) .",
    "moreover , they offer considerably more biological realism , since real neuronal connections tend to be unidirectional .",
    "we investigate a network of @xmath4 threshold elements , i.e. their firing states have binary values @xmath5 .",
    "each neuron @xmath6 is connected to @xmath7 presynaptic neurons by unidirectional weights @xmath8 , with @xmath9 and @xmath10 .",
    "all weights are independent random variables , drawn from a uniform distribution within @xmath11 $ ] . a neuron fires if its post - synaptic - potential ( psp ) is greater than its specific threshold @xmath12",
    ". therefore the network is described by the following system of equations for ` sum - and - fire ' mccullough - pitts neurons : @xmath13 where @xmath14 is the heaviside function .",
    "supposing that all neurons should actively participate in the dynamics , with a mean firing rate @xmath15 , the mean thresholds @xmath16 are adjusted so that the mean overall input @xmath17 to a generic neuron @xmath6 becomes zero ( so that it is poised on the boundary between firing and not firing ) .",
    "thus , we have :    @xmath18    where the parameter @xmath19 is chosen to modulate the threshold .",
    "the case @xmath20 for all @xmath6 corresponds to the choice known as ` normal ' thresholds ( clark ( 1991 ) ) .",
    "the mean firing rate of 0.5 is quite high biologically , but computationally , it is a reasonable point to begin our research ; it is not too difficult to adapt the treatment to lower mean firing rates . in order for a given amount of threshold disorder to affect all neurons more - or - less equally ,",
    "we have chosen here a multiplicative scaling of the thresholds relative to the normal thresholds rather than an additive scaling .",
    "we do not consider synaptic noise or modulation ; hence the weights @xmath8 are kept fixed for a given network .    in considering the living neural networks in the brain ,",
    "some researchers treat the neuronal thresholds as constant and noiseless ( as in the hodgkin - huxley and fitzhugh - nagumo models ; see murray ( 1989 ) for a summary ) ; others are convinced that neurons live in a very noisy environment , both chemically and electrically , with nontrivial consequences for neuronal and network function ( see zador ( 1997 ) , chow & white ( 1996 ) , clark ( 1988 ) , buhmann & schulten ( 1987 ) , shaw & vasudevan ( 1974 ) , little ( 1974 ) , taylor ( 1972 ) , and lecar & nossal ( 1971 ) ) .",
    "examining the issue more closely , we may note that mainen & sejnowski ( 1995 ) have presented data suggesting a low intrinsic noise level for neurons , which does not seriously affect the precision of spike timing in the case of stimuli with fluctations resembling synaptic activity . on the other hand , pei , wilkens & moss ( 1996 )",
    "have presented evidence that noise can exert beneficial effects on neural processing through the phenomenon of stochastic resonance .    ) and the spatially - averaged firing rate @xmath21 , as a function of trial - number @xmath22 , and in the inset , a magnified view of @xmath21 , all as functions of time , @xmath23.,width=491 ]    mathematically , the external inputs to a neuron from sensory organs or from other areas of the neural system can also be treated as a modulation of the threshold of that neuron .",
    "this suggests that the results obtained on threshold modulation might be easily generalized to the situation of external modulation .    taken together",
    ", the noisiness of thresholds and the variability of inputs can be viewed as a changing environment .",
    "we simply model this complex changing environment by varying the normal thresholds using multiplicative gaussian noise @xmath19 with mean @xmath24 and standard deviation @xmath0 , leading to eq .",
    "[ eq : threshnoise1 ] .",
    "the components @xmath19 are chosen independently for all neurons @xmath6",
    ". it may be much more reasonable to consider spatially - correlated noise amplitudes , but such a study exceeds the scope of our present effort .      since we wish to study the diversity of different limit cycles accessible with small changes of the thresholds , we need a robust criterion for detecting limit cycles . even in the presence of small - amplitude noise effective on a shorter time scale than the cycle length",
    ", the neural net will never stabilize into a detectable perfect cycle .",
    "rather , it will either converge to an _ approximate _",
    "limit cycle with occasional misfirings or never converge at all .",
    "such approximate limit - cycle behavior is more relevant to neurobiological systems than is its perfect realization , due to the inherent destabilizing noise ( from membrane - potential or synaptic noise ) and additional complicating factors , notably ( 1 ) the complexity of biological neurons , ( 2 ) the continuum of signal transmission times between neurons , and ( 3 ) the apparent lack of a clock to synchronously update all neurons .",
    "however , although approximate limit - cycle behavior might be more common in volatile systems , it is not ideal for computer simulation and computer characterization . therefore ,",
    "for the sake of the computational tractability , we restrict our search to perfect limit cycles . in order to achieve this",
    ", we fix the neural thresholds @xmath12 until a limit cycle is found during network evolution via eq .",
    "[ eq : dynamics ] .",
    "since the noise is frozen - in ( ` quenched ' ) for a long period , it is more properly considered as disorder . before the next trial , the thresholds are varied according to eq .",
    "[ eq : threshnoise1 ] , changing the underlying network dynamics ; they are then fixed again during limit cycle search .",
    "each trial step starts with the activity pattern @xmath25 with which the previous trial was terminated . to gain a qualitative understanding of our approach ,",
    "see figure [ fig : clock ] .",
    "fixed points ( with limit - cycle period @xmath26 ) are generally of less interest than cyclic modes in view of the spontaneous oscillatory behavior displayed by real neural systems ( e.g walking or singing ) .",
    "effectively chaotic or non - cycling behavior ( with @xmath27 ) is not predictable enough to be of much use for most applications in real neural systems .",
    "limit cycles of intermediate period are consequently our paramount concern .",
    "we update all neuron firing states in parallel , or ` synchronously ' , as opposed to either serial or random updating in which only one neuron is updated at a given time step .    in our simulations",
    ", we used @xmath28 incoming connections per neuron , where self - connections were not allowed , and we studied networks with @xmath29 neurons .",
    "self - connections tend to have a stabilizing effect on the network , often driving the behavior towards a fixed point with only very brief transients .",
    "the different behavior of networks with and without self - connections might be a worthy subject of future investigation , but we chose not to emphasize that direction here . for practical computational reasons ,",
    "the network sizes investigated are primarily constrained by the existence of extremely long limit cycles and transients of large networks , occurring especially when the thresholds are near - normal , ( see clark ( 1990 , 1991 ) , clark , krten & rafelski ( 1988 ) , and littlewort , clark & rafelski ( 1988 ) for discussions of normal thresholds and the correlation between transient length and limit - cycle period ) .",
    "a network of @xmath4 threshold units can assume @xmath30 states , placing an upper limit on the length of a limit cycle .",
    "this upper limit for the cycle length is due to the facts that there are only a finite number of states and that the time development of the system is deterministic and depends only on the initial network state @xmath25 .",
    "since the detection of limit cycles at the microstate level @xmath31 is too time consuming ( it requires @xmath32 comparisons ) , we use the system - averaged firing rate @xmath33 in order to test for periodicity : @xmath34 \\ , , \\end{aligned}\\ ] ] where the limit - cycle period is is identified as @xmath35 . though satisfying equation  [ eq : activity2 ] is only a necessary condition for an exact limit cycle of period @xmath35 at the microstate - level , in practice we observed no differences between exact and average comparison methods on a small test set .",
    "we used a window of @xmath36 time steps to ensure that the cycle does indeed repeat itself in @xmath37 four times ; without explicitly tracking the microstate @xmath31 , such care is necessary in order to avoid false limit - cycle detection and measurement .      since diversity and volatility ( which we define in sections  [ sec : div ]  &",
    "[ sec : vol ] ) require an abundance of _ different _ limit cycles , we need to introduce a high - contrast , direct , neuron - by - neuron measure to decide whether a given limit cycle is different from or similar to another limit cycle .",
    "one could , of course , just compare the full neuron - by - neuron time - dependence of the activity patterns of the cycles themselves , but that would require a vast amount of memory to store all observed cycles .",
    "however , if as above , we choose to compare the time - dependence of the system - averaged firing rates instead of the full firing vectors , different limit cycles may be remarkably similar , possibly distinguished by only a small numerical difference , which we elucidate here with a specific example . given that :    * a network of @xmath4 neurons has two cycles : cycle * a * with period @xmath35 and cycle * b * with period @xmath38 , * cycle * a * has the same firing pattern at each time step as cycle * b * with the exception of two neurons at each time step in cycle * a * which differ from the corresponding two neurons in cycle * b * , * and the total number of firing neurons at each time step in cycle * a * is the same at each time step in cycle * b * ( due to the two neurons cancelling each other ) ,    then with system - averaged firing rates , the two cycles would be deemed identical , with the same period ; though a comparison of the time - dependence of full firing vectors would show the different period of the two cycles .    reliable discrimination clearly requires a compact measure , i.e. a fingerprint of a cycle , which is :    * independent of cycle length , * capable of discriminating between a wide array of limit cycles , and * easily computable .",
    "for this purpose we use the vector @xmath39^t$ ] formed by the time - averaged firing rates within @xmath40 time steps , @xmath41 since we base our limit - cycle detection upon a temporal quantity ( the time - dependent , system - averaged firing rate ) , our additional reference to a ` spatial ' quantity ( the time - independent , time - averaged firing vector ) serves as a good cross - check .",
    "obviously , use of limit - cycle period alone as our measure of similarity might have commonly led to misclassified cycles .",
    "we do not want to distinguish between very similar limit cycles , separated by only a small number of misfirings .",
    "therefore , for two cycles to be considered similar , we allow small non - zero values of the distance @xmath42 between their fingerprints @xmath43 and @xmath44 .    in figure  [",
    "fig : diffhisto ] , we show histograms of the distances between limit cycles with ( a ) equal and ( b ) different lengths , accumulated over a large number of different cycles and all investigated networks and thresholds . due to their high frequency , we have excluded pairs of cycles with @xmath45 from this figure . if the two cycles have the same period @xmath35 , the overall number of misfirings during @xmath46 timesteps is given by @xmath47 .",
    "the chosen value of the threshold @xmath48 for cycles to be regarded as similar is indicated in figure  [ fig : diffhisto ] as well .",
    "evidently , this choice is low enough to prevent misclassification of most of the different limit cycles , as it avoids the large peaks for larger @xmath49 , and it is sufficiently larger than zero to tolerate small deviations in similar cycles .",
    "it corresponds to one ` misfiring ' per time step for @xmath50 , on average .",
    "as observed in figure  [ fig : diffhisto].a ( center column ) , cycle pairs with equal and long periods ( @xmath51 ) produce a curious clustering of distances within @xmath52 .",
    "a closer inspection of this peak reveals that only three cycle pairs contribute to this clustering .",
    "therefore , in order to be conservative , we raised the threshold for limit - cycle difference to @xmath53 in this case . since the number of cycle pairs within this peak is only a small fraction of the total number of cycle pairs observed , this change in @xmath54 changes the ` diversity ' and ` volatility ' ( defined later ) only by a small amount .    for cycle pairs with short periods ( @xmath55 ) , the non - zero distances approximately follow a gaussian distribution with mean @xmath56 and standard deviation @xmath57 ( see figure  [ fig : diffhisto ] , left column ) .",
    "cycles with larger periods display a non - gaussian distribution ( see figure  [ fig : diffhisto ] , center column ) with positive skew , mean @xmath58 , and standard deviation @xmath59 .    splitting the range of compared periods into smaller intervals reveals that within these smaller intervals the distribution is gaussian as well , but with decreasing mean for increasing periods ( not shown ) .",
    "long - period limit cycles often tend to have a large fraction of their neurons firing very close to 50% of the time , reducing the average distance .",
    "the firing rate of random asymmetric neural networks tends to converge to a fixed point where the neural firing vector @xmath60 does not change in time , if the deviation from normal thresholds is large .",
    "if the mean threshold value is much greater or much less than normal , the neurons are less or more likely to fire and the rsann will tend to have a fixed point with very few or very many neurons firing each time step .",
    "these extreme conditions are called network ` death ' and ` epilepsy ' , respectively . by contrast , for normal thresholds @xmath61 , limit cycles with very long periods are possible , as seen in figs .",
    "[ fig : period_mean ] , [ fig : firefrac_mean ] ( cf . , clark , krten & rafelski ( 1988 ) , krten ( 1988 ) , clark ( 1990,1991 ) , mcguire , littlewort & rafelski ( 1991 ) , mcguire _ et al . _",
    "( 1992 ) ) .",
    "( averaged over time and neuron index ) for each observed limit cycle as a function of @xmath62 , for @xmath63 and @xmath64 . ]",
    "( averaged over time and neuron index ) for each observed limit cycle as a function of @xmath62 , for @xmath63 and @xmath64 . ]    when the mean threshold value is normal ( @xmath65 , but the threshold fluctuations from normality are large ( @xmath66 ) , then there also exist _ many _ different mixed death / epilepsy fixed points in which a fraction of the neurons are firing at each time step and the remaining neurons never fire .",
    "with growing @xmath0 , this fraction of neurons with constant firing state ( @xmath67 or @xmath68 for all @xmath23 ) grows , due to the fact that a larger fraction of the neuron thresholds differ significantly from their normal values .",
    "therefore , as @xmath0 increases , a smaller fraction of neurons actively participate in the dynamics , making the effective network size smaller and the limit cycles shorter .",
    "as can be seen in figure  [ fig : period_eps ] , the average period and the maximal period both decrease roughly exponentially with growing @xmath0 .",
    "conversely , as @xmath0 increases , the number of different limit cycles increases as well ( as observed during many different trials , each with a different random realization of thresholds @xmath69 ) .",
    "this increase in the observed number of different cycles is caused by each network realization eventually producing a ( short ) limit cycle in a different portion of the network , as more and more different neurons drop out of the picture as dynamical participants ( figure  [ fig : newcycles ] ) .",
    "the saturation for some of the nets in the ensemble of 10 nets is artificial , since we limited the maximum number of trials to 1000 to constrain computational costs .",
    ", the behavior seems much more regular , with the large deviations from the ensemble - average behavior for large @xmath0 becoming less important .",
    "the general shape for @xmath70 is of a power law with exponent near @xmath71 and positive coefficient ( @xmath72 , with @xmath73 ) , the near - unity exponent of the power law making it roughly a linear dependence as well .",
    "for particular examples from this 10-network ensemble , the dependence of the @xmath74 curve is sometimes not a power - law ; and for the cases in which the behavior is similar to that of a power law , the coefficient @xmath75 and exponent @xmath22 of the power law both differ by as much as a factor of 2 from the coefficient and exponent for the average behavior .",
    "the fact that the average behavior is a power law or even a linear function ( rather than irregular behavior ) means that it might be worthwhile and interesting in the future to perform a theoretical analysis of cycle diversity for rsanns as a function of threshold disorder . ]    in the following three sections , we limit our discussion to a small ensemble of 10 networks with different connection - strength matrices , and we compute the mean and variation of the quantities - of - interest , as a function of the disorder amplitude , @xmath0 . in section  [ sec :",
    "ensemble ] , we explore a much larger ensemble of 300 networks , but for only a few values of @xmath0",
    ".     increases ( for @xmath76 , @xmath77 ; note the semi - logarithmic scale . ) the average period for 10 networks is plotted as a solid line , and the average of the maximum periods for these 10 networks is plotted as a thick dashed line , with @xmath78 deviation limits plotted as dotted lines . ]",
    "increases ( for @xmath50 , and for a maximal number of trials @xmath79 , in linear and log - log plots ) . for @xmath80 ,",
    "the ensemble - average scaling is approximately as a power law , @xmath81 , with @xmath73 , making it roughly a linear function as well.,title=\"fig : \" ]   increases ( for @xmath50 , and for a maximal number of trials @xmath79 , in linear and log - log plots ) . for @xmath80 ,",
    "the ensemble - average scaling is approximately as a power law , @xmath81 , with @xmath73 , making it roughly a linear function as well.,title=\"fig : \" ]      since we are interested in complex dynamical behaviour , a large fraction of neurons should participate non - trivially in the dynamical collective activity of the network ",
    "such a network is said to have a high degree of eligibility .",
    "a limit cycle @xmath22 will have a maximally eligible time - averaged firing pattern @xmath82 , if @xmath83 for all neurons @xmath6 .",
    "there will be minimal eligibility if @xmath84 for all neurons @xmath6 .",
    "the shannon information ( or entropy ) has these properties , so we will adopt an entropy function as our measure of the eligibility of a given limit - cycle attractor @xmath22 : @xmath85 the mean eligibility @xmath86 , averaged over all @xmath87 trials , is @xmath88 for fixed network connectivity and fixed @xmath0 . despite its utility , we do not have a rigorous dynamical motivation for quantifying eligibility by entropy .",
    "as discussed at the beginning of this section , the fraction of actively participating neurons decreases with growing @xmath0 ; thus eligibility is decreasing as well ( figure  [ fig : elig_eps ] ) .",
    "in other words , when the thresholds become grossly ` out - of - tune ' with the mean membrane potential , the rsann attractors become more trivial , with each neuron tending toward its own independent fixed point @xmath68 or @xmath67 .",
    "we measure the accessibility of a given attractor by estimating the probability @xmath89 that a given attractor ( first observed at trial @xmath22 ) is observed during all @xmath87 trials , identified with its relative frequency of occurence @xmath90 where @xmath91 is the number of observations of limit cycle @xmath22 .",
    "note that if a given attractor is only observed _ once _",
    ", then @xmath92 , while if the same attractor is observed in every trial , then @xmath93 .",
    "given that each different limit - cycle attractor is accessed by the network with probability @xmath89 , we can define the diversity @xmath94 as the attractor occupation entropy : @xmath95 and @xmath96 is the total number of different observed cycles .",
    "it is easily seen that a large @xmath94 corresponds to the ability to occupy many different cyclic modes with nearly equal probability ; the diversity will reach a maximum value of @xmath97 when @xmath98 for all limit cycles @xmath22 , i.e. if in each trial a different cycle is observed .",
    "a small value of @xmath99 corresponds to a strong stability ( or inflexibility ) of the system  very few different cyclic modes are available .",
    "as can be seen from figure  [ fig : div_eps ] the diversity grows rapidly with increasing disorder amplitude @xmath0 , and with a relatively small disorder value of @xmath100 , the diversity is already half of its maximal value . since it takes into account the accessibility of all the detected cycles , this technique of quantifying diversity by an entropy function is considerably more robust and meaningful than simply counting the cycles .",
    "volatility is defined as the ability to access a large number of highly eligible limit cycles , or a ` mixture ' of high eligibility and high diversity .",
    "having defined both eligibility and diversity , we can now combine them to define volatility as an entropy - weighted entropy : @xmath101 since the volatility curve in figure  [ fig : vol_eps ] is roughly the product of the eligibility and the diversity curve in figures  [ fig : elig_eps ] and [ fig : div_eps ] , there exists an intermediate regime @xmath102 of high volatility . at @xmath100",
    "the growing disorder amplitude causes a transformation to a condition of diversity , entailing many different limit cycles , whereas at @xmath103 the disorder amplitude has become so large that most limit cycles become fixed points .",
    "we accordingly identify three different regimes for the rsann with disorder :    1 .",
    "stable regime : @xmath104 2 .",
    "volatile regime : @xmath105 3 .",
    "trivially random regime : @xmath106 .",
    "neurons , each with different connection strength matrices , we form histograms of the number of limit cycles found in each different network .",
    "histograms for four different values of @xmath0 are presented .",
    "note the rebinned histogram in the inset of the @xmath107 histogram .",
    ", title=\"fig:\",scaledwidth=49.0% ]   neurons , each with different connection strength matrices , we form histograms of the number of limit cycles found in each different network .",
    "histograms for four different values of @xmath0 are presented .",
    "note the rebinned histogram in the inset of the @xmath107 histogram .",
    ", title=\"fig:\",scaledwidth=50.0% ]   neurons , each with different connection strength matrices , we form histograms of the number of limit cycles found in each different network .",
    "histograms for four different values of @xmath0 are presented .",
    "note the rebinned histogram in the inset of the @xmath107 histogram .",
    ", title=\"fig:\",scaledwidth=49.0% ]   neurons , each with different connection strength matrices , we form histograms of the number of limit cycles found in each different network .",
    "histograms for four different values of @xmath0 are presented .",
    "note the rebinned histogram in the inset of the @xmath107 histogram .",
    ", title=\"fig:\",scaledwidth=50.0% ]    the results obtained in sections  [ sec : elig ]  -  [ sec : vol ] were obtained from ten rsanns with random weight matrices drawn from the uniform distribution @xmath108 $ ] . as can be seen from the standard deviation curves in figures  [ fig : elig_eps]-  [ fig : vol_eps ] , which are in close proximity to the average curves , all networks exhibit the same qualitative behaviour . to further confirm this finding ,",
    "we have tabulated in tables  [ tab : numfig ] &  [ tab : periodlength ] and figure  [ fig : histonumdiff ] the statistics of the number of different limit cycles , their periods , and the diversity & volatility , for 300 networks with different connection strength matrices using 500 different disorder vectors @xmath109 for each network . the @xmath110 results in table  [ tab : numfig ] and",
    "figure  [ fig : histonumdiff ] confirm amari s theoretical result ( 1974 ) and the empirical results of clark , krten & rafelski ( 1988 ) , that random networks tend to possess only a small number of different cyclic modes . for larger @xmath0 , the ensemble - average number of cycles , the diversity and volatility are all much larger than for @xmath63 .",
    "in particular , the results shown in table  [ tab : periodlength ] suggest that with increasing @xmath0 , the minimum period rapidly decreases , whereas the maximum period rapidly increases , with the average period staying roughly constant and closer to the minimum than the maximum .",
    "this suggests that at least a few limit cycles having long periods exist with non - normal thresholds , and that there are many more fixed points than long - period limit cycles when the thresholds are far from normal , than when the thresholds are close to normal .",
    ".for 300 networks of @xmath50 neurons , each with a different matrix of connection strengths , we tabulate the statistics of the number of observed limit cycles ( maximum number , average number of cycles , and average number of long cycles ) , as well as the average diversity and the average volatility .",
    "the results are given for 4 different values of threshold disorder @xmath0 . [ cols= \"",
    "> , > , > , > , > , > \" , ]      we have shown in sections  [ sec : elig ]  -  [ sec : ensemble ] that when we change the threshold parameters of a network sufficiently far from their default values , then we get new , non - trivial behavior for nearly each parameter realization .",
    "since the level of threshold disorder which is needed to obtain new and complex behavior is not too high , the ensemble of networks can exhibit diverse and complex behavior with only slight changes in the network parameters .    ) of the small number of observed cycles ( compare fig .",
    "[ fig : stab_cycles_eps ] ) allows us to estimate the relative sizes of the basins of attraction .",
    "since the entropy reaches only half of its maximum , some cycles dominate over the others .",
    "the solid curve is a smoothed average curve ; the dashed curves are smoothed @xmath111 error curves . ]    ) of the small number of observed cycles ( compare fig .",
    "[ fig : stab_cycles_eps ] ) allows us to estimate the relative sizes of the basins of attraction .",
    "since the entropy reaches only half of its maximum , some cycles dominate over the others .",
    "the solid curve is a smoothed average curve ; the dashed curves are smoothed @xmath111 error curves . ]    in order to demonstrate that this diversity originates only from ensemble diversity and is not intrinsic to the specific network realizations , we must show that each specific network of the ensemble possesses only a limited set of limit cycles .",
    "for this reason we counted the number of different observed cycles @xmath112 of each network @xmath113 in the ensemble starting with 100 randomly - chosen initial activity patterns @xmath25 .",
    "then we performed the ensemble average @xmath114 as can be seen from figure  [ fig : stab_cycles_eps ] , the number of different observed cycles is rather small , _ and _ does not depend upon the disorder amplitude @xmath0 .",
    "of course , the _ actual _ size of the repertoire does depend on the instantiation of @xmath115 , as evidenced by the deviations ( indicated by dashed curves ) , but the degree of variation in @xmath116 in no way matches the substantial secular increase of @xmath116 observed in figure  [ fig : newcycles ] .    using a similar diversity measure like in equation  [ eq : div ] , but now using the occurence probabilities of observed cycles with fixed network parameters , it is possible to estimate the relative sizes of the basins of attraction of these cycles .",
    "the diversity becomes maximal when all cycles are observed with equal probability , corresponding to basins of attractions of equal size .",
    "as can be seen from figure  [ fig : stab_entropy_eps ] , the diversity reaches only the half of its maximum , indicating basins of attraction of different sizes .",
    "the figure suggests that @xmath117 , implying that @xmath118 . in other words , for fixed thresholds , as we vary the initial firing vector , we observe the same cycle in greater than @xmath119 of the trials ; as evident in figure  [ fig : stab_entropy_eps ] , there is little dependence in the fixed - threshold cycle - diversity upon the frozen - disorder amplitude @xmath0 .      for the choice of threshold and connectivity parameters made here",
    ", the average cycle length @xmath120 grows exponentially with the network size @xmath4 ( see fig .  [",
    "fig : periodlen_netsize ] ) .",
    "this exponential scaling of the cycle length puts it in the ` chaotic ' regime of krten s ( 1988 ) classification of dynamical phases , where the motion shows high sensitivity to initial conditions .",
    "krten also found a ` frozen ' regime where the limit - cycle period scales as a power law in @xmath4 , and where there is little sensitivity of the attracting limit cycle upon initial conditions . when @xmath121 , which is in the volatile region , a broad , non - gaussian distribution of cycle lengths is found ( see fig .",
    "[ fig : periodhisto ] ) .",
    "furthermore , since the cycle - length distribution shown in fig .",
    "[ fig : periodhisto ] does not exhibit peaks at regularly spaced intervals , the possibility that we have employed an errant limit - cycle comparison algorithm is unlikely .",
    "this distribution of cycle - lengths for rsanns differs significantly from the @xmath122 distribution of cycle - lengths predicted for kauffman s boolean nets by bastolla and parisi ( 1997 ) .",
    "this difference in distributions implies that there may be some significant differences between these two types of nets .    , @xmath121 ) .",
    "we overlay a fit to the distribution predicted by bastolla & parisi ( 1997 , 1997b ) for kauffman nets . ]    , @xmath121 ) .",
    "we overlay a fit to the distribution predicted by bastolla & parisi ( 1997 , 1997b ) for kauffman nets . ]      in figure [ fig : newcycles ] , we showed that the number of different attractors observed , @xmath74 , is a significant fraction of the total number of trials @xmath87 when @xmath123 . for disorder between @xmath124 and @xmath125 ,",
    "the number of cycles observed is much larger than one ( see figure  [ fig : div_eps].b ) , but less than the total number of trials . in the stable regime ( @xmath126 ) , @xmath74 is quite small and largely independent of @xmath87 .",
    "these three results are complementary : the first result ( at high @xmath0 ) implying a nearly inexhaustible source of different limit - cycle attractors accompanied by a steady decrease of eligibility with increasing @xmath0 ; the second result ( at moderate @xmath0 ) implying a large , but limited repertoire of limit cycles of high eligibility ; and the third result ( at very low @xmath0 ) implying that we can exhaustively access a small group of high - eligibility limit - cycle attractors with a high degree of robustness .    in the stable regime , @xmath74 is often greater than @xmath127 ( though small ) , which means that the stable phase can not be used to access a particular attractor upon demand , but we can demand reliable access to one of a small number of different attractors .",
    "frequently , however , there is a single dominant attractor , as indicated by the low entropy seen in fig .",
    "[ fig : stab_entropy_eps ] .",
    "we conclude that , in practice , for a given set of network parameters or external inputs to the network , but starting with different initial conditions , the network will converge to the same attractor most of the time .",
    "in the ` noisy ' runs at @xmath128 , epitomized by fig .",
    "[ fig : clock ] , we are actually sampling a significant fraction of an entire ensemble of closely - related networks over the course of time , as the noise or disorder or an external input slowly varies . based upon the results for our rsann model , quenched noise ( disorder ) can give a dynamical system access to a whole ensemble of different behaviors at different times during the lifetime of the dynamical system .",
    "in other words , slowly - varying threshold noise or disorder or external input can act as a ` scanner ' for a host of dynamic modes .    the posed existence ( skarda & freeman ( 1987 ) , yao & freeman ( 1990 ) , freeman _",
    "( 1997 ) ) of a chaotic ground - state attractor for the olfactory system and the existence of ` multistable ' limit - cycle excited - state attractor lobes provides a striking exemplification of our volatility concept , and potentially an _ in vivo _ demonstration of this phenomenon .",
    "the rsann networks studied here have a small repertoire of behaviors when there is no noise or disorder in the thresholds ( @xmath63 ) ; hence , there is little multistability .",
    "the size of the repertoire becomes tremendously large ( as does the extent of multistability ) for ` small ' changes in the threshold parameters ( @xmath129 ) .",
    "one is therefore tempted to call this behavior ` chaotic ' with respect to the parameter changes , since it has one of the hallmarks of chaos ( sensitive dependence upon small changes of the parameters ) . however , for smaller changes in the threshold parameters ( @xmath130 ) , the repertoire of @xmath131 behaviors is ` stable '  no new cycles are observed . for the purpose of discussion",
    ", we refer to this _ delimited _ sensitivity to parameter changes , as ` quasi - chaos ' or ` quasi - multistability ' .",
    "additionally , the stability is augmented by the fact that very frequently , the repertoire of a network in the stable regime is dominated by a single cycle ( for fixed connections and fixed disorder ) , a phenomenon known as ` canalization ' ( kauffman ( 1993 ) ) .",
    "hence , for the sake of argument , we will also assume that in the stable regime only one cycle is accessible . by taking advantage of the quasi - chaotic / quasi - multistable threshold parameters ( noting that the connection strength parameters are probably also quasi - chaotic )",
    ", we can access a large number of different rsann attractors , each with a small neighborhood of stability in threshold - parameter space . with a suitable feedback algorithm",
    ", one might be able to control this quasi - chaos ( cf .",
    "ott , grebogi & yorke ( 1990 ) ) and access and stabilize a given attractor upon demand . due to the proximity of other limit cycles just beyond the local neighborhood of stability of the given attractor , novel attractors are always within a stone s throw of the given attractor , while maintaining a respectable distance so as not to be destabilizing .",
    "such an approach to controlled creativity has been developed into the adaptive resonance formalism ( carpenter & grossberg ( 1987 ) ) .",
    "the volatile regime within @xmath132 can be subdivided into two sub - regimes .",
    "the lower end of the range , @xmath133 , which corresponds to the upward - sloping part of the volatility curve in figure  [ fig : vol_eps].b , could suggestively be named the ` creative ' regime , wherein new cycles are observed with some rarity , so as to provide truly new behavioral modes for the rsann .",
    "these new cycles can be taken together with the more commonly - observed cycles in the net s repertoire , perhaps to produce new and ` interesting ' sequences of behavior ( if these cyclic modes can be logically sequenced ) .",
    "the upper end of the range , @xmath134 , might be regarded as the ` overly - creative ' or ` slightly - mad ' regime of the rsann .",
    "new , rather complex modes are being found with almost every trial , which could overwhelm the ` bookkeeping ' resources necessary for the rsann to implement or utilize the new mode to its full potential .",
    "clearly , this abstract and simple rsann model is insufficent to be a true neurobiological model of creativity / madness , but it could be a good starting point for a more detailed model .      it may well be a common feature of a broad class of complex , non - linear systems without adaptability or noise that the diversity of non - trivial behaviors is limited .",
    "we have confirmed the lack of diverse behavior for a non - linear system with truly simple elements ( mccullough - pitts neurons ) ; we have also seen similar non - volatile behavior for a slightly more general , discretized integrate - and - fire neuron model .",
    "this canalization result may be generalizable to other complex systems of either simple or complex units .",
    "indeed , one of the first observations of canalization was in kauffman s boolean immunological networks , which have some significant differences from rsanns .",
    "the canalization property might have been more difficult to generalize if we had started with more complex units like hodgkin - huxley neurons .",
    "furthermore , it is plausible that the introduction of a moderate amount of noise or disorder will _ generally _ increase the diversity of complex behaviors , as we have seen in rsanns .",
    "our volatility - producing model might be applicable in more abstract situations .",
    "one might imagine that the states of our simple boolean neuron reflect in some manner the ` on or off ' state of complex subunits of a modular system .",
    "such modular complex systems could be probed to determine whether dynamical diversity can or can not be enhanced by small changes in network parameters .",
    "examples might include :    1 .   a random neural network composed of subnetworks ; 2 .",
    "a network of complex , real neurons ; 3 .",
    "the brain of an organism with its different subsystems ; 4 .",
    "the geoeconomic or political structure of a large country composed of smaller states , regions , or cities ; and 5 .   the ecological network of the world composed of different regions or of different subcommunities of animals or plants .    in models with subunits that are composed of many sub - subunits , the stability or canalizing ability of the system itself",
    "may be significantly enhanced either by a law - of - large - numbers decrease in the noise / disorder susceptibility of an individual subunit , or by self - stabilizing internal feedback loops which may be present by design within the subunits .      based on combinatorics and statistical arguments",
    ", one expects to find many limit cycles in a random synchronous asymmetric neural network ( rsann ) .",
    "experience has shown otherwise .",
    "after much of this paper was completed , we found an analytical argument by amari ( 1974 , 1989 ) to the effect that rsanns have only one attractor , in the thermodynamic limit of a large number of neurons , thus explaining our @xmath63 results .",
    "the main objective of our study has been to construct a volatile neural network which exhibits a large set of easily - accessible highly - eligible limit - cycle attractors , as has been achieved already in a non - neural system ( poon & grebogi ( 1995 ) ) .",
    "first , we have demonstrated that in the absence of noise and in the absence of random , long - term imposition of threshold disorder , a random asymmetric neural network can reach only a small number of different limit - cycle attractors .",
    "second , by imposing and freezing neuronal threshold disorder within a well - defined range ( @xmath135 ) , we show that rsanns can access a diversity of highly - eligible limit - cycle attractors .",
    "rsanns exhibit a phase transformation from a small number of distinct limit - cycle attractors to a large number at a disorder amplitude of @xmath136 .",
    "likewise , rsanns exhibit an eligibility phase transformation at a threshold disorder amplitude of @xmath137 .",
    "potentially , amari s argument can be extended to gain an understanding of how slight changes of threshold parameters beyond some minimal level can substantially increase the diversity of accessible cyclic modes .",
    "this extension is beyond the scope of the current work .",
    "another very interesting question is how the diversity and volatility curves scale with the size of the network .",
    "while the addition of threshold disorder seems to be a trivial mechanism for enhancing the volatility or diversity by constantly changing the parameters of the rsann , we believe that since some biological systems ( neiman _ et al . _",
    "( 1999 ) ) may use threshold , synapse and/or externally - generated noise or disorder to enhance their abilities , we have discovered a simple feature which could have some importance in modeling biological systems .",
    "we fully expect that other volatility - enhancing mechanisms are available beyond the particular one proposed here .    in summary ,",
    "our key result is that a random neural network can be driven easily from one to another stable recurrent mode . while such behavior can be always accomplished by radical modifications of some of the network properties , the interesting result we have here presented",
    "is that plausibly small ( e.g. , rms in the neighborhood of 0.1 - 1% ) and random changes imposed _ simultaneously _ upon all of the neural threshold parameters suffices to access new dynamical behavior .",
    "indeed , due to the combinatorics of changing many parameters simultaneously , an immense number of interesting modes become available to the system .",
    "we are aware that this does not yet create a network that can self - sequence a series of modes , though some authors have already made considerable progress in this direction ( e.g. dauc and quoy ( 2000 ) , tani ( 1998 ) ) .",
    "the development of autonomous control algorithms that provide access to mode sequences is a natural but challenging objective that can potentially lead to a deeper understanding of information processing in recurrent neural networks .",
    "h. bohr would like to acknowledge the hospitality of p. carruthers ( now deceased ) , j. rafelski , and the u. arizona department of physics during several visits when much of this work was carried out . during his graduate studies ,",
    "p. mcguire was partially supported by an nsf / u.s .",
    "department of education / state of arizona doctoral fellowship .",
    "clark acknowledges research support from the u.s .",
    "national science foundation under grant no .",
    "mcguire , bohr and clark were participants in the research year on the `` the sciences of complexity :  from mathematics to technology to a sustainable world '' at the center for interdisciplinary studies ( zif ) at the university of bielefeld , in germany .",
    "we all thank many individuals who have provided different perspectives to our work , including the following : g. sonnenberg , d. harley , z. hasan , h. ritter , r. vilela - mendes , and g. littlewort .",
    "clark , k.e .",
    "krten and j. rafelski , `` access and stability of cyclic modes in quasirandom networks of threshold neurons obeying a determinisitic synchronous dynamics , '' _ computer simulation in brain science _ , edited by r.m.j cotterill ( cambridge univ .",
    "press : cambridge,1988 ) 316 .",
    "z. hasan , `` biomechanical complexity and the control of movement , '' _ lectures in the sciences of complexity _ , edited by d.l .",
    "stein ( santa fe institute studies in the sciences of complexity , addison - wesley ) ( 1989 ) 841 .                    e. marder and s.l .",
    "hooper , `` neurotransmitter modulation of the stomatogastric ganglion of decapod crustaceans , '' _ model neural networks and behavior _ , editted by a.i .",
    "selverston ( plenum press : new york,1985 ) , 319 .",
    "mcguire , g.c .",
    "littlewort , c. pershing and j. rafelski , `` training random asymmetric ` neural ' networks towards chaos  a progress report , '' _ proceedings of the workshop on complex dynamics in neural networks_,edited by j.g taylor , e.r .",
    "caianiello , r.m.j .",
    "cotterill and j.w .",
    "clark ( springer - verlag , london , 1992 ) pp .",
    "90 - 102 .",
    "a. neiman , x. pei , d. russell , w. wojtenek , l. wilkens , f. moss , h. braun , m. huber and k. voight , `` synchronization of the electrosensitive noisy cells in the paddlefish , '' _ phys .",
    "* 82 * ( 1999 ) 660 .",
    "rand , a.h .",
    "cohen and p.j .",
    "holmes , `` systems of coupled oscillators as models of central pattern generators , '' _ neural control of rhythmic movements in vertebrates _ , eds .",
    "cohen , s. rossignol , and s. grillner ( john wiley : new york , 1988 ) , 333 ."
  ],
  "abstract_text": [
    "<S> we study the diversity of complex spatio - temporal patterns in the behavior of random synchronous asymmetric neural networks ( rsanns ) . special attention is given to the impact of disordered threshold values on limit - cycle diversity and limit - cycle complexity in rsanns which have ` normal ' thresholds by default . </S>",
    "<S> surprisingly , rsanns exhibit only a small repertoire of rather complex limit - cycle patterns when all parameters are fixed . </S>",
    "<S> this repertoire of complex patterns is also rather stable with respect to small parameter changes . </S>",
    "<S> these two unexpected results may generalize to the study of other complex systems . in order to reach beyond this seemingly - disabling ` stable and small ' aspect of the limit - cycle repertoire of rsanns </S>",
    "<S> , we have found that if an rsann has threshold disorder above a critical level , then there is a rapid increase of the size of the repertoire of patterns . </S>",
    "<S> the repertoire size initially follows a power - law function of the magnitude of the threshold disorder . as the disorder increases further , </S>",
    "<S> the limit - cycle patterns themselves become simpler until at a second critical level most of the limit cycles become simple fixed points . </S>",
    "<S> nonetheless , for moderate changes in the threshold parameters , rsanns are found to display specific features of behavior desired for rapidly - responding processing systems : accessibility to a large set of complex patterns . </S>"
  ]
}