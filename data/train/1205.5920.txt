{
  "article_text": [
    "communication networks are presenting ever - increasing challenges in a wide range of applications , and there is great interest in inferential methods for exploiting the information they contain .",
    "a common source of such data is a corpus of time - stamped messages such as e - mails or sms ( short message service ) .",
    "such messaging data is often useful for inferring a social structure of the community that generates the data . in particular , messaging data is an asset to anyone who would like to cluster actors according to their _ similarity_. a practitioner is often privy to messaging data in a _ streaming _ fashion , where the word _ streaming _ describes a practical limitation , as the practitioner might be privy only to the incoming data in a fixed summarized form without any possibility to retrieve past information .",
    "it is in the practitioner s interest to transform the summarized data so that the transformed data is appropriate for detecting _ emerging _ social trends in the source community .    we mathematically model such streaming data as a collection of tuples of the form @xmath0 of time and actors , where @xmath1 and @xmath2 represent actors exchanging the @xmath3-th message and @xmath4 represents the occurrence time of the @xmath3-th message .",
    "there are many models suitable for dealing with such data .",
    "the most notable are the cox hazard model , the doubly stochastic process ( also known as the cox process ) , and the self - exciting process ( although self - exciting processes are sometimes considered as special cases of the cox hazard model ) . for references on these topics , see @xcite , @xcite and @xcite .",
    "all three models are related to each other ; however , the distinctions are crucial to statistical inference as they stem from different assumptions on information available for ( online ) inference . to transform @xmath5 data to a data representation more suitable for clustering actors",
    ", we model @xmath5 as a ( multivariate ) doubly stochastic process , and develop a method for embedding @xmath5 as a stochastic process taking values in @xmath6 for some suitably chosen @xmath7 .",
    "for statistical inference when there is information available beyond @xmath5 , the cox - proportional hazard model is a natural choice . in @xcite and @xcite , for instance , instantaneous intensity of messaging activities between each pair of actors is assumed to be a function of , in the language of generalized linear model theory , known covariates with unknown regression parameters . more specifically , in @xcite , the authors consider a model where @xmath8 with @xmath9 and @xmath10 representing independent counting processes , e.g. , @xmath9 are bernoulli random variables and @xmath10 are random variables from the exponential family . on the other hand , in @xcite ,",
    "a cox multiplicative model was considered where @xmath11 .",
    "the model in @xcite posits that actor @xmath12 interacts with actor @xmath13 at a baseline rate @xmath14 modulated by the pair s covariate @xmath15 whose value at time @xmath16 is known and @xmath17 is a common parameter for all pairs . in @xcite , it is shown under some mild conditions that one can estimate the global parameter @xmath17 consistently . in @xcite , the intensity is modeled for _ adversarial _ interaction between _ macro _ level groups , and a problem of nominating unknown participants in an event as a missing data problem is entertained using a self - exciting point process model . in particular , while no explicit intensity between a pair of actors ( gang members ) is modeled , the event intensity between a pair of groups ( gangs ) is modeled , and the spatio - temporal model s chosen intensity process is self - exciting in the sense that each event can affect the intensity process .",
    "when data @xmath5 is the only information at hand , a common approach is to construct a time series of ( multi-)graphs to model association among actors .",
    "for such an approach , a simple method to obtain a time series of graphs from @xmath18 is to `` pairwise threshold '' along a sequence of non - overlapping time intervals .",
    "that is , given an interval , for each pair of actors @xmath12 and @xmath13 , an edge between vertex @xmath12 and vertex @xmath13 is formed if the number of messaging events between them during the interval exceeds a certain threshold .",
    "this is the approach taken in @xcite , @xcite and @xcite , to mention just a few examples .",
    "the resulting graph representation is often thought to capture the structure of some underlying social dynamics .",
    "however , recent empirical research , e.g. , @xcite , has begun to challenge this approach by noting that changing the thresholding parameter can produce dramatically different graphs .",
    "another useful approach when @xmath5 is the only information available is to use a doubly stochastic process model in which count processes are driven by latent factor processes .",
    "this is the approach taken explicitly in @xcite and @xcite , and this is also done implicitly in @xcite . in @xcite and @xcite",
    "interactions between actors are specified by proximity in their latent positions ; the closer two actors are to each other in their latent configuration , the more likely they exchange messages . using our model",
    ", we consider a problem of clustering actors `` online '' by studying their messaging activities .",
    "this allows us a more geometric approach afforded by embedding @xmath19 data to an @xmath20 representation for some fixed dimension @xmath21 .    in this paper , we propose a useful mathematical formulation of the problem as a filtering problem based on both a multivariate point process observation and a population latent position distribution .",
    "as a convention , we assume that a vector is a column vector if its dimension needs to be disambiguated .",
    "we denote by @xmath22 the filtration up to time @xmath16 that models the information generated by undirected communication activities between actors in the community , where `` undirected '' here means we do not know which actor is the sender and which is the receiver .",
    "we denote by @xmath23 the space of probability measures on @xmath6 . for a probability density function defined on @xmath6 , @xmath24 denotes the probability density function that is proportional to @xmath25 where the normalizing constant does not depend on @xmath26 .",
    "the set of all @xmath27 matrices over the reals is denoted by @xmath28 . for each @xmath29 matrix @xmath30 , we write @xmath31 .",
    "given a vector @xmath32 , we write @xmath33 for its euclidean norm .",
    "let @xmath34 and @xmath35 . for each @xmath36 and @xmath37",
    ", we write @xmath38 for the hadamard product of @xmath36 and @xmath39 , i.e. , @xmath40 denotes component - wise multiplication . given vectors @xmath41 in @xmath6 , the gram matrix of the ordered collection @xmath42 is the @xmath43 matrix @xmath44 such that its @xmath45- entry @xmath46 is the inner product @xmath47 of @xmath48 and @xmath49 . given a matrix @xmath50 , @xmath51 is the column vector whose @xmath52-th entry is the @xmath52-th diagonal element of @xmath53 . with a slight abuse of notation , given a vector @xmath32 , we will also denote by @xmath54 the @xmath43 diagonal matrix such that its @xmath52-th diagonal entry is @xmath55 .",
    "we always use @xmath56 for the number of actors under observation and @xmath21 for the dimension of the latent space .",
    "we denote by @xmath57 the @xmath56-fold product @xmath58 of @xmath6 .",
    "an element of @xmath57 will be written in bold face letters , e.g.  @xmath59 .",
    "similarly , bold faced letters will typically be used to denote objects associated with the @xmath56 actors collectively . an exception to this convention is the identity matrix which is denoted by @xmath60 , where the dimension is specified only if needed for clarification . also , we write @xmath61 as the column matrix of ones . with a bit of abuse of notation",
    ", we also write @xmath61 for an indicator function , and when confusion is possible , we will make our meaning clear .",
    "our actors under observation are assumed to be a subpopulation of a bigger population .",
    "that is , we observe actors @xmath62 that are sampled from a population for a longitudinal study .",
    "we are not privy to the actors latent features that determine the frequency of pairwise messaging activities , but we do observe messaging activities @xmath63 . a notional illustration of our approach thus far is summarized in figure [ fig : hierarchalmodeldiagram ] , figure [ fig : subpop_historgrams ] , and figure [ fig : kullback - leibler divergence - simulation ] .",
    "in both figure [ fig : subpop_historgrams ] and figure [ fig : kullback - leibler divergence - simulation ] , @xmath64 represents the ( same ) initial time when there was no cluster structure , and @xmath65 and @xmath66 represent the emerging and fully developed latent position clusters which represent the object of our inference task .     for a more detailed diagram . ]",
    "[ [ population - density - process - level ] ] population density process level + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the message - generating actors are assumed to be members of a community , which we call the population . the aspect of the population that we model in this paper is its members distribution over a latent space in which the proximity between a pair of actors determines the likelihood of the pair exchanging messages .",
    "the population distribution is to be time - varying and a mixture of component distributions .",
    "the latent space is assumed to be @xmath6 for some @xmath7 , and the population distribution at time @xmath16 is assumed to have a continuous density @xmath67 . to be more precise ,",
    "we assume that the ( sample ) path @xmath68 is such that for each @xmath69 , @xmath70 where    * @xmath71 is a smooth _ sample _ path of a stationary ( potentially degenerate ) diffusion process taking values in @xmath72 , * @xmath73 is a probability density function on @xmath6 with convex support with its mean vector being the zero vector and its covariance matrix being a positive definite ( symmetric ) matrix , * @xmath74 is a smooth _ sample _ path of an @xmath6-valued ( potentially non - stationary or degenerate ) diffusion process , * @xmath75 is a smooth _ sample _ path of a stationary ( potentially degenerate ) diffusion process taking values in @xmath76 .",
    "note that it is implicitly assumed that @xmath77 , and additionally , we also assume that for each @xmath78 and @xmath79 , the @xmath80-th moment @xmath81 of the @xmath52-th coordinate of @xmath67 is finite , i.e. , @xmath82 .    in this paper ,",
    "we take @xmath83 and @xmath75 as exogenous modeling elements .",
    "however , for an example of a model with yet further hierarchical structure , one _ could _ take a cue from a continuous time version of the classic `` co - integration '' theory , e.g. , see @xcite .",
    "the idea is that the location @xmath84 of the @xmath3-th center is non - stationary , but the inter - point distance between a combination of the centers is stationary .",
    "more specifically , one _ could _ further assume that there exist @xmath85 matrix @xmath86 , @xmath87 matrix @xmath88 and @xmath89 matrix @xmath90 such that    * @xmath91 is the @xmath92 dimensional zero matrix , * @xmath93 is a @xmath94 dimensional brownian motion , * @xmath95 is a stationary diffusion process .",
    "thus , the position of centers are unpredictable , but the relative distance between each pair of centers are as predictable as that of a stationary process .",
    "@xmath96)$ ] and @xmath97 0.1 in @xmath98 @xmath99 @xmath100    0.3 , the lightly - colored outer histogram represents the latent position distribution @xmath67 for the full population , and the darkly - colored inner histogram represents the distribution of the latent positions of actors under _ consideration_. the illustrated temporal order is @xmath101 .",
    ", title=\"fig : \" ]    0.3 , the lightly - colored outer histogram represents the latent position distribution @xmath67 for the full population , and the darkly - colored inner histogram represents the distribution of the latent positions of actors under _ consideration_. the illustrated temporal order is @xmath101 .",
    ", title=\"fig : \" ]    0.3 , the lightly - colored outer histogram represents the latent position distribution @xmath67 for the full population , and the darkly - colored inner histogram represents the distribution of the latent positions of actors under _ consideration_. the illustrated temporal order is @xmath101 .",
    ", title=\"fig : \" ]    [ [ actor - position - process - level ] ] actor position process level + + + + + + + + + + + + + + + + + + + + + + + + + + + +    figure [ fig : subpop_historgrams ] sketches the connection between actors and populations .",
    "we first define a process for a single actor . to begin , for each @xmath16 , given @xmath67 and @xmath102 , we write @xmath103 where @xmath104 the formulation here for the @xmath105 and @xmath106 is based on a quadratic taylor - series approximation of a so - called `` bounded confidence '' model studied in @xcite . here",
    ", the value of @xmath107 represents the confidence level of actor @xmath12 on its current position and @xmath108 represents the visibility of other actors position by actor @xmath12 . roughly speaking , an actor with a _ small _ value of @xmath107 and a _ large _ value of @xmath108",
    "will be influenced _",
    "greatly _ by actors that are positioned _ both near and far _ in the latent space whereas an actor with a _",
    "large _ value of @xmath107 and a _ small _ value of @xmath108 will be influenced only a _ small _ amount by actors that are _ nearby _ in the latent space . for",
    "further discussion on our motivation for the form of @xmath109 , see appendix [ appendix : motivationfora ] .    for each actor @xmath12 , the deterministic path @xmath110",
    "is assumed to be continuous , taking values in a compact subset of @xmath111 .",
    "it is assumed that given @xmath112 , each actor s latent position process @xmath113)$ ] is a diffusion process whose generator is @xmath109 , and moreover we assume that @xmath114 are mutually independent .",
    "for each @xmath16 , let @xmath115 where each @xmath116 is assumed to be a column vector , i.e. , a @xmath117 matrix . in other words , the @xmath12-th row of @xmath118 is the transpose of @xmath116 .",
    "@xmath97 , @xmath119)$ ] , and @xmath120)$ ] 0.1 in compute @xmath121 and @xmath122 compute the non - negative definite symmetric square root @xmath123 of @xmath124 @xmath98 @xmath125 standardnormalvector @xmath126 @xmath100    [ [ messaging - process - level ] ] messaging process level + + + + + + + + + + + + + + + + + + + + + + +    denote by @xmath127 the number of messages sent _ from _ actor @xmath12 _ to _",
    "actor @xmath13 . also , denote by @xmath128 the number of messages exchanged _ between _ actor @xmath12 _ and _ actor @xmath13 .",
    "note that @xmath129 .",
    "for each actor @xmath12 , we assume that the path @xmath130 is deterministic , continuous and takes values in @xmath76 . for each @xmath16 , we assume that @xmath131      & =       ( \\lambda_{t , i } \\lambda_{t , j}/2 ) p_{t , i\\rightarrow j}(\\bm x_{t})dt + o(dt).\\end{aligned}\\ ] ] for our algorithm development and experiment @xmath132 in section [ sec : numericalexperiments ] , we take @xmath133,\\end{aligned}\\ ] ] but for experiment @xmath134 in section [ sec : numericalexperiments ]",
    ", we take @xmath135 . next , by way of assumption , for each pair , say , actor @xmath12 and actor @xmath13 , we eliminate the possibility that both actor @xmath12 and actor @xmath13 send messages concurrently to each other .",
    "more specifically , we assume that @xmath136 \\\\      & =       ( \\lambda_i(t ) \\lambda_j(t)/2 )      ( p_{t , i\\rightarrow j}(x_{t , i } ) + p_{t , j \\rightarrow i}(x_{t , j } ) ) dt       + o(dt).\\end{aligned}\\ ] ] for future reference , we let @xmath137    @xmath138 , @xmath139 and @xmath140 0.1 in @xmath141 @xmath142 @xmath143 \\leftarrow ( t , i , j)$ ]",
    "@xmath144 @xmath145 @xmath100    0.3    0.3    0.3",
    "we denote by @xmath146 the conditional distribution of @xmath147 given @xmath22 , i.e. , for each @xmath148 , @xmath149.\\end{aligned}\\ ] ] for the rest of this paper , we shall assume that the ( random ) measure @xmath150 is absolutely continuous with respect to lebesgue measure with its density denoted by @xmath151 .",
    "that is , @xmath152 for @xmath153 .",
    "denote by @xmath154 the @xmath12-th marginal posterior distribution of @xmath146 , i.e. , for each @xmath155 , @xmath156 $ ] , and let @xmath157 denote its density .",
    "in theorem [ thm : exactposterior ] , the _ exact _ formula for updating the posterior is presented , and in theorem [ thm : simplifyingposteriorupdaterule ] , our _ working _ formula used in our numerical experiments is given .",
    "we develop our theory for the case where @xmath158 and @xmath159 are the same for all actors for simplicity , as generalization to the case of each actor having different values for @xmath107 and @xmath108 is straightforward but requires some additional notational complexity .",
    "[ thm : exactposterior ] for each @xmath160 and @xmath161 , @xmath162 where @xmath163 is an @xmath164 matrix such that for each @xmath165 , @xmath166 and for each @xmath167 , @xmath168 , and @xmath169 is an @xmath164 matrix such that for each pair @xmath170 , @xmath171 and for each pair @xmath167 , @xmath172 .",
    "hereafter , for developing algorithms further for efficient computations , we make the assumption that for each @xmath16 , @xmath173 where @xmath174 denotes the joint density for actors @xmath12 , @xmath13 and @xmath52 .",
    "[ thm : simplifyingposteriorupdaterule ] for each function @xmath175 , we have @xmath176    replacing @xmath177 with a dirac delta generalized function , theorem [ thm : simplifyingposteriorupdaterule ] states that for each @xmath178 , @xmath179 where @xmath180 denotes the formal adjoint operator of @xmath181 . for use only within algorithm [ algo : estimateactorposterior ] ,",
    "@xmath182    @xmath138 , @xmath139 , @xmath67 and @xmath183 , 1 \\le u_\\ell < v_\\ell   \\le n\\}$ ] 0.1 in compute @xmath184 from @xmath185 using @xmath186 @xmath187 @xmath188 @xmath189 @xmath190 @xmath191 update @xmath184 using @xmath192 and @xmath186 in update @xmath193 using @xmath192 and @xmath194 in @xmath145      the projection filter is an algorithm which provides an approximation to the conditional distribution of the latent process in a systematic way , the method being based on the differential geometric approach to statistics , cf .",
    "@xcite . when the space on which we project is a mixture family , as in @xcite , the projection filter is equivalent to an approximate filtering via the galerkin method , cf .",
    "following this idea , starting from theorem [ thm : simplifyingposteriorupdaterule ] , we obtain below in theorem [ thm : projfilterzakai ] the basic formula for our approximate filtering algorithm .    to be more specific ,",
    "consider a set of probability density functions @xmath195 .",
    "then , let @xmath196 be the space of all probability density functions that can be written as a probability - weighted sum of @xmath197 .",
    "that is , @xmath198 if and only if @xmath199 for some probability vector @xmath200 on indices @xmath201 . in particular , for deriving our algorithms , we will assume that for some systematic choice of @xmath202 , each probability density under consideration is a member of @xmath203 .    among many possible choices for @xmath204 in theorem [ thm : projfilterzakai ]",
    "are a multivariate haar wavelet basis and a multivariate daubechies basis . on the other hand , a gaussian mixture model is pervasively used throughout statistical inference tasks such as clustering and classification in algorithms such as @xmath52-means clustering . as such",
    ", we develop our algorithms with an eye towards use with other gaussian mixture model - based algorithms . in appendix",
    "[ appendix : mixtureprojectionformula ] , we further develop our algorithm under the assumption that @xmath205 where @xmath73 is the standard gaussian density function defined on @xmath206 , @xmath207 , and the finite sequence @xmath208 is to be chosen judiciously prior to implementing the algorithm .",
    "preparing for our next result in theorem [ thm : projfilterzakai ] , we let @xmath209 be the symmetric matrix such that @xmath210 , and for each @xmath52 , let @xmath211 be the symmetric matrix such that its @xmath45-entry @xmath212 is @xmath213 . collectively , we denote by @xmath214 the three - way tensor whose @xmath215 entry is @xmath212 .",
    "let @xmath216 be the matrix such that its @xmath45-entry @xmath217 is @xmath218 , where @xmath219 is the differential operator such that @xmath220 with @xmath221    [ thm : projfilterzakai ] suppose that for each @xmath16 , @xmath12 and @xmath26 , @xmath222 .",
    "let @xmath223 denote the column vector whose @xmath52-th entry is @xmath224 .",
    "then , @xmath225        in our application , our final analysis is completed by clustering the posterior distributions . instead of working directly with posteriors , an infinite - dimensional object , we propose to work with objects in an euclidean space each of which represents a particular actor .",
    "however , given @xmath185 and @xmath226 , using their mean vectors or their kl distance for clustering can be uninformative . for example , if @xmath227 , then their mean vectors would be the same and their kl distance would be zero .",
    "however , if @xmath227 is the density of , say , a normal random vector such that its mean is zero and its covariance matrix is @xmath228 for a large value of @xmath229 , then concluding that actor @xmath12 and actor @xmath13 are similar could be misleading .    to alleviate such situations in a clustering step of our numerical experiments , we propose using a multivariate statistical technique called classical multidimensional scaling ( cmds ) to obtain a lower dimensional representation of @xmath230 . more specifically",
    ", we achieve this by representing each actor as a point in @xmath6 , where the configuration is obtained by solving the optimization problem @xmath231 where @xmath232 denotes a strictly decreasing function defined on @xmath233 taking values in @xmath234 . for example",
    ", one can take @xmath235 where @xmath236 is chosen so that @xmath237 $ ] for all possible values @xmath238 of @xmath239 .",
    "another possibility among many others is to choose @xmath240 if @xmath241 is chosen so that @xmath242 $ ] for all possible values @xmath238 of @xmath243 .",
    "we denote by @xmath244 the set of solutions to the optimization problem . given a vector @xmath245 of @xmath56 probability densities on @xmath6 , it can be shown that the solution set @xmath244 is not empty and is closed under orthogonal transformations .    in the classical embedding literature , ensuring continuous embeddings is neglected as it is not relevant to their applications . however , for our work",
    ", this is crucial as we study their evolution through time , i.e. , ideally , we would like to see that a small change in time corresponds to a small change in latent location . in this section , we propose an extension to the cmds algorithm to remedy the aforementioned non - uniqueness issue , and show that the resulting algorithm ensures continuity of embeddings .    in our numerical experiments",
    ", for each @xmath245 , we choose a particular element @xmath246 of the solution set @xmath244 so that @xmath246 depends on @xmath245 in a consistent manner .    a matrix @xmath247 with full column rank and a symmetric matrix @xmath248 such that @xmath249 @xmath250 @xmath251 any @xmath252 classical mds solution of @xmath53 compute a singular value decomposition @xmath253 of @xmath254 return @xmath255      by a dissimilarity matrix",
    ", we shall mean a real symmetric non - negative matrix whose diagonal entries are all zeros .",
    "first , fix @xmath21 such that @xmath256 .",
    "then , for each @xmath164 dissimilarity matrix @xmath53 , define @xmath257 where @xmath258 .",
    "the elements of @xmath259 are known as _ classical multidimensional scalings _ , and as discussed in @xcite , it is well known that @xmath259 is not empty provided that the rank of @xmath260 is at least @xmath21 . our discussion in this section concerns making a selection @xmath261 from @xmath259 so that the map @xmath262 is continuous over the set of dissimilarity matrices such that @xmath260 is of rank at least @xmath21",
    ".    let @xmath53 be a dissimilarity matrix such that the rank of @xmath260 is at least @xmath21 .",
    "we begin by choosing an element of @xmath259 , say @xmath263 , through classical dimensional scaling .",
    "let @xmath264 be the eigenvalue decomposition of @xmath263 , where @xmath265 and @xmath266 is the diagonal matrix whose entries are the eigenvalues in non - increasing order . by the rank condition , we have @xmath267 .",
    "first , we formally write @xmath268 where    ( i ) : :    @xmath269 is the @xmath270 matrix with its    @xmath271 entry @xmath272 , ( ii ) : :    @xmath273 is the @xmath43 diagonal matrix    whose @xmath12-th diagonal entry is @xmath274 .",
    "dependence of @xmath275 on @xmath53 will be suppressed in our notation unless needed for clarity .",
    "now , if the diagonals of @xmath273 are distinct , then @xmath275 is well defined . however , in general , due to potential geometric multiplicity of an eigenvalue , our definition of @xmath275 can be ambiguous .",
    "this is the main challenge in making a continuous selection and we resolve this issue in our following discussion .",
    "for our remaining discussion , without loss of generality , we may assume that for each dissimilarity matrix @xmath53 , @xmath275 is well - defined by making an arbitrary choice if there is more than one cmds solution .",
    "note that the mapping @xmath276 may not be a continuous selection .",
    "we now remedy this .",
    "first , fix an @xmath270 matrix @xmath277 and let @xmath278 where @xmath279 runs over all @xmath43 real orthogonal matrices . then , define @xmath280    algorithm [ algo : cmdscc ] yields the solution @xmath261 and the proof of the following theorem , theorem [ thmstat : continuousembedding ] , can be found in appendix [ thmstat : contembedding : proof ] .",
    "[ thmstat : continuousembedding ] suppose that the @xmath270 matrix @xmath277 is of full column rank .",
    "then , the mapping @xmath281 yields a well - defined continuous function on the space of dissimilarity matrices such that @xmath260 is of rank at least @xmath21 .    , @xmath282 , and @xmath283 ) or exogenous modeling element @xmath284 .",
    "the arrows are associated with _ influence _ relationships , e.g ,",
    "@xmath285 reads @xmath67 influences @xmath286 . ]      here we discuss some insightful facts related to our model given the assumption stated in the last section .",
    "first , we have the following :    [ thm : elliptic ] fix @xmath287 and suppose that @xmath288 for a.e .  @xmath289 .",
    "the operator @xmath109 is elliptic , i.e. , for each @xmath290 , the matrix @xmath291 is positive definite .",
    "note that for each @xmath292 , @xmath293 note that @xmath294 and @xmath295 for each @xmath296 , and that @xmath297 away from a subspace of @xmath6 whose lebesgue measure is zero .",
    "it follows that @xmath298 for each @xmath299 , whence @xmath300 is positive definite .",
    "now , we further examine algorithm [ algo : populationprocess ] , algorithm [ algo : latentprocess ] , algorithm [ algo : messagingactivities ] , algorithm [ algo : estimateactorposterior ] , algorithm [ algo : cmdscc ] , and discuss some technical points behinds these algorithms .    in algorithm [ algo : latentprocess ] , existence and uniqueness of @xmath301 follows from theorem [ thm : elliptic ] .",
    "the continuity of @xmath302 follows from theorem [ thm : elliptic ] and @xcite . in algorithm [ algo : messagingactivities ] , for simulating a sample path of @xmath303 , we use the so - called time - change property ; that is , we use the fact that the process given by @xmath304 is a unit - rate simple poisson process , where @xmath305 and @xmath306 and @xmath307 . for simulation",
    ", we use its dual result , i.e. , @xmath308 is a point process whose intensity process is @xmath309 , where @xmath310 is a path of a unit - rate simple poisson process .",
    "also , we note that for computation of @xmath309 , online inference is a necessary part of our simulation in algorithm [ algo : messagingactivities ] ; that is , we need to compute @xmath311.$ ] in algorithm [ algo : messagingactivities ] and algorithm [ algo : estimateactorposterior ] , _ near - infinitesimally - small _ means @xmath97 so small that the likelihood of having more than one event during a time interval of length @xmath97 is practically negligible .",
    "also , by standardnormalvector in algorithm [ algo : latentprocess ] and unitexponentialvariable in algorithm [ algo : messagingactivities ] , we mean generating , respectively , a single normal random vector with its mean vector being zero and its covariance matrix being the identity matrix , and a single exponential random variable whose mean is one .",
    "in our experiments , we hope to detect clusters with accuracy and speed similar to that possible if the latent positions @xmath312 were actually observed even though we use only information in @xmath313 estimated from information contained in @xmath22 .",
    "we denote the end - time for our simulation as @xmath314 .",
    "there are two simulation experiments presented in this section , and the computing environment used in each experiment is reported at the end of this section .",
    "[ [ experiment-1 ] ] experiment 1 + + + + + + + + + + + +    we take @xmath315 and we assume that for each @xmath316 $ ] and actor @xmath317 , @xmath318 and @xmath319 . for the population process we take for each @xmath316 $ ] @xmath320 where @xmath321 .",
    "\\end{cases } \\end{aligned}\\ ] ] then , we also consider @xmath322 , where @xmath323 .",
    "\\end{cases } \\end{aligned}\\ ] ]    there is only one population density ; in other words , @xmath324 .",
    "note that even with _",
    "one population center _ , we can have _ more than one empirical mode _ for the subpopulation .",
    "one of these modes is near zero , and another mode is near one .",
    "the reason for this is that because of the value of @xmath325 and @xmath326 , when an actor is too far away from the mode @xmath327 of the population process , the population process affects the actors on its _ tail _ only by negligibly small amount . in figure",
    "[ fig : experimentone - sixactorpath ] and figure [ fig : experimentone - perfect - filtering - case ] , a sample path of the true latent position of each of eight actors is illustrated in black lines .",
    "it is apparent that in the @xmath328 , all eight actors are equally _ informed _ of the population mode shift , but in the @xmath329 case , only the last three were able to adapt to the change , and the first five actors are surprised by the abrupt change at time @xmath330 .",
    "our simulation is discretized .",
    "our unit time is @xmath331 , and in figure [ fig : experimentone - sixactorpath ] , each tick in the horizontal axis corresponds to an integral multiple of @xmath97 .",
    "the jump term in our update formula is quite sensitive to the number of actors being considered . as such , for updating the jump term , we further discretized @xmath97 into @xmath332 subintervals for numerical stability of our update iterations . for @xmath333 , each unit interval",
    "is associated with @xmath334 sub - iterations , and the total number of the ( main ) iteration is @xmath335 , and we use @xmath336 instead of @xmath337 in each @xmath3-th subiteration of each main iteration staring at time @xmath16 .    to implement our mixture projection algorithm ,",
    "we take @xmath338 .",
    "the initial position of the @xmath333 actors are sampled from the initial population distribution @xmath339 .",
    "we take @xmath340 .",
    "the discretized version @xmath341 of @xmath109 is illustrated in figure [ fig : levelplot(at)example ] .",
    "for inference during our experiment , we have dropped the second order term and used only the first order term to keep the cost of running our experiment low . on the other hand , for simulating the actors latent positions , we have used both the first and second order term of @xmath109 .",
    "the value of @xmath342 gives the first part of the change in @xmath343 .",
    "note that in both figure [ fig : levelplot(at)one ] and figure [ fig : levelplot(at)zero ] , the entries that are _ sufficiently far off _ from the diagonals are near zero .    for @xmath344",
    ", the time plot of the number of messages produced during interval @xmath345 $ ] is given in figure [ fig : experimentone - num - msg ] , and shows transient behaviors of varying degrees of messaging intensity over the interval .",
    "our set up for @xmath346 produced a simulation sample output of observing @xmath347 messages amongst the @xmath333 actors in unit time once the population center changed _ abruptly _ from @xmath348 to @xmath349 at the start of the @xmath350-th unit time interval , i.e. , @xmath351 .",
    "in other words , after @xmath352 , a single unit time is roughly associated with the amount of time during which the whole subpopulation of eight actors exchanges around @xmath353 messages , or equivalently , during which each pair of actors exchange around @xmath354 messages . on the other hand , in both @xmath328 and @xmath329 for the interval @xmath355=[0,5]$ ] , the subpopulation messaging rate is relatively constant at the rate of @xmath350 messages over each unit interval , and this is expected as all eight actors are tightly situated around @xmath132 .    0.45   for the discretized version @xmath341 of @xmath109 , used in the simulation experiment for two particular cases , where the horizontal axis is associated with the rows of @xmath356 and the vertical axis is associated with the columns of @xmath356.,title=\"fig : \" ]    0.45   for the discretized version @xmath341 of @xmath109 , used in the simulation experiment for two particular cases , where the horizontal axis is associated with the rows of @xmath356 and the vertical axis is associated with the columns of @xmath356.,title=\"fig : \" ]     case .",
    "the number of messages per @xmath97 across the time interval @xmath357 $ ] for the subpopulation of actors @xmath358 . ]     case .",
    "the _ sample _",
    "path of the true and estimated latent position of each of eight actors used for experiment 1 in a black solid line and in a dashed red line , respectively . ]",
    "the _ sample _",
    "path of the true and estimated latent position of each of eight actors used for experiment 1 respectively in a black solid line and in a dashed red line . ]",
    "our experiments for @xmath328 and @xmath329 both show that the filtered positions for all eight actors are close to the exact positions .",
    "+    [ [ experiment-2 ] ] experiment 2 + + + + + + + + + + + +    in this experiment , for each @xmath16 , we have used the empirical distribution of @xmath359 to obtain an estimate @xmath360 of @xmath67 by partitioning the latent space into sufficiently small intervals , where we place a uniform kernel of height equal to the proportion of @xmath361 that lies in that interval .",
    "our inference is on @xmath362 .",
    "recall that @xmath56 denotes the size of the subpopulation .",
    "the number @xmath363 is the size of the _ full _ population .",
    "this set - up is closer to the motivation for our work , the bounded confidence model , @xcite , and the connection with our model in this paper is made in appendix [ appendix : motivationfora ] . in theory , the general setup in experiment 1 is comparable to the setup in experiment 2 when @xmath364 in experiment 2 is taken to be @xmath365 .",
    "we set @xmath366 , @xmath367 , @xmath368 , and @xmath369 .",
    "we take the clustering based on @xmath370 as the _ ground truth_. note that @xmath371 here is comparable to @xmath108 in experiment 1 , or more generally , in our model .",
    "we set up the simulation to observe roughly 3000 messages amongst the @xmath56 actors in unit time .",
    "this translates to @xmath372 per actor per unit time .",
    "note that this is a rough estimate as the messaging intensity is time - dependent and stochastic . in figure",
    "[ fig : mdsvsexact ] , we have snapshots of @xmath373 and those of @xmath374 for a single simulation run .",
    "denote as the latency @xmath375 where the dependency on our choice for a clustering algorithm is suppressed in our notation and for some @xmath376 , @xmath377 :   \\operatorname*{mari}(\\kappa({\\bm x}_s ) , \\kappa({\\bm x}_t ) ) \\ge       1-\\varepsilon , \\text { for a.e.~ } s \\in [ t , t]\\},\\\\      & \\widehat{\\zeta } \\equiv \\inf\\ { t \\in [ 0,t ] : \\operatorname*{mari}(\\kappa(\\psi^*(\\mathbf p_s ) ) ,      \\kappa({\\bm x}_t ) ) \\ge 1-\\varepsilon , \\text { for a.e.~ } s \\in [ t , t]\\},\\end{aligned}\\ ] ] where @xmath378 denotes a moving average of the adjusted rand index ( c.f .",
    "@xcite and @xcite ) and we fix @xmath379 to be a @xmath52-means clustering algorithm for concreteness .",
    "we use the latency as a performance measure for a clustering algorithm @xmath379 under our framework . for our projection",
    ", we use a haar basis , i.e. , a set of simple step functions , where the width of the intervals used in the experiment is @xmath380 . also , unlike in experiment 1 , we take @xmath381 these changes require us to modify our algorithm slightly . however , the necessary modifications are straightforward , and we leave the details to the reader .",
    "it is important to note that we do not assume knowledge of the latent position of any individual , @xmath382 ; instead , we use only our knowledge of the overall population . as the number @xmath364 gets larger , as shown in @xcite , the dependence among @xmath383 diminishes , agreeing more closely with the model we specified in our framework .",
    "we investigate the behavior of our algorithm for small , medium and large values of @xmath364 , showing robustness of our framework in the face of limited information .",
    "recall that figure [ fig : mdsvsexact ] shows results for @xmath366 . figure [ fig : latency ] compares the latency for @xmath384 and @xmath366 .",
    "the clarity and accuracy of the clustering suffers with significant reductions in information used to estimate the priors @xmath67 .    in figure",
    "[ fig : mdsvsexact ] , we present snapshots of @xmath385 and @xmath386 for a single simulation run .",
    "note that @xmath387 is a cmds embedding of a dissimilarity matrix based on the posteriors @xmath388 .",
    "the colors denote the final cluster membership as determined from @xmath52-means clustering with @xmath389 .",
    "it is clear that the emerging cluster structure of the @xmath387 lags slightly behind that of @xmath118 in both accuracy and clarity ; comparing the middle two figures , we can see that there are a few data points misclassified at time @xmath65 . indeed ,",
    "figure [ fig : ari_ma ] shows that the clustering based on the embedded positions mirrors that possible with the true but unobserved latent positions with a small latency .",
    "+    [ [ computing - environment ] ] computing environment + + + + + + + + + + + + + + + + + + + + +    for experiment 1 , we used r 2.14.1 ( 64 bit ) under ubuntu 12.0.4 on an intel core i7 cpu 870 @ 2.93 ghz @xmath390 8 machine with 16 gb ram .",
    "for a single run for @xmath391 , @xmath392 and @xmath393 actors , our experiment took @xmath394 , @xmath395 and @xmath396 seconds respectively .",
    "for experiment 2 , we used a red hat linux cluster with 24 nodes with 24 @xmath390 2.5 mhz cpus and 132 gb memory each .",
    "each monte carlo replicate took a single slot .",
    "a single replicate took approximately 3000 seconds .    ) distribution for @xmath397 monte carlo experiments .",
    "the translucent grey histogram is based on @xmath384 , and the cross - hatch shaded histogram is based on @xmath366 .",
    "the latency is defined as the difference between the time @xmath398 at which the moving average of the predictive ari maintained a level of @xmath399 for all @xmath400 and the time @xmath401 at which true locations moving average of the ari maintained a level of @xmath399 for all @xmath402 .",
    "the latency can be negative , but is generally small and positive .",
    ", scaledwidth=70.0% ]    -means clusterings of the embedded @xmath403 and @xmath312 against the @xmath52-means clustering of @xmath389 .",
    "note that @xmath65 ( cf .",
    "figure  [ fig : mdsvsexact ] ) and @xmath404 are nearly identical . , scaledwidth=70.0% ]     versus @xmath405 at times @xmath406 .",
    "the size of the population used to estimate the prior was @xmath407 .",
    "the first row shows the cmds embedded positions ( @xmath408 ) , and the second row shows the latent positions . due to our cmds embedding procedure ( with rotation ) , the 1-dimensional embedding is the first coordinate of a 2-dimensional embedding .",
    "we show a 2-dimensional embedding for illustration purposes .",
    ", scaledwidth=70.0% ]",
    "we have described a strategy for clustering actors based on messaging activities .",
    "our analysis is completed by clustering a cmds embedding of posteriors .",
    "we have presented ways to simplify posterior analysis on two levels .",
    "the first level allows us to obtain an estimate of the posteriors in an online manner .",
    "the second level allows us to reduce our analysis to studying diffusion processes , which is often a starting point for addressing the optimal stopping problem .",
    "we have illustrated in our numerical experiments that the assumptions used to derive our two simplified approaches are mild enough to be useful for our inference task at hand , i.e. , clustering .",
    "we believe that our framework has potential for tackling the problems faced by the social network practitioner regarding emergence of structure .",
    "we intend to develop a measure of confidence for our inferred latent positions",
    ". this will be crucial to many applications , as it will provide the decision - maker with information about whether to act or to wait for more data to increase the confidence in the inferred positions",
    ". a measure of confidence would therefore be a way to establish a stopping rule .",
    "noting that we took the parameters of our model to be exogenous , we will need to explore robustness of our inference to incorrect parameter choices and then make explicit an algorithm for parameter estimation . making our algorithm",
    "more scalable is also an area of our interest .",
    "these areas of future work will be key to applying our framework on substantial problems .",
    "this work is partially supported by a national security science and engineering faculty fellowship ( nsseff ) , by the acheson j. duncan fund for the advancement of research in statistics , and by the johns hopkins university human language technology center of excellence ( jhu hlt coe ) .",
    "we also thank dr .",
    "youngser park for his technical assistance .",
    "our work in this paper is in part influenced by a so - called bounded confidence model in @xcite which focuses on establishing a propagation of chaos property of the interacting particles model studied there . when denoting the actors latent positions @xmath409 $ ] , in the bounded confidence model , the _ opportunities _ for ( latent ) position changes that each actor experiences is modeled as a simple poisson process .",
    "when there is a change at time @xmath16 , the change is assumed to involve precisely two actors , say , actor @xmath12 and actor @xmath13 , such that their position @xmath410 and @xmath411 differs by at most @xmath371 .",
    "this yields an inhomogeneity in the rate at which actors change their locations .",
    "then , the exact amount of change is specified by the following formula : @xmath412 where @xmath413 is a fixed constant . roughly speaking , upon interaction , actor @xmath12 keeps @xmath414 percent of its original position , and",
    "is allowed to be influenced by @xmath415 percent of the original position of actor @xmath13 , and vice versa .",
    "fix constants @xmath416 and @xmath417",
    ". then , define @xmath418 by letting for each @xmath419 and @xmath177 , @xmath420    studied in @xcite particularly is the interaction between @xmath67 and @xmath421 where @xmath67 is the empirical distribution of @xmath422 .",
    "as shown in @xcite , the bounded confidence model has an appealing feature that the parameter space for the underlying parameters @xmath423 and @xmath371 can be partitioned according to the type of consensus that the population eventually reaches , namely , a total consensus and a partial consensus . in a total consensus regime , for sufficiently large @xmath16",
    ", everyone is expected to gather tightly around some fixed common point @xmath424 $ ] . on the other hand , in a partial consensus regime , ( depending on @xmath423 and @xmath371 ) , there is a finite collection of distinct values in @xmath425 $ ] separated by at least @xmath371 , to exactly one of which each actor s position is attracted . in particular , the ( asymptotic ) position of actors yields a partition of the actor set when the exact locations of @xmath426 are known .",
    "generally , @xmath427)$ ] is contracting toward for some closed convex non - empty disjoint subsets @xmath428 and @xmath429 of @xmath425 $ ] in the sense that for some @xmath316 $ ] , @xmath430 for each @xmath431 and @xmath432 ) = 1 $ ] .    in our adaptation , for analytic tractability , we replace the indicator function @xmath433 with @xmath434 , take @xmath67 to be an exogenous modeling element , and take @xmath435 to be potentially time dependent , yielding the operator @xmath436    the second numerical experiment in section [ sec : numericalexperiments ] focuses on the case where the community starts with no apparent clustering but as time passes , each actor becomes a member of exactly one of clusters , where each cluster is uniquely identified by a closed convex subset of the latent space @xmath6 .",
    "in this work , we use a model that that captures the action in up to the second order . to begin , note that @xmath437 where @xmath438 and @xmath439 denote respectively the gradient and the hessian of @xmath177 at @xmath26 , and h.o.t .",
    "denotes the higher order terms .",
    "suppose that @xmath67 is given .",
    "now , we have @xmath440 where @xmath441 and @xmath442 are given by the following : @xmath443 dropping the term associated with h.o.t . , we obtain the following : @xmath444",
    "for each @xmath445 , we see that @xmath446 we first consider the second term of the right side of .",
    "@xmath447 now , we have that @xmath448 and that @xmath449 hence , @xmath450    next , for the first term of the right side of , we have @xmath451 in summary , for each @xmath452 , we have @xmath453 and our claim follows from this .",
    "this section contains two formulas to be used in the next section .",
    "our result and proof in lemma [ lem : product - density - formula ] is stated in the same notation as in lemma [ lem : algebra - formula ] .",
    "recall that @xmath454 .",
    "[ lem : algebra - formula ] let @xmath455 and @xmath456 .",
    "then , @xmath457 where @xmath458 is the gram matrix for @xmath459 and @xmath460 is the matrix whose @xmath45-entry is @xmath461 .",
    "let @xmath462 and for each @xmath3 , let @xmath463 .",
    "first , note that @xmath464 now , @xmath465 our claim follows from this .",
    "[ lem : product - density - formula ] let @xmath73 be the standard multivariate normal density defined on @xmath6 . also , fix a sequence @xmath466 , and a sequence @xmath467 . @xmath468    using lemma [ lem : algebra - formula ] , we see that @xmath469      here , we assume , as done in theorem [ thm : projfilterzakai ] , that @xmath470 and @xmath471 , where for simplicity , we have written @xmath472 . in this section ,",
    "we fix @xmath73 to be the standard multivariate normal density defined on @xmath6 and recall that @xmath473 . also , we fix @xmath207 , and a sequence @xmath474 .    [",
    "lem : micro - b - a ] fix @xmath475 , @xmath289 and @xmath207 .",
    "for each @xmath52 , @xmath476    let @xmath477 where to simplify the expression of @xmath478 , we have used the fact that @xmath479 also , note that @xmath480 using lemma [ lem : product - density - formula ] with @xmath481 , @xmath482 and @xmath483 , we see that @xmath484 then , for our claim in , it is enough to see that @xmath485 next , we show our claim in . hereafter , to ease our notation , we write @xmath486 for @xmath478 .",
    "first , for @xmath487 , we have @xmath488 and hence , @xmath489 on the other hand , for @xmath490 , we have @xmath491 and so , we have @xmath492 our claim in follows .    for lemma [ lem : b ] and lemma [ lem : a ] , by @xmath493 , we denote the gram matrix for @xmath494 , and define @xmath495 to be as in lemma [ lem : algebra - formula ] for @xmath496 , @xmath497 , @xmath498 .",
    "let @xmath499 to simplify our notation , we let @xmath500 define and note @xmath501 also , denote by @xmath502 the multivariate normal density defined on @xmath6 such that its mean vector is @xmath503 and its covariance matrix is @xmath504 .",
    "for @xmath505 and @xmath506 , we write @xmath507 and note that in particular , @xmath508    starting from , it is easy to see that @xmath509 and as a matter of definition , we have @xmath510    lemma [ lem : b ] and lemma [ lem : a ] are associated , respectively , with the first and the second terms appearing in the right side of .",
    "[ lem : b ] for each @xmath511 and @xmath512 , we have @xmath513    to ease our notation , we first let @xmath514 it follows that @xmath515 we compute @xmath516 instead of directly working with .",
    "first , we observe that @xmath517 and that @xmath518 using lemma [ lem : algebra - formula ] on the third equality , we see that @xmath519 continuing with the calculation , @xmath520 putting together , , and , and plugging in the full expression for @xmath521 , we see that @xmath522 our claim follows after summing over @xmath52 and replacing @xmath523 with its full expression .",
    "[ lem : a ] for each @xmath524 , @xmath16 and @xmath12 , @xmath525    note that @xmath526 where @xmath527 we first compute the diagonal terms , i.e. , the @xmath490 cases .",
    "note that @xmath528 and also that @xmath529    next , we compute the off - diagonal terms , i.e. , the @xmath487 cases . first , using our calculation just above , we see that we note that @xmath530 our claim follows from this after combining them together , and simplifying the combined term into a matrix notation .",
    "here , we will take the convention that @xmath531 is organized as a matrix . by the @xmath12-th row of @xmath118 , we mean @xmath532 .",
    "let @xmath533 = \\int { \\rho}_t(d\\bm x ) e^{\\imath \\langle \\bm v , \\bm x \\rangle},\\end{aligned}\\ ] ] where for each @xmath534 and @xmath535 , @xmath536 in other words , @xmath537 is the ( random ) conditional characteristic function of @xmath118 .",
    "note @xmath538 also , let , for each @xmath534 and @xmath539 , @xmath540.\\end{aligned}\\ ] ] for each @xmath541 , @xmath542 denotes the function obtained by fixing all other indices different from the @xmath12-th actor indices but letting the @xmath12-th actor indices to be free , and if @xmath542 is in the domain of the operator @xmath543 , with some abuse of notation , we write : @xmath544 similarly , for each @xmath545 , let @xmath546.\\end{aligned}\\ ] ] in other words , @xmath547 denotes the conditional characteristic function of the @xmath12-th row @xmath548 of @xmath312 , and also , let , for @xmath549 , and @xmath550 , @xmath551.\\end{aligned}\\ ] ] note that the definition of @xmath552 is actually independent of a particular choice of vertex @xmath12 as they are all identically distributed .",
    "one can prove the next result by directly following @xcite , but one needs to adapt to the fact that the underlying process can now be a time - inhomogeneous non - linear markov process .",
    "the proof details are left to the reader . for a survey of similar techniques , see also @xcite and @xcite .",
    "[ prop : donaldsnyder ] for each @xmath553 and @xmath161 , @xmath554    our proof of theorem [ thm : exactposterior ] is by brute force calculation , starting from proposition [ prop : donaldsnyder ] .",
    "in particular , our claim in theorem [ thm : exactposterior ] follows from proposition [ prop : donaldsnyder ] by directly applying lemma [ lemmaaa ] , lemma [ lemmaab ] and lemma [ lemmaac ] which we list and prove now .",
    "[ lemmaaa ] for each @xmath555 , @xmath556    fix @xmath16 , @xmath12 , @xmath229 and @xmath26 .",
    "then , for each @xmath557 , we have : @xmath558      =      1 +       \\int_{0}^{\\varepsilon}\\mathbb{e}\\left[\\mathcal{a}\\left(\\mu_{t+s}\\right)e^{\\imath      \\langle v , \\cdot - x\\rangle}\\left(x_{t+s , i}\\right)\\left|x_{t , i}=x\\right.\\right]ds.\\end{aligned}\\ ] ] we have @xmath559 and hence , @xmath560",
    "\\right|       \\le 1.\\end{aligned}\\ ] ] it follows that @xmath561      ds \\\\      = & \\",
    "\\mathbb{e}\\left[\\mathcal{a}\\left(\\mu_{t}\\right )      e^{\\imath \\langle v , \\cdot - x\\rangle}(x_{t } )      \\left|x_{t}=x\\right .      \\right]\\\\      = & \\",
    "\\mathcal{a}\\left(\\mu_{t}\\right )      e^{\\imath \\langle v , \\cdot - x\\rangle}(x).\\end{aligned}\\ ] ]    [ lemmaab ] for each @xmath562 , we have : @xmath563    fix @xmath564 and note : @xmath565 and that @xmath566      d\\bm v\\\\      & =       \\frac{1}{2\\pi }      \\int      \\lim_{\\varepsilon\\rightarrow0 }       \\frac{1}{\\varepsilon }      \\mathbb{e}\\left[e^{\\imath \\langle \\bm v , \\bm x_{t+\\varepsilon } - \\bm y\\rangle}-      e^{\\imath \\langle \\bm v , \\bm z -\\bm y \\rangle }      \\left|\\bm x_t = \\bm z\\right .",
    "\\right ]      d\\bm v.\\end{aligned}\\ ] ] treating @xmath567 as a generalized function ( i.e.  a tempered distribution ) , we have : @xmath568      d\\bm v      \\right )      d\\bm y      \\right)\\\\      & =      \\int          \\rho_t(d\\bm z )       \\lim_{\\varepsilon\\rightarrow0 }       \\frac{1}{\\varepsilon }      \\left (      \\mathbb{e}\\left [      \\int f(\\bm y )      \\left (      \\frac{1}{2\\pi }      \\int      e^{\\imath \\langle \\bm v , \\bm x_{t+\\varepsilon } - \\bm y\\rangle }      d\\bm v      \\right )      d\\bm y      \\left|\\bm x_t = \\bm z\\right .",
    "\\right ]      -      \\int f(\\bm y )      \\left (      \\frac{1}{2\\pi }      \\int      e^{\\imath \\langle \\bm v , \\bm z -\\bm y \\rangle }      d\\bm v      \\right )      d\\bm y      \\right)\\\\      & =      \\int          \\rho_t(d\\bm z )       \\lim_{\\varepsilon\\rightarrow0 }       \\frac{1}{\\varepsilon }      \\left (      \\mathbb{e}\\left [      \\int f(\\bm y )      \\delta_0(\\bm x_{t+\\varepsilon } - \\bm y )      d\\bm y      \\left|\\bm x_t = \\bm z\\right .",
    "\\right ]      -      \\left (      \\int f(\\bm y )      \\delta_0(\\bm z -\\bm y )      d\\bm y      \\right )      \\right)\\\\      & =      \\int          \\rho_t(d\\bm z )       \\lim_{\\varepsilon\\rightarrow0 }       \\frac{1}{\\varepsilon }      \\left (      \\mathbb{e}\\left [      f(\\bm x_{t+\\varepsilon } )      \\left|\\bm x_t = \\bm z\\right .",
    "\\right ]      -      f(\\bm z )      \\right)\\\\      & =      \\int          \\rho_t(d\\bm z )       ( \\mathcal{a}\\left(\\mu_t\\right)f)(\\bm z).\\end{aligned}\\ ] ]    [ lemmaac ] for each @xmath562 , we have : @xmath569    note @xmath570     +",
    "recall that for each @xmath541 , @xmath542 denotes the function obtained by fixing all other indices different from the @xmath12-th actor indices but letting the @xmath12-th actor indices to be free .",
    "fix @xmath571 .",
    "let @xmath541 be such that @xmath572 for all @xmath573 .",
    "for each @xmath161 , @xmath574 then , the claimed formula follows from our assumption in .",
    "suppose that @xmath575 as @xmath576 and that for each @xmath577 , @xmath578 satisfies the rank condition , i.e. , @xmath579 is of rank at least @xmath21 .",
    "note that each @xmath580 is a non - empty compact subset of @xmath581 since @xmath582 for any real orthogonal matrix @xmath279 .",
    "in particular , for sufficiently small @xmath583 , we may assume that @xmath584 } \\| \\xi_d^*(m_\\varepsilon ) \\|_f^2",
    "< \\infty$ ] .",
    "it is enough to show that for each arbitrary convergent subsequence of @xmath585 , @xmath586 consider an arbitrary convergent subsequence of @xmath585 .",
    "we begin by observing some linear algebraic facts .",
    "first , any sequence of real orthogonal matrices has a convergent subsequence whose limit is also real orthogonal .",
    "next , since both @xmath587 and @xmath277 are of rank @xmath21 , there exists a unique real orthogonal @xmath43 matrix @xmath588 such that @xmath589 and in fact , @xmath590 where @xmath591 is a singular value decomposition of @xmath592 , and @xmath593 is the corresponding _ unique right factor _ in the polar decomposition of @xmath592 .",
    "note that this implies the well - definition part of our claim on @xmath594 .",
    "also , since @xmath575 , we have that @xmath595 for relevant linear algebra computation details for these facts , see ( * ? ? ?",
    "69 , pg .  370 , pg .",
    "412 , and pg .",
    "now , by taking a subsequence if necessary , we also have that for some @xmath270 matrix @xmath596 such that @xmath597 , @xmath598 .",
    "then , @xmath599 next , note that if @xmath600 has distinct diagonal elements , then we also have @xmath601 so that @xmath602 . on the other hand ,",
    "more generally , i.e. , even when there are some repeated diagonal elements , we can find a @xmath43 matrix @xmath603 such that @xmath604 . to see this , note that the @xmath12-th column of @xmath605 is also an eigenvector of @xmath606 for the eigenvalue @xmath607 , and @xmath608 , and",
    "hence it follows that for some @xmath43 real orthogonal matrix @xmath609 , we have @xmath610 .",
    "moreover , exploiting the block structure of @xmath600 owing to algebraic multiplicity of eigenvalues , we can in fact choose @xmath609 so that @xmath611 . then , @xmath612    now , we have @xmath613 where @xmath614 is a @xmath43 real orthogonal matrix and and implicitly the limit was taken along a further subsequence when necessary . moreover , @xmath615 in summary , we have : @xmath616 by definition of @xmath617 , along with the facts that ( i ) all of the convergent subsequences share the common limit , ( ii ) each subsequence has a convergent subsequence , and ( iii ) @xmath618 and @xmath277 have of full column rank @xmath21 , we have ."
  ],
  "abstract_text": [
    "<S> we model messaging activities as a hierarchical doubly stochastic point process with three main levels , and develop an iterative algorithm for inferring actors relative latent positions from a stream of messaging activity data . </S>",
    "<S> each of the message - exchanging actors is modeled as a process in a latent space . </S>",
    "<S> the actors latent positions are assumed to be influenced by the distribution of a much larger population over the latent space . </S>",
    "<S> each actor s movement in the latent space is modeled as being governed by two parameters that we call confidence and visibility , in addition to dependence on the population distribution . the messaging frequency between a pair of actors </S>",
    "<S> is assumed to be inversely proportional to the distance between their latent positions . </S>",
    "<S> our inference algorithm is based on a projection approach to an online filtering problem . </S>",
    "<S> the algorithm associates each actor with a probability density - valued process , and each probability density is assumed to be a mixture of basis functions . for efficient numerical experiments , we further develop our algorithm for the case where the basis functions are obtained by translating and scaling a standard gaussian density .    </S>",
    "<S> = 1    social network ; multiple doubly stochastic processes ; classification ; clustering    62m0 , 60g35 , 60g55 </S>"
  ]
}