{
  "article_text": [
    "recent research in a cross - disciplinary field between the information theory ( it ) and statistical mechanics ( sm ) revealed a great similarity between the low density parity check ( ldpc ) error correcting codes and systems of ising spins ( microscopic magnets ) which interact with each other over random graphs@xcite . on the basis of this similarity ,",
    "notions and methods developed in sm were employed to analyse ldpc codes , which successfully clarified _ typical _ properties of these excellent codes when the code length @xmath1 is sufficiently large@xcite .    in general , an ldpc code is defined by a parity check matrix @xmath2 which represents dependences between codeword bits and parity checks determined under certain constraints .",
    "this implies that the performance of ldpc codes , in particular , the probability of the _ block _ decoding error @xmath3 fluctuates depending on each realization of @xmath2 .",
    "therefore , the average of the decoding error probability over a given ensemble @xmath4 is frequently used for characterising the performance of ldpc code ensembles .",
    "detailed analysis in it literature showed that @xmath4 of naively constructed ldpc code ensembles is generally composed of two terms : the first term which depends _ exponentially _ on @xmath1 represents the average performance of _ typical _ codes , whereas the second component scales _ polynomially _ with respect to @xmath1 due to a polynomially small fraction of poor codes in the ensemble @xcite .",
    "this means that even if the noise level of the communication channel is sufficiently low such that typical codes exhibit exponentially small decoding error probabilities ( which is implicitly assumed throughout this paper ) , communication performance can still be very low exhibiting an @xmath5 decoding error probability with a polynomially small probability when codes are naively generated from the ensembles .",
    "as the typical behaviour has mainly been examined so far , the polynomial contribution from the atypical codes has not been sufficiently discussed in the sm approach .",
    "although this slow decay in the error probability would not be observed for most codes in the ensemble , examining the causes of low error correction ability of the atypical poor codes is doubtlessly important both theoretically , and practically for constructing more reliable ensembles .",
    "the purpose of this paper is to answer this demand from the side of sm .",
    "more specifically , we develop a scheme to directly assess the most dominant contribution of the poor codes in @xmath4 on the basis of specific kinds of graph configuration utilising _",
    "diagrammatic _ techniques .",
    "this significantly simplifies the evaluation procedure of @xmath4 compared to the existing method @xcite , and can be employed for a wider class of expurgated ensembles .",
    "moreover , it provides insights that leads to a _",
    "practical _ expurgation method that is also presented in this paper . finally , the validity of the evaluation scheme and the efficacy of the proposed expurgation technique are computationally confirmed .",
    "the paper is organised as follows :- in the next section [ sec : dis ] , we briefly review the general scenario of ldpc codes and introduce basic notions which are necessary for evaluating the error probability in the proceeding sections .",
    "-in section [ sec : rep ] , we introduce the various code ensembles we will work with , and different representations for a code construction .- in section [ sec : dia ] , we link the probability of having a code with low minimal distance to the polynomial error probability , and we calculate the polynomial error probability by diagrammatic techniques for various code ensembles . as we can explicitly link it to the occurrence of short loops , the distribution of occurrence of such loops is also determined .- in section [ sec : alg ] , we present a practical linear time ( in average ) algorithm to remove short loops from a code construction , thus reducing the polynomial error probability to an arbitrarily low value .",
    "this is backed up by numerical simulations .",
    "-finally , section [ sec : con ] is devoted to a summary .",
    "-technical details about the diagrammatic technique can be found in appendix [ sec : appa].-details about the link between the minimal distance and the polynomial error probability for various decoding schemes are presented in appendix [ sec : appb ] .",
    "we here concentrate on _ regular _ @xmath6 ldpc code ensembles which involve @xmath1 message bits and @xmath7 parity checks . given a specific code , each message bit",
    "is involved in @xmath8 parity checks , and each parity check involves @xmath9 message bits . in practice , this dependence is represented by a parity check matrix @xmath2 .",
    "an encoding scheme consists in the generation of a codeword @xmath10 from an information vector @xmath11 ( with @xmath12 ) via the linear operation @xmath13 ( mod 2 ) where @xmath14 is the generator matrix that satisfies the condition @xmath15 ( mod 2 ) .",
    "the code rate is then given by @xmath16 , and measures the information redundancy of the transmitted vector .",
    "upon transmission of the codeword @xmath17 via a noisy channel , taken here to be a binary symmetric channel ( bsc ) , the vector @xmath18 ( mod 2 ) is received , where @xmath19 is the true channel noise .",
    "the statistics of the bsc are fully determined by the flip rate @xmath20 $ ] : @xmath21 decoding is carried out by multiplying @xmath22 by @xmath2 to produce the syndrome vector @xmath23 ( since @xmath24 ) . in order to reconstruct the original message @xmath25",
    ", one has to obtain an estimate @xmath26 for the true noise @xmath27 . one major strategy for this is _ maximum likelihood _ ( ml ) decoding and is mainly focused on in this paper .",
    "it consists in the selection of that vector @xmath28 that minimises the number of non - zero elements ( weight ) @xmath29 satisfying the parity check equation @xmath30 .",
    "decoding failure occurs when @xmath28 differs from @xmath27 .",
    "the probability of this occurring is termed as the ( block ) decoding error probability @xmath3 , which serves as a performance measure of the code specified by @xmath2 given the ( ml ) decoding strategy .",
    "it is worthwhile to mention that for any true noise vector @xmath27 , @xmath31 ( mod2 ) where @xmath32 is an arbitrary codeword vector for which @xmath33 ( mod 2 ) holds , also satisfies the parity check equation @xmath34 ( mod2 ) .",
    "the set of indices of non - zero elements of @xmath32 is denoted by @xmath35 .",
    "we denote the probability that a given decoding strategy ( ds ) will select @xmath31 with @xmath36 rather than @xmath27 , as @xmath37 .",
    "the ml decoding strategy fails in correctly estimating those noise vectors @xmath27 for which less than half of @xmath38 are zero , since the weight of @xmath39(mod2 ) becomes smaller than @xmath40 . to noise vectors @xmath27 for which exactly half of @xmath38 are zero , we attribute an error @xmath41 , since the weight of @xmath39(mod2 ) is equal to @xmath40 , such that p_ml(e|w)=_i=1^int((w1)/2)w + # 2p^w - i(1-p)^i  + _ ( w  even ) 12w + # 2 ( p(1-p))^w/2 ~(p^w2 ) [ eq : pewml ] where @xmath42 is the integer part of @xmath43 ( for @xmath44 for other decoding schemes we refer to appendix [ sec : appb ] ) .",
    "the minimum of @xmath45 under the constraints @xmath46 ( mod2 ) and @xmath47 , is commonly known as the _ minimal distance _ of @xmath2 and is here denoted as @xmath48 .",
    "it provides a lower bound for the decoding error probability of the ml scheme as @xmath49 .",
    "gallager @xcite showed that for @xmath50 the minimal distance grows as @xmath51 for most codes characterised by the @xmath52-constraints , which implies that the decoding error probability can decay exponentially fast with respect to @xmath1 when @xmath53 is sufficiently low .",
    "however , he also showed that the minimal distance and , more generally , the weights of certain codeword vectors become @xmath5 for a polynomially small fraction of codes when the code ensemble is naively constructed , which implies that the average decoding error probability over the ensemble @xmath4 exhibits a slow polynomial decay with respect to @xmath1 being dominated by the atypical poor codes .",
    "as gallager did not examine the detailed properties of the poor codes , it was only recently that upper- and lower - bounds of @xmath4 were evaluated for several types of naively constructed ldpc code ensembles @xcite .",
    "however , the obtained bounds are still not tight in the prefactors .",
    "in addition , extending the analysis to other ensembles does not seem straightforward as the provided technique is rather complicated . the first purpose of this paper is to show that one can directly evaluate the leading contribution of @xmath4 by making a one - to - one connection between occurrence of low weights in codeword vectors and the presence of some dangerous finite diagram(s )",
    "( sub - graph(s ) ) in a graph representation of that code .",
    "in order to suppress the influence of the atypical poor codes , gallager proposed to work in an _ expurgated _ ensemble , where the codes with low minimal distance are somehow removed .",
    "however , a practical way to obtain the expurgated ensemble has not been provided so far .",
    "the second purpose of the current paper is to provide a ( typically ) linear - time practical algorithm for the expurgation and we numerically demonstrate its efficacy .",
    "as mentioned in the previous section , evaluating the distribution of low weights of the poor codes in a given ensemble becomes relevant for the current purposes .",
    "this distribution highly depends on the details of the definition of code ensembles .",
    "we here work on the following three ensembles defined on the basis of bipartite graphs ( fig .",
    "[ fig : bi ] ) :    ( 160,50 ) ( 50 , 5 ) = 40    * miller - burshtein ( mb ) ensemble : * put @xmath1 vertices ( message bits ) and @xmath54 edges ( parity checks ) on the left and right , respectively . for each vertex and edge",
    ", we provide @xmath8 and @xmath9 arcs , respectively . in order to associate these",
    ", the arcs originating from the left are labelled from @xmath55 to @xmath56 , and similarly done for the right .",
    "a permutation @xmath57 is then uniformly drawn from the space of all permutations of @xmath58 .",
    "finally , we link the arc labelled @xmath59 on the left with the arc labelled @xmath60 on the right .",
    "this defines a code completely determining a specific dependence between message bits and parity checks .",
    "the uniform generation of @xmath60 characterises the ensemble .",
    "note that in this way multiple links between a pair of vertex / edge are allowed .    * no multiple links ( nml ) ensemble : * multiple links in the bipartite graph possibly reduces the effective number of parity checks of the associated message bits , which may make the error correction ability weaker .",
    "the second ensemble is provided by expurgating graphs containing multiple links from the mb ensemble .",
    "* minimum loop length @xmath61 ( mll-@xmath61 ) ensemble : * in the bipartite graph , length @xmath61 loops are defined as irreducible closed paths composed of @xmath61 different vertices and @xmath61 different edges . under this definition",
    "is usually counted as @xmath62 in the it literature @xcite . ] as shown later , short loops become a cause of poor error correction ability , as they allow for a shorter minimal distance .",
    "therefore , we construct code ensembles by completely expurgating graphs containing loops of length shorter than @xmath61 from the mb ensemble , and examine how well such expurgation contributes to the improvement of the average error correction capability .",
    "note that the mb and nml ensemble correspond to the mll-@xmath55 and mll-@xmath0 ensemble , respectively .",
    "although the ensembles above are constructed on the basis of bipartite graphs , for convenience we will also use other two representations :    * monopartite ( hyper)-graph representation : * each message bit is represented by a vertex .",
    "the vertices are connected by hyper - edges ( each linking @xmath9 vertices ) , each vertex is involved @xmath8 times in an hyper - edge ( see fig.[fig : mono ] ) .",
    "( 160,40 ) ( 50 , 5 ) = 30    * matrix representation : * @xmath54 rows , @xmath1 columns , where @xmath63 is the number of times vertex @xmath64 appears in edge @xmath65 . for regular @xmath6 codes , the following constraints on @xmath66 apply _",
    "v=1^n a_ev = d,&e=1, .. ,l , + _",
    "e=1^l a_ev = c,&v=1, .. ,n . [ reg_code ] for clarity , we always use indices @xmath67 to indicate message bits ( or vertices ) , and indices @xmath68 to indicate parity checks ( or edges ) . note that the parity check matrix of a given code is provided as @xmath69 ( mod 2 ) .",
    "for the nml and mll-@xmath70 ensembles , the matrix elements are constrained to binary values as @xmath71 .",
    "therefore , @xmath66 itself represents the parity check matrix @xmath2 in these cases , which implies that every parity check is composed of @xmath9 bits and every bit is associated with @xmath8 checks . however , as @xmath63 can take any integer from @xmath72 to @xmath8 in the mb ensemble , it can occur that certain rows and/or columns of the parity check matrix @xmath2 are composed of only zero elements , which means that corresponding checks and/or bits do not contribute to the error correction mechanism .",
    "note that in the matrix notation the exclusion of @xmath73-loops corresponds to the extra ( redundant ) constraints ( additional to @xmath74 , and ( [ reg_code ] ) ) : _",
    "i=1^l a_v_ie_ia_v_(i1)modle_i=0   \\{v_i , i=1 .. l } ,  \\{e_i , i=1 .. l}. [ nolloop ] where @xmath75 is a group of @xmath73 different vertices / edges .",
    "there is a one - to - one correspondence between the bipartite graph , and the matrix representation of the codes .",
    "note however , that with each monopartite graph correspond a number of ( identical up to permutation of the edges ) of bipartite graph / matrix representations .",
    "now , let us start to evaluate the error probability . for this , we first investigate necessary configurations in the bipartite graph representation for creating codeword vectors having a given weight .",
    "assume that a codeword vector @xmath32 which is characterised by @xmath46 ( mod 2 ) has a weight @xmath76 .",
    "as addition of zero elements of @xmath32 does not change parity checks , we can focus on only the @xmath77 non - zero elements . then , in order to satisfy the parity relation @xmath46 ( mod 2 ) , every edge associated with @xmath77 vertices corresponding to these non - zero elements must receive an even number of links from the @xmath77 vertices in the bipartite representation .",
    "let us now evaluate how frequently such configurations appear in the whole bipartite graph when a code is generated from a given ensemble .",
    "we refer to a sub - set of the @xmath77 vertices as @xmath78 .",
    "each vertex @xmath64 is directly linked to a subset @xmath79 of the edges .",
    "we denote @xmath80 , and @xmath81",
    ". then there are @xmath82 _ links _ to be put between @xmath78 and @xmath83 .",
    "note that there are exactly @xmath8 links arriving at each @xmath84 , and @xmath9 links arriving at each @xmath85 .",
    "each diagram consists in a combination @xmath86 . for an _ admissible _ diagram",
    ", we have the extra condition that each @xmath85 receives an even number of links from @xmath78 , such that the bits in @xmath78 can be collectively flipped preserving the parity relation @xmath46 ( mod 2 ) ) .",
    "note that we ignore the links arriving in @xmath87 from outside the set @xmath78 .",
    "for admissible diagrams , @xmath88 is limited from above by @xmath89 , where @xmath42 is the integer part of @xmath43 . a number @xmath88 of the links can be put freely , while the remaining @xmath90 links all have to fall in the group @xmath88 ( out of @xmath54 ) , such that it can easily be seen that each of those ( forced ) links carries a probability @xmath91 .",
    "there are @xmath92 ways of picking @xmath93 out of @xmath1 vertices , such that each diagram consisting of @xmath77 vertices and @xmath88 edges carries a probability of occurrence proportional to @xmath94 .",
    "this observation allows us to identify the `` _ most dangerous _ '' admissible diagrams as those with a probability of occurrence with the least negative power of @xmath1 , i.e. that combination of @xmath95 that maximises @xmath96 .",
    "the collective contributions of all other diagrams are at least a factor @xmath97 smaller , and therefore negligible . from this",
    ", it immediately follows that @xmath88 must take its maximal value which is @xmath98 , while @xmath77 has to be minimised , compatible with the constraints of the code ensemble under consideration .",
    "hence , the probability @xmath99 that a generated graph ( code ) contains a _ most dangerous _",
    "diagram including @xmath100 vertices , scales like p_f(n^*_v)~n^n^*_v(1-c2 ) .",
    "[ scale ] with the constraint on @xmath100 that @xmath101 is integer .",
    "note that for all ensembles we consider in this paper @xmath102 . at this point",
    ", we make some important observations : - firstly , from eq .",
    "( [ scale ] ) it is easily seen that for @xmath103 , any diagram containing an equal number of vertices and edges scales like @xmath104 .",
    "the number of diagrams contributing to @xmath4 becomes infinite , and @xmath105 .",
    "it was already recognised by gallager @xcite and @xcite that regular @xmath106 codes have very bad decoding properties under the block error criterion , which is currently adopted . therefore , in what follows , we will implicitly assume that @xmath107 .",
    "- secondly , as eq .",
    "( [ scale ] ) represents only the dependence on the code length @xmath1 , for an accurate evaluation of the asymptotic behaviour ( for @xmath108 ) of the error probability , we have to calculate the prefactor .",
    "nevertheless , this kind of _ power counting _ is still highly useful because this directly identifies the major causes of the poor performance , and allows us to concentrate on only a few relevant diagrams for further calculation , ignoring innumerable other minor factors .",
    "this is more systematic and much easier to apply in various ensembles than the existing method of @xcite .",
    "- thirdly , once @xmath109 is accurately evaluated , the average block error probability @xmath4 for any decoding scheme @xmath110 and for sufficiently low flip rates @xmath53 can be evaluated as p_b_dsp_b_ds(e|n^*_v ) p_f , [ eq : p_f_p_b ] where e.g. for ml decoding @xmath111 is given in ( [ eq : pewml ] ) ( the expressions for other decoding schemes can be found in appendix [ sec : appb ] ) . -",
    "the nml and mll-@xmath61 ensembles are generated from the mb ensemble by expurgating specific kinds of codes , which slightly changes the distributio of codes such that the above argument based on free sampling of links in constructing graphs might not be valid .",
    "however , for @xmath112 the current evaluation still provides correct results for the leading contribution to @xmath113 , since the influence of the expurgation procedure has a negligible effect on the leading contributions of the most dangerous diagrams . -",
    "finally , we note that this analysis essentially follows the _ weight enumerator _",
    "formalism @xcite , which can be regarded as a certain type of the _ annealed _ approximation @xcite .",
    "although we have argued that such formalism is not capable of accurately evaluating the performance of typical codes that decays exponentially with respect to @xmath1 @xcite , the current scheme correctly assesses the leading contribution of the average error probability @xmath114 of the above ensembles , which scales polynomially with respect to @xmath1 being dominated by atypically poor codes .",
    "this is because the probability of occurrence scales like @xmath115 ( with @xmath116 ) for all admissible diagrams .",
    "therefore , we can safely ignore the possibility that more than one such diagram occurs in the same graph ( as illustrated in fig .",
    "[ fig : dia ] ) , and to leading order for @xmath117 , we can simply add the contributions of all most dangerous diagrams .",
    "this is not so for the typical case analysis ( with @xmath118 ) , where exponentially rare codes may have an exponentially large contribution .",
    "in order to avoid this kind of over counting , a _ quenched _ magnetisation enumerator based treatment is then more suitable @xcite .",
    "note furthermore that in the sm treatment of typical codes , the polynomial error probability is hidden in the ferro - magnetic solution ( since @xmath119 when @xmath120 ) , and is therefore easily overlooked .",
    "once the notion of most dangerous diagrams is introduced , the asymptotic behaviour of the probability @xmath117 for sufficiently low flip rates @xmath53 is easily evaluated for various ensembles .",
    "@xmath121 * mb ensemble : * for the mb ensemble , multiple links between a pair of vertex / edge are allowed , which forces us to make a distinction between even and odd @xmath8 .",
    "for even @xmath8 the minimal admissible @xmath77 is @xmath55 , such that the error probability will scale like @xmath122 , while that for odd @xmath8 is @xmath0 which provides a faster scaling @xmath123 .",
    "-for @xmath8 even , the most dangerous diagram is given in fig.[fig : lk ] , and the probability @xmath124 is given by ( an explanation of the diagrams , and how there multiplicity is obtained can be found in appendix a ) p_f(=1,c  even)n^1-c2  ( 1-r)^-c2   ^c2  c!2^c2(c2 ) !   [ pf1e ] note that with `` @xmath125 '' , we indicate that `` @xmath126 '' .",
    "( 160,50 ) ( 20 , 5)=30 ( 80 , 5)=40    -for @xmath8 odd the minimal admissible @xmath77 is @xmath0 , such that the error probability will scale like @xmath123 .",
    "the most dangerous diagrams are given in fig.[fig : lk ] ( with @xmath127 ) , and the probability @xmath128 is given by ( for details see appendix a ) p_f(=1,c  odd)n^2-c  ( 1-r)^-c  ^c  c!2 _",
    "k=0^int(c/2)c!2 ^ 2kk!^2(c2k)![pf1o ] one can check that the values ( [ pf1e ] ) and ( [ pf1o ] ) , which we believe to be exact ( not bounds ) , satisfy the bounds given in @xcite . @xmath121",
    "* nml ensemble : * in the nml ensemble , multiple links are not allowed . in this ensemble",
    ", even and odd @xmath8 can be treated on the same footing . in both cases ,",
    "the minimal admissible @xmath129 , such that the error probability will scale like @xmath123 .",
    "the most dangerous diagram is given in fig.[fig : lk ] ( note that in this case only @xmath130 is allowed ) .",
    "the probability @xmath128 is given by ( for details see appendix a ) p_f(=2)n^2-c  ( 1-r)^-c  ^c  c!2   [ pf2 ] @xmath121 * mll-@xmath131 ensemble : * in the mll-@xmath131 ensemble , neither multiple links nor loops of length @xmath0 are allowed . note",
    "that this also implies that pairs of vertices may not appear more than once together in a parity check , such that all parity checks are different , making each monopartite graph correspond to exactly @xmath132 bipartite graphs / matrices . in the monopartite graph any pair of vertices",
    "is now connected by at most one ( hyper-)edge .",
    "( 160,50 ) ( 50 , 5)=40    one can easily convince oneself that the minimal @xmath133 ( each @xmath64 needs @xmath8 other vertices to connect to ) , and the most dangerous diagram is given in fig.[fig : l3 ] .",
    "the dominant part of @xmath134 is given by ( for details see appendix a ) p_f(=3)n^c1-c(c1)2(1-r)^-c(c1)2 ^c(c1)2  c!^c1(c1 ) ! !",
    "[ pf3 ] @xmath121 * mll-@xmath61 ensemble : * in the general mll-@xmath61 ensemble , neither multiple links nor loops of length @xmath135 are allowed . in general , identifying the most dangerous diagram(s ) and especially calculating their combinatorial prefactor becomes increasingly difficult with increasing @xmath61 , but we can still find the scaling of @xmath117 relatively easily by _",
    "power counting_. to this purpose it is more convenient to use the monopartite graph representation . in fig.[fig : l345 ] we observe that for @xmath136 and @xmath137 , the minimal @xmath77 is given by @xmath138 and @xmath139 respectively , such that using ( [ scale ] ) we obtain p_f(=3)~n^(c1)(1-c2)p_f(=4)~n^2c(1-c2)p_f(=5)~n^c(c1)(1-c2 ) [ pf345 ]    ( 160,50 ) ( 10 , 5)=40 ( 60 , 5)=40 ( 110 , 5)=40    for @xmath140 , even finding the most dangerous diagram and thus power counting becomes quite difficult to do by hand , but we can still easily upper bound the power by the following observation : from fig.[fig : lg5 ] we observe that for a given minimal allowed loop length @xmath61 the minimum number of _ generations _ without links between them starting from any vertex @xmath64 is given by int@xmath141 .",
    "therefore the minimal @xmath77 is lower bounded by n_v1+c_k=0^int(12)(c1)^k= 1+c , [ nvlb ] which implies that @xmath117 can be upper bounded as p_f()n^1+c(1-c2 ) .",
    "[ pflb ]    ( 160,70 ) ( 50 , 5 ) = 40    in fig .",
    "[ fig : dia ] we have plotted the frequencies of occurrence of dangerous diagrams that scale like @xmath142 .",
    "we have randomly generated @xmath143 code realisations ( for @xmath144 i.e. the nearest integer for which @xmath145 is also integer ) , and have plotted both the total frequency ( multiplied by @xmath1 ) of occurrence of a diagram ( dashed lines ) , and the frequency that a graph contains the diagram at least once ( full lines ) .",
    "note that in the limit @xmath108 , both coincide , illustrating the fact that we can safely ignore the possibility that more than one such diagram occurs in the same graph .",
    "we observe that the extrapolations @xmath146 are all in full accordance with the theoretical predictions .",
    "( 160,60 ) ( -5 , 5 ) = 55 ( -10 , 40 ) @xmath147 ( 33 , 2 ) @xmath148 ( 80 , 5 ) = 55 ( 75 , 40 ) @xmath147 ( 117 , 2 ) @xmath148    all this clearly illustrates how the exclusion of short loops reduces @xmath117 , and thus through ( [ eq : p_f_p_b ] ) the polynomial error probability probability .",
    "furthermore , from figs .",
    "[ fig : lk]-[fig : lg5 ] , it is clear that all most dangerous diagrams contain short loops .",
    "knowledge of the distribution of the number of short loops in the various ensembles is therefore relevant for our current purposes , and we analyse the distribution of the number of @xmath61-loops in the next subsection .      in this subsection",
    "we investigate the distribution @xmath149 of the number @xmath150 of @xmath61-loops for the various code ensembles.note that we only consider irreducible @xmath61-loops , in the sense that they are not combinations of shorter loops ( i.e. they do not visit the same vertex or edge twice ) .",
    "note that an @xmath61-_loop _ in the monopartite graph corresponds to a @xmath62-_cycle _ in the bipartite graph representation @xcite .",
    "the number of irreducible @xmath61-loops in a random regular @xmath6 graph ( with @xmath108 ) has the following distribution : p_(k)=p ( # -loops = k )  ( - _ ) , _ [ pl ] for the derivation of this result we refer to appendix a. from ( [ pl ] ) we observe that the average number of short loops increases rapidly with @xmath8 and @xmath9 .",
    "furthermore we note the symmetry between @xmath8 and @xmath9 , which reflects the edge / vertex duality which is typical for loops .",
    "( 160,50 ) ( 50 , 5 ) = 40    as explained in appendix a , the constraint that no loops of length @xmath135 are present in the graph , has no influence in the leading order to the diagrams for loops of length @xmath151 .",
    "we denote the number of codes in the ensemble where the minimum loop length is @xmath61 ( i.e. loops of length @xmath135 have been removed ) by @xmath152 , such that the size of the original ( mb ) ensemble with all regular @xmath6 codes is denoted by @xmath153 . from ( [ pl ] )",
    "it follows that the size of @xmath152 is given by _",
    "( c , d , n)=-_l=1 ^",
    "1_l  _ 1(c , d , n ) = -_l=1 ^ 1l(c1)^l(d1)^l2l  _ 1(c , d , n ) the reduction factor @xmath154 is @xmath155 , for any finite loop length @xmath61 . since the number of non - equivalent codes in the original ensemble @xmath156 , the final ensemble @xmath152 is still very big , but clearly smaller than gallager s ideally expurgated ensemble which has a reduction factor of just @xmath157 @xcite . note that the presence of ( short ) loops in a code does not only adversely affect the polynomial error probability , but also the success rate for practical decoding algorithms such as belief progagation @xcite .",
    "in this section we propose a linear time ( in @xmath1 ) algorithm that generates codes and removes loops up to arbitrary length ( the combination @xmath6 permitting ) .",
    "we also present simulation results , which corroborate our assumptions about the validity of the diagrammatic approach as presented in this paper .",
    "finally we give some practical limits and guidelines for code - ensembles with large but finite @xmath1 .",
    "the algorithm to generate a random regular @xmath6 code consists in the following steps :    make a list of available vertices @xmath158 of initial length @xmath159 , where each vertex appears exactly @xmath8 times    for each of the @xmath160 parity checks , @xmath9 times :    randomly pick a vertex from @xmath158 ,    remove it from the list    @xmath161 .",
    "note that in the process we keep construct the lists :    @xmath162[i],~v=1 .. n,~i=1 .. c$ ] containing the edges each vertex @xmath64 is involved in ,    @xmath163[j],~e=1 .. l,~j=1 .. d$ ] containing the vertices each edge @xmath65 involves .",
    "it is clear that this algorithm is linear in @xmath1 .",
    "we now describe the algorithm to detect ( and store ) all @xmath164-loops in the graph :    we consider all the vertices as a possible starting point @xmath165 of the loop    given a starting point @xmath165 _ grow _ a walk of length @xmath61 .",
    "each growing step consists in :    take @xmath166 from @xmath167 $ ] and check conditions for valid step    take @xmath168 from @xmath169 $ ] and check conditions for valid step    if all conditions are satisfied goto next step + else if possible goto the next @xmath170 $ ] or @xmath171 $ ] + else go to previous step    finally check whether the end point of the loop @xmath172 , if so store the loop i.e. @xmath173 the conditions for a valid step are the following :    @xmath174   for @xmath175 ,    @xmath176for @xmath177 .",
    "@xmath178 for @xmath179 ,    @xmath180   for @xmath181 ,    @xmath182   for @xmath183 .",
    "note that the conditions @xmath184 fix the starting point of the loop , while the conditions @xmath185 for @xmath175 , and @xmath186 for @xmath177 , fix its orientation .",
    "this has a double advantage : it avoids over counting , and reduces execution time by early stopping of the growing process.for 1-loops ( 2-cycles ) , for all @xmath187 we simply look in @xmath162 $ ] for double links to the same edge , i.e. @xmath162[i]=ev[v][j]$ ] . imposing that @xmath188 , then avoids double counting .",
    "since each vertex is connected to @xmath8 edges , and each edge is connected to @xmath9 vertices , the number of operations to check whether any vertex @xmath64 is involved in a loop , remains @xmath155 ( compared to @xmath108 ) .",
    "as we have to check this for all vertices , the loop finding stage of the algorithm is linear in @xmath1 .",
    "we start by detecting and removing the smallest loops and than work our way towards longer loops .",
    "assuming that all shorter loops have been successfully removed , and having found and listed all the loops of length @xmath61 , the procedure for removing them is very simple .",
    "for all stored @xmath61-loops @xmath189 :    randomly pick a vertex / edge @xmath190 combination from @xmath191    swap it with a random other vertex @xmath192 in a random other edge @xmath193 .",
    "are formed based on the adjacency matrix @xmath2 was recently developed in @xcite .",
    "however , it costs @xmath194 computation as computing powers of @xmath2 is required .",
    "this implies our approach , which typically runs in @xmath51 steps , is more efficient for large @xmath1 . ]    for @xmath195 and @xmath192 check whether they are now involved in a @xmath73-loop with @xmath196 .",
    "if so undo the swap and goto 1 .",
    "else accept the swap , the loop is removed .",
    "this procedure of removing loops takes typically @xmath155 operations .",
    "the typical number of loops of each length @xmath61 is @xmath155 . for each loop we only have to swap one vertex / edge combination to remove it , the checks that the swap is valid take @xmath155 operations , and we typically need only @xmath155 swap - trials to get an acceptable swap .",
    "although the algorithm is linear in @xmath1 , the number of operations needed to detect and remove loops of length @xmath61 in a @xmath52 code , grows very rapidly with @xmath197 and even exponentially with @xmath61 .",
    "furthermore , we note that only in the @xmath108 limit all short loops can be removed . in practice , for large but finite @xmath1 and given @xmath52 , the maximum loop length @xmath61 is clearly limited . a rough estimate for this limit",
    "is given by c  1-(c1)^12(1-(c1 ) ) , d  1-(d1)^12(1-(d1))~n because @xmath64 ( resp .",
    "@xmath65 ) is not allowed to be its own @xmath198-th nearest neighbour ( see fig . [",
    "fig : lg5 ] ) .",
    "hence , loops of logarithmic length in @xmath1 can not be avoided . for practical @xmath6",
    ", however , this loop length is reached rather quickly .",
    "therefore , we have built in the possibility for the algorithm to stop trying to remove a given loop when after max - swap trials , no suitable swap has been obtained . by choosing max - swap sufficiently large , the maximum removable loop length is easily detected . in practice",
    "we find that for all loop lengths that can be removed , we typically need 1 , and occasionally 2 trial swaps per loop . in fig.[fig : lp34 ] , we show the distribution of loops over the @xmath6 ensemble , for @xmath199 , for @xmath200 and averaged over @xmath201 codes , up to loops of length @xmath202 ( corresponding to length @xmath203 cycles in the it terminology @xcite ) , before and after removal of shorter loops .",
    "in general we observe that the poisson distribution with @xmath204 given in ( [ pl ] ) fits the simulations very well , for all @xmath61 not exceeding the maximal removable loop length , while it breaks down above that .",
    "( 160,60 ) ( 50 , 0 ) = 60    note that , in principle , this method also could be used to obtain gallager s ideally expurgated ensemble .",
    "we would start by finding and removing the most dangerous diagrams , and then move on to the next generation of most dangerous diagrams , and so on .",
    "however , the next most dangerous diagrams are obtained by adding additional vertices ( and necessary edges ) and/or by removing edges from the current most dangerous diagrams .",
    "one can easily convince oneself that the number of next most dangerous diagrams soon becomes enormous .",
    "in addition for each generation we only reduce the polynomial error probability by a factor @xmath142 . therefore , although in principle possible , this method is not practical , and we have opted for the removal of loops . the fact that we only have to look for one type of diagram ( i.e. loops ) , and the fact that we expurgate many entire generations of next most dangerous diagrams in one go , makes the cost of over - expurgating the ensemble a small one to pay .",
    "in summary , we have developed a method to directly evaluate the asymptotic behaviour of the average probability with respect to the block decoding error for various types of low density parity check code ensembles using diagrammatic techniques .",
    "the method makes it possible to accurately assess the leading contribution with respect to the codeword length @xmath1 of the average error probability which originates from a polynomially small fraction of poor codes in the ensemble , by identifying the most dangerous admissible diagrams in a given ensemble by a power counting scheme .",
    "the most dangerous diagrams are combinations of specific types of multiple closed paths ( loops ) in the bipartite graph representation of codes , and allow for codewords with low weights . the contribution of a diagram to the error probability becomes larger as the size of the diagram is smaller , which implies that one can reduce the average error probability by excluding all codes that contain _ any _ loops shorter than a given threshold @xmath61 .",
    "we have theoretically clarified how well such a sub - optimal expurgation scheme improves the asymptotic behaviour .",
    "we have also provided a practical algorithm which can be carried out typically in a linear scale of @xmath1 for creating such sub - optimally expurgated ensembles .",
    "the numerical experiments utilising the provided algorithm have verified the validity of the theoretical predictions .",
    "the current approach is relatively easy to adapt to irregularly constructed codes @xcite , codes over the extended fields @xcite , other noise channels @xcite , and other code constructions such as the mn codes @xcite .",
    "work in that direction is currently underway .",
    "99 h. nishimori , statistical physics of spin glasses and information processing , oxford univ . press ( new york ) , 2001 .",
    "n. sourlas , nature * 339 * , 693 , 1989 .",
    "t. murayama , y. kabashima , d. saad and r. vicente , phys .",
    "e * 62 * , 1577 , 2000 . h. nishimori and kym .",
    "wong , phys rev .",
    "e * 60 * , 132 , 1999 .",
    "a. montanari and n. sourlas , eur .",
    "j. b * 18 * , 121 , 2000 .",
    "g. miller and d. burshtein , ieee trans . on inf .",
    "theory * 47 * , 7 , 2001 .",
    "gallager , low density parity check codes , mit press ( cambridge , ma ) , 1963 .",
    "mackay , ieee trans . on inf .",
    "theory * 45 * , 399 , 1999 .",
    "s. aji , h. jin , a khandekar , d.j.c .",
    "mackay and r.j .",
    "mceliece , in codes , systems and graphical models , b. marcus and j. rosenthal ( eds . ) , springer verlag ( new york ) , 195 , 2001 .",
    "seung , h. sompolinsky and n. tishby , phys .",
    "a * 45 * , 6056 , 1992 . j. van mourik , d. saad and kabashima , phys .",
    "e * 66 * , 026705 , 2002 .",
    "r. vicente , d. saad and y. kabashima , j. phys . a * 33 * , 6527 , 2000 . i. kanter and d. saad , phys .",
    "lett . * 83 * , 2660 , 1999 .",
    "m. davey , error - correction using low - density parity - check codes , ph .",
    "d. thesis , university of cambridge , october 1998 .",
    "k. nakamura , y. kabashima and d. saad , europhys .",
    "lett . * 56 * , 610 , 2001 .",
    "r. vicente , d. saad and y. kabashima , phys .",
    "e * 60 * , 5352 , 1999 . n. skanzos , j. van mourik and d. saad , phys .",
    "e * 67 * , 037101 , 2003 .",
    "d.j.c . mackay and r. neal , electronics lett . * 32 * , 1645 , 1996 .",
    "p. rujn , phys .",
    "lett . * 70 * , 2968 , 1993 . n. sourlas , europhys .",
    "lett . * 25 * , 159 , 1994 .",
    "h. nishimori , j. phys .",
    ". jpn . * 62 * , 2973 , 1993 . y. iba , j. phys .",
    "a * 32 * , 3875 , 1999 .",
    "shannon , the mathematical theory of information , university illinois press ( urbana , il ) , 1949 ; reprinted 1998 .",
    "hu , e. eleftheriou and d.m .",
    "arnold , in ieee global telecommunications conference 2001 , vol . 2 , 995 , 2001 .",
    "j.a . mcgowan and r.c .",
    "williamson , _ removing loops from ldpc codes _ , in australian communication theory workshop proceedings 2003 , p167 , 2003 .",
    "diagrams are finite sub - graphs . provided that the graph is large and provided that the correlations between the different diagrams is not _ too strong _ , we can treat them as effectively independent to leading order in @xmath1 , even when they have ( many ) vertices and/or edges in common .",
    "it then suffices to calculate the probability of occurrence of a single diagram , and to count how any times such a diagram could occur in the graph , in order to extract its overall expectation , allowing us to calculate all quantities that depend on it . to illustrate this ,",
    "consider the following scenario .",
    "all diagrams we consider , consist of @xmath77 vertices and @xmath88 edges , with at least @xmath0 links arriving to each of the nodes from within the diagram .",
    "suppose now that we replace a single node ( vertex or edge ) , with another one not from within the diagram . since the probability for each link to be present is @xmath205 , there are is at least a 4 link difference between the diagrams , thus making the correlation between them negligible to leading order .",
    "the rules for calculating the combinatorial pre - factor of the diagram are easily described as follows : consider all possible sub - groups of @xmath77 vertices and @xmath88 edges .",
    "calculate the probability @xmath206 that a given group of @xmath77 vertices and @xmath88 edges forms the diagram we re interested in . since we assume that ( to leading order in @xmath1 ) these probabilities are independent for all groups , we just have to multiply @xmath206 with all the possible ways of picking @xmath77 vertices and @xmath88 edges from the graph ( i.e. @xmath207 ) .",
    "combined this leads to the following simple _ recipe _ for the calculation a the contribution of a diagram to @xmath117 :    for each vertex from which @xmath43 links depart , add a factor @xmath208 .    for each edge",
    "from which @xmath43 links depart , add a factor @xmath209 .    for each link",
    ", add a factor @xmath210 .",
    "divide by the number of symmetries , i.e. the number of permutations of vertices , edges or links , that lead to the same diagram .",
    "we calculate the probability @xmath211 that a combination of @xmath55 vertex @xmath64 , and @xmath212 edges forms the left diagram fig.[fig : lk ] in the following steps :    1 vertex with @xmath8 links ( @xmath213 ) .",
    "@xmath212 edges with 2 links ( @xmath214 ) .",
    "@xmath8 links ( @xmath215 ) .",
    "symmetry : @xmath212 double links ( @xmath216 ) .    symmetry : permutation of the edges ( @xmath217 ) .",
    "so , combined we have that p_f(1,c2)(d(d-1)/2)^c2 nl^c2(cn)^c  , [ a_pf1 ] and after some reworking we obtain ( [ pf1e ] ) .",
    "we calculate the probability @xmath218 that a combination of @xmath0 vertices , and @xmath8 edges forms the right diagram in fig.[fig : lk ] with @xmath219 in the following steps :    @xmath0 vertices with @xmath8 links ( @xmath220 ) .",
    "@xmath8 edges with @xmath0 links ( @xmath221 ) .",
    "@xmath222 links ( @xmath223 ) .",
    "symmetry : permute edges in groups of @xmath224 ( @xmath225 ) .",
    "symmetry : permute edges in group of @xmath226 ( @xmath227 ) .",
    "symmetry : @xmath228 double links ( @xmath229 ) .",
    "symmetry : simultaneously permute the vertices and the groups of @xmath224 edges ( @xmath0 ) .",
    "so , combined we have that p_f(2,c , k )  ( d(d1))^c   n^2l^c(cn)^2c  , [ a_pfk ] and after some reworking we obtain ( [ pf1o ] ) and ( [ pf2 ] ) .",
    "we calculate the probability @xmath230 that a combination of @xmath231 vertices , and @xmath232 edges forms diagram in fig.[fig : l3 ] in the following steps :    @xmath231 vertices with @xmath8 links ( @xmath233 )    @xmath234 edges with @xmath0 links ( @xmath235 ) .",
    "@xmath236 links ( @xmath237 ) .",
    "symmetry : permute vertices ( @xmath238 ) .",
    "symmetry : permute edges ( @xmath239 ) .",
    "so , combined we have that p_f(c1,c(c1)/2 )   ( d(d1))^c(c1)2   n^c1l^c(c1)2(cn)^c(c1 )  , [ a_pf3 ] and after some reworking we obtain ( [ pf3 ] ) .",
    "the probability @xmath149 that there are @xmath150 loops of length @xmath61 ( i.e. including @xmath61 vertices and edges of the bipartite graph ) , can be calculated from diagram fig.[fig : loop ] . by power",
    "counting it is easily checked that the probability for any loop length @xmath61 to occur is @xmath155 .",
    "therefore , we adapt a slightly different strategy compared to the diagrams above , ( this also illustrates where some of the rules of our _ recipe _ originate from ) first we calculate the probability @xmath240 that a given group of @xmath61 vertices ( and @xmath61 edges ) forms a `` true '' @xmath61-loop in the following steps :    we order the @xmath61 vertices into a ring ( @xmath241 ways ) .    for each pair of consecutive vertices we pick on of the edges to connect to both ( @xmath242 ways ) .    for each vertex choose a link to each edge it is connected to ( @xmath243 ways ) .",
    "for each edge choose a link to each vertex it is connected to ( @xmath244 ways ) .",
    "the probability that a chosen left and right link are connected is given by @xmath210 .",
    "so , combined we have that p_,g(c(c1)d(d1))^^2 there are @xmath245 ways to pick the vertices , and @xmath246 ways to pick the edges.we want exactly @xmath150 of these to form a loop , and @xmath247 of these not to form an @xmath61-loop , therefore : p_(k)=n + # 2l + # 2p_,g^k(1-p_,g)^n + # 2 l + # 2-k(- _ ) note that the exclusion ( or not ) of shorter loops , has no influence on the leading order of @xmath149 , since the probability of having a short - cut i.e. another edge that connects 2 vertices from within the group of @xmath61 ( or vertex that connects 2 edges from within the group of @xmath61 ) , requires 2 extra links to be present which adds a factor @xmath248 to the probability @xmath240 , and is therefore negligible .",
    "as shown , for a given code ensemble , the probability @xmath117 that a finite group of @xmath77 bits can be collectively flipped , is completely dominated by sub - sets of size @xmath100 , such that @xmath249 . from this",
    "we can then determine the polynomial error probability @xmath4 , which depends on the decoding scheme employed .",
    "here , we concentrate on the bsc@xmath250 for the following decoding schemes :    ml decoding @xcite : since this decoding scheme selects the code word with the lowest weight , an error occurs when the @xmath251 collectively flipped bits have a lower weight than the original ones .",
    "when the @xmath251 collectively flipped bits have an equal weight to the original ones , we declare an error with probability @xmath157 , such that one immediately obtains ( [ eq : pewml ] ) .",
    "mpm decoding @xcite : this decoding scheme selects the code word that maximizes the marginal posterior , and minimizes the bit error rate ( or in a statistical physics framework that minimizes the free energy at the nishimori temperature @xcite ) .",
    "effectively this attributes a posterior probability @xmath252 to each codeword @xmath26 , where @xmath253 , and where @xmath254 , with @xmath255 being the sum over all code words .",
    "since we assume that we are in the decodable region , we have that @xmath256 with @xmath257 being @xmath258 with @xmath100 bits flipped .",
    "hence , by selecting the solution with the maximal marginal posterior probability we obtain that @xmath259 as given in ( [ eq : pewml ] ) .",
    "typical set decoding ( ts ) @xcite : this decoding scheme randomly selects a code word from the typical set .",
    "we declare an error when a noise different from @xmath258 is selected .",
    "hence the error probability is given by @xmath260 , where @xmath261 is the number of code words in the typical set .",
    "since we are in the decodable region , for @xmath262 , the original and the flipped code word are both ( and the only ) codewords in the typical set , such that p_ts(e|n^*_v)=. [ pe_typ ] note that ts decoding has an inferior performance for @xmath4 compared to ml and mpm decoding ."
  ],
  "abstract_text": [
    "<S> we obtain exact expressions for the asymptotic behaviour of the average probability of the block decoding error for ensembles of regular low density parity check error correcting codes , by employing diagrammatic techniques . </S>",
    "<S> furthermore , we show how imposing simple constraints on the code ensemble ( that can be practically implemented in linear time ) , allows one to suppress the error probability for codes with more than @xmath0 checks per bit , to an arbitrarily low power of @xmath1 . as such </S>",
    "<S> we provide a practical route to a ( sub - optimal)_expurgated _ ensemble . </S>"
  ]
}