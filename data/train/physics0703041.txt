{
  "article_text": [
    "artificial neural networks ( nn ) are widely used in pattern recognition problems in the field of particle physics experiments .",
    "typical applications include particle recognition in the tracking system  @xcite , event classification problem in physics analyses  @xcite , and hardware triggers  @xcite . for hardware triggers ,",
    "realization with standard electronics  @xcite , with dedicated nn chip  @xcite , and recently with field programmable gate arrays  @xcite ( fpga ) have been studied . in particular ,",
    "recent advances in digital technology may make it possible to consider transferring complex level 2 nn based pattern recognition tasks to level 1 trigger using fpga technology .    in this work",
    ", a hardware implementation of a feed - forward nn using fpga technology is developed .",
    "first , training of the nn is made in offline computing environment in order to determine weights and thresholds of the network . and ,",
    "as an intermediate step , a standalone c++ program is then written in order to discretize the nn computation , for a bit - by - bit comparison with the response from the hardware . the hardware implementation is then carried out by programming a fpga hardware .",
    "the performance of the implemented hardware nn and possible application to the first level trigger in high energy physics experiments are discussed at the end .",
    "a feed - forward neural network feature function @xmath0  @xcite may be represented by the following formula @xmath1 \\label{eq : nn_structure}\\end{aligned}\\ ] ] where the weights @xmath2 , and thresholds @xmath3 are parameters to be fitted to the entire input patterns \\{@xmath4}. the eq .",
    "( [ eq : nn_structure ] ) represents one hidden - layer structure where the first summation is over hidden nodes and the second is over input nodes . in eq .",
    "( [ eq : nn_structure ] ) , @xmath5 is a `` temperature '' term that rescales the sum , @xmath6 denotes the number of input nodes of the network , and @xmath7 is activation function of neurons .",
    "the non - linear neuron activation function of the following type is frequently used  @xcite @xmath8 in order to model the activation of the neuron . in this study , a feed - forward neural network with 5 input patterns , first hidden later of 6 nodes and one output layer of one node",
    "is constructed ( to be referred as 5 - 6 - 1 structure from now on ) . in order to have a baseline nn performance , two sets of 5-variable gaussian random numbers",
    "are generated , one referred as `` signal '' and the other as `` background '' .",
    "training of the nn is carried out using jetnet  @xcite program . in total ,",
    "5,000 patterns are used for the training with the cycle of 3,000 .",
    "the inverse temperature term is set to 1.0 , and the back - propagation learning rule  @xcite is used . even if this learning rule is rather complicated , it takes less then one minute with a modern personal computer in order to train 5,000 input patterns . after the training , in total 36 weights and 7 threshold values",
    "are saved in order to calculate the nn output on given patterns .",
    "figure  [ fig : input ] ( a ) shows the two - dimensional distributions of two selected input patterns for both signal and background where there are weak correlations between patterns .",
    "rest of the others also have similar level of correlations . the trained nn output",
    "is shown in fig .",
    "[ fig : input ] ( b ) where the separation of the background from the signal is very clear .",
    "note that , at this stage , both input patterns and the nn output are real numbers . in particular , the nn output is bounded in [ 0,1 ] which is the region bounded by the activation function .",
    "in order to implement the nn algorithm in a fpga chip , one may need to convert the entire computational steps to integer - valued mathematical operations . as an intermediate step toward programming a fpga chip with a hardware description language , a standalone c++ program that does all necessary nn algorithm calculations in the integer - valued space",
    "is written .",
    "this program apparently will be a strong debugging tool when one writes the hardware description language to program the hardware .",
    "first , the real - valued input patterns , weights , and thresholds are converted into 8-bit integer values . here",
    ", the 8-bit is chosen so that the design of the firmware is appropriate for moderate performance fpga chips available in the market .",
    "the standalone c++ program mentioned above reads in the integer - valued input patterns and performs neural computation in purely integer - valued space with pre - stored weights and thresholds .",
    "the activation function in eq .",
    "( [ eq : nn_activation ] ) is replaced with a 8-bit wide integer lookup table for a faster access to the activation function at the hardware level that is implemented later .",
    "the nn output is also re - scaled to be bounded within [ 0,2@xmath9 as well .",
    "however , the internal networks storing values of @xmath10 have the bit width of 32 and therefore little information is lost in storing values into internal networks . by doing these conversions to integer - based calculations , the performance of the nn output is degraded because of the fact that the conversion from to integer numbers is a round - off process and therefore it is natural to loose information due to such process .",
    "figure  [ fig : nn_cpp ] ( a ) and ( b ) show such effects in detail . the output of nn algorithm with integer - valued algorithm",
    "is shown in fig .",
    "[ fig : nn_cpp ] ( a ) .",
    "the power of the discrimination can be compared with fig .",
    "[ fig : input ] ( b ) where the real - valued nn output is plotted .",
    "one can see easily that the discrimination is significantly weaker in fig .",
    "[ fig : nn_cpp ] ( a ) .",
    "the correlation between the real - valued versus integer - valued neural computation outcome is shown in fig .  [",
    "fig : nn_cpp ] ( b ) .",
    "there is a strong positive correlation between two , indicating the integer - valued version of the nn performs well , but there are also cases where the resolution is smeared toward background - like patterns relative to the prediction from the real - valued version .",
    "we attribute the source of the degradation at this stage is purely the effect of round - off .    in order to explicitly study the effect of the number of bits in the discretization of the computation , the integer - valued nn with 10-bit resolution",
    "is implemented .",
    "[ fig : nn_cpp10 ] ( a ) shows the nn output from the signal and the background patterns when 10-bit resolution is used in the computation .",
    "the discrimination power is marginally improved compared with the 8-bit version , as expected .",
    "[ fig : nn_cpp10 ] ( b ) shows the correlation between the real - valued versus 10-bit version of the integer - valued neural computation .",
    "clearly , the correlation is significantly improved with the 10-bit computation , supporting the argument that there is a clear relation between the nn performance and the number of bits used .",
    "a quantitative study on the performance is also carried out .",
    "two sets of selection criteria are applied to the real - valued version , 10-bit , and 8-bit c++ programs mentioned above .",
    "the signal - to - background ratios are calculated for two different cuts : nn output @xmath11 0.5 and nn output @xmath11 0.7 to the real - valued nn output , and scaled cuts for integer - valued versions .",
    "results are summarized in table  [ table : nn ] . for two different selection criteria ,",
    "real - valued version consistently gives the best signal - to - background ratio values and are becoming worse when smaller number of bits are used in the integer - valued neural computation .",
    "these results are consistent with the qualitative arguments made when figures were discussed above .",
    "a hardware implementation of the nn algorithm based on previous studies is carried out for real online applications .",
    "the xilinx  @xcite spartan xc3s4000 is selected as a target fpga .",
    "this is chosen as it has large number of input and output pins , moderate size of random access memory ( ram ) blocks , and configurable logic blocks .",
    "for the hardware implementation , the same 5 - 6 - 1 nn structure is chosen and the c++ codes developed in the previous section is converted into very high speed integrated circuit hardware description language ( vhdl ) . it has less than 800 lines of vhdl codes and 8-bit wide bus signals are used in the network interconnections . in order to evaluate the activation function quickly",
    ", a look - up table is implemented using the 16-bit wide , 1,024 deep single - port block ram that is available in the spartan core . in order to reduce the resource of the given fpga for future larger networks ,",
    "the symmetry in the shape of the activation function is used , resulting in reducing the number of the look - up tables in the design by half .",
    "the total number of block rams used in the implementation is 7 in 5 - 6 - 1 network structure and this can easily fit in the target fpga .",
    "the amount of resources spent by the neural computation logic after the synthesis is well below 10 % including the block ram usage .",
    "several clocks are used in order to convert integer values from / to standard logic vectors , as least for the vhdl level simulation purpose . in total , there are 11 clocks required in order to produce the final nn output .",
    "this number can in principle be further reduced for the real time application by removing the conversion between integer and standard logic vectors used in the current vhdl for easier simulation .    in order to check the validity of implemented vhdl logic ,",
    "15,000 input patterns and nn output expectations from c++ program mentioned in the previous section are written to a text file .",
    "the 15,000 input patterns are fed into the vhdl logic using @xmath12 package included in the standard vhdl library .",
    "the vhdl level simulation for 15,000 patterns is carried out .",
    "the outputs are saved and their distributions are shown in fig .",
    "[ fig : nn_vhdl ] ( a ) .",
    "the performance is degraded from the 8-bit c++ based nn output , in particular for the left - hand side patterns for the background .",
    "the situation is also seen from the fig .",
    "[ fig : nn_vhdl ] ( b ) where the correlation between the nn output from the vhdl based versus c++ ( 8-bit ) based computation is compared .",
    "first of all , there is a perfect correlation between two cases , indicating an excellent agreement between two computations .",
    "detailed study shows that , for the diagonal patterns in fig .",
    "[ fig : nn_vhdl ] ( b ) , the spread of the difference is mostly zero and certainly within 3 bins out of in total 256 . however , there are also small fraction of patterns that are accumulated high tail of the vhdl based nn output but are populated in the signal - like region according to the c++ based nn output .",
    "the detailed bit - by - bit comparison study with our c++ program that runs over integer values reveals that the source of this behavior is out - of - range values in the integer - valued neural computation . to be more specific",
    ", one finds that for small fraction of events , the value of @xmath13 is not small enough to be represented with only 8 digits , and in this case , the final output from nn becomes meaningless .",
    "note that in the computation with the c++ program , such calculation is carried out with 32 digits as mentioned earlier .",
    "this effect is also observed in the last row of table  [ table : nn ] where the signal - to - noise for the vhdl based algorithm is reduced from the value for the 8-bit version of the c++ program .",
    "this can in principle be recovered by increasing the number of bits used in the internal networks , but it requires the increase of the block rams in a multiple of the number of hidden nodes so no further study is persued .",
    "a feed - forward artificial neural network algorithm is implemented based on the fpga technology .",
    "a 5 - 6 - 1 neural network is first trained with a high level language in a non - real time os environment , in order to perform rather complicated back propagation algorithm promptly . as an intermediate stage , a c++ program that computes the nn output with pure integers",
    "is written in order to understand the possible under - performance of the real hardware algorithm and to obtain faster debugging of the firmware development .",
    "it is found that the distretization process degrades the performance of the neural network algorithm .",
    "for the real hardware implementation , less than 800 lines of vhdl program is developed where the weights and thresholds are distretized into 8-bit wide integers and pre - stored in the program .",
    "the hardware level simulation shows that there is another source of the degradation in our implementation due to the finite size of the internal network lines during the hardware level nn computation that is unavoidable .",
    "nonetheless , we found that the implementation of a feed forward artificial neural network algorithm of three layers with less than 10 input nodes may be easily fit in moderate fpga chips available in the market .",
    "an application to the level 1 hardware trigger in a high energy physics experiment is planned .",
    "00 a. eide , th .",
    "lindblad , t. linden , and c. s. lindsey , nucl .",
    "instr . and meth . a * 368 * , 855 ( 1996 ) ; a. badala , r. barbera , g. lo re , a. palmeri , g. s. pappalardo , a. pulvirenti , and f. riggi , nucl .",
    "instr . and",
    "meth a * 502 * , 503 ( 2003 ) .",
    "the d  collaboration , phys .",
    "* 83 * 1908 ( 1999 ) .",
    "e. boos , l. dudko , and d. smirnov , nucl .",
    "instr . and",
    "meth a * 502 * , 486 ( 2003 ) .",
    "f. hakl , m. hlavacek , and r. kalous , nucl .",
    "instr . and",
    "meth a * 502 * , 489 ( 2003 ) .",
    "d. haas , m. steinacher , l. tauscher , s. vlachos , and m. wadhwa , nucl .",
    "instr . and",
    "meth a * 420 * , 101 ( 1999 ) .",
    "prevotet , b. denby , p. garda , b. granado , and c. kiesling , nucl .",
    "instr . and",
    "meth a * 502 * , 511 ( 2003 ) .",
    "f. r. leimgruber , p. pavopoulos , m. steinacher , l. tauscher , s. vlachos , and h. wendler , nucl .",
    "instr . and",
    "meth a * 365 * , 198 ( 1995 ) .",
    "hermann kolanoski , nucl .",
    "instr . and",
    "meth a * 367 * , 14 ( 1995 ) and references therein .",
    "j. hertz , a. krogh , and r. g. palmer , _ introduction to the theory of neural computation _",
    ", addison wesley ( 1991 ) . c. peterson and t. rognvaldsson , jetnet3.0 , cern - th.7135/94 ( 1994 ) .",
    "d. e. rumelhard , g. e. hinton , and r. j. williams , nature * 323 * , 533 ( 1986 ) .",
    "xilinx corporation , san jose , ca , usa .    .[table : nn ] signal - to - background ratios for the output of jetnet ( real - valued ) , c++ versions ( 10-bit and 8-bit ) , and vhdl ( 8-bit ) version .",
    "note that the selection cut values for 10 ( 8)-bit version are 512 and 716 ( 128 and 179 ) for nn output @xmath11 0.5 and nn output @xmath11 0.7 , respectively .",
    "[ cols=\"^,^,^ \" , ]      and @xmath14 ) and the nn output after the training are shown . in ( a ) ,",
    "the grey ( black)-colored points are signal ( background ) . in ( b ) , the distribution of the nn outputs are shown as solid and dashed histograms for the signal and background , respectively",
    ". , width=529 ]"
  ],
  "abstract_text": [
    "<S> an artificial neural network algorithm is implemented using a field programmable gate array hardware . </S>",
    "<S> one hidden layer is used in the feed - forward neural network structure in order to discriminate one class of patterns from the other class in real time . with five 8-bit input patterns , six hidden nodes , and one 8-bit output , </S>",
    "<S> the implemented hardware neural network makes decision on a set of input patterns in 11 clocks and the result is identical to what to expect from off - line computation . </S>",
    "<S> this implementation may be used in level 1 hardware triggers in high energy physics experiments .    artificial neural network , fpga , vhdl , level 1 trigger 07.05.mh </S>"
  ]
}