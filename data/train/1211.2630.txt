{
  "article_text": [
    "recently , there has been increasing interest in analyzing on - line auction data and in inferring the underlying dynamics that drive the bidding process .",
    "each series of price bids for a given auction corresponds to pairs of random bidding times and corresponding bid prices generated whenever a bidder places a bid [ jank and shmueli ( @xcite , @xcite ) , @xcite , @xcite ] .",
    "related longitudinal data where similar sparsely and irregularly sampled noisy measurements are obtained are abundant in the social and life sciences ; for example , they arise in longitudinal growth studies . while more traditional approaches of functional data analysis require",
    "fully or at least densely observed trajectories [ @xcite , @xcite , @xcite ] , more recent extensions cover the case of sparsely observed and noise - contaminated longitudinal data [ @xcite , @xcite ] .",
    "a common assumption of approaches for longitudinal data grounded in functional data analysis is that such data are generated by an underlying smooth and square integrable stochastic process [ @xcite , @xcite , @xcite , @xcite , @xcite ] .",
    "the derivatives of the trajectories of such processes are central for assessing the dynamics of the underlying processes [ @xcite , @xcite ] .",
    "although this is difficult for sparsely recorded data , various approaches for estimating derivatives of individual trajectories nonparametrically by pooling data from samples of curves and using these derivatives for quantifying the underlying dynamics have been developed [ @xcite , @xcite , @xcite , @xcite ] .",
    "related work on nonparametric methods for derivative estimation can be found in @xcite , @xcite and on the role of derivatives for the functional linear model in @xcite .",
    "we expand here on some of these approaches and investigate an empirical dynamic equation .",
    "this equation is distinguished from previous models that involve differential equations in that it is empirically determined from a sample of trajectories , and does not presuppose knowledge of a specific parametric form of a differential equation which generates the data , except that we choose it to be a first order equation .",
    "this stands in contrast to current approaches of modeling dynamic systems , which are `` parametric '' in the sense that a prespecified differential equation is assumed .",
    "a typical example for such an approach has been developed by @xcite , where a prior specification of a differential equation is used to guide the modeling of the data , which is done primarily for just one observed trajectory .",
    "a problem with parametric approaches is that diagnostic tools to determine whether these equations fit the data either do not exist , or where they do , are not widely used , especially as nonparametric alternatives to derive differential equations have not been available .",
    "this applies especially to the case where one has data on many time courses available , providing strong motivation to explore nonparametric approaches to quantify dynamics .",
    "our starting point is a nonparametric approach to derivative estimation by local polynomial fitting of the derivative of the mean function and of partial derivatives of the covariance function of the process by pooling data across all subjects [ @xcite ] .",
    "we show that each trajectory satisfies a first order stochastic differential equation where the random part of the equation resides in an additive smooth drift process which drives the equation ; the size of the variance of this process determines to what extent the time evolution of a specific trajectory is determined by the nonrandom part of the equation over various time subdomains , and therefore is of tantamount interest .",
    "we quantify the size of the drift process by its variance as a function of time .",
    "whenever the variance of the drift process @xmath0 is small relative to the variance of the process @xmath1 , a deterministic version of the differential equation is particularly useful as it then explains a large fraction of the variance of the process .",
    "the empirical stochastic differential equation can be easily obtained for various types of longitudinal data .",
    "this approach thus provides a novel perspective to assess the dynamics of longitudinal data and permits insights about the underlying forces that shape the processes generating the observations , which would be hard to obtain with other methods .",
    "we illustrate these empirical dynamics by constructing the stochastic differential equations that govern online auctions with sporadic bidding patterns .",
    "we now describe a data model for longitudinally collected observations , which reflects that the data consist of sparse , irregular and noise - corrupted measurements of an underlying smooth random trajectory for each subject or experimental unit [ @xcite ] , the dynamics of which is of interest .",
    "given @xmath2 realizations @xmath3 of the underlying process @xmath1 on a domain @xmath4 and @xmath5 of an integer - valued bounded random variable @xmath6 , we assume that @xmath5 measurements @xmath7 , @xmath8 , are obtained at random times @xmath9 , according to @xmath10 where @xmath11 are zero mean i.i.d .",
    "measurement errors , with @xmath12 , independent of all other random components .",
    "the paper is organized as follows . in section  [ sec2 ] ,",
    "we review expansions in eigenfunctions and functional principal components , which we use directly as the basic tool for dimension reduction  alternative implementations with b - splines or p - splines could also be considered [ @xcite , @xcite , @xcite ] .",
    "we also introduce the empirical stochastic differential equation and discuss the decomposition of variance it entails .",
    "asymptotic properties of estimates for the components of the differential equation , including variance function of the drift process , coefficient of determination associated with the dynamic system and auxiliary results on improved rates of convergence for eigenfunction derivatives are the theme of section  [ sec3 ] .",
    "background on related perturbation results can be found in @xcite , @xcite , @xcite , @xcite .",
    "section  [ sec4 ] contains the illustration of the differential equation with auction data , followed by a brief discussion of some salient features of the proposed approach in section [ sec5 ] .",
    "additional discussion of some preliminary formulas is provided in appendix  [ seca1 ] , estimation procedures are described in appendix  [ seca2 ] , assumptions and auxiliary results are in appendix  [ seca3 ] and proofs in appendix  [ seca4 ] .",
    "@xmath13a  key methodology for dimension reduction and modeling of the underlying stochastic processes @xmath1 that generate the longitudinal data , which usually are sparse , irregular and noisy as in ( [ kl2 ] ) , is functional principal component analysis ( fpca ) .",
    "processes are assumed to be square integrable with mean function @xmath14 and auto - covariance function @xmath15 , @xmath16 , which is smooth , symmetric and nonnegative definite . using @xmath17 as kernel in a linear operator leads to the hilbert ",
    "schmidt operator @xmath18 .",
    "we denote the ordered eigenvalues ( in declining order ) of this operator by @xmath19 and the corresponding orthonormal eigenfunctions by @xmath20 .",
    "we assume that all eigenvalues are of multiplicity @xmath21 in the sequel .",
    "it is well known that the kernel @xmath17 has the representation @xmath22 and the trajectories generated by the process satisfy the karhunen ",
    "love representation [ @xcite ] @xmath23 . here",
    "the @xmath24 , @xmath25 @xmath26 , are the functional principal components ( fpcs ) of the random trajectories @xmath3 .",
    "the @xmath27 are uncorrelated random variables with @xmath28 and @xmath29 , with @xmath30 . upon differentiating both sides ,",
    "one obtains @xmath31 where @xmath32 and @xmath33 are the derivatives of mean and eigenfunctions .",
    "the eigenfunctions @xmath34 are the solutions of the eigen - equations @xmath35 , under the constraint of orthonormality . under suitable regularity conditions",
    ", one observes @xmath36\\\\[-8pt ] \\phi_k^{(1)}(t ) & = & \\frac{1}{\\lambda_k}\\int_{{\\mathcal{t } } } \\frac{\\partial}{\\partial t}\\,g(t , s)\\phi_k(s)\\,ds,\\nonumber\\end{aligned}\\ ] ] which motivates corresponding eigenfunction derivative estimates",
    ". a useful representation is @xmath37\\\\[-8pt ] \\eqntext{\\nu_1 , \\nu_2 \\in\\{0,1\\ } , s , t \\in{\\mathcal{t}},}\\end{aligned}\\ ] ] which is an immediate consequence of the basic properties of the functional principal components @xmath27 . for more details and discussion",
    ", we refer to appendix  [ seca1 ] .",
    "it is worthwhile to note that the representation ( [ kl3 ] ) does not correspond to the karhunen ",
    "love representation of the derivatives , which would be based on orthonormal eigenfunctions of a linear hilbert ",
    "schmidt operator defined by the covariance kernel @xmath38 .",
    "a method to obtain this representation might proceed by first estimating @xmath39 using ( [ rep ] ) for @xmath40 and suitable estimates @xmath41 for eigenfunction derivatives , then directly decomposing @xmath39 into eigenfunctions and eigenvalues .",
    "this leads to @xmath42 and the karhunen ",
    "love representation @xmath43 , with orthonormal eigenfunctions @xmath44 [ @xcite ] .      in the following we consider differentiable gaussian processes , for which the differential equation introduced below automatically applies . in the absence of the gaussian assumption",
    ", one may invoke an alternative least squares - type interpretation .",
    "gaussianity of the processes implies the joint normality of centered processes @xmath45 at all points @xmath46 , so that @xmath47    this joint normality immediately implies a `` population '' differential equation of the form @xmath48 , as has been observed in @xcite ; for additional details see appendix  [ seca1 ] . however , it is considerably more interesting to find a dynamic equation which applies to the individual trajectories of processes @xmath1 .",
    "this goal necessitates inclusion of a stochastic term which leads to an empirical stochastic differential equation that governs the dynamics of individual trajectories @xmath3 .",
    "[ thm1 ] for a differentiable gaussian process , it holds that @xmath49 where @xmath50\\\\[-8pt ] & = & \\frac{1}{2}\\frac{d}{dt}\\log[{\\operatorname{var}}\\{x(t)\\}],\\qquad t\\in{\\mathcal{t}},\\nonumber\\end{aligned}\\ ] ] and @xmath0 is a gaussian process such that @xmath51 are independent at each @xmath52 and where @xmath0 is characterized by @xmath53 and @xmath54 , with @xmath55\\\\[-8pt ] & & { } - \\beta(s)\\sum_{k=1}^\\infty\\lambda_k\\phi^{(1)}_k(t ) \\phi_k(s ) + \\beta(t)\\beta(s)\\sum_{k=1}^\\infty\\lambda_k\\phi_k(t ) \\phi_k(s).\\nonumber\\end{aligned}\\ ] ]    equation ( [ de ] ) provides a first order linear differential equation which includes a time - varying linear coefficient function @xmath56 and a random drift process @xmath57 .",
    "the process @xmath0 `` drives '' the equation at each time @xmath58 .",
    "it is square integrable and possesses a smooth covariance function and smooth trajectories .",
    "it also provides an alternative characterization of the individual trajectories of the process .",
    "the size of its variance function @xmath59 determines the importance of the role of the stochastic drift component .",
    "we note that the assumption of differentiability of the process @xmath1 in theorem  [ thm1 ] can be relaxed .",
    "it is sufficient to require weak differentiability , assuming that @xmath60 , where @xmath61 denotes the sobolev space of square integrable functions with square integrable weak derivative [ @xcite ] . along these lines ,",
    "equation ( [ de ] ) may be interpreted as a stochastic sobolev embedding .",
    "observe also that the drift term @xmath0 can be represented as an integrated diffusion process . upon combining ( [ kl3 ] ) and",
    "( [ de ] ) , and observing that functional principal components can be represented as @xmath62 , where @xmath63 is the @xmath64th eigenfunction of the wiener process @xmath65 on domain @xmath66 $ ] and @xmath67 the associated eigenvalue , such a representation is given by @xmath68    another observation is that the joint normality in ( [ jt ] ) can be extended to joint normality for any finite number of derivatives , assuming these are well defined .",
    "therefore , higher order stochastic differential equations can be derived analogously to ( [ de ] ) . however , these higher - order analogues are likely to be much less relevant practically , as higher - order derivatives of mean and eigenfunctions can not be well estimated for the case of sparse noisy data or even denser noisy data .",
    "finally , it is easy to see that the differential equation ( [ de ] ) is equivalent to the following stochastic integral equation : @xmath69 in the sense that @xmath1 is the solution of both equations . for a domain with left endpoint at time",
    "@xmath70 , setting @xmath71 in ( [ int ] ) then defines a classical initial value problem .",
    "given a trajectory of the drift process @xmath0 and a varying coefficient function @xmath72 , one may obtain a solution for @xmath1 numerically by euler or runga  kutta integration or directly by applying the known solution formula for the initial value problem of an inhomogeneous linear differential equation .",
    "we note that equations ( [ de ] ) and ( [ int ] ) are of particular interest on domains @xmath4 or subdomains defined by those times @xmath58 for which the variance function @xmath73 is `` small . '' from ( [ beta ] ) and ( [ gz ] ) one finds @xmath74 ^ 2}\\bigr)/{\\operatorname{var}}\\{x(t)\\}\\nonumber\\\\[-8pt]\\\\[-8pt ] & = & \\biggl(\\sum_{k=1}^\\infty\\lambda_k\\bigl(\\phi_k^{(1)}(t)\\bigr)^2 \\sum_{k=1}^\\infty\\lambda_k \\phi_k^2(t ) - \\biggl\\{\\sum_{k=1}^\\infty\\lambda_k\\phi_k^{(1)}(t ) \\phi_k(t ) \\biggr\\}^2 \\biggr)\\nonumber\\\\ & & { } \\bigg/\\sum_{k=1}^\\infty \\lambda_k\\phi_k^2(t).\\nonumber\\end{aligned}\\ ] ] on subdomains with small variance function , the solutions of ( [ de ] ) will not deviate too much from the solutions of the approximating equation @xmath75 in this situation , the future changes in value of individual trajectories are highly predictable and the interpretations of the dynamic behavior of processes @xmath1 obtained from the shape of the varying coefficient function @xmath56 apply at the individual level .",
    "if @xmath76 , the dynamic behavior can be characterized as `` dynamic regression to the mean '' ; a trajectory which is away from ( above or below ) the mean function @xmath77 at time @xmath58 is bound to move closer toward the mean function @xmath77 as time progresses beyond @xmath58 .",
    "similarly , if @xmath78 , trajectories will exhibit `` explosive '' behavior , since deviations from the mean ( above or below ) at time @xmath58 will be reinforced further as time progresses , so that trajectories are bound to move further and further away from the population mean trajectory .",
    "intermediate cases arise when the function @xmath72 changes sign , in which case the behavior will switch between explosive and regression to the mean , depending on the time subdomain .",
    "another situation occurs on subdomains where both @xmath72 and @xmath59 are very small , in which case the deviation of the derivative of an individual trajectory from the population mean derivative will also be small which means that trajectory derivatives will closely track the population mean derivative on such subdomains .",
    "the independence of @xmath57 and @xmath79 means that the right - hand side of ( [ de ] ) provides an orthogonal decomposition of @xmath80 into the two components @xmath81 and @xmath57 such that @xmath82 it is therefore of interest to determine the fraction of the variance of @xmath80 that is explained by the differential equation itself , that is , the `` coefficient of determination '' @xmath83 which is seen to be equivalent to the squared correlation between @xmath84 , @xmath85 ^ 2}{{\\operatorname{var}}\\{x(t)\\}{\\operatorname{var}}\\ { x^{(1)}(t)\\}}= \\frac{\\{\\sum_{k=1}^\\infty\\lambda_k\\phi_k^{(1)}(t ) \\phi_k(t)\\}^2}{\\sum_{k=1}^\\infty \\lambda_k\\phi_k(t)^2 \\sum_{k=1}^\\infty \\lambda_k\\phi_k^{(1)}(t)^2}.\\ ] ]    we are then particularly interested in subdomains of @xmath4 where @xmath86 is large , say , exceeds a prespecified threshold of 0.8 or 0.9 . on such subdomains",
    "the drift process @xmath0 is relatively small compared to @xmath80 so that the approximating deterministic first order linear differential equation ( [ approx ] ) can substitute for the stochastic dynamic equation ( [ de ] ) . in this case",
    ", short - term prediction of @xmath87 may be possible for small @xmath88 , by directly perusing the approximating differential equation  ( [ approx ] ) .",
    "it is instructive to visualize an example of the function @xmath86 for the case of fully specified eigenfunctions and eigenvalues . assuming that the eigenfunctions correspond to the trigonometric orthonormal system @xmath89 on @xmath90 $ ]",
    ", we find from ( [ r2 ] ) @xmath91 ^ 2\\\\ & & { } \\big/ \\bigl[\\sum\\lambda_k ( \\cos",
    "( 2k\\pi t))^2 \\sum\\lambda_k k ( \\sin(2k\\pi t))^2 \\bigr],\\qquad t \\in [ 0,1].\\end{aligned}\\ ] ] choosing @xmath92 and numerically approximating these sums , one obtains the functions @xmath86 as depicted in figure  [ rfig ] .",
    "this illustration shows     ( [ r1 ] ) , ( [ r2 ] ) , quantifying the fraction of variance explained by the deterministic part of the dynamic equation ( [ de ] ) , illustrated for the trigonometric basis @xmath93 on @xmath90 $ ] and eigenvalue sequences @xmath94 ( solid ) and @xmath95 ( dashed ) . ]    that the behavior of this function often will fluctuate between small and large values and also depends critically on both the eigenvalues and the shape of the eigenfunctions .",
    "we obtain asymptotic consistency results for estimators of the varying coefficient functions @xmath72 , for the variance function @xmath73 of the drift process and for the variance explained at time @xmath58 by the deterministic part ( [ approx ] ) of the stochastic equation ( [ de ] ) , quantified by @xmath86 .",
    "corresponding estimators result from plugging in estimators for the eigenvalues @xmath96 , eigenfunctions @xmath34 and eigenfunction derivatives @xmath41 into the representations ( [ beta ] ) for the function @xmath56 , ( [ v ] ) for the variance function of @xmath0 and ( [ r2 ] ) for @xmath86 . here",
    "one needs to truncate the expansions at a finite number @xmath97 of included eigen - components .",
    "details about the estimation procedures , which are based on local linear smoothing of one- and two - dimensional functions , are deferred to appendix  [ seca2 ] .",
    "our asymptotic consistency results focus on @xmath98 convergence rates .",
    "they peruse auxiliary results on the convergence of estimates of eigenvalues , eigenfunctions and eigenfunction derivatives , complementing and improving upon related results of @xcite , which were derived for convergence in the sup norm .",
    "improved rates of convergence in the @xmath98 distance are the consequence of a special decomposition that we employ in the proofs to overcome the difficulty caused by the dependence of the repeated measurements .",
    "required regularity conditions include assumptions for the distribution of the design points , behavior of eigenfunctions @xmath34 and eigenvalues @xmath96 as their order @xmath64 increases and the large sample behavior of the bandwidths @xmath99 for the estimation of the mean function @xmath77 and its first derivative @xmath32 , and @xmath100 for the estimation of the covariance surface and its partial derivative .",
    "we note that extremely sparse designs are covered , with only two measurements per trajectory ; besides being bounded , the number of measurements @xmath5 for the @xmath101th trajectory is required to satisfy @xmath102 .",
    "specifically , for the observations @xmath103 , @xmath104 , @xmath105 , made for the @xmath101th trajectory , we require that :    1 .",
    "@xmath5 are random variables with @xmath106 , where @xmath6 is a bounded positive discrete random variable with and @xmath107 , and @xmath108 are independent of @xmath5 , for @xmath109 .",
    "writing @xmath110 and @xmath111 , the triples @xmath112 are assumed to be i.i.d . for the bandwidths used in the smoothing steps for @xmath113 and @xmath32 in ( [ smooth1 ] ) , @xmath114 and @xmath115 in ( [ smooth2 ] ) , we require that , as @xmath116 ,    1 .",
    "@xmath117 , @xmath118 , @xmath119 , @xmath120 , @xmath121 .    to characterize the behavior of estimated eigenfunction derivatives @xmath122 , define @xmath123 for",
    "the kernels used in the local linear smoothing steps and underlying density and moment functions , we require assumptions ( b1 ) and ( b2 ) in the . denote the @xmath98 norm by @xmath124 , the hilbert ",
    "schmidt norm by @xmath125 and also define @xmath126 .",
    "the following result provides asymptotic rates of convergence in the @xmath98 norm for the auxiliary estimates of mean functions and their derivatives as well as covariance functions and their partial derivatives , which are briefly discussed in appendix  [ seca2 ] .",
    "a consequence is a convergence result for the eigenfunction derivative estimates @xmath127 , with constants and rates that hold uniformly in the order @xmath128 .    [ thm2 ] under and and , for @xmath129 , @xmath130\\\\[-8pt ] \\bigl\\|\\hat{g}^{(\\nu,0)}-g^{(\\nu,0)}\\bigr\\|_s & = & o_p \\biggl(\\frac{1}{\\sqrt { n}h_{g,\\nu}^{\\nu+1}}+h_{g,\\nu}^2 \\biggr).\\nonumber\\end{aligned}\\ ] ] for @xmath131 corresponding to @xmath96 of multiplicity @xmath21 , @xmath132\\\\[-8pt ] & & \\qquad = o_p \\biggl(\\frac { 1}{\\lambda_k } \\biggl\\{\\frac{1}{\\sqrt{n}h_{g , 1}^{2}}+h_{g,1}^2+\\frac{1}{\\delta_k } \\biggl(\\frac{1}{\\sqrt{n}h_{g , 0}}+h_{g,0}^2 \\biggr ) \\biggr\\ } \\biggr),\\nonumber\\end{aligned}\\ ] ] where the @xmath133 term in ( [ thm2-eq2 ] ) is uniform in @xmath128 .",
    "an additional requirement is that variances of processes @xmath1 and @xmath134 are bounded above and below , since these appear in the denominators of various representations , for example , in ( [ v ] ) and ( [ r2 ] ) ,    1 .   @xmath135 and @xmath136 for @xmath137 ,",
    "implying that @xmath138 by the cauchy ",
    "schwarz inequality .",
    "define remainder terms @xmath139 by the cauchy ",
    "schwarz inequality , @xmath140 .    in order to obtain consistent estimates of various quantities ,",
    "a necessary requirement is that the first @xmath141 eigen - terms approximate the infinite - dimensional process sufficiently well .",
    "the increase in the sequence @xmath97 as @xmath142 therefore needs to be tied to the spacing and decay of eigenvalues ,    1 .",
    "@xmath143 k&=&o\\bigl(\\min\\bigl\\{\\sqrt{n}h_{g,1}^{2 } , h_{g,1}^{-2}\\bigr\\}\\bigr),\\\\ \\sum_{k=1}^k \\delta_k^{-1}&=&o\\bigl(\\min\\bigl(\\sqrt{n}h_{g,0 } , h_{g,0}^{-2}\\bigr\\}\\bigr),\\\\ \\max_{\\nu=0 , 1}\\|r_{k , \\nu}\\|&\\rightarrow&0\\qquad\\mbox{as $ n\\rightarrow \\infty$.}\\end{aligned}\\ ] ]    if the eigenvalues decrease rapidly and merely a few leading terms are needed , condition ( a4 ) is easily satisfied .",
    "we use `` @xmath144 '' to connect two terms which are asymptotically of the same order in probability , that is , the terms are @xmath145 of each other .",
    "define the sequence @xmath146    note that @xmath147 with corresponding plug - in estimate @xmath148 , where @xmath97 is the included number of eigenfunctions .",
    "the plug - in estimate for @xmath56 is based on ( [ beta ] ) and given by @xmath149 and analogously the plug - in estimate @xmath150 of @xmath151 is based on representation  ( [ gz ] ) , using the estimate @xmath152 . in a completely analogous fashion one obtains the estimates @xmath153 of @xmath86 from ( [ r2 ] ) and @xmath154 of the variance function @xmath155 of the drift process from ( [ v ] ) .",
    "the @xmath98 convergence rates of these estimators of various components of the dynamic model ( [ de ] ) are given in the following result .",
    "[ thm3 ] under and , @xmath156\\\\[-8pt ] \\bigl\\|\\hat{g}_k^{(1,1)}-g^{(1,1)}\\bigr\\|_u&=&o_p(\\alpha_n+\\|r_{k,1}\\| ) , \\nonumber\\\\ \\|\\hat{\\beta}_k-\\beta\\| & \\stackrel{p}{\\asymp } & \\|\\hat{g}_{z , k}- g_z\\|_s \\stackrel{p}{\\asymp } \\|\\hat{g}_{z , k}-g_z\\|_u\\nonumber\\\\ \\label{thm3-eq2 } & \\stackrel{p}{\\asymp } & \\|\\hat{r}^2_k - r^2\\| \\stackrel{p}{\\asymp } \\|\\hat{v}_k - v\\| \\\\ & = & o_p(\\alpha_n+\\|r_{k,0}\\|+\\|r_{k,1}\\|).\\nonumber\\end{aligned}\\ ] ]    the weak convergence and @xmath98 consistency for the estimated eigenvalues @xmath157 and eigenfunctions @xmath158 of the drift process @xmath0 is an immediate consequence of this result . to see this",
    ", one may use @xmath159 where @xmath160 is any estimate of @xmath151 [ @xcite ] . here",
    "the @xmath133 terms are uniform in @xmath64 and @xmath161 for @xmath162 .",
    "to illustrate our methods , we analyze the dynamic system corresponding to online auction data , specifically using ebay bidding data for 156 online auctions of palm personal digital assistants in 2003 ( courtesy of wolfgang jank ) .",
    "the data are `` live bids '' that are entered by bidders at irregular times and correspond to the actual price a winning bidder would pay for the item .",
    "this price is usually lower than the `` willingness - to - pay '' price , which is the value a bidder enters .",
    "further details regarding the proxy bidding mechanism for the 7-day second - price auction design that applies to these data can be found in jank and shmueli ( @xcite , @xcite ) , liu and mller ( @xcite , @xcite ) .",
    "the time unit of these 7-day auctions is hours and the domain is the interval @xmath163 $ ] . adopting the customary approach ,",
    "the bid prices are log - transformed prior to the analysis .",
    "the values of the live bids @xmath7 are sampled at bid arrival times @xmath9 , where @xmath164 refers to the auction index and @xmath165 to the total number of bids submitted during the @xmath101th auction ; the number of bids per auction is found to be between 6 and 49 for these data .",
    "we adopt the point of view that the observed bid prices result from an underlying price process which is smooth , where the bids themselves are subject to small random aberrations around underlying continuous trajectories .",
    "since there is substantial variability of little interest in both bids and price curves during the first three days of an auction , when bid prices start to increase rapidly from a very low starting point to more realistic levels , we restrict our analysis to the interval [ @xmath166 ( in hours ) , thus omitting the first three days of bidding .",
    "this allows us to focus on the more interesting dynamics in the price curves taking place during the last four days of these auctions .",
    "our aim is to explore the price dynamics through the empirical stochastic differential equation ( [ de ] ) .",
    "our study emphasizes description of the dynamics over prediction of future auction prices and consists of two parts : a description of the dynamics of the price process at the `` population level '' which focuses on patterns and trends in the population average and is reflected by dynamic equations for conditional expectations .",
    "the second and major results concern the quantification of the dynamics of auctions at the individual or `` auction - specific level '' where one studies the dynamic behavior for each auction separately , but uses the information gained across the entire sample of auctions .",
    "only the latter analysis involves the stochastic drift term @xmath0 in the stochastic differential equation ( [ de ] ) .",
    "we begin by reviewing the population level analysis , which is characterized by the deterministic part of ( [ de ] ) , corresponding to the equation @xmath167 .",
    "this equation describes a relationship that holds for conditional means but not necessarily for individual trajectories .    for the population level analysis",
    ", we require estimates of the mean price curve @xmath77 and its first derivative @xmath168 , and these are obtained by applying linear smoothers to ( [ smooth1 ] ) to the pooled scatterplots that are displayed in figure  [ auc - mu ] ( for more details , see appendix  [ seca2 ] ) .",
    "one finds that both log prices and log price derivatives are increasing throughout , so that at the log - scale the price increases are accelerating in the mean as the auctions proceed .",
    "( left panel ) and of their derivatives ( right panel ) , @xmath169 ( solid ) , @xmath170 ( dashed ) and @xmath171 ( dash - dotted ) . ]    a second ingredient for our analysis are estimates for the eigenfunctions and eigenvalues ( details in appendix  [ seca2 ] ) .",
    "since the first three eigenfunctions were found to explain 84.3% , 14.6% and 1.1% of the total variance , three components were selected .",
    "the eigenfunction estimates are shown in the left panel of figure  [ auc - xeig ] , along with the estimates of the corresponding eigenfunction derivatives in the right panel . for the interpretation of the eigenfunctions",
    "it is helpful to note that the sign of the eigenfunctions is arbitrary .",
    "we also note that variation in the direction of the first eigenfunction @xmath172 corresponds to the major part of the variance .",
    "the variances @xmath173 that are attributable to this eigenfunction are seen to steadily decrease as @xmath58 is increasing , so that this eigenfunction represents a strong trend of higher earlier and smaller later variance in the log price trajectories .",
    "the contrast between large variance of the trajectories at earlier times and smaller variances later reflects the fact that auction price trajectories are less determined early on when both relatively high as well as low prices are observed , while at later stages prices differ less as the end of the auction is approached and prices are constrained into a narrower range .",
    "correspondingly , the first eigenfunction derivative is steadily increasing ( decreasing if the sign is switched ) , with notably larger increases ( decreases ) both at the beginning and at the end and a relatively flat positive plateau in the middle part .",
    "the second eigenfunction corresponds to a contrast between trajectory levels during the earlier and the later part of the domain , as is indicated by its steady increase and the sign change , followed by a slight decrease at the very end .",
    "this component thus reflects a negative correlation between early and late log price levels .",
    "the corresponding derivative is positive and flat , with a decline and negativity toward the right endpoint .",
    "the third eigenfunction , explaining only a small fraction of the overall variance , reflects a more complex contrast between early and late phases on one hand and a middle period on the other , with equally more complex behavior reflected in the first derivative .",
    "the eigenfunctions and their derivatives in conjunction with the eigenvalues determine the varying coefficient function @xmath72 , according to ( [ beta ] ) .",
    "the estimate of this function is obtained by plugging in the estimates for these quantities and is visualized in the left panel of figure  [ auc - beta - zeig ] , demonstrating small negative values for the function @xmath72 throughout most of the domain , with a sharp dip of the function into the negative realm near the right end of the auctions .    for subdomains of functional data , where the varying coefficient or `` dynamic transfer '' function @xmath72 is negative , as is the case for the auction data throughout the entire time domain",
    ", one may interpret the population equation @xmath174 as indicating `` dynamic regression to the mean . '' by this we mean the following : when a trajectory value at a current time @xmath58 falls above ( resp .",
    ", below ) the population mean trajectory value at @xmath58 , then the conditional mean derivative of the trajectory at @xmath58 falls below ( resp . ,",
    "above ) the mean .",
    "the overall effect of this negative association is that the direction of the derivative is such that trajectories tend to move toward the overall population mean trajectory as time progresses .    .",
    "]    thus , our findings for the auction data indicate that `` dynamic regression to the mean '' takes place to a small extent throughout the auction period and to a larger extent near the right tail , at the time when the final auction price is determined [ see also @xcite ] .",
    "one interpretation is that at the population level , prices are self - stabilizing , which tends to prevent price trajectories running away toward levels way above or below the mean trajectory .",
    "this self - stabilization feature gets stronger toward the end of the auction , where the actual `` value '' of the item that is being auctioned serves as a strong homogenizing influence .",
    "this means that in a situation where the current price level appears particularly attractive , the expectation is that the current price derivative is much higher than for an auction with an unattractive ( from the perspective of a buyer ) current price , for which then the corresponding current price derivative is likely lower .",
    "the net effect is a trend for log price trajectories to regress to the mean trajectory as time progresses .",
    "we illustrate here the proposed stochastic differential equation ( [ de ] ) . first estimating the function @xmath72",
    ", we obtain the trajectories @xmath175 of the drift process .",
    "these trajectories are presented in figure  [ auc - z ] for the entire sample of auctions .",
    "they quantify the component of the derivative process @xmath134 that is left unexplained by the varying coefficient function and linear part of the dynamic model ( [ de ] ) .",
    "the trajectories @xmath175 exhibit fluctuating variances across various subdomains .",
    "the subdomains for which these variances are small are those where the deterministic approximation ( [ approx ] ) to the stochastic differential equation works best .",
    "it is noteworthy that the variance is particularly small on the subdomain starting at around 158 hours toward the endpoint of the auction at 168  hours , since auction dynamics are of most interest during these last hours .",
    "it is well known that toward the end of the auctions , intensive bidding takes place , in some cases referred to as `` bid sniping , '' where bidders work each other into a frenzy to outbid each other in order to secure the item that is auctioned .    .",
    "right : smooth estimates of the first ( solid ) , second ( dashed ) and third ( dash - dotted ) eigenfunction of @xmath0 based on ( [ gz ] ) . ]",
    "the right panel of figure  [ auc - beta - zeig ] shows the first three eigenfunctions of @xmath0 , which are derived from the eigenequations derived from estimates @xmath150 of covariance kernels @xmath176 ( [ gz ] ) that are obtained as described after ( [ smooth2 ] ) . in accordance with the visual impression of the trajectories of @xmath0 in figure  [ auc - z ] ,",
    "the first eigenfunction reflects maximum variance in the middle portion of the domain and very low variance at both ends .",
    "interestingly , the second eigenfunction reflects high variance at the left end of the domain where prices are still moving upward quite rapidly , and very low variance near the end of the auction .",
    "this confirms that overall variation is large in the middle portion of the auctions , so that the drift process in ( [ de ] ) plays an important role in that period .",
    "further explorations of the modes of variation of the drift process @xmath0 can be based on the functional principal component scores of @xmath175 .",
    "following @xcite , we identify the three auctions with the largest absolute values of the scores .",
    "a scatterplot of second and first principal component scores with these auctions highlighted can be seen in the left upper panel of figure  [ auc - zscore - ext ] .",
    "the corresponding individual ( centered ) trajectories of the drift process @xmath0 are in the right upper panel , and the corresponding trajectories of centered processes @xmath1 and @xmath134 in the left and right lower panels .",
    "the highlighted trajectories of @xmath0 are indeed similar to the corresponding eigenfunctions ( up to sign changes ) , and we find that they all exhibit the typical features of small variance near the end of the auction for @xmath0 and @xmath1 and of large variance for @xmath134 .    , where the point marked by a circle corresponds to the auction with the largest ( in absolute value ) first score , the point marked with a square to the auction with the largest second score and the point marked with a `` triangle '' to the auction with the largest third score , respectively .",
    "top right : the trajectories @xmath175 of the drift process for these three auctions , where the solid curve corresponds to the trajectory of the `` circle '' auction , the dashed curve to the `` square '' auction and the dash - dotted curve to the `` triangle '' auction .",
    "bottom left : corresponding centered trajectories @xmath3 .",
    "bottom right : corresponding centered trajectory derivatives @xmath177 . ]    for the two trajectories corresponding to maximal scores for first and second eigenfunction of @xmath0 we find that near the end of the auctions their centered derivatives turn negative .",
    "this is in line with dynamic regression to the mean , or equivalently , negative varying coefficient function @xmath72 , as described in section  [ sec41 ] . here",
    "the trajectories for @xmath1 at a current time @xmath58 are above the mean trajectory , which means the item is pricier than the average price at @xmath58 . as predicted by dynamic regression to the mean , log price derivative trajectories at @xmath58 are indeed seen to be below the mean derivative trajectories at @xmath58 .",
    "the trajectory corresponding to maximal score for the third eigenfunction also follows dynamic regression to the mean : here the trajectory for @xmath1 is below the overall mean trajectory , so that the negative varying coefficient function @xmath72 predicts that the derivative trajectory @xmath134 should be above the mean , which indeed is the case .",
    "( dashed ) and @xmath57 ( solid ) .",
    "right : smooth estimate of @xmath86 ( [ r1 ] ) , the variance explained by the deterministic part of the dynamic equation at time @xmath58 . ]    that the variance of the drift process @xmath0 is small near the endpoint of the auction is also evident from the estimated variance function @xmath155 in the left panel of figure [ auc - var - r2 ] , overlaid with the estimated variance function @xmath178 of  @xmath134 .",
    "the latter is rapidly increasing toward the end of the auction , indicating that the variance of the derivative process is very large near the auction s end .",
    "this means that price increases vary substantially near the end across auctions .",
    "the large variances of derivatives coupled with the fact that @xmath59 is small near the end of the auction implies that the deterministic part ( [ approx ] ) of the empirical differential equation ( [ de ] ) explains a very high fraction of the variance in the data .",
    "this corresponds to a very high , indeed close to the upper bound 1 , value of the coefficient of determination @xmath86 ( [ r1 ] ) , ( [ r2 ] ) in an interval of about 10 hours before the endpoint of an auction , as seen in the right panel of figure  [ auc - var - r2 ] .",
    "we therefore find that the dynamics during the endrun of an auction can be adequately modeled by the simple deterministic approximation ( [ approx ] ) to the stochastic dynamic equation ( [ de ] ) , which always applies .",
    "this finding is corroborated by visualizing the regressions of @xmath80 versus @xmath79 at various fixed times @xmath58 .",
    "these regressions are linear in the gaussian case and may be approximated by a linear regression in the least squares sense in the non - gaussian case .",
    "the scatterplots of @xmath179 versus @xmath180 for times @xmath181 hours and @xmath182 hours ( where the time domain of the auctions is between 0 and 168 hours ) are displayed in figure  [ auc - reg ] .",
    "this reveals the relationships to be indeed very close to linear .",
    "these are regressions through the origin .",
    "the regression slope parameters are not estimated from these scatterplot data which are contaminated by noise , but rather are obtained directly from ( [ de ] ) , as they correspond to @xmath56 .",
    "thus one simply may use the already available slope estimates , @xmath183 and @xmath184 .",
    "the associated coefficients of determination , also directly estimated via ( [ r2 ] ) and the corresponding estimation procedure , are found to be @xmath185 and @xmath186 .",
    "on @xmath187 ( both centered ) at @xmath181 hours ( left panel ) and @xmath182 hours ( right panel ) , respectively , with regression slopes @xmath188 and coefficient of determination @xmath189 , respectively , @xmath190 and @xmath191 , demonstrating that the deterministic part ( [ approx ] ) of the empirical differential equation ( [ de ] ) explains almost the entire variance of @xmath134 at @xmath182 hours but only a fraction of variance at @xmath181 hours . ]    as the regression line fitted near the end of the auction at @xmath182 hours explains almost all the variance , the approximating deterministic differential equation ( [ approx ] ) can be assumed to hold at that time ( and at later times as well , all the way to the end of the auction ) . at @xmath181",
    "the regression line explains only a fraction of the variance , while a sizable portion of variance resides in the drift process @xmath0 , so that the stochastic part in the dynamic system ( [ de ] ) can not be comfortably ignored in this time range .",
    "these relationships can be used to predict derivatives of trajectories and thus price changes at time @xmath58 for individual auctions , given their log price trajectory values at @xmath58 .",
    "we note that such predictions apply to fitted trajectories , not for the actually observed prices which contain an additional random component that is unpredictable , according to model ( [ kl2 ] ) .",
    "we find that at time @xmath182 , regression to the mean is observed at the level of individual auctions : an above ( below ) average log price level is closely associated with a below ( above ) average log price derivative .",
    "this implies that a seemingly very good ( or bad ) deal tends to be not quite so good ( or bad ) when the auction ends .",
    "the main motivation of using the dynamic system approach based on ( [ de ] ) is that it provides a better description of the mechanisms that drive longitudinal data but are not directly observable .",
    "the empirical dynamic equation may also suggest constraints on the form of parametric differential equations that are compatible with the data . in the auction example , the dynamic equation quantifies both the nature and extent of how expected price increases depend on auction stage and current price level .",
    "this approach is primarily phenomenological and does not directly lend itself to the task of predicting future values of individual trajectories .",
    "that expected conditional trajectory derivatives satisfy a first - order differential equation model ( which we refer to as the `` population level '' since this statement is about conditional expectations ) simply follows from gaussianity and in particular does not require additional assumptions .",
    "this suffices to infer the stochastic differential equation described in ( [ jt ] ) which we term `` empirical differential equation '' as it is determined by the data .",
    "then the function @xmath192 , quantifying the relative contribution of the drift process @xmath0 to the variance of @xmath134 , determines how closely individual trajectories follow the deterministic part of the equation",
    ". we could equally consider stochastic differential equations of other orders , but practical considerations favor the modeling with first - order equations .",
    "we find in the application example that online auctions follow a dynamic regression to the mean regime for the entire time domain , which becomes more acute near the end of the auction .",
    "this allows us to construct predictions of log price trajectory derivatives from trajectory levels at the same  @xmath58 .",
    "these predictions get better toward the right endpoint of the auctions .",
    "this provides a cautionary message to bidders , since an auction that looks particularly promising since it has a current low log price trajectory is likely not to stay that way and larger than average price increases are expected down the line .",
    "conversely , an auction with a seemingly above average log price trajectory is likely found to have smaller than average price increases down the line .",
    "this suggests that bidders take a somewhat detached stance , watching auctions patiently as they evolve .",
    "in particular , discarding auctions that appear overpriced is likely not a good strategy as further price increases are going to be smaller than the average for such auctions .",
    "it also implies that bid snipers are ill advised : a seemingly good deal is not likely to stay that way , suggesting a more relaxed stance .",
    "conversely , a seller who anxiously follows the price development of an item , need not despair if the price seems too low at a time before closing , as it is likely to increase rapidly toward the end of the auction .    for prediction purposes , drift processes @xmath175 for individual auctions",
    "are of great interest . in time domains where their variance is large ,",
    "any log price development is possible .",
    "interestingly , the variance of drift processes is very small toward the right tail of the auctions , which means that the deterministic part of the differential equation ( [ de ] ) is relatively more important , and log price derivatives during the final period of an auction become nearly deterministic and thus predictable .",
    "other current approaches of statistical modeling of differential equations for time course data [ e.g. , @xcite ] share the idea of modeling with a first order equation . in all",
    "other regards these approaches are quite different , as they are based on the prior notion that a differential equation of a particular and known form pertains to the observed time courses and moreover usually have been developed for the modeling of single time courses .",
    "this established methodology does not take into account the covariance structure of the underlying stochastic process .",
    "in contrast , this covariance structure is a central object in our approach and is estimated nonparametrically from the entire ensemble of available data , across all subjects or experiments .",
    "formula ( [ rep ] ) is an extension of the covariance kernel representation in terms of eigenfunctions , given by @xmath193 [ @xcite ] , which itself is a stochastic process version of the classical multivariate representation of a covariance matrix @xmath194 in terms of its eigenvectors @xmath195 and eigenvalues @xmath96 , @xmath196 .",
    "specifically , using representation ( [ kl3 ] ) , one finds @xmath197 , and ( [ rep ] ) follows upon observing that @xmath198 for @xmath199 and @xmath200 for @xmath201 .    regarding the `` population differential equation '' @xmath202 ,",
    "observe that for any jointly normal random vectors @xmath203 with mean @xmath70 and covariance matrix @xmath194 with elements @xmath204 , it holds that @xmath205 . applying this to the jointly normal random vectors in ( [ jt ] ) then implies this population equation .",
    "the specific form for the function @xmath72 in ( [ beta ] ) is obtained by plugging in the specific terms of the covariance matrix given on the right - hand side of ( [ jt ] ) .    applying ( [ rep ] ) , observing @xmath206 , and then taking the log - derivative leads to @xmath207/[\\sum_k \\lambda_k \\phi_k^2(t)]$ ] , establishing the last equality in representation ( [ beta ] ) .      turning to estimation , in a first step we aggregate measurements across all subjects into one `` big '' scatterplot and apply a smoothing method that allows us to obtain the @xmath208th derivative of a regression function from scatterplot data .",
    "for example , in the case of local polynomial fitting , given a univariate density function @xmath209 and bandwidth @xmath210 , one would minimize @xmath211 for each @xmath58 with respect to @xmath212 for @xmath213 , from which one obtains @xmath214 [ @xcite ] .",
    "according to ( [ kl4 ] ) , we will also need estimates of @xmath215 . there are various techniques available for this task .",
    "following @xcite , to which we refer for further details , using again local polynomial fitting , we minimize the pooled scatterplot of pairwise raw covariances @xmath216\\\\[-8pt ] & & \\qquad\\hspace*{30.8pt}{}\\times \\biggl\\{g_i(t_{ij},t_{il})-\\biggl(\\sum_{m = 0}^{\\nu+1}\\alpha_{1 m } ( t_{ij}-t)^m+\\alpha_{21}(t_{il}-s)\\biggr ) \\biggr\\}^2\\nonumber\\end{aligned}\\ ] ] for fixed @xmath217 with respect to @xmath218 and @xmath219 for @xmath220 , where @xmath221 , @xmath222 , @xmath223 is a kernel chosen as a bivariate density function , and @xmath224 is a bandwidth .",
    "this leads to @xmath225 .",
    "the pooling that takes place in the scatterplots for estimating the derivatives of @xmath77 and of @xmath17 is the means to accomplish the borrowing of information across the sample , which is essential to overcome the limitations of the sparse sampling designs .",
    "we note that the case of no derivative @xmath226 is always included , and solving the eigenequations on the left - hand side of ( [ kl4 ] ) numerically for that case leads to the required estimates @xmath227 of the eigenvalues and @xmath228 of the eigenfunctions .",
    "the estimates @xmath229 of the eigenfunction derivatives are then obtained from the right - hand side of ( [ kl4 ] ) , plugging in the estimates for eigenfunctions and eigenvalues , followed by a numerical integration step .",
    "the plug - in estimates , @xmath230 , are then obtained from the corresponding representations , ( [ beta ] ) , ( [ gz ] ) , ( [ v ] ) , ( [ r2 ] ) , by including @xmath141 leading components in the respective sums .",
    "while for theoretical analysis and asymptotic consistency one requires @xmath231 , the number of included eigen - terms @xmath141 in practical data analysis can be chosen by various criteria , for example , aic / bic based on marginal / conditional pseudo - likelihood or thresholding of the total variation explained by the included components [ @xcite ] .",
    "one key feature of the covariance surface smoothing step in  ( [ smooth2 ] ) is the exclusion of the diagonal elements ( for which @xmath232 ) ; the expected value for these elements includes the measurement error variance @xmath233 in addition to the variance of the process .",
    "the difference between a smoother that uses the diagonal elements only and the resulting diagonal from the smoothing step ( [ smooth2 ] ) when no derivatives are involved can then be used to find consistent estimates for the error variance @xmath233 [ @xcite ] .    to obtain estimates for the derivatives of the trajectories",
    "@xmath3 , a realistic target is the conditional expectation @xmath234 .",
    "it turns out that this conditional expectation can be consistently estimated in the case of gaussian processes by applying principal analysis by conditional expectation ( pace ) [ @xcite ] . for @xmath235 , @xmath236 , @xmath237 , @xmath238 , if @xmath239 and @xmath11 in ( [ kl2 ] ) are jointly gaussian , then by standard properties of the gaussian distribution , @xmath240 where @xmath241",
    "this implies @xmath242 .",
    "the unknown quantities can be estimated by simply plugging in the variance , eigenvalue , eigenfunction and eigenfunction derivative estimates discussed above , again coupled with truncating the number of included components at @xmath141 .",
    "denote the densities of @xmath243 and @xmath244 by @xmath245 , @xmath246 , and define an interior domain by @xmath247 $ ] with @xmath248 $ ] for some @xmath249 .",
    "regularity conditions for the densities and the targeted moment functions as well as their derivatives are as follows , where @xmath250 are nonnegative integers :    1 .",
    "@xmath251 exists and is continuous on @xmath252 with @xmath253 , @xmath254 exists and is continuous on @xmath255 for @xmath256 ; 2 .",
    "@xmath257 exists and is continuous on @xmath252 , @xmath258 exists and is continuous on @xmath255 for @xmath256 .",
    "we say that a bivariate kernel function @xmath223 is of order @xmath259 , where @xmath260 is a multi - index @xmath261 , if @xmath262\\\\[-8pt ] & & \\qquad= \\cases{0 , & \\quad $ 0 \\leq\\ell_1+\\ell_2 < \\ell , \\ell_1\\neq\\nu _ 1 , \\ell_2 \\neq\\nu_2 $ , \\cr ( -1)^{|{\\bf\\nu}| } \\nu_1 !",
    "\\nu_2 ! , & \\quad $ \\ell_1=\\nu_1 , \\ell_2=\\nu _",
    "2$,\\cr \\neq0 , & \\quad $ \\ell_1+\\ell_2=\\ell$,}\\nonumber \\ ] ] where @xmath263 .",
    "the univariate kernel @xmath209 is said to be of order @xmath264 for a univariate @xmath265 , if ( [ order ] ) holds with @xmath266 on the right - hand side , integrating only over the argument @xmath267 on the left - hand side .",
    "for the kernel functions @xmath209 , @xmath223 used in the smoothing steps to obtain estimates for @xmath113 and @xmath32 in ( [ smooth1 ] ) and for @xmath114 and @xmath115 in ( [ smooth2 ] ) we assume    1 .",
    "kernel functions @xmath209 and @xmath223 are nonnegative with compact supports , bounded and of order @xmath268 and @xmath269 , respectively .",
    "the following lemma provides the weak @xmath98 convergence rate for univariate and bivariate weighted averages defined below . for arbitrary real functions @xmath270 and @xmath271 , define @xmath272 and @xmath273 , let @xmath274 for a single index @xmath208 and @xmath275 for a multi - index @xmath276 , and define the weighted kernel averages , employing bandwidths @xmath277 , @xmath278 \\label{kwa1 } \\hat{\\theta}^\\ast(t , s)&=&\\frac{1}{e\\{n(n-1)\\ } n h_2^{|\\bolds\\nu|+2}}\\sum_{i=1}^n \\sum_{1\\leq j\\neq l \\leq n_i } \\theta^\\ast(t_{ij } , t_{il } , y_{ij } , y_{il } ) \\kappa_2\\nonumber\\\\[-9pt]\\\\[-9pt ] & & \\hspace*{152.4pt}{}\\times\\biggl(\\frac{t - t_{ij}}{h_2 } , \\frac{s - t_{il}}{h_2 } \\biggr).\\nonumber\\end{aligned}\\ ] ] for establishing convergence results for the general weighted averages ( [ kwa ] ) , assume that :    1 .",
    "derivatives @xmath279 exist and are continuous on @xmath252 , @xmath280 exists and is continuous on @xmath255 for @xmath281 .",
    "the univariate kernel @xmath209 is of order @xmath264 and the bivariate kernel @xmath223 is of order @xmath259 .",
    "[ lem1 ] under , , , and",
    "if @xmath282 , @xmath283 and @xmath284 , as @xmath285 , @xmath286\\\\[-9pt ] \\|\\hat{\\theta}^\\ast-\\theta_{\\bolds\\nu}^\\ast\\|_s&=&o_p\\biggl(\\frac { 1}{\\sqrt{n}h_2^{|\\bolds\\nu|+1}}+h_2^{\\ell-|\\bolds\\nu|}\\biggr).\\nonumber\\end{aligned}\\ ] ]      proof of theorem  [ thm1 ] since @xmath287 are jointly gaussian processes , it is clear that @xmath0 is gaussian .",
    "formula ( [ beta ] ) for @xmath56 is obtained by observing that for joint gaussian r.v.s , @xmath288\\{x(t)-\\mu(t)\\ } $ ] .",
    "then the properties of the functional principal component scores lead directly to @xmath289 whence @xmath290 .",
    "this implies @xmath53 .",
    "according to ( [ de ] ) , @xmath291 , for all @xmath46 , using ( [ cov ] ) and ( [ beta ] ) .",
    "this implies the independence of @xmath51 , due to the gaussianity .",
    "next observe @xmath292 , from which one obtains the result by straightforward calculation .",
    "proof of lemma  [ lem1 ] since @xmath293 and @xmath6 is a bounded and integer - valued random variable .",
    "denote the upper bound by @xmath294 . to handle the one - dimensional case in ( [ kwa ] ) ,",
    "we observe @xmath295 where @xmath296 is the indication function . note that for each @xmath297 , @xmath298 is obtained from an i.i.d . sample . slightly modifying the proof of theorem 2 in @xcite for a kernel of order @xmath264",
    "provides the weak convergence rate @xmath299 .",
    "it is easy to check that @xmath300 , as @xmath6 is a positive integer - valued random variable .",
    "therefore , @xmath301 analogously , for the two - dimensional case in ( [ kwa1 ] ) , let @xmath302 and then @xmath303^{-1 } \\hat{\\theta}_{\\mathbf{j}}^\\ast$ ] . similarly to the above , one has @xmath304 .",
    "again it is easy to verify that @xmath305 .",
    "the triangle inequality for the @xmath98 distance entails @xmath306 .",
    "proof of theorem  [ thm2 ] note that the estimators @xmath307 , @xmath308 , @xmath309 and @xmath310 all can be written as functions of the general averages defined in ( [ kwa ] ) , ( [ kwa1 ] ) .",
    "slightly modifying the proof of theorem 1 in @xcite , with @xmath311 rates replaced by the @xmath98 rates given in lemma  [ lem1 ] , then leads to the optimal @xmath98 weak convergence rates for @xmath312 and @xmath313 in ( [ thm2-eq1 ] ) .",
    "for the convergence rate of @xmath314 , lemma 4.3 in @xcite implies that @xmath315 where @xmath316 is defined in ( [ spacing ] ) and @xmath309 is an arbitrary estimate ( or perturbation ) of @xmath17 .",
    "denote the linear operators generated from the kernels @xmath317 and @xmath318 by @xmath319 , respectively , @xmath320 .",
    "noting that @xmath321 , one finds @xmath322 which implies ( [ thm2-eq2 ] ) .",
    "proof of theorem  [ thm3 ] from ( [ bosq ] ) it is easy to see that @xmath323 , and from both ( [ bosq ] ) and ( [ pf1 ] ) that @xmath324 uniformly in @xmath64 .",
    "one then finds that @xmath325 is bounded in probability by @xmath326 which implies that @xmath327 , where @xmath328 is defined in ( [ rate ] ) and the remainder terms in ( [ rem ] ) .",
    "similar arguments lead to @xmath329 , noting @xmath330 due to the cauchy ",
    "schwarz inequality .",
    "regarding @xmath331 , one has @xmath332 applying the cauchy ",
    "schwarz inequality to @xmath333 .",
    "observing @xmath334 yields @xmath335 .",
    "to study @xmath336 , we investigate the @xmath98 convergence rates of @xmath337 where @xmath72 ( resp . , @xmath338 ) and @xmath34 ( resp .",
    ", @xmath339 ) share the same argument , and we define @xmath340 . in analogy to the above arguments , @xmath341 , @xmath342 .",
    "this leads to @xmath343 .",
    "the same argument also applies to @xmath344 .",
    "next we study @xmath345 and find that @xmath346 .",
    "analogous arguments apply to @xmath347 , completing the proof .",
    "we are grateful to two referees for helpful comments that led to an improved version of the paper .",
    "dauxois , j. , pousse , a. and romain , y. ( 1982 ) .",
    "asymptotic theory for the principal component analysis of a vector random function : some applications to statistical inference .",
    "_ j. multivariate anal . _",
    "* 12 * 136154 .",
    "mas , a. and menneteau , l. ( 2003 ) .",
    "perturbation approach applied to the asymptotic study of random operators . in _ high dimensional probability , iii ( sandjberg , 2002)_. _ progress in probability _ * 55 * 127134 .",
    "birkhuser , basel .",
    "ramsay , j. o. , hooker , g. , campbell , d. and cao , j. ( 2007 ) .",
    "parameter estimation for differential equations : a generalized smoothing approach ( with discussion )",
    ". _ j. r. stat .",
    "methodol . _ * 69 * 741796 .",
    "reithinger , f. , jank , w. , tutz , g. and shmueli , g. ( 2008 ) . modelling price paths in on - line auctions : smoothing sparse and unevenly sampled curves by using semiparametric mixed models .",
    "c _ * 57 * 127148 .",
    "shi , m. , weiss , r. e. and taylor , j. m. g. ( 1996 ) .",
    "an analysis of paediatric cd4 counts for acquired immune deficiency syndrome using flexible random curves .",
    "_ j.  roy .",
    "c _ * 45 * 151163 ."
  ],
  "abstract_text": [
    "<S> we demonstrate that the processes underlying on - line auction price bids and many other longitudinal data can be represented by an empirical first order stochastic ordinary differential equation with time - varying coefficients and a smooth drift process . </S>",
    "<S> this equation may be empirically obtained from longitudinal observations for a sample of subjects and does not presuppose specific knowledge of the underlying processes . for the nonparametric estimation of the components of the differential equation , it suffices to have available sparsely observed longitudinal measurements which may be noisy and are generated by underlying smooth random trajectories for each subject or experimental unit in the sample . </S>",
    "<S> the drift process that drives the equation determines how closely individual process trajectories follow a deterministic approximation of the differential equation . </S>",
    "<S> we provide estimates for trajectories and especially the variance function of the drift process . at each fixed time point </S>",
    "<S> , the proposed empirical dynamic model implies a decomposition of the derivative of the process underlying the longitudinal data into a component explained by a linear component determined by a varying coefficient function dynamic equation and an orthogonal complement that corresponds to the drift process . </S>",
    "<S> an enhanced perturbation result enables us to obtain improved asymptotic convergence rates for eigenfunction derivative estimation and consistency for the varying coefficient function and the components of the drift process . </S>",
    "<S> we illustrate the differential equation with an application to the dynamics of on - line auction data.=-1    and    .    . </S>"
  ]
}