{
  "article_text": [
    "decode - and - forward ( df ) and compress - and - forward ( cf ) are the two main relaying strategies developed in  @xcite for the three - node relay channel .",
    "there have been many attempts to generalize them to discrete memoryless networks ( dmn ) .",
    "for example , cf was generalized for dmn in  @xcite and df was generalized for dmn in  @xcite .",
    "for the three - node relay channel , the partial - decode - compress - and - forward relaying in theorem 7 in  @xcite combines both df and cf .",
    "however , to the best of our knowledge , there have been no results that generalize this to dmn .",
    "there were some relaying strategies for general dmn where each relay performs either cf or df @xcite , but not both .    in this paper",
    ", we propose a unified scheme that generalizes the partial - decode - compress - and - forward relaying in theorem 7 in  @xcite to dmn .",
    "our scheme , which we call noisy network coding with partial df ( nnc - pdf ) , simultaneously generalizes noisy network coding ( nnc ) by lim , kim , el gamal , and chung  @xcite and distributed decode - and - forward ( ddf ) by lim , kim , and kim  @xcite . in our scheme , each relay can perform both partial df and cf simultaneously .",
    "it is not trivial to combine nnc and ddf schemes . in nnc",
    ", the same long message is sent over multiple blocks . in each block , the source sends an independent codeword indexed by the message and each relay compresses its received channel output sequence and forwards the covering index . after the transmission of all blocks ,",
    "the destination decodes the message ( uniquely ) and the covering indices ( nonuniquely ) simultaneously over all blocks . on the other hand , in the ddf scheme",
    ", independent messages are sent over multiple blocks and information about each message is captured by a set of auxiliary covering indices , one per relay . before starting the transmission , the source finds those auxiliary covering indices for each message using backward encoding over all blocks . in each block",
    ", the relay decodes the auxiliary covering index intended for itself and forwards it . after the transmission of all blocks ,",
    "the destination decodes the message and the auxiliary covering indices sequentially using backward decoding .    due to these inherent incompatibility in encoding and decoding strategies of nnc and ddf schemes ,",
    "it is worthwhile to consider recent works on short message nnc @xcite .",
    "these works differ from @xcite in that the source sends independent messages over blocks and the destination decodes the message using sliding window decoding @xcite or backward decoding @xcite , and hence more compatible with ddf scheme .",
    "one drawback of short message nnc schemes is that they require the destination to uniquely decode the covering indices , which results in extra constraints .",
    "these extra constraints turn out to be redundant @xcite , but when combined with partial df , it is not clear whether similar arguments apply .",
    "this motivates us to consider a long message at the source and simultaneous nonunique decoding at the destination as in @xcite for combining nnc and ddf schemes . in our nnc - pdf scheme , before starting the transmission , the source finds the auxiliary covering indices that carry information about the message simultaneously over all blocks ( no backward encoding ) . in each block",
    ", each relay decodes the auxiliary covering index , compresses its received channel output sequence , and forwards the decoded and covered indices . after the transmission of all blocks ,",
    "the destination decodes the message uniquely and the auxiliary covering indices and the covering indices nonuniquely , simultaneously over all blocks .",
    "the following notations are used throughout the paper . for",
    "two integers @xmath0 and @xmath1 , @xmath2 $ ] denotes the set @xmath3 . for a set @xmath4 of real numbers , @xmath5",
    "$ ] denotes @xmath6 . for constants",
    "@xmath7 and @xmath8 $ ] , @xmath9 denotes the vector @xmath10 and @xmath11 denotes @xmath12}$ ] where the subscript is omitted when @xmath13 , i.e. , @xmath14}$ ] . for random variables @xmath15 and @xmath8 $ ] , @xmath16 and @xmath17 are defined similarly . for sets @xmath18 and @xmath8",
    "$ ] , @xmath19 denotes @xmath20 and @xmath21 denotes @xmath22}$ ] where the subscript is omitted when @xmath13 .",
    "@xmath23 is the indicator function , i.e. , it is 1 if @xmath24 and 0 otherwise .",
    "we follow the notion of typicality in @xcite , @xcite .",
    "a single - source multicast discrete memoryless network of @xmath25 nodes @xmath26}|x_{[1:n]}))$ ] consists of a set of channel input and output alphabets @xmath27 for @xmath28 $ ] and a collection of conditional probability mass functions @xmath29}|x_{[1:n]})$ ] .",
    "let node 1 denote the source node and let @xmath30 $ ] denote the set of destination nodes .",
    "an @xmath31 code for the single - source multicast discrete memoryless network consists of message @xmath32 , uniformly distributed over @xmath33 $ ] , encoding function at the source that maps @xmath34 to @xmath35 , processing function at node @xmath36 $ ] at time @xmath37 $ ] that maps @xmath38 to @xmath39 , and decoding function at destination @xmath40 that maps @xmath41 to @xmath42 .",
    "the probability of error is defined as @xmath43 and a rate @xmath44 is said to be achievable if there exists a sequence of @xmath31 codes such that @xmath45 .",
    "the capacity is defined as the supremum over all achievable rates .",
    "the following theorem gives a noisy network coding with partial decode - and - forward ( nnc - pdf ) bound for single - source multicast discrete memoryless networks , which simultaneously generalizes nnc @xcite and ddf @xcite .",
    "[ thm : gdcf ] for a single - source multicast dmn , a rate of @xmath44 is achievable if @xmath46\\setminus \\{d\\ } } i(x_1,v_s;u_{s^c},x_{t^c},\\hat{y}_{t^c},y_d|v_{s^c})\\cr & + i(x_{t},u_s;\\hat{y}_{t^c},y_d|x_1 , x_{t^c } , v^n , u_{s^c})\\cr & -i(\\hat{y}_{t};y_{t}|\\hat{y}_{t^c } , x^n , v^n , u^n , y_d)\\cr & -\\sum_{k\\in s^c } ( i(u_k;x^n , v^n , u_{s^c[k]}|v_k , x_k , y_k)+i(v_k;v_{s^c[k]}))\\end{aligned}\\ ] ] for some @xmath47 such that @xmath48})+i(u_k;u_{s'[k]},v_{s'}|v_k)$ ] for all @xmath49 $ ] .    for @xmath50",
    ", the nnc - pdf bound falls back to theorem 7 in @xcite , which is a partial - decode - compress - and - forward bound for three node relay networks .",
    "the nnc - pdf bound recovers nnc @xcite and ddf @xcite bounds by letting @xmath51 and by letting @xmath52})=\\prod_{k\\in [ 2:n]}p(v_k)$ ] , @xmath53 , and @xmath54 for @xmath36 $ ] , respectively .    in the ddf scheme @xcite , the relay nodes , i.e. , nodes @xmath55 , send independent codewords .",
    "in contrast , the nnc - pdf scheme allows arbitrary correlation among transmitted codewords from relay nodes .",
    "our nnc - pdf bound is derived as an application of our unified coding approach for network information theory   @xcite , @xcite .",
    "let us briefly present the unified coding framework and unified coding theorem @xcite , @xcite and then prove theorem [ thm : gdcf ] .",
    "let us first explain the unified framework @xcite , @xcite for proving the achievability of many network information theory problems .",
    "an @xmath25-node acyclic discrete memoryless network ( admn ) @xmath56 , @xmath57 consists of a set of alphabet pairs @xmath58 , @xmath28 $ ] and a collection of conditional pmfs @xmath59 , @xmath28 $ ] . here ,",
    "@xmath60 and @xmath61 represent any information that comes into and goes out of node @xmath62 , respectively . in this network ,",
    "information flows in one direction and node operations are sequential .",
    "let @xmath63 denote the number of channel uses .",
    "first , @xmath64 is generated according to @xmath65 and then node 1 processes @xmath66 based on @xmath64 .",
    "next , @xmath67 is generated according to @xmath68 and then node 2 encodes @xmath69 based on @xmath67 .",
    "similarly , @xmath70 is generated according to @xmath71 and node @xmath62 encodes @xmath72 based on @xmath70 for @xmath28 $ ] .",
    "clearly , any layered network @xcite or noncausal network ( without infinite loop ) @xcite possibly with noncausal state or side information can be represented as an admn .",
    "furthermore , any strictly causal ( usual discrete memoryless network with relay functions having one sample delay ) or causal network ( relays without delay @xcite ) with blockwise operations can be represented as an admn by unfolding the network .",
    "the objective of an admn is specified using a target joint distribution @xmath73 , which is shortly denoted as @xmath74 .",
    "the probability of error is defined as @xmath75}^n , y_{[1:n]}^n ) \\notin \\mathcal{t}_{\\epsilon}^{(n ) } ) $ ] , where the typical set @xmath76 is defined with respect to @xmath74 .",
    "we say the target distribution @xmath74 is achievable if there exists a sequence of node processing functions @xmath77 , @xmath78 , such that @xmath79 for any @xmath80 .    in the following ,",
    "we illustrate how the point - to - point channel coding problem can be represented using an admn and a target distribution .    for point - to - point channel coding problem with message rate of @xmath44 , we choose @xmath81 such that @xmath82 ( corresp . to the message of rate @xmath44 ) and @xmath83 ( corresp . to the channel ) and pick @xmath74 such that @xmath84 ( corresp . to the message estimate at node 2 ) is equal to @xmath85 .",
    "then , @xmath86 for any @xmath87 is lower - bounded by @xmath88 , and hence achievability of @xmath74 implies that of rate @xmath44 .",
    "let us present the unified coding theorem which gives a sufficient condition to achieve @xmath74 for an admn . to do that",
    ", we explain the coding parameters for the codebook generation and node operation of the unified coding scheme . in the unified coding scheme , @xmath89 covering codebooks @xmath90",
    "are generated to compress information that each node observes and decodes .",
    "let @xmath91 for @xmath92 $ ] denote the alphabet for the codeword symbol of @xmath93 . for indexing of codewords , we consider @xmath94 index sets @xmath95 , where @xmath96 $ ] for some @xmath97 for each @xmath98 $ ] .",
    "we denote by @xmath99 $ ] the set of indices of @xmath100 s associated with @xmath93 in a way that each codeword in @xmath93 is indexed by the vector @xmath101 and hence @xmath93 consists of @xmath102 codewords , i.e. , @xmath103 .",
    "each codebook is constructed allowing superposition coding .",
    "let @xmath104 , j\\in [ 1:\\nu]$ ] denote the set of the indices of @xmath105 s on which @xmath93 is constructed by superposition .",
    "node @xmath28 $ ] operates according to the following three steps as illustrated in fig .",
    "[ fig : scheme_flow ] :    * simultaneous nonunique decoding : after receiving @xmath106 , node @xmath62 decodes some covering codewords of previous nodes simultaneously , where some are decoded uniquely and the others are decoded non - uniquely .",
    "we denote by @xmath107 $ ] and @xmath108 $ ] the sets of the indices of @xmath105 s whose codewords are decoded uniquely and non - uniquely , respectively , at node @xmath62 . * simultaneous compression",
    ": after decoding , node @xmath62 finds covering codewords simultaneously according to a conditional pmf @xmath109 that carry some information about received channel output sequence @xmath106 and uniquely decoded codewords @xmath110 , where @xmath111 $ ] denotes the set of the indices of @xmath105 s used for compression . *",
    "symbol - by - symbol mapping : after decoding and compression , node @xmath62 generates @xmath112 by a symbol - by - symbol mapping from uniquely decoded codewords @xmath110 , covered codewords @xmath113 , and received channel output sequence @xmath106 .",
    "let @xmath114 denote the function used for symbol - by - symbol mapping .",
    "more rigorous explanations for the codebook generation and node operation of the unified coding scheme are provided in @xcite .    in summary ,",
    "our scheme requires the following set @xmath115 of coding parameters , where some constraints are added to make the aforementioned codebook generation and node operation proper :    1 .",
    "positive integers @xmath94 and @xmath89 2 .",
    "alphabets @xmath116 $ ] 3 .",
    "@xmath94-rate tuple @xmath117 4 .",
    "sets @xmath118\\setminus { } { w}^{k-1 } , { } { d}_k\\subseteq { } { w}^{k-1 } , { } { b}_k\\subseteq { } { w}^{k-1}\\setminus { } { d}_k$ ] , @xmath99 $ ] , and @xmath104 $ ] for @xmath28 $ ] and @xmath92 $ ] that satisfy 1",
    ".   @xmath119 s are disjoint , 2 .",
    "@xmath120 and @xmath121 if @xmath122 , 3 .",
    "@xmath123 , @xmath124 , and @xmath125 .",
    "a set of conditional pmfs @xmath126 and functions @xmath127 for @xmath28 $ ] such that @xmath128},y_{[1:n]})$ ] induced by @xmath129 is the same as the target distribution @xmath130},y_{[1:n]})$ ] .",
    "the following theorem gives a sufficient condition for achievability using the aforementioned unified coding scheme .",
    "[ thm : main ] for an @xmath25-node admn , @xmath74 is achievable if there exists @xmath131 such that for @xmath132 @xmath133\\cup   { } { s}_k^c},y_k|u_{a_j } ) \\label{eqn : main_sk}\\\\   \\sum_{j\\in { \\bar}{t}_k } r_j&>\\sum_{j\\in   { } { t}_k } i(u_j;u _ { { } { t}_k[j]\\cup { } { d}_k},y_k|u_{a_j})\\label{eqn : main_tk}\\end{aligned}\\ ] ] for all @xmath134 such that @xmath135 and for all @xmath136 such that @xmath137 , where @xmath138 , @xmath139 , @xmath140 , @xmath141    ( [ eqn : main_sk ] ) and ( [ eqn : main_tk ] ) for @xmath28 $ ] are the conditions for successful simultaneous nonunique decoding and simultaneous compression , respectively , at node @xmath62 .      to derive the nnc - pdf bound in theorem",
    "[ thm : gdcf ] , we first represent our network model as an admn and @xmath74 and then apply the unified coding theorem for a specific choice of coding parameter set @xmath115 .",
    "we note that our network model itself can not be represented as an admn . by assuming a block - wise operation at each node ,",
    "however , the network can be unfolded and represented as an admn .",
    "achievability uses @xmath142 transmission blocks blocks before the transmission of @xmath142 blocks , which will be explained later . ] , each consisting of @xmath63 channel uses .",
    "let @xmath143 and @xmath144 for @xmath28 $ ] and @xmath145 $ ] denote the channel output and channel input sequences , respectively , at node @xmath62 at block @xmath146 . at the end of block @xmath147 , where @xmath145 $ ] , node @xmath28 $ ] encodes what to transmit in block @xmath146 , i.e. , @xmath144 , using previously received channel outputs up to block @xmath147 , i.e. , @xmath148}^n$ ] . using this block - wise operation at each node , we unfold the network .",
    "in the unfolded network , we have @xmath149 nodes .",
    "the operation of node @xmath150 , b\\in [ 1:b]$ ] corresponds to that of node @xmath62 of the original network transmitting in block @xmath146 based on the received channel outputs up to block @xmath147 and the operation of node @xmath151 corresponds to that of node @xmath152 of the original network that estimates the message based on the received channel outputs up to block @xmath142 .",
    "let @xmath153 and @xmath154 denote the channel output and channel input at node @xmath155 of the unfolded network , respectively .",
    "a message generated at the source is regarded as the channel output at node @xmath156 , i.e. , @xmath157 such that @xmath158 , and the message estimate at destination @xmath40 is regarded as the channel input at node @xmath159 , i.e. , @xmath160 . to reflect the fact that node @xmath161 is originally the same node as node @xmath155",
    ", we assume that node @xmath155 has an orthogonal link of sufficiently large rate to node @xmath161 .",
    "hence , for @xmath28 $ ] and @xmath145 $ ] , we let @xmath162 and let @xmath163,[1:b]}^{\\mathrm{unf}},y_{[1:k-1],b+1}^{\\mathrm{unf}},x_{[1:n],[1:b]}^{\\mathrm{unf}},x_{[1:k-1],b+1}^{\\mathrm{unf}})=p_{y_k|y_{[1:k-1]},x_{[1:n]}}(y_{k , b}|y_{[1:k-1],b},x_{[1:n],b})$ ] where @xmath164 for @xmath165 and @xmath166 for some @xmath167 with arbitrarily large cardinality .",
    "we assume a target joint distribution @xmath130,[1:b+1]}^{\\mathrm{unf}},y_{[1:n],[1:b+1]}^{\\mathrm{unf}})$ ] such that @xmath168 for all @xmath40 .",
    "note that the achievability of @xmath74 for the unfolded network implies the achievability of rate @xmath44 for the original network .",
    "now , let us choose @xmath131 to obtain the nnc - pdf bound . in our nnc - pdf scheme , before starting the transmission , the source finds the auxiliary covering indices that carry information about the message simultaneously over all blocks . at each block ,",
    "node @xmath62 decodes the auxiliary covering index intended for it and finds the covering index that carries information about its received channel output .",
    "after all transmission , destination node decodes the message uniquely and the auxiliary covering indices and the covering indices nonuniquely , simultaneously over all blocks .",
    "this operation can be translated to the following parameter set for unified coding .",
    "fix @xmath169 .",
    "let @xmath170 and @xmath171 .",
    "consider a @xmath94-rate tuple @xmath172 , b'\\in [ 0,b ] , b''\\in [ 0,b-1 ] , k\\in [ 2:n])$ ] .",
    "for notational convenience , let us index the codebook @xmath105 by the auxiliary random variable used for its generation , i.e. , if a codebook consists of @xmath173 generated conditionally independently according to @xmath174 for some @xmath175 and @xmath176 , we denote the codebook by @xmath177 .",
    "in addition , we index the index set @xmath100 in the following way : @xmath178 , \\mathcal{l}_{l_{1,b}}=[1:2^{nr_{1,b } } ] ,   \\mathcal{l}_{l_{k , b'}}=[1:2^{nr_{k , b'}}]$ ] , and @xmath179 $ ] for @xmath145 , b'\\in [ 0,b ] , b''\\in [ 0,b-1]$ ] , and @xmath36 $ ] .",
    "the remaining coding parameters associated with each node are given as follows :      for @xmath28 $ ] and @xmath145 $ ] , we let @xmath188 } , w_{k}^b , d_{k}^b)$ ] . for @xmath189 ,",
    "let @xmath190 . before initiating the transmission of @xmath142 blocks , each @xmath191 chosen at the source",
    "is transmitted to node @xmath36 $ ] using multi - hop scheme as in @xcite , and this requires additional @xmath192 blocks .",
    "note the actual rate @xmath193 can be arbitrarily close to @xmath44 as @xmath194 . as a result of this initialization step",
    ", we can let @xmath195 for @xmath36 $ ] .    in the above choice of @xmath131",
    ", @xmath196 corresponds to the message index and @xmath197 , b\\in [ 0:b]\\}$ ] corresponds to the set of auxiliary covering indices that carry information about the message .",
    "these indices are chosen simultaneously at node ( 1,1 ) of the unfolded network , i.e. , the source before starting the transmission .",
    "node @xmath155 for @xmath36 $ ] , @xmath184 $ ] of the unfolded network , i.e. , node @xmath62 at the end of block @xmath147 , decodes @xmath198 and finds the covering index @xmath199 that carries information about @xmath200 . at node @xmath159 for @xmath40 of the unfolded network ,",
    "i.e. , node @xmath152 at the end of block @xmath142 , simultaneously decodes the message ( uniquely ) and the auxiliary covering indices and the covering indices ( nonuniquely ) .    to prove theorem [ thm : gdcf ] , we use the following lemma , whose proof is given in @xcite .",
    "[ corollary : gdcf_reduced ] consider @xmath131 .",
    "for @xmath134 such that @xmath135 and @xmath136 such that @xmath137 , the decoding and compression bounds , i.e. , ( [ eqn : main_sk ] ) and ( [ eqn : main_tk ] ) , in theorem [ thm : main ] are satisfied if @xmath201\\cup s_k'^c},y_k|u_{a_j})\\\\ \\sum_{j\\in \\bar{t}_k}r_j>\\sum_{j\\in t_k'}i(u_j;u_{t_k'[j]\\cup d_k},y_k|u_{a_j}),\\end{aligned}\\ ] ] for some @xmath202 such that @xmath203\\cup s_k^c$ ] for all @xmath204 and @xmath205 .",
    "now , we are ready to apply theorem [ thm : main ] to prove theorem [ thm : gdcf ] .",
    "let @xmath206 , @xmath207 , @xmath208 , and @xmath209 for some @xmath210 , and @xmath211 for @xmath145 $ ] , @xmath212 $ ] , and @xmath36 $ ] .",
    "for each node in the unfolded network , let us derive the decoding and compression bounds i.e. , ( [ eqn : main_sk ] ) and ( [ eqn : main_tk ] ) , respectively .",
    "first , for compression at node ( 1,1 ) , note that @xmath213 , b'\\in [ 0:b ] , k\\in [ 2:n]\\}$ ] . by applying lemma [ corollary :",
    "gdcf_reduced ] and using the following blockwise i.i.d .",
    "property @xmath214},v_{[2:n],[1:b ] } , u_{[2:n],[1:b ] } ) = \\prod_{b\\in [ 1:b ] }   p_{x_1,v_2^n , u_2^n}(x_{1,b},v_{[2:n],b } , u_{[2:n],b})$ ] , we can show that the condition for compression is satisfied if @xmath215 } ) + \\sum_{k\\in s } i(u_{k};u_{s[k]},v_{s}|v_{k})\\\\ r_1+\\sum_{k\\in [ 2:n ] } r_{k } & > \\sum_{k\\in [ 2:n]}i(v_{k};v^{k-1 } ) \\cr & + \\sum_{k\\in [ 2:n ] } i(u_{k};u^{k-1},v_{[2:n]},x_1|v_{k})\\end{aligned}\\ ] ] for all @xmath216 $ ]",
    ".    next , consider the decoding and compression bounds for node @xmath217 $ ] .",
    "since @xmath218 , the bound for decoding becomes inactive .",
    "furthermore , it can be easily shown that the bound for compression is also inactive .",
    "similarly , for node @xmath219 $ ] , since @xmath220 , the bound for decoding becomes inactive .",
    "lastly , consider the decoding bound at node @xmath151 .",
    "since @xmath231 , where @xmath232\\}$ ] , and @xmath233 contains @xmath234 and @xmath235 , we only need to consider @xmath236 , b'\\in [ 0:b-1 ] , k\\in [ 2:n]\\setminus \\{d\\}\\}$ ] such that @xmath237 . from lemma",
    "[ corollary : gdcf_reduced ] and using the blockwise i.i.d .",
    "property shown in ( [ eqn : gdcf_independence ] ) , we can show that the bound for decoding is satisfied if @xmath238\\setminus \\{d\\ } } \\big(\\sum_{k\\in s } i(v_k;v_{s[k ] } , v_{s^c } , u_{s^c } , \\hat{y}_{t^c } , x_{t^c } , y_d ) \\cr & + i(x_1;u_{s^c } , \\hat{y}_{t^c } , x_{t^c } , y_d|v_{[2:n]})\\cr & + \\sum_{k\\in t } i(x_k;x_{t[k ] } , x_1 , v_{[2:n]},u_{s^c } , \\hat{y}_{t^c } , x_{t^c } , y_d|v_k ) \\cr & + \\sum_{k\\in s } i(u_k;u_{s[k ] } , x^n ,   v_{[2:n]},u_{s^c } , \\hat{y}_{t^c},y_d|v_k ) \\cr & + \\sum_{k\\in t } i(\\hat{y}_k;\\hat{y}_{t[k ] } , \\hat{y}_{t^c},x^n ,   v_{[2:n]},u_{[2:n ] } , y_d|u_k , v_k , x_k ) \\cr & -(\\sum_{k \\in s}r_{k } + \\sum_{k\\in t}r_{k}')-r_1\\big)-\\sum_{k\\in [ 2:n ] } ( r_k+r_k').\\end{aligned}\\ ] ]    by performing fourier - motzkin elimination and taking @xmath194 , @xmath74 is shown to be achievable if the condition in thoerem [ thm : gdcf ] is satisfied , and hence theorem [ thm : gdcf ] is proved .",
    "this work was supported in part by the ciss funded by the ministry of science , ict & future planning as the global frontier project . "
  ],
  "abstract_text": [
    "<S> in this paper , we propose a noisy network coding integrated with partial decode - and - forward relaying for single - source multicast discrete memoryless networks ( dmn s ) . </S>",
    "<S> our coding scheme generalizes the partial - decode - compress - and - forward scheme ( theorem 7 ) by cover and el gamal . </S>",
    "<S> this is the first time the theorem is generalized for dmn s such that each relay performs both partial decode - and - forward and compress - and - forward simultaneously . </S>",
    "<S> our coding scheme simultaneously generalizes both noisy network coding by lim , kim , el gamal , and chung and distributed decode - and - forward by lim , kim , and kim . </S>",
    "<S> it is not trivial to combine the two schemes because of inherent incompatibility in their encoding and decoding strategies . </S>",
    "<S> we solve this problem by sending the same long message over multiple blocks at the source and at the same time by letting the source find the auxiliary covering indices that carry information about the message simultaneously over all blocks .    </S>",
    "<S> noisy network coding , distributed decode - and - forward , unified coding theorem </S>"
  ]
}