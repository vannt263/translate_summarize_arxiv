{
  "article_text": [
    "aggregate dynamical equations derived from individual - based models are usually exact only if the micro - level dynamics satisfy certain rather restrictive symmetry conditions brought about by homogeneity of the agent properties and interaction rules @xcite .",
    "micro - level heterogeneity or complex interaction structures often lead to correlations in the dynamics that a macro - level description may not account for .",
    "that is , it is not possible to exactly describe the system evolution as a closed set of macroscopic equations .",
    "for this reason , it is important to understand the consequences of heterogeneous agent properties on macroscopic formulations of the system dynamics . in this paper",
    ", we present results into that direction for the diamond search equilibrium model @xcite  also known as coconut model  which has been introduced in 1982 by the 2010 nobel laureate peter diamond as a model for an economy with trade frictions .",
    "imagine an island with @xmath0 agents that like to eat coconuts .",
    "they search for palm trees and harvest a nut from it if the tree is not too tall , meaning that its height does not exceed an individual threshold cost ( @xmath1 ) .",
    "however , in order to consume the nut and derive utility @xmath2 from this consumption agents have to find a trading partner , that is , another agent with a nut .",
    "therefore , the agents have to base their harvest decision _ now _",
    "( by setting @xmath3 ) on their expectation to find a trading partner _ in the future_. or , less metaphorically , agents are faced with production decisions that have to be evaluated based on their expectations about the future utility of the produced entity which in turn depends on the global production level via a trading mechanism .",
    "for this reason , the coconut model is useful not only for the incorporation of heterogeneity , but also for the analysis of adaptive agents that  rationally or not  have to form expectations about the future system state in order to evaluate their decision options .    in the original papers @xcite this problem of inter - temporal optimization",
    "is formulated using dynamic programming principles and the bellmann equation in particular .",
    "the author(s ) arrive at a differential equation ( de ) that describes the evolution of the cost threshold along an optimality path ( where the individual thresholds are all equal @xmath4 ) which is coupled to a second de describing the evolution of the number of coconuts in the population .",
    "however , knowing the optimal dynamics , that is , the differential equations that an optimal solution has to fulfill , is not sufficient to study problems such as equilibrium selection or stability in general , because the optimality conditions do not say anything about the behavior of the system when it is perturbed into a suboptimal state . on the other hand ,",
    "the bellmann equation is also at the root of reinforcement learning algorithms and temporal difference ( td ) learning in particular which are known to converge to this optimality under certain conditions @xcite .",
    "the incorporation of learning in the agent - based version of the coconut model and the assessment of its adequacy by comparison to the original solution is a second contribution of this paper .",
    "the necessity to take into account not only the result of rational choice but to focus more on the processes that may lead to it has been pointed at by simon almost 40 years ago @xcite . around ten years later , the notion of artificial adaptive agents has been proposed by @xcite who define an _ adaptive _ agent by two criteria : ( 1 . )",
    "the agent assigns a value ( fitness , accumulated reward , etc . ) to its actions , and ( 2 . )",
    "the agent intends to increase this value over time ( p. 365 ) .",
    "virtually all models with adaptive agents proposed since then follow these principles . in genetic algorithms , for instance , an evolutionary mechanism is implemented by which least fit strategies are replaced by fitter ones and genetic operators like recombination and mutation are used to ensure that potential improvements are found even in high - dimensional strategy spaces , ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "another approach which became prominent during the last years could be referred to as strategy switching ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "agents constantly evaluate a set of predefined decision heuristics by reinforcement mechanisms and chose the rule that performs best under the current conditions .",
    "the reader may be referred to the excellent introductory chapter to > > behavioral rationality and heterogeneous expectations in complex economic systems < < by @xcite for a very instructive account .",
    "the td approach used here differs mildly from these models but fits well with the abstract specification of adaptive behavior proposed in @xcite . in our case agents",
    "learn the value associated to having and not having a coconut in form of the expected future reward and use these values to determine their cost threshold @xmath3 .",
    "that is , agents are forward - looking by trying to anticipate their potential future gains . while checking genetic algorithms or strategy switching methods in the context of the coconut model is an interesting issue for future research , in this first paper we would like to derive an agent - based version of the model that is as closely related to the original model as possible .",
    "the motivation behind this is well - captured by a quote from @xcite ( p. 366 ) :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ > > as a minimal requirement , wherever the new approach overlaps classical theory , it must include verified results of that theory in a way reminiscent of the way in which the formalism of general relativity includes the powerful results of classical physics .",
    "< < _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    to our opinion , this relates to the tradition in abm research to verify and validate computational models by replication experiments ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "the main idea is that the same conceptual model implemented on different machines and possibly using different programming languages should always yield the same behavior . to our point of view",
    "this attempt to develop scientific standards for abms should not be restricted to comparing different computer implementations of the same conceptual model , but it should also aim at aligning or comparing the results of an abm implementation to analytical formulations of the same processes .",
    "at least , whenever such descriptions are available .    for the coconut model",
    "this is the case , and for its rich and sometimes intricate behavior on the one hand and the availability of a set of analytical results on the other the model is well  suited as a testbed for this kind of model comparison . in particular when it comes to extend a model that is formulated for an idealized homogeneous population so to incorporate heterogeneity at the agent level , we should make sure that it matches with the theoretical results that are obtained for the idealized case .    hence , the main objective of this paper is to derive an agent - based version of the coconut model as conceived in the original papers @xcite where the model dynamics have been derived for an idealized infinite and homogeneous population .",
    "we will see ( in section [ sec : homogeneous ] ) that this implementation does not lead to the fixed point(s ) of the original system . in order to align the abm to yield the right fixed point behavior we have at least two different options which again lead to slight differences in the dynamical behavior that are not obvious from the de description .",
    "this then allows us to study the effects that result from deviating from the idealized setting of homogeneous strategies , which we address in section [ sec : heterogeneous ] .",
    "heterogeneity may arise from the interaction structure , the information available to the agents as well as from heterogeneous agent strategies as an effect of learning in finite populations , and we will concentrate on the latter here . in particular , we will show that heterogeneity can by accounted for in a macroscopic model formulation by the correction term introduced in @xcite .",
    "a similar program shall be followed in section [ sec : learning ] where agents use td learning to learn the optimal strategy . as the learning scheme used in this paper can in fact be derived from the bellman equation used to set up the original model , an agent population that adapts according to this method should converge to the same equilibrium solution in a procedural way . however , as such an approach implements rationality as a process @xcite it describes the route to optimality and allows to analyze questions related to equilibrium selection and stability .",
    "we shall now describe the original model more carefully .",
    "consider an island populated by @xmath0 agents . on the island",
    "there are many palm trees and the agents wish to consume the coconuts that grow on these trees . the probability that agents find a coco tree",
    "is denoted by @xmath5 and harvesting a nut from the tree bears a cost @xmath6 ( the metaphor is the height of the tree ) that is described by a cumulative distribution @xmath7 defining the probability that the cost of a tree @xmath8 . in what follows we consider that the costs that come with a tree are uniformly distributed in the interval @xmath9 $ ] such that @xmath10 .",
    "agents can not store coconuts such that only agents without a nut may climb and harvest a new one",
    ". on encountering a tree ( with probability @xmath5 ) , an agent without coconut climbs if the cost @xmath6 of harvesting the tree they encountered does not exceed a strategic cost threshold @xmath3 ( referred to as strategy ) above which the agent assumes that harvesting the coconut would not be profitable . in other words , the probability with which an agent without nut will harvest a tree",
    "is given by @xmath11 .",
    "in the original model , the agent strategy is endogenously determined ( and then written as @xmath12 ) as described below .",
    "in what follows , we denote the state of an agent @xmath13 by the tuple @xmath14 where @xmath15 encodes whether agent @xmath13 holds a coconut or not and @xmath3 is the strategy of the agent .",
    "we define the macroscopic quantities @xmath16 and",
    "@xmath17 with the first being the number of coconuts in the population and the second the ratio of agents having a coconut , respectively . the time evolution in the limit of an infinite population can then be written as a differential equation ( de ) @xmath18 where the first term corresponds to the rate at which agents harvest a coconut and the second to trading with @xmath19 being the probability of randomly choosing two agents with coconut @xcite .",
    "@xmath20 corresponds to the optimal strategy of the agents .",
    "it is assumed to be homogeneous for the population but endogenously defined ( time - dependent ) in the original works of diamond and co - workers .",
    "@xmath21 is the fraction of trees that will be harvested at this cost threshold .",
    "a crucial ingredient of the coconut model is that agents are not allowed to directly consume the coconut they harvested .",
    "they rather have to search for a trading partner , that is , for another agent that also has a coconut . the idea behind this",
    "is that agents have to find buyers for the goods they produce .",
    "if an agent that possesses a nut encounters another agent with a nut both of them are supposed to consume instantaneously and derive each a reward of @xmath2 from this consumption . in effect",
    ", this means that the expected value of climbing a tree depends on the total number of coconuts in the population or , more precisely , on the time agents have to wait until a trading partner will be found .",
    "rational agents are assumed to maximize their expected future utility @xmath22 where @xmath23 corresponds to the cost of climbing or respectively to the utility @xmath2 from consumption of agent @xmath13 at time @xmath24 and @xmath25 to the discount factor .",
    "a fully rational agent has to find the strategy @xmath26 that maximizes its expected future reward and , since agents can not consume their coconut instantaneously , this reward depends on his expectation about their trading chances .",
    "this can be formulated as a dynamic programming problem with @xmath27 .",
    "considering that there are two states ( namely , @xmath28 or @xmath29 ) there is a value associated to having ( @xmath30 ) and to not having ( @xmath31 ) a coconut at time @xmath32 .",
    "as a rational agent accepts any opportunity that increases expected utility , a necessary condition for an optimal strategy is @xmath33 . by this reasoning , assuming homogeneous strategies @xmath34 diamond derives another de that describes the evolution of the optimal strategy @xmath35 \\label{eq : evodglstrat}\\ ] ]    the model ( [ eq : evodgl])-([eq : evodglstrat ] ) is interesting due to its a rather rich solution structure and because many macroeconomic models incorporating inter - temporal optimization have a similar form .",
    "first , the model may give rise to a market failure equilibrium which arises as a self - fulfilling prophecy where everyone believes that nobody else invests ( climbs the coco trees ) .",
    "it has multiple equilibria and it has been shown in @xcite that the model could also exhibit cyclic equilibria .",
    "this has been interpreted as an abstract model for endogenous business cycles .",
    "a complete stability analysis of the system ( [ eq : evodgl ] ) and ( [ eq : evodglstrat ] ) has been presented by @xcite .    the formulation of the model as a two - dimensional system of des ( [ eq : evodgl])-([eq : evodglstrat ] )",
    "@xcite assumes an infinite and homogeneously adapting population .",
    "while many aspects of the de system have been understood rather well using the corresponding analytical tools , some other important aspects of general theoretical interest can not be addressed within this setting .",
    "this includes equilibrium selection , but also stability and out - of - equilibrium perturbations , bounded or procedural rationality @xcite and learning , and finally the influence of micro - level heterogeneity . in order to address the first of these points  equilibrium selection ",
    "a reexamination of the model with finite populations had been undertaken in @xcite .",
    "the authors relate equilibrium selection to the finite - size stochastic fluctuations and show that transitions between different basins of attraction take place with positive probability .",
    "the benefit of implementing diamond s model as an abm is that we can eventually relax the other assumptions as well .",
    "as argued in the introduction , when reimplementing the model as an abm , we should make sure that the model incorporates the solution(s ) of the original model .",
    "in other words , that the abm with the original idealizations maintained leads to the same behavior .",
    "therefore , let us first look at the dynamics of the model when all agents adopt the same strategy @xmath4 .",
    "the fixed point solution of the de ( [ eq : evodgl ] ) is @xmath36 \\label{eq : fix}\\ ] ] which characterizes the equilibrium point @xmath37 for a given @xmath38 .",
    "if we implement the coconut model with homogeneous strategies @xmath38 in form of an abm we can expect that the average level of coconuts in the population approaches and fluctuates around the point @xmath39 .",
    "intuitively the diamond model as set up in the original paper @xcite could be implemented in the following way ( we refer to this > > intuitive < < implementation as ` i m ` ) : +    * random set - up : set strategies @xmath40 and initial states @xmath41 according to the desired initial distribution .",
    "* iteration loop : * * random choice of an agent @xmath13 with probability @xmath42 * * ` if ` @xmath43 climb a coco tree with probability @xmath11 and harvest a nut , i.e. , @xmath44 * * ` else if ` @xmath45 * * * choose a second agent @xmath46 with probability @xmath47 ( random matching ) * * * ` if ` @xmath48 trade such that @xmath49 and @xmath50    some short comments on this procedure are in order .",
    "for the initialization step ( 0 ) we usually define a desired level of coconuts in the initial population ( @xmath51 ) and a random initial state adhering to this level is obtained by letting each agent have a coconut with probability @xmath51 .",
    "the initialization of the strategies @xmath3 will be according to the different scenarios described in the next section but in general the strategies will ly in the interval @xmath9 $ ] . in this section ,",
    "the strategies are homogeneous and do not change over time so that all agents have identical strategies during all times .",
    "point ( 1a ) in the iteration process means that at each step we randomly choose one agent from the population .",
    "notice that this means that within @xmath0 iteration steps some agents may be chosen more than once whereas others might not be chosen at all . for point ( 1b )",
    "the climbing decision with probability @xmath52 is evaluated by drawing two random numbers , one for the rate of coco trees @xmath5 and another for the cost of the coconut which is uniformly distributed in the interval @xmath53 $ ] for all the experiments we perform throughout this paper .",
    "agents will climb the tree if @xmath54 . finally , if agent @xmath13 has a nut to trade ( 1c ) , a second agent @xmath46 is randomly chosen from the remaining agent set which means that there are no specific trading relations between the agents that direct the search for trading partners .",
    "in this section , we compare the outcome of the simulation model as specified above with homogeneous strategies @xmath4 to the behavior predicted by the de ( [ eq : evodgl ] ) .",
    "we look at a small system of only 100 agents in order to see how well the theoretical results obtained for infinite populations approximates the small - scale system . for the comparison",
    "the system is initialized with @xmath55 ( no coconuts in the population ) and run for 4000 steps to reach the stationary regime .",
    "then another 10000 update steps are performed during which we measure the mean level of coconuts @xmath56 in the population .",
    "we run a series of such experiments for different strategy values @xmath38 in between @xmath57 and @xmath58 .",
    "the results of this are shown by the stars points in fig .",
    "[ fig : comparisonim ] .    in addition",
    ", we also show the strategy dependent solution curve @xmath39 ( [ eq : fix ] ) obtained for the original de ( orange curve ) .",
    "it becomes clear that for the intuitive implementation the average coconut level is considerably below the de solution .",
    "this is due to the fact that in a single time step , on average , two agents may trade but only one agent may climb a coco tree and harvest a nut which means that the rate @xmath59 actually underestimates the decrease of coconuts by a factor of two .",
    "consequently , we should correct this term for @xmath60 in order to obtain a de corresponding to the behavior of the abm .",
    "that is , @xmath61 yielding the fixed point curve @xmath62 \\label{eq : fix2}\\ ] ] which is also shown ( green curve ) in fig . [ fig : comparisonim ] .",
    "it becomes clear that the simulation of the ` i m ` with homogeneous strategies reproduces fairly well the fixed point solution ( [ eq : fix2 ] ) of the adjusted de .",
    "notice that the adjusted de ( [ eq : evodgl2 ] ) does not change the behavior of the system ( [ eq : evodgl])-([eq : evodglstrat ] ) in a qualitative way .",
    "notice also that instead of multiplying @xmath59 by two , we could also rescale @xmath5 to @xmath63 so that the dynamical structure of the model is not really affected . for the experiments in section [ sec : heterogeneous ] we will stick to the intuitive model implementation ( ` i m ` ) as described above and use ( [ eq : fix2 ] ) for the comparison with the de description .      in order to obtain an abm that matches well with the original de description",
    ", we have at least two different options . on the one hand",
    ", we could allow two agents to climb at each time step by changing the iteration scheme to +    * iteration loop : * * random choice of an agent pair @xmath64 with probability @xmath65 * * ` if ` @xmath66 with probability @xmath11 climb tree and harvest , i.e. , @xmath44 * * ` if ` @xmath67 with probability @xmath68 climb tree and harvest , i.e. , @xmath69 * * ` else if ` @xmath70 trade such that @xmath49 and @xmath50    let s refer to this scheme as aligned model one ( ` am1 ` ) .",
    "on the other hand , we could decide that an agent @xmath13 with a nut ( @xmath71 ) trades that nut with a probability proportional to the number @xmath72 of coconuts in the population so that at most one coconut will be cleared at a single time step .",
    "the iteration ( we shall call this scheme ` am2 ` ) becomes : +    * iteration loop : * * random choice of an agent @xmath13 with probability @xmath42 * * ` if ` @xmath66 with probability @xmath11 climb tree and harvest , i.e. , @xmath44 * * ` else ` trade ( consume ) with probability @xmath72 such that @xmath49    in a sense , this mechanism does not really comply with what we usually do in an abm .",
    "however , it is a way to reproduce the fixed point solution ( [ eq : fix ] ) of the original de , which is shown in fig .",
    "[ fig : comparisonim ] as well .",
    "indeed , the two aligned schemes match very well with the de solution . `",
    "am2 ` will be used in section [ sec : learning ] where we incorporate learning dynamics into the model .",
    "in addition to the de and the abm formulation we shall consider here a third description in form of a markov chain ( mc ) . for homogeneous populations one can show that an mc description accounting for the transitions between the different numbers of coconuts in the population provides an exact formulation of a finite size abm with @xmath0 agents , @xcite . in the finite size case ,",
    "the possible @xmath56 are given as the finite set @xmath73 which we shall write as @xmath74 to simplify notation .",
    "we denote by @xmath75 the ( absolute ) number of agents with a coconut ( i.e. , @xmath76 ) . for the intuitive scheme ,",
    "the transition probabilities for the ` i m ` are given by @xmath77 and zero elsewhere .",
    "notice that trading decreases the number of coconuts by two whereas only one coconut can be harvested in a single transition as implemented by the intuitive model .",
    "if , instead , we choose @xmath78 and @xmath79 we obtain a mc representation that is aligned to the ` am2 ` scheme with only one agent consuming a nut on trade .    , @xmath80 and @xmath81 compared to the frequencies observed in 10 realizations ( each 100000 steps ) of the simulation model . ]",
    "a mc representation can be useful because it provides us with a good understanding about the finite size fluctuations around the equilibrium point . in fig .",
    "[ fig : pi100 ] , this is shown by comparing the observed coconut level in the intuitive model to the stationary vector of ( [ eq : homomc ] ) for the homogeneous strategy @xmath82 .",
    "notice , however , that the peak in the mc stationary vector and the solution of the de ( [ eq : fix2 ] ) do not match precisely .",
    "this is due to the fact that the trading probabilities ( with @xmath83 ) in the mean - field formulation do not explicitly exclude self - trading , whereas this is excluded in the mc formulation as well as in the abm ( and therefore the respective probability is @xmath84 ) . while the difference between the two probabilities is neglectable if @xmath0 is large , there is a notable effect for @xmath85",
    "we now relax the assumption of homogeneous strategies by assigning a random individual strategy @xmath3 to each agent drawn from a certain probability distribution .",
    "as before , the strategies are fixed for the entire simulation .",
    "the four different scenarios considered in the second part of this section differ with respect to the distribution from which the individual strategies are drawn ( in general , in the interval @xmath9 $ ] ) . before looking at these specific scenarios , however ,",
    "we derive a correction term that accounts for the effect of strategy heterogeneity .",
    "namely , if strategies are different we can expect that those agents in the population with a lower @xmath3 will also climb less often and are therefore less often with a coconut @xmath29 .",
    "that is , there is a correlation between the agent strategy @xmath3 and the probability @xmath86 that an agent has a coconut .    to account for this we have to consider that the rate @xmath87 that an agent of the population will climb from one time step to the other is given by @xmath88",
    "the equation covering the homogeneous case ( [ eq : homomc ] ) is satisfied because @xmath89 is equal for all agents and can be taken out of the sum .",
    "for heterogeneous strategies this is not possible but we can come to a similar expression by formulating @xmath87 as the expected value ( denoted as @xmath90 ) @xmath91 \\right]\\vspace{6pt}\\\\   & = f\\left [ ( 1- \\langle s_i\\rangle ) \\langle g(c_i)\\rangle - \\sigma[s_i , g(c_i ) ] \\right ] , \\end{array}\\ ] ] where @xmath92 $ ] is the covariance between agent states @xmath93 and individual climbing probability @xmath94 . with @xmath95 and @xmath96 ( the former being true due to the linearity of @xmath97 and the latter by definition ) this yields @xmath98 \\label{eq : corrmc}\\ ] ] which corresponds to the original term ( [ eq : homomc ] ) except for the additional covariance term @xmath99 .",
    "notice that the covariance depends on the individual agent states ( @xmath93 and @xmath94 ) so that the transition rate is no longer a pure function of the macroscopic average state .",
    "this correction term accounting for the correlation between the agent strategy and state should also be included into the infinite - size formulation ( [ eq : evodgl2 ] ) .",
    "this is accomplished by @xcite @xmath100- 2 \\epsilon^2 .",
    "\\label{eq : evodglkorrt}\\ ] ] note that covariance term @xmath101 in eq .",
    "( [ eq : evodglkorrt ] ) is here written as a time - dependent parameter because it depends on the actual microscopic agent configuration at time @xmath32 to be computed .",
    "in other words , this is no longer a closed description in the macroscopic variable @xmath56 as it is coupled to the evolution of the heterogeneity in the system contained in the covariance term .",
    "one way to address this issue is to derive an additional differential equation that describes the time evolution of @xmath102 and is coupled to ( [ eq : evodglkorrt ] ) . for this purpose",
    "let us denote the probability for an agent @xmath13 to be in state @xmath29 as @xmath103 .",
    "the evolution of this probability is described by @xmath104 which is very similar to the macroscopic equation ( [ eq : evodgl ] ) with the first term the probability of climbing and the second that of trading .",
    "the correction @xmath102 can be written as @xmath105 where @xmath106 ( @xmath107 in our case ) is the mean climbing probability .",
    "the differentiation is @xmath108 and substituting ( [ eq : evopropi ] ) and ( [ eq : evodglkorrt ] ) yields @xmath109 where @xmath110 is a new higher order covariance term between the second power of @xmath111 and the state probability @xmath112 .",
    "more generally , let us further denote the mean over powers of @xmath97 as @xmath113 and write @xmath114 when we express the dynamical equations for the correction term and then for the higher moment that emerges at each step , we arrive at the following infinite system of equations : @xmath115 hence , we see that a relatively simple form of heterogeneity  namely , a fixed heterogeneous cost threshold  leads to a rather complicated system when we aim at a closed description in terms of macroscopic or average entities . on the other hand ,",
    "if @xmath94 is strictly below one , these higher moments @xmath116 tend to zero as @xmath117 increases which allows , under certain conditions , to close the system .",
    "however , this goes beyond the scope of this paper and will be addressed elsewhere .      another way to illustrate the usefulness of the correction term derived for",
    "the heterogeneous model is to estimate @xmath102 from simulations .",
    "therefore , we run the abm with a certain strategy distribution and compute @xmath118 for each step .",
    "we then compute the time average over 2000 simulation steps which we may denote by @xmath119 and replace the correction terms in ( [ eq : corrmc ] ) and ( [ eq : evodglkorrt ] ) by this average heterogeneity term . the respective transition probability for the markovian description then becomes @xmath120\\ ] ] and we can compute the corrected stationary vector on that basis . likewise from ( [ eq : evodglkorrt ] ) we obtain for the fixed point solution @xmath121 .",
    "\\label{eq : fixkorr}\\ ] ]    these terms are now confronted with simulations initialized according to different distributions of individual strategies .",
    "namely , we consider four cases :    1 .",
    "strategies uniformly distributed within @xmath9 $ ] , 2 .",
    "there are two different strategies distributed at equal proportion over the population 3 .",
    "the probability of a strategy @xmath3 decreases linearly from @xmath57 to @xmath58 and reaches zero at @xmath58 4 .",
    "probability of a strategy @xmath3 decreases according to a @xmath122-distribution with shape @xmath123 and scale @xmath124    notice that the first two cases are chosen such that the mean climbing probability is @xmath125 whereas lower thresholds and therefore a lower average climbing probability are implemented with the latter two .    , @xmath80 , @xmath126 and the comparison to the frequencies observed in a series of 10 realization ( 10000 steps ) of the simulation model.,title=\"fig : \" ] , @xmath80 , @xmath126 and the comparison to the frequencies observed in a series of 10 realization ( 10000 steps ) of the simulation model.,title=\"fig : \" ]    , @xmath80 , @xmath126 and the comparison to the frequencies observed in a series of 10 realization ( 10000 steps ) of the simulation model.,title=\"fig : \" ] , @xmath80 , @xmath126 and the comparison to the frequencies observed in a series of 10 realization ( 10000 steps ) of the simulation model.,title=\"fig : \" ]",
    "the results of applying the heterogeneity correction are shown in figs .",
    "[ fig : pi100korr01 ] and [ fig : pi100korr02 ] . for the four scenarios , the fixed point with correction ( [ eq : fixkorr ] )",
    "is shown by the vertical line along with the two stationary distributions of the mcs with and without correction .",
    "the crosses in the plot correspond to simulation results measured on 10 simulation runs  10000 steps .",
    "in general , while significant deviations from the simulation results are visible for the descriptions without correction ( homogeneous case ) , the stationary statistics of the model are well  matched after the covariance correction is applied .",
    "this shows that very effective macroscopic formulations of heterogeneous agent systems may be possible by including correction terms that efficiently condense the actual micro - level heterogeneity in the system .",
    "having gained understanding about how to deal with heterogeneous strategies in the finite - size coconut model , we shall now turn to an adaptive mechanism by which the strategies are endogenously set by the agents . as in section",
    "[ sec : homogeneous ] , we follow in this implementation the conception of diamond @xcite as closely as possible . that is , firstly , the threshold @xmath3 has to trade off the cost of climbing against the expected future gain of earning a coconut from it . in other words , agents have to compare the value ( or expected performance if you wish ) of having a coconut @xmath127 with the value @xmath128 of staying without a nut .",
    "if the difference between the expected gain from harvesting at time @xmath32 and that of not harvesting ( @xmath129 ) is larger than the cost of the tree @xmath6 , agents can expect a positive reward from harvesting a nut now .",
    "therefore , in accordance to @xcite , it is reasonable to set @xmath130 .",
    "now , how do agents arrive at reliable estimates of @xmath127 and @xmath128 ?",
    "we propose that they do so by a simple temporal difference ( td ) learning scheme that has been designed to solve dynamic programming problems as posed in the original model .",
    "notice that for single - agent markov decision processes temporal difference schemes are proven to converge to the optimal value functions @xcite . in the coconut model with agents updated sequentially it is reasonable to hypothesize that we arrive at accurate estimates of @xmath127 and @xmath128 as well . but notice also that the decision problem as posed in @xcite is not the only possibility to formulate the problem .",
    "namely the model assumes that agents condition their action only on their own current state neglecting previous trends and information about other agents the consideration of which might lead to a richer set of solutions . in our case agents",
    "do not learn the @xmath56 dependence explicitly , which means that the agents will only learn optimal stationary strategies .",
    "the consideration of more complex ( and possibly heterogeneous ) information sets points certainly to interesting extensions of the model .",
    "however , we think that it is useful to first understand the basic model and relate it to the available theoretical results as this will also be needed to understand additional contributions by model extensions .",
    "the learning algorithm we propose is a very simple value td scheme .",
    "agents use their own reward signal @xmath131 to update the values of @xmath132 and @xmath133 independently from what other agents are doing . in each",
    "iteration agents compute the td error by comparing their current reward plus the discounted expected future gains to their current value estimate @xmath134}_{\\text{\\normalsize estimated discounted future value } } - \\underbrace{\\left [ s_i^t v_i^t(1 ) + ( 1-s_i^t ) v_i^t(0 ) \\right]}_{\\text{\\normalsize current estimate } } \\label{eq : tderror}\\ ] ] which becomes @xmath135 for the different possible transitions @xmath136 of the agents .",
    "notice that the discount factor @xmath25 as defined for the time continuous de system is rescaled as @xmath137 for the discrete - time setting and in order to account for the finite simulation with asynchronous update in which only one ( out of @xmath0 ) agents is updated in each time step ( @xmath138 ) .",
    "the iterative update of the value functions is then given by @xmath139 such that @xmath140 ( @xmath141 ) is updated only if agent @xmath13 has been in state @xmath123 ( @xmath142 ) in the preceding time step .",
    "the idea behind this scheme and td learning more generally is that the error between subsequent estimates of the values is reduced as learning proceeds which implies convergence to the true values .",
    "the form in which we implement it here is probably the most simple one which does not involve update propagation using eligibility traces usually integrated to speed up the learning process @xcite . in other words ,",
    "agents update only the value associated with their current state @xmath143 .",
    "while simplifying the mathematical description ( the evolution depends only on the current state ) we think this is also plausible as an agent decision heuristic .",
    "all in all the model implementation is +    * initialization : set initial values @xmath144 and states @xmath41 according to the desired initial distribution .",
    "set initial strategies @xmath145 .",
    "* iteration loop i ( search and trade ) : * * random choice of an agent @xmath13 with probability @xmath42 * * ` if ` @xmath28 climb a coco tree with probability @xmath11 and harvest a nut , i.e. , @xmath44 * * ` else ` trade ( consume ) with probability @xmath72 such that @xmath49 * iteration loop ii ( learning ) : * * compute td error @xmath146 for all agents with reward signal @xmath147 and @xmath148 depending on the action of @xmath13 in part ( 1 ) * * update relevant value function by @xmath149 for all agents * * update strategy by @xmath150    notice that for trading we adopt the mechanism introduced as ` am2 ` in section [ sec : aligning ] . if not stated otherwise , the simulation experiments that follow are performed with the following parameters .",
    "the interval from which the tree costs are drawn is given by @xmath151 and @xmath152 .",
    "a strategy @xmath3 larger than @xmath58 hence means that the agent accepts any tree , @xmath153 that no tree is accepted at all .",
    "the rate of tree encounter is @xmath154 and the utility of coconuts is @xmath155 .",
    "we continue considering a relatively small system of 100 agent and the learning rate is @xmath156 .",
    "the parameter much of the analysis will be concentrated on is the discount rate @xmath25 with small values indicating farsighted agents whereas larger values discount future observations more strongly .",
    "the system is initialized ( if not stated otherwise ) with @xmath157 , @xmath158 and @xmath159 for all agents such that @xmath160 .",
    "the first part of this paper ( exogonously fixed strategies ) has shown that the abm reproduces well the fixed point curve obtained for the coconut dynamics by setting @xmath162 . here",
    "we want to find out whether the simulation with td learning ( adaptive strategies ) matches with the fixed point behavior of the strategy dynamics of the original model obtained by setting @xmath161 .",
    "[ fig : learningmatchtheory ] shows the respective curves for three different @xmath163 .",
    "notice that the last value @xmath164 is so large that the @xmath56 and @xmath38curves do not intersect so that there is actually no fixed point solution .    in order to check these curves in the simulations we fix the expected probability of finding a trading partner by @xmath165 .",
    "independent of the actual level of coconuts in the population , an agent finds a trading partner with that probability , consumes the coconut and derives a reward of @xmath2 . for fig .",
    "[ fig : learningmatchtheory ] , for each @xmath166 the abm is run a single time for 200000 steps and the last system configuration ( namely , @xmath3 at the final step ) is used in the computation of the mean strategy @xmath38 which is then plotted against @xmath167 .     and comparison to the td learning dynamics implemented in the agent model .",
    ", scaledwidth=55.0% ]    the model generally matches with the theoretical behavior , especially when @xmath25 is small ( farsighted agents ) .",
    "however , for @xmath168 and @xmath169 we observe noticeable differences between the simulations and the fixed point curve of the theoretical model .",
    "notice that the number of coconuts @xmath56 ( which we fix for the trading step ) actually also affects the probability with which an agent is chosen to climb and that the actual level of coconuts in the simulation is generally different from @xmath167 .",
    "this might explain the deviations observed in fig .",
    "[ fig : learningmatchtheory ] . setting up the experiment",
    "so that the level of coconuts is constant at @xmath167 , however , is not straightforward because an additional artificial state - switching mechanism would have to be included that has no counterpart in the actual model .    on the other hand , the results shown in fig .",
    "[ fig : learningmatchtheory ] are actually a promising indication that agents which adapt according to td learning align with the theoretical results in converging to the same ( optimal ) strategy for a given @xmath56 .",
    "the next logical step is now to compare the overall behavior of the abm with learning to the theory .      for this purpose",
    ", we check the overall convergence behavior of the abm as a function of @xmath25 and compare it to the fixed point solution of @xcite , see also @xcite .",
    "there are two interesting questions here :    1 .",
    "what happens as we reach the bifurcation value @xmath170 at which the two fixed point curves @xmath162 and @xmath161 cease to intersect ?",
    "2 .   in the parameter space where they intersect , which of the two solutions is actually realized by the abm with td learning ?    both questions are answered with fig .",
    "[ fig : fixedpointsgammaai ] .    ) -",
    "( [ eq : evodglstrat ] ) for @xmath171 $ ] is compared to single model realizations ( 200000 steps ) for different @xmath25 .",
    "the agent model with td learning scheme converges closely to the theoretic fixed point values .",
    "r.h.s . : close - up view @xmath172 $ ] . in the experiments the model always reached the upper fixed point.,scaledwidth=100.0% ]    first , if @xmath25 becomes large , the abm converges to the state in which agents do not climb any longer .",
    "that is , @xmath173 and @xmath174 .",
    "however , as the close - up view on the right - hand side shows , the bifurcation takes place at slightly lower values of @xmath25 .",
    "this is probably related to the deviations observed in fig .",
    "[ fig : learningmatchtheory ] .",
    "in fact , further experiments revealed that the learning rate @xmath175 governing the fluctuations of the value estimates plays a decisive role ( the larger @xmath175 , the smaller the bifurcation point ) .",
    "the larger @xmath175 is , the more likely a perturbation takes place on the values of an agent ( @xmath13 ) which takes @xmath176 meaning that agent @xmath13 does not climb any longer .",
    "besides this small deviation , however , fig .",
    "[ fig : fixedpointsgammaai ] shows that on the whole the abm reproduces the theoretical results with considerable accuracy .    regarding the second question  that is , equilibrium selection ",
    "it seems that the only stable solution for the simulated dynamics is the upper fixed point , sometimes referred to as > > optimistic < < solution .",
    "we will confirm this in the sequel by providing numerical arguments for the instability of the lower fixed point by a series of simulation experiments .",
    "the previous experiments indicate that the lower fixed point derived in the original system is generally unstable under learning dynamics . in this section",
    "we present some further results to confirm this observation by initializing the model at the lower fixed point .",
    "we concentrate again on the parameterization used in the previous sections with @xmath177 , climbing costs uniformly distributed in @xmath9 $ ] and stick to a discount rate @xmath178 . as shown in fig .",
    "[ fig : learningmatchtheory ] , the respective > > pessimistic < < equilibrium solution is given by @xmath179 and @xmath180 just slightly above @xmath57 .",
    "however , for the true fixed point initialization of the simulation model , we have to use the respective values at the fixed point @xmath181 to initialize @xmath182 and @xmath183 .",
    "they can be obtained by solving the three - dimensional system from which eq .",
    "( [ eq : evodglstrat ] ) has been derived @xcite : @xmath184 where @xmath185 as before . with the parameters as given above , we obtain @xmath186 and @xmath187 .",
    "[ fig : stability01 ] shows the evolution ( 200000 steps ) of the abm with td learning for various initial conditions close to the low fixed point ( shown by the dashed dark line ) .",
    "there are 100 agents and the learning rate is @xmath188 .",
    "each curve in the plot is an average over 5 simulation runs .",
    "we first look at the bold curve corresponding to the trajectory starting at the lower fixed point ( see indication in the figure ) .",
    "it is clearly repelled from the low fixed point into the direction of the > > optimistic < < solution , however , it fails to reach the upper state .",
    "the figure also shows trajectories that are initialized with slightly higher @xmath182 leading to a slight increase of the initial strategy @xmath189 .",
    "the larger this initial deviation , the closer the trajectories converge to the expected > > optimistic < < strategy @xmath190 , but for a deviation smaller than @xmath191 the asymptotic behavior of the learning dynamics does not converge to this value .",
    "interestingly , also simulations initialized slightly below with an initial deviation of @xmath192 evolve into the direction of the upper solution , however , settling at a still smaller final strategy value .",
    "while this shows that the lower fixed point ( or at least a point very close to it ) is repelling , this effect of convergence to almost arbitrary states in between the two expected fixed points seems somewhat surprising at the first glance .",
    "one possible explanation is that td learning schemes may converge to suboptimal solutions if agents to not sufficiently explore the space of possibilities . in order to check",
    "if this is the reason for the unexpected convergence behavior when starting with the low initial values , we integrated a form of exploration by adding a small amount of noise to the strategies @xmath3 each time after the agents computed their new values .",
    "this can be seen as if agents are not completely perfect in determining the values and the respective value difference @xmath193 or just as well that they believe to be able to form estimates only of a given finite precision . in the simulations shown below , a random value uniformly distributed in between @xmath194 and @xmath195 has been added .",
    "the result of this > > exploration < < variant is shown in fig . [ fig : stability02 ] which compares the time evolution of the model starting exactly in the theoretical low fixed point with respect to different system sizes . in comparison with fig .",
    "[ fig : stability01 ] , where only @xmath85 has been considered and the initial deviation from the fixed point has been varied across realizations , we now observe an @xmath196shaped curve that approaches the upper fixed point and stabilizes there with high accuracy .",
    "this is observed for all @xmath0 .    as the size of the system increases , the initial period in which the system stays close to the lower fixed point increases .",
    "however , as shown on the right of fig .",
    "[ fig : stability02 ] , the differences between the learning curves in systems of different size vanish when time is rescaled by the number of agents such that one time step accounts for @xmath0 individual updates .",
    "this provides further evidence for the instability of the lower fixed point and shows that it is not merely a finite size effect but inherent in the agent system with procedural rationality based on td learning .    to summarize the analysis performed in this section",
    ", we computationally constructed the phase diagrams for the dynamics with learning for a system of 100 agents .",
    "that is , we perform a suite of systematic computations with samples of initial conditions in the plane spanned by @xmath197 $ ] and @xmath198 $ ] .",
    "we compute @xmath199 samples where @xmath189 is determined by letting @xmath200 and @xmath201 set homogeneously for the entire population .",
    "the initial level of coconuts is set randomly with @xmath197 $ ] such that the probability for each agent to have a coconut in the beginning is @xmath51 . for each initial combination",
    "we compute 10 simulations  10000 steps and compare the initial point @xmath202 with the respective outcome after 10000 steps .",
    "the result is shown in fig [ fig : stability03 ] for a discount rate of @xmath203 ( l.h.s . ) and @xmath204 ( r.h.s . ) .",
    "( left ) and @xmath204 ( right ) .",
    "the fixed point curves of the de system are also shown.,title=\"fig:\",scaledwidth=49.0% ]   ( left ) and @xmath204 ( right ) .",
    "the fixed point curves of the de system are also shown.,title=\"fig:\",scaledwidth=49.0% ]    the vector field indicates convergence to a state close to the upper fixed point for most of the initial conditions . for @xmath178 this is true even for very small initial strategies @xmath205 .",
    "however , we should notice that this point is very close to @xmath57 and that the sampling does not resolve the region around the low fixed point well enough .",
    "for @xmath206 where the strategy value in the lower fixed point increases to @xmath207 the dynamics around that point become visible . in this case",
    "we observe that initial strategies below this value lead to convergence to @xmath208 , that is to the situation in which agents do not climb any longer ( and therefore @xmath209 ) .",
    "however , if initially the level of coconuts is high enough the system is capable of reaching the stable upper solution because there is at least one instant of learning that having a nut is profitable ( @xmath210 ) for agents initially endowed with a nut .",
    "finally , a close - up view on this region is provided in fig .",
    "[ fig : stability04 ] for @xmath206 .",
    "it renders visible that the lower fixed point acts as a saddle under the learning dynamics . as noticed earlier , the exact fixed point values @xmath37 and @xmath20 are slightly different for the de system and the learning agents model which may be attributed to small differences in the models such as explicit exclusion of self - trading ( see section [ sec : homogeneous ] ) or the discrete learning rate @xmath175 ( this section ) .",
    "this paper makes four contributions .",
    "first , it develops a theory - aligned agent - based version of diamond s coconut model @xcite . in the model agents",
    "have to make investment decisions to produce some good and have to find buyers for that good .",
    "step by step , we analyzed the effects of single ingredients in that model  from homogeneous to heterogeneous to adaptive strategies  and relate them to the qualitative results obtained from the original dynamical systems description .",
    "we computationally verify that the overall behavior of the abm with adaptive strategies aligns to a considerable accuracy with the results obtained in the original model .",
    "the main outcome of this exercise is the availability of an abstract baseline model for search equilibrium which allows to analyze more realistic behavioral assumptions such as trade networks , heterogeneous information sets and different forms of bounded rationality but contains the idealized solution as a limiting case .",
    "secondly , this work provides insight on the effects of micro - level heterogeneity on the macroscopic dynamics and shows how heterogeneous agents can be taken into account in aggregate descriptions .",
    "we derive a heterogeneity correction term that condenses the present heterogeneity in the system and show how this term should be coupled to the mean - field equation .",
    "these mathematical arguments show that a full characterization of the system with heterogeneity leads to an infinite dimensional system of differential equations the analysis of which will be addressed in the future . in this paper",
    "we have provided support for the suitability of the heterogeneity term by simulation experiments with four different strategy distributions .",
    "we envision that the heterogeneity correction may be useful for other models such as opinion dynamics with heterogeneous agent susceptibilities as well .",
    "the third contribution this paper makes , is the introduction of temporal difference ( td ) learning as a way to address problems that involve inter - temporal optimization in an agent - based setting .",
    "the coconut model serves this purpose so well because the strategy equation in the original paper is based on dynamic programming principles which are also at the root in this branch of reinforcement learning . due to this common foundation",
    "we arrive at an adaptive mechanism for endogenous strategy evolution that converges to one of the theoretical equilibria , but provides , in addition to that , means to understand how ( and if ) this equilibrium is reached from an out - of - equilibrium situation .",
    "such a characterization of the model dynamics is not possible in the original formulation .",
    "our fourth contribution relates to that in providing some new insight into equilibrium selection and stability of equilibria in the coconut model . under learning dynamics",
    "only the upper > > optimistic < < solution with a high coconut level ( high productivity ) is realized .",
    "furthermore , convergence to this equilibrium takes place for a great proportion of out - of - equilibrium states .",
    "in fact , the phase diagrams presented at the end of the previous section show that in a system with farsighted agents ( @xmath178 ) the market failure equilibrium ( no production , no trade ) is reached only if agents are exceedingly pessimistic . if agents are less farsighted ( @xmath206 ) , this turning point increases slightly and makes market failure probable if the production level ( @xmath211 ) is currently low for some reason .",
    "however , we do not want to make general claims about the absence of cyclic equilibria in the artificial search and barter economy that the coconut model exemplifies .",
    "it is possible  even likely  that a richer behavior is obtained when agents learn not only based on their own state but take into account information about the global state of the system , trends or the strategy of others .",
    "this paper has been a necessary first step to address such question in the future .",
    "all models described in this paper have been implemented and analyzed using mathematica and matlab .",
    "the matlab version is made available at the openabm model archive @xcite ( see https://www.openabm.org/model/5045/version/1 ) .",
    "grimm , v. , berger , u. , bastiansen , f. , eliassen , s. , ginot , v. , giske , j. , goss - custard , j. , grand , t. , heinz , s.  k. , huse , g. , huth , a. , jepsen , j.  u. , jorgensen , c. , mooij , w.  m. , muller , b. , peer , g. , piou , c. , railsback , s.  f. , robbins , a.  m. , robbins , m.  m. , rossmanith , e. , ruger , n. , strand , e. , souissi , s. , stillman , r.  a. , vabo , r. , visser , u. & deangelis , d.  l. ( 2006 ) . a standard protocol for describing individual - based and agent - based models . _ ecological modelling _ , _ 198 _ , 115126                      vriend , n.  j. ( 2000 )",
    ". an illustration of the essential difference between individual and social learning , and its consequences for computational analyses .",
    "_ journal of economic dynamics and control _ , _",
    "24_(1 ) , 119"
  ],
  "abstract_text": [
    "<S> in this paper , we develop an agent - based version of the diamond search equilibrium model  also called coconut model . in this model , </S>",
    "<S> agents are faced with production decisions that have to be evaluated based on their expectations about the future utility of the produced entity which in turn depends on the global production level via a trading mechanism . </S>",
    "<S> while the original dynamical systems formulation assumes an infinite number of homogeneously adapting agents obeying strong rationality conditions , the agent - based setting allows to discuss the effects of heterogeneous and adaptive expectations and enables the analysis of non - equilibrium trajectories . </S>",
    "<S> starting from a baseline implementation that matches the asymptotic behavior of the original model , we show how agent heterogeneity can be accounted for in the aggregate dynamical equations . </S>",
    "<S> we then show that when agents adapt their strategies by a simple temporal difference learning scheme , the system converges to one of the fixed points of the original system . </S>",
    "<S> systematic simulations reveal that this is the only stable equilibrium solution .    </S>",
    "<S> * the coconut model with heterogeneous strategies and learning * + s. banisch , e. olbrich + max planck institute for mathematics in the sciences , leipzig , germany    ( 1,0 ) 450    ( 1,0 ) 450    the results of this paper have been subsequently presented at the 2015 and 2016 conference on artificial economics ( ) . </S>",
    "<S> we acknowledge the valuable feedback from the participants of these two events . </S>",
    "<S> the work was supported from the european community s seventh framework programme ( fp7/2007 - 2013 ) under grant agreement no .  </S>",
    "<S> 318723 ( mathemacs ) . </S>",
    "<S> s.b . also acknowledges financial support by the klaus tschira foundation .    </S>",
    "<S> ( 1,0 ) 450 </S>"
  ]
}