{
  "article_text": [
    "first introduced in 1987 , the reactive planning model of georgeff and lansky s prs system has subsequently proved to be one of the most influential and long - lived approaches to programming multi - agent systems @xcite . the  programming language , introduced by rao @xcite , represents an attempt to distill the key features of the prs approach into a simple , abstract , logic - based language .",
    "is particularly interesting , in comparison to other agent - oriented languages , in that it retains the most important aspects of the bdi - based reactive planning systems on which it was based , and at the same time it has robust working interpreters @xcite , its formal semantics and relation to bdi logics @xcite have been thoroughly studied @xcite , and there is ongoing work on the use of model - checking techniques for verification of  multi - agent systems @xcite .    in the original formulation of @xcite , the main emphasis was on the _ internal _ control structures and decision - making cycle of an agent : the issue of _ communication _ between agents was not addressed .",
    "accordingly , most attempts to give a formal semantics to the language have focused on these internal aspects @xcite .",
    "although several extensions to have been proposed in an attempt to make it a practically more useful language @xcite , comparatively little research has addressed the issue of a principled mechanism to support communication in , which is clearly essential for engineering _ multi_-agent systems .",
    "most agent communication languages have taken _ speech - act theory _",
    "@xcite as their starting point .",
    "as is suggested by its name , speech - act theory is predicated on the view that utterances are _ actions _ , performed by rational agents in the furtherance of their personal desires and intentions .",
    "thus , according to speech - act theory , utterances may be considered as actions performed by an agent , typically with the intention of changing the mental state of the hearer(s ) of the utterance .",
    "speech - act theory thus seems particularly appropriate as a foundation for communication among intentional agents . through communication ,",
    "an agent can share its internal state ( beliefs , desires , intentions ) with other agents , and can attempt to influence the mental states of other agents .",
    "although an initial speech - act based communication model for   agents was previously introduced @xcite , no formal semantics of that model was given in that paper . a preliminary formal account for communication of agents",
    "was first given by @xcite @xcite .",
    "the main contribution of the present paper is to thoroughly extend the operational semantics of accounting for speech - act style communication .",
    "our semantics precisely defines how to implement the processing of messages _ received _ by an  agent ; that is , how the computational representations of mental states are changed when a message is received .",
    "note that in implementations of the bdi architecture , the concepts of _ plan _ and _ plan library _ is used to simplify aspects of deliberation and means - ends reasoning",
    ". therefore , an  agent _ sends _ a message whenever there is a communicative action in the body of an intended plan that is being executed ; such plans are typically written by an agent programmer .    as pointed out by singh @xcite , well - known approaches to agent communication focus largely on the sender s perspective , ignoring how a message should be processed and understood .",
    "this is the main aspect of agent communication that we consider in this paper . in extending the operational semantics of  to account for inter - agent communication",
    ", we also touch upon another long - standing problem in the area of multi - agent systems : the semantics of communication languages based on speech acts .",
    "the difficulty here is that , taking their inspiration from attempts to develop a semantics of human speech acts , most semantics for agent communication languages have defined the meaning of messages between agents with respect to the mental states of communication participants .",
    "while this arguably has the advantage of remaining neutral on the actual internal structure of agents , a number of authors have observed that this makes it impossible in general to determine whether or not some program that claims to be implementing the semantics really _ is _ implementing it @xcite .",
    "the problem is that if the semantics makes reference to an agent believing ( or intending a state satisfying ) a certain proposition , there is no way to ensure that any software using that communication language complies with the underlying semantics of belief ( or intention , or mental attitudes in general ) .",
    "this is related to the fact that previous approaches attempt to give a programming language independent semantics of agent communication .",
    "our semantics , while developed for one specific language , have the advantage of not relying on mechanisms  such as abstractly defined mental states  that can not be verified for real programs .",
    "we note that , to the best of our knowledge , our work represents the first semantics given for a speech - act style , `` knowledge level '' communication language that is used in a real system .",
    "since a precise notion of belief - desire - intention has been given previously for  agents @xcite , we can provide such a computationally grounded @xcite semantics of speech - act based communication for this language , making it possible to determine how an  agent interprets a particular message when it is received .",
    "note , however , that whether and how an agent acts upon received communication depends on its plan library and its other circumstances at the time the message is processed . also , although our approach is tied to a particular language , it can be usefully employed as a reference model for developing communication semantics and implementing communication in other agent programming languages",
    ".    the remainder of this paper is organised as follows .",
    "section  [ secbsabac ] provides the general background on prs - style bdi architectures and speech - act based agent communication .",
    "section  [ secssa ] presents syntax and semantics  a much revised version of the syntax and semantics of  presented by moreira and bordini @xcite .",
    "section  [ secscaa ] presents the speech - act based communication model for  agents , an extension of the preliminary formal account given by @xcite @xcite .",
    "section  [ secerarc ] illustrates the semantics with an example of the semantic rules applied in a typical reasoning cycle . in section  [ secdefc ] ,",
    "we show how programmers can use our basic communication constructs to develop some of the more elaborate forms of communication required by some multi - agent applications ( for example , ensuring that a belief is shared between two agents and keeping track of the progress in the achievement of a delegated goal ) , and in section  [ secpcpaa ] we give a simple example of the use of our framework for proving properties of communicating agents .",
    "section  [ secapp ] presents a discussion on applications and further developments for the language presented in this paper .",
    "conclusions and planned future work are given in the final section .",
    "the ability to _ plan _ seems to be one of the key components of rational action in humans .",
    "planning is the ability to take a goal , and from this goal generate a `` recipe '' ( i.e. , plan ) for action such that , if this recipe is followed ( under favourable conditions ) , the goal will be achieved .",
    "accordingly , a great deal of research in artificial intelligence has addressed the issue of _ automatic planning _ : the synthesis of plans by agents from first principles @xcite . unfortunately , planning is , like so many other problems in artificial intelligence , prohibitively expensive in computational terms .",
    "while great strides have been made in developing efficient automatic planning systems @xcite , the inherent complexity of the process inevitably casts some doubt on whether it will be possible to use plan - synthesis algorithms to develop plans at run - time in systems that must operate under tight real - time constraints .",
    "many researchers have instead considered approaches that make use of _ pre - compiled _ plans , i.e. , plans developed off - line , at design time .",
    "the _ procedural reasoning system ( prs ) _ of georgeff and lansky is a common ancestor of many such approaches @xcite .      on one level",
    ", the prs can be understood simply as an architecture for executing pre - compiled plans . however , the control structures in the architecture incorporate a number of features which together provide a sophisticated environment for run - time practical reasoning .",
    "first , plans may be invoked by their _ effect _ , rather than simply by name ( as is the case in conventional programming languages ) .",
    "second , plans are associated with a _ context _ , which must match the agent s current situation in order for the plan to be considered a viable option .",
    "these two features mean that an agent may have multiple potential plans for the same end , and can dynamically select between these at run - time , depending on current circumstances .",
    "in addition , plans are associated with _ triggering events _ , the idea being that a plan is made `` active '' by the occurrence of such an event , which may be external or internal to the agent .",
    "external events are changes in the environment as perceived by the agent ; an example of an internal event might be the creation of a new sub - goal , or the failure of a plan to achieve its desired effect .",
    "thus , overall , plans may be invoked in a goal - driven manner ( to satisfy a sub - goal that has been created ) or in an event - driven manner .",
    "the prs architecture is illustrated in figure  [ fig : prs ] .",
    "the  language , introduced by rao @xcite , represents an attempt to distill the `` essential '' features of the prs into a simple , unified programming language ; we provide a detailed introduction to  below , after we discuss speech - act theory and agent communication .      the prs model , and the  language in turn ,",
    "are primarily concerned with the internal structure of decision making , and in particular the interplay between the creation of and the execution of plans to achieve these .",
    "the twin issues of _ communication _ and _ multi - agent interaction _ are not addressed within the basic architecture .",
    "this raises the question of how such issues might be dealt with within the architecture .",
    "while bdi theory is based on the philosophical literature on practical reasoning @xcite , agent communication in multi - agent systems is typically based on the speech - act theory , in particular the work of austin @xcite and searle @xcite .",
    "speech - act theory starts from the principle that language is action : a rational agent makes an utterance in an attempt to change the state of the world , in the same way that an agent performs `` physical '' actions to change the state of the world .",
    "what distinguishes speech acts from other ( `` non - speech '' ) actions is that the domain of a speech act  the part of the world that the agent wishes to modify through the performance of the act  is mostly the mental state(s ) of the hearer(s ) of the utterance .",
    "speech acts are generally classified according to their _ illocutionary force _  the `` type '' of the utterance . in natural language ,",
    "illocutionary forces are associated to utterances ( or locutionary acts ) .",
    "the utterance `` the door is open '' , for example , is generally an `` inform '' or `` tell '' type of action .",
    "the _ perlocutionary force _ represents what the speaker of the utterance is attempting to achieve by performing the act . in making a statement such as `` open the door '' , the perlocutionary force will generally be the state of affairs that the speaker hopes to bring about by making the utterance ; of course , the _ actual _ effect of an utterance will be beyond the control of the speaker . whether i choose to believe you when you inform me that the door is open depends upon how i am disposed towards you .",
    "in natural language , the illocutionary force and perlocutionary force will be implicit within the speech act and its context .",
    "when the theory is adapted to agent communication , however , the illocutionary forces are made explicit to facilitate processing the communication act .",
    "the various types of speech acts are generally referred to as `` performatives '' in the context of agent communication .",
    "other pragmatic factors related to communication such as social roles and conventions have been discussed in the literature @xcite .",
    "illocutionary forces may require the existence of certain relationships between speaker and hearer for them to be felicitous .",
    "a _ command _",
    ", for instance , requires a subordination relation between the individuals involved in the communication , whereas such subordination is not required in a _",
    "request_.    apart from illocutionary forces and social roles , other classifications of the relations among speech acts have been proposed @xcite ; for example , a reply follows a question , and threatening is stronger than warning .",
    "such categories place messages in the larger context of a multi - agent dialogue . in multi - agent systems ,",
    "communicative interactions can be seen as communication protocols , which in turn are normally related to a specific coordination / cooperation mechanism .",
    "the contract net @xcite , for example , is a protocol for task allocation , which is defined in terms of a number of constituent performatives ( such as announcing and bidding ) .",
    "the knowledge query and manipulation language ( kqml ) , developed in the context of the `` knowledge sharing effort '' project @xcite , was the first attempt to define a practical agent communication language that included high level ( speech - act based ) communication as considered in the distributed artificial intelligence literature .",
    "kqml is essentially a knowledge - level messaging language @xcite .",
    "kqml defines a number of performatives , which make explicit an agent s intentions in sending a message .",
    "for example , the kqml performative ` tell ` is used with the intention of changing the receiver s _ beliefs _ , whereas ` achieve ` is used with the intention of changing the receiver s _",
    "goals_. thus the performative label of a kqml message explicitly identifies the intent of the message sender .",
    "the fipa standard for agent communication was released in 2002 .",
    "this standard is closely based on kqml , being almost identical conceptually and syntactically , while differing in the performative set and certain details of the semantic framework @xcite .",
    "these differences are not important for the purposes of this paper ; when we refer to traditional approaches to semantics of speech - act based inter - agent communication , the reference applies to both equally .",
    "however , for historical reasons , we refer mainly to kqml and the richer literature that can be found on its semantics .",
    "perhaps the first serious attempt to define the semantics of kqml was made by labrou and finin @xcite .",
    "their work built on the pioneering work of cohen and perrault on an action - theoretic semantics of natural language speech acts @xcite .",
    "the key insight in cohen and perrault s work was that , if we take seriously the idea of utterances as action , then we should be able to apply a formalism for reasoning about action to reasoning about utterances .",
    "they used a strips - style pre- and post - condition formalism to define the semantics of `` inform '' and `` request '' speech acts ( perhaps the canonical examples of speech acts ) , where these pre- and post - conditions were framed in terms of the beliefs , desires , and abilities of conversation participants . when applied by labrou and finin to the kqml language @xcite , the pre- and post - conditions defined the mental states of the sender and receiver of a kqml message before and after sending such message .",
    "for the description of mental states , most of the work in the area is based on cohen and levesque s theory of intention @xcite .",
    "agent states are described through mental attitudes such as belief ( @xmath0 ) , knowledge ( @xmath1 ) , desire ( @xmath2 ) , and intention ( @xmath3 ) .",
    "these mental attitudes normally have propositions ( i.e. , symbolic representations of states of the world ) as arguments .",
    "figures  [ fig : lst ] and  [ fig : lsa ] give semantics for the kqml performatives @xmath4 ( @xmath5 tells @xmath6 that @xmath5 believes that @xmath7 is true ) , and @xmath8 ( @xmath5 asks @xmath6 if @xmath6 believes that @xmath7 is true ) , in the style introduced by labrou and finin @xcite .    as noted above , one of the key problems with this ( widely used ) approach to giving semantics to agent communication languages is that there is no way to determine whether or not any software component that uses such a communication language complies with the semantics .",
    "this is because the semantics makes reference to mental states , and we have in general no principled way to attribute such mental states to arbitrary pieces of software .",
    "this is true of the semantic approaches to both kqml and fipa , as discussed by both wooldridge @xcite and singh @xcite . as an example , consider a legacy software component wrapped in an agent that uses kqml or fipa to interoperate with other agents .",
    "one can not prove communication properties of such system , as there is no precise definition of when the legacy system believes that ( or intends to achieve a state of the world where ) some proposition is true .",
    "our approach builds on the work of bordini and moreira @xcite , which presented a precise definition of what it means for an agent to believe , desire , or intend a certain formula ; that approach is also adopted in our work on model - checking for @xcite . as a consequence , we are able to successfully and meaningfully apply speech act - style semantics to communication in .",
    "the drawback , of course , is that the approach is , formally , limited to agents , even though the same ideas can be used in work on semantics for other agent languages .",
    "the programming language was introduced by rao @xcite .",
    "it can be understood as a natural extension of logic programming for the bdi agent architecture , and provides an elegant abstract framework for programming bdi agents .",
    "the bdi architecture is , in turn , perhaps one of the major approaches to the implementation of rational practical reasoning agents @xcite .",
    "an  agent is created by the specification of a set of beliefs forming the initial _ belief base _ and a set of plans forming the _ plan library_. an agent s belief base is a set of ground first - order predicates , which will change over time to represent the current state of the environment as perceived by the agent .    distinguishes two types of goals : _ achievement goals _ and _ test goals_. achievement and test goals are predicates ( as with beliefs ) , prefixed with one of the operators `` ! ` ' and `` ? ` ' , respectively .",
    "achievement goals state that the agent wants to achieve a state of the world where the associated predicate is true ; in practice , as we will see , this is done by the execution of a plan .",
    "a test goal returns a unification for the associated predicate with one of the agent s beliefs ; it fails if no such unification is possible .",
    "a _ triggering event _ defines which events may initiate the execution of a plan .",
    "event _ can be internal ( when a subgoal needs to be achieved ) , or external ( when generated from belief updates as a result of perceiving the environment ) .",
    "additionally , with respect to the model of communication in this paper , external events can be related to messages received from other agents .",
    "there are two types of triggering events : those related to the _ addition _ ( `` + ` ' ) and _ deletion _ ( `` - ` ' ) of mental attitudes ( beliefs or goals ) .",
    "plans refer to the _ basic actions _ that an agent is able to perform on its environment . a plan is formed by a _ triggering event _ , denoting the events for which that plan is _ relevant_. the triggering event",
    "is followed by a conjunction of belief literals representing a _ context _ for the plan .",
    "the context must be a logical consequence of the agent s current beliefs for the plan to be _ applicable _  one of the plans that are both relevant and applicable is chosen for execution so as to handle a particular event .",
    "the remainder of the plan is a sequence of basic actions or that the agent has to achieve ( or test ) when the plan is executed .",
    "figure  [ figep ] shows some examples of  plans .",
    "the first plan tells us that , when a concert is announced for artist at venue ( so that , from perceiving the environment , a belief is _ added _ to the belief base ) , provided that the agent happens to like artist , it will have the new achievement goal of booking tickets for that concert .",
    "the second plan tells us that whenever this agent adopts the goal of booking tickets for s performance at , provided it is the case that the telephone is not busy , it can execute a plan consisting of retrieving from its belief base the telephone number of venue ( with the test goal ) , performing the basic action ( assuming that making a phone call is one of the actions that the agent is able to perform ) , followed by a certain protocol for booking tickets ( indicated by ` @xmath9 ' ) , which in this case ends with the execution of a plan for choosing the seats for such performance at that particular venue .",
    "next , we formally present the syntax and semantics of . note that we do not yet consider communication",
    "; we extend the semantics to deal with communication in section  [ secscaa ] .",
    "the syntax of an  agent program @xmath10 is defined by the grammar below . in",
    ", an agent program is simply given by a set @xmath11 of beliefs and a set @xmath12 of plans .",
    "the beliefs @xmath11 define the initial state of the agent s belief base ( i.e. , the state of the belief base when the agent starts running ) , and the plans @xmath12 form the agent s plan library .",
    "the atomic formul  @xmath13 of the language are predicates , where ` p ` is a predicate symbol and @xmath14 are standard terms of first order logic .",
    "belief _ is an atomic formula @xmath13 with no variables ; we use @xmath15 as a meta - variable for beliefs .",
    "@xmath16 }                                                         & ( n \\geq 0 , m > 0 ) \\\\ s        & \\percept   & \\self & \\multicolumn{3}{l}{\\id } \\\\ a        & \\multicolumn{4}{l}{\\texttt{a}(t_1,\\ldots , t_n ) } & ( n \\geq 0 ) \\\\ g        & !",
    "\\at & \\multicolumn{3}{l}{?\\at } \\\\",
    "u        & + b & \\multicolumn{3}{l}{-\\at } \\end{array}\\ ] ]    the grammar above gives an alternative definition for @xmath13 , extending the conventional syntactic form of predicates .",
    "the extension allows `` annotations '' to be associated with a predicate ; this is an extension of s original syntax motivated by our work on communication , which is discussed below in section  [ ssecse ] . for the time being , suffice it to say that the idea is to annotate each _ atomic formula _ with its _ source _ : either a term @xmath17 identifying which agent previously communicated that information , @xmath18 to denote beliefs created by the agent itself ( through belief update operations within a plan , as described below ) , or @xmath19 to indicate that the belief was acquired through perception of the environment .",
    "so , for example , if agent @xmath20 has a belief @xmath21 $ ] in its belief base , this would mean that agent @xmath22 had previously informed agent @xmath20 of @xmath23  in other words , that @xmath22 wanted @xmath20 to believe that there will be a concert by @xmath24 at @xmath25 .",
    "similarly , @xmath26 $ ] would mean that @xmath24 s concert at @xmath25 is believed not only because @xmath22 has informed agent @xmath20 of this , but because @xmath20 itself also perceived this fact ( e.g. , by seeing a poster when walking past the theatre ) .    a plan in is given by @xmath27 above , where @xmath28 is the _ triggering event _",
    ", @xmath29 is the plan s context , and @xmath30 is sequence of actions , goals , or belief updates ( which should be thought of as `` mental notes '' created by the agent itself ) .",
    "we refer to @xmath31 as the _ head _ of the plan , and @xmath30 is its _",
    "body_. the set of plans of an agent is given by @xmath12 .",
    "each plan has as part of its head a formula @xmath29 that specifies the conditions under which the plan can be chosen for execution .",
    "a triggering event @xmath28 can then be the addition or the deletion of a belief from an agent s belief base ( denoted @xmath32 and @xmath33 , respectively ) , or the addition or the deletion of a goal ( @xmath34 and @xmath35 , respectively , in our approach , are used in practice for handling plan failure .",
    "although we have left this construct in the grammar , we have omitted the discussion and formalisation of plan failure for clarity , as the focus in this paper is on the semantics of communication . ] ) . for plan bodies",
    ", we assume the agent has at its disposal a set of _ actions _ and we use @xmath24 as a meta - variable ranging over them .",
    "we are largely unconcerned here with respect to exactly what such actions are .",
    "actions are written using the same notation as predicates , except that an action symbol ` a ` is used instead of a predicate symbol .",
    "goals @xmath36 can be either _ achievement goals _ ( @xmath37 ) or _ test goals _ ( @xmath38 ) . finally , @xmath39 and @xmath33 ( in the body of a plan ) represent operations for updating ( @xmath40 ) the belief base by , respectively , adding or removing beliefs ; recall that an atomic formula must be ground if it is to be added to the belief base .",
    "we define the semantics of using operational semantics , a widely used method for giving semantics to programming languages @xcite .",
    "the operational semantics is given by a set of rules that define a transition relation between configurations where :    * an agent program @xmath41 is , as defined above , a set of beliefs @xmath11 and a set of plans @xmath12 . *",
    "an agent s circumstance @xmath42 is a tuple @xmath43 where : * * @xmath44 is a set of _ intentions _ @xmath45 .",
    "each intention @xmath20 is a stack of partially instantiated plans . *",
    "* @xmath46 is a set of _ events _ @xmath47 .",
    "each event is a pair @xmath48 , where @xmath28 is a triggering event and @xmath20 is an intention  a stack of plans in case of an internal event , or the empty intention @xmath49 in case of an external event .",
    "when the belief revision function ( which is not part of the interpreter but rather of the agent s overall architecture ) , updates the belief base , the associated events  i.e. , additions and deletions of beliefs  are included in this set .",
    "these are called _ external _ events ; internal events are generated by additions or deletions of goals from plans currently executing . * * @xmath50 is a set of _ actions _ to be performed in the environment .",
    "* @xmath51 is a tuple @xmath52 whose components characterise the following aspects of communicating agents ( note that communication is asynchronous ) : * * @xmath53 is the mail inbox : the system includes all messages addressed to this agent in this set .",
    "elements of this set have the form @xmath54 , where @xmath55 is a message identifier , @xmath17 identifies the sender of the message , @xmath56 is the illocutionary force of the message , and @xmath57 its content : a ( possibly singleton ) set of agentspeak predicates or plans , depending on the illocutionary force of the message . * * @xmath58 is where the agent posts messages it wishes to send ; it is assumed that some underlying communication infrastructure handles the delivery of such messages .",
    "( we are not concerned with this infrastructure here . )",
    "messages in this set have exactly the same format as above , except that here @xmath17 refers to the agent to which the message is to be sent . * * @xmath59 is used to keep track of intentions that were suspended due to the processing of communication messages ; this is explained in more detail in the next section , but the intuition is as follows : intentions associated with illocutionary forces that require a reply from the interlocutor are suspended , and they are only resumed when such reply has been received . *",
    "it is useful to have a structure which keeps track of temporary information that may be subsequently required within a reasoning cycle .",
    "@xmath60 is a tuple @xmath61 with such temporary information ; these components are as follows : * * @xmath6 is the set of _ relevant plans _ ( for the event being handled ) . * * @xmath62 is the set of _ applicable plans _ ( the relevant plans whose contexts are true ) . * * @xmath63 , @xmath64 , and @xmath65 record a particular intention , event , and applicable plan ( respectively ) being considered along the execution of one reasoning cycle . * the current step within an agent s reasoning cycle",
    "is symbolically annotated by @xmath66 .",
    "these labels stand for , respectively : processing a message from the agent s mail inbox , selecting an event from the set of events , retrieving all relevant plans , checking which of those are applicable , selecting one particular applicable plan ( the intended means ) , adding the new intended means to the set of intentions , selecting an intention , executing the selected intention , and clearing an intention or intended means that may have finished in the previous step .    in the interests of readability , we adopt the following notational conventions in our semantic rules :    *",
    "if @xmath42 is an agentspeak agent circumstance , we write @xmath67 to make reference to the @xmath46 component of @xmath42 , and similarly for other components of a configuration . * we write @xmath68 ( the underscore symbol ) to indicate that there is no intention presently being considered in that reasoning cycle .",
    "similarly for @xmath69 and @xmath70 .",
    "* we write @xmath71 $ ] to denote the intention that has plan @xmath27 on top of intention @xmath20 .",
    "the  interpreter makes use of three _ selection functions _ that are defined by the agent programmer .",
    "the selection function @xmath72 selects an event from the set of events @xmath73 ; the selection function @xmath74 selects one applicable plan given a set of applicable plans ; and @xmath75 selects an intention from the set of intentions @xmath76 ( the chosen intention is then executed ) .",
    "formally , all the selection functions an agent uses are also part of its configuration ( as is the social acceptance function that we mention later when we formalise agent communication ) . however ,",
    "as they are defined by the agent programmer at design time and do not ( in principle ) change at run time , we avoid including them in the configuration for the sake of readability .",
    "we define some functions which help simplify the semantics . if @xmath27 is a plan of the form @xmath77 , we define @xmath78 and @xmath79 .",
    "that is , these projection functions return the triggering event and the context of the plan , respectively .",
    "the @xmath80 function can also be applied to the head of a plan rather than the whole plan , but works similarly in that case .",
    "next , we need to define the specific ( limited ) notion of logical consequence used here .",
    "we assume a procedure that computes the most general unifier of two literals ( as usual in logic programming ) , and with this , define the logical consequence relation @xmath81 that is used in the definitions of the functions for checking for relevant and applicable plans , as well as executing test goals .",
    "given that we have extended the syntax of atomic formul  so as to include annotations of the sources for the information symbolically represented by it , we also need to define @xmath81 in our particular context , as follows .",
    "[ def : lc ] we say that an atomic formula @xmath82 with annotations @xmath83 is a logical consequence of a set of ground atomic formul  @xmath11 , written @xmath84 $ ] if , and only if , there exists @xmath85 \\in \\bels$ ] such that ( i ) @xmath86 , for some most general unifier @xmath87 , and ( ii ) @xmath88 .",
    "the intuition is that , not only should predicate @xmath13 unify with some belief in @xmath11 ( i ) , but also that all specified sources of information for @xmath13 should be corroborated in @xmath11 ( ii ) .",
    "thus , for example , @xmath89}$ ] follows from @xmath90}\\}$ ] , but @xmath91}$ ] does _ not _ follow from @xmath92}\\}$ ] . more concretely ,",
    "if , in order to be applicable , a plan requires that a drowning person was explicitly perceived rather than communicated by another agent ( which can be represented by @xmath93}$ ] ) , this follows from a belief @xmath94}$ ] ( i.e. , that this was both perceived and communicated by a passerby ) . on the other hand ,",
    "if the required context was that two independent sources provided the information , say @xmath95}$ ] , this can not be inferred from a belief @xmath96}$ ] .    in order to make some semantic rules more readable , we use two operations on a belief base ( i.e. , a set of annotated ground atomic formul )",
    ". we use @xmath97 to say that @xmath98 is as @xmath11 except that @xmath99 .",
    "similarly @xmath100 means that @xmath98 is as @xmath11 except that @xmath101 .",
    "a plan is considered _ relevant _ in relation to a triggering event if it has been written to deal with that event . in practice , this is checked by trying to unify the triggering event part of the plan with the triggering event within the event that has been selected for treatment in that reasoning cycle . in the definition below , we use the logical consequence relation defined above to check if a plan s triggering event unifies with the event that has occurred . to do this , we need to extend the @xmath81 relation so that it also applies to triggering events instead of predicates .",
    "in fact , for the purposes here , we can consider that any operators in a triggering event ( such as ` @xmath102 ' or ` @xmath103 ' ) are part of the predicate symbol or , more precisely , let @xmath82 be the predicate ( with annotation ) within triggering event @xmath104 and @xmath105 the one within @xmath106 , then @xmath107 if , and only if , @xmath108 and , of course , the operators prefixing @xmath104 and @xmath106 are exactly the same . because of the requirement of inclusion of annotations , the converse might not be true .",
    "[ def : rel ] given plans @xmath12 of an agent and a triggering event @xmath28 , the set @xmath109 of relevant plans for @xmath28 is defined as follows : @xmath110    the intuition regarding annotations is as follows .",
    "the programmer should include in the annotations of a plan s triggering event all the sources that must have generated the event for that plan to be relevant ( or include no annotation if the source of information is not important for the plan to be considered relevant ) . for the plan to be relevant , it therefore suffices for the annotations in the plan s triggering event to be a subset of those in the event that occurred . a plan with triggering event @xmath111}$ ] is relevant for an event @xmath112},\\tr\\rangle$ ] since @xmath113 requires that @xmath114}\\ } \\models \\mathtt{p(x)[s]}\\theta$ ] ( for some most general unifier @xmath87 ) , which in turn requires that @xmath115 . as a consequence , for a plan with a triggering event that has no annotations ( e.g. , @xmath116 ) to be relevant for a particular event ( say , @xmath117},i\\rangle$ ] ) it only requires that the predicates unify in the usual sense since @xmath118 , for any set @xmath5 .",
    "a plan is _ applicable _ if it is relevant and its context is a logical consequence of the agent s beliefs .",
    "again we need to extend slightly the definition of @xmath81 given above .",
    "a plan s context is a conjunction of literals ( @xmath119 is either @xmath13 or @xmath120 ) .",
    "we can say that @xmath121 if , and only if , @xmath122 if @xmath123 is of the form @xmath13 , and @xmath124 of @xmath123 is of the form @xmath120 , for @xmath125 .",
    "the function for determining the applicable plans in a set of relevant plans is formalised as follows .",
    "[ def : applic ] given a set of relevant plans @xmath6 and the beliefs @xmath11 of an agent , the set of applicable plans @xmath126 is defined as follows : @xmath127    we need another function to be used in the semantic rule for when the agent is to execute a test goal .",
    "the evaluation of a test goal @xmath38 consists in testing if the formula @xmath13 is a logical consequence of the agent s beliefs .",
    "the function returns a set of most general unifiers all of which make the formula @xmath13 a logical consequence of a set of formul  @xmath11 , as follows .",
    "[ def : test ] given a set of formul  @xmath11 and a formula @xmath13 , the set of substitutions @xmath128 produced by testing @xmath13 against @xmath11 is defined as follows :    @xmath129    next , we present the reasoning cycle of agents and the rules which define the operational semantics .",
    "figure  [ fig : cycle ] shows the possible transitions between the various steps in an agent s reasoning cycle as determined by an interpreter .",
    "the labels in the nodes identify each step of the cycle , which are : processing received messages ( @xmath130 ) ; selecting an event from the set of events ( @xmath131 ) ; retrieving all relevant plans ( @xmath132 ) ; checking which of those are applicable ( @xmath133 ) ; selecting one particular applicable plan ( the intended means ) ( @xmath134 ) ; adding the new intended means to the set of intentions ( @xmath135 ) ; selecting an intention ( @xmath136 ) ; executing the selected intention ( @xmath137 ) , and clearing an intention or intended means that may have finished in the previous step ( @xmath138 ) .    in the general case , an agent s initial configuration is , where @xmath41 is as given by the agent program , and all components of @xmath42 , @xmath51 , and @xmath60 are empty .",
    "note that a reasoning cycle starts with processing received messages ( @xmath130 )  the semantics for this part of the reasoning cycle are given in the main section of this paper .",
    "after that , the original reasoning cycle takes place .",
    "an event selection ( @xmath131 ) is made , which is followed by determining relevant and applicable plans ( @xmath132 and @xmath133 , respectively ) .",
    "one of the relevant plans is then selected ( @xmath134 ) ; note that when there are no events to be treated or when there are no applicable plans to deal with an event the agent turns its attention to the selection of an intended means ( @xmath136 ) to be executed next .",
    "after one of the relevant plans is selected ( @xmath134 ) and an instance of that plan becomes an `` intended means '' and is therefore included in the set of intentions ( @xmath135 ) .",
    "when there are more than one intention ( which is normally the case except for extremely simple agents ) , one of those intentions is selected ( @xmath136 ) and executed ( @xmath137 ) .",
    "these are the most important transitions ; the others will be made clearer when the semantics is presented . the rules which define the transition systems giving operational semantics to ( without communication ) are presented next .      in this section , we present an operational semantics for that formalises the transitions between possible steps of the interpretation of agents as shown in figure  [ fig : cycle ] . in the general case ,",
    "an agent s initial configuration is , where @xmath41 is as given by the agent program , and all components of @xmath42 , @xmath51 , and @xmath60 are empty .",
    "note that a reasoning cycle starts with processing received messages ( @xmath130 ) , according to the most recent extension of the semantics to be presented in section  [ secscaa ] .",
    "an event selection ( @xmath131 ) is then made , starting the reasoning cycle as originally defined for the language , which is the part of the semantics presented below .",
    "event selection : the rule below assumes the existence of a selection function @xmath72 that selects events from a set of events @xmath46 . the selected event is removed from @xmath46 and it is assigned to the @xmath64 component of the temporary information .",
    "rule skips to the intention execution part of the cycle , in case there are no events to handle .",
    "+    llcl & & = & \\ { , i } + & & = & , i    relevant plans : rule assigns the set of relevant plans to component @xmath139 .",
    "rule deals with the possibility that there are no relevant plans for an event , in which case the event is simply discarded .",
    "in fact , an intention associated with the event might also be discarded : if there are no relevant plans to handle an event generated by that intention , it can not be further executed . in practice , instead of simply discarding the event ( and possibly an intention with it ) , this leads to the activation of the plan failure mechanism , which we do not discuss here for clarity of presentation , as discussed earlier .",
    "+    llcl & & = & ( , )     +    an alternative approach for situations where there are no relevant plans for an event was introduced by @xcite @xcite .",
    "it assumes that in some cases , explicitly specified by the programmer , the agent will want to ask other agents what are the recipes they use for handling such events .",
    "the mechanism for plan exchange between agentspeak agents they proposed allows the programmer to specify which triggering events should generate attempts to retrieve external plans , which plans an agent agrees to share with others , what to do once the plan has been used for handling that particular event instance , and so forth .",
    "applicable plans : the rule assigns the set of applicable plans to the @xmath140 component ; rule applies when there are no applicable plans for an event , in which case the event is simply discarded .",
    "again , in practice , this normally leads to the plan failure mechanism being activated , rather than simply discarding the event ( and the whole intention with it ) .",
    "+    llcl & & = & ( , )     +    selection of an applicable plan : this rule assumes the existence of a selection function @xmath74 that selects one plan from a set of applicable plans @xmath140 .",
    "the selected plan is then assigned to the @xmath141 component of the configuration .",
    "+    llcl & & = & ( p , )    adding an intended means to the set of intentions : events can be classified as external or internal ( depending on whether they were generated from the agent s perception , or whether they were generated by the previous execution of other plans , respectively ) .",
    "rule determines that , if the event @xmath64 is external ( which is indicated by @xmath49 in the intention associated to @xmath64 ) , a new intention is created and the only intended means in that new intention is the plan @xmath27 assigned to the @xmath65 component .",
    "if the event is internal , rule determines that the plan in @xmath65 should be put on top of the intention associated with the event .",
    "+    llcl & & = & \\ {  [ p ]  }     +    llcl & & = & \\ {  i[(p ) ]  } +    note that , in rule , the whole intention @xmath20 that generated the internal event needs to be inserted back in @xmath76 , with @xmath27 pushed onto the top of that intention .",
    "this is related to resuming _ suspended intentions _ ; the suspending of intentions appears in rule below .",
    "intention selection : rule assumes the existence of a function @xmath75 that selects an intention for processing next , while rule takes care of the situation where the set of intentions is empty ( in which case the reasoning cycle simply starts again ) .",
    "+    llcl & & = & i    executing an intention : the group of rules below express the effects of executing a formula in the body of the plan .",
    "each rule deals with one type of formula that can appear in a plan body .",
    "recall from section  [ ssecse ] that an intention is a stack of ( partially instantiated ) plan instances ; a plan instance is a copy of a plan from the agent s plan library ) .",
    "the plan instance to be executed is always the one at the top of the intention that was selected in the previous step ( rule ) ; the specific formula to be executed is the one at the beginning of the body of that plan .    _",
    "actions : _ when the formula to be executed is an action , the action @xmath24 in the body of the plan is added to the set of actions @xmath50 ( which , recall , denotes that the action is to be executed using the agent s effectors ) .",
    "the action is removed from the body of the plan and the intention is updated to reflect this removal .",
    "+    llcl & & = & \\{a } + & & = & ( \\ { } ) \\ { i[h ] }    _ achievement goals : _ this rule registers a new internal event in the set of events @xmath46 .",
    "this event can then be selected for handling in a future reasoning cycle ( see rule ) .",
    "when the formula being executed is a goal , the formula is not removed from the body of the plan , as in the other cases .",
    "this only happens when the plan used for achieving that goal finishes successfully ; see rule  .",
    "the reasons for this are related to further instantiation of the plan variables as well as handling plan failure .",
    "+    llcl & & = & \\ { + ! , } + & & = & \\ { }    note how the intention that generated the internal event is removed from the set of intentions @xmath76 , capturing the idea of _ suspended intentions_. in a plan body , if we have ` @xmath142 ' ( where @xmath143 is any formula that can appear in plan bodies ) , this means that , before @xmath143 can be executed , the state of affairs represented by goal @xmath36 needs to be achieved ( through the execution of some relevant , applicable plan ) .",
    "the goal included in the new event created by rule above is treated as any other event , which means it will go the set of events until it is eventually selected in a later reasoning cycle , according to the agent s specific priorities for selecting events ( rule ) .",
    "meanwhile , that plan ( with formula @xmath143 to be executed next ) can no longer be executed , hence the whole intention is suspended by being placed , within the newly created event , in the set of events and removed from the set of intentions . when the event created by the rule above is selected and an applicable plan for achieving @xmath36 has been chosen , that intended means is pushed on top of the suspended intention , which can then be _ resumed _ ( i.e. , moved back to the set of intentions ) , according to rule . the next time that intention",
    "is selected , its execution will then proceed with a plan for achieving @xmath36 at the top , and only when that plan is finished will @xmath143 be executed ( as that plan , now without the achieved goal , will be at the top of the intention again ) ; further details on suspended intentions can be found in the literature .",
    "_ test goals : _ these rules are used when a test goal formula @xmath38 is to be executed .",
    "rule is used when there is a set of substitutions that can make @xmath13 a logical consequence of the agent s beliefs , which means that the test goal succeeded .",
    "if the test goal succeeds , the substitution is applied to the whole intended means , and the reasoning cycle can be continued . if that is not the case , it might turn out that the test goal is used as a triggering event of a plan , which is used by programmers to formulate more sophisticated queries .",
    "rule is used in such case : it generates an internal event , which may trigger the execution of a plan , as for achievement goals .",
    "if to carry out a plan an agent is required to obtain information ( at the time of actual execution of the plan ) which is not directly available in its belief base , a plan for a test goal can be written which , for example , sends messages to other agents , or processes available data , so that the particular test goal can be concluded ( producing an appropriate instantiation of logical variables ) . if an internal event is generated for the test goal being executed , the process is very similar to achievement goals , where the intention is suspended until a plan is selected to achieve the goal , as explained above .",
    "+    llcl & & = & ( \\ { } ) \\{i[(h ) ] } + & & & ( , )     +    llcl & & = & \\ { + ? , } + & & = & \\ { } +    _ updating beliefs : _ in the rules below , the set of beliefs of the agent is modified in a way that either an atomic formula ( with annotation @xmath18 ) is included in the new set of beliefs ( rule ) or it is removed from there ( rule ) .",
    "both rules add a new event to the set of events @xmath46 , and update the intention by removing from it the @xmath39 or @xmath33 formula just executed .",
    "note that belief deletions can have variables ( @xmath13 ) , whilst only ground atoms ( @xmath15 ) can be added to the belief base .",
    "+    llcl &  _ & = & _ + b [ ] + & & = & \\ { + b [ ] , } + & & = & ( \\ { } ) \\{i[h ] }     +    llcl &  _ & = & _ - + & & = & \\ { - , } + & & = & ( \\ { } ) \\{i[h ] }    clearing intentions : finally , the following rules remove empty intended means or intentions from the set of intentions .",
    "rule simply removes a whole intention when there is nothing else to be executed in that intention .",
    "rule clears the remainder of the plan with an empty body currently at the top of a ( non empty ) intention . in this case , it is necessary to further instantiate the plan below the finished plan ( currently at the top of that intention ) , and remove the goal that was left at the beginning of the body of the plan below ( see rules and ) .",
    "note that , in this case , further `` clearing '' might be necessary , hence the next step is still .",
    "rule takes care of the situation where no ( further ) clearing is required , so a new reasoning cycle can start ( at step ) .",
    "+    llcl & & = & \\{j }     +    llcl & & = & ( \\ { j } ) \\{k[( h ) ] } +",
    "the rules in the previous section give semantics to the key internal decision making and control aspects of agentspeak .",
    "furthermore , the overall agent architecture will have sensors ( with an associated belief revision function ) and effectors , in addition to an agentspeak interpreter .",
    "the relation of these components to the agentspeak interpreter is not essential for giving a semantics to the language itself .",
    "it suffices to note that belief revision from perception of the environment adds ( external ) events to the set @xmath73 ( which is then used in the agentspeak interpretation cycle ) , while the effectors simply execute every action that is included by the reasoner in the set @xmath144 .",
    "similarly , the mechanism that allows messages to be exchanged is part of the overall agent architecture  it is not part of its practical reasoning component , which is specifically what we program with .",
    "the notion of internal actions in @xcite is appropriate here : sending a message corresponds to executing the ( predefined ) internal action @xmath145 that appears in a plan body .",
    "the underlying agent architecture ensures that the necessary technical means is used for the message to reach the agent to which the message is addressed .",
    "however , as we will be referring to a special type of communication action that involves suspending intentions , we now need to include such details in the semantics .",
    "the format of messages is @xmath146 , where @xmath55 uniquely identifies the message , @xmath17 identifies the agent to which the message is addressed ( when the message is being sent ) or the agent that has sent the message ( when the message is being received ) , @xmath56 is the illocutionary force ( i.e. , the performative ) associated with the message , and @xmath57 is the message content .",
    "depending on the illocutionary force of the message , its content can be : an atomic formula ( @xmath13 ) ; a set of formul  ( @xmath147 ) ; a ground atomic formula ( @xmath15 ) ; a set of ground atomic formul  ( @xmath148 ) ; or a set of plans ( @xmath149 ) .    a mechanism for receiving and sending messages asynchronously",
    "is then defined .",
    "messages are stored in a mail box and one of them is processed by the agent at the beginning of a reasoning cycle .",
    "recall that , in a configuration of the transition system , @xmath150 is the set of messages that the agent has received but has not processed yet , @xmath151 is the set of messages to be sent to other agents , and @xmath152 is a set of suspended intentions awaiting replies for ( information request ) messages previously sent .",
    "more specifically , @xmath152 is a set of pairs of the form @xmath153 , where @xmath55 is a message identifier that uniquely identifies the previously sent message that caused intention @xmath20 to be suspended .    when sending messages with illocutionary forces related to information requests , we have chosen a semantics in which the intention is suspended until a reply is received from the interlocutor , very much in the way that intentions get suspended when they are waiting for an internal event to be handled . with this particular semantics for `` ask '' messages",
    ", the programmer knows with certainty that any subsequent action in the body of a plan is only executed after the requested information has already been received .",
    "however , note that the information received as a reply is stored directly in the agent s belief base , so a test goal is required if the information is to be used in the remainder of the plan .",
    "we now give two rules for executing the ( internal ) action of sending a message to another agent : the first is for the `` ask '' messages which require suspending intentions and the second is for other types of messages .",
    "these rules have priority over ; although could also be applied on the same configurations , we assume the rules below are used if the formula to be executed is specifically a @xmath145 action .",
    "( we did not include this as a proviso in rule to improve readability . )",
    "+    llcl & & = & \\ { } + & & = & \\ { ( , i[h ] ) } , + & & & + & & = & ( \\ { } )    the semantics of sending other types of illocutionary forces is then simply to add a well - formed message to the agent s mail outbox ( rule ) .",
    "note that in the rule above , as the intention is suspended , the next step in the reasoning cycle is ( i.e. , a new cycle is started ) , whereas in the rule below it is , as the updated intention  with the sending action removed from the plan body  might require `` clearing '' , as with any of the intention execution rules seen in the previous section .",
    "+    llcl & & = & \\ { } , + & & & + & & = & ( \\ { } ) \\ { i[h ] }    whenever new messages are sent , we assume the system creates unique _ message identifiers _ ( ) . later , we shall see that , when replying to a message , the same message identifier is kept in the message , similar to the way that ` reply - with ` is used in kqml .",
    "thus , the receiving agent is aware that a particular message is a reply to a previous one by checking the message identifiers in the set of intentions that were suspended waiting for a reply .",
    "this feature will be used when we give semantics to receiving @xmath154 messages , which can be sent by an agent when it spontaneously wants the receiver to believe something ( or at least to believe something about the sender s beliefs ) , but can also be used when the agent receives an `` ask '' type of message and chooses to reply to it .    as mentioned earlier ,",
    "it is not our aim to formalise every aspect of a system of multiple agentspeak agents .",
    "we extend the previous semantics only to the extent required to formalise speech - act based communication for such agents .",
    "it is relevant , therefore , to consider a rule that defines message exchange as accomplished by the underlying message exchange mechanism available in an overall agent architecture .",
    "this is abstracted away in the semantics by means of the following rule , where each @xmath155 , @xmath156 , is an agent configuration @xmath157 :    \\ { ,  , ,  , } + \\ { ,  , ,  , }",
    "+    llcl & m__i_out & = & m__i_out \\ { } + & m__j_in & = & m__j_in \\ { }    in the rule above , there are @xmath158 agents , and @xmath159 denotes the environment in which the agents are situated ; typically , this is not an agentspeak agent , it is simply represented as a set of properties currently true in the environment and how they are changed by an agent s actions .",
    "note how , in a message that is to be sent , the second component identifies the addressee ( the agent to which the message is being sent ) , whereas in a received message that same component identifies the sender of the message .      in this section",
    "we discuss the performatives that are most relevant for communication in .",
    "these are largely inspired by corresponding kqml performatives .",
    "we also consider some new performatives , related to plan exchange rather than communication about propositions as usual .",
    "the performatives that we consider are briefly described below , where @xmath160 denotes the agent that sends the message , and @xmath161 denotes the agent that receives the message .",
    "note that ` tell ` and ` untell ` can be used either for an agent to pro - actively send information to another agent , or as replies to previous ` ask ` messages .    `",
    "tell ` : : :    @xmath160 intends @xmath161 to believe ( that    @xmath160 believes ) the sentence in the message s content to be    true ; ` untell ` : : :    @xmath160 intends @xmath161 not to believe ( that    @xmath160 believes ) the sentence in the message s content to be    true ; ` achieve ` : : :    @xmath160 requests that @xmath161 to intend to achieve a    state of the world where the message content is true ; ` unachieve ` : : :    @xmath160 requests @xmath161 to drop the intention of    achieving a state of the world where the message content is true ; ` tell - how ` : : :    @xmath160 informs @xmath161 of a plan ( i.e. , some know - how    of @xmath160 ) ; ` untell - how ` : : :    @xmath160 requests @xmath161 to disregard a certain plan    ( i.e. , to delete that plan from its plan library ) ; ` ask - if ` : : :    @xmath160 wants to know if the content of the message is true    for @xmath161 ; ` ask - all ` : : :    @xmath160 wants all of @xmath161 s answers to a question    ( i.e. , all the beliefs that unify with the message content ) ; ` ask - how ` : : :    @xmath160 wants all of @xmath161 s plans for a particular    triggering event ( in the message content ) .    for processing messages ,",
    "a new selection function is necessary , which operates in much the same way as the other selection functions described in the previous section .",
    "the new selection function is called @xmath162 , and selects a message from @xmath150 ; intuitively , it represents the priority assigned to each type of message by the programmer .",
    "we also need another `` given '' function , but its purpose is different from selection functions .",
    "the boolean function @xmath163 , where @xmath56 is the illocutionary force of the message from agent @xmath17 , with propositional content @xmath13 , determines when a message is _ socially acceptable _ in a given context . for example , for a message of the form @xmath164 , the receiving agent may want to consider whether @xmath17 is a relevant source of information , as even remembering that @xmath17 believes @xmath13 might not be appropriate .",
    "for a message with illocutionary force @xmath165 , an agent would normally check , for example , whether @xmath17 has sufficient social power over itself , or whether it wishes to act altruistically towards @xmath17 , before actually committing to do whatever it is being asked .",
    "we should mention that the role of @xmath166 in our framework is analogous , on the receiver s side , to that of the `` cause to want '' and `` cause to believe '' predicates in cohen and perrault s plan - based theory of speech acts @xcite .",
    "that is , it provides a bridge from the illocutionary force of a message to its perlocutionary force .",
    "the idea of having user - defined functions determining relations such as `` trust '' and `` power '' has already been used in practice by @xcite @xcite .",
    "similar interpretations for the use of @xmath167 when applied to other types of messages ( e.g. , ) can easily be derived .",
    "there is considerable work on elaborate conceptions of trust in the context of multi - agent systems , for example in the work of @xcite @xcite . in our framework ,",
    "more sophisticated notions of trust and power can be implemented by considering the annotation of the sources of information during the agent s practical reasoning rather than the simple use of @xmath167 .",
    "the annotation construct facilitates determining , in a plan context , the source of a belief before that plan becomes an intended means .",
    "before we start the presentation of the semantic rules for communication , it is worth noting that , in this paper in particular , we do not consider _ nested _ annotations .",
    "nested annotations allow the representation of beliefs about other agents beliefs , or more generally situations in which an agent @xmath20 was told @xmath168 by @xmath22 , which in turn was told @xmath168 by @xmath169 , and so forth .      receiving a tell message : a @xmath154 message",
    "might be sent to an agent either as a reply or as an `` inform '' action . when receiving a @xmath154 message as an inform ( as opposed to a reply to a previous request ) , the agent will include the content of the received message in its knowledge base and will annotate the sender as a source for that belief .",
    "note that this corresponds , in a way , to what is specified as the `` action completion '' condition by labrou and finin @xcite : the receiver will know about the sender s attitude regarding that belief . to account for the social aspects of multi - agent systems , we consider that social relations will regulate which messages the receiver will process or discard ; this is referred to in the semantics by the  function , which is assumed to be given by the agent designer .",
    "the rule shows that the annotated belief is added to the belief base , and the appropriate event is generated .",
    "+    llcl & & = & \\ { } + & + &  _ & = & _ + b [ ] + & & = & \\ { + b [ ] , }    receiving a tell message as a reply : this rule is similar to the one above , except that now the suspended intention associated with that particular message  given that it is a reply to a previous `` ask '' message sent by this agent  needs to be resumed .",
    "recall that to resume an intention we just need to place it back in the set of intentions ( @xmath170 ) .",
    "+    llcl & & = & \\ { } + & & = & \\ { ( , i ) } + & & = & \\ { i } + & + &  _ & = & _ + b [ ] + & & = & \\ { + b [ ] , }    receiving an untell message : when receiving an @xmath171 message , the sender of the message is removed from the set of sources giving accreditation to the atomic formula in the content of the message . in case",
    "the sender was the only source for that information , the belief itself is removed from the receiver s belief base .",
    "note that , as the atomic formula in the content of an @xmath171 message can have uninstantiated variables , each belief in the agent s belief base that can be unified with that formula needs to be considered in turn , and the appropriate events generated .",
    "+    llcll & & = & \\ { } + & + & + &  _ & = & _ - b [ ] + & & = & \\ { -b [ ] , }    receiving an untell message as a reply : as above , the sender as source for the belief , or the belief itself , is excluded from the belief base of the receiver , except that now a suspended intention needs to be resumed ( similarly to a @xmath154 as a reply ) .",
    "+    llcll & & = & \\ { } + & & = & \\ { ( , i ) } + & & = & \\ { i } + & + & + &  _ & = & _ -b [ ] + & & = & \\ { -b [ ] , }    receiving an achieve message : in an appropriate social context ( e.g. , if the sender has `` power '' over the receiver ) , the receiver will try to execute a plan whose triggering event is @xmath172 ; that is , it will try to achieve the goal associated with the propositional content of the message .",
    "an external event is thus included in the set of events ( recall that external events have the triggering event associated with the empty intention @xmath49 ) .",
    "note that it is now possible to have a new focus of attention ( a stack of plans in the set of intentions @xmath44 ) being initiated by the addition ( or deletion , see below ) of an achievement goal .",
    "originally , only a belief change arising from perception of the environment initiated a new focus of attention ; the plan chosen for that event could , in turn , have achievement goals in its body , thus pushing new plans onto the stack .",
    "+    llcl & & = & \\ { } + & & = & \\ { + ! , }    we shall later discuss in more detail the issue of autonomy . while this gives the impression that simply accepting orders removes the agent s autonomy ( and similarly with regards to acquired beliefs ) ,",
    "the way the agent will behave once aware that another agent is attempting to delegate a goal completely depends on the particular plans that happen to be in the agent s plan library .",
    "if a suitable plan exists , the agent could simply drop the goal , or could tell the interlocutor that the goal delegation was noted but the goal could not be adopted as expected , etc .    receiving an unachieve message : this rule is similar to the preceding one , except that now the deletion ( rather than addition ) of an achievement goal is included in the set of events .",
    "the assumption here is that , if the agent has a plan with such a triggering event , then that plan should handle all aspects of dropping an intention .",
    "however , doing so in practice may require the alteration of the set of intentions , thus requiring special mechanisms which have not been included in any formalisation of as yet , even though it is already available in practice , for example in the interpreter @xcite .",
    "+    llcl & & = & \\ { } + & & = & \\ { - ! , }    receiving a tell - how message : the notion of plan is related to singh s concept of _ know - how _ @xcite .",
    "accordingly , we use the @xmath173 performative when agents wish to exchange know - how rather than communicate beliefs or delegate goals . that is , a @xmath173 message is used by the sender ( an agent or external source more generally ) to inform an  agent of a plan that can be used for handling certain types of events ( as expressed in the plan s triggering event ) .",
    "if the source is trusted , the plans in the message content are simply added to the receiver s plan library .",
    "+    llcl & & = & \\ { } + &  _ & = & _    note that we do not include any annotation to identify the source of a plan , and so , with this semantics , it is not possible to take into account the identity of the agent that provided a plan when deciding whether to use it . in practice",
    ", this feature is implemented in the interpreter , as the language is extended with the use of annotated predicates as plan labels .",
    "this also allows programmers to annotate plans with information that can be used for meta - level reasoning ( e.g. , choosing which plan to use in case various applicable plans are available , or which intention to execute next ) ; examples of such information would be the expected payoff of a specific plan and its expected chance of success , thus allowing the use of decision - theoretic techniques in making those choices .",
    "receiving a tell - how message as a reply : the @xmath173 performative as a reply will also cause the suspended intention  the one associated with the respective @xmath174 message previously sent  to be resumed .",
    "+    llcl & & = & \\ { } + & & = & \\ { ( , i ) } + & & = & \\ { i } + &  _ & = & _ +    receiving an untell - how message : this is similar to the rule above , except that plans are now removed from the receiver s plan library .",
    "an external source may find that a plan is no longer appropriate for handling the events it was supposed to handle ; it may then want to inform another agent about that .",
    "thus , when receiving a socially acceptable @xmath175 message , the agent removes the associated plans ( i.e. , those in the message content ) from its plan library .",
    "+    llcl & & = & \\ { } + &  _ & = & _    receiving an ask - if message : the receiver will respond to this request for information if certain conditions imposed by the social settings ( the  function ) hold between sender and receiver .",
    "note that _ ask - if _ and _ ask - all _ differ in the kind of request made to the receiver . with the former , the receiver should just confirm whether the predicate in the message content is in its belief base or not ; with the latter , the agent replies with all the predicates in its belief base that unify with the formula in the message content . the receiver processing an @xmath176 message responds with the action of sending either a @xmath154 ( to reply positively ) or @xmath171 message ( to reply negatively ) ; the reply message has the same content as the @xmath176 message .",
    "note that a reply is only sent if the social context is such that the receiver wishes to consider the sender s request .",
    "+    lcl + & = & \\ { } + & = & \\ {    ll \\ { } & _ b + \\ { } & _ b +    .    the role that @xmath162 plays in the agent s reasoning cycle is slightly more important here than originally conceived @xcite .",
    "an agent considers whether to accept a message or not , but the reply message is automatically assembled when the agent selects ( and accepts ) any of the `` ask '' messages . however , providing such a reply may require considerable computational resources ( e.g. , the whole plan library may need to be scanned and a considerable number of plans retrieved from it in order to produce a reply message ) .",
    "therefore , @xmath162 should normally be defined so that the agent only selects an @xmath176 , @xmath177 , or @xmath174 message if it determines the agent is not currently too busy to provide a reply .",
    "receiving an askall : as for @xmath176 , the receiver processing an @xmath177 has to respond either with @xmath154 or @xmath171 , provided the social context is such that the receiver will choose to respond .",
    "as noted above , here the agent replies with all the predicates in the belief base that unify with the formula in the message content .",
    "+   @xmath178    receiving an askhow : the receiver of an @xmath174 has to respond with the action of sending a @xmath173 message , provided the social configuration is such that the receiver will consider the sender s request .",
    "in contrast to the use of @xmath171 in @xmath177 , the response when the receiver knows no relevant plan ( for the triggering event in the message content ) is a reply with an empty set of plans .",
    "+    lcl + & = & \\ { } + & = & \\ { } + & & = \\ { p ( p , ) ( , ) }    when @xmath167 fails : all the rules above consider that the social relations between sender and receiver are favourable for the particular communicative act ( i.e , they require @xmath167 to be true ) .",
    "if the required social relation does not hold , the message is simply discarded  it is removed from the set of messages and ignored .",
    "the rule below is used for receiving a message from an untrusted source , regardless of the performative .",
    "+    llcl & & = & \\ { }    when @xmath150 is empty : this last semantic rule states that , when the mail inbox is empty , the agent simply goes to the next step of the reasoning cycle ( ) .",
    "+      as in any other distributed system , multi - agent systems can ( and do ) fail in the real world . possibly even more so than typical distributed systems , given that multi - agent systems are normally used in dynamic , unpredictable environments .",
    "in such contexts , failures are expected to happen quite often , so agents need to recover from them in the best possible way . in the specific case of systems composed of agents , failures can occur when , for instance , the agent for which a message has been sent has left the multi - agent system , can not be contacted , or has ceased to exist ( e.g. , because of a machine or network crash ) .",
    "equally , an intention that was suspended waiting for a reply may never be resumed again due to a failure in the agent that was supposed to provide a reply .",
    "( however , note that agents typically have various concurrent foci of attention  i.e. , multiple intentions currently in the set of intentions  so even if one particular intention can never progress because another agent never replies , the agent will simply carry on working on the other foci of attention . )    in the context of agents , both fault detection and recovery start at the level of the infrastructure that supports the agent execution .",
    "this infrastructure can adopt techniques available in traditional distributed systems but with a fundamental difference : it is responsible for adding appropriate events signaling failures in the set @xmath73 of external events , or possibly resuming suspended intentions and immediately making them fail if for example a message reply has timed out . such events , when treated by the agent in its normal reasoning cycle , using the plan failure mechanism not formalised here but available in practical interpreters , will trigger a plan specifically written by the agent programmer which defines a strategy for failure recovery . therefore , from the point of view of the formal semantics for , failure recovery reduces to event handling and plan execution , and is partly the responsibility of the underlying execution infrastructure and partly the responsibility of programmers .",
    "we should note that various approaches for failure detection and recovery within multi - agent systems in particular appear in the literature .",
    "they typically involve the use of special agents or plans defined to deal with failure .",
    "a natural concern when we have a set of agents executing concurrently is that shared resources should always be left in a consistent state .",
    "this is , of course , a classical problem in concurrency , and is typically solved by atomically executing the parts of the code that access the shared resources .",
    "many programming language have constructs that enable a programmer to guarantee the atomic execution of critical sections . in a multi - agent system written in ,",
    "atomicity is not immediately an issue since there are no critical sections , given that different agents do not directly share memory .",
    "however , agents do exchange information in the form of messages , but the responsibility for the management of such exchanges lies with the underlying message passing infrastructure . on the other hand , agents in a multi - agent systems typically share an environment , and if a particular application requires environment resources to be shared by agents , clearly programmers need to ensure that suitable agent interaction protocols are used to avoid dead-/live - locks or starvation",
    ".    another possible source of concern regarding atomicity is the concurrent execution of an agent s intentions .",
    "agents can have several intentions ready to be executed and each one of them can read / write data that is shared with other intentions ( as they all access the same belief base ) .",
    "it is not in the scope of this paper to formalise mechanisms to control such concurrency , but it is worth mentioning that the interpreter provides programmers with the possibility of annotating plans as being `` atomic '' , so that when one of them is selected for execution ( see the semantic rule ) , it is guaranteed by the runtime agent platform that the plan execution will not be suspended / interrupted ( i.e. , that no other intention will be selected for execution in the following reasoning cycles ) before the whole plan finishes executing .",
    "next , we give an example intended to illustrate how the semantic rules are applied during a reasoning cycle .",
    "the example includes agents exchanging messages using the semantic framework for agent communication formalised earlier in this section .",
    "consider the following scenario .",
    "firefighting robots are in action trying to control a rapidly spreading fire in a building , under the supervision of a commander robot .",
    "another robot is piloting a helicopter to observe in which direction the fire is spreading most rapidly .",
    "let the robot in the helicopter be , let be the ground commander , and let be one of the firefighting robots .",
    "one of the plans in s plan library , which we shall refer to as , is as shown in figure  [ fig : ffrps ] .",
    "this plan says that as soon as perceives fire spreading in direction ` d ` , it tells ` r ` that fire is spreading towards ` d ` , where ` r ` is the agent it believes to be the ground commander .",
    "plan is one of the plans that robot ( the commander ) has in its plan library , which is also shown in figure  [ fig : ffrps ] .",
    "plan says that , when gets to believe ` ) , this plan can be used when such belief is acquired from communication as well as perception of the environment . ]",
    "that fire is spreading in direction ` d ` , it will request the robot believed to be closest to that part of the building to achieve a state of the world in which ` d ` is the fighting post of that robot ( in other words , that the robot should relocate to the part of the building in direction ` d ` ) .",
    "we now proceed to show how the rules of the operational semantics apply , by using one reasoning cycle of the agent that controls as an example ; the rules for communication will be exemplified afterwards . for simplicity ,",
    "we assume is currently defined by a configuration @xmath179 , with @xmath180 and the @xmath181 component having :    @xmath182 @xmath183    suppose has just perceived fire spreading towards the south . after the belief revision function ( see section  [ ssecse ] ) has operated , s beliefs will be updated to @xmath184 and the @xmath185 component of s configuration ( i.e. , its set of events ) will be as follows :    @xmath186    at this point , we can show the sequence of rules that will be applied to complete one reasoning cycle : see table  [ tab : seqrulesrc ] , where the left column shows the rule being applied and the right column shows _ only the components of the configuration which have changed _ as a consequence of that rule having been applied .",
    "note that the `` next step '' component @xmath187 changes in an obvious way ( given the rules being applied ) , so we only show its change for the very first step , when there are no messages to be processed and the cycle goes straight on to selecting an event to be handled in that reasoning cycle .",
    "@xmath188 \\ } \\\\ \\hline \\rname{selint$_{1}$ } & \\taiota = [ \\psa\\theta_a ] \\\\ \\hline ~\\rname{execactsnd }    & \\maout =         \\ { \\msg{\\mid_1,\\rb,\\tell,\\{\\atom{spreading(south)}}\\ } \\ } \\\\                         & \\cai =         \\ { [ \\atom{+spreading(south ) : commander(\\rb ) < - \\tr}]\\ } \\\\",
    "\\hline \\rname{clrint$_{1}$ } & \\cai = \\{\\}\\\\",
    "\\hline \\end{array}$ ]    after s reasoning cycle shown in the table , rule applies and , assuming @xmath189 is s configuration , which for simplicity we assume is the initial ( i.e. , empty ) configuration hence @xmath190 , we shall have that :    @xmath191    which then leads to rule being applied , thus starting a reasoning cycle ( similar to the one in table  [ tab : seqrulesrc ] ) in from a configuration that will have had the following components changed ( see rule  ):    @xmath192 @xmath193 } \\}\\ ] ] @xmath194},\\tr\\rangle \\}.\\ ] ]    after a reasoning cycle in , we would have for that :    @xmath195    where @xmath196 is s mail inbox ( and assuming @xmath196 was previously empty ) .",
    "note that s @xmath167 function used by rule ( leading to @xmath197 being included in @xmath196 as stated above ) would probably consider the hierarchy determined by the firefighters ranks .",
    "robot would then consider the events generated by this received message in its subsequent reasoning cycles , and would act in accordance to the plans in its plan library , which we do not show here , for simplicity .",
    "we sometimes require more elaborate communication structures than performatives such as those discussed in section  [ secscaa ] . on the other hand , it is of course important to keep any communication scheme and its semantic basis as simple as possible .",
    "we emphasise that , in our approach , more sophisticated communication structures can be programmed , on top of the basic communication features formalised here , through the use of plans that implement interaction protocols . in practical interpreters , such communication features ( built by composing of the atomic performatives ) can be provided to programmers either as extra pre - defined performatives or as plan templates in plan libraries made publicly available  in @xcite , the former approach has been used , but the latter is also possible . in this section ,",
    "we give , as examples of more advanced communication features , plans that allow agents to reach shared beliefs and ensure that agents are kept informed of the adoption of their goals by other agents .",
    "note however that the examples make use of a simple practical feature ( available , e.g. , in ) which does not appear in the abstract syntax we used earlier in the formal presentation : a variable instantiated with a first order term can be used , within certain constructs ( such as belief or goal additions ) , in place of an atomic formula , as usual also in prolog implementations .",
    "[ exsb ]    if a network infrastructure is reliable , it is easy to ensure that agents reach shared beliefs . by reaching a shared belief , we mean two agents believing @xmath15 as well as believing that the other agent also believes @xmath15 .",
    "more explicitly , we can say agents ` ag1 ` and `",
    "ag2 ` share belief @xmath15 if ` ag1 ` believes both @xmath198`self`@xmath199 $ ] and @xmath198`ag2`@xmath199 $ ] , at the same time that ` ag2 ` believes both @xmath198`self`@xmath199 $ ] and @xmath198`ag1`@xmath199 $ ] . in order to allow agents ` ag1 ` and ` ag2 ` to reach such shared beliefs , it suffices messages from agents who have such know - how ) , they can become capable of reaching shared beliefs too . ] to provide both agents with copies of the following plans :     + ` + !",
    "reachsharedbel(p , a )  :  not  p[self ] ` + `  < -  + p ; ` + `  !",
    "reachsharedbel(p , a ) . ` +   +   + ` + !",
    "reachsharedbel(p , a )  :  p[self ]  &  not  p[a ] ` + `  < -  .send(a , tell , p ) ; ` + `  .send(a , achieve , reachsharedbel(p,`@xmath200 ` ) ) . `",
    "+   +   + ` + !",
    "reachsharedbel(p , a )  :  p[self ]  &  p[a ] ` + `  < -  true . `    in the plans above , @xmath200 stands for the agent s own name .",
    "( recall that , as in prolog , an uppercase initial denotes a logical variable . )",
    "assume agent ` ag1 ` has the above plans and some other plan , an instance of which is currently in its set of intentions , which requires itself and ` ag2 ` to share belief ` p(x ) ` .",
    "such a plan would have the following goal in its body : ` !",
    "reachsharedbel(p(x),ag2 ) ` . this would eventually lead to the execution of the plans in the example above , which can now be explained .",
    "the plan labelled ` rsb1 ` says that if ` ag1 ` has a ( new ) goal of reaching a shared belief ` p ` with agent ` a ` , in case ` ag1 ` does not yet believe ` p ` itself , it should first make sure itself believes ` p `  note that `` + p ; ` ' in the body of that plan will add the ground predicate bound to ` p ` with source ` self ` as a new belief to agent ` ag1 `  then it should again have the goal of reaching such shared belief ( note that this is a recursive plan ) . this time ,",
    "plan ` rsb1 ` will no longer be applicable , so ` rsb2 ` will be chosen for execution .",
    "plan ` rsb2 ` says that , provided ` ag1 ` believes ` p ` but does not yet believe that agent ` a ` believes ` p ` , it should tell agent ` a ` that itself ( ` ag1 ` ) believes ` p ` , then finally ask ` a ` to also achieve such shared belief with ` ag1 ` .",
    "agent ` ag2 ` , which also has copies of the plans in the example above , would then , given the appropriate @xmath167 function , have an instance of plan ` rsb1 ` in its own set of intentions , and will eventually execute ` rsb2 ` as well , or directly ` rsb2 ` as the case may be .",
    "note that the last line of plan ` rsb2 ` , when executed by the agent that was asked to reach a shared believe , rather than the one who took the initiative , is redundant and will lead the other agent to using ` rsb3 ` , which only says that no further action is required , given that the shared belief has already been obtained . clearly , there are more efficient ways of implementing a protocol for reaching shared belief , but we present this because the same plans can be used regardless of whether the agent takes the initiative to reach a shared belief or not .",
    "the version we give here is therefore arguably more elegant , and its symmetry facilitates reasoning about the protocol .",
    "we now give another example , which shows how agents can have further information about requests for goal adoption ( i.e. , when they ask another agent to achieve some state of affairs on their behalf ) .",
    "[ exfga ]    it is often the case that , if one agent asks another agent to do something , it may want to have at least some reassurance from the other agent that it has agreed to do whatever it has been asked .",
    "furthermore , it may want to know when the other agent believes it has accomplished the task .",
    "the following plans can be used for ` ag1 ` to delegate tasks to ` ag2 ` in such a way .",
    "+   +   + ` + needdoneby(g , a )  :  not  delegatedto(g , a ) ` + `  < -  + delegatedto(g , a ) ; ` + `  .send(a , achieve , doandfeedbackto(g,`@xmath200 ` ) ) . `",
    "+   +   + ` + needdoneby(g , a ) ` + `  :  agreedtodo(g)[a ]  &  not  finisheddoing(g)[a ] ` + `",
    "< -  .send(a , tell , shouldhavefinished(g ) ) ; ` + `  ... ` +   +   + ` + needdoneby(g , a )  :  finisheddoing(g)[a ] ` + `  < -  ... ` +   + ` ... ` +   +   + ` + finisheddoing(g)[a ]  :  true ` + `  < -  -delegatedto(g , a ) ; ` + `  -agreedtodo(g)[a ] . `",
    "+   +   +   +   +   + ` + !",
    "doandfeedbackto(g , a )  :  ` @xmath201 + `  < -  .send(a , tell , agreedtodo(g ) ) ; ` + `  + !",
    "g ; ` + `  .send(a , tell , finisheddoing(g ) ) . `",
    "+   +   + ` + !",
    "doandfeedbackto(g , a )  :  ` @xmath202 + `  < -  .send(a , tell , cannotdo(g ) ) . `    in the example above , we assume that something perceived in the environment leads the agent to believe that it needs some goal ` g ` to be achieved by agent ` a ` , and that such perception recurs at certain intervals , when the need that motivated the request still exists and the result of ` a ` s achieving ` g ` has not been observed .",
    "plan ` nsd1 ` is used when such a need occurs but no request has been as yet sent to ` a ` .",
    "the plan ensures that ` ag1 ` will remember that it already asked ` a ` ( say , ` ag2 ` ) to do ` g ` and then that agent to achieve a goal associated with a special plan : see plan ` dft1 ` in ` ag2 ` .",
    "such plan makes sure that the requesting agent is informed both that ` ag2 ` has adopted the goal as requested ( before it attempts to achieve it ) as well as when the agent believes to have achieved ` g ` .",
    "the programmer should define the @xmath167 function so that ` ag2 ` accepts such requests from ` ag1 ` , but the programmer can still determine how autonomous ` ag2 ` will be by using appropriate plan contexts . in plan",
    "` dft1 ` , context @xmath201 would determine the circumstances under which agent ` ag2 ` believes it will be able to adopt the goal , and context @xmath202 , in plan ` dft2 ` , can be used for the circumstances in which ` ag2 ` should simply inform it will not adopt the goal as requested by ` ag1 ` ( a more elaborate plan could explain why the agent can not adopt the goal , for example in case there are more than one situation in which the goal can not be adopted ) .    going back to plans ` nsd2 ` and ` nsd3 ` in agent ` ag1 ` , the former is used to `` put pressure '' on the agent that has adopted ` ag1 ` s goal ` g ` , as the need for that has been perceived again and ` a ` has already agreed to do that , so presumably it is not doing it fast enough .",
    "clearly , the `` ` shouldhavefinished ` '' belief should trigger some plan in ` ag2 ` for it to have the desired effect .",
    "plan ` nsd3 ` is just a template for one of various alternative courses of actions to be taken by ` ag1 ` when the need that motivated a request for ` ag2 ` to adopt a goal still exists but ` ag2 ` believes the goal has already been achieved : that might be an old belief which needs to be revised and a new request made , or ` ag1 ` could try asking another agent , or inform ` ag2 ` that its belief about achieving ` g ` might be wrong , etc .",
    "plan ` fd ` is used simply to remove unnecessary beliefs used in previous stages of the interaction aimed at a goal adoption .",
    "it is not difficult to see that plans for other important multi - agent issues , such as ensuring agents are jointly committed to some course of action , can be developed by elaborating on the combinations of communication performatives along the lines of the examples above .",
    "on the other hand , many other complications related to agent interaction might need to be accounted for which could not be addressed in the simple examples provided here , such as shared beliefs becoming inaccurate with the passage of time .",
    "further plans to go with the ones shown here would be required for coping with such complications , when necessary in particular applications .",
    "@xcite @xcite introduced a framework for proving bdi properties of agents based on its operational semantics .",
    "the framework included precise definitions of how the bdi modalities are interpreted in terms of configurations of the transition system that gives semantics to .",
    "those same definitions are used in the work on model checking for @xcite , which allows the use of automated techniques for verification of programs .",
    "below , we give an example of a proof using the operational semantics for a simple property that involves only the _ belief _ modality . as the belief modality is very clear with respect to an agent , given that its architecture includes a belief base explicitly ,",
    "we avoid the need to discuss in this paper our previous work on the interpretation of the modalities @xcite .    if any two agents @xmath203 and @xmath204 have in their plan libraries the ` rsb1 ` , `",
    "rsb2 ` , and ` rsb3 ` plans shown in example  [ exsb ] , and they also have an appropriate @xmath167 function as well as the usual implementation of selection functions ( or others for which fairness is also guaranteed , in the sense that all events and intentions are eventually selected ) , if at some moment in time @xmath203 has ` reachsharedbel(b , ag_2 ) ` as a goal in its set of events ( i.e. , it has an event such as @xmath205`+!reachsharedbel(b , ag_2)`@xmath206 , with @xmath20 an intention ) , then _ eventually both agents will believe @xmath15 and believe that the other agent also believes @xmath15 _  note that this can be formulated using a bdi - like logic on top of ltl as @xmath207 } \\wedge \\bel{ag_2}{b[ag_1 ] } \\wedge    \\bel{ag_2}{b[self ] } \\wedge \\bel{ag_1}{b[ag_2]}).\\ ] ]    it is assumed that @xmath203 has @xmath208 in its set of events . assume further that this is precisely the event selected when rule is applied .",
    "then rule would select plans ` rsb1 ` , ` rsb2 ` , and ` rsb3 ` as relevant for the chosen event .",
    "rule would narrow this down to ` rsb1 ` only as , presumably , @xmath203 does not yet believe @xmath15 itself .",
    "rule would necessarily select ` rsb1 ` as intended means , given that it is the only applicable plan , and rule would include @xmath209 $ ] in the set of intentions ( i.e. , the chosen intended means would be pushed on top of the intention that generated the event above ) .",
    "consider now that in this same reasoning cycle ( for simplicity ) , rule would choose precisely that intention for execution within this reasoning cycle .",
    "then rule would add @xmath210 $ ] to @xmath203 s belief base , hence @xmath211}$ ] .",
    "in subsequent reasoning cycles , when @xmath203 s intention selection function selects the above intention for further execution , rule would generate again an internal event @xmath208 .",
    "the process is then as above expect that plan ` rsb1 ` is no longer applicable , but ` rsb2 ` is , and is therefore chosen as intended means .",
    "when that plan is executed ( similarly as described above ) , rule would add message @xmath212 to @xmath203 s @xmath151 component .",
    "rule then ensures that message @xmath213 is added to @xmath204 s @xmath150 component , which in the beginning of the next reasoning cycle would lead to rule adding @xmath214 $ ] to @xmath204 s belief base , hence @xmath215}$ ] . when the intention is selected for execution in a third reasoning cycle , the final formula in the body of plan ` rsb1 ` would be executed . by the use of similar rules for sending and receiving messages",
    ", we would have @xmath204 receiving a message @xmath216 , so now rule is used for interpreting the illocutionary force in that message , thus adding an event @xmath217 to @xmath204 s set of events .",
    "note that this is precisely how the process started in @xmath203 so the same sequence of rules will apply to @xmath204 , which will , symmetrically , lead to @xmath218}$ ] and @xmath219}$ ] being true , eventually . at that point in time we will have @xmath220 } \\wedge \\bel{ag_2}{b[ag_1 ] } \\wedge    \\bel{ag_2}{b[self ] } \\wedge \\bel{ag_1}{b[ag_2]})$ ] .    as discussed earlier , because @xmath204 is using exact copies of the plans used by @xmath203",
    ", @xmath204 will also ask @xmath203 to reach @xmath15 as a shared belief , even though @xmath203 has already executed its part of the joint plan .",
    "this is why plan ` rsb3 ` is important .",
    "it ensures that the agent will act no further when its own part of the joint plan for reaching a shared belief has already been achieved .",
    "note , however , that it is only possible to guarantee that a shared belief is reached in _ all possible runs _ if neither agent has plans that can interfere negatively with the execution of the plans given in example  [ exsb ] , for example by forcing the deletion of any instance of belief @xmath15 before such shared belief is reached .",
    "this is a verification exercise different from the proposition we wanted to prove , showing that shared beliefs _ can _ be reached ( under the given assumptions ) .",
    "we mention here some of the applications written in . the programming language has also been used in academia for student projects in various courses",
    ". it should be noted , however , that the language is clearly suited to a large range of applications for which it is known that bdi systems are appropriate ; various applications of prs @xcite and dmars @xcite , for example , have appeared in the literature ( * ? ? ?",
    "* chapter  11 ) .",
    "one particular area of application in which we have great interest is social simulation @xcite .",
    "in fact , is being used as part of a project to produce a platform tailored particularly for social simulation .",
    "the platform is called mas - soc is being developed by @xcite @xcite ; it includes a high - level language called elms @xcite for describing environments to be shared by multiple agents .",
    "this approach was used to develop , for example , a social simulation on social aspects of urban growth @xcite .",
    "another area of application that has been initially explored is the use of for defining the behaviour of animated characters for computer animation or virtual reality environments @xcite .",
    "more recently , has been used in the implementation of a team of `` gold miners '' as an entry to an agent programming competition @xcite . in this scenario",
    ", teams of agents must coordinate their actions in order to collect as much gold as they can and to deliver the gold to a trading agent located in a depot where the gold is safely stored .",
    "the team , composed of four mining agents and one leader that helped coordinate the team of miners , won the competition in 2006 .",
    "it is worth noting that the language support for high - level communication ( formalised in this paper ) proved to be an important feature for designing and implementing the system .",
    "the interpreter and multi - agent platform is being constantly improved , with the long term goal of supporting various multi - agent systems technologies .",
    "an important aspect of is precisely that of having formal semantics for most of its essential features .",
    "various projects are currently looking at extending in various ways , for example to combine it with an organisational model such as the one propose by @xcite @xcite .",
    "this is particularly important given that social structure is a fundamental notion for developing complex multi - agent systems .",
    "another area of development is to incorporate ontologies into an belief base @xcite , facilitating the use of for semantic web applications .",
    "recent work has also considered automated belief revision @xcite and plan exchange mechanisms @xcite .",
    "a more detailed description of the language and comparison with other agent - oriented programming languages was given by @xcite @xcite .",
    "as pointed out by @xcite @xcite , there are various perspectives for the semantics of agent communication . whereas the sender s",
    "perspective is the most common one in the literature , our approach uses primarily that of the receiver .",
    "we have given a formal semantics to the processing of speech - act based messages by an agent .",
    "previous attempts to define the semantics of agent communication languages were based on the `` pre - condition  action ",
    "post - condition '' approach , referring to agent mental states in modal languages typically based on cohen and levesque s work on intention @xcite .",
    "our semantics for communication , besides being more closely linked to implementation ( as it serves as the specification for an interpreter for an agent programming language ) , can also be used in the proof of communication properties @xcite .",
    "our work is somewhat related to that of @xcite @xcite and @xcite @xcite , which also provide an operational semantics for an agent communication language .",
    "however , their work does not consider the effects of communication in terms of bdi - like agents ( such as those written in ) .",
    "the idea of giving semantics to speech - act based communication within a bdi programming language was first introduced by @xcite @xcite .",
    "subsequently , @xcite @xcite also published some initial work on the semantics of communication for  3apl agents , although with the emphasis being on formalising the message exchange mechanisms for synchronous and asynchronous communication .",
    "in contrast , we largely abstract away from the specific message exchange mechanism ( this is formalised at a very high level in our semantics ) , and we are interested only in asynchronous communication ( which is the usual communication model for cognitive agents ) . in order to illustrate their message exchange mechanism , dastani et al",
    ".  gave semantics to the effects of receiving and treating `` request '' and `` inform '' messages  that is , they only consider information exchange .",
    "our work uses a much more comprehensive selection of illocutionary forces , and the main contribution is precisely in giving detailed semantics to the ways in which the various illocutionary forces affect the mental states of agents implemented in a programming language which actually has precise definitions for the notions of the bdi architecture .",
    "a denotational semantics for agent communication languages was proposed by @xcite @xcite , but the semantics is given for an abstract version of an acl and does not address the issues of interaction between an acl and other components of an agent architecture .    in this paper we provided new semantic rules for all the illocutionary forces used in a communication language for agents . in giving semantics to communicating  agents ,",
    "we have provided the means for the implementation of  interpreters with such functionality , as well as given a more computationally grounded semantics of speech - act based agent communication .",
    "in fact , the operational semantics presented in this paper proved useful in the implementation of   interpreters such as @xcite .",
    "while singh s proposal for a social - agency based semantics @xcite may be appropriate for general purpose agent communication languages such as fipa or kqml , within the context of a bdi agent programming language , our approach can be used without any of the drawbacks pointed out by singh .",
    "the fact that we have to deal with the intentional states of other agents when giving semantics of communication leads us to a number of related pragmatic questions .",
    "first , many treatments of speech - act style communication make use of _ mutual _ mental states  mutual belief , common knowledge , and similar .",
    "we do not make use of mutual mental states in our formalisation .",
    "there are good reasons for this .",
    "first , although mutual mental states are a useful and elegant tool for _ analysis _ , it is known that they represent _ theoretical idealisations _ only , which _ can not be achieved in systems which admit the possibility of message delivery failure _ @xcite .",
    "thus , although mutual mental states are a useful abstraction for understanding how communication works , they can not , realistically , be implemented , as there will always be a mismatch between the implementation ( which excludes the possibility of mutual mental states being faithfully implemented ) and the theory .",
    "this is primarily why mutual mental states form no part of our language or semantics , but are built on top of the fundamental communication primitives that we formalised in this paper , as shown in section  [ secdefc ] .",
    "note that it is also known that mutual mental states can be _ simulated _ , to any desired degree of nesting , by an appropriate message acknowledgement scheme @xcite , therefore in our approach this problem can be solved by mechanisms such as processed messages triggering the action of sending a message that acknowledges receipt .",
    "it is also worth adding that the belief annotation scheme used in our language permits agents to have a simple mechanism for nested beliefs : the annotation of source in a belief is an indication that the agent who sent the message believed in its propositional content at the time the message was sent ( but note that this is an indication only , unless agent veracity is guaranteed ) .",
    "annotation of information source at the time a message is received is done automatically according to the semantics we have given .",
    "however , programmers can also use the belief base to register sent messages , possibly using annotations in the same manner as for received messages .",
    "these would function as an indication of other agents states of mind , but from the point of view of the sender .",
    "we plan to deal with these questions which lie in the gray area between semantics and pragmatics in more detail in future work .",
    "while discussing models of mutual mental states , we should also mention in passing that _ joint intentions _ do not form part of our semantics , although they are widely used in the implementation of coordination schemes for multi - agent systems , following the seminal work of @xcite @xcite .",
    "the fact that such constructs are not built into the language ( or the language semantics ) as primitives does not preclude them being _ implemented _ using the language constructs , provided the usual practical considerations and assumptions , such as limiting the number of required acknowledgement messages for the achievement of shared beliefs , are in place .",
    "indeed , this is exactly the approach taken by tambe , in his steam system @xcite , and jennings , in his grate * system @xcite . the examples in section  [ secdefc ]",
    "help indicate how this can be achieved by further elaboration of those plans , making use of the communication primitives for which we gave semantics in this paper .",
    "we anticipate that readers will ponder whether our semantics limits the autonomy of agents that use our approach to communication .",
    "we provide the @xmath166 function which works as an initial `` filter '' , but this may give the impression that beliefs are just acquired / trusted and goals adopted after such simple filter .",
    "it is very important to emphasise that the actual _ behaviour _ of the agent ensuing from communication received from other agents completely depends on the particular plans the agent happens to have in its plan library ; in the current semantics , only the `` ask '' variants , @xmath173 , and @xmath175 performatives are dependent solely on the @xmath167 filter .",
    "in example  [ exfga ] , we mentioned that some plan contexts should be used to determine whether the agent would actually act towards achieving a goal as requested by another agent , or choose not to commit to achieving the goal .",
    "this is the general rule : the agent autonomy depends on the plans given by the agent programmer or obtained by communication with other agents ( the plans currently in the agent s plan library )",
    ". it would be typically the programmer s responsibility to write plans that ensure that an agent will be `` sufficiently autonomous '' for its purpose in a given application or , to use a more interesting notion , to program agents with _",
    "adjustable autonomy_. similarly , how benevolent or self - interested an agent will be , and to what extent beliefs acquired from other agents are to be trusted , are all issues that _ programmers _ have to be careful about : the semantics of communication itself does not ensure one case or the other .",
    "needless to say , it will be a much more difficult task to program agents to take part in open systems where other agents are self - interested and can not be trusted .",
    "while an agent programming language combined with a suitable agent communication language gives much support for such task , it surely does not automatically solve all those problems ; it still remains a complex programming task .",
    "it is also worth commenting on how our semantics can be used by other researchers , particularly those using agent programming languages other than agentspeak .",
    "the main point here is that our semantics provides a _ reference _ to the semantics of the communication language used in the context of agent - oriented programming . that is , using our semantics , it is possible to predict exactly how a particular agentspeak agent would interpret a particular message in a given situation .",
    "using this as a reference model , it should in principle be possible to implement communication for other agent programming languages .",
    "of course , our semantics is not language independent : it was developed specifically for agentspeak , so language specifics ought to be considered",
    ". however , attempts at giving semantics of agent communication that are language independent have their own problems , most notably the computational grounding problem referred to above .",
    "our semantics , while developed specifically for a practical agent programming language , have the advantage of not relying on mechanisms ( such as abstractly defined mental states ) that can not be checked for real programs . we note that , to the best of our knowledge , our work represents the first semantics given for a speech - act style , `` knowledge level '' communication language that is used in a real system .",
    "our current work does not consider commissive and declarative speech acts .",
    "these are surely relevant topics for future work , since commissive acts and declarations are relevant for various forms of agent interaction , such as negotiation .",
    "nevertheless , in the proposed framework it is possible for the programmer or multi - agent system designer to incorporate such more elaborate forms of interactions by writing appropriate plans .",
    "in this work , we assume that communication occurs among agents written in the same programming language , and can not be adopted directly in heterogeneous multi - agent systems .",
    "( consider , for example , the issues arising in processing an @xmath174 performative , which involves sending a plan to another agent . ) however , for a variety of other agent languages , it should not be difficult to write `` wrappers '' for translating message contents .",
    "other relevant areas for future investigation are those regarding role definitions and social structures or agent organisations .",
    "we consider that these would be interesting developments of the proposed @xmath166 function and libraries of plans or plan patterns .",
    "deontic relationships and social norms are also closely related to such extensions . in the case of e - business , for instance , a contract usually creates a number of obligations for the contractors .",
    "future work should also consider giving a better formal treatment of information sources , in particular for the case of plans being exchanged between agents .",
    "further communication aspects such as ontological agreement among  agents , and reasoning about information sources ( e.g. , in executing test goals or choosing plans based on annotations ) will also be considered in future work .",
    "we further expect sophisticated multi - agent system applications to be developed with  interpreters implemented according to our semantics .",
    "many thanks to jomi f. hbner for his comments and suggestions on an earlier version of this paper , and to berndt farwer and louise dennis who carefully proofread it .",
    "the first and second authors acknowledge the support of cnpq .",
    "alechina , n. , bordini , r.  h. , hbner , j.  f. , jago , m. ,  logan , b. 2006 . automating belief revision for agentspeakin baldoni , m.   endriss , u. , proceedings of the fourth international workshop on declarative agent languages and technologies ( dalt 2006 ) , held with aamas 2006 , 8th may , hakodate , japan ,  116 .",
    "ancona , d. , mascardi , v. , hbner , j.  f. ,  bordini , r.  h. 2004 .",
    ": cooperation in agentspeak through plan exchangein jennings , n.  r. , sierra , c. , sonenberg , l. ,  tambe , m. , proceedings of the third international joint conference on autonomous agents and multi - agent systems ( aamas-2004 ) , new york , ny , 1923 july ,  698705  new york , ny .",
    "acm press .",
    "bordini , r.  h. , bazzan , a. l.  c. , jannone , r.  o. , basso , d.  m. , vicari , r.  m. ,  lesser , v.  r. 2002 . : efficient intention selection in bdi agents via decision - theoretic task schedulingin castelfranchi , c.   johnson , w.  l. , proceedings of the first international joint conference on autonomous agents and multi - agent systems ( aamas-2002 ) , 1519 july , bologna , italy , 12941302  new york , ny .",
    "acm press .",
    "bordini , r.  h. , da  rocha  costa , a.  c. , hbner , j.  f. , moreira ,  .",
    "f. , okuyama , f.  y. ,  vieira , r. 2005 . : a social simulation platform based on agent - oriented programming , 8(3 ) .",
    "jasss forum , < http://jasss.soc.surrey.ac.uk/8/3/7.html>.    bordini , r.  h. , fisher , m. , pardavila , c. ,  wooldridge , m. 2003 .",
    "model checking agentspeakin rosenschein , j.  s. , sandholm , t. , wooldridge , m. ,  yokoo , m. , proceedings of the second international joint conference on autonomous agents and multi - agent systems ( aamas-2003 ) , melbourne , australia , 1418 july ,  409416  new york , ny .",
    "acm press .",
    "bordini , r.  h. , hbner , j.  f. ,  tralamazza , d.  m. 2006 . using * _ jason _ * to implement a team of gold miners ( a preliminary design)in inoue , k. , satoh , k. ,  toni , f. , proceedings of the seventh workshop on computational logic in multi - agent systems ( clima vii ) , held with aamas 2006 , 89th may , hakodate , japan ,  233237 .",
    "( clima contest paper ) .",
    "bordini , r.  h. , hbner , j.  f. ,  vieira , r. 2005 . and the golden fleece of agent - oriented programmingin bordini , r.  h. , dastani , m. , dix , j. ,  el  fallah  seghrouchni , a. , multi - agent programming : languages , platforms , and applications ,  1 .",
    "springer - verlag .",
    "bordini , r.  h.   moreira ,  .",
    "f. 2004 . proving bdi properties of agent - oriented programming languages : the asymmetry thesis principles in agentspeak(l ) , 42(13 ) , 197226 .",
    "special issue on computational logic in multi - agent systems .",
    "bordini , r.  h. , visser , w. , fisher , m. , pardavila , c. ,  wooldridge , m. 2003 .",
    "model checking multi - agent programs with caspin hunt  jr .",
    ", w.  a.   somenzi , f. , proceedgins of the fifteenth conference on computer - aided verification ( cav-2003 ) , boulder , co , 812 july ,  2725 in lncs , 110113  berlin .",
    "springer - verlag .",
    "tool description .",
    "castelfranchi , c.   falcone , r. 1998 .",
    "principles of trust for mas : cognitive anatomy , social importance , and quantificationin demazeau , y. , proceedings of the third international conference on multi - agent systems ( icmas98 ) , 47 july , paris , 7279  washington .",
    "ieee computer society press .",
    "cohen , p.  r.   levesque , h.  j. 1990b .",
    "rational interaction as the basis for communicationin cohen , p.  r. , morgan , j. ,  pollack , m.  e. , intentions in communication ,  12 ,  221255 . mit press , cambridge ,",
    "de  boer , f.  s. , van eijk , r.  m. , van der  hoek , w. ,  meyer , j .- j .  c. 2000 .",
    "failure semantics for the exchange of information in multi - agent systemsin palamidessi , c. , eleventh international conference on concurrency theory ( concur 2000 ) , university park , pa , 2225 august ,  1877 in lncs ,  214228 .",
    "springer - verlag .",
    "georgeff , m.  p.",
    "lansky , a.  l. 1987 .",
    "reactive reasoning and planningin proceedings of the sixth national conference on artificial intelligence ( aaai87 ) , 1317 july,1987 , seattle , wa ,  677682 manlo park , ca .",
    "aaai press  / mit press .",
    "guerin , f.   pitt , j. 2001 .",
    "denotational semantics for agent communication languagein proceedings of the fifth international conference on autonomous agents ( agents 2001 ) , 28th may ",
    "1st june , montreal canada ,  497504 .",
    "acm press .",
    "hbner , j.  f. , sichman , j.  s. ,  boissier , o. 2004 . using the @xmath221oise+ for a cooperative framework of mas reorganisation.in bazzan , a. l.  c.   labidi , s. , advances in artificial intelligence - sbia 2004 , 17th brazilian symposium on artificial intelligence , so luis , maranho , brazil , september 29 - october 1 , 2004 , proceedings ,  3171 of lncs , 506515 .",
    "springer - verlag .",
    "kumar , s.   cohen , p.  r. 2000 . towards a fault - tolerant",
    "multi - agent system architecturein proceedings of the fourth international conference on autonomous agents ( agents 2000 ) , 37 june , barcelona , spain , 459466 .",
    "acm press .",
    "labrou , y.   finin , t. 1994 . a semantics approach for kqml  a general purpose communication language for software agentsin proceedings of the third international conference on information and knowledge management ( cikm94 ) , 29th november ",
    "2nd december , gaithersburg , md .",
    "acm press .",
    "levesque , h.  j. , cohen , p.  r. ,  nunes , j. h.  t. 1990 . on acting togetherin proceedings of the eighth national conference on artificial intelligence ( aaai-1990 ) , 29th july  3rd august , boston , ma , 9499 .",
    "aaai press .",
    "levinson , s.  c. 1981 .",
    "the essential inadequacies of speech act models of dialoguein parret , h. , sbisa , m. ,  verschuren , j. , possibilities and limitations of pragmatics : proceedings of the conference on pragmatics at urbino , july , 1979 ,  473492 .",
    "benjamins , amsterdam .",
    "mayfield , j. , labrou , y. ,  finin , t. 1996 .",
    "evaluation of kqml as an agent communication languagein wooldridge , m. , mller , j.  p. ,  tambe , m. , intelligent agents  ii  proceedings of the second international workshop on agent theories , architectures , and languages ( atal95 ) , held as part of ijcai95 , montral , canada , august1995 ,  1037 in lnai ,  347360  berlin .",
    "springer - verlag .",
    "moreira ,  .",
    "f.   bordini , r.  h. 2002 .",
    "an operational semantics for a bdi agent - oriented programming languagein meyer , j .- j .  c.   wooldridge , m.  j. , proceedings of the workshop on logics for agent - based systems ( labs-02 ) , held in conjunction with the eighth international conference on principles of knowledge representation and reasoning ( kr2002 ) , april 2225 , toulouse , france ,  4559 .",
    "moreira ,  .",
    "f. , vieira , r. ,  bordini , r.  h. 2004 . extending the operational semantics of a bdi agent - oriented programming language for introducing speech - act based communicationin leite , j. , omicini , a. , sterling , l. ,  torroni , p. , declarative agent languages and technologies , proceedings of the first international workshop ( dalt-03 ) , held with aamas-03 , 15 july , 2003 , melbourne , australia ( revised selected and invited papers ) ,  2990 in lnai ,  135154  berlin .",
    "springer - verlag .",
    "moreira ,  .",
    "f. , vieira , r. , bordini , r.  h. ,  hbner , j.  f. 2006 .",
    "agent - oriented programming with underlying ontological reasoningin baldoni , m. , endriss , u. , omicini , a. ,  torroni , p. , proceedings of the third international workshop on declarative agent languages and technologies ( dalt-05 ) , held with aamas-05 , 25th of july , utrecht , netherlands ,  3904 in lncs ,  155170 .",
    "springer - verlag .",
    "okuyama , f.  y. , bordini , r.  h. ,  da  rocha  costa , a.  c. 2005 . an environment description language for multi - agent simulationsin weyns , d. , van dyke  parunak , h. , michel , f. , holvoet , t. , ferber , j. , environments for multiagent systems , state - of - the - art and research challenges .",
    "proceedings of the first international workshop on environments for multiagent systems ( e4mas ) , held with aamas-04 , 19th of july ,  3374 in lnai ,  91108  berlin .",
    "springer - verlag .",
    "rao , a.  s. 1996 .",
    ": bdi agents speak out in a logical computable languagein van  de velde , w.   perram , j. , proceedings of the 7th workshop on modelling autonomous agents in a multi - agent world ( maamaw96 ) , 2225 january , eindhoven , the netherlands ,  1038 in lnai ,  4255  london .",
    "springer - verlag .",
    "torres , j.  a. , nedel , l.  p. ,  bordini , r.  h. 2004 .",
    "autonomous agents with multiple foci of attention in virtual environmentsin proceedings of 17th international conference on computer animation and social agents ( casa 2004 ) , geneva , switzerland , 79 july ,  189196 .",
    "vieira , r. , moreira ,  .",
    "f. , bordini , r.  h. ,  hbner , j. 2006 .",
    "an agent - oriented programming language for computing in contextin debenham , j. , proceedings of second ifip symposium on professional practice in artificial intelligence , held with the 19th ifip world computer congress , tc-12 professional practice stream , 2124 august , santiago , chile ,  218 in ifip ,  6170  berlin .",
    "springer - verlag .",
    "wooldridge , m. 1998 .",
    "verifiable semantics for agent communication languagesin proceedings of the third international conference on multi - agent systems ( icmas98 ) , 47 july , paris ,  349365 .",
    "ieee computer society press .",
    "wooldridge , m. 2000a .",
    "computationally grounded theories of agencyin durfee , e. , proceedings of the fourth international conference on multi - agent systems ( icmas-2000),1012 july , boston , 1320  los alamitos , ca .",
    "ieee computer society .",
    "paper for an invited talk ."
  ],
  "abstract_text": [
    "<S> research on agent communication languages has typically taken the speech acts paradigm as its starting point . despite their manifest attractions , speech - act models of communication </S>",
    "<S> have several serious disadvantages as a foundation for communication in artificial agent systems . </S>",
    "<S> in particular , it has proved to be extremely difficult to give a satisfactory semantics to speech - act based agent communication languages . in part , the problem is that speech - act semantics typically make reference to the `` mental states '' of agents ( their beliefs , desires , and intentions ) , and there is in general no way to attribute such attitudes to arbitrary computational agents . in addition , agent programming languages have only had their semantics formalised for abstract , stand - alone versions , neglecting aspects such as communication primitives . with respect to communication , </S>",
    "<S> implemented agent programming languages have tended to be rather _ </S>",
    "<S> ad hoc_. this paper addresses both of these problems , by giving semantics to speech - act based messages received by an  agent .  </S>",
    "<S> is a logic - based agent programming language which incorporates the main features of the prs model of reactive planning systems . </S>",
    "<S> the paper builds upon a structural operational semantics to  that we developed in previous work . </S>",
    "<S> the main contributions of this paper are as follows : an extension of our earlier work on the theoretical foundations of interpreters ; a computationally grounded semantics for ( the core ) performatives used in speech - act based agent communication languages ; and a well - defined extension of  that supports agent communication . </S>"
  ]
}