{
  "article_text": [
    "in causal inference contexts , confounding is most often controlled by one of two approaches : first , by conditioning on the confounders in a regression model for the outcome in an _",
    "outcome regression _ model ; secondly , by modelling the treatment assignment mechanism to obtain so - called _ propensity score _ values , and then using these scores to construct strata within the observed sample , or a pseudo - sample from a hypothetical population , within which treatment assignment is not confounded .",
    "this pseudo - sample can be obtained via inverse probability of treatment weighting of the original sample , analogously to survey sampling procedures .",
    "the outcome regression adjustment method requires correct specification of the regression function in order to obtain consistent inference ; this may be achieved in practice using flexible regression strategies and complex functions of typically a large number of covariates .",
    "the propensity score adjustment methods focus principally on the specification of the treatment assignment model , which may be similarly flexible or complex . under either approach , sufficient control of confounding",
    "is therefore dependent on possibly unverifiable modelling assumptions .",
    "this has motivated the development of _ doubly robust _ methods in which both model components are specified , but only one of them needs to be correctly specified to sufficiently control for confounding .",
    "adjustments that depend on the propensity score using regression or reweighting are not easy to interpret from the bayesian perspective , since bayesian inferences are naturally based on modelling of the outcome , with modelling of the treatment assignment playing no role in inference relating to the outcome / treatment relationship @xcite .",
    "@xcite attempted a bayesian interpretation as a compromise between a saturated outcome model and a parametric one ; however , the treatment assignment model did not feature in this interpretation . @xcite and @xcite pointed out a connection between a doubly robust estimator and a model - based estimator ; the two are equivalent if the outcome model in the latter features the so called clever covariate , a particular function of the propensity score .    separately from the above developments , there has been a body of work studying bayesian versions of propensity score adjustment to control for confounding @xcite .",
    "these approaches require one of two kinds of compromises ; they either force a parametrization which makes the outcome and treatment assignment models dependent , thus losing the balancing property of the propensity score , or cut such a feedback in which case the inference procedures are no longer bayesian . because of these difficulties , some authors ( e.g. * ? ? ?",
    "* ) have been content to fix the propensity scores to their best estimates in model - based inferences , without attempting to jointly estimate the two model components . in an alternative approach , @xcite and @xcite",
    "have suggested connecting the outcome and treatment assignment models through the prior distribution in order to incorporate the uncertainty in confounder selection .",
    "herein we do not consider model uncertainty , but rather , concentrate on inferences with a priori specified outcome and treatment assignment models .",
    "the purpose of this paper is to clarify the theoretical and practical motivations for bayesian propensity score adjustment , and the relationships between the different methods proposed for this , which have not been fully explored previously .",
    "we address these in the context of double adjustment for both the potential confounders and the propensity score , and argue that the problem can not be properly understood without considering it in the framework of misspecified models . to provide an alternative to bayesian propensity score adjustment",
    ", we propose deriving bayesian versions of various weighted estimators , including weighted outcome regression and the semi - parametric double robust estimator , through posterior predictive expectations , with the weights introduced as importance sampling weights in monte carlo integration .",
    "for simplicity , we consider the case of a single binary treatment , and defer discussion of the longitudinal , multiple exposure and continuous cases to the discussion . let the random vectors @xmath0 represent a set of pre - treatment covariate measurements , @xmath1 a binary treatment allocation indicator , and @xmath2 an outcome for individual @xmath3 , measured after sufficient time has passed since administering the treatment .",
    "we adopt , for convenience , the standard _ potential outcome _ ( or _ counterfactual _ ) framework : for individual @xmath3 , the observed outcome is related to the two possible potential outcomes @xmath4 by @xmath5 .",
    "we assume that @xmath0 includes a sufficient set of covariates to control for confounding in the sense that @xmath6 ( cf .",
    "ignorable treatment assignment , @xcite ) .",
    "the _ propensity score _ @xmath7 has the balancing property @xmath8 , which also implies that @xmath9  this scalar score is therefore useful in controlling for confounding .",
    "if the covariate space @xmath0 is high - dimensional , in practice the task of controlling for confounding often involves some covariate selection ; here one can either select for the features that predict the outcome , or the treatment assignment . to represent this ,",
    "let @xmath10 and @xmath11 represent some a priori selected subsets of the all observed features @xmath0 , so that the latter can be partitioned as @xmath12 or @xmath13 , where possibly @xmath14 and @xmath15 . if the selected set of features @xmath10 captures all relevant prognostic information , then @xmath16 @xcite .",
    "for the remainder of the paper , we consider the stronger condition ( i ) @xmath17 , which requires that @xmath10 also captures all relevant information about possible effect modification .    in this case",
    "@xmath10 is sufficient to control for confounding , since from the properties of conditional independence @xcite it follows that @xmath18 . if , on the other hand , the selected set of features @xmath11 has the balancing property ( ii ) @xmath19 , it is sufficient to control for confounding .",
    "we are interested in estimation procedures which are valid when either @xmath17 ( but possibly @xmath20 ) or @xmath19 ( but possibly @xmath21 ) .",
    "our parameter of interest is an average causal contrast such as @xmath22 interest then lies in the identifiability of the average potential outcomes based on the observed data . when the ` no unmeasured confounder ' assumption holds , it follows that ( e.g. *",
    "* ) @xmath23      any bayesian model specification is constructed via de finetti s representation for exchangeable random sequences @xmath24 ( see for example ( * ? ? ?",
    "4 ) ) . the ( subjective ) joint distribution for observations @xmath25",
    "may then be represented by @xmath26 implying the existence of the parametric models and the prior density @xmath27 .",
    "since the representation theorem is not constructive , that is , does not specify the models implicit in , in practice inferences about a given finite - dimensional parametrization involves the often implicit assumption that @xmath28 , @xmath29 and @xmath30 , where @xmath31 is the limiting value of the posterior @xmath32 in the sense of e.g. @xcite , and where the @xmath33s represent the ` true ' limiting ( sampling ) distributions .",
    "we might further assume that the parameters are a priori independent , so that @xmath34 , in which case it it also follows also that the posterior factorizes as @xmath35 ( e.g. * ? ? ?",
    "the marginal distribution @xmath36 can in practice be specified nonparametrically and estimated using the empirical covariate distribution , leading to a bayesian estimator of the average causal contrast , @xmath37 where @xmath38 , and @xmath39 . in supplementary appendix 1 , we show that can be motivated without the use of potential outcomes notation through posterior predictive expectations for a new observation under a hypothetical completely randomized setting .",
    "the estimator is the bayesian version of the well - known direct standardization or _",
    "we return to it in section [ section : iptw ] , but note here that it does not feature the treatment assignment model ; rather , the posterior predictive approach for estimating the marginal causal contrast depends entirely on correct specification of the distribution @xmath40 , or in a moment - based representation , @xmath41 . before discussing bayesian alternatives to",
    ", we briefly review some commonly used frequentist approaches for combining outcome regression and propensity score adjustment .",
    "because of the balancing property of the propensity score , it is tempting to specify a propensity score @xmath42 and use a statistical model such as @xmath43 , in the hope that , if the prognostic model is is misspecified , adjusting for the propensity score would still sufficiently control for any residual confounding . for simplicity , we take the parameters @xmath44 to specify also the functional dependence between the propensity score and the outcome ; to model this dependency , it is advisable to use flexible formulations such as splines ( e.g. * ? ? ?",
    "using such an outcome model , the marginal causal contrast would then be estimated by @xmath45,\\end{aligned}\\ ] ] where @xmath46 , and where @xmath47 and @xmath48 are maximum likelihood estimators for the parameters in the outcome regression and treatment assignment model , respectively .",
    "the motivation for such a double adjustment is that it is sufficient to control for confounding if either condition ( i ) or ( ii ) of section [ section : notation ] applies .",
    "we summarize this property in the following theorem ( a proof in supplementary appendix 2 ; in the notation all convergencies are in probability unless otherwise stated ) .",
    "[ doublerobustness ] estimator is consistent if the outcome model is correctly specified in the sense that @xmath49 , the parameters in this can be consistently estimated so that @xmath50 , the treatment assignment model is correctly specified in the sense that @xmath51 and @xmath52 , and either ( i ) holds true , or ( ii ) holds true .",
    "the estimator may be considered ` doubly robust ' in terms of the covariate selection in the sense that only one of the sets @xmath10 and @xmath11 needs to be correctly specified , although it still always relies on a correct parametric specification of the model for the expected outcome , conditional on @xmath53 .",
    "the estimator discussed in the previous section did not specify which function of the propensity score @xmath54 should be added to the regression model . @xcite and",
    "@xcite drew a connection between propensity score regression adjustment and doubly robust estimators of the form @xmath55 m(0,s_i;\\widehat \\phi)}{1 - e(b_i ; \\widehat\\gamma ) } , \\ ] ] which can be equivalently represented as @xmath56 on considering the score equation derived from a regression of @xmath2 on @xmath1 and @xmath10 with mean function @xmath57 , this form suggests incorporating the derived covariate @xmath58 ( termed the  clever covariate  by * ? ? ?",
    "* ) additively into the outcome regression , that is , for example @xmath59 the first term in is then zero through the maximum likelihood score equation , leaving only the last term which is the model based estimator of the marginal treatment effect .",
    "thus with the clever covariate in the outcome model , the doubly robust estimator is equivalent to the model - based estimator . in the special case of model ,",
    "this becomes @xmath60 a potential drawback of using this covariate is that it may lead to extreme variability for the resulting mean difference estimator , even compared to inverse probability of treatment weighted estimators of the form @xmath61 to see why this is the case , the distribution of @xmath62 in itself can be very skewed to the right , but this becomes even more pronounced in the model - based estimator where the clever covariate has to evaluated at both @xmath63 and @xmath64 for each @xmath65 .",
    "in contrast , the weighted estimator involves only the probabilities of treatments that were actually assigned .",
    "is doubly robust in a stronger , semi - parametric , sense than ; it does not require correct specification of the outcome model , if the treatment assignment model is correctly specified .",
    "the approximate bayesian double robust approach proposed by @xcite involved replacing @xmath41 in with a linear predictor augmented with the clever covariate .",
    "we take this to be a special case of the two - step bayesian methods to be discussed in section [ section : unknown ] , and thus do not separately consider it in the present paper .",
    "however , in section [ section : isdr ] we will show how the form may be derived through posterior predictive expectations and importance sampling .",
    "yet another estimator for the marginal causal contrast is @xmath66 where the parameters @xmath44 in the model for the potential outcomes @xmath67 are estimated using an weighted estimating function @xmath68 , where @xmath69 the corresponding estimating equation is @xmath70 , where the pseudo - score function is @xmath71 here the treatment assignment probabilities @xmath72 would in practice be replaced with estimates @xmath73 . to motivate the use of for the parameter estimation",
    ", we present the following theorem ( a proof given in supplementary appendix 2 ) .",
    "[ eequation ] the estimating equation @xmath74 is unbiased if the model for the potential outcomes is correctly specified in the sense that @xmath75 , and either ( i ) or ( ii ) holds true .",
    "if we further assume the consistency of the estimator for @xmath44 , as well as consistency of @xmath48 when the weights are correctly specified , it also follows that consistently estimates the marginal causal contrast . in section [ section : isor ] we demonstrate that an estimator of the form can also be motivated from bayesian arguments .",
    "in observational settings the function @xmath54 is unknown and has to be estimated . when using an estimator of the form , a central question from a bayesian perspective then",
    "is how the uncertainty in the estimation of the parameters @xmath76 is incorporated in the inference of the marginal causal contrast .",
    "a ` bayesian ' approach could be motivated by writing the posterior predictive expectation as @xmath77 where @xmath78    the integrals of the form could be evaluated by monte carlo integration , by forward sampling first from @xmath79 and given the current value @xmath76 , from the conditional posterior @xmath80 . however , a concern related to such an approach is that the product of the posterior distributions @xmath80 and @xmath79 in does not necessarily correspond to any well defined joint posterior , except in the case when the outcome is correctly specified in the sense ( i ) , in which case it does not depend on the propensity score .",
    "in contrast , for the correctly specified models in we indeed have that @xmath81 . as a result ,",
    "the above outlined two - step approach is not proper bayesian , and would have to be evaluated on its frequency - based properties .    to give an example of a situation where the two - step bayesian approach does not result in correct frequency - based inferences",
    ", we can consider the special case of the outcome model @xmath82 , where @xmath83 is , for example , some appropriate spline basis transformation of the propensity score . with this model",
    "the estimator based on for the average causal contrast @xmath84 reduces to @xmath85 , that is , to an estimator of the posterior mean @xmath86 .",
    "this estimator in turn can be approximated with @xmath87 , where @xmath88 is a monte carlo sample from @xmath79 ( cf .",
    "we note first that this estimator has the same asymptotic distribution as @xmath89 , where the treatment assignment model parameters have been fixed to their maximum likelihood estimates ( see supplementary appendix 3 ) . in supplementary appendix 3",
    "we further show that @xmath90 , where @xmath91 is the estimator given the ` true ' propensity scores .",
    "thus , with the propensity score adjusted outcome model specification , a variance adjustment due to estimating the propensity scores should reduce the asymptotic variance of the resulting treatment effect estimator compared to a hypothetical situation where the true propensity scores are known ( ( cf .",
    "in contrast , @xcite and @xcite propose variance estimators based on the variance decomposition formula @xmath92 which appears to add a further variance component .",
    "an explanation for the discrepancy is that with the correctly specified models in the representation , we have that @xmath93 , and the the second variance component becomes zero . on the other hand , if the models are misspecified , the product form likelihood in the representation does not apply in the first place .",
    "this illustrates the difficulty in applying bayesian procedures in the context of incompatible models . even though this is routinely done in the context of multiple imputation ( e.g. * ? ? ?",
    "* ) , and often produces reasonable results , in the present context there is little motivation to use an approach which introduces an additional variance component to the posterior variance , given that estimation of the propensity scores should reduce the variance of the treatment effect estimator .",
    "we further discuss this discrepancy in the following section .",
    "even though the outcome @xmath2 can obviously be predictive of the individual treatment assignment @xmath1 , the outcomes are not informative of the treatment assignment mechanism ( a proof in supplementary appendix 2 ) :    [ noninformative ] if the outcome model is correctly specified , the outcomes are non - informative of the parameters characterizing the treatment assignment process .",
    "in such a case the treatment assignment model plays no part in the inferences , since the corresponding posterior predictive estimator is .",
    "however , the bayesian propensity score approach proposed by @xcite specifies a parametrization making the outcome and treatment assignment models dependent and estimates the parameters jointly .",
    "more recently , @xcite suggested that a similar approach could be used to obtain a bayesian analogue to doubly robust inferences .",
    "such an approach can be understood by assuming that there exists a de finetti parametrization @xmath94 for which @xmath95 where @xmath96 . compared to @xmath97 in",
    ", neither @xmath98 or @xmath99 retains the original interpretation , but now there is a well defined joint posterior distribution @xmath100 \\pi_0(\\phi^*)\\pi_0(\\gamma^*).\\end{aligned}\\ ] ] inferences could now be based on the posterior predictive expectations @xmath101 at first sight , would seem more natural than , since the specification does not make use of incompatible models .",
    "however , now the quantities @xmath102 do not possess the balancing properties of propensity scores , and thus it would be difficult to show whether would have the ` double robustness ' property of the estimator .    to address the lack of balance",
    ", @xcite suggested a gibbs sampler type approach similar to that of @xcite to cut the feedback from the outcome model , by successively drawing from the conditional posteriors @xmath79 and @xmath80 to approximate the joint posterior of @xmath94 .",
    "however , as discussed in the previous section , these posteriors are incompatible and generally such a sampling procedure is not guaranteed to converge to any well defined joint distribution .",
    "in fact , if the conditional posteriors can be sampled directly , or if the second sampling step is allowed to converge to the corresponding conditional distribution , the inferences based on the formulations and will be equivalent .    to sum up",
    ", trying to recover fully probabilistic inferences through sampling from a joint posterior of the outcome and treatment assignment model parameters loses the balancing property of the propensity scores , and consequently , the properties of the resulting estimator would be difficult to establish . on the other hand , cutting the feedback in an attempt to recover",
    "the balancing property would mean that the inferences are no longer based on well - defined posterior distributions .",
    "thus , in the following section , following the approach outlined in @xcite , we formulate alternative bayesian estimators that are not based on bayesian propensity score adjustment .",
    "it has been recognized by various authors ( e.g. * ? ? ? * ; * ? ? ?",
    "* ) that weighting can be motivated through a change of probability measures , or equivalently , importance sampling . however , as far as we know , before @xcite this approach has not been used to formulate bayesian causal inferences . here",
    "we argue that this approach can be used to resolve the paradoxes discussed in sections and .",
    "we follow the posterior predictive reasoning of supplementary appendix 1 , but rather than trying to directly predict a new observation under the experimental setting @xmath103 , we consider first the task of parameter estimation under this regime . for this purpose , a bayes estimator for the outcome model parameters can be constructed by maximizing the expected utility @xmath104 with respect to @xmath44 , where the log - likelihood @xmath105 takes the role of a parametric utility function , and the expectation is over a predicted new observation @xmath106 , @xmath107 .",
    "let further @xmath108 be a set of parameters characterizing the entire data - generating mechanism under the observational regime @xmath109 .",
    "we can further write the expectation as @xmath110,\\ ] ] where , following @xcite , we can consider the lower dimensional decision of maximizing the expected utility @xmath111 with respect to @xmath44 conditional on @xmath108 . with a known regime @xmath103 and the stability assumption discussed in supplementary appendix 1 , @xmath112 is a deterministic function of @xmath108 .",
    "thus , the uncertainty represented by the posterior distribution @xmath113 then also reflects the uncertainty on @xmath44 , providing means to construct a posterior distribution for @xmath44 .",
    "this proceeds as follows ; the inner expectation can be written as @xmath114 & = \\int_{v_i } l(\\phi ; v_i ) p_{\\mathcal e}(v_i { \\,|\\,}v ; \\xi ) \\,\\textrm dv_i \\\\ & = \\int_{v_i } l(\\phi ; v_i ) \\frac{p_{\\mathcal e}(v_i { \\,|\\,}v ; \\xi)}{p_{\\mathcal o}(v_i { \\,|\\,}v ; \\xi ) } p_{\\mathcal o}(v_i { \\,|\\,}v ; \\xi ) \\,\\textrm dv_i \\\\ & = \\int_{v_i } l(\\phi ; v_i ) \\frac{p_{\\mathcal e}(y_i { \\,|\\,}z_i , x_i , v ; \\xi)p_{\\mathcal e}(z_i)p_{\\mathcal e}(x_i { \\,|\\,}v ; \\xi ) } { p_{\\mathcal o}(y_i { \\,|\\,}z_i , x_i , v ; \\xi)p_{\\mathcal o}(z_i { \\,|\\,}x_i , v ; \\xi)p_{\\mathcal o}(x_i { \\,|\\,}v ; \\xi ) } p_{\\mathcal o}(v_i { \\,|\\,}v ; \\xi ) \\,\\textrm dv_i \\\\ & = \\int_{v_i } l(\\phi ; v_i ) \\frac{p_{\\mathcal e}(z_i ) } { p_{\\mathcal o}(z_i { \\,|\\,}x_i , v ; \\xi ) } p_{\\mathcal o}(v_i { \\,|\\,}v ; \\xi ) \\,\\textrm dv_i,\\end{aligned}\\ ] ]",
    "where in the last equality we made use of the stability assumption of supplementary appendix 1 . in the last form",
    "we can replace the predictive distribution under @xmath109 with the bayesian bootstrap specification @xmath115 , where @xmath116 and @xmath117 , as in the weighted likelihood bootstrap of @xcite . denoting @xmath118 ,",
    "the expected utility now becomes @xmath119 = \\int_{v_i } l(\\phi ; v_i ) w_i(\\xi ) \\sum_{k=1}^n \\xi_k \\delta_{v_k}(v_i ) \\,\\textrm dv_i = \\sum_{k=1}^n   w_k(\\xi ) \\xi_k l(\\phi ; v_k),\\end{aligned}\\ ] ] that is , a weighted log - likelihood , motivating the estimator @xmath120 an approximate posterior distribution for @xmath44 under @xmath103 can now be constructed by repeatedly sampling the weight vectors from @xmath117 , and recalculating @xmath121 at each realization .",
    "this approach of creating a mapping between the non - parametric specification and a parametrization relevant to inferences is analogous to @xcite , but adds the importance sampling weights to the dirichlet weights in order to make inferences across the observational and experimental regimes .",
    "the weights @xmath122 function as importance sampling weights in monte carlo integration ; they add variability to the estimation , but in the present context provide some protection towards misspecification of the outcome model , in the sense of section [ section : iptwor ] .",
    "the above did not yet address how to calculate these weights ; in principle these are fully determined by the current realization of @xmath108 under the non - parametric specification , but in practice parametric model specifications are needed for smoothing purposes , and we need a way to link the @xmath108 and the treatment assignment model parameters @xmath76 . for this purpose",
    "@xmath76 itself can be estimated through the weighted likelihood bootstrap since this readily gives the deterministic function linking the two parametrizations ; thus in we choose @xmath123 , where @xmath124 .",
    "the probabilities @xmath125 are given by the chosen regime @xmath103 that is the object of inference ; in practice the estimation is most efficient when we choose the target regime to be as close as possible to the observed regime @xmath109 ; this can be achieved by fixing @xmath125 to the marginal treatment assignment probabilities under @xmath109 , which would result in the usual kind of stabilized weights used in marginal structural modelling @xcite .",
    "the marginal causal contrast may now be estimated through the expectations @xmath126 where we used the non - parametric specification @xmath127 , and where again @xmath113 is replaced with the uniform dirichlet distribution . since all uncertainty is contained in the parameter vector @xmath108 , a posterior distribution for the predictive mean or mean difference can be constructed as before through resampling . the point estimator given by is the direct bayesian analogue of , where the outcome model was estimated using weighted regression .",
    "in fact , if we fix @xmath128 , @xmath129 , instead of considering these as unknown parameters , the two estimators are equivalent .",
    "thus , we conjecture that the estimator given by has a similar ` double robustness ' property as .",
    "we demonstrate this through simulations in section [ section : simulation ] , but before that , we show how the semi - parametric doubly robust estimator can be motivated as a posterior predictive expectation .      in supplementary appendix 4",
    "we show that under the non - parametric specification in terms of @xmath108 , the posterior predictive causal contrast may be written as @xmath130 which corresponds to formulation . since the non - parametric specification places no restrictions on the conditional distributions , in practice , to obtain an estimator , the non - parametrically specified quantities @xmath131 and @xmath132 would have to be replaced with the parametric versions @xmath133 and @xmath134 , estimated using the weighted likelihood bootstrap , as in the previous section .",
    "it is straightforward to see that if the outcome model is correctly specified , the expression reduces to the model - based estimator ( the second additive term ) .",
    "this again reflects the fact that if we believe in our outcome model , the treatment assignment model does not play a part in the inferences .",
    "however , a bayesian might want to use an estimator of the form if being restricted by two parametric constraints , in terms of @xmath44 and @xmath76 , but not knowing which one of these is correct .",
    "if either one of the parametric specifications is correct , will still reduce to the posterior predictive mean difference , the natural bayesian estimator .",
    "we summarize this property in the following theorem ( a proof in supplementary appendix 2 ) .",
    "[ drproperty ] the estimator obtained by substituting the parametric specifications @xmath133 and @xmath134 into expression is equivalent to the posterior predictive mean difference if either one of these models is correctly specified .",
    "a posterior distribution for the mean difference can be generated as in the previous section through resampling of the parameter vectors @xmath108 and recalculating at each realization ; we will illustrate this in the following section .",
    "above we have made a distinction between model misspecification due to omission of relevant covariates , and misspecification of the parametric functional relationship between the outcome and the covariates , and noted that all the estimators discussed in section [ section : frequentist ] should be ` doubly robust ' against the former type of misspecification .",
    "however , in practice the consequences of these two types of misspecification will often be similar ; they result in residual confounding .",
    "therefore , herein we investigate how the different estimators perform when the covariate sets @xmath10 and @xmath11 are not only created by a partitioning , but also a transformation of the @xmath135 s . for this purpose , we simulated @xmath136 , @xmath137 , and transformed these as @xmath138 .",
    "the true treatment assignment and outcome mechanisms were specified as @xmath139 and @xmath140 , respectively . for estimation , we considered two scenarios : ( i ) @xmath141 and @xmath142 ( misspecified outcome model and correctly specified treatment assignment model ) , and ( ii ) @xmath143 and @xmath144 ( correctly specified outcome model and misspecified treatment assignment model ) .",
    "we are interested in the marginal causal contrast @xmath145 .",
    "to estimate this , we applied the bayesian estimators discussed in sections [ section : unknown ] , [ section : jointestimation ] , and [ section : iptw ] .",
    "in the two - step estimation we attempted both forward sampling from the posterior distributions , and the variance decomposition formula . in the former , instead of markov chain monte carlo , we applied normal approximations for the posterior distributions , of the form @xmath146 , where @xmath147 is the maximum likelihood estimate and @xmath148 its estimated variance - covariance matrix .",
    "the posterior distribution @xmath149 was approximated using the weighted likelihood bootstrap . in the joint estimation",
    ", we again used a normal approximation , centered at the joint maximum likelihood estimates @xmath150 , and the variance - covariance matrix given by the inverse of the observed information at the maximum likelihood point .",
    "in both two - step and joint estimation , the fitted models were specified as @xmath151 , where @xmath83 is a cubic polynomial basis , and @xmath152 . in the importance sampling (",
    "is ) estimator proposed in section [ section : isor ] , and in the importance sampling / doubly robust estimator ( is / dr ) of section [ section : isdr ] , the fitted treatment assignment model was the same , with the outcome model specified through @xmath153 .    for comparison to the bayesian estimators",
    ", we also calculate naive unadjusted comparison ( naive ) , outcome regression adjusted for covariates @xmath154 ( adjusted ) , the standard weighted estimator ( iptw ) , the semi - parametric doubly robust estimator ( dr ) , the clever covariate version of this ( cc ) , the weighted outcome regression based estimator ( or / iptw ) , as well as propensity score adjusted outcome regression based estimator ( or / ps ) . for iptw ,",
    "dr , cc , and or / iptw , the standard errors were estimated through the standard frequentist nonparametric bootstrap @xcite . for or / ps , to demonstrate the variance estimation issues discussed in section [ section : unknown ] , we calculated both observed information based standard errors , and the adjusted sandwich type standard errors discussed in supplementary appendix 3 .",
    "the results over 1000 replications are shown in table [ table : simresults ] . under scenario ( i ) , all estimators except naive and adjusted can correct for confounding , although the joint estimation approach produces a slight bias . in terms of efficiency , the estimators based on propensity score adjusted outcome regression are the best , with the weighting based estimators losing slightly . as discussed in section [ section : cc ] , the clever covariate approach results in higher variability compared to the other doubly adjusted estimators . in terms of variance estimation , the comparison between the unadjusted and adjusted standard errors for or / ps suggests that under this simulation setting estimation of the propensity scores substantially reduces the variance , and not adjusting for this results in overcoverage .",
    "the resampling based variance estimators adjust for this automatically .",
    "however , the two - step approach to variance estimation performs poorly ; as demonstrated in supplementary appendix 3 , the two - step point estimator has the same asymptotic variance as the other or / ps estimators , but the two - step variance estimators unnecessarily add a further variance component .",
    "thus , the simulation results support the discussion in sections [ section : unknown ] and [ section : jointestimation ] ; the two - step and joint estimation approaches are difficult to justify from bayesian arguments , and do not seem to provide practical advantages in terms of their frequency - based properties . on the other hand ,",
    "the importance sampling based bayesian estimators produce very similar results to the or / iptw and dr estimators , respectively",
    ".    under scenario ( ii ) , all the estimators except iptw are unbiased , which is expected based on their previously discussed theoretical properties . when the outcome model is correctly specified , there is also very little difference in the efficiency of the various estimators .",
    ".estimates for the marginal causal contrast ( true value @xmath155 ) over 1000 simulation rounds [ cols=\"<,<,^,>,^,^,^ , > \" , ]     the columns correspond to estimator , mean point estimate , relative bias , monte carlo standard deviation ( sd ) , mean standard error estimate ( se ) , monte carlo ( mc ) error ( batch means ) of the mean point estimate , and 95% confidence interval coverage probability .",
    "the two scenarios correspond to ( i ) misspecified outcome model and correctly specified treatment assignment model , and ( ii ) correctly specified outcome model and misspecified treatment assignment model .",
    "[ table : simresults ]",
    "in this paper we reviewed previously proposed bayesian approaches for propensity score adjusted inferences , focusing on the assumptions concerning correct model specifications . here",
    "it is important to make a distinction between misspecification due to omission of relevant covariates from the outcome model , and misspecification of the functional form of the dependency between the covariates and the outcome .",
    "the frequentist propensity score adjusted outcome regression is robust against the former type of model misspecification , but this property is lost in bayesian estimation , if the misspecified outcome model is allowed to feed back to the estimation of the propensity scores . while feedback issue has been well documented in the literature ( e.g. * ? ? ? * ; * ? ? ? * ) , and the reasons behind this were already stated by @xcite , here we attempted to make the assumptions underlying the bayesian propensity score approach more explicit . on the other hand , we point out that cutting this feedback in a two - step bayesian estimation procedure unnecessarily inflates the posterior variance estimates .    as reaching double robustness through bayesian propensity score adjustment",
    "looks difficult , herein we attempted a completely different approach through posterior predictive inferences .",
    "our proposed approach decouples the outcome regression and treatment assignment model through introducing the weights as importance sampling weights in monte carlo integration in evaluating posterior predictive expectations .",
    "a similar procedure was used in a marginal structural modelling context by @xcite , improved to its present form in @xcite .",
    "while they used the importance sampling approach for estimating marginal outcome models in a longitudinal setting , herein we showed that in a point treatment setting the combination of importance sampling and posterior predictive inferences can be used to motivate weighted outcome regression or semi - parametric doubly robust inferences .",
    "such a possibility was mentioned , but not formally justified , by @xcite who applied the importance sampling procedure in the context of estimating optimal treatment regimes .",
    "the disadvantage of the importance sampling approach is the same as in the corresponding frequentist weighted inference procedures : the importance sampling weights add variability to the point estimator . in order to control this",
    ", a standard approach would be to truncate the weights ( e.g. * ? ? ?",
    "* ) , which would also be possible in the importance sampling context @xcite .",
    "recently , vehtari & gelman ( 2015 , arxiv:1507.02646v2 ) suggested probabilistic truncation of importance sampling weights ; studying this possibility in the present context is a topic for further research .",
    "the authors acknowledge support of the natural sciences and engineering research council ( nserc ) of canada .",
    "supplementary material available includes supplementary appendices 1 - 4 referred to herein , containing proofs to theorems and other technical material .",
    "the estimator ( 2 ) can be motivated without the use of potential outcomes notation as a posterior predictive expectation for a new observation under a hypothetical completely randomized setting @xmath103 where @xmath156 and the probabilities @xmath157 are known constants ( cf .",
    "the randomized trial measure discussed by * ? ? ? * ) .",
    "the data are observed under a setting @xmath109 , where @xmath158 , and causal inference then corresponds to inference across these regimes .",
    "we can now write for @xmath159 @xmath160 where the last form was obtained by choosing the non - parametric specification @xmath161 . alternatively ,",
    "in one could use the bayesian bootstrap @xcite specification @xmath162 , where @xmath163 , with @xmath164 taken to be a uniform dirichlet distribution ( see section 6 ) . obtaining also required assuming that @xmath165 and and @xmath166 , which corresponds to the stability assumption discussed by @xcite .",
    "if ( i ) holds true , then also @xmath167 , and the propensity score adjustment does not add information .",
    "if on the other hand ( ii ) holds true , @xmath168 has jointly the balancing property @xmath169 .",
    "this follows from theorem 2 of @xcite and also implies that @xmath170 ( * ? ? ?",
    "* theorem 3 ) .",
    "now @xmath171 and further , @xmath172 the consistency of the estimator ( 3 ) then relies on being able to consistently estimate the quantities in .",
    "consider first the expectation of ( 8) under the assumption that ( i ) holds true . now",
    "@xmath173 which followed because now @xmath174 at the true parameter value .",
    "thus , the misspecified weights do not influence the estimation ( in terms of bias ) as long as the outcome model is correctly specified .    under the assumption that ( ii ) holds true",
    ", we have in turn that @xmath175 since now @xmath176 . using the partitioning @xmath177 ,",
    "we can write the last form in above as @xmath178 thus , even though the outcome regression does not include a sufficient set of confounders , through the ipt weighting we can still obtain valid estimates for the conditional distributions @xmath179 .    now the marginal posterior distribution of the parameters @xmath76 becomes @xmath180    the estimator obtained through substituting in the parametric models is @xmath181 \\left[\\frac{z_k } { { \\mathrm{pr}}_{\\mathcal o}\\{z_k = 1 { \\,|\\,}b_k ;   \\widehat\\gamma(\\xi)\\ } } -   \\frac{1 - z_k}{{\\mathrm{pr}}_{\\mathcal o}\\{z_k = 0 { \\,|\\,}b_k ; \\widehat\\gamma(\\xi)\\}}\\right ] \\nonumber \\\\ & \\quad+ \\sum_{k=1}^n \\xi_k \\left[m\\{1 , s_k ; \\widehat\\phi(\\xi)\\ } - m\\{0 , s_k ; \\widehat\\phi(\\xi)\\}\\right].\\end{aligned}\\ ] ] first , if the outcome model is correctly specified in the sense that @xmath182 , we get @xmath183 because the second to last form is equivalent to in supplementary appendix 4 . thus , the first summation term in cancels out , leaving only the model based estimator , which itself is now equivalent to the posterior predictive mean difference .",
    "on the other hand , if the treatment assignment model is correctly specified in the sense that + @xmath184 , we get @xmath185 therefore , the estimator now reduces to @xmath186,\\end{aligned}\\ ] ] which is again equivalent to the posterior predictive mean difference ( see supplementary appendix 4 ) .",
    "trivially , if the outcome model is correctly specified , then @xmath187 and ( 9 ) reduces to .",
    "the interesting situations are naturally those where this is not the case .",
    "we denote the log - likelihood by @xmath188 and @xmath189 and consider the quasi - maximum likelihood estimator @xmath190 .",
    "if the treatment assignment model is correctly specified , @xmath191 .",
    "in addition , we assume that with any fixed value of @xmath76 , @xmath192 , where @xmath193 is the parameter vector which minimizes the kullback - leibler divergence to the true outcome model ( e.g. * ? ? ? * ) .",
    "thus , by the law of large numbers and continuous mapping , we can write in the usual way that @xmath194 \\rightarrow e\\left[q_i(\\phi ; \\gamma_0 ) - q_i\\{\\phi_0(\\gamma_0 ) ; \\gamma_0\\ } \\right],\\ ] ] where the right hand side is maximized at zero when @xmath195 , at which point @xmath196 since we also have that the posterior @xmath197 in distribution , we can then conjecture that posterior predictive inferences based on ( 9 ) will be asymptotically uncounfounded .    with the definitions @xmath198 and noting that @xmath199 for each @xmath200 , @xmath201",
    ", we can consider the first order taylor expansion of @xmath202 around the true parameter values @xmath203 , which becomes @xmath204 and further , @xmath205 if @xmath206 .",
    "hence , @xmath207.\\end{aligned}\\ ] ] here we have , by another first order expansion around @xmath208 , that @xmath209 so finally , @xmath210\\right).\\end{aligned}\\ ] ] we may similarly expand @xmath211 where the parameters @xmath76 have been fixed to their maximum likelihood estimates around @xmath203 as @xmath212 to find that @xmath213 where @xmath214 since the two estimators @xmath215 and @xmath216 have the same linear approximation which is a sum of independent terms , we conclude that they have the same asymptotic distribution , @xmath217.\\ ] ]    fitting the regression model @xmath218 to estimate the parameter of interest @xmath219 is numerically equivalent to fitting the sequence of regressions @xmath220 , @xmath221 and @xmath222 , where @xmath223 $ ] .",
    "denoting the estimating function corresponding to the last regression as @xmath224,\\ ] ] and the partial derivatives of this as e.g. @xmath225 , we can expand this around @xmath226 , where @xmath227 and @xmath228 are the limiting values of the nuisance parameters , as @xmath229 since here @xmath230 .",
    "we can now see that the theorem 1 of @xcite applies to the last form here , implying that @xmath231 , where @xmath232 is the solution to @xmath233 and @xmath234 is the solution to @xmath235 .",
    "the usual ipt - weighted estimator for a marginal causal contrast may be derived through a posterior predictive argument as follows .",
    "first , @xmath238 & = \\int_{v_i } z_i y_i p_{\\mathcal e}(v_i { \\,|\\,}v ; \\xi ) \\d v_i \\nonumber \\\\ & = \\int_{v_i } z_i y_i \\frac{p_{\\mathcal e}(v_i { \\,|\\,}v ; \\xi)}{p_{\\mathcal o}(v_i { \\,|\\,}v ; \\xi ) } p_{\\mathcal o}(v_i { \\,|\\,}v ;   \\xi )   \\d v_i \\nonumber \\\\ & = \\int_{v_i } z_i y_i \\frac{p_{\\mathcal e}(y_i { \\,|\\,}z_i , x_i , v ; \\xi)p_{\\mathcal e}(z_i)p_{\\mathcal e}(x_i { \\,|\\,}v , \\xi ) } { p_{\\mathcal o}(y_i { \\,|\\,}z_i , x_i , v ; \\xi)p_{\\mathcal o}(z_i { \\,|\\,}x_i , v ; \\xi)p_{\\mathcal o}(x_i { \\,|\\,}v ; \\xi ) } p_{\\mathcal o}(v_i   { \\,|\\,}v ; \\xi )   \\d v_i \\nonumber \\\\ & = \\int_{v_i } z_i y_i \\frac{p_{\\mathcal e}(z_i ) } { p_{\\mathcal o}(z_i",
    "{ \\,|\\,}x_i , v ; \\xi ) } p_{\\mathcal o}(v_i { \\,|\\,}v ; \\xi ) \\d v_i \\\\ & = \\int_{v_i } z_i y_i \\frac{p_{\\mathcal e}(z_i ) } { p_{\\mathcal o}(z_i { \\,|\\,}x_i , v ; \\xi ) } \\sum_{k=1}^n \\xi_k \\delta_{v_k}(v_i ) \\d v_i \\nonumber \\\\ & = \\sum_{k=1}^n \\xi_k z_k y_k \\frac{p_{\\mathcal e}(z_k ) } { p_{\\mathcal o}(z_k { \\,|\\,}x_k , v ; \\xi ) } \\nonumber \\\\ & = { \\mathrm{pr}}_{\\mathcal e}(z_k = 1 ) \\sum_{k=1}^n \\xi_k \\frac{z_k y_k } { { \\mathrm{pr}}_{\\mathcal o}(z_k = 1 { \\,|\\,}x_k , v ; \\xi)},\\nonumber \\end{aligned}\\ ] ] and thus , @xmath239 and @xmath240    on the other hand , the usual outcome model based estimator may be motivated similarly as in supplementary appendix 1 through @xmath241 and @xmath242 finally , we note that we can write alternatively as @xmath243 and therefore @xmath244 thus , the posterior predictive mean difference can be written as @xmath245"
  ],
  "abstract_text": [
    "<S> in causal inference confounding may be controlled either through regression adjustment in an outcome model , or through propensity score adjustment or inverse probability of treatment weighting , or both . </S>",
    "<S> the latter approaches , which are based on modelling of the treatment assignment mechanism and their doubly robust extensions have been difficult to motivate using formal bayesian arguments ; in principle , for likelihood - based inferences , the treatment assignment model can play no part in inferences concerning the expected outcomes if the models are assumed to be correctly specified . on the other hand , forcing dependency between the outcome and treatment assignment models by allowing the former to be misspecified results in loss of the balancing property of the propensity scores and the loss of any double robustness . in this paper , we explain in the framework of misspecified models why doubly robust inferences can not arise from purely likelihood - based arguments , and demonstrate this through simulations . as an alternative to bayesian propensity score analysis , we propose a bayesian posterior predictive approach for constructing doubly robust estimation procedures . </S>",
    "<S> our approach appropriately decouples the outcome and treatment assignment models by incorporating the inverse treatment assignment probabilities in bayesian causal inferences as importance sampling weights in monte carlo integration .    </S>",
    "<S> a revised version of this article has been accepted for publication in _ biometrika _ , published by oxford university press . </S>",
    "<S> + saarela , o. , belzile , l. r. and d. a. stephens . a bayesian view of doubly robust causal inference , _ biometrika _ ( 2016 ) , 103 ( 3 ) : 667 - 681 . </S>",
    "<S> doi : 10.1093/biomet / asw025[doi : 10.1093/biomet / asw025 ] . </S>"
  ]
}