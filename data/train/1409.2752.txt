{
  "article_text": [
    "recently , supervised learning has been developed and used successfully to produce representations that have enabled leaps forward in classification accuracy for several tasks @xcite .",
    "however , the question that has remained unanswered is whether it is possible to learn as  powerful \" representations from unlabeled data without any supervision .",
    "it is still widely recognized that unsupervised learning algorithms that can extract useful features are needed for solving problems with limited label information . in this work ,",
    "we exploit sparsity as a generic prior on the representations for unsupervised feature learning .",
    "we first introduce the fully - connected winner - take - all autoencoders that learn to do sparse coding by directly enforcing a winner - take - all _ lifetime _ sparsity constraint .",
    "we then introduce convolutional winner - take - all autoencoders that learn to do shift - invariant / convolutional sparse coding by directly enforcing winner - take - all _ spatial _ and _ lifetime _ sparsity constraints .",
    "training sparse autoencoders has been well studied in the literature . for example , in @xcite , a ",
    "lifetime sparsity \" penalty function proportional to the kl divergence between the hidden unit marginals ( @xmath0 ) and the target sparsity probability ( @xmath1 ) is added to the cost function : @xmath2 .",
    "a major drawback of this approach is that it only works for certain target sparsities and is often very difficult to find the right @xmath3 parameter that results in a properly trained sparse autoencoder .",
    "also kl divergence was originally proposed for sigmoidal autoencoders , and it is not clear how it can be applied to relu autoencoders where @xmath0 could be larger than one ( in which case the kl divergence can not be evaluated ) . in this paper , we propose fully - connected winner - take - all ( fc - wta ) autoencoders to address these concerns .",
    "fc - wta autoencoders can aim for any target sparsity rate , train very fast ( marginally slower than a standard autoencoder ) , have no hyper - parameter to be tuned ( except the target sparsity rate ) and efficiently train all the dictionary atoms even when very aggressive sparsity rates ( _ e.g. _ , 1% ) are enforced .",
    "sparse coding algorithms typically comprise two steps : a highly non - linear sparse encoding operation that finds the  right \" atoms in the dictionary , and a linear decoding stage that reconstructs the input with the selected atoms and update the dictionary .",
    "the fc - wta autoencoder is a non - symmetric autoencoder where the encoding stage is typically a stack of several relu layers and the decoder is just a linear layer . in the feedforward phase , after computing the hidden codes of the last layer of the encoder , rather than reconstructing the input from all of the hidden units , for each hidden unit , we impose a lifetime sparsity by keeping the @xmath4 percent largest activation of that hidden unit across the mini - batch samples and setting the rest of activations of that hidden unit to zero . in the backpropagation phase , we only backpropagate the error through the @xmath4 percent non - zero activations . in other words",
    ", we are using the min - batch statistics to approximate the statistics of the activation of a particular hidden unit across all the samples , and finding a hard threshold value for which we can achieve @xmath5 lifetime sparsity rate . in this setting , the highly nonlinear encoder of the network ( relus followed by top - k sparsity ) learns to do sparse encoding , and the decoder of the network reconstructs the input linearly . at test time",
    ", we turn off the sparsity constraint and the output of the deep relu network will be the final representation of the input . in order to train a stacked fc - wta autoencoder",
    ", we fix the weights and train another fc - wta autoencoder on top of the fixed representation of the previous network .",
    ".33     .33     .33",
    ".52     .52     the learnt dictionary of a fc - wta autoencoder trained on mnist , cifar-10 and toronto face datasets are visualized in fig .",
    "[ fig : wta ] and fig [ fig : wta _ ] . for large sparsity levels , the algorithm tends to learn very local features that are too primitive to be used for classification ( fig .",
    "[ fig : wta:1 ] ) .",
    "as we decrease the sparsity level , the network learns more useful features ( longer digit strokes ) and achieves better classification ( fig .",
    "[ fig : wta:2 ] ) . nevertheless , forcing too much sparsity results in features that are too global and",
    "do not factor the input into parts ( fig .",
    "[ fig : wta:3 ] ) .",
    "section [ sec : experiment : fc ] reports the classification results .",
    "* winner - take - all rbms . *",
    "besides autoencoders , wta activations can also be used in restricted boltzmann machines ( rbm ) to learn sparse representations .",
    "suppose @xmath6 and @xmath7 denote the hidden and visible units of rbms . for training wta - rbms ,",
    "in the positive phase of the contrastive divergence , instead of sampling from @xmath8 , we first keep the @xmath5 largest @xmath8 for each @xmath9 across the mini - batch dimension and set the rest of @xmath8 values to zero , and then sample @xmath9 according to the sparsified @xmath8 .",
    "filters of a wta - rbm trained on mnist are visualized in fig .",
    "[ fig : rbm ] .",
    "we can see wta - rbms learn longer digit strokes on mnist , which as will be shown in section [ sec : experiment : fc ] , improves the classification rate .",
    "note that the sparsity rate of wta - rbms ( _ e.g. _ , 30% ) should not be as aggressive as wta autoencoders ( _ e.g. _ , 5% ) , since rbms are already being regularized by having binary hidden states .",
    ".52     .52",
    "there are several problems with applying conventional sparse coding methods on large images .",
    "first , it is not practical to directly apply a fully - connected sparse coding algorithm on high - resolution ( _ e.g. _ , @xmath10 ) images .",
    "second , even if we could do that , we would learn a very redundant dictionary whose atoms are just shifted copies of each other .",
    "for example , in fig .",
    "[ fig : toronto_dense ] , the fc - wta autoencoder has allocated different filters for the same patterns ( _ i.e. _ , mouths / noses / glasses / face borders ) occurring at different locations . one way to address",
    "this problem is to extract random image patches from input images and then train an unsupervised learning algorithm on these patches in isolation @xcite .",
    "once training is complete , the filters can be used in a convolutional fashion to obtain representations of images . as discussed in @xcite ,",
    "the main problem with this approach is that if the receptive field is small , this method will not capture relevant features ( imagine the extreme of @xmath11 patches ) . increasing the receptive field size is problematic , because then a very large number of features are needed to account for all the position - specific variations within the receptive field .",
    "for example , we see that in fig .",
    "[ fig : cifar_dense ] , the fc - wta autoencoder allocates different filters to represent the same horizontal edge appearing at different locations within the receptive field . as a result",
    ", the learnt features are essentially shifted versions of each other , which results in redundancy between filters .",
    "unsupervised methods that make use of convolutional architectures can be used to address this problem , including convolutional rbms @xcite , convolutional dbns @xcite , deconvolutional networks @xcite and convolutional predictive sparse decomposition ( psd ) @xcite .",
    "these methods learn features from the entire image in a convolutional fashion . in this",
    "setting , the filters can focus on learning the shapes ( _ i.e. _ , `` what '' ) , because the location information ( _ i.e. _ , `` where '' ) is encoded into feature maps and thus the redundancy among the filters is reduced .    in this section ,",
    "we propose convolutional winner - take - all ( conv - wta ) autoencoders that learn to do shift - invariant / convolutional sparse coding by directly enforcing winner - take - all _ spatial _ and _ lifetime _ sparsity constraints .",
    "our work is similar in spirit to deconvolutional networks @xcite and convolutional psd @xcite , but whereas the approach in that work is to break apart the recognition pathway and data generation pathway , but learn them so that they are consistent , we describe a technique for directly learning a sparse convolutional autoencoder .",
    "a shallow convolutional autoencoder maps an input vector to a set of feature maps in a convolutional fashion .",
    "we assume that the boundaries of the input image are zero - padded , so that each feature map has the same size as the input .",
    "the hidden representation is then mapped linearly to the output using a deconvolution operation ( appendix [ deconv ] ) .",
    "the parameters are optimized to minimize the mean square error .",
    "a non - regularized convolutional autoencoder learns useless delta function filters that copy the input image to the feature maps and copy back the feature maps to the output .",
    "interestingly , we have observed that even in the presence of denoising@xcite / dropout@xcite regularizations , convolutional autoencoders still learn useless delta functions .",
    "[ fig : wta - conv:1a ] depicts the filters of a convolutional autoencoder with 16 maps , 20% input and 50% hidden unit dropout trained on street view house numbers dataset @xcite .",
    "we see that the 16 learnt delta functions make 16 copies of the input pixels , so even if half of the hidden units get dropped during training , the network can still rely on the non - dropped copies to reconstruct the input .",
    "this highlights the need for new and more aggressive regularization techniques for convolutional autoencoders .    the proposed architecture for conv - wta autoencoder is depicted in fig .",
    "[ fig : wta - conv:1b ] .",
    "the conv - wta autoencoder is a non - symmetric autoencoder where the encoder typically consists of a stack of several relu convolutional layers ( _ e.g. _ , @xmath12 filters ) and the decoder is a linear deconvolutional layer of larger size ( _ e.g. _ , @xmath13 filters ) .",
    "we chose to use a deep encoder with smaller filters ( _ e.g. _ , @xmath12 ) instead of a shallow one with larger filters ( _ e.g. _ , @xmath13 ) , because the former introduces more non - linearity and regularizes the network by forcing it to have a decomposition over large receptive fields through smaller filters .",
    "the conv - wta autoencoder is trained under two winner - take - all sparsity constraints : _ spatial sparsity _ and _ lifetime sparsity_.    .3     .6     the conv - wta autoencoder with 16 first layer filters and 128 second layer filters trained on mnist : ( a ) input image .",
    "( b ) learnt dictionary ( deconvolution filters ) .",
    "( c ) 16 feature maps while training ( spatial sparsity applied ) .",
    "( d ) 16 feature maps after training ( spatial sparsity turned off ) .",
    "( e ) 16 feature maps of the first layer after applying local max - pooling .",
    "( f ) 48 out of 128 feature maps of the second layer after turning off the sparsity and applying local max - pooling ( final representation ) . ]",
    ".33     .33     .33       in the feedforward phase , after computing the last feature maps of the encoder , rather than reconstructing the input from all of the hidden units of the feature maps , we identify the single largest hidden activity within each feature map , and set the rest of the activities as well as their derivatives to zero .",
    "this results in a sparse representation whose sparsity level is the number of feature maps .",
    "the decoder then reconstructs the output using only the active hidden units in the feature maps and the reconstruction error is only backpropagated through these hidden units as well .",
    "consistent with other representation learning approaches such as triangle @xmath4-means @xcite and deconvolutional networks @xcite , we observed that using a softer sparsity constraint at test time results in a better classification performance .",
    "so , in the conv - wta autoencoder , in order to find the final representation of the input image , we simply turn off the sparsity regularizer and use relu convolutions to compute the last layer feature maps of the encoder .",
    "after that , we apply max - pooling ( _ e.g. _ , over @xmath14 regions ) on these feature maps and use this representation for classification tasks or in training stacked conv - wta as will be discussed in section [ stacked ] .",
    "[ fig : mnist ] shows a conv - wta autoencoder that was trained on mnist .",
    "although spatial sparsity is very effective in regularizing the autoencoder , it requires all the dictionary atoms to contribute in the reconstruction of every image .",
    "we can further increase the sparsity by exploiting the winner - take - all _ lifetime _ sparsity as follows .",
    "suppose we have 128 feature maps and the mini - batch size is 100 .",
    "after applying spatial sparsity , for each filter we will have 100  winner \" hidden units corresponding to the 100 mini - batch images .",
    "during feedforward phase , for each filter , we only keep the @xmath5 largest of these 100 values and set the rest of activations to zero . note that despite this aggressive sparsity , every filter is forced to get updated upon visiting every mini - batch , which is crucial for avoiding the dead filter problem that often occurs in sparse coding .",
    "[ fig : minist : lifetime ] and fig .",
    "[ fig : toronto ] show the effect of the lifetime sparsity on the dictionaries trained on mnist and toronto face dataset .",
    "we see that similar to the fc - wta autoencoders , by tuning the lifetime sparsity of conv - wta autoencoders , we can aim for different sparsity rates .",
    "if no lifetime sparsity is enforced , we learn local filters that contribute to every training point ( fig . [",
    "fig : minist : lifetime:1 ] and [ fig : toronto:1 ] ) .",
    "as we increase the lifetime sparsity , we can learn rare but useful features that result in better classification ( fig .",
    "[ fig : minist : lifetime:2 ] ) . nevertheless , forcing too much lifetime sparsity will result in features that are too diverse and rare and do not properly factor the input into parts ( fig .",
    "[ fig : minist : lifetime:3 ] and [ fig : toronto:2 ] ) .",
    ".52     .52     .52   whitened patches .",
    "( 64conv5 - 64conv5 - 64conv5 - 64deconv11).,title=\"fig : \" ]    .52   whitened patches .",
    "( 64conv5 - 64conv5 - 64conv5 - 64deconv11).,title=\"fig : \" ]      the conv - wta autoencoder can be used as a building block to form a hierarchy . in order to train the hierarchical model",
    ", we first train a conv - wta autoencoder on the input images",
    ". then we pass all the training examples through the network and obtain their representations ( last layer of the encoder after turning off sparsity and applying local max - pooling ) .",
    "now we treat these representations as a new dataset and train another conv - wta autoencoder to obtain the stacked representations .",
    "[ fig : mnist](f ) shows the deep feature maps of a stacked conv - wta that was trained on mnist .",
    "the goal of convolutional sparse coding is to learn _ shift - invariant _ dictionary atoms and encoding filters .",
    "once the filters are learnt , they can be applied convolutionally to any image of any size , and produce a spatial map corresponding to different locations at the input .",
    "we can use this idea to efficiently train conv - wta autoencoders on datasets containing large images .",
    "suppose we want to train an alexnet @xcite architecture in an unsupervised fashion on imagenet , ilsvrc-2012 ( 224x224 ) .",
    "in order to learn the first layer @xmath13 shift - invariant filters , we can extract medium - size image patches of size @xmath15 and train a conv - wta autoencoder with 64 dictionary atoms of size 11 on these patches .",
    "this will result in 64 shift - invariant filters of size @xmath13 that can efficiently capture the statistics of @xmath15 patches .",
    "once the filters are learnt , we can apply them in a convolutional fashion with the stride of @xmath16 to the entire images and after max - pooling we will have a @xmath17 representation of the images .",
    "now we can train another conv - wta autoencoder on top of these feature maps to capture the statistics of a larger receptive field at different location of the input image .",
    "this process could be repeated for multiple layers .",
    "[ fig : imagenet ] shows the dictionary learnt on the imagenet using this approach .",
    "we can see that by imposing lifetime sparsity , we could learn very diverse filters such as corner , circular and blob detectors .",
    ".49    .classification performance of conv - wta autoencoder trained on mnist .",
    "[ cols=\"<,>\",options=\"header \" , ]     .30",
    "* relationship of fc - wta to @xmath4-sparse autoencoders .",
    "* @xmath4-sparse autoencoders impose sparsity across different channels ( population sparsity ) , whereas fc - wta autoencoder imposes sparsity across training examples ( lifetime sparsity ) .",
    "when aiming for low sparsity levels , @xmath4-sparse autoencoders use a scheduling technique to avoid the dead dictionary atom problem .",
    "wta autoencoders , however , do not have this problem since all the hidden units get updated upon visiting every mini - batch no matter how aggressive the sparsity rate is ( no scheduling required ) . as a result , we can train larger networks and achieve better classification rates .    *",
    "relationship of conv - wta to deconvolutional networks and convolutional psd .",
    "* deconvolutional networks @xcite are top down models with no direct link from the image to the feature maps .",
    "the inference of the sparse maps requires solving the iterative ista algorithm , which is costly .",
    "convolutional psd @xcite addresses this problem by training a parameterized encoder separately to explicitly predict the sparse codes using a soft thresholding operator .",
    "deconvolutional networks and convolutional psd can be viewed as the generative decoder and encoder paths of a convolutional autoencoder .",
    "our contribution is to propose a specific winner - take - all approach for training a convolutional autoencoder , in which both paths are trained jointly using direct backpropagation yielding an algorithm that is much faster , easier to implement and can train much larger networks .    *",
    "relationship to maxout networks .",
    "* maxout networks @xcite take the max across different channels , whereas our method takes the max across space and mini - batch dimensions .",
    "also the winner - take - all feature maps retain the location information of the  winners \" within each feature map and different locations have different connectivity on the subsequent layers , whereas the maxout activity is passed to the next layer using weights that are the same regardless of which unit gave the maximum .",
    "we proposed the winner - take - all spatial and lifetime sparsity methods to train autoencoders that learn to do fully - connected and convolutional sparse coding .",
    "we observed that conv - wta autoencoders learn shift - invariant and diverse dictionary atoms as opposed to position - specific gabor - like atoms that are typically learnt by conventional sparse coding methods . unlike related approaches , such as deconvolutional networks and convolutional psd , our method jointly trains the encoder and decoder paths by direct back - propagation , and does not require an iterative em - like optimization technique during training .",
    "we described how our method can be scaled to large datasets such as imagenet and showed the necessity of the deep architecture to achieve better results .",
    "we performed experiments on the mnist , svhn and cifar-10 datasets and showed that the classification rates of winner - take - all autoencoders are competitive with the state - of - the - art .",
    "we showed our method is particularly effective in the semi - supervised settings where limited labeled data is available .",
    "in this section , we describe the network architectures and hyper - parameters that were used in the experiments . while most of the conventional sparse coding algorithms require complex matrix operations such as matrix inversion or svd decomposition , wta autoencoders only require the _ sort _ operation in addition to matrix multiplication and convolution which are all efficiently implemented in most gpu libraries .",
    "we used alex krizhevsky s _ cuda - convnet _ convolution kernels @xcite for this work .      at the decoder of a convolutional autoencoder ,",
    "deconvolutional layers are used .",
    "the deconvolution operation is exactly the reverse of convolution ( _ i.e. _ , its forward pass is the backward pass of convolution ) .",
    "for example , whereas a strided convolution decreases the feature map size , a strided deconvolution increases the map size .",
    "we implemented the deconvolution kernels by minor modifications of current available gpu kernels for the convolution operation .",
    "we found that tying the encoder and decoder of fc - wta autoencoders helps the generalization performance of them . but tying the convolution and deconvolution weights of wta - conv autoencoders hurts the generalization performance ( data not shown ) .",
    "we think this is because the conv - wta autoencoder is already very regularized by the aggressive sparsity constraints and tying the weights results in too much regularization .",
    "* shallow conv - wta autoencoder ( 128 maps ) . * in the shallow architecture , we used @xmath18 filters with a @xmath19 receptive field applied at strides of @xmath20 pixel .",
    "after training , we used max - pooling over @xmath12 regions at strides of @xmath21 pixels to obtain the final @xmath22 representation .",
    "svm was then applied to this representation for classification .    * stacked conv - wta autoencoder ( 128 , 2048 maps ) . * in the deep architecture , we trained another @xmath23 feature maps on top of the pooled feature maps of the first network , with a filter width of @xmath21 applied at strides of @xmath20 pixel .",
    "after training , we used max pooling over @xmath24 regions at strides of @xmath25 pixels to obtain the final @xmath26 representation .",
    "svm was then applied to this representation for classification .",
    "* semi - supervised conv - wta autoencoder . * in the semi - supervised setup , the amount of labeled data was varied from @xmath27 to @xmath28 .",
    "we ensured the dataset is balanced and each class has the same number of labeled points in all the experiments .",
    "we used the stacked conv - wta autoencoder ( 128 , 2048 maps ) trained in the previous part , and trained an svm on top of the unsupervised features using only @xmath29 labeled data .",
    "the street view house numbers ( svhn ) dataset consists of about 600,000 images ( both the difficult and the simple sets ) and 26,000 test images .",
    "we first apply global contrast normalization to the images and then used local contrast normalization using a gaussian kernel to preprocess each channel of the images .",
    "this is the same preprocessing that is used in @xcite .",
    "the contrast normalized svhn images are shown in fig .",
    "[ fig : svhn:1 ] .",
    "we trained two networks on this dataset .",
    "* conv - wta autoencoder ( 256 maps ) . *",
    "the architecture used for this network is 256conv3 - 256conv3 - 256conv3 - 256deconv7 .",
    "after training , we used max - pooling on the last @xmath30 feature maps of the encoder , over @xmath31 regions at strides of @xmath16 pixels to obtain the final @xmath32 representation .",
    "svm was then applied to this representation for classification .",
    "we observed that having a stack of conv3 layers instead of a 256conv7 encoder , significantly improved the classification rate .",
    "* stacked conv - wta autoencoder ( 256 , 1024 maps ) . * in the stacked architecture , we trained another @xmath33 feature maps on top of the pooled feature maps of the first network , with a filter width of @xmath21 applied at strides of @xmath20 pixel .",
    "after training , we used max pooling over @xmath24 regions at strides of @xmath25 pixels to obtain the final @xmath34 representation .",
    "svm was then applied to this representation for classification .",
    "* semi - supervised conv - wta autoencoder . * in the semi - supervised setup , we assumed only n=1000 labeled data is available .",
    "we used the stacked conv - wta autoencoder ( 256 , 1024 maps ) trained in the previous part , and trained an svm on top of the unsupervised features using only @xmath35 labeled data .      on the cifar-10 dataset , we used global contrast normalization followed by zca whitening with the regularization bias of 0.1 to preprocess the dataset .",
    "this is the same preprocessing that is used in @xcite .",
    "we trained three networks on cifar-10 .",
    "* conv - wta autoencoder ( 256 maps ) .",
    "* the architecture used for this network is 256conv3 - 256conv3 - 256conv3 - 256deconv7 .",
    "after training , we used max - pooling on the last @xmath30 feature maps of the encoder , over @xmath31 regions at strides of @xmath16 pixels to obtain the final @xmath32 representation .",
    "svm was then applied to this representation for classification .    * stacked conv - wta autoencoder ( 256 , 1024 maps ) . * for this network , we trained another @xmath33 feature maps on top of the pooled feature maps of the first network , with a filter width of @xmath21 applied at strides of @xmath20 pixel .",
    "after training , we used max pooling over @xmath24 regions at strides of @xmath25 pixels to obtain the final @xmath34 representation .",
    "svm was then applied to this representation for classification .    * stacked conv - wta autoencoder ( 256 , 1024 , 4096 maps ) . * for this model , we first trained a conv - wta network with the architecture of 256conv3 - 256conv3 - 256conv3 - 256deconv7 .",
    "after training , we used max pooling on the last @xmath30 feature maps of the encoder , over @xmath24 regions at strides of @xmath25 pixels to obtain a @xmath36 representation .",
    "we then trained another @xmath33 feature maps with filter width of @xmath21 and stride of @xmath20 on top of the pooled feature maps of the first layer .",
    "we then obtained the second layer representation by max pooling the @xmath33 feature maps with a pooling stride of @xmath25 and width of @xmath21 to obtain a @xmath37 representation .",
    "we then trained another @xmath38 feature maps with filter width of @xmath21 and the stride of @xmath20 on top of the pooled feature maps of the second layer .",
    "then we used max - pooling on the @xmath38 feature maps with a pooling width of @xmath21 applied at strides of @xmath25 pixels to obtain the final @xmath39 representation .",
    "an svm was trained on top of the final representation for classification ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a winner - take - all method for learning hierarchical sparse representations in an unsupervised fashion . </S>",
    "<S> we first introduce fully - connected winner - take - all autoencoders which use mini - batch statistics to directly enforce a lifetime sparsity in the activations of the hidden units . </S>",
    "<S> we then propose the convolutional winner - take - all autoencoder which combines the benefits of convolutional architectures and autoencoders for learning shift - invariant sparse representations . </S>",
    "<S> we describe a way to train convolutional autoencoders layer by layer , where in addition to lifetime sparsity , a spatial sparsity within each feature map is achieved using winner - take - all activation functions . </S>",
    "<S> we will show that winner - take - all autoencoders can be used to to learn deep sparse representations from the mnist , cifar-10 , imagenet , street view house numbers and toronto face datasets , and achieve competitive classification performance . </S>"
  ]
}