{
  "article_text": [
    "technical efficiency ( te ) measures have been used for several decades for benchmarking purposes .",
    "the concept of te was first introduced by farrell ( 1957 ) . since then , two strands of te measurement developed in the late 1970s and early 1980s : data envelopment analysis ( dea ) , based on linear programming , and stochastic frontier analysis ( sfa ) , which commonly uses parametric stochastic frontier ( sf ) models .    the dea technique is mainly used to measure te scores in the research fields of managerial and economics studies . since dea often requires only input and output quantities , it is quite easy to understand the technique s empirical results and to apply these results to any empirical investigations .",
    "however , a weakness of dea is that it is sensitive to extreme values , making it difficult to apply the technique to data sets with outliers .",
    "several attempts have been made to solve this problem .",
    "for example , wilson ( 1993 , 1995 ) suggested a method for detecting outliers and cazals et al .",
    "( 2002 ) proposed a robust estimator for the nonparametric frontier model .",
    "simar ( 2003 ) employed the method of cazals et al .",
    "( 2002 ) to detect outliers using classic dea estimators .",
    "florens and simar ( 2005 ) also proposed robust parametric estimators of nonparametric frontiers .",
    "the sfa framework is a counterpart to the dea in that it is a parametric approach .",
    "this means that the functional form , such as production or cost functions , needs to be assumed before estimating the te score .",
    "one of the pioneering methodologies in the sfa framework was developed by jondrow et al .",
    "( 1982 ) , who proposed a formula for separating a random error component and a te component . owing to the ease of application , various models have been developed and sf models have been widely employed in efficiency measurement studies .",
    "for example , the approach suggested by battese and coelli ( 1995 ) provides the te and the determinants of the te .",
    "numerous statistical methods have been proposed for estimating sf models .",
    "for example , park and simar ( 1994 ) and park et al .",
    "( 1998 ) considered semiparametric estimation in sf panel models and kumbhakar et al .",
    "( 2007 ) introduced an approach for nonparametric sf models .",
    "kopp and mullahy ( 1990 ) and van den broeck et al .",
    "( 1994 ) applied the generalized method of moments procedure and bayesian method , respectively , to parametric sf models .",
    "kneip et al .",
    "( 2015 ) proposed an alternative and new approach for nonparametric sf models using penalized likelihood .",
    "this study addresses the estimation of parametric sf models , particularly in the presence of high- or low - performing observations . in empirical data analyses ,",
    "one often faces observations with a comparative advantage , such as highly advanced technology , which yield a super efficiency score .",
    "these observations should be treated carefully because they can influence the estimation procedure in the same way as outliers do . as is widely recognized in the literature , the maximum likelihood ( ml ) estimation method is influenced strongly by outliers or extreme values .",
    "our simulation shows that applying the ml estimator to the sf model suffers from the same problem , requiring the development of a robust estimation method for sf models .",
    "however , to the best of our knowledge , little effort has been made in this regard .",
    "the purpose of this study is to propose a robust estimator for sf models . to construct a robust estimator",
    ", we consider the estimation method based on divergence , which evaluates the discrepancy between any two probability distributions .",
    "the divergence - based estimation method has been used successfully in constructing robust estimators in the past . for a review ,",
    "refer to pardo ( 2006 ) and cichocki and amari ( 2010 ) , as well as the references therein . in this study , we employ density power divergence , as proposed by basu et al .",
    "( 1998 ) ( henceforth , bhhj ) .",
    "bhhj proposed a minimum density power divergence ( mdpd ) estimator , and demonstrated that it possesses , relative to the ml estimator , strong robust properties with little loss in asymptotic efficiency . compared with other robust methods , such as the minimum hellinger distance estimation",
    ", the bhhj method does not require any smoothing methods .",
    "hence , it avoids the difficulty of selecting a bandwidth when estimating the nonparametric density estimation .",
    "for this reason , the bhhj method can be applied conventionally to any parametric models to which the ml estimation can be applied . for example , see jurez and schucany ( 2004 ) , fujisawa and eguchi ( 2006 ) , and kim and lee ( 2013 ) .",
    "the remainder of the paper is organized as follows .",
    "section 2 reviews the bhhj estimation method and proposes a robust estimator for sf models based on density power divergence .",
    "this section also examines the asymptotic and robust properties of the proposed estimator . in section 3",
    ", we discuss our simulation study that compares the performance of the conventional ml estimator and the mdpd estimator in the sfa framework . in section 4 ,",
    "we analyze real data that contain some low - performing observations using both estimators , again for comparative purposes .",
    "lastly , section 5 concludes the paper .",
    "this section reviews the mdpd estimator and integrates it into the sfa framework in order to estimate the te .      in this subsection , we review the bhhj estimation procedure that minimizes a density - based divergence measure .",
    "let @xmath0 and @xmath1 be probability densities . to measure the difference between @xmath0 and @xmath1 , bhhj defined the density power divergence , @xmath2 , as follows : @xmath3 note that the divergence includes kullback  leibler divergence and @xmath4-distance as special cases .",
    "since @xmath2 converges to @xmath5 as @xmath6 , the above divergence with @xmath7 provides a smooth bridge between the kullback  leibler divergence and the @xmath4-distance .",
    "consider a family of parametric distributions @xmath8 possessing densities @xmath9 with respect to the lebesgue measure , and let @xmath10 be the class of all distributions having densities with respect to the lebesgue measure . for a distribution @xmath11 with density @xmath1 ,",
    "the mdpd functional at @xmath12 ( i.e. , @xmath13 ) with respect to @xmath14 is defined by @xmath15 where it is assumed that @xmath16 exists and is unique , as will normally be the case .",
    "note that when @xmath12 belongs to @xmath17 ( i.e. , @xmath18 for some @xmath19 ) , @xmath16 becomes @xmath20 .",
    "roughly speaking , @xmath21 can be considered as a projection of @xmath12 onto the space of @xmath14 in terms of the divergence , and @xmath22 becomes the target parameter of the mdpd estimator below .",
    "given a random sample @xmath23 with unknown density @xmath1 , the mdpd estimator for the parameter @xmath22 is defined as an empirical version of ( [ 2.1.2 ] ) .",
    "that is , @xmath24 where @xmath25 bhhj showed that @xmath26 is weakly consistent with @xmath22 and asymptotically normal , and demonstrated that the estimator has strong robust properties .",
    "the robust property of the estimator can be understood by checking the following estimating equation : @xmath27 where @xmath28 . comparing the estimating equation of the ml estimator ( i.e. , @xmath29 )",
    ", one can see that the mdpd estimator provides density power weight , @xmath30 , to each @xmath31 , whereas the ml estimator gives the equal weight .",
    "this means that the robustness of the mdpd estimator is obtained by providing a down - weight to the outliers .",
    "indeed , @xmath32 controls the trade - off between robustness and asymptotic efficiency in the estimation procedure . in the literature that applies the bhhj procedure to other statistical or econometric models ,",
    "the mdpd estimators show good robustness against outliers , while still having a high efficiency relative to the ml estimator , especially when the true distribution belongs to @xmath33 and @xmath32 is close to 0 .",
    "for example , jurez and schucany ( 2004 ) and fujisawa and eguchi ( 2006 ) applied the procedure to the generalized pareto distribution and the normal mixture distribution , respectively .",
    "lee and song ( 2009 , 2013 ) introduced the mdpd estimator for the garch and diffusion models , respectively , and kim and lee ( 2013 ) employed the estimation method for the copula parameter in the scomdy models . since the estimator with @xmath34 causes a significant loss of efficiency , estimations with @xmath35 $ ] are commonly employed .",
    "this approach can be easily extended to estimations in regression models .",
    "let @xmath36 be a family of regression models with a parameter @xmath37 , and let @xmath38 be the true density for @xmath39 , given @xmath40 .",
    "then , a family of the @xmath41-conditional version of the density power divergence is defined as @xmath42 given observations @xmath43 , the above divergence makes it possible to employ the mdpd estimators for regression models , as follows : @xmath44 where @xmath45 as an alternative to the ml estimation , we apply this estimator to the sf models , as described in the next subsection .      consider a random sample @xmath46 with @xmath47 and @xmath48 , satisfying the following stochastic frontier model : @xmath49 where @xmath50 is the frontier production function with parameter @xmath51 ; @xmath52 and @xmath53 are the random error term and technical inefficiency , respectively ; and @xmath54 and @xmath55 are assumed to be independent .    denoting the true density functions of @xmath56 and @xmath57 by @xmath58 and @xmath59 , respectively ,",
    "the true conditional density of @xmath39 , given @xmath40 , is obtained by @xmath60 since it is not usually easy to specify the distributions of @xmath56 and @xmath57 , we consider a class of _",
    "pseudo(or quasi ) _ distributions having parametric densities to construct the mdpd estimator . in this case , the sf model under consideration is misspecified if the true distribution of @xmath56 and @xmath57 do not belong to the given family .",
    "let @xmath61 be the conditional density induced from the pseudo parametric distributions .",
    "then , the mdpd estimator can be defined by inserting the pseudo conditional density @xmath61 in the estimator given in ( [ 2.1.4 ] ) and the pseudo parameter to be estimated is given by @xmath62,\\end{aligned}\\ ] ] where @xmath63 denotes the parameter space .",
    "note that if @xmath56 and @xmath57 are correctly specified , i.e. , @xmath64 for some @xmath65 , it holds that @xmath66 for @xmath67 .    in this paper",
    ", we consider the normal distribution and the truncated - normal(or the exponential ) distribution as the pseudo distributions for @xmath56 and @xmath57 , respectively .",
    "that is , our mdpd estimator for ( [ 2.2.1 ] ) is constructed using the pseudo conditional densities below regardless of whether the true densities @xmath58 and @xmath59 belong to the assumed class or not .    1 .   when @xmath68 and @xmath69 are employed as the pseudo distributions for @xmath56 and @xmath57 , respectively ,",
    "the pseudo conditional density is given by @xmath70^{-1}\\phi\\big(\\frac{y - g(x,\\beta)+\\mu}{\\sigma}\\big)\\phi \\big(\\frac{\\mu}{\\sigma\\lambda}-\\frac{y - g(x,\\beta)}{\\sigma}\\lambda\\big),\\label{nt}\\end{aligned}\\ ] ] where @xmath71 and @xmath72 are the standard normal cumulative distribution and density functions , respectively ; @xmath73 and @xmath74 ; and @xmath75 denotes @xmath76 .",
    "note that setting @xmath77 , ( [ nt ] ) reduces to the following conditional density : @xmath78 which is the conditional density of the normal ",
    "half normal sf model .",
    "2 .   when @xmath68 and @xmath79 are considered for the pseudo distributions of @xmath56 and @xmath57 ,",
    "respectively , we have @xmath80 where @xmath75 denotes @xmath81 .    in the case of @xmath82 ,",
    "the above estimator becomes the quasi ml ( qml ) estimator .",
    "hereafter , we denote by [ nt](resp .",
    "[ ne ] ) the case in which ( [ nt])(resp . ( [ ne ] ) ) is adopted as the pseudo conditional density .",
    "further , we assume that @xmath83 . + * remark 1 . * to the best of our knowledge ,",
    "the integral of @xmath84 in ( [ 2.1.4 ] ) with ( [ nt ] ) or ( [ ne ] ) can not be expressed by a closed form .",
    "this makes it problematic to obtain the explicit form of the above objective function . in our simulation study",
    ", we use the numerical integration method provided in _",
    "r - metrics _ to implement the mdpd estimator , which seems to produce sufficiently good approximation results to estimate the parameters ( see section 3 ) .",
    "+      this subsection derives the asymptotic properties of the mdpd estimator for ( [ 2.2.1 ] ) .",
    "we particularly concentrate on the estimator with @xmath85 .",
    "the following regularity conditions are required to establish the consistency .    1 .",
    "the parameter space @xmath63 is compact and the pseudo parameter @xmath86 .",
    "@xmath87 is a set of @xmath88-dimensional i.i.d .",
    "random vectors with density @xmath89 and that are independent of @xmath55 and @xmath54 .",
    "@xmath50 is continuous in @xmath90 for all @xmath91 .",
    "4 .   @xmath92 for some @xmath93 , where @xmath93 does not depend on @xmath41 and @xmath94 .",
    "[ t1 ] let @xmath46 be a random sample from ( [ 2.2.1 ] ) and suppose that assumptions * a1**a3 * hold . if pseudo conditional density @xmath61 satisfy * a4 * , then , for each @xmath95 , the mdpd estimator @xmath96 defined by ( [ 2.1.4 ] ) with the pseudo conditional density @xmath61 converges almost surely to @xmath97 .",
    "* remark 2 . * in the case of [ nt ] , by the compactness of @xmath63 , we can take some constants @xmath98 and @xmath99 such that @xmath100^q \\times[\\underline{u},\\overline{u}]\\times [ \\underline{\\sigma},\\overline{\\sigma}]^2 $ ] , where @xmath101 . in what follows , without loss of generality ,",
    "we assume @xmath102^q \\times[\\underline{u},\\overline{u}]\\times [ \\underline{\\sigma},\\overline{\\sigma}]^2 $ ] under the case of [ nt ] .",
    "similarly , when the case [ ne ] is considered , @xmath63 is assumed to be @xmath103^q \\times [ \\underline{\\sigma},\\overline{\\sigma}]^2 $ ] .",
    "+ assumptions * a1**a3 * are general conditions in practice , so it suffices to check whether assumption * a4 * holds or not to ensure the consistency of the mdpd estimator . in the cases of [ nt ] and [ ne ]",
    ", one can readily get global upper bounds for the pseudo conditional densities .",
    "that is , when [ nt ] is considered , we have @xmath104^{-1}\\phi(0).\\ ] ] when [ ne ] is considered , we can obtain a following upper bound : @xmath105.\\end{aligned}\\ ] ] using the fact that @xmath106 for all @xmath107 , we can see that the rhs of the above inequality is finite .",
    "+ in order to obtain the asymptotic normality , we impose additional assumptions . through out this paper , @xmath108 and @xmath109 denote @xmath110 and @xmath111 , respectively , and the symbol @xmath112 denotes the @xmath113 norm for matrices and vectors .    1 .",
    "@xmath97 lies in the interior of @xmath63 .",
    "2 .   @xmath114 < \\infty$ ] .",
    "4 .   @xmath116 $ ] is positive definite .",
    "then , we have the second asymptotic result of the mdpd estimator .",
    "[ t2 ] assume that assumptions * a1**a8 * hold .",
    "then , for each @xmath95 , @xmath117    * remark 3.*[r3 ] in the case of @xmath64 for some @xmath118 , we have @xmath119,\\\\ k_{\\alpha}&=&(1+{\\alpha})^2{\\mathbb{e}}\\big [ f_{\\theta_0}^{2{\\alpha}-2}(y|x){\\partial } _ { \\theta } f_{\\theta_0 } ( y|x ) { \\partial } _ { \\theta^t } f_{\\theta_0 } ( y|x)\\big]-{\\mathbb{e}}\\big[\\xi \\xi^t\\big],\\end{aligned}\\ ] ] where @xmath120 . + for @xmath85 , assumptions * a6 * and * a7 * can be ensured by more simple conditions in the cases of [ nt ] and [ ne ] . indeed",
    ", the following proposition provides a sufficient condition for * a6 * and * a7*.    [ p1 ] assume that @xmath63 is compact and @xmath50 is twice differentiable w.r.t .",
    "@xmath90 for all @xmath41 . under the cases of [ nt ] and [ ne ] ,",
    "if @xmath121<\\infty$ ] and @xmath122<\\infty$ ] , then * a6 * and * a7 * hold for @xmath85 .",
    "* remark 4 . * in the case where @xmath50 is a linear function of @xmath41 , i.e. , @xmath123 , one can see that @xmath121={\\mathbb{e}}\\|xx^t\\|$ ] and @xmath124 .",
    "hence , the conditions in the proposition reduce to @xmath125 .",
    "this condition is not a serious restriction in empirical analysis , because it is usual to regard the input variables as limited resources which implies that the input vector @xmath126 can be assumed to be finite . in other cases , @xmath125 together with the compactness of @xmath63 and the continuity of @xmath127 and @xmath128 can be a sufficient condition for * a6 * and * a7*. + proofs for the results in this subsection are provided in appendix .      in this subsection",
    ", we discuss the influence function of the mdpd estimator to describe the effect of infinitesimal contamination .",
    "letting @xmath129 be the true distribution of @xmath130 , the functional @xmath131 corresponding to the mdpd estimator can be defined as @xmath132 note that since @xmath133-\\frac{1}{\\alpha}{\\mathbb{e}}\\big[f^{\\alpha}(y|x)\\big ] & \\mbox { , $ \\alpha > 0$}\\\\\\vspace{-0.3 cm } \\\\",
    "\\displaystyle{\\mathbb{e}}\\big [ d_\\alpha ( f(\\cdot|x ) , f_{\\theta}(\\cdot|x))\\big ] - { \\mathbb{e}}\\big[\\log f(y|x)\\big ]      & \\mbox { , $ \\alpha = 0 $ }   \\end{array }   \\right.\\end{aligned}\\ ] ] and @xmath134 has a minimum value at @xmath97 almost surely , @xmath131 becomes @xmath97 . for @xmath135",
    "$ ] , denote by @xmath136 the contaminated distribution of the form : @xmath137 where @xmath138 has all its mass at the point @xmath139 .",
    "then , the functional @xmath140 satisfies the following equation : @xmath141 hence , taking the derivative of the lhs of the above equation w.r.t . @xmath142 and putting @xmath143 , the influence function of @xmath144 at @xmath129 is obtained as @xmath145 using ( [ l3.3a ] ) , ( [ l3.3b ] ) , ( [ p1.0 ] ) and lemma [ l.3 ] in appendix , we have the following result .",
    "[ p2 ] assume that @xmath63 is compact and @xmath50 is differentiable w.r.t .",
    "@xmath90 for all @xmath41 . under the cases of [ nt ] and",
    "[ ne ] , we have that for @xmath85 and @xmath37 , @xmath146 where @xmath93 is a constant free from @xmath147 and @xmath90 .",
    "the proposition states that the influence function of the mdpd estimator with @xmath85 using ( [ nt ] ) or ( [ ne ] ) is bounded in @xmath148 regardless of the form of @xmath50 and the boundness in @xmath149 is determined by the boundness of @xmath150 .",
    "hence , examining @xmath151 , one can see whether the influence function of the estimator is bounded or not .",
    "for instance , if the input vector @xmath126 is assumed to be finite as mentioned in remark 4 , the continuity of @xmath150 yields @xmath152 which means that the mdpd estimator with @xmath85 has a finite gross error sensitivity . the case of @xmath153",
    "satisfies the condition .    on the other hand ,",
    "the influence function of the qml estimator is unbounded in @xmath148 .",
    "to see this , note that @xmath154 . using the notations in ( [ deriv : nt ] ) and ( [ deriv : ne ] ) , we have that under the case of [ nt ] , @xmath155 and under the case of [ ne ] , @xmath156 one can readily check that each of the above two equations contains unbounded terms .",
    "for instance , @xmath157 and @xmath158 include @xmath159 and @xmath160 , respectively , which are obviously unbounded in @xmath148 .",
    "thus , we have @xmath161 therefore , we can conclude that the mdpd estimator with @xmath85 has a robust property while the qml estimator does not .",
    "choosing an optimal @xmath32 is an important issue in empirical studies . taking a rather conservative approach , a small @xmath32",
    "is recommended because too a large @xmath32 may result in a significant loss in efficiency when the portion of outliers is not very large , as speculated .",
    "several studies on the problem are found in the literature .",
    "warwick and jones ( 2005 ) proposed a selection rule for @xmath32 that minimizes the asymptotic estimation of the mean squared error .",
    "fujisawa and eguchi ( 2006 ) proposed an adaptive method based on an empirical approximation of the cramer - von mises divergence .",
    "durio and isaia ( 2011 ) considered a data - driven method based on the similarity measure between the mdpd estimate and the ml estimate .    in our real data analysis",
    ", we employ the procedure of durio and isaia ( 2011 ) to select an optimal @xmath162 . more specifically ,",
    "suppose that a sample @xmath163 is observed from a regression model @xmath164 , where @xmath165 and the variance of @xmath142 is @xmath166",
    ". then , let @xmath167 and @xmath168 be two regression estimators for @xmath90 .",
    "now , we wish to choose one of the two estimators . to do so , durio and isaia ( 2011 ) proposed the following normalized index to measure the similarity between two estimates , say @xmath169 and @xmath170 . letting @xmath171\\times\\cdots\\times [ \\min x_{ip},\\max x_{ip}],\\\\ c&=&i^p \\times [ \\min y_i , \\max y_i],\\\\ d&=&\\{(x , y ) : \\min(m_{\\hat{\\beta}_{t_0}}(x ) , m_{\\hat{\\beta}_{t_1}}(x ) ) \\leq y \\leq \\max(m_{\\hat{\\beta}_{t_0}}(x ) , m_{\\hat{\\beta}_{t_1}}(x ) ) , x\\in i^p\\ } \\cap c,\\end{aligned}\\ ] ] the similarity index",
    "is defined by @xmath172 if two estimates @xmath169 and @xmath170 are close , then @xmath173 will be close to zero . in order to investigate whether @xmath169 and @xmath170 are close , they used the simplified monte carlo significance ( mcs ) test based on the above statistics .",
    "that is , after generating @xmath174 bootstrap samples of size @xmath175 , @xmath176 is calculated for each bootstrap sample to obtain a critical value . here",
    ", bootstrap sample @xmath177 is sampled from @xmath178 , where @xmath179 is generated from a specified distribution with mean zero and variance @xmath180 .",
    "if @xmath173 is less than the maximum value of @xmath176 , we accept the null hypothesis ( @xmath181 ) of @xmath182 at a significance level of @xmath183 , and conclude that @xmath169 and @xmath170 are close .",
    "this test can be used to check for outliers .",
    "for example , if @xmath167 is the ml estimator and @xmath168 is a robust estimator , accepting @xmath181 means that no outlier is detected and , therefore , we select the ml estimate owing to its efficiency . based on this , the procedure for selecting @xmath162 is as follows :    1 .   in order to check for the existence of outliers , conduct the simplified mcs test with the ml estimator ( @xmath167 ) and the mdpd estimator with @xmath184 ( @xmath168 ) , for some @xmath185 .",
    "if the mcs test leads us to accept @xmath181 , then we decide that outliers are absent and , thus , the ml estimate is selected .",
    "3 .   if not , we again perform the mcs test with the mdpd estimators with @xmath186 ( @xmath167 ) and @xmath184 ( @xmath168 ) , increasing @xmath187 until the first time we can accept @xmath181 .",
    "in this section , we evaluate the finite - sample performance of the mdpd estimator with @xmath85 and compare it with the ml estimator . for this task",
    ", we consider the following model : @xmath188 where @xmath189 , @xmath190 and @xmath191 .",
    "the true parameter vector @xmath192 is considered to be @xmath193 .",
    "we generate 1,000 samples of size @xmath194 and , for each sample , the ml estimates and the mdpd estimates with @xmath195 are obtained .",
    "based on @xmath196 repetitions , the mean , standard deviation ( sd ) , and the sample mean squared error ( mse ) of each estimate are calculated . in order to assess the performance , the following figure is considered : @xmath197 we also estimate the individual te using the estimator proposed by battese and coelli ( 1988 ) , which is based on the ml estimate and the mdpd estimates .",
    "then , we calculate the mse of the estimated tes . that is , @xmath198}:=\\frac{1}{n}\\sum_{i=1}^n\\big(\\hat{te}_i - te_i \\big)^2,\\ ] ] where @xmath199 is the true te given by @xmath200 and @xmath201 is obtained by @xmath202 where @xmath203 and @xmath204 .",
    "now , we compare the performance based on the means of @xmath205 and the @xmath206}$ ] .",
    "= 2.5pt    p0.3cm|p0.55cm|llllll|ll & & & & & & & & + & 4.950 & 5.001 & 1.730 & 1.122 & 0.761 & 0.969 & 0.404 & 0.061 + & ( 0.257/0.069 ) & ( 0.171/0.029 ) & ( 0.311/0.097 ) & ( 0.428/0.184 ) & ( 0.158/0.025 ) & ( 0.445/0.199 ) & [ 1.000 ] & + & 0.05 & 4.956 & 5.001 & 1.733 & 1.130 & 0.760 & 0.973 & 0.399 & 0.058@xmath207 + & & ( 0.245/0.062)@xmath207&(0.171/0.029)@xmath207&(0.307/0.094 ) & ( 0.412/0.170)@xmath207&(0.156/0.024)@xmath207&(0.438/0.193 ) & [ 0.986 ] & + m&0.10 & 4.954 & 5.000 & 1.732 & 1.127 & 0.762 & 0.970 & 0.397 & 0.059 + & & ( 0.248/0.064 ) & ( 0.171/0.029 ) & ( 0.307/0.094)@xmath207 & ( 0.413/0.171 ) & ( 0.156/0.025 ) & ( 0.438/0.192)@xmath207&[0.983]@xmath207 & + d&0.20 & 4.952 & 5.001 & 1.733 & 1.127 & 0.762 & 0.971 & 0.415 & 0.060 + & & ( 0.253/0.066 ) & ( 0.174/0.030 ) & ( 0.317/0.101 ) & ( 0.427/0.183 ) & ( 0.161/0.026 ) & ( 0.453/0.206 ) &",
    "[ 1.026 ] & + p&0.30 & 4.952 & 5.000 & 1.738 & 1.132 & 0.760 & 0.978 & 0.430 & 0.061 + & & ( 0.263/0.071 ) & ( 0.176/0.031 ) & ( 0.330/0.109 ) & ( 0.445/0.198 ) & ( 0.166/0.028 ) & ( 0.469/0.220 ) & [ 1.065 ] & + d&0.50 & 4.945 & 4.999 & 1.743 & 1.137 & 0.758 & 0.985 & 0.481 & 0.066 + & & ( 0.287/0.085 ) & ( 0.184/0.034 ) & ( 0.370/0.137 ) & ( 0.503/0.253 ) & ( 0.183/0.034 ) & ( 0.524/0.274 ) & [ 1.191 ] & + e&0.75 & 4.927 & 4.998 & 1.741 & 1.131 & 0.759 & 0.983 & 0.542 & 0.074 + & & ( 0.323/0.109 ) & ( 0.194/0.038 ) & ( 0.412/0.170 ) & ( 0.580/0.337 ) & ( 0.204/0.042 ) & ( 0.584/0.341 ) & [ 1.341 ] & + & 1.00 & 4.916 & 4.999 & 1.750 & 1.146 & 0.755 & 0.995 & 0.606 & 0.080 + & & ( 0.344/0.125 ) & ( 0.207/0.043 ) & ( 0.453/0.205 ) & ( 0.658/0.433 ) & ( 0.224/0.050 ) & ( 0.646/0.416 ) & [ 1.499 ] & +    first , we deal with the case where the observations are not contaminated by outliers .",
    "the estimation results are reported in table  [ tab1 ] , where the figures marked by the symbol @xmath208 denote the minimal mse , @xmath205 , and @xmath206}$ ] .",
    "it can be seen that the mdpd estimators with @xmath209 and @xmath210 slightly outperform the ml estimator , and the mdpd estimator with @xmath211 performs similarly to the ml estimator .",
    "this is interesting because we had anticipated that the ml estimator would perform best .",
    "nonetheless , we _ could _ expect that the ml estimator would show the best performance as the sample size increases .",
    "the point is that the performance of the mdpd estimator with @xmath32 close to 0 is similar to the ml estimator , and the efficiency of the mdpd estimator decreases with an increase in @xmath162 .",
    "the results in table  [ tab1 ] confirm this finding .",
    "next , we examine the case in which outliers are involved in the observations . for this , we generate two types of contaminated samples .",
    "the first considers upward outliers and is generated as follows : i ) generate the uncontaminated sample @xmath212 from the model  ( [ s1 ] ) , and outliers @xmath213 by @xmath214 where @xmath215 ; ii ) replace @xmath216 observations in @xmath212 by @xmath217 . in the second type of contamination ,",
    "@xmath216 observations in the uncontaminated sample are replaced by @xmath217 , where @xmath215 and @xmath218 , to create downward outliers .",
    "hence , the first sample describes a situation in which some companies or individuals achieve a relatively high efficiency , whereas the second considers low efficiency cases . for the simulation , @xmath219 and @xmath220",
    "are considered .",
    "= 2.5pt    .mean ( sd / mse ) of the estimates , mean of @xmath205 and @xmath206}$ ] when upward outliers exist : @xmath221 .",
    "[ cols= \" < , < , < , < , < , < , < , < , < , < \" , ]         table  [ tab : description ] provides summary statistics , including means , medians , and standard deviations . for all variables ,",
    "the mean value is much larger than the median value and the skewness of the value - added , capital , and labor variables are calculated to be 14.11 , 12.27 , and 12.98 , respectively .",
    "this indicates that the distributions of all variables are severely skewed to the right .",
    "clearly , our data set has some firms that operate with large amounts of inputs and outputs , and some firms operating with very small amounts are also included . in particular , note that a few firms are observed to produce comparatively small output to average production , as depicted in figure  [ cd_scatterplot1 ] , which displays the scatter plot of the pairs of @xmath222 and @xmath223 . in this study",
    ", we emphasize that these low- or high - performing firms could be influential observations , acting like outliers . as demonstrated in our simulation study ,",
    "these are highly likely to have an undesirable effect on the ml estimation , which also affects the te estimate . hence ,",
    "in the next subsection , we estimate the sf model using the qml and mdpd estimation methods .",
    "we also fit the sf model to the data set in which very low- or high - performing firms are removed and compare the results .      in order to investigate the distribution of the technical efficiency scores",
    ", we employ the cobb ",
    "douglas production function assuming constant returns - to - scale .",
    "then , logs of value - added per employee and capital stock per employee ( i.e. , @xmath222 and @xmath223 , respectively ) are considered as augmented output and input variables in the regression model . the production function form with random error @xmath52 and technical inefficiency @xmath53",
    "is given by @xmath224 in this analysis , we consider the normal and the half normal distributions as the pseudo distributions for @xmath56 and @xmath57 , respectively , as in usually done in most empirical studies .",
    "that is , @xmath190 and @xmath191 are assumed and thus the pseudo conditional distribution for ( [ eq : crs - cd ] ) is given by ( [ nh ] ) .",
    "the parameter @xmath225 , where @xmath73 and @xmath226 , is estimated using the qml estimator and the mdpd estimator with @xmath162 between 0.05 and 1 . however , we only report the results corresponding to @xmath162 in @xmath227 because the mdpd estimator with @xmath162 greater than 0.5 produces estimates of @xmath228 close to the boundary .",
    "lrrrrrr & & & & & & + qmle & 7.450(0.125 ) & 0.354(0.010 ) & 0.570(0.014 ) & 1.692(0.075 ) & 0.148 & 0.423 + @xmath229 & 7.303(0.114 ) & 0.363(0.010 ) & 0.463(0.011 ) & 1.508(0.065 ) & 0.141 & 0.322 + @xmath230 & 7.179(0.109 ) & 0.369(0.009 ) & 0.384(0.010 ) & 1.345(0.065 ) & 0.137 & 0.247 + @xmath231 & 7.022(0.107 ) & 0.378(0.009 ) & 0.298(0.011 ) & 1.151(0.079 ) & 0.128 & 0.170 + @xmath232 & 6.929(0.110 ) & 0.382(0.009 ) & 0.250(0.012 ) & 1.010(0.096 ) & 0.124 & 0.126 + @xmath233 & 6.858(0.115 ) & 0.384(0.009 ) & 0.213(0.014 ) & 0.840(0.126 ) & 0.125 & 0.088 + @xmath234 & 6.773(0.133 ) & 0.386(0.010 ) & 0.175(0.019 ) & 0.552(0.233 ) & 0.134 & 0.041 +    table  [ tab : estimation_result_cd1 ] presents the qml and the mdpd estimation results .",
    "the figures in parentheses denote the standard errors .",
    "there are significant differences between the qml estimates and the mdpd estimates .",
    "the estimates of @xmath235 , @xmath166 , and @xmath228 show a decreasing trend as @xmath162 increases , which is similar to the simulation result in which downward outliers exist , as shown in table  [ tab3 ] .",
    "however , the estimates of @xmath236 vary to some extent according to the estimators .",
    "it is important to note that the qml estimator produces a relatively large estimate of @xmath237 .",
    "the scatter plot of observations and the estimated frontier lines are displayed in figure  [ cd_scatterplot1 ] .",
    "the dashed and solid lines represent the frontier production function estimated by the qml estimate and the mdpd estimate with @xmath238 , respectively . as shown in the figure , the fact that the dashed line lies over the solid line , along with the estimation results in table  [ tab : estimation_result_cd1 ] , presumably indicates that the data set contains observations acting like downward outliers .",
    "cccc @xmath167 & @xmath173 & @xmath239 & @xmath181 + qmle & 0.04588 & 0.01533 & rej .",
    "+ @xmath229 & 0.03808 & 0.02058 & rej .",
    "+ @xmath230 & 0.03117 & 0.02302 & rej .",
    "+ @xmath231 & 0.02233 & 0.01849 & rej .",
    "+ @xmath232 & 0.01626 & 0.02756 & acc .",
    "+ @xmath233 & 0.01007 & 0.01944 & acc .",
    "+ @xmath234 & 0 & 0 & acc .",
    "+   +    for this reason , we first investigate whether outliers exist . to this end",
    ", we conduct the mcs test procedure introduced in subsection [ subsec : choice - alpha ] at a significance level of 1% , that is the case of @xmath240 . a bootstrap sample , @xmath241 , is generated from @xmath242 , where @xmath243 and @xmath244 .",
    "first , we compare the qml estimator ( @xmath167 ) and the mdpd estimator with @xmath245 @xmath246 . in this case , the similarity index , @xmath247 , and the maximum value of @xmath176 are calculated to be 0.046 and 0.015 , respectively . since @xmath247 is larger than the maximum of @xmath176 , we reject the null hypothesis of @xmath248 , signifying that outliers do exist in the data .",
    "next , we repeat the mcs test to select an optimal @xmath162 .",
    "the test results are summarized in table  [ tab : choice_alpha1 ] and show that the optimal value of the tuning parameter corresponds to @xmath238 .",
    "we therefore conclude that the optimal estimate of the cobb  douglas production model should be @xmath249 with @xmath250 and @xmath251 , which corresponds to the mdpd estimate with @xmath238 , and , thus , tes should be calculated using the mdpd estimate .",
    "accordingly , we calculate the tes based on the mdpd estimate with @xmath238 using the battese and coelli ( 1988 ) estimator .",
    "denote by te@xmath252 and te@xmath253 the tes calculated using the qml and mdpd estimates , respectively . for comparison",
    ", we also compute the te@xmath252 ( see figure  [ distribution_of_te_cd1 ] ) . here",
    ", the left panel depicts the estimated densities of te@xmath252 ( black solid line ) and te@xmath254 ( red dashed line ) , and the right panel displays the scatter plot of pairs ( te@xmath254 , te@xmath252 ) . note that the qml estimate yields comparatively lower te scores than does the mdpd estimate , mainly owing to the large estimate of @xmath237 .",
    "this result implies that if we were to rely only on the qml estimate , most of the firms would be measured as performing _",
    "worse _ than they did in reality .",
    "lrrrrrr & & & & & & + qmle & 7.150(0.123 ) & 0.365(0.010 ) & 0.303(0.020 ) & 0.977(0.129 ) & 0.155 & 0.148 + @xmath229 & 7.104(0.119 ) & 0.369(0.010 ) & 0.291(0.019 ) & 0.980(0.122 ) & 0.148 & 0.143 + @xmath230 & 7.059(0.115 ) & 0.372(0.009 ) & 0.279(0.017 ) & 0.979(0.117 ) & 0.142 & 0.137 + @xmath231 & 6.976(0.112 ) & 0.378(0.009 ) & 0.254(0.015 ) & 0.954(0.113 ) & 0.133 & 0.121 + @xmath232 & 6.905(0.112 ) & 0.382(0.009 ) & 0.227(0.014 ) & 0.885(0.122 ) & 0.127 & 0.100 + @xmath233 & 6.840(0.118 ) & 0.384(0.009 ) & 0.199(0.016 ) & 0.753(0.152 ) & 0.127 & 0.072 +    cccc @xmath167 & @xmath173 & @xmath239 & @xmath181 + qmle & 0.02321 & 0.06078 & acc .",
    "+ @xmath229 & 0.02146 & 0.02222 & acc .",
    "+ @xmath230 & 0.01949 & 0.03080 & acc .",
    "+ @xmath231 & 0.01475 & 0.03812 & acc .",
    "+ @xmath232 & 0.00859 & 0.02283 & acc .",
    "+ @xmath233 & 0 & 0 & acc .",
    "+   +        finally , in order to illustrate the behaviors of the qml estimator and the mdpd estimator in the absence of very low- or high - performing firms , we additionally estimate the model ( [ eq : crs - cd ] ) based on the data set in which such observations are removed . to get the cleaned data",
    ", we run an ols regression with @xmath255 , and then just eliminate in the original data the firms of which absolute value of the studentized residual is larger than 3 .",
    "the cleaned data and the estimated frontier lines are depicted in figure  [ cd_scatterplot2 ] , in which we can see that a few high- and several low - performing firms are removed .",
    "the estimation results are reported in table [ tab : estimation_result_cd2 ] .",
    "compared with the figures in table [ tab : estimation_result_cd1 ] , it can be seen that differences between the qml estimate and the mdpd estimates become comparatively small .",
    "this is consistent with the results of the mcs tests shown in table [ tab : choice alpha2 ] , where the test results indicate that all the estimates under consideration are close and outliers are absent .",
    "the behavior of the mdpd estimates with small @xmath162 is observed to be similar to that of the qml estimates .",
    "based on these results , the model with the qml estimate would be optimal if one can validate that @xmath56 and @xmath57 follow the normal and the half - normal distributions , respectively .",
    "for the moment , we do not , however , assert the qml estimate as the best one because it is not easy to check out the distributional assumptions . in the present case , we emphasize that the choice of @xmath162 is not crucial because the qml estimate and the mdpd estimates show similar results in such cases , not making a significant difference between te@xmath252 and te@xmath253 . as can be seen in figure [ distribution_of_te_cd2 ] , the qml estimate and the mdpd estimate with @xmath238 yield similar tes comparing with those in figure [ distribution_of_te_cd1 ] .    in summary ,",
    "our data analysis strongly suggest that the mdpd estimator can be a promising estimator for the sfa framework in the the presence of very low- or high- performing firms .",
    "as mentioned earlier , the choice of an optimal @xmath162 is an important issue particularly when outliers are suspected in the data .",
    "while we introduced the procedure of durio and isaia ( 2011 ) as the selection rule , the implementation of the procedure could be computationally burdensome , especially when considering many explanatory variables .",
    "for other statistical models , as mentioned in subsection  [ subsec : minim - dens - power ] , existing studies have found that the mdpd estimator with a small @xmath162 is robust enough against outliers , while maintaining efficiency , when there are no outliers .",
    "thus , based on previous studies and results of our simulation and empirical studies , we recommend values of @xmath162 in @xmath256 $ ] in situations in which selecting an optimal @xmath162 is difficult .",
    "this study has proposed a robust estimation method for stochastic frontier models .",
    "our robust estimator is constructed by minimizing the empirical version of the density power divergence introduced by basu et al .",
    "in particular , the conditional density of the normal  truncated normal(or exponential ) sf model is used in constructing the mdpd estimator regardless of the distributions of @xmath56 and @xmath57 , and its asymptotic and robust properties are investigated .",
    "the selection rule of an optimal @xmath162 is also introduced , adapting the procedure of durio and isaia ( 2011 ) .",
    "our simulation results indicate that the ml estimator is severely compromised by outliers .",
    "in contrast , the mdpd estimator with a small @xmath162 shows strong robustness against outliers , with little loss in asymptotic efficiency relative to the ml estimator .",
    "therefore , the proposed mdpd estimation method can be used when outliers are suspected to contaminate data .",
    "we also apply the estimation method to a real data set having very low- or high - performing observations to illustrate the behaviors of the qml and the mdpd estimators .",
    "our empirical study suggests that the estimator could be suitable for the case in which a few observations perform uniquely well or poorly , as often occurs in empirical studies .",
    "although we focus on a cross - sectional model , the estimation method can be extended to general sf models including panel models .",
    "we leave this extension as possible areas of future research .",
    "in this appendix , we provide proofs for the theorems and propositions stated in subsections [ subsec : asym - prop - mdpd ] and [ subsec : influence - ftn ] . + * proof of theorem  [ t1 ] * + first , note that by assumption * a2 * , @xmath257 = \\iint h_{\\alpha}(x , y;\\theta)f(y|x)f_x(x)dydx\\\\ & & \\hspace{2.4cm}={\\mathbb{e}}\\big [ d_\\alpha ( f(\\cdot|x ) , f_{\\theta}(\\cdot|x))\\big]-\\iint \\frac{1}{\\alpha}f^{1+{\\alpha}}(y|x)f_x(x)dydx\\end{aligned}\\ ] ] and @xmath258 $ ] has a minimum at @xmath97 . in order to show the consistency of the mdpd estimator , it is therefore necessary to derive the strong uniform convergence of the objective function .",
    "that is , @xmath259\\right|\\   \\stackrel{a.s.}{\\longrightarrow } \\ 0,\\end{aligned}\\ ] ] which in turn implies that @xmath260.\\ ] ] while there are several sets of conditions to guarantee ( [ a1 ] ) , we employ the following regularity conditions : ( _ i _ ) @xmath63 is compact ; ( _ ii _ ) @xmath261 is continuous in @xmath75 , for all @xmath262 ; and ( _ iii _ ) @xmath263 is dominated by an integrable random variable that is free from @xmath75 ( see , for example , chapter 16 in ferguson , 1996 ) . here",
    ", it is readily to see that ( _ ii _ ) holds by the continuity of @xmath50 .",
    "also , in view of assumption * a4 * , we have @xmath264 and @xmath265 for notational convenience .",
    "further , we shall use the relation @xmath266 , where @xmath267 and @xmath268 are nonnegative , to denote that @xmath269 for some constant @xmath270 .",
    "for example , @xmath271 means that @xmath267 is bounded by some constant @xmath93 .",
    "since @xmath274 $ ] is finite by assumption * a7 * , following the argument similar to that used in lemma a2 in ling and mcaleer ( 2010 ) , for any @xmath275 , we can take a @xmath276 such that @xmath277\\big\\}\\big\\| \\geq \\epsilon \\right)=0,\\end{aligned}\\ ] ] where @xmath278 .",
    "in addition , since @xmath272 converges almost surely to @xmath97 , we also have that for any @xmath275 , @xmath279 using this and ( [ l2 ] ) , we have @xmath280\\big\\}\\big\\| \\geq \\epsilon \\right)\\\\ & & \\hspace{-0.5cm}\\leq p\\left ( \\max_{n\\geq l } \\|\\tilde{\\theta}_{{\\alpha},n } -\\theta^*_{\\alpha}\\| \\geq \\eta_\\epsilon",
    "\\right ) + p\\left ( \\max_{n\\geq l } \\|\\tilde{\\theta}_{{\\alpha},n } -\\theta^*_{\\alpha}\\| \\leq \\eta_\\epsilon , \\max_{n\\geq l } \\frac{1}{n } \\big\\|\\sum_{i=1}^n \\big\\{{\\partial } ^2_{\\theta \\theta^t } h_i ( \\tilde{\\theta}_{{\\alpha},n } ) -{\\mathbb{e}}\\big [ { \\partial } ^2_{\\theta \\theta^t } h_i(\\theta^*_{\\alpha})\\big]\\big\\}\\big\\| \\geq \\epsilon \\right)\\\\ & & \\hspace{-0.5cm}\\leq p\\left ( \\max_{n\\geq l } \\|\\tilde{\\theta}_{{\\alpha},n } -\\theta^*_{\\alpha}\\| \\geq \\eta_\\epsilon \\right ) + p \\left ( \\max_{n\\geq l } \\sup_{\\theta \\in v_0 ( \\eta_\\epsilon)}\\frac{1}{n } \\big\\|\\sum_{i=1}^n \\big\\{{\\partial } ^2_{\\theta \\theta^t } h_i ( \\theta ) -{\\mathbb{e}}\\big [ { \\partial } ^2_{\\theta \\theta^t } h_i(\\theta^*_{\\alpha})\\big]\\big\\}\\big\\| \\geq \\epsilon \\right)\\\\ & & \\hspace{-0.5cm}\\stackrel{a.s.}{\\longrightarrow}\\ 0,\\end{aligned}\\ ] ] which asserts ( [ l1 ] ) .",
    "* proof of theorem  [ t2 ] * + note that @xmath281= { \\mathbb{e}}\\big[{\\partial_\\theta } d_{\\alpha}(f(\\cdot|x),f_{\\theta^*_{\\alpha}}(\\cdot|x))\\big]=0 $ ] . since @xmath282 $ ] is finite by assumption * a6 * and @xmath283 is a sequence of i.i.d .",
    "random vectors , it follows from the multivariate central limit theorem that @xmath284 applying taylor s expansion to @xmath285 , we have @xmath286 where @xmath272 lies between @xmath287 and @xmath97 .",
    "therefore , theorem  [ t2 ] is asserted from lemma  [ l.1 ] and  ( [ a2 ] ) .",
    "+ we now present derivatives of the pseudo conditional densities stated in subsection [ subsec : mdpd - estim - stoch ] and some lemmas to verify proposition [ p1 ]",
    ". + @xmath288 derivatives of ( [ nt ] ) + letting @xmath289 by simple calculation , we can show that @xmath290 where @xmath291              due to the compactness of @xmath63 , @xmath307 is bounded away from zero and @xmath308 is bounded above ( see , remark 2 ) . thus , using lemma [ l.2 ] , we have @xmath309 since @xmath310 and @xmath311 given in ( [ a3 ] ) and ( [ a4 ] ) , respectively , are continuous and @xmath63 is compact , @xmath310 and @xmath311 are bounded below and above .",
    "thus , it is readily shown that @xmath312 using this and lemma [ l.2 ] , we can show that @xmath313 which together with ( [ l3.3 ] ) implies ( [ l3.1 ] ) .",
    "we next derive an upper bound of the second derivatives .",
    "since @xmath63 is compact and @xmath314 we have @xmath315 and @xmath316 hence , using these and a similar method as for ( [ l3.3 ] ) , we have that @xmath317 furthermore , noting that @xmath318 we can show @xmath319 by a simple calculation , it is straightforward to show that @xmath320 , where @xmath321 , is dominated by a polynomial function of @xmath322 and @xmath323 .",
    "thus , in a similar fashion to the above , we can verify that @xmath324 combining ( [ l3.4])([l3.6 ] ) , we establish ( [ l3.2 ] ) .",
    "* proof of proposition  [ p1 ] * + note that @xmath325 then , we have @xmath326 and thus , by ( [ l3.1 ] ) , @xmath327 next , it follows from ( [ l3.1 ] ) that @xmath328 using this and ( [ l3.2 ] ) , we have @xmath329 hence , the proposition follows from ( [ p1.1 ] ) and ( [ p1.2 ] ) . +",
    "* references *                      jondrow , j. , lovell , c. a. k. , materove , i. s. and schmidt , p. ( 1982 ) . on the estimation of technical inefficiency in the stochastic frontier production function model .",
    "_ journal of econometrics _ , * 19 * , 233 - 238 ."
  ],
  "abstract_text": [
    "<S> this study proposes a robust estimator for stochastic frontier models by integrating the idea of basu et al . [ 1998 , biometrika 85 , 549 - 559 ] into such models . </S>",
    "<S> we verify that the suggested estimator is strongly consistent and asymptotic normal under regularity conditions and investigate robust properties . </S>",
    "<S> we use a simulation study to demonstrate that the estimator has strong robust properties with little loss in asymptotic efficiency relative to the maximum likelihood estimator . </S>",
    "<S> a real data analysis is performed for illustrating the use of the estimator .    * keywords * stochastic frontier model ; outliers ; robustness ; minimum density power divergence estimator + * jel classification * c13 ; d24 </S>"
  ]
}