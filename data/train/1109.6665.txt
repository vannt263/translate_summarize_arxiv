{
  "article_text": [
    "reference @xcite introduced the notion of a side information `` vending machine '' . to illustrate the idea ,",
    "consider the setting in fig .",
    "[ fig : fig0 ] , as studied in @xcite . here ,",
    "unlike the conventional wyner - ziv set - up ( see , e.g. , ( * ? ? ?",
    "* chapter 12 ) ) , the joint distribution of the side information @xmath0 available at the decoder ( node 2 ) and of the source @xmath1 observed at the encoder ( node 1 ) is not given .",
    "instead , it can be controlled through the selection of an `` action '' @xmath2 , so that , for a given action @xmath2 and source symbol @xmath1 , the side information @xmath0 is distributed according to a given conditional distribution @xmath3 action @xmath2 is selected by the decoder based on the message @xmath4 , of @xmath5 bits per source symbol , received from the encoder , and is subject to a cost constraint .",
    "the latter limits the `` quality '' of the side information that can be collected by the decoder .",
    "the source coding problem with a vending machine provides a useful model for scenarios in which acquiring data as side information is costly and thus should be done effectively .",
    "examples include computer networks , in which data must be obtained from remote data bases , and sensor networks , where data is acquired via measurements .",
    "the key aspect of this model is that the message @xmath4 produced by the encoder plays a double role .",
    "in fact , on the one hand , it needs to carry the description of the source @xmath1 itself , as in , e.g. , the standard wyner - ziv model . on the other hand",
    ", it can also carry _ control _ information aimed at enabling the decoder to make an appropriate selection of action @xmath6 the goal of such a selection is to obtain a side information @xmath0 that is better suited to provide partial information about the source @xmath1 to the decoder .",
    "this in turn can potentially reduce the rate @xmath5 necessary for the decoder to reconstruct source @xmath1 at a given distortion level ( or , vice versa , to reduce the distortion level for a given rate @xmath5 ) .    the performance of the system in fig .",
    "[ fig : fig0 ] is expressed in terms of the interplay among three metrics , namely the rate @xmath5 , the cost budget @xmath7 on the action @xmath8  and the distortion @xmath9 of the reconstruction @xmath10 at the decoder .",
    "this trade - off is summarized by the _ rate - distortion - cost _ function @xmath11 this function characterizes the infimum of all rates @xmath5 for which a distortion level @xmath9 can be achieved under an action cost budget @xmath12 by allowing encoding of an arbitrary number @xmath13 of source symbols @xmath14 this function is derived in @xcite for both cases in which the side information @xmath0 is available `` non - causally '' to the decoder , as in the standard wyner - ziv model , or `` causally '' , as introduced in @xcite . in the former case ( fig .",
    "[ fig : fig0]-(a ) ) , the estimated sequence @xmath15 is a function of message @xmath4 and of the entire side information sequence @xmath16 , while , in the latter ( fig .",
    "[ fig : fig0]-(b ) ) , each estimated sample @xmath17 is a function of message @xmath4 and the side information as received up to time @xmath18 , i.e. , @xmath19 for @xmath20 .",
    "we note that the model with causal side information is appropriate , for instance , when there are delay constraints on the reproduction at the decoder or when the decoder operates by filtering the side information sequence .",
    "we refer to ( * ? ? ?",
    "* ; * ? ? ?",
    "* sec i ) for an extensive discussion on these points .",
    "following reference @xcite , recent works @xcite and @xcite generalized the characterization of the rate - distortion - cost function for the models in fig .",
    "[ fig : fig0 ] to a set - up analogous to the so called kaspi - heegard - berger problem @xcite@xcite , in which the side information vending machine may or may not be available at the decoder .",
    "this entails the presence of _ two decoders _ , rather than only one as in fig .",
    "[ fig : fig0 ] , one with access to the vending machine and one without any side information .",
    "reference @xcite also solved the more general case in which both decoders have access to the same vending machine , and either the side informations produced by the vending machine at the two decoders satisfy a degradedness condition , or lossless source reconstructions are required at the decoders .",
    "the papers @xcite@xcite studied the setting of fig . [ fig : fig0 ] but under the additional constraints of common reconstruction , in the sense of @xcite , in @xcite , and of secrecy with respect to an `` eavesdropping '' node in @xcite , providing characterizations of the corresponding achievable performance .",
    "the impact of actions that adapt to the previously measured samples of the side information is studied in @xcite .",
    "finally , real - time constraints are investigated in @xcite .      in this paper , we study two multi - terminal extensions of the set - up in fig .",
    "[ fig : fig0 ] , namely the _ distributed source coding _ setting of fig .",
    "[ fig : fig1 ] , and the _ cascade _ model of fig . [ fig : fig3 ] .",
    "the analysis of these scenarios is motivated by the observation that they constitute key components of computer and sensor networks .",
    "in fact , as discussed above , an important aspect of these networks is the need to effectively acquire side information data , which can be modeled by including a side information vending machine .",
    "we overview the two extensions and the corresponding main results below .",
    "\\1 ) _ distributed source coding with a side information vending machine _ ( sec . [",
    "sec : distsc ] ) : in the distributed source coding setting of fig .",
    "[ fig : fig1 ] , _ two encoders _ ( node 1 and node 2 ) _ , _ which measure correlated sources",
    "_ _ @xmath21 _ _ and @xmath22 _ _ , _ _ respectively , communicate over rate - limited links , of rates @xmath23 and @xmath24 , respectively , to a single decoder ( node 3 ) .",
    "the decoder has side information @xmath0 on sources @xmath21 and @xmath25 which can be controlled through an action @xmath6 the action sequence is selected by the decoder based on the messages @xmath26 and @xmath27 received from node 1 and node 2 , respectively , and needs to satisfy a cost constraint of @xmath7 .",
    "inner bounds are derived to the rate - distortion - cost region @xmath28 under non - causal and causal side information by combining the strategies proposed in @xcite with the berger - tung strategy @xcite and its extension to the wyner - ziv set - up @xcite .",
    "these bounds are shown to be tight under specific assumptions , including the scenario where the sequence observed by one of the nodes is a function of the source observed by the other and the side information is available causally at the decoder .",
    "\\2 ) _ cascade source coding with a side information vending machine _",
    "( sec . [ sec : cascadesc ] ) : * * in the cascade model of fig .",
    "[ fig : fig3 ] , node 1 is connected via a rate - limited link , of rate @xmath29 , to node 2 , which is in turn communicates with node 3 with rate @xmath30 .",
    "source @xmath21 is measured by node 1 and the correlated source @xmath22 by both node 1 and node 2 .",
    "similarly to the distributed coding setting described above , node 3 has side information @xmath0 on sources @xmath21 and @xmath25 which can be controlled via an action @xmath2 .",
    "action @xmath2 is selected by node 3 based on the message received from node 2 and needs to satisfy a cost constraint of @xmath31 we derive the set @xmath32 of all achievable rates ( @xmath33 ) for given distortion constraints ( @xmath34 on the reconstructions @xmath35 and @xmath36 at node 2 and node 3 , respectively , and for cost constraint @xmath31 this characterization is obtained under the assumption that the side information @xmath0 be available causally at node 3 .",
    "it is mentioned that , following the submission of this work , the analysis of the case with non - causal side information at node 3 was carried out in @xcite .    _ notation _ : for @xmath37 integer with @xmath38 , we define @xmath39 $ ] as the interval @xmath40 $ ] and @xmath41 ; if instead @xmath42 we set @xmath39=\\emptyset$ ] and @xmath43 .",
    "we will also write @xmath44 for @xmath45 for simplicity of notation .",
    "random variables are denoted with capital letters and corresponding values with lowercase letters .",
    "given random variables , or more generally vectors , @xmath1 and @xmath46 we will use the notation @xmath47 or @xmath48 for @xmath49 $ ] , and @xmath50 or @xmath51 for @xmath52 $ ] ,        where the latter notations are used when the meaning is clear from the context .",
    "given set @xmath53 , we define as @xmath54 the @xmath13-fold cartesian product of @xmath53 .",
    "function @xmath55 represents the kronecker delta function , i.e. , @xmath56 if @xmath57 and @xmath58 otherwise .",
    "in this section , we first detail the system model for the problem of distributed source coding with a side information vending machine in sec .",
    "[ model_general ] .",
    "then , we propose an achievable strategy in sec . [ sub : achievable - strategy ] for both the cases with non - causal and causal side information at the decoder . in sec . [",
    "sec : xy , y - causal ] and sec .",
    "[ sec : distsc - x , y - noncausal - lossy - lossless ] scenarios are discussed in which the achievable strategies match given outer bounds .",
    "a numerical example is then developed in sec .",
    "[ example ] .",
    "the problem of distributed lossy source coding with a vending machine and non - causal side information is illustrated in fig .",
    "[ fig : fig1 ] .",
    "it is defined by the probability mass functions ( pmfs ) @xmath59 and @xmath60 and discrete alphabets @xmath61 as follows .",
    "the source sequences @xmath62 and @xmath63 with @xmath64 and @xmath65 , respectively , are such that the tuples @xmath66 for @xmath67 $ ] are independent identically distributed ( i.i.d . ) with joint pmf @xmath59 .",
    "node 1 measures sequences @xmath62 and encodes it into message @xmath26 of @xmath68 bits , while node 2 measures sequences @xmath63 and encodes it into message @xmath27 of @xmath69 bits .",
    "node 3 wishes to reconstruct the two sources within given distortion requirements , to be discussed below , as @xmath70 and @xmath71 .    to this end",
    ", node 3 selects an action sequence @xmath72 where @xmath73 based on the messages @xmath26 and @xmath27 received from node 1 and node 2 , respectively .",
    "the side information sequence @xmath74 is then realized as the output of a memoryless channel with inputs ( @xmath75 ) . specifically , given @xmath76 , @xmath62 and @xmath63 , the sequence @xmath74 is distributed as @xmath77 the overall cost of an action sequence @xmath78 is defined by a per - symbol cost function @xmath79 : @xmath80 $ ] with @xmath81 as @xmath82 the estimated sequences @xmath83 and @xmath84 are obtained as a function of both messages @xmath26 and @xmath27 and of the side information @xmath0 .",
    "the estimates @xmath83 and @xmath84 are constrained to satisfy distortion constraints defined by two per - symbol distortion measures , namely @xmath85 : @xmath86 $ ] for @xmath87 with @xmath88 . based on such scalar measures , the overall distortion for the estimated sequences @xmath89 and @xmath90 is defined as @xmath91 note that , based on ( [ eq : per - letter ] ) , the estimate @xmath92 @xmath93 can be required to be a lossy version of an arbitrary ( per - letter ) function of both sources @xmath62 and @xmath63 and of the side information sequence @xmath74 .",
    "a formal description of the operations at encoders and decoder , and of cost and distortion constraints , is presented below for both the cases in which the side information is available causally or non - causally at the decoder .",
    "[ def1]an @xmath94 code for the case of _ non - casual _ side information at node 3 consists of two source encoders @xmath95,\\nonumber \\\\ \\text{and } \\mathrm{g}_{2 } & \\text{:}\\text { } \\mathcal{x}_{2}^{n}\\rightarrow[1,2^{nr_{2}}],\\end{aligned}\\ ] ] which map the sequences @xmath62 and @xmath63 into messages @xmath26 and @xmath27 at node 1 and node 2 , respectively ; an  action  function @xmath96\\times[1,2^{nr_{2}}]\\rightarrow\\mathcal{a}^{n},\\label{action enc}\\ ] ] which maps the message @xmath97 into an action sequence @xmath76 at node 3 ; and two decoding functions @xmath98\\times[1,2^{nr_{2}}]\\times{\\cal y}^{n}\\rightarrow\\mathcal{\\hat{x}}_{1}^{n},\\label{eq : dec1_nc}\\\\ \\text{and } \\mathrm{h}_{2 } & \\text{:}\\text { } [ 1,2^{nr_{1}}]\\times[1,2^{nr_{2}}]\\times{\\cal y}^{n}\\rightarrow\\mathcal{x}_{2}^{n},\\label{eq : dec2_nc}\\end{aligned}\\ ] ] which map the messages @xmath26 and @xmath27 , and the side information sequence @xmath74 into the estimated sequences @xmath83 and @xmath84 at node 3 ; such that the action cost constraint @xmath7 is satisfied as @xmath99\\leq\\gamma,\\label{action_cost_const}\\ ] ] and the distortion constraints @xmath100 and @xmath101 hold , namely @xmath102 & \\leq d_{j},\\mbox { for } j=1,2.\\label{eq : dist_const}\\end{aligned}\\ ] ]    [ def1_c ] a @xmath94 code for the case of _ causal _ side information at node 3 is as in definition [ def1 ] with the only difference that , in lieu of ( 6)-(7 ) , we have the sequence of decoding functions @xmath103\\times[1,2^{nr_{2}}]\\times{\\cal y}^{i}\\rightarrow\\mathcal{\\hat{x}}_{1i},\\label{eq : dec1_c}\\\\ \\text{and } \\mathrm{h}_{2i } & \\text{:}\\text { } [ 1,2^{nr_{1}}]\\times[1,2^{nr_{2}}]\\times{\\cal y}^{i}\\rightarrow\\mathcal{x}_{2i},\\label{eq : dec2_c}\\end{aligned}\\ ] ] for @xmath67 $ ] , which map the message @xmath97 and the measured sequence @xmath104 into the @xmath18th estimated symbol @xmath105 for @xmath87 at node 3 .",
    "[ def2]given a distortion - cost tuple @xmath106 , a rate pair @xmath107 is said to be achievable for the case with non - causal or causal side information if , for any @xmath108 and sufficiently large @xmath13 , there exists a corresponding @xmath109 code .",
    "[ def3]the _ rate - distortion - cost region _",
    "@xmath110 is defined as the closure of all rate pairs @xmath107 that are achievable with non - causal side information given the distortion - cost tuple @xmath106 .",
    "the rate - distortion - cost region @xmath111 is similarly defined for the case of casual side information .      in this section ,",
    "we obtain inner bounds to the rate - distortion - cost regions for the cases with non - causal and causal side information .",
    "[ prop : ach_nc ] the rate - distortion - cost region with non - causal side information at node 3 satisfies the inclusion @xmath112 , where the region @xmath113 is given by the union of the set of all of rate tuples @xmath107 that satisfy the inequalities _ _    _ [ dsc_ach_reg_nc ] _",
    "@xmath114 for some joint pmfs that factorizes as    @xmath115    with pmfs @xmath116 and @xmath117 and @xmath118 and deterministic functions @xmath119 , @xmath120 for @xmath87 , such that the action and the distortion constraints    [ dsc_general_const ] @xmath121 & \\leq\\gamma\\label{eq : action_const_ach}\\\\ \\text{and } \\mathrm{e}\\left[d_{j}(x_{1},x_{2},y,\\hat{x}_{j})\\right ] & \\leq d_{j},\\mbox { for } j=1,2,\\label{eq : dist_const_ach}\\end{aligned}\\ ] ]    hold .",
    "finally , any extreme point of the region @xmath113 can be obtained by limiting the cardinalities of the random variables @xmath122 as @xmath123 and @xmath124 , for @xmath87 .    if we set @xmath125 so that the side information is action - independent , proposition [ prop : ach_nc ] reduces to the extension of the berger - tung scheme @xcite to the wyner - ziv set - up studied in ( * ? ? ? * theorem 2 ) . moreover , in the special case in which there is only one encoder , the achievable rate coincides with that derived in ( * ? ? ?",
    "* theorem 1 ) .",
    "the proof of proposition [ prop : ach_nc ] follows easily from standard arguments , and thus it is only briefly discussed here .",
    "the proposed scheme combines the berger - tung distributed source coding strategy @xcite and the distributed wyner - ziv approach proposed in ( * ? ? ?",
    "* theorem ii ) with the layered two - stage coding scheme that is proved to be optimal in @xcite for the special case of a single encoder . throughout the discussion",
    "we neglect the time - sharing variable @xmath126 for simplicity .",
    "this can be handled in the standard way ( see , e.g. , ( * ? ? ?",
    "4.5.3 ) ) . the encoding scheme at node 1 and node 2 multiplexes two descriptions , which are obtained in two encoding stages .",
    "in the first encoding stage , the distributed source coding strategy of @xcite , conventionally referred to as the berger - tung scheme , is adopted by node 1 and node 2 to convey descriptions @xmath127 and @xmath128 , respectively , to node 3 .",
    "in order for the decoder to be able to recover these descriptions the rates @xmath129 and @xmath130 allocated by node 1 and node 2 have to satisfy the conditions @xcite ( * ? ? ?",
    "* chapter 13 )    [ dsc_ach_reg_nc-1 ] @xmath131    having decoded the descriptions @xmath132 , node 3 selects the action sequence @xmath76 as the per - symbol function @xmath133 for @xmath67 $ ] .",
    "node 3 thus measures the side information sequence @xmath74 .",
    "the sequences @xmath134 can then be regarded as side information available at the decoder .",
    "therefore , in the second encoding stage , the distributed wyner - ziv scheme proposed in ( * ? ? ?",
    "* theorem 2 ) is used to convey the descriptions @xmath135 and @xmath136 by node 1 and node 2 , respectively , to node 3 . note that the fact that sequences @xmath134 are not i.i.d .",
    "does not affect the achievability of the rate region derived in @xcite .",
    "this is because , as shown in ( * ? ? ?",
    "* lemma 3.1 ) , the packing lemma leveraged to ensure the correctness of the decoding process applies for an arbitrary distribution of the sequences @xmath134 . in order for the decoder to correctly retrieve the descriptions @xmath135 and @xmath136 , the rates @xmath137 and @xmath138 allocated by node 1 and node 2 must satisfy the inequalities @xcite    [ dsc_ach_reg_nc-2 ] @xmath139    node 1 and node 2 multiplex the source indices obtained in the two phases and hence the overall rates are @xmath140 and @xmath141 . using these equalities , along with ( [ dsc_ach_reg_nc-1 ] ) and ( [ dsc_ach_reg_nc-2 ] ) , leads to ( [ dsc_ach_reg_nc ] ) . finally , the decoder @xmath142 estimates @xmath92 with @xmath87 sample by sample as a function of @xmath143 and @xmath144 .",
    "the proof of the cardinality bounds follows from standard arguments and is sketched in appendix a. we now turn to a similar achievable strategy for the case with causal side information .    [",
    "prop : ach_c ] the rate - distortion - cost region with causal side information at node 3 satisfies the inclusion @xmath145 , where the region @xmath146 is given by the union of the set of all of rate tuples @xmath107 that satisfy the inequalities _ _    _ [ dsc_ach_reg_c ] _",
    "@xmath147    for some joint pmfs that factorizes as @xmath148 with pmfs @xmath116 , @xmath149 and @xmath150 and deterministic functions @xmath151 and @xmath120 for @xmath87 , such that the action and the distortion constraints ( [ eq : action_const_ach])-([eq : dist_const_ach ] ) hold , respectively .",
    "finally , any extreme point in the region @xmath152 can be obtained by constraining the cardinalities of random variables @xmath153 as @xmath154 and @xmath155 .",
    "the proof follows by similar arguments as the ones in the proof of proposition [ prop : ach_nc ] with the only difference that only one stage of encoding is sufficient .",
    "specifically , as in proposition [ prop : ach_nc ] , berger - tung coding is adopted to convey the descriptions @xmath135 and @xmath136 to node 3 .",
    "note that , with causal side information , there is no advantage in having a second encoding stage , since the side information sequence can not be leveraged for binning in contrast to the case with non - causal side information @xcite ( * ? ? ?",
    "* chapter 12 ) .",
    "the cardinality bounds follow from arguments similar to appendix a.      in this section , we consider the special case in which the sequence observed by node 2 is a symbol - by - symbol function of the source observed at node 1 ( * ? ? ?",
    "v. ) ( see also @xcite ) . in other words , we can write @xmath156 for @xmath67 $ ] , where @xmath157 is an i.i.d . sequence independent of @xmath63 .",
    "we refer to this set - up as having _ degraded source sets_. moreover , we assume that the side information @xmath0 is available causally at node 3 .",
    "the next proposition proves that the achievable strategy of proposition [ prop : ach_c ] is optimal in this case .",
    "[ prop : dsc_opt1 ] the rate - distortion - cost region @xmath111 for the set - up with degraded source sets and with causal side information at node 3 satisfies @xmath158 .",
    "proposition 3 generalizes to the case with action - dependent side information the result in ( * ? ? ?",
    "v ) for the case with no side information .    for the proof of converse , we refer the reader to appendix b.      in this section , we consider a variation on the set - up of source coding with action - dependent non - causal side information described in definition [ def1 ] .",
    "specifically , node 3 selects the action sequence @xmath76 based only on the message @xmath26 received from node 1 . in other words ,",
    "the action function ( [ action enc ] ) is modified to @xmath96\\rightarrow\\mathcal{a}^{n},\\label{action enc-1}\\ ] ] which maps the message @xmath26 into an action sequence @xmath76 at node 3 .",
    "this may be the case in scenarios in which there is a hierarchy between node 1 and node 2 , e.g. , in a sensor network , and the functionality of remote control of the side information is assigned solely to node 1 .",
    "the next proposition characterizes the rate - distortion - cost function @xmath159 under the mentioned assumption when hamming distortion is selected for @xmath36 .",
    "that is , we choose the distortion measure @xmath160 as @xmath161 if @xmath162 and @xmath163 otherwise .",
    "this implies that we impose the constraint of vanishingly small per - symbol hamming distortion between source @xmath63 and estimate @xmath84 , or equivalently the constraint @xmath164\\rightarrow0 $ ] for @xmath165 .",
    "we will refer to this assumption by saying that source sequence @xmath63 must be recovered losslessly at the decoder .",
    "[ prop : dsc_opt2]if the action function is given by ( [ action enc-1 ] ) and @xmath63 must be recovered losslessly at node 3 , the _ _ rate - distortion - cost _ _ _ _ _ _ region _ _ _ _ @xmath159 is given by union of the set of all of rate tuples @xmath107 that satisfy the inequalities    [ dsc_opt2 ] @xmath166 for some joint pmfs that factorizes as    @xmath167    with pmfs @xmath116 and @xmath168 and deterministic function @xmath169 , such that the action and the distortion constraints    [ dsc_opt2_const ] @xmath121 & \\leq & \\gamma\\label{eq : action_const_opt2}\\\\ \\text{and } \\mathrm{e}\\left[d_{1}(x_{1},x_{2},y,\\hat{x}_{1})\\right ] & \\leq & d_{1}\\label{eq : dist_const_opt2}\\end{aligned}\\ ] ]    hold .",
    "finally , @xmath126 and @xmath170 are auxiliary random variables whose alphabet cardinality can be constrained as @xmath171 and @xmath172 without loss of optimality .",
    "in the case in which there is no side information , proposition [ prop : dsc_opt2 ] reduces to ( * ? ? ?",
    "* theorem 1 ) .    for the proof of converse ,",
    "we refer the reader to appendix c. the achievability follows from proposition [ prop : ach_nc ] by setting @xmath173 , @xmath174 and @xmath175 .",
    "extension of the result in proposition to an arbitrary number @xmath176 of encoders can be found in @xcite .",
    "we now focus on a specific numerical example in order to illustrate the result derived in proposition [ prop : ach_nc ] and proposition [ prop : dsc_opt2 ] and the advantage of selecting actions at node 3 based on the message received from one of the nodes .",
    "specifically , we assume that all alphabets are binary and that ( @xmath177 is a doubly symmetric binary source ( dsbs ) characterized by probability @xmath178 with @xmath179 , so that @xmath180 for @xmath181 and @xmath182=p$ ] .",
    "moreover , we adopt hamming distortion for both sources to reconstruct both @xmath21 and @xmath22 losslessly in the sense discussed above .",
    "note that , this implies that we set @xmath183 and @xmath184 the side information @xmath144 is such that @xmath185 where @xmath186 is a deterministic function to be specified .",
    "therefore , when action @xmath187 is selected , then @xmath188 is measured at the receiver , while  with @xmath189 no useful information is collected by the decoder .",
    "the action sequence @xmath76 must satisfy the cost constraint ( [ action_cost_const ] ) , where the cost function is defined as @xmath190 if @xmath187 and @xmath191 if @xmath189 .",
    "it follows that , given ( [ ex ] ) , a cost @xmath7 implies that the decoder can observe @xmath192 only for at most @xmath193 symbols . as for the function @xmath194 we consider two cases , namely @xmath195 where @xmath196 is the binary sum and @xmath197 , where @xmath198 is the binary product .",
    "we assume that the side information is available non - causally at the decoder .    to start with , observe that the sum - rate is a non - increasing function of the action cost @xmath7 and hence the minimum sum - rate is obtained when @xmath199 . with @xmath200",
    "it is clearly optimal to set @xmath201 irrespective of the value of @xmath21 . in this case , from the slepian - wolf theorem , the sum rate equals @xmath202 .",
    "specifically , with sum side information we get @xmath203 since we have @xmath204 where the second equality follows from the chain rule and the second from the crypto - lemma ( * ? ? ?",
    "* lemma 2 ) . instead , with product side information , we obtain @xmath205 where we have used the definition @xmath206 equation ( [ sumrate_pro1 ] ) follows since @xmath207,\\label{sumrate_pro21}\\end{aligned}\\ ] ] where the second equality is a consequence of the fact that @xmath208 implies that @xmath209 and @xmath210 sum - rate ( [ sumrate_pro1 ] ) is then obtained by evaluating ( [ sumrate_pro21 ] ) for the dsbs at hand .",
    "[ fig : plot3 ]     for sum and product side informations ( @xmath199).,width=392,height=281 ]    shows the sum - rates ( [ sumrate_sum1 ] ) and ( [ sumrate_pro1 ] ) , demonstrating that , if @xmath211 is sufficiently small , namely if @xmath212 we have @xmath213 and thus product side information is more informative than the sum , while for @xmath214 the opposite is true ( and for @xmath215 they are equally informative ) .     for product side information ( @xmath216).,width=412,height=297 ]     for sum side information ( @xmath217).,width=412,height=297 ]    considering a general cost budget @xmath218 , in order to emphasize the role of both data and control information for the system performance , we now evaluate the sum - rate attainable by imposing that the action @xmath2 be selected by node 3 a priori , that is , without any control from node 1 .",
    "this can be easily seen to be given by @xcite @xmath219 this sum - rate will be compared below with the performance of the scheme in proposition [ prop : ach_nc ] , in which the actions are selected based on both messages @xmath97 , and that of proposition [ prop : dsc_opt2 ] , in which the actions are selected based only on message @xmath26 .",
    "[ fig : plot4_new ] depicts the mentioned sum - rates is calculated by assuming binary auxiliary variables @xmath220 and @xmath221 and performing global optimization . ] versus the action cost @xmath7 for @xmath216 and product side information .",
    "it can be seen that the greedy approach suffers from a significant performance loss with respect to the approaches in which actions are selected based on the messages received from one encoder or both encoders .",
    "it can be also observed that no gains are obtained by selecting the actions based on both messages .",
    "the fact that choosing the action based on the message received from node 1 provides performance benefits can be explained as follows . if @xmath222 the value of the side information is always @xmath223 irrespective of the value of @xmath224 therefore , if @xmath222 the side information is less informative than if @xmath209 and hence it may be advantageous to save on the action cost by setting @xmath225 consequently , choosing actions based on the message received from node 1 can result in a lower sum - rate .",
    "the scenario with sum side information is considered in fig .",
    "[ fig : plot5_new ] for @xmath217 .",
    "a first observation is that , as proved in appendix d , choosing the action based only on @xmath26 can not improve the sum - rate with respect to the greedy case .",
    "this contrasts with the product side information case , and is due to the fact that @xmath21 is independent of the side information @xmath0 .",
    "instead , choosing the actions based on both messages allows to save on the necessary communication sum - rate .",
    "in this section , we first describe the system model for the setting of fig . [",
    "fig : fig3 ] of cascade source coding with a side information vending machine .",
    "we recall that side information @xmath0  is here assumed to be available causally at the decoder ( node 3 ) . the corresponding model with non - causal side information",
    "is studied in @xcite .",
    "we then present the characterization of the corresponding rate - distortion - cost performance in sec .",
    "[ rate_dist_cost_cascade ] .      the problem of cascade lossy computing with causal observation costs at second user , illustrated in fig .",
    "[ fig : fig3 ] , is defined by the pmfs @xmath59 and @xmath60 and discrete alphabets @xmath226 as follows .",
    "the source sequences @xmath62 and @xmath63 with @xmath64 and @xmath65 , respectively@xmath227 are such that the pairs @xmath66 for @xmath67 $ ] are i.i.d . with joint pmf @xmath59 .",
    "node 1 measures sequences @xmath62 and @xmath63 and encodes them in a message @xmath228 of @xmath229 bits , which is delivered to node 2 .",
    "node 2 estimates a sequence @xmath70 within given distortion requirements to be discussed below .",
    "moreover , node 2 encodes the message @xmath228 , received from node 1 , and the locally available sequence @xmath63 in a message @xmath230 of @xmath231 bits , which is delivered to node 3 .",
    "node 3 wishes to estimate a sequence @xmath71 within given distortion requirements to be discussed . to this end",
    ", node 3 receives message @xmath230 and based on this , selects an action sequence @xmath72 where @xmath232 the action sequence affects the quality of the measurement @xmath74 of sequence @xmath62 and @xmath63 obtained at the node 3 .",
    "specifically , given @xmath76 , @xmath62 and @xmath63 , the sequence @xmath74 is distributed as in ( [ pzxya ] ) .",
    "the cost of the action sequence is defined by a cost function @xmath79 : @xmath80 $ ] with @xmath81 as in ( [ overall_cost ] ) . the estimated sequence @xmath84 with @xmath71",
    "is then obtained as a function of @xmath230 and @xmath74 .",
    "estimated sequences @xmath92 for @xmath87 must satisfy distortion constraints defined by functions @xmath85 : @xmath233 $ ] with @xmath88 for @xmath234 respectively .",
    "a formal description of the operations at encoder and decoder follows .",
    "[ def1_cascade]an @xmath235 code for the set - up of fig .",
    "[ fig : fig3 ] consists of two source encoders , namely @xmath236,\\label{encoder1}\\ ] ] which maps the sequences @xmath62 and @xmath63 into a message @xmath237 @xmath238\\rightarrow[1,2^{nr_{23}}]\\label{encoder2}\\ ] ] which maps the sequence @xmath63 and message @xmath228 into a message @xmath239 an  action  function @xmath240\\rightarrow\\mathcal{a}^{n},\\label{action_fun}\\ ] ] which maps the message @xmath230 into an action sequence @xmath241 a decoding function @xmath242\\times\\mathcal{x}_{2}^{n}\\rightarrow\\mathcal{\\hat{x}}_{1}^{n},\\label{decoder1}\\ ] ] which maps the message @xmath228 and the measured sequence @xmath63 into the estimated sequence @xmath243 and a sequence of decoding functions @xmath244\\times\\mathcal{y}^{i}\\rightarrow\\mathcal{\\hat{x}}_{2},\\label{decoder2}\\ ] ] for @xmath67 $ ] which maps the message @xmath230 and the measured sequence @xmath104 into the @xmath18th estimated symbol @xmath245 such that the action cost constraint @xmath7 and distortion constraints @xmath246 for @xmath87 are satisfied , i.e. , @xmath247 & \\leq\\gamma\\label{action cost}\\\\ \\text { and } \\frac{1}{n}\\underset{i=1}{\\overset{n}{\\sum}}\\mathrm{e}\\left[d_{j}(x_{1i},x_{2i},y_{i},\\hat{x}_{ji})\\right ] & \\leq d_{j}\\text { for } j=1,2,\\label{dist const}\\end{aligned}\\ ] ] respectively .",
    "[ def2_cascade]given a distortion - cost tuple @xmath106 , a rate tuple @xmath248 is said to be achievable if , for any @xmath108 , and sufficiently large @xmath13 , there exists a @xmath249 code .",
    "the _ rate - distortion - cost region _",
    "@xmath32 is defined as the closure of all rate tuples @xmath248 that are achievable given the distortion - cost tuple @xmath106 .    for side information @xmath0 independent of the action",
    "@xmath2 given @xmath21 and @xmath25 i.e. , for @xmath250 the rate - distortion region @xmath32 has been derived in @xcite .",
    "we have the following characterization of the rate - distortion - cost region .",
    "[ prop:3 ] the rate - distortion - cost region @xmath32 for the set - up of fig .",
    "[ fig : fig3 ] is given by the union of all rate pairs ( @xmath33 ) satisfying the inequalities    [ reg_cascade ] @xmath251 for some joint pmf that factorizes as    @xmath252    with pmf @xmath253 and deterministic function @xmath254 , such that the action and the distortion constraints @xmath121 & \\leq\\gamma\\label{action_cascade}\\\\ \\text{and } \\mathrm{e}[d_{j}(x_{1},x_{2},y,\\hat{x}_{j } ) ] & \\leq d_{j},\\text{for } j=1,2,\\label{dist_cascade}\\end{aligned}\\ ] ] respectively , hold .",
    "finally , @xmath255 is an auxiliary random variable whose alphabet cardinality can be constrained as @xmath256 , without loss of optimality .    if @xmath125 proposition [ prop:3 ] reduces to (",
    "* theorem 1 ) .",
    "the proof of converse is provided in appendix e. the coding strategy that proves achievability is a combination of the techniques proposed in @xcite and ( * ? ? ?",
    "* theorem 1 ) . here",
    "we briefly outline the main ideas , since the technical details follow from standard arguments . in the scheme at hand ,",
    "node 1 first maps sequences @xmath62 and @xmath63 into the action sequence @xmath76 and an auxiliary codeword @xmath257 using the standard joint typicality criterion .",
    "this mapping operation requires a codebook of rate @xmath258 ( see , e.g. , ( * ? ? ?",
    "* chapter 3))@xmath259 then , given the so obtained sequences @xmath76 and @xmath260 source sequences @xmath62 and @xmath63 are further mapped into the estimate @xmath83 for node 2 so that the sequences @xmath261 are jointly typical .",
    "this requires rate @xmath262 ( * ? ? ?",
    "* chapter 3)@xmath259 leveraging the side information @xmath63 available at node 2 , conveying the codewords @xmath72 @xmath83 and @xmath257 to node 2 requires rate @xmath263 ( * ? ? ?",
    "* chapter 12)@xmath227 which equals the right - hand side of ( [ reg1_1 ] ) .",
    "node 2 conveys @xmath257 and @xmath76 to node 3 by simply forwarding the index received from node 1  ( of rate @xmath258 ) .",
    "finally , node 3 estimates @xmath84 through a symbol - by - symbol function as @xmath264 for @xmath67.$ ]",
    "in the setting of source coding with a side information vending machine introduced in @xcite , the decoder can control the quality of the side information through a control , or action , sequence that is selected based on the message encoded by the source node .",
    "since this message must also carry information directly related to the source to be reproduced at the decoder , a key aspect of the model is the interplay between encoding data and control information .    in this work ,",
    "we have generalized the original work @xcite to two standard multiterminal scenarios , namely distributed source coding and cascade source coding .",
    "for the former , we obtained inner bounds to the rate - distortion - cost regions for the cases with non - causal and causal side information at the decoder .",
    "these bounds have been found to be tight in two special cases .",
    "we have also provided some numerical example to shed some light on the advantages of an optimized trade - off between data and control transmission . as for the cascade source coding problem",
    ", a single - letter characterizations of achievable rate - distortion - cost trade - offs has been derived under the assumption of causal side information at the decoder .",
    "a number of open problems have been left unsolved by this work , including the identification of more general conditions under which the inner bounds of proposition 1 and proposition 2 are tight .",
    "the technical challenges that we have faced in this task are related to the well - known issues that arise when identifying auxiliary random variables that satisfy the desired markov chain conditions in distributed source coding problems ( see , e.g. , ( * ? ? ?",
    "* chapter 13 ) ) .",
    "using standard inequalities , it can be seen that the rate region ( [ dsc_ach_reg_nc ] ) evaluated with a constant @xmath126 is a contra - polymatroid , as the berger - tung region ( [ dsc_ach_reg_c ] ) ( see e.g. , @xcite ) . moreover , the role of the variable @xmath126 is that of performing the convexification of the union of all regions of tuples @xmath265 that satisfy ( [ dsc_ach_reg_nc ] ) and ( [ dsc_general_const ] ) for some fixed @xmath126 .",
    "it follows from @xcite that every extreme point of region of achievable tuples @xmath265 satisfies the equations    [ vertex1 ] @xmath266    along with ( [ dsc_general_const ] ) , where both relationships are satisfied with equality , or    [ vertex2 ] @xmath267    along with ( [ dsc_general_const ] ) satisfied with equality .",
    "applying the fenchel  eggleston ",
    "caratheodory theorem to the right - hand side of the equations above and to ( [ dsc_general_const ] ) concludes the proof ( see ( * ? ? ?",
    "* appendix c ) and @xcite ) .",
    "in this section , the proof of converse for proposition [ prop : dsc_opt1 ] is given .",
    "for any @xmath109 code , we have the following inequalities :      where ( _ a _ ) follows because @xmath26 is a function of @xmath269 given that @xmath63 is a function of @xmath62 by assumption ; ( @xmath270 ) follows since @xmath271forms a markov chain ; ( @xmath272 ) follows by the fact that conditioning decreases entropy ; and @xmath273 follows by defining @xmath274 for @xmath87 .",
    "we also have a similar chain of inequalities for @xmath24 . as for the sum - rate @xmath275",
    ", we have @xmath276 where ( _ a _ ) follows because @xmath97 are functions of @xmath269 ; ( @xmath270 ) follows since @xmath277 @xmath278 forms a markov chain ; and ( @xmath272 ) follows using the definition of @xmath279 for @xmath87 .",
    "next , let @xmath126 be a uniform random variable over the interval @xmath280 $ ] and independent of @xmath281 and define @xmath282 , for @xmath87 , @xmath283 , @xmath284 , @xmath285 .",
    "note that @xmath286 is a function of @xmath287 and @xmath0 for @xmath87 .",
    "moreover , from ( [ action_cost_const ] ) and ( [ eq : dist_const ] ) , we have @xmath288=\\mathrm{e}[\\lambda(a)]\\\\ \\text{and } d_{j}+\\epsilon & \\geq\\frac{1}{n}\\underset{i=1}{\\overset{n}{\\sum}}\\mathrm{e}\\left[d_{j}(x_{1i},x_{2i},y_{i}.\\hat{x}_{ji},)\\right]=\\mathrm{e}[d_{1}(x_{1},x_{2},y,\\hat{x}_{j})],\\mbox { for } j=1,2.\\end{aligned}\\ ] ]      in this section , the proof of converse for proposition [ prop : dsc_opt2 ] is given .",
    "fix a code @xmath289 for an @xmath108 , whose existence for all sufficiently large @xmath13 is required by the definition of achievability .    from the distortion constraint for @xmath36",
    ", we have the inequality @xmath290\\overset{(a)}{=}\\frac{1}{n}\\overset{n}{\\underset{i=1}{\\sum}}p_{e,2i},\\label{error}\\ ] ] where we have defined @xmath291,$ ] and ( _ a _ ) follows from the definition of the metric @xmath292 as the hamming distortion@xmath259 moreover , we also have the following chain of inequalities @xmath293 where ( _ a _ ) follows by conditioning reduces entropy ; ( _ b _ ) follows by fano s inequality ; ( _ c _ ) follows by jensen s inequality ; and ( _ d _ ) follows by ( [ error ] ) , where @xmath294 as @xmath295 note that , in the following , we use the convention in ( * ? ? ? * chapter 3 ) of defining as @xmath296 any function such that @xmath294 as @xmath295    for rate @xmath23 , we then have the following series of inequalities @xmath297 where ( _ a _ ) follows because @xmath76 is a function of @xmath26 and ( _ b _ ) follows because entropy is non - negative and conditioning decreases entropy .",
    "for the first three terms in ( [ eq3 ] ) we have @xmath298 where ( _ a _ ) follows by the chain rule for entropy and the fact that @xmath299 are i.i.d .",
    "and ( _ b _ ) follows since @xmath144@xmath300@xmath301 forms a markov chain , by the definition of problem , and since conditioning reduces entropy .    combining ( [ eq3 ] ) and ( [ eq4 ] ) , and defining @xmath302 we obtain @xmath303 where ( _ a _ ) follows by the chain rule for entropy ; ( _ b _ ) follows",
    "because mutual information is non - negative and due to the fact that conditioning decreases entropy ; and ( _ c _ ) follows by the definition of mutual information and definition of @xmath304 .    next , we consider the rate @xmath305 we have @xmath306 where ( _ a _ ) follows because from ( [ error1 ] ) , @xmath307 , given that @xmath84 is a function of @xmath308 @xmath27 and @xmath74and ( @xmath270 ) follows using the definition of @xmath304 and due to the fact that conditioning decreases entropy .",
    "for the sum - rate @xmath275 , we also have the following series of inequalities @xmath309 where ( _ a _ ) follows because @xmath76 is a function of @xmath26 ; and ( _ b _ ) follows as in ( @xmath310 ) of ( [ r2_conv_opt2 ] ) .",
    "for the first three terms in ( [ eq3 - 1 ] ) we have @xmath311 + where ( _ a _ ) follows from the chain rule for entropy and by the chain rule for entropy and the fact that @xmath269 are i.i.d . ; and ( _ b _ ) follows since @xmath144@xmath312@xmath301 forms a markov chain , by the definition of problem , and since conditioning reduces entropy . combining ( [ eq3 - 1 ] ) and ( [ eq4 - 1 ] ) , and using the definition of @xmath304 , we obtain @xmath313 where ( _ a _ ) follows by the chain rule for entropy ; ( _ b _ ) follows because mutual information is non - negative and due to the fact that conditioning decreases entropy ; and ( _ c _ ) follows by the definition of mutual information and definition of @xmath304 and the fact that conditioning decreases entropy .",
    "moreover , @xmath314 forms a markov chain .",
    "this can be seen by using the principle of @xmath315-separation ( * ? ? ?",
    "a.9 ) from fig .",
    "[ fig : graph1 ] , which represents the joint distribution of all the variables at hand .",
    "@xmath317 and define @xmath318 , @xmath283 , @xmath284 , @xmath285 , @xmath319 , and @xmath320 note that @xmath35 is a function of @xmath170 and @xmath0 .",
    "moreover , from ( [ action_cost_const ] ) and ( [ eq : dist_const ] ) , we have @xmath288=\\mathrm{e}[\\lambda(a)]\\nonumber \\\\ \\text{and } d_{1}+\\epsilon & \\geq\\frac{1}{n}\\underset{i=1}{\\overset{n}{\\sum}}\\mathrm{e}\\left[d_{1}(x_{1i},x_{2i},y_{i}.\\hat{x}_{1i})\\right]=\\mathrm{e}[d_{1}(x_{1},x_{2},y,\\hat{x}_{1})].\\end{aligned}\\ ] ]    finally , since ( [ r1_conv_opt2 ] ) , ( [ r2_conv_opt2 ] ) and ( [ r1+r2_conv_opt2 ] ) are convex with respect to @xmath168 for fixed @xmath116 , @xmath321 , and @xmath322 , we have that inequalities ( [ dsc_opt2 ] ) hold , which completes the proof of ( [ r1_opt2])-([eq : dist_const_opt2 ] ) .",
    "the cardinality bounds are proved by using the fenchel ",
    "caratheodory theorem in the standard way .      in this section",
    ", we provide the proof of converse for proposition [ prop:3 ] . for any @xmath249 code",
    ", we have the following inequalities : @xmath331 where ( _ a _ ) follows because @xmath230 is a function of ( @xmath228,@xmath332 ; ( _ b _ ) follows by definition of mutual information and since @xmath228 and @xmath230 are functions of @xmath62 and @xmath63 ; ( _ c _ ) follows because @xmath62 and @xmath63 are i.i.d and since @xmath76 is a function of @xmath239 ( _ d _ ) follows because @xmath333 forms a markov chain and since @xmath83 is a function of @xmath228 and @xmath63 ; and ( _ e _ ) follows by defining @xmath334 and since conditioning decreases entropy .",
    "we also have the inequalities @xmath335 where ( _ a _ ) follows because @xmath230 is a function of @xmath62 and @xmath63 ; ( _ b _ ) follows by the definition of mutual information and the chain rule for entropy and since @xmath62 and @xmath63 are i.i.d ; ( _ c _ ) follows because @xmath76 is a function of @xmath230 ; ( _ d _ ) follows because @xmath336 forms a markov chain ; and ( _ e _ ) follows by the definition of @xmath337 .",
    "let @xmath126 be a uniform random variable over @xmath280 $ ] and independent of @xmath338 and define @xmath339 , @xmath283 , @xmath284 , @xmath285 , @xmath319 , @xmath340 and @xmath341 .",
    "note that @xmath36 is a function of @xmath255 and @xmath0 .",
    "moreover , from ( [ action cost ] ) and ( [ dist const ] ) , we have @xmath288=\\mathrm{e}[\\lambda(a)]\\label{action_dist}\\\\ \\text{and } d_{j}+\\epsilon & \\geq\\frac{1}{n}\\underset{i=1}{\\overset{n}{\\sum}}\\mathrm{e}\\left[d_{j}(x_{1i},x_{2i},y_{i},\\hat{x}_{ji})\\right]=\\mathrm{e}[d_{j}(x_{1},x_{2},y,\\hat{x}_{j})]\\text { for } j=1,2.\\end{aligned}\\ ] ]    finally , since ( [ r1 ] ) and ( [ r2 ] ) are convex with respect to @xmath253 for fixed @xmath321 and @xmath322 , we have from ( [ r1 ] ) and ( [ r2 ] ) that inequalities ( [ reg_cascade ] ) hold .",
    "the cardinality bounds are proved by using the fenchelegglestoncaratheodory theorem in the standard way .",
    "b. ahmadi and o. simeone ,  robust coding for lossy computing with receiver - side observation costs ,  in _ proc .",
    "ieee international symposium on information theory _",
    "( isit 2011 ) , pp .",
    "2939 - 2943 , july 31-aug .",
    "5 , saint petersburg , russia , 2011 ( see also arxiv:1108.1535 ) .",
    "y. chia , h. asnani , and t. weissman ,  multi - terminal source coding with action dependent side information ,  in _ proc .",
    "ieee international symposium on information theory _",
    "( isit 2011 ) , pp .",
    "2035 - 2039 , july 31-aug . 5 , saint petersburg , russia , 2011 .",
    "k. kittichokechai , t. j. oechtering and m. skoglund ,  source coding with common reconstruction and action - dependent side information ,  in _ proc .",
    "ieee information theory workshop _ ,",
    "pp . 1 - 5 , dublin , ireland , aug . 2010",
    ".    k. kittichokechai , t. j. oechtering and m. skoglund ,  secure source coding with action - dependent side information ,  in _ proc .",
    "ieee international symposium on information theory _",
    "( isit 2011 ) , pp . 1678 - 1682 , july 31-aug .",
    "5 , saint petersburg , russia , 2011 .",
    "a. b. wagner , b. g. kelly , and y. altug , the lossy one - helper conjecture is false , _ in proc .",
    "allerton conf . on communications , control , and computing _ , pp .",
    "716723 , sept .",
    "2 , monticello , il , 2009 .",
    "g. d. forney jr . ,  on the role of mmse estimation in approaching the information- theoretic limits of linear gaussian channels : shannon meets wiener ,  in _ proc .",
    "allerton conf .",
    "communication , control , and computing _ , monticello , il , pp .",
    "430439 , oct .",
    "chia and t. weissman ,  cascade and triangular source coding with causal side information ,  in _ proc .",
    "ieee international symposium on information theory _",
    "( isit 2011 ) , pp . 16831687 , july 31-aug .",
    "5 , saint petersburg , russia , 2011 .",
    "j. chen , x. zhang , t. berger , and s. b. wicker , an upper bound on the sum rate distortion function and its corresponding rate allocation schemes for the ceo problem , _",
    "ieee j. select .",
    "areas commun .",
    "22 , no . 6 ,",
    "977987 , aug .",
    "which shows that no gain is accrued by choosing the actions based only on message @xmath26 with the sum side information .",
    "fix the pmf @xmath324 that achieves the minimum in the sum - rate obtained from ( [ r1+r2_opt2 ] ) , namely @xmath325 where the mutual information is calculated with respect to the distribution @xmath326 and the minimum is taken over all distributions @xmath324 such that @xmath327=\\mathrm{e}\\left[a\\right]\\leq\\gamma.$ ] note that for such a pmf @xmath324 we have @xmath328=p(a)=\\gamma,$ ] as it can be easily seen .",
    "we then have the following series of equalities : @xmath329 where ( _ a _ ) follows by the definition ( [ rsumgreedy ] ) ; ( _ b _ ) follows using the chain rule for entropy and from the definition of conditional entropy ; ( _ c _ ) follows by the crypto - lemma ( * ? ? ?",
    "* lemma 2 ) ; ( _ d _ ) follows from the fact that @xmath330 forms a markov chain ."
  ],
  "abstract_text": [
    "<S> source coding with a side information `` vending machine '' is a recently proposed framework in which the statistical relationship between the side information and the source , instead of being given and fixed as in the classical wyner - ziv problem , can be controlled by the decoder . </S>",
    "<S> this control action is selected by the decoder based on the message encoded by the source node . unlike conventional settings , the message can thus carry not only information about the source to be reproduced at the decoder , but also control information aimed at improving the quality of the side information .    in this paper , </S>",
    "<S> the analysis of the trade - offs between rate , distortion and cost associated with the control actions is extended from the previously studied point - to - point set - up to two basic multiterminal models . </S>",
    "<S> first , a distributed source coding model is studied , in which two encoders communicate over rate - limited links to a decoder , whose side information can be controlled . </S>",
    "<S> the control actions are selected by the decoder based on the messages encoded by both source nodes . </S>",
    "<S> for this set - up , inner bounds are derived on the rate - distortion - cost region for both cases in which the side information is available causally and non - causally at the decoder . </S>",
    "<S> these bounds are shown to be tight under specific assumptions , including the scenario in which the sequence observed by one of the nodes is a function of the source observed by the other and the side information is available causally at the decoder . </S>",
    "<S> then , a cascade scenario in which three nodes are connected in a cascade and the last node has controllable side information , is also investigated . for this model , the rate - distortion - cost region </S>",
    "<S> is derived for general distortion requirements and under the assumption of causal availability of side information at the last node .    </S>",
    "<S> : distributed source coding , cascade source coding , observation costs , side information , side information vending machine , rate - distortion theory . </S>"
  ]
}