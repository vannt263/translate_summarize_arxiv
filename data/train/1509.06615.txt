{
  "article_text": [
    "dozen years after its unexpected and somewhat serendipitous discoverty , the accelerated expansion of the universe is taken for granted due to the flood of data from different astrophysical probes confirming it ( see , e.g. , @xcite for a not updated yet exhaustive review ) .",
    "although the spatially flat concordance @xmath4cdm model , made out of a cosmological constant accounting for @xmath5 of the energy budget and responsible of the cosmic speed up , is in full agreement with observations ( as summarized , e.g. , in @xcite , where the latest datasets are considered ) , it is far from free of any conceptual and theoretical problems @xcite .",
    "this motivated the search for alternative models generally referred to as dark energy ( de ) ones and characterized by the presence of a scalar field with a negative equation of state ( eos ) denoted as @xmath6 , with @xmath7 the pressure and energy density of this leading component . while a huge number of papers has addressed the problem of what de is with proposal running from self interacting fields to modified gravity theories ( see , e.g. , @xcite for a recent textbook ) , observations are mainly aimed at constraining the de eos . under the simple yet efficient cpl @xcite parameterization",
    ", it is considered @xmath8 , with @xmath9 the scale factor and @xmath10 the redshift , so that the holy grail of observational cosmology has nowadays become to narrow down as much as possible the range for the @xmath11 parameters . as a consequence , the efficacy of an observational probe",
    "is presently quantified in terms of the figure of merit ( fom ) defined as the inverse of the area delimiting the @xmath12 confidence range in the @xmath11 space @xcite .",
    "gravitational lensing has soon been pointed at as one of the most promising tools to investigate the nature of the mysterious de . in its journy from the source to the observer",
    ", the light is deflected by both a dominant mass concentration ( a galaxy or a cluster acting as lens ) along the line of sight and the cumulative effect of the large scale structure . as a consequence , gravitational lensing probe both the background expansion and the growth of structures .",
    "cosmic shear tomography , that is to say the power spectrum of shear as measured from galaxies separated in different redshift bins @xcite , has emerged as one of the most promising tools to constrain the de eos , so motivating the interest in ongoing ( des , kids ) and future ( euclid , lsst ) dedicated surveys . while shear tomography is based on the weak regime of gravitational lensing ( where lensed galaxies are subject to tiny modifications detectable only on statistical grounds ) , also statistics based on strong lensing features",
    "is not less important . in this regime , the light emitted by the source passes close to a massive lens causing the formation of multiple images or spectacular einstein rings or radial and/or tangential arcs .",
    "the distribution of angular separation between double images @xcite , arc statistics @xcite and einstein rings properties @xcite have been used as tools to constrain cosmological parameters and the astrophysical properties of the lens population .",
    "galaxy scale strong lenses have been also proposed as a tool to probe the background expansion .",
    "the basic idea is usually to infer the distance ratio @xmath13 between the angular diameter distance from the lens to the source and from the observer to the source , and then use a sufficiently large sample to trace how this quantity evolves with @xmath10 . to this end ,",
    "one typically relies on measurements of both the einstein radius @xmath14 and the lens velocity dispersion @xmath15 . under the assumption of isothermal sphere",
    ", one gets @xmath16 , so that a measurement of @xmath17 immediately gives the distance ratio @xmath13 provided one sets @xmath18 , being @xmath19 a nuisance parameter to marginalize over @xcite .",
    "although quite simple , such a method however rests on some assumptions which , even if reasonably motivated , should nonetheless be verified .",
    "first , it is assumed that all the lenses can be modelled as singular isothermal sphere .",
    "second , the nuisance parameter @xmath19 is taken as a sort of universal constant , while its actual value can change from one system to another depending on both the lens properties ( redshift , mass , size ) and how @xmath15 is measured ( weighted within a circular aperture of fixed physical radius or through longslit spectroscopy ) . here",
    "we follow a similar approach , but weakening the strong assumptions of the standard approach in order to avoid biasing cosmological parameters because of incorrect lens modelling .",
    "the plan of the paper is as follows . in sect.2 , a step - by - step derivation of the method",
    "is presented underlying which assumptions are made and how we deal with them .",
    "sect.3 is devoted to validate the proposed technique showing that its basic assumptions are well motivated .",
    "we then present , in sect.4 , a fisher matrix analysis to forecast the errors on cosmological parameters for different configurations of future datasets .",
    "a summary of the results and a discussion of future perspectives are given in the concluding sect.5 .",
    "galaxy scale strong lenses are typically used to constrain the dark matter halo and its interplay with the properties of the stellar component . to this end ,",
    "two observational probes are used , namely the projected mass @xmath20 within the einstein radius @xmath14 and the central velocity dispersion @xmath15 . assuming the galaxy may be modelled as the sum of a stellar part modelled with a sersic ( 1968 ) profile and a dark matter halo , we get    @xmath21\\ , ,   \\label{eq : mprojth}\\ ] ]    with @xmath22 the total stellar and virial masses , respectively , and @xmath23 is a dimensionless function depending on the density profile . for the stellar component this reads    @xmath24}{\\gamma(2n)}\\ , , \\label{eq : defmustar}\\ ] ]    with @xmath25 the slope of the sersic model , @xmath26 a constant set so that half of the total luminosity is contained within the effective radius @xmath27 @xcite .",
    "we leave for the moment the @xmath28 function undetermined in order to be as general as possible .    provided that the lens and source redshifts @xmath29",
    "are known , one can get an estimate of the projected mass by simply measuring the einstein radius and then using    @xmath30    where we have used the definition of critical surface density @xmath31 :    @xmath32    being @xmath33 the speed of light and @xmath34 the angular diameter distances to the lens , the source and between lens and source .",
    "note that , in eq.([eq : mprojobs ] ) , @xmath35 is the einstein radius in arcsec since this is the quantity directly measured from the data in a model independent way .",
    "the second quantity of interest is the aperture velocity dispersion , i.e. the velocity dispersion luminosity weighted within a circular aperture of radius @xmath36 .",
    "approximating the deprojected sersic profile with the @xcite model , it turns out that    @xmath37 } \\\\   & \\times & \\frac{{\\cal{i}}_{\\star}(r_{ap } ; n ) + ( m_{vir}/m_{\\star } ) { \\cal{i}}_{dm}(r_{ap } ; n , r_{eff } ; { \\bf p}_{dm } ) } { \\gamma(2n ) - \\gamma[2n , b_n ( r_{ap}/r_{eff})^{1/n } ] } \\nonumber \\ , \\label{eq : sigmaapth}\\end{aligned}\\ ] ]    where @xmath38 is given in @xcite , @xmath39 collectively denotes the halo model parameters , and we refer to @xcite and @xcite for the details of the dimensionless @xmath40 functions . for dimensional reasons it is convenient to define an aperture mass as    @xmath41 } \\\\   & \\times & \\frac{{\\cal{i}}_{\\star}(r_{ap } ; n ) + ( m_{vir}/m_{\\star } ) { \\cal{i}}_{dm}(r_{ap } ; n , r_{eff } ; { \\bf p}_{dm } ) } { \\gamma(2n ) - \\gamma[2n , b_n ( r_{ap}/r_{eff})^{1/n } ] } \\nonumber \\ , \\label{eq : mapth}\\end{aligned}\\ ] ]    which can be straightforwardly estimated from measurable quantities as    @xmath42    with @xmath43 the effective radius in arcsec obtained from the fit to the surface brightness profile .",
    "it is now only a matter of algebra to first solve @xmath44 with respect to @xmath45 and then insert the result into @xmath46 to finally get    @xmath47    which represents the basic relation of our method relating the theoretical distance ratio @xmath48 on the left hand side with the @xmath49 quantities on the right hand side defined as follows    @xmath50}{b_n^{n(3 - p_n ) } } \\nonumber \\\\   & \\times & \\left \\ { 1 - \\frac{\\gamma[2n , b_n ( r_{ap}/r_{eff})^{1/n}]}{\\gamma(2n ) } \\right \\ } \\nonumber \\\\   & \\times & \\left \\{1 - \\frac{\\gamma[n(3 - p_n ) , b_n ( r_{ap}/r_{eff})^{1/n}]}{\\gamma[n(3 - p_n ) ] } \\right \\ } \\ , \\label{eq : defdobs}\\end{aligned}\\ ] ]    @xmath51 } { { \\cal{i}}_{\\star}(r_{ap } ; n ) + ( m_{vir}/m_{\\star } ) { \\cal{i}}_{dm}(r_{ap } ; n , r_{eff } ; { \\bf p}_{dm } ) } \\ . \\label{eq : defcalfe}\\ ] ]    eq.([eq : testeq ] ) is formally similar to the one used in previous similar methods expressing the distance ratio in terms of a quantity depending only on measurable quantities ( given by @xmath52 ) and an unknown nuisance parameter ( referred to as @xmath53 here ) .",
    "however , we improve on the classical approach in two ways . first , we have not assumed the galaxy to be a one component system , but rather modelled it as it actually is , i.e. the sum of a stellar part and a dark matter halo .",
    "second , we have now an analytical expression for the nuisance parameter , so that we can investigate whether it is the same for all lenses or rather it is a function of both the lens properties and the halo model .",
    "to infer the distance ratio from strong lensing data , one generally assumes that the @xmath19 parameter is a constant independent on the lens and marginalizes over it .",
    "this is actually a zero order approximation related to the properties of the assumed singular isothermal sphere model used to describe the total mass density . on the contrary , with our @xmath53 parameter in eq.([eq : defcalfe ] ) we account for the two components nature of the lens and explicitily specify the halo model .",
    "a careful analysis of the different terms entering its definition shows that @xmath53 depends on ( i ) the mass ratio @xmath54 , ( ii ) the length ratio @xmath55 ( with @xmath56 the radius where the dm logarithmic slope equals -2 ) , and ( iii ) the halo concentration provided that the logarithmic slope is not constantly equal to -2 , which is the case for the singular isothermal sphere only . ]",
    "actually , the halo model can be more complex , so that @xmath58 are not enough to fully assign it , and more parameters are needed , which makes @xmath53 depend on them too .",
    "moreover , since the mass and length ratios may both change with the redshift as it is suggested by , e.g. , the redshift dependence of the @xmath59-@xmath60 relation as well as of the @xmath27-@xmath45 scaling law , it turns out that @xmath53 is redshift dependent .",
    "these considerations strongly point against the standard assumption to consider the nuisance parameter as a constant , which implies that one should fit for @xmath53 separately for each lens , hence making the method unusable .",
    "however , a possible way out could be found if @xmath53 was constant within a certain scatter once the lenses were binned according to some suitably chosen properties . to investigate whether this is possible or not",
    ", we proceed as schematically pointed out below .    1 .",
    "we set the lens redshift @xmath61 sampling from a uniform distribution over the range @xmath62 and then set @xmath63 with @xmath64 randomly extracted from the range @xmath65 .",
    "we use the redshift dependent galactic stellar mass function used in @xcite to set the lens stellar mass @xmath45 and sample the effective radius @xmath27 from a gaussian distribution centred on @xmath66 and a @xmath67 scatter .",
    "the estimation of @xmath68 is obtained following @xcite , while the scaling with redshift has been chosen in accordance with @xcite considering the value of @xmath69 for massive galaxies ( @xmath70 ) .",
    "the halo virial mass is set solving the @xmath71 vs @xmath60 relation of @xcite with respect to @xmath60 , so that we can finally fix the concentration sampling from the @xmath59-@xmath60 relation of @xcite , taking also into account its scatter .",
    "+ 4 .   adopting an nfw @xcite model for the dm halo",
    ", we can now compute both the einstein radius @xmath14 and the central velocity dispersion @xmath72 .",
    "we then retain the simulated lens only if its input and output quantities are reasonable . to check whether this is the case",
    ", we compare them to the similar quantities for the slacs @xcite sample of 85 intermediate redshift lenses with well measured values of @xmath73 .    using the above recipe",
    ", we can generate a sample of @xmath74 lenses , with a distribution in @xmath73 similar to those of the real slacs , and confidently use it to investigate how the nuisance parameter , @xmath53 , scales with the lens properties .",
    "moreover , since we are interested more in the distance ratio estimate than in @xmath53 , we wonder what could be the bias on @xmath75 caused by using the mean value @xmath76 , averaged over a subsample of 1000 lenses selected according to a given criterion , instead of @xmath53 . to this end",
    ", we define the distance ratio estimator    @xmath77    and consider the quantity    @xmath78    as a measure of the relative error due to the distance ratio estimate . since @xmath79 is the average value over the lenses in a given bin ( so that we can trace how @xmath80 evolves with the bin centre ) , the question is now which parameter to use as binning quantity .    as a first case",
    ", we consider the most obvious choice and divide the simulated sample in 50 redshift bins .",
    "it turns out that , while @xmath79 increases with @xmath61 , its relative scatter only has a negligible variation , and that the root mean square value is @xmath81 independently of @xmath61 .",
    "moreover , we have verified that , for lenses in the same bin , @xmath80 has a negligible correlation with the source redshift , the lens size and mass , and the halo model parameters .",
    "we repeat this test , binning with respect to the stellar mass , central velocity dispersion , and einstein radius .",
    "we find that we are unable to get satisfactory results . indeed , binning with respect to @xmath82 increases @xmath83 and introduces a significant increase with the stellar mass for @xmath84 , with values going as large as @xmath85 .",
    "similarly large values are obtained when binning with respect to @xmath15 although a definite trend is not found , while binning in @xmath14 introduces an increasing trend for @xmath86 followed by a non monotonic variation leading to @xmath87 ( but the low statistics at large @xmath14 values makes these numbers not fully reliable ) .",
    "we therefore conclude that the estimator ( [ eq : hatd ] ) is reliable , once the lenses are divided in redshift bins . in this case , one can then rely on @xmath88 assuming that the nuisance parameter is the same for all the lenses in the same bin within a percentage scatter of @xmath89 .    to further validate this conclusion ,",
    "we have repeated the full analysis changing the assumptions in the simulation pipeline .",
    "we have indeeed considered a different @xmath59-@xmath60 relation either by adopting the one of @xcite or by changing the halo model from nfw to einasto ( 1965 , 1969 ) profile .",
    "although the @xmath53 values are different , the results on @xmath83 are qualitatively and quantitatively similar .",
    "in particular , we confirm the above conclusion that binning in lens redshift guarantees that @xmath81 independently of the bin centre and the stellar and dm halo properties of the lenses .",
    "in order to investigate whether and under which conditions the method proposed works in constraining the cosmological parameters , we perform a fisher matrix analysis .",
    "the elements of the fisher matrix are given by    @xmath90    being @xmath91 the i - th parameter and @xmath92 the fiducial values .",
    "to define the likelihood function @xmath93 we split the sample in @xmath94 bins and let @xmath95 be the number of lenses in the @xmath96-th bin .",
    "we can compute the likelihood for lenses in this bin as    @xmath97 ^ 2 } \\label{eq : deflikek}\\end{aligned}\\ ] ]    where @xmath98 is the set of cosmological parameters to be constrained , while @xmath99 is the average @xmath53 value for the @xmath100 bin which we marginalize over . in order to compute the likelihood ( and its derivatives ) we need to assign the quantities entering eq.([eq : deflikek ] ) .",
    "the @xmath101 may be easily computed for each lens using eq.([eq : defdobs ] ) ; the errors @xmath102 deserve , on the other hand , some more words .",
    "first of all , @xmath103 is the error on @xmath104 . since we are assuming that @xmath99 is constant , we can then simply write @xmath105 , where a naive propagation of errors is sufficient to get    @xmath106    here @xmath107 are the relative uncertainties on @xmath108 , respectively",
    ". we will make the simplifying assumption that these quantities are the same for all the lenses in a given bin and explore different values for them ( see later ) .",
    "the second term @xmath109 is the systematic error induced by replacing the actual @xmath53 with its average value and can be set as @xmath110 .",
    "based on the simulations described in the previous section , we will set @xmath111 , while @xmath99 is computed by binning the lenses according to the above chosen strategy .",
    "assuming that the lens redshift has been measured with a precision much smaller than the bin width , the total likelihood is simply :    @xmath112    where we collectively denote with @xmath113 the set of @xmath99 values . as a consequence",
    ", the total fisher matrix will be the sum of the fisher matrices for each bin .",
    "it is convenient to first compute the fisher matrix for the @xmath96-th bin , then marginalize over @xmath99 , and finally sum the marginalized matrices to get @xmath114 , i.e. , the total fisher matrix for the cosmological parameters only .      in order to compute the fisher matrix",
    ", some preliminary quantities must be set .",
    "first , we choose the fiducial cosmological model .",
    "we consider three different spatially flat models setting    @xmath115    which we will refer to as @xmath4cdm , quiessence , thawing , respectively .",
    "note that we have used the same matter density parameter for all three models , setting its value to the recent planck estimate although one should change it according to the de eos parameters in order to get the best match to the data .",
    "however , we are here only interested in exploring realistic models so that we do not worry much about the exact value of the parameters .",
    "we nevertheless want to stress that these cases span the range of quintessence models still allowed by the data @xcite .",
    "these parameters assign the dimensionless hubble parameter @xmath116 , reading    @xmath117    which enters the distance ratio given by    @xmath118    with    @xmath119    the comoving distance .",
    "note that eq.([eq : distratio ] ) only holds for spatially flat models .",
    "we also stress that the hubble constant @xmath120 drops out from the ratio of distances thus reducing the number of cosmological parameters .    a key role in determining the accuracy of the constraints",
    "is played by the errors on the observable quantities .",
    "these enters eq.([eq : deflikek ] ) through the statistical term @xmath121 and the systematic one @xmath109 . as already said above , we set @xmath110 , since this is the scatter in the distance ratio introduced by the approximation done when using the estimator @xmath88 instead of the correct one in eq.([eq : testeq ] ) . on the other hand ,",
    "the statistical uncertainty @xmath121 depends on the relative errors on @xmath108 .",
    "we will set @xmath122 as typically found fitting hst - like data on lens surface brightness profile , while we try three different configurations for the uncertainties on the einstein radius and central velocity dispersion , namely    @xmath123    as a final ingredient , we need to set the total number of lenses and the binning .",
    "we consider two cases .",
    "first , we take 1000 lenses splitted in 20 equally spaced bins over the redshift range @xmath62 , while secondly we take 10000 lenses splitted in 50 bins over the same redshift range as improved sample .",
    ".marginalized constraints on @xmath124 for @xmath4cdm , quiessence and tahwing models ( top , centre and bottom part of the table , respectively ) for different sample and error configurations .",
    "the labels @xmath125 and @xmath126 refer to the sample containing 1000 and 10000 lenses , respectively .",
    "we remind the reader that we set @xmath122 for all the cases . [",
    "cols=\"^,^,^,^,^,^\",options=\"header \" , ]     [ tab : fishmatrescst ]      table[tab : fishmatrescst ] and [ tab : fishmatresvar ] summarizes the results of the fisher matrix forecast for different models , sample and error configurations .",
    "first , we consider the simplifying assumption that @xmath127 is known @xcite . ] . while for @xmath4cdm and quiessence models this means that , in a hypothetical fit , we force @xmath128 , in the case of thawing model , one has to set @xmath129 in order to get the correct behaviour @xcite .",
    "the numbers in table[tab : fishmatrescst ] convincingly show that the distance ratio method is quite effective at constraining the cosmological parameters @xmath124 if a prior on @xmath127 is set .",
    "no matter which model is taken as fiducial , we find that 1000 lenses are sufficinet to get @xmath130 and @xmath131 .",
    "increasing the sample by an order of magnitude roughly halves these numbers pointing at a possible saturation of the method accuracy . for fixed model and lens sample ,",
    "it turns out that reducing the error on @xmath15 is a better strategy to improve the constraints since it is more effective at narrow down the error on @xmath132 .",
    "the constraints are basically the same for the three models , although those for the thawing case are consistently smaller .",
    "this can be qualitatively explained noting that , in this case , @xmath132 has a larger impact on the distance ratio thanks to the presence of the exponential term in the dimensionless hubble parameter ( which drops out when @xmath128 is used ) .",
    "although encouraging , these results are based on the strong prior that we know how to set @xmath127 . in a realistic application , however , one only assumes that the de eos is given by the cpl approximation and fits for the three parameters @xmath133 .",
    "the constraints we get are summarized in table[tab : fishmatresvar ] and show a significant degradation with respect to the case with @xmath127 fixed .",
    "while the trends with @xmath134 are qualitatively the same , the number of lenses becomes now of primary importance .",
    "indeed , 10000 rather than 1000 lenses are now needed to get @xmath130 and @xmath135 , while only weak constraints can be put on @xmath127 .",
    "this result can be easily understood looking at the pivot redshift @xmath136 defined as the value of @xmath10 where the errors are uncorrelated .",
    "not surprisingly , we find that @xmath137 no matter which error configuration , lens sample or fiducial model is used .",
    "this is an obvious consequence of the lens redshift distribution which indeed has a median value close to the pivot redshift . as a result ,",
    "the de eos is best constrained at @xmath136 with the error on @xmath138 turning out to becdm , but they are quite similar for other models . ]",
    "@xmath139    from 1000 lenses in the three error configurations and    @xmath140    from 10000 lenses .",
    "these results clearly show that the distance ratio method is better suited at probing the low redshift behaviour of the de eos so that its redshift evolution is hardly probed thus explaining the weak constraints on @xmath127 .",
    "it is interesting to look at the fom of the method .",
    "we get @xmath141 when using 1000 lenses , while it is @xmath142 if 10000 lenses are used .",
    "it is evident that interesting values can only be obtained reducing as much as possible the error on @xmath15 and increasing the lens sample .",
    "we , however , note that the orientation of the @xmath11 ellipses ( see fig,[fig : contplot ] ) , is quite different from other classical methods such as sneia and cmbr thanks to the different pivot redshift .",
    "it is therefore likely that a combination of the distance ratio method with these other probes helps breaking degeneracies thus boosting the total fom .",
    "[ tab : fishmatresvar ]",
    "einstein rings have always attracted a lot of attention not only for their spectacular beauty , but also as a probe of the dark matter content of lens galaxies .",
    "the measurement of both the einstein radius and central velocity dispersion allows to strengthen the constraints on the halo density profile , but can also be used as a way to estimate the ratio between the distance to the source and that between lens and source and hence probe the cosmic expansion .",
    "motivated by the previous literature results , we have proposed a novel approach which , although based on the same idea , ameliorates the estimate of the distance ratio . on one hand ,",
    "we have adopted a realistic two components model for the lens galaxy taking care of both the stellar and dm contributions .",
    "this led us to a general formula which permits to estimate the distance ratio @xmath143 as a function of observable quantities and a nuisance parameter @xmath53 depending on the details of the halo model and the lens parameters .",
    "the analytical formula we derive for @xmath53 has allowed us to show that its value is approximately constant for lenses belonging to the same redshift bin , so that we finally get an approximate estimator which helps us to define a likelihood function for the estimate of cosmological parameters .",
    "it is worth stressing that the method proposed does not depend on the particular halo model adopted or on the details of the @xmath71-@xmath45 and @xmath59-@xmath60 relations adopted .",
    "this is a further improvement with respect to the standard approach which , on the constrary , postulates that all lenses may be described by the singular isothermal sphere",
    ".    a well founded and movitated method to constrain cosmological parameters should be useless if the numbers of tracers and/or the requirements on the uncertainties on the observable quantities are too demanding . to investigate this ,",
    "we have carried on a fisher matrix analysis changing both the number of lenses and the relative errors on @xmath144 .",
    "it turns out that a survey measuring @xmath145 with @xmath146 accuracy for 10000 lenses can get @xmath147 , while @xmath148 constraints on @xmath124 can be obtained with 1000 lenses only if @xmath127 is fixed .",
    "it is therefore worth wondering whether these requirements are realistic . to this end",
    ", we note that present day lenses already achieved @xmath149 and @xmath150 , so that it is not unrealistic to guess that higher quality images ( as can be obtained from future large telescopes and satellite missions ) and improved spectrograph can easily achieve our requirements .",
    "more demanding is the constraint on the total number of lenses . as an example , however , one can note that the euclid mission @xcite is expected to observe up to @xmath151 strong lenses @xcite , so that asking that both @xmath14 and @xmath15 are measured for less than @xmath67 of them is not a too demanding requirement .    although the present day lens samples are far from the numbers explored in our fisher matrix analysis , it could be nevertheless interesting to apply the proposed method to real strong lensing data . @xcite",
    "have recently assembled a catalog of 118 strong lensing systems and used it to constrain the dark energy equation of state under the usual assumption of isothermal sphere model .",
    "we plan to repeat their analysis using our improved approach in order to investigate to which extent the constraints on the cosmological parameters depend on the assumed lens model .",
    "actually , given the small statistics , it is expected that the large errors could prevent a conclusive answer , but such a study can provide a comparison benchmark for an analysis based on simulated samples .",
    "it is worth noting that the results are always somewhat dependent on the lens redshift distribution . here",
    ", we have simulated lens samples in such a way that they grossly reproduce the main features of the slacs dataset since this is the most used catalog at the moment .",
    "however , future datasets can have a different redshift distribution , possibly changing the method fom .",
    "although a more detailed analysis will be carried on in a future work , we can qualitatively anticipate that the pivot redshift will likely be close to the median survey redshift .",
    "it is therefore possible that combining different samples with different median redshifts could help better tracing the de eos over a larger redshift range thus increasing the fom .",
    "note that we are here implicitly assuming that the median redshift of the full lens sample is the same as the median redshift of the subsample with measured values of @xmath152 , which can also not be the case because of selection effects . on the contrary , since not all the lenses contribute to the fom in the same way , it is possible that an optimal strategy can be worked out maximizing the scientific return of the companion spectroscopic survey needed to measure the lenses velocity dispersions .",
    "to this end , one can follow the same methodology presented , for time delay distances , in @xcite .    as a final remark ,",
    "we stress that , even if suboptimal conditions in terms of number of lenses and/or accuracy in the measurement of @xmath145 are achieved , the distance ratio method we have proposed can be efficiently combined with other probes helping to break degeneracies and hence boosting the total fom . should the present results be confirmed by a more detailed analysis of the lens samples properties , new light on dark energy will be shed by the strong regime of gravitational lensing .",
    "vfc is funded by italian space agency ( asi ) through contract euclid - ic ( i/031/10/0 ) and acknowledges financial contribution from the agreement asi / inaf / i/023/12/0 ."
  ],
  "abstract_text": [
    "<S> strong lensing provides popular techniques to investigate the mass distribution of intermediate redshift galaxies , testing galaxy evolution and formation scenarios . </S>",
    "<S> it especially probes the background cosmic expansion , hence constraining cosmological parameters . </S>",
    "<S> the measurement of einstein radii and central velocity dispersions indeed allows to trace the ratio @xmath0 between the distance @xmath1 from the observer to the source and the distance @xmath2 from the lens to the source . </S>",
    "<S> we present an improved method to explicitly include the two - component structure in the galaxy lens modeling , in order to analyze the role played by the redshift and the model dependence on a nuisance parameter,@xmath3 , which is usually marginalized in the cosmological applications . </S>",
    "<S> we show how to deal with these problems and carry on a fisher matrix analysis to infer the accuracy on cosmological parameters achieved by this method .    </S>",
    "<S> gravitational lensing  </S>",
    "<S> cosmology : distances </S>"
  ]
}