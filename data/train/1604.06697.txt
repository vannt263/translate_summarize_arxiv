{
  "article_text": [
    "sorting a sequence of elements of some totally ordered universe remains one of the most fascinating and well - studied topics in computer science .",
    "moreover , it is an essential part of many practical applications .",
    "thus , efficient sorting algorithms directly transfer to a performance gain for many applications .",
    "one of the most widely used sorting algorithms is quicksort , which has been introduced by hoare in 1962  @xcite and is considered to be one of the most efficient sorting algorithms . for sorting an array , it works as follows : first , it chooses an arbitrary pivot element and then rearranges the array such that all elements smaller than the pivot are moved to the left side and all elements larger than the pivot are moved to the right side of the array   this is called _",
    "partitioning_. then , the left and right side are both sorted recursively .",
    "although its average number of comparisons is not optimal  ",
    "@xmath3 vs.  @xmath4 for mergesort   , its over - all instruction count is very low .",
    "moreover , by choosing the pivot element as median of some larger sample , the leading term @xmath5 for the average number of comparisons can be made smaller   even down to @xmath6 when choosing the pivot as median of some sample of growing size  @xcite .",
    "other advantages of quicksort are that it is easy to implement and that it does not need extra memory except the recursion stack of logarithmic size ( even in the worst case if properly implemented ) .",
    "a major drawback of quicksort is its quadratic worst - case running time .",
    "nevertheless , there are efficient ways to circumvent a really bad worst - case .",
    "the most prominent is introsort ( introduced by musser  @xcite ) which is applied in gcc implementation of ` std:\\!:sort ` : as soon as the recursion depth exceeds a certain limit , the algorithm switches to heapsort .",
    "another deficiency of quicksort is that it suffers from branch mispredictions ( or branch misses ) in an essential way . on modern processors with long pipelines ( 14 stages for intel haswell ,",
    "broadwell , skylake processors   for the older pentium 4 processors even more than twice as many ) every branch misprediction causes a rather long interruption of the execution since the pipeline has to be filled anew . in  @xcite , kaligosi and sanders",
    "analyzed the number of branch mispredictions incurred by quicksort .",
    "they examined different simple branch prediction schemes ( static prediction and 1-bit , 2-bit predictors ) and showed that with all of them , quicksort with a random element as pivot causes on average @xmath7 branch mispredictions for some constant @xmath8 ( resp .",
    "@xmath9 , @xmath10 ) .",
    "in particular , in quicksort with random pivot element , every fourth comparison is followed by a mispredicted branch .",
    "the reason is that for partitioning , each element is compared with the pivot and depending on the outcome either it is swapped with some other element or not . since for an optimal pivot ( the median ) , the probability of being smaller the pivot is @xmath11 , there is no way to predict these branches .",
    "kaligosi and sanders also established that choosing skewed pivot elements ( far off the median ) might even decrease the running time because it makes branches more predictable .",
    "this also explains why , although theoretically larger samples for pivot selection were shown to be superior , in practice the median - of three variant turned out to be the best . in @xcite ,",
    "the skewed pivot phenomenon is confirmed experimentally .",
    "moreover , in  @xcite , precise theoretical bounds on the number of branch misses for quicksort are given   establishing also theoretical superiority of skewed pivots under the assumption that branch mispredictions are expensive .",
    "in  @xcite brodal and moruz proved a general lower bound on the number of branch mispredictions given that every comparison is followed by a conditional branch which depends on the outcome of the comparison . in this case",
    "there are @xmath12 branch mispredictions for a sorting algorithm which performs @xmath13 comparisons . as elmasry and",
    "katajainen remarked in  @xcite , this theorem does not hold anymore if the results of comparisons are not used for conditional branches .",
    "indeed , they showed that every program can be transformed into a program which induces only a constant number of branch misses and whose running time is linear in the running time of the original program .",
    "however , this general transformation introduces a huge constant factor overhead .",
    "still , in  @xcite and  @xcite elmasry , katajainen and stenmark showed how to efficiently implement many algorithms related to sorting with only few branch mispredictions .",
    "they call such programs _ lean_. in particular , they present variants of mergesort and quicksort suffering only very little from branch misses .",
    "their quicksort variant ( called tuned quicksort , for details on the implementation , see  @xcite ) is very fast for random permutations   however , it does not behave well with duplicate elements because it applies lomuto s uni - directional partitioner ( see e.g.  @xcite ) .",
    "another development in recent years is multi - pivot quicksort ( i.e.several pivots in each partitioning stage  @xcite ) .",
    "it started with the introduction of yaroslavskiy s dual - pivot quicksort  @xcite   which , surprisingly , was faster than known quicksort variants and , thus , became the standard sorting implementation in oracle java 7 and java 8 .",
    "concerning branch mispredictions all these multi - pivot variants behave essentially like ordinary quicksort  @xcite ; however , they have one advantage : every data element is accessed only a few times ( this is also referred to as the number of _ scans _ ) . as outlined in @xcite , increasing the number of pivot elements further ( up to 127 or 255 ) , leads to super scalar sample sort , which has been introduced by sanders and winkel  @xcite .",
    "super scalar sample sort not only has the advantage of few scans , but also is based on the idea of avoiding conditional branches . indeed , the correct bucket ( the position between two pivot elements ) can be found by converting the results of comparisons to integers and then simply performing integer arithmetic . in their experiments sanders and winkel",
    "show that super scalar sample sort is approximately twice as fast as quicksort ( ` std:\\!:sort ` ) when sorting random integer data .",
    "however , super scalar sample sort has one major draw - back : it uses a linear amount of extra space ( for sorting @xmath2 data elements , it requires space for another @xmath2 data elements and additionally for more than @xmath2 integers ) . in the conclusion of  @xcite , kaligosi and sander",
    "raised the question :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ however , an in - place sorting algorithm that is better than quicksort with skewed pivots is an open problem .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    ( here , in - place means that it needs only a constant or logarithmic amount of extra space . ) in this work , we solve the problem by presenting our block partition algorithm , which allows to implement quicksort without any branch mispredictions incurred by conditional branches based on results of comparisons ( except for the final insertionsort   also there are still conditional branches based on the control - flow , but their amount is relatively small ) .",
    "we call the resulting algorithm blockquicksort .",
    "our work is inspired by tuned quicksort from  @xcite , from where we also borrow parts of our implementation .",
    "the difference is that by doing the partitioning block - wise , we can use hoare s partitioner , which is far better with duplicate elements than lomuto s partitioner ( although tuned quicksort can be made working with duplicates by applying a check for duplicates similar to what we propose for blockquicksort as one of the further improvements in section  [ sec : improvments ] ) .",
    "moreover , blockquicksort is also superior to tuned quicksort for random permutations of integers .",
    "[ [ our - contributions ] ] our contributions    * we present a variant of the partition procedure that only incurs few branch mispredictions by storing results of comparisons in constant size buffers .",
    "* we prove an upper bound of @xmath14 branch mispredictions on average , where @xmath15 for our proposed block size ( theorem  [ thm : few_branches ] ) .",
    "* we propose some improvements over the basic version .",
    "* we implemented our algorithm with an ` stl`-style interface .",
    "* we conduct experiments and compare blockquicksort with ` std:\\!:sort ` , yaroslavskiy s dual - pivot quicksort and super scalar sample sort   on random integer data it is faster than all of these and also katajainen et al.s tuned quicksort .    [",
    "[ outline ] ] outline    section  [ sec : prelims ] introduces some general facts on branch predictors and mispredictions , and gives a short account of standard improvements of quicksort . in section  [ sec : partition ] , we give a precise description of our block partition method and establish our main theoretical result   the bound on the number of branch mispredictions .",
    "finally , in section  [ sec : experiments ] , we experimentally evaluate different block sizes , different pivot selection strategies and compare our implementation with other state of the art implementations of quicksort and super scalar sample sort .",
    "logarithms denoted by @xmath16 are always base 2 .",
    "the term _ average case _ refers to a uniform distribution of all input permutations assuming all elements are different . in the following ` std:\\!:sort`always",
    "refers to its gcc implementation .",
    "[ [ branch - misses ] ] branch misses    branch mispredictions can occur when the code contains conditional jumps ( i.e.  _ if _ statements , loops , etc . ) .",
    "whenever the execution flow reaches such a statement , the processor has to decide in advance which branch to follow and decode the subsequent instructions of that branch .",
    "because of the length of the pipeline of modern microprocessors , a wrong predicted branch causes a large delay since , before continuing the execution , the instructions for the other branch have to be decoded .",
    "[ [ branch - prediction - schemes ] ] branch prediction schemes    precise branch prediction schemes of most modern processors are not disclosed to the public .",
    "however , the simplest schemes suffice to make blockquicksort induce only few mispredictions .",
    "the easiest branch prediction scheme is the _ static predictor _ : for every conditional jump the compiler marks the more likely branch . in particular , that means that for every _ if _ statement , we can assume that there is a misprediction if and only if the _ if _",
    "branch is not taken ; for every _ loop _ statement , there is precisely one misprediction for every time the execution flow reaches that loop : when the execution leaves the loop . for more information about branch prediction schemes",
    ", we refer to ( * ? ? ?",
    "* section 3.3 ) .",
    "[ [ how - to - avoid - conditional - branches ] ] how to avoid conditional branches    the usual implementation of sorting algorithms performs conditional jumps based on the outcome of comparisons of data elements .",
    "there are at least two methods how these conditional jumps can be avoided   both are supported by the hardware of modern processors :    * conditional moves ( ` cmovcc ` instructions on x86 processors )   or , more general , conditional execution . in c++ compilation to a conditional move",
    "can be ( often ) triggered by + ....",
    "i = ( x < y ) ?",
    "j : i ;       .... * cast boolean variables to integer ( ` setcc ` instructions x86 processors ) . in c++ : + ....          int i = ( x < y ) ; ....    also many other instruction sets support these methods ( e.g.  arm @xcite , mips  @xcite ) .",
    "still , the intel architecture optimization reference manual  @xcite advises only to use these instructions to avoid unpredictable branches ( as it is the case for sorting ) since correctly predicted branches are still faster . for more examples how to apply these methods to sorting ,",
    "see @xcite .    [",
    "[ quicksort - and - improvements ] ] quicksort and improvements    the central part of quicksort is the partitioning procedure . given some pivot element , it returns a pointer @xmath17 to an element in the array and rearranges the array such that all elements left of the @xmath17 are smaller or equal the pivot and all elements on the right are greater or equal the pivot .",
    "quicksort first chooses some pivot element , then performs the partitioning , and , finally , recurses on the elements smaller and larger the pivot   see algorithm  [ alg : qs ] .",
    "we call the procedure which organizes the calls to the partitioner the _ quicksort main loop_.    pivot @xmath18 choosepivot(@xmath19 $ ] ) cut @xmath18 partition(@xmath19 $ ] , pivot ) quicksort(@xmath20 $ ] ) quicksort(@xmath21 $ ] )    there are many standard improvements for quicksort . for our optimized quicksort main loop ( which is a modified version of tuned quicksort @xcite ) , we implemented the following :    * a very basic optimization due to sedgewick  @xcite avoids recursion partially ( e.g.  ` std:\\!:sort ` ) or totally ( here   this requires the introduction of an explicit stack ) . *",
    "introsort  @xcite : there is an additional counter for the number of recursion levels .",
    "as soon as it exceeds some bound ( ` std:\\!:sort`uses @xmath22   we use @xmath23 ) , the algorithms stops quicksort and switches to heapsort  @xcite ( only for the respective sub - array ) . by doing so",
    ", a worst - case running time of @xmath24 is guaranteed .",
    "* sedgewick  @xcite also proposed to switch to insertionsort ( see e.g.  ( * ? ? ?",
    "* section 5.2.1 ) ) as soon as the array size is less than some fixed small constant ( 16 for ` std:\\!:sort`and our implementation ) .",
    "there are two possibilities when to apply insertionsort : either during the recursion , when the array size becomes too small , or at the very end after quicksort has finished .",
    "we implemented the first possibility ( in contrast to ` std:\\!:sort ` ) because for sorting integers , it hardly made a difference , but for larger data elements there was a slight speedup ( in  @xcite this was proposed as _ memory - tuned quicksort _ ) . * after partitioning , the pivot is moved to its correct position and not included in the recursive calls ( not applied in ` std:\\!:sort ` ) .",
    "* the basic version of quicksort uses a random or fixed element as pivot .",
    "a slight improvement is to choose the pivot as median of three elements   typically the first , in the middle and the last .",
    "this is applied in ` std:\\!:sort`and many other quicksort implementations .",
    "sedgewick  @xcite already remarked that choosing the pivots from an even larger sample does not provide a significant increase of speed . in view of the experiments with skewed pivots",
    "@xcite , this is no surprise . for blockquicksort ,",
    "a pivot closer to the median turns out to be beneficial ( figure  [ fig : skewed_pivots ] in section  [ sec : skewed ] ) .",
    "thus , it makes sense to invest more time to find a better pivot element . in  @xcite ,",
    "martinez and roura show that the number of comparisons incurred by quicksort is minimal if the pivot element is selected as median of @xmath25 elements .",
    "another variant is to choose the pivot as median of three ( resp .",
    "five ) elements which themselves are medians of of three ( resp .",
    "five ) elements .",
    "we implemented all these variants for our experiments   see section  [ sec : pivot_experiments ] .",
    "our main contribution is the block partitioner , which we describe in the next section .",
    "the idea of block partitioning is quite simple . recall how hoare s original partition procedure works ( algorithm  [ alg : hoare ] ) :     @xmath26 < \\mathrm{pivot}$ ]  @xmath27   @xmath28 > \\mathrm{pivot}$ ]  @xmath29   @xmath30   swap(@xmath26 , a[r]$ ] ) ; @xmath27 ; @xmath29   @xmath31    two pointers start at the leftmost and rightmost elements of the array and move towards the middle . in every step the current element is compared to the pivot ( line 3 and 4 ) . if some element on the right side is less or equal the pivot ( resp .",
    "some element on the left side is greater or equal ) , the respective pointer stops and the two elements found this way are swapped ( line 5 ) .",
    "then the pointers continue moving towards the middle .",
    "the idea of blockquicksort ( algorithm  [ alg : partition ] ) is to separate lines 3 and 4 of algorithm  [ alg : hoare ] from line 5 : fix some block size @xmath32 ; we introduce two buffers @xmath33 $ ] and @xmath34 $ ] for storing pointers to elements ( @xmath35 will store pointers to elements on the left side of the array which are greater or equal than the pivot element   likewise @xmath36 for the right side ) .",
    "the main loop of algorithm  [ alg : partition ] consists of two stages : the scanning phase ( lines 5 to 18 ) and the rearrangement phase ( lines 19 to 26 ) .",
    "* integer*@xmath37 , \\mathrm{offsets}_r[0 , \\dots , { \\ensuremath{b}\\xspace}- 1]$ ] * integer*@xmath38 @xmath39 @xmath40 \\gets i$ ] @xmath41 ) $ ] @xmath42 @xmath43 \\gets i$ ] @xmath44 ) $ ] * integer*num @xmath45 swap(@xmath46\\bigr ] , a\\bigl[r- \\mathrm{offsets}_r[\\mathrm{start}_r + j]\\bigr]$ ] ) @xmath47 ; @xmath48  @xmath49  @xmath50   @xmath51  @xmath52   compare and rearrange remaining elements    like for classical hoare partition , we also start with two pointers ( or indices as in the pseudocode ) to the leftmost and rightmost element of the array .",
    "first , the scanning phase takes place : the buffers which are empty are refilled . in order to do so",
    ", we move the respective pointer towards the middle and compare each element with the pivot .",
    "however , instead of stopping at the first element which should be swapped , only a pointer to the element is stored in the respective buffer ( lines 8 and 9 resp .",
    "15 and 16   actually the pointer is always stored , but depending on the outcome of the comparison a counter holding the number of pointers in the buffer is increased or not ) and the pointer continues moving towards the middle . after an entire block of @xmath32 elements has been scanned ( either on both sides of the array or only on one side ) , the rearranging phase begins : it starts with the first positions of the two buffers and swaps the data elements they point to ( line 21 ) ; then it continues until one of the buffers contains no more pointers to elements which should be swapped .",
    "now the scanning phase is restarted and the buffer that has run empty is filled again .    the algorithm continues this way until fewer elements than two times the block size remain .",
    "now , the simplest variant is to switch to the usual hoare partition method for the remaining elements ( in the experiments with suffix ` hoare finish ` ) .",
    "but , we also can continue with the idea of block partitioning : the algorithm scans the remaining elements as one or two final blocks ( of smaller size ) and performs a last rearrangement phase .",
    "after that , some elements to swap in one of the two buffers might still remain , while the other buffer is empty . with one run through the buffer",
    ", all these elements can be moved to the left resp .",
    "right ( similar as it is done in the lomuto partitioning method , but without performing actual comparisons ) .",
    "we do not present the details for this final rearranging here because on one hand it gets a little tedious and on the other hand it does neither provide a lot of insight into the algorithm nor is it necessary to prove our result on branch mispredictions .",
    "the c++ code of this basic variant can be found in  appendix  [ app : code ] .      if the input consists of random permutations ( all data elements different ) , the average numbers of comparisons and swaps are the same as for usual quicksort with median - of - three .",
    "this is because both hoare s partitioner and the block partitioner preserve randomness of the array .",
    "the number of scanned elements ( total number of elements loaded to the registers ) is increased by two times the number of swaps , because for every swap , the data elements have to be loaded again .",
    "however , the idea is that due to the small block size , the data elements still remain in l1 cache when being swapped   so the additional scan has no negative effect on the running time . in section  [ sec : blocksize_experiments ] we see that for larger data types and from a certain threshold on , an increasing size of the blocks has a negative effect on the running time .",
    "therefore , the block size should not be chosen too large   we propose @xmath53 and fix this constant throughout ( thus , already for inputs of moderate size , the buffers also do not require much more space than the stack for quicksort ) .",
    "[ [ branch - mispredictions ] ] branch mispredictions    the next theorem is our main theoretical result . for simplicity",
    "we assume here that blockquicksort is implemented without the worst - case - stopper heapsort ( i.e.  there is no limit on the recursion depth ) . since there is only a low probability that a high recursion depth is reached while the array is still large , this assumption is not a real restriction .",
    "we analyze a static branch predictor : there is a misprediction every time a loop is left and a misprediction every time the _ if _ branch of an _ if _ statement is not taken .",
    "[ thm : few_branches ]    let @xmath54 be the average number of comparisons of quicksort with constant size pivot sample",
    ". then blockquicksort ( without limit to the recursion depth and with the same pivot selection method ) with blocksize @xmath32 induces at most @xmath55 branch mispredictions on average .",
    "in particular , blockquicksort with median - of - three induces less then @xmath56 branch mispredictions on average .",
    "theorem  [ thm : few_branches ] shows that when choosing the block size sufficiently large , the @xmath57-term becomes very small and   for real - world inputs   we can basically assume a linear number of branch mispredictions . moreover , theorem  [ thm : few_branches ] can be generalized to samples of non - constant size for pivot selection .",
    "since the proof might become tedious , we stick to the basic variant here .",
    "the constant 6 in theorem  [ thm : few_branches ] can be replaced by 4 when implementing lines 19 , 24 , and 25 of algorithm  [ alg : partition ] with conditional moves .",
    "first , we show that every execution of the block partitioner algorithm  [ alg : partition ] on an array of length @xmath2 induces at most @xmath58 branch mispredictions for some constant @xmath59 . in order to do so ,",
    "we only need to look at the main loop ( line 4 to 27 ) of algorithm  [ alg : partition ] because the final scanning and rearrangement phases consider only a constant ( at most @xmath60 ) number of elements . inside the main loop",
    "there are three _ for _ loops ( starting lines 7 , 14 , 20 ) , four _ if _ statements ( starting lines 5 , 12 , 24 , 25 ) and the min calculation ( whose straightforward implementation is an _ if _ statement   line 19 ) . we know that in every execution of the main loop at least one of the conditions of the _ if _ statements in line 5 and 12 is true because in every rearrangement phase at least one buffer runs empty .",
    "the same holds for the two _ if _ statements in line 24 and 25 .",
    "therefore , we obtain at most two branch mispredictions for the _ _",
    "if__s , three for the _ for _ loops and one for the min in every execution of the main loop .    in every execution of the main loop ,",
    "there are at least @xmath32 comparisons of elements with the pivot .",
    "thus , the number of branch misses in the main loop is at most @xmath61 times the number of comparisons .",
    "hence , for every input permutation the total number of branch mispredictions of blockquicksort is at most @xmath62 where @xmath63 it the number of branch mispredictions of one execution of the main loop of quicksort ( including pivot selection , which only needs a constant number of instructions ) and the @xmath64 term comes from the final insertionsort .",
    "the number of calls to partition is bounded by @xmath2 because each element can be chosen as pivot only once ( since the pivots are not contained in the arrays for the recursive calls ) .",
    "thus , by taking the average over all input permutations , the first statement follows .",
    "the second statement follows because quicksort with median - of - three incurs @xmath65 comparisons on average  @xcite .",
    "[ rem : constant ] the @xmath64-term in theorem  [ thm : few_branches ] can be bounded by @xmath66 by taking a closer look to the final rearranging phase .    we give a rough heuristic estimate : it is save to assume that the average length of arrays on which insertionsort is called is at least 8 ( recall that we switch to insertionsort as soon as the array size is less than 17 ) . for insertionsort there is one branch miss for each element ( when exiting the loop for finding the position ) plus one for each call of insertionsort ( when exiting the loop over all elements to insert ) .",
    "furthermore , there are at most two branch misses in the main quicksort loop ( lines 177 and 196 in appendix  [ app : code ] ) for every call to insertionsort .",
    "hence , we have approximately @xmath67 branch misses due to insertionsort .",
    "it remains to count the constant number of branch misprediction incurred during every call of partitioning : after exiting the main loop of block partition , there is one more scan and rearrangement phase with a smaller block size . this leads to at most @xmath68 branch mispredictions ( one extra because there is an additional case that both buffers are empty ) . the final rearranging incurs at most three branch misses ( lines 118 , 136 , 140 ) .",
    "selecting the pivot as median - of - three ( line 11 ) induces no branch misses since all conditional statements are compiled to conditional moves .",
    "finally , there is at most one branch miss in the main quicksort loop for every call to partition ( line 180 ) .",
    "this sums up to at most @xmath69 branch misses per call to partition . because the average size of arrays treated by insertionsort is at least 8 , the number of calls to partition is less than @xmath70 .",
    "thus , in total the @xmath64-term in theorem  [ thm : few_branches ] consists of at most @xmath71 branch mispredictions .",
    "we propose and implemented further tunings for our block partitioner :    1 .",
    "loop unrolling : since the block size is a power of two , the loops of the scanning phase can be unrolled four or even eight times without causing additional overhead .",
    "2 .   cyclic permutations instead of swaps : we replace + swap(@xmath46\\bigr ] , a\\bigl[r- \\mathrm{offsets}_r[\\mathrm{start}_r + j]\\bigr]$ ] ) + by the following code , which does not perform exactly the same data movements , but still in the end all elements less than the pivot are on the left and all elements greater are on the right : + temp @xmath72\\bigr]$ ] @xmath73\\bigr ] \\gets        a\\bigl[r- \\mathrm{offsets}_r[\\mathrm{start}_r]\\bigr]$ ] @xmath74\\bigr ] \\gets      a\\bigl[\\ell + \\mathrm{offsets}_l[\\mathrm{start}_l + j]\\bigr]$ ] @xmath46\\bigr ]      \\gets a\\bigl[r - \\mathrm{offsets}_r[\\mathrm{start}_r + j ] \\bigr]$ ] @xmath75\\bigr ] \\gets$ ] temp + note that this is also a standard improvement for partitioning   see e.g.  @xcite .    in the following , we always assume these two improvements since they are of very basic nature ( plus one more small change in the final rearrangement phase ) .",
    "we call the variant without them ` block_partition_simple `   its c++ code can be found in appendix  [ app : code ] .    the next improvement is a slight change of the algorithm : in our experiments we noticed that for small arrays with many duplicates the recursion depth becomes often higher than the threshold for switching to heapsort   a way to circumvent this is an additional check for duplicates equal to the pivot if one of the following two conditions applies :    * the pivot occurs twice in the sample for pivot selection ( in the case of median - of - three ) , * the partitioning results very unbalanced for an array of small size .",
    "the check for duplicates takes place after the partitioning is completed .",
    "only the larger half of the array is searched for elements equal to the pivot .",
    "this check works similar to lomuto s partitioner ( indeed , we used the implementation from @xcite ) : starting from the position of the pivot , the respective half of the array is scanned for elements equal to the pivot ( this can be done by one _ less than _ comparison since elements are already known to be greater or equal ( resp .",
    "less or equal ) the pivot ) ) .",
    "elements which are equal to the pivot are moved to the side of the pivot .",
    "the scan continues as long as at least every fourth element is equal to the pivot ( instead every fourth one could take any other ratio   this guarantees that the check stops soon if there are only few duplicates ) .",
    "after this check , all elements which are identified as being equal to the pivot remain in the middle of the array ( between the elements larger and the elements smaller than the pivot ) ; thus , they can be excluded from further recursive calls .",
    "we denote this version with the suffix ` duplicate check ` ( dc ) .",
    "we ran thorough experiments with implementations in c++ on different machines with different types of data and different kinds of input sequences .",
    "if not specified explicitly , the experiments are run on an intel core i5 - 2500k cpu ( 3.30ghz , 4 cores , 32 kb l1 instruction and data cache , 256 kb l2 cache per core and 6 mb l3 shared cache ) with 16 gb ram and operating system ubuntu linux 64bit version 14.04.4 .",
    "we used gnu s ` g++ ` ( 4.8.4 ) ; optimized with flags ` -o3 -march = native ` .    for time measurements , we used ` std:\\!:chrono:\\ ! : high_resolution_clock ` , for generating random inputs , the mersenne twister pseudo - random generator ` std:\\!:mt19937 ` .",
    "all time measurements were repeated with the same 20 deterministically chosen seeds   the displayed numbers are the average of these 20 runs . moreover , for each time measurement , at least 128 mb of data were sorted   if the array size is smaller , then for this time measurement several arrays have been sorted and the total elapsed time measured . our running time plots all display the actual time divided by the number of elements to sort on the ` y`-axis .",
    "we performed our running time experiments with three different data types :    * ` int ` : signed 32-bit integers . * ` vector ` : 10-dimensional array of 64-bit floating - point numbers ( ` double ` ) .",
    "the order is defined via the euclidean norm   for every comparison the sums of the squares of the components are computed and then compared . * ` record ` : 21-dimensional array of 32-bit integers .",
    "only the first component is compared .",
    "the code of our implementation of blockquicksort as well as the other algorithms and our running time experiments is available at https://github.com/weissan/blockquicksort .",
    "[ [ sec : blocksize_experiments ] ] different block sizes    figure  [ fig : blocksizes ] shows experimental results on random permutations for different data types and block sizes ranging from 4 up to @xmath76 .        we see that for integers only at the end there is a slight negative effect when increasing the block size .",
    "presumably this is because up to a block size of @xmath77 , still two blocks fit entirely into the l3 cache of the cpu . on the other hand for ` vector ` a block size of 64 and for ` record ` of 8 seem to be optimal   with a considerably increasing running time for larger block sizes .    as a compromise we chose to fix the block size to 128 elements for all further experiments .",
    "an alternative approach would be to choose a fixed number of bytes for one block and adapt the block size according to the size of the data elements .",
    "[ [ sec : skewed ] ] skewed pivot experiments    [ sec : pivot_experiments ]     means that @xmath78-th element is chosen as pivot of an array of length @xmath2 . ]",
    "we repeated the experiments from  @xcite with skewed pivot for both the usual hoare partitioner ( ` std:\\!:__unguarded_partition ` , from the gcc implementation of ` std:\\!:sort ` ) and our block partition method .",
    "for both partitioners we used our tuned quicksort loop .",
    "the results can be seen in figure  [ fig : skewed_pivots ] : classic quicksort benefits from skewed pivot , whereas blockquicksort works best with the exact median .",
    "therefore , for blockquicksort it makes sense to invest more effort to find a good pivot .",
    "[ [ sec : pivot_selection ] ] different pivot selection methods    we implemented several strategies for pivot selection :    * median - of - three , median - of - five , median - of - twenty - three , * median - of - three - medians - of - three , median - of - three - medians - of - five , median - of - five - medians - of - five : first calculate three ( resp .",
    "five ) times the median of three ( resp .",
    "five ) elements , then take the pivot as median of these three ( resp .",
    "five ) medians , * median - of-@xmath79 .",
    "all pivot selection strategies switch to median - of - three for small arrays .",
    "moreover , the median - of-@xmath79 variant switches to median - of - five - medians - of - five for arrays of length below 20000 ( for smaller @xmath2 even the number of comparisons was better with median - of - five - medians - of - five ) . the medians of larger samples are computed with ` std:\\!:nth_element ` . despite the results on skewed pivots figure  [ fig : skewed_pivots ] , there was no big difference between the different pivot selection strategies as it can be seen in figure  [ fig : pivot_method ] .    .",
    "]    as expected , median - of - three was always the slowest for larger arrays .",
    "median - of - five - medians - of - five was the fastest for ` int ` and median - of-@xmath79 for ` vector ` .",
    "we think that the small difference between all strategies is due to the large overhead for the calculation of the median of a large sample   and maybe because the array is rearranged in a way that is not favorable for the next recursive calls .",
    "we compare variants of blockquicksort with the gcc implementation of ` std:\\!:sort ` ( which is known to be one of the most efficient quicksort implementations   see e.g.  @xcite ) , yaroslavskiy s dual - pivot quicksort  @xcite ( we converted the java code of  @xcite to c++ ) and an implementation of super scalar sample sort @xcite by hbschle - schneider . for random permutations and random values modulo @xmath79 , we also test tuned quicksort @xcite and three - pivot quicksort implemented by aumller and bingmann from  @xcite ( which is based on @xcite )   for other types of inputs we omit these algorithms because of their poor behavior with duplicate elements .",
    "[ [ branch - mispredictions-1 ] ] branch mispredictions        we experimentally determined the number of branch mispredictions of blockquicksort and the other algorithms with the _ chachegrind _ branch prediction profiler , which is part of the profiling tool _",
    "_ valgrind__. the results of these experiments on random ` int ` data can be seen in figure  [ fig : branch_misses ]   the ` y`-axis shows the number of branch misprediction divided the the array size .",
    "we only display the median - of - three variant of blockquicksort since all the variants are very much alike .",
    "we also added plots of blockquicksort and tuned quicksort skipping final insertionsort ( i.e.  the arrays remain partially unsorted ) .",
    "we see that both ` std:\\!:sort`and yaroslavskiy s dual - pivot quicksort incur @xmath80 branch mispredictions . the up and down for super scalar sample sort",
    "presumably is because of the variation in the size of the arrays where the base case sorting algorithm ` std:\\!:sort`is applied to .",
    "for blockquicksort there is an almost non - visible @xmath6 term for the number of branch mispredictions .",
    "indeed , we computed an approximation of @xmath81 branch mispredictions .",
    "thus , the actual number of branch mispredictions is still better then our bounds in theorem  [ thm : few_branches ] .",
    "there are two factors which contribute to this discrepancy : our rough estimates in the mentioned results , and that the actual branch predictor of a modern cpu might be much better than a static branch predictor .",
    "also note that approximately one half of the branch mispredictions are incurred by insertionsort   only the other half by the actual block partitioning and main quicksort loop .",
    "finally , figure  [ fig : branch_misses ] shows that katajainen et al.s tuned quicksort is still more efficient with respect to branch mispredictions ( only @xmath64 ) .",
    "this is no surprise since it does not need any checks whether buffers are empty etc .",
    "moreover , we see that over @xmath82 of the branch misses of tuned quicksort come from the final insertionsort .",
    "[ [ running - time - experiments ] ] running time experiments    in figure  [ fig : random_int ] we present running times on random ` int ` permutations of different blockquicksort variants and the other algorithms including katajainen s tuned quicksort and aumller and bingmann s three - pivot quicksort .",
    "the optimized blockquicksort variants need around 45ns per element when sorting @xmath83 elements , whereas ` std:\\!:sort`needs 85ns per element   thus , there is a speed increase of 88% ( i.e.  the number of elements sorted per second is increased by 88% ) .     and @xmath79 . ]",
    "the same algorithms are displayed in figure  [ fig : modulo_int ] for sorting random ` int`s between @xmath84 and @xmath79 .",
    "here , we observe that tuned quicksort is much worse than all the other algorithms ( already for @xmath85 it moves outside the displayed range ) . all variants of blockquicksort",
    "are faster than ` std:\\!:sort `   the ` duplicate check ` ( dc ) version is almost twice as fast .",
    "figure  [ fig : powers ] presents experiments with data containing a lot of duplicates and having specific structures   thus , maybe coming closer to `` real - world '' inputs ( although it is not clear what that means ) . since here tuned quicksort and three - pivot quicksort are much slower than all the other algorithms , we exclude these two algorithms from the plots .",
    "the array for the left plot contains long already sorted runs .",
    "this is most likely the reason that ` std:\\!:sort`and yaroslavskiy s dual - pivot quicksort have similar running times to blockquicksort ( for sorted sequences the conditional branches can be easily predicted what explains the fast running time ) .",
    "the arrays for the middle and right plot start with sorted runs and become more and more erratic ; the array for the right one also contains a extremely high number of duplicates . here the advantage of blockquicksort   avoiding conditional branches   can be observed again . in all three plots",
    "the check for duplicates ( dc ) established a considerable improvement .     of `",
    "int ` with duplicates : _ left _",
    ": @xmath86 = i \\mod { \\left\\lfloor\\mathinner{\\sqrt{n } } \\right\\rfloor}$ ] ; _ middle _ : @xmath86 = i^2 +           n/2\\mod n$ ] ; _ right _ : @xmath86 = i^8 + n/2 \\mod           n$ ] .",
    "since @xmath2 is always a power of two , the value @xmath87 occurs approximately @xmath88 times in the last case . ]        in figure  [ fig : recordvector ] , we show the results of selected algorithms for random permutations of ` vector ` and ` record ` .",
    "we conjecture that the good results of super scalar sample sort on ` record`s are because of its better cache behavior ( since ` record ` are large data elements with very cheap comparisons ) .",
    "more running time experiments also on other machines and compiler flags can be found in appendix  [ app : more_experiments ] .",
    "[ [ more - statistics ] ] more statistics    table  [ tab : more_stats ] shows the number of branches taken / branch mispredicted as well as the instruction count and cache misses .",
    "although ` std:\\!:sort`has a much lower instruction count than the other algorithms , it induces most branch misses and ( except tuned quicksort ) most l1 cache misses (= l3 refs since no l2 cache is simulated ) .",
    "blockquicksort does not only have a low number of branch mispredictions , but also a good cache behavior   one reason for this is that insertionsort is applied during the recursion and not at the very end .",
    ".instruction count , branch and cache misses when sorting random ` int ` permutations of size @xmath89 .",
    "all displayed numbers are divided by the number of elements . [ cols=\"^,^,^,^,^,^,^\",options=\"header \" , ]",
    "we have established an efficient in - place general purpose sorting algorithm , which avoids branch predictions by converting results of comparisons to integers . in the experiments",
    "we have seen that it is competitive on different kinds of data . moreover , in several benchmarks it is almost twice as fast as ` std:\\!:sort ` .",
    "future research might address the following issues :    * we used insertionsort as recursion stopper   inducing a linear number of branch misses .",
    "is there a more efficient recursion stopper that induces fewer branch mispredictions ? * more efficient usage of the buffers : in our implementation the buffers on average are not even filled half . to use the space more efficiently one could address the buffers cyclically and scan until one buffer is filled . by doing so ,",
    "also both buffers could be filled in the same loop   however , with the cost of introducing additional overhead . *",
    "the final rearrangement of the block partitioner is not optimal : for small arrays the similar problems with duplicates arise as for lomuto s partitioner .",
    "* pivot selection strategy : though theoretically optimal , median - of-@xmath79 pivot selection is not best in practice . also we want to emphasize that not only the sample size but also the selection method is important ( compare the different behavior of the two versions of ` std:\\!:sort`for sorted and reversed permutations ) .",
    "it might be even beneficial to use a fast pseudo - random generator ( e.g.  a linear congruence generator ) for selecting samples for pivot selection . * parallel versions : the block structure is very well suited for parallelism .",
    "* a three - pivot version might be interesting , but efficient multi - pivot variants are not trivial : our first attempt was much slower .",
    "[ [ acknowledgments ] ] acknowledgments    thanks to jyrki katajainen and max stenmark for allowing us to use their python scripts for measuring branch mispredictions and cache missses and to lorenz hbschle - schneider for his implementation of super scalar sample sort .",
    "we are also indebted to jan philipp wchter for all his help with creating the plots , to daniel bahrdt for answering many c++ questions , and to christoph greulich for his help with the experiments .    10    v8 instruction set overview , 2011 .",
    "document number : prd03-genc-010197 15.0 .",
    "intel 64 and ia-32 architecture optimization reference manual , 2016 .",
    "order number : 248966 - 032 .",
    "d.  abhyankar and m.  ingle .",
    "engineering of a quicksort partitioning algorithm .",
    ", 2(2):1723 , 2011 .",
    "martin aumller and martin dietzfelbinger .",
    "optimal partitioning for dual pivot quicksort - ( extended abstract ) . in _ icalp _ ,",
    "pages 3344 , 2013 .",
    "martin aumller , martin dietzfelbinger , and pascal klaue .",
    "how good is multi - pivot quicksort ? , abs/1510.04676 , 2015 .",
    "paul biggar , nicholas nash , kevin williams , and david gregg .",
    "an experimental study of sorting and branch prediction .",
    ", 12:1.8:139 , 2008 .",
    "gerth  stlting brodal , rolf fagerberg , and kristoffer vinther .",
    "engineering a cache - oblivious sorting algorithm .",
    ", 12:2.2:123 , 2008 .",
    "gerth  stlting brodal and gabriel moruz .",
    "tradeoffs between branch mispredictions and comparisons for sorting algorithms . in _ wads _ , volume 3608 of _ lncs _ , pages 385395 .",
    "springer , 2005 .",
    "thomas  h. cormen , charles  e. leiserson , ronald  l. rivest , and clifford stein . . the mit press , 3nd edition , 2009 .",
    "amr elmasry and jyrki katajainen .",
    "lean programs , branch mispredictions , and sorting . in _ fun _ , volume 7288 of _ lncs _ , pages 119130 .",
    "springer , 2012 .",
    "amr elmasry , jyrki katajainen , and max stenmark .",
    "branch mispredictions do nt affect mergesort . in _ sea _",
    ", pages 160171 , 2012 .",
    "robert  w. floyd .",
    "algorithm 245 : treesort 3 .",
    ", 7(12):701 , 1964 .    john  l. hennessy and david  a. patterson . .",
    "morgan kaufmann , 5th edition , 2011 .",
    "charles a.  r. hoare .",
    ", 5(1):1016 , 1962 .",
    "kanela kaligosi and peter sanders .",
    "how branch mispredictions affect quicksort . in _",
    "esa _ , pages 780791 , 2006 .",
    "jyrki katajainen .",
    "sorting programs executing fewer branches .",
    "cph stl report 2263887503 , department of computer science , university of copenhagen , 2014 .",
    "donald  e. knuth .",
    ", volume  3 of _ the art of computer programming_. addison wesley longman , 2nd edition , 1998 .",
    "shrinu kushagra , alejandro lpez - ortiz , aurick qiao , and j.  ian munro .",
    "multi - pivot quicksort : theory and experiments . in _ alenex _ ,",
    "pages 4760 , 2014 .",
    "anthony lamarca and richard  e ladner .",
    "the influence of caches on the performance of sorting .",
    ", 31(1):66104 , 1999 .",
    "conrado martnez , markus  e. nebel , and sebastian wild .",
    "analysis of branch misses in quicksort . in _ workshop on analytic algorithmics and combinatorics ,",
    "analco 2015 , san diego , ca , usa , january 4 , 2015 _ , pages 114128 , 2015 .    conrado martnez and salvador roura .",
    "optimal sampling strategies in quicksort and quickselect . , 31(3):683705 , 2001 .",
    "david  r. musser .",
    "introspective sorting and selection algorithms .",
    ", 27(8):983993 , 1997 .    charles price .",
    "nstruction set , 1995 .",
    "peter sanders and sebastian winkel .",
    "uper scalar sample sort . in _ esa _ ,",
    "pages 784796 , 2004 .",
    "robert sedgewick .",
    "the analysis of quicksort programs .",
    ", 7(4):327355 , 1977 .",
    "robert sedgewick .",
    "implementing quicksort programs .",
    ", 21(10):847857 , 1978 .",
    "sebastian wild and markus  e. nebel . average case analysis of java 7 s dual pivot quicksort . in _ esa _ ,",
    "pages 825836 , 2012 .",
    "sebastian wild , markus  e. nebel , and ralph neininger .",
    "average case and distributional analysis of dual - pivot quicksort .",
    "11(3):22:142 , 2015 .    j.  w.  j. williams .",
    "algorithm 232 : heapsort .",
    ", 7(6):347348 , 1964 .",
    "vladimir yaroslavskiy .",
    "ual - pivot quicksort algorithm , 2009 .",
    "url : http://codeblab.com/wp-content/uploads/2009/09/dualpivotquicksort.pdf .",
    "in figure  [ fig : inversions ] and figure  [ fig : basic_permutations ] we also included the new gcc implementation of ` std:\\!:sort`(gcc version 4.8.4 ) marked as ` std:\\!:sort`(new ) .",
    "the very small difference in the implementation of choosing the second instead of the first element as part of the sample for pivot selection makes a enormous difference when sorting special permutations like decreasingly sorted arrays .",
    "this shows how important not only the size of the pivot sample but also the proper selection is . in the other benchmarks both implementations were relatively close , so we do not show both of them .     =",
    "i +                   n/2 \\mod n$ ] . ]     inversions ( @xmath90 random swaps of neighboring elements ) : _ left _ : @xmath91 ; _ middle _ : @xmath92 ; _ right _ : @xmath93 . ]     of ` int ` with many duplicates : _ left : _ constant ; _ middle : _ @xmath86 = 0 $ ] for @xmath94 and @xmath86 = 1 $ ] otherwise ; _ right : _",
    "random 0 - 1 values . ]     and @xmath79 ; _ right : _ sorted . ]     and @xmath79 ; _ right : _ sorted . ]         and@xmath79 ; _ right _ : sorted . ]",
    "and@xmath79 ; _ right _ : sorted . ]",
    "here , we give the c++ code of the basic blockquicksort variant ( the final rearranging is also in block style , but there is no loop unrolling etc",
    ". applied ) .    .... template < typename iter , typename compare > inline void sort_pair(iter i1 , iter i2 , compare less ) {      typedef typename std::iterator_traits",
    "< iter>::value_type t ;      bool smaller = less(*i2 , * i1 ) ;      t temp = std::move(smaller ?",
    "* i1 : temp ) ;      * i1 = std::move(smaller ?",
    "* i2 : * i1 ) ;      * i2 = std::move(smaller ?",
    "temp : * i2 ) ; }       template < typename iter , typename compare >     inline iter median_of_3(iter i1 , iter i2 , iter i3 , compare less ) {      sort_pair(i1 , i2 , less ) ;      sort_pair(i2 , i3 , less ) ;      sort_pair(i1 , i2 , less ) ;      return i2 ; }    template < typename iter , typename compare > inline iter hoare_block_partition_simple(iter begin , iter end , iter pivot_position , compare less ) {      typedef typename std::iterator_traits < iter>::difference_type index ;      index indexl[blocksize ] , indexr[blocksize ] ;           iter last = end - 1 ;      std::iter_swap(pivot_position , last ) ;      const typename std::iterator_traits < iter>::value_type & pivot = * last ;      pivot_position = last ;      last-- ;           int num_left = 0 ;      int num_right = 0 ;      int start_left = 0 ;      int start_right = 0 ;      int num ;      //main loop      while ( last - begin + 1 > 2 * blocksize )      {      //compare and store in buffers      if ( num_left = = 0 ) {          start_left = 0 ;          for ( index j = 0 ; j < blocksize ; j++ ) {              indexl[num_left ] = j ;              num_left + = ( ! ( less(begin[j ] , pivot ) ) ) ;                       }      }      if ( num_right = = 0 ) {          start_right = 0 ;          for ( index j = 0 ; j < blocksize ; j++ ) {              indexr[num_right ] = j ;              num_right + = ! ( less(pivot , * ( last - j ) ) ) ;                         }      }      //rearrange elements      num = std::min(num_left , num_right ) ;      for ( int j = 0 ; j < num ; j++ )          std::iter_swap(begin + indexl[start_left + j ] , last - indexr[start_right + j ] ) ;           num_left -= num ;      num_right -= num ;      start_left + = num ;      start_right + = num ;      begin + = ( num_left",
    "= = 0 ) ? blocksize : 0 ;      last -= ( num_right = = 0 ) ?",
    "blocksize : 0 ;           } //end main loop           //compare and store in buffers final iteration      index shiftr = 0 , shiftl = 0 ;      if ( num_right = = 0 & & num_left = = 0 ) {   //for small arrays or in the unlikely case that both buffers are empty          shiftl = ( ( last - begin ) + 1 ) / 2 ;          shiftr = ( last - begin ) + 1 - shiftl ;          start_left = 0 ; start_right = 0 ;          for ( index j = 0 ; j < shiftl ; j++ ) {              indexl[num_left ] = j ;              num_left + = ( ! less(begin[j ] , pivot ) ) ;              indexr[num_right ] = j ;              num_right + = !",
    "less(pivot , * ( last - j ) ) ;          }          if ( shiftl < shiftr )          {              indexr[num_right ] = shiftr - 1 ;              num_right + = !",
    "less(pivot , * ( last - shiftr + 1 ) ) ;          }      }      else if ( num_right ! = 0 ) {          shiftl = ( last - begin ) - blocksize + 1 ;          shiftr = blocksize ;          start_left = 0 ;          for ( index j = 0 ; j < shiftl ; j++ ) {              indexl[num_left ] = j ;              num_left + = ( ! less(begin[j ] , pivot ) ) ;          }      }      else {          shiftl = blocksize ;          shiftr = ( last - begin ) - blocksize + 1 ;          start_right = 0 ;          for ( index j = 0 ; j < shiftr ; j++ ) {              indexr[num_right ] = j ;              num_right + = ! ( less(pivot , * ( last - j ) ) ) ;          }      }           //rearrange final iteration      num = std::min(num_left ,",
    "num_right ) ;      for ( int j = 0 ; j < num ; j++ )          std::iter_swap(begin + indexl[start_left + j ] , last - indexr[start_right + j ] ) ;           num_left -= num ;      num_right -= num ;      start_left + = num ;      start_right + = num ;      begin + = ( num_left",
    "shiftl : 0 ;      last -= ( num_right",
    "shiftr : 0 ;                //end final iteration                //rearrange elements remaining in buffer      if ( num_left ! = 0 )      {          int loweri = start_left + num_left - 1 ;          index upper = last - begin ;          //search first element to be swapped          while ( loweri > = start_left & & indexl[loweri ] = = upper ) {              upper-- ; loweri-- ;          }          while ( loweri > = start_left )              std::iter_swap(begin + upper-- , begin + indexl[loweri-- ] ) ;                   std::iter_swap(pivot_position , begin + upper + 1 ) ; // fetch the pivot           return begin + upper + 1 ;      }      else if ( num_right ! = 0 ) {          int loweri = start_right + num_right - 1 ;          index upper = last - begin ;          //search first element to be swapped          while ( loweri > = start_right & & indexr[loweri ] = = upper ) {              upper-- ; loweri-- ;          }               while ( loweri > = start_right )              std::iter_swap(last - upper-- , last - indexr[loweri-- ] ) ;                   std::iter_swap(pivot_position , last - upper);// fetch the pivot           return last - upper ;      }      else { //no remaining elements          std::iter_swap(pivot_position , begin);// fetch the pivot           return begin ;      } }    template < typename iter , typename compare > struct hoare_block_partition_simple {      static inline iter partition(iter begin , iter end , compare less ) {          //choose pivot          iter mid = median_of_3(begin , begin + ( end - begin ) / 2 , end , less ) ;          //partition          return hoare_block_partition_simple(begin + 1 , end - 1 , mid , less ) ;      } } ;    //quicksort main loop .",
    "implementation based on tuned quicksort ( elmasry , katajainen , stenmark ) template < template < class , class > class partitioner , typename iter , typename compare > inline void qsort(iter begin , iter end , compare less ) {      const int depth_limit = 2 * ilogb((double)(end - begin ) ) + 3 ;      iter stack[80 ] ;      iter * s = stack ;      int depth_stack[40 ] ;      int depth = 0 ;      int * d_s_top = depth_stack ;      * s = begin ;      * ( s + 1 ) = end ;      s + = 2 ;      * d_s_top = 0 ;      + + d_s_top ;      do {          if ( depth < depth_limit & & end - begin > is_thresh ) {              iter pivot = partitioner < iter , compare>::partition(begin , end , less ) ;              //push large side to stack and continue on small side              if ( pivot - begin > end - pivot ) {                  * s = begin ;                  * ( s + 1 ) = pivot ;                  begin = pivot + 1 ;              }              else {                  * s = pivot + 1 ;                  * ( s + 1 ) = end ;                  end = pivot ;              }              s + = 2 ;              depth++ ;              * d_s_top = depth ;              + + d_s_top ;          }          else {              if ( end - begin > is_thresh )   // if recursion depth limit exceeded                  std::partial_sort(begin , end , end ) ;              else                  insertionsort::insertion_sort(begin , end , less ) ; //copy of std::__insertion_sort ( gcc 4.7.2 )                                       //pop new subarray from stack              s -= 2 ;              begin = * s ;              end = * ( s + 1 ) ;              --d_s_top ;              depth = * d_s_top ;          }      } while ( s ! = stack ) ; }"
  ],
  "abstract_text": [
    "<S> since the work of kaligosi and sanders ( 2006 ) , it is well - known that quicksort   which is commonly considered as one of the fastest in - place sorting algorithms   suffers in an essential way from branch mispredictions . </S>",
    "<S> we present a novel approach to address this problem by partially decoupling control from data flow : in order to perform the partitioning , we split the input in blocks of constant size ( we propose 128 data elements ) ; then , all elements in one block are compared with the pivot and the outcomes of the comparisons are stored in a buffer . in a second pass , </S>",
    "<S> the respective elements are rearranged . by doing so </S>",
    "<S> , we avoid conditional branches based on outcomes of comparisons at all ( except for the final insertionsort ) . </S>",
    "<S> moreover , we prove that for a static branch predictor the average total number of branch mispredictions is at most @xmath0 for some small @xmath1 depending on the block size when sorting @xmath2 elements .    </S>",
    "<S> our experimental results are promising : when sorting random integer data , we achieve an increase in speed ( number of elements sorted per second ) of more than 80% over the gcc implementation of c++ ` std:\\!:sort ` . also for many other types of data and non - random inputs </S>",
    "<S> , there is still a significant speedup over ` std:\\!:sort ` . only in few special cases like sorted or almost sorted inputs , ` std:\\!:sort`can beat our implementation . </S>",
    "<S> moreover , even on random input permutations , our implementation is even slightly faster than an implementation of the highly tuned super scalar sample sort , which uses a linear amount of additional space . </S>"
  ]
}