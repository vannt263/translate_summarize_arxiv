{
  "article_text": [
    "_ nearest - neighbor searching _ is a fundamental operation employed in many applied areas including pattern recognition , computer vision , multimedia retrieval , computational biology , and statistical machine learning . to automate the search task ,",
    "real - world objects are represented in a compact numerical , e.g. , vectorial , form and a distance function @xmath1 , e.g. , the euclidean metric @xmath2 , is used to evaluate the similarity of data points @xmath3 and @xmath4 .",
    "traditionally , it assumed that the distance function is a non - negative function that is small for similar objects and large for dissimilar one .",
    "it is equal to zero for identical @xmath3 and @xmath4 and is always positive when objects are different .",
    "this mathematical formulation allows us to define the nearest - neighbor search as a _ conceptually simple _ optimization procedure .",
    "specifically , given a query data point @xmath5 , the goal is to identify the nearest ( neighbor ) data point @xmath3 , i.e. , the point with the minimum distance value @xmath6 among all data points ( ties can be resolved arbitrarily ) .",
    "a natural generalization is a @xmath0-nn search , where we aim to find @xmath0 closest points instead of merely one .",
    "if the distance is not symmetric , two types of queries are considered : _ left _ and _ right _ queries . in a",
    "_ left _ query , a data point compared to the query is always the first ( i.e. , the left ) argument of @xmath1 .    despite being conceptually simple , finding nearest neighbors in efficient and effective fashion",
    "is a _ notoriously hard _ task , which has been a recurrent topic in the database community ( see e.g. @xcite ) .",
    "the most studied instance of the problem is an _ exact _",
    "nearest - neighbor search in vector spaces , where a distance function is an actual metric distance ( a non - negative , symmetric function satisfying the triangle inequality ) .",
    "if the search is exact , we must guarantee that an algorithm _ always _ finds a true nearest - neighbor no matter how much computational resources such a quest may require .",
    "comprehensive reviews of exact approaches for metric and/or vector spaces can be found in books by zezula et al .",
    "@xcite and samet  @xcite .",
    "yet , exact methods work well only in low dimensional metric spaces .",
    "experiments showed that exact methods can rarely outperform the sequential scan when dimensionality exceeds ten @xcite .",
    "this a well - known phenomenon known as `` the curse of dimensionality '' .",
    "furthermore , a lot of applications are increasingly relying on non - metric spaces ( for a list of references related to computer vision see , e.g. , a work by jacobs  et  al .",
    "this is primarily because many problems are inherently non - metric @xcite .",
    "thus , using , a non - metric distance permits sometimes a better representation for a domain of interest .",
    "unfortunately , exact methods for metric - spaces are not directly applicable to non - metric domains .    compared to metric spaces , it is more difficult to design exact methods for arbitrary non - metric spaces , in particular , because they lack sufficiently generic yet simple properties such as the triangle inequality .",
    "when exact search methods for non - metric spaces do exist , they also seem to suffer from the curse of dimensionality @xcite .",
    "_ approximate _ search methods are less affected by the curse of dimensionality @xcite and can be used in various non - metric spaces when exact retrieval is not necessary @xcite .",
    "approximate search methods can be much more efficient than exact ones , but this comes at the expense of a reduced search accuracy .",
    "the quality of approximate searching is often measured using _ recall _ , which is equal to the average fraction of true neighbors returned by a search method .",
    "for example , if the method routinely misses every other true neighbor , the respective recall value is 50% .",
    "permutation - based algorithms is an important class of approximate retrieval methods that was independently introduced by amato  @xcite and chvez et al .",
    "it is based on the idea that if we rank a set of reference points  called _",
    "pivots_with respect to distances from a given point , the pivot rankings produced by two near points should be similar .",
    "a number of methods based on this idea were recently proposed and evaluated @xcite ( these methods are briefly surveyed in   [ sectionlitsurvey ] ) . however , a comprehensive evaluation that involves a diverse set of large",
    "metric and non - metric data sets ( i.e. , asymmetric and/or hard - to - compute distances ) is lacking . in ",
    "[ sectionexperiments ] , we fill this gap by carrying out an extensive experimental evaluation where these methods ( implemented by us ) are compared against some of the most efficient state - of - the art benchmarks .",
    "the focus is on the high - accuracy retrieval methods ( recall close to 0.9 ) for generic spaces . because distributed high - throughput main memory databases are gaining popularity ( see .",
    ", e.g. @xcite ) , we focus on the case where data and indices are stored in main memory .",
    "potentially , the data set can be huge , yet , we run experiments only with a smaller subset that fits into a memory of one server .",
    "permutation methods are _ filter - and - refine _ methods belonging to the class of pivoting searching techniques .",
    "_ pivots _ ( henceforth denoted as @xmath7 ) are reference points randomly selected during indexing . to create an index ,",
    "we compute the distance from every data point @xmath3 to every pivot @xmath7 .",
    "we then memorize either the original distances or some distance statistics in the hope that these statistics can be useful during searching . at search time",
    ", we compute distances from the query to pivots and prune data points using , e.g. , the triangle inequality @xcite or its generalization for non - metric spaces @xcite .    voronoi diagram produced by four pivots @xmath7 . the data points are @xmath8 , @xmath9 , @xmath10 , and @xmath11 .",
    "the distance is @xmath2.,scaledwidth=20.0% ]    alternatively , rather than relying on distance values directly , we can use precomputed statistics to produce estimates for distances between the query and data points .",
    "in particular , in the case of permutation methods , we assess similarity of objects based on their relative distances to pivots . to this end , for each data point @xmath3 , we arrange pivots @xmath7 in the order of increasing distances from @xmath3 .",
    "the ties can be resolved , e.g. , by selecting a pivot with the smallest index .",
    "such a _ permutation _",
    "( i.e. , ranking ) of pivots is essentially a vector whose element keeps an ordinal position of the pivot in the set of pivots sorted by their distances from @xmath3 .",
    "we say that point @xmath3 _ induces _ the permutation .",
    "consider the voronoi diagram in figure  [ figexample ] produced by pivots @xmath12 , @xmath13 , @xmath14 , and @xmath15 .",
    "each pivot @xmath7 is associated with its own cell containing points that are _ closer _ to @xmath7 than to any other pivot @xmath16 .",
    "the neighboring cells of two pivots are separated by a segment of the line _ equidistant _ to these pivots .",
    "each of the data points @xmath8 , @xmath9 , @xmath10 , and @xmath11 `` sits '' in the cell of its closest pivot .    for the data point @xmath8 ,",
    "points @xmath12 , @xmath13 , @xmath14 , and @xmath15 are respectively the first , the second , the third , and the forth closest pivots .",
    "therefore , the point @xmath8 induces the permutation @xmath17 . for the data point @xmath9 , which is the nearest neighbor of @xmath8 , two closest pivots",
    "are also @xmath12 and @xmath13 .",
    "however , @xmath15 is closer than @xmath14",
    ". therefore , the permutation induced by @xmath9 is @xmath18 .",
    "likewise , the permutations induced by @xmath10 and @xmath11 are @xmath19 and @xmath20 , respectively .",
    "the _ underpinning assumption _ of permutation methods is that most nearest neighbors can be found by retrieving a small fraction of data points whose pivot rankings , i.e. , the induced permutations , are similar to the pivot ranking of the query .",
    "two most popular choices to compare the rankings @xmath3 and @xmath4 are : spearman s rho distance ( equal to the squared @xmath2 ) and the footrule distance ( equal to @xmath21 ) @xcite .",
    "more formally , @xmath22 and @xmath23 . according to chvez et al .",
    "@xcite spearman s rho is more effective than the footrule distance .",
    "this was also confirmed by our own experiments .    converting the vector of distances to pivots into a permutation entails information loss , but this loss is not necessarily detrimental . in particular",
    ", our preliminary experiments showed that using permutations instead of vectors of original distances results in slightly better retrieval performance .",
    "the information about relative positions of the pivots can be further coarsened by binarization : all elements smaller than a threshold @xmath9 become zeros and elements at least as large as @xmath9 become ones @xcite .",
    "the similarity of binarized permutations is computed via the hamming distance .    in the example of figure  [ figexample ] , the values of the footrule distance between the permutation of @xmath8 and permutations of @xmath9 , @xmath10 , and @xmath11 are equal to 2 , 4 , and 6 , respectively .",
    "note that the footrule distance on permutations correctly `` predicts '' the closest neighbor of @xmath8 .",
    "yet , the ordering of points based on the footrule distance is not perfect : the footrule distance from the permutation of @xmath8 to the permutation of its second nearest neighbor @xmath11 is larger than the footrule distance to the permutation of the third nearest neighbor @xmath10 .    given the threshold @xmath24 , the binarized permutations induced by @xmath8 , @xmath9 , @xmath10 , and @xmath11 are equal to @xmath25 , @xmath25 , @xmath26 , and @xmath27 , respectively .",
    "in this example , the binarized permutation of @xmath8 and its nearest neighbor @xmath9 are equal , i.e. , the distance between respective permutations is zero .",
    "when we compare @xmath8 to @xmath10 and @xmath11 , the hamming distance does not discriminate between @xmath10 and @xmath11 as their binary permutations are both at distance two from the binary permutation of @xmath8 .",
    "permutation - based searching belongs to a class of _ filter - and - refine _ methods , where objects are mapped to data points in a low - dimensional space ( usually @xmath21 or @xmath2 ) . given a permutation of a query",
    ", we carry out a nearest neighbor search in the space of permutations .",
    "retrieved entries represent a ( hopefully ) small list of candidate data points that are compared directly to the query using the distance in the _ original _ space .",
    "the permutation methods differ in ways of producing candidate records , i.e. , in the way of carrying out the filtering step . in the next sections we describe these methods in detail .",
    "permutation methods are similar to the rank - aggregation method omedrank due to fagin et  al .  @xcite . in omedrank",
    "there is a small set of voting pivots , each of which ranks data points based on a somewhat imperfect notion of the distance from points to the query ( e.g. , computed via a random projection ) .",
    "while each individual ranking is imperfect , a more accurate ranking can be achieved by rank aggregation .",
    "thus , unlike permutation methods , omedrank uses pivots to rank data points and aims to find an _",
    "unknown _ permutation of _ data points _ that reconciles differences in data point rankings in the best possible way .",
    "when such a consolidating ranking is found , the most highly ranked objects from this _ aggregate _ ranking can be used as answers to a nearest - neighbor query .",
    "finding the aggregate ranking is an np - complete problem that fagin  et  al .",
    "@xcite solve only heuristically .",
    "in contrast , permutation methods use data points to rank pivots and solve a much simpler problem of finding _ already known and computed _ permutations of _ pivots _ that are the best matches for the query permutation .",
    "l c c c c c l & distance & # of rec . & brute - force & in - memory & dimens .",
    "& source + & function & & search ( sec ) & size & & +   + cophir & @xmath2 & @xmath28 & 0.6 & 5.4 gb & 282 & mpeg7 descriptors @xcite + sift & @xmath2 & @xmath28 & 0.3 & 2.4 gb & 128 & sift descriptors @xcite + imagenet & sqfd@xcite & @xmath29 & 4.1 & 0.6 gb & n / a & signatures generated from + & & & & & & imagenet lsvrc-2014  @xcite +   + wiki - sparse & cosine sim . & @xmath30 & 1.9 & 3.8 gb & @xmath31 & wikipedia tf - idf vectors + & & & & & & generated via gensim @xcite + wiki-8 & kl - div / js - div & @xmath32 & 0.045/0.28 & 0.13 gb & 8 & lda ( 8 topics ) generated + & & & & & & from wikipedia via gensim @xcite + wiki-128 & kl - div / js - div & @xmath32 & 0.22/4 & 2.1 gb & 128 & lda ( 128 topics ) generated + & & & & & & from wikipedia via gensim @xcite + dna & normalized & @xmath29 & 3.5 & 0.03 gb & n / a & sampled from the human genome + & levenshtein & & & & & with sequence length @xmath33 +      in this approach , the filtering stage is implemented as a brute - force comparison of the query permutation against the permutations of the data with subsequent selection of the @xmath34 entries that are @xmath34-nearest objects in the space of permutations .",
    "a number of candidate entries @xmath34 is a parameter of the search algorithm that is often understood as a fraction ( or percentage ) of the total number of points . because the distance in the space of permutations is not a perfect proxy for the original distance , to answer a @xmath0-nn - query with high accuracy , the number of candidate records has to be much larger than @xmath0 ( see   [ sectionindexability ] ) .",
    "a straightforward implementation of brute - force searching relies on a priority queue .",
    "chvez et al .",
    "@xcite proposed to use incremental sorting as a more efficient alternative . in our experiments with the @xmath2 distance ,",
    "the latter approach is twice as fast as the approach relying on a standard c++ implementation of a priority queue .",
    "the cost of the filtering stage can be reduced by using binarized permutations @xcite .",
    "binarized permutations can be stored compactly as bit arrays .",
    "computing the hamming distance between bit arrays can be done efficiently by xor - ing corresponding computer words and counting the number of non - zero bits of the result . for bit - counting",
    ", one can use a special instruction available on many modern cpus .",
    "the brute - force searching in the permutation space , unfortunately , is not very efficient , especially if the distance can be easily computed : if the distance is `` cheap '' ( e.g. , @xmath2 ) and the index is stored in main memory , the brute - force search in the space of permutations is not much faster than the brute - force search in the original space .",
    "to reduce the cost of the filtering stage of permutation - based searching , three types of indices were proposed : the permutation prefix index ( pp - index ) @xcite , existing methods for metric spaces @xcite , and the metric inverted file ( mi - file ) @xcite .",
    "permutations are integer vectors whose values are between one and the total number of pivots @xmath35 .",
    "we can view these vectors as sequences of symbols over a finite alphabet and index these sequences using a prefix tree .",
    "this approach is implemented in the pp - index . at query time , the method aims to retrieve @xmath34 candidates by finding permutations that share a prefix of a given length with the permutation of the query object .",
    "this operation can be carried out efficiently via the prefix tree constructed at index time .",
    "if the search generates fewer candidates than a specified threshold @xmath34 , the procedure is recursively repeated using a shorter prefix .",
    "for example , the permutations of points @xmath8 , @xmath9 , @xmath10 , and @xmath11 in figure  [ figexample ] can be seen as strings ` 1234 ` , ` 1243 ` , ` 2314 ` , and ` 3241 ` .",
    "the permutation of points @xmath8 and @xmath9 , which are nearest neighbors , share a two - character prefix with @xmath8 .",
    "in contrast , permutations of points @xmath10 and @xmath11 , which are more distant from @xmath8 than @xmath9 , have no common prefix with @xmath8 .    to achieve good recall , it may be necessary to use short prefixes .",
    "however , longer prefixes are more selective than shorter ones ( i.e. , they generate fewer candidate records ) and are , therefore , preferred for efficiency reasons . in practice , a good trade - off between recall and efficiency is typically achieved only by building several copies of the pp - index ( using different subsets of pivots ) @xcite .",
    "figueroa and fredriksson experimented with indexing permutations using well - known data structures for metric spaces @xcite .",
    "indeed , the most commonly used permutation distance : spearman s rho , is a monotonic transformation ( squaring ) of the euclidean distance .",
    "thus , it should be possible to find @xmath34 nearest neighbors by indexing permutations , e.g. , in a vp - tree @xcite .",
    "amato and savino proposed to index permutation using an inverted file @xcite .",
    "they called their method the mi - file . to build the mi - file , they first select @xmath35 pivots and compute their permutations / rankings induced by data points . for each data point , @xmath36 most closest pivots are indexed in the inverted file .",
    "each posting is a pair @xmath37 , where @xmath3 is the identifier of the data point and @xmath38 is a position of the pivot in the permutation induced by @xmath3 . postings of the same pivot are sorted by pivot s positions .",
    "consider the example of figure  [ figexample ] and imagine that we index two most closest pivots ( i.e. , @xmath39 ) .",
    "the point @xmath8 induces the permutation @xmath17 .",
    "two closest pivots @xmath12 and @xmath13 generate postings @xmath40 and @xmath41 .",
    "the point @xmath9 induces the permutation @xmath18 .",
    "again , @xmath12 and @xmath13 are two pivots closest to @xmath9 .",
    "the respective postings are @xmath42 and @xmath43 .",
    "the permutation of @xmath10 is @xmath44 .",
    "two closest pivots are @xmath12 and @xmath14 .",
    "the respective postings are @xmath45 and @xmath46 .",
    "the permutation of @xmath11 is @xmath47 .",
    "two closest pivots are @xmath13 and @xmath15 with corresponding postings @xmath48 and @xmath49 .    at query time",
    ", we select @xmath50 pivots closest to the query @xmath5 and retrieve respective posting lists . if @xmath51 , it is possible to compute the exact footrule distance ( or spearman s rho ) between the query permutation and the permutation induced by data points .",
    "one possible search algorithm keeps an accumulator ( initially set to zero ) for every data point .",
    "posting lists are read one by one : for every encountered posting @xmath52 we increase the accumulator of @xmath3 by the value @xmath53 . if the goal is to compute spearman s rho , the accumulator is increased by @xmath54 .    if @xmath55 , by construction of the posting lists , using the inverted index , it is possible to obtain rankings of only @xmath55 pivots . for the remaining , @xmath56 pivots we pessimistically assume that their rankings are all equal to @xmath35 ( the maximum possible value ) . unlike the case @xmath57 , all accumulators are initially set to @xmath58",
    "whenever we encounter a posting posting @xmath52 we subtract @xmath59 from the accumulator of @xmath3 .",
    "consider again the example of figure  [ figexample ] .",
    "let @xmath60 and @xmath8 be the query point .",
    "initially , the accumulators of @xmath9 , @xmath10 , and @xmath11 contain values @xmath61 . because @xmath62 , we read posting lists only of the two closest pivots for the query point @xmath8 , i.e. , @xmath12 and @xmath13 .",
    "the posting lists of @xmath12 is comprised of @xmath40 , @xmath42 , and @xmath45 . on reading them ( and ignoring postings related to the query @xmath8 ) , accumulators @xmath9 and @xmath10 are decreased by @xmath63 and @xmath64 , respectively .",
    "the posting lists of @xmath13 are @xmath41 , @xmath43 , and @xmath48 .",
    "on reading them , we subtract @xmath65 from each of the accumulators @xmath9 and @xmath11 . in the end , the accumulators @xmath9 , @xmath10 , @xmath11 are equal to 0 , 5 , and 4 .",
    "unlike the case when we compute the footrule distance between complete permutation , the footrule distance on truncated permutations correctly predicts the order of three nearest neighbors of @xmath8 .    using fewer pivots at retrieval time allows us to reduce the number of processed posting lists .",
    "another optimization consists in keeping posting lists sorted by pivots position @xmath66 and retrieving only the entries satisfying the following restriction on the maximum position difference : @xmath67 , where @xmath68 is a method parameter . because posting list entries are sorted by pivot positions , the first and the last entry satisfying the maximum position difference requirement can be efficiently found via the binary search .",
    "tellez  et  al .",
    "@xcite proposed a modification of the mi - file which they called a neighborhood approximation index ( napp ) .",
    "in the case of napp , there also exist a large set of @xmath35 pivots of which only @xmath69 pivots ( most closest to inducing data points ) are indexed .",
    "unlike the mi - file , however , posting lists contain only object identifiers , but no positions of pivots in permutations .",
    "thus , it is not possible to compute an estimate for the footrule distance by reading only posting lists .",
    "therefore , instead of an estimate for the footrule distance , the number of most closest _ common _ pivots is used to sort candidate objects .",
    "in addition , the candidate objects sharing with the query fewer than @xmath70 closest pivots are discarded ( @xmath70 is a parameter ) .",
    "for example , points @xmath8 and @xmath9 in figure  [ figexample ] share the same common pivot @xmath12 . at the same time",
    "@xmath8 does not share any closest pivot with points @xmath11 and @xmath10 .",
    "therefore , if we use @xmath8 as a query , the point @xmath9 will be considered to be the best candidate point .",
    "chvez et al .",
    "@xcite proposed a single framework that unifies several approaches including pp - index , mi - file , and napp .",
    "similar to the pp - index , permutations are viewed as strings over a finite alphabet . however , these strings are indexed using a special sequence index ( rather than a prefix tree ) that efficiently supports rank and select operations .",
    "these operations can be used to simulate various index traversal modes , including , e.g. , retrieval of all strings whose symbol is equal to a given one .",
    "we employ three image data sets : cophir , sift , imagenet , and several data sets created from textual data .",
    "the smallest data set ( dna ) has one million entries , while the largest one ( cophir ) contains five million high - dimensional vectors .",
    "all data sets derived from wikipedia were generated using the topic modelling library gensim @xcite .",
    "the data set meta data is summarized in table  [ tabledataset ] .",
    "below , we describe our data sets in detail .",
    "* cophir * is a five million subset of mpeg7 descriptors downloaded from the website of the institute of the national research council of italy@xcite .",
    "* sift * is a five million subset of sift descriptors ( from the learning subset ) downloaded from a texmex collection website@xcite .    in experiments involving cophir and sift , we employed @xmath2 to compare unmodified , i.e. , raw visual descriptors .",
    "we implemented an optimized procedure to compute @xmath2 that relies on single instruction multiple data ( simd ) operations available on intel - compatible cpus . using this implementation ,",
    "it is possible to carry out about 30 million @xmath2 computations per second using sift vectors or 10 million @xmath2 computations using cophir vectors .",
    "* imagenet * collection comprises one million signatures extracted from lsvrc-2014 data set  @xcite , which contains 1.2 million high resolution images .",
    "we implemented our own code to extract signatures following the method of beecks  @xcite .",
    "for each image , we selected @xmath71 pixels randomly and mapped them into 7-dimensional feature space : three color , two position , and two texture dimensions .",
    "the features were clustered by the standard @xmath0-means algorithm with 20 clusters .",
    "then , each cluster was represented by an 8-dimensional vector , which included a 7-dimensional centroid and a cluster weight ( the number of cluster points divided by @xmath71 ) .",
    "l r@r r@r r@r r@r r@r r@r & & & & & +   + cophir & 5.4 gb & ( 0.5min ) & 6 gb & ( 6.8min ) & 13.5 gb & ( 23.4min ) & & & 7 gb & ( 52.1min ) + sift & 2.4 gb & ( 0.4min ) & 3.1 gb & ( 5min ) & 10.6 gb & ( 18.4min ) & & & 4.4 gb & ( 52.2min ) + imagenet & 1.2 gb & ( 4.4min ) & 0.91 gb & ( 33min ) & & & 12.2 gb & ( 32.3min ) & 1.1 gb & ( 127.6min ) +   + wiki - sparse & & & 4.4 gb & ( 7.9min ) & & & & & 5.9 gb & ( 231.2min ) + wiki-8 ( kl - div ) & 0.35 gb & ( 0.1min ) & 0.67 gb & ( 1.7min ) & & & & & 962 mb & ( 11.3min ) + wiki-128 ( kl - div ) & 2.1 gb & ( 0.2min ) & 2.5 gb & ( 3.1min ) & & & & & 2.9 gb & ( 14.3min ) + wiki-8 ( js - div ) & 0.35 gb & ( 0.1min ) & 0.67 gb & ( 3.6min ) & & & & & 2.4 gb & ( 89min ) + wiki-128 ( js - div ) & 2.1 gb & ( 1.2min ) & 2.5 gb & ( 36.6min ) & & & & & 2.8 gb & ( 36.1min ) + dna & 0.13 gb & ( 0.9min ) & 0.32 gb & ( 15.9min ) & & & 61 mb & ( 15.6min ) & 1.1 gb & ( 88min ) +   +   +   +     +    images were compared using a metric function called the signature quadratic form distance ( sqfd ) . this distance is computed as a quadratic form , where the matrix is re - computed for each pair of images using a heuristic similarity function applied to cluster representatives . it is a distance metric defined over vectors from an infinite - dimensional space such that each vector has only finite number of non - zero elements . for further details ,",
    "please , see the thesis of beecks  @xcite .",
    "sqfd was shown to be effective @xcite .",
    "yet , it is nearly two orders of magnitude slower compared to @xmath2 .",
    "* wiki - sparse * is a set of four million sparse tf - idf vectors ( created via gensim @xcite ) . on average , these vectors have 150 non - zero elements out of @xmath31 .",
    "here we use a cosine similarity , which is a symmetric non - metric distance : @xmath72 computation of the cosine similarity between sparse vectors relies on an efficient procedure to obtain an intersection of non - zero element indices . to this end",
    ", we use an all - against - all simd comparison instruction as was suggested by schlegel  et  al .",
    "this distance function is relatively fast being only about 5x slower compared to @xmath2 .",
    "* wiki-@xmath73 * consist of dense vectors of topic histograms created using the latent dirichlet allocation ( lda)@xcite .",
    "the index @xmath74 denotes the number of topics . to create these sets , we trained a model on one half of the wikipedia collection and then applied it to the other half ( again using gensim @xcite ) .",
    "zero values were replaced by small numbers ( @xmath75 ) to avoid division by zero in the distance calculations .",
    "two distance functions were used for these data sets : the kullback - leibler  ( kl ) divergence : @xmath76 and its symmetrized version called the jensen - shannon ( js ) divergence : @xmath77.\\ ] ] both the kl- and the js - divergence are non - metric distances . note that the kl - divergence is not even symmetric .",
    "our implementation of the kl - divergence relies on the precomputation of logarithms at index time .",
    "therefore , during retrieval it is as fast as @xmath2 . in the case of js - divergence , it is not possible to precompute @xmath78 and , thus , it is about 10 - 20 times slower compared to @xmath2 .    * dna * is a collection of dna sequences sampled from the human genome  .",
    "starting locations were selected randomly and uniformly ( however , lines containing the symbol ` n ` were excluded ) .",
    "the length of the sequence was sampled from @xmath79 .",
    "the employed distance function was the _ normalized levenshtein distance_. this non - metric distance is equal to the minimum number of edit operations ( insertions , deletions , substitutions ) , needed to convert one sequence into another , divided by the maximum of the sequence lengths .",
    "+   +      table  [ tableindexsizetime ] lists all implemented methods and provides information on index creation time and size .",
    "* multiprobe - lsh ( mplsh ) * is implemented in the library lshkit .",
    "it is designed to work only for @xmath2 .",
    "some parameters are selected automatically using the cost model proposed by dong et al",
    ".  @xcite . however , the size of the hash table @xmath80 , the number of hash tables @xmath81 , and the number of probes @xmath82 need to be chosen manually .",
    "we previously found that ( 1 ) @xmath83 and @xmath84 provided a near optimal performance and ( 2 ) performance is not affected much by small changes in @xmath81 and @xmath82 @xcite .",
    "this time , we re - confirmed this observation by running a small - scale grid search in the vicinity of @xmath83 and @xmath85 for @xmath80 equal to the number of points plus one .",
    "the mplsh generates a list of candidates that are directly compared against the query .",
    "this comparison involves the optimized simd implementation of @xmath2 .",
    "* vp - tree * is a classic space decomposition tree that recursively divides the space with respect to a randomly chosen pivot @xmath86@xcite . for each partition , we compute a median value @xmath87 of the distance from @xmath86 to every other point in the current partition .",
    "the pivot - centered ball with the radius @xmath87 is used to partition the space : the inner points are placed into the left subtree , while the outer points are placed into the right subtree ( points that are exactly at distance @xmath87 from @xmath86 can be placed arbitrarily ) .    partitioning stops when the number of points falls below the threshold @xmath9 .",
    "the remaining points are organized in a form of a bucket . in our implementation , all points in a bucket are stored in the same chunk of memory . for cheap distances ( e.g. , @xmath2 and kl - div )",
    "this placing strategy can halve retrieval time .",
    "if the distance is the metric , the triangle inequality can be used to prune unpromising partitions as follows : imagine that @xmath88 is a radius of the query and the query point is inside the pivot - centered ball ( i.e. , in the left subtree ) . if @xmath89 , the right partition can not have an answer , i.e. , the right subtree can be safely pruned .",
    "if the query point is in the right partition , we can prune the left subtree if @xmath90 .",
    "the nearest - neighbor search is simulated as a range search with a decreasing radius : each time we evaluate the distance between @xmath5 and a data point , we compare this distance with @xmath88 .",
    "if the distance is smaller , it becomes a new value of @xmath88 .",
    "in the course of traversal , we first visit the closest subspace ( e.g. , the left subtree if the query is inside the pivot - centered ball ) .    for a generic , i.e. , not necessarily metric , space ,",
    "the pruning conditions can be modified .",
    "for example , previously we used a liner `` stretching '' of the triangle inequality @xcite . in this work",
    ", we employed a simple polynomial pruner .",
    "more specifically , the right partition can be pruned if the query is in the left partition and @xmath91 .",
    "the left partition can be pruned if the query is in the right partition and @xmath92 .",
    "we used @xmath93 for the kl - divergence and @xmath94 for every other distance function .",
    "the optimal parameters @xmath95 and @xmath96 can be found by a trivial grid - search - like procedure with a shrinking grid step @xcite ( using a subset of data ) . *",
    "@xmath0-nn graph * ( a proximity graph ) is a data structure in which data points are associated with graph nodes and @xmath0 edges are connected to @xmath0 nearest neighbors of the node .",
    "the search algorithm relies on a concept `` the closest neighbor of my closest neighbor is my neighbor as well . ''",
    "this algorithm can start at an arbitrary node and recursively transition to a neighbor point ( by following the graph edge ) that is closest to the query .",
    "this greedy algorithm stops when the current point @xmath3 is closer to the query than any of the @xmath3 s neighbors .",
    "however , this algorithm can be trapped in a local minima @xcite .",
    "alternatively , the termination condition can be defined in terms of an extended neighborhood @xcite .",
    "constructing an _ exact _",
    "@xmath0-nn graph is hardly feasible for a large data set , because , in the worst case , the number of distance computations is @xmath97 , where @xmath98 in the number of data points .",
    "while there are amenable metric spaces where an exact graph can be computed more efficiently than in @xmath97 , see e.g. @xcite , the quadratic cost appear to be unavoidable in many cases , especially if the distance is not a metric or the intrinsic dimensionality is high .",
    "an _ approximate _ @xmath0-nn graph can be constructed more efficiently . in this work , we employed two different graph construction algorithms : the nn - descent proposed by dong et al .",
    "@xcite and the search - based insertion algorithm used by malkov et  al .",
    "the nn - descent is an iterative procedure initialized with randomly selected nearest neighbors . in each iteration ,",
    "a random sample of queries is selected to participate in neighborhood propagation .",
    "malkov et al .",
    "@xcite called their method a _ small world _ ( sw ) graph .",
    "the graph - building algorithm finds an insertion point by running the same algorithm that is used during retrieval .",
    "multiple insertion attempts are carried out starting from a random point .",
    "the _ open - source _ implementation of nn - descent is publicly available online .. however , it comes without a search algorithm .",
    "thus , we used the algorithm due to malkov  et  al .",
    "@xcite , which was available in the non - metric space library @xcite .",
    "we applied both graph construction algorithms .",
    "somewhat surprisingly , in all but two cases , nn - descent took ( much ) longer time to converge . for each data",
    "set , we used the graph - construction algorithm that performed better on a subset of the data . both graph construction algorithms are computationally expensive and are ,",
    "therefore , constructed in a multi - threaded mode ( four threads ) .",
    "tuning of @xmath0-nn graphs involved manual selection of two parameters @xmath0 and the decay coefficient ( tuning was carried out on a subset of data ) .",
    "the latter parameter , which is used only for nn - descent , defines the convergence speed .",
    "* brute - force filtering * is a simple approach where we exhaustively compare the permutation of the query against permutation of every data point .",
    "we then use incremental sorting to select @xmath34 permutations closest to the query permutation .",
    "these @xmath34 entries represent candidate records compared directly against the query using the original distance .    as noted in ",
    "[ sectionlitsurvey ] , the cost of the filtering stage is high .",
    "thus , we use this algorithm only for the computationally intensive distances : sqfd and the normalized levenshtein distance .",
    "originally , both in the case of sqfd and normalized levenshtein distance , good performance was achieved with permutations of the size 128 .",
    "however , levenshtein distance was applied to dna sequences , which were strings whose average length was only 32 .",
    "therefore , using uncompressed permutations of the size 128 was not space efficient ( 128 32-bit integers use 512 bytes ) .",
    "fortunately , we can achieve the same performance using bit - packed binary permutations with 256 elements , each of which requires only 32 bytes .",
    "the optimal permutation size was found by a small - scale grid search ( again using a subset of data ) .",
    "several values of @xmath34 ( understood as a fraction of the total number of points ) were manually selected to achieve recall in the range 0.85 - 0.9 .    *",
    "napp * is a neighborhood approximation index described in   [ sectionlitsurvey ] @xcite .",
    "our implementation is different from the proposition of chvez et al .",
    "@xcite and tellez  et  al .",
    "@xcite in at least two ways : ( 1 ) we do not compress the index and ( 2 ) we use a simpler algorithm , namely , the scancount , to merge posting lists @xcite . for each entry in the database ,",
    "there is a counter .",
    "when we read a posting list entry corresponding to the object @xmath73 , we increment counter @xmath73 . to improve cache utilization and overall performance , we split the inverted index into small chunks , which are processed one after another . before each search counters",
    "are zeroed using the function ` memset ` from a standard c library .",
    "tuning napp involves selection of three parameters @xmath35 ( the total number of pivots ) , @xmath99 ( the number of indexed pivots ) , and @xmath70 .",
    "the latter is equal to the minimum number of indexed pivots that has to be shared between the query and a data point . by carrying out a small - scale grid search , we found that increasing @xmath35 improves both recall and decreases retrieval time , yet , improvement is small beyond @xmath100 . at the same time ,",
    "computation of one permutation entails computation of @xmath35 distances to pivots .",
    "thus , larger values of @xmath35 incur higher indexing cost",
    ". values of @xmath35 between 500 and 2000 provide a good trade - off .",
    "because the indexing algorithm is computationally expensive , it is executed in a multi - threaded mode ( four threads ) .",
    "increasing @xmath99 improves recall at the expense of retrieval efficiency : the larger is @xmath99 , the more posting lists are to be processed at query time .",
    "we found that good results are achieved for @xmath101 .",
    "smaller values of @xmath70 result in high recall values . at the same time",
    ", they also produce a larger number of candidate records , which negatively affects performance .",
    "thus , for cheap distances , e.g. @xmath2 , we manually select the smallest @xmath70 that allows one to achieve a desired recall ( using a subset of data ) . for more expensive distances",
    ", we have an additional filtering step ( as proposed by tellez  et  al .",
    "@xcite ) , which involves sorting by the number of commonly indexed pivots .",
    "our initial assessment showed that napp was more efficient than the pp - index and at least as efficient mi - file , which agrees with results of chvez et al .",
    "we also compared our napp implementation to that of chvez et al .",
    "@xcite using the same @xmath21 data set : @xmath102 normalized cophir descriptors . at 95% recall , chvez et al .",
    "@xcite achieve a 14x speed up , while we achieve a 15x speed up ( relative to respective brute - force search implementations ) .",
    "thus , our napp implementation is a competitive benchmark .",
    "additionally we benchmark our own implementation of fagin  et  al.s  omedrank algorithm @xcite and found napp to be more efficient .",
    "we also experimented with indexing permutations using the vp - tree , yet , this algorithm was either outperformed by the vp - tree in the original space or by napp .",
    "experiments were carried out on an linux intel xeon server ( 3.60 ghz , 32 gb memory ) in a single threaded mode using the _ non - metric space library _ @xcite as an evaluation toolkit .",
    "the code was written in c++ and compiled using gnu c++ 4.8 with the ` -ofast ` optimization flag . additionally , we used the flag ` -march = native ` to enable simd extensions .",
    "we evaluated performance of a 10-nn search using a procedure similar to a five - fold cross validation .",
    "we carried out five iterations , in which a data set was randomly split into two parts .",
    "the larger part was indexed and the smaller part comprised queries  ) the query set has the size 1000 , while for more expensive ones ( such as the sqfd ) , we used 200 queries for each of the five splits . ] . for each split , we evaluated retrieval performance by measuring the average retrieval time , the improvement in efficiency ( compared to a single - thread brute - force search ) , the recall , the index creation time , and the memory consumption . the retrieval time , recall , and the improvement in efficiency were aggregated over five splits . to simplify our presentation , in the case of non - symmetric kl - divergence ,",
    "we report results only the for the left queries . results for the right queries are similar .",
    "because we are interested in high - accuracy ( near 0.9 recall ) methods , we tried to tune parameters of the methods ( using a subset of the data ) so that their recall falls in the range 0.85 - 0.95 .",
    "method - specific tuning procedures are described in respective subsections of section [ sectionmethods ] .",
    "recall that permutation methods are filter - and - refine approaches that map data from the original space to @xmath2 or @xmath21 .",
    "their accuracy depends on the quality of this mapping , which we assess in this subsection . to this end , we explore ( 1 ) the relationship between the original distance values and corresponding values in the projected space , ( 2 ) the relationship between the recall and the fraction of candidate records scanned in response to a query .",
    "figure [ figprojcorr ] shows distance values in the original space ( on the x - axis ) vs. values in the projected space ( on the y - axis ) for eight combinations of data sets and distance functions .",
    "points were randomly sampled from two strata : a complete subset and a set of points that are 100 nearest neighbors of randomly selected points . of the presented panels ,",
    "[ corrrandl2 ] and [ corrrandcos ] correspond to the classic random projections .",
    "the remaining panels show permutation - based projections .",
    "classic random projections are known to preserve inner products and distance values @xcite .",
    "indeed , the relationship between the distance in the original and the projected space appears to be approximately linear in panels [ corrrandl2 ] and [ corrrandcos ] .",
    "therefore , it preserves the relative distance - based order of points with respect to a query .",
    "for example , there is a high likelihood for the nearest neighbor in the original space to remain the nearest neighbor in the projected space . in principle , any monotonic relationship  not necessarily linear  will suffice @xcite .",
    "if the monotonic relationship holds at least approximately , the projection typically distinguishes between points close to the query and points that are far away .",
    "for example , the projection in panel [ goodproj1 ] appears to be quite good , which is not entirely surprising , because the original space is euclidean .",
    "the projections in panels [ goodproj2 ] and [ goodproj3 ] are also reasonable , but not as good as one in panel [ goodproj1 ] .",
    "the quality of projections in panels [ unkproj1 ] and [ unkproj2 ] is somewhat uncertain .",
    "the projection in panel [ badproj1]which represents the non - symmetric and non - metric distance  is obviously poor . specifically , there are two clusters : one is close to the query ( in the original distance ) and the other is far away .",
    "however , in the projected space these clusters largely overlap .",
    "figure [ figprojquality ] contains nine panels that plot recall ( on x - axis ) against a fraction of candidate records necessary to retrieve to ensure this recall level ( on y - axis ) . in each plot",
    ", there are several lines that represent projections of different dimensionality .",
    "good projections ( e.g. , random projections in panels [ fig2rand1 ] and [ fig2rand2 ] ) correspond to steep curves : recall approaches one even for a small fraction of candidate records retrieved .",
    "steepness depends on the projection dimensionality",
    ". however , good projection curves are steep even in relatively low dimensions .",
    "the worst projection according to figure [ figprojcorr ] is in panel [ badproj1 ] .",
    "it corresponds to the wiki-128 data set with distance measured by kl - divergence .",
    "panel [ fig2badwikikl ] in figure [ figprojquality ] , corresponding to this combination of the distance and the data set , also confirms the low quality of the projection .",
    "for example , given a permutation of dimensionality 1024 , scanning 1% of the candidate permutations achieves roughly a 0.9 recall .",
    "an even worse projection example is in panel [ fig2badwikisparse ] . in this case , regardless of the dimensionality , scanning 1% of the candidate permutations achieves recall below 0.6 .    at the same time , for majority of projections in other panels , scanning 1% of the candidate permutations of dimensionality 1024 achieves an almost perfect recall . in other words , for some data sets , it is , indeed , possible to obtain a small set of candidate entries containing a true near - neighbor by searching in the permutation space .",
    "+   +      in this section , we use complete data sets listed in table [ tabledataset ] .",
    "figure [ figeffvsrecall ] shows nine data set specific panels with improvement in efficiency vs. recall .",
    "each curve captures method - specific results with parameter settings tuned to achieve recall in the range of 0.85 - 0.95 .",
    "it can be seen that in most data sets the permutation method napp is a competitive baseline . in particular , panels [ panelfinalsift ] and [ panelfinalcophir ]",
    "show napp outperforming the state - of - the art implementation of the multi - probe lsh ( mplsh ) for recall larger than 0.95 .",
    "this is consistent with findings of chvez et al .",
    "@xcite .",
    "in that , in our experiments , there was no single best method .",
    "@xmath0-nn graphs substantially outperform other methods in 6 out of 9 data sets .",
    "however , in low - dimensional data sets shown in panels [ vpwin1 ] and [ vpwin2 ] , the vp - tree outperforms the other methods by a wide margin .",
    "the wiki - sparse data set ( see panel [ panelwikisparse ] ) , which has high representational dimensionality , is quite challenging . among implemented methods ,",
    "only @xmath0-nn graphs are efficient for this set .",
    "interestingly , the winner in panel [ binpermwin ] is a brute - force filtering using binarized permutations .",
    "furthermore , the brute - force filtering is also quite competitive in panel [ finalimagenet ] , where it is nearly as efficient as napp . in both cases ,",
    "the distance function is computationally intensive and a more sophisticated permutation index does not offer a substantial advantage over a simple brute - force search in the permutation space .",
    "good performance of @xmath0-nn graphs comes at the expense of long indexing time .",
    "for example , it takes almost four hours to built the index for the wiki - sparse data set using as many as four threads ( see table  [ tableindexsizetime ] ) .",
    "in contrast , it takes only 8 minutes in the case of napp ( also using four threads ) . in general , the indexing algorithm of @xmath0-nn graphs is substantially slower than the indexing algorithm of napp : it takes up to an order of magnitude longer to build a @xmath0-nn graph .",
    "one exception is the case of wiki-128 where the distance is the js - divergence . for both napp and @xmath0-nn graph ,",
    "the indexing time is nearly 40 minutes .",
    "however , the @xmath0-nn graph retrieval is an order of magnitude more efficient .",
    "both napp and the brute - force searching of permutations have high indexing costs compared to the vp - tree .",
    "this cost is apparently dominated by time necessary to compute permutations .",
    "recall that obtaining a permutation entails @xmath35 distance computations .",
    "thus , building an index entails @xmath103 distance computations , where @xmath104 is the number of data points .",
    "in contrast , building the vp - tree requires roughly @xmath105 distance computations , where @xmath9 is the size of the bucket . in our setup , @xmath106 while @xmath107 .",
    "therefore , the indexing step of permutation methods is typically much longer than that of the vp - tree .",
    "even though permutation methods may not be the best solutions when both data and the index are kept in main memory , they can be appealing in the case of disk - resident data @xcite or data kept in a relational database . indeed , as noted by fagin  et  al .",
    "@xcite , indexes based on the inverted files are _ database friendly _ , because they require neither complex data structures nor many random accesses .",
    "furthermore , deletion and addition of records can be easily implemented . in that",
    ", it is rather challenging to implement a dynamic version of the vp - tree on top of a relational database .",
    "we also found that all evaluated methods perform reasonably well in the surveyed non - metric spaces .",
    "this might indicate that there is some truth to the two folklore wisdoms : ( 1 ) `` the closest neighbor of my closest neighbor is my neighbor as well '' , ( 2 ) `` if one point is close to a pivot , but another is far away , such points can not be close neighbors '' . yet",
    ", these wisdoms are not universal .",
    "for example , they are violated in one dimensional space with the `` distance '' @xmath108 . in this space , points 0 and 1 are distant .",
    "however , we can select a large positive number that can be arbitrarily close to both of them , which results in violation of properties ( 1 ) and ( 2 ) .",
    "it seems that such a paradox does not manifest in the surveyed non - metric spaces . in the case of continuous functions ,",
    "there is non - negative strictly monotonic transformation , @xmath109 such that @xmath110 is a @xmath111-defective distance function .",
    "thus , the distance satisfies the following inequality : latexmath:[\\[\\label{eq1 }    monotonic transformation of the cosine similarity is the metric function ( i.e , the angular distance ) @xcite .",
    "the square root of the js - divergence is metric function called jensen - shannon distance @xcite .",
    "the square root of all bregman divergences ( which include the kl - divergence ) is @xmath111-defective as well @xcite .",
    "the normalized levenshtein distance is a non - metric distance .",
    "however , for many realistic data sets , the triangle inequality is rarely violated . in particular",
    ", we verified that this is the case of our data set .",
    "the normalized levenshtein distance is approximately metric and , thus , it is approximately @xmath111-defective ( with @xmath113 ) .    if inequality ( [ eq1 ] ) holds , due to properties of @xmath114 , and implies @xmath115 .",
    "similarly if @xmath115 , but @xmath116 , @xmath117 can not be zero either .",
    "moreover , for a sufficiently large @xmath118 and small @xmath119 , @xmath117 can not be small .",
    "thus , the two folklore wisdoms are true if the strictly monotonic distance transformation is @xmath111-defective .",
    "we benchmarked permutation methods for approximate @xmath0-nearest neighbor search for generic spaces where both data and indices are stored in main memory ( aiming for high - accuracy retrieval ) .",
    "we found these filter - and - refine methods to be reasonably efficient .",
    "the best performance is achieved either by napp or by brute - force filtering of permutations .",
    "for example , napp can outperform the multi - probe lsh in @xmath2 .",
    "however , permutation methods can be outstripped by either vp - trees or @xmath0-nn graphs , partly because the filtering stage can be costly .",
    "we believe that permutation methods are most useful in non - metric spaces of moderate dimensionality when : ( 1 ) the distance function is expensive ( or the data resides on disk ) ; ( 2 ) the indexing costs of @xmath0-nn graphs are unacceptably high ; ( 3 ) there is a need for a simple , but reasonably efficient , implementation that operates on top of a relational database .",
    "this work was partially supported by the iad center   and the open advancement of question answering systems ( oaqa ) group  .",
    "we also gratefully acknowledge help of several people .",
    "in particular , we are thankful to anna belova for helping edit the experimental and concluding sections . we thank christian beecks for answering questions regarding the signature quadratic form distance ( sqfd ) @xcite ; daniel lemire for providing the implementation of the simd intersection algorithm ; giuseppe amato and eric s. tellez for help with data sets ; lu jiang for the helpful discussion of image retrieval algorithms and for providing useful references .",
    "we thank nikita avrelin and alexander ponomarenko for porting their proximity - graph based retrieval algorithm to the non - metric space library .",
    "the results of the preliminary evaluation were published elsewhere @xcite . in the current publication ,",
    "we use improved versions of the napp and baseline methods .",
    "in particular , we improved the tunning algorithm of the vp - tree and we added another implementation of the proximity - graph based retrieval @xcite .",
    "furthermore , we experimented with a more diverse collection of ( mostly larger ) data sets .",
    "in particular , because of this , we found that proximity - based retrieval may not be an optimal solution in all cases , e.g. , when the distance function is expensive to compute .",
    "a.  abdullah , j.  moeller , and s.  venkatasubramanian .",
    "approximate bregman near neighbors in sublinear time : beyond the triangle inequality . in _ proceedings of the twenty - eighth annual symposium on computational geometry _ , pages 3140 .",
    "acm , 2012 .",
    "g.  amato and p.  savino .",
    "approximate similarity search in metric spaces using inverted files . in _ proceedings of the 3rd international conference on scalable information systems",
    "_ , infoscale 08 , pages 28:128:10 , icst , brussels , belgium , belgium , 2008 .",
    "icst ( institute for computer sciences , social - informatics and telecommunications engineering ) .",
    "e.  bingham and h.  mannila .",
    "random projection in dimensionality reduction : applications to image and text data . in",
    "_ proceedings of the seventh acm sigkdd international conference on knowledge discovery and data mining _ ,",
    "pages 245250 .",
    "acm , 2001 .",
    "w.  dong , c.  moses , and k.  li .",
    "efficient k - nearest neighbor graph construction for generic similarity measures . in _ proceedings of the 20th international conference on world wide web _ , pages 577586 .",
    "acm , 2011 .",
    "w.  dong , z.  wang , w.  josephson , m.  charikar , and k.  li .",
    "modeling lsh for performance tuning .",
    "in _ proceedings of the 17th acm conference on information and knowledge management _ , cikm 08 , pages 669678 , new york , ny , usa , 2008 .",
    "acm .",
    "r.  fagin , r.  kumar , and d.  sivakumar .",
    "efficient similarity search and classification via rank aggregation . in _ proceedings of the 2003 acm sigmod international conference on management of data",
    "_ , sigmod 03 , pages 301312 , new york , ny , usa , 2003 .",
    "k.  figueroa and k.  frediksson .",
    "speeding up permutation based indexing with indexing . in _ proceedings of the 2009 second international workshop on similarity search and applications _",
    ", pages 107114 .",
    "ieee computer society , 2009 .",
    "h.  jgou , r.  tavenard , m.  douze , and l.  amsaleg .",
    "searching in one billion vectors : re - rank with source coding . in _",
    "acoustics , speech and signal processing ( icassp ) , 2011 ieee international conference on _ , pages 861864 .",
    "ieee , 2011 .",
    "r.  kallman , h.  kimura , j.  natkins , a.  pavlo , a.  rasin , s.  zdonik , e.  p.  c. jones , s.  madden , m.  stonebraker , y.  zhang , j.  hugg , and d.  j. abadi .",
    "h - store : a high - performance , distributed main memory transaction processing system . , 1(2):14961499 , aug . 2008 .    c.  li , j.  lu , and y.  lu . efficient",
    "merging and filtering algorithms for approximate string searches . in _ data engineering , 2008 .",
    "icde 2008 .",
    "ieee 24th international conference on _ , pages 257266 .",
    "ieee , 2008 .",
    "a.  ponomarenko , n.  avrelin , b.  naidan , and l.  boytsov . comparative analysis of data structures for approximate nearest neighbor search . in",
    "_ data analytics 2014 , the third international conference on data analytics _ , pages 125130 , 2014 .",
    "r.  ehuek and p.  sojka . .",
    "in _ proceedings of the lrec 2010 workshop on new challenges for nlp frameworks _ , pages 4550 , valletta , malta , may 2010 .",
    "o.  russakovsky , j.  deng , h.  su , j.  krause , s.  satheesh , s.  ma , z.  huang , a.  karpathy , a.  khosla , m.  bernstein , a.  c. berg , and l.  fei - fei . , 2014 .",
    "e.  s. tllez , e.  chvez , and a.  camarena - ibarrola . a brief index for proximity searching . in _",
    "progress in pattern recognition , image analysis , computer vision , and applications _ , pages 529536 .",
    "springer , 2009 .",
    "r.  weber , h.  j. schek , and s.  blott . a quantitative analysis and performance study for similarity - search methods in high - dimensional spaces .",
    "in _ proceedings of the 24th international conference on very large data bases _ , pages 194205 .",
    "morgan kaufmann , august 1998 ."
  ],
  "abstract_text": [
    "<S> we survey permutation - based methods for approximate @xmath0-nearest neighbor search . in these methods , </S>",
    "<S> every data point is represented by a ranked list of pivots sorted by the distance to this point . </S>",
    "<S> such ranked lists are called _ </S>",
    "<S> permutations_. the underpinning assumption is that , for both metric and non - metric spaces , the distance between permutations is a good proxy for the distance between original points . </S>",
    "<S> thus , it should be possible to efficiently retrieve most true nearest neighbors by examining only a tiny subset of data points whose permutations are similar to the permutation of a query </S>",
    "<S> . we further test this assumption by carrying out an extensive experimental evaluation where permutation methods are pitted against state - of - the art benchmarks ( the multi - probe lsh , the vp - tree , and proximity - graph based retrieval ) on a variety of realistically large data set from the image and textual domain . </S>",
    "<S> the focus is on the high - accuracy retrieval methods for generic spaces . </S>",
    "<S> additionally , we assume that both data and indices are stored in main memory . </S>",
    "<S> we find permutation methods to be reasonably efficient and describe a setup where these methods are most useful . to ease reproducibility , we make our software and data sets publicly available . </S>"
  ]
}