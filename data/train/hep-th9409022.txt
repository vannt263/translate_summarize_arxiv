{
  "article_text": [
    "algorithmic information theory@xcite , in combination with landauer s principle@xcite , which specifies the unavoidable energy cost @xmath7 for the erasure of a bit of information in the presence of a heat reservoir at temperature @xmath8 , has been applied successfully to a range of problems : the maxwell demon paradox@xcite , a consistent bayesian approach to statistical mechanics@xcite , a treatment of irreversibility in classical hamiltonian chaotic systems@xcite , and a characterization of quantum chaos relevant to statistical physics@xcite .",
    "the algorithmic information for a physical state is defined as the length in bits of the shortest self - delimiting program for a universal computer that generates a description of that state@xcite .",
    "algorithmic information with respect to two different universal computers differs at most by a computer - dependent constant@xcite .",
    "although typically the latter can be neglected in the context of statistical physics , the presence of an arbitrary constant in a physical theory is unsatisfactory and has led to criticism@xcite . in the present paper , we show how the computer - dependent constant can be eliminated from statistical physics .    in the following paragraphs",
    "we give a simplified account of the role of algorithmic information in classical statistical physics . a more complete exposition including the quantum case",
    "can be found in refs .",
    "we adopt here the information - theoretic approach to statistical physics pioneered by jaynes@xcite . in this approach ,",
    "the _ state _ of a system represents the observer s knowledge of the way the system was prepared .",
    "states are described by probability densities in phase space ; observers with different knowledge assign different states to the system .",
    "entropy measures the information missing toward a complete specification of the system .",
    "consider a set of @xmath0 states ( @xmath9 ) labeled by @xmath10 , all having the same energy and entropy .",
    "the restriction to states of the same energy and entropy is not essential , but it simplifies the notation . initially the system is assumed to be in a state in which state @xmath11 is occupied with probability @xmath12 .",
    "we assume throughout that the states @xmath11 are labeled such that @xmath13 .",
    "if an observation reveals that the system is in state @xmath11 , the increased knowledge is reflected in an entropy decrease @xmath14 where @xmath15 is the original missing information measured in bits . to make the connection with thermodynamics",
    ", we assume that there is a heat reservoir at temperature @xmath8 to which all energy in the form of heat must eventually be transferred , possibly using intermediate steps such as storage at some lower temperature . in the presence of this fiducial heat reservoir",
    ", the entropy decrease @xmath16 corresponds to a free energy increase @xmath17 .",
    "each bit of missing information decreases the free energy by the amount @xmath7 ; if information is acquired about the system , free energy increases .",
    "the fact that entropy can decrease through observation  which underlies most proposals for a maxwell demon  does not conflict with the second law of thermodynamics because the observer s physical state changes as a consequence of his interaction with the system .",
    "szilard@xcite discovered that no matter how complicated is the change in the observer s physical state , the associated irreducible thermodynamic cost can be described solely in terms of information .",
    "he found that in the presence of a heat reservoir at temperature @xmath8 each bit of information acquired by the observer has an energy cost at least as big as @xmath7 .",
    "total available work is reduced not only by missing information , but also by information the observer has acquired about the system . the physical nature of the cost of information was clarified by bennett@xcite , who applied landauer s principle@xcite to the maxwell demon problem and showed that the energy cost has to be paid when information is erased .    to keep the landauer erasure cost of the observational record as low as possible , the information should be stored in maximally compressed form .",
    "the concept of a maximally compressed record is formalized in algorithmic information theory@xcite . bennett@xcite and zurek@xcite gave szilard s theory its present form by using algorithmic information to quantify the amount of information in an observational record .",
    "in particular , by exploiting bennett s idea of a reversible computer@xcite , zurek@xcite showed how an observational record can be replaced by a compressed form at no thermodynamic cost .",
    "this means that the energy cost of the observational record can be reduced to the landauer erasure cost of the compressed form .",
    "let us denote by @xmath18 a binary string describing the @xmath11th state ( @xmath10 ) .",
    "a detailed discussion of how a description of a physical state can be encoded in a binary string is given in@xcite .",
    "the exact form of the strings @xmath18 is of no importance for the theory outlined here , however , because the information needed to generate a list of _ all _ the strings @xmath18 can be treated as _",
    "background information_@xcite .",
    "background information is the information needed to generate a list @xmath19 of all @xmath0 states together with their probabilities ; i.e. , background information is the information the observer has before the observation .",
    "algorithmic information is defined with respect to a specific universal computer @xmath20 .",
    "we denote by @xmath21 the conditional algorithmic information , with respect to the universal computer @xmath20 , to specify the @xmath11th state , given the background information@xcite .",
    "more precisely , @xmath21 is the length in bits of the shortest self - delimiting program for @xmath20 that generates the string @xmath18 , given a minimal self - delimiting program to generate @xmath22 . for a formal definition of a universal computer @xmath20 and of @xmath21 see sec .",
    "it should be emphasized that a minimal program that generates the list @xmath22 of descriptions of all states and their probabilities can be short even when a minimal program that generates the description @xmath18 of a typical single state is very long@xcite .    since total available work",
    "is reduced by @xmath7 by each bit of information the observer acquires about the system as well as by each bit of missing information , the change in _ total free energy _ or _",
    "available work _ upon observing state @xmath11 can now be written as @xmath23 = -k_bt\\ln2\\ , [ -h + i_u(s_j|s ) ] \\;.",
    "\\label{deltafj}\\ ] ] this definition of total free energy is closely related to zurek s definition of physical entropy@xcite .",
    "average conditional algorithmic information @xmath24 obeys the double inequality@xcite @xmath25 where @xmath5 denotes a positive computer - dependent constant@xcite .",
    "it follows immediately that the _ average _ change in total free energy , @xmath26 , is zero or negative : @xmath27 the left side of this double inequality establishes that acquiring information can not increase available work on the average . for standard choices for the universal computer @xmath20 ,",
    "e.g. , a turing machine or chaitin s lisp - based universal computer@xcite , the computer - dependent @xmath5 constant on the right is completely negligible in comparison with thermodynamic entropies .",
    "equation  ( [ febounds ] ) therefore expresses that on the average , with respect to a standard universal computer , total free energy remains essentially unchanged upon observation . despite the success of this theory ,",
    "the presence of an arbitrary constant is disturbing . to understand the issues involved in removing the arbitrary constant",
    ", we must introduce the notions of simple and complex states .    although the average information @xmath28 is greater than or equal to @xmath29",
    ", there is a class of low - entropy states that can be prepared without gathering a large amount of information .",
    "for example , in order to compress a gas into a fraction of its original volume , free energy has to be spent , but the length in bits of written instructions to prepare the compressed state is negligible on the scale of thermodynamic entropies .",
    "states that can be prepared reliably in a laboratory experiment usually are _ simple states _ , which means that there is a short verbal description of how to prepare such a state .",
    "the concept of a simple state is formalized in algorithmic information theory .",
    "a simple state is defined as a state for which @xmath30 ; i.e. , descriptions for simple states can be generated by short programs .",
    "the total free energy increases , in the sense of eq .",
    "( [ deltafj ] ) , upon observing the system to be in a simple state .",
    "simplicity is a computer - dependent concept .",
    "standard universal computers like turing machines reflect our intuitive notion of simplicity .",
    "it is easy , however , to define a universal computer for which there are no short programs at all ; such a computer would not recognize simplicity .",
    "intuitively , simplicity ought to be an intrinsic property of a state .",
    "a computer formalizing the intuitive concept of simplicity should reflect this .",
    "in particular , for such a computer a simple state should have a short program independent of the probability distribution @xmath31 .",
    "this is not true for all universal computers . in sec .",
    "[ opt ] we introduce a universal computer @xmath32 for which @xmath33 is determined solely by the probabilities @xmath31 . for this computer , a short program for the @xmath11th state reflects a large probability @xmath34 , not an intrinsic property of the state .",
    "we will say that such a computer does not recognize intrinsically simple states .",
    "simple states are rare  there are fewer than @xmath35 states @xmath11 for which @xmath36@xcite  and thus arise rarely as the result of an observation , yet they are of great importance .",
    "simple states are states for which the algorithmic contribution to total free energy is negligible .",
    "the concept of total free energy does not conflict with conventional thermodynamics because thermodynamic states are simple .",
    "if the theory does not have the notion of simple states , the connection with conventional thermodynamics is lost .",
    "the opposite of a simple state , a _ complex state _",
    ", is defined as a state for which @xmath21 is of the same order as @xmath29 .",
    "complex states arise not just through maxwell demon - like observations .",
    "we have shown@xcite that initially simple states of chaotic hamiltonian systems in the presence of a perturbing environment rapidly evolve into extremely complex states@xcite for which the negative algorithmic contribution to total free energy is vastly bigger than @xmath29 and thus totally dominates conventional free energy .",
    "in addition to giving insight into the second law of thermodynamics , this result leads to a new approach to quantum chaos@xcite .    in this paper",
    ", we show how the computer - dependent @xmath5 constant can be eliminated from the theory summarized above . in sec .",
    "[ opt ] we construct an optimal universal computer for which the @xmath5 constant is minimal .",
    "it turns out , however , that optimal universal computers do not recognize intrinsically simple states and thus are unsatisfactory in formulating the theory .",
    "this difficulty is solved in sec .",
    "[ twobit ] where we show that any universal computer @xmath20 can be modified in a simple way such that ( a ) any state that is simple with respect to @xmath20 is also simple with respect to the modified universal computer @xmath37 and ( b ) average conditional information with respect to @xmath37 exceeds average conditional information with respect to an optimal universal computer by at most @xmath38 bits .",
    "moreover , conditional algorithmic information with respect to the modified computer @xmath37 obeys the inequality @xmath39 .",
    "this double bound is the tightest possible in the sense that there is no tighter bound that is independent of the probabilities @xmath34 .",
    "the idea of an optimal universal computer is motivated by zurek s discussion@xcite of _",
    "huffman coding_@xcite as an alternative way to quantify the information in an observational record .",
    "we consider only binary codes , for which the code words are binary strings . before reviewing huffman coding , we need to formalize the concept of a list consisting of descriptions of @xmath0 states together with their probabilities .    *",
    "definition 1 : * a _ list of states _",
    "@xmath22 is a string of the form @xmath19 where @xmath9 , @xmath40 , @xmath41 , and @xmath18 is a binary string ( @xmath10 ) . more precisely , the list of states @xmath22 is the binary string obtained from the list @xmath42 by some definite translation scheme .",
    "one possible translation scheme is to represent parentheses , commas , and numbers ( i.e. , the probabilities @xmath34 ) in ascii code , and to precede each binary string @xmath18 by a number giving its length @xmath43 in bits .",
    "the entropy of a list of states is @xmath44 . throughout this paper",
    ", @xmath45 denotes the length of the binary string @xmath46 .",
    "the huffman code for a list of states @xmath19 is a prefix - free or instantaneous code@xcite  i.e .",
    ", no code word is a prefix of any other code word  and can , like all prefix - free codes , be represented by a binary tree as shown in fig .",
    "[ treehuff ] .",
    "the number of links leading from the root of the tree to a node is called the _",
    "level _ of that node .",
    "if the level-@xmath47 node @xmath48 is connected to the level-@xmath49 nodes @xmath50 and @xmath51 , then @xmath48 is called the _",
    "parent _ of @xmath50 and @xmath51 ; @xmath48 s _ children _ @xmath50 and @xmath51 are called _",
    "siblings_. there are exactly @xmath0 terminal nodes or _ leaves _ , each leaf corresponding to a state @xmath11 . each link connecting two nodes is labeled 0 or 1 .",
    "the sequence of labels encountered on the path from the root to a leaf is the code word assigned to the corresponding state .",
    "the code - word length of a state is thus equal to the level of the corresponding leaf .",
    "each node is assigned a probability @xmath52 such that the probability of a leaf is equal to the probability @xmath34 of the corresponding state and the probability of each non - terminal node is equal to the sum of the probabilities of its children .",
    "a binary tree represents a huffman code if and only if it has the _ sibling property_@xcite , i.e. , if and only if each node except the root has a sibling , and the nodes can be listed in order of nonincreasing probability with each node being adjacent to its sibling in the list .",
    "the tree corresponding to a huffman code and thus the huffman code itself can be built recursively .",
    "create a list of @xmath0 nodes corresponding to the @xmath0 states .",
    "these @xmath0 nodes will be the leaves of the tree that will now be constructed .",
    "repeat the following procedure until the tree is complete : take two nodes with smallest probabilities , and make them siblings by generating a node that is their common parent ; replace in the list the two nodes by their parent ; label the two links branching from the new parent node by 0 and 1 .",
    "the procedure outlined above does not define a unique huffman code for the list of states @xmath22 , nor does it give generally a unique set of code - word lengths . in the following , we will assume that we are given some definite algorithm to assign a huffman code where the freedom in the coding procedure is used to assign to the first state ( the one with smallest probability ) a code word of maximum length consisting only of zeros .    * definition 2 : * given a list of states @xmath19 , the binary string @xmath53 with length @xmath54 denotes the huffman code word assigned to the @xmath11th state using a definite algorithm with the property that @xmath55 and @xmath56 for @xmath57 .",
    "we denote the average huffman code - word length by @xmath58 .",
    "the _ redundancy _ @xmath59 of the huffman code is defined by @xmath60 .",
    "the redundancy @xmath59 obeys the bounds @xmath61 , corresponding to bounds @xmath62 for the average code - word length .",
    "huffman coding is optimal in the sense that there is no prefix - free binary code with an average code - word length less than @xmath63 .",
    "there can be , however , optimal prefix - free codes that are not huffman codes .",
    "the length @xmath64 of the huffman code word @xmath53 can not be determined from the probability @xmath34 alone , but depends on the entire set of probabilities @xmath31 .",
    "the tightest general bounds for @xmath64 are@xcite @xmath65 where @xmath66 is the golden mean .",
    "the code - word length for some states @xmath11 thus can differ widely from the value @xmath67 . for most states",
    "@xmath11 , however , the huffman code - word length is @xmath68 .",
    "the following theorem@xcite is a precise version of this statement .",
    "* theorem 1 : * * ( a ) : * @xmath69 where @xmath70 , i.e. , the probability that a state with probability @xmath71 has huffman code - word length smaller than @xmath72 is less than @xmath73 .",
    "( this is true for any prefix - free code . ) * ( b ) : * @xmath74 where @xmath75 and @xmath76 , i.e. , the probability that a state with probability @xmath71 has huffman code - word length greater than @xmath77 is less than @xmath78 .    :",
    "@xmath79    suppose that one characterizes the information content of a state @xmath11 by its huffman code - word length @xmath64 .",
    "then in eq .",
    "( [ infobounds ] ) average algorithmic information @xmath28 is replaced by average code - word length @xmath63 , the @xmath5 constant is replaced by 1 , and eq .",
    "( [ febounds ] ) assumes the concise form @xmath80 .",
    "this way of eliminating the @xmath5 constant , however , has a high price .",
    "since huffman code - word lengths depend solely on the probabilities @xmath31states with high probability are assigned shorter code words than states with low probability ",
    "huffman coding does not recognize intrinsically simple states .",
    "this means that one of the most appealing features of the theory is lost , namely that the landauer erasure cost associated with states that can be prepared in a laboratory is negligible .    in the present article",
    ", we show that it is possible to retain this feature of the theory , yet still eliminate the computer - dependent constant .",
    "we first attempt to do this by constructing an optimal universal computer , i.e. , a universal computer for which the @xmath5 constant in eq .",
    "( [ infobounds ] ) is minimal .",
    "we find , however , that optimal universal computers do not recognize intrinsically simple states , either . a solution to this problem",
    "will be given in sec .",
    "[ twobit ] where we discuss a class of nearly optimal universal computers",
    ".    we will need precise definitions of a computer and a universal computer , which we quote from chapter  6.2 in@xcite .",
    "* definition 3 : * a _ computer _ @xmath81 is a computable partial function that carries a program string @xmath71 and a free data string @xmath82 into an output string @xmath83 with the property that for each @xmath82 the domain of @xmath84 is a prefix - free set ; i.e. , if @xmath83 is defined and @xmath71 is a proper prefix of @xmath85 , then @xmath86 is not defined . in other words , programs must be self - delimiting .",
    "@xmath20 is a _ universal computer _ if and only if for each computer @xmath81 there is a constant @xmath87 with the following property : if @xmath83 is defined , then there is a @xmath85 such that @xmath88 and @xmath89 .    in this definition ,",
    "all strings are binary strings , and @xmath90 denotes the length of the string @xmath71 as before .",
    "the self - delimiting or prefix - free property entails that for each free data string @xmath82 , the set of all valid program strings can be represented by a binary tree .    for any binary string @xmath46",
    "we denote by @xmath91 ( or just @xmath92 if no confusion is possible ) the shortest string for which @xmath93 where @xmath94 is the empty string ; i.e. , @xmath92 is the shortest program for the universal computer @xmath20 to calculate @xmath46 .",
    "if there are several such programs , we pick the one that is first in lexicographic order .",
    "this allows us to define conditional algorithmic information .",
    "* definition 4 : * the _ conditional algorithmic information _ @xmath95 to specify the binary string @xmath96 , given the binary string @xmath97 , is @xmath98 in words , @xmath95 is the length of a shortest program for @xmath20 that computes @xmath96 in the presence of the free data string @xmath99 .",
    "in particular , the conditional algorithmic information @xmath21 to specify the @xmath11th state , given a list of states @xmath19 , is @xmath100 the average of @xmath21 is denoted by @xmath101 .",
    "the next theorem puts a lower bound on the average information .",
    "* theorem 2 : * for any universal computer @xmath20 and any list of states @xmath19 , the average conditional algorithmic information obeys the bound @xmath102    : we denote by @xmath103 a shortest string for which @xmath104 . the @xmath0 strings @xmath103 form a prefix - free code . if the @xmath0 strings @xmath103 are represented by the leaves of a binary tree , then there is at least one node that has no sibling .",
    "otherwise @xmath105 would be defined only for a finite number @xmath0 of programs @xmath71 , and @xmath20 would not be a universal computer .",
    "let us denote by @xmath106 a sibling - free node and by @xmath82 its probability ( @xmath107 ) .",
    "then a shorter prefix - free code @xmath108 can be obtained by moving node @xmath106 down one level .",
    "more precisely , for states @xmath11 corresponding to leaves of the subtree branching from node @xmath106 , @xmath109 is obtained from @xmath103 by removing the digit corresponding to the link between node @xmath106 and its parent ; for all other states @xmath11 , @xmath110 . the code - word lengths of the new code are @xmath111 if state @xmath11 is a leaf of the subtree branching from node @xmath106 and @xmath112 otherwise . since the new code is prefix - free , its average code - word length is greater than or equal to the huffman code - word length @xmath113 .",
    "it follows that @xmath114 which proves the theorem .",
    "@xmath79    we can now proceed to define an optimal universal computer .    * definition 5 : * @xmath20 is an _ optimal universal computer _ if there is a constant @xmath115 such that for all lists of states @xmath19 with @xmath116 the average conditional algorithmic information has its minimum value @xmath117    * theorem 3 : * for any @xmath115 there is an optimal universal computer @xmath118 .    :",
    "let @xmath20 be an arbitrary universal computer and @xmath115 .",
    "for any list of states @xmath19 with @xmath116 we define @xmath119 and @xmath120 for @xmath57 where @xmath121 denotes concatenation of strings . the strings @xmath122 thus differ from the huffman code @xmath53 in that a 1 has been appended to the code word for the state @xmath123 .",
    "according to eq .",
    "( [ huffbounds ] ) , @xmath124 , where @xmath66 and @xmath125 denotes the largest integer less than or equal to @xmath126 .",
    "we denote by @xmath127 a string composed of @xmath128 zeros ; none of the strings @xmath122 is longer than @xmath127 .    for the definition of @xmath129 we distinguish two cases .",
    "if the binary string @xmath82 is of the form @xmath130 for some list of states @xmath19 with @xmath116 , then @xmath131 is defined for @xmath132 with @xmath133 and @xmath134 if the binary string @xmath82 is not of the form  ( [ qform ] ) , then @xmath131 is defined for @xmath135 with @xmath136 in both cases , the set @xmath137 , which is the domain of @xmath138 , is clearly prefix - free . moreover , since @xmath139 whenever @xmath140 is defined and @xmath20 is a universal computer , @xmath118 is also a universal computer , with the simulation constant @xmath141 increased by @xmath128 .",
    "for any string @xmath46 the minimal program on @xmath118i.e . , the shortest program given an empty free data string  is @xmath142 , where @xmath91 is the minimal program for @xmath46 on @xmath20 . in particular ,",
    "the shortest program for @xmath118 to compute @xmath22 is @xmath143 .",
    "since @xmath144 and @xmath145 for @xmath10 while @xmath146 for all other programs @xmath147 , it follows immediately that @xmath148 and thus that @xmath149 @xmath79    if @xmath150 , i.e. , if @xmath151 is a program for @xmath20 generating a list of states @xmath22 , the programs @xmath71 for which @xmath152 is defined can be represented by a binary tree similar to fig .  [ treeopt ] .",
    "with respect to the binary tree representing the huffman code ( fig .",
    "[ treehuff ] ) , the leaf for the @xmath123 state has been moved up one level to make room for the new node labeled by @xmath20 .",
    "this new node leads to a subtree representing all programs @xmath85 for which @xmath153 is defined .",
    "the operation of the optimal universal computer @xmath118 can be described in the following way .",
    "when @xmath118 reads a string that begins with @xmath128 zeros from its program tape , @xmath118 disregards the @xmath128 zeros and interprets the rest of the string as a program for the universal computer @xmath20 , executing it accordingly . if @xmath118 encounters the digit 1 while reading the first @xmath128 digits from its program tape , @xmath118 interrupts reading from the program tape , reads in the free data string , and executes it .",
    "if the result of executing the free data string is a list of states @xmath19 , @xmath118 establishes the modified huffman code @xmath154 for @xmath22 , continues reading digits from the program tape until the string read matches one of the code words , say @xmath155 , and then prints the string @xmath156 .",
    "the output of @xmath118 is undefined in all other cases .    since @xmath157@xcite , @xmath158 for any optimal universal computer @xmath20 . for the particular optimal universal computer @xmath118 defined in the proof of theorem 3 ,",
    "however , the information @xmath159 is completely determined by the huffman code - word length for the @xmath11th state and therefore is completely determined by the probabilities @xmath31 .",
    "this optimal universal computer does not recognize intrinsically simple states .",
    "as an aside , note that @xmath118 can not give a short description of the background information for any probability distribution , because a minimal program for computing the list of states @xmath22 on @xmath118 must begin with @xmath128 zeros .",
    "it turns out that all optimal universal computers , not just @xmath118 , are unable to recognize intrinsically simple states .",
    "the following theorem formulates this inability for all optimal universal computers in a slightly weaker form than holds for @xmath118 . as a consequence , the use of algorithmic information with respect to an optimal universal computer to quantify the information in an observational record presents no advantage over the use of huffman coding .",
    "* theorem 4 : * for any optimal universal computer @xmath20 and any list of states @xmath19 for which @xmath160 , the following holds : if @xmath161 , then @xmath162 .",
    "optimal universal computers therefore do not recognize intrinsically simple states .",
    ": to prove the theorem , we show that @xmath163 for any universal computer @xmath20 and any list of states @xmath19 for which there are indices @xmath164 and @xmath11 such that @xmath161 but @xmath165 .",
    "we denote by @xmath103 a shortest string for which @xmath104 .",
    "the strings @xmath103 form a prefix - free code . following an argument similar to the proof of theorem 2",
    ", we can shorten that code on the average by moving a sibling - free node one level down and in addition by interchanging the code words for states @xmath164 and @xmath11 .",
    "the resulting shorter code must obey the huffman bound , from which the inequality @xmath166 follows .",
    "although the discussion in the last section shows that optimal universal computers present no advantages over huffman coding , the main idea behind their construction can be further exploited . if the subtree representing the programs for the universal computer @xmath20 is not attached next to the @xmath123 leaf as in fig .",
    "[ treeopt ] , but instead is attached close to the root as in fig .  [ tree3 ] , the resulting universal computer @xmath37 combines the desirable properties of huffman coding and the computer @xmath20 .",
    "this is the content of the following theorem .",
    "* theorem 5 : * for any universal computer @xmath20 there is a universal computer @xmath37 such that @xmath167 for all binary strings @xmath96 and @xmath97 , and that @xmath168 and @xmath169 for all lists of states @xmath19 .",
    ": let @xmath20 be an arbitrary universal computer .",
    "for any list of states @xmath19 we define the set of strings @xmath122 as follows .",
    "we start from the binary tree formed by the huffman code words @xmath53 where we denote by @xmath170 the probability of the level-1 node connected to the root by the link labeled 0 ( see fig .  [ treehuff ] ) . according to the value of @xmath170 , we distinguish two cases . in the case",
    "@xmath171 , @xmath172 if @xmath53 is of the form @xmath173 , and @xmath120 if @xmath53 is of the form @xmath174 . in the case",
    "@xmath175 , @xmath172 if @xmath53 is of the form @xmath174 , and @xmath176 if @xmath53 is of the form @xmath173 .",
    "figure  [ tree3 ] illustrates the binary tree formed by the code words @xmath122 for the case @xmath171 .",
    "of the two main subtrees emerging from the level-1 nodes in fig .",
    "[ treehuff ] , the subtree having smaller probability is moved up one link and attached to the node labeled 01 , and the subtree having larger probability is attached to the node labeled 1 . in this way , the node labeled 00 is freed for the subtrees representing the valid programs for @xmath20 .    for the definition of @xmath177",
    "we distinguish three cases .",
    "if the binary string @xmath82 is of the form @xmath178 for some list of states @xmath19 , then @xmath177 is defined for @xmath179 with @xmath180 @xmath181 and @xmath182 if the binary string @xmath82 is of the form @xmath183 but there is _ no _ list of states @xmath22 such that @xmath184 , then @xmath177 is defined for @xmath185 with @xmath186 and @xmath187 finally , if @xmath82 is not of the form  ( [ qform3 ] ) , then @xmath177 is defined for @xmath188 with @xmath189    in all three cases , the set @xmath137 , which is the domain of @xmath190 , is clearly prefix - free . moreover , since @xmath191 whenever @xmath140 is defined and @xmath20 is a universal computer , @xmath37 is a also a universal computer , with the simulation constant @xmath141 increased by 3 .",
    "equation  ( [ 3bit ] ) holds because of the following .",
    "the minimal program for @xmath97 on @xmath37 in the presence of an empty free data string is @xmath192 since @xmath193 is defined only if @xmath194 and @xmath195 is defined , in which case @xmath196 . if @xmath71 is a minimal program for @xmath96 on @xmath20 in the presence of the minimal program for @xmath97 , i.e. , if @xmath197 then @xmath198 and therefore @xmath199    the strings @xmath122 form a prefix - free code with an unused code word of length 2 , for which @xmath200 according to theorem  3 in@xcite .",
    "( in@xcite , the inequality appears with a @xmath201 sign , but equality can occur only if the smallest probability @xmath202 is equal to zero , a case we have excluded . )",
    "the shortest program for @xmath37 to compute @xmath22 is @xmath203 , where @xmath204 is the shortest program for @xmath20 to compute @xmath22 . since @xmath205 for @xmath10",
    ", it follows immediately that @xmath206 and thus that @xmath207 which establishes the upper bound in eq .",
    "( [ avhuffbounds ] ) . the lower bound in eq .",
    "( [ avhuffbounds ] ) holds for all universal computers .",
    "equation  ( [ u2-huff ] ) follows from @xmath208 @xmath79    if @xmath209 , i.e. , if @xmath151 is a program for @xmath20 generating a list of states @xmath22 , the programs @xmath71 for which @xmath210 is defined can be represented by a binary tree similar to fig .",
    "[ tree3 ] .",
    "the level-3 node labeled @xmath20 is the root of a subtree corresponding to the programs @xmath85 for which @xmath211 is defined , and the level-3 node labeled @xmath212 is the root of a subtree corresponding to the programs @xmath85 for which @xmath213 is defined .    the operation of the universal computer @xmath37 can be described in the following way . when @xmath37 reads a string that begins with the prefix 000 from its program tape , @xmath37 disregards the prefix and interprets the rest of the string as a program for the universal computer @xmath20 , executing it accordingly . when @xmath37 reads a string that begins with the prefix 001 from its program tape , the output is only defined if the free data string begins with 000 , in which case @xmath37 disregards the first 3 digits of the program and free data strings and interprets the rest of the strings as program and free data strings for the universal computer @xmath20 , executing it accordingly . if @xmath37 encounters the digit 1 while reading the first two digits from its program tape , @xmath37 interrupts reading from the program tape , reads in the free data string , and executes it .",
    "if the result of executing the free data string is a list of states @xmath19 , @xmath37 establishes the modified huffman code @xmath154 for @xmath22 , continues reading digits from the program tape until the string read matches one of the code words , say @xmath155 , and then prints the string @xmath156 .",
    "the output of @xmath37 is undefined in all other cases .",
    "the computer @xmath37 compromises between the desirable properties of algorithmic information and huffman coding . since algorithmic information defined with respect to @xmath37 exceeds algorithmic information relative to @xmath20 by at most 3 bits , states that are simple with respect to @xmath20 are simple with respect to @xmath37 .",
    "those 3 bits are the price to pay for a small upper bound on average information .",
    "the average conditional algorithmic information @xmath214 obeys the close double bound eq .",
    "( [ avhuffbounds ] ) and exceeds the huffman bound @xmath63 by at most @xmath38 bits .",
    "this half bit is the price to pay for the recognition of intrinsically simple states .",
    "we have shown that any universal computer @xmath20 can be modified in such a way that ( i ) the modified universal computer @xmath37 recognizes the same intrinsically simple states as @xmath20 and ( ii ) average algorithmic information with respect to @xmath37 obeys the same close double bound as huffman coding , @xmath215 .",
    "if for any choice of a universal computer @xmath20 , total free energy is defined with respect to the corresponding modified universal computer @xmath37 , i.e. , if the change of total free energy due to finding the system in the @xmath11th state is @xmath216 $ ] , then the bounds for the average change in total free energy are given by @xmath217 instead of by eq .",
    "( [ febounds ] ) .",
    "this result effectively eliminates the undetermined computer - dependent constant from applications of algorithmic information theory to statistical physics . except for an unavoidable loss due to the coding bounded by @xmath7 , on the average available",
    "work is independent of the information the observer has acquired about the system , any decrease of the statistical entropy being balanced by an equal increase in algorithmic information ."
  ],
  "abstract_text": [
    "<S> given a list of @xmath0 states with probabilities @xmath1 , the average conditional algorithmic information @xmath2 to specify one of these states obeys the inequality @xmath3 , where @xmath4 and @xmath5 is a computer - dependent constant . </S>",
    "<S> we show how any universal computer can be slightly modified in such a way that the inequality becomes @xmath6 , thereby eliminating the computer - dependent constant from statistical physics . </S>"
  ]
}