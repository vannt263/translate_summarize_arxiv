{
  "article_text": [
    "= -1 over the last years data has become a more and more critical asset both in research and in application . while there is a general agreement on the need for data citation to ensure research reproducibility and to facilitate data reuse , the research community is still debating how to concretely realise it . citing data is not a trivial task since it has a few notable differences from citing literature : data evolve over time",
    ", data availability might change over time , only a subset of data might be relevant , and on top of that the authorship of data is not always clear since it may be the result of an automated process ( _ e.g._sensor data ) , involve a large number of contributors ( _ e.g._crowdsourcing ) , or even be built on the top of other data ( _ e.g._inferring a taxonomy from a document corpus ) .",
    "levering on the insights provided by @xcite , @xcite , @xcite , and @xcite we outline the following data citation functional requirements :    * _ identification and access _ : data citation should provide a persistent , machine readable , and globally unique identifier for data ; moreover a reference to a persistent repository should also be provided to facilitate data access . * _ credit and attribution _ : data citation should facilitate giving credit and legal attribution to all contributors to the data .",
    "such contributors might be humans as well as automated processes such as reasoners ; * _ evolution _ : data citation should provide a reference to the exact version of the cited data , since data might change over time .",
    "this is a fundamental requirement for research reproducibility purposes .",
    "an additional , non functional requirement , is efficiency : the data citation should lead to the data in practical time , which means fast enough for the purposes of data consumer applications .",
    "for instance a database query allows to access the data in practical time , while solving a complex set of logical clauses probably does not .    in the last years linked data has rapidly emerged as the preferred format for publishing and sharing structured data , creating a vast network of interlinked datasets @xcite .",
    "however the open nature of the format makes data provenance hard to track , moreover the rdf recommendation does not provide a clear mechanism for expressing meta - information about rdf documents .",
    "semantic web technologies such as owl , rdf , and rdfs leverage upon description logic and first order logic and it is well known that an incautious usage of their primitives may lead to non decidable sets of conditions @xcite .    with respect to the requirements of a good data citation expressed above , the semantic web community has proposed a number of solutions to the data provenance problem which addresses the problem of assessing the authorship of data . methods for partitioning rdf graphs",
    "have been proposed as well and also version identification and storage of rdf data have already been discussed .",
    "however most of those solutions imply the embedding of meta - information inside rdf data .",
    "this practice tends to make data cumbersome and the usage of reification @xcite to realise tasks such as generating data subsets may lead to a combinatorial explosion of triples .    in this paper",
    "we discuss a simple framework to satisfy data citation requirements levering on the stratification of linked data , which basically means providing a separation between proper data and meta - information .",
    "such separation can be effectively guaranteed with the usage of a simple type system allowing programs such as reasoners to discriminate in an efficient way .",
    "we would also like to show that the fact that linked data technologies such as rdf and owl are powerful enough to let you seamlessly represent and embed meta - information inside the data does not mean that you really _",
    "should_.    [ [ synopsis ] ] synopsis + + + + + + + +    complements the introduction with a concise survey of related work and pointers for the interested reader",
    ". recalls an established formalisation of meta - information over linked data that abstracts from implementation dictated details and conventions .",
    "this formalisation is completed with a simple yet expressive algebra and an abstract notion of reasoner which offer the formal context for developing the paper main contribution .",
    "said contribution is introduced in and is a notion of _ coherence for ( meta)information _ capable of characterising properties of information organisation .",
    "this result is augmented with the notion of _ coherent reasoner _ _ i.e._an abstract characterisation of reasoners that can operate on coherent data while preserving such cornerstone property .",
    "finally , we investigate the cost of verifying and preserving coherency :    * in we introduce a type system that allows us to reduce coherence checking to type checking ; type inference can be applied to derive type - annotations in order to speed - up future checks . * in",
    "we reduce coherence checking to suitable graph problems thus deriving an algorithm that can asses whether a given data store is coherent during a single read _",
    "i.e._in linear time .",
    "* this verification algorithm proceeds incrementally ; we show how , given a coherent data store , the algorithm can check whether an operation preserves coherency .",
    "remarkably , this on - the - fly check has negligible costs : linear to the number of entries created , deleted or updated .",
    "each subsection is completed with a short _ takeaway message _ paragraph containing general remarks and intuitions aimed at rendering the technical results more accessible . in we discuss how these results and notions may be translated into practice : in particular , we envision a new modelling layer with richer language support on top of existing technologies such as rdf .",
    "final remarks are provided in .",
    "data citation has already been explored by the semantic web community and it significantly overlaps with the problem of assessing data provenance since determining the authorship of data is vital for citation purposes and both tasks need meta - information over data .",
    "provenance has already been widely discussed by the semantic web community leveraging on the insights provided by the database community @xcite .",
    "provenance information can be represented exploiting two approaches : the annotation approach and the inversion approach @xcite . in the first approach all meta - information",
    "is explicitly stated , while in the latter is computed when needed in a lazy fashion which requires external resources containing the information upon which provenance is entailed to be constantly available .",
    "the annotation approach is favoured since it provides richer information and allows data to be self - contained ; several vocabularies have been proposed to describe meta - information over linked data such as _ void _ ( vocabulary of interlinked datasets ) @xcite , that offers a rich language for describing semantic web resources built on top of well known and widely used ontologies such as foaf and dublincore , and _ prov ontology _",
    "( prov - o ) , which is the lightweight ontology for provenance data standardized by the w3c provenance working group .",
    "regardless of the vocabulary used , adopting the annotation approach will result in producing a lot of meta - information which might exceed the actual data in size : provenance data in particular increases exponentially with respect to its depth @xcite . for more information about the problem of data provenance , we reference the curious reader to @xcite .",
    "the state of the art technique for embedding meta - information in rdf , is reification @xcite which consists in assigning a uri to a rdf triple by expressing it as an _ rdf : statement _ object .",
    "recently the rdf 1.1 recommendation @xcite introduced the so called `` rdf quad semantic '' which consists in adding a fourth element to rdf statements which should refer to the name of the graph which the triple belongs to .",
    "the actual semantic of the fourth element however is only hinted , leaving room for interpretation and therefore allowing semantics tailored to fit application needs . in @xcite",
    "is presented a methodology for citing linked data exploiting the quad semantics : the fourth element is used as identifier for rdf predicates allowing the definition of data subsets .",
    "other usages of the fourth element include specification of a time frame , uncertainty marker , and provenance information container @xcite . finally , the idea of using a type system to ease the fruition of semantic resources is not new to the semantic web community : the authors of@xcite propose a type system to facilitate programmatic access to rdf resources .",
    "in this section we provide a uniform formalisation of meta - information over linked data and of the related operations .",
    "our formalisation abstracts over implementation details ( such as how triples are extended with a fourth element ) retaining all relevant information .",
    "= -1 a _ named graph _",
    "( herein ng ) is a labelled set of triples and may consist in a single labelled statement or in a larger set including multiple statements .",
    "usually in rdf data triples are labelled using _ reification _",
    ", however to the extents of our discussion how the triples are labelled is irrelevant . following the formalisation proposed in @xcite",
    "we define a family of ngs as a 5-tuple @xmath0 where :    @xmath1 is a set of iris ;    @xmath2 is a set of literals ;    @xmath3 is a set of blank nodes ;    @xmath4 is the union of the pairwise disjoint @xmath1 , @xmath2 , and @xmath3 ;    @xmath5 is a set of assignments @xmath6 mapping each @xmath7 to at most one triple @xmath8 .",
    "equivalently , the set @xmath5 can be read as a partial function @xmath9 called _ naming function _ of the ng family .",
    "the set @xmath4 is called _ vocabulary _ of the ng family for it defines all the iris , literals etc .  appearing in the family .",
    "note how every pair in @xmath5 consists in a label ( the first element ) and a non void rdf graph ( the second element ) , thus is an ng .",
    "it is important to stress how the above formalisation holds regardless of the actual technique employed to associate an identifier to a named graph .    intuitively , assigning an iri to a triple puts that iri in the rle of _ meta - information _ w.r.t .  that triple whence thought as _",
    "information_. note that the separation between information and meta - information is not absolute but _ relative _ to the context _",
    "i.e._the level where the reasoning happens . for an example , consider the rdf snipped :    ....      $ x$ type       statement      $ x$ subject    $ y$      $ x$ predicate $ b$      $ x$ object     $ c$      $ y$ type       statement      $ y$ subject    $ a$      $ y$ predicate $ b$      $ y$ object     $ c$     ....    accordingly to the reification semantics , here @xmath10 is assigned to triple @xmath11 and @xmath12 to the triple @xmath13 hence , can be seen as an ng family whose @xmath5 is corresponds to the assignments : @xmath14 clearly , @xmath12 plays the rle of meta - information with respect to the triple @xmath13 and @xmath10 plays the rle of meta - information about @xmath11 whence @xmath13 .",
    "w    [ rem : blank - nodes ] since the presence of blank nodes arises several non trivial problems for the purposes of merging and comparing linked data , the last w3c recommendation suggests the replacements of blank nodes with iris when data references are expected . linked data including blank nodes are still common on the web , but one can always assume the existence a renaming function @xmath15 assigning unique iris to blank nodes .",
    "= -1 above we recalled ng families as introduced in @xcite however , because of remark  [ rem : blank - nodes ] , we could equivalently characterise them by their associated naming function alone . clearly , every 5-tuple @xmath0 describing a family of ngs uniquely induces a naming function @xmath16 but the opposite is not true in general .",
    "this can be traced down to the later lacking information the separation of @xmath17 into blank nodes and literals . as a consequence of remark  [ rem : blank - nodes ]",
    "we can safely assume @xmath18 and hence recover @xmath2 as @xmath17 .",
    "formally , for a naming function @xmath9 , define the associated ng family as follows :    a.   @xmath5 is the function graph of @xmath16 _ i.e. _ @xmath19 b.   @xmath4 is the first or third projection of @xmath16 codomain _ i.e. _",
    "@xmath20 c.   @xmath1 is the second projection of @xmath16 codomain _ i.e. _ @xmath21 d.   @xmath2 is the difference @xmath22 ; e.   @xmath3 is empty .",
    "we use the two presentations interchangeably .    [",
    "[ takeaway - message ] ] takeaway message + + + + + + + + + + + + + + + +    along the lines of @xcite , we described an abstract formalisation encompassing rdf data triples labelled using reification , among other equivalent representations .",
    "the main reason behind this effort is to have a disciplined representation that :    avoids the use of reification while retaining its expressive power ;    hides conventions and idiosyncrasies due to implementation details ;    clearly separates information from meta - information .",
    "families of named graphs can be organised into the partial order defined as : @xmath23 intuitively , @xmath24 means that @xmath25 has more data than @xmath16 but does not carry any implication on the semantic of such information since , for instance , the former may contain semantically inconsistent information not held by the latter .",
    "we say that @xmath25 _ is an extension of _",
    "@xmath16 whenever @xmath24 .",
    "note that @xmath16 and @xmath25 are not required to have the very same set of iris and literals ( hence vocabulary ) .",
    "in fact , for any pair of ng families @xmath9 and @xmath26 , the only information about @xmath1 , @xmath27 , @xmath4 , and @xmath28 we can infer from @xmath24 is that @xmath27 and @xmath28 overlap with @xmath1 and @xmath4 where @xmath16 is defined . formally : @xmath29 two families are equivalent iff they extend each other : @xmath30 = -1 clearly , @xmath31 is an equivalence relation and all of its equivalence classes have a canonical representative family _",
    "i.e._the unique and minimal element in the class .",
    "intuitively , to obtain such family we only need to start with any family in the equivalence class and trim its vocabulary and set of iris by removing any element that does not appear in the naming function range or image _ i.e._remove everything but @xmath32 , @xmath33 , @xmath34 , @xmath35 such that @xmath36 .",
    "empty families form an equivalence class @xmath37 represented by the unique naming function for the empty vocabulary .",
    "hereafter , we shall not distinguish families in the same equivalence class , unless otherwise stated .",
    "a ng family is called _ atomic _ whenever it assigns exactly one name _ i.e._a naming function @xmath16 that defined exactly on one element of its domain .",
    "we shall denote atomic families by their only assignment : @xmath38 which corresponds to the rdf triple @xmath39 plus the fourth element @xmath10 that identifies the named graph .    from the order - theoretic perspective , atomic ng",
    "families are atoms for the order @xmath40 .",
    "in fact , @xmath16 is atomic iff : @xmath41 for the sake of simplicity , we shall abbreviate @xmath42 as @xmath13 when the particular choice of @xmath10 is irrelevant and confusion seems unlikely ; we still assume @xmath10 to be implicitly unique in the context of its use .",
    "in general , any non - empty set @xmath43 of ng families admits a minimal element @xmath44 given by the intersection of all the families in @xmath43 or , using the naming function presentation , to : @xmath45 from which it is immediate to see that @xmath46 for any @xmath47 .",
    "we may denote @xmath48 by @xmath49 when confusion seems unlikely .",
    "it could be tempting to dualise @xmath50 defining maximal elements as follows : @xmath51 however , note that this represents the merging of heterogeneous data and may not yield an ng - family , hence is not a total operation .",
    "for instance , consider any set containing some @xmath16 and @xmath25 assigning some @xmath32 to different triples _",
    "e.g. _ : @xmath36 and @xmath52 where @xmath53 .",
    "the operation can be turned into a total one without altering the definition of ng family by adopting some resolution policy for conflicting overlaps : discarding both , either , introducing suitable renaming , or more sophisticated techniques developed under the name of _ _ ontology alignment _ _ a complex task whose formalisation exceeds the scope of this work . in the remaining of this subsection we show how the aforementioned simple conflict resolution policies yield `` surrogate '' operators for @xmath54 corresponding to specific and well - known operations .    before defining these operations let us introduce some auxiliary definitions and notation . for an ng family @xmath9 ,",
    "its _ support _ is the subset @xmath55 of @xmath1 whose elements are assigned to some graph by @xmath16 : @xmath56 for a pair of families @xmath57 and @xmath58 , their _ conflict set _ @xmath59 is the set of iris being assigned to different graphs by @xmath57 and @xmath58 , _",
    "i.e. _ : @xmath60 for a family @xmath16 , an injective map @xmath61 from its vocabulary defines a renamed family @xmath62 $ ] : @xmath63(u ) =       \\begin{cases }          ( \\sigma(a),\\sigma(b),\\sigma(c ) )   & \\text{if } n(u ' ) = ( a , b , c ) \\land \\sigma(u ' ) = u\\\\          { \\perp } & \\text{otherwise }       \\end{cases}\\ ] ] we adopt the convention that any renaming @xmath64 implicitly extends to a renaming on any superset of @xmath4 that acts as @xmath61 on @xmath4 and as the identity elsewhere .",
    "the first `` surrogate '' for @xmath65 resolves conflicts by ignoring any conflicting information from @xmath58 .",
    "formally : @xmath66 we call this operation a surrogate for binary joins since it is total and agrees with joins whenever they are defined : @xmath67    the operation @xmath68 is associative : @xmath69 has the empty family as a left and right unit : @xmath70 is idempotent : @xmath71 and hence defines an idempotent monoid of ng families . in general , @xmath68 is not commutative : it is easy to check that commutativity does not hold unless @xmath57 and @xmath58 agree wherever both are defined _ i.e._the set of conflicts @xmath59 is empty .",
    "the operation @xmath68 is monotonic : @xmath72 and distributes over meets : @xmath73    the second `` surrogate '' for @xmath65 uses an approach symmetric to @xmath68 by discarding conflicting data from its first operand .",
    "because of the symmetry , it will be denoted as @xmath74 and presented simply mirroring @xmath68 : @xmath75 like @xmath68 , this operation yields an idempotent monoid over ng families ; moreover , both operations share the same unit and distribute over each other .",
    "a third option is to resolve conflicts by discarding every data assigned to iris in the conflict @xmath76 although this operation may seem more drastic than @xmath68 and @xmath74 , @xmath77 treats its operands equally and coincides with @xmath54 whenever the later is defined . as a consequence ,",
    "@xmath77 is commutative , associative , idempotent and has a unit .",
    "note that the conflict set between @xmath78 and @xmath57 or @xmath58 is always empty and hence the following equations are well - defined and hold true : @xmath79 _ vice versa _ , @xmath77 can be derived from @xmath68 and @xmath74 : @xmath80    we introduce a surrogate for @xmath65 that handles conflicts without discarding any information from its operands by renaming all conflicting assignments made by @xmath57 and @xmath58 .",
    "intuitively , this may be though to be implemented by `` doubling '' the conflict set as : @xmath81 in general , we abstract from specific renaming policies by assuming a pair of injective maps @xmath82 and @xmath83 such that the conflict set @xmath84\\lightning n_2[\\sigma_2])$ ] is empty . referring to the intuitive implementation described above , each renaming @xmath85 , for @xmath86 in @xmath87 , is defined as follows : @xmath88 then , the last operator is defined as @xmath89    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } n_2 ) { \\triangleq}n_1[\\sigma_1 ] \\sqcup n_2[\\sigma_2 ]      \\text{.}\\ ] ] the binary join @xmath90\\sqcup n_2[\\sigma_2]$ ] is always well - defined since @xmath84\\lightning n_2[\\sigma_2])$ ] is empty by assumption on the renaming maps @xmath82 and @xmath83 and @xmath90\\sqcup n_2[\\sigma_2 ] = n_1 \\sqcup n_2 $ ] whenever @xmath91 .",
    "we extend the conventions introduced for @xmath50 to the operations @xmath74 , @xmath68 , @xmath77 , and @xmath92    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } $ ] : we shall use @xmath92    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } \\{n_1,\\dots , n_k\\}$ ] for @xmath93    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } n_2 {   \\mathbin {     \\mathpalette {       \\sbox0{$\\boxplus\\m@th$ }   \\dimen2=.5\\dimexpr\\wd0-\\ht0-\\dp0\\relax    \\dimen@=\\dimexpr\\ht0+\\dp0\\relax    \\def\\lw{.06 }   \\kern\\dimen2    \\tikz [      rotate=180 ,      line width=\\lw\\dimen@ ,      line join = round ,      x=\\dimen@ ,      y=\\dimen@ ,    ]    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } \\dots {   \\mathbin {     \\mathpalette {       \\sbox0{$\\boxplus\\m@th$ }   \\dimen2=.5\\dimexpr\\wd0-\\ht0-\\dp0\\relax    \\dimen@=\\dimexpr\\ht0+\\dp0\\relax    \\def\\lw{.06 }   \\kern\\dimen2    \\tikz [      rotate=180 ,      line width=\\lw\\dimen@ ,      line join = round ,      x=\\dimen@ ,      y=\\dimen@ ,    ]    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } n_k$ ] and _ vice versa_.    every ng family can be defined using the constants and operations described in this subsection .",
    "more complex operations such as inferences are described in the remaining part of this section .",
    "[ [ takeaway - message-1 ] ] takeaway message + + + + + + + + + + + + + + + +    in this subsection we introduced a simple yet expressive algebra for describing ng families .",
    "although , more convenient constructs , operations or sophisticated techniques are not part of this algebra , we believe they can be easily implemented on top of it hence suggesting the use of this algebra as a _ core _",
    "language for targeting ( via compilation ) any chosen implementation of ng families such as reified rdf @xcite or graphical models like @xcite .      in this subsection",
    "we formalise the problems of provenance , subsetting , and versioning in the setting of ng families as formalised above . to this end , we introduce an abstract and general notion of _ abstract reasoner _ subsuming any process ( automatic or not ) transforming ng families . at this level of abstraction",
    "we formalise the problem of understanding whether    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ `` @xmath10 in @xmath16 has been generated by @xmath94 '' _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    for an iri @xmath10 , a named graph family @xmath16 and reasoner @xmath94 and",
    "then show how provenance , subsetting , and versioning are covered as instances of the above .",
    "[ def : abstract - reasoner ] an _ ( abstract ) reasoner _ is a ( partial ) function over ng families .    for a simple example , consider a reasoner that expands a family @xmath16 by computing the transitive and reflexive closure of any predicate @xmath34 that @xmath16 describes as being transitive or reflexive _",
    "e.g._by means of some graph @xmath95 .",
    "such reasoner can be described as assigning to any family @xmath16 the least family closed under the derivation rules : @xmath96 hence @xmath97 .",
    "likewise , symmetry can be computed by means of : @xmath98 and reversible predicates by means of : @xmath99 these examples describe _ monotonic _ reasoners since @xmath100 for any family @xmath16 ; however , an abstract reasoner may be non - monotonic as well : consider for instance a human annotator performing a revision of an ontology , such an annotator is likely to both add and withdraw triples from the knowledge base and still fits the definition of an abstract reasoner .",
    "a simple example of situation where the withdrawal of a triple is needed to keep data consistent is offered by the derivation rule : @xmath101    all examples of reasoners described so far essentially work at the triple level for they never really follow any iri .",
    "this kind of reasoner never crosses the boundary between information and meta - information but this is not true in general .",
    "actually , crossing such boundary is often necessary when reasoning about the ( meta)information stored in an ng family as we introduce reasoners that handle operations over meta - information such as tracking data authorship , extracting data subsets , and managing versions . before we delve into this topic ,",
    "let us introduce some auxiliary reasoners and definitions that allow us to describe such reasoners as well .",
    "for an abstract reasoner @xmath94 and a family @xmath16 , define the sets of created , updated , and deleted assignments as : @xmath102 given @xmath16 and @xmath94 , computing the above sets could be prohibitively demanding even under the assumption of ng families being finite . in practice ,",
    "changes are recorded by explicitly tagging all affected assignments . since this good practice",
    "is not imposed by definition  [ def : abstract - reasoner ] we introduce new reasoners that extend the output of any given reasoner @xmath94 with this tagging information . @xmath103",
    "\\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } \\{(\\gamma,\\mathtt{new},x ) \\mid x \\in c_\\gamma(n ) \\}\\\\",
    "\\delta^u_\\gamma(n ) & { \\triangleq}\\gamma(n ) {   \\mathbin {     \\mathpalette {       \\sbox0{$\\boxplus\\m@th$ }   \\dimen2=.5\\dimexpr\\wd0-\\ht0-\\dp0\\relax    \\dimen@=\\dimexpr\\ht0+\\dp0\\relax    \\def\\lw{.06 }   \\kern\\dimen2    \\tikz [      rotate=180 ,      line width=\\lw\\dimen@ ,      line join = round ,      x=\\dimen@ ,      y=\\dimen@ ,    ]    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } \\{(\\gamma,\\mathtt{upd},x ) \\mid x \\in u_\\gamma(n ) \\}\\\\",
    "\\delta^d_\\gamma(n ) & { \\triangleq}\\gamma(n ) {   \\mathbin {     \\mathpalette {       \\sbox0{$\\boxplus\\m@th$ }   \\dimen2=.5\\dimexpr\\wd0-\\ht0-\\dp0\\relax    \\dimen@=\\dimexpr\\ht0+\\dp0\\relax    \\def\\lw{.06 }   \\kern\\dimen2    \\tikz [      rotate=180 ,      line width=\\lw\\dimen@ ,      line join = round ,      x=\\dimen@ ,      y=\\dimen@ ,    ]    \\draw      ( \\lw/2,0 ) rectangle ( 1-\\lw,1-\\lw )      ( \\lw,0 ) -- ( .5,1-\\lw-\\lw/2 ) -- ( 1-\\lw-\\lw/2 , 0 )    ;   \\kern\\dimen2 } } \\{(\\gamma,\\mathtt{del},x ) \\mid x \\in d_\\gamma(n ) \\}\\end{aligned}\\ ] ]    everything added by one of the above reasoners to the output of @xmath94 is meta - information with respect to said output .",
    "as expected , this data enables reasoning on the evolution of the family itself .",
    "for instance , consider the following simple inference that reconstructs which reasoner used other reasoners by looking whether they recorder their activity : @xmath104 = -1 clearly , any reasoning on the evolution of a named family due to the action of reasoners ( via the oversight of @xmath105 , for exposition convenience ) inherently require that some references stored as named graphs are followed hence that the boundary between information and meta - information is crossed at some point .",
    "levering on these definitions , one can easily describe reasoners that realise authorship attribution over data with different granularity , reasoners to label and extract data subsets and versions .",
    "[ [ takeaway - message-2 ] ] takeaway message + + + + + + + + + + + + + + + +    in this section , we unearthed the core issues arising from reasoning about information and meta - information as well and provided a framework for describing all operations needed to perform data citation .",
    "since our formal treatment has been carried at the abstract level of named graph families , we have shown how these issues are inherent to the problem and independent from implementation details and specific techniques such as reification .",
    "in this section we characterise a class of ng families called _ well - stratified _ with the fundamental property of stratifying meta - information over information in a way that prevents any infinite chain of `` downward '' references where the direction is interpreted as crossing the boundary between meta - information and information .",
    "since practical ng families ( hence triple stores ) contain only a finite amount of explicit information , absence of such chains corresponds to the absence of reference cycles like , for instance , in the ng family : @xmath106 we characterise a class of abstract reasoners , called _ coherent _ , that preserve well - stratification of named graph families they operate on .",
    "finally , we introduce a decidable and efficient procedures for assessing the well - stratification of an ng family and operations on them .",
    "before we define well - stratified ng families , let us recall some auxiliary notions and notation .",
    "a binary relation @xmath107 on a ( non necessary finite ) set @xmath108 is called _ well - founded _ whenever every non - empty subset @xmath43 of @xmath108 has a minimal element _",
    "i.e._there exists @xmath109 that is not related by @xmath110 for @xmath111 .",
    "this means that we can intuitively walk along @xmath107 going from right to left for finitely many steps _",
    "i.e._we have to stop , eventually .",
    "in fact , well - foundedness can be reformulated say that @xmath107 contains no ( countable ) infinite descending chain ( _ i.e._an infinite sequence @xmath112 such that @xmath113 ) .",
    "the predecessor relation @xmath114 on the set of natural numbers is well - founded .",
    "the prefix and suffix relations on the set @xmath115 of finite words over the alphabet @xmath116 is well - founded .",
    "any acyclic relation on a finite set is ( trivially ) well - founded .",
    "point - wise and lexicographic extensions of well - founded relations are well - founded .    = -1",
    "this kind of relations are common - place in mathematics and computer science since they provide the structure for several inductive and recursive principles and , with regard to this work aim , approaches for proving termination .",
    "intuitively , the idea is to equip the state space of an algorithm with a well - founded relation and then show that each step of the algorithm travels such relation right to left ( descends ) . by well - foundedness hypothesis ,",
    "all descent paths are bound to terminate in a finite number of steps .",
    "[ [ takeaway - message-3 ] ] takeaway message + + + + + + + + + + + + + + + +    well - founded relations such as the successor relation over natural numbers are at the core of several techniques used to prove termination .",
    "such techniques revolve around the idea of reducing the problem under scrutiny to walks along said well - founded relation and hence termination follows by the fact that any such ( descending ) walk can not be infinite .",
    "the intuitive desiderata of an ng family being free from infinite paths descending along the ( meta-)information chain is formally captured by the following definition .",
    "a family of named graphs is called _ well - stratified _ whenever it comes equipped with a well - founded relation @xmath117 on its vocabulary s.t .",
    "@xmath16 descends along @xmath118 _ i.e. _ @xmath119 the relation @xmath118 is called _ witness _ for @xmath16 .",
    "following any chain of assignments @xmath120 described by a well - stratified ng family has to eventually terminate since each step corresponds to a step along @xmath118 which is well - founded by hypotheses .",
    "thus , any reasoner based on such visits is bound to terminate as long as it descends along @xmath118 and each internal step in its chain is decidable . moreover , for a given ng family the length of these chains is known and bounded .",
    "operations described in section  [ sec : ng - algebra ] preserve well - stratification under the assumption that all operands can share their witness @xmath118 .",
    "abstract reasoners may easily break well - stratified stores .",
    "intuitively most reasoning tasks and well - engineered human annotation processes should be coherent , however breaking the well - stratification of data is subtle and can be achieved even with monotonic reasoning .",
    "for instance , consider a set of triples where there exists a triple @xmath121 labelled with some iri @xmath10 and an abstract reasoner @xmath94 that adds a new triple @xmath122 labelled as @xmath12 .",
    "this insertion is totally legit if we are using reification but introduces a circularity in the chain of meta data since the family now contains the following assignments : @xmath123 and hence is no more well - stratified .    an abstract reasoner is called _ well - behaved _ whenever it preserves well - stratification .",
    "reasoners for provenance , subsetting , and versioning are well - behaved for they cross the boundary between information and meta - information only in one direction : descent .    in general , assessing whether a reasoner is well - behaved may not be immediate especially since definition  [ def : abstract - reasoner ] describes them as `` black boxes transforming ng families '' .",
    "there are several ways for describing classes of abstract reasoners with different degrees of expressivity .",
    "covering all of them is out of the scope of this work and indeed impossible , still derivation rules are a presentation fit for many reasoners ( like the ones described so far ) and well known across the computer science community .",
    "this approach allows to quickly inspect the `` internals of the box '' and statically prove a reasoner well - behaved .",
    "moreover , it is possible to define reasoners that are `` well - behaved by design '' by imposing suitable syntactic constraints on these derivation rules akin to rule formats developed in the field of concurrency theory ( _ cf._@xcite ) .",
    "albeit interesting , this topic can not be fully developed in the context of this work .",
    "[ [ takeaway - message-4 ] ] takeaway message + + + + + + + + + + + + + + + +    in this subsection we characterised a class of ng families that stratify meta - information over information without creating incoherences such as loops . in general",
    ", reasoners may easily break this cornerstone property and treating them as black boxes prevents any practical attempt to statically check whether they really break well - stratification .",
    "however , with access to enough information about the internal working of a reasoner ( _ e.g._its description in terms of derivation rules ) , established formal methods can be applied to prove it well - behaved ; even develop languages for creating reasoners guaranteed to be well - behaved .",
    "remarkably , reasoners for provenance , subsetting , and versioning admit well - behaved implementations .",
    "ng families share some similarities formal graphical languages like bigraphs and hierarchical graphs .",
    "this observation suggest to introduce a simple type system , along the line of @xcite , with a special type whose inhabitants are exactly well - stratified ng families",
    ". then , to verify if a given family is well - stratified it would suffice to check if it is well - typed .",
    "for the aims of this work , we introduce a simple type system whose only type @xmath124 is inhabited by exactly well - stratified families .",
    "judgements are of the form @xmath125 where @xmath9 is a family of named graphs and the stage @xmath126 is a partial function from the vocabulary @xmath4 to a well - founded structure .",
    "for instance , could map @xmath4 to the set of natural numbers under the successor relation : @xmath127 .    the proposed type system is composed by three typing rules : @xmath128      \\frac {          \\gamma(x ) >",
    "\\gamma(a )          \\quad          \\gamma(x ) >",
    "\\gamma(b )          \\quad          \\gamma(x ) >",
    "\\gamma(c )      } {          \\gamma \\vdash { { x\\mapsto(a , b ,",
    "c)}}\\colon \\checkmark      }      \\\\[5pt ]      \\frac {          \\gamma_1 \\vdash n_1 \\colon \\checkmark          \\quad          \\gamma_2 \\vdash n_2 \\colon \\checkmark          \\quad          \\gamma = \\gamma_1 \\sqcup \\gamma_2          \\quad",
    "n = n_1 \\sqcup n_2      } {          \\gamma \\vdash n\\colon \\checkmark      } \\end{gathered}\\ ] ] the first captures the fact that the empty family is always well - stratified .",
    "the second ensures that @xmath126 describes relations on @xmath4 such that the assignment @xmath42 is well - stratified .",
    "finally , the third rule allows to break @xmath16 and @xmath126 reducing the problem to smaller objects which can then be checked separately ( clearly , applying this rule with either @xmath57 or @xmath58 being @xmath37 is pointless ) .",
    "regardless of the structure used as codomain , @xmath126 determines a class of relations on @xmath4 that are well - founded where @xmath126 is defined : for a relation @xmath118 on @xmath4 s.t . :",
    "@xmath129 the restriction of @xmath118 to @xmath55 is clearly well - founded .",
    "this property is enough to guarantee that any family @xmath16 such that @xmath130 ( _ i.e._is well - typed ) is well - founded .",
    "in fact , because of the above typing rules , @xmath126 must be defined on every iri and literal occurring in @xmath16 and hence @xmath118 as above is a witness for @xmath16 being well - stratified .    we do not need to `` guess '' @xmath126 .",
    "this function can be obtained by applying the above typing judgements while considering @xmath126 as an unknown collecting all the hypotheses on it ( _ e.g._@xmath131 from the second rule ) in a set of constraints .",
    "any partial function satisfying these constraints can be used as @xmath126 to derive @xmath130 .",
    "although computing such solutions can be done pretty efficiently , at this point it suffices to prove solution existence to prove @xmath16 well - stratified .    in practice",
    ", type checkers may be helped by providing typing annotations as separate meta - data , as primitives of a specialised language for ng families , or just as comments like in the following rdf snipped :    ....      //",
    "$ x$ : 4 ; $ y$ : 2 ; $ b$ , $ c$ : 0      $ x$ type       statement      $ x$ subject    $ y$      $ x$ predicate $ b$",
    "$ x$ object     $ c$ ....    this statically computed information can be used to optimise reasoners since @xmath132 provides an upped bound to the length of meta - information / information steps starting from @xmath10 . as we show in subsection  [ sec : ws - with - graphs ] , the very same information can be used to efficiently reject any operation that breaks well - stratification .",
    "[ [ takeaway - message-5 ] ] takeaway message + + + + + + + + + + + + + + + +    in this subsection we characterised well - stratified ng families by means of a simple type system and showed the type inference problem to be decidable .",
    "this approach suggests to explore the use of more expressive type systems and sortings in order to express / enforce richer properties about ng families .",
    "moreover , the connection between ng families and formal graphical models suggests the possibility to extend compositionality results such us those offered by _",
    "monoidal sortings _",
    "@xcite to this settings .      for a family @xmath16",
    "whose support @xmath55 is finite , the only way to not be well - stratified is to contain cycles of dependencies between information and meta - information : the only way for a relation on a finite set to not be well - founded is to contain cycles .",
    "therefore , if we read assignments described by @xmath16 as arcs in a directed graph we can reduce the problem of checking if @xmath16 is well - stratified to checking if this `` graph of dependencies '' is free from cycles .    for an ng family @xmath16 its _ dependency graph",
    "@xmath133 is a graph with @xmath55 and @xmath134 as its set of nodes and edges , respectively .    for a family @xmath16 containing a finite amount of _ explicit _ meta - information ( as in any real - world scenario ) well - stratification",
    "can be checked with time cost linear to the number of assignments described by @xmath16 ( _ i.e._the cardinality of the set @xmath55 ) .    for a family of named graphs @xmath16 such that @xmath55 is finite , @xmath16 is well - stratified if and only if its dependency graph @xmath133 is a directed acyclic graph .    by hypothesis on @xmath16 ,",
    "@xmath133 has finitely many edges and nodes hence the only way for it to contain an infinite path is to have a directed cycle .",
    "absence of directed cycles reduces to the existence of a topological sorting which can be easily computed in polynomial time with tarjan s algorithm . intuitively , this amounts to a depth first visit of the dependency graph @xmath133 : a graph whose nodes have at most three outgoing edges , hence the time complexity actually is linear .",
    "well - stratification can be checked with a time cost linear in the size of @xmath55 .    because of the size that real - world triple stores can reach , computing a topological sorting of @xmath133 from scratch every time an operation on @xmath16 is performed can be a daunting task . in the remaining of this section",
    "we describe how to efficiently and precisely reject all changes that will break well - stratification .    in section  [ sec :",
    "ng - algebra ] we described a core algebra for ng families highlighting that complex transformations basically reduce to insertions and deletions of name assignments ( updates are modelled as atomic pairs of deletions and insertions , as usual ) . clearly , deleting a named assignment preserves well stratification and hence only insertions need to be checked before being carried out .    a way to curb this cost is to cache the information about on the topological sorting in a map from @xmath55 to some linear order relation on a dense but limited set such us the rational part of the interval @xmath135 .",
    "this order relation is not well - founded but it is acyclic and hence any restriction to a finite subset of @xmath135 is well - founded . moreover , being dense , we can always `` make room '' for newly inserted ( meta)information .    in the following",
    "let @xmath16 be a well - stratified ng family and let @xmath136 be a partial map from @xmath1 to the subset of rational numbers : @xmath137 under the assumption that we start from an empty family @xmath16 and an empty map @xmath136 , the algorithm ensures that after an arbitrary sequence of insertions    * @xmath136 is defined exactly on every element occurring in @xmath16 as information or meta - information ; * the natural order on @xmath138 defines a well - founded relation on all elements where @xmath136 is defined ; * an operation is rejected if , and only if , it does not preserve well - stratification of @xmath16 .",
    "note that the first two points imply well - stratification .",
    "consider the insertion of @xmath42 in @xmath16 . since @xmath139",
    "we have to consider two main scenarios : in the first @xmath10 does not occur in @xmath16 ( _ i.e._@xmath140 ) whereas in the second @xmath10 occur in @xmath16 as information only ( @xmath141 but @xmath142 ) .",
    "assume @xmath140 , we need to assign to @xmath10 a value above those assigned to @xmath33 , @xmath34 , and @xmath35 but below everything that we already put above these three piece of data : @xmath143 note that although the definition of @xmath144 may seem a bit convoluted , it can be readily implemented by means of an ordered set of values from @xmath136 : is exactly the first successor to @xmath12 in such structure and corresponds to an insertion right between @xmath12 and @xmath144 .",
    "assume @xmath141 , we have three sub - cases :    a.   if @xmath145 then at least one of @xmath33 , @xmath34 , or @xmath35 occurs in @xmath16 in the rle of meta - information w.r.t .",
    "@xmath10 and thus @xmath42 is rejected and the algorithm terminates .",
    "b.   if @xmath146 we need to promote @xmath10 `` pushing '' everything above it up and everything else down as in the first scenario ; therefore , @xmath147 is redefined using . c.   if @xmath148 then no further action is required .",
    "if the algorithm did not reject the operation , then it can be safely performed .",
    "the only step left is to assign the value @xmath149 to any @xmath150 for which @xmath136 is undefined .",
    "carrying out the procedure sketched above requires a constant numbers of reads and writes of the map @xmath136 whose efficiency depends on the implementation of choice but can be safely assumed as negligible .",
    "[ [ takeaway - message-6 ] ] takeaway message + + + + + + + + + + + + + + + +    as shown in the previous subsections , well - stratification is an useful property for ng families thus , being able to efficiently check    * if a family is well - stratified or * if an operation preserves well - stratification    is of vital importance . in this subsection",
    "we described how these two questions can be answered with a cost that is linear in the number of assignments ( _ i.e._the size of meta - information ) and constant , respectively .",
    "these results are strictly related to those described in subsection  [ sec : ws - with - types ] since the dependency graph @xmath133 induced by a family @xmath16 is a graph representation of the constraints on @xmath126 derived by applying type inference to @xmath16 .",
    "therefore , we can read the above results as complementing the type system we introduced with an implementation .",
    "in the previous sections we introduced the concept of well - stratified data , that is crucial to the practical realisation of data citation : as long as data is well - stratified resolving a data citation is always possible .",
    "moreover we showed how assessing the well - stratification of a data set is linear with respect to the size of the data and can be done incrementally as new statements are added to the data set . in this section",
    "we discuss how these notions may translate into practice .",
    "intuitively , for a data set to be well - stratified it means that it is always possible to draw a line separating information from meta - information while baring in mind that such separation is bound to be inherently relative to current datum . in order to illustrate this idea",
    "consider the simple example depicted in : the triple @xmath151 is the information , while its identifier @xmath1 and its related predicates represent the meta - information with respect to the datum considered _ i.e._@xmath152 .",
    "intuitively @xmath1 is the iri of the reified _ statement _ that has as subject , object , and predicate respectively @xmath153 , @xmath154 , and @xmath3 .",
    "each iri in the data set should belong to exactly one of these levels .",
    "theoretically , there should be no upper bound to the number of meta - information levels since one might be interested in expressing statements over meta - information .",
    "an hypothetical reification , for instance , of @xmath155 having as identifier @xmath156 would imply a further meta - information level containing only @xmath156 .",
    "= -1 this intuitive stratification can be seen as assigning to ( meta-)information to levels that decreases as we move from meta - information to information .",
    "the lowest level contains all the data that data citation resolution should ultimately reach .",
    "well - stratification not only ensures the existence of a lowest level but it also guarantees that wherever a reasoner starts unravelling the ( meta-)information chain it will eventually reach said level .",
    "indeed this is the approach described in and embodied by the function @xmath127 used by the type system introduced in . from a concrete perspective",
    "this means that identifiers of a reified statement should therefore be assigned a higher level by @xmath126 than their subject , object , and predicate .",
    "this condition is met if , and only if , the data set is well - stratified .",
    "finally , we remark that finding such levels can be done incrementally while reading the data set or on - the - fly as operations are performed on a well - stratified set ; the cost of the former is linear in the size of the base whereas the cost of the second is linear on the number of operations .",
    "the various data levels that can be identified this way can be considered as distinct data `` slices '' that , though linked , can be considered independent data sets and treated accordingly . for instance",
    "a large , multi - layered data set could be distributed as a whole , with all layers of meta - information or `` reduced '' to its sole data level , _",
    "i.e. _ , without meta - information . since well - stratification can be checked automatically in a reasonably efficient way and allows the separation of meta - information from ground level information , it addresses the need for such a separation introduced by state of the art data citation methodologies @xcite .",
    "such a concept , however , does not exist yet in the semantic web stack .",
    "the rdf language in fact has several limitations that make well - stratification hard to realise , and here we pinpoint the most evident :    * checking well - stratification implies , as shown in section [ sec : ws - with - types ] , the presence of a type - checking mechanism that does not exist in rdf .",
    "* there is a data - level usage of reification ( for instance to express sentences like `` bob says that alice is kind '' ) that must not be confused with the labelling of triples for meta - information expression purpose we analysed so far , and rdf does not provide a way to discriminate them . * assigning an identifier to a triple in rdf is not handy due to the bloated syntax of reification .    to overcome these limitations we strongly advocate the creation of a new language wherein the concept of well - stratification is a first - class citizen .",
    "more specifically , such a language should include in its specifications :    * a class for meta - information objects , allowing to explicitly state which triples are to be considered meta - information and which information ; * a _ level _ property that can be associated to any iri , serving as explicit annotation of the information level the iri belongs to ; * a syntax for quad semantics , _",
    "i.e. _ , switching from a language of triples ( like rdf ) to a language of quadruples where triples are considered quadruples with a void fourth element ; * a more restrictive semantics for the fourth element of the quadruple , allowing to discriminate between reification for meta - information annotation purpose from actual data level usage ; * a _ type system _ for data including well - stratified data",
    ".    given such a language the actual information would be still expressed in the form of triples , allowing compatibility with the other levels of the semantic web , and the meta - information could be handled separately .",
    "in this paper we briefly outlined a formalisation of data citation over linked data and showed how resolving authorship attribution , subset and version identification are computable in an efficient way as long as the considered data is well - stratified . because of the relevance of this property , we explored how it can be expressed and verified by means of a type system and _ ad hoc_algorithms .",
    "we showed that checking whether a given ng family ( which abstracts over the concrete form of data ) is well - stratified requires linear time and proposed a constant time solution for checking if an operation performed by any reasoner preserves or breaks this property .",
    "= -1 with respect to the problem of data citation , the expressive power of owl and rdf is largely over - abundant and might be harmful since a misuse of their primitives might break the stratification of information and meta - information , thus making resolving citations an undecidable problem . in our opinion , a more restricted language , designed specifically to grant the stratification of data should be taken into consideration to effectively enable problems such as data citation and provenance assessment to be resolved in practical time , allowing the creation of an effective data trust layer .",
    "attaching meta - information to data published on the web leveraging such a language might be , in our opinion , linked open data s sixth star , like publishing versioned code is a fundamental quality requirement for open source software . the similarity between data meta - information handling and source code versioning is striking since they address similar problems : tracking who and how edited something , identifying subsets of the managed items , and allowing external application or documents to refer to a specific revision . in our opinion",
    "this separation is also consistent with the present development of the semantic web stack : owl itself , thought being a logical extension of rdfs , is not built on the top of rdfs but is rather a distinct language sharing concepts and primitives with rdfs . in a similar way a new language for data meta - information management could be built compatibly with rdf and the linked data philosophy without being rdf .",
    "finally , this work suggests a deeper connection between formal graph models and knowledge management problems encountered by the digital libraries and semantic web communities . in our opinion",
    "a more formal take on a broad range of non trivial knowledge management tasks and practises might provide relevant insights both on the application side and on the theoretical one as suggested by preliminary works in this directions like _ e.g._@xcite .",
    "r.  bruni , a.  corradini , f.  gadducci , a.  lluch - lafuente , and u.  montanari . on gs - monoidal theories for graphs with nesting . in g.",
    "engels , c.  lewerentz , w.  schfer , a.  schrr , and b.  westfechtel , editors , _ graph transformations and model - driven engineering - essays dedicated to manfred nagl on the occasion of his 65th birthday _ , volume 5765 of _ lecture notes in computer science _ , pages 5986 .",
    "springer , 2010 .",
    "a.  mansutti , m.  miculan , and m.  peressotti .",
    "multi - agent systems design and prototyping with bigraphical reactive systems . in k.  magoutis and p.  pietzuch , editors ,",
    "dais _ , volume 8460 of _ lecture notes in computer science _ , pages 201208 .",
    "springer , 2014 .",
    "w.  wang and t.  t. hildebrandt .",
    "dynamic ontologies and semantic web rules as bigraphical reactive systems . in e.",
    "tuosto and c.  ouyang , editors , _ proc .",
    "ws - fm _ , volume 8379 of _ lecture notes in computer science _ , pages 127146 .",
    "springer , 2013 .",
    "a.  zimmermann , m.  krtzsch , j.  euzenat , and p.  hitzler .",
    "formalizing ontology alignment and its operations with category theory . in _ proc .",
    "4th international conference on formal ontology in information systems ( fois ) _ , pages 277288 .",
    "ios press , 2006 ."
  ],
  "abstract_text": [
    "<S> in this paper we analyse the functional requirements of linked data citation and identify a minimal set of operations and primitives needed to realise such task . citing linked data implies solving a series of data provenance issues and finding a way to identify data subsets . </S>",
    "<S> those two tasks can be handled defining a simple type system inside data and verifying it with a type checker , which is significantly less complex than interpreting reified rdf statements and can be implemented in a non data invasive way . </S>",
    "<S> finally we suggest that data citation should be handled outside of the data , possibly with an _ ad hoc_language .    </S>",
    "<S> = 1    2 </S>"
  ]
}