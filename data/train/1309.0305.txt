{
  "article_text": [
    "many complex systems are able to self - organise into a critical state @xcite . in the critical state local distortions",
    "can propagates throughout the entire system @xcite .",
    "this leads to correlation spanning across the entire system .",
    "we address here how to identify directed stochastic causal connections embedded in stochastic fluctuating but strongly correlated background .    most of ` causality '  and directionality measures have been tested on low dimension systems and neglect addressing the behaviour of systems consisting of large numbers of interdependent degrees of freedom that is a main feature of complex systems . from a complex systems",
    "point of view , on one hand there is the system as a whole ( collective behaviour ) and on another there are individual interactions that lead to the collective behaviour .",
    "a measure that can help understand and differentiate these two elements is needed .",
    "we shall first seek to make a clear definition of ` causality '  and then relate this definition to complex systems .",
    "we outline the different approaches and measures used to quantify this type of ` causality ' .",
    "we highlight that for multiple reasons , transfer entropy  seems to be a very suitable candidate for a ` causality '  measure for complex systems . consequently we seek to shed some light on the usage transfer entropy  on complex systems .    to improve our understanding of transfer entropy",
    "we study two simplistic models of complex systems which in a very controllable way generates correlated time series .",
    "complex system whose main characteristic consist in essential cooperative behaviour  @xcite takes into account instances when the whole system is interdependent .",
    "therefore , we apply transfer entropy  to the ( amended ) ising model  in order to investigate its behaviour at different temperatures particularly near the critical temperature .",
    "moreover , we are also interested in investigating the different magnitude of transfer entropy  in general ( which is not fully understood @xcite ) by looking at the effect of different transition probabilities , or activity levels .",
    "we discuss the interpretation of the different magnitudes of the transfer entropy  by varying transition rates in a random transition model .",
    "the quantification of ` causality '  was first envisioned by the mathematician wiener @xcite who propounded the idea that the ` causality '  of a variable in relation to another can be measured by how well the variable helps to predict the other . in other words ,",
    "variable @xmath0 ` causes ' variable @xmath1 if the ability to predict @xmath1 is improved by incorporating information about @xmath0 in the prediction of @xmath1 .",
    "the conceptualisation of ` causality '  as envisioned by wiener was formulated by granger @xcite leading to the establishment of the wiener - granger framework of ` causality ' .",
    "this is the definition of ` causality '  that we shall adopt in this paper .    in literature ,",
    "references to ` causality '  take many guises .",
    "the term directionality , information transfer and sometimes even independence can possibly refer to some sort of ` causality '  in line with the wiener - granger framework . continuing the assumption that @xmath0 causes @xmath1",
    ", one would expect the relationship between @xmath1 and @xmath0 to be asymmetric and that the information flows in a direction from the source @xmath0 to the target @xmath1 .",
    "one can assume that this information transfer is the unique information provided by the causal variable to the affected one .",
    "when one variable causes another variable , the affected variable ( the target ) will be dependent ( to certain extent ) on the causal variable ( the source ) .",
    "there must exist a certain time lag however small between the source and the target @xcite , this will be henceforth referred to as the causal lag  @xcite .",
    "one could also say the wiener - granger framework of prediction based ` causality '  is equivalent to looking for dependencies between the variables at a certain causal lag .",
    "roughly , there are two different approaches in establishing ` causality '  in a system .",
    "one approach is to make a qualified guess of a model that will fit the data , called the confirmatory approach @xcite .",
    "models of this nature are typically very field specific and rely on particular insights into the mechanism involved .",
    "a contrasting approach known as the exploratory approach , infers ` causal ' direction from the data .",
    "this approach does not rely on any preconceived idea about underlying mechanisms and let results from data shape the directed model of the system .",
    "most of the measures within the wiener - granger framework falls into this category .",
    "one can think of the different approaches as being on a spectrum from purely confirmatory to purely exploratory .",
    "the nature of complex systems  calls for the exploratory approach .",
    "the abundance of data emphasises this even more so .",
    "in fact ` causality '  measures in the wiener granger framework have been increasingly utilised on data sets obtained from complex systems  such as the brain @xcite and financial systems @xcite . unfortunately , most of the basic testings of the effectiveness of these measures is mostly done on dynamical systems @xcite or simple time series , without taking into account the emergence of collective behaviour and criticality .",
    "complex systems are typically stochastic and thus different from deterministic systems where the internal and external influences are distinctly identified .",
    "as mentioned above , here we focus on the emergence of collective behaviour in complex systems and in particular on how the intermingling of the collective behaviour with individual ( coupled ) interactions complicates the identification of ` causal ' relationships .",
    "identifying a measure that is able to distinguish between these different interactions will obviously help us to improve our understanding the dynamics of complex systems .",
    "within the wiener - granger framework , two of the most popular ` causality '  measure are granger causality ( g - causality ) and its nonlinear analog transfer entropy .",
    "g - causality and transfer entropy  are exploratory as their measures of causality are based on distribution of the sampled data .",
    "the standard steps of prediction based ` causality '  that underlies these measures can be summarized as follows .",
    "say we want to test whether variable @xmath0 causes variable @xmath1 .",
    "the first step would be to predict the current value of @xmath1 using the historical values of @xmath1 .",
    "the second step is to do another prediction where the historical values of @xmath0 and @xmath1 are both used to predict the current value of @xmath1 . and",
    "the last step would be to compare the former to the latter . if the second prediction is judged to be better than the first one",
    ", then one can conclude that @xmath0 causes @xmath1 .",
    "this being the main idea , we outline why transfer entropy  is more suitable for complex systems .",
    "granger causality is the most commonly used ` causality '  indicator @xcite .",
    "however , in the context of the nonlinearities of a complex systems  ( collective behaviour and criticality being the main example ) , using g - causality may not be sufficient .",
    "moreover , this ar framework makes g - causality less exploratory than transfer entropy .",
    "transfer entropy  was defined @xcite as a nonlinear measure to infer directionality using the markov property .",
    "the aim was to incorporate the properties of mutual information  and the dynamics captured by transition probabilities in order to understand the concept and exchange of information .",
    "more recently , the usage of transfer entropy  to detect causal relationships @xcite and causal lags ( the time between cause and effect ) has been further examined @xcite .",
    "thus we are especially interested in transfer entropy  due to its propounded ability to capture nonlinearities , its exploratory nature as well as its information theoretic background that provides information transfer related interpretation .",
    "unfortunately , some of the vagueness in terms of interpretation may cause confusion in complex systems .",
    "the rest of the paper is an attempt to discuss these issues in a reasonably self - contained manner .",
    "define random variables @xmath2 and @xmath3 with discrete probability distributions @xmath4 , @xmath5 and @xmath6 .",
    "the entropy of @xmath1 is defined @xcite as @xmath7 where log to the base @xmath8 and @xmath9 is used .",
    "the joint entropy of @xmath1 and @xmath0 is defined as @xmath10 and the conditional entropy can be written as @xmath11 where @xmath12 is the joint distribution and @xmath13 is the respective conditional distribution .",
    "the mutual information  @xcite is defined as @xmath14 taking into account conditional variables , the conditional mutual information  @xcite is defined as @xmath15 .",
    "a variant of conditional mutual information  namely the transfer entropy  was first defined by schreiber in @xcite .",
    "let @xmath16 be the variable @xmath1 that is shifted by @xmath17 , so that the values of @xmath18 where @xmath19 is the value of @xmath1 at time step @xmath20 and similarly for @xmath0 .",
    "we highlight a simple form of transfer entropy  where conditioning is minimal such that @xmath21 the idea is that , if @xmath0 causes @xmath1 at causal lag @xmath22 , then @xmath23 for any lag @xmath17 since @xmath24 due to the fact that @xmath25 should provide the most information about the change of @xmath26 to @xmath1 .",
    "this simple form allows us to vary the values of time lag @xmath17 in ascertaining the actual causal lag .",
    "this form of transfer entropy  was also used in @xcite .",
    "the transfer entropy  in equation ( [ tetau ] ) can also be written as @xmath27 our choice of this simple definition was motivated by the fact that it directly captures how the state of @xmath28 influences the changes in @xmath1 i.e. from @xmath19 to @xmath29 . in other words ,",
    "equation ( [ tetau ] ) is tailor made to measure whether the state of @xmath30 influences the current changes in @xmath1 .",
    "this coincides with the predictive view of ` causality '  in the wiener - granger framework where the current state of one variable ( the source ) influences the changes in another variable ( the target ) in the future . the same concept will be applied in order to probe this kind of ` causality '  in our models .",
    "a system is critical when correlations are long ranged .",
    "a simple prototype example is the ising model  @xcite at critical temperature , @xmath31 , away from @xmath31 correlations are short ranged and dies off exponentially with separation .",
    "we shall apply transfer entropy  to the ising model  in order to investigate its behaviour at different temperatures particularly in the vicinity of the critical temperature .",
    "one can visualize the 2d ising model  as a two dimensional square lattice with length @xmath32 composed of @xmath33 sites @xmath34 .",
    "these sites can only be in two possible states , spin - up ( @xmath35 ) or spin - down ( @xmath36 ) .",
    "we restrict the interaction of the sites to only its nearest neighbours ( in two dimensions this will be sites to the north , south , east and west ) .",
    "let the interaction strength between @xmath37 and @xmath38 be denoted by @xmath39 so that the hamiltonian ( energy ) , @xmath40 , is given by @xcite @xmath41 @xmath40 is used to the obtain the boltzmann ( gibbs ) distribution @xmath42 where @xmath43 and @xmath44 is the boltzmann constant and @xmath45 is temperature .",
    "we implement the usual metropolis monte carlo ( mmc ) algorithm @xcite for the simulation of the ising model in two dimensions with periodic boundary conditions . the algorithm proposed by metropolis and co - workers in 1953",
    "was designed to sample the boltzmann distribution @xmath46 by artificially imposing dynamics on the ising model .",
    "the implementation of the mmc algorithm in this paper is outlined as follows .",
    "a site is chosen at random to be considered for flipping ( change of state ) with probability @xmath46 .",
    "the event of considering the change and afterwards the actual change ( if accepted ) of the configuration , shall henceforth be referred to as flipping consideration .",
    "a sample is taken after each @xmath47 flipping considerations .",
    "the logic being that , since sites to be considered are chosen randomly one at a time , after @xmath47 flips , each site will on average have been selected for consideration once .",
    "the interaction strength is set to be @xmath48 and the boltzmann constant is fixed as @xmath49 for all the simulations .",
    "we let the system run up to @xmath50 samples before sampling at every @xmath33 time steps .    through the mmc algorithm , a markov chain ( process )",
    "is formed for every site on the lattice .",
    "the state of each site at each sample will be taken as a time step @xmath20 in the markov chain @xmath51 .",
    "let @xmath52 be the number of samples ( length of the markov chains ) . to get the probability values for each site , we utilise temporal average .",
    "all the numerical probabilities obtained for the ising model  in this paper have been obtained by averaging over simulations with @xmath53 unless stated otherwise .      in an infinite two dimensional lattice",
    ", the phase transition of the ising model  with @xmath48 and @xmath49 is known to occur at the critical temperature @xmath54 @xcite . in a finite system , due to finite size effects",
    ", the critical values will not be quite as exact , we will call the temperature where the transition effectively occurs in the simulation as the crossover temperature @xmath31 .",
    "susceptibility @xmath55 is an observable that is normally used to identify @xmath31 for the ising model  as seen in figure ( [ suscep100 ] ) . in order to define @xmath55 ,",
    "let @xmath56 be the sum of spins on a lattice of size @xmath47 at time steps @xmath57 .",
    "the susceptibility  @xcite is given by@xmath58-e[m(n)]^2\\right ) \\end{aligned}\\ ] ] where @xmath59 $ ] is the expectation in terms of temporal average and @xmath45 is temperature .",
    "the covariance on the ising model  can be defined as @xmath60-e[s_x]e[s_y]\\end{aligned}\\ ] ] where @xmath61 .",
    "to display measures applied on individual sites , let sites @xmath62 represent coordinates @xmath63 $ ] , @xmath64 $ ] and @xmath65 $ ] respectively .",
    "the values of the covariance @xmath66 and @xmath67 is displayed in figure ( [ cov100 ] ) and figure ( [ mi100 ] ) .",
    "it can be seen that for the ising model , mutual information  gives no more information than covariance . from this figure",
    ", one can see that the values are system size dependent up to system size @xmath68 or @xmath69 .",
    "we conclude from this that , up to this length scale correlations are detectable across the entire lattice@xcite .",
    "thus we shall frequently utilize @xmath68 when illustration is required .",
    "using time shifted variables we obtained the transfer entropy  @xmath70 in figure ( [ allteim ] ) .",
    "one can see that there is no clear difference between @xmath71 and @xmath72 in the figures thus no direction of ` causality '  can be established between @xmath73 and @xmath74 .",
    "this is expected due to the symmetry of the lattice .",
    "more interestingly , the fact that transfer entropy  peaks near @xmath31 can be due to the fact that at @xmath31 the correlations span across the entire lattice .",
    "therefore , one may say that the critical transition and collective behaviour in the ising model  is detected by transfer entropy  as a type of ` causality '  that is symmetric in both directions . it is logical to interpret collective behaviour as a type of ` causality '  in all directions since information is disseminated throughout the whole lattice when it is fully connected .",
    "this is an important fact to take into account when estimating transfer entropy  on complex systems .",
    "in the amended ising model we introduce an explicit directed dependence between the sites @xmath73 , @xmath75 and @xmath74 in order to study how well transfer entropy  is able to detect this causality .",
    "we will define the amended ising model  using the algorithm outlined as follows . at each step in the algorithm a site chosen at random will be considered for flipping with a certain probability @xmath46 except when @xmath73 or @xmath75 is selected where an extra condition needs to be fulfilled first before it can be allowed to change . if @xmath76 , @xmath73 ( or @xmath75 ) can be considered for flipping with probability @xmath46 as usual , however if @xmath77 , no change is allowed .",
    "thus only one state of @xmath74 ( @xmath78 in this case ) allows sites @xmath73 and @xmath75 to be considered for flipping .",
    "therefore , although @xmath73 ( and @xmath75 ) have their own dynamics , their changes still depend on @xmath74 .",
    "we simulated the amended ising model  with @xmath79 for different lattice lengths @xmath32 .",
    "figures ( [ suscep100tau10 ] ) display the values of susceptibility @xmath55 on the model and the peaks clearly show the presence of @xmath31 in our model .",
    "figures ( [ cov100tau10 ] ) and ( [ mi100tau10 ] ) display the values of the covariance @xmath66 and the mutual information  @xmath80 .",
    "we reiterate that our correlations reach across the system for @xmath81 @xcite .",
    "while covariance and mutual information  gives similar results to those of the standard ising model , a difference is clearly seen in transfer entropy  values .",
    "figure ( [ tagga25]-[teag100tau10 ] ) displays the contrasts of @xmath82 and @xmath83 on the amended ising model  which explicitly indicates the direction of ` causality '  @xmath84 .",
    "the effect of deviation from the predetermined causal lag @xmath79 , can be clearly seen in figure ( [ tetau10l50 ] ) , where for the values of @xmath85 reduces to @xmath86 but at different rates depending on the deviation of @xmath17 from @xmath87 . the further away from @xmath87 , the faster the decrease to @xmath86 .",
    "figure ( [ tesvtauaim ] ) is simply figure ( [ tetau10l50 ] ) plotted over different time lags @xmath17 to illustrate how transfer entropy   correctly and distinctly identified causal lag @xmath79 .",
    "that temperature is a main factor in influencing the strength of transfer entropy  values is apparent in all the figures in this section .",
    "one can observe that the transfer entropy  values approaches @xmath86 as they get further away from @xmath31 except when the time lag matches the delay induced by definition between the dynamics of the two spins @xmath73 and @xmath75 and the @xmath74 spin , in which case the transfer entropy  value stabilizes to a certain fixed value as seen in figure ( [ temp0to15 ] ) . in the vicinity of @xmath31 , the lattice",
    "is highly correlated thus subsequently leading to higher values of transfer entropy .",
    "the increase and value stabilization after @xmath31 is due to the fact that , as temperature increases , the probability for all spin flips approaches a uniform distribution .",
    "this leads to transfer of information between site @xmath74 and sites @xmath73 and @xmath75 occurring much more frequently at elevated temperature .    figure ( [ tewithabasicl50 ] ) and ( [ tewithal50 ] ) display transfer entropy  values for the ising model  and amended ising model  with @xmath88 respectively .",
    "the figures illustrate the mechanism in which transfer entropy  detects the predefined causal delay .",
    "consider the following question : which site ` causes ' site @xmath73 ?",
    "firstly we see that @xmath89 is zero in both figures due to the definition in equation ( [ tetau ] ) .",
    "note that this is only for @xmath90 , if @xmath91 the transfer entropy  value will be nonzero and also peak at @xmath31 .",
    "more importantly we see that @xmath92 is different from @xmath93 . in figure ( [ tewithabasicl50 ] )",
    "the difference is due to distance in space and nearest neighbour interaction in the model , thus @xmath94 since @xmath74 is further away from @xmath73 than @xmath75 .",
    "but in figure ( [ tewithal50 ] ) , the opposite is true and distance in space does not dominate in this interaction .",
    "the figure very clearly indicates that @xmath74 ` causes ' @xmath73 at @xmath90 and @xmath75 does not . in other words , in the amended ising model",
    "transfer entropy  identifies @xmath74 as a source in which one of the target is @xmath73 , whereas in the ising model  the expected nearest neighbour dynamics presides .",
    "this result is only obtained for measures sensitive to transition probabilities .",
    "measures that depend only on static probabilities such as covariance , mutual information  and conditional mutual information  will only give values in accordance to the underlying nearest neighbour dynamics in both the ising model  and the amended ising model@xcite .      in order to understand the dynamics of of each site we calculate the effective rate of change ( erc ) in relation to the transition probabilities .",
    "let @xmath95 for any site @xmath1 on the lattice .",
    "figure ( [ ercl50 ] ) illustrates how @xmath96 and @xmath97 are equal , as expected , and significantly different from @xmath98 . in figure ( [ tagga25 ] )",
    ", the corresponding transfer entropy   in both directions are displayed . at higher temperatures",
    ", it can be clearly seen that @xmath99 is larger than @xmath100 .",
    "however for temperatures near @xmath31 it is not as clear and therefore to highlight the relative values we calculate @xmath101 in figure ( [ dtl25 ] ) and figure ( [ dt ] ) where @xmath102 if @xmath103 .",
    "we see that this value actually gives a clear jump at @xmath31 and remains more or less a constant after @xmath31 .",
    "therefore even though transfer entropy  in neither direction is zero , a clear indication of directionality can be obtained .",
    "interestingly , the division with erc brought out the clear phase transition - like behaviour that seems to distinguish the situation below and above @xmath31 . referring back to figure ( [ tagga ] ) of the unamended ising model we can clearly see that @xmath104 for any direction in the unamended ising model .",
    "we have demonstrated that @xmath101 is able to cancel out the symmetric contribution from the collective behaviour and only captures the imposed directed interdependence .    in his introductory paper @xcite",
    ", schreiber warns that in certain situations due to different information content as well as different information rates , the difference in magnitude should not be relied on to imply directionality unless transfer entropy  in one direction is @xmath86 .",
    "we have shown that when collective behaviour is present on the ising model , the value of transfer entropy  can not possibly be @xmath86 .",
    "we suggest that this is due to fact that collective behaviour is as a type of ` causality '  ( disseminating information in all directions ) and thus the transfer entropy  is correctly indicating ` cause ' in all directions . the clear difference in transfer entropy  magnitude ( even at @xmath31 ) observed when the model is amended indicates that the _ difference _ in transfer entropy  can indeed serve as an indicator of directionality in systems with emergent cooperative behaviour .",
    "we have seen that transfer entropy  is influenced by the nearest neighbour interactions , collective behaviour and the erc . in the next section we use the random transition model to further investigate how the erc influences the transfer entropy .",
    "in the amended ising model  we implemented a causal lag as a restriction of one variable on another , in a way that a value of the source variable will affect the possible changes of the target variable . it is this novel concept of implementing ` causality '  that we will analyze and expand in the random transition model .",
    "let @xmath105 , @xmath106 and @xmath107 , be the independent probabilities for the stochastic swaps of the variables @xmath1 , @xmath0 and @xmath3 at every time step respectively .",
    "in addition to that , a restriction is placed on @xmath1 and @xmath0 such that they are only allowed to do the stochastic swap with probability @xmath105 and @xmath106 if the state of @xmath108 fulfills a certain condition .",
    "this restriction means that @xmath1 and @xmath0 can only change states if @xmath3 is in the conditioned state at time step @xmath109 thus creating a ` dependence ' on @xmath3 , analogous to the dependence of @xmath73 and @xmath75 on @xmath74 in the amended ising model .",
    "however in this model we allow the number of states @xmath110 to be more than just two .",
    "the purpose of this is twofold , on one hand it contributes towards verifying that the behaviours of transfer entropy  observed on the amended ising model  does extend to cases where @xmath111 . on the other hand",
    ", the model also serves to highlight different properties of transfer entropy  as well as the very crucial issue of probability estimation that may lead to misleading results .",
    "the processes are initialized randomly and independently .",
    "the swapping probabilities are taken to be @xmath112 , thus enabling transfer entropy  values to be calculated analytically ( see appendix for detailed analytic formulations ) .",
    "the unclear meaning of the magnitude of transfer entropy  is one of its main criticism  @xcite .",
    "this is partly due to the erc which incorporates both external and internal influences , the separation of which is rather unclear .",
    "the advantage of investigating transfer entropy  on the random transition model is that the erc can be defined in terms of internal and external elements i.e. for any variable @xmath1 we have that @xmath113 where @xmath105 is the internal transition probability of @xmath1 and @xmath114 represents the external influence applied on @xmath1 .",
    "if the condition in our model is that @xmath115 for @xmath116 and @xmath117 to change values then , @xmath118 so that @xmath119 and @xmath120",
    ". however , for the source @xmath3 which has no external influence , @xmath121 and consequently @xmath122    when @xmath123 , the model essentially replicates the ising model  without the collective behaviour effect i.e. far above the @xmath31 where the boltzmann distribution approaches a uniform distribution .",
    "consequently , at these temperatures the influence of collective behaviour is close to none .",
    "one can see in figure ( [ svarymx ] ) and figure ( [ svarymz ] ) that the @xmath124 ( hence the erc ) values are indeed key in determining the strength of transfer entropy . in figure ( [ svarymx ] ) , @xmath105 influences @xmath125 monotonically when every other value is fixed , therefore in this case the transfer entropy  reflects the internal dynamics @xmath105 rather than the external influence @xmath114 . if ` causality ' is the aim , surely @xmath114 is the very thing that makes the relationship ` causal ' and should be the main focus .",
    "this is a factor that needs to be taken into account when comparing the magnitudes of transfer entropy .",
    "figure ( [ svarymx ] ) also shows that when @xmath107 is uniform ( since @xmath123 hence @xmath126 , one gets that @xmath127 only if @xmath128 which makes causal lag detection fairly straight forward .",
    "however , in figure ( [ svarymz ] ) the effect of varying @xmath107 can be clearly seen in the nonzero values @xmath127 when @xmath129 .",
    "nevertheless , the value at @xmath128 seems to be fully determined by @xmath105 regardless of @xmath107 value .",
    "the mechanism in which @xmath107 effects @xmath130 is sketched in the appendix .",
    "therefore one can conclude that when @xmath3 is the source ( ` causal ' variable ) and @xmath1 is the target ( the variable being affected by the ` causal ' link ) , the value of the transfer entropy  @xmath130 at @xmath128 is influenced only by @xmath105 but for @xmath129 , @xmath130 is determined by both @xmath105 and @xmath107 .",
    "we have verified that this is indeed the case even when @xmath111 in this model .",
    "this should apply to all variables in the model and much more generally to any kind of source - target ` causal ' relationship in this sense .",
    "we suspect that this also extends to cases when there is more than one source and this will be a subject of future research .",
    "thus for causal lag detection purposes , it is clear that theoretically transfer entropy  will attain maximum value at the exact causal lag .",
    "it is also clear that transfer entropy  at nearby lags can be nonzero due to this single ` causal ' relationship and on data sets it is strongly recommended to test for relative lag values .",
    "the estimations of transfer entropy  for large number of states @xmath110 requires sufficient sample size . to illustrate this we set the value @xmath114 to three different values ; @xmath131 for case @xmath132 , @xmath133 for case @xmath134 and @xmath135 for case @xmath136 .",
    "we plot the analytical transfer entropy@xmath137 , and the estimations of it on simulated values for all three cases in figure ( [ cases ] ) .",
    "even though @xmath110 is known and incorporated in the estimations , the inaccuracies are quite worrying",
    ". this situation would be even more exaggerated in situations where @xmath110 is not known ( unfortunately , this is more often than not the case ) .",
    "we strongly advice checking the accuracy of transfer entropy  estimation and adjusting the @xmath110 value before using it for any type of analysis and drawing any conclusion .",
    "one way to do this is by generating a null model ( in the case of the random transition model this is simply three randomly generated time series ) and test the values of transfer entropy  as in figure ( [ nullall ] ) to ascertain the level of accuracy that is to be expected .",
    "subtracting the null model from the values on the random transition model is equal to subtracting the transfer entropy  values of both directions as one direction is theoretically zero .",
    "however this does not quite solve the problem as the values may still be negative if the sample size is small .",
    "there are many other types of corrections @xcite proposed to address this issue involving substraction of the null model in some various forms .",
    "nevertheless , as we have seen in figure ( [ dtl25 ] ) of the amended ising model , only by subtracting the two directions of transfer entropy  did we obtain the clear direction as this cancelled out the underlying collective behaviour .",
    "we suspect that this will work as well for cancelling out other types of background effects and succeed in revealing directionality .",
    "this paper highlights the question of distinguishing interdependencies induced by collective behaviour and individual ( coupled ) interactions , in order to understand the inner workings of complex systems  derived from data sets .",
    "these data sets are usually in the form of time series that seem to behave essentially as stochastic series .",
    "it is hence of great interest to understand measures proposed to be able to probe ` causality '  in view of complex systems .",
    "transfer entropy  has been suggested as a good probe on the basis of its nonlinearities , exploratory approach and information transfer related interpretation .",
    "to investigate the behaviour of transfer entropy , we studied two simplistic models . from results of applying transfer entropy  on the ising model , we proposed that the collective behaviour is also a type of ` causality '  in the wiener - granger framework but highlighted that it should be identified differently from individual interactions by illustrating this issue on an amended ising model .",
    "the collective behaviour that emerges near criticality may overshadow the intrinsic directionality in the system as it is not detected by measures such as covariance ( correlation ) and mutual information .",
    "we showed that by taking into account both directions of transfer entropy  on the amended ising model , a clear direction can be identified .",
    "in addition to that , we verified that the transfer entropy  is indeed maximum at the exact causal lag by utilizing the amended ising model .    by obtaining the phase transition - like _ difference _ measure ,",
    "we have shown that the transfer entropy  is highly dependent on the effective rate of change ( erc ) and therefore likely to be dependent on the overall activity level given by , say , the temperature in thermal systems as we demonstrated in the amended ising model . using the random transition model we have illustrated that the erc is essentially comprised of internal as well as external influences and",
    "this is why transfer entropy  depicts both .",
    "this also explains why collective behaviour on the ising model is detected as type of ` causality ' .",
    "in complex systems where there is bound to be various interactions on top of the emergent collective behaviour , the situation can be difficult to disentangle and caution is needed .",
    "moreover we pointed out the danger of spurious values in the estimation of the transfer entropy  due to finite statistics which can be circumvented to a certain extend by a comparison of the amplitude of the causality measure in both directions and also by use of null models .",
    "we believe that identifying these influences is important for our understanding of transfer entropy  with the aim of utilising its full potential in uncovering the dynamics of complex systems .",
    "the mechanism of replicating ` causality '  in the amended ising model  and the random transition model may be used to investigate these ` causality '  measures even further .",
    "plans for future investigations involve indirect ` causality ' , multiple sources and multiple targets",
    ". it would also be interesting to understand these measures in terms of local and global dynamics in dynamical systems .",
    "it is our hope that these investigations will help establish these ` causality '  measures as a repertoire of measures for complex systems .",
    "the transition probability of the random transition model is as follows .",
    "we assume that if a process chooses to change it must choose one of the other states equally , thus we have that @xmath138 , so that the marginal and joint probabilities remain uniform but the transition probabilities are @xmath139 @xmath140 and @xmath141 where @xmath142 such that one can control ` dependence ' on @xmath3 by altering @xmath114 .      to understand how the values of @xmath107 affects the value of @xmath144",
    "we need a different variable .",
    "let @xmath143 be the probability that the condition is fulfilled given current knowledge at time @xmath17 such that @xmath145 .",
    "the value of @xmath146 will depend on @xmath147 , and in our model here , particularly on whether or not @xmath148 satisfies the condition .",
    "one can divide the possible states @xmath147 of all the processes into two groups such that @xmath149 @xmath150 note that @xmath151 and @xmath152 since @xmath153 such that @xmath114 can be interpreted as the proportion of states of @xmath3 that fulfill the condition . due to equiprobability of spins and uniform initial distribution , for any @xmath17",
    "there are only two possible values of @xmath146 , one for @xmath154 and one for @xmath155 .",
    "therefore define @xmath156 such that @xmath157 to get @xmath158 thus @xmath159 with the @xmath156 as in equation ( [ sgn ] ) .",
    "the relationship between @xmath146 and @xmath114 can be defined using the formula for total probability @xmath160 let @xmath161 and using the fact that @xmath162 , we get that @xmath163 due to the sole dependence of @xmath3 on @xmath107 , @xmath164 will make the transition probability of @xmath3 uniform such that @xmath165 for any @xmath20 since we have that@xmath166 for any @xmath167 .",
    "consequently , @xmath164 also makes all values of @xmath146 uniform so that equation ( [ omeganq ] ) becomes @xmath168 therefore on the model when the @xmath164 , we have that @xmath169 for any @xmath128 . and",
    "this is why we get figure ( [ svarymx ] ) , where @xmath127 only if @xmath128 since @xmath169 in equation ( [ tzxgeneral ] ) cancels out .    for any @xmath107",
    ", the relationship between @xmath170 and @xmath171 can be derived from equation ( [ omeganq ] ) where @xmath172 note that when @xmath123 ( hence @xmath135 ) this simplifies to @xmath173 .      using @xmath146 as in equation ( [ qgeneral ] ) we have that @xmath174 which gives us @xmath175 \\notag\\\\ & + |\\{x_n \\ne x_{n-1}\\}|\\sum_{\\gamma}\\left[\\frac{\\frac{1}{n_{s}-1}\\mu_xq_{sgn(\\gamma)}^{(\\tau)}}{n^{2}_{s^{}}}\\,log\\,\\frac{q_{sgn(\\gamma)}^{(\\tau)}}{\\omega}\\right ] \\notag\\\\ = & n_s\\sum_{\\gamma}\\left[\\frac{1-\\mu_xq_{sgn(\\gamma)}^{(\\tau)}}{n^{2}_{s^{}}}\\,log\\,\\frac{1-\\mu_xq_{sgn(\\gamma)}^{(\\tau)}}{1-\\mu_x\\omega } \\right ] \\notag\\\\ & + n_s(n_s-1)\\sum_{\\gamma}\\left[\\frac{\\frac{1}{n_{s}-1}\\mu_xq_{sgn(\\gamma)}^{(\\tau)}}{n^{2}_{s^{}}}\\,log\\,\\frac{q_{sgn(\\gamma)}^{(\\tau)}}{\\omega}\\right ]",
    "\\notag\\\\ = & \\frac{1}{n_s}\\sum_{\\gamma \\in g_u } \\left[(1-\\mu_x q_{sgn(\\gamma)}^{(\\tau)})\\,log\\,\\frac{1-\\mu_xq_{sgn(\\gamma)}^{(\\tau)}}{1-\\mu_x\\omega } + \\mu_x q_{sgn(\\gamma)}^{(\\tau)}\\,log\\,\\frac{q_{sgn(\\gamma)}^{(\\tau)}}{\\omega}\\right]\\notag\\\\ & + \\frac{1}{n_s}\\sum_{\\gamma \\in g_d}\\left[(1-\\mu_x q_{sgn(\\gamma)}^{(\\tau)})\\,log\\,\\frac{1-\\mu_xq_{sgn(\\gamma)}^{(\\tau)}}{1-\\mu_x\\omega } + \\mu_x q_{sgn(\\gamma)}^{(\\tau)}\\,log\\,\\frac{q_{sgn(\\gamma)}^{(\\tau)}}{\\omega}\\right ] \\notag\\\\ = & \\frac{1}{n_s}(n_s \\omega)\\left[(1-\\mu_x q_{+}^{(\\tau)})\\,log\\,\\frac{1-\\mu_xq_{+}^{(\\tau)}}{1-\\mu_x\\omega } + \\mu_x q_{+}^{(\\tau)}\\,log\\,\\frac{q_{+}^{(\\tau)}}{\\omega}\\right]\\notag\\\\ & + \\frac{1}{n_s}n_s(1-\\omega)\\left[(1-\\mu_x q_{-}^{(\\tau)})\\,log\\,\\frac{1-\\mu_xq_{-}^{(\\tau)}}{1-\\mu_x\\omega } + \\mu_x q_{-}^{(\\tau)}\\,log\\,\\frac{q_{-}^{(\\tau)}}{\\omega}\\right ] \\notag\\\\ = & \\ , \\omega\\left[(1-\\mu_x q_{+}^{(\\tau)})\\,log\\,\\frac{1-\\mu_xq_{+}^{(\\tau)}}{1-\\mu_x\\omega } + \\mu_x q_{+}^{(\\tau)}\\,log\\,\\frac{q_{+}^{(\\tau)}}{\\omega}\\right]\\notag\\\\ & + ( 1-\\omega)\\left[(1-\\mu_x q_{-}^{(\\tau)})\\,log\\,\\frac{1-\\mu_xq_{-}^{(\\tau)}}{1-\\mu_x\\omega } + \\mu_x q_{-}^{(\\tau)}\\,log\\,\\frac{q_{-}^{(\\tau)}}{\\omega}\\right]\\end{aligned}\\ ] ] where we used the bayes theorem i.e @xmath176 due to independence , if @xmath0 were to be conditioned on @xmath1 we would have that @xmath177 therefore for values other than when @xmath1 and @xmath0 conditioned on @xmath3 , this ratio will yield @xmath132 .",
    "this renders @xmath178 . and",
    "if we get that @xmath127 , we can say that transfer entropy indicates ` causality '  or some form of directionality from @xmath3 to @xmath1 and @xmath3 to @xmath0 , at time lag @xmath17 . in a similar manner for @xmath179",
    "we have that @xmath180 such that @xmath181 in exactly like equation ( [ tzxgeneral ] ) except that @xmath105 is replaced with @xmath106 .    when @xmath128 we have that @xmath182 is either @xmath86 or @xmath132 since the condition was placed at @xmath109 .",
    "more specifically we will have that @xmath183 and that @xmath184 .",
    "putting these two values in equation ( [ tzxgeneral ] ) we obtain @xmath185\\notag\\\\ & + ( 1-\\omega)\\left[(1-\\mu_x q_{-}^{(t_{z})})\\,log\\,\\frac{1-\\mu_xq_{-}^{(t_{z})}}{1-\\mu_x\\omega } + \\mu_x q_{-}^{(t_{z})}\\,log\\,\\frac{q_{-}^{(t_{z})}}{\\omega}\\right]\\notag\\\\ = \\,\\omega&(1-\\mu_x)\\,log\\,\\frac{1-\\mu_x}{1-\\mu_x\\omega}+\\,\\omega\\mu_x\\,log\\,\\frac{1}{\\omega } + ( 1-\\omega)\\,log\\,\\frac{1}{1-\\mu_x\\omega}.\\end{aligned}\\ ] ] a more thorough treatment of the random transition model and other methods of transfer entropy  estimations is given in @xcite .",
    "10    f.  abdul  razak .",
    ". phd thesis , department of mathematics , imperial college london , 2013 .",
    "p.  bak . .",
    "springer - verlag , new york , 1996 .",
    "s.  l. bressler and a.k .",
    "wiener - granger causality : a well established methodolgy .",
    ", 58:323329 , 2011 .",
    "k.  christensen and r.  n. moloney . .",
    "imperial college press , london , 2005 .    b.  a. cipra .",
    "an introduction to the ising model .",
    ", 94(10):937959 , 1987 .",
    "t.  cover and j.  thomas . .",
    "wiley , new york , 1999 .",
    "k.  friston .",
    "dynamic causal modeling and granger causality comments on : the identification of interacting networks in the brain using fmri : model selection , causality and deconvolution . , 58:303305 , 2011 .    c.  w.  j. granger . investigating causal relations by econometric models and cross - spectral methods . , 37:424438 , 1969 .",
    "d.  m. hausman .",
    "the mathematical theory of causation .",
    ", 3:151162 , 1999 .",
    "k.  hlavackova - schindler et  al .",
    "causality detection based on information - theoretic approaches in time series analysis .",
    ", 441:146 , 2007 .",
    "h.  j. jensen . .",
    "cambridge university press , cambridge , 1998 .",
    "h.  j. jensen .",
    "probability and statistics in complex systems , introduction to . in _ encyclopedia of complexity and systems science _ , pages 70247025 .",
    "a.  kaiser and t.  schreiber .",
    "information transfer in continuous process .",
    ", 166:4362 , 2002 .",
    "a.  kraskov , h.  stgbauer , and p.  grassberger .",
    "estimating mutual information . , 69:066138 , jun 2004 .",
    "w.  krauth . .",
    "oxford university press , oxford , 2006",
    ".    z.  li et  al .",
    "characterization of the causality between spike trains with permutation conditional mutual information .",
    ", 84:021929 , 2011 .",
    "m.  lungarella et  al .",
    "methods for quantifying the causal structure of bivariate time series . , 17:903921 , 2007 .",
    "r.  marschinski and h.  kantz .",
    "analysing the information flow between financial time series : an improved estimator for transfer entropy . , 30:275281 , 2002 .",
    "m.  martini et  al . inferring directional interactions from transient signals with symbolic transfer entropy .",
    ", 83:011919 , 2011 .",
    "j.  m. nichols et  al . detecting nonlinearity in structural systems using the transfer entropy .",
    ", 72:046217 , 2005 .",
    "j.  r. norris . .",
    "cambridge university press , cambridge , 2008 .",
    "b.  pompe and j.  runge . momentary information transfer as a coupling of measure of time series .",
    ", 83:051122 , 2011 .",
    "g.  pruessner . .",
    "cambridge university press , cambridge , 2012 .",
    "j.  runge et  al . quantifying causal coupling strength : a lag - specific measure for multivariate time series related to transfer entropy .",
    ", 86:061121 , 2012 .",
    "n.  sauer .",
    "causality and causation : what we learn from mathematical dynamic systems theory .",
    ", 65:6568 , 2010 .",
    "t.  schreiber .",
    "measuring information transfer .",
    ", 85:461464 , jul 2000 .    c.  e. shannon . a mathematical theory of communication",
    ", 27:379423 , 623656 , 1948 .",
    "m.  vejmelka and m.  palus . inferring the directionality of coupling with conditional mutual information .",
    ", 77:026214 , 2008 .",
    "r.  vicente et  al .",
    "transfer entropy : a model - free measure of effective connectivity for the neurosciences .",
    ", 30:4567 , 2011 .",
    "m.  wibral et  al . measuring information - transfer delays .",
    ", 8(2):55809 , 2013 .",
    "n.  wiener . .",
    "mit press , massachusetts , 1956 .",
    "l.  witthauer and m.  dieterle .",
    "the phase transition of the 2d - ising model , 2007 .",
    "on the ising model * with lengths @xmath186 obtained using equation ( [ covising ] ) . ]                   &  @xmath83 on the amended ising model * of lengths @xmath68 and @xmath79 , obtained using equation ( [ tetau ] ) .",
    "direction @xmath84 at time lag @xmath188 is indicated . very different from result on ising model  in figure [ tagga ] . ]     &  @xmath83 on the amended ising model * of lengths @xmath68 and @xmath79 , obtained using equation ( [ tetau ] ) .",
    "direction @xmath84 at time lag @xmath188 is indicated . very different from result on ising model  in figure [ tagga ] . ]                         versus time lags @xmath17 of the random transition model with @xmath123 ( hence @xmath135 ) and @xmath192 in equation ( [ tzxgeneral ] ) where @xmath193 fixed and @xmath107 is varied .",
    "@xmath107 does not effect @xmath125 but causes @xmath127 at @xmath129 .",
    "@xmath194 and @xmath195 coincides ]     versus time lags @xmath17 of the random transition model with @xmath123 ( hence @xmath135 ) and @xmath192 in equation ( [ tzxgeneral ] ) where @xmath193 fixed and @xmath107 is varied .",
    "@xmath107 does not effect @xmath125 but causes @xmath127 at @xmath129 .",
    "@xmath194 and @xmath195 coincides ]     transfer entropy  @xmath137 versus number of state @xmath110 for cases @xmath196 and @xmath136 .",
    "@xmath197 are uniformly distributed .",
    "analytical values obtained from substituting respective @xmath114 values in equation ( [ tzgeneral ] ) .",
    "simulated values are acquired using equation ( [ tetau ] ) on simulated data of varying sample size @xmath52 where @xmath198 . ]",
    "transfer entropy  @xmath137 versus number of state @xmath110 for cases @xmath196 and @xmath136 .",
    "@xmath197 are uniformly distributed .",
    "analytical values obtained from substituting respective @xmath114 values in equation ( [ tzgeneral ] ) .",
    "simulated values are acquired using equation ( [ tetau ] ) on simulated data of varying sample size @xmath52 where @xmath198 . ]",
    "transfer entropy  @xmath137 versus number of state @xmath110 for cases @xmath196 and @xmath136 .",
    "@xmath197 are uniformly distributed .",
    "analytical values obtained from substituting respective @xmath114 values in equation ( [ tzgeneral ] ) .",
    "simulated values are acquired using equation ( [ tetau ] ) on simulated data of varying sample size @xmath52 where @xmath198 . ]"
  ],
  "abstract_text": [
    "<S> ` causal ' direction is of great importance when dealing with complex systems </S>",
    "<S> . often big volumes of data in the form of time series are available and it is important to develop methods that can inform about possible causal connections between the different observables . here </S>",
    "<S> we investigate the ability of the transfer entropy measure to identify causal relations embedded in emergent coherent correlations . </S>",
    "<S> we do this by firstly applying transfer entropy  to an amended ising model . </S>",
    "<S> in addition we use a simple random transition model to test the reliability of transfer entropy as a measure of ` causal ' direction in the presence of stochastic fluctuations . </S>",
    "<S> in particular we systematically study the effect of the finite size of data sets . </S>"
  ]
}