{
  "article_text": [
    "in production theory and efficiency analysis , there is sometimes the need to estimate the boundary of a production set ( the set of feasible combinations of inputs and outputs ) .",
    "this boundary ( the production frontier ) represents the set of optimal production plans so that the efficiency of a production unit ( a firm , for example ) is obtained by measuring the distance from this unit to the estimated production frontier .",
    "parametric approaches rely on parametric models for the frontier and the underlying stochastic process , whereas nonparametric approaches offer much more flexible models for the data - generating process ( see , for example , @xcite for recent surveys on this topic ) .    formally , in this paper , we consider technologies where @xmath0 , a vector of production factors ( inputs ) is used to produce a single quantity ( output ) @xmath1 .",
    "the attainable production set is then defined , in standard microeconomic theory , as @xmath2 assumptions are usually made on this set , such as free disposability of inputs and outputs , meaning that if @xmath3 , then @xmath4 for any @xmath5 such that @xmath6 ( this inequality must be understood componentwise ) and @xmath7 . to the extent",
    "that the efficiency of a firm is a concern , the boundary of  @xmath8 is of interest . the efficient boundary ( or _ production frontier _ ) of  @xmath8 is the locus of optimal production plans ( maximal achievable output for a given level of inputs ) . in our setup , the production frontier is represented by the graph of the production function @xmath9 the economic efficiency score of a firm operating at the level @xmath10 is then given by the ratio @xmath11 .",
    "cazals _ et al . _",
    "@xcite proposed a probabilistic interpretation of the production frontier .",
    "let @xmath8 be the support of the joint distribution of a random vector @xmath12 and let @xmath13 be the probability space on which the vector of inputs @xmath14 and the output @xmath15 are defined .",
    "the distribution function of @xmath16 can be denoted @xmath17 and @xmath18 will be used to denote the conditional distribution function of @xmath15 given @xmath19 , with @xmath20 .",
    "it has been proven in @xcite that @xmath21 is a monotone non - decreasing function with @xmath22 .",
    "so , for all @xmath6 with respect to the partial order , @xmath23 .",
    "the graph of @xmath24 is the smallest non - decreasing surface which is greater than or equal to the upper boundary of @xmath8 .",
    "further , it has been shown that under the free disposability assumption , @xmath25 , that is , the graph of @xmath24 coincides with the production frontier .",
    "since @xmath8 is unknown , it must be estimated from a sample of i.i.d .",
    "firms @xmath26 .",
    "the _ free disposal hull _ ( fdh ) @xmath27 of @xmath28 was introduced by @xcite .",
    "the resulting fdh estimator of @xmath29 is @xmath30 where @xmath31 with @xmath32 and @xmath33 .",
    "this estimator represents the lowest monotone step function covering all of the data points @xmath34 .",
    "the asymptotic behavior of @xmath35 was first derived by @xcite for the consistency and by @xcite for the asymptotic sampling distribution .",
    "to summarize , under regularity conditions , the fdh estimator @xmath35 is consistent and converges to a weibull distribution with some unknown parameters . in park _",
    "et al . _",
    "@xcite , the obtained convergence rate @xmath36 requires that the joint density of @xmath16 has a jump at its support boundary .",
    "in addition , the estimation of the parameters of the weibull distribution requires the specification of smoothing parameters and the resulting procedure has very poor accuracy . in hwang _",
    "et al . _",
    "@xcite , the convergence of @xmath35 to the weibull distribution was established in a general case where the density of @xmath16 may decrease to zero or increase toward infinity at a speed of power @xmath37 ( @xmath38 ) of the distance from the frontier .",
    "they obtain the convergence rate @xmath39 and extend the particular result of park _ et al . _",
    "@xcite where @xmath40 , but their result is only derived in the simple case of one - dimensional inputs @xmath41 which may be of less interest in practice .    in this paper",
    ", we first analyze the properties of the fdh estimator from an extreme value theory perspective . in doing so ,",
    "we generalize and extend the results of park _ et al . _",
    "@xcite and hwang _ et al . _",
    "@xcite in at least three directions .",
    "first , we provide the necessary and sufficient condition for the fdh estimator to converge in distribution and we specify the asymptotic distribution with the appropriate rate of convergence .",
    "we also provide a limit theorem for moments in a general framework .",
    "second , we show how the unknown parameter @xmath42 involved in the necessary and sufficient extreme value conditions , is linked to the dimension @xmath43 of the data and to the shape parameter @xmath38 of the joint density : in the general setting where @xmath44 and @xmath45 may depend on @xmath22 , we obtain , under a convenient regularity condition , the general convergence rate @xmath46 of the fdh estimator @xmath35 .",
    "third , we suggest a strongly consistent and asymptotically normal estimator of the unknown parameter @xmath47 of the asymptotic weibull distribution of @xmath35 .",
    "this also answers the important question of how to estimate the shape parameter @xmath48 of the joint density of @xmath16 when it approaches the frontier of the support @xmath8 .    by construction ,",
    "the fdh estimator is very non - robust to extremes .",
    "recently , aragon _",
    "et al . _",
    "@xcite constructed an original estimator of @xmath29 , which is more robust than @xmath49 but which keeps the same limiting weibull distribution as @xmath35 under the restrictive condition @xmath40 . in this paper , we provide further insights and generalize their main result .",
    "we also suggest attractive estimators of @xmath29 converging to a normal distribution , which appear to be robust to outliers . the paper is organized as follows .",
    "section  [ sec2 ] presents the main results of the paper .",
    "section  [ sec3 ] illustrates how the theoretical asymptotic results behave in finite - sample situations and gives an example with a real data set on the production activity of the french postal services .",
    "section  [ sec4 ] concludes the paper , with proofs deferred for the .",
    "from now on , we assume that @xmath50 such that @xmath51 and will denote by @xmath52 and @xmath53 , respectively , the @xmath54-quantiles of the distribution function @xmath55 and its empirical version @xmath56 , @xmath57 with @xmath580,1]$ ] . when @xmath59 , the conditional quantile @xmath60 tends to @xmath61 , which coincides with the frontier function @xmath62 .",
    "likewise , @xmath53 tends to the fdh estimator @xmath63 of @xmath29 as @xmath59 .",
    "we first derive the following interesting results on the problem of convergence in distribution of suitably normalized maxima @xmath64 .",
    "we will denote by @xmath65 the gamma function .",
    "[ thm1 ] if there exist @xmath66 and some non - degenerate distribution function @xmath67 such that @xmath68 then @xmath69 coincides with @xmath70 with support @xmath71{-}\\infty , 0]$ ] for some @xmath72 .",
    "a.   there exists @xmath66 such that @xmath73 converges in distribution if and only if @xmath74 @xmath75 .",
    "+ in this case , the norming constants @xmath76 can be chosen as @xmath77 b.   given , @xmath78 for all integers @xmath79 and @xmath80\\\\ & & \\quad = \\psi _ { \\rho_x}[\\{\\gamma(1 + 2\\rho^{-1}_x)-\\gamma^2(1+\\rho^{-1}_x)\\ } ^{1/2}y-\\gamma(1+\\rho^{-1}_x ) ] .\\end{aligned}\\ ] ]    [ rmk2.4 ] since the function @xmath81 \\in   \\mathit{rv } _ { -\\rho_x}$ ] ( regularly varying in @xmath82 ) by , this function can be represented as @xmath83 with @xmath84 ( @xmath85 being slowly varying ) and so the extreme value condition holds if and only if we have the following representation : @xmath86=l_x\\bigl(\\{\\varphi(x)-y\\}^{-1}\\bigr ) \\bigl(\\varphi(x)-y\\bigr)^{\\rho_x}\\qquad   \\mbox{as }   y\\uparrow\\varphi(x ) .\\end{aligned}\\ ] ] in the particular case where @xmath87 is a strictly positive function in @xmath22 , it is shown in the next corollary that @xmath88 . from now on ,",
    "a random variable @xmath89 is said to follow the distribution @xmath90 if @xmath91 is exponential with parameter @xmath92 .",
    "[ ( corcor ) ] given or , equivalently , with @xmath93 , we have @xmath94    [ rmk2.4.1 ] park _ et al . _",
    "@xcite and hwang _ et al . _",
    "@xcite have obtained similar results under more restrictive conditions .",
    "indeed , a unified formulation of the assumptions used in @xcite can be expressed as @xmath95 where @xmath96 is the joint density of @xmath16 , @xmath37 is a constant satisfying @xmath38 and @xmath97 is a strictly positive function in @xmath22 . under the restrictive condition that @xmath98 is strictly positive on the frontier ( that is , @xmath40 ) ,",
    "park _ et al . _",
    "@xcite , among others , have obtained the limiting weibull distribution of the fdh estimator with the convergence rate @xmath36 .",
    "when @xmath37 may be non - null , hwang _ et al . _",
    "@xcite have obtained the asymptotic weibull distribution with the convergence rate @xmath39 in the simple case @xmath99 ( here , it is also assumed that holds uniformly in a neighborhood of the point at which we want to estimate @xmath100 , and that this frontier function is strictly increasing in that neighborhood and satisfies a lipschitz condition of order @xmath92 ) . in the general setting where @xmath44 and @xmath101 may depend on @xmath22",
    ", we have the following , more general , result , which involves the link between the tail index @xmath47 , the data dimension @xmath43 and the shape parameter @xmath48 of the joint density near the boundary .    [ ( corscors ) ] if the condition of corollary [ ( corcor ) ] holds with @xmath17 being differentiable near the frontier ( that is , @xmath102 , @xmath103 and @xmath29 are differentiable in @xmath22 with first partial derivatives of @xmath29 being strictly positive ) , then holds with @xmath104 and we have @xmath105    [ rmk2.4.2 ] we assume the differentiability of the functions @xmath106 , @xmath47 with @xmath103 and @xmath29 in order to ensure the existence of the joint density near its support boundary .",
    "we distinguish between three different behaviors of this density at the frontier point @xmath107 based on how the value of @xmath108 compares to the dimension @xmath109 : when @xmath110 , the joint density decays to zero at a speed of power @xmath111 of the distance from the frontier ; when @xmath112 , the density has a sudden jump at the frontier ; when @xmath113 , the density increases toward infinity at a speed of power @xmath114 of the distance from the frontier .",
    "the case @xmath115 corresponds to sharp or fault - type frontiers .",
    "[ rmk2.4.22 ] as an immediate consequence of corollary [ ( corscors ) ] , when @xmath99 and @xmath116 ( or , equivalently , @xmath117 ) does not depend on @xmath22 , we obtain the convergence in distribution of the fdh estimator , as in hwang _",
    "et al . _",
    "@xcite ( see remark [ rmk2.4.1 ] ) , with the same convergence rate @xmath39 ( in the notation of @xcite , theorem 1 , @xmath118 ) . in the other particular case where the joint density is strictly positive on the frontier , we achieve the best rate of convergence @xmath36 , as in park _",
    "_  @xcite ( in the notation of theorem 3.1 in @xcite , @xmath119 ) .",
    "note , also , that the condition with @xmath120 ( as in corollary [ ( corscors ) ] ) has been considered by @xcite . in section [ parag2.3 ]",
    ", we answer the important question of how to estimate the shape parameter @xmath48 in or , equivalently , the regular variation exponent @xmath47 in .    as an immediate consequence of theorem [ thm1](iii ) in conjunction with corollary [ ( corscors ) ] , we obtain @xmath121\\\\[-8pt ] & & { } + \\mathrm{o}\\bigl(n^{-k/(\\beta_x+p+1)}\\bigr ) .\\nonumber\\end{aligned}\\ ] ] this extends the limit theorem of moments of park _ et al .",
    "_  ( @xcite , theorem 3.3 ) to the more general setting where @xmath48 may be non - null .",
    "likewise , hwang _ et al . _",
    "( @xcite , remark 1 ) provide only for @xmath122 , @xmath99 and @xmath116 .",
    "the result also reflects the well - known curse of dimensionality from which the fdh estimator @xmath35 suffers as the number @xmath123 of inputs - usage increases , as pointed out earlier by park _",
    "et al . _",
    "@xcite in the particular case where @xmath124 .      by an appropriate choice of @xmath54 as a function of @xmath125 ,",
    "et al . _",
    "@xcite have shown that @xmath126 estimates the full frontier @xmath29 itself and converges to the same weibull distribution as the fdh @xmath35 under the restrictive conditions of @xcite .",
    "the next theorem provides further insights and generalizes their main result .",
    "[ thm2.2 ]    a.",
    "if @xmath127 , then for any fixed integer @xmath128 , @xmath129 for the distribution function @xmath130 . b.   suppose that the upper bound of the support of @xmath15 is finite . if @xmath131 , then @xmath132 for all sequences @xmath133 satisfying @xmath134 .",
    "when @xmath35 converges in distribution , the estimator @xmath135 , for @xmath136 ( that is , @xmath137 in theorem [ thm2.2](i ) ) , estimates @xmath29 itself and also converges in distribution , with the same scaling , but a different limit distribution ( here , . to recover the same limit distribution as the fdh estimator",
    ", it suffices to require that @xmath138 rapidly so that @xmath134 .",
    "this extends the main result of aragon _ et al . _",
    "( @xcite , theorem  4.3 ) , where the convergence rate achieves @xmath36 under the restrictive assumption that the density of @xmath16 is strictly positive on the frontier .",
    "note , also , that the estimate @xmath139 does not envelop all of the data points providing a robust alternative to the fdh frontier @xmath140 ; see @xcite for an analysis of its quantitative and qualitative robustness properties .",
    "the important question of how to estimate @xmath47 from the multivariate random sample @xmath28 is very similar to the problem of estimating the so - called _ extreme value index , _ which is based on a sample of _ univariate _ random variables .",
    "an attractive estimation method has been proposed by @xcite , which can be easily adapted to our conditional approach : let @xmath141 be a sequence of integers tending to infinity and let @xmath142 as @xmath143 .",
    "a pickands - type estimate of @xmath47 can be derived as @xmath144 the following result is particularly important since it allows the hypothesis @xmath145 to be tested and will later be employed to derive asymptotic confidence intervals for @xmath29 .",
    "[ thm2 ] if holds , @xmath146 and @xmath147 , then @xmath148 .",
    "a.   if holds , @xmath149 and @xmath150 , then @xmath151 .",
    "b.   assume that @xmath152 , @xmath153 , has a positive derivative and that there exists a positive function @xmath154 such that for @xmath155 , @xmath156 for either choice of the sign @xmath157-variation , which will in the sequel be denoted by : @xmath158 .",
    "then , @xmath159 with asymptotic variance @xmath160 , for @xmath146 satisfying @xmath161 , where @xmath162 is the generalized inverse function of @xmath163 . c.   if , for some @xmath164 and @xmath165 , the function @xmath166 , then holds with @xmath167^{-1/\\rho_x}(\\rho_x)^{{1}/{\\rho _",
    "x}-1})\\}^2 $ ] .",
    "note that the second order regular variation conditions ( iii ) and ( iv ) of theorem [ thm2 ] are difficult to check in practice , which makes the theoretical choice of the sequence @xmath168 a hard problem . in practice , in order to choose a reasonable estimate @xmath169 of @xmath47 , one can construct the plot of @xmath170 , consisting of the points @xmath171 , and select a value of @xmath47 at which the obtained graph looks stable .",
    "this technique is known as the _ pickands plot _ in the univariate extreme value literature ( see , for example , @xcite and the references therein , section 4.5 , pages 9396 ) .",
    "this is this kind of idea which guides the automatic data - driven rule we suggest in section [ sec3 ] .",
    "we can also easily adapt the well - known moment estimator for the index of a univariate extreme value distribution ( dekkers _ et al . _",
    "@xcite ) to our conditional setup .",
    "define @xmath172 we can then define the moment - type estimator for the conditional regular - variation exponent @xmath47 as @xmath173^{-1}\\biggr\\}^{-1 } .\\ ] ]    [ thm ? ] if holds , @xmath149 and @xmath174 , then @xmath175 .",
    "a.   if holds , @xmath149 and @xmath176 for some @xmath165 , then @xmath177 . b.   if @xmath178 for some positive function @xmath179 , then @xmath180 has , asymptotically , a normal distribution with mean zero and variance @xmath181 for @xmath146 satisfying @xmath161 , where @xmath182 ^ 2 $ ] .    note that the @xmath157-variation condition @xmath183 of theorem [ thm2](iii ) is equivalent to @xmath184 , following theorem a.3 in @xcite , and that this equivalent regular - variation condition implies that @xmath185 , according to @xcite , proposition 0.11(a ) , with auxiliary function @xmath186 .",
    "hence , the condition of theorem [ thm2](iii ) implies that of theorem [ thm?](iii ) .",
    "note , also , that a result similar to theorem  [ thm?](iii ) can be stated under the conditions of theorem [ thm2](iv ) .",
    "the next theorem enables the construction of confidence intervals for @xmath29 and for high quantile - type frontiers @xmath187 when @xmath188 and @xmath189 .",
    "[ thm3 ]    a.   suppose that @xmath55 has a positive density @xmath190 .",
    "then , @xmath191 where @xmath192 , provided that @xmath193 , @xmath189 and @xmath194 $ ]",
    ". b.   suppose that the conditions of theorem or hold , and define @xmath195 then , putting @xmath196 , we have @xmath197 c.   suppose that the conditions of theorem or hold , and define @xmath198 then , putting @xmath199 , we have @xmath200\\\\[-8pt ] & & \\bigl\\{\\hat\\varphi_{1-{(k_n-1)}/{(n\\hat f_x(x))}}(x)- \\hat\\varphi_{1-{(2k_n-1)}/{(n\\hat f_x(x))}}(x)\\bigr\\}\\big/\\biggl\\{\\frac{n}{2k_n}u'\\biggl(\\frac{n}{2k_n}\\biggr)\\biggr\\}\\nonumber\\\\ & & \\quad \\stackrel { p}{\\longrightarrow}\\rho_x(1 - 2^{-1/\\rho_x } ) .\\nonumber\\end{aligned}\\ ] ]    [ rmk424 ] note that theorem [ thm3](ii ) is still valid if the estimate @xmath170 is replaced by the true value @xmath47 , up to a change of the asymptotic variance .",
    "it is easy to see that @xmath201 and so the estimator @xmath202 of @xmath29 is asymptotically more efficient than @xmath203 .",
    "we also conclude from that @xmath204 and @xmath203 have the same rate of convergence , namely @xmath205 . in the particular case where @xmath206 in , we have @xmath207 .",
    "note , also , that in this particular case , the condition of theorem  [ thm3](i ) holds , that is , @xmath208 .",
    "however , the conditions of theorem  [ thm2](iii ) and ( iv ) do not hold since both functions @xmath209 and @xmath210 are constant in @xmath211 . nevertheless , the conclusions of theorem  [ thm2](iii ) and ( iv ) hold in this case for all sequences @xmath212 satisfying @xmath213 . the same is true for the conclusion of theorem  [ thm3](ii ) .",
    "[ thm3bis ] if the condition of corollary [ ( corcor ) ] holds , @xmath212 and @xmath214 as @xmath215 , then @xmath216\\\\ & & \\quad { } \\stackrel{d}{\\longrightarrow } \\mathcal{n}(0,1)\\qquad   \\mbox{as }   n \\rightarrow\\infty .\\end{aligned}\\ ] ]    [ rmq29 ] the optimization of the asymptotic mean - squared error of@xmath217 is not an appropriate criteria for selecting the optimal @xmath218 since the resulting value of @xmath218 does not depend on @xmath125",
    ".    we shall now construct asymptotic confidence intervals for both @xmath29 and @xmath219 using the sums @xmath220 and @xmath221 .",
    "[ thm2.7 ]    a.   under the conditions of theorem [ thm3 ] , @xmath222 where @xmath223 , provided that @xmath193 , @xmath189 and @xmath194 $ ] .",
    "b.   suppose that the conditions of theorem hold and that @xmath224 has a regularly varying derivative @xmath225 .",
    "define the moment estimator @xmath226 then , @xmath227 .\\hspace*{78pt}&\\end{aligned}\\ ] ]      [ exemple1 ] we consider the case where the support frontier is linear .",
    "we choose @xmath16 uniformly distributed over the region @xmath228 . in this case",
    "( see , for example , @xcite ) , it is easy to see that @xmath229 and @xmath230=(\\varphi(x)-y)^2 $ ] for all @xmath231 . thus , @xmath232 and @xmath233 for all @xmath22 .",
    "therefore , the conclusions of all theorems [ thm1][thm3bis ] hold ( see remark [ rmk424 ] ) .",
    "[ exemple2 ] we now choose a nonlinear monotone upper boundary given by the cobb ",
    "douglas model @xmath234 , where @xmath14 is uniform on @xmath235 $ ] and @xmath236 , independent of  @xmath14 , is exponential with parameter @xmath237 ( see , for example , @xcite ) . here , the frontier function is @xmath238 and the conditional distribution function is @xmath239 for @xmath240 and @xmath241 .",
    "it is then easily seen that the extreme value condition or , equivalently , holds with @xmath233 and @xmath242/[\\varphi(x)]^3 $ ] for all @xmath2430,1]$ ] and @xmath155 .",
    "the simulation experiments of this section illustrate how the convergence results work in practice .",
    "we also apply our approach to a real data set on the production activity of the french postal services .",
    "we will simulate 2000 samples of size @xmath244 according the scenario of example [ exemple1 ] above . here ,",
    "@xmath229 and @xmath245 . denote by @xmath246 the number of observations @xmath34 with @xmath247 . by construction of the estimators @xmath248 and @xmath203 , the threshold @xmath249 can vary between 1 and @xmath250 . for the estimator with known @xmath47 and @xmath204 ,",
    "@xmath249 is bounded by @xmath251 and , finally , for the moment estimators @xmath252 and @xmath253 , the upper bound for @xmath249 is given by @xmath254 .",
    "so , in our monte carlo experiments for the pickands estimator , @xmath249 was selected on a grid of values determined by the observed value of @xmath255 .",
    "we choose @xmath256 - k + 1 $ ] , where @xmath257 is an integer varying between 1 and @xmath258 $ ] . in the tables below , @xmath259 is the average value observed over the 2000 monte carlo replications .",
    "the tables display the values of @xmath260 , which is the average of the monte carlo values of @xmath249 obtained for a fixed selection of values of @xmath257 . for the moment estimators ,",
    "the upper values of @xmath249 were chosen as @xmath254 .",
    "the tables display only a part of the results to save space , but in each case , we typically choose a set of values of @xmath257 that includes not only the most favorable cases , but also covers a wide range of values for @xmath249 .",
    "these tables provide the monte carlo estimates of the bias and the mean - squared error ( mse ) of the various estimators computed over the 2000 random replications , as well as the average lengths and the achieved coverages of the corresponding 95% asymptotic confidence intervals .",
    "they display only the results for @xmath22 ranging over @xmath261 to save space .",
    "@d4.1d2.5d5.5d2.5d2.5d2.5d1.5@ & & & & & & +   + [ 3pt ] 77.7 & -0.25757 & 784.19539 & -0.02585 & 6.93961 & 0.00021 & 0.00028 + 74.4 & 0.41215 & 17.20703 & 0.03723 & 0.14471 & 0.00024 & 0.00028 + 71.0 & 0.42344 & 105.75775 & 0.03830 & 0.89895 & 0.00016 & 0.00028 + 67.7 & 0.44401 & 16.30552 & 0.03877 & 0.11468 & 0.00030 & 0.00028 + 64.4 & 0.30552 & 145.08207 & 0.02564 & 1.01166 & 0.00031 & 0.00029 + 61.0 & 0.68905 & 35.13730 & 0.05654 & 0.24012 & 0.00053 & 0.00029 + 57.7 & 0.82177 & 15489.98302 & 0.05929 & 89.02353 & 0.00053 & 0.00029 + 54.3 & 1.17914 & 1780.66037 & 0.08527 & 9.90370 & 0.00055 & 0.00029 + 51.0 & -4.41384 & 13169.38480 & -0.33207 & 74.80129 & 0.00046 & 0.00030 + 47.6 & 0.03147 & 3204.61688 & -0.00179 & 14.27123 & 0.00064 & 0.00029 + [ 6pt ] + [ 3pt ] 312.1 & 0.09248 & 0.22503 & 0.01696 & 0.00735 & 0.00026 & 0.00029 + 297.0 & 0.09311 & 0.24340 & 0.01668 & 0.00759 & 0.00012 & 0.00029 + 281.9 & 0.09124 & 0.24958 & 0.01595 & 0.00742 & -0.00001 & 0.00029 + 266.8 & 0.09201 & 0.27538 & 0.01579 & 0.00780 & -0.00009 & 0.00029 + 251.7 & 0.08954 & 0.29784 & 0.01490 & 0.00797 & -0.00042 & 0.00030 + 236.6 & 0.09840 & 0.33195 & 0.01584 & 0.00831 & -0.00049 & 0.00030 + 221.5 & 0.11387 & 0.38048 & 0.01768 & 0.00893 & -0.00043 & 0.00030 + 206.3 & 0.12297 & 0.47557 & 0.01840 & 0.01038 & -0.00060 & 0.00030 + 191.2 & 0.12060 & 0.43562 & 0.01720 & 0.00881 & -0.00081 & 0.00030 + 176.1 & 0.14573 & 0.72946 & 0.01989 & 0.01371 & -0.00080 & 0.00029 + [ 6pt ] + [ 3pt ] 1250.0 & 0.02755 & 0.04085 & 0.01025 & 0.00540 & 0.00078 & 0.00028 + 1188.0 & 0.02863 & 0.04254 & 0.01047 & 0.00537 & 0.00085 & 0.00028 + 1126.0 & 0.02780 & 0.04643 & 0.00991 & 0.00557 & 0.00065 & 0.00029 + 1064.0 & 0.02689 & 0.05068 & 0.00953 & 0.00575 & 0.00064 & 0.00030 + 1002.0 & 0.02890 & 0.05241 & 0.00981 & 0.00559 & 0.00061 & 0.00029 + 940.0 & 0.02670 & 0.05545 & 0.00875 & 0.00552 & 0.00032 & 0.00029 + 878.0 & 0.02738 & 0.06064 & 0.00872 & 0.00564 & 0.00029 & 0.00029 + 816.0 & 0.02877 & 0.06738 & 0.00882 & 0.00577 & 0.00024 & 0.00028 + 754.0 & 0.03001 & 0.07071 & 0.00899 & 0.00562 & 0.00037 & 0.00028 + 692.0 & 0.03686 & 0.07869 & 0.01065 & 0.00583 & 0.00065 & 0.00029 +    we will first comment on the results obtained for the pickands estimators and for the estimator of @xmath29 obtained with the knowledge that @xmath262 ( the jump of the joint density of @xmath16 at the frontier ) ; these results are displayed in tables [ tab : mcex2_bmse ] and [ tab : mcex2_ci ] .",
    "we observe that the pickands estimates @xmath263 and @xmath203 behave much better when the sample size @xmath255 increases , although the convergence is rather slow . in contrast , even with the smallest sample size @xmath255 ( for @xmath264 ) , the estimator @xmath204 computed with the true value of @xmath233 provides remarkable estimates of @xmath29 and is rather stable with respect to the choice of @xmath249 .",
    "we see the improvement of @xmath204 over the fdh in terms of the bias , without significantly increasing the mse .",
    "the achieved coverages of the normal confidence intervals obtained from @xmath265 are also quite satisfactory and much easier to derive than those obtained from the fdh estimator .",
    "as soon as @xmath255 is greater than 1000 , all of the estimators provide reasonably good confidence intervals of the corresponding unknown , with quite good achieved coverages . in these cases ( @xmath266 )",
    ", we also observe some stability of the results with respect to the choice of @xmath249 .",
    "@d4.1d5.4d1.4d4.4d1.4d1.4d1.4@ & & & & & & +   + [ 3pt ] 77.7 & 630.9019 & 0.9040 & 59.3041 & 0.8925 & 0.0670 & 0.9455 + 74.4 & 18.4635 & 0.9060 & 1.6821 & 0.8970 & 0.0670 & 0.9505 + 71.0 & 92.5814 & 0.9000 & 8.5104 & 0.8960 & 0.0670 & 0.9480 + 67.7 & 18.6125 & 0.8990 & 1.5673 & 0.8910 & 0.0670 & 0.9485 + 64.4 & 131.0169 & 0.8910 & 10.9372 & 0.8845 & 0.0670 & 0.9525 + 61.0 & 37.9315 & 0.8960 & 3.1260 & 0.8840 & 0.0671 & 0.9465 + 57.7 & 14491.7449 & 0.8965 & 1098.2578 & 0.8850 & 0.0671 & 0.9470 + 54.3 & 1735.9675 & 0.8930 & 129.3070 & 0.8820 & 0.0671 & 0.9430 + 51.0 & 13077.3352 & 0.8910 & 981.3170 & 0.8805 & 0.0671 & 0.9440 + 47.6 & 3374.6016 & 0.8925 & 224.7041 & 0.8735 & 0.0672 & 0.9410 + [ 6pt ] + [ 3pt ] 312.1 & 1.7798 & 0.9295 & 0.3232 & 0.9195 & 0.0670 & 0.9485 + 297.0 & 1.8330 & 0.9255 & 0.3248 & 0.9245 & 0.0669 & 0.9490 + 281.9 & 1.8810 & 0.9250 & 0.3247 & 0.9240 & 0.0669 & 0.9475 + 266.8 & 1.9457 & 0.9220 & 0.3269 & 0.9240 & 0.0669 & 0.9460 + 251.7 & 2.0095 & 0.9200 & 0.3279 & 0.9145 & 0.0668 & 0.9505 + 236.6 & 2.1038 & 0.9195 & 0.3329 & 0.9165 & 0.0668 & 0.9420 + 221.5 & 2.2256 & 0.9150 & 0.3409 & 0.9100 & 0.0668 & 0.9390 + 206.3 & 2.3707 & 0.9115 & 0.3506 & 0.9075 & 0.0668 & 0.9440 + 191.2 & 2.4375 & 0.9105 & 0.3468 & 0.9085 & 0.0667 & 0.9455 + 176.1 & 2.7460 & 0.9155 & 0.3754 & 0.9080 & 0.0667 & 0.9440 + [ 6pt ] + [ 3pt ] 1250.0 & 0.8019 & 0.9645 & 0.2909 & 0.9605 & 0.0670 & 0.9540 + 1188.0 & 0.8238 & 0.9625 & 0.2914 & 0.9595 & 0.0670 & 0.9555 + 1126.0 & 0.8463 & 0.9535 & 0.2914 & 0.9495 & 0.0670 & 0.9425 + 1064.0 & 0.8707 & 0.9510 & 0.2915 & 0.9445 & 0.0670 & 0.9435 + 1002.0 & 0.8994 & 0.9530 & 0.2922 & 0.9455 & 0.0670 & 0.9475 + 940.0 & 0.9273 & 0.9445 & 0.2918 & 0.9420 & 0.0669 & 0.9460 + 878.0 & 0.9614 & 0.9420 & 0.2923 & 0.9450 & 0.0669 & 0.9420 + 816.0 & 1.0002 & 0.9450 & 0.2932 & 0.9440 & 0.0669 & 0.9500 + 754.0 & 1.0426 & 0.9475 & 0.2939 & 0.9460 & 0.0669 & 0.9550 + 692.0 & 1.0976 & 0.9455 & 0.2966 & 0.9430 & 0.0670 &",
    "0.9455 +    @d4.1d2.5d4.5d2.5d1.5d5.4d1.4d3.4d1.4@ & & & & & & & & +   + [ 3pt ] 150.4 & 0.36520 & 1.47278 & -0.04187 & 0.00339 & 2.5969 & 0.8900 & 0.0869 & 0.3350 + 137.9 & 0.35077 & 1.86333 & -0.03615 & 0.00337 & 2.8243 & 0.8905 & 0.0939 & 0.3765 + 125.3 & 0.33799 & 1.26492 & -0.03080 & 0.00226 & 2.7378 & 0.8990 & 0.0893 & 0.4435 + 112.9 & 0.30315 & 1.02334 & -0.02670 & 0.00173 & 2.7495 & 0.9005 & 0.0874 & 0.4840 + 100.4 & 0.27374 & 0.93872 & -0.02284 & 0.00139 & 2.8414 & 0.8930 & 0.0873 & 0.5495 + 87.9 & 0.28569 & 1.22921 & -0.01810 & 0.00137 & 3.1695 & 0.8965 & 0.0936 & 0.5860 + 75.4 & 0.30500 & 9.96907 & -0.01330 & 0.00806 & 7.3693 & 0.8865 & 0.2075 & 0.6340 + 62.9 & 0.26381 & 29.37920 & -0.01097 & 0.02156 & 17.2434 & 0.8880 & 0.4629 & 0.6740 + 50.5 & 0.51850 & 18.67121 & -0.00130 & 0.01090 & 14.4349 & 0.8780 & 0.3524 & 0.7020 + 38.0 & 0.53418 & 21.11753 & 0.00124 & 0.00956 & 18.2022 & 0.8645 & 0.3897 & 0.7225 + 19.2 & 0.62323 & 267.28452 & 0.00481 & 0.06789 & 246.3768 & 0.8430 & 3.8848 & 0.7525 + 12.9 & -0.30491 & 1266.44113 & -0.00977 & 0.30730 & 1431.7282 & 0.8150 & 22.2514 & 0.7315 + [ 6pt ] + [ 3pt ] 600.5 & 0.16644 & 0.16966 & -0.09657 & 0.01004 & 0.9860 & 0.8375 & 0.0645 & 0.0575 + 550.5 & 0.16412 & 0.16874 & -0.08407 & 0.00776 & 1.0281 & 0.8590 & 0.0667 & 0.0890 + 500.4 & 0.16750 & 0.17596 & -0.07212 & 0.00588 & 1.0818 & 0.8735 & 0.0691 & 0.1360 + 450.5 & 0.17133 & 0.18419 & -0.06106 & 0.00440 & 1.1442 & 0.8970 & 0.0715 & 0.2155 + 400.5 & 0.16370 & 0.19777 & -0.05158 & 0.00334 & 1.2099 & 0.9085 & 0.0733 & 0.2945 + 350.5 & 0.15716 & 0.20738 & -0.04270 & 0.00250 & 1.2897 & 0.9225 & 0.0751 & 0.3815 + 300.5 & 0.16437 & 0.23740 & -0.03370 & 0.00182 & 1.4051 & 0.9335 & 0.0778 & 0.4775 + 250.4 & 0.15151 & 0.25663 & -0.02649 & 0.00137 & 1.5307 & 0.9430 & 0.0794 & 0.5650 + 200.5 & 0.13915 & 0.28167 & -0.01987 & 0.00101 & 1.7031 & 0.9415 & 0.0811 & 0.6475 + 150.5 & 0.12971 & 0.36589 & -0.01373 & 0.00082 & 1.9765 & 0.9305 & 0.0836 & 0.7180 + 50.5 & 0.29865 & 6.19391 & 0.00098 & 0.00356 & 6.8895 & 0.8895 & 0.1734 & 0.8000 + 13.0 & -0.58590 & 9410.59672 & -0.01445 & 1.57034 & 10243.4270 & 0.8150 & 131.6029 & 0.7550 + [ 6pt ] + [ 3pt ] 2000.0 & 0.13502 & 0.05141 & -0.14729 & 0.02230 & 0.5207 & 0.7685 & 0.0664 & 0.0000 + 1800.0 & 0.13019 & 0.05132 & -0.12609 & 0.01649 & 0.5471 & 0.8140 & 0.0682 & 0.0025 + 1600.0 & 0.12099 & 0.04935 & -0.10701 & 0.01202 & 0.5765 & 0.8455 & 0.0697 & 0.0145 + 1400.0 & 0.11212 & 0.05190 & -0.08930 & 0.00855 & 0.6129 & 0.8595 & 0.0712 & 0.0455 + 1200.0 & 0.10555 & 0.05445 & -0.07261 & 0.00584 & 0.6593 & 0.8965 & 0.0727 & 0.1055 + 1000.0 & 0.09393 & 0.05677 & -0.05771 & 0.00388 & 0.7168 & 0.9180 & 0.0740 & 0.2325 + 800.0 & 0.07446 & 0.05965 & -0.04469 & 0.00251 & 0.7911 & 0.9245 & 0.0748 & 0.3680 + 600.0 & 0.07713 & 0.07992 & -0.03069 & 0.00148 & 0.9179 & 0.9310 & 0.0771 & 0.5615 + 400.0 & 0.06905 & 0.10581 & -0.01877 & 0.00087 & 1.1221 & 0.9415 & 0.0790 & 0.7255 + 200.0 & 0.07559 & 0.20770 & -0.00744 & 0.00059 & 1.6176 & 0.9365 & 0.0830 & 0.8375 + 100.0 & 0.09821 & 0.49803 &",
    "-0.00225 & 0.00067 & 2.4204 & 0.9095 & 0.0896 & 0.8465 + 50.0 & 0.15884 & 1.20953 & 0.00051 & 0.00083 & 3.9082 & 0.8920 & 0.1034 & 0.8420 +    we now turn to the performances of the moment estimators @xmath267 and @xmath253 .",
    "the results are displayed in table [ tab : mcex2_mom ] .",
    "note that we used the same seed in the monte carlo experiments as the one used for the preceding tables .",
    "compared with the pickands estimators @xmath170 and @xmath203 , we observe here much more reasonable results in terms of the bias and mse of the estimators @xmath252 and @xmath253 . in addition ,",
    "when @xmath255 increases , the results are much less sensitive to the choice of @xmath249 than for the pickands estimators .",
    "we also observe that the most favorable values of @xmath249 for estimating @xmath47 and @xmath29 are not necessarily in the same range of values .",
    "we note that the confidence intervals for @xmath47 achieve quite reasonable coverage as soon as @xmath255 is greater than , say , 1000 . however , the results for the confidence intervals of @xmath29 obtained from the moment estimator @xmath253 are very poor , even when @xmath255 is as large as 5000 . a more detailed analysis of the monte carlo results allows us to conclude that this comes from an under - evaluation of the asymptotic variance of @xmath268 given in theorem [ thm2.7 ]",
    "indeed , in most of the cases , the monte carlo standard deviation of @xmath253 was larger than the asymptotic theoretical expression by a factor of the order 25 when @xmath255 equalled @xmath269 , and by a factor of the order 1.31.7 when it equalled @xmath270 .",
    "so , the poor behavior seems to improve slightly when @xmath255 increases , but at a very slow rate .",
    "we could say that using the pickands estimators @xmath170 and @xmath203 is only reasonable in our setup when @xmath255 is larger than , say , 1000 .",
    "these estimators are highly sensitive to the choice of @xmath249 .",
    "the moment estimators @xmath252 and @xmath268 have a much better behavior in terms of bias and mse , and a greater stability with respect to the choice of @xmath249 , even for moderate sample sizes .",
    "when @xmath255 is very large ( @xmath271 ) , @xmath248 and @xmath203 become more accurate than the moment estimators . on the other hand , the confidence intervals of @xmath47 constructed from the asymptotic distribution of @xmath170",
    "provide more satisfactory results than those derived from the limit distribution of @xmath267 for large values of @xmath255 , say , @xmath272 . for inference purposes on the frontier function itself",
    ", the estimate of the asymptotic variance of the moment estimator @xmath253 does not provide reliable confidence intervals , even for relatively large values of @xmath255 . in the latter case , it would be better to use the confidence intervals obtained from the asymptotic distribution of the pickands estimator @xmath203 .",
    "so , in terms of bias and mse computed over the 2000 random replications , as well as the average lengths and the achieved coverages of the @xmath273 asymptotic confidence intervals , the moment estimators of @xmath47 and @xmath29 are sometimes preferable to the pickands estimators and sometimes not .",
    "it is difficult to imagine one procedure being preferable in all contexts .",
    "hence , a sensible practice is not to restrict the frontier analysis to one procedure , but rather to check that both pickands and moment estimators point toward similar conclusions .",
    "however , when @xmath47 is known , we have remarkable results for @xmath204 , even when @xmath255 is small , including remarkable properties of the resulting normal confidence intervals , with great stability with respect to the choice of @xmath249 . recall that in most situations described thus far in the econometric literature on frontier analysis , this tail index @xmath47 is supposed to be known and equal to @xmath43 ( here , @xmath245 ) : this corresponds to the common assumption that there is a jump of the joint density of @xmath16 at the frontier .",
    "this might suggest the following strategy with a real data set .",
    "if @xmath47 is known ( typically equal to @xmath43 if the assumption of a jump at the frontier is reasonable ) , then we can use the estimator  @xmath204 .",
    "if , on the other hand , @xmath47 is unknown , we could consider using the following two - step estimator : first , estimate @xmath108 ( the moment estimator of @xmath47 seems the more appropriate , unless @xmath255 is large enough ) and , second , use the estimator @xmath204 , as if @xmath47 were known , by substituting the estimated value @xmath267 or @xmath170 in place of @xmath47 . in a situation involving a real data set ,",
    "the best approach is not to favor the moment or the pickands estimator of @xmath47 in the first step , but to compute @xmath204 by substituting in each of them , in the hope that the two resulting values of @xmath204 point toward similar conclusions .",
    "it should be clear that the two - step estimator @xmath204 , obtained by substituting in @xmath170 , does not necessarily coincide with the pickands estimator @xmath274 which is , instead , obtained by a simultaneous estimation of @xmath47 and @xmath29 .",
    "indeed , in our monte carlo exercise , we have observed that the most favorable values of @xmath249 for estimating @xmath47 and @xmath29 are not necessarily in the same range of values .",
    "thus , nothing guarantees that the selected value @xmath249 when computing @xmath170 in the first step is the same as the one selected when computing  @xmath203 .",
    "of course , when @xmath255 is very large , the two values of @xmath249 are expected to be similar , but the idea in the two - step procedure is to use the asymptotic results of the more efficient estimator @xmath204 and not those of @xmath203 . in the next section , we suggest an ad hoc procedure for determining appropriate values of @xmath249 with a real data set .",
    "the question of selecting the optimal value of @xmath249 is still an open issue and is not addressed here .",
    "we will simply suggest an empirical rule that turns out to give reasonable estimates of the frontier in the simulated samples above .",
    "first , we have observed in our monte carlo exercise that the optimal value for selecting @xmath249 when estimating the index @xmath47 is not necessarily the same as the value for estimating @xmath29 .",
    "the  idea is thus to select first , for each @xmath22 ( in a chosen grid of values ) , a grid of values for @xmath249 for estimating @xmath47 . for the pickands estimator @xmath170",
    ", we choose @xmath256 - k + 1 $ ] , where @xmath257 is an integer varying between 1 and @xmath258 $ ] , and for the moment estimator @xmath252 , we choose @xmath275 , where @xmath257 is an integer varying between 1 and @xmath255 .",
    "we then evaluate the estimator @xmath276 ( resp . , @xmath277 ) and",
    "select the @xmath257 where the variation of the results is the smallest .",
    "we achieve this by computing the standard deviations of @xmath276 ( resp . , @xmath278 ) over a ` window ' of @xmath279 $ ] ( resp . ,",
    "@xmath280 $ ] ) successive values of @xmath257 .",
    "the value of @xmath257 where this standard deviation is minimal defines the value of @xmath249 .",
    "we follow the same procedure for selecting a value for @xmath249 for estimating the frontier @xmath29 itself . here , in all of the cases , we choose a grid of values for @xmath249 given by @xmath281 $ ] and select the @xmath257 where the variation of the results is the smallest . to achieve this here ,",
    "we compute the standard deviations of @xmath204 ( resp . ,",
    "@xmath203 and @xmath253 ) over a ` window ' of size @xmath282)$ ] ( this corresponds to having a window large enough to cover around 10% of the possible values of @xmath257 in the selected range of values for @xmath249 ) . from now on ,",
    "we only present illustrations for @xmath204 to save space .    for a sample generated with @xmath283 in the uniform case",
    ", we get the results shown in fig .",
    "[ fig1 ] .     for a uniform data set of size @xmath283 ( plus one outlier for the right panels ) ; from top to bottom , we have the cases @xmath233 , substituting in @xmath170 , substituting in @xmath252 . ]    in fig .",
    "[ fig1 ] , the estimator @xmath204 is first computed with the true value @xmath233 ( top panel of the figure ) , then with a plug - in value of @xmath47 estimated by the pickands estimator ( middle panel ) and finally with a plug - in value of @xmath252 estimated by the moment estimator ( bottom panel ) .",
    "the pointwise confidence intervals are also displayed .",
    "the three right - hand panels correspond to the same data set plus one outlier .",
    "this allows us to see how our robust estimators behave in the presence of outlying points , in contrast with the fdh estimator .",
    "in particular , due to the remarkable behavior of @xmath265 in the monte carlo experiment , if we know that @xmath233 , then we should use the top panel results and , according to our suggestion at the end of the preceding section , if @xmath47 is unknown , we should use , in this particular example , the bottom panel results , where we replace @xmath47 by its moment estimator @xmath252 ( since here @xmath284 ) and continue as if @xmath47 were known .",
    "it is quite encouraging that the two panels are very similar .     for the french post offices .",
    "we include four extreme data points ( circles ) for the bottom panels . from left to right , we have the cases @xmath233 , substituting in @xmath252 . ]",
    "we use the same real data example as in @xcite , which undertook the frontier analysis of @xmath285 french post offices observed in @xmath286 , with @xmath14 as the quantity of labor and @xmath15 as the volume of delivered mail . in this illustration",
    ", we only consider the @xmath287 observed post offices with the smallest levels @xmath288 .",
    "we used the empirical rules explained above for selecting reasonable values for @xmath249 .",
    "the cloud of points and the resulting estimates are provided in fig .",
    "[ fig : poste1 ] .    to save space",
    ", we only represent @xmath204 when @xmath47 is supposed to be equal to 2 ( left - hand panels ) and when it is estimated by the moment estimator ( right - hand panels ) .",
    "the fdh estimator is clearly determined by only a few very extreme points .",
    "if we delete four extreme points from the sample ( represented by circles in the figure ) , then we obtain the pictures from the top panels : the fdh estimator changes drastically , whereas the extreme - value - based estimator @xmath204 is very robust to the presence of these four extreme points .",
    "we also note the considerable stability of the various forms of the estimator @xmath204 .",
    "in our approach , we provide the necessary and sufficient condition for the fdh estimator @xmath35 to converge in distribution , we specify its asymptotic distribution with the appropriate convergence rate and provide a limit theorem for moments in a general framework .",
    "we also provide further insights and generalize the main result of @xcite on robust variants of the fdh estimator , and we provide strongly consistent and asymptotically normal estimators @xmath170 and @xmath252 of the unknown conditional tail index @xmath47 involved in the limit law of @xmath35 .",
    "moreover , when the joint density of @xmath16 decreases to zero or increases toward infinity at a speed of power @xmath289 of the distance from the boundary , as is often assumed in the literature , we answer the question of how @xmath47 is linked to the data dimension @xmath43 and to the shape parameter @xmath48 .",
    "the quantity @xmath290 describes the rate at which the density tends to infinity ( in the case @xmath291 ) or to @xmath292 ( in the case @xmath293 ) at the boundary . when @xmath124 , the joint density is strictly positive on the frontier .",
    "we establish that @xmath294 . as an immediate consequence ,",
    "we extend the previous results of @xcite to the general setting where @xmath44 and @xmath45 may depend on @xmath22 .",
    "we propose new extreme - value - based frontier estimators @xmath203 , @xmath204 and @xmath295 , which are asymptotically normally distributed and provide useful asymptotic confidence bands for the monotone frontier function @xmath29 .",
    "these estimators have the advantage of not being limited to a bi - dimensional support and benefit from their explicit and easy formulations , which is not the case for estimators defined by optimization problems , such as local polynomial estimators ( see , for example , @xcite ) .",
    "their asymptotic normality is derived under quite natural and general extreme value conditions , without lipschitz conditions on the boundary and without recourse to assumptions either on the marginal distribution of @xmath14 or on the conditional distribution of @xmath15 given @xmath296 , as is often the case in both statistical and econometrics literature on frontier estimation .",
    "the study of the asymptotic properties of the different estimators considered in the present paper is easily carried out by relating them to a simple dimensionless random sample and then applying standard extreme value theory ( for example , @xcite ) .",
    "two closely related works in boundary estimation via extreme value theory are @xcite , in which the estimation of the frontier function at a point @xmath22 is based on an increasing number of higher order statistics generated by the @xmath297 observations falling into a strip around @xmath22 , and @xcite , in which estimators are instead based on a fixed number of higher order statistics .",
    "the main difference with the present approach is that hall _",
    "et al . _",
    "@xcite only focus on estimation of the support curve of a bivariate density ( that is , @xmath99 ) in the case @xmath298 ( that is , the decrease in density is no more than algebraically fast ) , where it is known that estimators based on an increasing number of higher order statistics give optimal convergence rates .",
    "in contrast , gijbels and peng @xcite consider the maximum of all @xmath297 observations falling into a strip around @xmath22 and an end - point type of estimator based on three large order statistics of the @xmath297 s in the strip .",
    "this methodology is closely related and comparable to our estimation method using the pickands - type estimator , but , like the procedure of @xcite , it is only valid in the simple case @xmath99 and involves , in addition to the sequence @xmath218 , an extra smoothing parameter ( bandwidth of the strip ) which also needs to be selected .",
    "moreover , the asymptotic results in @xcite are provided for densities of @xmath16 decreasing as a power of the distance from the boundary , whereas the setup in our approach is a general one .",
    "also , note that our transformed dimensionless data set @xmath299 is constructed in such a way as to take into account the monotonicity of the frontier ( the end - point of the common distribution of the @xmath300 s coincides with the frontier function @xmath29 ) , the univariate random variables @xmath300 do not depend on the sample size and they allow the available results from standard extreme value theory to be easily employed , which is not the case for either of @xcite .",
    "it should be clear that the monotonicity constraint on the frontier is the main difference with most of the existing approaches in the statistical literature .",
    "indeed , the joint support of a random vector @xmath16 is often described in the literature as the set @xmath301 , where the graph of @xmath302 is interpreted as its upper boundary . as a matter of fact , the function of interest , @xmath24 , in our approach is the smallest monotone non - decreasing function which is greater than or equal to the frontier function @xmath302 . to our knowledge ,",
    "only the estimators fdh and dea estimate the quantity  @xmath24 . of course",
    ", @xmath302 coincides with @xmath24 when the boundary curve is monotone , but the construction of estimators of the end - point @xmath303 of the conditional distribution of @xmath15 given @xmath296 requires a smoothing procedure , which is not the case when the distribution of @xmath15 is conditioned by @xmath19 .",
    "we illustrate how the large - sample theory applies in practice by carrying out some monte carlo experiments .",
    "good estimates of @xmath29 and @xmath47 may require a large sample of the order of several thousand . theoretically selecting the optimal extreme conditional quantiles @xmath304 for estimating @xmath29 and/or @xmath47 is a difficult question that is worthy of future research .",
    "here , we suggest a simple automatic data - driven method that provides a reasonable choice of the sequence @xmath305 for large samples .",
    "the empirical study reveals that the simultaneous estimation of the tail index and of the frontier function requires large sample sizes to provide sensible results .",
    "the moment estimators of @xmath47 and of @xmath29 sometimes provide better estimations than the pickands estimates and sometimes not .",
    "when considering bias and mse , @xmath253 and @xmath252 provide more accurate estimations , but when the sample size is large enough , @xmath203 and @xmath170 significantly improve and even seem to outperform the moment estimators . as far as the inference on @xmath47 is concerned , @xmath306 also provides quite reliable confidence intervals , but @xmath170 provides more satisfactory results for sufficiently large samples .",
    "however , when inference about the frontier function itself is concerned , the moment estimator provides very poor results compared with the pickands estimator .",
    "on the other hand , the performance of the estimator @xmath204 , computed when @xmath47 is known , is quite remarkable , even compared with the popular fdh .",
    "the confidence intervals for @xmath29 are very easy to compute and have quite good coverages .",
    "in addition , the results are quite stable with respect to the choice of the ` smoothing ' parameter @xmath249 . as shown in our illustrations",
    ", the estimates also have the advantage of being robust to extreme values .",
    "this suggests , even if @xmath47 is unknown , the use of a plug - in version of @xmath204 for making inference on @xmath29 : here , in a first step , we estimate @xmath47 ( using the moment estimator , unless @xmath255 is large enough ) , then we use the asymptotic results for @xmath204 , as if @xmath47 was known .",
    "a sensible practice is not to restrict the first step to one procedure , but rather to check that both pickands and moment estimators point toward similar conclusions .",
    "proof of theorem [ thm1 ] let @xmath307 and @xmath308\\}\\mathbh{1}(\\cdot\\geq0)$ ] .",
    "it can be easily seen that @xmath309 for any @xmath310 .",
    "therefore , @xmath311 , @xmath312 is an i.i.d .",
    "sequence of random variables with common distribution function  @xmath313 .",
    "moreover , it is easy to see that the right end - point of @xmath313 coincides with @xmath29 and that @xmath314 coincides with @xmath315 .",
    "thus , assertion ( i ) follows from the fisher  tippett theorem .",
    "it is well known that the normalized maxima @xmath316 ( that is , @xmath313 belongs to the domain of attraction of @xmath317 ) if and only if @xmath318 where @xmath319 .",
    "this necessary and sufficient condition is equivalent to . in this case",
    ", the norming constant @xmath76 can be taken to be equal to @xmath320 , which gives assertion ( ii ) . for assertion ( iii ) , since holds and @xmath321=f_x(x)\\mathbb{e}(y^k|x\\leq x)\\leq{\\varphi ( x)}^k$ ] , it is immediate ( see @xcite , proposition  2.1 ) that @xmath322 .",
    "likewise , the last result follows from  @xcite , corollary 2.3 .",
    "proof of corollary [ ( corcor ) ] following the proof of theorem [ thm1 ] , we can set @xmath323 , where @xmath3240,\\varphi(x)]\\dvtx   f_x ( y ) \\geq t\\}$ ] for all @xmath3250,1]$ ] .",
    "it follows from that @xmath326 as @xmath327 and so @xmath328 for all @xmath125 sufficiently large .",
    "proof of corollary [ ( corscors ) ] under the given conditions , it can be easily seen from that @xmath329\\qquad   \\mbox{as }   y\\uparrow\\varphi(x ) , \\end{aligned}\\ ] ] where the term @xmath330 depends on the partial derivatives of @xmath331 , @xmath332 and @xmath333 .",
    "a.   if @xmath336 , then @xmath337 for each @xmath338 .",
    "b.   for any fixed integer @xmath128 , we have @xmath337 as @xmath339 , with probability @xmath92 . c.   for any sequence of integers @xmath340 such that @xmath214 as @xmath215 , we have @xmath341    proof of theorem [ thm2.2 ] ( i ) since @xmath342 and @xmath343 for all @xmath344 , we have  @xmath345 . hence ,",
    "if @xmath127 , then @xmath346 converges to the same distribution @xmath67 . therefore , following @xcite , theorem 21.18 , @xmath347 for any integer @xmath128 , where @xmath348",
    "finally , since @xmath349 as @xmath215 , in view of lemma [ delt](ii ) , we obtain @xmath350 .",
    "writing @xmath351 , it suffices to find an appropriate sequence @xmath352 such that @xmath353 .",
    "et al . _",
    "@xcite ( see equation ( 20 ) ) showed that @xmath354 with probability @xmath92 , for any @xmath355 .",
    "it thus suffices to choose @xmath356 such that @xmath357 .",
    "proof of theorem [ thm2 ] ( i ) let @xmath358 in .",
    "the pickands @xcite estimate of the exponent of variation @xmath359 is then given by @xmath360 under , condition holds and so there exists @xmath66 such that @xmath361 = \\psi _ { -1/\\gamma_x}(y ) .",
    "$ ] since this limit is unique only up to affine transformations , we have @xmath362 = \\psi_{-1/\\gamma_x}(-\\gamma_x y-1)= \\exp\\{-(1+\\gamma_x y)^{-1/\\gamma_x } \\}\\end{aligned}\\ ] ] for all @xmath363 , where @xmath364 and @xmath365 .",
    "thus , condition ( 1.1 ) from dekkers and de haan @xcite holds .",
    "therefore , @xmath366 if @xmath146 and @xmath367 , in view of @xcite , theorem 2.1 .",
    "this gives the weak consistency of @xmath170 since @xmath368 as @xmath369 , in view of lemma  [ delt](iii ) .",
    "we have @xmath373 , which corresponds to the inverse function @xmath374 .",
    "since @xmath375 with @xmath376 , it follows from @xcite ( see theorem 2.3 ) that @xmath377 with @xmath378 for @xmath212 satisfying @xmath379 , where @xmath380 . by using the fact that @xmath381 as @xmath215 ,",
    "in view of lemma [ delt](iii ) and applying the delta method , we conclude that @xmath382 with asymptotic variance @xmath383 .",
    "proof of theorem [ thm ? ] we have , by lemma [ delt](iii ) , that for each @xmath385 , @xmath386 @xmath387 then coincides almost surely , for all @xmath125 large enough , with the well - known moment estimator @xmath388 ( given by @xcite , equation ( 1.7 ) ) of the index defined in by @xmath389 .",
    "hence , theorem  [ thm?](i ) and ( ii ) follow from the weak and strong consistency of @xmath388 proved in @xcite , theorem 2.1",
    ". likewise , theorem  [ thm?](iii ) follows by applying @xcite , corollary 3.2 , in conjunction with the delta method .",
    "proof of theorem [ thm3 ] ( i ) under the regularity condition , the distribution function @xmath313 of @xmath390 has a positive derivative @xmath391 for all @xmath392 such that @xmath393 .",
    "therefore , according to @xcite ( see theorem 3.1 ) , @xmath394 is asymptotically normal with mean zero and variance @xmath395 .",
    "we conclude by using the facts that @xmath396 and @xmath397      let @xmath401 be the order statistics of i.i.d .",
    "exponential variables @xmath402 .",
    "then , @xmath403 .",
    "writing @xmath404 , we obtain @xmath405\\\\ & & \\hspace*{33pt}{}\\times \\frac{v'(\\log{n}/{(2k_n)})}{v(e_{(n - k_n+1)})-v(e_{(n-2k_n+1 ) } ) } .\\end{aligned}\\ ] ] the first term on the right - hand side tends to zero as established by dekkers and de haan ( @xcite , proof of theorem 3.2 ) .",
    "the second term converges in distribution to @xmath406 , in view of lemma 3.1 and @xcite , corollary 3.1 .",
    "the third term converges in probability to @xmath407 by the same corollary 3.1 .",
    "this ends the proof of ( iii ) , in conjunction with the fact that @xmath408 with probability @xmath92 .",
    "proof of theorem [ thm3bis ] write @xmath409 $ ] and @xmath410 for all @xmath411 .",
    "let @xmath412 for all @xmath413 and let @xmath414 be the statistic of order @xmath415 generated by @xmath125 independent standard exponential random variables .",
    "@xmath416 then has the same distribution as @xmath417 $ ] , where @xmath418 hence , @xmath419-r^{-1}_x\\biggl[\\log \\biggl(\\frac{n}{k_n}\\biggr)\\biggr]\\\\ & & \\quad = \\biggl[e_{(n - k_n + 1 ) } - \\log\\biggl(\\frac{n}{k_n}\\biggr)\\biggr ] ( r^{-1}_x ) ' \\biggl[\\log\\biggl(\\frac{n}{k_n}\\biggr)\\biggr]\\\\ & & \\qquad { } + \\frac { 1}{2 } \\biggl[e_{(n - k_n + 1 ) } - \\log \\biggl(\\frac{n}{k_n}\\biggr)\\biggr]^2 ( r^{-1}_x ) '' [ \\delta_n ] , \\end{aligned}\\ ] ] provided that @xmath420 . by the regularity condition",
    ", we have that @xmath421 for all @xmath211 large enough .",
    "therefore , for all @xmath125 sufficiently large , @xmath422\\\\ & & \\quad \\stackrel{d}{= } k^{1/2}_n\\bigl[e_{(n -k_n + 1 ) } - \\log(n / k_n)\\bigr]\\\\ & & \\qquad { } -\\{k^{1/2}_n/2\\rho_x\\}\\bigl[e_{(n - k_n+1 ) } -\\log(n / k_n)\\bigr]^2 \\exp\\{-[\\delta_n - \\log(n / k_n)]/\\rho_x\\ } .\\end{aligned}\\ ] ] since @xmath423 \\stackrel{{d}}{\\rightarrow } \\mathcal{n}(0,1)$ ] and @xmath424 as @xmath425 , we obtain @xmath426\\stackrel{{d}}{\\longrightarrow } \\mathcal{n}(0,1)$ ] as @xmath427 .",
    "since @xmath428 for all @xmath429 large enough , we have @xmath430 for all @xmath125 sufficiently large .",
    "thus , @xmath431\\stackrel{{d}}{\\to } \\mathcal{n}(0,1)$ ] as @xmath215 .",
    "we conclude by using the fact that @xmath432 as @xmath339 .",
    "proof of theorem [ thm2.7 ] ( i ) as shown in the proof of theorem [ thm3](i ) , we have @xmath433 .",
    "then , by applying dekkers",
    "_ et al . _",
    "@xcite , theorem 5.1 , in conjunction with , we get @xmath434 the proof is completed by simply using the fact that @xmath435 and @xmath436 as @xmath215 .    since @xmath437 and @xmath438 as @xmath215",
    ", we have @xmath439 as @xmath215 .",
    "it is then easy to see from that @xmath295 coincides almost surely , for all @xmath125 large enough , with the end - point estimator @xmath440 of @xmath441 introduced by @xcite , equation ( 4.8 ) .",
    "it is also easy to check that @xmath442 satisfies the conditions of @xcite , theorem 3.1 , with @xmath443 .",
    "according to @xcite , theorem 5.2 , we then have @xmath444 which gives the desired convergence in distribution of theorem [ thm2.7](ii ) since @xmath445 , @xmath446 , @xmath438 and @xmath437 as @xmath215",
    ".                deprins , d. , simar , l. and tulkens , h. ( 1984 ) . measuring labor inefficiency in post offices . in _ the  performance of public enterprises : concepts and measurements _ ( m. marchand , p. pestieau and h.  tulkens , eds . ) 243267 .",
    "amsterdam : north - holland ."
  ],
  "abstract_text": [
    "<S> in this paper , we investigate the problem of nonparametric monotone frontier estimation from the perspective of extreme value theory . </S>",
    "<S> this enables us to revisit the asymptotic theory of the popular free disposal hull estimator in a more general setting , to derive new and asymptotically gaussian estimators and to provide useful asymptotic confidence bands for the monotone boundary function . </S>",
    "<S> the finite - sample behavior of the suggested estimators is explored via monte carlo experiments . </S>",
    "<S> we also apply our approach to a real data set based on the production activity of the french postal services .    , </S>"
  ]
}