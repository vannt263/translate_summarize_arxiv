{
  "article_text": [
    "can be said to be built by the interplay of various instruments .",
    "a human can easily identify what instruments are used in a music , but it is still a difficult task for a computer to automatically recognize them .",
    "this is mainly because music in the real world is mostly polyphonic , which makes extraction of information from an audio highly challenging .",
    "furthermore , instrument sounds in the real world vary in many ways such as for timbre , quality , and playing style , which makes identification of the musical instrument even harder .    in the music information retrieval ( mir ) field",
    ", it is highly desirable to know what instruments are used in an audio sample .",
    "first of all , instrument information per se is an important and useful information for users , and it can be included in the audio tags .",
    "there is a huge demand for music search owing to the increasing number of music files in digital format . unlike text search",
    ", it is difficult to search for music because input queries are usually in text format .",
    "if an instrument information is included in the tags , it allows people to search for music with the specific instrument they want .",
    "in addition , the obtained instrument information can be used for various audio / music applications .",
    "for instance , more instrument - specific and tailored audio equalization can be applied to the music ; moreover , a music recommendation system can reflect the preference of users for musical instruments .",
    "furthermore , it can also be used to enhance the performance of other mir tasks .",
    "for example , knowing the number and type of the instrument would significantly improve the performance of source separation and automatic music transcription ; it would also be helpful for identifying the genre of the music .",
    "instrument recognition can be performed in various forms .",
    "hence , the term `` instrument recognition '' or `` instrument identification '' might indicate several different research topics .",
    "for instance , many of the related works focus on studio - recorded isolated notes . to name a few",
    ", eronen used cepstral coefficients and temporal features to classify 30 orchestral instruments with several articulation styles and achieved a classification accuracy of 95% for instrument family level and about 81% for individual instruments @xcite .",
    "diment et al .",
    "used a modified group delay feature that incorporates phase information together with mel - frequency cepstral coefficients ( mfccs ) and achieved a classification accuracy of about 71% for 22 instruments @xcite .",
    "yu et al . applied sparse coding on cepstrum with temporal sum - pooling and achieved an f - measure of about 96% for classifying 50 instruments",
    "they also reported their classification result on a multi - source database , which was about 66% .    some previous works such as krishna and sreenivas @xcite experimented with a classification for solo phrases rather than for isolated notes .",
    "they proposed line spectral frequencies ( lsf ) with a gaussian mixture model ( gmm ) and achieved an accuracy of about 77% for instrument family and 84% for 14 individual instruments .",
    "moreover , essid et al .",
    "@xcite reported that a classification system with mfccs and gmm along with principal components analysis ( pca ) achieved an overall recognition accuracy of about 67% on solo phrases with five instruments .",
    "more recent works deal with polyphonic sound , which is closer to real - world music than to monophonic sound . in the case of polyphonic sound , a number of research studies used synthesized polyphonic audio from studio - recorded single tones .",
    "heittola et al .",
    "@xcite used a non - negative matrix factorization ( nmf)-based source - filter model with mfccs and gmm for synthesized polyphonic sound and achieved a recognition rate of 59% for six polyphonic notes randomly generated from 19 instruments .",
    "kitahara et al .",
    "@xcite used various spectral , temporal , and modulation features with pca and linear discriminant analysis ( lda ) for classification .",
    "they reported that , using feature weighting and musical context , recognition rates were about 84% for a duo , 78% for a trio , and 72% for a quartet .",
    "duan et al .",
    "@xcite proposed the uniform discrete cepstrum ( udc ) and mel - scale udc ( mudc ) as a spectral representation with a radial basis function ( rbf ) kernel support vector machine ( svm ) to classify 13 types of western instruments .",
    "the classification accuracy of randomly mixed chords of two and six polyphonic notes , generated using isolated note samples from the rwc musical instrument sound database @xcite , was around 37% for two polyphony notes and 25% for six polyphony notes .",
    "as shown above , most of the previous works focused on the identification of the instrument sounds in clean solo tones or phrases .",
    "more recent research studies on polyphonic sounds are closer to the real - world situation , but artificially produced polyphonic music is still far from professionally produced music .",
    "real - world music has many other factors that affect the recognition performance .",
    "for instance , it might have a highly different timbre , depending on the genre and style of the performance .",
    "in addition , an audio file might differ in quality to a great extent , depending on the recording and production environments .    in this paper",
    ", we investigate a method for predominant instrument recognition in professionally produced western music recordings .",
    "we utilize convolutional neural networks ( convnets ) to learn the spectral characteristics of the music recordings with 11 musical instruments and perform instrument identification on polyphonic music excerpts .",
    "the major contributions of the work presented in this paper are as follows .",
    "= 0.7 cm 1 .",
    "we present the convnet architecture for predominant musical instrument identification where the training data are single labeled and the target data are multi - labeled with an unknown number of classes existing in the data .",
    "= 0.7 cm 2 .",
    "we introduce a new method to aggregate the outputs of convnets from short - time sliding windows to find the predominant instruments in a music excerpt with variable length , where the conventional method of majority vote often fails .",
    "= 0.7 cm 3 .",
    "we conduct an extensive experiment on activation function for the neurons used in convnets , which can cause a huge impact on the identification result .",
    "the remainder of the paper is organized as follows . in section",
    "ii , we introduce emerging deep neural network techniques in the mir field .",
    "next , the system architecture section includes audio preprocessing , the proposed network architecture with detailed training configuration , and an explanation of various activation functions used for the experiment .",
    "section iv , the evaluation section , contains information about the dataset , testing configuration including aggregation strategy , and our evaluation scheme .",
    "then , we illustrate the performance of the proposed convnet in section v , the results section , with an analysis of the effects of activation function , analysis window size , aggregation strategy , and identification threshold , and with an instrument - wise analysis .",
    "moreover , we present a qualitative analysis based on the visualization of the convnet s intermediate outputs to understand how the network captured the pattern from the input data . finally , we conclude the paper in section vi .",
    "the ability of traditional machine learning approaches was limited in terms of processing input data in their raw form .",
    "hence , usually the input for the learning system , typically a classifier , has to be a hand - crafted feature representation , which requires extensive domain knowledge and a careful engineering process .",
    "however , it is getting more common to design the system to automatically discover the higher - level representation from the raw data by stacking several layers of nonlinear modules , which is called deep learning @xcite .",
    "recently , deep learning techniques have been widely used across a number of domains owing to their superior performance . a basic architecture of deep learning",
    "is called deep neural network ( dnn ) , which is a feedforward network with multiple hidden layers of artificial neurons .",
    "dnn - based approaches have outperformed previous state - of - the - art methods in speech applications such as phone recognition , large - vocabulary speech recognition , multi - lingual speech recognition , and noise - robust speech recognition @xcite .",
    "there are many variants and modified architectures of deep learning , depending on the target task .",
    "especially , recurrent neural networks ( rnns ) and convnets have recently shown remarkable results for various multimedia information retrieval tasks .",
    "rnns are highly powerful approaches for sequential inputs as their recurrent architecture enables their hidden units to implicitly maintain the information about the past elements of the sequence . since languages natively contain sequential information , it is widely applied to handle text characters or spoken language .",
    "it has been reported that rnns have shown a successful result on language modeling @xcite and spoken language understanding @xcite .        on the other hand",
    ", convnet is useful for data with local groups of values that are highly correlated , forming distinctive local characteristics that might appear at different parts of the array @xcite .",
    "hence , it is one of the most popular approaches recently in the image processing area such as handwritten digit recognition @xcite for the mnist dataset and image tagging @xcite for the cifar-10 dataset .",
    "in addition , it has been reported that it has outperformed state - of - the - art approaches for several computer vision benchmark tasks such as object detection , semantic segmentation , and category - level object recognition @xcite , and also for speech - recognition tasks @xcite .",
    "the time - frequency representation of a music signal is composed of harmonics from various musical instruments and a human voice .",
    "each musical instrument produces a unique timbre with different playing styles , and this type of spectral characteristics in music signal might appear in a different location in time and frequency as in the image .",
    "convnets are usually composed of many convolutional layers , and inserting a pooling layer between convolutional layers allows the network to work at different time scales and introduces translation invariance with robustness against local distortions .",
    "these hierarchical network structures of convnets are highly suitable for representing music audio , because music tends to present a hierarchical structure in time and different features of the music might be more salient at different time scales @xcite .    hence ,",
    "although convnets have been a more commonly used technique in image processing , there are an increasing number of attempts to apply convnets for music signal .",
    "it has been reported that convnet has outperformed previous state - of - the - art approaches for various mir tasks such as onset detection @xcite , automatic chord recognition @xcite , and music structure / boundary analysis @xcite .",
    "an attempt to apply convnets for musical instrument identification can be found in the recent report from park et al .",
    "@xcite and li et al .",
    "@xcite , although it is still an ongoing work and is not a predominant instrument recognition method ; hence , there are no other instruments but only target instrument sounds exist .",
    "our research differs from @xcite because we deal with polyphonic music , while their work is based on the studio recording of single tones .",
    "in addition , our research also differs from @xcite because we use single - label data for training and estimate multi - label data , while they used multi - label data from the training phase .",
    "moreover , they focused on an end - to - end approach , which is promising in that using raw audio signals makes the system rely less on domain knowledge and preprocessing , but usually it shows a slightly lower performance than using spectral input such as mel - spectrogram in recent papers @xcite .",
    "the convolutional neural network is one of the representation learning methods that allow a machine to be fed with raw data and to automatically discover the representations needed for classification or detection @xcite .",
    "however , appropriate preprocessing of input data is still an important issue to improve the performance of the system .    in the first preprocessing step ,",
    "the stereo input audio is converted to mono by taking the mean of the left and right channels , and then it is downsampled to 22,050 hz from the original 44,100 hz of sampling frequency .",
    "this allows us to use frequencies up to 11,025 hz , the nyquist frequency , and it is sufficient to cover most of the harmonics generated by musical instruments while removing noises possibly included in the frequencies above this range .",
    "moreover , all audios are normalized by dividing the time - domain signal with its maximum value .",
    "then , this downsampled time - domain waveform is converted to a time - frequency representation using short - time fourier transform ( stft ) with 1024 samples for the window size ( approx .",
    "46 ms ) and 512 samples of the hop size ( approx . 23",
    "next , the linear frequency scale - obtained spectrogram is converted to a mel - scale .",
    "we use 128 for the number of mel - frequency bins , following the representation learning papers on music annotation by nam et al .",
    "@xcite and hamel et al .",
    "@xcite , which is a reasonable setting that sufficiently preserves the harmonic characteristics of the music while greatly reducing the dimensionality of the input data .",
    "finally , the magnitude of the obtained mel - frequency spectrogram is compressed with a natural logarithm .",
    "convnets can be seen as a combination of feature extractor and the classifier .",
    "our convnet architecture generally follows a popular alexnet @xcite and vggnet @xcite structure , which contains very deep architecture using repeated several convolution layers followed by max - pooling , as shown in figure [ fig : figure_sysarch ] .",
    "this method of using smaller receptive window size and smaller stride for convnet is becoming highly common especially in the computer vision field such as in the study from zeiler and fergus @xcite and sermanet et al .",
    "@xcite , which has shown superior performance in ilsvrc-2013 .",
    "although the general architecture style is similar to that of other successful convnets in the image processing area , the proposed convnet is designed according to our input data .",
    "we use filters with a very small @xmath0 receptive field , with a fixed stride size of 1 , and spatial abstraction is done by max - pooling with a size of @xmath0 and a stride size of 1 .    in table",
    "[ tab : convnet_arch ] , we illustrate the detailed convnet architecture with the input size in each layer with parameter values except the zero - padding process .",
    "the input for each convolution layer is zero - padded with @xmath1 to preserve the spatial resolution regardless of input window size , and we increase the number of channels for the convolution layer by a factor of 2 after every two convolution layers , starting from 32 up to 256 .    in the last max - pooling layer after the eight convolutional layers , we perform global max - pooling followed by one fully connected layer .",
    "recently , it has been reported that the use of global average pooling without a fully connected layer before a classifier layer is less prone to overfitting and shows better performance for image processing datasets such as cifar-10 and mnist @xcite .",
    "however , our empirical experiment found that global average pooling slightly decreases the performance and that global max - pooling followed by a fully connected layer works better for our task .    finally , the last classifier layer is the sigmoid layer .",
    "it is common to use a softmax layer when there is only one target label , but our system must be able to handle multiple instruments present at the same time , and , thus , a sigmoid output is used .    .proposed convnet structure .",
    "the input size demonstrated in this table is for an analysis window size of 1 second ( number of filters @xmath2 time @xmath2 frequency ) .",
    "the activation function is followed by each convolutional layer and a fully connected layer .",
    "the input of each convolution layer is zero - padded with 1 @xmath2 1 , but is not shown for brevity . [",
    "cols=\"<,<\",options=\"header \" , ]     [ tab : theta_comp ]      we conducted an experiment with two different strategies , _",
    "s1 _ and _ s2 _ , for the aggregation of convnet outputs as explained in the testing configuration section .",
    "the performance of _ s1 _ and _ s2 _ is demonstrated in table [ tab : theta_comp ] with a threshold @xmath3 that returned the highest @xmath4 measure for each strategy . as a result , _",
    "s2 _ showed better identification performance than _",
    "s1 _ overall .",
    "there was only a slight performance gap between _",
    "s1 _ and _ s2 _ for the micro @xmath4 measure , but the difference was notable for the macro @xmath4 measure .",
    "this result shows that performing a class - wise sum followed by normalization is a better aggregation method for predominant instrument identification than taking class - wise mean values .",
    "it is likely due to the training and testing audios differing in quality to a great extent , depending on the recording and production time , and the audio - excerpt - wise normalization helped to minimize the effect of quality differences between audio excerpts , which would result in a more generalized output .",
    "the results demonstrated above were focused on the overall identification performance . in this section ,",
    "we analyze and discuss the result instrument - wise ( i.e. , class - wise ) to observe the system performance in detail .",
    "as shown in figure [ fig : class_wise ] , identification performance varies to a great extent , depending on the instruments .",
    "regardless of parameter setting , it can be observed that the system recognizes the voice in the music very well , showing an @xmath4 measure of about 0.90 . on the other hand ,",
    "cello and clarinet showed relatively poor performance compared to other instruments , showing an @xmath4 measure of around 0.20 .",
    "these results were highly likely affected by the insufficient number of training audio samples . for deep learning ,",
    "the number of training examples is critical for the performance compared to the case of using hand - crafted features because it aims to learn a feature from the low - level input data .",
    "as illustrated in table [ tab : instruments ] , the number of training audio samples for voice is 778 , which is the largest number of training audio . on the contrary ,",
    "338 and 505 audio excerpts were used for cello and clarinet , respectively , which were the least and third least number of training audio .",
    "we believe that increasing the number of training data for cello and clarinet would be helpful to increase the identification performance for these instruments .",
    "in addition , the number of test audio samples for cello and clarinet was much less than those for other instruments too .",
    "the dataset only has 111 and 62 test audio samples for cello and clarinet , respectively , which are the first and second least number of test audio , while it has 1044 audio samples for the human voice .",
    "evaluating the system on a small number of test data would make the result less reliable and less stable than other identification results .",
    "apart from the issue related to the number of audio , high identification performance of the voice class is highly likely owing to its spectral characteristic that is distinct from other musical instruments .",
    "the other instruments used in the experiment usually produce relatively clear harmonic patterns ; however , the human voice produces highly unique spectral characteristics that contain much more inharmonic spectrum with a natural vibrato .    regarding aggregation strategy , using _",
    "s1 _ instead of _",
    "s2 _ decreased the identification performance for organ and piano .",
    "this result indicates that _ s1 _ showed a slight advantage on instruments that are usually used as an accompaniment instrument , while using _",
    "s1 _ for aggregation was better for most of the cases . on the other hand , using a 3-s analysis window instead of the default 1-s window considerably decreased the performance , especially for flute , acoustic guitar , electric guitar , and violin .",
    "this result shows that using a longer analysis window is a disadvantage for most of the cases . finally , using a very low identification threshold , 0.20 ,",
    "caused considerable performance loss especially for flute , saxophone , trumpet , and violin , while it showed a slight improvement for electric guitar , organ , and piano .",
    "this result can be understood to mean that using a lower threshold for identification performance helps to detect instruments that are usually in the background , while using a higher threshold is suitable for instruments that are frequently used as a lead instrument or for wind instruments that usually show relatively strong presence in the music . as mentioned in the results section",
    ", this result indicates that there can be a potential performance improvement by using a different identification threshold for each instrument .",
    "to understand the internal mechanism of the proposed model , we conducted a visual analysis with various visualization methods .",
    "first , we tried clustering for each layer s intermediate hidden states from a given input data sample to verify how the encoding behavior of each layer contributes to the clustering of input samples .",
    "we selected the t - distributed stochastic neighbor embedding ( t - sne ) @xcite algorithm , which is a technique for dimensionality reduction of high - dimensional data .",
    "second , we exploited the deconvolution @xcite method to identify the functionality of each unit in the proposed convnet model by visual analysis .",
    "our system basically repeats two convolutional layers followed by one pooling layer , and we grouped these three components and call it `` convolutional block '' throughout this section for simplicity .    the t - sne algorithm is based on the stochastic neighbor embedding ( sne ) algorithm , which converts the similarities between given data points to joint probability and then embeds high - dimensional data points to lower - dimensional space by minimizing the kuller - leibler divergence between the joint probability of low - dimensional embedding and the high - dimensional data points .",
    "this method is highly effective especially in a dataset where its dimension is very high @xcite .",
    "this advantage of the algorithm accorded well with our condition , where the target observations were necessarily in a high dimension since we reshaped each layer s filter activations to a single vector respectively .    with the visualization exploiting t - sne",
    ", we could observe how each layer contributed to the classification of the dataset . reflecting a gradually changing inter - distance of data points at each stage of the proposed model ,",
    "four intermediate activations were extracted at the end of each convolutional block and one from the hidden fully connected layer , and another one from the final output layer . for the compression of dimensionality and computational efficiency , we pooled the maximum values for activation matrices of each unit . by this process",
    ", the dimensionality of each layer s output could be diminished to each layer s unit size .",
    "we visualized on both randomly selected training and validation data samples from the entire dataset to verify both how the model exactly works and how it generalizes its classification capability . in figure",
    "[ fig : cluster_tsne_result_1s ] , it is clearly shown that data samples under the same class of instrument are well grouped and each group is separated farther , with the level of encoding being higher , particularly on the training set . while the clustering was not clearer than the former case , the tendency of clustering on the validation set was also found to be similar to the training set condition .",
    "another visualization method , deconvolution , has recently been introduced as a useful analysis tool to qualitatively evaluate each node of a convnet .",
    "the main principle of this method is to inverse every stage of operations reaching to the target unit , to generate a visually inspectable image that has been , as a consequence , filtered by the trained sub - functionality of the target unit @xcite . with this method ,",
    "it is possible to reveal intuitively how each internal sub - function works within the entire deep convolutional network , which tends to be thought of as a `` black box '' .    by this process",
    ", the functionality of a sub - part of the proposed model is explored .",
    "we generated deconvoluted images like those in figure [ fig : deconv_res_new ] from the arbitrary input mel - spectrogram , for each unit in the entire model .",
    "from the visual analysis of the resulting images , we could see several aspects of the sub - functionalities of the proposed model : ( 1 ) most units in the first layer tend to extract vertical , horizontal , and diagonal edges from the input spectrogram , just like the lower layers of convnets do in the usual image object recognition task .",
    "( 2 ) from the second layer through the fourth layer , each deconvoluted image indicates that each unit of the mid - layers has a functionality that searches for particular combinations of the edges extracted from the first layer .",
    "( 3 ) it was found that it is difficult to strongly declare each sub - part of the proposed model that detects a specific musical articulation or expression .",
    "however , in an inductive manner , we could see that some units indicate that they can be understood as a sub - function of such musical expression detector .",
    "we conducted a visual analysis of the deconvoluted image of two independent music signals , which have the same kind of sound sources , but differently labeled .",
    "for both cases , the most activated units of the first layer strongly suggested that their primary functionality is to detect a harmonic component on the input mel - spectrogram by finding horizontal edges in it , as shown in the top figures in figure [ fig : deconv_res_new ] .",
    "however , from the second layer to higher layers , the highly activated units behavior appeared to be quite different for each respective input signal .",
    "for instance , the most activated unit of signal ( a ) s second layer showed a functionality similar to onset detection , by detecting a combination of vertical and horizontal edges .",
    "compared to this unit , the most activated units of the third layer showed a different functionality that seems to activate unstable components such as the vibrato articulation or the `` slur '' of the singing voice part , by detecting a particular combination of diagonal and horizontal edges . on the other hand , the model s behavior in signal ( b ) was very different . as is clearly shown in the second and the third layers output in figure [ fig : deconv_res_new ]",
    ", the highly activated sub - functions were trying to detect a dense field of stable , horizontal edges which are often found in harmonic instruments like guitar .",
    "each field detected from those units corresponded to the region where the strumming acoustic guitar sound is .",
    "in this paper , we described how to apply convnet to identify predominant instrument in the real - world music .",
    "we trained the network using fixed - length single - labeled data , and identify an arbitrary number of the predominant instrument in a music clip with a variable length .",
    "our results showed that very deep convnet is capable of achieving good performance by learning the appropriate feature automatically from the input data .",
    "our proposed convnet architecture outperformed previous state - of - the - art approaches in a predominant instrument identification task on the irmas dataset .",
    "mel - spectrogram was used as an input to the convnet , and we did not use any source separation in the preprocessing unlike in existing works .",
    "we conducted several experiments with various activation functions for convnet .",
    "tanh and relu were used as a baseline , and the recently introduced lrelu and prelu were also evaluated .",
    "results confirmed that relu worked reasonably well , which is a de facto standard in recent convnet studies .",
    "furthermore , we obtained the better results with lrelu than with normal relu , especially with the very leaky setting ( @xmath5 = 0.33 ) .",
    "the performance of tanh was worse than those of other rectifier functions as expected , and prelu just showed a matching performance with relu for our task .",
    "this paper also investigated different aggregation methods for convnet outputs that can be applied to music excerpts with various lengths .",
    "we experimented with two different aggregation methods , which are the class - wise mean probability _",
    "s2 _ and the class - wise sum followed by normalization _ s2_. the experimental results showed that _ s2 _ is a better aggregation method because it effectively deals with the quality difference between audios through the audio - excerpt - wise normalization process .",
    "in addition , we conducted an extensive experiment with various analysis window sizes and identification thresholds .",
    "for the analysis window size , using a shorter window improved the performance by increasing the temporal resolution .",
    "however , 0.5 s was too short to obtain an accurate identification performance , and 1.0 s was found to be the optimal window size .",
    "there was a trade - off between precision and recall , depending on the identification threshold ; hence , we used an @xmath4 measure , which is the harmonic mean of precision and recall . for the result ,",
    "a threshold value of 0.5 showed the best performance .",
    "visualization of the intermediate outputs using t - sne showed that the feature representation became clearer each time the input data were passed through the convolutional blocks .",
    "moreover , visualization using deconvolution showed that the lower layer tended to capture the horizontal and vertical edges , and that the higher layer tended to seek the combination of these edges to describe the spectral characteristics of the instruments .",
    "our study shows that many recent advances in a neural network on the image processing area are transferable to the audio processing domain .",
    "however , audio signal processing , especially music signal processing , has many different aspects compared to the image processing area where convnets are most extensively used .",
    "for example , spectral characteristics are usually overlapped in both time and frequency unlike the objects in an image , which makes the detection difficult .",
    "moreover , music signals are much more repetitive and continuous compared to natural images and are present in various lengths .",
    "we believe that applying more musical knowledge on the aggregation part with adaptive thresholding for each instrument can improve the performance further , which warrants deeper investigation .",
    "this research was supported partly by the msip ( ministry of science , ict and future planning ) , korea , under the itrc ( information technology research center ) support program ( iitp-2016-h8501 - 16 - 1016 ) supervised by the iitp ( institute for information & communications technology promotion ) , and partly by a national research foundation of korea ( nrf ) grant funded by the msip ( nrf-2014r1a2a2a04002619 ) .",
    "yoonchang han was born in seoul , republic of korea , in 1986 .",
    "he studied electronic engineering systems at king s college london , uk , from 2006 to 2009 , and then moved to queen mary university of london , uk , and received an meng ( hons ) degree in digital audio and music system engineering with first class honours in 2011 .",
    "he is currently a phd candidate in digital contents and information studies at the music and audio research group ( marg ) , seoul national university , republic of korea .",
    "his main research interest lies within developing deep learning techniques for automatic musical instrument recognition .",
    "jaehun kim was born in seoul , republic of korea , in 1986 .",
    "he is currently a researcher at the music and audio research group .",
    "his research interests include signal processing and machine learning techniques applied to music and audio .",
    "he received a ba in english literature and linguistics from seoul national university and received an ms degree in the digital contents and information studies at the music and audio research group ( marg ) , seoul national university , republic of korea .",
    "kyogu lee is an associate professor at seoul national university and leads the music and audio research group .",
    "his research focuses on signal processing and machine learning techniques applied to music and audio .",
    "lee received a phd in computer - based music theory and acoustics from stanford university ."
  ],
  "abstract_text": [
    "<S> identifying musical instruments in polyphonic music recordings is a challenging but important problem in the field of music information retrieval . </S>",
    "<S> it enables music search by instrument , helps recognize musical genres , or can make music transcription easier and more accurate . in this paper </S>",
    "<S> , we present a convolutional neural network framework for predominant instrument recognition in real - world polyphonic music . </S>",
    "<S> we train our network from fixed - length music excerpts with a single - labeled predominant instrument and estimate an arbitrary number of predominant instruments from an audio signal with a variable length . to obtain the audio - excerpt - wise result , </S>",
    "<S> we aggregate multiple outputs from sliding windows over the test audio . in doing so </S>",
    "<S> , we investigated two different aggregation methods : one takes the average for each instrument and the other takes the instrument - wise sum followed by normalization . in addition , we conducted extensive experiments on several important factors that affect the performance , including analysis window size , identification threshold , and activation functions for neural networks to find the optimal set of parameters . using a dataset of 10k audio excerpts from 11 instruments for evaluation </S>",
    "<S> , we found that convolutional neural networks are more robust than conventional methods that exploit spectral features and source separation with support vector machines . </S>",
    "<S> experimental results showed that the proposed convolutional network architecture obtained an f1 measure of 0.602 for micro and 0.503 for macro , respectively , achieving 19.6% and 16.4% in performance improvement compared with other state - of - the - art algorithms .    </S>",
    "<S> = 1    shell : bare demo of ieeetran.cls for ieee journals    instrument recognition , convolutional neural networks , deep learning , multi - layer neural network , music information retrieval    * edics category : 3-bbnd * </S>"
  ]
}