{
  "article_text": [
    "determination of the eigenvalues and eigenvectors of a matrix is important in many areas of science , for example in web ranking @xcite , computer graphics and visualization @xcite , quantum mechanics @xcite , statistics @xcite , medicine , communications , construction vibration analysis @xcite .",
    "one of the most important numerical methods designed to calculate the eigenvalues and eigenvectors of matrix @xmath0 is the power method @xcite .",
    "it is used to determine a maximum module eigenvalue of @xmath0 and the corresponding eigenvector @xmath1 .",
    "the limit of the product @xmath2 , where @xmath3 is a randomly chosen element , is the vector corresponding to the largest eigenvalue .",
    "the eigenvalue can be calculated from the rayleigh quotient @xmath4 .",
    "the most common method of solving the full eigenvalue problem , i.e.  finding all the eigenvalues and corresponding eigenvectors , is the qr method @xcite .",
    "there are methods for locating eigenvalues such as gerschgorin theorem @xcite from 1931 .",
    "this theorem allows to strictly locate the position of the eigenvalues of the matrix with real or complex coefficients .",
    "however , it does not allow to localize the eigenvectors .    with the growing importance of these concepts",
    "there is a need to look for new methods of localizing simultaneously eigenvalues and eigenvectors .",
    "we do not know strict and efficient methods for locating eigenvectors of real or complex matrices , so we want to fill this gap . our aim is to create and analyze a new method of strict location eigenvectors and eigenvalues with the use of interval arithmetic .",
    "using the fact that the polynomial @xmath5 of the @xmath6-th degree equals the determinant of the matrix @xmath7 0 & 0 & 1 & \\ddots & \\vdots           \\\\[0.3em ] \\vdots & \\vdots & \\ddots & 1 & 0   \\\\[0.3em ] 0 & 0 & \\ldots & 0 & 1   \\\\[0.3em ] -a_0 & -a_1 & -a_2 & \\ldots & -a_{n-1 } \\end{bmatrix},\\ ] ] we show that we can effectively localize zeros of real or complex polynomials ( for non - strict methods see @xcite ) .",
    "the content of this paper can be described as follows . in the following short subsection we present an algorithm which is the final outcome of our theory . in the section 2",
    "we introduce notation and present the simple properties of our theory , which is based the concept of cone condition . the notion of cone condition originally appeared in the late 60 s in the works of alekseev , anosov , moser and sinai @xcite .",
    "these techniques are used in the examination of differential equations @xcite . in section 3",
    "we show the basic properties of operations . in the following section we present the main result of this article corollary [ x_1 ] , which allow as a consequence",
    "obtain strictly localize the position of the eigenvector corresponding to the given eigenvalue in a small cone . in the last section we present a simple algorithm and some numerical applications of the theory on a few basic examples .",
    "in particular for a random matrix of size @xmath8 with randomly generated values from the set @xmath9 $ ] we obtain the eigenvectors and eigenvalues with typical accuracy @xmath10 ( see example [ ex ] ) .      in this subsection",
    "we present a basic idea how our method can be used ( more detailed explanation is given in last section ) .",
    "this algorithm determines the accuracy for numerical approximation of the eigenvectors and the corresponding eigenvalues .",
    "now we introduce the following notation for clarity and simplicity of the presentation .",
    "a matrix @xmath0 of dimensions @xmath11 with elements @xmath12 is denoted by @xmath13_{1\\leq i ,",
    "j\\leq n}\\in m_n(\\k).\\ ] ] for @xmath14 by @xmath15}:=[a_{kj}]_{k \\in k , j \\in j}$ ] we denote the sub - matrix with rows @xmath16 and columns @xmath17 .",
    "we put @xmath18 for @xmath19 .",
    "for @xmath20 by @xmath21 we understand the set @xmath22 the identity matrix is denoted by @xmath23 .    by @xmath24",
    "we understand interval representation of @xmath25 that is an interval with representable ends such that @xmath26 .",
    "for complex number @xmath27 we put @xmath28 , and for a matrix @xmath29_{1\\leq i , j\\leq n}$ ] , @xmath30 denotes the matrix @xmath31_{1\\leq i , j\\leq n}$ ] .",
    "we refer the reader to @xcite for more information concerning interval arithmetic .    as a sup norm",
    "@xmath32 we take the maximum sum of absolute values of the elements in rows of matrix @xmath0 , that is @xmath33\\|_{\\infty } : = \\max\\limits_{1\\leq i\\leq n}\\sum_{j=1}^{n}\\|a_{ij}\\|_{\\infty}.\\ ] ]    we are given a matrix @xmath29_{1\\leq i , j\\leq n}\\in m_n(\\c)$ ] with pairwise disjoint single eigenvalues , @xmath34 for @xmath35 and @xmath36 .",
    "we assume that we have calculated the numerical approximation of eigenvectors @xmath37 and eigenvalues @xmath38 of the matrix @xmath0 . to locate the exact position of @xmath39-th eigenvector @xmath40 of @xmath0 one",
    "can use the following algorithm .",
    "[ code ]    1 .   put @xmath41$],[p:1 ] 2 .",
    "calculate interval hull @xmath42 of inverse of @xmath43 ( we call it the inverse interval matrix of @xmath43 ) we denote such an interval matrix that @xmath44 for every @xmath45.],[p:2 ] 3 .",
    "calculate the interval matrix @xmath46,[p:3 ] 4 .",
    "seek a constant @xmath47 as small as possible so that the matrix [ p:4 ]    @xmath48    where the number @xmath49 is at the intersection of the k - th row and k - th column , satisfies the following condition @xmath50}\\|_{\\infty } & < \\|(b^{\\e}_{[\\neq k,\\neq k]})^{-1}\\|_{\\infty}^{-1 } - \\|b^{\\e}_{[\\neq k , k]}\\|_{\\infty}.    \\end{aligned}\\ ] ] then the @xmath39-th eigenvector of @xmath0 satisfies @xmath51    we estimate the eigenvalue @xmath52 from the rayleigh coefficient @xmath53 we show more precise details in the last section of this paper .",
    "our method can be modified to work with multiple single eigenvalues ( see proposition [ dim ] ) .",
    "however , it does not work with multiple eigenvalues of the form but this is a typical problem of most algorithms calculating the eigenvalues and eigenvectors . @xmath54",
    "in this section we modify the concept of cones from @xcite , which will allow us to locate the eigenvectors of the matrix .",
    "let @xmath55 be a finite - dimensional banach space with semi - norms @xmath56 ( we call it _ contracting _ ) , @xmath57 ( which we call _ expanding _ ) such that @xmath58 defines an equivalent norm on @xmath55 . by the _",
    "r - norm _ for @xmath59 on the cone - space @xmath55 we take @xmath60    [ d1 ] let @xmath55 be a cone - space .",
    "we define the _ @xmath61-contracting cone _ in @xmath55 by @xmath62    note that @xmath63 in the same way we define @xmath61-contracting cone and @xmath61-expanding cone in subspace @xmath55 .",
    "if @xmath64 we will omit the subscript @xmath61 , in particular we speak of contracting cone .",
    "we introduce the scaling by @xmath61 of semi - norms to have better control over size of the cones ( see figure [ rys ] ) , and which consequently will allow us to better locate the eigenvectors .    0.43    ( -1.5,1.5 )  ( 0,0 ) ",
    "( -1.5,-1.5 )  cycle ; ( 1.5,1.5 ) ",
    "( 1.5,-1.5 )  cycle ; ( -1.5,0 )  ( 1.5,0 ) coordinate ( x axis ) ; ( 0,-1.5 )  ( 0,1.5 ) coordinate ( y axis ) ;    0.43    ( -1.5,0.75 ) ",
    "( 0,0 )  ( -1.5,-0.75 )  cycle ; ( 1.5,0.75 ) ",
    "( 1.5,-0.75 )  cycle ; ( -1.5,0 )  ( 1.5,0 ) coordinate ( x axis ) ; ( 0,-1.5 )  ( 0,1.5 ) coordinate ( y axis ) ;     +    0.45    ( -1.5,1.5 )  ( 0,0 )  ( 1.5,1.5 )  cycle ; ( -1.5,-1.5 )  ( 0,0 )  ( 1.5,-1.5 )  cycle ; ( -1.5,0 )  ( 1.5,0 ) coordinate ( x axis ) ; ( 0,-1.5 )  ( 0,1.5 ) coordinate ( y axis ) ;    0.45    ( -0.75,1.5 )  ( 0,0 ) ",
    "( 0.75,1.5 )  cycle ; ( -0.75,-1.5 )  ( 0,0 )  ( 0.75,-1.5 )  cycle ; ( -1.5,0 )  ( 1.5,0 ) coordinate ( x axis ) ; ( 0,-1.5 )  ( 0,1.5 ) coordinate ( y axis ) ;    for a product @xmath65 we introduce cone - space @xmath66 where we put @xmath67 analogically , we define cone - space for direct sum @xmath68 .    in our main result , corollary [ x_1 ] , the following proposition will play a crucial role .",
    "[ dim ] let @xmath69 be cone - space such that @xmath70 , @xmath71 and let @xmath59 be given .",
    "assume that we have direct sum decomposition @xmath72 such that @xmath73 then @xmath74    first we show that @xmath75 .",
    "for an indirect proof , assume that @xmath76 .",
    "then there exist linearly independent vectors @xmath77 .",
    "obviously @xmath78 for @xmath79 and uniques @xmath80 , @xmath81 .",
    "since @xmath82 and @xmath70 there exist a set of @xmath83 scalars , @xmath84 , not all zero , such that @xmath85 note that @xmath86 because otherwise vectors @xmath87 would not be linearly independent . consequently we obtain @xmath88 and thus @xmath89 , which implicate @xmath90 .",
    "we get a contradiction with the fact the sequence of vectors @xmath87 is linearly independent .",
    "the proof that @xmath91 is analogous . finally ,",
    "since @xmath92 and @xmath75 , @xmath91 we obtain @xmath93    by an _ operator _ we mean a linear mapping between cone - spaces @xmath55 and @xmath94 . we denote the space of all operators by @xmath95 .",
    "if @xmath96 , we denote @xmath97 by @xmath98 .",
    "let @xmath99 .",
    "we define @xmath100     { \\langle a \\rangle}_r & : = \\ ; & \\sup & \\ { r \\in \\r_+ \\ , | \\ ,   { \\interleavea{\\mathsf{x}}\\interleave}_r \\geqslant r{\\interleave{\\mathsf{x}}\\interleave}_r \\text { for all }   { \\mathsf{x } } \\in e : { \\mathsf{x } } \\in { \\langle e \\rangle}_r\\}. \\label{rate_2}\\end{aligned}\\ ] ]    let @xmath101 , @xmath102 be subspaces and let @xmath99 such that @xmath103 .",
    "we define @xmath104     { \\langle a|_{\\tilde{e } } \\rangle}_r & : = \\ ; & \\sup & \\ { r \\in \\r_+ \\ , | \\ ,   { \\interleavea{\\mathsf{x}}\\interleave}_r \\geqslant r{\\interleave{\\mathsf{x}}\\interleave}_r \\text { for all }   { \\mathsf{x } } \\in\\tilde{e } : { \\mathsf{x } } \\in { \\langle \\tilde{e } \\rangle}_r\\}.\\end{aligned}\\ ] ]    [ def:1 ] we say that @xmath99 is _ @xmath61-dominating _ , if @xmath105 by @xmath106 we denote the set of all @xmath99 which are @xmath61-dominating .",
    "if @xmath96 , we denote the space @xmath107 by @xmath108 .",
    "[ ob:1 ] let @xmath101 , @xmath102 be subspaces and let @xmath99 such that @xmath103 .",
    "we have @xmath109 moreover , if @xmath110 then @xmath111 .",
    "it is consequence of , and definition [ def:1 ] .",
    "[ inter ] let @xmath112 and let @xmath113 be arbitrary",
    ". then @xmath114    a{\\mathsf{v}}\\in { \\,\\rangle\\hspace{-1pt}f\\hspace{-1pt}\\langle_{r}\\ , } & \\implies { \\mathsf{v}}\\in { \\,\\rangle\\hspace{-1pt}e\\hspace{-1pt}\\langle_{r}\\,}.\\end{aligned}\\ ] ]    the proof is a simple modification of the proof of ( * ? ? ?",
    "* proposition 2.1 ) .",
    "[ domin ] let @xmath115 and @xmath116 .",
    "then @xmath117 and @xmath118    to prove the first inequality from , let @xmath119 and @xmath120 . from and theorem [ inter ]",
    "we know that @xmath121 .",
    "we have @xmath122    hence @xmath123 using and theorem [ inter ] , we obtain the second inequality from .    as a simple consequence of we",
    "obtain @xmath117 .",
    "in this section we show how given an operator @xmath0 to estimate @xmath124 , @xmath125 .",
    "consider two cone - spaces @xmath65 and @xmath126 .",
    "let @xmath127 be an operator given in the matrix form by @xmath128         a_{21 } & a_{22 }       \\end{bmatrix}.\\ ] ] by @xmath129 we define the @xmath61-norm of operator @xmath0 .",
    "observe that it satisfies @xmath130 note that in general it is not , if @xmath131 is not one dimensional , the classical operator norm for @xmath132 .",
    "[ ob ] let @xmath133 , @xmath134 we put @xmath128         a_{21 } & a_{22 }       \\end{bmatrix }       \\quad \\text{and } \\quad   r = \\begin{bmatrix }         i & 0            \\\\[0.3em ]         0 & ri       \\end{bmatrix}.\\ ] ] then @xmath135    [ tw ] let @xmath136_{1\\leq i , j\\leq 2}\\in\\o_r(e_1\\times e_2,f_1\\times f_2)$ ] .    1 .",
    "we have @xmath137 2 .   additionally ,",
    "if @xmath138 is invertible , then @xmath139    we show the proof for @xmath64 . for arbitrary @xmath140 the proof needs a simple modification , see observation [ ob ] .    for the proof of the first inequality , we take @xmath141 such that @xmath142 . from definition [ d1 ]",
    "we have @xmath143 therefore @xmath144    for the proof of the second inequality , suppose that @xmath145 , where @xmath146 , @xmath147 .",
    "then @xmath148    we know that @xmath149 finally , we obtain @xmath150    let us verify that the matrix @xmath151 @xmath152 is dominating .",
    "by theorem [ tw ] we have @xmath153 and therefore @xmath0 is dominating .",
    "in this section we show the main results of the paper , concerns the strict location of the eigenspace .",
    "we denote the spectrum of the operator @xmath0 by @xmath154 .",
    "[ lem ] let @xmath155",
    ". then @xmath156\\cup [ { \\langle a \\rangle}_r,\\infty).\\ ] ] moreover @xmath157\\cap [ { \\langle a \\rangle}_r,\\infty)=\\emptyset$ ] .    since @xmath155 we get @xmath157\\cap [ { \\langle a \\rangle}_r,\\infty)=\\emptyset$ ] .",
    "now we show implication .",
    "let @xmath158 be an eigenvalue of @xmath0 and let @xmath119 be a corresponding eigenvector . by we know that @xmath159 .",
    "we consider two cases .",
    "first suppose that @xmath160 .",
    "since @xmath161 is an eigenvector , @xmath162 , and thus @xmath163 . by we get @xmath164 now suppose that @xmath165 . by we",
    "get @xmath166 which complete the proof .",
    "let @xmath55 be a vector space over the field @xmath167 and let operator @xmath168 be given .",
    "one can easy deduce from the theorem of jordan , see ( * ? ? ?",
    "* appendix to chapter 4 ) for the general case , that if @xmath169 ( for @xmath170 we assume additional that @xmath171 and @xmath172 ) then there is a unique direct sum decomposition @xmath173 such that @xmath174 , @xmath175 and @xmath176 , @xmath177 .",
    "for @xmath178 we define @xmath179    [ tw1 ] let @xmath55 be a finite - dimensional cone - space and let @xmath155 .",
    "then there is a direct sum decomposition @xmath180    for the clarity of presentation we consider only the case @xmath64 and we omit the subscript @xmath61 .",
    "from lemma [ lem ] and jordan theorem we obtain a direct sum decomposition @xmath181 such that @xmath182\\quad\\text{and}\\quad \\sigma(a|_{e_{\\geq{\\langle a \\rangle}}})=[{\\langle a \\rangle},\\infty).\\ ] ]    now we show @xmath183 .",
    "consider an arbitrary @xmath184 .",
    "the case when @xmath185 is obvious .",
    "assume that @xmath186 .",
    "without loss of generality we can assume that @xmath187 .",
    "for an indirect proof , assume that @xmath188 .",
    "then @xmath189 ( by [ e ] ) .",
    "let @xmath47 be arbitrary .",
    "from the fact that @xmath184 , we know that @xmath190{{\\interleavea^n { \\mathsf{x}}\\interleave}}\\leq{\\,\\rangle\\hspace{-1pt}a\\hspace{-1pt}\\langle_{}\\,},\\ ] ] and thus there exists @xmath191 such that for all @xmath192 @xmath193{{\\interleavea^n { \\mathsf{x}}\\interleave}}\\leq { \\,\\rangle\\hspace{-1pt}a\\hspace{-1pt}\\langle_{}\\,}+\\e.\\ ] ]    since @xmath189 and from theorem [ inter ] we obtain @xmath194 using we get @xmath195 finally we have @xmath196{{\\langle a \\rangle}^n } \\leq \\sqrt[n]{{\\interleavea^n { \\mathsf{x}}\\interleave } } \\leq { \\,\\rangle\\hspace{-1pt}a\\hspace{-1pt}\\langle_{}\\,}+\\e.\\ ] ] since @xmath197 was arbitrary , we get a contradiction with the fact that @xmath0 is @xmath61-dominating .",
    "analogously to the proof of the second conclusion , assume that @xmath198 and @xmath199",
    ". then @xmath200 .",
    "since @xmath201 and @xmath202 we know that @xmath203 is invertible .",
    "let @xmath47 be arbitrary .",
    "using the fact that @xmath204 we know that @xmath190{{\\interleavea| _ { e_{\\geq{\\langle a \\rangle}}}^{-n } { \\mathsf{x}}\\interleave}}\\leq{\\langle a \\rangle}^{-1},\\ ] ] and",
    "thus there exists @xmath191 such that for all @xmath192 @xmath205{{\\interleavea| _ { e_{\\geq{\\langle a \\rangle}}}^{-n } { \\mathsf{x}}\\interleave}}\\leq { \\langle a \\rangle}^{-1}+\\e.\\ ] ] from observation [ ob:1 ] and theorem [ inter ] we get @xmath206 and from we have @xmath207 hence @xmath208    finally from observation [ ob:1 ] and , we obtain @xmath209{({\\,\\rangle\\hspace{-1pt}a| _ { e_{\\geq{\\langle a \\rangle}}}\\hspace{-1pt}\\langle_{}\\,})^{n}}\\geq\\sqrt[n]{\\frac{1}{{\\interleavea| _ { e_{\\geq{\\langle a \\rangle}}}^{-n } { \\mathsf{x}}\\interleave}}}\\geq\\frac{1}{{\\langle a \\rangle}^{-1}+\\e}={\\langle a \\rangle}\\cdot \\frac{1}{1+\\e\\cdot{\\langle a \\rangle}},\\ ] ] which get a contradiction with the fact that @xmath0 is @xmath61-dominating .    by @xmath210",
    "we denote interval @xmath211 .",
    "for @xmath47 we put @xmath212 .",
    "[ x_1 ] let @xmath47 and @xmath213 .",
    "assume that an operator @xmath214 for @xmath215 is given .",
    "1 .   @xmath170 . then there exist unique eigenvalue @xmath158 of @xmath0 such that @xmath216 and the eigenspace is one - dimensional space . the unique ( module rescaling ) eigenvector @xmath161 corresponding to the eigenvalue @xmath158 satisfies @xmath217 2 .   @xmath218 . then there",
    "exist unique eigenvalue @xmath158 of @xmath0 such that @xmath216 and the eigenspace is one - dimensional space . the unique ( module rescaling ) eigenvector @xmath161 corresponding to the eigenvalue @xmath158 satisfies @xmath219    it is a direct consequence of theorem [ tw1 ] and proposition [ dim ] .",
    "consider the following square matrix @xmath220 0.4   & 4 & 0.4   \\\\[0.3em ] 0.5 & 0.4 & 8   \\end{bmatrix}.\\ ] ] we find the localization of @xmath221 eigenvector corresponding to the eigenvalue of smallest module .",
    "since @xmath0 satisfies for @xmath222 @xmath223 we can use theorem [ tw1 ] .",
    "we get @xmath224    finding the roots of the characteristic polynomial of @xmath0 , which is equal to @xmath225 & = -(\\lambda-4)(\\lambda-\\frac{9-\\sqrt{51.28}}{2})(\\lambda-\\frac{9+\\sqrt{51.28}}{2}).\\end{aligned}\\ ] ] we get @xmath226 & { \\mathsf{x_1}}\\approx\\left ( - 15.686641 x , 1.9070447x , x\\right)\\ ; & & \\text { for } \\ ; x\\in\\r,\\end{aligned}\\ ] ] note that @xmath221 satisfies .",
    "in this section we show the numerical applications of our theory . for the purposes of this article",
    ", we use the programming language c++ with  boost",
    " libraries @xcite ( version 1.51.0 ) , which contains the interval arithmetic , and software library for numerical linear algebra  linear algebra package  @xcite ( revision 1348 ) .",
    "alternatively , one could use numerical computing environment  matlab  with an interval package . in the first section we presented a simple algorithm ( see algorithm [ code ] ) , which strictly localizes the position of particular eigenvalues and eigenvectors of a matrix .",
    "now we discuss in more details the steps from the algorithm [ code ] .",
    "first we determine the numerical approximation of eigenvectors @xmath37 and corresponding eigenvalues @xmath38 of the matrix @xmath227 . in the step [ p:1 ] of this algorithm",
    "we create matrix @xmath43 of numerical approximate eigenvectors @xmath37 . for the step [ p:2 ]",
    "we calculate the inverse matrix of the interval matrix which is composed of the approximate eigenvectors .",
    "the inverse matrix we can determine by the method of gauss - jordan elimination . in the next step",
    "we calculate the interval matrix @xmath228 the most important stage of our method is the step [ p:4 ] . in this step",
    "we want to take advantage of corollary [ x_1 ] , but first we need to check whether our matrix @xmath229 satisfies the assumptions of this corollary ( is it @xmath61-dominating ) .",
    "we want to localize the @xmath39-th eigenvector of a general matrix .",
    "we create matrices @xmath230 ( see ) and we check whether the following inequality is satisfied ( see theorem [ tw ] ) : @xmath231 if we find an @xmath197 which satisfies the above condition for the matrix @xmath230 , then from corollary [ x_1 ] we know that the @xmath39-th eigenvector of @xmath229 satisfies @xmath232 where @xmath233 . since @xmath234",
    "we obtain the @xmath39-th eigenvector of @xmath0 multiplying the @xmath39-th eigenvector of @xmath229 by interval matrix @xmath235 .",
    "finally we have @xmath51 the eigenvalue @xmath52 corresponding to the eigenvector @xmath40 we estimate from @xmath236      [ ex ] consider @xmath237 random matrices of size @xmath8 with randomly generated values from the set @xmath9 $ ] . for each such matrix we launched our program to find accurate @xmath197 location of all eigenvectors .",
    "we obtained @xmath238 $ ] and for the results we have the fist - quantile to equal @xmath239 , the median to equal @xmath240 and the third - quantile to equal @xmath241 .",
    "let @xmath0 be given in the matrix form @xmath242 0 & 3 & -1 & 4 & 2 & 2 & -3 & 0 & -4 & 0 \\\\[0.3em ] 0 & 0 & -3 & -4 & 2 & -2 & 0 & -3 & -1 & 1 \\\\[0.3em ] -4 & -1 & 4 & 1 & -1 & 2 & 4 & 1 & 2 & 0 \\\\[0.3em ] 3 & -1 & 4 & 0 & 4 & 3 & -2 & 0 & 1 & 3 \\\\[0.3em ] 4 & -1 & 1 & 2 & 1 & -4 & 2 & -2 & -4 & -2 \\\\[0.3em ] 0 & 4 & 1 & -1 & -2 & -4 & -2 & 4 & 1 & -1 \\\\[0.3em ] -3 & -4 & 2 & 0 & 0 & 0 & 0 & 0 & 4 & 0 \\\\[0.3em ] 4 & -4 & 2 & 0 & -1 & 0 & -2 & -4 & 4 & 0 \\\\[0.3em ] -4 & -3 & 4 & 4 & 0 & 4 & -3 & 3 & 3 & -1   \\end{bmatrix}.\\ ] ] our program found the following set of @xmath243 $ ] .",
    "due to the large size of eigenvectors of @xmath0 we write only first of them @xmath244\\cdot 10^{-9}+ ( - 0.1909691+[-14 , -10]\\cdot 10^{-9})i,\\\\ & & 0.0032301+&[20 , 62]\\cdot 10^{-9}+\\;\\ ; ( 0.1909691+[\\quad\\!\\;9,\\quad\\ !",
    "16]\\cdot 10^{-9})i,\\\\ & & 0.1312400+&[61 , 85]\\cdot 10^{-9}+[-34 , 34]\\cdot 10^{-10}i,\\\\ & & 0.2755005+&[42 , 60]\\cdot 10^{-9}+[-28 , 28]\\cdot 10^{-10}i,\\\\ & & 0.1849394+&[66 , 98]\\cdot 10^{-9}+(- 0.0068575+[-54 , -45]\\cdot 10^{-9})i,\\\\ & & 0.1849394+&[66 , 98]\\cdot 10^{-9}+\\;\\ ; ( 0.0068575+[\\quad\\!45,\\quad\\ !",
    "54]\\cdot 10^{-9})i,\\\\ & & 0.3754802+&[56 , 77]\\cdot 10^{-9}+\\;\\;(0.0266195+[\\quad\\!36,\\quad\\ !",
    "44]\\cdot 10^{-9})i,\\\\ & & 0.3754802+&[56 , 77]\\cdot 10^{-9}+(- 0.0266195+[-43 , -36]\\cdot 10^{-9})i,\\\\ & & 0.1456179+&[89 , 94]\\cdot 10^{-9}+[-54 , 54]\\cdot 10^{-11}i,\\\\ & -&0.0358730+&[-7 , 0]\\cdot 10^{-9}+[-78 , 78]\\cdot 10^{-11}i ) , \\end{aligned}\\ ] ]      [ roots ] consider the polynomial @xmath246 to find all the roots of polynomial @xmath247 we estimate the eigenvalues of the matrix @xmath248    0 & 0 & 1 & 0 & 0 & \\\\[0.3em ]    0 & 0 & 0 & 1 & 0 & \\\\[0.3em ]    0 & 0 & 0 & 0 & 1 & \\\\[0.3em ] 8 & -2 - 4i & 7i & 0 & -5+i \\end{bmatrix}.\\ ] ] from our program we obtain @xmath249\\cdot 10^{-9 } + 1.2610393+[39 , 67]\\cdot 10^{-9}i,\\\\ \\lambda_2\\in & \\quad\\!0.384\\;\\,+[\\quad\\!37,\\quad\\ !",
    "42]\\cdot 10^{-5 } + 1.2215+[\\quad\\!45,\\quad\\ ! 97]\\cdot 10^{-6}i,\\\\ \\lambda_3\\in & \\quad\\!0.9572+[\\quad\\!53,\\quad\\ ! 90]\\cdot 10^{-6 } + 0.1374+[\\quad\\!16,\\quad\\ !",
    "42]\\cdot 10^{-6}i,\\\\ \\lambda_4\\in & -1.0805+[-80 , -10]\\cdot 10^{-6}\\ , - 0.6647+[-95 , -42]\\cdot 10^{-6}i,\\\\ \\lambda_5\\in & -0.1421+[-68 , -30]\\cdot 10^{-6}\\ , - 0.9552+[-97 , -45]\\cdot 10^{-6}i .",
    "\\end{array}\\ ] ]            m. j. capiski and p. zgliczyski .",
    "cone conditions and covering relations for topologically normally hyperbolic invariant manifolds .",
    "discrete and continuous dynamical systems - series a , 30:641670 , 2011 .",
    "m. c. irwin .",
    "smooth dynamical systems .",
    "advanced series in nonlinear dynamics , 17 .",
    "world scientific publishing co. , inc .",
    ", river edge , nj , 2001 .",
    "xii+259 pp .",
    "isbn : 981 - 02 - 4599 - 8 , reprint of the 1980 original . with a foreword by r. s. mackay ."
  ],
  "abstract_text": [
    "<S> in this article we show and implement a simple and efficient method to strictly locate eigenvectors and eigenvalues of a given matrix , based on the modified cone condition . as a consequence </S>",
    "<S> we can also effectively localize zeros of complex polynomials .    </S>",
    "<S> eigenvectors , eigenvalues , cone condition , spectrum , interval arithmetic , zeros of polynomials . </S>",
    "<S> + 65f15 . </S>"
  ]
}