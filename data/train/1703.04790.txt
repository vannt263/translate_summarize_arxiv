{
  "article_text": [
    "widespread deployment of synchro - phasor measurement units ( pmus ) on power transmission grids has made possible the real - time monitoring and control of power system dynamics .",
    "however , these functions can not be reliably achieved without the development of a fast and robust dynamic state estimator ( dse ) .",
    "indeed , the state variable estimates of the synchronous machines can be utilized by power system stabilizers , automatic voltage regulators , and under - frequency relays to enhance small signal stability and to initiate generation outages and load shedding during transient instabilities , among other actions @xcite .",
    "to date , a variety of dynamic state estimators have been proposed in the literature ; they are based on the extended kalman filter ( ekf ) @xcite , the iterated ekf ( iekf ) @xcite , the unscented kalman filter ( ukf ) @xcite , to cite a few .",
    "however , all these methods suffer from several important shortcomings , precluding them from being adopted by power utilities for power system real - time applications . to be specific",
    ", they can not handle _",
    "i ) non - gaussian process and observation noise of the system nonlinear dynamic models and ii ) innovation , observation and structural outliers_.    there are several reasons for these shortcomings .",
    "firstly , the current dse approaches assume that both the process and the observation noise of the system nonlinear dynamic models are gaussian .",
    "however , two recent investigations conducted by pnnl @xcite revealed that the pmu measurement errors of the voltage and current magnitudes obey non - gaussian probability distributions .",
    "this is demonstrated in fig.[fig.non_gaussian_noise_real_data ] using real pmu data provided to us by pnnl .",
    "this figure displays histograms and parametric probability density estimates of pmu errors on nodal voltage magnitudes and angles , line current magnitudes and angles , and line real and reactive powers . as observed in fig.[fig.non_gaussian_noise_real_data ] , except for the measurement errors on nodal voltage and line current angles , which are roughly gaussian , the measurement errors on both nodal voltage and line current magnitudes obey a bimodal gaussian mixture distribution . as for the measurement errors of line real and reactive powers calculated from voltage and current phasors , they follow a thick tailed distribution that may be approximated by either the laplacian or the cauchy distribution . recall that",
    "in contrast to the gaussian distribution , which is a short - tailed distribution , a thick - tailed distribution is the one that allows the associated random variable to take , as compared to a scale parameter , large values with a non - negligible probability .",
    "evidently , the presence of non - gaussian noise calls for new research and development in robust power system dse based on robust statistics .",
    "secondly , three types of outliers associated with a given dynamical system model have been defined by gandhi and mili @xcite , namely observation outliers , which affect the metered values ; innovation outliers , which corrupt the predicted state estimates ; and structural outliers , which affect the system dynamic states and the observation functions .",
    "observation outliers may result from large biases in pmu measurements due to infrequent calibration , or instrument failures , or impulsive communication noise @xcite . as for innovation outliers",
    ", they may occur in several different ways .",
    "for example , some of the generator models may not be well calibrated , resulting in highly inaccurate model outputs that are inconsistent with the measurements .",
    "this was precisely the case in the 1996 blackout , where the model being used predicted system stability while in reality the system was undergoing numerous cascading failures , which resulted in a rapid system collapse that occurred within minutes @xcite .",
    "innovation outliers may also be induced by the approximations in the state prediction model or by a system process impulsive noise . by contrast",
    ", structural outliers are induced by wrong circuit breaker statuses or gross errors in the model parameters of the transmission lines , or of the automatic voltage regulators , or of the synchronous machines . in @xcite , it is reported that wrong estimates of the parameters of the synchronous machine models may result from the use of erroneous metered values .",
    "it turns out that the conventional filters , namely the ekf , the iekf , the ukf , and the particle filter ( pf ) are not robust to any type of outliers .",
    "for instance , it is demonstrated in @xcite that their performances are significantly degraded in the presence of observation outliers . to address this issue , rouhani and abur @xcite developed a robust ukf - based dse using the least - absolute - value ( lav ) estimator .",
    "however , the authors do not address the vulnerability of the dse to innovation outliers . in @xcite ,",
    "a robust iekf was proposed to handle observation and innovation outliers , but it may suffer from divergence problems if the nonlinearity of the system model is strong .",
    "in addition , both @xcite do not address the non - gaussianity of the measurement noise .    in this paper , a robust generalized maximum - likelihood - type ukf (",
    "gm - ukf ) method is proposed to suppress observation and innovation outliers while filtering out non - gaussian measurement noise .",
    "our choice of the ukf is motivated by the fact that , considering the real - time implementation requirements for nonlinear dse , it achieves a more balanced performance between computational efficiency and ability to cope with strong system nonlinearities than the ekf , or the iekf , or the pf . however , the ukf is based on the sigma points , which reliably approximate the mean and the covariance matrices of the state estimates only under the gaussian assumption of the process and observation noises .",
    "we show that this assumption is further stressed by the reliance of the ukf on the weighted least squares estimator .",
    "interestingly , the state estimates calculated by our gm - ukf are shown to be asymptotically gaussian even when the noises obey thick - tailed distributions , which is precisely the case when using pmu measurements .",
    "furthermore , we show that the state estimates obtained from the application of statistical linearization to the nonlinear discrete - time state space system model are equivalent to those of the unscented transformation .",
    "therefore , our filter allows the sigma points to provide good results .",
    "it is developed according to the following steps .",
    "we first derive a redundancy batch - mode regression form by processing the predictions and observations simultaneously ; this overdetermined system of equations provides the data redundancy needed for the detection and suppression of the innovation and observation outliers .",
    "this is achieved by means of a robust gm - estimator defined as the minimum of the huber convex cost function while using weights calculated via the projection statistics ( ps s ) .",
    "the latter are applied to a two - dimensional matrix consisting of serially correlated predicted state and innovation vectors .",
    "then , a statistical test is applied to them to flag the outliers .",
    "finally , the gm - estimator is solved via the iteratively reweighted least squares algorithm and the asymptotic error covariance matrix of the state estimates is calculated from the total influence function .",
    "the rest of the paper is organized as follows .",
    "section ii presents the problem formulation .",
    "section iii develops the theory of the proposed gm - ukf and finally section iv concludes the paper .",
    "a discrete - time state space representation of a general nonlinear dynamical system is expressed as @xmath0 @xmath1 where @xmath2 and @xmath3 are the state vector and the measurement / observation vector at time sample @xmath4 , respectively ; @xmath5 and @xmath6 are vector - valued nonlinear functions ; @xmath7 and @xmath8 are the system process and observation noise , respectively ; they are assumed to be independent and identically distributed with zero mean and covariance matrices @xmath9 and @xmath10 , respectively ; @xmath11 is the system input vector .",
    "the main idea underlying the ukf is the application of a deterministic sampling technique known as the unscented transformation , which allows us , under the gaussian noise assumption , to choose a set of sample points , termed sigma points , that have the same mean and covariance matrix as those of the a priori state vector @xcite .",
    "these sigma points are then propagated through the non - linear functions @xmath5 and @xmath6 , yielding an estimation of the a posteriori state statistics by using the kalman filter approach , i.e. , the sample mean and the sample covariance matrix .",
    "consequently , no calculation of jacobian matrices is required , which can be by itself a difficult task to achieve in some cases or computationally costly .",
    "to be specific , given a state estimate at time step @xmath4 - 1 , @xmath12 , having a covariance matrix given by @xmath13 , its statistics are captured by 2@xmath14 weighted sigma points defined as @xmath15 with weights @xmath16 . then , each sigma point is propagated through the nonlinear system process model ( [ eq : discrete_state_model ] ) , yielding a set of transformed samples expressed as @xmath17 next , the predicted sample mean and sample covariance matrix of the state vector are calculated by @xmath18 @xmath19 finally , the measurement updating is performed and the filtered state @xmath20 with the covariance matrix @xmath21 are calculated by @xmath22 @xmath23 @xmath24 where @xmath25 is the predicted measurement vector and @xmath26 ; the self and cross - covariance matrices , @xmath27 and @xmath28 , are respectively calculated by @xmath29 @xmath30      if the system process and measurement noises obey a gaussian probability distribution , the filtered state , @xmath31 , will follow a gaussian distribution as well . in that case , the sample mean and the sample covariance matrix of @xmath31 will be captured by the sigma points and the ukf will produce reliable state estimates .",
    "however , the gaussianity assumption may not hold true in practice .",
    "this is precisely the case in power systems ; for instances , impulsive process noise may occur due to system model inaccuracy at a certain time window and the pmu measurement noise may not follow a gaussian distribution as shown in fig.[fig.non_gaussian_noise_real_data ] .",
    "consequently , the sigma points may not capture the complete statistics of the state vector , resulting in poor or even diverged estimations .",
    "furthermore , since the ukf lacks statistical robustness , it is sensitive to any type of outliers , including observation , innovation and structural outliers . in power system dse",
    ", observation outliers refer to the phase biases and gross errors in pmu measurements @xcite ; innovation outliers may be induced by incorrect generator parameter values , failure of brushless exciter rotating diodes , or impulsive system process noise ; and structural outliers may be caused by transmission parameter errors or topology errors . in the following section",
    ", we will propose a robust gm - ukf that is able to suppress observation and innovation outliers and to filter out various types of thick - tailed measurement noises .",
    "note that the problem of the identification and suppression of structural outliers is outside the scope of this paper since it requires a different formulation ; it will be addressed in a future work .",
    "our gm - ukf consists of four major steps , namely a batch - mode regression form step , a robust pre - whitening step , a robust regression state estimation step , and a robust error covariance matrix updating step .",
    "they are described next .          in this subsection",
    ", we first show the equivalence of statistical linearization and the unscented transformation using sigma points .",
    "we then derive the proposed batch - mode regression form .",
    "the former claim is presented in the following theorem :    given the state estimate vector @xmath32 and its associated covariance matrix @xmath33 , statistical linear regression applied to an arbitrary nonlinear function @xmath34 yields results that are equivalent to those of the unscented transformation using the sigma points generated according to ( [ eq : sigma_points1 ] ) .",
    "consider a nonlinear function @xmath35 evaluated in 2@xmath14 points , i.e. , @xmath36 , where @xmath37 for @xmath38= 1 , ... , 2@xmath14 .",
    "assuming that the nonlinear function is statistically linearized as @xmath39 , the objective is to find @xmath40 and @xmath41 so that the point - wise linearization error @xmath42 is minimized , i.e. , @xmath43 where @xmath44 . by taking the derivative of the objective function with respect to @xmath45 and @xmath46 and let them equal to zero , respectively , we obtain @xmath47 @xmath48 where @xmath49 ; @xmath50 ; @xmath51 ; @xmath52 .",
    "then , the estimation error covariance matrix is calculated as @xmath53 where @xmath54 .",
    "now , by taking the expectation and the outer product of the statistical linearized model , respectively , we obtain the posterior statistics given by @xmath55 @xmath56 which are the same expressions as those obtained by applying the unscented transformation to the nonlinear function @xmath35 .",
    "thus , the proof is completed .    in statistical linearization",
    ", @xmath40 is no longer the jacobian matrix of @xmath34 at a given point .",
    "the error covariance matrix @xmath57 is used to compensate the linearization errors of the higher order taylor series expansion terms .",
    "this is however explicitly contained in the unscented transformation process .    by applying statistical linearization to the nonlinear system process model ,",
    "we obtain the predicted state vector @xmath58 along with its covariance matrix @xmath59 .",
    "we define @xmath60 , where @xmath61 is the true state vector ; @xmath62 is the prediction error ; and @xmath63 = { \\bm{p } _ { k\\left| { k - 1 } \\right.}^{xx}}$ ] .",
    "then , statistical linearization can be applied to the nonlinear observation equation , yielding @xmath64 where @xmath65 , which is no longer a jacobian matrix . here",
    ", the covariance of the statistical linearization error term is @xmath66 = \\bm{p}_{_{k\\left| { k - 1 } \\right.}}^{zz } - { ( { \\bm{p}_{_{k\\left| { k - 1 } \\right.}}^{xz } } ) ^t}{\\bm{p}_{k\\left| { k - 1 } \\right.}^{xx}}\\bm{p}_{_{k\\left| { k - 1 } \\right.}}^{xz}$ ] , where @xmath67 and @xmath68 are two covariance matrices that are calculated by following the same steps as those of the ukf . by processing the predictions and the observations simultaneously , we get the following batch - mode regression form : @xmath69 = \\bigg [ { \\begin{array}{*{10}{c } } { { \\bm{h}_k}}\\\\ \\bm{i } \\end{array}}\\bigg]{\\bm{x}_k } + \\bigg [ { \\begin{array}{*{10}{c } } { { \\bm{\\nu}_k } + { \\bm{\\varepsilon}_k}}\\\\ { - { \\bm{\\delta}_k } } \\end{array}}\\bigg ] \\label{eq : batchmodel}\\ ] ] which can be rewritten in a compact form as @xmath70 and the error covariance matrix is given by @xmath71 = \\left [ { \\begin{array}{*{20}{c } } { { \\bm{\\sigma } _ { k\\left| { k - 1 } \\right.}}}&\\bm{0}\\\\ \\bm{0}&{{\\bm{p } _ { k\\left| { k - 1 } \\right.}^{xx } } } \\end{array } } \\right ] = { \\bm{s}_k}\\bm{s}_k^t , \\label{eq : batchmodelcompactcovariance}\\ ] ] where @xmath72=\\bm{r}_k+\\bm{\\widetilde{r}}_k$ ] ; @xmath73 is an identity matrix ; @xmath74 is calculated by the cholesky decomposition technique .",
    "the weighted least squares estimator of the batch - mode regression form ( [ eq : batchmodelcompact ] ) yields an estimated state vector @xmath75 and its associated covariance matrix @xmath76 that are equivalent to those of the ukf .",
    "it is well - known that the state estimate of ( [ eq : batchmodelcompact ] ) using the weighted least squares estimator is given by @xmath77 with the covariance matrix @xmath78 . by applying an algebraic substitution and using the matrix inversion lemma",
    ", we get @xmath79 where the gain matrix is expressed as @xmath80 thus , we can conclude that the estimation error covariance is identical to that of the ukf in ( [ eq : ukf_covariance_matrix_updating ] ) . by applying similar substitutions and using the matrix inversion lemma",
    ", we can also show that the estimated state vector is given by @xmath81 which completes the proof .    in the literature ,",
    "a few huber estimator - based robust ukf methods have been proposed and applied to various applications in signal processing , target tracking , to name a few @xcite . however , in their developed regression models , @xmath82 that compensates higher order taylor series expansion error terms is neglected completely . as a consequence , the estimation results are biased .",
    "in addition , they are unable to handle innovation outliers and filter out non - gaussian measurement noise .      before carrying out a robust regression , we uncorrelate the state prediction errors of the batch - mode regression form .",
    "this is achieved by pre - multiplying @xmath83 on both sides of ( [ eq : batchmodelcompact ] ) , yielding @xmath84 which can be further organized to the compact form @xmath85 where @xmath86=\\bm{i}$ ] .",
    "if outliers occur , the application of @xmath83 will corrupt the prewhitening @xcite . to overcome this problem",
    ", we first detect the outliers and calculate the weights using the projection statistics ( ps ) @xcite .",
    "those weights will be incorporated in the objective function that is defined in the proposed gm - estimator shown in section iii - c .",
    "now , we describe the procedures used to calculate the weights .",
    "we apply the ps to a 2-dimensional matrix @xmath87 that contains serially correlated samples of the innovations and of the predicted state variables .",
    "note that the innovation vector is defined as the difference between the observations and their associated predicted values at the previous step .",
    "formally , we have @xmath88 , \\label{z_matrix}\\ ] ] where @xmath89 and @xmath90 are the innovation vectors while @xmath91 and @xmath92 are the predicted state vectors at time instants @xmath4 - 1 and @xmath4 , respectively .",
    "we may also apply the ps to higher dimensional samples , but we found that 2 dimensions are enough to identify outliers .",
    "the ps values of the predictions and of the innovations are separately calculated because the values taken by the former and the latter are centered around different points .",
    "the ps of the @xmath93th row vector , @xmath94 , of the predictions ( respectively the innovations ) in @xmath87 is defined as the maximum of the standardized projections of all the @xmath94 s on every direction @xmath95 that originates from the coordinatewise medians of the predictions ( respectively the innovations ) and that passes through every data point , and where the standardized projections are based on the sample median and the median - absolute - deviation @xcite . the implementation of the ps to detect outliers in matrix @xmath87 is displayed in fig .",
    "[ fig.ps ] , while its mathematical expression is defined as @xcite .",
    "@xmath96 where @xmath97 .",
    "once the ps values are calculated , they are compared to a statistical threshold to identify outliers .",
    "extensive monte carlo simulations and q - q plots reveal that the probability distributions of the ps applied to @xmath87 , whose data points obey bivariate gaussian and laplace probability distributions , follow chi - square distributions with degree of freedom 2 and 4 , respectively ( see fig .",
    "[ fig.ps_distributions ] ) .",
    "this investigation allows us to apply statistical tests to the ps and to flag all the data points that satisfy @xmath98 as outliers .",
    "the latter are downweighted via @xmath99 where the parameter @xmath100 is set equal to 1.5 to yield good statistical efficiency at different distributions without increasing too much the bias induced by outliers . as an example , when the noise is assumed to be laplacian , the ps obeys a chi - square distribution with 4 degrees of freedom . in that case",
    ", we can choose the statistical detection threshold @xmath101 as @xmath102 at a significance level of 97.5% .      to suppress the outliers and filter out thick - tailed non - gaussian measurement noise",
    ", we develop a robust gm - estimator that minimizes the following objective function : @xmath103 where @xmath104 is calculated by ( [ eq : psdownweightfunction ] ) ; @xmath105 is the standardized residual ; @xmath106 is the residual , where @xmath107 is the @xmath38th row vector of the matrix @xmath108 ; @xmath109 is the robust scale estimate ; @xmath110 is a correction factor to achieve unbiasedness for a finite sample of size @xmath111 at a given probability distribution ; @xmath112 is the nonlinear function of @xmath113 . in this paper ,",
    "the convex huber-@xmath114 function @xcite is adopted , that is @xmath115 where the parameter @xmath116 between the quadratic and the linear segment of @xmath112 is typically chosen between 1.5 to 3 in the literature .",
    "to minimize ( [ eq : objectivefunction ] ) , one takes its partial derivative with respect to @xmath61 and sets it equal to zero , yielding @xmath117 where @xmath118is the so - called @xmath119-function . by dividing and multiplying the standardized residual @xmath120 to both sides of ( [ eq : objectivefunctionpartialderivative ] ) and putting it in a matrix form , we get @xmath121 where @xmath122diag@xmath123 and @xmath124 .    by using the irls algorithm @xcite ,",
    "the state vector correction at the @xmath93 iteration is calculated through @xmath125 where @xmath126 .",
    "the algorithm converges when @xmath127 .      upon convergence of the iterative algorithm ,",
    "the error covariance matrix @xmath128 is updated so that the state prediction for the next step can be performed . to this end , consider the @xmath129-contamination model @xmath130 , where @xmath131 and @xmath132 are the contaminated and the true cumulative probability distribution function of the residual , respectively ; @xmath133 is the point mass to model outliers or unknown non - gaussian distributions .",
    "the error covariance matrix is updated based on the following theorem :    let @xmath134 be the functional form of the gm - estimator with a bounded @xmath135 function and @xmath136 be the empirical cumulative probability distribution function , then @xmath137 where @xmath138 ; @xmath139 means convergence in probability distribution ; @xmath140 $ ] with the influence function @xmath141 evaluated at @xmath132 .    by taking a first - order taylor series expansion of the functional form of the estimator @xmath142 with respective to @xmath132",
    ", we get @xmath143 which can be reorganized into the following form by multiplying @xmath144 on both sides of the equality :    lll ( ( _ ) - ( ) ) + = ( _ - ) + ( _ - ) + = d(_- ) + ( _ - ) + = d _ + ( _ - ) + = _ i = 1^ + ( _ - ) , [ eq : taylor_functional ]    where the definition of the influence function is applied to yield ( 38 ) to ( 39 ) ; by virtue of fisher consistency at the distribution @xmath132 , that is , @xmath145 , ( 39 ) reduces to ( 40 ) ; finally , by using the property of the empirical cumulative probability distribution function , we have @xmath146 yielding ( 40 ) to ( 41 ) .    following the work of fernholz @xcite",
    ", we can show that @xmath147 where @xmath148 means probability convergence .",
    "therefore , by applying the central limit theorem and slutsky s lemma to ( [ eq : taylor_functional ] ) , it follows that @xmath137 where @xmath140 $ ] .",
    "_ discussion _ : the ukf is able to provide good results only when the process and observation noises obey a gaussian distribution @xcite . indeed , in that case the filtered state vector @xmath149 is gaussian and the mean and covariance matrix of @xmath149 can be accurately estimated by the sample mean and",
    "the sample covariance matrix of the sigma points . however , this property no longer holds true if the gaussianity assumption of the noises is violated . in that case , the state estimate vector @xmath149 obtained from the ukf is significantly biased due the filter lack of statistical robustness to thick - tailed non - gaussian noise . by contrast , our gm - ukf guarantees the asymptotic gaussianity of @xmath149 for thick - tailed non - gaussian noises and yields reliable state estimates with good statistical efficiency .",
    "assume that the system process noise is contaminated about a gaussian distribution .",
    "then , the data points defined by the row vectors of the matrix @xmath87 follow asymptotically a gaussian distribution .    from the definition of the matrix @xmath87 given by ( [ z_matrix ] ) and theorem 3",
    ", we can see that the predicted state vector is roughly gaussian .",
    "furthermore , under the assumption that the minority of the measurements obey a thick - tailed non - gaussian distribution , the innovation vectors can be shown to be approximately gaussian . from this , we conclude that @xmath87 is asymptotically gaussian .",
    "let s now derive the @xmath141 of our gm - ukf at the cumulative probability distribution @xmath132 .",
    "the total influence function of the gm - ukf defined by ( [ eq : objectivefunctionpartialderivative ] ) using the regression model ( [ eq : finalbatchmodel ] ) is expressed as @xmath150^ { - 1}}\\varpi \\bm{c}\\psi \\left ( { { r_{{s_i } } } } \\right ) .",
    "\\label{eq : iffinal}\\ ] ]    in our previous work @xcite , the total influence function of a gm - estimator based on a nonlinear regression model given by @xmath151 is expressed as @xmath152 where @xmath153 is the hessian matrix of @xmath154 .",
    "since we have @xmath155 for the gm - ukf , ( [ eq : genral_if ] ) reduces to @xmath156^ { - 1}}\\varpi \\bm{c}\\psi \\left ( { { r_{{s_i } } } } \\right ) .",
    "\\label{eq : iffinal}\\ ] ]    now , we are in a position to derive the covariance matrix @xmath157 from ( [ eq : gaussian_convergence ] ) .",
    "first , let us prove the following theorem :    the sample variance of the robust scale estimator @xmath158 of the gm - standardized residuals tends to one as the number of observation tends to infinity .    by the law of large numbers",
    ", the distribution of the residuals tends to the gaussian distribution , i.e. , @xmath159 .",
    "since the median absolute deviation ( mad=@xmath160 ) is a consistent estimator for the standard deviation @xmath161 of a gaussian distribution , we get @xmath162 therefore , we obtain @xmath163 as @xmath164 tends to infinity , where @xmath132 is the cumulative probability function of the standard gaussian distribution . on the other hand , from the equation ( [ eq : finalbatchmodel ] ) and the fact that @xmath86=\\bm{i}$ ] , the residuals can be shown to actually follow the standard gaussian distribution .",
    "therefore , @xmath165=s^2\\to 1 $ ] .    finally , by theorems 3 and 4 , the asymptotic error covariance matrix of our gm - ukf at time sample @xmath4",
    "is updated by @xmath166\\\\ \\quad\\quad\\ ; = \\frac{{{\\mathbb{e}_\\phi}\\left [ { { \\psi ^2}\\left ( { { r_{{s_i } } } } \\right ) } \\right]}}{{{{\\left\\ { { { \\mathbb{e}_\\phi}\\left [ { { \\psi ^{\\prime}}\\left ( { { r_{{s_i } } } } \\right ) } \\right ] } \\right\\}}^2}}}{\\left ( { { \\bm{c}_k^t}\\bm{c}_k } \\right)^ { - 1}}{\\left ( { { \\bm{c}_k^t}{\\bm{q}_\\varpi } \\bm{c}_k } \\right)^{}}{\\left ( { { \\bm{c}_k^t}\\bm{c}_k } \\right)^ { - 1 } } \\end{array } \\label{eq : updatingsigmafinal}\\ ] ] where @xmath167 .      in this section ,",
    "we discuss the statistical efficiency of our proposed gm - ukf under various probability distributions of the noise .",
    "firstly , under gaussian measurement noise , the outliers detected by the ps will be downweighted by the linear segment of the @xmath114-function while all the good measurements will be assigned weights equal or close to one since most of them will be processed by the quadratic segment of the @xmath114-function . as a result",
    ", the state estimator exhibits a high statistical efficiency . secondly ,",
    "if the measurement noise obeys a laplace distribution , those measurements associated with the thick tails of that distribution will have standardized residuals corresponding to the linear segment of the @xmath114-function .",
    "this means that for them , the gm - estimator behaves like the least absolute value estimator ; since the latter is the maximum - likelihood estimator at that distribution , it will have a high asymptotic statistical efficiency .",
    "on the other hand , when the estimation error covariance matrix is updated , all the outliers with respect to the gaussian distribution , which include the measurements associated with the tails of the laplacian or the cauchy distribution , will be heavily downweighted through the matrix @xmath168 , yielding bounded biases and variances in the state estimates .",
    "in this first part of a two - part series paper , we present the fundamental theory of the proposed gm - ukf .",
    "we show first that the ukf estimates the state vector via a weighted least squares estimator under the gaussianity assumption of the system process or measurement noises ; consequently , it yields strongly biased state estimates when the noises follow non - gaussian probability distributions , which is precisely the case when processing pmu measurements . by contrast , the state estimates and residuals of our gm - ukf are proved to be asymptotically gaussian , allowing the sigma points to reliably approximate the mean and the covariance matrices of the predicted and corrected state vectors .",
    "furthermore , by relying on the projection statistics and the gm - estimator , the proposed gm - ukf is able to suppress observation and innovation outliers while exhibiting high statistical efficiency of the state estimates .",
    "in addition , we derive the expression of the asymptotic error covariance matrix of the gm - ukf state estimates from the total influence function of the gm - estimator . in the companion paper",
    ", we will discuss the implementation of our gm - ukf in power systems and analyze its performance by carrying out extensive simulations under various scenarios .",
    "99 i. kamwa , r. grondin , and y. hebert ,  wide - area measurement based stabilizing control of large power systems - a decentralized / hierarchical approach , \" _ ieee trans .",
    "power syst_. , vol .",
    "1 , pp . 136153 , feb . 2001 .",
    "e. ghahremani , i. kamwa ,  dynamic state estimation in power system by applying the extended kalman filter with unknown inputs to phasor measurements , \" _ ieee trans .",
    "power syst .",
    "25562566 , nov .",
    "z. huang , k. schneider , and j. nieplocha ,  feasibility studies of applying kalman filter techniques to power system dynamic state estimation , \" in _ proc .",
    ". power eng .",
    "_ , singapore , dec .",
    "2007 , pp . 376382 .",
    "n. zhou , z. huang , d. meng ,  capturing dynamics in the power grid : formulation of dynamic state estimation through data assimilation .",
    "technical report pnnl-23213 , pacific northwest national laboratory , 2014 .",
    "z. huang , p. du , d. kosterev , s. yang ,  generator dynamic model validation and parameter calibration using phasor measurements at the point of connection , \" _ ieee trans .",
    "power syst .",
    "2 , pp . 19391949 , 2013 .",
    "s. julier , j. uhlmann , and h. f. durrant - whyte ,  a new method for the nonlinear transformation of means and covariances in filters and estimators , \" _ ieee trans .",
    "3 , pp . 477482 , mar ."
  ],
  "abstract_text": [
    "<S> this paper develops the theoretical framework and the equations of a new robust generalized maximum - likelihood - type unscented kalman filter ( gm - ukf ) that is able to suppress observation and innovation outliers while filtering out non - gaussian measurement noise . </S>",
    "<S> because the errors of the real and reactive power measurements calculated using phasor measurement units ( pmus ) follow long - tailed probability distributions , the conventional ukf provides strongly biased state estimates since it relies on the weighted least squares estimator . </S>",
    "<S> by contrast , the state estimates and residuals of our gm - ukf are proved to be roughly gaussian , allowing the sigma points to reliably approximate the mean and the covariance matrices of the predicted and corrected state vectors . to develop our gm - ukf </S>",
    "<S> , we first derive a batch - mode regression form by processing the predictions and observations simultaneously , where the statistical linearization approach is used . </S>",
    "<S> we show that the set of equations so derived are equivalent to those of the unscented transformation . </S>",
    "<S> then , a robust gm - estimator that minimizes a convex huber cost function while using weights calculated via projection statistics ( ps s ) is proposed . </S>",
    "<S> the ps s are applied to a two - dimensional matrix that consists of serially correlated predicted state and innovation vectors to detect observation and innovation outliers . </S>",
    "<S> these outliers are suppressed by the gm - estimator using the iteratively reweighted least squares algorithm . finally , the asymptotic error covariance matrix of the gm - ukf state estimates is derived from the total influence function . in the companion paper </S>",
    "<S> , extensive simulation results will be shown to verify the effectiveness and robustness of the proposed method .    </S>",
    "<S> shell : bare demo of ieeetran.cls for journals    dynamic state estimation , robust estimation , unscented kalman filter , non - gaussian noise , total influence function , outliers , cyber attacks , power system dynamics . </S>"
  ]
}