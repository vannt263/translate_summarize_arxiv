{
  "article_text": [
    "multi - target tracking is a central and difficult problem arising in many scientific and engineering applications including radar and signal processing , air traffic control and gps navigation @xcite .",
    "the tracking problem consists of computing the best estimate of the targets trajectories based on noisy measurements ( observations ) .",
    "several strategies have been developed for addressing the multi - target tracking problem , see e.g. @xcite .",
    "as in our recent work @xcite , in this paper we also focus on particle filter techniques @xcite . the popularity of the particle filter method has increased due to its flexibility to handle cases where the dynamic and observation models are non - linear and/or non - gaussian .",
    "the particle filter approach is an importance sampling method which approximates the target distribution by a discrete set of weighted samples ( particles ) .",
    "the weights of the samples are updated when observations become available in order to incorporate information from the observations .    despite the particle filter s flexibility , it is often found in practice that most samples will have a negligible weight with respect to the observation , in other words their corresponding contribution to the target distribution will be negligible .",
    "therefore , one may resample the weights to create more copies of the samples with significant weights @xcite .",
    "however , even with the resampling step , the particle filter might still need a lot of samples in order to approximate accurately the target distribution .",
    "typically , a few samples dominate the weight distribution , while the rest of the samples are in statistically insignificant regions .",
    "thus , some authors ( see e.g. @xcite ) have suggested the use of an extra step , after the resampling step , which can help move more samples in statistically significant regions .",
    "the extra step for the particle filter is a problem of conditional path sampling for stochastic differential equations ( sdes ) . in @xcite , a new approach to conditional path sampling based on drift homotopy",
    "was presented . in that paper , it was also shown how the algorithm can be used to perform the extra step of a particle filter . in @xcite , we applied the conditional path sampling algorithm from @xcite to perform the extra step of a particle filter for the problem of multi - target tracking .",
    "the numerical results in @xcite suggested that the approach can improve significantly the performance of a particle filter for multi - target tracking . in the current work ,",
    "we show yet another way of how to perform the extra step of a particle filter . both the current approach and the one in @xcite stem from the general formulation of the filtering problem .",
    "the details of the currently proposed implementation of the extra step for a single target are given in section [ mcmc_step ] and for multiple targets in section [ mcmc_step_multi ] .",
    "the relative merits of the proposed approach in this paper and the one proposed in @xcite are briefly discussed in section [ discussion ] .",
    "a more detailed comparison will be presented elsewhere .    to address the target - observation association problem",
    "we have used a simple metropolis monte carlo algorithm which first appeared in @xcite .",
    "this algorithm effects a probabilistic search of the space of possible associations to find the best target - observation association .",
    "of course , one can use more sophisticated association algorithms ( see @xcite and references therein ) but the monte carlo algorithm performed very well in the numerical experiments .",
    "the paper is organized as follows .",
    "sections [ generic ] and [ generic_multi ] provide a brief presentation of particle filters for single and multiple targets ( more details can be found in @xcite ) , which will serve to highlight the versatility and drawbacks of this popular filtering method .",
    "sections [ mcmc_step ] and [ mcmc_step_multi ] demonstrate how one can use an extra step to improve the performance of particle filters for single and multiple targets .",
    "section [ numerical ] presents numerical results for multi - target tracking for the cases of linear and nonlinear observation models .",
    "finally , section [ discussion ] contains a discussion of the results as well as directions for future work .",
    "particle filters are a special case of sequential importance sampling methods . in sections [ generic ] and [ generic_multi ]",
    "we discuss the generic particle filter for a single and multiple targets respectively . in sections",
    "[ mcmc_step ] and [ mcmc_step_multi ] we discuss the addition of an extra step to the generic particle filter for the cases of a single and multiple targets respectively .",
    "suppose that we are given an sde system and that we also have access to noisy observations @xmath0 of the state of the system at specified instants @xmath1 the observations are functions of the state of the system , say given by @xmath2 where @xmath3 are mutually independent random variables . for simplicity ,",
    "let us assume that the distribution of the observations admits a density @xmath4 i.e. , @xmath5    the filtering problem consists of computing estimates of the conditional expectation @xmath6,$ ] i.e. , the conditional expectation of the state of the system given the ( noisy ) observations .",
    "equivalently , we are looking to compute the conditional density of the state of the system given the observations @xmath7 there are several ways to compute this conditional density and the associated conditional expectation but for practical applications they are rather expensive .",
    "particle filters fall in the category of importance sampling methods . because computing averages with respect to the conditional density involves the sampling of the conditional density which can be difficult , importance sampling methods proceed by sampling a reference density @xmath8 which can be easily sampled and then compute the weighted sample mean @xmath9 \\approx \\frac{1}{n } \\sum_{n=1}^n f(x^n_{t_k})\\frac{p(x^n_{t_k}|\\{z_{t_j}\\}^{k}_{j=1})}{q(x^n_{t_k}|\\{z_{t_j}\\}^{k}_{j=1})}\\ ] ] or the related estimate @xmath10 \\approx \\frac{\\sum_{n=1}^n f(x^n_{t_k } ) \\frac{p(x^n_{t_k}|\\{z_{t_j}\\}^{k}_{j=1})}{q(x^n_{t_k}|\\{z_{t_j}\\}^{k}_{j=1})}}{\\sum_{n=1}^n \\frac{p(x^n_{t_k}|\\{z_{t_j}\\}^{k}_{j=1})}{q(x^n_{t_k}|\\{z_{t_j}\\}^{k}_{j=1})}},\\ ] ] where @xmath11 has been replaced by the approximation @xmath12 particle filtering is a recursive implementation of the importance sampling approach .",
    "it is based on the recursion @xmath13 if we set @xmath14 then from we get @xmath15 the approximation in expression becomes @xmath16 \\approx \\frac{\\sum_{n=1}^n f(x^n_{t_k})g(x^n_{t_k},z_{t_k})}{\\sum_{n=1}^n g(x^n_{t_k},z_{t_k})}\\ ] ] from we see that if we can construct samples from the predictive distribution @xmath17 then we can define the ( normalized ) weights @xmath18 use them to weigh the samples and the weighted samples will be distributed according to the posterior distribution @xmath7    in many applications , most samples will have a negligible weight with respect to the observation , so carrying them along does not contribute significantly to the conditional expectation estimate ( this is the problem of degeneracy @xcite ) . to create larger diversity",
    "one can resample the weights to create more copies of the samples with significant weights .",
    "the particle filter with resampling is summarized in the following algorithm due to gordon _",
    "_ @xcite .    1 .",
    "begin with @xmath11 unweighted samples @xmath19 from @xmath20 2 .",
    "* prediction * : generate @xmath11 samples @xmath21 from @xmath22 3 .",
    "* update * : evaluate the weights @xmath23 4 .",
    "* resampling * : generate @xmath11 independent uniform random variables @xmath24 in @xmath25 for @xmath26 let @xmath27where @xmath28 where @xmath29 can range from @xmath30 to @xmath31 5 .",
    "set @xmath32 and proceed to step 1 .    the particle filter algorithm is easy to implement and adapt for different problems since the only part of the algorithm that depends on the specific dynamics of the problem is the prediction step .",
    "this has led to the particle filter algorithm s increased popularity @xcite . however , even with the resampling step , the particle filter can still need a lot of samples in order to describe accurately the conditional density @xmath7 snyder _ et al . _",
    "@xcite have shown how the particle filter can fail in simple high dimensional problems because one sample dominates the weight distribution .",
    "the rest of the samples are not in statistically significant regions .",
    "even worse , as we will show in the numerical results section , there are simple examples where not even one sample is in a statistically significant region . in the next subsection we present how an extra step can be used to push samples closer to statistically significant regions .",
    "suppose that we have @xmath33 targets .",
    "also , for notational simplicity , assume that the @xmath34th target comes from the @xmath34th observation .",
    "even when this is not the case , we can relabel the observations to satisfy this assumption .",
    "the targets are assumed to evolve independently so that the observation weight of a sample of the vector of targets is the product of the individual observation weights of the targets @xcite . the same is true for the transition density of the vector of targets between observations .",
    "we denote the vector of targets at observation @xmath35 by @xmath36 and the observation vector at @xmath35 by @xmath37 also , we can have different observation weight densities @xmath38 for different targets .",
    "however , in the numerical examples we have chosen the same observation weight density for all targets .    following @xcite",
    "we can write the particle filter for the case of multiple targets as    1 .",
    "begin with @xmath11 unweighted samples @xmath19 from @xmath39 2 .",
    "* prediction * : generate @xmath11 samples @xmath21 from @xmath40 3 .",
    "* update * : evaluate the weights @xmath41 4 .",
    "* resampling * : generate @xmath11 independent uniform random variables @xmath24 in @xmath25 for @xmath26 let @xmath27where @xmath28 where @xmath29 can range from @xmath30 to @xmath31 5 .",
    "set @xmath32 and proceed to step 1 .      several authors ( see e.g. @xcite ) have suggested the use of a mcmc step after the resampling step ( step 4 ) in order to move samples away from statistically insignificant regions .",
    "there are many possible ways to append an mcmc step after the resampling step in order to achieve that objective .",
    "the important point is that the mcmc step must preserve the conditional density @xmath7 in the current section we show that the mcmc step constitutes a case of conditional path sampling .",
    "we begin by noting that one can use the resampling step ( step 4 ) in the particle filter algorithm to create more copies not only of the good samples according to the observation , but also of the values ( initial conditions ) of the samples at the previous observation .",
    "these values are the ones who have evolved into good samples for the current observation ( see more details in @xcite ) .",
    "the motivation behind producing more copies of the pairs of initial and final conditions is to use the good initial conditions as starting points to produce statistically more significant samples according to the current observation .",
    "this process can be accomplished in two steps .",
    "first , step 4 of the particle filter algorithm is replaced by    : generate @xmath11 independent uniform random variables @xmath24 in @xmath25 for @xmath26 let @xmath42where @xmath28 also , through bayes rule @xcite one can show that the posterior density @xmath43 is preserved if one samples from the density @xmath44 where @xmath45 are given by the modified resampling step .",
    "this is a problem of conditional path sampling for ( continuous - time or discrete ) stochastic systems .",
    "the important issue is to perform the necessary sampling efficiently @xcite .",
    "we are now in a position to present the particle filter with mcmc step algorithm    1 .",
    "begin with @xmath11 unweighted samples @xmath19 from @xmath20 2 .",
    "* prediction * : generate @xmath11 samples @xmath21 from @xmath22 3 .",
    "* update * : evaluate the weights @xmath23 4 .",
    "* resampling * : generate @xmath11 independent uniform random variables @xmath24 in @xmath25 for @xmath26 let @xmath42 where @xmath28 where @xmath29 can range from @xmath30 to @xmath31 5 .",
    "* mcmc step * : for @xmath26 choose a modified drift ( possibly different for each @xmath46 ) . construct a markov chain for @xmath47 with stationary distribution @xmath48 6 .",
    "set @xmath49 7 .",
    "set @xmath32 and proceed to step 1 .",
    "since the samples @xmath50 are constructed by starting from different sample paths , they are independent . also , note that the samples @xmath51 are unweighted . however , we can still measure how well these samples approximate the posterior density by comparing the effective sample sizes of the particle filter with and without the mcmc step . for a collection of @xmath11 samples the effective sample size @xmath52 is defined by @xmath53 where @xmath54 the effective sample size can be interpreted as that the @xmath11 weighted samples are worth of @xmath55 i.i.d .",
    "samples drawn from the target density , which in our case is the posterior density . by definition , @xmath56 if the samples have uniform weights , then @xmath57 on the other hand , if all samples but one have zero weights , then @xmath58      we discuss now the case of multiple , say @xmath59 targets . instead of the observations for a single target",
    "now we have a collection of observations for all the targets @xmath60    the particle filter with mcmc step for the case of multiple targets is    1 .",
    "begin with @xmath11 unweighted samples @xmath19 from @xmath39 2 .",
    "* prediction * : generate @xmath11 samples @xmath21 from @xmath40 3 .",
    "* update * : evaluate the weights @xmath41 4 .",
    "* resampling * : generate @xmath11 independent uniform random variables @xmath24 in @xmath25 for @xmath26 let @xmath42 where @xmath28 where @xmath29 can range from @xmath30 to @xmath31 5 .",
    "* mcmc step * : for @xmath26 and @xmath33 choose a modified drift ( possibly different for each @xmath46 and each @xmath34 ) .",
    "construct a markov chain for @xmath47 with stationary distribution @xmath61 6 .",
    "set @xmath49 7 .   set @xmath32 and proceed to step 1 .    for a collection of @xmath11 samples",
    "the effective sample size @xmath62 for @xmath63 targets is @xmath64 where @xmath65",
    "we present numerical results for multi - target tracking using the particle filter with an mcmc step performed by hybrid monte carlo .",
    "we have synthesized tracks of targets moving on the @xmath66 plane using a @xmath67 near constant velocity model @xcite . at each time @xmath68",
    "we have a total of @xmath69 targets and the evolution of the @xmath70th target ( @xmath71 ) is given by @xmath72^t , \\notag\\end{aligned}\\ ] ] where @xmath73 and @xmath74 are the @xmath66 position and velocity of the @xmath70th target at time @xmath75 the matrices @xmath76 and @xmath77 are given by @xmath78 \\;\\ ; \\text{and } \\;\\ ; { \\bf{b}}= \\left [ \\begin{array}{cc } t^2/2 & 0\\\\   t & 0\\\\ 0 & t^2/2 \\\\ 0 & t \\end{array } \\right],\\ ] ] where @xmath79 is the time between observations . for the experiments we have set @xmath80 i.e.",
    ", noisy observations of the model are obtained at every step of the model .",
    "the model noise @xmath81 is a collection of independent gaussian random variables with covariance matrix @xmath82 defined as @xmath83.\\ ] ] in the experiments we have @xmath84 also , we have considered two possible cases for the observation model , one linear and one nonlinear . due to the different possible combinations of targets to observations we use a different index @xmath85 to denote the obsevations . since we do not assume any clutter we have @xmath86 if the @xmath85th observation @xmath87 at time @xmath68 comes from the @xmath70th target we have @xmath88 + { \\bf{w}}_{m , t}\\ ] ] for the linear observation model and @xmath89 + { \\bf{w}}_{m , t}\\ ] ] for the nonlinear observation model .",
    "as is usual in the literature , the nonlinear observation model consists of the bearing @xmath90 and range @xmath91 of a target .",
    "the observation noise @xmath92 is white and gaussian with covariance matrix @xmath93\\ ] ] for the linear observation model and @xmath94\\ ] ] for the nonlinear observation model .",
    "for the numerical experiments with the linear observation model we chose @xmath95 for the numerical experiments with the nonlinear observation model we chose @xmath96 and @xmath97 these values make our example comparable in difficulty to examples appearing in the literature ( see e.g. @xcite ) .",
    "the synthesized target tracks were created by specifying a certain scenario , to be detailed below , of surviving , newborn and disappearing targets . according to this scenario we evolved the appropriate number of targets according to and recorded the state of each target at each step . for the surviving targets we created an observation by using the state of the target in the observation model .",
    "thus , for the linear observation model , the observations were created directly in @xmath66 space by perturbing the @xmath66 position of the target by . for the nonlinear observation model ,",
    "the observations were created in bearing and range space @xmath98 by using .",
    "the perturbed bearing and range were transformed to @xmath66 space by the transformation @xmath99 to create a position for the target in @xmath66 space .",
    "the newborn targets for the linear model were created in @xmath66 space directly by sampling uniformly in @xmath100.$ ] afterwards , the observations of the newborn targets were constructed by perturbing the @xmath101 positions using .",
    "the newborn targets for the nonlinear model were created in @xmath66 space by sampling uniformly in @xmath100.$ ] afterwards , we transformed the @xmath101 positions to the bearing and range space @xmath102 and perturbed the bearing and range according to .",
    "the perturbed bearing and range were again transformed back to @xmath66 space to create the position of the newborn target .",
    "note that both observation models do _ not _ involve the velocities .",
    "the newborn target velocities were sampled uniformly in @xmath103.$ ] the number of targets at each observation instant is : @xmath104 @xmath105 , @xmath106 @xmath107",
    "@xmath108 @xmath109 so , for the majority of the steps we have @xmath110 targets which makes the problem of tracking rather difficult .      for the @xmath46th sample , the density we have to sample for the _ linear _ model is @xmath111      we chose to use hybrid monte carlo to perform the sampling ( any other mcmc method can be used ) @xcite .",
    "we present briefly the hybrid monte carlo ( hmc ) formulation that we have used to sample the conditional density for each target .",
    "define the potential @xmath112 by @xmath113 define the vectors @xmath114^t$ ] and @xmath115^t,$ ] where @xmath79 is the transpose ( not to be confuse with the interval between observations @xmath79 used before ) .",
    "consider @xmath116 as the position variables of a hamiltonian system .",
    "we define the @xmath117-dimensional position vector @xmath118^t$ ] with @xmath119 and @xmath120 to each of the position variables we associate a momentum variable and we write the hamiltonian @xmath121 where @xmath122^t$ ] is the momentum vector .",
    "thus , the momenta variables are gaussian distributed random variables with mean zero and variance 1 .",
    "the equations of motion for this hamiltonian system are given by hamilton s equations @xmath123 hmc proceeds by assigning initial conditions to the momenta variables ( through sampling from @xmath124 ) , evolving the hamiltonian system in fictitious time @xmath125 for a given number of steps of size @xmath126 and then using the solution of the system to perform a metropolis accept / reject step ( more details in @xcite ) .",
    "after the metropolis step , the momenta values are discarded .",
    "the most popular method for solving the hamiltonian system , which is the one we also used , is the verlet leapfrog scheme . in our numerical implementation , we did not attempt to optimize the performance of the hmc algorithm . for the sampling we used @xmath127 metropolis",
    "accept / reject steps and @xmath30 hmc step of size @xmath128 to construct a trial path .    for the nonlinear observation model we can use the same procedure as in the linear observation model to define a hamiltonian system and its associated equations .",
    "we omit the details .",
    "we start the presentation of our numerical experiments with results for the linear observation model .",
    "figures [ plot_linear_linear ] and [ plot_linear_linear_focus ] show the evolution in the @xmath66 space of the true targets , the observations as well as the estimates of the improved particle filter .",
    "it is obvious from the figures that the improved particle filter follows accurately the targets and there is no ambiguity in the identification of the target tracks .",
    "the performance of the improved particle filter with 100 samples is compared to the performance of the generic particle filter with 120 samples in figure [ plot_linear_linear_error ] by monitoring the evolution in time of the rms error per target .",
    "the rms error per target ( rmse ) is defined with reference to the true target tracks by the formula @xmath129",
    "\\|^2     } \\ ] ] where @xmath130 is the norm of the position and velocity vector .",
    "note that the state vector norm involves both positions and velocities even though the observations use information only from the positions of a target .",
    "@xmath131 is the true state vector for target @xmath132 @xmath133 $ ] is the conditional expectation estimate calculated with the improved or generic particle filter depending on whose filter s performance we want to calculate .",
    "the improved particle filter has a computational overhead of the order of a few percent compared to the generic particle filter .",
    "we have thus used the generic particle filter with more samples than the improved particle filter . this additional number of samples more than accounts for the computational overhead of the improved particle filter .",
    "as can be seen in figure [ plot_linear_linear_error ] the generic particle filter s accuracy deteriorates quickly .",
    "on the other hand , the improved particle filter maintains an @xmath134 rms error per target for the entire tracking interval .",
    "the average value of the rms error over the entire time interval of tracking is about 2.5 with standard deviation of about 0.5 . for the generic particle filter",
    ", the average of the rms error over the time interval of tracking is about 800 with standard deviation of about 760 .",
    "figure [ plot_linear_linear_effective ] compares the effective sample size for the generic particle filter and the improved particle filter . because the number of samples is different for the two filters we have plotted the effective sample size as a percentage of the number of samples .",
    "we have to note that , after about 50 steps , the generic particle filter started producing observation weights ( before the normalization ) which were numerically zero .",
    "this makes the normalization impossible . in order to allow the generic particle filter to continue we chose at random one of the samples , since all of them are equally bad , and assigned all the weight to this sample .",
    "we did that for all the steps for which the observation weights were zero before the normalization .",
    "as a result , the effective sample size for the generic particle filter drops down to 1 sample after about 50 steps .",
    "once the generic particle filter deviates from the true target tracks there is no mechanism to correct it . also , we tried assigning equal weights to all the samples when the observation weights dropped to zero .",
    "this did not improve the generic particle s performance either .",
    "on the other hand , the improved particle filter maintains an effective sample size which is about @xmath135 of the number of samples .",
    "we continue with results for the nonlinear observation model .",
    "figures [ plot_linear_nonlinear ] and [ plot_linear_nonlinear_focus ] show the evolution in the @xmath66 space of the true targets , the observations as well as the estimates of the improved particle filter . again , as in the case of the linear observation model , the improved particle filter follows accurately the targets and there is no ambiguity in the identification of the target tracks .",
    "the case of the nonlinear observation model is much more difficult than the case of the linear observation model .",
    "the reason is that for the nonlinear observation model , the observation errors , though constant in bearing and range space , they become position dependent in @xmath66 space . in particular , when @xmath136 and/or @xmath137 are large , the observation errors can become rather large .",
    "this is easy to see by taylor expanding the nonlinear transformation from bearing and range space to @xmath66 space around the true target values .",
    "suppose that the true target bearing and range are @xmath138 and its @xmath66 space position is @xmath139 also , assume that the observation error in bearing and range space is , respectively , @xmath140 and @xmath141 the @xmath66 position of a target that is perturbed by @xmath140 and @xmath142 in bearing and range space is ( to first order ) @xmath143 thus , the perturbation in @xmath66 space can be significant even if @xmath140 and @xmath144 are small .",
    "in our example we have @xmath145 so , when the true target @xmath136 and @xmath137 values become of the order of @xmath146 as happens for some of the targets , the observation value in bearing and range space can be quite misleading as far as the @xmath66 space position of the target is concerned . as a result ,",
    "even if one does a good job in following the observation in bearing and range space , the conditional expectation estimate of the @xmath66 space position can be inaccurate .    with this in mind",
    ", we have used 200 samples for the improved particle filter and 220 samples for the generic particle filter .",
    "again , the extra samples used for the generic particle filter more than account for the computational overhead of the improved particle filter .",
    "the performance of the improved particle filter is compared to the performance of the generic particle filter in figure [ plot_linear_nonlinear_error ] by monitoring the evolution in time of the rms error per target .",
    "the generic particle filter s accuracy again deteriorates rather quickly .",
    "the error for the improved particle filter is larger than in the linear observation model but never exceeds about 80 even after 200 steps when the targets have reached large values of @xmath136 and/or @xmath147 the average value of the rms error over the entire time interval of tracking is about 22 with standard deviation of about 21 . for the generic particle filter ,",
    "the average of the rms error over the time interval of tracking is about 760 with standard deviation of about 770 .",
    "figure [ plot_linear_nonlinear_effective ] compares the effective sample size for the generic particle filter and the improved particle filter .",
    "after about 60 steps , the generic particle filter , started producing observation weights ( before the normalization ) which were numerically zero .",
    "this makes the normalization impossible . in order to allow the generic particle filter to continue we chose at random one of the samples , since all of them are equally bad , and assigned all the weight to this sample .",
    "we did that for all the steps for which the observation weights were zero before the normalization .",
    "as a result , the effective sample size for the generic particle filter drops down to 1 sample after about 60 steps .",
    "once the generic particle filter deviates from the true target tracks there is no mechanism to correct it . also , we tried assigning equal weights to all the samples when the observation weights dropped to zero .",
    "this did not improve the generic particle s performance either .",
    "on the other hand , the improved particle filter maintains an effective sample size which is about @xmath135 of the number of samples .",
    "we have presented an algorithm for multi - target tracking which builds on the existing particle filter methodology for multi - target tracking by appending an mcmc step after the particle filter resampling step .",
    "the purpose of the addition of the mcmc step is to bring the samples closer to the observation .",
    "even though the addition of an mcmc step for a particle filter has been proposed and used before @xcite , to the best of our knowledge , the currently proposed implementation of the mcmc step is novel ( see also @xcite for a related approach ) .",
    "we have tested the performance of the algorithm on the problem of tracking multiple targets evolving under the near constant velocity model @xcite .",
    "we have examined two cases of observation models : i ) a linear observations model involving the positions of the targets and ii ) a nonlinear observation model involving the bearing and range of the targets . for both cases",
    "the proposed improved particle filter exhibited a significantly better performance than the generic particle filter .",
    "since the improved particle filter requires more computations than the generic particle filter it is bound to be more expensive .",
    "however , the computational overhead of the improved particle filter is rather small , of the order of a few extra samples worth for the generic particle filter .",
    "in @xcite we proposed another way of performing the extra mcmc step of a particle filter .",
    "that approach was based on modifying the drift of the dynamic model and then accounting for the modification . in the current work ,",
    "we use the original drift of the dynamic model without any modification .",
    "for the case of multi - target tracking with observations at every time step both algorithms perform equally well . thus , at first sight it would appear that there is no need for the extra complication of modifying the drift of the dynamic model and then accounting for the modification as was done in @xcite .",
    "however , in cases where there are only sparse observations , the sampling of the conditional density needed for the extra step can be much more difficult ( and consequently expensive ) for the original dynamic model than for the modified dynamic model . with this in mind , the approach in @xcite seems to have wider applicability .",
    "a detailed comparison of the algorithm proposed in the current work and the one proposed in @xcite will be presented in a future publication .",
    "we are grateful to prof .",
    "j. weare for many discussions .",
    "also , we would like to thank the institute for mathematics and its applications in the university of minnesota for its support .",
    "blackman s. and popoli r. , design and analysis of modern tracking systems , norwood , ma , artech house , 1999 .",
    "chorin , a.j .",
    "and tu x. , implicit sampling for particle filters , proc .",
    "acad . sc .",
    "usa 106 ( 2009 ) pp .",
    "17249 - 17254 .",
    "maroulas v. and stinis p. , a drift homotopy monte carlo approach to particle filtering for multi - target tracking , ( 2010 ) , arxiv:1006.3100v1 .",
    "ng w. , li j.f . , godsill s.j . and vermaak j. , a hybrid approach for online joint detection and tracking for multiple targets , proc .",
    "ieee aerospace conference ( 2005 ) pp .",
    "2126 - 2141 ."
  ],
  "abstract_text": [
    "<S> in recent work @xcite , we have presented a novel approach for improving particle filters for multi - target tracking . </S>",
    "<S> the suggested approach was based on drift homotopy for stochastic differential equations . </S>",
    "<S> drift homotopy was used to design a markov chain monte carlo step which is appended to the particle filter and aims to bring the particle filter samples closer to the observations . in the current work , </S>",
    "<S> we present an alternative way to append a markov chain monte carlo step to a particle filter to bring the particle filter samples closer to the observations . </S>",
    "<S> both current and previous approaches stem from the general formulation of the filtering problem . </S>",
    "<S> we have used the currently proposed approach on the problem of multi - target tracking for both linear and nonlinear observation models . </S>",
    "<S> the numerical results show that the suggested approach can improve significantly the performance of a particle filter . </S>"
  ]
}