{
  "article_text": [
    "real - world information sensing and transmission devices are subject to various types of measurement noise ; for example , losses in resolution ( e.g. ,  quantization effects ) , randomness inherent in the signal of interest ( e.g. ,  photon or packet arrivals ) , and variabilities in physical devices ( e.g. ,  thermal noise , electron leakage ) can all contribute significantly to signal degradation .",
    "estimation of a vector - valued signal @xmath0 given noisy observations @xmath1 therefore plays a prominent role in a variety of engineering applications such as signal processing , digital communications , and imaging .    at the same time , statistical modeling of transform coefficients as latent variables has enjoyed tremendous popularity across these diverse applications  in particular , wavelets and other filterbank transforms provide convenient platforms ; as is by now universally acknowledged , such classes of transform coefficients tend to exhibit temporal and spectral decorrelation and energy compaction properties for a variety of data . in this",
    "setting , the special case of additive white gaussian noise is by far the most studied scenario , as the posterior distribution of coefficients is readily accessible when the likelihood function admits a closed form in the transform domain .",
    "the twin assumptions of additivity and gaussianity , however , are clearly inadequate for many genuine engineering applications ; for instance , measurement noise is often dependent on the range space of the signal @xmath2 , effects of which permeate across multiple transform coefficients and subbands  @xcite .",
    "for instance , the number of photoelectrons @xmath3 accumulated by the @xmath4th element of a photodiode sensor array  an integrating detector that `` counts photons''is well modeled as a poisson random variable @xmath5 , where @xmath6 is proportional to the average incident photon flux density at the @xmath4th sensor element .    recall that for @xmath5 we have that @xmath7 , and so in the case at hand @xmath6 reflects ( up to quantum efficiency ) the @xmath4th expected photoelectron count , with the resultant `` noise '' in the form of variability being signal - dependent and hence heteroscedastic .",
    "indeed , the local signal - to - noise ratio at the @xmath4th sensor element is seen to grow linearly with signal strength as @xmath8 = @xmath9 , implying very noisy conditions when dealing with inefficient detectors or low photon counts .",
    "classical variance stabilization techniques dating back to bartlett and anscombe  @xcite yield an approach to poisson mean estimation designed to recover homoscedasticity , with  @xcite providing a summary of more recent work .",
    "here one seeks an invertible operator @xmath10 , typically by way of a compressive nonlinearity such as the component - wise square root , that ( approximately ) maps the heteroscedastic realizations of an inhomogeneous poisson process to the familiar additive white gaussian setting : @xmath11 standard techniques may then be used to estimate @xmath12 directly , with the inverse transform @xmath13 applied post hoc .",
    "inhomogeneous poisson data can also be treated directly .",
    "for instance , empirical bayes approaches leverage the independence of poisson variates via their empirical marginal distributions  @xcite , while multiparameter estimators borrow strength to improve upon maximum - likelihood estimation  @xcite ; however , this ignores potential correlations amongst elements of @xmath2 .",
    "to address such concerns , multiresolution approaches to poisson intensity estimation were introduced to explicitly encode the dependencies between the poisson variables in the context of haar frames  @xcite .",
    "the relative merits of the various methods described above are well documented  @xcite and will not be repeated here .    in this paper",
    ", we address poisson rate estimation directly in the haar wavelet and haar filterbank transform domains by way of the _ skellam distribution _",
    "@xcite , whose use to date has been limited to special settings  @xcite .",
    "after briefly reviewing wavelet and filterbank coefficient models in section  [ sec : wavelets ] , we then describe in section  [ sec : estimation ] new bayesian and frequentist transform - domain estimators for both exact and approximate inference . here",
    "we first derive posterior means under canonical heavy - tailed priors , along with analytical approximations to the optimal estimators that we show to be both efficient and practical .",
    "we then show how inhomogeneous poisson variability leads to a variant of stein s unbiased risk estimation  @xcite for parametric estimators in the transform domain .",
    "simulation studies presented in section  [ sec : results ] verify the effectiveness of our approach , and we conclude with a brief discussion in section  [ sec : discussion ] .",
    "consider a nested sequence of closed subspaces @xmath14 of @xmath15 satisfying the axioms required of a multiresolution analysis  @xcite .",
    "then there exists a _ scaling function _",
    "@xmath16 such that the family @xmath17 is an orthonormal basis of @xmath18 for all @xmath19 .",
    "there also exist a corresponding _ conjugate mirror filter _",
    "sequence @xmath20 and _ admissible wavelet _",
    "@xmath21 , with fourier transforms @xmath22 respectively , satisfying @xmath23 moreover , for any fixed scale @xmath24 the wavelet family @xmath25 forms an orthonormal basis of the orthogonal complement of @xmath18 in @xmath26 , and for all @xmath27 the wavelet families together comprise an orthobasis of @xmath15 .",
    "recursively expanding the above @xmath28 times , and defining @xmath29 we see that any @xmath30 admits the following orthobasis expansion in terms of its wavelet and scaling coefficients : @xmath31 the mapping @xmath32 is termed a @xmath28-level continuous wavelet transform , with an analogous discrete wavelet transform defined for sequences in @xmath33 .    for the special case of a haar wavelet transform , we take as our scaling function @xmath34}$ ] ( the unit indicator ) , with @xmath35 yielding @xmath36 as the only nonzero conjugate mirror filter values .",
    "this in turn induces a recursive relationship as follows : @xmath37    in fact , this one - level transform is a version of a filterbank transform  a canonical multirate system of the type used for time - frequency analysis in digital signal processing .",
    "that is , @xmath38 satisfies the perfect reconstruction condition  @xcite @xmath39    in the formulation of  , each sequence @xmath40 is decomposed into lowpass and highpass components @xmath41 in turn .",
    "a recursive application of the map @xmath42 yields the haar wavelet transform , whereas the same transform applied to highpass component @xmath43 further decomposes it into narrower bands .",
    "recursive decomposition of _ both _ lowpass and highpass sequences in this way yields the hadamard transform , otherwise known as the haar filterbank transform .",
    "the low computational requirements of these transforms make them attractive alternatives to other joint time - frequency analysis techniques possessing better frequency localization .",
    "the haar transforms enjoy orthogonality , compact spatial support , and computational simplicity , with the haar wavelet transform satisfying the axioms of a multiresolution analysis .",
    "we later demonstrate how their simplicity serves to admit analytical tractability that in turn enables efficient inference and estimation procedures .    as a final note ,",
    "we omit subband index @xmath44 in the sequel , as wavelet coefficients @xmath45 are always aggregated within a given scale @xmath24 ; for notational clarity in the finite - dimensional setting , further suppression of subscript @xmath4 will be used to indicate a generic scalar coefficient @xmath46 , as distinct from vector - valued quantities ( e.g. , @xmath47 ) indicated in bold throughout .      turning to the problem of transform - domain denoising ,",
    "consider the case whereupon a vector of noisy orthobasis coefficients @xmath48 is observed , with @xmath47 deterministic but unknown .",
    "writing an estimator for @xmath47 as @xmath49 , stein s lemma  @xcite may be used to formulate an unbiased estimate of the associated @xmath50 risk @xmath51 as follows .",
    "[ lem : stein_lem ] let @xmath52 , with @xmath47 unknown , and fix an estimator @xmath53 such that @xmath54 is weakly differentiable . then the resultant risk may be formulated as @xmath55 \\text{,}\\ ] ] with @xmath56 an unbiased estimate thereof .",
    "hence , by replacing the latter expectation of   with an evaluation over the vector @xmath57 of observed transform coefficients , one may directly optimize parameter choices for nonlinear shrinkage estimators  for example soft thresholding , given by @xmath58 as an example that we shall return to later , sureshrink  @xcite is obtained from   and   by writing @xmath59 : @xmath60 and thus @xmath61 is chosen to minimize the empirical risk estimate @xmath62      in contrast to the above setting of additive white gaussian noise , the distribution of inhomogeneous poisson data @xmath63 is _ not _ invariant under orthogonal transformation  and",
    "so transform - domain denoising ceases to be as straightforward in the general setting  @xcite .",
    "however , for the special cases of the haar wavelet and filterbank transforms described in section  [ sec : review_wavelets ] , we may characterize their coefficient distributions in closed form as sums and differences of poisson counts .    to this end , let the matrix @xmath64 denote an ( unnormalized ) haar filterbank transform .",
    "taking @xmath65 to be the transform of @xmath66 , the resultant wavelet and scaling coefficients comprise sums and differences of elements of @xmath2 : @xmath67    an analogous definition with respect to the observed data @xmath5 and its haar filterbank transform @xmath68 implies that the empirical wavelet and scaling coefficients themselves comprise sums and differences of poisson counts : @xmath69    thus the empirical coefficients defined by   are effectively corrupted versions of those in  .",
    "while the sum of poisson variates @xmath70 and @xmath71 is again poisson , as indicated by the expression of   for empirical scaling coefficient @xmath72 , the distribution of their difference also admits a closed - form expression , first characterized by skellam  @xcite using generating functions .",
    "[ prop : poissondiff ] fix @xmath73 , and let the random variable @xmath74 denote the difference of two poisson variates @xmath75 and @xmath76 .",
    "defining @xmath77 to be the @xmath78th - order modified bessel function of the first kind , we have that @xmath79    a direct verification is provided by series representations of bessel functions  @xcite .",
    "first , note that via correlation of poisson densities we obtain directly @xmath80 by change of variables in the summation index of   according to @xmath81 , we obtain a summand that is symmetric in @xmath82 as follows : @xmath83 the result follows from the observation that @xmath84 admits , for positive argument and order , the real - valued taylor expansion @xmath85 coupled with the fact that @xmath86 for @xmath87 .",
    "we have thus proved that the distribution of each empirical coefficient @xmath88 in   may be described as follows .",
    "[ def : skellam ] let @xmath89 denote a difference of poisson variates according to   , with index @xmath4 suppressed for clarity as in proposition  [ prop : poissondiff ] .",
    "then @xmath90 where @xmath91 , and variate @xmath78 takes the _ skellam distribution _ : @xmath92    as the difference of two poisson variates , a skellam variate ranges over the integers unless either @xmath93 , in which case a direct appeal to the discrete convolution of   recovers the limiting poisson cases . on the other hand ,",
    "as both @xmath94 , it follows from the central limit theorem that the distribution of a skellam variate tends toward that of a normal .",
    "the skewness of a skellam random variable is easily obtained from its generating function as @xmath95  @xcite , and hence is proportional to the difference in poisson means @xmath96 and @xmath97 , with a rate that grows in inverse proportion to their sum . indeed , when @xmath98 the distribution is symmetric , with variance @xmath99 proportional to the geometric mean of @xmath96 and @xmath97 according to  . a standard",
    "@xmath100 skellam random variable is shown in fig .",
    "[ fig : skellamstandard ] ,     +    with fig .",
    "[ fig : skellamtail ] detailing the tail behavior of other symmetric cases @xmath101 ; examples illustrating skewness as a general function of mean and variance are shown in fig .",
    "[ fig : skellamskew ] .",
    "returning now to our context of haar transforms , we next observe that the density of empirical coefficient @xmath102 depends only on the corresponding wavelet and scaling coefficients @xmath103 and @xmath104 ( and similarly for the coarsest haar wavelet subband ) .    [ prop : condind ] let @xmath105 according to definition  [ def : skellam ] , with @xmath65 a vector of haar filterbank transform coefficients , and @xmath57 that of the empirical coefficients .",
    "then @xmath106    the relation is a straightforward consequence of the choice of transform . from the definitions in  ,",
    "@xmath107 let @xmath108 and @xmath109 be row vectors from @xmath110 such that @xmath111 and @xmath112 , respectively .",
    "it is easily verified that the @xmath113th entry of @xmath114 is nonzero if and only if @xmath115 , and hence @xmath116",
    "recall our goal of leveraging properties of haar wavelets and filterbanks to accomplish transform - domain intensity estimation for inhomogeneous poisson data . to this end",
    "there are two main conclusions to be drawn from section  [ sec : skellam ] above : first , poisson variability in the data domain gives rise to skellam variability in haar transform domains ( definition  [ def : skellam ] ) .",
    "second , the conditional independence structure of haar coefficients suggests univariate skellam estimators as a first step toward achieving satisfactory performance ( proposition  [ prop : condind ] ) .",
    "accordingly , we now turn our attention to deriving univariate skellam mean estimators under both bayes and frequentist assumptions .",
    "we work throughout with the generic scalar quantity @xmath117 , where haar scaling coefficient @xmath99 is given and haar wavelet coefficient @xmath118 is a latent variable , assumed to be random or deterministic depending on context . although the scaling coefficient is not directly observed in practice , this standard wavelet estimation assumption amounts to using the empirical scaling coefficient @xmath72 of   as a plug - in estimator of @xmath104 in  . as haar",
    "scaling coefficients constitute sums of poisson variates in this context , their expected signal - to - noise ratios are likely to be high , in keeping with the arguments of section  [ sec : intro ] , and moreover they admit asymptotic normality .",
    "we first develop some needed properties of the skellam likelihood model ; while these follow from standard recurrence relations for bessel functions of integral order , probabilistic derivations can prove more illuminating .",
    "we begin with expressions for partial derivatives of the skellam distribution .",
    "[ prop : skellampartials ] partial derivatives of the skellam likelihood @xmath119 admit the following finite - difference expressions : @xmath120 \\\\ \\frac{\\partial}{\\partial s } p(y\\,;x , s ) & = \\frac{1}{2}\\left[p(y\\!-\\!1\\,;x , s)+p(y\\!+\\!1\\,;x , s)\\right ] - p(y\\,;x , s ) \\text{.}\\end{aligned}\\ ] ]    recall from definition  [ def : skellam ] that a skellam variate @xmath117 comprises the difference of two poisson variates with respective means @xmath96 and @xmath97 . denoting by @xmath121 the ( conjugate ) fourier transform operator acting on the corresponding probability measure",
    ", its characteristic function in @xmath122 follows as @xmath123 \\\\ & = \\textstyle \\exp\\left [ \\frac{1}{2}(s+x )   e^{j\\omega } + \\frac{1}{2}(s - x ) e^{-j\\omega } - s \\right ] \\text{;}\\end{aligned}\\ ] ] and hence , invoking linearity , we may compute derivatives as : @xmath124 and similarly for the partial derivative of @xmath119 in @xmath99 .",
    "property  [ prop : skellampartials ] implies that @xmath125 is the normalized first central difference of the likelihood on its domain @xmath78 , and that @xmath126 is one - half the normalized second central difference . hence slope and curvature of the likelihood",
    "are encoded directly in the skellam score functions .",
    "next , we note that for @xmath87 the standard bessel identity @xmath127 implies the following .",
    "[ prop : skellamrecursion ] the skellam likelihood @xmath119 admits the following recurrence relation in @xmath78 for fixed @xmath128 : @xmath129    this property lends itself to easy calculation of the skellam likelihood , as fixed initial values may be tabulated and used to initialize the recursion , thus avoiding the evaluation of bessel functions .    combining properties  [ prop : skellampartials ] and  [ prop : skellamrecursion ] , we have our final result .    [",
    "prop : deriv ] the skellam likelihood @xmath119 satisfies a linear , first - order hyperbolic partial differential equation in @xmath128 , for fixed @xmath78 , as follows : @xmath130      having developed needed properties of the skellam likelihood @xmath119 above , and with @xmath99 assumed directly observed , we now consider the setting in which each underlying transform coefficient @xmath131 is modeled as a random variable . while determining the most appropriate choice of prior distribution for different problem domains remains an open area of research , with examples ranging from generalized gaussian distributions through discrete and continuous scale mixtures , we make no attempt here to introduce new insights on prior elicitation .",
    "rather , we focus on optimal estimation for general classes of prior distributions having compact support .",
    "the problem being univariate , exact inference is realizable through numerical methods ; however , the requisite determination of prior parameters , possibly from data via empirical bayes , renders this approach infeasible in practice , as posterior values can not be easily tabulated in advance . to this end , the main result of this section is an approximate skellam conditional mean estimator with bounded error , obtained as a closed - form shrinkage rule .",
    "[ thm : skellampost ] consider a skellam random variable @xmath132 , with @xmath99 fixed but @xmath133 a random variable that admits a density with respect to lebesgue measure on @xmath134 $ ] .",
    "define the bayes point estimator @xmath135 whence a projection of the score function in @xmath118 via conditional expectation .",
    "its squared approximation error , relative to the conditional expectation @xmath136 , then satisfies @xmath137 ^ 2 \\big\\vert\\,y;s\\right ) \\ !",
    "\\text{.}\\ ] ]    bayes rule applied to the differential equation of   yields the necessary conditional expectations , after which cauchy - schwarz serves to bound its latter term .",
    "while we can not control the second moment of @xmath133 conditioned on @xmath138 in the bound above , its latter term admits by property  [ prop : skellampartials ] the equivalence @xmath139 ^ 2 \\big\\vert\\,y;s\\right ) = \\operatorname{\\mathbb{e}}\\!\\left(\\left [ \\frac{(\\delta_2^y \\ !",
    "p)(y\\,\\vert\\,x;s)}{2p(y\\,\\vert\\,x;s ) } \\right]^2 \\big\\vert\\,y;s \\right ) \\text{,}\\ ] ] where @xmath140 denotes the normalized second central difference in @xmath138 , analogous to a second derivative .",
    "this term therefore goes as the square of the normalized local curvature in the likelihood at @xmath141 , averaged over the posterior distribution of @xmath133 ; it will be small on portions of the domain over which the likelihood remains approximately linear for sets of @xmath133 having high posterior probability .",
    "theorem  [ thm : skellampost ] thus provides a means of obtaining bayesian shrinkage rules under different choices of prior distribution @xmath142 , via evaluation of the expectation of   as @xmath143 while the above formulation is amenable to further approximation via taylor expansion ( akin to laplace approximation ) , we focus here on a direct evaluation of @xmath144 .    discounting the former term of  , which simply measures the difference in posterior tail decay at @xmath145 and goes to zero with increasing @xmath99 , the derivative on @xmath134 $ ] is easily computed for the so - called generalized gaussian distribution for @xmath146 , with location parameter @xmath147 and scale parameter @xmath148 : @xmath149 \\ ! \\text{,}\\end{aligned}\\ ] ] with @xmath150 the gamma function and @xmath151^{p/2}$ ] .",
    "this distribution being unimodal and symmetric about its mean , we obtain for @xmath152 the expression @xmath153 from which the gaussian ( @xmath154 ) and laplacian ( @xmath155 ) cases admit straightforward evaluation .    [",
    "prop : approx_bound ] let @xmath156 denote a generalized gaussian distribution with exponent @xmath146 having mean zero and variance @xmath157 , and set @xmath158}(x)$ ] . for @xmath132",
    "we then have :    if @xmath154 so that @xmath159}(x)$ ] , then @xmath160 with @xmath161 the lower incomplete gamma function , and @xmath162    if @xmath155 so that @xmath163}(x)$ ] , then @xmath164 @xmath165    combining proposition  [ prop : approx_bound ] with theorem  [ thm : skellampost ] yields approximate posterior mean estimators under truncated gaussian and laplacian priors . the gaussian case recovers the shrinkage rule @xmath166 the optimal linear estimator under a second - moment normal approximation to the skellam likelihood , with mean zero and variance @xmath99 . the heavier - tailed laplacian case yields an implicit shrinkage rule illustrated in fig .  [",
    "fig : posterior ] ,     illustration of the shrinkage implicit in   as a function of the posterior distribution @xmath167 in the case of a skellam likelihood , showing the contribution of posterior mass to shrinkage toward and away from zero , scaledwidth=52.5% ]    whose asymptotic behavior in turn enables a simple soft - thresholding rule to be fitted : @xmath168 \\\\ & \\approxeq \\operatorname{sgn}(y ) \\ , \\max \\ !",
    "\\left ( |y| - \\sqrt{2}s / \\sigma_x , 0 \\right ) \\label{eqn : sbt } \\text{,}\\end{aligned}\\ ] ] the soft - thresholding estimator of   can in turn be adapted to yield a piecewise - linear estimator whose",
    "slope matches that of   at the origin . to accomplish this , note that for any prior distribution with even symmetry ,   of definition  [ def : skellam ] implies odd symmetry of the posterior expectation functional ; i.e.",
    ", @xmath169 therefore the slope of any shrinkage estimator at the origin may be computed as @xmath170   = \\operatorname{\\mathbb{e}}(x\\,\\vert\\,y\\!=\\!1\\,;s ) \\text{.}\\ ] ] the slope term @xmath171 may in turn be pre - computed to arbitrary accuracy using numerical methods , and indexed as a function of @xmath99 and prior variance @xmath157 , yielding the following piecewise - linear shrinkage estimator : @xmath172 figure  [ fig : bayes ]    bayesian shrinkage rules corresponding to a laplacian prior and skellam likelihood , with dotted 45@xmath173 line shown for reference : skellam bayes ( sb ) mmse shrinkage rule , computed numerically ; soft - thresholding ( sbt ) approximation of  ; and piecewise - linear ( sbl ) approximation of  ]    in turn compares the exact posterior mean shrinkage rule , corresponding to @xmath174 and computed numerically , with the soft - thresholding estimator of   and the piecewise - linear estimator of  .",
    "the ideas above can be straightforwardly extended to the multivariate case  @xcite , owing to conditional independence properties of the skellam likelihood ; derivatives may also be computed for the case of mixture priors , though no efficient solution is yet known to compute the mixture weights .",
    "having derived bayes estimators for the class of unimodal , zero - mean , symmetric priors considered above , we now turn to parameter and risk estimation for skellam shrinkage . with only a single observation of each haar coefficient in this heteroscedastic setting , maximum - likelihood methods will simply return the identity as a shrinkage rule .",
    "however , by borrowing strength across multiple coefficient observations we may improve upon the risk properties of this approach ; as we now detail , this is equally attainable in a frequentist or bayes setting .",
    "here we consider coefficient aggregation within a given scale , with notation @xmath175 below indicating summation over location parameter @xmath4 within a single haar subband .",
    "the main result of this section is the following theorem , which yields a procedure for unbiased @xmath50 risk estimation in the context of soft thresholding and other shrinkage operators .    [ thm : skellam ] let @xmath105 and @xmath176 according to  , with @xmath177 unknown .",
    "fix a vector - valued estimator @xmath178 , where @xmath179 , and let @xmath180 denote the vector of all ones .",
    "then the @xmath50 risk of @xmath181 may be expressed as follows : @xmath182 \\text{,}\\end{gathered}\\ ] ] with @xmath183 an unbiased estimate thereof .",
    "the risk @xmath184 may be expanded as @xmath185 with @xmath186 . to evaluate the final term in   above , note first that @xmath187 according to   and  , and furthermore that @xmath188 .",
    "by conditioning on @xmath189 or @xmath190 we in turn obtain poisson variates , and thus general results for discrete exponential families  @xcite apply , yielding the final relations needed to complete the proof of theorem  [ thm : skellam ] : @xmath191    parameters of any chosen estimator form @xmath181 may thus be optimized by minimizing the unbiased risk estimate of theorem  [ thm : skellam ] with respect to observed data vectors @xmath57 and @xmath192 .",
    "as an important special case , we obtain the following corollary .",
    "[ cor : skellamshrink ] the optimal threshold @xmath61 for soft thresholding as @xmath193 is obtained by minimizing @xmath194    recall the stein s unbiased risk estimate sureshrink result  @xcite for soft thresholding in the case of additive white gaussian noise of variance @xmath195 , as described in   of section  [ sec : review_denoising ] . recasting the objective function of   for sureshrink threshold optimization as @xmath196",
    "we see that @xmath72 in   plays a role analogous to @xmath195 in the homoscedastic sureshrink setting represented by  , with the dependence on coefficient index @xmath4 reflecting the heteroscedasticity present in the skellam likelihood case .",
    "we may also consider a generalization of the skellamshrink soft thresholding estimator of corollary  , inspired by the bayes point estimator @xmath197 of theorem  [ thm : skellampost ] , in which individual coefficient thresholds depend in general on the corresponding scaling coefficient . by treating the quantity @xmath148 appearing in the bayesian estimators of section  [ sec : bayesest ] not as a prior variance parameter , but simply as part of a parametric risk form",
    "to be optimized , we may appeal directly to the unbiased risk estimation formulation of theorem  [ thm : skellam ] .",
    "since a priori knowledge limitations may well preclude exact prior elicitation in practice , this flexible approach provides a degree of robustness to prior model mismatch , as borne out by our simulation studies below .    as an example , consider a shrinkage estimator @xmath198 that depends on @xmath199 and unknown parameter @xmath148 as per the soft thresholding formulation of  : @xmath200 defining @xmath201 and @xmath202 for notational convenience , we have the risk estimate @xmath203 with @xmath204 and @xmath205 denoting the floor and ceiling operators , respectively , and @xmath206 and @xmath207 adjusting for the singularity at @xmath208 .      the strategy outlined above",
    "naturally generalizes to any form of parametric estimator via the unbiased risk estimation formulation of theorem  [ thm : skellam ] , enabling an improvement over the variance - stabilization strategies of section  [ sec : intro ] by direct minimization of empirical risk . as a specific example , consider the haar - fisz estimator of  @xcite , in which each empirical haar wavelet coefficient @xmath102 is scaled by the root of its corresponding empirical scaling coefficient as @xmath209 in order to achieve variance stabilization , after which standard gaussian shrinkage methods such as sureshrink are applied and the variance stabilization step inverted .    for the case of nonlinear shrinkage operators , of course , neither the resultant estimators nor the risk estimates themselves will in general commute with this haar - fisz strategy , leading to a loss of the unbiasedness property of risk minimization  in contrast to the direct application of theorem  [ thm : skellam ] .",
    "taking haar - fisz soft thresholding with some fixed threshold @xmath61 as an example , the equivalent skellam shrinkage rule is seen to be @xmath210with @xmath211 in contrast to the scaling of @xmath199 implied by theorem  [ thm : skellampost ] , as in the adjusted - threshold approach of   above . in an analogous manner , the corresponding _ exact _ unbiased risk estimate for this shrinkage rule can in turn be derived directly by appeal to theorem  [ thm : skellam ] , rather than relying on the heretofore standard haar - fisz approach of sureshrink empirical risk minimization via  , applied to the variance - stabilized coefficients @xmath212 .",
    "we conclude this section with a simple and effective empirical bayes strategy for estimating scaling coefficients @xmath213 and prior parameter @xmath148 for the bayesian shrinkage rules derived in section  [ sec : bayesest ] above .",
    "recall from   that @xmath214 , implying the use of the empirical scaling coefficient @xmath72 as a direct substitute for @xmath104 in the bayesian setting .",
    "note that @xmath215 for haar transform matrix @xmath216 , with @xmath199 a corresponding sum of poisson variates with means @xmath217 representing the underlying intensities of interest to be estimated . in turn , as the sum @xmath104 increases , the relative risk @xmath218 of the plug - in estimator @xmath219 will rapidly go to zero precisely at rate @xmath220 .",
    "next note that under the assumption of a unimodal , zero - mean , and symmetric prior distribution @xmath142 , only @xmath221 remains to be estimated .",
    "a convenient moment estimator is available , since @xmath222 and @xmath223 together imply that @xmath224 , and hence we obtain @xmath225 .",
    "once estimates @xmath226 and @xmath213 are obtained for the coefficient population of interest , the implicit variance equations of   and   may be solved numerically to yield scale parameter @xmath148 of the truncated generalized gaussian distribution considered earlier , with @xmath227 in the limit as @xmath99 grows large . in our simulation regimes , we observed no discernable difference in overall wavelet - based estimation performance by setting @xmath228 directly .",
    "we now describe a series of simulation studies undertaken to evaluate the efficacy of the wavelet - based shrinkage estimators derived above .",
    "we considered exact skellam bayes ( sb ) posterior mean estimators , computed numerically with respect to a given prior ; the skellam bayes gaussian approximation ( sbg ) linear shrinkage of  ; the skellam bayes laplacian soft - thresholding ( sbt ) approximation of  ; the skellam bayes laplacian piecewise - linear ( sbl ) approximation of  ; the skellamshrink ( ss ) soft - thresholding estimator with empirical risk minimization of corollary  [ cor : skellamshrink ] ; and the skellamshrink hybrid ( sh ) adjusted - threshold shrinkage of  .",
    "estimators were implemented using a 3-level undecimated haar wavelet decomposition , with empirical risk minimization or the moment methods of section  [ sec : ebayes ] above used to estimate parameters for the corresponding shrinkage rules . as first comparison of relative performance , figs .",
    "[ fig : boxplot1 ] and  [ fig : boxplot2 ] tabulate results in mean - squared error ( mse ) for skellam likelihood inference in cases when the latent variables of interest are drawn from normal and laplacian distributions with known parameter @xmath229 .",
    "the accompanying box plots are shown on a log - mse scale for visualization purposes , in order to better reveal differences between estimator performance .",
    "these figures confirm that exact bayesian estimators ( sb ) outperform all others , but indicate that prior - specific skellam bayes approximations sbg and sbl are comparable , respectively , for the gaussian and laplacian cases over the range of prior parameters shown here . among soft - thresholding approaches ,",
    "the frequentist skellamshrink methods ss and sh in turn offer improvements over the bayesian soft - thresholding estimator sbt .",
    "[ cols=\"^ , > , > , > , > , > , > , > , > , > , > \" , ]     we now consider an image reconstruction scenario using a test set of well - known 8-bit gray scale test images that feature frequently in the engineering literature : `` barbara , '' `` boat , '' `` clown , '' `` fingerprint , '' `` house , '' `` lena , '' and `` peppers . ''",
    "corresponding pixel values are considered as the true underlying intensity function of interest ; both noise level characterization and reconstruction results are reported in terms of signal - to - noise ratio ( snr ) in decibels , a quantity proportional to log - mse . by way of competing approaches",
    "we consider  @xcite , with  @xcite used in conjunction with the variance stabilization methods of  @xcite .",
    "implementations were set at an equal baseline implementation comprising a 3-level undecimated haar wavelet decomposition , with no a priori neighborhood structures assumed amongst the coefficients .",
    "the performance of the skellam methods proposed here offers noticeable improvements over alternative approaches , in terms of visual quality ( fig .",
    "[ fig : example3 ] ) , mean - squared error ( table  [ tab : snr ] ) , and perceptual error ( table  [ tab : ssim ] ) . in terms of visual quality",
    ", we have generally observed that the proposed skellam bayes approaches yield restored images in which the spatial smoothing is appropriately locally adaptive  for example , these methods yield effective noise attenuation in both bright ( see forehead ) and dark ( see black background ) regions of the example image shown in fig .",
    "[ fig : example3 ] . a comparison of figs .",
    "[ fig : example3](c ) and  ( f ) reveals the importance of incorporating the scaling coefficient @xmath99 explicitly in the estimator ; images processed via sbt tended to be similar to those for which sh was used , but with softer edges . in comparison ,",
    "methods based on variance stabilization typically fail to completely resolve the heteroscedasticity of the underlying process , as evidenced by the under- and over - smoothed noise in bright regions such as the forehead and hair textures of fig .",
    "[ fig : example3](g ) .",
    "the bayesian method of  @xcite typically yields far smoother output images , in which texture information is almost entirely lost ; see , for example , the hair in fig .",
    "[ fig : example3](h ) . with the exception of ss ,",
    "skellam - based estimation methods suffer considerably less from the reconstruction artifacts typically associated with wavelet - based denoising , as can be seen in the cheek structure of the `` clown '' image .",
    "we also report numerical evaluations of estimator performance in this setting , by way of both snr in table  [ tab : snr ] and the widely - used perceptual error metric of structural similarity index ( ssim )  @xcite in table  [ tab : ssim ] , for input snr of 0 , 3 , and 10  db .",
    "the results readily confirm that skellam - based approaches outperform competing alternatives , with only that of  @xcite remaining competitive  though as described above , its oversmoothing results in a great deal of loss of texture .",
    "the skellamshrink adjusted - threshold hybrid ( sh ) method measures the best in terms of both snr and ssim , with other skellam - based approaches generally outperforming all alternatives save for  @xcite .",
    "in this article we derived new techniques for wavelet - based poisson intensity estimation by way of the skellam distribution .",
    "two main theorems , one showing the near - optimality of bayesian shrinkage and the other providing for a means of frequentist unbiased risk estimation , served to yield new estimators in the haar transform domain , along with low - complexity algorithms for inference .",
    "a simulation study using standard wavelet test functions as well as test images confirms that our approaches offer appealing alternatives to existing methods in the literature  and indeed subsume existing variance - stabilization approaches such as haar - fisz by yielding exact unbiased risk estimates  along with a substantial improvement for the case of enhancing image data degraded by poisson variability .",
    "we expect further improvements for specific applications in which correlation structure can be assumed a priori amongst haar coefficients , in a manner similar to the gains reported by  @xcite for the case of image reconstruction in the presence of additive noise .",
    "hirakawa , k. , baqai , f. , and wolfe , p.  j. ( 2009 ) .",
    "wavelet - based poisson rate estimation using the skellam distribution . in _ proceedings of the is&t / spie",
    "20th annual symposium on electronic imaging science and technology_. vol .  * 7246*. omputational imaging conference ( cic ) , doi 10.1117/12.815487 , http://sisl.seas.harvard.edu .",
    "hirakawa , k. and wolfe , p.  j. ayesian skellam shrinkage for denoising photon - limited image data .",
    "submitted to the 2009 _ ieee internat .",
    "conf . image process .",
    "_ , february 2009 , http://sisl.seas.harvard.edu .    hirakawa , k. and wolfe , p.  j. ( 2009 ) .",
    "kellamshrink : poisson intensity estimation for vector - valued data . in _ proc .",
    "ieee internat .",
    "speech signal process .",
    "_ 34413444 .",
    "http://sisl.seas.harvard.edu .",
    "luisier , f. , vonesch , c. , blu , t. , and unser , m. ( 2009 ) .",
    "fast haar - wavelet denoising of multidimensional fluorescence microscopy data . to appear in _ proc .",
    "6th ieee internat .",
    "imaging_. http://bigwww.epfl.ch/preprints .",
    "raphan , m. and simoncelli , e.  p. ( 2007 ) . learning to be bayesian without supervision . in _ advances in neural information processing systems 19",
    "_ , b.  schlkopf , j.  platt , and t.  hoffman , eds . mit press , cambridge , 11451152 .",
    "tweedie , m. c.  k. and veevers , a. ( 1968 ) .",
    "the inversion of cumulant operators for power - series distributions , and the approximate stabilization of variance by transformations .",
    "_ j. am . statist",
    "_  _ 63 _ , 321328 .",
    "willett , r. ( 2007 ) .",
    "multiscale analysis of photon - limited astronomical images . in _",
    "statistical challenges in modern astronomy iv _ ,",
    "g.  j. babu and e.  d. feigelson , eds . vol .  *",
    "371 * of the astronomical society of the pacific conference series ."
  ],
  "abstract_text": [
    "<S> the ubiquity of integrating detectors in imaging and other applications implies that a variety of real - world data are well modeled as poisson random variables whose means are in turn proportional to an underlying vector - valued signal of interest . in this article , </S>",
    "<S> we first show how the so - called skellam distribution arises from the fact that haar wavelet and filterbank transform coefficients corresponding to measurements of this type are distributed as sums and differences of poisson counts . </S>",
    "<S> we then provide two main theorems on skellam shrinkage , one showing the near - optimality of shrinkage in the bayesian setting and the other providing for unbiased risk estimation in a frequentist context . </S>",
    "<S> these results serve to yield new estimators in the haar transform domain , including an unbiased risk estimate for shrinkage of haar - fisz variance - stabilized data , along with accompanying low - complexity algorithms for inference . </S>",
    "<S> we conclude with a simulation study demonstrating the efficacy of our skellam shrinkage estimators both for the standard univariate wavelet test functions as well as a variety of test images taken from the image processing literature , confirming that they offer substantial performance improvements over existing alternatives . </S>"
  ]
}