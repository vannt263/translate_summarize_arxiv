{
  "article_text": [
    "in many social , biological , and technological networks , nodes have underlying attributes or variables that are correlated with the network s topology .",
    "blogs tend to link to other blogs with similar political views  @xcite . in vertebrate food webs ,",
    "predators tend to eat prey whose mass is smaller , but not too much smaller , than their own  @xcite .",
    "networks of word adjacencies are correlated with those words parts of speech  @xcite . in the internet ,",
    "different types of service providers form different kinds of links based on their capacities and business relationships  @xcite  and so on .",
    "there has been a great deal of work on efficient algorithms for community detection in networks ( see  @xcite for reviews ) .",
    "however , most of this work defines a `` community '' as a group of nodes with high density of connections within the group and a low density of connections to the rest of the network . while this type of _ assortative _ community structure is common in social networks , we are interested in a more general definition of _ functional _ community  a group of nodes that connect to the rest of the network in similar ways .",
    "a set of predators might form a functional group in a food web , not because they eat each other , but because they eat similar prey . in english",
    ", nouns often follow adjectives , but seldom follow other nouns .",
    "even some social networks have _ disassortative _ structure where pairs of nodes are more likely to be connected if they are from different classes . for example",
    ", some human societies are divided into moieties , and only allow marriages between different moieties  @xcite .",
    "we consider a setting where the topology of the network is known , but the class labels of the nodes are not",
    ". this could be the case , for instance , if we have a network of blogs and hyperlinks between them ( like citations , trackbacks , blogrolls , etc . ) and we are trying to classify the blogs according to their political leanings .",
    "another possible application is in online social networks , where friendships are known and we are trying to infer hidden demographic variables .",
    "this problem is sometimes referred to as collective classification  @xcite . however , in that work the focus is on classification of individual nodes .",
    "in contrast , our focus is on the discovery of functional communities in the network , and our underlying generative model is designed around the assumption of that these communities exist .",
    "we make no initial assumptions about the structure of the network  for instance , whether its groups are assortative , disassortative , or some mixture of the two .",
    "we assume that we can learn the label of any given node , but at a cost , say in terms of work in the field or laboratory .",
    "our goal is to identify a small subset of nodes such that , once we explore them and learn their labels , we can accurately predict the labels of all the others .",
    "we present a general approach to this problem .",
    "our algorithm uses information - theoretic measures to decide which node to explore next  that is , which one will give us the most information about the rest of the network .",
    "we start with a probabilistic generative model of the network , called a _ stochastic block model _",
    "@xcite , in which groups connect to each other according to a matrix of probabilities .",
    "this model allows an arbitrary mixture of assortative and disassortative structure , as well as directed links from one group to another , and has been used to model networks in many fields  ( e.g. @xcite ) .",
    "we stress , however , that our approach could be applied equally well to many other probabilistic models , such as those where nodes belong to a mixture of classes  @xcite , a hierarchy of classes and subclasses  @xcite , locations in a latent geographical or social space  @xcite , or niches in a food web  @xcite .",
    "it could also be applied to degree - corrected block models such as those in  @xcite , which treat the nodes degrees as parameters rather than data to be predicted .    at each stage of the learning process ,",
    "some of the nodes labels are already known and we need to decide which node to explore next .",
    "we do this by estimating , for each node , the mutual information between its label and the joint distribution of all the others labels , conditioned on the labels of the nodes that are known so far .",
    "we obtain this estimate by gibbs sampling , giving each classification of nodes a probability integrated over the parameters of the block model .",
    "we then explore the node for which this mutual information is largest .    a key fact about the mutual information , which we argue is essential to our algorithm s performance ,",
    "is that it is not just a measure of uncertainty : it is a combination of uncertainty about a node s label and the extent to which it is correlated with the labels of other nodes .",
    "thus the algorithm explores nodes which maximize the expected amount of information it will gain about the entire network .",
    "it skips nodes whose labels seem obvious to it , or which are uncertain but have little effect on other nodes . in an assortative network , for instance , it starts by exploring nodes which are central to their communities , and then explores nodes along the boundaries between them , without being told in advance to pursue this strategy .",
    "we also present an alternate approach which maximizes a quantity we call the _",
    "average agreement_. for each node @xmath0 , this is the average number of nodes at which two independent samples of the gibbs distribution agree , conditioned on the event that they agree at @xmath0 . like mutual information ,",
    "average agreement is high for nodes that are highly correlated with the rest of the network .",
    "a similar idea ( but not applied to networks ) is present in  @xcite .",
    "we test our algorithm on three real - world networks : the social network of a karate club , a network of common adjacent words in a charles dickens novel , and a marine food web of species in the antarctic .",
    "each of these networks is curated in the sense that we possess the correct node labels , such as the faction of the social network each individual belongs to , the part of speech of each word , or the part of the habitat each species lives in .",
    "we judge our algorithm according to how accurately it predicts the labels of the unexplored nodes , as a function of the number of nodes it has explored so far .",
    "we also compare our algorithm with several simple heuristics , such as exploring nodes based on their degree or betweenness centrality , and find that it significantly outperforms them .",
    "the idea of designing experiments by maximizing the mutual information between the variable we learn next and the joint distribution of the other variables , or equivalently the expected amount of information we gain about the joint distribution , has a long history in statistics , artificial intelligence , and machine learning , e.g.  mackay  @xcite and guo and greiner  @xcite .",
    "indeed , it goes back to the work of lindley  @xcite in the 1950s .",
    "however , to our knowledge this is the first time it has been coupled with a generative model to discover hidden variables in networks .    in recent work , zhu ,",
    "lafferty , and ghahramani  @xcite study active learning of node labels using gaussian fields and harmonic functions defined using the graph laplacian . however , this technique only applies to networks where neighboring nodes are likely to be in the same class  that is , networks with assortative community structure .",
    "in contrast , our techniques are capable of learning about much more general types of network structure , including disassortative and directed relationships between functional communities .    another approach to active learning of node labels",
    "is found in the work of bilgic and getoor  @xcite and bilgic , mihalkova , and getoor  @xcite , who use collective vector - based classifiers . by properly defining the collective relationships between nodes , both assortative or disassortative communities",
    "can be learned in this framework .",
    "however , our technique differs from theirs by using mutual information as the active learning criterion , which takes into account not just uncertainty , but correlations as well .",
    "additional works by goldberg , zhu , and wright  @xcite and tong and jin  @xcite also perform semi - supervised learning on graphs , and handle the disassortative case .",
    "but they work in a setting where they know , for each link , if the ends should have the same or different labels , such as if one writer quotes another with pejorative words .",
    "in contrast , we work in a setting where we have no such information : only the topology is available to us , and there are no signs on the edges telling us whether we should propagate similar or dissimilar labels .",
    "we represent our network as a directed graph @xmath1 with @xmath2 nodes .",
    "we assume that there are @xmath3 classes of nodes , so that each node @xmath0 has a class label @xmath4 .",
    "we are given the graph @xmath5 , and our goal is to learn the labels @xmath6 . to do this , we assume that @xmath5 is generated by a probabilistic model , in which its topology is correlated with these labels .    the simplest such model , although by no means the only one to which our methods could be applied , is a stochastic block model  @xcite .",
    "it assumes that for each pair of nodes @xmath7 , there is an edge from @xmath8 to @xmath0 with a probability @xmath9 that depends only on their labels , and that these events are independent .",
    "given a classification , i.e. , a function @xmath10 assigning a label to each node , the probability of generating a given graph @xmath5 in this model is @xmath11 here @xmath12 is the number of nodes of class @xmath13 , and @xmath14 is the number of edges from nodes of class @xmath13 to nodes of class @xmath15 .",
    "if we wish to focus on undirected graphs , we can modify this expression by restricting the product over pairs of classes with @xmath16 .",
    "we can also forbid self - loops , if we wish , by replacing @xmath17 in the term @xmath18 with @xmath19 or @xmath20 in the directed or undirected case respectively .",
    "this kind of stochastic block model is well - known in the machine learning , statistics , and network communities  @xcite and has also been used in ecology to identify groups of species in food webs  @xcite . unlike e.g.  @xcite , we do not assume that @xmath21 takes one value when @xmath18 and a smaller value when @xmath22 .",
    "in other words , we do not assume an assortative community structure , where nodes are more likely to be connected to other nodes of the same class .",
    "nor do we require in general that @xmath23 , since the directed nature of the edges may be important  for instance , in a food web or word adjacency network .",
    "if all classifications @xmath24 are equally likely _ a priori _ , then bayes rule implies that the gibbs distribution on the classifications , i.e. , the probability of @xmath24 given @xmath5 , is proportional to the probability of @xmath5 given @xmath24 : @xmath25 in order to define @xmath26 , we need to integrate @xmath27 over some prior probability distribution on @xmath28 .",
    "if we assume that the @xmath21 are independent , then this integral factors over the product  .",
    "in particular , if each @xmath21 follows a beta prior , we have the bayesian estimate of edge probabilities @xmath29 for reasonable choices of the hyperparameters @xmath30 and @xmath31 , the prior dominates only in small data cases , such as very small networks or sparsely populated classes . for such small data cases ,",
    "the beta prior allows the user to input some domain knowledge about , say , the ( dis)assortativity of the target network s community structure . in the limit of large data ,",
    "the prior will wash out and the data - driven community structure will dominate .    if the user wishes to remain agnostic , however , he or she can specify a uniform prior ( @xmath32 ) and allow the learning algorithm to estimate the degree of assortativity , disassortativity , directedness , and so on entirely from the data .",
    "we take this approach in this paper , in which case @xmath33 an even simpler approach is to assume that the @xmath21 take their maximum likelihood values @xmath34 and set @xmath35 .",
    "this approach was used , for instance , for a hierarchical block model in  @xcite . when @xmath3 is fixed and the @xmath36 are large",
    ", this will give results similar to  , since the integral over @xmath28 is tightly peaked around @xmath37 .",
    "however , for any particular finite graph it makes more sense , at least to a bayesian , to integrate over the @xmath21 , since they obey a posterior distribution rather than taking a fixed value .",
    "moreover , averaging over the parameters as in   discourages overfitting , since the average likelihood goes down when we increase @xmath3 and hence the volume of the parameter space .",
    "this gives us a principled way to determine @xmath3 automatically , although in this paper we set @xmath3 by hand .",
    "other methods to determine @xmath3 include minimum description length ( mdl ) techniques  @xcite and the akaike information criterion  @xcite",
    "in the active learning setting , the algorithm can learn the class label of any given node , but at a cost  say , by devoting resources in the laboratory or the field .",
    "since these resources are limited , it has to decide which node to explore .",
    "its goal is to explore a small set of nodes and use their labels to guess the labels of the remaining nodes .",
    "one natural approach is to explore the node @xmath0 with the largest mutual information ( mi ) between its label @xmath6 and the labels @xmath38 of the other nodes according to the gibbs distribution  .",
    "we can write this as the difference between the entropy of @xmath38 and its conditional entropy given @xmath6 , @xmath39 here @xmath40 is the entropy , averaged over @xmath6 according to the marginal of @xmath6 in the gibbs distribution , of the joint distribution of @xmath38 conditioned on @xmath6 .",
    "in other words , @xmath41 is the expected amount of information we will gain about @xmath38 , or equivalently the expected decrease in the entropy , that will result from learning @xmath6 .",
    "since the mutual information is symmetric , we also have @xmath42 where @xmath43 is the entropy of the marginal distribution of @xmath6 , and @xmath44 is the entropy , on average , of the distribution of @xmath6 conditioned on the labels of the other nodes .",
    "thus @xmath41 is large if ( i ) we are uncertain about @xmath0 , so that @xmath43 is large , and ( ii ) @xmath0 is strongly correlated with the other nodes , so that @xmath45 is small .",
    "we estimate these entropies by sampling from the space of classifications @xmath24 according to the gibbs distribution .",
    "specifically , we use a single - site heat - bath markov chain . at each step",
    ", it chooses a node @xmath0 uniformly from among the unexplored nodes , and chooses its label @xmath6 according to the conditional distribution proportional to @xmath26 , assuming that the labels of all other nodes stay fixed .",
    "in addition to exploring the space , this allows us to collect a sample of the conditional distribution of the chosen node @xmath0 and its entropy . since @xmath44 is the average of the conditional entropy , and since @xmath43 is the entropy of the average conditional distribution ,",
    "we can write @xmath46 where @xmath47 is the probability that @xmath48 and @xmath49 denotes the average , according to the gibbs distribution , over the labels of the other nodes .    we offer no theoretical guarantees about the mixing time of this markov chain , and it is easy to see that there are families of graphs and values of @xmath3 for which it it takes exponential time .",
    "however , for the real - world networks we have tried so far , it appears to converge to equilibrium in a reasonable amount of time .",
    "we test for equilibrium by measuring whether the marginals change noticeably when the number of updates is increased by a factor of @xmath50 .",
    "we improve our estimates by averaging over many runs , each one starting from an independently random initial state .",
    "we say that the algorithm is in _",
    "stage @xmath15 _ if it has already explored @xmath15 nodes . in that stage , it estimates @xmath41 for each unexplored node @xmath0 , using the markov chain to sample from the gibbs distribution conditioned on the labels of the nodes explored so far .",
    "it then explores the node @xmath0 with the largest mi .",
    "we provide it with the correct value of @xmath6 from the curated network , and it moves on to the next stage .",
    "the mutual information is not the only quantity we might use to identify which node to explore .",
    "another is the _ average agreement _ , which we define as follows .",
    "given two classifications @xmath51 , define their _ agreement _ as the number of nodes on whose labels they agree , @xmath52 since our goal is to label as many nodes correctly as possible , we wish we could maximize the agreement between an classification @xmath53 , drawn from the gibbs distribution , and the correct classification @xmath54 .",
    "however , the algorithm does nt know @xmath54 , so it assumes that it is drawn from the gibbs distribution as well .",
    "exploring @xmath0 projects onto the part of the joint distribution of @xmath55 where @xmath56 .",
    "so , we define @xmath57 as the expected agreement between two classifications @xmath51 drawn independently from the gibbs distribution , conditioned on the event that they agree at @xmath0 : @xmath58 we estimate the numerator and denominator of @xmath57 using the same heat - bath gibbs sampler as for @xmath41 , except that we sample independent pairs of classifications @xmath55 by starting the markov chain at two independently random initial states .",
    "we tested our algorithms on three different networks from three different fields .",
    "the first is zachary s karate club  @xcite . as shown in fig .",
    "[ fig : karate ] , this is a social network consisting of @xmath59 members of a karate club , where undirected edges represent friendships .",
    "the club split into two factions , indicated by diamonds and circles respectively .",
    "one of them centered around the instructor ( node 1 ) and the other around the club president ( node 34 ) , each of which formed their own club .",
    "shaded nodes are more peripheral , and have weaker ties to their communities .",
    "this network is highly assortative , with a high density of edges within each faction and a low density of edges between them .",
    "we judge the performance of each algorithm by asking , at each stage and for each node , with what probability the gibbs distribution assigns it the correct label . in each stage",
    "we sampled the gibbs distribution using @xmath60 independently chosen initial conditions , doing @xmath61 steps of the heat - bath markov chain for each one , and computing averages using the last @xmath62 steps . increasing the number of markov chain steps to @xmath63 per stage produced only marginal improvements in performance .",
    "[ fig : learnkarate ] shows what fraction of the unexplored nodes are assigned the correct label with probability at least @xmath64 , for various thresholds @xmath65 , as a function of the stage @xmath15 .",
    "after exploring just four or five nodes , both of our algorithms succeed in correctly predicting the labels of most of the remaining nodes  i.e . , to",
    "which faction they belong  with high accuracy .",
    "the aa algorithm performs slightly better than mi , achieving an accuracy close to @xmath66 after exploring nine nodes .",
    "of course , the karate club network is quite small , and there are many community - finding algorithms that classify the two factions with perfect or near - perfect accuracy  @xcite .",
    "perhaps more interesting is the _ order _ in which our algorithms choose to explore the nodes . in fig .",
    "[ fig : explorekarate ] , we sort the nodes in order of the median stage at which they are explored .",
    "error bars show @xmath67 confidence intervals over @xmath60 independent runs of each algorithm .",
    "some nodes show a large variance in the stage in which they are explored , while others are consistently explored at the beginning or end of the process .",
    "both algorithms start by exploring nodes @xmath68 and @xmath59 , which are central to their respective communities .",
    "note that these nodes are chosen , as we argued above , not just because their labels are uncertain , but because they are highly correlated with the labels of other nodes .",
    "after learning that nodes @xmath68 and @xmath59 are in class @xmath68 and @xmath50 respectively , the algorithms `` know '' that the network consists of two assortative communities .",
    "they they explore nodes such as 3 , 9 , and 10 which lie at the boundary between these communities .",
    "once the boundary is clear , they can easily predict the labels of the remaining nodes .",
    "the last nodes to be explored are those such as @xmath50 , @xmath69 , and @xmath70 , which lie so deep inside their communities that their labels are not in doubt .",
    "the second network consists of the 60 most commonly occurring nouns and the 60 most commonly occurring adjectives in charles dickens novel _",
    "david copperfield_. a directed edge connects any pair of words that appear adjacently in the text , pointing from the preceding word to the following one .",
    "excluding eight words which are disconnected from the rest leaves a network with 112 nodes  @xcite . unlike zachary s karate club , this network is both directed and highly disassortative . of the 1494 edges , 1123 of them point from adjectives to nouns",
    "this lets us classify most nodes early on , simply by labeling a node as an adjective or noun if its out - degree or in - degree is large .",
    "accordingly , our algorithms focus their attention on words about which they are uncertain , like `` early , '' `` low , '' and `` nothing , '' whose out - degrees and in - degrees in the text are roughly equal , and words like `` perfect '' that precede words of both classes ( see fig .  [",
    "fig : explorewords ] , where green and yellow nodes represent nouns and adjectives respectively ; rectangular nodes are explored first , and elliptical ones last ) . once these nodes are resolved , both algorithms achieve high accuracy@xmath71 accuracy after exploring 20 nodes and close to @xmath66 after exploring 65 nodes ( see fig .  [",
    "fig : learnword ] ) .",
    "+        in each stage we sampled the gibbs distribution using @xmath60 independently chosen initial conditions , doing @xmath72 steps of the heat - bath markov chain for each one , and computing averages using the last @xmath73 steps . increasing the number of markov chain steps to @xmath63 per stage produced only marginal improvements in performance . as in fig .",
    "[ fig : learnkarate ] , the @xmath74-axis shows the fraction of unexplored nodes which are labeled correctly by the conditional gibbs distribution with probability at least @xmath64 , for @xmath65 .",
    "the performance of the two algorithms is similar in the later stages , but unlike the karate club , here mi performs noticeably better than aa in the early stages .",
    "the third network is a food web of @xmath75 species in the weddell sea in the antarctic  @xcite , with edges pointing to each predator from its prey .",
    "this data set is very rich , but we focus on two particular variables  the feeding type and the habitat in which the species lives .",
    "the feeding type takes @xmath76 values , namely primary producer , omnivorous , herbivorous / detrivorous , carnivorous , detrivorous , and carnivorous / necrovorous .",
    "the habitat variable takes @xmath77 values , namely pelagic , benthic , benthopelagic , demersal , and land - based .",
    "we show results of our algorithms for both variables in fig .",
    "[ fig : learnfoodweb ] .",
    "the results are averaged over 100 runs of each algorithm . in each stage",
    "we sampled the gibbs distribution using @xmath60 independently chosen initial conditions , doing @xmath72 steps of the heat - bath markov chain for each one , and computing averages using the last @xmath73 steps .",
    "for the feeding type , after exploring half the nodes , both algorithms correctly label about @xmath78 of the remaining nodes . for the habitat variable ,",
    "both algorithms are less accurate , although aa performs somewhat better than mi .",
    "note that the accuracy only includes the unexplored nodes , not the nodes we have already explored .",
    "thus it can decrease if we explore easily - classified nodes early on , so that hard - to - classify nodes form a larger fraction of the remaining ones .",
    "[ fig : learnfoodweb ] shows that both algorithms get to a state where they are confident , but wrong , about many of the unexplored nodes . for the feeding type variable , for instance ,",
    "after the aa algorithm has explored @xmath79 species , it labels @xmath78 of the remaining nodes correctly with probability @xmath67 , but it labels the other @xmath80 correctly with probability less than @xmath81 . in other words , it has a high degree of confidence about all the nodes , but is wrong about many of them .",
    "its accuracy improves as it explores more nodes , but it does nt achieve high accuracy on all the unexplored nodes until there are only about @xmath82 of them left .",
    "why is this ?",
    "we argue that the fault lies , not with our learning algorithms and the order in which they explore the nodes , but with the stochastic block model and its ability to model the data .",
    "for example , for the habitat variable , these algorithms perform well on pelagic , demersal , and land - based species .",
    "but the benthic habitat , which is the largest and most diverse , includes species with many feeding types and trophic levels .",
    "these additional variables have a large effect on the topology , but they are not taken into account by the block model . as a result ,",
    "more than half the benthic species are mislabeled by the block model in the following sense : even if we condition on the correct habitats of _ all _ the other species , the species most likely habitat is pelagic , benthopelagic , demersal , or land - based .",
    "specifically , 219 of the 488 species are mislabeled by the most likely block model , @xmath83 of them with confidence over @xmath84 .",
    "of course , we can also regard our algorithms mistakes as evidence that these habitat classifications are not cut and dried .",
    "indeed , ecologists recognize that there are `` connector species '' that connect one habitat to another , and belong to some extent to both .",
    "to test our hypothesis that it is the block model s inability to model the data that causes some nodes to be misclassified , we artificially modified the data set to make it consistent with the block model .",
    "starting with the nodes original class labels , we updated the habitat of each species to its most likely value according to the block model , given the habitats of all the other species .",
    "after iterating this process six times , we reached a fixed point where each species habitat is consistent with the block model s predictions . on this synthetic data set both of our learning algorithms perform perfectly , predicting the habitat of every species with close to @xmath66 accuracy after exploring just @xmath85 of them .    more generally , it is important to remember that the topology of the network is only imperfectly correlated with the nodes types .",
    "zachary  @xcite relates that one of members of the karate club joined the instructor s faction even though the network s topology suggests that he was more strongly connected to the president .",
    "the reason is that he was only three weeks away from a test for his black belt when the split occurred .",
    "he had already invested four years learning the instructor s style of karate , and if he had joined the president s club he would have had to start over with a white belt . in any real - world network , there is information of this kind that is not reflected in the topology and which is hidden from our algorithm .",
    "if a node is of a given class for idiosyncratic reasons like these , we can not expect any algorithm based solely on topology and the other nodes class labels  no matter how sophisticated a probabilistic model we use  to correctly classify it .",
    "+        we compared our active learning algorithms with several simple heuristics .",
    "these include exploring the node with the highest degree in the subgraph of unexplored nodes , exploring the node with the highest betweenness centrality ( the fraction of shortest paths that go through it , see  @xcite ) in the subgraph of unexplored nodes , and exploring a node chosen uniformly at random from the unexplored ones .",
    "we judge the performance of these heuristics using the same gibbs sampling process as for mi and aa .    in fig .",
    "[ fig : compare ] , we show the results of these heuristics at the @xmath84 accuracy threshold on all three networks , including both the habitat and feeding type variables in the food web . on zachary s karate club ( left ) our algorithms outperform these heuristics consistently . in the _ david copperfield _",
    "network ( right ) , the highest - degree and highest - betweenness heuristics enjoy an early lead , but quickly hit a ceiling and are surpassed by mi and aa .",
    "for the weddell sea food web ( bottom ) , the highest - degree and highest - betweenness heuristics perform poorly throughout the learning process .",
    "one reason for this is that many nodes with high degree or high betweenness are easy to classify from the labels of their neighbors . by exploring these nodes first , these heuristics leave themselves mainly with hard - to - classify nodes .",
    "the random - node heuristic performs surprisingly well early on , but all three heuristics are worse than mi or aa once they have explored half the nodes .",
    "active learning , using mutual information or average agreement coupled with a generative model , offers a new approach to analyzing networks where the topology is known , but knowledge of class labels is incomplete and costly to obtain .",
    "we have shown for three networks , one social , one lexical , and one biological , that our algorithms do a good job of predicting the labels of unexplored nodes after exploring a relatively small fraction of the network , correctly recognizing both assortative and disassortative functional communities .",
    "certainly not all networks are well - described by the simple block model we use here , but our approach can be generalized to probabilistic network models which take information on the nodes locations or degrees into account .",
    "we are grateful to joel bader , aaron clauset , jennifer dunne , nathan eagle , brian karrer , jon kleinberg , mark newman , cosma shalizi , and jerry zhu for helpful conversations , and to ute jacob for the weddell sea food web data .",
    "r. is also grateful to the santa fe institute for their hospitality .",
    "this work was supported by the mcdonnell foundation .",
    "u.  brose , l.  cushing , e.  l. berlow , t.  jonsson , c.  banasek - richter , l.  f. bersier , j.  l. blanchard , t.  brey , s.  r. carpenter , m.  f. blandenier , et  al .",
    "body sizes of consumers and their resources . , 86(9):25452545 , 2005 .",
    "x.  zhu , j.  lafferty , and z.  ghahramani . combining active learning and semi - supervised learning using gaussian fields and harmonic functions . in _ proc .",
    "icml-2003 workshop on the continuum from labeled to unlabeled data _ , 2003 ."
  ],
  "abstract_text": [
    "<S> in many real - world networks , nodes have class labels , attributes , or variables that affect the network s topology . </S>",
    "<S> if the topology of the network is known but the labels of the nodes are hidden , we would like to select a small subset of nodes such that , if we knew their labels , we could accurately predict the labels of all the other nodes . </S>",
    "<S> we develop an active learning algorithm for this problem which uses information - theoretic techniques to choose which nodes to explore . </S>",
    "<S> we test our algorithm on networks from three different domains : a social network , a network of english words that appear adjacently in a novel , and a marine food web . </S>",
    "<S> our algorithm makes no initial assumptions about how the groups connect , and performs well even when faced with quite general types of network structure . </S>",
    "<S> in particular , we do not assume that nodes of the same class are more likely to be connected to each other  only that they connect to the rest of the network in similar ways .    </S>",
    "<S> = 10000 = 10000    * categories and subject descriptors : * i.2.6 [ * artificial intelligence * ] : learning g.2.2 [ * discrete mathematics * ] : graph theory    * general terms : * algorithms , experimentation , theory * keywords : * complex networks , structure and function , community detection , information theory , active learning , collective classification , transductive graph labeling </S>"
  ]
}