{
  "article_text": [
    "in the resolute hunt for transiting hot jupiters , much effort is focused on very small instruments that are capable of observing large area of the sky and gathering data with a photometric precision better than 0.01  mag .",
    "there are many projects targeting this goal ( see horne 2003 ) , using instruments with typical apertures of order 10  cm ; it has even been argued that the small telescope projects with @xmath0  inch diameter optics are the best for this purpose ( pepper , gould & depoy 2003 ) .",
    "the attained photometric precision plays a central role in transit signal detection .",
    "however , the large field of view and the semi - professional ccd detectors often employed by these low - budget projects drastically amplify some of the standard problems of ccd photometry .",
    "these include narrow psf , crowded field , differential extinction and refraction ( see bakos et al .  2004 , hereafter b04 , for a more comprehensive summary ) .",
    "most of the problems become more severe toward fainter magnitudes , where the objects are more affected by time - dependent merging with brighter stars .",
    "most of these , and other hidden effects not only increase the noise of the light curves , but leave their fingerprint in the data as systematic variations , because they vary in a non - smooth fashion over the field , and standard position - dependent smooth transformations applied at various stages of the data reduction do not eliminate them perfectly .",
    "the efficiency of the detection of periodic signals drops dramatically when the light curves become dominated by noise _ and _ systematic variations .",
    "for example , the bls method ( kovcs , zucker & mazeh 2002 , hereafter k02 ) , an application used for searching for transits , is efficient on light curves exhibiting a box - shaped dip , but fails to recover transits superposed on strongly variable light curves .",
    "these systematics are also harmful in discovering interesting low - amplitude phenomena , such as @xmath1  scuti or @xmath2  dor stars .",
    "many of the systematic variations in a given light curve are shared by light curves of other stars in the same data set , due to common effects like colour - dependent extinction , or blending of two or more star images ( which could produce similar light curve variations in all of them ) , etc . a solution to remove or reduce these common systematic variations",
    "can therefore be devised using the already reduced data . for each target star",
    ", one must identify objects in the field that suffer from the same kind of systematics as the target , and apply some kind of optimum filtering of the target light curve based on the light curves of a set of comparison / template stars .    the algorithm to be presented in this paper",
    "can be applied to two types of problems .",
    "the first application is to remove trends from trend- and noise - dominated time series , thereby increasing the probability of detecting a weak signal ( periodic or non - periodic ) .",
    "secondly , if there _ is _ a periodic signal present , the tfa algorithm can be used in a slightly different way to reconstruct also the shape of that signal .",
    "the structure of the paper is the following .",
    "section 2 gives a more detailed description of the systematics and their possible causes .",
    "section 3 describes the mathematical formulation of the tfa algorithm , and section 4 presents a number of tests of its ability to remove spurious trends from the data .",
    "section 5 explores the increase in detectability of periodic transit signals ( using the bls algorithm ) from data after processing with the tfa .",
    "section 6 then investigates the capability of reconstructing the detailed shape and amplitude of such periodic signals , using a variant of the basic algorithm .",
    "the paper closes with a brief highlighting of the most important results . throughout this paper",
    "we rely on the database of the hatnet project ( see b04 ) .",
    "the systematic variations might be intrinsic to the data , or they could be due to uncorrected instrumental effects or changing observing conditions , or they could also originate from imperfect data reduction .",
    "first we outline the procedure of common photometry reduction methods along with their smooth transformations that correct for trivial systematic variations .",
    "then we proceed to the characterization of the remaining systematics , and discuss them and their possible causes through the examples of the hat network light curves .    the typical procedure of wide field photometry either employs flux extraction with aperture - photometry or point spread function ( psf ) fitting ( e.g. , daophot ; stetson 1987 ) , or uses image subtraction ( isis ; alard & lupton 1998 ; alard 2000 ) .",
    "in the first type of approach , the instrumental magnitudes of individual frames are transformed to a common magnitude reference system , in order to eliminate the instrumental or observational changes between the epochs . for narrow field surveys ,",
    "all stars experience the same fractional flux change , and thus the transformation can be treated as a constant magnitude shift with good approximation .    for wide - field surveys",
    ", this transformation takes a more complex form , and for convenience it is assumed to be smooth function of the fitting parameters , e.g. , of the co - ordinates .",
    "the transformation is established by iterative fitting over a substantial sample of stars and subsequent rejection of outlier values .",
    "the underlying assumption in this procedure is that ccd images of typical surveys have a large number of stars , and the overwhelming majority of them are non - variable above the noise - level ( see pojmaski 2003 ) .",
    "we note in passing that other wide field surveys use similar methods in their basic reduction pipelines .",
    "ideally , after applying the above determined transformation , the resulting light curves should be free of systematic variations , and constant stars should be dominated only by noise .",
    "however , omission of some `` hidden '' parameters , characteristic of the transformation , might lead to systematic spurious variations in the transformed magnitudes ; sources with close values of these parameters will exhibit similar variations .",
    "improper functional form of the transformation , or inclusion of variable stars in the fit might lead to similar systematics .",
    "furthermore , because local effects might dominate the light curves ( local in position or other parameters ) , variations remain even after application of the best large scale ( smooth ) transformations .",
    "such systematics are known to exist in various massive photometric surveys ( see , e.g. , drake & cook 2004 for the macho and kruszewski & semeniuk 2003 for the ogle projects ) and even in classical ccd observations ( makidon et al .",
    "2004 ) , but in wide field observations they could be especially severe ( alonso et al .",
    "2003 ) .    to give examples ,",
    "a time - dependent psf causes variable merging , where the flux contribution of a star to the flux of another star and its background annulus varies ( assuming aperture photometry ) . the extent of systematics induced will depend on the exact configuration of the neighbourhood of the source .",
    "although image subtraction convolves the profiles of the reference frame before the subtraction so that they have ( in principle ) the same width as on the frame that is analysed , we found that there remain small amplitude correlations with the periodic variation of original psf widths .",
    "periodic motion of stars across the imperfectly corrected pixels , hot - pixels or bad columns , or simply the gate - structure of front - illuminated pixels can be another cause for systematic variations .",
    "faint stars that fall in the vertical vicinity of stars that are on the saturation limit might be periodically affected by the saturation of the bright source , e.g. , with the @xmath3 period of moon - cycle through the increased background , or by the nightly variation of extinction , as the object rises and sets .",
    "here and throughout the paper we employ the database on the moderately crowded ( @xmath4 ) g175 field observed by hatnet .",
    "similar results were obtained with other fields .",
    "observations for g175 were made during the fall and winter of 2003 , spanning a compact interval of 202  d with @xmath5 data points for each variable in @xmath6-band .",
    "nearly 10000 stars down to @xmath6=12 were analysed with aperture photometry from the field .",
    "we employed a 4th order polynomial function of the x and y coordinates to fit each frame s magnitude system to that of the reference frame .",
    "@xmath7-band data were also taken on selected nights to have complementary colour information on the sources , but this was not incorporated in the above fits .",
    "field g175 observations started or ended every night whenever the field crossed the 35@xmath8  horizon , and exposures were taken with 5  min resolution with no interruption by observations of another field .",
    "there is obviously a ( close to sidereal ) daily periodicity in the time - base , which has 48  hour long sections , and 16 hour or longer gaps .",
    "although the field contains nearly 10000 photometered stars , we present tests on only the 4293 stars , among the 5000 brightest , whose light curve contains at least 2800 points .",
    "these bright , intensively observed and accurately photometered stars are the most interesting ones for shallow transit searches",
    ". the faintest stars in this sample have @xmath9  mag .    after discrete fourier transformation ( dft ) of the light curves in the @xmath10$]d@xmath11 frequency range with 20000 frequency steps ,",
    "the derived histogram of primary frequencies shows a distribution with high peaks around @xmath12  d@xmath11 frequencies , where @xmath12 is a small integer .",
    "the histogram also shows that the 1 and 2d@xmath11 peaks have double structures , with slight offsets from the exact integer values ( see fig .  1 ) .",
    "the double peak structure is attributed to the cadence of 1 sidereal day of the observations and its alias .",
    "other , higher frequency peaks do not show double structure , only an offset , because they are further off from their alias counterparts leaking from the negative frequency regime . a very large fraction ( 83% ) of the peak frequencies",
    "fall in the @xmath13  d@xmath11 interval , with @xmath140,1,2,3,4,5 . even excluding the n=0 peak to avoid counting long - periodic variables as the stars showing real systematics ,",
    "the occurrence rate of integer peak frequencies is still 69% .",
    "weighting the histogram according to the signal - to - noise ratio of the frequency peaks does not significantly alter its appearance .",
    "% over the full frequency range is equal to 100 . _",
    "small panels : _ blow - ups of the neighbourhood of the peaks .",
    "each bin has a width of @xmath15d@xmath11 in all panels .",
    "[ fig : dfthist],width=321 ]    d period and arbitrary epochs .",
    "[ fig : sys],width=321 ]    i vs.  v system ( small dots ) with stars exhibiting strong 1d@xmath11 ( filled boxes ) or 2d@xmath11 ( open circles ) systematics overplotted .",
    "[ fig : cmd],width=302 ]    ) and boxes ( 2d@xmath11 ) .",
    "north is up , east is left , image size is approx .",
    "white vertical lines are due to bad ccd columns .",
    "most of the 1d@xmath11 stars are merging with neighbours .",
    "the bright star marked as `` a '' is on the saturation limit , and might induce the systematic variations seen in the stars south from it .",
    "the open cluster ngc2281 ( marked as `` b '' ) is moderately crowded with our 14pixel - scale , and the merging contributes to the 1d@xmath11 or 2d@xmath11 systematics for some of its stars .",
    "nevertheless , there are unexplained cases where isolated stars also show systematic variations , such as `` c '' or `` d '' . [ fig : image],width=302 ]    the systematic variations are of small amplitude , typically @xmath16  mag . to have a better measure on this quantity ,",
    "we derived folded and phase - binned light curves ( with 100 bins ) , rejected the lowest and highest 5 points of the phased curve , and determined the amplitude .",
    "for instance , the median value of the amplitudes of the 1d@xmath11 stars is @xmath17  mag , with 85% of them falling below @xmath18  mag . for illustration , in fig .  2 we exhibit examples of daily trends for a few selected stars in our field .",
    "we searched the observational parameters of hat for commensurate periodicities the effect of which might get superposed on the data and cause the above mentioned systematics .",
    "the trivial daily hour - angle or zenith - distance variation , and the fact that we employ a simple 4th order polynomial transformation that neglects colour dependence suggested that colour - dependent differential extinction should also cause a daily periodicity : redder or bluer than average stars should deviate from others as the field rises or sets .",
    "probably because our data are dominated by other systematics , we found no sign of this when plotting the distribution of higher amplitude @xmath12  d@xmath11 stars on a @xmath19 vs. @xmath7 colour - magnitude diagram ( see fig .",
    "however , we noticed that the psf also varies with close to 1d@xmath11 , which should result in variable merging .",
    "indeed , as shown in fig .  4 ,",
    "the most prominent systematic variations are exhibited by stars that have close - by merging or almost saturated companions .",
    "on the other hand , there remain a few perplexing stars that seem equally merging , but show no strong @xmath12  d@xmath11 variations .",
    "early image subtraction results on another field show slightly smaller occurrence of integer cycle - per - day systematics as compared to aperture photometry , which suggest that merging indeed plays a central role . using more accurate crowded - field photometry , which takes into account the variable stellar profiles , the extent of systematics is somewhat suppressed",
    ". there is also sign for slight increase of the occurrence of systematics in the proximity of bad columns . in conclusion , the degree and the appearance of the systematics depend on many factors ( position , colour , brightness , merging ) , among which merging is probably the most important in our case , but not the only one .",
    "in this section we give a description of the algorithm in two steps .",
    "the first subsection outlines the method and highlights basic problems to be dealt with , whereas the second one reveals more technical details .",
    "first of all , it is important to mention that the simplest and seemingly the most general approach to trend filtering would be the application of high - pass filtering on each daily track of observation . in this case with a low - order polynomial or spline fitting we would filter out any variation occurring on a daily time base , presuming that the order of the polynomial ( or that of the spline ) is properly set . although we experimented with this approach at the beginning of our tests , we did not find it satisfactory for several reasons : ( i ) although the daily trends may be the strongest ones , other time scales play a role too ; ( ii ) it is unclear what parts of the variation come from the trend and from the true change in the object ; ( iii ) short tracks of observations may not be treated well in this way at all , because of the increasing chance of mixing intrinsic and systematic variations .",
    "the idea of tfa is based on the observation that in a large photometric database there are many stars with similar systematic effects ( this is why they are called ` systematics ' ) . as we discussed in the previous section",
    ", various systematics may be present in the individual objects .",
    "we assume that the sample size is large enough for allowing us to select a representative set for all the possible systematics .",
    "once this subsample ( _ template set _ ) is selected , one may try to build up a filter function from these light curves and subtract systematics from the other , non - template light curves .",
    "the first question is how to choose the template set . because of the lack of a priori information on the type of systematics influencing our target , selection of the template set follows only some very broad guidelines and constitutes basically a random set , drawn from the available database .",
    "more details on the template selection are given in section 3.2 .",
    "the second question that must be addressed is how to choose the filter function .",
    "since we have no a priori knowledge on the functional form of the systematics , we take the simplest form of it , i.e. , the _ linear combination _ of the template light curves .    the third question is how to choose the weights of the template light curves in the filter function . if we assume that the variation in all light curves is caused only by systematics , a natural choice would be a simple least squares criterion for the residuals ( observed minus filter - predicted ) . since  as we mentioned in sec .",
    "2  most of the stars are non - variable , the criterion of minimum variance seems to be a good one for most of the observed stars .",
    "the fourth question is what distortion the tfa process causes in the signal being sought .",
    "it is clear that the signal will suffer from some distortion that can be very severe if the time scale and phase of its variation are close enough to those of some of the template time series .    in view of the above considerations",
    ", tfa is designed to tackle two types of problems :    ( a ) : :    _ increase the detection probability _ by filtering out trends from the    trend- and noise - dominated signals .",
    "( b ) : :    _ restore the signal form _ by filtering out trends iteratively from    _ periodic _ signals , assuming that the period is known .",
    "if the trends are sufficiently small ( as compared to the signal amplitude ) , tfa processing is not necessary for the signal search ( i.e. , period analysis , application ( a ) ) , but ( b ) can still be a useful utility if the signal turns out to be periodic .",
    "the fifth question is whether the method generates unwanted signal components by chance inclusion of variables in the template set . in classical variable star observations",
    "special care was taken to avoid variables among the comparison stars .",
    "this was necessary to do so , because variable star magnitudes were obtained by simply subtracting the directly observed magnitudes of the variable star from those of the comparison stars . in the case of tfa",
    "the situation is very different .",
    "here we create a linear combination of all template light curves which fits to the target light curve in the best way .",
    "this approach tends to fit features that appear in similar forms and in proper timings both in the target and in one or more of the template light curves . because of the low likelihood this to happen for non - systematic variations , variables in the template set",
    "are not expected to influence the tfa filtering .",
    "more specifically , templates , containing pure sinusoidal signals will not generate detectable artificial signals in a target of pure white noise ( see appendix a ) . of course ,",
    "this result , referring to the statistical average of the signal detection parameter , does not exclude rare false signal detections due to statistical fluctuations .",
    "let us assume that all time series are sampled in the same moments and contain the same number of data points @xmath20 .",
    "let our filter be assembled from a subset of @xmath21 time series ( this is the template set , the method of selection will be discussed later ) .",
    "the filter \\{@xmath22 } is built up from the following linear combination of the template time series \\{@xmath23 } @xmath24 it is assumed that the template time series are zero - averaged ( i.e. , @xmath25 for all @xmath26 ) .",
    "the coefficients \\{@xmath27 } are determined through the minimization of the following expression : @xmath28 ^ 2 \\hskip 2 mm .\\end{aligned}\\ ] ] here \\{@xmath29 } stands for the target time series being filtered , and \\{@xmath30 } denotes the current best estimate of the _ detrended _ light curve , defined in the following way .    in application ( a )",
    "( _ frequency analysis _ ) , we start from the assumption that the time series is dominated by systematics and noise , and have no a priori knowledge of any real ( periodic or aperiodic ) signal in the light curve .",
    "consequently , in this case we set \\{@xmath31 } equal to the average of the target time series , i.e. , @xmath32 . as we will see in the following sections , this simple choice of \\{@xmath31 } works very well , except for the rare case when the signal is similar to some of the templates ( this happens usually for signals with long periods  comparable to the length of the total time span ) .",
    "in application ( b ) ( _ signal reconstruction _ ) , we have already established ( from previous analysis of the data ) that the time series contains a periodic signal .",
    "the phase - folded time series can thus be used iteratively to estimate \\{@xmath31}. first , an initial filter is constructed using @xmath33 as above .",
    "the filtered time series \\{@xmath34 } is then phase - folded and binned , then _ re - mapped _ to the original time based to give a new estimate of \\{@xmath31 } , which is in turn fed into equation  ( 2 ) to compute a new set of filter coefficients \\{@xmath27}. the new filter leads to a better determination of \\{@xmath31 } , and the iteration continues until some convergence criterion is satisfied .",
    "further details and examples of signal reconstruction are given in section  6 .",
    "note that the unbiased estimate of the variance of noise of the filtered data can be obtained from the following equation @xmath35 at a more technical level , the main steps of tfa are the following .",
    "( 1 ) : :    select @xmath21 template time series in the _ full _ field ,    distributed nearly uniformly in the field ( presumably ensuring uniform    sampling also in other parameters , e.g. , in colour ) .",
    "since we have no    a priori knowledge on which stars are bona fide variables , the above    selection is almost random , except that stars with low number of data    points , low brightness and high standard deviation are not selected .",
    "although the result is not sensitive to the actual values of the above    limits , it is still better to employ them , in order to avoid any    ( however small ) chance of biasing the target light curve .    nevertheless , for long - periodic target variables there is a higher    chance of finding a template member varying on a similar time scale    with similar phase .",
    "once the template set is selected , it is fixed    throughout the analysis .",
    "( 2 ) : :    define the time base to be used by the filter and target time series .    since in modern automated surveys nearly all photometered stars",
    "have    the same number of data points distributed in the same moments of    time , selection of the uniform time base is made on a subsample of the    template light curves ( containing @xmath36 stars in our    case ) .",
    "we select the time base from the template light curve that    contains the largest number of data points .",
    "occasionally , data points ,    at some moments defined by the template time base , might be missing in    the observed light curve . in these cases",
    "they are filled in with the    average value of that light curve .",
    "( 3 ) : :    compute zero - average template time series by using some criterion for    outlier selection ( in our case a 5@xmath37 clipping ) .",
    "( 4 ) : :    compute normal matrix from the above template time series :    @xmath38 and compute the    inverse of it : \\{@xmath39}. ( 5 ) : :    _ for each light curve _ , compute scalar products of the target and    template time series : @xmath40 here    the modified target time series    \\{@xmath41 } is also assumed to be    free of outliers .",
    "( 6 ) : :    compute solution for \\{@xmath27 } and apply correction    accordingly : @xmath42 the    corrected time series is computed from @xmath43    it is important to make the following comments concerning additional details of the computational implementation .",
    "a significant advantage of the above algorithm is that there is no need to compute the normal matrix for each target separately .",
    "this means only the computation of simple array - array and matrix  array products ( steps 56 above ) . for period search",
    "this is done only once for each star , but for signal reconstruction this is repeated several times ( which is still not too time - consuming ) .",
    "since the template set is fixed , in principle the normal matrix need only be computed once . in practice ,",
    "if the target accidentally coincides with one of the template components , the latter must be eliminated from the normal matrix before computing the filter .",
    "this requires a reshuffling and inverting of the normal matrix , but it should happen fairly rarely , because of the relative low number of template time series ( @xmath44 ) compared to the size of database ( @xmath45 stars ) . the cpu request for the initial setup of a filter with few hundred templates is only a few times slower than a single run of the bls algorithm for transit search .",
    "nevertheless , for large template numbers the extra matrix manipulations increase the execution time substantially .",
    "for example , on a 3ghz commercial pc a full bls analysis of a set of 13000 time series with 2300 data points per time series , 30000 frequency steps per time series and 920 tfa templates required 100 cpu hours .",
    "the cost of the non - tfa analysis of the same dataset was only one fifth of it .",
    "the computer memory required by tfa can be quite large .",
    "this is mostly because of the template set , since it requires the usage of @xmath46 floating point array elements .",
    "inversion of the normal matrix may pose also some numerical problems if @xmath21 is too large , although we have not encountered such problems even for very large @xmath21 such as @xmath47 .",
    "this stability is probably due to the basically uncorrelated noise of the the light curves .",
    "we note that a possible way to decrease the number of templates is to perform a singular value decomposition ( svd , see press et al .",
    "1992 ) and employ only the ` significant ' eigenvectors derived from this decomposition . although we experimented with svd at some point , we decided that a clearcut division of the eigenvectors into ` significant ' and ` non - significant ' ones was not possible .",
    "therefore , the original ` brute force ' , full template set approach was followed .",
    "there is also the question if magnitude or intensity ( flux ) values should be used in the above procedure .",
    "we experimented with both quantities and finally settled at the direct magnitude values , since no definite advantage was observed to result from a conversion to fluxes .",
    "the simplest way to check the most straightforward effect of tfa is to compare the standard deviations of the original and tfa - processed time series .",
    "this comparison , of course , will not tell us if all temporal distortions due to trends have been successfully filtered out or not .",
    "nevertheless , it will at least give us some indication on the efficiency of the method .",
    "the effect of decreasing the standard deviation is displayed in fig .",
    "unbiased estimates of the standard deviations @xmath37 for the tfa runs were computed with the aid of equation  ( 3 ) by using a template number of @xmath48 .",
    "( originally we set @xmath49 , but limitations on the template time series  see section  3.2  lowered this value . a similar statement",
    "is applied to other template numbers used in this paper . )",
    "we see that with the increase of the standard deviation @xmath37(non - tfa ) of the original time series , tfa is likely to introduce significant corrections .",
    "this , as expected , means that toward larger @xmath37(non - tfa ) ( i.e. , at fainter magnitudes ) there are time series that are more affected by systematic errors than most of the brighter stars .",
    "there are relatively sharp upper and lower boundaries in the decrease of the standard deviation .",
    "the existence of the upper boundary at small corrections suggests that _ all _ stars are affected by some ( however small ) systematic errors and tfa is capable of filtering out a substantial part of them .",
    "although tfa also has some side - effects on any real signal in the time series , it suppresses the systematics much more effectively than the signal , as shown by the fact that it leads to a significant increase in detection probability ( see section  5 ) .",
    ", we plotted a horizontal line to indicate the zero correction level .",
    ", width=302 ]    in order to examine the question whether the decrease of the standard deviation has also led to the diminishing of the temporal signatures of the systematics , we frequency analysed the original and tfa - processed light curves .",
    "the bls routine was run on both datasets .",
    "the analysis was performed in the [ 0.01,0.99]d@xmath11 band that covers the period of interest in transit search , but excludes very long periods close to the total time span .",
    "we recall that the bls routine generates several aliases ( subharmonics ) from the daily trends at frequencies of small integer ratios ( see k02 ) .",
    "this effect results in the appearance of several aliases in the frequency band chosen for this test .",
    "therefore , the success of tfa in filtering out systematic periodicities can be judged from the above analysis .    the distribution function of the frequencies of the highest peaks obtained on the original , unfiltered dataset is shown in the upper panel of fig .",
    "the large number of stars affected by the daily trends ( that appears here mostly at @xmath50d@xmath11 ) is somewhat surprising .",
    "actually , it turns out that 24% of the highest peaks fall in the [ 0.49,0.51]d@xmath11 frequency range and about 22% of them appear in the @xmath51d@xmath11 neighbourhood of 0.02 , 0.33 and 0.66d@xmath11 .",
    "it is clear that a simple direct use of the data for transit search would leave a quite substantial part of the sample not utilized because of the domination of trends .",
    "next , the above analysis is repeated by applying tfa .",
    "the result is displayed in the lower panel of fig .",
    "we see that severe aliases due to the daily trends disappeared .",
    "now , as it can be expected for a sample with time series of mostly pure noise , all frequency bins are nearly uniformly occupied .",
    "the remaining fluctuations are all of statistical origin , due to the low number of events falling in the narrow bins .",
    "we note in passing that we performed the above test also on the peak frequencies based on dft spectra . although at low or moderate template numbers we still got some remnants under the 1% level in the frequency distribution around integer frequencies , at high number of templates we got basically a flat distribution at the 0.3% level , very similar to the one we got for the bls spectra .",
    "we recall that 69% of the dft peak frequencies obtained by the non - tfa dft analysis fell in the @xmath52  d@xmath11 neighbourhood of positive integer frequencies .",
    "the sum of the bin occupation number @xmath53% over the full frequency range is equal to 100 .",
    "the same number of data points and templates are used as in fig .",
    "5 . , width=321 ]",
    "we examine the periodic transit detection capabilities of the bls method on the tfa - processed light curves .",
    "this is done with the aid of various test signals generated from the observed time series and synthetic signals .",
    "to each of the 4293 observed , zero - averaged light curve we add the transit signals given in table  1 .",
    "although most of the tests presented in this paper refer to signal # 1 , the other test signals were also utilized in order to check the efficiency of the method for various signal parameters .",
    "most of these parameters correspond to realistic transit configurations , except perhaps for # 5 , where the relative duration of the transit is somewhat too long .    in order to illustrate the signal detection capability after applying tfa , in fig .",
    "7 we exhibit two specifically chosen examples for the extreme improvement one can get for trend - dominated signals . it is obvious that tfa is capable of suppressing a considerable part of the trend without a simultaneous suppression of the periodic signal component .",
    "although the signal also suffers from some amount of suppression , in a very large number of cases this is smaller than the one exerted on the trends .",
    "this , as we will see below , ultimately leads to significantly higher detection rates for tfa - processed signals .",
    ".parameters of the synthetic signals [ cols=\"^,^,^,^,^\",options=\"header \" , ]     finally , in fig .",
    "12 we show two real examples for signal reconstruction from the g175 database . as in all of our examples presented in this section , we used bin averaging applicable for arbitrary - shaped signals .",
    "although these examples are not representative of the overall effect of tfa on the other variables in the database , they clearly show the size of improvement one may get in cases heavily corrupted by systematics .",
    "current studies indicate that the incidence rate of hot jupiters is much lower than it was believed a few years ago ( brown 2003 ) .",
    "although we do not have good observational constraint yet for bright galactic field stars , based on the ogle survey of faint galactic bulge stars and the very low number of positive cases obtained by spectroscopic follow - ups ( alonso et al .",
    "2004 ; pont et al .",
    "2004 , and references therein ) , the predicted low incidence rate could be close to reality .",
    "therefore , it is of prime importance to develop effective methods both for data reduction and for subsequent data analysis .",
    "the goal to be reached by photometric surveys targeting extrasolar planets is twofold : ( i ) to reach photometric accuracy close to the photon noise ; ( ii ) to minimize systematic effects leading to coloured noise and therefore seriously jeopardizing the discovery rate .",
    "although current sophisticated data reduction techniques ( e.g. , differential image analysis by alard & lupton 1998 ; alard 2000 ) may help to reach the near photon noise limit and minimize systematic effects , the latter seems to be never eliminated completely .",
    "systematic effects , usually appearing on a daily timebase , are present even in observations that cover small area of the sky per frame ( macho , ogle ) .",
    "wide field surveys have severe additional disadvantages ( e.g. , narrow psf , strong nonlinearities in the magnitude / position transformations , etc . ) that amplify further the systematic effects and thereby make subsequent data analysis more difficult .    since the appearance of systematics seems to be generic",
    ", it is important to devise a method that is capable of filtering out systematics from the time series photometry in a post - reduction phase .",
    "the reason why such an approach may work is that in standard data reduction pipelines the photometry is done through image processing of snapshots .",
    "therefore , these types of data reduction methods are unable to consider the time series properties of the database .",
    "the trend filtering algorithm ( tfa ) described in this paper takes into consideration the temporal behavior of the data by constructing a linear filter from a template set of time series chosen from the database to be analysed .",
    "our tfa is capable to handle two problems :    ( a ) : :    create optimally filtered time series for frequency analysis ; ( b ) : :    reconstruct periodic signals scrambled by systematics .    in both cases",
    "the optimization of the filter is made in the standard least squares sense . in application ( a ) the signal is assumed to be trend- and noise - dominated , whereas in ( b ) this assumption is not made and the filtered signal is iteratively built up by applying case ( a ) assumption on the residual ( observed minus cycle - averaged ) time series .",
    "tests made on the database of the hatnet project have shown that by the application of tfa the signal detection rate ( the cumulative detection probability  cdp ) increases by up to 0.4 for stars brighter than 11  mag . the improvement in the signal to noise ratio ( snr ) is often spectacular , leading to secure discoveries from signals originally completely hidden in the systematics .",
    "once the period is found , the signal can be reconstructed by applying tfa iteratively as mentioned above .",
    "results presented in this paper indicate that there is a steady increase in cdp and snr even for template numbers above 500 .",
    "this suggests that systematics show up in many different forms and one needs to consider as many of them as possible when targeting the detection of weak signal components .",
    "limitations to very high template numbers are set only by the size of the sample , the number of the data points , statistical and numerical stability and computational power .",
    "a part of this work was done during gk s stay at cfa .",
    "he thanks for the support and hospitality provided by the staff of the institute . thorough review of the paper by the referee is greatly appreciated .",
    "we thank to kris stanek for the useful discussions .",
    "operation of the hatnet at the fred lawrence whipple observatory , arizona , and the submillimeter array , hawaii has been supported by the harvard - smithsonian center for astrophysics .",
    "we are grateful to carl akerlof and the rotse project ( university of michigan ) for the long - term loan of the lenses and ccds used in hatnet",
    ". supports from nasa grant nag510854 and otka grant t038437 are acknowledged .",
    "the purpose of this appendix is to show that templates containing periodic signals do not induce similar components at the level of detection in a pure noise target time series . for simplicity",
    "we discuss only the case for a single template .",
    "the result holds also for arbitrary number of orthogonal templates .",
    "let the target \\{@xmath54 } be equal to a pure gaussian white noise series \\{@xmath55 } with the following properties @xmath56 where @xmath57 denotes the expectation value , @xmath58 is the kronecker delta function , @xmath37 is the standard deviation .",
    "the template is a simple harmonic function in the form of @xmath59 where @xmath60 .",
    "the tfa minimization criterion leads to the following expression for the estimate of the filtered target \\{@xmath61 } @xmath62 it is seen that the amplitude of the induced periodic signal is expected to be very small , because it is computed through the fourier transformation of the noise .    in order to compute the power spectrum of \\{@xmath61 } at arbitrary test frequency @xmath63",
    ", we take the fourier transform of \\{@xmath61}. for the sine and cosine transforms we get @xmath64 where @xmath65 by using the properties of equation ( a1 ) , we get for the expectation value of the power @xmath66 @xmath67 \\hskip 2 mm .\\end{aligned}\\ ] ] by omitting sums of oscillating terms , far from the template frequency @xmath68 we get the well - known result for the average noise power ( see , e.g. , kovcs 1980 ) @xmath69 at the template frequency , with the above assumption on the oscillating terms , we have @xmath70 and @xmath71 .",
    "therefore , we get @xmath72 thus , @xmath73 , which means that tfa ( on the average ) _ does not _ induce extra signal component in the filtered time series ; on the contrary , it ` whitens out ' ( in the statistical sense ) even the pure noise target , resulting in a decrease of a factor of two in the average power at the template frequency .",
    "alard c. , 2000 , a&as , 144 , 363 alard c. , lupton r. 1998 , apj , 503 , 325 alonso r. , belmonte j. a. , deeg h. , brown t. m. , 2003 , in ` scientific frontiers in research on extrasolar planets ' , eds .",
    ": d. deming , s. seager , asp conf .",
    ", 294 , 371 alonso r. , brown t. m. , torres g. et al . , 2004 ,",
    "apj ( letters ) , to be published ( astro - ph/0408421 ) bakos g. , noyes r. w. , kovcs g. , stanek k. z. , sasselov d. d. , domsa i. , 2004 , pasp , 116 , 266 ( b04 ) brown t. m. , 2003 , ap . j. , 593 , 125 drake a. j. , cook k. h. , 2004 , apj , 604 , 379 horne k. , 2003 , in ` scientific frontiers in research on extrasolar planets ' , eds . : d. deming , s. seager , asp conf .",
    "ser . , 294 , 36 kovcs g. , 1980 , ap&ss 69 , 485 kovcs g. , zucker s. , mazeh , t. , 2002 , a&a , 391 , 369 ( k02 ) makidon r. b. , rebull l. m. , storm s. e. , adams m. t. , patten b. m. , 2004 , aj , 127 , 2228 kruszewski a. , semeniuk i. , 2003 , acta astr . , 53 , 241 pepper j. , gould a. , depoy d. l. , 2003 , acta astr . , 53 , 213 pojmaski g. , 2003 , acta astr . , 53 , 341 pont f. , bouchy f. , queloz d. , santos n. c. , melo c. , mayor m. , udry s. , 2004 , a&a ( letters ) , to be published ( astro - ph/0408499 ) press w. h. , teukolsky s. a. , vetterling w. t. , flannery b. p. , 1992",
    ", numerical recepies in fortran , the art of scientific computing , cambridge university press stetson p. b. , 1987 , pasp , 99 , 191"
  ],
  "abstract_text": [
    "<S> we show that various systematics related to certain instrumental effects and data reduction anomalies in wide field variability surveys can be efficiently corrected by a trend filtering algorithm ( tfa ) applied to the photometric time series produced by standard data pipelines . </S>",
    "<S> statistical tests , performed on the database of the hatnet project , show that by the application of this filtering method the cumulative detection probability of periodic transits increases by up to 0.4 for variables brighter than 11  mag with a trend of increasing efficiency toward brighter magnitudes . we also show that tfa can be used for the reconstruction of periodic signals by iteratively filtering out systematic distortions .    </S>",
    "<S> [ firstpage ]    stars : variables  stars : planetary systems  methods : data analysis  surveys </S>"
  ]
}