{
  "article_text": [
    "public opinion expressed in results of elections and opinion polls have been studied widely using traditional statistics .",
    "an alternative approach is information theory , which can be applied to probabilistic data .",
    "electoral data can be easily transformed from percentages to probabilities .",
    "thus the use of information theory to investigate public opinion about political parties and the conduct of governments and its opposition is obvious , but has not been carried out so far .",
    "such an application , the only one to our knowledge , is an analytical approach to interpret the public s high job approval rating for president clinton @xcite .",
    "this rating has been high and nearly constant between january 1998 and february 1999 , despite the well known unfavorable conditions for the us president in that period .",
    "such a high rating could be explained partially , but is still considered unusual for several reasons @xcite . the political situation in greece in the recent three years is completely different than the united states of the years 1998 - 1999 .",
    "however , an interesting ( parallel ) question arises : greek prime minister karamanlis enjoyed a high job approval ( 2004 - 2007 ) , although his party new democracy approval by the public was just @xmath0 higher than the opposition party pasok , headed by george papandreou .",
    "we note that we used statistical data from a specific greek opinion polls company ( metron analysis ) in the period 2004 - 2007 , stopping just three months before the latest parliament elections in greece ( september 2007 ) .",
    "it is of interest to try to clarify the above striking fact by extending the usual statistical treatment to shannon s information theory @xcite .",
    "information theory was used for the first time in telecommunications in the late 40 s .",
    "our aim is to investigate the possibility to extract some general , qualitative conclusions from typical opinion polls in greece , employing the tools of information and complexity theories . as we mentioned above",
    ", our inspiration comes from a similar study in the united states .",
    "although the political systems and the conditions in the usa and greece are very different , our work leads to the same mathematical model .",
    "it is seen that information - theoretic methods can be used to extend the results of usual statistics , which illuminate certain statistical data of public opinion .",
    "information theory can proceed further towards an interpretation , in some sense , of statistical processes .",
    "the use of the logarithm in the definition of information entropy smooths small differences in statistical data from various companies and yields the same qualitative conclusions .",
    "this illustrates the strength of information theory to give quantitative ( numerical ) answers to qualitative questions .",
    "specifically information entropy @xmath1 , corresponding to a probability distribution @xmath2 of @xmath3 events occuring with probabilities @xmath4 , respectivelly , can be defined as @xmath5    @xmath1 is an information theoretic quantity which takes into account all the moments of a probability distribution and can be considered , in a sense , superior to traditional statistics employing the well - known quantities of average value and variance . @xmath1 in relation ( [ eq : eq1 ] ) is measured in bits ( if the base of logarithm is 2 ) , nats  natural units of information ( if the base is e ) and hartleys ( if the base is 10 ) . in the present paper",
    "the base is 10 , for the sake of comparison with @xcite .",
    "however , one case can be transformed to the other one , by multiplying with just a constant .    definition ( [ eq : eq1 ] ) represents the average information content of an event , which occurs with a specific probability distribution @xmath6 .",
    "the use of the logarithm is justified because in such a way @xmath1 obeys certain mathematical and intuitive properties expected from a quantity related to information content of a probability function .",
    "specifically , @xmath1 is positive and the joint information content of two simultaneous independent events translate to the addition of the corresponding information measures of each event e.t.c . for more properties and a pedagogical description see @xcite .",
    "@xmath1 is maximum for an equiprobable or uniform probability distribution @xmath7 , i.e. @xmath8 .",
    "@xmath1 is minimum when one of the @xmath4 s is 1 ( @xmath9 ) and all the other @xmath4 s are 0 , i.e. @xmath10 , under the convention that @xmath11 . in this case ,",
    "one of the outcomes is certain , while all the other ones are impossible to occur .",
    "@xmath1 represents a measure of information content of a probabilistic event , i.e. the average number of `` yes '' or `` no '' questions needed to specify the event ( in the case of bits ) .",
    "@xmath1 is reciprocal to the degree of surprise of an event , i.e. the least probable event has the most information and vice versa .",
    "we give a simple example in order to understand the meaning of relation ( [ eq : eq1 ] ) .",
    "let us ask to a certain number of people the following question : _ is c. karamanlis suitable for the position of prime minister of greece ?",
    "_ we receive answers with percentages and corresponding probabilities @xmath12 ( yes ) , @xmath13 ( no ) , @xmath14 ( something else ) . a direct application of ( [ eq : eq1 ] ) for the normalized probability distribution @xmath15 , where @xmath16 ( @xmath17 ) gives the information content in hartleys of that set of probabilities .    in the case of a uniform ( equiprobable )",
    "distribution i.e. @xmath18 , relation ( [ eq : eq1 ] ) gives @xmath19 .",
    "this is the maximum information entropy with uniform probability distribution ( @xmath17 ) .",
    "this can be interpreted as a distribution of complete ignorance ( unbiased ) in the sense that a specific answer does not contain more information than any other one .",
    "a case of maximum entropy @xmath1 corresponds to a minimum amount of information @xmath20 about our question .",
    "thus information @xmath20 , is reciprocal with @xmath1    @xmath21    the above convention agrees with our intuition , i.e. the information content of an event corresponding to a probability distribution can be quantified by the magnitude of our surprise after the event has occurred or how unpredictable is the outcome .    the case of equiprobable distribution for @xmath22 , i.e. @xmath23 occurred in the recent general parliament elections in italy ( april 2006 ) .",
    "there were two large coalition of parties and one of the coalitions won with a slight difference in votes , about 40,000 -while the number of votes was about 40,000,000 .",
    "thus , with real results @xmath24 versus @xmath25 , we can consider with a very satisfactory approximation that @xmath26 .",
    "the application of information theory in this case gives @xmath27 bit ( base of the logarithm equals 2 ) .",
    "this fact is completely equivalent with throwing a fair coin ( equal probability for the two results heads - tails ) or with the question yes - no ( equiprobable ) which coalition will win .",
    "that means that @xmath28 gives @xmath29 and the minimum information can be interpreted as a complete homogenization of the public opinion about the two coalitions . in other words ,",
    "the results of elections in italy correspond to the random throw of a fair coin i.e. a complete lack of knowledge of the voters .",
    "our observation does not intend to depreciate the process of elections , the culmination of democracy , but it is an extreme case with maximum possible information entropy @xmath30 .",
    "there are other measures of information such as onicescu s information energy @xmath31 @xcite and fisher s information @xmath32 @xcite .",
    "shannon s information is a global measure , while fisher s is a local one i.e. @xmath1 does not depend on the ordering of the probabilities @xmath6 , while @xmath32 does depend , due to the existence of the derivative of the distribution in its definition .",
    "their definitions are given below together with appropriate comments .",
    "it is stressed that all are based on the same probability distributions @xmath6 as @xmath1 .",
    "landsberg s definition of disorder @xmath33 @xcite is @xmath34 and order @xmath35    disorder @xmath33 is a normalized disorder ( @xmath36 ) .",
    "@xmath37 ( zero disorder , @xmath38 ) corresponds to complete order @xmath39 and @xmath40 ( complete disorder , @xmath28 ) corresponds to zero order @xmath41 .",
    "@xmath42 enable us to study the organization of data , described probabilistically .",
    "the next important step is the _ statistical complexity _ @xmath43 defined by shiner - davison - landsberg ( sdl ) @xcite , where @xmath44 is the strength of disorder and @xmath45 is the strength of order . in the present work we consider the simple case @xmath46 and @xmath47 .",
    "another measure of _ complexity _ is @xmath48 according to lopez ruiz - mancini - calbet ( lmc ) @xcite . here",
    "@xmath49 is the so - called _ disequilibrium _ ( or distance from equilibrium ) defined as @xmath50    sdl complexity @xmath51 describes correctly the two extreme cases of complete order and complete disorder , where we expect intuitively zero complexity or organization of the data .",
    "an example taken from the physical world is illuminating .",
    "a perfect crystal ( complete order ) has @xmath52 and the same holds for a gas ( complete disorder ) where @xmath52 as well .",
    "thus ( perfect ) crystals and gases are not interesting , lacking complexity or organization .",
    "this is given by @xmath51 and agrees with intuition .",
    "instead , for the information entropy we have @xmath38 for crystals and @xmath28 for gases , which is not satisfactory .    thus extending from physics , @xmath33 , @xmath53 , @xmath51 and @xmath54",
    "enable us to study quantitatively the ( organized ) complexity of probabilistic data of opinion polls and elections .",
    "an other very important information measure is fisher information @xmath32 @xcite .",
    "recently , there is a revival of interest for fisher information , culminating in two books @xcite and @xcite , defined as    @xmath55    for a continuous probability distribution @xmath56 , which is modified accordingly in the present work for discrete probability distributions .",
    "specifically , for a discrete probability distribution @xmath6 employed in the present work , relation ( [ eq : eq8 ] ) becomes    @xmath57    thus the treatment of high job approval of clinton in @xcite , will be repeated for the case of the greek prime minister constantinos karamanlis and the greek political scene in the recent three years ( 2004 - 2007 ) and extended in the present paper using new quantities e.g. @xmath33 , @xmath53 , @xmath51 , @xmath54 and @xmath32 as functions of time .",
    "we used statistical data for the public opinion coming from the greek opinion polls company _ _ metron analysis__. specifically , we focused our interest on the following three questions , presented in table [ tab : tab1 ] ."
  ],
  "abstract_text": [
    "<S> a general methodology to study public opinion inspired from information and complexity theories is outlined . </S>",
    "<S> it is based on probabilistic data extracted from opinion polls . </S>",
    "<S> it gives a quantitative information - theoretic explanation of high job approval of greek prime minister mr . </S>",
    "<S> constantinos karamanlis ( 2004 - 2007 ) , while the same time series of polls conducted by the company metron analysis showed that his party new democracy ( abbr . </S>",
    "<S> nd ) was slightly higher than the opposition party of pasok -party leader mr . </S>",
    "<S> george papandreou . </S>",
    "<S> it is seen that the same mathematical model applies to the case of the popularity of president clinton between january 1998 and february 1999 , according to a previous study , although the present work extends the investigation to concepts as complexity and fisher information , quantifying the organization of public opinion data . </S>"
  ]
}