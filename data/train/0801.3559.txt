{
  "article_text": [
    "let @xmath4 be a collection of @xmath5 points in @xmath6-dimensional euclidean space , @xmath7 , where the dimension @xmath6 is large , of the order of hundreds or thousands .",
    "we are interested in distance - preserving dimension reduction via random projections , where the points in @xmath4 are randomly projected onto a lower @xmath2-dimensional space such that pairwise distances between original points are well preserved with high accuracy .",
    "statistical analyses based on pairwise distances between points in @xmath4 can be performed on the set of projected points , thus reducing the computational cost of computing all pairwise distances from @xmath8 to @xmath9 .",
    "important applications of distance - preserving dimension reduction are approximate clustering in high dimensional spaces and computations over streaming data , for example hamming distance approximations .",
    "we consider the problem of preserving @xmath10 distances ( quasi - distances ) defined by @xmath11 , for @xmath12 and @xmath13 , for @xmath14 $ ] .",
    "we remark that @xmath15^{1/\\alpha}$ ] is a distance measure for @xmath16 , but not for @xmath17 , and that the hamming distance is obtained as @xmath18 .    in the case",
    "@xmath19 , the lemma of johnson and lindenstrauss ( 1984 ) demonstrates the existence of a projection map @xmath20 such that @xmath21 provided that @xmath22 .",
    "we are interested in dimension reduction in @xmath10 , for general @xmath14 $ ] , using stable random projections .",
    "see indyk ( 2006 ) for an introduction to this technique .",
    "the goal will be to satisfy the inequality in with high probability . in section  [ secproj ] we define stable random projections , and show that distance preserving dimension reduction in @xmath10 reduces to estimation of the scale parameter of the symmetric , strictly stable law , where the latter is discussed in section  [ secpar ] . in section  [ seclest ]",
    "we present an asymptotically efficient estimator of the scale parameter , followed by numerical results in section  [ secresults ] .",
    "a random variable @xmath23 with distribution @xmath24 is said to be _ strictly stable _ if for every @xmath25 , and independent variables @xmath26 , there exist constants @xmath27 such that @xmath28 , where @xmath29 denotes equality in distribution .",
    "the only possible norming constants are @xmath30 , where @xmath31 ; the parameter @xmath0 is known as the _ index _ of stability ( feller , 1971 ) .",
    "the densities of stable distributions are not available in closed form , except in a few cases : cauchy(@xmath32 ) , normal(@xmath33 ) and lvy(@xmath34 .",
    "we are interested in symmetric , strictly stable random variables of index @xmath0 and parameter @xmath35 , with characteristic function @xmath36 , defined for @xmath37 real .",
    "let @xmath38 and @xmath39 be the density and distribution function of @xmath23 . of particular interest is the following property .",
    "suppose that @xmath40 are independent variables with distribution function @xmath41 and that @xmath42 are real constants , then @xmath43 where @xmath44 with @xmath45 .",
    "we assume that the data @xmath4 is arranged into a matrix @xmath46 with @xmath5 rows and @xmath6 columns , i.e.  one row for each of the @xmath5 data points .",
    "let @xmath47 be a matrix whose entries are independent symmetric , strictly stable random variables with index @xmath0 , and @xmath48 for fixed @xmath31 .",
    "we term @xmath49 a _ random projection matrix _ mapping from @xmath7 to @xmath50 via the map @xmath51 .",
    "let @xmath52 and consider @xmath53 and @xmath54 , the @xmath55th and @xmath56th rows of @xmath46 , @xmath57 , corresponding to the @xmath55th and @xmath56th data points in @xmath4 .",
    "let @xmath58 and @xmath59 be the corresponding rows of @xmath60 . then , for @xmath61 , we have @xmath62 where @xmath63 . our aim is to recover @xmath64 from @xmath65 . since @xmath66 provides a sample of values from a distribution with parameter @xmath64 we are in a position to apply the usual repertoire of statistical estimation techniques to obtain estimators with specified accuracy .",
    "this is of particular relevance in the context of streaming data , where @xmath67 , for @xmath68 , is a meaningful measure of the pairwise distance between streams ; in the extreme case of @xmath69 , @xmath67 tends to the hamming distance , the number of mismatches between two sequences .",
    "when @xmath70 $ ] , the @xmath10 distance is given by @xmath71 with potential interest for clustering in high dimensional spaces .",
    "in the case @xmath70 $ ] the statistical problem reduces to estimating the standard scale parameter of the symmetric , strictly stable law .",
    "the problem of parameter estimation of the stable law is particularly challenging due to the fact that the density function does not exist in closed form for most values of @xmath72 $ ] .",
    "the cases @xmath73 and @xmath33 have been extensively studied .",
    "see for example ( li et al . , 2007 ) for references .",
    "maximum likelihood estimation of the parameters was first attempted in dumouchel ( 1973 ) who showed that the mle s are both consistent and asymptotically normal , and computed estimates of the asymptotic standard deviations and correlations .",
    "matsui and takemura ( 2006 ) improved upon these estimates by providing accurate approximations to the first and second derivatives of the stable densities .",
    "nolan ( 2001 ) proposes an iterative approach to maximum likelihood estimation of the parameters , implemented in his software package stable , available at http://www.robustanalysis.com/.    we compute approximations to the second derivative of the stable density and the logarithm of a transformed density by a second order finite difference scheme with grid width @xmath74 using the integral form of the density function given in nolan ( 2007 ) , as implemented in the contributed package fbasics to r ; figure  [ figure : second_derivative ] displays the approximations .",
    "we obtained similar estimates using the expressions in matsui and takemura ( 2006 ) .    among the first estimators of the scale parameter",
    "are those of fama and roll ( 1968 ) based on sample quantiles , for @xmath75 .",
    "the known form of the characteristic function of the stable law has proved to be a useful tool for parameter estimation ( kogon and williams , 1998 ) .",
    "more recently , li ( 2008 ) proposes the harmonic mean estimator for @xmath76 and the geometric mean estimator for @xmath77 to estimate @xmath78 ; combined , these estimators have an asymptotic relative efficiency exceeding @xmath79% and increasing to @xmath80% as @xmath81 .",
    "furthermore , li and hastie ( 2008 ) propose a unified estimator based on fractional powers with are no smaller than @xmath82% , out - performing the combined harmonic and geometric mean estimators , and with good small sample performance for values of @xmath2 as small as 10 ; we point out that the fractional power estimator has been proposed previously in nikias and shao ( 1995 ) .",
    "our approach is to use l - estimation to estimate the logarithm of the scale parameter .",
    "we will show that the method is simple and practical , involving only a precalculated table and then a subsequent sum of products to achieve asymptotic efficiency of 100% .",
    "consider a random sample @xmath83 and let @xmath84 .",
    "define @xmath85 where @xmath86 is distributed as the logarithm of the absolute value of a symmetric , strictly stable random variable of index @xmath0 and @xmath87 , and @xmath88 .",
    "let @xmath89 and @xmath90 denote the p.d.f .  and distribution function of @xmath86 , respectively .",
    "so , @xmath91 is a random sample of variables with p.d.f .",
    "@xmath92 , where @xmath93 the problem reduces to that of estimating the location parameter @xmath94 for the family of distributions @xmath95 , based on a random sample @xmath91 from @xmath92 .",
    "the method of l - estimation defines the estimate @xmath96 as a weighted linear combination of order statistics @xmath97 .",
    "chernoff et al.(1967 ) prove that when the weights are suitably chosen @xmath98 is asymptotically normal with mean 0 and variance @xmath99 .",
    "consequently the estimator @xmath96 is asymptotically efficient .    in large samples",
    ", the weights can be approximated by @xmath100 where @xmath101 .",
    "furthermore , the systematic bias - correction term is given by @xmath102 so , the corresponding bias - corrected estimator is @xmath103 .",
    "table  [ table : fisherbias ] gives the fisher information and the bias for various values of @xmath0 , obtained numerically by making use of approximations to the stable densities and quantiles in the r package fbasics .",
    "the values of fisher information agree with those presented by matsui and takemura ( 2006 ) to within 3 - 4 significant digits for @xmath104 , but appear to be slightly different for @xmath0 outside this range ; for example , for @xmath105 , our estimate is 1.3920 , whereas that of matsui and takemura ( 2006 ) is 1.3898 .",
    ".[table : fisherbias ] fisher information @xmath106 for the parameter @xmath94 and the systematic bias ( bc ) in estimating @xmath94 by efficient l - estimation , tabulated for values of @xmath107 $ ] . [",
    "cols=\"^,^,^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     in the case @xmath108 we will be interested in estimating @xmath109 , corresponding to the @xmath1 norm .",
    "we propose the estimator @xmath110 .",
    "it follows that @xmath111 is asymptotically normal with mean 0 and variance @xmath112 , where @xmath113 is the fisher information about the scale parameter @xmath114 contained in @xmath115 , or equivalently @xmath116 . by second order taylor expansion",
    ", we show that the bias incurred by exponentiating is approximately @xmath117 so the bias - corrected estimator @xmath118 is unbiased up to terms of order @xmath119 .    in practice",
    ", we use the following approximation for the weights in @xmath120 normalised to sum to 1 ; figure [ figure : weights ] displays the weights for various values of @xmath0 . for @xmath0 small , the weighted sum in the formulation of the l - estimator places significant weight on the small order statistics , and negligible weight on the large order statistics , gradually shifting the weight balance towards large order statistics as @xmath121 .",
    "the bias - corrected estimator of @xmath114 is computed as follows : @xmath122.\\ ] ] similar calculations provide an asymptotically efficient estimator for @xmath78 ; a more relevant parameter for values of @xmath0 less than @xmath123 .     for @xmath124 and , starting from the left , following the peaks , @xmath125.,scaledwidth=80.0% ]",
    "with the fractional power estimator of li and hastie ( 2008 ) ( @xmath126 replicates ) .",
    "the cramr - rao lower bound is plotted for comparison .",
    "the equivalent plot for estimators of @xmath84 shows a similar pattern .",
    "the perturbation in the m.s.e.for the l - estimator at @xmath127 is caused by an oscillation in the weight function ; it can be minimised by selective trimming.,scaledwidth=80.0% ]    the l - estimator is easily computable as the weights depend only on @xmath0 and @xmath2 , and can be tabulated once - and - or - all for any required value of @xmath0 .",
    "the calculation of these terms depends on accurate approximations to the quantiles and the density of the symmetric , strictly stable distribution . whereas it is possible to obtain a good approximation to the mle via an iterative procedure with a suitably large table of pre - calculated derivatives for fixed @xmath0 , the l - estimation procedure has the advantage of achieving the same asymptotic performance without iteration .",
    "the l - estimator has modest computing requirements ; it has @xmath3 running time and @xmath3 storage requirement given a table of pre - calculated weights for given @xmath0 .    to confirm the superior performance of out l - estimator we have simulated its mean square error for various sample size and various values of @xmath0 .",
    "figure  [ figure : mse ] shows that , as expected , the l - estimator has smaller mean square error than the estimator of li and hastie ( 2008 ) .",
    "the perturbations in the m.s.e .  of the l - estimator at @xmath128 are caused by an oscillation of the weight function which becomes negative when @xmath129 is close to 1 ( see figure  [ figure : weights ] ) .",
    "the effect can be minimised by using a trimmed version of the l - estimator .",
    "this is work in progress and will be reported elsewhere .",
    "chernoff , h. , gastwirth , j. l. and johns , jr .",
    ", m. v. ( 1967 ) : asymptotic distribution of linear combinations of functions of order statistics with applications to estimation .",
    "38 ( 1 ) , 52 - 72_.              kogon , s. m. and williams , d. b. ( 1998 ) : characteristic function based estimation of stable parameters . in : r. adler , r. feldman and m. taqqu ( eds . ) : _ a practical guide to heavy tailed data_. birkhuser , boston , ma , 311 - 338 .",
    "li , p. and hastie , t. j. ( 2008 ) : a unified near - optimal estimator for dimension reduction in @xmath10 @xmath131 using stable random variables . in : j. c. platt , d. koller , y. singer and s. roweis ( eds . ) : _ advances in neural information processing systems 20_. mit press , cambridge , ma .",
    "nolan , j. p. ( 2001 ) : maximum likelihood estimation of stable parameters . in : o.",
    "e. barndorff - nielsen , t. mikosch and s. i. resnick ( eds . ) : _ lvy processes : theory and applications_. birkhuser , boston , ma , 379 - 400 ."
  ],
  "abstract_text": [
    "<S> in recent years , large high - dimensional data sets have become commonplace in a wide range of applications in science and commerce . techniques for dimension reduction are of primary concern in statistical analysis . </S>",
    "<S> projection methods play an important role . </S>",
    "<S> we investigate the use of projection algorithms that exploit properties of the @xmath0-stable distributions . </S>",
    "<S> we show that @xmath1 distances and quasi - distances can be recovered from random projections with full statistical efficiency by l - estimation . the computational requirements of our algorithm are modest ; after a once - and - for - all calculation to determine an array of length @xmath2 , the algorithm runs in @xmath3 time for each distance , where @xmath2 is the reduced dimension of the projection . </S>"
  ]
}