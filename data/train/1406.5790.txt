{
  "article_text": [
    "the advent of widefield and sensitive radio telescopes such as lofar , the mwa , meerkat , the jvla and askap has imparted renewed impetus to surveys of the transient radio sky ( bower et al.2007 ; croft et al.2010 ; frail et al.2012 ; mooley et al.2013 ; murphy 2013 ) .",
    "the most common and straightforward search mode employed on interferometric facilities such as these involves inspection of the data in the imaging domain .",
    "imaging surveys are restricted to transients on timescales greater than the telescope correlator integration timescale , typically 3 - 10 seconds , and typically span event durations between several seconds up to days or months .",
    "the domain of astrophysical radio transient events remains poorly characterized .",
    "the large volume of unexplored parameter space that may be occupied by transient events means that even fundamental observables of the whole population , such as the number of transients detectable as a function of flux density or timescale , are poorly known ( e.g. bower et al.2007 ; frail et al.2012 ) .",
    "it is often for this reason that several survey groups espouse a variety of different survey techniques ( e.g. vast ) , based on the philosophy that various survey optimizations are necessary to cover the diversity of all possible transient astrophysical phenomena ( murphy et al.2013 ) .",
    "the fact that transient astrophysical phenomena may span a large range in timescale , luminosity and frequency need not necessarily preclude the existence of an optimal strategy capable of simultaneously capturing events covering a large range of these parameters .",
    "it is the purpose of this paper to explore the optimization of imaging transients surveys in order to capture the largest number of events .",
    "there are several important differences between fast and slow transients that dictate how to survey them optimally .",
    "radio transients can be distinguished as either slow or fast on the basis of their duration relative to the typical integration timescale of the telescope correlator .",
    "it is usually necessary to dedisperse the signals associated with fast transients in order to maximise their signal - to - noise ratio , and the short duration of their emission renders them subject to temporal smearing caused by scattering in interstellar and intergalactic plasmas .",
    "a defining characteristic of slow transients is that they occur on a timescale too slow for either dispersion or scattering to significantly diminish their signal - to - noise ratio ; thus these effects are not relevant considerations in the context of slow transients surveys . in this paper",
    "we are concerned with strategies for imaging surveys of slow transients only .",
    "an important consideration is the duration of the events relative to the telescope survey time .",
    "if the interval between two successive observations of a given field is large compared to the typical transient event duration , then the observations are statistically independent , and we may expect to discover a disjoint set of transients between observations . it is convenient to introduce the formal concept of an event decoherence time as the timescale over which independence applies . if the interval between the observations is short compared to this timescale , then one expects to redetect essentially the same set of transients discovered in the first observation of that field .",
    "fast and slow transients may also thus be distinguished on the basis of whether the event decoherence time is short or long compared to the interval that the telescope dwells on a given field . according to this definition , it is possible to search any given field of view for slow transients down to a given sensitivity limit only infrequently , and to use the intervening time between searches of a given field to survey other fields for further slow transients .",
    "it is this defining characteristic of slow transients that forms the basis of the present optimization analysis .",
    "a crucial consideration in any transients survey is the balance between sensitivity and field of view .",
    "is it more advantageous to visit in succession a small number of fields of view with high sensitivity , or a large number of fields of view with accordingly lower sensitivity ?",
    "the objective of this paper is to determine the optimal balance between total survey field of view and sensitivity for a survey of slow transients , and to consider how the choice of these parameters alters the event detection rate .",
    "the structure of this paper is as follows . in section [ decohere ]",
    "we preface our discussion of event detection rates by making a formal definition of the event decoherence time and compute its value for several likely distributions of event durations . in section [ singlefield ]",
    "we relate the detection rate of transients for a single field to the underlying luminosity function of the parent transient population . in section [ multifields ] we then consider the increase in detection rate obtained by subdividing the observation into a survey of @xmath2 fields .",
    "our objective is to find the value for @xmath2 that optimises the balance between the sensitivity reached per field and the total area that may be surveyed in a given time @xmath1 so that the detection rate is maximised .",
    "section [ discussion ] discusses the implications of our results by presenting a set of simple rules for optimizing the survey strategy , and section [ conclusion ] presents our conclusions .",
    "our analysis is based on the premise that a survey is optimal if it detects a maximal number of unique transient events .",
    "survey optimization therefore depends on several fundamental attributes of both the events we wish to detect and of our survey instrument , namely : ( 1 ) the event decoherence time , which is a measure of the interval of time between which successive visits to the same field detect a disjoint set of transient events ( see below ) , ( 2 ) the telescope sensitivity , ( 3 ) the luminosity distribution function of the population , particularly its slope , and ( 4 ) the manner of survey we wish to undertake . in relation to",
    "( 4 ) , we consider here two archetypical surveys : ( i ) those which target events are distributed homogeneously throughout space , and ( ii ) those which target events at fixed distance , as is appropriate for events embedded in a galaxy or a cluster of galaxies .",
    "this work extends the formalism originally introduced in macquart ( 2011 ) to treat the detection of fast transients .",
    "another consideration is the effect of interstellar scintillation , which can alter the flux density of any compact object whose radiation propagates through the interstellar medium of our galaxy .",
    "most slow transients are not sufficiently compact to exhibit the fast , large amplitude variability caused by diffractive interstellar scintillation , but they are compact enough to undergo refractive scintillation .",
    "although refractive scintillation is a widespread phenomenon amongst compact objects , the typical amplitude of variations is often small compared to the factor of several variations that may be expected of the transients themselves . at centimetre wavelengths",
    "the expected refractive modulation index ( i.e. root - mean - square flux density variation normalised by the mean flux density ) is typically @xmath16 , with an associated timescale of order days to weeks ( e.g.walker 1998 ) .",
    "for instance , the refractive scintillations exhibited by compact intraday - variable quasars typically display modulation indices less than @xmath17 ( lovell et al.2008 ) and timescales @xmath18days , with timescales @xmath19weeks at wavelengths longer than @xmath20 cm ( lovell et al.2008 ; but see kedziora - chudczer et al.1997 & macquart & de bruyn 2006 ) .",
    "the timescale of refractive scintillation increases as @xmath21 , and its amplitude decreases with wavelength .",
    "the effects of refractive scintillation on the detectability of transients are further discussed in  [ refisseffect ] .",
    "a consideration in a survey for slow transients is the desire to avoid repeatedly redetecting the same long - duration events .",
    "we introduce the concept of the event decoherence function , which characterises how the particular transient events that are detected in a given survey field are correlated in time with those detected in a subsequent observation .",
    "this quantity then determines the timescale over which successive visits to a given patch of sky would detect a fundamentally new set of transient sources . where redetection is deemed desirable , the event decoherence function , if known , allows one to set the reobservation time according to the fraction of events to be redetected .",
    "we represent the occurrence of an event by a function @xmath22 such that , when the event occurs @xmath23 assumes the value one , and it is zero otherwise . for an event that commences at @xmath24 and",
    "has duration @xmath25 one has @xmath26 , where @xmath27 is the heaviside function .",
    "one may use this function to count the number of events occurring over a time interval @xmath28 from the superset containing all @xmath29 events . for events due to a large ensemble of sources with event times @xmath30 and durations @xmath31",
    ", the number of transient events occurring at a time @xmath32 is given by @xmath33 as we are interested in the correlations between different events , the quantity of interest here is the autocorrelation in the fluctuation in the event count , @xmath34 . for events which are distributed randomly and independently in time ,",
    "this is given by ( see appendix [ acfapp ] ) , @xmath35   - { \\cal o } \\left ( \\frac{{\\cal n } \\langle \\delta t\\rangle^2}{{\\cal t}^2 } \\right ) , \\label{nacf0}\\end{aligned}\\ ] ] where we henceforth neglect the terms that are second order in @xmath36 or higher .",
    "we may satisfy ourselves that the formalism introduced here , in terms of event counting , is truly a measure of the timescale over which the detection of a set of events in a field becomes statistically independent from a future measurement .",
    "an alternative conceptual approach is to consider the correlation in time between each event and every other event , and then average over all correlations of event pairs .",
    "this is equivalent to an average over all pairs of events , and it is evident ( see eq.([bigavg ] ) ) that this is mathematically identical to the approach adopted here .    in order to evaluate the decoherence function",
    "explicitly we specify a probability distribution for the event durations , @xmath31 and take the continuum limit so that the sum over events becomes an integral .",
    "let us denote @xmath37 as the probability of obtaining events between durations @xmath25 and @xmath38 .",
    "then the average event decoherence time is represented in the form , @xmath39   d\\delta t \\right ] .",
    "\\label{nacf}\\end{aligned}\\ ] ] to acquire an intuitive appreciation of the event decoherence timescale , we evaluate the event decoherence function for three representative cases : events all possessing identical durations , events whose durations follow a gaussian distribution , and event durations that follow a power law distribution .      for a single event duration one",
    "has @xmath40 , where @xmath41 is the duration of all the events . in this case eq.([nacf ] ) becomes @xmath42 this illustrative result shows that , as intuitively expected , the correlation between events is a maximum at @xmath43 and falls to zero on a timescale of precisely @xmath41 , the event duration .",
    "the amplitude of the autocorrelation is linearly proportional to the event rate , @xmath44 .      for a gaussian distribution of event durations with",
    "mean @xmath41 and standard deviation @xmath45 , @xmath46,\\end{aligned}\\ ] ] one has @xmath47 where @xmath48   \\quad \\hbox{and } \\quad g(t ) = \\frac{1}{\\sqrt{2 \\pi \\sigma_{\\delta t}^2 } } \\exp \\left[- \\frac{t^2}{2 \\sigma_{\\delta t}^2 } \\right]\\end{aligned}\\ ] ] are the cumulative and probability density functions of a gaussian distribution respectively .",
    "the width of this autocorrelation is determined by both @xmath41 and @xmath45 .",
    "when @xmath41 is large compared to @xmath45 , the second term in eq.([gaussacf ] ) is small , and the behaviour of the autocorrelation is dominated by the first term .",
    "for @xmath45 small , the function in the first term , @xmath49 $ ] , behaves like @xmath50 .",
    "the result is an autocorrelation function which is dominated by a linear decrease with @xmath51 until the autocorrelation reaches zero at @xmath52 .",
    "as @xmath53 becomes larger one finds that the second term in eq.([gaussacf ] ) increases in magnitude , and its effect is to add gaussian wings to the autocorrelation at @xmath54 .",
    "we note , however that , for the purposes of this particular distribution , it is unphysical to consider situations in which @xmath55 because the probability distribution of event durations would then imply that a large number of events with negative durations occur .",
    "the event decoherence function declines linearly for lags @xmath56 and then declines exponentially quickly to zero for lags @xmath57 .",
    "another likely possibility is one in which the distribution of event durations follows a power law of the form , @xmath58 for durations between @xmath59 and @xmath60 .",
    "for such an event duration distribution , the event decoherence function takes the form , @xmath61 where we define @xmath62    \\quad \\hbox{and } \\quad f(t ) = \\left [ \\frac{\\delta t_{\\rm max}^{1-\\gamma}-{t}^{1-\\gamma}}{\\delta",
    "t_{\\rm max}^{1-\\gamma}-\\delta t_{\\rm min}^{1-\\gamma } } \\right].\\end{aligned}\\ ] ] it is obvious that this autocorrelation falls to zero on a timescale @xmath63 .",
    "however , as the value of @xmath64 increases , more of the event durations are close to @xmath59 , and the decoherence function is more sharply peaked about the origin ; accordingly , the half power point of the function moves to progressively smaller time lags and approaches @xmath59 .",
    "illustrative plots of the event decoherence function for the various duration probability distribution functions examined here are shown in figure [ figacfs ] .",
    "hereafter throughout the text we denote @xmath65 as the timescale at which the event decoherence function effectively decays to a negligible value .",
    "an important consideration in the optimization of a transients survey relates to the types of events one should optimize for .",
    "our analysis is informed by two premises :    * the average event rate is uniform across the survey region on the sky and is homogeneous in time . * the events that we are interested in optimizing the survey for occur on a duration longer than the duration that the telescope dwells on any one field .",
    "this tenet relates to our definition of a slow transient ; if the event duration is shorter than the telescope dwell time , no advantage is gained in event rate by slewing the telescope to survey another location . based on tenet ( i ) ,",
    "the event detection rate for these faster - timescale transients is identical whether one continues surveying the same patch of sky or moves to another field .",
    "thus the only events worth considering in an optimization of dwell time versus survey area in a slow transients are those whose duration exceeds the dwell time .    before determining how to optimize the event detection rate within a survey ,",
    "it is first necessary to ascertain the rate at which a telescope with a given field of view , @xmath11 , and sensitivity would detect transients in a single integration on a single field .",
    "we consider a survey with a telescope whose limiting detection flux density within an observing duration @xmath1 is , @xmath66 where @xmath67 is the observing bandwidth , @xmath68 the telescope effective area , @xmath69 the system temperature , @xmath70 the number of polarizations recorded and @xmath71 the minimum signal - to - noise ratio that is acceptable for detection ( e.g. @xmath72 for a 7@xmath73 detection ) coverage , such as meerkat and the ska .",
    "imaging artefacts may instead limit the practical sensitivity achievable , especially if the @xmath74 coverage of the radio array is sufficiently poor over a time @xmath75 . in this case",
    "one might expect that the limiting `` believable '' flux density , @xmath12 will decrease more slowly than the @xmath76 dependence of thermal noise .",
    "the rate at which this occurs will depend heavily on the array configuration and sky complexity at the observing frequency , and a general analysis of its effects for specific arrays is beyond the scope of this paper .",
    "however , the analysis presented here is readily generalised to take into account such effects if their average dependence on integration time is known . ] .",
    "some discussion regarding point ( ii ) above is in order . in practice",
    ", the survey will detect events of durations both shorter and longer than the telescope dwell time .",
    "for those events with durations whose spans smaller than @xmath1 , the sensitivity to an event of duration @xmath77 is smaller than @xmath12 by a factor @xmath78 , and the detection rate of these `` fast '' transients will depend in detail on the bi - variate distribution of event luminosity and duration relative to the telescope limiting flux density ( which will vary for each event depending on its duration ) .",
    "thus the survey detection rate for such events is a complicated function of the particular event luminosity - duration distribution that pertains to any given transient population , which is hard to predict _ a priori_. fortunately , however , by tenet ( ii ) there is no advantage to gained by trading integration time versus survey area for such transient events .",
    "an important point is that the survey will detect just as many of these fast transients by observing the same field as it would by observing another field . as",
    "such events make no contribution to the survey rate optimization , we do not consider the contributions of events @xmath79 , further in the present analysis , and our detection rate does not take them into account .",
    "the reader is referred to macquart ( 2011 ) for an analysis of their contribution to the event rate .    in this work",
    "we consider events whose luminosity function follows a power law with index @xmath3 between luminosities @xmath80 and @xmath7 such that the volume density of objects between luminosities @xmath81 and @xmath82 is @xmath83 where @xmath84 is the total event rate per unit volume integrated over all luminosities and the normalization constant is @xmath85",
    "we consider the event detection rate for two types of surveys .",
    "the first relates to a search for events whose progenitors are distributed homogeneously throughout space , and the second relates to a targetted search of a system ( e.g. a galaxy or a cluster of galaxies ) located at a fixed distance from the observer .",
    "we additionally consider an obvious generalization of the former case in which the events are distributed homogeneously throughout space , but are only detectable beyond a certain minimum distance ; this case illustrates the effect on survey rate of a population whose detection requires a certain minimum sensitivity .      for a population of transients distributed homogeneously throughout space ,",
    "the telescope is capable of detecting objects of luminosity @xmath81 out to a luminosity distance @xmath86 , so that the observed number of events per second for objects of of luminosities between @xmath81 and @xmath82 is , @xmath87 where @xmath11 is the telescope field of view .",
    "the total event rate integrated over all luminosities may be expressed in the compact form ) .",
    "this generalization is discussed in appendix [ appendixcosmo ] . however , in many populations at cosmological distances ( e.g. quasars ) , strong evolution in the source population overwhelms cosmological effects when considering the event rate .",
    "we do not attempt to model the cosmological evolution of any hypothetical population of transient progenitors in this work .",
    "] , @xmath88 it is apparent that the detection rate scales linearly with field of view , but increases more slowly with telescope dwell time .",
    "this is the basis of the survey optimization : the event detection rate may be increased by sacrificing telescope dwell time in favour of field of view by make multiple pointings over a given survey time @xmath1 .",
    "the event rate in a survey over a truly homogeneously - distributed population is always nonzero , however how poor the survey sensitivity , by virtue of the fact that the survey may detect events arbitrarily close to the observer .    in certain cases",
    "it is more realistic to suppose events are only detectable beyond a certain minimum distance , @xmath89 .",
    "this situation effectively pertains to searches in which a certain minimum sensitivity is required before the survey can detect far enough out into the universe in order to detect any of the target events .",
    "the detection rate between luminosities @xmath81 and @xmath90 is therefore @xmath91 the requirement @xmath92 implies an inequality between luminosity , sensitivity and @xmath89 : @xmath93 , and the detection rate integrated over all luminosities is @xmath94 h\\left [ l - 4 \\pi s_0 d_{\\rm min}^2 \\right ] dl .",
    "\\end{aligned}\\ ] ] the behaviour of the detection rate depends on the survey sensitivity relative to the flux density of the brightest and faintest objects detectable at the inner radius of the survey volume .",
    "the detection rate is , @xmath95 where it is convenient to define , @xmath96 and where we define the lowest luminosity detectable at the inner radius of the survey volume as @xmath97 .",
    "these results may be understood as follows .",
    "if the survey sensitivity is so poor that @xmath98 , it is incapable of even detecting events at the minimum distance , and the event rate is zero .",
    "if the survey is extremely sensitive , @xmath99 , the survey detects every event at the inner radius of the survey volume , and the event rate is the same as that for a survey of homogeneously - distributed events except that there is no contribution from events interior to the volume bounded by the radius @xmath89 . in the intermediate case , @xmath100",
    ", the survey only detects that fraction of the events whose luminosities exceed @xmath101 at the inner radius of the survey volume .",
    "another possible survey mode involves targeted observations of a galaxy at a known luminosity distance , @xmath102 .",
    "since all the putative transient events are located at the same distance , we detect all events whose luminosity exceeds @xmath103 . if the total event rate per unit volume is @xmath84 , then the total event rate per unit solid angle , @xmath104 is found by integrating over the depth of the object , @xmath105 ( assumed small compared to its distance ) and over the surface area subtended by the portion of sphere of radius @xmath106 that encompasses the telescope field of view .",
    "an observation over a solid angle @xmath11 would detect a fraction @xmath107 of these objects over the total surface @xmath108 and subtend an area @xmath109 , where @xmath110 is the angular diameter distance to the object and @xmath111 .",
    "thus the total event rate per solid angle is @xmath112 and so we identify the rate of events between luminosities @xmath81 and @xmath82 as @xmath113    the total observed detection rate is therefore @xmath114}^{{\\rm min}[l_0,l_{\\rm max } ] } \\rho_{l,\\omega } dl    = \\rho_0 \\delta z d_a^2 \\omega \\left\\ {   \\begin{array}{ll } 1 , & l_0 < l_{\\rm min } , \\\\",
    "\\eta(l_0 ) , & l_{\\rm min } < l_0 < l_{\\rm max } , \\\\ 0 , & l_0 > l_{\\rm",
    "max}. \\\\ \\end{array } \\right . \\label{ratetarget}\\end{aligned}\\ ] ] the three cases in the above expression are interpreted to mean : ( i ) when @xmath115 the sensitivity of the observation is so good that even the faintest event can be detected by our observation , so we detect all possible events and the measured event rate is equal to the intrinsic field event rate of @xmath116 ; ( ii ) when @xmath117 , the sensitivity of the observation is so poor that not even the most luminous event can be detected , so the event detection rate is zero ; and ( iii ) for the case @xmath118 , the sensitivity is intermediate to the two preceding cases and we detect only a fraction @xmath119 of all the events that occur .",
    "an illustration of the behaviour of @xmath120 as a function of @xmath8 is shown in figure [ rtotdemo ] .      as an illustration of the effects of interstellar scintillation on the results presented in this paper , we consider briefly here how interstellar scintillation alters the foregoing result .",
    "interstellar scintillation can randomly amplify or deamplify the signals of compact transients , and so alter the apparent distribution of event flux densities . in situations",
    "where the scintillation timescale is long compared to both the event duration and the duration of the observation , scintillation can bear on the detection rate by amplifying some events that would otherwise be too faint to detect . for events all located at the same distance , as considered in this subsection , there is a linear relationship between source luminosity and flux density .",
    "it is then straightforward to incorporate this scintillation effect by considering an `` effective '' event luminosity distribution that replaces that given in eq.([ldist ] ) by making the replacement @xmath121 , where @xmath122 is the amplification caused by scintillation . the resulting distribution of effective event luminosities is then given by , @xmath123 where @xmath124 is the probability distribution of amplifications , @xmath125 is the distribution of intrinsic luminosities ( viz .",
    "eq.([ldefn ] ) ) , and @xmath126 is the distribution of effective event luminosities after scintillation is taken into account .",
    "for the moderate modulation indices typical of refractive scintillation at centimetre and decametre wavelengths ( i.e.@xmath71 much less than one ) , the amplification probability distribution takes the form , @xmath127.\\end{aligned}\\ ] ] we assume that the timescale of both the event and of the observation is short compared to the scintillation timescale ; if the observed emission from the transient encompasses several ( say @xmath128 ) independent scintillations the modulation index is reduced by a factor of @xmath129 . noting that @xmath125 is non - zero only over the range @xmath130 $ ] , the effective luminosity function becomes , @xmath131 \\ , p_l \\left ( \\frac{l}{a } \\right).\\end{aligned}\\ ] ] we are unable to evaluate this integral in closed form for non - integer values of @xmath132",
    ", however we may still understand the effects of scintillation qualitatively by considering its solution for integer values .",
    "the solution for @xmath133 is particularly simple : @xmath134   \\right .",
    "\\nonumber \\\\ & \\null & \\left.\\qquad \\qquad \\qquad - \\frac{m}{\\sqrt{2 \\pi } }       \\left [ \\exp \\left ( - \\frac { ( l - l_{\\rm min})^2}{2 m^2 l_{\\rm min}^2 } \\right )       - \\exp \\left ( - \\frac { ( l - l_{\\rm max})^2}{2 m^2 l_{\\rm max}^2 }   \\right ) \\right ]   \\right\\}. \\label{leff}\\end{aligned}\\ ] ] scintillation only alters the shape of @xmath126 near @xmath135 and @xmath136 ; for luminosities in the range @xmath137 $ ] the effective luminosity distribution is , to an excellent approximation , @xmath138 . a plot of the behaviour of this function is shown in figure[figscint ] .",
    "it shows that the effect of scintillation is to extend the low and high flux density limits of the distribution to yet lower and higher values respectively .",
    "the behaviour of the effective luminosity distribution function near @xmath80 and @xmath7 is dominated by the error functions in eq.([leff ] ) , from which we deduce that the effect of scintillation is to extend a small fraction of high luminosity events to yet higher luminosities , @xmath139 , and some events at the low luminosity end down to values @xmath140 .    in practice , for the small modulation indices ( @xmath141 ) typically observed for refractive interstellar scintillation , the effects of scintillation on the event detection rate are small unless the survey sensitivity is such that the limiting luminosity of the observations , @xmath142 is close to @xmath7 .",
    "we note , however , that there are cases in which the refractive modulation index is observed to be higher ( @xmath143 ) , and that compact objects are also subject to the effects of extreme scattering events ( eses ; fiedler et al.1987 ) .",
    "eses may produce flux density deviations exceeding 50% in some cases , but these events are rare , estimated at 0.013 src@xmath144year@xmath144 .",
    "in the section above we have derived the detection rate for a single telescope field of solid angle @xmath11 whose sensitivity is such that it can detect objects down to a limiting flux density of @xmath12 in a duration @xmath1 . in this section",
    "we consider the detection rate for a modified search strategy in which the total observing time is subdivided so that we visit a number of fields , @xmath2 . if the telescope requires a time @xmath4 to move between fields , then the total amount of time spent slewing is since a slew to the first field is unnecessary and is not included in the single - field event rate calculations of eqs.([ratehomog ] ) and ( [ ratetarget ] ) : the exact starting position is unimportant in a survey for events distributed homogeneously ( and thus isotropically about the sky ) .",
    "however , where time consumed in an initial slew is an important consideration , one may always choose to reinterpret @xmath2 as @xmath145 . ]",
    "@xmath146 , and the total time spent observing on each field is @xmath147 the following results are also applicable to drift - scan surveys , in which case @xmath4 should be identified as the time that it takes the telescope beam to traverse a fixed point in the sky .",
    "although the survey covers more field of view by increasing @xmath2 , the limiting sensitivity per field will be commensurately lower , and it is our purpose to determine the value of @xmath2 that maximizes the total number of detections over the interval @xmath1 .      equation ( [ ratehomog ] ) presents the event detection rate for a telescope whose sensitivity is such that it can detect objects down to a limiting flux density of @xmath12 in a duration @xmath1 .",
    "the event detection rate for a survey over @xmath2 fields for the same duration is then @xmath148 and the maximum event rate occurs when the number of fields visited is @xmath149 the associated maximum event rate is @xmath150 which is a factor @xmath151 larger than the event rate that would be obtained by spending the entire integration time on a single field .",
    "a few obvious points are in order .",
    "we have regarded @xmath2 as a continuous variable , but in practice @xmath2 is an integer , so it will only be possible to approximately obtain the maximum event rate .",
    "where @xmath152 is less than one , the optimal strategy is to survey only a single field",
    ".    equation ( [ nmax ] ) indicates that , as @xmath1 increases , the number of fields that should be searched increases similarly .",
    "however , there is a practical limitation to the number of fields to be searched which is set by the physics of the target transient events . after a duration comparable to the event decoherence time one expects each of the searched fields to contain a new set of transient events , so that a second measurement of the same field would be statistically independent of the original measurement .",
    "thus a search of the same field after a duration @xmath65 is statistically equivalent to searching another ( as yet ) unsearched field .",
    "as there is no advantage to searching other statistically independent fields over the same fields a second time , this allows us to identify a practical search cycle time as @xmath65 .",
    "thus the maximum number of fields that the survey should cycle over is @xmath153 .",
    "here we examine the optimum detection strategy for the slightly more complicated case in which the transient events are only detectable beyond a certain minimum distance .",
    "for the sake of algebraic simplicity we assume that the slewing time is negligible relative to observing time , so that the total amount of time spent per field is @xmath154 . in this case the detection rate is obtained from eq.([rmindist ] ) by making the replacement @xmath155 and @xmath156 : @xmath157 the behaviour of this function is shown in figure [ fignfielddmin ] , from which it is clear that the maximum event rate occurs at @xmath158 for luminosity functions shallower than @xmath159 .",
    "we derive an exact expression for the value of @xmath2 that optimises the event rate by differentiating eq.([rdmin ] ) . for most cases of interest ,",
    "in which @xmath160 , the maximum rate occurs in the range @xmath161 .",
    "the location of the maximum is given by the lowest nonzero solution to the following equation : @xmath162 as is obvious from figure [ fignfielddmin ] , the optimal number of survey fields decreases as the luminosity function becomes progressively steeper .",
    "equation ( [ n4solns ] ) also has the solution @xmath163 , which corresponds to the point at which the event detection rate reaches zero ; for @xmath164 this is the only nonzero solution , reflecting the fact that when @xmath165 the detection rate becomes a monotonically decreasing function of @xmath2 , and the optimal strategy is to survey only a single field .",
    "the turning point may , in principle , instead occur in the regime @xmath166 , in which case it occurs at a value of @xmath2 given by @xmath167 ^ 2.\\end{aligned}\\ ] ] combining this solution with the inequality , @xmath168 , we see that this solution is only valid when @xmath169 in most practical situations this alternative solution may be ignored .",
    "let us now consider the detection rate over a set of targeted objects at fixed distance .",
    "this situation is applicable to a survey of an individual galaxy or cluster of galaxies ( e.g. the virgo supercluster ) whose angular size subtends more than one telescope beam , so that multiple pointings are required to cover it .",
    "more generally , the situation is applicable to any survey of multiple targets which are approximately equidistant but located in separate fields of view .",
    "we start from equation ( [ ratetarget ] ) , which relates the detection rate in a single field to the luminosity distribution of the transient population and our telescope sensitivity , expressed in terms of the limiting detectable luminosity , @xmath170 .",
    "now , since @xmath171 , we see that the limiting luminosity of a survey of total duration @xmath1 which visits @xmath2 fields is approximately @xmath172 .",
    "if we account for slewing time , we see that the total time per observation is @xmath173 , so the limiting luminosity increases to @xmath174}$ ] .",
    "the detection rate for a survey which visits @xmath2 fields is then , @xmath175 a plot of the behaviour of this function is shown in figure [ rnfieldplot ] . an important characteristic of this function is that the detection rate is found to peak for survey luminosities @xmath176 for @xmath177 .",
    "for @xmath164 , we see that the optimal detection rate occurs at the point where @xmath178 .",
    "the reason for this relates to the steepness of the luminosity distribution . for distributions steeper than @xmath164 ,",
    "most of the events occur at the low luminosity end , and thus a survey that seeks to maximize detection rate must ensure that it achieves a sensitivity sufficient to reach this minimum luminosity in each field that it surveys .",
    "for such a distribution , the optimal number of fields corresponds to a strategy in which the time available is subdivided so that each field is surveyed to a sensitivity sufficient to detect objects of @xmath80 ( but obviously no lower ) .",
    "conversely , if the luminosity distribution is shallower than @xmath179 , there are not enough events at the low luminosity end to justify spending the integration time on that field to reach the sensitivity to detect them .",
    "the optimal strategy is to increasingly favour field of view over sensitivity as the luminosity distribution becomes progressively shallower .",
    "this point is illustrated in figure [ rnfieldplot ] , where we see that the peak detection rate occurs at larger @xmath2 for the case @xmath180 relative to the case @xmath181 .",
    "+   +   +    for the case @xmath182 , we obtain the location and value of the optimal detection rate by finding the turning point of @xmath183 .",
    "one has @xmath184 + l_{\\cal n}^{1-\\alpha } \\left [   \\frac{t_{\\rm obs } ( \\alpha-3)}{2 } + t_{\\rm slew } \\left ( n + \\frac{\\alpha-3}{2 } \\right )   \\right ] } { [ t_{\\rm obs } - ( n-1 ) t_{\\rm slew } ] [ l_{\\rm max}^{1-\\alpha } - l_{\\rm min}^{1-\\alpha } ] } \\right ] ,        & l_{\\rm min } < l_{\\cal n } < l_{\\rm max } , \\\\ 0 , & l_{\\cal n } > l_{\\rm max}. \\\\",
    "\\end{array } \\right .",
    "\\end{aligned}\\ ] ] for @xmath185 , the location of the turning point , at @xmath186 , has the simple solution : @xmath187 whose associated maximum detection rate is @xmath188 note that the maximum detection rate depends on @xmath189 , and thus @xmath190 .",
    "thus , in this special instance , the maximum detection rate scales as @xmath191 , which is the metric employed in some telescope survey figures of merit ( cordes 2007 , 2009 ) .",
    "more generally , for @xmath192 , the maximum detection rate occurs at the value of @xmath2 which satisfies the following transcendental equation : @xmath193 } \\right].\\end{aligned}\\ ] ]    as a final remark , we note that it is possible in principle for the value of @xmath152 to exceed the total number of independent telescope pointings , @xmath0 , required to cover the entire survey area .",
    "this implies that the optimal strategy includes re - surveying a number of fields for new transients .",
    "a re - observation of a previously visited field can be considered statistically independent of a prior observation , and should detect an entirely new set of transient events , as long as the time between observations of the same field exceeds the event decoherence time ( see  [ sec : decoherence ] above ) . in the opposite limit , in which the event decoherence time is long compared to the interval between observations of the same field , the assumption underpining the foregoing calculation , namely that each observation of a field is statistically independent , is violated . however , in this case we see trivially that iff @xmath9 then the optimal strategy is simply to survey each field only once for a duration @xmath194 ( hence @xmath195 ) .",
    "we have derived in the foregoing section a set of conditions for optimising the tradeoff between survey sensitivity and total field of view .",
    "this enables us to draw some general inferences regarding the optimization of survey strategy .",
    "although , in a blind transients survey for unknown transient populations , the particulars of the luminosity distribution of events are unknown , we will often be able to place reasonable prior bounds on the luminosity distribution function ( i.e. @xmath132 , @xmath80 and @xmath7 are known only to within a certain range ) . to the extent that it is possible to prescribe these bounds it is also possible to specify the range of optimal survey strategies .",
    "moreover , even when this range is large , the foregoing formalism is useful in determining the optimal means of targetting specific regions of survey parameter space .",
    "we find that , for both surveys of targets at a single fixed distance and surveys over a population of homogeneously - distributed events , the prime consideration in maximizing the detection rate relates to the steepness of the luminosity distribution function . for distribution functions steeper than @xmath159 , the number of events at low luminosity merits an approach which surveys each field down to a sensitivity limit capable of detecting objects at the lowest end of the distribution .",
    "on the other hand , for shallower distributions the highest event rate is achieved by shifting the balance towards greater field of view at the expense of sensitivity .",
    "for @xmath196 it is advantageous to instead survey events down to an intermediate sensitivity , @xmath197 , and to survey a greater number of fields .",
    "the dependence on the slope of the luminosity function for a targetted survey can be understood as follows .",
    "the event detection rate is the result of interplay between the increase in the field of view , with which the number of events detected scales linearly , and the increase in sensitivity with time and the associated number of events detectable down to that sensitivity .",
    "the number of objects detectable per field scales as @xmath198 ( provided the survey has sufficient sensitivity to be in the regime @xmath199 ) , and the time required to reach this sensitivity scales as inverse square root of integration time , so the number of objects detected after an integration time @xmath200 on a single field is proportional to a term that scales as @xmath201 , where @xmath202 is a constant .",
    "now , if we subdivide the time into observations over @xmath2 separate fields , we see that there is a linear increase in event rate with the number of fields surveyed , but the number of events per field scales as @xmath203 .",
    "thus we see that when the index of the luminosity distribution is steeper than @xmath204 , the product of the rate per field and the number of fields is a declining function of @xmath2 , and the optimal strategy is to keep @xmath2 as small as possible by surveying a single field . on the other hand , for @xmath205",
    "the overall event rate is an increasing function of @xmath2 , at least for small @xmath2 , and thus the optimal strategy is to survey multiple fields of view .",
    "the formalism we have introduced in this paper allows us to address two further facets of survey strategy .",
    "the first relates to the spacing in time of observations of a given survey field , while the second relates to figures of merit for transients surveys .",
    "1 . there has been a considerable amount of qualitative discussion within the transients community concerning the most effective means of surveying the variable sky . a survey which revisits particular field in logarithmically - spaced time intervals",
    "is often espoused as optimal on the basis that it detects transients on a variety of timescales ( e.g. murphy et al.(2013 ) , section 4 ) . however ,",
    "if one seeks to optimize the event detection rate , the optimal strategy is to visit any given field on an interval no shorter than the event decoherence time so that no time is wasted redetecting all the slowest - timescale transients in the same field on multiple occasions .",
    "although the survey will have missed a number of shorter timescale transients in the same field in the meantime , it will have instead detected other short timescale transients while surveying other fields in the intervening time .",
    "an alternative argument might suggest that the logarithmic sampling approach is advantageous because it performs the dual role of detection and timescale characterization simultaneously .",
    "however , it is difficult to define a metric which quantifies the relative value of both detection and timescale characterization , because it forces one to identify the relative importance of these two dissimilar observational tasks .",
    "there are many other observables ( e.g. spectral index , brightness , polarization ) by which a transient may be characterised , and these may obviate the need for timescale characterization in certain circumstances .",
    "some assessments of the efficacy of transients surveys are based on a survey figure of merit which scales as @xmath206 ( cordes 2007 , 2009 ) .",
    "this metric is sometimes adopted as the standard for assessing the survey capabilities of next generation widefield telescopes , and is employed to compare telescope performance in the ska baseline design .",
    "this metric is appropriate for steady emission ( e.g. for steady continuum source and hi surveys ) and in quantifying the rate which a given telescope design can survey sky down to a limiting flux density @xmath12 .",
    "however , _",
    "the rate at which a transients survey detects events _ often exhibits a difference dependence on @xmath12 .",
    "it often scales as @xmath207 for surveys of fast transients ( see macquart 2011 ) , and eq.([ratehomog ] ) indicates that it similarly holds for survey of slow transients in which the events are distributed homogeneously in the survey volume . for a targetted survey , the event rate scales as @xmath208 .",
    "this distinction is important , because the metric based on event detection rate indicates a different relative importance between field of view and telescope sensitivity to that in common use .",
    "it bears implications for assessment of telescope designs ; a telescope designed to survey for transients based on a metric proportional to @xmath209 favours field of view over sensitivity more than one based on the metric @xmath15 .",
    "interestingly , in a targetted survey for events at a fixed distance , we find that the _ optimal _ detection rate does scale as @xmath190 .",
    "this result therefore provides a basis for connecting to some earlier metrics for surveys for transients ( e.g. cordes 2007 ) .",
    "however , we stress that this result only holds once the survey is optimized .",
    "it is possible to optimise slow transients surveys by slewing to multiple independent fields of view within a timescale less than the duration of each transient event and thus trade sensitivity against the total survey area .",
    "we consider an optimization specifically for slow events , namely ones whose duration exceeds the telescope dwell time ( see  [ sec : decoherence ] for a discussion of this point ) . at one extreme",
    "it may be optimal to integrate deeply on a small number of fields , and at the other extreme it may be optimal to conduct a shallow search across a large number of fields .",
    "the optimal tradeoff particularly depends on the steepness and upper and lower bounds of the luminosity function and the telescope sensitivity , and a summary of our results is as follows .    *",
    "_ surveys of homogenous populations : _ for a population of events distributed homogeneously throughout space , the optimum event rate occurs when the maximum number of independent fields of view visited is @xmath210 , where @xmath4 is the time taken to slew from one field to the next .",
    "this yields an enhancement over the single - field event detection rate of a factor of @xmath211 * _ surveys of quasi - homogeneous populations : _ for most homogeneously distributed populations , there is a minimum sensitivity which the survey must attain in order to detect the weakest event at the closest distance at which the events occur , @xmath89 , with @xmath212 corresponding to a completely homogeneous distribution .",
    "the optimal number of fields to survey lies in the range @xmath161 provided that the luminosity distribution function is shallower than @xmath204 ( neglecting telescope slewing ) .",
    "we present an equation to derive the optimal number of fields to survey in eq.([n4solns ] ) , which qualitatively behaves as follows . * * since the number of detections scales linearly with the number of fields of view surveyed , there is a balance between survey sensitivity and the total survey area that depends on the steepness of the luminosity function . for progressively steeper luminosity distributions ,",
    "more of the events occur at luminosities near @xmath80 , which biases the event detection rate in favour of searching a smaller number of fields more deeply . * * for luminosity distributions steeper than @xmath164 the best strategy is to survey only a single field : the maximum detection rate is attained by achieving the sensitivity required to detect all objects all the way down to @xmath80 in each field .",
    "conversely , for shallow luminosity distribution functions , there is progressively less benefit in surveying each field down to @xmath80 , and the optimal balance between sensitivity and field shifts in favour of field of view . *",
    "* the assumption of true homogeneity ( @xmath213 ) biases the survey to favour wider fields of view because the survey optimization in part reflects the fact that events may then occur arbitrarily close to the observer , which are best detected by surveying large fields of view at lower sensitivity . *",
    "_ surveys of targetted systems : _ for a survey of a system ( e.g. a galaxy or a cluster ) at a fixed distance , and neglecting slewing time , the optimal number of survey fields is given by @xmath214 for @xmath215 , and the associated detection rate is @xmath188 optimization of the survey strategy yields an enhancement in the event rate by a factor of @xmath216 compared to the detection rate for a single field ( eq.[ratetarget ] ) ) .",
    "however , for very steep luminosity functions , @xmath217 , the optimal strategy is one in which occurs at the point where the sensitivity satisfies @xmath218 . * in a survey which cycles between a set of fields it is useful to quantify the extent of overlapping event detections between successive visits to the same field .",
    "we present a formalism for quantifying this , and we examine cases in which the distribution of event durations follows gaussian and power - law distributions .",
    "event overlap considerations are important when eq.([nmaxagain ] ) implies @xmath9 and @xmath219 exceeds the time @xmath220 ; in this case the optimal strategy is instead to set @xmath195 .",
    "parts of this research were conducted by the australian research council centre of excellence for all - sky astrophysics ( caastro ) , through project number ce110001020 .",
    "in this appendix we evaluate the event decoherence function explicitly for a succession of events of durations @xmath31 with random start times @xmath30 .",
    "the autocorrelation of @xmath2 is obtained from eq.([ndefn ] ) as follows , @xmath221 where the operators @xmath222 and @xmath223 denote a fourier transform . now",
    "if the events are distributed randomly in time and there are no correlations in the occurrence times between separate events , then the second term contributes at most a value that is independent of @xmath51 , namely a constant .",
    "we see this by performing the average @xmath224 as follows .",
    "if the event times are evenly distributed over the interval @xmath225 $ ] then the probability distribution of @xmath226 is @xmath227 , and one has @xmath228 \\right\\rangle & = & \\frac{1}{{\\cal t}^2 } \\int_{-{\\cal t}/2}^{{\\cal t}/2 } \\int_{-{\\cal t}/2}^{{\\cal t}/2 }   dt_j dt_k   \\exp \\left [ - i \\omega ( t_j - t_k ) \\right ]   \\nonumber \\\\ & = & \\frac{2 - 2 \\cos { \\cal t } \\omega}{{\\cal t}^2 \\omega}.\\end{aligned}\\ ] ] thus the second term in @xmath229 is , after substituting in the expression for @xmath230 : @xmath231 \\left[\\frac{i}{\\omega } - \\frac{i   e^{i \\delta t_k \\omega } } { \\omega } \\right]^ * \\nonumber \\\\ & = & \\frac{1}{6 { \\cal t}^3 } \\sum_{j \\neq k }       \\left [ 6 { \\cal t } \\delta t_j \\delta t_k + t'^3 { \\rm sgn}(t ' ) - ( t'-\\delta t_j)^3 { \\rm sgn}(t'-\\delta t_j ) \\right .",
    "\\nonumber \\\\      & \\null & \\left .",
    "\\qquad - ( t'+\\delta t_k)^3 { \\rm sgn}(t'+\\delta t_k ) + ( t ' - \\delta t_j + \\delta t_k)^3 { \\rm sgn}(t'-\\delta t_j + \\delta t_k )         \\right ] \\nonumber \\\\ & \\null & \\underset{{\\cal t } \\rightarrow \\infty}{\\longrightarrow }   \\sum_{j \\neq k } \\frac{\\delta t_j \\delta t_k } { { \\cal t}^2 }   = \\frac{{\\cal n } ( { \\cal n}-1)}{{\\cal t}^2 } \\langle \\delta t_j \\delta",
    "t_k \\rangle =   \\frac{{\\cal n } ( { \\cal n}-1)}{{\\cal t}^2 } \\langle \\delta t \\rangle^2\\end{aligned}\\ ] ] where in the second line we have used the fact that @xmath232 and in the third line we have assumed that the durations @xmath233 are mutually independent .    in the limit in which @xmath234 , the autocorrelation reduces to the simple form , @xmath235 as we are interested in the correlations between different events , the quantity of interest here is the autocorrelation in the fluctuations in the number of events , @xmath34 , which is given by @xmath236 + \\frac{{\\cal n}({\\cal n}-1)\\langle \\delta t \\rangle^2}{{\\cal t}^2 } -   \\left ( \\frac{{\\cal n } \\langle \\delta t \\rangle}{\\cal t }   \\right)^2 \\nonumber \\\\ & = & \\left [ \\frac{1}{2 { \\cal t } } \\sum_j^{\\cal",
    "n } \\left ( |t+\\delta t_j |   + |t-\\delta",
    "t_j   | - 2 |t| \\right ) \\right ]   - { \\cal o } \\left ( \\frac{{\\cal n } \\langle \\delta t\\rangle^2}{{\\cal t}^2 } \\right ) .",
    "\\label{nacfapp}\\end{aligned}\\ ] ] we henceforth ignore the term @xmath237 , since this is much smaller than the first term .",
    "this result may be expressed in the equivalent form @xmath238   \\right].\\end{aligned}\\ ] ] this expression may be evaluated for various distributions of event durations @xmath25 .",
    "the calculation in section 2.1 for a set of homogeneously distributed events is only valid when the spacetime geometry is approximately euclidean .",
    "if the events occur at cosmological distances , the curvature of spacetime needs to be taken into account when computing the event rate . the foregoing formalism can be modified in a straightforward way to incorporate these effects as follows .    as before ,",
    "the maximum distance out to which an object of luminosity @xmath81 can be detected is @xmath239 where @xmath240 is interpreted as the luminosity distance , which can be related to the redshift of the burst , @xmath241 , by the following equation : @xmath242 for a concordance cosmology one has @xmath243 , @xmath244 and @xmath245 and @xmath246 .",
    "this luminosity distance corresponds to a comoving distance @xmath247 , so the number of events of between luminosities @xmath81 and @xmath82 detected down to a limiting flux density @xmath12 is @xmath248 .",
    "the event rate calculations now proceed the same as before , and we obtain the following generalization to equation ( [ ratehomog ] ) : @xmath249 where @xmath241 is the redshift that satisfies the equation @xmath250 .",
    "we note that our detection rate problem is encountered in other contexts in astrophysics : the problem identical to that encountered when considering number counts of quasars in flux - limited surveys ( see , e.g. , longair 1966 ; wall 1980 ; de zotti et al . 2010 ) .",
    "this event rate reduces to eq.([ratehomog ] ) when @xmath251 , however for @xmath252 cosmological effects become non - negligible . in this case evaluation of the integral in eq.([rtotgen ] ) is complicated by the fact that @xmath241 is a function of @xmath81 but can not be expressed in terms of @xmath81 in closed form .",
    "it therefore requires numerical evaluation of @xmath241 as a function of @xmath81 .    we might hope to gain some insight into the dependence of @xmath120 on @xmath12 for cosmological events using various approximations that relate @xmath241 to @xmath81 .",
    "to lowest order in @xmath241 , one has @xmath253 , so @xmath254 the analytical solution of this integral involves the hypergeometric function @xmath255 , and it does not yield any immediate further insight into the behaviour of the detection rate .",
    "further simplification is possible if one takes @xmath256 , for which , @xmath257 .\\end{aligned}\\ ] ]    bower , g.c . , saul , d. , bloom , j.s . ,",
    "bolatto , a. , filippenko , a.v . ,",
    "foley , r.j . & perley , d. 2007 , apj , 666 , 346 cordes , j.m . 2007 , the ska as a radio synoptic survey telescope : widefield surveys for transients , pulsars and eti , 14th edn . , ska memo 97 ( www.skatelescope.org/publications ) cordes , j.m .",
    "2009 , survey metrics , ska memo 109 ( www.skatelescope.org/publications ) croft , s. et al .",
    "2010 , apj , 719 , 45 de zotti , g. , massardi , m. , negrello , m. & wall , j. 2010 , ara&a , 18 , 1 fiedler , r.l .",
    "1987 , apjs , 65 , 319 frail , d.a . ,",
    "kulkarni , s.r .",
    ", ofek , e.o . ,",
    "bower , g.c .",
    "& nakar , e. 2012 , apj , 747 , 70 kedziora - chudczer , l. , jauncey , d.l . , wieringa , m.h . ,",
    "walker , m.a . ,",
    "nicholson , g.d . , reynolds , j.e . &",
    "tzioumis , a.k .",
    "1997 , apj , 490 , l9 longair , m.s .",
    "1966 , mnras , 133 , 421 lovell , j.e.j .",
    "et al . 2008 , apj , 689 , 108 macquart , j .-",
    ", 2011 , apj , 734 , 20 macquart , j .-",
    "de bruyn , a.g .",
    "2006 , a&a , 446 , 185 mooley , k.p . ,",
    "frail , d.a .",
    ", ofek , e.o . ,",
    "miller , n.a . ,",
    "kulkarni , s.r .",
    "& horesh , a. 2013 , apj , 768 , 165 murphy , t. et al . 2013 , pasa , 30 , 6 swinbank , j. 2007 , in bursts , pulses and flickering : wide - field monitoring of the dynamic radio sky , pos ( dynamic2007 ) 044 walker , m.a . , mnras , 294 , 307 wall , j.v .",
    "1980 , phil .",
    "a 296 , 367"
  ],
  "abstract_text": [
    "<S> we investigate the optimal tradeoff between sensitivity and field of view in surveys for slow radio transients using the event detection rate as the survey metric . </S>",
    "<S> this tradeoff bears implications for the design of surveys conducted with upcoming widefield radio interferometers , such as the askap vast survey and the meerkat trapum survey . </S>",
    "<S> we investigate ( i ) a survey in which the events are distributed homogeneously throughout a volume centred on the earth , ( ii ) a survey in which the events are homogeneously distributed , but are only detectable beyond a certain minimum distance , and ( iii ) a survey in which all the events occur at an identical distance , as is appropriate for a targetted survey of a particular field which subtends @xmath0 telescope pointings . for a survey of fixed duration , @xmath1 </S>",
    "<S> , we determine the optimal tradeoff between number of telescope pointings , @xmath2 , and integration time per field . </S>",
    "<S> we consider a population in which the event luminosity distribution follows a power law with index @xmath3 , and @xmath4 is the slewing time between fields or , for a drift scan , the time taken for the telescope drift by one beamwidth . </S>",
    "<S> several orders of magnitude improvement in detection rate is possible by optimization of the survey parameters . </S>",
    "<S> the optimal value of @xmath2 for case ( i ) is @xmath5 , while for case ( iii ) we find @xmath6^{2/(\\alpha-1)}$ ] , where @xmath7 is the maximum luminosity of a transient event and @xmath8 is the minimum luminosity event detectable in an integration of duration @xmath1 . </S>",
    "<S> ( the instance @xmath9 in ( iii ) implies re - observation of fields over the survey area , except when the duration of transient events exceeds that between re - observations of the same field , where @xmath10 applies instead . ) </S>",
    "<S> we consider the balance in survey optimization between telescope field of view , @xmath11 , and sensitivity , characterized by the minimum detectable flux density , @xmath12 . for homogeneously distributed events ( i ) , the detection rate scales as @xmath13 , while for targetted events ( iii ) it scales as @xmath14 . </S>",
    "<S> however , if the targetted survey is optimized for @xmath2 the event detection rate scales instead as @xmath15 . </S>",
    "<S> this analysis bears implications for the assessment of telescope designs : the quantity @xmath15 is often used as the metric of telescope performance in the ska transients literature , but only under special circumstances is it the metric that optimizes the event detection rate .    </S>",
    "<S> techniques : radio astronomy  surveys </S>"
  ]
}