{
  "article_text": [
    "many applications such as agriculture , wind energy production or aviation require accurate and reliable forecasts of wind speed .",
    "wind speed predictions are usually based on output from numerical weather prediction ( nwp ) models which describe the dynamical and physical behavior of the atmosphere through nonlinear partial differential equations .",
    "historically , single runs of nwp models with the best available initial conditions were used to obtain single - valued predictions of the future state of the atmosphere . however , such deterministic forecasts fail to account for uncertainties in the initial conditions and the numerical model . therefore , nwp models are nowadays often run several times with varying initial conditions and/or numerical representations of the atmospheric processes , resulting in an ensemble of forecasts @xcite .",
    "since the first operational implementation by the european centre for medium - range weather forecasts ( ecmwf , see * ? ? ?",
    "* for a description of the current version ) , the generation of ensemble forecasts has become standard practice in meteorology .",
    "all major national meteorological services operate their own ensemble prediction systems ( epss ) as for example the pearp eps of mteo france @xcite or the cosmo - de eps of the german meteorological service @xcite .",
    "recent developments in ensemble forecasting include multi - model ensemble prediction systems such as the thorpex interactive grand global ensemble ( tigge , * ? ? ?",
    "* ) where several single - model ensembles each based on multiple runs of individual nwp models are combined , see , e.g. , @xcite .",
    "another example is the grand limited area model ensemble prediction system ( glameps , * ? ? ?",
    "* ) considered in this article which is described in more detail in section [ sec : sec2 ] .    generally , probabilistic forecasts , i.e. , forecasts given in the form of full probability distributions , are desirable as they allow for a quantification of the uncertainty associated with the prediction .",
    "probabilistic forecasts further allow for optimal decision making since optimal deterministic forecasts can be obtained as functionals of the forecast distributions @xcite .",
    "this is particularly important for applications such as wind power forecasting for auction processes in electricity markets where the optimal bidding strategy depends on permanently changing features of the market conditions @xcite .",
    "while the implementation of ensemble prediction systems is an important step in the transition from deterministic to probabilistic forecasting , ensemble forecasts are finite and do not provide full predictive distributions .",
    "further , ensemble forecasts generally tend to be underdispersive and subject to systematic bias , and thus require some form of statistical postprocessing @xcite .",
    "various methods for statistical postprocessing of ensemble forecasts have been developed over the last years , for recent reviews and comparisons , see , e.g. , @xcite .",
    "state of the art techniques include bayesian model averaging ( bma ; * ? ? ?",
    "* ) and ensemble model output statistics ( emos ) or non - homogeneous regression @xcite .",
    "both approaches provide estimates of the future distributions of the weather variables of interest and are partially implemented in the ensemblebma and ensemblemos packages for the statistical programming language r @xcite .    in the case of bma",
    ", the predictive probability density function ( pdf ) of a future weather quantity is a weighted mixture of individual pdfs corresponding to the members of the ensemble , where the weights are determined by the relative performance of the ensemble members during a given training period .",
    "the bma models for various weather quantities differ in the pdfs of the mixture components . for wind speed ,",
    "@xcite suggest the use of a gamma mixture , whereas @xcite considers bma component pdfs following a truncated normal ( tn ) rule .",
    "the emos approach is conceptually simpler , the predictive pdf is given by a single parametric distribution with parameters depending on the ensemble members .",
    "over the last years , emos models have been developed for calibrating ensemble forecasts of various weather variables such as temperature and sea level pressure @xcite , wind speed @xcite and precipitation @xcite .",
    "the parameters of the forecast distributions are typically estimated by minimizing proper scoring rules evaluated at forecasts and verifying observations over rolling training periods consisting of the preceding @xmath0 days @xcite . for selecting the corresponding training sets ,",
    "two basic approaches are given by local and regional methods .",
    "in the local approach , only forecast cases from the single observation station of interest are considered for the parameter estimation , whereas in the regional approach , data from all available observation stations are composited to form a single training set for all stations .",
    "local estimation generally results in better predictive performance ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , however , is often problematic if only limited amounts of training data are available . on the other hand ,",
    "there are typically no numerical stability issues in regional parameter estimation , however , in case of large ensemble domains it is undesirable to obtain a single set of coefficients for all observation stations due to the potentially significant differences in the climatological properties of the observation stations and forecast errors of the ensemble .",
    "we apply the truncated normal emos model of @xcite for statistical postprocessing of wind speed forecasts of the 52-member glameps ensemble .",
    "the glameps ensemble covers a large domain across europe and northern africa , however , only a short period of data is available .",
    "we propose two similarity - based semi - local approaches to parameter estimation in order to account for these challenges .",
    "a distance - based approach uses data from stations with similar characteristics to augment the training data for a given stations and follows ideas of @xcite .",
    "our novel clustering - based approach employs @xmath1-means clustering to obtain groups of similar observation stations with respect to various features which then form shared training sets for parameter estimation .",
    "the remainder of this article is organized as follows . in section [ sec : sec2 ] , we introduce the glameps ensemble and the observation data . in section",
    "[ sec : sec3 ] , we review the truncated normal emos model and propose similarity - based semi - local approaches to parameter estimation based on distance functions and clustering . in section",
    "[ sec : sec4 ] , we report the results of the case study based on the glameps data .",
    "we conclude with a discussion in section [ sec : sec5 ] .",
    "the glameps ensemble is a short - range multi - model eps launched in 2006 as a part of the cooperation between the aladin and hirlam consortia .",
    "it operates on a large domain covering europe , north - africa and the northern atlantic and the currently running version 2 ( glamepsv2 ) is a combination of the subensembles from two versions of the alaro model ( isba and surfex schemes , see , e.g. , @xcite and @xcite ) and two version of the hirlam model ( kain - fritsch and straco schemes , see , e.g. , @xcite and @xcite ) .",
    "each subensemble consists of @xmath2 perturbed members and a control forecast , and half of the perturbed members are lagged by 6h @xcite .",
    "our data base contains 52 ensemble members of 18h ahead forecasts of 10-m wind speed for 1738 observation sites ( see figure [ fig : fig1]a ) together with the corresponding validating observations for october 2  november 25 , 2013 , and february 2  may 18 , 2014 .",
    "we divide the available data into two equally large periods from october 2013 to february 2014 and from march 2014 to may 2014 in order to allow for rolling training periods of sufficient length .",
    "the forecasts are evaluated over the second period .",
    "data from the first period are used to obtain training periods of equal lengths for all days , and to estimate the similarities between the stations used in the distance - based semi - local approach to parameter estimation , see section [ sec : sec3 ] for details .",
    "while @xcite apply bma to calibrate temperature forecasts of the glameps ensemble , the article at hand is the first application of postprocessing techniques to the corresponding wind speed forecasts to the best of the authors knowledge .",
    "figure [ fig : fig1]b shows the verification rank histogram of the raw ensemble .",
    "this is the histogram of ranks of validating observations relative to the corresponding 52 ensemble member forecasts over the verification period ( see , e.g. , * ? ? ?",
    "* section 7.7.2 ) . for a calibrated ensemble ,",
    "forecasts and observations should be exchangeable and all observed ranks should thus be equally likely and follow a uniform distribution corresponding to the dashed line in figure [ fig : fig1]b .",
    "the u - shaped verification rank histogram of the glameps ensemble indicates that the glameps forecasts lack calibration and are underdispersive , i.e. , too many observations fall outside the ensemble range .",
    "this deficiency can be observed for various ensemble prediction systems , see , e.g. , @xcite .",
    "as discussed in the introduction , the goal of ensemble postprocessing is to correct for biases and dispersion errors in nwp model output .",
    "the emos approach uses a single parametric distribution to model the pdf of the future weather quantity , where the parameters depend on the ensemble members . in case of the wind speed",
    "this pdf should be concentrated on the non - negative values . here",
    "we apply the truncated normal emos model introduced by @xcite , however , alternative emos models utilizing a generalized extreme value distribution @xcite and a log - normal distribution @xcite are available and have also been tested .",
    "as these alternative choices do not offer substantial improvements for the data at hand , we limit our discussion to results for the tn model and note that similar conclusions apply for the alternative emos approaches .",
    "the pdf of the tn distribution with location @xmath3 , scale @xmath4 , and cut - off at zero , denoted by @xmath5 , is given by @xmath6 where @xmath7 and @xmath8 are the pdf and the cumulative distribution function ( cdf ) of the standard normal distribution , respectively .",
    "the emos predictive distribution proposed by @xcite is @xmath9 where @xmath10 denote the ensemble of distinguishable forecasts of wind speed for a given location and time , and @xmath11 denotes the ensemble mean .",
    "location parameters @xmath12 and scale parameters @xmath13 of model can be estimated from the training data consisting of ensemble forecasts and verifying observations from the preceding @xmath0 days by optimizing an appropriate verification score ( see section [ subs : subs3.2 ] ) .",
    "however , in case of the glameps ensemble , similar to the majority of the currently used ensemble prediction systems such as the ecmwf ensemble or the pearp eps of mteo france , some of the ensemble members are generated with the help of perturbations of the initial conditions simulating model uncertainties .",
    "this should be incorporated into the model formulation since these exchangeable members are assumed to be statistically indistinguishable .    in what follows , if we have @xmath14 ensemble members divided into @xmath15 groups of exchangeable members , where the @xmath1th group contains @xmath16 ensemble members ( @xmath17 ) , notation @xmath18 is used for the @xmath19th member of the @xmath1th group . in this situation ensemble members within a given group share the same coefficient of the location parameter @xcite resulting in the predictive distribution @xmath20 where again , @xmath21 denotes the ensemble variance .",
    "model formulations that take into account the grouping in modeling the variance have also been investigated , but result in a reduction of the predictive performance @xcite .",
    "as argued concisely by @xcite , the general goal of probabilistic forecasting should be to maximize the sharpness of the predictive distribution subject to calibration . while calibration is a notion of statistical consistency between the predictive distribution and the observation ,",
    "sharpness is a property of the forecasts only and refers to the information content in the forecast distribution .",
    "calibration of emos post - processed forecasts can be assessed using probability integral transform ( pit ) histograms .",
    "the pit is the value of the predictive cdf evaluated at the verifying observations @xcite and the closer the histogram to the desired uniform distribution , the better the calibration .",
    "pit histograms can be seen as continuous analogues of verification rank histograms , see section [ sec : sec2 ] .",
    "further , one can also investigate the coverage of the central prediction interval corresponding to the nominal coverage of the raw ensemble which is @xmath22 or @xmath23 for the glameps ensemble .",
    "the coverage of a @xmath24 central prediction interval is the proportion of validating observations located between the lower and upper @xmath25 quantiles of the predictive distribution . for a calibrated probabilistic forecast this value should be around @xmath26 and the choice of @xmath27 corresponding to the nominal coverage",
    "allows direct comparison to the raw ensemble .",
    "given the predictive distribution is calibrated , it should be as sharp as possible , where sharper distributions correspond to narrower central prediction intervals .",
    "proper scoring rules assign numerical values to pairs of forecasts and observations and can be used to assess calibration and sharpness simultaneously @xcite .",
    "the most popular scoring rules providing summary measures of predictive performance are the logarithmic score , i.e. , the negative logarithm of the predictive pdf evaluated at the verifying observation , and the continuous ranked probability score ( crps ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) . given a predictive cdf @xmath28 and an observation @xmath29 , the crps is defined as @xmath30 where @xmath31 denotes the indicator of a set @xmath32 , while @xmath33 and @xmath34 are independent random variables with cdf @xmath35 and finite first moment . in case of ensemble forecasts ,",
    "the predictive cdf is given by the empirical cdf of the ensemble .",
    "the crps can be expressed in the same unit as the observation and both scores are proper scoring rules which are negatively oriented , i.e. smaller scores indicate better predictive performance .    following the optimum score estimation approach of @xcite ,",
    "proper scoring rules can be utilized in parameter estimation by minimizing the average value of a proper scoring rule over a training set . in this way",
    "the optimization with respect to the logarithmic score corresponds to the classical maximum likelihood ( ml ) estimation of the parameters . in case of a truncated normal predictive distribution",
    "the crps has a closed form ( see , e.g. , * ? ? ? * ) which allows for an efficient parameter estimation based on optimizing the mean crps .",
    "point forecasts given by the median value of the predictive distribution are evaluated using the mean absolute error ( mae ) quantifying the deviation from the corresponding validating observations to assess the deterministic predictive accuracy .",
    "note that the median value is the optimal point forecast under the mae @xcite .      in general ,",
    "the coefficients of the tn emos model are estimated by minimizing the mean crps of the predictive distributions over suitably chosen rolling training periods consisting of the preceding @xmath0 days .",
    "there exist two basic approaches for selecting the training data @xcite .",
    "the regional ( or global ) approach composites ensemble forecasts and validating observations from all available stations during the rolling training period .",
    "therefore , one obtains a single universal set of parameters across the entire ensemble domain , which is then used to produce the forecasts at all observation sites . in case of the glameps ensemble",
    "this means that a single set of coefficients is used for the wide - ranging domain and the geographical and climatological variability might thus not be sufficiently taken into account . while the regional approach to parameter estimation can be implemented without numerical stability issues and offers slight gains in predictive performance compared to the raw ensemble ( see section [ sec : sec4 ] ) , there is room for further improvement for large and heterogeneous domains .",
    "by contrast , the local approach produces distinct parameter estimates for different stations by using only the training data of the given station .",
    "local models typically result in better predictive performance compared to regional models ( see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , however , these training sets contain only one observation per day and the estimation of local emos models thus requires significantly longer training periods to avoid numerical stability issues .",
    "for example , in model with @xmath2 exchangeable groups ( which is the case for the glameps ensemble , see section [ sec : sec4 ] ) the number of free parameters to be estimated is @xmath36 , making the use of local emos impossible for small data sets such as the one considered in this article . in a recent case study on emos models for the ecmwf ensemble , @xcite find that training period lengths between 365 and 1816 days give the best results for local parameter estimation . for the glameps data at hand ,",
    "choosing such long training periods is impossible as the whole data set consists of only 161 days .",
    "we propose two alternative similarity - based semi - local approaches which avoid the problems that make both regional and local estimation of the emos coefficients undesirable for the glameps data .",
    "the basic idea of the semi - local methods is to combine the advantages of regional and local estimation by augmenting the training data for a given station with data from stations with similar characteristics .",
    "the choice of similar stations is either based on suitably defined distance functions , or on clustering .",
    "following @xcite , the training sets of a given station are increased by including training data from other stations with similar features .",
    "the similarity between stations is determined based on suitably defined distance functions with @xmath37 .",
    "distance functions can thus be seen as negatively oriented similarity measures with smaller values indicating more similar characteristics of the stations of interest . ] .",
    "note that compared to @xcite , we consider alternative choices of distance functions , and our forecasts are evaluated over a set of observation stations whereas the forecasts and analysis data used by @xcite are given on a grid .",
    "different conclusions may apply for grid - based data .",
    "generally , the distance between two stations @xmath38 and @xmath39 denoted by @xmath40 with @xmath41 is determined using the first period of available data from october 2013 to february 2014 which is distinct from the verification period . in the semi - local estimation of the emos model for a given station @xmath42",
    ", we then add the corresponding forecast cases in the rolling training period from the @xmath43 most similar stations , i.e. , the @xmath43 stations with the smallest distances @xmath44 .",
    "alternatively , one could also iteratively determine the similarities anew in every rolling training period .",
    "however , this approach requires lots of computational resources as all pair - wise distances between stations have to be re - computed for every training period ( up to symmetry ) , and is thus infeasible due to the large number of observation stations .",
    "in particular , note that already the simple distance - based semi - local model estimation with a fixed set of distances is computationally more demanding compared to local parameter estimation which arises as special case for @xmath45 . furthermore , initial tests did not indicate significant improvements in the predictive performance for the glameps data , we thus limit our discussion to the use of the first period of data for determining the similarities between stations for the distance - based approach .",
    "we investigate the following five distance functions .",
    "_ distance 1 : geographical locations_. the distance between stations @xmath38 and @xmath39 is given by the euclidean distance of the locations @xmath46 and @xmath47 of the two stations , i.e. , @xmath48 the euclidean distance is employed here since the station locations in the data set are given on the linearly transformed model estimation grid .",
    "in general , the spherical or great - circle distance is a more appropriate distance measure for actual geographical locations on the globe .",
    "_ distance 2 : station climatology_. let @xmath49 denote the empirical cdf of wind speed observations at station @xmath38 over the first period of data . similar to the distance function proposed by @xcite , the distance to station @xmath39",
    "is given by the normalized sum over the absolute differences of the respective empirical cdfs @xmath49 and @xmath50 evaluated at a set of fixed values @xmath51",
    ", i.e. , @xmath52 where @xmath53 denotes the cardinality of @xmath51 . here ,",
    "we choose @xmath54 and note that the obtained similarities are robust to minor changes in the definition of @xmath51 .",
    "_ distance 3 : ensemble forecast errors_. denote the ensemble mean for station @xmath38 and date @xmath55 by @xmath56 and the corresponding verifying observation by @xmath57 then the forecast error @xmath58 of the ensemble mean is given by @xmath59 the third distance function is based on the distribution of these forecast errors . to that end",
    ", we define the empirical cdf of the forecast errors at station @xmath38 as @xmath60 where @xmath61 denotes the set of dates in the first period of data .",
    "the distance between two stations @xmath38 and @xmath39 is then given by @xmath62 where @xmath63 denotes the set of fixed values at which the empirical cdfs of the forecast errors are evaluated .",
    "as before , the obtained sets of similar stations are robust to changes of @xmath64 .",
    "_ distance 4 : combination of distance 2 and 3_. we add up the values of distances 2 and 3 to define a distance function which depends on both the climatology of the observations as well as the distribution of the forecast errors of the ensemble , i.e. , with the above notation , @xmath65    _ distance 5 : ensemble characteristics_. @xcite proposes a similarity - based implementation of the shaake shuffle using a distance function that depends on summary statistics of the ensemble .",
    "with @xmath56 and @xmath66 denoting the mean and standard deviation of the ensemble member forecasts at station @xmath38 and date @xmath67 , the distance between station @xmath38 and @xmath39 is given by @xmath68 where @xmath69 again denotes the set of dates during the first period of data .",
    "+    figure [ fig : distances - illustration ] illustrates the five distance functions for two of the observation stations by displaying the 100 most similar stations in a specific color each . for both stations",
    ", a portion of the sets of most similar stations measured by two or more distance functions overlaps . see figure [ fig : appendxfig1 ] in the appendix for individual plots for the five distance functions and the two stations .    for the station at ouessant ( figure [ fig : distances - illustration]a ) which is located on the north - western coast of france",
    ", it can be observed that the 100 most similar stations measured by the distance functions depending on the distribution of the observations and forecast errors ( distances 24 ) are mostly located at coastal regions and islands in northern europe , in particular if these characteristics are combined ( distance 4 ) . by contrast",
    ", the most similar stations to the observation site at vienna ( figure [ fig : distances - illustration]b ) are distributed over continental central europe , mostly located in france , germany and poland .    as implied by the definition ,",
    "the most similar stations measured by distance 1 ( and due to the large overlap also by distance 5 ) are located in close geographical proximity around the two observation sites . due to the differences in the density of the observation station network ,",
    "the stations similar to the reference station at ouessant are spread out over larger geographical distances compared to the respective stations similar to the one at vienna .",
    "therefore , data from stations with potentially significantly different climatological properties might be added to the training sets for parameter estimation .",
    "further , as an alternative to the distance - based approach we propose a novel semi - local approach based on cluster analysis . here , the observation sites are grouped into clusters , and parameter estimation is performed for each cluster individually using only ensemble forecasts and validating observations at stations within the given cluster . to determine the clusters of observation stations we apply @xmath1-means clustering ( see , e.g. , * ? ? ?",
    "* ) to various choices of feature sets which are based on climatological characteristics of the observation stations and the distribution of forecast errors , and are described in more detail below .    in comparison to the distance - based method ,",
    "the clustering - based semi - local approach is computationally much more efficient , as the parameter estimation is only performed for @xmath1 distinct training sets for each given day , whereas the distance - based approach requires individual estimation of the coefficients at each of the 1738 stations with partially overlapping training sets .",
    "further , the similarities between the observation stations are obtained in a more efficient way as clustering is computationally less demanding compared to the computation of pair - wise distances between all observation stations ( up to symmetry ) . ] . in particular , clustering - based semi - local estimation is also computationally more efficient than local parameter estimation which arises as a special case with @xmath70 clusters of size 1 each .",
    "the above discussion does not account for the computational costs of the actual clustering . however , there exist efficient algorithms for @xmath1-means clustering , e.g. , the hartigan - wong algorithm @xcite , which converge rapidly for the data at hand .",
    "the costs of the actual clustering are thus negligible compared to the computational costs of the numerical parameter estimation .    in contrast to the distance - based approach , this allows for iteratively determining the clusters anew in every training period without a significant increase in the overall computational costs .",
    "this adaptive approach will be pursued for all clustering - based semi - local models discussed below .",
    "we denote the number of features used in the @xmath1-means clustering procedure by @xmath71 and consider the following feature sets .",
    "_ feature set 1 : station climatology_. let @xmath72 denote the empirical cdf of the wind speed observations at station @xmath38 over the rolling training period consisting of the preceding @xmath0 forecast cases at this station .",
    "the feature set for station @xmath38 is given by the set of equidistant quantiles of @xmath72 at levels @xmath73 .",
    "_ feature set 2 : forecast errors_. denote the empirical cdf of forecast errors @xmath58 by @xmath74 . with a slight abuse of the above notation",
    ", the set @xmath69 in the expression @xmath75 denotes the preceding @xmath0 dates as the clusters are iteratively determined anew in every rolling training period . the feature set for station @xmath38",
    "is then given by the set of equidistant quantiles of @xmath76 at levels @xmath73 .",
    "_ feature set 3 : combination of feature sets 1 and 2_. to define a feature set that depends on both the station climatology and the distribution of forecast errors , we combine equidistant quantiles of @xmath72 at levels @xmath77 and equidistant quantiles of @xmath76 at levels @xmath78 into one single set of size @xmath79 , where @xmath80 and @xmath81 are defined as follows .",
    "if @xmath71 is an even number , let @xmath82 , otherwise let @xmath83 and @xmath84 .",
    "alternative choices of feature sets where the geographical location of the observation stations is included in the definition have also been investigated , but result in a reduction of the predictive performance and are thus omitted in the following discussion .",
    "figure [ fig : clustering - illustration ] illustrates the obtained clusters of observation stations for the different feature sets with a fixed number of @xmath85 clusters . for the feature set defined in terms of the distribution of the observations ( feature set 1 , figure [ fig : clustering - illustration]a ) , one can observe two larger clusters distributed over central europe , where one cluster mainly contains stations in germany and france , while the other one contains most of the stations in the alps and continental eastern europe .",
    "the remaining clusters are predominantly centered around the united kingdom and coastal regions of france and northern europe .",
    "if the clusters are determined based on forecast errors ( feature set 2 , figure [ fig : clustering - illustration]b ) , the stations are mainly grouped into three almost equally large clusters , where the most notable difference compared to the fist feature set is the predominant presence of the third cluster in north - eastern europe .",
    "further , the stations in the united kingdom and coastal regions of europe now mostly belong to the two biggest clusters rather than forming separate sets .",
    "clustering based on a combination of the distribution of the observations and forecast errors ( feature set 3 , figure [ fig : clustering - illustration]c ) results in a pattern of cluster memberships in between the other two choices . in particular , the alpine regions , continental europe and the coastal regions and the united kingdom",
    "show the most clear - cut separation compared to the other feature sets .",
    "as discussed in section [ subs : subs3.1 ] , the link functions connecting the parameters of the predictive distribution of the emos models and the ensemble forecasts depend on the stochastic properties of the ensemble .",
    "the glameps ensemble consists of four subensembles which differ in the choice of numerical model and parametrization scheme .",
    "each subensemble contains a control and @xmath86 ( non - lagged and lagged ) perturbed members .",
    "this induces a natural grouping into twelve groups : @xmath87    the members within each individual group are exchangeable and should share a common set of emos coefficients , resulting in a predictive tn distribution with location @xmath88 and scale @xmath89 , which is a special case of model .",
    "this model has a total number of @xmath36 parameters to be estimated and will be referred to as _",
    "full model_.    a natural simplification is to assign the same parameter values to the lagged and non - lagged exchangeable ensemble members of a subensemble , which results in a reduced model with location @xmath90 and @xmath91 parameters to be estimated .",
    "this model will be referred to as _ lag - ignoring model_.    finally , we also investigate the fully exchangeable situation where the existence of the aforementioned groups is ignored , and all ensemble members are assumed to form a single exchangeable group . in this case the predictive distribution is given by @xmath92 where again , @xmath11 denotes the ensemble mean , and we refer to this model as _ simplified model_.      both semi - local parameter estimation techniques require the choice of various tuning parameters given by the length of the rolling training period , the number of similar stations to be taken into account , the number of features and the number of clusters .",
    "we now discuss the effect of these tuning parameters on the predictive performance of the forecast models . to that end , the full , lag - ignoring and simplified model were estimated using the distance - based and clustering - based semi - local parameter estimation techniques described in section [ subs : subs3.3 ] .",
    "conclusions are drawn based on the mean crps over the evaluation period .",
    "for comparison , note that the average crps values of the glameps ensemble and the best regional tn model with a training period of 80 days are 1.058 and 0.955 , respectively .    due to numerical stability issues in the parameter estimation ,",
    "a comparison to local tn models is impossible , an estimate of the average crps of the locally estimated simplified tn model with a training period of 80 days can be obtained if the problematic parameter estimates ( around 0.1% of the total number of forecast cases ) are replaced by corresponding estimates from preceding forecast cases .",
    "this estimate of the average crps of the local simplified model with such subsequent modifications equals 0.790 ( see section [ subs : subs4.3 ] ) .       on the predictive performance of the distance - based semi - local models for three choices of training period lengths @xmath0 ( in days ) . missing line segments indicate unsuccessful parameter estimation for these choices of tuning parameters.,title=\"fig:\",scaledwidth=99.0% ] .    in the distance - based semi - local approach to parameter estimation ,",
    "the size of the training set for a given station @xmath38 is increased by including corresponding training data from the @xmath43 most similar stations , i.e. , the @xmath43 stations with the smallest distances @xmath93 .",
    "note that for the distance functions defined in section [ subs : subs3.3 ] , @xmath37 , a value of , e.g , @xmath94 thus means that the training set for station @xmath38 consists of data from this station , and of data from the 4 stations with the smallest distances to station @xmath38 .",
    "figure [ fig : tuningpar - l - distbased ] illustrates the effect of the number of close stations on the predictive performance measured as mean crps of the three proposed models for selected lengths of the training period . due to the large overlap of close stations determined by distance functions 1 and 5 ( see , e.g. , figure [ fig : distances - illustration ] ) we omit the corresponding plots for distance 5 which closely resemble the plots for distance 1 and remark that similar conclusions apply , in particular for small values of @xmath43 .",
    "note the varying scales of the plots in the first and second row of figure [ fig : tuningpar - l - distbased ] caused by the different predictive performances of the respective models .",
    "for distance 1 which is based on geographical locations , the predictive performance generally decreases with the number of similar stations added to the training sets , except for the more complex lag - ignoring and full models and shorter training periods , where the best crps values are attained for values around @xmath95 .",
    "clearly , the inclusion of similar stations then allows for unproblematic parameter estimation , but as few stations as possible should be chosen in order to achieve results as close as possible to the desirable ( however , even for long training periods impossible ) local parameter estimation .",
    "similar conclusions apply for the climatology - based distance 2 , however , the predictive performance of these models is notably better .",
    "a different pattern emerges for distance 3 which is based on the distribution of forecast errors . particularly for the more complex lag - ignoring and full model ,",
    "the best predictive performances are achieved with choices of @xmath43 between 10 and 30 , depending on the length of the training periods , whereas smaller values of @xmath43 result in worse predictions .",
    "note that with these choices of @xmath43 , the predictive performance of the semi - local models is better than the estimate of the predictive performance for the ( simplified ) local model . for distance 4 , a combination of distance functions 2 and 3 , similar conclusions apply with optimal values of @xmath43 between 10 and 25 .",
    "semi - local models based on this similarity measure show the best predictive performance and are also able to outperform the simplified local tn model for a wide range of tuning parameter choices .",
    "the effect of the length of the rolling training periods consisting of the preceding @xmath0 days can also be seen from figure [ fig : tuningpar - l - distbased ] where each individual plot contains three different choices of @xmath0 .",
    "together with further investigations of plots of the average crps against the employed training period lengths ( not shown ) , one can observe that @xmath0 only has a small effect on the predictive performance of the models .",
    "for all considered distance functions , the predictive performance increases with longer training periods , in particular for the more complex models and smaller values of @xmath43 .",
    "this is to be expected from the smaller size of the training sets as parameter estimation becomes problematic for shorter training periods and few additional forecast cases from similar stations taken into account .",
    "the simplified models show a slight decrease in predictive performance for training periods longer than 4050 days , however , the differences are negligible compared to those between models based on varying choices of distance functions or varying numbers of similar stations taken into account .",
    "the overall best predictive performances across the three considered model formulations are achieved with training period lengths of 80 days .       on the predictive performance of clustering - based semi - local models for three choices of training period lengths @xmath0 ( in days ) .",
    "all models are estimated with feature sets of size @xmath96 .",
    "missing line segments indicate unsuccessful parameter estimation for these choices of tuning parameters . ]    in the clustering - based semi - local approach @xmath1-means clustering based on the different feature sets ( discussed in section [ subs : subs3.3 ] ) is employed to group the observation stations into clusters .",
    "the lower computational costs of this approach allow for iterative computation of the clusters in every training period , whereas the similarities between stations used in the distance - based semi - local approach are computed over a fixed period of data from october 2013 to february 2014 preceding the verification period .",
    "this adaptive application of @xmath1-means clustering leads of improvements in mean crps of around 1 - 5% compared to the use of a fixed set of clusters determined over the first period of available data .",
    "figure [ fig : tuningpar - k - clustering ] illustrates the effect of the number of clusters @xmath1 on the predictive performance of the clustering - based semi - local models .",
    "choosing @xmath97 obviously corresponds to regional parameter estimation .",
    "for all three feature sets considered here , the predictive performance increases for larger values of @xmath1 up to around 100 clusters except for shorter training periods . clearly , a larger number of clusters allows for a more refined grouping into sets of observation stations with similar characteristics .",
    "the predictive performance decreases for all considered models and training period lengths if much more than @xmath98 clusters are used .",
    "this behavior is to be expected as the clusters become smaller and parameter estimation becomes numerically unstable , particularly for the lag - ignoring and full models . note that depending on training period length and feature set , only small improvements can be observed for @xmath1 exceeding values of around 40 to 70 clusters .    as observed for the distance - based models , the clustering - based semi - local models defined in terms of the distribution of forecast errors and the station climatology ( feature sets 2 and 3 ) are able to outperform the local model over a wide range of tuning parameter choices except for short training periods .",
    "the worse predictive performance for shorter training periods is to be expected as the smaller amount of forecasts cases used to determine the clusters might result in a less accurate partitioning of the observation stations .",
    "compared to the distance - based approach it can be observed that for some numbers of clusters , training period lengths below 80 days are optimal , in particular for the lag - ignoring and full model .",
    "however , in comparison to the effect of different choices of feature sets the effect of the length of the training period is negligible .     on the predictive performance of clustering - based semi - local models for three choices of numbers of clusters @xmath1 .",
    "all models are estimated over a training period of 80 days .",
    "missing line segments indicate unsuccessful parameter estimation for these choices of tuning parameters . ]",
    "thus far , all clustering - based semi - local models shown in figure [ fig : tuningpar - k - clustering ] were estimated for a fixed feature set size of @xmath96 . to illustrate the effect of @xmath71 on the predictive performance , figure [ fig : tuningpar - n - clustering ] shows the average crps of the clustering - based models as functions of the number of features @xmath71 considered in @xmath1-means clustering for three choices of @xmath1 .",
    "given that sufficiently many features ( around 5 - 10 depending on the other tuning parameters ) are used , the feature set size has only a small effect on the predictive performance compared to different choices of @xmath1 or @xmath0 .",
    "reasons for this behavior clearly include the aforementioned robustness of the obtained cluster memberships with regards to @xmath71 .",
    "the best results across all considered tuning parameter combinations are generally obtained for feature set sizes between 20 and 40 thus justifying our previous choice of @xmath96 .",
    "the predictive performance of the semi - local models is evaluated by computing the verification scores introduced in section [ subs : subs3.2 ] over the verification period march 1  may 18 , 2014 .",
    "we use the local climatological forecasts given by the observations at the corresponding station during the rolling training periods , the raw glameps ensemble predictions , and probabilistic forecast by the regional tn model as benchmark models .",
    "while locally estimated models are desirable , the estimation of these models is highly problematic for the glameps data due to the issues discussed earlier . even for the simplified model with a maximum training period length of 80 days ,",
    "numerical issues occur in the local parameter estimation , e.g. , some shape parameters are estimated to be 0 .",
    "an estimate of the predictive performance of the local model can be obtained by replacing these problematic parameter estimates by the preceding ones . however , note that these subsequent adjustments are not necessary for the semi - local or regional models .",
    "further , neither the lag - ignoring nor the full local tn model can be successfully estimated as the employed numerical optimization algorithms fail to converge or produce numerical errors .    in the interest of brevity",
    ", we limit our discussion to the simplified and the lag - ignoring models . it can be seen from figures [ fig : tuningpar - l - distbased][fig : tuningpar - n - clustering ] that the full semi - local models generally result in slightly worse predictive performance compared to the lag - ignoring models , therefore the additional computational costs of taking into account the lagging in the subensembles are not justified .",
    "note that different conclusions may apply for other ensemble prediction systems with lagged members .    with regards to the tuning parameters for the semi",
    "- local approaches , we employ a fixed training period length of 80 days , and use a fixed number of @xmath96 features for @xmath1-means clustering to ensure comparability across the different models .",
    "for the individual distance - based and clustering - based semi - local models we then choose suitable values for the number of most similar stations @xmath43 and the number of clusters @xmath1 from figures [ fig : tuningpar - l - distbased][fig : tuningpar - n - clustering ] ( see section [ sec:4-tuningpar ] for a detailed discussion of the effect of these tuning parameters ) . while the chosen tuning parameter combinations might not be the overall optimal values for the individual models , the results hold for a wide range of tuning parameter choices as indicated by the sensitivity considerations in section [ sec:4-tuningpar ] .",
    "l@-1cml@1.5cmcccc & & crps & mae & coverage & width + forecast & & ( m s@xmath99 ) & ( m s@xmath99 ) & ( % ) & ( m s@xmath99 ) + local climatology & & 1.127 & 1.580 & 96.6 & 7.96 + glameps ensemble & & 1.058 & 1.376 & 67.1 & 3.50 +   + simpl . &",
    "& 0.957 & 1.324 & 90.3 & 6.36 + lag - ign . & & 0.955 & 1.320 & 90.3 & 6.33 +   + simpl . & & 0.790 & 1.100 & 88.7 & 5.12 + & + d1 simpl . &",
    "@xmath100 & 0.873 & 1.218 & 90.2 & 5.99 + d1 lag - ign . &",
    "@xmath100 & 0.887 & 1.236 & 89.2 & 5.71 + d2 simpl . &",
    "@xmath94 & 0.816 & 1.136 & 90.0 & 5.61 + d2 lag - ign & @xmath94 & 0.815 & 1.136 & 89.6 & 5.42 + d3 simpl . &",
    "@xmath94 & 0.774 & 1.083 & 90.3 & 5.25 + d3 lag - ign . &",
    "@xmath101 & 0.774 & 1.083 & 90.2 & 5.21 + d4 simpl . &",
    "@xmath100 & 0.766 & 1.069 & 89.9 & 5.16 + d4 lag - ign . &",
    "@xmath101 & 0.770 & 1.075 & 90.0 & 5.18 + d5 simpl . & @xmath100 & 0.874 & 1.220 & 90.2 & 5.95 + d5 lag - ign . & @xmath94 & 0.895 & 1.248 & 89.8 & 5.91 + & + c1 simpl . & @xmath102 & 0.836 & 1.162 & 89.8 & 5.68 + c1 lag - ign . & @xmath102 & 0.832 & 1.156 & 89.6 & 5.55 + c2 simpl . &",
    "@xmath102 & 0.789 & 1.103 & 89.9 & 5.25 + c2 lag - ign . &",
    "@xmath102 & 0.787 & 1.099 & 89.8 & 5.22 + c3 simpl . &",
    "@xmath102 & 0.782 & 1.091 & 89.7 & 5.19 + c3 lag - ign . & @xmath102 & 0.781 & 1.090 & 89.7 & 5.17 +    [ table : perf - measures ]    table [ table : perf - measures ] shows the average crps , mae of median values , and coverage and average width of 96.2% prediction intervals for the considered models .",
    "the raw glameps ensemble predictions outperform the climatological forecasts and provide sharp prediction intervals , however , at the cost of being uncalibrated .",
    "regional tn models are able to improve the calibration of the ensemble , and result in around 10% better mean crps values , however , the semi - local approaches significantly outperform the regional approaches for all considered models and tuning parameter choices , see also figures [ fig : tuningpar - l - distbased ] and [ fig : tuningpar - k - clustering ] .    among the distance - based semi - local models ,",
    "the best predictive performances are obtained by distance functions 3 and 4 which utilize the distribution of forecast errors and combinations with the station climatology to determine similarities between stations .",
    "note that these semi - local models are also able to outperform the local tn model for a wide range of tuning parameter choices without requiring subsequent corrections and while further allowing for a successful estimation of the more complex lag - ignoring and full semi - local models .",
    "the semi - local models based on distance functions 1 and 5 exhibit similar predictive performances which are slightly worse compared to the other distances , but are still able to outperform the regional model .",
    "the similarity is clearly caused by the large overlap of selected similar stations , see figure [ fig : distances - illustration ] . except for distance 2 ,",
    "the simplified model performs slightly better than the lag - ignoring model , however , the differences are negligible compared to the differences between the different model estimation approaches .",
    "we obtain similar results for the clustering - based semi local models which perform slightly worse compared to the corresponding distance - based models , however , still significantly outperform the regional models and the local model if the clusters are determined on the basis of forecast errors and station climatology . here , the lag - ignoring models show better predictive performances compared to the simplified models , but again , the differences are small compared to the influence of the choice of feature sets .     for the corresponding tuning parameter choices .",
    "]    figure [ fig : pits ] shows pit histograms of the lag - ignoring regional , the simplified local , and the distance - based and clustering - based semi - local models with the best average crps values ( see table [ table : perf - measures ] ) . compared to the verification rank histogram of the raw glameps ensemble forecasts ( see figure [ fig : fig1]b ) , all postprocessing models exhibit significantly improved calibration with pit histograms showing much smaller deviations from the desired uniform distribution .",
    "the hump - shaped pit histogram of the regional tn model indicates a slight under - prediction of lower wind speed values .",
    "the local and semi - local models are able to correct for this deficiency and show slightly better calibration , in particular for the semi - local models .",
    "most of the models in table [ table : perf - measures ] show similarly shaped pit histograms .",
    "alternative distributional choices such as log - normal or generalized extreme value distributions might lead to further improvement in calibration , see e.g. @xcite .    to conclude",
    ", we note that the overall best predictive performance is achieved by distance - based semi - local models utilizing both the distribution of observations as well as the distribution of forecast errors at the observation stations , closely followed by clustering - based models with feature sets defined in a similar way .",
    "these models show better predictive performances than the local model , and can be estimated without any numerical issues .",
    "figures [ fig : tuningpar - l - distbased ] and [ fig : tuningpar - k - clustering ] indicate that these conclusions hold for a wide range of tuning parameter choices . with regards to the two semi - local approaches ,",
    "the respective distance - based models generally show slightly better predictive performance , however , the estimation of the clustering - based models is computationally much more efficient and allows for an iterative application of the clustering algorithm in each training period .",
    "we have proposed two semi - local approaches to parameter estimation for ensemble postprocessing where the training data for a given observation station are augmented with data from stations with similar characteristics .",
    "the distance - based approach roughly follows the ideas of @xcite and uses distance functions to determine the similarities between observations stations , whereas the novel clustering - based approach employs @xmath1-means clustering to obtain groups of similar stations .",
    "various choices of distance functions , feature sets and tuning parameters have been tested .",
    "the best results are obtained for semi - local models where the similarities between stations are determined based on combinations of the climatological distribution of observations as well as the distribution of forecast errors at the given stations . while all semi - local models show significantly better predictive performance than the regional models , these best models are also able to outperform the locally estimated model .",
    "the semi - local parameter estimation methods further allow for estimating more complex models without numerical issues , whereas local estimation is only possible for simplified model formulations with a reduced number of parameters and still requires subsequent modifications .",
    "the semi - local models thus offer several advantages over the standard approaches to parameter estimation and are straightforward to implement .",
    "the clustering - based semi - local model estimation is further computationally much more efficient than local model estimation which arises as a special case with @xmath70 clusters of size 1 each .",
    "while distance - based semi - local models show slightly better predictive performance compared to the clustering - based models , the estimation requires substantially more computational resources .",
    "in particular , an adaptive computation of the similarities in every training period is not feasible for the distance - based models .",
    "compared to the work of @xcite , we propose several alternative distance functions and use the distance - based approach for observations at specific stations instead of gridded data .",
    "it would be interesting to apply the novel similarity measures as well as the clustering - based approach to grid - based forecast and analysis data and assess potential differences .",
    "in particular , distance functions incorporating the distribution of forecast errors ( distances 3 and 4 ) result in significantly better predictive performance for the glameps data and might also offer improvements over the climatology - based distance function used by @xcite ( similar to distance function 2 ) when applied to gridded data .    with regards to the results for the employed distance functions it might appear somewhat surprising that models based on similarities defined by characteristics of the ensemble ( mean and variance ) as measured by distance 5 do not result in improvements compared to simple location - based similarities ( distance 1 ) .",
    "however , this might be due to the fact that these characteristics of the ensemble are substantially influenced by the locations of the stations , and the training sets thus largely overlap with those of the location - based distance 1 .",
    "these results might change for other ensemble prediction systems .",
    "further , potential improvements might be obtained by including different summary statistics of the ensemble , e.g. , by adding information about the within - group variances of the subensembles , or quantiles of the distribution of ensemble forecasts .",
    "the group memberships of the observation stations in the clustering - based semi - local models are all determined by applying @xmath1-means clustering .",
    "alternative clustering methods exist and might potentially lead to improvements ( for reviews and comparisons see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "we did not incorporate informations on the geographical locations of the stations or characteristics of the ensemble into the selected feature sets as initial tests indicated a worse predictive performance . for different ensemble prediction systems , these alternative choices of feature sets may lead to further improvements .    in the interest of brevity , we limited our discussion to the standard truncated normal emos model proposed by @xcite .",
    "an extension of the similarity - based semi - local parameter estimation approach to other postprocessing models might in particular be interesting for complex models where larger numbers of parameters have to be estimated and local parameter estimation might thus not be feasible ( for recent examples see , e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "@xcite propose analog - based local emos models where the training set for a given station is chosen by selecting forecast cases with similar ensemble forecasts for that station .",
    "this analog - based approach thus utilizes information for a given station in an optimal way by selecting subsets of the local training sets , whereas our semi - local models combine informations from multiple observation stations based on similarities .",
    "while the analog - based modification of the local parameter estimation method shows good predictive performance in a case study on hub height wind speed , it requires sufficiently long training periods for locally selecting similar forecast cases .",
    "the implementation of this analog - based approach is thus infeasible for the glameps data , however , comparisons and combinations with the similarity - based semi - local approaches proposed here are of interest and might result in further improvement in predictive performance .",
    "* acknowledgments . *",
    "lerch gratefully acknowledges support by the volkswagen foundation through the program `` mesoscale weather extremes  theory , spatial modelling and prediction ( wex - mop ) '' and by deutsche forschungsgemeinschaft ( dfg ) through the research training group `` rtg 1953  statistical modeling of complex systems and processes '' .",
    "sndor baran was supported by the jnos bolyai research scholarship of the hungarian academy of sciences .",
    "the authors are indebted to tilmann gneiting and michael scheuerer for useful suggestions and remarks , and to maurice schmeits , jan barkmeijer and john bjrnar bremnes for providing the glameps data and assistance in data handling .",
    "deckmyn , a. ( 2014 ) introducing glamepsv2 . _ aladin forecasters meeting , _ ankara , turkey , 1011 september , 2014 .",
    "available at : http://www.cnrm.meteo.fr/aladin/meshtml/fm2014/presentation/aladinfm_ad_be.pdf .",
    "gneiting , t. , raftery , a. e. , westveld , a. h. and goldman , t. ( 2005 ) calibrated probabilistic forecasting using ensemble model output statistics and minimum crps estimation . _ mon .",
    "weather rev .",
    "_ * 133 * , 10981118 .",
    "hagedorn , r. , buizza , r. , hamill , t. , leutbecher , m. and palmer , t. ( 2012 ) comparing tigge multimodel forecasts with reforecast - calibrated ecmwf ensemble forecasts .",
    "_ q. j. r. meteorol .",
    "* 138 * , 18141827 .",
    "hamdi , r. , degrauwe , d. , duerinckx , a. , cedilnik , j. , costa , v. , dalkilic , t. , essaouini , k. , jerczynki , m. , kocaman , f. , kullmann , l. , mahfouf , j .- f . ,",
    "meier , f. , sassi , m. , schneider , s. , va , f. and termonia , p. ( 2014 ) evaluating the performance of surfexv5 as a new land surface scheme for the aladincy36 and alaro-0 models .",
    "model dev . _",
    "* 7 * , 2339 .",
    "iversen , t. , deckmin , a. , santos , c. , sattler , k. , bremnes , j. b. , feddersen , h. and frogner , i .-",
    "( 2011 ) evaluation of glameps  a proposed multimodel eps for short range forecasting . _ tellus a _ * 63 * , 513530 .",
    "mller , a. , thorarinsdottir , t. l. , lenkoski , a. and gneiting , t. ( 2015 ) spatially adaptive , bayesian estimation for probabilistic temperature forecasts .",
    "_ working paper_. available at http://arxiv.org/abs/1507.06517              ruiz , j. j. and saulo , c. ( 2012 ) how sensitive are probabilistic precipitation forecasts to the choice of calibration algorithms and the ensemble generation method ?",
    "part i : sensitivity to calibration methods .",
    "_ meteorol .",
    "_ * 19 * , 302313 .",
    "sass , b. h. ( 2002 ) a research version of the straco cloud scheme .",
    "_ dmi tech .",
    "_ 02 - 10 .",
    "danish meteorological institute , copenhagen , denmark , 25 pp . available at : http://www.dmi.dk/dmi/index/viden/dmi-publikationer/tekniskerapporter.htm .",
    "schmeits , m. j. and kok , k. j. ( 2010 ) a comparison between raw ensemble output , ( modified ) bayesian model averaging and extended logistic regression using ecmwf ensemble precipitation reforecasts .",
    "weather rev . _ * 138 * , 41994211 .",
    "swinbank , r. , kyouda , m. , buchanan , p. , froude , l. , hamill , t. m. , hewson , t. d. , keller , j. h. , matsueda , m. , methven , j. , pappenberger , f. , scheuerer , m. , titley , h. a. , wilson , l. and yamaguchi , m. ( 2015 ) the tigge project and its achievements .",
    "soc . _ http://dx.doi.org/10.1175/bams-d-13-00191.1    thorarinsdottir , t. l. and gneiting , t. ( 2010 ) probabilistic forecasts of wind speed : ensemble model output statistics by using heteroscedastic censored regression",
    ". _ j. r. stat .",
    "a _ * 173 * , 371388 ."
  ],
  "abstract_text": [
    "<S> weather forecasts are typically given in the form of forecast ensembles obtained from multiple runs of numerical weather prediction models with varying initial conditions and physics parameterizations . </S>",
    "<S> such ensemble predictions tend to be biased and underdispersive and thus require statistical postprocessing . in the ensemble model output statistics ( emos ) approach , </S>",
    "<S> a probabilistic forecast is given by a single parametric distribution with parameters depending on the ensemble members . </S>",
    "<S> this article proposes two semi - local methods for estimating the emos coefficients where the training data for a specific observation station are augmented with corresponding forecast cases from stations with similar characteristics . </S>",
    "<S> similarities between stations are determined using either distance functions or clustering based on various features of the climatology , forecast errors , ensemble predictions and locations of the observation stations . in a case study on wind speed over europe with forecasts from the grand limited area model ensemble prediction system , </S>",
    "<S> the proposed similarity - based semi - local models show significant improvement in predictive performance compared to standard regional and local estimation methods . </S>",
    "<S> they further allow for estimating complex models without numerical stability issues and are computationally more efficient than local parameter estimation .    </S>",
    "<S> _ key words : _ clustering , continuous ranked probability score , ensemble model output statistics , ensemble postprocessing , probabilistic forecasting , truncated normal distribution , weather forecasting , wind speed . </S>"
  ]
}