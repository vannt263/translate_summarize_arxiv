{
  "article_text": [
    "billions of astronomical objects are detected in large astronomical surveys , for which thousands of properties are quantified .",
    "the classical way to handle catalog data produced by large surveys , is to create a static relational database with a direct interface to the user .",
    "this classical approach has several conceptual drawbacks .",
    "the catalogs are published in releases as is ; there is very limited flexibility in the derivation of the data .",
    "redoing part of the data reduction entails downloading a large part of the original data and reprocessing it offline .",
    "scientists require knowledge about the internal representation of the data to access it .",
    "examples of such an approach are the sloan digital sky survey ( sdss ) @xcite and the wfcam science archive @xcite .",
    "it is possible to create user - defined tables in the ` casjobs ' service of sdss .",
    "these are of a limited size and there is no facility to reprocess the data .",
    "this is an inherently _ pushing _ or _ forward chaining _ approach ,",
    "that is , scientists create derived catalogs in a stepwise fashion  starting from the released catalogs  until they reach their required end product .",
    "the used database queries are stored within the tables , but there is no conceptual information about what the data in the catalogs represent .",
    "this paper discusses the design of novel mechanisms to handle such large catalogs in astro - wisethrough request driven processing .",
    "that is , scientists request their required end product , and the information system autonomously determines the best way to provide this catalog .",
    "we achieve a high level of automation and implicit scalability , while enhancing flexibility in processing and sharing of data .",
    "this is done by using an object oriented data model that focuses on storing information about processing ; storing the catalog data itself is of secondary importance .",
    "the astro - wiseconsortium has designed a new paradigm and has implemented a fully scalable information system to overcome the huge information avalanche produced by wide - field astronomical surveys @xcite .",
    "this is achieved by capturing in a generic way the reality of end - to - end survey operations into a conceptual data model which is translated into hierarchical classes .",
    "the model maps all links between dependencies : objects are stored in the database , which links all data products to their dependencies .",
    "this creates a _ dependency graph _ with the _ full data lineage _ of the entire processing chain .",
    "astro - wiseuses the advantages of object - oriented programming ( oop ) to process data in the simplest and most powerful ways .",
    "in essence , it turns the objects that represent conventional astronomical science products , into oop objects , called _",
    "process targets_. every individual science product , such as frame or catalog , is an instantiation of a specific process targetclass .",
    "each of these process targetinstances knows how to process itself to create the data product it represents .",
    "each process targethas associated _ processing parameters _ , which are configurable parameters that guide the processing of that target .    the most unique aspect of astro - wiseis its ability to process data based on the final desired result to an arbitrary depth .",
    "this data pulling is the heart of astro - wiseand is called _",
    "target processing_. contrary to the typical case of forward chaining such as in the sdss casjobs service , the astro - wisedatabase links allow the dependency chain to be examined from the intended _",
    "process target _ all the way back to the raw data .",
    "a target s dependencies are checked to see if it is _ up - to - date _ : if there is a newer dependency or if the target does not exist , the target is ( re)created .",
    "target processing has been incorporated in the image reduction part of the astro - wise  information system since its inception @xcite .",
    "originally , only a few classes were available in astro - wiseto handle catalog data , of which the sourcelist is the most prominent .",
    "the sourcelist is primarily used to create catalogs with attributes derived from images and has limited functionality for creating new catalogs from existing catalogs . in particular such derived catalogs do not have full data lineage and can therefore not be pulled .",
    "furthermore they can require large amounts of duplication of catalog data , leading to scalability problems .",
    "this paper describes how data lineage and data pulling mechanisms are extended to cover astronomical catalogs with the design of process targetclasses  which we call _ source collections_for catalog data .",
    "a source collectioninstance represents a collection of sources ( astronomical objects ) with attributes ( or parameters ) that quantify physical properties .",
    "there are separate process targetclasses for different operations to create and manipulate catalogs ( section  [ sec : operatorsummary ] ) .",
    "the source collectionclasses take data pulling mechanisms to a higher level than is necessary for images ; in particular it is not required to store the catalog data that a source collectionrepresents in its entirety .",
    "the full data lineage allows any target to be processed at any time for any reason , since the process parameters unambiguously define how to do so .",
    "ultimately , this means that it is not necessary to process a target completely , or at all . in a sense",
    ", this turns the object - oriented approach into a functional one : a process targetcan also be seen as a representation of the operation that is used derive the science product , in addition to seeing it as a representation of the result itself .",
    "the actual processing of the object and storing the result is then optional .",
    "these two viewpoints are equivalent and interchangeable and the contributions in this work stem from this dual perspective :    1 .",
    "we allow source collectionsto be created  and used as a dependency for other process targets  by specifying their data lineage , without requiring them to be processed , unlike other process targetsin astro - wise .",
    "dependency graphs of source collectionsare created automatically through data pulling .",
    "these mechanisms create new source collectionsin a way that maximizes their reusability for future data pulling requests .",
    "3 .   we present a novel way to process only the part of a source collectionthat is required for the last process targetin a dependency graph .",
    "this is done by using the power of backward chaining to temporarily optimize the dependency graph .",
    "we use a novel algorithm ( @xcite , hereafter paper ii ) to infer the logical relationships between catalogs from their data lineage directly .",
    "this is required because the exact set of sources that a catalog represents might not be evaluated .",
    "this algorithm is used to find source collectionsand for the optimization of dependency graphs .",
    "the methods to calculate new attributes from existing attributes are decoupled from their application .",
    "this offers scientists flexibility in implementing their own methods while reinforcing the principles of data pulling .",
    "the catalog objects and data pulling mechanisms are designed to be used in query driven visualization @xcite .",
    "the high level of automation allows the data pulling to be abstracted , which implicitly minimizes the processing required to create the visualized datasets .",
    "the remainder of the paper is structured as follows .",
    "the source collectionconcept is introduced and demonstrated with an example in section  [ sec : introducingsourcecollections ] .",
    "this is followed by a short description of the different source collectionclasses that are implemented in astro - wisein section  [ sec : ssoperators ] and a discussion about storing source collectionsand the catalog data they represent in section  [ sec : sckeystorelineage ] .",
    "subsequently the concept of _ dependency graphs _ is explained in section  [ sec : dependencygraphs ] and their automatic creation through data pulling in section  [ sec : scpullingdata ] .",
    "the optimization of dependency graphs is discussed in section  [ sec : sctreemodifications ] and their processing in section  [ sec : scprocessingandstoring ] .",
    "a summary and conclusion is provided in section  [ sec : conclusions ] .",
    "a source collectionis an astro - wiseprocess target(section  [ sec : proctargetintro ] ) for the handling of astronomical catalogs .",
    "these catalogs consist of sets of sources and attributes that quantify properties of the sources .",
    "the exact set of sources and the values of the attributes is determined by processing a source collection .",
    "when we refer to _ catalog data _ , we mean this processing result .",
    "a source collectioncan also be seen as a representation of the action required to derive the catalog data , since a source collectioncan be created without being processed .",
    "we refer to this action in a conceptual sense as the _ operator _ of a source collectionand define separate process targetclasses for different operations on catalogs ( section  [ sec : operatorsummary ] ) .",
    "every source in a source collectionhas a unique identifier and two source collectionsare considered to represent the same sources if and only if the identifiers of their sources are identical .",
    "a source itself can be seen as an object in the computer science reading of the term .",
    "a parametrized property of a source can then be seen as an attribute of such an object .",
    "we will use the term _ attribute _ instead of _ parameter _ , which originates from this object oriented approach .",
    "attributes quantify physical properties of the sources in a source collectionand the set of attributes forms the source collectiondimensions .",
    "the label of an attribute only describes what physical property is represented by the attribute .",
    "this labeling could be standardized , for example with unified content descriptors ; for the scope of this paper we will refer to attributes by their name only .",
    "every source collectioninstance is linked to its dependencies , forming a dependency graph all the way to the raw data .",
    "dependencies of a source collectionthat are source collectionsthemselves are also called its _ parents _ , because the catalog represented by the source collectionis derived from them .",
    "such a dependency graph can be visualized as interconnected nodes . in the figures in this paper , the dependencies of a process targetare shown above it .",
    "therefore the data processing runs from top to bottom and the data lineage from bottom to top .",
    "such a dependency graph can conceptually be extended in both directions .",
    "the top nodes will contain photometric attributes and can be connected to nodes representing frames that were used to measure these attributes .",
    "the bottom nodes can be connected to nodes representing hypothetical process targetsfor graphs or other analysis products .",
    "we demonstrate the source collectionconcept with a simplified example of data pulling .",
    "we assume the existence of a source collection(labeled @xmath0 , fig .",
    "[ fig : scintroexample ] ) that contains apparent magnitudes and redshifts for a large set of galaxies .",
    "a scientist pulls a dataset with both absolute and apparent magnitudes for nearby galaxies .",
    "first , the scientist formulates a data pulling request ( fig .",
    "[ fig : scintroexample ] ) in which three pieces of information are specified :    * the data set from which the sources should be selected : source collection@xmath0 . * the selection criterion for the sources : a redshift below 0.1 . * the required attributes : absolute and apparent magnitudes .",
    "subsequently , the information system creates the required source collections(fig .",
    "[ fig : scintreexamplepers ] ) :    * source collection@xmath1 is created to select all sources that match the given selection criterion . *",
    "the information system determines that no absolute magnitudes have been defined for these sources and it creates source collection@xmath2 to calculate absolute magnitudes from apparent magnitudes . *",
    "the information system determines that the calculation can be performed on all sources in source collection@xmath0 .",
    "therefore , it optimizes for generality and uses source collection@xmath0 as dependency for source collection@xmath2 , instead of @xmath1 .",
    "the source collectionis not yet processed at this stage .",
    "* source collection@xmath3 and @xmath4 are created to combine the attributes represented by different source collectionsand select the required ones .",
    "finally , the created dependency graph is optimized and processed ( fig .",
    "[ fig : scintreexampletrans ] ) :    * the information system creates a temporary copy of the dependency graph in order to optimize it for scalability to fulfill the request as quickly as possible .",
    "* it reorganizes the dependency graph to minimize the required processing by placing the selection of sources before the calculation of absolute magnitudes . *",
    "the information system retrieves the data of source collection@xmath5 and uses this to process source collection@xmath6 completely .",
    "the calculated attributes will be stored for future requests as part of source collection@xmath2 , because they can not be derived on the fly . * the other source collectionsare processed on the fly while retrieving the catalog data of source collection@xmath7 .",
    "the catalog data is subsequently returned to the scientist .",
    "the example in section [ sec : scexample ] highlights the key aspects of the source collection :    * catalog data is pulled and new source collectionsare created to compute attributes that do not yet exist ( section [ sec : scpullingdata ] ) . * the final catalog has full data lineage : any attribute value can be recalculated and the selection criterion is stored ( section  [ sec : sckeystorelineage ] ) .",
    "* calculations are defined to be as general as applicable .",
    "source collection@xmath2 can be reused if at a later stage absolute magnitudes are requested for another subset of source collection@xmath0 ( section [ sec : scpullingdata ] ) . *",
    "the information system reorganizes the order of the source collectionsto prevent the calculation of unnecessary data ( section  [ sec : sctreemodifications ] ) .",
    "the algorithm to determine logical relationships between sets of sources of paper iiis used for more complex dependency graphs .",
    "* source collection@xmath2 is processed partially by processing its smaller copy @xmath6 entirely and sharing the result ( sections [ sec : sckeystorelineage ] , [ sec : sctreemodifications ] ) . *",
    "the calculation of the absolute magnitudes can be performed on the workstation of the scientist or on a distributed computing cluster , while the selection of data can be performed on the database ( section  [ sec : processingscs ] ) .",
    "[ sec : ssoperators ] [ sec : sckeyoperators ] many of the novel features of the source collectionsoriginate from the ability of the information system to assess aspects of the catalogs by inspecting only the data lineage .",
    "this is achieved by having a predefined set of operations that can be used to process a source collection .",
    "separate process targetclasses are designed for the different operations .",
    "we use the term _ operator _ to refer to the action required to create the catalog data .",
    "these operators are designed to be as elementary as possible in order to maximize the information that can be inferred from the data lineage directly",
    ". therefore , there are no source collectionoperators that are entirely user - defined .",
    "however , the behavior of source collectionscan be influenced by setting the process parameters .",
    "for example , we do define an operator to calculate new attributes of sources from existing attributes ( section  [ sec : sckeycalculator ] ) .",
    "this allows scientist to specify their own calculation method as a process parameter .",
    "there are two main effects of the elementary operators : firstly , they allow the information system to determine whether a source collectioncan be used in the construction of a dependency graph ( section [ sec : scpullingdata ] ) .",
    "secondly , they allow efficient reorganization of the dependency graph , e.g. for partial processing ( section [ sec : sctreemodifications ] ) .",
    "most operators we define are modeled after relation operations @xcite to allow them to be evaluated on the astro - wisedatabase .",
    "in essence , we extend sql commands to target processing , although this is not directly our goal . the important aspect in the design of the operators is maximizing the information that can be inferred from the data lineage .",
    "not all operators we describe can be evaluated on sql and vice versa , most operators can be evaluated in the astro - wisepythonenvironment as well .",
    "we summarize the operators that are most important for our research :    * * select attributes * : selects a subset of attributes from a parent source collection . * * concatenate attributes * : combines the different attributes from several parent source collectionsthat represent the same sources . * * rename attributes * : renames attributes of a parent source collection . * * filter sources * : selects a subset of sources from a parent source collectionby evaluating a selection criterion . * * select sources * : selects a subset of sources from a parent source collectionby listing the required sources explicitly . * * concatenate sources * : combines the different sources of several parent source collectionsthat represent the same attributes . * * relabel sources * : changes the source identifiers of a parent source collection . * * attribute calculator * : calculates new attributes from existing attributes for the sources in a parent source collection(section  [ sec : sckeycalculator ] ) . * * external * : represents a catalog without data lineage . * * pass * : represents the exact same catalog as its parent . * * sourcelist wrapper * : a special source collectionto use the astro - wisesourcelist class as a source collection .",
    "the sourcelist class is used to detect sources from images and measure photometric and related attributes .",
    "a special source collectionclass is designed for the calculation of new attributes of sources from existing attributes .",
    "the calculation performed by a source collectionof this class , is decoupled from the definition of the class and is stored as another persistent object , which can be created by scientists themselves .",
    "this auxiliary object is called an _ attribute calculator definition _ and contains both information about how to perform the calculation as well as information about the calculation itself : which attributes are calculated , which attributes are required and which process parameters can be set .",
    "this allows the information system to discover attribute derivation methods in order to instantiate source collectionsto calculate these attributes for a requested set of sources .",
    "this offers scientists flexibility in implementing their own methods while reinforcing the principles of data pulling .",
    "multiple attribute calculator definitionsmight exist for the calculation of the same attribute , for example through different methods or different versions of the same method .",
    "astro - wisehas functionality to indicate that stored objects should not be used anymore by invalidating them , for example when a newer version of the object exist .",
    "this is used within the source collectionsto indicate that newer versions of attribute calculator definitionsexist .",
    "this allows existing functionality to be used for ensuring that catalogs are always created with the latest method and that out - dated catalogs are flagged for possible recreation .",
    "sourcecollections can be created and stored by specifying their data lineage only ; it is not required to process them .",
    "that is , the actual determination of the exact composition of sources in a catalog , and the calculation of the values of their attributes , is delayed as long as possible .",
    "furthermore , the result of the processing is stored only if necessary for performance reasons and the results can be shared between source collections .",
    "we summarize the benefits of this approach :    * different source collectioncan represent partially identical catalogs without any duplication of stored data . * the processing of intermediate source collectioncan be limited to those subsets that are required for the end node of a dependency graph .",
    "source collectionscan therefore be created with arbitrary sizes without performance penalties .",
    "this ensures maximum reusability of the created source collections .",
    "* no results have to be stored at all for source collectionsthat can be processed on the fly .",
    "the _ persistent properties _ of a process targetare the properties of the object that are stored in a database .",
    "these properties can be grouped in the following types , a categorization that is especially important for source collections :    * * data lineage * : properties that define the catalog that is represented by the source collection .",
    "these are dependencies and process parameters .",
    "dependencies are other process targetsfrom which the catalog represented by this source collectionis derived , often source collectionsas well .",
    "process parameters that influence the processing as defined by the class of the source collection .",
    "the dependencies and process parameters together unambiguously define the catalog that the source collectionrepresents . * * processing results * : results of processing the source collection , detailed in section [ sec : processingresults ] . * * other properties * : properties that do not refer directly to the processing or the processing results .",
    "these include identifiers of the object , a human readable name of the source collection , a reference to its creator , status of the processing , etc .",
    "some of these can be specified by the user , others are set automatically by the information system .",
    "the result of processing a process targetinstance ( section  [ sec : proctargetintro ] ) can be stored persistently .",
    "the processing results of image classes are primarily the values of the pixels of the image , which in astro - wiseare stored as fits files on the dataserver .",
    "for source collectionsthe primary result is the catalog data it represents , which in astro - wiseis stored in the database .",
    "the source collectionclasses are designed to allow partial processing of objects , for example because only a part of the catalog data is required at a specific moment .",
    "the processing results are split up in distinct components in order to achieve this .",
    "these components can , in principle , be processed separately .",
    "the following results can be distinguished :    * the catalog the source collectionrepresents : the values of all the attributes for all the sources .",
    "this is the primary processing result and can be decomposed in the partial results that follow . * a partial catalog : the values of the attributes for a subset of the sources or attributes . *",
    "the set of sources the source collectionrepresents , which can be seen as a list of identifiers of the sources .",
    "this can be further split up into the number of sources , or an identification of the set without actually enumerating all the sources individually . *",
    "the set of attributes of the sources .",
    "that is , which physical properties the source collectionrepresents , not the actual values of the attributes .",
    "to process a source collectionpartially , a new process targetis created that only represents the required component , which is subsequently processed in its entirety .",
    "such a component is either stored in its entirety or not at all , and can be shared between source collections .",
    "the sharing of processing results leads to multiple paths to the same stored data .",
    "the dependency graphs representing these different paths are only created automatically by the information system through modifications of existing dependency graphs ( section  [ sec : graphmodification ] ) .",
    "the information system ensures that the different paths are equivalent by only performing modifications where this is guaranteed .",
    "a source collectionrepresents a catalog that is derived from its dependencies , which again have dependencies themselves .",
    "these dependencies chain a source collectionback to the raw data and form a graph of process targets .",
    "the term _ dependency graph _ is used to refer to this complete set of dependencies of a source collection .",
    "these graphs are _ directed acyclic graphs _ , or _",
    "acyclic digraphs _ , because there are no cyclic dependencies @xcite .    in the figures depicting dependency graphs in this paper , the dependencies of a source collectionare shown above it .",
    "therefore the data processing runs from top to bottom and the data lineage from bottom to top .",
    "there are no arrows on the shown edges , because the preferred direction is dependent on context .",
    "this paper only treats the part of such a dependency graph that considers source collections .",
    "the information system can modify dependency graphs of source collections , e.g. while constructing new ones or when optimizing existing ones as discussed in the next sections .",
    "all modification steps in the following algorithms are performed by replacing a source collectionwith another one .",
    "there are two ways to do this :    * replacing a source collectionwith another one that represents the exact same catalog .",
    "this is the only mechanism that is used in the dependency graph optimization ( section [ sec : sctreemodifications ] ) . *",
    "replacing a source collectionwith one that represents a different catalog .",
    "this is only performed during the creation of new dependency graphs ( section [ sec : sctreemodifications ] ) and only on dependencies of the passsource collectionsat the end of the graph .",
    "the individual modifications themselves are designed in a way that separates the knowledge of _ how _ to perform a modification and _ why _ to do so . how to perform",
    "a modification is part of the definition of the source collectionclasses .",
    "whether a specific modification should be applied is the responsibility of the part of the information system that governs the entire dependency graph .",
    "therefore , all modifications are between a source collectionand its direct dependencies , because an individual source collectionhas no knowledge of other objects .",
    "a specific kind of modifying a dependency graph is ` moving ' source collectionsthrough the graph . the way this",
    "should be interpreted  in simplified form  is that copies of a source collectionand its parent are created , but with their dependencies swapped .",
    "the original source collectionis then replaced by these copies . as a result , source collectionscan only be moved ` up ' the graph . to move a source collectiondown , the source collectionwith",
    "that source collectionas a parent should be moved up .",
    "some modifications can only be performed if the relationship between the sets of sources of the involved source collectionsis known .",
    "the information system uses the algorithm of paper iito provide this information to the individual source collections .",
    "the ` pushing ' way to use catalogs such as represented by the source collectionsis to define the catalog , process and store it , and then request subsets of the catalog .",
    "this order is changed with target processing @xcite .",
    "source collectionsare primarily created automatically by pulling data , which means that the evaluation of processing starts at the end of the chain by requesting the final catalog that is required .",
    "the information system will autonomously create a dependency graph of source collectionwhich ends with a source collectionthat represents the requested catalog ( algorithm [ algo : pullcatalogtree ] ) .",
    "there are two main goals of the data pulling mechanisms with respect to the creation of the dependency graph : firstly , they ensure that existing source collectionswill be reused as much as possible and secondly , new source collectionsare created in a way that maximizes their reusability .",
    "the pulling of data starts with a request for a specific dataset . in our research",
    "we have limited such requests to three pieces of information :    * a starting source collectionfrom which a selection is made . * a list of required attributes , not necessarily represented by the starting source collection .",
    "* optionally , a selection criterion for the sources .    receive and parse a request for catalog data .",
    "instantiate the starting source collection . create a select attributesthat selects an empty attribute list from this source collection . create a passsource collectionwith the select attributesas parent .",
    "select the right sources ( algorithm [ algo : pullcatalogselect ] ) . add the attribute to the passsource collection(algorithm [ algo : pullcatalogaddattribute ] ) .",
    "the information system will use existing and newly created source collectionsto create a dependency graph which ends with a source collectionrepresenting the requested catalog .",
    "the information system is able to autonomously decide how to proceed if there are multiple source collectionsthat can be used to fulfill a particular dependency .",
    "this is done by applying a ranking function to all source collectionsthat can be used and select the one with the highest ranking .",
    "scientists can influence this process by specifying their own ranking function or by overruling the choices made by the information system manually .      fulfilling a request for",
    "a catalog begins with creating a source collectionwith the correct the composition of sources ( algorithm [ algo : pullcatalogselect ] ) .",
    "the resulting source collectionwill only represent the selected set of sources at this stage , without attributes .    in this paper we restrict ourselves to requesting subsets of sources that are already represented by an existing source collection , because our focus is on operations on catalogs .",
    "in particular we assume the existence of source collectionswith photometric and related attributes derived from images .",
    "these catalogs could be created through pulling mechanisms as well ; this is beyond the scope of this paper .",
    "the logical relations algorithm of paper iiis used to search for an existing source collectionthat represents the requested selection .",
    "first all source collectionsthat represent the same sources as the original source collectionare found .",
    "subsequently a filter sourcesis sought , one with the specified selection criterion and with one of these source collectionsas parent .",
    "new source collectionsare created to select the required sources if no suitable source collectionis found .",
    "this might require more than only a single filter sourcessource collectionbecause the information system has to ensure that the attributes used in the selection criteria are available .",
    "for example , the specified selection criterion in the example in section  [ sec : scexample ] depends on the availability of the redshift attribute .",
    "the information system would have tried to find this attribute if it would not have been included in source collection@xmath0 .    a select attributessource collectionis created to select no attributes from the found or created source collectionwith the sources .",
    "the required attributes are subsequently added to this new source collectionwith only sources ( section  [ sec : selectingattributes ] ) .",
    "search for all source collectionsrepresenting the original sources .",
    "search for all filter sourceswith one of these source collectionsas parent and the specified criterion as parameter .",
    "rank all found source collections .",
    "use the highest ranking source collectionto represent the sources .",
    "use algorithm [ algo : pullcatalogtree ] to create a source collectionwith all attributes referenced in the selection criterion .",
    "create a new filter sourcesto represent the sources .",
    "create a select attributesto select no attributes from the source collectionrepresenting the sources .",
    "create a select sourceswith the original source collectionas parent and the select attributesto specify the selected sources . use the select sourcesas the parent of the final passsource collection .",
    "a catalog pulling request should contain a list of required attributes .",
    "for every requested attribute , the information system will search for an existing source collectionthat represents this attribute for the requested sources .",
    "a hierarchy of select attributesand concatenate attributessource collectionsis created to add the attribute to the passsource collectionalready representing the sources ( algorithm [ algo : pullcatalogaddattribute ] ) .",
    "requested attributes for which no suitable source collectionscan be found , are derived with new source collections(algorithm [ algo : pullcatalognewcalculators ] ) . in this paper",
    "we limit ourselves to attributes that are derived from other attributes using attribute calculatorssource collections .",
    "the calculation performed by an attribute calculatoris specified through a process parameter referencing an attribute calculator definitionobject .",
    "new attribute calculatorsource collectionsare instantiated for all attribute calculator definitionsthat can be used to derive the requested attribute .",
    "the search for attributes is applied recursively if more attributes are required for the derivation of the requested attributes , as specified by the attribute calculator definition .",
    "source collectionsthat require the calculation of new attributes will automatically be defined to operate on the largest dataset the calculation is applicable for .",
    "this is done by giving source collectionswhich represent a larger set of sources a higher ranking when searching for attributes .",
    "search for all source collectionsrepresenting the attribute .",
    "rank all found source collections .",
    "use the highest ranking source collectionto represent the attribute .",
    "create an attribute calculatorto represent the attribute ( algorithm [ algo : pullcatalognewcalculators ] ) .",
    "create a select attributesthat selects the requested attribute from this source collection .",
    "create a concatenate attributeswith the original parent of the final passsource collectionand the new select attributesas parents . use the concatenate attributesas new parent of the final pass .",
    "search for all attribute calculator definitionsthat can be used to calculate the required attribute .",
    "create a source collectionwith all the attributes required by the attribute calculator definition(algorithm [ algo : pullcatalogtree ] ) .",
    "create an attribute calculatorwith that source collectionas parent , using the attribute calculator definition .",
    "rank all created attribute calculators .",
    "use the highest ranking attribute calculatorto represent the attribute .",
    "the result of data pulling is the creation of a dependency graph that ends with a source collectionthat represents the requested catalog .",
    "the source collectionsin this dependency graph might be stored persistently if necessary .",
    "the information system will subsequently optimize this graph to process it in the most optimal way ( section  [ sec : modifyingsc ] ) .",
    "[ sec : modifyingsc ] [ sec : sctreemodifications ] [ sec : sclazydata ] [ sec : sccachingdata ] the information system will optimize the dependency graph of a source collectionbefore processing the source collectionsthat it contains .",
    "there are two goals to these optimizations : minimization of the required processing and optimization of the processing itself .",
    "these optimizations are performed on a temporary transient copy of the dependency graph , which can be discarded after the processing is completed .    reducing the necessary processing to the minimum required for the last source collectionis the primary goal of this paper .",
    "in essence this is done by placing filtering source collectionsbefore source collectionsthat create new attributes and removing parts of the dependency graph that are not necessary for the final result .",
    "this will ensure that the source collectionsin the dependency graph only represent data that is required for the requested catalog data .",
    "these mechanisms allow the information system , or the scientist , to create and store source collectionsinstances in their most general and reusable form , ( e.g. as in fig .",
    "[ fig : scintreexamplepers ] ) , because the creation and storage of the catalog data is minimized automatically ( e.g. as in fig .",
    "[ fig : scintreexampletrans ] ) .",
    "optimization of the processing itself is a secondary goal of this paper .",
    "this is done by reorganizing the dependency graphs such that the processing can be performed on the most suitable subsystem of the information system .",
    "for example , source collectionsthat can best be processed on the database are placed such that they can be combined into one sql query and processed together .",
    "parts of the dependency graph can be parallelized in order to process large source collectionson a distributed cluster , especially those that can not be processed on the database .    optimizing the dependency graph of the example in figure [ fig : scintroexample2 ]",
    "is depicted in figure [ fig : scintreexampledata ] .",
    "the required processing in this example is dominated by a calculation of absolute magnitudes . without optimization ,",
    "absolute magnitudes have to be calculated for 100000 sources ; with optimization the calculation is only performed for the 1000 sources that are actually requested , resulting in a factor 100 increase in performance . the optimizations required to determine the exact set of sources in a source collectionis depicted in figure [ fig : scintreexamplesources ] . in this case",
    ", the calculation of absolute magnitudes is removed from the dependency graph entirely and the entire graph can be processed on the database .",
    "the best strategy for the optimization of dependency graphs depends on many factors , such as the size of the catalogs , how they will be processed , etc .",
    "therefore it is not possible to give a one - size - fits - all optimization strategy .",
    "algorithms [ algo : optimizeforload ] and [ algo : simplifyforload ] are procedures that cover most scenarios , they can be adjusted for particular cases . the steps described in the algorithms are detailed in the rest of the section .",
    "create transient copy of the involved source collections .",
    "simplify the dependency graph ( algorithm [ algo : simplifyforload ] ) .",
    "perform this step after every movement - step .",
    "move all select attributesup the graph , to remove parts of the graph .",
    "convert all filter sourcesto select sources , to move them through the graph .",
    "move all select sourcesdown , to copy them to every part of the graph .",
    "move all select sourcesup the graph , to limit processing to the required subset .",
    "move all select attributesup the graph once more , to simplify the graph further .",
    "move all select sourcesup the graph in order to combine them .",
    "convert processed source collectionsto externalsource collections . remove parts of the graph with unnecessary dependencies .",
    "remove source collectionsthat are essentially a passsource collection .",
    "integrate source collectionsand their parents if possible .",
    "unite identical source collections , especially those with the same parents .",
    "no more of these modifications are possible .",
    "a dependency graph of source collectionscan be simplified as part of the optimization routines ( algorithm [ algo : simplifyforload ] ) .",
    "a source collectionthat has already been fully processed does not have to be processed again .",
    "all these source collectionscan be substituted with an externalsource collectionthat represents the same catalog .",
    "furthermore , the complexity of a dependency graph can be reduced by combining operators or removing redundant ones .",
    "for example , the initial source collectionin fig .",
    "[ fig : scintroexample2 ] is an externalsource collectionfor simplicity . in a realistic scenario",
    ", this source collectionwould have dependencies of its own and would only be substituted with an externalsource collectionjust before processing . in fig .",
    "[ fig : scintreexamplesources1 ] two serial select attributessource collectionsare combined and in fig .",
    "[ fig : scintreexampledata4 ] two parallel select sourcessource collectionsare combined .",
    "unnecessary parts of a dependency graph can be removed by moving select attributessource collectionsup in the graph ( algorithm [ algo : optimizeforload ] ) .",
    "the result of moving a select attributesup past a concatenate attributes , might be that one of the dependencies of the concatenate attributesdoes not represent attributes anymore .",
    "the part of the graph that ends with this dependency might be removed from the graph in its entirety .",
    "the set of sources of a concatenate attributesis the intersection of the sets of sources of its parents .",
    "therefore it is only possible to remove this part of the dependency graph if doing so does not influence the selection of sources .",
    "the logical relations algorithm of paper iiis used to determine whether this is the case .",
    "select sourcessource collectionsare moved through the dependency graph to ensure that only those parts of the source collectionsare processed that are required to create the catalog data of the end node ( algorithm [ algo : optimizeforload ] ) .",
    "filter sourcessource collectionsfirst have to be converted into a select sources . before moving the select sourcessource collectionsup the dependency graph ,",
    "they are moved down in order to copy them to all parts of the dependency graph they are applicable to .    in fig .",
    "[ fig : scintreexampledata ] the select sourcessource collectionis moved up through the attribute calculatorsource collection .",
    "this creates a copy of the attribute calculatorthat represents a subset of the sources of the original .",
    "the source collectionsare well suited for parallelization because they are processed on a per - source basis .",
    "a source collectioncan be parallelized by creating a set of select sources(or filter sources ) source collectionsthat each select a subset of the original target , such that all sources are selected exactly once .",
    "the set of select sourcessource collectionsis then combined with a concatenate sourcessource collectionwhich can replace the original source collectionin the dependency graph .",
    "further optimization can move the select sourcesup to parallelize the entire graph .",
    "the parallelization algorithm is currently not implemented in astro - wise .",
    "the result of the dependency graph optimization is a set of source collectionsthat requires the least amount of processing to create the requested catalog data .",
    "the information system will recursively process the source collectionsand store the results if necessary .",
    "the mechanisms designed for the research presented in this paper are intended be used in conjunction with existing large - scale data storage and processing facilities .",
    "therefore , the precise way catalog data is processed and stored is largely beyond the scope of this paper and will depend on what is available in the information system .",
    "we give a general discussion of how the processing and storage could be achieved and highlight how this is implemented in astro - wise .",
    "in particular , for this paper we assume the existence of mechanisms for authentication of users , privilege management and for queuing requests when processing source collectionson shared resources .",
    "[ sec : scviewsandbackends ] the information system can process the source collectionson the most suitable subsystem to achieve scalability for large scale catalogs and real time interaction for small scale catalogs .",
    "we describe the different subsystems to evaluate the operators on :    * * database * : the selection and combining operators are designed to be evaluated on a database .",
    "the operators of consecutive source collectionscan be combined into one database query .",
    "the database can create indexes on columns containing attributes that are frequently used in selection criteria and can automatically cache the results .",
    "some source collections , in particular attribute calculators , will not be suitable to be processed on the database . * * workstation * : the processing can be performed on the workstation of the scientist for source collectionthat can not be processed on the database . furthermore , all the relational operators should also be evaluated on the local machine during interactive visualization of small datasets .",
    "the latency of a round trip to the database or distributed computing facility is too large for responsive interaction .",
    "such a local implementation of the source collectionsholds all the catalog data in memory or in files . *",
    "* distributed computation * : operators that require large computations can be performed on a distributed processing cluster .",
    "this is done by parallelizing the respective parts of the dependency graph and evaluating each sub - graph on a cluster node",
    ".    within astro - wise , most operators can be performed on both the oracle 11 g database or in the python .",
    "database queries usually scale linearly ; requests similar to the example of section [ sec : scexample ] are typically delivered with speeds of 100000 source attributes per second in the current setup .",
    "there is currently no explicit functionality to process source collectionson the distributed processing cluster .",
    "the result of processing a source collection  the exact set of sources and the values of the attributes  only has to be stored if this is necessary for performance reasons .",
    "therefore we make no explicit distinction between storing and caching of catalog data .",
    "the optimization process ( section  [ sec : sctreemodifications ] ) creates copies of source collectionsthat represent subsets of the originals . if the information system decides to store the processing result of such a copy , it will append the catalog data of the copy to that of the original . deciding what should be stored",
    "is primarily the responsibility of the information system .",
    "the decision should be made for individual processing results .",
    "[ sec : sccachingsources ] for example , it can be useful to store the identifiers of the sources without storing the values of the attributes in order to store the result of evaluating a complex selection criterion .",
    "different source collectionsthat represent the same sources can share this processing result .",
    "a key principle of the presented research , inherited from astro - wise , is that a source collectioncannot be altered once stored .",
    "therefore , any stored catalog data of a source collectioncannot change either .",
    "reliability of the data storage , e.g. acid properties @xcite , is automatically achieved as a result .",
    "for example , an incomplete database transaction will not leave the database in an invalid state because these will only append data that could also be ingested partially in the first place .",
    "stored catalog data can , in principle , also be deleted at any time , since it can always be recreated .",
    "a deletion mechanism is currently not incorporated in astro - wise ; instead , all catalog data is backed up regularly to be able to recover quickly from database failures .",
    "the last node in the dependency graph represents the requested catalog .",
    "once it has been processed , the catalog data can be returned to the scientist or used for further analysis or visualization .",
    "any temporary transient source collectionsinstantiated for the processing are discarded .",
    "the presented work shows a novel approach for the handling of source catalogs , as incorporated in astro - wise .",
    "the core difference between the astro - wiseapproach and the way astronomical catalogs are traditionally disclosed , is that the user works with data models rather than a set of tables in a relation database .",
    "we showed how data pulling is extended to source catalogs , a first step to data pulling and data lineage in the analysis domain .",
    "a process target  labeled a source collection  is designed to represent catalog data and operations thereon .",
    "we summarize the key features of our design :    * source collectionsare primarily created automatically by the information system through data pulling .",
    "source collectionsthat derive new data are created as general as possible in order to facilitate reuse and to prevent duplication of data .",
    "* source collectionsallow a functional approach to target processing : they can be seen as the operation to create the catalog data .",
    "a source collectionis only processed when this is required , not necessarily at the moment it is created .",
    "every source collectionclass correspond to an elementary operation on catalogs ; complex operations should be split over multiple source collectioninstances . * the source collectionhave full data lineage , which allows the information system to assess aspects of the catalogs without processing them .",
    "for example , it allows the information system to optimize the a dependency graph of source collectionsbefore processing it . *",
    "a source collectionis processed by creating temporary copy of the dependency graph and reordering the dependencies so they are as specific as possible in order to minimize the required processing . * a generic source collectionclass is designed for the calculation of new attributes from existing attributes .",
    "this offers a framework for scientists to implement their own methods while enforcing the benefits of full data lineage and data pulling .",
    "the astro - wiseway of handling astronomical catalogs takes care of most of the administrative tasks automatically .",
    "discovery of existing catalogs and creation of new catalog is done in the same way , by requesting the required end product .",
    "catalogs are shared implicitly , because existing catalogs are discovered automatically .",
    "new catalogs are automatically created in their most general form , but only the necessary parts are processed . together , this allows scientists to focus on the data itself and the science they want to perform instead of how the data is handled .",
    "buddelmeijer , h. , valentijn , e.a . : leveraging data lineage to infer logical relations between sets . in prep .",
    "( 2011a ) ( paper ii ) buddelmeijer , h. , valentijn , e.a . :",
    "query driven visualization of astronomical catalogs .",
    "codd , e.f . : a relational model of data for large shared data banks .",
    "acm 13 , 377387 ( 1970 ) gray , j. : the transaction concept : virtues and limitations .",
    "proceedings of the 7th international conference on very large databases . 144154 ( 1981 )",
    "gray , j. , szalay , a.s .",
    ", thakar , a.r . , kunszt , p.z . ,",
    "stoughton , c. , slutz , d. , van den berg , j. : data mining the sdss skyserver database .",
    "arxiv : cs/0202014 hambly , n.c . ,",
    "collins , r.s . , cross , n.j.g . ,",
    "mann , r.g . ,",
    "read , m.a .",
    ", sutorius , e.t.w . ,",
    "bond , i. , bryant , j. , emerson , j.p . ,",
    "lawrence , a. , rimoldini , l. , stewart , j.m . ,",
    "williams , p.m. , adamson , a. , hirst , p. , dye , s. , warren , s.j . : the wfcam science archive .",
    "mnras384 , 637662 ( 2008 ) mcfarland , j. : astro - wise : an information system for wide - field imaging surveys . in prep .",
    "( 2010 ) mwebaze , j. , boxhoorn , d. , valentijn , e.a .",
    ": astro - wise : tracing and using lineage for scientific data processing . in : proceedings of the 2009 international conference on network - based information systems , nbis 09 , pp .",
    "ieee computer society , washington , dc , usa ( 2009 ) szalay , a.s .",
    ", gray , j. , thakar , a.r .",
    ", kunszt , p.z . ,",
    "malik , t. , raddick , j. , stoughton , c. , vandenberg , j. : the sdss skyserver : public access to the sloan digital sky server data .",
    "arxiv : cs/0202013 thulasiraman , k. , swamy , m.n.s . :",
    "graphs : theory and algorithms .",
    "wiley - interscience ( 1992 )"
  ],
  "abstract_text": [
    "<S> we present the design of a novel way of handling astronomical catalogs in astro - wisein order to achieve the scalability required for the data produced by large scale surveys . </S>",
    "<S> a high level of automation and abstraction is achieved in order to facilitate interoperation with visualization software for interactive exploration . at the same time flexibility in processing </S>",
    "<S> is enhanced and data is shared implicitly between scientists .    </S>",
    "<S> this is accomplished by using a data model that primarily stores how catalogs are derived ; the contents of the catalogs are only created when necessary and stored only when beneficial for performance . </S>",
    "<S> discovery of existing catalogs and creation of new catalogs is done through the same process by directly requesting the final set of sources ( astronomical objects ) and attributes ( physical properties ) that is required , for example from within visualization software .    </S>",
    "<S> new catalogs are automatically created to provide attributes of sources for which no suitable existing catalogs can be found . </S>",
    "<S> these catalogs are defined to contain the new attributes on the largest set of sources the calculation of the attributes is applicable to , facilitating reuse for future data requests . </S>",
    "<S> subsequently , only those parts of the catalogs that are required for the requested end product are actually processed , ensuring scalability .    </S>",
    "<S> the presented mechanisms primarily determine which catalogs are created and what data has to be processed and stored : the actual processing and storage itself is left to existing functionality of the underlying information system . </S>"
  ]
}