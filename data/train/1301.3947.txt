{
  "article_text": [
    "genomic technologies were originally developed and applied for basic science research and hypothesis generation @xcite .",
    "as these technologies mature , they are increasingly being used as clinical tools for diagnosis or prognosis @xcite .",
    "the high - dimensional measurements made by microarrays can be used to classify patients into predictive , prognostic , or diagnostic groups . despite the incredible clinical promise of these technologies there",
    "have only been a few signatures that have successfully been translated into the clinic .",
    "one of the reasons for the relatively low rate of success is the impact of unmeasured technological or biological confounders .",
    "these artifacts are collectively referred to as `` batch effects '' because the processing date , or batch , is the most commonly measured surrogate for these unmeasured variables in genomic studies @xcite .",
    "the umbrella term batch effects also refers to any unmeasured variables that can vary from experiment to experiment , ranging from the technician who performs the experiment to the temperature and ozone levels that day @xcite .",
    "batch effects are responsible for the failure of promising genomic prognostic signatures @xcite , major ambiguities in published genomic results @xcite , and retractions of widely - publicized findings @xcite . in many experiments , the signal from these unmeasured confounders is larger than the biological signal of interest @xcite .",
    "but the impact of batch effects on prediction problems has only recently been demonstrated @xcite .",
    "batch effects were also recognized as a significant hurdle in the development of personalized genomic biomarkers in the institute of medicine s report on clinical genomics @xcite .",
    "while a number of methods have been developed for removing batch effects in population - based genomic studies @xcite , there is currently no method for removing batch effects for prediction problems .",
    "there are two key differences between population level corrections and corrections designed for prediction problems .",
    "first , population level corrections assume that the biological groups of interest are known in advance . in prediction problems ,",
    "the goal is to predict the biological group .",
    "second , in prediction problems , new samples are observed one at a time , so the surrogate batch variable will have a unique and unknown value for each sample .",
    "here we propose frozen surrogate variable analysis ( fsva ) as a method for batch correction in prediction problems .",
    "fsva borrows strength from a reference database to address the challenges unique to batch correction for prediction .",
    "the fsva approach has two main components .",
    "first , surrogate variable analysis ( sva ) is used to correct for batch effects in the training database .",
    "any standard classification algorithm can then be applied to build a classifier based on this clean training data set .",
    "second , probability weights and coefficients estimated on the training database are used to remove batch effects in new samples .",
    "the classifier trained on the clean database can then be applied to these cleaned samples for prediction .",
    "we show with simulated data that the fsva approach leads to substantial improvement in predictive accuracy when unmeasured variables are correlated with biological outcomes .",
    "we also apply fsva to multiple publicly available microarray data sets and show improvements in prediction accuracy after correcting for batch .",
    "the methods developed in this paper have been implemented in the freely available ` sva ` bioconductor package .",
    "the first step in batch correction for prediction problems is to remove batch effects from the training set . in the training set ,",
    "the biological groups are known .",
    "this setting is similar to the population genomics setting and we can use a model for gene expression data originally developed for population correction of unmeasured confounders . if there are @xmath0 measured features and @xmath1 samples in the training set , we let @xmath2 be the matrix of feature data , where @xmath3 is the value of feature @xmath4 for sample @xmath5 . for convenience",
    ", we will refer to @xmath6 as the expression matrix for the remainder of the paper .",
    "however , our methods can be generally applied to any set of features , including measures of protein abundance , gene expression , or dna methylation .",
    "we propose a linear model for the relationship between the expression levels and the outcome of interest @xmath7 : @xmath8 .",
    "the @xmath9 are a set of basis functions parameterizing the relationship between expression and outcome .",
    "if the prediction problem is two - class , then @xmath10 and @xmath11 is an indicator function that sample @xmath5 belongs to class one . in a multi - class prediction problem",
    "@xmath12 and the @xmath9 may represent a factor model for each class . in matrix form this model can be written @xcite .",
    "@xmath13 where @xmath14 is a model matrix of @xmath15 biological variables of interest for the @xmath1 samples , @xmath16 are the coefficients for these variables , and @xmath17 is the matrix of errors .    in genomic studies , the error term @xmath18 is not independent across samples @xcite .",
    "that is , there is still correlation between rows of @xmath18 after accounting for the model @xmath19 .",
    "the correlation is due to unmeasured and unwanted factors such as batch",
    ". we can modify model [ eqn_before_batch ] to account for these measured biological factors and unmeasured biological and non - biological factors :    @xmath20    where @xmath21 is a @xmath22 random matrix , called a dependence kernel @xcite that parameterizes the effect of unmeasured confounders , @xmath23 is the @xmath24 matrix of coefficients for @xmath25 , and @xmath26 is the @xmath27 matrix of independent measurement errors .",
    "we previously demonstrated that such a decomposition of the variance exists under general conditions typically satisfied in population genomic experiments @xcite .    in the training set ,",
    "the biological classes are known , so @xmath19 is known and fixed .",
    "but the matrices @xmath28 , @xmath29 and @xmath25 must be estimated .",
    "fsva first performs surrogate variable analysis ( sva ) on the training database in order to identify surrogates for batch effects in the training samples .",
    "the training set can be `` cleaned '' of batch effects by regressing the effect of the surrogate variables out of the data for each feature .",
    "any classification algorithm can then be developed on the basis of the clean training data set .",
    "sva is an iterative algorithm that alternates between two steps .",
    "first sva estimates the probabilities @xmath30 using an empirical bayes estimation procedure @xcite .",
    "these probabilities are then combined to define an estimate of the probability that a gene is associated with unmeasured confounders , but not with the group outcome @xmath31 the second step of the sva algorithm weighs each row of the expression matrix @xmath6 by the corresponding probability weight @xmath32 and performs a singular value decomposition of the weighted matrix .",
    "letting @xmath33 the decomposition can be written @xmath34 .",
    "after iterating between these two steps , the first @xmath35 weighted left singular vectors of @xmath6 are used as estimates of @xmath25 .",
    "an estimate of @xmath35 can be obtained either through permutation @xcite or asymptotic @xcite approaches .",
    "once estimates @xmath36 have been obtained , it is possible to fit the regression model in equation [ full_expression_matrix ] using standard least squares .",
    "the result are estimates for the coefficients @xmath37 and @xmath38 .",
    "batch effects can be removed from the training set by setting @xmath39 .",
    "any standard prediction algorithm can then be applied to @xmath40 to develop a classifier based on batch - free genomic data .",
    "the result is a prediction function @xmath41 that predicts the outcome variable @xmath7 based on the clean expression matrix .      removing batch effects from the training database",
    "is accomplished using standard population genomic sva batch correction .",
    "but the application of classifiers to new genomic samples requires batch correction of individual samples when both the batch and outcome variables are unknown .",
    "the fsva algorithm borrows strength from the training database to perform this batch correction .    to remove batch effects from a new sample @xmath42",
    ", it is first appended to the training data to create an augmented expression matrix @xmath43 $ ] where @xmath44 $ ] denotes concatenation of columns . to estimate the values of @xmath25 for the new sample",
    ", fsva uses a weighted singular value decomposition , using the probability weights estimated from the training database @xmath45 .",
    "the result is an estimate @xmath46 that includes a column for the new sample .    to remove batch effects from the new sample",
    ", fsva uses the coefficients estimated from the training database @xmath38 and the estimated surrogate variables : @xmath47 . if there are @xmath1 training samples , then the @xmath48st column of @xmath49 represents the new clean sample .",
    "the classifier built on the clean training data can be applied to this clean data set to classify the new sample .",
    "fsva requires that a new singular value decomposition be applied to the augmented expression matrix once for each new sample .",
    "although this is somewhat computationally intensive , in typical personalized medicine applications , sample collection and processing will be spread over a long period of time . in this",
    "setting , computational time is not of critical concern .",
    "however , for evaluating the fsva methodology or developing new classifiers using cross - validation , it is important to be able to quickly calculate clean expression values for test samples .",
    "we propose an approximate fsva algorithm that greatly reduces computing time by performing a streaming singular value decomposition @xcite .",
    "the basic idea behind our computation speed - up is to perform the singular value decomposition once on the training data , save the left singular vectors and singular values , and use them to calculate approximate values for the right singular values in new samples .    when removing batch effects from the training data , the last step is a weighted singular value decomposition of the training expression matrix @xmath50 .",
    "after convergence , the first @xmath35 columns of the matrix @xmath51 are the surrogate variables for the training set . since @xmath52 and @xmath51 are orthonormal matrices , we can write @xmath53 . the matrix @xmath54 projects the columns of @xmath6 onto the right singular vectors @xmath55 . pre - multiplying a set of new samples @xmath56 by @xmath57 results in an estimate of the singular values for the new samples : @xmath58 .",
    "the surrogate variable estimates for the new samples consist of the first @xmath35 columns of @xmath59 .",
    "we obtain clean data for the new samples using the estimated coefficients from the training set , identical to the calculation for the exact fsva algorithm : @xmath60 .",
    "estimates obtained using this approximate algorithm are not identical to those obtained using the exact fsva algorithm . the projection matrix used in the approximation , @xmath61 ,",
    "is calculated using only the samples in the training set .",
    "however , there is only a one - sample difference between the projection calculated in the training set and the projection that would be obtained with exact fsva . as the training set size grows , the approximation is closer and closer to the answer that would be obtained from the exact algorithm . for smaller databases ,",
    "there is less computational burden in calculating the exact estimates .",
    "however , for large training sets , the computational savings can be dramatic , as described in the simulation below .",
    "we performed a simulation examining the benefit of fsva in prediction problems . in order to do this , we simulated data using equation [ full_expression_matrix ] under different distributions of each parameter .",
    "we also discretized the probability weights @xmath62 and @xmath63 , and varied the distribution of these probability weights ( table [ dist_table ] ) .",
    "we crafted these simulations to mimic scenarios with a subtle outcome and a strong batch effect , which is frequently the case in genomic data .",
    ".*specifications for the three simulation scenarios used to show the performance of fsva .",
    "* we performed three simulations under slightly different parameterizations to show the effectiveness of fsva in improving prediction accuracy .",
    "parameters from equation [ full_expression_matrix ] were simulated using the distributions specified in this table . additionally , the percentage of features in the simulation affected by batch , outcome , or both are as indicated in this table . results from these simulations can be found in figure [ simres ] . [ cols=\"^,^,^\",options=\"header \" , ]     [ studytab ]",
    "batch effects have been recognized as a crucial hurdle for population genomics experiments @xcite .",
    "they have also been recognized as a critical hurdle in developing genomic signatures for personalized medicine @xcite .",
    "here we have introduced the first batch correction method specifically developed for prediction problems .",
    "our approach borrows strength from a training set to infer and remove batch effects in individual clinical samples .",
    "we have demonstrated the power of our approach in both simulated and real gene expression microarray data .",
    "however , our approach depends on similarity between the training set and the test samples , both in terms of the genes affected and the estimated coefficients . in small training sets ,",
    "these assumptions may be violated .",
    "similarly , training sets that show near perfect correlation between batch variables and biological classes represent an extreme case that can not be directly corrected using fsva .",
    "an interesting avenue for future research is the use of publicly available microarray data to build increasingly large training databases for batch removal ."
  ],
  "abstract_text": [
    "<S> batch effects are responsible for the failure of promising genomic prognostic signatures , major ambiguities in published genomic results , and retractions of widely - publicized findings . </S>",
    "<S> batch effect corrections have been developed to remove these artifacts , but they are designed to be used in population studies . </S>",
    "<S> but genomic technologies are beginning to be used in clinical applications where samples are analyzed one at a time for diagnostic , prognostic , and predictive applications . </S>",
    "<S> there are currently no batch correction methods that have been developed specifically for prediction . in this paper </S>",
    "<S> , we propose an new method called frozen surrogate variable analysis ( fsva ) that borrows strength from a training set for individual sample batch correction . </S>",
    "<S> we show that fsva improves prediction accuracy in simulations and in public genomic studies . </S>",
    "<S> fsva is available as part of the ` sva ` _ bioconductor _ package . </S>",
    "<S> genomics ; prediction ; batch effects ; personalized medicine ; surrogate variable analysis </S>"
  ]
}