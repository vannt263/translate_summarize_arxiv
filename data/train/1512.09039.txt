{
  "article_text": [
    "the social adoption of new technologies in networked cyberphysical systems relies heavily on the privacy preservation of individual information .",
    "social networking , the power grid , and smart transportation are only but a few examples of domains in need of privacy - aware design of control and coordination strategies . in these scenarios ,",
    "the ability of a networked system to fuse information , compute common estimates of unknown quantities , and agree on a common view of the world is critical . motivated by these observations , this paper studies the multi - agent average consensus problem , where a group of agents seek to agree on the average of their individual values by only interchanging information with their neighbors .",
    "this problem has numerous applications in synchronization , network management , and distributed control / computation / optimization . in the context of privacy preservation , the notion of differential privacy has gained significant popularity due to its rigorous formulation and proven security properties , including resilience to post - processing and side information , and independence from the model of the adversary . roughly speaking ,",
    "a strategy is differentially private if the information of an agent has no significant effect on the aggregate output of the algorithm , and hence its data can not be inferred by an adversary from its execution .",
    "this paper is a contribution to the emerging body of research that studies privacy preservation in cooperative network systems , specifically focused on gaining insight into the achievable trade - offs between privacy and performance in multi - agent average consensus .",
    "the problem of multi - agent average consensus has been a subject of extensive research in networked systems and it is impossible to survey here the vast amount of results in the literature .",
    "we provide  @xcite and the references therein as a starting point for the interested reader . in cyberphysical systems ,",
    "privacy at the physical layer provides protection beyond the use of higher - level encryption - based techniques .",
    "information - theoretic approaches to privacy at the physical layer have been actively pursued  @xcite .",
    "recently , these ideas have also been utilized in the context of control  @xcite .",
    "the paper  @xcite also surveys the more recent game - theoretic approach to the topic . in computer science ,",
    "the notion of differential privacy , first introduced in  @xcite , and the design of differentially private mechanisms have been widely studied in the context of privacy preservation of databases .",
    "the work  @xcite provides a recent comprehensive treatment .",
    "a well - known advantage of differential privacy over other notions of privacy is its immunity to post - processing and side information , which makes it particularly well - suited for multi - agent scenarios where agents do not fully trust each other and/or the communication channels are not fully secure . as a result , this notion has been adopted by recent works in a number of areas pertaining to networked systems , such as control  @xcite , estimation  @xcite , and optimization  @xcite . of relevance to our present work , the paper  @xcite studies the average consensus problem with differentially privacy guarantees and proposes an adjacency - based distributed algorithm with decaying laplace noise and mean - square convergence .",
    "the algorithm preserves the differential privacy of the agents initial states but the expected value of its convergence point depends on the network topology and may not be the exact average , even in expectation .",
    "by contrast , the algorithm proposed in this work enjoys almost sure convergence , asymptotic unbiasedness , and an explicit characterization of its convergence rate .",
    "our results also allow individual agents to independently choose their level of privacy .",
    "the problem of privacy - preserving average consensus has also been studied using other notions of privacy .",
    "the work  @xcite builds on  @xcite to let agents have the option to add to their first set of transmitted messages a zero - sum noise sequence with finite random length , which in turn allows the coordination algorithm to converge to the exact average of their initial states .",
    "as long as an adversary can not listen to the transmitted messages of an agent as well as all its neighbors , the privacy of that agent is preserved , in the sense that different initial conditions may produce the same transmitted messages .",
    "this idea is further developed in  @xcite , where agents add an infinitely - long exponentially - decaying zero - sum sequence of gaussian noise to their transmitted messages .",
    "the algorithm has guaranteed mean - square convergence to the average of the agents initial states and preserves the privacy of the nodes whose messages and those of their neighbors are not listened to by the malicious nodes , in the sense that the maximum - likelihood estimate of their initial states has nonzero variance .",
    "finally , @xcite considers the problem of privacy preserving maximum consensus .",
    "we study the average consensus problem where a group of agents seek to compute and agree on the average of their local variables while seeking to keep them differentially private against an adversary with potential access to all group communications .",
    "this privacy requirement also applies to the case where each agent wants to keep its initial state private against the rest of the group ( e.g. , due to the possibility of communication leakages ) .",
    "the main contributions of this work are the characterization and optimization of the fundamental trade - offs between differential privacy and average consensus .",
    "our first contribution is the formulation and formal proof of a general impossibility result .",
    "we show that as long as a coordination algorithm is differentially private , it is impossible to guarantee the convergence of agents states to the average of their initial values , even in distribution .",
    "this result automatically implies the same impossibility result for stronger notions of convergence . motivated by it , our second contribution is the design of a linear laplacian - based consensus algorithm that achieves average consensus in expectation the most that one can expect .",
    "we prove the almost sure convergence and differential privacy of our algorithm and characterize its accuracy and convergence rate .",
    "our final contribution is the computation of the optimal values of the design parameters to achieve the most accurate consensus possible .",
    "letting the agents fix a ( local ) desired value of the privacy requirement , we minimize the variance of the algorithm convergence point as a function of the noise - to - state gain and the amplitude and decay rate of the noise .",
    "we show that the minimum variance is achieved by the one - shot perturbation of the initial states by laplace noise .",
    "this result reveals the optimality of one - shot perturbation for static average consensus , previously ( but implicitly ) shown in the sense of information - theoretic entropy .",
    "various simulations illustrate our results .",
    "this section introduces notations and basic concepts .",
    "we denote the set of reals , positive reals , non - negative reals , positive integers , and nonnegative integers by @xmath0 , @xmath1 , @xmath2 , @xmath3 , and @xmath4 , respectively .",
    "we denote by  @xmath5 the euclidean norm .",
    "we let @xmath6 denote the space of vector - valued sequences in  @xmath7 . for @xmath8",
    ", we use the shorthand notation @xmath9 and @xmath10 . @xmath11 and @xmath12 denote the identity matrix and the vector of ones , respectively . for @xmath13 , @xmath14 denotes the average of its components .",
    "we let @xmath15 .",
    "note that @xmath16 is diagonalizable , has one eigenvalue equal to @xmath17 with eigenspace @xmath18 and all other eigenvalues equal  @xmath19 . for a vector space @xmath20 ,",
    "we let @xmath21 denote the vector space orthogonal to @xmath22 .",
    "a matrix @xmath23 is stable if all its eigenvalues have magnitude strictly less than 1 .",
    "a function @xmath24 belongs to class @xmath25 if it is continuous and strictly increasing and @xmath26 .",
    "similarly , a function @xmath27 belongs to class @xmath28 if @xmath29 belongs to class @xmath25 for any @xmath30 and @xmath31 is decreasing and @xmath32 for any @xmath33 . for @xmath34 , the euler function",
    "is given by @xmath35 .",
    "note that @xmath36 for a function @xmath37 and sets @xmath38 and @xmath39 , we use @xmath40 and @xmath41 . in general , @xmath42 . finally , for any topological space @xmath43 , we denote by @xmath44 the set of borel subsets of  @xmath43 .",
    "we present some useful notions on algebraic graph theory following  @xcite .",
    "let @xmath45 denote a weighted undirected graph with vertex set @xmath22 of cardinality  @xmath46 , edge set @xmath47 , and symmetric adjacency matrix @xmath48 .",
    "a path from @xmath49 to @xmath50 is a sequence of vertices starting from @xmath49 and ending in @xmath50 such that any pair of consecutive vertices is an edge .",
    "the set of neighbors @xmath51 of @xmath49 is the set of nodes @xmath50 such that @xmath52 .",
    "a graph is connected if for each node there exists a path to any other node .",
    "the weighted degree matrix is the diagonal matrix @xmath53 with diagonal @xmath54 .",
    "the laplacian is @xmath55 and has the following properties :    * @xmath56 is symmetric and positive semi - definite ; * @xmath57 and @xmath58 , i.e. , @xmath19 is an eigenvalue of @xmath56 corresponding to the eigenspace @xmath59 ; * @xmath60 is connected if and only if @xmath61 , so @xmath19 is a simple eigenvalue of @xmath56 ; * all eigenvalues of @xmath56 belong to @xmath62 $ ] , where @xmath63 is the largest element of @xmath64 .    for convenience ,",
    "we define @xmath65 .      here",
    "we briefly review basic notions on probability following  @xcite .",
    "consider a probability space @xmath66 . if @xmath67 are two events with @xmath68 , then @xmath69 .",
    "for simplicity , we may sometimes denote events of the type @xmath70 by  @xmath71 , where @xmath72 is a logical statement on the elements of @xmath73 .",
    "clearly , for two statements @xmath72 and @xmath74 , @xmath75 a random variable is a measurable function @xmath76 . for any @xmath77 and any random variable @xmath43 with",
    "finite expected value @xmath78 and finite nonzero variance @xmath79 , chebyshev s inequality states that @xmath80 for a random variable @xmath43 , let @xmath81 $ ] and @xmath82 denote its expectation and cumulative distribution function , respectively . a sequence of random variables @xmath83 converges to a random variable @xmath43    * almost surely ( a.s . ) if @xmath84 ; * in mean square if @xmath85 , { \\mathbb{e}}[x^2 ] < \\infty$ ] for all @xmath86 and @xmath87 = 0 $ ] ; * in probability if @xmath88 for any @xmath89 ; * in distribution or weakly if @xmath90 for any @xmath91 at which @xmath82 is continuous .",
    "almost sure convergence and convergence in mean square imply convergence in probability , which itself implies convergence in distribution .",
    "moreover , if @xmath92 for all @xmath93 and some fixed random variable @xmath94 with @xmath95 < \\infty$ ] , then convergence in probability implies mean square convergence , and if @xmath43 is a constant , then convergence in distribution implies convergence in probability .",
    "a zero - mean random variable @xmath43 has laplace distribution with scale @xmath96 , denoted @xmath97 , if its pdf  is given by @xmath98 for any @xmath99 .",
    "it is easy to see that @xmath100 has exponential distribution with rate @xmath101 .",
    "this section briefly describes notions of robustness for discrete - time systems following  @xcite .",
    "consider a discrete - time system of the form @xmath102 where @xmath103 is a disturbance input , @xmath104 is the state , and @xmath105 is a vector field satisfying @xmath106 .",
    "the system   is globally input - to - state stable ( iss ) if there exists a class @xmath28 function  @xmath107 and a class @xmath25 function  @xmath108 such that , for any bounded input @xmath109 , any initial condition @xmath110 , and all @xmath93 , @xmath111 where @xmath112 . the system   has a @xmath25-asymptotic gain if there exists a class @xmath25 function @xmath113 such that , for any initial condition @xmath110 , @xmath114 if a system is iss , then it has a @xmath25-asymptotic gain .",
    "furthermore , any lti system @xmath115 is iss if @xmath116 is stable .",
    "consider a group of @xmath46 agents whose interaction topology is described by an undirected connected graph  @xmath60 .",
    "the group objective is to compute the average of the agents initial states while preserving the privacy of these values against potential adversaries eavesdropping on all the network communications .",
    "note that this privacy requirement is the same as the case where each agent wants to keep its initial state private against the rest of the group due to the possibility of communication leakages .",
    "we next generalize the exposition in  @xcite to provide a formal presentation of this problem .",
    "the state of each agent @xmath117 is represented by @xmath118 .",
    "the message that agent @xmath49 shares with its neighbors about its current state is denoted by  @xmath119 . for convenience , the aggregated network state and the vector of transmitted messages",
    "are denoted by @xmath120 and @xmath121 , respectively .",
    "agents update their states in discrete time according to some rule , @xmath122 with initial states @xmath123 , where the state - transition function @xmath124 is such that its @xmath49th element depends only on @xmath125 and @xmath126 .",
    "the messages are calculated from @xmath127 where @xmath128 is such that its @xmath49th element depends only on @xmath125 and @xmath129 . for simplicity , we assume that @xmath130 and @xmath131 are continuous .",
    "@xmath132 is a vector random variable , with @xmath133 being the noise generated by agent @xmath49 at time @xmath134 from an arbitrary distribution .",
    "consequently , @xmath135 and @xmath136 are sequences of vector random variables on the total sample space @xmath137 whose elements are noise sequences @xmath138 .",
    "although one could choose @xmath131 to only depend on @xmath139 , corrupting the messages by noise is necessary to preserve privacy . given an initial state @xmath140 , @xmath136 is uniquely determined by @xmath138 according to  - .",
    "therefore , the function @xmath141 such that @xmath142 is well defined .",
    "we next introduce the notion of differential privacy .    *",
    "( differential privacy)*[def : privacy ] given @xmath143 , the initial network states @xmath144 and @xmath145 are @xmath146-adjacent if , for some @xmath147 , @xmath148 for @xmath149 . given @xmath150 , the dynamics  - is @xmath151-differentially private if , for any pair @xmath144 and @xmath145 of @xmath146-adjacent initial states and any set @xmath152 , @xmath153    a final aspect to consider is that , because of the presence of noise , the agents states under   might not converge exactly to their initial average @xmath154 , but to a neighborhood of it .",
    "this is captured by the notion of accuracy .    *",
    "( accuracy)*[def : accuracy ] for @xmath155 $ ] and @xmath156 , the dynamics  - is @xmath157-accurate if , from any initial state @xmath140 , the network state @xmath158 converges to @xmath159 as @xmath160 , with @xmath161 = { \\operatorname{ave}(\\theta_0 ) } { \\mathbf{1}}_n$ ] and @xmath162 .    in definition  [ def : accuracy",
    "] , the type of convergence of @xmath158 to @xmath163 can be any of the four classes described in section  [ subsection : probability ] . furthermore",
    ", for each notion of convergence , @xmath164-accuracy is equivalent to the convergence of @xmath158 to @xmath165 .",
    "we are finally ready to formally state our problem .    *",
    "( differentially private average consensus)*[problem : main ] design the dynamics  , the inter - agent messages  , and the distribution of noise sequences @xmath138 such that asymptotic average consensus is achieved with @xmath157-accuracy while guaranteeing @xmath151-differential privacy for ( finite ) @xmath151 , @xmath166 , and @xmath167 as small as possible .",
    "in this section we establish the impossibility of solving problem  [ problem : main ] with @xmath164-accuracy , even if considering the weakest notion of convergence .    [",
    "prop : bound ] consider a group of agents executing a distributed algorithm of the form   with messages generated according to  .",
    "then , for any @xmath168 , agents can not simultaneously converge to the average of their initial states in distribution and preserve @xmath151-differential privacy of their initial states .",
    "we reason by contradiction .",
    "assume there exists an algorithm that achieves convergence in distribution to the exact average of the network initial state and preserves @xmath151-differential privacy of it .",
    "since the algorithm must preserve the privacy of _ any _ pair of @xmath146-adjacent initial conditions , consider a specific pair satisfying @xmath169 for some @xmath170 and @xmath171 for all @xmath172 . since @xmath154 is fixed ( i.e. , deterministic ) , the convergence of @xmath173 , @xmath174 to @xmath154 is also in probability .",
    "thus , for any @xmath117 and any @xmath89 , we have @xmath175 , for @xmath176 .",
    "therefore , for any @xmath177 , there exists @xmath86 such that for all @xmath117 , @xmath178 now , considering  - , it is clear that , for any fixed initial state @xmath140 and any @xmath86 , @xmath179 is uniquely determined by @xmath180 and @xmath181 is uniquely determined by @xmath179 .",
    "therefore , the functions @xmath182 such that @xmath183 are well defined and continuous ( due to continuity of @xmath130 and @xmath184 ) .",
    "next , for @xmath185 , define @xmath186 , where @xmath187 and @xmath188 is the @xmath189-neighborhood of @xmath190 . by  , we have @xmath191 note that @xmath192 is open as it is the continuous pre - image of an open set , so @xmath193 is borel . to reach a contradiction , we define @xmath194 and show that @xmath195 can be made arbitrarily small by showing that @xmath196 . to do this , note that by the definitions of @xmath197 , @xmath198 and @xmath192 , we have @xmath199 recall that in  , @xmath130 is such that the next state of each agent only depends on its current state and the messages it receives .",
    "hence , since for all @xmath172 , @xmath200 , we have from   that @xmath201 where @xmath202 is the same as @xmath203 except that the requirement on @xmath204 ( to be close to @xmath205 ) is relaxed .",
    "now , since @xmath206 and , by choosing @xmath207 , we get @xmath208 , we conclude that @xmath209 , which implies @xmath210 , so we get @xmath211 as desired . now , let @xmath212 .",
    "for any initial condition @xmath140 , @xmath213 hence , since the algorithm is @xmath151-differentially private , @xmath214 thus , using   and  , we have for all @xmath177 , @xmath215 which is clearly a contradiction because @xmath151 is a finite number , completing the proof .",
    "since convergence in distribution is the weakest notion of convergence , proposition  [ prop : bound ] implies that a differentially private algorithm can not guarantee any type of convergence to the exact average .",
    "therefore , in our forthcoming discussion , we relax the exact convergence requirement and allow for convergence to a random variable that is at least unbiased ( i.e. , centered at the true average ) .",
    "here , we develop a solution to problem  [ problem : main ] . consider the following linear distributed dynamics , @xmath216 for @xmath217 , where @xmath218 is the step size , @xmath219 is a diagonal matrix with diagonal @xmath220 and @xmath221 for each @xmath117 , and the messages are generated according to @xmath222 where the @xmath49th component of the noise vector @xmath223 has the laplace distribution @xmath224 at any time @xmath225 with @xmath226 note that   is a special case of   ( since @xmath227 ) and   a special case of  .",
    "also note that without the term @xmath228 , the average of the agents initial states would be preserved throughout the evolution .    *",
    "( comparison with the literature ) * the proposed algorithm  - has similarities and differences with the algorithm proposed in  @xcite which can be expressed ( with a slight change of notation in using @xmath229 instead of @xmath230 ) as @xmath231 \\theta(k ) + \\big[s - s d^{-1 } l          \\big ] \\eta(k ) .",
    "\\end{aligned}\\ ] ] if each agent selects @xmath232 , then we recover  - . as we show later , this particular choice results in an unbiased convergence point , while in general the expected value of the convergence point of the algorithm in  @xcite depends on the graph structure and may not be the true average .",
    "furthermore , this algorithm is only shown to exhibit mean square convergence of @xmath158 for @xmath233 , while here we provide an explicit expression for the convergence point and establish convergence in the stronger a.s .",
    "sense for larger range of @xmath234 . as we show later , the inclusion of @xmath235 is critical , as it leads to identifying the optimal algorithm performance . on a different note ,",
    "the algorithms in  @xcite and  @xcite add a noise sequence to the messages which is correlated over time ",
    "the latter using a different notion of privacy .",
    "@xcite generate a single noise at time @xmath236 and add a scaled version of it to the messages at every time @xmath237 , leading to an effectively `` one - shot''-type of perturbation .",
    "we show in section  [ section : optimal - noise - selection ] that the one - shot approach is optimal for static average consensus while sequential perturbation is necessary for dynamic scenarios .",
    "this section analyzes the asymptotic correctness of the algorithm  - and characterizes its rate of convergence .",
    "we start by establishing convergence .    *",
    "( asymptotic convergence)*[prop : convergence ] consider a network of @xmath46 agents executing the distributed dynamics  - .",
    "define the random variable @xmath163 as @xmath238 then , @xmath163 is well - defined a.s . , and the states of all agents converge to @xmath163 almost surely",
    ".    note that @xmath221 ensures that @xmath239 is not empty .",
    "substituting   into  , the system dynamics is @xmath240 with @xmath241 and @xmath242 .",
    "for any @xmath243 , let @xmath244 multiplying both sides of   by @xmath245 on the left and using the fact that @xmath245 and @xmath56 commute , the dynamics of @xmath246  can be expressed as @xmath247 notice that @xmath248 is forward invariant under  . therefore , considering @xmath248 as the state space for   and noting that @xmath249 is stable on it , we deduce that   is iss .",
    "consequently , this dynamics has a @xmath25-asymptotic gain ( c.f .",
    "section  [ subsection : iss ] ) , i.e. , there exists @xmath250 such that @xmath251 therefore , @xmath252 implies @xmath253 . by definition , the latter means that there is @xmath89 such that for all @xmath254 there exists @xmath255 with @xmath256 .",
    "in other words , there exists a subsequence @xmath257 such that @xmath258 for all @xmath259 .",
    "this , in turn , implies that for all @xmath259 , @xmath260 , i.e. , @xmath261 according to  , this chain of implications gives @xmath262 the last equality holds because @xmath263 .",
    "therefore , we conclude @xmath264 from  , we see that a.s .",
    "convergence of @xmath139 requires a.s .",
    "convergence of @xmath265 as well .",
    "left multiplying   by @xmath266 , we obtain for all @xmath225 , @xmath267 which in turn implies @xmath268 we next prove that @xmath269 converges almost surely to @xmath163 . in order for the latter to be well - defined over  @xmath73",
    ", we simply set @xmath270 when the series does not converge .",
    "clearly , for any @xmath271 such that @xmath272 converges for all @xmath117 , we have @xmath273 .",
    "therefore , using  , @xmath274 note that , for each @xmath117 and any @xmath275 , if @xmath276 for all @xmath277 , then @xmath278 converges .",
    "therefore , using   and the definition of laplace distribution , we have for all @xmath275 , @xmath279 for each @xmath117 , because @xmath280 , there exists @xmath281 such that @xmath282 for @xmath283 .",
    "therefore , using the euler function @xmath284 , @xmath285 for all @xmath275 , and hence , @xmath286 this , together with   and  , implies that @xmath287 , which completes the proof .",
    "[ rem : ms ] from   and the fact that @xmath288 , we have @xmath289 for all @xmath93 .",
    "it is straightforward to show @xmath290 < \\infty$ ] , so , using proposition  [ prop : convergence ] , @xmath158 also converges to @xmath291 in mean square .",
    "our next aim is to characterize the convergence rate of the distributed dynamics  - . given the result in proposition  [ prop : convergence ] , we define the exponential mean - square convergence rate of the dynamics  - as @xmath292}{{\\mathbb{e}}\\big[(\\theta(0 ) - \\theta_\\infty        { \\mathbf{1}}_n)^t ( \\theta(0 ) - \\theta_\\infty { \\mathbf{1}}_n)\\big ] }    \\right)^\\frac{1}{2k } \\hspace*{-1ex}.\\end{aligned}\\ ] ] in the absence of noise ( @xmath293 ) , this definition coincides with the conventional exponential convergence rate of autonomous linear systems , see e.g. ,  @xcite .    *",
    "( convergence rate)*[prop : conv - rate ] under the hypotheses of proposition  [ prop : convergence ] , the exponential mean - square convergence rate of the distributed dynamics  -  is @xmath294 where @xmath295 and @xmath296 is the spectral radius of @xmath297 .    for convenience ,",
    "we let @xmath298 denote the convergence error at @xmath93 and @xmath299 .",
    "our first goal is to obtain an expression for @xmath300 $ ] . from   and",
    "the proof of proposition  [ prop : convergence ] , we have @xmath301 almost surely .",
    "then , from  , we have almost surely for all @xmath93 , @xmath302 where we have used the fact that @xmath303 .",
    "next , note that for all @xmath304 , @xmath305 where we have used the facts that @xmath16 is idempotent and @xmath306 for any @xmath307 .",
    "let @xmath308 .",
    "notice that @xmath309 has spectral radius @xmath310 and the same eigenvectors as @xmath56 .",
    "then , using   twice , we have almost surely for all @xmath304 , @xmath311 by the independence of @xmath312 over time , we have @xmath313 & = \\theta_0^t      { \\mathcal{a}}^{2k } \\theta_0      \\\\      \\notag & \\quad + \\sum_{j = 0}^{k - 2 } { \\mathbb{e}}[\\eta(j)^t b { \\mathcal{a}}^{2k - 2 -        2j } b \\eta(j ) ]      \\\\      \\notag & \\quad + { \\mathbb{e}}[\\eta(k - 1)^t b l_\\text{cpt}^2 b \\eta(k - 1 ) ]      \\\\      & \\quad + \\sum_{j = k}^\\infty { \\mathbb{e}}[\\eta(j)^t s \\pi_n^2 s \\eta(j ) ] ,    \\end{aligned}\\ ] ] for all @xmath304 .",
    "next , we upper bound the exponential mean - square convergence rate  @xmath78 .",
    "let @xmath314 and note that for any @xmath315 and any @xmath307 , @xmath316 & = \\sum_{i = 1}^n 2 b_i^2(j ) ( n^t      n)_{ii } \\\\      & \\le 2 \\overline c^2 \\overline q^{2j } { \\text{tr}}(n^t n ) = 2 \\overline c^2      \\overline q^{2j } \\|n\\|_f^2 ,    \\end{aligned}\\ ] ] where @xmath317 denotes the frobenius norm . therefore , @xmath318 \\le \\theta_0^t      { \\mathcal{a}}^{2k } \\theta_0 + 2 \\overline",
    "c^2 \\sum_{j = 0}^{k - 2 } \\overline      q^{2j } \\|{\\mathcal{a}}^{k - 1 - j } b\\|_f^2      \\\\      & + 2 \\overline c^2 \\overline q^{2(k - 1 ) } \\|l_\\text{cpt } b\\|_f^2 +      2 \\overline c^2 \\sum_{j = k}^\\infty \\overline q^{2j } \\|\\pi_n      s\\|_f^2 .",
    "\\end{aligned}\\ ] ] since the frobenius norm is submultiplicative , @xmath319 for any matrix @xmath320 , and @xmath321 , we have @xmath318 \\le \\theta_0^t      { \\mathcal{a}}^{2k } \\theta_0 + c_1 \\sum_{j = 0}^{k - 2 } \\overline q^{2j }      \\overline \\lambda^{2k - 4 - 2j } + c_2 \\overline q^{2k } ,    \\end{aligned}\\ ] ] where @xmath322 and @xmath323 are constants .",
    "note that for any @xmath324 , we have @xmath325 .",
    "therefore , using the fact that the supremum of a sum is less than or equal to the sum of suprema , we have @xmath326}{{\\mathbb{e}}\\big[\\hat \\theta_0^t \\hat \\theta_0\\big ] } \\le      \\sup_{\\theta_0 \\in { \\ensuremath{\\mathbb{r}}}^n } \\frac{\\theta_0^t { \\mathcal{a}}^{2k }        \\theta_0}{{\\mathbb{e}}\\big[\\hat \\theta_0^t \\hat \\theta_0\\big ] }      \\\\      & \\qquad \\qquad \\qquad + \\sup_{\\theta_0 \\in { \\ensuremath{\\mathbb{r}}}^n}\\frac{c_3 ( k -        1 ) \\max\\{\\overline q , \\overline \\lambda\\}^{2k } + c_2 \\overline        q^{2k}}{{\\mathbb{e}}\\big[\\hat \\theta_0^t \\hat \\theta_0\\big ] } ,    \\end{aligned}\\ ] ] where @xmath327 .",
    "let @xmath328 be the initial disagreement vector .",
    "it is straightforward to verify that @xmath329 and @xmath330 = \\tilde \\theta_0^t      \\tilde \\theta_0 + \\frac{1}{n } \\sum_{i = 1}^n \\frac{2 c_i^2        s_i^2}{1 - q_i^2 } \\triangleq \\tilde \\theta_0^t \\tilde \\theta_0 +      c_4 .",
    "\\end{aligned}\\ ] ] therefore , @xmath331}{{\\mathbb{e}}\\big[\\hat",
    "\\theta_0^t \\hat \\theta_0\\big ] } & \\le      \\sup_{\\tilde \\theta_0 \\in ( { \\ensuremath{\\mathbb{r}}}{\\mathbf{1}}_n)^\\perp } \\frac{\\tilde \\theta_0^t        { \\mathcal{a}}^{2k } \\tilde \\theta_0}{\\tilde \\theta_0^t \\tilde \\theta_0 +        c_4 }      \\\\      & + \\frac{c_3 ( k - 1 ) \\max\\{\\overline q , \\overline \\lambda\\}^{2k } +        c_2 \\overline q^{2k}}{\\inf_{\\tilde \\theta_0 \\in ( { \\ensuremath{\\mathbb{r}}}{\\mathbf{1}}_n)^\\perp }        ( \\tilde \\theta_0^t \\tilde \\theta_0 + c_4 ) }      \\\\      & \\hspace{-1in}= \\overline \\lambda^{2k } + c_3 c_4^{-1 } ( k - 1 )      \\max\\{\\overline q , \\overline \\lambda\\}^{2k } + c_2 c_4^{-1 }      \\overline q^{2k}.    \\end{aligned}\\ ] ] by raising the right hand side of the above expression to the power @xmath332 and taking the limit as @xmath333 , the constant / polynomial factors converge to 1 and the terms containing @xmath334 dominate the sum , proving that @xmath335 .",
    "similarly , we can lower bound @xmath78 as follows . from  , we have for all @xmath304 , @xmath336 \\ge \\theta_0^t      { \\mathcal{a}}^{2k } \\theta_0      \\\\      & \\rightarrow \\mu \\ge \\lim_{k \\to \\infty } \\left(\\sup_{\\tilde          \\theta_0 \\in ( { \\ensuremath{\\mathbb{r}}}{\\mathbf{1}}_n)^\\perp } \\frac{\\tilde \\theta_0^t { \\mathcal{a}}^{2k }          \\tilde \\theta_0}{\\tilde \\theta_0^t \\tilde \\theta_0 + c_4 }      \\right)^{1/2k } = \\overline \\lambda ,    \\end{aligned}\\ ] ] and @xmath336 \\ge { \\mathbb{e}}[\\eta(k)^t s      \\pi_n^2 s \\eta(k ) ] = \\sum_{i = 1}^n c_{5i } q_i^{2k }      \\\\      & \\rightarrow \\mu \\ge \\lim_{k \\to \\infty } \\left(\\sup_{\\tilde          \\theta_0 \\in ( { \\ensuremath{\\mathbb{r}}}{\\mathbf{1}}_n)^\\perp } \\frac{\\sum_{i = 1}^n c_{5i }          q_i^{2k}}{\\tilde \\theta_0^t \\tilde \\theta_0 + c_4 }      \\right)^{1/2k } = \\overline q ,    \\end{aligned}\\ ] ] where @xmath337 for all @xmath338 . therefore , @xmath339 , completing the proof .",
    "note that @xmath340 is the convergence rate of the noise - free ( and non - private ) laplacian - based average consensus algorithm , while @xmath341 is the worst - case decay rate of the noise sequence among the agents . from",
    ", the convergence rate @xmath78 is the larger of these two values , confirming our intuition that the slower rate among them is the bottleneck for convergence speed .",
    "also , note that @xmath340 depends on the network topology @xmath60 while @xmath341 is independent of it .",
    "having established the convergence properties of the algorithm  , this section characterizes the extent to which our design solves problem  [ problem : main ] by providing guarantees on its accuracy and differential privacy .",
    "the next result elaborates on the statistical properties of the agreement value of the algorithm .",
    "[ cor : accuracy ] under the hypotheses of proposition  [ prop : convergence ] , the convergence point @xmath163 is an unbiased estimate of @xmath154 with bounded dispersion , @xmath342 as a result , the algorithm  - is @xmath343-accurate for any @xmath344 .",
    "since noises are independent over time and among agents , we deduce from   that for any @xmath93 , @xmath345 and @xmath346 which establishes unbiasedness and bounded dispersion for any time . as @xmath333 , we get @xmath347 and @xmath348 the @xmath349-accuracy follows directly by applying chebyshev s inequality   for @xmath350 .    * ( comparison with the literature ",
    "contd ) * proposition  [ prop : convergence ] and corollary  [ cor : accuracy ] establish almost sure convergence , with the expected value of convergence being the average of the agents initial states .",
    "in contrast , the results in  @xcite establish convergence in mean square , and the expected value of convergence depends on the network topology . in both cases , the accuracy radius @xmath166 decreases with the number of agents as @xmath351 .",
    "the expression for @xmath349-accuracy in corollary  [ cor : accuracy ] shows that one can not obtain the ideal case of @xmath352-accuracy , and that @xmath166 is a decreasing function of @xmath72 , with @xmath353 as @xmath354 .",
    "this is an ( undesirable ) consequence of the lack of preservation of the average under   due to the term  @xmath355 . in turn",
    ", the presence of this expression helps establish the differential privacy of the algorithm with bounded , asymptotically vanishing noise , as we show next .",
    "[ prop : privacy ] under the hypotheses of proposition  [ prop : convergence ] , let @xmath356 for each @xmath117 , where @xmath146 is the adjacency bound in  . then , the algorithm preserves the @xmath357-differential privacy of agent @xmath49 s initial state for all @xmath117 .",
    "consequently , the algorithm is @xmath151-differential private with @xmath358 .",
    "consider any pair of @xmath146-adjacent initial conditions @xmath144 and @xmath145 and an arbitrary set @xmath359 .",
    "for any @xmath93 , let @xmath360 where @xmath361 is the sample space up to time @xmath134 , @xmath362 is given in  , and @xmath363 is the set composed by truncating the elements of @xmath364 to finite subsequences of length @xmath365 .",
    "then , by the continuity of probability  ( * ? ? ? * theorem 1.1.1.iv ) , @xmath366 for @xmath367 , where @xmath368 is the @xmath369-dimensional joint laplace pdf given by @xmath370 next , we define a bijection between @xmath192 and @xmath371 . without loss of generality ,",
    "assume @xmath372 for some @xmath170 , where @xmath373 and @xmath374 for all @xmath172 .",
    "then , for any @xmath375 , define @xmath376 by @xmath377 for @xmath378 .",
    "it is not difficult to see that @xmath379 , so @xmath380 .",
    "since the converse argument is also true , the above defines a bijection .",
    "therefore , for any @xmath380 there exists a unique @xmath381 such that @xmath382 note that @xmath383 is fixed and does not depend on @xmath376 .",
    "thus , we can use a change of variables to get @xmath384 comparing   for @xmath385 with  , we see that both integrals are over @xmath192 with different integrands . dividing the integrands for any @xmath375 yields , @xmath386 due to  ,",
    "the geometric series in the exponent of the multiplicative term is convergent .",
    "therefore , integrating both sides over @xmath192 and letting @xmath333 , we have @xmath387 which establishes the @xmath388-differential privacy for agent  @xmath389 .",
    "the fact the @xmath389 can be any agent establishes  , while the last statement follows from definition  [ def : privacy ] .    since the algorithm  - converges almost surely ( cf .",
    "proposition  [ prop : convergence ] ) and is differentially private ( cf .",
    "proposition  [ prop : privacy ] ) , proposition  [ prop : bound ] implies that it can not achieve @xmath164-accuracy , as noted above when discussing corollary  [ cor : accuracy ] .",
    "the explicit privacy - accuracy trade - off is given by the relation between @xmath390 and @xmath391 , i.e. , ( c.f .",
    ",  ) @xmath392 so @xmath393 increases as any @xmath357 is decreased and vice versa . we optimize this trade - off over @xmath394 in section  [ section : optimal - noise - selection ] and depict the optimal trade - off curve for a test network in section  [ section : simulations ] .    even though the choice of laplacian noise in   is not the only one that can be made to achieve differential privacy , it is predominant in the literature  @xcite .",
    "the work  @xcite shows that laplacian noise is optimal ( among all possible distributions ) in the sense that it minimizes the entropy of the transmitted messages while preserving differential privacy .    * ( comparison with the literature  contd ) * proposition  [ prop : privacy ] guarantees the @xmath357-differential privacy of agent @xmath49 s initial state independently of the noise levels chosen by other agents .",
    "therefore , each agent can choose its own level of privacy , and even opt not to add any noise to its messages , without affecting the privacy of other agents .",
    "in contrast , in  @xcite , agents need to agree on the level of privacy before executing the algorithm . in both cases ,",
    "privacy is achieved against an adversary that can hear everything , independently of how it processes the information .",
    "in contrast , the algorithm in  @xcite assumes the adversary uses maximum likelihood estimation and only preserves the privacy of those agents who are sufficiently `` far '' from it in the graph ( an agent is sufficiently far if the adversary can not listen to it and all of its neighbors ) . the latter work uses a different notion of privacy based on the covariance of the maximum likelihood estimate which allows for guaranteed exact convergence , in the mean - square sense , to the true average .      in this section , we discuss the effect on the algorithm s performance of the free parameters present in our design . given the trade - off between accuracy and privacy , cf .  , we fix the privacy levels @xmath395 constant and study the best achievable accuracy of the algorithm as a function of the remaining free parameters .",
    "each agent @xmath396 gets to select the parameters @xmath229 , @xmath397 , @xmath398 determining the amount of noise introduced in the dynamics , with the constraint that @xmath399 , where @xmath400 given the characterization of accuracy in corollary  [ cor : accuracy ] , we consider as cost function the variance of the agents convergence point , i.e. , @xmath163 , around @xmath154 , giving @xmath401 the next result characterizes its global minimization .    *",
    "( optimal parameters for variance minimization)*[prop : optimal ] for the adjacency bound @xmath402 and privacy levels @xmath403 fixed , the optimal value of the variance of the agents convergence point  is @xmath404 the infimum is not attained over @xmath405 but approached as @xmath406 and @xmath407 for all @xmath117 .    for each @xmath117 , with the privacy level fixed , the expression   follows directly from  . for convenience ,",
    "we re - parameterize the noise decaying ratio  @xmath398 as @xmath408 note that @xmath409 . substituting   and   into  , we obtain ( with a slight abuse of notation , we also use @xmath410 to denote the resulting function ) , @xmath411}.    \\end{aligned}\\ ] ] therefore , to minimize @xmath410 , each agent has to independently minimize the same function @xmath412 of its local parameters @xmath413 over @xmath414 .",
    "figure  [ fig : phi ] illustrates the graph of this function over  @xmath64 .",
    "since @xmath64 is not compact , the infimum might not be attained , and in fact , this is the case .",
    "it is easy verify that @xmath415 .",
    "now , for all @xmath416 , @xmath417 so @xmath418 if @xmath419 , then @xmath420 . if @xmath421 , then @xmath422",
    "therefore , for all @xmath416 , @xmath423 , which completes the proof .    given that differential privacy is resilient to post - processing , an alternative design strategy to preserve the differential privacy of agents initial states is to inject noise only at the initial time , @xmath424 . from",
    ", the introduction of a one - shot noise by agent  @xmath49 corresponds to @xmath425 which is not feasible if @xmath426 .",
    "this can also be seen by rewriting   as @xmath427 so if @xmath426 for any @xmath49 , @xmath173 directly ( not only through @xmath428 ) depend on @xmath429 . however ,",
    "if @xmath235 , one can verify using a simplified version of the proof of proposition  [ prop : privacy ] that @xmath425 also preserves @xmath357-differential privacy of @xmath429 with @xmath430 .",
    "this results in a cost of @xmath431 showing that the optimal accuracy is also achieved by one - shot perturbation of the initial state at time @xmath236 and injection of no noise thereafter .",
    "a similar conclusion ( that one - shot laplace perturbation minimizes the output entropy ) can be drawn from  @xcite , albeit this is not explicitly mentioned therein .    *",
    "( dynamic average consensus ) * one - shot perturbation would no longer be optimal in dynamic average consensus scenarios  @xcite , where agents seek to compute the average of individual exogenous , time - varying signals ( the `` static '' average consensus considered here would correspond to the exogenous signals being constant ) . in such scenarios , there is a recurrent flow of information at each node whose privacy can no longer be preserved with one - shot perturbation .",
    "sequential perturbation as in  - is then necessary and the variance of the noise sequence has to dynamically depend on the rate of information flow to each node .",
    "although the detailed design of such algorithms is beyond the scope of this work , such an algorithm can be designed following the idea of the sequential perturbation design of this work and the proof of its privacy in proposition  [ prop : privacy ] . to see this , note that ( for @xmath432 ) we `` tune '' the amount of noise injection @xmath133 so that the privacy of @xmath433 is preserved at each round @xmath237 , but @xmath434 is the amount of `` retained information '' of @xmath435 at round @xmath134 and plays the same role as @xmath436 in the dynamic average consensus problem .",
    "in this section , we report simulation results of the distributed dynamics  - on a network of @xmath437 agents .",
    "figure  [ fig : graph ] shows the random graph used throughout the section , where edge weights are i.i.d .",
    "and each one equals a sum of two i.i.d .",
    "bernoulli random variables with @xmath438 .",
    "the agents initial states are also i.i.d . with distribution @xmath439 .",
    "as can be seen from   and  , neither accuracy nor privacy depend on the initial values or the communication topology ( albeit according to   the convergence rate depends on the latter ) . in all the simulations , @xmath440 and @xmath441 for all @xmath117",
    ".    figure  [ fig : sweep ] depicts simulations with @xmath442 and @xmath443 while sweeping  @xmath444 over @xmath445 $ ] with logarithmic step size . for each value of  @xmath444",
    ", we set @xmath446 with @xmath447 for each @xmath117 and repeat the simulation @xmath448 times .",
    "for each run , to capture the statistical properties of the convergence point , the graph topology and initial conditions are the same and only noise realizations change .",
    "figure  [ fig : sweep](a ) shows the empirical ( sample ) standard deviation of the convergence point as a function of  @xmath444 , verifying the optimality of one - shot perturbation . in particular ,",
    "notice the sensitivity of the accuracy to  @xmath444 close to @xmath449 .",
    "figure  [ fig : sweep](b ) shows the ` settling time ' , defined as the number of rounds until convergence ( measured by a tolerance of @xmath450 ) , as a function of  @xmath444 .",
    "the fastest convergence is achieved for @xmath449 , showing that one - shot noise is also optimal in the sense of convergence speed .",
    "we have observed the same trends as in figure  [ fig : sweep ] for different random choices of initial conditions and network topologies .",
    "note that the settling time depends on both the convergence rate and the initial distance from the convergence point @xmath451 .",
    "the former is constant at @xmath452 for @xmath453 $ ] .",
    "the latter depends on @xmath454 , which in turn depend on @xmath444 by  .",
    "this explains the trend observed in figure  [ fig : sweep](b ) .",
    "figure  [ fig : tradeoff ] depicts the privacy - accuracy trade - off for the proposed algorithm .",
    "we have set @xmath455 , @xmath456 , and @xmath457 and then swept @xmath458 logarithmically over @xmath459 $ ] . in figure",
    "[ fig : tradeoff](a ) , the algorithm is run 25 times for each value of the @xmath458 and the error @xmath460 for each run is plotted as a circle . in figure",
    "[ fig : tradeoff](b ) , the sample variance of the convergence point @xmath163 is shown as a function of @xmath458 together with the theoretical value given in proposition  [ prop : optimal ] .",
    "in both plots , we see an inversely - proportional relationship between accuracy and privacy , as expected .",
    "figure  [ fig : hist ] shows the histogram of convergence points for @xmath461 runs of the algorithm with @xmath462 , @xmath455 and @xmath456 ( optimal accuracy ) .",
    "the distribution of the convergence point is a bell - shaped curve with mean exactly at the true average , in accordance with corollary  [ cor : accuracy ] .",
    "although the distribution of @xmath163 is provably non - gaussian , the central limit theorem , see e.g. ,  @xcite , implies that it is very close to gaussian since the number of agents is large .    finally , figure  [ fig : mu ] illustrates the convergence rate of the algorithm . here , for @xmath463 , @xmath464 , @xmath465 , and the same topology as in the previous plots ,",
    "the initial agents states are randomly selected and the whole algorithm is run 100 times with different noise realizations @xmath138 , each time until @xmath466 iterations . for each value of initial states and",
    "each @xmath467 , we empirically approximate the quantity @xmath468}{{\\mathbb{e}}\\big[(\\theta(0 ) -        \\theta_\\infty { \\mathbf{1}}_n)^t ( \\theta(0 ) - \\theta_\\infty        { \\mathbf{1}}_n)\\big ] } \\right)^{1/2k}\\end{aligned}\\ ] ] by taking the sample mean instead of the expectation in the numerator and denominator .",
    "we repeat this whole process 50 times for different random initial conditions and plot the result , together with the theoretical value of @xmath78 ( which in this case equals @xmath469 ) given by proposition  [ prop : conv - rate ] .",
    "as figure  [ fig : mu ] shows , the supremum of the resulting curves converges to @xmath78 as @xmath333 , as expected .",
    "we have studied the problem of multi - agent average consensus subject to the differential privacy of agents initial states .",
    "we have showed that the requirement of differential privacy can not be satisfied if agents states weakly converge to the exact average of their initial states .",
    "this result suggests that the most one can expect of a differentially private consensus algorithm is that the consensus value is unbiased , i.e. , its expected value is the true average , and the variance is minimized .",
    "we have designed a linear consensus algorithm that meets this objective , and have carefully characterized its convergence , accuracy , and differential privacy properties .",
    "future work will include the investigation of the limitations and advantages of differential privacy in multi - agent systems , the extension of the results to distributed optimization , filtering , and estimation , and the design of algorithms for privacy preservation of the network structure and other parameters such as edge weights and vertex degrees .",
    "this work was supported by nsf award cns-1329619 .",
    "f.  bullo , j.  corts , and s.  martnez .",
    "_ distributed control of robotic networks_. applied mathematics series . princeton university press , 2009 .",
    "isbn 978 - 0 - 691 - 14195 - 4 .",
    "electronically available at http://coordinationbook.info .            c.  dwork , f.  mcsherry , k.  nissim , and a.  smith . calibrating noise to sensitivity in private data analysis . in _ proceedings of the 3rd theory of cryptography conference _ , pages 265284 , new york , ny , march 2006 .",
    "s.  han , u.  topcu , and g.  j. pappas .",
    "differentially private convex optimization with piecewise affine objectives . in _",
    "ieee conf .  on decision and control _ , pages 21602166 , los angeles , ca , december 2014 .",
    "z.  huang , s.  mitra , and g.  dullerud .",
    "differentially private iterative synchronous consensus . in _ proceedings of the 2012 acm workshop on privacy in the electronic society _ , pages 8190 , new york , ny , 2012 .",
    "z.  huang , y.  wang , s.  mitra , and g.  e. dullerud .",
    "on the cost of differential privacy in distributed control systems . in _ proceedings of the 3rd international conference on high confidence networked systems ( hicons ) _ , pages 105114 , berlin , germany , april 2014 .",
    "z.  huang , s.  mitra , and n.  vaidya . differentially private distributed optimization . in _ proceedings of the 2015 international conference on distributed computing and networking _ , pilani , india ,",
    "january 2015 .",
    "m.  kefayati , m.  s. talebi , b.  h. khalaj , and h.  r. rabiee .",
    "secure consensus averaging in sensor networks using random offsets . in _",
    "ieee intern .",
    "conf . on telec . , and malaysia intern",
    ". conf . on communications _",
    ", pages 556560 , penang , may 2007 .",
    "s.  s. kia , j.  corts , and s.  martnez .",
    "dynamic average consensus under limited control authority and privacy requirements .",
    "_ international journal on robust and nonlinear control _ , 250 ( 13):0 19411966 , 2015 .            a.  mukherjee , s.a.a .",
    "fakoorian , j.  huang , and a.l .",
    "principles of physical layer security in multiuser wireless networks : a survey . _ ieee communications surveys & tutorials _ , 160 ( 3):0 15501573 , 2014 .",
    "y.  wang , z.  huang , s.  mitra , and g.  e. dullerud .",
    "entropy - minimizing mechanism for differential privacy of discrete - time linear feedback systems . in _",
    "ieee conf .  on decision and control _ ,",
    "pages 21302135 , los angeles , ca , december 2014 ."
  ],
  "abstract_text": [
    "<S> this paper studies the multi - agent average consensus problem under the requirement of differential privacy of the agents initial states against an adversary that has access to all the messages . </S>",
    "<S> we first establish that a differentially private consensus algorithm can not guarantee convergence of the agents states to the exact average in distribution , which in turn implies the same impossibility for other stronger notions of convergence . </S>",
    "<S> this result motivates our design of a novel differentially private laplacian consensus algorithm in which agents linearly perturb their state - transition and message - generating functions with exponentially decaying laplace noise . </S>",
    "<S> we prove that our algorithm converges almost surely to an unbiased estimate of the average of agents initial states , compute the exponential mean - square rate of convergence , and formally characterize its differential privacy properties . </S>",
    "<S> we show that the optimal choice of our design parameters ( with respect to the variance of the convergence point around the exact average ) corresponds to a one - shot perturbation of initial states and compare our design with various counterparts from the literature . </S>",
    "<S> simulations illustrate our results .        </S>",
    "<S> average consensus , differential privacy , multi - agent systems , exponential mean - square convergence rate , networked control systems </S>"
  ]
}