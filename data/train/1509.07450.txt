{
  "article_text": [
    "brain - machine interfaces ( bmi ) are becoming increasingly popular over the last decade and open up the possibility of neural prosthetic devices for patients with paralysis or in locked - in state .",
    "as depicted in fig .",
    "[ fig : bmi ] , a typical implanted bmi consists of a neural recording ic to amplify , digitize and transmit neural action potentials ( ap ) recorded by the micro - electrode array ( mea ) .",
    "significant effort has been dedicated to develop energy efficient neural recording channel in recent years for long - term operation of the implanted devices@xcite@xcite@xcite@xcite .",
    "some recent solutions have also integrated ap detection@xcite@xcite@xcite@xcite and spike sorting features@xcite@xcite@xcite . however , in order to produce an actuation command ( e.g. for a prosthetic arm ) , the subsequent step of motor intention decoding is required to map spike train patterns acquired in the neural recording to the motor intention of the subjects .",
    "though various elaborate models and methods of motor intention decoding have been developed in past decades with the goal of achieving high decoding performance @xcite@xcite@xcite , the state - of - the art neural signal decoding are mainly conducted on pc consuming a considerable amount of power and making it impractical for the long - term use . with on - chip real - time motor intention decoding , the size and the power consumption of the computing device can be reduced effectively and the solution becomes truly portable .",
    "furthermore , integrating the neural decoding algorithm with the neural recording device is also desired to reduce the wireless data transmission rate and make the implanted bmi solution scalable as required in the future@xcite .",
    "until now , very few attempts have been made to give a solution for this problem .",
    "a low - power motor intention architecture using analog computing is proposed in @xcite , featuring an active filtering with massive parallel computing through low power analog filters and memories .",
    "however , no measurement results are published to support the silicon viability of the architecture .",
    "a more recent work proposes a universal computing architecture for the neural signal decoding @xcite .",
    "the architecture is implemented on a fpga with a power consumption of @xmath6 @xmath0w .    in this paper , we present a machine learning co - processor ( mlcp ) achieving low - power operation through massive parallelism , sub - threshold analog processing and careful choice of algorithm .",
    "figure [ fig : bmi ] contrasts our approach with traditional approaches : our mlcp acts in conjunction with the digital signal processor ( dsp ) already present in implants ( for spike sorting , detection and packetizing ) to provide the decoded outputs .",
    "the bulk of processing is done on the mlcp while simple digital functions are performed on the dsp .",
    "compared to traditional designs that perform the decoding outside the implant , our envisioned system that provides opportunity for huge data compression by integrating the decoder in the implant .",
    "the mlcp is characterized by measurement and the decoding performance of the proposed design is verified with data acquired in individuate finger movements experiment of monkeys .",
    "some initial results of this work were presented in @xcite . here ,",
    "we present more detailed theory , experimental results including decoding time of movement , new sparsity promoting training and also discuss scalability of this architecture .",
    "the machine learning algorithm used in this design is extreme learning machine ( elm ) proposed in @xcite . as depicted in fig .",
    "[ fig : elm ] ( a ) , the elm is essentially a single hidden - layer feed - forward network ( slfn ) .",
    "the k - th output of the network ( 1@xmath7 k @xmath7 c ) can be expressed as follows , @xmath8 where @xmath9 denotes the input feature vector , @xmath10 is the number of hidden neurons , @xmath11 is the output of the hidden layer , @xmath12 is the bias for each hidden layer node , @xmath13 and @xmath14 are input and output weights respectively . a non - linear activation function @xmath15 is needed for non - linear classification .",
    "a special case of the nonlinear function is the additive node defined by @xmath16 .",
    "the above equation can be compactly written for all classes as @xmath17 $ ] where @xmath18 $ ] denotes the @xmath19 matrix of output weights .",
    "while the output @xmath20 can be directly used in regression , for classification tasks the input is categorized as the k - th class if @xmath21 is the largest output .",
    "formally , we can define the classification output as an integer class label @xmath22 given by @xmath23 .",
    "intuitively , we can think of the first layer as creating a set of random basis functions while the second layer chooses how to combine these functions to match a desired target .",
    "of course , if we could choose the basis functions through training as well , we would need less number of such functions .",
    "but the penalty to be paid is longer training times .",
    "more details about the algorithm can be found in @xcite .",
    "( a )        ( b )      the special property of the elm is that @xmath24 can be random numbers from any continuous probability distribution and remains unchanged after initiation@xcite , while only @xmath25 needs to be trained and stored with high resolution .",
    "therefore the training of this slfn reduces to finding a least - square solution of @xmath25 given the desired target values in a training set .",
    "we will next show two methods of training  the conventional one ( t1 ) for improved generalization as well as a second method ( t2 ) that promotes sparsity . for simplicity",
    ", we show the solution of weights for one output @xmath20the same method can be extended to other output weights as well and can be represented in a compact matrix equation@xcite .",
    "suppose there are @xmath26 training samples  then we can create a @xmath27 hidden layer output matrix @xmath28 where each row of @xmath28 has the hidden layer neuron output for each training sample .",
    "let @xmath29 be the vector of target values for the @xmath26 samples . with these inputs ,",
    "the two training methods are shown in fig .",
    "[ fig : training ] .",
    "the step for @xmath30 norm minimization can be solved directly with the solution given by @xmath31 where @xmath32 is the moore - penrose generalized inverse of the matrix @xmath28 .",
    "hence , training can happen quickly in this case .",
    "the @xmath33 norm minimization step in t2 however has to be performed using standard optimization algorithms like lars@xcite .",
    "thus t2 provides reduced hardware complexity due to reduction in the number of hidden neurons at the cost of increased training time .",
    "the neural decoding algorithm we use is inspired by the method in @xcite .",
    "we replace the committee of ann in their work with elm in our case .",
    "three specific advantages of the elm for this application are ( 1 ) the fixed random input weights can be realized by a current mirror array exploiting fabrication mismatch of the cmos process ; ( 2 ) one - step training that is necessary for quick weight update to address change in input statistics and ( 3 ) the hidden layer outputs @xmath11 can be reused for multiple operations on the same input data @xmath9 . in this case , we have reused @xmath11 to classify both the onset time and type of movement .",
    "one disadvantage of the elm algorithm is the usage of @xmath34 hidden neurons compared to fully tuned architectures ( e.g. svm , adaboost ) since the hidden nodes in elm only create random projections that are not fine tuned@xcite .",
    "however , implementing random weights results in more than @xmath35 savings over fully tunable weights making this architecture more lucrative overall .",
    "next , we give an overview of the decoding algorithm while the reader is pointed to @xcite for more details .",
    "figure [ fig : elm ] ( b ) depicts how the elm is used in neural decoding .",
    "even though the input is an asynchronous spike train , the elm produces classification outputs at a fixed rate of once every @xmath36 seconds .",
    "the input @xmath9 is created from the firing rate of spike trains @xmath37 of biological neurons by finding the moving average over a duration @xmath38 .",
    "hence , we can define the firing rate @xmath39 of i - th neuron at time instant @xmath40 as @xmath41 where @xmath42 ms and @xmath43 ms following @xcite . finally , @xmath9@xmath44 $ ] where there are @xmath45 biological neurons in the recording ( @xmath46 ) . as shown in fig .",
    "[ fig : elm ] ( b ) , we have @xmath47 output neurons in this case where there are @xmath48 movement types to be decoded .",
    "the @xmath48 + 1-th neuron is used to decode the onset time of movement . for decoding type of movement",
    ", we can directly use the method described in the earlier section [ sec : elm ] for @xmath48-class classifier to get the predicted output class at time @xmath40 as @xmath49 .    for decoding movement onset time",
    ", we further create a binary classifier that reuses the same hidden layer but adds an extra output neuron .",
    "similar to @xcite , this output is trained for regression  the target is a trapezoidal fuzzy membership function which gradually rises from @xmath50 to @xmath51 representing the gradual evolution of biological neural activity .",
    "this output @xmath52 is thresholded to produce the final output @xmath53 at time @xmath40 as : @xmath54 where @xmath55 is a threshold optimized as a hyperparameter .",
    "moreover , to reduce spurious classification and produce a continuous output , the primary output @xmath53 is processed to create @xmath56 that is high only if @xmath57 is high for at least @xmath58 times over the last @xmath59 time points .",
    "further , to reduce false positives , another detection is prohibited for @xmath60 ms after a valid one .",
    "the final decoded output , @xmath61 is obtained by a simple combination of the two classifiers as @xmath62 .     for the current mirror ; ( c ) neuron - based cco to implement hidden node non - linearity and convert to digital.,scaledwidth=45.0% ]    ( a )     for the current mirror ; ( c ) neuron - based cco to implement hidden node non - linearity and convert to digital.,scaledwidth=45.0% ]    ( b )     for the current mirror ; ( c ) neuron - based cco to implement hidden node non - linearity and convert to digital.,scaledwidth=42.0% ]    ( c )      a common problem in long - term neural recording is the loss of information from electrodes over time due to tissue reactions such as gliosis , meningitis or mechanical failures @xcite .",
    "hence , initially functional electrodes may not provide information later on . to retain the quality of decoding ,",
    "we propose a method commonly used in time series analysis  the use of information from earlier time points@xcite .",
    "in the context of neural decoding , it means that we use more information from the dynamics of neural activity in functional electrodes in place of lost information from the instantaneous values of activity in previously functional electrodes .",
    "so if we use @xmath63 previous values from the @xmath64 functional electrodes , the new feature vector is given by : @xmath65 \\end{split}\\ ] ] where the input dimension of the elm is given by @xmath66 .",
    "this is a novel algorithmic feature in our work compared to @xcite .",
    "fig.[fig : bmi ] shows a typical usage scenario for our mlcp where it works in tandem with the dsp and performs the intention decoding .",
    "the dsp only needs to send very simple control signals to the mlcp and performs the calculation of the second stage of elm ( multiplication by learned weights @xmath25 ) .",
    "the input to the mlcp comes from spike sorting that can be performed on the dsp@xcite . in some cases ,",
    "spike sorting may not be needed and spike detection may be the only required pre - processing @xcite .      details and timing of the mlcp",
    "are shown in fig .",
    "[ fig : diagram ] .",
    "we map input and hidden layers of elm into the mlcp fabricated in ams 0.35-@xmath0 m cmos process , where high computation efficiency is achieved by exploiting fabrication mismatch abundantly found in analog devices , while the output layer that requires precision and tunability ( tough to attain in analog designs ) can be implemented on the dsp .",
    "since the number of computations in first stage far outnumbers those in the second ( as long as @xmath67 ) , such a system partition still retains the power efficiency of the analog design . up to @xmath68 input channels and @xmath68",
    "hidden layer nodes are supported by the mlcp , with each input channel embedding an input processing circuit that extracts input feature from the incoming spike trains .",
    "as mentioned in the earlier section , we extract a moving average of the spike count as the input feature of interest .    on receiving a spike from the neural amplifier array ( after spike detection and/or spike sorting ) , the dsp sends a pulse via @xmath69 and @xmath70-bit channel address ( a@xmath71 ) to the demux in the mlcp for row - decoding . each row of the mlcp",
    "has a @xmath72-bit window counter ( @xmath73 ) to count the total number of input spikes in a moving window with length of @xmath74 and a moving step of @xmath75 .",
    "the length of @xmath75 , normally set to @xmath76 ms , is determined by the period of @xmath77 .",
    "the counter value in j - th row is converted into input feature current @xmath78 for the elm , corresponding to the input @xmath79 in fig .",
    "[ fig : elm ] .",
    "furthermore , a @xmath51-bit control signal ( @xmath80 ) stored in each row determines whether the j - th row s input to the moving window circuit is an external spike count or a delayed spike count from the previous channel .",
    "the delay length can be selected from among @xmath81 delay steps ranging from @xmath76 ms to @xmath82 ms , based on @xmath83 .",
    "this is how the tdbdi feature described earlier is implemented in the mlcp .",
    "the input feature current from each row is further mirrored into all hidden - layer nodes by a current mirror array .",
    "hence , ratios of the current mirrors are essentially the input weights , and are inherently random due to fabrication mismatch of the transistors even when identical value is used in the design",
    ". we use sub - threshold current mirror to achieve very low power consumption , resulting in @xmath84 with @xmath85 denoting thermal voltage and @xmath86 denoting the threshold voltage mismatch between input transistor on j - th row and mirror transistor on i - th column of that row .",
    "this is similar to the concepts described in @xcite@xcite .",
    "the input weights are log - normal distributed since @xmath86 follows a normal distribution .",
    "we therefore realize random input weights in a very low ` cost ' way that requires only one transistor per weight .",
    "it is the fixed random input weights of the elm that makes this unique design possible .",
    "a capacitance @xmath87 = @xmath88 ff on each row sets the snr of the mirroring to @xmath89 db .",
    "the hidden layer node is implemented by a current controlled oscillator ( cco ) driving a @xmath90-bit counter with a @xmath91-bit programmable stop value @xmath92 to implement a saturating nonlinearity in the activation function @xmath15 .",
    "the advantage of choosing this nonlinearity is that it can be digitally set and also some neurons can be configured to be linear as well to achieve good performance in linearly separable problems @xcite .",
    "the computation of hidden layer nodes is activated by setting @xmath93 high .",
    "the output of cco is a pulse frequency modulated signal with the frequency proportional to total input current .",
    "the counter outputs are latched and serially read using the @xmath94 signal when @xmath93 is low with cco disabled to save power .",
    "the output weights , @xmath25 , are stored on the dsp where the final output @xmath20 is calculated .",
    "thus the mlcp performs the bulk of macs ( d@xmath95l ) while the dsp only performs c@xmath95l macs of the output layer .",
    "it should be noted here , the output of hidden layer neurons changes with power supply voltage due to sensitivity of the cco frequency to power supply variation , leading to degradation of the decoding accuracy .",
    "however , since power supply variation is a common - mode component to all ccos , normalization methods can be applied in post - processing ( see section [ sec : normalization ] ) to the hidden layer outputs to reduce the effect introduced by power supply variation .    -@xmath0",
    "m cmos process and the portable external unit ( peu ) integrating mlcp with mcu and battery.,scaledwidth=50.0% ]      fig .",
    "[ fig : circuits ] shows diagrams of the circuit blocks in the mlcp .",
    "[ fig : circuits ] ( a ) shows two adjacent input processing circuits with @xmath96 configured to receive an external spike train by setting @xmath80 = 0 and @xmath97 configured as time delay based channel by setting @xmath98 = 1 .",
    "the corresponding signal flows are also depicted in the figure by red dash lines",
    ". the moving window counter is realized by ( 1 ) counting spike in a sub - window in a length of @xmath75 ; ( 2 ) storing sub - window counter value in a delay chain made of shift registers ; and ( 3 ) adding and subtracting previous @xmath72-b output value with corresponding sub - window counter values in the delay chain to get new @xmath72-b output value of @xmath73 .",
    "this calculation can be represented as : @xmath99 where @xmath100 and @xmath101 are @xmath72-b output value and @xmath102-b sub - window counter value at time instance @xmath64 respectively .",
    "all registers in the input processing circuits toggle at the rising edge of @xmath77 .",
    "the advantage of this structure is that the delay chain for sub - window counter value is reused in the proposed tdbdi feature , leading to a compact design .",
    "a compact , @xmath72-bit mos ladder based current mode dac , as shown in fig .",
    "[ fig : circuits ] ( b ) , splits a reference current @xmath103 ( @xmath72-bit programmable in range of @xmath51 na to @xmath104 na ) according to the @xmath73 output value to generate the input feature current @xmath105 to the current mirrors .",
    "randomly selected input dac channels show @xmath106 lsb performance.,scaledwidth=45.0% ]    .",
    "these values are measured by reading the output counter values when a fixed input value is given one row at a time.,scaledwidth=45.0% ]      the diagram of the current controlled oscillator ( cco ) is depicted in fig .",
    "[ fig : circuits ] ( c ) .",
    "the capacitance of @xmath107 ff sets oscillation frequency of this relaxation oscillator based on the summed input current while @xmath108 ff provides hysteresis through positive feedback .",
    "when @xmath93 is pulled high , pfet @xmath109 is turned off .",
    "@xmath110 is used to set the leakage term @xmath111 in equation [ eq : elm_out ] and can be set to @xmath50 for most cases .",
    "@xmath112 from the current mirrors starts to discharge @xmath113 until it crosses the threshold voltage of the @xmath114 , leading to transition of all inverters .",
    "then , @xmath113 is pulled down very quickly through a positive feedback loop formed by @xmath115 . at the same time , @xmath116 turns on , charging @xmath113 towards @xmath117 until it crosses the threshold voltage of @xmath114 from low to high and the cycle repeats . neglecting higher order effects ,",
    "the time for each cycle of the cco operation is determined by the sum of the charging and discharging time constant of @xmath113 , and can be expressed by : @xmath118 where @xmath119 is the charging current when @xmath116 is on .",
    "normally @xmath120 reducing equation [ eq : cco ] to : @xmath121",
    "this section presents the measurement results from the mlcp fabricated in 0.35-@xmath0 m cmos process . to test the circuit , we have integrated it with a microcontroller unit or mcu ( ti msp430f5529 ) to act as the dsp .",
    "though we have not integrated it with an implant yet , this setup does allow us to realistically assess performance of the mlcp with pre - recorded neural data as shown later .",
    "moreover , the designed board is entirely portable with its own power supply and wireless tx - rx module ( ti cc2500 ) .",
    "hence , it can be used as a portable external unit ( peu ) for neural implant systems as well . as shown in fig .",
    "[ fig : photo ] , the mlcp has a die area of @xmath122 @xmath123 and the peu measures @xmath124 cm @xmath95 @xmath125 cm .",
    ".mean and standard deviation of @xmath86 [ cols=\"^,^,^\",options=\"header \" , ]     can be further extended by reusing input channels at the expense of classification rate    assuming 1000 support vectors    1024 6-bit multiply at 10 mhz consumes 14 mw .",
    "the operations are much simpler than a mac .",
    "5.2 pj / mac includes both analog and digital power for @xmath126 , @xmath127 and @xmath128 . in reality ,",
    "analog power is amortized across all multiplies and the peak efficiency of @xmath129 pj / mac is attainable for @xmath130 for the same value of @xmath131 .",
    "see section [ sec : power ] for details .    each multiply is 7 bit accurate due to snr limitation while the output quantization in the cco - adc has 14 bits for dynamic range .",
    "finally , we report the power consumption of the proposed mlcp for the @xmath132 input channels , @xmath133 hidden layer nodes , @xmath134-class classification problem .",
    "the current drawn from analog and digital power supply pins were measured using a keithley picoammeter . the power breakup is shown in fig .",
    "[ fig : break_power ] . at the lowest value of @xmath135 = @xmath136 v and @xmath117 = @xmath137 v needed for robust operation ,",
    "the total power dissipated is @xmath138 nw with @xmath139 nw from @xmath117 and @xmath140 nw from @xmath135 . performing @xmath141 mac in the current mirror array at @xmath2 hz rate of classification ,",
    "the mlcp provides a @xmath1 pj / mac and @xmath142 nj / classify performance .",
    "it is clear that the efficiency is limited by the fixed analog power that is amortized across the @xmath10 hidden layer neurons and @xmath143 current mirror multipliers .",
    "the fundamental limit of this architecture is the power dissipation of the cco and current mirror array which is limited to @xmath144 pj / mac .",
    "in contrast , recently reported @xmath145-bit digital multipliers consume 16 - 70 pj / mac @xcite@xcite@xcite@xcite where we ignore the power consumed by the adder for simplicity .",
    "we have also implemented near threshold digital array multipliers in @xmath146 nm cmos operating at @xmath147 v that resulted in energy efficiency of @xmath148 pj / mac confirming the much lower energy attainable by analog solutions over digital ones . moreover , implementing the mlcp computations in digital domain would incur further energy cost due to memory access ( for getting the weight values ) and clocking which are ignored here .",
    "since we implement the operation of second stage in digital domain , we need @xmath149 multiplications per classification . for the case of @xmath127 and @xmath128 described above and energy cost of @xmath148 pj / mac for digital multiplies , the total energy cost of second stage operation is @xmath150 nj / classify .",
    "hence , the total energy / classification becomes @xmath151 nj and the combined energy / operation increases to @xmath152 pj / mac . for peak energy efficiency",
    ", we consider @xmath153 , @xmath154 and @xmath128 resulting in a net energy / computation of @xmath129 pj / mac including both stages .        our mlcp is compared with other recently reported machine learning systems in table [ tab : compare ] .",
    "compared to the digital implementation of svm in @xcite , our implementation achieves far less energy per mac due to the analog implementation . @xcite,@xcite and",
    "@xcite achieve good energy efficiency similar to our method by using analog computing .",
    "@xcite uses a multiplying dac ( mdac ) to perform the multiplication by weights",
    " however , they have only @xmath72 bit resolution in the multiply and also the mdac occupies much larger area than the single transistor we use for multiplications . @xcite and @xcite use analog floating - gate transistors for the multiplication .",
    "compared to these , our single transistor multiplier takes lesser area ( no capacitors that are needed in floating - gates ) , does not require high voltages for programming charge and allows digital correction of errors because of the digital output .",
    "@xmath155 ) are very small.,scaledwidth=37.0% ]      using a single transistor for multiplication in the first layer should provide area benefits over other schemes . the current layout ( fig .",
    "[ fig : layout ] ) was done due to its simple connection patterns and is not optimized .",
    "it can be seen that the actual area of a unit transistor in the array ( @xmath156 @xmath155 ) is much less than the area of an unit cell in the layout which is limited by the pitch of the cco and the window counter circuits . moving to a highly scaled process or folding the placement of the output cco layer to be parallel to the input window counter circuits",
    "would enable large reduction ( @xmath157 ) in the area of the current mirror array .",
    "the ultimate limit in terms of area for this architecture stems from the area of capacitors  for this @xmath68 input ,",
    "@xmath68 output architecture , the total capacitor area is @xmath158 mm@xmath159 .",
    "when used in an implant with offline training , the mlcp can reduce transmission data rate drastically .",
    "firstly , for direct transmission of @xmath82 channel data sampled at @xmath76 khz with @xmath160 bit resolution , required data rate is @xmath76 mbps .",
    "this massive data rate can be reduced partially by including spike sorting @xcite . in this case , assuming @xmath161 bit address encoding a maximum of @xmath162 biological neurons each firing at a rate @xmath163 , the data rate to be transmitted for a conventional implant without neural decoder is given by @xmath164 . as an example , with @xmath165 hz , @xmath166 kbps .",
    "this can be reduced even further by integrating the decoder as proposed here . for the proposed case , the output of the decoder",
    "is obtained at a rate @xmath167 . during regular operation after training ,",
    "the data rate for @xmath131 classes is given by @xmath168 .",
    "as an example , for the case described in section [ sec : decoding_meas ] with @xmath169 hz and @xmath170 , @xmath171 bps .",
    "this example , shows the potential for thousand fold data rate reductions over spike sorting by integrating the decoder in the implant .    from the viewpoint of power dissipation",
    ", the analog front end and spike detection can be accomplished within a power budget of @xmath51 @xmath0w per channel@xcite@xcite@xcite . assuming a transmission energy of @xmath172 pj / bit from recently reported wireless transmitters for implants@xcite , the power dissipation for raw data rates of @xmath173 kbps / channel and compressed data rates of @xmath174 kbps / channel after spike sorting are @xmath160 @xmath0w and @xmath175 @xmath0w respectively .",
    "hence , the power for wireless transmission is a bottleneck for systems transmitting raw data . for systems with",
    "spike sorting in the implant , this power dissipation is not a bottleneck .",
    "however , the power / channel needed for the spike sorter is about @xmath81 @xmath0w . in comparison ,",
    "if our decoder operates directly on the spike detector output , it can provide compression at a power budget of @xmath176 @xmath0w / channel .",
    "this would result in a total power dissipation / channel of @xmath177 @xmath0w in our case compared to @xmath178 @xmath0w in the case of spike sorting  a 6x reduction .",
    "there is a lot of evidence that the decoding algorithms can work on the spike detector output@xcite ; in fact , it is believed that this will make the system more robust for long term use .",
    "this will be a subject of our future studies .    even if the decoder is explanted , a mcu can not provide sufficient throughput to support advanced decoding algorithms while fpga based systems consume a large baseline power .",
    "a custom mlcp based solution provides an attractive combination of low - power and high throughput operation when paired with a flexible mcu for control flow .",
    "the variation of temperature is not a big concern in the case of implantable electronics since body temperature is well regulated .",
    "however , variation of power supply voltage can be a concern .",
    "a normalization method can be applied to the hidden layer output for reducing its variation due to power supply fluctuation , at the cost of additional computation .",
    "the normalization proposed here can be expressed by : @xmath179 the rationale behind the proposed normalization is that the effect of power supply fluctuation on the hidden layer output can be modelled as multiplication factor in hidden layer output equation . as analyzed before ,",
    "the output of the @xmath180 hidden layer node can be formulated as : @xmath181 , where @xmath182 is the input current of the @xmath180 hidden layer node and @xmath183 is counting window length . since @xmath182 is proportional to the strength of input vector @xmath184 $ ] , we can model the relation between the input vector and hidden layer output as : @xmath185 , where the variation part is a multiplicative term @xmath186 , and @xmath187 lumps up the constant part of the path gain from input to @xmath180 hidden layer output .",
    "it is reasonable to assume that @xmath186 is the same across different nodes , since fluctuation of power supply is a global effect on chip scale .",
    "hence , it can be cancelled by the proposed normalization as : @xmath188 simulation results are presented here to verify the proposed method of normalization .",
    "the original hidden layer outputs ( @xmath189 ) are obtained by spice simulations where @xmath117 is swept from @xmath137 v to @xmath190 v and input @xmath191 ( @xmath192 ) changes from @xmath161 to @xmath160 .",
    "original and normalized values of one of the hidden layer outputs are compared in fig .",
    "[ fig : vdd_norm ] .",
    "as can be observed here , the normalized output ( in green dashed lines ) varies significantly less due to variation of @xmath117 than the original output ( in blue solid lines ) .",
    "the hardware cost for this normalization is @xmath193 additions and @xmath10 divisions .",
    "assuming similar costs for division and multiplication , the normalization does not incur much overhead if @xmath194 since @xmath19 multiplications are required by the second stage anyway .",
    "blue lines are original hidden layer output from spice simulation , while green dashed lines are normalized output in both ( a ) and ( b ) .",
    "the input x in ( a ) and ( b ) are 8 and 10 respectively .",
    "[ fig : vdd_norm ]      when using this mlcp based decoder in long term implants , we have to consider issues of parameter drift over several time scales . over long term of days ,",
    "aging of the circuits in mlcp or probe impedance change due to gliosis and scarring may change performance .",
    "this is typically countered by retraining the decoder every day @xcite .",
    "such retraining has allowed decoders to operate at similar level of performance over years . over shorter time scales ,",
    "any variation not sufficiently quenched by the normalization method described earlier can be explicitly calibrated by having digital multiplication of coefficients for every input and output channel .",
    "these can be determined periodically by injecting calibration inputs and observing the output of the cco .",
    "another type of training  referred to as decoder retraining@xcite are needed to take into account change in neural statistics during closed loop experiments .",
    "the training done here may be thought of as open loop training for initialization of coefficents of second stage of elm .",
    "next , the experiment has to be redone with closed loop feedback and new training data set has to be generated for retraining the second layer weights .",
    "after several such iterations , the final set of weights of second layer will be obtained .",
    "we presented a mlcp in @xmath195-@xmath0 m cmos with a die area of 4.95 @xmath95 4.95 @xmath123 and a 7.4 cm @xmath95 5.1 cm peu based on the proposed mlcp that achieves real - time motor intention decoding in an efficient way .",
    "implementing the elm algorithm , the mlcp utilizes massive parallel low power analog computing and hardware reuse , achieving a power consumption of @xmath196 @xmath0w at @xmath2 hz classification rate , resulting in an energy efficiency of @xmath1 pj / mac .",
    "learning in the second stage also compensates for non - idealities in the analog processor .",
    "furthermore , it includes time - delayed sample based dimension increase feature for enhancing decoding performance when number of recorded neurons are limited .",
    "a sparsity promoting training method is shown to reduce the number of hidden layer neurons and output weights by @xmath197 .",
    "we demonstrated the operation of the ic for decoding individuated finger movements using recordings of m1 neurons .",
    "however , the elm algorithm used in the decoder is quite general and has been shown to be an universal approximator and equivalent to svm or multi - layer perceptrons@xcite .",
    "hence , our mlcp can also be used for other decoding applications requiring regression or classification computations .",
    "higher dimensions of inputs and hidden layers can be handled by making a larger ic and also by reusing the same hidden layer several times . in either case ,",
    "power dissipation increases but not energy / compute .",
    "higher input dimensions can be accommodated at same power by reducing the bias current input of the splitter dacs in input channels@xcite .",
    "increase of hidden layer neurons however do incur a proportional power increase .",
    "given that the power requirement of the current decoder is @xmath198 lower than the afe , we can easily extend it to handle many more input and output channels .",
    "the authors would like to thank dr .",
    "nitish thakor for providing neural recording data .",
    "r.  r. harrison , p.  t. watkins , r.  j. kier , r.  o. lovejoy , d.  j. black , b.  greger , and f.  solzbacher , `` a low - power integrated circuits for a wireless 100-electrode neural recording system , '' , vol .",
    "1 , pp . 123133 , jan . 2007 .",
    "r.  sarpeshkar , w.  wattanapanitch , s.  k. arfin , b.  i. rapoport , s.  mandal , michael  w. baker , m.  s. fee , s.  musallam , and r.  a. adersen , `` low - power circuits for brain - machine interfaces , '' , vol .",
    "3 , pp . 173183 , sept .",
    "f.  shahrokhi , k.  abdelhalim , d.  serletis , p.  l. carlen , and r.  genov , `` the 128-channel fully differnetial digital integrated neural recording and stimulation interface , '' , vol .",
    "3 , pp . 149161 , jun . 2010 .",
    "t.  chen , k.  chen , z.  yang , k.  cockerham , and w.  liu , `` a biomedical multiprocessor soc for closed - loop neuroprosthetic applications , '' in _ solid - state circuits conference - digest of technical papers , 2009 .",
    "isscc 2009 .",
    "ieee international _ , feb 2009 , pp .",
    "434435,435a .",
    "s.  acharya , f.  tenore , v.  aggarwal , r.  etienne - cummings , m.  schieber , and n.  thakor , `` decoding individuated finger movements using volume - constrained neuronal ensembles in the m1 hand area , '' , vol .",
    "1523 , 2008 .",
    "l.  hochberg , d.  bacher , b.  jarosiewicz , n.  masse , j.  simeral , j.  vogel , s.  haddain , j.  liu , s.  cash , p.  der smagt , and j.  donoghue , `` reach and grasp by people with tetraplegia using a neurally controlled robotic arm , '' , vol .",
    "485 , pp . 372375 , 2012 .",
    "b.  rapoport , w.  wattanapanitch , h.  penagos , s.  musallam , r.  andersen , and r.  sarpeshkar , `` a biomimetic adaptive algorithm and low - power architecture for implantable neural decoders , '' in _",
    "31st annual international conference of the ieee embs _ , 2009 .",
    "kao , s.d .",
    "stavisky , d.  sussillo , p.  nuyujukian , and k.v .",
    "shenoy , `` information systems opportunities in brain - machine interface decodersinformation systems opportunities in brain - machine interface decoders , '' , vol .",
    "5 , pp . 666682 , may 2014 .",
    "kyong  ho lee and n.  verma , `` a low - power processor with configurable embedded machine - learning accelerators for high - order and adaptive analysis of medical - sensor signals , '' , vol .",
    "48 , no . 7 , pp .",
    "16251637 , july 2013 .",
    "jinwook oh , gyeonghoon kim , byeong - gyu nam , and hoi - jun yoo , `` a 57 mw 12.5 uj / epoch embedded mixed - mode neuro - fuzzy processor for mobile real - time object recognition , '' , vol .",
    "11 , pp . 28942907 , nov 2013 .",
    "d.  han , y.  zheng , r.  rajkumar , g.  dawe , and m.  je , `` a 0.45v 100-channel neural - recording ic with sub - uw / channel consumption in 0.18um cmos , '' in _ ieee international solid - state circuits conference _",
    ", 2013 , pp . 290291 .",
    "s.  x. diao , y.  j. zheng , y.  gao , s.  j. cheng , x.  j. yuan , and m.  y. je , `` a 50-mb / s cmos qpsk / o - qpsk transmitter employing injection locking for direct modulation , '' , vol .",
    "1 , pp . 120130 , jan 2012 .",
    "a.  l. orsborn , s.  dangi , h.  g. moorman , and j.  m. camena , `` closed - loop decoder adaptation on intermediate time - scales facilitates rapid bmi performance improvements independent of decoder initialization conditions , '' , vol .",
    "468477 , july 2012 ."
  ],
  "abstract_text": [
    "<S> currently , state - of - the - art motor intention decoding algorithms in brain - machine interfaces are mostly implemented on a pc and consume significant amount of power . </S>",
    "<S> a machine learning co - processor in 0.35-@xmath0 m cmos for the motor intention decoding in the brain - machine interfaces is presented in this paper . using extreme learning machine algorithm and low - power analog processing </S>",
    "<S> , it achieves an energy efficiency of @xmath1 pj / mac at a classification rate of @xmath2 hz . </S>",
    "<S> the learning in second stage and corresponding digitally stored coefficients are used to increase robustness of the core analog processor . </S>",
    "<S> the chip is verified with neural data recorded in monkey finger movements experiment , achieving a decoding accuracy of @xmath3 for movement type . </S>",
    "<S> the same co - processor is also used to decode time of movement from asynchronous neural spikes . with time - delayed feature dimension enhancement </S>",
    "<S> , the classification accuracy can be increased by @xmath4 with limited number of input channels . </S>",
    "<S> further , a sparsity promoting training scheme enables reduction of number of programmable weights by @xmath5 .    </S>",
    "<S> neural decoding , motor intention , brain - machine interfaces , vlsi , extreme learning machine , machine learning , neural network , portable , implant </S>"
  ]
}