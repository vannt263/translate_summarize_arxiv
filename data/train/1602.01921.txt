{
  "article_text": [
    "recently , a convolutional neural network ( cnn ) [ 1 ] , inspired by the mammalian visual cortex , has shown remarkably better object image recognition performance than conventional vision recognition schemes employing elaborately hand - coded visual features .",
    "a cnn trained with 1 million visual images from imagenet [ 2 ] can classify hundreds of object images with an error rate of 6.67% [ 3 ] , near - human performance [ 4 ] .",
    "however successful in the recognition of static visual images , cnns have poor dynamic image processing capability .",
    "the model lacks the capacity to process temporal information . a typical approach to overcome",
    "this limitation has been to use a 3d convolutional neural network ( 3d cnn ) [ 5 ] . with this model",
    ", dynamic visual images can be recognized through convolutions in the temporal and spatial domains in a fixed window .",
    "3d cnns have shown good performance on many public human action video datasets such as ucf-101 [ 6 ] and hmdb-51 [ 7 ] .",
    "even a cnn without any temporal processing capability is able to achieve recognition rates of 73% and 40.5% on ucf-101 and hmdb-51 , respectively [ 8 ] .",
    "baccouche et al .",
    "[ 9 ] has proposed a two - stage model to extract temporal information over entire image sequences , also adding a long short - term memory ( lstm ) network [ 10 ] as a second stage of a 3d cnn .",
    "similarly , venugopalan and colleagues [ 11 ] trained an lstm ( for the generation of corresponding descriptive sentences ) extended cnn ( for video processing ) with nearly a hundred thousand videos and corresponding descriptions with good test results . and recently , shi et al . [ 12 ] developed a convolutional lstm that has lstm cells embedded in the structure of the cnn for precipitation nowcasting .    for machine vision systems to learn the semantics of human actions",
    ", they have to perceive continuous visual streams and extract underlying spatio - temporal structures present in action patterns [ 13][14 ] . in the process",
    ", complex human actions can be characterized as compositions both in spatial and in temporal dimensions , which can then decomposed into and even creatively composed from reusable parts .",
    "`` temporal compositionality '' represents goal - directed human actions as sequential combinations of commonly used behavior primitives [ 13 ] .",
    "`` spatial compositionality '' represents the coordination of movement patterns in different limbs . recognizing this distinction , jung et al",
    ". proposed the multiple spatio - temporal scale neural network ( mstnn ) [ 15 ] model to impose both spatial and temporal constraints on cnn neural dynamics .",
    "specifically , jung et al .",
    "adjusted the time constants of the lower layers to a smaller values than that of the higher layers in the mstnn to make the temporal receptive field size of each layer to increase as the layer goes up .",
    "and the spatial receptive field size of each layer in the mstnn also increases as the layer goes up as in the case of the cnn . as a result",
    ", the model could extract spatio - temporal features in a hierarchical manner .",
    "this characteristic of the mstnn differentiates the mstnn from the rest of the models that were discussed previously . and also , the characteristic is consistent with the neurophysiological evidences that increasingly large spatio - temporal receptive windows are observed in the human cortex [ 16][17 ] . in jung",
    "et al.s work , the mstnn was able to categorize different sequential combinations of behavior primitives demonstrated by different subjects by learning from exemplar videos .",
    "however , the mstnn is limited in that it extracts temporal features of input action videos only utilizing the slow damping dynamics of its leaky integrator neurons .",
    "therefore , the stored information of extracted spatial features decays over time , leaving the model to depend largely on extracted spatial features of recent time steps instead . as a result ,",
    "the model is not able to learn complicated , temporally extended sequences . in order to overcome these limitations",
    ", the current work adds leaky integrator neural units with recurrent connections at each level of the mstnn . with this addition ,",
    "extracted spatial features no longer decay over time .",
    "the extracted spatial features of previous time steps can be preserved , or decayed , or amplified with the recurrent weights .",
    "this new model , the multiple spatio - temporal scales recurrent neural network ( mstrnn ) contains both leaky integrator neural units without recurrent connectivity as feature units and leaky integrator neural units with recurrent connectivity as context units , with each type at each level employing identical time constants .",
    "learning compositional action sequences requires the development of temporal correlations in memory .",
    "the present work investigates how a recurrent neural structure can enhance this capacity , and compares the performance of the mstrnn and mstnn models in the categorization of long sequences of primitive actions to observe the degree of enhancement .",
    "analysis of the internal representation of the mstrnn further reveals how neural activation patterns develop inside the model .",
    "then , the paper looks more deeply into the development of structural relationships between objects and transitive actions . for this purpose ,",
    "a video dataset of object - directed human actions was prepared .",
    "this set of actions was designed so that the category of each action and action - directed object ( ado ) could not be inferred in a trivial manner . also , a pantomime ( actions without ados )",
    "version of the dataset was prepared and the mstrnn was tested on it to see if the model can infer correct ados from given pantomime action image sequences , including cases where non - ados ( distractors ) are present in image sequences .",
    "it is impossible for the model to perform correct ado categorizations on the pantomime dataset without exploiting links between actions and ados that are learned from the training data of object - directed human actions .",
    "the multiple spatio - temporal scales recurrent neural network ( mstrnn ) is a spatio - temporally hierarchical neural network model that classifies videos .",
    "the model has the structure of the convolutional neural network ( cnn ) with additional recurrent structures included in each convolutional layer .",
    "the recurrent structure plays an important role in extracting latent temporal information from exemplar temporal sequences [ 18][19 ] .",
    "context neurons constituting recurrent structures are leaky integrator neurons with time constants that are similar to those used in the multiple timescales recurrent neural network ( mtrnn ) [ 20 ] .",
    "the mstrnn model consists of the following four layers : input , context , fully - connected , and an output layer as shown in figure 1 ( a ) .",
    "the mstrnn receives rgb image sequences in the input layer .",
    "then from the image sequences , multiple context layers extract spatio - temporal features from the input image sequences .",
    "the extracted spatio - temporal features go through several layers of fully - connected layers .",
    "then finally , in the output layer , the model classifies actions and action - directed - objects ( ados ) in object - directed human action videos .",
    "the output layer utilizes two softmax vectors to categorize both the action and the ado of the input video .",
    "is a time constant for a context layer .",
    "( b ) the structure of the context layer . an arrow with a @xmath0 indicates decay dynamics of leaky integrator neurons in either the feature units or the context units .",
    "the arrow with `` rec '' indicates recurrent connections made on the context units ]    the context layer simultaneously extracts spatio - temporal features , and is the core building block of the mstrnn .",
    "the context layer consists of feature units , pooling units , and context units as shown on figure 1 ( b ) .",
    "each context layer is assigned a time constant that controls the decay dynamics of the context units and the feature units .",
    "a larger time constant makes the internal states of leaky integrator neurons in the context layer change more slowly at each time step . with a smaller time",
    "constant , the internal states of the leaky integrator neurons change faster at every time step .",
    "the mstrnn assigns a larger time constant to higher layer leaky integrator neurons in order to develop a spatio - temporal hierarchy [ 15][20 ] .",
    "the feature units in a context layer are composed of leaky integrator neurons with time constants instead of static neurons as are normally used in a cnn [ 15 ] .",
    "the feature units are capable of extracting temporal features via decay dynamics of leaky integrator neurons , as well as capable of extracting spatial features by convolutional operations .",
    "feature units extract features from context units and pooling units of the previous context layer as shown on figure 1 ( b ) .",
    "the features in the pooling units are extracted from them via convolutional kernels , and the features in the context units are extracted from them with the weights connecting the feature units and the context units belonging to the same retinotopic positions of the maps .",
    "feature units and the context units in the same context layer have the same map sizes , and are connected in this way so that the feature locality is retained .",
    "the forward dynamics of the feature units are explained in equation 1 and 2 .",
    "the internal states and the activation values of the feature units at the _ _ l__th context layer , the _ _ m__th map of feature units , at time step _ t _ and at retinotopic coordinates ( x , y ) are represented as @xmath1 and @xmath2 in equation 1 and 2 , respectively .",
    "@xmath3    @xmath4    where @xmath0 represents the time constant , _ k _ is the convolutional kernel , _ b _ is the bias used in the convolution operation , @xmath5 is the convolution operator , _",
    "n _ is the total number of maps of the pooling units , _ a _ is the total number of maps of the context units . additionally , _",
    "w _ is the weight connecting the context units and the feature units , _ p _ and _ c _ are the activation values of the pooling units and the context units respectively .",
    "the first term on the right hand side of equation 1 describes the decay dynamics of the leaky integrator neurons .",
    "the second term represents the convolution of the features in the pooling units . and , the third term describes the features extracted from the context units of the previous context layer .",
    "the hyperbolic tangent function recommended by lecun et al .",
    "[ 21 ] is used as the activation functions of the feature units ( equation 2 ) .",
    "the context units consist of maps of leaky integrator neurons with recurrent weights .",
    "they extract spatio - temporal features in a similar manner to the feature units , except that they have enhanced temporal processing capacity by feeding back spatio - temporal information of the previous time step by the recurrent weights . to be specific , with recurrent connections , the context units exhibit recurrent dynamics in addition to decay dynamics normal to leaky integrator neurons .",
    "therefore , the recurrent dynamics enhance the extraction of latent temporal features from input image sequences in the context units [ 18][19 ] .",
    "the recurrent connections are made to each neuron and also to the neurons of different maps in the same retinotopic positions to retain the locality of spatial features . besides recurrent connections ,",
    "context units have convolutional kernels that extract features from pooling units in the same layer ( see figure 1 ( b ) ) .",
    "the forward dynamics of context units are shown in equation 3 and 4 .",
    "internal states and activation values for the _ _ a__th map of the context units in the _ _ l__th context layer at time step _",
    "t _ and at retinotopic coordinates ( x , y ) are represented as @xmath6 and @xmath7 respectively .",
    "@xmath8    @xmath9    where @xmath0 represents the time constant , @xmath10 is the convolutional kernel , @xmath11 is the bias for the convolution operation , @xmath5 is the convolution operator , _",
    "n _ is the total number of maps of the pooling units , _ b _ is the total number of maps of the context units , @xmath12 is the recurrent weight of the context units , _ p _ is the neural activations of pooling units .",
    "the first term on the right hand side of equation 3 describes the decay dynamics of the leaky integrator neurons .",
    "the second term represents the convolution of the pooling units .",
    "the third term describes the recurrent dynamics in terms of recurrent weights .",
    "the neural activations of the context units in the previous time step are supplied through the recurrent weights .",
    "for the activation function of the context units , the model uses the same hyperbolic tangent function that was used for the feature units as shown in equation 4 .",
    "training was conducted in a supervised manner using the delay response scheme [ 15 ] .",
    "black frames were input to the mstrnn after each input image sequence during the delay response period . in this period , errors were calculated for each time step by comparing the outputs of the mstrnn with the true labels of the input image sequences using kullback - leibler divergence . the cost function used in the training phase",
    "is shown in equation 5 .",
    "the error calculated for a whole input image sequence is represented as _ e_.    @xmath13    where _ d _ is the delay response period , _ t _ is the input video s duration ( length of frames ) , _ s _ is the total number of softmax vectors in the output layer .",
    "_ n(s ) _ is the total number of neurons in the _",
    "_ s__th softmax vector of the output layer , @xmath14 is the true output , and _ o _ is the output categorized by the mstrnn . the true output was given as the one - hot - vector for each softmax vector . here",
    ", the term one - hot - vector refers to a vector of values where a value is `` 1 '' for the one and only correct category and `` 0 '' for the rest of the categories .",
    "the error for each input action video is obtained with equation 5 .",
    "the error is used for the optimization of learnable parameters with the back propagation through time ( bptt ) [ 22 ] , and the stochastic gradient descent algorithms .",
    "the learnable parameters are , _ k _ , _ b _ , _ w _ of equation 1 , @xmath10 , @xmath11 , @xmath12 of equation 3 , weights held by the fully - connected layers , and the weights held by the output layer . to prevent overfitting , all learnable parameters ( except biases )",
    "were learned with a weight decay of 0.0005 [ 23 ] .",
    "the current study examines the performance of the multiple spatio - temporal scales recurrent neural network ( mstrnn ) given two types of experimental task .",
    "the first task compares the categorization performance of the model with that of the multiple spatio - temporal scales neural network ( mstnn ) [ 15 ] .",
    "then , the behavioral characteristics of the context layer in the mstrnn is analyzed .",
    "the second task examines how the mstrnn can learn to categorize a set of object - directed actions with an appropriate capacity to generalize .",
    "we compared learning and categorization capabilities of the mstrnn and the mstnn with a set of compositional long visual sequences .",
    "a set of exemplar video data was prepared by concatenating videos of 3 different human actions ( jump - in - place ( jp ) , one - hand - wave ( oh ) , and two - hand - wave ( th ) as shown on figure 2 ) from the weizmann dataset , resulting in 27 categories , and one video clip of concatenated actions for each category .",
    "27 videos for each of 9 subjects exist in the dataset .",
    "the foreground silhouettes of the resulting 3 actions concatenated weizmann ( 3acw ) dataset were emphasized by background subtraction utilizing background sequences , and were resized to 48x54 ( 48 pixels wide , 54 pixels high ) .",
    "the mstrnn and the mstnn models were trained ( see the `` training method '' section ) with the same learning rate ( 0.1 ) . both models were trained for 50 epochs . for the evaluation of categorization performance ,",
    "the leave - one - subject - out cross - validation ( losocv ) scheme was used . on this method , for each of 50 training epochs , 1 subject was selected from the 9 , his / her video clips were left out of the training data , and these were used as test data for that epoch . 9 sets of test accuracies from the 9 test subjects were averaged ( rounded to the first decimal point ) .",
    "the highest accuracy is reported in evaluation of performance .    structurally , both the mstrnn and the mstnn models have an input layer with one feature map for the input of grayscale video images .",
    "the size of the feature maps is 48x54 .",
    "the models have identical output layer structures also , consisting of a softmax vector with 27 neurons .",
    "the models were designed to have only one softmax vector output since they only categorize the action category .",
    "each of the softmax neurons in the vector represents one of 27 movement categories in the 3acw dataset .",
    "except for the input and output layers , the structure of the mstrnn and the mstnn are specified in table 1 and 2 , respectively .",
    "the only difference between their architectures is the addition of context units , and number of maps that consist the feature units in the layers of the models .",
    "the number of weights used in the mstrnn and mstnn were designed to be similar ( mstrnn : 495,327 weights , mstnn : 497,506 weights ) by adjusting the number of maps that are used in feature units in each layer of the mstnn while also keeping similar ratio between the numbers of maps in adjacent layers ( see figure 1 ) ( b ) ) .        .",
    "* parameters of the context layers in the mstrnn model used in the experiment . * [ cols=\"^,^,^,^,^,^,^,^,^,^,^ \" , ]     the joint category categorization rates were rounded off the the first decimal place .",
    "[ table6 ]    action - ado recognition accuracies are slightly better with the pantomime test videos than with the original object - directed human action test videos .",
    "for example , table 6 shows that the model correctly categorized the drink - cup pantomime correctly in 93.3% of instances , and incorrectly as drink - bottle in 6.7% .",
    "it is worth noting that the pantomime actions of drink - cup and drink - bottle are quite similar , so that even human beings may mis - categorize these pantomimed actions .",
    "consider also the categorization accuracy using the stir - cup pantomime test videos without distractors .",
    "performance here is similar to accuracies obtained using the object - present stir - cup test data .",
    "when given distractors - present pantomime test data , the mstrnn demonstrated a tendency to be distracted by non - ados .",
    "table 6 shows that the mstrnn recognized drink - cup pantomime action videos with distractor non - ados present as drink - cup ( 70% ) and as drink - bottle ( 30% ) . but again , pantomimed drink - cup and drink - bottle are difficult even for humans to distinguish , and so such ambiguous cases may be discounted .",
    "performance was worst with the stir - cup pantomime test data with distractors .",
    "the action - ado category of the test videos were mis - categorized more than the other test conditions ( stir - cup , stir - cup pantomime in table 6 ) by 50% .",
    "this significant amount of mis - categorization is caused by the mstrnn mis - categorizing distractors as ados . because , the categorization performance of the mstrnn on the drink - cup pantomime and stir - cup pantomime test videos without distractors were similar or better than its performance on the cup and non - ados present drink - cup , stir - cup test videos ( table 6 ) .",
    "indeed , the mstrnn correctly categorized ado ( cup ) of the test videos by only 50% which is lower than the ado categorization accuracies of the other test conditions ( stir - cup : 93.3% , stir - cup pantomime : 93.3% ) in table 6 . in the end",
    ", the preceding analysis shows that the ado categorization process of the mstrnn depends on both currently perceived objects and actions .",
    "in the first experiment categorizing long - ranged videos of compositional human action sequences , the proposed multiple spatio - temporal scales recurrent neural network ( mstrnn ) model performed better than the previous multiple spatio - temporal scales neural network ( mstnn ) [ 15 ] model .",
    "the recurrent connectivity in the context units enhanced the capability of the model to extract long - term correlations latent in training data .",
    "analysis of the internal dynamics of the context layer demonstrated that the feature units in the context layer tended to capture spatio - temporal features of recently given input images over a short time interval . on the other hand , the context units in the context layer captured spatio - temporal features of image sequences over a relatively longer period of time due to its recurrent structure and larger time constant .",
    "the second experiment tasked the mstrnn with learning to categorize object - directed human actions in order to examine the model s ability to capture underlying spatio - temporal structures linking human actions and visual images of objects at which the actions are directed .",
    "the overall categorization accuracies on the action category and the action - directed - object ( ado ) category were 75.9% and 81.9% , respectively .",
    "these categorization results demonstrate that the mstrnn is capable of learning structural links between actions and corresponding ados by extracting spatio - temporal features in its context layers .",
    "the mstrnn was distracted by non - ados present in image sequences , but could successfully recognize ados in most cases .",
    "principle component analysis ( pca ) [ 24 ] of the neural activations of the last time step in the second fully - connected layer shows that the model developed structural links between actions and corresponding ados .",
    "this is evident in the pca mapping as similar neural activations are mapped to similar locations in the pca mapped space ( as shown in figure 7 ) . in pca space ,",
    "neural activations generated from test data with the same joint category are more similar than neural activations generated from test data with same action , and both are more similar than neural activations generated from test data with merely the same ado .",
    "testing reveals that the mstrnn can infer ados from pantomime action videos by exploiting the structural links between actions and ados learned in training .",
    "however , the mstrnn demonstrated a tendency to be distracted when tested on the pantomime action videos with non - ado distractors present , and its ado categorization accuracies were lower in these cases than with pantomime test videos without distractors present .",
    "these results imply that the mstrnn depends on spatio - temporal features extracted from sequences of action images as well as on static object presence in order to correlate a given action with its appropriate ado .    currently , the best action - ado recognition rate obtained in the second experiment is 68.9% , which should be improved in future study .",
    "one of the main reasons for such a significant degree of mis - categorization might be overfitting .",
    "overfitting may be alleviated with recently developed deep learning regularization techniques including the dropout technique for recurrent connections [ 27 ] . by applying the dropout technique to long short - term memory ( lstm ) , gal et al . came up with the variational lstm which has demonstrated less susceptibility to problems of overfitting than the standard lstm .",
    "recurrent batch normalization [ 28 ] may also help to alleviate overfitting .",
    "cooijmans et al .",
    "have shown that batch - normalization of lstm improves its generalization capacity and encourages faster convergence in the learning phase .",
    "good performance depends on appropriate model parameters . in the current study",
    ", it was found that the performance of the model depends crucially on time constant values ascribed to each context layer . since there is no analytical way to determine the optimal values for time constants ,",
    "these must be established heuristically .",
    "future study should investigate a scheme for the self - adjustment of time constants .",
    "two approaches immediately present themselves .",
    "one involves using lstm [ 10 ] or gated recurrent units ( gru ) [ 29 ] to adapt time constants at each time step .",
    "lstm recurrent neural networks have demonstrated outstanding performance on sequence - based tasks with long - term dependencies [ 30 ] . and , the recently developed gru has demonstrated similar or higher performance [ 31 ] .",
    "embedding these models in the structure of our proposed model will make a model that is somewhat similar to the convolutional lstm [ 12 ] . from the results that were reported so far",
    ", the lstm and the gru do not develop hierarchical structures while learning from data , so constraints on time - constant adaptation must be applied to each layer .",
    "another approach to self - adapting time constants involves their automatic determination by way of genetic algorithm . on this approach ,",
    "simulated robot experiments demonstrate that the network naturally develops slow dynamics in the higher layer [ 32 ] .",
    "therefore , integration with the current work seems promising .",
    "future study should also investigate the possibility of improving categorization performance by modifying the structure of the mstrnn .",
    "first , by implementing a top - down prediction and attention pathway in addition to the current bottom - up pathway , mstrnn action recognition performance may improve because top - down processes provide values for anticipated future perceptual events .",
    "also , a recurrent loop may be added from the higher layer to the lower layer .",
    "currently , recurrent connections are made only within each context layer , and as a consequence , extracted spatio - temporal information in the higher layer can not affect lower layer neural activations .",
    "recurrent structures connecting higher to lower layers should facilitate this influence , and as a result , the capability of the mstrnn to extract latent features of sptaio - temporal patterns may be enhanced .",
    "ongoing work is focusing on improving the mstrnn to enhance the development of structural links via learning and involves making a dataset to be tested on an improved version of the mstrnn .",
    "the dataset will be more complex in terms of action - ado compositionality , requiring the use of transitive verbs , object nouns and modifiers , e.g. put - cup - on - book .",
    "the improved version of the mstrnn will be tested on this new dataset to see if the model is able to learn more complex structural links of transitive verbs , object nouns , and modifiers .",
    "biological evidence exists that humans learn temporal sequences through recurrent neural networks in their brains .",
    "goel et al .",
    "have shown not only that recurrent neural circuits and cortical circuits in particular are capable of encoding time , but also that there are mechanisms in place that allow such circuits to ` learn ' the temporal structures of stimuli [ 33 ] . also , recent neurophysiological studies suggest that human object recognition is aided by the understanding of object relevant actions [ 34 ] . as a recurrent neural network model for object - directed human action recognition ,",
    "the mstrnn is inspired by such biological insights .",
    "the mstrnn also recognizes action - directed - objects ( ados ) in light of perceived actions , and has demonstrated a capacity to infer correct ados from pantomime action videos .",
    "this capacity is grounded on learned structural links between actions and corresponding ados , a capacity to be emphasized in future work .    in summary ,",
    "the mstrnn model network developed categorical memories for a set of trained object - directed actions , self - organizing an internally consistent relational structure among them within a bottom - up generated metric space .",
    "development of such a relational structure in metric space may facilitate generalization in categorization .",
    "but , a fundamental question presents itself : what sort of metric space is developed in the categorical memories in the trained model network ?",
    "it is highly desired to establish a direct relation between spatio - temporal analysis of neural activity associated with perception of categorical patterns , and intended action - ado pairs . although the present preliminary study used principle component analysis ( pca ) [ 24 ] to examine how neural activations generated by the mstrnn retain relationships between actions and corresponding ados , solid results have not yet been obtained .",
    "future study should develop effective methods to determine a distance measure among spatio - temporal patterns in massive numbers of neural units for different categories .",
    "this work was supported by the national research foundation of korea ( nrf ) grant funded by the korea government ( msip ) ( no .",
    "2014r1a2a2a01005491 ) .",
    "[ 1 ] lecun y , bottou l , bengio y , haffner p. gradient - based learning applied to document recognition .",
    "proceedings of the ieee .",
    "1998 nov;86(11):2278 - 324 .",
    "[ 3 ] szegedy c , liu w , jia y , sermanet p , reed s , anguelov d , erhan d , vanhoucke v , rabinovich a. going deeper with convolutions . in proceedings of the ieee conference on computer vision and pattern recognition 2015 .",
    "p. 1 - 9 .",
    "[ 4 ] russakovsky o , deng j , su h , krause j , satheesh s , ma s , huang z , karpathy a , khosla a , bernstein m , berg ac , fei - fei l. imagenet large scale visual recognition challenge .",
    "international journal of computer vision .",
    "2015 dec 1;115(3):211 - 52 .",
    "[ 12 ] shi x , chen z , wang h , yeung dy , wong wk , woo wc .",
    "convolutional lstm network : a machine learning approach for precipitation nowcasting . in advances in neural information processing systems 2015 ( pp .",
    "802 - 810 ) .",
    "[ 25 ] srivastava n , hinton g , krizhevsky a , sutskever i , salakhutdinov r. dropout : a simple way to prevent neural networks from overfitting . the journal of machine learning research .",
    "2014 jan 1;15(1):1929 - 58 .",
    "[ 26 ] karpathy a , toderici g , shetty s , leung t , sukthankar r , fei - fei l. large - scale video classification with convolutional neural networks . in proceedings of the ieee conference on computer vision and pattern recognition 2014 .",
    "1725 - 1732 .",
    "[ 29 ] cho k , van merrinboer b , gulcehre c , bahdanau d , bougares f , schwenk h , bengio y. learning phrase representations using rnn encoder - decoder for statistical machine translation .",
    "arxiv preprint arxiv:1406.1078 .",
    "2014 jun 3 .",
    "[ 30 ] graves a , mohamed ar , hinton g. speech recognition with deep recurrent neural networks . in 2013 ieee international conference on acoustics , speech and signal processing 2013 may 26 ( pp .",
    "6645 - 6649 ) ."
  ],
  "abstract_text": [
    "<S> the current paper proposes a novel dynamic neural network model for categorization of complex human action visual patterns . </S>",
    "<S> the multiple spatio - temporal scales recurrent neural network ( mstrnn ) adds recurrent connectivity to a prior model , the multiple spatio - temporal scales neural network ( mstnn ) . by developing adequate recurrent contextual dynamics </S>",
    "<S> , the mstrnn can learn to extract latent spatio - temporal structures from input image sequences more effectively than the mstnn . </S>",
    "<S> two experiments with the mstrnn are detailed . </S>",
    "<S> the first experiment involves categorizing a set of human movement patterns consisting of sequences of action primitives . </S>",
    "<S> the mstrnn is able to extract long - ranged correlations in video images better than the mstnn . </S>",
    "<S> time series analysis on neural activation values obtained from the recurrent structure shows that the mstrnn accumulates extracted spatio - temporal features which discriminate action sequences . </S>",
    "<S> the second experiment requires that the model categorize a set of object - directed actions , and demonstrates that the mstrnn can learn to extract structural relationships between actions and action - directed - objects ( ados ) . </S>",
    "<S> analysis of characteristics employed in categorizing both object - directed actions and pantomime actions indicates that the model network develops categorical memories by organizing relational structures between each action and appropriate ado . </S>",
    "<S> such relational structure may be necessary for categorizing human actions with an adequate ability to generalize .    </S>",
    "<S> = 1 </S>"
  ]
}