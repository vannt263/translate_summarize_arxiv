{
  "article_text": [
    "since the mid-1980s , interest has steadily grown in _ derivative - free _ methods ( also called _ non - derivative _ methods ) for solving optimization problems , unconstrained and constrained .",
    "derivative - free methods that adaptively construct a local model of relevant nonlinear functions are often described as `` model - based '' , and derivative - free methods that do not explicitly involve such a model tend to be called `` direct search '' methods .",
    "see @xcite for a recent survey of derivative - free methods ; discussions focusing on direct search methods include , for example , @xcite .",
    "the nelder ",
    "mead ( nm ) simplex method @xcite is a direct search method .",
    "each iteration of the nm method begins with a nondegenerate simplex ( a geometric figure in @xmath1 dimensions of nonzero volume that is the convex hull of @xmath3 vertices ) , defined by its vertices and the associated values of @xmath0 .",
    "one or more trial points are computed , along with their function values , and the iteration produces a new ( different ) simplex such that the function values at its vertices typically satisfy a descent condition compared to the previous simplex .",
    "the nm method is appealingly simple to describe ( see figure  [ fig - nmmoves ] ) , and has been widely used ( along with numerous variants ) for more than 45 years , in many scientific and engineering applications .",
    "but little mathematical analysis of any kind of the method s performance has appeared , with a few exceptions such as @xcite ( from more than 20 years ago ) and ( more recently ) @xcite . as we discuss in more detail below , obtaining",
    "even limited convergence proofs for the original method has turned out to be far from simple .",
    "the shortage of theory , plus the discovery of low - dimensional counterexamples ( see  ) have made the nm method an outlier among modern direct search methods , which are deliberately based on a rigorous mathematical foundation .",
    "( see , for example , @xcite , as well as more recent publications about direct search methods for constrained problems . )",
    "nevertheless the nm method retains importance because of its continued use and availability in computer packages ( see @xcite ) and its apparent usefulness in some situations .    in an effort to develop positive theory about the original nm algorithm ,",
    "an analysis of its convergence behavior was initiated in @xcite in 1998 , along with resolution of ambiguities in @xcite about whether function comparisons involve `` greater than '' or `` greater than or equal '' tests . in what follows we use the term _ nelder - mead algorithm _ to refer generically to one of the precisely specified procedures in @xcite",
    "; these contain a number of adjustable parameters ( coefficients ) , and the _ standard coefficients _ represent an often - used choice .",
    "for strictly convex objective functions with bounded level sets , @xcite showed convergence of the most general form of the nm algorithm to the minimizer in one dimension .",
    "for the nm algorithm with standard coefficients in dimension two , where the simplex is a triangle , it was shown that the function values at the simplex vertices converge to a limiting value , and furthermore that the diameter of the simplices converges to zero .",
    "but it was not shown that the simplices always converge to a limiting point , and up to now this question remains unresolved .    taking the opposite perspective",
    ", mckinnon  @xcite devised a family of two - dimensional counterexamples consisting of strictly convex functions with bounded level sets and a specified initial simplex , for which the nm simplices converge to a nonminimizing point . in the smoothest mckinnon example , the objective function is @xmath4 when the vertices of the starting simplex are @xmath5 , @xmath6 and @xmath7 .",
    "note that @xmath8 is twice - continuously differentiable and that its hessian is positive definite except at the origin , where it is singular . as shown in figure  [ fig - mckinfig ] , the nm algorithm converges to the origin ( one of the initial vertices ) rather than to the minimizer @xmath9 , performing an infinite sequence of inside contractions ( see section  [ sec - nmalgs ] ) in which the best vertex of the initial triangle is never replaced .",
    "= 4 in = 2.25 in @xmath10    functions proposed by various authors on which the nm algorithm fails to converge to a minimizer are surveyed in  @xcite , but counterexamples in the mckinnon family illustrated by constitute the `` nicest '' functions for which the nm algorithm converges to a non - stationary point .",
    "an algorithmic flaw that has been observed is that the iterations `` stagnate '' or `` stall '' , often because the simplex becomes increasingly close to degenerate ( as depicted in figure  [ fig - mckinfig ] ) .",
    "previously proposed corrective strategies include : placing more restrictions on moves that decrease the size of the simplex ; imposing a `` sufficient decrease '' condition ( stronger than simple decrease ) for accepting a new vertex ; and resetting the simplex to one that is `` nice '' .",
    "see , for example , @xcite , a small selection of the many papers that include convergence results for modifications of nelder  mead .",
    "our object in this paper is to fill in additional theory for the nm algorithm in the two - dimensional case , which remains of interest in its own right . as noted by mckinnon @xcite , it is not even known whether the nm algorithm converges for the prototypically nice function @xmath11 . here",
    "we answer this question affirmatively for a simplified variant of the nm algorithm , where the simplification reduces the number of allowable moves rather than attempting to `` fix '' the method . in the original nm algorithm ( see section  [ sec - nmalgs ] ) , the allowable moves are reflection , expansion , outside contraction , inside contraction , and shrink ; an expansion doubles the volume of an nm simplex , while all other moves either leave the volume the same or decrease it .",
    "an expansion is tried only after the reflection point produces a strict improvement in the best value of @xmath12 ; the motivation is to allow a longer step along an apparently promising direction .",
    "the _ restricted _ nelder  mead ( rnm ) algorithm defined in section  [ sec - nmalgs ] does not allow expansion steps .",
    "thus we are in effect considering a `` small step '' nm algorithm .",
    "our analysis applies to the following class of functions :    let @xmath13 denote the class of twice - continuously differentiable functions @xmath14 with bounded level sets and everywhere positive definite hessian .",
    "the class @xmath13 is a subclass of those considered in @xcite , where there is no requirement of differentiability .",
    "the contribution of this paper is to prove convergence of the restricted nelder - mead algorithm for functions in @xmath13 :    [ thm - rnmconv ] if the rnm algorithm is applied to a function @xmath15 , starting from any nondegenerate triangle , then the algorithm converges to the unique minimizer of @xmath12 .",
    "theorem  [ thm - rnmconv ] immediately implies a generalization to a larger class of functions .",
    "namely , if @xmath15 , and @xmath16 is a strictly increasing function , then the rnm algorithm applied to @xmath17 converges , because the rnm steps for @xmath18 are identical to those for @xmath12 .",
    "because the nm iterations in the mckinnon examples include no expansion steps , the rnm algorithm also will fail to converge to a minimizer on these examples .",
    "it follows that , in order to obtain a positive convergence result , additional assumptions on the function over those in @xcite must be imposed . in particular , the positive - definiteness condition on the hessian in theorem  [ thm - rnmconv ] rules out the smoothest mckinnon example ( [ eqn - mckinsamp ] ) , in which the hessian is singular at the origin ( the nonminimizing initial vertex to which the nm algorithm converges ) .",
    "an interesting general property of the nelder ",
    "mead algorithm is the constantly changing shape of the simplex as the algorithm progresses .",
    "understanding the varying geometry of the simplex seems crucial to explaining how the algorithm behaves .",
    "our proof of theorem  [ thm - rnmconv ] analyzes the rnm algorithm as a discrete dynamical system , in which the shapes of the relevant simplices ( with a proper scaling ) form a phase - space for the algorithm s behavior .",
    "the imposed hypothesis on the hessian , which is stronger than strict convexity , allows a crucial connection to be made between a ( rescaled ) local geometry and the vertex function values .",
    "we analyze the algorithm s behavior in a transformed coordinate system that corrects for this rescaling .",
    "the proof of theorem  [ thm - rnmconv ] establishes convergence by contradiction , by showing that the algorithm can find no way not to converge .",
    "we make , in effect , a `` sherlock holmes '' argument : once you have eliminated the impossible , whatever remains , however improbable , must be the truth .",
    "we show that , in order not to converge to the minimizer , the triangles would need to flatten out according to a particular geometric scaling , but there is no set of rnm steps permitting this flattening to happen .",
    "this result is confirmed through an auxiliary potential function measuring the deviation from scaling .",
    "one can almost say that the rnm algorithm converges in spite of itself .",
    "let @xmath19 be a function to be minimized , and let @xmath20 be the vertices of a nondegenerate simplex in @xmath21 .",
    "one iteration of the rnm algorithm ( with standard coefficients ) replaces the simplex by a new one according to the following procedure .",
    "* one iteration of the standard rnm algorithm . *    1 .   * order .",
    "* order and label the @xmath3 vertices to satisfy @xmath22 , using appropriate tie - breaking rules such as those in @xcite .",
    "[ step - reflect ] * reflect . *",
    "calculate @xmath23 , the average of the @xmath1 best points ( omitting @xmath24 ) .",
    "compute the _ reflection point _",
    "@xmath25 , defined as @xmath26 , and evaluate @xmath27 . if @xmath28 , accept the reflected point @xmath25 and terminate the iteration .",
    "[ step - contract ] * contract . *",
    "if @xmath29 , perform a _ contraction _ between @xmath30 and the better of @xmath24 and @xmath25 . +",
    "* a. outside contract.*if @xmath31 ( i.e. , @xmath25 is strictly better than @xmath24 ) , perform an _ outside contraction _ : calculate the outside contraction point @xmath32 , and evaluate @xmath33 . if @xmath34 , accept @xmath35 and terminate the iteration",
    "; otherwise , go to step [ step - shrink ] ( perform a shrink ) . + * b. inside contract.*if @xmath36 , perform an _ inside contraction _ : calculate the inside contraction point @xmath37 , and evaluate @xmath38 .",
    "if @xmath39 , accept @xmath40 and terminate the iteration ; otherwise , go to step [ step - shrink ] ( perform a shrink ) .",
    "[ step - shrink ] * perform a shrink step . *",
    "evaluate @xmath0 at the @xmath1 points @xmath41 , @xmath42 , ",
    ", @xmath3 .",
    "the ( unordered ) vertices of the simplex at the next iteration consist of @xmath43 , @xmath44 ,  , @xmath45 .",
    "the result of an rnm iteration is either : ( 1 ) a single new vertex  the _ accepted point_that replaces the worst vertex @xmath24 in the set of vertices for the next iteration ; or ( 2 ) if a shrink is performed , a set of @xmath1 new points that , together with @xmath43 , form the simplex at the next iteration .",
    "@xmath46    starting from a given nondegenerate simplex , let @xmath47 ,  ,",
    "@xmath48 be the vertices at the _ start _ of the @xmath49 iteration .",
    "let @xmath50 be a point .",
    "we say that the rnm algorithm converges to @xmath51 if @xmath52 for every @xmath53 .    in two dimensions ,",
    "a reflect step performs a @xmath54 rotation of the triangle around @xmath30 , so the resulting triangle is congruent to the original one .",
    "but in higher dimensions , the reflected simplex is not congruent to the original .",
    "shrink steps are irrelevant in this paper because we are concerned only with strictly convex objective functions , for which shrinks can not occur ( lemma 3.5 of @xcite ) .",
    "it follows that , at each nm iteration , the function value at the new vertex is strictly less than the worst function value at the previous iteration .",
    "the original nelder ",
    "mead algorithm differs from the above in step  2 .",
    "namely , if @xmath25 is better than all @xmath3 of the vertices , the original nm algorithm tries evaluating @xmath0 at the _ expansion _",
    "point @xmath55 for a fixed expansion coefficient @xmath56 , and the worst vertex @xmath24 is then replaced by the better of @xmath57 and @xmath25 .",
    "in fact , nelder and mead proposed a family of algorithms , depending on coefficients for reflection , contraction , and shrinkage in addition to expansion . a complete , precise definition of an nm iteration is given in @xcite , along with a set of tie - breaking rules .",
    "instances of the moves in the original nm algorithm are shown in figure  [ fig - nmmoves ] .",
    "one feature of the rnm algorithm that makes it easier to analyze than the original algorithm is that the volume of the simplex is non - increasing at each step .",
    "the volume thus serves as a lyapunov function .",
    "we henceforth consider the rnm algorithm _ in dimension two _ , for which it is known that the simplex diameter converges to zero .",
    "[ lem - diamtozero ] suppose that the rnm algorithm is applied to a strictly convex @xmath58-variable function with bounded level sets .",
    "then for any nondegenerate initial simplex , the diameters of the rnm simplices ( triangles ) produced by the algorithm converge to @xmath59 .",
    "the proof given in ( * ? ? ?",
    "* lemma  5.2 ) for the original nm algorithm applies even when expansion steps are disabled .",
    "because the logic of the convergence proof is complicated , we begin with an overview of the argument .",
    "each @xmath15 is strictly convex , so by lemma  [ lem - diamtozero ] we know that the evolution of any triangle under the rnm algorithm has the diameter of the triangle converging to zero .",
    "( we do not yet know that the triangles converge to a limit point . )",
    "the convergence proof proceeds by contradiction , making an initial hypothesis ( hypothesis  1 in section  [ sec - levelset ] ) that the ( unique ) minimizer of @xmath12 is not a limit point of the rnm triangles . under this condition",
    ", all three rnm vertices must approach a level set corresponding to a function value strictly higher than the optimal value . by our assumptions on @xmath12 ,",
    "this level set is a strictly convex closed curve with a continuously differentiable tangent vector .",
    "the rnm triangle must become small as it approaches this bounding level set .",
    "therefore , from the viewpoint of the triangle , blown up to have ( say ) unit diameter , the level set flattens out to a straight line .",
    "the heuristic underlying our argument is that , in order for this to happen , the triangle must itself have its shape flatten out , with its width in the level set direction ( nearly horizontal , as seen from the triangle ) being roughly the square root of its height in the perpendicular direction . in particular , its width becomes proportionally much larger than its height .",
    "a local coordinate frame ( section  [ sec - coordframe ] ) is defined in order to describe this phenomenon .    at the _ start _ of iteration @xmath60 , we measure area and width in a local coordinate frame , and define a quantity called `` flatness '' by @xmath61 .",
    "if a reflection is taken during iteration @xmath60 and the same coordinate frame is retained , the area and width of the rnm triangle at iteration @xmath62 remain the same , so @xmath63 .",
    "hence , in order for the diameter to converge to zero ( lemma  [ lem - diamtozero ] ) , there must be infinitely many contraction steps .",
    "we show that , at a sufficiently advanced iteration @xmath60 of the rnm algorithm , a necessary condition for a contraction to occur is that @xmath64 ; we also show that the value of @xmath65 eventually unavoidably increases as the algorithm proceeds .",
    "a contradiction thus arises because no combination of the permitted reflection and contraction steps allows the needed square root rate of decrease .",
    "the argument is complicated because the local coordinate frame changes at every step .",
    "near the end of the proof ( in proposition  [ prop-14steps ] ) , we analyze sequences of no more than 14 steps , beginning with a contraction , in an advanced phase of the algorithm . using a coordinate frame defined by a vertex of the first triangle in the sequence ,",
    "we show that switching to a new coordinate system defined via the final triangle in the sequence makes only a small change in the flatness .",
    "this allows us to show that the flatness is inflated by a factor of at least @xmath66 after at most @xmath67 steps , which eventually means that a contraction can not be taken .",
    "since the triangle can not reflect forever , our contradiction hypothesis must have been false ; i.e. , the method must converge .",
    "points in two dimensions are denoted by boldface lower - case letters , but a generic point is often called @xmath68 , which is treated as a column vector and written as @xmath69 .",
    "we shall also often use an affinely transformed coordinate system with generic point denoted by @xmath70 . to stress the @xmath71 coordinates of a specific point , say @xmath72 , we write @xmath73 .    for future reference",
    ", we explicitly give the formulas for the reflection and contraction points in two dimensions : @xmath74 given the three vertices of a triangle , the reflection and contraction points depend only on which ( one ) vertex is labeled as `` worst '' .      the type of move at each rnm iteration is governed by a discrete decision , based on comparing values of @xmath0 .",
    "heuristically , for a very small triangle near a point @xmath75 , the result of the comparison is usually unchanged if we replace @xmath0 by its degree-@xmath58 taylor polynomial centered at @xmath75 .",
    "if @xmath75 is a nonminimizing point , then we can simplify the function further by making an affine transformation into a new coordinate system @xmath76 ( depending on @xmath75 ) in which the taylor polynomial has the form @xmath77 this motivates the following lemma , which is a version of taylor s theorem .",
    "[ lem - affdef ] let @xmath15 .",
    "given a point @xmath75 and a nonsingular @xmath78 matrix @xmath79 , we may define an affine transformation @xmath80 ( with inverse map @xmath81 )",
    "[ i : existence of m ] for each point @xmath75 that is not the minimizer of @xmath12 , there exists a unique @xmath79 with @xmath82 such that when the function @xmath12 of @xmath83 is re - expressed in the new coordinate system @xmath84 above , the result has the form @xmath85 where @xmath86 is an error term satisfying @xmath87 as @xmath88 ( i.e. , as @xmath89 ) , for some @xmath90 .",
    "[ i : function r ] the function @xmath86 in   satisfies @xmath91 and @xmath92 , and the rate at which the @xmath93 terms approach zero and the bounds implied by @xmath94 can be made uniform for @xmath75 in any compact set not containing the minimizer of @xmath12 .",
    "[ i : uniformly continuous ] as @xmath75 varies over a compact set not containing the minimizer of @xmath12 , the matrices @xmath79 and @xmath95 are bounded in norm and uniformly continuous .",
    "let @xmath96 and @xmath97 denote , respectively , the gradient and hessian matrix of @xmath12 at @xmath75 . since @xmath12 is strictly convex , its gradient can vanish only at the unique minimizer , so @xmath98 .",
    "because @xmath0 is twice - continuously differentiable , we can expand it in taylor series around @xmath75 : @xmath99 the taylor expansion has the desired form if @xmath100 for some @xmath90 .",
    "in terms of the columns @xmath101 and @xmath102 of @xmath79 , these conditions say @xmath103 and then we may set @xmath104 , which will be positive since @xmath105 is positive definite and since the conditions above force @xmath102 to be nonzero .",
    "since @xmath98 , the condition @xmath106 says that @xmath101 is a multiple of the vector @xmath107 obtained by rotating @xmath108 by @xmath109 clockwise : @xmath110 for some @xmath111 .",
    "the condition @xmath112 implies that @xmath113 .",
    "the condition @xmath114 says that @xmath115 is a multiple of @xmath108 .",
    "since @xmath105 is positive definite , @xmath105 is nonsingular , so the equation @xmath116 has the unique solution @xmath117 , and then @xmath118 for some @xmath119 .",
    "the normalizations @xmath120 and @xmath121 are equivalent to @xmath122 the denominators are positive since @xmath105 is positive definite and @xmath123 and @xmath107 are nonzero .",
    "these conditions determine @xmath79 uniquely up to the choice of sign of its first column , i.e. , the sign of @xmath111 , but we have not yet imposed the condition @xmath82 .",
    "we claim that it is the positive choice of @xmath111 that makes @xmath82 : since @xmath101 and @xmath102 are then positive multiples of @xmath107 and @xmath123 , respectively , the condition @xmath82 is equivalent to @xmath124 , or equivalently , @xmath125 , which is true since the matrix @xmath126 is positive definite .",
    "this proves  .    since @xmath12 is twice - continuously differentiable , @xmath108 and @xmath105 vary continuously as @xmath75 varies within a compact set not containing the minimizer of @xmath12 .",
    "hence @xmath79 and @xmath95 vary continuously as well .",
    "this proves and .",
    "if @xmath105 is positive semidefinite and singular , then the equation @xmath127 continues to have a solution provided that @xmath128 , as in the mckinnon example  .",
    "but in this case , @xmath129 , so @xmath130 , which contradicts @xmath121 , and no matrix @xmath79 exists .",
    "as @xmath75 approaches the minimizer of @xmath12 , we have @xmath131 , and the formulas obtained in the proof of lemma  [ lem - affdef ] show that @xmath101 remains bounded while @xmath102 and the value of @xmath132 `` blow up '' , so @xmath79 becomes unbounded in norm with an increasing condition number .",
    "the local coordinate frame defined in lemma  [ lem - affdef ] depends on the base point @xmath75 , the gradient vector @xmath108 , and the hessian matrix @xmath105 . in the rest of this section",
    ", we use @xmath133 ( with a nonminimizing point @xmath75 as argument ) to denote the local coordinate frame with base point @xmath75 . in the context of a sequence of rnm iterations , @xmath134 ( or @xmath135 , with a subscripted rnm triangle as argument ) will mean the coordinate frame defined with a specified base point in rnm triangle @xmath136 .",
    "this section collects some results about transformed rnm triangles .",
    "[ def - flatness ] let @xmath15 , and let @xmath137 denote a nondegenerate triangle that lies in a compact set @xmath138 not containing the minimizer of @xmath12 .",
    "assume that we are given a base point @xmath75 in @xmath138 , along with the coordinate frame defined at @xmath75 as in lemma  [ lem - affdef ] .",
    "* the ( transformed ) _ width _ of @xmath137 , denoted by @xmath139 , is the maximum absolute value of the difference in @xmath140-coordinates of two vertices of @xmath137 ; * the ( transformed ) _ height _ , denoted by @xmath141 , is the maximum absolute value of the difference of @xmath142-coordinates of two vertices of @xmath137 ; * the _ flatness _ of @xmath137 , denoted by @xmath143 , is @xmath144 where @xmath145 is the ( positive ) area of @xmath137 measured in the transformed coordinates .",
    "the argument @xmath137 may be omitted when it is obvious .",
    "[ lem - refeffects ] the ( transformed ) height and width of an rnm triangle are the same as those of its reflection , if the same base point is used to define the local coordinate frame for both triangles .    the new triangle is a @xmath54 rotation of the old triangle .",
    "the next lemma bounds the change in three quantities arising from small changes in the base point used for the local coordinate frames . in  , we need a hypothesis on the width and height since for a tall thin triangle , a slight rotation can affect its flatness dramatically .",
    "[ consequences of close base points . ]",
    "[ lem - closebase ] assume that @xmath15 and that @xmath138 is a compact set that does not contain the minimizer of @xmath12 .",
    "let @xmath146 and @xmath147 denote two points in @xmath138 , and @xmath137 denote an rnm triangle contained in @xmath138 .",
    "for @xmath148 , let @xmath149 , @xmath150 , and @xmath151 be the transformed width , height , and flatness of @xmath137 measured in the local coordinate frame @xmath152 associated with @xmath153 , and let @xmath154 be the matrix of lemma  [ lem - affdef ] associated with @xmath152 .    1 .",
    "[ i : closebase matrix ] given @xmath155 , there exists @xmath156 ( independent of @xmath146 and @xmath147 ) such that if @xmath157 , then @xmath158 2 .",
    "[ i : closebase area ] given @xmath155 , there exists @xmath159 ( independent of @xmath146 , @xmath147 , and @xmath137 ) such that if @xmath160 , then @xmath161 3 .",
    "[ i : closebase flatness ] given @xmath162 , there is @xmath156 ( independent of @xmath146 , @xmath147 , and @xmath137 ) such that if @xmath160 and @xmath163 , then @xmath164    1 .",
    "we have @xmath165 by lemma  [ lem - affdef ] , the first factor @xmath166 is uniformly bounded , and @xmath95 is uniformly continuous as a function of @xmath167 , so the second factor @xmath168 can be made as small as desired by requiring @xmath169 to be small .",
    "2 .   letting @xmath170 and @xmath171 denote the transformed versions of a point @xmath68 in @xmath138 using @xmath172 and @xmath173 , we have @xmath174 so that @xmath170 and @xmath171 are related by an affine transformation with matrix @xmath175 . when an affine transformation with nonsingular matrix @xmath176 is applied to the vertices of a triangle ,",
    "the area of the transformed triangle is equal to the area of the original triangle multiplied by @xmath177 @xcite . applying this result to @xmath137",
    "gives @xmath178 since @xmath179 is a continuous function of @xmath176 , the result follows from .",
    "because of  , it suffices to prove the analogous inequalities for width instead of flatness .",
    "fixing two vertices of @xmath180 , we let @xmath181 denote the vector from one to the other measured in @xmath152 , and let @xmath182 denote the corresponding @xmath183-component",
    ". then @xmath184 , since @xmath185 . by ,",
    "@xmath186 , so @xmath187 this bounds the change in @xmath183-component of each vector of the triangle in passing from @xmath172 to @xmath173 , and it follows that @xmath188 finally , by  , @xmath189 can be made arbitrarily small .",
    "our proof of theorem  [ thm - rnmconv ] is by contradiction .",
    "therefore we assume the following hypothesis for the rest of section  [ sec - convproof ] and hope to obtain a contradiction .",
    "[ hyp1 ] assume that the rnm algorithm is applied to @xmath15 and a nondegenerate initial triangle , and that it does not converge to the minimizer of @xmath12 .",
    "we begin with a few easy consequences of hypothesis  1 .",
    "let @xmath136 be the rnm triangle at the start of the @xmath49 iteration .",
    "let @xmath190 be that triangle in the coordinate frame determined by any one of its vertices , and define its width @xmath191 , height @xmath192 , and flatness @xmath193 as in definition  [ def - flatness ] .",
    "[ l : consequences of hypothesis 1 ] assume hypothesis  1 .",
    "then :    1 .",
    "[ i : diameter tends to 0 ] the diameter of @xmath136 tends to @xmath59 .",
    "[ i : at least one limit point ] the rnm triangles have at least one limit point @xmath194 .",
    "[ i : function values tend to limit ] the function values at the vertices of @xmath136 are greater than or equal to @xmath195 , and they tend to @xmath195 .",
    "[ i : action ] if @xmath138 is a neighborhood of the level set of @xmath194 , then all the action of the algorithm is eventually inside @xmath138 .",
    "[ i : eigenvalues of hessian ] we may choose @xmath138 to be a compact neighborhood not containing the minimizer of @xmath12 ; then there is a positive lower bound on the smallest eigenvalue of the hessian in @xmath138 .",
    "[ i : transformed diameter ] the diameter of @xmath190 tends to zero . 7 .",
    "[ i : transformed width and height ] we have @xmath196 and @xmath197 .    1 .",
    "this follows from lemma  [ lem - diamtozero ] , even without hypothesis  1 . 2 .",
    "lemma  3.3 of @xcite states that the best , next - worst , and worst function values in each successive triangle can not increase , and that at least one of them must strictly decrease at each iteration . because level sets are bounded , compactness guarantees that there is a limit point @xmath194 .",
    "this follows from the monotonic decrease in function values , the shrinking of the diameter to zero , and the continuity of @xmath12 .",
    "since the level sets are compact , there is a compact neighborhood @xmath198 of @xmath199 such that @xmath200 is a compact set contained in the interior of @xmath138 . by  , the triangles are eventually contained in @xmath200 . by  ,",
    "eventually even the rejected points tested in each iteration lie within @xmath200 .",
    "the first statement follows since the minimizer is not on the level set of @xmath194 .",
    "the second statement follows from uniform continuity of the hessian .",
    "6 .   by lemma  [ lem - affdef ] , the distortion of the triangles is uniformly bounded . 7 .",
    "this follows from  .    for the rest of section  [ sec - convproof ]",
    ", we may assume that all our rnm triangles and test points lie in a compact set @xmath138 not containing the minimizer , as in lemma  [ l : consequences of hypothesis 1 ] .",
    "in particular , the implied bounds in lemma  [ lem - affdef ] are uniform .      under hypothesis 1",
    ", we now show that the transformed rnm triangles `` flatten out '' in the sense that the height becomes arbitrarily small relative to the width .",
    "the proof is again a proof by contradiction , showing that , unless the triangles flatten out , there must be a sequence of consecutive reflections in which the value of @xmath12 at the reflection point is eventually less than @xmath195 , contradicting lemma  [ l : consequences of hypothesis 1 ] .",
    "[ lem - rattozero ] assume hypothesis  1",
    ". then @xmath201 .",
    "assume that the result of the lemma does not hold .",
    "in other words , within the rest of this proof , the following hypothesis is assumed :    [ hyp2 ] there exists @xmath202 such that for arbitrarily large @xmath60 we have @xmath203 .",
    "we may assume also that @xmath194 is a limit point of the triangles @xmath136 for which @xmath203 .",
    "given @xmath204 , we define a _ downward - pointing sector _ of points @xmath205 satisfying @xmath206 , and a _ truncated sector _ of points in the downward sector that also satisfy @xmath207 : see figure  [ fig - sectors ] .",
    "= 3 in = 1.5 in @xmath208    we now show that there exists @xmath204 ( depending on @xmath12 and @xmath209 ) such that , for any sufficiently advanced iteration @xmath210 for which @xmath211 ,    1 .",
    "[ i : initial triangle ] @xmath212 is contained in the truncated sector .",
    "[ i : subsequent triangles ] if @xmath213 is _ any _ rnm triangle in the coordinates @xmath205 of @xmath214 such that @xmath213 is contained in the truncated sector and has ( transformed ) width @xmath215 and height @xmath216 satisfying @xmath217 , then 1 .",
    "[ i : it reflects ] one rnm iteration reflects @xmath213 to a new triangle @xmath218 .",
    "( and @xmath218 has the same width and height as @xmath213 , by lemma  [ lem - refeffects ] . )",
    "[ i : centroid drops ] the @xmath142-coordinate of the centroid of @xmath218 is at least @xmath219 below that of @xmath213 .",
    "[ i : stays in sector ] @xmath218 is contained in the downward - pointing sector .",
    "[ i : function value ] if @xmath218 is not contained in the truncated sector , then the function value at the new vertex is less than @xmath195 .",
    "starting from  , applying   repeatedly shows that the triangle in the @xmath205 coordinates reflects downward until it exits the truncated sector through the bottom , at which point the function value at the exiting vertex is less than @xmath195 , which contradicts lemma  [ l : consequences of hypothesis 1 ] .",
    "thus it remains to prove and  .",
    "_ proof of  .",
    "_    by definition of @xmath214 , the point @xmath5 is a vertex of @xmath212 . for",
    "any given @xmath204 , if @xmath210 is sufficiently large , then lemma  [ l : consequences of hypothesis 1 ] shows that the diameter of @xmath212 is less than the distance from @xmath5 to the boundary of the truncated sector , so @xmath212 is entirely contained in the truncated sector .",
    "_ proof of  .",
    "_    suppose that @xmath213 is contained in the truncated sector and satisfies @xmath220 .",
    "its vertices @xmath221 are the transforms of vertices @xmath222 of some @xmath137 .",
    "we will use the notation @xmath223 for any subscript @xmath224 , and use similar abbreviations for other functions and coordinates .",
    "we show first that the difference in @xmath12 values at any two vertices @xmath222 and @xmath225 is within @xmath226 of the differences of their @xmath142-coordinates . using  , we find that @xmath227 the quantity @xmath228 is bounded by @xmath229 . if @xmath230 , then @xmath231 for any point in the truncated sector . by lemma  ,",
    "if @xmath210 is large enough , then @xmath232 .",
    "it follows that @xmath233 so @xmath234 . on the other hand",
    ", @xmath235 is the line integral of @xmath236 over a path of length at most @xmath237 .",
    "since @xmath238 and @xmath239 are @xmath240 , the derivatives can be made arbitrarily small on the truncated sector by choosing @xmath241 small enough , and we may assume that @xmath242",
    ". now yields @xmath243    a.   let @xmath244 be the vertices of @xmath137 ordered so that @xmath245 .",
    "let @xmath246 be the same vertices ordered so that @xmath247 .",
    "recall that the reflection point @xmath248 is accepted only if @xmath249 .",
    "equation   implies that @xmath250 , @xmath251 , @xmath252 are within @xmath226 of @xmath253 , @xmath254 , @xmath255 , respectively .",
    "hence the difference @xmath256 is within @xmath257 of @xmath258 .",
    "applying to the reflected triangle shows that @xmath259 , and the reflection point is accepted .",
    "b.   the reflection decreases the @xmath142 coordinate of the reflected vertex by @xmath260 which is within @xmath261 of @xmath262 consequently , @xmath263 , and the centroid drops by at least @xmath219 . c.",
    "furthermore , @xmath264 differs from @xmath265 by no more than @xmath266 , i.e. , @xmath267 .",
    "since @xmath268 lies in the truncated sector and @xmath269 , it follows that @xmath270 thus , using the local coordinate frame @xmath214 , the reflection point @xmath271 lies in the downward - pointing sector , and also lies in the truncated sector as long as @xmath272 .",
    "d.   let @xmath72 denote the base point of @xmath214 , so @xmath273 .",
    "for @xmath274 on the bottom edge of the truncated sector , we have @xmath275 and @xmath276 as @xmath277 ( similar triangles ) .",
    "relation   then implies @xmath278 fixing @xmath241 to be small enough that @xmath279 everywhere on the bottom edge , we can also fix a neighborhood @xmath280 of the bottom edge and a neighborhood @xmath281 of @xmath273 such that @xmath282 holds whenever @xmath283 and @xmath284 .",
    "+ if @xmath218 is not in the truncated sector , its new vertex @xmath285 is within @xmath286 of the bottom edge .",
    "if @xmath210 is sufficiently large to make @xmath286 small enough , it follows that @xmath287 .",
    "+ by choice of @xmath194 ( defined immediately following hypothesis  2 ) , @xmath210 can be taken large enough that @xmath194 is arbitrarily close to @xmath72 in _ untransformed _ coordinates . by lemma  [ lem - affdef ] ,",
    "the matrix defining the local coordinate transformation is bounded and nonsingular .",
    "hence we can make @xmath288 arbitrarily close to @xmath5 in transformed coordinates , and in particular we can guarantee that @xmath288 lies in @xmath281 .",
    "+ thus @xmath289 .",
    "[ r : width greater than height ] an important consequence of lemma  [ lem - rattozero ] is that @xmath290 for @xmath136 measured in a coordinate frame associated to any one of its vertices , so that lemma  [ lem - closebase ] can be applied with @xmath291 .      we now show that a sequence of valid reflections , starting from a sufficiently advanced iteration , does not move the triangle far .",
    "this result limits the possible change in flatness caused by moving the base point of the local coordinate system from the first to last triangle in the series of reflections .",
    "[ lem - must - contract ] assume hypothesis  1 . given @xmath292 ,",
    "the following is true for any sufficiently large @xmath210 and any @xmath293 : if all steps taken by the rnm algorithm from @xmath294 to @xmath136 are reflections , then the distance between the transformed centroids of @xmath294 and @xmath136 is less than @xmath295 ( where we use a coordinate frame whose base point is a vertex of @xmath294 ) .",
    "we work in the coordinates @xmath205 of @xmath214 .",
    "it suffices to show that for sufficiently small positive @xmath296 , if @xmath210 is sufficiently large and @xmath213 is a later rnm triangle with centroid in the box @xmath297 , then the next move does not reflect @xmath213 so that its centroid exits the box .",
    "more precisely , for suitable @xmath241 and @xmath210 , the idea is to prove :    1 .",
    "[ i : top of box ] the centroid can not escape out the top of the box ( i.e. , the @xmath142-coodinate can not increase beyond @xmath241 ) because the function value of the reflection point would exceed the function values of @xmath294 ( i.e. , the function values near the center of the box ) .",
    "[ i : bottom of box ] the centroid can not escape out the bottom because the function value there would be less than the limiting value @xmath195 .",
    "[ i : sides of box ] the centroid can not escape out either side , because the triangle @xmath213 will be flat enough that the function values there are controlled mainly by the @xmath140-coordinates , which force the triangle to reflect inward towards the line @xmath298 .",
    "the conditions on @xmath241 and @xmath210 will be specified in the course of the proof .",
    "_ proof of  .",
    "_    we copy the argument used in proving ( iv ) of lemma  [ lem - rattozero ] .",
    "let @xmath72 be the base point used to define @xmath214 .",
    "for @xmath68 along the top edge of the box , by definition @xmath299 .",
    "thus the same argument that proved shows that @xmath300 and that if @xmath241 is sufficiently small , then there are neighborhoods @xmath280 of the top edge and @xmath281 of @xmath5 such that @xmath301 holds whenever @xmath283 and @xmath284 . if @xmath210 is sufficiently large , and @xmath213 is the later triangle whose centroid is about to exit the box through the top , then by lemma  , @xmath212 and @xmath213 are small enough that @xmath302 and @xmath303 , so the function values at vertices of @xmath137 are greater than those for @xmath294 , which is impossible since function values at vertices of successive rnm triangles are non - increasing .    _ proof of  . _",
    "this case is even closer to the proof of ( iv ) in lemma  [ lem - rattozero ] .",
    "that argument shows that if @xmath241 is sufficiently small and @xmath210 is sufficiently large , then the function values at the vertices of a triangle @xmath137 whose transformed centroid is about to exit through the bottom are strictly less than the value @xmath199 ( which is made arbitrarily close to @xmath304 by taking @xmath210 large ) .",
    "this contradicts lemma  [ l : consequences of hypothesis 1 ] .",
    "_ proof of  . _    by symmetry , suppose that @xmath213 reflects so that its centroid exits the box through the _",
    "right _ side . by lemma  [ l :",
    "consequences of hypothesis 1 ] and lemma  [ lem - rattozero ] , we may take @xmath210 large enough that @xmath305 the width @xmath215 and height @xmath216 of @xmath213 are the same as that of @xmath212 .",
    "so all vertices of @xmath213 satisfy @xmath306 and @xmath307 .",
    "let @xmath308 and @xmath309 be two such vertices .",
    "we claim that if @xmath310 , then @xmath311 . by  ,",
    "@xmath312    now we can mimic part of the proof of   in lemma  [ lem - rattozero ] , but in the horizontal rather than the vertical direction . let @xmath313 be the @xmath140-coordinates of the vertices ordered by increasing function value , and let @xmath314 be the same @xmath140-coordinates in increasing order .",
    "the previous paragraph shows that @xmath313 are within @xmath315 of @xmath314 , respectively .",
    "the reflection decreases the @xmath140 coordinate of the reflected vertex by @xmath316 which is within @xmath317 of @xmath318 so the @xmath140 coordinate of the centroid decreases instead of increasing beyond @xmath241 as hypothesized .      assuming hypothesis  1 , we next show that , whenever a contraction step is taken at a sufficiently advanced iteration @xmath60 , we have @xmath319 .",
    "we stress the assumption that the base of the local coordinate frame at iteration @xmath60 lies inside @xmath136 .",
    "[ lem - smallheight ] assume hypothesis  1 .",
    "if @xmath60 is sufficiently large and a contraction step is taken at iteration @xmath60 ( meaning that the reflection point was not accepted ) , then the transformed height @xmath216 and width @xmath215 of @xmath136 in a coordinate frame with base point inside @xmath136 must satisfy @xmath320 .    given a base point of the local coordinate frame in @xmath136 , lemma  [ lem - affdef ] shows that the difference in values of @xmath12 at any two points @xmath68 and @xmath321 is @xmath322    for @xmath323 , let @xmath222 be the @xmath324 vertex of @xmath136 , and let @xmath325 be its transform in the local coordinate frame .",
    "we assume throughout the proof that @xmath326 is the worst vertex .",
    "let @xmath327 be the reflect point , and let @xmath285 be its transform .",
    "the origin of the coordinate frame is inside @xmath136 , so @xmath328 for @xmath329 .",
    "the rnm triangles are flattening out ( lemma  [ lem - rattozero ] ) , and the flatness does not change very much when measured using the coordinate frame with a nearby base point ( lemma  [ lem - closebase ] ) . hence ,",
    "if @xmath60 is large enough , @xmath330 , so @xmath331 for @xmath329 . since @xmath326 is the worst vertex , @xmath332 . substituting and rearranging yields @xmath333 because @xmath328 and @xmath334 , we obtain @xmath335 , so the inequality   implies @xmath336    next we use the definition of the reflection point to obtain bounds in the other direction .",
    "a contraction occurs only when the reflection point is not accepted ( see step  3 of algorithm rnm in section  [ sec - nmalgs ] ) , which implies that @xmath337",
    ". substituting and rearranging yields @xmath338 by definition of @xmath271 , we have @xmath339 . substituting into the left - hand side of yields",
    "@xmath340 we have @xmath341 and @xmath342 , so @xmath343    if @xmath60 is sufficiently large , we know from lemmas  [ lem - diamtozero ] and [ lem - affdef ] that , in the smallest box containing a transformed advanced rnm triangle and its reflection point , @xmath344 and @xmath345 . consequently , @xmath346 substituting the equations   into and  , respectively , we obtain @xmath347 these imply @xmath348 and @xmath349 , so @xmath350 .",
    "our numbering of @xmath351 and @xmath352 was arbitrary , so @xmath353 too .",
    "these two inequalities imply @xmath320 .",
    "the lemma just proved applies to an rnm triangle not at an arbitrary iteration , but only at a sufficiently advanced iteration @xmath60 . even for large @xmath60",
    ", the condition @xmath354 is necessary but not sufficient to characterize an rnm triangle for which a contraction occurs .",
    "figures  [ fig - refheight ] and [ fig - conheight ] illustrate two cases for the function @xmath355 .",
    "the worst vertex is at the origin in each figure . in figure  [ fig - refheight ]",
    ", we have @xmath356 and @xmath357 , so @xmath358 ; as lemma  [ lem - smallheight ] would predict at an advanced iteration , the triangle reflects instead of contracting . in figure  [ fig - conheight ] , by contrast , @xmath359 and @xmath357 , so @xmath360 and an outside contraction is taken .",
    "the vertical scale in each figure is greatly compressed compared to the horizontal , and the vertical scale in figure  [ fig - refheight ] differs from that in figure  [ fig - conheight ] by two orders of magnitude .",
    "are shown along with an rnm triangle with @xmath361 .",
    "the reflection is accepted.,title=\"fig:\",width=480,height=192 ]    , are shown along with an rnm triangle with @xmath362 .",
    "the reflection step is not accepted , and an outside contraction is performed .",
    "note the difference , by four orders of magnitude , between the horizontal and vertical scales.,title=\"fig:\",width=480,height=192 ]    [ lem - smalldelta ] under the assumptions of lemma  [ lem - smallheight ] , if @xmath60 is sufficiently large and a contraction step is taken at iteration @xmath60 , then @xmath64 , where @xmath363 is the flatness of @xmath190 as in definition  [ def - flatness ] .",
    "let @xmath215 , @xmath216 , @xmath364 be the width , height , and area of @xmath136 with respect to the coordinate frame associated by lemma  [ lem - affdef ] to a vertex of @xmath136 . if @xmath60 is sufficiently large , then lemma  [ lem - smallheight ] implies @xmath354 .",
    "hence @xmath365      the final piece of the proof of theorem  [ thm - rnmconv ] will show that , for sufficiently advanced iterations , the flatness of the rnm triangles must increase by a factor of at least @xmath366 _ within a specified number of iterations following a contraction_. to obtain this result , we begin by characterizing the structure of rnm vertices at sufficiently advanced iterations following a contraction , and then defining a related but simpler triangle .",
    "assume that ( i ) there is a limit point @xmath194 of the rnm triangles that is not the minimizer of @xmath12 , ( ii ) @xmath210 is sufficiently large , and ( iii ) iteration @xmath210 is a contraction .",
    "for the rnm triangle @xmath294 , let @xmath367 denote the coordinate frame whose base point is the vertex of @xmath294 with the worst value of @xmath12 : @xmath368 this first coordinate frame is used to identify @xmath369 and @xmath370 , the transformed vertices of @xmath294 with leftmost and rightmost @xmath140 coordinates .    a second coordinate frame , @xmath371 , is defined next whose base point ( measured in frame @xmath367 ) is the midpoint of @xmath372 $ ] : @xmath373 unless otherwise specified , the coordinate frame @xmath371 is used throughout the remainder of this proof .",
    "the base points of @xmath367 and @xmath371 will be arbitrarily close if @xmath210 is sufficiently large .",
    "we assume that @xmath210 is sufficiently large so that the rnm triangles have become tiny in diameter and flattened out ( lemma  [ lem - rattozero ] ) .",
    "the reason for defining @xmath371 is that we can choose a small @xmath374 such that the transformed three vertices of @xmath294 , measured in coordinate frame @xmath371 , may be expressed as @xmath375 where vertex @xmath376 corresponds to @xmath377 and vertex @xmath378 to @xmath379 .    without loss of generality the value of @xmath380 in",
    "can be taken as nonnegative .",
    "the vertices @xmath376 and @xmath378 were leftmost and rightmost when measured in @xmath367 ; by lemma  [ lem - closebase ] , the @xmath380 in can not be too much larger than @xmath381 .",
    "we assume that @xmath210 is large enough so that @xmath382 .",
    "because of the form of the vertices in and the bounds on @xmath380 , the transformed width @xmath215 of @xmath294 ( measured using coordinate frame @xmath371 ) can be no larger than @xmath383 .",
    "iteration @xmath210 is , by assumption , a contraction , so it follows from lemma  [ lem - smallheight ] that the transformed height of @xmath294 satisfies @xmath320 , and hence @xmath384 . since @xmath216 is equal to the larger of @xmath385 or @xmath386 , it follows that @xmath387 and @xmath388 in  .",
    "the next step is to make a rescaling of coordinates to define a triangle @xmath398 that is related to @xmath399 by the diagonal affine transformation @xmath400 .",
    "let @xmath401 be a point in @xmath402 measured in @xmath371 .",
    "then @xmath403 where @xmath404 and @xmath405 satisfy the bounds  .",
    "the flatness of @xmath406 , defined as @xmath407 , is equal to the flatness of @xmath395 measured in coordinate frame @xmath371 .",
    "assume now that @xmath408 ; the reason for this limit on @xmath409 will emerge later in proposition  [ prop-14steps ] . for vertex @xmath224 of @xmath410 , equation   shows that the coefficients in its transformed coordinates satisfy @xmath411 and @xmath412 . by , , and , once @xmath210 is large enough to make @xmath413 sufficiently small , the difference in @xmath12 values between vertices @xmath224 and @xmath414 is @xmath415     + \\remain(\\eta\\mu_i,\\eta^2\\lambda_i ) - \\remain(\\eta\\mu_j,\\eta^2\\lambda_j^2)\\\\ \\label{eqn - funsimplediff }     & = & \\eta^2 [ ( \\half\\lambda_i^2 + \\mu_i ) - ( \\half\\lambda_j^2 + \\mu_j ) ]     + o(\\eta^2).\\end{aligned}\\ ] ]    let @xmath416 denote the simple quadratic function @xmath417 then shows that , if @xmath210 is large enough , the following relationships hold between @xmath12 at vertices of @xmath410 and @xmath416 at vertices of @xmath398 : @xmath418 where @xmath419 is not magical , but simply a number small enough so our subsequent results follow .    for illustration ,",
    "let @xmath420 . based on  ,",
    "the vertices of @xmath421 are given by @xmath422 and suppose that @xmath376 is the worst transformed vertex of @xmath294 , i.e.  that @xmath423 application of   gives @xmath424 and @xmath425 , i.e. @xmath426    in this way , inequalities characterizing the transformed vertices of @xmath395 when applying the rnm algorithm with function @xmath12 can be derived in terms of vertices of the simpler triangle @xmath398 when applying the rnm algorithm to the function @xmath427 , except that _ both possible outcomes of a comparison must be allowed _ if the two values of @xmath416 are within @xmath419 .",
    "the importance of   is that , for @xmath408 , a possible sequence of rnm moves specifying the move type and worst vertex leads to a set of algebraic inequalities in @xmath380 , @xmath428 , and @xmath429 .      in the remainder of this section",
    ", we consider the transformed width , area , and flatness of a sequence of rnm triangles , @xmath294 ,  , @xmath410 , defined using a coordinate frame whose base point is in @xmath294 .",
    "accordingly , notation is needed that separately identifies the rnm triangle being measured and the relevant coordinate frame .",
    "the value @xmath430 will denote the flatness of rnm triangle @xmath431 measured in @xmath367 of , and @xmath432 will denote the flatness of @xmath136 measured in @xmath371 , with similar notation for @xmath215 and @xmath364 .",
    "since the base points of coordinate frames @xmath367 and @xmath371 are in @xmath294 , an essential point is that , when @xmath433 , the triangle containing the base point of the coordinate frame is different from the triangle being measured .",
    "the result in the following proposition was found using symbolic computation software .",
    "[ prop-14steps ] assume hypothesis  1 .",
    "if @xmath210 is sufficiently large and a contraction step is taken at iteration @xmath210 , then there exists @xmath409 with @xmath434 such that @xmath435 .    before giving the proof ,",
    "we sketch the basic idea .",
    "as just described in section  [ sec - rnminequalities ] , we are in a situation where two properties apply : ( 1 ) the transformed objective function at the scaled point @xmath436 can be very well approximated by the quadratic function @xmath437 in  , and ( 2 ) the rnm move sequences of interest can be analyzed by beginning with an initial simplified ( scaled ) triangle whose vertices ( see  ) involve bounded scalars @xmath438 that lie in a compact set . under these conditions , the proof explains how algebraic constraints can be derived that characterize geometrically valid sequences of rnm moves .",
    "further algebraic constraints involving @xmath380 can also be defined that must be satisfied when the flatness increases by a factor of no more than @xmath66 .    in principle , one could establish the result of the proposition by numerically checking flatness for all geometrically valid rnm move sequences beginning with the simplified triangle , but this approach is complicated , structureless , and too time - consuming for numerical calculation .",
    "instead , we used mathematica  7.0 to construct symbolic inequalities representing rnm move sequences such that    * @xmath380 , @xmath428 , and @xmath429 are suitably bounded , * the geometric condition   for a valid rnm move applies , and * the flatness increases by a factor of _ less than or equal to _ @xmath66 .",
    "the flatness is not changed by a reflection step as long as the same coordinate frame is retained . assuming that @xmath210 is sufficiently large and that the move taken during iteration @xmath210 is a contraction , we wish to show that there is an index @xmath409 satisfying @xmath439 such that the flatness @xmath65 of the rnm triangle @xmath410 , _ measured in coordinate frame _",
    "@xmath371 , must be a factor of at least @xmath66 larger than the flatness of @xmath294 , i.e. , that @xmath440    let us prove   directly for @xmath441 when @xmath442 of   is the worst vertex of @xmath421 and an inside contraction occurs . in this case",
    ", the next triangle @xmath443 has vertices @xmath444 where the first vertex @xmath445 has been replaced .",
    "we have two cases :    * if @xmath446 , then @xmath447 and @xmath448 , which implies that @xmath449 . * if @xmath450 , then @xmath451 and @xmath452 , so that @xmath453 and @xmath454 .    for all @xmath380 satisfying @xmath382",
    ", it follows that @xmath449 , and hence that @xmath455 the area of @xmath443 is half the area of @xmath421 . hence the ratio of the flatnesses of @xmath443 and @xmath421 satisfies @xmath456 the same argument applies when @xmath443 is the result of an _ outside _ contraction in which vertex @xmath442 is the worst .",
    "but when the sequence of moves begins with a contraction in which vertex @xmath457 or @xmath458 is worst , we must break into further cases , and the analysis becomes too complicated to do by hand . to examine such sequences of rnm moves",
    ", we use a mathematica program that generates inequalities involving vertices of @xmath406 and the function @xmath416 of  , as described in section  [ sec - rnminequalities ] .",
    "any sequence of rnm moves ( where a move is specified by the worst vertex and the type of move ) starting with triangle @xmath294 gives rise to a set of algebraic inequalities in @xmath380 , @xmath428 , and @xmath429 .",
    "the @xmath324 of these latter inequalities has one of the forms @xmath459 or @xmath460 , where @xmath461 is a quadratic polynomial in @xmath380 with rational coefficients , and @xmath462 , @xmath463 , and @xmath464 are rational constants .",
    "the next step is to determine whether there are acceptable values of @xmath380 , @xmath428 , and @xmath429 for which these inequalities are satisfied .",
    "to do so , we begin by treating @xmath380 as constant ( temporarily ) and considering the feasibility of a system of _ linear _ inequalities in @xmath428 and @xmath429 , namely the system @xmath465 , where @xmath466 , the @xmath324 row of @xmath467 is @xmath468 , and @xmath469 . a variant of farkas lemma @xcite states that the system of linear inequalities @xmath465 is feasible if and only if @xmath470 for every vector @xmath471 satisfying @xmath472 and @xmath473 . if the only nonnegative vector @xmath471 satisfying @xmath473 is @xmath474 , then @xmath465 is feasible for any @xmath475 .",
    "the existence ( or not ) of a nonnegative nonzero @xmath471 in the null space of @xmath476 can be determined symbolically by noting that the system @xmath465 is feasible if and only if it is solvable for every subset of three rows of @xmath467 .",
    "let @xmath477 denote the @xmath478 matrix consisting of three specified rows of @xmath467 , with a similar meaning for @xmath479 . to determine the feasibility of @xmath480",
    ", we first find a vector @xmath481 such that @xmath482 .    if @xmath477 has rank @xmath58 , then @xmath481 is unique ( up to a scale factor ) and we can write @xmath483 ( or a column permutation ) so that the leftmost @xmath484 submatrix @xmath176 is nonsingular . then , with @xmath485 where the components of @xmath486 and @xmath487 are rational numbers . if ( with appropriate scaling ) @xmath488 with at least one positive component , then @xmath489 is solvable if and only if @xmath490 . if the components of @xmath481 do not have the same sign",
    ", @xmath489 is solvable for any @xmath479 .",
    "if @xmath491 has rank one , its three rows must be scalar multiples of the same vector , i.e. , the @xmath324 row is @xmath492 , and the null vectors of @xmath483 are linear combinations of @xmath493 , @xmath494 , and @xmath495 .",
    "since the components of @xmath475 are quadratic polynomials in @xmath380 and the components of each @xmath481 are rational numbers , the conditions for feasibility of @xmath465 ( e.g. , the conjunction of conditions that @xmath496 for each set of three rows of @xmath467 ) can be expressed as a boolean combination of quadratic inequalities in @xmath380 with rational coefficients that , for a given value of @xmath380 , evaluates to `` true '' if and only if there exist @xmath428 and @xmath429 such that these inequalities are satisfied .    to verify the result of the proposition for a given sequence of @xmath409",
    "rnm moves applied to @xmath421 , we need to compute the flatness of @xmath398 , which is , by construction , equal to the flatness of @xmath395 measured in coordinate frame @xmath371 ; see  .",
    "we can directly calculate the ratio of the area of @xmath406 to the area of @xmath421 by using the number of contractions in the move sequence , since each contraction multiplies the area by @xmath497 .",
    "the width of @xmath398 can be obtained using inequalities and linear polynomials in @xmath380 , since the width is determined by the largest and smallest @xmath140 coordinates , which are linear polynomials in @xmath380 .",
    "consequently , the condition that the flatness for each triangle in the sequence is less than @xmath66 times the original flatness can be expressed as a boolean combination of ( at most cubic ) polynomial inequalities in @xmath380 , where @xmath380 is constrained to satisfy @xmath382 .    to determine whether there are allowable values of @xmath380 for which a specified sequence of rnm moves is possible , observe that a boolean combination of polynomial inequalities in @xmath380 will evaluate to `` true '' for @xmath380 in a certain union of intervals that can be computed as follows .",
    "we first find the values of @xmath380 that are solutions of the polynomial _ equations _ obtained by replacing any inequalities by equalities .",
    "then , between each adjacent pair of solutions , we choose a test value ( e.g. , the midpoint ) and check whether the associated inequality evaluates to `` true '' on that interval .    the computation time can be cut in half by considering only sequences that begin with an _ inside _ contraction , for the following reason . the outside contraction point for an original triangle @xmath137 with vertices @xmath351 , @xmath352 , and @xmath326 is equal to the inside contraction point for a triangle , denoted by @xmath389 , whose worst vertex @xmath326 is the reflection point @xmath271 of @xmath137 . with exact computation ,",
    "the conditions for an outside contraction of @xmath137 differ from those for an inside contraction of @xmath389 if equality holds in some of the comparisons .",
    "in particular , if @xmath498 , then @xmath137 will undergo an outside contraction and @xmath389 will undergo an inside contraction ; but if @xmath499 , then both @xmath389 and @xmath137 will undergo inside contractions . since our inequalities allow for a small error in comparisons , this difference will not change the result , and we may assume that the rnm move at @xmath294 is an inside contraction .    finally , the definition of the rnm algorithm imposes further constraints on valid move patterns .",
    "for example , if a reflection occurs , the reflection point must be strictly better than the second - worst vertex , so this reflection point can not be the worst point in the new triangle .",
    "such sequences ( impossible in the rnm algorithm ) would be permitted by the small error allowed in the inequalities , so they are explicitly disallowed in the mathematica code .",
    "putting all this together , a program can test each sequence of valid operations that begins with an inside contraction to determine whether there exists an initial triangle for which ratio of the flatnesses , measured in @xmath371 , is less than @xmath66 .",
    "the results of this computation show that , within no more than 14 rnm moves following a contraction , a triangle is always reached for which the ratio of the flatnesses , measured in the second coordinate frame @xmath371 , is at least @xmath66 .",
    "we stress that the count of 14 moves includes a mixture of reflections and both forms of contraction .",
    "details of these move sequences can be found in the appendix .",
    "there we list the @xmath380-values and the associated sequences of 14 or fewer rnm moves for which the ratio of the flatnesses remains less than @xmath66 .",
    "proposition  [ prop-14steps ] used @xmath371 , but its analogue for @xmath367 follows almost immediately with a slightly smaller constant in place of @xmath66 .    [ lem-14steps ] under the assumptions of proposition  [ prop-14steps ] , there exists @xmath409 with @xmath434 such that @xmath500    the base point of @xmath367 is the worst point of @xmath294 ; the base point of @xmath371 is the midpoint of the edge of @xmath294 joining the two vertices whose @xmath140 coordinates are leftmost and rightmost when measured in @xmath367 . by choosing @xmath210 to be large enough , the two base points can be made arbitrarily close .",
    "lemma  [ lem - closebase ] with @xmath501 shows that for large enough @xmath210 , the flatnesses of triangles @xmath294 and @xmath395 measured in coordinate frames @xmath367 and @xmath371 satisfy @xmath502 now , for @xmath409 as in proposition  [ prop-14steps ] , @xmath503      the main result of this paper is the following theorem ( called theorem  [ thm - rnmconv ] in section  [ sec - introduction ] ) .",
    "[ thm - converges ] if the rnm algorithm is applied to a function @xmath15 , starting from any nondegenerate triangle , then the algorithm converges to the unique minimizer of @xmath12 .    in this proof",
    ", @xmath504 denotes the flatness of rnm triangle @xmath505 measured in a coordinate frame @xmath506 whose base point is the _ worst vertex of triangle @xmath507_.    given a small positive number @xmath508 , let @xmath210 be sufficiently large ( we will specify how small and how large as we go along ) . as mentioned in section  [ sec - bigpic ] , the rnm triangle must contract infinitely often , so we may increase @xmath210 to assume that @xmath294 contracts .",
    "lemma  [ lem-14steps ] shows that the flatness measured in @xmath214 increases by a factor of @xmath366 in at most @xmath67 rnm moves ; i.e. , there exists @xmath509 with @xmath510 such that @xmath511 we now switch coordinate frames on the left hand side : lemma  [ lem - closebase ] and remark  [ r : width greater than height ] show that the flatness of @xmath512 in @xmath513 is close to its flatness in @xmath214 .",
    "in particular , if @xmath210 is sufficiently large , then @xmath514 let @xmath515 be the first iteration after ( or equal to ) @xmath509 such that @xmath516 contracts .",
    "lemma  [ lem - must - contract ] shows that if @xmath210 is sufficiently large , then from iteration @xmath509 to the beginning of iteration @xmath517 , the distance travelled by the centroid , measured in @xmath513 , is less than @xmath295 . during those iterations",
    ", the rnm triangle retains its shape and hence its flatness , as measured in @xmath513 ; that is , @xmath518 if @xmath508 was small enough , lemma  [ lem - closebase ] and remark  [ r : width greater than height ] again imply @xmath519 combining , , , and   yields @xmath520    if @xmath210 is sufficiently large , then repeating the process that led from @xmath210 to @xmath517 defines @xmath521 such that @xmath522 for all @xmath1 : to know that the same lower bound on @xmath210 works at every stage , we use that in lemma  [ lem - closebase ] the number @xmath523 is independent of @xmath524 , @xmath525 , and @xmath137 .",
    "now , if @xmath1 is sufficiently large , then @xmath526 but @xmath527 contracts , so this contradicts lemma  [ lem - smalldelta ] .",
    "hence the assumption made at the beginning of our long chain of results , hypothesis  1 , must be wrong .",
    "in other words , the rnm algorithm _ does _ converge to the minimizer of @xmath12 .",
    "for general interest , we briefly revisit the smoothest mckinnon counterexample  , which consists of a twice - continuously differentiable function @xmath0 and a specific starting triangle for which the rnm algorithm converges to a nonminimizing point ( with nonzero gradient ) .",
    "the hessian matrix is positive semidefinite and singular at the limit point , but positive definite everywhere else .",
    "thus all the assumptions in our convergence theorem are satisfied except for positive - definiteness of the hessian , which fails at one point .",
    "hypothesis [ hyp1 ] is valid for this example , and it is enlightening to examine where the proof by contradiction fails .",
    "the mckinnon iterates do satisfy several of the intermediate lemmas in our proof : the rnm triangles not only flatten out ( lemma  [ lem - rattozero ] ) , but they do so more rapidly than the rate proved in lemma  [ lem - smallheight ] . , the mckinnon triangles satisfy @xmath528 for @xmath529 , where @xmath530 .",
    "] however , an essential reduction step , lemma  [ lem - closebase ] , fails to hold for the mckinnon example , as discussed below .",
    "positive - definiteness of the hessian plays a crucial role in our proof by contradiction because it allows us to uniformly approximate the objective function close to the limit point @xmath194 by its degree-@xmath58 taylor polynomial .",
    "applying a well - defined change of variables , the function @xmath531 for a simple triangle can then be taken as a surrogate , and we can essentially reduce the problem to studying the rnm algorithm for the objective function @xmath531 near the non - optimal point @xmath5 . in the mckinnon example  , however , the objective function near the limit point @xmath5 can not be ( uniformly ) well approximated by @xmath531 , even after a change of variable . although the hessian of the mckinnon function @xmath0 remains positive definite at base points in @xmath136 as @xmath532 , it becomes increasingly close to singular , in such a way that ever - smaller changes in the base point will eventually not satisfy the closeness conditions of lemma  [ lem - closebase ] .",
    "in fact , the actual shape of the mckinnon objective function allows a sequence of rnm moves that are forbidden for @xmath531 near the non - optimal point @xmath533 namely an infinite sequence of inside contractions with the best vertex never replaced . in dynamical terms , the mckinnon objective function allows symbolic dynamics forbidden for @xmath531 near @xmath5 , and these symbolic dynamics evade the contradiction in our argument .      most of this paper has been devoted to analysis of situations that we subsequently show can not occur ; this is the nature of arguments by contradiction .",
    "for contrast , we present one example where the rnm algorithm will converge , as we have proved , on the strictly convex quadratic function @xmath534 whose minimizer is @xmath535 .",
    "using starting vertices @xmath536 , @xmath537 , and @xmath538 , after 20 rnm iterations the best vertex is @xmath539 , and the rnm triangles are obviously converging to the solution .",
    "the first nine iterations are depicted in figure  [ fig - rnmquad ] .",
    "this paper began by noting that very little is known about the theoretical properties of the original nelder ",
    "mead method , despite 45 years of practice .",
    "it is fair to say that proving convergence for an rnm algorithm in two dimensions on a restricted class of functions adds only a little more to this knowledge .",
    "this contribution seems of interest , however , because of the lack of other results despite determined efforts , and the introduction of dynamical systems methods to the analysis .",
    "our analysis applies only to a simplified (  small step \" ) version of the original nelder ",
    "mead method which excludes expansion steps .",
    "we have observed that in thousands of computational experiments with functions defined in @xmath21 ( @xmath540 ) in which the nelder  mead method converges to a minimizer , expansion steps are almost never taken in the neighborhood of the optimum .",
    "expansion steps are typically taken early on , forming part of the `` adaptation to the local contours '' that constituted the motivation for nelder and mead when they originally conceived the algorithm @xcite .",
    "thus the rnm algorithm appears to represent , to a large extent , the behavior of the original method near the solution . in this direction",
    ", it would be valuable if these empirical observations could be rigorously justified under a well - defined set of conditions .",
    "the observed good performance of the nelder ",
    "mead method on many real - world problems remains a puzzle .",
    "this paper applies dynamical systems methods to the analysis of the rnm algorithm .",
    "the use of such ideas in the proofs , particularly that of a ( rescaled ) local coordinate frame in section  [ sec - rnminequalities ] , may also be useful in other contexts where it is valuable to connect the geometry of a simplex with the contours of the objective function .",
    "the evolving geometric figures of the algorithm remain one of the intuitive appeals of the original nelder  mead method , leading to the nickname of `` amoeba method '' @xcite .",
    "there may well be other applications , but the latest direct search methods tend to exhibit a less clear connection with geometry .",
    "finally , our analysis for the rnm algorithm relies in part on the fact that the volume of the rnm simplex is non - increasing at every iteration , thereby avoiding the difficulties associated with expansion steps .",
    "consequently , mckinnon s question remains open : does the original nelder  mead algorithm , including expansion steps , always converge for the function @xmath541 , or more generally for a class of functions like those treated in theorem  [ thm - converges ] ?",
    "we hope that further development of the dynamical systems approach could lead to progress on this question .",
    "this appendix provides details of the symbolic computation performed to prove proposition  [ prop-14steps ] .",
    "we regard the coding of moves as a form of _ symbolic dynamics _ for the rnm iteration .",
    "moves are represented as follows : 1 , 2 , and 3 denote reflections with , respectively , vertex @xmath542 , @xmath543 , or @xmath544 of   taken as the worst vertex , i.e.  replaced during the move .",
    "similarly , 4 , 5 , and 6 denote inside contractions , and 7 , 8 , 9 denote outside contractions with worst vertex @xmath545 respectively .      1 .",
    "the variables @xmath548 satisfy the inequality implied by   for each rnm move , 2 .",
    "the flatness after each step is less than or equal to @xmath66 times the original flatness , and 3 .",
    "no reflection undoes an immediately preceding reflection .",
    "because   involves a relaxation of @xmath419 , a sequence characterized as `` possible '' using the first two properties listed above could be impossible for the rnm algorithm _ in exact arithmetic_. this is why the third condition explicitly prohibits sequences in which a reflection undoes the previous move , something that can never happen in the rnm algorithm .    in the proof of proposition  [ prop-14steps ]",
    ", we described a symbolic algorithm for computing all possible sequences beginning with an inside contraction .",
    "the mathematica output below lists all these sequences .",
    ".... { 5 } possible for s in { { 0.999999 , 1.00001 } } { 5 , 6 } possible for s in { { 0.999999 , 1.00001 } } { 6 } possible for s in { { 0.582145 , 1 . } } { 6 , 2 } possible for s in { { 0.582145 , 0.737035 } } { 6 , 2 , 1 } possible for s in { { 0.582145 , 0.695708 } } { 6 , 2 , 1 , 3 } possible for s in { { 0.582145 , 0.654949 } } { 6 , 2 , 1 , 3 , 2 } possible for s in { { 0.582145 , 0.654949 } } { 6 , 2 , 1 , 3 , 6 } possible for s in { { 0.582145 , 0.654949 } } { 6 , 2 , 1 , 3 , 6 , 2 } possible for s in { { 0.616769 , 0.654949 } } { 6 , 2 , 1 , 3 , 6 , 2 , 5 } possible for s in { { 0.616769 , 0.64706 } } { 6 , 2 , 1 , 3 , 6 , 8 } possible for s in { { 0.582145 , 0.64706 } } { 6 , 2 , 1 , 3 , 6 , 8 , 4 } possible for s in { { 0.582145 , 0.623495 } } { 6 , 2 , 1 , 3 , 9 } possible for s in { { 0.582145 , 0.644579 } } { 6 , 2 , 1 , 6 } possible for s in { { 0.582145 , 0.695708 } } { 6 , 2 , 1 , 9 } possible for s in { { 0.582145 , 0.673138 } } { 6 , 2 , 1 , 9 , 2 } possible for s in { { 0.616769 , 0.673138 } } { 6 , 2 , 1 , 9 , 2 , 5 } possible for s in { { 0.616769 , 0.64706 } } { 6 , 2 , 1 , 9 , 8 } possible for s in { { 0.582145 , 0.64706 } } { 6 , 2 , 1 , 9 , 8 , 4 } possible for s in { { 0.582145 , 0.623495 } } { 6 , 2 , 5 } possible for s in { { 0.582145 , 0.737035 } } { 6 , 2 , 5 , 4 } possible for s in { { 0.582145 , 0.695708 } } { 6 , 2 , 5 , 7 } possible for s in { { 0.582145 , 0.681931 } } { 6 , 2 , 5 , 7 , 6 } possible for s in { { 0.582145 , 0.635866 } } { 6 , 2 , 5 , 7 , 9 } possible for s in { { 0.582145 , 0.681931 } } { 6 , 2 , 5 , 7 , 9 , 5 } possible for s in { { 0.582145 , 0.679967 } } { 6 , 2 , 5 , 7 , 9 , 8 } possible for s in { { 0.582145 , 0.663254 } } { 6 , 2 , 5 , 7 , 9 , 8 , 4 } possible for s in { { 0.582145 , 0.646912 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 } possible for s in { { 0.582145 , 0.663254 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 6 } possible for s in { { 0.582145 , 0.663254 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 6 , 5 } possible for s in { { 0.589537 , 0.663254 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 6 , 5 , 1 } possible for s in { { 0.589537 , 0.635373 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 } possible for s in { { 0.582145 , 0.65445 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 5 } possible for s in { { 0.582145 , 0.651784 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 5 , 4 } possible for s in { { 0.582145 , 0.651784 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 5 , 4 , 3 } possible for s in { { 0.582145 , 0.651784 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 8 } possible for s in { { 0.597869 , 0.65445 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 8 , 4 } possible for s in { { 0.597869 , 0.65445 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 } possible for s in { { 0.597869 , 0.65445 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 , 2 } possible for s in { { 0.597869 , 0.654004 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 , 2 , 5 } possible for s in { { 0.64094 , 0.654004 } } { 6 , 2 , 5 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 , 8 } possible for s in { { 0.64094 , 0.65445 } } { 6 , 2 , 8 } possible for s in { { 0.582145 , 0.614711 } } { 6 , 5 } possible for s in { { 0.582145 , 1 . } } { 6 , 8 } possible for s in { { 0.582145 , 0.853944 } } { 6 , 8 , 4 } possible for s in { { 0.582145 , 0.810502 } } { 6 , 8 , 7 } possible for s in { { 0.582145 , 0.853944 } } { 6 , 8 , 7 , 6 } possible for s in { { 0.582145 , 0.853944 } } { 6 , 8 , 7 , 9 } possible for s in { { 0.582145 , 0.818183 } } { 6 , 8 , 7 , 9 , 5 } possible for s in { { 0.582145 , 0.811611 } } { 6 , 8 , 7 , 9 , 8 } possible for s in { { 0.582145 , 0.818183 } } { 6 , 8 , 7 , 9 , 8 , 4 } possible for s in { { 0.582145 , 0.818183 } } { 6 , 8 , 7 , 9 , 8 , 4 , 6 } possible for s in { { 0.763168 , 0.818183 } } { 6 , 8 , 7 , 9 , 8 , 4 , 6 , 2 } possible for s in { { 0.763168 , 0.817831 } } { 6 , 8 , 7 , 9 , 8 , 7 } possible for s in { { 0.582145 , 0.777853 } } { 6 , 8 , 7 , 9 , 8 , 7 , 6 } possible for s in { { 0.582145 , 0.777853 } } { 6 , 8 , 7 , 9 , 8 , 7 , 6 , 5 } possible for s in { { 0.589537 , 0.777853 } } { 6 , 8 , 7 , 9 , 8 , 7 , 6 , 5 , 1 } possible for s in { { 0.589537 , 0.777853 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 } possible for s in { { 0.582145 , 0.751661 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 5 } possible for s in { { 0.582145 , 0.751661 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 5 , 4 } possible for s in { { 0.582145 , 0.751661 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 5 , 4 , 3 } possible for s in { { 0.582145 , 0.751661 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 8 } possible for s in { { 0.597869 , 0.694824 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 8 , 4 } possible for s in { { 0.597869 , 0.694824 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 } possible for s in { { 0.597869 , 0.694824 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 , 2 } possible for s in { { 0.597869 , 0.694824 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 , 2 , 5 } possible for s in { { 0.64094 , 0.663616 } } { 6 , 8 , 7 , 9 , 8 , 7 , 9 , 8 , 4 , 6 , 8 } possible for s in { { 0.64094 , 0.663616 } } ....",
    "all we need from this computation is that there is no possible sequence of @xmath67 steps or more . in other words , following an inside contraction , the flatness will be greater than @xmath66 times the original flatness after no more than @xmath67 steps ( including the initial contraction ) .",
    "the remarks in this section are not needed for the proof , but they may give further insight into the behavior of the rnm algorithm as well as clear up some potential ambiguity about the computer output above .",
    "* that the sequence @xmath549 is not possible ( i.e. , that an inside contraction with @xmath442 as worst vertex immediately increases the flatness by at least a factor of @xmath66 ) was shown already near the beginning of the proof of proposition  [ prop-14steps ] . *",
    "the bound @xmath550 on @xmath551 and @xmath552 need not be fed into the program , because the program automatically calculates stronger inequalities that are necessary for a contraction to occur .",
    "* move sequences that do not appear in the list may still occur in actual runs of the rnm algorithm , but then the flatness must grow by more than a factor of @xmath66 . similarly , a move sequence appearing in the list may occur while running the rnm algorithm even if @xmath380 lies outside the given interval . for example , one can show that there exist triangles with @xmath553 on which the rnm algorithm takes move @xmath554 .",
    "* one can not predict from the list _ which _ step causes the flatness to grow beyond the factor of @xmath66 .",
    "for example , using our definition the sequence @xmath555 is possible ( for a certain range of @xmath380 ) , but the extended sequence @xmath556 is not .",
    "this should not be taken to mean that the last reflection @xmath557 caused the increase in flatness , since reflections do not change the flatness ( measured in the same coordinate frame ) .",
    "rather , there may exist a triangle in the given range that for the objective function @xmath558 will take the sequence of steps @xmath556 . what must be the case , however , is that for any such triangle the initial inside contraction @xmath559 will have already increased the invariant by a factor at least @xmath66 .",
    "* one can not deduce that in every run of the rnm algorithm , every sufficiently advanced sequence of 14 steps involves a contraction .",
    "experiments show that , when omitting any test for flatness , a sequence beginning with @xmath554 can legitimately be followed by a very large number of reflect steps during which the flatness does not change .",
    "thus we truly needed lemma  [ lem - must - contract ] in addition to proposition  [ prop-14steps ] to complete our proof .",
    "* the entire computation took about 11 minutes on an intel xeon 3.0  ghz processor .",
    "a.  p.  gurson ( 2000 ) .",
    "`` simplex search behavior in nonlinear optimization '' , bachelor s honors thesis , computer science department , college of william and mary , williamsburg , virginia .",
    "+ www.cs.wm.edu/@xmath560va/cs495            f.  klein ( 1939 ) .",
    "_ elementary mathematics from an advanced standpoint : geometry _ , dover publications : new york .",
    "( reprint of volume ii of english translation of f. klein , _ elementarmathematik vom hheren standpunkte aus , _ j. springer , berlin 19241928 . )",
    "d.  j.  woods ( 1985 ) .",
    "_ an interactive approach for solving multi - objective optimization problems _ , phd thesis , technical report 85 - 5 , department of computational and applied mathematics , rice university , houston , texas",
    ".    m.  h. wright ( 1996 ) . direct search methods : once scorned , now respectable . in _ numerical analysis 1995 : proceedings of the 1995 dundee biennial conference in numerical analysis _ , d.  f.  griffiths and g.  a.  watson",
    "( eds . ) , 191208 , addison wesley longman , harlow , uk ."
  ],
  "abstract_text": [
    "<S> the nelder  mead algorithm , a longstanding direct search method for unconstrained optimization published in 1965 , is designed to minimize a scalar - valued function @xmath0 of @xmath1 real variables using only function values , without any derivative information . </S>",
    "<S> each nelder  mead iteration is associated with a nondegenerate simplex defined by @xmath2 vertices and their function values ; a typical iteration produces a new simplex by replacing the worst vertex by a new point . despite the method s widespread use , theoretical results have been limited : for strictly convex objective functions of one variable with bounded level sets , the algorithm always converges to the minimizer ; for such functions of two variables , the diameter of the simplex converges to zero , but examples constructed by mckinnon show that the algorithm may converge to a nonminimizing point .    </S>",
    "<S> this paper considers the _ restricted _ nelder  mead algorithm , a variant that does not allow expansion steps . in two dimensions we show that , for any nondegenerate starting simplex and any twice - continuously differentiable function with positive definite hessian and bounded level sets , the algorithm always converges to the minimizer . </S>",
    "<S> the proof is based on treating the method as a discrete dynamical system , and relies on several techniques that are non - standard in convergence proofs for unconstrained optimization .    epsf    plus2pt minus4pt 3 pt plus 3pt plus3pt minus3pt </S>"
  ]
}