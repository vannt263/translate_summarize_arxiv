{
  "article_text": [
    "the relationship between the number of sources and the threshold at which they can be detected is an important tool in astrophysics for describing and investigating the properties of various types of source populations . known as the @xmath2@xmath3  relationship",
    ", the idea is to use the number of sources @xmath4 that can be detected at a given sensitivity level @xmath5 , on the @xmath6@xmath6 scale , to describe the distribution of source fluxes . in simple settings and under restrictive assumptions",
    "a linear relationship between the log - flux and the log - survival function can be derived from first principles .",
    "traditionally , astrophysicists have therefore examined this relationship by characterizing the slope of the log of the empirical survival function as a function of the log - flux of the sources .",
    "one of the first examples of the @xmath2@xmath3 relationship being derived from first principles is in  @xcite .",
    "it is shown that if radio stars are uniformly distributed in space , then the number with intensity exceeding a threshold @xmath5 is given by @xmath7 .",
    "importantly , the relationship holds irrespective of several factors such as luminosity dispersion and the reception pattern of the detector .",
    "the derived relationships therefore allow for researchers to test for departures from specific theories .",
    "for example ,  @xcite uses the derived relationship to infer a nonuniform distribution of sources for a particular population .",
    "other examples of  @xmath2@xmath3  analyses include  @xcite , who use the relationship for gamma ray bursts ( grbs ) to constrain the structure of grb jets . by comparing the @xmath8@xmath3  relationship for observed data to the predicted @xmath8@xmath3  relationship under different physical models for grb jets ,",
    "the authors are able to uncover limitations in the physical models .",
    "the @xmath2@xmath3  curves have also been used to constrain cosmological parameters using cluster number counts in different passbands ; see , for example , @xcite and @xcite .",
    "other applications of @xmath2@xmath3 modeling include the study of active galactic nuclei ( agns ) .",
    "for example , @xcite use the @xmath2@xmath9 relationship over different x - ray bands to constrain the population characteristics of hard x - ray sources .    under independent sampling",
    ", the linear @xmath2@xmath3 relationship corresponds to a pareto distribution for the source fluxes , known to astrophysicists as a power - law model . despite the unrealistic assumptions in the derivation , the linear @xmath2@xmath9 relationship does have strong empirical support in a variety of contexts , for example , @xcite .",
    "in addition to its simplicity , the power - law model also retains a high degree of interpretability , with the power - law exponent often of direct scientific interest . as a result of this simplicity and interpretability , the power - law model forms the basis of most @xmath8@xmath3 analyses despite its many practical limitations in the ability to fit more complex data sets .    to address the limitations of this simple model , astrophysicists",
    "have also experimented with a variety of broken power - law models .",
    "this is particularly important for larger populations or populations of sources spread over a wide energy range .",
    "@xcite illustrate this by using both a two- and three - piece broken power - law model to capture the structure of the @xmath2@xmath3 distribution across a wide range of energies .",
    "the basic idea of broken power - law models is to relax the assumption that the log survival function is a linear function of the log flux , and to instead assume a piecewise linear function .",
    "this adds additional challenges in estimating the location of the breakpoint and quantifying the need for the breakpoint model above the simpler single power - law model . while recognizing the need to have more flexible models for @xmath2@xmath3 analyses , most of the work in this area does not provide a coherent means to selecting the location and number of breakpoints .",
    "similarly to the single power - law model , the broken power - law model can be derived from first principles as a mixture of truncated and untruncated pareto distributions .",
    "the direct physical plausibility of the model is not as complete as for the single power - law model , but the model parameters , in particular , the slopes of the @xmath2@xmath9 relationship , can be used to draw conclusions about competing theories .",
    "the broken power law provides a useful approximation that can be used to model mixtures of populations of sources , as well as more general piecewise - linear populations .",
    "indeed , the broken power law has empirical support in a variety of contexts both in astrophysics [ @xcite ] and outside [ @xcite ] .",
    "there are many alternative generalizations of the single power law in addition to the broken power law considered in this paper .",
    "for example , @xcite considers a smoothly broken power - law model that avoids the nondifferentiability introduced by the strict broken power - law model .",
    "other alternatives include mixtures of log - normal distributions and power laws with modified tail behavior .",
    "in addition to parametric methods , the flux distribution can also be modeled nonparametrically . for the types of applications we are considering here , the main goal is parameter estimation and model selection to distinguish between single and broken power - law models .",
    "the scientific interpretability of a nonparametric model for the @xmath10@xmath11 relationship is more complicated than the parametric alternative , and such approaches have gained less traction in the astrophysics community in the context of @xmath2@xmath3 analyses . therefore , while a more flexible nonparametric fit is perhaps statistically preferable , it is not as amenable to downstream science as in other contexts where the goal is prediction rather than estimation .    among all generalizations ,",
    "the strict broken power law remains the most popular alternative .",
    "this popularity is a result of the interpretability of the model and the ease of translation from statistical results to scientific interpretability . despite the popularity of the broken power - law model in the @xmath2@xmath3 literature ,",
    "there is currently no widely applicable and statistically rigorous method framework for fitting broken power - law models to the @xmath2@xmath3 relationship to astrophysical source populations .    in this paper",
    "we provide an automatic method for jointly inferring the number and location of breakpoints and the parameters of interest for the @xmath2@xmath3 problem .",
    "our method allows astrophysicists to reliably infer both the number and the location of breakpoints in the @xmath2@xmath3 relationship in a statistically rigorous manner for the first time .",
    "this simultaneous fitting introduces new computational challenges , so our method utilizes a new extension of the em algorithm , known as the interwoven em algorithm ( iem ) [ @xcite ] .",
    "the iem algorithm provides efficient and stable estimation of the model parameters across a wide range of parameter settings for a fixed number of breakpoints . to determine the number of breakpoints",
    ", we then use an additional model selection procedure that employs the power posterior technique of @xcite to accurately compute the log - likelihood of the candidate models .",
    "the remainder of the paper is organized as follows . in section  [ secmotivation ]",
    "we introduce the necessary background and statistical formulation of the @xmath2@xmath3 model .",
    "section  [ secestimation ] provides details of our estimation procedure for a fixed number of breakpoints , with section  [ secchoiceb ] outlining our model selection procedure to determine the number of breakpoints required . the performance of our method in terms of both parameter estimation and identification of the number of breakpoints is detailed in section  [ secsims ] .",
    "an application to data from the _ chandra _ deep - field north x - ray survey is provided in section  [ seccdfn ] .",
    "large - sample theory is developed in section  [ seclargesample ] and concluding remarks are offered in section  [ secconc ] .",
    "last , technical details are given in an online supplement [ @xcite ] .",
    "let @xmath12 denote a vector of the fluxes ( in units of erg  s@xmath13  @xmath14 ) of each of a population of @xmath15 astrophysical sources .",
    "for example , we may be interested in the flux distribution of a selection of @xmath15 x - ray pulsars located in a specified region of sky at a specified distance .",
    "the basic building block of our method is the power - law model : @xmath16 this specifies that the unnormalized survival function @xmath4 is approximately a power of the flux @xmath5 .",
    "the power - law exponent , @xmath17 , is the parameter of primary interest and provides domain specific knowledge about the source populations .",
    "the lower threshold @xmath18 can either be fixed according to the desired sensitivity level or estimated from the data .",
    "equivalently , taking the logarithm of both sides , ( [ eqpowerlaw ] )  assumes a linear relationship between @xmath19 and @xmath11 : @xmath20 in a statistical context , the theoretical power - law assumption corresponds to assuming that the source fluxes follow a pareto distribution : @xmath21 in practice , the linear @xmath2@xmath3 , or pareto , assumption is not sufficient to describe the @xmath2@xmath3 relationship for many real data sets .",
    "there are several ways to generalize ( [ eqpowerlaw ] ) , the most popular among astrophysicists being the broken power - law model as illustrated in @xcite and @xcite .",
    "the starting point of the broken power law is to replace ( [ eqpowerlaw ] ) with a monotonically decreasing piecewise linear approximation . in the case of a two - piece model",
    "we assume @xmath22 where @xmath23 and @xmath24 are parameters of interest .",
    "note that as a result of the continuity and normalization constraints on @xmath25 and @xmath26 , there are a total of 4 free parameters in this expanded two - piece model .",
    "applications of the broken power - law model in the astrophysics community typically use either fixed numbers and locations of the breakpoint(s ) or selection via ad hoc procedures [ @xcite ] .",
    "the contribution of this paper is the proposal of an automatic procedure for selecting the number and estimating the locations of the breakpoints jointly with the parameters of interest.=-1    . for the broken power - law example",
    ", the vertical blue line corresponds to the location of the breakpoint . ]",
    "figure  [ figsimplots ] depicts the @xmath2@xmath3 relationship for flux distributions simulated under a single power - law ( left ) and broken power - law model ( right ) .",
    "as may be expected , even under a theoretically linear relationship , the empirical curve regularly exhibits nonlinear features in the @xmath2@xmath9-space . depending on the difference in the power - law slopes",
    ", the breakpoint may be clearly visible or indistinguishable by eye . in either case",
    ", it should be noted that much larger variations in the @xmath2@xmath3 relationship are to be expected in the lower right part of the curves as a result of the @xmath6@xmath6 scaling . as will be seen in section  [ secdataexplanation ] , the task of estimating the parameters controlling the flux distribution and/or detecting a breakpoint is additionally challenging because the fluxes depicted in figure  [ figsimplots ] are not directly observed .",
    "we now describe the connection between the broken power - law model introduced in  ( [ eqtwobreak ] ) and the observed data . in practice ,",
    "the flux of each source , @xmath27 , is not observed directly .",
    "instead , we observe a poisson - distributed photon count whose intensity is a known function of the parameter @xmath27 .",
    "let @xmath28 denote the source counts , then we assume the following hierarchical model . for @xmath29 , @xmath30\\\\[-8pt]\\nonumber s_i & \\stackrel{\\mathrm{i.i.d . } } { \\sim}&\\operatorname{pareto}_b(\\bolds { \\beta},\\bolds{\\tau } ) , \\end{aligned}\\ ] ] where @xmath31 s and @xmath32 s are known constants ( see below ) , @xmath33 , @xmath34 such that @xmath35 , and @xmath36 represents a @xmath37-piece pareto distribution with survival distribution @xmath38 and thus its distribution function @xmath39 .",
    "note that the @xmath37-piece pareto distribution corresponds to the broken power law .",
    "the probability density @xmath40 can be easily found by differentiation .",
    "when @xmath41 , the @xmath37-pareto distribution reduces to a pareto distribution with probability density function @xmath42 in the above @xmath31 s , sometimes known as effective areas , represent sensitivities of the detector , while @xmath32 s represent background intensities . with the above model the goal is then to estimate @xmath37 and , at the same time , @xmath43 and @xmath44 . at first sight",
    ", this seems to be a straightforward statistical problem : for a fixed @xmath37 , maximum likelihood estimation can be used to estimate @xmath45 and @xmath44 , while the issue of choosing @xmath37 can be viewed as a model selection problem and , thus , traditional ideas such as aic and bic can be used . however , as to be seen below , practical implementation of these ideas poses serious computational challenges that can not be easily solved .",
    "in this section we provide details of how to obtain maximum likelihood estimates of @xmath43 and @xmath44 for a fixed number of breakpoints @xmath37 in the @xmath2@xmath3 model . defining @xmath46 , @xmath47 and @xmath48 ,",
    "the likelihood is @xmath49 note that the likelihood involves some numerically unstable integrals that do not have a closed - form solution and , hence , a direct maximization is extremely difficult . to further appreciate this difficulty , consider the case when there is no background contamination ( @xmath50 ) , for which the above likelihood degenerates to @xmath51.\\ ] ] here",
    ", @xmath52 is the incomplete gamma function which is numerically unstable , particularly when the first argument is large .",
    "together with the inner summation in the above expression , these issues make a direct maximization of the ( log-)likelihood difficult even when there is no background contamination . to address these issues",
    ", we propose an em - algorithm [ @xcite ] to find the maximum likelihood estimators of @xmath43 and @xmath44 for the general case of @xmath53 .",
    "the em algorithmhas long been popular for its monotone convergence and resulting stability , and is therefore well suited to our context . as",
    "always , the em algorithm must be formulated in terms of `` missing data '' or auxiliary variables , that must be integrated out to obtain the observed data log - likelihood . for the current problem ,",
    "since we are interested only in inference for @xmath54 and @xmath44 , marginalizing over the uncertainty in the individual fluxes , it is natural to treat @xmath55 as the missing data .",
    "since @xmath56 is a sufficient statistic for @xmath57 , we call this the sufficient augmentation ( sa ) scheme in the terminology of @xcite",
    ".    let @xmath58 .",
    "the complete data log - likelihood of @xmath59 is @xmath60 where @xmath61 is the probability mass function of a poisson distribution with mean  @xmath62 . in the e - step of the algorithm",
    "we compute the conditional expectation @xmath63 where @xmath64 denotes the estimate of @xmath65 at the @xmath66th iteration .",
    "the m - step of the algorithm must then maximize @xmath67 with respect to @xmath65 .",
    "since the first term of  ( [ eqnqsaem ] ) does not depend on @xmath68 , it can be ignored in our maximization . for the second term ,",
    "as it does not admit a closed - form expression , a monte carlo method is used to approximate it .",
    "the basic idea is to estimate it by the mean of a suitable monte carlo sample of the @xmath69 s as described in algorithm  [ algsaem ] .",
    "choose a starting value @xmath70 and set @xmath71 .",
    "generate @xmath72 from @xmath73 using the following metropolis ",
    "hastings algorithm . for each simulation of @xmath56",
    ", we sample the elements of @xmath56 one at a time .",
    "suppose @xmath74 is the current draw .",
    "denote @xmath75 , where @xmath76 is drawn from @xmath77 .",
    "we accept this @xmath78 as new value with probability @xmath79 ; otherwise , we retain  @xmath56 . the acceptance probability is given by @xmath80    find the maximizer @xmath81 of the monte carlo estimate of @xmath67 .",
    "this is equivalent to computing @xmath82 where @xmath83 is the number of burn - in . as discussed above ,",
    "@xmath84 can be obtained by the following steps :    a.   set @xmath85 , b.   obtain @xmath86 as the maximizer of @xmath87 , where @xmath88 , using the nelder  mead algorithm , and c.   set @xmath89 using  ( [ eqnbetaj ] ) , for @xmath90 .    set @xmath91 .",
    "repeat steps ( 2 ) to ( 4 ) until convergence .    without the first term in  ( [ eqnqsaem ] ) ,",
    "the maximization of @xmath92 is equivalent to finding the mle of @xmath93 from an i.i.d .",
    "sample @xmath94 from the @xmath95 distribution .",
    "the log - likelihood of @xmath96 is @xmath97 where @xmath98 , @xmath99 , @xmath100 , @xmath48,@xmath101 is defined to be 0 , and @xmath102 .",
    "note that the @xmath103 s and @xmath104 s are functions of @xmath44 . for any fixed @xmath44",
    ", straightforward algebra shows that @xmath105 is maximized when @xmath106 is set to @xmath107 @xmath90 . by substituting the above expression , @xmath108 becomes @xmath109 therefore , to obtain the mle for @xmath110 from @xmath96 , one can first maximize @xmath111 in  ( [ eqnloglikex ] ) with respect to @xmath44 , and then plug the corresponding maximizer @xmath112 ( i.e. , the mle of @xmath113 ) into  ( [ eqnbetaj ] ) to obtain the mle @xmath114 for @xmath43 .",
    "the mle of @xmath115 is @xmath116 , while unfortunately the mles for @xmath117 do not admit closed - form expressions .",
    "further , ( [ eqnloglikex ] ) is not a continuous function in @xmath44 and , therefore , traditional optimization methods that require function derivatives ( e.g. , newton - like methods ) can not be applied here .",
    "we have experimented with various optimization algorithms and found that the nelder  mead algorithm works well for this problem .",
    "the major steps of the em algorithm in the sa scheme ( saem ) for finding the mles of @xmath118 are given in algorithm  [ algsaem ] .",
    "in practice , the saem algorithm often converges very slowly .",
    "section  [ secemcompare ] below provides some illustrative numerical examples .",
    "given the slow convergence of the saem algorithm , we seek faster alternatives .",
    "this subsection proposes an alternative em algorithm that is based on an ancillary augmentation ( aa ) scheme , called the aaem algorithm . for a discussion of augmentation schemes and their use in em ,",
    "see  @xcite .",
    "the basis of our aaem is to re - express our model using auxiliary variables @xmath119 : @xmath120 for @xmath29 . here",
    "@xmath121 is treated as the missing data and preserves the observed data log - likelihood . in the e - step",
    "we then calculate the conditional expectation @xmath122 this conditional expectation can be approximated and maximized in a similar manner as for the @xmath67 in the saem algorithm .",
    "the resulting aaem algorithm is summarized in algorithm  [ algaaem ] .",
    "section  [ secemcompare ] provides some empirical comparisons between the aaem and saem algorithms .",
    "as may be expected , there are some situations where the aaem algorithm converges faster , while there are other situations where the saem algorithm converges faster .",
    "choose a starting value @xmath70 and set @xmath71 .",
    "generate @xmath123 from @xmath124 using the metropolis  hastings algorithm .",
    "for each simulation of @xmath125 , we sample the element of @xmath125 one by one .",
    "let @xmath126 be the previous draw .",
    "we denote @xmath127 , where @xmath128 is drawn from @xmath129 .",
    "we accept this @xmath130 as new value with probability @xmath131 ; otherwise , we retain @xmath125 .",
    "the acceptance probability is given by @xmath132    find the maximizer @xmath84 of the following monte carlo estimate of @xmath67 : @xmath133 the maximization can be done , for example , with the nelder ",
    "mead algorithm .",
    "set @xmath91 .",
    "repeat steps ( 2 ) to ( 4 ) until convergence .      in practice , choosing the most efficient algorithm between the saem and aaem requires knowledge of the unknown parameter values and the theoretical convergence rates , both of which are not available in most contexts .",
    "therefore , it would instead be desirable if one could combine the `` best parts '' of saem and aaem rather than select one of them .",
    "one simple way to combine the two algorithms is to use the so - called alternating em ( aem ) algorithm .",
    "the aem algorithm proceeds by using saem for the first iteration , then uses aaem for the second iteration , followed by saem for the third , and so on .",
    "while this procedure tends to `` average '' the performance of the two algorithms , a more sophisticated way to combine them is to use the interwoven em ( iem ) algorithm of  @xcite .",
    "theoretical and empirical results show that iem typically achieves sizeable performance gains over the component em algorithms .",
    "the key to the boosted performance of iem is that it utilizes the joint structure of the two augmentation schemes through a special `` ie - step . ''",
    "in contrast , aem simply performs sequential updates using each augmentation scheme that makes no use of this joint information .",
    "the theory of the iem algorithm in  @xcite shows that the rate of convergence of iem is dependent on the `` correlation '' between the two component augmentation schemes .",
    "since the sa and aa schemes typically have low correlation , here we interweave these two schemes to produce an iem algorithm for estimating the parameters of flux distributions .",
    "choose a starting value @xmath70 and set @xmath71 .",
    "execute steps  ( 2 ) and  ( 3 ) of the saem algorithm .",
    "set @xmath134 .",
    "execute step  ( 3 ) of the aaem algorithm , with @xmath135 generated as @xmath136 , for @xmath137 and @xmath138 .",
    "set @xmath139 .",
    "if convergence is achieved or @xmath66 attains @xmath140 , then declare @xmath141 to be mle ; otherwise , set @xmath142 and return to step ( 2 ) .",
    "the iem algorithm for our @xmath2@xmath3  model is given in algorithm  [ algiem ] .",
    "the algorithm requires very minimal computation in addition to the component saem and aaem algorithms , so is comparable in real - time per - iteration speed .",
    "last , we note that there is some freedom in how to combine the iem algorithm with mc methods",
    ". specifically , there are variations in how one may choose to implement step  ( 3 ) .",
    "one may want to sample @xmath143 again instead of using the previous samples in step  ( 2 ) . in both cases",
    ", one obtains a sample from @xmath144 and achieves the goal . from our practical experience",
    ", we found that there is very little difference between the performances of these two approaches .",
    "thus , we choose to use the one which is least computationally expensive .      in this subsection",
    "we empirically compare the convergence speeds of saem , aaem , aem and iem by applying them to two simulated data sets .",
    "these two data sets were simulated from a model with @xmath41 and no background contamination counts .",
    "this model is somewhat simple , but the advantage is that the likelihood function simplifies considerably , and the corresponding maximum likelihood estimates can be reliably obtained with non - em methods . with these maximum likelihood estimates the maximized log - likelihood value can be calculated and used for baseline comparisons .    in figure  [ figemcompare](a ) , for the first simulated data set , we plot the negative log - likelihood values of the saem , aaem , aem and iem estimates evaluated at different iterations .",
    "one can see the slow convergence speeds of saem and aaem , with saem being the slower . also , both aem and iem converged relatively fast , with iem being the faster .",
    "when comparing to aem , iem utilizes the relationship between saem and aaem at each step , which leads to the superiority of iem .",
    "as noted earlier , the convergence rate of iem is heavily influenced by the `` correlation '' between the two data augmentation schemes being interwoven , that is , the sa and aa for this example . for the @xmath2@xmath3 model",
    "the correlation between these augmentation schemes is hard to estimate exactly , but it appears empirically that the sa and aa have a reasonably high correlation , thus preventing iem from outperforming aem by a larger amount .",
    "this is likely due to @xmath145 , which controls the boundary of the parameter of the space and heavily impacts the rate of convergence .",
    "however , among the candidate algorithms iem yields the best convergence properties .",
    "we repeat the same plot in figure  [ figemcompare](b ) for the second simulated data set .",
    "this time the relative speeds of saem and aaem switched , that is , saem converged faster .",
    "this illustrates that neither saem nor aaem is uniformly superior to the other across all data sets .",
    "the relative rate of convergence of aem and iem remain the same for these two data sets and across other simulated data sets ( not shown ) .",
    "overall , from these two plots one can see that the iem algorithm is the most efficient and robust .",
    "also , when comparing to aem , it is computationally faster due to the skipping of an extra sampling step .",
    "similar performance was observed across a wide range of simulation settings .",
    "therefore , we recommend using the iem algorithm to compute the maximum likelihood estimates when @xmath37 is known .",
    "this section addresses the important problem of selecting the number of `` pieces , '' @xmath37 , in the broken - pareto model .",
    "since this problem can be seen as a model selection problem , one can adopt well - studied methods such as aic and bic to solve it . to proceed",
    ", we first note that when @xmath41 , the number of free parameters in the model is @xmath146 .",
    "with aic , the best @xmath37 is chosen as @xmath147 while for bic @xmath37 is chosen as the minimizer of @xmath148 despite the straightforward definitions , in practice , the numerical instability of the likelihood function makes computation of @xmath149 and @xmath150 very challenging . to address this problem",
    ", we adopt the so - called power posterior method proposed by @xcite to approximate the log - likelihood directly .    in our context",
    ", the power posterior is defined as @xmath151 in addition , define @xmath152 and , for simplicity , write the likelihood as @xmath153 .",
    "the following equality is crucial to this method : @xmath154\\,dt,\\ ] ] where the last expectation ( inside the integral ) is taken with respect to the power posterior @xmath155 .",
    "the idea is as follows .",
    "first , for any given @xmath156 , monte carlo methods can be applied to sample from the power posterior and approximate the expectation .",
    "once a sufficient number of these expectations ( corresponding to different values of @xmath156 ) are calculated , numerical methods can be used to approximate the integral , which is the same as the log - likelihood . since",
    "this method approximates the log - likelihood directly ( i.e. , without the computation of the likelihood ) , it is numerically quite stable .",
    "the detailed algorithm is presented as algorithm  [ algpower ] .",
    "choose a starting value @xmath157 and set @xmath71 .",
    "set @xmath158 , where @xmath159 controls the density of the grid values of @xmath156 .",
    "it is typically set to 3 or 5 [ see @xcite ] .",
    "generate @xmath72 from @xmath160 using the metropolis ",
    "hastings algorithm described in step  ( 2 ) of the saem algorithm .",
    "note that the acceptance probability becomes @xmath161    estimate @xmath162 $ ] with @xmath163    if @xmath164 , set @xmath142 , @xmath165 , and go to step ( 2 ) .",
    "otherwise , go to the next step .",
    "given the @xmath166 s , the log - likelihood @xmath167 can be approximated via any reliable numerical integration method .",
    "the above algorithm provides a reliable method for approximating the log - likelihood for a given value of @xmath65 .",
    "then one natural question to ask is as follows : can we not simply obtain the mle of @xmath68 by directly maximizing this log - likelihood approximation via , say , newton s method ?",
    "the answer , in principle , is yes , but the iem algorithm is still preferred mainly because the estimates from iem are generally more stable and reliable .",
    "moreover , the power posterior approximation to the log - likelihood is computationally intensive if one wants to obtain an accurate estimate . for these reasons",
    ", we only use this power posterior approximation to estimate the log - likelihood evaluated at the mle obtained by the iem algorithm .",
    "numerical experiments were conducted to evaluate the practical performance of the proposed methodology .",
    "four experimental settings were considered :    @xmath41 , @xmath168 , @xmath169 and @xmath170 ,    [ s2 ] @xmath171 , @xmath172 , @xmath173 and @xmath174 ,    [ s3 ] @xmath171 , @xmath172 , @xmath175 and @xmath174 ,    @xmath176 , @xmath177 , @xmath178 and @xmath179 .",
    "the parameter values of these settings were chosen to mimic the typical behavior of the real data .",
    "the effective areas and the expected background counts are set to @xmath180 and @xmath181 , respectively , for all @xmath182 .",
    "two hundred data sets were generated for each experimental setting .",
    "for each generated data set , both aic and bic were applied to choose the value of @xmath37 , and model parameters were estimated by the iem algorithm .",
    "the selected values of @xmath37 are summarized in table  [ simb ] .",
    "one can see that bic works substantially better than aic for selecting @xmath37 , and while bic occasionally overestimates @xmath37 , there is a clear tendency for aic to consistently overestimate @xmath37 .",
    "other crucial factors that determine the ability of our method to detect structural breaks in the population distribution include : ( i ) the sample size , ( ii ) the separation between breakpoints , and ( iii ) the magnitude of the difference between the power - law slopes on adjacent segments .",
    "the impact of the third factor can be seen by comparing simulation results from settings   and  , where the misclassification rate is seen to increase as the slopes become closer . from additional simulations",
    "our experience suggests that in typical settings a sample size of 200 or more is needed to reliably detect a single breakpoint , with double this required to detect two breakpoints . in simulations ,",
    "true breakpoints can be detected for smaller sample sizes , but at a lower rate that is more dependent on the noise properties of the specific simulation .",
    "@@lcd3.0d3.0d3.0d2.0@ & & + & & + & & & & & + 1&aic & 94 & 53 & 35 & 18 + & bic & 164 & 33 & 3 & 0 + 2&aic & 0 & 135 & 45 & 20 + & bic & 0 & 198 & 2 & 0 + 3&aic & 0 & 110 & 71 & 19 + & bic & 0 & 177 & 23 & 0 + 4&aic & 0 & 0 & 138 & 62 + & bic & 0 & 0 & 194 & 6 +    in addition to selecting the number of breakpoints , we also conducted a simulation to assess the quality of parameter estimation when using the iem algorithm .",
    "for each experimental setting , we calculated the squared error @xmath183 of @xmath184 for all those data sets where @xmath185 were correctly selected .",
    "we then computed the average of all these squared errors , denoted as @xmath186 , and calculated the relative mean squared error @xmath187 .",
    "similar relative mean squared errors for other estimates in @xmath188 and @xmath189 were obtained in a similar manner . these relative mean",
    "squared errors are given in table  [ simest ] .",
    "we note that all of these are of the order of @xmath190 or  @xmath191 .",
    "@@lc cd2.2cd2.2d2.2c@ & & & + & & & + * setting * & * method * & & & & & & + 1&aic & 5.14 & & & 11.1 & & + & bic & 4.91 & & & 10.6 & & + 2&aic & 3.33 & 2.55 & & 9.81 & 11.3 & + & bic & 3.52 & 2.60 & & 9.17 & 10.8 & + 3&aic & 3.52 & 14.2 & & 12.0 & 13.2 & + & bic & 3.57 & 12.9 & & 11.1 & 13.5 & + 4&aic & 2.71 & 3.26 & 5.04 & 7.08 & 9.91 & 12.3 + & bic & 2.72 & 3.94 & 4.97 & 7.16 & 9.74 & 11.9 +    we now apply our method to data from the _ chandra _ deep field north ( cdfn ) x - ray survey .",
    "our data set comprises a total of 225 sources with an off - axis angle of 8 arcmins or less and counts ranging from 5 to 8655 .",
    "the full cdfn data set is comprised of multiple observations at many different aimpoints , however , we here consider only a subset where the aimpoints are close to each other to avoid complications such as variations in detection probability due to changes in the point spread function ( psf ) shape and consequent variations in detection probability .",
    "the decision to include only aimpoints close to each other was taken primarily to avoid the issue of `` incompleteness '' and essentially amounts to taking a higher signal to noise subset of the full data set .",
    "incompleteness occurs when sources are not observed , typically a result of being too faint to be detected under the specific detector configuration used .",
    "since this missingness is a function of the quantity to be estimated , it must be accounted for and can lead to tremendously more complicated and challenging modeling .",
    "this approach is taken as part of a fully bayesian analysis in  @xcite , but there are significant challenges to the method .",
    "most notably , results are very sensitive to the `` incompleteness function , '' which is frequently not known to such high precision . by considering only a subset of aimpoints we focus on a higher snr subset of the _ chandra _ data that is not subject to issues arising from incompleteness .",
    "we do not believe that the subset choice impacts the final conclusion , as the results in the unpublished report of udaltsova , which models the full data set and accounts for incompleteness , are extremely similar to those presented here . since the off - axis angle measures the radial distance of the source from the center of the detector , sources with large off - axis angles",
    "can be thought of as being `` close to the edge of the image . ''",
    "sources appearing at large off - axis angles appear much larger and at lower resolution than those closer to the center of the detector .",
    "the source - specific scaling constant , effective area @xmath192 , is used to account for variations in the expected number of photons as a function of source location and photon energy . however , at large off - axis angles additional complications such as `` confusion '' ( two or more sources overlapping and appearing as one ) and `` incompleteness '' ( possible nondetections of fainter sources ) must be considered . for the purposes of our analysis here",
    ", we include all sources with an off - axis angle @xmath1938  arcmin to achieve a worst - case completeness of @xmath194 .",
    "we also consider thresholding at @xmath1936 and @xmath1937  arcmins , with a full discussion of the sensitivity to this threshold considered in section  [ subseccdfnoffaxis ] .",
    "@xmath3 plot for the _ chandra _ deep field north data with off - axis angle truncation at 8  arcmins .",
    "the vertical dotted lines are drawn at @xmath195 and @xmath196 .",
    "the red lines correspond to the fitted broken - pareto model with estimated slopes @xmath197 and @xmath198 . ]    applying our model selection procedure to the data set with @xmath1938  arcmins yields an estimate of @xmath199 , with @xmath200 for the @xmath1936 and @xmath1937  arcmin subsets .",
    "as discussed in detail in section  [ subseccdfnoffaxis ] , the consistency of the observations in the 68  arcmin range suggests that the ability to detect the presence of a breakpoint is limited by the small sample sizes at @xmath1936 and @xmath1937 .",
    "figure  [ figlnsplot ] shows the @xmath2@xmath3  plot for the @xmath1938  arcmin data set , depicting the log ( base 10 ) of the empirical survival count as a function of the log flux , using the imputed fluxes from the final e - step of our algorithm .",
    "while the plot ignores the uncertainty in the @xmath27 s , it remains the standard plot for the analysis of @xmath2@xmath3 relationships .",
    "we note from the plot that the `` break '' is clearly visible around @xmath201 , with a change in slope from @xmath202 to @xmath203 .",
    "full parameter estimates and standard error estimates are provided in table  [ tabcdfnresults ] .",
    "standard error estimates are obtained using a simple bootstrap resampling procedure .",
    "we also note that by simulating from the model , the seemingly nonlinear behavior of the curve at @xmath204 is nonetheless seen to be consistent with the piecewise linear model .",
    "our analysis shows that a two - piece broken power - law model is preferred for this subset , with a breakpoint at a lower flux than shown in @xcite and with the lower segment at a flatter slope .",
    "this differs from what would be expected if point sources are to make up all of the diffuse background [ @xcite ] , suggesting that a significant proportion of the residual x - ray background is composed of diffuse emission ( e.g. , hot intergalactic plasma ) ; see also @xcite .",
    "@@ld3.3c@ * parameter * & & * se * + @xmath23 & 0.483 & 0.060 + @xmath24 & 0.854 & 0.224 + @xmath205 & -16.344 & 0.030 + @xmath206 & -15.657 & 0.271 +    the analysis in @xcite was based on optical sources from the hubble space telecope ( hst ) which had no x - ray counterparts . by considering various models for the x - ray intensities of these sources , @xcite compared them to the residual x - ray background from deep chandra observations .",
    "the proportion of the cosmic x - ray background ( cxb ) that can be explained by point sources alone is typically around 7080% .",
    "connecting to our results , higher values for @xmath23 increase the possibility that deeper observations could be obtained that would explain an additional proportion of the cxb as discrete sources .",
    "alternatively , lower values for @xmath23 signify a flatter @xmath2@xmath3 , suggesting a greater amount of diffuse emission .",
    "figure  8 of  @xcite depicts the relationship between the proportion of the 0.52 kev cxb from unresolved hst point sources and the power - law slope .",
    "the breakpoint estimated in our analysis translates to @xmath207  ergs@xmath13  @xmath14 for the passbands used by  @xcite .",
    "however , in the 2 msec data set they analyze , they do not detect any breakpoints ( see their figure  7 ) .",
    "our analysis indicates that the @xmath2@xmath9 curve flattens for fluxes less than the breakpoint , thus allowing for a significant proportion of the unresolved residual x - ray background to be due to diffuse emission .",
    "in this section we consider the sensitivity of our analysis to the chosen off - axis angle threshold . as discussed in section  [ seccdfn ] , at higher off - axis angles",
    "there are additional complications such as incompleteness and confusion that must be built into any statistical analysis that are not covered by the method presented here .",
    "let @xmath208 denote the maximum off - axis angle , that is , all sources with off - axis angle less than @xmath208 are retained and all others are excluded from the analysis .",
    "the choice of @xmath209 for our analysis in section  [ seccdfn ] is motivated by scientific considerations and an estimated completeness above 80% at @xmath209 .",
    "however , by varying the truncation point we obtain additional insight into the sensitivity of our analysis to this decision , as well as to the statistical sensitivity to the sample size required for breakpoint detection .",
    "table  [ tabcdfnk ] shows the results of the analysis for differing values of @xmath208 .",
    "as explained , results for @xmath210 are likely to be untrustworthy , although they happen to be similar to those with @xmath209 . on the other extreme ,",
    "if we truncate at @xmath211 or @xmath212 , we unnecessarily discard a large number of sources .",
    "@ld3.0d3.3d3.3d1.3c@ & & & + & & & + @xmath213 & & & & & + 4 & 77 & -16.364 & & 0.788 & + 5 & 112 & -16.353 & & 0.738 & + 6 & 152 & -16.329 & & 0.691 & + 7 & 192 & -16.373 & & 0.590 & + 8 & 225 & -16.343 & -15.668 & 0.482 & 0.850 + 9 & 257 & -16.352 & -15.732 & 0.449 & 0.850 + 10 & 287 & -16.378 & -15.696 & 0.450 & 0.792 + 11 & 298 & -16.389 & -15.702 & 0.456 & 0.793 + 12 & 303 & -16.403 & -15.677 & 0.454 & 0.802 + 13 & 304 & -16.429 & -15.843 & 0.412 & 0.743 +    we note that at @xmath214 we are also no longer able to formally detect a break , that is , @xmath200 .",
    "however , upon closer examination the bic values for @xmath41 and @xmath171 when @xmath214 are very similar ( 2186.79 vs. 2188.37 ) , indicating that there is little to choose between the @xmath41 and @xmath171 models .",
    "with a few additional data points added at @xmath209 , our procedure then has enough power to detect the break at @xmath209 .",
    "it is worth noting that all additional data points with off - axis angle between 7 and 8 were manually screened , and are quantitatively very similar to those with @xmath215 .",
    "that is , the detection ( or lack ) of a breakpoint in this context appears to be primarily determined by the sample size of the data set used .",
    "this is consistent with our results from the simulation study in section  [ secsims ] , where a sample size of approximately 200 was required to reliably detect a break with similar parameter configurations .",
    "indeed , looking at the plot in figure  [ figlnsplot ] , we note that the break is rather a subtle one , with the estimated slopes differing by approximately 0.37 . in summary , for this particular data set we note that there appears to be evidence of a breakpoint , although the sample size required to detect the breakpoint is not reached until we truncate at @xmath209 , just before additional modeling considerations such as incompleteness must be accounted for .",
    "this section deals with the large - sample properties of the proposed procedure .",
    "we first establish consistency results for the case when @xmath37 is known , with no background contamination ( @xmath50 for all @xmath182 ) and all @xmath31 are assumed to be identical .",
    "then we describe how one could weaken the assumptions of identical @xmath31 s and zero @xmath32 s .",
    "however , as explained at the end of this section , the case of unknown @xmath37 is substantially more difficult and we are unable to provide any theoretical results for this case .    if it is assumed that @xmath216 and @xmath50 for all @xmath29 , then @xmath217 constitute an i.i.d .",
    "sample from model  ( [ eqnymodel ] ) .",
    "denote the density of @xmath218 by @xmath219 the parameter space is defined as @xmath220 .",
    "let @xmath221 denote the true parameter value .",
    "notice that @xmath222 is not compact and that the value of the likelihood does not converge to zero if the parameter approaches the boundary of @xmath222 .",
    "therefore , standard arguments such as the ones based on @xcite do not apply directly in order to establish strong consistency of the maximum likelihood estimator @xmath223 of @xmath224 .",
    "instead a compactification device is applied to subsequently use the results of @xcite .",
    "this leads to the following result .",
    "[ teoconsta ] suppose @xmath37 is known and @xmath216 for all @xmath29 .",
    "then , the maximum likelihood estimator @xmath223 is strongly consistent for @xmath224 , that is , @xmath225 with probability one as @xmath226",
    ".    the proof of theorem  [ teoconsta ] is provided in an online supplement [ @xcite ] . to weaken the restriction of identical @xmath31 ,",
    "observe that this condition is mainly applied to allow the use of the strong law of large numbers for i.i.d .",
    "random variables , as required for the direct application of the results in @xcite and @xcite .",
    "since the arguments used to prove theorem  [ teoconsta ] are still valid if only the assumption @xmath227 is made , kolmogorov s version of the strong law of large numbers can be applied to adapt their proof to the present case , imposing additional assumptions such as the kolmogorov criterion @xmath228 or conditions ensuring the validity of kolmogorov s three - series theorem .",
    "then , the result of theorem  [ teoconsta ] holds also in this more general setting . the case for  nonzero @xmath32 s can also be dealt with similarly , but with long and tedious algebra .",
    "in the theory developed above , the number of pieces , @xmath37 , in the broken - pareto model is assumed to be known .",
    "the case of unknown @xmath37 is , however , substantially more difficult .",
    "in fact , in results in simpler settings such as the traditional `` change in mean '' scenario , in which segments of independent observations differ only by their levels , strong distributional assumptions become necessary to show consistency of an estimator for @xmath37 .",
    "these typically require normality of the observations so that sharp tail estimates of the supremum of certain gaussian processes are available , for example , see @xcite .",
    "these techniques have also been exploited in @xcite for image segmentation purposes . however , in the current context of the more complex broken - pareto model , these arguments are not applicable and , in fact , it seems infeasible to derive theoretical properties under a set of practically relevant assumptions .",
    "we provide a coherent statistical procedure for selecting the number and orientation of `` pieces '' in an assumed piecewise linear @xmath8@xmath3  relationship .",
    "our framework allows astrophysicists to use a principled approach to reliably select the model order @xmath37 , and for parameter estimation via maximum likelihood estimation in a numerically challenging context . to our knowledge , this is the first statistically rigorous procedure developed for solving this important scientific problem .",
    "@xmath229 code implementing the proposed procedure can be obtained from the authors .",
    "the authors are grateful to the associate editor and the editor , professor tilmann gneiting , for their most useful and constructive comments which substantially improved the paper ."
  ],
  "abstract_text": [
    "<S> in astrophysics a common goal is to infer the flux distribution of populations of scientifically interesting objects such as pulsars or supernovae . in practice , inference for the flux distribution </S>",
    "<S> is often conducted using the cumulative distribution of the number of sources detected at a given sensitivity . </S>",
    "<S> the resulting `` @xmath0@xmath1 '' relationship can be used to compare and evaluate theoretical models for source populations and their evolution . under restrictive assumptions </S>",
    "<S> the relationship should be linear . in practice , however , when simple theoretical models fail , it is common for astrophysicists to use prespecified piecewise linear models . </S>",
    "<S> this paper proposes a methodology for estimating both the number and locations of `` breakpoints '' in astrophysical source populations that extends beyond existing work in this field . </S>",
    "<S> an important component of the proposed methodology is a new interwoven em algorithm that computes parameter estimates . </S>",
    "<S> it is shown that in simple settings such estimates are asymptotically consistent despite the complex nature of the parameter space . through simulation studies </S>",
    "<S> it is demonstrated that the proposed methodology is capable of accurately detecting structural breaks in a variety of parameter configurations . </S>",
    "<S> this paper concludes with an application of our methodology to the _ chandra _ deep field north ( cdfn ) data set .    ,    ,    , </S>"
  ]
}