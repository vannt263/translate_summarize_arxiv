{
  "article_text": [
    "this article is concerned with the behaviour of functionals of a large number of exchangeable random variables and the efficient numerical estimation of their expectation .",
    "the objective of this work is thus two - fold : to analyse the order of convergence in @xmath2 of expected functionals for @xmath3 , and to derive estimators for these expectations for which the computational complexity is asymptotically independent of @xmath0 .",
    "first , we analyse convergence in the case of general lipschitz and smooth functions @xmath6 of the average of @xmath0 exchangeable bernoulli random variables as @xmath0 goes to infinity .",
    "we then specify @xmath6 further to certain piecewise linear functions and show that the convergence order is the same as in the smooth case .",
    "these results are relevant , for instance , if one wants to approximate the result for large but finite @xmath0 by its limit .",
    "a number of applications comes from the credit risk literature . in @xcite",
    ", vasicek derives an expression for the limiting distribution of portfolio losses in a normal factor model , where default of a firm is indicated by its value process being below a default barrier at maturity of the debt . in the large portfolio limit",
    ", the randomness comes solely from a common market factor , while a law of large numbers holds for idiosyncratic components conditionally on this factor .",
    "et al_. , in @xcite , extend this to a dynamic set - up where it is seen that the density of the limit empirical measure of firm values satisfies a stochastic partial differential equation ( spde ) and can be used to approximate tranche spreads of basket credit derivatives ; @xcite gives an extension to jump diffusion models while @xcite include extensions to heterogeneity and self - exciting defaults rendering the resulting equations non - linear .",
    "further studies focus particularly on the tail of the limiting loss distribution , see @xcite , @xcite and the references therein .",
    "a driving practical motivation for investigating the limiting behaviour is that the original sequence of random variables is costly to simulate , because of the large number @xmath0 of underlying processes , often required over large time horizons .",
    "moreover , often many monte carlo samples are necessary for sufficiently accurate estimation of , for instance , expected tranche losses of credit basket .",
    "this paper takes a different tack and develops a simulation method where the computational complexity is asymptotically independent of @xmath0 .",
    "a small tweak of the algorithm can also be used to approximate the limit obtained for @xmath3 .",
    "more concretely , it turns out that an interpretation of the multi - level monte carlo approach ( see @xcite ) in the present context allows us to construct estimators based on sequences with increasing lengths and a number of samples which decreases faster than the length increases , such that the overall computational complexity is essentially no larger than for fixed small @xmath0 . a conceptually similar though distantly related approach is used in @xcite , where the multilevel idea is applied to a sequence of martingales to estimate a dual upper bound for the value of an early exercise option . in that setting",
    "they are able to show , as we do here , that the achievable complexity is not substantially larger than that of a non - nested simulation .",
    "the general problem of estimating conditional expectations through nested multilevel simulation is addressed in @xcite . there , further extrapolation is used to reduce the bias of estimators , while here we will propose an improved estimator which reduces the variance of higher level estimators .",
    "this article is organised as follows . in section [ setup ] , we introduce the setting and outline the main convergence results , explaining how they can be used to construct efficient estimators . the first key result on the convergence order of expected functionals",
    "is proved in section [ convergence1 ] , with numerical illustrations from an example of a basket credit derivative presented in section [ numerical ] . in section [ multi ]",
    ", we introduce in detail two multilevel simulation methods and derive bounds on their computational complexity to achieve a prescribed accuracy . finally , in section [ multitests ] we present numerical results illustrating the efficiency gains achieved through multilevel simulation in this context and section [ conclusion ] concludes .",
    "in this article , we are concerned with the behaviour of `` loss '' variables describing the fraction of @xmath0 random variables in a certain state , and expected functionals of this loss variable , as @xmath0 goes to infinity .",
    "the application we have in mind , and for which we will present numerical illustrations , is that of a basket of defaultable firms , and then the loss is the fraction of firms which default over a certain period .    more precisely , on a probability space @xmath7 , consider a sequence of bernoulli random variables @xmath8 , @xmath9 , and a random variable @xmath10 taking values in @xmath11 $ ] .",
    "if required we write @xmath12 where canonically we could take @xmath13 and @xmath14 $ ] .",
    "the probability measure @xmath15 is constructed as follows .",
    "the random variable @xmath10 is generated according to its marginal law @xmath16 and then , conditional on @xmath17 , the @xmath18-algebra generated by @xmath10 , the @xmath19 are independent random variables with law given by @xmath20 = l.\\ ] ] thus for each @xmath21 @xmath22\\ ] ] where @xmath23 .",
    "we will often write @xmath24 for the conditional law of the @xmath19 given @xmath17 and @xmath25 for the associated conditional expectation . in the setting of defaultable firms",
    ", @xmath26 iff the @xmath27-th firm defaults , and @xmath10 is a global factor modelling the common tendency of firms to default .",
    "we define the loss variable to be the proportion of bernoulli variables in state 1 @xmath28 we consider a lipschitz function @xmath6 and random variables @xmath29 and @xmath30 defined as @xmath31    in particular , we will study @xmath6 of the form @xmath32^{+}-[l - k_2]^{+ } = \\left\\ { \\begin{array}{rl } 0 & l \\le k_1 , \\\\",
    "l - k_1 & k_1 \\le l \\le k_2 , \\\\",
    "k_2-k_1 & l \\ge k_2 , \\end{array } \\right.\\end{aligned}\\ ] ] where @xmath33^+=\\max(x,0)$ ] denotes the positive part and @xmath34 are constants . in credit derivative pricing ,",
    "the particular shape of the function @xmath6 in ( [ payoff ] ) measures the losses in a certain _ tranche _ with attachment point @xmath35 and detachment point @xmath36 , and its expectation is the building block for formulae for cdo tranche spreads .",
    "a typical cdo pool consists of @xmath37 firms , while typical loan or mortgage books can have substantially more obligors , and it is therefore practically relevant to understand the behaviour of expected functionals for large @xmath0 and to devise computationally efficient estimators .    by a conditional version of the strong law of large numbers and the continuity of @xmath6 @xmath38 this convergence will also hold in @xmath39 ( see lemma  [ oldlemmadwa ] ) .",
    "we study here the convergence rate of @xmath40 and will prove the following two results .",
    "the first statement for lipschitz and smooth functions @xmath6 is a relatively straightforward consequence of ( [ expectl ] ) and the easily computable @xmath41 convergence rate of @xmath1 .",
    "the second result shows that for a specific @xmath6 which is only piecewise smooth we can still obtain the same convergence order as in the smooth case and with explicitly computable bounds .",
    "[ newertheorem ] let @xmath29 and @xmath30 be defined by and , respectively , and assume that @xmath6 is lipschitz with constant @xmath42 .",
    "we have that @xmath43 \\vert & \\leq & \\frac{c_p}{2 \\sqrt{n}},\\\\   var[p_n -p ] & \\leq &   \\frac{c_p^2}{4n}. \\label{betapart}\\end{aligned}\\ ] ] if , moreover , @xmath6 is differentiable and the derivative has lipschitz constant @xmath44 , then @xmath45 \\vert & \\leq & \\frac{c_p}{8 n}.\\end{aligned}\\ ] ]    [ oldtheorem ] for @xmath6 defined in ( [ payoff ] ) , if the cumulative density function ( cdf ) @xmath46 of @xmath10 is lipschitz at any @xmath47 and @xmath48 with lipschitz constant @xmath49 , i.e. , @xmath50 for @xmath51 and all @xmath52 $ ] , then @xmath53 \\vert   \\leq   \\frac{4c_l\\sqrt{\\pi}}{n}.\\ ] ]    note that if @xmath10 has a density function which is bounded , then the cdf is certainly lipschitz . the fact that we only need the lipschitz property at @xmath35 and @xmath36 will be useful for the applications considered later .",
    "taking the two theorems together , order 1 for the convergence of expectations also follows for piecewise smooth @xmath6 which are lipschitz overall , provided @xmath46 is lipschitz .",
    "these theorems show that expected functionals for large or infinite @xmath0 can be successively approximated by those with smaller @xmath0 .",
    "combining this with a control variate idea leads to multilevel simulation with a substantial variance reduction for large @xmath0 .",
    "specifically , the above results imply that for lipschitz @xmath6 we have @xmath54| \\le c_1/\\sqrt{n}$ ] and @xmath55 \\le c_2/n$ ] for any positive integer @xmath56 with some constants @xmath57 and @xmath58 .",
    "we can consider a sequence @xmath59 , @xmath60 , with corresponding @xmath61 and @xmath62 .",
    "translating the central idea in @xcite to this setting , we estimate in the decomposition @xmath63 = { \\mbox{$\\mathbb e$}}[{p^{(0 ) } } ] +   \\sum_{k=1}^l { \\mbox{$\\mathbb e$}}[{p^{(k)}}- { p^{(k-1)}}]\\ ] ] every summand separately with independent samples of different sizes . these can be chosen to obtain an optimal allocation of computational cost for a given overall mean - square error ( mse ) .",
    "the general construction in @xcite immediately gives the following result .",
    "[ ml - theorem ] let @xmath29 , @xmath64 as above . if there exist independent estimators @xmath65 based on @xmath66 monte carlo samples , and positive constants @xmath67 such that @xmath68 and    1 .",
    "[ alph ] @xmath69 \\right| \\leq c_1\\ , m^{-\\alpha\\ , l } $ ] 2 .",
    "[ cons ] @xmath70 = \\left\\ { \\begin{array}{ll } { \\mathbb{e}}[{p^{(0 ) } } ] , & l=0 \\\\[0.1 in ] { \\mathbb{e}}[{p^{(l)}}\\!-\\ ! { p^{(l-1 ) } } ] , & l>0 \\end{array}\\right .",
    "[ bet ] [ ml - iii ] @xmath71 \\leq c_2\\ , n_l^{-1 } m^{-\\beta\\ , l } $ ] 4 .",
    "[ compl ] [ ml - iv ] @xmath72 where @xmath73 is the computational complexity of @xmath65    then there exists a positive constant @xmath74 such that for any @xmath75 there are values @xmath76 and @xmath66 for which the multilevel estimator @xmath77 has a mean - square - error with bound @xmath78\\right)^2\\right ] < { \\varepsilon}^2\\ ] ] with a computational complexity @xmath79 with bound @xmath80 c_4\\ , { \\varepsilon}^{-2 } ( \\log { \\varepsilon})^2 ,     & \\beta=1 , \\\\[0.1 in ] c_4\\ , { \\varepsilon}^{-2-(1\\!-\\!\\beta)/\\alpha } , & 0<\\beta<1 .",
    "\\end{array}\\right.\\ ] ]    [ complex1 ] let @xmath30 and @xmath29 be as in ( [ trancheloss0 ] ) and ( [ tranchelossinfty ] ) , and assume @xmath6 is lipschitz .    1 .",
    "there is a multilevel estimator for @xmath81 $ ] with mse @xmath4 with computational complexity @xmath82 .",
    "2 .   for all @xmath0",
    ", there is a multilevel estimator for @xmath83 $ ] with mse @xmath4 with computational complexity @xmath82 , where @xmath74 is independent of @xmath0 .",
    "note that only order @xmath84 is required for the convergence of expectations in proposition [ ml - theorem ] , [ alph ] , and that the complexity is then dictated by @xmath85 , the case @xmath86 implied by theorem [ newertheorem ] for all lipschitz payoffs being a boundary case .",
    "we point out that for fixed @xmath0 the standard ( i.e. , single level ) monte carlo estimator has a complexity @xmath87 , however , @xmath88 increases linearly in @xmath0 .",
    "the significance of the multilevel estimator is that the constant @xmath74 is independent of @xmath0 .",
    "for the specific @xmath6 as in ( [ payoff ] ) , we can exploit the piecewise linearity of @xmath6 to construct multilevel estimators with even better complexity , by making the following observations : the summands in ( [ telescope ] ) are unchanged if we replace @xmath89 with any of @xmath90 for @xmath91 , where @xmath92 this is a direct consequence of the exchangeability .",
    "now , @xmath93 and , if all @xmath94 lie in the same interval @xmath95 $ ] , @xmath96 $ ] or @xmath97 $ ] , also @xmath98 , where @xmath99 since @xmath6 is linear in these intervals . because of @xmath100 = { \\mbox{$\\mathbb e$}}[{\\overline{p}^{(k-1)}}]$ ] , we can now write @xmath101 = { \\mbox{$\\mathbb e$}}[{p^{(0 ) } } ] +   \\sum_{k=1}^l { \\mbox{$\\mathbb e$}}[{p^{(k)}}- { \\overline{p}^{(k-1)}}],\\ ] ] and if we estimate the individual terms in the sum independently in the multilevel spirit , there is only a variance contribution from a specific sample of the @xmath102-th term if at least two @xmath103 lie in different intervals . for large @xmath102 , the probability of this is small , and we will be able to show the following result .",
    "[ newtheorem ] for @xmath6 as in ( [ payoff ] ) , let @xmath64 as in proposition [ ml - theorem ] and @xmath104 as in ( [ pbar ] ) .",
    "if the cdf @xmath46 of @xmath10 is lipschitz with lipschitz constant @xmath49 , then @xmath105 & \\leq &   \\frac{c_2}{n_l^{3/2}},\\end{aligned}\\ ] ] where @xmath106 .    here and throughout the paper we give explicit expressions for the constants .",
    "these should not be regarded as optimal in any sense .",
    "for lipschitz @xmath46 and @xmath6 as in ( [ payoff ] ) , there is a constant @xmath107 and multilevel estimators for @xmath81 $ ] and @xmath83 $ ] with mse @xmath4 with computational complexity @xmath108 .",
    "the point here is that we managed to remove the logarithmic factor present in corollary [ complex1 ] and that @xmath107 does not depend on @xmath0 .",
    "we first prove theorem [ newertheorem ] which contains statements in the general and smooth case .",
    "the rest of this section is devoted to the proof of theorem [ oldtheorem ] dealing with a specific non - smooth payoff relevant to our application .",
    "[ oldlemmadwa ] let @xmath30 and @xmath29 be as in ( [ trancheloss0 ] ) and ( [ tranchelossinfty ] ) , and assume @xmath6 is lipschitz with constant @xmath42 .",
    "then @xmath109 \\leq \\frac{c_p^2}{4n}.\\ ] ]    since the function @xmath6 in is assumed lipschitz and @xmath110 = l$ ] , we have @xmath111   \\leq   c_p ^2 \\ { \\mbox{$\\mathbb e$}}_{|l}[({l_n}-l)^2 ]   = c_p^2 \\ var[{l_n}|{\\mathcal{f}_l } ] = \\frac{c_p^2}{n } \\ var[{y_i}|{\\mathcal{f}_l } ]   = \\frac{c_p^2}{n } \\ l(1-l).\\end{aligned}\\ ] ] for @xmath112 $ ] , @xmath113 , which gives the result .",
    "equation ( [ betapart ] ) follows directly from lemma [ oldlemmadwa ] , and then , by hlder s inequality , @xmath114   \\vert \\le \\sqrt { { \\mbox{$\\mathbb e$}}[{\\mbox{$\\mathbb e$}}_{|l}[(p_n - p)^2 ] ] } \\le \\frac{c_p}{2 \\sqrt{n}}.\\ ] ]    for differentiable @xmath6 , we can write @xmath115 =   { \\mbox{$\\mathbb e$}}[p'(l)(l - l_n ) ] + { \\mbox{$\\mathbb e$}}[r(l , l_n)],\\ ] ] with some remainder @xmath116 , where the first term on the left - hand side is @xmath117 = 0.\\ ] ] for a lipschitz derivative of @xmath6 , @xmath118 for all @xmath119 and the remainder term satisfies @xmath120| \\le \\frac{c_p}{8n},\\ ] ] from which ( [ smoothest ] ) follows .",
    "now , we turn to the proof of theorem [ oldtheorem ] and show a few lemmas first .",
    "we divide the ranges of @xmath10 and @xmath1 into the three intervals @xmath121 $ ] , @xmath122 $ ] and @xmath123 $ ] , in each of which the function @xmath6 from ( [ trancheloss0 ] ) is linear ; the point being that the probability of @xmath10 and @xmath1 lying in different intervals is small for large @xmath0 , and the expected difference of @xmath124 is small if they are in the same interval .",
    "the following lemmas quantify this .",
    "[ oldlemmacztery ] for @xmath51 , we have @xmath125    this is a standard large deviations result . by theorem 2.2.3 in @xcite , p.  27 , and remark ( c ) thereafter , for @xmath17-independent and identically distributed random variables @xmath126 with @xmath127=l$ ] , we obtain that if @xmath128 , @xmath129 and if @xmath130 , @xmath131 where the rate function @xmath132 is given on p.  35 in @xcite as @xmath133 since @xmath8 are bernoulli distributed random variables with @xmath134 .",
    "it is straightforward to check that for all @xmath135 @xmath136 hence , by , for @xmath137 @xmath138 and similarly for @xmath139 .",
    "these estimates are clearly true for the degenerate cases @xmath140 and @xmath141 . from this",
    "the result follows .",
    "[ oldlemmajeden ] let @xmath6 be as in ( [ payoff ] ) . if @xmath142 is the event that @xmath1 and @xmath10 are in the same interval and @xmath143 its complement , then @xmath144 = - { \\mbox{$\\mathbb e$}}[({l_n}-l){1_{{a_n^c}}}1_{\\{l\\in i_3\\}}].\\end{aligned}\\ ] ]    by splitting the range of @xmath10 into the different intervals , @xmath144 & = & \\sum_{j=1}^3 { \\mbox{$\\mathbb e$}}[({p_n}-p){1_{{a_n}}}1_{\\{l\\in i_j\\ } } ] \\\\ & = & { \\mbox{$\\mathbb e$}}[({l_n}-l){1_{{a_n}}}1_{\\{l\\in i_3\\ } } ]   \\\\ & = & - { \\mbox{$\\mathbb e$}}[({l_n}-l){1_{{a_n^c}}}1_{\\{l\\in i_3\\}}],\\end{aligned}\\ ] ] where we have used in the second line that @xmath145 if both @xmath146 and @xmath10 lie in either @xmath147 or @xmath148 and that @xmath149 in @xmath150 ; in the last line that @xmath151 = 0 $ ] and @xmath152 .",
    "[ oldlemmapieca ] let @xmath153 be as in lemma [ oldlemmajeden ]",
    ". if the cdf @xmath46 of @xmath10 is lipschitz at @xmath154 , @xmath51 , with constant @xmath49 , then @xmath155 \\right)^{\\frac{1}{2 } } \\right ] \\leq \\frac{c_l \\ ; 4 \\sqrt{\\pi}}{\\sqrt{n}}.\\end{aligned}\\ ] ]    let @xmath156 $ ] and @xmath157 $ ] be the complements in @xmath11 $ ] of @xmath147 and @xmath148 , then @xmath158 and therefore @xmath159 & \\leq & { \\mbox{$\\mathbb p$}}_{|l } [ { l \\in i_1 } ,    \\ ; { { l_n}\\in i_1^c } ] + { \\mbox{$\\mathbb p$}}_{|l } [ { l \\in i_2 } ,    \\ ; { l_n \\in i_2^c } ] + { \\mbox{$\\mathbb p$}}_{|l } [ { l \\in i_1^c } , \\ ; { l_n \\in i_1 } ] \\nonumber \\\\ & & + \\ ; { \\mbox{$\\mathbb p$}}_{|l } [ { l \\in i_2^c } , \\ ; { l_n \\in i_2 } ] .",
    "\\nonumber\\end{aligned}\\ ] ] by , we have @xmath160 \\leq 2 \\ ; \\left ( e^{-n ( l - k_1)^2}+ e^{-n ( l - k_2)^2 } \\right ) , \\end{aligned}\\ ] ] and we obtain @xmath155 \\right)^{\\frac{1}{2 } } \\right ]   & \\leq & 2^{\\frac{1}{2 } } \\ ; \\left ( { \\mbox{$\\mathbb e$}}\\left [ e^{-n \\frac{(l - k_1)^2}{2 } } \\right ] + { \\mbox{$\\mathbb e$}}\\left [ e^{-n \\frac{(l - k_2)^2}{2 } } \\right ]   \\right ) . \\label{beforeint}\\end{aligned}\\ ] ] if we extended @xmath46 by 0 and 1 from @xmath11 $ ] to @xmath161 then , for @xmath51 , we have @xmath162 & = &   \\int_{-\\infty}^{\\infty } e^{-n \\frac{(l - k_j)^2}{2 } } \\ ;   df_l(l ) \\\\ & = & n\\ ; \\int_{-\\infty}^\\infty ( l - k_j ) e^{-n \\frac{(l - k_j)^2}{2 } } f_l(l ) \\ ; dl \\label{lipuse } \\\\ & \\leq & n f_l(k_j ) \\int_{-\\infty}^{\\infty } ( l - k_j ) e^{-n \\frac{(l - k_j)^2}{2 } } \\ ; dl + c_l \\ ; n \\int_{-\\infty}^{\\infty } ( l - k_j)^2 e^{-n \\frac{(l - k_j)^2}{2 } } \\ ; dl \\nonumber \\\\ & = &   \\frac{c_l \\sqrt{2\\pi}}{\\sqrt{n } } , \\nonumber\\end{aligned}\\ ] ] where we used the lipschitz property of the cdf after ( [ lipuse ] ) and then integrated exactly .",
    "the result follows directly by insertion in ( [ beforeint ] ) .    by the tower property of conditional expectations and",
    "jensen s inequality , we have @xmath163 \\vert \\leq   { \\mbox{$\\mathbb e$ } } [ \\vert { \\mbox{$\\mathbb e$}}_{|l } [ ( { p_n}-p )   \\ ; 1_{{a_n^c } } ] \\vert ] . \\end{aligned}\\ ] ] then cauchy - schwarz gives @xmath164",
    "\\vert \\leq { \\mbox{$\\mathbb e$}}_{|l } \\left [ \\left({\\mbox{$\\mathbb e$}}[({p_n}-p)^2]\\right)^{\\frac{1}{2 } } \\ ; \\left({\\mbox{$\\mathbb p$}}_{|l}[{{a_n^c } } ] \\right)^{\\frac{1}{2 } } \\right].\\end{aligned}\\ ] ] by lemmas [ oldlemmadwa ] and [ oldlemmapieca ] , we obtain @xmath165 \\vert \\leq \\frac{c_l 2\\sqrt{\\pi}}{n}.\\end{aligned}\\ ] ]    similarly , using lemma [ oldlemmajeden ] and the same argument as above , @xmath166",
    "\\vert \\leq \\frac{c_l 2 \\sqrt{\\pi}}{n},\\ ] ] from which the statement follows .",
    "to illustrate the theoretical rate of convergence , we study numerical results for expected tranche losses of a synthetic cdo for an increasing size @xmath0 of the underlying cds pool .    we consider a structural factor model ( see , e.g. , @xcite ) , where the _ distance - to - default _ of the @xmath27-th firm , @xmath167 , evolves according to @xmath168 where @xmath169 , @xmath85 given . here , @xmath170 is assumed to be a standard brownian motion and @xmath171 , where @xmath172 is a compound poisson process with intensity @xmath173 and @xmath174 are independent normals with mean @xmath175 and variance @xmath176 , while all @xmath177 are independent standard brownian motions and independent of @xmath170 and @xmath178 .",
    "thus @xmath170 and @xmath178 model factors affecting the whole market , whereas @xmath177 are idiosyncratic effects .",
    "the @xmath27-th firm is considered to be in default if its distance - to - default is below 0 at any one of the observation times @xmath179 , @xmath180 ( quarterly ) , up to @xmath181 , the assumed maturity of the debt here .",
    "we introduce the default time @xmath182 and bernoulli random variable @xmath8 indicating default of the @xmath27-th firm before @xmath183 , by @xmath184    for the numerical experiments , the initial values @xmath185 are drawn independently from a normal distribution , @xmath186 where the mean @xmath187 and standard deviation @xmath188 are obtained from a calibration to itraxx data as detailed in @xcite , as are @xmath189 , @xmath190 , @xmath191 and @xmath192 .",
    "we illustrate the cdf @xmath46 of @xmath10 for different parameters in figure [ fig_empiricalcdf_final ] .    to this end , we generated samples of @xmath10 by simulating the spde satisfied by the limit empirical measure of distances - to - default for @xmath3 , see @xcite for details .",
    "it appears that @xmath46 is lipschitz in @xmath193 but that the derivative at 0 and 1 can become very large in certain parameter ranges for @xmath194 and overall instantaneous correlation @xmath195 between @xmath196 and @xmath197 ( see @xcite ) .    for large values of @xmath198 ,",
    "the probability of defaults becomes very small and the density of @xmath10 is concentrated around 0 . for @xmath199 approaching 1 , all @xmath19 become identical and therefore either all or none of the firms default , such that here the density of @xmath10 is concentrated at 0 and 1 . in the degenerate case @xmath200 ( i.e. , @xmath201 ) , @xmath10 is deterministic , the measure is atomic and @xmath46 a step function .",
    "the empirical evidence thus suggests that @xmath46 is lipschitz in the range @xmath193 .",
    "given that theorem [ oldtheorem ] only requires the lipschitz property at interior values @xmath154 , the conditions appear to be satisfied and the theorem to apply in this setting . even in situations where @xmath46 has a bounded derivative at 0 and 1 , the fact that only the lipschitz constants from @xmath35 and @xmath36 enter into the estimates gives us substantially smaller bounds .",
    "we now move on to present numerical results for the payoff function @xmath6 from ( [ payoff ] ) illustrating the convergence as the number of firms @xmath0 goes to infinity .",
    "we consider portfolios consisting of @xmath202 companies for @xmath203 .",
    "to include a recovery value of defaulted firms in the model , we rescale @xmath1 by @xmath204 , where @xmath205 is the recovery rate .",
    "equivalently , we pick @xmath206 in ( [ trancheloss0 ] ) and @xmath207 as the attachment and detachment points for itraxx tranches , and then study @xmath208 .    a straightforward monte carlo estimator for expected tranche losses",
    "@xmath209 $ ] is then given by @xmath210 where @xmath211 are independent samples of @xmath19 , i.e. , corresponding to independent paths for @xmath170 , @xmath212 and @xmath178 .",
    "there is no time discretisation error as ( [ xti ] ) can be sampled directly .",
    "however , it turns out to be computationally prohibitively expensive to choose @xmath213 , the number of samples , large enough to produce estimators with sufficiently small rmse to allow us to distinguish between @xmath214 and @xmath215 for large @xmath102 .",
    "we therefore use the multilevel simulation approach outlined in section [ setup ] and detailed further in section [ multi ] .",
    "the point is that the differences @xmath216 are simulated directly in the multilevel approach .",
    "therefore , we approximate @xmath217 , where @xmath218 , by @xmath219 for @xmath220 , where @xmath65 is an estimator for @xmath221 $ ] as used in the construction of @xmath222 in ( [ multiest ] ) ( precisely , we used the estimator @xmath65 defined later in ( [ mlestisimple ] ) ) .",
    "the difference between @xmath223 and @xmath217 for @xmath224 is given by @xmath225 and for @xmath226 by @xmath227 .",
    "given @xmath228 in our examples , the error due to this approximation will be seen to be smaller than the estimation error .",
    "the results are shown in figure [ fig_convergencex0_resampling_improved ] .",
    "we plot the logarithm of @xmath223 to base @xmath56 , together with the sample standard deviation of the the multilevel estimators @xmath222 ( see ( [ multiest ] ) ) and @xmath229 where @xmath230 is a suitably chosen constant , to verify the predicted convergence order empirically .    the data points appear to be in good agreement with first order convergence .",
    "in this section , we describe and analyse a multilevel simulation approach for the estimation of expected functionals of the form ( [ trancheloss0 ] ) and ( [ tranchelossinfty ] ) , the latter with a particular emphasis on the case of large @xmath0 . [ subsec : basic ]    the multilevel monte carlo method proposed by giles in @xcite estimates the expected value of a functional of the solution to a stochastic differential equation obtained by a timestepping scheme .",
    "it performs computations on different refinement levels @xmath231 with time steps @xmath232 for @xmath233 , such as to minimise the overall computational time of the monte carlo estimator for prescribed mean square error ( mse ) .",
    "since the mse consists of a monte carlo error ( variance ) and a discretisation error ( bias ) , the method controls both the number of samples @xmath66 on level @xmath231 , to bound the monte carlo variance of order @xmath234 , and the finest @xmath10 with time step @xmath235 on which to approximate the sde , in order to reduce the bias .",
    "the multilevel method is based on two premises : monte carlo estimators for an increasing number of time steps converge at a certain order in @xmath236 , and the computational cost needed to calculate an estimator increases with @xmath237 . in this approach , estimators obtained with a smaller number of time steps are used as control variates for estimators with a larger number of time steps , which significantly decreases the computation time . to obtain a complexity result for an estimator of @xmath81",
    "$ ] with @xmath29 from ( [ trancheloss0 ] ) , we substitute @xmath236 by @xmath238 in theorem 3.1 of @xcite and immediately obtain proposition [ ml - theorem ] from section [ setup ] .",
    "we hence define estimators @xmath65 by @xmath239 where ` c ' denotes a ` coarse ' estimator on level @xmath231 , i.e. , using only @xmath240 instead of @xmath241 bernoulli random variables , precisely , @xmath242 where @xmath243 , @xmath244 , are independent samples of @xmath19 for fixed level @xmath231 and independent across levels . they are constructed from a loss factor @xmath245 ( with the same distribution as @xmath10 , independent across @xmath231 and @xmath246 ) in the same way that @xmath19 is constructed from @xmath10 .    by direct inspection , for this construction of @xmath65 , assumption [ cons ] holds in proposition [ ml - theorem ] . from theorem [ newertheorem ] , we know that [ alph ] holds with @xmath247 for general lipschitz @xmath6 .",
    "clearly , the computational effort to compute @xmath65 is proportional to @xmath248 as required in [ compl ]",
    ". finally , [ bet ] holds by the following simple application of lemma [ oldlemmadwa ] .",
    "[ thmpl ] let @xmath62 as per ( [ tranchelossinfty ] ) , where @xmath6 is lipschitz with constant @xmath42 , then @xmath249 & \\leq & c_p^2 \\ \\frac{m+1}{2n_l}.\\end{aligned}\\ ] ]    this follows directly from @xmath250 & = & { \\mbox{$\\mathbb e$}}_{|l}[(({p^{(l)}}-p)-({p^{(l-1)}}-p))^{2 } ] \\nonumber \\\\ & \\leq & 2 \\left ( { \\mbox{$\\mathbb e$}}_{|l}[({p^{(l)}}-p)^{2 } ] + { \\mbox{$\\mathbb e$}}_{|l}[({p^{(l-1)}}-p)^{2 } ]    \\right)\\end{aligned}\\ ] ] by lemma [ oldlemmadwa ] and taking expectations over @xmath10 .",
    "we have therefore proven the first statement of corollary [ complex1 ] .",
    "+ in practice , it is also relevant to be able to compute @xmath83 $ ] efficiently for finite @xmath0 .",
    "it is clear that for fixed @xmath0 , the complexity is bounded by @xmath251 for some @xmath252 , but for a nave ( single - level ) estimator the constant @xmath88 will increase with @xmath0 . from the proof of theorem 3.1 in @xcite it is clear , however , that there is a multilevel estimator with _ a priori _ bounded upper level @xmath76 which satisfies the second statement in corollary [ complex1 ] .",
    "+ [ subsec : improved ]    we now propose a multilevel estimator with even lower variance , based on the faster decay rate 3/2 in theorem [ newtheorem ] , which we prove subsequently . specifically",
    ", we define estimators @xmath253 by @xmath254 where @xmath255 is defined as in ( [ finep ] ) , but instead of @xmath256 we use @xmath257 and where the rest of the set - up is as earlier .",
    "it is clear that @xmath253 satisfies [ cons ] in proposition [ ml - theorem ] and that the computational complexity is still bounded as required per [ compl ] .",
    "in fact , as the main computational cost is typically in sampling @xmath8 , the computational complexity is virtually identical to that of @xmath65 . in particular , if we evaluate ( [ lfine ] ) by using ( [ llmrel ] ) and the already computed ( [ lscoarse ] ) , the difference in evaluating @xmath65 and @xmath253 is an @xmath258 cost , i.e. , independent of @xmath241 .",
    "now , given theorem [ newtheorem ] , we have that @xmath259 \\le c \\ , n_l^{-1 } m^{-3/2 \\ , l},\\end{aligned}\\ ] ] for some @xmath88 , such that we are in the first regime in the complexity result of proposition [ ml - theorem ] , i.e. , we have optimal complexity order . + the remainder of this section is devoted to the proof of theorem [ newtheorem ] .",
    "[ thmb2 ] assume the cdf @xmath46 of @xmath10 is lipschitz with constant @xmath49 .",
    "let @xmath260 be the event that @xmath261 lies in the same interval as @xmath262 , @xmath263 its complement , then @xmath264 \\right)^{\\frac{1}{2}}\\right ] \\leq \\frac{c}{\\sqrt{n_l } } , \\nonumber \\end{aligned}\\ ] ] where @xmath265 .",
    "let @xmath266 again be the event that @xmath261 and @xmath10 are in the same interval , @xmath267 its complement",
    ". then from @xmath268 follows @xmath269 & \\leq & { \\mbox{$\\mathbb p$}}_{|l}[{{a^{(l ) } } } \\cap { { a^{(l-1),c } } } ] + { \\mbox{$\\mathbb p$}}_{|l}[{{a^{(l),c } } } \\cap { { a^{(l-1 ) } } } ] + { \\mbox{$\\mathbb p$}}_{|l}[{{a^{(l),c } } } \\cap { { a^{(l-1),c } } } ] \\nonumber \\\\ & \\leq & 2 \\ ; { \\mbox{$\\mathbb p$}}_{|l}[{{a^{(l),c } } } ]   + { \\mbox{$\\mathbb p$}}_{|l}[{{a^{(l-1),c } } } ] , \\nonumber\\end{aligned}\\ ] ] which leads to @xmath270 \\right)^{\\frac{1}{2 } } \\right ] \\leq \\sqrt{2 } \\ ; { \\mbox{$\\mathbb e$}}\\left [ \\left ( { \\mbox{$\\mathbb p$}}_{|l}[{{a^{(l),c } } } ] \\right)^{\\frac{1}{2 } } \\right ]   + { \\mbox{$\\mathbb e$}}\\left [ \\left (   { \\mbox{$\\mathbb p$}}_{|l}[{{a^{(l-1),c } } } ] \\right)^{\\frac{1}{2 } } \\right ] .",
    "\\nonumber\\end{aligned}\\ ] ] by lemma [ oldlemmapieca ] , we obtain the result .",
    "[ thm0 ] [ nowelemmaone ] [ nowelemma ] for @xmath29 , @xmath64 , @xmath271 and @xmath104 as above , @xmath6 lipschitz with constant 1 , @xmath272 & \\leq & \\frac{3}{16n_l^2}\\left(1+\\frac{4}{3n_l}\\right ) \\leq \\frac{7}{16n_l^2 } , \\label{fourtha } \\\\ { \\mbox{$\\mathbb e$}}_{|l}[({p^{(l)}}-{p^{(l-1)}})^4 ] & \\leq & \\frac{c}{n_l^2 } , \\label{fourthb } \\\\ { \\mbox{$\\mathbb e$}}_{|l}[({p^{(l)}}-{\\overline{p}^{(l-1)}})^4 ] & \\leq & \\frac{c}{n_l^2 } , \\label{fourthc}\\end{aligned}\\ ] ] where @xmath273 .",
    "see appendix [ app : moments ] .",
    "let @xmath274 be the event that all @xmath275 lie in the same interval , @xmath276 , and @xmath277 its complement , then @xmath278 & = & { \\mbox{$\\mathbb e$}}[({p^{(l)}}-{\\overline{p}^{(l-1)}})^2 1_{{e^{(l ) } } } ] + { \\mbox{$\\mathbb e$}}[({p^{(l)}}-{\\overline{p}^{(l-1)}})^2 1_{{e^{(l),c } } } ] .",
    "\\nonumber \\end{aligned}\\ ] ] by and linearity of @xmath6 in each interval , we have @xmath279 & = & 0",
    ". \\nonumber \\end{aligned}\\ ] ] by cauchy - schwartz , we have @xmath280 \\leq \\left({\\mbox{$\\mathbb e$}}_{|l}[({p^{(l)}}-{\\overline{p}^{(l-1)}})^4 ] \\right)^{\\frac{1}{2 } } \\left({\\mbox{$\\mathbb p$}}_{|l } [ { { e^{(l),c } } } ] \\right)^{\\frac{1}{2 } } , \\nonumber\\end{aligned}\\ ] ] hence , @xmath281 \\leq { \\mbox{$\\mathbb e$}}\\left [ \\left({\\mbox{$\\mathbb e$}}_{|l } [ ( { p^{(l)}}-{\\overline{p}^{(l-1)}})^4 ] \\right)^{\\frac{1}{2 } }   \\left({\\mbox{$\\mathbb p$}}_{|l } [ { { e^{(l),c } } } ] \\right)^{\\frac{1}{2 } } \\right ]",
    ". \\nonumber\\end{aligned}\\ ] ] by lemma [ nowelemma ] , we have that @xmath282 \\right)^{\\frac{1}{2 } } \\leq \\frac{\\sqrt{c_1}}{n_l } , \\label{wyzej}\\end{aligned}\\ ] ] where @xmath283 .    if we denote by @xmath284 the event that @xmath275 and @xmath261 lie in the same interval , then @xmath285 and therefore @xmath286 by lemma [ thmb2 ] , this gives @xmath287 \\right)^{\\frac{1}{2 } } \\right ] \\leq \\frac{c_2}{n_l } , \\nonumber\\end{aligned}\\ ] ] where @xmath288 .",
    "together with , we obtain the result .",
    "in this section , we present multilevel simulation results based on the estimators from the previous section and illustrating the theoretical findings from there . we return to the example from section [ numerical ] and estimate expected tranche losses for credit baskets with an increasing number of firms @xmath59 . for the estimator @xmath65 from ( [ mlestisimple ] ) , an upper bound for the variance  although not a sharp one  is analytically known from ( [ basicvar ] ) and we could use that to determine the number @xmath66 of samples on level @xmath231 which is required to bring the variance contribution under a desired threshold . for the improved estimator @xmath253 from ( [ mlestiimpr ] ) , however , the bound in ( [ varbar ] ) contains the unknown lipschitz constant of the cdf of @xmath46 via theorem [ newtheorem ] . in order to determine the optimal allocation @xmath289 , we use the following algorithm as per @xcite .",
    "in contrast to there , the upper level @xmath76 is fixed here which simplifies the stopping criterion somewhat",
    "start with @xmath290 .",
    "2 .   estimate the variance @xmath291 of a single sample using @xmath292 realisations .",
    "3 .   calculate the optimal number of samples , @xmath293 , for @xmath294 , using @xmath295 where @xmath296 is a chosen upper bound of @xmath297 $ ] .",
    "4 .   draw extra samples for each level according to @xmath293 .",
    "if @xmath298 , set @xmath299 and go to 2 . 6 .",
    "if @xmath300 , finish .    as per @xcite , choosing @xmath293 by , guarantees that the variance @xmath297 $ ] is bounded by @xmath296 , since @xmath301 \\;=\\ ; \\sum_{l=1}^{k } \\left(n_l^ { * } \\right)^{-1 } v_l \\leq \\sum_{l=1}^{k } \\left ( \\gamma^{-2 } \\sqrt{v_l n_l^{-1 } } \\sum_{j=1}^{k } \\sqrt{v_j n_j } \\right)^{-1 } v_l \\ ; = \\ ;   \\gamma^{2}. \\end{split}\\ ] ] a side effect is that , for @xmath220 , the variance is smaller than for @xmath300 , since @xmath302=\\sum_{l=1}^{k } \\left(n_l^{*}\\right)^{-1 } v_l < \\gamma^2 \\frac{\\sum_{l=1}^{k}\\sqrt{v_l n_l } } { \\sum_{l=1}^{k } \\sqrt{v_l n_l}}.\\ ] ] hence , if we compute estimators @xmath222 for all @xmath102 as a by - product of @xmath303 , the variance is the smallest for @xmath304 and then for @xmath222 , @xmath305 , gradually reaches the upper bound @xmath306 .",
    "this effect can be observed in figure [ fig_multilevel_resampling].d .    in figure [ fig_multilevel_resampling ]",
    "we show results for the same parameter setting as in section [ numerical ] and only for the equity tranche .",
    "results from other tests were very similar and did not show any noteworthy additional effects . in order to easily see the rate of convergence in [ fig_multilevel_resampling].a .",
    ", we plot the logarithm of @xmath307 to base @xmath56 , together with @xmath308 for different values of @xmath85 .",
    "the estimated slope is @xmath309 for the original estimator and @xmath310 for the improved estimator , which agrees with the theoretical findings .",
    "the order of convergence of @xmath311 \\vert$ ] is @xmath312 , which also agrees with the previous results . as can be observed in figure [ fig_multilevel_resampling].c , he number of samples ranges from @xmath313 millions for @xmath290 to @xmath314 for @xmath315 .",
    "the improved estimator gives further reductions in computational time : the total number of samples ranges now from @xmath316 millions for @xmath290 to only @xmath317 for @xmath315 .",
    "the standard deviation of @xmath222 is an increasing function of @xmath102 , and is less than or equal to the chosen upper bound @xmath318 .",
    "a main focus of this paper was the construction of an efficient simulation algorithm for functionals of a large number of exchangeable random variables . for a specific set - up",
    ", we were able to demonstrate optimal complexity order by theoretical analysis and numerical illustrations .    the results from the previous section show that the computational savings can be significant in situations of practical relevance .",
    "as seen from figure [ fig_multilevel_resampling].c , already for @xmath37 ( i.e. , @xmath319 ) , the size of a cdo basket , the required number @xmath320 of samples on this level is reduced by about two orders of magnitude compared to the number of samples for @xmath290 , @xmath321 .",
    "it is roughly this number which would be required for a standard ( i.e. , single level ) estimator on level @xmath322 for a comparable variance achieved by the multilevel estimator at substantially lower cost .",
    "we would expect there to be scope to apply the presented nested simulation approach to a wider range of settings beyond the particular application studied here .",
    "an interesting extension would be to the model from @xcite , where the analysis requires further tools accounting especially for the heterogeneity of the basket , resulting in non - exchangeability .",
    "while our motivation comes from credit baskets and some of the later results are specific to piecewise linear functionals encountered in the valuation of basket credit derivatives , there appears to be a wider relevance of the main approach to the simulation of certain functionals arising in large interacting particle systems and elsewhere .",
    "* acknowledgement : * we thank mike giles for suggesting the improved estimator .    1    , _ multilevel dual approach for pricing american style derivatives _ , tech .",
    "1647 , weierstra - institut berlin , 2011 .    ,",
    "_ numerical valuation of basket credit derivatives in structural jump - diffusion models _ , j. comp .",
    "fin . , 15(4 ) , 115158 , 2012 .    ,",
    "_ stochastic evolution equations in portfolio credit modelling",
    "_ , siam j. finan .",
    ", 2 , 627664 , 2011 .    , _ computing functions of conditional expectation via multilevel nested simulation _ , conference presentation at mcqmc 2012 .    , _ large portfolio losses _ , finance stoch . , 8 , 316 , 2004    , _ large deviations techniques and applications _ ,",
    "jones and bartlett pulishers , boston , first edition , 1993 .    ,",
    "_ large portfolio asymptotics for loss from default _ , math . finance , forthcoming , 2012 .    , _ multi - level monte carlo path simulation _ , oper .",
    "res . , 56 , 607617 , 2008 .    , _ large deviations in multifactor portfolio credit risk _ , math .",
    "finance , 17(3 ) , 345379 , 2007 .    , _ assets with jumps _ , risk , 15(9 ) , 149153 , 2002 .",
    ", _ limiting loan loss probability distribution _ , kmv corporation , document number : 999@xmath3230000@xmath323046 , 1991 .",
    "[ of lemma [ nowelemma ] ] we begin by showing ( [ fourtha ] ) and then deduce ( [ fourthb ] ) and ( [ fourthc ] ) .",
    "we have @xmath324 where @xmath325 hence , we get @xmath326 \\leq { \\mbox{$\\mathbb e$}}_{|l } [ ( { l^{(l)}}-l)^4 ] = { \\mbox{$\\mathbb e$}}_{|l } \\bigg [ \\bigg(\\frac{1}{n_l } \\sum_{i=1}^{n_l } ( y_i - l)\\bigg)^4\\bigg].\\ ] ] as @xmath10 is @xmath17-measurable and the @xmath19 are independent and identically distributed given @xmath17 with @xmath327 = 0 $ ] , we have @xmath328 & = & \\frac{1}{n_l^4 } { \\mbox{$\\mathbb e$}}_{|l } \\bigg [ \\sum_{i=1}^{n_l } ( y_i - l)^4 + 3\\sum_{i\\neq j } ( y_i - l)^2(y_j - l)^2 \\bigg ] \\\\ & = & \\frac{1}{n_l^3 } \\left ( ( 1-l)^4l+l^4(1-l)\\right)+ \\frac{3(n_l-1)}{n_l^3 } \\left((1-l)^2l+l^2(1-l)\\right)^2 \\\\ & = & \\frac{3l^2(1-l)^2}{n_l^2 } + \\frac{l(1-l)(1 - 6l(1-l))}{n_l^3}.\\end{aligned}\\ ] ] using the fact that @xmath329 we have the required bound in ( [ fourtha ] ) .    for ( [ fourthb ] ) , observe that there are many ways of estimating this fourth moment ; we choose the following @xmath330 therefore , using cauchy - schwarz on the last term and applying ( [ fourtha ] ) we have @xmath331 & \\leq & 2 \\left ( { \\mbox{$\\mathbb e$}}_{|l } [ ( { p^{(l)}}-p)^4 ] + { \\mbox{$\\mathbb e$}}_{|l } [ ( { p^{(l-1)}}-p)^4 ] \\right ) \\\\ & & \\qquad \\qquad + \\ ; 12 \\ ; { \\mbox{$\\mathbb e$}}_{|l } [ ( { p^{(l)}}-p)^4]^{1/2 } \\ , { \\mbox{$\\mathbb e$}}_{|l } [ ( { p^{(l-1)}}-p)^4 ] ^{1/2 }    \\\\ & \\leq & \\frac{7}{8n_l^2 } +   \\frac{7}{8n_{l-1}^2 } + \\frac{42}{8n_ln_{l-1}}\\end{aligned}\\ ] ] as required to obtain ( [ fourthb ] ) .",
    "finally , ( [ fourthc ] ) follows from @xmath332 & = & { \\mbox{$\\mathbb e$}}_{|l } \\bigg [ \\bigg ( \\frac{1}{m } \\sum_{m=1}^{m } ( { p^{(l)}}-{p^{(l-1)}_m } )   \\bigg)^4 \\bigg ] \\\\ & \\le & { \\mbox{$\\mathbb e$}}_{|l } \\big[\\frac{1}{m } \\sum_{m=1}^{m } ( { p^{(l)}}-{p^{(l-1)}})^4\\big ] \\\\ & = & { \\mbox{$\\mathbb e$}}_{|l } [ ( { p^{(l)}}-{p^{(l-1)}})^4],\\end{aligned}\\ ] ] and an application of ( [ fourthb ] ) ."
  ],
  "abstract_text": [
    "<S> we consider @xmath0 bernoulli random variables , which are independent conditional on a common random factor determining their probability distribution . </S>",
    "<S> we show that certain expected functionals of the proportion @xmath1 of variables in a given state converge at rate @xmath2 as @xmath3 . based on these results , </S>",
    "<S> we propose a multi - level simulation algorithm using a family of sequences with increasing length , to obtain estimators for these expected functionals with a mean - square error of @xmath4 and computational complexity of order @xmath5 , independent of @xmath0 . </S>",
    "<S> in particular , this optimal complexity order also holds for the infinite - dimensional limit . </S>",
    "<S> numerical examples are presented for tranche spreads of basket credit derivatives .    * </S>",
    "<S> key words : * multilevel monte carlo simulation , large deviations principle , exchangeability , basket credit derivatives </S>"
  ]
}