{
  "article_text": [
    "since the invention of turbo codes  @xcite and the rediscovery of low - density parity - check  ( ldpc ) codes  @xcite , constructing practical good codes has been being an active research topic in our field .",
    "recent developments include the invention of polar codes  @xcite and flourishment of spatially coupled ldpc  ( sc - ldpc ) codes  ( first introduced as ldpc convolutional codes  @xcite and later recast as sc - ldpc codes  @xcite ) , both of which are provable capacity - achieving  @xcite over memoryless binary - input symmetric - output channels . despite this success in theory ,",
    "more flexible constructions are still desired in practice .",
    "especially , it is often desirable in practice to design codes that support a variety of code rates but maintain essentially the same encoding / decoding hardware structure .",
    "one way to achieve this is the use of rate - compatible codes , which can be constructed from a mother code by using the puncturing and/or extending techniques .",
    "the former starts with a low - rate mother code and punctures some coded bits to achieve higher rates  @xcite , while the latter starts with a high - rate code and extends its parity - check matrix to achieve lower rates  @xcite . both puncturing and extending require optimizations .",
    "for example , the puncturing patterns for rate - compatible punctured convolutional  ( rcpc ) codes in  @xcite were selected by maximizing the average free distance , while the puncturing distributions for rate - compatible ldpc codes in  @xcite were optimized by density evolution . in  @xcite ,",
    "the incremental protomatrices for protograph - based raptor - like  ( pbrl ) ldpc codes were chosen by maximizing the density evolution threshold . to reduce the construction complexity caused by the optimizations , one can use random puncturing , as proposed in  @xcite .",
    "however , similar to the conventional punctured ldpc codes  @xcite , the performance of the randomly punctured ldpc codes degrades significantly when the puncturing fraction increases beyond a threshold . to the best of our knowledge ,",
    "no methods were reported along with simulations in the literature that can construct good rate - compatible codes over all rates of interest in the interval ( 0,1 ) .",
    "recently , a coding scheme called block markov superposition transmission  ( bmst ) of short codes  ( referred to as _ basic codes _ ) was proposed  @xcite , which has a good performance over the binary - input additive white gaussian noise  ( awgn ) channel .",
    "it has been pointed out in  @xcite that any short code  ( linear or nonlinear ) with fast encoding algorithm and efficient soft - in soft - out  ( siso ) decoding algorithm can be chosen as the basic code .",
    "a bmst code is indeed a convolutional code with extremely large constraint length , which has a simple encoding algorithm and a low complexity sliding window decoding algorithm .",
    "more importantly , bmst codes have near - capacity performance  ( observed by simulation and confirmed by extrinsic information transfer  ( exit ) chart analysis  @xcite ) in the waterfall region of the bit - error - rate ( ber ) curve and an error floor  ( predicted by analysis ) that can be controlled by the encoding memory . in  @xcite ,",
    "short hadamard transform  ( ht ) codes are taken as the basic codes , resulting in a class of multiple - rate codes with fixed code length , referred to as bmst - ht codes .",
    "an even simpler construction for multiple - rate bmst codes was proposed in  @xcite , where the involved basic codes consist of repetition  ( r ) codes and single - parity - check  ( spc ) codes , resulting in bmst - rspc codes .",
    "different from bmst - ht codes which adjust their code rates by setting properly the number of frozen bits in the short ht codes , bmst - rspc codes adjust the code rates by time - sharing between the r code and the spc code .",
    "the construction of bmst codes is flexible , in the sense that it applies to all code rates of interest in the interval ( 0,1 ) .",
    "however , original bmst codes  @xcite are neither rate - compatible nor systematic .",
    "note that systematic codes may be more attractive in practical applications since the information bits can be extracted directly from the estimated codeword .",
    "even worse , original bmst codes do not perform well over block fading channels due to errors propagating to successive decoding windows .    in this paper , we propose systematic bmst of repetition codes , referred to as systematic bmst - r codes . for encoding ,",
    "the information sequence is partitioned equally into blocks and transmitted directly , while their replicas are interleaved and transmitted in a block markov superposition manner . for decoding ,",
    "a sliding window decoding algorithm with a tunable decoding delay can be implemented , as with sc - ldpc codes  @xcite .",
    "systematic bmst - r codes not only preserve the advantages of the original non - systematic bmst codes , namely , low encoding complexity , effective sliding window decoding algorithm and predictable error floors , but also have improved decoding performance especially in short - to - moderate decoding latency .    the main contributions of this paper include :    1 .",
    "we propose systematic rate - compatible bmst - r codes by using both extending and puncturing .",
    "the construction requires no optimization but applies universally to all code rates varying  continuously \" from zero to one .",
    "we propose an upper bound on the ber of a systematic bmst - r code ensemble under maximum _ a posteriori _  ( map ) decoding , which can be evaluated by calculating partial input - redundancy weight enumerating function  ( irwef ) with truncated information weight .",
    "we propose a lower bound on the ber of a systematic bmst - r code ensemble under map decoding , which depends on the encoding memory and code rate .",
    "the derived lower bound reveals connections among ber , encoding memory and code rate , which provides a way to design good systematic bmst - r codes and also allows us to make trade - offs among efficiency , performance and complexity .",
    "we investigate the impact of various parameters on the performance of systematic bmst - r codes , and then present a performance comparison of systematic bmst - r codes and sc - ldpc codes on the basis of equal decoding latency .",
    "simulation results show that : 1 )  the upper and lower bounds are tight in the high signal - to - noise ratio  ( snr ) region ; 2 )  with a moderate decoding delay , the ber curves can match the respective lower bounds in the low ber region , implying that the iterative sliding window decoding algorithm is near optimal ; 3 )  systematic bmst - r codes perform well  ( within one db away from the corresponding shannon limits ) in a wide range of code rates , confirming the effectiveness of the construction procedure ; and 4 )  over both awgn channels and block fading channels , systematic bmst - r codes , overcoming the weakness of non - systematic bmst codes , can have better performance than sc - ldpc codes in the waterfall region under the equal decoding latency constraint .",
    "the rest of the paper is structured as follows . in section  [ secii ] , we present the encoding and decoding algorithms of systematic bmst - r codes . in section  [ seciii ] , we analyze the performance and complexity of systematic bmst - r codes . numerical analysis and performance comparison",
    "are presented in section  [ seciv ] .",
    "finally , some concluding remarks are given in section  [ sec : conclusion ] .",
    "let @xmath0 be the binary field .",
    "let @xmath1 , @xmath2 , @xmath3 be the information sequence to be transmitted , where @xmath4 is the information subsequence of length @xmath5 .",
    "the encoding algorithm of a systematic bmst - r code of rate @xmath6 with encoding memory @xmath7 is described as follows  ( see fig .",
    "[ bmst_encoder ] for reference ) , where @xmath8 @xmath9 are interleavers of size @xmath5 .     and encoding memory @xmath10 , where the information subsequence @xmath11 at time @xmath12",
    "is encoded into the subcodeword @xmath13 for transmission . ]",
    "encoding of systematic bmst - r codes[alg : encoding ]    1 .",
    "* initialization : * [ step : encoding_initialize ] for @xmath14 and @xmath15 , set @xmath16 .",
    "* loop : * [ step : encoding_iteration ] for @xmath17 , * repeat @xmath11 @xmath18 times such that @xmath19 and @xmath20 for @xmath15 ; * for @xmath15 , 1 .   for @xmath21 , interleave @xmath22 into @xmath23 using the @xmath24-th interleaver @xmath8 ; 2 .   compute @xmath25 .",
    "* take @xmath26 as the @xmath12-th block of transmission .",
    "the above encoding structure can implement all code rates of the form @xmath6 , @xmath27 .",
    "if @xmath28 of @xmath5 bits in @xmath29 are randomly punctured resulting in @xmath30 , we can implement a code rate @xmath31 , where @xmath32 is the puncturing fraction . in practice ,",
    "the code need to be terminated .",
    "this can be done easily by driving the encoder to the zero state with a zero - tail of length @xmath33 after @xmath34 blocks of data .",
    "that is , for @xmath35 , @xmath36 , @xmath37 , @xmath38 , we set @xmath39 , compute @xmath40 following  * loop * in algorithm  [ alg : encoding ] , and then take the redundant check part of @xmath40 as the @xmath12-th block of transmission . the rate of the resulting terminated systematic bmst - r code is @xmath41 which is less than that of the unterminated code .",
    "however , the rate loss is negligible for large @xmath34 .    in summary ,",
    "all code rates of interest in the interval ( 0,1 ) can be implemented by adjusting the _ repetition degree _ @xmath18 and the _ puncturing fraction _",
    "@xmath42 , all with the encoding structure as shown in fig .",
    "[ bmst_encoder ] , where stands for the optional puncturing .",
    "assume that the subcodeword @xmath40 is modulated using binary phase - shift keying  ( bpsk ) with 0 and 1 mapped to @xmath43 and @xmath44 , respectively , and transmitted over an awgn channel , resulting in a received vector @xmath45 expressed as @xmath46 for @xmath47 , where @xmath48 is the @xmath49-th component of @xmath45 and @xmath50 is a sample from an independent gaussian random variable with distribution @xmath51 .",
    "the decoding algorithm for systematic bmst - r codes can be described as an iterative message processing / passing algorithm over the associated forney - style factor graph , which is also known as a normal graph  @xcite . in the normal graph ,",
    "edges represent variables and vertices  ( nodes ) represent constraints . all edges connected to a node must satisfy the specific constraint of the node .",
    "a full - edge connects to two nodes , while a half - edge connects to only one node . a half - edge is also connected to a special symbol , called a  dongle \" , that denotes coupling to other parts of the transmission system  ( say , the channel or the information source )  @xcite .",
    "[ bmst_decoder ] shows the normal graph of a systematic bmst - r code with @xmath52 , @xmath53 and @xmath54 .",
    "it is indeed a high - level normal graph , where each edge represents a sequence of random variables .",
    "there are four types of nodes in the normal graph of the systematic bmst - r code .",
    "* * node * @xmath55 : all edges  ( variables ) connected to node @xmath55 must sum to the all - zero vector . the message updating rule at node @xmath55 is similar to that of a check node in the factor graph of a binary ldpc code .",
    "the only difference is that the messages on the half - edges are obtained from the channel observations . * * node * @xmath56 : all edges  ( variables ) connected to node @xmath56 must take the same ( binary ) values .",
    "the messages on the half - edges are obtained from both the channel observations and the information source . to avoid confusion and messy plots , are assumed to be independent and uniformly distributed over @xmath57 . ] the message updating rule at node @xmath56 is the same as that of a variable node in the factor graph of a binary ldpc code . * * node * : the node represents the @xmath24-th interleaver , which interleaves or de - interleaves the input messages . *",
    "* node * : two edges  ( variables ) connected to node must satisfy the constraint specified by the puncturing rules .    , @xmath53 and @xmath54 . ]    the normal graph of a systematic bmst - r code can be divided into _",
    "layers _ , where each layer typically consists of a node of type , @xmath58 nodes of type , @xmath59 nodes of type , and a node of type  ( see fig .  [ bmst_decoder ] ) .",
    "similar to sc - ldpc codes , an iterative sliding window decoding algorithm with decoding delay @xmath60 performing over a subgraph consisting of @xmath61 consecutive layers can be implemented for systematic bmst - r codes . for each window position , the sliding window decoding algorithm can be implemented using the parallel  ( flooding ) updating schedule within the decoding window . the first layer in any window is called the _",
    "target layer_. decoding proceeds until a fixed number of iterations has been performed or certain given stopping criterion is satisfied , in which case the window shifts to the right by one layer and the symbols corresponding to the target layer shifted out of the window are decoded .      from fig .",
    "[ bmst_encoder ] , we can see that systematic bmst - r codes resemble the classical rcpc codes  @xcite .",
    "evidently , we can start from a rate @xmath6 systematic bmst - r code  ( the mother code ) , where @xmath18 is as large as required . by puncturing can be removed . ]",
    ", one can obtain all code rates of interest from @xmath6 to 1 , all of which can be implemented with essentially the same pair of encoder and decoder .",
    "the difference between systematic bmst - r codes and rcpc codes is also obvious .",
    "the encoding of systematic bmst - r codes is block - oriented and the decoding is typically not implementable by the viterbi algorithm  @xcite due to the huge constraint length induced by the block - oriented encoding process .    alternatively",
    ", systematic bmst - r codes are decodable with a sliding window decoding algorithm , which is similar to sc - ldpc codes .",
    "more generally , systematic bmst - r codes can be viewed as a special class of spatially coupled codes , since spatial coupling can be interpreted as introducing memory among successive independent transmissions , where extra edges are allowed to be added during the coupling process  @xcite .",
    "in contrast to sc - ldpc codes , which are usually defined by the null space of a sparse parity - check matrix , systematic bmst - r codes are easily described using generator matrices .",
    "further , since the encoder for a systematic bmst - r code is non - recursive , an all - zero tail can be added to drive the encoders to the zero state at the end of the encoding process .",
    "this is different from sc - ldpc codes , where the tail is usually non - zero and depends on the encoded information bits  ( see section  iv of  @xcite ) . as a result , the encoding procedure for systematic bmst - r codes is simpler than for sc - ldpc codes .    when described in terms of generator matrices , systematic bmst codes",
    "can also be viewed as a special class of spatially coupled low - density generator - matrix ( sc - ldgm ) codes  @xcite . however , as an ensemble , systematic bmst - r codes are different from sc - ldgm codes .",
    "sc - ldgm code ensembles are usually defined in terms of their node distributions , while systematic bmst - r code ensembles are defined in terms of their interleavers  ( see fig .",
    "[ bmst_encoder ] ) .    as another evidence that systematic bmst - r codes are different from existing codes",
    ", we would like to emphasize that systematic bmst - r codes have a simple lower bound on the ber performance , as described in the next section .",
    "a reasonable criterion for a construction to be good is its ability to make trade - offs between complexity and performance .",
    "specifically , if the error performance required by the user is relaxed or , if the gap between the code rate and the capacity is more tolerant , the encoding / decoding complexity should be reduced . in this section",
    ", we will find a relation of the performance to the complexity for _ terminated _ systematic bmst - r codes .",
    "we start with a general systematic linear block code .",
    "a binary linear block code @xmath62 $ ] is a @xmath63-dimensional subspace of @xmath64 .",
    "an encoding algorithm can be described simply by @xmath65 where @xmath66 is the information vector , @xmath67 is the associated codeword , and @xmath68 is a generator matrix of size @xmath69 with rank of @xmath63 .",
    "define @xmath70 let @xmath71 be the minimum hamming weight of @xmath72 , i.e. , @xmath73 where @xmath74 represents the hamming weight .",
    "obviously , the minimum hamming weight @xmath75 of the linear block code @xmath76 can be given by @xmath77    assume that the codeword @xmath78 is modulated using bpsk and transmitted over an awgn channel , resulting in a received vector @xmath79 .",
    "a decoding algorithm is defined as a mapping @xmath80 where @xmath81 .",
    "given the signal mapping @xmath82 and @xmath83 , the snr is given by @xmath84 in db , where @xmath85 is the variance of the noise .",
    "suppose that @xmath86 is distributed uniformly at random over @xmath87 .",
    "let @xmath88 be the error event that the decoder output @xmath89 is not equal to the encoder input vector @xmath86 , and let @xmath90 be the error event that the @xmath91-th estimated bit @xmath92 at the decoder is not equal to the @xmath91-th input bit @xmath93 .",
    "obviously , @xmath94 .",
    "then , under the given decoding algorithm @xmath95 , we can define frame error probability @xmath96 and bit - error probability @xmath97 from the definitions of ber and fer , we have @xmath98 we also have @xmath99 thus , we have @xmath100    the maximum - likelihood  ( ml ) decoding algorithm selects a codeword @xmath101 such that @xmath102 for all codewords @xmath103 . if ties happen , the ml decoding algorithm can randomly select one candidate as the decoder output .",
    "since @xmath86 is distributed uniformly at random over @xmath104 , the ml decoding algorithm is optimal in the sense that it minimizes the fer . to minimize the ber , the map decoding algorithm computes @xmath105 for all @xmath91 . for each @xmath106 ,",
    "the map decoding algorithm outputs @xmath107",
    "if @xmath108 and @xmath109 otherwise .    the irwef of a systematic block code can be given as  @xcite @xmath110 where @xmath111 , @xmath112 are two dummy variables and @xmath113 denotes the number of codewords having input  ( information bits ) weight @xmath91 and redundancy  ( parity check bits ) weight @xmath49 .",
    "the irwef can also be written in a more compact form as @xmath114 where @xmath115 is the conditional redundancy weight enumerating function  ( crwef ) , which enumerates redundancy weight for a given input weight @xmath91 .",
    "since map decoding is optimal in the sense that it minimizes the ber , an upper bound on ber performance under any decoding algorithm is applicable to the map decoding algorithm . in the following ,",
    "we consider a suboptimal list decoding algorithm .",
    "a list decoding algorithm for the purpose of performance analysis[alg : listdecoding ]    1 .",
    "make hard decisions on the information part of the received vector @xmath79 , resulting in a vector @xmath116 of length @xmath63 .",
    "then the channel becomes a memoryless binary symmetric channel  ( bsc ) with cross probability @xmath117 2 .",
    "list all sequences of length @xmath63 within the hamming sphere with center at @xmath116 of radius @xmath118 .",
    "the resulting list is denoted as @xmath119 .",
    "3 .   encode each sequence in @xmath119 by the encoding algorithm of the systematic code , resulting in a list of codewords , denoted as @xmath120 .",
    "4 .   find the codeword @xmath121 that is closest to @xmath79 .",
    "output the information part @xmath122 of @xmath123 as the decoding result .",
    "the above list decoding algorithm is similar to but different from the algorithm presented in  @xcite . the _ list region _ in  @xcite is an @xmath124-dimensional hamming sphere with center at the hard decision of the whole received sequence , while the list region here is a @xmath125-dimensional hamming sphere with center at the hard decision of the information part of the received sequence . by analyzing the ber performance of the proposed list decoding algorithm",
    ", we have the following theorem .",
    "[ theoremupperbound ] for any integer @xmath126 , the bit - error probability of systematic codes under map decoding is upper - bounded by @xmath127 @xmath128    consider the list decoding algorithm  ( algorithm  [ alg : listdecoding ] ) .",
    "the decoding error occurs in two cases under the assumption that the all - zero codeword is transmitted .    1 .",
    "the all - zero sequence of length @xmath63 is not in the list @xmath119 , i.e. , the hard - decisions have @xmath129 errors . in this case",
    ", the decoder output has at most @xmath130 erroneous bits .",
    "hence , the bit - error probability , denoted as @xmath131 , is upper - bounded by @xmath132 2 .",
    "the all - zero sequence of length @xmath63 is in the list @xmath119 , but the all - zero codeword @xmath133 is not the closest one to @xmath79 . in this case , the bit - error probability , denoted as @xmath134 , is upper - bounded by @xmath135    in summary , for any given radius @xmath136 , we have @xmath137 @xmath138 combining  ( [ list ] ) and the fact that @xmath139 , we complete the proof .    from theorem  [ theoremupperbound",
    "] , we have the following three corollaries .    [ corollary1 ] @xmath140    it",
    "can be proved by simply setting @xmath141 in  ( [ upperbound ] ) .",
    "[ corollary2 ] @xmath142    by simply setting @xmath143 in  ( [ upperbound ] ) , we have @xmath144    [ corollary3 ] assuming that we know only the truncated irwef @xmath145 , @xmath146 of systematic codes , we have @xmath147 @xmath148    it is obvious and omitted here .    * remarks .",
    "*  corollary  [ corollary1 ] is the well - known union bound , while corollary  [ corollary2 ] is almost trivial , which can be easily understood by noting that setting @xmath143 in algorithm  [ alg : listdecoding ] is equivalent to taking directly the hard decisions @xmath116 as the decoding result @xmath122  ( one of the simplest sub - optimal decoding algorithms ) . given that only the truncated irwef is available , corollary  [ corollary3 ] is the tightest upper bound of this type .",
    "there exist several lower bounds on fer under ml decoding  @xcite .",
    "however , lower bounds on ber are rarely mentioned in the literature .",
    "any lower bound on @xmath149 can be adapted to a lower bound on ber by noticing that @xmath150 from  ( [ eq1 ] ) .",
    "the simplest lower bound on fer under ml decoding over awgn channels is given by @xmath151 which leads to @xmath152 logically , it is not safe to conclude from the above derivation that the lower bound  ( [ ml_propo ] ) applies to map decoding .",
    "this is subtle due to the fact that ml decoding is not optimal for minimizing the bit - error probability . in the following",
    ", we will show that the lower bound on @xmath153  ( [ ml_propo ] ) is indeed a lower but usually loose bound on @xmath154 by proving an improved lower bound .",
    "was found with proof in the literature . ] to see the looseness of the lower bound , we consider the following toy example .",
    "let @xmath155 with @xmath156 and @xmath157 with @xmath158 be two codes .",
    "define @xmath159 , whose codewords are in a cartesian product form @xmath160 , where @xmath161 and @xmath162 for @xmath163 . obviously , the code @xmath76 has minimum hamming weight @xmath156 .",
    "however , for bpsk modulation over an awgn channel , the ber for the code @xmath76 is dominated by the code @xmath164 rather than the code @xmath165 . to be precise ,",
    "@xmath166 which implies that the lower bound @xmath167 can be very loose in the low snr region . in the following",
    "we present an improved lower bound under map decoding .",
    "[ maplowerbound ] the bit - error probability for the linear block code @xmath76 under map decoding can be lower - bounded by @xmath168    it suffices to prove that @xmath169 for each given @xmath91  @xmath170 .",
    "let @xmath171 be a codeword such that @xmath172 .",
    "there must exist an invertible matrix @xmath173 of size @xmath174 such that @xmath175 with the first row of @xmath176 being @xmath177 .",
    "assume @xmath178 be the information vector and @xmath179 be the codeword to be transmitted .",
    "define @xmath180 .",
    "the map decoder for a binary linear block code computes @xmath181 . we know",
    "that if @xmath182 , the decoding output is correct for this considered bit . in the meanwhile , we assume a _ genie - aided decoder _ , which computes @xmath183 with @xmath184 available . likewise ,",
    "if @xmath185 , the decoding output is correct for this considered bit . for a specific @xmath186 and @xmath79 , it is possible that @xmath187",
    "however , the expectation @xmath188 = i \\left(u_i ; \\boldsymbol{v } ' | \\boldsymbol{y}\\right ) \\geq 0,\\end{aligned}\\ ] ] where @xmath189 is the conditional mutual information .",
    "this implies that the genie - aided decoder performs statistically no worse than the map decoder of the binary linear block code . under the condition that @xmath190 is available ,",
    "there exist only two codewords whose hamming distance is @xmath71 .",
    "thus , the bit - error probability with the genie - aided decoder for the binary - input awgn channels is @xmath191 .",
    "it follows that @xmath192    * remarks .",
    "*  theorem  [ maplowerbound ] also applies to _ non - systematic _ linear block codes .",
    "however , it does not apply to non - linear codes , indicating that the proof is not that simple as considering only the two closest codewords .    from theorem  [ maplowerbound ]",
    ", we have the following three corollaries .    [ ml_lowerbound2map ]",
    "@xmath193    combining  ( [ dmin ] ) and theorem  [ maplowerbound ] , we have @xmath194    [ cyclic_lowerbound ] if a code has the property that @xmath195 for all @xmath91 , we have @xmath196    it is obvious and omitted here .",
    "[ ldgm_lowerbound ] if the row weights of the generator matrix @xmath197 for a linear block code @xmath76 are @xmath198 , we have @xmath199    this can be proved by noting that @xmath200 and that @xmath201 is a decreasing function .",
    "* remarks .",
    "*  corollary  [ ml_lowerbound2map ] shows that the lower bound  ( [ ml_propo ] ) on @xmath153 is also a lower bound on the @xmath154 , while corollary  [ cyclic_lowerbound ] indicates that the lower bound  ( [ ml_propo ] ) can be very loose .",
    "corollary  [ ldgm_lowerbound ] indicates that an ldgm code may have a higher error floor compared to an ldpc code , since the generator matrix for an ldpc code is typically high - density .      to apply the derived bounds to systematic bmst - r codes ,",
    "we need calculate the irwef . for systematic bmst - r codes",
    ", we have @xmath202 @xmath203 where the summation is over all possible data sequences @xmath186 with @xmath204 for @xmath205 .",
    "since it is a sum of products , @xmath206 can be computed in principle by a trellis - based algorithm over the polynomial ring . for specific interleavers ,",
    "the trellis has a state space of size @xmath207 , which makes the computation intractable for large @xmath33 . to circumvent this issue",
    ", we turn to an ensemble of systematic bmst - r codes by assuming that all the interleavers  ( see fig .  [ bmst_encoder ] for reference ) are chosen at each time independently and uniformly at random , and that @xmath30 is obtained by randomly puncturing @xmath28 of @xmath5 bits in @xmath29 . with the assumption that all interleavers are uniform interleavers  @xcite",
    ", we can see that @xmath208 , for @xmath15 , is a random variable which depends _ only _ on the hamming weights @xmath209 .",
    "this admits a reduced - complexity trellis representation of the average irwef of the defined systematic bmst - r code ensemble .",
    "the trellis is time - invariant . at stage @xmath12 ,",
    "the trellis has @xmath210 states , each of which corresponds to a vector of hamming weights @xmath211 .",
    "a state @xmath212 at stage @xmath12 and a state @xmath213 at stage @xmath214 are connected  ( with a branch denoted by @xmath215 ) if and only if @xmath216 for @xmath217 , where @xmath218 and @xmath219 are the @xmath49-th components of @xmath212 and @xmath213 , respectively .",
    "evidently , emitting from  ( or entering into ) each state , there are @xmath220 branches . associated with a branch @xmath215",
    "are a deterministic input weight @xmath221 but a random redundancy weight due to the existence of random interleavers .",
    "the weight distribution of the parity check vector @xmath222 is given by @xmath223 where @xmath224 is interpreted as the probability of current outputs @xmath222 having weight @xmath225 given that the weight vector of previous @xmath7 input blocks @xmath226 and the current input weight @xmath227 . by symmetry , it is easy to see that the weight distribution of @xmath228 for @xmath229 is the same as @xmath230 .",
    "since the parity check vector @xmath30 is obtained by randomly puncturing @xmath28 of @xmath5 bits in @xmath29 , the weight distribution of @xmath30 is given by is equal to zero for @xmath231 or @xmath232 .",
    "] @xmath233    to calculate the probability @xmath224 , we define @xmath234 as the probability that a vector of length @xmath5 has weight @xmath225 , given that the vector is obtained by superimposing two randomly interleaved vectors of  ( respective ) weights @xmath235 and @xmath236 .",
    "define @xmath237 .",
    "following the same lines as the method in section  iv - b of  @xcite , the probability @xmath234 is given by @xmath238 then , @xmath224 can be calculated as described in algorithm  [ alg : f_pqr ] .",
    "computing the probability @xmath224[alg : f_pqr ]    1 .",
    "initialize a vector @xmath239 of length @xmath220 such that its components are all zero except that the @xmath221-th component is 1 . 2 .",
    "for @xmath240 , @xmath241 , @xmath37 , @xmath242 , compute @xmath243 for @xmath244 , where @xmath245 is the @xmath246-th component of @xmath247 and @xmath248 is the @xmath49-th component of @xmath212 .",
    "we have @xmath249 for @xmath250 , @xmath241 , @xmath37 , @xmath5 .",
    "finally , @xmath251 can be calculated recursively by performing a forward trellis - based algorithm  @xcite over the polynomial ring in algorithm  [ alg : iowef ] .",
    "computing irwef of systematic bmst - r codes[alg : iowef ]    1 .",
    "initialize @xmath252 if @xmath212 is the all - zero state ; otherwise , initialize @xmath253 .",
    "2 .   for @xmath254 , @xmath241 , @xmath37 , @xmath38 , for each state @xmath213 , @xmath255 where @xmath256 is the first component of @xmath213 .",
    "3 .   at time @xmath257",
    ", we have @xmath258 .",
    "* remarks .",
    "*  the summation for step  2 ) in algorithm  [ alg : iowef ] is over @xmath220 possible states @xmath212 for a given state @xmath213 .",
    "the computation of algorithm  [ alg : iowef ] becomes more complicated and even intractable for large @xmath7 and/or @xmath5 due to the huge number of trellis states @xmath210 .",
    "fortunately , as shown in section  [ subsec : upperbound ] , we can calculate bounds by the use of a truncated irwef , which can be obtained by removing certain states and branches from the trellis . specifically , for a given truncating parameter @xmath259 which corresponds to the maximum input weight , we remove all the branches @xmath215 with @xmath260 and keep only those terms @xmath261 with @xmath262 of the polynomial @xmath263 for @xmath264 .    from corollary  [ corollary3 ] ,",
    "the upper bounds may be improved by increasing the truncating parameter @xmath259 , which usually needs more computational and memory loads . however , the lower bound  ( as well as the upper bound in the high snr region ) is dominated by the crwefs with input weights 1 and 2 , which can be given explicitly as below .",
    "we first show the crwefs for a systematic bmst - r code ensemble without puncturing .",
    "we have @xmath265 for the crwef @xmath266 , we consider the following three cases .    1",
    ".   the two non - zero information bits are in the same layer . in this case , the corresponding crwef @xmath267 is given by @xmath268 2 .",
    "the two non - zero information bits are in two different layers with a gap @xmath246  ( spaced away from @xmath269 layers ) satisfying that @xmath270 . in this case , the corresponding crwef @xmath271 is given by @xmath272 @xmath273 3 .",
    "the two non - zero information bits are in two different layers with a gap @xmath246 satisfying that @xmath274 . in this case , the corresponding crwef @xmath275 is given by @xmath276    in summary , the crwef @xmath266 for a systematic bmst - r code ensemble without puncturing is given by @xmath277    then , we consider the crwefs for a systematic bmst - r code ensemble with @xmath28 bits in each layer punctured .",
    "taking into account the puncturing effect , when @xmath28 bits of a sequence with length @xmath5 and weight 1 are randomly punctured , the resulting weight enumerator @xmath278 is given by @xmath279 when @xmath28 bits of a sequence with length @xmath5 and weight 2 are punctured , the resulting weight enumerator @xmath280 is given by @xmath281 @xmath282 then we have @xmath283 @xmath284    for the crwef @xmath266 , we consider the following three cases .    1",
    ".   the two non - zero information bits are in the same layer . in this case , the corresponding crwef @xmath267 is given by @xmath285 2 .",
    "the two non - zero information bits are in two different layers with a gap @xmath246 satisfying that @xmath270 . in this case , the corresponding crwef @xmath271 is given by @xmath286 3 .",
    "the two non - zero information bits are in two different layers with a gap @xmath246 satisfying that @xmath274 . in this case , the corresponding crwef @xmath275 is given by @xmath287 @xmath288    in summary , the crwef @xmath266 for a systematic bmst - r code ensemble with @xmath28 bits in each layer punctured is given by @xmath289    from theorem  [ maplowerbound ] , we know that the bit - error probability for systematic codes under map decoding can be lower - bounded in terms of the minimum hamming weights @xmath71 of @xmath72",
    ". however , these minimum weights are usually not available for a general code .",
    "if this is the case , we can use instead the row weights of the generator matrix to calculate a looser lower bound as shown in corollary  [ ldgm_lowerbound ] , where the @xmath91-th row weight can be determined by setting the binary information data @xmath186 to a nonzero sequence with only the @xmath91-th component @xmath290 .",
    "then we have the following two corollaries .    [ corollaryensemblelowerbound ]",
    "the bit - error probability of a systematic bmst - r code ensemble under map decoding can be lower - bounded by @xmath291 @xmath292 where @xmath42 is the puncturing fraction .",
    "[ corollary8 ] the bit - error probability of a systematic bmst - r code ensemble without puncturing  ( i.e. , with puncturing fraction @xmath300 ) under map decoding can be lower - bounded by @xmath301    for a specific @xmath91  @xmath302 , we can see from  ( [ eq : a1 ] ) that the @xmath91-th row of the generator matrix has a deterministic weight @xmath303 thus , the error probability of the @xmath91-th estimated bit of the systematic bmst - r code ensemble under map decoding can be lower - bounded by @xmath304 it follows that the bit - error probability of the systematic bmst - r code ensemble without puncturing under map decoding can be lower - bounded by @xmath305    * remarks .",
    "*  corollaries  [ corollaryensemblelowerbound ] and  [ corollary8 ] also hold for systematic bmst - r codes with specific interleavers for the reason that the interleavers have no effect on the row weights of the generator matrix .",
    "since the lower bound  ( [ codelowerbound ] ) without puncturing is equivalent to the lower bound  ( [ ensemblelowerbound ] ) with puncturing fraction @xmath300 , in the rest of the paper , we consider for generality the lower bound  ( [ ensemblelowerbound ] ) .      , @xmath306 and @xmath307 . ]    , @xmath306 and @xmath307 . ]",
    "the implementation complexity of systematic bmst - r codes can be analyzed as with their non - systematic counterpart . for encoding ,",
    "the information sequence is partitioned equally into blocks and transmitted directly , while their replicas are interleaved and transmitted in a block markov superposition manner .",
    "this shows that the encoding complexity grows linearly with the encoding memory @xmath10 . for decoding ,",
    "a sliding window decoding algorithm with a tunable decoding delay can be implemented over the normal graph  ( see fig .",
    "[ bmst_decoder ] ) . the decoding complexity for node and node of systematic bmst - r codes grows linearly with the encoding memory @xmath10 .",
    "furthermore , similar to non - systematic bmst codes , a decoding delay @xmath308 is required to achieve the lower bound on the performance . as a result",
    ", the decoding complexity for systematic bmst - r codes can be roughly given as @xmath309 , or equivalently , @xmath310 .",
    "the above analysis shows that the decoding complexity is closely related to the repetition degree @xmath18 and the encoding memory @xmath10 , both of which in turn determine the lower bound  ( [ ensemblelowerbound ] ) .",
    "this allows us to make trade - offs among efficiency , performance and complexity . to be precise , we consider the following two cases .    1 .   fixed snr .",
    "we can observe from the lower bound  ( [ ensemblelowerbound ] ) that , for a given snr and ber , the required encoding memory @xmath10 decreases as the repetition degree @xmath18 increases  ( accordingly , the code rate decreases ) , resulting in a lower complexity .",
    "[ fig_complexity_diffrate ] shows the decoding complexity for systematic bmst - r codes as a function of code rate that requires an snr of 2 db to achieve bers of @xmath311 , @xmath306 and @xmath307 .",
    "as expected , for fixed ber , the greater the code rate is , the higher the decoding complexity is .",
    "we also see that for fixed code rate , the higher the performance requirement  ( equivalently , the more stringent the ber ) is , the higher the decoding complexity is",
    "fixed code rate .",
    "we can observe from the lower bound  ( [ ensemblelowerbound ] ) that , for a given rate and ber , the required encoding memory @xmath10 decreases as the snr increases , resulting in a lower decoding complexity .",
    "this is reasonable since more excessive snr is available compared to the corresponding shannon limit .",
    "[ fig_complexity_rate0.5 ] shows the decoding complexity for rate 1/2 systematic bmst - r codes as a function of snr with bers of @xmath311 , @xmath306 and @xmath307 .",
    "as expected , for fixed ber , the greater the snr is , the lower the decoding complexity is .",
    "we also observe that for fixed snr , the more stringent the ber is , the higher the decoding complexity is .",
    "in this section , all simulations are performed assuming bpsk modulation and transmitted over an awgn channel , unless otherwise specified .",
    "the @xmath59 random interleavers  ( randomly generated but fixed ) of size @xmath5 are used for encoding . the iterative sliding window decoding algorithm for systematic bmst - r codes",
    "is performed using the parallel ( flooding ) updating schedule within the decoding window with a maximum iteration number of 18 , and the entropy stopping criterion  @xcite with a preselected threshold of @xmath312 is employed .      in this subsection",
    ", we present an example to study the performance bounds on ber of systematic bmst - r codes .",
    "we consider systematic bmst - r codes with repetition degree @xmath313 and puncturing fraction @xmath300 .",
    "the decoding delay @xmath60 for the sliding window decoding is specified as @xmath314 .",
    "[ example1 ]     of systematic bmst - r code ensembles with encoding encoding memory @xmath315 , @xmath53 and @xmath316 in example 1 .",
    "assume @xmath317 blocks of information data , where the information subsequence has length @xmath318 .",
    "the systematic bmst - r code with @xmath315 is equivalent to the independent transmission of rate 0.5 repetition code .",
    "the truncating parameter is set to @xmath319 .",
    "the code rates of systematic bmst - r code ensembles with @xmath315 , @xmath53 and @xmath316 are 0.5 , 0.4878 and 0.4762 , respectively . ]    , @xmath53 and @xmath316 in example 1 .",
    "the systematic bmst - r code with @xmath315 is equivalent to the independent transmission of rate 0.5 repetition code .",
    "assume @xmath317 blocks of information data , where the information subsequence has length @xmath318 .",
    "the codeword is modulated using bpsk and transmitted over an awgn channel .",
    "the decoding delay @xmath60 is specified as @xmath314 .",
    "the truncating parameter is set to @xmath319 .",
    "the code rates of systematic bmst - r code ensembles with @xmath315 , @xmath53 and @xmath316 are 0.5 , 0.4878 and 0.4762 , respectively . ]",
    "assume that there are @xmath317 blocks of information data to be transmitted , where the information subsequence have length @xmath318 .",
    "we consider systematic bmst - r code ensembles with encoding memory @xmath315 , @xmath53 and @xmath316 , whose code rates are 0.5 , 0.4878 and 0.4762 , respectively . here , the systematic bmst - r code with @xmath315 is equivalent to the independent transmission of rate 0.5 repetition code .",
    "assume that we only calculate the truncated irwef @xmath145 , @xmath320 .",
    "that is , the truncating parameter is set to @xmath319 .",
    "[ fig_spectrum ] shows the spectrum @xmath321 of systematic bmst - r code ensembles , where @xmath322 from fig .",
    "[ fig_spectrum ] , we see that the spectrum of the systematic bmst - r code ensembles with @xmath53 and @xmath316 have less number of codewords with small hamming weights .",
    "we also see that the minimum hamming distances of systematic bmst - r code ensembles with encoding memory @xmath315 , @xmath53 and @xmath316 are 2 , 3 and 4 , respectively .",
    "these indicate that the systematic bmst - r codes have potentially better performance than the independent transmission system .",
    "the simulation results are shown in fig .",
    "[ fig_performancebounds ] , where we observe that    1 .",
    "the lower and upper bounds on the ber performance of systematic bmst - r codes are tight in the high snr region .",
    "2 .   the simulated ber performance curves match well with the bounds in the high snr region , indicating that the sliding window decoding algorithm is near optimal in the high snr region .",
    "the systematic bmst - r codes outperform the independent transmission system  ( i.e. , the systematic bmst - r code with @xmath315 ) .",
    "furthermore , the systematic bmst - r code with encoding memory @xmath316 outperforms the systematic bmst - r code with @xmath53 . taking into account the rate loss",
    ", the systematic bmst - r code with @xmath316 obtains a net gain of 1.175 db in terms of @xmath323 at a ber of @xmath307 , compared to the systematic bmst - r code with @xmath53 .",
    "given the tightness of the lower bound  ( [ ensemblelowerbound ] ) as demonstrated in example  [ example1 ] , we have the following simple procedure to construct good codes .",
    "let @xmath324 be the target code rate and @xmath325 be the target ber .",
    "the object is to construct a code with rate @xmath326 , which can approach the shannon limit at the target ber .",
    "a systematic bmst - r code has the following five parameters : repetition degree @xmath18 , information subsequence length @xmath5 , puncturing length @xmath28 , data block length @xmath34 , and encoding memory @xmath7 .",
    "these parameters can be determined as follows .    1 .",
    "determine the repetition degree @xmath18 and puncturing fraction @xmath42 such that @xmath327 .",
    "choose sufficiently large information subsequence length suffices to approach the shannon limit within around half db . ]",
    "@xmath5 and puncturing length @xmath28 such that @xmath328 ; 2 .",
    "find the shannon limit for the given code rate @xmath329 and target ber @xmath325 ; 3 .",
    "determine the minimum encoding memory @xmath7 such that the lower bound of @xmath154 in  ( [ ensemblelowerbound ] ) at the shannon limit is not greater than the preselected target ber @xmath325 ; 4 .",
    "choose a data block length @xmath34 such that the rate loss ( i.e. , @xmath330 ) due to the termination is small ; 5 .",
    "generate @xmath59 interleavers randomly .",
    "evidently , the above procedure requires no optimization and hence can be easily implemented .",
    "the encoding memories for some systematic bmst - r codes required to approach the corresponding shannon limits at given target bers are shown in table  [ table1 ] . as expected , the lower the target ber is , the greater the required encoding memory @xmath10 is .    [ cols=\"^,^,^,^,^ \" , ]      in this subsection , we study the impact of various parameters  ( e.g. , encoding memory @xmath10 , information subsequence length @xmath5 and decoding delay @xmath60 ) on the ber performance of systematic bmst - r codes with fixed code rate .",
    "note that , as pointed out in  section  [ subsec : encoding ] , varying repetition degree @xmath18 and puncturing fraction @xmath42 results in systematic codes with different rates .",
    "for simplicity , we focus on @xmath331 systematic bmst - r codes with repetition degree @xmath313 and puncturing fraction @xmath300 .",
    "three regimes are considered : ( 1 )  fixed @xmath10 and @xmath5 , increasing @xmath60 , ( 2 )  fixed @xmath10 and @xmath60 , increasing @xmath5 , and ( 3 )  fixed @xmath5 , increasing @xmath10  ( and hence @xmath60 ) .",
    "systematic bmst - r codes decoded with different decoding delays @xmath60 in example 2 .",
    "information subsequence length @xmath332 , encoding memory @xmath333 and data block length @xmath334 .",
    "the codeword is modulated using bpsk and transmitted over an awgn channel .",
    "the corresponding window decoding thresholds and the lower bound are also plotted . ]",
    "consider a systematic bmst - r code with information subsequence length @xmath332 , encoding memory @xmath333 and data block length @xmath334 .",
    "the ber performance of the systematic bmst - r code decoded with different decoding delays @xmath60 is shown in fig .",
    "[ fig_impactparameters_diffdelay ] . the asymptotic threshold performance obtained by using the exit",
    "chart analysis method in  @xcite is also included . from fig .",
    "[ fig_impactparameters_diffdelay ] , we observe that    1 .",
    "the ber performance of the systematic bmst - r code decoded with different delays @xmath60 matches well with the corresponding window decoding thresholds in the high snr region .",
    "the ber performance in the waterfall region improves as the decoding delay @xmath60 increases , but it does not improve much further beyond a certain decoding delay  ( roughly @xmath335 ) .",
    "the ber performance in the error floor region improves as the decoding delay @xmath60 increases , and it matches well with the lower bound for the systematic bmst - r code with @xmath333 when @xmath60 increases up to a certain point  ( roughly @xmath336 ) .",
    "systematic bmst - r codes with different information subsequence lengths @xmath5 in example 3 .",
    "the codes are constructed with encoding memory @xmath333 and data block length @xmath334 , and decoded with decoding delay @xmath336 .",
    "the codeword is modulated using bpsk and transmitted over an awgn channel .",
    "the corresponding lower bound is also plotted . ]",
    "consider systematic bmst - r codes constructed with encoding memory @xmath333 , data block length @xmath334 and decoded with decoding delay @xmath336 .",
    "the ber performance of systematic bmst - r codes constructed with different information subsequence lengths @xmath5 is shown in fig .",
    "[ fig_impactparameters_diffcartesianproductorder ] , where we observe that    1 .   increasing the information subsequence length @xmath5 can improve waterfall region performance . as expected , this improvement saturates for sufficiently large @xmath5 .",
    "for example , the improvement at a ber of @xmath307 from @xmath337 to @xmath338 , both decoded with @xmath339 , is about 0.25 db , while the improvement decreases to about 0.05 db from @xmath340 to @xmath341 .",
    "2 .   the error floors , which are determined by the encoding memory and code rate  ( see corollary  [ corollaryensemblelowerbound ] ) ,",
    "can not be lowered by increasing @xmath5 .",
    "systematic bmst - r codes constructed with different encoding memories @xmath10 and decoded with decoding delay @xmath342 in example 4 .",
    "the information subsequence length of the involved systematic bmst - r codes is @xmath343 .",
    "the codeword is modulated using bpsk and transmitted over an awgn channel .",
    "the corresponding window decoding thresholds and lower bounds for systematic bmst - r codes are also plotted . ]",
    "consider systematic bmst - r codes constructed with information subsequence length @xmath343 and encoding memories @xmath344 , @xmath345 and @xmath346 . the performance with sufficiently large decoding delay @xmath342 of the systematic bmst - r codes is shown in fig .",
    "[ fig_impactparameters_diffmemory ] , where we observe that    1 .",
    "the ber performance of systematic bmst - r codes matches well with the corresponding window decoding thresholds in the high snr region .",
    "2 .   for a high target ber  ( roughly above @xmath311 )",
    ", the ber performance improves as the encoding memory @xmath10 increases , which is consistent with the threshold analysis performance .",
    "note that this phenomenon does not exist for non - systematic bmst codes whose performance degrades slightly as @xmath10 increases  ( see section  v - c of  @xcite ) .",
    "the error floor can be lowered by increasing the encoding memory @xmath10  ( and hence the decoding delay @xmath60 ) .",
    "in addition to decoding performance , the latency introduced by employing channel coding is a crucial factor in the design of a practical communication system , such as personal wireless communication and real - time audio and video . in this subsection",
    ", we study the ber performance of systematic bmst - r codes based on their decoding latency .     for finite - length systematic bmst - r codes ,",
    "non - systematic bmst - r codes in  @xcite , @xmath347-regular sc - ldpc codes , and @xmath348-regular sc - ldpc codes as a function of decoding latency .",
    "all the codes have rate 0.49 .",
    "the decoding delays for @xmath347-regular sc - ldpc codes and @xmath348-regular sc - ldpc codes are @xmath349 and @xmath350 , respectively .",
    "the encoding memories for non - systematic bmst - r codes and systematic bmst - r codes are 8 and 16 , respectively .",
    "the values of the information subsequence length and decoding delay for the non - systematic bmst - r codes are chosen such that the combination gives the best decoding performance .",
    "the decoding delays for the systematic bmst - r codes are @xmath339 , @xmath351 , @xmath37 , @xmath352 .",
    "the codeword is modulated using bpsk and transmitted over an awgn channel . ]",
    "we consider rate @xmath331 systematic bmst - r codes with encoding memory @xmath333 , repetition degree @xmath313 and puncturing fraction @xmath300 .",
    "the decoding latency of the sliding window decoder , in terms of bits , is given by @xmath353 the snr required to achieve a ber of @xmath307 as a function of decoding latency is shown in fig .",
    "[ fig_equaldecodinglatency ] .",
    "we observe that the performance of systematic bmst - r codes  ( with fixed information subsequence length @xmath5 ) improves as the decoding delay @xmath60  ( and hence the latency ) increases , but it does not improve much further beyond a certain decoding delay .",
    "moreover , beyond a certain latency , using a greater information subsequence length @xmath5 with a smaller decoding delay @xmath60 gives better performance .",
    "for example , the systematic bmst - r code constructed with a greater information subsequence length @xmath332 and decoded with a smaller decoding delay @xmath354 outperforms the systematic bmst - r code constructed with a small information subsequence length @xmath355 and decoded with a greater decoding delay @xmath356  ( both have the same decoding latency of 12000 bits ) .",
    "we also compare the performance of systematic bmst - r codes , non - systematic bmst - r codes in  @xcite , and sc - ldpc codes when the decoding latencies are equal , as shown in fig .",
    "[ fig_equaldecodinglatency ] .",
    "all the codes have rate 0.49 .",
    "we restrict consideration to @xmath347-regular sc - ldpc codes with two component submatrices @xmath357 $ ] and @xmath358 $ ] , and @xmath348-regular sc - ldpc codes with two component submatrices @xmath359 $ ] and @xmath360 $ ] .",
    "the decoding delays for @xmath347-regular sc - ldpc codes and @xmath348-regular sc - ldpc codes are @xmath349 and @xmath350 , respectively , which are good choices to achieve optimum performance when the decoding latencies are fixed .",
    "the encoding memories for non - systematic bmst - r codes and systematic bmst - r codes are 8 and 16 , respectively .",
    "the values of the information subsequence length and decoding delay for the non - systematic bmst - r codes are chosen such that the combination gives the best decoding performance  ( see section  vi - a of  @xcite ) .",
    "the decoding delays for the systematic bmst - r codes are @xmath339 , @xmath351 , @xmath37 , @xmath352 .",
    "we observe that the systematic bmst - r codes perform better than both the non - systematic bmst - r codes and the sc - ldpc codes .",
    "for example , in the decoding latency of 12000 bits , the systematic bmst - r code with information subsequence length @xmath332 and decoding delay @xmath354 gains 0.12 db , 0.21 db and 0.24 db , respectively , compared to the non - systematic bmst - r code , @xmath347-regular sc - ldpc code , and @xmath348-regular sc - ldpc code .      in this subsection , we show the performance of systematic bmst - r codes with different rates by varying repetition degree @xmath18 and puncturing fraction @xmath42 .     and data block length @xmath361 . the repetition degree @xmath18 ,",
    "encoding memories @xmath7 and puncturing fraction @xmath42 are specified in the legends .",
    "the decoding delay is specified as @xmath362 .",
    "the codeword is modulated using bpsk and transmitted over an awgn channel .",
    "the corresponding lower bounds  ( dotted magenta ) for systematic bmst - r codes are also plotted .",
    "the rates of the systematic bmst - r codes corresponding to the ber curves from left to right in the figure are @xmath363 and @xmath364 . ]     for systematic bmst - r codes with information subsequence length @xmath365 .",
    "the codeword is modulated using bpsk and transmitted over an awgn channel .",
    "the performances of three ar4ja ldpc codes with code rates @xmath366 , @xmath367 and @xmath368 in the ccsds standard  @xcite , and five pbrl ldpc codes  @xcite with code rates @xmath369 , @xmath370 , @xmath366 , @xmath367 , and @xmath368 , all of which have information length @xmath371 , are also included . ]    consider systematic bmst - r codes with information subsequence length @xmath365 and data block length @xmath361 .",
    "the encoding memories @xmath7 for systematic bmst - r codes required to approach the shannon limits at a target ber of @xmath307 are determined following the procedure described in section  [ seciv - a ] .",
    "the decoding delay is specified as @xmath362 .",
    "simulation results for systematic bmst - r codes with different rates are shown in fig .",
    "[ fig_bermultirate ] .",
    "we observe that the performances for all code rates are almost the same as that for uncoded code in the relatively low snr region .",
    "this is different from non - systematic bmst codes whose performance in the relatively low snr region is very bad due to error propagation .",
    "we also observe that , as the snr increases , the performance curves of the systematic bmst - r codes drop down to the respective lower bounds for all considered code rates .",
    "to evaluate the bandwidth efficiency , we plot the required snr to achieve a ber of @xmath307 of the systematic bmst - r codes with information subsequence length @xmath365 against the code rate in fig .",
    "[ fig_requiredsnrmultirate ] , where we observe that the systematic bmst - r codes achieve the ber of @xmath307 within one db from the shannon limits for all considered code rates . in fig .",
    "[ fig_requiredsnrmultirate ] , we also include the simulation results of three ar4ja ldpc codes with code rates @xmath366 , @xmath367 and @xmath368 in the ccsds standard  @xcite , and five pbrl ldpc codes  @xcite with code rates @xmath369 , @xmath370 , @xmath366 , @xmath367 , and @xmath368 , all of which have information length @xmath371 .",
    "we observe that the systematic bmst - r codes have a similar performance as both ar4ja ldpc codes and pbrl ldpc codes over such code rates .",
    "note that no simulation results were reported for ar4ja ldpc codes and pbrl ldpc codes with rates less than @xmath369 , while codes of all rates of interest in the interval ( 0,1 ) can be constructed using the systematic bmst - r construction .",
    "actually , to the best of our knowledge , no other methods were reported along with simulations in the literature that can construct good rate - compatible codes over such a wide range of code rates .",
    "all the examples above assume that the subcodewords are modulated using bpsk and transmitted over an awgn channel . in this subsection ,",
    "we study the performance of systematic bmst - r codes transmitted over a block fading channel .",
    "the word - error - rate  ( wer ) is defined as the ratio between the number of erroneous subcodewords and the total number of subcodewords transmitted .",
    "assume that the subcodeword @xmath40 is modulated using bpsk with 0 and 1 mapped to @xmath43 and @xmath44 , respectively , and transmitted over a block fading channel , resulting in a received vector @xmath45 expressed as @xmath372 for @xmath373 , where @xmath48 is the @xmath49-th component of @xmath45 , @xmath50 is a sample from an independent gaussian random variable with distribution @xmath51 , and @xmath374 is a fading coefficient . in this paper",
    ", we consider a rayleigh fading channel , where @xmath374 is a sample from a rayleigh distribution @xmath375 with @xmath376=1 $ ] . for block fading channels with a coherence period of @xmath377 symbols , we assume that @xmath374  ( perfectly known at the receiver ) remains constant over @xmath377 symbols within the same period and is independent identically distributed across different coherence periods .     systematic bmst - r codes with information subsequence length @xmath378 , repetition degree @xmath313 and puncturing fraction @xmath300 over a block fading channel .",
    "the encoding memories are @xmath379 and @xmath380 .",
    "the decoding delay is specified as @xmath342 . ]    , encoding memory @xmath344 , repetition degree @xmath313 , and puncturing fraction @xmath300 , and decoded with decoding delay @xmath381 .",
    "the @xmath347-regular sc - ldpc codes is constructed with the protograph lifting factor 100 and three component submatrices @xmath382 $ ] , and decoded with decoding delay @xmath381 .",
    "the decoding latencies of two codes are the same . ]    consider @xmath331 systematic bmst - r codes with information subsequence length @xmath378 , repetition degree @xmath313 and puncturing fraction @xmath300 .",
    "the subcodewords are modulated using bpsk and transmitted over a block fading channel with a coherence period of @xmath383 symbols .",
    "that is , a subcodeword @xmath40 has @xmath384 independent fading values .",
    "the wer curves of systematic bmst - r codes constructed with encoding memory @xmath379 and @xmath380 , and decoded with decoding delay @xmath342 are shown in fig .  [ fig_pbmst_diff_m_fadingchannel ] , where we observe that the performance of systematic bmst - r code improves with increasing encoding memory @xmath10 until @xmath344 and then it degrades slightly as @xmath10 increases further .",
    "this implies that @xmath344 is a good choice for optimum performance .",
    "the performance comparison of the systematic bmst - r code and the sc - ldpc code over a block fading channel is shown in fig .",
    "[ fig_pbmst_scldpc_fadingchannel ] .",
    "the systematic bmst - r code is constructed with information subsequence length @xmath378 , encoding memory @xmath344 , repetition degree @xmath313 , and puncturing fraction @xmath300 , and decoded with decoding delay @xmath381 .",
    "the @xmath347-regular sc - ldpc code is constructed with the protograph lifting factor 100 and three component submatrices @xmath382 $ ] , and decoded with decoding delay @xmath381 presented in  @xcite .",
    "thus , the decoding latencies of two codes are the same .",
    "we see from fig .",
    "[ fig_pbmst_scldpc_fadingchannel ] that , in the low wer region , the systematic bmst - r code performs better than the @xmath347-regular sc - ldpc code under the equal decoding latency constraint .",
    "for example , at a wer of @xmath306 , the systematic bmst - r code gains about one db compared to the equal latency @xmath347-regular sc - ldpc code .",
    "these results confirm that systematic bmst - r codes without any further optimization can perform well over block fading channels .",
    "in this paper , we have proposed systematic block markov superposition transmission  ( bmst ) of repetition codes , referred to as systematic bmst - r codes . using both extending and puncturing , systematic bmst - r codes support a wide range of code rates but maintain essentially the same encoding / decoding hardware structure .",
    "the systematic bmst - r codes not only preserve the advantages of the original non - systematic bmst codes , namely , low encoding complexity , effective sliding window decoding algorithm and predictable error floors , but also have improved decoding performance especially in short - to - moderate decoding latency . a simple lower bound and an upper bound",
    "were derived to analyze the performance of systematic bmst - r codes under map decoding .",
    "simulation results show that , over an awgn channel , 1 )  the performance of systematic bmst - r codes around or below the ber of @xmath307 can be predicted by the lower bound ; 2 )  systematic bmst - r codes can approach the shannon limit at a ber of @xmath307 within one db for a wide range of code rates ; and 3 )  systematic bmst - r codes can outperform both non - systematic bmst codes and sc - ldpc codes in the waterfall region under the equal decoding latency constraint .",
    "simulation results also show that , systematic bmst - r codes without any further optimization can outperform @xmath347-regular sc - ldpc codes over a block fading channel .",
    "a final note is that the construction of systematic bmst - r codes can be extended to high - order abelian groups since only addition is required during the encoding process .",
    "the authors would like to thank prof .",
    "costello from university of notre dame for his helpful comments on the performance lower bounds . the second author , ever visiting university of notre dame for one year as an exchange student , is also grateful to prof .",
    "costello for his insightful supervision on the related research .",
    "the authors would also like to thank dr . chulong liang and dr .",
    "jia liu for helpful discussions .",
    "s.  kudekar , t.  j. richardson , and r.  l. urbanke , `` threshold saturation via spatial coupling : why convolutional ldpc ensembles perform so well over the bec , '' _ ieee trans .",
    "theory _ , vol .",
    "57 , no .  4 , pp . 803834 ,",
    "m.  lentmaier , a.  sridharan , d.  j. costello , jr . , and k.  s. zigangirov , `` iterative decoding threshold analysis for ldpc convolutional codes , '' _ ieee trans .",
    "inf . theory _",
    "56 , no .",
    "52745289 , oct .",
    "s.  kudekar , t.  j. richardson , and r.  l. urbanke , `` spatially coupled ensembles universally achieve capacity under belief propagation , '' _ ieee trans .",
    "theory _ , vol .",
    "59 , no .  12 , pp .",
    "77617813 , dec . 2013 .",
    "x.  ma , c.  liang , k.  huang , and q.  zhuang , `` block markov superposition transmission : construction of big convolutional codes from short codes , '' _ ieee trans .",
    "inf . theory _ ,",
    "61 , no .  6 , pp .",
    "31503163 , june 2015 .",
    "a.  r. iyengar , m.  papaleo , p.  h. siegel , j.  k. wolf , a.  vanelli - coralli , and g.  e. corazza , `` windowed decoding of protograph - based ldpc convolutional codes over erasure channels , '' _ ieee trans .",
    "inf . theory _ ,",
    "58 , no .  4 ,",
    "pp . 23032320 , apr .",
    "2012 .",
    "a.  e. pusane , a.  j. felstrm , a.  sridharan , m.  lentmaier , k.  s. zigangirov , and d.  j. costello , jr .",
    ", `` implementation aspects of ldpc convolutional codes , '' _ ieee trans .  commun . _ , vol .  56 , no .  7 , pp .",
    "10601069 , july 2008 .",
    "s.  kumar , a.  j. young , n.  macris , and h.  d. pfister , `` threshold saturation for spatially coupled ldpc and ldgm codes on bms channels , '' _ ieee trans .",
    "theory _ , vol .",
    "60 , no .  12 , pp .",
    "73897415 , dec . 2014 .",
    "i.  sason and s.  shamai , `` performance analysis of linear codes under maximum - likelihood decoding : a tutorial , '' in _ foundations and trends in communications and information theory _ , vol .  3 , no . 1 - 2.1em plus",
    "0.5em minus 0.4emdelft , the netherlands : now , 2006 , pp . 1225 .",
    "k.  huang , d.  g.  m. mitchell , l.  wei , x.  ma , and d.  j. costello , jr .",
    ", `` performance comparison of ldpc block and spatially coupled codes over gf@xmath385 , '' _ ieee trans .",
    "_ , vol .",
    "63 , no .  3 , pp . 592604 , mar .",
    "2015 .    _ tm synchronization and channel coding ",
    "summary of concept and rationale _ , consultative committee for space data systems  ( ccsds ) std .",
    ", nov . 2012 .",
    "[ online ] .",
    "available : http://public.ccsds.org/publications/archive/130x1g2.pdf    n.  ul  hassan , m.  lentmaier , i.  andriyanova , and g.  p. fettweis , `` improving code diversity on block - fading channels by spatial coupling , '' in _ proc .",
    "symp . on inf .",
    "theory _ , honolulu , hi , june 2014 , pp . 23112315 ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose systematic block markov superposition transmission of repetition  ( bmst - r ) codes , which can support a wide range of code rates but maintain essentially the same encoding / decoding hardware structure . </S>",
    "<S> the systematic bmst - r codes resemble the classical rate - compatible punctured convolutional  ( rcpc ) codes , except that they are typically non - decodable by the viterbi algorithm due to the huge constraint length induced by the block - oriented encoding process . </S>",
    "<S> the information sequence is partitioned equally into blocks and transmitted directly , while their replicas are interleaved and transmitted in a block markov superposition manner . by taking into account that the codes are systematic </S>",
    "<S> , we derive both upper and lower bounds on the bit - error - rate  ( ber ) under maximum _ a posteriori _  ( map ) decoding . </S>",
    "<S> the derived lower bound reveals connections among ber , encoding memory and code rate , which provides a way to design good systematic bmst - r codes and also allows us to make trade - offs among efficiency , performance and complexity . </S>",
    "<S> numerical results show that :  1 )  the proposed bounds are tight in the high signal - to - noise ratio  ( snr ) region ;  2 )  systematic bmst - r codes perform well in a wide range of code rates ; and  3 )  systematic bmst - r codes outperform spatially coupled low - density parity - check  ( sc - ldpc ) codes under an equal decoding latency constraint </S>",
    "<S> .    block markov superposition transmission  ( bmst ) , lower bounds , maximum _ a posteriori _  ( map ) decoding , rate - compatible codes , upper bounds , sliding window decoding , systematic codes . </S>"
  ]
}