{
  "article_text": [
    "the flexible image transport system ( fits ) is the standard data format for astronomical observed data even though they are products through calibration pipelines or otherwise .",
    "one fits file can store multiple ccd images and photon event lists as tables , and this feature makes fits format prevail from the radio band to the x - ray band .",
    "especially , most archival datasets and source catalogs are provided as fits files in these days .",
    "the original purpose of the fits format was to transport digital astronomical images from a computer to another with a magnetic tape @xcite .",
    "there were no unified standard for computers at that time , and bit size assigned to a character and an integer was quite different from one model to another , even from the same makers .",
    "thus the authors newly had to create a machine independent and future expandable image format for data exchange , fits . since then",
    "the fits format has been repeatedly extended to agree with astronomical needs of the day ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) .    however , we will look at the issue of astronomical data inflation , not of the format , in the years ahead ; atacama large millimeter / submillimeter array ( alma ) , which is the largest radio telescope built on the chajnantor plateau in northern chile , started observations last year .",
    "alma is estimated to generate @xmath0200  tb observational raw data every year , and the volume of a processed 4-dimensional data cube ( 2d image ) @xmath1 ( spectrum ) @xmath1 ( polarization ) ] for one target may exceed @xmath22  tb @xcite .",
    "furthermore , large synoptic survey telescope ( lsst ) , a project in 2020s , will generate 30  tb data every night .",
    "we need a system which assists astronomers to find something interested in such big data .",
    "looking at such future , national astronomical observatory of japan has been developing a large data providing system for alma utilizing the technology of virtual observatory ( vo ) to share our outputs with global astronomical communities ; all processed datasets ( fits files ) are hosted on a vo server , and an user can select cut - out region to download by a web - based graphical user interface ( * ? ? ?",
    "* paper i hereafter ) .",
    "a prototype service is already public , and i am working on its optimization now .",
    "the system has to process a tb scale data cube in a few 10 seconds for users convenience , thus it is planned to equip a very high - speed disk array 4  gb / s read / write performance . ] and disk i / o speed and data processing one will be comparable .",
    "all the components of the system consist of intel platform , which adopts little endian , while the fits format does big endian . for",
    "the interactive tb size fits file processing system , the endian conversion time is not negligible .    in this paper ,",
    "i introduce a technique to make the endian conversion time apparently disappear , and to make the system much faster by multiprocessing .",
    "i describe the hardware and software configuration for evaluation in section  2 , and compare endian conversion algorithms and their performance in section  3 . in section 4 ,",
    "i examine the best timing for endian conversion , and discuss the performance increase by the conversion timing in section 5 . through the paper",
    ", i repeated measurements 100 times for each item , and adopted its sample standard deviation ( a square root of unbiased variance ) as 1-@xmath3 statistical error , ignoring any systematic ones .",
    "ccc cpu & intel core i7 - 2600 ( 3.4  ghz ) & amd fx-8350 ( 4.0  ghz ) + ram & 8  gb ( @xmath4  gb / s ) & 16  gb ( @xmath5  gb / s ) + storage & ssd ( read : @xmath6  mb / s ) & hdd ( read : @xmath7  mb / s ) + operating system & + c / c++ compiler & + fits library & +    14,321 pixels ( 3.4  gb ) . [ fig - test - image ] ]    table  [ tab - configuration ] shows the hardware and software configuration used for verification of the method .",
    "i used two types of cpus , intel core i7 - 2600 ( for machine a ) and amd fx-8350 ( for machine b ) , to prevent bias due to microarchitecture . through the paper , intel turbo boost technology ( the former ) and amd turbo core technology ( the latter )",
    "are disabled by bios for simplicity .",
    "in addition , intel hyper - threading technology ( the former ) is also disabled for the same reason .",
    "thus machine a and b are available 4 and 8 physical processors , respectively . the memory bandwidths and storage speeds were obtained the following commands : ` dd if=/dev / zero of=/dev / null bs=1 g count=100 ` , and ` hdparm -t ( device ) ` , respectively .    the same software is installed in both computers : ubuntu 12.04.1 lts ( amd64 ) , a debian based 64-bit linux , for operating system , gnu compiler collection ( gcc ) version 4.6 for c / c++ compiler ( ` gcc`/`g++ ` ) , and cfitsio version 3.310 for c language fits library @xcite .",
    "i applied the ` -o2 -pipe",
    "-wall ` compile options to cfitsio and programs used in the paper .",
    "the streaming simd extensions 2 ( sse2 ) codes in cfitsio was enabled since i built the library on a 64-bit linux , but the ssse3 option was disabled since the ssse3 instruction set is treated as an extension in the amd64 environment .",
    "i use a false color mosaic image of carina nebula obtained with hubble space telescope for test data .",
    "the image is public in tagged image file format ( tiff ) , thus i converted it into a gray scale double precision fits file with ` convert ` command provided by imagemagick .",
    "the size is 29,566 pixels in width and 14,321 pixels in height .",
    "the file volume is 3.4  gb ( figure  [ fig - test - image ] ) . through the paper",
    ", i put this fits file on a tmpfs @xcite mounted on ` /run",
    "/ shm ` , to ensure that the file is always on memory for fast access .",
    "see appendix  [ sec - tmpfs ] for the difference between tmpfs and ramdisk .",
    "for the endian conversion of a 64-bit value .",
    "[ fig - operator - sigma ] ]      let @xmath8 be a byte sequence of an internal expression of a 64-bit size value @xmath9 .",
    "the 64-bit endian conversion of @xmath9 can be expressed with a permutation @xmath3 as @xmath10 where @xmath11 in cauchy s two - line notation , and @xmath12 ( figure  [ fig - operator - sigma ] ) .        a straightforward implementation of eq .",
    "( [ eq - endian - conversion1 ] ) and eq .",
    "( [ eq - endian - conversion2 ] ) can be written as follows :    .... uint64_t byte_shuffle(uint64_t a ) {    unsigned char * p = ( unsigned char * ) & a ;    unsigned char tmp ;      tmp = p[7 ] ; p[7 ] = p[0 ] ; p[0 ] = tmp ;    tmp = p[6 ] ; p[6 ] = p[1 ] ; p[1 ] = tmp ;    tmp = p[5 ] ; p[5 ] = p[2 ] ; p[2 ] = tmp ;    tmp = p[4 ] ; p[4 ] = p[3 ] ; p[3 ] = tmp ;      return a ; } ....",
    "i now call this method `` byte shuffle '' .",
    "one will find a short discussion about another implementation of byte shuffle algorithm in appendix  [ sec - another - byteshuffle ] .",
    "another implementation to perform endian conversion is to use both bit shift and logical operations :    .... uint64_t bit_shift(uint64_t a ) {    return    ( ( a & 0x00000000000000ffull )               < < 56 )           | ( ( a & 0x000000000000ff00ull )               < < 40 )           | ( ( a & 0x0000000000ff0000ull )               < < 24 )           | ( ( a & 0x00000000ff000000ull )               <",
    "< 8)           | ( ( a & 0x000000ff00000000ull )               > > 8)           | ( ( a & 0x0000ff0000000000ull )               > > 24 )           | ( ( a & 0x00ff000000000000ull )               > > 40 )           | ( ( a & 0xff00000000000000ull )               > > 56 ) ; } ....    hereafter , i call this method `` bit shift '' .",
    "intel i486 and later processors have the ` bswap ` instruction , which converts the endian on a given 32-bit register .",
    "the instruction is extended in order to accept a 64-bit register in amd64 @xcite .",
    "furthermore , gcc version 4.3 and later have a helper function to call the instruction , and its prototype is ` uint64_t _ _ builtin_bswap64(uint64_t x ) ; ` .",
    "now i call endian conversions utilizing this function `` ` bswap ` '' .",
    "sse2 is a set of vector instructions for intel platform , became a part of default instruction set for amd64 environment .",
    "the endian conversion codes utilizing sse2 can process two 64-bit values at once , and be written as follows :    .... # include < emmintrin.h > void sse2(uint64_t a[2 ] ) {    _ _",
    "m128i r0 = _ mm_load_si128((__m128i * ) a ) ;                  //",
    "r0 < - a    _ _",
    "m128i r1 = _ mm_srli_epi16(r0 , 8) ;                  //",
    "8-bit shifts towards right                  // for four 2-byte integers    _ _",
    "m128i r2 = _ mm_slli_epi16(r0 , 8) ;                  //",
    "8-bit shifts towards left                  // for four 2-byte integers    r0 = _ mm_or_si128(r1 , r2 ) ;                  // 128-bit or operation                  // on r1 and r2    r0 = _ mm_shufflelo_epi16(r0 ,                 _",
    "mm_shuffle(0 , 1 , 2 , 3 ) ) ;                  //",
    "byte shuffle for the                  //",
    "lower half of r0 register    r0 = _ mm_shufflehi_epi16(r0 ,                 _ mm_shuffle(0 , 1 , 2 , 3 ) ) ;                  //",
    "byte shuffle for the                  // higher half of r0 register    _ mm_store_si128((__m128i * ) a , r0 ) ;                  // a < - r0 } ....    there are almost the same codes in cfitsio and sllib / sfitsio .",
    "i call these codes simply `` sse2 '' , hereafter .",
    "another vector instruction set called `` ssse3 '' is available for intel core series and later cpus . utilizing this instruction set",
    ", one can perform endian conversion of two 64-bit values at one instruction .",
    "an example is follows :    .... # include",
    "< tmmintrin.h > void ssse3(uint64_t a[2 ] ) {    static const _ _ m128i mask      = _ mm_set_epi8 (          8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 ,          0 , 1 , 2 , 3 , 4 , 5 , 6 , 7        ) ;    _ _ m128i r = _ mm_load_si128((__m128i * ) a ) ;    _ _ m128i r = _ mm_shuffle_epi8(r , mask ) ;    _ mm_store_si128((__m128i * ) a , r ) ; } ....    there are almost same codes in cfitsio too .",
    "i call these codes simply `` ssse3 '' , hereafter",
    ".    cccccc machine a & @xmath13 & @xmath13 & @xmath14 & @xmath15 & @xmath16 + machine b & @xmath17 & @xmath18 & @xmath19 & @xmath20 & @xmath21 +      to see which one is fastest and how they behave towards parallelization , i performed simple benchmark . in the benchmark , i reserved a ` double`-type array whose number of elements were set to 29,566@xmath2214,321 = 423,414,686 , just the number of pixels in figure  [ fig - test - image ] , and filled the array for uniform real random numbers of 32-bit resolution on @xmath23 $ ] generated with mersenne twister @xcite .",
    "the results are summarized in table  [ tab - endian - conversion - algorithm ] . for machine",
    "a , three algorithms except for ssse3 and byte shuffle process the test data in about 410 milliseconds , while ssse3 does about 370 millisecond . on the other hand , for machine b , four algorithms except for byte shuffle process the test data in about 600 milliseconds , and the sse2 algorithm is fastest in the all ones .",
    "the byte shuffle algorithm is slowest by one oder compared to the others .",
    "cccccc 1 & @xmath13 & @xmath24 & @xmath25 & @xmath26 & @xmath27 + 2 & @xmath28 & @xmath28 & @xmath29 & @xmath30 & @xmath31 + 3 & @xmath32 & @xmath32 & @xmath32 & @xmath33 & @xmath34 + 4 & @xmath35 & @xmath35 & @xmath35 & @xmath36 & @xmath37 +    cccccc 1 & @xmath38 & @xmath39 & @xmath40 & @xmath41 & @xmath42 + 2 & @xmath43 & @xmath44 & @xmath43 & @xmath45 & @xmath46 + 3 & @xmath47 & @xmath48 & @xmath49 & @xmath50 & @xmath51 + 4 & @xmath52 & @xmath53 & @xmath52 & @xmath54 & @xmath55 + 5 & @xmath56 & @xmath57 & @xmath58 & @xmath59 & @xmath60 + 6 & @xmath61 & @xmath62 & @xmath63 & @xmath64 & @xmath65 + 7 & @xmath66 & @xmath67 & @xmath68 & @xmath69 & @xmath70 + 8 & @xmath71 & @xmath72 & @xmath73 & @xmath74 & @xmath75 +      i also examined the cpu - scalability of these algorithms .",
    "i adopted ` pthread ` for parallelization , and simply divided the array containing the test data into equal - size segments so that the total number of the segments were equal to the number of threads .",
    "then i assigned each thread with each segment .",
    "figure  [ fig - endian - algorithm ] represents the results .",
    "i also list the observed values for detailed comparison of the algorithms in table  [ tab - endian - conversion - algorithm - scalabilitya ] ( for machine a ) and table  [ tab - endian - conversion - algorithm - scalabilityb ] ( for machine b ) . except for byte shuffle algorithm ,",
    "i observed @xmath76 performance gain for machine a , and @xmath77 up to four threads for machine b with the four algorithms .",
    "it seems strange that the memory bandwidth of machine b is sufficient for the test data size but the four algorithms show performance cutoff at four threads .",
    "i performed detailed hardware benchmark utilizing lmbench , and found that context switching time and the latency of l2 cache memory normalized in cpu cycles of machine b are 2.4 times and 4.6 times , respectively , larger than those of machine a. hence i conclude that there are some hardware bottlenecks in machine b , which cause the plateau in figure  [ fig - endian - algorithm ] .",
    "the behaviors of the four algorithms with respect to the number of threads are very similar , and i adopt bit shift algorithm in the next section because of its compiler portability and identicalness to ` bswap ` ( see appendix  [ sec - bitshift - bswap ] ) .",
    "a modern cpu has multiple arithmetic logic units ( alus ) and instruction pipelines to boost the operating rates of alus .",
    "as seen in the previous section , the hardware limitation lies just below the endian conversion time of single thread ( figure  [ fig - endian - algorithm ] , machine a ) , preventing the cpu scalability .",
    "this may lead to many holes ( or `` no operation '' instructions ) in the pipelines and reduce the performance .",
    "if this is the case , shuffling instructions in source codes can produce improvement .    to verify this assumption ,",
    "i disabled the endian conversion functionality in cfitsio ; i changed the ` byteswapped ` macros for i386 and amd64 architectures from ` true ` into ` false ` in ` fitsio2.h ` , and commented out the codes which cfitsio perform runtime check to verify whether the machine endian definition by the above macro is consistent with the execution environment in ` cfileio.c ` , and i rebuilt the library .",
    "the patches for those files are shown in appendix  [ sec - cfitsio - patch ] .",
    "i compare the following two methods ;    1 .",
    "it loads the full test image ( figure  [ fig - test - image ] ) from tmpfs ( see  [ sec - configuration ] ) onto an array , then it converts the endian by the parallelized bit shift algorithm ( described in  [ sec - endian - multithread ] ) , and it sums up all the elements . 2 .",
    "it loads the full test image onto an array , and it sums up all the elements with converting the endian one after another by the bit shift algorithm .    from here , i refer to the former as `` on ahead endian conversion method '' , and to the latter as `` just - in - time endian conversion method '' .    on ahead endian conversion method can be written as follows :    .... {    double * v ;    // an array to store                 // a fits image    size_t len ;   // the length of                 // the array v      // load a byte sequence from a fits    // file into v here ...       //",
    "endian conversion    for ( size_t i = 0 ; i < len ; + + i ) {      uint64_t * p = ( uint64_t * ) & v[i ] ;      uint64_t a = bit_shift(*p ) ;      double * q = ( double * ) & a ;      v[i ] = * q ;    }      // process v here ... } ....    and just - in - time endian conversion method can be written as follows :    .... {    double * v ;    // an array to store                 // a fits image    size_t len ;   // the length of                 // the array v      //",
    "load a byte sequence from a fits    //",
    "file into v here ...      //",
    "image processing ...",
    "{      // something ...           // one needs to refer the value      // of v[i ] here           //",
    "endian conversion      uint64_t * p = ( uint64_t * ) & v[i ] ;      uint64_t a = bit_shift(*p ) ;      double * q = ( double * ) & a ;      double x = * q ;      // use x instead of v[i ] below        // something ...    } } ....    where ` bit_shift ( ) ` is the endian conversion function defined in  [ sec - definition - bit - shift ] .    in this section ,",
    "i adopt summing up all the elements in the test image as an example of image processing .",
    "i implemented both methods in single thread and performed benchmark .",
    "the codes of on ahead conversion method are following :    .... {    // endian conversion    for ( size_t i = 0 ; i < len ; + + i ) {      uint64_t * p = ( uint64_t * ) & v[i ] ;      uint64_t a = bit_shift(*p ) ;      double * q = ( double * ) & a ;      v[i ] = * q ;    }      // summation    double sum = 0.0 ;    for ( size_t i = 0 ; i < len ; + + i ) {      sum + = v[i ] ;    } } ....    and those of just - in - time endian conversion method are following :    .... {    double sum = 0.0 ;    for ( size_t i = 0",
    "; i < len ; + + i ) {      // endian conversion      uint64_t * p = ( uint64_t * ) & v[i ] ;      uint64_t a = bit_shift(*p ) ;      double * q = ( double * ) & a ;        // summation      sum + = * q ;    } } ....    note that the former codes are identical to those with original cfitsio .    the results are summarized in table  [ tab - fitsprocess - single ] .",
    "i obtained slightly faster ( @xmath78 ) total processing time of @xmath79 sec and @xmath80 sec for machine a and b , respectively , with on ahead endian conversion method , while that with original cfitsio is @xmath81 and @xmath82 for machine a and b , respectively .    on the other hand , i obtained significantly faster time of @xmath83 and @xmath84 for machine a and b , respectively , which corresponds to @xmath85 performance gain , with just - in - time endian conversion method .",
    "i made both methods multithreaded by utilizing openmp apis for its simple implementation .",
    "the codes of just - in - time endian conversion method , for example , are below :    .... {    double sum = 0.0 ;    # pragma omp parallel for reduction ( + : sum)\\\\ schedule ( auto )    for ( size_t i = 0 ; i < len ; + + i ) {      // endian conversion      uint64_t * p = ( uint64_t * ) & v[i ] ;      uint64_t a = bit_shift(*p ) ;      double * q = ( double * ) & a ;        // summation      sum + = * q ;    } } ....    on the other hand , i could not find the best parameters in openmp apis for the endian conversion routine in on ahead conversion method , hence i applied openmp only to the summation routine , and adopted the ` pthread`-based parallelization described in  [ sec - endian - multithread ] for the endian conversion routine in on ahead conversion method ; the number of the threads for openmp was set to that for the endian conversion .",
    "the results obtained with these programs are summarized in table  [ tab - fitsprocess - multithread - a ] ( for machine a ) , table  [ tab - fitsprocess - multithread - b ] ( for machine b ) , figure  [ fig - fits - processing ] ( for on ahead endian conversion method ) , and figure  [ fig - fits - processing - lazy ] ( for just - in - time endian conversion method ) .",
    "note that the endian conversion time of on ahead endian conversion method is included in the fits reading time .",
    "the total time to perform the same things with the original cfitsio in single thread is superimposed on these figures as a dotted line : @xmath81 seconds for machine a , and @xmath82 seconds for machine b.    for the on ahead endian conversion method , the total time slightly scales the number of threads and gets faster than original cfitsio , while the file reading time ( including endian conversion time ) seems to be little scalable .",
    "the scalability of the total time mostly owes that of the summation routine , and the parallelization of the endian conversion has little impact due to the hardware limit seen in ",
    "[ sec - endian - multithread ] .",
    "on the other hand , for the just - in - time endian conversion method , the total time is interestingly smaller than that of original cfitsio even for single thread .",
    "the summation routine seems to be scalable almost in the full range , while the total time scales up to four threads .",
    "ccccc & machine a & @xmath86 & @xmath87 & @xmath79 + & machine b & @xmath88 & @xmath89 & @xmath80 + & machine a & @xmath90 & @xmath91 & @xmath83 + & machine b & @xmath92 & @xmath93 & @xmath94 +    ccccc & 1 & @xmath95 & @xmath96 & @xmath81 + & 2 & @xmath97 & @xmath98 & @xmath99 + & 3 & @xmath100 & @xmath101 & @xmath102 + & 4 & @xmath103 & @xmath104 & @xmath105 + & 1 & @xmath106 & @xmath107 & @xmath108 + & 2 & @xmath109 & @xmath110 & @xmath111 + & 3 & @xmath109 & @xmath112 & @xmath113 + & 4 & @xmath114 & @xmath104 & @xmath115 +    ccccc & 1 & @xmath116 & @xmath117 & @xmath118 + & 2 & @xmath119 & @xmath120 & @xmath121 + & 3 & @xmath122 & @xmath123 & @xmath124 + & 4 & @xmath125 & @xmath126 & @xmath127 + & 5 & @xmath128 & @xmath129 & @xmath130 + & 6 & @xmath125 & @xmath131 & @xmath132 + & 7 & @xmath133 & @xmath134 & @xmath135 + & 8 & @xmath136 & @xmath137 & @xmath135 + & 1 & @xmath138 & @xmath139 & @xmath140 + & 2 & @xmath141 & @xmath142 & @xmath143 + & 3 & @xmath144 & @xmath145 & @xmath146 + & 4 & @xmath144 & @xmath147 & @xmath148 + & 5 & @xmath149 & @xmath150 & @xmath151 + & 6 & @xmath149 & @xmath152 & @xmath153 + & 7 & @xmath154 & @xmath155 & @xmath156 + & 8 & @xmath141 & @xmath157 & @xmath158 +",
    "there is a well - known equation to estimate the increase by parallelization , amdahl s law @xcite : @xmath159 where @xmath160 and @xmath161 represent processing time in single thread and mult - thread cases , respectively , @xmath162 is the ratio of codes which parallelization methods are applied to term .",
    "] , @xmath163 is the number of threads , and @xmath164 is the overhead caused by parallelization .    to quantify the performance increase of on ahead endian conversion method and just - in - time endian conversion method",
    ", i performed model fitting to the total time of both methods with eq.([eq - amdahl ] ) .",
    "i found that @xmath165 while the fitting , thus i fixed @xmath164 at 0 .",
    "the results are summarized in table  [ tab - endian - conversion - amdahl ] and figure  [ fig - amdahl ] .",
    "the increasing rates of performance compared to original cfitsio ( @xmath166 for machine a and @xmath167 for machine b ) are also listed in the table .",
    "the figure shows that the above results are explained well by amdahl s law , and that the on ahead endian conversion method for single thread has almost the same performance as original cfitsio .",
    "in fact , these two agree with each other in @xmath168 errors according to the table .",
    "the table also suggests that multi - threading boosts this method up about 20% . considering the parallelization rate @xmath169",
    ", one can not expect further speed up by multi - threading in @xmath170 .",
    "this suggests that the bottlenecks of other hardwares disrupt order in the instruction pipelines and leads to the decrease of operating ratio of alus .    on the other hand ,",
    "the just - in - time endian conversion method is 20% faster than both of original cfitsio and the single thread version of on ahead one , surprisingly .",
    "this seems as if the endian conversion process disappeared . in the parallelized case ,",
    "the just - in - time conversion method is 40% faster than the others in single thread .",
    "however , the performance increase by multi - threading can be expected only in @xmath171 since the parallelization rate @xmath169 , due to the hardware bottlenecks mentioned above .",
    "for further investigation , i fitted the summation time of these methods with eq.([eq - amdahl ] ) to investigate the impact of the endian conversion codes in the summation routine on performance ; there are endian conversion codes in the summation routine in case of just - in - time endian conversion method , but not in case of on ahead endian conversion method .",
    "the results are summarized in table  [ tab - amdahl - sumup ] and figure  [ fig - amdahl - sumup ] .",
    "i found that the parallelization rate @xmath172 in both cases , and that the ratio of @xmath160 of just - in - time endian conversion method against that of on ahead one @xmath173 was equal to @xmath174 for machine a and @xmath175 for machine b. there is no overhead of endian conversion in the summation routine , since the shift of @xmath176 from unity is not significant statistically .",
    "thus i conclude that endian conversion is so simple operation for a modern cpu that the bottlenecks of other hardwares disrupt order in the instruction pipelines ; to prevent the disruption , the endian conversion should be done just before a value is referred .",
    "ccccccc & machine a & @xmath177 & @xmath178 & 0.09 ( 2 ) & @xmath179 & @xmath180 + & machine b & @xmath181 & @xmath182 & 49@xmath183 ( 6 ) & @xmath184 & @xmath185 + & machine a & @xmath186 & @xmath187 & 0.5 ( 2 ) & @xmath188 & @xmath189 + & machine b & @xmath190 & @xmath191 & 8.5 ( 6 ) & @xmath192 & @xmath193 +    ccccc & machine a & @xmath194 & @xmath195 & 127.9 ( 2 ) + & machine b & @xmath196 & @xmath197 & 491.1 ( 6 ) + & machine a & @xmath198 & @xmath199 & 913.4 ( 2 ) + & machine b & @xmath200 & @xmath201 & 312.7 ( 6 ) +            ]    ccc @xmath202 & @xmath203 & @xmath204 + @xmath205 & @xmath206 & @xmath207 + @xmath208 & @xmath209 & @xmath210 + @xmath211 & @xmath212 & @xmath213 + @xmath214 & @xmath215 & @xmath216 + @xmath217 & @xmath218 & @xmath219 + @xmath220 & @xmath221 & @xmath222    ccc @xmath202 & @xmath223 & @xmath224 + @xmath205 & @xmath225 & @xmath226 + @xmath208 & @xmath227 & @xmath228 + @xmath211 & @xmath229 & @xmath230 + @xmath214 & @xmath231 & @xmath232 + @xmath217 & @xmath233 & @xmath234 + @xmath220 & @xmath235 & @xmath236          from here , i only investigated the performance increase of summing up all the elements in a large fits file by just - in - time endian conversion method . in this subsection ,",
    "i apply the method to almawebql , our interactive web viewer for alma data cubes described in paper i , to obtain more realistic benchmark data . for realistic and fair comparison ,",
    "the sse2 boosted endian conversion codes in cfitsio are enabled for on ahead endian conversion method , while there is no sse2 code in just - in - time endian conversion method .",
    "alma data cubes not contain information of polarization currently , and they are simple 3-dimensional fits files ( figure  [ fig - alma - data - cube ] ) . for image extraction , one have to integrate the cube along the spectral direction ; for spectrum extraction , one convolute all spatial information .",
    "i measured the time to complete these computations in single thread with various size data on machine a. the results for image extraction are summarized in table  [ tab - almawebql - image ] , and those for spectrum extraction are summarized in table  [ tab - almawebql - spectrum ] . from these tables , i obtain @xmath237 @xmath238 for image extraction and @xmath239 @xmath240 for spectrum extraction , where @xmath241 and @xmath242 represent the time with on ahead and just - in - time endian conversion methods , respectively , and @xmath243 is file size in the mb unit ( figure  [ fig - almawebql ] ) . hence just - in - time endian conversion method in single thread is @xmath244 faster than on ahead conversion method boosted by sse2 above @xmath245 .",
    "this demonstrates that just - in - time endian conversion method can be very powerful when one performs convolution and stacking of very large images , which are very common analysis techniques in optical band , obtained with future large telescopes .",
    "in this paper , i only treated a double precision fits file , but one could expect almost the same results for float and ` long ` data types , which correspond to ` bitpix ` @xmath246 -32 and 32 , respectively ; as demonstrated in appendix  [ sec - bitshift - bswap ] , ` bit_shift ( ) ` function is compiled into ` bswap ` instruction .",
    "the amd64 architecture can handle both of 32 bit and 64 bit operation codes and their operands seamlessly . on the other hand ,",
    "for byte and short data type , there may be little advantage of just - in - time endian conversion method since ` bswap ` instruction can not take any 16 bit values as its operand , and up - casting into 32 bit integer always occurs in arithmetic operations in both cases .",
    "the fits format was originally developed to exchange digital astronomical datasets from a computer to another , but the progress of computation power and software technology enables one to process fits files through web browsers .",
    "in addition , data size has been inflating year by year , and it will exceed @xmath0  tb in the year ahead . to handle such big fits file with web applications , the endian conversion time from the fits native to the machine one can not be negligible , and a solution for this problem is required .    in this paper , i compared the features of four typical endian conversion algorithms under multi - thread environment , and found the bit shift one was suitable for parallelization",
    ". then i examined the best timing for endian conversion under multi - thread environment .",
    "i found that one should postpone the endian conversion until a value is really referred in a program , because endian conversion is so simple for a modern cpu that the bottlenecks of other hardwares disrupt order in the instruction pipelines , which leads to the decrease of operating ratio of alus .",
    "in fact , by applying this method to loading 3.4  gb fits file and sum up all the elements , the performance increased 20% for single thread and 40% for multi - thread compared to cfitsio , which corresponded to @xmath247 milliseconds , and one can be aware of the speed - up .",
    "no overhead of endian conversion was found on the summation routine ; hence one can sweep the endian conversion time out of his / her codes . note that parallelization of this method peaked out in four threads in the experiment .",
    "cpu vendors introduce various techniques , such as speculative execution and branch prediction , to improve the efficiency of instruction pipelines ; an executed instruction code sequence is apart from a programmed one . in this context ,",
    "modern cpus partially break `` causality '' , a programmed instruction code sequence , and gain speed .",
    "just - in - time endian conversion method utilizes such boosting technology .",
    "there is nothing new in the method , but it must be a small step to handle astronomical big data generated by the next generation telescopes .",
    "i greatly appreciate dr .  chisato yamauchi , who is my colleague and the author of sllib / sfitsio , for rewarding discussions .",
    "both tmpfs and ramdisk are a data space allocated on memory .",
    "one has to specify the size in advance for ramdisk , while one does not set the size for tmpfs in advance necessarily since it is under control of virtual memory manager and shares swap space .",
    "when an application requests the operating system for memory blocks and when there does not remain sufficient physical memory space , the memory manager firstly swap out the files on tmpfs .",
    "tmpfs is ideal space to put temporal files which one requires very fast access to .",
    "one can also implements byte shuffle algorithm as follows :    .... uint64_t byte_shuffle2(uint64_t a ) {    unsigned char * p = ( unsigned char * ) & a ;    uint64_t b ;    unsigned char * q = ( unsigned char * ) & b ;      q[0 ] = p[7 ] ;    q[1 ] = p[6 ] ;    q[2 ] = p[5 ] ;    q[3 ] = p[4 ] ;    q[4 ] = p[3 ] ;    q[5 ] = p[2 ] ;    q[6 ] = p[1 ] ;    q[7 ] = p[0 ] ;      return b ; } ....    the number of assignments of the codes ( @xmath248 ) is less than that shown in the main part of this paper ( @xmath249 ) , and one would expect further performance improvement .",
    "i disassembled both two codes compiled with the ` -o2 ` option , and obtained followings :    .... 0000000000000000 < byte_shuffle > :     0 :    49 89 fa                 mov     % rdi,%r10     3 :    49 89 f8                 mov     % rdi,%r8     6 :    89 fe                    mov     % edi,%esi     8 :    48 89 f9                 mov     % rdi,%rcx     b :    89 fa                    mov     % edi,%edx     d :    48 89 f8                 mov     % rdi,%rax    10 :    40 88 7c 24 ff           mov     % dil,-0x1(%rsp )    15 :    48 c1 e8 20              shr     $ 0x20,%rax    19 :    49 c1 ea 38              shr     $ 0x38,%r10    1d :    49 c1 e8 30              shr     $ 0x30,%r8    21 :    66 c1 ee 08              shr     $ 0x8,%si    25 :    48 c1 e9 28              shr     $ 0x28,%rcx    29 :    c1 ea 10                 shr     $ 0x10,%edx    2c :    c1 ef 18                 shr     $ 0x18,%edi    2f :    44 88 54 24 f8           mov     % r10b,-0x8(%rsp )    34 :    40 88 74 24 fe           mov     % sil,-0x2(%rsp )    39 :    44 88 44 24 f9           mov     % r8b,-0x7(%rsp )    3e :    88 54 24 fd              mov     % dl,-0x3(%rsp )    42 :    88 4c 24 fa              mov     % cl,-0x6(%rsp )    46 :    40 88 7c 24 fc           mov     % dil,-0x4(%rsp )    4b :    88 44 24 fb              mov     %",
    "al,-0x5(%rsp )    4f :    48 8b 44 24 f8           mov",
    "-0x8(%rsp),%rax    54 :    c3                       retq     ....    , and    .... 0000000000000000 < byte_shuffle2",
    "> :     0 :    49 89 fa                 mov     % rdi,%r10     3 :    49 89 f9                 mov     % rdi,%r9     6 :    49 89 f8                 mov     % rdi,%r8     9 :    48 89 fe                 mov     % rdi,%rsi     c :    89 f9                    mov     % edi,%ecx     e :    89 fa                    mov     % edi,%edx    10 :    89 f8                    mov     % edi,%eax    12 :    49 c1 ea 38              shr     $ 0x38,%r10    16 :    49 c1 e9 30              shr     $ 0x30,%r9    1a :    66 c1 e8 08              shr     $ 0x8,%ax    1e :    49 c1 e8 28              shr     $ 0x28,%r8    22 :    48 c1 ee 20              shr     $ 0x20,%rsi    26 :    c1 e9 18                 shr     $ 0x18,%ecx    29 :    c1 ea 10                 shr     $ 0x10,%edx    2c :    44 88 54 24 f8           mov     % r10b,-0x8(%rsp )    31 :    44 88 4c 24 f9           mov     % r9b,-0x7(%rsp )    36 :    44 88 44 24 fa           mov     % r8b,-0x6(%rsp )    3b :    40 88 74 24 fb           mov     %",
    "sil,-0x5(%rsp )    40 :    88 4c 24 fc              mov     % cl,-0x4(%rsp )    44 :    88 54 24 fd              mov     % dl,-0x3(%rsp )    48 :    88 44 24 fe              mov     % al,-0x2(%rsp )    4c :    40 88 7c 24 ff           mov     % dil,-0x1(%rsp )    51 :    48 8b 44 24 f8           mov     -0x8(%rsp),%rax    56 :    c3                       retq     ....    , that is , there are less assignments in ` byte_shuffle2 ( ) ` ( @xmath248 ) than ` byte_shuffle ( ) ` ( @xmath249 ) , however , the former binary codes are longer than the latter ones . hence one can not expect more performance gain with the codes .",
    "the bit shift endian conversion codes is actually identical to ` bswap ` instruction when compiled with the optimization option of ` -o2 ` .",
    "the disassembled codes obtained with ` objdump -d ` command are below :    .... 0000000000000000 < bit_shift",
    "> :     0 :    48 89 f8                 mov     % rdi,%rax     3 :    48 0f c8                 bswap   % rax     6 :    c3                       retq     ....    cccccc machine a & @xmath250 & @xmath251 & @xmath252 & @xmath253 & @xmath254 + machine b & @xmath255 & @xmath256 & @xmath257 & @xmath258 & @xmath259 +",
    "it is ensured that the leading memory address ( alignment ) of an array is always in multiplies of 16 ( 16-byte alignment ) in amd64 architecture . however",
    ", if one would like to read a file in multi - thread , he / she has to make the copy of the file image on memory . in such case , the alignment is not always 16-byte .",
    "thus i performed the benchmark described in ",
    "[ sec - endian - benchmark ] ( single thread case ) but made alignment of the arraya random number .    for the benchmark , i modified `",
    "_ mm_load_si128 ( ) ` and ` _ mm_store_si128 ( ) ` in the sse2 codes into ` _ mm_loadu_si128 ( ) ` and ` _ mm_storeu_si128 ( ) ` , respectively , to make the codes operable .",
    "the results are summarized in table  [ tab - endian - conversion - algorithm - ramdom ] .",
    "the trend found in  [ sec - endian - single - thread ] is roughly true in this case though the all algorithms are slightly slower ( within a few % ) than 16-byte alignment case . hence one does not have to get nervous about memory alignment .",
    ".... * * * fitsio2.h.org    2013 - 03 - 08 14:19:49.560538980 + 0900 --- fitsio2.h    2013 - 01 - 15 14:43:10.000000000 + 0900 * * * * * * * * * * * * * * * * * * 96,102 * * * *       # elif defined(__ia64 _",
    "_ )   || defined(__x86_64 _ _ )                      / *   intel itanium 64-bit pc , or amd opteron 64-bit pc * / ! # define byteswapped true    # define longsize 64          # elif defined(_sx )              / * nec superux * / --- 96,103 ----       # elif defined(__ia64 _ _ )   || defined(__x86_64 _ _ )                      / *   intel itanium 64-bit pc , or amd opteron 64-bit pc * / ! / * # define byteswapped true * / ! # define byteswapped false    # define longsize 64          # elif defined(_sx )              / * nec superux * / * * * * * * * * * * * * * * * * * * 169,175 * * * *       / *   generic 32-bit ibm pc * /    # define machine ibmpc ! #",
    "define byteswapped true       # elif defined(__arm _ _ )     --- 170,178 ----       / *   generic 32-bit ibm pc * /    # define machine ibmpc ! / * # define byteswapped true * / ! #",
    "define byteswapped false",
    "!        # elif defined(__arm _ _ )     ....      .... * * * cfileio.c.org    2013 - 03 - 08 14:20:09.052539296 + 0900 --- cfileio.c    2013",
    "- 01 - 16 19:57:46.000000000 + 0900 * * * * * * * * * * * * * * * * * * 3763,3769 * * * *        }           / *    test for correct byteswapping .    * / !",
    "u.ival = 1 ;        if   ( ( byteswapped & & u.cval[0 ] !",
    "= 1 ) ||             ( byteswapped = = false & & u.cval[1 ] ! = 1 ) ) --- 3763,3769 ----        }           / *    test for correct byteswapping .",
    "* / ! / *        u.ival = 1 ;        if   ( ( byteswapped & & u.cval[0 ] !",
    "= 1 ) ||             ( byteswapped = = false & & u.cval[1 ] ! = 1 ) ) * * * * * * * * * * * * * * * * * * 3776,3782 * * * *          ffunlock ;          return(1 ) ;        } !                    /",
    "*   test that longlong is an 8 byte integer * /         --- 3776,3782 ----          ffunlock ;          return(1 ) ;        } !",
    "* /                   / *   test that longlong is an 8 byte integer * /         ....    00 amdahl , g.  m. , proceedings of the april 18 - 20 , 1967 , spring joint computer conference , afips 67 ( spring ) , 483 eguchi , s. , kawasaki , w. , shirasaki , y. , et al .",
    "2012 , arxiv:1211.3790 greisen , e.  w. , & harten , r.  h.  1981 , , 44 , 371 grosbol , p. , harten , r.  h. , greisen , e.  w. , & wells , d.  c.  1988 , , 73 , 359 intel corporation , 2012 , intel 64 and ia-32 architectures software developer s manuals , volume 2a , 3 - 78 lucas , r. , richer , j. , shepherd , d. , testi , l. , wright , m. , & wilson , c.  2004 , alma memo # 501 matsumoto , m. , & nishimura , t. , 1998 , acm trans . model .",
    "simul . , 8 , 3 pence , w.  d.  2010 , astrophysics source code library , 10001 rohland , c. , 2001 , http://www.kernel.org/doc/documentation/filesystems/tmpfs.txt wells , d.  c. , greisen , e.  w. , & harten , r.  h.  1981 , , 44 , 363"
  ],
  "abstract_text": [
    "<S> the fits is the standard file format in astronomy , and it has been extended to agree with astronomical needs of the day . however , astronomical datasets have been inflating year by year . in case of alma telescope , </S>",
    "<S> a @xmath0 tb scale 4-dimensional data cube may be produced for one target . considering that typical internet bandwidth is a few 10 mb / s at most , </S>",
    "<S> the original data cubes in fits format are hosted on a vo server , and the region which a user is interested in should be cut out and transferred to the user @xcite . </S>",
    "<S> the system will equip a very high - speed disk array to process a tb scale data cube in a few 10 seconds , and disk i / o speed , endian conversion and data processing one will be comparable . hence to reduce the endian conversion time is one of issues to realize our system . in this paper , </S>",
    "<S> i introduce a technique named `` just - in - time endian conversion '' , which delays the endian conversion for each pixel just before it is really needed , to sweep out the endian conversion time ; by applying this method , the fits processing speed increases 20% for single threading , and 40% for multi - threading compared to cfitsio . </S>",
    "<S> the speed - up by the method tightly relates to modern cpu architecture to improve the efficiency of instruction pipelines due to break of `` causality '' , a programmed instruction code sequence . </S>"
  ]
}