{
  "article_text": [
    "stochastic processes enter physics because of some reduced or incomplete description in terms of variables whose states at earlier times do not uniquely determine their future states .",
    "unless we go to infinite scale separations and treat the relevant set of variables as for example in the hydrodynamic limit , we expect that the reduced description allows for fluctuations and randomness in the dynamics .",
    "we then speak about the mesoscopic level of description for which reproducibility which is so typical for the macroscopic world , is not available yet .",
    "furthermore , the resulting or effective descriptions in terms of stochastic dynamics can not always be reliably treated within the markov approximation . that markovian level would also require particular time - scale separations such that the random evolution becomes essentially memoryless .",
    "one easily looses the markov property when the landscape of states and their mutual connections are getting very complicated and some further coarse - graining collects various states into one , if only to simplify things .",
    "for example in the theory of spin glasses , by combining various local minima of the free energy in one state and depending on the various activation energies , one could effectively obtain stretched exponential waiting time distributions . or , for transport in strongly disordered systems , one can think that conduction is the result of a large series of hops , and the effective or total hopping rate must convolute different exponentials , cf .",
    "mott s variable range hopping  @xcite . for biophysical processes such as in molecular motors or in ion channels",
    "one observes gate states that are either at the beginning or at the end of a series of states that appear different only in some minor ( internal ) rearrangement of molecules .",
    "the passage from entrance to exit through these internal and largely hidden states can again give rise to nonexponential waiting time distributions .",
    "see @xcite for specific biomolecular realizations . in the examples that follow in section [ exa ]",
    ", we present a very simple scenario of such a transport problem .",
    "the natural probabilistic environment is then that of semi - markov processes , @xcite .",
    "other scenario s can be due to the random nature of energy levels such as conjectured in blinking quantum dots for which the phenomenology suggests power law waiting time distributions , @xcite .",
    "+ the purpose of the present paper is to investigate the role of entropy fluxes and of dynamical activity in the fluctuation theory for semi - markov processes .",
    "such a theory has been investigated for markov jump and markov diffusion processes in the light of recent studies in nonequilibrium statistical mechanics , @xcite .",
    "it remains important to characterize the fluctuation functionals in their physical role away from the strict markovian context .",
    "going now beyond these markov processes , we are especially interested in the influence and in the role of the waiting time distribution in the dynamical fluctuations .",
    "after all , it parameterizes a time - symmetric factor in the transition events , whose influence on the joint occupation and current statistics needs to be understood . in this sense",
    ", we go here also beyond previous approaches ( e.g.  @xcite ) , where only the time - antisymmetric factor is considered .",
    "our results give detailed expressions for the fluctuation functionals and we interpret the role of the waiting time distribution in them .",
    "we provide some more results in the regime of small fluctuations , where we prove that the current and occupation fluctuations decouple close to equilibrium . here",
    "we also conclude that occupation fluctuations are in a sense more sensitive to non - markovian behaviour than current fluctuations .",
    "+ the next section contains a brief introduction to the world ( and the notation ) of semi - markov processes .",
    "further elements of the semi - markov theory are recalled in the appendix .",
    "we then move to a general introduction on dynamical fluctuation theory , which contains our main formulations of the fluctuation functionals for semi - markov processes .",
    "subsections are devoted to some corollaries and to the interpretation of these functionals . that includes a fluctuation symmetry for the entropy production and in section [ small ] the treatment of small fluctuations around a nonequilibrium state .",
    "we end in section [ exa ] with examples of semi - markovian transport in rings for which our results are getting fully explicit ( for small fluctuations ) . in a more specific example",
    "we also compute the generating function and the first few cumulants for the current fluctuations .",
    "we consider jump processes on a finite space @xmath0 with states denoted by @xmath1 the updating is time - homogeneous and in continuous time .",
    "semi - markov processes are non - poissonian with a renewal property .",
    "this means that the probability of a jump from @xmath2 to @xmath3 at a certain time depends only on the states @xmath2 , @xmath3 and the time @xmath4 since the last jump occurred .",
    "more precisely , let us denote @xmath5 for the density of random transitions at time @xmath4 from the state @xmath2 to @xmath3 .",
    "this so called semi - markov kernel defines the process .",
    "further it is useful to introduce @xmath6 which are respectively the waiting ( or sojourn ) time distribution in @xmath2 and the transition probabilities regardless of the waiting time , and @xmath7 the probability that the system rests at state @xmath2 for at least time @xmath4 . in the sequel",
    "we always assume that @xmath8 , @xmath9 asymptotically for @xmath10 so that the first and the second moments with respect to the distributions @xmath11 are finite .",
    "an important role plays the effective escape rate @xmath12 from @xmath2 defined as the reciprocal to the average sojourn time in @xmath2 , i.e. , @xmath13 we say that the semi - markov process enjoys time - direction independence when @xmath14 that is the case when the waiting time only depends on the present ( and not on the future ) state .",
    "we make that assumption throughout the paper .",
    "see section and for a specific ( counter)example .",
    "if the process is markov then @xmath15 with @xmath16 the escape rate from state @xmath2 ; the product @xmath17 is called the transition rate .",
    "the effective escape rates are @xmath18 .",
    "+ further elements of the theory of semi - markov processes are summarized in the appendix . in particular , there we review a derivation of the ( generalized ) master equation , and its formulation from the point of view of an embedded markov chain .",
    "more details are of course available in the literature , see e.g.  @xcite for physics introductions .      we add here some ingredients of the theory of semi - markov processes that relate to the statistical mechanics we are going for in the next section . + as explained in the appendix , see   and section  [ sta ] , the stationary distribution @xmath19 solves the stationarity equation @xmath20 where @xmath21 is the stationary ( probability ) current from state @xmath2 to @xmath3 .",
    "remark that this equation coincides with the stationarity condition for a continuous time markov process with transition rates @xmath22 .",
    "in particular , the stationary distribution and currents depend on the waiting time distributions only through the effective escape rates .",
    "+ in this paper we go beyond the above stationary characterization of the semi - markov process and we want to understand the structure of fluctuations of the occupations and currents around their stationary values , i.e. , to develop a dynamical fluctuation theory for these processes . for that we need more details about the process and a natural starting point is the path - space distribution evaluating the plausibility of trajectories .",
    "this was the general idea of onsager and machlup , @xcite .",
    "here we follow the strategy developed in  @xcite for markov systems . +",
    "a path @xmath23 specifies the sequence of states together with the jump times , @xmath24 in order to construct a transient semi - markov process started from a given initial distribution @xmath25 at time zero , we make a `` stationarity '' assumption about the history of the process in negative times : we let the age of an initial configuration sampled from @xmath25 be random and conditionally distributed according to the stationary process .",
    "then the resulting path space distribution @xmath26 giving the probability of a path @xmath27 has the density @xmath28 in which @xmath29 is the waiting time distribution for the initial interval @xmath30 $ ] , taking into account the random ( stationarily distributed ) age of the initial configuration @xmath31 at time zero when the process starts .",
    "similarly , the last term , @xmath32 , comes out by integrating the waiting time distribution @xmath33 over all possible times of the first jump outside the time interval , @xmath34 .",
    "note that for @xmath35 the above construction yields a stationary process .",
    "the apparent similarity between the first and the last terms in  , representing the past and the future of the process , will be exploited next in the analysis of the time - reversal symmetry and its breaking .",
    "any open system weakly coupled to its environment and being in thermal equilibrium with the latter has to satisfy two general conditions that directly follow from first principles : ( i ) its stationary distribution has the canonical form @xmath36 with @xmath37 the energy of the system and @xmath38 the bath temperature , and ( ii ) the ( effective ) stochastic dynamics of the system is symmetric under time - reversal .",
    "this symmetry can be broken either by starting the dynamics from a nonstationary condition ( i.e. , in transients ) , or provided the system is coupled to several thermal reservoirs mutually not in thermal equilibrium ( i.e. , in transport processes ) .",
    "then the dynamics of the system is no longer time - reversal symmetric , however , this symmetry is broken in a very specific way : a natural ` measure ' of irreversibility , see below , coincides with the change of entropy together in the system and in the environment . for a general argument see , e.g. , @xcite .",
    "next we specify these considerations to the semi - markov processes . + as a standard measure of irreversibility of the process we consider the path - dependent quantity defined as the relative plausibility of a path with respect to its time - reversed counterpart . introducing the time - reversal @xmath39 of a path",
    "@xmath40 as @xmath41 or @xmath42 cf .  , we define @xmath43 where @xmath44 is the distribution at time @xmath45 as evolved from the @xmath25 at time zero , i.e. , the solution of the generalized master equation   or  .",
    "as we restrict ourselves to the case of time - direction independence , equation ( [ pathentropy ] ) considerably simplifies to @xmath46 which is formally the same as one has for a markov process with escape rates @xmath47 .",
    "assume first that the system is in thermal equilibrium with a heat bath .",
    "then @xmath35 is given by   and , by time - reversibility , @xmath48 , pathwise .",
    "this is equivalent to @xmath49\\ ] ] which is a generalized detailed balance condition ( recall that in the markov case , @xmath50 are transition rates ) . using  ,",
    "this is further equivalent to the absence of all stationary currents , @xmath51 .",
    "a rigorous argument for the equivalence between the ( generalized ) detailed balance condition and the time - reversibility of time - direction independent semi - markov processes can be found in  @xcite .",
    "remark that the assumption of time - direction independence is crucial here and can not be easily abandoned .    to make a step beyond thermal equilibrium ,",
    "observe first that the right - hand side of   reads @xmath52 times the heat flux (= entropy flux ) into the heat bath , per a single transition @xmath53 in the system .",
    "this is clearly a global condition since all the local entropy fluxes derive from a potential ( or state quantity ) @xmath54 .",
    "however , it has a natural local variant that only requires that @xmath55 no matter whether the entropy fluxes derive from a potential or not .",
    "physically this corresponds to a system coupled to several heat baths on nonequal temperatures , assuming that each transition @xmath53 is assisted by no more than one reservoir .",
    "the condition   is called local detailed balance .",
    "when modeling a particular physical process , we usually take the individual entropy fluxes per each transition as _ a priori _ known , cf .",
    "@xcite .    under the local detailed balance condition ,",
    "the path quantity @xmath56 is the sum of two terms : of the difference @xmath57 which is to be understood as the variable entropy increase in the system ( one checks that its expectation equals the increase in shannon entropy ) , and of the total entropy flux into environment .",
    "the latter adds up contributions from all transitions along the random trajectory .",
    "+ let us conclude here with two remarks : first of all , local detailed balance is not a mathematical condition but rather a general guiding principle to be followed when modeling an arbitrary open system driven out of equilibrium . it is mainly because of this that we restrict ourselves to time - direction independent processes . for time - direction",
    "dependent processes the assumption of local detailed balance does not seem to make sense .",
    "furthermore , a direct consequence of local detailed balance is a symmetry in the fluctuations of the time - integrated entropy flux and also of the time - integrated currents ( fluctuation theorems ) .",
    "it follows easily from via standard manipulations .",
    "see also  @xcite for another and more detailed approach .      by construction , the entropy flux",
    "is intimately related to the time - antisymmetric part in the logarithmic probabilities ( or action ) . in order to separate more explicitly the time - symmetric sector of fluctuations from the time - antisymmetric one",
    ", we will make a parametrization , inspired by the markov case  @xcite : there one relates the transition rates @xmath58 to an equilibrium reference process with rates @xmath59 so that @xmath60 and @xmath61 .",
    "( one checks that for a markov processes such a representation always exists ) . by local detailed balance",
    ", @xmath62 can be seen as ( @xmath38 times ) the work done by an extra ( with respect to the reference ) force along the transition @xmath63 .    as a generalization",
    ", we consider as a suitable equilibrium reference system another semi - markov process with the waiting time distributions @xmath64 such that @xmath65 $ ] derives from a potential ( the global detailed balance condition ) and that the waiting times of the original and the reference processes are related by  @xcite @xmath66 for some @xmath67 .",
    "the term @xmath68 is a compensator fixed by the normalization condition @xmath69 note that the parametrization   preserves the time - direction independence property . by comparing with condition   of local detailed balance ,",
    "the entropy flux per transition @xmath53 reads @xmath70 with some potential @xmath71 that is explicitly computable .",
    "the process breaks the ( global ) detailed balance unless @xmath62 also derives from a potential .",
    "we can therefore say that @xmath62 is the forcing of the process .",
    "the decomposition of the entropy flux into potential and nonpotential parts is hence fixed by comparing to a particularly chosen reference equilibrium .    here",
    "is how we split the action into , respectively , a time - antisymmetric and a time - symmetric parts . from  , the logarithmic density of our process with respect to the equilibrium reference process @xmath72 is @xmath73 where @xmath74 denotes that we have only taken the time - extensive part , and neglected temporal boundary terms that will become redundant . in the first term",
    "the sum is over all jump times in @xmath27 and by it is equal to the total ( i.e. , time - integrated ) entropy flux along path @xmath40 , for the original process .",
    "the second term in   is manifestly time - symmetric and it can be understood as a time - undirected dynamical activity , or what we have called traffic in  @xcite ( relatively with respect to the reference dynamics . )",
    "the path - space average of   with respect to our process gives its dynamical or also called , kolmogorov - sinai entropy  the relative entropy between the process and its reference as distributions on paths .",
    "the decomposition   suggests to define two functionals which take averages over the two terms in   separately .",
    "they will appear later ; for the stationary regime with stationary density @xmath19 we divide by @xmath45 and let @xmath75 to write @xmath76 with @xmath77 the quantity @xmath78 is the stationary average of the entropy flux per unit time .",
    "note that it does not depend on the particular choice of the reference equilibrium process as it is insensitive to adding any potential difference to the driving @xmath79 .",
    "the second component of the dynamical entropy , @xmath80 , measures the stationary dynamical activity in the sense of its `` excess '' with respect to the equilibrium dynamics taken as a reference .",
    "equilibrium statistical mechanics provides us with a fluctuation theory through which the thermodynamic potentials can also be understood as fluctuation functionals .",
    "natural variables for these functionals usually are the energy and particle densities , the magnetization or still other characteristics of an equilibrium state .",
    "the precise formulation of all that is found in the theory of large deviations as pioneered by boltzmann , planck , and einstein , which starts from the identification of the thermodynamic entropy with the logarithm of a probability , see e.g.  @xcite .",
    "we call this a static fluctuation theory where the main extensive parameter is the spatial volume or the number of particles",
    ". that also has an extension to spatially extended systems out of equilibrium but there is no simple way of determining the stationary distribution .",
    "the difficulties with its direct determination can be overcome by analyzing typical paths along which macroscopic fluctuations get spontaneously created , via exploiting methods of analytical mechanics .",
    "the fluctuation functionals , often called nonequilibrium free energies , are then found to solve an appropriate hamilton - jacobi equation @xcite .",
    "in contrast , dynamical fluctuation theory deals with deviations from stationary behavior that are observed over a large time period .",
    "this formulation is most useful for mesoscopic systems in contact with large external reservoirs , where these fluctuations can be visible on the level of the system .",
    "an immediate consequence is the variational characterizations of the steady state regime , much as the gibbs variational principle characterizes thermal equilibrium from the minimum of a free energy functional . beyond that",
    ", the question is once more whether the corresponding ( now , dynamical ) fluctuation functionals allow for a natural physical interpretation , whether they can provide relations between quantities directly accessible via measurement etc .",
    "indeed , we recall that in equilibrium the onsager - machlup theory constructs actions for the distribution of macroscopic histories that relate to response coefficients and to dissipation functions , @xcite",
    ". it would be most interesting to obtain an extension of these functionals to reach domains further away from equilibrium and also in situations different from those of fluctuating hydrodynamics .",
    "here we consider the set - up of semi - markovian jump processes ; the markov case has been discussed in @xcite .",
    "the questions can however be put in a more general context , as now follows .",
    "+ we consider a path ( or history or trajectory ) and we observe the occupation of states and the various transitions over states in some large time - interval @xmath81 $ ] .",
    "more precisely , we first look at the fraction of time that the system spends in a state @xmath82 for one specific path @xmath27 : @xmath83\\,{\\textrm{d}}t\\ ] ] where @xmath84 $ ] is @xmath85 whenever @xmath86 and zero otherwise . obviously , @xmath87 , defines a probability law but it is itself random as dependent on the stochastic trajectory @xmath27 .",
    "we assume that these paths are drawn from the unique steady state with stationary density @xmath19 .",
    "then , as time @xmath75 we have convergence of @xmath88 to that @xmath89 ; that corresponds to an assumption of ergodicity .",
    "secondly we define the empirical densities of jumps between states @xmath2 and @xmath3 : @xmath90\\,\\delta[x_{t+ } = y]\\ ] ] where the sum is over all jump times and @xmath91 are the configurations before and after the jump , respectively .",
    "again , that is a random quantity , typically converging for large @xmath45 to @xmath92 .",
    "finally there is the empirical current @xmath93 the question of our dynamical fluctuation theory is to see and to physically understand the asymptotic statistics for @xmath88 and @xmath94 .",
    "what values do these assume and with what probability ?",
    "in other words , we take a probability law @xmath25 on @xmath0 and a family @xmath95 with @xmath96 and we ask for the steady state probability @xmath97 \\propto e^{-t\\,i(\\mu , j)}\\ ] ] as @xmath75 , to realize these @xmath25 and @xmath98 along the trajectories .",
    "we already suggest here that there exists a rate function @xmath99 which exactly picks up the leading order in @xmath45 . that rate function is the legendre transform of the log - generating function of the occupation and current statistics which would give more direct access to the various cumulants , but we will not need these here .",
    "our ambition here is not so much on the computational but rather on the conceptual level , to understand what is the generic structure of @xmath99 as well as its possible physical configuration . in particular , we want to stress the similarities and the differences with markov processes , and to recognize the influence of modifying the waiting time distribution . as we will see explicitly in the examples of section [ exa ] , both the current and the occupation statistics do pick up also higher moments of the waiting time distribution , yielding markers for non - markovian behavior .",
    "the fluctuation functionals appearing as rate functions such as the @xmath99 in the exponent of , are understood as relative entropy densities , see @xcite for an introduction to the systematic theory of large deviations .",
    "the relative entropy is between a modified and the original process where the modified process is chosen such as to make the deviations typical . in our case , we deal with temporal processes and the relative entropy density is like the rate of change of dynamical entropies between the two processes . more specifically , to compute @xmath100:={{\\mathbb p}}[\\mu_t \\simeq \\mu\\,;\\ , j_t \\simeq j]$ ]",
    ", we define a new semi - markov process in the following way : @xmath101 where @xmath102 , with @xmath103 and @xmath104 . comparing",
    "with we see that @xmath105 is of the form @xmath106 hence , @xmath107 .",
    "most important now , we require that @xmath25 and @xmath98 are stationary in this new ( modified ) dynamics , i.e. , @xmath108 in terms of these new quantities the joint fluctuation functional reads @xmath109 indeed , by using the explicit form   of the path - space measure we get @xmath110 = \\int dp_{\\mu}(\\omega)\\delta[\\mu_t=\\mu , j_t = j ]   = \\int dp_{\\mu}^{*}(\\omega)\\frac{dp_{\\mu}}{dp^{*}_{\\mu}}(\\omega)\\delta[\\mu_t=\\mu , j_t = j]\\ ] ] where @xmath111\\\\ & = & -\\frac{t}{4 } \\sum_{x , y } j_t(x , y)f(x , y)-t\\sum_x\\mu_t(x)\\delta(x)\\end{aligned}\\ ] ] note that we have only written the extensive part in time , because we are considering the large time limit anyway . continuing the computation , we now see that : @xmath110 =   e^{-\\frac{t}{4}\\sum_{x , y }   j(x , y)f(x , y)-t\\sum_x\\mu(x)\\delta(x)}\\int dp_{\\mu}^{*}(\\omega )   \\delta[\\mu_t=\\mu , j_t = j]\\ ] ] finally , in the large time limit we have that @xmath112\\approx 1 $ ] , because @xmath25 and @xmath98 are typical in the modified process .",
    "therefore the probability of the fluctuations has the asymptotic form : @xmath110 \\propto e^{-t i(\\mu , j)}\\ ] ] with @xmath99 given in ( [ imuj ] ) .",
    "a subquestion concerns the time - symmetric fluctuation sector ; to understand the statistics of the occupations _ alone_. that means to look at and to write similarly to , @xmath113 \\propto e^{-t\\,i(\\mu)}\\ ] ] to find the fluctuation functional @xmath114 of only the occupation statistics , one can perfectly repeat the argument for occupation - current statistics above , but this time it suffices to restrict oneself to the class of modified processes driven by gradient forces , @xmath115 . again , the point is that the potential @xmath116 can be chosen such that it makes @xmath25 typical .",
    "the result for the occupation fluctuation functional is @xmath117 we see that @xmath118 appears as the quantity to average over with @xmath25 , for expressing the rate at which the system deviates from the @xmath119statistics .",
    "we can interpret @xmath120 as the excess traffic of the modified process that makes @xmath121 typical , with respect to the original process : @xmath122 where the traffic functional is defined as @xmath123 to be compared with . using ( [ deltacond ] ) , we can deduce the response relation @xmath124 with @xmath125 the expected transient current for a fluctuation @xmath25 in a dynamics as in determined by @xmath79 . in this sense",
    ", the traffic can be understood as a potential with respect to the currents ; cf .  similar remarks for the markov processes , @xcite . however , in contrast with the latter , the traffic   does not allow for a simple `` kinematic '' interpretation in terms of an expected number of jumps irrespectively of their direction .",
    "we now turn to the antisymmetric fluctuation sector , where we recover the fluctuation theorem , cf .",
    "this is a direct consequence of the local detailed balance we have proposed in section [ sm ] : indeed , local detailed balance dictates that ( the extensive part of ) the entropy production is @xmath126 where @xmath127 is again the empirical current . as a consequence : @xmath128 & = & \\int { \\textrm{d}}{{\\mathbb p}}(\\omega)\\,\\delta[j_t = j]\\\\ & = & \\int { \\textrm{d}}{{\\mathbb p}}(\\theta\\omega)\\,e^{\\frac{t}{2}\\sum_{x , y}j_t(x , y)g(x , y)}\\,\\delta[j_t = j]\\\\ & = & e^{\\frac{t}{2}\\sum_{x , y}j(x , y)g(x , y)}\\int { \\textrm{d}}{{\\mathbb p}}(\\omega)\\delta[j_t = -j]\\end{aligned}\\ ] ] which means that @xmath129 } { { { \\mathbb p}}[j_t \\simeq -j ] } \\propto e^{\\frac{t}{2}\\sum_{x , y}j(x , y)g(x , y)}\\ ] ] again asymptotically for @xmath130 , i.e. , up to temporal boundary terms . indeed and we already concluded in  , because of local detailed balance , @xmath62 is the generalized thermodynamic force for the transition @xmath53 in the entropy production .",
    "taking the logarithm and the limit @xmath75 , formula establishes a symmetry in the dynamical fluctuations of the entropy production , cf .",
    "@xcite .    for convenience ,",
    "we add in the next section some more details concerning the physical interpretation of various players in the dynamical fluctuation theory , along with the comparison to the markov case .      in the fluctuation",
    "functionals two new quantities appear : @xmath120 and @xmath131 .",
    "the meaning of @xmath131 can be made clear through local detailed balance .",
    "we already know that for the original process , local detailed balance means that @xmath132 where @xmath133 is the entropy flux between system and reservoir per jump from @xmath2 to @xmath3 , see . for the modified process",
    "we find @xmath134 where now @xmath135 is the excess entropy flux of the modified process with respect to the original process and is given by @xmath136 this means that , again up to some ` potential difference , ' ( the last two terms in ) the term @xmath131 is the extra force one adds to the system to make @xmath25 and @xmath98 stationary . for a markov process this extra ` potential ' becomes zero .",
    "when the process is not markov we still have that @xmath137 whenever the stationarity condition @xmath96 is fulfilled .",
    "in particular , this means that the potential terms do not make a time - extensive contribution to the total entropy flux since along any trajectory , the empirical currents @xmath94 always satisfy that stationarity condition up to corrections @xmath138 . in this sense , the second term in the joint fluctuation functional @xmath99 functional",
    "can really be called an excess entropy flux .",
    "+ we have mentioned already above how the quantity @xmath120 appears . in the case of a markov process , @xmath120 is simply ( minus ) the excess escape rate of the modified process with respect to the original process : @xmath139 combining   with , the @xmath68 can be expanded around a markov reference : e.g. , by writing @xmath140 then , the normalization leads to @xmath141 assuming that @xmath142 and that the other @xmath143 , @xmath144 are all small gives rise to an expansion of @xmath68 and of @xmath120 around the markov case  .",
    "in this section we examine the regime of small ( or gaussian ) fluctuations , to say more about the traffic and the influence of the waiting time distributions on the fluctuations . for this",
    "we make a quadratic approximation to the various functionals but not ( necessarily ) around equilibrium .",
    "we let the fluctuations in the empirical distribution and the empirical current be parameterized with some @xmath145 , @xmath146\\\\ j(x , y ) & = & j_{\\rho}(x , y ) + \\epsilon j_1(x , y)\\end{aligned}\\ ] ] where @xmath89 is the stationary measure , and @xmath147 is the stationary current .",
    "also @xmath120 and @xmath131 are now of order @xmath145 and to indicate that , we replace those with @xmath148 and @xmath149 . to first order in @xmath145 , the conditions   become @xmath150 \\nonumber \\\\   & \\phantom{***}- ` ( x\\longleftrightarrow y ) ' \\\\ \\label{smallfluct1 }   \\delta(x ) & = -\\frac{1}{2\\left<\\tau\\right>_x}\\sum_zp(x , z)f(x , z)\\end{aligned}\\ ] ] where @xmath151 the fluctuation functional within the quadratic approximation is , cf .",
    ", @xmath152    we observe that for small fluctuations , only the first and second moments of the waiting time distributions contribute .",
    "furthermore , the second term on the right hand side of  ) marks the difference with the markov case since for the exponentially distributed waiting times @xmath153 . due to the presence of this term beyond markov , the functional @xmath99 no more splits into a sum over different transitions , hence",
    ", it is responsible for the emergence of a new type of nonlocality in the fluctuations , not present under the markov condition .      in the case of a ( global ) detailed balance dynamics",
    ", we can prove that the occupation and current fluctuations become decoupled within the quadratic approximation .",
    "indeed , by using the detailed balance condition , the equation   can be explicitly solved for the extra forcing @xmath154 : @xmath155 substituted in the equation  , it yields @xmath156\\ ] ] where we have used that @xmath157 .",
    "clearly , that @xmath158 only depends on the occupations @xmath159 and not on the currents .",
    "that is why the occupation and the current fluctuations become statistically independent , with the joint fluctuation functional being a sum of the occupation functional and the current functional : @xmath160 where @xmath161    suppose now that the ( global ) detailed balance is slightly broken , in the following sense : take @xmath162 , where @xmath163 are detailed balanced transition probabilities . as the functionals ( [ decoupled])([decoupled2 ] ) are already of order @xmath164 , the small deviation from detailed balance will not contribute .",
    "we have therefore still uncorrelated statistics for the occupations and currents in the close - to - equilibrium regime , and the marginal fluctuation functionals  ([decoupled2 ] ) remain unchanged .",
    "remark that whereas the current statistics has exactly the same form as for a markov process with escape rates @xmath165 , we observe a difference in the occupation statistics . as the difference between semi - markov and markov processes lies in the time - symmetric part of the path - space probabilities , it should come as no surprise that the occupation statistics are more sensitive to details of the waiting time distribution than are the current statistics .",
    "first we give an example of semi - markov process obtained from a markov model via coarse - graining .",
    "its generalized version is then used to illustrate our dynamical fluctuation theory .",
    "consider a markov random walk as in  fig .",
    "[ picture1 ] , with three kinds of states @xmath166 , and @xmath167 for @xmath168 on a ring ( @xmath169 ) .    as the arrows in fig .",
    "[ picture1 ] suggest , the only transitions allowed are @xmath170 , @xmath171 , @xmath172 , and @xmath173 , whereas all the others are are forbidden .",
    "this is a model of a one - dimensional random walk with ` hidden ' states : the particle at state @xmath174 can go ` to the right ' ( from @xmath174 to @xmath175 ) through the ` hidden ' state @xmath176 only , and ` to the left ' through @xmath167 only .",
    "more specifically , we fix @xmath177 and we set the markov transition rates to @xmath178 for some @xmath179 . the rates do not depend on the position @xmath180 on the ring .",
    "since every pair of ` hidden ' states @xmath176 and @xmath167 have the unique precursor @xmath174 , we can follow a simple coarse - graining procedure : for each @xmath180 to take together all three states @xmath174 , @xmath176 , and @xmath167 , see fig .",
    "[ picture2 ] . by construction ,",
    "the coarse - grained random walk on the new ` block ' states , denoted by @xmath181 , is a semi - markov process .",
    "we can calculate the probability that the walker occupies @xmath181 for a time @xmath182 before jumping to @xmath183 , and its time derivative is the density @xmath184 . exploiting that the only possibility of going from @xmath181 to @xmath183 ( or @xmath185 ) is via the ` hidden ' state @xmath176 ( or @xmath167 ) , the waiting time distributions   read @xmath186 it is clear that @xmath184 and @xmath187 determine the dynamics of the new stochastic process which is semi - markov : the updates are decided by the immediate history but the waiting time distribution is not exponential and it can depend on the specific transition . observe also that @xmath188 which indicates a driving whenever @xmath189 . in all events",
    "the stationary distribution is uniform over the ring .",
    "+ let us investigate two different limits of this example .",
    "first let @xmath190 . in this limit we get @xmath191 unless @xmath192 ,",
    "the process is not markov . in general",
    "it is semi - markov with direction dependent waiting time distribution .",
    "secondly we consider the limits @xmath193 and @xmath194 together .",
    "the resulting transition densities are @xmath195 here the time dependence of the two clocks for going to the left or to the right are the same .",
    "in particular , it does not matter whether the walker first picks a direction or just picks the first clock that rings .",
    "still it is not a markov process , because the waiting time distributions of the clocks are not exponential .",
    "this process is semi - markov with waiting time - direction independence .",
    "the semi - markov model obtained in the previous section is an example of continuous time random walk ( ctrw ) . in this section",
    "we give some explicit solutions to equations that appear in dynamical fluctuation theory , for a ctrw on the ring .",
    "we continue with states that represent the sites on a ring of length @xmath196 , with translation invariance as in the above explicit example .",
    "let the transition densities be @xmath197 we restrict to the small fluctuations as in section  [ small ] .",
    "because the current fluctuation @xmath198 has to satisfy @xmath199 , we see that @xmath200 , and therefore @xmath201 is a constant on the ring .",
    "the equations ( [ smallfluct ] ) become @xmath202\\nonumber\\\\ \\delta(x ) & = & \\frac{1}{2\\left<\\tau\\right>}(qf(x-1,x)-pf(x , x+1))\\end{aligned}\\ ] ] where the constants @xmath203 and @xmath204 are @xmath205 the fluctuation functional reads @xmath206 the second term on the right - hand side is easily computed by summing   over all @xmath2 . using that @xmath207 we get @xmath208 defining now @xmath209 by @xmath210",
    ", we see that @xmath211 , hence , @xmath212 is of the gradient form @xmath213 . substituting in",
    ", we get @xmath214\\nonumber\\\\ \\delta(x ) & = & \\frac{1}{2\\left<\\tau\\right>}(qf(x-1,x)-pf(x , x+1 ) ) + ( q - p)\\frac{n^2\\left<\\tau\\right > j_1}{b-2a } \\nonumber\\\\ & = : & \\delta'(x ) + ( q - p)\\frac{n^2\\left<\\tau\\right > j_1}{b-2a}\\end{aligned}\\ ] ] finally , takes the form @xmath215 so there is a decoupling of current and occupation statistics .",
    "whereas , in general , this occurs only for small fluctuations and close to equilibrium , here it is apparently valid arbitrarily far from equilibrium .",
    "the fundamental reason lies in the translation - invariance property of the dynamics .",
    "+ let us further examine the statistics of current fluctuations , exploiting that the functional @xmath216 is explicit .",
    "using that in the markov case @xmath217 , we can write in general @xmath218 , with @xmath219 the fluctuation functional for a markov process with the same average waiting time @xmath220 , and with @xmath221 given by @xmath222 where @xmath223 is the variance of the waiting time distribution .",
    "thus @xmath221 is a correction factor with respect to the markov case ; one checks that @xmath224 .",
    "we also see that the bigger the variance of the waiting times , the smaller @xmath225 , and therefore the @xmath216 will become flatter .",
    "remark that in detailed balance ( i.e.  for @xmath226 ) , we have that @xmath227 .",
    "so in this case one has the same fluctuation functional as in the markov case , as it should be according to  .",
    "furthermore , there is a fundamental difference between the cases @xmath228 and @xmath229 ( i.e. , whether the variance of the waiting times is bigger or smaller than in the markov case ) .",
    "when the variance is smaller than in the markov case , @xmath221 as a function of @xmath230 tends to get bigger when @xmath230 gets closer to @xmath231 or @xmath85 . in the other case , @xmath221 becomes smaller when @xmath230 is closer to @xmath231 or @xmath85 .",
    "+ finally we can compute the occupation statistics @xmath114 .",
    "formul considerably complicate however when @xmath196 is large and that is why we choose to be explicit only for @xmath232 ( a ring with three sites ) .",
    "similarly as for @xmath216 we can write @xmath233 , with @xmath234\\end{aligned}\\ ] ] using that @xmath235 .",
    "the @xmath236 is given by @xmath237 also here , the bigger the variance of the waiting times , the flatter the fluctuation functional becomes .",
    "however , in the detailed balance case the functional does not reduce to the markov - form .",
    "this is indeed what we concluded in the discussion after ( [ decoupled ] ) .",
    "there is another difference with the current fluctuations : as a function of @xmath230 , the fluctuation functional gets flatter when @xmath230 gets closer to @xmath231 or @xmath85 , independent of the sign of @xmath238 .",
    "finally we consider ( arbitrary ) current fluctuations on the ring and compare two possible approaches . as explained in the present paper ,",
    "one way of computing this is via contraction of the joint fluctuation functional : @xmath239 as is however often the case , explicit computations proceed more easily via the generating function @xmath240 defining @xmath241 , one can prove that @xmath242 exists and is the legendre transform of the fluctuation functional @xmath216 : @xmath243 and vice versa .",
    "it generates the current cumulants , see e.g.  @xcite for applications to nonequilibrium interacting particle systems . by using the laplace",
    "transform as in , with @xmath244 the laplace transform of @xmath245 , we solve the equation @xmath246 for @xmath247 ; then @xmath248 .    as an example , consider the waiting time distribution @xmath249 for @xmath250 .",
    "( note that @xmath251 represents the markov case . ) for this distribution , @xmath252 and ( [ geneq ] ) becomes @xmath253 or , @xmath254 by taking derivatives at @xmath255 we obtain the next explicit expressions for the current moments : @xmath256 it is interesting to see that the variance of the currents picks up a term depending on the driving @xmath257 and that this term is only non - zero if the process is non - markov .",
    "this is indeed what we expect from the discussions about the small fluctuations regime , where we found that in , or close to , the detailed balance case the current fluctuations are quite insensitive to changes in the variance of the waiting times .",
    "k.  n.  acknowledges the support from the project av0z10100520 in the academy of sciences of the czech republic and from the grant agency of the czech republic ( grant no .",
    "202/07/j051 ) .",
    "benefits from the belgian interuniversity attraction poles programme p6/02 .",
    "b.  w.  is an aspirant of fwo flanders .",
    "we give some more details on the structure of semi - markov processes .",
    "see @xcite for excellent introductions .      to have a good intuition about a semi - markov process it is worth seeing it as a discrete time markov chain to which specific waiting times are added .",
    "in particular , the discrete sequence of states in the semi - markov process is drawn from the markov chain with transition probabilities @xmath258 : if at time @xmath259 the state @xmath31 was created , then we choose the next state @xmath260 with probability @xmath261 .",
    "secondly , we have to decide how long has been the waiting between the creation of @xmath31 and the creation of @xmath260 . for",
    "that we need the waiting time distribution : let its distribution ( i.e. the integrated probability density ) be @xmath262 , so that the ( total ) distribution function for the random waiting time @xmath263 between the creation of @xmath31 and the creation of @xmath260 , is @xmath264 .    a semi - markov process is thus constructed most elegantly from a markov renewal process @xmath265 for @xmath266 and @xmath267 denoting jump times , with transition probabilities @xmath268 = p(x_n , y)-\\lambda(x_n , y;t ) , \\quad n , t\\geq 0\\ ] ] satisfying all of with @xmath269 .",
    "+ the process @xmath270 with transition probabilities @xmath258 is called the embedded markov chain . for the randomness in time , we define the jump counting process @xmath271 of the total dynamical activity up to time @xmath4 , @xmath272 which we assume is finite with probability one .",
    "the semi - markov process corresponding to that renewal process is then defined by @xmath273 where the state at time @xmath4 is just equal to @xmath274 of the embedded markov chain , if @xmath275 . for a markov process",
    "@xmath276 is just a poisson process .",
    "an intuitive way of deriving a generalization of the master equation for semi - markov processes is by considering the corresponding markov process @xmath277 , where @xmath278 is the configuration of the semi - markov process at time @xmath4 and @xmath279 is the time that the system has been in this configuration since its last jump .",
    "+ with this in mind we can write down the transition probabilities for the process @xmath280 , @xmath281 we then have that with @xmath282 ,        let us now look at the evolution of probability densities @xmath286 ) in this dynamics .",
    "it is easily seen that for @xmath287 : @xmath288\\ ] ] from which it follows that @xmath289 and for @xmath290 , @xmath291 because we are mainly interested in the process @xmath278 ( which is no longer markov ) , we integrate over the waiting times @xmath292 : @xmath293 . doing that for we get ( assuming that @xmath294 ) : @xmath295 using ( [ tauzero ] ) we thus arrive at a generalized master equation : @xmath296 = -\\sum_yj_t(x , y)\\ ] ] which also defines the currents @xmath297 .",
    "there is obviously a downside to this equation , and that is that we need knowledge of @xmath298 to compute the time derivative of @xmath299 .",
    "there is a way to circumvent this problem by using the laplace transform .",
    "+ taking the laplace transform of a function @xmath212 as @xmath300 and putting @xmath301 it can be proven that @xmath302 with @xmath303 having laplace transform @xmath304we substitute that in the master equation : @xmath305\\varphi(y , x;t - t )   - \\left[\\mu_t(x)-\\mu_0(x)\\right]\\varphi(x , y;t - t ) \\right\\ } \\nonumber\\\\   & & + \\sum_y\\left [ \\mu_0(y)\\bar{\\lambda}(y)p(y , x ) - \\mu_0(x)\\bar{\\lambda}(x)p(x , y ) \\label{malap}\\right]\\end{aligned}\\ ] ] the function @xmath303 represents the memory of the semi - markov process .",
    "the faster @xmath306 decays to zero , the less memory we have .",
    "for example , for a markov process with escape rates @xmath16 we find that @xmath307 .",
    "indeed a markov process has no memory ( and the master equation for markov processes arises as a special case of this generalized equation ) .",
    "stationarity of the semi - markov process means that path - space averages of time - independent observables are still time independent .",
    "but as above we can use the corresponding markov process @xmath277 .",
    "stationarity of the semi - markov process is ensured by demanding that @xmath308 is stationary .",
    "solving then ( [ mastertau ] ) with the lhs zero , and using @xmath309 , we get @xmath310 .",
    "this means that if we know that the system is in a configuration @xmath2 , then the probability that it has been there already for a time @xmath292 is equal to @xmath311 .",
    "the stationary measure of our semi - markov process is @xmath312 where @xmath313 is the stationary measure of the embedded markov chain .",
    "we write @xmath314 for some normalization @xmath315 , the overall average waiting time . in this notation , we see that the stationary currents are @xmath316 and that they are zero iff the embedded markov chain is detailed balance . that however is only equivalent with time - reversal invariance if the semi - markov process is time - direction independent , see e.g. @xcite .",
    "p.  g.  bergmann and j.  l.  lebowitz : new approach to nonequilibrium processes , _ phys .",
    "rev . _ * 99 * , 578587 ( 1955 ) ; j.  l.  lebowitz and p.  g.  bergmann : irreversible gibbsian ensembles , _ annals of physics _",
    "* 1 * , 1 ( 1957 ) ; j.  l.  lebowitz : stationary nonequilibrium gibbsian ensembles , _ physical review _ * 114 * , 11921202 ( 1959 ) .",
    "l.  bertini , a.  de sole , d.  gabrielli , g.  jona lasinio , and c.  landim : large deviation approach to non equilibrium processes in stochastic lattice gases , _ bull .",
    "( n.s . ) * 37 * , 611643 ( 2006 ) .                            o.  e.  lanford iii : entropy and equilibrium states in classical statistical mechanics , in _ statistical mechanics and mathematical problems ( batelle seattle rencontres 1971 ) _ , lecture notes in physics no .  20 ( springer - verlag , berlin ) , 1113 ( 1973 ) .          c.  maes ,",
    "k.  neton , and b.  wynants : on and beyond entropy production ; the case of markov jump processes , _ markov proc .",
    "fields _ * 14 * , 445464 ( 2008 ) ; c. maes , k.  neton , and b. wynants : steady state statistics of driven diffusions , _ physica a _ * 387 * , 26752689 ( 2008 ) .",
    "e.  w.  montroll and g.  h.  weiss : _ j. math .",
    "phys . _ * 6 * , 167 ( 1965 ) ; e.  w.montroll and m.  f.  shlesinger : in _ studies in statistical mechanics _ , eds j.  l.  lebowitz and e.  w.  montroll , vol.l .",
    "xi ( north - holland , amsterdam ) , pp .  5 - 121 ( 1984 ) .",
    "there are always infinitely many reference equilibrium processes such that this relation is true .",
    "its satisfaction makes the coming large deviation argument particularly convenient since the stochastic modification needed to make a fluctuation typical will appear to have an identical form , see section [ jointsec ] ."
  ],
  "abstract_text": [
    "<S> we develop an onsager - machlup - type theory for nonequilibrium semi - markov processes . </S>",
    "<S> our main result is an exact large time asymptotics for the joint probability of the occupation times and the currents in the system , establishing some generic large deviation structures . </S>",
    "<S> we discuss in detail how the nonequilibrium driving and the non - exponential waiting time distribution influence the occupation - current statistics . </S>",
    "<S> the violation of the markov condition is reflected in the emergence of a new type of nonlocality in the fluctuations . </S>",
    "<S> explicit solutions are obtained for some examples of driven random walks on the ring . </S>"
  ]
}