{
  "article_text": [
    "high - visibility images reflect clear details of target scenes , which are critical to many vision - based techniques , such as object detection @xcite and tracking @xcite .",
    "but , images captured in low - light conditions are often of low visibility . besides degrading the visual quality of images",
    ", it very likely hurts the performance of algorithms that are primarily designed for high - visibility inputs .",
    "figure [ fig : open ] provides three such examples , from which , we can see that many details , the paintings on the wall in the first case for example , have almost been  buried \" in the dark . to make the buried information visible again , low - light image enhancement is demanded .        directly amplifying the low - light image",
    "is probably the most intuitive and simplest way to recall the visibility of dark regions . but this operation gives birth to another problem , say relatively bright regions might be saturated and thus loss corresponding details .",
    "histogram equalization strategies @xcite can avoid the above problem by somehow forcing the output image to fall in the range @xmath0 $ ]",
    ". however , in nature , they focus on contrast enhancement instead of exploiting real illumination causes , having the risk of over- and under - enhancement .",
    "the method proposed in @xcite tries to enhance contrast while preserving naturalness of illumination .",
    "although it prevents the result from over - enhancement , in our test , its performance is not so attractive in both efficiency and visual quality .",
    "as noticed in @xcite , inverted low - light images look like hazy images , as shown in fig .",
    "[ fig : ive ] . based on this observation",
    ", the authors of @xcite alternatively resorted to dehaze the inverted low - light images .",
    "after dehazing , the obtained unrealistic images is inverted again as the final enhanced results .",
    "recently , li _ et al .",
    "_ followed this technical line and further improved the visual quality by first over - segmenting the input image and then adaptively denoising different segments @xcite .",
    "even though the above methods can provide reasonable results , the basic model they rely on is lacking in physical explanation .",
    "this paper will try to connect this un - rooted model to a more physically meaningful one that our method adopts .    .",
    "]    this work intends to enhance a low - light image by estimating its illumination map .",
    "the illumination map is first constructed by finding the maximum intensity of each pixel in r , g and b channels .",
    "then , we exploit the structure of the illumination and execute structure - aware smoothing to refine the illumination map . experiments on a number of challenging images are conducted to demonstrate the advantages of our method in comparison with other state - of - the - art methods .",
    "our method is built upon the following model , which explains the formation of a low - light ] where @xmath1 and @xmath2 are the captured image and the desired recovery , respectively .",
    "in addition , @xmath3 represents the illumination map , and the operator @xmath4 means element - wise multiplication .",
    "the model is with clear physical meaning , say the observed image can be decomposed into the product of the desired scene and the illumination image . as can be seen , the estimation of @xmath3 is key to the recovery of @xmath2 .",
    "as mentioned , another widely used model is based on the observation that inverted low - light images @xmath5 look similar to haze images , which is thus expressed as @xcite : @xmath6 where @xmath7 represents the global atmospheric light .",
    "although the visual effect of inverted low - light images @xmath5 is intuitively similar to haze images , compared to the model , the physical meaning of the above is not easy to directly explain .",
    "we will show the relation between and later .      as one of the first color constancy methods , max - rgb @xcite tries to estimate the illumination by seeking the maximum value of three color channels , say r , g and b. but this estimation can only boost the global illumination . in this paper , to handle non - uniform illuminations , we alternatively adopt the following initial estimation : @xmath8 the obtained @xmath9 guarantees that the recovery will not be saturated , because of @xmath10 where @xmath11 is a very small constant to avoid the zero denominator .",
    "let us here recall the dark channel prior , a commonly used prior to estimate the transmission map for dehazing @xcite , on @xmath5 as follows : @xmath12 accordingly , substituting into yields : @xmath13 we can see that when @xmath14 , both and reach the same result .",
    "but , if @xmath7 gets away from @xmath15 , the equivalence between the model @xcite and breaks ( see fig . [",
    "fig : dif ] for difference ) .",
    "estimated by @xcite is larger than @xmath16 . even though , the difference is still noticeable . ]    in this work , we employ to initially estimate illumination map @xmath17 , due to its simplicity , although various approaches , like @xcite , have been developed to improve the accuracy in past decades .",
    "most of these improvements essentially consider the local consistency of illumination by taking into account neighboring pixels within a small region around the target pixel . in the following ,",
    "we provide a more powerful scheme to better achieve this goal .          as aforementioned , the illumination estimation can benefit from local consistency .",
    "two representative ways are : @xmath18 where @xmath19 is a region centered at pixel @xmath20 , and @xmath21 is the location index within the region .",
    "these strategies can somewhat enhance the local consistency , but they are structure - blind",
    ".    a  good \" solution should simultaneously preserve the overall structure and smooth the textural details . to address this issue , based on the initial illumination map @xmath17",
    ", we propose to solve the following optimization problem : @xmath22 where @xmath23 ( @xmath24 for all the experiments ) is the coefficient to balance the involved two terms and , @xmath25 and @xmath26 designate the frobenious and @xmath27 norms , respectively .",
    "further , @xmath28 is the weight matrix , and @xmath29 that contains @xmath30 ( horizontal ) and @xmath31 ( vertical ) , is the first order derivative filter . in the objective ,",
    "the first term takes care of the fidelity between the initial map @xmath17 and the refined one @xmath3 , while the second term considers the ( structure - aware ) smoothness .",
    "it can be seen that setting the weight matrix to @xmath32 ( all entries being @xmath15 ) leads to a classic @xmath33 loss total variation minimization problem ( tv for short ) @xcite , which is also short of ability to distinguish between strong structural edges and texture @xcite .",
    "hence , the key is the design of @xmath28 .",
    "inspired by rtv @xcite , for each location , the weight ( _ e.g. _ @xmath34 ) is set via : @xmath35 where @xmath36 is produced by the gaussian kernel with the standard deviation @xmath37 ( we use @xmath38 throughout this paper ) , and @xmath39 is the absolute value operator .",
    "please note that , different to rtv , our weight matrix is constructed based on the given @xmath17 instead of being iteratively updated according to @xmath40 .",
    "that means @xmath28 only needs to be calculated once .",
    "traditionally , the problem can be effectively solved via alternating direction minimization techniques . to speed up the calculation",
    ", we approximate by the following : @xmath41 as can be seen , the problem now only involves quadratic terms .",
    "thus , the solution can be directly computed without requiring any iterations .",
    "figure [ fig : map ] shows a comparison of different methods on illumination map , from which , we can see the advance of our method .",
    "+      with @xmath42 , @xmath43 and @xmath44 , respectively .",
    "the corresponding illumination map is given in the up - right corner of each sub - picture .",
    "noises appear in the enhanced images .",
    "( d ) is the denoised version of ( b ) by bm3d , while ( e ) is the recomposed result of ( b ) and ( e ) by .",
    "it can be seen from the zoomed - in patches that the recomposition adaptively keeps the fine details of the bright region and suppresses the noises of the dark region . ]    having the refined illumination map @xmath3 , we can recover @xmath2 by following .",
    "one can also manipulate the illumination map through gamma transformation , say @xmath45 . from the upper row of fig .",
    "[ fig : finrec ] , we can see the difference between the results by setting @xmath46 to @xmath47 , @xmath48 and @xmath15 . for the rest experiments , we adopt @xmath43 .",
    "moreover , possible noises previously hiding in the dark are also accordingly amplified , especially for the very low - light inputs ( regions ) , as shown in fig .",
    "[ fig : finrec ] .",
    "denoising techniques are required to further improve the visual quality .",
    "many off - the - shelf denosing tools , such as @xcite , can be employed to do the job .",
    "considering the comprehensive performance , bm3d @xcite is the choice of this work . in our implementation , for further cutting the computational load , we only execute bm3d on the y channel by converting @xmath2 from the rgb colorspace into the ycbcr one . in addition , the magnitude of noises is not the same for different regions of the input , as the amplification is different .",
    "and bm3d treats different patches equally . therefore , to avoid the unbalance of processing , _",
    "e.g. _ some ( dark ) places are well - denoised while some ( brighter ) over - smoothed , we employ the following operation : @xmath49 where @xmath50 and @xmath51 are the results after denoising and recomposing , respectively .",
    "the merit of this operation can be viewed from fig .",
    "[ fig : finrec ] ( e ) , compared with fig .",
    "[ fig : finrec ] ( d ) .",
    "we mention that the denoising , as a post - processing step , can be concatenated to any low - light image enhancing method .",
    "in this section , we compare our lime with several state - of - the - art methods , including histogram equalization ( he ) , adaptive histogram equalization ( ahe ) , gamma correction ( gc ) , dehazing based method @xcite ( dehz ) and naturalness preserved enhancement algorithm ( npe ) @xcite .",
    "all the codes are in matlab , while the code of npe is downloaded from the authors website .",
    "the code of dehz is not publicly available when this paper is prepared , but it is easy to be implemented based on @xcite . ] , which ensures the fairness of time comparison .",
    "all the experiments are conducted on a machine running windows 7 os with 64 g ram and 2.4ghz cpu .",
    "figure [ fig : cmp1 ] provides several comparisons . from the top row ( the input is the second case of fig . [",
    "fig : open ] with size @xmath52x@xmath53 ) , we can see that ahe can not effectively recall the information in dark regions while gc ( @xmath54 ) changes the color of the whole image .",
    "these problems almost exist always , therefore we discard them for the rest comparisons .",
    "he , dehz and npe outperform ahe and gc in this case , but are inferior to our method in terms of visual quality . in time cost , although lime spends more than he , ahe and gc , it is comparable to or even more efficient than dehz , while much more efficient than npe .",
    "most cost of dehz comes from the estimation of atmospheric light .",
    "two more comparisons are given in fig .",
    "[ fig : cmp1 ] , which are the additional evidence of the advantage of lime , compared with he , dehz and npe .",
    "figure [ fig : post ] gives another test .",
    "the very low - light input hides intensive noises in the dark . after performing lime ,",
    "the details of the scene get enhanced , but the noises also come out , as shown in the middle of fig .",
    "[ fig : post ] .",
    "this is an inevitable problem encountered by almost all of existing low - light enhancement algorithms . as we have discussed in sec .",
    "[ sec : post ] , denoising is required . the right picture in fig .",
    "[ fig : post ] is the denoised result by executing bm3d on the middle of fig .",
    "[ fig : post ] , from which we can see the improvement in terms of visual quality . to allow more experimental verification and comparisons ,",
    "we provide our code at http://cs.tju.edu.cn/orgs/vision/~xguo/homepage.htm",
    "this paper has proposed an efficient and effective method to enhance low - light images for boosting the visual quality and offering contemporary vision applications with reliable inputs .",
    "the key to the enhancement is how well the illumination map is estimated .",
    "the structure - aware smoothing has been developed to improve the illumination consistency .",
    "the experimental results have revealed the advance of our method compared with several state - of - the - art alternatives ."
  ],
  "abstract_text": [
    "<S> when one captures images in low - light conditions , the images often suffer from low visibility . </S>",
    "<S> this poor quality may significantly degrade the performance of many computer vision and multimedia algorithms that are primarily designed for high - quality inputs . in this paper </S>",
    "<S> , we propose a very simple and effective method , named as lime , to enhance low - light images . more concretely , </S>",
    "<S> the illumination of each pixel is first estimated individually by finding the maximum value in r , g and b channels . </S>",
    "<S> further , we refine the initial illumination map by imposing a structure prior on it , as the final illumination map . having the well - constructed illumination map , </S>",
    "<S> the enhancement can be achieved accordingly . </S>",
    "<S> experiments on a number of challenging real - world low - light images are present to reveal the efficacy of our lime and show its superiority over several state - of - the - arts . </S>"
  ]
}