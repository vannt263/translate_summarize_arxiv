{
  "article_text": [
    "advances in modern high - level computer vision have helped usher in a new era of capable , perceptive physical platforms , such as automated vehicles . as the performance of these systems improves",
    ", the expectations of their capabilities and tasks will also increase , commensurately , with platforms moving from the highways into our homes , for example .",
    "the need for these platforms to understand not only * what * action is happening , but also * who * is doing the action and * where * the action is happening , will be increasingly critical to extracting semantics from video and , ultimately , to interacting with humans in our complex world .",
    "for example , a home kitchen robot must distinguish and locate _ adult - eating _",
    ", _ dog - eating _ and _ baby - crying _ in order to decide how to prepare and when to serve food .    despite the recent successes of aspects of this problem , such as action recognition  @xcite , action segmentation  @xcite , video object segmentation  @xcite , the collective problem had not been codified until  @xcite , which posed a new actor - action semantic segmentation task on a large - scale youtube video dataset called a2d .",
    "this dataset contains seven classes of actors including both articulated ( e.g. _ baby _ , _ cat _ and _ dog _ ) and rigid ( e.g. _ car _ and _ ball _ ) ones , and eight classes of actions ( e.g. _ flying _ , _ walking _ and _ running _ ) .",
    "the task is to label each pixel in a video as a pair of actor and action labels or a null actor / action ; one third of a2d videos contain multiple actors and actions .",
    "this task is challenging  their benchmarked leading method , the _ trilayer model _ , only achieves a 26.46% per - class pixel - level accuracy for joint actor - action labeling .",
    "this model builds a large three - layer crf on video supervoxels , where random variables of actor , actor - action , and action labels are defined on each layer , respectively , and connects layers with two sets of potential functions that capture conditional probabilities ( e.g. conditional distribution of action given a specific actor class ) . although their model accounts for the interplay of actors and actions , the interactions of the two sets of labels are restricted to the local crf neighborhoods , which , based on the low absolute performance they achieve , is insufficient to solve this unique actor - action problem for three reasons .",
    "first , we believe the pixel - level model must be married to a secondary process that captures instance - level or video - level global information , such as action recognition , in order to properly model the actions .",
    "lessons learned from images strongly supports this argument  the performance of semantic image segmentation on the msrc dataset seems to hit a plateau @xcite until information from secondary processes , such as context @xcite , object detectors @xcite and a holistic scene model @xcite , are added . however , to the best of our knowledge , there is no method in video semantic segmentation that directly leverages the recent success in action recognition .",
    "second , these two sets of labels , actors and actions , exist at different levels of granularities . for example , suppose we want to label _ adult - clapping _ in a video . the actor , _ adult _ , can probably be recognized and labeled by looking only at the lower body , e.g. legs",
    ". however , in order to recognize and label the _ clapping _ action , we have to either localize the acting parts of the human body or simply look at the whole actor body for recognizing the action .",
    "third , actors and actions have different orientations along space and time dimensions in a video .",
    "actors are more space - oriented  they can be fairly well labeled using only still images , as in semantic image segmentations  @xcite , whereas actions are more space - time - oriented .",
    "although one can possibly identify actions by still images alone  @xcite , there are strong distinctions between different actions along the time dimension .",
    "for example , _ running _ is faster and has more repeated motion patterns than _ walking _ for a given duration ; and _ walking _ performed by a _",
    "baby _ is very different compared to an _ adult _ , although they may easily confuse a spatially trained object detector , such as dpm  @xcite , without more complex spatiotemporal modeling .",
    "our method overcomes the above limitations in two ways : ( 1 ) we propose a novel grouping process model ( gpm ) that adaptively groups segments together during inference , and ( 2 ) we incoporate video - level recognition into segment - level labeling thru multi - label labeling costs and the grouping process model . the gpm is a dynamic and continuous process of information exchange of the labeling crfs and a supervoxel hierarchy .",
    "the supervoxel hierarchy provides a rich multi - resolution decomposition of the video content , where object parts , deformations , identities and actions are retained in space - time supervoxels across multiple levels in the hierarchy @xcite . rather than using object and action proposals as separate processes , we directly localize the actor and action nodes in a supervoxel hierarchy by the labeling crfs .",
    "during inference , the labeling crfs influence what supervoxels in a hierarchy are _ active _ , and these active supervoxels , in turn , influence the connectivity in the crf , thus refining the labels .",
    "this bidirectional inference for gpm is dynamic and iterative as shown in fig .",
    "[ fig : model ] and can be efficiently solved by graph cuts and binary linear programming .",
    "we show that the gpm can be effectively combined with video - level recognition signals to efficiently influence the actor - action labelings in video segmentation . throughout the entire inference process , the actor and action labels exchange information at various levels in the supervoxel hierarchy , such that the multi - resolution and space - time orientations of the two sets of labels are explicitly explored in our model .",
    "we conduct thorough experiments on the large - scale actor - action video dataset ( a2d ) @xcite .",
    "we compare the proposed method to the previous benchmarked leading method , the trilayer model , as well as two leading semantic segmentation methods  @xcite that we have extended to the actor - action problem .",
    "the experimental results show that our proposed method , which is driven by the grouping process model , outperforms the second best method by a large margin of 17% per - class accuracy ( 60% relative improvement ) and over 10% global pixel accuracy , which demonstrates the effectiveness of our modeling .",
    "our paper is closely related to xu et al .",
    "@xcite , where the actor - action semantic segmentation problem is first proposed .",
    "their paper demonstrates that inference jointly over actors and actions outperforms inference independently over them .",
    "they propose a trilayer model that achieves the state - of - the - art performance on the actor - action semantic segmentation problem .",
    "however , their model only captures the interactions of actors and actions in a local crf pairwise neighborhood , whereas our method considers the interplays at various levels of granularities in space and time introduced by a supervoxel hierarchy .",
    "supervoxels have demonstrated potential to capture object boundaries , follow object parts over time @xcite , and localize objects and actions @xcite .",
    "supervoxels are used as higher - order potentials for human action segmentation  @xcite and video object segmentation  @xcite .",
    "different from the above works , we use a supervoxel hierarchy to connect bottom - up pixel labeling and top - down recognition , where supervoxels contain clear actor - action semantic meaning .",
    "we also use the tree slice concept for selecting supervoxels in a hierarchy as in @xcite , but the difference is that our model selects the tree slices in an iterative fashion , where the tree slice also modifies the pixel - level groupings .",
    "our work also differs from the emerging works in action localization , action detection , and video object segmentation for two reasons .",
    "first , our segmentation contains clear semantic meanings of actor and action labels , whereas most existing works in action localization and detection do not  @xcite .",
    "second , we consider multiple actors performing actions in a video and explicitly model the types of actors , whereas existing works assume one human actor  @xcite or do not model the types of actors at all  @xcite .",
    "although there have been some works on action detection  @xcite , this remains an open challenge .",
    "we relate our work to ahrf @xcite and fcrf  @xcite in section [ sec : infer ] after presenting the new model .",
    "grouping process model ( gpm ) is a dynamic and continuous process of information exchange during inference : the local crf influences what supervoxels in a hierarchy are active , and these active supervoxels , in turn , influence the connectivity in the crf . here",
    ", we give its general form , and fig .",
    "[ fig : model ] shows an overview .",
    "we define the detailed potentials adapted to the actor - action problem in sec .",
    "[ sec : model ] .    * segment - level . * without loss of generality , we define @xmath0 as a video with @xmath1 voxels or a video segmentation with @xmath1 segments . a graph @xmath2 is defined over the entire video , where the neighborhood structure of the graph @xmath3 is induced by the connectivities in the voxel lattice @xmath4 or segmentation graph over space - time in a video .",
    "we define a set of random variables @xmath5 where the subscript corresponds to a certain node in @xmath6 and each @xmath7 takes some label from a label set .",
    "the gpm is inherently a labeling crf , but it leverages a supervoxel hierarchy to dynamically adjust its non - local grouping structure .    * supervoxel hierarchy . * given a coarse - to - fine supervoxel hierarchy generated by a hierarchical video segmentation method , such as gbh @xcite , we extract a supervoxel tree , denoted as @xmath8 with @xmath9 total nodes in the tree , by ensuring that each supervoxel at a finer level segmentation has one and only one parent at its coarser level ( sec .  [",
    "sec : exp ] details the tree extraction process in the general case ) .",
    "we define a set of random variables @xmath10 on supervoxel nodes in the entire tree @xmath8 , where @xmath11 takes a binary label to indicate whether the @xmath12th supervoxel node is active or not .",
    "being a segmentation hierarchy , each supervoxel connects to a set of segment nodes by their overlapping in voxel lattice @xmath4 , thus we have each @xmath13 connecting to a set of random variables at the segment level , denoted as @xmath14 .",
    "supervoxel hierarchies , such as @xcite , are built by iteratively recomputing and merging finer supervoxels into coarser ones based on appearance and motions , where the body parts of an actor and its local action are contained at the finer levels in the hierarchy and the identity of the actor and its long - ranging action are contained at the coarser levels . but going too coarse will cause oversegmentation with the background and going too fine will lose the meaningful actions . therefore it is challenging to locate the supervoxels in a hierarchy that best describe the actor and its action .",
    "instead , our gpm uses the evidence from a second source  the segment - level crf , to locate the supervoxels supported by the labeling @xmath15 .",
    "once the supervoxels @xmath16 are selected , they provide strong labeling cues to the segment - level labeling ",
    "these segment - level nodes are from a same actor or a same action , thus they can be fully connected to refine the labeling .",
    "the objective of gpm is to find the best labeling of @xmath17 and @xmath18 to minimize the following energy : @xmath19 where @xmath20 and @xmath21 encode the potentials at the segment - level and the supervoxel hierarchy , respectively ; @xmath22 and @xmath23 are conditional potential functions defined as directional edges in fig .",
    "[ fig : model ] . to keep the discussion general",
    ", we do not define the specific form of @xmath20 here , it can be any segment - level crf , such as  @xcite .",
    "we define the other terms next .      given an active node @xmath13 in the supervoxel hierarchy , we use it as a cue to refine the segment - level labelings and we define the energy of this process as : @xmath24 here , @xmath25 has the form : @xmath26 where @xmath27 is a constant parameter to be learned .",
    "@xmath28 penalizes any two nodes in the field @xmath14 that contain different labels .",
    "eq .  [ eq : energy_gpm_labeling ] will change the graph structure in @xmath14 by fully connecting the nodes inside , and has clear semantic meaning-this set of nodes in @xmath29 at the segment - level are linked to the same supervoxel node @xmath13 and hence they are from the same object , taking evidences from the appearance and motion features used in a typical supervoxel segmentation method .      if the selected supervoxels are too fine , they are subject to losing object identity and long - ranging actions ; if they are too coarse , they are subject to oversegmenting with the background .",
    "therefore , we set the selected supervoxels to best reflect the segment - level labelings while also respecting a selection prior .",
    "given some video labeling at the segment - level , we select the nodes in the supervoxel hierarchy that best correspond to this current labeling : @xmath30 where @xmath31 denotes the size of a supervoxel in terms of video voxels and @xmath32 is a parameter to be learned that encodes a prior of the node selection in the hierarchy .",
    "@xmath33 is defined as the entropy of the labeling field connected to @xmath13 : @xmath34 where @xmath35 and @xmath36 is an indicator function . intuitively , the first term in eq .",
    "[ eq : energy_gpm_grouping ] pushes down the selection of nodes in the hierarchy such that they only include the labeling field that has same labels , and the second term pulls up the node selection , giving penalties for going down the hierarchy .      the active nodes in @xmath16 define what groups of segments the gpm will enforce during labeling ; hence the name grouping process model .",
    "however , not all active node sets @xmath16 are permissible : since we seek a single labeling over the video , we enforce that each node in @xmath6 ( each segment ) is associated with one and only one active group in @xmath16 .",
    "this notion was introduced in @xcite by way of a _ tree slice _ :",
    "on every root - to - leaf path in the tree @xmath8 one and only one node in @xmath16 is active .",
    "we follow @xcite to define a matrix @xmath37 that encodes all root - to - leaf paths in @xmath8 .",
    "@xmath38 is one row in @xmath37 , and it encodes the path from the root to @xmath39th leaf with @xmath40s for nodes on the path and @xmath41s otherwise .",
    "we define the energy to regulate @xmath16 as : @xmath42 where @xmath43 is the total number of leaves ( also the number of such root - to - leaf paths ) , @xmath44 denotes dot product , and @xmath45 is a large constant to penalize an invalid tree slice .",
    "the tree slice selects supervoxel nodes to form a new video representation that has a one - to - one mapping to the video 3d lattices @xmath4 .",
    "in this section , we show that we can use an iterative bidirectional inference schema to efficiently solve the objective function defined in eq .",
    "[ eq : energy_gpm]given the segment - level labeling , we find the best supervoxels in the hierarchy ; and given the selected supervoxels in the hierarchy , we regroup the segment - level labeling .    * the video labeling problem . * given a tree slice @xmath16 , we would like to find the best @xmath17 .",
    "formally , we have : @xmath46 this equation can have a standard crf form depending on how @xmath20 is defined .",
    "the higher - order energy we defined in @xmath22 can be decomposed to a locally fully connected crf , and its range is constrainted by @xmath13 such that the inference is inexpensive even without gaussian kernels  @xcite .    *",
    "the tree slice problem . * given the current labeling @xmath15 , we would like to find the best @xmath18 .",
    "formally , we have : @xmath47 we use binary linear programming to optimize eq .",
    "[ eq : infer_top ] , and thus we rewrite the problem to have the following form : @xmath48 where @xmath49 . note that this optimization is substantially simpler than that proposed by the original tree slice paper @xcite , which incorporated quadratic terms in a binary quadratic program .",
    "we use a standard solver ( ibm cplex ) to solve the binary linear programming problem",
    ".    * iterative inference . * the above two conditional inferences are iteratively carried out , as depicted in fig .",
    "[ fig : model ] . to be specific , we initialize a coarse labeling @xmath15 by solving eq .  [ eq : infer_bottom ] without the second term , then we solve eq .",
    "[ eq : infer_top ] and [ eq : infer_bottom ] in an iterative fashion .",
    "each round of the tree slice problem enacts an updated set of grouped segments , which are then encouraged to be assigned the same label during the subsequent labeling process .",
    "although we do not include a proof of convergence in this paper , we notice that the solution converges after a few rounds .",
    "* relation to ahrf . * the associative hierarchical random field ( ahrf ) @xcite implicitly pushes up the inference nodes towards higher - levels in the segmentation tree @xmath8 , whereas our model ( gpms ) explicitly models the best set of active nodes in the segmentation tree @xmath8 by the means of a tree slice .",
    "ahrf defines a full random field on the hierachy ; our model leverages the hierarchy to adaptively group at the pixel level .",
    "our model is hence more scalable to videos .",
    "gpms assume that the best representations of the video content exist in a tree slice rather than enforcing the agreement across different levels as in ahrf .",
    "for example , a video of _ long jumping _ often contains _ running _ in the beginning .",
    "the running action exists and has a strong classifier signal at a fine - level in a supervoxel hierarchy , but it quickly diminishes when one goes to a higher level in the hierarchy where supervoxels capture longer range time dimension in the video and would then favor the jumping action .",
    "* relation to fcrf . *",
    "the fully - connected crf ( fcrf ) in  @xcite imposes a gaussian mixture kernel to regularize the pairwise interactions of nodes .",
    "although our model fully connects the nodes in each @xmath14 for a given iteration of inference , we explicitly take the evidence from the supervoxel groupings rather than a gaussian kernel .",
    "the energy in eq .",
    "[ eq : energy_gpm_grouping ] restricts the selected supervoxels to avoid overmerging .",
    "although a more complex process , in practice , our inference is efficient .",
    "it takes on the order of seconds for a typical video with a few thousand label nodes and a few hundred supervoxel nodes .",
    "typical semantic segmentation methods @xcite train classifiers at the segment - level . in our case , these segment - level classifiers capture the local appearance and motion features of the actors body parts ; they have some ability to locate the actor - action in a video , but these predictions are noisy since they do not capture the actor - whole or leverage any context information in the video .",
    "video - level classifiers , as a secondary process , capture the global information of actors performing actions and have good prediction performance at the video - level .",
    "however , they are not able to localize where the action is happening . these two streams of information captured at the segment - level and at the video - level are complementary to each other . in this section , we implement these two streams together in a single model , leveraging the grouping process model as a means of marrying the video - level signal to the segment level problem .",
    "let us first define notation , extending that from sec .",
    "[ sec : gpm ] where possible .",
    "we use @xmath50 to denote the set of actor labels ( e.g. _ adult _ , _ baby _ and _ dog _ ) and @xmath51 to denote the set of action labels ( e.g. _ eating _ , _ walking _ and _ running _ ) .",
    "the segment - level random fields @xmath15 now take two labels  for the @xmath52th segment , @xmath53 is a label from the actor set and @xmath54 is a label from the action set .",
    "we define @xmath55 as the joint product space of the actor and action labels .",
    "we define a set of binary random variables @xmath56 on the video - level , where @xmath57 denotes the @xmath58th actor - action label is active at the video - level .",
    "they represent the video - level multi - label labeling problem .",
    "again , we have the set of binary random variables @xmath16 defined on the supervoxel hierarchy as in sec .",
    "[ sec : gpm ] .",
    "therefore , we have the total energy function of the actor - action semantic segmentation defined as : @xmath59 where the term @xmath60 now models the joint potentials of the segment - level labeling field @xmath14 and the video - level labeling @xmath61 , which is slightly different from its form in eq .",
    "[ eq : energy_gpm_labeling ] .",
    "we have two new terms , @xmath62 and @xmath63 , from the video - level , where @xmath64 is the @xmath58th coordinate in @xmath61 .",
    "we explain these new terms next .      at the segment - level",
    ", we use the same bilayer actor - action crf model from @xcite to capture the local pairwise interactions of the two sets of labels : @xmath66 where @xmath67 and @xmath68 encode separate potentials for a random variable @xmath69 to take the actor and action labels , respectively .",
    "@xmath70 is a potential to measure the compatibility of the actor - action tuples on segment @xmath52 , and @xmath71 and @xmath72 capture the pairwise interactions between segments , which have the form of a contrast sensitive potts model @xcite .",
    "we use the publicly available code from @xcite to capture the local pairwise interactions of the two sets of labels .      rather than a uniform penalty over all labels @xcite",
    ", we use the video - level recognition signals as global multi - label labeling costs to impact the segment - level labeling .",
    "we define the unary energy at the video - level as : @xmath74 where @xmath75 is the video - level classification response for a particular actor - action label , and sec .",
    "[ sec : exp ] describes its training process .",
    "here , @xmath76 is a parameter to control response threshold , and @xmath77 is a large constant parameter . in other words , to minimize eq .",
    "[ eq : video_multi_unary ] , the label @xmath57 only when the classifier response @xmath78 .",
    "we define the interactions between the video - level and the segment - level : @xmath79 where @xmath80 is an indicator function to determine whether the current labeling @xmath15 at the segment - level contains a particular label @xmath81 or not : @xmath82 here , @xmath83 is another indicator function to determine whether a particular label @xmath84 is supported at the video - level or not : @xmath85 where @xmath86 maps a label in the joint actor - action space to the actor space .",
    "@xmath87 is a constant cost for any label that exists in @xmath15 but not supported at the video - level .",
    "we define @xmath88 and @xmath89 similarly .",
    "to make the cost meaningful , we set @xmath90 . in practice , we observe that these labeling costs from video - level potentials help the segment - level labeling to achieve a more parsimonious - in - labels result that enforces more global information than using local segments along ( see results in table [ tab : exp_dataset ] ) .",
    "the energy terms @xmath92 and @xmath93 involved in the tree slice problem are defined the same as in sec .",
    "[ sec : gpm ] .",
    "now , we define the new labeling term : @xmath94 here , @xmath25 has the form : @xmath95 where @xmath96 denotes the dominant actor label in the segment - level labeling field @xmath14 that connected to @xmath13 , and we define @xmath97 similarly .",
    "this new term selectively refines the segmentation where the majority of the segment - level labelings agree with the video - level multi - label labeling .",
    "we show in fig .",
    "[ fig : visual_gbh ] how this gpm process helps to refine the actor s shape ( the car ) in the segmentation labeling .",
    "the initial labelings from @xmath98 propose a rough region of interest , but they do not capture the accurate boundaries and shape .",
    "after two iterations of inferences , the tree slice selects the best set of nodes in the gbh hierarchy that represents the actor , and they regroup the segment - level labelings such that the labelings can better capture the actor shape . notice that the car body in the third column merges with the background , but our full model ( fourth column ) overcomes the limitation by selecting different parts from the hierarchy to yield the final grouping segmentation .",
    "the inference of the actor - action problem defined in eq .",
    "[ eq : energy_total ] follows the bidirectional inference described in sec .",
    "[ sec : infer ] .",
    "the tree slice problem can be efficiently solved by binary linear programming .",
    "the video labeling problem could be solved using loopy belief propagation .",
    "however , given the fact that the crfs are defined over two sets of labels , the actors and actions , this inference problem would be very expensive . here ,",
    "we derive a way to solve it efficiently using graph cuts inference with label costs @xcite .",
    "we show this conceptually in fig .",
    "[ fig : infer_gco ] and rewrite eq .",
    "[ eq : energy_seg ] as : @xmath99 where we define the new unary as : @xmath100 and the pairwise interactions as : @xmath101 we can rewrite eq .  [ eq : energy_tree_seg ] in a similar way , and they satisfy the submodular property according to the triangle inequality  @xcite .",
    "the label costs can be solved as in @xcite .",
    "* parameters .",
    "* we manually explore the parameter space based on the pixel - level accuracy in a heuristic fashion .",
    "we first tune the parameters involved in the video - level labeling , then those involved in the segment - level labeling , and finally , those involved in gpm by running the bidirectional inference as in sec .",
    "[ sec : infer ] .",
    "we evaluate our method on the recently released a2d dataset @xcite and use their benchmark to evaluate the performance ; this is the only dataset we are aware of that incorporates actors and actions together .",
    "we compare with the top - performing trilayer model benchmark , and two strong semantic image segmentation methods , ahrf @xcite and fcrf  @xcite . for ahrf , we use the public available code from @xcite as it contains a complete pipeline from training classifiers to learning and inference . for fcrf",
    ", we extend it to use the same features as our method .        * data processing . * we experiment with two distinct supervoxel trees : one is extracted from the hierarchical supervoxel segmentations generated by gbh @xcite , where supervoxels across mutliple levels natively form a tree structure hierarchy , and the other one is extracted from mutliple runs of a generic non - hierarchical supervoxel segmentation by tsp @xcite . to extract a tree structure from the non - hierarchical video segmentations , we first sort the segmentations by the number of supervoxels they contain .",
    "then we enforce the supervoxels in the finer level segmentation to have one and only one parent supervoxel in the coarser level segmentation , such that the two supervoxels have the maximal overlap in the video pixel space .",
    "we use four levels from a gbh hierarchy , where the number of supervoxels varies from a few hundred to less than one hundred .",
    "we also use four different runs of tsp to construct another segmentation tree where the final number of nodes contained in the tree varies from 500 to 1500 at the fine level , and from 50 to 150 at the coarse level .",
    "we also use tsp to generate the segments for the base labeling crf .",
    "we extract the same set of appearance and motion features as in @xcite ( we use their code ) and train one - versus - all linear svm classifiers on the segments for three sets of labels : actor , action , and actor - action pair , separately . at the video - level , we extract improved dense trajectories @xcite , and use fisher vectors @xcite to train linear svm classifiers at the video - level for the actor - action pair .",
    "we use the bidirectional inference and learning methods described in sec .",
    "[ sec : infer ] and follow the train / test splits used in @xcite .",
    "the output of our system is a full video pixel labeling .",
    "we evaluate the performance on sampled frames where the ground - truth is labeled .",
    "* results and comparisons .",
    "* we follow the benchmark evaluation in @xcite and evaluate performance for joint actor - action and separate individual tasks . tab .  [",
    "tab : exp_dataset ] shows the overall results of all methods in three different calculations : when all test videos are used ; when only videos containing single - label actor - action are used ; and when only videos containing multiple actor - action labels are used .",
    "roughly one - third of the videos in the a2d dataset have multiple actor - action labels .",
    "overall , we observe that our methods ( both gpm - tsp and gpm - gbh ) outperform the next best one , the trilayer method , by a large margin of 17% average per - class accuracy and more than 10% global pixel accuracy over all test videos .",
    "the improvement of global pixel accuracy is consistent over the two sub - divisions of test videos , and the improvement of average per - class accuracy is larger on videos that only contain single - label actor - action . we suspect that videos containing multiple - label actor - action are more likely to confuse the video - level classifiers .",
    "we also observe that the added grouping process in gpm - tsp and gpm - gbh consistently improves the average per - class accuracy over the intermediate result ( @xmath98 ) on both single - label and multiple - label actor - action videos .",
    "there is a slight decrease on the global pixel accuracy .",
    "we suspect the decrease mainly comes from the background class , which contributes a large portion of the total pixels in evaluation .",
    "to verify that , we also show the individual actor - action class performance in tab .  [",
    "tab : exp_a2 ] when all test videos are used .",
    "we observe that gpm - gbh has the best performance on majority classes and improves @xmath98 on all classes except _ dog - crawling _ , which further shows the effectiveness of the grouping process .",
    "the performance of our method using the gbh hierarchy is slightly better than our method using the tsp hierarchy .",
    "we suspect that this is due to the gbh method s greedy merging process that complements the gaussian process in tsp , such that the resulting segmentation complements the segment - level tsp segmentation we used .",
    "figure [ fig : visual_all ] shows the visual comparison of video labelings for all methods , where ( a)-(c ) show cases where methods output correct labels and ( d)-(g ) show cases where our proposed method outperforms other methods .",
    "we also show failure cases in ( h ) and ( i ) where videos contain complex actors and actions .",
    "for example , our method correctly labels the _ ball - rolling _ but confuses the label _ adult - running _ as _ adult - walking _ in ( h ) ; we correctly label _ adult - crawling _ but miss the label _ adult - none _ in ( i ) .",
    "our thorough experiments on the a2d dataset show that when the segment - level labeling is combined with secondary processes , such as our grouping process models and video - level recognition signals , the semantic segmentation performance increases dramatically .",
    "for example , gpm - gbh improves almost every class of actor - action labels compared to the intermediate result without the supervoxel hierarchy , i.e. , without the dynamic grouping of crf labeling variables .",
    "this finding strongly supports our motivating argument that the two sets of labels , actors and actions , are best modeled at different levels of granularities and that they have different space - time orientations in a video .      1 .   a novel model that dynamically combines segment - level labeling with a hierarchical grouping process that influences connectivity of the labeling variables .",
    "an efficient bidirectional inference method that iteratively solves the two conditional tasks by graph cuts for labeling and binary linear programming for grouping allowing for continuous exchange of information .",
    "3 .   a new framework that uses video - level recognition signals as cues for segment - level labeling thru multi - label labeling costs and the grouping process model .",
    "our proposed method significantly improves performance ( 60% relative improvement over the next best method ) on the recently released large - scale actor - action semantic video dataset @xcite .",
    "* future work .",
    "* we set two directions for our future work .",
    "first , although our model is able to improve the segmentation performance dramatically , the opportunity of this joint modeling to improve video - level recognition is yet to be explored .",
    "second , our grouping process does not incorporate semantics in the supervoxel hierarchy ; we believe this would further improve results ."
  ],
  "abstract_text": [
    "<S> actor - action semantic segmentation made an important step toward advanced video understanding problems : what action is happening ; who is performing the action ; and where is the action in space - time . </S>",
    "<S> current models for this problem are local , based on layered crfs , and are unable to capture long - ranging interaction of video parts . </S>",
    "<S> we propose a new model that combines these local labeling crfs with a hierarchical supervoxel decomposition . </S>",
    "<S> the supervoxels provide cues for possible groupings of nodes , at various scales , in the crfs to encourage adaptive , high - order groups for more effective labeling . </S>",
    "<S> our model is dynamic and continuously exchanges information during inference : the local crfs influence what supervoxels in the hierarchy are active , and these active nodes influence the connectivity in the crf ; we hence call it a _ grouping process model_. the experimental results on a recent large - scale video dataset show a large margin of 60% relative improvement over the state of the art , which demonstrates the effectiveness of the dynamic , bidirectional flow between labeling and grouping . </S>"
  ]
}