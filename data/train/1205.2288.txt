{
  "article_text": [
    "in many practical applications in @xmath0body integrations , the block time  step approach is preferred . in this approach",
    ", many particles share the same step size , where the only allowed values for the time  step length are powers of two .",
    "block time ",
    "steps are advantageous to reduce the prediction overheads , and are needed both for good parallelization and code efficiency .",
    "however , the time - symmetricity and symplecticity of previous direct integration schemes are disturbed by using variable block time  steps .",
    "the algorithm developed by @xcite ( tsbts ) is the first algorithm for time symmetrizing block time  steps which carry the benefits of time symmetry to block time ",
    "step algorithms . in this algorithmic approach",
    ", the total history of the simulation is divided into a number of smaller periods , with each of these smaller periods called an `` era '' .",
    "symmetrization is achieved by applying a time symmetrization procedure with an era - based iteration .",
    "the tsbts algorithm was generated for direct integration of @xmath0body systems and as such is suitable to use for a moderate number of bodies no more than @xmath1 .",
    "the direct approach to @xmath0body integration is preferred when we are interested in the close - range dynamics of the particles , and aiming at obtaining high accuracy .",
    "the algorithm gives us the ability to reach long integration times with high accuracy .",
    "however it has some limitations on memory usage which stem from choosing the size of the era .",
    "the tsbts algorithm also provides some benefits for parallelization of @xmath0body algorithms .",
    "development of parallel versions of variable time ",
    "step codes becomes increasingly necessary for many areas of research , such as stellar dynamics in astrophysics , plasma simulations in physics , and molecular dynamics in chemistry and biology .",
    "the most natural way to do this is through the use of block time  steps , where each particle has to choose its own power of two , for the size of its time ",
    "step @xcite .",
    "block time ",
    "steps allow efficient parallelization , given that large numbers of particles sharing the same block time ",
    "step can then be integrated in parallel .    in section 2 ,",
    "we summarize the tsbts algorithm time - symmetric block time  step algorithm .",
    "we provide definitions for the era concept , and for time - symmetrization of block time  steps . in section 3 ,",
    "we present sample numerical tests for choosing the size of the era .",
    "we show how important is the effect of the era size on the energy errors , and the relationship between era size and iteration number . in section 4 ,",
    "we offer a dynamic era size scheme for both better energy conservation and better memory usage . in section 5",
    ", we present a parallel algorithm for the tsbts scheme with a hybrid force calculation procedure . in section 6 ,",
    "we discuss load balance and parallel performance tests of the algorithm .",
    "section 7 sums up the study .",
    "in the tsbts algorithm , an iterative scheme is combined with an individual block time  step scheme to apply the algorithm to the @xmath0body problem effectively .",
    "there are two important points in this algorithm : the era concept and the time - symmetrization procedure .",
    "the era is a time period in which we collect and store information for all positions and velocities of the particles for every step . at the end of each era , we synchronize all particles with time symmetric interpolation .",
    "this synchronization is repeated many times during the integration period , depending on the size of the era .",
    "let us remember the tsbts algorithm briefly :    we used a self - starting form of the leapfrog scheme ; @xmath2    with taylor expansion for predicted velocities and positions ; @xmath3    one of the easiest estimates for the time ",
    "step criterion is the _ collisional time ",
    "step_. when two particles approach each other , or move away from each other , the ratio between relative distance and relative velocity gives us an estimation .    on the other hand , if particles move at roughly the same velocity , the collision time scale estimate produces infinity when the particles relative velocities are zero . for such cases",
    ", we use a _ free fall time scale _ as an additional criterion , or just take the allowed largest time",
    " steps for those particles .",
    "time - steps are determined using both the free - fall time scale and the collision time scale ( [ eq : nbdt ] ) for particle @xmath4 by taking the minimum over the two criterion and over the all @xmath5 as ;    @xmath6    where @xmath7 is a constant accuracy parameter , @xmath8 and @xmath9 are the relative position and velocity between particles @xmath4 and @xmath5 , and @xmath10 is the pairwise acceleration .    even if aarseth s time  step criterion @xcite serves us better in avoiding such unexpected situations and gives us a better estimation , it needs higher order derivatives and it is expensive for a second order integration scheme .    our time - symmetry criterion is defined in eq.[blockcondition ] .",
    "this criterion gives us the smallest @xmath11 values that suit the condition @xmath12 ;    @xmath13    where @xmath14 is the iteration counter . here ,",
    "@xmath14 and @xmath15 refer to the beginning and end of the time step .    in the case of block time ",
    "step schemes , a group of particles advances at the same time . at each step of the integration ,",
    "a group of particles is integrated with the smallest value of @xmath16 . here",
    ", we refer to the group of particles as particle blocks .",
    "the first group of particles in an era is called the _",
    "first block_.    in the first pass through an era , we perform standard forward integration with the standard block step scheme , without any intention to make the scheme time  symmetric . to compute the forces on the particles with the smallest value of @xmath16",
    ", we use second - order taylor expansions for the predicted positions , while a first - order expansion suffices for the predicted velocity .",
    "predicted positions , velocities , and accelerations for each particle for every time ",
    "step are stored during each era .    in the second pass , which is the first iteration , instead of taylor expansions we use time - symmetric interpolations with stored data .",
    "this time , each time  step is calculated in a different way for symmetrization as in algorithm [ algorithm ] . here , @xmath17 is the block time",
    " step of the integrated particle group , and @xmath18 is the @xmath11th level block time",
    " step , which is obtained from a time - symmetry criterion ( eq.[blockcondition ] ) . if the current time is an even multiple of the current block time ",
    "step , that time value is referred to as _ even time _ , otherwise it is referred to as _ odd time_.",
    "@xmath19 @xmath20 @xmath21 @xmath19    here is the description of the symmetrization scheme for block time",
    " steps ( as in algorithm [ algorithm ] ) :    * if the current time is * _ odd _ * , first , we try to continue with the same time  step . if , upon iteration , that time  step qualifies according to the time - symmetry criterion ( as in eq.[blockcondition ] ) , then we continue to use the same step size that was used in the previous step of the iteration .",
    "if not , we use a step size half as large as that of the previous time  step . *",
    "if the current time is * _ even _ * , our choices are : doubling the previous time  step size ; keeping it the same ; or halving it .",
    "we first try the largest value , given by doubling . if eq.[blockcondition ] shows us that this larger time ",
    "step is not too large , we accept it : otherwise , we consider keeping the time ",
    "step size the same . if eq.[blockcondition ] shows us that keeping the time ",
    "step size the same is okay , we accept that choice : otherwise , we simply halve the time ",
    "step , in which case no further testing is needed .",
    "the same steps are repeated for higher iterations as in the first iteration .",
    "the main steps of the integration cycle is given by algorithm [ seq_algorithm ] .",
    "initialization : + - read initial position and velocity vectors from the source .",
    "+ - arrange size in the memory .",
    "+ - initialize particles forces , time  steps , and next block times .",
    "+ - sort particles according to time blocks .",
    "+ start the iteration for the era .",
    "start the integration for the first block of the era .",
    "predict position and velocity vectors of all particles for the current integration time .",
    "if this is the first step of the iteration , or if the time of the particle is smaller than the current time , do direct prediction : otherwise perform interpolation from the currently stored data .",
    "calculate forces on the active particles .",
    "correct position and velocity vectors of the particles in the block .",
    "update their new time ",
    "steps and next block time .",
    "+ - after the first iteration , symmetrize new time steps according to algorithm [ algorithm ] . sort",
    "particles according to time blocks .",
    "repeat from step 3 while current time is @xmath22 time at the end of the era .",
    "repeat from step 2 until the number of the iteration reaches the iteration limit .",
    "repeat from step 2 for the next era , until the final time is reached .",
    "write the outputs and finish the program .",
    "the size of an era can be chosen as any integer multiple of the maximum allowed time  step .",
    "there is not any important computational difference between dividing the integration to the small era parts and taking the whole simulation in one big era .",
    "however some symmetrization routines such as adjusting the time  steps and interpolating the old data increase the computation time .",
    "additionally , keeping the whole history of the simulation requires a huge amount of memory .",
    "it is important to decide what is the most convenient choice for an era .",
    "we need to store sufficient information from the previous steps to adjust the time  steps with iterations .",
    "to avoid doing additional work and storing a uselessly large history , choosing a large size for the era is not recommended . on the other hand",
    ", the era size must be large enough to store rapid and sharp time  step changes .",
    "we made several tests with different plummer model initial conditions , using different sizes of era .",
    "units were chosen as standard @xmath0body units @xcite , as the gravitational constant @xmath23 , the total mass @xmath24 and the total energy is @xmath25 .",
    "we limited the maximum time ",
    "step to @xmath26 .",
    "the @xmath7 parameter was kept larger than usual to see the error growth in smaller time periods .",
    "the @xmath7 parameter was set as 0.1 for 100-body problems , and 0.5 for 500-body problems .",
    "the plummer type softening length @xmath27 was taken as 0.01 .",
    "each system was integrated for every era size ( @xmath28 ) for 1000 time units .",
    "fig.[fig1 ] shows the energy errors for 5 different 100-body problems with 5 different era sizes . in these test runs ,",
    "time - symmetrized block time ",
    "steps were used with 3 iterations .",
    "we also performed test runs for other era sizes ( @xmath29 ) .",
    "however , the growth of energy errors for these era sizes reached beyond the scales of this figure .",
    "the figure shows that , 3 iterations are not enough to avoid linearly growing errors for large ( here , @xmath30 ) era sizes .",
    "( 120mm,120mm)fig1.eps    we conducted the following tests to see this effect clearly .",
    "fig.[fig2 ] shows the energy errors for 5 different 100-body problems with 5 different era sizes as in the previous figure .",
    "however , we used 5 iterations here . in this figure , the largest era size ( @xmath30 time unit ) does not show a linearly growing error exactly the contrary to the case of 3 iterations.the improvement on energy errors comes directly from the iteration process as we expected .",
    "( 120mm,120mm)fig2.eps    we increased the particle number 5 times , and set the @xmath7 parameter as @xmath31 .",
    "the @xmath7 parameter could have been kept as @xmath32 , but we forced the algorithm to take larger time  steps , which in turn produce larger energy errors for relatively small time periods .",
    "fig.[era_tests_p500_1 ] shows the energy errors for 5 different 500-body problems with 7 different era sizes .",
    "the red curves show the errors for era sizes of @xmath33 , and @xmath34 time units ; the black curves show the errors for era sizes of @xmath35 , and @xmath36 time units .",
    "( 120mm,120mm)fig3.eps    it seems that more iterations are needed to obtain smaller energy errors while working with larger era sizes . if time - symmetric block time ",
    "steps can not be produced with a small number of iterations , the total energy error grows linearly . as indicated by our tests ,",
    "iteration number and era size must be chosen carefully to ensure symmetric block time  steps .",
    "although the size of the era is not very important as long as the iteration number is large enough , a high number of iterations is not the preferred choice , as it demands high computational cost . also , the era size would have to be kept small to avoid the huge memory usage . in practice ,",
    "our tests show that , 5 iterations is not enough to prevent linearly growing errors when we use greater than @xmath30 time unit as the era size",
    ".    on the other hand , the era size must be greater than the greatest time ",
    "otherwise we can not store past information for the iteration process and the algorithm works as a classical block time  step scheme .",
    "our test results for symmetrized time  steps with a small number of iterations in the previous section show that keeping the era size large or small has a clear effect on energy errors . however , the amount of the past position and the velocity information increase with the size of the era .",
    "then , many more iterations are required to obtain optimized time  steps . and increased numbers of iterations consume more cpu time .",
    "let us remember and give some additional details and definitions about the relationship between block time ",
    "steps and era : similar to the _ first block _ definition we provided in section 2 , the last group of particles in an era is referred to as the _",
    "last block_. the current time in the integration for the first and last blocks are referred to as _ first block time _ and _ last block time _ , respectively .    at the end of each era ,",
    "integration of every particle stops at the same time , and new block time ",
    "steps are calculated and assigned for new blocks .",
    "the last block can take the maximum allowed time ",
    "step at the most .",
    "the first block can take any block time ",
    "step smaller than the maximum allowed time  step .",
    "then , particles are sorted according to their block time  steps .",
    "also , every block has its own integration time related to its block time  step .",
    "if we can find the proper criterion to change it , era size can be controlled dynamically .",
    "the simplest choices can vary between 1 time unit and the allowed largest time  step .",
    "our suggestion is : calculate the new block time  steps and the first and last block times at the end of each era , and take the difference between the last and first block times .",
    "this difference gives us a dynamically changing size and we can assign this as the size of the new era .    naturally , sometimes this difference can be larger than 1 time unit , or smaller than the maximum allowed time  step .",
    "also , if all of the particles take the same time  step in any era , the difference goes to zero .",
    "we can use the maximum allowed time  step and any power - of - two times of this era size for the top and bottom limits of the era , respectively . here",
    ", we used @xmath37 multiples of the largest time ",
    "step for the lower limit .",
    "if all of the particles take the largest time  step , or larger time ",
    "steps than the new era size , there will not be enough past information for symmetrization .",
    "for these reasons , era size must not be much smaller than the largest time  step .",
    "initialization ( same as algorithm [ seq_algorithm ] ) .",
    "+ set first and last block times .",
    "calculate dynamic era size ( _ dynamic era size _",
    "= _ last block time _ - _ first block time _",
    "+ ) if _ dynamic era size _ @xmath38",
    "_ maximum time step _",
    "+ @xmath39 _ maximum time step _ + ) if _ dynamic era size _ @xmath40",
    "_ maximum time step _",
    "+ = _ maximum time step _ + start the iteration for the era . start the integration for the first block of the era . predict position and velocity vectors of all particles for the current integration time .",
    "if this is the first step of the iteration , or if the time of the particle is smaller than the current time , do direct prediction : otherwise perform interpolation from the currently stored data . calculate forces on the active particles .",
    "correct position and velocity vectors of the particles in the block .",
    "update their new time ",
    "steps and next block time .",
    "+ - after the first iteration , symmetrize new time steps according to algorithm [ algorithm ] .",
    "sort particles according to time blocks .",
    "repeat from step 5 while current time is @xmath22 time at the end of the era .",
    "repeat from step 4 until the number of the iteration reaches the iteration limit .",
    "repeat from step 2 for the next era , until the final time is reached .",
    "write the outputs and finish the program .",
    "if our estimate of the era size is smaller than our largest time  step , the particles with largest time  steps are excluded from the integration process of the era , and are then left for the next era .",
    "errors of energy conservation oscillate in time , when they happen .",
    "we can use the allowed largest time ",
    "step for the era size in these cases .",
    "the main steps of the algorithm is given by algorithm [ seq_dynera_algorithm ] .",
    "in the tests we did for the dynamic era , we used two choices for era size : equal to the allowed largest time  step , and dynamically changing size as defined above .",
    "we already know from previous runs for these test problems that we obtained the smallest errors on total energies when we took the allowed largest time  steps as the era size .",
    "we performed 3 iterations .",
    "fig.[fig:500dyn1 ] shows the energy errors for 10 different 500-body problems .",
    "the green curves show the results for the dynamically changing era ; the red curves show the results for the fixed era .",
    "fig.[fig:100dyn1 ] shows the energy errors for 10 different 100-body problems .",
    "( 120mm,120mm)fig4.eps    the results for dynamic era size are in the same range with those of fixed era size .",
    "even if the chosen fixed era size ( @xmath41 ) seems like the best choice for previous tests with the same initial conditions and parameters ( i.e. , maximum allowed time  steps , softening and accuracy parameters ) , in general , dynamic era gives modestly better results than fixed era for @xmath41 .",
    "we ran more than 20 tests , and in @xmath42 of them were the errors for dynamic era size larger than errors for fixed era size .",
    "the rest of the results are clearly better than those for fixed era sizes , besides the advantage of reduced memory usage for the same number of iterations .",
    "running times for dynamic era size are @xmath43 less than for fixed era sizes in general .",
    "basically , there are two well known schemes that are used in direct @xmath0body parallelizations : copy and ring .",
    "the ring algorithm is generally preferred for reducing memory usage",
    ". it can be reasonable for shared time ",
    "step codes , but it is not easy to use with block step schemes .",
    "it is also well known from previous works that this algorithm achieves almost the same speedup as the copy algorithm @xcite . the number of the particles in the integrated block changes with every step . in many cases ,",
    "the size of the integrated block can be smaller than the number of the processors .",
    "it is difficult to obtain balanced load distribution for such cases .",
    "we used the copy algorithm .",
    "while it is much easier to extend for block step schemes , the copy algorithm also has the load imbalance problem in classical usage . for any case , block size can be smaller than the number of processors again .",
    "we divided the partitioning strategy into two cases to avoid bad load balancing . in the first case",
    ", we divided the particles when the number of particles in the first block is greater than number of nodes .",
    "this is a kind of data partitioning , with every node containing a full copy of the system . in the second case",
    ", we divide the force calculation of the particles in the first block as a kind of work partitioning .",
    "our parallel algorithm works with the following steps , as in algorithm [ par_algorithm ] .",
    "broadcast all particles .",
    "each node has a full copy of the system .",
    "initialize the system for all particles in all nodes .",
    "every node computes time ",
    "steps for all particles .",
    "compute and sort time blocks . integrate particles in the first block whose block times are the minimum for the era :",
    "+ ) if the number of the first block @xmath44 number of nodes : every processor + calculates forces and integrates + ( number of first time block)/(number of nodes ) particles .",
    "+ ) if the number of the first block @xmath45 number of nodes : every processor + calculates ( number of particles)/(number of nodes ) part of the forces + on the particles of the first block . + update integrated particles .",
    "repeat from step 3 .",
    "we have performed test runs on a linux cluster in itu - hpc lab . with 37 dual core 3.40 ghz intel(r )",
    "xeon(tm ) cpu with myrinet interconnect .",
    "the compute time was measured using mpi_wtime ( ) .",
    "the timing for total compute time was started before the broadcast of the system to the nodes , and ended at the end of integration .",
    "the calculation time of the subset of the particles in the current time block that are being handled by a given processor was taken as the work load of the processor . in the iteration process , the largest time was taken as the work load of the processor for the same time block .",
    "work load of the @xmath4th processor for every active integrated particle group is defined as @xmath46 ; @xmath47 is the number of processors ; the mean work load @xmath48 is :    @xmath49    and load imbalances : @xmath50    fig.[fig : imbalance ] shows the load imbalance for a 1000-body problem .",
    "we used 12 processors . in direct @xmath0body simulations ,",
    "a 1000 body is not a big number for 12 processors @xcite . here ,",
    "load imbalance is not seen as more than @xmath51 in general . moreover , load imbalance is smaller than expected .",
    "the main reason for this is in the iteration routines of the tsbts algorithm , which increases both communication and calculation times for active particles . also , when the number of particles in the first block is smaller than the number of nodes , work partitioning is applied in the algorithm , which also increases communication time .",
    "( 120mm,120mm)fig6.eps    @xmath52 is the running time for one processor ; @xmath53 is the running time for @xmath11 processors .",
    "@xmath54 , and @xmath55 are given respectively , as : @xmath56    @xmath57    fig.[fig : speedup ] and fig.[fig : efficiency ] show @xmath58 and @xmath59 results of symmetrized and non - symmetrized block time  steps for an 10000-body problem initial conditions with plummer softening length of @xmath60 and accuracy parameter @xmath61 .",
    "only one iteration with the tsbts algorithm corresponds to individual block time ",
    "step algorithm without symmetrization .",
    "the speedup result for 3 iterations is clearly better than the result for 1 iteration .",
    "these results show that the communication / calculation ratio decreases with the iteration process , though iteration needs much more computation time .",
    "( 120mm,120mm)fig7.eps    ( 120mm,120mm)fig8.eps    for moderately short integration times , as in one time unit cases , the same error bounds can be obtained with less computation times by classical algorithms .",
    "however , the algorithm already shows its advantages in long time integrations .",
    "fig.[fig : errcpu ] shows relative energy errors and cpu times for 20 different 500-body problems with 2 different accuracy parameters ( @xmath62 ) for 1 cpu .",
    "each system was integrated for 1 and 3 iterations and 1000 time units . even if it is not possible to obtain the same degree of energy errors for different test problems , the results are still highly promising .",
    "we obtained significantly better energy errors with the tsbts algorithm ( 3 iterations ) than with the classical individual block time ",
    "step algorithm ( 1 iteration ) for the same accuracy parameters ( @xmath63 ) in all tests . also , in some tests ( more or less in @xmath64 of the tests )",
    ", we obtained better results with 3 iterations for 10 times larger accuracy parameters than with 1 iteration runs for @xmath65 .",
    "for example in one of our 500-body problems , we obtained a relative energy error of @xmath66 with @xmath63 for 3 iterations , while it was @xmath67 for 1 iteration . to reach the same error bound with one iteration for 1000 time units",
    ", we had to reduce the accuracy parameter to 10 times smaller ( @xmath68 ) .",
    "then , we obtained relative energy error of @xmath69 with 1 iteration . in this example , calculation times for 1 and 3 iterations with @xmath63 were @xmath70 sec . , and @xmath71 sec",
    "respectively , while the time was @xmath72 sec . for @xmath65 with 1 iteration . here ,",
    "3 iterations increase the calculation time by almost a multiple of 2 . however , calculation time increases by a multiple of 10 , while the accuracy parameter is reduced by the same order .",
    "fig.[fig : wallclocktime ] shows running time requirements of the algorithm for the same 10000-body problem , both for 1 and 3 iterations , for one @xmath0body time unit .",
    "the tsbts algorithm needs up to 5 times more run time than 1 iteration case with 1 cpu for this test ( for 500-body tests , this ratio was 4.75 as an average of their run times ) .",
    "this extra time is consumed by iteration and symmetrization procedures .",
    "the time - consuming ratio between the 1 and 3 iteration cases reduces to almost @xmath73 times when we increased the number of processors .",
    "we have analyzed the era concept in greater detail for time symmetrized block time  steps .",
    "our test results show that the size of the era must be chosen carefully .",
    "this is important , especially for long - term simulations with highly desirable energy conservations .",
    "the era size is also important to avoid the need for additional data storage and a uselessly high number of iterations , which require too much running time .    in this work ,",
    "we suggested a dynamically changing size for the era .",
    "this enables us to follow the adaptively changing size for these time periods . in this scheme",
    ", the era size will be well - adjusted to the physics of the problem .",
    "in many cases , we obtained better energy errors than previous algorithm with fixed era size .",
    "additionally , we produced a copy algorithm - based parallel scheme combining with our time symmetrized block time ",
    "step scheme .",
    "we divided the force calculation into two approaches , according to the number of the integrating particles , to avoid bad load balancing .",
    "if the number of particles in the integrated block was greater than the number of processors , we used the classical approach the copy algorithm to calculate forces . if we had a lower number of particles than processors to integrate , we divided the force calculations between the processors using work partitioning .",
    "parallelization of direct @xmath0body problem already features some difficulties regarding communication costs .",
    "communication times dramatically increase with the number of processors .",
    "previous works show that , using more than 10 processors for a few thousands particles does not result in a substantial gain @xcite .",
    "this problem is replicated in individual time ",
    "step and block time  step cases .",
    "even if we need to expend some additional communication efforts in our work partitioning approach , we obtain good load balancing results with this approach .",
    "also , the iteration process requires much more effort .",
    "speedup and efficiency results are as we expected for current implementations .",
    "scaling of the algorithm can be increased by using hyper systolic or other efficient algorithms @xcite in future works .",
    "spinnato ps , van  albada gd and sloot pma ( 2000 ) performance analysis of parallel @xmath0body codes .",
    "proceedings of high performance computing and networking , lecture notes in computer science v : 1823 p : 249 - 260"
  ],
  "abstract_text": [
    "<S> the time - symmetric block time  step ( tsbts ) algorithm is a newly developed efficient scheme for @xmath0body integrations . </S>",
    "<S> it is constructed on an era - based iteration . in this work , </S>",
    "<S> we re - designed the tsbts integration scheme with dynamically changing era size . </S>",
    "<S> a number of numerical tests were performed to show the importance of choosing the size of the era , especially for long time integrations . </S>",
    "<S> our second aim was to show that the tsbts scheme is as suitable as previously known schemes for developing parallel @xmath0body codes . in this work , we relied on a parallel scheme using the copy algorithm for the time - symmetric scheme . </S>",
    "<S> we implemented a hybrid of data and task parallelization for force calculation to handle load balancing problems that can appear in practice . using the plummer model initial conditions for different numbers of particles </S>",
    "<S> , we obtained the expected efficiency and speedup for a small number of particles . </S>",
    "<S> although parallelization of the direct @xmath0body codes is negatively affected by the communication / calculation ratios , we obtained good load balance results . </S>",
    "<S> moreover , we were able to conserve the advantages of the algorithm ( e.g. , energy conservation for long  term simulations ) . </S>"
  ]
}