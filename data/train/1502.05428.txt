{
  "article_text": [
    "although the source - channel separation architecture is asymptotically optimal in the point - to - point communication setting @xcite as well as several classes of multiuser communication settings ( see _ e.g. , _",
    "@xcite and references therein ) , uncoded schemes have several particularly attractive properties .",
    "firstly , they have very simple encoders and decoders ; secondly , they belong to the so - called zero - delay codes , which can avoid the long delay required to approach the asymptotic performance in the separation - based schemes ; lastly , they are in fact optimal in some settings , while the separation - based schemes are not ( see _ e.g. _ , @xcite ) .",
    "it was shown in @xcite that uncoded schemes are optimal when certain matching conditions involving the source probability distribution , the channel transition probability distribution , the channel cost function and the distortion measure function are satisfied . though the focus in @xcite was mainly on the point - to - point setting , recent results @xcite suggest that the concept of matching indeed carries over to the multiuser case .",
    "in fact , in multiuser settings , matching may occur naturally when the distortion measure , the channel cost function and source distribution are all fixed , and the channel parameters , which represent physically meaningful quantities , satisfy certain conditions . in this work ,",
    "we consider such matching , particularly , when the sources and the channels are gaussian , the channel constraints are on the expected average signal power , the distortion measure is the mean squared error ( mse ) , and only the channels parameters , such as the channel amplification factors and the additive noise powers , are allowed to vary .    in this context , of interest is whether for a fixed source and fixed coding parameters , the distortion vector such induced is on the boundary of the achievable distortion region ( and thus optimal ) .",
    "more specifically , we seek to answer the following questions :    * is there a set of ( explicitly ) computable conditions that can be used to certify a fixed uncoded scheme to be optimal for a given source and channel pair ? * if so , is there a non - trivial set of channels that satisfy such conditions for a given source and uncoded scheme pair",
    "?    we shall refer to this kind of channels as `` matched channels '' ; a dual question is to ask for `` matched sources '' , however in the context of problems considered here , the dual question is notationally more involved , and thus we choose to investigate the problems from the perspective of `` matched channels '' .",
    "one can also ask for `` matched distortion measures '' , similarly as the approach taken in @xcite , however in the gaussian setting we consider here , fixing the mse distortion is practically more important and well - motivated .",
    "the set of matched channels should be distinguished from the complete set of channels for which the given uncoded scheme is optimal .",
    "the former may be a strict subset of the latter , since the former may be only sufficient for an uncoded scheme to be optimal , which usually depends on the specific outer bounding technique employed . characterizing the latter region",
    "is naturally more difficult than answering the questions we posed above .",
    "the two questions posed above are in essence the two facets of the same question .",
    "since we only provide conditions for matching , or in other words , sufficient conditions for the scheme to be optimal , the set of matched channels may in fact be empty . a trivial condition to answer",
    "the first question is simply an impossible one such that we would never be able to certify a channel to be matched .",
    "thus the second question is important , and we show indeed for the two problems considered here , there are non - trivial channels that match the source and the uncoded scheme .    traditionally , research in information theory asks for characterization of certain achievable region , for which we first derive an expression for an outer bound , and derive an expression for an inner bound , and then make comparison of them .",
    "this approach can be challenging because it usually involves optimization over a set of parameters , and solving such an optimization problem explicitly can be difficult .",
    "it is not clear whether the obstacle mainly stems from the intractable nature of the underlying communication problem , or it is mainly caused by the embedded optimization problem .",
    "the aforementioned difficulty motivates the formulation of the first question , which is a decision problem instead of an optimization problem .",
    "an analogy of this situation can be found in computer science algorithm research , where instead of asking whether an optimization problem can be solved in polynomial time , the alternative question is asked whether a decision ( _ e.g. _ , regarding a solution is above a threshold ) can be made in polynomial time .",
    "our problem formulation naturally leads to a different approach in the investigation .",
    "instead of focusing on comparison of the inner bounds and outer bounds using their expressions , we focus on the necessary conditions that the outer bound becomes tight , _",
    "i.e. , _ the conditions when the information inequalities hold with strict equality . with fixed source and fixed coding parameters",
    ", the coding vector can be substituted into the conditions , and the necessary and sufficient conditions for such equality can be derived .",
    "the outer bounds naturally provide certain `` decoupled '' conditions , which significantly simplifies the overall task .",
    "though this approach may have inherently been used by many researchers in the past , its effectiveness becomes particularly evident in our investigation of uncoded schemes in the joint source channel communication setting .    in the rest of the paper , we focus specifically on two joint source channel coding problems using the approach outlined above .",
    "the first problem is to send correlated gaussian sources on a gaussian broadcast channel where each receiver is interested in reconstructing only one source component ( or equivalently one specific linear function of the source ) under the mse distortion measure .",
    "the second problem is to send vector gaussian sources on a gaussian multiple - access channel , where each transmitter observes a noisy combination of the source , _",
    "i.e. , _ a case of the vector ceo problem , and the receiver wishes to reconstruct the source components ( or equivalently linear functions of the source components ) under the mse distortion measure .",
    "general conditions for matching are derived , which either include or generalize well - known existing results on the optimality of uncoded schemes in the multiuser setting .",
    "particularly notable are the following cases :    * the first problem generalizes the two - user case considered in @xcite and @xcite to the @xmath0-user case , for which we show that the uncoded scheme is optimal for a large set of sources and channels ; our results reveal that uncoded scheme can still be optimal when some source components are negatively correlated . * the results on the second problem includes as specials cases the symmetric scalar gaussian ceo problem @xcite , the problem of sending bivariate gaussian sources on a gaussian multiple - access channel @xcite , and sending remote ( noisy ) bivariate gaussians on a gaussian multiple - access channel @xcite .",
    "our results reveal that in addition to the symmetric case considered in @xcite , uncoded scheme is also optimal when the sensor observation quality is proportional to the channel quality .",
    "these results also allow the sensor observations to have more general correlation structure and the observations to be noisy , thus extending the results in@xcite and @xcite .",
    "when viewed from the perspective of computation , our result also provides new characterizations for the problem of computing linear functions of gaussian random variables on the gaussian multiple - access channels considered in @xcite and @xcite .",
    "notationally , we write for a source @xmath1 at time @xmath2 as @xmath3 $ ] , and a length-@xmath4 vector as @xmath5 . for a set of coefficients @xmath6 , we sometimes write it in a ( column ) vector form as @xmath7 . for a real matrix @xmath8",
    ", we write its transpose as @xmath9 .",
    "the positive semidefinite order is denoted as @xmath10 .",
    "in this section we consider the problem of broadcasting correlated gaussian sources on a gaussian broadcast channel , which can be described as follows ; see also fig . [",
    "fig : bc ] for an illustration .",
    "let the zero - mean gaussian source be @xmath11,s_2[n],\\ldots , s_m[n])$ ] with covariance matrix @xmath12 , which is assumed to be full rank .",
    "the channel is given by @xmath13=x[n]+z_m[n],\\end{aligned}\\ ] ] where @xmath14 are zero - mean additive noises which are mutually independent , with variances @xmath15 , respectively ; the channel input must satisfy an average power constraint @xmath16 .",
    "the transmitter encodes the length-@xmath4 source vector @xmath17 into a length-@xmath4 channel vector @xmath18 , and the @xmath19-th receiver reconstructs from the channel output vector @xmath20 the source vector @xmath21 as @xmath22 , resulting in a distortion @xmath23-\\hat{s}_m[n])^2 $ ] .",
    "we omit the formal problem definition using encoding and decoding function , which is standard and can be obtained by extending that in , for example , @xcite .",
    "the uncoded scheme of interest has the form @xmath24=\\sum_{m=1}^m \\alpha_m s_m[n],\\end{aligned}\\ ] ] such that @xmath25=p.\\end{aligned}\\ ] ] in other words , at each time instance , the channel input is simply a linear combination of the source components with coefficients @xmath6 , such that the resulting signal has an expected variance that is equal to the power constraint @xmath26 .",
    "we shall assume @xmath27 .",
    "the decoders simply estimate @xmath28 $ ] as @xmath29= { \\mathbb{e }   } ( s_m[n]|y_m[n])$ ] , at each time instance @xmath30 at decoder @xmath31 .",
    "notice that the problem can be equivalently formulated as computation of linear functions of gaussian sources on the broadcast channel , however this alternative formulation is notationally more involved .",
    ", width=491 ]    define @xmath32 the main result is summarized in the following theorem , which gives a matching condition in a positive semidefinite form .",
    "[ theorem : bc ] a gaussian broadcast channel is said to be matched to a given source and an uncoded scheme with non - zero parameters @xmath7 , and the distortion vector induced by the given scheme is on the boundary of the achievable distortion region thus optimal , if @xmath33 where the entries of the symmetric matrix @xmath34 are specified as @xmath35,\\quad m=1,2,\\ldots , m.\\end{aligned}\\ ] ]    this theorem establishes a condition that is sufficient to guarantee a distortion vector induced by an uncoded scheme to be on the boundary of the achievable distortion region , and thus an optimal solution .",
    "the matrix @xmath34 may seems mysterious at the first sight , however , the reason for introducing this matrix will become clear shortly .",
    "this theorem clearly answers our first question regarding conditions that can be used to certify whether a given uncoded scheme is optimal .",
    "in fact , it also provides clues on the second question regarding whether there exist non - trivial channels that such matching is possible .",
    "indeed , in section [ sec : cholesky ] and section [ sec : bcchannels ] we establish several properties of matched channels , through which an answer to the second question is given . before presenting those results , the proof of this theorem",
    "is presented next in two parts : the critical conditions in a novel outer bound are outlined in section [ sec : bcouter ] , and then these conditions for the bound to hold with equality in the uncoded scheme are analyzed in section [ sec : bcinner ] .",
    "the proof details for the outer bound are relegated to the appendix .      in order to obtain the matching condition",
    ", we first derive a novel outer bound for this problem . an important technique in the derivation of this outer bound",
    "is the introduction of certain appropriate random variables outside of the original problem .",
    "this approach is partly motivated by our previous work @xcite , which can further be traced back to ozarow @xcite .",
    "consider @xmath0 zero - mean gaussian random variables @xmath36 , independent of everything else , with covariance matrix @xmath37 , and write @xmath38=s_m[n]+w_m[n].\\end{aligned}\\ ] ]    the outer bound will be written as a necessary condition that any distortion vector has to satisfy .",
    "for this purpose , we bound the following quantity for any encoding and decoding functions : @xmath39,\\end{aligned}\\ ] ] where @xmath40 for notational simplicity .",
    "an almost identical quantity was used in @xcite to obtain an approximate characterization for the distortion region of the gaussian broadcast problem with bandwidth mismatch .",
    "we shall upper - bound this quantity using the channel properties and lower - bound it using the source reconstruction requirements , then combine them to obtain an eventual outer bound .",
    "this quantity can be upper - bounded as given in the appendix as @xmath41 with equality holds if and only if @xmath42 and the following condition stemming from the entropy power inequalities hold with equality @xmath43=\\exp\\left[\\frac{2}{n}h(y^n_{m+1}|u^n_m , u^n_{m-1},\\ldots , u^n_1)\\right]+2\\pi e[\\sigma^2_{z_m}-\\sigma^2_{z_{m+1}}],\\nonumber\\\\ & \\qquad\\qquad\\qquad\\qquad\\qquad \\qquad\\qquad\\qquad\\qquad\\qquad \\qquad\\qquad\\qquad\\qquad\\qquad m=1,2,\\ldots , m.\\label{eqn : epi}\\end{aligned}\\ ] ] the conditions in ( [ eqn : epi ] ) are standard , as bergmans @xcite also used the entropy power inequality to establish the gaussian broadcast channel capacity , and in general a gaussian codebook suffices to make them equalities .",
    "the condition ( [ eqn : bcpower ] ) intuitively requires that the power is fully utilized .",
    "the condition ( [ eqn : degerate ] ) is however rather peculiar , which essentially requires the noisy source @xmath44 to be as useful as the real source @xmath17 in determining the channel output @xmath45 .    the quantity @xmath46 can also be lower - bounded as given in the appendix , where its individual summands are bounded as @xmath47\\geq \\frac{|\\sigma_{s_1,s_2,\\ldots , s_m}+\\sigma_{w_1,w_2,\\ldots , w_m}|}{\\pi^m_{j=1}(d_j+\\sigma^2_{w_j})},\\label{eqn : bcsource}\\end{aligned}\\ ] ] with equality holds if and only if @xmath48,\\quad m=1,2\\ldots , m,\\label{eqn : bccondition1}\\\\ h(u^n_m|y^n_m , u^n_1,u^n_2,\\ldots , u^n_{m-1})&=h(u^n_m|y^n_m),\\quad m=2,3,\\ldots , m.\\label{eqn : bccondition2}\\end{aligned}\\ ] ] the conditions in ( [ eqn : bccondition1 ] ) are standard which can be viewed as requiring the codes to achieve the given distortions with equality , however the conditions in ( [ eqn : bccondition2 ] ) are peculiar which essentially require all the information @xmath49 on @xmath50 to be from @xmath20 .",
    "combining ( [ eqn : bcchannel ] ) and ( [ eqn : bcsource ] ) , we obtain an outer bound , or outer bounds since each set of the auxiliary random variables @xmath36 provides one specific outer bound . in the approach we shall take , the precise form of this outer bound is less important than the extracted matching conditions ( [ eqn : degerate ] ) , ( [ eqn : bcpower ] ) , ( [ eqn : epi ] ) , ( [ eqn : bccondition1 ] ) and ( [ eqn : bccondition2 ] ) .",
    "in fact , the conditions ( [ eqn : bcpower ] ) , ( [ eqn : epi ] ) and ( [ eqn : bccondition1 ] ) can be satisfied simply by choosing a proper jointly gaussian coding scheme , yet the conditions ( [ eqn : degerate ] ) and ( [ eqn : bccondition2 ] ) are the effectual non - trivial conditions .",
    "note that from the problem setting and taking into consideration the fact that physical degradedness is equivalent to stochastic degradedness in the broadcast setting , we have the markov string @xmath51 where we have utilized the fact that physical degradation is equivalent to stochastic degradation in broadcast channels .",
    "this markov string is not sufficient to guarantee ( [ eqn : degerate ] ) and ( [ eqn : bccondition2 ] ) , and thus they require special attention .",
    "we first introduce some additional notation and make a few observations .",
    "notice that due to the power constraint , the coefficient vector @xmath52 should satisfy @xmath53 and it follows that @xmath54    due to the jointly gaussian distribution of the uncoded scheme , we can write @xmath55 where the three components are mutually independent , since @xmath56 $ ] ; we have also omitted the time index @xmath57 $ ] to simplify the notation .",
    "it follows that the covariance matrix of @xmath58 given @xmath59 can be decomposed as follows @xmath60 where @xmath61 let @xmath62 for @xmath31 .    with the above observations , we now return to the derivation of the forward matching conditions .",
    "as mentioned earlier , we need to substitute the random vectors specified by the uncoded scheme , _",
    "i.e. , _ assigning @xmath63=\\sum_{m=1}^m \\alpha_m s_m[n]$ ] , into the critical conditions ( [ eqn : degerate ] ) , ( [ eqn : bcpower ] ) , ( [ eqn : epi ] ) , ( [ eqn : bccondition1 ] ) and ( [ eqn : bccondition2 ] ) in order to identify the matching conditions .",
    "it is straightforward to see that ( [ eqn : bcpower ] ) , ( [ eqn : epi ] ) and ( [ eqn : bccondition1 ] ) indeed hold with equality due to the jointly gaussian distribution of the uncoded scheme , and the chosen coefficients .",
    "thus we only need to focus on ( [ eqn : degerate ] ) and ( [ eqn : bccondition2 ] ) , which in the context of the uncoded scheme are equivalent to the following single - letter forms @xmath64    to satisfy the condition ( [ eqn : bcindep ] ) with the jointly gaussian uncoded scheme , for any @xmath65 , we must have @xmath66+\\beta_m\\beta_j\\sigma^2_{x|y_m}=0 $ ] for @xmath67 .",
    "this specifies all the off - diagonal terms of @xmath68 , as @xmath69=\\gamma_{m , j}=-\\beta_m\\beta_j\\sigma^2_{x|y_m},\\quad",
    "1\\leq j < m,\\quad m=2,3,\\ldots , m .",
    "\\label{eqn : crossterms}\\end{aligned}\\ ] ] it remains to determine the diagonal entries of @xmath68 .",
    "since @xmath70 in order to satisfy the condition ( [ eqn : bcasifnonoise ] ) with equality , we must have @xmath71 where we have taken into account of the fact that @xmath12 is full rank .",
    "thus for any @xmath31 , @xmath72= { \\mathbb{e }   } [ v_m\\sum_{j=1}^m\\alpha_jv_j]=0.\\end{aligned}\\ ] ] it follows that @xmath73 can be determined from @xmath74-\\sum_{j = m+1}^m\\alpha_j { \\mathbb{e }   } [ v_mv_j]=\\beta_m\\sigma^2_{x|y_m}\\sum_{j=1}^{m-1}\\alpha_j\\beta_j+\\beta_m\\sum_{j = m+1}^m\\alpha_j\\beta_j\\sigma^2_{x|y_j},\\end{aligned}\\ ] ] since @xmath27 .",
    "thus the conditions ( [ eqn : bcasifnonoise ] ) and ( [ eqn : bcindep ] ) being equalities uniquely specify the matrix @xmath68 .",
    "conversely , as long as the matrix @xmath75 is positive semidefinite , the conditions ( [ eqn : bcasifnonoise ] ) and ( [ eqn : bcindep ] ) hold with equality and the corresponding auxiliary random variables @xmath36 can be found , and the outer bound derived previously is thus tight .",
    "this is exactly the matching condition given in theorem [ theorem : bc ] .",
    "* remark : * the outer bounds conditions ( [ eqn : degerate ] ) and ( [ eqn : bccondition2 ] ) in the context of the uncoded scheme provide two constraints on the matrix @xmath68 . their effects on the matrix @xmath68 are largely decoupled : the condition required by ( [ eqn : bccondition2 ] ) being equal determines the off - diagonal entries of @xmath68 , while the condition ( [ eqn : degerate ] ) determines its diagonal entries .",
    "this decoupling effect is particularly helpful in deriving the matching conditions . in the second problem we consider in the next section , _",
    "i.e. , _ the multiple access channel problem , this decoupling effect is even more pronounced .",
    "the condition given theorem [ theorem : bc ] is in a positive semidefinite form , however , due to the specific problem structure , it can also be represented as a set of recursive conditions , which is discussed in this section .",
    "this alternative representation also leads to a necessary condition for matching to hold , which plays an instrumental role for several results given in section [ sec : bcchannels ] , where we answer the second question regarding the existence of non - trivial set of matched channels .    determining whether a matrix is positive semidefinite is equivalent to computing the ldl decomposition , and checking whether the resultant diagonal matrix in the decomposition has non - negative entries .",
    "the matrix @xmath75 is positive semidefinite if and only if the diagonal matrix in the ldl decomposition has only non - negative entries .",
    "computationally this can be accomplished with the cholesky factorization @xcite on the matrix @xmath75 .",
    "here we provide an intuitive description of the cholesky factorization in the context of the problem being considered , and its conceptual interpretation as the recursive thresholding determination for the channel to yield a matching .    in the first step of the cholesky factorization",
    ", we use symmetric column and row gaussian elimination to eliminate all the entries of the @xmath0-th column and the @xmath0-th row , except the diagonal entry . denote the resulting upper - left @xmath76 matrix after this first step as @xmath77 . a necessary condition for the matrix @xmath75 to be positive definite is that the lower right entry of the matrix @xmath75 is strictly positive , or all the entries on the last column are zero .",
    "notice that the condition only involves @xmath78 or the channel noise power @xmath79 , which yields a necessary condition on @xmath79 in the form of @xmath80 .",
    "continue the cholesky factorization on @xmath77 , and a similar necessary condition is its lower right entry is strictly positive , or the entries on the @xmath81-th row of @xmath77 are zero .",
    "similarly as the previous step , the condition on @xmath82 is found to be in the form that @xmath83 .    continuing",
    "this process will yield a set of conditions in the form of @xmath84 the matrix @xmath75 is positive definite if and only if all such threshold conditions are satisfied .",
    "notice that the threshold function @xmath85 for @xmath86 depends on the channel noise power values @xmath87 , but not on @xmath88 .",
    "thus these functions @xmath89 , @xmath90 can be viewed as a recursive threshold checking ( or determination ) procedure , and the channel noise power @xmath91 needs to be chosen to be larger than the threshold determined by @xmath87 in every step to yield a matching . given the above observation",
    ", it is natural to speculate that if a channel is matched , then any more noisy channel also induces a match .",
    "this intuition is in fact correct , and the statement is made more rigorous in the next section as corollary [ coro1 ] .",
    "one necessary condition for a matching to exist is that the matrix @xmath34 is positive semidefinite .",
    "we can thus apply the cholesky factorization technique on this particular matrix to obtain a necessary condition for matching to exist .    for the matrix @xmath34",
    "constructed previously to be positive semidefinite ( with @xmath92 ) , it must be true that @xmath93 , @xmath94 .",
    "note that this condition is essentially independent of the channel , as long as the channel is not perfect .",
    "this lemma is proved in the appendix .      with lemma 1",
    ", we can establish several properties of the set of matched channels , given next as corollaries to theorem [ theorem : bc ] .",
    "their proofs are provided in the appendix .",
    "these properties essentially provide an answer to the second question posed earlier , and we shall also further illustrate such sources and channels using an example .",
    "[ coro1 ] if an uncoded scheme is matched on @xmath95 , then it is matched and thus optimal on any channel with noise powers @xmath96 where @xmath97 , @xmath31 .",
    "the corollary reveals a property of matched channels : once a channel is matched , any channel with more noise is also a matched channel and thus the uncoded scheme is optimal .",
    "the next corollary states , from the perspective of only the source and the uncoded scheme parameters , the necessary and sufficient condition for matching to exist .",
    "[ coro2 ] matching ( on a broadcast channel with finite noise powers ) exists , if and only if @xmath98 and the matrix @xmath99 has its largest eigenvalue being 1 with multiplicity 1 , where @xmath100 is a diagonal matrix with diagonal entries being @xmath101 moreover , if the above condition holds , then any channel with @xmath102 is a matched channel , where @xmath103 , and @xmath104 is the second largest eigenvalue of the matrix @xmath99 .",
    "* remark : * if the entries of @xmath105 are strictly positive , then matching is always possible .",
    "this follows from the fact that the matrix @xmath99 has positive entries , and @xmath106 is its positive eigenvector , such that @xmath107 is its largest eigenvalue with multiplicity 1 ( by perron - frobenius theorem @xcite ) .",
    "different from the case discussed in the previous remark , the next corollary gives another sufficient condition for matching to occur when the sources and the coding parameters satisfy the same positive correlation condition .",
    "[ coro3 ] let the entries of the matrix @xmath108 be strictly positive",
    ". denote the entries of @xmath12 as @xmath109 , and define @xmath110 any channel with @xmath111 such that @xmath112 for @xmath65 is a matched channel .",
    "* remark : * @xmath113 as defined above may in fact be negative",
    ". however this does not cause any discrepancy due to the requirement @xmath111 . as a reality check ,",
    "notice that @xmath114 but @xmath115 unless @xmath116 , which however would contradict our assumption .",
    "it thus follows @xmath117 and thus @xmath118 always holds under the condition in the corollary .",
    "* remark : * for the symmetric case where @xmath119 , @xmath120 , @xmath121 and @xmath122=\\beta x$ ] , for @xmath94 . a necessary and sufficient condition for matching is simply @xmath123    to see this , notice that @xmath124.\\end{aligned}\\ ] ] and @xmath125 can be computed as @xmath126 checking the first condition in the cholesky factorization , it is easily verified that ( [ eqn : symmetric ] ) is a necessary condition for matching .",
    "however , from corollary [ coro3 ] , it is seen that it is sufficient to choose any @xmath112 , where @xmath127 , @xmath65 .",
    "this is exactly condition ( [ eqn : symmetric ] ) .",
    "pairs for which matching is possible , given in shade .",
    "[ fig : rho1rho2],width=302 ]    let us consider a source with three components whose covariance matrix is either @xmath128 or @xmath129 and further assume that the coefficients are chosen @xmath130 in the uncoded scheme .",
    "in addition to the constraint that the matrix @xmath131 must be positive definite , for a matching to exist , the condition in corollary [ coro2 ] must be satisfied .",
    "it can be shown that the eigenvalues of @xmath132 are @xmath133 and we must have @xmath134 and @xmath135 . in the appendix , we show that the valid choices are the @xmath136 pairs such that @xmath137 the corresponding region is plotted in fig [ fig : rho1rho2 ] . notice that the two matrices are equivalent for the purpose of determining whether matching is possible , thus the region in fig [ fig : rho1rho2 ] is valid for both cases .    next let us fix a @xmath136 pair , and consider the region of @xmath138 pairs such that matching occurs .",
    "the tradeoffs can be computed explicitly , and are illustrated in fig .",
    "[ fig : n1n2 ] for @xmath139 .",
    "the circles in the plots give the channels specified by corollary [ coro2 ] .",
    "the channels given by corollary [ coro3 ] can be computed directly ( given as the dots ) , which is loose in the first case , but on the lower boundary ( and it is an extreme point ) for the second case . since @xmath140 , we also include this boundary in the plot .",
    "for the first case , the boundary @xmath141 is also shown , while for the second , the lower bound @xmath142 required by the function @xmath143 in the first step of the cholesky factorization is shown .",
    "the corresponding channels that matching occurs are those inside the fan regions .",
    "note that there is a tension between the noise powers @xmath144 and @xmath145 for matching to occur with for the fixed source and uncoded scheme .",
    "for the two covariance matrices ( [ eqn : cov1 ] ) and ( [ eqn : cov2 ] ) , respectively .",
    "[ fig : n1n2],width=604 ]",
    "in this section we consider the problem of sending correlated gaussian sources on a gaussian multiple - access channel , where the transmitters observe noise linear combinations of the source components ; see also fig .",
    "[ fig : mac ] for an illustration .",
    "a zero - mean vector gaussian source @xmath11,s_2[n],\\ldots , s_m[n])$ ] has a covariance matrix @xmath12 .",
    "there are a total of @xmath146 sensors , whose observations are @xmath147,t_2[n],\\ldots , t_l[n])$ ] , respectively , with covariance matrix @xmath148 .",
    "the sources and observations are jointly gaussian .",
    "each sensor observes @xmath149 , encodes it under an average transmission power constraint @xmath150 , @xmath151 .",
    "the channel output is given as @xmath152=z[n]+\\sum_{\\ell=1}^l\\delta_\\ell x_\\ell[n],\\end{aligned}\\ ] ] where @xmath153 .",
    "the receiver wishes to reconstruct @xmath17 using channel output @xmath154 to minimize the individual mse measure , which achieves mse distortion @xmath155 for @xmath156 , _",
    "i.e. _ , @xmath23-\\hat{s}_m[n])^2 $ ] .",
    "notice that due to the jointly gaussian distribution , we can write @xmath157\\triangleq \\tilde{s}_m=\\sum_{\\ell=1}^l\\gamma_{m,\\ell}t_\\ell,\\quad m=1,2,\\ldots , m.\\end{aligned}\\ ] ] the parameters @xmath158 can be conveniently written in a matrix form @xmath159 , and computed as @xmath160 where @xmath161 is the cross - covariance matrix between vectors @xmath162 and @xmath163 .",
    "notice that the problem can be equivalently formulated as computation of linear functions of gaussian sources on the multiple - access channel . in this alternative setting , the functions to be computed are @xmath162 , which can be represented as noisy linear functions of the sensor observations @xmath163 .",
    "this alternative formulation is notationally more involved in the current problem setting , but we shall explore this connection in a separate work .",
    "we assume @xmath164 , and consider the case that the matrices @xmath12 , @xmath148 , @xmath165 and @xmath161 all have full ( row ) rank , which hold in general except certain degenerate cases .",
    "denote the entries of @xmath148 as @xmath166 .",
    "the uncoded scheme we consider is @xmath167=\\eta_\\ell\\sqrt{\\frac{p_\\ell}{\\psi_{\\ell,\\ell}}}t_\\ell[n],\\quad \\ell=1,2,\\ldots , l,\\label{eqn : xform}\\end{aligned}\\ ] ] where @xmath168 is either @xmath169 or @xmath170 to be specified next . in other words",
    ", each sensor sends its noisy observation directly using the full power , but it can choose whether to negate its observations .",
    "the @xmath19-th receiver estimates @xmath28 $ ] as @xmath29= { \\mathbb{e }   } [ s_m[n]|y[n]]$ ] .",
    "define @xmath171^{-1}\\nonumber\\\\ & \\qquad\\cdot\\sigma_{(s_1,s_2,\\ldots , s_m),(t_1,t_2,\\ldots , t_l)}\\sigma_{t_1,t_2,\\ldots , t_l}\\left(\\delta_1",
    "\\eta_1\\sqrt{\\frac{p_1}{\\psi_{1,1}}},\\delta_2 \\eta_2\\sqrt{\\frac{p_2}{\\psi_{2,2}}},\\ldots,\\delta_l \\eta_l\\sqrt{\\frac{p_l}{\\psi_{l , l}}}\\right)^t,\\label{eqn : alphas}\\end{aligned}\\ ] ] and we assume @xmath27 , @xmath31 , which is true in general except certain degenerate cases . our main result on this problem is summarized in the following theorem .",
    ", width=604 ]    [ theorem : mac ] a gaussian multiple - access channel is said to be matched to a given gaussian source and an uncoded scheme with parameters @xmath172 , and the distortion vector induced by the given scheme is on the boundary of the achievable distortion region and thus optimal , if    1 .",
    "@xmath173 ; 2 .",
    "the vector @xmath174 is in the row space of the matrix @xmath161 ; 3 .",
    "@xmath175 , where @xmath104 is the second largest eigenvalue of the matrix @xmath176 , where @xmath100 is a diagonal matrix with diagonal entries @xmath177 and @xmath178 s are the entries of the matrix @xmath179    these conditions can be intuitively explained as follows : condition one guarantees that the channel inputs from all transmitters coherently add up ; condition two stems from the requirement that the noise observations should serve the same role as the underlying source for the chosen power constraints and amplification factors , _",
    "i.e. , _ as if the observation noise does not exist ; condition three is similar to the effect in the previous problem where once a channel is matched , a more noisy channel will also induce a match .",
    "when all @xmath180 , we can simply choose @xmath181 ( or @xmath170 ) for all @xmath182 to satisfy the first condition .",
    "however , when some of the terms @xmath183",
    "are negative , a simple algorithmic approach can be used to determine whether there exists a valid assignment of @xmath168 .",
    "in fact this condition is completely source dependent , and the choice of @xmath184 is unique up to a negation ( assuming any component @xmath185 is not completely independent of the others ) , and thus can be considered fixed for a given source observation covariance matrix .",
    "the proof of this theorem also has two parts given in section [ sec : outermac ] and section [ sec : innermac ] .",
    "this theorem answers the first question regarding the conditions to certify whether an uncoded scheme is optimal in this communication problem .",
    "the answer to the second question for this problem turns out to be simpler than that in the broadcast case , and we discuss in section [ sec : macexample ] as special case examples several problems previously considered in the literature .",
    "define @xmath186 and thus @xmath187 the reason to introduce @xmath188 s is that in the remote coding setting , the distortion can be decomposed into two independent parts : the first part is due to encoding the observable part of the underlying sources , which are @xmath189 random variables , with a distortion , and the second is due to the inherent noisy nature of the observations which induces a fixed distortion @xmath190 . thus encoding the source @xmath156 to distortion",
    "@xmath155 is equivalent to encoding the equivalent source @xmath188 to distortion @xmath191 .",
    "we can now derive an outer bound by combining the approach used in the broadcast problem with a technique based on witsenhausen s bound @xcite . again consider @xmath0 auxiliary zero - mean gaussian random variables @xmath36 with covariance matrix @xmath37 , which are independent of everything else , and write @xmath38=\\tilde{s}_m[n]+w_m[n],\\quad m=1,2,\\ldots , m.\\end{aligned}\\ ] ] notice the markov string @xmath192 and we can write using data processing inequality that @xmath193 where equality holds if and only if @xmath194    following the exact steps as in @xcite ( see also @xcite ) and applying witsenhausen s bound @xcite , we can obtain @xmath195 where @xmath196 and @xmath197 .",
    "this inequality intuitively says that the mutual information between the channel inputs and the output is upper bounded by the capacity of a point - to - point channel , whose power constraint is equal to the resultant signal power when all the inputs on the multiple - access channel are coherently added .",
    "we will not attempt to further simplify this condition at this point , since in the context of the uncoded scheme , it has a particularly simple form .",
    "the right hand side of ( [ eqn : dataprocessing ] ) can be bounded similarly as in the broadcast problem .",
    "here the equivalent source is @xmath198 , and the distortion vectors are @xmath199 , and moreover , @xmath200 for @xmath31 .",
    "we thus arrive at @xmath201 where equality holds if and only if @xmath202,\\quad m=1,2,\\ldots , m,\\label{eqn : maccondition1}\\\\ h(u^n_m|y^n , u^n_1,u^n_2,\\ldots , u^n_{m-1})&=h(u^n_m|y^n),\\quad m=2,3,\\ldots , m.\\label{eqn : maccondition2}\\end{aligned}\\ ] ]    an outer bound is then obtained by combining ( [ eqn : dataprocessing ] ) , ( [ eqn : channelcondition ] ) and ( [ eqn : sameasbc ] ) .",
    "again the precise form of this outer bound is less important than the extracted matching conditions ( [ eqn : macindep ] ) , ( [ eqn : channelcondition ] ) being equality , ( [ eqn : maccondition1 ] ) and ( [ eqn : maccondition2 ] ) .",
    "the condition ( [ eqn : channelcondition ] ) being equality and the condition ( [ eqn : maccondition1 ] ) can be satisfied simply by choosing a proper jointly gaussian coding scheme , and the conditions ( [ eqn : macindep ] ) and ( [ eqn : maccondition2 ] ) are almost identical to ( [ eqn : degerate ] ) and ( [ eqn : bccondition2 ] ) in the broadcast case .      since the uncoded scheme takes single letter encoding function , ( [ eqn : channelcondition ] ) being equality is equivalent to @xmath203 because in the uncoded scheme the channel input @xmath204 is given in ( [ eqn : xform ] ) , the equality holds as long as @xmath205 this yields the first condition stated in theorem [ theorem : mac ] .    the conditions ( [ eqn : macindep ] ) and ( [ eqn : maccondition2 ] ) in the context of uncoded scheme are equivalent to @xmath206    denote @xmath207 for ( [ eqn : macasinnonoise ] ) to hold with equality , two conditions must hold @xmath208=\\tilde{x},\\label{eqn : dataprocessing1}\\end{aligned}\\ ] ] and @xmath209=\\tilde{x}.\\label{eqn : dataprocessing2}\\end{aligned}\\ ] ]    let us consider the first condition ( [ eqn : dataprocessing1 ] ) . due to the jointly gaussian distribution",
    ", there exists a set of coefficients @xmath6 such that @xmath208=\\sum_{m=1}^m\\alpha_m\\tilde{s}_m=\\sum_{m=1}^m\\alpha_m\\sum_{\\ell=1}^l\\gamma_{m,\\ell}t_\\ell.\\end{aligned}\\ ] ] however notice that @xmath210 thus the condition ( [ eqn : dataprocessing1 ] ) is equivalent to the fact that the vector @xmath211 is in the row space of the matrix @xmath212 .",
    "equivalently , the vector @xmath213 needs to be in the row space of the matrix @xmath161 .",
    "this leads to the second condition stated in theorem [ theorem : mac ] .",
    "when this condition is satisfied , the coefficients @xmath7 can be determined exactly as in ( [ eqn : alphas ] ) .",
    "the conditions ( [ eqn : maccondition2singleletter ] ) and ( [ eqn : dataprocessing2 ] ) are now identical to the broadcast case with @xmath214 being the sources and @xmath215 being the channel input . by corollary 2 ,",
    "such a channel is matched when the second largest eigenvalue of the matrix @xmath176 is less than @xmath216 , or in other words , the noise power must be above or equal to the given threshold stated in theorem [ theorem : mac ] .",
    "* remark : * the first condition in theorem [ theorem : mac ] generally has a unique solution if it can be satisfied , up to a negation of all the signs of the channel input signals . the second condition can almost always be satisfied by choosing appropriate a @xmath217 vector , except a few special cases where an all positive solution does not exist ( recall we have assumed @xmath153 , and thus only all positive solutions are valid ) . if the third condition is satisfied for certain source - channel - code triple , then it is satisfied for any more noisy channels .",
    "it is seen that the critical conditions in the outer bound derivation essentially decouples the matching problem into several simpler ones , leading to the three largely independent conditions given in theorem [ theorem : mac ] .      in the multiple - access setting , the conditions for matching in theorem [ theorem",
    ": mac ] are already rather simple , and there is no need to further investigate the properties of matched channels as in the broadcast case .",
    "next we consider two special cases in the general problem setting which extend those considered in @xcite and @xcite , respectively .",
    ", width=529 ]    consider a zero - mean scalar gaussian source @xmath3 $ ] with variance @xmath218 .",
    "there are a total of @xmath146 sensors , whose observations are @xmath219=d_\\ell s[n]+z\\rq{}_\\ell[n ] , \\ell=1,2,\\ldots , l,\\end{aligned}\\ ] ] where @xmath220 ( without loss of generality ) and @xmath221$]s are the zero - mean independent additive noise with variance @xmath222 .",
    "this special case is depicted in fig .",
    "[ fig : ceo ] .",
    "it is clear that the first condition in theorem [ theorem : mac ] is satisfied by @xmath223 for all @xmath151 .",
    "the second condition for this case is equivalent to @xmath224 where @xmath225 here means a component - wise proportional relation . in other words ,",
    "the uncoded scheme is optimal if @xmath226 however , the lhs of the above condition can be simplified to @xmath227 where the second term is proportional to @xmath228 , and the first term is proportional to @xmath228 if and only if @xmath229    it remains to check the third condition , however in this case @xmath230 , and the second eigenvalue of the matrix @xmath176 can be viewed as zero , thus any noise power @xmath231 will allow a matching . summarizing the above analysis",
    ", it is seen that for the scalar ceo problem on a gaussian multiple - access channel , as long as the condition ( [ eqn : proportional ] ) holds , the uncoded scheme is optimal .",
    "conversely , for any noisy observation qualities , there always exists a matched channel by choosing the values of @xmath232 properly .",
    "the condition ( [ eqn : proportional ] ) corresponds to a proportional quality requirement : the quality of the observations need to match the transmission powers and the transmission amplification factors .",
    "gastpar @xcite showed that when all the sensors have the same observation quality , the same power and the same amplification factor , the uncoded scheme is optimal .",
    "our result thus generalizes it to the proportional case .",
    "consider the case when @xmath233 , and we shall assume that the first condition in theorem [ theorem : mac ] can be satisfied .",
    "the second condition is also satisfied trivially since the matrix @xmath161 is full rank in our problem setting .",
    "thus only the last condition needs to be checked in this case .",
    "equivalently , when @xmath104 is strictly less than @xmath107 , there always exists a noise power @xmath231 such that the channel is matched and thus the uncoded scheme is optimal .    ,",
    "width=604 ]    lapidoth and tinguely @xcite previously considered the case that @xmath234 , @xmath31 ; see fig .",
    "[ fig : local ] .",
    "it was shown that for covariance matrix @xmath12 with strictly positive entries , there always exists a noise power @xmath231 such that the uncoded scheme is optimal .",
    "our result generalizes theirs to the case that the observations can be noisy linear combinations , and the covariance matrix @xmath12 does not necessarily all have strictly positive entries .",
    "we considered the problem of determining whether a given uncoded scheme is optimal for multiuser joint source - channel coding .",
    "it was shown that for both broadcast and multiple - access in the gaussian setting , matching occurs naturally under certain general conditions .",
    "our approach differs from the more conventional approach in that instead of attempting to find explicit outer bound and inner bound then compare them , our focus is on the critical conditions that make the outer bound hold with equality .",
    "this approach has a decoupling effect which tremendously simplifies the overall task . as future work",
    ", we plan to extend and generalize this approach to explore matching in other channel networks .",
    "to upper - bound @xmath46 , first recall the markov string @xmath235 we start by writing the following : @xmath236\\nonumber\\\\ & = \\sum_{j=1}^m \\left[h(y^n_j|u^n_1,u^n_2,\\ldots , u^n_{j-1})-h(y^n_j|u^n_1,u^n_2,\\ldots , u^n_j)\\right]\\nonumber\\\\ & = \\sum_{j=1}^m h(y^n_j|u^n_1,u^n_2,\\ldots , u^n_{j-1})-\\sum_{j=1}^m h(y^n_j|u^n_1,u^n_2,\\ldots , u^n_j).\\end{aligned}\\ ] ] since physical degradedness is equivalent to stochastic degradedness in the broadcast setting , _",
    "i.e. , _ @xmath237 can be assumed to be decomposable into two independent components as @xmath238 , we can apply the entropy power inequality @xcite for @xmath239 , @xmath240\\nonumber\\\\ & \\geq \\exp\\left[\\frac{2}{n}h(y^n_{j+1}|u^n_1,u^n_2,\\ldots , u^n_j)\\right]+\\exp\\left[\\log(2\\pi e ( \\sigma^2_{z_j}-\\sigma^2_{z_{j+1}}))\\right]\\nonumber\\\\ & = \\exp\\left[\\frac{2}{n}h(y^n_{j+1}|u^n_1,u^n_2,\\ldots , u^m_j)\\right]+2 \\pi e(\\sigma^2_{z_j}-\\sigma^2_{z_{j+1 } } ) .",
    "\\label{eqn : applyentropypower}\\end{aligned}\\ ] ] for @xmath241 , it is clear that @xmath242\\geq \\exp\\left[\\frac{2}{n}h(y^n_m|s^n_1,s^n_2,\\ldots , s^n_m)\\right]= 2 \\pi e\\sigma^2_{z_m},\\end{aligned}\\ ] ] with equality if and only if @xmath243 it now follows that @xmath244\\nonumber\\\\ & \\leq \\sum_{m=1}^m ( \\sigma^2_{z_{m}}-\\sigma^2_{z_{m+1 } } ) \\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^m h(y^n_j|u^n_1,u^n_2,\\ldots , u^n_{j-1})\\right]}{\\prod_{j=1}^m\\left[\\exp\\left(\\frac{2}{n}h(y^n_{j+1}|u^n_1,u^n_2,\\ldots , u^n_j)\\right)+2 \\pi e ( \\sigma^2_{z_j}-\\sigma^2_{z_{j+1}})\\right]},\\end{aligned}\\ ] ] where for convenience @xmath245\\triangleq 0 $ ] .    we upper - bound this summation , by considering the summands in the reversed order , _",
    "i.e. _ , @xmath90 .",
    "starting with the summands when @xmath246 and @xmath247 , we have @xmath248}{\\prod_{j=1}^{m-1}\\left[\\exp\\left(\\frac{2}{n}h(y^n_{j+1}|u^n_1,u^n_2,\\ldots , u^n_j)\\right)+2 \\pi e(\\sigma^2_{z_j}-\\sigma^2_{z_{j+1}})\\right]}\\nonumber\\\\ & \\qquad\\qquad+\\sigma^2_{z_{m } } \\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{m } h(y^n_j|u^n_1,u^n_2,\\ldots , u^n_{j-1})\\right]}{\\prod_{j=1}^{m}\\left[\\exp\\left(\\frac{2}{n}h(y^n_{j+1}|u^n_1,u^n_2,\\ldots , u^n_j)\\right)+2 \\pi e(\\sigma^2_{z_j}-\\sigma^2_{z_{j+1}})\\right]}\\nonumber\\\\ & = \\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{m-1 } h(y^n_j|u^n_1,u^n_2,\\ldots , u^n_{j-1})\\right]}{\\prod_{j=1}^{m-1}\\left[\\exp\\left(\\frac{2}{n}h(y^n_{j+1}|u^n_1,u^n_2,\\ldots , u^m_j)\\right)+2 \\pi e ( \\sigma^2_{z_j}-\\sigma^2_{z_{j+1}})\\right]}\\nonumber\\\\ & \\qquad\\qquad\\cdot\\left[(\\sigma^2_{z_{m-1}}-\\sigma^2_{z_{m } } ) + \\sigma^2_{z_{m}}\\frac{\\exp\\left[\\frac{2}{n}h(y^n_m|u^n_{m-1})\\right]}{2 \\pi e\\sigma^2_{z_{m}}}\\right]\\nonumber\\\\ & = \\frac{1}{2 \\pi e}\\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{m-1 } h(y^n_j|u^n_1,u^n_2,\\ldots , u^m_{j-1})\\right]}{\\pi_{j=1}^{m-2}\\left[\\exp\\left(\\frac{2}{n}h(y^n_{j+1}|u^n_1,u^n_2,\\ldots , u^n_j)\\right)+2 \\pi e(\\sigma^2_{z_{m-1}}-\\sigma^2_{z_{m}})\\right]}.\\label{eqn : firststep}\\end{aligned}\\ ] ] continuing this line of reduction , we finally arrive at when @xmath249 @xmath250}{\\exp\\left(\\frac{2}{n}h(y^n_{2}|u^n_1)\\right)+2 \\pi e(\\sigma^2_{z_{2}}-\\sigma^2_{z_{1}})}+\\frac{1}{2 \\pi e}\\frac{\\exp\\left[\\frac{2}{n}\\sum_{j=1}^{2 } h(y^n_j|u^n_1,\\ldots , u^n_{j-1})\\right]}{\\exp\\left(\\frac{2}{n}h(y^n_{2}|u^n_1)\\right)+2 \\pi e(\\sigma^2_{z_{2}}-\\sigma^2_{z_{1}})}\\nonumber\\\\ & = \\frac{\\exp\\left[\\frac{2}{n } h(y^n_1)\\right]}{\\exp\\left(\\frac{2}{n}h(y^n_{2}|u^n_1))\\right)+2 \\pi e(\\sigma^2_{z_{2}}-\\sigma^2_{z_{1}})}\\left[(\\sigma^2_{z_{2}}-\\sigma^2_{z_{1}})+\\frac{\\exp \\left[\\frac{2}{n}h(y^n_2|u^n_1)\\right]}{2\\pi e}\\right]\\nonumber\\\\ & = \\frac{\\exp\\left[\\frac{2}{n } h(y^n_1)\\right]}{2\\pi e}\\leq p+\\sigma^2_{z_1},\\label{eqn : bcchannela}\\end{aligned}\\ ] ] where the last inequality is by the concavity of the @xmath251 function and the given power constraint .",
    "the chain of inequalities in ( [ eqn : bcchannela ] ) holds with equality holds if and only if @xmath252 as well as ( [ eqn : bcasifnonoisea ] ) and the entropy power inequalities hold with equality .",
    "we next lower bound @xmath46 . by the rate - distortion theorem @xcite @xmath253 with equality",
    "holds if and only if @xmath254.\\end{aligned}\\ ] ] furthermore , @xmath255\\label{eqn : bccondition3a}\\\\ & = \\frac{n}{2}\\log\\frac{|\\sigma_{s_1,s_2,\\ldots , s_m}+\\sigma_{w_1,w_2,\\ldots , w_m}|}{|(\\sigma_{s_1,s_2,\\ldots , s_{m-1}}+\\sigma_{w_1,w_2,\\ldots , w_{m-1}})|[d_m+\\sigma^2_{w_m}]},\\nonumber\\end{aligned}\\ ] ] where ( [ eqn : bccondition2a ] ) is because conditioning reduces entropy , and ( [ eqn : bccondition3a ] ) is because gaussian distribution maximizes the entropy for random variables with the same variance , together with the concavity of the @xmath256 function . for ( [ eqn : bccondition2a ] ) to hold with equality",
    ", we must have @xmath257 and for ( [ eqn : bccondition3a ] ) to hold with equality requires @xmath258,\\quad m=2,3,\\ldots , m.\\end{aligned}\\ ] ]          recall @xmath27 . in the @xmath263-th step of the cholesky decomposition @xmath264",
    ", we claim that @xmath265 and @xmath266 .",
    "moreover , we claim the matrix partially diagonalized , denoted as @xmath267 , has entries in the following form :    * @xmath268 , @xmath269 and @xmath270 ; by symmetry , @xmath271 , @xmath272 and @xmath270 . * @xmath273 , @xmath274 ; * @xmath275 , @xmath276 and @xmath277 ; by symmetry @xmath278 , @xmath279 and @xmath280 ; * @xmath281 $ ] , @xmath282 .    where the terms @xmath283 are determined recursively as @xmath284 and @xmath285 for which @xmath286 clearly the claim is true when @xmath287 .",
    "suppose it is also true for @xmath288 , and we wish to prove the claim for @xmath289 .",
    "it is clear that due to the positive semidefinite requirement for the degenerate case when @xmath290 we must have for @xmath291 @xmath292 and this cholesky step can essentially be skipped , and @xmath283 does not need to be updated .",
    "it is easy to check the recursive formula @xmath293 for @xmath294 is indeed valid for this case .",
    "if @xmath295 , then clearly @xmath296 due to the assumption in the induction .",
    "if @xmath297 then @xmath298 for @xmath291 , and thus @xmath299 .",
    "thus the induction is valid in this case .",
    "if @xmath300 , then due to the assumption in the induction we have @xmath301 first observe that due to the assumption in the induction , we have @xmath302 using the cholesky factorization , we have for any @xmath303 and @xmath277 @xmath304\\nonumber\\\\ & = -\\beta_i\\beta_jb^{(k^*+1)}_j.\\end{aligned}\\ ] ] similarly for @xmath294 @xmath305-\\beta^2_m\\beta_{m - k^*}b^{(k^*)}_{m - k^*}\\frac{\\alpha_{m - k^*}}{\\sum_{j=1}^{{m - k^*-1}}\\alpha_j\\beta_j}\\nonumber\\\\ & = \\frac{\\beta_m}{\\alpha_m}b^{(k^*)}_m\\sum_{j=1}^{m-1}\\alpha_j\\beta_j+\\frac{\\beta_m}{\\alpha_m}\\sum_{j = m+1}^{m - k^*-1}\\alpha_j\\beta_jb^{(k^*)}_j\\nonumber\\\\ & \\qquad+\\alpha_{m - k^*}\\beta_{m - k^*}\\frac{\\beta_m}{\\alpha_m}\\frac{\\sum_{j=1}^{{m - k^*-1}}\\alpha_j\\beta_j-\\alpha_m\\beta_m}{\\sum_{j=1}^{{m - k^*-1}}\\alpha_j\\beta_j}b^{(k^*)}_{m - k^*}\\nonumber\\\\ & = \\frac{\\beta_m}{\\alpha_m}\\left[b^{(k^*)}_m+\\frac{\\sum_{j=1}^{m-1}\\alpha_{m - k^*}\\beta_{m - k^*}}{\\sum_{t=1}^{{m - k^*-1}}\\alpha_t\\beta_t}b^{(k^*)}_{m - k^*}\\right]\\sum_{j=1}^{m-1}\\alpha_j\\beta_j\\nonumber\\\\ & \\qquad+\\frac{\\beta_m}{\\alpha_m}\\sum_{j = m+1}^{m - k^*-1}\\alpha_j\\beta_j\\left[b^{(k^*)}_j+\\frac{\\sum_{j=1}^{m-1}\\alpha_{m - k^*}\\beta_{m - k^*}}{\\sum_{t=1}^{{m - k^*-1}}\\alpha_t\\beta_t}b^{(k^*)}_{m - k^*}\\right]\\nonumber\\\\ & = \\frac{\\beta_m}{\\alpha_m}\\left[b^{(k^*+1)}_m\\sum_{j=1}^{m-1}\\alpha_j\\beta_j+\\sum_{j = m+1}^{m - k^*-1}\\alpha_j\\beta_jb^{(k^*+1)}_j\\right].\\end{aligned}\\ ] ]    suppose @xmath306 , this implies that @xmath307 which however contradicts with the positive semidefinite requirement that @xmath308 if @xmath309 , then from the assumption in the induction , we have @xmath310 thus this case does not cause any problem .",
    "if @xmath311 , then it also follows that @xmath312 . the lemma is proved .",
    "it suffices to consider the case that @xmath313 , @xmath314 , and @xmath315 .",
    "denote @xmath316 , and matrices constructed for the two channels as @xmath34 and @xmath317 , respectively .",
    "it is clear that @xmath318 however , it is easily seen that this matrix is positive semidefinite since the first @xmath319 diagonal terms are non - negative , and we can remove all the other terms through symmetric elimination , _",
    "i.e. , _ the cholesky factorization .",
    "it follows that @xmath320 + \\left[\\sigma_{v_1,v_2,\\ldots , v_m}-\\sigma_{s_1,s_2,\\ldots , s_m}+p\\bar{\\beta}\\bar{\\beta}^t \\right]\\end{aligned}\\ ] ] is positive semidefinite since it is a summation of two positive semidefinite matrices .",
    "for the `` only if '' direction , it follows from corollary 1 that matching must hold for the degraded channel with noise power @xmath322 .",
    "the requirement ( [ eqn : semidefinite ] ) implies @xmath323 this implies that @xmath324 , since otherwise the left hand side is rank deficient . together with lemma 1",
    ", it follows that @xmath98 .",
    "next multiply both sides from left and from right by @xmath100 , it follows that @xmath325 notice that @xmath106 is in fact an eigenvector corresponding to eigenvalue @xmath107 for the matrix @xmath99 , easily verified using ( [ eqn : alphatobeta ] ) .",
    "we can write the eigen decomposition of the matrix @xmath99 as @xmath326 where @xmath327 are the other eigenvalues of @xmath99 , and @xmath328 are the corresponding eigenvectors .",
    "it follows that @xmath329 which implies @xmath330 , @xmath331 .    for the `` if '' direction",
    ", we choose a @xmath332 such that ( [ eqn : nlarge ] ) holds , which is always possible when @xmath332 is sufficiently large .",
    "this implies that for the channel @xmath333 , condition ( [ eqn : matchingspecial ] ) holds , and thus it is a matched channel .",
    "the entries of matrix @xmath108 , denoted as @xmath334 , is given ( by symmetry only the upper - triangle entries need to be specified ) @xmath335 and @xmath336 a necessary and sufficient condition for matching is that the matrix @xmath108 is positive semidefinite .",
    "observe that @xmath337 if all the off - diagonal entries of @xmath108 are non - positive , then the matrix is diagonally dominant , and the diagonal entries are all positive , which implies that it is a positive semidefinite matrix .",
    "thus as long as @xmath338 and @xmath339 the positive semidefinite condition is satisfied .",
    "it is thus sufficient to have @xmath340 together with corollary 1 , this implies the statement given in the corollary is indeed true .",
    "since the matrix @xmath131 is positive definite , we have @xmath341 and @xmath342 . since @xmath343 , we must also have @xmath344 , @xmath345 and @xmath346 for matching to occur .",
    "the first condition gives that @xmath347 but the latter two require a few more steps .",
    "notice that the condition @xmath346 implies that @xmath348 if @xmath349 , then @xmath345 implies @xmath350 if @xmath351 , this yields a condition already implied by @xmath352 ; on the other hand , @xmath353 is an impossible case . it can be verified that @xmath354 is also an impossible case .",
    "thus we must have @xmath349 and @xmath351 simultaneously , from which we obtained the set of conditions given in ( [ eqn : source2 ] ) ."
  ],
  "abstract_text": [
    "<S> we investigate whether uncoded schemes are optimal for gaussian sources on multiuser gaussian channels . </S>",
    "<S> particularly , we consider two problems : the first is to send correlated gaussian sources on a gaussian broadcast channel where each receiver is interested in reconstructing only one source component ( or one specific linear function of the sources ) under the mean squared error distortion measure ; the second is to send vector gaussian sources on a gaussian multiple - access channel , where each transmitter observes a noisy combination of the source , and the receiver wishes to reconstruct the individual source components ( or individual linear functions ) under the mean squared error distortion measure . </S>",
    "<S> it is shown that when the channel parameters match certain general conditions , the induced distortion tuples are on the boundary of the achievable distortion region , and thus optimal . instead of following the conventional approach of attempting to characterize the achievable distortion region , </S>",
    "<S> we ask the question whether and how a match can be effectively determined . </S>",
    "<S> this decision problem formulation helps to circumvent the difficult optimization problem often embedded in region characterization problems , and also leads us to focus on the critical conditions in the outer bounds that make the inequalities become equalities , which effectively decouples the overall problem into several simpler sub - problems .    </S>",
    "<S> = 0.2 cm </S>"
  ]
}