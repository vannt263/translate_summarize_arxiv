{
  "article_text": [
    "in a typical instance of a combinatorial optimization problem the underlying constraints model a static application frozen in one time step . in many applications",
    "however , one needs to solve instances of the combinatorial optimization problem that changes over time . while this is naturally handled by re - solving the optimization problem in each time step separately , changing the solution one holds from one time step to the next often incurs a transition cost .",
    "consider , for example , the problem faced by a vendor who needs to get supply of an item from @xmath10 different producers to meet her demand . on any given day",
    ", she could get prices from each of the producers and pick the @xmath10 cheapest ones to buy from .",
    "as prices change , this set of the @xmath10 cheapest producers may change .",
    "however , there is a fixed cost to starting and/or ending a relationship with any new producer .",
    "the goal of the vendor is to minimize the sum total of these two costs : an `` acquisition cost '' @xmath11 to be incurred each time she starts a new business relationship with a producer , and a per period cost @xmath12 of buying in period @xmath2 from the each of the @xmath10 producers that she picks in this period , summed over @xmath13 time periods . in this work",
    "we consider a generalization of this problem , where the constraint `` pick @xmath10 producers '' may be replaced by a more general combinatorial constraint .",
    "it is natural to ask whether simple combinatorial problems for which the one - shot problem is easy to solve , as the example above is , also admit good algorithms for the multistage version .",
    "the first problem we study is the _ multistage matroid maintenance _ problem ( ) , where the underlying combinatorial constraint is that of maintaining a base of a given matroid in each period . in the example above , the requirement the vendor buys from @xmath10 different producers could be expressed as optimizing over the @xmath14uniform matroid . in a more interesting case",
    "one may want to maintain a spanning tree of a given graph at each step , where the edge costs @xmath12 change over time , and an acquisition cost of @xmath11 has to paid every time a new edge enters the spanning tree .",
    "( a formal definition of the problem appears in section  [ sec : formal - defs ] . )",
    "while our emphasis is on the online problem , we will mention results for the offline version as well , where the whole input is given in advance .    a first observation we make",
    "is that if the matroid in question is allowed to be different in each time period , then the problem is hard to approximate to any non - trivial factor ( see section  [ sec : time - varying ] ) even in the offline case .",
    "we therefore focus on the case where the same matroid is given at each time period .",
    "thus we restrict ourselves to the case when the matroid is the same for all time steps .    to set the baseline , we first study the offline version of the problem ( in section  [ sec : offline ] ) , where all the input parameters are known in advance .",
    "we show an lp - rounding algorithm which approximates the total cost up to a logarithmic factor .",
    "this approximation factor is no better than that using a simple greedy algorithm , but it will be useful to see the rounding algorithm , since we will use its extension in the online setting .",
    "we also show a matching hardness reduction , proving that the problem is hard to approximate to better than a logarithmic factor ; this hardness holds even for the special case of spanning trees in graphs .",
    "we then turn to the online version of the problem , where in each time period , we learn the costs @xmath12 of each element that is available at time @xmath2 , and we need to pick a base @xmath15 of the matroid for this period . we analyze the performance of our online algorithm in the competitive analysis framework : i.e. , we compare the cost of the online algorithm to that of the optimum solution to the offline instance thus generated . in section  [ sec : online ] , we give an efficient randomized @xmath16-competitive algorithm for this problem against any oblivious adversary ( here @xmath17 is the universe for the matroid and @xmath6 is the rank of the matroid ) , and show that no polynomial - time online algorithm can do better .",
    "we also show that the requirement that the algorithm be randomized is necessary : any deterministic algorithm must incur an overhead of @xmath18 , even for the simplest of matroids .    our results above crucially relied on the properties of matriods , and",
    "it is natural to ask if we can handle more general set systems , e.g. , @xmath19-systems . in section  [ sec : matchings ] , we consider the case where the combinatorial object we need to find each time step is a perfect matching in a graph .",
    "somewhat surprisingly , the problem here is significantly harder than the matroid case , even in the offline case . in particular",
    ", we show that even when the number of periods is a constant , no polynomial time algorithm can achieve an approximation ratio better than @xmath20 for any constant @xmath21 .",
    "we first show that the problem , which is a packing - covering problem , can be reduced to the analogous problem of maintaining a spanning set of a matroid .",
    "we call the latter the _ multistage spanning set maintenance _ ( ) problem .",
    "while the reduction itself is fairly clean , it is surprisingly powerful and is what enables us to improve on previous works .",
    "the problem is a covering problem , so it admits better approximation ratios and allows for a much larger toolbox of techniques at our disposal .",
    "we note that this is the only place where we need the matroid to not change over time : our algorithms for work when the matroids change over time , and even when considering matroid intersections .",
    "the problem is then further reduced to the case where the holding cost of an element is in @xmath22 , this reduction simplifies the analysis .    in the offline case , we present two algorithms . we first observe that a greedy algorithm easily gives an @xmath23-approximation .",
    "we then present a simple randomized rounding algorithm for the linear program .",
    "this is analyzed using recent results on contention resolution schemes  @xcite , and gives an approximation of @xmath24 , which can be improved to @xmath25 when the acquisition costs are uniform .",
    "this lp - rounding algorithm will be an important constituent of our algorithm for the online case .",
    "for the online case we again use that the problem can be written as a covering problem , even though the natural lp formulation has both covering and packing constraints . phrasing it as a covering problem ( with box constraints )",
    "enables us to use , as a black - box , results on online algorithms for the fractional problem  @xcite",
    ". this formulation however has exponentially many constraints .",
    "we handle that by showing a method of adaptively picking violated constraints such that only a small number of constraints are ever picked .",
    "the crucial insight here is that if @xmath26 is such that @xmath27 is not feasible , then @xmath26 is at least @xmath28 away in @xmath29 distance from any feasible solution ; in fact there is a single constraint that is violated to an extent half .",
    "this insight allows us to make non - trivial progress ( using a natural potential function ) every time we bring in a constraint , and lets us bound the number of constraints we need to add until constraints are satisfied by @xmath27 .",
    "our work is related to several lines of research , and extends some of them .",
    "the paging problem is a special case of where the underlying matroid is a uniform one .",
    "our online algorithm generalizes the @xmath30-competitive algorithm for weighted caching  @xcite , using existing online lp solvers in a black - box fashion .",
    "going from uniform to general matroids loses a logarithmic factor ( after rounding ) , we show such a loss is unavoidable unless we use exponential time .",
    "the problem is also a special case of classical metrical task systems @xcite ; see  @xcite for more recent work .",
    "the best approximations for metrical task systems are poly - logarithmic in the size of the metric space . in our case",
    "the metric space is specified by the total number of bases of the matroid which is often exponential , so these algorithms only give a trivial approximation .    in trying to unify online learning and competitive analysis , buchbinder et al .",
    "@xcite consider a problem on matroids very similar to ours .",
    "the salient differences are : ( a )  in their model all acquisition costs are the same , and ( b )  they work with fractional bases instead of integral ones .",
    "they give an @xmath31-competitive algorithm to solve the fractional online lp with uniform acquisition costs ( among other unrelated results ) .",
    "our online lp solving generalizes their result to arbitrary acquisition costs .",
    "they leave open the question of getting integer solutions online ( seffi naor , private communication ) , which we present in this work . in a more recent work , buchbinder , chen and naor  @xcite use a regularization approach to solving a broader set of fractional problems , but once again can do not get integer solutions in a setting such as ours .",
    "shachnai et al .",
    "@xcite consider `` reoptimization '' problems : given a starting solution and a new instance , they want to balance the transition cost and the cost on the new instance .",
    "this is a two - timestep version of our problem , and the short time horizon raises a very different set of issues ( since the output solution does not need to itself hedge against possible subsequent futures ) .",
    "they consider a number of optimization / scheduling problems in their framework .",
    "cohen et al .",
    "@xcite consider several problems in the framework of the stability - versus - fit tradeoff ; e.g. , that of finding `` stable '' solutions which given the previous solution , like in reoptimization , is the current solution that maximizes the quality minus the transition costs .",
    "they show maintaining stable solutions for matroids becomes a repeated two - stage reoptimization problem ; their problem is poly - time solvable , whereas matroid problems in our model become np - hard .",
    "the reason is that the solution for two time steps does not necessarily lead to a base from which it is easy to move in subsequent time steps , as our hardness reduction shows .",
    "they consider a multistage offline version of their problem ( again maximizing fit minus stability ) which is very similar in spirit and form to our ( minimization ) problem , though the minus sign in the objective function makes it difficult to approximate in cases which are not in poly - time .    in dynamic steiner tree maintenance  @xcite where the goal is to maintain an approximately optimal steiner tree for a varying instance ( where terminals are added ) while changing few edges at each time step . in dynamic load balancing",
    "@xcite one has to maintain a good scheduling solution while moving a small number of jobs around .",
    "the work on lazy experts in the online prediction community  @xcite also deals with similar concerns .",
    "there is also work on `` leasing '' problems  @xcite : these are optimization problems where elements can be obtained for an interval of any length , where the cost is concave in the lengths ; the instance changes at each timestep .",
    "the main differences are that the solution only needs to be feasible at each timestep ( i.e. , the holding costs are @xmath32 ) , and that any element can be leased for any length @xmath33 of time starting at any timestep for a cost that depends only on @xmath33 , which gives these problems a lot of uniformity . in turn , these leasing problems are related to `` buy - at - bulk '' problems .",
    "given reals @xmath34 for elements",
    "@xmath35 , we will use @xmath36 for @xmath37 to denote @xmath38 .",
    "we denote @xmath39 by @xmath40 $ ] .",
    "we assume basic familiarity with matroids : see , e.g. ,  @xcite for a detailed treatment . given a matroid @xmath41 ,",
    "a _ base _ is a maximum cardinality independent set , and a _ spanning set _ is a set @xmath42 such that @xmath43 ; equivalently , this set contains a base within it .",
    "the _ span _ of a set @xmath44 is @xmath45 .",
    "the _ matroid polytope _",
    "@xmath46 is defined as @xmath47 .",
    "the _ base polytope _ @xmath48 . we will sometimes use @xmath5 to denote @xmath49 and @xmath6 to denote the rank of the matroid .",
    "an instance of the _ multistage matroid maintenance _ ( ) problem consists of a matroid @xmath41 , an _ acquisition cost _",
    "@xmath50 for each @xmath35 , and for every timestep @xmath51 $ ] and element @xmath35 , a _ holding cost _ cost @xmath12 .",
    "the goal is to find bases @xmath52}$ ] to minimize @xmath53 where we define @xmath54 .",
    "a related problem is the _ multistage spanning set maintenance _",
    "( ) problem , where we want to maintain a spanning set @xmath55 at each time , and cost of the solution @xmath56}$ ] ( once again with @xmath57 ) is @xmath58      the following lemma shows the equivalence of maintaining bases and spanning sets .",
    "this enables us to significantly simplify the problem and avoid the difficulties faced by previous works on this problem .",
    "[ lem : pack - cover ] for matroids , the optimal solutions to and have the same costs .    clearly , any solution to is also a solution to , since a base is also a spanning set .",
    "conversely , consider a solution @xmath59 to .",
    "set @xmath60 to any base in @xmath61 .",
    "given @xmath62 , start with @xmath63 , and extend it to any base @xmath64 of @xmath15 .",
    "this is the only step where we use the matroid properties  indeed , since the matroid is the same at each time , the set @xmath63 remains independent at time @xmath2 , and by the matroid property this independent set can be extended to a base .",
    "observe that this process just requires us to know the base @xmath65 and the set @xmath15 , and hence can be performed in an online fashion .",
    "we claim that the cost of @xmath66 is no more than that of @xmath67 .",
    "indeed , @xmath68 , because @xmath69 .",
    "moreover , let @xmath70 , we pay @xmath71 for these elements we just added . to charge this , consider any such element @xmath72 , let @xmath73 be the time it was most recently added to the cover  i.e .",
    ", @xmath74 for all @xmath75 $ ] , but @xmath76 .",
    "the solution paid for including @xmath77 at time @xmath78 , and we charge our acquisition of @xmath77 into @xmath64 to this pair @xmath79 .",
    "it suffices to now observe that we will not charge to this pair again , since the procedure to create @xmath80 ensures we do not drop @xmath77 from the base until it is dropped from @xmath15 itself  the next time we pay an addition cost for element @xmath77 , it would have been dropped and added in @xmath81 as well .",
    "hence it suffices to give a good solution to the problem .",
    "we observe that the proof above uses the matroid property crucially and would not hold , e.g. , for matchings .",
    "it also requires that the _ same _ matroid be given at all time steps . also , as noted above , the reduction is online : the instance is the same , and given an solution it can be transformed online to a solution to .",
    "we will find it convenient to think of an instance of as being a matroid @xmath82 , where each element only has an acquisition cost @xmath83 , and it has a lifetime @xmath84 $ ] .",
    "there are no holding costs , but the element @xmath77 can be used in spanning sets only for timesteps @xmath85 . or one can equivalently think of holding costs being zero for @xmath86 and @xmath87 otherwise .",
    "_ an offline exact reduction . _",
    "the translation is the natural one : given instance @xmath88 of , create elements @xmath89 for each @xmath90 and @xmath91 , with acquisition cost @xmath92 , and interval @xmath93 $ ] .",
    "( the matroid is extended in the natural way , where all the elements @xmath89 associated with @xmath77 are parallel to each other . ) the equivalence of the original definition of and this interval view is easy to verify .",
    "_ an online approximate reduction .",
    "_ observe that the above reduction created at most @xmath94 copies of each element , and required knowledge of all the costs .",
    "if we are willing to lose a constant factor in the approximation , we can perform a reduction to the interval model in an _ online _ fashion as follows . for element @xmath35 ,",
    "define @xmath95 , and create many parallel copies @xmath96 of this element ( modifying the matroid appropriately ) .",
    "now the @xmath97 interval for @xmath77 is @xmath98 $ ] , where @xmath99 is set to @xmath100 in case @xmath101 , else it is set to the _ largest _ time such that the total holding costs @xmath102 for this interval @xmath103 $ ] is at most @xmath11 .",
    "this interval @xmath104 is associated with element @xmath105 , which is only available for this interval , at cost @xmath106 .",
    "a few salient points about this reduction : the intervals for an original element @xmath77 now partition the entire time horizon @xmath40 $ ] .",
    "the number of elements in the modified matroid whose intervals contain any time @xmath2 is now only @xmath107 , the same as the original matroid ; each element of the modified matroid is only available for a single interval .",
    "moreover , the reduction can be done online : given the past history and the holding cost for the current time step @xmath2 , we can ascertain whether @xmath2 is the beginning of a new interval ( in which case the previous interval ended at @xmath108 ) and if so , we know the cost of acquiring a copy of @xmath77 for the new interval is @xmath109 .",
    "it is easy to check that the optimal cost in this interval model is within a constant factor of the optimal cost in the original acquisition / holding costs model .",
    "given the reductions of the previous section , we can focus on the problem .",
    "being a covering problem , is conceptually easier to solve : e.g. , we could use algorithms for submodular set cover  @xcite with the submodular function being the sum of ranks at each of the timesteps , to get an @xmath23 approximation .    in section  [ sec : greedy ] , we give a dual - fitting proof of the performance of the greedy algorithm . here",
    "we give an lp - rounding algorithm which gives an @xmath110 approximation ; this can be improved to @xmath25 in the common case where all acquisition costs are unit .",
    "( while the approximation guarantee is no better than that from submodular set cover , this lp - rounding algorithm will prove useful in the online case in section  [ sec : online ] ) .",
    "finally , the hardness results of section  [ sec : hardness - offline ] show that we can not hope to do much better than these logarithmic approximations .",
    "we now consider an lp - rounding algorithm for the problem ; this will generalize to the online setting , whereas it is unclear how to extend the greedy algorithm to that case .",
    "for the lp rounding , we use the standard definition of the problem to write the following lp relaxation . @xmath111",
    "it remains to round the solution to get a feasible solution to ( i.e. , a spanning set @xmath15 for each time ) with expected cost at most @xmath31 times the lp value , since we can use lemma  [ lem : pack - cover ] to convert this to a solution for at no extra cost .",
    "the following lemma is well - known ( see , e.g.  @xcite ) .",
    "we give a proof for completeness .",
    "[ lem : alon ] for a fractional base @xmath112 , let @xmath113 be the set obtained by picking each element @xmath35 independently with probability @xmath114",
    ". then @xmath115 \\geq r(1 - 1/e)$ ] .",
    "we use the results of chekuri et al .",
    "@xcite ( extending those of chawla et al .",
    "@xcite ) on so - called contention resolution schemes . formally , for a matroid @xmath82 , they give a randomized procedure @xmath116 that takes the random set @xmath113 and outputs an independent set @xmath117 in @xmath82 , such that @xmath118 , and for each element @xmath77 in the support of @xmath119 , @xmath120 \\geq ( 1 - 1/e)$ ] .",
    "( they call this a @xmath121-balanced cr scheme . )",
    "now , we get @xmath122 & \\geq { { \\mathbf{e } } } [ { \\textsf{rank}}(\\pi_z(r(z ) ) ) ] = \\sum_{e \\in \\text{supp}(z ) } \\pr [ e \\in      \\pi_z(r(z ) ) ] \\\\      & = \\sum_{e \\in \\text{supp}(z ) } \\pr [ e \\in \\pi_z(r(z ) ) \\mid e \\in r(z ) ] \\cdot \\pr [ e \\in r(z ) ]      \\\\      & \\geq \\sum_{e \\in \\text{supp}(z ) } ( 1 - 1/e ) \\cdot z_e = r(1 - 1/e ) .",
    "\\end{aligned}\\ ] ] the first inequality used the fact that @xmath117 is a subset of @xmath113 , the following equality used that @xmath117 is independent with probability  1 , the second inequality used the property of the cr scheme , and the final equality used the fact that @xmath119 was a fractional base .    [",
    "thm : lp - round ] any fractional solution can be randomly rounded to get solution to with cost @xmath24 times the fractional value , where @xmath6 is the rank of the matroid and @xmath13 the number of timesteps .",
    "set @xmath123 . for each element @xmath35 , choose a random threshold @xmath124 independently and uniformly from the interval @xmath125 $ ] .",
    "for each @xmath126 , define the set @xmath127 ; if @xmath128 does not have full rank , augment its rank using the cheapest elements according to @xmath129 to obtain a full rank set @xmath15 . since @xmath130 = \\min\\ { l\\cdot z_t(e ) , 1\\}$ ] , the cost @xmath131 .",
    "moreover , @xmath132 exactly when @xmath124 satisfies @xmath133 , which happens with probability at most @xmath134 hence the expected acquisition cost for the elements newly added to @xmath128 is at most @xmath135 .",
    "finally , we have to account for any elements added to extend @xmath128 to a full - rank set @xmath15 .",
    "[ lem : rand - round ] for any fixed @xmath51 $ ] , the set @xmath128 contains a basis of @xmath82 with probability at least @xmath136 .",
    "the set @xmath128 is obtained by threshold rounding of the fractional base @xmath137 as above . instead ,",
    "consider taking @xmath138 different samples @xmath139 , where each sample is obtained by including each element @xmath35 independently with probability @xmath140 ; let @xmath141 .",
    "it is easy to check that @xmath142 \\leq \\pr [      { \\textsf{rank}}(\\widehat{s}_t ) = r]$ ] , so it suffices to give a lower bound on the former expression . for this",
    ", we use lemma  [ lem : alon ] : the sample @xmath143 has expected rank @xmath144 , and using reverse markov , it has rank at least @xmath145 with probability at least @xmath146 . now focusing on the matroid @xmath147 obtained by contracting elements in @xmath148 ( which",
    ", say , has rank @xmath149 ) , the same argument says the set @xmath150 has rank @xmath151 with probability at least @xmath152 , etc . proceeding in this way , the probability that the rank of @xmath13 is less than @xmath6 is at most the probability that we see fewer than @xmath153 heads in @xmath154 flips of a coin of bias @xmath152 . by a chernoff bound ,",
    "this is at most @xmath155 .",
    "now if the set @xmath128 does not have full rank , the elements we add have cost at most that of the min - cost base under the cost function @xmath156 , which is at most the optimum value for  ( [ eq : lp2 ] ) .",
    "( we use the fact that the lp is exact for a single matroid , and the global lp has cost at least the single timestep cost . )",
    "this happens with probability at most @xmath157 , and hence the total expected cost of augmenting @xmath128 over all @xmath13 timesteps is at most @xmath158 times the lp value .",
    "this proves the main theorem .",
    "again , this algorithm for works with different matroids at each timestep , and also for intersections of matroids . to see this observe that the only requirements from the algorithm are that there is a separation oracle for the polytope and that the contention resolution scheme works .",
    "in the case of @xmath14matroid intersection , if we pay an extra @xmath30 penalty in the approximation ratio we have that the probability a rounded solution does not contain a base is @xmath159 so we can take a union bound over the multiple matroids .",
    "0      we can replace the dependence on @xmath13 by a term that depends only on the variance in the acquisition costs .",
    "let us divide the period @xmath160 into `` epochs '' , where an epoch is an interval @xmath161 for @xmath162 such that the total fractional acquisition cost @xmath163 .",
    "we can afford to build a brand new tree at the beginning of each epoch and incur an acquisition cost of at most the rank @xmath6 , which we can charge to the lp s fractional acquisition cost in the epoch . by theorem  [ thm : lp - round ] , naively applying the rounding algorithm to each epoch independently gives a guarantee of @xmath164 , where @xmath165 is the maximum length of an epoch .",
    "now we should be able to use the argument from the online section that says that we can ignore steps where the total movement is smaller than half .",
    "thus @xmath165 can be assumed to be @xmath166 .",
    "more details to be added once we consistentize notation .",
    "in fact , if we define epoch to be a period of acquisition cost @xmath167 , then the at least half means movement cost at least @xmath168 .",
    "thus the epoch only has @xmath169 relevant steps in it , so we get log of that .    for the special case where all the acquisition costs @xmath11 are all the same , this implies we get rid of the @xmath13 term in the lp rounding , and get an @xmath25-approximation .      when the ratio of the maximum to the minimum acquisition cost is small , we can improve the approximation factor above .",
    "more specifically , we show that essentially the same randomized rounding algorithm ( with a different choice of @xmath138 ) gives an approximation ratio of @xmath170 .",
    "we defer the argument to section  [ sec : just - logr ] , as it needs some additional definitions and results that we present in the online section .",
    "[ [ an - improvement - avoiding - the - dependence - on - t.-1 ] ] an improvement : avoiding the dependence on @xmath13 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    when the ratio of the maximum to the minimum acquisition cost is small , we can improve the approximation factor above . more specifically , we show that essentially the same randomized rounding algorithm ( with a different choice of @xmath138 ) gives an approximation ratio of @xmath170 .",
    "we defer the argument to section  [ sec : just - logr ] , as it needs some additional definitions and results that we present in the online section .",
    "we defer the hardness proof to appendix  [ app : offline ] , which shows that the and problems are np - hard to approximate better than @xmath171 even for graphical matroids .",
    "an integrality gap of @xmath172 appears in appendix  [ sec : int - gap - matroids ] .",
    "[ thm : matr - hard ] the and problems are np - hard to approximate better than @xmath173 even for graphical matroids .",
    "we give a reduction from set cover to the problem for graphical matroids .",
    "given an instance @xmath174 of set cover , with @xmath175 sets and @xmath176 elements , we construct a graph as follows . there is a special vertex @xmath6 , and @xmath5 set vertices ( with vertices @xmath177 for each set @xmath178 ) .",
    "there are @xmath5 edges @xmath179 which all have inclusion weight @xmath180 and per - time cost @xmath181 for all @xmath2 .",
    "all other edges will be zero cost short - term edges as given below .",
    "in particular , there are @xmath182 timesteps . in timestep",
    "@xmath183 $ ] , define subset @xmath184 to be vertices corresponding to sets containing element @xmath185 .",
    "we have a set of edges @xmath186 for all @xmath187 , and all edges @xmath188 for @xmath189 .",
    "all these edges have zero inclusion weight @xmath11 , and are only alive at time @xmath190 .",
    "( note this creates a graph with parallel edges , but this can be easily fixed by subdividing edges . )    in any solution to this problem , to connect the vertices in @xmath191 to @xmath6 , we must buy some edge @xmath192 for some @xmath193 .",
    "this is true for all @xmath190 , hence the root - set edges we buy correspond to a set cover .",
    "moreover , one can easily check that if we acquire edges @xmath194 such that the sets @xmath195 form a set cover , then we can always augment using zero cost edges to get a spanning tree . since the only edges we pay for are the @xmath194 edges , we should buy edges corresponding to a min - cardinality set cover , which is hard to approximate better than @xmath196 . finally , that the number of time periods is @xmath182 , and the rank of the matroid is @xmath197 for these hard instances .",
    "this gives us the claimed hardness .",
    "we now turn to solving in the online setting . in this setting , the acquisition costs @xmath11 are known up - front , but the holding costs @xmath12 for day @xmath2 are not known before day @xmath2 . since the equivalence given in lemma  [ lem : pack - cover ] between and holds even in the online setting , we can just work on the problem .",
    "we show that the online problem admits an @xmath198-competitive ( oblivious ) randomized algorithm . to do this ,",
    "we show that one can find an @xmath199-competitive fractional solution to the linear programming relaxation in section  [ sec : offline ] , and then we round this lp relaxation online , losing another logarithmic factor .",
    "again , we work in the interval model outlined in section  [ sec : intervals ] .",
    "recall that in this model , for each element @xmath77 there is a unique interval @xmath200 $ ] during which it is alive . the element @xmath77 has an acquisition cost @xmath11 , no holding costs .",
    "once an element has been acquired ( which can be done at any time during its interval ) , it can be used at all times in that interval , but not after that . in the online setting",
    ", at each time step @xmath2 we are told which intervals have ended ( and which have not ) ; also , which new elements @xmath77 are available starting at time @xmath2 , along with their acquisition costs @xmath11 . of course",
    ", we do not know when its interval @xmath201 will end ; this information is known only once the interval ends",
    ".    we will work with the same lp as in section  [ sec : lp - round ] , albeit now we have to solve it online .",
    "the variable @xmath202 is the indicator for whether we acquire element  @xmath77 . @xmath203",
    "\\notag\\end{aligned}\\ ] ] note that this is not a packing or covering lp , which makes it more annoying to solve online .",
    "hence we consider a slight reformulation .",
    "let @xmath204 denote the _ spanning set polytope _ defined as the convex hull of the full - rank ( a.k.a .",
    "spanning ) sets @xmath205 .",
    "since each spanning set contains a base , we can write the constraints of  ( [ eq:3 ] ) as : @xmath206 here",
    "we define @xmath207 to be the vector derived from @xmath208 by zeroing out the @xmath202 values for @xmath209 .",
    "it is known that the polytope @xmath204 can be written as a ( rather large ) set of covering constraints .",
    "indeed , @xmath210 , where @xmath211 is the dual matroid for @xmath82 .",
    "since the rank function of @xmath212 is given by @xmath213 , it follows that  ( [ eq:4 ] ) can be written as @xmath214 thus we get a covering lp with `` box '' constraints over @xmath17 .",
    "the constraints can be presented one at a time : in timestep @xmath2 , we present all the covering constraints corresponding to @xmath215 .",
    "we remark that the newer machinery of  @xcite may be applicable to [ eq : coveringconstraints ] .",
    "we next show that a simpler approach suffices will be useful in improving the rounding algorithm . ] .",
    "the general results of buchbinder and naor  @xcite ( and its extension to row - sparse covering problems by  @xcite ) imply a deterministic algorithm for fractionally solving this linear program online , with a competitive ratio of @xmath216 . however , this is not yet a polynomial - time algorithm , the number of constraints for each timestep being exponential .",
    "we next give an adaptive algorithm to generate a small yet sufficient set of constraints .",
    "[ [ solving - the - lp - online - in - polynomial - time.-1 ] ] solving the lp online in polynomial time .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given a vector @xmath217^e$ ] , define @xmath218 as follows : @xmath219 clearly , @xmath220 and @xmath221^e$ ] .",
    "we next describe the algorithm for generating covering constraints in timestep @xmath2 .",
    "recall that  @xcite give us an online algorithm @xmath222 for solving a fractional covering lp with box constraints ; we use this as a black - box .",
    "( this lp solver only raises variables , a fact we will use . ) in timestep @xmath2 , we adaptively select a small subset of the covering constraints from ( [ eq : coveringconstraints ] ) , and present it to @xmath222 .",
    "moreover , given a fractional solution returned by @xmath222 , we will need to massage it at the end of timestep @xmath2 to get a solution satisfying all the constraints from ( [ eq : coveringconstraints ] ) corresponding to @xmath2 .",
    "let @xmath208 be the fractional solution to  ( [ eq : coveringconstraints ] ) at the end of timestep @xmath108 . now given information about timestep @xmath2 , in particular the elements in @xmath215 and their acquisition costs",
    ", we do the following . given @xmath208",
    ", we construct @xmath218 and check if @xmath223 , as one can separate for @xmath204 .",
    "if @xmath223 , then @xmath218 is feasible and we do not need to present any new constraints to @xmath222 , and we return @xmath218 . if not , our separation oracle presents an @xmath42 such that the constraint @xmath224 is violated .",
    "we present the constraint corresponding to @xmath42 to @xmath222 to get an updated @xmath208 , and repeat until @xmath218 is feasible for time @xmath2 .",
    "( since @xmath222 only raises variables and we have a covering lp , the solution remains feasible for past timesteps . )",
    "we next argue that we do not need to repeat this loop more than @xmath225 times .",
    "[ lem : farfromfeasible ] if for some @xmath208 and the corresponding @xmath218 , the constraint @xmath226 is violated .",
    "then @xmath227    let @xmath228 and let @xmath229 .",
    "let @xmath230 denote @xmath231 .",
    "thus @xmath232 since both @xmath233 and @xmath234 are integers , it follows that @xmath235 . on the other hand , for every @xmath236 , and thus @xmath237 .",
    "consequently @xmath238 finally , for any @xmath239 , @xmath240 , so the claim follows .",
    "the algorithm @xmath222 updates @xmath208 to satisfy the constraint given to it , and lemma  [ lem : farfromfeasible ] implies that each constraint we give to it must increase @xmath241 by at least @xmath28 .",
    "the translation to the interval model ensures that the number of elements whose intervals contain @xmath2 is at most latexmath:[$|e_t| \\leq    time @xmath2 is at most @xmath243 .",
    "we summarize the discussion of this section in the following theorem .",
    "[ thm : lp - solve ] there is a polynomial - time online algorithm to compute an @xmath244-approximate solution to  ( [ eq:3 ] ) .",
    "we observe that the solution to this linear program can be trivially transformed to one for the lp in section  [ sec : lp - round ] .",
    "finally , the randomized rounding algorithm of section  [ sec : lp - round ] can be implemented online by selecting a threshold @xmath245 $ ] the beginning of the algorithm , where @xmath246 and selecting element @xmath77 whenever @xmath247 exceeds @xmath248 : here we use the fact that the online algorithm only ever raises @xmath202 values , and this rounding algorithm is monotone .",
    "rerandomizing in case of failure gives us an expected cost of @xmath24 times the lp solution , and hence we get an @xmath249-competitive algorithm .",
    "the dependence on the time horizon @xmath13 is unsatisfactory in some settings , but we can do better using lemma  [ lem : farfromfeasible ] . recall that the @xmath251-factor loss in the rounding follows from the naive union bound over the @xmath13 time steps .",
    "we can argue that when @xmath252 is small , we can afford for the rounding to fail occasionally , and charge it to the acquisition cost incurred by the linear program .",
    "the details appear in appendix  [ sec : just - logr ] .",
    "the dependence on the time horizon @xmath13 is unsatisfactory in some settings , but we can do better using lemma  [ lem : farfromfeasible ] . recall that the @xmath251-factor loss in the rounding follows from the naive union bound over the @xmath13 time steps .",
    "we now argue that when @xmath252 is small , we can afford for the rounding to fail occasionally , and charge it to the acquisition cost incurred by the linear program .",
    "let us divide the period @xmath253 $ ] into disjoint `` epochs '' , where an epoch ( except for the last ) is an interval @xmath161 for @xmath162 such that the total fractional acquisition cost @xmath254 .",
    "thus an epoch is a minimal interval where the linear program spends acquisition cost @xmath255 $ ] , so that we can afford to build a brand new tree once in each epoch and can charge it to the lp s fractional acquisition cost in the epoch . naively applying theorem  [ thm : lp - round ] to each epoch",
    "independently gives us a guarantee of @xmath256 , where @xmath165 is the maximum length of an epoch .",
    "however , an epoch can be fairly long if the lp solution changes very slowly .",
    "we break up each epoch into phases , where each phase is a maximal subsequence such that the lp incurs acquisition cost at most @xmath257 ; clearly the epoch can be divided into at most @xmath258 disjoint phases .",
    "for a phase @xmath259 $ ] , let @xmath260}$ ] denote the solution defined as @xmath260}(e ) = \\min_{t\\in [ t_1,t_2 ] } z_t(e)$ ] .",
    "the definition of the phase implies that for any @xmath261 $ ] , the @xmath262 difference @xmath263 } - z_t\\|_1 \\leq \\frac{1}{4}$ ]",
    ". now lemma  [ lem : farfromfeasible ] implies that @xmath264}$ ] is in @xmath265 , where @xmath266 is defined as in  ( [ eq:5 ] ) .",
    "suppose that in the randomized rounding algorithm , we pick the threshold @xmath267 $ ] for @xmath268 .",
    "let @xmath269}$ ] be the event that the rounding algorithm applied to @xmath260}$ ] gives a spanning set .",
    "since @xmath264 } \\leq 2z_{[t_1,t_2]}$ ] is in @xmath270 for a phase @xmath259 $ ] , lemma  [ lem : rand - round ] implies that the event @xmath269}$ ] occurs with probability @xmath271 .",
    "moreover , if @xmath269}$ ] occurs , it is easy to see that the randomized rounding solution is feasible for all @xmath272 $ ] .",
    "since there are @xmath273 phases within an epoch , the expected number of times that the randomized rounding fails any time during an epoch is @xmath274 .",
    "suppose that we rerandomize all thresholds whenever the randomized rounding fails .",
    "each rerandomization will cost us at most @xmath275 in expected acquisition cost .",
    "since the expected number of times we do this is less than once per epoch , we can charge this additional cost to the @xmath275 acquisition cost incurred by the lp during the epoch .",
    "thus we get an @xmath276-approximation .",
    "this argument also works for the online case ; hence for the common case where all the acquisition costs are the same , the loss due to randomized rounding is @xmath25 .",
    "we can show that any polynomial - time algorithm can not achieve better than an @xmath277 competitive ratio , via a reduction from online set cover .",
    "details appear in appendix  [ app : sec : hardness - online ] .      in the online set cover problem ,",
    "one is given an instance @xmath278 of set cover , and in time step @xmath2 , the algorithm is presented an element @xmath279 , and is required to pick a set covering it .",
    "the competitive ratio of an algorithm on a sequence @xmath280}$ ] is the ratio of the number of sets picked by the algorithm to the optimum set - cover of the instance @xmath281\\},{{\\mathcal{f}}})$ ] .",
    "korman  ( * ? ? ?",
    "* theorem  2.3.4 ) shows the following hardness for online set cover :    there exists a constant @xmath282 such that if there is a ( possibly randomized ) polynomial time algorithm for online set cover with competitive ratio @xmath283 , then @xmath284 .",
    "recall that in the reduction in the proof of theorem  [ thm : matr - hard ] , the set of long term edges depends only on @xmath285 .",
    "the short term edges alone depend on the elements to be covered .",
    "it can then we verified that the same approach gives a reduction from online set cover to online .",
    "it follows that the online problem does not admit an algorithm with competitive ratio better than @xmath286 unless @xmath284 .",
    "in fact this hardness holds even when the end time of each edge is known as soon as it appears , and the only non - zero costs are @xmath287 .",
    "we next consider the _ perfect matching maintenance _ ( ) problem where @xmath17 is the set of edges of a graph @xmath288 , and the at each step , we need to maintain a perfect matchings in @xmath289 .",
    "* integrality gap . *",
    "somewhat surprisingly , we show that the natural lp relaxation has an @xmath290 integrality gap , even for a constant number of timesteps .",
    "the lp and the ( very simple ) example appears in appendix  [ sec : match - int - gap ] .",
    "the natural lp relaxation is : @xmath291 the polytope @xmath292 is now the perfect matching polytope for @xmath289 .",
    "[ lem : int - gap ] there is an @xmath290 integrality gap for the problem .",
    "consider the instance in the figure , and the following lp solution for 4 time steps . in @xmath293",
    ", the edges of each of the two cycles has @xmath294 , and the cross - cycle edges have @xmath295 . in @xmath296",
    ", we have @xmath297 and @xmath298 , and otherwise it is the same as @xmath293 .",
    "@xmath299 and @xmath300 are the same as @xmath293 . in @xmath301",
    ", we have @xmath302 and @xmath303 , and otherwise it is the same as @xmath293 .",
    "for each time @xmath2 , the edges in the support of the solution @xmath304 have zero cost , and other edges have infinite cost .",
    "the only cost incurred by the lp is the movement cost , which is @xmath158 .",
    "consider the perfect matching found at time @xmath305 , which must consist of matchings on both the cycles .",
    "( moreover , the matching in time 3 must be the same , else we would change @xmath290 edges . )",
    "suppose this matching uses exactly one edge from @xmath306 and @xmath307 .",
    "then when we drop the edges @xmath308 and add in @xmath309 , we get a cycle on @xmath310 vertices , but to get a perfect matching on this in time @xmath311 we need to change @xmath290 edges . else",
    "the matching uses exactly one edge from @xmath306 and @xmath312 , in which case going from time @xmath313 to time @xmath314 requires @xmath290 changes .    * hardness .",
    "* moreover , in appendix  [ app : sec : match - hard ] we show that the perfect matching maintenance problem is very hard to approximate :    for any @xmath315 it is np - hard to distinguish instances with cost @xmath316 from those with cost @xmath317 , where @xmath318 is the number of vertices in the graph .",
    "this holds even when the holding costs are in @xmath22 , acquisition costs are @xmath319 for all edges , and the number of time steps is a constant .      in this section",
    "we prove the following hardness result :    for any @xmath315 it is np - hard to distinguish instances with cost @xmath316 from those with cost @xmath317 , where @xmath318 is the number of vertices in the graph .",
    "this holds even when the holding costs are in @xmath22 , acquisition costs are @xmath319 for all edges , and the number of time steps is a constant .",
    "the proof is via reduction from @xmath313-coloring .",
    "we assume we are given an instance of @xmath313-coloring @xmath288 where the maximum degree of @xmath289 is constant .",
    "it is known that the @xmath313-coloring problem is still hard for graphs with bounded degree  ( * ? ? ?",
    "* theorem  2 ) .",
    "we construct the following gadget @xmath320 for each vertex @xmath321 .",
    "( a figure is given in figure  [ fig : gadget ] . )",
    "there are two cycles of length @xmath322 , where @xmath33 is odd .",
    "the first cycle ( say @xmath323 ) has three distinguished vertices @xmath324 at distance @xmath33 from each other .",
    "the second ( called @xmath325 ) has similar distinguished vertices @xmath326 at distance @xmath33 from each other .",
    "there are three more `` interface '' vertices @xmath327 .",
    "vertex @xmath328 is connected to @xmath329 and @xmath330 , similarly for @xmath331 and @xmath332 .",
    "there is a special `` switch '' vertex @xmath333 , which is connected to all three of @xmath334 .",
    "call these edges the _ switch _ edges .    due to the two odd cycles ,",
    "every perfect matching in @xmath320 has the structure that one of the interface vertices is matched to some vertex in @xmath323 , another to a vertex in @xmath325 and the third to the switch @xmath333 .",
    "we think of the subscript of the vertex matched to @xmath333 as the color assigned to the vertex @xmath335 .    at every odd time step @xmath126 ,",
    "the only allowed edges are those within the gadgets @xmath336 : i.e. , all the holding costs for edges within the gadgets is zero , and all edges between gadgets have holding costs @xmath87 .",
    "this is called the `` steady state '' .    at every even time step @xmath2 , for some matching @xmath337 of the graph",
    ", we move into a `` test state '' , which intuitively tests whether the edges of a matching @xmath338 have been properly colored .",
    "we do this as follows . for every edge @xmath339 ,",
    "the switch edges in @xmath340 become unavailable ( have infinite holding costs ) .",
    "moreover , now we allow some edges that go between @xmath320 and @xmath341 , namely the edge @xmath342 , and the edges @xmath343 for @xmath344 and @xmath345 .",
    "note that any perfect matching on the vertices of @xmath346 which only uses the available edges would have to match @xmath342 , and one interface vertex of @xmath320 must be matched to one interface vertex of @xmath341 .",
    "moreover , by the structure of the allowed edges , the colors of these vertices must differ .",
    "( the other two interface vertices in each gadget must still be matched to their odd cycles to get a perfect matching . ) since the graph has bounded degree , we can partition the edges of @xmath289 into a constant number of matchings @xmath347 for some @xmath348 ( using vizing s theorem ) . hence , at time step @xmath349 , we test the edges of the matching @xmath350 .",
    "the number of timesteps is @xmath351 , which is a constant .    .",
    "the test - state edges are on the right . ]",
    "suppose the graph @xmath289 was indeed @xmath313-colorable , say @xmath352 is the proper coloring .",
    "in the steady states , we choose a perfect matching within each gadget @xmath320 so that @xmath353 is matched . in the test state @xmath354 ,",
    "if some edge @xmath355 is in the matching @xmath338 , we match @xmath342 and @xmath356 .",
    "since the coloring @xmath357 was a proper coloring , these edges are present and this is a valid perfect matching using only the edges allowed in this test state .",
    "note that the only changes are that for every test edge @xmath358 , the matching edges @xmath359 and @xmath360 are replaced by @xmath342 and @xmath361 .",
    "hence the total acquisition cost incurred at time @xmath354 is @xmath362 , and the same acquisition cost is incurred at time @xmath363 to revert to the steady state .",
    "hence the total acquisition cost , summed over all the timesteps , is @xmath364 .",
    "suppose @xmath289 is not @xmath313-colorable .",
    "we claim that there exists vertex @xmath365 such that the interface vertex not matched to the odd cycles is different in two different timesteps ",
    "i.e . , there are times @xmath366 such that @xmath367 and @xmath185 ( for @xmath345 ) are the states",
    ". then the length of the augmenting path to get from the perfect matching at time @xmath368 to the perfect matching at @xmath369 is at least @xmath33 .",
    "now if we set @xmath370 , then we get a total acquisition cost of at least @xmath371 in this case .",
    "the size of the graph is @xmath372 , so the gap is between @xmath373 and @xmath374 .",
    "this proves the claim .",
    "in this paper we studied multistage optimization problems : an optimization problem ( think about finding a minimum - cost spanning tree in a graph ) needs to be solved repeatedly , each day a different set of element costs are presented , and there is a penalty for changing the elements picked as part of the solution .",
    "hence one has to hedge between sticking to a suboptimal solution and changing solutions too rapidly .",
    "we present online and offline algorithms when the optimization problem is maintaining a base in a matroid .",
    "we show that our results are optimal under standard complexity - theoretic assumptions .",
    "we also show that the problem of maintaining a perfect matching becomes impossibly hard .",
    "our work suggests several directions for future research .",
    "it is natural to study other combinatorial optimization problems , both polynomial time solvable ones such shortest path and min - cut , as well np - hard ones such as min - max load balancing and bin - packing in this multistage framework with acquisition costs .",
    "moreover , the approximability of the _ bipartite _ matching maintenance , as well as matroid intersection maintenance remains open .",
    "our hardness results for the matroid problem hold when edges have @xmath375 acquisition costs . the unweighted version where all acquisition costs are equal may be easier ; we currently know no hardness results , or sub - logarithmic approximations for this useful special case .",
    "an extension of /problems is to the case when the set of elements remain the same , but the matroids change over time . again",
    "the goal in is to maintain a matroid base at each time .",
    "[ thm : diff - matrs - wpb ] the problem with different matroids is np - hard to approximate better than a factor of @xmath376 , even for partition matroids , as long as @xmath377 .",
    "the reduction is from 3d - matching ( 3 dm ) .",
    "an instance of 3 dm has three sets @xmath378 of equal size @xmath379 , and a set of hyperedges @xmath380 .",
    "the goal is to choose a set of disjoint edges @xmath381 such that @xmath382 .    first , consider the instance of with three timesteps @xmath383 .",
    "the universe elements correspond to the edges . for @xmath384 , create a partition with @xmath10 parts , with edges sharing a vertex in @xmath385 falling in the same part .",
    "the matroid @xmath386 is now to choose a set of elements with at most one element in each part . for @xmath387",
    ", the partition now corresponds to edges that share a vertex in @xmath388 , and for @xmath389 , edges that share a vertex in @xmath390 .",
    "set the movement weights @xmath391 for all edges .",
    "if there exists a feasible solution to 3 dm with @xmath10 edges , choosing the corresponding elements form a solution with total weight @xmath10 . if the largest matching is of size @xmath392 , then we must pay @xmath393 extra over these three timesteps .",
    "this gives a @xmath10-vs-@xmath394 gap for three timesteps .    to get a result for @xmath13 timesteps , we give the same matroids repeatedly , giving matroids @xmath395 at all times @xmath396",
    "$ ] . in the `` yes '' case",
    "we would buy the edges corresponding to the 3d matching and pay nothing more than the initial @xmath10 , whereas in the `` no '' case we would pay @xmath397 every three timesteps .",
    "finally , the apx - hardness for 3 dm  @xcite gives the claim .",
    "the time - varying problem does admit an @xmath24 approximation , as the randomized rounding ( or the greedy algorithm ) shows .",
    "however , the equivalence of and does not go through when the matroids change over time .",
    "the restriction that the matroids vary over time is essential for the np - hardness , since if the partition matroid is the same for all times , the complexity of the problem drops radically .",
    "[ thm : partition ] the problem with partition matroids can be solved in polynomial time .",
    "the problem can be solved using min - cost flow .",
    "indeed , consider the following reduction .",
    "create a node @xmath398 for each element @xmath77 and timestep @xmath2 .",
    "let the partition be @xmath399 .",
    "then for each @xmath400 $ ] and each @xmath401 , add an arc @xmath402 , with cost @xmath403 .",
    "add a cost of @xmath12 per unit flow through vertex @xmath398 .",
    "( we could simulate this using edge - costs if needed . ) finally , add vertices @xmath404 and source @xmath405 . for each @xmath406 ,",
    "add arcs from @xmath177 to all vertices @xmath407 with costs @xmath408 .",
    "all these arcs have infinite capacity .",
    "now add unit capacity edges from @xmath405 to each @xmath177 , and infinite capacity edges from all nodes @xmath409 to @xmath2 .    since the flow polytope is integral for integral capacities , a flow of @xmath6 units will trace out @xmath6 paths from @xmath405 to @xmath2 , with the elements chosen at each time @xmath2 being independent in the partition matroid , and the cost being exactly the per - time costs and movement costs of the elements .",
    "observe that we could even have time - varying movement costs .",
    "whereas , for graphical matroids the problem is @xmath410 hard even when the movement costs for each element do not change over time , and even just lie in the set @xmath375 .    moreover , the restriction in theorem  [ thm : diff - matrs - wpb ] that @xmath411 is also necessary , as the following result shows .",
    "[ thm : two ] for the case of two rounds ( i.e. , @xmath412 ) the problem can be solved in polynomial time , even when the two matroids in the two rounds are different .",
    "the solution is simple , via matroid intersection .",
    "suppose the matroids in the two timesteps are @xmath413 and @xmath414 .",
    "create elements @xmath415 which corresponds to picking element @xmath77 and @xmath416 in the two time steps , with cost @xmath417 .",
    "lift the matroids @xmath386 and @xmath418 to these tuples in the natural way , and look for a common basis .",
    "we note that deterministic online algorithms can not get any non - trivial guarantee for the problem , even in the simple case of a @xmath319-uniform matroid .",
    "this is related to the lower bound for deterministic algorithms for paging .",
    "formally , we have the 1-uniform matroid on @xmath5 elements , and @xmath419 .",
    "all acquisition costs @xmath11 are 1 . in the first period , all holding costs are zero and the online algorithm picks an element , say @xmath420 .",
    "since we are in the non - oblivious model , the algorithm knows @xmath420 and can in the second time step , set @xmath421 , while leaving the other ones at zero .",
    "now the algorithm is forced to move to another edge , say @xmath422 , allowing the adversary to set @xmath423 and so on . at the end of @xmath419 rounds ,",
    "the online algorithm is forced to incur a cost of 1 in each round , giving a total cost of @xmath13 .",
    "however , there is still an edge whose holding cost was zero throughout , so that the offline opt is 1 . thus against a non - oblivious adversary , any online algorithm must incur a @xmath424 overhead .      in this section ,",
    "we show that if the aspect ratio of the movement costs is not bounded , the linear program has a @xmath426 gap , even when @xmath13 is exponentially larger than @xmath5 .",
    "we present an instance where @xmath426 and @xmath427 are about @xmath6 with @xmath428 , and the linear program has a gap of @xmath425 .",
    "this shows that the @xmath429 term in our rounding algorithm is unavoidable .",
    "the instance is a graphical matroid , on a graph @xmath289 on @xmath430 , and @xmath431 .",
    "the edges @xmath432 for @xmath433 $ ] have acquisition cost @xmath434 and holding cost @xmath435 for all @xmath2 .",
    "the edges @xmath436 for @xmath437 $ ] have acquisition cost @xmath438 and have holding cost determined as follows : we find a bijection between the set @xmath40 $ ] and the set of partitions @xmath439 of @xmath440 with each of @xmath441 and @xmath442 having size @xmath443 ( by choice of @xmath13 such a bijection exists , and can be found e.g. by arranging the @xmath441 s in lexicographical order . ) . in time",
    "step @xmath2 , we set @xmath181 for @xmath444 , and @xmath445 for all @xmath446 .",
    "first observe that no feasible integral solution to this instance can pay acquisition cost less than @xmath443 on the @xmath432 edges .",
    "suppose that the solution picks edges @xmath447 for some set @xmath448 of size at most @xmath443 .",
    "then any time step @xmath2 such that @xmath449 , the solution has picked no edges connecting @xmath450 to @xmath442 , and all edges connecting @xmath441 to @xmath442 have infinite holding cost in this time step .",
    "this contradicts the feasibility of the solution .",
    "thus any integral solution has cost @xmath290 .",
    "finally , we show that on this instance , ( [ eq : lp2 ] ) from section  [ sec : lp - round ] , has a feasible solution of cost @xmath158 .",
    "we set @xmath451 for all @xmath452 $ ] , and set @xmath453 for @xmath454 .",
    "it is easy to check that @xmath455 is in the spanning tree polytope for all time steps @xmath2 . finally , the total acquisition cost is at most @xmath456 for the edges incident on @xmath450 and at most @xmath457 for the other edges , both of which are @xmath158 .",
    "the holding costs paid by this solution is zero .",
    "thus the lp has a solution of cost @xmath158    the claim follows .",
    "the greedy algorithm for is the natural one .",
    "we consider the interval view of the problem ( as in section  [ sec : intervals ] ) where each element only has acquisition costs @xmath11 , and can be used only in some interval @xmath201 .",
    "given a current subset @xmath458 , define @xmath459 .",
    "the benefit of adding an element @xmath77 to @xmath385 is @xmath460 and the greedy algorithm repeatedly picks an element @xmath77 maximizing @xmath461 and adds @xmath77 to @xmath385 .",
    "this is done until @xmath462 for all @xmath51 $ ] .",
    "phrased this way , an @xmath23 bound on the approximation ration follows from wolsey  @xcite .",
    "we next give an alternate dual fitting proof .",
    "we do not know of an instance with uniform acquisition costs where greedy does not give a constant factor approximation .",
    "the dual fitting approach may be useful in proving a better approximation bound for this special case .",
    "using lagrangian variables @xmath465 for each @xmath77 and @xmath466 , we write a lower bound for @xmath467 by @xmath468 which using the integrality of the matroid polytope can be rewritten as : @xmath469 here , @xmath470 denotes the cost of the minimum weight base at time @xmath2 according to the element weights @xmath471 , where the available elements at time @xmath2 is @xmath472 .",
    "the best lower bound is : @xmath473              it is useful to maintain , for each time @xmath2 , a _ minimum weight base _ @xmath64 of the subset @xmath479 according to weights @xmath480 .",
    "hence the current dual value equals @xmath481 .",
    "we start with @xmath482 and @xmath483 for all @xmath2 , which satisfies the above properties .",
    "suppose we now pick @xmath77 maximizing @xmath461 and get new set @xmath484 .",
    "we use @xmath485 akin to our definition of @xmath486 . call a timestep @xmath2 `` interesting '' if @xmath487 ; there are @xmath488 interesting timesteps .",
    "how do we update the duals ?",
    "for @xmath489 , we set @xmath490 .",
    "note the element @xmath77 itself satisfies the condition of being in @xmath491 for precisely the interesting timesteps , and hence @xmath492 .",
    "for each interesting @xmath86 , define the base @xmath493 ; for all other times set @xmath494 .",
    "it is easy to verify that @xmath495 is a base in @xmath496 .",
    "but is it a min - weight base ?",
    "inductively assume that @xmath64 was a min - weight base of @xmath479 ; if @xmath2 is not interesting there is nothing to prove , so consider an interesting @xmath2 .",
    "all the elements in @xmath491 have just been assigned weight @xmath497 , which by the monotonicity properties of the greedy algorithm is at least as large as the weight of any element in @xmath479 . since @xmath77 lies in @xmath491 and",
    "is assigned value @xmath498 , it can not be swapped with any other element in @xmath496 to improve the weight of the base , and hence @xmath499 is an min - weight base of @xmath496 .",
    "it remains to show that the dual constraints are approximately satisfied .",
    "consider any element @xmath500 , and let @xmath501 .",
    "the first step where we update @xmath502 for some @xmath503 is when @xmath500 is in the span of @xmath486 for some time @xmath2 .",
    "we claim that @xmath504 .",
    "indeed , at this time @xmath500 is a potential element to be added to the solution and it would cause a rank increase for @xmath505 time steps .",
    "the greedy rule ensures that we must have picked an element @xmath77 with weight - to - coverage ratio at most as high .",
    "similarly , the next @xmath2 for which @xmath502 is updated will have @xmath506 , etc .",
    "hence we get the sum @xmath507 since each element can only be alive for all @xmath13 timesteps , we get the claimed @xmath23-approximation .    note that the greedy algorithm would solve @xmath508 even if we had a different matroid @xmath509 at each time @xmath2",
    ". however , the equivalence of and no longer holds in this setting , which is not surprising given the hardness of theorem  [ thm : diff - matrs - wpb ] ."
  ],
  "abstract_text": [
    "<S> this paper is motivated by the fact that many systems need to be maintained continually while the underlying costs change over time . </S>",
    "<S> the challenge then is to continually maintain near - optimal solutions to the underlying optimization problems , without creating too much churn in the solution itself . </S>",
    "<S> we model this as a multistage combinatorial optimization problem where the input is a sequence of cost functions ( one for each time step ) ; while we can change the solution from step to step , we incur an additional cost for every such change .    </S>",
    "<S> we first study the multistage matroid maintenance problem , where we need to maintain a base of a matroid in each time step under the changing cost functions and acquisition costs for adding new elements . </S>",
    "<S> the online version of this problem generalizes onine paging , and is a well - structured case of the metrical task systems . </S>",
    "<S> e.g. , given a graph , we need to maintain a spanning tree @xmath0 at each step : we pay @xmath1 for the cost of the tree at time @xmath2 , and also @xmath3 for the number of edges changed at this step . </S>",
    "<S> our main result is a polynomial time @xmath4-approximation to the online multistage matroid maintenance problem , where @xmath5 is the number of elements / edges and @xmath6 is the rank of the matroid . </S>",
    "<S> this improves on results of buchbinder et al .  </S>",
    "<S> @xcite who addressed the _ fractional _ version of this problem under uniform acquisition costs , and buchbinder , chen and naor  @xcite who studied the fractional version of a more general problem . </S>",
    "<S> we also give an @xmath7 approximation for the offline version of the problem . </S>",
    "<S> these bounds hold when the acquisition costs are non - uniform , in which case both these results are the best possible unless p = np .    </S>",
    "<S> we also study the perfect matching version of the problem , where we must maintain a perfect matching at each step under changing cost functions and costs for adding new elements . </S>",
    "<S> surprisingly , the hardness drastically increases : for any constant @xmath8 , there is no @xmath9-approximation to the multistage matching maintenance problem , even in the offline case . </S>"
  ]
}