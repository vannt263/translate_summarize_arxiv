{
  "article_text": [
    "a fundamental application of stellar dynamics is using observations of a galaxy s kinematics to constrain its potential  @xmath1 . the galaxy is normally assumed to be collisionless and in a steady state , so that the dynamics of any population of stars are completely described by its phase space distribution function ( df ) , @xmath2 , which is the probability density of finding a star in the small volume of phase space around @xmath3 . by jeans theorem , this df can depend on @xmath3 only through the integrals of motion of the ( unknown ) potential .",
    "most approaches to this task begin by considering the simpler problem of constraining @xmath4 given the observed data and some trial @xmath5 .",
    "the infinite - dimensional df is parametrized by a finite sum of delta functions ( e.g. , * ? ? ?",
    "* ) or a truncated basis function expansion ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) , and the df parameters are adjusted to optimize the fit to the observations . if no set of parameters yields an acceptable fit while simultaneously representing a df that is everywhere non negative , then the assumed potential can be ruled out .",
    "this basic idea can be refined further .",
    "@xcite pointed out that naive application of this method will yield unrealistically spiky dfs , leading them to advocate the use of entropy ( or something similar ) as a regularizer .",
    "this idea of regularizing the resulting dfs was made more explicit by @xcite , who cast the problem as one of finding the maximum penalized log - likelihood , @xmath6 $ ] , which allows a trade off between goodness of fit , as measured by @xmath0 , and smoothness , as measured by the penalty function @xmath7 .",
    "the choice of penalty function and the value to use for the tradeoff parameter  @xmath8 are arbitrary and subjective . given a range of trial potentials ,",
    "one finds the maximum penalized likelihood for each and then uses normal statistical methods to make statements about how well constrained the potential is .",
    "this general approach has become the method of choice in stellar - dynamical searches for supermassive black holes ( hereafter bhs ) in galaxy centres , with choices of penalty function ranging from the mean - square second derivative of the df ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) or entropy ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ) through to models in which no regularization whatsoever has been applied ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "i refer to these as `` maximum - likelihood '' or `` maximum - penalized likelihood '' methods .",
    "another way to look at the problem of constraining potentials is to treat it as a straightforward mathematical inverse problem .",
    "@xcite considered the case of constraining the potential of a spherical galaxy given perfect knowledge of its projected df in the form of its line - of - sight velocity profiles ( hereafter vps ) @xmath9 . by using a set of higher - order jeans equations they showed that , given the potential , the df @xmath10 is completely determined by its projected vps . constraining the potential ,",
    "however , proved less amenable to their methods , but they found that choosing a potential too far from the true one would yield moments ( and therefore dfs ) that became negative , ruling out that potential .",
    "of course , one never has perfect knowledge of the full projected df .",
    "more recently , ( * ? ? ?",
    "* hereafter vme04 ) investigated the slightly less idealized problem of constraining the bh mass in a toy axisymmetric galaxy given noiseless measurements of a restricted number of ( modified ) moments of its vps averaged over a number of spatial bins on the sky .",
    "they showed that even when the potential has just one free parameter ",
    "the bh mass  there are many different potentials that can fit the available kinematics almost perfectly , even when the central spatial resolution of the kinematics is much finer than the bh s sphere of influence .",
    "one thing that all these methods have in common is that they consider just one df for each trial potential .",
    "this is fine for the idealized case considered by @xcite : given perfectly resolved , noiseless projected vps of a spherical galaxy there is a unique df for any assumed potential , even though this df may not be non - negative everywhere .",
    "but when the available data have finite spatial and velocity resolution , there will in general be many perfectly sensible , non - negative dfs that yield equally good fits to the data , and even more dfs producing fits that are only slightly worse .",
    "intuitively , one might expect that the more such dfs a potential admits , the more likely it is .",
    "the purpose of the present paper is to revisit the the problem of constraining bh masses from a thoroughly bayesian perspective , showing how it naturally incorporates this intuitive notion of counting up dfs . to illustrate the ideas , i use simulated observations of some idealized spherical toy galaxies described in section  2 , modelling them under the assumptions given in section  3 . in section  4",
    "i test how well the conventional maximum likelihood method recovers bh masses and counter some of the more pessimistic conclusions of vme04 .",
    "section  5 presents a bayesian approach to the problem , which overcomes some of the inconsistencies of the maximum likelihood method .",
    "finally , section  6 sums up and discusses the implications for bh masses in real galaxies .",
    "my toy galaxies are spherical with luminosity density profile @xcite @xmath11 and constant mass - to - light ratio  @xmath12 for radii @xmath13 , so that the total stellar mass @xmath14 . at @xmath15",
    "there is a bh of mass @xmath16 .",
    "the galaxies used in this paper all have inner density slope @xmath17 , for which the bh dominates the kinematics inside a radus @xmath18 .    by jeans theorem @xcite",
    ", a spherical galaxy can be in equilibrium only if its phase - space distribution function ( df ) depends on @xmath19 only through the integrals of motion @xmath20 and  @xmath21 , the energy and angular momentum per unit mass .",
    "the dfs of the toy galaxies have the form @xcite @xmath22 where the parameter @xmath23 controls the degree of anisotropy , with @xmath24 .",
    "i solve for @xmath25 given @xmath26 and @xmath27 using the method described in @xcite , and present results for both isotropic ( @xmath28 ) and mildly radially anisotropic ( @xmath29 ) toy galaxies .",
    "the standard `` observations '' of each toy galaxy consist of its luminosity - weighted vps averaged over abutting shells , with 5 shells per decade in radius whose centres run from @xmath30 to @xmath31 .",
    "these observations both resolve the bh s sphere of influence and extend to more than twice the galaxies effective radii .",
    "i calculate vps  @xmath9 using the procedure described in @xcite and parametrize each using a gauss ",
    "hermite series @xcite , @xmath32 \\sum_{i=0}^\\infty h_ih_i\\left(v - v\\over\\sigma\\right).\\end{aligned}\\ ] ] this expresses the vp as an underlying gaussian with normalization @xmath33 , mean  @xmath34 and dispersion  @xmath35 , modified by a sum of hermite polynomials  @xmath36 . for any reasonable choice of @xmath37",
    "it is straightforward to show that choosing @xmath38 l(v)h_i\\left(v - v\\over\\sigma\\right)\\,{\\rm d}v\\ ] ] minimizes the mean - square deviation between @xmath9 and @xmath39 .",
    "therefore , the @xmath40 are simply _ modified moments _ of @xmath9 .",
    "i choose @xmath37 to be the parameters of the best - fitting gaussian to @xmath9 , in which case @xmath34 and the odd @xmath40 are zero , @xmath41 ( by equs .",
    "[ eq : ghseries ] and [ eq : ghcoeff ] above ) and @xmath42 measures the lowest - order departure of the vp from gaussianity .",
    "each realization of a toy galaxy then consists of 19 vps .",
    "i expand each vp about its underlying best - fit gaussian @xmath37 , and reduce the vp to four `` measurements '' : the mean surface brightness @xmath43 , and the three lowest - order luminosity - weighted modified moments ( @xmath44 . to these",
    "i add independent , normally distributed errors @xmath45 , @xmath46 , comparable to the formal errors from observations of real galaxies . notice that the parameters of the underlying gaussian @xmath37 are _ chosen _ by me , not measured , and so have no measurement uncertainties .",
    "some further comments on the use of the modified moments  ( [ eq : ghcoeff ] ) are in order . @xcite",
    "have shown that gauss ",
    "hermite expansions are not particularly well suited for parametrizing the vps of real galaxy centres : real vps can be very strongly non - gaussian , and in practice measurements of the coefficients  @xmath40 are not independent , even for fixed @xmath37 .",
    "i nevertheless use the gauss ",
    "hermite parametrization in the present paper for the following reasons : truncated fourth - order gauss ",
    "hermite expansions turn out to provide reasonably accurate fits to the vps of the toy galaxies ; real observations have finite velocity resolution , which is mimicked , at least qualitatively , by truncating the infinite gauss ",
    "hermite expansion ( e.g. , compare the eigen - vps in fig .",
    "6 of @xcite with the gauss ",
    "hermite basis in fig .  1 of @xcite ) ; finally , using gauss ",
    "hermite expansions permits a more direct comparison with vme04 s method and results .",
    "the general modelling scheme is the same as that used in @xcite .",
    "the model potentials  @xmath47 have two free parameters , the bh mass  @xmath27 and the mass - to - light ratio  @xmath12 , corresponding to mass densities of the form @xmath48 where @xmath26 is given by  ( [ eq : lumprof ] ) . since the kinematics of the toy galaxies are averaged over abutting shells and extend to many effective radii , it turns out that @xmath12 is very well constrained by virtue of the virial theorem @xcite .",
    "so , for the results presented in this paper i simply fix @xmath12 at its correct value .",
    "this means that model and galaxy potentials differ only in their bh masses .",
    "having the potential  @xmath5 , i discretize the df @xmath49 on an @xmath50 regular grid in phase space .",
    "the points @xmath51 are chosen through @xmath52 with the @xmath53 spaced logarithmically between @xmath54 and @xmath55 .",
    "there are @xmath56 values of angular momentum for each  @xmath51 , with @xmath57 running linearly between @xmath58 and @xmath59 , the angular momentum of a circular orbit of energy  @xmath51 . to avoid a rash of indices",
    "i henceforth write the double sum  ( [ eq : dfdoublesum ] ) as a single sum over @xmath60 points : @xmath61 this discretization effectively partitions phase space into abutting rectangular cells , with the luminosity contained in each cell being given by @xmath62 where @xmath63 is the density of states for the potential  @xmath5 and @xmath64 the volume occupied by the cell . in section",
    "[ sec : priors ] it will provide convenient to use a dimensionless luminosity @xmath65 where @xmath66 is a characteristic luminosity scale . the models projected observables @xmath67 , @xmath68 depend linearly on the orbit weights @xmath69 , so that the @xmath0 of a model with df @xmath70 is the quadratic form @xmath71^t\\cdot \\left[{\\b q}-p(\\psi)\\cdot\\b f\\right],\\ ] ] where @xmath72 is a column vector containing the list of observations , normalized by their uncertainties , and @xmath73 is a projection matrix whose @xmath74 columns contain the contribution each df component makes to the model s prediction for @xmath75 .",
    "the calculation of @xmath73 is described in appendix  a.",
    "having a set of observations of a toy galaxy , let us first test how well a simplified version of the standard maximum - likelihood method ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* ) reproduces the correct bh mass and its uncertainties .",
    "the procedure is as follows :    1 .",
    "choose a trial bh mass @xmath27 and calculate the corresponding potential  @xmath5 ; 2 .   calculate the projection matrices @xmath73 appearing in  ( [ eq : chisq ] ) ; 3 .   use a non - negative least - squares algorithm @xcite to find @xmath76 , the minimum value of  ( [ eq : chisq ] ) subject to the constraint that all @xmath77 ; 4 .",
    "assign a likelihood @xmath78 $ ] to the potential  @xmath5 .",
    "one obtains constraints on @xmath27 by considering a range of  @xmath27 and comparing their relative likelihoods . to keep the interpretation of the results as simple as possible",
    ", i do not impose any regularization on the  @xmath69 .",
    "section  [ sec : reg ] below discusses this further .",
    "distributions returned by the conventional maximum - likelihood method ( section  [ sec : maxlik ] ) for noiseless observations of an isotropic toy galaxy ( solid curve ) and for two different realizations of observations with simulated noise ( dashed and dot - dashed curves ) . ]",
    "one of the more alarming conclusions reached by vme04 was that the problem of constraining bh masses is inherently strongly degenerate ; they found that a wide range of bh masses could provide equally good fits to mock kinematics with realistic spatial resolution .",
    "the main goal of this section of the present paper is to understand this result and to investigate whether its implications really are as negative as vme04 suggest .    the solid curve in figure  [ fig : chisqconven ] plots @xmath79 obtained for models with @xmath80 df components when applied to noise - free observations of the isotropic toy galaxy .",
    "it demonstrates that vme04 s central result also holds for the simpler spherical case considered here : a wide range of @xmath27 can produce perfect fits to perfect noiseless data . for bh masses in the range @xmath81 ,",
    "@xmath0 is of order @xmath82 , rising to @xmath83 for @xmath84 or @xmath85 . a model with _ no",
    "_ bh can produce kinematics that differ by only a small amount ( @xmath86 ) from the toy galaxy s . of course",
    ", these values of @xmath0 are statistically meaningless since they do not account for the fact that the observations in this contrived situation have zero uncertainty ; the increase of @xmath0 to @xmath87 from its minimum value of @xmath82 ( which is zero to machine precision ) is actually very significant .",
    "the other two curves in figure  [ fig : chisqconven ] show the results of adding two different realizations of noise to the simulated dataset .",
    "this makes @xmath79 become nicely rounded , similar to what one finds in models of real galaxies ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "vme04 , however , only presented results for the noiseless case .    these results can be explained by remembering that , for a fixed potential , @xmath0 is a quadratic form  ( [ eq : chisq ] ) in the orbit weights  @xmath88 . since the number of unknowns is very much less than the number of observations , this quadratic form is hugely degenerate",
    ": it resembles more a multi - dimensional trough than a parabola .",
    "if we relax the constraint that all @xmath77 , then it turns out that for all the models considered here  independent of the value of  @xmath27  the value of @xmath0 at the bottom of the trough is zero ( to machine precision ) ; the non - negativity constraint is essential for constraining the bh mass . of course , for the correct model with @xmath89 , the bottom of the trough passes through the discretized version of the true df  ( [ eq : df ] ) , which is well away from the boundaries given by @xmath77 . then making a small change in the trial  @xmath27 leads to a small change in the projection matrix , particularly for those @xmath69 corresponding to the most tightly bound orbits , and therefore changes the shape of the quadratic form slightly as well as the location of its minimum . changing the potential too much moves the location of the minimum to a region where at least one of the weights becomes negative , so that the minimum value of @xmath0 in the subvolume @xmath77 is no longer zero . adding noise simply shifts the centre of the quadratic form , with no change in its shape . for realistic amounts of noise ,",
    "the centre is shifted well into the region where many of the orbit weights are negative , leading to the rounded @xmath79 profiles .      in order to examine this more quantitatively ,",
    "let us consider how the uncertainties on @xmath27 depend on the signal - to - noise ratio of the simulated data . to do this ,",
    "we need a method of quantifying the uncertainty on @xmath27 .",
    "the accepted practice in this field is to assume that the @xmath90 boundaries of @xmath91 give reliable indicators of the 68 percent confidence limits on @xmath27 ( e.g. , * ? ? ?",
    "this is based on the assumption ( e.g. , * ? ? ?",
    "* ) that @xmath91 is close to quadratic and therefore that the probability distribution @xmath92 is almost gaussian , but the results above and in vme04 show that this assumption can be far from the truth .",
    "so , throughout this paper i use the mean and variance , @xmath93\\d m_\\bullet\\\\ \\left(\\delta { m_{\\bullet}}\\right)^2 & \\equiv a\\int ( m_\\bullet-\\overline{m_\\bullet})^2   \\exp\\left[-{1\\over2}\\chi^2_{\\rm min}(m_\\bullet)\\right]\\d m_\\bullet , \\end{split } \\label{eq : meanvar}\\ ] ] to quantify the best - fitting @xmath27 and its associated uncertainty , the quantity @xmath94 being chosen to make @xmath95\\,\\d m_\\bullet=1 $ ] .",
    "i find that this @xmath96 agrees well with the ( correctly calculated ) 68 percent confidence intervals for the following .",
    ", on the bh mass @xmath27 returned by the maximum - likelihood method for a typical realization of the noise in the observations .",
    "the solid curves in the top panel plots the mean @xmath27 and its formal uncertainty ( eq .  [ eq : meanvar ] ) as a function of @xmath97 , the relative size of the observational errors .",
    "for comparison , the dotted curves show the uncertainties on @xmath27 returned by the widely used @xmath98 criterion .",
    "the bottom panel plots the corresponding minimum value of @xmath0 .",
    "the @xmath99 case corresponds to the dot - dashed curve in figure  [ fig : chisqconven ] . ]",
    "figure  [ fig : varynoise ] shows how @xmath100 and @xmath96 vary as one changes the size of the observational uncertainties for one particular noise realization @xmath101 , the errors @xmath102 being shrunk by a factor  @xmath97 with respect to the `` standard '' observational errors .",
    "the following points hold for typical noise realizations @xmath101 :    1 .   given noiseless data ( @xmath103 ) ,",
    "a range of @xmath27 spanning @xmath104 can produce perfect fits .",
    "this is essentially the `` @xmath98 '' measure of the uncertainty on @xmath27 applied to a uniform distribution .",
    "the variance of a distribution uniform for @xmath105 $ ] is given by @xmath106 .",
    "therefore , the more useful estimate of the uncertainty given by equ .",
    "( [ eq : meanvar ] ) is a factor @xmath107 smaller , or @xmath108 .",
    "3 .   one can obtain perfect fits to the data for any @xmath109 , the precise upper bound on  @xmath97 depending on the particular noise realization .",
    "4 .   around the value of @xmath97 where the best - fitting @xmath0 starts to lift off from zero ,",
    "the uncertainty @xmath96 _ drops _ as @xmath97 increases .",
    "overall , @xmath96 grows slowly with @xmath97 ; it grows by only a factor @xmath110 between the noise - free @xmath103 and the more realistic @xmath99 situation .",
    ".bh mass estimates for toy galaxies using the conventional maximum - likelihood method [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]     columns are : the galaxy s anisotropy ( @xmath23 ) , the number of orbits used in the modelling ( @xmath111 ) and the innermost extent of the projected kinematics ( @xmath112 ) ; the mean bh mass from many realizations @xmath113 and the typical formal uncertainty in @xmath27 .",
    "[ tab : conventional ]    at first sight the last point might seem to suggest that there is little point in obtaining very high signal - to - noise observations , but of course one could extract higher - order information on the vps from such observations , such as @xmath114 or its equivalent , and , in some cases , one could also use finer spatial binning .",
    "both of these would act to reduce the degeneracy in @xmath27 for @xmath103 .",
    "having examined the effects of observational uncertainties on the uncertainty on @xmath27 , let us now turn to the simpler question of whether the maximum - likelihood method yields estimates of @xmath27 close to the true bh mass .",
    "taking the @xmath99 situation of realistic noise and averaging over many hypothetical datasets , the typical formal error in @xmath27 is about @xmath115 ( isotropic galaxy ) or @xmath116 ( anisotropic galaxy ) , both increasing only slightly as the number of df components used increases ( table  1 ) .",
    "the maximum - likelihood method yields fairly strongly biased estimates of @xmath27 for the anisotropic galaxy , which nevertheless are well within the formal uncertainties .      apart from the strange dependence of the formal uncertainty @xmath117 on the signal - to - noise ratio ,",
    "perhaps the most telling feature of models obtained using the maximum - likelihood method is how well they fit : they are too good to be true . while adding realistic amounts of noise to the observations removes the flat bottom in @xmath0 , the value of @xmath0 at the minimum remains very much less than the number ( 76 ) of observed data points ( e.g. , figure  [ fig : chisqconven ] ) .",
    "these fits are implausibly good ; the chances are tiny that the actual values of @xmath118 in the real galaxy are all so close to the observed estimates . furthermore , the models achieve this level of fit by having only @xmath119 of the @xmath69",
    "greater than zero : the internal kinematics of the model are very irregular .",
    "it is important then to consider how @xmath27 is affected when one includes models that yield more plausible fits to the data .",
    "following  @xcite , the approach advocated by vme04 and subsequently by @xcite is to regularize the df , finding for each  @xmath27 the @xmath120 that maximize a penalized log - likelihood , @xmath121 $ ] .",
    "the penalty function @xmath122 $ ] provides some arbitrary measure of the smoothness of the df and the parameter @xmath8 is set by how much one is willing to trade off goodness - of - fit for a smoother df .",
    "although beguiling , this approach is only marginally better than the conventional maximal likelihood method used above , because both    1 .",
    "identify a single privileged `` best '' df ; 2 .   and",
    "then take this df to be representative of _ all _ of the dfs for the assumed potential .",
    "the first step is fine ( at least for certain applications ) , but the second is wholly unjustified and ignores the fact that @xmath123 $ ] is hugely degenerate .    to see a variant of this problem in a much milder context , consider how one measures @xmath27 in real galaxies .",
    "the potential then has at least one additional free parameter , the mass - to - light ratio  @xmath12 , and one has to construct a grid of models for a range of different values of @xmath27 and @xmath12 .",
    "the uncertainties on @xmath27 are never obtained by picking out a special value of @xmath12 for each @xmath27 ; instead one marginalizes @xmath12 either explicitly ( e.g. , * ? ? ? * ) or implicitly through the use of a @xmath124 criterion ( e.g. , * ? ? ?",
    "* ; * ? ? ?",
    "this idea of marginalization is key to resolving the issues noted above .",
    "the maximum - likelihood approach of the previous section pays scant attention to the orbit weights  @xmath69 , which serve merely as co - ordinates used to locate a point somewhere along the degenerate minimum in @xmath0 . from a bayesian point of view",
    ", however , the @xmath69 are _ nuisance parameters_. although we are not interested knowing their precise values , they deserve to be treated on an equal footing with the parameters defining the potential .",
    "applying bayes theorem twice , the posterior probability of a model with potential @xmath5 and a set of orbit weights  @xmath125 , @xmath126 where @xmath127 $ ] is the usual likelihood and the priors @xmath128 and @xmath129 will be discussed later .",
    "since we are not interested in the values of weights ( as long as they are non - negative ) , let us marginalize  ( [ eq : bayesone ] ) to obtain @xmath130 where the marginalized likelihood , @xmath131 , \\end{split}\\ ] ] is obtained by summing the likelihood over all non - negative dfs , each weighted by the as - yet - unspecified prior @xmath128 .",
    "notice that this is directly analogous to the partition function in statistical mechanics , with @xmath0 playing the role of energy and the prior standing in for the density of states .",
    "the conventional maximum - likelihood method of the last section can be viewed as the very crude approximation @xmath132\\right],\\ ] ] obtained by completely ignoring the prior @xmath133 and approximating the remaining integral by the peak value of its integrand .",
    "there is a straightforward and obvious analogue for the maximum penalized likelihood method .",
    "there is nothing noteworthy about the choice of the potential prior @xmath129 for the situation considered here .",
    "the potential has one free parameter , @xmath27 , which can be zero or positive , meaning that the natural prior to use is flat in @xmath134 .",
    "the choice of prior for the df , @xmath128 , is more interesting .",
    "recall that we use discrete cells  ( [ eq : dfdiscretization ] ) to model continuous phase space .",
    "now , there is no a priori natural way to partition phase space into cells .",
    "let us assume for the moment that there are no correlations among cells and that the prior is independent of location in phase space .",
    "let @xmath135 be the prior expectation value for the dimensionless luminosity @xmath136 ( eq .  [ eq : flux ] ) in cell  @xmath137 ; it can therefore be thought of as measure of the cell s volume .",
    "then a natural requirement on the prior is that , given a partition  @xmath138 of phase space , we should be able to select any cell and construct a new partition  @xmath139 by subdividing this cell into @xmath140 subcells and have that @xmath141 where the cell volumes satisfy @xmath142 .",
    "that is , marginalizing over the subcells should return the original prior .",
    "a consequence of this is that , for finite - resolution data , the marginalized likelihood @xmath143 is independent of the chosen partition provided only that one uses fine enough cells .",
    "the infinite - divisibility ( hereafter i d ) condition  ( [ eq : id ] ) puts strong constraints on the form of the prior .",
    "it is not satisfied by any of the simplest commonly used priors @xmath144 & \\text{(entropy ) . }",
    "\\end{cases}\\ ] ] the form of the convolution in eq .",
    "( [ eq : id ] ) suggests that laplace transforms might be helpful in finding i d priors , and indeed it can be shown @xcite that a probability distribution @xmath145 satisfies  ( [ eq : id ] ) if and only if its laplace transform @xmath146 is of the form @xmath147,\\ ] ] with the only constraint on the measure @xmath148 , known as the _ lvy measure _ , being that the integral @xmath149 converges for all @xmath150 .",
    "thus we can construct priors that are guaranteed to be i d simply by considering a variety of choices for @xmath151 .",
    "for example , substituting @xmath152 in  ( [ eq : levykhinchin ] ) results in the possion distribution , while @xmath153 gives the gamma distribution .",
    "both of these obviously satisfy the i d criterion  ( [ eq : id ] ) .    a concise and very readable introduction to this subject is given by @xcite .",
    "he argues that the maximally ignorant choice of @xmath151 when one knows only a characteristic scale for  @xmath154 is @xmath155 this results in the so - called `` massive inference '' prior @xmath156 , \\end{split } \\label{eq : incontinent}\\ ] ] where @xmath157 is the first - order modified bessel function of the first kind .",
    "appendix  b gives an elementary derivation of this prior , explaining how it is the natural generalization of entropy to continuous distributions .",
    "i adopt it for the calculations below .",
    "[ eq : en ] ) for isotropic ( solid curve ) and anisotropic ( dashed ) toy galaxies , along with their difference ( bottom panel ) .",
    "@xmath158 is the apocentre radius of a perfectly radial orbit with energy  @xmath20 . ]",
    "there remains the question of what to choose for the prior weights  @xmath135 . from the laplace",
    "transform  ( [ eq : levykhinchin ] ) it is straightforward to show that the prior mean and variance , @xmath159 and therefore that the prior  ( [ eq : incontinent ] ) likes to have @xmath160 . in the absence of a compelling model of galaxy formation",
    ", i simply use the well - known fact @xcite that for reasonable galaxy models the differential energy distribution , @xmath161 is almost independent of anisotropy once the galaxy s luminosity density @xmath26 and potential  @xmath47 have been specified ( e.g. , see fig .",
    "[ fig : ne ] ) . for each trial potential",
    "i find the isotropic df @xmath162 that produces the luminosity density  ( [ eq : lumprof ] ) and , following  ( [ eq : lumcell ] ) and  ( [ eq : flux ] ) , assign @xmath163 this depends on the choice of characteristic luminosity scale @xmath164 ( equ .",
    "[ eq : flux ] ) .",
    "now , the prior rms fractional spread in each cell is equal to @xmath165 , which clearly depends on @xmath66 and has a poisson - like @xmath166 dependence on the cell volume . ) or from the fact that any i d prior is a limit of a sequence of compound poisson distributions @xcite . ] in order to make the prior variance independent of the partitioning scheme used to represent the df , i introduce a second , independent reference partition and choose @xmath167 so that the prior rms fractional spread in each reference cell is given by the adjustable parameter  @xmath168 .",
    "for the results presented here i use the partition defined by the @xmath169 grid for this reference partition .      although one could attempt the difficult task of evaluating the marginalized likelihood @xmath143  ( eq .",
    "[ eq : marglike ] ) directly , we are not so much interested in the absolute value of @xmath143 as in the odds , @xmath170 of one potential  @xmath171 compared to another  @xmath172 .",
    "i evaluate the ratio @xmath173 using the method of thermodynamic integration @xcite .",
    "consider two models , one having potential  @xmath172 , the other with a slightly different potential  @xmath171 , but both having @xmath50 df components chosen according to the scheme described in section  3 for their respective potentials .",
    "let @xmath174\\,\\d\\b f\\ ] ] where @xmath175\\\\ & \\quad+ ( 1-\\lambda)\\ln\\pr(\\b f|\\psi_0 ) + \\lambda \\ln\\pr(\\b f|\\psi_1 ) .",
    "\\end{split}\\ ] ] as the parameter @xmath8 varies between 0 and  1 , @xmath176 interpolates smoothly between @xmath177 and @xmath178 .",
    "taking the logarithm of  ( [ eq : intermed ] ) and differentiating with respect to  @xmath8 , @xmath179\\d\\b f\\\\ & = \\big\\langle { \\d c_\\lambda\\over \\d\\lambda}\\big\\rangle_\\lambda , \\end{split}\\ ] ] where @xmath180 denotes the expectation value of @xmath181 when @xmath125 has probability density @xmath182/z_\\lambda$ ] .",
    "therefore we can use a markov - chain monte carlo method to draw points from this density , and taking the mean value of @xmath183 for these points gives an immediate estimate of @xmath184 .",
    "then , integrating , @xmath185 this method will be reasonably efficient only if the dependence of @xmath186 on @xmath125 does not vary significantly as @xmath8 changes , which is the case for the choice of @xmath69 using the scheme described in section  3 .    for the results presented below i use a gibbs sampler to draw @xmath187 points from @xmath188",
    "$ ] after a burn - in period of @xmath189 iterations starting from @xmath190 . instead of evaluating the derivative  ( [ eq : zprime ] ) for a range of fixed @xmath8",
    "i instead increase @xmath8 slowly from 0 to 1 over the course the iterations , yielding @xmath191 directly .",
    "a direct test of this procedure is to run it backwards by swapping the potentials around and calculating @xmath192 .",
    "i find that that both forward and backward iterations typically agree very well , provided @xmath193 . for larger @xmath168 ,",
    "the delta function in the prior  ( [ eq : incontinent ] ) becomes dominant and the posterior becomes effectively stuck at @xmath194 for a significant fraction of the df components",
    ".           used in the prior . ]",
    "using priors with @xmath195 , 10 and ( heavy solid curve ) 20 . for comparison , the dashed curve plots the corresponding probability distribution returned by the conventional maximum - likelihood method . ]    here i present results of applying the bayesian analysis to observations of the anisotropic toy galaxy .",
    "the results for the isotropic galaxy are similar but less instructive since i use the isotropic case to assign the prior weights @xmath196 .",
    "figure  [ fig : compareflat ] demonstrates the importance of using a prior that satisfies the i d criterion  ( [ eq : id ] ) .",
    "non - id ) prior flat in the orbit weights  @xmath125 leads to a marginalized likelihood  @xmath143 that depends on the number of orbits used and , more generally , on exactly how one discretizes phase space .",
    "in contrast , the marginalized likelihood @xmath197 for the i d prior  ( [ eq : incontinent ] ) does not depend on whether we discretize using @xmath198 , @xmath199 or @xmath200 cells .",
    "incidentally , this also shows that , for the present purposes at least , it is acceptable to use delta functions  ( eq .  [ eq : dfdiscretization ] ) to calculate the contribution each cell makes to the observations .",
    "although the marginalized likelihood is independent of the discretization , it still has one free parameter , the fractional variance per reference cell  @xmath201 . to investigate the dependence of the results on @xmath168 , i use the mean and variance of the posterior distribution @xmath202 , @xmath203 figure  [ fig : deltadep ]",
    "shows how the formal uncertainty @xmath117 varies with @xmath168 for a typical realization of the observations .",
    "as one might expect , @xmath96 is low for small @xmath204 , but grows rapidly as @xmath168 increases . once @xmath168 reaches @xmath205 though , @xmath96 stabilizes at about @xmath206 .",
    "the marginalized likelihoods @xmath197 used in calculating @xmath96 for the three largest values of @xmath168 plotted are shown in figure  [ fig : margprob ] , which shows that there is little change as one increases @xmath168 from 10 to 20 .",
    "it is somewhat surprising that @xmath168 needs to be so large .",
    "this might be a consequence of the power - law dependence of the df ( eq .  [ eq : df ] ) on  @xmath207 . for comparison , the figure also includes the probability distribution returned by applying the conventional maximum - likelihood method to the same dataset .",
    "taking many realizations of the galaxy , the bayesian method yields a mean @xmath96 of @xmath208 compared to the @xmath209 returned by the conventional method ( table  1 ) .",
    "most bh mass estimates come from the conventional maximum - likelihood method .",
    "they fit observations using models with specially constructed , unrealistically spiky dfs , yielding implausibly good fits to the observations .",
    "results from the toy galaxies considered here suggest that the ( unpenalized ) maximum - likelihood method nevertheless does yield reliable bh masses , but with overly pessimistic error estimates .",
    "i confirm vme04 s result that a wide range of bh masses can yield perfect fits to finite - resolution , noiseless observations .",
    "contrary to their somewhat speculative arguments , however , i show that one does not expect to find flat - bottomed @xmath0 distributions in practice , unless one is blessed with very high signal - to - noise observations ( figure  [ fig : varynoise ] ) and fits only the low - order shapes of the vps .",
    "although the maximum - likelihood method yields reliable bh masses , it is flawed because it considers only one df for each bh mass .",
    "the remedy is to consider all possible dfs for each potential , weighting each one by a suitably chosen prior .",
    "this significantly improves the constraints on the bh mass , since the closer a trial potential comes to the true potential , the greater the number of non - negative dfs that are consistent with the observations .",
    "an open question is to what extent these results depend on the choice of prior weights ( equ .",
    "[ eq : mu ] ) , and more generally on the use of the prior  ( [ eq : incontinent ] ) , which is just one of many possible infinitely divisible distributions .",
    "a very general argument @xcite shows that drawing random realizations from most i d priors will yield spiky , uncorrelated distributions .",
    "this is just what one expects if dealing with galaxies at the level of individual stars , but the present models are far from this level of detail and one might plausibly expect some degree of correlation among neighbouring cells in phase space .",
    "making this idea quantitative is difficult , however .      it would be straightforward in principle to apply the ideas presented here to axisymmetric or triaxial galaxy models .",
    "one could simply adopt the prior  ( [ eq : incontinent ] ) , using the scheme described by @xcite to calculate the volumes used to assign the prior weights @xmath210 . in practice , however , calculating the marginalized likelihood @xmath143 will probably be very difficult .",
    "the dfs of axisymmetric galaxies are three - integral , which means that , in order to ensure a fine enough discretization , one has to use many more df components than for two - integral spherical models , with the markov chain monte carlo procedure used in section  [ sec : marginalization ] taking correspondingly more iterations to converge . on the other hand ,",
    "it is very likely that there are much more efficient methods than the combination of gibbs sampling and thermodynamic integration used here .      before applying this method to real galaxies though",
    ", it is probably worth addressing the following more tractable problems first :    1 .",
    "vps are extracted from spectra , which suffer from poorly understood systematic errors @xcite .",
    "2 .   for real observations ,",
    "neither individual vp velocity bins nor ( surprisingly ) gauss  hermite coefficients are independent @xcite .",
    "most models of axisymmetric galaxies make an ad hoc assumption about the galaxy s three - dimensional light distribution @xmath211 , despite the fact that there are many @xmath211 consistent with a given surface brightness distribution ( e.g. , * ? ? ?",
    "neglect of this degeneracy can lead to incorrect inferences about the galaxy s orbit structure @xcite which are likely to affect bh mass estimates .",
    "the widely used @xmath124 criteria for obtaining uncertainties on bh masses are based on the assumption that @xmath212 is close to quadratic , which does not necessarily hold in practice .",
    "i thank james binney , karl gebhardt , andrew jaffe , douglas richstone , prasenjit saha and scott tremaine for helpful discussions , the anonymous referee and the participants of the 2006 lorentz center workshop on galactic nuclei for comments that greatly improved the presentation of the results contained here , and the royal society for financial support .",
    "99    binney j. , tremaine s. , 1987 , galactic dynamics .",
    "princeton university press .",
    "cappellari m. , verolme e.  k. , van der marel r.  p. , kleijn g.  a.  v. , illingworth g.  d. , franx m. , carollo c.  m. , de zeeuw p.  t. , 2002 , apj , 578 , 787 cretton n. , emsellem e. , 2004 , mnras , 347 , l31 cuddeford p. , 1991 ,",
    "mnras , 253 , 414 dehnen w. , 1993 , mnras , 265 , 250 dejonghe h. , 1989 , apj , 343 , 113 dejonghe h. , merritt d. , 1992 , apj , 391 , 531 feller w. , 1971 , an introduction to probability theory and its applications , vol 2 . ,",
    "gebhardt k. , et al .",
    ", 2003 , apj , 583 , 92 gerhard o.  e. , 1993 , mnras , 265 , 213 gull s.  f. , daniell g.  j. , 1978 , nature , 272 , 686 houghton r.  c.  w. , magorrian j. , sarzi m. , thatte n. , davies r.  l. , krajnovi d. , 2006 , mnras , 367 , 2 kingman j.  f.  c. , 1993 , poisson processes .",
    "oxford university press .",
    "kochanek c.  s. , rybicki g.  b. , 1996 , mnras , 280 , 1257 lawson , c. l. , & hanson , r. j. 1974 , solving least squares problems ( englewood cliffs , new jersey : prentice - hall ) magorrian j. , 1999 , mnras , 302 , 530 magorrian j. , tremaine s. , 1999 , mnras , 309 , 447 merritt d. , 1993 , apj , 413 , 79 neal r.  m. , 1993 , technical report crg - tr-93 - 1 , department of computer science , university of toronto press w.  h. , teukolsky s.  a. , vetterling w.  t. , flannery b.  p. , 1992",
    ", numerical recipes in c richstone d.o . , tremaine s. , 1988 , apj , 327 , 82 saglia r.  p. , kronawitter a. , gerhard o. , bender r. , 2000 , aj , 119 , 153 schwarzschild m. , 1979 , apj , 232 , 236 shu f.  h. , 1978 , apj , 225 , 83 silge j.  d. , gebhardt k. , bergmann m. , richstone d. , 2005 , aj , 130 , 406 skilling j. , 1998 , `` massive inference and maximum entropy '' , in maximum entropy and bayesian methods , g.erickson , j.t.rychert & c.ray.smith ( eds ) kluwer academic publishers , dordtrecht , p. 14",
    "thomas j. , saglia r.  p. , bender r. , thomas d. , gebhardt k. , magorrian j. , richstone d. , 2004 , mnras , 353 , 391 tremaine s. , richstone d.  o. , byun y. , dressler a. , faber s.  m. , grillmair c. , kormendy j. , lauer t.  r. , 1994 , aj , 107 , 634 valluri m. , merritt d. , emsellem e. , 2004 , apj , 602 , 66 ( vme04 ) van der marel r.  p. , franx m. , 1993 , apj , 407 , 525 van der marel r.  p. , cretton n. , de zeeuw p.  t. , rix h .- w . , 1998 , apj , 493 , 613 van der marel r.  p. , magorrian j. , carlberg r.  g. , yee h.  k.  c. , ellingson e. , 2000 , aj , 119 , 2038",
    "i use a rectangular @xmath213 co - ordinate system with origin  @xmath214 at the galaxy centre and whose @xmath215 axis is parallel to lines of sight .",
    "points on the plane of the sky are then labelled by the co - ordinates @xmath216 .",
    "of course , real observations do not have perfect spatial resolution . instead ,",
    "any function @xmath217 defined on the plane of the sky is measured convolved with a two - dimensional point - spread function @xmath218 : @xmath219 since we assume that the galaxy is spherical , then @xmath220 , where @xmath221 is the usual cylindrical polar radius , and the psf - convolved value of @xmath4 at radius  @xmath222 , @xmath223 where @xmath224 is the azimuthally integrated contribution of light from radii  @xmath225 to measurements at radius  @xmath222 . for example , in section  [ sec : toy ] the toy galaxies are `` observed '' through annulii that admit light between some radii @xmath226 and  @xmath227 .",
    "for this situation @xmath228 a more realistic psf is a gaussian with some dispersion  @xmath229 , for which @xmath230   i_0\\left(rr'\\over\\sigma_\\star^2\\right),\\ ] ] where @xmath231 is a bessel function .",
    "both these examples are symmetric , but we note that we can use ( [ eq : psfconvolve ] ) and  ( [ eq : psfrr ] ) to convolve any spherically symmetric function @xmath232 with a psf of arbitrary shape .    now consider a single df component  ( [ eq : dfdiscretization ] ) of energy  @xmath20 and angular momentum  @xmath207 per unit mass in potential  @xmath47 . written explicitly as a function of @xmath233 , @xmath234 \\delta\\big[r^2(v_\\theta^2+v_\\phi^2)-j^2\\big ] .",
    "\\label{eq : onedf}\\ ] ] the individual orbits making up the df component have peri- and apo - centre radii @xmath235 given by the roots of the equation @xmath236 , where @xmath237-{l^2\\over r^2},\\ ] ] and i have omitted the obvious dependence of the result on @xmath20 , @xmath207 and  @xmath5 .",
    "the velocity moments of the component  ( [ eq : onedf ] ) , @xmath238(r ) & \\equiv    \\int\\d^3\\b v\\ , v_r^{2i } v_\\theta^{2j}v_\\phi^{2k}\\ , f\\cr    & = 2b\\left(\\textstyle{i+{1\\over2},j+{1\\over2}}\\right)\\cr   & \\quad \\times \\begin{cases }    { v_r^{2i-1}j^{2(j+k)}\\over      r^{2(j+k+1 ) } } & \\text{if $ r_-<r < r_+$,}\\\\      0 & \\text{otherwise . } \\end{cases}\\end{aligned}\\ ] ] taking @xmath239 yields the luminosity density @xmath240 , which has integrable singularities at both @xmath241 and @xmath242 . integrating @xmath26 over radius , the total luminosity of the component  ( [ eq : onedf ] )",
    "is given by @xmath243 which is just the usual density - of - states factor .",
    "substituting  @xmath26 into equation  ( [ eq : psfconvolve ] ) , the psf - convolved surface brightness distribution @xmath244 i evaluate this integral numerically by substituting @xmath245 and applying simpson s rule with intervals @xmath246 and @xmath247 .",
    "a simple test of this calculation is to compare the integrated surface brightness @xmath248 against the density - of - states factor  ( [ eq : dosfac ] ) .",
    "i find that the two typically agree to around one part in @xmath249 .",
    "the calculation of velocity profiles is a little more involved .",
    "a star at position @xmath250 with velocity @xmath251 has projected line - of - sight velocity @xmath252.\\ ] ] the luminosity density of stars located at a position @xmath250 having projected velocities in the range @xmath253 is @xmath254\\,\\d^3\\b v\\\\ & = \\sum_\\pm\\int{\\d\\vp\\over rr|v_rv_{\\phi\\pm}| } , \\label{eq : histbinrz } \\end{split}\\ ] ] where the range of integration includes only those @xmath255 $ ] for which @xmath256 is non - negative , and the @xmath257 takes care of both possibilities for the sign of @xmath258 . integrating along the line of sight and using  ( [ eq : psfconvolve ] ) , the ( unnormalized ) psf - convolved contribution of the df component  ( [ eq : onedf ] ) to a vp bin that extends from from @xmath259 to  @xmath260 is @xmath261 the integral  ( [ eq : histbinrz ] ) for @xmath262 can be carried out by hand , but finding efficiently the regions where it is nonzero is far from easy .",
    "so , to evaluate the double integral  ( [ eq : histbinr ] ) i simply adopt the scheme i use to calculate  @xmath67 and substitute @xmath245 : the integration over @xmath263 already takes care of the worst effects of the singularities in the integrand of  ( [ eq : histbinrz ] ) . to test this approach , i compare the integrated vp histogram , @xmath264 for some choice of  @xmath265 , against  @xmath67 . for my standard integration parameters ,",
    "the typical rms fractional difference between these two quantities is about @xmath266 .",
    "this merely indicates that very little light `` leaks '' from the models , not that its vps are calculated to that accuracy . comparing vps calculated with different stepsizes",
    ", i estimate that this standard integration scheme yields vps with an rms fractional error of a few parts in @xmath249 .    to obtain the contribution each df component makes to the modifed moments @xmath68 , i calculate the component s vp histogram @xmath267 for 20 bins from @xmath268 to @xmath269 , where @xmath35 is the velocity dispersion used in the gauss ",
    "hermite expansion , and use this histogram in equation  ( [ eq : ghcoeff ] ) .",
    "the following derivation of the prior  ( [ eq : incontinent ] ) follows @xcite .",
    "imagine a monkey @xcite with a bag of @xmath270 identical stars each of luminosity  @xmath271 .",
    "he sits outside a big box containing phase space ( strictly , integral space ) , takes each star in turn and throws it into the box .",
    "the probability of each star landing in a small volume @xmath272 around the point @xmath3 is @xmath273 . if we take a small cell of volume @xmath274 , the probability that @xmath275 of the @xmath270 stars land inside the cell is @xmath276 now shrink the cell volume @xmath277 and increase the number of stars @xmath278 keeping the product @xmath279 constant . equation  ( [ eq : binom ] ) becomes @xmath280 describing a poisson process with mean @xmath281 .",
    "therefore , the probability of having luminosity  @xmath282 in a cell of phase - space volume @xmath64 is given by @xmath283 with @xmath284 .",
    "for a partition of phase space into @xmath74 cells , the probability of the configuration @xmath285 is given by a product of factors like  ( [ eq : monkeyfac]),which obviously satisfies the criterion  ( [ eq : id ] ) for infinite divisibility .",
    "apart from uninteresting scale factors , this prior is identical to equation  ( 20 ) of @xcite . in the limit",
    "@xmath286 it takes on the entropy - like form @xmath287 $ ] .",
    "the prior  ( [ eq : monkeyfac ] ) has the disadvantage of requiring a discretization of the light into individual stars , with the result that @xmath288 is very strongly peaked at 0 whenever @xmath289 .",
    "for an alternative , suppose that we place the monkey inside the box representing phase space and liquify his bag of stars so that the contents dribble out at a constant rate .",
    "encumbered by his heavy bag of stellar light , the monkey sits at one point @xmath290 dribbling starlight unless disturbed .",
    "every so often , however , we squeeze his tail and he jumps to a new position @xmath291 with probability density  @xmath292 . let the tail squeezes be a poisson process with rate  @xmath8 , so that the distribution of time intervals between consecutive squeezes is @xmath293 .",
    "more generally , the distribution of times between the @xmath294 and @xmath295 squeezes follows a gamma distribution . then",
    ", if the monkey lands @xmath275 times in a cell of volume  @xmath274 , the total length of time he spends in that cell has probability density @xmath296 in the limit of many tail squeezes , the probability that he lands @xmath275 times in a cell of volume  @xmath274 is again given by  ( [ eq : poisson ] ) .",
    "summing over  @xmath275 , the probability distribution for the length of time he spends in the cell is @xmath297 , \\label{tmpprobt } \\end{split}\\ ] ] with the bessel function @xmath157 coming in through the identity @xmath298 equation  ( [ tmpprobt ] ) is the i d prior  ( [ eq : incontinent ] ) with @xmath299 ."
  ],
  "abstract_text": [
    "<S> when faced with the task of constraining a galaxy s potential given limited stellar kinematical information , what is the best way of treating the galaxy s unknown distribution function ( df ) ? using the example of estimating black hole ( bh ) masses , i argue that the correct approach is to consider all possible dfs for each trial potential , marginalizing the df using an infinitely divisible prior . </S>",
    "<S> alternative approaches , such as the widely used maximum penalized likelihood method , neglect the huge degeneracies inherent in the problem and simply identify a single , special df for each trial potential .    </S>",
    "<S> using simulated observations of toy galaxies with realistic amounts of noise , i find that this marginalization procedure yields significantly tighter constraints on bh masses than the conventional maximum - likelihood method , although it does pose a computational challenge which might be solved with the development of a suitable algorithm for massively parallel machines . </S>",
    "<S> i show that in practice the conventional maximum - likelihood method yields reliable bh masses with well - defined minima in their @xmath0 distributions , contrary to claims made by valluri , merritt & emsellem .    </S>",
    "<S> [ firstpage ]    galaxies : nuclei  galaxies : kinematics and dynamics  stellar dynamics  </S>",
    "<S> methods : statistical </S>"
  ]
}