{
  "article_text": [
    "the first @xmath0-ensembles were introduced by dumitriu and edelman @xcite , the @xmath0-hermite ensemble and the @xmath0-laguerre ensemble .",
    "a @xmath0- ensemble is defined to be a real random matrix with a nonrandom continuous tuning parameter @xmath1 such that when @xmath3 , the @xmath0- ensemble has the same joint eigenvalue distribution as the real , complex , or quaternionic -ensemble .",
    "for @xmath0 not equal to @xmath4 its eigenvalue distribution interpolates naturally among the @xmath3 cases . a @xmath0-circular ensemble and four @xmath0-jacobi ensembles shortly followed @xcite , @xcite , @xcite , @xcite .",
    "the extreme eigenvalues of the @xmath0-jacobi ensembles were characterized by dumitriu and koev in @xcite .",
    "more recently , forrester @xcite and dubbs - edelman - koev - venkataramana @xcite separately introduced a @xmath0-wishart ensemble with diagonal covariance , which generalizes the @xmath0-laguerre ensemble by adding the covariance term .",
    "this paper introduces the @xmath0-manova ensemble with diagonal covariance , which generalizes the @xmath0-jacobi ensembles by adding the covariance term . when @xmath5 this amounts to finding the distribution of the cosine generalized singular values of the pair @xmath6 , where @xmath7 is @xmath8 gaussian , @xmath9 is @xmath10 gaussian , and @xmath11 is @xmath12 diagonal pds .",
    "note that forcing @xmath11 to be diagonal does not lose any generality ; using orthogonal transformations , were @xmath11 not diagonal we could replace it with its diagonal matrix of eigenvalues and preserve the model .",
    "our @xmath0-manova ensemble also generalizes the real , complex , and quaternionic manova ensembles ( the last of which has never been studied ) .",
    "@xcite , @xcite , and @xcite independently solved the @xmath5 identity - covariance case , @xcite solved our problem in the @xmath5 , general - covariance case , and @xcite solved our problem in the @xmath13 , general - covariance case .",
    "we find the joint eigenvalue distribution of the @xmath0-manova ensemble , and generalize dumitriu and koev s results in @xcite by finding the distribution of the largest generalized singular value of the @xmath0-manova ensemble .",
    "we also set the covariance to the identity to add a fourth @xmath0-jacobi ensemble to the literature in theorem 3.1 .",
    "our @xmath0-manova ensemble is unique in that it is not built on a recursive procedure , rather it is sampled by calling the sampler for the @xmath0-wishart ensemble .",
    "generalizations of our results exist in the @xmath14 cases by adding a mean matrix to one of the wishart - distributed parameters .",
    "the @xmath5 case is from @xcite and the @xmath13 case is from @xcite .",
    "the sampler for the @xmath0-wishart ensemble of forrester @xcite and dubbs - edelman - koev - venkataramana @xcite is the following algorithm :    .1 in .1 in    the elements of @xmath15 are distributed according to the following theorem of @xcite and @xcite :    the distribution of the singular values @xmath16 , @xmath17 , generated by",
    "the above algorithm is equal to : @xmath18 where @xmath19 and @xmath20 are defined in the upcoming section , preliminaries .    to get the generalized singular values of the @xmath0-manova ensemble with general covariance , in diagonal @xmath21 , we use the following algorithm which calls @xmath22 . let @xmath11 be an @xmath12 diagonal matrix .",
    ".1 in .1 in    our main theorem is the joint distribution of the elements of @xmath21 ,    the distribution of the generalized singular values @xmath23",
    ", @xmath24 , generated by the above algorithm for @xmath25 is equal to : @xmath26 where @xmath27 and @xmath20 are defined in the upcoming section , preliminaries .",
    "we also find the distributions of the largest generalized singular value in certain cases :    if @xmath28 , @xmath29 where the jack function @xmath30 and pochhammer symbol @xmath31 are defined in the upcoming section , preliminaries .",
    "these expressions can be computed by edelman and koev s software , mhg , @xcite .",
    "it is actually intuitive that @xmath32 should generalize the real , complex , and quaternionic manova ensembles with diagonal covariance using the `` method of ghosts . ''",
    "the method of ghosts was first used implicitly to derive @xmath0-ensembles for the laguerre and hermite cases in @xcite , was stated precisely by edelman in @xcite , and was expanded on in @xcite . to use the method of ghosts , assume a given ensemble is full of @xmath0-dimensional gaussians , which generalize real , complex , and quaternionic gaussians and have some of the same properties :",
    "they can be left invariant or made into a @xmath33 s under rotation by a real orthogonal or `` ghost orthogonal '' matrix . then apply enough orthogonal transformations and/or ghost orthogonal transformations to the ghost matrix to make it all real .    in the @xmath0-manova case ,",
    "let @xmath7 be @xmath8 real , complex , quaternion , or ghost normal , @xmath9 be @xmath34 real complex , quaternion , or ghost normal , and let @xmath11 be @xmath12 diagonal real pds .",
    "let @xmath35 have eigendecomposition @xmath36 , and @xmath37 have eigendecomposition @xmath38 .",
    "we want to draw @xmath39 so we can draw @xmath40 . let @xmath41 mean `` having the same eigenvalues . ''",
    "@xmath42 which we can draw the eigenvalues @xmath39 of using @xmath43 .",
    "since @xmath44 can be drawn using @xmath45 , this completes the algorithm for @xmath32 and proves theorem 1.1 in the @xmath3 cases .",
    "the following section contains preliminaries to the proofs of theorems 1.1 and 1.2 in the general @xmath0 case .",
    "most important are several propositions concerning jack polynomials and hypergeometric functions .",
    "proposition 2.1 was conjectured by macdonald @xcite and proved by baker and forrester @xcite , proposition 2.3 is due to kaneko , in a paper containing many results on selberg - type integrals @xcite , and the other propositions are found in @xcite .",
    "we define the generalized gamma function to be @xmath46 for @xmath47 .",
    "@xmath48    @xmath49 if @xmath7 is a diagonal matrix , @xmath50    as in dumitriu , edelman , and shuman , if @xmath51 , @xmath52 is nonnegative , ordered non - increasingly , and it sums to @xmath53 .",
    "let @xmath54 .",
    "let @xmath55 .",
    "we define @xmath56 to be the number of nonzero elements of @xmath57 .",
    "we say that @xmath58 in `` lexicographic ordering '' if for the largest integer @xmath59 such that @xmath60 for all @xmath61 , we have @xmath62 .    as in dumitriu , edelman and shuman ,",
    "@xcite we define the jack polynomial of a matrix argument , @xmath63 , as follows : let @xmath64 be the eigenvalues of @xmath7 . @xmath63 is the only homogeneous polynomial eigenfunction of the laplace - beltrami - type operator : @xmath65 with eigenvalue @xmath66 having highest order monomial basis function in lexicographic ordering ( see dumitriu , edelman , shuman , section 2.4 ) corresponding to @xmath57 . in addition , @xmath67    we define the generalized pochhammer symbol to be , for a partition @xmath68 @xmath69    as in koev and edelman @xcite , we define the hypergeometric function @xmath70 to be @xmath71 the best software available to compute this function numerically is described in koev and edelman , mhg , @xcite .",
    "@xmath72 .",
    "we will also need two theorems from the literature about integrals of jack polynomials and hypergeometric functions .",
    "conjectured by macdonald @xcite , proved by baker and forrester @xcite with the wrong constant , correct constant found using _ special functions _",
    "@xcite ( corollary 8.2.2 ) :    let @xmath7 be a diagonal matrix .",
    "@xmath73 where @xmath74 .    from @xcite ,    if @xmath75 is diagonal , @xmath76    kaneko , corollary 2 @xcite :    let @xmath77 be nonincreasing and @xmath7 be diagonal .",
    "let @xmath78 and @xmath1 .",
    "@xmath79 dx \\\\",
    "= c_\\kappa^{(\\beta)}(i)\\cdot\\prod_{i=1}^{n}\\frac{\\gamma(i\\beta/2 + 1)\\gamma(\\kappa_i+a+(\\beta/2)(n - i)+1)\\gamma(b + ( \\beta/2)(n - i)+1)}{\\gamma((\\beta/2)+1)\\gamma(\\kappa_i+a+b+(\\beta/2)(2n - i-1)+2)}.\\end{gathered}\\ ] ]    from @xcite ,    let @xmath7 be diagonal , @xmath80    from @xcite ,    if @xmath7 is @xmath12 diagonal and @xmath81 or @xmath82 is a nonpositive integer , @xmath83    from @xcite ,    @xmath84",
    "_ proof of theorem 1.1 .",
    "_ let @xmath85 .",
    "we will draw @xmath39 by drawing @xmath86 , and compute @xmath39 by drawing @xmath87 .",
    "the distribution of @xmath39 is @xmath88",
    ". then we will compute @xmath21 by @xmath89 .",
    "we use the convention that eigenvalues and generalized singular values are unordered . by the @xcite @xmath90 described in the introduction , we sample the diagonal @xmath44 from    @xmath91 @xmath48    likewise , by inverting the answer to the @xcite @xmath90 described in the introduction , we can sample diagonal @xmath39 from    @xmath92    to get @xmath93 we need to compute @xmath94 @xmath95 expanding the hypergeometric function , this is @xmath96 @xmath97.\\ ] ] using proposition 2.1 , @xmath96 @xmath98.\\ ] ] cleaning things up , @xmath99.\\ ] ] by the definition of the hypergeometric function , this is @xmath100 converting to cosine form , @xmath101 , this is @xmath102    if we set @xmath103 and @xmath104 , @xmath105 obey the standard @xmath0-jacobi density of @xcite , @xcite , @xcite , and @xcite . @xmath106    proposition 2.2 works from the statement of theorem 1.1 because @xmath107 ( we know that @xmath108 from how it is sampled , so @xmath109 , likewise @xmath110 ) . @xmath111 or equivalently @xmath112 if we substitute @xmath104 , by the change - of - variables theorem we get the desired result",
    ".    _ proof of theorem 1.2 .",
    "_ let @xmath113 . changing variables from ( 3.1 )",
    "we get @xmath114 taking the maximum eigenvalue , following mvs.pdf , @xmath115 letting @xmath116 , changing variables again we get @xmath117 expanding the hypergeometric function we get @xmath118.\\end{gathered}\\ ] ] using proposition 2.3 , @xmath119 now @xmath120 therefore , @xmath121 using ( 3.4 ) and the definition of the hypergeometric function we get @xmath122 rewriting the constant we get @xmath123 commuting some terms gives @xmath124 the left fraction in parentheses is @xmath125 hence @xmath126 now @xmath127 and @xmath128 , so equivalently , @xmath129 * remark . *",
    "using @xmath130 and setting @xmath103 this is @xmath131 so by using proposition 2.4 , this is @xmath132 which is familiar from dumitriu and koev @xcite .    now back to the proof of theorem 1.2 .",
    "if we use proposition 2.4 on ( 3.6 ) we get @xmath133 using the approach of dumitriu and koev @xcite , let @xmath134 in @xmath135 .",
    "we can prove that the series truncates : looking at ( 3.7 ) , the hypergeometric function involves the term @xmath136 which is zero when @xmath137 and @xmath138 , so the series truncates when any @xmath139 has @xmath140 , or just @xmath141 .",
    "this must happen if @xmath142 .",
    "thus ( 3.7 ) is just a finite polynomial , @xmath143 let @xmath144 be a positive - definite diagonal matrix , and @xmath145 a real with @xmath146 .",
    "define @xmath147 using proposition 2.5 , @xmath148 using the definition of the hypergeometric function and the fact that the series must truncate , @xmath149 now the limit is obvious @xmath150 plugging this expression into ( 3.8 ) @xmath151 cancelling via proposition 2.6 gives @xmath152",
    "the plots below are empirical cdf s of the greatest generalized singular value as sampled by the @xmath153 pseudocode in the introduction ( the blue lines ) against the theorem 1.2 formula for them as calculated by mhg ( red x s ) .    , @xmath154 , @xmath155 , @xmath156 , and @xmath157 .",
    "]    , @xmath154 , @xmath158 , @xmath159 , and @xmath157 . ]",
    "we acknowledge the support of the national science foundation through grants solar grant no . 1035400 , dms-1035400 , and dms-1016086 .",
    "alexander dubbs was funded by the nsf grfp .",
    "peter j. forrester , eric m. rains , `` interpretations of some parameter dependent generalizations of classical matrix ensembles , '' _ probability theory and related fields _ , volume 131 , issue 1 , pp .",
    "1 - 61 , january , 2005 .                      plamen koev and alan edelman , `` the efficient evaluations of the hypergeometric function of a matrix argument , '' _ mathematics of computation _ , volume 75 , number 254 , pages 833 - 846 , january 19 , 2006 .",
    "code available at http://www-math.mit.edu/  plamen / software / mhgref.html"
  ],
  "abstract_text": [
    "<S> we find the joint generalized singular value distribution and largest generalized singular value distributions of the @xmath0-manova ensemble with positive diagonal covariance , which is general . </S>",
    "<S> this has been done for the continuous @xmath1 case for identity covariance ( in eigenvalue form ) , and by setting the covariance to @xmath2 in our model we get another version . for the diagonal covariance case , it has only been done for @xmath3 cases ( real , complex , and quaternion matrix entries ) . </S>",
    "<S> this is in a way the first second - order @xmath0-ensemble , since the sampler for the generalized singular values of the @xmath0-manova with diagonal covariance calls the sampler for the eigenvalues of the @xmath0-wishart with diagonal covariance of forrester and dubbs - edelman - koev - venkataramana . </S>",
    "<S> we use a conjecture of macdonald proven by baker and forrester concerning an integral of a hypergeometric function and a theorem of kaneko concerning an integral of jack polynomials to derive our generalized singular value distributions . </S>",
    "<S> in addition we use many identities from forrester s _ log - gases and random matrices_. we supply numerical evidence that our theorems are correct .    </S>",
    "<S> = 1 </S>"
  ]
}