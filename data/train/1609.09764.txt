{
  "article_text": [
    "audio signals occurring in nature which are generally of interest to us are a mixture of foreground speech and background noise like factory or babble noise .",
    "analysis of these audio signals is useful for acquiring information about the speaker , background noise environment , location of speech segments and source separation .",
    "estimation of background noise helps us to narrow down to the possible geographical location of the speaker .",
    "other applications include selection of appropriate noise model for speech enhancement .",
    "speaker estimation is useful for tracking the person and selecting an appropriate speaker model for source separation .",
    "estimation of frame - wise energy of speech source is used for speech segment detection .",
    "these speech segments can then be processed for further speech analysis and recognition .",
    "we also estimate the segmental snr and detect the speech segments in a noisy speech signal .    in the case of",
    "when both speaker and background noise are unknown , the noise can be mapped to the nearest noise and speaker index , and the model for the same can be used for separation or enhancement .",
    "the model corresponding to the nearest noise/ speaker index can be adapted using the segments of the test signal containing noise/ speech only segments .",
    "snr estimation and location of speech segments gives us the temporal information of speech/ noise only segments occurring within an audio signal .",
    "so , analysis of audio signals can be done even though the noise/ speaker components belong to a unknown set .",
    "identification of background environment and speaker is useful in other applications like hearing aids @xcite , forensics @xcite and robotic navigation systems @xcite . in this work ,",
    "we address the problem of classification and separation of a mixed audio signal containing multiple speakers and noises using the concept of dictionary based representation , block sparsity @xcite and sparse non - negative recovery @xcite .",
    "the advantage of using dictionary based approach for classification is that sparse representation using dictionaries can assume that the signal to be classified may be mixed with noises whose dictionary is known or can be estimated .",
    "however , conventional methods for classification generally fail when the signal to be classified is mixed with noises at low signal to noise ratios .",
    "we propose a novel , rule - based , sparse representation approach to first identify the type of noises and speakers present in a mixed audio signal and subsequently separate the speech and noise signals .",
    "we assume the mixed audio signal consists of speech from two speakers , each in the presence of a specific type of noise .",
    "the objective score of signal to distortion ratio and improvement in signal to noise ratio ( snr ) shows the speech enhancement achieved .",
    "work on audio content analysis and scene classification has been done by many researchers .",
    "@xcite used k - nearest neighbor and line spectral pairs - vector quantization to classify audio into speech , music , environmental sound and silence .",
    "zhang et.al .",
    "@xcite classified and segmented audio signal from movies or tv programs using simple audio features like energy function and average zero crossing rate .",
    "a review of the state of the art in acoustic scene classification was done by barchiesi et.al .",
    "@xcite while giannoulis et al .",
    "@xcite evaluated 11 algorithms along with a baseline system for scene classification using a statistical model or majority vote based classifier .",
    "cauchi @xcite did auditory scene classification using non - negative matrix factorization ( nmf ) .",
    "lyon @xcite explored machinery noise diagnostics while shirkhodaie et .",
    "@xcite surveyed acoustic signature classification of aircrafts or vehicles .",
    "kates @xcite classified noise for hearing aid applications based on variation of signal envelope as features .",
    "classification of different kinds of noise and speech using line spectral frequencies as features was done by maleh et .",
    "a system using a hidden markov model classifier and log - spectral features to classify twenty different types of sounds was devised by casey @xcite . matching pursuit based features",
    "were combined with mel - frequency cepstral coefficients by chu et .",
    "@xcite to recognize 14 different environmental sounds .",
    "techniques for stationary and non - stationary environmental sound recognition was surveyed by chachada et .",
    "malik @xcite estimated the amount of reverberation and background noise variance using a statistical technique .",
    "sparsity based speaker identification using discriminative dictionary learning was done by tzagkarakis et .",
    "@xcite while non - negative matrix factorization for feature extraction was explored by joder et .",
    "al . @xcite .",
    "machine listening research to solve real world problems in perceptual computing was explored by malkin @xcite .",
    "our paper addresses some components of machine listening like classification and separation of multiple speakers and noises in a mixed audio signal .",
    "a dictionary is a representation of features from large training data using a weighted linear combination of vectors called as atoms .",
    "source recovery is the method of estimating weights corresponding to these atoms , given a test feature vector .",
    "representation of audio signals as a linear combination of non - negative dictionary atoms is shown for audio source separation @xcite , recognition @xcite , classification @xcite and coding @xcite .",
    "dictionary learning ( dl ) method by random selection of features from the training data is done in @xcite .",
    "k - means clustering has been used for dl by @xcite .",
    "the relation between dl and vector quantization was shown by @xcite .",
    "a probabilistic model of the features has been used by olshausen @xcite and lewicki @xcite for dl .",
    "engan et al .",
    "@xcite performed dl using dictionary update method ( minimization of mean square error ) and sparse coding using orthogonal matching pursuit ( omp ) @xcite or focal underdetermined system solver ( focuss ) @xcite .",
    "recursive least squares dictionary learning ( rls - dla ) @xcite , k - svd @xcite , simultaneous codeword optimisation ( simco ) @xcite and fast dictionary learning @xcite are other dl algorithms . dl and source recovery methods have been used for classification of objects in images by learning class - specific dictionaries @xcite .",
    "shafiee et al .",
    "@xcite have used three different dl methods to classify faces and digits in images .",
    "some source recovery algorithms are matching pursuit @xcite , orthogonal matching pursuit ( omp ) @xcite , basis pursuit @xcite , focal underdetermined system solver ( focuss ) @xcite and active - set newton algorithm ( asna ) @xcite .",
    "dl and source recovery methods have been used for classification of objects in images by learning class - specific dictionaries @xcite .",
    "we have used the active - set newton algorithm ( asna ) @xcite algorithm for source recovery in the testing phase .",
    "the benefits of this algorithm are that the it returns non - negative weights and can handle non - stationary signals like speech .",
    "the training phase for the classification problem is dl from various speaker/ noise sources where different dictionary atoms encompass the variation in the spectral characteristics .",
    "girish et .",
    "@xcite classified the speaker and noise type using sparse representation in the case of a single speaker and noise .",
    "this paper deals with segments containing multiple noises and speakers , and estimates all the speakers and noises embedded in the mixed audio signal .",
    "also , this paper uses additional dictionary learning methods and separates speech and noise sources .",
    "in addition , we deal with unknown speaker and noise sources using adaptive dictionaries .",
    "the major contributions of this paper are : ( 1 ) simulating audio signals containing a concatenation of multiple noises , with speech from different speakers mixed with each type of noise , ( 2 ) block sparsity and concatenated dictionary based classification of multiple speech and noise sources in a mixed audio signal , ( 3 ) a rule based divide and conquer approach to segment and classify multiple noise segments , ( 4 ) using high energy frames along with relatively higher average weights corresponding to speaker dictionaries with respect to that of noise dictionary for speaker classification ( 3 ) exploring different dictionary learning methods for classification and separation of audio signals , ( 5 ) adaptive update of noise and speaker dictionaries and a novel generalized algorithm to update dictionaries using noise and speech only parts of the noisy speech signal and evaluating improvement in performance .",
    "a dictionary is defined as a matrix @xmath0 ( with @xmath1 as the dimension of the acoustic feature vector ) containing @xmath2 column vectors called atoms , denoted as @xmath3 .",
    "any real valued feature vector can be represented as @xmath4 , where @xmath5 is the vector containing weights for each dictionary atom .",
    "the vector @xmath6 is estimated by minimizing the distance @xmath7 , where @xmath8 is a distance metric between @xmath9 and @xmath10 such as @xmath11 norm or kullback - leibler ( kl)-divergence @xcite . in case",
    "the dictionary @xmath12 is overcomplete , the weight vector @xmath13 tends to be sparse .",
    "dictionary learning is the method of constructing the dictionary @xmath12 , given the training features for each source .",
    "all the atoms of the dictionary are normalized to unit @xmath14 norm . in this paper , we use dictionary learning methods which learn non - negative dictionary atoms , since non - negative training features are used and we want to avoid negative representation of features .",
    "threshold dependent cosine similarity based dictionary learning ( tdcs ) proposed in @xcite is used apart from random selection and clustering based methods for dictionary learning .    in tdcs , each dictionary atom is selected such that it is as uncorrelated as possible to the rest of the atoms belonging to the same as well as other sources . the correlation between a pair of atoms @xmath15",
    "is measured using the cosine similarity as :    @xmath16    two types of cosine similarity measures are used : ( a ) intra - class cosine similarity ( intra - cs ) defined as @xmath17 @xmath18 where @xmath19 is the dictionary for a specific source ; and ( b ) inter - class cosine similarity ( inter - cs ) defined as @xmath20 .    for each source , the dictionary atoms are learnt such that the cosine similarity between the atoms is below a set threshold , chosen based on the desired performance .",
    "a randomly selected feature vector , denoted as @xmath21 , is taken as the first atom for the first source , @xmath22 .",
    "the rest of the atoms are learnt by random selection of the feature vectors ( excluding features already selected as atoms ) : @xmath23 feature , @xmath24 , is selected as the @xmath25 atom , @xmath26 of dictionary @xmath27 if the maximum of intra - cs , @xmath28 ( similar to coherence in @xcite ) is less than a threshold @xmath29 .",
    "the selection of dictionary atoms is stopped once the number of dictionary atoms reaches a pre - decided number @xmath30 . in case",
    "@xmath30 atoms are not obtained , additional features , which do not satisfy the intra - class threshold @xmath31 , are appended in the order of increasing @xmath32 .",
    "to learn dictionaries for subsequent sources , atoms are learnt using an additional constraint : @xmath24 is selected as the @xmath25 atom @xmath33 for the @xmath34 dictionary @xmath19 , if @xmath35 @xmath36 is less than a threshold @xmath37 .",
    "the threshold @xmath29 ensures that atoms within the same source dictionary are as uncorrelated as possible , while @xmath38 ensures that atoms from different source dictionaries are maximally uncorrelated .",
    "lower the values of the thresholds @xmath29 and @xmath38 , greater is the uncorrelatedness between the dictionary atoms .",
    "the tdcs algorithm is summarized in algorithm [ dictalgo ] . for the sake of simplicity",
    ", the algorithm does not show the appending of additional dictionary atoms when @xmath30 atoms could not be obtained .",
    "dictionary learning using tdcs[dictalgo ]    * initialize : * dictionary index @xmath39 ; @xmath40 ; atom index @xmath41 ; set @xmath29 and @xmath38 .    extract @xmath42 number of features denoted as @xmath43 from the @xmath44 source .",
    "if @xmath45 , find the maximum of intra - cs , @xmath46 as :    @xmath47    if @xmath48 , find the maximum of inter - cs , @xmath49 as :    @xmath50 assign randomly selected @xmath51 as the @xmath25 atom : @xmath52 and append to the dictionary : @xmath53 $ ] @xmath54    @xmath55 ; @xmath56    the following five dictionary learning methods have been used in this paper :    1 .",
    "_ random selection of features _ : features randomly picked up from the training set using a uniform distribution are assigned as the dictionary atoms . 2 .",
    "_ k - means clustering _ :",
    "k - means clustering @xcite using euclidian distance measure , where @xmath57 is the number of atoms and normalized means are used as the dictionary atoms .",
    "_ k - medoid clustering _ :",
    "this is performed using the algorithm proposed by park et.al . @xcite and",
    "the @xmath2 medoids are used as the dictionary atoms .",
    "tdcs-0.9 _ : tdcs algorithm with the intra and inter - class thresholds as @xmath58 5 .   _",
    "tdcs-0.8 _ : tdcs algorithm with the intra and inter - class thresholds as @xmath59    figure [ csim ] shows the percentage distribution of number of dictionary atom combinations as a function of intra - cosine similarity and inter - cosine similarity .",
    "it is seen in fig .",
    "[ csim ] ( a , c ) that tdcs using a threshold of @xmath60 has higher number of atoms combinations with low cosine similarity .",
    "the test mixed audio signal , @xmath61 $ ] is simulated as a concatenation of two noisy speech signals , @xmath62 $ ] and @xmath63 $ ] .",
    "each @xmath64 $ ] is simulated as a linear combination of a speech , @xmath65 $ ] and a noise source , @xmath66 $ ] as    @xmath67=s_{sp}[n]+s_{ns}[n]\\ ] ]    both the speaker and noise sources for the two noisy speech signals are different and are constrained to belong to a specific set of speaker and noise sources .",
    "so , @xmath61 $ ] contains two different speakers and noise sources , each noise segment containing speech utterance by a single speaker .",
    "the first noise segment contains a male speaker and second noise segment contains a female speaker .",
    "the common occurrence of these type of test audio signals are telephonic conversations where the two speakers are in a different noise environment .",
    "figure [ spnsch ] shows the concatenated noise sources in ( a ) , concatenated clean speech utterances from two different speakers in ( b ) and the mixed audio signal as a linear combination of ( a ) and ( b ) at a snr of 0 db .",
    "the transition from babble noise to f16 noise and the boundaries of the speech segments are depicted in the figure .    given the mixed audio signal , we find the instant of transition from one noise to another and classify the noises . within each noise segment",
    ", we estimate the speaker source and separate the speech from noise .",
    "we also estimate the possible regions containing the speech segments .",
    "the approach and the algorithms used for the same are described in the following subsections .          frames of 60 ms duration are extracted with a shift of 15 ms from the training set of speaker and noise sources .",
    "features are extracted as the magnitude of the short - time fourier transform of these frames using a hanning window",
    ". for dictionary learning , features having very low relative energy compared to the average energy of the features are removed .",
    "it is to be noted that all the features and dictionary atoms are non - negative as we require a non - negative representation during classification and separation stage .",
    "dictionaries for all the sources are learnt separately by the five dictionary learning methods as given in sec .",
    "[ dictlearn ] using @xmath68 number of atoms .",
    "features for each speaker and noise source are extracted separately and the corresponding dictionaries are built .",
    "the dictionaries for @xmath69 speaker and @xmath70 noise sources are denoted as @xmath71 and @xmath72 , respectively .      in a test audio signal ,",
    "the class of noise source is constant across various frames over a significant span of time as the noise class may not change unless the speaker is traveling .",
    "so , we follow a top down approach of classifying and segmenting a test utterance . for practical purposes , accumulated classification",
    "is more realistic than frame - wise classification .",
    "initially , a frame - wise assignment of noise classes is done , then assuming a constant noise source across the whole test signal , and then recursively dividing the test utterance into multiple segments , segment level classification is performed .",
    "it is assumed that at least 2 seconds of signal will have the same noise .",
    "the frame - wise class label is assigned based on sum of cosine similarity for each dictionary using a block sparsity @xcite based approach @xcite .",
    "the steps for noise classification using this approach is enumerated in algorithm [ recuralgo ] . a divide and conquer approach",
    "is proposed by recursively dividing the frames into two equal parts until 90% of the component frames are classified as same class or the number of component frames corresponds to less than 2 seconds .",
    "all the segments are then assigned to two classes based on a rule based approach . in the case where 90% of frames are not classified as same class ,",
    "ten lowest energy frames within the segment are used to classify the segment .",
    "the reasoning behind using ten lowest energy frames is that in case the noise segment contains speech , the silence frames of speech ( which have low energy ) can be used for noise classification @xcite .",
    "the exact transition instant is arrived at by refining the approximate transition frame .",
    "although the algorithm assumes that the signal consists of two consecutive noise segments , it can be generalized to the segmentation of a signal containing multiple noises and transitions .",
    "the estimated noise classes are @xmath73 and the estimated transition frame is @xmath74 .    noise segmentation and classification[recuralgo ]    given @xmath70 number of noise source dictionaries , initialize the estimated class labels as @xmath75 $ ] .",
    "find the frame - wise energy as @xmath76 for @xmath77 , for @xmath78 number of features .",
    "find the frame - wise sum of cosine - similarity of each feature @xmath79 for each dictionary @xmath80 as @xmath81    sort the @xmath82 in decreasing order in each row so as to get the initial estimate of noise indices corresponding to the highest cosine similarity as @xmath83 .",
    "find the transition indices @xmath84 where change of estimated noise indices @xmath85 occurs assuming only two noise classes are present within the whole test signal , find two noise classes @xmath86 which have the maximum occurence in @xmath85 .",
    "find the centroid of the indices corresponding to the noise classes @xmath86 in @xmath85 as @xmath87 .",
    "find the absolute differences between the centroid of the present segment , @xmath88 and @xmath87 as @xmath89 .",
    "update the class labels of the present segment as the index @xmath90 or @xmath91 corresponding to minimum of @xmath89    * noise classification : * the estimated noise classes are @xmath86 , and initial estimate of transition frame is @xmath92 @xmath93 is refined using the initial frame labels @xmath83 * noise segmentation : * find the final transition frame within + /-1 second of @xmath93 around which there is equal distribution of @xmath94 within a 2 second duration as @xmath74 .",
    "the exact transition instant can be obtained from the mid - point of @xmath95 frame in time domain .",
    "select a subset of the indices as @xmath96    find the percentage occurrence of selected noise indices @xmath97 among all the noise classes as @xmath98 if the highest percentage occurrence to a particular noise class @xmath99 is greater than @xmath100 i.e. update the estimate of the class labels as @xmath101    sort the subset of frame energies @xmath102 and pick set of indices @xmath103 corresponding to the ten lowest energy frames @xcite find the noise index @xmath99 having the highest occurrence among @xmath104 update the estimate of the class labels as @xmath101    assign @xmath105      given the estimated noise sources , and the transition frame @xmath95 , the next task is to estimate the speaker corresponding to the utterance within each noise segment .",
    "the algorithm for speaker classification is explained in algorithm [ spkalgo ] .",
    "the test feature @xmath106 is approximated as the linear combination of the dictionary atoms from the estimated noise source , @xmath107 and the concatenated dictionary of speaker sources @xmath108 $ ] . since",
    "speech segment occurs for a short duration and consists of silence , unvoiced and voiced regions , we use only those features having higher energy ( 30% of the total number of features , @xmath106 ) for speaker classification .",
    "as speech is non - stationary and noise further corrupts it , the speaker index is determined by comparing the weights estimated in the representation :    @xmath109[\\mathbf{x}_1^t    ... \\mathbf{x}_{n_{sp}}^t \\mathbf{x}_{\\hat{m}_i}^t]^t=\\textbf{d}\\mathbf{x}\\ ] ]    the weight vector , @xmath13 is estimated by minimizing the distance @xmath110 using asna @xcite , where @xmath8 is the kl - divergence between @xmath106 and @xmath111 .",
    "@xmath112    @xmath6 is constrained to be non - negative and sparse by asna algorithm .",
    "a measure _ sum of weights ( sw ) _ for each of the selected features @xmath9 is defined as the absolute sum of elements of @xmath113 ,    @xmath114    the features used for speaker classification are further constrained by comparing the sum of weights corresponding to the noise dictionary @xmath115 and the average @xmath116 scaled by a factor , @xmath117 corresponding to speaker dictionaries for each of the selected features .",
    "the reasoning is that the frames having approximate @xmath118 below -12 db are neglected for speaker estimation .",
    "it is observed that we achieve an improvement of around 20% for male and 10% for female speaker classification accuracy using tdcs-0.8 dictionary method at 0 db snr by constraining the features used .",
    "figure [ percfr ] shows the number of features constrained expressed as a percentage of selected frames as a function of snr using different dictionary types for male and female speakers . it",
    "is observed that as snr increases more number of features are used and the percentage is nearly a linear function of snr from 0 to 20 db .",
    "so , lower number of features are desirable for speaker classification if the @xmath118 is low .",
    "also , it is seen that female speakers have higher percentage which means relative weights corresponding to speakers are higher for females .",
    "the speaker sources are estimated as the indices @xmath119 as given in steps 9 , 10 in algorithm [ spkalgo ] .",
    "speaker classification[spkalgo ]    given the estimated noise sources @xmath120 , divide the @xmath78 features into two sets @xmath121 and @xmath122 . for each set of @xmath123 $ ] , find the frame - wise energy as @xmath76 .",
    "pick 30% of features having highest energy , @xmath76 .",
    "find the weights recovered using asna algorithm as in equation [ nsw ] for each of the features picked up in the previous step .",
    "the sum of weights , @xmath116 corresponding to each dictionary index @xmath124 is found as in equation [ tsw ] .",
    "calculate the sum of weights corresponding to the noise dictionary as @xmath125 .",
    "find the set of frame indices , @xmath126 for which @xmath127 . in case number of elements of @xmath126",
    "is very low , corresponding to less than around 700 ms , increment @xmath128 until we get adequate @xmath126 .",
    "find the total sum of weights using frame indices @xmath126 as @xmath129 .",
    "estimate the speaker index as @xmath130 .          a novel algorithm to update speaker and noise dictionaries",
    "is proposed .",
    "it is a generalized algorithm which works with any dictionary learning algorithm . in the case of a test signal containing noise or speech only segments ,",
    "the corresponding features are used to update the estimated noise / speaker source dictionary . the intuition behind this method",
    "is that even though the dictionary for a particular source is not a good representation , it can be considered as the base dictionary which we update using the test signal itself .",
    "it is also useful when the test signal is of short duration or it varies with time .",
    "algorithm [ dictalgo ] illustrates the dictionary update algorithm in which a concatenation of the old dictionary and the test features @xmath131 $ ] is used to update the dictionary as @xmath132 .",
    "dictionary update[dictalgo ]    given an input dictionary @xmath133 and the test features @xmath134    update the dictionary @xmath133 as @xmath135)$ ] , where @xmath136 is any dictionary learning algorithm like @xmath137      the estimated noise indices @xmath138 and speaker indices @xmath139 are used to recover the noise and speaker components of the test features using a concatenated dictionary , @xmath140\\forall \\;i=1,2 $ ] and recovery algorithm asna similar to eqn .",
    "the test features are divided into @xmath141 corresponding to the first and second parts using the estimated transition frame index @xmath74 .",
    "the estimated features @xmath142 and the noise and speech component @xmath143 are    @xmath144[\\textbf{x}^t_{\\hat{m}_i } \\ ; \\textbf{x}^t_{\\hat{n}_i } ] ^t\\ ] ]    @xmath145    the speech component in the time domain @xmath65 $ ] is reconstructed using the estimated @xmath146 and phase of the mixed audio signal using overlap and add method as @xmath147 $ ] .",
    "the corresponding noise signal is estimated as @xmath148-\\hat{s}_{sp}[n]$ ] .",
    "the following measures are used to evaluate the performance of speech and noise separation :    * _ signal to distortion ratio _",
    "( sdr ) @xcite between the original and the estimated speech signal is defined as : + @xmath149||_2}{||s_{sp}[n]-\\hat{s}_{sp}[n]||_2}\\ ] ] + sdr quantifies the deviation of the separated speech signal from the original signal ; higher the sdr , better is the separation performance . * _ error in segmental snr _ : for segments in the mixed signal , where speech is present , estimated segmental snr is defined as the ratio of the total energy of the estimated speech to noise features in decibel , while the original segmental snr uses the original features extracted from the ground truth speech and noise signal : + @xmath150 + the error in the estimate of snr is given by @xmath151 .",
    "mean of the absolute value of the @xmath152 and the standard deviation of the @xmath152 are used as the measures to quantify the performance of the algorithm .",
    "it is to be noted that sdr and error in segmental snr are computed only for the regions/ frames , where speech is present .",
    "figure [ mrfar ] shows the plot of frame - wise energies for the original , estimated and mixed audio signal features and speech segments in the mixed audio signal , at the snr of 0 db .",
    "the speech features are estimated using dictionaries of randomly selected features of the estimated speaker and noise .",
    "it is seen from the figure that high energy frames contain speech , since voiced regions in the speech have high energy peaks . in case",
    "the noise has almost non - varying energy , local maxima are high in the speech segments .",
    "this distinguishes the maxima in the speech and noise frames using a k - means clustering algorithm to extract the significant maxima corresponding to the speech region .",
    "the algorithm used for extracting the speech segments is given in algorithm [ segalgo ] @xcite .",
    "two values of @xmath124 , namely @xmath153 and @xmath154 are used as the number of clusters .",
    "figure [ mrfar ] shows the local maxima and the clusters corresponding to the highest centroid as black squares and red stars .",
    "it can be seen that the cluster elements lie within the speech segments .",
    "it is to be noted that the clustering is carried out independently on the first and second parts partitioned at the estimated transition frame of 732 .",
    "detection of the speech segments[segalgo ]    extract local maxima of the frame energies .",
    "do k - means clustering of the local maxima using the initial centroids as equally distributed between the maximum and minimum of the local maxima .",
    "pick the elements of the cluster corresponding to the highest centroid value and assign them as @xmath155 which may correspond to the voiced segments of the speech .",
    "miss rate and false alarm rate @xcite are used as the measures for the detection of the speech segments :    * miss rate ( mr ) : percentage of number of speech segments , which do not encompass any element of @xmath155 with respect to the total number of speech segments .",
    "* false alarm rate ( far ) : percentage of number of @xmath155 which are outside the speech segments with respect to the total number of @xmath155 .",
    "this section describes the speaker and noise databases used and the training and test setup .      for noise sources ,",
    "all the 15 noises from the noisex database @xcite have been used .",
    "the first 20 seconds of each noise is used for testing and the rest for training . for speaker sources ,",
    "ten male and ten female speakers are randomly selected from dialect 5 of the training set of the timit database .",
    "the first eight utterances from each speaker are used for training ; the rest two are used for updating dictionary and testing .",
    "table [ dbase ] shows the list of noise sources and male/ female speakers used in this work .",
    "a mixed audio signal is simulated by concatenating two different noise sources such that the transition instant is between 9 and 11 seconds and the total duration is 20 seconds .",
    "a test utterance from a male speaker is added to the noise source in the first part , and from a female speaker to the second part at randomly selected locations at snr s of -10 , 0 , 10 and 20 db . the minimum separation between speech utterances",
    "is constrained to be 2 seconds .",
    "it is to be noted that our approach is independent of the gender of the speakers used in both parts of the test signal .",
    "male and female speakers used in first and second part is only to get results on both male and female speakers separately .",
    "two different noise sources are randomly chosen for the first and second part such that all the noise sources are used in each part .",
    "the speaker classes are selected such that all the ten combinations are different and all male / female speakers are used .",
    "so , @xmath156 combinations of mixed audio signal are used for testing at different snr s .    for testing our classification and separation performance using ground truth and updated dictionaries",
    ", we have four test cases using different combinations of dictionaries .    1 .",
    "_ complete speaker and noise dictionary : _ the test mixed audio signal is tested using all the noise and speaker dictionaries , and the separation is achieved using the identified noise/ speaker dictionary .",
    "2 .   _ ground truth speaker and noise dictionary : _ the ground truth speaker and noise dictionaries are used to evaluate the separation performance .",
    "3 .   _ out of set noise sources : _ the test mixed audio signal is tested using all the noise dictionaries except for the two dictionaries corresponding to the noise sources used in the test signal and all the speaker dictionaries .",
    "so , by pruning known noise dictionaries , the test signal is tested against out of set / unknown noise sources and known speakers .",
    "the results reported using this case show the robustness of our method given unknown test noises .",
    "_ out of set speaker sources : _ the two dictionaries corresponding to the speaker sources used in the test audio signal are removed from the training set for classification and separation .",
    "this case shows the robustness of our method given unknown test speakers .",
    "the out of set noise and speaker dictionaries used in the test cases @xmath157 give the estimated speaker and noise source indices .",
    "these dictionaries corresponding to the estimated source indices are updated using the dictionary update method in sec .",
    "[ dicupd ] . for noise dictionary update",
    ", it is assumed that the features corresponding to noise only region is known and the same is used to update the estimated noise dictionary . for speaker dictionary update , features from the utterance not in the training / test set is used to update the estimated speaker dictionary .",
    "results on speaker classification and separation performance are reported both before and after dictionary update using ( estimated ) out of set and updated dictionaries .",
    "the results for noise and speaker classification , detection of noise transition instant , sdr , error in snr , miss rate ( mr ) and false alarm rate ( far ) are reported in this section .",
    "the five dictionary learning methods used are ( 1 ) random selection , ( 2 ) k - means , ( 3 ) k - medoid , ( 4 ) tdcs-0.9 and ( 5 ) tdcs-0.8 .",
    "all the results given below are averages over all the combinations of speakers and noises for male and female speakers separately , unless otherwise mentioned .",
    "it is to be noted that although we report separate results for male and female speakers , the test audio signal is tested against all twenty speaker dictionaries ( both male and female ) for speaker classification stage .",
    "table [ nscl ] shows the overall noise classification accuracy at various @xmath158 in the presence of utterances from male and female speakers separately .",
    "random , k - means and tdcs-0.8 give the same accuracies for male and female speakers , so it is shown as a single value .",
    "all the noises are correctly classified except for machine gun noise which is mostly misclassified as volvo noise , which reduces the accuracy to 93.3% .",
    "k - medoid gives the best accuracy for female speakers , while tdcs-0.9 gives the best accuracy for male speakers . in the case of tdcs-0.8 , factory1 is also misclassified as pink noise , which reduces the accuracy to 86.67%",
    ".    table [ sca ] shows the overall speaker classification accuracy using the complete noise and speaker dictionaries , out of set noise dictionaries , updated noise dictionaries , and when the right speaker is within the top three speakers ( based on @xmath159 in algorithm [ spkalgo ] ) at various snr s using the five dictionary learning methods .",
    "it is seen that top three using complete gives the best accuracy across all the cases .",
    "so , it helps in narrowing down to top three speakers , and other approaches can be used to classify the speaker among the top three .",
    "it is seen that random selection and k - means give the best speaker classification accuracy at snr= -10 db while other methods do not degrade much , relatively .",
    "tdcs-0.8 gives the best accuracy at all snr s due to the variability of speech features requiring a low value threshold on cosine similarity measure , except for snr= -10 db . at an snr of 20 db ,",
    "tdcs-0.9 gives low accuracy for female speakers while lowering the threshold @xmath160 to 0.8 increases the accuracy to around 90% .",
    "unknown noise using out of set noise dictionaries gives lowest accuracies while using an updated dictionary gives similar accuracies as the complete dictionaries .",
    "it is seen that male speakers have accuracy higher than female speakers , and we get 100% for male speakers at snr= 20 db .",
    "this may be due to the low pitch frequency of male speakers with the harmonics concentrated in the low frequency regions , which may not be corrupted with noise .",
    "noise classification accuracy is better at a threshold of 0.9 while speaker classification is better at 0.8 .",
    "thus , selection of appropriate threshold is necessary .",
    "table [ err ] shows the mean absolute and standard deviation of error ( in seconds ) in the detection of noise transition instant for various snr s .",
    "it is seen than tdcs-0.9 gives the lowest mean absolute and standard deviation of error of 0.16 seconds at snr= -10 db , while there is a slight increase of error with increase in snr .",
    "figure [ sdrpl ] shows the variation of sdr in db using the five dictionary methods evaluated on complete dictionaries ( complete ) , ground truth dictionaries ( ground ) , out of set noise ( os noise ) , out of set speaker dictionaries ( os speaker ) , updated noise ( upd . noise ) and updated speaker dictionary ( upd .",
    "speaker ) .",
    "it is seen that using ground givesthe best sdr while using os noise dictionaries gives the lowest sdr .",
    "noise dictionary gives sdr comparable to complete test cases .",
    "using os speaker results in the lowest sdr at a snr of 20 db due to high speech energy .",
    "it is observed that using os speaker does not degrade sdr much as compared to complete at other snr s .",
    "average improvements of sdr over snr of -10 , 0 , 10 and 20 db are 11 , 9 , 6 and 3 db , neglecting the worst case using os noise .",
    "the variation of sdr is not much across the different dictionary methods .",
    "figure [ errsnrmn ] shows the variation of mean absolute error ( mae ) while fig .",
    "[ errsnrstd ] shows the standard deviation of error ( std ) for different dictionary learning methods and test cases similar to fig .",
    "[ sdrpl ] .",
    "it is seen that for male speakers , mae and std for updated noise and updated speaker dictionary cases outperform other cases at all snr s for male speakers .",
    "os noise results in the worst performance over all test cases giving an mae of around 15 db at -10 db . also , we get mae and std of around 2 db as the best over all the test cases .        .",
    "]    . ]",
    "table [ mr ] shows the miss rate ( mr ) while table [ far ] shows the false alarm rate ( far ) in percentage for the five dictionary methods and four test cases for the choices of number of clusters @xmath161 and @xmath154 .",
    "it is observed complete and ground truth dictionaries achieve poor performance at snr of -10 db even though these test cases give better results on other measures .",
    "it may be due to the few high noise energy segments at low snr s . at high snr s",
    ", it is seen that mr is almost negligible and zero for 10 , 20 db snr except for os noise test case .",
    "it is seen that high far is obtained at -10 db snr due to the high variability in the energy of some of the noises like machine gun .",
    "using @xmath162 improves the far by 10 - 20 % while it degrades mr by around 2- 15% .",
    "far is zero at high snr s while it is less than about 10% at 0 db snr .",
    "far is the highest for os noise test case at a snr of -10 db .",
    "the results presented are not directly comparable to other methods in the literature since the test cases simulated in this paper are unique and novel .",
    "a few of the results are compared indirectly here .",
    "@xcite reported a speaker classification accuracy of 98.9 % for eight speakers with clean speech , while we achieve 100% accuracy for male speakers and 88% for female speakers using tdcs-0.8 method at snr= 20 db snr . rose et .",
    "@xcite proposed speaker identification in noise using gausssian mixture models for 16 speakers and 10 seconds segments reporting a accuracy of 79.9 % at 10 db snr while we get average accuracy of 80% tested against 20 speakers at 10 db in the presence of babble noise . on white noise , @xcite reported 68.8% accuracy while we get 90% accuracy at 10 db snr .",
    "so , we achieve a comparably higher speaker classification accuracy even though we do not know the location of the speech segments . loizou @xcite performed speech enhancement and reported an improvement in segmental snr in speech with speech - shaped noise of around 5 db at 0 db snr while we achieve a high sdr of around 10 db at 0 db snr , which is equivalent an to improvement of 10 db .",
    "mohammadiha et.al .",
    "@xcite did unsupervised speech enhancement based on bayesian formulation of nmf reported sdr of around 5.5 db at 0 db snr while we reported sdr of around 9 db using our methods in all test cases except for os noise case .",
    "a novel approach is proposed for the classification and separation of mixed audio signals commonly occurring in telephonic conversations . since mobile communication",
    "is prolific nowadays , our approach can be used for tracking of speaker/ noise sources and noise adaptive speech enhancement using sparse representation based methods .",
    "we have shown how updation of dictionaries using parts of the test signal itself improves the classification and separation performance . as a future work",
    ", we plan to use machine learning techniques to learn discriminative dictionaries so as to classify multiple classes of noise and speech signals , and mixed audio signals .",
    "using discriminative dictionaries may classify the various components in a mixed signal like language , speaker , gender , music and noises in a more generic way .",
    "s. chu , s. narayanan , c. c. jay kuo , and m. j. matari ,  where am i ?",
    "scene recognition for mobile robots using audio features , \" _ in ieee international conference on multimedia and expo _ , pp .",
    "885 - 888 , 2006 .",
    "t. virtanen , j. f. gemmeke , b. raj ,  active - set newton algorithm for overcomplete non - negative representations of audio \" , _ ieee trans .",
    "audio , speech , and lang .",
    "2277 - 2289 , 2013 .",
    "d. barchiesi , d. giannoulis , d. stowell , m. d. plumbley and p. mermelstein , `` acoustic scene classification : classifying environments from the sounds they produce , '' _ ieee signal processing magazine _ , vol .",
    "32 , no .  3 , pp .",
    "1634 , 2015 .",
    "d. giannoulis , e. benetos , d. stowell , m. rossignol , m. lagrange and m. d. plumbley ,  detection and classification of acoustic scenes and events : an ieee aasp challenge , \" _ ieee workshop applications of signal processing to audio and acoustics _ , oct .",
    "2013 .",
    "a. shirkhodaie , and a. alkilani ,  a survey on acoustic signature recognition and classification techniques for persistent surveillance systems , \" _ proc .",
    "signal processing , sensor fusion , and target recognition _ , may 2012 .",
    "m. casey ,  reduced - rank spectra and minimum - entropy priors as consistent and reliable cues for generalized sound recognition , \" _ proc .",
    "workshop on consistent and reliable acoustic cues for sound analysis , eurospeech _ , aalborg , denmark , 2001 .",
    "r. g. malkin ,  machine listening for context - aware computing , \" _ doctoral dissertation , carnegie mellon university _ , 2006 t. virtanen ,  monaural sound source separation by non - negative matrix factorization with temporal continuity and sparseness criteria , \" _ ieee trans .",
    "audio , speech , and lang .",
    "_ , vol.15 , no.3 , 2007 .",
    "g. j. mysore , p. smaragdis , and b. raj ,  non - negative hidden markov modeling of audio with application to source separation , \" _ lecture notes in computer science , latent variable analysis and signal separation _ ,",
    "7572 , pp .",
    "186 - 199 , 2012 .",
    "n. bertin , r. badeau , and e. vincent ,  enforcing harmonicity and smoothness in bayesian non - negative matrix factorization applied to polyphonic music transcription , \" _ ieee trans .",
    "audio , speech , and lang .",
    "18 , no . 3 , 2010 .",
    "j. gemmeke , t. virtanen , and a. hurmalainen ,  exemplar - based sparse representations for noise robust automatic speech recognition , \" _ ieee trans .",
    "audio , speech , and lang .",
    "19 , no . 7 , 2011 .",
    "y. c. cho and s. choi ,  nonnegative features of spectro - temporal sounds for classication , \" _ pattern recognition letters _",
    "( 9 ) , 2005 .",
    "s. zubair , f. yan , w. wang  dictionary learning based sparse coefficients for audio classification with max and average pooling , \" _ elsevier digital signal processing _ , vol .",
    "23 , issue . 3 , 2013 .",
    "j. nikunen and t. virtanen ,  object - based audio coding using non - negative matrix factorization for the spectrogram representation , \" _ proceedings of the 128th audio engineering society convention _ , london , uk , 2010 . m. d. plumbley , t. blumensath , l. daudet , r. gribonval , and m. e. davies ,  sparse representations in audio and music : from coding to source separation , \" _ proceedings of the ieee , _ vol . 98 ( 6 ) , pp .",
    "995 - 1005 , 2009 .",
    "k. engan , s. o. aase , and j. h. husoy ,  multi - frame compression : theory and design , \" _ eurasip sig .",
    "80 , no . 10 , pp .",
    "2121 - 2140 , 2000 .",
    "y. pati , r. rezaiifar , and p. krishnaprasad ,  orthogonal matching pursuit : recursive function approximation with applications to wavelet decomposition , \" _ proceedings of asilomar conference on signals , systems and computers _",
    ", 1993 .",
    "m. g. jafari , m. d. plumbley ,  fast dictionary learning for sparse representations of speech signals , \" _ ieee journal .",
    "selected topics sig . process .",
    "_ , vol . 5 , pp.1025 - 1031 , 2011 . s. kong , and d. wang ,  a dictionary learning approach for classification : separating the particularity and the commonality , \" _ lecture notes in computer science , computer vision _ , vol",
    "7572 , pp .",
    "186 - 199 , 2012 .",
    "s. shafiee , f. kamangar andv .",
    "athitsos , and j. huang ,  the role of dictionary learning on sparse representation - based classification , \" _ proc .",
    "pervasive technologies related to assistive environments _ , no .",
    "47 , 2013 .",
    "k v vijay girish , a g ramakrishnan and t v ananthapadmanabha ,  hierarchical classification of speaker and background noise and estimation of snr using sparse representation , \" _ to be presented in interspeech , 2016 _",
    "r. c. rose , e. m. hofstetter and d. a. reynolds integrated models of signal and background with application to speaker identification in noise , \" _ ieee transactions on speech and audio processing _",
    "2 , pp . 245257 , 1994 .",
    "n mohammadiha , p. smaragdis and a. leijon ,  supervised and unsupervised speech enhancement using nonnegative matrix factorization , \" _ ieee transactions on audio , speech and language processing _",
    "21402151 , 2013 ."
  ],
  "abstract_text": [
    "<S> a judicious combination of dictionary learning methods , block sparsity and source recovery algorithm are used in a hierarchical manner to identify the noises and the speakers from a noisy conversation between two people . </S>",
    "<S> conversations are simulated using speech from two speakers , each with a different background noise , with varied snr values , down to -10 db . </S>",
    "<S> ten each of randomly chosen male and female speakers from the timit database and all the noise sources from the noisex database are used for the simulations . for speaker identification , </S>",
    "<S> the relative value of weights recovered is used to select an appropriately small subset of the test data , assumed to contain speech . </S>",
    "<S> this novel choice of using varied amounts of test data results in an improvement in the speaker recognition rate of around 15% at snr of 0 db . </S>",
    "<S> speech and noise are separated using dictionaries of the estimated speaker and noise , and an improvement of signal to distortion ratios of up to 10% is achieved at snr of 0 db . </S>",
    "<S> k - medoid and cosine similarity based dictionary learning methods lead to better recognition of the background noise and the speaker . </S>",
    "<S> experiments are also conducted on cases , where either the background noise or the speaker is outside the set of trained dictionaries . in such cases , </S>",
    "<S> adaptive dictionary learning leads to performance comparable to the other case of complete dictionaries .    shell : bare demo of ieeetran.cls for ieee journals    dictionary , tdcs , sdr , segments , noise source , speaker , classication , asna , segmental snr , detection , speech segments </S>"
  ]
}