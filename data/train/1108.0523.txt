{
  "article_text": [
    "with the start of the large hadron collider ( lhc )  @xcite , we have entered an era in which speculation about new physics has given way to detailed experimental study .",
    "this has had the welcome consequence of focusing attention on a difficult practical question : given the plethora of models of potential new physics , many depending on multiple unknown parameters , what is the best practical way to navigate the landscape of possibilities ? this is a multi - faceted problem , of which undoubtedly the most challenging is devising reliable background estimates for all the final states that are being scrutinized .",
    "another challenge is the construction of very fast accurate simulations  @xcite of new physics models at hundreds of thousands , even millions , of parameter points .",
    "this is necessary because , in general , the effective cross section , @xmath0that is , the signal efficiency , @xmath1 , times cross section , @xmath2is a function of the parameters @xmath3 of the model under investigation .    in this paper , we shall assume that both of these difficult tasks have been accomplished .",
    "instead we address another important facet of the problem , namely , that of extracting information about a given new physics model once lhc data become sufficiently abundant to test it .",
    "we propose a new method that is applicable to any multi - parameter model that yields a prediction about the expected signal count .",
    "we illustrate the method using three supersymmetric ( susy ) models  @xcite : the constrained minimal supersymmetric standard model ( cmssm )  @xcite and two non - universal variants of it .",
    "the availability of increasingly powerful computers has made it possible to study multi - parameter models in a holistic manner .",
    "indeed , it has become routine to use techniques such as markov chain monte carlo ( mcmc )  @xcite to explore the multi - dimensional parameter spaces of models such as susy  @xcite .",
    "this is another welcome development .",
    "recent work on susy models  @xcite has shown that a holistic approach can yield qualitatively different conclusions from those arrived at using the traditional approach based on benchmarks  @xcite .",
    "susy models have been studied using both frequentist  @xcite and bayesian  @xcite methods .",
    "the frequentist studies typically construct confidence regions and obtain the best - fit point .",
    "sometimes , information about individual parameters or pairs of parameters is obtained by projecting the likelihood function onto the parameters of interest .",
    "this procedure is actually a frequentist / bayesian hybrid , which amounts to using a flat prior on the parameters .",
    "a conceptually more consistent , albeit approximate , frequentist approach is to construct a profile likelihood  @xcite for the parameter of interest .",
    "for example , if the parameter of interest is @xmath4 and @xmath5 is the likelihood function for observations @xmath6 , where @xmath7 denotes the remaining parameters , the profile likelihood for @xmath4 is @xmath8 , where @xmath9 is the best fit value of the parameters @xmath7 for a given value of @xmath4 . the profile likelihood @xmath10 is then used as if it were a true likelihood .",
    "we propose to use the bayesian approach  @xcite because of its strong theoretical foundations , its generality and the fact that it is conceptually straightforward : given a prior @xmath11 defined on the parameter space @xmath12 of the model , where in general @xmath3 is multi - dimensional , and a likelihood @xmath13 , one computes the posterior density @xmath14 from which a myriad of details can be extracted such as point estimates or credible regions .",
    "it is also possible to make predictions about which data would be most useful to take next , and one can rank models according to their concordance with observations .",
    "moreover , all manner of uncertainties , irrespective of their provenance and how we choose to label them  statistical , systematic , theoretical , best guess , etc.can be accounted for in a conceptually coherent and unified manner .",
    "every fully bayesian analysis , however , must contend with the problem of constructing a prior @xmath11 on the parameter space of the model under investigation .",
    "this task is especially difficult in circumstances in which intuition provides little guidance as is invariably the case for multi - parameter models .",
    "current studies , which place flat or logarithmic priors on the parameters of new physics models , are sensitive to the choice of prior  @xcite ; therefore , the choice of prior is a critical issue that must be squarely faced .",
    "this is the main purpose of this paper .",
    "the current sensitivity of results to the prior is sometimes construed as an intrinsic difficulty with the bayesian approach .",
    "in fact , the correct conclusion to be drawn is that it is not yet possible to place robust constraints on all the parameters of a typical multi - parameter model of new physics , a conclusion that is independent of the method used to extract information about the model be it frequentist or bayesian .",
    "the difficulty is not that results are sensitive to the prior  this fact tells us something obvious and important : we need more data and better analyses .",
    "rather the difficulty is that flat priors on multi - dimensional parameter spaces can lead to pathological results , which may not be apparent without a careful study .",
    "flat priors have been used successfully , witness the recent discovery of single top quark production by d  @xcite and cdf  @xcite .",
    "but these results were obtained with a flat prior applied to a _",
    "single _ carefully chosen parameter , namely , the cross section  @xcite .",
    "given that our multi - dimensional intuition may be unreliable , we are faced with a choice : either abandon the bayesian approach  and , in our view , abandon an extremely powerful set of ideas  or , as we propose , put intuition aside and use a formal procedure with mathematically verifiable properties to place priors on the parameter spaces .",
    "we propose a solution inspired by a set of bayesian methods called _ reference analysis _",
    "@xcite , whose key construct is the _ reference prior_.    we advocate the use of reference priors because they lead to inferences with useful properties , including invariance under one - to - one transformations of the parameters and excellent frequentist coverage .",
    "the latter property means that the ( bayesian ) credible regions are also approximate ( frequentist ) confidence regions .",
    "moreover , the reference prior can be perturbed in a controlled way to check the robustness of conclusions .",
    "having initiated the inference chain with a reference prior , we can use bayesian methods to    * quantify the statistical significance of a signal , * rank models according to their concordance with observations , * estimate model parameters , and * design an optimal analysis for a given model and a given integrated luminosity .    in this paper , in addition to the main task of constructing multi - parameter priors , we address the first two points  the statistical significance of a signal and model ranking  and we defer consideration of the last two to a future publication .",
    "bayesian reference analysis  @xcite provides a principled way to approach the problem of multi - parameter priors .",
    "however , while the solution it proposes is computationally feasible for one - parameter problems , it rapidly becomes computationally prohibitive for multi - parameter problems using current algorithms .",
    "since the 1-parameter problem is a well - understood , solved , problem , our proposed solution begins with the solution of a 1-parameter problem and proceeds to the multi - parameter problem by imposing two requirements on the multi - parameter prior : consistency and equiprobability , both of which are described in detail below .",
    "our solution proceeds in four steps :    1 .",
    "first , we compute the marginal likelihood by integrating the likelihood function with respect to an evidence - based prior over all parameters except the parameter of interest ; 2 .",
    "next , we compute the reference prior associated with the marginal likelihood ; 3 .",
    "then , we compute the reference posterior density for the parameter of interest , 4 .   and ,",
    "finally , we map the reference posterior density to a posterior density on the parameter space of each multi - parameter model under study .",
    "clearly , these steps can be applied to any experiment that has a single parameter of interest . in this paper",
    ", we apply the steps to a single count experiment because it yields the simplest possible analysis and the key calculations can be done exactly . in the following sections , we describe the single count model , its reference prior , and our method for mapping the signal posterior density to the parameter space of a given multi - parameter model .",
    "the paper is organized as follows . in sec .",
    "[ sec : singlecountmodel ] , we give a detailed description of the single count model and its associated reference prior .",
    "our construction of multi - parameter priors is described in sec .",
    "[ sec : method ] . in sec .",
    "[ sec : examples ] we illustrate the method using three susy models , a 2-parameter cmssm and two 5-parameter non - universal generalizations .",
    "we end with a summary and concluding remarks .",
    "in the context of the lhc , the single count model describes the results of a  cut and count \" analysis in which @xmath15 proton - proton collision events are found to pass a given set of selection criteria , that is , cuts .",
    "the expected number of events , @xmath16 , is given by @xmath17 where @xmath18 is the expected number of standard model background events and @xmath19assumed to be purely additive  is the expected number of signal events due to ( unknown ) new physics .",
    "the observed count is denoted by @xmath15 and the expected ( that is , mean ) count is denoted by @xmath16 .",
    "we shall use upper case letters for observed values and lower case letters for expected values .",
    "the result of _ any _ experiment can be encoded in its likelihood function , the probability density function ( pdf ) of the observations ( sometimes called the probability mass function if the data are discrete ) evaluated at the actual observations . from the likelihood function and the prior density for the expected signal and background we can compute the posterior probability @xmath20 of the signal , that is , the probability that the expected signal lies in the interval @xmath21 , given the observed count @xmath15 .    we choose to parametrize the likelihood in terms of the expected signal @xmath22 rather than the cross section @xmath23 , as is done in ref .",
    "@xcite , so that the results of the counting experiment remain independent of the new physics model .",
    "the cuts may have been motivated by a specific model of new physics , however , the signal posterior density can be interpreted using _ any _ physics model that makes predictions for the expected signal in the final states considered . moreover , as we shall see , we can devise a purely bayesian measure of the degree to which the observation of @xmath15 events favors the hypothesis @xmath24 rather than the background - only hypothesis @xmath25 , independently of any presumed model of new physics .",
    "moreover , this can be readily generalized to a multi - count analysis .    for a counting experiment that yields @xmath15 events",
    ", we make the usual assumption that the likelihood function is given by a poisson distribution , @xmath26 with mean @xmath27 .",
    "the associated 2-parameter prior , @xmath28 , can be factorized in two ways , @xmath29 both of which were considered in ref .",
    "@xcite . here , we consider method 2 only .",
    "we do so because we can reduce the likelihood function @xmath30 to a function of the single parameter @xmath22 through marginalization , @xmath31 which permits the application of the 1-parameter reference prior algorithm  @xcite to compute the reference prior for the expected signal , while avoiding the technical issue of nested compact sets  @xcite .    following ref .",
    "@xcite , we model the evidence - based prior @xmath32 for the expected background by a gamma density , @xmath33 where @xmath34 and @xmath35 are known constants .",
    "we further assume that the prior is independent of the expected signal , @xmath22 .",
    "( see appendix  [ app : backgroundprior ] for its derivation . )",
    "then , we integrate over @xmath18 to arrive at the 1-parameter marginal likelihood , @xmath36              & \\;=\\;\\int \\frac{(\\mu + s)^{n}}{n!}\\ ;                    e^{-\\mu - s}\\ ;                    \\frac{b(b\\mu)^{y-1/2}}{\\gamma(y+1/2)}\\ ;                    e^{-b\\mu}\\;d\\mu,\\nonumber\\\\[2 mm ]              & \\;=                    \\left[\\frac{b}{b+1}\\right]^{y+\\frac{1}{2}}\\ ;                    \\sum_{k=0}^{n}v_{nk}\\ , \\textrm{poisson}(k|s),\\nonumber\\\\[2 mm ] \\mbox{where}\\quad   v_{ik } & \\;\\equiv\\;\\frac{\\gamma(y+\\frac{1}{2}+i - k)}{\\gamma(y+\\frac{1}{2 } ) \\ ; ( i - k)!}\\ ;               \\left[\\frac{1}{b+1}\\right]^{i - k } , \\label{eq : marginalmodel}\\end{aligned}\\ ] ] for the expected signal , @xmath22 , whose reference prior , @xmath37 , is calculated in the next section .      when we know almost nothing about a potential signal it seems prudent to use a prior for the expected signal that is as noncommittal as possible .",
    "the approach in high energy physics has been to use a flat prior  @xcite for a parameter about which little is known , or for which one wishes to act as if that is the case .",
    "but , for multi - parameter models , our intuition is ill - equipped to choose the parameterization in terms of which the prior is flat .",
    "we therefore propose a different approach .",
    "our idea is to construct a prior for each new physics model starting with the reference prior for an experiment with a single parameter of interest  here the expected signal , @xmath22 , for a single count experiment . by construction ,",
    "a reference prior  @xcite , on average and given unlimited data , maximizes the influence of the data relative to the prior .",
    "the intuition that underlies the construction of such priors is that the influence of the observations will be greatest if the  separation \" between the posterior density and the prior is as large as possible .",
    "reference analysis  @xcite quantifies the separation between the two densities @xmath38 and @xmath37 using the kullback - leibler ( kl ) , divergence , which for the particular problem we address is given by @xmath39 \\equiv \\int \\ ,   p(s | n)\\;\\ln\\frac{p(s| n)}{\\pi(s ) } \\ , ds .",
    "\\label{eq : kl}\\ ] ] this non - negative quantity , which is invariant under one - to - one transformations of @xmath22 and zero if and only if the densities @xmath38 and @xmath37 are identical , may also be interpreted as a measure of the information gained from the ( single count ) experiment .",
    "since we wish to maximize the influence of the observations , we might be tempted to maximize eq .",
    "( [ eq : kl ] ) with respect to the prior , @xmath37 .",
    "this , however , would be unsatisfactory because the prior would then depend on the specific observations , which would enter the posterior density twice : once in the prior and once in the likelihood .",
    "it is more satisfactory to use the average of @xmath40 $ ] over all possible observations .",
    "integration over the space of observations ",
    "standard practice in the frequentist approach  may seem a decidedly un - bayesian thing to do .",
    "however , the likelihood principle  @xcite , the idea that inferences should be based on the observed data only , makes sense only if we actually have observations . obviously",
    ", before we perform the analysis , we do not know the value of the count @xmath15 ; therefore , since the count is unknown we should average over all possible realizations of @xmath15 .",
    "once we know the count , our inferences should be based on @xmath15 only . for completeness ,",
    "we give the key details of the reference prior algorithm in the appendix  [ app : refprior ] .",
    "the calculation of reference priors simplifies considerably for posterior densities that are asymptotically normal , that is , that become gaussian as more and more data are included . in this case , the reference prior coincides with the jeffreys prior  @xcite , @xmath41 } , \\label{eq : jeffreysprior}\\ ] ] where for the single count model the expectation is with respect to the ( marginal ) likelihood @xmath42 , given in eq .",
    "( [ eq : marginalmodel ] ) . for a counting experiment , the asymptotic form of the posterior density",
    "@xmath38 is indeed gaussian .",
    "therefore , the reference prior for @xmath42 can be computed using eq .",
    "( [ eq : jeffreysprior ] ) . adapting the results of ref .",
    "@xcite , we find , @xmath43^{2}}{t_{i}^{0}(s)}},\\nonumber\\\\[2 mm ] \\mbox{where}\\quad t_{i}^{m}(s ) & \\;\\equiv\\;\\sum_{k=0}^{i } k^{m}\\;v_{ik}\\ ; \\textrm{poisson}(k|s)\\quad\\textrm{for}\\quad m=0,1,\\end{aligned}\\ ] ] and @xmath44 are the coefficients defined in eq .",
    "( [ eq : marginalmodel ] ) . the complete reference prior , @xmath28 , is the product of eqs .",
    "( [ eq : mu ] ) and ( [ eq : pir2p ] ) , while the complete reference posterior density is @xmath45 the reference posterior density for the expected signal is obtained by integrating over @xmath18 , @xmath46 where @xmath42 and @xmath37 are given by eqs .",
    "( [ eq : marginalmodel ] ) and ( [ eq : pir2p ] ) , respectively .",
    "( see appendix  [ app : likelihood ] for more technical details . )      assessing the statistical significance of a signal is a standard analysis task in high energy physics  @xcite , one which traditionally has been done with a @xmath47-value  @xcite .",
    "here we propose an alternative measure that uses the reference posterior density @xmath48 .",
    "suppose we are given some function @xmath49 that measures the separation between the ( composite ) background plus signal hypothesis , @xmath50 , and the ( composite ) background - only hypothesis , @xmath51 .",
    "if the separation between the hypotheses were large enough then presumably we would reject the background - only hypothesis in favor of the alternative .",
    "but , since we know neither the expected background @xmath18 nor the expected signal @xmath22 , the natural bayesian thing to do is to average @xmath49 with respect to all possible hypotheses about the values of @xmath18 and @xmath22 , @xmath52 & = &   \\int_0^{\\infty } ds \\int_0^{\\infty }   d\\mu \\ , \\delta(\\mu , s ) \\ ; p(\\mu , s | n ) , \\nonumber \\\\      & = & \\int_0^{\\infty } ds \\int_0^{\\infty }   d\\mu \\ , \\delta(\\mu , s ) \\ ; p(n| \\mu , s ) \\ ; \\pi(\\mu , s ) / p(n ) , \\label{eq : dn}\\end{aligned}\\ ] ] where @xmath53 is the normalization constant @xmath54 .",
    "if @xmath49 is interpreted as a loss function then @xmath55 is a measure of the loss incurred , on average , if one were to stubbornly adhere to the background - only hypothesis regardless of the outcome of the experiment .",
    "a signal is declared to be statistically significant if @xmath56 , where @xmath57 is some agreed - upon threshold . moreover ,",
    "the decision to accept or reject @xmath58 and thereby reject or accept the alternative @xmath59 may be taken independently of any model of new physics .",
    "there are many possible choices for the function @xmath49 .",
    "we propose to use the kullback - leibler divergence  @xcite , @xmath60 between the densities @xmath61 and @xmath62 associated with hypotheses @xmath59 and @xmath58 , respectively . for fully specified models , eq .",
    "( [ eq : loss ] ) is simply the expected log - likelihood ratio .",
    "we can gain some insight into @xmath49 by considering a counting experiment for which @xmath63 , which characterizes early searches for new physics . in this limit   and @xmath58 are nearly degenerate ",
    "the kl divergence can be interpreted as twice the square of the distance between the associated densities in the space of functions  @xcite .",
    "] , @xmath64                              \\approx \\frac{1}{2 } \\frac{s^2}{\\mu},\\ ] ] that is , @xmath65",
    ". this suggests taking the quantity , @xmath66 as a bayesian analog of the well - known ( and oft - abused ) measure of  signal significance , \" @xmath67 . as such",
    ", it is an analog of an ",
    "n - sigma , \" that is , the standard re - scaling of a @xmath47-value using the single tail area of a normal density  @xcite .",
    "approximate _ correspondence provides a simple calibration of @xmath55 .      for an experiment that yields @xmath68 independent counts , @xmath69 , @xmath70 , with expected background and signal counts @xmath71 and @xmath72 , respectively ,",
    "the kl divergence is simply the sum @xmath73 over terms @xmath74 , each of which is given by eq .",
    "( [ eq : loss ] ) , while the signal significance measure generalizes to @xmath75 \\nonumber \\\\              & =   & \\int_0^{\\infty } ds_1 \\int_0^{\\infty }   d\\mu_1 \\cdots   \\int_0^{\\infty } ds_k \\int_0^{\\infty } d\\mu_k \\ , \\delta(\\mu_1 , s_1 , \\cdots ) \\ ; \\nonumber \\\\              & \\times & p(\\mu_1 , s_1 , \\cdots | n_1 , \\cdots ) , \\nonumber \\\\ \\nonumber \\\\ & =   & \\sum_{k=1}^k \\int_0^{\\infty } ds_1 \\int_0^{\\infty }   d\\mu_1 \\cdots   \\int_0^{\\infty } ds_k \\int_0^{\\infty } d\\mu_k \\ , \\delta(\\mu_k , s_k ) \\ ; \\nonumber \\\\              & \\times & p(n_1| \\mu_1 , s_1 ) \\ ; \\pi(\\mu_1 , s_1 ) / p(n_1 ) \\cdots               p(n_k| \\mu_k , s_k ) \\ ; \\pi(\\mu_k , s_k ) / p(n_k ) , \\nonumber \\\\              & = & \\sum_{k=1}^k d(n_k ) , \\label{eq : dn1nk}\\end{aligned}\\ ] ] where we have used the fact that the posterior density @xmath76 factorizes into a product of @xmath68 terms , one for each count @xmath69 , each of which integrates to one .",
    "we have a well - defined reference posterior density for the signal , @xmath77 , which satisfies @xmath78 our task now is to map it to a density @xmath79 on the parameter space @xmath12 of a given physics model .    by assumption , the model predicts the expected signal @xmath22 via a predictor function @xmath80 .",
    "consequently , the reference posterior density @xmath77 induces , or is consistent with , posterior densities on @xmath12 that satisfy  @xcite @xmath81 \\ , p(\\theta ) \\ , d\\theta .",
    "\\label{eq : intmap}\\end{aligned}\\ ] ] equation  ( [ eq : intmap ] ) is the consistency requirement we alluded to .",
    "note , eqs .",
    "( [ eq : psnnorm ] ) and ( [ eq : intmap ] ) imply that @xmath82 .",
    "equation ( [ eq : intmap ] ) determines @xmath79 only to within a class .",
    "therefore , we need a plausible way to choose a specific function from that class that would serve as a suitable posterior density and hence a prior for subsequent analysis . to that end",
    ", we note that every point @xmath83 , where @xmath84 is the image of @xmath85 , is associated with the _ same _ expected signal @xmath86 . in that sense , the points in @xmath84 are indistinguishable ; that is , @xmath84 defines a set of `` look - alike '' ( ll ) models .",
    "we therefore propose that @xmath79 be chosen so that @xmath87 that is , that the density @xmath79 be constant over @xmath84 .",
    "this choice yields the following expression for @xmath79 , @xmath88 where , @xmath89 \\ , d\\theta , \\label{eq : area}\\ ] ] is the _ area _ of the hyper - surface defined by @xmath90 .",
    "this choice is arguably the simplest for @xmath79 given that the _ only _ information at hand is the reference posterior density for the signal . if , however , one has cogent information about how @xmath79 should vary on these hyper - surfaces , then our simple choice can be replaced with something consistent with this information and eq .",
    "( [ eq : intmap ] ) .",
    "there are two technical challenges in our proposed method .",
    "the first is that , in general , we do not have explicit functional forms for the mapping @xmath80 . in practice , in order to calculate the expected signal , we simulate a large number of signal events for a given parameter point @xmath3 , we apply cuts to these events and we determine what fraction of them survive the cuts ; that is , we calculate the signal efficiency @xmath1 .",
    "then , for a given integrated luminosity @xmath91 , we compute the expected signal using @xmath92 , where @xmath2 is the cross section .",
    "the second challenge is the calculation of the surface term , eq .",
    "( [ eq : area ] ) .",
    "we discuss both of these calculations in sect .",
    "[ sec : examples ] , in which we illustrate the practical application of our method .",
    "but first we briefly review the standard bayesian approach to model ranking .",
    "if nature is kind to us , we shall eventually start to see signals of new physics at the lhc .",
    "then , the most important tasks will be to characterize the observations experimentally and determine which candidate model best describes them .",
    "suppose we wish to rank @xmath93 candidate models of new physics according to their concordance with the observations . in general , each model will have its own set of parameters @xmath94 , perhaps differing in meaning and , or , dimensionality .",
    "the standard bayesian approach to model ranking is , as usual , direct : calculate the probability of each model @xmath95  @xcite given the observations .",
    "the model with the highest probability wins .    given the likelihood function @xmath96 and prior @xmath97 , we first compute the _ evidence _  @xcite , @xmath98 and then the probability of each model @xmath99 where @xmath100 is a discrete prior probability distribution over the space of models . the polemical aspect of eq .",
    "( [ eq : probm ] ) is the need to specify the values of @xmath100 , on which there seems little chance of agreement . if , however , the models are judged to be equally implausible  or if the lhc experiments were to reach an accord to that effect , it would be appropriate to set @xmath101 , in which case eq .",
    "( [ eq : probm ] ) reduces to @xmath102 absent such an accord , it is still possible to rank models using their evidences : the larger the evidence the more favored is the model .",
    "but , there is an important caveat : it is necessary to use proper priors for @xmath103 , that is , priors that integrate to one .",
    "an improper prior is defined only to within an arbitrary scale factor .",
    "consequently , were such a prior to be used to compute the evidence , the latter would be defined only to within the same arbitrary scale factor .",
    "therefore , in order for the evidences to be well - defined , the priors must be proper . by construction , this is the case for the multi - dimensional priors introduced above .",
    "models can also be ranked using bayesian reference analysis .",
    "however , we defer the discussion to a future publication .",
    "our proposed method for constructing multi - parameter priors is quite general .",
    "it can be applied , in principle , to any physics model of any dimensionality provided that the model makes a prediction for the parameter of interest , which in our case is the expected signal in a counting experiment . for simplicity ,",
    "however , we illustrate the application of the method using a susy model with only two free parameters for which the results are easily visualized .",
    "we then consider two 5-parameter models .",
    "the first model we consider is the sub - model of the cmssm  @xcite defined by the free parameters @xmath4 , @xmath104 , and the fixed parameters @xmath105 , @xmath106 and @xmath107 .",
    "we take the cms benchmark point lm1  @xcite , defined by the fixed parameters @xmath108 , @xmath109 , @xmath105 , @xmath106 and @xmath107 , as our _ true state of nature _",
    "( tsn ) , which provides the  observed \" count @xmath15  @xcite . for each point in a grid of points in the @xmath110 plane ,",
    "including the point lm1 , the susy spectrum is calculated using softsusy 3.1  @xcite and sparticle decays using susyhit  @xcite .",
    "we generate 1000 7 tev lhc events using pythia 6.4  @xcite and approximate the response of the cms detector  @xcite to these events using a modified version of the fast detector simulation program pgs  @xcite .",
    "we apply a cms multijets plus missing transverse energy ( @xmath111 ) event selection  @xcite to the events simulated at each point @xmath112 and we take the background estimates from the cms analysis in ref .  @xcite .",
    "three hypothetical results are considered : i ) @xmath113 events observed in @xmath114 pb@xmath115 of data ; ii ) @xmath116 events observed in 100 pb@xmath115 , and @xmath117 events observed in 500 pb@xmath115 . in each case , we compute the posterior density @xmath38 for the expected signal count at each point in the @xmath110 plane and map it to the posterior density @xmath118 , which we take as the prior @xmath119 .",
    "the value of the surface term in this case is simply the length of the curve @xmath120 .",
    "plane for 1 pb@xmath115 ( left ) , 100 pb@xmath115 ( center ) , and 500 pb@xmath115 ( right ) .",
    "the tsn is indicated by the black dot .",
    "[ fig : priorslm1],scaledwidth=100.0% ]    the plots in fig .",
    "[ fig : priorslm1 ] show the induced posterior density @xmath118 , and hence prior @xmath121 , for the three integrated luminosities .",
    "the plots show several nice features . for low statistics ,",
    "the prior is featureless in the region to which the experiment has no sensitivity , while the low mass region is disfavored . at moderate luminosity the prior peaks at the right value , favoring the correct model and , with the same probability , all its ll models . at large luminosity",
    "the prior converges to the correct ll sub - space @xmath84 , which , as noted , is a curve .",
    "the fact that the sub - space is not a single point shows that an infinite amount of data does not necessarily guarantee the irrelevance of the prior that initiated the chain of inference .",
    "this is why choosing the prior carefully is important .",
    "since the ll sub - space @xmath84 is extended , it remains sensitive to the initiating prior , which because of the manner in which we choose to map @xmath77 to @xmath118 is constant across the ll sub - space .",
    "the upshot of this is that we should expect the initiating prior to become irrelevant only if an analysis is able to break the model degenaracy so that with an infinite amount of data the ll sub - space collapses to a point or , more realistically , to a very small sub - space over which the variation of the initiating prior is negligible .",
    "the degeneracy between models with the same expected signal count  which we argue is a desirable property  is intrinsic to the approach we propose .",
    "however , having defined a prior over the parameter space of the model under study , we can move well beyond a simple counting experiment .",
    "susy models have the virtue of making numerous predictions that can be tested in a variety of ways . we argue that the interpretation of data at the lhc should be done in a manner that is consistent with all the tested predictions of the model under consideration . to do otherwise risks reaching scientifically untenable conclusions : for example , that a region of parameter space is still allowed when a more complete analysis might say quite the opposite . if we have access to results from different analyses , perhaps from different experiments , we argue that a consistent analysis should incorprate these results whenever possible .",
    "the ability to do this in a systematic manner is one of our motivations for addressing the problem of multi - parameter priors .    in order to break the model degeneracy",
    ", we can incorporate the likelihood associated with a set of additional observables @xmath122 and compute the posterior density @xmath123 using the prior @xmath119 computed from the single count analysis .",
    "an example is given in fig .",
    "[ fig : posteriorlm1 ] , where the function , @xmath124 is shown as a function of @xmath4 and @xmath104 .",
    "we consider the set of measured electroweak observables , @xmath125 , @xmath126 , @xmath127 , @xmath128 , @xmath129 , @xmath130 , @xmath131 and @xmath132 , for which the likelihood is @xmath133 where @xmath134 is the predicted value of the observable @xmath135 for the model ( @xmath4 , @xmath104 ) , which is computed for each observable above using superiso  @xcite and micromegas 2.4  @xcite and @xmath136 is the associated experimental measurement , in which the central value @xmath137 is taken as the prediction for our tsn , and the uncertainty @xmath138 is taken from the actual measurements quoted by the particle data group  @xcite .",
    "plane , after the inclusion of the electroweak observables , for 1 pb@xmath115 ( left ) , 100 pb@xmath115 ( center ) , and 500 pb@xmath115 ( right ) .",
    "the tsn is indicated by the black dot .",
    "the central values of the electroweak observables are computed at the tsn point , but we use the experimental uncertainties from refs .",
    "[ fig : posteriorlm1],scaledwidth=100.0% ]    the plots in fig .",
    "[ fig : posteriorlm1 ] show that the electroweak results are helpful in breaking the model degeneracy .",
    "we expect this conclusion to remain true for realistic analyses and models .",
    "we now consider two 5-parameter models that illustrate the more realistic situation in which the use of a regular grid of parameter points in the space @xmath12 rapidly becomes unfeasible due to the well - known  curse of dimensionality \" . the standard way to circumvent this problem is to sample points using markov chain monte carlo .",
    "this is what we propose to do in order to approximate the posterior density @xmath79 where , now , @xmath3 represents a parameter point in the 5-dimensional model space .",
    "we define two non - universal extensions of the cmssm that we call num@xmath139 and num@xmath140 , which respectively have non - universal @xmath4 and non - universal @xmath104 .",
    "we choose our tsn from num@xmath139 , and therefore also refer to it as the  tsn model \" .",
    "we refer to the other model as the  wrong model \" .",
    "note that this model can not be used to parametrize the tsn point due to its universal @xmath4 .",
    "the free parameters of the two models and the parameter values at tsn are as follows :    * tsn model : num@xmath139 ( cmssm with non - universal m@xmath141 ) : * * @xmath142 : 250 gev at tsn * * @xmath143 : 1.5 tev at tsn * * @xmath104 where @xmath144 : 300 gev at tsn * * @xmath145 : 0 gev at tsn * * @xmath146 : 10 at tsn * wrong model : num@xmath140 ( cmssm with non - universal m@xmath140 ) : * * @xmath4 where @xmath147 * * @xmath148 * * @xmath149 * * @xmath145 * * @xmath146    for both cases , we take the sign of @xmath18 to be positive .      our method follows the common bayesian strategy of  sacrificing \" a small fraction of the data to generate what we have referred to as an _ initiating _ prior , that is , a prior that permits the inference chain to proceed .",
    "in this example , the multi - parameter priors for the tsn and wrong models are constructed assuming a 100 pb@xmath115 data - set .",
    "we again use the softsusy  @xcite , susyhit  @xcite , pythia  @xcite sequence to generate events , but delphes  @xcite to simulate the cms detector  @xcite , and we apply the same cms jets plus  analysis  @xcite .",
    "for simplicity , we assume that the subsequent analysis is again that of a counting experiment identical to the one used to construct the priors , except that the integrated luminosity is larger . in practice , one would work hard to adapt , improve , and change the analyses as more and more data are accumulated .",
    "however , our purpose here is not to do a realistic analysis but simply to illustrate our method .",
    "the quantities pertaining to the tsn point , and assuming 100 pb@xmath115 are : @xmath150 the reference prior using the above values for @xmath35 and @xmath34 is shown in fig .",
    "[ fig : refprior ] .    , for the single count model computed using eq .",
    "( [ eq : pir2p ] ) ( line ) compared with the same computed numerically using eq .",
    "( [ eq : jeffreysprior ] ) ( points ) .",
    "[ fig : refprior],scaledwidth=40.0% ]    the reference posterior density @xmath77 is computed using the numbers at the tsn point . however , since it is no longer realistic to use a uniform grid of points , we generate a sample of points @xmath151 from the reference posterior density @xmath77 with @xmath80 , for each model , using the metropolis - hastings algorithm  @xcite and multiple mcmc chains .",
    "asymptotically , this sampling procedure will produce a density that satisfies eq .",
    "( [ eq : intmap ] ) . moreover , to the degree that the chains can thoroughly explore the surfaces @xmath90",
    ", the generated points will also satisfy eq .",
    "( [ eq : ptheta ] ) ; that is , the surface term will be automatically incorporated .",
    "the mapping from one to multiple dimensions is discussed further in appendix  [ app:2dmapping ] using a 2-dimensional toy model .    .",
    "the shaded histograms are the priors .",
    "the posterior densities , obtained by weighting the sampled points by the likelihood for the counting experiment ( dark line ) and the combined likelihood for the electroweak experiments ( light line ) , are superimposed on the priors .",
    "the vertical dashed line indicates the position of the tsn point . from these projections",
    ", one would conclude that the influence of the result of the counting experiment is negligible , while the influence of the electroweak results is quite evident .",
    "[ fig : priorslm1tsn],scaledwidth=100.0% ]    figure  [ fig : priorslm1tsn ] shows the 1-dimensional marginal densities of the induced prior for the tsn model on which are superimposed the posterior densities .",
    "the 1-dimensional marginals for the wrong model are shown in fig .",
    "[ fig : priorslm1wrong ] . in both figures ,",
    "the location of the tsn point is indicated by the vertical dashed line .",
    "note that in each figure two of the plots are degenerate : the @xmath148 and @xmath149 plots in fig .",
    "[ fig : priorslm1tsn ] for the tsn model and the @xmath142 and @xmath152 plots in fig .",
    "[ fig : priorslm1wrong ] for the wrong model . for the tsn model ,",
    "most of the peaks of the 1-dimensional densities are near the tsn point , while for the wrong model this is not the case .     for details .",
    "[ fig : priorslm1wrong],scaledwidth=100.0% ]    , scaledwidth=100.0% ]    we can get a better idea of the shape of the posterior densities from their 2-dimensional marginals , which are shown in fig .",
    "[ fig : priorslm1tsn2d ] . the black point in each plot",
    "is the tsn point .",
    "one feature which seems puzzling at first is that the tsn point does not always lie at the peak of the densities .",
    "but , the following should be noted .",
    "if the hyper - surface @xmath90 on which the tsn point lies is larger than that of another hyper - surface associated with a smaller value of the reference posterior density @xmath77 , then it could happen that the value of @xmath79 on the tsn hyper - surface is actually smaller than its value on the other hyper - surface , even though the total probability of the tsn hyper - surface is greater than the total probability of other hyper - surfaces .    , scaledwidth=100.0% ]    figure  [ fig : priorslm1tsn2dew ] shows what happens to the prior after multiplication by the likelihood for the electroweak results .",
    "as expected , these results make a noticeable change to the prior in sharp contrast to the result of the counting experiment .",
    "this is , perhaps , not surprising since the observed count constrains only the signal strength , whereas the electroweak results constrain multiple observables that help break the model degeneracy .",
    "table  [ tab : significance ] shows how the signal significance , as defined in eq .",
    "( [ eq : dn ] ) , increases as a function of integrated luminosity .",
    "we expect this number to scale like @xmath153 , which indeed it does .",
    ".signal significance as a function of integrated luminosity for the tsn model .",
    "[ cols=\"^,^,^,^ \" , ]     [ tab : ranking ]",
    "we have proposed a method for building multi - parameter priors that follows the general strategy of building a proper prior using a small portion of the data and analyzing the rest using that prior . since the direct construction of multi - parameter priors , with mathematically well - defined properties , is a difficult task",
    "we have proposed a method that begins with a simpler task , namely , the construction of a reference prior for an analysis having a single parameter of interest .",
    "together with the likelihood function , the reference prior yields a proper posterior density that is consistent with a class of posterior densities on the parameter space of the physics model under study .",
    "we proposed choosing a particular member from this class to serve as the multi - parameter prior for subsequent analyses .",
    "that prior has the property that its density is constant on every hyper - surface indexed by the parameter of interest .",
    "moreover , because it is built from a reference prior , the multi - parameter prior is expected to yield credible regions with excellent frequentist properties . finally , the robustness of inferences can be assessed by weighting the multi - parameter prior @xmath11 by , for example , @xmath154^r$ ] and studying the sensitivity of inferences to the exponent @xmath155 .",
    "the exponent @xmath156 permits a smooth interpolation between the reference prior @xmath157 and a flat prior ( @xmath158 ) .",
    "our proposed construction must surmount a technical hurdle : generating a sample of points in the parameter space of the physics model with the properties that 1 ) the number of points on each hyper - surface is proportional to the reference posterior density associated with that hyper - surface and 2 ) the points on the hyper - surface are uniformly distributed . we showed , using three illustrative examples , how one might address this question , in general . for high - dimensional models ,",
    "the use of mcmc seems feasible .",
    "however , we have found that convergence may be an issue because of the severe degeneracies present when relatively little information is used to create the multi - parameter prior . in a realistic application it will be necessary to tune the mcmc algorithm to ensure convergence of the markov chains .",
    "it would be useful to explore different sampling methods , such as multinest  @xcite , that may be better suited to problems with severe degeneracies .",
    "in spite of these challenges , however , we have shown that our method yields priors that give consistent results as more and more data are accumulated .",
    "what remains to be done is to apply the method to a real analysis at the lhc .",
    "our expectation is that the method would fare well .",
    "we thank jim berger and jos bernardo for discussions on reference priors and bayesian methods in general and sabine kraml for discussions on the susy models .",
    "we also thank luc demortier , bob cousins , and kyle cranmer for several discussions that helped clarify our thoughts .",
    "this work was supported in part by the u.s .",
    "department of energy under grant no .",
    "de - fg02 - 97er41022 .",
    "99 the large hadron collider , http://lhc.web.cern.ch/lhc .    , s.  ovyn , x.  rouby , and v.  lemaitre , [ arxiv:0903.2225 [ hep - ph ] ] .",
    "j.  wess , and b.  zumino , nucl .",
    "* b70 * , 39 ( 1974 ) ; h.  p.  nilles , phys .",
    "rept .   * 110 * , 1 ( 1984 ) ; h.  baer , and x.  tata , _ weak scale supersymmetry : from superfields to scattering events _ ( cambridge university press , cambridge , 2006 ) .",
    "see for example , a.  h.  chamseddine , r.  l.  arnowitt , and p.  nath , phys .",
    "* 49 * , 970 ( 1982 ) ; g.  l.  kane , c.  f.  kolda , l.  roszkowski , and j.  d.  wells , phys",
    ".  rev .",
    "* d49 * , 6173 ( 1994 ) .",
    "[ hep - ph/9312272 ] .",
    "a.  a.  markov , izvestiya fiziko - matematicheskogo obschestva pri kazanskom universitete , 2-ya seriya , tom * 15 * , 135 ( 1906 ) ; a.  a.  markov , reprinted in appendix b of r.  howard , _ dynamic probabilistic systems _ , vol . 1 : _ markov chains _ ( john wiley and sons , 1971 ) . for a modern textbook introduction see , for example , b.  a.  berg ,",
    "_ markov chain monte carlo simulations and their statistical analysis _",
    "( world scientific , singapore , 2004 ) .",
    "see for example , e.  a.  baltz , p.  gondolo , jhep * 0410 * , 052 ( 2004 ) , [ arxiv : hep - ph/0407039 [ hep - ph ] ] ; c.  g.  lester , m.  a.  parker , m.  j.  white , 2 , jhep * 0601 * , 080 ( 2006 ) , [ hep - ph/0508143 ] ; r.  r.  de austri , r.  trotta , l.  roszkowski , jhep * 0605 * , 002 ( 2006 ) .",
    "[ hep - ph/0602028 ] ; e.  a.  baltz , m.  battaglia , m.  e.  peskin , t.  wizansky , phys .",
    "rev .   * d74 * , 103521 ( 2006 ) . [ hep - ph/0602187 ] ; b.  c.  allanach , c.  g.  lester , a.  m.  weber , jhep * 0612 * , 065 ( 2006 ) .",
    "[ hep - ph/0609295 ] ; b.  c.  allanach , c.  g.  lester , comput .",
    "commun .  * 179 * , 256 ( 2008 ) .",
    "[ arxiv:0705.0486 [ hep - ph ] ] ; l.  m.  h.  hall , h.  v.  peiris , jcap * 0801 * , 027 ( 2008 ) .",
    "[ arxiv:0709.2912 [ astro - ph ] ] ; s.  davidson , j.  garayoa , f.  palorini , n.  rius , jhep * 0809 * , 053 ( 2008 ) . [ arxiv:0806.2832 [ hep - ph ] ] ; h.  baer , s.  kraml , s.  sekmen , h.  summy , jhep * 0803 * , 056 ( 2008 ) .",
    "[ arxiv:0801.1831 [ hep - ph ] ] ; o.  buchmueller , r.  cavanaugh , a.  de roeck , j.  r.  ellis , h.  flacher , s.  heinemeyer , g.  isidori , k.  a.  olive _ et al .",
    "_ , jhep * 0809 * , 117 ( 2008 ) .",
    "[ arxiv:0808.4128 [ hep - ph ] ] .",
    "f.  brummer , s.  fichet , s.  kraml , r.  k.  singh , jhep * 1008 * , 096 ( 2010 ) .",
    "[ arxiv:1007.0321 [ hep - ph ] ] ; h.  baer , s.  kraml , a.  lessa , s.  sekmen , x.  tata , jhep * 1010 * , 018 ( 2010 ) .",
    "[ arxiv:1007.3897 [ hep - ph ] ] .    c.  f.  berger , j.  s.  gainer , j.  l.  hewett , and t.  g.  rizzo , jhep * 0902 * , 023 ( 2009 ) .",
    "g.  l.  bayatian _ et al . _",
    "[ cms collaboration ] , j.  phys .",
    "g * g34 * , 995 ( 2007 ) .",
    "see for example , o.  buchmueller , r.  cavanaugh , a.  de roeck , j.  r.  ellis , h.  flacher , s.  heinemeyer , g.  isidori , k.  a.  olive _ et al .",
    "_ , eur .  phys .",
    "j.   * c64 * , 391(2009 ) , [ arxiv:0907.5568 [ hep - ph ] ] ; o.  buchmueller , r.  cavanaugh , d.  colling , a.  de roeck , m.  j.  dolan , j.  r.  ellis , h.  flacher , s.  heinemeyer _ et al .",
    "_ , eur .",
    "j.   * c71 * , 1583 ( 2011 ) .",
    "[ arxiv:1011.6118 [ hep - ph ] ] .",
    "see for example , d.  e.  lopez - fogliani , l.  roszkowski , r.  r.  de austri , t.  a.  varley , phys .",
    "rev .   * d80 * , 095013 ( 2009 ) .",
    "[ arxiv:0906.4911 [ hep - ph ] ] ; r.  trotta , f.  feroz , m.  p.  hobson , l.  roszkowski , r.  ruiz de austri , jhep * 0812 * , 024 ( 2008 ) , [ arxiv:0809.3792 [ hep - ph ] ] ; b.  c.  allanach , k.  cranmer , c.  g.  lester , and a.  m.  weber , jhep * 08 * , 023 ( 2007 ) .",
    "r.  d.  cousins , j.  t.  linnemann , and j.  tucker , nucl .",
    "instrum .",
    "* a595 * , 480 ( 2008 ) .",
    "g.  cowan , k.  cranmer , e.  gross , and o.  vitells , eur .",
    "j.   * c71 * , 1554 ( 2011 ) .",
    "[ arxiv:1007.1727 [ physics.data-an ] ] .",
    "f.  feroz , k.  cranmer , m.  hobson , r.  ruiz de austri , and r.  trotta , jhep * 1106 * , 042 ( 2011 ) .",
    "[ arxiv:1101.3296 [ hep - ph ] ] .",
    "y.  akrami , p.  scott , j.  edsjo , j.  conrad , and l.  bergstrom , jhep * 1004 * , 057 ( 2010 ) .",
    "[ arxiv:0910.3950 [ hep - ph ] ] .",
    "c.  p.  robert , _ the bayesian choice : from decision - theoretic foundations to computational implementation _ ( springer , new york , 2007 ) , 2nd ed . ; e.  t.  jaynes , _ probability theory : the logic of science _ , edited by g.  l.  bretthorst ( cambridge university press , cambridge , 2003 ) ; a.  ohagan , _ kendall s advanced theory of statistics , volume 2b : bayesian inference _ ( edward arnold , london , 1994 ) ; h.  jeffreys , _ theory of probability _ ( oxford university press , oxford , 1961 ) , 3rd ed .",
    "v.  m.  abazov _ et al . _",
    "( d0 collaboration ) , phys .",
    "* 103 * , 092001 ( 2009 ) .",
    "t.  aaltonen _ et al . _",
    "( cdf collaboration ) , phys .",
    "lett . * 103 * , 092002 ( 2009 ) .",
    "i.  bertram , g.  landsberg , j.  linnemann , r.  partridge , m.  paterno , and h.  b.  prosper , fermilab preprint fermilab - tm-2104 ( 2000 ) .",
    "j.  m.  bernardo , j. r. statist .",
    "b * 41 * , 113 ( 1979 ) ; j.  o.  berger and j.  m.  bernardo , j. amer . statist . assoc . * 84 * , 200 ( 1989 ) ; j.  o.  berger and j.  m.  bernardo , biometrika * 79 * , 25 ( 1992 ) ; j.  o.  berger and j.  m.  bernardo , in _",
    "bayesian statistics 4 _ , edited by j.  m.  bernardo , j.  o.  berger , a.  p.  dawid , and a.  f.  m.  smith ( oxford university press , oxford , 1992 ) , pp .",
    "35 - 60 , http://www.uv.es/~bernardo/1992valencia4ref.pdf ; j.  m.  bernardo , in _ handbook of statistics 25 _ , edited by d.  k.  dey and c.  r.  rao ( elsevier , amsterdam , 2005 ) , pp .",
    "17 - 90 , http://www.uv.es/~bernardo/refana.pdf .",
    "l.  demortier , in _ statistical problems in particle physics , astrophysics , and cosmology : proceedings of phystat05 _ , eds .",
    "l.  lyons and m.  k.  nel ( imperial college press , london , 2006 ) , pp .  11 - 14 .",
    "l. demortier , s. jain , and h. b. prosper , phys .",
    "d * 82 * , 034002 ( 2010 ) .",
    "d.  t.  gillespie , am .",
    "* 51 * , 520 ( 1983 ) .",
    "j.  o.  berger , j.  m.  bernardo , and d.  sun , ann .",
    "statist . *",
    "37 * , 905 ( 2009 ) , http://www.uv.es/~bernardo/2009annals.pdf .",
    "f.  feroz , k.  cranmer , m.  hobson , r.  ruiz de austri , and r.  trotta , jhep * 1106 * , 042 ( 2011 ) .",
    "[ arxiv:1101.3296 [ hep - ph ] ] .",
    "myung , v.  balasubramanian , and m.a .",
    "pitt , proc .",
    "usa , * 97 * , 11170 ( 2000 ) ; http://www.ncbi.nlm.nih.gov/pmc/articles/pmc17172 .",
    "berger , and r.l .",
    "wolpert , _ the likelihood principle _ , lecture notes ",
    "monograph series , vol .",
    "* 6 * , ed .",
    "gupta ( institute of mathematical statistics , hayward , 1984 ) .",
    "see , for example , d.  j.  c.  mackay , _ bayesian methods for adaptive models _ , phd thesis , caltech ( 1992 ) .",
    "http://www.inference.phy.cam.ac.uk/mackay/phd.html .",
    "m.  pierini , h.  prosper , s.  sekmen , and m.  spiropulu , [ arxiv:1107.2877 [ hep - ph ] ] .",
    ", b.  c.  allanach , comput .",
    "commun .   * 143 * , 305 ( 2002 ) .",
    "[ hep - ph/0104145 ] .",
    ", a.  djouadi , m.  m.  muhlleitner , and m.  spira , acta phys .",
    "polon .   * b38 * , 635 ( 2007 ) .",
    "[ hep - ph/0609292 ] .    , t.  sjostrand , s.  mrenna , and p.  z.  skands , jhep * 0605 * , 026 ( 2006 ) .",
    "[ hep - ph/0603175 ] .",
    "r.  adolphi _ et al . _",
    "[ cms collaboration ] , jinst * 3 * , s08004 ( 2008 ) .",
    ", j.  conway , _ et al .",
    "_ , + http://physics.ucdavis.edu/~conway/research/software/pgs/pgs4-general.htm .",
    "s.  sekmen , ph.d .",
    "thesis , cms ts-2009/025 .    , f.  mahmoudi , comput .",
    "commun .",
    "* 178 * , 745 ( 2008 ) .",
    "[ arxiv:0710.2067 [ hep - ph ] ] ; f.  mahmoudi , cphcb,180,1579 - 1613 .",
    "2009 * 180 * , 1579 ( 2009 ) .",
    "[ arxiv:0808.3144 [ hep - ph ] ] .    ,",
    "g.  belanger , f.  boudjema , a.  pukhov , a.  semenov , comput .",
    "commun .",
    "* 176 * , 367 ( 2007 ) .",
    "[ hep - ph/0607059 ] .",
    "k.  nakamura _ et al .",
    "_ [ particle data group collaboration ] , j.  phys .",
    "g * g37 * , 075021 ( 2010 ) .    n.  metropolis , a.  w.  rosenbluth , m.  n.  rosenbluth , a.  h.  teller , and e.  teller , j.  chem .  phys .",
    "* 21 * , 1087 ( 1953 ) ; w.  k.  hastings , biometrika * 57 * , 1970 ( 1970 ) .    ,",
    "f.  feroz , m.  p.  hobson , and m.  bridges , [ arxiv:0809.3437 [ astro - ph ] ] .",
    "this form for the prior @xmath159 can be motivated  @xcite by considering an experiment comprising two data - sets @xmath160 and @xmath161 .",
    "data - set @xmath160 is modeled as a mixture of signal and background events with expected background count @xmath18 .",
    "data - set @xmath161 , perhaps a sideband , is presumed to be overwhelmingly dominated by background events with expected background @xmath162 .",
    "although we do not know @xmath18 , we assume that we know the ratio @xmath34 of the expected background in data - set @xmath161 to that in data - set @xmath160 .",
    "the expected background @xmath162 for data - set @xmath161 is estimated by the number of events @xmath35 in that data - set .",
    "the likelihood for the observed count @xmath35 in data - set @xmath161 is taken to be @xmath163 , which , together with its reference prior , @xmath164 , yields the posterior density @xmath165 .",
    "this posterior density serves as the evidence - based prior @xmath159 for the expected background in data - set @xmath160 .",
    "one begins with the information gained from @xmath68 repetitions of the single count experiment , @xmath166 \\equiv \\sum_{n_1 = 0}^{\\infty } \\cdots \\sum_{n_k = 0}^{\\infty }   m(n_{(k ) } ) \\ , d [ \\pi ,",
    "p(s | n_{(k ) } ) ] , \\label{eq : ik}\\ ] ] where @xmath167 is the marginal density for @xmath68 experiments .",
    "the maximization of the expected information gain , @xmath168 $ ] , with respect to the prior yields the function @xmath169 . by definition",
    "@xcite , the reference prior @xmath37 is the limit @xmath170\\,\\right\\ } , \\label{eq : refprior}\\end{aligned}\\ ] ] where @xmath171 is any fixed point in the space of expected signal and @xmath172 is any positive function , such as @xmath173 . however , since the posterior density for the single count model is asymptotically normal , the reference prior computed using the above algorithm coincides with jeffreys prior , eq .",
    "( [ eq : jeffreysprior ] ) .",
    "defining the recursive functions , @xmath174 w_{k}(s , z ) & \\;=\\ ; z \\left ( \\frac{s}{k } \\right)\\;w_{k-1 }                      \\quad\\textrm{for}\\quad k=1,\\cdots , n,\\\\[2 mm ] y_0(z )       & \\;=\\ ; 1 , \\\\[2 mm ] y_k(z )       & \\;=\\ ; z \\left ( \\frac{y-\\frac{1}{2}+k}{k } \\right )                       \\left ( \\frac{1}{b+1 } \\right)\\;y_{k-1 } ,                      \\quad\\textrm{for}\\quad k=1,\\cdots , n , \\end{split }",
    "\\label{eq : wxy}\\ ] ] we can write @xmath175 and @xmath176 as @xmath177^{y+\\frac{1}{2}}\\ ;                    \\sum_{k=0}^{n } w_k(s , z ) \\ ; y_{n - k}(z),\\\\    t_n^m & \\;=\\;&\\sum_{k=0}^n k^m \\ ; w_k(s , z ) \\ ; y_{n - k}(z ) ,                           \\label{eq : marginalmodelcalc}\\end{aligned}\\ ] ] with @xmath178 for @xmath179 and @xmath180 for @xmath181 .",
    "to illustrate further how the mapping from a 1-d posterior density to an @xmath16-d parameter space works in practice , we consider the case of a model described by two unknown parameters @xmath6 and @xmath182 . an experimental measurement is available for the quantity @xmath183 .",
    "one builds the reference prior corresponding to all the possible outcomes of the measurement of @xmath184 and derives a reference posterior @xmath185 .",
    "we now want to find a function @xmath186 that is consistent with the 1-d reference posterior density @xmath185 .",
    "* @xmath187 is constant for all the points @xmath188 corresponding to the same value of @xmath184 .",
    "this implies that @xmath189 .",
    "this makes perfect sense because the only available information on @xmath6 and @xmath182 is the measurement of @xmath184 , which can not break the degeneracy of the iso-@xmath184 contour . without any loss of generality , we can then write @xmath190 ; * when marginalized to @xmath184 , through eq .",
    "( [ eq : intmap ] ) , @xmath187 should recover @xmath185 . this consistency requirement , together with the first , is what permits identifying @xmath191 with the  area \" of the iso-@xmath184 contour .",
    "the first requirement is quite natural if one thinks of the bayesian analysis as an update of our knowledge about the parameters @xmath6 and @xmath182 .",
    "the second requirement may need further explanation .",
    "suppose for the moment that the function @xmath191 does not enter the problem .",
    "enforcing the first condition would then imply that @xmath192 . consider a measurement of @xmath184 with a gaussian likelihood .",
    "this measurement would translate into a 2-d function of @xmath6 and @xmath182 as shown in the left plot of fig .",
    "[ fig : wrongmap ] .    , where @xmath185 is the 1-d reference posterior density .",
    "( right ) ratio of @xmath193 marginalized back to @xmath184 , via eq .",
    "( [ eq : intmap ] ) , over the reference posterior density @xmath185 .",
    "clearly the two 1-d densities are not the same , as they should be if the density @xmath194 were consistent with @xmath185 .",
    "[ fig : wrongmap],title=\"fig : \" ] , where @xmath185 is the 1-d reference posterior density .",
    "( right ) ratio of @xmath193 marginalized back to @xmath184 , via eq .",
    "( [ eq : intmap ] ) , over the reference posterior density @xmath185 .",
    "clearly the two 1-d densities are not the same , as they should be if the density @xmath194 were consistent with @xmath185 .",
    "[ fig : wrongmap],title=\"fig : \" ]    once marginalized , this function gives a function @xmath195 which differs from @xmath185 by a factor linear in @xmath184 , coming from the jacobian of the @xmath196 marginalization .",
    "this is shown in the right plot of fig .",
    "[ fig : wrongmap ] , which shows the ratio @xmath197 as a function of @xmath184 .",
    "however , in this specific case , we know the form of the function @xmath198 ; it is simply given by @xmath199 .",
    "therefore , the correct mapping from 1-d to 2-d yields @xmath200 , shown in the left plot of fig .",
    "[ fig : anmap ] , which gives a constant value for the ratio @xmath197 ( see right plot of fig .  [",
    "fig : anmap ] ) as one would expect for a density @xmath186 that is consistent with @xmath185 .    , where @xmath185 is the 1-d reference posterior density .",
    "( right ) ratio of @xmath193 marginalized back to @xmath184 , via eq .",
    "( [ eq : intmap ] ) , over the reference posterior density @xmath185 . the two 1-d densities are identical , as they should be since , by construction , the density @xmath194 is consistent with @xmath185.[fig : anmap],title=\"fig : \" ] , where @xmath185 is the 1-d reference posterior density .",
    "( right ) ratio of @xmath193 marginalized back to @xmath184 , via eq .",
    "( [ eq : intmap ] ) , over the reference posterior density @xmath185 .",
    "the two 1-d densities are identical , as they should be since , by construction , the density @xmath194 is consistent with @xmath185.[fig : anmap],title=\"fig : \" ]    in the absence of an analytical solution for @xmath201 , one could follow a simple numerical procedure , which takes full advantage of the fact that @xmath202 .",
    "this simple fact implies that , by incorrectly using @xmath203 one is wrong by a factor that is constant over the iso-@xmath184 contour .",
    "this factor is nothing else than the ratio @xmath197 , mapped onto the @xmath188 plane ( see left plot of fig .",
    "[ fig : correctedmap ] ) .",
    "this simple construction allows one to solve for the integral , eq .  ( [ eq : area ] ) , defining @xmath204 without having to perform the integral explicitly ; one simply weights each point by @xmath197 , which is shown in the right - hand plot of fig .",
    "[ fig : correctedmap ] ) . when the corrected function @xmath186 is marginalized , the function @xmath185 is recovered by construction .",
    "the use of mcmc to sample the space @xmath205 makes the procedure even simpler . rather than scanning the @xmath188 plane and associating to each point the value of @xmath185 , one samples @xmath188 according to @xmath185 directly .",
    "this implies that @xmath206 by construction , as one can easily verify ."
  ],
  "abstract_text": [
    "<S> the interpretation of data in terms of multi - parameter models of new physics , using the bayesian approach , requires the construction of multi - parameter priors . </S>",
    "<S> we propose a construction that uses elements of bayesian reference analysis . </S>",
    "<S> our idea is to initiate the chain of inference with the reference prior for a likelihood function that depends on a single parameter of interest that is a function of the parameters of the physics model . </S>",
    "<S> the reference posterior density of the parameter of interest induces on the parameter space of the physics model a _ class _ of posterior densities . </S>",
    "<S> we propose to continue the chain of inference with a particular density from this class , namely , the one for which indistinguishable models are equiprobable and use it as the prior for subsequent analysis . </S>",
    "<S> we illustrate our method by applying it to the constrained minimal supersymmetric standard model and two non - universal variants of it .    </S>",
    "<S> = msbm10  </S>"
  ]
}