{
  "article_text": [
    "let @xmath0 denote the heights of @xmath2 simple random walks on @xmath3 , conditioned on satisfying    @xmath4 , \\left| z^{(i+1)}_n - z^{(i)}_n \\right| = 1.\\ ] ]    more precisely , the random walk is a markov chain on the state space of @xmath5-step walks in @xmath6    @xmath7 , |z^{(i+1 ) } - z^{(i)}| = 1 \\}\\ ] ]    where the next step from @xmath8 is selected uniformly among the neighbours of @xmath9 in the usual lattice @xmath10 that belong to @xmath11 .",
    "in other words , we consider @xmath2 simple random walks on the lattice @xmath3 coupled under a shape condition .    as in the case of a simple random walk ,",
    "the rescaled trajectory of a walker , say @xmath12 , will converge in law to a brownian motion .",
    "however , it is interesting to note that the constraint between each coordinate only slow down the walk by decreasing its variance .",
    "since it is classical to illustrate for our students the simple random walk as the motion of a drunk man , we can illustrate the previous mathematical fact by considering the random walk as the motion of a chain of prisoners .",
    "it should convince even non mathematicians that the motion of the walk is slowed by the constraint .",
    "however it seems very hard to guess the variance from this comparison !",
    "more precisely , denote    @xmath13    where @xmath14 is the integer part of the real number @xmath15    [ t : var ] the rescaled random walk @xmath16 converges in law , as @xmath17 goes to infinity , to a brownian motion with variance @xmath18    convergence to the brownian motion is the usual invariance principle  :  the noteworthy statement here is that it is possible to give an explicit expression for the limit diffusivity of the process , and that its expression is particularly simple .",
    "our object of interest , the motion of @xmath19 is a non - markovian process that falls into the class of random walks with internal structure .",
    "related questions of limit diffusivity for random walks conditioned to respect some geometric shape have been studied in the literature , under the name of `` spider random walks '' or `` molecular spiders '' , see @xcite .",
    "the computation of the limit diffusion coefficient is also a central aim there , although the model and methods are different .",
    "our initial motivation was however more remote .",
    "actually we first addressed this question starting from combinatorial problems related to @xmath20-vertex model in relation with the razumov stroganov conjecture ( see  @xcite for instance ) .",
    "the problem can also be related to random graph - homomorphisms ( see  @xcite ) or the square ice model ( see  @xcite where @xmath12 evolves on a torus . )    roughly speaking we can say that , in the literature we read , the authors consider questions related to the uniform distribution on a sequence of finite graphs @xmath21 and wonder about various asymptotics when @xmath22 later in the article the evolution of @xmath23 will be described as the simple random walk on a graph @xmath24 hence on the one hand our problem is a very simplified version of the problems stated above , on the other hand we were surprised to have such a simple formula for @xmath25 which is true for all @xmath26 and not only for @xmath22 we thought in the beginning that the proof of this fact should be simple but it turns out that , although elementary , the tools used to obtain the result are more sophisticated than expected .",
    "it is the aim of this note to show these tools .    to prove the theorem",
    ", we will look for a decomposition @xmath27    where @xmath28 is a martingale , and where @xmath29 is a bounded function .",
    "we will then show that the following limit exists :    @xmath30.\\ ] ]    and that it is indeed the desired diffusivity .",
    "the path to this conclusion is akin to classical results for central limit theorems for markov chains ( e.g. @xcite ) .",
    "we will use another equivalent , albeit more geometric , point of view on this decomposition .",
    "we split the chain in two parts : on the one hand , the motion of one of the walkers , and on the other hand , the relative positions of the walkers ( which we call the `` shape '' of the chain at a given time ) .",
    "the latter part is a markov chain over the state space @xmath31 and our quantity of interest is ( almost ) an observable of this chain .",
    "computing the martingale decomposition that we wish for amounts to decomposing a discrete vector field over this new state space into a divergence - free part ( corresponding to the martingale part ) and a gradient part ( corresponding to the function @xmath32 ) . owing to a particular geometric property of this vector field ,",
    "for which we coin the term `` stationarity '' , it is indeed possible to perform this calculation explicitly .",
    "let us denote @xmath33 , y_n^{(i ) } = z_n^{(i+1)}- z_n^{(i)},\\ ] ] and @xmath34 here @xmath35 describes the shape of @xmath0 , i.e. the position of each @xmath36 relatively to the previous one , and belongs to @xmath37 , whereas @xmath38 can be seen as the height of the first walker .",
    "obviously , the evolution of the chain of walkers may be described by the variables @xmath39 .    for a convenient analysis",
    ", we will represent our process as the simple random walk on a ( multi)-graph @xmath40 , which we define below .    set @xmath41 : the multi - graph @xmath40 is given as a triplet @xmath42 where @xmath43 are two edge sets , called respectively the set of  positive `` and ' ' negative  edges .",
    "a couple @xmath44 , @xmath45 , belongs to @xmath46 if the vector @xmath47 has nonzero entries of alternating signs , with the first one negative .",
    "moreover , @xmath48 also contains a loop from each @xmath49 to itself , noted @xmath50 .",
    "likewise , @xmath51 contains those couples @xmath44 , @xmath45 , such that @xmath47 has nonzero entries of alternating sign , with the first one positive , and self - loops noted @xmath52 for each @xmath49 .",
    "set @xmath53 .",
    "finally , we consider the following function on @xmath54    [ def : a ] let @xmath55 be the function that takes the value @xmath56 on @xmath48 and @xmath57 on @xmath51",
    ". note that we have , for any @xmath49 , @xmath58 .",
    "let @xmath59 be the simple random walk on @xmath40 .",
    "the processes @xmath60 and @xmath61 have the same distribution .",
    "it is sufficient to prove that the two markov chains ( taking values in @xmath62 ) @xmath60 and @xmath61 have the same transition matrix .",
    "we claim that @xmath63    recall that @xmath64 , \\left| z^{(i + 1 ) } - z^{(i ) } \\right| = 1 \\right\\}$ ] .",
    "denote    @xmath65 , \\left| z_1^{(i ) } - z_2^{(i ) } \\right| = 1 \\right\\}.\\ ] ]    since @xmath66 and @xmath67 are both simple random walks , the corresponding transition matrices are given respectively by @xmath68    denote now @xmath69    so that @xmath70 .    to prove the proposition , it is sufficient to prove that    @xmath71    where @xmath72 ( and @xmath73 is the sign function ) .",
    "first note that , if @xmath74 , and if @xmath75 , z_1^{(i ) } = z_2^{(i ) } - \\epsilon$ ] , then @xmath76 .",
    "moreover , we have in this case @xmath77 , and @xmath78 as claimed . on the other hand , if @xmath77 and @xmath79 , then @xmath75 , z_1^{(i ) } = z_2^{(i ) }   + \\epsilon$ ] .",
    "for the chain , it means that , if @xmath80 then @xmath81 is @xmath82 with equal probability @xmath83 independently of @xmath84 .",
    "assume now that @xmath85 .",
    "we will prove that @xmath86 , where @xmath87 , i.e. @xmath88 , with nonzero entries of alternating signs , and a first one of the sign of @xmath89 .",
    "indeed , there is a first index @xmath90 , \\ ;   \\mbox{such that } \\quad   \\delta(z_{1})^{(i ) } \\neq   \\delta(z_2)^{(i ) } \\}.\\ ] ]    there are two possible cases @xmath91 @xmath92    in the two cases we have @xmath93    furthermore , we have @xmath94    then if @xmath95 let us define @xmath96 , \\ ;   \\mbox{such that } \\quad      \\delta(z_2)^{(i ) } \\neq \\delta(z_1)^{(i ) }   \\},\\ ] ] where we set by convention @xmath97 if the condition defining the infimum is never satisfied .    using the same arguments",
    ", we get @xmath98    by induction one can define @xmath99 , \\ ;   \\mbox{such that } \\quad",
    "\\delta(z_1)^{(i)}\\neq \\delta(z_2)^{(i ) }    \\},\\ ] ] until @xmath100    we have @xmath101    by definition , we get @xmath102 where @xmath103 .    on the other hand , if @xmath104 , where @xmath105 , then one can recover explicitly @xmath106 from the definition of @xmath107",
    ". moreover , the condition @xmath108 , \\left| z_2^{(i ) } - z_1^{(i ) } \\right|=1 $ ] is implied by the previous arguments ( following the definitions of the @xmath109 ) .",
    "we may denote , @xmath110 when @xmath111 ( @xmath112 ) and @xmath113 when @xmath114 ( @xmath115 ) .    for a general @xmath116",
    "the previous enumeration of its neighbors is surprisingly complicated but we can provide some simple examples .",
    "for instance if @xmath117 has only @xmath118 neighbors : @xmath119 , a & \\rightarrow ( 1,\\cdots , -1 , \\cdots,1 ) , \\end{aligned}\\ ] ]    where the @xmath57 is in the @xmath120-th position .    note",
    "now that the graph @xmath40 can also be described inductively : there are only six following possibilities for @xmath121 , described below :                    in the figure , we have used the concatenation notation : given a string @xmath122 , the string @xmath123 , resp .",
    "@xmath124 , is obtained by adding a @xmath56 , resp . @xmath57 in front of @xmath122 . looking only at the @xmath125 cases such that @xmath126",
    ", we can deduce the construction of @xmath127 from @xmath128 :    @xmath129    figure 1 shows the first two graphs @xmath130 and @xmath131 . note that each edge of @xmath132 gives @xmath125 edges for @xmath133 , one on each facet @xmath134 , and @xmath135 and one crossing from the facet @xmath136 to the facet @xmath135 .",
    "[ f : constr ]     and @xmath131 . ]",
    "we obtain the cardinality @xmath137 of @xmath138 ( as a multigraph ) by induction : @xmath139 we will also make use of the number @xmath140 of edges of the form @xmath141 which can be computed by induction : @xmath142    let us now describe vector fields on this graph .",
    "in the previous section a function @xmath143 has been defined on edges of @xmath144 we will consider here @xmath143 as a vector field on @xmath145      let us first recall some classical definitions .",
    "a vector field on @xmath146 is a function @xmath147 such that @xmath148 and such that , for any @xmath49 , @xmath149 .",
    "we say that the vector field @xmath150 on @xmath40 is a gradient vector field if there exists a function @xmath32 on the vertices of @xmath40 such that for each edge @xmath151 , @xmath152 .",
    "the gradient vector field associated with @xmath32 is denoted by @xmath153 .",
    "the divergence of a vector field @xmath150 at point @xmath154 is defined by    @xmath155    we say that a vector field @xmath150 is divergence - free if its divergence vanishes at all points",
    ".    we can endow the set of vector fields with a scalar product @xmath156    please note that the sum runs over all edges , including loops @xmath157 .",
    "denote also , for any subsets @xmath158 of @xmath159 , @xmath160 the flux of @xmath150 going from @xmath161 to @xmath162 . note that a divergence free field @xmath163 verifies @xmath164      in analogy with the case of vector fields in euclidean spaces",
    ", we can decompose any vector field on @xmath40 into the sum of a gradient vector field and a divergence - free field .",
    "the following proposition is well - known .",
    "[ prop_dec_usual ] let @xmath150 be a vector field on @xmath40 .",
    "there exist a unique gradient vector field @xmath153 and a unique divergence - free field @xmath163 such that    @xmath165    moreover @xmath166    the last identity simply means that gradient fields and divergence - free fields are orthogonal complements of each other in the vector space of vector fields over @xmath40 .",
    "in our case we are interested in stationary vector fields .",
    "[ def : stat ] a subgraph @xmath167 of the complete graph on @xmath168 is _ stationary _ , if the following holds . for @xmath169 and @xmath170 such that @xmath171 if @xmath172 is an edge of @xmath167 , then @xmath173 is an edge of @xmath167 .",
    "a vector field @xmath150 defined on a subgraph of the complete graph on @xmath168 with a stationary domain is _ stationary _ if for all @xmath174 edges of @xmath167 , @xmath175 only depends on @xmath176 ( where @xmath168 is embedded in @xmath177 in an obvious way ) .    note that , thanks to the construction of @xmath48 , it is stationary . moreover if @xmath178 and @xmath179 , then @xmath180 and thus the vector field @xmath181 taking values @xmath56 , resp .",
    "@xmath57 , on @xmath182 , resp .",
    "@xmath51 , is stationary .",
    "so we may expect the gradient vector field @xmath183 in the hodge decomposition of @xmath143 to be stationary .",
    "unfortunately if @xmath150 is a stationary vector field on @xmath40 and its decomposition is @xmath184 as per proposition [ prop_dec_usual ] , then @xmath153 is not always stationary .",
    "nevertheless it turns out that the gradient vector field @xmath183 in the hodge decomposition of @xmath143 is actually stationary as it will be shown in the next section .",
    "let us recall the definition  [ def : a ] the vector field @xmath181 on @xmath40 is such that @xmath185 in this section our aim is to compute a function @xmath186 such that @xmath187 one can first remark that @xmath188 @xmath189 in the previous equation we used the notation @xmath190 for cardinality of sets .",
    "we will introduce various notations related to other cardinalities @xmath191 then we need also to define for @xmath192 @xmath193 the number of the vertices @xmath194 such that @xmath195 with @xmath196 digits @xmath197 such that @xmath198 similarly @xmath199 is the number of the vertices @xmath194 such that @xmath200 and @xmath196 digits @xmath197 such that @xmath201 then we consider @xmath202 and @xmath203 similarly @xmath204 and @xmath205    let us consider the function @xmath206 on @xmath207 such that @xmath208 the last equation is trivial since @xmath209 is the number of the @xmath210s equal to @xmath211 and @xmath212 the number of @xmath210s equal to @xmath213 obviously we also get @xmath214 for any vertex @xmath122 in @xmath215 let us remark that for any function @xmath186 on @xmath159 @xmath216 since @xmath217 yields the sum of the digits of any vertex , we first observe that if @xmath218 and the number of digits @xmath197 such that @xmath219 is even then @xmath220 if the number of digits @xmath197 such that @xmath219 is odd and @xmath221 then @xmath222 one can then deduce that @xmath223    it turns out that if we consider the function @xmath224 on @xmath207 such that @xmath225 then @xmath226 we will prove   by induction on @xmath227 to do that we split @xmath228 into the sum of two functions @xmath229 to proceed the induction argument we remark that for any vertex @xmath122 in @xmath159 @xmath230 we will then compute @xmath231 the easiest computation is @xmath232 since @xmath233 then @xmath234 to evaluate @xmath235 we use that @xmath212 is the number of digits equal to @xmath236 in @xmath237 if @xmath238 and if the number of @xmath239 is even then @xmath240 if this number is odd then @xmath241 therefore @xmath242 hence @xmath243 one also get in the same way @xmath244 the induction is a bit more involved for @xmath245 because of   @xmath246 then @xmath247 hence @xmath248 similarly we get @xmath249 we can now evaluate the functions @xmath250    [ lem : phi_barphi ]",
    "@xmath251 @xmath252 @xmath253    we will only sketch the proof performed by an easy induction on @xmath26 for @xmath254 computations are similar for @xmath255 let us assume that  , hold for @xmath256 we have to compute @xmath257 and @xmath258 and check that they fulfill  , for @xmath259 because of   @xmath260 one can check that @xmath261 using   for @xmath256 we get   for @xmath262 and @xmath263 the computations for @xmath258 are left to the reader .    by summing   and",
    "we get  , and we deduce that if we take @xmath264 @xmath265 is divergence free",
    ". please note that obviously the additive constant in   is arbitrary but it yields the following convenient expression of @xmath266 in terms of the digits of @xmath267    [ lem : form - grad a ] @xmath268 where @xmath269 moreover @xmath183 is a stationary gradient vector field .    since we already know",
    "that @xmath270 it is enough to show by induction on @xmath26 that @xmath271 obviously the formula is true for @xmath272 because of   and  , @xmath273 hence   is proved for @xmath274 owing to @xmath270 and  , it is obvious that @xmath275 are stationary and consequently @xmath183 is a stationary gradient vector field .",
    "we denote by @xmath276 the decomposition of @xmath143 as per proposition [ prop_dec_usual ] .    back to the original problem , we recall that @xmath277    let us denote @xmath278 .",
    "let @xmath279 , we have    @xmath280 = ( \\nabla \\cdot b)(y_n ) = 0,\\ ] ] and @xmath281 is a martingale .",
    "we now sketch out how to apply the central limit theorem for markov chains .",
    "let @xmath282 @xmath283 is a markov chain on @xmath54 then our quantity of interest @xmath284 is an additive observable of the process @xmath283 , as    @xmath285    the central limit theorem for markov chains ( see e.g. @xcite ) shows that @xmath286 converges as @xmath287 to a brownian motion , with variance given by    @xmath288 \\\\              & =   \\lim_{n \\rightarrow + \\infty } \\frac{1}{n } \\mathbb{e } \\left[m_n^2\\right]+ \\lim_{n \\rightarrow + \\infty } \\frac{1}{n } \\mathbb{e } \\left [ f(y_n)^2\\right ] + \\lim_{n \\rightarrow + \\infty } \\frac{2}{n } \\mathbb{e } \\left[\\left(f(y_n ) m_n \\right)\\right].\\end{aligned}\\ ] ]    let us first compute @xmath289.$ ] we can remark that @xmath290 is a @xmath291 martingale , hence @xmath292=\\lim_{n \\rightarrow + \\infty } \\frac{1}{n } \\mathbb{e } \\left [ \\sum_{i = 0}^{n-1 } \\big(b(y_i , y_{i+1 } )    \\big)^2\\right].$ ]    if @xmath293 denotes the invariant measure for the random walk @xmath294 , by ergodicity , we get @xmath295=\\mathbb{e}_\\mu \\left[\\left(b(y_0 , y_1)\\right)^2\\right].\\ ] ]    under @xmath296 the distribution of @xmath297 is uniform on @xmath298 because @xmath299 is uniformly chosen among all neighbours of @xmath300 hence @xmath301 using that @xmath32 does not depend on @xmath302 we obtain @xmath303 = 0,\\ ] ] and by cauchy schwarz inequality and   @xmath304=0.\\ ] ]    so we get @xmath305,\\ ] ]    and by ergodicity , @xmath306.\\ ] ]    since , under @xmath307 the distribution of @xmath297 is uniform on @xmath298 @xmath308    by orthogonality of @xmath163 and @xmath153 ,    @xmath309    thus , it remains to compute @xmath310 ( since @xmath311 , by definition ) .    at this point",
    "we use the fact that @xmath153 is a stationary field , in the sense of definition  [ def : stat ] .",
    "then if we denote by @xmath312 ( where @xmath57 is in @xmath120-th position ) and , for @xmath313 , we have by   @xmath314 now we compute @xmath310 as a function of @xmath315 , the value @xmath153 on the edge @xmath316 .    by   @xmath317 if @xmath318 and @xmath319 , then using the relation between @xmath320 and @xmath321 @xmath322 by stationarity of @xmath323 @xmath324    then , because of the definition of @xmath325 and @xmath326 @xmath327 then by stationarity of @xmath153 @xmath328    in the proof , the way we guessed   is a bit mysterious . assuming that @xmath183 is a stationary gradient vector field , the family @xmath329}$ ] can be computed considering the system of equations given by @xmath330 , j_{m_i , n_i } = 0,\\ ] ] where @xmath331 } \\in v_k , a_i = 1\\right\\}$ ] and @xmath332 } \\in v_k , a_i = -1\\right\\}$ ] .",
    "this leads to the following system : @xmath333    f = \\left[\\begin{matrix}3^{k-1 }   \\\\                    3^{k-2 }   \\\\",
    "\\vdots    \\\\ 3   \\\\",
    "1\\end{matrix } \\right].\\ ] ]    the unique solution is given by :    @xmath334    even if the guess is correct , we did not find another way as the techniques used in the section  [ sec : hodge - a ] to show that @xmath183 is a stationary gradient vector field .",
    "in this final section we briefly outline some related problems .",
    "* it is possible to make sense of the process when @xmath5 is infinite .",
    "several questions arise : what happens to the process of one marked walker  ?",
    "is there a scaling limit under equilibrium for the `` shape''process @xmath335 ?",
    "+ another natural step would be to let @xmath5 grow with @xmath336 in a suitable way , so as to get a scaling limit for the two - parameter process @xmath337 .",
    "* one may also ask about different quantities , such as the diameter of the set of walkers under the invariant measure for the entire walk .",
    "* one may also consider random walkers conditioned on satisfying different shape constraints , and on graphs more general than @xmath3 . as a starting example , what happens if we work on a torus , i.e. if we force also @xmath338 ? the  shape  chain changes in this case and it is no longer irreducible over @xmath339 ( one may check that the number of @xmath57 symbols is fixed , and that this enumerates the recurrence classes ) .",
    "it is interesting to point out that this setup is the one chosen by e. lieb for the computation of the  six - vertex constant  in @xcite .",
    "we warmly thank charles bordenave for fruitful conversations and useful comments ."
  ],
  "abstract_text": [
    "<S> we consider a random walk @xmath0 with the constraint that each coordinate of the walk is at distance one from the following one . in this paper , we show that this random walk is slowed down by a variance factor @xmath1 with respect to the case of the classical simple random walk without constraint .    </S>",
    "<S> _ keywords _ : random walk , graph , central limit theorem    _ ams classification ( 2000 ) _ : 05c81 , 60f05 . </S>"
  ]
}