{
  "article_text": [
    "in this paper we consider the problem of designing distributed protocols for a dynamic heterogeneous storage system .",
    "many solutions for distributed storage systems have already been proposed in the literature . in the peer - to - peer area ,",
    "distributed hash tables ( dhts ) have been the most popular choice . in a dht ,",
    "data elements are mapped to hosts with the help of a hash function , and the hosts are organized in an overlay network that is often of hypercubic nature so that messages can be quickly exchanged between any two hosts . to be able to react to dynamics in the set of hosts and their capacities , a distributed storage system should support , on top of the usual data operations , operations to join the system , to leave the system , and to change the capacity of a host in the desired way .",
    "we present self - stabilizing protocols that can handle all of these operations in an efficient way .",
    "many data management strategies have already been proposed for distributed storage systems .",
    "if all hosts have the same capacity , then a well - known approach called _ consistent hashing _ can be used to manage the data @xcite . in consistent hashing ,",
    "the data elements are hashed to points in @xmath0 , and the hosts are mapped to disjoint intervals in @xmath0 , and a host stores all data elements that are hashed to points in its interval . an alternative strategy is to hash data elements and hosts to pseudo - random bit strings and to store ( indexing information about ) a data element at the host with longest prefix match @xcite .",
    "these strategies have been realized in various dhts including can @xcite , pastry @xcite and chord @xcite .",
    "however , all of these approaches assume hosts of uniform capacity , despite the fact that in p2p systems the peers can be highly heterogeneous .    in a heterogeneous setting , each host ( or node ) @xmath1 has its specific capacity @xmath2 and the goal considered in this paper is to distribute the data among the nodes so that node @xmath1 stores a fraction of @xmath3 of the data . the simplest solution would be to reduce the heterogeneous to the homogeneous case by splitting a host of @xmath4 times the base capacity ( e.g. , the minimum capacity of a host ) into @xmath4 many virtual hosts .",
    "such a solution is not useful in general because the number of virtual hosts would heavily depend on the capacity distribution , which can create a large management overhead at the hosts .",
    "nevertheless , the concept of virtual hosts has been explored before ( e.g. , @xcite ) . in @xcite",
    "the main idea is not to place the virtual hosts belonging to a real host randomly in the identifier space but in a restricted range to achieve a low degree in the overlay network .",
    "however , they need an estimation of the network size and a classification of nodes with high , average , and low capacity . a similar approach is presented in @xcite .",
    "rao et al .",
    "@xcite proposed some schemes also based on virtual servers , where the data is moved from heavy nodes to light nodes to balance the load after the data assignment , so and data movement is induced even without joining or leaving nodes . in @xcite",
    "the authors organize the nodes into clusters , where a super node ( i.e. , a node with large capacity ) is supervising a cluster of nodes with small capacities .",
    "giakkoupis et al .",
    "@xcite present an approach which focuses on homogeneous networks but also works for heterogeneous one .",
    "however , updates can be costly .",
    "several solutions have been proposed in the literature that can manage heterogeneous storage systems in a centralized way , i.e. they consider data placement strategies for heterogeneous disks that are managed by a single server  @xcite or assume a central server that handles the mapping of data elements to a set of hosts  @xcite .",
    "we will only focus on the most relevant ones for our approach . in @xcite brinkmann et al .",
    "introduced several criteria a placement scheme needs to fulfill , like a faithful distribution , efficient localization , and fast adaptation .",
    "they introduce two different data placement strategies named share and sieve that fulfill their criteria . to apply their approach , the number of nodes and the overall capacity of the system must be known .",
    "in @xcite redundancy is added to the share strategy to allow a fair and redundant data distribution , i.e. several copies of a data element are stored such that no two copies are stored on the same host . another solution to handle redundancy in heterogeneous systems",
    "is proposed in @xcite , but also here the number of nodes and the overall capacity of the system must be known .",
    "the only solution proposed so far where this is not the case is the approach by schindelhauer and schomaker @xcite , which we call _ cone hashing_. their basic idea is to assign a distance function to each host that scales with the capacity of the host .",
    "a data element is then assigned to the host of minimum distance with respect to these distance functions .",
    "we will extend their construction into a self - stabilizing dht with low degree and diameter that does not need any global information and that can handle all operations in a stable system efficiently with high probability ( w.h.p . ) for any constant @xmath5 .",
    "a central aspect of our self - stabilizing dht is a self - stabilizing overlay network that can be used to efficiently check the correct distribution of the data among the hosts and that also allows efficient routing .",
    "there is a large body of literature on how to efficiently maintain overlay networks , e.g. , @xcite .",
    "while many results are already known on how to keep an overlay network in a legal state , far less is known about self - stabilizing overlay networks .",
    "a self - stabilizing overlay network is a network that can recover its topology from an arbitrary weakly connected state .",
    "the idea of self - stabilization in distributed computing was introduced in a classical paper by e.w .",
    "dijkstra in 1974 @xcite in which he looked at the problem of self - stabilization in a token ring .",
    "in order to recover certain network topologies from any weakly connected state , researchers have started with simple line and ring networks ( e.g. @xcite ) . over the years",
    "more and more network topologies were considered @xcite . in @xcite",
    "the authors present a self - stabilizing algorithm for the chord dht @xcite , which solves the uniform case , but the problem of managing heterogeneous hosts in a dht was left open , which is addressed in this paper . to the best of our knowledge",
    "this is the first self - stabilizing approach for a distributed heterogeneous storage system .    in this paper",
    "we present a self - stabilizing overlay network for a distributed heterogeneous storage system based on the data assignment presented in @xcite .",
    "we assume an asynchronous message passing model for the cone - dht which is related to the model presented in @xcite by nor et al .",
    "the overlay network consists of a static set @xmath6 of @xmath7 nodes or hosts .",
    "we further assume _ fixed identifiers _ ( ids ) for each node .",
    "these identifiers are _ immutable _ in the computation , we only allow identifiers to be compared , stored and sent . in our model the identifiers are used as addresses , such that by knowing the identifier of a node another node can send messages to this node .",
    "the identifiers form a unique order .",
    "the communication between nodes is realized by passing messages through channels .",
    "a node @xmath8 can send a message to @xmath1 through the channel @xmath9 .",
    "we denote the channel @xmath10 as the union of all channels @xmath9 .",
    "we assume that the capacity of a channel is unbounded and no messages are lost .",
    "furthermore we assume that for a transmission pair @xmath11 the messages sent by @xmath8 are received by @xmath1 in the same order as they are sent , i.e. @xmath9 is a fifo channel .",
    "note that this does not imply any order between messages from different sending nodes . for the channel",
    "we assume _ eventual delivery _ meaning that if there is a state in the computation where there is a message in the channel @xmath10 there also is a later state where the message is not in the channel , but was received by the process .",
    "we distinguish between the _ node state _",
    ", that is given by the set of identifiers stored in the internal variables @xmath1 can communicate with , and the _ channel state _",
    ", that is given by all identifiers contained in messages in a channel @xmath10 .",
    "we model the network by a directed graph @xmath12 .",
    "the set of edges @xmath13 describes the possible communication pairs .",
    "@xmath13 consists of two subsets : the _ explicit edges _ @xmath14 and the _ implicit edges _",
    "@xmath15 , i.e. @xmath16 . moreover we define @xmath17 .",
    "an action has the form @xmath18 .",
    "_ guard _ is a predicate that can be true or false . _",
    "command _ is a sequence of statements that may perform computations or send messages to other nodes .",
    "we introduce one special guard predicate @xmath19 called the _ timer predicate _ , which is periodically true ; i.e. according to an internal clock @xmath19 becomes true after a number of clock cycles and is false the other times , and allows the nodes to perform periodical actions .",
    "a second predicate is true if a message is received by a node .",
    "the _ program state _ is defined by the node states and the channel states of all nodes , i.e. the assignment of values to every variable of each node and messages to every channel .",
    "we call the combination of the node states of all nodes the _ node state of the system _ and the combination of the channel states of all nodes is called the _ channel state of the system_. an action is enabled in some state if its guard is true and disabled otherwise .",
    "computation _ is a sequence of states such that for each state @xmath20 the next state @xmath21 is reached by executing an enabled action in @xmath20 . by this definition , actions can not overlap and are executed atomically giving a sequential order of the executions of actions . for the execution of actions we assume _ weak fairness _ meaning that if an action is enabled in all but finitely many states of the computation then this action is executed infinitely often .",
    "we state the following requirements on our solution : _ fair load balancing _ : every node with x% of the available capacity gets x% of the data . _ space efficiency _ : each node stores at most + @xmath22 information . _",
    "routing efficiency _ : there is a routing strategy that allows efficient routing in at most @xmath23 hops .",
    "_ low degree _ : the degree of each node is limited by @xmath23 . furthermore we require an algorithm that builds the target network topology in a _ self - stabilizing _ manner , i.e. , any weakly connected network @xmath24 is eventually transformed into a network so that a ( specified ) subset of the explicit edges forms the target network topology ( _ convergence _ ) and remains stable as long as no node joins or leaves ( _ closure _ ) .",
    "we present a self - stabilizing algorithm that organizes a set of heterogeneous nodes in an overlay network such that each data element can be efficiently assigned to the node responsible for it .",
    "we use the scheme described in @xcite ( which gives us good load balancing ) as our data management scheme and present a distributed protocol for the overlay network , which is efficient in terms of message complexity and information storage and moreover works in a self - stabilizing manner .",
    "the overlay network efficiently supports the basic operations of a heterogeneous storage system , such as the joining or leaving of a node , changing the capacity of a node , as well as searching , deleting and inserting a data element .",
    "in fact we show the following main result :    [ theo : main ] there is a self - stabilizing algorithm for maintaining a heterogeneous storage system that achieves fair load - balancing , space efficiency and routing efficiency , while each node has a degree of @xmath23 w.h.p .",
    "the data operations can be handled in @xmath25 time in a stable system , and if a node joins or leaves a stable system or changes its capacity , it takes at most @xmath26 structural changes , i.e. , edges that are created or deleted , until the system stabilizes again .",
    "the paper is structured as follows : in section  [ cone - dht ] we describe our target network and its properties . in section  [ alg ]",
    "we present our self - stabilizing protocol and prove that it is correct .",
    "finally , in section  [ ops ] we describe the functionality of the basic network operations .",
    "before we present our solution , we first give some more details on the original cone - hashing @xcite our approach is based on . in @xcite the authors present a centralized solution for a heterogeneous storage system in which the nodes are of different capacities .",
    "we denote the capacity of a node @xmath1 as @xmath2 .",
    "we use a hash function @xmath27 that assigns to each node a hash value .",
    "a data element of the data set @xmath28 is also hashed by a hash function @xmath29 .",
    "we assume that all hash values and capacities are distinct . according to @xcite each node",
    "has a capacity function @xmath30 , which determines which data is assigned to the node .",
    "a node is _ responsible _ for those elements @xmath31 with @xmath32 , i.e. @xmath31 is assigned to @xmath1 .",
    "we denote by @xmath33 the _ responsibility range _ of @xmath1 ( see figure  [ example ] ) .",
    "note that @xmath34 can consist of several intervals in @xmath0 . in the original paper @xcite , the authors considered two special cases of capacity functions , one of linear form @xmath35 and of logarithmic form @xmath36 . for these capacity functions",
    "the following results were shown by the authors @xcite :    [ theo : coneoriginal1 ] a data element @xmath31 is assigned to a node @xmath1 with probability @xmath37 for linear capacity functions @xmath38 and with probability @xmath39 for logarithmic capacity functions @xmath40 .",
    "thus in expectation fair load balancing can be achieved by using a logarithmic capacity function @xmath40 .",
    "the cone - hashing supports the following operations for a data element @xmath31 or a node @xmath8 :    * _ search(d ) _ : returns the node @xmath1 such that @xmath41 . * _ insert(d ) _ :",
    "@xmath31 is assigned to the node returned by @xmath42 . * _ delete(d ) _ : @xmath31 is removed from the node returned by @xmath42 . * _ join(v ) _ : for all @xmath43 the responsibility ranges @xmath34 are updated and data elements @xmath31 , with @xmath44 are moved to @xmath8 . * _ leave(v ) _ : for all @xmath43 the responsibility ranges @xmath34 are updated and data elements @xmath31 assigned to @xmath8 are moved to nodes @xmath45 such that @xmath46 . * _ capacitychange(v ) _ : for all @xmath43 the responsibility ranges @xmath34 are updated and data elements @xmath31 not assigned to @xmath8 , but with @xmath44 are moved to @xmath8 while data elements @xmath47 assigned to @xmath8 but with @xmath46 are moved to nodes @xmath45 .",
    "moreover , the authors showed that the fragmentation is relatively small for the logarithmic capacity function , with each node having in expectation a logarithmic number of intervals it is responsible for .",
    "in the case of the linear function , it can be shown that this number is only constant in expectation .    in @xcite",
    "the authors further present a data structure to efficiently support the described operations in a centralized approach . for their data structure they showed that there is an algorithm that determines for a data element @xmath31 the corresponding node @xmath1 with @xmath48 in expected time @xmath49 .",
    "the used data structure has a size of @xmath50 and the joining , leaving and the capacity change of a node can be handled efficiently . in the following",
    "we show that cone - hashing can also be realized by using a distributed data structure .",
    "further the following challenges have to be solved .",
    "we need a suitable topology on the node set @xmath6 that supports an efficient determination of the responsibility ranges @xmath34 for each node @xmath1 .",
    "the topology should also support an efficient _ search(d ) _ algorithm , i.e. for an _",
    "search(d ) _ query inserted at an arbitrary node @xmath45 , the node @xmath8 with @xmath51 should be found .",
    "furthermore a _",
    "join(v ) _ , _",
    "leave(v ) _ , _ capacitychange(v )",
    "_ operation should not lead to a high amount of data movements , ( i.e. not more than the data now assigned to @xmath8 or no longer assigned to @xmath8 should be moved , ) or a high amount of structural changes ( i.e. changes in the topology built on @xmath6 ) .",
    "all these challenges will be solved by our cone - dht .      in order to construct a heterogeneous storage network in the distributed case , we have to deal with the challenges mentioned above .",
    "for that , we introduce the _ cone_-graph , which is an overlay network that , as we show , can support efficiently a heterogeneous storage system .",
    "we define the _ cone _ graph as a graph @xmath52 , with @xmath6 being the hosts of our storage system .    for the determination of the edge set ,",
    "we need following definitions , with respect to a node @xmath1 :    * @xmath53 is the next node at the right of @xmath1 with larger capacity , and we call it the first larger successor of @xmath1 . building upon this , we define recursively the i - th larger successor of @xmath1 as : @xmath54 , and the union of all larger successors as @xmath55 . * the first larger predecessor of @xmath1 is defined as : @xmath56 i.e. the next node at the left of @xmath1 with larger capacity .",
    "the i - th larger predecessor of @xmath1 is : @xmath57 , and the union of all larger predecessors as @xmath58 .",
    "* we also define the set of the smaller successors of @xmath1 , @xmath59 , as the set of all nodes @xmath8 , with @xmath60 , and the set of the smaller predecessors of @xmath1 , @xmath61 as the set of all nodes @xmath8 , such that @xmath62 .",
    "now we can define the edge - set of a node in @xmath63 .",
    "@xmath64 iff @xmath65    we define also the neighborhood set of @xmath1 as @xmath66 . in other words",
    ", @xmath8 maintains connections to each node @xmath1 , if there does not exist another node with larger capacity than @xmath1 between @xmath8 and @xmath1 ( see figure  [ example3 ] ) .",
    "we will prove that this graph is sufficient for maintaining a heterogeneous storage network in a self - stabilizing manner and also that in this graph the degree is bounded logarithmically w.h.p ..      we discussed above how the data is assigned to the different nodes .",
    "that is the assignment strategy we use for data in the _ cone_-network .    in order to understand how the various data operations are realized in the network",
    ", we have to describe how each node maintains the knowledge about the data it has , as well as the intervals it is responsible for .",
    "it turns out that in order for a data item to be forwarded to the correct node , which is responsible for storing it , it suffices to contact the closest node ( in terms of hash value ) from the left to the data item s hash value .",
    "that is because then , if the _ cone _ graph has been established , this node ( for example node @xmath1 in figure  [ example ] ) is aware of the responsible node for this data item .",
    "we call the interval between @xmath67 and the hash value of @xmath1 s closest right node @xmath68 .",
    "we say that @xmath1 is _ supervising _ @xmath68 .",
    "we show the following theorem .",
    "[ theo : responsibility ] in @xmath63 a node @xmath1 knows all the nodes v with @xmath69 .",
    "we need to show that all these nodes @xmath69 are in @xmath70 @xmath71 .",
    "w.l.o.g . let us consider only the case of @xmath72 .",
    "indeed , there can not be a node at the right of @xmath1 ( @xmath73 ) that has a responsible interval in @xmath1 s supervising interval and that is not in @xmath74 or @xmath75.we will prove it by contradiction .",
    "let @xmath76 be such a node .",
    "for @xmath76 not to be in @xmath75 or @xmath74 there must be at least one node @xmath8 larger ( in terms of capacity ) than @xmath76 , which is closer to @xmath1 than @xmath76 ( @xmath77 )",
    ". then @xmath78 it holds that @xmath79 , since @xmath80 is increasing .",
    "moreover , since @xmath81 we have @xmath82 , so @xmath8 dominates @xmath76 for @xmath83 . and",
    "since @xmath84 , it can not be that @xmath76 is responsible for an interval in @xmath68 , since in that region @xmath76 is dominated ( at least ) by @xmath8 .",
    "this contradicts the hypothesis and the proof is completed .",
    "so , the nodes store their data in the following way . if a node @xmath1 has a data item that falls into one of its responsible intervals , it stores in addition to this item a reference to the node @xmath8 that is the closest from the left to this interval .",
    "moreover , the subinterval @xmath1 thinks it is responsible for ( in which the data item falls ) is also stored ( as described in the next section , when the node s internal variables are presented ) . in case the data item is not stored at the correct node , @xmath8 can resolve the conflict when contacted by @xmath1 .",
    "now we can discuss the functionality of the data operations .",
    "a node has operations for inserting , deleting and searching a datum in the cone - network .",
    "let us focus on @xmath85 a data item .",
    "as shown above , it suffices to search for the left closest node to the data item s hash value .",
    "we do this by using greedy routing .",
    "greedy routing in the _",
    "cone_-network works as follows : if a search request wants to reach some position @xmath86 in @xmath0 , and the request is currently at node @xmath1 , then @xmath1 forwards @xmath87 to the node @xmath8 in @xmath88 that is closest to @xmath86 , until the closest node at the left of @xmath86 is reached .",
    "then this node will forward the request to the responsible node .",
    "a more formal definition of the greedy routing follows :    the cone greedy routing strategy is defined as : if operation op is to be executed at position @xmath86 in @xmath89 $ ] and op is currently at node @xmath1 , then @xmath1 forwards op to the node @xmath8 such that @xmath90 if @xmath91 or @xmath1 forwards op to the node @xmath8 such that @xmath92 if @xmath93 .",
    "if @xmath94 and @xmath91 , then @xmath95 and @xmath1 forwards @xmath96 to the node responsible for the subinterval containing pos . if @xmath94 and @xmath93 then @xmath1 forwards op to @xmath97 $ ] as @xmath86 is in its supervised interval",
    ".    in that way we can route to the responsible node and",
    "then get an answer whether the data item is found or not , and so the searching is realized .",
    "note that the @xmath98 of a data item can be realized in the same way , only that when the item is found , it is also deleted from the responsible node .",
    "@xmath99 an item follows a similar procedure , with the difference that when the responsible node is found , the data item is stored by it .",
    "moreover , the network handles efficiently structural operations , such as the joining and leaving of a node in the network , or the change of the capacity of a node .",
    "since this handling falls into the analysis of the self - stabilization algorithm , we will discuss the network operations in section  [ alg ] , where we also formally analyze the algorithm .",
    "it turns out that a single data or network operation ( i.e greedy routing ) can be realized in a logarithmic number of hops in the _ cone_-network , and this happens due to the structural properties of the network , which we discuss in the next section , where we also show that the degree of the _ cone_-network is logarithmic .      in this section",
    "we show that the degree of a node in a stable cone - network is bounded by @xmath23 w.h.p , and hence the information stored by each node ( i.e the number of nodes which it maintains contact to , @xmath100 ) is bounded by @xmath101 w.h.p",
    "..    first we show following lemma :    [ log ] in a stable cone network for each @xmath102 , @xmath103 and @xmath104 in @xmath23 w.h.p .",
    "for an arbitrary @xmath102 let @xmath105 and let @xmath106 be sorted by ids in ascending order , such that @xmath107 for all @xmath108 .",
    "furthermore , let @xmath109 be the set of all nodes with larger ids and larger capacities than @xmath110 .",
    "so , the determination of @xmath106 is done by continuously choosing the correct @xmath110 out of @xmath111 , when @xmath112 are already chosen . in this process , each time a @xmath110 is determined , the number of nodes from which @xmath113 can be chosen is getting smaller , since the nodes at the left of @xmath110 as well as the nodes with smaller capacity than @xmath110 can be excluded .",
    "we call the choice of @xmath114 _ good _ , if @xmath115 , i.e. the number of remaining nodes in @xmath116 is ( at least ) halved",
    ". let @xmath117 . since the id / position for each node is assigned uniformly at random , we can easily see that pr[@xmath110 is a good choice]@xmath118 . then after a sequence of @xmath119 choices that contains @xmath120 good choices the remaining set @xmath116 is the empty set . thus there can not be more than @xmath120 good choices in any sequence of choices .",
    "so , what we have now is a random experiment , that is described by the random variable @xmath4 , that is equal to the number choices we must make , until we managed to have made @xmath120 good ones . then the random variable",
    "@xmath4 follows the negative binomial distribution . in order to bound the value of @xmath4 from above",
    "we apply the following tail bound for negative binomially distributed random variables shown in @xcite , derived by using a chernoff bound :    let @xmath121 have the negative binomial distribution with parameters @xmath122 and @xmath123 , i.e. with probability @xmath123 there is a success and @xmath121 is equal to the number of trials needed for @xmath122 successes . pick @xmath124 $ ] and set @xmath125",
    ". then @xmath126\\leq exp(\\frac{-\\delta^{2}s}{3(1-\\delta)})$ ]    we apply this claim with @xmath127 and @xmath128 and we pick @xmath129",
    ". then @xmath130\\leq \\exp(\\frac{-\\delta^{2}2\\log m}{3(1-\\delta)})<m^{- 2}$ ] . thus with probability at least @xmath131 , @xmath132 as @xmath133 also @xmath134 .    in a stable cone network for each @xmath102 , @xmath135 $ ] and @xmath136 $ ] are @xmath137 and @xmath138 and @xmath139 are @xmath23 w.h.p ..    w.l.o.g .",
    "we consider only @xmath135 $ ] and @xmath140 in the proof .",
    "for each node @xmath141 being in an interval @xmath59 it holds @xmath142 .",
    "but since each node has ( at most ) one @xmath143 , the sum over all @xmath144 , @xmath145 must be ( at most ) @xmath7 .",
    "so we have @xmath146 , so @xmath147=n$ ] @xmath148 @xmath149=n $ ] .",
    "that means for a node @xmath1 , @xmath150=1 $ ] .",
    "now we consider the second part of the statement .",
    "let @xmath45 be the direct right neighbor of @xmath1 , i.e. the first ( from the left ) node in @xmath59 ( @xmath151 $ ] ) .",
    "then we can observe that every node in @xmath59 ( expect @xmath45 ) must be in @xmath152 .",
    "let us assume a node @xmath141 is in @xmath152 but not in @xmath59 , then there must be another node @xmath153 and @xmath154 , such that @xmath155 .",
    "but then @xmath156 would be also in @xmath152 instead of @xmath141 .",
    "so , we contradicted this scenario .",
    "as a consequence @xmath157 , but we already shown that @xmath158 w.h.p . , from which follows that @xmath159 w.h.p ..    combining the two lemmas we get the following theorem .",
    "[ theo : degree ] the degree of each node in a stable cone network is @xmath23 w.h.p .    additionally to the nodes in @xmath74 , @xmath75 , @xmath160 and",
    "@xmath161 that lead to the degree of @xmath23 w.h.p .",
    "a node @xmath1 only stores references about the closest nodes left to the intervals it is responsible for , where it actually stores data . a node @xmath1 stores at most one reference and one interval for each data item .",
    "thus the storage only has a logarithmic overhead for the topology information and the following theorem follows immediately .",
    "[ theo : storage ] in a stable cone network each node stores at most @xmath101 information w.h.p .",
    "once the cone network @xmath63 is set up , it can be used as an heterogeneous storage system supporting inserting , deleting and searching for data .",
    "the cone greedy routing implies the following bound on the diameter :    [ lem : routing ] cone greedy routing takes on a stable cone network w.h.p .",
    "no more than a logarithmic number of steps , i.e. the diameter of a cone network is @xmath23 w.h.p ..",
    "this follows directly from lemma [ log ] , where we showed that each node @xmath1 has w.h.p . a logarithmic number of nodes in @xmath162 , which means it has a logarithmic distance to the node with the greatest capacity , and vice versa , which means that the node with the greatest capacity has logarithmic distance to every node in the network .",
    "the proof for the cone greedy routing follows from a generalization of this observation .",
    "if an operation @xmath96 with position @xmath95 is currently at node @xmath8 w.l.o.g .",
    "we assume @xmath163 , then @xmath96 is forwarded at most @xmath23 times w.h.p .",
    "( along nodes in @xmath164 ) to a node @xmath45 such that @xmath165 and further @xmath23 times w.h.p .",
    "( along nodes in @xmath75 ) from @xmath45 to @xmath1 .     and @xmath8 , we can see by the coloring which interval is assigned to which node ( the one having the lowest capacity function value at that interval ) . according to the _ cone_-graph",
    ", @xmath1 must be aware of all these nodes ( @xmath166 and @xmath141).,title=\"fig:\"][example ]     is aware of @xmath166 and @xmath141 .",
    "in fact , @xmath167 , title=\"fig:\"][example3 ]",
    "we now formally describe the problem of topological self - stabilization . in topological self - stabilization",
    "the goal is to state a protocol _",
    "p _ that _ solves _ an overlay problem _ op _ starting from an initial topology of the set _",
    "it_. a protocol is _ unconditionally _ self - stabilizing if _ it _ contains every possible state .",
    "analogously a protocol is _ conditionally _ self - stabilizing if _ it _ contains only states that fulfill some conditions . for topological self - stabilization",
    "we assume that _ it _ contains any state as long as @xmath168 is weakly connected , i.e. the combined knowledge of all nodes in this state covers the whole network , and there are no identifiers that do nt belong to existing nodes in the network .",
    "the set of target topologies defined in _",
    "op _ is given by @xmath169 , i.e. the goal topologies of the overlay problem are only defined on explicit edges and @xmath170 can be an arbitrary ( even empty ) set of edges .",
    "we also call the program states in _ op _ _ legal states_. we say a protocol _",
    "p _ that solves a problem _ op _ is topologically self - stabilizing if for _ p _ _ convergence _ and _ closure _ can be shown .",
    "_ convergence _ means that _ p _ started with any state in _ it _ reaches a legal state in _",
    "op_. _ closure _ means that _ p _ started in a legal state in _ op _ maintains a legal state . for a protocol _",
    "p _ we assume that there are no oracles available for the computation .",
    "in particular we assume there to be no _ connection oracle _",
    ", that can connect disconnected parts of the network , no _ identifier detector _",
    ", that can decide whether an identifier belongs to an existing node or not , and no _ legal state detector _",
    ", that can decide based on global knowledge whether the system is in a legal state or not . with these assumptions",
    "our model complies with the _ compare - store - send _ program model in @xcite in which protocols do not manipulate the internals of the nodes identifiers . for",
    "our modified model the impossibility results of @xcite still hold such as lemma 1 that states if the graph @xmath171 is initially disconnected , then the graph is disconnected in every state of the computation .",
    "furthermore theorem 1 states that if the goal topology is a single component a program only solves the problem if the initial graph is weakly connected .",
    "now we define the problem we solve in this paper in the previously introduced notation .",
    "we provide a protocol _",
    "p _ that solves the overlay problem _ cone _ and is topologically self - stabilizing .    in order to give a formal definition of the edges in @xmath172 and in @xmath173 we firstly describe which internal variables are stored in each node @xmath1 , i.e. which edges exist in @xmath172 :    * @xmath174 * @xmath175 : the first node to the right with a larger capacity than @xmath1 * @xmath176 * @xmath177 : the first node to the left with a larger capacity than @xmath1 * @xmath178 * @xmath179 * @xmath180 : the set of right neighbors that @xmath1 communicates with .",
    "we assume that the nodes are stored in ascending order so that @xmath181)<h(u.s^*[i+1])$ ]",
    ". if there are @xmath4 nodes in @xmath182 then @xmath183=u.succ^+_1 $ ] .",
    "* @xmath184 : the set of left neighbors that @xmath1 communicates with .",
    "we assume that the nodes are stored in descending order so that @xmath185)>h(u.p^*[i+1])$ ] if there are @xmath4 nodes in @xmath186 then @xmath187=u.pred^+_1 $ ] .",
    "* @xmath188 the data set , containing all intervals @xmath189=[a , b]$ ] , for which @xmath1 is responsible and stores actual data @xmath189.data$ ] .",
    "additionally for each interval a reference @xmath189.ref$ ] to the supervising node is stored    additionally each node stores the following variables :    * @xmath19 : the timer predicate that is periodically true * @xmath190 : the interval between @xmath1 and the successor of @xmath1 .",
    "@xmath1 is supervising @xmath190 . *",
    "@xmath191 : the message in @xmath10 that now received by the node .",
    "[ def : valid ] we define a valid state as an assignment of values to the internal variables of all nodes so that the definition of the variables is not violated , e.g. @xmath192 contains no nodes @xmath45 with @xmath193 or @xmath194 or @xmath195 and @xmath196 for any @xmath197 .",
    "now we can describe the topologies in the initial states and in the legal stable state .",
    "let @xmath198 and let @xmath199 , such that for @xmath200 the following conditions hold :    * @xmath201 * @xmath200 is in a valid state * @xmath202    note that we assume @xmath172 to be a multiset , i.e in @xmath200 an edge @xmath203 might still exists , although @xmath204 if e.g. @xmath205 .",
    "further note that , in case the network has stabilized to a _",
    "cone_-network , it holds for every node that @xmath206 and @xmath207 .      in this section",
    "we give a description of the the distributed algorithm .",
    "the algorithm is a protocol that each node executes based on its own node and channel state .",
    "the protocol contains periodic actions that are executed if the timer predicate @xmath19 is true and actions that are executed if the node receives a message @xmath191 . in the periodic actions each node performs a consistency check of its internal variables , i.e. are all variables valid according to definition  [ def : valid ] .",
    "if some variables are invalid , the nodes causing this invalidity are delegated . by _ delegation _",
    "we mean that node @xmath1 delegates a node @xmath208 ( resp .",
    "@xmath209 ) to the node @xmath210 ( resp .",
    "@xmath211 ) by a message @xmath212 to @xmath213 .",
    "the idea behind the delegation is to forward nodes closer to their correct position , so that the sorted list ( and the _ cone_-network ) is formed . in order for a node @xmath1 to maintain valid lists ( @xmath214 )",
    ", it makes a periodic check of its lists with its neighbors in @xmath215 , where the lists are compared , so that inconsistencies are repaired .",
    "moreover a node checks whether @xmath216 are valid and introduces to them their closest larger right / left neighbors ( from @xmath1 s perspective ) .",
    "unnecessary ( for these lists ) nodes are delegated.we show later in the analysis section that this process leads to the construction of the correct lists by each node and thus to the _ cone_-network . furthermore in the periodic actions each node introduces itself to its successor and predecessor",
    "@xmath217 $ ] and @xmath97 $ ] by a message @xmath218 . also each pair of nodes in @xmath186 and @xmath182 with consecutive ids",
    "is introduced to each other .",
    "@xmath1 also introduces the nodes @xmath219 and @xmath220 to each other by messages of type @xmath221 . by this",
    "triangulation _ is formed by edges @xmath222 ( see figure  [ example3 ] ) . to establish correct @xmath223 and @xmath224 lists in each node",
    ", a node @xmath1 sends its @xmath225 ( resp .",
    "@xmath192 ) list periodically to all nodes @xmath8 in @xmath226 ( resp .",
    "@xmath227 ) by a message @xmath228 ( resp .",
    "@xmath229 ) to @xmath8 .",
    "the last action a node periodically executes is to send a message to each reference in @xmath188 to check whether @xmath1 is responsible for the data in the corresponding interval @xmath230 $ ] by sending a message @xmath231,u)$ ] .",
    "if the message predicate is true and @xmath1 receives a message @xmath191 , the action @xmath1 performs depends on the type of the message . if @xmath1 receives a message @xmath212 @xmath1 checks whether @xmath8 has to be included in it s internal variables @xmath225 , @xmath192 , @xmath227 or @xmath226 . if @xmath1 does nt store @xmath8 , @xmath8 is delegated . if @xmath1 receives a message @xmath232 , @xmath1 checks whether the ids in @xmath233 has to be included in it s internal variables @xmath225 , @xmath192 , @xmath227 or @xmath226 .",
    "if @xmath1 does nt store a node @xmath8 in @xmath233 , @xmath8 is delegated . if @xmath1 stores a node @xmath8 in @xmath192 ( resp .",
    "@xmath225 ) that is not in @xmath233 , @xmath8 is also delegated as it also has to be in the list of @xmath220 ( resp .",
    "@xmath219 ) .",
    "the remaining messages are necessary for the data management .",
    "if @xmath1 receives a message @xmath231,v)$ ] it checks whether @xmath8 is in @xmath192 or @xmath225 or has to be included , or delegates @xmath8",
    ". then @xmath1 checks whether @xmath230 $ ] is in @xmath190 and if @xmath8 is responsible for @xmath230 $ ] . if not",
    ", @xmath1 sends a message @xmath234 to @xmath8 containing a set of intervals in @xmath230 $ ] that @xmath8 is not responsible for and references of the supervising nodes . if @xmath1 receives a message @xmath234 it forwards all data in intervals in @xmath235 to the corresponding references by a message @xmath236 .",
    "if @xmath1 receives such a message it checks whether the data is in its supervised interval @xmath190 . if not @xmath1 forwards the data according to a greedy routing strategy , if @xmath1 supervises the data it sends a message @xmath237 to the responsible node .",
    "if @xmath1 receives such a message it inserts the data , the interval and the corresponding reference in @xmath188 .",
    "note that no identifiers are ever deleted , but always stored or delegated .",
    "this ensures the connectivity of the network .    in the following we give a description of the protocol executed by each node in pseudo code .",
    "periodic actions including a consistency check , where all list @xmath238 are checked and invalid nodes are delegated like in the listupdate / buildtriangle operation .",
    "furthermore each node sends its lists @xmath239 to the next smaller nodes and @xmath192 to its direct left neighbor .",
    "finally in the buildtriangle ( ) @xmath1 introduces itself to its neighbors and neighbored nodes in @xmath186 and @xmath182 and @xmath220 and @xmath219 to each other and checks whether the information in @xmath188 is still up to date .",
    "@xmath240 consistency check for @xmath225 , @xmath192 , @xmath226 , @xmath227 send m=(list - update,@xmath241 ) to @xmath45 send m=(list - update,@xmath242 ) to @xmath45 buildtriangle ( ) checkdataintervals ( )    @xmath243 send m=(build - triangle , w ) to @xmath244 and m=(build - triangle,@xmath244 ) to @xmath45 @xmath245 send m=(build - triangle,@xmath45 ) to @xmath246 and m=(build - triangle,@xmath246 ) to @xmath45 send m=(build - triangle,@xmath1 ) to @xmath45 send m=(build - triangle,@xmath220 ) to @xmath219 and m=(build - triangle,@xmath219 ) to @xmath220 send m=(buildtriangle,@xmath219 ) to @xmath141 @xmath247 send m=(buildtriangle,@xmath220 ) to @xmath141 @xmath248 calculate @xmath249 out of @xmath226 and @xmath141 @xmath250 send m=(build - triangle,@xmath45 ) to @xmath244 @xmath251 calculate @xmath252 out of @xmath227 and @xmath141 @xmath253 send m=(build - triangle,@xmath45 ) to @xmath246 @xmath254    @xmath255 @xmath256 @xmath257 @xmath258 calculate @xmath259 out of @xmath225 and @xmath260 @xmath261 send m=(build - triangle , z ) to @xmath262 $ ] @xmath263 calculate @xmath264 out of @xmath192 and @xmath265 @xmath266 send m=(build - triangle,@xmath267 ) to @xmath268 $ ] @xmath269 calculate @xmath252 out of @xmath227 and @xmath270 @xmath253 send m=(build - triangle,@xmath45 ) to @xmath246 @xmath254 calculate @xmath249 out of @xmath226 and @xmath271 @xmath272 send m=(build - triangle,@xmath45 ) to @xmath244 @xmath251    a node checks for each interval it is responsible for , if this is really the case .",
    "send m=(check - interval,@xmath230=u.ds[i]$],@xmath1 ) to @xmath189.ref$ ]    a node receiving a check - interval message , checks if the node which sent it is really responsible for the interval [ a , b ] .",
    "buildtriangle(x ) intervalset : = @xmath273 i:=1 intervalset[i]=@xmath274 \\cap [ a , b]$ ] intervalset[i].ref=@xmath97 $ ] i:=i+1 intervalset[i]=@xmath275,b]\\cap [ a , b]$ ] intervalset[i].ref=@xmath217 $ ] i:=i+1 @xmath276:=i_u(x)$ ] : = @xmath277\\cap u.i_u)/i_u(x)$ ] intervalset[i]=@xmath278\\cap [ a , b]$ ] intervalset[i].ref = u i:=i+1 intervalset[i]=@xmath279\\cap [ a , b]$ ] intervalset[i].ref = u send m=(update - interval , intervalset ) to @xmath141    by receiving an update - interval message , a node updates the lists of intervals which it is responsible for , and forwards the data in the deleted intervals to another node , who is possibly responsible .",
    "l:=@xmath280 u.ds[l+1]=[e,f ] u.ds[l+1].ref=[c,d].ref u.ds:=@xmath281\\right\\}$ ] send m = forward - data(data ) to @xmath230.ref$ ] delete(data ) buildtriangle([a , b].ref ) updateds ( )    by receiving a forward - data message , a node checks if it knows which node is responsible for the data it received , and sends a store - data message to it , in the other case it also forwards the data .",
    "send m=(forward - data(data ) ) to @xmath97 $ ] send m=(forward - data(data ) to @xmath282 send m=(store - data , data,@xmath283,u ) to @xmath284    storing the data received from the node supervising the corresponding interval .",
    "u.ds[i].data : = @xmath189.data \\cup data.id \\in u.ds[i]$ ] buildtriangle(u.ds[i].ref ) u.ds[i].ref=x l:=@xmath280 u.ds[l+1]=interval u.ds[l+1].ref=x u.ds[l+1].data=data    @xmath285 listupdate(list ) buildtriangle(x ) checkinterval([a , b],x ) updateinterval(intervalset ) forwarddata(data , boolean ) storedata(data , interval , x )",
    "in this section we show the correctness of the presented algorithm . we do this by showing that by executing our algorithm any weakly connected network eventually converges to a cone network and once a cone network is formed it is maintained in every later state .",
    "we further show that in a cone network the data is stored correctly .      to show convergence we will divide the process of convergence into several phases , such that once one phase",
    "is completed its conditions will hold in every later program state . for our analysis we additionally define @xmath286 as the set of edges at time @xmath76 .",
    "analogous @xmath287 and @xmath288 are defined .",
    "we show the following theorem .",
    "[ theo : convergence ] if @xmath289 at time @xmath76 then eventually at a time @xmath290 @xmath291 .",
    "we divide the proof into 3 phases .",
    "first we show the preservation of the connectivity of the graph , then we show the convergence to the sorted list and eventually the convergence to the _ cone_-network .      in the first phase",
    "we will show that the protocol keeps the network weakly connected and eventually forms a network that is connected by edges @xmath292 such that @xmath293 and edges @xmath294 such that @xmath295 .",
    "[ lem : gconnectivity ] any graph which is weakly connected due to edges in @xmath296 stays weakly connected according to the given protocol , i.e if @xmath286 is weakly connected then @xmath297 , @xmath298 is also weakly connected .",
    "we show that for each existing edge @xmath299 either the edge remains and @xmath300 or a path connecting @xmath301 exists .",
    "obviously @xmath141 and @xmath156 stay weakly connected as long as an edge @xmath302 exists .",
    "we therefore assume @xmath303 and @xmath304 .",
    "if @xmath156 is stored in an internal variable of @xmath141 then there can be the following cases :    * @xmath305 at time @xmath76 , then @xmath156 is delegated to @xmath306 ( resp .",
    "@xmath307 ) and @xmath141 and @xmath156 stay connected over the edges @xmath308 and @xmath309 .",
    "* @xmath310 at time @xmath76 , then @xmath156 is delegated to @xmath311 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 stay connected . * @xmath313.ref$ ] at time @xmath76 then x has received an interval - update message with a new reference for the data in @xmath314 $ ] or the data is deleted .",
    "then in both cases @xmath141 delegates @xmath156 to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 stay connected .    if @xmath156 is stored in an incoming message @xmath191 in @xmath316 .",
    "when @xmath191 is received then there can be the following cases :    * @xmath156 is in a list in a list - update message .",
    "then either @xmath156 is stored in a new list @xmath317 or @xmath156 is delegated to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 stay connected .",
    "* @xmath156 is the node sending a check - interval message .",
    "then either @xmath156 is stored in @xmath318 or delegated to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 stay connected .",
    "* @xmath156 is a reference in an interval - update message , then either @xmath156 is stored as a new reference for some data or if there is no corresponding data @xmath156 is delegated to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 stay connected .",
    "* @xmath156 is a reference in an store - data message , then @xmath156 is stored as a new reference in @xmath319 . * @xmath156 is the i d in a build - triangle message , then @xmath156 is either stored in one of the lists @xmath317 or @xmath156 is delegated to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 stay connected .",
    "[ def : triangulationgraph ] let @xmath320 and @xmath321 @xmath322 we then define the graph @xmath323 as the _ triangulation graph_.    [ lem : triconnectivity ] if @xmath141 and @xmath156 are connected in @xmath324 at time @xmath76 then they will be weakly connected at every time @xmath290 .    again we will consider every possible edge @xmath302 in @xmath324 and show that @xmath141 and @xmath156 stay weakly connected .",
    "if @xmath325 then there can be the following cases :    * @xmath305 at time @xmath76 , then either @xmath156 is delegated to @xmath306 ( resp .",
    "@xmath307 ) by a build - triangle message send to @xmath306 ( resp .",
    "@xmath307 ) and @xmath141 and @xmath156 are connected in @xmath326 by @xmath327 and @xmath328 , or @xmath156 is stored in @xmath329 and @xmath330 .",
    "* @xmath310 at time @xmath76 , then either @xmath156 is delegated to @xmath331 ( resp .",
    "@xmath312 ) or @xmath156 is also stored in @xmath332 ( resp .",
    "@xmath333 ) at time @xmath334 . by the same arguments as above @xmath141 and @xmath156",
    "are connected in @xmath326 .    if @xmath335 then @xmath336 . if @xmath141 processes @xmath191 , then either @xmath141 is stored in @xmath337 and @xmath330 or @xmath156 is delegated to @xmath338 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 are connected in @xmath326 .",
    "[ lem : triconnectivity2 ] if @xmath339 is weakly connected then eventually @xmath324 will be weakly connected .",
    "again we consider every edge @xmath302 in @xmath339 and show that eventually @xmath141 and @xmath156 will be connected in @xmath324 .",
    "note that we already showed in lemma [ lem : triconnectivity ] , that nodes connected in @xmath324 stay connected in @xmath324 .",
    "therefore we only have to consider those edges in @xmath340 .",
    "if @xmath341 there can be the following case :    @xmath313.ref$ ] at time @xmath76 and @xmath141 has received an interval - update message with a new reference for the data in @xmath314 $ ] or the data is deleted .",
    "then in both cases @xmath141 delegates @xmath156 to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 are connected in @xmath324 .",
    "if @xmath141 does not delegate @xmath156 , then @xmath141 eventually sends an check - interval message to @xmath156 .",
    "then either @xmath342 or @xmath156 delegates @xmath141 and @xmath141 and @xmath156 are weakly connected in @xmath324 .",
    "if @xmath156 is stored in an incoming message in @xmath316 then there can be the following cases :    * @xmath156 is in a list in a list - update message .",
    "then either @xmath156 is stored in a new list @xmath317 or @xmath156 is delegated to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 are weakly connected in @xmath324 .",
    "* @xmath156 is a reference in an interval - update message , then either @xmath156 is stored as a new reference for some data or if there is no corresponding data @xmath156 is delegated to @xmath315 ( resp .",
    "@xmath312 ) and @xmath141 and @xmath156 eventually are weakly connected in @xmath324 .",
    "* @xmath156 is a reference in an store - data message , then @xmath156 is stored as a new reference in @xmath319 . and as already shown @xmath141 and @xmath156 are eventually weakly connected .    combining the lemmas  [ lem : gconnectivity ] ,  [ lem : triconnectivity ] and  [ lem : triconnectivity2 ] leads to the following theorem :    [ theo : phase1 ] if @xmath339 is weakly connected at time @xmath76 , then for some time @xmath290 @xmath324 will be weakly connected at every time @xmath343 .",
    "for the rest of the analysis we assume that all variables of each node are valid according to definition  [ def : valid ] , i.e. we assume that each node has performed one consistency check . in this phase",
    "we show that eventually all nodes form a sorted list .",
    "we therefore define another subtopology    @xmath344 with @xmath345 \\vee y = x.s^*[1])\\right\\}$ ] and @xmath346 .",
    "in the end @xmath347 with @xmath348\\- \\vee y = x.s^*[1 ] ) \\wedge x.p^*[1]= \\argmax _ { v \\in v } \\left\\{h(v ) : h(v)<h(x ) \\right\\ } \\wedge x.s^*[1]=\\-\\argmin _ { v \\in v } \\left\\{h(v ) : h(v)>h(x)\\right\\}\\}$ ] shall be formed .",
    "[ theo : phase2 ] if @xmath324 is weakly connected eventually @xmath349 will be strongly connected and @xmath350 .",
    "before we can show the theorem we show some helping lemmas .",
    "[ lem : rconnectivity ] eventually all nodes @xmath351 $ ] and @xmath352 $ ] ( resp .",
    "@xmath353 $ ] and @xmath354 $ ] ) with @xmath355 will be connected and stay connected in every state after over nodes @xmath356)<h(w)<h(x.s^*[i+1])$ ] .    in the periodic action @xmath141",
    "executes @xmath357 , in which @xmath141 introduces every pair of nodes @xmath351,x.s^*[i+1]$ ] to each other .",
    "the connecting path only changes if w.l.o.g .",
    "@xmath351 $ ] delegates @xmath352 $ ] , but then @xmath351 $ ] can delegate @xmath352 $ ] only to a node @xmath8 with @xmath358)<h(v)<h(x.s^*[i+1])$ ] . by using this argument inductively @xmath351",
    "$ ] and @xmath352 $ ] stay connected in every state after over nodes @xmath358)<h(w)<h(x.s^*[i+1])$ ] .",
    "[ lem : forward ] if @xmath359 and @xmath360 and @xmath361 ( resp .",
    "@xmath362 ) then eventually @xmath363 with @xmath364 ( resp .",
    "@xmath365 ) and @xmath141 and @xmath267 are connected over nodes @xmath366 .",
    "if @xmath141 delegates @xmath267 to a node @xmath8 then obviously @xmath364 and @xmath141 and @xmath267 are connected over @xmath367 . in case @xmath267",
    "is not delegated @xmath267 is stored in @xmath368 or @xmath332 ( resp .",
    "@xmath329 or @xmath333 ) or in a message @xmath369 .",
    "if @xmath267 is stored in @xmath332 and @xmath359 and @xmath361 then either @xmath370 or @xmath371 . eventually @xmath372 is processed by @xmath141 and either @xmath156 is delegated , then there is another node @xmath373 or @xmath156 is stored in @xmath332 . thus eventually @xmath374 and another node @xmath375 such that @xmath376 . from all such nodes @xmath375 such that @xmath376 @xmath141 introduces @xmath267 to @xmath377 and @xmath363 with @xmath364 and by the same arguments as above @xmath141 and @xmath267",
    "stay connected over nodes @xmath378 . if @xmath379 and @xmath380 the same analysis as for @xmath381 can be applied . if @xmath379 and @xmath382 eventually @xmath141 will receive the @xmath383 list of @xmath384 .",
    "if @xmath385 then @xmath363 with @xmath364 and by the same arguments as above @xmath141 and @xmath267 stay connected over nodes @xmath386 .",
    "otherwise @xmath141 sends a message @xmath387 to @xmath8 and again @xmath363 with @xmath364 and by the same arguments as above @xmath141 and @xmath267 stay connected over nodes @xmath388 .",
    "if @xmath369 , then eventually @xmath141 processes @xmath191 and either stores @xmath267 in @xmath368 or @xmath332 and we can apply one of the cases above or @xmath267 is delegated .",
    "[ lem : mirror ] if @xmath360 with @xmath389 then eventually @xmath390 with @xmath361 and @xmath141 and @xmath156 are connected over nodes @xmath391 .",
    "if @xmath360 and @xmath359 and @xmath361 we can apply lemma  [ lem : forward ] and eventually @xmath363 with @xmath364 ( resp .",
    "@xmath365 ) and @xmath8 and @xmath267 are connected over nodes @xmath392 @xmath386 in every state after . now if @xmath393 with @xmath394 we might again apply the lemma . obviously we only can apply lemma  [ lem : forward ] a finite number of times until there is a node @xmath395 such that @xmath396 and there is no @xmath397 with @xmath398 and @xmath141 and @xmath267 are connected over nodes @xmath399",
    ". then either @xmath400 $ ] or @xmath401 .",
    "if @xmath400 $ ] then eventually @xmath395 will introduce itself to @xmath267 by a message @xmath402 , then @xmath403 with @xmath376 and @xmath141 and @xmath395 are connected over nodes @xmath392 @xmath399 .",
    "otherwise as soon as @xmath395 processes @xmath372 @xmath404 $ ] is set to @xmath267 and the same arguments as in the first case hold .",
    "before we prove the theorem we introduce some additional definitions .    in the directed graph",
    "we define an _ undirected path _ @xmath123 as a sequence of edges @xmath405 @xmath406 ) , such that @xmath407 .",
    "let @xmath408 and @xmath409 then the _ range of a path _",
    "@xmath410 is given by @xmath411 .",
    "now we are ready to prove theorem  [ theo : phase2 ] .",
    "let @xmath141 and @xmath156 be a pair of nodes connected in @xmath347 ; i.e. w.o.l.g . @xmath412 and @xmath413 .",
    "then as @xmath324 is weakly connected there is an undirected path connecting @xmath141 and @xmath156 .",
    "let @xmath414 be such a path at time @xmath76 .",
    "we show that there is a path @xmath415 with @xmath290 that connects @xmath141 and @xmath156 weakly such that @xmath416 .",
    "let @xmath417 and @xmath418 be the smallest and greatest node on the path @xmath414 that limit the range of @xmath414 .",
    "then @xmath417 is connected to nodes @xmath419 and @xmath420 . if @xmath421 and @xmath422 .",
    "then according to lemma  [ lem : mirror ] eventually @xmath423 and @xmath419 and @xmath424 are connected over nodes @xmath213 such that @xmath425 .",
    "the same holds for @xmath420 .",
    "thus eventually @xmath423 and @xmath426 and @xmath419 and @xmath424 are connected over nodes @xmath213 with @xmath425 and @xmath420 and @xmath427 are connected over nodes @xmath428 . then either @xmath429",
    "and we can construct another path connecting @xmath141 and @xmath156 over @xmath419 and @xmath420 with @xmath430 , and @xmath431 , otherwise @xmath432 or @xmath433 .",
    "we assume @xmath432 . then according to lemma  [ lem : forward ]",
    "eventually @xmath434 and @xmath435 and @xmath417 are connected over nodes @xmath436 .",
    "either @xmath437 $ ] or also according to lemma  [ lem : forward ] @xmath438 and @xmath439 and @xmath417 are connected over nodes @xmath440 .",
    "note that according to the proof of lemma  [ lem : forward ] @xmath439 and @xmath435 have to be in @xmath441 at the time the edge @xmath434 resp .",
    "@xmath438 is created .",
    "then according to lemma  [ lem : rconnectivity ] @xmath439 and @xmath435 are also connected to @xmath442 $ ] .",
    "thus again we can construct another path connecting @xmath141 and @xmath156 over @xmath419 and @xmath420 with @xmath443\\wedge h(u_{min}.s^*[1])>h(u_{min})$ ] . the same arguments can be used symmetrically to show that @xmath418 can be decreased .",
    "thus eventually a connecting path can be found with a strict smaller range and by applying these arguments a finite number of times @xmath444 and @xmath445 . then if @xmath446 @xmath447=y$ ] otherwise @xmath295 will eventually be processed and @xmath447 $ ]",
    "is set to @xmath156 . by the same arguments",
    "eventually @xmath448 $ ] . as this holds for every pair @xmath141 , @xmath156 in @xmath347 , eventually @xmath350 .      in this section",
    "we show that once the network has stabilized into a sorted list , it eventually also stabilizes into the legal cone - network , that means , each node @xmath1 maintains a correct set of neighbors , so the lists @xmath449 maintain the correct nodes , so for example the list @xmath225 maintains the nodes in @xmath450 .",
    "for all the following lemmas and theorems in this section we assume @xmath350",
    ".    we will first do the proof for the sets @xmath226 and @xmath192 .",
    "the following lemma will be helpful .",
    "[ induct1 ] if every node at the right ( with larger i d ) of a node @xmath1 knows its correct closest larger right node @xmath451 ( stored in @xmath219 ) , then for all nodes @xmath141 which are in the correct right internal neighborhood of @xmath1 , @xmath59 , it holds that @xmath1 will eventually learn @xmath141 ( and store it in @xmath226 )",
    ".    we will prove it by induction over @xmath141 ( in ascending order of their @xmath452 values ) .",
    "* induction basis : * @xmath141 is the direct right neighbor of @xmath1 . in that case",
    "@xmath1 already knows @xmath141 , since we assumed the presence of the sorted list , and the statement holds .",
    "* inductive step : * if @xmath1 knows the next node to the left of @xmath141 ( let this be @xmath156 ) which is in the right internal neighborhood of @xmath1 , then @xmath1 eventually learns @xmath141 . in this case , @xmath141 is the closest larger right node of @xmath156 .",
    "that is because @xmath141 must be larger ( in terms of capacity ) than @xmath156 , since else @xmath141 would not be in @xmath59 . by hypothesis",
    ", @xmath156 knows about @xmath141 ( so @xmath453 ) .",
    "so , when @xmath156 conducts its periodic @xmath454 call , it will introduce @xmath1 and @xmath141 to each other ( as they are @xmath455 and @xmath456 respectively ) and @xmath1 will learn about @xmath141 .",
    "now we show that eventually all nodes learn their correct right larger - node lists .",
    "[ s^+ ] once the list has been established and @xmath350 , then eventually every node @xmath1 learns its correct right larger - node list @xmath457 ( and stores it in @xmath192 ) .",
    "we will prove this by induction over the nodes @xmath1 ( in descending order of their @xmath67 values ) .    *",
    "induction basis : * @xmath1 does not have any closest larger right node @xmath451 .",
    "the statement is obliviously true .",
    "* inductive step : * if every node at the right of @xmath1 in the list , knows its correct right larger - node list , then eventually @xmath1 will learn its correct right larger - node list @xmath457 .    from the induction hypothesis",
    ", every node at right of @xmath1 knows its correct right larger - node list ( so also its correct closest larger right node ) , so according to lemma  [ induct1 ] , @xmath1 will eventually learn its correct right internal neighborhood ( and store it in @xmath226 ) .",
    "let @xmath8 the node being the most right one in @xmath226 .",
    "it is obvious that the closest larger right node of @xmath8 , @xmath458 , is also the closest larger right node of @xmath8 , since otherwise @xmath458 would also be in @xmath226 . by the inductive hypothesis",
    ", @xmath8 knows this node , and will introduce it to @xmath1 by its periodic @xmath454 call .",
    "so , once @xmath1 learns @xmath458 ( and as a consequence @xmath458 learns @xmath1 after @xmath1 s periodic @xmath454 call , @xmath458 will also send to @xmath1 its right larger - node list ( @xmath192 ) , through its periodic @xmath459 message , which ( together with @xmath458 ) is the correct right larger - node list of @xmath1 .",
    "[ s^- ] if @xmath350 , then eventually every node @xmath1 learns its correct right internal neighborhood @xmath59 ( and stores it in @xmath226 ) .    by lemma  [ s^+ ] ,",
    "there is a point where every node knows its right larger - node list @xmath457 .",
    "this is the hypothesis of lemma  [ induct1 ] for all nodes @xmath1 , so by using this lemma for every node @xmath1 we derive the proof .",
    "[ theo : phase3 ] if @xmath350 then eventually , every node @xmath1 learns its correct internal neighborhood @xmath460 , as well as its correct larger - node lists @xmath461 .",
    "we already showed that for the right part of the neighborhood ( for @xmath457 and @xmath59 ) by lemmas  [ s^+ ] and  [ s^- ] . by symmetry ( i.e. by using symmetric proofs for the left part ) it also holds for @xmath450 and @xmath61 .",
    "combining theorem  [ theo : phase1 ] , theorem  [ theo : phase3 ] and theorem  [ theo : phase3 ] we can show that theorem  [ theo : convergence ] holds , and by our protocol each weakly connected network converges to a cone network .",
    "we showed that from any initial state we eventually reach a state in which the network forms a correct cone network .",
    "we now need to show that in this state the explicit edges remain stable and also that each node stores the data it is responsible for .",
    "[ theo : closure ] if @xmath462 at time @xmath76 then for @xmath290 also @xmath462 .",
    "the graph @xmath463 only changes if the explicit edge set is changed .",
    "so if we assume that @xmath462 at time @xmath76 and for @xmath290 also @xmath464 then we added or deleted at least one explicit edge .",
    "let @xmath465 at time @xmath76 .",
    "we assume @xmath84 .",
    "either @xmath466 or @xmath467 . in both cases",
    "the edge is only deleted if @xmath1 knows a node @xmath45 with @xmath468 and @xmath469 as following from theorem  [ theo : phase3 ] all internal neighborhoods are correct in @xmath63 there can not be such a node @xmath45 . by the same argument also no new edges are created .",
    "thus @xmath462 at time @xmath470 .",
    "so far we have shown that by our protocol eventually a cone network is formed .",
    "it remains to show that also by our protocol eventually each node stored the data it is responsible for .",
    "[ theo : datastructure ] if @xmath462 eventually each node stores exactly the data it is responsible for .    according to theorem  [ theo : responsibility ] each node knows which node is responsible for parts of the interval it supervises . in our described algorithm",
    "each node @xmath1 checks whether it is responsible for the data it currently stores by sending a message to the node @xmath8 that @xmath1 assumes to be supervising the corresponding interval .",
    "if @xmath8 is supervising the interval and @xmath1 is responsible for the data , then @xmath1 simply keeps the data .",
    "if @xmath8 is not supervising the data or @xmath1 is not responsible for the data then @xmath8 sends a reference to @xmath1 with the i d of anode that @xmath8 assumes to be supervising the interval .",
    "then @xmath1 forwards the data to the new reference and does not store the data . by forwarding the data by greedy routing it eventually reaches a node supervising the corresponding interval , this node then tells the responsible node to store the data .",
    "thus eventually all data is stored by nodes that are responsible for the data .",
    "concerning the network operations in the network , i.e. the joining of a new node , the leaving of a node and the capacity change of a node , we show the following :    [ theo : dynam ] in case a node @xmath1 joins a stable cone network , or a node @xmath1 leaves a stable cone network or a node @xmath1 in a stable cone network changes its capacity , we show that in any of these three cases @xmath26 structural changes in the explicit edge set are necessary to reach the new stable state .",
    "we show the statement by considering the 3 cases separately .",
    "when a new node @xmath1 enters the network , it does so by maintaining a connection to another node @xmath8 , which is already in the network .",
    "@xmath1 is forwarded due to the @xmath454 and @xmath471 rules in the network until it reaches its right position , as it takes part in the linearization procedure .",
    "if a node @xmath1 joins a stable cone network @xmath26 structural changes in the explicit edge set are necessary to reach the new stable state .",
    "we show that there is at most a constant number of temporary edges , i.e. edges that are not in the stable state .",
    "@xmath1 stores @xmath8 in its internal variables @xmath186 or @xmath182 as @xmath8 is the only node @xmath1 knows . in the periodic buildtriangle ( )",
    "@xmath1 sends a message to @xmath8 containing its own i d creating an implicit edge @xmath11 .",
    "now there can be two cases : either @xmath1 is in @xmath8 lists @xmath472 , @xmath383 , @xmath473 , @xmath474 in a stable state then @xmath8 stores @xmath1 s identifier or @xmath1 is not stored and delegated to another node @xmath45 creating the implicit edge @xmath475 .",
    "thus only explicit edges pointing to @xmath1 are created that are in the stable state and only the explicit edge @xmath203 is temporary .",
    "so far we have shown that according to theorem  [ theo : phase3 ] and  [ theo : degree ] at most @xmath23 edges are created w.h.p .",
    "that point to @xmath1 or start at @xmath1 .",
    "but by the join of @xmath1 to the network also edges that have been in the stable state not longer exist in the new stable state .",
    "e.g. let @xmath476 and @xmath477 and @xmath478 then @xmath45 is not longer stored in @xmath368 as soon as @xmath1 is integrated in the network . according to  [ theo : degree ]",
    "there is at most @xmath23 w.h.p .",
    "such nodes @xmath141 , as each node @xmath141 has to store @xmath1 in its lists , and also at most @xmath23 w.h.p .",
    "nodes @xmath45 , as @xmath1 has to store each @xmath45 in its lists .",
    "therefore there are at most @xmath26 edges that have to be deleted .",
    "once a node decides it wants to leave the network , it disconnects itself from its neighbors . in the case",
    "it is the node with the greatest capacity , it introduces its two direct neighbors to each other before doing so . in that way ,",
    "connectivity is still guaranteed ( at least in the stable state ) .",
    "send m = forward - data(data , false ) to @xmath479 $ ] delegate the references in @xmath188 send m=(buildtriangle , @xmath480 $ ] ) to @xmath479 $ ] delete all connections , leave network    after the leaving , the network must stabilize again .",
    "this means that @xmath479 $ ] and @xmath480 $ ] must connect to each other .",
    "lets consider @xmath480 $ ] . since it wo nt have a direct right neighbor after the leaving of @xmath1",
    ", the linearization process will take place again until @xmath480 $ ] learns @xmath479 $ ] .",
    "if a node @xmath1 leaves a stable cone network @xmath26 structural changes in the explicit edge set are necessary to reach the new stable state .",
    "the proof is analogous to the proof in the case of a joining node . obviously according to  [ theo : degree ] w.h.p .",
    "@xmath23 edges are deleted that start at or point to the leaving node @xmath1 . by deleting @xmath1 further edges",
    "have to be created .",
    "e.g. let @xmath481 and @xmath482 and @xmath478 then @xmath45 might now be stored in @xmath368 or @xmath332 and the edge @xmath483 has to be created . again according to  [ theo : degree ]",
    "there are w.h.p . at",
    "most @xmath23 such nodes @xmath141 and @xmath23 such nodes @xmath45 , thus in total at most @xmath26 edges have to be created .",
    "if the capacity of a single node @xmath1 in a stable cone network decreases we can apply the same arguments as for the leaving of a node , as some nodes might now be responsible for intervals that @xmath1 was responsible for .",
    "additionally @xmath1 might have to delete some ids in @xmath484 and add ids in @xmath485 .",
    "if a node increases its capacity we can apply the same arguments as for the joining of a node , as some nodes might not longer be responsible for intervals that @xmath1 is now responsible for .",
    "additionally @xmath1 might have to add some ids in @xmath484 and delete ids in @xmath485",
    ". thus the following theorem follows .",
    "if a node @xmath1 in stable cone network changes its capacity @xmath26 structural changes in the explicit edge set are necessary to reach the new stable state .",
    "we studied the problem of a self - stabilizing and heterogeneous overlay network and gave an algorithm of solving that problem , and by doing this we used an efficient network structure .",
    "we proved the correctness of our protocol , also concerning the functionality of the operations done in the network , data operations and node operations .",
    "this is the first attempt to present a self - stabilizing method for a heterogeneous overlay network and it works efficiently regarding the information stored in the hosts .",
    "furthermore our solution provides a low degree , fair load balancing and polylogarithmic updates cost in case of joining or leaving nodes . in the future",
    "we will try to also examine heterogeneous networks in the two - dimensional space and consider heterogeneity in other aspects than only the capacity , e.g. bandwidth , reliability or heterogeneity of the data elements .",
    "d. karger , e. lehman , t. leighton , m. levine , d. lewin , and r. panigrahy .",
    "consistent hashing and random trees : distributed caching protocols for relieving hot spots on the world wide web . in _ stoc 97 _ , pages 654 - 663 , 1997 ."
  ],
  "abstract_text": [
    "<S> we consider the problem of managing a dynamic heterogeneous storage system in a distributed way so that the amount of data assigned to a host in that system is related to its capacity . two central problems </S>",
    "<S> have to be solved for this : ( 1 ) organizing the hosts in an overlay network with low degree and diameter so that one can efficiently check the correct distribution of the data and route between any two hosts , and ( 2 ) distributing the data among the hosts so that the distribution respects the capacities of the hosts and can easily be adapted as the set of hosts or their capacities change . </S>",
    "<S> we present distributed protocols for these problems that are self - stabilizing and that do not need any global knowledge about the system such as the number of nodes or the overall capacity of the system . prior to this work </S>",
    "<S> no solution was known satisfying these properties . </S>"
  ]
}