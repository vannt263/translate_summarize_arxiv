{
  "article_text": [
    "in the context of financial data some variables often present strong discontinuities , the so - called jumps . the well - known stochastic differential equation driven by a brownian motion of black and scholes @xcite",
    "may then becomes unsuitable .",
    "decision - making in the presence of jumps has been recently considered , in both theoretical and empirical work .",
    "merton @xcite has proposed diffusion models with jumps where the logarithm of jump sizes is assumed to be gaussian .",
    "kou @xcite has suggested a double exponential law for that variable and a more general case , with the power exponential distribution , has been considered by galea , ma and torres @xcite .",
    "several inferential techniques have been developed in this area .",
    "lee and mykland @xcite present a nonparametric approach , chan @xcite suggests maximum likelihood estimation .",
    "continuous time models face however a difficulty in detecting jumps , as available data are obviously discrete .",
    "on the other hand , diffusion processes with jumps are inherently non - identifiable models : trajectories are sums of diffusion and jump processes .",
    "the usual methodology of classical statistical inference then become inappropriate ( khalof , saphores and bilodeau @xcite ; luan and xie @xcite ) .",
    "finally , asymptotic sampling distributions are particularly inadequate for small samples in this context .",
    "this paper proposes a full bayesian inference approach for the problem .",
    "the full bayesian significance test ( fbst ) was developed by pereira and stern @xcite for sharp hypothesis testing in parametric models .",
    "the fbst is also the optimal solution for the considered decision problem , as shown by madruga , esteves and wechsler @xcite , who obtained well - defined loss functions that make fbst a genuine bayes test .",
    "such loss functions are very useful in our context as the statistician may fix them to particular numerical descriptions of her world .",
    "a deep analysis and revision of fbst may be found in pereira , stern and wechsler @xcite .",
    "this paper considers diffusion models with jumps driven by the following stochastic differential equation @xmath0 in the equation above , @xmath1 is a standard brownian motion , @xmath2 is a poisson process , and @xmath3 are non - negative independent identically distributed random variables .",
    "the derivative @xmath4 represents expected return , and @xmath5 represents the volatility .    by making time discrete with unit steps , the equation above can be approximated by the difference equation @xmath6 @xmath7 , @xmath8 , and @xmath9 are independent random variables , @xmath7 and @xmath8 having a bernoulli and a standard normal law , respectively .",
    "a natural parameterization of the previous convolution allows us to frame the problem of jump detection as a test of hypothesis . in this test ,",
    "the null hypothesis of no jumps is a sharp hypothesis .",
    "section 2 describes the formulation of the diffusion model with jumps and its discrete version .",
    "section 3 presents the full bayesian significance test .",
    "the parameterization of the model and the application of fbst to it are seen in section 4 .",
    "section 5 has numerical results for both real and simulated data , yielding also parameter estimates of maximum posterior density .",
    "section 6 discusses possible generalizations and presents conclusions .",
    "in this section we state the jump - diffusion model that motivated the statistics test that we are interested in .",
    "let @xmath10 be a completed filtered probability space on which is defined a brownian motion @xmath11 and a compound poisson process @xmath12 , both adapted to the filtration @xmath13 .",
    "more precisely , we assume that the process @xmath12 takes the following form : @xmath14 where @xmath15 is a standard poisson process with rate @xmath16 , and @xmath17is a sequence of i.i.d .",
    "nonnegative random variables .",
    "we assume that :    1 .   for each @xmath18 ,",
    "@xmath19 has a given distribution ; 2 .",
    "the process @xmath11 , @xmath20 , and @xmath21 s are independent ; 3 .",
    "@xmath22 , augmented under @xmath23 so that it satisfies the _ usual hypothesis .",
    "_    in our jump - diffusion model we assume that all economics have a finite horizon @xmath24 $ ] , and the price of our underlying risky asset is given by the following stochastic differential equation :    @xmath25    for notational simplicity and in order to get analytical solutions , the drift @xmath4 and the volatility @xmath5 are assumed to be constants , and the brownian motion and jumps are assumed to be one dimensional .",
    "these assumptions , however , can be omitted to develop a general theory .",
    "the goal of this section is to approximate the equation given in ( [ precio ] ) using the euler method .",
    "we know that , from protter @xcite , the solution to the stochastic differential equation ( [ precio ] ) , that give us the dynamics of the asset price , is given by @xmath26 next , @xmath27 if @xmath28 is small enough , we can reject the terms of greatest order from the taylor expansion , approximating @xmath29 by @xmath30 .",
    "we obtain @xmath31 @xmath32 where @xmath8 is a normal standard random variable and the unknown parameters are @xmath4 , which represents the expected return , @xmath5 , the volatility , and @xmath16 , the jump rate .",
    "as it was shown in kou @xcite , for @xmath33 small enough we have : @xmath34 in other words , if @xmath35 is sufficiently small , the return can be approximated in distribution by @xmath36 where @xmath7 is a bernoulli random variable with @xmath37 and @xmath38 , and @xmath39 .",
    "note that @xmath40    @xmath41",
    "so , returns can be modeled as the convolution @xmath42 , between independent normal random variable and a random variable with some distribution @xmath43 .    in this work",
    ", we will assume that @xmath44 and random variable @xmath9 has bernoulli distribution with unknown parameter @xmath45 .",
    "then , @xmath46 has a bernoulli distribution given by @xmath47 there are many alternative models depending on the distribution of the jumps , see for example merton @xcite , for the normal distribution , kou for double exponential , and galea , ma and torres @xcite for a generalization of the previous works .    from ( [ sumapp ] ) and ( [ bernoulli ] ) ,",
    "the density function of @xmath48 has the following representation : @xmath49    .,title=\"fig : \" ] .,title=\"fig : \" ]    figure [ figure1 ] shows a realization of the returns @xmath50 and the density ( [ ng ] ) , for @xmath51 day , @xmath52 , @xmath53 , @xmath54 . in other words , for this process , there are about @xmath55 jumps per year with size one .",
    "let us consider a random variable d whose value @xmath56 in the measurable sample space @xmath57 is to be observed .",
    "let @xmath58 be the parametric space , that is , a set such that @xmath59 is a well - defined probability measure in @xmath60 , for all @xmath61 .",
    "denote by @xmath62 a probability measure structure on @xmath58 such that @xmath63 determines a priori probability distribution on @xmath58 .    after observing data @xmath56 ,",
    "the information about @xmath64 is updated by bayes theorem and quantified by the posterior probability law on @xmath58 , @xmath65",
    ".    full bayesian significance test ( fbst ) procedure is defined in the case when this posterior distribution has a density function with respect to lebesgue measure .",
    "let @xmath66 denote the priori density , @xmath67 , the likelihood function of @xmath64 after observing data @xmath56 , and @xmath68 , the posterior density of @xmath64 given data @xmath56 , related by @xmath69    a precise hypothesis @xmath70 can be defined as a submanifold @xmath71 such that @xmath72 .",
    "this implies that the posterior probability of a precise hypothesis is null for an absolutely continuous posterior distribution : every precise hypothesis should be rejected in that case .    in order to avoid such a drastic conclusion , fbst deals not directly with @xmath73 , but with a sort of critical region defined by the level surfaces of the posterior density @xmath68 .",
    "let us define the _ tangential set _",
    "@xmath74 to the null hypothesis @xmath73 as the set @xmath75 in other words , the tangential set to @xmath73 considers all points `` most probable '' than @xmath73 , according to the posterior law",
    ".    the posterior probability of @xmath74 , @xmath76 is called its _ credibility_. the _ evidence _ for the null hypothesis is then defined as @xmath77    so , if tangential set has high posterior probability , the evidence in favor of @xmath73 is small ; if it has low posterior probability , the evidence against @xmath73 is small .    in madruga",
    "@xcite , the bayesianity of the test of significance based on this evidence measure is showed , in the sense that there exists a loss function such that the decision for rejecting the null hypothesis is based on its posterior expected value minimization .",
    "the computation of @xmath78 can be performed in two steps : a numerical optimization procedure to find @xmath79 , and a numerical integration to find @xmath80 .",
    "for the problem presented in section [ s : jdmf ] , let us consider the parametric space @xmath81 , \\mu \\in r , \\sigma^2>0\\ } .\\ ] ]    according to equation ( [ ng ] ) , the likelihood for the parameter @xmath64 , given a sample @xmath82 , may be written as @xmath83 \\nonumber\\\\ & = & ( 2\\pi\\sigma^2)^{-n/2 } e^{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n ( x_{i}-\\mu)^2 } \\\\ & & \\times \\sum_{k=0}^n ( \\lambda p\\ , e^{-\\frac{1 + 2\\mu}{2\\sigma^2}})^k ( 1-\\lambda p)^{n - k}\\sum e^{\\frac{1}{\\sigma^2}\\sum_{l=1}^k x_{i_l } } .\\nonumber\\end{aligned}\\ ] ]    from the above equation , we note that if @xmath84 , then the parameters @xmath85 and @xmath86 are observationally equivalent , as they have the same likelihood from data @xmath56 .",
    "the function @xmath87 , @xmath88 is an identifying function , that is , it is a one - to - one transformation under that equivalence relation .",
    "( see kadane @xcite for more properties and examples of identifying functions . )",
    "theorem 5 in kadane @xcite states that the bayesian analysis can be done on @xmath89 , from the prior induced on @xmath89 by @xmath90 and the likelihood function .    aiming to preserve the information of an experiment about the parameters of interest",
    ", we will define a prior distribution for @xmath64 such that @xmath91 whenever @xmath92 .",
    "it will be assumed that @xmath93 and @xmath94 are independent random vectors , yielding @xmath95 for every @xmath96 .",
    "the following prior density will be adopted for @xmath93 @xmath97 with known @xmath98 .    in order to ease some numerical aspects",
    ", we will assume a uniform on @xmath99 density for @xmath100 and , given @xmath100 , a uniform on @xmath101 law for @xmath4 , with hyperparameters @xmath102 , @xmath103 .",
    "the posterior density for @xmath104 is then @xmath105    the null hypothesis , @xmath106 states that the process has no jumps , a sharp hypothesis .    under this formulation ,",
    "the measure of evidence in favor of @xmath73 , @xmath107 , defined by ( [ eq : ev ] ) , allows us to perform a significance test for @xmath108 without having to modify the posterior distribution ( either by assigning positive probability to the null hypothesis or by enlarging it , both polemical solutions in the literature ) .",
    "we used s - plus to perform fbst on simulated data from the convolution of a normal@xmath109 and a bernoulli with parameter @xmath110 having the values 0 , 0.025 , 0.10 , 0.35 and 0.50 .",
    "data were standardized @xmath111 where @xmath112 and @xmath113 are , respectively , the sample mean and sample standard deviation , with sample size @xmath114 .",
    "the hyperparameters for the prior distribution were chosen to be @xmath115 , @xmath116 , @xmath117 , @xmath118 .",
    "cccc @xmath110 & @xmath107 & posterior mode @xmath119 & posterior mean @xmath119 0 & 1 & ( .0000 , 5.045 , .2087 ) & ( .4077 , 4.629 , .2139 ) 0.025 & .00382 & ( .06211 , 4.993 , .2071 ) & ( .08346 , 5.005 , .2044 ) 0.10 & 3.98e-8 & ( .1494 , 5.002 , .1510 ) & ( .1438 , 5.011 , 0.1766 ) 0.35 & 3.47e-5 & ( .3416,5.029,.1719 ) & ( .3501 , 5.021 , .1933 ) 0.50 & 3.37e-6 & ( .5193 , 5.046 , .1826 ) & ( .5184 , 5.049 , .2046 )    table [ t:1 ] presents the evidence values @xmath107 for the distinct rates simulated , and also maximum posterior estimates and the mean posterior estimate for @xmath120 .",
    ", @xmath121.,title=\"fig : \" ] , @xmath121.,title=\"fig : \" ]    figure [ figure2 ] presents the simulated data on time for a process having @xmath122 as jump rate .",
    "the right - hand graph shows the data empirical density ( in full line ) , and the density adjusted by the posterior mode ( in dotted line ) .",
    "data suggest the possibility of jumps , quantified by the small evidence in favor of the null hypothesis , @xmath123 .",
    "graph [ figure3 ] shows the simulated data empirical density ( full line ) in each case and the density determined by the posterior mode ( dotted line ) , for the various rates considered .    , @xmath124 ; ( b ) @xmath125 , @xmath126 ; ( c ) @xmath127 , @xmath128 ; ( d ) @xmath129 , @xmath130.,title=\"fig : \" ] , @xmath124 ; ( b ) @xmath125 , @xmath126 ; ( c ) @xmath127 , @xmath128 ; ( d ) @xmath129 , @xmath130.,title=\"fig : \" ] , @xmath124 ; ( b ) @xmath125 , @xmath126 ; ( c ) @xmath127 , @xmath128 ; ( d ) @xmath129 , @xmath130.,title=\"fig : \" ] , @xmath124 ; ( b ) @xmath125 , @xmath126 ; ( c ) @xmath127 , @xmath128 ; ( d ) @xmath129 , @xmath130.,title=\"fig : \" ]    it can be seen , a strong bimodality in the sample is well detected by the fbst procedure as expected .",
    "on the other hand , without a strong bimodality , the evidence in favour of @xmath73 is large , as seen in the graph of simulated data with @xmath131 , where @xmath124 .",
    "the computation of evidence values @xmath78 was based on the simulation of 400,000 independent points uniformly distributed over the support of the posterior distribution , and having their non - normalized values , @xmath132 , computed .",
    "other 400,000 points were uniformly generated on @xmath73 , in order to obtain the sample maximum of the non - normalized posterior density on @xmath73 , @xmath133 .",
    "the posterior probability of the tangential set can be approximated by the ratio of the sum of values of @xmath132 larger than @xmath133 to the total sum of @xmath132 for all generated points .",
    "the mean time for running of this program was 600 seconds approximately , in a standard pc .",
    "other optimization numerical methods which are more efficient for determining @xmath133 and integrating on @xmath74 , may be used .",
    "our simple method , however , had a good performance for the problem of model choice between models having bernoulli jumps or models without jumps .",
    "furthermore , it can be generalized in a straightforward way for other jump .",
    "figure [ figure4 ] presents annual maximum rainfall data ( maiquetia station at venezuela central coast ) during 1951 - 1998 .",
    "source :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ http://www.blackwellpublishing.com/rss/volumes/cv52p4.htm _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    coles and pericchi @xcite use these data to compare bayesian and classical methods on the prediction of the 1999 catastrophic maximum of 410 mm .",
    "data were transformed to the standard scale , as described in the previous section .",
    "the jump size was considered random , so the parametric space had one more dimension added to it , @xmath134 , having a uniform prior distribution on @xmath135 $ ] , independently from the other components .",
    "the analysis obtained an evidence value in favour of @xmath73 , @xmath136 . the posterior mode and mean estimates are @xmath137 @xmath138    in original units , the posterior mode estimate represents the model @xmath139 and the posterior mean estimate represents the model @xmath140 where @xmath141 and @xmath142 are the sample mean and the sample standard deviation , @xmath8 has standard normal distribution , @xmath143 has a bernoulli(.145 ) distribution and @xmath144 , has a bernoulli(.168 ) law .",
    "as seen in figure [ figure5 ] , that estimate fits well the observed data .",
    ".,title=\"fig : \" ] .,title=\"fig : \" ]    the posterior mode estimate is here the maximum likelihood estimate , as the chosen prior is uniform .",
    "the posterior distribution simulation yields other relevant probabilities : given a threshold @xmath145 , let @xmath146 be the event that values not smaller than @xmath145 are recorded only after time @xmath147 . in the example , @xmath146 indicates that an annual maximum rainfall largest than @xmath145 takes at least @xmath147 years to be recorded .",
    "@xmath148 can be approximated essentially with the same values obtained by the previous simulation .",
    "figure [ figure6 ] shows this probability as a function of time @xmath147 up to 400 years , for several thresholds .",
    "the curves correspond to threshold of 100 , 150 , 165 , 180 and 350 mm , respectively from left to right , for annual maximum rainfall .    , for thresholds",
    "@xmath149 , @xmath150 , 165 , 180 , 350 , as a function of time @xmath147 , in years . ]",
    "as an illustration , a maximum value larger than 100 mm , that corresponds to the ninth observed decile , has a 10@xmath151 chance of being recorded after 27 years , and a 56@xmath151 chance of being observed during the next ten years .",
    "an annual maximum larger than 165 mm , not recorded in the sample , has a 3@xmath151 chance of being recorded during the next 10 years , 12@xmath151 during the next 50 years and 20@xmath151 probability of being observed during the next 100 years .",
    "axis , to reach threshold @xmath145 , @xmath152 axis . ]    finally , given a threshold @xmath145 , we may demand the expected time until recording a value not smaller than @xmath145 , @xmath153 : @xmath154    figure [ figure7 ] presents expected times @xmath153 , to reach threshold @xmath145 ( indicated as abscisse ) . for instance , the expected time to record an annual maximum higher than 140 mm is around 46 years , and 77 years is the expected time until an annual maximum surpasses 150 mm .",
    "in this work we are testing two kinds of models : diffusion processes versus diffusion processes with bernoulli jumps . we could also be interested in testing for more general jump families , which allow , for instance , heavy - tailed distributions or diffusion processes having non - constant volatility against processes having constant volatility .    the proposed test procedure extends naturally for each of theses families of models , as long as there is a sharp hypothesis to be tested .",
    "modifications on the likelihood function are straightforward . the computational cost increases with the size of the parameter space , as the required probabilities are integrated directly on the latter .",
    "we stress the absolute continuity of the posterior distribution .",
    "the chosen priors are usually lebesgue absolutely continuous , entailing absolute continuity of the posterior for the models in our context .",
    "the measure of evidence used in this paper is associated ( section [ intro ] ) to a decision problem . in the real decision problem",
    ", we could - and should - consider the loss function the minimization of its expected value is tantamount to performing the fbst .",
    "kadane , j.b .",
    "( 1977 ) the role of identification in bayesian theory . in _ studies in bayesian econometrics and statistics , in honor of leonard j. savage _ , ( eds . fienberg , s.e . and zellner , a. )",
    "i : 175 - 191 ."
  ],
  "abstract_text": [
    "<S> a new bayesian significance test is adjusted for jump detection in a diffusion process . </S>",
    "<S> this is an advantageous procedure for temporal data having extreme valued outliers , like financial data , pluvial or tectonic forces records and others .    </S>",
    "<S> * keywords : * full bayesian significance test , jump - diffusion process    full bayesian analysis for a class of    jump - diffusion models    * laura l.r . </S>",
    "<S> rifo * +    * soledad torres * + </S>"
  ]
}