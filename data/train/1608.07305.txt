{
  "article_text": [
    "the use of advertisements as a means for marketing consumer goods has been common practice for centuries .",
    "mass distribution of advertisements through newspapers was first made possible by the printing press , but it was the advent of the radio and the television in the twentieth century that ultimately revolutionized advertising by allowing companies to transmit marketing messages into millions of homes around the world simultaneously @xcite .",
    "today , advertising is an over $ 500 trillion dollar global industry , and although advertising through digital media is growing rapidly , television remains the primary advertising medium with total television advertising expenditures making up approximately 40% of the worldwide total @xcite .",
    "advertising on `` linear '' ( traditional live , not on - demand ) television typically consists of an arrangement between content providers / programmers ( tv networks such as abc , nbc and fox or cable operators such as comcast or cox ) and advertising agencies in which the networks / operators are paid to run commercials in order to reach a desired audience .",
    "this audience is typically specified in demographic or psychographic terms , such as `` women 18 - 54 '' , or `` people concerned with health and fitness . ''",
    "a campaign s marketing target can be quantified by three measures : _ impressions _ , which is the total number of times the message or ad is seen by a member of the target audience , _ reach _ , which is the number of unique members of the target groups exposed to the ad , and _ frequency _ , which is the average number of times the ad is viewed by each member of the target group that is reached by the ad .",
    "when a content provider agrees to fill an advertising order , they commit to running the commercial as many times as necessary until the desired number of impressions ( and possibly reach and frequency ) have been obtained .",
    "since the available commercial time in a given time frame is limited and each order that a content provider is able to fill provides additional revenue , it is of interest to meet each impression target in such a way that leaves broadcast time available for additional orders .",
    "therefore , before an order can be accepted , content programmers must assess whether the number of impressions can be achieved in an acceptable time - frame and whether the budget for the order is large enough to warrant using broadcast time to provide those impressions .    in order to make this determination ,",
    "it is necessary to be able to generate a schedule that satisfies the order constraints in an efficient way .",
    "however , the generation of optimal advertising schedules poses a number of challenges .",
    "first of all , one must know the viewership demographics of each television program .",
    "unfortunately , this is not known in advance and can only be estimated from past viewership data .",
    "secondly , depending on the content provider and time - frame , there can be a large number of possible orders and available commercial slots along with a large number constraints on what schedules are acceptable .",
    "this makes finding an optimal schedule a computationally intensive problem that can not usually be solved by hand .",
    "for this reason , naive approaches to scheduling lead to wasted resources and disenchanted audiences when ads fail to reach the interested consumers efficiently and must be aired repeatedly in order to meet impression targets .    here , we address two aspects of this interesting mathematical problem .",
    "first , using data modeled statistically mimic real tv viewership behavior as reported , for example by the nielsen company @xcite , we explore a number of methods for predicting the number of impressions of future programming ( section [ sec : predict ] ) .",
    "these methods make use of spectral analysis , machine learning , kalman filtering and distance scores .",
    "second , we demonstrate that when combined with advertising orders , these predictions can be used to formulate a nonlinear optimization problem that can be solved using standard integer programming techniques ( section [ sec : bip ] ) .",
    "finally , we outline a method for extending earlier results to account for the reach and frequency of an advertisement ( section [ sec : reach ] ) .",
    "this work was sponsored by clypd inc .  and made possible by the 2015 mathematical problems in industry workshop .",
    "in order to generate predictions for the viewership and demographics of future programs , we used simulated past program viewership data provided by clypd inc . since precise data on the viewership of commercials was not available , we assume that program viewership data is representative of the viewership of advertisements as well .",
    "figure [ fig:0 ] shows a time series for the number of impressions on one particular channel over a period of about 273 days .",
    "qualitatively , the signal is noisy with large spikes in the viewership .",
    "although the data appears noisy , there are clear periodic trends in the data .",
    "these are mostly likely driven by the periodic nature of the channel programming . in order to identify these trends , we assume that the number of impressions , @xmath0 can be decomposed into a deterministic , periodic part @xmath1 and a stochastic part @xmath2 , @xmath3 we attempt to filter the signal to remove @xmath2 , leaving behind @xmath1 by first filling in missing data using linear interpolation and then performing a fourier transform on the data and taking only the dominant modes in the power spectrum .    ) .",
    "( c , d ) : filtered signal and power spectrum with @xmath4 .",
    "( e , f ) : filtered signal and power spectrum with @xmath5 . ]    ) .",
    "( c , d ) : filtered signal and power spectrum with @xmath6 .",
    "( e , f ) : filtered signal and power spectrum with @xmath7 . ]    for this filtering scheme , we used matlab s ` fft ` and ` ifft ` algorithms to compute the power spectrum and then removed all frequencies with amplitude less than a given threshold @xmath8 .",
    "we write the full signal as @xmath9 where @xmath10 is the time ( in hours ) , @xmath11 is the number of frequencies in the transform , @xmath12 is the total duration of the signal , @xmath13 and @xmath14 are complex amplitudes ( conjugates of each other ) , and @xmath15 are dimensionless frequencies . for our data set , we have @xmath16 , and the total duration of the signal is @xmath17 hours @xmath18 days .",
    "this corresponds to 6551 data points @xmath19 and 6551 fourier coefficients ( distinguishing between @xmath13 and @xmath14 ) and therefore , representation ( [ eqn : ss ] ) exactly reproduces @xmath0 .",
    "we decompose the signal @xmath0 as follows @xmath20 where the _ signal _ is defined as @xmath21 while the _ noise _ is defined as @xmath22 therefore , noise can be eliminated by removing all frequency modes @xmath23 such that @xmath24 . in other words ,",
    "which fourier modes are considered part of the signal and which are part of the noise depends solely on the cut - off @xmath25 .",
    "the resulting signal is displayed in figures [ fig:1 ] ( for the general viewership ) and [ fig:2 ] ( for males 65 and older ) .",
    "power spectra are shown for rescaled frequencies @xmath26 which have units of inverse time . in figure",
    "[ fig:1 ] , we see that there are `` spikes '' at @xmath27 per day for @xmath28 .",
    "there are also spikes at @xmath29 and @xmath30 per day .",
    "broadly speaking , the power spectra reveal that the predictable portion of the signal contains nine dominant frequencies / periods for viewer behavior    1 .",
    "the zero mode in which the television is always on or off , regardless of the time ( @xmath29 per day ) 2 .   viewing patterns that repeat weekly ( @xmath31 per day ) 3 .   viewing patterns that repeat twice per week ( @xmath32 per day ) 4 .",
    "viewing patterns that repeat three times per week ( @xmath33 per day ) 5 .   viewing patterns that repeat four times per week ( @xmath34 per day ) 6 .   viewing patterns that repeat five times per week ( @xmath35 per day ) 7 .   viewing patterns that repeat six times per week ( @xmath36 per day ) 8 .   viewing patterns that repeat daily ( @xmath37 per day ) 9 .   viewing patterns that repeat twice daily ( @xmath38 per day )    these behaviors do not necessarily refer to the same members of the viewership .",
    "the frequencies above also appeared in different demographic groups .",
    "however , males and females 65 and older did not exhibit these frequencies ( see fig .",
    "[ fig:2 ] ) suggesting that older members of the population have qualitatively different viewing habits .",
    "we should note , however , that upon taking different 7-week subsets of the data , some of the spikes at @xmath39 no longer appear .",
    "that is , the @xmath29 , @xmath37 and @xmath38 per day modes are the most robust .    in summary ,",
    "viewership patterns are periodic with both daily and weekly frequency components .",
    "the weekly pattern is shown as a solid black curve in figure [ v2 ] .",
    "this figure indicates the median number of impressions over a typical week along with confidence intervals .",
    "the distribution of impressions at a given time in the week is found from the first 38 weeks of data .",
    "90% confidence intervals ( dashed light blue ) are calculated by taking the 5th and 95th percentiles of the distribution .",
    "we see that during the evening of each day , there is a rise in the viewership .",
    "saturday seems to be the hardest to predict since it has the highest variability in impressions .",
    "the red curve shows the viewership over the 39th week , which mostly falls within the confidence intervals .",
    "( obtained using the cut - off @xmath5 ) is displayed along with fitted normal and @xmath10 location - scale distributions .",
    "the mean and standard deviation of the best - fit normal pdf are @xmath40 and @xmath41 .",
    "the parameters of the best - fit @xmath10 location - scale pdf are @xmath42.,scaledwidth=70.0% ]    we now examine the noise @xmath2 , after removing the periodic signal using @xmath5 .",
    "we assume that @xmath43 is a time - homogeneous sequence of random variables with a different realization for every @xmath10 : @xmath44 = f(x ) dx.\\ ] ] attempts at fitting this data to various well - known probability distributions reveals two distributions that yield a good fit : normal and the @xmath10 location - scale distributions ( see fig [ fig:5 ] ) with @xmath10-location - scale distribution yielding a better overall fit .",
    "for a normal distribution , the we obtained the best - fit @xmath45 with @xmath40 and @xmath41 .",
    "for the @xmath10 location - scale distribution with probability density function @xmath46}{\\sigma \\sqrt{\\nu \\pi } \\gamma(\\nu/2 ) } \\left [ \\frac{[(x-\\mu)/\\sigma]^2+\\nu}{\\nu}\\right]^{-\\frac{\\nu+1}{2}},\\end{aligned}\\ ] ] we found that the best - fit parameters were @xmath47 , @xmath48 and @xmath49 .",
    "one notable feature of @xmath0 is that large spikes seem to occur randomly in time .",
    "we define the spiking event time as the time when the impressions signal crosses a fixed threshold from below ( see fig . [",
    "fig : sp1 ] ) .",
    "here we choose the threshold to be the 95th percentile of the available impressions data points .",
    "in figure [ v4 ] , we show that the distribution of waiting times @xmath50 between consecutive spikes appears to be approximately exponentially distributed : @xmath51 = \\lambda \\exp(-\\lambda t ) dt.\\ ] ] this suggests that the spiking has no memory ( spiking is approximately markovian ) and occurs at a poisson rate of @xmath52 per hour , so that the mean time between spikes is about 69 hours .",
    "the analysis of spiking time was performed on unfiltered data @xmath0 .",
    "one might also consider spikes in the noise left over from the filtering , @xmath2 .",
    "however , this yields similar results because the periodic signal generally has small amplitude .",
    "although spectral analysis of viewership data provides insight into the mechanisms that contribute to the observed trends , this approach assumes periodic behavior and ignores programming information .",
    "these findings can be helpful for filling in missing data and for estimating viewership of new programming , but an approach that takes into account the programming could potentially explain both the periodic behavior and the noise .",
    "we therefore implement a machine learning algorithm to predict the number of impressions in a time slot by learning from past data .",
    "the machine learning task is defined with the following attributes : program i d ( nominal ) , day of the week ( nominal ) and time of the day ( numeric ) .",
    "the output class is the number of impressions .",
    "we explored two different approaches .",
    "first , we treated the output class as numeric .",
    "a number of machine learning methods are suitable for this task , and we tested k - nearest neighbor , neural networks , linear regression , regression tree , and k - star . the best performing algorithm was 1-nearest neighbor .",
    "the root relative square error for this method was 61% ( 100% would correspond to the error in naively guessing the mean of all impressions ) .",
    "second , we divided the output class into 5 bins , and tested 4 algorithms : decision trees , random forest , naive bayes , and random tree .",
    "decision tree and random forest performed equally well - the error was 44% ( compared with 80% from naively guessing the correct bin ) .",
    "a learning curve is shown in figure  [ fig : ml1 ] .",
    "the fact that the curve did not plateau shows potential for more accurate prediction given more data .",
    "the fact that testing error decreases with training error demonstrates that this approach does not over - fit the data .",
    "we also investigated the use of bayesian estimation and kalman filtering to predict the number of impressions for a program . in order to do this , we neglected any sampling issues that may be present in the data and assumed perfect data .",
    "we treated the number of interested viewers as fixed with a particular probability of watching the program or not .",
    "this probability can be modeled by a binomial distribution because of the two possible values ; however , due to the large sample size of viewers , we can apply the central limit theorem and approximate the distribution with a normal distribution @xcite .    for a bayesian estimation , a prior probability distribution and likelihood function",
    "must be assumed in order to formulate an initial prediction .",
    "after this initial prediction is made , the new data is observed and is used to update the probability distribution and gives a posterior probability distribution . for our purposes , this posterior distribution was then used as our prior for predicting the next week @xcite .",
    "the number of impressions , @xmath53 , for each week @xmath54 was modeled by a gaussian with mean @xmath55 and standard deviation @xmath56 . while we allow @xmath57 to vary from week to week , we keep @xmath56 fixed for simplicity . under the bayesian framework , we view @xmath55 as an unknown parameter which we will represent by a subjective probability distribution .",
    "we can think of @xmath58 as a measure of the popularity of the show at week @xmath59 , while the actual viewership will have an unpredictable fluctuation from week to week due to external factors .",
    "the standard deviation @xmath56 measures this inherent variability in weekly viewership .    to find a reasonable value for the fixed @xmath60 ,",
    "the available data was divided into a particular number of bins . for each bin of data ,",
    "the standard deviation was found , and then all of the standard deviations were averaged together to get an _",
    "standard deviation .",
    "this was repeated multiple times with varying numbers of bins in order to choose the optimal ( smallest ) standard deviation .",
    "the smallest value found was then used as @xmath60 for @xmath61 .    to understand the distribution of @xmath62 , a recursive bayesian estimation was used . to start ,",
    "a weak prior probability distribution was chosen for @xmath62 based on a gaussian fit to a histogram of 39 weeks of historical viewership data for a given time slot on a given channel on a given day .",
    "these histograms and their gaussian fits are illustrated in figure  [ fig : histnorm ] for 7 different weekly time slots , namely 8 p.m. on the given day of the week and a given channel .",
    "in particular , the prior distribution for @xmath57 will depend on the time of the week ( and channel ) under consideration .",
    "bayes rule is applied in the usual way to update the prior distribution for an upcoming week with the likelihood of the data , once collected , to obtain a posterior distribution for @xmath57 on that week .",
    "this posterior distribution is then taken as the prior distribution for @xmath57 on the following week . the likelihood model , as described above , is gaussian , so the recursive bayesian estimation procedure reduces to a simple version of the kalman filter , with the predicted ( prior ) distribution of the parameter @xmath57 at the next week taken to be the same as the posterior distribution on the current week . the evolving value of @xmath57 is used as a point estimate for the expected number of impressions for a given channel on a given day of the week at a given time .",
    "in order to assess the performance of this model , we chose the first 20 weeks of data as the `` training '' data and then tested the model against the last 19 weeks .",
    "we tested 7 such data sets , namely the viewereship of a given channel at 8 p.m.   on one of the 7 days of the week .",
    "for every day of the week the relative errors between the predicted impressions and observed number of impressions for the last 19 weeks were computed .",
    "the root mean square ( rms ) of the relative errors was calculated as the measure of error for our model .",
    "the rms error for each day of the week was below 30% , where days such as tuesday , friday and saturday were under 10% .",
    "this suggests that our model is able to make reasonably accurate predictions for the number of future impressions given the data from the first 20 weeks .",
    "these results are displayed in table [ impress ] .",
    "the table also includes an example of our model s prediction for a week ( 39@xmath63 week ) for a particular network at 8:00pm .",
    ".impressions estimate for february 2 - 8 , 2015 for a given network at 8:00pm .",
    "the model estimates are given along with the observed number of impressions .",
    "the relative errors for the displayed week is calculated and compared to the root mean square determined from all of the 39 weeks . [ cols=\"^,^,^,^,^,^,^,^ \" , ]",
    "in this section , we implement a method for creating an optimal schedule of advertisements , given a set of orders from an advertising agency and predicted viewership numbers such as those that could be generated using the methods outlined in section [ sec : predict ] .    in order to formalize the optimization method we define the following notation and assumptions :    *",
    "@xmath64 is the total number of channels , and the subscript index @xmath65 with @xmath66 is used to denote one particular channel .",
    "* @xmath67 is the number of commercial slots on channel @xmath65 , and the subscript index @xmath68 with @xmath69 is used to denote the corresponding slot .",
    "this index takes into account both day and time .",
    "we assume the number of slots are specified by programmers in advance .",
    "* @xmath70 indicates the price for commercial slot @xmath68 on channel @xmath65 .",
    "we assume these prices are set by the programmer in advance .",
    "* @xmath71 contains the number of impressions for slot @xmath68 , demographic group @xmath72 , on channel @xmath65 .",
    "we assume these values are provided in advance and that this data is reliable .",
    "* @xmath73 gives the number of advertising orders , and the superscript index @xmath74 with @xmath75 denotes one particular order .",
    "we assume that all orders for a given week are received in advance , that the schedule can be determined one week at a time , and that all advertisers have equality priority and therefore orders accepted or rejected only on the basis of whether the order is likely to be satisfiable .",
    "* @xmath76 is a binary vector indicating the target demographics in the order for advertiser @xmath77 .",
    "* @xmath78 contains the number of impressions for slot @xmath68 , in the demographics specified by advertiser @xmath77 , on channel @xmath65 . in other words , @xmath79 .",
    "we assume that all target demographics are of equal value to the advertiser and therefore the desired number of impressions can be satisfied by any subset of the target audience .",
    "* @xmath80 represents the budget of advertising order @xmath77 , and @xmath81 represents desired impressions for order @xmath77 .",
    "we assume that these requirements are strict and can be implemented as hard inequality constraints for the solution .",
    "* @xmath82 is a ` binary matrix ' indicating whether advertiser @xmath77 is assigned to slot @xmath68 on channel @xmath65 .",
    "this is the schedule we are trying to find .",
    "we now use this notation to express the scheduling problem as a constrained optimization problem .",
    "the most basic constraint on a proposed schedule is that two advertisements can not air simultaneously on the same channel .",
    "no overlap : _ + only one advertiser can use a given slot on a given channel . mathematically , this can be stated as @xmath83 this constraint can be modified to allow for variable length commercials by weighting each entry in @xmath82 by the commercial length for advertiser @xmath77 and then changing the right hand side to include the number of ` time slots ' in each commercial break .",
    "in addition to this , each order @xmath74 that is accepted imposes two additional inequality constraints on the schedule .",
    "budget : _ + the total cost to each advertiser must not exceed their budget @xmath80 .",
    "this implies that @xmath84 note that it may not be possible to satisfy every order , so if the total cost to an advertiser is greater than 0 , then we must also meet the target number of impressions .",
    "impression target : _ + the total number of impressions ( as given by @xmath78 ) must exceed the campaign goal @xmath81 . in other words , @xmath85 since this linear inequality only yields a feasible region if it is possible to satisfy every order ( which in practice is unlikely ) , we impose these constraints by solving a sequence of optimization problems where @xmath81 are replaced with 0 for the orders we are not able to fill . in section [ vf ] ,",
    "we propose a value function that can be used to determine which orders should be eliminated .",
    "the above constraints are necessary to obtain a usable schedule that satisfies the advertising campaign goals .",
    "however , programmers may impose additional requirements on allowable schedules to prevent consecutive airings of the same commercial ( @xmath86 for all @xmath68 , @xmath65 , @xmath77 ) , commercials with adult content from airing during children s programming ( @xmath87 for particular @xmath68 , @xmath65 , @xmath77 ) , etc .",
    "these and any other requirements can be implemented by imposing additional inequality and equality constraints on @xmath82 .",
    "however , for simplicity , we omit these constraints in what follows .      presumably , the advertising schedule is set by the programmer or an intermediary who is interested in maximizing advertising revenue .",
    "therefore , the objective function of interest is simply the total revenue which is given by @xmath88      this optimization problem involves finding a vector inputs @xmath89 ( a vectorized version of @xmath82 ) that satisfies a set of linear constraints and that maximizes the value of a linear objective function .",
    "if the inputs were real numbers , then this could be solved with a linear program .",
    "however , @xmath89 must contain binary inputs so therefore we solved this using a binary integer program .    to implement this program ,",
    "we write the inequality constraints as a matrix inequality @xmath90 and the objective function as dot product @xmath91 where @xmath92 is a vectorized version of @xmath93 .",
    "this allows us to make use of matlab s built - in mixed integer linear programming algorithm from the optimization toolbox .",
    "this algorithm consists of the following three steps @xcite :    1 .",
    "solve the linear programming problem without the integer valued constraints .",
    "2 .   use a heuristic algorithm to find a nearby feasible integer solution .",
    "3 .   perform branching to try to improve on the heurtistic feasible solution .    depending on the data and parameters used",
    ", this algorithm occasionally finds a solution which sells all of the time slots or it fills all of the order leaving some time slots unfilled .",
    "these outcomes represent the global maximum for the revenue .",
    "other times , it can not find a feasible solution at all .",
    "this suggests that a high quality heuristic is necessary for finding feasible solutions to initialize the integer program @xcite .",
    "we explore one such heuristic in section [ greedy ] .",
    "one explanation for this inability to find a feasible solution is the fact that it is not always possible to satisfy all of the orders . to overcome this",
    ", we iteratively remove orders and instead choose a subset of the orders that includes only the ones that are the most valuable ( see section [ vf ] ) .      in order to generate a feasible solution both to initialize the integer program and to compare to the results from the integer program , we also implemented a greedy algorithm . in this algorithm",
    ", we generate a matrix @xmath94 , where the rows are indexed by the slot @xmath95 and the columns are index by the advertiser @xmath77 . we assign a value to each entry of @xmath94 for each advertiser . then we choose the slot with the highest value and assign that to the advertiser who gets the most value from that slot .",
    "the value of slot @xmath95 is for advertiser @xmath77 is equal to @xmath96 which represents the fraction of the desired impressions that can be provided by the slot divided by the fraction of the budget that must be used for the slot .",
    "this process is repeated until there are no longer available slots , the orders have all been met or no advertisers can afford a slot . at this point , incomplete orders are removed and the process is repeated with the remaining orders until all orders have been satisfied or removed .      in order to determine which orders should be rejected , a systematic way of prioritizing orders is needed .",
    "below , we propose a heuristic ranking scheme .",
    "+   + _ step 1 : eliminate unreasonable orders _",
    "+ if the number of impressions desired is more than the size of the viewership for that demographic ( in the time allotted ) , then the order can not be satisfied .",
    "these orders should be rejected immediately . in other words",
    ", an order must be rejected if @xmath97 .",
    "+   + _ step 2 : monte carlo method _ + a monte carlo method can be used to estimate the number of feasible solutions for each advertiser .",
    "we then assign a value proportional to that number .    1 .",
    "first generate a random binary vector @xmath82 for fixed @xmath77 .",
    "2 .   check to see if it is feasible .",
    "3 .   repeat @xmath11 times .",
    "let @xmath98 be an @xmath11 by 1 vector indicating which candidate solutions are feasible . then , the fraction of solutions that are feasible is given by @xmath99 which we call the value function , and the orders that are more likely to be satisfiable should be prioritized .",
    "this provides a simple method for identifying feasible orders .",
    "however , in practice the decision making process might be more complex .",
    "for example , if rather than having fixed time - slot prices advertisers were allowed to bid for a given slot , then the advertisers with larger budgets relative to their demands should be prioritized since their orders are likely to be both more satisfiable and more lucrative . also , if a variable scheduling horizon for orders is allowed ( rather than focusing on a single week at a time ) ,",
    "then the urgency of the order should also be taken into account .",
    "+   + _ modification 1 : weight by excess budget .",
    "_ + this value function can be modified to account for bidding on time slots by weighting the feasible solutions by the price the advertiser would be willing to pay in an auction .",
    "an advertiser should be willing to increase the bid by a factor of @xmath100 to remain under budget and ensure that their advertising campaign order is accepted .",
    "so , given a set of random @xmath82 from the monte carlo method above , rather than just computing the fraction that are feasible , the feasible schedules can be weighted to account for the amount of leftover money in the budget . for a feasible solution @xmath23 ,",
    "the percentage of the budget that is unused is just @xmath101 let @xmath98 be an @xmath11 by 1 vector indicating which candidate solutions are feasible .",
    "let @xmath102 be the percentages from above .",
    "then the total value of an order would be given by the average of this excess @xmath103 and orders with larger average value should be prioritized . in order to balance both feasibility and value ,",
    "a balance of the monte carlo and bidding based values such as @xmath104 was employed , where @xmath105 represents the relative weight of the excess budget to the feasibility .",
    "+   + _ modification 2 : weight by urgency . _",
    "+ in order to take into account variable time frames for orders , this value could factor in the fact that certain orders are more urgent than others .",
    "orders that have already been accepted will usually need to be prioritized over new orders .",
    "for new orders , some orders with short time tables will be infeasible , others with short time tables would need to be completed immediately , and orders with long time tables may be saved for later , but not postponed so long that they become infeasible .",
    "this modification was not implemented , but it warrants further exploration .      in order to test this optimization scheme",
    ", we used a subset of the viewership data over a single work week ( monday - friday ) between the hours 5:00am-12:00am for three channels .",
    "we also assumed that impressions by demographic are constant over the span of an hour ( if there are two half hour shows in an hour we average the impressions per demographic from both shows ) and do not take into account any uncertainty in the estimates of impressions per time slot .",
    "the results are displayed below .",
    "for this data set , an optimal schedule can be found that satisfies the top 49 orders and fills all available ad time when orders are sorted using the monte carlo value function .",
    "the optimal schedule is shown in figure [ sample_schedule : fig ] . with more orders",
    ", however , the algorithm fails because it is unable to find a feasible solution .",
    "thus iterative reductions in the total number of orders are necessary before a satisfiable subset of orders can be found .",
    "in contrast , the greedy algorithm always yields a feasible solution ( by automatically rejecting unsatisfied orders ) , but that solution may not be close to optimal . with 149 orders ( the total number of sample orders in our data - set ) ,",
    "a solution satisfying 112 orders that generates 91.8% of the maximum allowable revenue is found in 0.57 seconds whereas the integer program finds the optimal solution satisfying as many as 49 orders in 6.5 seconds .     with @xmath106 .",
    "this suggests that the computation time is proportional to the square of the time frame . ]    in the our data set , adding more time slots by expanding the time horizon to several weeks or using more channels with varied viewership allows us to accommodate more orders , but it can also increase the computation time ( see figure [ run_time : fig ] ) .",
    "thus this method may be more suitable for smaller problems with fixed time horizons . scaling the algorithm to larger data sets and to include more complex constraints ( for example , to take into account the reach and frequency of an advertisement ) would require a hybrid approach involving multiple algorithmic frameworks . when long time horizons , large numbers of channels or large numbers of orders must be considered , one promising approach would be to segment orders and schedules into smaller intervals and then apply this integer programming method to each interval . the most efficient method for this segmentation",
    "would likely be dependent on the data considered but there may be structural properties of this type of problem that can be exploited .",
    "therefore , scaling this method effectively would require a deeper look at segmentation strategies that would allow for the large scale problem to be divided into pieces that could be solved in parallel .",
    "these results suggest that binary integer programming provides a flexible framework for implementing the essential constraints and searching for optimal solutions",
    ". however , the development of new heuristics and improvement of current heuristics could be beneficial for scaling of the problem to more realistic sizes and warrants further exploration .",
    "in addition to the total number of impressions , advertisers may also be interested in specifying the desired _ reach _ and _ frequency _ of their advertisements .",
    "the _ reach _ of an advertisement is the number of unique individuals who have received at least one impression of the advertisement , and the _ frequency _ of an advertisement is the mean number of times the advertisement is seen by these individuals . from detailed viewership data",
    ", we can express the reach of an advertisement by the following exact formula : @xmath107 where @xmath108 is number of _ new _ impressions made at time slot @xmath109 of the @xmath23th airing of advertisement , and @xmath110 is the total number of times the advertisement is shown . to reduce the notational complexity , we are dropping here the indices referring to the channel and demographic group , essentially assuming we are focusing on a fixed channel and a specified demographic group .",
    "this can be generalized in principle to allow multiple channels and multiple demographic groups , with accompanying complication in notation .",
    "the formula for reach is to be contrasted with the formula for total number of impressions made by the advertising campaign , @xmath111 where @xmath112 is the number of impressions ( including both new and repeat viewers ) made at the time slot @xmath109 of the @xmath23th airing of the advertisement .",
    "@xmath113 by contrast only counts those viewers on whom an impression was made at time slot @xmath109 , but not on a previous airing of that advertisement .",
    "consequently , to count reach , we must know more about the viewership than simply the statistics for the number of impressions likely to be made in each time slot .",
    "put another way , the number of impressions @xmath114 is only a function of the data at time slot @xmath115 ( and thus may be thought of as a one - dimensional marginal distribution of the viewership data ) , whereas the number of new impressions @xmath116 depends not only on the statistics of time slot @xmath115 by also on statistics of previous time slots ( and thus inherently involves joint distributions of viewership data at different time slots ) . to make matters more complicated for the purpose of schedule optimization , the number of impressions @xmath114 in a time slot depends only on the time slot in which the ad is scheduled , whereas the number of new impressions @xmath117 depends not only on the time slot @xmath115 but also the previously scheduled time slots of the advertisement .",
    "the average frequency fortunately is easily determined from the reach by the simple formula : @xmath118      as noted above , the reach of a previously aired advertisement can easily be calculated from historical data . however , predicting the reach of a proposed future advertising campaign is a much more delicate matter . even if the viewership of future programs could be assumed to be identical to previous weeks , the reach could be calculated for any proposed schedule , but this would be an expensive and unwieldy calculation .",
    "either it would be necessary to do an online processing of historical data , or it would be necessary to refer to an intractably large data structure which has precomputed reach scores for every feasible advertising schedule . including reach into the optimization scheme for the advertising schedule would , as we show , introduce an inherent nonlinearity , and nonlinear optimization typically requires additional iterations beyond that required for linear optimization .",
    "that means many schedules will be proposed in the optimization , and thus the expensive reach computation would be invoked many times .",
    "we therefore consider a simplified way to estimate future reach .",
    "such simplification is justified in particular because future viewership can not be perfectly predicted , so involving a expensive and precise computation for reach in the schedule optimization algorithm would seem to be a misplaced effort .",
    "we propose encoding the information needed for future reach calculations in a two - slot function @xmath119 which , for @xmath120 , represents an estimate of the fraction of viewers at time slot @xmath121 who also viewed time slot @xmath115 .",
    "under our standing simpilfying assumptions , @xmath119 could be estimated from historical data , possibly using the kalman filtering idea in section [ sec : kalman ] .",
    "if we allow future time slots to be associated with programs different from those in the past , we could try to develop an inference scheme for combining historical data on viewership of time slots with viewership of programs .",
    "but this might still be attempting too fine a resolution .",
    "since the number of potential time slots in which a proposed advertisement could air within a typical campaign window is large , such a detailed data - driven approach would require the storage of @xmath122 as an immense matrix , which would be at least @xmath123 for a weeklong campaign even in our very simplified setting , and much larger in practice .",
    "a more tractable approach might be to simply treat @xmath119 as a function of only @xmath124 , meaning essentially the time difference between slots ( and possibly also a measure of difference between channels for a multichannel campaign ) .",
    "we might imagine that @xmath125 begins as a decaying function of @xmath126 , but has peaks at multiples of a day and a week for patterned viewer behavior .",
    "perhaps historical data could be fit to a sum of a small number of periodic functions with frequencies identified by the spectral analysis in section [ sec : spectral ] , with decaying amplitudes .",
    "we now assume we have in hand some scheme for estimating the two - slot function @xmath119 , and now wish to estimate the reach of a proposed scheduling of the advertising campaign in time slots @xmath127 . according to formula",
    ", we need to estimate the number of new impressions made with each airing of the advertisement , and we propose to approximate this in terms of the estimated number of impressions and the two - slot function as follows : @xmath128 that is , the estimated number of new impressions is equal to the estimated number of impressions , discounted by factors @xmath129 representing the fraction of the viewers of the @xmath23th airing of the ad who did _ not _ also see the prior @xmath130th airing of the ad .",
    "the approximation in eq .",
    "is conditional independence of the viewership of all previous airings of the advertisement by the viewers of the @xmath23th airing of the advertisement . for a concrete example , for @xmath131 ,",
    "the _ conditional _ independence assumption is that whether viewers of the third airing of the advertisement watched the first airing of the advertisement is independent of whether they watched the second airing .",
    "note that this is not the same as stating that a general viewer has an independent chance of viewing the first and second airing of the advertisement ( unconditional independence ) .",
    "indeed , if @xmath132 and @xmath133 were @xmath134 , then the probability model underlying the formula   would have a substantial positive correlation between the viewers of the first and second airing of the advertisement .",
    "the point of the conditional independence assumption is that we assume all such correlations between the viewership of the various airings of the advertisement can be well represented by an explicit model of the correlation between the viewer of each airing @xmath135 and the airing @xmath136 under consideration , with the correlations between the previous airings being implied ( not neglected ) by the conditional independence assumption .",
    "the conditional independence assumption can lead to either overestimates or underestimates of the reach .",
    "for example , if the airings occur during successive episodes of a program with a substantial committed core base who watches every episode , the number of new impressions would be underestimated by formula  . on the other hand ,",
    "if the airings of the advertisement involve some episodes repeated at different times during a week , the viewership of those airings would be more negatively correlated than the conditional independence assumption , and the number of new impressions could be overestimated by formula  .",
    "this can be verified under a simple model in which no viewer makes repeated viewings of the same episode at different times .",
    "some kind of conditional independence assumption seems to be necessary to reduce the reach calculation to a complexity comparable to the 2-slot statistic .",
    "another natural way to invoke conditional independence is via a markov chain model , which would only attempt to explicitly model the repetition in viewership between successive airings of the advertisement .",
    "such a markovian approach appears less suitable than the conditional independence we suggest in the previous paragraph for a couple of reasons .",
    "first of all , it is unclear how to deduce the number of new impressions made on the third airing of an advertisement by knowing how many viewers of the first advertisement saw the second advertisement , and how many viewers of the second advertisement saw the third advertisement . how does one infer from this the number of viewers of the third advertisement who saw neither the first nor the second airing ? moreover , the markovian approach seems completely incapable of representing the likely strong repeat viewership of a regularly airing program from one week to the next , if advertisements are also aired in between those weekly episodes .",
    "so if the first and third airing of the advertisement took place one week apart in successive episodes , and a second airing took place in between , one would expect a large number of repeat viewers between the first and third airing , but not between the second airing and either the first or third airing .",
    "the approximate reach estimate developed in subsection  [ sec : reach_predict ] can be expressed as a polynomial function of the schedule vector @xmath137 : @xmath138 where @xmath139 is the number of slots available on the channel @xmath65 under consideration .",
    "constraints involving reach ( or frequency ) would become smooth nonlinear constraints , and after relaxation from the integer constraint , could be approached by the alternating direction method of multipliers @xcite .      for the purpose of building in safety margins in a schedule to avoid disappointing an important advertising client ,",
    "we might be interested in characterizing the risk that a particular advertising campaign might miss the targets set by an advertiser s bid .",
    "the simplest characterization of uncertainty would be a standard deviation .",
    "if the number of impressions @xmath140 and the 2-slot characterization of repeat viewership , @xmath119 are directly estimated from historical data by one of the methods described in section [ sec : predict ] , and then those methods could also be used to produce uncertainty estimates .",
    "( kalman filtering does this automatically . )",
    "the reach and frequency are somewhat complicated functions of these variables , so in what follows , we describe one simple way we might translate the uncertainty estimates of these variables to an uncertainty estimate for reach and frequency .",
    "we begin by assuming the uncertainty in the estimates of @xmath141 and @xmath142 are all independent , and indicate the mean of a random variable @xmath143 as @xmath144 and its standard deviation as @xmath145 ( so variance is @xmath146 ) .",
    "because the variance of a sum of independent random variables is the sum of the variances of each term , we can therefore express the variance of the reach as a sum of the variances of the new impressions : @xmath147 the independence assumption does allow the variance of the new impressions , @xmath148 to be worked out in a closed form expression in terms of the mean and standard deviations of @xmath141 and @xmath142 , but this expression is quite long .",
    "we therefore compute an approximation to the variance that is valid when the standard deviations of all the constituent random variables are small compared to their means : @xmath149 then one can conduct a small noise expansion by writing every random variable in the form @xmath150 , taking a taylor expansion up to first order in the fluctuations @xmath151 and @xmath152 , and then computing the variance .",
    "we can thereby obtain : @xmath153 actually this small noise expansion can be readily generalized to allow correlations between the random variable models for @xmath154 and @xmath155 ; the same strategy would produce further sums involving the covariances between all pairs of these variables .",
    "applying the same small noise approximation to the frequency , we obtain an estimate for its standard deviation : @xmath156 where @xmath157 similar estimates can be made for the predictions for future numbers of impressions thereby making it possible to estimate the inherent risk in any given schedule .",
    "in this report , we analyzed the problem of optimally scheduling advertisements using several different methods . first , we analyzed historical data to obtain trends in the viewership .",
    "we found that the viewership was strongly periodic and that deviations from the periodic signal ( noise ) were approximately bell - shaped .",
    "we supplemented these analyses with predictions from several machine learning algorithms for viewership , from a bayesian procedure for predicting new program impressions from the program s target demographic , and a measure for comparing programs in order to fill in missing or unknown data .",
    "second , we developed an algorithm , based on binary integer programming , to schedule advertisements .",
    "given orders in the form of a budget , number of impressions desired and demographic targets , the algorithm produces a binary matrix that tells the media company how to schedule advertisements in such a way as to maximize revenue .",
    "the algorithm can be initialized with a schedule generated by a greedy heuristic .",
    "finally , we developed a theoretical framework to quickly estimate the reach ( number of new impressions made ) of an advertisement .",
    "this framework approximates the number of new viewers through historical impressions data and a two - slot function , which gives the fraction of viewers who watched the same advertisement in two time slots",
    ".    in summary , mathematical analysis can be an extremely useful tool for understanding how to best schedule advertisements . techniques from probability , statistics , data science , signal analysis and linear / non - linear programming can all be used to improve and optimize advertising campaigns , give insight into viewership trends and predict the reach of future television programs .",
    "the authors declare that they have no competing interests .",
    "gs bhatt , s burhoe , m capps , cj edholm , s - l estock , p - w fok , n gold , m houser , p kramer , h - w lee , l rossi , d shutt , & vc yang contributed primarily to the development of methods for predicting viewership .",
    "f el moustaid , t emerson , r halabi , q li , w li , d lu , y qian , mj panaggio , & y zhou contributed primarily to the formulation and solution of the scheduling optimization problem .",
    "mj panaggio and p - w fok compiled the content of the manuscript and all contributed to the revision of the manuscript .",
    "this problem and the data used in this project were provided by marco montes de oca and clypd , inc .",
    "this work was partially supported by nsf grant dms-1261594 through the 2015 mathematical problems in industry workshop .",
    "global media report 2014 . technical report , mckinsey & company ( september 2014 ) .",
    "/media / mckinsey / dotcom / client_service / media%20and%20entertainment / pdfs/6232%20_global_media_trends%20report_2014_industry%20overview_v8_online.ashx[http://www.mckinsey.com/\\texttildelow    /media / mckinsey / dotcom / client_service / media%20and%20entertainment / pdfs/6232%20_global_media_trends%20report_2014_industry%20overview_v8_online.ashx ]"
  ],
  "abstract_text": [
    "<S> advertising is a crucial component of marketing and an important way for companies to raise awareness of goods and services in the marketplace . </S>",
    "<S> advertising campaigns are designed to convey a marketing image or message to an audience of potential consumers and television commercials can be an effective way of transmitting these messages to a large audience . in order to meet the requirements for a typical advertising order , television content providers must provide advertisers with a predetermined number of `` impressions '' in the target demographic . </S>",
    "<S> however , because the number of impressions for a given program is not known a priori and because there are a limited number of time slots available for commercials , scheduling advertisements efficiently can be a challenging computational problem . in this case study </S>",
    "<S> , we compare a variety of methods for estimating future viewership patterns in a target demographic from past data . </S>",
    "<S> we also present a method for using those predictions to generate an optimal advertising schedule that satisfies campaign requirements while maximizing advertising revenue .    </S>"
  ]
}