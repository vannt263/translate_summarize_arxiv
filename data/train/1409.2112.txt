{
  "article_text": [
    "proliferation of computer , network and communication technology and applications , and in particular social networking and cloud computing had a great impact on the way personal data is collected , stored and used .",
    "data collected in one location ( e.g. , hospital ) can now be stored remotely in a cloud and accessed from anywhere in the world .",
    "these advances have undoubtedly changed the way we think about privacy  @xcite and what once could have been regulated by legislative measures alone now requires a sophisticated suite of privacy enhancing technologies . in this study",
    "we are concerned with a situation where confidential personal data is made available to a wide range of users who are authorised to perform data mining and statistical analysis , but not to access any individual data .",
    "there are various _ statistical disclosure control ( sdc ) _ techniques that can be used to alleviate this problem  @xcite but , unfortunately , none of them is able to solve it completely , due to its intrinsic contradictory nature . on one hand , one must keep the risk of individual value disclosure as low as possible . on the other hand ,",
    "the utility ( usefulness ) of the data must remain high .",
    "however , low risk implies low utility and high utility implies high risk .",
    "a good sdc technique aims at finding a right balance between the two . in order to achieve this balance ,",
    "it is crucial to adequately measure both utility and disclosure risk .",
    "while measuring data utility has been well studied in the literature  @xcite , measuring disclosure risk is still considered as a difficult problem and has been only partly solved .",
    "* contribution : * ( 1 ) in this paper we propose a novel entropy based measure of disclosure risk , which we refer to confidential attribute equivocation ( cae ) , and which is independent of the underlying sdc technique , and thus can always be used .",
    "the main novelty and advantage of our technique over similar ones is that it takes into account the candidate confidential values themselves , rather than just their probabilities , and is thus able to capture the risk of approximate disclosure of confidential values , rather than the exact disclosure alone .",
    "( 2 ) we develop an efficient dynamic programming algorithm to evaluate the cae .",
    "( 3 ) we show how our technique can be applied to evaluate a few common sdc techniques , including sampling , query restriction and noise addition .",
    "this paper is organised as follows . in the next section we present related",
    "work on disclosure risk measures and in section 3 we present a scenario that is not adequately covered by any of the previous measures and introduce a novel entropy - based measure . in section 4 we present a dynamic programming algorithm for calculating the disclosure risk , in section 5 we use our measure to empirically evaluate a few existing sdc techniques , and in section 6 we discuss the experimental results and give some concluding remarks .",
    "privacy is an elusive concept , and many privacy models have been proposed , with varying success .",
    "we next present a few of the most prominent models , including @xmath0-anonymity and differential privacy .    in a data set , some attributes",
    "may be considered public knowledge and used to identify records .",
    "they are refereed to as `` identifying '' attributes or `` quasi - identifiers '' ( qi ) . a class of records where values of all qi attributes are the same is called _",
    "equivalence class_. to limit disclosure , samarati and sweeney  @xcite  proposed a so - called _ k_-anonymity that requires each equivalence class to have no less than @xmath0 records .",
    "the main problem with _",
    "k_-anonymity arises when all the records in an equivalence class share the same confidential value , which allows intruder to disclose the confidential value without actually re - identifying the record . in order to alleviate this problem , machanavajjhala et al proposed _",
    "l_-diversity  @xcite , which in its simplest form requires every qi to contain at least @xmath1 distinct values .",
    "while this model is indeed a great improvement over @xmath0-anonymity , it does not consider how close these values are from each other , and thus leaves room for approximate disclosure of confidential values .",
    "li et al .",
    "@xcite  introduced _",
    "t_-closeness , which considers the distribution of confidential attribute values in each equivalence class and the distribution of the confidential attribute values in the whole dataset , and requires that the distance between these two distributions does not exceed a given threshold _",
    "t_. while it greatly reduces the disclosure risk , _",
    "t_-closeness is overly restrictive and severely impacts the utility of data . in this context",
    ", our measure of disclosure risk can be seen as bridging a gap between the _ l_-diversity and the rigid _ t_-closeness .",
    "another prominent privacy model is differential privacy  @xcite , which requires that the results to all queries allowed on the database do not change significantly if a single record is added or deleted from the database .",
    "while this is certainly an efficient model against table linkage attack , it is not design to prevent attribute and record linkage @xcite and in practice may be inferior to k - anonymity @xcite .",
    "each one of the above models can be implemented using different sdc techniques , which can be classified as modification techniques and query restriction techniques  @xcite .",
    "_ modification techniques _ involve some kind of alternation of the original data set before it is released to statistical users .",
    "this includes noise addition , data swapping , aggregation , suppression and sampling  @xcite .",
    "the common denominator of all modification techniques is that the modified dataset is released to users who are free to perform any query on it , but the answers they get are only approximate and not exact . on the other hand , _ query restriction techniques _ do not release database to a user but rather provide a query access .",
    "the sdc system decides whether or not to answer the query but if the query is answered , the answer will always be exact and not approximate as with modification techniques  @xcite .    in this study",
    "we are not concerned with sdc techniques or privacy models as such but rather with measuring disclosure risk . in the literature",
    ", disclosure risk measures are classified as measures for record re - identification or confidential value disclosure  @xcite .",
    "the latter focuses on measuring the risk of compromising a confidential value of a particular individual , while the former focuses on measuring the risk of inferring an individual s identity . in either case",
    "the disclosure risk measures may be applied to the database as a whole , or to individual records .",
    "several methods have been proposed to estimate the disclosure risk in sampling and they fall under the category of record identification .",
    "winkler  @xcite  refers to these methods as sample - unique - population - unique ( supu ) methods as disclosure risk estimation requires assessing the uniqueness of records in the released sample and in the population .",
    "skinner and eliot  @xcite  introduced a new disclosure risk measure for microdata which falls under supu methods  @xcite .",
    "their measure is based on the probability @xmath2 that a microdata record and a population unit are correctly matched .",
    "additionally , they introduced a simple variance estimator and claimed that their measure is able to evaluate the different ways of releasing microdata from a sample survey .",
    "truta et el .",
    "@xcite  introduced other supu measures and termed them minimal , maximal , and weighted disclosure risk measures .",
    "the minimal disclosure risk measure is the percentage of records in a population that can be correctly re - identified by an intruder .",
    "all these records must be population unique .",
    "the maximum disclosure risk measure takes into account records that are not population unique while the weighted disclosure risk measure assigns more weights to unique records over other records .",
    "their measures are not linked to a certain individual but compute the overall disclosure risk for the database .",
    "these measures can only be applied to limited sdc methods such as sampling and microaggregation and it is considered hard to choose the disclosure risk weight matrix  @xcite . however , assigning weights enables a data owner to setup different levels of confidentiality .",
    "these measures are useful in deciding the order of applying more than one sdc method on the initial data .",
    "trottini and fienberg  @xcite  proposed a simple bayesian model for capturing user uncertainty after releasing the data by an agency .",
    "they distinguish between the legitimate user ( researcher ) uncertainty and the malicious user ( intruder ) uncertainty .",
    "this distinction is used as the basis of defining appropriate disclosure risk measure .",
    "the proposed measure is an arbitrary decreasing function of the user s uncertainty about a confidential attribute value .",
    "spruill  @xcite measured confidentiality as a percentage of records in the released data where a link with the original data can not be made . in order to decide",
    "if there is such a link , for each released record , we add up either the square or the absolute value of the difference between the released value and the true value for all common numerical attributes .",
    "a link is said to be made if a released record was derived from the true record that has the minimum sum of differences .",
    "spruill s early work gave rise to _",
    "record linkage _ , much studied in recent years  @xcite .",
    "there are some recent proposals that use information - theoretic approach to measure privacy and utility of various sdc techniques @xcite ; however , none of them measures the  approximate \" compromise , as we explain in the next section .",
    "out of all disclosure risk measures , the closest to our proposal is a measure proposed by onganian and domingo - ferrer  @xcite that evaluates the security of releasing tabular data .",
    "the measure is equal to the reciprocal of conditional entropy given the knowledge of an intruder : @xmath3 where _ x _ represents a confidential attribute for a given record and _ y _ represents intruder s knowledge .",
    "the disclosure risk is inversely proportional to the uncertainty about the confidential attribute given intruder s knowledge .",
    "the measure performs _ a posteriori _ , that is , after applying one of sdc methods to the tables .",
    "it is a complement to _ a priori _ measures such as some currently used sensitivity rules including ( _ n , k_)-dominance and _ pq_-rule , which help a data owner in deciding whether to release the data or not . the main strength of the above a posteriori measure is its generality : it is applicable to various sdc methods such as cell suppression , rounding , and table redesign . in order to evaluate this disclosure risk , one has to find a set of the possible confidential attribute values and their probabilities given the condition @xmath4 . a down side of this measure is that it does not capture accurately the knowledge that an intruder has about a confidential attribute , as it does not give careful consideration to the attribute values but only the probabilities with which the values occur .",
    "our proposed method considers the attribute values in addition to their probabilities .    before we proceed to describe our measure in more detail and compare some of the sdc techniques in the experimental section , we need to introduce the concept of `` database compromise '' .",
    "we say that a database is _ compromised _ if a _ sensitive statistic _ is disclosed  @xcite .",
    "there are several distinct types of compromise , depending upon what is considered to be sensitive .",
    "for example , if only exact individual values are considered sensitive , we have the so - called _ exact compromise_. _ approximate compromise _ occurs when a user is able to infer that a confidential individual value @xmath5 lies within a range  @xmath6 $ ]  for some predefined value of @xmath7 .",
    "approximate compromise will prove crucial for the definition of our new security measure .",
    "we consider a scenario where an intruder is trying to unlawfully disclose confidential information from a database .",
    "she uses all the available information she can get from the database , as well as any external knowledge she may have . at the end of her analysis , the intruder is able to reduce the possibilities and limit her suspicion to certain data values .",
    "shannon s entropy can measure the intruder s uncertainty , but does not take into consideration how far or close these values are from each other .    the first example in table  [ table : queryexample ]   shows the queries submitted by the intruder and the database response to them . assuming that there are only two female academics , layla and angela",
    ", the intruder learns that layla s salary is one of the two values : it is either @xmath8 or @xmath9 .    in the second example",
    "we assume that there are only two academics aged @xmath10 , qays and tony .",
    "then the intruder knows that qays s salary is either @xmath11 or @xmath12 .",
    "if we use shannon s entropy to evaluate the intruder s uncertainty in examples @xmath13 and @xmath14 , we get the same result , 1 bit in each case . however , we argue that the intruder learns more in example @xmath14 , as he can pretty accurately estimate the salary to be @xmath15 .",
    "this highlights the need for more accurate measure than shannon s entropy , which would be able to capture such differences .",
    "recall that a compromise can be exact or approximate .",
    "shannon s entropy can be considered a satisfactory measure for the disclosure risk that is related to the exact compromise . however , in the approximate compromise , we argue that shannon s entropy does not express precisely the intruder s knowledge about a particular confidential value .    we introduce a notion of privacy for the so - called _ approximate compromise range _ ( @xmath7 ) . in the approximate compromise an intruder learns that the confidential value @xmath5 lies within a range @xmath6 $ ] . for the two example we have @xmath16 $ ] for layla and @xmath17 $ ] for qay , where in both cases @xmath18 .",
    "obviously , the intruder knows more about qay s than layla s salary , as in the former the approximate compromise range is @xmath19 , while in the latter it is @xmath20 .    to capture the information about the range @xmath7",
    ", we use shannon s entropy @xmath21 as a function of @xmath7 . the graphs in figure  [ fig : ourmeasure77 - 80 ]  correspond to the intruder s uncertainty @xmath22 in the above examples .",
    "we notice that the entropy @xmath23 is the same in both cases , that is , the disclosure risks are the same for exact compromise",
    ". however , the area under @xmath22 is much larger for layla implying that this case is more resistant against approximate compromise .        in general",
    ", we can then evaluate intruder s uncertainty for any given @xmath7 .",
    "in particular , we use @xmath24 to denote intruder s uncertainty in the case of exact compromise , that is , approximate compromise range of `` @xmath25 '' and we call it _",
    "initial entropy_. additionally , in what follows we examine the area ( @xmath26 ) determined as an integral : @xmath27 , where `` @xmath28 '' is the value of @xmath7 for which entropy @xmath22 drops to zero .",
    "formally , @xmath29 and @xmath30 for all @xmath31    we next explain how @xmath22 is calculated in general .",
    "we introduce a `` window '' of length @xmath7 .",
    "when a window `` covers '' two or more values , then they are replaced with a single value whose probability is equal to the sum of probabilities of all the values covered by the window . in general , there will be more than one way to cover the values with windows of length @xmath7 and we need to select the way that minimises the entropy @xmath22 .",
    "we next formally define the problem of calculating @xmath22 . * calculating @xmath22 * + * input * : + * sorted values @xmath32 , @xmath33 for any @xmath34 + * their corresponding probabilities : @xmath35 + * parameter @xmath36 + * output * : + * collection @xmath37 of subsets @xmath38 , such that ( 1 ) @xmath39 , ( 2 ) @xmath40 , @xmath41 , ( 3 ) @xmath42 + * corresponding probabilities @xmath43 + * @xmath22 calculated over probabilities @xmath44 , such that @xmath22 is maximised over all collections @xmath37 satisfying conditions above .    computing",
    "the minimum entropy @xmath22 as a function of @xmath7 is not straightforward and in appendix we provide an example to illustrate the entropy calculation . in the next section",
    "we introduce a dynamic programming algorithm to find the optimal entropy and hence calculate the area ( @xmath26 ) that together with the initial entropy ( @xmath45 ) represents our disclosure risk .",
    "we are given as input a set of values @xmath46 in increasing order ( @xmath47 ) where each @xmath46 has a given probability @xmath48 where @xmath49 and and @xmath50 . in order to produce our security measure",
    ", we need to calculate minimum @xmath22 for each @xmath7 .",
    "we break the problem into stages ( rows ) and states ( columns ) .",
    "each row in the table corresponds to a stage or @xmath7 .",
    "column `` @xmath51 '' in the table corresponds to the subproblem containing values @xmath52 . for a given row ( stage ) in the table , each cell in this row is viewed as a subproblem  @xmath53  of the original problem  @xmath22 . for a given stage and state ,  @xmath53",
    "is computed by the following recurrence : @xmath54\\ ] ]    where @xmath55    @xmath56 , @xmath57 for @xmath58 $ ] and @xmath59    @xmath60 @xmath61    @xmath62",
    "in this section we apply our proposed security measure to a few common statistical disclosure control ( sdc ) techniques . in all instances",
    "we assume that the intruder has _ supplementary knowledge _ ( sk ) about an individual whose corresponding record is stored in the original dataset , which can be as limited as one attribute or can be as extensive as all attributes except the confidential one .",
    "the comparative study is performed on three different data sets . here",
    "we present results on pums dataset , whose decription can be found in the appendix .",
    "* sampling . * in this experiment , we release a subset of records ( sample ) from the original microdata file ( population ) .",
    "we use a simple random sample without replacement where each record in the original is equally likely to be included in the produced sample and duplicates are not allowed .",
    "the produced sample has a constant size specified as a percentage of the original dataset total size and referred to as  sampling size \" ( or `` sampling factor '' ) . in deciding on the structure of the sampling experiment",
    ", we follow work by truta et el .  @xcite  on disclosure risk measures for sampling , where we compute the overall disclosure risk for the database , rather than for a certain individual .    in order to study the effect of sample size on the security we use four different sampling factors : @xmath63 . for each sample size",
    ", we generate @xmath64 different sample files .",
    "additionally , we study the effect of the intruder s supplementary knowledge .",
    "we start with supplementary knowledge as little as one attribute and extended it to reach all attributes except the confidential one .",
    "for each attribute we performed experiments for all possible values .",
    "the results in figure  [ sampling_usa_general_h0_area_vs_attrnumber ] are the averaged over all 30 samples , all attributes and all values .    * query restriction . * in this experiment , we consider a scenario where an intruder submits a set of range queries to a dbms .",
    "the intruder performs an analysis using the answers to the submitted queries as well as the supplementary knowledge with an aim to infer a confidential attribute value for the given record , e.g salary in pums dataset .",
    "we assume that the intruder has build a system of linear equations out of the responses to range queries .",
    "we use @xmath65 to denote the query set size for the queries a user ( i.e. , an intruder ) is permitted to ask . for simplicity , we only consider even query set sizes .",
    "we use @xmath0 to denote the number of queries and thus also the number of linear equations : @xmath66 .",
    "we run the experiment for @xmath67 different query set size @xmath68 . for each query set size",
    ", we shuffle the records in the original dataset to get different systems of linear equations . for each query set size ,",
    "we produce randomly @xmath64 different systems of linear equations . just like in the case of sampling",
    ", for each attribute we performed experiments for all possible values .",
    "the results in figure  [ sampling_usa_general_h0_area_vs_attrnumber ] are the average results , over all @xmath64 systems of linear equations , all sk attributes and all values .",
    "* noise addition .",
    "* we consider a scenario where a dbms alters an original dataset by adding certain level of noise .",
    "the noise is added to all attributes in the dataset , sensitive and non - sensitive , categorical and numerical .",
    "we use additive noise studied in  @xcite .",
    "the amount of noise is drawn randomly from binomial probability distribution as the nature of attributes in our dataset is discrete .",
    "the dbms then releases the perturbed version of the dataset and an intruder obtains a copy of it .",
    "the intruder performs an analysis using the released perturbed dataset together with the supplementary knowledge with an aim to infer a confidential attribute value , e.g salary in pums dataset , corresponding to the individual of concern .",
    "we assume there is only one confidential attribute ; it is straightforward to generalize our experiments to cover more than one confidential attribute .",
    "as expected , for all three sdc techniques our privacy measure , cae , increases with decrease in utility ( figure 2 ) . in sampling , utility is proportional to the sample size , in query restriction utility is inversely proportional to the query size , and in noise addition utility is inversely proportional to the amount of noise .    the experiments also show that privacy declines with additional supplementary knowledge that intruder might have , which is expressed on horizontal axis as the number of known attributes .",
    "we note that this decline is sometimes gentle and sometimes sharp , depending on the utility which is in figure 2 given as a parameter : for low utility privacy only gently declines with supplementary knowledge , while for higher utility the decline is typically sharp .    importantly ,",
    "our experiments demonstrate how we can compare different sdc techniques and select the most suitable one for specific application and requirements .",
    "for example , in the absence of supplementary knowledge sampling with size 50% and query restriction with query set size 8 provide similar level of privacy ( blue line in figure ( a ) and red line in figure ( c ) ) ; however , the privacy sharply drops with supplementary knowledge increases in sampling , while it remains flat in query restriction .",
    "moreover , figures ( b ) and ( d ) that indicate approximate compromise show a slight superiority of sampling in the absence of supplementary knowledge , but as supplementary knowledge grows sampling becomes much more vulnerable than query restriction .    in summary , unlike previously proposed privacy measures , our novel information theoretic privacy measure ( cae )",
    "has the ability to capture approximate compromise ; it can also be applied to any sdc technique , as long as the probabilities of different confidential values can be estimated . in this paper",
    "we considered the most common sdc techniques and showed how cae can be used to evaluate the privacy they offer , and how this privacy relates to both utility and supplementary knowledge .",
    "10    _ public use microdata sample ( pums ) _ , 2006 .",
    "adam , n.r .",
    ", john  c. worthmann , j.c . : security - control methods for statistical databases : a comparative study , _ acm comput . surv . _ * 21*(4 ) , 515556 , 1989 .",
    "blake , c.l . : _ wine recognition data _ , 1998 .",
    "brankovic , l. and estivill - castro , v. : privacy issues in knowledge discovery and data mining . _ in proceedings of the australian institute of computer ethics conference ( aice1999 ) _ , 8999 , 1999 .",
    "brankovic , l. , giggins , h. : _ security , privacy , and trust in modern data management _ , data - centric systems and applications , ch .  statistical database security , pp .",
    "167181 , springer berlin heidelberg , 2007 .",
    "brankovic , l. , horak , p. , miller , m. : an optimization problem in statistical databases , _ siam journal on discrete mathematics _ * 13*(3 ) , 46353 , 2000 .",
    "brankovic , l. , horak , p. , miller , m. , wrightson , g. : usability of compromise - free statistical databases for range sum queries .",
    "_ in proceedings of the 9th international conference on scientific and statistical database management _ , ieee computer society , august 11 - 13 , olympia , washington , 144154 , 1997 .",
    "brankovic , l. , lopez , n. , miller , m. , sebe , f. : triangle randomization for social network data anonymization .",
    "_ ars mathematica contemporanea _ , * 7*(2 ) , 461477 , 2014 .",
    "brankovic , l. , miller , m. , siran , j. : range query usability of statistical databases .",
    "_ international journal of computer mathematics _ , * 79*(12 ) , 12651271 , 2002 .",
    "brankovic , l. : _ usability of secure statistical databases_. phd thesis , newcastle , australia , 1998 .",
    "brankovic , l. , siran , j. : 2-compromise usability in 1-dimensional statistical databases . _ in proceedings of cocoon2002 _ , h. ibarra and l. zhang ( eds . ) , lncs * 2387 * , 448455 , 2002 .",
    "brankovic , l. , miller , m. , siran , j. : usability of k - compromise - free statistical databases .",
    "_ proceedings of the 11th australasian workshop on combinatorial algorithms ( awoca2000 ) _ , hunter valley , 159166 , 2000 .",
    "brankovic , l. , islam , md.z . , giggins , h.:_security , privacy , and trust in modern data management _ , data - centric systems and applications , ch .",
    "privacy - preserving data mining , 151165 , springer berlin heidelberg , 2007 .",
    "denning , d.e . : _ cryptography and data security_. addison - wesley longman publishing co. , inc . ,",
    "boston , ma , usa , 1982 .",
    "duncan , g.t . , lambert , d. : disclosure - limited data dissemination .",
    "_ journal of the american statistical association _ , 81 , 1028 , 1986 .",
    "dwork , c. : differential privacy .",
    "_ in proceedings of the 33rd international colloquium on automata , languages and programming ( icalp ) _ , 10 - 14 july , venice , 112 , 2006 .",
    "estivill - castro , v. , brankovic , l. : data swapping : balancing privacy against precision in mining for logic rules .",
    "_ in proceedings of data warehousing and knowledge discovery ( dawak99 ) _ , lncs * 1676 * , 389399 , 1999 .",
    "estivill - castro , v. , brankovic , l. and dowe , d.l . :",
    "privacy in data mining . _",
    "privacy - law and policy reporter _",
    ", * 9*(3 ) , 3335 , 1999 .",
    "fuller , w.a . : masking procedures for microdata disclosure limitation . _",
    "journal of official statistics _ , * 9*(2 ) , 383406 , 1993 .",
    "fung , c.c.m . ,",
    "wang , k. , chen , r. , yu , p.s . : privacy - preserving data publishing : a survey of recent developments .",
    "_ acm computing surveys _ , * 42*(4 ) ,",
    "article 14 , 14.214.53 , 2010 .",
    "horak , p. , brankovic , l. , miller , m. : a combinatorial problem in database security",
    ". _ discrete applied mathematics _ * 91*(1 - 3 ) , 119126 , 1999 .",
    "islam , md.z .",
    ", barnaghi , p.m. , brankovic , l. : measuring data quality : predictive accuracy vs. similarity of decision trees .",
    "_ in proceedings of the 6th international conference on computer and information technology ( iccit2003 ) _ , december , dhaka , bangladesh , 457462 , 2003 .",
    "islam , md.z . ,",
    "brankovic , l. : noise addition for protecting privacy in data mining . _ in proceedings of the 6th engineering mathematics and applications conference ( emac2003 ) _ , sydney , 8590 , 2003 .",
    "islam , md.z . ,",
    "brankovic , l. : detective : a decision tree based categorical value clustering and perturbation technique in privacy preserving data mining . _ in proceedings of the 3rd international ieee conference on industrial informatics ( indin2005 ) _ , perth , australia , 701 - 708 , 2005 .",
    "kim , j.j . : a method for limiting disclosure in microdata based on random noise and transformation .",
    "_ proceedings of the section on survey research methods _ , american statistical association , 303308 , 1986 .",
    "kim , j.j .",
    ", winkler , w.e . : masking microdata files .",
    "_ proceedings of the section on survey research methods _ , american statistical association , 114119 , 1995 .",
    "lambert , d. : measures of disclosure risk and harm .",
    "_ journal of official statistics _ , * 9*,313331 , 1993 .",
    "king , t. , brankovic , l. , gillard , p. : perspectives of australian adults about protecting the privacy of their health information in statistical databases , _ international journal of medical informatics _ , * 81*(4 ) , 2012 , pp .",
    "27989 .",
    "li , n. , li , t. , venkatasubramanian , s. : _ t_-closeness : privacy beyond _ k_-anonymity and _ l_-diversity . in _ proceedings of ieee international conference on data engineering _ , 2007 .",
    "machanavajjhala , a. , kifer , d. , gehrke , j. , venkitasubramaniam , m. : l - diversity : privacy beyond k - anonymity .",
    "_ acm trans .",
    "data _ * 1 * , 2007 .",
    "oganian , a. , domingo - ferrer , j. : a _ posteriori _ disclosure risk measure for tabular data based on conditional entropy .",
    "_ sort - statistics and operations research transactions _ , * 27*(2 ) , 175190 , 2003 .",
    "samarati , p. , sweeney , l. : protecting privacy when disclosing information : _",
    "k_-anonymity and its enforcement through generalization and suppression .",
    "_ technical report sri - csl-98 - 04 _ , sri computer science laboratory , palo alto , ca .",
    ", 1998 .",
    "sankar , l. , rajagopalan , s.r . ,",
    "poor , h.v .",
    ": utility - privacy tradeoffs for databases : an information - theoretic approach .",
    "_ ieee transactions on information forensics and security , special issue on privacy and trust management in the cloud and distributed data systems _ , * 9*(6 ) , 838852 , 2013 .",
    "skinner , c.j . , elliot , m.j . : a measure of disclosure risk for microdata . _",
    "journal of the royal statistical society _",
    "* 64*(4 ) , 855867 , 2002 .",
    "spruill , n.l .",
    ": measures of confidentiality .",
    "_ statistics of income and related administrative record research _ , 131136 , 1982 .",
    "sramka , m. , safavi - naini , r. , denzinger , j. , askari , m. : a practice - oriented framework for measuring privacy and utility in data sanitization systems . _ in proceedings of edbt / icdt2010 workshops _ ,",
    "march 22 - 26 , lausanne , switzerland , 315333 , 2010 .",
    "tendick , p. : optimal noise addition for preserving confidentiality in multivariate data . _ journal of statisical planning and inference _ * 27 * , 341353 , 1991 .    trottini , m. , fienberg , s.e . : modelling user uncertainty for disclosure risk and data utility . _ international journal of uncertainty , fuzziness and knowledge - based systems _ * 10*(5 ) , 511527 , 2002 .",
    "truta , t.m . ,",
    "fotouhi , f. , barth - jones , d. : disclosure risk measures for the sampling disclosure control method .",
    "_ sac 04 : proceedings of the 2004 acm symposium on applied computing _ , march ,",
    "ny , usa , 301306 , 2004 .",
    "willenborg , l. , de  waal , t. : elements of statistical disclosure control . _ lecture notes in statistics _ , 155 , springer - verlag , new york , 2001 .",
    "winkler , w.e .",
    ": _ privacy in statistical databases _ ,",
    "masking and re - identification methods for public - use microdata : overview and research problems , pp .  231246 , springer berlin heidelberg , 2004 .",
    "wolberg , w.h . , street , w.n . ,",
    "mangasarian , o.l . : _ wisconsin diagnostic breast cancer _ , 1995 .",
    "yancey , w.e . ,",
    "winkler , w.e .",
    ", creecy , r.h . : disclosure risk assessment in perurbative microdata protection . _ lecture notes in computer science : inference control in statistical databases _ , springer , 2002 .",
    "we demonstrate on a small example how @xmath22 is calculated .",
    "consider as input a set of values @xmath46 of a confidential attribute @xmath5 , where for each @xmath46 we have a given probability @xmath48 , where @xmath49 and @xmath50 . in order to produce our security measure and compute the area , we need to calculate @xmath22 for each @xmath7 . in our example",
    ", an intruder learns that a confidential variable @xmath69 $ ]  has four possible values with probabilities as follow :        we use the following notation : ( 1 ) @xmath70  is a number of records in the original database ; ( 2 ) @xmath37  is the confidential attribute ; ( 3 ) @xmath71 , @xmath72 , is the value of the confidential attribute @xmath37 in record @xmath51 ; ( 4 ) @xmath73  is the domain of the confidential attribute @xmath37 in the original database ; ( 5 ) @xmath74  is the @xmath75 value of the confidential attribute in the domain @xmath73 , where @xmath76 ; ( 6 ) @xmath48  is the probability that the confidential attribute value is @xmath74 ; ( 7 ) @xmath77  is the set of records in the original dataset that matches the intruder supplementary knowledge .    * sampling . * we consider a scenario where an intruder obtains a copy of the released sample file and performs an analysis using the released sample together with the supplementary knowledge with an aim to infer a confidential attribute value corresponding to the individual in question , e.g. , salary in pums dataset .    we introduce the following notation specific to sampling : ( 1 )",
    "@xmath78  is the set of records in the released sample dataset that matches the intruder s supplementary knowledge ( 2 ) @xmath79  is the frequency of @xmath74 in @xmath78 , that is , how many times @xmath74 appears in records that belong to @xmath78 .    to compute the initial and average entropy",
    ", we need a set of @xmath74 s and their corresponding @xmath48 s .",
    "we first identify @xmath80 and @xmath81 and then calculate @xmath79 for each @xmath82 .",
    "then for each @xmath82 we compute a corresponding @xmath48 , that is , the probability that the record in question is in the sample and @xmath74 is its confidential value @xmath83 that the record does not appear in the sample and @xmath74 is its confidential value .",
    "note that for those records that do not appear in the sample the equal probability of all @xmath84 values is assumed .",
    "we also assume that @xmath81 is a part of the intruder s supplementary knowledge .",
    "@xmath85    * query restriction . *",
    "the intruder obtains a system of @xmath0 linearly independent equations in @xmath70 unknowns . to be able to solve the system and completely compromise the database , the intruder needs @xmath70 linearly independent equations .",
    "nevertheless , with @xmath86 linearly independent equations , the intruder is able to find the upper and lower bounds ( min , max ) for the confidential attribute value in each record .",
    "we follow the evaluation of an entropy based measure of disclosure risk presented in  @xcite and solve two linear programming problems , maximisation and minimisation , to find @xmath87 and @xmath88 , the upper and the lower bound for @xmath89 , the value of the confidential attribute @xmath37 in record @xmath51 that matches the intruder s sk .",
    "the constraints for the linear programming problems consist of the given system of @xmath0 linearly independent equations in @xmath70 unknowns , plus a system of inequalities of the form @xmath90 and @xmath91 , where @xmath92 and @xmath93 are the minimum and the maximum value in the domain @xmath73 .",
    "the linear function to be maximised ( minimised ) is the confidential value in the record @xmath51 .",
    "we use @xmath87 and @xmath88 for each record that matches the intruder s sk to find the probability @xmath48 for each value @xmath82 in the domain @xmath73 . see algorithm  [ algorithm : qr ] bellow .",
    "* noise addition .",
    "* algorithm 3 shows the steps that are followed in order to analyse noise and obtain a set of @xmath74 and their corresponding @xmath48 .",
    "figure 4 shows the average of initial and average entropy over @xmath64 perturbed files , each size of the intruder s sk , and for each amount of noise . by @xmath94 noise , we mean that the maximum noise @xmath95 is @xmath94 of @xmath96 , rounded to the nearest @xmath14 ."
  ],
  "abstract_text": [
    "<S> it is well recognised that data mining and statistical analysis pose a serious treat to privacy . </S>",
    "<S> this is true for financial , medical , criminal and marketing research . </S>",
    "<S> numerous techniques have been proposed to protect privacy , including restriction and data modification . </S>",
    "<S> recently proposed privacy models such as differential privacy and k - anonymity received a lot of attention and for the latter there are now several improvements of the original scheme , each removing some security shortcomings of the previous one . </S>",
    "<S> however , the challenge lies in evaluating and comparing privacy provided by various techniques . in this paper </S>",
    "<S> we propose a novel entropy based security measure that can be applied to any generalisation , restriction or data modification technique . </S>",
    "<S> we use our measure to empirically evaluate and compare a few popular methods , namely query restriction , sampling and noise addition . </S>"
  ]
}