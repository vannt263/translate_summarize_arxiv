{
  "article_text": [
    "start by providing a brief overview of practical distributed storage systems and some of their properties .",
    "these examples motivate the mathematical model of distributed storage subsequently introduced and analyzed .",
    "a distributed storage system generically consists of interconnected storage nodes , where each node can store a large quantity of data .",
    "a primary goal of a distributed storage system is to reliably store as much source data  as possible for a long time .",
    "commonly , distributed storage systems are built using relatively inexpensive and generally not completely reliable hardware .",
    "for example , nodes can go offline for periods of time ( transient failure ) , in which case the data they store is temporarily unavailable , or permanently fail , in which case the data they store is permanently erased .",
    "permanent node failures are not uncommon , and transient node failures are frequent",
    ".    although it is often hard to accurately model node failures , a random node failure model can provide insight into the strengths and weaknesses of a practical system , and can provide a first order approximation to how a practical system operates",
    ".    distributed storage systems generally allocate a fraction of their raw capacityto storage overhead : they use erasure codes to generate redundant data from the source data , and take advantage of the storage overhead  to store the redundant data in addition to source data  to ensure the source data  is recoverable even when nodes ( or other components ) fail .",
    "source data  is maintained at the granularity of _",
    "objects_. for a @xmath4 erasure code , each object is segmented into @xmath5 source fragments , an encoder generates @xmath6 repair fragments from the @xmath5 source fragments , and each of these @xmath7 fragments is stored at a different node .",
    "an erasure code is mds if the object can be recovered from any @xmath5 of the @xmath8 fragments .",
    "replication is an example of a trivial mds erasure code , i.e. , each fragment is a copy of the original object . for example , triplication can be thought of as using the simple @xmath9 erasure code , wherein the object can be recovered from any one of the three copies .",
    "many distributed storage systems use replication .",
    "reed - solomon codes @xcite , @xcite , @xcite are mds codes that are used in a variety of applications and are a popular choice for storage systems .",
    "for example , @xcite and  @xcite use a @xmath10 reed - solomon code , and  @xcite uses a @xmath11 reed - solomon code . these are examples of _ small code systems _ ,",
    "i.e. , systems that use small values of @xmath8 , @xmath5 and @xmath12 .",
    "a _ repairer _ maintains recoverability of source data  as node failures occur , by reading , regenerating and writing fragments lost due to node failures .",
    "since a small number @xmath13 of node failures can cause object data loss for small code systems , _ reactive repair _ is used , i.e. , the repairer operates as quickly as practical to regenerate fragments lost from a node that permanently fails before another node fails , and typically reads @xmath5 fragments to regenerate each lost fragment .",
    "thus , the peak read repair rate  is higher than the average read repair rate , and the average read repair rate  is @xmath5 times the node failure erasure rate .",
    "the _ read repair rate _ needed to maintain source data  recoverability for small code systems can be substantial",
    ". modifications of standard erasure codes have been designed for storage systems to reduce this rate , e.g. , _ local reconstruction codes _",
    "@xcite , @xcite , and _ regenerating codes _",
    "@xcite , @xcite .",
    "some versions of local reconstruction codes have been used in deployments , e.g. , by microsoft azure .    _",
    "placement groups _ ,",
    "each mapping @xmath8 fragments to @xmath8 of the @xmath1 nodes , determine where fragments for objects are stored .",
    "an equal amount of object data should be assigned to each placement group , and an equal number of placement groups should map a fragment to each node . for small code systems ,",
    "ceph  @xcite recommends @xmath14 placement groups , i.e. , 100 placement groups map a fragment to each node .",
    "a placement group  should avoid mapping fragments to nodes with correlated failures , e.g. , to the same rack .",
    "pairs of placement groups should avoid mapping fragments to the same pair of nodes .",
    "placement groups are continually remapped as nodes fail and are added . these and other issues make it challenging to design placement groups for small code systems .",
    "the paper  @xcite introduces _",
    "liquid systems_. liquid systems use erasure codes with large values of @xmath8 , @xmath5 and @xmath12 .",
    "for example , @xmath15 and a fragment is assigned to each node for each object , i.e. , only one placement group  is used for all objects .",
    "the raptorq code @xcite ,  @xcite is an example of an erasure code that is suitable for a liquid system , since objects with large numbers of fragments can be encoded and decoded efficiently in linear time .    for a liquid system , @xmath12 is typically large , and thus object data is not reliably recoverable only when a large number of nodes fail .",
    "the repairer is lazy , i.e. , repair operates in the background to slowly over time regenerate fragments erased from nodes that have permanently failed . generally the repairer reads @xmath5 fragments for each object to regenerate around @xmath12 fragments erased over time due to permanent node failures , and the peak read repair rate  is close to the average read repair rate .",
    "there are any number of possible strategies , such as the strategies outlined above , and others which have not yet been invented , that could be used to implement a distributed storage system .",
    "our primary goal is to capture the properties and metrics essential to all strategies , and provide fundamental insights into what is possible , and impossible , to achieve .",
    "our distributed storage model and results are inspired by shannon s communication model  @xcite and results .",
    "figure  [ shannon_model fig ] shows an architectural overview of shannon s model .",
    "a transmitter produces a signal generated from a source data  @xmath16 received from a source , and sends the signal over a channel .",
    "noise perturbs the signal within the channel .",
    "a receiver receives signal @xmath17 , generates @xmath18 from @xmath17 , and provides @xmath18 to a destination , where the source data  is reliably recovered if @xmath19 .",
    "the theory proves every channel has an _ information capacity _ , which is the maximum rate at which source data  can be transmitted over the channel and still be reliably recovered at the receiver .",
    "the _ binary erasure channel _ ( bec ) is the closest analog to our work , which can be characterized as follows .",
    "the _ signal rate _",
    "@xmath20 is the raw rate at which data can be transmitted over the channel , independent of reliability .",
    "the _ erasure rate _",
    "@xmath21 is the rate at which data transmitted over the channel is erased .",
    "the _ signal rate to erasure rate ratio _ ( ser ) @xmath2 is defined as @xmath22    the bec information capacity  is @xmath23 this information capacity  is asymptotically achievable as the source data  size grows .",
    "we introduce a model of distributed storage which is inspired by properties inherent and common to systems described in section  [ practical sec ] .",
    "figure  [ storage_model fig ] shows an architectural overview of the distributed storage model .",
    "a storer generates data from source data  @xmath16 received from a source , and stores the generated data at nodes .",
    "the _ source data  size _",
    "@xmath24 is the number of bits in @xmath16 .",
    "alternatively , @xmath25 , where @xmath26 is the entropy of @xmath27 .",
    "figure  [ storage_nodes fig ] shows the nodes of the distributed storage system , together with the network that connects each node to a repairer .",
    "each of @xmath1 nodes can store @xmath3 bits of data , and the _ raw capacity _ is @xmath28 the _ storage overhead _",
    "@xmath29 is the fraction of raw capacity  available beyond the source data  size , i.e. , @xmath30 and thus source data  size @xmath31 .",
    "as time passes , nodes fail and data stored at the failed nodes is erased .",
    "a failure process determines when and what nodes fail as time passes .",
    "all bits at a node are immediately erased when the node fails , and a node with all bits initialized to zeroes is immediately added to replace the failed node .",
    "thus , at each point in time there are @xmath1 nodes .",
    "the _ erasure rate _ is @xmath32 where @xmath33 is the average time between node failures , since @xmath3 bits are erased each time a node fails",
    ".    as nodes fail and are replaced , a repairer continually reads data from the nodes , computes a function of the read data , and writes the computed data back to the nodes .",
    "the repairer tries to ensure that the source data  can be recovered at any point in time from the data stored at the nodes .",
    "the _ read repair rate _",
    "@xmath34 is the rate at which the repairer reads data , the _ write repair rate",
    "_ @xmath35 is the rate at which the repairer writes data , and the _ repair rate _ @xmath36 .    the _ read repair rate  to erasure rate  ratio _",
    "( _ rrer _ ) is @xmath37 the _ write repair rate  to erasure rate  ratio _",
    "( _ wrer _ ) is @xmath38 and the _ repair rate  to erasure rate  ratio _",
    "( _ rer _ ) is @xmath39    after some amount of time @xmath40 passes , an accessor reads data @xmath17 from the nodes , generates @xmath18 from @xmath17 , and provides @xmath18 to a destination , where @xmath16 is reliably recovered if @xmath19 .",
    "_ _ ( mean time to data loss ) is the mean amount of time @xmath40 the accessor can reliably recover @xmath16 .",
    "the _ ds information capacity _ is the largest value of @xmath24 for which a large  is possible , for a given rer  @xmath2 and raw capacity  @xmath41 .",
    "we show the ds information capacity  approaches @xmath42 as @xmath2 and the number of nodes @xmath1 grow .",
    "this is a consequence of the main results described in section  [ statements sec ] , and the results in section  [ write sec ]",
    ".      we highlight connections between bec information capacity  ( equation  ) and ds information capacity  ( equation  ) .",
    "the bec signal rate @xmath20 plays two different roles in defining the bec information capacity :    ( 1 ) : :    * signal overcomes noise * : @xmath20 combats the bec    erasure rate  @xmath21 to enable reliable delivery of    source data  ( equation  ) .",
    "( 2 ) : :    * noise - free capacity * : @xmath20 is the bec information    capacity  when there are no erasures ( equation  ) .    for the ds model",
    ", these roles are split between the ds repair rate  and the ds raw capacity .",
    "the ds repair rate  plays role ( 1 ) , i.e. , the ds repair rate  combats the ds erasure rate  to enable reliable storage of source data  ( equation  ) .",
    "the ds raw capacity  plays role ( 2 ) , i.e. , the ds raw capacity  is the ds information capacity  when there are no erasures ( equation  ) .    given these connections , it is notable how similar in form the bec information capacity  equation   is to the ds information capacity  equation  .",
    "the bounds we prove are with respect to _ node failure sequences_. a node failure sequence  is an indexed sequence of pairs @xmath43 where for _ index _ @xmath44 , @xmath45 is the _ time _ at which the node fails and @xmath46 is the _ identifier _ of the node that fails .",
    "thus , @xmath47 is the _ timing sequence _ , and @xmath48 is the _ identifying sequence _ for this node failure sequence .    in some cases",
    "we analyze the repairer with respect to one node failure sequence , and in other cases we analyze the repairer with respect to a _ node failure distribution _ , which is a probability distribution on node failure sequences .",
    "* fixed timing sequence * : : :    for fixed @xmath33 , for all @xmath49 ,    @xmath50 , i.e. , the time    increment between node failures is @xmath33 .    the fixed timing sequence  is used to prove some core results .    * general timing distribution * : : :    fix @xmath33 and let @xmath51 be any    non - negative random variable with    @xmath52 } = \\delta$ ] . for all    @xmath49 , the time increment    @xmath53 between the    @xmath54 node failure and the    @xmath55 node failure is chosen by independently    sampling @xmath51 .",
    "* poisson timing distribution * : : :    a special case of a general timing distribution  where    @xmath51 is the first event waiting time for a poisson    random variable with rate @xmath56 .",
    "a poisson timing distribution  with @xmath57 models each node failing at poisson rate @xmath58 independent of other nodes ( and thus @xmath59 is the average lifetime of a node ) .",
    "note that @xmath33 is the average time between consecutive node failures for all considered node failure timing sequences .",
    "the _ erasure rate _ is @xmath60 , i.e. , @xmath3 bits of raw capacity  is erased each time a node fails .    * uniform identifier distribution * : : :    let @xmath61 be the set of all    possible identifiers and let random variable @xmath62    be uniformly distributed on @xmath63 . for all    @xmath64 ,",
    "the identifier @xmath46    of the @xmath54 node to fail is chosen by    independently sampling @xmath62 . * random node failure distribution * : : :    a node failure distribution  which combines a poisson timing    distribution  and the uniform identifier distribution .    in practice ,",
    "random node failure distributions are often used to model and evaluate distributed storage systems .",
    "the main results below are with respect to random node failure distributions .",
    "a repairer ensures that the source data  is recoverable when data for source data  is stored at the unreliable nodes .",
    "as nodes fail and are replaced , the repairer reads data from nodes , performs computation on the read data , and writes computed data to nodes .",
    "for a randomized repairer , the random bits @xmath65 used by the repairer are chosen independent of @xmath27 . without loss of generality ,",
    "@xmath65 is chosen and fixed before running the repairer .",
    "the repairer has @xmath66 bits of local memory that it can use to temporarily store and perform computations on data .",
    "generally , @xmath67 , e.g. , @xmath68 , @xmath69 , @xmath70 and @xmath71 , and thus @xmath72 .",
    "repairers are computationally unlimited for repair rate  lower bounds .",
    "the node failure sequence  up to index  @xmath44 is provided to the repairer operating at time @xmath73 , where @xmath44 is the largest index  such that @xmath74 , and this determines the repairer actions up till @xmath73 .",
    "we prove that if the read repair rate  is too small then the source data  is not reliably recoverable .",
    "the lower bound is on an average read repair rate  @xmath75 , which is also a lower bound on the peak read repair rate  @xmath76 , since @xmath77 .",
    "repair rate  upper bounds describe efficient repairers that maintain source data  recoverability for long durations . at all times",
    "the read repair rate  is at most a peak rate @xmath76 , which is also an upper bound on the average read repair rate  @xmath75 , since @xmath78 .",
    "theorem  [ main_lower theorem ] provides a lower bound on average read repair rate  @xmath75 for fixed erasure rate  @xmath21 and storage overhead @xmath29 .",
    "the upper bound on ds information capacity  implied by equation   follows from theorem  [ main_lower theorem ] and theorem  [ main_lower_write theorem ] .",
    "theorem  [ main_upper theorem ] provides an essentially matching upper bound on peak read repair rate  @xmath76 for fixed erasure rate  @xmath21 and storage overhead @xmath29 .",
    "the lower bound on ds information capacity  implied by equation   follows from theorem  [ main_upper theorem ] and theorem  [ main_upper_write theorem ] .",
    "the function @xmath79 mentioned in theorem  [ main_lower theorem ] is defined by equation  , and table  [ lbfunction table ] in section  [ lfunction sec ] provides values of @xmath79 as a function of example values of @xmath29 .",
    "[ main_lower theorem ] for every fixed @xmath80 , asymptotically as @xmath1 grows , for source data  size @xmath81 , for any repairer with average read repair rate  @xmath75 with respect to any random node failure distribution   with erasure rate  @xmath21 , if the repairer is able to achieve a  polynomial in @xmath1 then @xmath82    the proof of theorem  [ main_lower theorem ] is provided in section  [ main_lower sec ] .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    for example , from table  [ lbfunction table ] for @xmath83 , inequality   is @xmath84    the advanced liquid repairer  mentioned in theorem  [ main_upper theorem ] is described in section  [ main_upper sec ] , and is based on the paper  @xcite that introduces liquid systems with features such as the repairer peak read rate is equal to the average read rate , and traffic generated by the repairer is uniformly distributed across the network .    [ main_upper theorem ] for every fixed @xmath29 , asymptotically as @xmath1 grows , for source data  size @xmath81 , the advanced liquid repairer  with peak read repair rate  @xmath76 with respect to any random node failure distribution  with erasure rate  @xmath21 can achieve a  exponential in @xmath1 and satisfy @xmath85    the proof of theorem  [ main_upper theorem ] is provided in section  [ main_upper sec ] .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    for example , for @xmath83 , inequality   is @xmath86    the bounds on rrer  @xmath87 in theorem  [ main_lower theorem ] and on rrer  @xmath88 in theorem  [ main_upper theorem ] converge to @xmath89 as @xmath90 .      figures  [ read vs overhead fig ] and  [ read ratio vs overhead fig ] provide visualizations of the main results .",
    "the horizontal axis in figure  [ read vs overhead fig ] is the storage overhead , and the vertical axis is the corresponding bound on the rrer : ",
    "rrer  lower bound \" shows the lower bound on @xmath87 from inequality  , ",
    "rrer  upper bound \" shows the upper bound on @xmath88 from inequality  , and ",
    "@xmath91 curve \" shows the @xmath89 curve for comparison , which is between the lower and upper bounds .    the horizontal axis in figure  [ read ratio vs overhead fig ] is the storage overhead , and the vertical axis is the rrer   lower and upper bounds from figure  [ read vs overhead fig ] normalized by multiplying by @xmath92 , which shows how these bounds converge to the  @xmath91 curve \" as @xmath29 approaches zero",
    "this section introduces the key ideas used to prove theorem  [ main_lower theorem ] .",
    "the core read repair rate  lower bounds use the function @xmath93 where @xmath29 , @xmath94 and @xmath95 satisfy the conditions in subsection  [ epsilon_psi sec ] , and @xmath96 is defined in equation  .",
    "fixing @xmath97 and @xmath98 satisfies the conditions for @xmath80 , and equation   simplifies to @xmath99 table  [ lbfunction table ] in section  [ lfunction sec ] provides example values of @xmath100 .    [ core_lower theorem ] for every fixed @xmath80 , for source data  size @xmath31 , for every repairer there is a node failure sequence  with a fixed timing sequence  and with erasure rate  @xmath21 such that if the repairer has average read repair rate  @xmath75 and is always able to maintain recoverability of the source data  then @xmath101    the proof of theorem  [ core_lower theorem ] follows immediately from lemma  [ core_lower lemma ] in section  [ core lemma sec ] .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    the following sections introduce the concepts and notation needed to prove lemma  [ core_lower lemma ] , and thus theorem  [ core_lower theorem ] .",
    "we introduce the concepts and notation needed to prove lower bounds on read repair rate .",
    "let @xmath43 be a node failure sequence .",
    "let @xmath102 be the @xmath41 node bit - locations , @xmath3 bit - locations for each of the @xmath1 nodes , and let @xmath103 be the @xmath66 repairer local memory bit - locations .",
    "let @xmath104 .",
    "let @xmath105 be the node bit - locations whose bits are erased due to the node failures with indices  @xmath106 .",
    "thus , @xmath107    let @xmath108 be the node bit - locations whose bits are read by the repairer between the node failures with indices  @xmath106 .",
    "generally , the repairer can read at any point in time .",
    "we assume without loss in generality the repairer does not read at the instant in time of a node failure , and thus @xmath109 .",
    "let @xmath110 be the node bit - locations whose bits are read by the repairer between the node failures with indices  @xmath106 , and the read bits are the same as just before the node failure with index  @xmath44 , more formally , @xmath111 , and for @xmath112 , @xmath113 let @xmath114 be the node bit - locations whose bits are erased before they are read by the repairer due to node failures with indices  @xmath106 , i.e. , these bit - locations are assigned to nodes with identifiers in @xmath115 , and these bit - locations have not been read by the repairer between @xmath45 and the time the node to which they are assigned fails . more formally , @xmath116 let @xmath117 be the bit  at bit - location  @xmath118 at the instant just after the node failure with index  @xmath119 , and let @xmath120 let @xmath121 be the bit - locations that have not been erased due to the node failures with indices  @xmath106 , and let @xmath122 be the bit  at bit - location  @xmath118 at the instant just before the node failure with index  @xmath44 , and let @xmath123 let @xmath124 be the random bits used to choose the node failure sequence  for indices  @xmath106 . then , @xmath125 is a deterministic function of @xmath126 , and thus , @xmath127 where the last equality is because @xmath128 source data  @xmath27 is not reliably recoverable after the node failure with index  @xmath119 if @xmath129 .",
    "since @xmath130 and @xmath131 this implies that source data  @xmath27 is not reliably recoverable just after the node failure with index  @xmath119 if @xmath132 from equation  , @xmath27 is not reliably recoverable after the node failure with index  @xmath119 if @xmath133 an equivalent formulation of inequality   is that some source data   is not reliably recoverable after the node failure with index  @xmath119 , independent of repairer computation , if @xmath134 since @xmath135 , we assume @xmath136 in the lower bounds .      let @xmath137 be a node failure sequence  with a fixed timing sequence , and consider the situation starting at the node failure with index  @xmath138 , and let @xmath139 . assume for now :    ( 1 ) : :    identifiers    @xmath140 are all    distinct . ( 2 ) : :    for each @xmath141 , the repairer has not read    any bits from @xmath142 between the node    failures with indices  @xmath143",
    ".    then @xmath144 and @xmath145 .",
    "inequality   implies @xmath146 or the source data  is not reliably recoverable just after the node failure with index  @xmath147 .    under these assumptions ,",
    "the rrer  is @xmath148    assumption ( 1 ) is close to true for theorem  [ main_lower theorem ] .",
    "assumption ( 2 ) is roughly  half - true \" : when a random node fails at time @xmath149 , the average fraction of unread data on that node since time @xmath138 is equal to the fraction of unread data from all nodes that have not failed since time @xmath138 .",
    "the proofs are based on a bound @xmath150 ( see equation  ) with @xmath151 , i.e. , @xmath152 . if for some @xmath153 the read repair rate  is averaging above @xmath154 per node failure at time @xmath149 then the average over this interval is above the desired read repair rate  bound @xmath154 .",
    "if for all @xmath155 the read repair rate  is averaging below @xmath154 per node failure at time @xmath149 then , for any fraction @xmath156 , the repairer has read at most @xmath157 bits up till time  @xmath158 . from the `` half - true '' observation and these linear in @xmath156 relationships ,",
    "at least half the erased bits on average on the @xmath159 nodes that fail are lost , i.e. , the number of bits lost is at least @xmath160 the source data  is not reliably recoverable from inequality  .",
    "the factor of two difference in the denominator of equation   compared to equation   is explained by @xmath161 .",
    "[ core_lower lemma ] for every @xmath29 , for @xmath94 and @xmath95 that satisfy the conditions in subsection  [ epsilon_psi sec ] , for source data  size @xmath31 , for every repairer , there is a node failure sequence@xmath137 and a subsequence of the indices @xmath162 such that , for all @xmath163 :    * @xmath164 * if the source data  is recoverable just before the node failure with index  @xmath165 then either @xmath166 or the source data  is not reliably recoverable just after the node failure with index  @xmath167 .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    based on the repairer , a node failure sequence  is generated in a series of phases .",
    "in general , for all @xmath49 , how many and which bits the repairer reads between the node failures with indices  @xmath44 and @xmath168 is repairer specific and can depend on the node failures with indices  @xmath169 , and as described below this is used to determine how to set the identifiers in a phase . in phase @xmath138 , @xmath170 is set to @xmath138 and @xmath171 is set to any identifier , e.g. , @xmath172 .",
    "phase @xmath173 operates as follows for @xmath163 .",
    "when phase @xmath173 begins , @xmath165 and @xmath174 are set to @xmath175 and @xmath176 , respectively , as determined in phase @xmath177 .",
    "phase @xmath173 determines @xmath178 and identifiers @xmath179 .",
    "let @xmath180 @xmath181 for @xmath182 , what the repairer reads up to time @xmath183 is determined by @xmath184 , where @xmath185 have been fixed in previous phases and are thus implicitly fixed in the remainder of the proof .",
    "let @xmath186 be @xmath147 possible identifiers that are distinct from one another and from @xmath174 .",
    "there are @xmath187 sets of such @xmath147 possible identifiers . for each @xmath188 and for each set of @xmath147 possible identifiers @xmath189 , consider the inequality @xmath190 when @xmath191 is set to @xmath192 .",
    "if there is a @xmath193 and @xmath189 that satisfies inequality   then phase @xmath173 sets @xmath194 , and sets @xmath179 to @xmath192 . with these settings ,",
    "inequality   is satisfied .    if there is no @xmath193 and @xmath189 that satisfies inequality   then for all @xmath193 and for sets of @xmath193 possible identifiers @xmath192 , @xmath195 when @xmath191 is set to @xmath192 .",
    "we prove that if inequality   is satisfied for all @xmath193 and all sets of @xmath147 possible identifiers @xmath186 then there is at least one set of identifiers @xmath186 for which the source data  is not reliably recoverable just after the node failure with index  @xmath196 when @xmath197 is set to @xmath186 .",
    "phase @xmath173 sets @xmath198 and sets @xmath179 to @xmath186 .",
    "to simplify notation , the proof below is for phase @xmath199 , where @xmath200 is an arbitrary identifierfor index  @xmath201 .",
    "let @xmath186 be a set of @xmath147 possible identifiers for the subsequent @xmath147 node failures , where all @xmath202 identifiers are disinct .    for each @xmath203 ,",
    "define @xmath204 for each fixed @xmath205 .",
    "we have the disjoint union @xmath206 for each fixed @xmath205 .    for @xmath207 , @xmath208 for each fixed @xmath209 .",
    "thus , @xmath210 for each fixed @xmath211 , where the sets in the union on the right are disjoint and form subsets of @xmath212 .    for all @xmath213 , define @xmath214 consider fixed @xmath215 and the uniform distribution over distinct subsequent choices @xmath216 .",
    "taking expectation over this distribution , for all @xmath217 @xmath218 } = c_j \\cdot { \\lvert{{{\\delta{\\cal r}}}_j}\\rvert}.\\ ] ] taking expectation over @xmath219 , we obtain @xmath220 } = \\psi \\cdot r \\cdot s - \\sum_{j=1}^{m } c_j \\cdot { \\mathbf{e}\\left[{{\\lvert{{{\\delta{\\cal r}}}_j}\\rvert}}\\right]}.\\ ] ] since @xmath221 this can be rewritten as @xmath222 } & = \\psi \\cdot r \\cdot s \\\\ & - \\sum_{j=1}^{m } ( c_j - c_{j+1 } ) \\cdot   \\sum_{j'=1}^{j } { \\mathbf{e}\\left[{{\\lvert{{{\\delta{\\cal r}}}_{j'}}\\rvert}}\\right]}.\\end{aligned}\\ ] ] from inequality  , @xmath223 } = { \\mathbf{e}\\left[{{\\lvert{{{\\cal r}}(0,j)}\\rvert}}\\right ] }   < j \\cdot { { \\mathbf{b}}}(\\beta,\\epsilon,\\psi ) \\cdot s\\ ] ] for all @xmath224 . hence , @xmath222 } & > \\psi \\cdot r \\cdot s -   \\sum_{j=1}^{m } ( c_j - c_{j+1 } ) \\cdot j \\cdot { { \\mathbf{b}}}(\\beta,\\epsilon,\\psi ) \\cdot s \\\\ & = \\left ( \\psi \\cdot r   - { { \\mathbf{b}}}(\\beta,\\epsilon,\\psi ) \\cdot \\sum_{j=1}^{m } c_j \\right ) \\cdot s.\\end{aligned}\\ ] ] with the definition of @xmath96 provided in equation  , @xmath225 and thus @xmath226 } >   \\psi   \\cdot \\left ( 1 - \\frac{\\epsilon \\cdot \\psi}{2 } \\right ) \\cdot",
    "r \\cdot s.\\ ] ] using values for @xmath94 and @xmath95 that satisfy the constraints described in section  [ epsilon_psi sec ] , equation   simplifies to @xmath227 } > r \\cdot s.\\ ] ] thus , from equations  ,  , and inequality   the source data  is not reliably recoverable in expectation after the node failure with index  @xmath147 when averaging over all sets of @xmath147 possible identifiers .",
    "thus , there is at least one set of @xmath147 identifiers @xmath186 for which the source data  is not be reliably recoverable .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em      in the proof of lemma  [ core_lower lemma ] , there is some choice in the values of @xmath94 and @xmath95 for a given @xmath29 that provide the best read repair rate  lower bound on the tradeoffs , subject to the following constraints .",
    "since @xmath228 must be satisfied , the constraint @xmath229 follows from equation  .",
    "another constraint , from equations   and  , is that @xmath94 and @xmath95 should satisfy @xmath230 for fixed @xmath29 , one would like to set @xmath94 and @xmath95 to maximize @xmath231 defined in equation   subject to these constraints . for @xmath80 , @xmath97 and @xmath98",
    "satisfy these constraints , and equation   is based on this ( these values do not maximize @xmath231 ) .    for @xmath232 ,",
    "define @xmath233 note that for @xmath232 , @xmath234 with @xmath235 , the lefthand side of equation  , excluding the factor of @xmath231 , is at most @xmath236 where @xmath237 and where the second inequality in equation   follows from equation  .",
    "thus , the lefthand side of equation   is at most @xmath238 equation   simplifies to the righthand side of equation   when @xmath96 is defined as @xmath239 note that for all @xmath240 $ ] , @xmath241 since , as @xmath242 , @xmath243      table  [ lbfunction table ] shows example values of @xmath100 ( see equation  ) and @xmath79 ( see equation  ) as a function of @xmath80 .",
    "@xmath100 & @xmath79 & @xmath29 & @xmath100 & @xmath79    ' '' ''     + 0.05 & 0.966 & 0.917 & 0.30 & 0.771 & 0.505    ' '' ''     + 0.10 & 0.931 & 0.834 & 0.35 & 0.723 & 0.420    ' '' ''     + 0.15 & 0.894 & 0.752 & 0.40 & 0.669 & 0.333    ' '' ''     + 0.20 & 0.856 & 0.670 & 0.45 & 0.605 & 0.236    ' '' ''     + 0.25 & 0.815 & 0.588 & 0.50 & 0.500 & @xmath246    ' '' ''     +    [ lbfunction table ]",
    "the proof of theorem  [ main_lower theorem ] follows immediately from lemma  [ main_lower lemma ] .",
    "the function @xmath79 mentioned in lemma  [ main_lower lemma ] is defined by equation  .",
    "[ main_lower lemma ] for every fixed @xmath247 , there are functions @xmath248 and @xmath249 such that , asymptotically as @xmath1 grows , @xmath250 approaches zero , and @xmath251 is exponentially small in @xmath1 , with the following properties .",
    "for source data  size @xmath31 , for any random node failure distribution  interacting with any repairer there is a subsequence @xmath252 of the indices of the node failure sequence  produced by the random node failure distribution , such that , for all @xmath163 :    * @xmath253 , where @xmath254 is a constant .",
    "* if the source data  is recoverable just before the node failure with index  @xmath165 then with probability at least @xmath255 , either @xmath256 or the source data  is not reliably recoverable just after the node failure with index  @xmath167 .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    most of the main proof ideas are similar to the proof of lemma  [ core_lower lemma ] .",
    "we now sketch the remaining details to prove lemma  [ main_lower lemma ] . in this case",
    ", a poisson timing distribution  is used to choose the time increments between node failures , where @xmath257}$ ] is the average increment with respect to random variable @xmath51 .",
    "in addition , uniform identifier distribution  is used to choose the identifiers of which nodes fail .",
    "one difference from lemma  [ core_lower lemma ] is that the number of node failures within a period of time is not deterministic , but instead depends on @xmath51 . using standard concentration of distribution bounds",
    ", it can be seen that over a duration of time @xmath258 , the probability the number of node failures is not within a small relative interval around @xmath259 is exponentially small in @xmath1 .",
    "thus , the average time between failures over a period of duration @xmath258 is approximately @xmath52 } = \\delta$ ] with high probability .",
    "another difference is that not each node failure is a distinct failure , since the uniform identifier distribution  is used to choose identifiers of nodes that fail . in subsection",
    "[ distinct count sec ] we show that the number of distinct failures within phases is tightly related to the overall number of node failures within phases .",
    "another difference is that the lower bound is not with respect to a carefully chosen identifying sequence  that is dependent on the repairer , but instead with respect to the uniform identifier distribution  independent of the repairer . in subsection  [ high_prob unrecoverable sec ]",
    "we improve the result in subsection  [ core lemma sec ] proving that the source data  is not reliably recoverable in expectation , to a much stronger result proving that the source data  is not reliably recoverable with high probability .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em      the uniform identifier distribution  implies that the expected number of node failures from a phase start until the distinct failure  count reaches @xmath173 is @xmath260 where @xmath261 is defined in equation  , and where the inequality follows from equation  .",
    "thus , the expected number of node failures from a phase start until the distinct failure  count reaches @xmath262 is @xmath263    for a fixed value of @xmath29 , asymptotically as @xmath1 grows , it can be shown that the number of node failures from a phase start until there are @xmath264 distinct failures is with high probability close to the expected value shown in equation  .    however , the distinct failure  count @xmath173 can be can be much smaller than @xmath264 for many phases , and thus it is not the case that number of node failures in a phase is with high probability close to the expected value shown in equation  . furthermore , the distinct failure  count of phases depends on the repairer .",
    "instead , for the analysis we group together consecutive phases , where the aggregate number of node failures in the group is proportional to @xmath264 , and relate the the aggregate number of distinct failures summed over the group of phases to the number of distinct failures of a single phase that spans the group of phases .",
    "let @xmath265 be a group of @xmath44 consecutive phases with respective distinct failure  counts @xmath266 .",
    "let @xmath3 be an phase that begins at the beginning of phase @xmath267 and ends at the end of phase @xmath268 , and let @xmath173 be the distinct failure  count of @xmath3 . then , because any node failure that is a distinct failure  for the phase @xmath3 is also a distinct failure  for an phase @xmath269 that contains the node failure , @xmath270    if for example @xmath271 , then the total number of node failures within the phase @xmath3 concentrates to at most @xmath272 .",
    "alternatively , if @xmath3 spans @xmath272 node failures then @xmath273 , and thus @xmath274 from equation  .",
    "one can formalize the above ( many details are omitted from this outline ) and argue that within consecutive sequences of @xmath272 node failures there are approximately @xmath275 distinct failures among the phases spanning the node failures .",
    "one can argue that this occurs with high enough probability that discarding the portions of the timeline where this is not true does not affect the overall read repair rate  lower bound .",
    "define @xmath276 where @xmath96 is defined in equation   and @xmath277 is defined in equation  .",
    "then , combining the above with equation   yields equation  .",
    "we consider a phase as described in the proof of lemma  [ core_lower lemma ] in section  [ core lemma sec ] .",
    "let @xmath278 and let @xmath279 be the identifierof the node that fails at the beginning of the phase , and let @xmath280 be a set of @xmath147 possible identifiers .",
    "suppose inequality   is satisfied for all sets of @xmath147 possible identifiers .",
    "we prove that the source data  is recoverable for at most a fraction @xmath249 of these sets , where @xmath281 is an exponentially small in @xmath1 value .",
    "the proof is based on the observation that in the analysis described in section  [ core_lower sec ] , the value of @xmath282 as a function of @xmath283 defines a sub - martingale process with respect to the random choices of @xmath280 . by setting @xmath284 and @xmath98 , where @xmath285 is a small constant , one can see that @xmath286 } \\ge ( 1+\\alpha ) \\cdot r \\cdot s.\\ ] ] furthermore , for each increase in @xmath44 by one , the change in the value of @xmath282 changes by at most @xmath3 .",
    "thus , azuma s inequality can be used to show that @xmath287 with exponentially small probability @xmath249 , i.e. , the source data  is reliably recoverable with probability at most @xmath249 .    let @xmath288 be the probability that inequality   is not satisfied with respect random choices of @xmath280 , and thus @xmath289 is the probability that inequality   is satisfied . by a small modification of the argument outlined in the previous paragraph , with probability at least @xmath290 , the source data  is not reliably recoverable after the node failure with identifier  @xmath291 .",
    "thus , with probability at least @xmath292 , either inequality   is satisfied or the source data   is not reliably recoverable after the node failure with identifier  @xmath291 .",
    "we provide some intuition for theorem  [ main_upper theorem ] .",
    "we first describe a simplified version of the system in @xcite with a tradeoff between @xmath29 and @xmath76 that is around a factor of two worse than optimal .",
    "the liquid repairer  operates as follows , where @xmath293 and @xmath294 .",
    "source data  @xmath16 of @xmath24 bits is partitioned into @xmath259 equal sized objects @xmath295 an erasure code is applied to each object independently , where each object is partitioned into @xmath296 source fragments from which at least @xmath259 repair fragments can be generated .",
    "an _ encoding fragment i d _ , or efi , is used to uniquely identify each fragment of an object . in this case",
    ", efis @xmath297 can be used to identify the source fragments of a object , and efis @xmath296 or larger can be used to identify the repair fragments generated from source fragments .",
    "examples of erasure codes can be found in  @xcite and  @xcite .",
    "we assume that any @xmath296 fragments of an object , identified by their efis , can be used to decode the object .",
    "this is true for the reed - solomon code  @xcite , and essentially true for the raptorq code  @xcite .    for each @xmath298 ,",
    "let @xmath299 be the efi assigned to node @xmath44 .",
    "using an erasure code , for each @xmath300 , for each @xmath301 , the storer generates and writes fragment @xmath302 for @xmath303 to node @xmath44 .",
    "the storage overhead  is @xmath304 , since each node has raw capacity  to store a fragment for each object , and the storage overhead  for all fragments of an object is @xmath305 . also , the size of each fragment is @xmath306 , since each node has raw capacity  @xmath3 to store up to @xmath259 fragments .",
    "the following invariant is established by the storer and maintained by the repairer :    * just before the next node failure , for each @xmath307 , @xmath303 has at least @xmath308 fragments stored at the nodes .",
    "since each node has at most one fragment for each object , a node failure can decrease the number of available fragments for an object by at most one .",
    "since the invariant ensures that each object has at least @xmath309 fragments available just before the next node failure , each object has at least @xmath296 fragments available just after the next node failure , and is thus recoverable , and thus the source data  is recoverable at each point in time .    the repairer cycles through the objects , repairing after each node failure the object @xmath310 with the least available fragments .",
    "suppose a node fails and is replaced with a node with all @xmath3 bits initialized to zeroes .",
    "the repairer operates as follows to reestablish the invariant after the node failure .",
    "the repairer reads @xmath296 of the fragments available for @xmath310 , uses the erasure encoder to generate the missing up to @xmath259 fragments for @xmath310 , and writes these up to @xmath259 generated fragments to the nodes with their assigned efis .",
    "after this repair , @xmath310 has all @xmath1 fragments available at the nodes .",
    "the objects are logically reordered at this point , i.e. , for @xmath311 , the old @xmath303 becomes the new @xmath312 , and the old @xmath310 becomes the new @xmath313 .",
    "this reestablishes the invariant .",
    "if the repairer reads at a steady rate of @xmath314 then the repairer can read @xmath296 fragments between node failures and reestablish the invariant .    for small @xmath29 ,",
    "equation   for the liquid repairer  is around a factor of two worse than inequality   of theorem  [ main_upper theorem ] for the advanced liquid repairer   described in section  [ main_upper sec ] .",
    "the intuition for this gap in optimality for the liquid repairer  is that although the maximum redundancy per object is @xmath29 , the average redundancy needed per object is only @xmath315 , i.e. , object @xmath316 needs only @xmath317 fragments for the repairer to succeed in maintaining recoverability of all objects .",
    "thus @xmath315 of the allocated @xmath29 storage overhead  is not in use at each point in time , as some nodes store less fragments than other nodes . on the other hand ,",
    "the value of @xmath76 in equation   is inversely proportional to the maximum redundancy per object @xmath29 .",
    "the redundancy per object for the advanced liquid repairer  varies similar to that for the liquid repairer .",
    "the intuition behind the better bound for the advanced liquid repairer  is that fragments are generated and stored using a strategy that allows the unequal object redundancy to be distributed equally among the nodes at each point in time , while maintaining the property that the value of @xmath76 is inversely proportional to the maximum redundancy per object .",
    "the advanced liquid repairer  uses a maximum of around @xmath92 redundancy per object , but the average redundancy per object is @xmath29 , and this redundancy is equally distributed among the nodes at each point in time .",
    "thus , @xmath76 for the advanced liquid repairer  is inversely proportional to @xmath92 in inequality   of theorem  [ main_upper theorem ] when the storage overhead  is @xmath29 .      as the core for proving the main read repair rate  upper bound results , we prove read repair rate  upper bounds for repairers with respect to any node failure sequence  with a fixed timing sequence .",
    "the advanced liquid repairer  introduced below is based on the paper  @xcite .",
    "[ core_upper theorem ] for every fixed @xmath29 , for source data  size @xmath81 , the advanced liquid repairer  with peak read repair rate  @xmath76 with respect to any node failure sequence  with a fixed timing sequence  and with erasure rate  @xmath21 guarantees that the source data  is always recoverable if @xmath318    the advanced liquid repairer  operates as follows . a value @xmath319 is determined so that the following equation holds : @xmath320 note that for large @xmath1 , @xmath321 source data  is initially stored as follows by the storer .",
    "source data  @xmath16 of @xmath24 bits is partitioned into @xmath322 equal sized objects @xmath323    let @xmath324 be the number of source fragments into which each object is partitioned for erasure coding .",
    "an erasure code is applied to each object independently , where each object is partitioned into @xmath325 source fragments from which at least @xmath319 repair fragments can be generated .",
    "an efi is used to uniquely identify each fragment . in this case",
    ", efis @xmath326 can be used to identify the source fragments of an object , and efis @xmath325 or larger can be used to identify the repair fragments generated from source fragments .",
    "we assume that any @xmath325 fragments of an object , identified by their efis , can be used to erasure decode the object .    for each @xmath298 ,",
    "let @xmath299 be the efi initially assigned to node @xmath44 .",
    "there is also an efis queue of @xmath319 unassigned efis , where initially these efis are @xmath327 .",
    "the values of the efis that are either assigned efis or unassigned efis change over time , but at any point in time they are all distinct .    using an erasure code , for each @xmath328 , for each @xmath329 , for each @xmath330 , the storer generates and writes fragment @xmath331 for @xmath332 to node @xmath173 .",
    "for each @xmath328 and for each @xmath333 , the storer generates fragments for the first @xmath334 unassigned efis for @xmath332 and writes these @xmath334 fragments at node @xmath44 .",
    "the following invariants are established by the storer and maintained by the repairer :    * just before the next node failure , for each @xmath335 , for each @xmath333 , for each @xmath336 , fragment @xmath331 for @xmath332 is stored at node @xmath173 . * just before the next node failure , for each @xmath335 , for each @xmath333 , fragments for the first @xmath334 unassigned efis for @xmath332 are stored at node @xmath44 .    from the first invariant , all @xmath322 objects can be recovered from the fragments associated with assigned efis stored at the nodes just after a node failure , and thus the source data  is recoverable at each point in time .",
    "the repairer operates as follows to reestablish these invariants after a node failure .",
    "suppose for some @xmath335 , node @xmath44 fails and is replaced by a node @xmath44 with all bits set to zeroes .",
    "let @xmath337 .",
    "the repairer dequeues the first efi @xmath338 from the front of the unassigned efis queue , and assigns @xmath338 as the efi @xmath302 for node @xmath44 .",
    "the repairer enqueues efi @xmath339 to the end of the unassigned efis queue , which reestablishes @xmath319 as the number of unassigned efis .",
    "the first repairer step operates as follows . for each @xmath340 and for each @xmath333 ,",
    "the repairer moves fragment @xmath341 for object @xmath342 from node @xmath119 to node @xmath44 .",
    "the number of fragments read by the repairer in the first step is @xmath343 , and the number of fragments written by the repairer in the first step is also @xmath343 .    after this first step , for each @xmath340 , @xmath344",
    "no longer has a fragment for any unassigned efi , and for @xmath345 , @xmath342 has fragments for the first @xmath193 unassigned efis .",
    "there are no fragments for the last unassigned efi @xmath339 at the end of unassigned efis queue .",
    "thus , the objects are logically reordered at this point , i.e. , for @xmath345 , the old @xmath342 becomes the new @xmath346 , and the old @xmath344 becomes the new @xmath347 ( which currently has no fragments for unassigned efis ) .",
    "the second repairer step operates as follows . for each @xmath340 ,",
    "the repairer reconstructs @xmath347 from the fragments for the assigned efis at the @xmath348 nodes other than node @xmath44 , generates fragments for the @xmath319 unassigned efis and writes these fragments to node @xmath119 .",
    "the number of fragments read by the repairer in the second step is @xmath349 , and the number of fragments stored by the repairer in the second step is @xmath343 .",
    "the third repairer step operates as follows . for each @xmath333 ,",
    "the repairer reconstructs @xmath332 from the fragments for the assigned efis at the @xmath348 nodes other than node @xmath44 , generates fragments for @xmath350 and the first @xmath334 unassigned efis for @xmath332 , and writes these fragments to node @xmath44 .",
    "the number of fragments read by the repairer in the third step is @xmath343 and the number of fragments stored by the repairer in the third step is @xmath351 .",
    "the three repairer steps reestablish the invariants after a node failure .",
    "the fragments read by the repairer in the first and second steps are somewhat overlapping , and thus the total number of fragments read from those two steps is @xmath352 , and the total number of fragments read from all three steps for each node failure is @xmath353 and the total number of fragments stored from all three steps for each node failure is @xmath354    the storage overhead  of this system can be derived as follows .",
    "the aggregate number of source fragments is @xmath355 . at each point in time , there are @xmath322 fragments for assigned efis and @xmath356 fragments for unassigned efis at each node , and thus the aggregate number of fragments at each node is @xmath357 since there are @xmath1 nodes , the value of @xmath29 defined by equation   is the storage overhead .    for large @xmath1 , @xmath358 and @xmath359 and @xmath360 thus ,",
    "@xmath361 if the read repair rate  is at a steady rate of @xmath362 then the repairer can read @xmath363 fragments between node failures and complete the three steps between node failures to reestablish the invariants . putting this together , yields inequality  , and completes the proof of theorem  [ core_upper theorem ] .    similarly , @xmath364 if the write repair rate  is at a steady rate of @xmath365 then the repairer can store @xmath366 fragments between node failures and complete the three steps between node failures to reestablish the invariants .",
    "thus , @xmath367 < 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em      we compare theorem  [ core_lower theorem ] with theorem  [ core_upper theorem ] .",
    "the righthand side of inequalities   and   converge to @xmath89 as @xmath90 . even for larger @xmath29",
    "the bounds are relatively tight , e.g. , when @xmath368 , inequality   is @xmath369 whereas inequality   is @xmath370      in this section we sketch the proof of theorem  [ main_upper theorem ] .",
    "the advanced liquid repairer  used for this proof is a small modification ( described below ) of the advanced liquid repairer  introduced in section  [ core_upper sec ] .",
    "the proof is similar in outline to the proof of theorem  [ core_upper theorem ] provided in section  [ core_upper sec ] .",
    "one thing that needs to be shown in the proof of theorem  [ main_upper theorem ] , is that over a long enough period of time the expected number of node failures over that period and the actual number of node failures over that period differ by a relatively small amount with high probability .",
    "the increments of time between node failures is chosen by independently sampling a random variable @xmath51 with @xmath52 } = \\delta$ ] . for a fixed @xmath371 , and for a given @xmath51 , asymptotically",
    "as @xmath1 grows , it can be shown that over periods of duration @xmath372 the probability that the number of node failures is not within a small relative interval around @xmath373 is exponentially small in @xmath1 .",
    "thus , the average time between node failures over a period of duration @xmath374 is approximately @xmath52 } = \\delta$ ] with high probability .",
    "another issue is that the advanced liquid repairer  described in section  [ core_upper sec ] does not have any buffer of protection against node failures that occur at random times instead of at fixed known times .",
    "thus , we use @xmath375 for a constant @xmath285 , and then the advanced liquid repairer  operates at a smooth read rate , but always makes sure that the three repairer steps described in section  [ core_upper sec ] with reference to node @xmath44 failing are completed before there are at most @xmath376 additional node failures after node @xmath44 failed .",
    "it can be guaranteed that this condition is not met with only an exponentially small in @xmath1 probability , where the  is inversely proportional to this probability .",
    "the overall storage overhead  is then approximately @xmath377 .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em",
    "a _ functional repairer _ generalizes a repairer that reads bits from a node to a repairer that reads the output of a locally computed function of bits at a node .",
    "functional repairers are conceptually more powerful than repairers",
    ". some forms of functional repairers were introduced in @xcite , @xcite , which are discussed in section  [ related work sec ] .",
    "the _ functional read repair rate _ is the rate at which output bits of locally computed functions are read by the functional repairer , and the _ read repair rate _ is the rate at which input bits to locally computed functions are read from nodes .",
    "we let @xmath378 and @xmath379 denote the peak and average functional read repair rate , and as before @xmath76 and @xmath75 denote the peak and average read repair rate .",
    "figure  [ func_storage_nodes fig ] shows an example of a distributed storage system using a functional repairer , where @xmath380 is the local function computed at node @xmath8 .",
    "the input bits to @xmath380 read from node @xmath8 are included in the read repair rate , whereas the output bits of @xmath380 read by the functional repairer are included in the functional read repair rate .",
    "when the local functions are the identity functions at each node then a functional repairer is simply a repairer and the read repair rate  and the functional read repair rate  are the same . in general , a local function can compress input bits into a smaller number of output bits , and thus the read repair rate  can be larger than the functional read repair rate  for a functional repairer .",
    "algorithm  [ functional phase ] emulates a phase as described in section  [ core lemma sec ] with respect to a functional repairer , and describes the information available to reconstruct the source data .",
    "steps  [ initialize start ] through  [ initialize lost ] are initialization steps for the phase .",
    "@xmath124 is the set of random bits used to choose the portion of the node failure sequence .",
    "note that @xmath381 @xmath382 is the set of output bits from local functions that have been read since the phase start and , for each @xmath383 , @xmath384 is the set of output bits read from the local function at node @xmath8 since the phase start .",
    "@xmath385 is fixed to the set of bits stored in the repairer local memory at the phase start and , for each @xmath383 , @xmath386 is fixed to the set of @xmath3 bits stored at node @xmath8 at the phase start .",
    "@xmath387 is the list of node failure indices  chosen since the phase start .",
    "@xmath388 is the set of nodes that have not yet failed since the phase start .",
    "the value of @xmath389 is a lower bound on the amount of entropy lost due to node failures .",
    "@xmath390 bits used to choose node identifiers [ initialize start ] @xmath391",
    "@xmath392 @xmath393 bits in repairer local memory @xmath394 bits at node @xmath8 @xmath395 @xmath396 @xmath397 [ initialize lost ] [ trigger ] @xmath398 @xmath399 [ fail node ] @xmath400",
    "@xmath401 @xmath402 [ erase node ] @xmath403 [ increment lost ] @xmath404 [ g function ] [ determine failed ] @xmath405 [ f function ] @xmath406 @xmath407    the functions @xmath408 , @xmath409 , and @xmath410 define the functional repairer actions as the phase proceeds .",
    "the inputs to @xmath408 , @xmath409 and @xmath410 include the values of @xmath411 , since these bits determine the action of the repairer at each point in time .",
    "the function @xmath410 determines how much data is read between distinct failures .",
    "when all reads since the previous distinct failure  are completed and it is time for the next distinct failure  to occur , @xmath410 evaluates to true at step  [ trigger ] , triggering the next distinct failure .",
    "when a distinct failure  is triggered , @xmath412 is called in step  [ fail node ] to select node @xmath8 from the remaining set @xmath388 of node that have not yet failed since the phase start . in step",
    "[ erase node ] , @xmath386 is zeroed , indicating that node @xmath8 has failed and been replaced with a node initially storing all zeroes .",
    "after step  [ increment lost ] , the value of @xmath389 after the node failure with index  @xmath147 is the generalization for functional repairers of @xmath413 .",
    "the function @xmath409 determines the node @xmath8 from which to read the next bits in step  [ g function ] .",
    "there can be many bit  reads from many different nodes between each node failure , and thus @xmath409 may be called multiple times ( until @xmath410 evaluates to true ) between node failures .",
    "if node @xmath8 has failed since the phase start , as determined in step  [ determine failed ] , then reading bits from @xmath8 does not provide additional information , since bits written to node @xmath8 since it failed are determined by @xmath411 .",
    "the function @xmath408 determines which bits are read by the repairer .",
    "@xmath408 is called each time just after @xmath409 has determined the node @xmath8 from which to read the next bits , and thus one of the inputs to @xmath408 is @xmath386 .",
    "each call to @xmath408 at step  [ f function ] determines which function to apply to @xmath386 at that call and how many bits are in the output of the call ( which is the number of bits counted as read by the functional repairer due to the call ) .",
    "these parameters vary at each call to @xmath408 depending on the values of the inputs @xmath411 . the output of each call to @xmath408",
    "is appended to both @xmath382 and @xmath384 .",
    "since the inputs to @xmath408 includes all the inputs to @xmath409 and @xmath410 , @xmath408 implicitly can calculate @xmath409 and @xmath410 at any point in time , and thus @xmath409 and @xmath410 are introduced for notational convenience .    inequality   of theorem  [ true_entropy theorem ] is the functional repairer equivalent of inequality  , and thus theorem  [ true_entropy theorem ] formally justifies the functional analogs of all the results , i.e. , the functional repairer analogs of theorem  [ core_lower theorem ] , lemma  [ core_lower lemma ] , theorem  [ main_lower theorem ] , and lemma  [ main_lower lemma ] are exactly the same except that repairer is replaced with functional repairer and read repair rate  @xmath75 is replaced with functional read repair rate  @xmath379 .",
    "[ true_entropy theorem ] source data  @xmath27 is not reliably recoverable if @xmath414 where @xmath389 is defined by algorithm  [ functional phase ] .",
    "consider the conditions just after @xmath389 is updated in step  [ increment lost ] .",
    "let @xmath415 be the concatenation for all @xmath416 of @xmath386 , i.e. , @xmath415 is the concatenation of bits stored at not yet failed nodes .",
    "let @xmath417 be the concatenation of the portions of @xmath382 that are the output of @xmath408 when the input @xmath386 to @xmath408 is for some @xmath416 .",
    "let @xmath418 be the set of failed nodes .",
    "let @xmath419 be the concatenation for all @xmath420 of @xmath386 , i.e. , @xmath419 is the concatenation of the bits stored at failed nodes , and thus all bits of @xmath419 are zeroes .",
    "let @xmath421 be the concatenation of the portions of @xmath382 that are the output of @xmath408 when the input @xmath386 to @xmath408 is for some @xmath420 .",
    "( at the time @xmath386 is an input to @xmath408 , node @xmath8 has not yet failed . )",
    "@xmath382 can be rearranged as @xmath422 note that @xmath423 and @xmath424 .",
    "the bits @xmath425 stored at the nodes and repairer local memory after step  [ increment lost ] is a deterministic function of @xmath426 and thus @xmath427 since @xmath419 is all zeroes , @xmath428 note that @xmath429 however , @xmath417 is @xmath408-computable from @xmath430 and thus @xmath431 because @xmath423 and because @xmath432 @xmath433 thus , @xmath434 source data  @xmath27 is not reliably recoverable if @xmath435 . from inequalities  , , and  , if @xmath436 just after step  [ increment lost ] then @xmath27 is not reliably recoverable .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    note that the upper bounds on read repair rate  @xmath76 for the advanced liquid repairers of theorem  [ core_upper theorem ] and theorem  [ main_upper theorem ] essentially match the lower bounds on functional read repair rate  @xmath379 provided by the functional repairer analogs of theorem  [ core_lower theorem ] and theorem  [ main_lower theorem ] .",
    "the read repair rate  generally dominates the write repair rate , i.e. , the write repair rate  for a repairer is substantially less than the read repair rate  when @xmath29 is small .",
    "thus , bounds with respect to write repair rates are generally less important than bounds with respect to read repair rates .",
    "let @xmath437 be the bit - locations to which the repairer _ writes _ in a phase that starts at a node failure with index  @xmath44 and ends with index  @xmath119 .",
    "then , by reasoning similar to that used to justify inequality  , the source data  is not reliably recoverable after the node failure with index  @xmath119 if @xmath438 from this it can be seen that if there are @xmath439 distinct failures starting at index  @xmath44 and ending at @xmath119 and the source data  is recoverable after the node failure with index  @xmath119 then @xmath440    [ core_lower_write theorem ] for every fixed @xmath441 , for source data  size @xmath81 , for every repairer there is a node failure sequence  with a fixed timing sequence  and with erasure rate  @xmath21 such that if the repairer has average write repair rate  @xmath442 and is always able to maintain recoverability of the source data  then @xmath443    for each phase , a permutation of the @xmath1 possible identifiers , e.g. , @xmath444 , can be chosen as the identifiers of the nodes that fail , and thus each node failure is a distinct failure .",
    "thus , from inequality  , after all @xmath1 node failures of the phase ( which is of duration @xmath445 , and corresponds to @xmath446 ) , the repairer must have written at least @xmath447 bits if the source data  is still recoverable .",
    "thus , the average rate at which bits are written by the repairer must satisfy inequality  .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    [ main_lower_write theorem ] for every fixed @xmath448 , for source data  size @xmath81 , for any repairer with average write repair rate  @xmath442 with respect to any random node failure distribution  with erasure rate  @xmath449 , if the repairer is always able to maintain recoverability of the source data  then @xmath450    on average , after there have been @xmath439 distinct failures since the phase start , the number of node failures overall is @xmath451 . from inequality  , after @xmath439 distinct failures since the phase start ( which takes average time @xmath452 ) , the repairer must have written at least @xmath453 bits if the source data  is still recoverable .",
    "thus , @xmath454 inequality   follows using the setting @xmath455 .",
    "< 1.5em - 1.5em plus0em minus0.5em height0.75em width0.5em depth0.25em    note that inequality   becomes @xmath456 when @xmath457 , @xmath458 when @xmath459 , and @xmath460 transitions from @xmath461 to @xmath462 as @xmath29 transitions from @xmath463 to @xmath138 .",
    "based on equation  , it can be shown that the advanced liquid repairer  satisfies the following write repair rate  upper bound .",
    "[ main_upper_write theorem ] for every @xmath441 , asymptotically as @xmath1 grows , for source data  size @xmath81 , the advanced liquid repairer  with peak write repair rate  @xmath464 with respect to any random node failure distributionwith erasure rate  @xmath21 , can achieve  exponential in @xmath1 and satisfy @xmath465",
    "in this section we briefly discuss some additional ds models with different types of fail processes .",
    "one can extend the read repair rate  lower bound results to an augmented random node failure distribution , where a variable number of nodes concurrently fail .",
    "thus , the augmented random node failure distribution  decides the timing of failures , the number of nodes to fail , and the pattern of node failures . for each next failure event ,",
    "the augmented random node failure distributionfirst chooses a number @xmath466 of nodes to next fail from a probability distribution @xmath467 ( where @xmath467 can be known to the repairer ) .",
    "then , the augmented random node failure distribution  chooses the timing of the next failure event , according to a poisson distribution with rate @xmath468 , where @xmath468 can depend on @xmath466 and @xmath1 ( where the poisson distribution rate @xmath468 associated with @xmath469 can be known to the repairer ) . finally , the augmented random node failure distribution  chooses @xmath466 nodes to fail uniformly and randomly from among the @xmath1 nodes at the chosen timing of the next failure event",
    ".    lemmas  [ core_lower lemma ] and  [ main_lower lemma ] extend to this model , where the erasure rate   @xmath449 in the statement of the theorems is replaced with @xmath470}\\cdot \\frac{s \\cdot n ' } { \\lambda(n',n)},\\ ] ] i.e. , with the average rate at which bits are erased by the augmented random node failure distribution .",
    "let @xmath471 be an upper bound on the number @xmath466 of the nodes that can fail at one time .",
    "then , the analog of lemmas  [ core_lower lemma ] and  [ main_lower lemma ] holds for this model as long as @xmath472 .",
    "small units of data may be corrupted on nodes , i.e. , corruption may be at the granularity at which data units are read from nodes .",
    "corruption of a data unit is treated as loss ( erasure ) when strong check sums are used to protect data stored at the nodes , i.e. , a corrupted data unit is discarded when it fails the check sum condition .",
    "there are two possible scenarios :    notified loss : : :    corruption of a data unit is detected when it occurs .",
    "silent loss : : :    corruption of a data unit is undetected until it is read .    the ds information capacity  with respect to any node failure sequence  with a fixed timing sequence  and with notified loss is asymptotically at most @xmath473 as rer  @xmath2 grows , which can be proved similar to the arguments in section  [ intuition_lower sec ] . the ds information capacity  with respect to a random node failure distribution  with silent loss is asymptotically at least @xmath473 as rer  @xmath2 grows , which can be proved similar to the arguments in section  [ intuition_upper sec ] .",
    "the shannon information capacity  for the _ binary symmetric channel _ ( bsc ) can be characterized as follows",
    ". the _ signal rate _",
    "@xmath20 is the raw rate at which data can be transmitted over the channel , independent of reliability .",
    "the _ error rate _",
    "@xmath21 is the rate at which data transmitted over the channel is randomly corrupted ( each bit  selected for corruption is equally likely to be zero or one if corrupted ) .",
    "the bsc ser is defined as @xmath474    the bsc information capacity  has been shown to be @xmath475 where @xmath476 is the entropy of @xmath477 .",
    "this information capacity  is asymptotically achievable as the source data  size grows .",
    "one can consider a bsc random node failure distribution  with error rate @xmath21 similar to that for the bsc , and the rer  @xmath2 with respect to the bsc random node failure distribution  is @xmath478 where @xmath34 is the repair rate .",
    "it can be shown that the ds information capacity  with respect to a bsc random node failure distribution  is asymptotically at most @xmath479 as rer  @xmath2 grows , which can be proved similar to the arguments in sections  [ core_lower sec ] and  [ main_lower sec ] .",
    "the ds information capacity  with respect to a bsc random node failure distribution  is asymptotically at least @xmath480 as rer  @xmath2 grows , which can be proved similar to the arguments in section  [ main_upper sec ] .",
    "the groundbreaking research of dimakis et .",
    "al . , described in  @xcite and  @xcite , is closest to our work : an object - based distributed storage framework is introduced , and optimal tradeoffs between storage overhead  and functional read repair rate  are proved .",
    "we refer to the framework , the lower bounds , and the repairer described in  @xcite and  @xcite as the _ regenerating framework _ , the _ regenerating lower bounds _ , and the _ regenerating repairer _ , respectively .    the regenerating framework  models repair of a single lost fragment , and is applicable to reactive repair  of a single object .",
    "the regenerating framework  is based on @xmath481 : @xmath8 is the number of fragments for the object ( each stored at a different node ) ; @xmath5 is the number of fragments from which the object must be recoverable ; @xmath482 is the number of fragments used to generate a lost fragment at a new node when a node fails ; @xmath483 is the fragment size ; and @xmath484 is the amount of data generated from each of @xmath482 fragments needed to generate a fragment at a new node .",
    "we consider minimum storage regenerating ( msr ) settings ( the object size is @xmath485 ) , and fix @xmath486 , as these are typically thought of as the most practical settings that minimize storage overhead and minimize repairer traffic .",
    "the regenerating repairer  @xcite , @xcite is a functional repairer ( section  [ functional_rep sec ] ) .",
    "when a node fails , at each of the @xmath487 remaining nodes a network coding function is applied to the fragment read from that node to generate @xmath488 bits that are sent to the repairer , which uses all received bits from the nodes to generate and store a fragment at the new node .",
    "the @xmath488 bits sent to the repairer from each of the @xmath487 nodes is counted in @xmath378 , whereas reading the fragment of size @xmath483 to generate the @xmath488 bits at each node is counted in @xmath76 but not counted in @xmath378 . at the optimal",
    "setting that minimizes @xmath378 , @xmath489 and thus @xmath490 .",
    "the regenerating repairer  @xcite is much more advanced .",
    "when a node fails , at each of the @xmath487 remaining nodes a selected subset of @xmath488 bits of the fragment is read from that node and sent to the repairer , which uses all received bits from the nodes to generate and store a fragment at the new node .",
    "this construction can use reed - solomon codes , and is efficient for small values of @xmath5 and @xmath8 .",
    "each fragment is partitioned into sub - fragments for the regenerating repairer  @xcite , and the number of sub - fragments provably grows quickly as @xmath491 grows or as the storage overhead  @xmath492 approaches zero .",
    "for example there are @xmath493 sub - fragments per fragment for @xmath494 and @xmath495 , and the regenerating repairer  generates a fragment at a new node from receiving @xmath496 non - consecutive sub - fragments from each of @xmath497 nodes .",
    "reading many non - consecutive sub - fragments directly from a node is sometimes efficient , in which case @xmath498 , but typically it is more efficient to read an entire fragment from a node and select the appropriate sub - fragments to send to the repairer , in which case @xmath490 .",
    "in contrast to the regenerating repairers  @xcite , @xcite , @xcite , the advanced liquid repairer  of theorem  [ main_upper theorem ] directly reads unmodified data from nodes , for example using http , and thus the upper bound on @xmath76 accounts for all data read from nodes .",
    "when regenerating repairers  @xcite , @xcite , @xcite are used to repair all objects in a system , @xmath499 with respect to any node failure sequence  with a fixed timing sequence , which is around a factor of two above the lower bound on @xmath500 from the functional repairer analog of theorem  [ core_lower theorem ] .",
    "when regenerating repairers  @xcite , @xcite , @xcite with fixed @xmath8 and @xmath5 are used to repair all objects in a system , @xmath501 necessarily grows as @xmath1 grows in order to achieve a  exponential in @xmath1 with respect to any random node failure distribution .",
    "( compare to the bound on @xmath88 from theorem  [ main_upper theorem ] . )",
    "this is because there is a good chance that multiple node failures occur over a small interval of time with a poisson timing distribution , implying that repair for a node failure must occur in a very short interval of time .",
    "thus , although the regenerating repairers  @xcite , @xcite , @xcite optimally minimize @xmath378 with respect to the regenerating frameworkfor repairing individual objects using reactive repair , they do not provide optimal @xmath378 at the system level when used to store and repair objects , for fixed @xmath8 and @xmath5 as @xmath1 grows .",
    "regenerating lower bounds on the functional read repair rate  prove necessary conditions on the regenerating framework  parameters to ensure than an individual object remains recoverable when using reactive repair .",
    "the bounds are based on a specially constructed acyclic graph , which corresponds to a specially constructed node failure sequence , and does not show for example a lower bound for uniformly chosen node failures .",
    "also , the lower bounds are not extendable to non - trivial timing sequences , e.g. , a poisson timing distribution .",
    "one could consider applying the regenerating framework  at the system level across all objects , e.g. , @xmath502 , and , for msr settings , @xmath503 and @xmath504 for source data  of size @xmath24 .",
    "the following two examples illustrate how the regenerating framework  so applied is nt suitably expressive , and thus the regenerating lower bounds do not provide system level lower bounds .",
    "the regenerating framework  requirement would be that all source data  is recoverable from any @xmath296 of the @xmath1 nodes .",
    "however , as described in section  [ practical sec ] , small code systems partition source data   into objects , and fragments for objects are distributed equally to all @xmath1 nodes , and thus small code systems read data from almost all @xmath1 nodes to recover all source data , which violates this requirement .",
    "the regenerating framework  requirement would be that data is only written to a node when it is added : writing data incrementally to a node over time as nodes fail is not expressible .",
    "liquid systems write data incrementally to a node over a large number of node failures after the node is added , which violates this requirement .",
    "there are many ways to extend this research , accounting for practical issues in storage system deployments .    failures in deployed systems can happen at a variable rate that is not known a priori .",
    "for example , a new batch of nodes introduced into a deployment may have failure rates that are dramatically different than previous batches .",
    "both time and spatial failure correlation is common in deployed systems .",
    "failures in different parts of the system are not completely independent , e.g. , racks of nodes fail concurrently , entire data centers go offline , power and cooling units fail , node outages occur due to rolling system maintenance and software updates , etc .",
    "all of these events introduce complicated correlations between failures of the different components of the system .",
    "intermittent node failures are common in deployed systems , accounting for a vast majority ( e.g. , 90% ) of node failures . in the case of an intermittent node failure ,",
    "the data stored at the node is lost for the duration of the failure , but after some period of time the data stored on the node is available again once the node recovers ( the period of time can be variable , e.g. , ranging from a few seconds to days ) .",
    "intermittent failures can also affect entire data centers , a rack of nodes , etc .",
    "repairing fragments temporarily unavailable due to transient node failures wastes network resources .",
    "thus , a timer is typically set to trigger a fixed amount of time after a node fails ( e.g.,15 minutes ) , and the node is declared permanently failed and scheduled for repair if it has not recovered within the trigger time . setting the trigger time can be tricky for a small code system ; a short trigger time can lead to unnecessary repair , whereas a long trigger time can reduce reliability .",
    "data can silently be corrupted or lost without any notification to the repairer ; the only mechanism by which a repairer may become aware of such corruption or loss of data is by attempting to read the data , i.e. , data scrubbing .",
    "( the data is typically stored with strong checksums , so that the corruption or loss of data becomes evident to the repairer when an attempt to read the data is made . ) for example , the talk  @xcite reports that read traffic due to scrubbing can be greater than all other read data traffic combined",
    ".    there can be a delay between when a node permanently fails and when a replacement node is added .",
    "for example , in many cases adding nodes is performed by robots , or by manual intervention , and nodes are added in batches instead of individually .",
    "it is important in many systems to distribute the repair evenly throughout the nodes and the network , instead of having a centralized repairer .",
    "this is important to avoid cpu and network hotspots . distributed versions of the the algorithms described in sections  [ intuition_upper sec ] , [ core_upper sec ] and  [ main_upper sec ] distribute the repair traffic smoothly among all nodes of the system .",
    "based on this , it can be seen that distributed versions of the lower bounds and upper bounds asymptotically converge as the storage overhead  approaches zero .",
    "network topology is an important consideration in deployments , for example when objects are geo - distributed to multiple data centers . in these deployments ,",
    "the available network bandwidth between different nodes may vary dramatically , e.g. , there may be abundant bandwidth available between nodes within the same data center , but limited bandwidth available between nodes in different data centers .",
    "the paper  @xcite addresses these issues , and the papers  @xcite , @xcite introduce some erasure codes that may be used in solutions to these issues .",
    "an example of such a deployment is described in  @xcite .    enhancing the distributed storage model by incorporating the elements described above into the model and providing an analysis can be of value in understanding fundamental tradeoffs for practical systems .",
    "we introduce a mathematical model of distributed storage that captures some of the relevant features of practical distributed storage systems .",
    "shannon in @xcite introduced a model of communication and provided asymptotically matching upper and lower bounds on the rate at which information can be communicated .",
    "shannon s mathematical theory of communication has been of great importance in the understanding and design of practical communication systems .",
    "our hope is that the model of distributed storage and the asymptotically matching upper and lower bounds on the tradeoffs between storage overhead  and read repair rate  described herein will be found to have importance in the understanding and design of practical distributed storage systems .",
    "i thank roberto padovani for consistently championing this research .",
    "i thank members of the qualcomm systems technical team for being great collaborators and for providing invaluable feedback on this work as it evolved ( roberto , tom richardson , lorenz minder , pooja aggarwal ) .",
    "i thank the simons institute at uc berkeley for sponsoring the information theory program january - april 2015 , as the participants in this program provided a lot of detailed information about work in distributed storage that helped understand the context of our research in general .",
    "i thank tom richardson for taking the time to deeply understand and provide dramatic improvements to this research , ranging from novel high level presentation suggestions to technical simplifications of proofs .",
    "i thank tom and the organizers of the shannon lecture series at ucsd for conspiring to invite me to give the shannon lecture december 1 , 2015  preparing the presentation for this lecture inspired thinking about a mathematical model analogous to shannon s communication theory model .",
    "i thank colleagues at dropbox ( in particular james cowling ) , microsoft azure ( in particular cheng huang and parikshit gopalan ) , google ( in particular lorenzo vicisano ) and facebook for sharing valuable insights into operational aspects and potential issues with large scale deployed distributed storage systems .",
    "michael g. luby is vp technology , qualcomm , inc .",
    "research and development projects include liquid distributed storage , lte broadcast multimedia delivery , and dash internet streaming .",
    "mike earned a bsc in applied math from mit and a phd in theoretical computer science from uc berkeley .",
    "he founded digital fountain inc . in 1999 , and served as cto until acquired by qualcomm inc . in 2009 .",
    "awards for his research include the ieee richard w. hamming medal , the acm paris kanellakis theory and practice award , the acm edsger w. dijkstra prize in distributed computing , the acm sigcomm test of time award , the ieee eric e. sumner communications theory award , the acm siam outstanding paper prize , the uc berkeley distinguished alumni in computer science award , and the ieee information theory society information theory paper award .",
    "he is a member of the national academy of engineering , and is an ieee fellow and an acm fellow ."
  ],
  "abstract_text": [
    "<S> the _ information capacity _ of a distributed storage system is the amount of source data   that can be reliably stored for long durations . </S>",
    "<S> storage nodes fail over time and are replaced , and thus data is erased at an _ </S>",
    "<S> erasure rate_. to maintain recoverability of source data , a repairer generates redundant data from data read from nodes , and writes redundant data to nodes , where the _ repair rate _ is the rate at which the repairer reads and writes data . </S>",
    "<S> we prove the information capacity  approaches @xmath0 as @xmath1 and @xmath2 grow , where @xmath1 is the number of nodes , @xmath3 is the amount of data each node can store , and @xmath2 is the _ repair rate  to erasure rate  ratio_.    distributed information systems , data storage systems , data warehouses , information science , information theory , information entropy , error compensation , mutual information , channel capacity , channel coding , time - varying channels , error correction codes , reed - solomon codes , network coding , signal to noise ratio , throughput , distributed algorithms , algorithm design and analysis , reliability , reliability engineering , reliability theory , fault tolerance , redundancy , robustness , failure analysis , equipment failure . </S>"
  ]
}