{
  "article_text": [
    "in this paper , we discuss a structural linear regression technique in the context of model of mixture with varying concentrations ( mvc ) .",
    "mvc means that the observed subjects belong to @xmath0 different subpopulations ( mixture components ) .",
    "the true numbers of components to which the subjects @xmath1 , @xmath2 , belong , say , @xmath3 , are unknown , but we know the probabilities @xmath4 ( mixing probabilities or concentrations of the mixture components ) .",
    "mvc models arise naturally in the description of medical , biologic , and sociologic data @xcite .",
    "they can be considered as a generalization of finite mixture models ( fmm ) .",
    "classical theory of fmms can be found in monographs @xcite .",
    "let @xmath5 be a vector of observed features ( random variables ) of a subject @xmath6 .",
    "we consider the following linear regression model for these variables : @xmath7 where @xmath8 are nonrandom regression coefficients for the @xmath9th component , @xmath10 is an error term , which is assumed to be zero mean and conditionally independent of the regressors vector @xmath11 given @xmath12 .    *",
    "* we consider a subject @xmath6 as taken at random from an infinite population , so it is random in this sense .",
    "the vector of observed variables @xmath13 can be considered as a random vector even for a fixed @xmath6 .",
    "our aim is to estimate the vectors of regression coefficients @xmath14 , @xmath15 , by the observations @xmath16 , where @xmath17 .",
    "we assume that @xmath18 are independent for different @xmath19 .",
    "a statistical model similar to mvc with ( [ eqlinregr ] ) is considered in @xcite , where a  parametric model for the conditional distributions of @xmath10 given @xmath12 is assumed . for this case ,",
    "maximum likelihood estimation is proposed in @xcite , and a version of em - algorithm is developed for numerical computation of the estimates .    in this paper , we adopt a nonparametric approach assuming no parametric models for @xmath10 and @xmath20 distributions .",
    "nonparametric and semiparametric technique for mvc was developed in @xcite .",
    "we use the weighted empirical moment technique to derive estimates for the regression coefficients and then obtain conditions of consistency and asymptotic normality of the estimates .",
    "these results are based on general ideas of least squares @xcite and moment estimates @xcite .",
    "the rest of the paper is organized as follows . in section [ sectnonp ]",
    ", we recall some results on nonparametric estimation of functional moments in general mvc .",
    "the estimates are introduced , and conditions of their consistency and asymptotic normality are presented in section [ sectass ] . section [ sectproof ] contains proofs of the statements of section [ sectass ] .",
    "results of computer simulations are presented in section  [ sectsimulat ] .",
    "let us start with some notation and definitions .",
    "we denote by @xmath21 the distribution of @xmath13 for @xmath6 belonging to the @xmath9th component of the mixture , that is , @xmath22 for all measurable sets @xmath23 .",
    "then by the definition of mvc @xmath24 in the asymptotic statements , we will consider the data @xmath25 as an element of ( imaginary ) series of data @xmath26 in which no link between observations for different @xmath27 is assumed .",
    "so , in formal notation , it should be more correct to write @xmath28 instead of @xmath29 , but we will drop the subscript @xmath27 when it is insignificant .",
    "we consider an array of all concentrations for all data sizes @xmath30 its subarrays @xmath31 are considered as vector columns , and @xmath32 as an @xmath33-matrix .",
    "we will also consider a weight array @xmath34 of the same structure as @xmath35 with similar notation for its subarrays .    by the angle brackets with subscript @xmath36 we denote the averaging by @xmath37 : @xmath38 multiplication , summation , and other operations in the angle brackets",
    "are made elementwise : @xmath39 we define @xmath40 if this limit exists .",
    "let @xmath41 @xmath42 be an @xmath43 matrix , and @xmath44 be its @xmath45th minor .",
    "the matrix @xmath46 can be considered as the gramian matrix of vectors @xmath47 in the inner product @xmath48 , so that it is nonsingular if these vectors are linearly independent .    in",
    "what follows , @xmath49 means convergence in probability , and @xmath50 means weak convergence .",
    "assume now that model ( [ eqmvcdef ] ) holds for the data @xmath51 .",
    "then the distribution @xmath21 of the @xmath9th component can be estimated by the weighted empirical measure @xmath52 where @xmath53 it is shown in @xcite that if @xmath46 is nonsingular , then @xmath54 is the minimax unbiased estimate for @xmath21 .",
    "the consistency of @xmath54 is demonstrated in @xcite ( see also @xcite ) .",
    "consider now functional moment estimation based on weighted empirical moments .",
    "let @xmath55 be a measurable function . then to estimate @xmath56=\\int g(x)f_m(dx),\\vspace*{-3pt}\\ ] ] we can use @xmath57    [ lemconsist ] assume that    1 .",
    "@xmath58<\\infty$ ] for all @xmath15 .",
    "there exists @xmath59 such that @xmath60 for all @xmath27 large enough .",
    "then @xmath61 as @xmath62 .",
    "this lemma is a simple corollary of theorem 4.2 in @xcite .",
    "( see also theorem 3.1.1 in @xcite ) .",
    "[ lemclt ] assume that    1 .",
    "@xmath63<\\infty$ ] for all @xmath15 .",
    "there exists @xmath59 such that @xmath60 for all @xmath27 large enough .",
    "3 .   there exists the limit @xmath64    then @xmath65 for univariate @xmath66 , the statement of the lemma is contained in theorem 4.2 from @xcite ( or theorem 3.1.2 in @xcite ) .",
    "the multivariate case can be obtained from the univariate one applying the cramr ",
    "wold device ( see @xcite , p.  382 ) .",
    "in view of lemma [ lemconsist ] , we expect that , under suitable assumptions , @xmath68 converges to @xmath69{\\stackrel{\\text{\\rm def}}{=}}j_{m;\\infty}({{\\mathbf b}})\\end{aligned}\\ ] ] as @xmath62 .",
    "since @xmath70 attains its minimal value at @xmath71 , it is natural to suggest the argmin of @xmath72 as an estimate for @xmath71 .",
    "if the weights @xmath73 were positive , then this argmin would be @xmath74 where @xmath75 is the @xmath76 matrix of observed regressors , @xmath77 is the vector of observed responses , and @xmath78 is the diagonal weight matrix for estimation of @xmath9th component .",
    "( obviously , @xmath79 depends on @xmath9 , but we do not show it explicitly by a   subscript since the number @xmath9 of the component for which @xmath67 is estimated will be further fixed . )    generally speaking , by ( [ eqdefa ] ) @xmath80 must be negative for some @xmath19 , so @xmath81 is not necessarily an argmin of @xmath82 .",
    "but we will take @xmath81 as an estimate for @xmath67 and call it a modified least - squares estimate for @xmath67 in mvc model ( mvc - ls estimate ) .",
    "let @xmath83\\ ] ] be the matrix of second moments of the regressors for subjects belonging to the @xmath84th component .",
    "denote the variance of the @xmath84th component s error term by @xmath85.\\ ] ] ( recall that @xmath86=0 $ ] ) . in what follows",
    ", we assume that these moments and variances exist for all components .",
    "[ thconsist ] assume that    1 .",
    "@xmath87 and @xmath88 are finite for all @xmath15 .",
    "@xmath89 is nonsingular .",
    "there exists @xmath59 such that @xmath60 for all @xmath27 large enough .",
    "then @xmath90 as @xmath62 .    * note .",
    "* assumption 3 can be weakened . applying theorem 4.2 from @xcite",
    ", we can show that @xmath91 is consistent if the vector @xmath92 is asymptotically linearly independent from the vectors @xmath93 , @xmath94 , as @xmath62 . to avoid complexities in this presentation",
    ", we do not formulate the strict meaning of this statement",
    ".    denote @xmath95 $ ] , @xmath96\\bigr)_{l , q=1}^d,&\\\\ & { { \\mathbf m}}^{ik(s , p)}{\\stackrel{\\text{\\rm def}}{=}}\\bigl(d^{il(s)}d^{kq(p)}\\bigr)_{l , q=1}^d.&\\end{aligned}\\ ] ]    [ thclt ] assume that    1 .",
    "@xmath97<\\infty$ ] and @xmath98<\\infty$ ] for all @xmath15 .",
    "matrix @xmath99 is nonsingular .",
    "there exists @xmath59 such that @xmath60 for all @xmath27 large enough .",
    "4 .   for all @xmath100,@xmath101",
    ", there exist @xmath102",
    ".    then @xmath103 , where @xmath104 with @xmath105",
    "note that if @xmath89 is nonsingular , then @xmath106.\\ ] ] by lemma [ lemconsist ] , @xmath107 and @xmath108\\ ] ] as @xmath62 .",
    "this implies the statement of the theorem .",
    "let us introduce a set of random vectors @xmath109 , @xmath110 , with distributions @xmath111 that are independent for different @xmath19 and @xmath84 and independent from @xmath112 .",
    "denote @xmath113 , @xmath114 then the distribution of @xmath115 is the same as that of @xmath51 . since in this theorem we are interested in weak convergence only , without loss of generality , let us assume that @xmath116 . by @xmath117",
    "we denote the sigma - algebra generated by @xmath118 .",
    "let us show that @xmath119 converges weakly to @xmath120 .",
    "it is readily seen that @xmath121^{-1}\\biggl[\\frac{1}{\\sqrt{n}}\\bigl({{\\mathbf x}}^t { { \\mathbf a}}{{\\mathbf y}}- { { \\mathbf x}}^t { { \\mathbf a}}{{\\mathbf x}}{{\\mathbf b}}^{(m)}\\bigr)\\biggr].\\ ] ]    since @xmath122 , we need only to show week convergence of the random vectors @xmath123 to @xmath124 .",
    "denote @xmath125    obviously , @xmath126 we will apply lemma [ lemclt ] to show that @xmath127 .    first , let us show that @xmath128 .",
    "it is equivalent to @xmath129 for all @xmath130 .",
    "in fact , @xmath131\\\\ & \\quad = \\frac{1}{\\sqrt{n } } \\operatorname{\\mathsf e}\\sum_{j=1}^{n}a_{j;n}^{(m)}\\sum_{s=1}^m p_{j;n}^s x_j^{i ( s ) } \\biggl(y_j^{(s ) } - \\sum_{l=1}^d x_j^{l(s)}b_l^{(m)}\\biggr)\\\\ & \\quad = \\sqrt{n } \\sum_{s=1}^m \\underbrace{{\\bigl\\langle a^{(m ) } { { \\mathbf p}}^s \\bigr\\rangle } _ n } _",
    "{ \\mathbh1\\{m = s\\}}\\operatorname{\\mathsf e}\\biggl[x_1^{i ( s ) } \\biggl ( y_1^{(s ) } -\\sum_{l=1}^d x_1^{l ( s)}b_l^{(m ) } \\biggr)\\biggr]\\\\ & \\quad = \\sqrt{n } \\operatorname{\\mathsf e}\\biggl[x_1^{i ( m ) } \\underbrace{\\biggl(y_1^{(m ) } - \\sum_{l=1}^d x_1^{l ( m ) } b_l^{(m)}\\biggr)}_{\\varepsilon_1^{(m)}}\\biggr ] = \\sqrt{n } \\operatorname{\\mathsf e}x_1^{i ( m ) } \\operatorname{\\mathsf e}\\varepsilon_1^{(m ) } = 0.\\end{aligned}\\ ] ]    so @xmath132 in view of lemma [ lemclt ] , to complete the proof , we only need to show that@xmath133 .",
    "denote @xmath134 and @xmath135 then @xmath136 where @xmath137 note that @xmath138=0.\\ ] ] now @xmath139 \\cdot\\delta_j^{(p ) } \\biggl(\\sum_{q=1}^d d^{kq(p)}\\bigl(b_q^{(p)}- b_q^{(m)}\\bigr ) \\biggr)\\nonumber\\\\ & \\quad = \\frac{1}{n}\\sum_{j=1}^n\\bigl(a_j^{(m)}\\bigr)^2 \\sum_{s=1}^m p_{j;n}^s \\biggl(\\sum_{l=1}^d \\bigl(\\underbrace{d^{il(s)}- d^{il(s)}}_{0}\\bigr ) \\bigl(b_l^{(s ) } -b_l^{(m)}\\bigr ) + \\operatorname{\\mathsf e}x_j^{i ( s)}\\underbrace { \\operatorname{\\mathsf e}\\varepsilon_j^{(s)}}_{0}\\biggr)\\nonumber\\\\ & \\qquad \\times\\biggl(\\sum_{q=1}^d d^{kq(s)}\\bigl(b_q^{(s ) } - b_q^{(m)}\\bigr ) \\biggr ) = 0;\\end{aligned}\\ ] ] @xmath140 & \\quad \\times\\bigl(x_j^{k(s)}x_j^{q(s ) } - d^{kq(s)}\\bigr)\\bigr ) \\bigl(b_q^{(s ) } - b_q^{(m)}\\bigr)\\\\[3pt ] & \\quad + \\frac{1}{n}\\sum_{j=1}^n \\bigl(a_{j;n}^{(m)}\\bigr)^2 \\sum_{s=1}^m p_{j;n}^s d^{ik(s ) } ) \\bigl(\\sigma^{(s)}\\bigr)^2;\\\\[3pt ] \\operatorname{cov}\\bigl(s_2^i , s_2^k\\bigr ) & = \\frac{1}{n}\\sum_{j=1}^n \\bigl(a_{j;n}^{(m)}\\bigr)^2 \\sum_{s=1}^m p_{j;n}^s \\sum_{q=1}^d \\sum_{l=1}^d \\bigl(b_l^{(s ) } - b_l^{(m)}\\bigr)d^{il(s)}\\\\[2pt ] & \\quad \\times\\biggl [ \\bigl(b_q^{(s ) } - b_q^{(m)}\\bigr ) d^{kq(s ) } - \\sum_{r=1}^m p_{j;n}^r \\bigl(b_q^{(r ) } - b_q^{(m)}\\bigr ) d^{kq(r)}\\biggr].\\end{aligned}\\ ] ]    thus , @xmath141 & \\quad + \\frac{1}{n}\\sum_{j=1}^n\\bigl(a_j^{(m)}\\bigr)^2 \\sum_{s=1}^m p_{j;n}^s \\sum_{q=1}^d \\sum_{l=1}^d\\bigl(b_l^{(s ) } - b_l^{(m)}\\bigr)\\biggl [ \\bigl(b_q^{(s ) } - b_q^{(m)}\\bigr)\\\\[2pt ] & \\quad \\times \\underbrace{\\operatorname{\\mathsf e}x_j^{i(s ) } x_j^{k(s)}x_j^{l(s)}x_j^{q(s)}}_{l_{lq}^{ik(s ) } } - d^{il(s ) } \\sum_{r=1}^m p_{j;n}^r \\bigl(b_q^{(r ) } - b_q^{(m)}\\bigr ) d^{kq(r)}\\biggr]\\bigg)_{i , k=1}^d.\\end{aligned}\\ ] ]    from the last equation we get @xmath133 as @xmath62 .",
    "to assess the accuracy of the asymptotic results from section [ sectass ] , we performed a small simulation study .",
    "we considered a two - component mixture ( @xmath142 ) with mixing probabilities @xmath143 and @xmath144 . for each subject , there were two observed variables @xmath145 and @xmath146 , which were simulated based on the simple linear regression model@xmath147 where @xmath148 is the number of component the @xmath19th observation belongs to , @xmath149 was simulated as @xmath150 , @xmath151 as @xmath152 , and @xmath153 were zero - mean gaussians with standard deviations 0.01 for the first component and 0.05 for the second one .",
    "the values of the regression coefficients were @xmath154 , @xmath155 , @xmath156 , @xmath157 .",
    "the means and covariances of the estimates were calculated over 2000 replications .",
    "the results of simulation are presented in table [ table1 ] .",
    "the true values of parameters and asymptotic covariances are placed in the last rows of the tables .",
    "= 8.7 cm    llllll +   + @xmath36 & @xmath158 & @xmath159 & @xmath160 & @xmath161 & @xmath162 + 500 & 3.0014 & 0.5235 & 47.61 & 45.83 & @xmath163 42.27 + 1000 & 3.0033 & 0.512 & 41.19 & 37.50 & @xmath16335.04 + 2000 & 3.0011 & 0.5032 & 38.84 & 34.71 & @xmath16332.87 + 5000 & 3.0003 & 0.5016 & 39.54 & 34.49 & @xmath16332.83 + @xmath164 & 3 & 0.5 & 39.13 & 33.96 & @xmath16332.53 +   +   + @xmath36 & @xmath165 & @xmath166 & @xmath167 & @xmath168 & @xmath169 + 500 & @xmath1632.0243 & 1.0084 & 67.37 & 7.94 & @xmath16322.17 + 1000 & @xmath16342.0100 & 1.0027 & 63.04 & 7.57 & @xmath16320.90 + 2000 & @xmath1632.0039 & 1.0016 & 63.57 & 7.52 & @xmath16320.95 + 5000 & @xmath1632.0074 & 1.0025 & 62.41 & 7.32 & @xmath16320.48 + @xmath164 & @xmath1632 & 1 & 62.20 & 7.34 & @xmath16320.47 +    the presented data show good concordance with the asymptotic theory for @xmath170 .",
    "we considered a modification of least - squares estimators for linear regression coefficients in the case where observations are obtained from a mixture with varying concentrations .",
    "conditions of consistency and asymptotic normality of the estimators were derived , and dispersion matrices were evaluated .",
    "the results of simulations confirm good concordance of estimators covariances with the asymptotic formulas for sample sizes larger then 1000 observations .    in real - life data analysis ,",
    "concentrations ( mixing probabilities ) are usually not known exactly but estimated .",
    "so , to apply the proposed technique , we also need to analyze sensitivity of the estimates to perturbations of the concentrations model .",
    "( we are thankful to the unknown referee for this observation ) .",
    "it is worth noting that performance of these estimates will be poor if the true concentrations of the components are nearly linearly dependent ( @xmath171 ) .",
    "we also expect stability of the estimates w.r.t .",
    "concentration perturbations if @xmath172 is bounded away from zero .",
    "more deep analysis of sensitivity will be a  part of our further work .",
    "grn , b. , leisch , f. : fitting finite mixtures of linear regression models with varying & fixed effects in r. in alfredo rizzi and maurizio vichi , editors , compstat 2006  proceedings in computational statistics , pages 853 - 860 .",
    "physica verlag , heidelberg , germany , 2006 ."
  ],
  "abstract_text": [
    "<S> we consider a finite mixture model with varying mixing probabilities . </S>",
    "<S> linear regression models are assumed for observed variables with coefficients depending on the mixture component the observed subject belongs to . </S>",
    "<S> a modification of the least - squares estimator is proposed for estimation of the regression coefficients . </S>",
    "<S> consistency and asymptotic normality of the estimates is demonstrated .    </S>",
    "<S> ./style / arxiv - vmsta.cfg    finite mixture model , linear regression , mixture with varying concentrations , nonparametric estimation , asymptotic normality , consistency 62j05 , 62g20 </S>"
  ]
}