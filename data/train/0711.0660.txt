{
  "article_text": [
    "penalized maximum likelihood estimators have been studied intensively in the last few years .",
    "a prominent example is the least absolute selection and shrinkage ( lasso ) estimator of tibshirani ( 1996 ) .",
    "related variants of the lasso include the bridge estimators studied by frank and friedman ( 1993 ) , least angle regression ( lars ) of efron , hastie , johnston , tibshirani ( 2004 ) , or the smoothly clipped absolute deviation ( scad ) estimator of fan and li ( 2001 ) .",
    "other estimators that fit into this framework are hard- and soft - thresholding estimators .",
    "while many properties of penalized maximum likelihood estimators are now well understood , the understanding of their distributional properties , such as finite - sample and large - sample limit distributions , is still incomplete .",
    "the probably most important contribution in this respect is knight and fu ( 2000 ) who study the asymptotic distribution of the lasso estimator ( and of bridge estimators more generally ) when the tuning parameter governing the influence of the penalty term is chosen so that the lasso acts as a conservative model selection procedure ( that is , a procedure that does not select underparameterized models asymptotically , but selects overparameterized models with positive probability asymptotically ) ; see also knight ( 2008 ) . in knight and fu ( 2000 ) ,",
    "the asymptotic distribution is obtained in a fixed - parameter as well as in a standard local alternatives setup .",
    "this is complemented by a result in zou ( 2006 ) who considers the fixed - parameter asymptotic distribution of the lasso when tuned to act as a consistent model selection procedure .",
    "another contribution is fan and li ( 2001 ) who derive the asymptotic distribution of the scad estimator when the tuning parameter is chosen so that the scad estimator performs consistent model selection ; in particular , they establish the so - called ` oracle ' property for this estimator .",
    "the results in that latter paper are also fixed - parameter asymptotic results .",
    "it is well - known that fixed - parameter ( i.e. , pointwise ) asymptotic results can give a wrong picture of the estimators actual behavior , especially when the estimator performs model selection ; see , e.g. , kabaila ( 1995 ) , or leeb and ptscher ( 2005 , 2008a ) .",
    "therefore , it is interesting to take a closer look at the actual distributional properties of such estimators .    in the present paper",
    "we study the finite - sample as well as the asymptotic distributions of the hard - thresholding , the lasso ( which coincides with soft - thresholding in our context ) , and the scad estimator .",
    "we choose a model that is simple enough to facilitate an explicit finite - sample analysis that showcases the strengths and weaknesses of these estimators in a readily accessible framework .",
    "yet , the model considered here is rich enough to demonstrate a variety of phenomena that will also occur in more complex models .",
    "we study both the cases where the estimators are tuned to perform conservative model selection as well as where the tuning is such that the estimators perform consistent model selection .",
    "we find that the finite - sample distributions can be decisively non - normal ( e.g. , multimodal ) .",
    "moreover , we find that a fixed - parameter asymptotic analysis gives highly misleading results . in particular , the ` oracle ' property , which is based on a fixed - parameter asymptotic analysis , is shown to not provide a reliable assessment of the estimators actual performance .",
    "for these reasons , we also obtain the asymptotic distributions of the estimators mentioned before in a general ` moving parameter ' asymptotic framework , which better captures essential features of the finite - sample distribution .",
    "[ interestingly , it turns out that in the consistent model selection case a ` moving parameter ' asymptotic framework more general than the usual @xmath0-local asymptotic framework is necessary to exhibit the full range of possible limiting distributions . ]",
    "furthermore , we derive the uniform convergence rate of the estimators and show that it is slower than @xmath0 in the case where the estimators are tuned to perform consistent model selection .",
    "this again exposes the misleading character of the ` oracle ' property .",
    "we also show that the finite - sample distribution of these estimators can not be estimated in any reasonable sense , complementing results of this sort in the literature ( leeb and ptscher ( 2006a , b , 2008b ) , ptscher ( 2006 ) ) . in a subsequent paper , ptscher and schneider ( 2009 ) ,",
    "analogous results are obtained for the adaptive lasso estimator .",
    "we note that penalized maximum likelihood estimators are intimately related to more classical post - model - selection estimators .",
    "the distributional properties of the latter estimators have been studied by sen ( 1979 ) , ptscher ( 1991 ) , and leeb and ptscher ( 2003 , 2005 , 2006a , b , 2008b ) .",
    "the paper is organized as follows : the model and the estimators are introduced in section [ mo_est ] , and the model selection probabilities are discussed in section [ prob ] .",
    "consistency , uniform consistency , and uniform convergence rates of the estimators are the subject of section cons&ucons .",
    "the finite - sample distributions are derived in section finite , whereas the asymptotic distributions are studied in section asydistribs .",
    "section [ imposs ] provides impossibility results concerning the estimation of the finite - sample distributions of the estimators , and section  [ conclusion ] concludes and summarizes our main findings .",
    "the appendix contains results on the asymptotic distribution in the consistent model selection case when the estimators are scaled by the inverse of the uniform convergence rate obtained in section [ cons&ucons ] rather than by @xmath1 .",
    "we start with the orthogonal linear regression model@xmath2where @xmath3 is diagonal and the vector @xmath4 is multivariate normal with mean zero and variance covariance matrix @xmath5 . the multivariate linear model with orthogonal design occurs in many important settings , including wavelet regression or the analysis of variance .",
    "because we consider penalized least - squares estimators with a penalty term that is separable with respect to @xmath6 , the resulting estimators for the components of @xmath6 are mutually independent and each component estimator is equivalent to the corresponding penalized least squares estimator in a univariate gaussian location model . we therefore restrict attention to this simple model in the sequel without loss of generality .",
    "suppose @xmath7 are independent and each distributed as @xmath8 .",
    "we assume for simplicity that @xmath9 is known , and hence we can set @xmath10 without loss of generality .",
    "apart from the standard maximum likelihood ( least squares ) estimator @xmath11 we consider the following estimators :    1 .   the hard - thresholding estimator @xmath12 where the threshold @xmath13 is a positive real number and @xmath14 denotes the indicator function .",
    "the threshold @xmath13 is a tuning parameter set by the user .",
    "the hard - thresholding estimator can be viewed as a penalized least - squares estimator that arises as the solution to the minimization problem @xmath15we also note here that for @xmath16 the hard - thresholding estimator is a simple instance of hodges estimator ( see , e.g. , lehmann and casella ( 1998 ) , pp .",
    "440 - 443 ) .",
    "2 .   the soft - thresholding estimator @xmath17 with @xmath13 as before . [ here",
    "@xmath18 is defined as @xmath19 , @xmath20 , and @xmath21 in case @xmath22 , @xmath23 , and @xmath24 , respectively , and @xmath25 is shorthand for @xmath26 . ]",
    "that estimator arises as the solution to the penalized least - squares problem@xmath27which shows that @xmath28 coincides with the lasso in the form considered in knight and fu ( 2000 ) . note that the tuning parameter in the latter reference is @xmath29 .",
    "the scad - estimator of fan and li ( 2001 ) is  in the present context",
    " given by @xmath30where @xmath31 is an additional tuning parameter .",
    "this estimator can be viewed as a simple combination of soft - thresholding for ` small ' @xmath32 and hard - thresholding for ` large ' @xmath32 , with a ( piecewise ) linear interpolation in - between .",
    "alternatively , the estimator can also be obtained as a solution to a penalized least squares problem ; see fan and li ( 2001 ) for details .",
    "we note that the scad - estimator is closely related to the firm shrinkage estimator of bruce and gao ( 1996 ) .",
    "each of the three estimators discussed above induces a selection between the restricted model @xmath33 consisting only of the @xmath34-distribution and the unrestricted model @xmath35 in an obvious way , i.e. , @xmath33 is selected if the respective estimator for @xmath36 equals zero , and @xmath37 is selected otherwise . in the present context ,",
    "the hard - thresholding estimator @xmath38 is furthermore nothing else than a traditional pre - test estimator that chooses between the unrestricted maximum likelihood estimator @xmath39 and the restricted maximum likelihood estimator @xmath40 according to the outcome of a @xmath41-type test for the hypothesis @xmath42 .",
    "we now study the model selection probabilities , i.e. , the probabilities that model @xmath37 or @xmath33 , respectively , is selected . as they add up to one , it suffices to consider one of them .",
    "first note that the probability  of selecting the model @xmath33 is the same for each of the estimators @xmath43 , @xmath28 , and @xmath44 ( provided the same tuning parameter @xmath13 is used ) .",
    "this is so because the events @xmath45 , @xmath46 , and @xmath47 coincide .",
    "hence , @xmath48where @xmath49 stands for any of the estimators @xmath38 , @xmath50 , and @xmath44 , and where @xmath51 is a standard normal random variable with cumulative distribution function ( cdf ) @xmath52 . here",
    "we use @xmath53 to denote the probability governing a sample of size @xmath54 when @xmath55 is the true parameter , and @xmath56 to denote a generic probability measure .    in the following",
    "we shall always impose the condition that @xmath57 for asymptotic considerations , which guarantees that the probability of incorrectly selecting the restricted model @xmath33 ( i.e. , selecting @xmath33 if the true @xmath55 is non - zero ) vanishes asymptotically .",
    "conversely , if this probability vanishes asymptotically for _ every _",
    "@xmath58 , then @xmath59 follows .",
    "therefore , the condition @xmath59 is a basic one and without this condition the estimators @xmath38 , @xmath28 , and @xmath60 do not seem to be of much interest ( from an asymptotic viewpoint ) . as we shall see in the next section , this basic condition is also equivalent to consistency for @xmath55 of the hard - thresholding ( soft - thresholding , scad ) estimator .",
    "given the condition @xmath59 , two cases need to be distinguished : ( i ) @xmath61 , @xmath62 and ( ii ) @xmath63 .",
    "holds can always be reduced to case ( i ) or case ( ii ) by passing to subsequences . ] in case ( i ) the hard - thresholding ( soft - thresholding , scad ) estimator acts as a conservative model selection procedure , i.e. , the probability of selecting the unrestricted model @xmath37 has a positive limit even when @xmath42 , whereas in case ( ii ) it acts as a consistent model selection procedure , i.e. , this probability vanishes in the limit when @xmath42 .",
    "this is immediately seen by inspection of ( model_prob ) .",
    "these facts have long been known , see bauer , ptscher , and hackl ( 1988 ) .",
    "the results discussed in the preceding paragraph are of a ` pointwise ' asymptotic nature in the sense that the value of @xmath55 is held fixed when sample size @xmath54 goes to infinity . as noted before ,",
    "such pointwise asymptotic results often miss essential aspects of the finite - sample behavior , especially in the context of model selection ; cf . leeb and ptscher ( 2005 )",
    ". to obtain large - sample results that better capture finite - sample phenomena",
    ", we next present a ` moving parameter ' asymptotic analysis , i.e. , we allow @xmath55 to vary with @xmath54 as @xmath64 .",
    "the following result shows in particular that convergence of the model selection probability to its limit in a pointwise asymptotic analysis is _ not _ uniform in @xmath65 ( in fact , it fails to be uniform in any neighborhood of @xmath42 ) .",
    "[ selection_prob]let @xmath49 be either @xmath38 , @xmath66 , or @xmath44 .",
    "suppose that @xmath59 and @xmath61 with @xmath67 .",
    "( i ) assume @xmath68 ( corresponding to conservative model selection ) .",
    "suppose the true parameter @xmath69 satisfies @xmath70",
    ". then @xmath71(ii ) assume @xmath72 ( corresponding to consistent model selection ) .",
    "suppose @xmath73 satisfies @xmath74",
    ". then    1 .",
    "@xmath75 implies @xmath76 ; 2 .",
    "@xmath77 and @xmath78 for some @xmath79 , implies @xmath80 ; 3 .",
    "@xmath81 implies @xmath82 .",
    "the proof of part ( i ) is immediate from ( [ model_prob ] ) . to prove part ( ii ) we use ( [ model_prob ] ) to rewrite @xmath83 as @xmath84the first and the third claim follow immediately from this .",
    "for the second claim , assume first that @xmath85 .",
    "then @xmath86 obviously converges to @xmath87 , whereas @xmath88 converges to zero .",
    "the case @xmath89 is handled similarly .",
    "proposition  [ selection_prob ] in fact completely describes the large - sample behavior of the model selection probability without _ any _ conditions on the parameter @xmath55 , in the sense that all possible accumulation points of the model selection probability along _ arbitrary _ sequences of @xmath90 can be obtained in the following manner : just apply the result to subsequences and note that , by compactness of @xmath91 , we can select from each subsequence a further subsequence such that all relevant quantities such as @xmath92 , @xmath93 , @xmath94 , or @xmath95 converge in @xmath96 along this further subsequence .    in the conservative model selection case",
    "we see from proposition selection_prob that the usual local alternative parameter sequences describe the asymptotic behavior . in particular , if @xmath90 is local to @xmath42 in the sense that @xmath97 , the local alternatives parameter @xmath98 governs the limiting model selection probability .",
    "deviations of @xmath90 from @xmath42 of order @xmath99 are detected with positive probability asymptotically and deviations of larger order are detected with probability one asymptotically in this case . in the consistent model selection case , however , a different picture emerges . here , proposition [ selection_prob ] shows that local deviations of @xmath90 from @xmath42 that are of the order @xmath99 are not detected by the model selection procedures at all !",
    "in fact , even larger deviations of @xmath55 from zero go asymptotically unnoticed by the model selection procedure , namely as long as @xmath100 , @xmath75 .",
    "[ note that these larger deviations would be picked up by a _ conservative _ procedure with probability one asymptotically .",
    "] this unpleasant consequence of model selection consistency has a number of repercussions as we shall see later on .",
    "for a more detailed discussion of these phenomena in the context of post - model - selection estimators see leeb and ptscher ( 2005 ) .",
    "the speed of convergence of the model selection probability to its limit in part ( i ) of the proposition is governed by the slower of the convergence speeds of @xmath101 and @xmath102 . in part ( ii ) it is exponential in @xmath101 in cases 1 and 3 , and is governed by the convergence speed of @xmath101 and @xmath103 in case 2 .",
    "it is easy to see that the basic condition @xmath59 discussed in the preceding section is in fact also equivalent to consistency of @xmath38 for @xmath55 , i.e. , to @xmath107the same is also true for @xmath28 and @xmath44 , as is elementary to verify .",
    "[ at least the sufficiency parts are well - known , see ptscher ( 1991 ) for hard - thresholding , knight and fu ( 2000 ) for soft - thresholding , and fan and li ( 2001 ) for scad . ] in fact , under this basic condition on @xmath13 , the estimators are even uniformly consistent with a certain rate as we show next :    [ unif_cons]assume @xmath59 .",
    "let @xmath49 stand for either @xmath38 , @xmath28 , or @xmath44 .",
    "then @xmath49 is uniformly consistent , i.e. , @xmath108 in fact , the supremum in the above expression converges to zero exponentially fast for every @xmath109 .",
    "furthermore , set @xmath110",
    ". then for every @xmath109 there exists a ( nonnegative ) real number @xmath111 such that@xmath112holds .",
    "in particular , @xmath49 is uniformly @xmath113-consistent .",
    "we begin with proving uniform consistency of @xmath114 .",
    "observe that @xmath115 can be written as @xmath116where @xmath51 is standard normally distributed .",
    "now the first term on the far r.h.s . in the above display obviously converges to zero exponentially fast as @xmath64 . in the second term on the far right",
    ", the probability gets large as @xmath117 gets close to @xmath118 .",
    "therefore , the second term on the far r.h.s . equals @xmath119and also goes to zero exponentially fast because @xmath59 .",
    "next , for the soft - thresholding estimator , observe that we have the relation@xmath120consequently , @xmath121which equals zero for sufficiently large @xmath54 .",
    "hence , the results established so far for @xmath38 carry over to @xmath28 .    for the scad estimator observe that it is ` sandwiched ' between the other two in the sense that @xmath122holds if @xmath123 , and that the order is reversed if @xmath124 .",
    "this entails the corresponding result for the scadestimator .",
    "we next prove uniform @xmath125-consistency of @xmath38 : repeating the arguments from the beginning of the proof with @xmath126 replacing @xmath127 , we see that @xmath128 is bounded from above by @xmath129because @xmath130 , the first term on the right - hand side of the above expression is not larger than @xmath131 .",
    "the second term equals@xmath132note",
    "that @xmath130 and @xmath133 . for @xmath134 , the expression in the above display is therefore not larger than @xmath135 .",
    "uniform @xmath125-consistency of @xmath38 follows from this .",
    "the proof for @xmath28 and @xmath44 is then similar as before .",
    "for the case where the estimators @xmath38 , @xmath28 , and @xmath44 are tuned to perform conservative model selection , the preceding theorem shows that these estimators are uniformly @xmath1-consistent .",
    "in contrast , in case the estimators are tuned to perform consistent model selection , the theorem only guarantees uniform @xmath136-consistency ; that the estimators do actually not converge faster than @xmath13 in a uniform sense in this case will be shown in section [ sec_consist ] .",
    "[ r1]let @xmath49 denote any one of the estimators @xmath137 , @xmath28 , or @xmath44 . in case",
    "@xmath138 it is easy to see that @xmath49 is uniformly asymptotically equivalent to @xmath39 in the sense that @xmath139 for every @xmath109 .",
    "[ for @xmath140 , this follows easily from proposition [ selection_prob ] , for @xmath141 it follows then from ( [ hard - soft ] ) , and for @xmath142 from ( [ sandwich ] ) . ]",
    "for purpose of comparison we note the obvious fact that the distribution of the unrestricted maximum likelihood estimator @xmath39(corresponding to model @xmath37 ) as well as the distribution of the restricted maximum likelihood estimator @xmath40 ( corresponding to model @xmath33 ) are normal ; more precisely , @xmath146 is @xmath34-distributed and @xmath147 is @xmath148-distributed , where the singular normal distribution is to be interpreted as pointmass at @xmath149 . for the hard - thresholding estimator ,",
    "the finite - sample distribution @xmath150 of @xmath151 is of the form@xmath152where @xmath153 denotes pointmass at @xmath154 and @xmath155 denotes the standard normal density . relation ( [ distri_h ] ) is most easily obtained by writing @xmath156 as the sum of @xmath157 and @xmath158 .",
    "this also shows that the two terms in ( [ distri_h ] ) correspond to the distribution of @xmath151 conditional on the events @xmath159 and @xmath160 , respectively , multiplied by the probability of the respective events .",
    "relation ( [ distri_h ] ) also follows as a special case of leeb and ptscher ( 2003 ) , which provides the finite - sample as well as the asymptotic distributions of a general class of post - model - selection estimators .",
    "we recognize that the distribution of the hard - thresholding estimator is a mixture of two components : the first one is a singular normal distribution ( i.e. , pointmass ) and coincides with the distribution of the restricted maximum likelihood estimator .",
    "the second one is absolutely continuous and represents an ` excised ' version of the normal distribution of the unrestricted maximum likelihood estimator .",
    "note that the absolutely continuous part in ( [ distri_h ] ) is bimodal and hence is distinctly non - normal .",
    "the shape of the distribution of @xmath161 is exemplified in figure  1 .",
    "c    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ figure  1 : distribution of @xmath151 for @xmath162 , @xmath163 , and @xmath164 .",
    "the density of the absolutely continuous part is shown by the solid curve , which is discontinuous at @xmath165 and @xmath166 .",
    "[ for better readability , the left- and right - hand limits at discontinuity points are joined by line segments . ]",
    "the vertical dotted line indicates the location of the point - mass at @xmath149 ; the weight of the point - mass , i.e. , the multiplier of @xmath167 in ( [ distri_h ] ) , equals @xmath168 . for other values of the constants involved here ,",
    "a similar picture is obtained . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the finite - sample distribution @xmath169 of @xmath170 is given by@xmath171for later use we note that this implies@xmath172relation ( [ distri_s ] ) is obtained from a derivation similar to that of ( [ distri_h ] ) , namely by representing @xmath173 as the sum of @xmath174 , @xmath175 , and @xmath176 .",
    "similar to before , the three terms in ( [ distri_s ] ) correspond to the distributions of @xmath177 conditional on the events @xmath46 , @xmath178 , and @xmath179 , respectively , multiplied by the respective probabilities of these events .",
    "the distribution in ( [ distri_s ] ) is again a mixture of a singular normal distribution and of an absolutely continuous part , which is now the sum of two normal densities , each with a truncated tail .",
    "figure  2 exemplifies a typical shape of this distribution .",
    "c    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ figure  2 : distribution of @xmath180 .",
    "the choice of constants and the interpretation of the image is the same as in figure  1 . _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    the finite - sample distribution of the scad - estimator is obtained in a similar vein : decomposing the probability @xmath181 into a sum of seven terms by decomposing the relevant event into its intersection with the events @xmath182 , @xmath183 , @xmath184 , @xmath185 , @xmath186 , @xmath187 , and @xmath188 , shows that the distribution @xmath189 of @xmath190 is of the form@xmath191where @xmath192and where @xmath193 , @xmath194 , and @xmath195 are defined as @xmath196 , @xmath197 , and @xmath198 , respectively , but with @xmath199 replacing @xmath200 and with @xmath201 replacing @xmath55 in the formulae . like in the case of the other estimators ,",
    "the distribution of the scad - estimator is a mixture of a singular normal distribution and an absolutely continuous part , the latter being more complicated here as it is the sum of six pieces , each obtained from normal distributions by truncation or excision .",
    "as shown in figure  3 , the absolutely continuous part of @xmath202 can be multimodal .",
    "c    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ figure  3 : distribution of @xmath190 .",
    "the tuning - parameter @xmath203 is chosen as @xmath204 here , cf . fan and li ( 2001 ) ; the choice of the other constants and the interpretation of the image is the same as in figure  1 .",
    "the graph for the scad estimator coincides with that for the soft - thresholding estimator inside a neighborhood of the location of the atomic part at @xmath149 ( vertical dotted line ) , and with that for the hard - thresholding estimator outside of a ( larger ) neighborhood of @xmath205 .",
    "the area between these two regions corresponds to the dips shown in the figure .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    in summary , we see that the finite - sample distributions of the estimators @xmath137 , @xmath28 , and @xmath44 are typically highly non - normal and can be multimodal . as a point of interest , we also note that the computations leading to the above formulae also deliver the conditional finite - sample distributions of the estimators @xmath43 , @xmath28 , and @xmath44 , respectively , conditional on selecting model @xmath33 or @xmath37 .",
    "in particular , we note that the conditional distribution of each of these estimators , conditional on having selected the restricted model @xmath33 , coincides with the distribution of the restricted maximum likelihood estimator @xmath206 ; in contrast , conditional on selecting the unrestricted model @xmath37 , the conditional distribution is not identical to the distribution of the unrestricted maximum likelihood estimator @xmath207 , but is more complicated .",
    "this phenomenon applies also to large classes of post - model - selection estimators ; see ptscher ( 1991 ) and leeb and ptscher ( 2003 ) for more discussion .",
    "we next obtain the asymptotic distributions of @xmath38 , @xmath66 , and @xmath44 .",
    "we present the asymptotic distributional results under general ` moving parameter ' asymptotics , where the true parameter @xmath90 can depend on sample size , because considering only fixed - parameter asymptotics may paint a quite misleading picture of the behavior of the estimators ( cf .",
    "leeb and ptscher ( 2003 , 2005 ) ) .",
    "in fact , the results given below amount to a complete description of all possible accumulation points of the finite - sample distributions of the estimators in question , cf .",
    "remarks [ rxx ] and [ rxxx ] . not surprisingly , the results in the conservative model selection case are different from the ones in the consistent model selection case .      here",
    "we characterize the large - sample behavior of the distributions of @xmath43 , @xmath28 , and @xmath44 for the case where these estimators are tuned to perform conservative model selection .",
    "[ h_conserv ] consider the hard - thresholding estimator with @xmath57 and @xmath61 , @xmath62 .",
    "suppose the true parameter @xmath69 satisfies @xmath70 .",
    "then @xmath208 converges weakly to the distribution given by@xmath209[note that ( [ asydistr_h_conserv ] ) reduces to a standard normal distribution in case @xmath210 or @xmath211 . ]",
    "is essentially a special case of results obtained in leeb and ptscher ( 2003 ) for a more general class of post - model - selection estimators .",
    "the proof of this result is included here because of its brevity and illustrative value . ]",
    "recall that the finite - sample distribution is given in ( [ distri_h ] ) .",
    "convergence of the weights @xmath212 to @xmath213 is obvious ( cf .",
    "proof of proposition 1 ) .",
    "hence , the atomic part of @xmath208 converges weakly to the atomic part of ( [ asydistr_h_conserv ] ) if @xmath214 and @xmath215 ; if @xmath216 or if @xmath211 , the total mass of the atomic part converges to zero . the density of the absolutely continuous part of @xmath208 is easily seen to converge lebesgue almost everywhere ( in fact everywhere on @xmath217 except possibly at @xmath218 ) to the density of the absolutely continuous part of ( [ asydistr_h_conserv ] ) .",
    "also the total mass of the absolutely continuous part is seen to converge to the total mass of the absolutely continuous part of ( [ asydistr_h_conserv ] ) . by an application of scheff s lemma ,",
    "the densities converge in absolute mean , and hence the absolutely continuous part converges in the total variation sense .    the fixed - parameter asymptotic distribution is obtained from theorem  h_conserv by letting @xmath219 : if @xmath42 , the pointwise asymptotic distribution of the hard - thresholding estimator is seen to be @xmath220which coincides with the finite - sample distribution ( [ distri_h ] ) in this case except for replacing @xmath101 by its limiting value @xmath221 . however , if @xmath58 , the pointwise asymptotic distribution is always standard normal , which clearly misrepresents the actual distribution ( distri_h ) .",
    "this disagreement is most pronounced in the statistically interesting case where @xmath55 is close to , but not equal to , zero ( e.g. , @xmath222 ) .",
    "in contrast , the distribution ( asydistr_h_conserv ) much better captures the behavior of the finite - sample distribution also in this case because ( [ asydistr_h_conserv ] ) coincides with ( [ distri_h ] ) except for the fact that @xmath101 and @xmath92 have settled down to their limiting values .",
    "[ s_conserv ] consider the soft - thresholding estimator with @xmath57 and @xmath61 , @xmath62 .",
    "suppose the true parameter @xmath69 satisfies @xmath70 .",
    "then @xmath223 converges weakly to the distribution given by@xmath224[note that ( [ asydistr_s_conserv ] ) reduces to a @xmath225-distribution in case @xmath216 or @xmath211 . ]",
    "the proof is completely analogous to the proof of theorem [ h_conserv ] .",
    "since soft - thresholding arises as a special case of the lasso - estimator , the above result is closely related to the results in knight and fu ( 2000 ) .",
    "similar to the case of hard - thresholding , a fixed - parameter asymptotic analysis only partially reflects the finite - sample behavior of the estimator : in case @xmath42 , the pointwise asymptotic distribution is @xmath226however , if @xmath58 , the pointwise limit distribution is @xmath227 , which is not in good agreement with the finite - sample distribution ( [ distri_s ] ) , especially in the statistically interesting case where @xmath55 is close to , but not equal to , zero ( e.g. , @xmath222 ) .",
    "in contrast , ( [ asydistr_s_conserv ] ) is in better agreement with ( [ distri_s ] ) also in this case in the sense that ( asydistr_s_conserv ) coincides with ( [ distri_s ] ) , except that @xmath228 and @xmath102 have settled down to their limiting values .",
    "[ scad_conser ] consider the scad estimator with @xmath59 and @xmath61 , @xmath62 .",
    "suppose the true parameter @xmath69 satisfies @xmath229 .",
    "then @xmath230 converges weakly to the distribution given by@xmath231[note that ( [ asydistr_scad_conserv ] ) reduces to a standard normal distribution in case @xmath216 or @xmath211 . ]",
    "the proof of theorem  [ scad_conser ] is again completely analogous to that of theorem [ h_conserv ] . as with the hard- and soft - thresholding estimators discussed before , a fixed - parameter asymptotic analysis of the scad estimator",
    "only partially reflects its finite - sample behavior : in case @xmath232 , the pointwise asymptotic distribution is given by ( asydistr_scad_conserv ) with @xmath233 , but in case @xmath58 it is given by @xmath34 , which is definitely not in good agreement with the finite - sample distribution ( [ distri_scad ] ) , especially in the statistically interesting case where @xmath55 is different from , but close to , zero , e.g. , @xmath234 .",
    "in contrast , ( asydistr_scad_conserv ) is in much better agreement with ( [ distri_scad ] ) in view of the fact that ( [ asydistr_scad_conserv ] ) coincides with ( distri_scad ) , except that @xmath101 and @xmath102 have settled down to their limiting values .",
    "we note that the mathematical reason for the failure of the pointwise asymptotic distribution to capture the behavior of the finite - sample distribution well is that the convergence of the latter to the former is not uniform in the underlying parameter @xmath55 .",
    "see leeb and ptscher ( 2003 , 2005 ) for more discussion in the context of post - model - selection estimators .",
    "[ rx ] if @xmath216 , or @xmath211 , or @xmath235 does not depend on @xmath54 , the convergence in the above three theorems is even in the total variation distance . in the first two cases this follows because the total mass of the atomic part converges to zero ; in the third case it follows because the location of the pointmass is independent of @xmath54 .",
    "[ rxx ] the above theorems actually completely describe the limiting behavior of the finite - sample distributions of @xmath38 , @xmath50 , and @xmath44 without _ any _ condition on the sequence of parameters @xmath90 . to see this , just apply the theorems to subsequences and note that by compactness of @xmath236 we can select from every subsequence a further subsequence such that @xmath102 converges in @xmath236 along this further subsequence .      in the case where the estimators @xmath38 , @xmath28 , and @xmath44 are tuned to perform consistent model selection",
    "( i.e. , @xmath59 and @xmath237 ) , the _ fixed - parameter _ limiting behavior of the finite - sample distributions is particularly simple : the finite - sample distribution of the hard - thresholding estimator converges to the @xmath238-distribution ( i.e. , to pointmass at @xmath20 ) if @xmath42 , and to the @xmath34-distribution if @xmath239 ; cf .",
    "lemma  1 in ptscher ( 1991 ) . in other words ,",
    "the pointwise asymptotic distribution of @xmath151 coincides with the asymptotic distribution of the restricted maximum likelihood estimator if @xmath42 , and coincides with the asymptotic distribution of the unrestricted maximum likelihood estimator if @xmath240 .",
    "the hard - thresholding estimator , when tuned in this way , therefore satisfies what has sometimes been dubbed the ` oracle ' property in the literature .",
    "the scad - estimator with the same tuning is also known to possess the ` oracle ' property ; cf .",
    "fan and li ( 2001 ) . with the same tuning ,",
    "the soft - thresholding has a somewhat different pointwise asymptotic behavior which is discussed later .",
    "the ` oracle ' property of the hard - thresholding estimator and the scad - estimator implies in particular that both estimators are @xmath1-consistent .",
    "in theorem [ unif_cons ] , however , we have  in contrast to the conservative model selection case  only been able to establish uniform @xmath241-consistency and not uniform @xmath1-consistency .",
    "this begs the question whether theorem [ unif_cons ] is just not sharp enough or whether the estimators actually are not uniformly @xmath1-consistent .",
    "it furthermore raises the question of the behavior of the finite - sample distributions of @xmath151 , @xmath170 , and @xmath190 in a ` uniform ' asymptotic framework .",
    "the three results that follow answer this by determining the limits of the finite - sample distributions of @xmath242 , @xmath28 , and @xmath44 under general ` moving parameter ' asymptotics when the estimators are tuned to perform consistent model selection .",
    "[ h_consist ] consider the hard - thresholding estimator with @xmath57 and @xmath237 .",
    "assume that @xmath243 for some @xmath244 and that @xmath245 for some @xmath246 .",
    "[ note that in case @xmath247 the convergence of @xmath102 already follows from that of @xmath93 , and @xmath98 is then given by @xmath248 . ]    1 .   if @xmath249 , then @xmath208 approaches pointmass at @xmath250 . in case @xmath251",
    ", this means that @xmath208 converges weakly to pointmass at @xmath252 ; in case @xmath253 , this means that the total mass of @xmath208 escapes to @xmath252 , in the sense that @xmath254 for every @xmath255 if @xmath256 , and @xmath257 for every @xmath258 if @xmath259 .",
    "if @xmath260 and @xmath78 for some @xmath79 , then @xmath261 converges to@xmath262for every @xmath263 .",
    "this limit corresponds to pointmass at @xmath264 if @xmath265 , and otherwise represents a convex combination of pointmass at @xmath266 and an absolutely continuous distribution whose density , a kind of truncated standard normal , is given by @xmath267 times the integrand in the above formula ; the weights in that convex combination are given by @xmath268 and @xmath269 , respectively .",
    "[ the weight of the absolutely continuous component equals one in case @xmath270 ; in this case , convergence is in fact in total variation distance . ]",
    "if @xmath271 , then @xmath272 converges weakly to @xmath52 , the standard normal cdf .",
    "[ in fact , convergence is in total variation distance . ]",
    "proposition [ selection_prob ] shows that the total mass of the atomic part of @xmath208 converges to one under the conditions of part  1 .",
    "because the atomic part is located at @xmath273 in view of ( [ distri_h ] ) , part  1 follows immediately .    for part 2 ,",
    "assume first that @xmath274 .",
    "proposition [ selection_prob ] shows that the total mass of the atomic part of @xmath208 converges to @xmath268 .",
    "furthermore , @xmath275 certainly holds , which implies that the atomic part escapes to @xmath276 .",
    "if @xmath265 , we are hence done .",
    "suppose now that @xmath277 . in ( distri_h ) , the boundaries of the ` excision interval ' of the absolutely continuous part of @xmath208 , i.e. , @xmath278 and @xmath279 then converge to @xmath276 and @xmath280 , respectively .",
    "this shows that @xmath281for lebesgue almost every @xmath263 .",
    "the dominated convergence theorem then shows that the convergence in the above display also holds in absolute mean .",
    "this completes the proof of part 2 in case @xmath274 .",
    "the case where @xmath282 is treated similarly .    under the conditions of part 3 ,",
    "proposition [ selection_prob ] shows that the total mass of the absolutely continuous part converges to one .",
    "furthermore , the boundaries of the ` excision interval ' in ( [ distri_h ] ) , i.e. , @xmath283 and @xmath284 , diverge either both to @xmath285 or both to @xmath276 , because @xmath286 .",
    "this implies that@xmath287for every @xmath263 .",
    "together with the dominated convergence theorem this completes the proof .",
    "the fixed - parameter asymptotic behavior of the hard - thresholding estimator discussed earlier , including the ` oracle ' property , can clearly be recovered from the above theorem by setting @xmath219 .",
    "however , the theorem shows that the asymptotic behavior of the hard - thresholding estimator is more complicated than what the ` oracle ' property predicts .",
    "in particular , the theorem shows that the hard - thresholding estimator is not uniformly @xmath1-consistent as the sequence of finite - sample distributions is not stochastically bounded in all cases .",
    "[ in that sense scaling by @xmath1 does not appear to be the natural thing to do , see the discussion below as well as the appendix .",
    "] furthermore , as shown by ( distri_h ) , the finite - sample distribution is highly non - normal , whereas the _ pointwise _ asymptotic distribution is always normal and thus can not capture essential features of the finite - sample distribution .",
    "in contrast , the asymptotic distribution given in theorem [ h_consist ] is also non - normal in some cases .",
    "all this goes to show that the ` oracle ' property , which is based on the pointwise asymptotic distribution only , paints a highly misleading picture of the behavior of the hard - thresholding estimator and should not be taken at face value . a result for a certain post - model - selection estimator that is related to theorem h_consist above",
    "can be found in appendix a of leeb and ptscher ( 2005 ) .",
    "[ s_consist ] consider the soft - thresholding estimator with @xmath57 and @xmath237 .",
    "assume that @xmath70 .",
    "then @xmath223 approaches pointmass at @xmath252 . in case",
    "latexmath:[$|\\nu    weakly to pointmass at @xmath252 ; in case @xmath253 , it means that the total mass of @xmath223 escapes to @xmath252 , in the sense that @xmath289 for every @xmath263 if @xmath290 , and @xmath291 for every @xmath255 if @xmath259 .    from ( [ distri_s_1 ] )",
    "we have that @xmath292 for @xmath293 and @xmath294 for @xmath295 . because @xmath296 , this entails that @xmath297 converges to one for each @xmath298 and to zero for each @xmath299 .",
    "the fixed - parameter asymptotic distribution of the soft - thresholding estimator is obtained by setting @xmath219 in the above theorem : it is @xmath238 ( i.e. , pointmass at @xmath20 ) if @xmath42 ; if @xmath240 the total mass of the finite - sample distribution escapes to @xmath300 .",
    "hence , the soft - thresholding estimator when tuned to act as a consistent model selector is not even pointwise @xmath301-consistent ( zou ( 2006 ) ) and certainly does not satisfy the ` oracle ' property .",
    "[ this contradicts an incorrect claim in zhao and yu ( 2006 , section 2.1 ) to the effect that tuning lasso to act as a consistent model selector results in an asymptotically normal estimator . ] the fact that this estimator is not pointwise @xmath1-consistent also suggest studying the asymptotic distribution under a scaling that increases slower than @xmath1 , an issue that we take up further below ; cf .",
    "also the appendix .",
    "[ scad_consist ] consider the scad estimator with @xmath302 and @xmath237 .",
    "assume that @xmath303 for some @xmath304 and that @xmath245 for some @xmath305 .",
    "[ note that in case @xmath306 the convergence of @xmath102 already follows from that of @xmath307 , and @xmath98 is then given by @xmath308 . ]    1 .",
    "if @xmath309 , or if @xmath310 and @xmath311 , then @xmath312 approaches pointmass at @xmath252 . in case @xmath251",
    ", this means that @xmath230 converges weakly to pointmass at @xmath252 ; in case latexmath:[$%",
    "@xmath312 escapes to @xmath252 , in the sense that @xmath314 for every @xmath263 if @xmath256 , and @xmath315 for every @xmath263 if @xmath259 .",
    "if @xmath310 and @xmath316 for some @xmath317 , then @xmath318 converges to@xmath319for every @xmath263 , with the convention that the integral over the first term in the above expression is zero if @xmath270 .",
    "[ in fact , convergence is in total variation distance . ]",
    "if @xmath320 , then @xmath312 converges weakly to the standard normal distribution @xmath34 .",
    "[ in fact , convergence is in total variation distance . ]    for each @xmath55 , the cdf @xmath202 consists of contributions from the atomic part and from the absolutely continuous part .",
    "the contribution of the absolutely continuous part can be further broken down into the contributions from the integrands @xmath321 , @xmath322 , @xmath323 , @xmath324 , @xmath325 , and @xmath326 in view of ( [ distri_scad ] ) .",
    "we hence may write @xmath327where @xmath328 denotes the contribution of the atomic part , and where the remaining terms on the right - hand side denote the contributions corresponding to @xmath321 , @xmath322 , @xmath323 , @xmath329 , @xmath325 , and @xmath326 , respectively ; e.g. , @xmath330 .",
    "now @xmath331 can be written as @xmath332[use the formula for @xmath333 given after ( [ distri_scad ] ) with @xmath334 in place of @xmath55 , and perform a simple change of variables .",
    "] by a similar argument , we also have @xmath335and @xmath336 .",
    "assume first that @xmath337 .",
    "in the subcase @xmath338 , proposition [ selection_prob ] shows that the total mass of the atomic part of @xmath312 converges to one , and the statement in part 1 then follows , since @xmath245 . for the remaining subcases to be considered",
    "observe that we have @xmath339 whenever @xmath340 .",
    "for the subcase @xmath274 , assume for now also that @xmath341 .",
    "then the atomic part of @xmath230 escapes to @xmath259 , and the total mass of the atomic part converges to @xmath268 by proposition  [ selection_prob ] . in other words ,",
    "@xmath342 for each @xmath343 , where @xmath344 denotes the contribution from the atomic part of @xmath312 .",
    "moreover , from the preceding formula for @xmath331 , it is evident that @xmath345 holds for each @xmath258 ( because the upper limit in the integral diverges to @xmath346 , because the lower limit in the indicator is @xmath347 , and because the upper limit is @xmath348 ) .",
    "hence , @xmath349 for each @xmath263 , as required .",
    "because that limit does not depend on @xmath280 , and because any subsequence contains a further subsequence along which @xmath350 converges to some limit @xmath351 ( due to compactness of this space ) , the result follows for the subcase @xmath274 . in the subcase @xmath352 , it is easy to see that @xmath331 converges to one for each @xmath263 , whence @xmath353 for each @xmath263 . in the subcase @xmath354 ,",
    "assume for now also that @xmath355 .",
    "we then see that @xmath356 and @xmath357 , whence @xmath315 for each @xmath263 . because this limit does not depend on @xmath280 and @xmath358 is compact , a subsequence argument as above shows that the statement follows also in this subcase . finally , in the subcases @xmath359 and @xmath360 but @xmath361 , it suffices to note that @xmath362 for all @xmath263 .",
    "assume next that @xmath360 and that @xmath363 .",
    "note that @xmath364 holds because @xmath365 . using the formula for @xmath366 and @xmath367 given after ( [ distri_scad ] ) with @xmath4 replacing @xmath200 and @xmath90 replacing @xmath55",
    ", it is then easy to see that @xmath368 converges to the integrand in the display given in part 2 , for almost all @xmath4 .",
    "moreover , the total mass of @xmath369 is also easily computed and seen to converge to one .",
    "furthermore , it is easily checked that the total mass of the limiting cdf displayed in part 2 is one .",
    "scheff s lemma then shows that @xmath370 , and hence @xmath312 , converge in total variation to the limit cdf given in part 2 .",
    "next , assume that @xmath371 .",
    "then the integrand in the formula for @xmath372 converges to the density @xmath373 for each @xmath154 .",
    "the dominated convergence theorem then establishes the convergence of @xmath374 , and hence of @xmath312 , to @xmath52 in total variation distance .",
    "for @xmath375 , the proof is , mutatis mutandis , the same with @xmath329 , @xmath376 , and @xmath326 now taking the roles of @xmath321 , @xmath322 , and @xmath323 , respectively , and with the case @xmath377 now being handled by showing that @xmath378 for each @xmath343 .",
    "alternatively , it can be reduced to what has already been established by observing that @xmath379 , where @xmath380 denotes the limit from the left of @xmath381 at the indicated argument .",
    "the fixed - parameter asymptotic distribution of the scad estimator , including the ` oracle ' property discussed at the beginning of this section , can clearly be recovered from theorem [ scad_consist ] by setting @xmath382 . like in the case of the hard - thresholding estimator ,",
    "theorem [ scad_consist ]  shows that the asymptotic behavior of the scad - estimator is much more complicated than what the ` oracle ' property predicts .",
    "in particular , theorem [ scad_consist ] shows that the scad - estimator is not uniformly @xmath1-consistent .",
    "[ for a discussion of the behavior of this estimator under a different scaling see the next paragraph as well as the appendix .",
    "] furthermore , since the finite - sample distribution of the scad - estimator is highly non - normal but the _ pointwise _ asymptotic distribution is normal , the latter can not adequately capture many of the essential features of the former .",
    "in contrast , the asymptotic distributions given in theorem [ scad_consist ] are non - normal in some cases .",
    "all this again shows that the ` oracle ' property is more of an artifact of the asymptotic framework than of much statistical significance .",
    "the observation , that the estimators @xmath38 and @xmath383 are not uniformly @xmath1-consistent if tuned to perform consistent model selection , prompts the question of the behavior of @xmath384 and @xmath385 under a sequence of norming constants @xmath386 that are @xmath387 .",
    "since both estimators are _ pointwise _ @xmath1-consistent , it follows that the _ pointwise _ limiting distributions of @xmath388 and @xmath385 will then degenerate to pointmass at zero .",
    "furthermore , it is not difficult to see that under general ` moving parameter ' asymptotics the finite - sample distributions of @xmath389 and @xmath390 are then nevertheless stochastically unbounded for certain sequences of parameters @xmath391 unless @xmath392 . if @xmath392 , theorem [ unif_cons ] has shown that @xmath393 and @xmath390 are indeed stochastically bounded .",
    "hence , the uniform convergence rate of @xmath38 and @xmath394 is seen to be given precisely by @xmath13 .",
    "the precise limit distributions of these estimators under a scaling by @xmath386 can be obtained in a manner similar to the above theorems and are given in theorems [ hard_rescaled ] and [ scad_rescaled ] in the appendix for the ( only interesting ) case @xmath395 .",
    "it turns out that the limit distributions under ` moving parameter ' asymptotics are always given by a linear combination of at most two pointmasses , each located in the interval @xmath396 $ ] . with regard to the soft - thresholding estimator",
    "we have already observed that it is not even pointwise @xmath1-consistent .",
    "even the distributions of @xmath397 with @xmath398 are stochastically unbounded if @xmath58 unless @xmath399 .",
    "this is most easily seen by using the relation to the hard - thresholding estimator given in ( [ hard - soft ] ) .",
    "if @xmath399 , relation ( [ hard - soft ] ) also shows that @xmath400 is stochastically bounded , but has a degenerate ( pointwise ) limiting distribution .",
    "this has been noted by zou ( 2006 ) . in view of theorem [ unif_cons ] , under this condition on @xmath386",
    "the distributions of @xmath401 are in fact stochastically bounded for _ any _ sequence @xmath90 .",
    "the precise forms of the possible limit distributions under such a ` moving parameter ' asymptotic are given in theorem [ soft_rescaled ] in the appendix .",
    "theorems [ h_consist ] and [ scad_consist ] demonstrate that the ` oracle ' property of the hard - thresholding estimator and of the scad - estimator paints a misleading picture of the actual finite - sample behavior of these estimators due to nonuniformity problems . in order to rescue the ` oracle ' property ,",
    "sometimes the argument is put forward that parameter sequences @xmath90 that are responsible for the nonuniformity problem should be eliminated from the parameter space a priori , since such @xmath391 are supposedly close to zero and hence are difficult to distinguish statistically from zero . while we think that such a reasoning is not sensible ( because asymptotic properties of statistical procedures that are quite unstable under local perturbations of the parameter are highly suspect )",
    ", we next show that the suggested reasoning actually is flawed : consider first the consistently tuned scad - estimator .",
    "suppose one considers a priori the restricted parameter space @xmath402  of the form @xmath403 for some sequence @xmath404 . in order to achieve that for every @xmath405 with @xmath406 , the distribution of @xmath407 converges weakly to the standard normal @xmath34 ( as desired when attempting to rescue the ` oracle ' property )",
    ", it follows from theorem [ scad_consist ] that @xmath408 would have to satisfy @xmath409 ( e.g. , @xmath410 with @xmath411 ) .",
    "but then it is easy to see that the ` forbidden ' set @xmath412 contains elements @xmath90 that are large in the sense that ( i ) they are of order larger than @xmath0 and ( ii ) they are classified as nonzero with probability converging to unity by the very same scad - procedure , i.e. , @xmath413 holds ( to see this use proposition [ selection_prob ] ) . on top of this ,",
    "the parameter space @xmath402  is highly artificial , depends on sample size , and also on the tuning parameter @xmath13 and thus on the estimation procedure used .",
    "an analogous statement holds for the hard - thresholding estimator ( with the exception that the ` forbidden ' set in this case contains @xmath90 that are large in the sense that they satisfy ( i ) above and ( ii ) are classified as non - zero with probability tending to unity by any _ conservatively _ tuned hard - thresholding procedure ) .",
    "taken together , this shows that adopting a parameter space like @xmath402 rules out values of @xmath55 that are substantially large , and not only values of @xmath55 that are statistically difficult to distinguish from zero .",
    "hence , there seems to be little support for adopting such @xmath402 as the parameter space .",
    "[ rxxx ] the theorems in this subsection actually completely describe the limiting behavior of the finite - sample distributions of @xmath43 , @xmath28 , and @xmath44 without _ any _ condition on the sequence of parameters @xmath90 . to see this ,",
    "just apply the theorems to subsequences and note that by compactness of @xmath414 we can select from each subsequence a further subsequence such that the relevant quantities like @xmath415 , @xmath93 , @xmath350 , @xmath416 , etc .",
    "converge in @xmath236 along this further subsequence .",
    "[ ry ] ( i ) as a point of interest we note that the full complexity of the possible limiting distributions in theorems [ h_consist ] , [ s_consist ] , and [ scad_consist ] already arises if we restrict the sequences @xmath90 to a bounded neighborhood of zero .",
    "hence , the phenomena described by these theorems are of a local nature , and are not tied in any way to the unboundedness of the parameter space .",
    "\\(ii ) it is also interesting to observe that what governs the different cases , in theorems [ h_consist ] and [ scad_consist ] , is essentially the behavior of @xmath93 , which is of smaller order than @xmath92 because @xmath237 in the consistent case .",
    "hence , an analysis relying on the usual local asymptotics based on perturbations of @xmath55 of the order of @xmath0 does not properly reveal all possible limits of the finite - sample distributions in the case where the estimators perform consistent model selection .",
    "[ ryy ] similar as in section [ sec_conserv ] , the mathematical reason for the failure of the pointwise asymptotic distribution to capture the behavior of the finite - sample distribution well is that the convergence of the latter to the former is not uniform in the underlying parameter @xmath55 .",
    "see leeb and ptscher ( 2003 , 2005 ) for more discussion in the context of post - model - selection estimators .",
    "as shown in section [ finite ] , the cdfs @xmath419 , @xmath420 , and @xmath202 of the ( centered and scaled ) estimators @xmath43 , @xmath28 , and @xmath44 depend on the unknown parameter @xmath55 in a complicated manner .",
    "it is hence of interest to consider estimation of these cdfs .",
    "we show that this is an intrinsically difficult estimation problem in the sense that these cdfs can not be estimated in a uniformly consistent fashion .",
    "parts of the results that follow have been presented in earlier work ( in slightly different settings ) : for a general class of post - model - selection estimators including the hard - thresholding estimator , this phenomenon was discussed in leeb and ptscher ( 2006b,2008b ) for the case where the estimator is tuned to be conservative , whereas leeb and ptscher ( 2006a ) consider the case where the hard - thresholding estimator is tuned to be consistent ; the latter paper also gives similar results for a soft - thresholding estimator tuned to be conservative . in the following ,",
    "we give a simple unified treatment of hard - thresholding , soft - thresholding , and also of the scad estimator .",
    "for the scad estimator and for the consistently tuned soft - thresholding estimator , such non - uniformity phenomena in estimating the estimator s cdf have not been established before .",
    "we provide large - sample results that cover both consistent and conservative choices of the tuning parameter , as well as finite - sample results that hold for any choice of tuning parameter .",
    "it is straight - forward to construct consistent estimators for the distributions of the ( centered and scaled ) estimators @xmath38 , @xmath50 and @xmath44 .",
    "one popular choice is to use subsampling or the @xmath421 out of @xmath54 bootstrap with @xmath422 .",
    "another possibility is to use the pointwise large - sample limit distributions derived in section  [ asydistribs ] together with a properly chosen pre - test of the hypothesis @xmath42 versus @xmath58 : because the pointwise large - sample limit distribution takes only two different functional forms depending on whether @xmath42 or @xmath58 , one can perform a pre - test that rejects the hypothesis @xmath42 in case @xmath423 , say , and estimate the finite - sample distribution by that large - sample limit formula that corresponds to the outcome of the pre - test ; which is then to be replaced by @xmath101 . ]",
    "the test s critical value @xmath424 ensures that the correct large - sample limit formula is selected with probability approaching one as sample size increases .",
    "when estimating the distribution of thresholding ( and related ) estimators , there is evidence in the literature that certain specific consistent estimation procedures , like those sketched above , may not perform well in a worst - case scenario .",
    "for some examples , see kulperger and ahmed ( 1992 ) ; the disclaimer issued after corollary  2.1 in beran ( 1997 ) ; the discussion at the end of section  4 in knight and fu ( 2000 ) ; or samworth ( 2003 ) .",
    "the next result shows that this problem is not caused by the specifics of the consistent estimators under consideration but is an intrinsic feature of the estimation problem itself .",
    "[ t1 ] let @xmath49 denote any one of the estimators @xmath242 , @xmath28 , or @xmath44 , and write @xmath425 for the cdf of @xmath426 under @xmath53 .",
    "consider a sequence of tuning parameters such that @xmath59 and @xmath61 as @xmath64 with @xmath427 .",
    "let @xmath428 be arbitrary .",
    "then _ every consistent _ estimator _",
    "_  _ _ @xmath429 of @xmath430 satisfies @xmath431for each @xmath432 and each @xmath433 . _ _  _ _ in particular , no uniformly consistent estimator for @xmath430 exists .    for two sequences @xmath434 and @xmath435 satisfying @xmath436 and @xmath437 are mutually contiguous as is elementary to verify ( cf . , e.g. , lemma  a.1 of leeb and ptscher ( 2006a ) ) .",
    "the corresponding estimands @xmath438 and @xmath439 , however , do not necessarily get close to each other : for each @xmath440 write @xmath441 as shorthand for @xmath442 . the cdfs @xmath443 and",
    "@xmath444 have a jump at @xmath445 and at @xmath446 , respectively , so that for @xmath447@xmath448cf .",
    "( [ distri_h ] ) , ( [ distri_s ] ) , and ( [ distri_scad ] ) for @xmath43 , @xmath28 , and @xmath44 , respectively . moreover , @xmath449 goes to zero with @xmath450 , because the absolutely continuous part of @xmath430 is a continuous function of @xmath55 ( again in view of the finite - sample formulae and dominated convergence ) .",
    "taking the supremum of @xmath451 over all @xmath440 with @xmath452 , we obtain that this supremum is bounded from below by @xmath453 .",
    "[ to see this note that this supremum is not less than @xmath454 and use ( [ pt1.1 ] ) . ]",
    "because that lower bound converges to @xmath455 as @xmath64 , the theorem now follows from lemma  3.1 of leeb and ptscher ( 2006a ) .",
    "[ use this result with the identifications @xmath456 , @xmath457 , @xmath458 , @xmath459 , and with @xmath460 .",
    "moreover , note that @xmath461 contains @xmath462 and @xmath463 for @xmath464 . ]",
    "we stress that the above result also applies to any kind of bootstrap- or subsampling - based estimator of the cdf @xmath465 whatsoever , since the results in leeb and ptscher ( 2006a ) on which the proof of theorem  t1 rests apply to arbitrary randomized estimators ( cf .",
    "lemma 3.6 in leeb and ptscher ( 2006a ) ) ; the same applies to theorem  [ t2 ] that follows as well as to theorem [ t3 ]  in the appendix .    loosely speaking , theorem  [ t1 ] states that any consistent estimator for the cdf of interest suffers from an unavoidable worst - case error of at least @xmath466 with @xmath432 .",
    "the error range , i.e. , @xmath467 , is governed by the limit @xmath468 . in case",
    "the estimator @xmath49 is tuned to be consistent , i.e. , in case @xmath72 , the error range equals @xmath469 , and the phenomenon is most pronounced . if the estimator @xmath49 is tuned to be conservative so that @xmath68 , the error range is less than @xmath470 but can still be substantial . only in case",
    "@xmath211 the error range equals zero , and the condition @xmath432 in theorem  [ t1 ] leads to a trivial conclusion .",
    "this is , however , not surprising as then the resulting estimator is uniformly asymptotically equivalent to the unrestricted maximum likelihood estimator @xmath471 ; cf .",
    "remark [ r1 ] .",
    "a similar non - uniformity phenomenon as described in theorem  [ t1 ] for consistent estimators @xmath429 also occurs for not necessarily consistent estimators . for such arbitrary estimators ,",
    "we find in the following that the phenomenon can be somewhat less pronounced , in the sense that the lower bound is now @xmath469 instead of @xmath21 ; cf .",
    "( [ t2.1 ] ) below .",
    "the following theorem gives a large - sample limit result that parallels theorem  [ t1 ] , as well as a finite - sample result , both for arbitrary ( and not necessarily consistent ) estimators of the cdf .",
    "[ t2 ] let @xmath49 denote any one of the estimators @xmath242 , @xmath28 , or @xmath44 , and write @xmath425 for the cdf of @xmath426 under @xmath53 .",
    "let @xmath472 and let @xmath428 be arbitrary . then _ every _ estimator @xmath429 of @xmath430 satisfies @xmath473for each @xmath474 , for each @xmath475 , and for each fixed sample size @xmath54 . if @xmath13 satisfies @xmath59 and @xmath476 as @xmath64 with @xmath67 , we thus have @xmath477for each @xmath432 and for each @xmath433 , where the infimum in ( [ t2.1 ] ) extends over _ all _ estimators @xmath429 .",
    "only the finite - sample statement needs to be proven .",
    "let @xmath478 be as in the proof of theorem  [ t1 ] .",
    "the total variation distance of @xmath479 and @xmath480 , i.e. , latexmath:[$%    to zero as @xmath450 ( which is easy to see , either by direct computation or using , say , lemma  a.1 of leeb and ptscher ( 2006a ) ) . in view of ( [ pt1.1 ] ) , however , the estimands @xmath482 and @xmath483 do not get close to each other as @xmath484 ( @xmath447 ) , as we have already seen in the proof of theorem  [ t1 ] . for each @xmath466 that is smaller than @xmath485 ,",
    "the left - hand side of ( [ t2.2 ] ) is bounded from below by @xmath486this follows from lemma  3.2 of leeb and ptscher ( 2006a ) together with remark  b.2 of that paper .",
    "[ use the result described in remark  b.2 with @xmath487 , @xmath488 , @xmath489 , @xmath457 , @xmath460 , and with @xmath490 equal to @xmath451 .",
    "moreover , note that @xmath461 is contained in @xmath491 provided @xmath492 . ] for @xmath450 , now observe that the expression in the preceding display converges to @xmath469 , i.e. , the lower bound in ( [ t2.2 ] ) , and that @xmath451 converges to @xmath493 .",
    "apart from being of interest in its own right , the asymptotic statement in theorem  [ t2 ] also provides additional insight into some phenomena related to inference based on shrinkage - type estimators that have recently attracted some attention : when estimating the cdf of a hard - thresholding estimator , samworth ( 2003 ) noted that , while the bootstrap is not consistent , it nevertheless may perform better , in a uniform sense , than the @xmath421 out of @xmath54 bootstrap which is consistent ( provided @xmath494 , @xmath422 ) .",
    "theorem  [ t1 ] and the asymptotic statement in theorem  [ t2 ] together show that this phenomenon of better performance of the bootstrap is possible precisely because the bootstrap is not consistent .",
    "the finite - sample statement in theorem  [ t2 ] clearly reveals how the estimability of the cdf of the estimator depends on the tuning parameter @xmath495 : a larger value of @xmath13 , which results in a ` more sparse ' estimator in view of ( [ model_prob ] ) , directly corresponds to a larger range @xmath496 for the error @xmath466 within which any estimator @xmath429 performs poorly in the sense of ( [ t2.2 ] ) . in large samples ,",
    "the limit @xmath468 takes the role of @xmath101 .",
    "an impossibility result paralleling theorem [ t2 ] for the cdf of @xmath497 , where @xmath114 , @xmath50 , or @xmath44 , is given in the appendix .",
    "we have studied the distribution of the lasso , i.e. , of a soft - thresholding estimator , of the scad , and of a hard - thresholding estimator in finite samples and in the large - sample limit .",
    "the finite - sample distributions of these estimators were found to be highly non - normal , because they are a mixture of a singular normal distribution and an absolutely continuous component that can be multimodal , for example .",
    "the large - sample behavior of these distributions depends on the choice of the estimators tuning parameter where , in essence , two cases can occur :    in the first case , the estimator can be viewed as performing conservative model selection . in this case ,",
    "fixed - parameter asymptotics , where the true parameters are held fixed while sample size increases , reflect the large - sample behavior only in part . ` moving parameter ' asymptotics , where the true parameter may depend on sample size , give a more complete picture .",
    "we have seen that the distribution of the lasso , of the scad , and of the hard - thresholding estimator can be highly non - normal irrespective of sample size , in particular in the statistically interesting case where the true parameter is close ( in an appropriate sense ) to a lower - dimensional submodel .",
    "this also shows that the finite - sample phenomena that we have observed are not small - sample effects but can occur at any sample size .    in the second case",
    ", the estimator can be viewed as performing consistent model selection , and the hard - thresholding as well as the scad estimator have the ` oracle ' property in the sense of fan and li ( 2001 ) .",
    "[ this is not so for the lasso . ]",
    "this ` oracle ' property , which is based on fixed - parameter asymptotics , seems to suggest that the estimator in question performs very well in large samples .",
    "however , as before , fixed - parameter asymptotics do not capture the whole range of large - sample phenomena that can occur . with ` moving parameter ' asymptotics , we have shown that the distribution of these estimators can again be highly non - normal , even in large samples .",
    "in addition , we have found that the observed finite - sample phenomena not only can persist but actually can be more pronounced for larger sample sizes .",
    "for example , the distribution of the scad estimator can diverge in the sense that all its mass escapes to either @xmath498 or @xmath276 .",
    "we have also demonstrated that the lasso , the scad , and the hard - thresholding estimator are always uniformly consistent , irrespective of the choice of tuning parameter ( except for non - sensible choices ) . in case",
    "the tuning is such that the estimator acts as a conservative model selector , we have also seen that these estimators are in fact uniformly @xmath1-consistent .",
    "however , uniform @xmath1-consistency no longer holds in the case where the estimator acts like a consistent model selector ( and where the scad and the hard - thresholding estimator have the ` oracle ' property ) .",
    "in fact , the estimators then have a uniform convergence rate slower than @xmath499 in that they are only uniformly @xmath241-consistent .",
    "the asymptotic distributions of the estimators under an @xmath241-scaling , rather than an @xmath1-scaling , are discussed in the appendix .",
    "finally , we have studied the problem of estimating the cdf of the ( centered and scaled ) lasso , scad , and hard - thresholding estimator .",
    "we have shown that this cdf can not be estimated in a uniformly consistent fashion , even though pointwise consistent estimators can be constructed with relative ease . moreover , we have obtained performance bounds for estimators of the cdf that suggest that inconsistent estimators for this cdf may actually perform better , in a uniform sense , than consistent estimators .",
    "the phenomena observed here for distributional properties of the estimators under consideration not surprisingly spill over to the estimators risk behavior .",
    "the finite - sample distributions derived in this paper in fact facilitate a detailed risk analysis , but this is not our main focus here .",
    "therefore , we only point out the most important risk phenomena : we consider squared error loss scaled by sample size ( i.e. , @xmath500 ) , and we shall compare the estimators to the maximum - likelihood estimator based on the overall model , i.e. , @xmath501 . in finite samples , the lasso ,",
    "the scad , and the hard - thresholding estimator compare favorably with @xmath207 in terms of risk , if the true parameter is in a neighborhood of the lower dimensional model ; outside of that neighborhood , the situation is reversed .",
    "[ this is well - known for the hard- and soft - thresholding estimators and for more general pre - test estimators ; cf .",
    "judge and bock ( 1978 ) , bruce and gao ( 1996 ) .",
    "explicit formulae for the risk of a hard - thresholding estimator are also given in leeb and ptscher ( 2005 ) .",
    "] as sample size goes to infinity , again two cases need to be distinguished : if these estimators are tuned to perform conservative model selection , the worst - case risk of the lasso , of the scad , and of the hard - thresholding estimator remains bounded as sample size increases . if the tuning is such that these estimators perform consistent model selection ( the case when the scad as well as the hard - thresholding estimator have the ` oracle ' property ) , then the worst - case risk of these estimators increases indefinitely as sample size goes to infinity .",
    "[ in fact , this is true for any estimator that has a ` sparsity ' property ; see theorem  2.1 in leeb and ptscher ( 2008a ) for details . ]",
    "thus for these estimators the asymptotic worst - case risk behavior is in marked contrast to their favorable pointwise asymptotic risk behavior reflected in the ` oracle ' property .",
    "for the scad , the lasso , and for the hard - thresholding estimator , this worst - case risk behavior is also in line with the fact that these estimators are uniformly @xmath1-consistent if tuned to perform conservative model selection , but that uniform @xmath1-consistency breaks down when they are tuned to perform consistent model selection .",
    "finally we want to stress that our results should not be read as a criticism of penalized maximum likelihood estimators per se , but rather as a warning that the distributional properties of such estimators are more intricate and complex than might appear at first glance .",
    "input and suggestions from ulrike schneider are greatly appreciated .",
    "for the case where the estimators @xmath38 , @xmath28 , and @xmath44 are tuned to perform consistent model selection ( i.e. , @xmath59 and @xmath237 ) , we now consider the possible limits of the distributions of @xmath502 , @xmath503 , and @xmath504 when @xmath392 .",
    "the only interesting case is where @xmath505 , since for @xmath506 these limits are always pointmass at zero in view of theorem [ unif_cons ] .",
    "holds can  by passing to subsequences  always be reduced to the cases where @xmath505 or @xmath507 holds .",
    "] let @xmath508 , @xmath509 , and @xmath510 stand for the finite - sample distributions of @xmath511 , @xmath512 , and @xmath513 , respectively , under @xmath53 .",
    "clearly , @xmath514 and similar relations hold for @xmath515 and @xmath516 .",
    "we next provide the limits of these distributions under ` moving parameter ' asymptotics .",
    "note that comments like in remarks [ rxxx ] , [ ry ] , and [ ryy ] also apply to the three subsequent theorems .",
    "[ hard_rescaled]consider the hard - thresholding estimator with @xmath57 and @xmath237 .",
    "assume that @xmath243 for some @xmath244 .    1 .",
    "if @xmath249 , then @xmath517 converges weakly to pointmass @xmath518 .",
    "2 .   if @xmath260 and @xmath78 for some @xmath79 , then @xmath519 converges weakly to@xmath520 3 .",
    "if @xmath271 , then @xmath521 converges weakly to pointmass @xmath522 .",
    "consider case 1 first . on the event",
    "@xmath159 we have @xmath523 . by proposition [ selection_prob ] , @xmath524 .",
    "since @xmath525 by assumption , the result follows . to prove case 2 write @xmath526 as @xmath527 where @xmath528 is standard normally distributed under @xmath529 .",
    "since proposition [ selection_prob ] shows that @xmath530 , the result in case 2 now follows as is easily seen . to prove case 3 ,",
    "observe that @xmath531 and that @xmath532 converges to a standard normal distribution under @xmath533 in view of theorem [ h_consist ] .",
    "[ soft_rescaled]consider the soft - thresholding estimator with @xmath57 and @xmath237 .",
    "assume that @xmath243 for some @xmath244 .",
    "then @xmath534 converges weakly to pointmass @xmath535 .    from ( [ distri_s_1 ] )",
    "we obtain that @xmath536now it is easy to see that this expression converges to @xmath20 if @xmath537 and to @xmath21 if @xmath538 .",
    "[ scad_rescaled]consider the scad estimator with @xmath302 and @xmath237 .",
    "assume that @xmath303 for some @xmath304 .    1 .",
    "if @xmath539 , then @xmath540 converges weakly to pointmass @xmath535 .",
    "2 .   if @xmath541 , then @xmath540 converges weakly to pointmass @xmath542 .",
    "3 .   if @xmath543 , then @xmath544 converges weakly to pointmass @xmath522 .    if @xmath249 the proof is identical to the proof of case 1 in theorem hard_rescaled .",
    "next assume @xmath274 : assume also for the moment that @xmath545 , @xmath546 .",
    "the atomic part @xmath547 of the cdf @xmath548 is given by @xmath549 which is seen to converge weakly to @xmath550 which is the cdf of @xmath551 .",
    "furthermore , recalling the definition of @xmath552 given in the proof of theorem [ scad_consist ] , @xmath553is seen to converge to @xmath20 for @xmath554 and to @xmath555 for @xmath556 , since @xmath545 and @xmath557 .",
    "hence , @xmath558 converges weakly to @xmath559 , and thus @xmath560 converges weakly to pointmass @xmath561 .",
    "this implies that also @xmath540 has the same limit .",
    "since the limit does not depend on @xmath280 , a subsequence argument as in the proof of theorem [ scad_consist ] completes the proof of the case @xmath562 .",
    "next consider the case @xmath563 : here @xmath564 is easily seen to converge to @xmath20 for @xmath554 and to @xmath21 for @xmath556 , since @xmath565 and @xmath566 .",
    "hence , @xmath567 converges weakly to pointmass @xmath561 , and consequently @xmath544 has to have the same limit .",
    "we turn to the case @xmath568 : assume now for the moment that @xmath569 , @xmath351 .",
    "then @xmath570 is seen to converge to @xmath20 for @xmath554 and to @xmath571 for @xmath556 , since @xmath572 and @xmath573 .",
    "furthermore , note that in the case considered @xmath574 converges to @xmath276 for @xmath554 and to @xmath285 for @xmath556 .",
    "consequently,@xmath575is seen to converge to @xmath20 for @xmath554 and to @xmath555 for @xmath556 , since @xmath576 and @xmath577 . but",
    "this shows that @xmath578 converges weakly to pointmass @xmath561 , and hence the same must be true for @xmath544 .",
    "since the limit does not depend on @xmath280 , a subsequence argument completes the proof for the case @xmath354 .",
    "consider next the case where @xmath359 : then @xmath579 is easily seen to converge to @xmath20 if @xmath580 and to @xmath21 if @xmath581 , since @xmath574 converges to @xmath276 or @xmath285 depending on whether @xmath200 is smaller or larger than @xmath582 , and since @xmath583 and @xmath584 .",
    "this proves that @xmath585 , and hence @xmath540 , converges weakly to pointmass @xmath586 . assume next that @xmath360 and assume for the moment that @xmath587 , @xmath546 : then the upper limit in the integral defining @xmath588 converges to @xmath285 if @xmath24 and to @xmath276 if @xmath22 .",
    "this is obvious if @xmath589 , and follows from rewriting the upper limit as @xmath590 if @xmath591 .",
    "furthermore , the lower limit in the indicator function in ( [ 99 ] ) converges to @xmath276 , while the upper limit converges to @xmath280 .",
    "this shows that @xmath585 converges weakly to @xmath592 .",
    "inspection of @xmath593 shows that this converges weakly to @xmath594 .",
    "together this gives weak convergence of @xmath595 , and hence of @xmath596 , to pointmass @xmath522 .",
    "since the limit does not depend on @xmath280 , a subsequence argument again completes the proof of the case @xmath360 .",
    "suppose next that @xmath597 : inspection of @xmath598 immediately shows that it ( and hence also @xmath540 ) converges weakly to pointmass @xmath522 .",
    "the remaining cases for @xmath599 are proved completely analogous to the corresponding cases with positive @xmath600 .",
    "finally , we provide an impossibility result for the estimation of the finite sample distributions @xmath508 , @xmath509 , and @xmath510 .",
    "[ t3 ] let @xmath49 denote any one of the estimators @xmath242 , @xmath28 , or @xmath44 , and write @xmath601 for the cdf of @xmath602 under @xmath603 .",
    "let @xmath472 and let @xmath428 be arbitrary .",
    "then _ every _ estimator @xmath604 of @xmath605 satisfies @xmath606for each @xmath607 , for each @xmath475 , and for each fixed sample size @xmath54 . if @xmath13 satisfies @xmath59 and @xmath296 as @xmath64 , we thus have for each @xmath475@xmath608for each @xmath609 if @xmath610 and for @xmath611 if @xmath612 , where the infimum in ( t3.1 ) extends over _ all _ estimators @xmath604 .",
    "this result shows , in particular , that no uniformly consistent estimator exists for @xmath605 in case @xmath613 ( not even over compact subsets of @xmath217 containing the origin ) . in view of theorems",
    "[ hard_rescaled ] , [ soft_rescaled ] , and [ scad_rescaled ] we see that for @xmath614 we have @xmath615 as @xmath64 , hence @xmath616 is trivially a uniformly consistent estimator .",
    "similarly , for @xmath617 we have @xmath618 as @xmath64 , hence @xmath619 is trivially a uniformly consistent estimator .",
    "we first prove ( [ t3.2 ] ) . for",
    "fixed @xmath54 and @xmath41 set @xmath620 .",
    "define @xmath621 . also note that @xmath622 holds . by theorem [ t2 ]",
    "we know that@xmath623for each @xmath624 and for each @xmath625 .",
    "rewriting this in terms of @xmath41 , @xmath604 , and @xmath605 and setting @xmath626 gives ( [ t3.2 ] ) .",
    "relation ( [ t3.1 ] ) is a trivial consequence of ( [ t3.2 ] ) .",
    "bauer , p. , ptscher , b.  m. & p. hackl ( 1988 ) : model selection by multiple test procedures . _ _ statistics  _ _ 19 , 3944 .",
    "leeb , h. & b.  m. ptscher ( 2006a ) : performance limits for estimators of the risk or distribution of shrinkage - type estimators , and some general lower risk - bound results .",
    "_ econometric theory _  22 , 6997 .",
    "( corrigendum : ibidem , 24 , 581 - 583 ) ."
  ],
  "abstract_text": [
    "<S> we study the distributions of the lasso , scad , and thresholding estimators , in finite samples and in the large - sample limit . </S>",
    "<S> the asymptotic distributions are derived for both the case where the estimators are tuned to perform consistent model selection and for the case where the estimators are tuned to perform conservative model selection . </S>",
    "<S> our findings complement those of knight and fu ( 2000 ) and fan and li ( 2001 ) . </S>",
    "<S> we show that the distributions are typically highly nonnormal regardless of how the estimator is tuned , and that this property persists in large samples </S>",
    "<S> . the uniform convergence rate of these estimators is also obtained , and is shown to be slower than @xmath0 in case the estimator is tuned to perform consistent model selection . </S>",
    "<S> an impossibility result regarding estimation of the estimators distribution function is also provided .    </S>",
    "<S> _ msc 2000 subject classification_. primary 62j07 , 62j05 , 62f11 , 62f12 , 62e15 .    </S>",
    "<S> _ key words and phrases_. penalized maximum likelihood , lasso , scad , thresholding , post - model - selection estimator , finite - sample distribution , asymptotic distribution , oracle property , estimation of distribution , uniform consistency . </S>"
  ]
}