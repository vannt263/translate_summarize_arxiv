{
  "article_text": [
    "graph processing continues to increase in popularity with the emergence of applications such as social network mining , real - time network traffic monitoring , etc . due to their data - intensive nature",
    ", the performance and dependability of such applications depends upon how well the choice of runtime data structure matches the input data characteristics and availability of memory ( low memory can prevent the applications from completing ) .",
    "programmers often choose specific , fixed data structures when developing graph applications .",
    "the memory used by the data structure can be greatly influenced by the input data characteristics .",
    "thus , it is possible that the characteristics of data may not match the choice of the data structure .",
    "this is particularly problematic when the application is expected to encounter a wide range of input data characteristics , and these characteristics may change during the course of execution .",
    "for example , matrices can be represented in the compressed column storage ( ccs ) format , appropriate for sparse matrices , or the array representation , appropriate for dense matrices .",
    "an application , e.g. , matrix multiplication , programmed to use the sparse ccs format , could take longer to complete when presented with a dense input . similarly ,",
    "evolving graphs  @xcite , where nodes or edges are added during execution , are another example of changes in input data characteristics .",
    "the data structure selection based on input pre - analysis will fail under such scenario .",
    "therefore , in our approach , _ adaptive applications tailor the choice of data structure to match input data characteristics at runtime .",
    "_    since real - world applications often do not run in isolation , they share the available memory resources with other applications . there could be times where the application experiences a resource crunch , caused by other running programs . in this scenario",
    "the performance of the application may be degraded , or the application may even be prematurely terminated . therefore , in our approach , _ adaptive applications tailor the choice of data structure to match availability of memory at runtime .",
    "_ it is well known that for data - intensive applications , the choice of data structure is critical to memory usage and execution time .",
    "there has been previous work on data structure identification  @xcite , as well as data structure prediction and selection  @xcite . while these prior approaches help in data structure selection , none of them support switching from one data structure to another as the application executes .",
    "there has also been work on dynamically adapting the representation of individual data items for impacting memory usage and performance  employing data compression  @xcite or replacing float data with int data  @xcite .",
    "these techniques are orthogonal to our work that switches between alternate high level data structures .",
    "other approaches dynamically switch between implementations .",
    "elastin  @xcite allows a program to switch between versions using dynamic software update techniques @xcite ; however , it does not consider switching between alternate high level data structures .",
    "k42 operating system  @xcite supports hot - swapping classes as a mechanism for performing dynamic updates .",
    "scenario based optimization  @xcite , a binary level online optimization technique dynamically changes the course of execution through a route meant for a particular runtime scenario as predefined by developer .",
    "wang et al .",
    "@xcite proposed dynamic resource management techniques based on user - specific , application - specific and hardware - specific management policies . in contrast , our objective is to simultaneously support alternate data structures and switch between them . in this paper",
    "we consider several widely - used graph applications and study how data structure representations impact execution time and memory consumption on a range of input graphs ( section  [ sec_motivation ] ) .",
    "the input graphs consist of both real - world graphs such as wikipedia metadata , gnutella network topology ( from the snap library  @xcite ) , and synthetic graphs . based upon the observations from our study , we design a concrete adaptation system that supports switching between alternate representations of the data in memory ( section  [ sec_approach ] ) .",
    "we demonstrate that the cost of performing the runtime adaptations is quite small in comparison to the benefits of adaptation ( section  [ sec_eval ] ) .",
    "moreover , the lightweight monitoring we employ to detect adaptation opportunities imposes acceptable overhead even when no adaptations are triggered at runtime .",
    "thus , our adaptive versions have nearly the same performance as the most appropriate non - adaptive versions for various input characteristics .",
    "we compare our approach with related work in section  [ sec_rel ] , and in section  [ sec_conc ] we conclude .",
    "in this section we study the execution time and memory usage behavior of a set of graph applications . the goal of this study is two fold .",
    "first , we want to quantify how input data characteristics and the choice of data structures used to represent the graphs impact memory usage and execution time .",
    "second , we would like to develop a simple characterization of program behavior that can be used to guide data structure selection at runtime .",
    "we considered six graph algorithms : muliple source shortest path ( mssp ) finds the shortest path from all the nodes to every other node ; betweenness centrality ( bc ) computes the importance of a node in a network ; breadth first search ( bfs ) traverses the graph with each node as root per iteration ; boruvka s algorithm ( mst - b ) and kruskal s algorithm ( mst - k ) , finds the minimum spanning tree ; preflow push ( pp ) , finds out the maximum flow in a network starting with each individual node as source .",
    "the core data structure used in these applications is a graph .",
    "we consider two different representations of graphs : adjacency list ( ` adjlist ` ) ; and adjacency matrix ( ` adjmat ` ) .",
    "when the graph is sparse , it is expected that ` adjlist ` will use less memory than ` adjmat ` . on the other hand , for highly dense graphs ` adjmat ` may use less memory than ` adjlist ` .",
    "determining whether a pair of nodes is connected by an edge can be done in constant time using ` adjmat ` while it may require searching through a list with ` adjlist ` .",
    "thus , the runtime memory usage and execution time depend upon the sparsity , or conversely the density , of the input graph . the input graphs with relevant properties and densities were generated to study program behavior .    to observe the trade - offs of using the alternative representations of graphs",
    ", we executed each of the programs using the two representations .",
    "the programs were run on inputs consisting of randomly - generated graphs with varying density which is computed as @xmath0 , where @xmath1 and @xmath2 are number of nodes and edges in the graph .",
    "the inputs were selected such that the trade - offs could be exposed easily .",
    "the results of these executions are summarized as follows :    we present the relative memory usage and execution time of program versions in table  [ tbl : perfranges ] . in particular",
    ", we computed the ratios of memory usages and execution times for ` adjlist ` and ` adjmat ` versions across all graph densities considered .",
    "the minimum and maximum values of observed ratios is given in table  [ tbl : perfranges ] .",
    "as we can see , in terms of both memory usage and execution time , the relative performances vary a great deal . moreover",
    ", neither representation gives the best memory usage or execution time performance across all graph densities .",
    "hence , it is crucial to select the data structure at runtime , based upon the input data characteristics .    for the purpose of runtime data structure selection ,",
    "we characterize the behavior of each application as shown in table  [ dsranges ] .",
    "note that graph densities are divided into three subranges . in the first range ( e.g. , @xmath3 for mssp )",
    "the ` adjlist ` is both more memory- and time - efficient than ` adjmat ` . in the second range",
    "( e.g. , @xmath4 ) ` adjlist ` is more memory - efficient while ` adjmat ` is more time - efficient .",
    "thus , the selection can be made at runtime based upon memory availability . finally , in the third range ( e.g. , @xmath5 for mssp ) `",
    "adjmat ` is both more memory and time efficient than ` adjlist ` .",
    "[ sec_approach ]        [ fig : framework ]    we now present our approach for building adaptive applications ; an overview is shown in figure  [ fig : framework ] . the starting point is the _ annotated source code _ : in the source code , programmers add _ annotations _ to identify the alternative data structures , e.g. , ds@xmath6 and ds@xmath7 , and functions operating on them .",
    "the compiler takes heed of these annotations and generates the _ source code with transition logic _ , that is capable of dynamically switching among alternative data structure representations .",
    "the transitions are allowed at selected program points where the processing of an input item has just completed and that of another item is about to begin .",
    "lastly , the _ adaptation module _ consists of the runtime monitors for tracking input data characteristics and memory usage as well as the code that implements the transition policy that triggers the switch from one data structure representation to another . the adaptation can be triggered by a mismatch between the input data characteristics and the data structure currently in use . to discover this mismatch the characterization of application behavior as performed in the previous section is used .",
    "the adaptation can also be triggered by the system during high memory usage .    to enable adaptation , the programmer implements the alternate data structures .",
    "in addition , a compute - intensive function during whose execution adaptation may be performed , must be coded as follows .",
    "first , it should contain a variable that tracks the progress in terms of processing steps defined as either the amount of input processed or results produced .",
    "second , it should be written so that it can commence execution from any point between two processing steps .",
    "the latter is needed because we allow execution to switch from one data representation to another at these points .",
    "we used a set of pragmas in our approach to identify alternate data structure representations , enable generation of code that transfers code from one representation to another , and identify program points where transitions may be performed .",
    "first , the programmer identifies the data structure to the compiler .",
    "the programmer annotates the alternate representation of data structures in multiple files with ` # pragma adp(<src_filename > , \" data1_def \" ) ` . `",
    "< src_filename > ` s presence clearly differentiates the alternate representation of the data structure in multiple files .",
    "if there are multiple data structures with alternate representations in different files , then they could be annotated with a different index , e.g. , ` # pragma adp(<src_filename > , \" data2_def \" ) ` .",
    "second , the programmer uses several pragmas to identify the key methods ( insert , delete , traverse , and fetch ) that manage data stored in the data structure .",
    "another pragma allows access to the initialization parameters which must be migrated from one data structure to another .",
    "all of this information is used to generate the code for data and function migration when we switch between data structures .",
    "the adaptation module decides whether or not to switch between data structures based upon the input from runtime monitors and the transition policy . since the adaptation could be program - triggered or system - triggered , there are two kinds of monitors which are required by the adaptation module .",
    "the input data monitor captures input data characteristics and the memory monitor reports the available system memory .",
    "the transition policy defines which data structure representation is better for what range of input data characteristics in terms of execution time and memory consumption .",
    "its specification consist of three parts , as illustrated below :    ....         / * execution time * /             ds1 [ 0,9 )              ds2 [ 9,100 ]        /*memory*/             ds1 [ 0,25 )              ds2 [ 25,100 ]       /*threshold*/             memory 100 ....    the first part indicates the ranges for which a particular data structure representation is best in terms of execution time : under ` execution time ` in the figure , the input data property for which ` adjlist ` ( ds1 ) is better is denoted by directives ` ds1 ` , which means that ` adjlist ` is favorable in terms of execution time if the input data property or density of the graph ( in case of mssp ) is in between 0% and 9% .",
    "the second part consists of the ranges of the input data property for which a particular data structure representation is better in terms of memory . according to the figure , under ` memory ` , we see that ` adjlist ` ( ds1 ) is better when the density of the input graph is between 0% and 25% while ` adjmatrix ` ( ds2 ) is better when the density of the graph is between 26% and 100% .",
    "the third part is the threshold for memory , defined by the programmer to notify the system that if the available memory is below this threshold then , regardless of input data characteristics always use the representation requiring least memory ; in the figure ( under ` threshold ` ) the threshold is set to 100 mb .    .... datamigrationds1ds2(void * ds1 , void * ds2 ) {    initializationparameters * ip ;    ip = getinitializationparameter(ds1 ) ;    initializeds2(&ds2,ip ) ;    transferdatads1ds2(&ds1,&ds2 )    deleteds1(&ds1 ) ; } transferdatads1ds2(void * * ds1 , void * * ds2 ) {    i = 0 ; void * datavalue ;   for(i = 0;i < * * ds1->maxdata;i++ ) {      datavalue = fetchdatads1(i,*ds1 ) ;      if(datavalue ! = null ) {        insertdatads2(*ds2 , datavalue , i);deletedatads1(i,*ds1 ) ; } } } ....    [ fig : src_datamigration ]        .... # pragma adp(\"ds1 \" ,          \" ds1_op1 \" )   void computemssp_ds1 (           void * graph , void * rs ,           int * progress ) ; ...    computemssp_ds1(graph ,             rs , progress ) ;    ... ....    &    .... //#pragma adp(\"ds1 \" ,          \" ds1_op1 \" ) void computemssp_ds1 (            void * graph , void * rs ,             int * progress ) ; ...    callop1(graph ,            rs , progress ,             startds ) ; ...   ....     +    the data structure transition logic is inserted into the source files by the compiler , guided by the pragmas .",
    "this transition logic carries out on - the - fly transitions from one data structure representation to another whenever required . to accomplish the transition ,",
    "the in - memory data must be transformed from one representation to another , along with the functions operating on them .",
    "the transition logic handles this by function migration and in - memory data methods contained in the logic .",
    "when the code for transition logic is inserted , appropriate header files are also inserted such that source code after modification compiles and links properly .",
    "to avoid recomputation of already - computed results , the result transfer logic ( injected into code along with the transition logic ) will transfer the already - computed results from one representation to the other representation .",
    ".... void callop1(void * ds , void * rs , int progress , currentds ) {    extern int changereq ; void * newds ; void * newrs ;    while(progress < 100 ) {      if(changereq = = 1 ) { switch(currentds ) {          case 1 :                     currentds = 2 ; datamigrationds1ds2(ds , newds ) ;            resultmigrationrs1rs2(rs , newrs ) ;            ds = newds ; newds = null ;   rs = newrs ;   newrs = null ;            computemsspds2(ds , rs , progress ) ;            break ;          case 2 :            currentds = 1 ; datamigrationds2ds1(ds , newds ) ;            resultmigrationrs2rs1(rs , newrs ) ;            ds = newds ; newds = null ; rs = newrs ; newrs = null ;            computemsspds1(ds , rs , progress ) ;            break ;                    } }      else { switch(currentds ) {          case 1 : computemsspds1(ds , rs , progress ) ;   break ;          case 2 : computemsspds2(ds , rs , progress ) ;   break ;       } } } } ....    an example data migration function is shown in figure  [ fig : src_datamigration ] .",
    "the code in the figure transfers the data from the data structure representation ds1 to another representation ds2 .",
    "it begins with initialization of the ds2 data structure representation .",
    "the initialization parameters are fetched from ds1 and they consist of standard parameters that are invariant in both ds1 and ds2 .",
    "for example , in the mssp benchmark the invariant data is the number of nodes . in the pp benchmark",
    "the invariant data consists of number of nodes , the height , capacity and flow of each node .",
    "the ` transferdata ` function is generated from ` traversedata ` function of ds1 as provided by the developer .",
    "this function traverses through the data by reading each data value , migrating it to ds2 representation using ` insertdatads2 ` and also deleting that data from ds1 using ` deletedatads1 ` thus releasing memory .",
    "the ` deleteds1 ` clears memory which contains the data regarding the initialization parameters .",
    "the transition between implementations , i.e. , switching from one set of functions operating on representation ds1 to functions operating on representation ds2 must be carefully orchestrated .",
    "the developer denotes an operation with a directive such as ` # pragma adp(\"ds1\",\"data1_op1 \" ) ` , which informs the compiler that the function is compute - intensive , as shown in figure  [ fig : code1 ] .",
    "any call to that function is replaced by our customized method , which checks and executes operations with the suitable data structure . in this example ` computemssp_ds1 ` is replaced by ` callop1 ` .",
    "the additional parameter , ` startds ` , denotes the type of the current data structure representation in memory .",
    "the other three parameters are the data structure , a progress gauge , and the result set for storing the result .",
    "for example in the case of mssp , a method that finds mssp has the signature ` void computemssp_ds1(void * graph , void * rs , int * progress ) ` .",
    "the first parameter is the input graph and the second parameter ` rs ` stands for the result set and its declaration must be annotated by the programmer with ` # pragma adp(\"ds1 \" , \" data1_res1 \" ) ` .",
    "the last parameter identifies the progress , which is the iteration number of the outer most long running loop .",
    "for example , if the method is called with a progress value 10 , then the execution is started from progress value 10 and continuously updated with the loop iteration number .",
    ".... void computemssp_ds1 (           void * graph ,           void * rs ,            int * progress ) { ... # pragma adp(\"ds1 \" ,      \" ds1_op1_safe \" ) ...        } ....    &    .... void computemssp_ds1 (            void * graph ,            void * rs ,             int * progress ) { ... //#pragma adp(\"ds1 \"      , \" ds1_op1_safe \" )     if(checkchangestatus()==1 ) {      * progress = curprogress ;       return ;    } } ....     +    the detailed function selection and migration activity is shown in figure  [ fig : src_fnmigration]for mssp benchmark .",
    "an external variable ` changereq ` , set by the adaptation module , is checked ( line  4 ) . if a transition has been requested , then first the data is migrated from one data structure representation to another ( lines  6 and  12 ) .",
    "next , if needed , the result is migrated from one representation to another ( lines  7 and  13 ) .",
    "finally , the corresponding mssp function for that data structure is called ( lines  9 and  15 ) and the operation is resumed from the progress point . if there is a change request from the adaptation module , then operation is paused and it returns back to ` callop1 ` .",
    "this process continues until the mssp computation completes .",
    "the question arises where ongoing mssp computations should be interrupted to check if the adaptation module has requested a change or not . to solve this problem , we rely on the programmers to use the directive ` # pragma adp(\"ds1 \" , \" ds1_op1_safe \" ) ` to indicate the safe transition points in ` operation1 ` as shown in figure  [ fig : code2 ]",
    "this directive notifies our framework that , if the operation is paused and the transformation is performed at that point , then there is minimal recomputation of result .",
    "this is typically the end of an iteration in long - running loops . since the programmer is well aware of the long running loops in the compute - intensive function , it is best to have the programmer mark the points appropriate for the insertion of adaptation module interrupts .",
    "the directive is replaced by an interrupt which checks if there is a change required and thus returns back to ` callop1 ` .",
    "[ pt - table ]",
    "[ sec_eval ] in this section we evaluate the performance of adaptive versions of graph algorithms and compare them with corresponding non - adaptive versions of the applications .",
    "the goals of these experiments are as follows .",
    "first , we evaluate the efficiency of our approach by measuring its benefits and overhead .",
    "second , we consider the benefits of adaptation under two scenarios : adaptation triggered by the input characteristic , i.e. , graph density ; and system triggered adaptation .",
    "all experiments were run on a 24-core machine ( 4 six - core amd opteron@xmath8 8431 processors ) with 32 gb ram .",
    "the system ran ubuntu 10.04 , linux kernel version 2.6.32 - 21-server .",
    "the sources were compiled with gcc 4.4.3 .    _ real world data - sets : _ we evaluate our system on some of the real - world graphs from the snap graph library  @xcite .",
    "the first graph , wiki - vote , contains the who - votes - for - whom graph in wikipedia administrator elections .",
    "this graph has 7,115 nodes and 103,689 edges .",
    "the second graph , p2p - gnutella , is a snapshot of gnutella , a decentralized peer to peer file sharing network from august 9 , 2002 .",
    "this graph has 8,114 nodes representing hosts and 26,013 edges representing the connections between these hosts . for experiments , in cases where a more dense graph was needed , we added edges in both the graphs to raise the required density .",
    "the programmers need to add annotations to transform off - the - shelf applications to adaptive ones .",
    "in addition to this , programmers also need to modify the compute - intensive methods so they can be executed in incrementalized fashion .",
    "the number of pragmas added and the number of additional lines of code added to modify the methods are shown in table  [ tbl_preffort ] .",
    "as we can see , these numbers are fairly modest .    .programming effort . [ cols=\"<,^,^,^,^,^,^,^\",options=\"header \" , ]            the additional execution time taken by the adaptive version over the non - adaptive ` adjlist ` version can be divided into three categories : time spent on converting from one data structure representation to another ; time spent on runtime monitoring and transition logic to trigger adaptation ; and the time lost due to running the application in suboptimal mode , i.e. , with the ` admat ` data structure .",
    "the breakdown of the extra execution time into the three categories is shown in table  [ tbl_breakdown ] . as we can see",
    ", the majority of the time is spent on runtime monitoring and transition logic .",
    "the next significant component is the time spent due to running the program in the suboptimal configuration before the transition occurs .",
    "note that the time spent on converting one data structure into another ( column 2 ) is the least .",
    "an intuitive way to visualize adaptation is to plot how the memory used by applications varies before , during , and after adaptation . in figure",
    "[ pt - mem ] we show how memory ( @xmath9-axis ) varies over time ( @xmath10-axis ) when starting the application in the ` adjmat ` representation and then through adaptation , the application transitions to ` adjlist ` . the charts point out several aspects .",
    "first , since we are using sparse graphs , as expected , the memory used is reduced significantly ( tens of megabytes ) when we switch from the ` adjmat ` to ` adjlist ` representation .",
    "second , the switch from one data structure to the other takes place fairly early in the execution of the program .",
    "third , the time to perform adaptation and the extra memory used during adaptation are very low .    in figure  [ overall ]",
    "we show the execution time of the adaptive version for varying input densities over the range where we expect the adaptive application to switch from the ` adjlist ` to the ` adjmat ` representation . for these experiments ,",
    "we have used graph size of 4000 nodes and varied densities .",
    "the execution times of the non - adaptive versions that use fixed representations ( ` adjlist ` and ` adjmat ` ) are also shown .",
    "as we can see , the performance of the adaptive application is very close to the best of the two non - adaptive versions .",
    "[ st - wiki ]      in this section we study the second scenario , i.e. , when the adaptation is triggered by the system .",
    "the graph used for these experiments was p2p - gnutella at 20% density .",
    "however , we select ` adjmat ` as the initial data structure representation so that no adaptation was triggered due to the mismatch between the data structure and graph density .",
    "instead we provided the program with a system trigger that forces the program to reduce its memory consumption .",
    "this causes adaptation to be triggered , and the program to switch from ` adjmat ` to ` adjlist ` representation to save memory .",
    "as expected , the execution takes longer .",
    "since the conversion from one representation to another can be triggered at any time during a program s execution , in this study we present data for different trigger points ",
    "after 25% , 50% , and 75% of total processing .",
    "we controlled the trigger point by tracking the amount of processing that has been completed .",
    "the results are presented in figure  [ st - table ] .",
    "the execution times of the following versions are presented : non - adaptive version in the ` adjmat ` representation ( leftmost bar ) ; three adaptive versions with different trigger points ( middle three bars ) ; and non - adaptive ` adjlist ` ( rightmost bar ) .",
    "all times are normalized with respect to the time for non - adaptive ` adjlist ` .",
    "as we can see , the execution time of the adaptive version is always greater than the non - adaptive ` adjmat ` version and less than the non - adaptive ` adjlist ` version . in other words ,",
    "if large amounts of memory are available for longer duration , the adaptive version yields greater reduction in execution time over the non - adaptive ` adjlist ` version .    to study the behavior of our approach when there are multiple transitions , we ran experiments on wiki - vote at 10% density in the following scenario .",
    "for each benchmark , the execution was started with ` adjmat ` and then switched to ` adjlist ` and vice versa after 20 % , 40% , 60% and 80% .",
    "we controlled the triggers for memory changes from the system by tracking the amount of processing that has been completed .",
    "we present the results in figure  [ st - wiki ] .",
    "we can clearly see that , during a resource crunch when available memory decreases , our applications adapt to decrease their memory requirements accordingly , hence running slower ; after the resource crunch is over , our applications re - assume the uncompressed representation and their performance increases .",
    "first , our approach is only useful when the alternative data structures offer a significant trade - off between memory usage and execution time .",
    "for example , for the _ agglometric clustering _",
    "benchmark , when we tried using two alternate data structures of kd - tree and r - tree , we observed no significant trade - off between memory usage and execution time .",
    "since there is a need to bulk load the data , the kd - tree always outperforms the r - tree .",
    "second , our approach is only useful when the application is sufficiently compute and data intensive to justify the cost of runtime monitoring and transition logic .",
    "for example , in the case of the max cardinality bipartite matching benchmark , although the trade - off exists , the benchmark is not sufficiently compute - intensive to justify the adaptation cost .",
    "[ sec_rel ] there is a large body of work on program transformations applied at compile - time or runtime to enhance program performance , which also influences resource usage .",
    "some of these techniques can be used to support adaptation .",
    "contexterlang  @xcite supports the construction of self - adaptive software using different call back modules .",
    "compiler - enabled adaptation techniques include altering of the contentiousness of an application  @xcite , which enables co - location of applications without interfering with their performance ; data spreading  @xcite migrates the application across multiple cores ; adaptive loop transformation  @xcite allows a program to execute in more than one way during execution based on runtime information .",
    "multiple applications that are running on multicore systems can significantly impact each other s performance as they must share hardware resources ( e.g. , last level cache , access paths to memory )  @xcite .",
    "the impact of interference on program performance can be predicted and estimated  @xcite , and contention management techniques guided by last level shared cache usage and lock contention have been developed  @xcite .",
    "huang et al .",
    "proposed self adaptive containers  @xcite where they provide the developer with a container library which adjusts the underlying data structure associated with the container to meet service level objectives ( slo ) ; adaptation occurs during slo violations .",
    "similarly , coco  @xcite allows adaptation by switching between java collections during execution depending on the size of collection .",
    "these methods are orthogonal to our approach as they do not have scope for user - defined data structures , and the space - time tradeoff is not taken into consideration .",
    "[ sec_conc ] graph applications have resource requirements that vary greatly across runs due to differences in graph characteristics ; moreover , the required memory might not be available due to pressure from co - located applications .",
    "we have observed that data structure choice is crucial for allowing the application to get the best out of available resources .",
    "we propose an approach that uses programming and runtime support to allow graph applications to be transformed into adaptive applications by choosing the most appropriate data structure .",
    "experiments with graph - manipulating applications which adapt by switching between data structure representations show that our approach is easy to use on off - the - shelf applications , is effective at performing adaptations , and imposes very little overhead .",
    "this work was supported in part by nsf grants ccf-0963996 and ccf-1149632 .",
    "this research was sponsored by the army research laboratory and was accomplished under cooperative agreement number w911nf-13 - 2 - 0045 ( arl cyber security cra ) .",
    "the views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies , either expressed or implied , of the army research laboratory or the u.s .",
    "government is authorized to reproduce and distribute reprints for government purposes notwithstanding any copyright notation here on ."
  ],
  "abstract_text": [
    "<S> graph processing is used extensively in areas from social networking mining to web indexing . </S>",
    "<S> we demonstrate that the performance and dependability of such applications critically hinges on the graph data structure used , because a fixed , compile - time choice of data structure can lead to poor performance or applications unable to complete . to address this problem </S>",
    "<S> , we introduce an approach that helps programmers transform regular , off - the - shelf graph applications into adaptive , more dependable applications where adaptations are performed via runtime selection from alternate data structure representations . using our approach , </S>",
    "<S> applications dynamically adapt to the input graph s characteristics and changes in available memory so they continue to run when faced with adverse conditions such as low memory . experiments with graph algorithms on real - world ( e.g. , wikipedia metadata , gnutella topology ) and synthetic graph datasets show that our adaptive applications run to completion with lower execution time and/or memory utilization in comparison to their non - adaptive versions .    runtime data structure selection , space - time trade - off </S>"
  ]
}