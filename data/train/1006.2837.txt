{
  "article_text": [
    "we consider a gaussian random field living on a @xmath3-di - mensional domain @xmath12 , @xmath13 . for every finite subset @xmath14 ,",
    "@xmath15 is a multivariate gaussian random vector .",
    "the quantity of interest is @xmath16 as @xmath1 .",
    "the motivations of the study of @xmath17 are from multiple sources .",
    "we will present a few of them .",
    "consider a point process on @xmath18 associated with a  poisson random measure @xmath19 with intensity @xmath20 , where @xmath21 represents the borel sets of @xmath18 .",
    "one important task in spatial modeling is to build in dependence structures .",
    "a  popular strategy is to let @xmath22 , which can take all values in @xmath23 , and model @xmath24 as a gaussian random field .",
    "then , @xmath25 for all @xmath26 . with the multivariate gaussian structure , it is easy to include linear predictors in the intensity process .",
    "for instance , @xcite models @xmath27 , where @xmath28 is the observed ( deterministic ) covariate process and @xmath29 is a stationary ar(1 ) process .",
    "similar models can be found in @xcite which are special cases of the cox process @xcite .",
    "such a modeling approach has been applied to many disciplines , a  short list of which is as follows : astronomy , epidemiology , geography , ecology , material science and so forth .    in portfolio risk analysis , consider a portfolio consisting of equally weighted assets @xmath30 .",
    "one stylized model is that @xmath31 is a multivariate normal random vector ( cf .",
    "the value of the portfolio @xmath32 is then the sum of correlated log - normal random variables . if one can represent each asset price by the value of a gaussian random field at one location in @xmath4 , that is , @xmath33 .",
    "as the portfolio size tends to infinity and the asset prices become more correlated , the limit of the unit share price of the portfolio is @xmath34 . for more general cases , such as unequally weighted portfolios ,",
    "the integral is possibly with respect to some other measures instead of the lebesgue measure .    in option pricing , if we let @xmath35 be a geometric brownian motion ( cf .",
    "@xcite , chapter 5 of @xcite , chapter 3.2 of @xcite ) , the payoff function of an asian option ( with expiration time @xmath4 ) is a function of @xmath36 .",
    "for instance , the payoff of an asian call option with strike price @xmath37 is @xmath38 ; the payoff of a digital asian call option is @xmath39 .",
    "we want to emphasize that the extreme behavior of @xmath40 connects closely to that of @xmath41 .",
    "as we will show in theorem [ thmm ] , with the threshold  @xmath42 appropriately chosen according to @xmath7 , the probabilities of events@xmath43 and @xmath44 have asymptotically the same decaying rate .",
    "it suggests that these two events have substantial overlap with each other .",
    "therefore , we will borrow the intuitions and existing results on the high excursion of the supremum of random fields for the analysis of @xmath17 .",
    "there is a vast literature on the extremes of gaussian random fields mostly focusing on the tail probabilities of @xmath41 and its associated geometry .",
    "the results contain general bounds on @xmath45 as well as sharp asymptotic approximations as @xmath1 .",
    "a partial literature contains @xcite .",
    "several methods have been introduced to obtain asymptotic approximations , each of which imposes different regularity conditions on the random fields .",
    "a  few examples are given as follows .",
    "the double sum method @xcite requires expansions of the covariance function and locally stationary structure .",
    "the euler  poincar characteristic of the excursion set",
    "[ @xmath46 approximation uses the fact that @xmath47 , which requires the random field to be at least twice differentiable @xcite . the tube method @xcite uses the karhunen  love expansion and imposes differentiability assumptions on the covariance function ( fast decaying eigenvalues ) .",
    "the rice method @xcite represents the distribution of @xmath48 ( density function ) in an implicit form .",
    "recently , the efficient simulation algorithms are explored by @xcite .",
    "these two papers provided computation schemes that run in polynomial time to compute the tail probabilities for all hlder continuous gaussian random fields and in constant time for twice differentiable and homogeneous fields .",
    "in addition , @xcite studied the geometric properties of a high level excursion set for infinitely divisible non - gaussian fields as well as the conditional distributions of such properties given the high excursion .",
    "the distribution of @xmath49 for the special case that @xmath24 is a wiener process has been studied by @xcite . for other general functionals of gaussian processes and multivariate gaussian random vectors ,",
    "the tail approximation of the finite sum of correlated log - normal random variables has been studied by @xcite .",
    "the corresponding simulation is studied in @xcite .",
    "the gap between the finite sums of log - normal r.v.s and the integral of continuous fields is substantial in the aspects of both generality and techniques .",
    "the basic strategy of the analysis consists of two steps .",
    "the first step is to partition the domain @xmath4 into @xmath50 small squares of equal size denoted by @xmath51 , @xmath52 , and develop asymptotic approximations for each @xmath53 .",
    "the size of @xmath51 will be chosen carefully such that it is valid to use taylor s expansion on @xmath24 to develop the asymptotic approximations of @xmath54 .",
    "the second step is to show that @xmath55 .",
    "this implies that when computing @xmath56 , we can pretend that all the @xmath57 s are independent , though they are truly highly dependent .",
    "the sizes of the @xmath51 s need to be chosen carefully .",
    "if @xmath51 is too large , taylor s expansion may not be accurate ; if @xmath51 is too small , the dependence of the fields in different @xmath51 s will be high and the second step approximation may not be true . since the first step of the analysis requires taylor s expansion of the field , we will need to impose certain conditions on the field , which will be given in section [ secpre ] .    this paper is organized as follows . in section [ secpre ]",
    "we provide necessary background and the technical conditions on the gaussian random field in context .",
    "the main theorem and its connection to asymptotic approximation of @xmath58 are presented in section [ secmain ] .",
    "in addition , two important steps of the proof are given in the same section , which lay out the proof strategy .",
    "sections [ sec_proof1 ] and [ sec_proof2 ] give the proofs of the two steps presented in section [ secmain ] .",
    "detailed lemmas and their proofs are given in the .",
    "consider a homogeneous gaussian random field , @xmath24 , living on a domain @xmath4 .",
    "denote the covariance function by @xmath59 throughout this paper , we assume that the random field satisfies the following conditions :    @xmath2 is homogeneous with @xmath60 and @xmath61 .",
    "@xmath2 is almost surely at least three times continuously differentiable with respect to @xmath62 .",
    "@xmath4 is a @xmath3-dimension jordan measurable compact subset of @xmath18 .",
    "the hessian matrix of @xmath63 at the origin is @xmath64 , where @xmath65 is a @xmath66 identity matrix",
    ".    condition ( c1 ) imposes unit variance",
    ". we will later study @xmath67 and treat @xmath68 as an extra parameter .",
    "condition ( c2 ) implies that @xmath63 is at least 6 times differentiable .",
    "in addition , the first , third and fifth derivatives of  @xmath63 evaluated at the origin are zero . for any @xmath69 such that @xmath70 and @xmath71 , ( c4 ) can always be achieved by an affine transformation on the domain @xmath4 by letting @xmath72 and @xmath73 where for a symmetric matrix @xmath74 we let @xmath75 be a symmetric matrix such that @xmath76 .    for @xmath77 ,",
    "let @xmath78 for the jordan measurable set @xmath79 . of interest is @xmath80 as @xmath1 .",
    "equivalently , we may consider that the variance of @xmath2 is @xmath81 .",
    "however , it is notionally simpler to focus on a unit variance field and treat @xmath68 as a scale parameter .",
    "we adopt the following notation .",
    "let `` @xmath82 '' and `` @xmath83 '' denote the gradient and hessian matrix with respect to @xmath62 , and `` @xmath84 '' denote the vector of second derivatives with respect to @xmath62 .",
    "the difference between `` @xmath83 '' and `` @xmath84 '' is that , for a specific @xmath62 , @xmath85 is a @xmath66 symmetric matrix whose upper triangle entries are the elements of @xmath86 which is a @xmath87-dimensional vector .",
    "let @xmath88 denote the partial derivative with respect to the @xmath89th component of @xmath90 .",
    "we use similar notation for higher order derivatives . for @xmath7 large enough ,",
    "let @xmath42 be the unique solution to @xmath91 the uniqueness of @xmath42 is immediate by noting that the left - hand side is monotone increasing with @xmath42 for all @xmath92 .",
    "in addition , we use the following notation and changes of variables : @xmath93 the vector @xmath94 contains the spectral moments of order two . similar to @xmath95 and @xmath96",
    ", @xmath97 is a symmetric matrix whose entries consist of elements in @xmath98 .",
    "we create different notation because we will treat the second derivative of  @xmath2 as a matrix when doing taylor s expansion and as a vector when doing integration .",
    "as stated in condition ( c4 ) , we have @xmath99 .",
    "equivalently ,  @xmath100 is a vector of independent unit variance gaussian r.v.s .",
    "we plan to show that in order to have @xmath101 , @xmath41 needs to reach a  level around @xmath42 .",
    "the distance between @xmath102 and @xmath42 is denoted by @xmath103 .",
    "in addition , since @xmath104 is jointly independent of @xmath100 , the distribution of  @xmath100 is unaffected even if @xmath102 reaches a high level .",
    "further , the covariance between  @xmath102 and  @xmath105 is @xmath94 .",
    "given @xmath106 , the conditional expectation of @xmath96 is @xmath107 .",
    "the distance between @xmath96 and this conditional expectation is denoted by vector @xmath98 .",
    "a well - known result ( see , e.g. , chapter 5.5 in @xcite ) is that the joint distribution of @xmath108 is multivariate normal with mean zero and variance @xmath109 where @xmath110 , @xmath111 and @xmath112 is defined previously .",
    "the matrix @xmath113 is a @xmath114 by @xmath114 positive definite matrix and contains the 4th - order spectral moments arranged in an appropriate order .",
    "conditional on @xmath115 , @xmath116 and @xmath117 , @xmath24 is a continuous gaussian random field with conditional expectation @xmath118 where @xmath119 note that @xmath120 is the vector version of @xmath121 .",
    "therefore , conditional on @xmath122 , we have representation @xmath123 where @xmath124 is a gaussian random field with mean zero and @xmath125 whose form is given in ( [ et ] ) . since @xmath63 is six times differentiable",
    ", @xmath126 is at least four times differentiable .",
    "using the form of @xmath126 in ( [ et ] ) and @xmath127 in ( [ gamma ] ) , after some tedious calculations , we have @xmath128 \\delta e(0)&=&-ui+{\\mathbf z},\\qquad \\partial_{ijk}^{3}e(0)=y^{\\top}\\,\\partial_{ijk}\\mu_{1}(0),\\\\[-2pt ] \\partial_{ijkl}^{4}e(0 ) & = & ( u - w , u\\mu_{20}+z^{\\top})\\gamma ^{-1}\\pmatrix{\\partial_{ijkl}c(0 ) \\cr \\partial_{ijkl}\\mu_{2}(0)}.\\nonumber\\end{aligned}\\ ] ] in order to obtain the above identities , we need the following facts .",
    "the first , third and fifth derivatives of @xmath63 evaluated at @xmath129 are all zero . the first and second derivatives of @xmath63 are contained in @xmath110 and @xmath111 .",
    "we also need to use the fact that @xmath130 with the derivatives of @xmath126 , we can write @xmath131 if we let @xmath132 , then @xmath133 and @xmath134 is the remainder term of the taylor expansion .",
    "the taylor expansion of @xmath126 is the same as @xmath24 for the first two terms because @xmath124 is of order @xmath135 .",
    "it is not hard to check that @xmath136 for some @xmath137 and @xmath138 small enough .      for the comparison with the high excursion of @xmath41 ,",
    "we cite one result for homogeneous random fields , which has been proved in more general settings in many different ways .",
    "see , for instance , @xcite .",
    "this result is also useful for the proof of theorem [ thmm ] . for comparison purpose",
    ", we only present the result for the random fields discussed in this paper .",
    "[ thmpiterbarg ] suppose gaussian random field @xmath2 satisfies condi - tion  .",
    "there exists a constant @xmath139 such that @xmath140 as @xmath141 .",
    "we also present one existing result on the tail probability approximation of the sum of correlated log - normal random variables which provides intuitions on the analysis of @xmath40 .",
    "[ proplogn ] let @xmath142 be a multivariate gaussian random variable with mean @xmath143 and covariance matrix @xmath74 , with @xmath144 .",
    "then , @xmath145 as @xmath146",
    ".    the proof of this proposition can be found in @xcite .",
    "this result implies that the large value of @xmath147 is largely caused by one of the @xmath148 s being large . in the case",
    "that @xmath148 s are independent , proposition [ proplogn ] is a simple corollary of the subexponentiality of log - normal distribution .",
    "though the @xmath148 s are correlated , asymptotically they are tail - independent .",
    "the result presented in the next section can be viewed as a natural generalization of proposition [ proplogn ] . nevertheless , the techniques are quite different from the following aspects",
    ". first , proposition [ proplogn ] requires @xmath74 to be nondegenerated . for the continuous random fields ,",
    "this is usually not true . as shown in the analysis",
    ", we indeed need to study the sum of random variables whose correlation converges to  @xmath149 when @xmath7 tends to infinity .",
    "second , the approximation in ( [ logn ] ) is for a sum of a  fixed number of random variables .",
    "the analysis of the continuous field usually needs to handle the situation that the number of random variables in a  sum grows to infinity as @xmath1 .",
    "last but not least , to obtain approximations for @xmath150 , one usually needs to first obtain approximations for @xmath151 for some small domain @xmath152 .",
    "we will address all these issues in later sections .    for notation convenience , we write @xmath153 if there exists a constant @xmath137 independent of everything such that @xmath154 for all @xmath155 , and @xmath156",
    "if @xmath157 as @xmath141 and the convergence is uniform in other quantities . we write @xmath158 if @xmath159 and @xmath160 . in addition , we write @xmath161 if @xmath162 as @xmath163 .",
    "the main theorem of this paper is stated as follows .",
    "[ thmm ] let @xmath2 be a gaussian random field living on @xmath12 satisfying .",
    "given @xmath77 , for @xmath7 large enough , @xmath42 is the unique solution to equation @xmath164 then , @xmath165 as @xmath1 , where @xmath166 is the lebesgue measure of @xmath4 , @xmath167\\\\[-8pt ] & & { } \\times \\int_{r^{d(d+1)/2 } } \\exp\\biggl\\{-\\frac1 2 \\biggl [ b^\\top b + \\frac { ( \\mu_{20}\\mu_{22}^{-1/2}b + { \\mu_{20}\\mathbf1}/({2\\sigma}))^2}{1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02 } } \\biggr]\\biggr\\}\\,db , \\nonumber\\hspace*{-35pt}\\end{aligned}\\ ] ] @xmath127 is defined in ( [ gamma ] ) , @xmath94 , @xmath168 , @xmath169 are defined in the previous section and @xmath170    the integral in ( [ h ] ) is clearly in an analytic form . we write it as an integral because it arises naturally from the derivation .",
    "[ corsharp ] let @xmath2 be a gaussian random field living on @xmath12 satisfying .",
    "adopting all the notation in theorem [ thmm ] , let @xmath171 and @xmath172 then , @xmath173    the result is immediate by the taylor expansion on the left - hand side of equation ( [ u ] ) and note that @xmath174 .",
    "as we see , the asymptotic tail decaying rates of @xmath175 and @xmath176 take a very similar form .",
    "more precisely , @xmath177 with @xmath42 and @xmath7 connected via ( [ u ] ) .",
    "this fact suggests the following intuition on the tail probability of @xmath178 .",
    "first , the event @xmath179 has substantial overlap with event @xmath180 .",
    "it has been shown by many studies mentioned before that given @xmath42 sufficiently large @xmath181 is mostly caused by just a single @xmath182 being large for some @xmath183 .",
    "put these two facts together , @xmath179 is mostly caused by @xmath184 , for some @xmath183 not too close to the boundary of @xmath4 . therefore ,",
    "conditional on @xmath179 , the distribution of @xmath24 is very similar to the distribution conditional on @xmath181 . of course , these two conditional distributions are not completely identical",
    ". the difference will be discussed momentarily .",
    "now we perform some informal calculation to illustrate the shape of @xmath24 given @xmath185 .",
    "thanks to homogeneity , it is sufficient to study @xmath186 . given @xmath106 , @xmath187 since @xmath63 is 6 times differentiable , @xmath188 and @xmath189 , we obtain @xmath190 . for the exact slepian model of the random field",
    "given that @xmath2 achieves a local maximum at @xmath191 of level @xmath42 , see @xcite .",
    "note that for @xmath7 large , @xmath192 is approximately equivalent to @xmath193 in theorem [ thmm ] , this is exactly how @xmath42 is defined . as shown in figure [ figshift ] , the three curves are @xmath194 for different @xmath191 s .",
    "given that , these three curves are equally likely to occur .",
    "second , as mentioned before , the conditional distributions of @xmath24 are different given @xmath195 or @xmath180 .",
    "this is why the two constants in theorem  [ thmm ] ( @xmath196 ) and proposition [ thmpiterbarg ] ( @xmath139 ) are different .",
    "the difference is due to the fact that the symmetric difference between @xmath181 and @xmath197 is substantial though their overlap is significant too .",
    "consider the following situation that contributes to the difference .",
    "@xmath41 is slightly less than @xmath42 [ e.g. , by a magnitude of @xmath198 . for this case",
    ", @xmath178 still has a large chance to be greater than @xmath7 . for this sake we will need to consider the contribution of @xmath199 . as is shown in the technical proof , if @xmath200 and @xmath201 , then a sufficient and necessary condition for @xmath202 is that @xmath203 where @xmath204 denotes the trace of a squared matrix .",
    "note that conditional on @xmath106 , @xmath205 .",
    "therefore , @xmath206 is of size @xmath207 .",
    "one well - known result is that the trace of a symmetric matrix is the sum of its eigenvalues .",
    "let @xmath208 be the eigenvalues of @xmath209 .",
    "then , the sufficient and necessary condition is translated to @xmath210 .",
    "this also suggests that , conditional on @xmath211 , @xmath212 is of size  @xmath213 .",
    "this forms the intuition behind the proof of theorem [ propsmall ] .",
    "the proof of theorem [ thmm ] consists of two steps presented in sections [ secstep1 ] and [ secstep2 ] , respectively .",
    "each of the two steps is summarized as one theorem .",
    "construct a cover of @xmath4 , @xmath214 , such that @xmath215 .",
    "each @xmath51 is a closed square , @xmath216 for @xmath217 .",
    "because @xmath4 is jordan measurable , as @xmath218 , @xmath219 . to simplify the analysis",
    ", we make each @xmath51 of identical shape and let @xmath220^d\\}$ ] .",
    "the size of the partition @xmath50 and choice of @xmath221 depend on the threshold @xmath7 .",
    "the first step analysis involves computing the integral @xmath222 . because @xmath2 is homogeneous , it is sufficient to study  @xmath223 .",
    "the basic strategy to approximate @xmath223 is as follows . because @xmath2 is at least three times differentiable ,",
    "the first and second derivatives are almost surely well defined . without loss of generality , we assume that @xmath224 .",
    "conditional on @xmath225 , @xmath226 , where @xmath124 is a gaussian field with mean zero and variance of order @xmath227 .",
    "then , @xmath228\\\\[-8pt ] & & \\hphantom{\\int } { } \\times p\\biggl(\\int_{a_1 } e^{\\sigma[u - w + y^\\top t+ ( 1/2 ) t^\\top(-ui+{\\mathbf z } ) t + g_3(t ) + g_4(t ) + r(t)+g(t)]}\\,dt \\nonumber\\\\ & & \\hphantom{\\int { } \\times p\\biggl ( } { } > b \\biggr)\\,dw\\,dy\\,dz,\\nonumber\\end{aligned}\\ ] ] where @xmath229 is the density function of @xmath225 evaluated at @xmath230 , which is a multivariate gaussian random vector .",
    "let  @xmath42 be defined in ( [ u ] ) .",
    "there exists a @xmath231 ( small enough ) such that if we let  @xmath51 s be squares of size @xmath232 and , hence , @xmath233 , the asymptotics of @xmath54 can be derived by repeatedly using taylor s expansion and evaluating the integral on the right - hand side of ( [ p1 ] ) .",
    "the main result of this step is presented as follows .",
    "it establishes a similar result to that of theorem [ thmm ] but within a much smaller domain .",
    "[ propsmall ] let @xmath2 be a gaussian random field living in @xmath4 satisfying conditions .",
    "let @xmath234 .",
    "let @xmath42 and @xmath196 be defined in theorem [ thmm ] . without loss of generality ,",
    "assume @xmath152 with @xmath235 for some @xmath236 small enough and @xmath42 large enough .",
    "then , for any @xmath237 @xmath238 as @xmath146 .",
    "the proof of this theorem is in section [ sec_proof1 ] .",
    "we will then choose each @xmath51 to be of the same shape as @xmath239 .",
    "then , all the @xmath54 s are identical .",
    "the second step is to show that with the particular choice of  @xmath51 in the first step , @xmath240 .",
    "we first present the main result of the second step .",
    "[ propind ] let @xmath2 be a gaussian random field satisfying conditions   and @xmath241 be chosen in theorem [ propsmall ] .",
    "let @xmath242 and @xmath243 .",
    "further , let @xmath244 and @xmath245 , then @xmath246 and @xmath247    we consider @xmath248 as a sum of finitely many dependently and identically distributed random variables .",
    "the conclusion of the above theorem implies that the tail distribution of the sum of these dependent variables exhibits the so - called `` one big jump '' feature  the high excursion of the sum is mainly caused by just one component being large .",
    "this result is similar to that of the sum of correlated log - normal r.v.s .",
    "nevertheless , the gap between the analyses of finite sum and integral is substantial because the correlation between fields in adjacent squares tends to @xmath149 . for finite sums ,",
    "the correlation is always bounded away from @xmath149 .",
    "the key step in the proof of theorem [ propind ] is that the @xmath241 defined in theorem [ propsmall ] , though tends to zero as @xmath1 , is large enough such that the one - big - jump principle still applies .",
    "we will connect the event of high excursion of @xmath249 to the high excursion of @xmath250 and apply existing results on the bound on the supremum of gaussian random fields .",
    "a short list of recent related literature on the `` one - big - jump '' principle and multivariate gaussian random variables is @xcite .    with the preparation of the two steps , we are ready to present the proof for theorem [ thmm ] .",
    "proof of theorem [ thmm ] from theorem [ propsmall ] , @xmath251 therefore , thanks to theorem [ propind ] , @xmath252 similarly , @xmath253 jordan measurability of @xmath4 implies that @xmath254 therefore , @xmath255",
    "in this section we present the proof of theorem  [ propsmall ] .",
    "we arrange all the lemmas and their proofs in the .",
    "proof of theorem [ propsmall ] we evaluate the probability by conditioning on @xmath256 , @xmath257 where @xmath258 and @xmath229 is the density function of @xmath259 , @xmath260 evaluated at @xmath261 .",
    "now we take a closer look at the integrand inside the above integral .",
    "conditional on @xmath262 , @xmath263 , @xmath264\\biggr\\}\\,dt \\\\ & = & \\det(ui-{\\mathbf z})^{-1/2}\\\\ & & { } \\times\\int_{|(ui-{\\mathbf z})^{-1/2}t|_{\\infty } < \\varepsilon}e^{\\sigma\\{u - w+ ( { 1/2})y^{\\top}(ui-{\\mathbf z})^{-1}y\\ } } \\\\ & & { } \\times\\exp\\biggl\\{\\sigma\\biggl[-\\frac{1}{2}\\bigl(t-(ui-{\\mathbf z})^{-1/2}y\\bigr)^{\\top } \\bigl(t-(ui-{\\mathbf z})^{-1/2}y\\bigr)\\\\ & & \\hspace*{45.2pt } { } + g_{3}\\bigl((ui-{\\mathbf z})^{-1/2}t\\bigr ) + g_{4}\\bigl((ui-{\\mathbf z})^{-1/2}t\\bigr)\\\\ & & \\hspace*{69.6pt } { } + r\\bigl((ui-{\\mathbf z})^{-1/2}t\\bigr)+g\\bigl((ui-{\\mathbf z})^{-1/2}t\\bigr ) \\biggr]\\biggr\\}\\,dt.\\end{aligned}\\ ] ] for the second equality , we plugged in ( [ e ] ) .",
    "for the last step , we first change the variable from @xmath62 to @xmath265 and then write the exponent in a quadratic form of  @xmath62 .",
    "we write the term inside the exponent without the factor @xmath68 as @xmath266\\\\[-8pt ] & & { } + g_{4}\\bigl((ui-{\\mathbf z})^{-1/2}t\\bigr)+r\\bigl((ui-{\\mathbf z})^{-1/2}t\\bigr),\\nonumber\\end{aligned}\\ ] ] which is asymptotically a quadratic form .",
    "but , as is shown later , @xmath267 and @xmath268 terms do play a role in the calculation . also , it is useful to keep in mind that @xmath269 depends on @xmath270 and @xmath98 .",
    "hence , we can write @xmath271 let @xmath272 let @xmath42 solve @xmath273 then , @xmath274 if and only if @xmath275 we take the logarithm on both sides and rewrite the above inequality and have @xmath276 where @xmath277 is a random variable on the region that @xmath278 with density proportional to @xmath279 and @xmath280\\\\[-9pt ] & & { } + \\log \\int_{|(ui-{\\mathbf z})^{-1/2}t|<\\varepsilon}e^{\\sigma j(t)}\\,dt - h_{0}.\\nonumber\\end{aligned}\\ ] ]    thanks to lemma [ lemex1 ] , we only need to consider the set that @xmath281\\\\[-9pt ] & & \\hphantom{\\{}\\vert\\partial f ( 0 ) \\vert\\leq u^{{1 } /{2}+\\delta+\\varepsilon_{0}},\\vert\\partial ^{2}f(0)-u\\mu_{20}\\vert\\leq u^{{1/2}+\\varepsilon _ { 0}}\\}.\\nonumber\\end{aligned}\\ ] ] also , by abusing notation , we write @xmath282    lemma [ lemdensity ] gives the form of @xmath229 .",
    "we plug in the results in lemmas  [ lemex1 ] and  [ lemdensity ] , @xmath283 & & \\hphantom{\\int_{\\mathcal{r}}}{}\\times p\\bigl(a(w , y , z)+\\log e\\exp\\bigl(\\sigma g\\bigl((ui- { \\mathbf z})^{-1/2}s\\bigr)\\bigr)>0\\bigr)\\,dw\\,dy\\,dz \\nonumber\\\\[-2pt ] & = & o(1)u^{-\\alpha } e^{-u^{2}/2}\\nonumber\\\\[-0.4pt ] & & { } + \\int_{\\mathcal{l}}h(w , y , z)\\nonumber\\\\[-2pt ] & & \\hphantom{{}+\\int_{\\mathcal{l } } } { } \\times p\\bigl(a(w , y , z)+\\log e\\exp\\bigl ( \\sigma g\\bigl((ui-{\\mathbf z})^{-1/2}s\\bigr)\\bigr)>0 \\bigr)\\,dw\\,dy\\,dz \\nonumber\\\\[-2pt ] & = & o(1)u^{-\\alpha}e^{-u^{2}/2 } \\nonumber\\\\[-2pt ] & & { } + \\frac{1}{(2\\pi)^{(d+1)(d+2)/4}}|\\gamma    & & \\hspace*{11pt}{}\\times\\int_{\\mathcal{l}}p\\bigl(a(w , y , z ) + \\log e\\exp\\bigl(\\sigma g\\bigl((ui-{\\mathbf z})^{-1/2}s\\bigr)\\bigr)>0\\bigr)\\nonumber\\\\[-2pt ] & & \\hspace*{34.2pt}{}\\times\\exp\\biggl\\{-\\biggl[\\frac{1}{2}u^{2}+\\frac u \\sigma a(w , y , z)\\nonumber\\\\[-2pt ] & & \\hspace*{81.3pt}{}+\\frac{1}{2}y^{\\top } \\bigl(i-(i-{\\mathbf z}/u)^{-1}\\bigr)y \\nonumber\\\\[-2pt ] & & \\hspace*{81.3pt } { } + \\frac{1}{2}\\frac{(w+\\mu_{20}\\mu_{22}^{-1}z)^{2}}{1-\\mu _ { 20}\\mu_{22}^{-1}\\mu_{02}}+\\frac{1}{2}z^{\\top}\\mu _ { 22}^{-1}z\\nonumber\\\\[-2pt ] & & \\hspace*{81.3pt}{}+\\frac{u}{2\\sigma}\\log \\det(i - u^{-1}{\\mathbf z } ) \\nonumber\\\\[-2pt ] & & \\hspace*{81.3pt } { } -\\frac u\\sigma\\log\\int_{|(ui-\\mathbf z)^{-1/2}t|<\\varepsilon}e^{\\sigma j(t)}\\,dt+\\frac u\\sigma h_{0}\\biggr]\\biggr\\ } \\,dw\\,dy\\,dz.\\nonumber\\vadjust{\\goodbreak}\\end{aligned}\\ ] ] we define @xmath284 and proceed with some tedious algebra to write @xmath285 in a friendly form for integration .",
    "first notice that @xmath286 plug this into the third term of @xmath287 and obtain @xmath288      adopt the notation in lemmas [ lemg ] and [ lemj ] .",
    "note that according to the definition of @xmath289 in lemma [ lemg ] that @xmath290 we obtain that @xmath291 we plug in results of lemmas [ lemg ] and [ lemj ] .",
    "first , considering the first situation in lemma [ lemj ] , that is , @xmath292 , we have @xmath293 also , it is useful to keep in mind that @xmath294 is not a vector of @xmath149 s . the next step is to plug in the result of lemma [ lemdet ] and replace the @xmath295 term by @xmath296 & & \\qquad= -u^{-1 } \\mathbf1^\\top z + \\tfrac1 2 u^{-2 } \\mathcal e^2 ( { \\mathbf z } ) + o(u^{-1})\\end{aligned}\\ ] ] and obtain @xmath297 & & { } + \\frac{1}{2}\\frac{(w+\\mu_{20}\\mu_{22}^{-1}z)^{2}}{1-\\mu _ { 20}\\mu_{22}^{-1}\\mu_{02}}+\\frac{1}{2}z^{\\top}\\mu _ { 22}^{-1}z-\\frac{1}{2\\sigma } \\mathbf{1}^{\\top}z + \\frac1 { 4\\sigma u } \\mathcal e^2 ( { \\mathbf z } ) \\\\[2pt ] & & { } + \\frac{1}{8}(u^{-1}y+\\mathbf{1}/\\sigma)^{\\top}\\mu _ { 22}(u^{-1}y+\\mathbf{1}/\\sigma)- \\frac{1}{8\\sigma^2}\\mathbf{1}^{\\top}\\mu_{22}\\mathbf{1 } \\\\[2pt ] & & { } + \\frac u \\sigma h_{0}-\\frac u \\sigma h\\bigl((ui-\\mathbf{z})^{-1/2}y,(ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr)\\\\[2pt ] & & { } -\\frac{1}{8\\sigma^2}\\sum_{i}\\partial_{iiii}c(0)+o(1).\\end{aligned}\\ ] ] then , we group the terms @xmath298 and @xmath299 and leave the @xmath300 to the end and have @xmath301 & & { } + \\frac{1}{2}z^{\\top}\\mu _ { 22}^{-1}z-\\frac{1}{2}(u^{-1}y+\\mathbf{1}/\\sigma)^{\\top } z\\\\[2pt ] & & { } + \\frac{1}{8}(u^{-1}y+\\mathbf{1}/\\sigma)^{\\top}\\mu _ { 22}(u^{-1}y+\\mathbf{1}/\\sigma ) \\\\[2pt ] & & { } + \\frac u\\sigma h_{0}-\\frac u\\sigma h\\bigl((ui-\\mathbf { z})^{-1/2}y,(ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr ) \\\\[2pt ] & & { } -\\frac{1}{8\\sigma^2}\\mathbf{1}^{\\top}\\mu _ { 22}\\mathbf{1 } -\\frac{1}{8\\sigma^2 } \\sum_{i}\\partial_{iiii}c(0)+o(1)\\\\[2pt ] & & { } + o(u^{-2}|z|^2|y|^2 ) + o(u^{-1 } \\mathcal e^2 ( { \\mathbf z})).\\end{aligned}\\ ] ] note that second and third lines in the above display is in fact in a  quadratic form .",
    "we then have @xmath302 & & { } + \\frac{1}{2}\\biggl[\\mu_{22}^{-1/2}z-\\frac{1}{2}\\mu _ { 22}^{1/2}(u^{-1}y+\\mathbf{1}/\\sigma)\\biggr]^{\\top}\\\\[-2pt ] & & \\hspace*{11pt}{}\\times\\biggl[\\mu _",
    "{ 22}^{-1/2}z-\\frac{1}{2}\\mu _ { 22}^{1/2}(u^{-1}y+\\mathbf{1}/\\sigma)\\biggr ] \\\\[-2pt ] & & { } + \\frac u \\sigma h_{0}-\\frac u \\sigma h\\bigl((ui-\\mathbf { z})^{-1/2}y,(ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr)\\\\[-2pt ] & & { } -\\frac{1}{8\\sigma^2}\\mathbf{1}^{\\top}\\mu _ { 22}\\mathbf{1}-\\frac{1}{8\\sigma^2 } \\sum_{i}\\partial _ { iiii}c(0)+o(1)\\\\[-2pt ] & & { } + o(u^{-2}|z|^2|y|^2 ) + o(u^{-1 } \\mathcal e^2 ( { \\mathbf z})).\\end{aligned}\\ ] ] now , consider another change of variable , @xmath303\\\\[-9pt ] b&=&\\mu _ { 22}^{-1/2}z-\\tfrac{1}{2}\\mu_{22}^{1/2}(u^{-1}y+\\mathbf{1}/\\sigma ) , \\qquad y = y.\\nonumber\\end{aligned}\\ ] ] then , by noting that @xmath94 is a row vector in which the first @xmath3 entries are @xmath304 s and the rest are @xmath129 s , we have @xmath305 therefore , we have @xmath306 & & { } + \\frac{1}{2}\\frac{(-{a}/{\\sigma}+\\mu_{20}\\mu_{22}^{- { 1/2}}b+({1}/({2\\sigma}))\\mu_{20}\\mathbf{1}+o(1))^{2}}{1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02}}\\\\[-2pt ] & & { } + \\frac{u}{\\sigma}h_{0 } -\\frac{u}{\\sigma}h\\bigl((ui-\\mathbf { z})^{-1/2}y,(ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr)\\\\[-2pt ] & & { } -\\frac{1}{8\\sigma^{2 } } \\mathbf{1}^{\\top}\\mu_{22}\\mathbf{1 } - \\frac{1}{8\\sigma^{2}}\\sum_{i}\\partial_{iiii}c(0)+o(1)+o(u^{-2}|z|^{2}|y|^{2})+o(u^{-1}\\mathcal{e}^{2}({\\mathbf z})).\\end{aligned}\\ ] ] we write @xmath307 if @xmath308 in probability as @xmath141 .",
    "we insert the above form back to the integral in ( [ probs ] ) and apply lemma [ lemremainder ] , @xmath309 & & { } + \\frac{1}{(2\\pi ) ^{(d+1)(d+2)/4}}|\\gamma|^{-1/2}\\\\[-2pt ] & & \\hspace*{10pt}{}\\times\\int_{\\mathcal{l}}p\\bigl(u\\cdot a > o_{p}(1)\\bigr ) \\\\[-2pt ] & & \\hspace*{-24.5pt}\\hspace*{34.3pt}{}\\times\\exp\\biggl\\{-\\biggl[\\frac{1}{2}u^{2}+\\frac{u}{\\sigma}a+\\frac { 1}{2}b^{\\top}b\\\\[-2pt ] & & \\hspace*{-24.5pt}\\hspace*{81.7pt}{}+ \\frac{1}{2}\\frac{(-{a}/{\\sigma}+\\mu_{20}\\mu_{22}^{- { 1/2}}b+{1}/({2\\sigma})\\mu_{20}\\mathbf{1}+o(1))^{2 } } { 1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02 } } \\\\[-2pt ] & & \\hspace*{-24.5pt}\\hspace*{81.7pt } { } + \\frac{u}{\\sigma}h_{0}-\\frac{u}{\\sigma}h\\bigl((ui-\\mathbf { z})^{-1/2}y,(ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr ) \\\\[-2pt ] & & \\hspace*{-24.5pt}\\hspace*{81.7pt}{}-\\frac{1}{8\\sigma^{2}}\\mathbf{1}^{\\top}\\mu_{22}\\mathbf { 1}-\\frac{1}{8\\sigma^{2}}\\sum_{i}\\partial _ { iiii}c(0)+o(1)\\\\[-2pt ] & & \\hspace*{-24.5pt}\\hspace*{81.7pt}\\hspace*{51.4pt}{}+o(u^{-2}|z|^{2}|y|^{2})+o(u^{-1}\\mathcal{e}^{2}({\\mathbf z}))\\biggr]\\biggr\\}\\,dw\\,dy\\,dz.\\end{aligned}\\ ] ] note that jacobian determinant is @xmath310 note that when @xmath311 ( the first situation in lemma  [ lemj ] ) , @xmath312 then , with another change of variable , @xmath313 , the integration on @xmath314 is @xmath315 & & \\qquad=\\frac{|\\gamma|^{-1/2}}{(2\\pi)^{(d+1)(d+2)/4}}\\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times\\int_{\\mathcal{l}_{1}}p\\bigl ( u\\cdot a >",
    "o_{p}(1)\\bigr ) \\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times\\exp\\biggl\\{-\\biggl[\\frac{1}{2}u^{2}+\\frac{u}{\\sigma}a+\\frac { 1}{2}b^{\\top}b\\nonumber\\\\[-2pt ] & & \\qquad\\quad\\hspace*{-28.6pt}\\hspace*{74.88pt}{}+ \\frac{1}{2}\\frac{(-{a}/{\\sigma}+\\mu_{20}\\mu_{22}^{- { 1/2}}b+{1}/({2\\sigma})\\mu_{20}\\mathbf{1}+o(1))^{2 } } { { 1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02 } } } \\\\[-2pt ] & & \\qquad\\quad\\hspace*{-28.6pt}\\hspace*{73.8pt}{}+\\frac{u}{\\sigma}h_{0 } -\\frac{u}{\\sigma}h\\bigl((ui-\\mathbf { z})^{-1/2}y,(ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr)\\nonumber\\\\[-2pt ] & & \\qquad\\quad\\hspace*{-28.6pt}\\hspace*{73.8pt}{}-\\frac{1}{8\\sigma ^{2}}\\mathbf{1}^{\\top}\\mu_{22}\\mathbf{1}-\\frac{1}{8\\sigma^{2}}\\sum_{i}\\partial _ { iiii}c(0)+o(1 ) \\nonumber\\\\[-2pt ] & & \\qquad\\quad\\hspace*{-28.6pt}\\hspace*{130.6pt } { } + o(u^{-2}|z|^{2}|y|^{2})+o(u^{-1}\\mathcal{e}^{2}({\\mathbf z}))\\biggr]\\biggr\\}\\,dw\\,dy\\,dz \\nonumber\\\\[-2pt ] & & \\qquad=\\frac{\\sigma^{-1}|\\gamma|^{-1/2}}{(2\\pi)^{(d+1)(d+2)/4}}\\det ( \\mu_{22})^{1/2}\\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times e^{-({1/2})u^{2}+({1}/({8\\sigma^{2}}))\\mathbf{1}^{\\top}\\mu _ { 22}\\mathbf{1}+({1}/({8\\sigma^{2}}))\\sum_{i}\\partial_{iiii}c(0)}\\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times\\int_{\\mathcal{l } _ { 1}}p\\bigl(u\\cdot a > o_{p}(1)\\bigr ) \\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times\\exp\\biggl\\{-\\biggl[\\frac{u}{\\sigma}\\cdot a+\\frac{b^{\\top } b}{2}\\nonumber\\\\[-2pt ] & & \\qquad\\quad\\hspace*{46.7pt } { } + \\frac{(-{a}/{\\sigma}+\\mu_{20}\\mu_{22}^{-{1/2}}b+ { 1}/({2\\sigma})\\mu _ { 20}\\mathbf{1}+o(1))^2 } { 2(1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02 } ) } \\nonumber\\\\[-2pt ] & & \\qquad\\quad\\hspace*{46.7pt}\\hspace*{30.5pt } { } + o(1)+o\\bigl(u^{-2}|z|^{2}|y|^{2}+u^{-1}\\mathcal{e}^{2}({\\mathbf z})\\bigr)\\biggr]\\biggr\\}\\,da\\,db\\,dy \\nonumber\\\\[-2pt ] & & \\qquad=\\frac{\\sigma^{-1}|\\gamma|^{-1/2}}{(2\\pi)^{(d+1)(d+2)/4}}\\det ( \\mu _ { 22})^{1/2}u^{-1}\\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times e^{-({1/2})u^{2}+({1}/({8\\sigma^{2}}))\\mathbf { 1}^{\\top}\\mu_{22}\\mathbf{1}+({1}/({8\\sigma^{2}}))\\sum_{i}\\partial _ { iiii}c(0)}\\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times\\int_{\\mathcal{l}_{1}}p\\bigl(a^{\\prime}>o_{p}(1)\\bigr ) \\nonumber\\\\[-2pt ] & & \\qquad\\quad{}\\times\\exp\\biggl\\{-\\biggl[\\frac{a^{\\prime}}{\\sigma}+\\frac{b^{\\top } b}{2}\\nonumber\\\\[-2pt ] & & \\qquad\\quad\\hspace*{46.9pt}{}+\\frac{(-{a^{\\prime}}/({\\sigma u})+\\mu_{20}\\mu_{22}^{-{1/2}}b+ { 1}/({2\\sigma})\\mu_{20}\\mathbf{1}+o(1))^{2}}{2(1-\\mu_{20}\\mu_{22}^{-1}\\mu _ { 02})}\\nonumber\\\\[-2pt ] & & \\qquad\\quad\\hspace*{46.9pt}\\hspace*{34.6pt } { } + o(1)+o\\bigl(u^{-2}|z|^{2}|y|^{2}+u^{-1}\\mathcal{e}^{2}({\\mathbf z})\\bigr)\\biggr]\\biggr\\}\\,da^{\\prime}\\,db\\,dy . \\nonumber\\end{aligned}\\ ] ] the second equality is a change of variable from @xmath316 to @xmath317 .",
    "the third equality is a change of variable from @xmath317 to @xmath318 .",
    "note that @xmath319 as @xmath141 .",
    "in addition , on the set @xmath320 , @xmath321 by choosing @xmath236 and @xmath322 small enough , when @xmath323 , @xmath324 ; @xmath325 , @xmath326 , therefore , @xmath327 the integrant in ( [ l1 ] ) has the following bound , for @xmath328 @xmath329 \\hspace*{-5pt}&&\\hspace*{-1pt}\\quad{}\\times \\exp\\biggl\\{-\\biggl[\\frac{a^{\\prime}}{\\sigma}+\\frac{b^{\\top}b}{2}+ \\frac{(-{a^{\\prime}}/({\\sigma u})+\\mu_{20}\\mu _ { 22}^{-{1/2}}b+({1}/({2\\sigma}))\\mu_{20}\\mathbf { 1}+o(1))^{2}}{2(1-\\mu _ { 20}\\mu_{22}^{-1}\\mu_{02 } ) } \\\\[-2pt ] \\hspace*{-5pt}&&\\hspace*{-1pt}\\qquad\\quad\\hspace*{104.3pt } { } + o(1)+o\\bigl(u^{-2}|z|^{2}|y|^{2}+u^{-1}\\mathcal{e}^{2}({\\mathbf z})\\bigr)\\biggr]\\biggr\\ } \\\\[-2pt ] \\hspace*{-5pt}&&\\hspace*{-1pt}\\qquad\\leq 2\\exp\\biggl\\{\\!-\\frac{1}{\\delta^{\\prime}}\\biggl[\\frac{a^{\\prime } } { \\sigma}+\\frac{b^{\\top}b}{2}+\\frac{(-{a^{\\prime}}/({\\sigma u})+\\mu _ { 20}\\mu_{22}^{-{1/2}}b+({1}/({2\\sigma}))\\mu_{20}\\mathbf { 1})^{2}}{2(1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02})}\\biggr]\\biggr\\}\\end{aligned}\\ ] ] for @xmath330 small enough .",
    "note that the @xmath331 is in fact @xmath332 .",
    "thanks to the result of lemma [ lemremainder ] , the integral of the left - hand side of the above display in the region @xmath333 is @xmath334 . by dominated convergence theorem , ( [ l1 ] )",
    "equals @xmath335 & & \\quad{}\\times\\det(\\mu _ { 22})^{1/2}u^{-1}e^{-({1/2})u^{2}+({1}/({8\\sigma^{2}}))\\mathbf { 1}^{\\top}\\mu_{22}\\mathbf{1}+({1}/({8\\sigma^{2}}))\\sum_{i}\\partial _ { iiii}c(0 ) } \\nonumber\\\\[-2pt ] & & \\quad{}\\times\\int_{a^{\\prime}>0,|y|_{\\infty}<\\kappa u^{\\delta+1/2}-u^{\\delta /2 + 1/2}}\\exp\\biggl\\{-\\biggl[a^{\\prime}/\\sigma+\\frac{b^{\\top } b}{2}\\\\ & & \\qquad\\quad\\hspace*{97pt}{}+\\frac{(\\mu _",
    "{ 20}\\mu_{22}^{-{1/2}}b+({1}/({2\\sigma}))\\mu_{20}\\mathbf { 1})^{2}}{2(1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02})}\\biggr]\\biggr\\}\\,da^{\\prime}\\,db\\,dy\\hspace*{-1pt}\\nonumber\\\\[-2pt ] & & \\qquad=\\bigl(1+o(1)\\bigr)h{\\operatorname{mes}}(u\\xi_{\\varepsilon})u^{-1}e^{-({1/2})u^{2 } } , \\nonumber\\end{aligned}\\ ] ] where @xmath196 is defined in ( [ h ] ) .",
    "the above display is obtained by the fact that @xmath336",
    ".      for the second situation in lemma [ lemj ] , let @xmath337 and there exists @xmath338 such that @xmath339 & & \\quad{}\\times \\exp\\biggl\\ { -\\biggl[\\frac{1}{2}u^{2}+\\frac{u}{\\sigma}a+\\frac{1}{2}b^{\\top}b\\nonumber\\\\[-2pt ] & & \\quad\\hspace*{47.6pt}{}+\\frac{1}{2}\\frac { ( -{a/\\sigma}+\\mu_{20}\\mu_{22}^{-{1/2}}b+({1}/({2\\sigma}))\\mu _ { 20}\\mathbf{1}+o(1))^{2}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02 } } \\nonumber\\\\[-2pt ] & & \\quad\\hspace*{47.6pt } { } + \\frac{u}{\\sigma}h_{0}-\\frac{u}{\\sigma}h\\bigl((ui-\\mathbf { z})^{-1/2}y,(ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr)\\\\[-2pt ] & & \\quad\\hspace*{47.6pt}{}-\\frac{1}{8\\sigma ^{2}}\\mathbf{1}^{\\top}\\mu_{22}\\mathbf{1}-\\frac{1}{8\\sigma^{2}}\\sum_{i}\\partial _ { iiii}c(0)+o(1 ) \\nonumber\\\\[-2pt ] & & \\quad\\hspace*{134.7pt } { } + o(u^{-2}|z|^{2}|y|^{2})+o(u^{-1}\\mathcal{e}^{2}({\\mathbf z}))\\biggr]\\biggr\\}\\,dw\\,dy\\,dz \\nonumber\\\\[-2pt ] & & \\qquad\\leq \\bigl(c_{1}\\varepsilon_{1}^{d}+o(1)\\bigr)h { \\operatorname{mes}}(u\\xi_{\\varepsilon } ) u^{-1}e^{-({1/2})u^{2}}.\\nonumber\\vadjust{\\goodbreak}\\end{aligned}\\ ] ] for the third situation , @xmath340 , @xmath341\\\\[-8pt ] & & \\quad\\hspace*{47.3pt}{}-\\frac{1}{8\\sigma ^{2}}\\mathbf{1}^{\\top}\\mu_{22}\\mathbf{1}-\\frac{1}{8\\sigma^{2}}\\sum_{i}\\partial _ { iiii}c(0)+o(1 ) \\nonumber\\\\ & & \\quad\\hspace*{135pt } { } + o(u^{-2}|z|^{2}|y|^{2})+o(u^{-1}\\mathcal{e}^{2}({\\mathbf z}))\\biggr]\\biggr\\}\\,dw\\,dy\\,dz \\nonumber\\\\ & & \\qquad\\leq o(1)\\biggl(\\frac{1}{2}\\biggr)^{u/\\sigma}u^{-1}u^{({1/2}+\\delta + \\varepsilon _ { 0})d}e^{-({1/2})u^{2}}\\nonumber\\\\ & & \\qquad = o(1){\\operatorname{mes}}(u\\xi_{\\varepsilon } ) u^{-1}e^{-(1/2)u^{2}}.\\nonumber\\end{aligned}\\ ] ] we put ( [ apxl1 ] ) , ( [ apxl2 ] ) and ( [ apxl3 ] ) together and conclude the proof .",
    "similar to section [ sec_proof1 ] , we arrange all the lemmas and their proofs in the .    proof of theorem [ propind ] since the proofs for @xmath342 and @xmath343 are complete analogue , we only provide the proof for @xmath344 .",
    "we prove for the asymptotics by providing bounds from both sides .",
    "we first discuss the easy case : the lower bound .",
    "note that @xmath345 thanks to lemma [ lempair ] , @xmath346 the rest of the proof is to establish the asymptotic upper bound . to simplify our writing",
    ", we let @xmath347 } \\xi_{\\varepsilon,{\\mathbf k}'}\\biggr),\\hspace*{-35pt}\\ ] ] where @xmath348 is the set of neighbors of @xmath239 , that is , @xmath349 if and only if @xmath350 an illustration of @xmath351 , @xmath352 and @xmath353 is given in figure [ figsq ] .    ,",
    "@xmath21 and @xmath354 . ]",
    "further , let @xmath355 and @xmath356 solves @xmath357 and there exists @xmath358 such that @xmath359 .",
    "the first step in developing the upper bound is to use the following inequality @xmath360 & & \\qquad\\leq p({\\mathcal a } > b - b_0 ) + p({\\mathcal a}\\leq b_0 , { \\mathcal a}+ { \\mathcal b}+{\\mathcal d}>b)\\nonumber\\\\[2pt ] & & \\qquad\\quad { } + p(b_0 < { \\mathcal a}\\leq b - b_0 , { \\mathcal a}+ { \\mathcal b}+{\\mathcal d}>b)\\\\[2pt ] & & \\qquad\\leq p({\\mathcal a } > b - b_0)+ p({\\mathcal b}+{\\mathcal d}>b - b_0 ) \\nonumber\\\\[2pt ] & & \\qquad\\quad{}+ p({\\mathcal a}>b_0,{\\mathcal b}+ { \\mathcal d}>b_0 , { \\mathcal a}+ { \\mathcal b}+ { \\mathcal d } > b).\\nonumber\\end{aligned}\\ ] ] from theorem [ propsmall ] , @xmath361 the next step is to show that the last term in ( [ upper ] ) is ignorable . note that @xmath362 & & \\qquad = p ( { \\mathcal a}+{\\mathcal b}>b - b_{0},{\\mathcal a}>b_{0},{\\mathcal b}+{\\mathcal d}>b_{0},{\\mathcal a}+{\\mathcal b}+{\\mathcal d}>b ) \\\\[-2pt ] & & \\qquad\\quad { } + p ( { \\mathcal d}>b - b_{0},{\\mathcal a}>b_{0},{\\mathcal b}+{\\mathcal d}>b_{0},{\\mathcal a}+{\\mathcal b}+{\\mathcal d}>b ) \\\\[-2pt ] & & \\qquad\\quad{}+p ( { \\mathcal a}+{\\mathcal b}>b_{0},{\\mathcal d}>b_{0},{\\mathcal a}>b_{0},{\\mathcal b}+{\\mathcal d}>b_{0},{\\mathcal a}+{\\mathcal b}+{\\mathcal d}>b )   \\\\[-2pt ] & & \\qquad\\leq p ( { \\mathcal a}+{\\mathcal b}>b - b_{0},{\\mathcal a}>b_{0},{\\mathcal b}+{\\mathcal d}>b_{0},{\\mathcal a}+{\\mathcal b}+{\\mathcal d}>b)\\\\[-2pt ] & & \\qquad\\quad { } + 2p ( { \\mathcal d}>b_{0},{\\mathcal a}>b_{0})\\\\[-2pt ] & & \\qquad= o\\bigl(p ( { \\mathcal a}>b)\\bigr).\\end{aligned}\\ ] ] the last step is due to lemmas [ lemad ] and [ lemlast ] . by noting that @xmath363 , the conclusion of the theorem is immediate by induction , where @xmath364 is the cardinality of a set .",
    "lemma [ lemex1 ] isolated the dominating event so that we will be in good shape to use taylor s expansion .    [ lemex1 ] there exist @xmath365 small enough and @xmath366 large .",
    "let @xmath367 such that for any @xmath368 , @xmath369 & & \\hspace*{21.2pt}\\vert \\partial ^{2}f(0)-u\\mu_{20}\\vert > u^{{1}/{2}+\\varepsilon _ { 0}},\\int{\\xi_\\varepsilon}e^{f ( t ) } \\,dt > b\\biggr ) \\\\[-2pt ] & & \\qquad = o ( 1 ) u^{-\\alpha}e^{-({1}/{2})u^{2}}.\\end{aligned}\\ ] ]    note that there exists @xmath370 such that @xmath371 .",
    "let @xmath372 .",
    "since we only consider the case that @xmath42 is large , we always have : @xmath373 & & \\qquad\\leq p\\bigl(f(0)<u - u^{2\\delta+\\varepsilon_{0}},\\sup f(t)>\\tilde{u}\\bigr ) \\\\[-2pt ] & & \\qquad\\leq cp\\bigl(f(0)<u - u^{2\\delta+\\varepsilon_{0}}|\\sup f(t)>\\tilde { u}\\bigr)\\tilde{u}^{d-1}e^{-\\tilde{u}^{2}/2}.\\end{aligned}\\ ] ] the last inequality is an application of proposition [ thmpiterbarg ] . because for any @xmath374 , for some @xmath375 , @xmath376 & & \\qquad\\geq u^{\\prime}\\inf_{t\\in\\xi_{\\varepsilon}}c(t)\\geq u-\\kappa ^{2}\\varepsilon_{1}u^{2\\delta}\\bigl(1+o(1)\\bigr)\\vadjust{\\goodbreak}\\end{aligned}\\ ] ] and @xmath377 one can choose @xmath366 large enough such that @xmath378 therefore , @xmath379 for all @xmath380 .",
    "also , @xmath381 .",
    "similarly , we have @xmath383 the above two displays are immediate by noting that @xmath384 is a multivariate gaussian random vector .",
    "in addition , @xmath385 is independent of @xmath100 and the covariance between @xmath102 and @xmath96 is @xmath168 .",
    "the form of @xmath389 in ( [ gammainv ] ) is a result from linear algebra .",
    "the form of @xmath389 is direct application of the block matrix inverse from linear algebra .",
    "note that @xmath390 by plugging in the form of @xmath389 , we have @xmath391(z+u\\mu_{02 } ) \\\\ & & \\qquad\\quad { } -2(u - w)\\frac{\\mu_{20}\\mu_{22}^{-1}}{1-\\mu_{20}\\mu _ { 22}^{-1}\\mu_{02 } } ( z+u\\mu_{02 } ) \\\\ & & \\qquad= u^{2}+y^{\\top}y-2wu+\\frac{w^{2}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu _ { 02 } } \\\\ & & \\qquad\\quad { } + z^{\\top}\\biggl[\\mu_{22}^{-1}+\\frac{\\mu_{22}^{-1}\\mu_{02}\\mu _ { 20}\\mu_{22}^{-1}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu _ { 02}}\\biggr]z+2w\\frac{\\mu_{20}\\mu _ { 22}^{-1}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02}}z \\\\ & & \\qquad= u^{2}+\\frac{2u}{\\sigma}a(w , y , z)+y^{\\top } \\bigl(i-(ui-{\\mathbf z})^{-1}\\bigr)y+\\frac{(w+\\mu_{20}\\mu _ { 22}^{-1}z)^{2}}{1-\\mu_{20}\\mu_{22}^{-1}\\mu_{02 } } \\\\ & & \\qquad\\quad { } + z^{\\top}\\mu_{22}^{-1}z+\\frac u\\sigma\\log\\det(i - u^{-1}{\\mathbf z})\\\\ & & \\qquad\\quad{}-\\frac{2u}{\\sigma}\\log \\int_{|(ui-{\\mathbf z})^{-1/2}t|<\\varepsilon}e^{j(t)}\\,dt+\\frac{2u}{\\sigma}h_{0}.\\end{aligned}\\ ] ] therefore , we conclude the proof .          using the derivatives in ( [ derivative ] ) , we have that @xmath401 we plug this into the definition of @xmath267 and @xmath268 in ( [ g34 ] ) and obtain , on the set @xmath398 , @xmath402 & & \\qquad=-\\frac{1}{6}u^{-3/2}\\sum_{ijkl}\\partial^4 _ { ijkl}c(0)e(x_{i}x_{j}x_{k}y_{l})\\\\[-2pt ] & & \\qquad\\quad{}+\\frac{u^{-1}}{24}\\sum _ { ijkl}\\partial^4 _ { ijkl}c(0)e(x_{i}x_{j}x_{k}x_{l } ) + o(u^{-1})\\\\[-2pt ] & & \\qquad=-\\frac{1}{8}u^{-3/2}\\sum_{ijkl}\\partial^4 _ { ijkl}c(0)e(x_{i}x_{j}x_{k}y_{l})\\\\[-2pt ] & & \\qquad\\quad{}+\\frac{u^{-1}}{24}\\sum _ { ijkl}\\partial^4 _ { ijkl}c(0)e\\bigl(x_{i}x_{j}x_{k}\\bigl(x_{l}-y_{l}/\\sqrt{u}\\bigr)\\bigr ) + o(u^{-1})\\\\[-2pt ] & & \\qquad=-\\frac{1}{8}u^{-3}\\sum_{ijkl}\\partial^4 _ { ijkl}c(0)y_{i}y_{j}y_{k}y_{l}- \\frac{3}{8\\sigma}u^{-2}\\sum_{il}y_{i}y_{l}\\sum_{j}\\partial^4 _ { iljj}c(0 ) \\\\[-2pt ] & & \\qquad\\quad { } + \\frac{u^{-2}}{8\\sigma}\\sum_{ij}y_{i}y_{j}\\sum_{l}\\partial^4 _ { ijll}c(0)+\\frac { 3u^{-1}}{24\\sigma^2}\\sum_{i}\\partial^4 _ { iiii}c(0 ) + o(u^{-1})\\\\[-2pt ] & & \\qquad=-\\frac{1}{8}u^{-3}\\sum_{ijkl}\\partial^4 _ { ijkl}c(0)y_{i}y_{j}y_{k}y_{l}- \\frac{1}{4\\sigma}u^{-2}\\sum_{ij}y_{i}y_{j}\\sum_{l}\\partial^4 _ { ijll}c(0)\\\\[-2pt ] & & \\qquad\\quad{}+\\frac{u^{-1 } } { 8\\sigma^2}\\sum_{i}\\partial^4 _ { iiii}c(0 ) + o(u^{-1}).\\end{aligned}\\ ] ] this last step is true because @xmath403 , which is just a change of index .",
    "then , with the definition of @xmath289 and @xmath294 in the statement of this lemma ( note that @xmath294 is not a vector of @xmath149 s ) , we have @xmath402 & & \\qquad=-\\frac{u^{-3}}{8}y^{\\top}\\mu _ { 22}y-\\frac{u^{-2}}{4\\sigma}y^{\\top}\\mu_{22 } \\mathbf{1}+\\frac{u^{-1}}{8\\sigma^2}\\sum_{i}\\partial^4 _ { iiii}c(0 ) + o(1)\\\\[-2pt ] & & \\qquad=-\\frac{u^{-1}}{8}(u^{-1}y+\\mathbf{1}/\\sigma)^{\\top}\\mu _ { 22}(u^{-1}y+\\mathbf{1}/\\sigma)+\\frac{u^{-1}}{8\\sigma^2}\\mathbf { 1}^{\\top } \\mu_{22}\\mathbf{1}\\\\[-2pt ] & & \\qquad\\quad{}+\\frac{u^{-1}}{8\\sigma^2 } \\sum_{i}\\partial^4 _ { iiii}c(0)+o(1).\\end{aligned}\\ ] ]      when @xmath406 , @xmath407 & & \\qquad= \\exp\\bigl [ \\sigma e\\bigl(g_{3}\\bigl(x/\\sqrt{u}\\bigr)+g_{4}\\bigl(x/\\sqrt{u}\\bigr)\\bigr)\\\\[-2pt ] & & \\qquad\\quad\\hspace*{17.6pt}{}+h\\bigl((ui-\\mathbf{z})^{-1/2}y , ( ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr)+o(u^{-1})\\bigr],\\end{aligned}\\ ] ] where @xmath408 and @xmath409 is the random vector defined in lemma [ lemg ] .",
    "in addition , @xmath410    for any @xmath411 , when @xmath412 , @xmath413 & & \\qquad\\leq \\exp\\bigl [ \\sigma e\\bigl(g_{3}\\bigl(x/\\sqrt{u}\\bigr)+g_{4}\\bigl(x/\\sqrt{u}\\bigr)\\bigr)\\\\[-2pt ] & & \\qquad\\quad\\hspace*{17pt } { } + h\\bigl((ui-\\mathbf{z})^{-1/2}y , ( ui-\\mathbf{z})^{1/2},\\varepsilon\\bigr)+o(u^{-1})\\bigr].\\end{aligned}\\ ] ]      note that @xmath415 & & \\qquad = e^{h((ui-{\\mathbf z})^{-1/2}y,(ui-{\\mathbf z})^{-1/2},\\varepsilon ) } \\\\[-2pt ] & & \\qquad\\quad\\hspace*{0pt}{}\\times e\\bigl\\ { \\exp\\bigl [ \\sigma g_{3}\\bigl((ui-{\\mathbf z})^{-1/2}x^{\\prime}\\bigr)\\\\[-2pt ] & & \\qquad\\quad\\hspace*{24pt}{}+\\sigma g_{4}\\bigl((ui-{\\mathbf z})^{-1/2}x^{\\prime}\\bigr)+\\sigma r\\bigl((ui-{\\mathbf z } ) ^{-1/2}x^{\\prime}\\bigr)\\bigr ] ; \\\\[-2pt ] & & \\qquad\\quad\\hspace*{149.2pt}|(ui-\\mathbf{{\\mathbf z } } ) ^{-1/2}x^{\\prime}|<\\varepsilon\\bigr\\ } .\\end{aligned}\\ ] ] also , @xmath416 and @xmath417 for the first situation , @xmath418 and @xmath419,@xmath420 ; \\\\[-2pt ] & & \\hspace*{252.8pt}|(ui-\\mathbf{z } ) ^{-1/2}x^{\\prime}|<\\varepsilon\\bigr\\ } \\\\[-2pt ] & & \\qquad = e\\bigl\\ { \\exp\\bigl [ \\sigma g_{3}\\bigl(x^{\\prime } /\\sqrt{u}\\bigr)+\\sigma",
    "g_{4}\\bigl(x^{\\prime}/\\sqrt{u } \\bigr)+\\sigma r\\bigl(x^{\\prime}/\\sqrt{u}\\bigr)+o(u^{-1})\\bigr ] ; \\\\[-2pt ] & & \\hspace*{219.2pt}|(ui-\\mathbf{z})^{-1/2}x^{\\prime}|<\\varepsilon\\bigr\\ } \\\\[-2pt ] & & \\qquad = e\\bigl\\ { \\exp\\bigl [ \\sigma g_{3}\\bigl(x^{\\prime } /\\sqrt{u}\\bigr)+\\sigma",
    "g_{4}\\bigl(x^{\\prime}/\\sqrt{u } \\bigr)+\\sigma r\\bigl(x^{\\prime}/\\sqrt{u}\\bigr)+o(u^{-1})\\bigr ] \\bigr\\ } \\\\[-2pt ] & & \\qquad = e\\bigl\\ { \\exp\\bigl [ \\sigma g_{3}\\bigl(x/\\sqrt{u}\\bigr)+\\sigma g_{4}\\bigl(x/\\sqrt{u}\\bigr)+\\sigma r\\bigl(x/\\sqrt{u } \\bigr)+o(u^{-1})\\bigr ] \\bigr\\ } .\\end{aligned}\\ ] ] in addition , because @xmath421 , then@xmath422 \\bigr\\ } \\\\ & & \\qquad = e\\bigl\\ { \\exp\\bigl [ \\sigma g_{3}\\bigl(x/\\sqrt{u}\\bigr)+\\sigma g_{4}\\bigl(x/\\sqrt{u}\\bigr)+o(u^{-1})\\bigr ] \\bigr\\}.\\vadjust{\\goodbreak}\\end{aligned}\\ ] ] further , @xmath423 and @xmath424 , then by repeatedly using talyor s expansion , we have @xmath425 ; |(ui-\\mathbf{z})^{-1/2}x^{\\prime } |<\\varepsilon\\bigr\\ } \\\\ & & \\qquad=\\exp\\bigl\\ { e\\bigl [ \\sigma g_{3}\\bigl(x/\\sqrt{u}\\bigr)+\\sigma g_{4}\\bigl(x/\\sqrt{u}\\bigr)+o(u^{-1})\\bigr ] \\bigr\\}.\\end{aligned}\\ ] ] for the second situation , the inequality is immediate by noting that @xmath426 ; |(ui-\\mathbf{z})^{-1/2}x^{\\prime } |<\\varepsilon\\bigr\\ } \\\\ & & \\qquad\\leq e\\bigl\\ { \\exp\\bigl [ \\sigma g_{3}\\bigl(x^{\\prime } /\\sqrt{u}\\bigr)+\\sigma g_{4}\\bigl(x^{\\prime}/ \\sqrt{u}\\bigr)+\\sigma r\\bigl(x^{\\prime}/\\sqrt{u}\\bigr)\\bigr ] \\bigr\\}.\\end{aligned}\\ ] ] for the third situation , note that the integral is not focusing on the dominating part , and the conclusion follows immediately .      [ lemborel ]",
    "let @xmath24 , @xmath427 , @xmath428 is a parameter set , be a mean zero gaussian random field .",
    "@xmath2 is almost surely bounded on @xmath428 .",
    "then , @xmath429 and @xmath430\\geq b\\bigr)\\leq e^ { -{b^{2}}/({2\\sigma_{\\mathcal{u}}^{2 } } ) } , \\ ] ] where @xmath431.\\ ] ]          without loss of generality , we consider @xmath440 .",
    "if @xmath441 and  @xmath442 are connected to each other , @xmath443 the second step is an application of theorem [ propsmall ] . if @xmath441 and @xmath444 are not connected , that is , @xmath445 , then @xmath446 & & \\qquad\\leq p\\bigl(\\sup_{t\\in\\xi _ { \\varepsilon}}f(t)>u - c\\log u,\\sup_{t\\in\\xi _ { \\varepsilon,{\\mathbf k}}}f(t)>u - c\\log u\\bigr ) \\\\[-1.3pt ] & & \\qquad\\leq p\\bigl(\\sup_{t\\in\\xi_{\\varepsilon},s\\in\\xi_{\\varepsilon,{\\mathbf k}}}f(t)+f(s)>2u-2c\\log u\\bigr ) \\\\[-1.3pt ] & & \\qquad\\leq o(1)p\\biggl ( z>\\frac{2u-2c\\log u + o(1)}{\\sqrt{4-\\theta(1)u^{-1 + 2\\delta } } } \\biggr ) \\\\[-1.3pt ] & & \\qquad= o(1)u^{d-1}e^{-({1/2})u^{2}-\\theta(1)u^{1 + 2\\delta}},\\end{aligned}\\ ] ] where @xmath447 is a standard gaussian random variable .",
    "the last inequality is an application of the borel - tis lemma in lemma [ lemborel ] .",
    "similar to the second case in the proof of lemma [ lempair ] , we have @xmath450 & & \\qquad\\leq p\\bigl ( \\sup_{\\xi_{\\varepsilon}}f(t)>u - c_{1}\\log u,\\sup_{\\bigcup_{{\\mathbf k}\\in c^{+}\\setminus\\{\\mathbf0,{\\mathbf k}\\}}\\xi _ { \\varepsilon,{\\mathbf k}}}f(t)>u - c_{1}\\log u\\bigr ) \\\\[-1.3pt ] & & \\qquad\\leq p\\bigl ( \\sup_{s\\in\\xi_{\\varepsilon},t\\in\\bigcup _ { { \\mathbf k}\\in c^{+}\\setminus\\{\\mathbf0,{\\mathbf k}\\}}\\xi_{\\varepsilon , { \\mathbf k}}}f(s)+f(t)>2u-2c_{1}\\log u\\bigr ) \\\\[-1.3pt ] & & \\qquad\\leq u^{\\alpha}e^{-{(2u-2c_{1}\\log u)^{2}}/({2(4 - 2\\kappa ^{2}u^{-1 + 2\\delta})})}\\leq e^{-{u^{2}}/{2}-\\theta(1)u^{1 + 2\\delta}}.\\end{aligned}\\ ] ] the conclusion follows immediately .",
    "note that there exists @xmath452 such that @xmath453 & & \\qquad\\leq p\\bigl ( \\mathcal{a}+\\mathcal{b}>b - b_{0},\\sup_{\\xi _ { \\varepsilon}}f(t)>u - c^{\\prime}\\log u,\\\\[-1.3pt ] & & \\qquad\\hspace*{65.3pt}\\sup_{\\bigcup_{{\\mathbf k}\\in\\mathcal{c}^{+}\\setminus\\{\\mathbf{0 } \\}}\\xi_{\\varepsilon , { \\mathbf k}}}f(t)>u - c^{\\prime}\\log u\\bigr).\\end{aligned}\\ ] ] it suffices to show that the right - hand side of the above inequality is@xmath454 and also @xmath455 . in order to do so",
    ", we will borrow part of the derivations in the proof of theorem [ propsmall ] .",
    "let @xmath456 solve @xmath457 note that because @xmath458 , we have @xmath459 and @xmath460 . by the results in ( [ apxl1 ] ) , ( [ apxl2 ] ) and ( [ apxl3 ] ) , we have @xmath461\\biggr\\}\\,da^{\\prime}\\,db\\,dy.\\end{aligned}\\ ] ] note that the only change in the above display from ( [ apxl1 ] ) is the probability inside the integral .",
    "in what follows , we show that it is almost always @xmath334 .",
    "note that @xmath436 . therefore , for any @xmath462 with @xmath463 , if @xmath464\\\\[-8pt ] \\sup_{\\xi_{3\\varepsilon}\\setminus\\xi_{\\varepsilon } } e(t ) & < & u - c'\\log u -\\theta(u^{-1}),\\nonumber\\end{aligned}\\ ] ] then @xmath465 this fact implies that @xmath124 can be basically ignored .",
    "therefore , it is useful to keep in mind that `` @xmath466 . ''    since @xmath467 we only need to consider the case that @xmath468 . given the form @xmath469 which is asymptotically quadratic in @xmath470 , let @xmath471 . on the set that @xmath468 , we have @xmath472 let @xmath473 be the border of @xmath239 .",
    "then @xmath474\\\\[-8pt ] \\sup_{\\xi_{3\\varepsilon}\\setminus\\xi_{\\varepsilon } } e(t ) & > & u - c'\\log u -\\theta(u^{-1}),\\nonumber\\end{aligned}\\ ] ] only when @xmath475 .",
    "this implies that @xmath476 must be very closed to the boundary of @xmath239 so as to have ( [ both ] ) hold .",
    "therefore , for all @xmath477 @xmath478\\biggr\\}\\,da'\\,db\\,dy\\\\ \\hspace*{-4pt}&&\\qquad= o(1)p(\\mathcal{a}+\\mathcal{b}>b - b_{0}).\\end{aligned}\\ ] ] the last equation is because @xmath479 hereby , we conclude the proof ."
  ],
  "abstract_text": [
    "<S> this paper develops asymptotic approximations of @xmath0 as @xmath1 for a homogeneous smooth gaussian random field , @xmath2 , living on a compact @xmath3-dimensional jordan measurable set @xmath4 . </S>",
    "<S> the integral of an exponent of a gaussian random field is an important random variable for many generic models in spatial point processes , portfolio risk analysis , asset pricing and so forth .    </S>",
    "<S> the analysis technique consists of two steps : 1 . </S>",
    "<S> evaluate the tail probability @xmath5 over a small domain @xmath6 depending on @xmath7 , where @xmath8 as @xmath9 and @xmath10 is the lebesgue measure ; 2 . with @xmath6 </S>",
    "<S> appropriately chosen , we show that @xmath11 .    .    </S>"
  ]
}