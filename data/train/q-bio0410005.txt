{
  "article_text": [
    "it is possible to consider that cognitive psychology appeared as a reaction to behaviorist approaches , where the mental content plays the role of a black box @xcite . in contrast",
    ", this content constitutes a central issue in cognitive sciences .",
    "consequently , the use of computers to implement or imitate human intellectual tasks naturally emerged as a methodological tool , and even as a powerful metaphor , in the investigation of mental processes such as intelligence , learning , memorization , among others .",
    "it is along these lines that we prepared a sequence of experiments with humans , to be later on compared with similar experiments , or simulations , done with computers provided with appropriate algorithms , in particular simple perceptrons .",
    "it should of course be clear that such comparisons have philosophical implications ( see , for instance , @xcite ) , which we address in the present work only in the conclusions ( section v ) .    in the present study ,",
    "two different memorization tasks were implemented .",
    "the first of them was relatively simple , namely the memorization of simple binary codes in @xmath0 and @xmath6 matrices .",
    "most of the present effort is dedicated to this analysis .",
    "the second task was , intellectually speaking , sensibly more complex .",
    "it consisted of learning ambiguous images , where the figure - background reversal is crucial .",
    "although semantic and strategic aspects are present in both learning tasks , the second one is by far more delicate and reveals higher level cognitive phenomena .",
    "consistently , our study leads to quantitative information concerning the first task , whereas only some qualitative features were determined for the latter .    at the level of the comparison with computational simulations ,",
    "our emphasis is put on whether learning occurs in an _ extensive _ or a _ nonextensive _ manner .",
    "these terms will be mathematically defined and further analyzed in section iii .",
    "they are currently used in statistical mechanics and thermodynamics , branches of physics dedicated to the study of the connections between the microscopic and the macroscopic worlds . at the present stage ,",
    "it is enough to think of extensivity as a form of _ nonglobality _ or _ locality _",
    "@xcite , as opposed to nonextensivity or _",
    "globality _ or _",
    "nonlocality_. in a loose manner , they respectively correspond to the _ molecular _ and _ molar _ approaches in psychology , i.e. , the system is perceived as the sum of its parts , or as different from the sum of its parts .    in section",
    "ii we present the experimental study with humans . in section iii",
    "we describe the entropic concepts that we use with regard to the computational simulations that have been implemented . in section",
    "iv we compare both approaches , namely with humans and computers . finally , we conclude in section v.",
    "the experiment consists in individually learning fixed binary codes ( represented by the signs * @xmath7 * and * @xmath8 * ) in @xmath9 matrices .",
    "it was presented to each person , initially one @xmath0 matrix ( see fig . 1 ) and , then , two @xmath10 binary matrices ( see figs . 2 and 3 ) . in order to avoid any kind of uncontrolled cultural effect , the location of the symbols @xmath7 and @xmath8 in all the matrices was randomly generated by computer and fixed once for ever .",
    "it was carried out with approximatively 150 university students whose specialty was not directly related to geometry , mathematics or images , in order to avoid professional bias .",
    "for instance , students of physics , mathematics , engineering , architecture , visual publicity were excluded .",
    "the experiment population was mainly constituted by students of psychology , administration , social service and social comunication of the federal university of rio de janeiro .",
    "approximately 30 students were used for preliminary tests in order to fix an optimal experimental protocol ( matrix sizes , binary code of each matrix , exhibition and hiddening times , among others ) .",
    "then , precisely 120 ( 92 female and 28 male ) students were exposed to the same protocol , and only their results were taken into account for quantitative purposes in the statistical processing ( averaging , in particular ) .",
    "their ages ranged between 17 and 27 years old , the majority of them being around 22 years old .",
    "each of them was sequentially isolated in a peaceful room and tested , for about 40 minutes , by one of us .",
    "information about the scope of the research was given to each one of the 120 individuals .",
    "it was told that the experiment was not measuring their intelligence ( so that they would feel relaxed ) , and that it was important for understanding how learning occurs ( so that they would seriously try to perform satisfactorily ) .",
    "after these instructions were given to each one of the 120 students , three matrices were shown . in all cases ,",
    "a @xmath0 matrix was first shown , one of the two complementary matrices ( i.e , obtained by interchanging the symbols * + * and * o * ) .",
    "then , one of the four @xmath10 matrices was shown ( matrix in fig .",
    "2 to 30 students , matrix in fig . 3 to other 30 , and so on ) . then the other noncomplementary @xmath10 matrix was shown .",
    "the sequence of each individual test was as follows : + _ ( 1 ) _ after some general explanations , an empty @xmath0 matrix and the @xmath8 and @xmath7 symbols were shown , and the subjects were asked to randomly fill the matrix with the two symbols .",
    "this step aimed to provide to the individuals some familiarity with the experiment ; + _ ( 2 ) _ then fig . 1 was exhibited during 8 seconds and then hidden . the student had to try to reproduce it on the spot on an empty matrix .",
    "when this was done , the operation was repeated after a rest interval of 10 seconds .",
    "the @xmath0 matrix was never shown more than 10 times ( the individuals started feeling tired after 10 times ) .",
    "the matrix was considered to be learnt if no error was made after two successive exhibitions ; + _ ( 3 ) _ then the learning test was repeated by successively using two of the four @xmath10 matrix , one at a time ; + _ ( 4 ) _ finally , the student was asked to briefly describe how he(she ) proceeded to learn .    the _ error _",
    "@xmath11 of the @xmath12-th individual ( @xmath13 ; @xmath14 corresponds to the initial random filling ) is defined as the number of wrong elements of the filled @xmath9 matrix ( @xmath15 ) ; @xmath16 .",
    "typical results are presented in figs . 4 , 5 and 6 for the @xmath0 and in figs . 7 and 8 for one of the four @xmath10 matrices ( the figures associated with the other three @xmath10 matrices are quite similar in fact ) .",
    "although in a quite different context , results that have some connection with the present ones have been exhibited in @xcite .",
    "the averages @xmath17 ( with @xmath18 if the entire set of students is used for averaging ) are shown in fig .",
    "these curves already achieved the aspect presented in this figure when the averages were performed with approximately 80 individuals . using the entire set of 120 results just improved the precision but incorporated no new qualitative elements in the curves .",
    "if we define the _ learning time _ as the number of times shown before learning , excluding those who did not suceed learning that particular matrix untill the end of the experiment , we can check that it is of the order of 6 .",
    "incidentally we verified an interesting ( and indeed unexpected ) cultural phenomenon .",
    "for the @xmath0 matrix we were expecting @xmath19 to be close to @xmath20 since , before starting to show the codified matrix , we asked to _ randomly _ fill the empty matrix with symbols * o * and * + * , indicated in _ this _ order above the empty matrix , if we look at them from left to right . in variance with this reasonable expectation , we found , for the first 60 students , @xmath21 .",
    "after some hesitation about what could be the cause of this asymmetry ( e.g. , could it be the different semantics humans associate with a circle or a cross ? ) , we speculated that it could be the fact that portuguese language ( within which the brazilian population is educated ) is read _ from left to right_. then , to the second and last set of 60 students , an empty fig .",
    "1 was presented with the symbols in the ordering * + o * instead of * o + * .",
    "very symptomatically , we then obtained @xmath22 , the overall average being consequently @xmath23 , reasonably close to 12.5 as initially expected ! to confirm this cultural cause of the observed asymmetry , it would be interesting to repeat the experiment with say arabic students ( educated within _ right - to - left _ reading ) .",
    "another interesting feature that we observed is that , for many individuals , @xmath24 , thus systematically contradicting the overall monotonic tendency of @xmath25 to decrease with time .",
    "the reason for this kind of a priori unexpected behavior appeared to be ( as commented by the individuals themselves during the free final conversation ) that , after seeing for the first time the code to be learnt , the student dedicated a good part of his ( her ) attention to establish astrategy \" for learning rather to properly learn the matrix .",
    "let us mention , by the way , that in an experiment like the present one it is quite hard to differentiate between learning the strategy and memorizing the matrix within that strategy .",
    "this kind of modelization is supported by the fact that , several months after conclusion of the experiment , quite a few students still remembered the strategy , while they had completely forgotten the particular matrix code itself .",
    "let us now briefly comment the second experiment we developed .",
    "we chose several ambiguous images , all of them being susceptible of two mutually excluding interpretations on the basis of figure - background reversal .",
    "for example , if one sees in fig .",
    "15 @xcite a young woman , one does not simultaneously see the old woman , and reciprocally .",
    "we implemented this more complex learning task by showing the image and then asking to the individual what he sees .",
    "then we tried to count the time needed by the person in order to recognize the other image interpretation .",
    "this perception mechanism is sometimes referred to as _ reversal _ of the figure - background .",
    "it turned out that the times involved in this type of experiment , and very specifically the slowness of learning , if any , how to recognize the reversal , were so ill - defined that we decided not to proceed with this protocol .",
    "the question of how to conveniently quantify such learning remains , therefore , an open question ( see also @xcite ) .",
    "a great variety of computer learning algorithms are available in the literature .",
    "it is clear that all of them process , in one way or another , information .",
    "entropy is well known to be a convenient tool for quantifying ( lack of ) information .",
    "it can therefore be used in the context of any learning algorithm , at least in principle .",
    "we shall use it here in connection with the specific perceptron we shall describe later on . for convenience ,",
    "let us briefly review at this point some basic notions about the entropic forms we are referring to in the present paper .",
    "the boltzmann - gibbs - shannon ( bgs ) entropy is the basis of standard statistical mechanics and thermodynamics .",
    "it is defined ( in its discrete version ) by @xcite @xmath26 where @xmath27 is the number of microscopic possibilities accessible to the system , and @xmath28 are the associated probabilities ( @xmath29 ) ; for simplicity , we have taken boltzmann constant equal to unity . this entropy becomes maximal at equiprobability , i.e. , @xmath30 for all @xmath12 , and achieves the value @xmath31 which is the celebrated boltzmann formula .    if we consider a composite system made of two ( probabilistically ) independent systems @xmath32 and @xmath33 , i.e. , if we assume that @xmath34 , and replace this into eq .",
    "( 1 ) , we straightforwardly obtain @xmath35 which can be phrased as _ the entropy of the whole is the sum of the entropies of the parts_. the entropic form ( 1 ) is the basis of standard , boltzmann - gibbs ( bg ) , statistical mechanics and thermodynamics , and property ( 3 ) is known as _",
    "extensivity _ or _ additivity_. this entropy , as well as others , are in some sense ubiquitous .",
    "indeed , they emerge in a great variety of discussions .",
    "for example , they have often been used concerning complex phenomena such as the organization of living matter ( see , for instance , @xcite ) , as well as other types of organization , including that of knowledge ( e.g. , memorization and learning ) , economics , linguistics , to mention but a few ( see , for instance , @xcite ) . before addressing the generalization of @xmath36 we are interested in here ,",
    "let us mention that optimization of eq .",
    "( 1 ) in the presence of a constraint of the type @xmath37 ( where @xmath38 might be say microscopic energy levels ) , leads to @xmath39 where @xmath40 is a parameter to be determined through the value of the constraint . in statistical mechanics ,",
    "( 4 ) is in fact the celebrated boltzmann - gibbs weight .    in 1988 ,",
    "one of us ( ct ) proposed @xcite the generalization of bg statistical mechanics on the basis of a more general entropic form , namely @xmath41 @xmath1 being any real number .",
    "we can verify that @xmath42 , in other words , the bg formalism becomes now the @xmath2 particular case of this more general formalism .",
    "if we assume , once again , two independent systems @xmath32 and @xmath33 , we can prove that @xmath43 which can be phrased as _ the generalized entropy of the whole is different from the sum of the generalized entropies of the parts_. this property is referred to as _",
    "nonextensivity _ or _",
    "nonadditivity_. to be more precise , if we take into account that @xmath44 is always zero or positive , eq .",
    "( 6 ) implies that @xmath45 if @xmath46 and @xmath47 if @xmath48 .",
    "only if @xmath2 we have that @xmath49 .",
    "it is from property ( 6 ) that the terms _ nonextensive _ statistical mechanics and thermodynamics have been coined ( for reviews see @xcite ) .",
    "analogously to what we did before , if we optimize @xmath44 in the presence of the constraint @xmath50 , we obtain @xcite @xmath51^{1/(1-q ) } \\;,\\ ] ] where , as before , @xmath52 is a parameter to be determined through the value of the constraint .",
    "notice that for the normal regime for @xmath52 , i.e. , @xmath53 , we have , for large values of @xmath38 , a long _ power - law _",
    "tail for @xmath48 , whereas we have a short _ exponential _",
    "tail for @xmath2 ; finally , for @xmath46 , we have a cutoff .",
    "( 7 ) can be re - written in the boltzmann - gibbs form , namely @xmath54 where @xmath55 \\;.\\ ] ] in other words , in what concerns the optimizing distribution , @xmath56 plays the role of an effective energy which replaces @xmath38 ( in the @xmath57 limit , of course we recover @xmath58 ) .",
    "this effective energy can be used to @xmath59generalize a variety of microscopic and mesoscopic equations .",
    "one such example is the langevin equation , on which the perceptron that we use here has been constructed .",
    "matrix.,width=226 ]     matrix .",
    "this matrix is referred to as the @xmath7diagonal matrix .",
    "its dual matrix is obtained by permutating the @xmath7 and the @xmath8 symbols , and is referred to as the @xmath8diagonal matrix.,width=207 ]     matrix .",
    "this matrix is referred to as the @xmath8column matrix .",
    "its dual matrix is obtained by permutating the @xmath7 and the @xmath8 symbols , and is referred to as the @xmath7column matrix .",
    ", width=207 ]     matrix .",
    "the three left correspond to three different individuals ( the abscissa is the number of presentations of the matrix ; the ordinate is the number of matrix elements incorrectly reproduced ) .",
    "the three right ( see [ 16 ] for further details ) correspond to three different initial conditions for the perceptron ( the abscissa is the number of iterations ; the ordinate is the percentual error).,width=340 ]     matrix as a function of the number of presentations : circles , squares and triangles respectively correspond to averaging over @xmath60 , @xmath61 and @xmath62 individuals.,width=302 ]     matrix .",
    "the abscissa is the ordinal of the presentation at which the individual learnt the matrix : 82 ( out of 120 ) individuals learnt the matrix before or at the 9th presentation ( we recall that the 10th presentation was used to confirm the learning at the 9th one ) ; 38 individuals did not succeed ( and are not computed in the histogram).,width=264 ]     @xmath7diagonal matrix as a function of the number of presentations : the circles correspond to averaging the results of @xmath63 individuals to whom the @xmath7diagonal matrix was shown in _ first _ place ; the squares correspond to averaging the results of @xmath63 individuals to whom the @xmath7diagonal matrix was shown in _",
    "second _ place ( after having seen , in _ first _ place , the @xmath8column matrix ) .",
    ", width=264 ]     matrix , either the @xmath7diagonal or the @xmath8diagonal ones .",
    "the abscissa is the ordinal of the presentation at which the individual learnt the matrix : 50 ( out of 60 ) individuals learnt the matrix before or at the 9th presentation ( we recall that the 10th presentation was used to confirm the learning at the 9th one ) ; 10 individuals did not succeed ( and are not computed in the histogram).,width=264 ]         matrix ) as a function of the number of iterations ( @xmath64 is a parameter of the perceptron ) .",
    "the perceptron has been chosen with @xmath65 binary inputs , in order to simulate the human task ( dots ) as closely as possible on the average ( taken on 92 individuals in this example ) .",
    "see [ 16 ] for further details.,width=321 ]     matrix ) as a function of the number of iterations ( @xmath64 is a parameter of the perceptron ) .",
    "we notice the extreme sensitivity to the value of @xmath1 in the neighborhood of @xmath2 .",
    "see [ 16 ] for further details.,width=321 ]     matrix , where @xmath66 is the value of @xmath67 at which the error becomes half of its value at @xmath14 .",
    "the dots correspond to averaging the experimental data with @xmath62 humans .",
    "the continuous curve has been obtained averaging a large number of initial conditions for the perceptron with the gain parameter @xmath68 , the temperature - like parameter @xmath69 and the entropic index @xmath70 .",
    "it is with these values that optimal fitting was obtained for the experimental data .",
    "the parabolic extrapolation of the experimental data corresponding to @xmath71 and @xmath72 provides , for @xmath14 , the value of @xmath73 for the percentual error , which corresponds to @xmath74 for the absolute error .",
    "therefore the value of @xmath66 corresponds to the value of @xmath67 at which the absolute error equals @xmath75 . since no integer value of @xmath67 corresponds exactly to this value , a linear interpolation has been performed , yielding @xmath76 for the experimental data with 120 individuals .",
    "see [ 16 ] for further details.,width=321 ]    as we see , the entropic property ( 6 ) has a kind of _ gestalt_-like flavor .",
    "its use constitutes a natural choice if we desire to deal with informational phenomena involving global or nonlocal aspects .",
    "since this might well be the case of human learning , we have adopted this formalism in order to have the possibility of comparing human and machine learnings .",
    "to do so , a nonextensive perceptron has been implemented @xcite which performs a task similar to the learning of the @xmath77 and @xmath78 matrices that were exposed to the students , according to the experimental protocol we described earlier . in order to perform calculations",
    ", the perceptron needs an internal dynamical equation . to fulfill this requirement , the @xmath1-generalized langevin equation previously introduced by stariolo @xcite",
    "was implemented in the perceptron .",
    "some typical runs of the perceptron are shown in fig .",
    "4 , and typical averages are shown in figs .",
    "16 , 17 and 18 ( from @xcite ) .",
    "the purpose of the present section is to compare the results obtained with humans and those obtained with the nonextensive perceptron .",
    "the comparison will be illustrated on the learning / memorizing of the @xmath0 matrix .",
    "we shall verify that , for this specific task , the human and perceptron results can be amazingly similar .",
    "this can be checked on fig .",
    "4 . the three individual results ( on the left ) are indeed similar to the perceptron realizations with three different initial conditions ( on the right ) .",
    "the three human examples have been chosen as to exhibit typical cases .",
    "the three perceptron examples have been chosen in order to have an overall aspect similar to the human ones .",
    "averages over many realizations of the data just presented are shown ( with dots ) in figs .",
    "16 and 18 .",
    "we have rescaled the time variable in such a way that comparison becomes possible on the same graph .",
    "more precisely , we have expressed time in units of the corresponding half - time @xmath66 , defined as the value of time at which the average error curve decays to its half value .",
    "a rescaling such as this one is clearly necessary in order to quantitatively compare the results . indeed ,",
    "time \" is here represented as the number of presentations , whereas perceptron  time \" essentially corresponds to the number of computer iterations .",
    "these two numbers being of a completely different nature ( see also @xcite ) , it is clear that rescaling becomes necessary .",
    "we may consider fig .",
    "18 as the central result of the present work .",
    "we verify that , for the specific task of learning / memorizing 25 binary states ( on a matrix for the humans ) , humans and machines are remarkably similar .",
    "of course , the parameters of the perceptron have been chosen in such a way as to optimize the overall fitting to the human data .",
    "the number of individuals that have been averaged is 120 , and we have verified that no sensible variation is obtained under increase of that number . in the language of statistical mechanics , we may say that we have practically attained the thermodynamic limit .",
    "there is a little bump in the human results at @xmath79 : we have not identified its origin ( perhaps fatigue of the tested individuals , perhaps something else ) .",
    "the perceptron does not exhibit such bump . as we see",
    ", the perceptron that fits the data has some degree of nonextensivity , as was conjectured in the beginning of the present work .",
    "although @xmath1 is quite close to unity , we must take into consideration the fact that the error curves have been shown to be ( see fig .",
    "17 ) extremely sensitive to the degree of nonextensivity in the neighborhood of @xmath2 ( extensive case ) .",
    "in summary , we have implemented an experimental study aiming to measure the learning / memorizing performance of humans on simple codes on matrices .",
    "it is on purpose that we simultaneously use the words  learning \" and  memorization \" .",
    "indeed , the experiments clearly showed that the improvement of correct answers was due to a mixture of memorization of the specific codified example and devising learning _ strategies _ ( symmetry rules and other mnemonic tricks ) in order to efficiently implement the memorization effort .",
    "in fact , after several months , we informally verified that the individuals had forgotten the codes , but still remembered the strategy they used for memorizing them .    through comparison with machine results",
    ", we verified that this particular human task was executed with clear indication of a slight , though very efficient nonextensivity ( or globality ) quantified by the entropic index @xmath1 .",
    "this index appeared to be slightly _ above _ unity , which characterizes _ slower _ learning / memorizing ( the error curves takes longer to become basically zero ) , but perhaps higher ability for devising strategies .",
    "it is then allowed to conjecture that human nature evolved , during successive generations , not so much to strongly improve the speed associated with such kind of memorization , but rather to improve the capacity of spontaneously and quickly generating intellectual strategies for performing tasks such as memorization .",
    "we also applied a similar experimental protocol for learning / memorizing how to analyze complex figure - background images in order to quickly realize alternative ( typically two ) interpretations of the figures .",
    "we verified that , unless much more sophisticated experimental protocols and computational algorithms are deviced , cognitive tasks with important semantic content are by all means nontrivial to measure and compare .",
    "for such complex tasks , even more than for the simple binary learning / memorization addressed here , the role of strategies might well be fundamental , although this remains to be proved .",
    "on more general grounds , the scenario which emerges is that nonextensivity seems to serve to humans for achieving _ abduction _ , one of charles sanders pierce three basic forms of inference ( see @xcite and references therein ) . in other words ,",
    "given its intrinsic _ nonlocal _ nature ( strong collective correlations are necessary for making the entropic index @xmath1 to differ from unity ) , it is plausible that nonextensivity constitutes the structure necessary to make _ metaphors_. given the very high intellectual level attributed , since aristotle , to metaphors @xcite , it is allowed to think that it has some specific relation with the nature of the one that we might consider as the _ animal who makes metaphors_. we may use _  homo metaphoricus \" _ to express this concept .",
    "further developments , on both philosophical and cognitive - psychological grounds , within the frame that we have outlined here would naturally be very welcome .",
    "they could reinforce or exclude the interpretation that our present human - machine comparison suggests .",
    "we thank a.b . lima and k.b .",
    "miziara for assistance during the early stages of the present work , as well as s.a .",
    "cannas and d.a .",
    "stariolo for making available to us their perceptron curves . computational assistance and useful remarks by l. silva , c. anteneodo , f. baldovin and m.p .",
    "albuquerque are acknowledged as well .",
    "we finally thank capes , cnpq , pronex and faperj ( brazilian agencies ) for partial financial support .",
    "h. atlan , _ application of information theory to the study of the stimulating effects of ionizing radiation , thermal energy , and other environmental factors _ , j. theoret",
    "* 21 * , 45 ( 1968 ) ; _ on a formal definition of organization _ , j. theoret",
    ". biol . * 45 * , 295 ( 1974 ) ; _ self - organizing networks : weak , strong and intentional , the role of their underdeter mination _ , in _ functional models of cognition _ , ed .",
    "a. carsetti ( kluwer academic , amsterdam , 1999 ) , p. 127 .    c. tsallis , j. stat .",
    "_ possible generalization of boltzmann - gibbs statistics _ , j. stat .",
    "52 * , 479 ( 1988 ) ; e.m.f .",
    "curado and c. tsallis , _ generalized statistical mechanics : connection with thermodynamics _ , j. phys .",
    "a * 24 * , l69 ( 1991 ) [ corrigenda : * 24 * , 3187 ( 1991 ) and * 25 * , 1019 ( 1992 ) ] ; c. tsallis , r.s .",
    "mendes and a.r .",
    "plastino , _ the role of constraints within generalized nonextensive statistics _ , physica a * 261 * , 534 ( 1998 ) .",
    "a regularly updated bibliography can be accessed at http://tsallis.cat.cbpf.br/biblio.htm    s.r.a .",
    "salinas and c. tsallis , eds.,_nonextensive statistical mechanics and thermodynamics _",
    "* 29 * ( 1999 ) ; s. abe and y. okamoto , eds . , _ nonextensive statistical mechanics and its applications _ , series _ lecture notes in physics _",
    "* 560 * ( springer - verlag , heidelberg , 2001 ) [ isbn 3 - 540 - 41208 - 5 ] ; p. grigolini , c. tsallis and b.j . west , eds . ,",
    "_ classical and quantum complexity and nonextensive thermodynamics _ , chaos , solitons and fractals * 13 * , number 3 , 371 ( pergamon - elsevier , amsterdam , 2002 ) ; c. tsallis , _ nonextensive statistical mechanics : a brief review of its present status _ , annals of the brazilian academy of sciences * 74 * , 393 ( 2002 ) ; g. kaniadakis , m. lissia and a. rapisarda , eds . , _ non extensive statistical mechanics and physical applications _ , physica a * 305 * , 129 ( 2002 ) ; m. gell - mann and c. tsallis , eds . , _ nonextensive entropy - interdisciplinary applications _ , ( oxford university press , new york , 2004 ) ; h.l .",
    "swinney and c. tsallis , eds .",
    ", _ anomalous distributions , nonlinear dynamics and nonextensivity _ , physica d * 193 * ( 2004 ) ; c. tsallis , _ algumas reflexoes sobre a natureza das teorias fisicas em geral e da mecanica estatistica em particular _ , in _ tendencias da fisica estatistica no brasil _ , ed . t. tome , volume honoring s.r.a .",
    "salinas ( editora livraria da fisica , sao paulo , 2003 ) , page 10 .",
    "aristotle , _ ars poetica _ [  the greatest thing by far is to be a master of metaphor .",
    "it is the one thing that can not be learned from others ; it is also a sign of genius , since a good metaphor implies an eye for resemblance \" ] ."
  ],
  "abstract_text": [
    "<S> simple memorizing tasks have been chosen such as a binary code on a @xmath0 matrix . </S>",
    "<S> after the establishment of an appropriate protocol , the codified matrices were individually presented to 150 university students ( conveniently pre - selected ) who had to memorize them . </S>",
    "<S> multiple presentations were offered seeking perfect performance verified through the correct reproduction of the code . </S>",
    "<S> we measured the individual percentual error as a function of the number of successive presentations , and then averaged over the examined population . </S>",
    "<S> the _ learning curve _ thus obtained decreases ( almost monotonically ) until becoming virtually zero when the number of presentations attains six . </S>",
    "<S> a computer simulation for a similar task is available which uses a two - level perceptron on which an algorithm was implemented allowing for some degree of _ globality _ or _ nonlocality _ ( technically referred to as entropic _ nonextensivity _ within a current generalization of the usual , boltzmann - gibbs , statistical mechanics ) . </S>",
    "<S> the degree of nonextensivity is characterized by an index @xmath1 , such that @xmath2 recovers the usual , extensive , statistical mechanics , whereas @xmath3 implies some degree of nonextensivity . in other words , @xmath4 is a ( very sensitive ) measure of globality ( gestalt perception or learning ) . </S>",
    "<S> the computer curves fit well the human result for @xmath5 . </S>",
    "<S> it has been verified that even extremely small departures of @xmath1 from unity lead to strong differences in the learning curve . </S>",
    "<S> our main observation is that , for the very specific learning task on which we focus here , humans perform similarly to slightly nonextensive perceptrons . </S>",
    "<S> in addition to this experiment , some preliminary studies were done concerning the human learning of ambiguous images ( based on figure - background perception ) . in spite of the complexity of drawing conclusions from such a comparison </S>",
    "<S> , some generic trends can be established . </S>",
    "<S> moreover , the enormous and well known difficulty for computationally defining semantic , hierarchic and strategic structures reveals clear - cut differences between human and machine learning .    . </S>"
  ]
}