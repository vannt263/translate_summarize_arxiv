{
  "article_text": [
    "the search for microlensing events towards the lmc macho ( alcock _ et al .",
    "_ 1993 ) , eros ( aubourg _ et al .",
    "_ 1993 ) the galactic bulge ogle ( udalski _ et al .",
    "_ 1994 ) , macho , duo ( alard & guibert 1997 ) or the m31 galaxy , agape ( ansari _ et al .",
    "_ 1997 ) , has provided us with an impressive database of images of densely crowded fields .",
    "the target fields have been monitored for several seasons , providing us with time series containing hundreds of images .",
    "light curves for millions of stars can then be easily obtained with one of the widely used profile fitting codes such as dophot ( schechter & mateo , 1993 ) .",
    "the search for variable objects among these huge light curve databases has proved very fruitful , for microlensing ( macho , ogle , duo , eros ) , and also for variable stars ( macho , ogle , duo , eros ) .",
    "however we would like to emphasize that photometry and detection of variable ( including moving ) objects should be based on the difference between frames , whereas photometric codes like dophot are designed to perform profile fitting photometry of stars detected on a reference frame . in a variable object",
    "appears but was not seen on the reference it wo nt be detected , leading to a serious loss of efficiency for microlensing .",
    "the completeness of the variable star catalogue will be also seriously affected .",
    "another concern is that of photometric accuracy . with multi - profile fitting techniques , the absolute photometry of a given ( crowded ) star requires perfect psf estimation and careful modeling of all other close components , and also a correct estimate of the background value around each star .",
    "for the particular application of finding light curves of variable objects , it is more efficient to estimate only that part of the star s brightness which varies from image to image ; this is exactly the problem that image subtraction is designed to solve . the first attempt to perform image subtraction",
    "was made by tomaney & crotts 1996 , ( hereafter tc ) for data taken towards the m31 galaxy ( crotts & tomaney 1996 ) . to make a perfect subtraction of two images , one has to match the frames to exactly the same seeing .",
    "tc proposed degrading a good seeing image to match a reference frame with bad seeing .",
    "the quality achieved in the subtracted image is very dependent of the quality of the kernel determination , and finding the proper kernel is a very delicate operation .",
    "tc proposed deriving the kernel by simply taking the ratio of the fourier transform of a bright star on each image .",
    "however the high frequencies are dominated by noise and they were forced to use a gaussian extrapolation to determinate the wings ( phillips and davies 1995 ) .",
    "this method provides no guarantee of producing the highest attainable quality of the subtracted image .",
    "even apart from the non - gaussian wings of the true kernel , and the limited number of bright , uncrowded , stars with sufficient signal to noise ratio , this method is non - optimal in the sense that it does not use all the information available : in fact every star , even if extremely crowded , contains information about the kernel ; to get an optimal solution we must use all of that information .",
    "additionally their method has difficulty with rapid , complicated , psf variations , and does not intrinsically handle background subtraction .",
    "the problem that we address here is how to find an optimal kernel solution , in order to get the best possible subtracted image .",
    "before looking for the optimal subtraction , we need to perform some basic operations , to register the frames to a reference frame .",
    "usually the frames have slightly different centers and orientation ( and possibly scale ) , and we need to perform an astrometric transform to match the coordinates of the reference frame .",
    "we determine this transform by fitting a two dimensional polynomial using 500 stars on the reference frame , and the same number on the other frame . using this",
    "transform we then resample the frame on the grid defined by the reference frame .",
    "this resampling is performed by interpolating using bicubic splines , which gives excellent accuracy .",
    "all the frames are then on the same coordinate system , and we can proceed to matching the seeing .      here",
    "we emphasize that , contrary to tc , we choose to take the _",
    "best _ seeing frame as the reference .",
    "we do not wish to degrade the frame to the worst seeing frame , as this will clearly lower the signal to noise ratio .",
    "later , we will match the seeing in our frames by convolving the reference to the seeing of each other frame .",
    "this is likely to be more difficult , as aligning to good seeing frames is more difficult , but we are looking for an optimal result .",
    "we now arrive to the fundamental problem of matching the seeing of two frames with different psfs .",
    "we do not want to make any assumption concerning the psf on the frame , and we plan to use all the pixels .",
    "the important point is that most of the stars on a given frame do not have large amplitude variations , but variations of at most 1 or 2 % .",
    "this allows us to say that most of the pixels on two frames of the same field would be very similar , if the seeing were the same .",
    "consequently , one possibility is to try to find the kernel by finding the least square solution of the equation : @xmath0 where ref is the reference image , and i the image to align .",
    "the symbol @xmath1 denotes convolution . in principle",
    "solving this equation is a non - linear problem , for which a realistic computer solution looks impossible .",
    "however if we decompose our kernel using some basis of functions , the problem becomes a standard linear least square problem . if we decompose the kernel as : @xmath2 solving the least square gives the following matrix equation for the @xmath3 coefficients : @xmath4 with : @xmath5 @xmath6 @xmath7 in choosing to solve the problem by least - squares we ve implicitly approximated the images poisson statistics with gaussian distributions with variance @xmath8 : @xmath9 we set the constant k by taking into account the detector s gain ( ratio of photons detected to adu ) .",
    "note that the matrix m is just the scalar product of the set of vectors @xmath10 , and the vector v the scalar product of the @xmath10 with i. all we have to do now is to look for a suitable basis of functions to model the kernel .",
    "the functions of this basis must have finite sums , and must drop rapidly beyond a given distance ( the size of an isolated star s image ) . to solve this problem , we start with a set of gaussian functions , which we modify by multiplying with a polynomial .",
    "these basis functions allow us to model the kernel , even if its shape is extremely complicated .",
    "we adopt the following decomposition : @xmath11 where @xmath12 , @xmath13 , and @xmath14 is the degree of the polynomial corresponding to the @xmath15 gaussian component .",
    "there are a total of @xmath16 terms for each value of @xmath17 .    in the notation of eq",
    "( 2 ) , @xmath18 in practice , it seems that 3 gaussian components with associated polynomial degrees in the range 2 to 6 can give subtracted images with residuals comparable to @xmath19 .",
    "another important issue is that the differential background variation between the frames can be fitted simultaneously with the kernel . in eq ( 1 )",
    "we did not considered any background variations between the two frames ; let s modify eq ( 1 ) in the following way : @xmath20 we shall use the following polynomial expression for @xmath21 : @xmath22 with @xmath23 , @xmath24 , and @xmath25 is the degree of the polynomial used to model the differential background variation .",
    "the least square solution of eq ( 3 ) , will lead to a matrix equation similar to the previous one , except that we have to increase the number of @xmath10 vectors ; our definitions of the matrix m and vector v relative to the @xmath10 remain the same as in section [ matchingseeing ] .",
    "we have : @xmath26 where @xmath27 and @xmath28 ; note that , for @xmath29 , the @xmath10 are identical to our previous results .",
    "there are two ways to handle the problem of psf variations .",
    "firstly , most of the time , the field is so dense that a transformation kernel can be determined in small areas , small enough that we can ignore the psf s variation .",
    "this is the great advantage of a method which does not require any bright isolated stars to determine the kernel , but can be used on any portion of an image , provided that the signal to noise is large enough to determine the kernel .",
    "indeed , the more crowded the field the easier it is to model variations of the psf .",
    "a second possibility is to make an analytical model of the kernel variations .",
    "we take the following kernel model : @xmath30 \\\\ % $ $ \\end{aligned}\\ ] ] where : @xmath31 , @xmath32 , and @xmath33 is the degree of the polynomial transform that we use to fit the kernel variations .",
    "provided that the kernel variations with x and y are small enough compared to the u , v variations , we can easily calculate new expressions for the @xmath10s : @xmath34 where @xmath35 with the values of @xmath36 and @xmath37 implicit in the index @xmath38 , and now @xmath39 .",
    "unfortunately these equations do not guarantee the conservation of flux .",
    "consequently we must add the condition that the sum of the kernel has to be constant . to simplify the equation",
    "we also normalize the bo functions , so that each of them sums to one .",
    "we can then rewrite the kernel decomposition : @xmath40 \\\\ & & \\qquad + \\ \\hbox{norm } \\times bo_n\\end{aligned}\\ ] ] we can calculate the norm ( the sum of the kernel ) by making a constant psf fit in several small area .",
    "the different values will then be averaged to get the constant norm .",
    "the solution of the system for the coefficients @xmath41 is very similar to the previous case of a constant psf . we shall not bother to give all the the details here",
    "the ogle team has kindly provided us with a stack of images of a field situated 2 degrees from the galactic center , in order to experiment with our method . for these particular images ,",
    "the optimal kernel has a complicated shape and it would be probably be very difficult to compute reliably with a simple fourier division ; we consider this field an excellent test of our method . the data was taken in drift scan mode ( tdi ) , so the form of the psf can vary rapidly with row number on the ccd .",
    "we extracted a small ( @xmath42 ) sub - frame from the @xmath43 original images .",
    "one of the images has quite outstanding seeing , and we took it as a reference .",
    "all frames were resampled to the reference grid by using the method previously described . to model the kernel",
    ", we took 3 gaussian components with associated polynomials .",
    "for the first gaussian we took @xmath44 pixels and @xmath45 and @xmath46 for the two others .",
    "the degree of the associated polynomials were respectively 6 ,  4 ,  and  2 .",
    "we divided the sub frame into @xmath47 pixels regions .",
    "we applied our method to each of these regions , which provided us with one subtracted image per region .",
    "we reconstructed the subtracted image of our whole sub - frame by mosaicing the subtracted images obtained for each region .",
    "in this set of 86 images , the seeing varies from 0.7 arcsec to 2.5 arcsec , and some of the frames have elongated stellar images .",
    "we started by making an initial residual image using all unsaturated pixels .",
    "we then made a 3 @xmath48 rejection of the pixel list , to get rid of the variables .",
    "we usually used 4 iterations of the method , to be completely unbiased by large amplitude variables .",
    "we found that for all images , the final residual calculated from the subtracted image was very close to that expected from poisson statistics .",
    "to illustrate this result we plot in fig .",
    "1 the initial images and the subtracted image for a small field containing a variable star at its center .",
    "the stellar images are sharply peaked on the reference , while they look quite fuzzy and assymetric on the other image .",
    "this is well confirmed by the shape of the best convolution kernel which looks elongated and has a complicated shape .",
    "this example clearly illustrate the ability of our method to deal with any kernel shape .",
    "we can imagine that in this case any gaussian approximation of the kernel itself or of its fourier transform would not be satisfactory .",
    "for illustrative purposes , we also normalized the subtracted image by the sum of the photon noise expected from the two images ( see fig .",
    "2 ) . once this normalization is applied , we see that the larger deviations visible at the location of the bright stars disappear , suggesting that the subtraction errors correspond to poisson noise .",
    "this is confirmed by calculating the reduced chi squared : we find @xmath49 ( before doing this calculation we removed a small area around the variable star at center of the image ) .",
    "we also plot the histogram of the normalized deviations in fig .",
    "this histogram is very close to a gaussian with zero mean and unit variance ( i.e. n(0,1 ) ) .",
    "we observe deviations significantly larger than the poisson expectations only for very bright stars ( about 5 to 10 times brighter than the brightest stars in the small field we present ) .",
    "we believe that these residuals are due to seeing variations , see section 5 for more details ; the number of such bright stars in an image is very small .",
    "to spot the variables stars , we created a `` deviation image '' by co - adding the square of the subtracted images .",
    "we normalized the deviation image by normalizing with the pixels standard deviations .",
    "we found many variables at very significant levels .",
    "most of them seem to be bright giants with small amplitudes .",
    "some of the variables appeared to be periodic , we found a few rr lyraes and some eclipsing variables .",
    "we computed the flux variations for these stars by making simple aperture photometry . in fig . 3 and fig .",
    "4 we give an illustration of the result we have obtained .",
    "as discussed above , the variance of the residual image is approximately equal to the sum of the variances of the input images . if we created a reference image by co - adding a large number of good - seeing images we could remove the contribution of the noise in the reference",
    "; we would , of course , have to be careful about variability between the different reference frames . upon inspection of the residual images ,",
    "however , some showed significantly larger residuals than expected from poisson statistics near the position of bright , but non - saturated , stars ( it does represent less than 1 % of the stars visible on the frame ) .",
    "these showed the characteristic signature of centering errors , with equal positive and negative residuals even for stars which show no evidence of variability ( i.e. the sum of all residuals within a few arc - seconds is zero ) .",
    "we believe that this is produced by the turbulent atmosphere modulating our kernel on the scale of our sub - regions .",
    "shao and colavita ( 1992 ) quote the variance in the angle between two stars separated by @xmath50 as @xmath51 for the regime in which we are interested ( their equation 2 ) .",
    "they evaluate the integral using data from roddier et al .",
    "( 1990 ) for a night on mauna kea with @xmath52arcsec seeing to give @xmath53 if we assume that the integral over the atmosphere scales with seeing in a similar way to the integral @xmath54 which enters into the definition of the fried parameter , @xmath55 , we may expect that this result will scale as @xmath56 ( a result which is independent of @xmath57 due to the wavelength dependence of @xmath55 ) . in 1 arcsec",
    "seeing , therefore , we may expect that @xmath58 on the typical scale of our @xmath59 regions , and for 128s exposures , this corresponds to an rms image motion of about 0.011arcsec .",
    "if we model the psf as a gaussian with width parameter @xmath60 ( @xmath61 for 1arcsec fwhm images ) , this would produce a maximum residual of @xmath62 , or 1.6% .",
    "this is of the same order as the residuals that we see in our frames .",
    "we expect that the periodic variables light curves to be well approximated with truncated fourier series .",
    "we calculate the period using the renson method ( 1978 ) , and we fit fourier series with different number of harmonics .",
    "the errors are calculated from the photon noise in each image .",
    "we do not include the noise associated with the reference image because it is produces an error only in the total magnitude , and , to first order , does nt affect the variable part of the object s flux .",
    "we estimate each time the chi - square per degree of freedom ( @xmath63 ) , and we look for the best chi - square with the minimum number of harmonics .",
    "the results are given in table 1 where we see that the resulting value of @xmath64 is close to unity , for most variables .",
    "except for variable p1 our mean error is at most only 25 @xmath65 larger than the poisson expectation ( i.e. @xmath66 ) ; of course , this @xmath63 excess is significant . in the case of the variable",
    "p1 the @xmath63 is very inconsistent with the poisson expectation .",
    "this variable has about the same brightness as p6 .",
    "we checked the quality of the subtracted images , but could not identify any defects .",
    "the quality of the image subtraction is as good for p1 and for p6 , they have about the same brightness , so what s wrong ?",
    "considering that the mean error is fairly small ( about 1% ) , we might suspect some residual error due to flat fielding .",
    "however , we get a mean residual of only 0.6 % for p6 and @xmath67 showing that the flat fielding errors are much smaller than 0.6 % .",
    "this is not surprising because these images were taken in drift scan mode , and consequently , we average the sensitivity of many pixels .",
    "we conclude that there must be some intrinsic reason for p1 s bad @xmath63 .",
    "it is possible that variables do not repeat perfectly from cycle to cycle .",
    "this kind of variable star is well known to have spots which are likely to induce variability at the sub percent level .",
    "it is also possible that the rr lyraes do nt repeat perfectly , they are well known to show the blashko effect , and we can explain some of the @xmath63 as being due to cycle to cycle variations . although estimating the @xmath63 of periodic variable stars is not an absolute test , we conclude that on average we are only about 20 % above the poisson error , and consequently there is not much to be gained from improving our method .",
    "however , we must note that the errors due to the reference frame are the same for the integrated flux of a star on each image only at first order of approximation . by convolving the reference each time to fit the seeing variations , we change slightly the noise distribution around the star .",
    "especially for the case where a bright star is close to our object , convolving with the kernel might spread some noise into our photometric aperture .",
    "this effect will be negligible for good seeing frames , but noticeable when the seeing s bad .",
    "an obvious solution is to construct a reference with a signal to noise as good as possible by stacking the best seeing images ; see the next section .",
    "another approach with potential to improve the signal - to - noise would be to use a matched filter to measuring our stars variability .",
    "unfortunately , simply applying the usual psf - filter leads to problems with aperture corrections , and we shall not investigate this approach in this paper .",
    "llll variable & @xmath63 & mean residual ( % ) & @xmath68 + p1 & 2.01 & 1.0 & -1.117 + p2 & 1.43 & 1.1 & -0.4402 + p3 & 1.55 & 1.6 & 0 + p4 & 1.46 & 1.2 & 0 + p5 & 1.17 & 1.3 & 0 + p6 & 1.1 & 0.6 & -0.4348 +",
    "we averaged the 20 best seeing images to build a reference frame with excellent signal to noise .",
    "the resulting seeing is of course not as good as it was in our previous reference which was the best image .",
    "but the seeing variations are much reduced , as well as the noise amplitude .",
    "all the images were reprocessed using this new reference .",
    "we found that all the subtracted frames were improved .",
    "even for the good seeing frame , were the seeing quality of the reference is critical we found some improvements .",
    "the light curves of the variables stars were also improved , we give the result of harmonic fitting in table 2 .",
    "lll variable & @xmath63 & mean residual ( % ) + p1 & 2.0 & 1.0 + p2 & 1.16 & 1.0 + p3 & 1.27 & 1.45 + p4 & 1.45 & 1.2 + p5 & 1.15 & 1.3 + p6 & 1.03 & 0.6 +",
    "one might think that a method which fits all the pixels in an image ( even if the fit is linear ) is going to be much more time consuming than conventional methods .",
    "but the actual cost of the calculations is much lighter than might appear at first glance .",
    "most of the computing time is taken by the calculation of the matrix we define in section 2.3 this is an @xmath69 process ( n is the number of basis function we use ) .",
    "the rest of the calculation is an n process .",
    "the matrix could be calculated once for all and used to fit the kernel solution for all images .",
    "a problem with this approach is that we reject different pixels on each frame ( due to new saturated pixels , or variable stars ) and consequently the matrix elements change . in practice",
    ", we find that we reject no more than 1 % percent of the total number of pixels , so that all that we have to do is to calculate the matrix elements for the rejected pixels , and subtract them from the original values .",
    "this process cost very little cpu , and once the original matrix has been built , the kernel solution can be fitted very quickly even though we use several clipping passes .",
    "the rest of the operations requires about the same computing time .",
    "by applying this method we can process a @xmath70 frame in about 1 min with a 200 mhz pc ; this could certainly be improved further by using better numerical algorithms for the solution of the linear system .",
    "we would like to thank the ogle team for providing the ccd images we presented in our article .",
    "in particular we would like to thank a. udalski and m. szymaski for helping with the data .",
    "we are especially indebted to b. paczyski for supporting our project , and for many interesting discussions .",
    "c. alard would like to acknowledge support from nsf grant ast-9530478 during his stay in princeton , where most of the research was done .",
    "alard , c. and guibert , j. a&a 1997 , * 326 * , 1 alcock , c. et al .",
    "1993 , nature , 365 , 621 aubourg , e. et al .",
    "1993 , nature , 365 , 623 crotts , a. and tomaney , a. , apj * 87 * , l473 ( 1996 ) tomaney , a. and crotts , a. , aj * 112 * 2872 phillips , a.c . &",
    "davis , l.e . in astronomical data analysis and systems",
    "iv , asp 77 edited by r. shaw payne , & j.j.e .",
    "hayes p. 297",
    "( 1995 ) schechter , p. and mateo , m. pasp * 105 * , 1342 ( 1993 ) renson , p. a&a * 63 * , 125 ( 1978 ) roddier ,  f , cowie ,  l , graves ,  j.  e. , and songaila  a , 1990 , proc .",
    "spie 1236 , 485 ( 1990 ) .",
    "shao  m. and colavita  m.  m. , a&a * 262 * 353 ( 1992 ) .",
    "udalski , a. et al . 1994a , acta astron . , 44 , 165"
  ],
  "abstract_text": [
    "<S> we present a new method designed for optimal subtraction of two images with different seeing . </S>",
    "<S> using image subtraction appears to be essential for the full analysis of the microlensing survey images , however a perfect subtraction of two images is not easy as it requires the derivation of an extremely accurate convolution kernel . </S>",
    "<S> some empirical attempts to find the kernel have used the fourier transform of bright stars , but solving the statistical problem of finding the best kernel solution has never really been tackled . </S>",
    "<S> we demonstrate that it is possible to derive an optimal kernel solution from a simple least square analysis using all the pixels of both images , and also show that it is possible to fit the differential background variation at the same time . </S>",
    "<S> we also show that psf variations can also be easily handled by the method . </S>",
    "<S> to demonstrate the practical efficiency of the method , we analyzed some images from a galactic bulge field monitored by the ogle ii project . </S>",
    "<S> we find that the residuals in the subtracted images are very close to the photon noise expectations . </S>",
    "<S> we also present some light curves of variable stars , and show that , despite high crowding levels , we get an error distribution close to that expected from photon noise alone . we thus demonstrate that nearly optimal differential photometry can be achieved even in very crowded fields . </S>",
    "<S> we suggest that this algorithm might be particularly important for microlensing surveys , where the photometric accuracy and completeness levels could be very significantly improved by using this method </S>",
    "<S> .    # 1 # 1 # 1 </S>"
  ]
}