{
  "article_text": [
    "consider a collection of points in euclidean space that forms roughly isotropic clusters .",
    "the _ centroid _ of a given cluster is found by averaging the position vectors of its points , while the _ medoid _ , or exemplar , is the point _ from within the collection _ that best represents the cluster . to distinguish clusters , it is popular to pursue the @xmath0-means objective : partition the points into @xmath0 clusters such that the average squared distance between a point and its cluster centroid is minimized .",
    "this problem is in general np - hard @xcite .",
    "further , it has no obvious convex relaxation , which could recover the global optimum while admitting efficient solution ; practical algorithms like lloyds@xcite and hartigan - wong @xcite typically converge to local optima .",
    "@xmath0-medoids clustering - medoids clustering is sometimes called @xmath0-medians clustering in the literature . ] is also in general np - hard @xcite , but it does admit a linear programming ( lp ) relaxation .",
    "the objective is to select @xmath0 points as medoids such that the average squared distance ( or other measure of dissimilarity ) between a point and its medoid is minimized .",
    "* this paper obtains guarantees for exact recovery of the unique globally optimal solution to the @xmath0-medoids integer program by its lp relaxation . *",
    "commonly used algorithms that may only converge to local optima include partitioning around medoids ( pam ) @xcite and affinity propagation @xcite .",
    "[ yalies ]     6 facial expressions from the yale face database were clustered using affinity propagation and lloyd s algorithm .",
    "the medoids identified by affinity propagation ( framed ) are representative faces from the clusters , while the centroids found by lloyd s algorithm are averaged faces.,title=\"fig:\",width=188 ]   6 facial expressions from the yale face database were clustered using affinity propagation and lloyd s algorithm .",
    "the medoids identified by affinity propagation ( framed ) are representative faces from the clusters , while the centroids found by lloyd s algorithm are averaged faces.,title=\"fig:\",width=188 ]    to illustrate the difference between a centroid and a medoid , let us put faces to points .",
    "the yale face database @xcite has grayscale images of several faces , each captured wearing a range of expressions ",
    "normal , happy , sad , sleepy , surprised , and winking .",
    "suppose every point encodes an image from this database as the vector of its pixel values .",
    "intuitively , facial expressions represent perturbations of a background composed of distinguishing image features ; it is thus natural to expect that the faces cluster by individual rather than expression .",
    "both lloyd s algorithm and affinity propagation are shown to recover this partitioning in figure [ yalies ] , which also displays centroids and medoids of clusters .",
    "randomly initialized repetitions of lloyd s algorithm were run ; the clustering that gave the smallest objective function value is shown .",
    "the package apcluster @xcite was used to perform affinity propagation . ]",
    "the centroids are averaged faces , but the medoids are actual faces from the dataset .",
    "indeed , applications of @xmath0-medoids clustering are numerous and diverse : besides finding representative faces from a gallery of images @xcite , it can group tumor samples by gene expression levels @xcite and pinpoint the influencers in a social network @xcite .",
    "we formulate @xmath0-medoids clustering on a complete weighted undirected graph @xmath1 with @xmath2 vertices , although recovery guarantees are proved for the case where vertices correspond to points in euclidean space and * each edge weight is the squared @xmath3 distance between the points it connects .",
    "* distances rather than unsquared @xmath3 distances only because we were able to derive stronger theoretical guarantees using squared @xmath3 distances . ]",
    "let characters in boldface ( `` @xmath4 '' ) refer to matrices / vectors and italicized counterparts with subscripts ( `` @xmath5 '' ) refer to matrix / vector elements .",
    "denote as @xmath6 the nonnegative weight of the edge connecting vertices @xmath7 and @xmath8 , and note that @xmath9 since @xmath10 is simple .",
    "@xmath0-medoids clustering ( kmed ) finds the minimum - weight bipartite subgraph @xmath11 of @xmath10 such that @xmath12 and every vertex in @xmath13 has unit degree .",
    "the vertices in @xmath14 are the medoids .",
    "expressed as a binary integer program , kmed is @xmath15 \\label{kmed1 } \\\\ & \\sum_{j=1}^n z_{jj } \\leq k \\label{kmed2 } \\\\ & z_{ij } \\leq z_{jj } , \\quad i , j \\in [ n ] \\label{kmed3 } \\\\ &",
    "z_{ij } \\in \\{0 , 1\\ } \\label{kmed4}\\,.\\end{aligned}\\ ] ] above , @xmath16 $ ] means the set @xmath17 .",
    "when @xmath18 , vertex @xmath19 serves as vertex @xmath7 s medoid ; that is , among all edges between medoids and @xmath7 , the edge between @xmath8 and @xmath7 has the smallest weight .",
    "otherwise , @xmath20 .",
    "a cluster is identified as a maximal set of vertices that share a given medoid .",
    "like many clustering programs , kmed is in general np - hard and thus computationally intractable for a large @xmath2 . replacing the binary constraints ( [ kmed4 ] ) with nonnegativity constraints , we obtain the linear program relaxation",
    "linkmed : @xmath21 \\label{linkmed1}\\\\ & \\sum_{i=1}^n z_{ii } \\leq k \\label{linkmed2 } \\\\ &",
    "z_{ij } \\leq z_{jj } , \\quad i , j \\in [ n ] \\label{linkmed3 } \\\\ & z_{ij } \\geq 0 \\label{linkmed4}\\,.\\end{aligned}\\ ] ]    for a vector ( point ) @xmath22 , let @xmath23 denote its @xmath3 norm .",
    "it is known that for any configuration of points in one - dimensional euclidean space , the lp relaxation of @xmath0-medoids clustering invariably recovers @xmath0 clusters when unsquared distances are used to measure dissimilarities between points@xcite .",
    "therefore , we confine our attention to @xmath24 .",
    "the following is our main recovery result , and its proof is obtained in the third section .",
    "[ thm1 ] consider @xmath0 unit balls in @xmath25-dimensional euclidean space ( with @xmath24 ) for which the centers of any two balls are separated by a distance of at least @xmath26 . from each ball , draw @xmath27 points @xmath28 as independent samples from a spherically symmetric distribution supported in the ball satisfying @xmath29 suppose that squared distances are used to measure dissimilarities between points , @xmath30 .",
    "then there exist values of @xmath27 and @xmath31 for which the following statement holds : with probability exceeding @xmath32 , the optimal solution to @xmath0-medoids clustering ( kmed ) is unique and agrees with the unique optimal solution to ( linkmed ) , and assigns the points in each ball to their own cluster .",
    "the uniform distribution satisfies in dimension @xmath33 , but for @xmath34 , a distribution satisfying concentrates more probability mass towards the center of the ball .",
    "this means that the recovery results of theorem [ thm1 ] are stronger for smaller @xmath25 .",
    "however , by applying a random projection , @xmath27 points in @xmath25 dimensions can be projected into @xmath35 dimensions while preserving pairwise euclidean distances up to a multiplicative factor @xmath36 . in this sense , clustering problems in high - dimensional euclidean space can be reduced to problems in low - dimensional euclidean space@xcite .",
    "once the centers of any two unit balls are separated by a distance of 4 , points from within the same ball are necessarily at closer distance than points from different balls . for the k - medoid problem ,",
    "cluster recovery guarantees in this regime are given in @xcite .",
    "as far as the authors are aware , theorem [ thm1 ] provides the first recovery guarantees for k - medoids beyond this regime .      while the literature on clustering is extensive , three lines of inquiry",
    "are closely related to the results contained here .",
    "* * recovery guarantees for clustering by convex programming .",
    "* our work is aligned in spirit with the tradition of the compressed sensing community , which has sought probabilistic recovery guarantees for convex relaxations of nonconvex problems .",
    "reference @xcite presents such guarantees for the densest @xmath0-clique problem @xcite : partition a complete weighted graph into @xmath0 disjoint cliques so that the sum of their average edge weights is minimized .",
    "also notable are @xcite , which find recovery guarantees for correlation clustering @xcite and variants .",
    "correlation clustering outputs a partitioning of the vertices of a complete graph whose edges are labeled either `` @xmath37 '' ( agreement ) or `` @xmath38 '' ( disagreement ) ; the partitioning minimizes the number of agreements within clusters plus the number of disagreements between clusters .",
    "+ in all papers mentioned in the previous paragraph , the probabilistic recovery guarantees apply to the stochastic block model ( also known as the planted partition model ) and generalizations .",
    "consider a graph with @xmath2 vertices , initially without edges .",
    "partition the vertices into @xmath0 clusters .",
    "the stochastic block model @xcite is a random model that draws each edge of the graph _ independently _ : the probability of a `` @xmath37 '' ( respectively , `` @xmath38 '' ) edge between two vertices in the same cluster is @xmath39 ( respectively , @xmath40 ) , and the probability of a `` @xmath37 '' ( respectively , `` @xmath38 '' ) edge between two vertices in different clusters is @xmath41 ( respectively , @xmath42 ) .",
    "unfortunately , any model in which edge weights are drawn independently does not include graphs that represent points drawn independently in a metric space .",
    "for these graphs , the edge weights are _ interdependent _ distances .",
    "+ a recent paper @xcite builds on @xcite to derive probabilistic recovery guarantees for subspace clustering : find the union of subspaces of @xmath43 that lies closest to a set of points .",
    "this problem has only trivial overlap with ours ; exemplars are `` zero - dimensional hyperplanes '' that lie close to clustered points , but there is only one zero - dimensional _ subspace _ of @xmath43the origin .",
    "reference @xcite , on the other hand , introduces a tractable convex program that does find medoids .",
    "this program can be recast as a dualized form of @xmath0-medoids clustering .",
    "however , the deterministic guarantee of @xcite : 1 .   applies only to the case where the clusters are recoverable by thresholding pairwise distances ; that is , two points in the same cluster must be closer than two points in different clusters .",
    "our probabilistic guarantees include a regime where such thresholding may fail .",
    "2 .   specifies that a regularization parameter @xmath44 in the objective function must be lower than some critical value for medoids to be recovered .",
    "@xmath44 is essentially a dual variable associated with the @xmath0 of @xmath0-medoids , and it remains unchosen in the karush - kuhn - tucker conditions used to derive the guarantee of @xcite .",
    "the number of medoids obtained is thus unspecified .",
    "by contrast , we guarantee recovery of a specific number of medoids . * * recovery guarantees for learning mixtures of gaussians . *",
    "we derive recovery guarantees for a random model where points are drawn from isotropic distributions supported in nonoverlapping balls .",
    "this is a few steps removed from a gaussian mixture model . starting with the work of dasgupta @xcite",
    ", several papers ( a representative sample is @xcite ) already report probabilistic recovery guarantees for learning the parameters of gaussian mixture models using algorithms unrelated to convex programming .",
    "hard clusters can be found after obtaining the parameters by associating each point @xmath7 with the gaussian whose contribution to the mixture model is largest at @xmath7 .",
    "the questions here are different from our ours : under what conditions does a given polynomial - time algorithm  not a convex program , which admits many algorithmic solution techniques  recover the global optimum ?",
    "how close are the parameters obtained to their true values ?",
    "the progression of this line of research had been towards reducing the separation distances between the centers of the gaussians in the guarantees ; in fact , the separation distances can be zero if the covariance matrices of the gaussians differ @xcite .",
    "our results are not intended to compete with these guarantees .",
    "rather , we seek to provide complementary insights into how often clusters of points in euclidean space are recovered by lp . *",
    "* approximation algorithms for @xmath0-medoids clustering and facility location . * as mentioned above , for any configuration of points in one - dimensional euclidean space , the lp relaxation of @xmath0-medoids clustering exactly recovers medoids for dissimilarities that are unsquared distances @xcite . in more than one dimension ,",
    "nonintegral optima whose costs are lower than that of an optimal integral solution may be realized .",
    "there is a large literature on approximation algorithms for @xmath0-medoids clustering based on rounding the lp solution and other methods .",
    "this literature encompasses a family of related problems known as facility location .",
    "the only differences between the uncapacitated facility location problem ( ufl ) and @xmath0-medoids clustering are that 1 ) only certain points are allowed to be medoids , 2 ) there is no constraint on the number of clusters , and 3 ) there is a cost associated with choosing a given point as a medoid .",
    "+ constant - factor approximation algorithms have been obtained for metric flavors of ufl and @xmath0-medoids clustering , where the measures of distance between points used in the objective function must obey the triangle inequality .",
    "reference @xcite obtains the first polynomial - time approximation algorithm for metric ufl ; it comes within a factor of 3.16 of the optimum .",
    "several subsequent works give algorithms that improve this approximation ratio @xcite .",
    "it is established in @xcite that unless @xmath45 , the lower bounds on approximation ratios for metric ufl and metric @xmath0-medoids clustering are , respectively , @xmath46 and @xmath47 . here",
    ", @xmath48 is the solution to @xmath49 . in unpublished work",
    ", sviridenko strengthens the complexity criterion for these lower bounds to @xmath50 . the best known approximation ratios for metric ufl and metric @xmath0-medoids clustering are , respectively , @xmath51 @xcite and @xmath52 @xcite .",
    "before the 2012 paper @xcite , only a @xmath53-approximation algorithm had been available since 2001 @xcite . because there is still a large gap between the current best approximation ratio for @xmath0-medoids clustering ( @xmath54 ) and the theoretical limit ( @xmath55 ) ,",
    "finding novel approximation algorithms remains an active area of research . along related lines ,",
    "a recent paper @xcite gives the first constant - factor approximation algorithm for a generalization of @xmath0-medoids clustering in which more than one medoid can be assigned to each point .",
    "+ we emphasize that our results are recovery guarantees ; instead of finding a novel rounding scheme for lp solutions , we give precise conditions for when solving an lp yields the @xmath0-medoids clustering .",
    "in addition , our proofs are for squared distances , which do not respect the triangle inequality .",
    "the next section of this paper uses linear programming duality theory to derive sufficient conditions under which the optimal solution to the @xmath0-medoids integer program kmed coincides with the unique optimal solution of its linear programming relaxation linkmed .",
    "the third section obtains probabilistic guarantees for exact recovery of an integer solution by the linear program , focusing on recovering clusters of points drawn from separated balls of equal radius .",
    "numerical experiments demonstrating the efficacy of the linear programming approach for recovering clusters beyond our analytical results are reviewed in the fourth section .",
    "the final section discusses a few open questions , and an appendix contains one of our proofs .",
    "let @xmath56 be the index of vertex @xmath7 s medoid and @xmath57 be @xmath58 . for points in euclidean space , @xmath57 is the index of the second - closest medoid to point @xmath7 . for simplicity of presentation ,",
    "take @xmath59 when there is only one medoid .",
    "denote as @xmath60 the set of points whose medoid is indexed by @xmath7 .",
    "let @xmath61 refer to the positive part of the term enclosed in parentheses . begin by writing a necessary and sufficient condition for a unique integral solution to linkmed .",
    "[ dualcert ] linkmed has a unique optimal solution @xmath62 that coincides with the optimal solution to kmed if and only if there exist some @xmath63 and @xmath64 such that @xmath65\\ , .",
    "\\nonumber\\end{aligned}\\ ] ]    proposition [ dualcert ] rewrites the karush - kuhn - tucker ( kkt ) conditions corresponding to the linear program linkmed in a convenient way ; refer to the appendix for a derivation .",
    "let @xmath66 be the number of points in the same cluster as point @xmath7 .",
    "choose @xmath67 to obtain the following tractable sufficient condition for medoid recovery .",
    "[ forrecursion ] linkmed has a unique optimal solution @xmath68 that coincides with the optimal solution to kmed if there exists a @xmath69 such that @xmath70 for @xmath71 , @xmath72 $ ] , and @xmath73    the choice of the kkt multipliers @xmath74 made here is democratic : each cluster @xmath75 has a total of @xmath63 `` votes , '' which it distributes proportionally among the @xmath74 for @xmath76 .",
    "now consider the dual certificates contained in the following two corollaries .",
    "[ determcorollary ] if kmed has a unique optimal solution @xmath68 , linkmed also has a unique optimal solution @xmath68 when @xmath77}\\max_{j \\in s_{m(i ) } } n_i\\left(w_{ij } - w_{i , m(i)}\\right ) < \\min_{i\\in [ n]}\\min_{j \\notin s_{m(i ) } } n_i\\left(w_{ij } - w_{i , m(i)}\\right)\\,.\\label{generaldeterm}\\ ] ]    [ refdremark ] choose points from within @xmath0 balls in @xmath43 , each of radius @xmath78 , for which the centers of any two balls are separated by a distance of at least @xmath79 .",
    "measure @xmath79 in units of a ball s radius by setting @xmath80 .",
    "take @xmath81 , where @xmath82 is the distance between points @xmath7 and @xmath8 and @xmath83 .",
    "the inequality is satisfied for @xmath84 by assigning the points chosen from each ball to their own cluster . here ,",
    "@xmath85 and @xmath86 are the maximum and minimum numbers of points drawn from any one of the balls , respectively . in the limit @xmath87 ,",
    "becomes @xmath88 .",
    "impose both @xmath89 when points @xmath7 and @xmath8 are in the same cluster and @xmath90 when points @xmath7 and @xmath8 are in different clusters .",
    "combined with , the restrictions on @xmath63 are then @xmath91 ; j\\in s_{m(i ) } ; \\ell \\notin s_{m(i)}\\ , .",
    "\\label{bothcond}\\end{aligned}\\ ] ] condition holds by definition of a medoid _ unless the optimal solution to kmed itself is not unique . _ in that event , it may be possible for a nonmedoid and a medoid in the same cluster to trade roles while maintaining solution optimality , making the lhs of vanish for some @xmath8 .",
    "the phrasing of the corollary accommodates this edge case .",
    "the inequality requires @xmath92 for @xmath7 in the same cluster as @xmath8 but a different cluster from @xmath93 .",
    "so any two points in the same cluster must be closer than any two points in different clusters .",
    "corollary [ determcorollary ] does not illustrate the utility of lp for solving kmed . given the conditions of a recovery guarantee",
    ", clustering could be performed without lp using some distance threshold @xmath94 : place two points in the same cluster if the distance between them is smaller than @xmath94 , and ensure two points are in different clusters if the distance between them is greater than @xmath94 . in the separated balls model of remark [ refdremark",
    "] , @xmath88 guarantees that two points in the same ball are closer than two points in different balls .",
    "the next corollary is needed to obtain results for @xmath95 .",
    "[ usedcorollary ] let @xmath96}\\max_{j \\in s_{m(i ) } } n_i\\left(w_{ij } - w_{i , m(i)}\\right)\\,.\\ ] ] linkmed has a unique optimal solution @xmath68 that coincides with the optimal solution to kmed if @xmath97 \\label{finaltijgreaterthan0}\\\\ \\sum _ { i \\notin s_{m(j ) } } \\left(\\frac{u}{n_i}+w_{i , m(i ) } - w_{ij}\\right)_+ < \\sum_{i \\in s_{m(j ) } } \\left(w_{ij } - w_{i , m(i)}\\right)\\,,\\quad j \\notin { \\cal m}.\\label{bigsuffcond}\\end{aligned}\\ ] ]    impose only @xmath98 when points @xmath7 and @xmath8 are in the same cluster so that together with , the restrictions on @xmath63 are @xmath99 ; j \\notin { \\cal m}\\,.\\label{needpos2}\\end{aligned}\\ ] ] to minimize the lhs of , choose @xmath63 so it approaches its lower bound ..    the inequality requires @xmath100 for @xmath7 and @xmath8 in the same cluster .",
    "corollary [ determcorollary ] imposes both extra upper bounds and extra lower bounds on @xmath63 in its proof .",
    "when two points in different clusters are closer than two points in the same cluster , @xmath63 can not simultaneously satisfy these upper and lower bounds . to break this `` thresholding barrier , '' corollary [ usedcorollary ]",
    "imposes only extra lower bounds on @xmath63 and permits large @xmath63 .",
    "stronger recovery guarantees are obtained for large @xmath63 when medoids are sparsely distributed among the points .",
    "( note that the optimal solution @xmath68 is @xmath0-column sparse . )",
    "the next subsection obtains probabilistic guarantees using corollary [ usedcorollary ] for a variant of the separated balls model of remark [ refdremark ] .",
    "the theorem stated in the introduction is proved in this section . consider @xmath0 nonoverlapping @xmath25-dimensional unit balls in euclidean space for which the centers of any two balls are separated by a distance of at least @xmath79 .",
    "take @xmath6 to be the squared distance @xmath101 between points @xmath102 and @xmath103 . under a mild assumption about how points are drawn within each ball , the exact recovery guarantee of remark [ refdremark ] is extended in this subsection to the regime @xmath104 , where two points in the same cluster are not necessarily closer to each other than two points in different clusters . in particular ,",
    "let the points in each ball correspond to independent samples of an isotropic distribution supported in the ball and which obeys @xmath105 above , @xmath22 is the vector extending from the center of the ball to a given point , and @xmath23 refers to the @xmath3 norm of @xmath106 . in @xmath33 dimensions ,",
    "the assumption holds for the uniform distribution supported in the ball . for larger @xmath25 , requires distributions that concentrate more probability mass closer to the ball s center . for simplicity , we assume in the sequel that the number @xmath27 of points drawn from each ball is equal .",
    "let @xmath107 denote an expectation and @xmath108 a variance .",
    "we state a preliminary lemma .",
    "[ lem : bern ] consider @xmath109 sampled independently from an isotropic distribution supported in a @xmath25-dimensional unit ball which satisfies @xmath110\\,.\\ ] ] use squared euclidean distances to measure dissimilarities between points .",
    "let @xmath111 be the medoid of the set @xmath112 and @xmath113 .",
    "assume that @xmath24 , @xmath114 , and @xmath115 .",
    "with probability exceeding @xmath116 , all of the following statements are true .    1",
    ".   @xmath117 for all @xmath118 $ ] .",
    "2 .   @xmath119 .",
    "3 .   @xmath120 .",
    "first prove statement 1 .",
    "note that for @xmath118 $ ] , @xmath121 above , @xmath122 .",
    "since the @xmath123 are drawn from an isotropic distribution , the direction of the unit vector @xmath124 is independent of @xmath125 and drawn uniformly at random .",
    "it follows that the @xmath126 for @xmath127 are i.i.d .",
    "zero - mean random variables despite how @xmath128 depends on the @xmath129 . indeed , for @xmath127 , @xmath130 where the last equality is obtained by integrating in generalized spherical coordinates .",
    "bernstein s inequality thus gives @xmath131 so @xmath132 is bounded from above with high probability given .",
    "further , @xmath133 from the triangle inequality . these facts together with imply that _ for a given @xmath134 _ ,",
    "@xmath135 with probability exceeding @xmath136 . for @xmath137 ,",
    "the inequalities above clearly hold with unit probability .",
    "take a union bound over the other @xmath118 $ ] to obtain that statement 1 holds with probability exceeding @xmath138 ( for valid @xmath48 as specified in ) .",
    "now observe that @xmath139 it follows that statement 2 holds with probability exceeding @xmath136 .",
    "moreover , statements 1 and 2 together hold with probability exceeding @xmath140 . condition on them , and prove statement 3 by contradiction : suppose that @xmath141 exceeds @xmath142 .",
    "then because @xmath143 , @xmath144 but from statement 1 for @xmath145 , this implies that @xmath146 which violates the assumption that @xmath147 is a medoid .",
    "so all three statements hold with probability exceeding @xmath140 , which is the content of the lemma .",
    "we now write the main result of this section .    *",
    "( restatement of theorem [ thm1].)*[main ] consider @xmath0 unit balls in @xmath25-dimensional euclidean space ( with @xmath24 ) for which the centers of any two balls are separated by a distance of @xmath148 , @xmath149 . from each ball , draw @xmath27 points @xmath28 as independent samples from an isotropic distribution supported in the ball which satisfies @xmath150 suppose that squared distances are used to measure dissimilarities between points , @xmath30 . for each @xmath149",
    ", there exist values of @xmath27 and @xmath0 for which the following statement holds : with probability exceeding @xmath32 , the unique optimal solution to each of @xmath0-medoids clustering and its linear programming relaxation assigns the points in each ball to their own cluster .",
    "[ tableremark ] a table of valid combinations of @xmath151 , @xmath27 , and @xmath0 ( for @xmath152 ) follows .",
    "[ cols=\"^,^,^\",options=\"header \" , ]      +    remarkably , cluster recovery failed no more than 12 ( 8) times out of 1000 across all sets of 1000 simulations for case 1 ( 2 ) .",
    "it therefore appears that high - probability cluster recovery is always realized when drawing samples from the distributions we consider .",
    "however , since the kkt conditions require some assumption about how points cluster , general cluster recovery guarantees are difficult to prove . in the previous section ,",
    "we obtain guarantees assuming the points cluster into the balls from which they are drawn .",
    "the ball recovery results of our simulations for cases 1 and 2 are depicted in , respectively , figures [ unigrid ] and [ r2grid ] . note that the vertical axis of each plot measures the number of _ failed _ ball recoveries .",
    "we conclude this section with the following observations .    * on the whole , case 2 yields more ball recoveries than case 1 .",
    "this is not unexpected : with the exception of @xmath33 , case 2 concentrates more probability mass towards the centers of the balls than does case 1 , typically making the points drawn from each ball cluster more tightly . for @xmath33",
    ", the plots in both figures [ unigrid ] and [ r2grid ] correspond to draws from uniform distributions supported in the balls ; they are repetitions and thus look essentially the same . * in general",
    ", as the number @xmath27 of points drawn from each ball is increased , the number of ball recoveries increases for fixed @xmath25 , @xmath0 , and @xmath79 .",
    "this is again not unexpected : if fewer points are drawn , clustering is more susceptible to outliers that can prevent ball recovery .",
    "* as @xmath79 increases , the number of ball recoveries increases for fixed @xmath25 , @xmath0 , and @xmath27 because points drawn from different balls tend to get further apart . for @xmath33",
    ", high - probability ball recovery appears to be guaranteed for @xmath79 greater than somewhere between @xmath153 and @xmath154 even for the small values of @xmath27 considered here .",
    "this is considerably better than the guarantee of theorem [ main ] : it holds for @xmath33 and @xmath155 only if @xmath27 is at least @xmath156 , as shown toward the end of its proof . * for @xmath27 , @xmath79 , and @xmath25 fixed , there are more ball recoveries for two balls than there are for three balls .",
    "this suggests that as @xmath0 increases , the probability of recovery decreases , which is consistent with intuition from theorem [ main ] .",
    "* for @xmath27 , @xmath79 , and @xmath0 fixed , as @xmath25 increases , the number of ball recoveries increases , even for the uniform distributions of case 1 .",
    "there is thus substantial room for improving our recovery guarantees , which require concentrating more probability mass towards the centers of the balls as @xmath25 increases .",
    "we proved that with high probability , the @xmath0-medoids clustering problem and its lp relaxation share a unique globally optimal solution in a nontrivial regime , where two points in the same cluster may be further apart than two points in different clusters .",
    "however , our theoretical guarantees are preliminary ; they fall far short of explaining the success of lp in distinguishing points drawn from different balls at small separation distance and with few points in each ball . more generally , in simulations we did not present here , the @xmath0-medoids lp relaxation appeared to recover integer solutions for very extreme configurations of points  in the presence of extreme outliers as well as for nonisotropic clusters with vastly different numbers of points .",
    "we thus conclude with a few open questions that interest us .    *",
    "how do recovery guarantees change for different choices of the dissimilarities between points  for example , for euclidean distances rather than for the squared euclidean distances used here ?",
    "what about for gaussian and exponential kernels ?",
    "* can exact recovery be used to better characterize outliers ? *",
    "is it possible to obtain cluster recovery guarantees instead of just ball recovery guarantees ?",
    "( `` cluster recovery '' and `` ball recovery '' are defined right after . )",
    "we thank shi li and chris white for helpful suggestions .",
    "we are extremely grateful to sujay sanghavi for offering his expertise on clustering and for pointing us in the right directions as we navigated the literature .",
    "is especially grateful to jun song for his constructive suggestions and for general support during the preparation of this work .",
    "r.w . was supported in part by a research fellowship from the alfred p. sloan foundation , an onr grant n00014 - 12 - 1 - 0743 , an nsf career award , and an afosr young investigator program award .",
    "was supported by jun song s grant r01ca163336 from the national institutes of health .",
    "10    d.  aloise , a.  deshpande , p.  hansen , and p.  popat , `` np - hardness of euclidean sum - of - squares clustering , '' _ machine learning _ ,",
    "vol .  75 , no .  2 , pp .",
    "245248 , 2009 .",
    "s.  dasgupta and y.  freund , `` random projection trees for vector quantization , '' _ information theory , ieee transactions on _ , vol .",
    "55 , no .  7 , pp .  32293242 , 2009 .",
    "s.  lloyd , `` least squares quantization in pcm , '' _ information theory , ieee transactions on _ , vol .  28 , no .  2 , pp .",
    "129137 , 1982 .",
    "j.  a. hartigan and m.  a. wong , `` algorithm as 136 : a k - means clustering algorithm , '' _ journal of the royal statistical society .",
    "series c ( applied statistics ) _ , vol .",
    "28 , no .  1 ,",
    "pp .  100108 , 1979 .",
    "c.  h. papadimitriou , `` worst - case and probabilistic analysis of a geometric location problem , '' _ siam journal on computing _ , vol .",
    "10 , no .  3 , pp .",
    "542557 , 1981 .",
    "n.  megiddo and k.  j. supowit , `` on the complexity of some common geometric location problems , '' _ siam journal on computing _ , vol .  13 , no .  1 ,",
    "pp .  182196 , 1984 .",
    "m.  van  der laan , k.  pollard , and j.  bryan , `` a new partitioning around medoids algorithm , '' _ journal of statistical computation and simulation _ , vol .",
    "73 , no .  8 , pp .  575584 , 2003 .",
    "l.  kaufman and p.  j. rousseeuw , _ finding groups in data : an introduction to cluster analysis _ ,",
    "vol .  344 .",
    "wiley . com , 2009 .",
    "b.  j. frey and d.  dueck , `` clustering by passing messages between data points , '' _ science _ , vol .",
    "315 , no .",
    "5814 , pp .  972976 , 2007 .",
    "i.  e. givoni and b.  j. frey , `` a binary variable model for affinity propagation , '' _ neural computation _",
    "21 , no .  6 , pp .",
    "15891600 , 2009 .",
    "n. belhumeur , j.  p. hespanha , and d.  j. kriegman , `` eigenfaces vs. fisherfaces : recognition using class specific linear projection , '' _ pattern analysis and machine intelligence , ieee transactions on _ , vol .  19 , no .  7 , pp .  711720 , 1997 .",
    "u.  bodenhofer , a.  kothmeier , and s.  hochreiter , `` apcluster : an r package for affinity propagation clustering , '' _ bioinformatics _ , vol .  27 , no .  17 , pp .",
    "24632464 , 2011 .",
    "m.  mzard , `` computer science . where are the exemplars ? , ''",
    "_ science ( new york , ny ) _ , vol .  315 , no .  5814 , pp .",
    "949951 , 2007 .",
    "m.  leone , m.  weigt , _",
    "et  al . _ ,",
    "`` clustering by soft - constraint affinity propagation : applications to gene - expression data , '' _ bioinformatics _ , vol .",
    "23 , no .",
    "20 , pp .  27082715 , 2007 .",
    "j.  tang , j.  sun , c.  wang , and z.  yang , `` social influence analysis in large - scale networks , '' in _ proceedings of the 15th acm sigkdd international conference on knowledge discovery and data mining _ , pp .  807816 , acm , 2009 .",
    "s.  de  vries , m.  posner , and r.  vohra , `` the k - median problem on a tree , '' tech .",
    "rep . , citeseer , 1998 .    c.  boutsidis , a.  zouzias , and p.  drineas , `` random projections for @xmath157-means clustering , '' _ in proc . nips _ , pp .",
    "pp.298306 , 2010 .",
    "b.  p. ames , `` guaranteed clustering and biclustering via semidefinite programming , '' _ arxiv preprint arxiv:1202.3663 _ , 2012 .",
    "b.  p. ames and s.  a. vavasis , `` convex optimization for the planted k - disjoint - clique problem , '' _ arxiv preprint arxiv:1008.2814 _ , 2010 .",
    "s.  oymak and b.  hassibi , `` finding dense clusters via low rank+ sparse decomposition , '' _ arxiv preprint arxiv:1104.5186 _ , 2011 .",
    "a.  jalali and n.  srebro , `` clustering using max - norm constrained optimization , '' _ arxiv preprint arxiv:1202.5598 _ , 2012 .",
    "y.  chen , s.  sanghavi , and h.  xu , `` clustering sparse graphs , '' _ arxiv preprint arxiv:1210.3335 _ , 2012 .",
    "a.  jalali , y.  chen , s.  sanghavi , and h.  xu , `` clustering partially observed graphs via convex optimization , '' _ arxiv preprint arxiv:1104.4803 _ , 2011 .",
    "n.  bansal , a.  blum , and s.  chawla , `` correlation clustering , '' _ machine learning _ ,",
    "56 , no .  1 - 3 , pp .",
    "89113 , 2004 .",
    "a.  condon and r.  m. karp , `` algorithms for graph partitioning on the planted partition model , '' _ random structures and algorithms _",
    "18 , no .  2 , pp .",
    "116140 , 2001 .",
    "w. holland , k.  b. laskey , and s.  leinhardt , `` stochastic blockmodels : first steps , '' _ social networks _ , vol .  5 , no .  2 , pp .",
    "109137 , 1983 .",
    "m.  soltanolkotabi , e.  elhamifar , and e.  cands , `` robust subspace clustering , '' _ arxiv preprint arxiv:1301.2603 _ , 2013 .",
    "e.  elhamifar and r.  vidal , `` sparse subspace clustering : algorithm , theory , and applications , '' _ arxiv preprint arxiv:1203.1005 _ , 2012 .",
    "e.  elhamifar and r.  vidal , `` sparse subspace clustering , '' in _ computer vision and pattern recognition , 2009 .",
    "cvpr 2009 .",
    "ieee conference on _ , pp .  27902797 , ieee , 2009 .",
    "e.  elhamifar , g.  sapiro , and r.  vidal , `` finding exemplars from pairwise dissimilarities via simultaneous sparse recovery , '' in _ advances in neural information processing systems _ , pp .  1927 , 2012 .",
    "s.  dasgupta , `` learning mixtures of gaussians , '' in _ foundations of computer science , 1999 .",
    "40th annual symposium on _ , pp .  634644 ,",
    "ieee , 1999 .",
    "a.  sanjeev and r.  kannan , `` learning mixtures of arbitrary gaussians , '' in _ proceedings of the thirty - third annual acm symposium on theory of computing _ , pp .  247257 , acm , 2001 .",
    "s.  vempala and g.  wang , `` a spectral algorithm for learning mixture models , '' _ journal of computer and system sciences _ , vol .",
    "68 , no .  4 , pp .",
    "841860 , 2004 .",
    "r.  kannan , h.  salmasian , and s.  vempala , `` the spectral method for general mixture models , '' in _ learning theory _ , pp .  444457 , springer , 2005 .",
    "d.  achlioptas and f.  mcsherry , `` on spectral learning of mixtures of distributions , '' in _ learning theory _ , pp .  458469 , springer , 2005 .",
    "j.  feldman , r.  a. servedio , and r.  odonnell , `` pac learning axis - aligned mixtures of gaussians with no separation assumption , '' in _ learning theory _",
    ", pp .  2034 , springer , 2006 .",
    "s.  c. brubaker , `` robust pca and clustering in noisy mixtures , '' in _ proceedings of the twentieth annual acm - siam symposium on discrete algorithms _ , pp .",
    "10781087 , society for industrial and applied mathematics , 2009 .",
    "m.  belkin and k.  sinha , `` learning gaussian mixtures with arbitrary separation , '' _ arxiv preprint arxiv:0907.1054 _ , 2009 .",
    "k.  chaudhuri , s.  dasgupta , and a.  vattani , `` learning mixtures of gaussians using the k - means algorithm , '' _ arxiv preprint arxiv:0912.0086 _ , 2009 .",
    "a.  t. kalai , a.  moitra , and g.  valiant , `` efficiently learning mixtures of two gaussians , '' in _ proceedings of the 42nd acm symposium on theory of computing _ , pp .",
    "553562 , acm , 2010 .",
    "m.  belkin and k.  sinha , `` polynomial learning of distribution families , '' in _ foundations of computer science ( focs ) , 2010 51st annual ieee symposium on _ , pp .  103112 , ieee , 2010 .",
    "d.  b. shmoys ,  .",
    "tardos , and k.  aardal , `` approximation algorithms for facility location problems , '' in _ proceedings of the twenty - ninth annual acm symposium on theory of computing _ , pp .  265274 , acm , 1997 .",
    "s.  guha and s.  khuller , `` greedy strikes back : improved facility location algorithms , '' in _ proceedings of the ninth annual acm - siam symposium on discrete algorithms _ , pp .  649657 , society for industrial and applied mathematics , 1998 .",
    "m.  r. korupolu , c.  g. plaxton , and r.  rajaraman , `` analysis of a local search heuristic for facility location problems , '' in _ proceedings of the ninth annual acm - siam symposium on discrete algorithms _ , pp .  110 , society for industrial and applied mathematics , 1998 .",
    "m.  charikar and s.  guha , `` improved combinatorial algorithms for the facility location and k - median problems , '' in _ foundations of computer science , 1999 .",
    "40th annual symposium on _ , pp .  378388 ,",
    "ieee , 1999 .",
    "m.  mahdian , e.  markakis , a.  saberi , and v.  vazirani , `` a greedy facility location algorithm analyzed using dual fitting , '' in _ approximation , randomization , and combinatorial optimization : algorithms and techniques _ , pp .  127137 , springer , 2001 .",
    "k.  jain , m.  mahdian , and a.  saberi , `` a new greedy approach for facility location problems , '' in _ proceedings of the thirty - fourth annual acm symposium on theory of computing _",
    ", pp .  731740 , acm , 2002 .",
    "f.  a. chudak and d.  b. shmoys , `` improved approximation algorithms for the uncapacitated facility location problem , '' _ siam journal on computing _ , vol .",
    "33 , no .  1 ,",
    "pp .  125 , 2003 .",
    "k.  jain , m.  mahdian , e.  markakis , a.  saberi , and v.  v. vazirani , `` greedy facility location algorithms analyzed using dual fitting with factor - revealing lp , '' _ journal of the acm ( jacm ) _ , vol .",
    "50 , no .  6 , pp .",
    "795824 , 2003 .    m.  sviridenko , `` an improved approximation algorithm for the metric uncapacitated facility location problem , '' in _ integer programming and combinatorial optimization _ , pp .  240257 , springer , 2006 .",
    "m.  mahdian , y.  ye , and j.  zhang , `` approximation algorithms for metric facility location problems , '' _ siam journal on computing _ , vol .",
    "36 , no .  2 , pp .",
    "411432 , 2006 .",
    "j.  byrka , `` an optimal bifactor approximation algorithm for the metric uncapacitated facility location problem , '' in _ approximation , randomization , and combinatorial optimization .",
    "algorithms and techniques _ , pp .  2943 , springer , 2007 .",
    "j.  vygen , _ approximation algorithms facility location problems_. forschungsinstitut fr diskrete mathematik , rheinische friedrich - wilhelms - universitt , 2005 .",
    "s.  li , `` a 1.488 approximation algorithm for the uncapacitated facility location problem , '' _ information and computation _ , 2012 .",
    "s.  li and o.  svensson , `` approximating k - median via pseudo - approximation , '' in _ proceedings of the 45th annual acm symposium on symposium on theory of computing _ , pp .  901910 , acm , 2013 .",
    "v.  arya , n.  garg , r.  khandekar , a.  meyerson , k.  munagala , and v.  pandit , `` local search heuristics for k - median and facility location problems , '' _ siam journal on computing _ , vol .",
    "33 , no .  3 , pp .",
    "544562 , 2004 .",
    "m.  hajiaghayi , w.  hu , j.  li , s.  li , and b.  saha , `` a constant factor approximation algorithm for fault - tolerant k - median , '' _ arxiv preprint arxiv:1307.2808 _ , 2013 .",
    "[ dualcertrestatement ] * ( restatement of proposition [ dualcert ] . )",
    "* linkmed has a unique solution @xmath68 that coincides with the solution to kmed if and only if there exist some @xmath63 and @xmath64 such that @xmath65\\ ,",
    ". \\nonumber\\end{aligned}\\ ] ]    suppose the solution to kmed @xmath158 is known .",
    "let @xmath159 be the index set of nonzero entries of @xmath160 , and let @xmath161 be its complement .",
    "for some matrix @xmath4 , denote as @xmath162 the vector of @xmath163 variables @xmath5 for which @xmath164 .",
    "eliminating the @xmath165 from linkmed using the constraints ( [ linkmed1 ] ) yields the following equivalent program : @xmath166 ; j \\notin m ; i \\neq j\\label{linkmed2 - 2}\\\\ & \\sum_{i\\notin { \\cal m } } z_{ii } - \\sum_{i \\in { \\cal m } } \\sum_{j \\neq i } z_{ij } \\leq 0 \\label{linkmed2 - 2a}\\\\ & x_{ij } \\leq 1 - \\sum_{\\ell \\neq j } z_{j\\ell } , \\quad j \\in m ; i \\notin",
    "s_j \\label{linkmed3 - 2}\\\\ & \\sum_{\\ell \\neq m(i ) } z_{m(i),\\ell } \\leq \\sum_{\\ell \\neq m(i ) } z_{i\\ell } , \\quad i \\notin m \\label{linkmed4 - 2}\\\\ & \\sum_{\\ell \\neq m(i ) } z_{i\\ell } \\leq 1 , \\quad i \\in [ n ] \\label{linkmed5 - 2 } \\\\ &",
    "z_{ij } \\geq 0 , \\quad ( i , j ) \\in \\omega^c\\label{linkmed6 - 2}\\,,\\end{aligned}\\ ] ] where @xmath167 .",
    "the only @xmath168 in the program ( [ linkmedobj-2])-([linkmed6 - 2 ] ) have @xmath169 .",
    "associate the _ nonnegative _ dual variables @xmath170 , @xmath63 , @xmath171 , @xmath172 , @xmath173 , and @xmath174 with ( [ linkmed2 - 2 ] ) , ( [ linkmed2 - 2a ] ) , ( [ linkmed3 - 2 ] ) , ( [ linkmed4 - 2 ] ) , ( [ linkmed5 - 2 ] ) , and ( [ linkmed6 - 2 ] ) , respectively . enforcing stationarity of the lagrangian",
    "gives @xmath175    call the primal lagrangian @xmath176 . above , the quantities on the lefthand sides of the equalities are components of @xmath177 . because @xmath178 , complementary slackness of ( [ linkmed3 - 2 ] ) and ( [ linkmed5 - 2 ] ) gives that @xmath179 and @xmath180 where a medoid solution is exactly recovered .",
    "the @xmath174 are merely slack variables .",
    "uniqueness of the solution @xmath181 occurs if and only if for any feasible perturbation @xmath182 of @xmath183 , @xmath184 because the feasible solution set includes only nonnegative @xmath183 , any feasible perturbation @xmath182 away from @xmath185 must be nonnegative with at least one positive component .",
    "demanding that every component of @xmath177that is , each lhs of -is positive thus simultaneously satisfies the kkt conditions and guarantees solution uniqueness .",
    "more precisely , linkmed has a unique solution @xmath68 that coincides with the solution to kmed if and only if there exist @xmath186 that satisfy @xmath187    assigning each @xmath170 its minimum possible value minimizes the restrictiveness of ( [ kkt3strict ] ) .",
    "from ( [ kkt1strict ] ) , the minimum possible value of @xmath188 approaches @xmath189 from above . from ( [ kkt2strict ] ) ,",
    "the minimum possible value of @xmath190 approaches @xmath191 from above .",
    "inserting these values of @xmath170 into the conditions above gives @xmath192 there exist @xmath193 that satisfy - if and only if there exist @xmath194 that satisfy - ."
  ],
  "abstract_text": [
    "<S> for a certain class of distributions , we prove that the linear programming relaxation of @xmath0-medoids clustering  a variant of @xmath0-means clustering where means are replaced by exemplars from within the dataset  distinguishes points drawn from nonoverlapping balls with high probability once the number of points drawn and the separation distance between any two balls are sufficiently large . </S>",
    "<S> our results hold in the nontrivial regime where the separation distance is small enough that points drawn from different balls may be closer to each other than points drawn from the same ball ; in this case , clustering by thresholding pairwise distances between points can fail . </S>",
    "<S> we also exhibit numerical evidence of high - probability recovery in a substantially more permissive regime . </S>"
  ]
}