{
  "article_text": [
    "natural language processing is a wide and varied subfield of artificial intelligence .",
    "the question of how best to give a computer an intuitive understanding of language is one with many possible answers , which nonetheless has not yet been answered satisfactorily .",
    "most existing programs work only within a limited scope , and in most cases it can not realistically be said that the computer actually understands the language in question .",
    "this project seeks to give a computer a truly intuitive understanding of a given language , by developing methods which allow the computer to learn the language with a minimum of outside input , on its own terms .",
    "we have developed methods to teach the computer both the morphology and the syntax of a language , and have provided some suggestions regarding language acquisition at the semantic level .",
    "the idea of natural language processing originates from alan turing , a british computer scientist , who formulated a hypothetical test , known as the `` turing test '' .",
    "the `` turing test '' proposes that the question `` can machines think ? '' can be answered if a computer is indistinguishable from a human in all facets of thought , such as conversation ; object identification based on given properties ; and so forth @xcite . after turing s proposition",
    ", many attempts have been made to create natural language processing software , particularly using sound recognition , which is currently used in cell - phones , most proficiently in the iphone 4s siri system. however , most of these programs do not have high - level semantic abilities , rather they have a very limited set of operations , for which keywords are assigned .",
    "for example , the siri system can send an email or text message .",
    "when told to send an email or text message , the software uses these keywords to open a blank e - mail or text message and when told what is to be written in the e - mail or text message , there is no semantic understanding of the message , simply a transcription of the words using voice recognition @xcite . similarly , there is a lot of software , such as lingpipe , that is able to determine the origin and basic ` significance ' of a term or sentence by searching the term(s ) on a database for other uses of the term(s ) .",
    "these programs do not , however , gain a semantic understanding of the term(s ) , rather they simply collect patterns of information with association to the term(s ) @xcite .",
    "there have also been some more technical , less commercially efficacious attempts at natural language processing , such as statistical language parsers , which have been intricately developed by many educational institutions .",
    "parsers are a set of algorithms that determine the parts of speech of the words in a given sentence .",
    "current parsers use a set of human - parsed sentences that creates a probability distribution , which is then used as a statistical model for parsing other sentences .",
    "stanford university and the university of california berkeley use probabilistic context - free grammars ( pcfg ) statistical parsers , which are the most accurate statistical parsers currently used , with 86.36% and 88% accuracy , respectively @xcite @xcite .",
    "the different parts of speech are separated as in figure [ tree ] .        in figure 1 , nn @xmath0 noun , np @xmath0 noun phrase , s @xmath0 subject , vp @xmath0 verb phrase , and the other symbols represent more specific parts of speech .",
    "one can see that the parser splits the sentence into three parts : the subject noun phrase , the verb phrase , and the noun phrase .",
    "each of these parts is then split into more parts and those parts into parts , finally arriving at individual qualifications for each word .",
    "the assignment of a given part of speech for a word is determined by tentatively allocating the part of speech that is most probable for that word , which is then tested within its phrase ( i.e. subject noun phrase , or verb phrase , etc . ) , and if the probability remains high then that part of speech is set for the word .",
    "these parsers are called context - free because the parse of a word is not affected by the other words in the sentence other than those in its phrase , while the less accurate parsers obtain an overall probability for a sentence and adjust their parsing accordingly @xcite .",
    "in addition to statistical parsers , which only determine the syntax of a sentence , some elementary programs have been written for evaluating the semantics of a given body of text .",
    "there is a system called frump that organises news stories by finding key words in an article that match a set of scripts and then assigns the article to a certain category , in which it is grouped with other articles of similar content .",
    "scisor summarizes a given news article by analyzing the events , utilizing three different sets of knowledge : semantic knowledge , abstract knowledge , and event knowledge . as the program sifts through the body of text , certain words trigger different pieces of knowledge , which are compiled to gain the best understanding of that word or sequence of words .",
    "the resultant meanings can then be organized and rewritten using similar meanings , equally balanced among the three sets of knowledge as the original piece of information .",
    "similarly , topic summarizes a given text by distinguishing the nouns and noun phrases and then analyzing their meaning through a `` thesaurus - like ontological knowledge base '' , after which the program uses these equivalent meanings to rewrite the text @xcite .",
    "certain elements of language are commonly used both in natural language processing and the general analysis of language .",
    "these properties include bigrams and recursion , two properties which play a significant role in this project .",
    "an @xmath1-gram is a sequence of @xmath1 letters .",
    "the most commonly used forms of @xmath1-grams are bigrams and trigrams because these offer a specific indication for a set of information , without signifying extremely rare and complex aspects of the subject .",
    "a good example of this is the use of bigrams in cryptography .",
    "a common method of decoding a message that has been encoded using a keyword , like the vigenere cipher encryption , is to calculate the distance in letters between two of the same bigrams in order to determine the length of the keyword , and then the keyword itself @xcite . if any n - grams are used , where n is greater than or equal to 4 or even in some cases if n is equal to 3 , then the number of same n - grams for a given message would be very rare and make determining the length of the keyword increasingly difficult .    similarly , in natural language processing ,",
    "bigrams are used for word discrimination , which is the understanding of an unknown word based upon bigram correspondence with a reference list of known words .",
    "in addition , word bigrams are used in some lexical parsers , the markov model for bag generation , and several text categorization tools @xcite .",
    "the principle of recursion is an essential aspect of human language , and is considered one of the primary ways in which children learn a language . for a sentence with a particular pattern , a word with a specific part of speech can be exchanged for another word of the same part of speech , indicating that the two words have the same part of speech .",
    "for example , given the sentence : `` the boy wears a hat '' , it can be determined that `` the '' and `` a '' are the same part of speech by reconstructing the sentence as `` a boy wears the hat '' .",
    "in addition , the word `` boy '' can be exchanged for the word `` girl '' , indicating that these are also the same type of word , thereby expanding the lexicon of the child .",
    "in addition , the words of a sentence can remain unchanged , while the pattern changes , thereby introducing a new part of speech .",
    "if we have the sentence `` the boy wears a hat '' or `` a b c a b '' if represented as a pattern of parts of speech , we can add a `` d '' part of speech by creating a new sentence , `` the boy wears a big hat '' ( a b c a d b ) .",
    "the child ascertains that `` big '' must be a new part of speech because no words have previously been placed between an `` a '' and a `` b '' .",
    "this method can be repeated for any new part of speech , as well as embedded clauses such as `` the boy , who is very funny , wears a big hat . ''",
    "finally , recursion can be used to indicate the grammatical structures of a language .",
    "let us examine the following poem :    when tweetle beetles fight , + it s called + a tweetle beetle battle . + and when they + battle in a puddle , + it s a tweetle + beetle puddle battle . + and when tweetle beetles + battle with paddles in a puddle , + they call it a tweetle + beetle puddle paddle battle",
    "+    - excerpt from dr .",
    "fox in socks _",
    "@xcite    the author uses the recursive principle to indicate that `` tweetle beetle '' can be both a noun and an adjective , and then repeats this demonstration with `` puddle '' and `` paddle '' .",
    "further , the correct placement of the new noun acting as an adjective is shown to be between the old string of nouns acting as adjectives and the object noun .",
    "conversely , the poem illustrates that a noun acting as an adjective can be rewritten as a preposition and an added clause , e.g `` a tweetle beetle puddle battle '' can be rephrased as `` a tweetle beetle battle in a puddle '' @xcite .",
    "thus , the principle of recursion can allow a child to acquire new vocabulary , new types of parts of speech , and new forms of grammar .",
    "there is a basic three - link chain in the structure of language .",
    "phonetics is the most basic structure , which is formed into meaning by units , known as words .",
    "units are then arranged syntactically to form sentences , which in turn forms a more extensive meaning , formally called semantics @xcite .",
    "it is fundamental in learning a language that a computer understand the connections in the phonetics - syntax - semantics chain , and the structure and computations of each , with the exception of phonetics .",
    "phonetics and their formulation can be disregarded because these refer more greatly to the connections of the brain to external sounds , than the core structure of language .",
    "in fact , the entire external world can be ignored , as there need not be an inference between external objects in their human sensory perception , and their representation as language , formally known as pragmatics or in chomskyan linguistics as e - language ( external language ) . instead ,",
    "the relations between words and meaning , intricately augmented by the semantics created by their syntactically accurate formed sentences , is the only form of language necessary , denominated contrastingly as i - language ( internal language ) @xcite .",
    "noam chomsky argues that i - language is the only form of language that can be studied scientifically because it represents the innate structure of language @xcite .",
    "language similar to this form can be found in humans who are literate in a language , yet can not speak it .",
    "therefore , due to the increase in structure , the lack of external representation in natural language processing may be more advantageous than one might think .",
    "this project examines the nature of language acquisition in computers by implementing techniques similar to those used by children to acquire language .",
    "we have focused primarily on morphology and syntax , developing methods to allow a computer to gain knowledge of these aspects of language .",
    "we have developed programs in both c++ and java .",
    "regarding morphology , the program is able to analyze the word structure of given languages and distinguish between languages in different samples of text using bigram frequencies , and we have examined the usefulness and limitations of this method in the context of existing methods .",
    "using this technique we have developed computationally understandable definitions of english , french and spanish morphologies .",
    "we have also described and partially implemented a novel technique for understanding the syntax of a language using a minimum of initial input and recursive methods of learning both approximate meanings of words and valid sentence structures .",
    "finally , we provide suggestions for future work regarding the further development of our methods for understanding syntax as well as potential methods for gaining a rudimentary understanding of semantics .",
    "to analyze the morphology of a given language , bigrams can be used to define and compare languages . since the frequency distribution of a set of bigrams is unique to a given language ( across a large enough sample text ) , this can be used as an accurate identifier of a language with minimal effort .",
    "the program was initially developed in c++ then translated to java to take advantage of non - standard characters , and is set up in two main portions .",
    "the first step involves generating a table of frequency values from a file , and the second step is to compare the two tables and determine the level of similarity .    to generate a frequency table , a two - dimensional numerical array is created from the set of valid characters such that the array includes a space for every possible bigram , with the initial value for each being set to zero . for each word from the input file , the program checks each pair of letters , adding one to the corresponding position in the bigram frequency table .",
    "once the end of the file is reached , each frequency count is divided by the total number of bigrams found times 100 to give a percentage frequency .",
    "this process is shown in figure [ bigram ] .",
    "this produces an array similar to table [ array ] , which can be analyzed separately to examine common and uncommon bigrams for a given language , or compared with another text s table to distinguish between languages as detailed below .",
    ".sample of frequency array [ cols=\"^,^,^,^,^\",options=\"header \" , ]",
    "in this project we have developed methods for allowing a computer to understand and learn both the morphology and the syntax of a language . using novel techniques or applications ,",
    "we have designed and implemented these methods and tested their capabilities for learning language .",
    "although the use of bigrams in language analysis is not a new idea , we have implemented it in a novel way by working to develop it as a defining quality and learning mechanism for natural language processing .",
    "the method proves very useful for understanding the morphology of a language , though only to a point .",
    "it is extremely effective when using a large enough sample text , but with smaller sample texts it is no longer able to accurately compare languages .",
    "hence , although it creates a computationally effective `` definition '' of a language , its actual ability as a learning mechanism is limited . used in tandem with other methods ,",
    "the bigram method could prove extremely powerful .",
    "the recursive learning method implemented for gaining an understanding of syntax proves very useful and has great potential to be developed further .",
    "both of its submethods work with high accuracy for simple sentences , and hence it is able to develop a growing model of sentence construction . even more particularly , it is able to do this with a very small amount of initial input and with methods which could be applied to many types of languages .      the use of bigrams to understand and analyze different parts of a given language has been studied and implemented substantially . for example , there are programs that calculate bigram frequencies to evaluate a language s morphology .",
    "however , unlike our program , none to date have utilized the differences in bigram frequencies between two languages to distinguish one language from the next .",
    "the system in the program that was used for determining the parts of speech in a sentence has rarely been attempted , and when it has been used , only partially and in conjunction with other methods .",
    "most natural language processing programs have been designed to be as the efficient and effective as possible . as a result , many use large banks of initial data , which the program then analyzes and uses for subsequent input . as discussed previously ,",
    "the most common and successful programs of this sort are statistical parsers . on the contrary",
    ", our program uses the recursive principle to acquire new vocabulary and forms of syntax for a given language , provided only a very small initial set of data . in practice ,",
    "our model only required one sentence with verb and noun indicated to determine the parts of speech of all other words , although not denoting them in linguistic terms ( article , preposition , etc . ) , as well as learn new words and , in theory , to learn new sentence patterns . despite the extensive power of the recursive method ,",
    "it has rarely been used in the history of natural language processing .",
    "the results of our program illustrate the potential abilities of the recursive method that have not been seen previously .",
    "the program as it stands now can learn and understand a range of language elements , including morphology and simple sentence patterns . however , there is still significant room for further exploration both by developing the techniques for learning syntax to allow for a more complete range of sentence patterns , and by developing methods for a computational understanding of semantics .",
    "in addition to existing sentence structures and constructs , the syntax program can learn other common constructs .",
    "although some may be understandable at present , others may require some additions to the program to fully understand .",
    "below are some examples of other simple sentence constructs and how the program would interpret them .",
    "_ `` the man has a blue hat . '' _    here , the only unknown word with present knowledge is `` blue '' .",
    "the program at present would interpret it using the word - context method , resulting in a type of `` abnoun bnoun '' .",
    "continuing in this manner would quickly lead to complications , however , so the program could be extended to understand words based on the form of types which are not nouns or verbs .",
    "the word directly before blue has the type `` bnoun '' , so `` blue '' would be interpreted in this manner as a noun , resulting in two nouns in a row .",
    "the program could additionally be edited to interpret two like words in a row as a `` noun phrase '' or `` verb phrase '' , which would differentiate adjectives from nouns and adverbs from verbs in a way more intuitive to the computer .",
    "_ `` the hat is blue . '' _",
    "this sentence presents a different use of an adjective effectively in the place of a noun .",
    "assuming `` is '' had been previously learned as a verb , this sentence would be more - or - less readily understandable as `` blue '' is still interpreted as related to nouns .",
    "this introduces another common sentence construct as well , namely that some nouns can appear directly after verbs without a `` bnoun '' word in between . here",
    ", it may become worthwhile to add some indicator to new nouns about whether they can appear directly after a verb or not .",
    "_ `` the man has one hat . ''",
    "this sentence would introduce numerical words , which would be readily understandable as `` bnoun '' words similar to `` a '' or `` the '' .",
    "this is sufficient and accurate for most cases , though as the program expands into semantics this construct may require more specific definition .",
    "_ `` the man has four hats . '' _    here , the concept of plurality is introduced .",
    "this sentence would simply be another example of the above sentence with regards to syntax alone  the word `` hats '' would just be considered a new noun",
    ". however , this would likely be the most problematic concept regarding semantics . without an external concept of meaning or some other indication",
    ", plurality would have to be learned simply by similarity at the word level .",
    "in many cases this would be sufficient , such as `` hats '' , but some words do not follow standard plurality rules such as `` mice '' versus `` mouse '' .",
    "similar issues apply to verb tenses , though here the rules are even less standardized .",
    "this issue could be at least partially remedied by creating an artificial semblance of external understanding , though this would likely prove difficult as well .",
    "many other sentence constructs are built from these sorts of basic patterns .",
    "for example , another common sentence construct involves prepositions such as the sentence `` the man threw the hat in the trash '' . assuming prior knowledge of the nouns present",
    ", the program could interpret `` in '' as verb - like , appearing between two noun phrases .",
    "this is , again , a sufficient interpretation in most cases .",
    "a marker indicating what would effectively be two full constructs could be implemented as well .",
    "embedded clauses would be interpreted similarly , where the program would find the pattern of the outside clause and then the pattern of the inside clause .",
    "an understanding of punctuation would make such sentences more easily interpretable .    despite some issues ,",
    "the program can , currently or with only minor modifications , understand many common sentence constructs using the two main forms of learning and still a fairly small amount of initial information .",
    "the program proves fairly versatile , though of course not at the full level of human understanding .",
    "semantics is the meanings of words or sentences , not only determined by direct definition , but also by connotation and context . to gain a computational understanding of semantics in a given language , without external representation for words ,",
    "we have devised an associative approach . for a noun , different adjectives and verbs can be used when employing the noun in a sentence .",
    "the particular set of adjectives and verbs for that noun are representative of the nature of the object .",
    "a second noun will have some shared verbs and adjectives , and the degree to which this is true will indicate the similarities of the two objects .",
    "conversely , a verb would be understood based on the different objects associated with it , especially the order of the nouns , i.e the subjects and objects used with that noun . from a set of sentences",
    ", a threshold of similarity could be experimentally determined , which would result in the categorization of the different nouns and verbs .",
    "the sequence of sentences could be as follows :    1 .",
    "the man wears the big hat .",
    "the man throws the small hat .",
    "+ ( `` hat '' is known to be something that can be `` big '' , `` small '' , `` worn '' , and `` thrown '' ) 3 .   the man throws the big ball .",
    "the man bounces the small ball .",
    "+ ( `` ball '' is like `` hat '' in having the ability to be `` big '' or `` small '' and can be `` thrown '' , however it has not yet be found that it can be `` worn '' , and `` hat '' has not be shown to be able to be `` bounced '' ) 5 .",
    "the man wears the big shoes .",
    "the man throws the small shoes .",
    "+ ( `` shoes '' is then understood as the same type of object as `` hat '' ) 7 .",
    "the man uses the telephone .",
    "the man answers the telephone .",
    "let us stop here because the fundamental logic of the sequence of sentences can now be seen . using these characteristics of nouns ,",
    "a complex associative web would be formed , where objects have meaning based on their relation to a set of other objects , which also have meaning in relations to another set objects that the first may not .",
    "this web may be represented visually by a venn diagram similar to the one in figure [ venn ] .        for the verbs `` wear '' , `` throw '' , `` bounce '' etc .",
    ", the program would interpret the above sentences as suggesting that only `` man '' can conduct these actions , but can not be the recipient of these actions , while certain nouns can be the recipient of these actions .",
    "further , it should be noted that the training sentences do not require a strict order because a characteristic of a particular noun would be stored until another noun was found to have the same characteristic , and the two nouns would then share a link of the web .",
    "similarly , a verb would have tentative subjects and objects associated with it until more were found .",
    "nevertheless , this method is limited by the requirement of large amounts of sentences in order to gain any significant understanding of a given word .    to understand a concept such as time , which is essential for semantics and acknowledging tenses ,",
    "the program would require some initial specification , as well as using a time indicator in all sentences referring to the past or present .",
    "it would start with the conditional parameter that if a sentence has the word `` yesterday '' , `` ago '' , `` tomorrow '' , `` later '' , `` past '' , or `` future '' , then a time different from the current moment is being referenced , and the verb used is similar to another verb ( the present form , which is the first form the program learns ) , but with a slightly different morphology . yet , a problem arises because `` last '' and `` next '' applied in `` last / next week '' or `` last / next month '' can not be used strictly as indicators of time , as they can be used in other contexts , such as `` he ate the last cookie in the jar '' or `` he is next in line at the supermarket '' .",
    "thus , in certain cases , time would present a difficulty for the semantic understanding of the program .",
    "the same applies for the use of negation , as in the sentence `` the man is not big '' , whereby `` not '' , `` never '' , `` none '' , `` no longer '' , and `` no more '' would have to be explained prior and would result in the noun or verb being categorized as different from other nouns and verbs with shared associative terms .",
    "in addition , the associative method only allows for a definitional understanding of a given word , which can be substantially limited due to the possible changes in the meaning of a word as a result of its context . to allow a computer to have an understanding of context",
    ", a system could be implemented to keep track of previously learned information .",
    "cognitive scientist marvin minsky suggests that a series of `` frames '' which represent generalized situations can be used to represent cognition computationally .",
    "these general frames could then be modified with situation - specific variables @xcite .",
    "this idea could prove useful in natural language processing to give a computer an understanding of context .",
    "for example , if a series of sentences read `` john is playing soccer .",
    "he kicked the ball , '' the program would be able to select a general frame which it could use to keep track of relevant variables , such as `` john '' being the subject of this action  hence linking this to the `` he '' in the next sentence .",
    "another issue that might arise is the issue of connotative meaning of words rather than merely denotative meaning .",
    "this is also related to the idea of symbolism , another element of language which can prove difficult for a computer to understand . here",
    ", a method similar to the associative approach above could be implemented after the initial denotative associations were formed . here",
    ", the training sentences would be ones using symbolism rather than literal ones as above .",
    "if a word is suddenly associated with a word which is not within the proper categorization , such as `` a heart of stone , '' it could be interpreted by the computer as a connotative association .",
    "this would allow the computer to examine characteristics related only to one or the other , hence gaining an understanding of the symbolic associations of words .",
    "using certain principles of language , we have designed a novel method by which a computer can gain an intuitive understanding of language rather than simply an artificial understanding .",
    "we have developed techniques by which a computer can learn and analyze the morphology of any given language , and hence understand differences between two languages .",
    "we have also developed a recursive learning system for understanding sentence patterns and constructs , which uses a minimum of initial information . at present",
    ", the program can interpret many basic sentences , and we have also provided possibilities and suggestions for extending the capabilities of the program . this approach is unique compared to common natural language processing systems because of this lack of need for significant initial input and its recursive design , and could have great potential in the field of natural language processing .",
    "99    e. reingold .",
    "the turing test .",
    "university of toronto department of psychology .",
    "available at http://www.psych.utoronto.ca/users/reingold/courses/ai/turing.html .",
    "learn more about siri .",
    "apple inc .",
    "available at http://www.apple.com/iphone/features/siri-faq.html .",
    "alias - i .",
    "available at http://alias - i.com / lingpipe/.    d. klein and c.d . manning .",
    "accurate unlexicalized parsing . in : _ proceedings of the 41st annual meeting on association for computational linguistics _",
    ", vol . 1 ( 2003 ) , 423430 .",
    "m. bansal and d. klein .",
    "simple , accurate parsing with an all - fragments grammar . in : _ proceedings of the 48th annual meeting on association for computational linguistics _",
    "( 2010 ) .",
    "e. charniak .",
    "statistical parsing with a context - free grammar and word statistics . in : _ proceedings of the fourteenth national conference on artificial intelligence_. aaai press / mit press , menlo park , ca ( 1997 ) , 598603 .",
    "c.m . powell . from e - language to i - language : foundations of a pre - processor for the construction integration model .",
    "oxford brookes university ( 2005 ) .",
    "r. morelli .",
    "the vigenere cipher .",
    "trinity college department of computer science .",
    "available at http://www.cs.trincoll.edu/~crypto/historical/vigenere.html .",
    "chen and y.s .",
    "approximate n - gram markov model natural language generation .",
    "national taiwan university department of computer science and information engineering ( 1994 ) .",
    "_ fox in socks_. available at http://ai.eecs.umich.edu/people/dreeves/fox-in-socks.txt .",
    "m.h . christiansen and n. chater . constituency and recursion in language . in : m.a .",
    "arbib . _ the handbook of brain theory and neural networks_. 2nd ed . mit press , cambridge , ma ( 2003 ) , 267271 .",
    "_ child language : acquisition and growth_. cambridge university press , cambridge , uk ( 2006 ) .",
    "the charter of fundamental rights of the european union .",
    "european parliament .",
    "available at http://www.europarl.europa.eu/charter/default_en.htm .",
    "digraph frequency .",
    "cornell university department of mathematics .",
    "available at http://www.math.cornell.edu/~mec/2003-2004/cryptography/subs/digraphs.html .",
    "m. minsky .",
    "a framework for representing knowledge . in : j. haugeland , editor .",
    "_ mind design_. the mit press , cambridge , ma ( 1981 ) , 95128 .",
    "sample texts for the morphology - analysis system were primarily selected from randomized wikipedia articles in the respective languages , and were selected primarily for length .",
    "the following sample texts were used for testing :    english eu charter ( available at http://www.europarl.europa.eu/charter/pdf/text_en.pdf )    french eu charter ( available at http://www.europarl.europa.eu/charter/pdf/text_fr.pdf )    spanish eu charter ( available at http://www.europarl.europa.eu/charter/pdf/text_es.pdf )    english wikipedia article on `` philosophy '' ( available at http://en.wikipedia.org/wiki/philosophy )    english wikipedia article on `` encyclopedias '' ( available at http://en.wikipedia.org/wiki/encyclopedia )    english wikipedia article on `` peace dollars '' ( available at http://en.wikipedia.org/wiki/peace_dollar )    english wikipedia article on `` buffalo nickels '' ( available at http://en.wikipedia.org/wiki/buffalo_nickel )    french wikipedia article on `` france '' ( available at http://fr.wikipedia.org/wiki/france )    french wikipedia article on `` capitalism '' ( available at http://fr.wikipedia.org/wiki/capitalisme )    french wikipedia article on `` karl marx '' ( available at http://fr.wikipedia.org/wiki/karl_marx )    french wikipedia article on `` democracy '' ( available at http://fr.wikipedia.org/wiki/dmocratie )    spanish wikipedia article on `` jazz '' ( available at http://es.wikipedia.org/wiki/jazz )    spanish wikipedia article on `` new york city '' ( available at http://es.wikipedia.org/wiki/new_york_city )    spanish wikipedia article on `` the sassanid empire '' ( available at http://es.wikipedia.org/wiki/imperio_sasnida )    spanish wikipedia article on `` the crown of castile '' ( available at http://es.wikipedia.org/wiki/corona_de_castilla )",
    ".... package ngrams ;    import java.io.bufferedreader ; import java.io.file ; import java.io.filewriter ; import java.io.ioexception ; import java.io.inputstreamreader ; import java.io.printwriter ; import java.util.scanner ;    public class ngrams {        // main program      public static void main(string [ ] args ) throws ioexception {          string file1 = \" \" , file2 = \" \" ;          float diff = 0 ; // total frequency difference between two files          char [ ] alpha = { ' a','\\`{a}','\\^{a}','\\\"{a}','b','c','\\c{c}','d','e','\\`{e}','\\'{e}','\\^{e}','\\\"{e}','f','g','h','i','\\^{i}','\\\"{i}','j','k','l','m','n','o','\\^{o } ' ,              ' p','q','r','s','t','u','\\`{u}','\\^{u}','\\\"{u}','v','w','x','y','\\\"{y}','z ' } ; //",
    "valid characters          system.out.print(\"input first file name : \") ;          file1 = read(file1 ) ; // reads text from file          system.out.print(\"input second file name : \") ;          file2 = read(file2 ) ;          float bi1 [ ] [ ] = count(file1 , alpha ) ; // creates frequency table for file          float bi2 [ ] [ ] = count(file2 , alpha ) ;          // calculates total frequency difference          for ( int i = 0 ; i < alpha.length ; i++ )              for ( int j = 0 ; j < alpha.length ; j++ )                  diff + = math.abs(bi1[i][j ] - bi2[i][j ] ) ;          system.out.println(diff ) ;          if ( diff < 55 ) //",
    "experimentally determined threshold              system.out.println(\"same language \" ) ;          else              system.out.println(\"different language \" ) ;      }        // create frequency tables      public static float [ ] [ ] count(string file , char [ ] alpha )      throws ioexception {",
    "// 2-d frequency table of all possible bigrams          float bigram [ ] [ ] = new float[alpha.length][alpha.length ] ;          for ( int i = 0 ; i <",
    "alpha.length ; i++ )              for ( int j = 0 ; j < alpha.length ; j++ )                  bigram[i][j ] = 0 ; // initialize with frequency=0          int a = alpha.length+1 , b = alpha.length+1 ;          float total = 0 ; // total number of bigrams          scanner in = new scanner(new file(file+\".txt \" ) ) ;          while(in.hasnext(\"\\\\s+ \" ) ) { // read file word by word              string word = in.next(\"\\\\s+ \" ) ;              word.tolowercase ( ) ;              for ( int k = 0 ; k < word.length()-1 ; k++ )              { // for each pair of letters                  a = alpha.length+1 ;                  b = alpha.length+1 ;                  for ( int m = 0 ; m < alpha.length ; m++ )                  { // locates each letter within alpha list                      if ( word.charat(k ) = = alpha[m ] )                          a = m ;                      if ( word.charat(k+1 ) = = alpha[m ] )                          b = m ;                  }                  if ( a < alpha.length & & b < alpha.length )                  { // adds valid bigrams to frequency list                      bigram[a][b]++ ;                      total++ ;                  }              }          }          // create new file with frequency table          printwriter out = new printwriter(new filewriter(file+\"_tab.csv \" ) ) ;          for ( int p = 0 ; p < alpha.length ; p++ ) {              for ( int q = 0 ; q < alpha.length ; q++ ) {                  bigram[p][q ] = ( bigram[p][q ] / total ) * 100 ;                      // convert to decimal frequency                  out.print(bigram[p][q ] ) ;                  out.print ( \" , \" ) ;              }              out.print(\"\\n \" ) ;          }          out.close ( ) ;          return bigram ;      }        // read text from file      public static string read(string str ) {          string str2 = \" \" ;          bufferedreader read = new bufferedreader(new inputstreamreader(system.in ) ) ;          try {              str2 = read.readline ( ) ;          } catch ( ioexception ioe ) {              system.out.println(\"error : can not read input\\n \" ) ;              read(str ) ;          }          return str2 ;      }    } ....",
    "to begin , types must be created and initial input defined , and the sentence must be divided into its component words which are checked against known information :    ....      // type definitions      struct word {          string word ;          string type ;      } list[50 ] ;      struct pattern {          int wcount ;          string patt[10 ] ;      } list2[10 ] ;      // initial input - first word must be \" null \" to avoid errors      list[0].word = \" null \" ;      list[0].type = \" null \" ;      list[1].word = \" has \" ;      list[1].type = \" verb \" ;      list[2].word = \" hat \" ;      list[2].type = \" noun \" ;      list[3].word = \" man \" ;      list[3].type = \" noun \" ;             // split sentence into component words      for (",
    "i = 0 ; i < sen.length ( ) ; i++ ) {          if ( sen.at(i ) = = ' ' )              sen_count++ ;      }      for ( i = 0 ; i < sen.length ( ) ; i++ ) {          if ( sen.at(i ) = = ' ' ) {              words[pos ] = sen.substr(temp,i-temp ) ;              temp = i+1 ;              pos++ ;          }      }        // find words in \" list \" array      num2 = num ;      for ( i = 0 ; i <",
    "sen_count ; i++ ) { // for each word          for ( j = 0 ; j < num ; j++ ) {              if ( words[i ] = = list[j].word ) {                  inarray[i ] = j ; // for known words , track position              }          }          if ( inarray[i ] = = 0 ) {              inarray[i ] = num2 ; // for unknown words , set new position              num2++ ;          }      } ....            // define unknown words by surrounding words      for ( i = 0 ; i < sen_count ; i++ ) { // for each word          if ( inarray[i ] > = num )          { // if unknown , position will be greater than num ( number of words )              list[inarray[i]].word = words[i ] ;              list[inarray[i]].type = \" \" ;              if ( i > 0 ) // if not the first word in the sentence                  list[inarray[i]].type =                   list[inarray[i]].type + \" a \" + list[inarray[i-1]].type + \" \" ;              if ( i < sen_count-1 ) // if not the last word in the sentence                  list[inarray[i]].type =                   list[inarray[i]].type + \" b \" + list[inarray[i+1]].type + \" \" ;          }          else if ( list[inarray[i]].type ! = \" noun \" & &          list[inarray[i]].type ! = \" verb \" )          { // if known , but not a noun or verb , checks if should be redefined              type_temp = \" \" ;              if ( i > 0 )                  type_temp = type_temp + \" a \" + list[inarray[i-1]].type + \" \" ;              if ( i < sen_count-1 )                  type_temp = type_temp + \" b \" + list[inarray[i+1]].type + \" \" ;              if ( type_temp.length ( ) < = list[inarray[i]].type.length ( ) )                  // the shorter one is the type                  list[inarray[i]].type = type_temp ;          }      }      num = num2 ; // reset known number of words        ....      // define unknown words by sentence structure      for ( j = 0 ; j < 2 ; j++ ) { // for each existing pattern          matches = 0 ;          for ( i = 0 ; i < sen_count ; i++ ) { // for each word              if ( inarray[i ] < num )                  if ( list[inarray[i]].type = = list2[j].patt[i ] )                      matches++ ;          }          if ( sen_count = = list2[j].wcount ) // if word counts match              matches++ ;          if ( matches > sen_count/2 )          { // if enough matches exist , unknown words are defined              for ( i = 0 ; i < sen_count ; i++ ) {                  if ( inarray[i ] > = num ) {                      list[inarray[i]].word = words[i ] ;                      list[inarray[i]].type = list2[j].patt[i ] ;                  }              }          }      }      num = num2 ; // reset known number of words ...."
  ],
  "abstract_text": [
    "<S> this project explores the nature of language acquisition in computers , guided by techniques similar to those used in children . </S>",
    "<S> while existing natural language processing methods are limited in scope and understanding , our system aims to gain an understanding of language from first principles and hence minimal initial input . </S>",
    "<S> the first portion of our system was implemented in java and is focused on understanding the morphology of language using bigrams . </S>",
    "<S> we use frequency distributions and differences between them to define and distinguish languages . </S>",
    "<S> english and french texts were analyzed to determine a difference threshold of 55 before the texts are considered to be in different languages , and this threshold was verified using spanish texts . </S>",
    "<S> the second portion of our system focuses on gaining an understanding of the syntax of a language using a recursive method . </S>",
    "<S> the program uses one of two possible methods to analyze given sentences based on either sentence patterns or surrounding words . </S>",
    "<S> both methods have been implemented in c++ . </S>",
    "<S> the program is able to understand the structure of simple sentences and learn new words . </S>",
    "<S> in addition , we have provided some suggestions regarding future work and potential extensions of the existing program . </S>"
  ]
}