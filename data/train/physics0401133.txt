{
  "article_text": [
    "as of the durham conference  @xcite , the problem of obtaining a goodness of fit in unbinned likelihood fits was an unsolved one . in what follows , we will denote by the vector @xmath0 , the theoretical parameters ( @xmath0 for `` signal '' ) and the vector @xmath1 , the experimentally measured quantities or `` configurations '' . for simplicity",
    ", we will illustrate the method where both @xmath0 and @xmath1 are one dimensional , though either or both can be multi - dimensional in practice .",
    "we thus define the theoretical model by the conditional probability density @xmath2",
    ". then an unbinned maximum likelihood fit to data is obtained by maximizing the likelihood  @xcite , @xmath3 where the likelihood is evaluated at the @xmath4 observed data points @xmath5 .",
    "such a fit will determine the maximum likelihood value @xmath6 of the theoretical parameters , but will not tell us how good the fit is .",
    "the value of the likelihood @xmath7 at the maximum likelihood point does not furnish a goodness of fit , since the likelihood is not invariant under change of variable .",
    "this can be seen by observing that one can transform the variable set @xmath1 to a variable set @xmath8 such that @xmath9 is uniformly distributed between 0 and 1 .",
    "such a transformation is known as a hypercube transformation , in multi - dimensions .",
    "other datasets will yield different values of likelihood in the variable space @xmath1 when the likelihood is computed with the original function @xmath10 .",
    "however , in the original hypercube space , the value of the likelihood is unity regardless of the dataset @xmath11 , thus the likelihood @xmath7 can not furnish a goodness of fit by itself , since neither the likelihood , nor ratios of likelihoods computed using the same distribution @xmath10 is invariant under variable transformations .",
    "the fundamental reason for this non - invariance is that only a single distribution , namely , @xmath10 is being used to compute the goodness of fit .",
    "in binned likelihood cases , where one is comparing a theoretical distribution @xmath2 with a binned histogram , there are two distributions involved , the theoretical distribution and the data distribution .",
    "the @xmath12 of the data is approximated by the bin contents of the histogram normalized to unity .",
    "if the data consists of @xmath4 events , the @xmath12 of the data @xmath13 is defined in the frequentist sense as the normalized density distribution in @xmath1 space of @xmath4 events as @xmath14 . in the binned case",
    ", we can bin in finer and finer bins as @xmath14 and obtain a smooth function , which we define as the @xmath12 of the data @xmath13 . in practice",
    ", one is always limited by statistics and the binned function will be an approximation to the true @xmath12 .",
    "we can now define a likelihood ratio @xmath15 such that @xmath16 where we have used the notation @xmath17 to denote the event set @xmath5 .",
    "let us now note that @xmath18 is invariant under the variable transformation @xmath19 , since @xmath20 and the jacobian of the transformation @xmath21 cancels in the numerator and denominator in the ratio .",
    "this is an extremely important property of the likelihood ratio @xmath18 that qualifies it to be a goodness of fit variable .",
    "since the denominator @xmath22 is independent of the theoretical parameters @xmath0 , both the likelihood ratio and the likelihood maximize at the same point @xmath6 .",
    "one can also show  @xcite that the maximum value of the likelihood ratio occurs when the theoretical likelihood @xmath23 and the data likelihood @xmath24 are equal for all @xmath25 .",
    "in the case where the @xmath12 @xmath13 is estimated by binned histograms and the statistics are gaussian , it is readily shown  @xcite that the commonly used goodness of fit variable @xmath26 .",
    "it is worth emphasizing that the likelihood ratio as defined above is needed and not just the negative log of theoretical likelihood @xmath27 to derive this result .",
    "the popular conception that @xmath28 is -2 log @xmath27 is simply incorrect!. it can also be shown that the likelihood ratio defined above can describe the binned cases where the statistics are poissonian  @xcite . in order to solve our problem of goodness of fit in unbinned likelihood cases",
    ", one needs to arrive at a method of estimating the data @xmath12 @xmath13 without the use of bins .",
    "one of the better known methods of estimating the probability density of a distribution in an unbinned case is by the use of probability density estimators @xmath29 , also known as kernel density estimators  @xcite @xmath30 .",
    "the @xmath12 @xmath13 is approximated by @xmath31 where a kernel function @xmath32 is centered around each data point @xmath25 , is so defined that it normalizes to unity and for large @xmath4 approaches a dirac delta function  @xcite .",
    "the choice of the kernel function can vary depending on the problem .",
    "a popular kernel is the gaussian defined in the multi - dimensional case as @xmath33 where @xmath34 is the error matrix of the data defined as @xmath35 and the @xmath36 implies average over the @xmath4 events , and @xmath37 is the number of dimensions .",
    "the hessian matrix @xmath38 is defined as the inverse of @xmath34 and the repeated indices imply summing over .",
    "the parameter @xmath39 is a `` smoothing parameter '' , which has@xcite a suggested optimal value @xmath40 , that satisfies the asymptotic condition @xmath41 the parameter @xmath39 will depend on the local number density and will have to be adjusted as a function of the local density to obtain good representation of the data by the @xmath42 .",
    "our proposal for the goodness of fit in unbinned likelihood fits is thus the likelihood ratio @xmath43 evaluated at the maximum likelihood point @xmath6 .",
    "we consider a simple one - dimensional case where the data is an exponential distribution , say decay times of a radioactive isotope .",
    "the theoretical prediction is given by @xmath44 we have chosen an exponential with @xmath45 for this example . the gaussian kernel for the @xmath42",
    "would be given by @xmath46 where the variance @xmath47 of the exponential is numerically equal to @xmath0 . to begin with",
    ", we chose a constant value for the smoothing parameter , which for 1000 events generated is calculated to be 0.125 . figure  [ genev ] shows the generated events , the theoretical curve @xmath2 and the @xmath42 curve @xmath48 normalized to the number of events .",
    "the @xmath42 fails to reproduce the data near the origin due to the boundary effect , whereby the gaussian probabilities for events close to the origin spill over to negative values of @xmath1 .",
    "this lost probability would be compensated by events on the exponential distribution with negative @xmath1 if they existed . in our case , this presents a drawback for the @xmath42 method , which we will remedy later in the paper using @xmath42 definitions on the hypercube and periodic boundary conditions . for the time being , we will confine our example to values of @xmath49 to avoid the boundary effect .    in order to test the goodness of fit capabilities of the likelihood ratio @xmath18",
    ", we superimpose a gaussian on the exponential and try and fit the data by a simple exponential .     and the @xmath42 estimator ( solid ) histogram with no errors . [ genev],width=245 ]",
    "figure  [ genev1 ] shows the `` data '' with 1000 events generated as an exponential in the fiducial range @xmath50 .",
    "superimposed on it is a gaussian of 500 events .",
    "more events in the exponential are generated in the interval @xmath51 to avoid the boundary effect at the fiducial boundary at c=1.0 .",
    "since the number density varies significantly , we have had to introduce a method of iteratively determining the smoothing factor as a function of @xmath1 as described in  @xcite . with this modification in the @xmath42 ,",
    "one gets a good description of the behavior of the data by the @xmath42 as shown in figure  [ genev1 ]",
    ".     generated as an exponential with decay constant @xmath0=1.0 with a superimposed gaussian of 500 events centered at @xmath1=2.0 and width=0.2 .",
    "the @xmath42 estimator is the ( solid ) histogram with no errors .",
    "[ genev1],width=245 ]    we now vary the number of events in the gaussian and obtain the value of the negative log likelihood ratio @xmath52 as a function of the strength of the gaussian .",
    "table  [ tab1 ] summarizes the results .",
    "the number of standard deviations the unbinned likelihood fit is from what is expected is determined empirically by plotting the value of @xmath52 for a large number of fits where no gaussian is superimposed ( i.e. the null hypothesis ) and determining the mean and @xmath53 of this distribution and using these to estimate the number of @xmath47 s the observed @xmath52 is from the null case .",
    "table  [ tab1 ] also gives the results of a binned fit on the same `` data '' .",
    "it can be seen that the unbinned fit gives a @xmath54 discrimination when the number of gaussian events is 85 , where as the binned fit gives a @xmath55 of 42/39 for the same case .",
    "we intend to make these tests more sophisticated in future work .    .",
    "goodness of fit results from unbinned likelihood and binned likelihood fits for various data samples .",
    "the negative values for the number of standard deviations in some of the examples is due to statistical fluctuation .",
    "[ tab1 ] [ cols=\"^,^,^,^ \" , ]",
    "equation  [ pns ] can be used to show that the expectation value of @xmath56 of the parameter @xmath0 is given by @xmath57 where @xmath58 is the average of @xmath0 for individual experiments .",
    "equation  [ sbar ] states @xmath56 is the weighted average of @xmath58 obtained from individual measurements , the weight for each experiment being the `` data likelihood '' @xmath59 for that experiment . in the absence of experimental bias , @xmath56 would be identical to the true value @xmath60 .",
    "it remains to be shown that the weighted average of maximum likelihood values @xmath6 from indiviual experiments also converge to the maximum likelihood point of @xmath61 .",
    "also one needs to develop an analytic theory of the goodness of fit for unbinned likelihood fits .",
    "finally , one needs to investigate a bit more closely the transformation properties of @xmath61 under change of variable .",
    "to conclude , we have proposed a scheme for obtaining the goodness of fit in unbinned likelihood fits .",
    "this scheme involves the usage of two @xmath12 s , namely data and theory . in the process of computing the fitted errors , we have demonstrated that the quantity in the joint probability equations that has been interpreted as the `` bayesian prior '' is in reality a number and not a distribution .",
    "this number is the value of the @xmath12 of the parameter , which we call the `` unknown concomitant '' at the true value of the parameter .",
    "this number is calculated from a combination of data and theory and is seen to be an irrelevant parameter .",
    "if this viewpoint is accepted , the controversial practice of guessing distributions for the `` bayesian prior '' can now be abandoned , as can be the terms `` bayesian '' and `` frequentist '' .",
    "we show how to use the posterior density to rigorously calculate fitted errors .",
    "9 k.  kinoshita , `` evaluating quality of fit in unbinned maximum likelihood fitting '' , proceedings of the conference on advanced statistical techniques in particle physics , durham , march 2002 ippp/02/39 , dcpt/02/78 .",
    "+ b.  yabsley,``statistical practice at the belle experiment , and some questions'',ibid .",
    "r.  d.  cousins,``conference summary '' , ibid .",
    "r.  a.  fisher,``on the mathematical foundations of theoretical statistics '' , _ philos .",
    "london ser .",
    "a _ * 222 * , 309 - 368(1922 ) ; + r.  a.  fisher,``theory of statistical estimation '' , _ proc . cambridge philos .",
    "* 22 * , 700 - 725 ( 1925 ) . ``",
    "a measure of the goodness of fit in unbinned likelihood fits '' , r  .raja , long write - up , + http://www-conf.slac.stanford.edu/phystat2003/talks + /raja",
    "/ raja_bayes_maxlike.pdf `` end of bayesianism ? '' , r.raja , http://www-conf.slac.stanford.edu/phystat2003/talks/raja/raja-end_bayesianism.pdf e.  parzen , `` on estimation of a probability density function and mode '' _ ann.math.statis . _  * 32 * , 1065 - 1072 ( 1962 ) .",
    "d.  scott .",
    "_ multivariate density estimation_.  john wiley & sons , 1992 .",
    "+ m.  wand and m.  jones ,  _ kernel smoothing_. chapman & hall , 1995 ."
  ],
  "abstract_text": [
    "<S> maximum likelihood fits to data can be done using binned data ( histograms ) and unbinned data . with binned data </S>",
    "<S> , one gets not only the fitted parameters but also a measure of the goodness of fit . with unbinned data , </S>",
    "<S> currently , the fitted parameters are obtained but no measure of goodness of fit is available . </S>",
    "<S> this remains , to date , an unsolved problem in statistics . </S>",
    "<S> using bayes theorem and likelihood ratios , we provide a method by which both the fitted quantities and a measure of the goodness of fit are obtained for unbinned likelihood fits , as well as errors in the fitted quantities . </S>",
    "<S> the quantity , conventionally interpreted as a bayesian prior , is seen in this scheme to be a number not a distribution , that is determined from data . </S>"
  ]
}