{
  "article_text": [
    "given an external perturbation @xmath0 , the total molecular electronic energy can be expanded in a taylor series@xmath1 where the coefficients @xmath2 are called the _ molecular properties _ and describe the response of the system to the applied perturbation @xcite .",
    "we consider time - independent properties , which can be obtained by differentiating the energy at @xmath3,@xmath4 many examples of useful derivatives can be given .",
    "for instance , the derivatives with respect to the electric field @xmath5 are the permanent electric dipole , the static polarizability , and the static hyperpolarizabilities of various orders:@xmath6 where the subscript denotes differentiation at @xmath7 .",
    "the derivatives with respect to nuclear coordinates @xmath8 include the forces on the nuclei and the force constants , while mixed derivatives can provide information such as raman intensities @xcite .    on a classical computer ,",
    "an energy derivative can be evaluated either numerically or analytically , and we discuss each approach in turn .",
    "numerical derivative techniques rely on computing the value of the energy at several discrete points , and then using those values to estimate the true derivative .",
    "the simplest technique is finite difference , which for the first derivative in one dimension is the familiar formula,@xmath9 in @xmath10 dimensions , computing the gradient requires at least @xmath11 evaluations of the energy , once at the origin and once at a distance @xmath12 along each axis ( fig .",
    "[ fig : dimensions ] ) .",
    "similarly , evaluating higher - order derivatives requires the knowledge of the energy on a particular grid , with at least @xmath13 points for the @xmath14 derivative .",
    "while numerical gradient techniques usually require minimal effort to implement , they are occasionally susceptible to numerical instability , due to the ill - posedness of numerical differentiation in general @xcite .",
    "this is particularly problematic when using finite - precision arithmetic , where various rounding errors can accumulate and be amplified upon division by the small number @xmath12 .",
    "the fact that small errors in the evaluated function can lead to large errors in the derivative affects _ ab initio _ electronic structure methods insofar as they usually involve long calculations with many potential sources of error , including rounding and quadrature .",
    "-dimensional space classically requires sampling the function @xmath11 times , once at the origin and once at a distance @xmath12 along each of the axes . shown above",
    "are the sample points for the cases @xmath15 through @xmath16 .",
    "the quantum gradient algorithm can evaluate many sample points in superposition , producing the same calculated gradient using only one call to the function.[fig : dimensions ] ]    by contrast , analytic derivative techniques are those that compute the derivative by direct evaluation of an analytic expression .",
    "they were introduced in quantum chemistry by pulay @xcite , and have since largely supplanted numerical procedures .",
    "they are numerically more stable and , more importantly , they are usually faster as well .",
    "analytic gradient formulas exist for just about all electronic structure techniques and for most kinds of perturbations .",
    "to illustrate the argument and establish the correct scaling , we will describe the particularly simple case of derivatives of fully variational wavefunctions .",
    "we start by writing the molecular energy as a function @xmath17 of the external perturbation @xmath0 and the wavefunction parameters @xmath18 . these parameters , such as the configuration interaction coefficients ,",
    "completely describe the electronic wavefunction .",
    "although @xmath18 is a function of @xmath0 , for simplicity we will write only @xmath19 .",
    "the energy is said to be _ fully variational _ with respect",
    "to @xmath19 if , for any given @xmath0 , @xmath19 assumes the value @xmath20 such that the variational condition holds:@xmath21 where @xmath22 indicates @xmath23 . in that case",
    "we can write @xmath24 .    for fully variational wavefunctions , the gradient with respect to @xmath0 is given by@xmath25 where we have used the variational condition and the hellman - feynman theorem . since one need not know the first - order wavefunction response @xmath26 , computing the gradient is , to within a small constant factor @xcite , as hard as computing the energy . that is , once @xmath27 is available , calculating the expectation value of the hamiltonian has approximately the same computational cost as calculating its derivative .",
    "however , computing the second derivative matrix does require the knowledge of the first - order wavefunction response .",
    "in fact , as a direct consequence of wigner s @xmath28 rule of perturbation theory , one needs to know the first @xmath29 wavefunction responses in order to calculate the @xmath30 derivative .",
    "computing the responses often becomes the bottleneck , and it is what leads to a higher asymptotic cost of higher - order derivatives . while the gradient requires about the same resources as the energy , the second and third derivatives require resources that scale as @xmath31 times the cost of computing the energy ( where @xmath10 is the number of degrees of freedom , i.e. , the dimension of @xmath0 ) @xcite .",
    "this scaling comes about because @xmath31 time is required to compute the matrix @xmath26 .",
    "likewise , the scaling of the @xmath30 derivative is @xmath32 , because the bottleneck becomes the computation of the @xmath33 order wavefunction response . in other words ,",
    "the computational cost of finding the @xmath14 analytical derivative is @xmath34 , roughly a quadratic speed - up over the @xmath32 numerical methods of the same degree .",
    "the fact that the scaling of derivative techniques , both numerical and analytical , depends on @xmath10 has meant that these techniques are often restricted to small systems .",
    "is independent of system size .",
    "for example , if the perturbation is the electric field , then @xmath16 , and indeed there are classical techniques for computing electrical properties of large molecules .",
    "the quantum speed - up is therefore most pronounced in cases where @xmath10 varies with system size , as it does whenever there is differentiation with respect to nuclear coordiates . ]",
    "this is most acutely true of the molecular hessian , which is often beyond reach , even though the gradient is routinely accessible .",
    "we now show that if quantum computers were available , the cost of the higher derivatives would no longer be prohibitive .",
    "the quantum algorithm for molecular properties is based on jordan s quantum gradient estimation algorithm @xcite .",
    "jordan s method can numerically compute the gradient of any function @xmath35 , given a black box ( oracle ) that computes the value of @xmath35 for an arbitrary input .",
    "in particular , the algorithm can evaluate the gradient using a _ single _ query to @xmath35 , regardless of the number of dimensions @xmath10 of the domain of @xmath35 .",
    "by contrast , the simplest classical finite - difference scheme would require @xmath11 queries to @xmath35 ( see fig .",
    "[ fig : dimensions ] ) .",
    "the speed - up is essentially achieved by being able to sample along all the @xmath10 dimensions in superposition .",
    "we apply jordan s algorithm to the computation of molecular properties by specifying a way to compute the energy on a quantum computer as well as by outlining how to obtain higher derivatives . in this section",
    ", we describe the algorithm , its application to quantum chemistry , and finally argue that a return to numerical techniques for molecular properties would be justified if quantum computers became feasible .",
    ".time resources required by various techniques of computing molecular properties , in terms of the cost of computing the energy .",
    "for example , the entry `` @xmath11 '' means that computing the property requires @xmath11 evaluations of the molecular energy , while the entries in the `` analytical '' column indicate comparable computational effort .",
    "@xmath36 is the total electronic energy , @xmath0 is the external perturbation , and @xmath10 is the dimension of @xmath0 .",
    "all the derivatives are evaluated at @xmath3 . on classical computers ,",
    "the numerical scalings correspond to the simplest finite - difference scheme .",
    "analytical techniques are the ones that evaluate the derivative directly ( the exponent @xmath37 comes from wigner s @xmath28 rule ) . on a quantum computer",
    ", the quantum gradient estimation algorithm is used .",
    "it should be noted that on a quantum computer , the number of evaluations of @xmath36 needed for any derivative is independent of @xmath10 , and thus of the size of the system . [",
    "cols=\"^,^,^,^\",options=\"header \" , ]     we assume that the molecular energy is a smooth , bounded function of the perturbation , @xmath38^{d}\\rightarrow\\left[e_{\\mathrm{min}},e_{\\mathrm{max}}\\right]$ ] , where a small @xmath12 is chosen so that @xmath36 varies sufficiently slowly over the domain . for convenience ,",
    "we express the perturbations in units such that @xmath12 is unitless and such that the bounds are the same along all of the axes .",
    "we also assume that we have a black box for @xmath36 , which , given a perturbation @xmath0 , outputs the energy @xmath39 .",
    "the precise nature of the algorithm inside the black box is not important , so long as it can be implemented on a quantum computer . in particular , any classical technique of electronic - structure theory can be converted into a quantum algorithm @xcite . in sec .",
    "[ sec : blackbox ] , we will discuss possible realizations of the black box , including the use of quantum simulation algorithms , which offer a significant improvement over classical ones .",
    "we begin by choosing the number @xmath29 of bits of precision that we desire in the final gradient .",
    "jordan s algorithm starts in an equal superposition on @xmath10 registers of @xmath29 qubits each ( @xmath40 qubits total ) @xcite:@xmath41 where @xmath42 , the states @xmath43 are integers on @xmath29 qubits represented in binary , and @xmath44 is a @xmath10-dimensional vector of all the @xmath45 s .",
    "we use this state as an input for the black box for @xmath36 , which will , for every integer - vector @xmath44 in the superposition , append a phase proportional to the energy @xmath39 at perturbation @xmath46 ( where @xmath47 is the vector @xmath48 and serves to center the sampling region on the origin ) . to achieve maximum precision with fewest qubits",
    ", one needs an estimate @xmath49 of the largest magnitude of any of the first derivatives of @xmath36 .",
    "then , the energy evaluated by the black box is scaled by a factor @xmath50 . because the black box operates on all the terms in the superposition at once ,",
    "a single call results in the state @xmath51\\left|\\mathbf{k}\\right\\rangle \\approx\\\\ \\approx\\frac{1}{\\sqrt{n^{d}}}\\sum_{\\mathbf{k}}\\exp\\left[\\frac{2\\pi in}{hm}\\left(e(\\mathbf{0})+\\frac{h}{n}\\left(\\mathbf{k}-\\mathbf{n}/2\\right)\\cdot\\left.\\frac{\\text{d}e}{\\text{d}\\boldsymbol{\\mu}}\\right|_{\\mathbf{0}}\\right)\\right]\\left|\\mathbf{k}\\right\\rangle .\\end{gathered}\\ ] ] the neglect of terms quadratic in @xmath12 and higher is a valid approximation for sufficiently small @xmath12 ( the error caused by higher - order terms is discussed in @xcite and is only polynomial ) .",
    "the final state is separable and equals @xmath52\\left|k_{1}\\right\\rangle\\cdots \\\\",
    "\\cdots\\sum_{k_{d}=0}^{n-1}\\exp\\left[\\frac{2\\pi i}{m}k_{d}\\left.\\frac{\\partial e}{\\partial\\mu_{d}}\\right|_{\\mathbf{0}}\\right]\\left|k_{d}\\right\\rangle , \\end{gathered}\\ ] ] with phase @xmath53    applying the inverse quantum fourier transform @xcite to each of the @xmath10 registers results in the gradient @xmath54 the scaling factor @xmath55 ensures that @xmath56 is an integer - vector with @xmath29 bits of precision along each dimension .",
    "it should be reiterated that a single call to @xmath36 was made , as opposed to the @xmath11 that would be needed in the case of numerical differentiation by finite difference .",
    "overall , the gradient estimation algorithm produces the transformation@xmath57 we can compute the hessian ( and higher derivatives ) by iterating this algorithm .",
    "if , instead of making a call to @xmath39 , the algorithm sought @xmath58 from the black box , we would perform , at the cost of this single additional subtraction , @xmath59 with global phase @xmath60 because we will be using this procedure as a subroutine , it is important to remove ( or `` uncompute '' ) the global phase , which would otherwise become a relative phase .",
    "one additional evaluation of @xmath36 ( at @xmath61 ) suffices for this uncomputation .",
    "overall , this supplies another black box , which , given @xmath61 , yields @xmath62 using only two calls to the original black box for @xmath36 .",
    "one can use the gradient algorithm with this new black box , producing the state@xmath63 which is a two - dimensional array of @xmath64 quantum registers containing all the elements of the hessian matrix of @xmath36 .",
    "in addition , @xmath65 is an estimate for the magnitude of the largest second derivative , and the phase is @xmath66    computing higher derivatives would require additional factors of two in the number of required black box calls , caused by the need to uncompute a global phase at each step ( this problem is a common feature when it comes to recursing quantum algorithms @xcite ) .",
    "hence , evaluating the @xmath14 derivative requires @xmath67 queries to @xmath36 , which , although exponential in @xmath29 , is much better than @xmath13 , which is the minimum number of function queries required to compute the derivative by classical finite difference .",
    "we stress that the number of calls to @xmath36 is independent of @xmath10 , and thus of the size of the system , for the derivative of any order .",
    "one could remark that the quantum gradient algorithm is a numerical approach and that therefore , just like classical numerical techniques , it would be affected by numerical instability .",
    "this implies that the quantum gradient algorithm can not be used indiscriminately for problems that feature errors that can not be controllably reduced through additional computational effort .",
    "for example , finite - precision arithmetic presents the same problems to quantum computers as it does to classical ones , but the rounding errors can be brought under control by using more digits of precision ( as on classical computers ) .",
    "quantum chemistry techniques might present numerical problems as well , insofar as they contain uncontrolled sources of error .",
    "however , if the technique for computing the energy is numerically exact , that is to say , if the error in the energy can be controllably reduced below any level , the magnitude of the numerical error in the calculated derivative can likewise be made arbitrarily small .",
    "fortunately , quantum computers would make it possible to efficiently evaluate the numerically exact molecular energy , meaning that numerical instability will not be a problem .",
    "we turn to the topic of molecular energy evaluation next .",
    "the application of jordan s gradient algorithm to chemical problems requires that there be a black box that can compute the value of the ground - state molecular energy at any value of the perturbation @xmath0 in the neighborhood of @xmath3 .",
    "furthermore , to avoid numerical artifacts , this black box should be numerically exact , allowing the error in the energy to be controllably reduced through additional computational work .",
    "the problem of exact classical electronic structure methods is that they generally have a computational cost that scales exponentially with the size of the system .",
    "although these classical algorithms could also be used as subroutines in the quantum gradient algorithm , there are quantum electronic - structure algorithms that could avoid the exponential scaling in many cases .",
    "in particular , we have recently described a quantum full ci algorithm @xcite for computing the molecular ground state energy to a given precision in @xmath68 time @xcite , where @xmath69 is the number of basis functions .",
    "this algorithm could be easily recast as a subroutine that would function as the black box for the energy .",
    "several modifications would have to be made , including the direct computation of the overlap integrals on the quantum computer , rendering it possible to introduce the perturbation @xmath0 into the calculation .",
    "nevertheless , a quantum computer running the quantum fci algorithm could be used to obtain a molecular property of a system with basis size @xmath69 in @xmath68 time , a dramatic improvement over the possibilities of classical computers .",
    "a more recent development is the real - space chemical dynamics simulation algorithm @xcite , based on zalka s earlier work @xcite .",
    "it is known that simulating , to a given precision , the exact dynamics of a system of @xmath70 particles interacting under a pairwise interaction requires at most @xmath71 time and @xmath72 space , in contrast to the classical exponential cost .",
    "if an eigenstate of the system hamiltonian were prepared as the initial state @xcite , the dynamics would only apply a phase to the wavefunction .",
    "this phase could be read out by the phase estimation algorithm @xcite , forming the required energy black box .",
    "although the large prefactor of this algorithm would make it slower for small molecules than the equivalent quantum fci calculation , it benefits from a superior asymptotic scaling as well as from the fact that only minimal modifications would need to be made to insert the perturbation @xmath0 into the calculation .",
    "for example , simulations with different nuclear coordinates proceed in exactly the same way , while an electromagnetic field requires only a small modification of the simulated hamiltonian @xcite .",
    "it should be remarked that current quantum algorithms for energy estimation , such as the ones mentioned above , rely on quantum phase estimation , which has been criticized as inefficient @xcite because its cost grows exponentially with the number of bits of precision sought .",
    "this could be significant for gradient estimation , which may require precise energy evaluations to avoid numerical errors . to estimate the cost",
    ", we note that if the gradient is desired to @xmath29 bits of precision ( as in eq .",
    "[ eq : gradient ] ) , the black box should evaluate the energy to @xmath73\\approx n+\\log_2\\frac{2\\pi}{\\theta}\\ ] ] bits of precision @xcite , where @xmath74 is the desired success probability of the algorithm .",
    "for example , with @xmath75 , the algorithm succeeds 85% of the time and requires four more digits of precision in the energy than is desired in the gradient .",
    "the four additional digits present only a constant overhead , meaning that the computation of any molecular property at any precision is , up to a constant factor , as hard as computing the energy of the same molecule at the same precision .",
    "finally , a limitation of current quantum simulation algorithms is that they are generally spin - free and non - relativistic , which limits the ability to compute derivatives such as indirect spin - spin coupling .",
    "perhaps the single most common use of molecular derivatives is molecular geometry optimization .",
    "we can therefore use it to illustrate some of the advantages of a quantum algorithm over a classical one , including a quantum version of newton s method , which offers an additional quadratic speedup over its classical counterpart .    a simple way for finding the locally optimal geometry is to perform the standard newton iterations , @xmath76 until convergence is reached . here",
    ", @xmath77 are the nuclear coordinates at the @xmath78 iteration , and @xmath79 and @xmath80 are , respectively , the gradient and hessian of @xmath36 with respect to nuclear displacement ( the `` molecular gradient '' and the `` molecular hessian '' ) . if a quantum computer were used to compute the derivatives , one would require exactly 3 calls to a black box for @xmath36 per iteration : one for the gradient and two for the hessian . a classical approach , on the other hand ,",
    "would be much slower , requiring at least @xmath81 function calls for finite difference , and approximately @xmath31 effort in the analytical case . for large molecules with large @xmath10 ,",
    "this savings could prove significant , even if each energy evaluation takes much longer on a quantum machine than on a classical computer .",
    "there are many classical tricks available for speeding up the convergence of newton s method if the initial guess is not close to a local minimum , in which case the usual newton step might be inappropriately large . techniques such as trust regions and level shifts @xcite are still available to quantum computers , or they can be implemented as classical post - processing .",
    "in addition , we remark that newton s method is the first in the class of householder methods , which offer a rate of convergence of @xmath82 , provided that derivatives up to order @xmath82 exist and can be calculated .",
    "a quantum computer could be used to accelerate householder methods of any degree , requiring @xmath83 calls to the black box for order-@xmath84 householder optimization method . although exponential in @xmath84 , this expression is independent of system dimension @xmath10 .    of course ,",
    "newton s method is only useful for local minimization , and we are often interested in global optimization . here , we can use a quantum version of the multistart technique , called the quantum basin hopper @xcite .",
    "a number of points is selected at random , and each is followed , using a local search , to its local basin ( if a quantum version of newton s method is used for the local search , such as the one we propose above , we can get the usual quadratic convergence ) .",
    "then , the minima of all the basins are compared and the least one chosen as the global minimum . quantum computers could add a quadratic speed - up to such a multistart technique , since the resulting local minima form an unstructured database that can be searched using grover s algorithm @xcite with a quadratic speed - up .",
    "as drr and hyer pointed out @xcite , a grover search can find the minimum of an unstructured database with @xmath85 calls to the database ( where @xmath86 is the number of database entries , i.e. multistart points ) , as opposed to the classically required @xmath87 queries .",
    "we have shown that jordan s quantum gradient estimation algorithm can be applied to the estimation of time - independent , non - relativistic molecular properties .",
    "doing so requires a quantum electronic - structre black box , for which known quantum simulations algorithms are well suited .",
    "the quantum algorithm offers a speed - up from the classical cost of @xmath88 for analytical derivatives to the quantum query complexity of @xmath67 .",
    "that is , the number of energy calculations required on the quantum computer is independent of @xmath10 , and thus of the system size , which could offer a significant advantage for the computation of properties of large systems . in particular",
    ", it would make the molecular hessian of any molecule only twice as expensive as its molecular gradient , enabling a fast , local geometry optimization using newton s method .",
    "finally , global optimization could combine the local newton s method with grover search to offer an additional quadratic speed - up over the classical multi - start technique ."
  ],
  "abstract_text": [
    "<S> it is known that quantum computers , if available , would allow an exponential decrease in the computational cost of quantum simulations . </S>",
    "<S> we extend this result to show that the computation of molecular properties ( energy derivatives ) could also be sped up using quantum computers . </S>",
    "<S> we provide a quantum algorithm for the numerical evaluation of molecular properties , whose time cost is a constant multiple of the time needed to compute the molecular energy , regardless of the size of the system . </S>",
    "<S> molecular properties computed with the proposed approach could also be used for the optimization of molecular geometries or other properties . for that purpose , we discuss the benefits of quantum techniques for newton s method and householder methods . finally , global minima for the proposed optimizations can be found using the quantum basin hopper algorithm , which offers an additional quadratic reduction in cost over classical multi - start techniques .    applying _ ab initio _ </S>",
    "<S> methods of quantum chemistry to particular problems often requires computing derivatives of the molecular energy . for instance , obtaining a molecule </S>",
    "<S> s electric properties relies on the ability to compute derivatives with respect to external electromagnetic fields . </S>",
    "<S> likewise , computing the gradient of the molecular energy with respect to the nuclear coordinates is the most commonly used method for the proper characterization of potential energy surfaces and for optimizing the geometry of all but the smallest molecules . the computation of these kinds of derivatives , known as _ molecular properties _ </S>",
    "<S> , is nowadays a routine matter when it comes to low - order derivatives or small systems ( or both ) . </S>",
    "<S> this is largely due to advances in analytical gradient techniques , which allow for explicit property evaluation without resorting to numerical differentiation @xcite .    nevertheless , the computation of higher - order derivatives is often prohibitively expensive , even though such derivatives are often needed . </S>",
    "<S> for example , third- and fourth - order anharmonic constants are sometimes required to accurately compute a vibrational absorption spectrum @xcite or efficiently determine the location of transition states on complex potential energy surfaces @xcite . </S>",
    "<S> other properties of interest , such as hyperpolarizabilities , raman intensities , or vibrational circular dichroism , are also cubic or quartic derivatives . in this report </S>",
    "<S> , we show that quantum computers , once available , will be able to bypass some of the high cost of computing these properties . </S>",
    "<S> in particular , we show that any molecular property can be evaluated on a quantum computer using resources that , up to a small constant , are equal to those required to compute the molecular energy once . </S>",
    "<S> we have previously characterized the advantage of quantum computers at both computing molecular energies @xcite and simulating chemical reaction dynamics @xcite , and the present work extends our program to molecular properties .    </S>",
    "<S> this paper begins with a brief overview of classical techniques for the evaluation of molecular properties , both numerical and analytical . </S>",
    "<S> we then introduce the quantum algorithm for molecular properties , and discuss its advantages and disadvantages with respect to classical techniques . </S>",
    "<S> we conclude with geometry optimization as a particular example , and we show that it can benefit from an additional quadratic speed - up through grover s search @xcite . </S>"
  ]
}