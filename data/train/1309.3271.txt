{
  "article_text": [
    "due to the fast development of astronomical observations such as the measurements of the cosmic microwave background temperature anisotropy ( e.g.  _ wmap _ @xcite and _ planck _ @xcite satellites ) and observations of galaxy clustering ( e.g.  6df @xcite and sdss @xcite galaxy surveys ) , more and more large - scale data sets are available for studying a variety of astrophysical systems .",
    "it is , therefore , a common practice in astronomy to combine different data sets to obtain the joint likelihood for astrophysical parameters of interest .",
    "the standard approach for this joint analysis assumes that the data sets are independent , therefore the joint likelihood is simply the product of the likelihood of each data set .",
    "the joint likelihood function can then be used to determine optimal parameter values and their associated uncertainties . in the frequentist approach to parameter estimation , this is equivalent to the weighted sum of the parameter constraints from the individual data sets , where the weight of each data set is the inverse variance .",
    "data sets with small errors provide stronger constraints on the parameters .",
    "there is a long history discussing the appropriate way to combine observations from different experiments . in the context of cosmology",
    ", the discussion can be traced back to @xcite and @xcite , where weight parameters were assigned to different data sets to obtain joint constraints on the velocity field and hubble parameter @xmath0 . in these approaches , however , the assignment of weights to data sets with differing systematic errors was , in some ways , ad - hoc .",
    "for instance , if a data set has large systematic error and is not reliable , it is always assigned a weight of zero and is effectively excluded from the joint analysis . on the other hand , a more trustworthy data set can be assigned a higher relative weighting .    due to the subjectivity and limitations of this traditional way of assigning weights to different data sets",
    ", @xcite and @xcite ( hereafter hbl02 ) developed the original hyperparameter method .",
    "this allows the statistical properties of the data themselves to determine the relative weights of each data set . in the framework developed by @xcite and hbl02 , a set of hyperparameters",
    "is introduced to weight each independent data set , and the posterior distribution of the model parameters is recovered by marginalization over the hyperparameters .",
    "the marginalization can be carried out with a brute - force grid evaluation of the hyperparameters , or it can be explored by using monte carlo methods which directly sample the posterior distribution .",
    "such possibilities include markov chain monte carlo ( mcmc ) algorithms such as metropolis - hastings and simulated annealing , or non - mcmc methods such as nested sampling  @xcite .",
    "the application of hyperparameters was considered for a variety of cases by  hbl02 .",
    "for instance , if the error of a data set is underestimated , the direct combination of data sets ( no hyperparameter ) results in an underestimated error - budget , providing unwarranted confidence in the observation and producing a fake detection of the signal . the hyperparameter method ,",
    "however , was shown to detect such a phenomenon and act to broaden the error - budget , thus recovering the true variance of the data sets . by using the hyperparameter method ,",
    "the results of joint constraints become more robust and reliable .",
    "this approach has also been applied to the joint analysis of the primordial tensor mode in the cosmic microwave background radiation ( cmb ) @xcite , the distance indicator calibration @xcite , the study of mass profile in galaxy clusters @xcite , and the cosmic peculiar velocity field study @xcite .",
    "notably , the hyperparameter method established by @xcite and hbl02 is limited to independent data sets , where `` no correlation between data sets '' is assumed in the joint analysis . in the analysis of cosmology and many other astrophysical systems ,",
    "the data sets sometimes are correlated .",
    "for instance , in the study of the angular power spectrum of the cmb temperature fluctuations , the data from the atacama cosmology telescope ( act ) , south pole telescope ( spt ) and _ planck _ satellite share a large range of multipole moments @xmath1 ( see fig",
    ".  1 of @xcite and fig .  11 of @xcite ) .",
    "when combining these observations , one needs to consider the correlated cosmic variance term since these data are drawn from a close region of the sky .",
    "in addition , in the study of the cosmic velocity field @xcite , the bulk flows from different peculiar velocity surveys are drawn from the same underlying matter distribution so , in principle , a non - zero correlation term exists between different peculiar velocity samples .",
    "therefore , a method both using hyperparameter method and taking into account the correlation between different data sets is needed in the study of astrophysics . providing such a method is the main aim of this paper .    for a clear presentation",
    ", we build up our method step - by - step from the most basic level , explaining the concepts and derivation process in a pedagogical way .",
    "the structure of the paper is as follows . in section  [ sec : statistics ] , we review bayes theorem ( section  [ sec : bayes ] ) and the standard multivariate gaussian distribution ( section  [ sec : multi - gauss ] ) in the absence of any hyperparameters .",
    "section  [ sec : hyperparameter ] provides a review of the hyperparameter method as proposed in hbl02 . in section  [ sec : hypermatrix ] we present the hyperparameter matrix method , which is the core of the new method proposed in this paper .",
    "we quote the appropriate likelihood function for the hyperparameter matrix method for correlated data in section  [ sec : hypermatrix ] , leaving its derivation and proofs of its salient features in [ app : posdef ] .",
    "the proof of the functional form for the joint likelihood of correlated data sets makes use of several recondite matrix operations and lemmas .",
    "these are laid out in  [ app : hadamard ] and  [ block_matrix2 ] , while the main text simply quotes their results . in section",
    "[ sec : test ] , we apply our method to a straight - line model while fitting two independent data sets .",
    "we vary the error - budget and systematic errors in each data set to test the behaviour of the hyperparameter matrix method . in section  [ sec : improve ] , we also discuss the improvement of our hyperparameter matrix method over the original method proposed by hbl02 .",
    "the conclusion and discussion are presented in the last section .",
    "let us suppose that our data set is represented by @xmath2 and the parameters of interest are represented by vector @xmath3 .",
    "then by bayes theorem , the posterior distribution pr(@xmath4 ) is given by @xmath5 where @xmath6 is called the likelihood function , but here we stick to the notation pr@xmath7 . ] , @xmath8 is the prior distribution of parameters and @xmath9 is the bayesian evidence , an important quantity for model selection .    given a data set @xmath2 , let us suppose we have two alternative models ( or hypotheses ) for @xmath2 , namely @xmath0 and @xmath10 .",
    "one can calculate the bayesian evidence for each hypothesis @xmath11 as @xmath12 where the integral is performed over the entire parameter space @xmath3 of each model @xmath13 .",
    "note that the models may have different sets of parameters .",
    "the evidence is an important quantity in the bayesian approach to parameter fitting , and it plays a central role in model selection  @xcite .",
    "specifically , if we have no prior preference between models @xmath10 and @xmath0 , the ratio between two bayesian evidences gives a model selection criterion , or bayes factor @xmath14    the value of @xmath15 indicates whether the model @xmath10 is favoured over model @xmath0 by data @xmath2 .",
    "@xcite gave an empirical scale for interpreting the value of @xmath15 , as listed in table  [ tab : evidence ] .",
    "we will use this table as a criterion to assess the improvement of statistical significance when using the hyperparameter matrix method .",
    ".jeffreys empirical criterion for strength of evidence @xcite . [ cols=\"<,<\",options=\"header \" , ]      ) ) as a function of the correlation strength @xmath16 .",
    "@xmath16 is sampled from @xmath17 to @xmath18 with each step @xmath19 .",
    "@xmath20 is equal to the value of the bayesian evidence with our hyperparameter matrix method to consider full covariance between data sets , minus the value of bayesian evidence from the original hyperparameter method ( ignore the correlation between data sets ) . for the specific experiment",
    ", please refer to sec .",
    "[ sec : improve].,width=307 ]    the hyperparameter matrix method we propose here is the most general method which can be used to combine arbitrary number of multi - correlated experimental data .",
    "this greatly breaks up the limitation of the original hyperparameter method ( @xcite and hbl02 ) which can only deal with multiple independent data sets .",
    "it is always important , to include all of the correlation information between data sets to obtain correct parameter values and justify the goodness of fit .    to see the importance of our method , we design an illustrative experiment to demonstrate this . we generate two data sets with @xmath21 . for each data",
    "set , we generate the samples with mean @xmath22 and @xmath23 with gaussian error @xmath24 but correlated between the two data sets .",
    "we take the correlation strength @xmath16 as @xmath23 , @xmath19 , @xmath25 , ... , @xmath18 .",
    "then we use these correlated data sets to do a parameter estimation .",
    "we first use our hyperparameter matrix method , which considers the full covariance matrix between two data sets .",
    "then in order to check the behaviour of the original hyperparameter method , we _ ignore _ the correlation part of the two experiments and treat them as individual data sets .",
    "we calculate the bayesian evidence value ( eq .",
    "( [ eq : bayes2 ] ) ) for both cases , and obtain the difference between the two bayesian evidence ( be ) values .    in fig .",
    "[ fig : correlate ] , we plot the difference between be value for our hyperparameter matrix method and for the original hyperparameter method .",
    "first , one can see that when @xmath26 , the two methods are the same one so @xmath27 . but as the correlation strength increases , the @xmath28 increases as well , indicating that the hyperparameter matrix method provides better and better fits than the original hyperparameter method .",
    "this can be understood as the danger of ignoring correlation between data sets , since the model becomes inadequate to fit the data if the correlation is not included . in fig .",
    "[ fig : correlate ] , one can see that if @xmath29 , the bayes factor becomes `` substantial '' , and if @xmath30 , the bayes factor becomes `` decisive '' .",
    "this strongly indicates that when combining multiple correlated data sets , it is very necessary to use our hyperparameter matrix method rather than the original hyperparameter method .",
    "in this paper we have reviewed the standard approach to parameter estimation when there are multiple data sets .",
    "this is an important aspect to most scientific enquiries , where multiple experiments are attempting to observe the same quantity . in the context of a bayesian analysis",
    ", the data can also be used for model selection and tests of the null hypothesis .",
    "we reviewed the original hyperparameter method of  hbl02 for combining independent data sets , showing how it can overcome inaccurate error bars and systematic differences between multiple data sets .",
    "here we developed the hyperparameter matrix method for the case of correlated data sets , and we have shown that it is a preferred model to the standard non - hyperparameter approach of parameter estimation .",
    "we rigorously prove that the hyperparameter matrix likelihood can be greatly simplified and be easily implemented . from this form of the likelihood",
    ", we can recover the simple case of no hyperparameters where all of the data sets have equal weights .",
    "as well , the original hyperparameter approach is recovered in the limit of no inter - data set covariance ( @xmath31 if @xmath32 ) , so our likelihood function provides a generalized form which covers hyperparameter and non - hyperparameter analysis , as well as correlated and uncorrelated data sets .",
    "we test this statistical model by fitting two data sets to a straight line , and looked at the consequences of mis - reported error bars , as well as systematic differences between correlated data sets . in all cases , with the assistance of bayesian evidence , we find that the hyperparameter matrix method is heavily favoured over the traditional joint analysis . by using an illustrative example to calculate the difference of bayesian evidence value between the hyperparameter matrix method , and the original hyperparameter method , we demonstrate that the bayes factor becomes very substantial ( decisive ) if @xmath33 is greater than @xmath34 ( @xmath35 ) .",
    "this suggests that for the case where two experiments are strongly correlated , our hyperparameter matrix method is heavily favoured over the original hyperparameter method .",
    "the method proposed here can be used in a variety of astrophysical systems . in the context of cosmology , when cosmic variance is a common component to all large - scale observations , the data sets drawn from the same underlying density or temperature field will be correlated to some degree .",
    "for instance , in the study of cmb where multiple data sets drawn from the same region of the sky are combined ( such as _ planck _ @xcite , _ wmap _",
    "@xcite , spt @xcite and act @xcite ) , it is necessary to consider the correlation between data sets since they follow the same underlying temperature distribution .",
    "therefore our method can be an objective metric to quantify the posterior distribution of cosmological parameters estimated from the cmb .",
    "in addition , in the analysis of the galaxy redshift surveys for cosmic density and velocity fields , when combining two surveys data drawn from the similar cosmic volume , the cosmic variance between different data sets should also be considered as a part of the total covariance matrix since they all follow the same underlying matter distribution . in the future survey of 21  cm ,",
    "if two or more surveys sample the neutral hydrogen in the same ( or close ) cosmic volume , the correlation between surveys should also be considered when combining data sets . in this sense",
    ", our hyperparameter matrix method provides an objective metric to quantify the probability distribution of the parameters of interest when multiple data sets are combined .    in summary ,",
    "when combining correlated data sets , the hyperparameter matrix method can provide an unbiased and objective approach that can wisely detect and down - weight any unaccounted experimental errors or systematic errors , in this way it provides the most robust and reliable constraints on astrophysical parameters .",
    "we would like to thank chris blake , andrew johnson , douglas scott and jasper wall for helpful discussions .",
    ". is supported by a cita national fellowship .",
    "this research is supported by the natural science and engineering research council of canada .",
    "the generalized form of the likelihood function for the hyperparameter analysis in the presence of correlated data sets ( eq .  ( [ eq : like - hyper2 ] ) )",
    "must satisfy several properties in order to serve as a probability density function .",
    "in particular , the generalized hyperparameter covariance matrix @xmath36 ( eq .  ( [ cov_generalize2 ] ) ) must have positive determinant , and must be invertible .",
    "however , since the matrix @xmath37 is a function of the hyperparameters @xmath38 which , in principle , vary from zero to infinity , the positive definiteness and invertibility of @xmath39 are not immediately clear .    the following theorem guarantees the feasibility of inverting the total covariance matrix @xmath39 , and the positive definiteness of the determinant .",
    "* theorem : * the likelihood function of combining @xmath40 correlated data sets with hyperparameter matrix , i.e. eq .  ( [ eq : like - hyper2 ] ) is equivalent to @xmath41 \\frac{1}{\\sqrt{\\det \\tilde{c}}}\\exp \\left ( -\\frac{1}{2}\\vec{x}^{t}\\left ( \\hat{p}\\odot \\tilde{c}^{-1}\\right ) \\vec{x}\\right ) , \\label{like4}\\]]where @xmath42 is the dimension of the @xmath43th data set , @xmath44 is the covariance matrix between @xmath40 data sets without the inclusion of hyperparameter ( eq .  ( [ new_cov1 ] ) ) , @xmath45 is the element - wise product ( same as eq .",
    "( [ eq : element ] ) ) , and @xmath46 is the `` hadamard inverse '' of the @xmath37 matrix ( see  [ app : hadamard ] ) .",
    "we first prove the inverse relation , @xmath47 * proof .",
    "*  ( 1 ) let us multiply matrices @xmath48 and @xmath49 , then take the block element @xmath50 of the matrix , i.e. `` @xmath43 , @xmath51 , @xmath52 '' are the block element which can take any value between ( @xmath53 ) @xmath54 _ { ij }   \\nonumber \\\\ & = & \\sum_{k}\\left ( p\\odot \\tilde{c}\\right ) _ { ik}\\left ( \\hat{p}\\odot \\tilde{c}^{-1}\\right ) _ { kj }   \\nonumber \\\\ & = & \\sum_{k}\\left ( \\tilde{c}_{ik}\\ast \\left ( \\alpha _ { i}\\alpha _ { k}\\right ) ^{-1/2}\\right ) \\left ( \\tilde{c}_{kj}^{-1}\\ast \\left ( \\alpha _ { k}\\alpha _ { j}\\right ) ^{1/2}\\right )   \\nonumber \\\\ & = & \\sum_{k}\\left ( \\tilde{c}_{ik}\\tilde{c}_{kj}^{-1}\\right ) \\left ( \\alpha _ { j}/\\alpha _ { i}\\right ) ^{1/2 }   \\nonumber \\\\ & = & ( \\delta _ { ij})i_{n_{i}\\times n_{j}}\\left ( \\alpha _ { j}/\\alpha _ { i}\\right ) ^{1/2 }   \\nonumber \\\\ & = & ( \\delta _ { ij})i_{n_{i}\\times n_{i } } , \\label{eq : proof1}\\end{aligned}\\]]where in the second step , we use the property of block matrix product . the final line of eq .",
    "( [ eq : proof1 ] ) indicates that , only if @xmath55 , the product is an @xmath56 identity matrix , otherwise it is all zeros .",
    "thus we prove the inverse relation ( eq .",
    "( [ inverse_new1 ] ) ) .",
    "@xmath57    next , let us prove the determinant relation@xmath58where @xmath39 is given by eq .",
    "( [ cov_generalize2 ] ) , @xmath44 is given by ( eq .  ( [ new_cov1 ] ) ) and @xmath59 is the dimension of the @xmath43th block matrix .",
    "* proof . *  ( 2 ) in [ block_matrix2 ]",
    ", we have proved that a matrix of type @xmath44 ( [ new_cov1 ] ) follows the determinant eqs .",
    "( [ det1])-([det5 ] ) .",
    "we now use eqs .",
    "( [ det1])-([det5 ] ) to prove eq .",
    "( [ detc_hyper1 ] ) . from eq .",
    "( [ det1 ] ) , we have @xmath60where the @xmath61 matrix stands for eqs .  ( [ det2])-([det5 ] ) but replacing @xmath62 matrix for @xmath39 matrix .",
    "we then apply the same equation for the covariance matrix @xmath44 @xmath63where the @xmath64 matrix stands for eqs .",
    "( [ det2])-([det5 ] ) but replacing @xmath62 matrix with @xmath44 matrix .",
    "now we compare the last terms in eqs .",
    "( [ deter_prove1 ] ) and ( [ deter_prove2 ] ) . since @xmath65 is indeed @xmath66 as given by eq .",
    "( [ det2 ] ) , we have @xmath67we then calculate the @xmath43th term ; following eq .",
    "( [ det2 ] ) , we have @xmath68by using eq .",
    "( [ inverse_new1 ] ) , we obtain @xmath69 therefore we have @xmath70thus , by mathematical induction , we have proved that all of the terms in eqs .",
    "( [ deter_prove1 ] ) and ( [ deter_prove2 ] ) follow eq .",
    "( [ eq : proof2-last ] ) .",
    "therefore the relationship between eqs .",
    "( [ deter_prove1 ] ) and ( deter_prove2 ) is @xmath71i.e .",
    "we have proved eq .",
    "( [ detc_hyper1 ] ) . @xmath57    combining proofs ( 1 ) and ( 2 ) , we have shown that , in general , when combining multiple correlated data sets with hyperparameters , the inverse and determinant of the covariance matrix follow eqs .",
    "( [ inverse_new1 ] ) and ( [ detc_hyper1 ] ) .",
    "therefore the likelihood function for combined correlated data sets is eq .",
    "( [ like4 ] ) .",
    "equation  ( [ like4 ] ) greatly simplifies the computation of hyperparameter likelihood , since one can always calculate the covariance matrix for correlated data sets @xmath44 and then use `` element - wise '' product @xmath45 to calculate the covariance matrix with hyperparameters , and then numerically solve for the maximum likelihood solution .",
    "the hadamard product is the element - wise product of any two matrices with the same dimension . if @xmath62 and @xmath72 are the two matrices with the same dimension @xmath73 , the hadamard product @xmath74 is a matrix with the same dimension with element ( @xmath75 ) equal to @xmath76    the hadamard inverse is an inverse operation which requires that each element of the matrix is nonzero , so that each element of the hadamard inverse matrix is @xmath77here we use a hat to denote the hadamard inverse",
    ". therefore the hadamard product of an @xmath73 matrix and its hadamard inverse becomes a unit matrix where all elements are equal to one , i.e. @xmath78",
    "we will use the following lemma to prove the determinant relation of the covariance matrix of hyperparameter likelihood , eq .",
    "( [ detc_hyper1 ] ) .",
    "let @xmath62 be an ( @xmath79 real or complex matrix , which is partitioned into @xmath80 blocks , each of size is @xmath81which satisfies @xmath82@xmath83the determinant of @xmath62 is given by @xmath84where @xmath85 is defined as @xmath86where vectors @xmath87 and @xmath88 are defined as @xmath89@xmath90and @xmath91 is defined as @xmath92    a particular case of this lemma , where each block matrix has the same dimension @xmath93 , is shown as a theorem in @xcite . here",
    "we extend the theorem shown in @xcite to a more general case where each diagonal block matrix may have a different size , so the off - diagonal matrix can be a rectangular matrix .",
    "* proof . *",
    "we start from the simplest case , where @xmath94 , i.e. @xmath62 is a @xmath95 symmetric block matrix @xmath96where @xmath97 and @xmath98 are @xmath99 and @xmath100 semi - positive definite symmetric matrix respectively , and @xmath101 is a @xmath102 matrix .",
    "the determinant of @xmath62 is @xmath103we can immediately check that this is indeed the simplest case for eqs .",
    "( det1)-([det5 ] ) where @xmath94 . since if @xmath94 , eq .",
    "( [ det2 ] ) gives @xmath104 where @xmath105 and @xmath106 , which is exactly eq .",
    "( [ det2by2 ] ) .",
    "now we can use eq .",
    "( [ det2by2 ] ) for the @xmath94 case to inductively derive general equations ( [ det1])-(det5 ) .",
    "let us treat matrix ( [ a_mat ] ) as a 2-by-2 matrix , where all of the matrices @xmath107 are grouped into a big matrix @xmath108 @xmath109where @xmath110is exactly @xmath111 ( eq .  ( [ det5 ] ) ) , and @xmath112is exactly the definition of @xmath113 ( eq .",
    "( [ det3 ] ) ) .",
    "in addition , @xmath114is exactly @xmath115 ( eq .  ( [ det4 ] ) ) . now applying the second line of eq .",
    "( [ det2by2 ] ) to this matrix , one has @xmath116now proceeding to @xmath117 again , @xmath118 can be separated into two big matrices as@xmath119where @xmath120and @xmath121therefore @xmath122so combining eqs .",
    "( [ deta22 ] ) and ( [ deta221 ] ) , we have @xmath123repeating this operation until breaking down the first term , one can eventually reach @xmath124 therefore the determinant of @xmath62 is @xmath125by comparing the brackets in eq .",
    "( [ eq : deta1 ] ) with eq .",
    "( [ det2 ] ) , one can find that each term is exactly the same , therefore the determinant is given by eq .",
    "( det1 ) . @xmath57"
  ],
  "abstract_text": [
    "<S> we construct a `` hyperparameter matrix '' statistical method for performing the joint analyses of multiple correlated astronomical data sets , in which the weights of data sets are determined by their own statistical properties . </S>",
    "<S> this method is a generalization of the hyperparameter method constructed by @xcite and @xcite which was designed to combine independent data sets . </S>",
    "<S> the advantage of our method is to treat correlations between multiple data sets and gives appropriate relevant weights of multiple data sets with mutual correlations . </S>",
    "<S> we define a new `` element - wise '' product , which greatly simplifies the likelihood function with hyperparameter matrix . </S>",
    "<S> we rigorously prove the simplified formula of the joint likelihood and show that it recovers the original hyperparameter method in the limit of no covariance between data sets . </S>",
    "<S> we then illustrate the method by applying it to a demonstrative toy model of fitting a straight line to two sets of data . </S>",
    "<S> we show that the hyperparameter matrix method can detect unaccounted systematic errors or underestimated errors in the data sets . </S>",
    "<S> additionally , the ratio of bayes factors provides a distinct indicator of the necessity of including hyperparameters . </S>",
    "<S> our example shows that the likelihood we construct for joint analyses of correlated data sets can be widely applied to many astrophysical systems .    </S>",
    "<S> bayesian analysis , data analysis , statistical method , observational cosmology </S>"
  ]
}