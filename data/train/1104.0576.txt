{
  "article_text": [
    "using algebraic error / erasure decoders for pseudo  soft decoding of _ reed  solomon ( rs ) _ codes dates back to forney @xcite .",
    "his _ generalized minimum distance ( gmd ) _ decoding applies an error / erasure decoder multiple times , each time with an increased number of erased most unreliable symbols of the received word . in very good channels , the residual codeword error probability of gmd decoding approaches that of _ maximum likelihood ( ml ) _ decoding if the number @xmath0 of such decoding trials is sufficiently large , i.e. @xmath1 , where @xmath2 is the minimum _ hamming distance _ of the rs code .",
    "thus , the computational complexity of gmd decoding is @xmath3times that of errors  only decoding .",
    "roughly , we can say @xmath4 , which means that quadratic decoding complexity in the code length @xmath5 becomes cubic and so on .",
    "ktter @xcite provided a modification of the berlekamp ",
    "massey algorithm that essentially computes all decoding trials at once , i.e. without increasing complexity .",
    "a similar result was achieved in @xcite for the euclidean algorithm and in @xcite using newton interpolation .",
    "up to our knowledge , there is no such modification of _ guruswami  sudan ( gs ) _",
    "@xcite list decoding  which can be considered as state of the art in algebraic decoding ",
    "however , ktter and vardy provided a modification of the gs algorithm that is capable of exploiting soft information @xcite .",
    "gmd decoding is per se a _ fixed _ approach , i.e. the erasing strategy is constant for each received word .",
    "_ adaptive _ variants have been investigated in @xcite .",
    "the respective authors show that the number @xmath0 of decoding trials can be reduced significantly , if the erasing strategy is optimally calculated for every single received word .",
    "the aforementioned papers focus on the maximization of the achievable _ decoding radius _ , i.e. the maximum correctable number of errors in the received word .",
    "in contrast to that , our objective is to minimize the residual codeword error probability after decoding .",
    "we achieve this using a technique first introduced in 2010 @xcite for optimal error / erasure decoding of binary codes . as in the latter paper",
    ", we restrict ourselves to one single decoding trial , i.e. @xmath6 , for simplicity .",
    "the rest of the paper is organized as follows . in section  [ sec : ee ] we give an overview of error / erasure decoding and introduce the required notations .",
    "we introduce the decoder capability function which allows to derive the optimal erasing strategy in a general manner . here and in the following , _",
    "optimal _ means _ minimizing the residual codeword error probability_. in section  [ sec : strategy ] , we derive an optimal adaptive erasing strategy for one single decoding trial .",
    "section  [ sec : approx ] describes two computationally efficient approximations of the optimal strategy , one of them with complexity quadratic in the code length @xmath5 . in section  [ sec : sim ] we show the potential of single  trial error / erasure decoding in terms of achievable residual codeword error probability as well as the quality of the two approximative variants by simulation .",
    "the paper is wrapped up with conclusions and an outlook in section  [ sec : conc ] .",
    "consider the rs code @xmath7 of length @xmath5 , dimension @xmath8 and minimum distance @xmath2 over the extension field @xmath9 .",
    "thereby , @xmath10 for some prime number @xmath11 and some integer @xmath12 .",
    "the transmitter encodes an information vector @xmath13 into a codeword @xmath14 .",
    "each symbol @xmath15 , @xmath16 , is mapped to a symbol @xmath17 of a modulation alphabet @xmath18 resulting in the modulated codeword @xmath19 .",
    "this modulated codeword is transmitted over the channel , where it is distorted by two  dimensional _ additive white gaussian noise ( awgn)_. at the receiver , the received word @xmath20 is obtained .",
    "it is the sum of the modulated codeword and an error word @xmath21 .",
    "each symbol @xmath22 is mapped to the closest ( in euclidean metric ) modulation point of @xmath23 , the result of this procedure is the _ hard decision _ @xmath24 of @xmath25 .",
    "this hard decision can be fed into the inverse mapper function to obtain a received vector @xmath26 , which in turn can be fed into any algebraic hard decision decoder for @xmath27 .",
    "the hard decision , i.e. the mapping from received symbols @xmath22 to closest modulation points @xmath28 , is error ",
    "prone since it is not necessarily correct : the received @xmath29 might be closest in euclidean metric to an @xmath30 .",
    "we refer to the probability of an incorrect hard decision as _ unreliability _ of a received symbol and denote it by @xmath31 . here , @xmath32 is the awgn standard deviation for @xmath33 given in db .",
    "note that due to the one  to  one mapping between @xmath28 and @xmath34 we can as well write the unreliability as a function of the de  modulated received symbols , i.e. @xmath35 . by definition , we have @xmath36 where the last equality follows from the assumption of equiprobable codeword symbols . in practice ,",
    "the calculation of ( [ eqn : unrel_exact ] ) is not feasible for large modulation alphabets @xmath23 , hence we use the _ nearest neighbor approximation _",
    "@xmath37 where @xmath38 is the set of nearest neighbors of @xmath28 .",
    "this allows to store all possible values of @xmath39 in a comparatively small lookup table as the following example demonstrates .",
    "assume _ @xmath40quadrature amplitude modulation ( qam ) _ with average signal energy one , gray mapping and @xmath41bit  quantization .",
    "without nearest neighbor approximation , this leads to a lookup table with @xmath42 entries , each containing two integers for the coordinates and one real number for the unreliability value @xmath39 . considering only the nearest neighbors ,",
    "the lookup table consists of only @xmath43 such entries if symmetries within the qam decision regions are exploited .",
    "this allows to store lookup tables for many different @xmath33 values , e.g. up to the precision of the ( required ) channel estimation .",
    "[ fig : unrel_full ] shows a density plot of @xmath39 for the complete euclidean plane , the black dots mark the modulation points , darker color marks higher unreliability .",
    "note that the unreliabilities for most decision regions are either rotated versions of each other or they coincide .",
    "furthermore , the unreliabilities of the decision regions are either point symmetric to their modulation point ( regions in the center ) or symmetric to a line through the modulation point ( border and corner regions ) .",
    "this allows to discard @xmath44 of the quantization intervals in the first case and @xmath45 of the intervals in the second case .     for the euclidean plane , @xmath40qam , @xmath41bit  quantization , awgn@@xmath46 db . ]    at the receiver , the unreliability is calculated ( or taken from the lookup table ) for every received symbol @xmath34 , @xmath16 .",
    "we assume here and in the following that the received word @xmath47 is ordered according to its symbol s unreliabilities , i.e. @xmath48 . the idea of error / erasure decoding is to discard the @xmath49 most unreliable symbols ( i.e. to erase them ) since it is likely that they are erroneous . instead of @xmath47 , the input vector fed into the algebraic decoder",
    "is then @xmath50 where the first @xmath49 symbols are replaced by the erasure marker @xmath51 . in order to do this ,",
    "two conditions need to be fulfilled .",
    "first , we require an algebraic decoder which is capable of decoding both errors and erasures .",
    "second , we must be capable of deciding how many of the most unreliable symbols should be discarded .",
    "algebraic error / erasure decoders for rs codes are well  known .",
    "classical _ bounded minimum distance ( bmd ) _",
    "e.g. decoding using the berlekamp ",
    "massey- or the sugiyama algorithms can be augmented by an erasure option @xcite as can the gs list decoder @xcite . in @xcite , a decoder with erasure option for _ interleaved reed ",
    "solomon ( irs ) _ codes from @xcite is applied to decode _",
    "@xmath52punctured _ rs codes .",
    "the _ decoder capability function ( dcf ) _ of an algebraic error / erasure decoder is an inequality of the form @xmath53 which is true whenever the decoder can correct @xmath54 errors and @xmath49 erasures in any given received word .",
    "three important examples for error / erasure decoders and their respective @xmath55 are given in table  [ tab : dcf ] .",
    "[ cols=\"<,^,^\",options=\"header \" , ]     as a result , all values @xmath56 in ( [ eqn : pf ] ) can be neglected and a good approximation of the residual codeword error probability is obtained by @xmath57    in @xcite , the complexity of adaptive single  trial error / erasure decoding of binary codes with the hoeffding approximation of @xmath58 is stated to be in @xmath59 , this also holds for our case of ( non  binary ) rs codes .",
    "for the second approximation , we require the following proposition . so far it is verified only by experiments and we are working on a proof .    [",
    "prop : unimodal ] for fixed @xmath49 , @xmath61 , @xmath62 is a unimodal function in @xmath54 and its mode is determined by the expectation @xmath63 .    fig .",
    "[ fig : optimization ] shows a @xmath64d plot of @xmath65 for all @xmath49 , @xmath61 , each slice in @xmath54direction is unimodal according to proposition  [ prop : unimodal ] and each @xmath63 coincides with the mode of the respective @xmath49 .     for @xmath66 , awgn@@xmath46 db , @xmath60 of the gs list decoder .",
    "]    if the expectation is smaller than the error boundary , i.e. if @xmath67 , then we can approximate the sum @xmath68 by its largest element , which is @xmath69 .",
    "analogously , if @xmath70 , then @xmath71 is a good approximation of the sum @xmath72 . inserting into ( [ eqn : pf ] ) gives @xmath73    based on the complexity analysis of the hoeffding approximation in @xcite , it is easy to see that the complexity of the @xmath60 approximation is in @xmath74 . since there are no practical decoders with lower complexity than @xmath74 , adaptive single  trial error / erasure decoding is in the same complexity class as the error / erasure decoder itself and the computation of @xmath75 increases complexity only by an additive constant .",
    "we investigate the potential of adaptive single  trial error / erasure decoding for the rs code @xmath66 .",
    "two error / erasure decoders are considered : the classical bmd decoder ( e.g. berlekamp  massey or sugiyama ) and the gs list decoder with multiplicities @xmath76 .    performance evaluation is done by simulation and by semi ",
    "simulative upper bounds of the residual codeword error probability . for each considered @xmath33",
    ", we calculate an average unreliability vector @xmath77 , @xmath78 , by averaging over @xmath79 random unreliability vectors . for each variant of @xmath58 ( exact , hoeffding approximation , @xmath60 approximation ) , we calculate @xmath80 for @xmath81 according to ( [ eqn : solution ] ) .",
    "we use @xmath82 for every received vector , which means that the simulation is in fact non - adaptive , using the optimal erasing strategy for the average unreliability vector .",
    "the resulting residual codeword error probability curves are indeed upper bounds , it is clear that the error probability can not be higher when @xmath75 is calculated for every single received vector .",
    "precise error probabilities of errors  only decoding are obtained by inserting @xmath83 into ( [ eqn : pf ] ) .    .",
    "adaptive single  trial error / erasure decoding is based on the @xmath60 approximation . ]",
    "the @xmath60 approximation is considered in fig .  [ fig : sim255_144 ] .",
    "it shows actual simulation results for @xmath84 db and the aforementioned upper bound for @xmath85 db .",
    "clearly , adaptive single  trial error / erasure decoding with a classical bmd decoder yields a gain of approximately @xmath86 db for practical error probabilities . for the gs list decoder",
    ", the achievable gain is negligible .",
    "the reason for this lies in the non  linearity of the gs list decoder s @xmath60 function , whose slope gets steeper with decreasing @xmath49 .",
    "this means that the benefit of transforming errors into erasures diminishes for a small number of erased symbols .",
    "the residual codeword probability curve of forney s original @xmath1trial gmd decoding @xcite is given as a reference .",
    "[ fig : sim255_144 ] shows that most of gmd s gain can be achieved by a single adaptive trial , if only the erasing strategy is chosen optimally .",
    "[ fig : sim255_144_zoom ] shows for an interesting range of residual codeword error probabilities that there is virtually no difference between exact calculation of @xmath58 and the two proposed approximations .",
    "our recommendation is to use the @xmath60 approximation whenever exact calculation of @xmath58 is prohibitive .",
    "it is feasible both in terms of computational complexity ( @xmath74 ) and approximation quality .    .",
    "classical error / erasure bmd decoders for rs codes are widely deployed .",
    "we presented an adaptive single  trial error / erasure decoding technique , which allows to decrease the residual codeword error probability of such decoders using a low  complexity , i.e. @xmath74 , pre  computation step .",
    "the achievable gain of our technique is around @xmath86 db for @xmath66 .",
    "this is slightly less than the gain of gmd decoding but neither does it require a modification of the decoder itself ( ktter s fast gmd decoder @xcite ) nor does it require @xmath1 decoding trials ( forney s original gmd decoder @xcite ) .",
    "our technique is general , it can be applied to any error / erasure decoder as long as its dcf is known .",
    "the authors would like to thank dejan e. lazich for carefully proofreading the manuscript .",
    "s.  kampf and m.  bossert , `` a fast generalized minimum distance decoder for reed - solomon codes based on the extended euclidean algorithm , '' in _ proc .",
    "symposium on inform . theory _",
    ", austin , tx , usa , june 2010 , pp . 10901094 .",
    "v.  guruswami and m.  sudan , `` improved decoding of reed - solomon and algebraic - geometric codes , '' _ ieee trans .",
    "inform . theory _ , vol .",
    "it-45 , no .  6 , pp .",
    "17551764 , september 1999 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/18.782097    r.  koetter and a.  vardy , `` algebraic soft - decision decoding of reed ",
    "solomon codes , '' _ ieee trans .",
    "inform . theory _",
    "it-49 , no .",
    "11 , pp . 28092825 ,",
    "november 2003 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/tit.2003.819332    s.  i. kovalev , `` two classes of minimum generalized distance decoding algorithms , '' _ problems of information transmission _",
    ", vol .  22 , no .  3 , pp .",
    "186192 , 1986 , translated from russian , original in problemy peredachi informatsii , pp .",
    "v.  r. sidorenko , c.  senger , m.  bossert , and v.  v. zyablov , `` single - trial adaptive decoding of concatenated codes , '' in _ proc .",
    "international workshop on algebraic and combinatorial coding theory _ ,",
    "pamporovo , bulgaria , june 2008 .",
    "[ online ] .",
    "available : http://www.moi.math.bas.bg/acct2008/b44.pdf    v.  r. sidorenko , a.  chaaban , c.  senger , and m.  bossert , `` on extended forney  kovalev gmd decoding , '' in _ proc .",
    "symposium on inform .",
    "theory _ , seoul , korea , july 2009 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/isit.2009.5205900    c.  senger , v.  r. sidorenko , s.  schober , m.  bossert , and v.  v. zyablov , `` adaptive single - trial error / erasure decoding of binary codes , '' in _ proc .",
    "symposium on inform . theory and its applications",
    "_ , taichung , taiwan , october , pp . 267272 .",
    "[ online ] .",
    "available : http://arxiv.org/abs/1004.3372      v.  r. sidorenko , g.  schmidt , and m.  bossert , `` decoding punctured reed ",
    "solomon codes up to the singleton bound , '' in _ proc .",
    "international itg conference on source and channel coding _ , ulm , germany , january 2008 .",
    "g.  schmidt , v.  r. sidorenko , and m.  bossert , `` collaborative decoding of interleaved reed  solomon codes and concatenated code designs , '' _ ieee trans .",
    "inform . theory",
    "it-55 , no .  7 , pp .",
    "29913012 , july 2009 .",
    "[ online ] .",
    "available : http://dx.doi.org/10.1109/tit.2009.2021308"
  ],
  "abstract_text": [
    "<S> algebraic decoding algorithms are commonly applied for the decoding of reed  solomon codes . </S>",
    "<S> their main advantages are low computational complexity and predictable decoding capabilities . </S>",
    "<S> many algorithms can be extended for correction of both errors and erasures . </S>",
    "<S> this enables the decoder to exploit binary quantized reliability information obtained from the transmission channel : received symbols with high reliability are forwarded to the decoding algorithm while symbols with low reliability are erased . in this paper </S>",
    "<S> we investigate adaptive single  trial error / erasure decoding of reed  </S>",
    "<S> solomon codes , i.e. we derive an adaptive erasing strategy which minimizes the residual codeword error probability after decoding . our result is applicable to any error / erasure decoding algorithm as long as its decoding capabilities can be expressed by a decoder capability function . </S>",
    "<S> examples are bounded minimum distance decoding with the berlekamp  massey- or the sugiyama algorithms and the guruswami  </S>",
    "<S> sudan list decoder . </S>"
  ]
}