{
  "article_text": [
    "brain s activity results from the interplay of an extraordinary large number of neurons gathering into large - scale populations .",
    "this view is supported by anatomical evidences : neurons with the same dynamics and interconnection properties gather into cortical columns ( _ neural populations _ ) with a diameter of about @xmath0 to @xmath1 , containing of the order of few thousands to one hundred thousand neurons in charge of specific functions  @xcite .",
    "this macroscopic signal emerging from the interaction of a large number of cells is recorded by most non - invasive imaging techniques ( eeg / meg / optical imaging and local field potentials ) .",
    "these columns have specific functions and spatial locations resulting in the presence of delays in their interactions due to the transport of information through axons and to the typical time the synaptic machinery needs to transmit it .",
    "these delays have a clear role in shaping the neuronal activity , as established by different authors ( see e.g.  @xcite ) . each neuron involved in this processing",
    "has a nonlinear dynamics and is subject to an intense noise .",
    "this picture motivated the development of models of large - scale activity for stochastic neuronal networks  @xcite for different models .",
    "some of the approaches are heuristic , and other based on statistical physics methods .",
    "recently , extensions of the theory of mean - field limits to neuronal systems including spatial extension and delays have been developed in a mathematically rigorous framework  @xcite .",
    "these papers exhibited the limit as the number of neurons goes to infinity , of multi - population ( up to a continuum ) neuronal networks in the presence of external noise and delays , and showed an essential role of noise in the qualitative dynamics of the macroscopic activity .",
    "however , all these work overlook a prominent aspect of brain networks . indeed ,",
    "deeper analysis of the brain s connectivity evidence a high degree of heterogeneity , in particular in the interconnections  @xcite .",
    "these are due to a number of phenomena , among which intervene the precise number of receptors and the extremely slow plasticity mechanisms .",
    "all these phenomena induce a static disorder termed _ static random synaptic heterogeneities_. moreover , thermal noise , channel noise and the intrinsically noisy mechanisms of release and binding of neurotransmitter  @xcite result in stochastic variations of the synaptic weights termed _ stochastic synaptic noise_.    experimental studies of cortical areas  @xcite showed that the degree of heterogeneity in the connections significantly impacts the input - output function , rhythmicity and synchrony . yet",
    ", qualitative effects induced by connection heterogeneities are still poorly understood theoretically .",
    "one notable exception is the work of sompolinsky and collaborators  @xcite . in the thermodynamic limit of a one - population firing - rate neuronal network with synaptic weights modeled as centered independent gaussian random variables",
    ", they evidenced a phase transition between a stationary and a chaotic regime as the disorder is increased .",
    "more recently , we showed  @xcite that an additional phase transition towards synchronized activity could occur upon increase of the heterogeneity in multi - populations networks .",
    "the topic of the present manuscript is to analyze in a mathematically rigorous manner the effect of heterogeneities and noise in large - scale networks in the presence of delays .",
    "one objective of the present manuscript is to understand from a mathematical perspective the mean - field equations used by sompolinsky and colleagues in  @xcite and to generalize their approach in order to be closer from the biological problem that motivates this study .",
    "the paper is organized as follows . in section  [ sec : mathsetting ] , we will present the mathematical framework and the equations that will be studied throughout the paper , and in particular the inclusion of interaction delays between cells , multiple populations and non - centered synaptic coefficients which were not present of prior models analyzed . from a mathematical perspective",
    ", this problem falls in the class of interacting diffusions in a random environment and is reminiscent of the work developed by ben arous and guionnet on the sherrington - kirpatrick model  @xcite for spin - glass dynamics . following their approach",
    ", we will extend their framework in order to address our biological problem . a heuristic physical argument and a summary of the results",
    "is provided in that section , and proofs will be presented in section  [ sec : benarous ] and appendix  [ append : proofs ] .",
    "similarly to their analysis of spin glass dynamics , we will use large - deviation techniques to characterize the macroscopic limits of these systems in the limit where the number of neurons tends to infinity .",
    "there are two main technical distinctions with existing literature .",
    "first is the fact that we deal with multi - populations networks , which involves highly nontrivial difficulties , some of which will be further analyzed in a forthcoming study .",
    "second , the fact that the connectivity weights are not centered introduce additional terms that need special care . and",
    "third is the presence of delays in the interactions , leading to work in infinite - dimensional spaces .    the limit of the systems being found",
    ", we will analyze the solutions of the asymptotic system in section  [ sec : solutions ] .",
    "fortunately , we will show that the solutions of the limit system has gaussian solutions that are exponentially attractive .",
    "these gaussian solutions are univocally characterized by their mean and covariance functions , and these variables satisfy a closed set of deterministic equations , similar to the ones generally used by physicists from the dynamic mean - field theory  @xcite .",
    "the mean satisfies a delayed differential equation coupled to the variance of the solution .",
    "these are extremely hard to study analytically .",
    "in particular , in contrast with the case of deterministic synaptic weights  @xcite , the variance does not satisfies an ordinary differential equation but can be written as the solution of a fixed point equation .",
    "this distinction is fundamentally related to the non - markovian nature of the asymptotic equation .",
    "however , based on the bifurcation analysis of the equation on the mean of the gaussian solution , an alternative method to more usual analyzes of these mean - field equations , we will be able to characterize the solutions and demonstrate that noise is directly related to the emergence of synchronized oscillations , a highly relevant macroscopic state related to fundamental cortical functions such as memory , attention , sleep and consciousness , and its impairments relate to serious pathologies such as epilepsy or parkinson s disease  @xcite , and that may account for the results of aradi and colleagues showing that increased heterogeneity was related with epilepsy .",
    "in this section we introduce the model that we will be investigating in the present manuscript and the main results of the analysis .",
    "a heuristic discussion is provided to explain from a physical viewpoint the results that we will establish in section  [ sec : benarous ] .      in all the manuscript",
    ", we are working in a complete probability space @xmath2 endowed with a filtration @xmath3 satisfying the usual conditions .",
    "we consider a network composed of @xmath4 neurons falling into one of @xmath5 populations .",
    "we define by @xmath6 the _ population function _ associating to a neuron index the population label it belongs to .",
    "the state of each neuron @xmath7 in population @xmath8 is described by its membrane potential @xmath9 , and considered to satisfy a firing - rate equation ( similar to the hopfield network well known to physicists , see  @xcite ) : @xmath10 where @xmath11 is the characteristic time of neurons of population @xmath12 , @xmath13 is the synaptic efficiency of the synapse between neuron @xmath14 and neuron @xmath7 , @xmath15 the sigmoidal voltage - to - rate function , @xmath16 the propagation delay between neurons of population @xmath17 and neurons of population @xmath12 , and @xmath18 the noise intensity .",
    "the brownian motions @xmath19 account for the noisy input received by all neurons , and the heterogeneity of the connections is integrated in the synaptic weights @xmath13 .",
    "these weights are assumed to be independent gaussian random variables , with law @xmath20 , and in the stochastic synaptic noise case , these will be assumed to be stochastic processes , further specified below .",
    "let us emphasize that all the results readily generalize to neurons having a nonlinear intrinsic dynamics : @xmath21 under the condition that the functions @xmath22 for @xmath23 satisfy two standard regularity conditions :    1 .",
    "the functions @xmath22 are uniformly locally lipschitz - continuous in their second variable .",
    "they satisfy a uniform monotone growth condition : for any @xmath24 , @xmath25 .",
    "these refinements allow considering more biologically relevant neuron models .",
    "however , generalizations of the interaction that would depend on both the pre- and post - synaptic neurons ( consisting in replacing the function @xmath26 by a nonlinear function @xmath27 in equation  ) are harder to achieve and the methodology used in the present manuscript can not be extended to these more general cases .",
    "let us define @xmath28 , and let @xmath29 a collection of @xmath5 probability distributions on @xmath30 , { \\mathbbm{r}})$ ] that will be used to characterize the initial condition of neurons in population @xmath12 .",
    "the initial condition on the network are considered chaotic , given by : @xmath31 } = \\bigotimes_{i=1}^n \\mu_{p(i)}.\\ ] ]    the function @xmath32 are lipschitz - continuous sigmoidal functions , i.e. non - decreasing functions tending to @xmath33 at @xmath34 and to @xmath35 at @xmath36 .",
    "this model differs from the work of ben - arous and guionnet in that the voltage is not bounded , there exist multiple populations and the interactions are nonlinear and delayed , which sets the problem in an infinite - dimensional space .",
    "the first question that may arise at this point is the well - posedness of the system .",
    "[ pro : existenceuniquenessnetwork ] for each @xmath37 and @xmath38 , there exists a unique weak solution to the system   defined on @xmath39 $ ] with initial condition  .",
    "moreover , this solution is square integrable .",
    "the proof of this result direct stems of standard theory of delayed stochastic differential equations  @xcite .",
    "indeed , the network equations correspond to delayed stochastic differential equation in dimension @xmath4 . for these equations , it is established that existence , uniqueness and square integrability of the solution hold under the assumption that the drift and diffusion functions are lipschitz - continuous and enjoy a linear growth property , which clearly hold for our system .",
    "note that if the initial condition was given by @xmath40}=\\zeta^i$ ] with @xmath41 , we can also prove strong existence and uniqueness of solutions .",
    "the mean - field approach consists in reducing the @xmath4-dimensional delayed stochastic differential equation   to a @xmath5-dimensional equation on the law of the system in the limit where all @xmath42 . in",
    ", one needs to characterize the behavior of @xmath43 in the large @xmath44 limit .",
    "following the idea of molecular chaos of boltzmann ( `` stozahlansatz '' ) , we may assume that all neurons behave independently and independently of the disorder .",
    "this physical ansatz is the basis of our heuristical approach . assuming that the processes @xmath45 and the coefficients @xmath13 are independent , the local interaction term @xmath43 is a sum of independent gaussian processes . a functional version of the central limit theorem ( under suitable regularity and boundedness conditions ) would ensure that @xmath46 , \\sum_{\\gamma=1}^m { \\sigma_{\\alpha \\gamma}}^2{\\mathbbm{e}}\\big[{s_{\\alpha \\gamma}}(\\bar{x}^{\\gamma}_{t-{\\tau_{\\alpha \\gamma}}})^2\\big ]   \\right)\\ ] ] where the gaussian limits are pairwise independent .",
    "in other words , under the molecular chaos hypothesis , averaging effects occur at the level of all neurons , and an effective interaction term in the form of a gaussian process , will be obtained as an effective collective interaction term : @xmath47 , \\sum_{\\gamma=1}^m { \\sigma_{\\alpha \\gamma}}^2{\\mathbbm{e}}\\big[{s_{\\alpha \\gamma}}(\\bar{x}^{\\gamma}_{t-{\\tau_{\\alpha \\gamma}}})^2\\big ]   \\right ) pairwise \\ ; independent . \\end{cases}\\end{aligned}\\ ] ]    this is precisely the same kind of results one obtains in the mean - field theory for spin - glasses . from a mathematical viewpoint , the assumptions of independence of the variables @xmath48 and of the @xmath13 can not be rigorously legitimated .    and unfortunately , as is the case in the theory of spin glasses , rigorous approaches up to now rely on relatively abstract methods using in particular large - deviations theory .",
    "this is the approach we will now develop .",
    "we shall eventually note that a posteriori validation of the intuition provided by this heuristic argument will be obtained as a side result of our analysis : we will indeed show that a propagation of chaos phenomenon occurs in the limit where all @xmath49 , i.e. that , provided the initial conditions are independent identically distributed for all neurons in the same population , then finite subsets of neurons behave independently for all times and have the same law given by the mean - field equation  .",
    "mathematical demonstration of such convergence results for multi - populations networks are still to be developed in general settings , and up to our knowledge no result of this kind for multi - populations networks with different population size exist in the literature .",
    "in particular , sanov s theorem , hinge of most studies for the convergence of large - scale networks with heterogeneities , is still to be proved for such systems where the elements are one of a few populations and not identically distributed . in order to show rigorous results on the dynamics",
    ", we will slightly specify the problem and consider that all populations have identical sizes @xmath50 ( hence , @xmath51 ) . in that case",
    ", the analysis can be reduced to the analysis of one - populations systems but with @xmath5-dimensional variables , whose @xmath52 component is the voltage of one of the neurons in population @xmath12 .",
    "we now group the @xmath4 variables @xmath53 into @xmath5-dimensional variables @xmath54 where @xmath55 , and such that for any @xmath56 , @xmath57 .",
    "the dynamics of these variables , readily deduced from the original network dynamics , can be written in vector form as : @xmath58 where @xmath59 is the diagonal matrix with coefficient @xmath60 equal to @xmath61 , @xmath62 is the @xmath63 matrix with elements @xmath64 , and @xmath65 is the @xmath63 matrix with elements @xmath66 given by @xmath67 .",
    "the linear operator @xmath68 acts on @xmath63 matrices by giving the diagonal ( as a @xmath5-dimensional vector ) of the classical matrix product of two matrices , so that the component @xmath12 of @xmath69 is precisely equal to @xmath70 .",
    "@xmath71 is the diagonal matrix with diagonal element @xmath18 and @xmath72 .",
    "we now work with an arbitrary fixed time @xmath38 and denote by @xmath73 the unique law solution of the network equations   restricted to the @xmath74-algebra @xmath75 .",
    "@xmath73 is a probability measure on @xmath76 where @xmath77 is the space of continuous functions of @xmath78 $ ] with value in @xmath79 .",
    "when neurons are not coupled ( i.e. @xmath80 for all @xmath81 ) , the law of all variables @xmath82 are identical , independent , and given by the unique solution @xmath83 of the one - dimensional standard sde : @xmath84 the uncoupled system hence has the law of the ornstein - uhlenbeck process .",
    "@xmath83 is the law of this process restricted to the @xmath74-algebra @xmath85 , it is a probability measure on the space @xmath86 of continuous functions of @xmath87 $ ] in @xmath79 .",
    "we will denote by @xmath88 the law of its component @xmath12 ( in our case , @xmath89 ) .",
    "we want to study the behavior of the empirical law on each population : @xmath90 under @xmath73 where the coefficients @xmath13 are independent gaussian with law given above . by a direct application of girsanov theorem ,",
    "@xmath73 is absolutely continuous with respect to @xmath91 and we have : @xmath92 where the prime denotes the transposition .",
    "the aim of the present manuscript is to prove the following :    [ thm : convergence ] under @xmath93 the law of the @xmath4-neurons system averaged over all possible configurations ( realizations of the synaptic weights @xmath94 ) , the sequence of empirical measures @xmath95 converges towards @xmath96 as @xmath50 goes to infinity for some probability measure @xmath97 .    in detail",
    ", we will show that the sequence empirical measures @xmath95 satisfies a weak large deviation upper bound property and is tight .",
    "precisely , we will demonstrate that :    [ thm : ldp ] there exists a good rate function @xmath98 such that for any compact subset @xmath99 of @xmath100 where @xmath101,{\\mathbbm{r}}^m)$ ] : @xmath102    moreover , we will show a tightness result on that sequence , namely :    [ thm : tightness ] for any real number @xmath103 , there exists a compact subset @xmath104 such that for any integer @xmath50 , @xmath105    these two results imply the convergence result provided that we characterize uniquely the minima of @xmath98 , which will be the subject of theorem :    [ thm : limit ] the good rate function @xmath98 is such that :    1 .",
    "it achieves its minimal value at the probability measure @xmath106 satisfying the implicit equation : @xmath107\\ ] ] where @xmath108 denotes the expectation over @xmath109 a gaussian process with mean : @xmath110 = \\sum_{\\gamma=1}^m { \\bar{j}_{\\alpha \\gamma}}\\int { s_{\\alpha \\gamma}}(x_{t-\\tau_{\\alpha\\beta}})dq^{\\beta}(x)\\ ] ] and covariance : @xmath111 = \\delta_{\\alpha\\gamma}\\sum_{\\beta=1}^m \\sigma_{\\alpha\\beta}^2\\int s_{\\alpha\\beta}(x_{t-\\tau_{\\alpha\\beta}})s_{\\alpha\\beta}(x_{s-\\tau_{\\alpha\\beta}})dq^{\\beta}(x)\\ ] ] where @xmath112 equals @xmath35 if @xmath113 and @xmath33 otherwise .",
    "2 .   this provides an implicit self - consistent equation on @xmath97 the limit distribution , which has a unique solution .",
    "this theorem will be demonstrated in section  [ sec : limitidentification ] .",
    "eventually , we will show that the unique solution has gaussian local equilibria ( theorem  [ pro : gaussiansolutions ] ) , with mean @xmath114 and covariance @xmath115 satisfying the well - posed system of deterministic equations : @xmath116 where @xmath117 .",
    "the covariance is equal to zero when @xmath118 and : @xmath119\\ ] ] where @xmath120 $ ] is a nonlinear function of @xmath121 , @xmath122 , @xmath123 , @xmath124 and @xmath125 .    in other words ,",
    "the solution can be written , in law , as the solution of an implicit equation : @xmath126 where the processes @xmath127 are independent brownian motions and the processes @xmath128 are gaussian processes with law as @xmath129 as described in theorem  [ thm : limit ]",
    ". these characterizations will be very handy to analyze the qualitative dynamics and phase transitions of the system .",
    "the aim of this section is to identify a good rate function for the system that we will use in theorem [ thm : ldp ] to show a large deviation principle . in order to introduce our good rate function ,",
    "it is convenient to analyze for a moment a time - discretization of the equation ( section  [ sec : discretetime ] ) , which will expedite the analysis of our continuous time problem .      given an integer @xmath130 , we define @xmath131 a partition of @xmath87 $ ] and consider the following dynamics for the neurons of population @xmath12 : @xmath132 } = \\mu_{\\alpha}^{\\otimes { n_{\\alpha } } }          \\end{cases}\\ ] ] as in proposition [ pro : existenceuniquenessnetwork ] , this system clearly admits a unique weak solution for any @xmath133 .",
    "we will denote @xmath134 its restriction to the @xmath74-algebra @xmath135 , and @xmath136 .",
    "they are both probability measures on @xmath137,{\\mathbbm{r}})^n$ ] . by girsanov theorem ,",
    "@xmath138 with : @xmath139 for every @xmath140 , the relative entropy with respect to @xmath83 is defined by : @xmath141 we introduce , for @xmath142 , the two following functions , respectively defined on @xmath87 ^ 2 $ ] and @xmath87 $ ] : @xmath143    remark that , since @xmath144 takes value in @xmath145 $ ] , both functions are bounded : @xmath146 and @xmath147 , with @xmath148 and @xmath149 .",
    "we now define @xmath150 it is well known that we can find a @xmath5-dimensional stochastic process @xmath151 on @xmath152 such that , for any @xmath63 variance - covariance matrix @xmath99 on @xmath87 ^ 2 $ ] , there exists a probability measure @xmath153 , under which @xmath154 is a centered gaussian process with covariance @xmath99 .",
    "we shall use the shorthand notation @xmath155 for @xmath156 , and @xmath157 the expectation under @xmath155 .",
    "we now define for @xmath142 : @xmath158    @xmath159    where @xmath160 , for @xmath161 .",
    "eventually , we define the function : @xmath162    one can easily see that @xmath163 , as the components of @xmath154 are independent under @xmath155 .",
    "we further define : @xmath164 @xmath165    where @xmath166 one can easily see that this function takes values in the @xmath63 diagonal positive matrices .",
    "moreover , we can define @xmath167 , probability measure on @xmath168 , such that @xmath169 under which @xmath154 is a @xmath5-dimensional centered gaussian process with covariance @xmath170 ( this gaussian calculus property is proved for instance in  ( * ? ? ?",
    "* appendix a ) ) .",
    "[ pro : dcompositiongamma ] we have : @xmath171    let @xmath172 @xmath173 for @xmath174 , it is sufficient to prove that @xmath175 but , @xmath176 \\bigg\\ } - \\frac{1}{2}\\int_0^t ( m^{\\alpha}_{\\mu}({t^{(k)}}))^2 dt + \\int \\int_0^t m_{\\mu}^{\\alpha}({t^{(k ) } } ) dw_t^{\\alpha } d\\mu \\\\      & + \\int \\log\\bigg\\ { \\int \\exp { \\bigg(\\int_0^t g_{{t^{(k)}}}^{\\alpha}\\big(dw_t^{\\alpha } - m_{\\mu}^{\\alpha}({t^{(k)}})dt\\big ) \\bigg ) } d\\gamma_{\\widetilde{k}_{\\mu}^{t , k } } \\bigg\\ } d\\mu      \\end{aligned}\\ ] ] standard gaussian calculus yields : @xmath177 so that , @xmath178 which concludes the proof .",
    "for all @xmath179 , let :    @xmath180    @xmath181    one can easily see that @xmath182 .",
    "let    @xmath183    we eventually denote by @xmath184 the vaserstein distance on @xmath185 , compatible with the weak topology : @xmath186 the infimum being taken on the laws @xmath187 with marginals @xmath188 and @xmath189 .    we now show the following regularity properties on the introduced functions :    [ lemma1 ]    1 .",
    "there exists a positive constant @xmath190 , depending on t but not on n , such that : @xmath191 .",
    "@xmath192 i.e. @xmath193 is a positive function . in particular",
    ", @xmath194 is finite whenever @xmath195 is .",
    "there exists real constants @xmath196 and @xmath197 such that @xmath198 .",
    "4 .   there exists a positive constant @xmath190 , depending on t but not on n , such that : @xmath199 .",
    "5 .   defining the following probability measure on @xmath200 : @xmath201 we have @xmath202 , so that @xmath203 is lower semi - continuous on @xmath200 .",
    "@xmath193 is a good rate function .",
    "this technical lemma is proved in appendix  [ append : prooflemma1 ]      in this section , we shall prove theorem  [ thm : convergence ] as a consequence of theorems  [ thm : ldp ] and  [ thm : tightness ] . we start by extending the function constructed in the previous section to our continuous time setting . to this purpose ,",
    "let us define @xmath204 @xmath205 and @xmath206    remark that , as for the discrete time case , @xmath207 .    1 .   on the compact set @xmath208",
    ", @xmath209 converges uniformly to @xmath210 .",
    "@xmath211 where @xmath212 @xmath213 3 .",
    "@xmath214 and @xmath215 .",
    "4 .   @xmath98 is a good rate function .",
    "( i ) , ( ii ) : :    following the same demonstration as in lemma.[lemma1 ] ( i ) and ( iv ) , we    find that there exists @xmath216 and @xmath217    such that ( see and ) @xmath218 but , according to , we have for any    @xmath219    @xmath220    and by bounded convergence theorem    @xmath221    let @xmath103 , choosing    @xmath222 , it is easy to see that there    exists an integer @xmath223 such that , for    @xmath224 :    @xmath225    hence , for any @xmath226 , any    @xmath227 , and any @xmath228 :    @xmath229 which shows that    @xmath230 , @xmath231 ,    and thus @xmath232 converge uniformly on    @xmath233 .",
    "it is not difficult to see that the respective    limits are @xmath234 ,    @xmath235 and @xmath236 ,    which implies    @xmath237 on    @xmath233 .",
    "besides , as    @xmath238 and    @xmath239 , we also have    the uniform convergence of @xmath209 towards    @xmath210 on @xmath233 .",
    "( iii ) : :    the proof is identical to lemma[lemma1 ] ( iii ) and ( iv ) .",
    "( iv ) : :    lets show that @xmath240 is a compact set",
    ".    @xmath241 so that    @xmath242 .",
    "hence    @xmath243 .",
    "let    @xmath244 .    as here",
    "@xmath245 is a    compact set , there exists a subsequence @xmath246    such that @xmath247 as    @xmath248 .",
    "we conclude by stating that , as    @xmath193 converge uniformly towards @xmath98 on    @xmath245 , the latest    inherits the lower semi - continuity of the firsts .",
    "hence    @xmath240 is a closed set so that    @xmath249 and    @xmath246 converges in    @xmath240 .",
    "[ lemma2 ]    @xmath250    by , we have : @xmath251 applying fubini theorem , we find that @xmath252 and : @xmath253.\\ ] ] but , under @xmath254 , the @xmath13 are independent , so that : @xmath255.\\ ] ] lets show that @xmath256 is an @xmath5-dimensional gaussian process with covariance @xmath257 , and mean @xmath258 .",
    "in fact @xmath259 lets remember that the functions @xmath260 are , in this equality , seen as determinists as arguments of the studied density . with this in mind and because of the independence of the gaussian random variables @xmath13 , we can see that the components of the above vector are gaussian processes , mutually independents .",
    "moreover , the mean and covariance of the component @xmath261 are the following : @xmath262 & = \\frac{1}{{\\lambda_{\\alpha } } } \\sum_{\\gamma=1}^m { \\bar{j}_{\\alpha \\gamma}}\\frac{1}{n } \\sum_{j=1}^n { s_{\\alpha \\gamma}}(x^{j_{\\gamma}}_{t-{\\tau_{\\alpha \\gamma}}})\\\\      & = m^{\\alpha}_{\\hat{\\mu}_n}(t )      \\end{aligned}\\ ] ] @xmath263\\\\      & = \\frac{1}{{\\lambda_{\\alpha}}^2 } \\sum_{\\gamma=1}^m { \\sigma_{\\alpha \\gamma}}^2 \\frac{1}{n } \\sum_{j=1}^n { s_{\\alpha \\gamma}}(x^{j_{\\gamma}}_{t-{\\tau_{\\alpha \\gamma}}}){s_{\\alpha \\gamma}}(x^{j_{\\gamma}}_{s-{\\tau_{\\alpha \\gamma}}})\\\\ = k^{\\alpha}_{\\hat{\\mu}_n}(t )      \\end{aligned}\\ ] ]    we eventually find that : @xmath264    let , for any @xmath265 , @xmath266 @xmath267 @xmath268 @xmath269 as in lemma  [ lemma1 ] .",
    "@xmath270 , we can show that @xmath271 and is therefore semi - continuous .",
    "[ lemma3 ] for any compact subset @xmath99 of @xmath200 , @xmath272    let @xmath273 .",
    "we can find an integer @xmath274 and a family @xmath275 of probability measure on @xmath77 such that @xmath276 where @xmath277 and @xmath184 denotes the vaserstein distance on @xmath200 .",
    "a very classical result ( see e.g.  ( * ? ? ? * lemma 1.2.15 ) ) , ensures that @xmath278 let @xmath279 .",
    "lemma  [ lemma2 ] gives us : @xmath280 but , for any probability measure @xmath279 , @xmath281 is a probability measure on @xmath282 .",
    "hence , for any conjugate exponents @xmath283 , @xmath284    we will first bound the second term of the right hand side by proving the following lemma  [ lemma3.1 ] .",
    "once this step performed , concluding the proof amounts bounding the first term in the right hand side of ( [ ineqpi ] ) using the same arguments as in ( * ? ? ?",
    "* lemma 3.8 ) .",
    "remark that , as the space we work on remains a polish and the @xmath285 are i.i.d under @xmath286 , we can still resort to sanov theorem .",
    "[ lemma3.1 ] for any real number @xmath287 , there exists a strictly positive real number @xmath288 such that , for any @xmath289 , there exists a function @xmath290 in @xmath291 such that @xmath292 and : @xmath293    the proof of this lemma is relatively technical , and it is provided in appendix  [ append : prooflemma3.1 ] .    [ thm : tightness ] for any real number @xmath294 , there exists a compact set @xmath104 of @xmath200 such that , for any integer @xmath50 , @xmath295    the proof of this theorem consists in using the relative entropy inequality   and to use the exponential tightness of the sequence of laws @xmath91 . indeed , defining @xmath296 an arbitrary set in @xmath76 and applying   to the function @xmath297 yields : @xmath298 and the exponential tightness of @xmath91 ( see e.g.  ( * ? ? ?",
    "* lemma 3.2.7 ) ) ensures that for any @xmath103 there exists a compact subset @xmath104 of @xmath200 such that @xmath299    the theorem is hence proved as soon as we show that there exists a finite constant @xmath300 , such that for any integer @xmath50 , @xmath301 .",
    "using the expression of the relative entropy and the interchangeability of the neurons of the same population , we find : @xmath302}dq^n\\ ] ] for every @xmath261 let , @xmath303 d{p_{\\alpha}}^{\\otimes { n_{\\alpha}}}\\ ] ] which is a probability measure on @xmath137,{\\mathbbm{r}})^{{n_{\\alpha}}}$ ] .",
    "one can see that @xmath304 .",
    "after some gaussian computations ( see ( * ? ? ?",
    "* lemma 5.15 ) ) , we find that : @xmath305 = \\exp\\bigg\\{\\int_0^t h^{\\alpha}_t(q^{{n_{\\alpha } } } ) dw^{1_{\\alpha}}_t-\\frac{1}{2}\\int_0^t \\big(h^{\\alpha}_t(q^{{n_{\\alpha}}})\\big)^2dt\\bigg\\}\\ ] ] where @xmath306 + m^{\\alpha}_{\\hat{\\mu}_n}(t )      \\end{aligned}\\ ] ] @xmath307}.\\ ] ]    consequently , there exists a @xmath308 brownian motion @xmath309 such that : @xmath310    using   and this brownian motion in  , we have : @xmath311 + m^{\\alpha}_{\\hat{\\mu}_n}(t ) \\bigg)^2 dt dq^n \\nonumber \\\\      & \\leq n \\sum_{\\alpha=1}^n \\int \\int_0^t   \\bigg ( { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\lambda_t^{{n_{\\alpha } } } g^{\\alpha}_t \\times \\int_0^t   g^{\\alpha}_s \\big(dw^{1_{\\alpha}}_s - m^{\\alpha}_{\\hat{\\mu}_n}(s)ds\\big ) \\bigg ] \\bigg)^2 + { m^{\\alpha}_{\\hat{\\mu}_n}}^2(t ) dt dq^n \\nonumber \\\\      & \\leq n \\sum_{\\alpha=1}^n \\times \\bigg\\ { \\int_0^t \\int \\underbrace{\\int   \\bigg ( { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\lambda_t^{{n_{\\alpha } } } g^{\\alpha}_t \\times \\int_0^t   g^{\\alpha}_s \\big(dw^{1_{\\alpha}}_s - m^{\\alpha}_{\\hat{\\mu}_n}(s)ds\\big ) \\bigg ] \\bigg)^2 dq^{{n_{\\alpha}}}}_{f^{\\alpha}(t ) } d(\\otimes_{\\gamma \\neq \\alpha } q^{{n_{\\gamma } } } ) dt + \\frac{{\\bar{j}_{\\alpha}}^2 t}{{\\lambda_{\\alpha}}^2 } \\bigg\\ } \\label{ineqi }      \\end{aligned}\\ ] ] we now will bound @xmath312 : @xmath313 ^ 2 dq^{{n_{\\alpha } } } + \\int   { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\lambda_t^{{n_{\\alpha } } } g^{\\alpha}_t \\int_0^t   g^{\\alpha}_s m^{\\alpha}_{\\hat{\\mu}_n}(s)ds \\ ; \\bigg]^2 dq^{{n_{\\alpha } } } \\\\      & + \\int   \\bigg ( \\int_0^t { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\lambda_t^{{n_{\\alpha } } } g^{\\alpha}_t g^{\\alpha}_s \\bigg ] { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\lambda_s^{{n_{\\alpha } } } g^{\\alpha}_s \\int_0^s g^{\\alpha}_u \\big(dw^{1_{\\alpha}}_u - m^{\\alpha}_{\\hat{\\mu}_n}(u)du\\big ) \\bigg ] ds \\bigg)^2 dq^{{n_{\\alpha } } } \\bigg\\ }      \\end{aligned}\\ ] ] but by cauchy - schwarz inequality , @xmath314 ^ 2 dq^{{n_{\\alpha } } }   \\leq \\int \\bigg\\ {   { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\big(\\lambda_t^{{n_{\\alpha } } } g^{\\alpha}_t\\big)^2 \\bigg ] { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\big ( \\int_0^t   g^{\\alpha}_s db^{1_{\\alpha}}_s\\big)^2 \\ ; \\bigg ] \\bigg\\ } dq^{{n_{\\alpha } } }      \\end{aligned}\\ ] ] as @xmath315 \\leq \\frac{{k_{\\alpha}}}{{\\lambda_{\\alpha}}^2}$ ] ( see @xcite appendix a ) , we have by fubini theorem and ito s isometry : @xmath316 ^ 2 dq^{{n_{\\alpha } } } \\leq   \\frac{{k_{\\alpha}}}{{\\lambda_{\\alpha}}^2 } \\int \\bigg\\ { { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\bigg ( \\int_0^t   { g^{\\alpha}_s}^2 ds \\bigg ) \\bigg ] \\bigg\\ } dq^{{n_{\\alpha } } } \\leq \\frac{{k_{\\alpha}}^2 t}{{\\lambda_{\\alpha}}^4 }      \\end{aligned}\\ ] ] by similar arguments , @xmath317 ^ 2 dq^{{n_{\\alpha } } } & \\leq \\int \\bigg\\ {   { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\big(\\lambda_t^{{n_{\\alpha } } } g^{\\alpha}_t\\big)^2 \\bigg ] { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\big ( \\int_0^t   g^{\\alpha}_s m^{\\alpha}_{\\hat{\\mu}_n}(s ) ds\\big)^2 \\ ; \\bigg ] \\bigg\\ } dq^{{n_{\\alpha}}}\\\\      & \\leq \\frac{{k_{\\alpha}}}{{\\lambda_{\\alpha}}^2 } \\int \\bigg\\ { { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\frac{{\\bar{j}_{\\alpha}}^2 t}{{\\lambda_{\\alpha}}^2 } \\bigg ( \\int_0^t   { g^{\\alpha}_s}^2 ds \\bigg)^2 \\ ; \\bigg ] \\bigg\\ } dq^{{n_{\\alpha } } } \\leq \\frac{{\\bar{j}_{\\alpha}}^2 { k_{\\alpha}}^2 t^2}{{\\lambda_{\\alpha}}^6 }      \\end{aligned}\\ ] ]    and , @xmath318 { { \\mathcal{e}}}_{\\hat{\\mu}_n } \\bigg [ \\lambda_s^{{n_{\\alpha } } } g^{\\alpha}_s \\int_0^{s } g^{\\alpha}_u \\big(dw^{1_{\\alpha}}_u - m^{\\alpha}_{\\hat{\\mu}_n}(u)du\\big ) \\bigg ] ds \\bigg)^2 dq^{{n_{\\alpha } } } \\leq \\big(\\frac{{k_{\\alpha}}}{{\\lambda_{\\alpha}}^2}\\big)^2 t   \\int_0^t f^{\\alpha}(s ) ds .      \\end{aligned}\\ ] ]    eventually , we proved the following inequality : @xmath319",
    "so that , by gronwall lemma , @xmath320 thus , ( [ ineqi ] ) implies : @xmath321      we have seen that the empirical laws @xmath322 satisfy a weak large deviations upper bound with good rate function @xmath98 . in order to identify the limit of the system , we study the minima of the functions @xmath98 through a variational study",
    ". we will show in section  [ sec : charact]that any minimum of all @xmath98 are measures @xmath323 satisfying the implicit equation : @xmath324 we will then prove in section  [ sec : existuniquelim ] that there exists a unique probability measure @xmath97 satisfying  .",
    "this law will be further analyzed in the next section .",
    "the large deviation principle ensures that the sequence of empirical measures converge , and that the possible limits minimize the good rate functions .",
    "we hence need to identify the minima and show that these are uniquely defined by equation  . to this purpose ,",
    "we start by showing that any probability density achieving the minimum of all the @xmath98 is equivalent to @xmath83 . to this end",
    ", we show the following technical result :    [ lem : qequivp ] let @xmath97 be a probability measure on @xmath77 which minimizes @xmath98",
    ". then @xmath106",
    ". moreover , noting @xmath325 and @xmath326 , we have , noting @xmath327 :    * @xmath328 * @xmath329    if @xmath97 minimizes @xmath98 , then necessarily @xmath330 is finite , meaning that @xmath106 .",
    "moreover , it is easy to see that : @xmath331 which proves the first point .",
    "the second point is proved using standard gaussian calculus noting that if @xmath332 and @xmath333 are independent centered gaussian processes with covariance @xmath334 and @xmath335 , then @xmath336 has the covariance @xmath337 .",
    "we hence have @xmath338 , and we can write : @xmath339 the exponential term is given by : @xmath340 using the fact that @xmath341 and @xmath342 are gaussian processes with bounded covariances and using the fact that the mean quadratic variation of @xmath343 under @xmath344 is also bounded ( see  @xcite ) we can obtain that : @xmath345 and we finally obtain : @xmath346 integrating with respect to @xmath347 and using the independence of @xmath332 and @xmath333 and the fact that @xmath333 is centered , we obtain the desired result .",
    "this lemma ensures that any minimum of @xmath98 is equivalent to @xmath83 .",
    "indeed , if @xmath348 , then the result of lemma  [ lem : qequivp ] implies that @xmath349 which is strictly negative for small @xmath350 , contradicting the fact that we assumed that @xmath97 minimized @xmath98 .",
    "we therefore necessarily have @xmath351 , that is @xmath352 .",
    "let us now characterize the minima of @xmath98 . to this purpose",
    ", we use a variational formulation to show that any minimum of @xmath98 satisfies equation  , and start by proving the following technical result :    [ lem : density ] let @xmath353 be a positive and bounded measurable function on @xmath77 such that @xmath354 , and denote @xmath355 and @xmath356 . we have :    * @xmath357 * @xmath358 where @xmath359 is an adapted process with finite variation and @xmath360 is a bounded function .",
    "the first point is simply proved as follows : @xmath361 noting that @xmath362 and @xmath363 , we readily obtain the desired result .",
    "the second point is slightly more delicate but based on the same argument as outlined in the proof of lemma  [ lem : qequivp ] .",
    "we introduce two independent centered gaussian processes @xmath332 and @xmath333 with covariances @xmath334 and @xmath364 respectively and build the gaussian process @xmath365 that has the covariance given by @xmath366 .",
    "we then express @xmath367 as : @xmath368 and a series expansion ensures that : @xmath369 \\\\   & \\qquad \\qquad + \\sum_{\\alpha \\neq \\gamma } \\bigg ( \\int_0^t v^{\\alpha}_t dw^{\\alpha}_t - \\int_0^t v^{\\alpha}_t\\left(g^{\\alpha}_t + m^{\\alpha}_q(t)\\right)dt\\bigg ) \\bigg(\\int_0^t",
    "v^{\\gamma}_t dw^{\\gamma}_t - \\int_0^t v^{\\gamma}_t\\left(g^{\\gamma}_t + m^{\\gamma}_q(t)\\right)dt\\bigg)\\bigg\\ } + o(s^{\\frac 3 2})\\bigg )           \\end{aligned}\\ ] ] integrating with respect to @xmath370 and injecting this expansion in the expression of @xmath210 yields the expression : @xmath371 with @xmath372 and @xmath373    it is easy to see that @xmath374 , so that : @xmath375 or , @xmath376 where @xmath377 and @xmath378    let @xmath379 . as @xmath380 , fubini theorem ensures that : @xmath381 \\\\      \\end{gathered}\\ ] ] as @xmath382 , we conclude by stating that @xmath383 is an @xmath97-integrable process , which ends the proof .",
    "we are now able to prove that any minimum satisfies equation  .",
    "a necessary condition for @xmath97 to minimize @xmath98 is @xmath384 but lemma  [ lem : density ] implies that , for every @xmath353 such that @xmath354 , @xmath385 let @xmath386 we can rewrite   as : @xmath387 lets show that for any bounded measurable function @xmath388 with @xmath389 , we have @xmath390 and , as a consequence , we can find a constant @xmath391 such that @xmath392 almost surely under @xmath97 , and thus @xmath83-almost surely . indeed ,",
    "if not , we can find @xmath388 such that @xmath393 and @xmath394 .",
    "now let @xmath395 .",
    "choosing @xmath396 with @xmath397 large enough , it is clear that @xmath398 satisfies the condition of lemma  [ lem : density ] , and moreover : @xmath399 which is strictly negative for @xmath400 big enough .",
    "hence , we find a contradiction with condition  , so that @xmath83 almost surely we have the equality @xmath392 .",
    "but @xmath401 must be a @xmath402 local martingale .",
    "since @xmath403 is a local martingale and @xmath404 a process with finite variation , we have by uniqueness of semimartingale decomposition , we conclude that : @xmath405      as a consequence of the form of the density obtained from equation   and the fact that the law of the uncoupled process @xmath83 is gaussian , it is easy to show that when considering gaussian initial conditions , any possible minimum of @xmath98 is a gaussian process . indeed , the characterization of the minima readily implies ( as a simple application of girsanov theorem ) that the possible limits of the network equations are the law of the solutions of the implicit equation : @xmath406 where the processes @xmath127 are independent brownian motions and the processes @xmath128 are gaussian processes with mean @xmath407\\ ] ] and covariance @xmath408 if @xmath409 and @xmath410 where @xmath411\\ ] ] the relation given by   provides a self - consistent equation on the moments of the gaussian , which is given in the following :    [ pro : gaussiansolutions ] considering that the initial conditions are gaussian",
    ", then possible minimum @xmath412 of the good rate function is gaussian .",
    "denoting by @xmath413 the mean of @xmath414 and by @xmath415 $ ] their covariance , we have : @xmath416 where @xmath417 .",
    "the covariance is equal to zero when @xmath118 and : @xmath418\\ ] ] where @xmath120 $ ] is a nonlinear function of @xmath121 , @xmath122 , @xmath123 , @xmath124 and @xmath125 .",
    "moreover , there exists a unique solutions to these self consistent equations   and  .",
    "the above theorem hence characterizes univocally the limits of the network equations considered .",
    "the proof of this proposition was done in  @xcite starting from equations   which were introduced using a heuristic argument .",
    "note also that if the initial condition is not gaussian , the solutions are not gaussian .",
    "however , as time goes by , solutions get exponentially fast attracted to the gaussian solutions described in theorem  [ pro : gaussiansolutions ] .",
    "that description hence provides a handy procedure to analyze the solutions of the mean - field equations and their dynamics as a function of the parameters .",
    "in particular , we observe that the levels of heterogeneity , @xmath419 , appear as parameters of the equations .",
    "the moment equations provided above hence allow analyzing the qualitative effects of heterogeneity on the behavior of the network .",
    "if one is interested in the possible solutions of the mean - field equations for non - gaussian initial conditions , or when the intrinsic dynamics of the system is not linear ( i.e. @xmath83 is not a gaussian measure ) , existence and uniqueness of solutions to the implicit equations   also hold , but the demonstration of this property is more involved .",
    "the basic idea of the proof is based on a contraction principle , as usually done for proving existence and uniqueness of solutions .",
    "it is possible to show that one has a contraction in the vaserstein distance .",
    "the steps of the proof are given in a different context in  ( * ? ? ?",
    "* section 5.2 ) , and is not given here since we are not dealing with these more general cases .",
    "we are now in a position to prove theorem  [ thm : convergence ] .    indeed , for @xmath420 a strictly positive real number and @xmath421 the open ball of radius @xmath420 centered in @xmath97 for the vaserstein distance .",
    "we prove that @xmath422 tends to zero as @xmath50 goes to infinity .",
    "indeed , for @xmath104 a compact defined in theorem  [ thm : tightness ] , we have for any @xmath103 : @xmath423 the set @xmath424 is a compact , and theorem  [ lemma3 ] now ensures that @xmath425 and eventually , theorem  [ thm : limit ] ensures that the righthand side of the inequality is strictly negative , which implies that @xmath426 that is : @xmath427    based on this result , we can further conclude on the following :    [ thm : propagationofchaos ] the system enjoys the propagation of chaos property .",
    "in other terms , @xmath428 $ ] is @xmath97-chaotic , i.e. for any bounded continuous functions @xmath429 and any neuron indexes @xmath430 , we have : @xmath431    this is a direct consequence theorem  [ thm : convergence ] , thanks to a result due to alain - sol sznitman , see  ( * ? ? ?",
    "* lemma 3.1 ) .",
    "all these results can be readily confirmed by numerical simulations of the network equations .",
    "considering for instance a two - populations network with parameters given in section  [ sec:2popsoscill ] , we simulated a network of @xmath432 neurons ( @xmath433 in each population ) and considered the distribution of the values of the membrane potentials as a statistical sample . the empirical distribution , superimposed with the theoretical gaussian distribution , is plotted in figure fig .",
    "[ fig : statistics ] and shows a very clear fit , which we confirmed using the kolmogorov - smirnov test . for each population",
    ", the kolmogorov - smirnov test comparing the sample obtained by numerical simulations with the predicted gaussian distribution ensures that the sample has indeed the gaussian distribution , with a p - value equal to @xmath35 .",
    "moreover , we used a chi - square test of independence which validates the independence between the two populations and this independence test was validated with a p - value of @xmath434 .     with common heterogeneity parameter @xmath435 and noise @xmath436 ) . ]",
    "in this section , we analyze the obtained limit equations to analyze the qualitative macroscopic behavior of networks , with a particular focus on the effect of the disorder parameters .",
    "the first step of this analysis consists in confronting our results with the seminal study of sompolinsky , crisanti and sommers ( scs )  @xcite dealing with one population model with centered coefficients , centered sigmoidal functions @xmath437 and no delays .",
    "we will then discuss the persistence of the phase transition they identified when the assumptions on the parameters ( non - centered synaptic weights or sigmoids , delays , multiple populations  ) are relaxed . a particularly important phenomenon in neuroscience essentially absent of their initial study , synchronized oscillations ,",
    "will be an important focus of the present section .",
    "let us eventually note that the results of scs hold for zero - noise limits ( @xmath438 ) .",
    "we will also sometimes consider this limit equations , even if rigorously , the proofs of section  [ sec : benarous ] hold for non - trivial noise .",
    "these non - noisy regimes correspond to limits of the mean - field equations where @xmath439 , and correspond to a sort of viscosity solution of the system : all the properties of convergence , existence and uniqueness of solution hold for arbitrarily small @xmath18 and provide solutions that have a limit when @xmath439 .      in their article , sompolinsky , crisanti and sommers ( scs )",
    "introduce a set of equations governing the dynamics of covariance of possible stationary solutions to the mean - field equations .",
    "these equations are used to analyze the dynamics of the limit process and in particular to show a striking transition between stationary and chaotic solutions .",
    "we derive here a generalized equation of the type of the scs equations in our framework with multiple populations and delays , and use these equations to explore the boundaries of the scs phase transition when considering different models .    [ pro : stationaryequations ] possible stationary solutions are gaussian with mean @xmath440 and covariance @xmath441 for any @xmath442 .",
    "these two variables satisfy the system of equations : @xmath443    note that the above equations do not constitute a dynamical system , but rather correspond to implicit equations . in particular , an important difficulty is the choice of the initial condition @xmath444 which corresponds to the variance of the stationary solution , which is obviously unknown .",
    "this quantity parametrizes both the equation on the first moment and the form of the term @xmath445 on the second moment equations .",
    "the equation on the mean @xmath440 is a simple rewriting of equation   under stationarity condition .",
    "the equation on the stationary covariance requires more care . for arbitrary time @xmath446 ,",
    "denoting @xmath447 the solution of the mean - field equation with for all @xmath12 , @xmath438 , we have , using equation  : @xmath448}\\\\          \\label{eq : sompofirststep } & = -\\frac{c^{\\alpha}(\\zeta)}{\\theta_{\\alpha } } + { \\mathbbm{e}}{[\\bar{x}^{\\alpha}(t ) { u}^{\\alpha , \\bar{x}}(t+\\zeta)]}.      \\end{aligned}\\ ] ] the second term is not easy to characterize .",
    "the method used by sompolinsky and collaborators to deal with this term is to derive a second time with respect to @xmath449 .",
    "however , the differential of @xmath450 is unknown .",
    "fortunately , we can express this term as a function of @xmath451 $ ] .",
    "this function is way easier to handle since using the differential equation   and differentiating this expression with respect to @xmath187 , one obtains : @xmath452 where we denoted with a slight abuse of notations @xmath453 the common value of @xmath454 for any @xmath455 using the assumed stationarity of the solution .    in order to relate the second term of the righthand side of   with @xmath456 , we compute @xmath457 expressing it the differential with respect to @xmath187 of @xmath458 $ ] . in this computation ,",
    "most of the terms cancel out and we obtain the simple expression at @xmath459 : @xmath460 } - \\delta^{\\alpha}(\\zeta).\\ ] ] plugging this expression into   we obtain : @xmath461 differentiating this expression with respect to @xmath449 and reinjecting the latter equation in the obtained expression , we get : @xmath462    this equation is very similar to the original scs equation . as they remarked , this equation does not characterize the process . indeed , we know that @xmath463 using the fact that the covariance is even , but the initial condition @xmath444 is not fixed : it is the asymptotic stationary variance of the process , when it exists , and this initial condition is a parameter of both the stationary mean equation and stationary covariance equation . let us emphasize also the that it does not involve the average of the synaptic coefficients @xmath464 , and that the function @xmath465 is a nonlinear function of @xmath466 and @xmath467 which can be written as : @xmath468}\\\\          & = \\int_{{\\mathbbm{r}}^2 } s_{\\alpha\\beta}\\left(\\sqrt{\\frac{\\bar{c}^{\\beta}(0)^2-\\bar{c}^{\\beta}(\\zeta)^2}{\\bar{c}^{\\beta}(0 ) } } x + \\frac{\\bar{c}^{\\beta}(\\zeta)}{\\sqrt{\\bar{c}^{\\beta}(0 ) } } y + \\bar{\\mu}^{\\beta}\\right ) \\quad s_{\\alpha\\beta}\\left(\\sqrt{\\bar{c}^{\\beta}(\\zeta)}y + \\bar{\\mu}^{\\beta}\\right ) dx\\,dy      \\end{aligned}\\ ] ] where @xmath469 and @xmath470 are the probability measure of standard gaussian random variables ( @xmath471 and similarly for @xmath472 ) .",
    "the linear term has a positive sign , hallmark of diverging systems . and",
    "indeed , the solution can be formally written as : @xmath473 in that equation , the term in hyperbolic cosine diverges very fast , and the nonlinear term can overcome the divergence .",
    "when one does not consider the precise initial condition corresponding to stationary solutions , the solutions of the second order ode in @xmath474 diverge very fast , as remarked by sompolinsky and colleagues in  @xcite , and therefore one needs to analyze the stability of the possible solutions , which is relatively complex to perform .",
    "numerical simulations of the system are very intricate as well , because of the time - consuming calculation of of the nonlinear function @xmath475 and because of the possible divergence of the solutions .",
    "however , sompolinsky and collaborators show very elegantly an important phase transition taking place in this system , analyzing the shape of the potential together with a stability analysis of the solutions . we revisit their results in our more general framework , first in one population systems , and then in higher dimensional systems , and",
    "particularly focus on the effects of delays , non - zero mean connectivity and non - centered sigmoids .",
    "the heterogeneity level appears as a parameter in  . in their one - population setting ,",
    "equation   can be written the equation of the position of a particle submitted to a force deriving from a potential @xmath476 ( the label @xmath35 denotes the number of populations ) which is equal to @xmath477 where @xmath478 is a primitive of @xmath475 considered as a function of @xmath300 .",
    "the shape of the potential showing a transition from convex to double - well as @xmath74 is increased allowed the authors to conclude on a phase transition between a stationary solution where   has a unique equilibrium equal to zero and a chaotic regime where the covariance is non - zero .",
    "the value of the noise at this transition corresponds to @xmath479 .",
    "let us start by a one - population network with no delays and @xmath480 . in that case , it is easy to see that fixed point with mean @xmath481 is stable if and only if @xmath482 .",
    "when letting @xmath74 fixed and increasing @xmath483 , we can see that at @xmath484 , the system undergoes a pitchfork bifurcation , and two new equilibria @xmath485 and @xmath486 appear , which are stable . for these equilibria , the null covariance is no more a solution to the equations , and we observe a stationary behavior of neurons with a non - zero standard deviation , i.e. a dispersion of the individual trajectories , that remain stationary . at these points ,",
    "the system undergoes also a phase transition from stationary to chaotic activity when the heterogeneity coefficient crosses the critical value @xmath487 .",
    "this equation is an implicit equation since the righthand side depends on @xmath74 through the stationary variance of the process .",
    "let us denote by @xmath488 the stationary standard deviation @xmath489 .",
    "it is clear that @xmath488 is an increasing function of @xmath74 , and to fix ideas , let us consider that the sigmoid used is an erf function @xmath490 . then it is easy to show using a change of variables ( see  @xcite ) that @xmath491 and therefore the pitchfork bifurcation arises along the parameter curve @xmath492 , and the phase transition from stationary to chaotic behavior along the curve @xmath493 . since the differential of @xmath437 takes its maximum at @xmath33 and decreases to zero at @xmath494 , the value of @xmath74 corresponding to the secondary phase transition to chaos is an increasing function of @xmath74 .",
    "moreover , in that case , the chaotic activity will be no more centered around zero but around the new fixed point @xmath495 .",
    "eventually , it is interesting to note that for @xmath483 smaller than the value corresponding to the pitchfork bifurcation , the stationary covariance @xmath488 precisely equal to zero . a hand - drawn bifurcation diagram reflecting this behavior , together with simulations of the trajectories ,",
    "is plotted in figure fig .",
    "[ fig : onepopulationj ] .    ) and two chaotic regions ( pink : centered around zero and orange : centered around @xmath495 ) .",
    "the boundaries of these regions are : a pitchfork bifurcation ( blue curve ) separating the stationary or chaotic regions centered on @xmath33 to the ones centered on @xmath495 , and a generalized scs phase transition ( red curve ) separating the stationary and chaotic regimes .",
    "the subfigures ( a)-(e ) show the time course of @xmath496 arbitrarily chosen neurons in the network corresponding to the points a - e of the diagram : @xmath497 , @xmath498 , ( a ) : @xmath499 , @xmath500 , ( b ) : @xmath499 , @xmath501 , ( c ) : @xmath502 , @xmath501 , ( d ) : @xmath502 , @xmath503 , ( e ) : @xmath502 , @xmath504 . ]",
    "we now consider a one - population network with delays . without loss of generality",
    ", we consider that the time constant is equal to @xmath35 .",
    "the solutions of the mean - field equations with no heterogeneity are gaussian processes whose moments reduce to a dynamical system : @xmath505 and hence the variance converges towards @xmath506 . to fix ideas , we consider @xmath507 , so that @xmath508 . since for any @xmath509 , @xmath510",
    ", the null mean is a stationary solution of the equation .",
    "its stability depends on the roots of the characteristic equation ( or dispersion relationship ) : @xmath511",
    "if all characteristic roots have negative real part , the fixed point @xmath481 is stable . as a function of the parameters of the system",
    ", characteristic roots can cross the imaginary axis and yield a destabilization of the fixed point .",
    "turing - hopf instabilities arise when there exists purely imaginary characteristic roots @xmath512 . in that case , we obtain the following equivalent system : @xmath513 which has real solutions only for @xmath514 .",
    "it is then easy to show that turing - hopf bifurcations arise when the parameters satisfy the relationship : @xmath515 and these correspond to characteristic roots @xmath516 .",
    "these result into oscillations of the solutions at a pulsation equal by @xmath517 .",
    "let us now return to the case of random coefficients with variance @xmath74 and no additive noise @xmath518 .",
    "the mean of the gaussian solution satisfy the same equation as the one studied above with @xmath519 , and as noted in the previous section , the stationary covariance is an increasing function of @xmath74 . for @xmath520 ,",
    "the fixed point @xmath33 is unstable , and the covariance is non - zero .",
    "this implies that for sufficiently large values of the delay , the network displays oscillations .",
    "thanks to the propagation of chaos property , all neurons have the same distribution , which is a gaussian with oscillatory mean , and hence the network displays phase - locked oscillations . eventually , as noise is increased beyond a critical value , a scs phase transition occurs and the system no more displays phase locked oscillations but asynchronous chaotic activity .",
    "this is illustrated in figure fig .",
    "[ fig : delayoscillations ]      in this section , we analyze the dynamics of randomly coupled neuronal networks in the case of the deterministic coupling of several original scs networks , before turning the analysis of the dynamics of a more biologically plausible neuronal network composed of an excitatory and an inhibitory population . as demonstrated by sompolinsky and coworkers in  @xcite ,",
    "the study of the stationary states using equations   is very useful to analyze the dynamics of their networks .",
    "unfortunately , this method does not persists in higher dimensions , since the equation does not necessarily derive from a potential . indeed , in order for the equation to derive from a potential @xmath521 in dimension @xmath5 greater than @xmath35",
    ", we need that for any @xmath522 : @xmath523 the only case where this is possible is the case where @xmath524 for any @xmath525 .",
    "indeed , shall the above relationship be true , the equality @xmath526 directly yields @xmath527 .",
    "the lefthand side is a function of @xmath528 only and the righthand side a function of @xmath529 only , they for @xmath530 these functions are necessarily constant . for regular functions @xmath437 , this necessitates to have @xmath531 .",
    "this is precisely the case of deterministic lateral connections between randomly coupled networks , which will now study .      in this section",
    "we analyze the coupling of different scs networks , called lateral coupling , with deterministic coefficients . the only randomness in the models",
    "is included in the random synaptic coefficients between neurons belonging to the same population . in that particular case ,",
    "equation   derives from the potential @xmath532 , and in that case the analysis driven by sompolinsky and collaborators can be adapted to the multi - dimensional case .",
    "since the potential is now the sum of the individual potentials at each population , we observe a strange phenomenon of localization of chaos in the populations that display a large heterogeneity ( namely , in our notations , when the scs condition @xmath533 is satisfied ) .",
    "only the populations that individually would be in a chaotic state are in a chaotic state , and the other populations converge to zero with a dirac delta covariance at zero , and the input received by such populations from chaotic populations do not perturb this state .",
    "let us for instance illustrate this phenomenon on a two - populations network with parameters : @xmath534 each population receives input from the neurons of the other population , with a constant synaptic weight equal to @xmath535 , and the intra - population synaptic weights are noisy .",
    "further analysis of this networks as a function of the coupling reveals a similar phenomenon as the one described in the one - population network of section  [ sec : onepopnoncentered ] .",
    "indeed , as the strength of the lateral coupling @xmath536 and @xmath537 are increased , additional stationary solutions with non - zero covariance appear .",
    "let us for instance denote by @xmath538 the mean of one of these stationary solutions .",
    "following scs analysis , we are ensured that the behavior of the trajectories of neurons in population @xmath12 around @xmath539 is stationary as long as @xmath540 and chaotic otherwise , and this independently of the behavior of the other population .",
    "this phenomenon is illustrated in figure fig .",
    "[ fig : locchaosnozero ] .",
    "we eventually discuss the effect of heterogeneities in a more biologically plausible neuronal network including one excitatory and one inhibitory population , with strictly positive sigmoidal transforms ( since these functions model the input to firing - rate transformation ) , that tend to zero at @xmath34 and to @xmath35 at @xmath36 .",
    "this system was analyzed in  @xcite .",
    "considering @xmath541 populations , all sigmoids equal to @xmath542 ( yielding @xmath543 ) , all time constants @xmath544 , and the connectivity matrix , inspired from the seminal article of wilson and cowan  @xcite : @xmath545 we showed that the system presents phase transitions as a function of the heterogeneity parameter , between stationary distributions to periodic oscillations ( see figure fig .",
    "[ fig : noiseinducedoscillations ] ) : considering all @xmath546 equal and denoting @xmath74 the common value , we observe that for small heterogeneity parameter @xmath74 , the network converges towards a stationary solution with non - zero mean . for intermediate values of the heterogeneity ,",
    "phase - locked perfectly periodic behaviors appear at the network level , that disappear , as heterogeneity is further increased , through a scs phase transition yielding chaotic activity .",
    "+    this phenomenon relates the level of heterogeneity to the presence of synchronized oscillations in networks , an essential phenomenon , as we discuss in the conclusion .",
    "in this manuscript , we analyzed randomly coupled neuronal networks and derived their limit as the number of neurons tends to infinity . to this purpose",
    ", we showed that the system satisfied a large deviation principle and exhibited the related good rate function .",
    "this approach generalized the work of gerard ben arous and alice guionnet  @xcite developed for spin glasses in three main directions : ( i ) the synaptic weights are not centered , introducing additional , deterministic terms in the coupling , ( ii ) interactions are delayed , which projects the problem into infinite dimensions , and ( iii ) the system is composed of several populations , which was handled showing that empirical measures on each populations simultaneously satisfy a large deviation principle .",
    "the proof is made on a particular model very popular in physics and neurosciences , the wilson and cowan system , which is close of the famous hopfield model , but as mentioned , can be easily generalized to nonlinear neuron models . indeed , most of the proofs deal a quantity which is related to the density of the coupled network with respect to the uncoupled dynamics , and this quantity is independent of the dynamics of individual cells .",
    "our approach can be also readily extended to networks with distributed delays .",
    "eventually , let us note that this result provides large - deviations estimates on the convergence of deterministically coupled networks as studied in  @xcite .    from the neuroscience viewpoint , this approach has the interest to justify an equation which has been widely used in the analysis of large - scale networks , and introduced in the seminal paper of sompolinsky and collaborators  @xcite",
    ". moreover , our setting substantially extends their result by taking into account important features present in cortical networks : interconnection delays , multiple populations with non - zero average synaptic connection .",
    "all these refinements allowed going deeper into the understanding of the dynamics of neuronal networks .",
    "in particular , we showed that delays can induce oscillations in one - populations networks modulated by the level of heterogeneity , and that non - zero average connectivity yields non - trivial dynamics that were not present in the original scs model .",
    "moreover , we showed that networks with multiple populations can show relative counter - intuitive phenomena such as the localization of chaos : a few populations can have a chaotic behavior which is not transmitted to the other populations , whatever the connection strength . another phenomenon we illustrated was the apparition of heterogeneity - induced oscillations , phenomenon first presented in a very recent article  @xcite .",
    "as discussed in that article , the latter phenomenon can be related to experimental studies that showed that the cortex of developing rats subject to absence seizures ( abnormal synchronization of some cortical areas ) was characterized by the same mean synaptic connectivity , but increased dispersion of the synaptic weights  @xcite .",
    "we further showed here that such oscillations were facilitated by the presence of delays .",
    "let us eventually underline that the particular form of our system is not essential in the apparition of such phenomena , and in  @xcite , it is shown that the transition to synchronized activity as a function of heterogeneity levels persists for realistic neuronal networks made of excitable cells , the fitzhugh - nagumo model .",
    "an important observations is that in all the examples treated , the scs phase transition to chaos is present as the heterogeneity is increased .",
    "this phenomenon seems relatively universal in this kind of randomly coupled neuronal networks .",
    "it was very recently related to the topological complexity of the underlying vector field in  @xcite in the original scs framework , and we conjecture that the same phenomenon occurs in our more complex settings .",
    "the analysis of the present manuscript underlines the fact that the structure of connectivity maps is essential to the function of the networks , and illustrated the fact that averaging effects do not cancel the structure into populations and allow serving functions such as oscillations .",
    "however , actual brain connectivity maps are not recurrent , and can display different topologies , with different computational capabilities .",
    "the extension of our methods to such networks is an active part of our future research .",
    "moreover , our analysis did not take into account the plasticity mechanisms , resulting in the slow evolution of the synaptic weights as a function of the activity of neurons , which tends to correlate the synaptic weights to the voltage variables .",
    "techniques to rigorously address the dynamics of neuronal networks with non - recurrent connectivity , with specific topologies , or with correlated synaptic weights , are deep questions that are still largely left unexplored , and we can expect that a wide range of novel phenomena will arise from the analysis of such networks .",
    "before proceeding to the proof of the lemma , let us start by showing an inequality which will be very useful in several steps of the demonstration .",
    "we recall the following well known formula ( see  ( * ? ? ?",
    "* lemma 3.2.13 ) for instance ) : @xmath547",
    "so that , for any bounded measurable function @xmath353 on @xmath77 , we have : @xmath548 the result hold for positive measurable functions by the monotone convergence theorem .",
    "* proof of lemma  [ lemma1].(i ) . *",
    "+ lets prove the lipschitzianity result for @xmath549 .",
    "we have : @xmath550 let @xmath187 be a probability measure on @xmath551 with marginals @xmath188 and @xmath189 , and let @xmath552 be the law of a bidimensional centered gaussian process @xmath553 with covariance @xmath554 : @xmath555 then , @xmath556 by cauchy - schwarz inequality . then , using the covariance of @xmath557 under @xmath552 , we find : @xmath558    moreover , we have : @xmath559 but @xmath560 by cauchy - schwarz inequality . +",
    "consequently : @xmath561 as the @xmath144 are @xmath562 lipschitz , we have : + @xmath563 so that @xmath230 is lipschitz for the vaserstein distance . using the triangle inequality , the result holds for @xmath564 . +",
    "* proof of lemma[lemma1].(ii ) : * + let @xmath565 this function is a.s .",
    "finite but not bounded , let us hence define for @xmath566 @xmath567 by the monotone convergence theorem and using equation  , we have for any @xmath568 : @xmath569 by jensen inequality and fubini theorem , + @xmath570 but , as @xmath343 is a @xmath88-brownian motion , @xmath571.\\\\\\ ] ] so that , @xmath572 letting @xmath573 proves that @xmath574 . + * proof of lemma[lemma1 ] ( iii ) : * + as the components of @xmath154 are independent under @xmath155 , we only have to check that , for every @xmath575 , there exists a finite constant @xmath576 such that + @xmath577 \\leq \\exp{\\frac{b c_b { k_{\\alpha}}t}{{\\lambda_{\\alpha}}^2 } } \\label{ineqa}.\\ ] ] it was proved in  ( * ? ? ? * lemma a.3(2 ) ) in their particular framework that for every @xmath578 verifying @xmath579 , there exists a finite constant @xmath580 such that : @xmath581 in our case , the covariance function is slightly different of that of  @xcite , but the proof and result remain unchanged and can be readily extended .",
    "moreover , since we have @xmath582 we obtain the desired result with the following constant @xmath583 , under the condition @xmath584 .",
    "+ * proof of lemma[lemma1].(iv ) * + as above , lets prove the result for @xmath585 .",
    "we have : latexmath:[\\[\\begin{gathered }     let @xmath187 be a probability measure on @xmath551 with marginals @xmath188 and @xmath189 , and let @xmath552 be the law of a bidimensional centered gaussian process @xmath553 with covariance @xmath554 .",
    "let @xmath587 as in ( * ? ? ?",
    "* lemma 3.4 ) , we can show that : @xmath588 hence , we have by jensen inequality , @xmath589 so that @xmath590 which eventually gives , @xmath591    let @xmath592 , dt)$ ] , with @xmath274 bounded . by cauchy - schwarz and the relative entropy inequality   ( with @xmath593 under @xmath88 , and besides is a positive and measurable function of @xmath77 ) , we have the existence of a finite constant @xmath300 such that , @xmath594 we can now bound the different terms in inequality ( [ ineqgamma2 ] ) .",
    "for all @xmath261 , let @xmath613 the equality between the two expression of @xmath614 is easily obtained by gaussian calculus ( see the proof of proposition  [ pro : dcompositiongamma ] ) .",
    "we deduce by the martingale property of this density that it is a probability measure on @xmath137,{\\mathbbm{r}})$ ] .",
    "hence , according to girsanov theorem , there exists a @xmath624-brownian motion @xmath625 such that : @xmath626 as @xmath627 is an affine function of @xmath625 , it is , under @xmath624 , a gaussian variable with finite moments .",
    "in particular , @xmath628 is finite .",
    "but @xmath629,{\\mathbbm{r } } ) } \\log\\big (   { \\frac{\\text{d } q^{\\alpha , k}_{\\nu}}{\\text{d } { p_{\\alpha } } } } ( x^{\\alpha } ) \\big ) dq^{\\alpha , k}_{\\nu}(x^{\\alpha } ) = \\sum_{\\alpha=1}^m i(q_{\\nu}^{\\alpha , k}|{p_{\\alpha}})\\ ] ] so that @xmath630 is finite .",
    "now , let @xmath631 be a sequence of stopping times for the brownian filtration @xmath632 . as @xmath343 is a @xmath88-mb",
    ", we have @xmath633 almost surely under @xmath88 .",
    "@xmath634 defines a sequence stopping times for @xmath635 which tends to infinity along with @xmath274 @xmath83 a.s .",
    "we define : @xmath636              * proof of lemma[lemma1].(vi ) : * in order to demonstrate that @xmath193 is a good rate function , we need to show that it is lower semi - continuous and that it has compact level sets , i.e. @xmath648 is a compact set for any @xmath649 .",
    "this is a direct consequence of points ( i)-(iv ) proved above .",
    "let @xmath650 writing the definitions of @xmath210 and @xmath651 , we find : @xmath652}{{{\\mathcal{e}}}_{\\nu } \\bigg[\\exp\\bigg\\ { \\int_0^t \\big ( { \\mathbf{g}}_t + { \\mathbf{m}}_{\\nu}(t ) \\big ) ' \\cdot d{\\mathbf{w}}^i_t - \\frac{1}{2 } \\int_0^t \\big\\| { \\mathbf{g}}_t + { \\mathbf{m}}_{\\nu}(t ) \\big\\|^2 dt \\bigg\\ } \\bigg ] } \\bigg)^a d(q_{\\nu})^{\\otimes n}\\ ] ]      @xmath653}{{{\\mathcal{e}}}_{\\xi } \\bigg[\\exp\\bigg\\ { \\int_0^t \\big ( { \\mathbf{g}}_t ' + { \\mathbf{m}}_{\\nu}(t ) \\big)d{\\mathbf{w}}^i_t - \\frac{1}{2 } \\int_0^t \\big\\| { \\mathbf{g}}_t ' + { \\mathbf{m}}_{\\nu}(t ) \\big\\|^2 dt \\bigg\\ } \\bigg ] } \\bigg)^a d(q_{\\nu})^{\\otimes n}\\ ] ]        then @xmath659}{{{\\mathcal{e}}}_{\\xi } \\big[\\exp\\big\\ { y_i ' \\big\\ } \\big ] } \\bigg)^a d(q_{\\nu})^{\\otimes n } \\\\ & = \\int_{\\hat{\\mu}_n \\in b(\\nu,\\delta ) } \\prod_{i=1}^n \\bigg ( { { \\mathcal{e}}}_{\\xi } \\bigg [ \\frac{\\exp{y_i'}}{{{\\mathcal{e}}}_{\\xi } \\big[\\exp{y_i ' } \\big ] } \\exp { \\big ( y_i - y_i ' \\big ) } \\bigg ] \\bigg)^a d(q_{\\nu})^{\\otimes n } \\\\ & \\leq \\int_{\\hat{\\mu}_n \\in b(\\nu,\\delta ) } \\prod_{i=1}^n { { \\mathcal{e}}}_{\\xi } \\bigg [ \\frac{\\exp{y_i'}}{{{\\mathcal{e}}}_{\\xi } \\big[\\exp { y_i ' } \\big ] } \\exp { a \\big ( y_i - y_i ' \\big ) } \\bigg ] d(q_{\\nu})^{\\otimes n } \\\\\\end{aligned}\\ ] ] by jensen inequality . + then , using holder inequality twice with conjugate exponents @xmath283 and @xmath660 , one finds : + @xmath661}{\\big ( { { \\mathcal{e}}}_{\\xi } \\big[\\exp{y_i ' } \\big ] \\big)^p } d(q_{\\nu})^{\\otimes n}}^{b^n_1 } \\bigg\\}^{\\frac{1}{p } } \\bigg\\ { \\overbrace{\\int \\exp\\big\\{n \\sigma \\gamma_{\\nu}(\\hat{\\mu}_n ) \\big\\ } dp^{\\otimes n}}^{b^n_2 } \\bigg\\}^{\\frac{1}{q\\sigma } } \\\\",
    "\\times \\bigg\\ { \\underbrace{\\int_{\\hat{\\mu}_n \\in b(\\nu,\\delta ) } \\prod_{i=1}^n { { \\mathcal{e}}}_{\\xi } \\big [ \\exp { a \\eta q \\big ( y_i -y_i ' \\big ) } \\big ] dp^{\\otimes n}}_{b^n_3 } \\bigg\\}^{\\frac{1}{q\\eta } } \\label{ineqlemma}\\end{gathered}\\ ] ]",
    "we first bound the first term of the right hand side .",
    "let @xmath662 be a probability measure on @xmath168 such that @xmath663 . + according to appendix a of @xcite ( where @xmath664 ) , we have , for any @xmath665 , that @xmath154 is a m - dimensional centered gaussian process under @xmath662 .",
    "+ consequently , using the independence of @xmath654 s components :    @xmath666 & = \\prod_{\\alpha=1}^m \\exp\\bigg\\ { p \\big ( \\int_0^t m_{\\nu}^{\\alpha}(t ) dw^{i_{\\alpha}}_t - \\frac{1}{2 } \\int_0^t { m^{\\alpha}_{\\nu}}^2(t ) dt \\big ) \\bigg\\ } \\ ; { { \\mathcal{e}}}_{\\xi}\\big [ \\exp\\bigg\\{-\\frac{p}{2 } \\int_0^t { { g^{\\alpha}_t}'}^2 dt\\bigg\\ } \\big ] \\\\ & \\times \\int \\exp\\bigg\\ { p\\big(\\int_0^t { g^{\\alpha}_t } ' \\big(dw^{i_{\\alpha}}_t - m_{\\nu}^{\\alpha}(t ) dt\\big ) \\big ) \\bigg\\}d\\gamma_{p,\\widetilde{k}^t_{\\nu}}\\\\ & = \\prod_{\\alpha=1}^m \\exp\\bigg\\ { p \\big ( \\int_0^t m_{\\nu}^{\\alpha}(t ) dw^{i_{\\alpha}}_t - \\frac{1}{2 } \\int_0^t { m^{\\alpha}_{\\nu}}^2(t ) dt \\big ) \\bigg\\ } \\ ; { { \\mathcal{e}}}_{\\xi}\\big [ \\exp\\bigg\\{-\\frac{p}{2 } \\int_0^t { { g^{\\alpha}_t}'}^2 dt\\bigg\\ } \\big ] \\\\ & \\exp\\bigg\\ { \\big ( \\frac{p^2}{2 } \\int   \\big(\\int_0^t g^{\\alpha}_t \\big(dw^{i_{\\alpha}}_t - m_{\\nu}^{\\alpha}(t ) dt\\big ) \\big)^2 \\frac{\\exp{\\left(-\\frac{p}{2}\\int_0^t { g^{\\alpha}_t}^2 dt\\right ) } } { \\int \\exp{\\left(-\\frac{p}{2}\\int_0^t { g^{\\alpha}_t}^2 dt\\right ) } d\\gamma_{\\nu } } d\\gamma_{\\nu } \\big)\\bigg\\}\\\\\\end{aligned}\\ ] ]    hence , @xmath667}{{{\\mathcal{e}}}_{\\xi}\\big [ \\exp{y_i ' } \\big]^p } & = \\prod_{\\alpha=1}^m \\underbrace{\\frac{{{\\mathcal{e}}}_{\\xi}\\big [ \\exp{-\\frac{p}{2 } \\int_0^t { { g^{\\alpha}_t}'}^2 dt } \\big]}{{{\\mathcal{e}}}_{\\xi}\\big [ \\exp{-\\frac{1}{2 } \\int_0^t { { g^{\\alpha}_t}'}^2 dt } \\big]^p}}_{f^{\\alpha}(p ) } \\exp\\bigg\\ { \\frac{p}{2 } \\int   \\big(\\int_0^t g^{\\alpha}_t \\big(dw^{i_{\\alpha}}_t - m_{\\nu}^{\\alpha}(t ) dt\\big ) \\big)^2 \\\\ & \\times \\underbrace{\\big(p\\frac{\\exp{-\\frac{p}{2}\\int_0^t { g^{\\alpha}_t}^2dt } } { \\int \\exp{-\\frac{p}{2}\\int_0^t { g^{\\alpha}_t}^2dt } d\\gamma_{\\nu } } - \\lambda_t(g^{\\alpha } ) \\big)}_{g^{\\alpha}(p ) } d\\gamma_{\\nu }   \\bigg\\}\\end{aligned}\\ ] ]    remark that@xmath668 is bounded for @xmath669 .",
    "in fact , on one hand it is clear that @xmath670\\leq 1,\\ ] ] furthermore jensen inequality and fubini theorem give us : @xmath671 \\geq \\exp\\bigg\\ { - \\frac{p}{2 } \\int_0^t { { \\mathcal{e}}}_{\\nu}\\big [ { g^{\\alpha}_t}^2 \\big ] dt \\bigg\\ } \\geq \\exp\\big\\ { -\\frac{p t { k_{\\alpha}}}{2 { \\lambda_{\\alpha}}^2 } \\big\\}.\\\\\\ ] ] therefore , bounded convergence monotone gives @xmath672 and , similarly , @xmath673 as @xmath674 . moreover , as @xmath675 has finite moments under @xmath676 , we can find a finite constant @xmath677 , @xmath678 as @xmath674 , such that : @xmath679}{\\big ( { { \\mathcal{e}}}_{\\xi } \\big[\\exp { y_i ' } \\big ] \\big)^p } dq_{\\nu}\\bigg)^n \\leq e^ { c_1(p ) n } \\label{t1}\\ ] ] moreover : @xmath680^{\\sigma } dp(x ) \\bigg)^n \\\\ & \\leq \\bigg ( { { \\mathcal{e}}}_{\\nu}\\bigg [ \\int \\exp\\bigg\\ { \\sigma \\int_0^t \\big({\\mathbf{g}}_t + { \\mathbf{m}}_{\\nu}(t)\\big ) ' \\cdot d{\\mathbf{w}}_t(x ) \\bigg\\ } dp(x ) \\ ; \\exp\\bigg\\ { - \\frac{\\sigma}{2 } \\int_0^t \\big\\|{\\mathbf{g}}_t + { \\mathbf{m}}_{\\nu}(t)\\big\\|^2 dt\\bigg\\ } \\bigg ] \\bigg)^n \\\\ & = \\bigg ( { { \\mathcal{e}}}_{\\nu}\\bigg [ \\exp\\bigg\\ { \\frac{\\sigma^2-\\sigma}{2 } \\int_0^t \\big\\|{\\mathbf{g}}_t + { \\mathbf{m}}_{\\nu}(t)\\big\\|^2 dt\\bigg\\ } \\bigg ] \\bigg)^n\\end{aligned}\\ ] ]        we now will bound the last term of the right hand side of ( [ ineqlemma ] ) . by cauchy - schwarz inequality , if @xmath683 : @xmath684 dp^{\\otimes",
    "n } \\bigg\\}^{\\frac{1}{2 } } \\ ! \\bigg\\ { \\ ! \\int_{\\hat{\\mu}_n \\in b(\\nu,\\delta ) } \\ ! { { \\mathcal{e}}}_{\\xi } \\bigg [ \\exp\\big\\ { 2\\kappa^2 \\ ! \\int_0^t \\ !",
    "\\big\\|{\\mathbf{g}}_t \\!- \\ ! { \\mathbf{g}}_t'\\ ! + \\!({\\mathbf{m}}_{\\hat{\\mu}_n } \\ !",
    "- \\!{\\mathbf{m}}_{\\nu})(t)\\big\\|^2 \\!dt\\\\ & - \\kappa \\int_0^t \\big\\|{\\mathbf{g}}_t+{\\mathbf{m}}_{\\hat{\\mu}_n}(t)\\big\\|^2 - \\big\\| { \\mathbf{g}}_t ' + { \\mathbf{m}}_{\\nu}(t)\\big\\|^2 dt \\big\\ } \\bigg]^n dp^{\\otimes n } \\bigg\\}^{\\frac{1}{2}}\\end{aligned}\\ ] ] the first term is the square root of a martingale s expectation , thus equal to one .",
    "for the second term , we remark that : @xmath685 so that , by cauchy - schwarz inequality : @xmath686^n dp^{\\otimes n}\\bigg\\}^{\\frac{1}{4 } } \\\\ & \\times \\bigg\\ { \\int { { \\mathcal{e}}}_{\\xi } \\bigg [ \\exp\\big\\ { \\kappa\\delta^{\\frac{1}{2}}\\int_0^t \\big\\| { \\mathbf{g}}_t+{\\mathbf{g}}_t'+ ( { \\mathbf{m}}_{\\hat{\\mu}_n}+{\\mathbf{m}}_{\\nu})(t)\\big\\|^2 dt \\big\\ } \\bigg]^n dp^{\\otimes n } \\bigg\\}^{\\frac{1}{4 } } \\\\ & \\leq \\exp{\\sum_{\\alpha=1}^n \\big\\{\\frac{1}{2 } ( 4\\kappa^2+\\kappa\\delta^{-\\frac{1}{2}})\\frac{{\\bar{j}_{\\alpha}}^2 k_s^2}{{\\lambda_{\\alpha}}^2}t\\delta^2 + ( 2\\kappa\\delta^{\\frac{1}{2}}t\\frac{{\\bar{j}_{\\alpha}}^2}{{\\lambda_{\\alpha}}^2 } ) \\big\\ } }   \\\\ & \\times \\bigg\\ { \\int { { \\mathcal{e}}}_{\\xi } \\bigg [ \\exp\\big\\ { 2\\big(4\\kappa^2+\\kappa\\delta^{-\\frac{1}{2}}\\big ) \\int_0^t \\big\\|{\\mathbf{g}}_t-{\\mathbf{g}}_t'\\big\\|^2 dt \\big\\ } \\bigg]^n dp^{\\otimes n}\\bigg\\}^{\\frac{1}{4 } } \\\\ & \\times \\bigg\\ { \\int { { \\mathcal{e}}}_{\\xi } \\bigg [ \\exp\\big\\ { 2\\kappa\\delta^{\\frac{1}{2}}\\int_0^t \\big\\|{\\mathbf{g}}_t+{\\mathbf{g}}_t'\\big\\|^2 dt \\big\\ } \\bigg]^n dp^{\\otimes n } \\bigg\\}^{\\frac{1}{4}}\\end{aligned}\\ ] ] as @xmath687 = \\sum_{\\alpha , \\gamma=1}^m \\frac{{\\sigma_{\\alpha \\gamma}}^2 k_s^2}{{\\lambda_{\\alpha}}^2 } \\int_0^t \\int \\big| { s_{\\alpha \\gamma}}(x^{\\gamma}_{t-{\\tau_{\\alpha \\gamma } } } ) - { s_{\\alpha \\gamma}}(y^{\\gamma}_{t-{\\tau_{\\alpha \\gamma}}})\\big|^2 d\\xi(x , y ) dt \\leq \\sum_{\\alpha , \\gamma=1}^m \\frac{{\\sigma_{\\alpha \\gamma}}^2 t}{{\\lambda_{\\alpha}}^2 } \\delta^2 $ ] ( in fact , @xmath688 , we can use appendix a , lemma 3.2 of @xcite to bound the two last term of the previous inequality : there exists two finite constants @xmath689 and @xmath690 such that , @xmath691 \\leq \\exp\\big\\ { 4\\big(4\\kappa^2+\\kappa\\delta^{-\\frac{1}{2}}\\big ) c^{\\kappa}_1(\\delta ) c_t \\delta^2 \\big\\}\\ ] ] @xmath692 \\leq \\exp{\\big\\ { 4\\kappa\\delta^{\\frac{1}{2 } } c^{\\kappa}_2(\\delta ) \\sum_{\\alpha=1}^m \\frac{4{k_{\\alpha}}t}{{\\lambda_{\\alpha}}^2 } \\big\\ } } \\ ] ]"
  ],
  "abstract_text": [
    "<S> we analyze the macroscopic behavior of multi - populations randomly connected neural networks with interaction delays . similar to cases occurring in spin glasses , </S>",
    "<S> we show that the sequences of empirical measures satisfy a large deviation principle , and converge towards a self - consistent non - markovian process . </S>",
    "<S> the proof differs in that we are working in infinite - dimensional spaces ( interaction delays ) , non - centered interactions and multiple cell types . </S>",
    "<S> the limit equation is qualitatively analyzed , and we identify a number of phase transitions in such systems upon changes in delays , connectivity patterns and dispersion , particularly focusing on the emergence of non - equilibrium states involving synchronized oscillations .    ' '' ''    ' '' '' </S>"
  ]
}