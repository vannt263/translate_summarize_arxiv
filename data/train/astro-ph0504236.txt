{
  "article_text": [
    "one of the greatest advances of modern experimental astrophysics is the automation of photometric surveys , which allow massive amounts of data to be gathered systematically , efficiently and with the minimum need for human intervention .",
    "such surveys scour large regions of the sky , carefully searching for a wide variety of rare objects and phenomena such as microlensing events ( surveys like ogle , macho and eros ) , gamma - ray burst optical counterparts ( rotse ) , extra - solar planetary transits ( superwasp ) and near - earth objects ( neat ) .",
    "these surveys have provided the scientific community with invaluable information and resulted in many new discoveries , yet they have also left us with a new ( and very welcome ) problem : how can we sort through the vast data catalogues to reliably filter out objects of interest",
    "?    the raw data produced by these surveys are simply collections of the lightcurves of the objects found in the survey s field of detection .",
    "transient objects hold particular interest for a long list of fields , including cosmology ( sne ia ) , single and binary stellar evolution ( sne and cataclysmic variables , respectively ) , and dark matter studies ( microlensing ) .",
    "they are generally rare and have short lifetimes , so must be identified and studied quickly .",
    "the sheer size of such datasets means that such transient objects are inevitably present in the catalogues ; however there is still a pressing need to detect objects swiftly and reliably for further study or follow - up .",
    "a number of researchers have argued that neural networks may provide a viable solution to this problem @xcite .",
    "neural networks have already been proven to be useful pattern - recognition tools in astrophysical applications such as galaxy @xcite and stellar spectra @xcite classification .",
    "they are highly adaptable , easy and quick to use , but perhaps their most relevant asset in this application is their ability to attach a probability to their classification of an object , thus allowing the user to prioritise their further study .    the contribution of this paper is to provide working neural networks for the detection of classical novae ( cne ) .",
    "these are close interacting binary stars , consisting of a white dwarf primary and a cool red dwarf secondary .",
    "the secondary star overflows its roche lobe and loses mass to the primary .",
    "very occasionally , runaway thermonuclear burning of the degenerate layer of hydrogen accreted by the white dwarf can cause a nova outburst .",
    "the nova s brightness rises rapidly to an absolute magnitude of between @xmath1 and @xmath2 before slowly fading back to quiescence .",
    "much remains unknown concerning the abundance and distribution of nova in galaxies due to the lack of systematic surveys .",
    "so , there is a need for fully automated , and less subjective , selection of candidate cne so that more soundly based conclusions concerning the nova rate and distributions can be drawn .",
    "@xcite have already devised one possible systematic algorithm . here",
    ", we provide an alternative to the method of darnley et al . using a novel application of neural networks .",
    "the paper is organised as follows . in  2 ,",
    "the dataset through which we search for cne lightcurves is described .",
    "this is derived from the point - agape microlensing experiment towards m31 .",
    "although the primary aim of this experiment is to find microlensing events , the dataset of varying lightcurves is a rich resource for the study of variable stars towards m31 @xcite .",
    " 3 discusses the properties of nova lightcurves and summarises previous work to find cne in m31 .",
    "next ,  4 provides a short introduction to neural networks for the astronomical user .",
    " 5 describes the pre - processing and the architecture of neural networks to identify cne , while  6 describes the computations .",
    "the nova catalogue obtained by the networks is presented in  7 .",
    "the data used in this paper was gathered by the point - agape collaboration working with the wide field camera ( wfc ) mounted on the 2.5 m isaac newton telescope ( int ) on la palma .",
    "the collaboration took images of the andromeda galaxy ( m31 ) over the course of three observing seasons ( 1999 - 2001 ) , searching for evidence of microlensing events @xcite . for one hour of each observing night",
    ", the wfc was used to take images of m31 over two fields , to the north and south of m31 s central bulge , with each field - image formed using the four 4100@xmath32048 ccds that make up the wfc ( see figure 1 of @xcite ) .",
    "the raw data produced by the point - agape collaboration then consisted of light curves generated from the flux gathered in three pass - bands by individual pixels in each field - image .",
    "the pass - bands used were denoted _",
    "g _ , _ r _ and _ i _ , and are similar to those used by the sloan digital sky survey .",
    "the m31 fields are mainly composed of unresolved stars , and the effects of seeing from epoch to epoch are substantial . in order to build lightcurves , we use the superpixel method to ensure the same fraction of flux falls within the window function , irrespective of seeing @xcite .",
    "this provides superpixel lightcurves ( 7@xmath37 pixels in size ) .",
    "each pixel is @xmath4 on a side , so the @xmath5 superpixel is @xmath6 on a side .",
    "this matches the typically worst seeing at the int site , which is about @xmath7 .",
    "the superpixel lightcurves are then cleaned ( for details , see @xcite and @xcite ) : a mask of the known ccd defects was constructed , together with regions around all resolved stars detected in the reference frame . after masking , 44635 variable superpixel @xmath8 band lightcurves remained , and",
    "this is the catalogue through which we search for nova - like lightcurves .",
    "although the collaboration produced a very large amount of data and thus greatly increased the chances of discovering new objects , there are two complicating factors which slightly reduce the data s quality and ease of analysis .",
    "first , the observations were carried out over the course of three seasons .",
    "these seasons correspond to the periods in which m31 was visible from the northern hemisphere , and mean that the lightcurves are sampled in runs of @xmath9150 days , with @xmath9200-day gaps ( see figure [ m31nova ] for an illustration of the sampling ) .",
    "three other factors , the limited mounting of the wfc , the limited scheduled observing time on the int and the weather , result in the sampled runs consisting of well - sampled periods typically lasting 1 - 2 weeks , separated by very poorly - sampled periods lasting 1 - 3 weeks .",
    "secondly , the large distance of m31 means that in most cases single stars are not resolved by the int .",
    "this means that the superpixel lightcurves almost always consist of flux produced by more than one star , which could result in very exotic lightcurves , hence limiting our ability to classify objects .",
    "in classical novae , the cool red dwarf secondary overflows its roche lobe and loses mass to the primary white dwarf .",
    "this mass builds up in an accretion disc before falling onto the surface of the white dwarf ( see e.g. , bode & evans 1989 ) . the main feature of nova lightcurves is a single outburst , typically increasing the absolute magnitude of the nova to between -6 and -9 before slowly ( compared to the initial rise ) fading back to the quiescent state .",
    "these classical nova outbursts are caused by the runaway thermonuclear burning of the degenerate layer of hydrogen accreted by the white dwarf .",
    "once a critical amount of hydrogen has been accreted , it begins to burn via the cno cycle , precipitating thermonuclear runaway and resulting in the ejection of the accreted layer on the white dwarf surface .",
    "this explosion and ejection are accompanied by an intense brightening , followed by a gradual decay back to quiescence .",
    "the progress of the nova outburst depends on several parameters , including the mass accretion rate from the secondary , and the temperature and mass of the white dwarf ( e.g. , prialnik & kovetz 1995 ) .",
    "the outbursts therefore vary from system to system , as shown by the rich viety of cne lightcurves in sterken & jaschek ( 1996 ) .",
    "however , it is possible to divide novae into speed classes according to the time ( @xmath10 ) taken to decline by two magnitudes from maximum light , the two main classes being fast ( @xmath11 days ) and slow ( @xmath12 days ) novae ( e.g. , payne - gaposchkin 1957 ) .",
    "fast novae rise rapidly to maximum light , taking 1 to 2 days , and generally have relatively smooth initial decays with only small fluctuations in their early light curves .",
    "slow novae on the other hand can take much longer to reach maximum light and usually have more erratic lightcurve decays , with strong fluctuations capable of producing secondary maxima of varying strengths during initial decline .",
    "furthermore , the maximum absolute magnitudes of classical novae are correlated to the rate of their decline , which coupled with their high luminosities makes classical novae potentially important standard candles @xcite .",
    "figure [ m31nova ] shows the lightcurves of a slow and fast nova respectively , as previously found in m31 .",
    "the lightcurves of classical novae share many features with the lightcurve peaks of dwarf novae and recurrent novae .",
    "the main distinguishing feature in the lightcurves of these objects is that dwarf and recurrent novae undergo repeated outbursts .",
    "however , the periods between outbursts and the gaps in the point - agape sampling could lead to only one peak of a dwarf or recurrent nova lightcurve being sampled .",
    "hence , we may pick up some stray dwarf or recurrent novae in our final catalogue .",
    "dwarf nova outbursts are not be detectable in m31 .",
    "however , they may be present in the point - agape catalogue as foreground objects , though even this has a very low probability",
    ".    dedicated nova searches of m31 have been carried out ever since hubble first did so in 1929 ( see table 1 of @xcite for a list of papers ) .",
    "very recently , @xcite and @xcite have published cne lightcurves from the point - agape catalogue .",
    "@xcite used a pipeline ( see table 3 in their paper ) to filter out novae independently of any prior knowledge .",
    "this pipeline first selected only objects ( defined to be resolved structures with fluxes significantly higher than the local median ) present in five consecutive observations , to remove rapid variations .",
    "the catalogue was further pruned by selecting against periodicity , requiring an adequately - sampled primary peak and also requiring any secondary peak to be an acceptable size .",
    "the remaining candidates were finally required to fit data , rate of decline , colour and colour - magnitude criteria before being accepted as nova candidates .",
    "@xcite were primarily interested in the cataloguing of the variable stars in the point - agape dataset .",
    "they first constructed a catalogue of variable objects by selecting only ( suitably cleaned , masked , etc . )",
    "superpixel lightcurves with deviations from their baseline significant enough in size and duration .",
    "novae were then located by looking for variable objects matching ( within a 3@xmath13 error - circle ) the positions of novae as published in _",
    "iau circulars_. using these methods , @xcite gave 20 novae and @xcite 12 novae lightcurves , with 7 novae common to both papers .",
    "this section is intended as a brief introduction to the basics of neural network structure and use as they apply to this paper ( for more details , consult @xcite and @xcite ) .",
    "neural networks are pattern - recognition tools composed of neurons ( or units ) arranged in layers .",
    "neurons come in three types : input , hidden and output .",
    "the structure of the networks used in this paper is one layer of input units , one layer of hidden units and one layer of output units .",
    "the neurons in neighbouring layers are fully connected with each other , and these connections have assigned to them adaptive weights which are used to calculate the response of a specific neuron to its inputs .",
    "the input data are taken as the values of the input units , and the value of each hidden unit is then given by the sum over all connections of the activation value on each input unit , weighted by the weight on the connection .",
    "these activation values are calculated using an activation function acting on the value of the unit .",
    "the values of the output units are calculated in a similar fashion , except the sum is performed over all connections between the output unit in question and the hidden units . in this paper , the activation function is chosen to be the logistic function , which allows the outputs to be interpreted as _ a posteriori _ probabilities .",
    "before all this can happen , the network must be trained in order to determine the weights .",
    "the weights are initially randomised , and the network is presented with a training set , made up of sets of input values ( called patterns ) for which the desired outputs are known .",
    "the outputs produced by the randomly - weighted net are compared to the desired values , and the network performance on all patterns is quantified using an error function , namely the cross - entropy error @xcite .",
    "a learning function then uses these errors in conjunction with the values of the hidden units and the hidden - to - output layer weights in order to update the weights and hence reduce the output errors .",
    "the errors are also propagated back up to the input - to - hidden layer weights so as to update these weights with the same goal in mind .",
    "this whole process , called back - propagation , is carried out a number of times ( called epochs ) until the desired network performance is reached . with most choices of learning function ,",
    "it is possible for the network to become over - trained on the training set , with the result that performance on a more general set of inputs is reduced . in this",
    "a paper , a special learning function ( see  [ sub : netdet ] ) is used to avoid this problem .",
    "the process behind training neural networks is the minimisation of the error function ( as applied to the training set ) with respect to the adaptive weights within the network .",
    "this error function may not have just a global minimum in the multi - dimensional weight - space , but could have a number of local minima instead or as well . in any case , networks trained using the exact same training set for the same number of epochs , but using different initial weights ( and therefore different starting points in this space ) , will converge to slightly different final weights . in the case of multiple minima",
    ", this means that networks can follow different error - minimisation paths into entirely separate minima , some of which might classify the general set ( as opposed to the training set ) much better than others .",
    "we can turn this fact to our advantage by using network committees ( see @xcite ,  9.6 and  10.7 ) , produced by training groups of networks on the same training set but with initial weights randomly chosen from a range of values .",
    "these networks therefore sample a region ( rather than a point ) of the weight - space around the error function minimum / a , and hence produce a range of results when classifying the final test set .",
    "the results can then be averaged out over the committee to take account of a whole range of network ` opinions ' , making sure poor quality networks stuck in high - error minima do nt overly affect the results .",
    "the ideal training set should contain examples of all forms of stellar variability we expect the networks to encounter , along with as many examples of nova lightcurves as possible .",
    "the usual process is to build the training set from a comprehensive selection of example nova and variable star lightcurves taken from existing data catalogues .",
    "we do not do this for two reasons .",
    "first , there are not enough well - sampled nova lightcurves in the @xmath14 , @xmath8 and @xmath15 bands in the standard catalogues for our purposes .",
    "therefore , we are obliged to simulate nova lightcurves from templates .",
    "second , all of the other forms of variability needed for the training set are already present in the point - agape catalogue , and we can therefore use the data set itself to provide the non - nova examples required to build the training set , using a variation on a technique called @xmath0-fold cross - validation ( see below and @xcite  9.8.1 ) .    in @xmath0-fold cross - validation , the data set is first partitioned into @xmath0 separate segments .",
    "a network is then trained using a training set containing all of the data from @xmath16 segments , before being tested on the remaining segment .",
    "this process is then repeated , each time choosing a different segment to be left out of the training set , until all @xmath0 choices for the omitted segment have been covered .",
    "the test errors are then averaged out over all @xmath0 results to create a much more robust estimate of the network performance , hence providing one of the two main advantages of using this technique .",
    "the second advantage is that all of the examples in the data set are used in both training and testing , in effect creating a large training set without the need for any ` external ' data .",
    "the major disadvantages are that the training process must be repeated @xmath0 times , and that some or all of the training sets will contain nova - type lightcurves present in the catalogue falsely identified as non - nova objects .",
    "we therefore use a new variation on the technique , training networks using just one data segment before testing the networks on the remaining @xmath16 segments .",
    "we believe this is advantageous as it reduces both processing time and the risk of training set contamination , whilst still retaining the benefits of normal @xmath0-fold cross - validation .",
    "the final form for the training set is 1000 simulated nova light curves , assigned desired output probabilities of 1 , and 1000 randomly - chosen point - agape lightcurves , with desired output probability 0 .",
    "the decision to use exactly 1000 point - agape lightcurves is a compromise : 1000 point - agape lightcurves should include a sufficient cross - section of the forms of variability whilst greatly reducing individual training times and keeping the number of falsely - classified nova examples down to o(1 ) per training set.40,000 lightcurves in the catalogue , with o(20 ) true nova examples present . hence choosing 1000 point - agape examples per training set gives @xmath90.5 false nova - type lightcurves per set . ]",
    "the main drawback to using 1000 point - agape lightcurves is that the training process must be repeated @xmath17 times , and is therefore quite slow .",
    "the number of nova examples is chosen to overwhelm any falsely - classified novae and also to create networks biased towards producing false positives rather than false negatives .",
    "over - representing the novae ( as compared to their natural frequency ) in the training set increases the prior probability of finding a nova in the set , and hence training using such sets produces networks that are much more likely to misclassify non - novae as novae than vice - versa ( see  [ sub : decbound ] ) .",
    "this is exactly the trend required considering that we are trying to locate a very rare phenomenon .",
    "of course , the drawback to permitting more false positives than false negatives is that an additional algorithm may be needed after the neural network search to root out the contaminants .",
    ".@xcite and @xcite identification numbers of the template novae , along with estimates of decay time . [ cols=\"^,^,^ \" , ]      the nova catalogue also contains 19 lightcurves which , upon inspection , are either recognisable as novae or exhibit some nova characteristics , and hence can be classified as candidates for newly discovered novae . the ids , location and probabilities of these 19 candidates are listed in table  [ newnovtab ] , while their lightcurves are displayed in figure  [ new ] .",
    "the candidates can be roughly separated into four groups according to which nova features they exhibit .",
    "the first group consists of 1430 , 42808 , 50177 and 74935 .",
    "their lightcurves contain most or all of the desired features , and hence make excellent nova candidates .",
    "the second group have lightcurves where only the first few measurements of a rise towards a peak are present ( ids 58826 , 66538 , 73732 , 80951 and 92933 ) , with no sampling of the decay .",
    "the third group have lightcurves with samples present which suggest some form of decay from a peak , but no measurements of the rise or peak itself ( ids 2973 , 86283 , 88205 , 89701 , 93095 and 95935 ) .",
    "the fourth group have lightcurves which feature prominent , sharp peaks but not much clear evidence for the characteristic nova rise or decay ( ids 6251 , 39995 , 42075 and 86234 ) , and which could therefore be very fast novae or simply instrumental defects .",
    "it is difficult to say for certain that objects in these three groups are novae without more data .",
    "the locations of the 19 candidates in table  [ newnovtab ] , together with the 9 candidates in table  [ main_results ] are shown in figure  [ loc ] , superposed on the optical isophotes of m31 .",
    "these are all the candidates with a network probability @xmath18 .",
    "the difference images of all 19 candidates have been examined and the psfs constructed .",
    "if the psf is not roundish with a size controlled by the seeing , then this suggests that the candidates may be fakes .",
    "performing this test yields the result that perhaps 10 of the candidates are spurious ( 2973 , 6251 , 39995 , 42075 , 86234 , 86283 , 88205 , 89701 , 93095 and 95935 ) .",
    "finally , the nova catalogue also contains 19 contaminants that appear to be true variable objects , and are primarily made up of the lightcurves of superpixels covering periodic stars such as miras and cepheids , although many lightcurves exhibit some other superposed form of variability .",
    "this paper has presented working neural networks for the identification of fast cne . the use of @xmath0-fold cross - validation and the choice of pre - processing techniques ( i.e. reducing the lightcurve to a suitably binned and normalised power spectrum ) _ has _ produced a set of neural networks capable of detecting the fast classical nova present in the point - agape survey . this conclusion is borne out by the consistently high nova probabilities assigned to the previously - identified novae with @xmath19 days , the detection of 4 strong new nova candidates in the point - agape catalogue and a further 15 possible candidates .",
    "this adds further weight to the claims by a number of authors @xcite that neural networks offer a promising solution to the problem of lightcurve identification in massive variability surveys .",
    "the variation of @xmath0-fold cross - validation used in this paper is new and particularly well - adapted to the search for rare objects in a large dataset .",
    "usually , in @xmath0-fold cross - validation , the data set is first partitioned into @xmath0 separate sets .",
    "a network is then trained using a training set containing all of the data from @xmath16 segments , and tested on the remaining data .",
    "our variation on this technique is to train the networks using just one point - agape data segment before testing the networks on the remaining @xmath16 segments .",
    "this is beneficial as the processing times is substantially reduced . in many circumstances",
    ", there would be a risk of training set contamination using this variation on @xmath0-fold cross - validation .",
    "however , cne are very scarce in the point - agape dataset .",
    "so , the point - agape lightcurves themselves can be used for the non - nova examples in the training set with little risk of contamination .",
    "the nova examples are produced in the training set must be produced with templates .",
    "this method therefore can be used to find any rare lightcurves in a massive variability survey , provided suitable templates exist .",
    "nonetheless , the networks can not be used in their current form to obtain a nova - rate for m31 .",
    "very fast novae are missing because the the point - agape sampling rate is just not good enough to detect them .",
    "as demonstrated by figure [ prob_vs_t ] , the networks also do not detect enough slow , bumpy novae .",
    "furthermore , these novae are more often than not assigned high probabilities , yet these probabilities fall below the classification cutoff because the networks produce too many false positives .",
    "the difficulty here is that artifical templates for slow novae are harder to construct , as they exhibit a greater morphology in the declining part of the curve .",
    "the best way to overcome this is to use known examples of slow cne as part of the training set .",
    "unfortunately , there are very few such lightcurves available in the @xmath14 , @xmath8 and @xmath15 passbands of the point - agape survey .",
    "this however may become possible in the future using transformed colours .",
    "the extension of the networks to slow novae may also require modifications to the pre - processing technique , as the power spectra of slow novae are different ( less sinc - like ) to those of fast novae .    finally , it is worth mentioning the limiting factor for detection of fast nova is actually the temporal sampling of the point - agape dataset .",
    "as fast cn are the brightest cn , they are still easy to detect even against the bright bulge of m31 . although we have not carried out a full efficiency analysis , it is clear that the networks successfully detect the cn types on which the system was trained , up to the limit imposed by the temporal sampling .",
    "vb and ejk are supported by the particle physics and astronomy research council of the united kingdom , while ja is supported by the leverhulme trust .",
    "work by ag is supported by nsfgrant 02 - 01266 .",
    "we thank all the members of the point - agape collaboration for access to their data ."
  ],
  "abstract_text": [
    "<S> the point - agape collaboration surveyed m31 with the primary goal of optical detection of microlensing events , yet its data catalogue is also a prime source of lightcurves of variable and transient objects , including classical novae ( cne ) . </S>",
    "<S> a reliable means of identification , combined with a thorough survey of the variable objects in m31 , provides an excellent opportunity to locate and study an entire galactic population of cne . </S>",
    "<S> this paper presents a set of 440 neural networks , working in 44 committees , designed specifically to identify fast cne . </S>",
    "<S> the networks are developed using training sets consisting of simulated novae and point - agape lightcurves in a novel variation on @xmath0-fold cross - validation , and use the binned , normalised power spectra of the lightcurves as input units . </S>",
    "<S> the networks successfully identify 9 of the 13 previously identified m31 cne within their optimal working range ( and 11 out of 13 if the network error bars are taken into account ) . </S>",
    "<S> the networks provide a catalogue of 19 new candidate fast cne , of which 4 are strongly favoured . </S>"
  ]
}