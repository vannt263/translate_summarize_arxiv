{
  "article_text": [
    "in recent years , a machine learning technique known as explanation - based learning ebl @xcite has successfully been applied to control and speeding - up natural language parsing @xcite .",
    "the core idea of ebl is to transform the derivations ( or _ explanations _ ) computed by a problem solver ( e.g. , a parser ) to some generalized and compact forms , which can be used very efficiently for solving similar problems in the future .",
    "ebl has primarily been used for parsing to automatically specialize a given source grammar to a specific domain . in that case , ebl is used as a method for adapting a general grammar and/or parser to the sub - language defined by a suitable training corpus @xcite .    a specialized grammar can be seen as describing a domain - specific set of prototypical constructions . therefore , the ebl approach is also very interesting for natural language generation ( nlg ) .",
    "informally , nlg is the production of a natural language text from computer - internal representation of information , where nlg can be seen as a complex  potentially cascaded  decision making process .",
    "commonly , a nlg system is decomposed into two major components , viz . the strategic component which decides ` what to say ' and the tactical component which decides ` how to say ' the result of the strategic component .",
    "the input of the tactical component is basically a semantic representation computed by the strategic component .",
    "using a lexicon and a grammar , its main task is the computation of potentially all possible strings associated with a semantic input .",
    "now , in the same sense as ebl is used in parsing as a means to control the range of possible strings as well as their degree of ambiguity , it can also be used for the tactical component to control the range of possible semantic input and their degree of _",
    "paraphrases_.    in this paper , we present a novel method for the automatic extraction of subgrammars for the control and speeding - up of natural language generation .",
    "its main advantage for nlg is that the complexity of the ( linguistically oriented ) decision making process during natural language generation can be vastly reduced , because the ebl method supports adaption of a nlg system to a particular language use .",
    "the core properties of this new method are :    * prototypical occuring grammatical constructions can automatically be extracted ; * generation of these constructions is vastly sped up using simple but efficient mechanisms ; * the new method supports _ partial _ matching , in the sense that new semantic input need not be completely covered by previously trained examples ; * it can easily be integrated with recently developed chart - based generators as described in , e.g. , @xcite .    the method has been completely implemented and tested with a broad - coverage hpsg - based grammar for english ( see sec . [ properties ] for more details ) .",
    "the main focus of this paper is tactical generation , i.e. , the mapping of structures ( usually representing semantic information eventually decorated with some functional features ) to strings using a lexicon and a grammar .",
    "thus stated , we view tactical generation as the inverse process of parsing . informally , ebl can be considered as an intelligent storage unit of example - based generalized parts of the grammatical search space determined via training by the tactical generator .",
    "processing of similar new input is then reduced to simple lookup and matching operations , which _ circumvent _ re - computation of this already known search space .",
    "we concentrate on constraint - based grammar formalism following a sign - based approach considering linguistic objects ( i.e. , words and phrases ) as utterance - meaning associations @xcite .",
    "thus viewed , a grammar is a formal statement of the relation between utterances in a natural language and representations of their meanings in some logical or other artificial language , where such representations are usually called _ logical forms _ @xcite .",
    "the result of the tactical generator is a feature structure ( or a set of such structures in the case of multiple paraphrases ) containing among others the input logical form , the computed string , and a representation of the derivation .    in our current implementation",
    "we are using tdl , a typed feature - based language and inference system for constraint - based grammars .",
    "tdl allows the user to define hierarchically - ordered types consisting of type and feature constraints .",
    "as shown later , a systematic use of type information leads to a very compact representation of the extracted data and supports an elegant but efficient generalization step .",
    "@xmath0 { \\mbox{{{\\sc handel } } } & { { \\it h1\\/ } }   \\\\ }       { \\mbox{{{\\sc index } } } & { { \\it e2\\/ } }   \\\\ }       { \\mbox{{{\\sc liszt } } } & { { \\it { \\mbox{$\\left\\langle { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it sandyrel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h4\\/ } }   \\\\ }                                     { \\mbox{{{\\sc inst } } } & { { \\it x5\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                        { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it giverel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h1\\/ } }   \\\\ }                                          { \\mbox{{{\\sc event } } } & { { \\it e2\\/ } }   \\\\ }                                          { \\mbox{{{\\sc act } } } & { { \\it x5\\/ } }   \\\\ }                                          { \\mbox{{{\\sc preparg } } } & { { \\it x6\\/ } }   \\\\ }                                          { \\mbox{{{\\sc und } } } & { { \\it x7\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                        { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it tempover } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h1\\/ } }   \\\\ }                                        { \\mbox{{{\\sc event } } } & { { \\it e2\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } }   \\right.$ } } ,                        { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it some } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h9\\/ } }   \\\\ }                                    { \\mbox{{{\\sc bv } } } & { { \\it x7\\/ } }   \\\\ }                                    { \\mbox{{{\\sc restr } } } & { { \\it h10\\/ } }   \\\\ }                                    { \\mbox{{{\\sc scope } } } & { { \\it h11\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                          \\/ } }   \\\\ }      { \\mbox{{{\\sc } } } & { { \\it { \\mbox{$\\left . { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it chairrel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h10\\/ } }   \\\\ }                                      { \\mbox{{{\\sc inst } } } & { { \\it x7\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                       { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it to } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h12\\/ } }   \\\\ }                                     { \\mbox{{{\\sc arg } } } & { { \\it v13\\/ } }   \\\\ }                                     { \\mbox{{{\\sc prep } } } & { { \\it x6\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                       { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it kimrel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h14\\/ } }   \\\\ }                                         { \\mbox{{{\\sc inst } } } & { { \\it x6\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } }                       \\right\\rangle$}}\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}\\ ] ]    @xmath0 { \\mbox{{{\\sc liszt } } } & { { \\it { \\mbox{$\\left\\langle { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it sandyrel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h4\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                        { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it giverel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h1\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                        { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it tempover } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h1\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                        { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it some } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h9\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                            \\right.$}}\\/ } }   \\\\ }      { \\mbox{{{\\sc } } } & { { \\it { \\mbox{$\\left . { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it chairrel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h10\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                       { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it to } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h12\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } } ,                       { \\mbox{{\\begin{tabular}{@{}l@ { } }                                          $ \\mbox{\\it kimrel } ^{{\\mbox{\\begin{math }                 \\setlength{\\arraycolsep}{1 mm }                             \\renewcommand{\\arraystretch}{1 }                                  \\hspace*{-0.35em }                  \\left [                              \\begin{array}{@{}l@{~}l@ { } }                                    \\\\[-0.16 in ] { \\mbox{{{\\sc handel } } } & { { \\it h14\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}}$                                   \\end{tabular } } } }                       \\right\\rangle$}}\\/ } }   \\\\ } \\\\[-0.16 in ]                                       \\end{array }                             \\right ] \\hspace*{-0.05em }                             \\end{math}}}\\ ] ]    we are adapting a `` flat '' representation of logical forms as described in @xcite .",
    "this is a minimally structured , but descriptively adequate means to represent semantic information , which allows for various types of under-/overspecification , facilitates generation and the specification of semantic transfer equivalences used for machine translation @xcite . for more details ) . ]",
    "informally , a flat representation is obtained by the use of extra variables which explicitly represent the relationship between the entities of a logical form and scope information . in our current system",
    "we are using the framework called _ minimal recursion semantics _",
    "( mrs ) described in @xcite . using their typed feature structure notation figure [ exam - mrs ] displays a possible mrs of the string `` sandy gives a chair to kim '' ( abbreviated where convenient ) .",
    "the value of the feature liszt is actually treated like a set , i.e. , the relative order of the elements is immaterial .",
    "the feature handel is used to represent scope information , and index plays much the same role as a lambda variable in conventional representations ( for more details see @xcite ) .",
    "the above figure displays the overall architecture of the ebl learning method .",
    "the right - hand part of the diagram shows the linguistic competence base ( lcb ) and the left the ebl - based subgrammar processing component ( sgp ) .",
    "lcb corresponds to the tactical component of a general natural language generation system nlg . in this paper",
    "we assume that the strategic component of the nlg has already computed the mrs representation of the information of an underlying computer program .",
    "sgp consists of a training module tm , an application module am , and the subgrammar , automatically determined by tm and applied by am .",
    "briefly , the flow of control is as follows : during the training phase of the system , a new logical form @xmath1 is given as input to the lcb .",
    "after grammatical processing , the resulting feature structure @xmath2 ( i.e. , a feature structure that contains among others the input mrs , the computed string and a representation of the derivation tree ) is passed to tm .",
    "tm extracts and generalizes the derivation tree of @xmath2 , which we call the template @xmath3 of @xmath2 .",
    "@xmath3 is then stored in a _ decision tree _ , where indices are computed from the mrs found under the root of @xmath3 . during the application phase , a new semantic input @xmath4 is used for the retrieval of the decision tree .",
    "if a candidate template can be found and successfully instantiated , the resulting feature structure @xmath5 constitutes the generation result of @xmath4 .",
    "thus described , the approach seems to facilitate only exact retrieval and matching of a new semantic input .",
    "however , before we describe how _ partial matching _ is realized , we will demonstrate in more detail the exact matching strategy using the example mrs shown in figure [ exam - mrs ] .",
    "[ [ training - phase ] ] training phase + + + + + + + + + + + + + +    the training module tm starts right after the resulting feature structure @xmath6 for the input mrs @xmath1 has been computed . in the first phase ,",
    "tm extracts and generalizes the derivation tree of @xmath6 , called the template of @xmath6 .",
    "each node of the template contains the rule name used in the corresponding derivation step and a generalization of the local mrs . a generalized",
    "mrs is the abstraction of the liszt value of a mrs where each element only contains the ( lexical semantic ) type and handel information ( the handel information is used for directing lexical choice ( see below ) ) .    in our example @xmath1 , figure",
    "[ exam - mrs - g ] displays the generalized mrs @xmath7 . for convenience , we will use the more compact notation :    \\{(sandyrel h4 ) , ( giverel h1 ) , + ( tempover h1 ) , ( some h9 ) , + ( chairrel h10 ) , ( to h12 ) , ( kimrel h14 ) }    using this notation , figure [ dtree ] ( see next page ) displays the template @xmath3 obtained from @xmath6 . note that it memorizes not only the rule application structure of a successful process but also the way the grammar mutually relates the compositional parts of the input mrs .    in the next step of the training module tm",
    ", the generalized mrs @xmath7 information of the root node of @xmath3 is used for building up an index in a decision tree .",
    "remember that the relative order of the elements of a mrs is immaterial .",
    "for that reason , the elements of @xmath7 are alphabetically ordered , so that we can treat it as a sequence when used as a new index in the decision tree .",
    "the alphabetic ordering has two advantages .",
    "firstly , we can store different templates under a common prefix , which allows for efficient storage and retrieval .",
    "secondly , it allows for a simple efficient treatment of mrs as sets during the retrieval phase of the application phase .",
    "[ [ application - phase ] ] application phase + + + + + + + + + + + + + + + + +    the application module am basically performs the following steps :    1 .",
    "retrieval : for a new mrs @xmath4 we first construct the _ alphabetically sorted _ generalized mrs @xmath8 .",
    "@xmath8 is then used as a path description for traversing the decision tree . for reasons we will explain soon ,",
    "traversal is directed by _ type subsumption_. traversal is successful if @xmath8 has been completely processed and if the end node in the decision tree contains a template .",
    "note that because of the alphabetic ordering , the relative order of the elements of new input @xmath4 is immaterial .",
    "expansion : a successfully retrieved template @xmath9 is expanded by _ deterministically _ applying the rules denoted by the non - terminal elements from the top downwards in the order specified by @xmath9",
    ". in some sense , expansion just re - plays the derivation obtained in the past .",
    "this will result in a grammatically fully expanded feature structure , where only lexical specific information is still missing .",
    "but note that through structure sharing the terminal elements will already be constrained by syntactic information .",
    "lexical lookup : from each terminal element of the _ unexpanded _ template @xmath9 the type and handel information is used to select the corresponding element from the input mrs @xmath4 ( note that in general the mrs elements of the @xmath4 are much more constrained than their corresponding elements in the generalized mrs @xmath8 ) . the chosen input mrs element is then used for performing lexical lookup , where lexical elements are indexed by their relation name . in general this will lead to a set of lexical candidates .",
    "lexical instantiation : in the last step of the application phase , the set of selected lexical elements is unified with the constraints of the terminal elements in the order specified by the terminal yield .",
    "we also call this step _ terminal - matching_. in our current system terminal - matching is performed from left to right . since the ordering of the terminal yield",
    "is given by the template , it is also possible to follow other selection strategies , e.g. , a semantic head - driven strategy , which could lead to more efficient terminal - matching , because the head element is supposed to provide selectional restriction information for its dependents .",
    "a template together with its corresponding index describes all sentences of the language that share the same derivation and whose mrs are consistent with that of the index .",
    "furthermore , the index and the mrs of a template together define a normalization for the permutation of the elements of a new input mrs .",
    "the proposed ebl method guarantees _ soundness _ because retaining and applying the original derivation in a template enforces the full constraints of the original grammar .",
    "[ [ achieving - more - generality ] ] achieving more generality + + + + + + + + + + + + + + + + + + + + + + + + +    so far , the application phase will only be able to re - use templates for a semantic input which has the same semantic type information .",
    "however , it is possible to achieve more generality , if we apply a further abstraction step on a generalized mrs .",
    "this is simply achieved by selecting a _ supertype _ of a mrs element instead of the given specialized type .",
    "the type abstraction step is based on the standard assumption that the word - specific lexical semantic types can be grouped into classes representing morpho - syntactic paradigms .",
    "these classes define the upper bounds for the abstraction process . in our current system , these upper bounds are directly used as the supertypes to be considered during the type abstraction step .",
    "more precisely , for each element @xmath10 of a generalized mrs @xmath7 it is checked whether its type @xmath11 is subsumed by an upper bound @xmath12 ( we assume disjoint sets ) . only if this is the case , @xmath12 replaces @xmath11 in @xmath7 . applying this type abstraction strategy on the mrs of figure [ exam - mrs ] , we obtain :    \\{(named h4 ) , ( actundprep h1 ) , + ( tempover h1 ) , ( some h9 ) , + ( regnom h10 ) , ( to h12 ) , ( named h14 ) }    where e.g. , named is the common supertype of sandyrel and kimrel , and actundprep is the supertype of giverel . figure [ dtree2 ] shows the template @xmath13 obtained from @xmath6 using the more general mrs information .",
    "note , that the mrs of the root node is used for building up an index in the decision tree .",
    "now , if retrieval of the decision tree is directed by type subsumption , the same template can be retrieved and potentially instantiated for a wider range of new mrs input , namely for those which are _ type compatible _ wrt .",
    "subsumption relation .",
    "thus , the template @xmath13 can now be used to generate , e.g. , the string `` kim gives a table to peter '' , as well as the string `` noam donates a book to peter '' .",
    "however , it will not be able to generate a sentence like `` a man gives a book to kim '' , since the retrieval phase will already fail . in the next section",
    ", we will show how to overcome even this kind of restriction .",
    "the core idea behind partial matching is that in case an exact match of an input mrs fails we want at least as many subparts as possible to be instantiated .",
    "since the instantiated template of a mrs subpart corresponds to a phrasal sign , we also call it a _ phrasal template_. for example , assuming that the training phase has only to be performed for the example in figure [ exam - mrs ] , then for the mrs of `` a man gives a book to kim '' , a partial match would generate the strings `` a man '' and `` gives a book to kim . ''",
    "the instantiated phrasal templates are then combined by the tactical component to produce larger units ( if possible , see below ) .",
    "[ [ extended - training - phase ] ] extended training phase + + + + + + + + + + + + + + + + + + + + + + +    the training module is adapted as follows : starting from a template @xmath9 obtained for the training example in the manner described above , we extract recursively all possible subtrees @xmath14 also called _",
    "phrasal templates_. next , each phrasal template is inserted in the decision tree in the way described above .",
    "it is possible to direct the subtree extraction process with the application of _ filters _ , which are applied to the whole remaining subtree in each recursive step . by using these filters it is possible to restrict the range of structural properties of candidate phrasal templates ( e.g. ,",
    "extract only saturated nps , or subtrees having at least two daughters , or subtrees which have no immediate recursive structures ) .",
    "these filters serve the same means as the `` chunking criteria '' described in @xcite .    during the training phase",
    "it is recognized for each phrasal template @xmath14 whether the decision tree already contains a path pointing to a previously extracted and already stored phrasal template @xmath15 , such that @xmath16 . in that case , @xmath14 is not inserted and the recursion stops at that branch .    [ [ extended - application - phase ] ] extended application phase + + + + + + + + + + + + + + + + + + + + + + + + + +    for the application module , only the retrieval operation of the decision tree need be adapted .",
    "remember that the input of the retrieval operation is the sorted generalized mrs @xmath7 of the input mrs @xmath1 .",
    "therefore , @xmath7 can be handled like a sequence .",
    "the task of the retrieval operation in the case of a partial match is now to potentially find all subsequences of @xmath7 which lead to a template .    in case of exact matching strategy",
    ", the decision tree must be visited only once for a new input . in the case of partial matching",
    ", however , the decision tree describes only possible _ prefixes _ for a new input .",
    "hence , we have to recursively repeat retrieval of the decision tree as long as the remaining suffix is not empty .",
    "in other words , the decision tree is now a finite representation of an infinite structure , because implicitly , each endpoint of an index bears a pointer to the root of the decision tree .    assuming that the following template / index pairs have been inserted into the decision tree : , , .",
    "then retrieval using the path @xmath17 will return all three templates , retrieval using @xmath18 will return template @xmath19 and @xmath20 , and @xmath21 will only return @xmath19 .",
    "[ [ interleaving - with - normal - processing ] ] interleaving with normal processing + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our ebl method can easily be integrated with normal processing , because each instantiated template can be used directly as an already found sub - solution . in case of an agenda - driven chart generator of the kind described in @xcite , an instantiated template can be directly added as a _ passive edge _ to the generator s agenda .",
    "if passive edges with a wider span are given higher priority than those with a smaller span , the tactical generator would try to combine the largest derivations before smaller ones ,",
    "i.e. , it would prefer those structures determined by ebl .",
    "the ebl method just described has been fully implemented and tested with a broad coverage hpsg - based english grammar including more than 2000 fully specified lexical entries .",
    "the tdl grammar formalism is very powerful , supporting distributed disjunction , full negation , as well as full boolean type logic .    in our current system ,",
    "an efficient chart - based bidirectional parser is used for performing the training phase . during training ,",
    "the user can interactively select which of the parser s readings should be considered by the ebl module . in this way the user can control which sort of structural ambiguities should be avoided because they are known to cause misunderstandings . for interleaving the ebl application phase with normal processing a first prototype of a chart generator",
    "has been implemented using the same grammar as used for parsing .",
    "first tests has been carried out using a small test set of 179 sentences .",
    "currently , a parser is used for processing the test set during training .",
    "generation of the extracted templates is performed solely by the ebl application phase ( i.e. , we did not considered integration of ebl and chart generation ) . the application phase is very efficient .",
    "the average processing time for indexing and instantiation of a sentence level template ( determined through parsing ) of an input mrs is approximately one second . compared to parsing the corresponding string the factor of speed up is between 10 to 20 .",
    "a closer look to the four basic ebl - generation steps : indexing , instantiation , lexical lookup , and terminal matching showed that the latter is the most expensive one ( up to 70% of computing time ) .",
    "the main reasons are that 1 . )",
    "lexical lookup often returns several lexical readings for an mrs element ( which introduces lexical non - determinism ) and 2 . )",
    "the lexical elements introduce most of the disjunctive constraints which makes unification very complex .",
    "currently , terminal matching is performed left to right .",
    "however , we hope to increase the efficiency of this step by using head - oriented strategies , since this might help to re - solve disjunctive constraints as early as possible .",
    "the only other approach i am aware of which also considers ebl for nlg is @xcite .",
    "however , he focuses on the compilation of a logic grammar using lr - compiling techniques , where ebl - related methods are used to optimize the compiled lr tables , in order to avoid spurious non - determinisms during normal generation .",
    "he considers neither the extraction of a specialized grammar for supporting controlled language generation , nor strong integration with the normal generator .    however , these properties are very important for achieving high applicability .",
    "automatic grammar extraction is worthwhile because it can be used to support the definition of a _ controlled _ domain - specific language use on the basis of training with a general source grammar .",
    "furthermore , in case exact matching is requested only the application module is needed for processing the subgrammar . in case of normal processing , our ebl method serves as a speed - up mechanism for those structures which have `` actually been used or uttered '' .",
    "however , completeness is preserved .",
    "we view generation systems which are based on `` canned text '' and linguistically - based systems simply as two endpoints of a contiguous scale of possible system architectures ( see also @xcite ) .",
    "thus viewed , our approach is directed towards the automatic creation of application - specific generation systems .",
    "we have presented a method of automatic extraction of subgrammars for controlling and speeding up natural language generation ( nlg ) .",
    "the method is based on explanation - based learning ( ebl ) , which has already been successfully applied for parsing .",
    "we showed how the method can be used to train a system to a specific use of grammatical and lexical usage .",
    "we already have implemented a similar ebl method for parsing , which supports on - line learning as well as statistical - based management of extracted data . in the future",
    "we plan to combine ebl - based generation and parsing to one _ uniform _ ebl approach usable for high - level performance strategies which are based on a strict interleaving of parsing and generation ( cf .",
    "the research underlying this paper was supported by a research grant from the german bundesministerium fr bildung , wissenschaft , forschung und technologie ( bmb+f ) to the dfki project paradime fkz  itw  9704 .",
    "i would like to thank the hpsg people from csli , stanford for their kind support and for providing the hpsg - based english grammar .",
    "in particular i want to thank dan flickinger and ivan sag .",
    "many thanks also to walter kasper for fruitful discussions .",
    "copestake , a. , d.  flickinger , r.  malouf , s.  riehemann , and i.  sag . 1996 .",
    "translation using minimal recursion semantics . in _",
    "proceedings , 6th international conference on theoretical and methodological issues in machine translation_.    dale , r. , w.  finkler , r.  kittredge , n.  lenke , g.  neumann , c.  peters , and m.  stede .",
    "1994 . report from working group 2 : lexicalization and architecture . in w.",
    "hoeppner , h.  horacek , and j.  moore , editors , _ principles of natural language generation _",
    ", dagstuhl - seminar - report ;  93 .",
    "schlo dagstuhl , saarland , germany , europe , pages 3039 .",
    "krieger , hans - ulrich and ulrich schfer .",
    "a type description language for constraint - based grammars . in _ proceedings of the 15th international conference on computational linguistics , coling-94 _ , pages 893899 .",
    "neumann , g. 1994a .",
    "application of explanation - based learning for efficient processing of constraint based grammars . in _ proceedings of the tenth ieee conference on artificial intelligence for applications _ , pages 208215 , san antonio , texas , march .",
    "neumann , g. and g.  van noord .",
    "reversibility and self - monitoring in natural language generation . in tomek",
    "strzalkowski , editor , _ reversible grammar in natural language processing_. kluwer , pages 5996 .",
    "samuelsson , c. and m.  rayner .",
    "1991 . quantitative evaluation of explanation - based learning as an optimization tool for a large - scale natural language system . in _",
    "ijcai-91 _ , pages 609615 , sydney , australia .",
    "srinivas , b. and a.  joshi .",
    "some novel applications of explanation - based learning to parsing lexicalized tree - adjoining grammars . in _",
    "33th annual meeting of the association for computational linguistics _ , cambridge , ma ."
  ],
  "abstract_text": [
    "<S> this paper presents a method for the automatic extraction of subgrammars to control and speeding - up natural language generation nlg . </S>",
    "<S> the method is based on explanation - based learning ebl . </S>",
    "<S> the main advantage for the proposed new method for nlg is that the complexity of the grammatical decision making process during nlg can be vastly reduced , because the ebl method supports the adaption of a nlg system to a particular use of a language .    </S>",
    "<S> # 1 </S>"
  ]
}