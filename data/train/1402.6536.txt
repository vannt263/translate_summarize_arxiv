{
  "article_text": [
    "the problem of constructing confidence intervals for parameters of discrete distributions continues to attract considerable interest in the statistical community .",
    "the lack of smoothness of these distributions causes the coverage ( i.e. the probability that the interval covers the true parameter value ) of such intervals to fluctuate from @xmath0 when either the parameter value or the sample size @xmath1 is altered .",
    "recent contributions to the theory of these confidence intervals include @xcite , @xcite , @xcite , @xcite and @xcite .",
    "the purpose of this short note is to discuss the split sample method recently proposed by @xcite .",
    "the split sample method reduces the oscillations of the coverage by splitting the sample in two .",
    "it is applicable to most existing confidence intervals for parameters of lattice distributions , including the binomial and poisson distributions . for simplicity , we will in most of the remainder of the paper limit our discussion to the binomial setting , with the split sample method being applied to the celebrated @xcite interval for the proportion @xmath2 .",
    "our conclusions are however equally valid for other confidence intervals and distributions .",
    "a random variable @xmath3 is the sum of a sequence @xmath4 of independent @xmath5 random variables .",
    "the split sample method is applied to @xmath4 rather than to @xmath6 .",
    "the idea is to split the sample into two sequences @xmath7 and @xmath8 with @xmath9 and @xmath10 . in the formula for the chosen confidence interval , the maximum likelihood estimator @xmath11",
    "is then replaced by the weighted estimator @xmath12 the formula for the wilson interval is @xmath13 where @xmath14 is the @xmath15 standard normal quantile , so the split sample wilson interval is given by @xmath16    @xcite showed by numerical and asymptotic arguments based on @xcite that when @xmath17 ( rounded to the nearest integer ) and @xmath18 the split sample method greatly reduces the oscillations of the coverage of the interval , without increasing the interval length . in the remainder of the paper ,",
    "whenever @xmath19 and @xmath20 need to be specified , we will use these values . depending on how the sample is split",
    ", different confidence intervals will result , making the split sample interval a randomized confidence interval .",
    "if the sequence @xmath4 is available , the interval can be data - randomized in the sense that the randomization can be determined by the data : the first @xmath19 observations can be put in the first subsample and the remaining @xmath20 observation in the second subsample .",
    "if the results of the individual trials have not been recorded , one must use randomness from outside the data to create a sequence @xmath4 of 0 s and 1 s such that @xmath21 .",
    "we will discuss these two settings separately .",
    "@xcite left two questions open .",
    "the first is how the split sample interval performs in comparison to other randomized intervals , as @xcite only compared the split sample interval to non - randomized confidence intervals .",
    "the second question is to what extent the randomization can affect the bounds of the interval . in the remainder of this note we answer these questions ,",
    "discussing the impact of the random splitting on the confidence interval and comparing the split sample interval to alternative intervals .",
    "section [ randomized ] is concerned with externally randomized intervals whereas we in section [ datarandomized ] study data - randomized intervals . in both settings , we find the competing intervals to be superior to the split sample interval .",
    "various criticisms of randomized intervals are then discussed in section [ discussion ] .",
    "when @xmath22 , @xmath23 and @xmath24 . ]",
    "a strategy for smoothing the distribution of the binomial random variable @xmath6 is to base our inference on @xmath25 , where @xmath26 is a comparatively small random noise , using @xmath25 instead of @xmath6 in the formula for our chosen confidence interval . having a smoother distribution leads to a better normal approximation , which in turn reduces the coverage fluctuations of the interval .",
    "the split sample method can be seen to be a special case of this strategy .",
    "let @xmath27 be a random variable which , conditioned on @xmath6 , follows a @xmath28 distribution .",
    "then it follows from ( [ eq1 ] ) that @xmath29 so that @xmath30 the conditional distribution of @xmath26 when @xmath22 is shown in figure [ fig0 ] .",
    "indeed , when the sequence @xmath4 has not been observed , the splitting of the sample is superficial ( since the sample itself is not available to us ) and it may be more natural to think of the split sample procedure as adding this discrete random noise term @xmath26 , the distribution of which is conditioned on @xmath6 .",
    "if one has decided to use random noise to improve the normal approximation , the next step is to ask whether there are other distributions for the noise that yield an even better approximation and thereby decrease the coverage oscillations even further .",
    "the answer is yes , for instance if @xmath6 is replaced by @xmath31 where @xmath32 independently of @xmath6 .",
    "the normal approximations of @xmath6 , @xmath33 and @xmath34 are compared in figure [ fig1 ] .",
    "we will refer to the interval based on @xmath34 as the @xmath35 interval .",
    ", ( b ) @xmath33 , ( c ) @xmath34 when @xmath36 . ]    a randomized confidence interval that does not rely on a normal approximation is the @xcite interval .",
    "it belongs to an important class of confidence intervals for @xmath2 , consisting of intervals @xmath37 where the lower bound @xmath38 is such that @xmath39 and the upper bound @xmath38 is such that @xmath40 for @xmath41 this is the non - randomized clopper  pearson interval @xcite and for @xmath42 this is the non - randomized mid - p interval @xcite .",
    "the choice @xmath43 and @xmath44 corresponds to the randomized stevens interval , which is an inversion of the most powerful unbiased test for @xmath2 @xcite .",
    "we note that stevens procedure also can be applied when constructing confidence intervals for parameters of poisson and negative binomial distributions .",
    ".,title=\"fig : \" ] .,title=\"fig : \" ]    the coverage fluctuations and expected length of the split sample wilson , @xmath35 wilson and stevens intervals are compared in figure [ fig2 ] .",
    "the @xmath35 interval improves upon the split sample interval about as much as the split sample interval improves upon the standard wilson interval . unlike the split sample and @xmath35 intervals",
    ", the stevens interval has coverage exactly equal to @xmath0 for all values of @xmath2 , so that there are no coverage oscillations at all .",
    "the difference in expected length between the intervals is quite small for all combinations of @xmath2 and @xmath1 and is decreasing in @xmath1 .",
    "the stevens interval is shorter when @xmath2 is close to 0 or 1 , but wider when @xmath2 is close to @xmath45 .",
    "when @xmath46 the difference in expected length is at most 0.018 and when",
    "@xmath47 it is at most 0.002 .",
    "the randomization has a strong impact on the bounds of the confidence intervals . as an example , when @xmath48 and @xmath49 the upper bound of the split sample wilson interval ranges from 0.476 to 0.558 , meaning that the range of the upper bound is 0.082 or 18 % of the interval s conditional expected length 0.45",
    "the impact of the randomization can be substantial even for relatively large @xmath1 .",
    "consider for instance the case @xmath50 , @xmath51 .",
    "the conditional mean length of the split sample wilson interval is 0.11 , whereas the range of the upper bound of the interval is 0.016 , or 14.5 % of the conditional expected length of the interval .     and",
    "the ranges are only defined for integer @xmath6 ; the lines are used only to guide the eye . ]    the @xmath52 wilson and stevens intervals are similarly affected by the randomization for small @xmath1 : when @xmath48 and @xmath49 the conditional expected length of the stevens interval is 0.48 and the range of the upper bound is @xmath53 or 23 % of the conditional expected length . however , the impact of the randomization on these interval decreases quicker than it does for the split sample wilson interval .",
    "when @xmath50 and @xmath51 the conditional expected length of the stevens interval is 0.11 .",
    "the range of the upper bound is 0.005 , which is no more than 4.5 % of the conditional expected length .",
    "figure [ fig3 ] shows the range of the upper bounds of the three intervals for different combinations of @xmath6 and @xmath1 .",
    "the intervals are about as bad for @xmath46 , but the @xmath52 wilson and stevens intervals are much less affected by the randomization for @xmath47 and @xmath54 . because of the equivariance of the intervals , the figures for the lower bound are identical if @xmath6 is replaced by @xmath55 .",
    "as pointed out by @xcite , if the result of each of the @xmath1 independent trials are recorded , one can put the first @xmath19 observations in the first subsample and the other @xmath20 observations in the second subsample , so that the randomness only comes from the data itself .",
    "this means that there is no ambiguity about the interval , so that there is no need to discuss the range of the upper bound and that two different statisticians always will obtain the same confidence interval when they apply the procedure to the same data .",
    "alternatives to the split sample interval are available also if the sequence of observations has been recorded .",
    "it is possible to let the randomization of the stevens interval be determined by @xmath4 , for instance by letting the sequence determine the ( now approximately ) @xmath56 random variable @xmath57 .",
    "an example of this is given by the following algorithm .",
    "it generalizes the data - randomized korn interval @xcite , for which the p - value of a rank test of the hypothesis that the 1 s are uniformly distributed in the sequence is used to determine @xmath58 .",
    "it is our hope that the below description of the procedure is somewhat more straightforward .",
    "the algorithm can be applied to the @xmath35 wilson interval as well , with @xmath59 .",
    "the function used to associate a number @xmath58 with each permutation is arbitrary . however , as long as this function is given explicitly , no ambiguity will remain when the above algorithm is used .",
    "we also note that the split sample function proposed by @xcite is equally arbitrary , as is the choice of @xmath19 and @xmath20 .",
    "data - randomized stevens intervals can be constructed for parameters of other stochastically increasing lattice distributions , including the poisson and negative binomial distributions , in an analogue manner .",
    "similarly , the data - randomized @xmath35 procedure can be used to lessen the coverage fluctuations of other confidence intervals and for other distributions .      when @xmath46 the split sample method smoothens the binomial distribution by replacing its 21 possible values by 119 possible values .",
    "when the above algorithm is used to produce the korn interval , @xmath60 possible values are used instead , smoothing the distribution even further , and reducing the coverage oscillations to a much greater extent .",
    "the split sample wilson interval is compared to the korn and @xmath35 wilson intervals in figure [ fig4 ] . when @xmath46 , the korn interval has near - perfect coverage for @xmath61 , but like the externally randomized stevens interval it is slightly wider than the competing intervals in this region of the parameter space .",
    "this difference in expected length quickly becomes smaller as @xmath1 increases .",
    "the data - randomized @xmath35 wilson interval has smaller coverage fluctuations than the split sample wilson interval , but is no wider .    .",
    "the expected length of the wilson interval equals that of the split sample wilson interval and the data - randomized @xmath35 interval . ]",
    "in the split sample method random noise with a discrete distribution is added to the data to reduce the coverage fluctuations of a confidence interval .",
    "we have shown that it is better to use a continuous distribution such as the @xmath35 distribution for the random noise , as this lowers the coverage fluctuations even further and reduces the impact of the randomization on the interval bounds .",
    "this kind of randomization can however not be used to remove the coverage fluctuations completely . in contrast , the stevens interval offers exact coverage .",
    "moreover , for larger @xmath1 the randomization has a smaller impact on the bounds of the stevens interval than it has on the split sample wilson interval . if a randomized confidence interval for the binomial proportion @xmath2 is to be used , we therefore recommend the stevens interval over split sample intervals .",
    "the main objection against randomized confidence intervals is that different statisticians may produce different intervals when applying the same method to the same data .",
    "@xcite solve this problem by putting the first @xmath19 observations in the first subsample and the remaining @xmath20 observations in the second subsample , using so - called data - randomization .",
    "we compared several data - randomized intervals in section [ comp2 ] and found that the split sample wilson interval had the worst performance of the lot .",
    "neither of these intervals manages to remove the coverage fluctuations completely .",
    "when using the data - randomization strategy we have to condition our inference on an auxiliary random variable  the order of the observations  which has no relation to the parameter of interest .",
    "we then lose the rather natural property of invariance under permutations of the sample .",
    "consequently , a statistician that reads the sequence from the left to the right may end up with a different interval than a statistician that reads the sequence from the right to the left .",
    "care should be taken when using data - randomization : in most binomial experiments it is arguably neither reasonable nor desirable that the order in which the observations were obtained affects the inference .",
    "objections against randomized confidence intervals are sometimes met by the argument that randomization already is widely used in virtually all areas of statistics : bootstrap methods , mcmc , tests based on simulated null distributions and random subspace methods ( e.g. @xcite ) all rely on randomization .",
    "an important difference is however that for any @xmath1 the impact of the randomization on these methods can be made arbitrarily small by allowing more time for the computations .",
    "this is not possible for randomized confidence intervals for parameters of lattice distributions , where for each @xmath1 there exists a positive lower bound for the impact of the randomization . in this context",
    "we also mention @xcite , who proposed a completely different approach to dealing with the ambiguity of randomized confidence intervals , based on fuzzy set theory .",
    "in our study we applied the split sample method to the wilson interval for a binomial proportion .",
    "this interval has excellent performance , with competitive coverage and length properties , and is often recommended for general use @xcite .",
    "we note however that it can be more or less uniformly improved upon by using a level - adjusted clopper  pearson interval @xcite instead ; we opted to use the wilson interval in our study simply because it is less computationally complex ."
  ],
  "abstract_text": [
    "<S> split sample methods have recently been put forward as a way to reduce the coverage oscillations that haunt confidence intervals for parameters of lattice distributions , such as the binomial and poisson distributions . </S>",
    "<S> we study split sample intervals in the binomial setting , showing that these intervals can be viewed as being based on adding discrete random noise to the data . </S>",
    "<S> it is shown that they can be improved upon by using noise with a continuous distribution instead , regardless of whether the randomization is determined by the data or an external source of randomness . </S>",
    "<S> we compare split sample intervals to the randomized stevens interval , which removes the coverage oscillations completely , and find the latter interval to have several advantages . </S>",
    "<S> + * keywords : * binomial distribution ; confidence interval ; poisson distribution ; randomization ; split sample method . </S>"
  ]
}