{
  "article_text": [
    "understanding the brain requires mathematical models on different spatial scales . on the `` microscopic '' level of nerve cells , neural spike trains can be well predicted by phenomenological spiking neuron models . on a coarse scale ,",
    "neural activity can be modeled by phenomenological equations that summarize the total activity of many thousands of neurons .",
    "such population models are widely used to model neuroimaging data such as eeg , meg or fmri data .",
    "however , it is largely unknown how large - scale models are connected to an underlying microscale model .",
    "linking the scales is vital for a correct description of rapid changes and fluctuations of the population activity , and is crucial for multiscale brain models .",
    "the challenge is to treat realistic spiking dynamics as well as fluctuations arising from the finite number of neurons .",
    "we obtained such a link by deriving stochastic population equations on the mesoscopic scale of 100  1000 neurons from an underlying microscopic model .",
    "these equations can be efficiently integrated and reproduce results of a microscopic simulation while achieving a high speed - up factor .",
    "we expect that our novel population theory on the mesoscopic scale will be instrumental for understanding experimental data on information processing in the brain , and ultimately link microscopic and macroscopic activity patterns .",
    "when neuroscientists report electrophysiological , genetic , or anatomical data from a cortical neuron , they typically refer to the cell type , say , a layer 2/3 fast - spiking interneuron , a parvalbumin - positive neuron in layer 5 , or a martinotti cell in layer 4 , together with the area , say primary visual cortex or somatosensory cortex @xcite .",
    "whatever the specific taxonomy used , the fact that a taxonomy is plausible at all indicates that neurons can be viewed as being organized into populations of cells with similar properties . in simulation studies of cortical networks with spiking neurons ,",
    "the number of different cell types , or neuronal populations , per cortical column ranges from eight @xcite to about 200 @xcite with 31000 to 80000 simulated neurons for one cortical column , but larger simulations of several columns adding up to a million neurons ( and 22 cells types ) have also been performed @xcite . in the following",
    ", we will refer to a model where each neuron in each population is simulated explicitly by a spiking neuron model as a _ microscopic _ model .    on a much coarser level , neural mass models @xcite , also called field models @xcite , population activity equations @xcite , rate models @xcite , or wilson - cowan models @xcite represent the activity of a cortical column at location @xmath0 by one or at most a few variables , such as the mean activity of excitatory and inhibitory neurons located in the region around @xmath0 .",
    "computational frameworks related to neural mass models have been used to interpret data from fmri @xcite and eeg @xcite . since neural mass models give a compact summary of coarse neural activity , they can be efficiently simulated and fit to experimental data @xcite .",
    "however , neural mass models have several disadvantages .",
    "while the stationary state of neural mass activity can be matched to the single - neuron gain function and hence to detailed neuron models @xcite , the dynamics of neural mass models in response to a rapid change in the input does not correctly reproduce a microscopic simulation of a population of neurons @xcite .",
    "second , fluctuations of activity variables in neural mass models are either absent or described by an _ ad hoc _ noise model .",
    "moreover , the links of neural mass models to local field potentials are difficult to establish @xcite . because a systematic link to microscopic models at the level of spiking neurons is missing , existing neural mass models must be considered as heuristic phenomenological , albeit successful , descriptions of neural activity .    in this paper",
    "we address the question of whether equations for the activity of populations , similar in spirit but not necessarily identical to wilson - cowan equations @xcite , can be systematically derived from the interactions of spiking neurons at the level of microscopic models . at the microscopic level ,",
    "we start from generalized integrate - and - fire ( gif ) models @xcite because , first , the parameters of such gif models can be directly , and efficiently , extracted from experiments @xcite and , second , gif models can predict neuronal adaptation under step - current input @xcite as well as neuronal firing times under in - vivo - like input @xcite . in our modeling framework ,",
    "the gif neurons are organized into different interacting populations .",
    "the populations may correspond to different cell types within a cortical column with known statistical connectivity patterns @xcite . because of the split into different cell types , the number of neurons per population ( e.g. , fast - spiking inhibitory interneurons in layer 2/3 ) is finite and in the range of 50 - 2000 @xcite .",
    "we call a model at the level of interacting cortical populations of finite size a _ mesoscopic _ model",
    ". the mathematical derivation of the mesoscopic model equations from the microscopic model ( i.e. network of generalized integrate - and - fire neurons ) is the main topic of this paper .",
    "the small number of neurons per population is expected to lead to characteristic fluctuations of the activity which should match those of the microscopic model .",
    "the overall aims of our approach are two - fold . as a first aim ,",
    "this study would like to develop a theoretical framework for cortical information processing .",
    "the main advantage of a systematic link between neuronal parameters and mesoscopic activity is that we can quantitatively predict the effect of changes of neuronal parameters in ( or of input to ) one population on the activation pattern of this as well as other populations .",
    "in particular , we expect that a valid mesoscopic model of interacting cortical populations will become useful to predict the outcome of experiments such as optogenetic stimulation of a subgroup of neurons @xcite",
    ". a better understanding of the activity patterns within a cortical column may in turn , after suitable postprocessing , provide a novel basis for models of eeg , fmri , or lfp @xcite . while we can not address all these points in this paper , we present an example of nontrivial activity patterns in a network model with stochastic switching between different activity states potentially linked to perceptual bistability @xcite or resting state activity @xcite .    as a second aim , this study would like to contribute to multiscale simulation approaches @xcite in the neurosciences by providing a new tool for efficient and consistent coarse - grained simulation at the mesoscopic scale .",
    "understanding the computations performed by the nervous system is likely to require models on different levels of spatial scales , ranging from pharmacological interactions at the subcellular and cellular levels to cognitive processes at the level of large - scale models of the brain .",
    "ideally , a modeling framework should be efficient and consistent across scales in the following sense .",
    "suppose , for example , that we are interested in neuronal membrane potentials in one specific group of neurons which receives input from many other groups of neurons . in a microscopic model",
    ", all neurons would be simulated at the same level ; in a multi - scale simulation approach , only the group of neurons where we study the membrane potentials is simulated at the microscopic level , whereas the input from other groups is replaced by the activity of the mesoscopic model .",
    "a multiscale approach is consistent , if the replacement of parts of the microscopic simulation by a mesoscopic simulation does not lead to any change in the observed pattern of membrane potentials in the target population .",
    "the approach is efficient if the change of simulation scale leads to a significant speed - up of simulation . while we do not intend to present a systematic comparison of computational performance , we provide an example and measure the speed - up factor between mesoscopic and microscopic simulation for the case of a cortical column consisting of eight populations @xcite .    despite of its importance ,",
    "a quantitative link between mesoscopic population models and microscopic neuronal parameters is still largely lacking .",
    "this is mainly due to two obstacles : first , in a cortical column the number of neurons of the same type is small ( 502000 @xcite ) and hence far from the @xmath1 limit of classic `` macroscopic '' theories in which fluctuations vanish @xcite .",
    "systematic treatments of finite - size networks using methods from statistical physics ( system size expansion @xcite , path integral methods @xcite , neural langevin equations @xcite ) have so far been limited to simplified markov models that lack , however , a clear connection to single neuron physiology .",
    "second , spikes generated by a neuron are generally correlated in time due to refractoriness @xcite , adaptation and other spike history dependencies @xcite .",
    "therefore spike trains are often not well described by an ( inhomogeneous ) poisson process , especially during periods of high firing rates @xcite , implying that the mesoscopic population activity ( i.e. the summed spike trains ) is generally also not captured by a poisson model @xcite .",
    "these non - poisson spike trains serve as input to other neurons leading to temporal input correlations ( colored noise ) that can drastically influence the population activity @xcite but which are hard to tackle analytically @xcite .",
    "therefore , most theoretical approaches rely on a white - noise or poisson assumption to describe the synaptic input @xcite , thereby neglecting spike - history effects . in the finite - size case ,",
    "refractoriness and adaptation lead to further complications , even in the absence of synaptic couplings @xcite . here",
    ", we will exploit earlier approaches to treating refractoriness @xcite and spike frequency adaptation @xcite and combine these with a novel treatment of finite - size fluctuations .",
    "our approach is novel for several reasons .",
    "first , we use generalized integrate - and - fire models that accurately describe neuronal data @xcite as our microscopic reference .",
    "second , we derive stochastic population equations that account for fluctuations of the population activities caused by the finite number @xmath2 of spiking neurons . our theory does not hinge on a system - size expansion with respect to a small parameter @xmath3 @xcite , and thus also works for relatively small populations .",
    "third , going beyond earlier studies @xcite , we treat refractoriness and adaptation and elucidate its interactions with finite - size fluctuations . and forth , our theory works far away from stationary states in contrast to linear response theories @xcite .    in the results section we present our mesoscopic population equations ,",
    "suggest an efficient numerical implementation , and illustrate the main dynamical effects via a selected number of examples . to validate the mesoscopic theory",
    "we numerically integrate the stochastic differential equations for the mesoscopic population activities and compare their statistics to those of the population activities derived from a microscopic simulation .",
    "a detailed account of the derivation is presented in the methods section . in the discussion section",
    "we point out limitations and possible applications of our mesoscopic theory .",
    "80000 neurons organized into four layers ( l2/3 , l4 , l5 , l6 ) each consisting of an excitatory ( `` e '' ) and an inhibitory ( `` i '' ) population . on the microscopic level , each individual neuron is described by a generalized integrate - and - fire ( gif ) model with membrane potential @xmath4 , dynamic threshold @xmath5 and conditional intensity @xmath6 .",
    "inset : gif dynamics for a specific neuron @xmath7 of population l4e ( @xmath8 ) .",
    "the neuron receives spikes from neurons in l4e , l4i and l6e , which drive the membrane potential @xmath4 .",
    "spikes are elicited stochastically by a conditional intensity @xmath9 that depends on the instantaneous difference between @xmath4 and the dynamic threshold @xmath5 .",
    "spike feedback ( voltage reset and spike - triggered threshold movement ) gives rise to spike history effects like refractoriness and adaptation .",
    "( b ) spike raster plot of the first 200 neurons of each population .",
    "the panels correspond to the populations in ( a ) . layer 4 and 6",
    "are stimulated by a step current during the interval @xmath10 mimicking thalamic input ( gray bars ) .",
    "solid lines show the population activities @xmath11 computed with temporal resolution @xmath12  ms , cf .",
    "the activities are stochastic due to the finite population size .",
    "( c ) on the mesoscopic level , the model reduces to a network of 8 populations , each represented by its population activity @xmath11 .",
    "inset : the mesoscopic model generates realizations of @xmath11 from an expected rate @xmath13 , which is a deterministic functional of the past population activities .",
    "( d ) a corresponding simulation of the mesoscopic model yields population activities with the same temporal statistics as in ( b ) . ]",
    "we consider a structured network of interacting homogeneous populations .",
    "homogeneous here means that each population consists of spiking neurons with similar intrinsic properties and random connectivity within and between populations . to define such populations",
    ", one may think of grouping neurons into genetically - defined cell classes of excitatory and inhibitory neurons @xcite , or , more traditionally , into layers and cell types ( fig .",
    "[ fig : potjans - scheme]a ) .",
    "for example , pyramidal cells in layer 2/3 of rodent somatosensory cortex corresponding to whisker c2 form a population of about 1700 neurons @xcite .",
    "pyramidal cells in layer 5 of the same cortical column form another one ( @xmath14 neurons @xcite ) , fast - spiking inhibitory cells in layer 2/3 a third one ( @xmath15 neurons @xcite ) and non - fast - spiking inhibitory cells in layer 2/3 a fourth one ( @xmath16 neurons @xcite ) , and so on @xcite .",
    "we suppose that the parameters of typical neurons from each population @xcite , the number of neurons per population @xcite and the typical connection probabilities @xcite and strength within and between populations @xcite are known from experimental data . the resulting spiking neural network can be simulated on a cellular level by numerical integration of the spiking dynamics of each individual neuron ( fig .",
    "[ fig : potjans - scheme]b ) . in the following",
    ", we will refer to this level of description as the _ microscopic _ level . apart from being computationally expensive ,",
    "the full microscopic network dynamics is highly complex and hence difficult to understand . to overcome these shortcomings ,",
    "we have developed a new mean - field description for the mesoscopic dynamics of interacting populations .",
    "a population @xmath17 of size @xmath18 is represented by its population activity @xmath11 ( greek superscripts label the populations , fig .  [",
    "fig : potjans - scheme]c ) defined as @xmath19 here , @xmath20 with the dirac @xmath21-function denotes the spike train of an individual neuron @xmath7 in population @xmath17 with spike times @xmath22 .",
    "empirically , the population activity is measured with a finite temporal resolution @xmath23 . in this case",
    ", we define the coarse - grained population activity as @xmath24 where @xmath25 is the number of neurons in population @xmath17 that have fired in a time bin of size @xmath23 starting at time @xmath26 .",
    "the two definitions converge in the limit @xmath27 .",
    "an example of population activities derived from spiking activity in a cortical circuit model under a step current stimulation is shown in fig .",
    "[ fig : potjans - scheme]b . to bridge the scales between neurons and populations , the corresponding mean - field model should ideally result in the same population activities as obtained from the full microscopic model ( fig .",
    "[ fig : potjans - scheme]d ) . because of the stochastic nature of the population activities",
    ", however , the qualifier `` same '' has to be interpreted in a statistical sense .",
    "the random fluctuations apparent in fig .",
    "[ fig : potjans - scheme]b , d are a consequence of the finite number of neurons because microscopic stochasticity is not averaged out in the finite sum in eq .  .",
    "this observation is important because estimated neuron numbers reported in experiments on local cortical circuits are relatively small @xcite .",
    "therefore , a quantitatively valid population model needs to account for finite - size fluctuations . as mentioned above",
    ", we will refer to the population - level with finite size populations ( @xmath28 to @xmath29 per population ) as the _ mesoscopic _ level . in summary",
    ", we face the following question : is it possible to derive a closed set of evolution equations for the mesoscopic variables @xmath11 that follow the same statistics as the original microscopic model ?    to address this question , we describe neurons by generalized integrate - and - fire ( gif ) neuron models ( fig .  [",
    "fig : potjans - scheme]a ( inset ) and methods , sec .  `` '' ) with escape noise @xcite .",
    "in particular , neuron @xmath7 of population @xmath17 is modeled by a leaky integrate - and - fire model with dynamic threshold @xcite .",
    "the variables of this model are the membrane potential @xmath4 and the dynamic threshold @xmath30 ( fig .",
    "[ fig : potjans - scheme]a , inset ) , which depends on earlier spikes @xmath22 of neuron @xmath7 and accounts for adaptation @xcite and other spike - history effects @xcite via a convolution of the spike train with a spike - triggered adaptation kernel or filter function @xmath31 .",
    "spikes are elicited stochastically depending on the present state of the neuron ( fig .",
    "[ fig : potjans - scheme]a , inset ) .",
    "specifically , the probability that neuron @xmath7 fires a spike in the next time step @xmath32 $ ] is given by @xmath33 , where @xmath34 is the conditional intensity of neuron @xmath7 ( also called conditional rate or hazard rate ) : @xmath35 with an exponential function @xmath36 .",
    "analysis of experimental data has shown that the `` softness '' parameter @xmath37 of the threshold is in the range of 1 to 5 mv @xcite .",
    "the parameter @xmath38 can be interpreted as the instantaneous rate at threshold .",
    "besides the effect of a spike on the threshold as mediated by the filter function @xmath31 , a spike also triggers a change of the membrane potential . in the gif model ( methods , sec .",
    "`` '' ) , the membrane potential @xmath4 is reset after spiking to a reset potential @xmath39 , to which @xmath4 is clamped for an absolute refractory period @xmath40 .",
    "absolute refractoriness is followed by a period of relative refractoriness , where the conditional intensity eq .",
    "is reduced .",
    "this period is determined by the relaxation of the membrane potential from the reset potential to the unperturbed or `` free '' potential , denoted @xmath41 , which corresponds to the membrane potential dynamics in the absence of resets .",
    "the gif model accurately predicts spikes of cortical neurons under noisy current stimulation mimicking in - vivo like input @xcite and its parameters can be efficiently extracted from single neuron recordings @xcite .",
    "[ [ mean - field - approximations . ] ] mean - field approximations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    in order to derive a mesoscopic mean - field theory for populations of gif neurons , we first approximate the conditional intensity @xmath34 of an individual neuron by an effective rate @xmath42 that only depends on its last spike time @xmath43 and on the history of the population activity @xmath44 , @xmath45 ( as expressed by the subscript `` @xmath46 '' ) .",
    "this is called the quasi - renewal approximation @xcite .",
    "taking into account the dependence on the last spike is particularly important because of neuronal refractoriness .    to obtain such a quasi - renewal description we make two approximations .",
    "firstly , we approximate the random connectivity by an effective full connectivity with proportionally scaled down synaptic weights ( `` mean - field approximation '' ) . as a result ,",
    "all neurons of the same population are driven by identical synaptic input ( see methods ) .",
    "this implies that for all neurons that had the same last spike time , the time course of the membrane potential is identical , @xmath47 .",
    "secondly , we make the quasi - renewal approximation for gif neurons @xcite , which replaces the threshold @xmath48 by an effective threshold @xmath49 . again , the effective threshold only depends on the last spike time and the history of the population activity . as a final result",
    "we obtain the conditional intensity for all neurons with a given last spike time @xmath50 as @xmath51 ( fig .",
    "[ fig : potjans - scheme]c , inset ) .",
    "a comparison of eq .",
    "( [ eq : lambda - short ] ) with eq .",
    "( [ eq : hazard - def - results ] ) shows that the explicit dependence on _ all _ past spike times @xmath52 of a given neuron @xmath7 has disappeared .",
    "instead , the conditional intensity now only depends on the _ last _ firing time @xmath50 and the past population activity @xmath44 , @xmath45 . to keep the notation simple , we omit in the following the population label @xmath17 at all quantities .",
    "[ [ finite - size - mean - field - theory . ] ] finite - size mean field theory .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + +     shown as a function of @xmath50 ( left ) and @xmath26 ( right ) .",
    "typically , the conditional intensity increases as the time since the last spike grows and the neuron recovers from refractoriness .",
    "( b ) for @xmath1 , the population activity @xmath53 ( hatched bin ) results from @xmath54 averaged over the density @xmath55 of last spike times ( blue ) , @xmath56 being the survival probability .",
    "( c ) the refractory states @xmath50 are discretized into time bins . in the bin immediately before @xmath26 , a large fluctuation ( blue peak ) was induced by forcing some of the neurons with last spike time around @xmath57 to fire . at time @xmath26 , the density of last spike times ( blue ) has a hole and a peak of equal probability mass .",
    "the red line shows the pseudo - density @xmath58 that would be obtained if we had used the survival probability @xmath59 of the unperturbed system . for recent last spike times , @xmath60 because of refractoriness ( a ) .",
    "hence the peak does not contribute to @xmath53 , whereas the negative mass of the hole `` contributes '' with a non - vanishing rate implying a reduction of the activity ( hatched bin ) .",
    "( d ) for a finite population size ( here @xmath61 ) , the refractory density @xmath62 ( blue ) , determines the expectation @xmath63 ( hatched bin ) of the fluctuating activity @xmath64 .",
    "analogous to the forced fluctuation in ( c ) , the finite - size fluctuations are associated with negative and positive deviations in the refractory density ( holes and overshoots ) compared to the non - normalized density @xmath65 ( red line ) that would be obtained if only the mean @xmath56 and not the exact survival fraction @xmath66 had been taken into account . the variance of the deviations is proportional to @xmath67 given by eq .",
    "( [ eq : pt ] ) . as a function of @xmath50",
    ", @xmath67 shows the range of @xmath50 where deviations are most prominent ( bottom ) .",
    "( e , f ) given the number of neurons firing in the bin @xmath68 , @xmath69 , the fraction of neurons that survive until time @xmath26 is shown for ten realizations ( gray lines , one highlighted in black for clarity ) .",
    "the mean fraction equals the survival probability @xmath56 ( red line , top panel ) .",
    "the variance of the number of survived neurons at time @xmath26 , @xmath70 , is shown at the bottom ( red line : semi - analytic theory , eq .",
    "( [ eq : pt ] ; circles : simulation ) .",
    "( e ) @xmath71 , ( f ) @xmath72 . ]    in this section , we present the main theoretical results with a focus on the finite - size effects arising from neuronal refractoriness .",
    "in particular , we work out and illustrate the interplay of finite - size fluctuations and refractoriness .    in the previous section ,",
    "we have effectively reduced the firing probability of a neuron to a function @xmath54 that only depends on its last spike time @xmath50 ( fig .",
    "[ fig : scheme - theory]a ) .",
    "this allows us to describe the evolution of the system by the density of the last spike time @xcite .",
    "because the last spike time characterizes the refractory state of the neuron , this density will also be referred to as the refractory density . before we describe the novel finite-@xmath2 theory , it is instructive to first recall the population equations for the case of infinite @xmath2 ( fig .",
    "[ fig : scheme - theory]b , c ) .",
    "let us look at the population of neurons at time @xmath26 and ask the following question : what fraction of these neurons has fired their last spike between @xmath50 and @xmath73 ?",
    "this fraction is given by the number of neurons @xmath74 that have fired in this interval multiplied by the survival probability @xmath56 that such a neuron has not fired again until time @xmath26 .",
    "in other words , the product @xmath55 evaluated at time @xmath26 represents the density of last spike times @xmath50 .",
    "because a neuron with last spike time @xmath50 emits a spike with rate @xmath54 , the total population activity at time @xmath26 is given by the integral @xcite @xmath75 this situation is depicted in fig .",
    "[ fig : scheme - theory]b . at the same time",
    ", the survival probability @xmath56 of neurons that fired their last spike at @xmath50 decays according to @xmath76 with initial condition @xmath77 ( fig .",
    "[ fig : scheme - theory]e , f red line ) . equations and define the population dynamics for @xmath1 @xcite .    in the limit @xmath1 , the dynamics of @xmath78 is deterministic because microscopic noise averages out .",
    "nevertheless , the infinite-@xmath2 case is useful to understand the main effect of fluctuations in the finite-@xmath2 case . to this end",
    ", let us perform the following thought experiment : in a small time interval of length @xmath23 immediately before time @xmath26 , we induce a large , positive fluctuation in the activity by forcing many of the neurons with last spike close to a given time @xmath79 to fire a spike ( fig .  [",
    "fig : scheme - theory]c ) . as a result ,",
    "the density of last spike times at time @xmath26 exhibits a large peak just prior to time @xmath26 corresponding to the large number of neurons that have been forced to fire in the time interval @xmath80 . at the same time",
    ", these neurons leave behind a `` hole '' in the density around @xmath79 . because the number of neurons is conserved",
    ", this hole exactly balances the area under the peak , and hence , the density of last spike times remains normalized .",
    "however , the two fluctuations ( the hole and the peak ) have two different effects on the population activity after time @xmath26 .",
    "specifically , the hole implies that some of the neurons which normally would have fired at time @xmath26 with a nonzero rate @xmath81 are no longer available .",
    "moreover , neural refractoriness implies that neurons which fired in the peak have a small or even vanishing rate @xmath82 at time @xmath26 . as a result",
    ", the population activity is reduced shortly after the perturbation ( fig .",
    "[ fig : scheme - theory]c ) .",
    "this example highlights the importance of the normalization of the refractory density as well as the state - dependence of the firing probability for understanding the effect of fluctuations .",
    "in particular , the normalization condition and neuronal refractoriness imply that a positive fluctuation of the population activity is succeeded by a negative fluctuation , and vice versa .",
    "this behavior is characteristic for spiking neurons , which are known to exhibit negative auto - correlations of their mean - centered spike trains at short time lags ( see e.g. @xcite ) .",
    "we now turn to the finite - size case . in this case , it is advantageous to discretize the last spike times into small bins of size @xmath23 that begin at the grid points @xmath83 , @xmath84 .",
    "furthermore , we adopt the definition of the coarse - grained population activity , eq .  , according to which @xmath85 is proportional to the number of spikes @xmath86 in the time bin @xmath87 . instead of the survival probability",
    ", we introduce the fraction of survived neurons @xmath88 , @xmath89 , such that @xmath90 is the number of neurons from bin @xmath91 that have not fired again until time @xmath26 ( fig .  [ fig : scheme - theory]d , e ) .",
    "dividing this number by @xmath92 and taking the continuum limit @xmath27 , yields the density of last spike times @xmath62 in the case of finite @xmath2 . since all neurons are uniquely identified by their last spike time , this density is normalized @xcite @xmath93 moreover , each bin contributes with rate @xmath94 a random number of spikes to the total activity at time @xmath26 ( fig .",
    "[ fig : scheme - theory]d ) . in the continuum limit , this results in the expected population activity @xmath95 here , the integral extends over all last spike times @xmath50 up to but not including time @xmath26 . comparing eq .",
    "( [ eq : abar - def ] ) with the corresponding equation for the infinite system , eq .",
    "( [ eq : pop - eq - infty ] ) , we observe that the integral only yields the expected population activity .",
    "the actual activity @xmath64 is a random process ( with mean @xmath96 ) that reflects the stochasticity of spike generation at the neuronal level .",
    "a population dynamics based on eq .",
    "( [ eq : abar - def ] ) depends on the population activity @xmath97 in the past as well as on the temporal evolution of the survival fraction @xmath88 . as shown in fig .",
    "[ fig : scheme - theory]e and f , @xmath88 decreases in time like a random stair case , where a step down at time @xmath26 represents a spiking event from the group of neurons with last spike time in the bin @xmath87 .",
    "each of these spiking events decreases the number of survived neurons by one .",
    "hence , after @xmath86 steps no neurons from this group are left and @xmath88 is exactly zero .",
    "examples for @xmath98 and @xmath99 are shown in fig .",
    "[ fig : scheme - theory]e and f. while the population activity @xmath97 arises from the sum of @xmath2 neurons and is thus a mesoscopic quantity , the survival fraction @xmath88 must be regarded as a microscopic quantity .",
    "this is because @xmath88 refers to the number of survived neurons in a small time bin , which is a small number .",
    "although it is possible to perform an independent stochastic simulation of @xmath88 for each of the many time bins @xmath91 in the past and from this obtain the population activities @xmath64 , such finite - size population dynamics would not yield the reduced mesoscopic dynamics that we are looking for . in the limit case @xmath27 , such an approach would be as complex as the original microscopic dynamics of @xmath2 neurons .",
    "a mesoscopic description should , however , not contain such microscopic detail .",
    "the question arises whether the stochasticity of the many different random processes @xmath88 , @xmath100 , can be reduced to a single effective noise process that drives the dynamics on the mesoscopic level . to tackle this question , we use the fact that the mean and variance of @xmath88 are mesoscopic quantities , i.e. they are completely determined by the past activities @xmath101 , @xmath102 .",
    "as shown in methods , the mean survival fraction is given by the survival probability , @xmath103 ( fig .  [ fig : scheme - theory]e , f ) , which obeys eq .",
    "( [ eq : q - dyn ] ) .",
    "we emphasize that @xmath104 is a valid mesoscopic quantity since it only depends on the population activity through @xmath105 , cf .",
    "( [ eq : q - dyn ] ) , and not on a specific microscopic realization .",
    "similarly , the variance of the number of survived neurons , @xmath90 , is given by the mesoscopic variable @xmath106 calculated from the differential equation @xmath107 with initial condition @xmath108 ( see methods , eq .  ) .",
    "again we note that the dynamics of @xmath109 involves mesoscopic quantities only .",
    "how can we use the means and variances to remove the microscopic randomness in eq .",
    "( [ eq : abar - def ] ) ? to answer this question , we use the picture from our thought experiment : just as the artificially induced fluctuation in the infinite - size system , the endogenously generated fluctuations of @xmath64 in the finite - size system are accompanied by deviations of the microscopic density @xmath110 from the pseudo - density @xmath111 ( fig .",
    "[ fig : scheme - theory]c and d , red line ) . a negative deviation ( @xmath112 ) can be interpreted as a hole and a positive deviation ( @xmath113 ) as an overshoot .",
    "the pseudo - density uses the actual history of the mesoscopic activity @xmath97 for @xmath114 and combines it with the macroscopic survival probability @xmath56 .",
    "in contrast to the macroscopic density @xmath55 in eq .   or the microscopic density @xmath110 , the pseudo - density is not normalized",
    ". however , the pseudo - density @xmath111 has the advantage that it is based on mesoscopic quantities only .",
    "this suggests to split the survival fraction into its mesoscopic mean and a microscopic deviation , @xmath115 .",
    "because the expression @xmath116 represents the mismatch between the pseudo - density and the microscopic density , it exactly corresponds to the holes and overshoots in the picture of our thought experiment ( compare red curve and blue histogram in fig .  [",
    "fig : scheme - theory]d ) . using this split , eq .",
    "( [ eq : abar - def ] ) can be written as @xmath117 analogously , the normalization of the refractory density , eq .",
    ", can be written as @xmath118 we refer to the second integral in eq .   as a correction term because it corrects for the error that one would make if one sets @xmath119 in eq .",
    "( [ eq : abar - def ] ) .",
    "this correction term represents the overall contribution of the holes ( @xmath120 ) and overshoots ( @xmath121 ) to the expected activity .",
    "equation is not yet the desired mesoscopic equation since it involves the microscopic deviations @xmath122 .",
    "however , we can use the normalization condition , eq .",
    ", to remove these microscopic degrees of freedom .",
    "this is possible because the correction term is tightly constrained by the sum of all holes and overshoots , @xmath123 , which by eq .",
    ", is completely determined by the past mesoscopic activities .",
    "this suggests to make the deterministic ansatz @xmath124 for the correction term .",
    "as shown in methods ( `` mesoscopic population equations '' ) , the optimal rate @xmath125 that minimizes the mean squared error of this approximation is given by @xmath126 this effective rate is fully determined by the mesoscopic variance @xmath67 known from eq .",
    "( [ eq : pt ] ) .",
    "it has a simple interpretation : as a function of @xmath50 , the quantity @xmath127 is a probability density proportional to the variance of the fluctuation at the location @xmath50 ( fig .  [",
    "fig : scheme - theory]d , bottom ) .",
    "thus , the effective rate @xmath125 can be regarded as a weighted average of the conditional intensity @xmath54 that accounts for the expected amplitude of the holes and overshoots .    using the effective rate @xmath125 in eq .",
    "( [ eq : abar - split ] ) results in the expected activity @xmath128 looking at the structure of eq .",
    ", we find that the first term is the familiar population integral known from the infinite-@xmath2 case , eq .  .",
    "the second term is a correction that is only present in the finite-@xmath2 case .",
    "in fact , in the limit @xmath1 , the pseudo - density @xmath65 converges to the macroscopic density @xmath55 , which is normalized to unity .",
    "hence the correction term vanishes and we recover the population equation for the infinite system .    to obtain the population activity we consider a time scale @xmath129 that is sufficiently small such that the probability of a neuron to fire during an interval @xmath130 is much smaller than one , i.e. @xmath131 . on this time scale",
    "we expect @xmath132 spikes of the population , where @xmath96 is given by eq .  .",
    "given @xmath133 , the actual number of spikes @xmath134 is an independent , poisson distributed random number with mean @xmath133 ( see methods ) . therefore , eq .   yields the population activity    [ eq : an ] @xmath135.\\ ] ] in the continuum limit @xmath136 , the population activity can be formally written as a @xmath21-spike train , or `` shot noise '' , @xmath137 where @xmath138 is a random point process with a conditional intensity function @xmath139 . in eq .  , the condition @xmath140 denotes the history of the point process @xmath141 up to ( but not including ) time @xmath26 , or equivalently the history of the population activity @xmath97 for @xmath114 . the conditional intensity in eq .",
    "means that the conditional expectation of the population activity is given by @xmath142 , which according to eq .",
    "is indeed a deterministic functional of the past activities . while the shot noise , eq .",
    ", yields the formal continuum limit of the population activity , we note that in simulations it is not necessary to resolve each single spike time @xmath143 of the population and a temporally coarse - grained description similar to eq .",
    "is more appropriate ( see also methods , sec .  `` '' ) .",
    "finally , we note that the case of large but finite populations permits a gaussian approximation of the shot noise , eq .  , which yields the more explicit form @xmath144    here",
    ", @xmath145 is a gaussian white noise with correlation function @xmath146 .",
    "the gaussian approximation , eq .  , explicitly reveals the dependence on @xmath96 , which in the shot - noise representation , eq .  , is hidden in the intensity of the point process @xmath147 .",
    "the set of coupled equations ,  ( [ eq : pt ] ) ,     constitute the desired mesoscopic population dynamics and is the main result of the paper .",
    "the dynamics is fully determined by the history of the mesoscopic population activity @xmath148 . the gaussian white noise in eq .   or the independent random number involved in the generation of the population activity via eq .   or is the only source of stochasticity and summarizes the effect of microscopic noise on the mesoscopic level .",
    "microscopic detail such as the knowledge of how many neurons occupy a certain microstate @xmath50 has been removed .",
    "one may wonder where the neuronal interactions enter in the population equation .",
    "synaptic interactions are contained in the conditional intensity @xmath54 which depends on the membrane potential @xmath149 , which in turn is driven by the synaptic current that depends on the population activity via eq .",
    "( [ eq : i_syn - fully ] ) in methods . an illustration of the derived mesoscopic model is shown in fig .",
    "[ fig : potjans - scheme]c ( inset ) . in this section",
    ", we considered a single population to keep the notation simple .",
    "however , it is straightforward to formulate the corresponding equations for the case of several equations as shown in methods , sec .",
    "`` '' .",
    "for a first analysis of the finite - size effects , we consider the special case of a fully - connected network of poisson neurons with absolute refractory period @xcite . in this case",
    ", the conditional intensity can be represented as @xmath150 , where @xmath40 is the absolute refractory period , @xmath151 is the heaviside step function and @xmath41 is the free membrane potential , which obeys the passive membrane dynamics @xmath152 where @xmath153 is the membrane time constant , @xmath154 accounts for all currents that are independent of the population activities , @xmath155 is the synaptic strength and @xmath156 is a synaptic filter kernel ( see methods , eq .",
    "( [ eq : h - eta ] ) for details ) . for this conditional intensity , the effective rate @xmath125 , eq .  ,",
    "is given by @xmath157 because the variance @xmath67 is zero during the absolute refractory period @xmath158 .",
    "as a result , the mesoscopic population equation ( [ eq : master - cont - a - inf - main ] ) reduces to the simple form @xmath159.\\ ] ] this mesoscopic equation is exact and could have been constructed directly in this simple case . for @xmath1 , where @xmath64 becomes identical to @xmath96 , this equation has been derived by wilson and cowan @xcite , see also @xcite .",
    "the intuitive interpretation of eq .",
    "( [ eq : wilson - cowan - abs - refract ] ) is that the activity at time @xmath26 consists of two factors , the `` free '' rate @xmath160 that would be expected in the absence of refractoriness and the fraction of actually available ( `` free '' ) neurons that are not in the refractory period . for finite - size populations ,",
    "these two factors explicitly reveal two distinct finite - size effects : firstly , the free rate is driven by the fluctuating population activity @xmath64 via eq .",
    "( [ eq : rate - eq ] ) and hence the free rate exhibits finite - size fluctuations .",
    "this effect originates from the transmission of the fluctuations through the recurrent synaptic connectivity .",
    "secondly , the fluctuations of the population activity impacts the refractory state of the population , i.e. the fraction of free neurons , as revealed by the second factor in eq .",
    "( [ eq : wilson - cowan - abs - refract ] ) .",
    "in particular , a large positive fluctuations of @xmath148 in the recent past reduces the fraction of free neurons , which causes a negative fluctuation of the number @xmath161 of expected firings in the next time step .",
    "therefore , refractoriness generates negative correlations of the fluctuations @xmath162 for small @xmath163 .",
    "we note that such a decrease of the expected rate would not have been possible if the correction term in eq .",
    "was absent .",
    "however , incorporating the effect of recent fluctuations ( i.e. fluctuations in the number of refractory neurons ) on the number of free neurons by adding the correction term , and thereby balancing the total number of neurons , recovers the correct equation  .",
    "the same arguments can be repeated in the general setting of eq .  .",
    "firstly , the conditional intensity @xmath54 depends on the past fluctuations of the population activity because of network feedback .",
    "secondly , the fluctuations lead to an imbalance of fluctuations in the number of neurons across different states of relative refractoriness ( i.e. fluctuations do not add up to zero ) which gives rise to the `` correction term '' , i.e. the second term on the r.h.s .",
    "of eq .  .",
    "the primary purpose of this study was the derivation of a general mesoscopic dynamics starting from a microscopic model of single neurons with spike history effects .",
    "although the resulting set of equations are generally too complicated for a direct analytical solution , the stochastic population equations provide a rapid means to integrate the population dynamics on a mesoscopic level . because the population equations do not scale with the number of neurons , we expect a significant speed - up factor for large neural networks compared to a corresponding microscopic simulation .",
    "for example , the microscopic simulation of the cortical column in fig .",
    "[ fig : potjans - scheme]b took 13.5 minutes to simulate 10 seconds of biological time , whereas the corresponding forward integration of the stochastic population dynamics ( fig .",
    "[ fig : potjans - scheme]d ) took only 6.6 seconds on the same machine ( see sec .  `` '' ) .",
    "the numerical integration of the population equation eq .   from time @xmath26 to @xmath164 relies on the approximation of the infinite integrals by discrete sums over a finite number of refractory states @xmath50 . as shown in methods , sec .",
    "`` '' , it is possible to rewrite the population equations only in terms of a relatively short history into the past , which can then be discretized into a finite number of time bins ( see methods , sec .  `` '' ) .",
    "concerning the first step , we divide the past into two epochs : the recent past of length @xmath165 that corresponds to the interval @xmath166 , and the remaining past corresponding to the time interval @xmath167 . for neurons that have their last spike time in the recent past",
    ", we have to explicitly account for the dependence of the conditional firing rate @xmath54 on the last spike time @xmath50 . since this dependence arises from ( relative )",
    "refractoriness , these neurons will be collectively termed _",
    "refractory neurons _ and the time window @xmath166 will be referred to as the _ refractory epoch_.    the size of the refractory epoch @xmath165 is chosen such that the collective effect of all neurons with @xmath168 on the population activity at time @xmath26 can be approximated by a common intensity @xmath169 .",
    "this `` free '' hazard rate depends only on the population activities @xmath97 for @xmath168 but is `` free '' from the explicit dependence on the last spike time @xmath50 .",
    "therefore , these neurons and the corresponding time range @xmath167 will be termed _",
    "free neurons _ and _ free epoch _ , respectively , in analogy to the discussion of the case of absolute refractoriness in the previous section . as shown in methods , sec .",
    "`` '' , this requires that @xmath165 is much larger than the typical relaxation time of the membrane potential to relax back to its resting potential after a spike .",
    "this time is usually set by the absolute refractory period and the membrane time constant @xmath153 .",
    "in addition to that , we require that @xmath165 is large enough such that for all @xmath168 the adaptation kernel @xmath170 is significantly below the softness @xmath171 of the threshold in the gif model , cf .",
    "the integrals of the population equation and can be split into two integrals corresponding to the free and refractory epoch .",
    "this splitting gives rise to the variables @xmath172 and @xmath173 representing the mean and variance of the number of free neurons , respectively .",
    "furthermore , the effective threshold of free neurons can be written in terms of the variables @xmath174 , where the time constants @xmath175 with @xmath176 represent the time scales of the adaptation kernel ( see methods , eq .  ) .",
    "importantly , the variables @xmath0 , @xmath177 and @xmath178 as well as the free membrane potential @xmath179 satisfy simple , ordinary differential equations , which capture the effect of the population activities before time @xmath180 .",
    "thus , the update of all neurons with refractory states with @xmath168 is fast and compactly implemented as a single iteration of @xmath181 variables . as a result , we have to explicitly memorize the history only for the refractory epoch , i.e. neurons with @xmath182 .    as a second step ,",
    "we discretize time such that the refractory epoch is subdivided into @xmath183 time bins of width @xmath23 , i.e. @xmath184 .",
    "let us denote the discrete time points by @xmath185 , @xmath84 .",
    "we identify the index @xmath186 with the current time @xmath26",
    "( i.e. @xmath187 ) and the index @xmath188 with the beginning of the refractory epoch , i.e. @xmath189 . the interval @xmath190 for @xmath191 is called the @xmath91-th time bin .",
    "each time bin of the refractory epoch is associated with its own conditional intensity @xmath192 , the expected number @xmath193 of neurons with last spike in the @xmath91-th time bin , the variance @xmath194 of this number , the membrane potential @xmath195 and threshold @xmath196 of the corresponding group of neurons .",
    "how large should we choose the time step @xmath23 ?",
    "at a first glance , the formal representation eq .   of the population activity as a shot noise with conditional intensity @xmath197 seems to require @xmath198^{-1}$ ] . however , this strict condition is not necessary because we do not need to resolve each single spike .",
    "rather it is sufficient to know the activity on a coarser time scale that results from many spikes generated by the population . as shown in methods , sec .",
    "`` '' , this only requires that @xmath23 is not larger than the absolute refractory period of the neurons and the transmission delay of spikes , and that during one time step the membrane potential and the threshold do not vary too much .",
    "one simple way to initialize the system is to fully synchronize the network at time @xmath199 such that at time @xmath200 all neurons are refractory .",
    "this gives rise to the sharp initial condition @xmath201 and @xmath202 for the refractory epoch ( @xmath203 ) .",
    "here , @xmath204 denotes the kronecker delta , which is unity for @xmath205 and zero otherwise .",
    "after synchronization there are no free neurons , hence @xmath206 and , if there were no further spikes in the past , @xmath207 for @xmath176 .",
    "the initialization of @xmath178 corresponds to a zero adaptation level at the beginning of the simulation .",
    "the population equations can now be evolved from time @xmath208 to time @xmath209 . a detailed explanation of the algorithm and a pseudocode implementation is given in methods , sec .  `` '' . in summary ,",
    "the following update steps have to be performed for all populations @xmath210 :    1 .",
    "calculate the total integrated input in voltage units ( cf .",
    ") @xmath211}}{{\\tau_\\text{s}}^\\beta-{\\tau_\\text{m}}^\\alpha}}\\right.\\\\ + \\left.\\frac{{\\tau_\\text{s}}^\\beta e^{-\\frac{\\delta t}{{\\tau_\\text{s}}^\\beta}}{\\left [ y^{\\alpha\\beta}(t_l)-a_n^\\beta(t_l-\\delta ) \\right]}-e^{-\\frac{\\delta t}{{\\tau_\\text{m}}^\\alpha}}{\\left [ { \\tau_\\text{s}}^\\beta y^{\\alpha\\beta}(t_l)-{\\tau_\\text{m}}^\\alpha a_n^\\beta(t_l-\\delta ) \\right]}}{{\\tau_\\text{s}}^\\beta-{\\tau_\\text{m}}^\\alpha}\\right\\}.\\end{gathered}\\ ] ] here , @xmath212 is an external stimulus and @xmath213 is a synaptic variable that filters the presynaptic activity arriving from population @xmath214 by a first - order kinetics with a synaptic time constant @xmath215 . for @xmath216 ,",
    "these variables are updated according to @xmath217}e^{-\\delta t/{\\tau_\\text{s}}^\\beta}.\\ ] ] 2 .",
    "update the free membrane potential @xmath179 and threshold variable @xmath178 for free neurons using the exact integration over one time step and use these values to compute their conditional intensity @xmath218 : @xmath219 here and in the following , the obvious population index @xmath17 is omitted .",
    "the firing probability of free neurons can now be computed as follows : + @xmath220\\delta t/2 \\right]}.\\ ] ] 3 .",
    "[ enum : u - update ] for all refractory states @xmath221 , compute @xmath222 where @xmath223 captures the effect of the last spike on the threshold and @xmath224 accounts for the baseline threshold @xmath225 and the effect of the spikes before the last one .",
    "the variables @xmath224 can be iterated rapidly by the following formula @xmath226 with @xmath227 and initial condition @xmath228 .",
    "this allows us to compute the firing probability of refractory neurons : @xmath229\\delta t/2 \\right]}.\\ ] ] 4 .",
    "[ enum : plam ] calculate the effective firing probability of `` neurons '' belonging to the `` holes and overshoots '' by the formula @xmath230 which corresponds to the discretized form of eq .  .",
    "[ enum : main ] calculate the expected activity @xmath231 by @xmath232 which is the discretized version of the population equation .",
    "the empirical population activity can be obtained by drawing a binomially distributed random number with mean @xmath233 and maximal value equal to the population size @xmath2 : @xmath234 here , @xmath2 and @xmath235 correspond to the number of `` bernoulli trials '' and `` success probability '' of the binomial distribution @xmath236 , respectively .",
    "[ enum : m - v - update ] update the mean and variance of the survival numbers as follows : @xmath237\\bar{m}_k(t_l ) \\\\",
    "v_k(t_{l+1})&=[1-p_{\\lambda}(t_l|t_k)]^2v_k(t_l ) + p_{\\lambda}(t_l|t_k)\\bar m_k(t_{l}).\\\\    x(t_{l+1})&=[1-p_{\\text{free}}(t_l)]x(t_l)+\\bar m_{l - k}(t_{l+1}),\\\\      z(t_{l+1})&=[1-p_{\\text{free}}(t_l)]^2z(t_l)+p_{\\text{free}}(t_l)x(t_l)+v_{l - k}(t_{l+1 } ) .",
    "\\end{aligned}\\ ] ] 7 .",
    "realize the boundary conditions at @xmath238 by setting : @xmath239    the algorithm involves the generation of only one random number ( in step [ enum : main ] ) per time step and population , whereas the microscopic simulation requires to draw a random number for each neuron per time step .",
    "furthermore , in contrast to the microscopic simulation , the algorithm does not scale with the system size .",
    "this makes it a convenient tool to explore the behavior of large but finite populations , for which a microscopic simulation is infeasible . whereas the complexity of the microscopic simulation is of order @xmath240 ,",
    "the integration of the population equation is of order @xmath241 because in each time step one has to update a history of length @xmath242 ( step [ enum : u - update ] , [ enum : plam ] and [ enum : m - v - update ] ) .",
    "hence , at low neuron numbers ( e.g. @xmath243 ) , the direct simulation of the microscopic system may become more efficient .",
    "we emphasize , however , that to achieve a comparable accuracy , the integration of the mesoscopic population equation can be performed on a coarser , millisecond time scale ( e.g. , @xmath244  ms ) , whereas the microscopic simulation requires precise spike times and hence a sub - millisecond simulation ( e.g. , @xmath245  ms ) . if we take advantage of this fact , the mesoscopic population model performs well even at low neuron numbers .",
    "in addition to the pseudocode in methods , a reference implementation of this algorithm to simulate neural population dynamics will be made publicly available as part of the neural simulation tool ( nest ) @xcite , https://github.com/nest/nest-simulator , as a module named gif_pop_psc_exp .",
    "we wondered how well the statistics of the population activities obtained from the integration of the mesoscopic equations compare with the corresponding activities generated by a microscopic simulation . as we deal with a finite - size system , not only to the first - order statistics ( mean activity ) but also higher - order statistics needs to be considered .",
    "because there are several approximations involved ( e.g. full - connectivity , quasi - renewal approximation and effective rate of fluctuations in the refractory density ) , we do not expect a perfect match . to compare first- and second - order statistics",
    ", we will mainly use the power spectrum of the population activities in the stationary state ( see methods , sec .  `` '' ) .",
    "[ [ mesoscopic - equations - capture - refractoriness . ] ] mesoscopic equations capture refractoriness .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    our theory describes the interplay between finite - size fluctuations and spike - history effects .",
    "the most prominent spike - history effect is refractoriness , i.e. the strong effect of the last spike on the current probability to spike . to study this effect ,",
    "we first focus on a population of uncoupled neurons with a constant threshold corresponding to leaky integrate - and - fire ( lif ) models without adaptation ( fig  [ fig : lif ] ) .",
    "the reset of the membrane potential after each spike introduces a period of relative refractoriness , where spiking is less likely due to a hyper - polarized membrane potential ( fig .",
    "[ fig : lif]a ) . because of the reset to a fixed value , the spike trains of the lif neurons are renewal processes . in the stationary state ,",
    "the fluctuation statistics as characterized by the power spectrum is known analytically for the case of a population of independent renewal spike trains ( eq .   in methods ) .",
    "such that @xmath246 increased from @xmath247  mv to @xmath248  mv ( top ) .",
    "voltage trace of one of 500 neurons ( bottom ) .",
    "stationary firing statistics ( rate and coefficient of variation ( cv ) of the interspike intervals ) corresponding to the two stimuli are indicated above the step current .",
    "( b ) realizations of the population activity @xmath64 for the microscopic ( top ) and mesoscopic ( bottom , blue line ) simulation .",
    "the magenta line shows the expected population rate @xmath96 given the past actual realization @xmath101 for @xmath45 .",
    "( c ) the power spectrum of the stationary activity @xmath64 obtained from renewal theory , eq .  , ( black solid line ) and from the mesoscopic simulation ( blue circles ) .",
    "the top and bottom panel corresponds to weak ( @xmath247  mv ) and strong ( @xmath248  mv ) constant stimulation ( transient removed ) . ]",
    "the empirical population activity @xmath64 fluctuates around the expected activity @xmath96 that exhibits a typical ringing in response to a step current stimulation @xcite .",
    "the time course of the expected activity as well as the size of fluctuations are similar for microscopic simulation ( fig .",
    "[ fig : lif]b , top ) and the numerical integration of the population equations ( fig .",
    "[ fig : lif]b , bottom ) .",
    "we also note that the expected activity @xmath96 is not constant in the stationary regime but shows weak fluctuations .",
    "this is because of the feedback of @xmath64 onto the dynamics of @xmath96 , eq .  .",
    "a closer inspection confirms that the fluctuations generated by the mesoscopic population dynamics in the stationary state exhibit the same power spectrum as the theoretically predicted one , which is given by eq .",
    "[ fig : lif]c ) .",
    "in particular , the mesoscopic equations capture the fluctuation statistics even at high firing rates , where the power spectrum strongly deviates from the white ( flat ) power spectrum of a poisson process ( fig .",
    "[ fig : lif]c bottom ) .",
    "the pronounced dip at low - frequencies is expected for neuronal refractoriness @xcite .",
    "[ [ mesoscopic - equations - capture - adaptation - and - burstiness . ] ] mesoscopic equations capture adaptation and burstiness .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +     that increased @xmath246 from @xmath249  mv to @xmath250  mv ( top ) .",
    "voltage trace of one neuron ( bottom ) .",
    "stationary firing statistics ( rate and coefficient of variation ( cv ) ) corresponding to the two stimuli are indicated above the step current .",
    "( b ) realizations of the population activity obtained from microscopic simulation ( black ) and mesoscopic population equation ( blue ) as well as @xmath96 ( magenta ) .",
    "( c ) power spectra corresponding to the stationary activity ( averaged over 1024 trials each of 20  s length ) at low and high firing rates as in ( a ) , circles and lines depict microscopic and mesoscopic case , respectively .",
    "parameters in ( a)(c ) : @xmath251  mv , @xmath252  mv , threshold kernel @xmath253 for @xmath254 with @xmath255  mv@xmath256s , @xmath257  s , @xmath258  mv@xmath256s , @xmath259  s. ( d ) bursty neuron model .",
    "( i ) biphasic threshold kernel @xmath260 , where a combination of a negative part ( facilitation ) and a positive part ( adaptation ) yields a bursty spike pattern , ( ii ) sample firing pattern of one neuron .",
    "( iii ) the interspike interval distribution with values of rate and cv .",
    "( e ) power spectrum of the population activity @xmath64 shown in ( d)-(iv ) .",
    "parameters in ( d ) and ( e ) : @xmath261 , @xmath251  mv , @xmath262  mv , @xmath263  s , facilitation : @xmath264  mv@xmath256s , @xmath265  s ; adaptation : @xmath266  mv@xmath256s , @xmath259  s ]    further important spike - history effects can be realized by a dynamic threshold . for instance , spike - frequency adaptation , where a neuron adapts its firing rate in response to a step current after an initial strong response ( fig .",
    "[ fig : bursting]a , b ) , can be modeled by an accumulating threshold that slowly decays between spikes @xcite . in simulations ,",
    "the mean population rate as well as the size of fluctuations appear to be the same for the microscopic and mesoscopic case ( fig .",
    "[ fig : bursting]b , top and bottom , respectively ) .",
    "the effect of adaptation on the fluctuation statistics is a marked reduction in the power spectrum at low frequencies , which is captured by our theory ( fig .",
    "[ fig : bursting]c ) .",
    "the small discrepancies compared to the microscopic simulation originate from the quasi - renewal approximation , which does not account for the individual spike history of a neuron before the last spike but only uses the population averaged history .",
    "this approximation is expected to work well if the threshold kernel changes slowly , effectively averaging the spike history locally in time @xcite .    in the case of fast changes of the threshold kernel , we do not expect that the quasi - renewal approximation holds .",
    "for example , a biphasic kernel @xcite with a facilitating part at short interspike intervals ( isi ) and an adaptation part for large isis ( fig .",
    "[ fig : bursting]d-(i ) ) can realize bursty spike patterns ( fig .",
    "[ fig : bursting]d-(ii ) ) .",
    "the burstiness is reflected in the isi density that exhibits a peak at small isis , corresponding to isis within a burst , and a tail that extends to large isis representing interburst intervals ( fig .",
    "[ fig : bursting]d-(iii ) ) .",
    "remarkably , the mesoscopic equations with the quasi - renewal approximation qualitatively capture the burstiness , as can be seen by the strong low - frequency power at about @xmath267  hz ( fig .",
    "[ fig : bursting]e ) . at the same time , the effect of adaptation manifests itself in a reduced power at even lower frequencies . as an aside",
    ", we note that facilitation which is strong compared to adaptation can lead to unstable neuron dynamics even for isolated neurons @xcite .",
    "[ [ recurrent - network - of - randomly - connected - neurons . ] ] recurrent network of randomly connected neurons .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    so far , we have studied populations of uncoupled neurons . this allowed us to demonstrate that the mesoscopic dynamics captures effects of single neuron dynamics on the fluctuations of the population activity .",
    "let us now suppose that each neuron in a population @xmath17 is randomly connected to presynaptic neurons in population @xmath214 with probability @xmath268 such that the in - degree is fixed to @xmath269 connections . in the presence of synaptic coupling ,",
    "the fluctuations at time @xmath26 are propagated through the recurrent connectivity and may significantly influence the population activity at time @xmath270 .",
    "for instance , in a fully - connected network ( @xmath271 ) of excitatory and inhibitory neurons ( e - i network , fig .  [ fig : ei - net]b , c ) , all neurons within a population receive identical inputs given by the population activities @xmath11 ( cf .",
    "finite - size fluctuations of @xmath11 generate common input to all neurons and tend to synchronize neurons .",
    "this effect manifests itself in large fluctuations of the population activity ( fig .",
    "[ fig : ei - net]b ) .",
    "since the mean - field approximation of the synaptic input becomes exact for a fully - connected network , we expect a good match between the microscopic and mesoscopic simulation in this case .",
    "interestingly , the power spectra of the population activities obtained from these simulations coincide well even for an extremely small e - i network consisting of only one inhibitory and four excitatory neurons ( fig .  [",
    "fig : ei - net]c ) . the power spectra reveal pronounced oscillations that are induced by finite size fluctuations @xcite .",
    "the amplitude of these stochastic oscillations decreases as the network size increases and vanishes in the large-@xmath2 limit .",
    "if the network is not fully but randomly - connected ( @xmath272 ) , neurons still share a part of the finite - size fluctuations of the population activity .",
    "earlier theoretical studies @xcite have pointed out that these common fluctuations inevitably yield correlated and partially synchronized neural activity , as observed in simulations ( fig .",
    "[ fig : ei - net]d , f ) .",
    "this genuine finite - size effect vanishes in the large-@xmath2 limit @xcite ( asynchronous state ) , as indicated by simulations of larger networks ( fig .",
    "[ fig : ei - net]c , e ) .",
    "as argued in previous studies @xcite , the fluctuations of the synaptic input can be regarded as consisting of two components , a coherent and an incoherent one .",
    "the coherent fluctuations are given by the fluctuations of the population activity and are thus common to all neurons of a population .",
    "this component is exactly described by our mesoscopic theory .",
    "the incoherent fluctuations are caused by the quenched randomness of the network ( i.e. each neuron receives input from a different subpopulation of the network ) and have been described as independent white - noise input currents for each neuron in earlier studies @xcite but are neglected here . for a large number of inputs @xmath273 and not too small @xmath274 ( dense connectivity ) , the incoherent contribution is expected to be small because it averages out , whereas the coherent component dominates .",
    "this is indeed indicated by simulation results ( fig .",
    "[ fig : ei - net]e and g ) .",
    "remarkably , even for @xmath275 synapses per neuron and @xmath276 , the mesoscopic model agrees well with the macroscopic model .",
    "however , if both @xmath277 and @xmath274 are small , the mesoscopic theory breaks down as expected ( fig .",
    "[ fig : ei - net]g , blue circles ) .    , connection probability @xmath274 and number of synapses per neuron @xmath277 . *",
    "+ ( a ) left : schematic of the network of @xmath278 excitatory and @xmath279 inhibitory leaky integrate - and - fire ( lif ) neurons , each receiving @xmath280 ( @xmath281 ) connections from a random subset of excitatory ( inhibitory ) neurons .",
    "total numbers are @xmath282 and @xmath283 . at @xmath275 ,",
    "the synaptic strength is @xmath284  mv and @xmath285  mv for excitatory and inhibitory connections , respectively . to preserve a constant mean synaptic input , the synaptic strength",
    "is scaled such that @xmath286 .",
    "right : schematic of a corresponding mesoscopic model of two interacting populations .",
    "( b ) trajectories of @xmath287 for five example neurons ( top ) and of the excitatory population activity @xmath288 obtained from the network simulation ( middle ) and the mesoscopic simulation ( bottom , dark green ) for @xmath289 ; time resolution @xmath290  ms . the light green trajectory ( bottom panel )",
    "depicts the expected population activity @xmath291 given the past activity .",
    "( c ) power spectra of @xmath288 for different network sizes while keeping @xmath271 fixed ( microscopic : symbols , mesoscopic : solid lines with corresponding dark colors ) .",
    "( d ) sample trajectories corresponding to the green curve in ( e ) ( @xmath292 , @xmath293 ) . ( e )",
    "analogously to ( c ) but varying the connection probabilities while keeping @xmath294 fixed .",
    "( f ) sample trajectories corresponding to the green curve in ( g ) ( @xmath295 , @xmath296 ) . (",
    "g ) analogously to ( c ) but varying the number of synapses @xmath277 while keeping @xmath295 fixed .",
    "note that the mesoscopic theory ( black solid line ) is independent of @xmath277 because the product @xmath297 , which determines the interaction strength in the mesoscopic model ( see , left panel of ( a ) ) , is kept constant .",
    "parameters : @xmath298  mv , @xmath299  mv and @xmath300 ( no adaptation).,width=720 ]    [ [ finite - size - induced - switching - in - bistable - networks . ] ] finite - size induced switching in bistable networks .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    ) interact with a common inhibitory population ( @xmath301 ) .",
    "( b)-(d ) in the absence of adaptation ( @xmath300 ) , the excitatory populations switch between low and high activities in an irregular fashion ( b ) .",
    "activities in ( b , e ) are low - pass - filtered by a moving average of @xmath302  ms .",
    "top : full network simulation .",
    "inset : magnified view of the activities for @xmath267  s ( without moving average ) showing fast large - amplitude oscillations .",
    "bottom : mesoscopic simulation .",
    "( c ) the power spectrum of the activity of the excitatory populations exhibits large low - frequency power and a high - frequency peak corresponding to the slow stochastic switching between high- and low - activity states and the fast oscillations , respectively .",
    "( d ) the density of the dominance times ( i.e. the residence time in the high - activity states ) has an exponential form .",
    "( e - g ) like ( b - d ) but excitatory neurons exhibit weak and slow adaptation ( @xmath303 with @xmath304  mv@xmath256s , @xmath305  s for @xmath254 ) . switching between high- and low - activity states is more regular than in the non - adapting case as revealed by a low - frequency peak in the power spectrum ( f ) and a narrow , unimodal density of dominance times ( g ) . in ( c ,",
    "d ) and ( f , g ) microscopic and mesoscopic simulation correspond to cyan symbols / bars and dark blue solid lines , respectively .",
    "parameters : @xmath306  mv except for @xmath307 in ( e - g ) to compensate adaptation .",
    "time step @xmath308  ms ( microscopic ) , @xmath290  ms ( mesoscopic ) .",
    "efficacies of excitatory and inhibitory connections : @xmath309  mv and @xmath310  mv ( b - d ) , and @xmath311  mv and @xmath312  mv ( e - g ) , @xmath271 , @xmath299  mv .",
    ", width=720 ]    in large but finite e - i networks , the main effect of weak finite - size fluctuations is to distort the deterministic population dynamics of the infinitely large network ( stable asynchronous state or limit cycle motion ) leading to stochastic oscillations and phase diffusion that can be understood analytically by linear response theory @xcite and weakly nonlinear analysis @xcite .",
    "this is qualitatively different in networks with multiple stable states . in such networks",
    ", finite - size fluctuations may have a drastic effect because they enable large switch - like transitions between metastable states that can not be described by a linear or weakly nonlinear theory .",
    "we will show now that our mesoscopic population equation accurately captures strongly nonlinear effects , such as large fluctuations in multistable networks .",
    "multistability in spiking neural networks can emerge as a collective effect in balanced e - i networks with clustered connectivity @xcite , and , generically , in networks with a winner - take - all architecture , where excitatory populations compete through inhibitory interactions mediated by a common inhibitory population ( see , e.g. @xcite and fig .",
    "[ fig : bistable]a ) . jumps between metastable states have been used to model switchings in bistable perception @xcite . to understand such finite - size induced switching in spiking neural networks on a qualitative level , phenomenological rate models have been usually employed @xcite . in these models ,",
    "stochastic switchings are enabled by noise added to the deterministic rate equations in an _ ad hoc _ manner .",
    "our mesoscopic mean - field equations keep the spirit of such rate equations , however with the important difference that the noisy dynamics is systematically derived from the underlying spiking neural network without any free parameter . here",
    ", we show that the mesoscopic mean - field equations _",
    "quantitatively _ reproduce finite - size induced transitions between metastable states of spiking neural networks .",
    "we emphasize that the switching statistics depends sensitively on the properties of the noise that drive the transitions @xcite .",
    "therefore , an accurate account of finite - size fluctuations is expected to be particularly important in this case .",
    "we consider a simple bistable network of two excitatory populations with activities @xmath313 and @xmath314 , respectively , that are reciprocally connected to a common inhibitory population with activity @xmath315 ( fig .",
    "[ fig : bistable]a ) .",
    "we choose the mean input and the connection strength such that in the large-@xmath2 limit the population activities exhibited two stable equilibrium states , one corresponding to a situation , where @xmath313 is high and @xmath314 is low , the other state corresponding to the inverse situation , where @xmath313 is low and @xmath314 is high .",
    "we found that in smaller networks , finite - size fluctuations are indeed sufficient to induce transitions between the two states leading to repeated switches between high- and low - activity states ( fig .",
    "[ fig : bistable]b , e ) .",
    "the regularity of the switching appears to depend crucially on the presence of adaptation , as has been suggested previously @xcite .",
    "remarkably , both in the presence and absence of adaptation , the switching dynamics of the spiking neural network appears to be well reproduced by the mesoscopic mean - field model .    for a more quantitative comparison ,",
    "we use several statistical measures that characterize the bistable activity .",
    "let us first consider the case without adaptation . as before , we compare the power spectra of the population activity for both microscopic and mesoscopic simulation and find a good agreement ( fig .",
    "[ fig : bistable]c ) .",
    "the peak in the power spectrum at relatively high - frequency reveals strong , rapid oscillations that are visible in the population activity after a switch to the high - activity state ( inset of fig .",
    "[ fig : bistable]b with magnified view ) .",
    "in contrast , the large power at low frequencies corresponds to the slow fluctuations caused by the switching of activity between the two excitatory populations , as revealed by the low - pass filtered population activity ( fig .",
    "[ fig : bistable]b ) .",
    "the lorentzian shape of the power spectrum caused by the slow switching dynamics is consistent with stochastically independent , exponentially distributed residence times in each of the two activity states ( i.e. , a homogeneous poisson process ) . in models for perceptual bistability ,",
    "residence times in the high - activity state are usually called dominance times .",
    "the dominance time distribution shows indeed a monotonic , exponential decay ( fig .",
    "[ fig : bistable]d ) both in the microscopic and mesoscopic model .",
    "furthermore , residence times do not exhibit significant serial correlations ( data not shown ) .",
    "together , this confirms the poissonian nature of bistable switching in the absence of adaptation .    in the presence of weak adaptation of excitatory neurons ,",
    "the population activity strongly increases when the population enters a high - activity state followed by slow decay to a somewhat smaller , stationary activity ( fig .",
    "[ fig : bistable]e ) .",
    "eventually , the population jumps back to the low - activity state .",
    "the switching dynamics is much more regular with than without adaptation leading to slow stochastic oscillations as highlighted by a second peak in the power spectrum at low frequencies ( fig .",
    "[ fig : bistable]f ) and a narrow distribution of dominance times ( fig .",
    "[ fig : bistable]g ) .",
    "this is in line with previous theoretical studies @xcite .",
    "we emphasize , however , that in contrast to these studies the underlying deterministic dynamics for @xmath1 is in our case not oscillatory but bistable , because the adaptation level is below the critical value necessary in the deterministic model to switch back to the low - activity state .",
    "the emergence of regular switching due to finite - size noise can be understood by interpreting the residence time of a given population in the high - activity state as arising from two stages : ( i ) the initial transient of the activity to a decreased ( but still large ) stationary value due to adaptation and ( ii ) the subsequent noise - induced escape from the stationary adapted state .",
    "the first stage is deterministic and hence does not contribute to the variability of the residence times .",
    "the variability results mainly from the second stage .",
    "the duration of the first stage is determined by the adaptation time scale .",
    "if this time covers a considerable part of the total residence time , we expect that the coefficient of variation ( cv ) , defined as the ratio of standard deviation and mean residence time , is small . in the case without adaptation ,",
    "a deterministic relaxation stage can be neglected against the mean noise - induced escape time so that the cv is larger .",
    "[ [ mesoscopic - dynamics - of - cortical - microcolumn . ] ] mesoscopic dynamics of cortical microcolumn .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    .",
    "circles and blue solid line show microscopic simulation ( 250 trials , simulation time step @xmath308  ms ) and mesoscopic simulation ( 1000 trials , @xmath12  ms ) , respectively .",
    "a step current mimicking thalamic input is provided to neurons in layer 4 and 6 during a time window of 30 ms as indicated by the gray bar .",
    "rows correspond to the layers l2/3 , l4 , l5 and l6 , respectively , as indicated .",
    "columns correspond to excitatory and inhibitory populations , respectively .",
    "( b ) corresponding , time - dependent standard deviation of @xmath64 measured with temporal resolution @xmath12  ms . ]     in the modified potjans - diesmann model in the absence of time - dependent thalamic input ( corresponding to the activities shown in fig .",
    "[ fig : potjans - scheme]b ( microscopic ) and fig .",
    "[ fig : potjans - scheme]d ( mesoscopic ) outside of the stimulation window . circles and blue solid lines represent microscopic and mesoscopic simulation , respectively .",
    "rows correspond to the layers l2/3 , l4 , l5 and l6 , respectively , as indicated .",
    "columns correspond to excitatory and inhibitory populations , respectively . ]    as a final example , we applied the mesoscopic population equations to a biologically more detailed model of a local cortical microcircuit .",
    "specifically , we used the multi - laminar column model of v1 proposed by potjans and diesmann @xcite .",
    "it consists of about @xmath316 non - adapting integrate - and - fire neurons organized into four layers ( l2/3 , l4 , l5 and l6 ) , each accommodating an excitatory and an inhibitory population ( see schematic in fig .  [",
    "fig : potjans - scheme]a ) .",
    "the neurons are randomly connected within and across the eight populations .",
    "we slightly changed this model to include spike - frequency adaptation of excitatory neurons , as observed in experiments ( see e.g. @xcite ) .",
    "furthermore , we replaced the poissonian background noise in the original model by an increase of mean current drive and escape noise ( both in the microscopic and mesoscopic model ) .",
    "the mean current drive was chosen such that the firing rates of the spontaneous activity were matched to the firing rates in the original model .",
    "we note that the fitting of the mean current was made possible by the use of our population equations , which allow for an efficient evaluation of the firing rates .",
    "the complete set of parameters is listed in tab .",
    "[ parampotjans ] .",
    "sample trajectories of the population activities have already served as an illustration of our approach in fig .",
    "[ fig : potjans - scheme ] , where neurons in layer 4 and 6 are stimulated by a step current of 30 ms duration , mimicking input from the thalamus as in the original study @xcite . individual realizations obtained from the microscopic and mesoscopic simulation differ due to the marked stochasticity of the population activities ( fig .",
    "[ fig : potjans - scheme]b , d ) . however , trial - averaging reveals that the mean time - dependent activities ( `` psth '' ) obtained from microscopic and mesoscopic simulations indeed agree well ( fig .",
    "[ fig : potjans_psth]a ) .",
    "moreover , the fluctuations around the mean , as expressed by the time - dependent standard deviation , are also predicted quantitatively by the mesoscopic mean - field theory ( fig .",
    "[ fig : potjans_psth]b ) . a closer look at the second - order statistics , as provided by the power spectra of spontaneous activities ( `` ground state '' of cortical activity ) , also reveals a good agreement at all frequencies ( fig .",
    "[ fig : potjans_spectra]b ) .",
    "this agreement is remarkable in view of the low connection probabilities ( @xmath317 , see table 5 in @xcite ) that violate the assumption of dense random connectivity used in the derivation of the mesoscopic mean - field equations .",
    "more generally , this example demonstrates that the range of validity of our mesoscopic theory covers relevant cortical circuit models .    finally , we mention that the numerical integration of the mesoscopic population equations yields a significant speed - up compared to the microscopic simulation . while a systematic and fair comparison of the efficiencies depends on many details and",
    "is thus beyond the scope of this paper , we note that a simulation on a single core of 10s of biological time took 811.2s using the microscopic model , whereas the mesoscopic model only took 6.6s .",
    "this corresponds to a speed - up factor of around 120 achieved by using the mesoscopic population model . in the simulation , we employed the same integration time step of @xmath12  ms for both models for a first naive assessment of the performance .",
    "however , a more detailed comparison of the performance should be based on simulation parameters that achieve a given accuracy . in this case",
    ", we expect an even larger speed - up of the mesoscopic simulation because for the same accuracy the temporally coarse - grained population equations allow for a significantly larger time step than the microscopic simulation of spiking neurons .",
    "in the present study we have derived stochastic population equations that govern the evolution of mesoscopic neural activity arising from a finite number of neurons . to our knowledge , this is the first time that such a mesoscopic dynamics has been derived from an underlying microscopic model of spiking neurons with pronounced spike - history effects .",
    "the microscopic model consists of interacting homogeneous populations of generalized integrate - and - fire ( gif ) neuron models @xcite , or alternatively , spike - response ( srm ) @xcite or generalized linear models ( glms ) @xcite . these classes of neuron models account for various spike - history effects like refractoriness and adaptation @xcite .",
    "importantly , parameters of these models can be efficiently extracted from single cell experiments @xcite providing faithful representations of real cortical cells under somatic current injection .",
    "the resulting population equations on the mesoscopic level yield the expected activity of each population at the present time as a functional of the population activities at past times . given the expected activities at the present time ,",
    "the actual mesoscopic activities can be obtained by drawing independent random numbers .",
    "the derived mesoscopic dynamics captures nonlinear emergent dynamics as well as finite - size effects , such as noisy oscillations and stochastic transitions in multistable networks .",
    "realizations generated by the mesoscopic model have the same statistics as the original microscopic model to a high degree of accuracy .",
    "the equivalence of the population dynamics ( mesoscopic model ) and the network of spiking neurons ( microscopic model ) holds for a wide range of population sizes and coupling strengths , for time - dependent external stimulation , random connectivity within and between populations , and even if the single neurons are bursty or have spike - frequency adaptation .",
    "our theory provides a general framework to replace spiking neural networks that are organized into homogeneous populations by a network of interacting mesoscopic populations .",
    "for example , the excitatory and inhibitory neurons of a layer of a cortical column @xcite may be represented by one population each , as in fig .",
    "[ fig : potjans - scheme ] . weak heterogeneity in the neuronal parameters are allowed in our theory because the mesoscopic equations describe the population - averaged behavior .",
    "further subdivisions of the populations are possible , however , such as a subdivision of the inhibitory neurons into fast - spiking and non fast - spiking types @xcite .",
    "populations that show initially a large degree of heterogeneity can be further subdivided into smaller populations . in this case",
    ", a correct description of finite - size fluctuations , as provided by our theory , will be particularly important .",
    "however , as with any mean - field theory , we expect that our theory breaks down if neural activity and information processing is driven by a few `` outlier '' neurons such that a mean - field description becomes meaningless .",
    "further limitations may result from the mean - field and quasi - renewal approximation , eq .  , which requires dense connectivity and slow threshold dynamics .",
    "however , as we have demonstrated here , our mesoscopic population equations may provide excellent predictions even for sparse connectivity ( fig .",
    "[ fig : ei - net]d - g ,  [ fig : potjans_psth ] and  [ fig : potjans_spectra ] ) and may qualitatively reproduce the mesoscopic statistics in the presence of fast threshold dynamics ( fig .",
    "[ fig : bursting]d , e ) .    using our mesoscopic population equations it is possible to make specific predictions about the response properties of local cortical circuits",
    ". for instance , recent progress in genetic methods now enables experimentalists to selectively label and record from genetically identified cell types , such as intratelencephalic ( it ) , pyramidal tract ( pt ) and corticothalamic ( ct ) neurons among the excitatory neurons , and vasoactive intestinal peptide ( vip ) , somatostatin ( sst ) and parvalbumin ( pvalb ) expressing neurons among the interneurons @xcite .",
    "these cell types have received much attention recently as it has been proposed that they may form a basic functional module of cortex , the canonical circuit @xcite .",
    "the genetic classification of cells defines subpopulations of the cortical network",
    ". a model of the canonical circuits of the cortex in terms of interacting mesoscopic populations can be particularly useful if used to describe experiments that use optogenetic stimulation of genetically - defined populations by light , which in our framework can be represented as a transient external input current . to build a mesoscopic population model based on our theory demands some assumptions about microscopic parameters such as ( i ) typical neuron parameters for each subpopulation , ( ii ) structural parameters as characterized by average synaptic efficacies and time scales of connections between and within populations , and ( iii ) estimates of neuron numbers per subpopulation .",
    "parameters for a typical neuron of each population could be extracted by the efficient fitting procedures presented in @xcite .",
    "structural parameters and neuron numbers have been estimated , for instance , for barrel columns in rodents somato - sensory cortex @xcite and other studies ( see e.g. , @xcite ) .",
    "our population equations could then be used to make predictions about circuit responses to light stimuli , e.g. by imaging the activity of a genetically - defined subpopulation in one column in response to optogenetic stimulation of another cell class in another column .    as a first step in this direction ,",
    "we have demonstrated here that our population equations correctly predict the mesoscopic activities ( means and fluctuations ) of a simulation of a detailed , microscopic network model of a cortical microcircuit @xcite under thalamic stimulation of layer 4 and 6 neurons .",
    "predicting activities in real experiments is , however , complicated by the fact that the parameters of a microscopic network model are typically underconstrained given the lack or uncertainty of measured or estimated parameters @xcite . here , our population equations provide an efficient means to constrain unknown microscopic parameters by requiring consistence with mesoscopic experimental data .    while the canonical circuit represents a model of interacting populations on the mesoscopic level ,",
    "recent interest in macroscopic models of entire brain areas or even of whole brains has risen @xcite .",
    "population dynamics can be used in this context as a means to reduce large parts of the macroscopic neuronal network to a system of interacting populations that is numerically manageable , and requires less detailed knowledge of synaptic connectivity ( mean synaptic coupling of populations as opposed to individual synapses ) . however ,",
    "even this information about mesoscopic network structure might not be available given that it corresponds to an @xmath318 matrix of mean synaptic efficacies , where the number @xmath319 of populations , or respectively cell types , might be large . in this case , our population equations can be utilized to efficiently constrain unknown structural parameters , such as synaptic weights , such that the resulting mesoscopic activities are consistent with experimental data .",
    "this leads in turn to experimentally testable predictions for synaptic connectivities .",
    "such an approach @xcite has been recently applied to a network model of primate visual cortex demonstrating the usefulness of mean - field theories for predicting structural properties of large - scale cortical networks .",
    "an interesting complementary route for further studies is a multiscale model , in which a large - scale model is simulated in terms of reduced , mesoscopic populations but with one or several areas in focus that are simulated in full microscopic detail .",
    "as knowledge of anatomy and computational capacity increases , more and more mesoscopic populations can be replaced by a microscopic simulation , while at any time in this process the full system is represented in the model .",
    "we therefore expect our population dynamics model to be a useful tool to continuously integrate experimental data into multiscale models of whole mammalian brains .",
    "simplified whole brain models of interacting neuronal areas have recently been proposed @xcite .",
    "furthermore , large - scale neuro imaging data are routinely modeled by phenomenological population models such as neural mass , wilson - cowan , or neural field models @xcite .",
    "our new population dynamics theory could be used in such approaches as an accurate representation of the fluctuations of neural activity in the reduced areas .",
    "for example , in macroscopic recording data such as resting state fmri , eeg or meg , the endogenously generated fluctuations of brain activity are of major interest @xcite .",
    "a fortiori the same applies to mesoscopic data such as local field potentials ( lfp ) or voltage - sensitive dye ( vsd ) , in which finite - size fluctuation are expected to be large .",
    "our theory paves the way for relating macroscale fluctuations to the underlying networks of spiking neurons and their activity , and so to the neuronal circuits that underlie the computations of the brain .",
    "another interesting application of our population model is to predict the activity of neural networks grown in cultures .",
    "this model system is much more accessible and controllable ( e.g. , by optogenetic stimulations ) than cortical networks in - vivo but may still provide valuable insights into the complex network activity of excitatory and inhibitory neurons as proposed in a recent study @xcite . in particular , in that study the authors propose a critical role for short - term plasticity @xcite .",
    "although we have here used static synapses , an extension of our mesoscopic mean - field theory to synaptic short - term plasticity is feasible .",
    "furthermore , finite - size fluctuations appear to be particularly important in cell cultures as suggested by a previous theoretical study @xcite .",
    "our mesoscopic population theory thus represents a framework to predict spontaneous as well as evoked activity in neuronal cell cultures .      from a theoretical point of view , the major advancement of our study is the generalization of _ deterministic _ population equations that describe the dynamics of macroscopic populations of spiking neurons @xcite to _ stochastic _ population equations that capture the mesoscopic case of finite neuron numbers .",
    "the resulting dynamics can be directly used to generate stochastic samples of mesoscopic activities , in analogy to a langevin dynamics .",
    "although similar in spirit , our work thus differs from the study of buice and chow @xcite , who also considered a finite network spiking neurons but derived deterministic evolution equations for the moments of the population activities .    outside the low - rate poisson firing regime ,",
    "spiking neurons exhibit history dependencies in their spike trains , the most prominent of which is neuronal refractoriness , i.e. the strongly reduced firing probability depending on the time since the last spike . on the population level",
    "this means that a positive ( negative ) fluctuation of the population rate affects the underlying refractory state of the population because more ( less ) neurons than expected become refractory .",
    "this altered refractory state in turn tends to decrease ( increase ) the mean and variance of the population activity shortly after the fluctuation .",
    "more generally , fluctuations in the population activity influence the population density of the microscopic state variables in a specific way , which in turn influences fluctuations . in this study , we have worked out how to incorporate this interplay between fluctuations and refractoriness into a mesoscopic population dynamics .",
    "the key to achieve this was to exploit the normalization of the density of microscopic states ( in our case , the density of last spike times ) as well as the variability profile of the density across states due to finite - size fluctuations ( in our case , the variance @xmath67 of the density of last spike times @xmath50 ) .",
    "our work is thus in marked contrast to previous stochastic rate models for finite - size systems in the form of stochastic wilson - cowan equations @xcite , or stochastic neural field equations @xcite . in these models , finite - size fluctuations of the rate",
    "may feed back through the recurrent connections but the self - feedback caused by refractoriness is neglected .",
    "this is the case even if the stationary or dynamic transfer function employed in the rate dynamics corresponds to a spiking neuron model @xcite .",
    "furthermore , fluctuations of the population rate have often been implemented _ ad hoc _ by a phenomenological white - noise source , which was added to the macroscopic ( i.e. deterministic ) rate dynamics @xcite .",
    "the intensity of the noise is a free parameter in these cases .",
    "our mesoscopic equations are also driven by a noise source , but two differences are noteworthy : first , it is derived from a microscopic model and does not contain any free parameter ; and second , the noise is white _ given _ the predicted mean activity but since the activity predicted in one time step depends on fluctuations in all earlier time steps , the effective noise leads to a colored noise spectrum  even if coupling is removed ( see fig .",
    "[ fig : lif ] ) .",
    "this observation is consistent with our previous study @xcite , in which the power spectrum of the fluctuations about a steady - state has been calculated analytically .    on the population level",
    ", refractoriness can be taken into account by population density equations such as the fokker - planck equation for the membrane potential density ( see e.g. @xcite ) or the population integral equation for the refractory density @xcite .",
    "these studies were mainly concerned with macroscopic populations , which formally correspond to the limit @xmath1 . here , we have shown how to adjust the population integral equation in the presence of finite - size fluctuations of the population rate , in order to correct for the missing normalization of the mesoscopic density ( e.g. @xmath65 in eq .   or @xmath320 in eq .  ) , and hence to account for the interplay between fluctuations and refractoriness .",
    "finite - size fluctuations of the population rate have also been used in the fokker - planck formalism @xcite but the effect of these fluctuations on the refractoriness as expressed by the membrane potential density has been neglected . in terms of the membrane potential density ,",
    "a positive ( negative ) fluctuation of the population rate decreases ( increases ) the number of neurons close to the threshold , which implies that the mesoscopic density is no longer normalized .",
    "the numerical integration of the finite-@xmath2 fokker - planck equation of mattia and del giudice @xcite seems to be a satisfying solution in the poissonian firing regime at low rates , where refractory effects can be neglected . at higher rates ,",
    "however , this approach becomes unstable unless the membrane potential density is renormalized manually at every time step @xcite .",
    "how to correct for the missing normalization in the fokker - planck approach is still an unsolved theoretical question . in this respect , using analogies to and insights from our approach might be promising .",
    "the quasi - renewal approximation @xcite allowed us to develop a finite - size theory for an effectively one - dimensional population density equation even in the presence of adaptation . here , the only microscopic state variable is the last spike time @xmath50 , or equivalently the age of the neuron @xmath321 .",
    "longer lasting spike history effects such as adaptation are captured by the dependence of the conditional intensity on the population activity @xmath148 , which as a mesoscopic mean - field variable does not need to be treated as a state variable but only enters the density equations as a `` parameter '' .",
    "this one - dimensional description has great advantages compared to population density equations that include additional adaptation variables and thus require a multi - dimensional state - space @xcite : firstly , the numerical solution of the density equations grows exponentially with the number of dimensions , which becomes quickly infeasible if multiple adaptation variables are needed as e.g. in the case of multi - timescale adaptation @xcite or if an adiabatic approximation of slow variables @xcite is not possible .",
    "secondly , it is unclear how to treat finite - size fluctuations in the multi - dimensional case .",
    "our theory is based on an effective fully - connected network , in which neurons are coupled by the actual realization of the stochastic population activity ( the `` mean field '' ) , both in the microscopic and mesoscopic model .",
    "thus , in the limit of a fully - connected network , the problem of self - consistently matching the input and output statistics , which arises in mean - field theories , is automatically satisfied to any order by our finite - size theory .",
    "this is in marked contrast to the opposite limit of a sparsely - connected network @xcite . in that case , the mean - field variables correspond to the _ statistics _ of the spike trains ( e.g. rate and auto - correlation function ) rather than to the actual realization of the population activity .",
    "these statistics must be matched self - consistently for input and output , which is a hard theoretical problem @xcite .",
    "between these two limit cases , where the network is randomly connected with some finite connection probability @xmath272 , our examples ( fig .",
    "[ fig : ei - net ] , [ fig : potjans_psth ] and [ fig : potjans_spectra ] ) indicate that the approximation by an effective fully - connected network can still yield reasonable results even for relatively sparse networks with @xmath322 .",
    "we emphasize that in our microscopic network model we used a fixed in - degree in order to avoid additional variability due to the quenched randomness in the number of synapses .",
    "this allowed us to focus on dynamic finite - size noise in homogeneous populations and its interactions with refractoriness .",
    "in contrast , the heterogeneity caused by the quenched randomness is a further finite - size effect @xcite that needs to be examined in a future study .    as an integral equation ,",
    "the mesoscopic population model is formally infinitely dimensional and represents a non - markovian dynamics for the population activity @xmath148 .",
    "such complexity is expected given that the derived population equations are general and not limited to a specific dynamical regime .",
    "loosely speaking , the equations must be rich enough , and hence sufficiently complex , in order to reproduce the rich repertoire of dynamical regimes that fully connected networks of spiking neurons are able to exhibit ( e.g. limit cycles , multi - stability , cluster states @xcite ) . for a mathematical analysis , however , it is often desirable to have a low - dimensional representation of the population dynamics in terms of a few differential equations , at least for a certain parameter range .",
    "apart from the dynamics about an equilibrium point ( see e.g. @xcite ) or in the limit of slow synapses @xcite , such `` firing rate models '' are difficult to link to the microscopic model already in the deterministic ( macroscopic ) case ( for a notable exception see @xcite ) , let alone the stochastic , finite - size case . here , our mesoscopic population rate equations can serve as a suitable starting point for deriving low - dimensional dynamics that links microscopic models to mesoscopic rate equations with realistic finite - size noise .    here",
    ", we have used a discrete set of populations . in large - scale models of the brain ,",
    "one often regards the spatial continuum limit , resulting in so - called stochastic neural field equations @xcite .",
    "these equations represent a compact description of neural activity and do not depend on a specific discretization of space . just as discrete firing rate models",
    ", these field equations must be considered phenomenological because the link to neuronal parameters is not clear ( note however that such equations have been derived from non - spiking , two - state neuron models for @xmath323 @xcite , and from spiking models for @xmath1 @xcite ) . by taking the spatial continuum limit ,",
    "our mesoscopic population equations can be formulated as a stochastic neural field equation that is directly derived from a finite - size , spiking neural network .",
    "it would be interesting to employ this continuous extension of our mesoscopic equations to study the effect of spike - history effects on the stochastic behavior of bumps and waves in neural fields .    a first simple comparison of the computational performance in results , `` mesoscopic dynamics of cortical microcolumn '' , demonstrated already that the mesoscopic population dynamics outperformed the microscopic simulation by a speed - up factor of around 120 . in this example",
    ", the numerical integration of the population dynamics has not been particularly optimized with respect to time step @xmath23 and history length @xmath165 .",
    "a systematic comparison under the condition of some given accuracy , has the potential for an even larger speed - up because the population equations can be integrated with a larger time step than the spiking neural network .",
    "these computational aspects will be investigated in a separate study .",
    "[ [ network - setup . ] ] network setup .",
    "+ + + + + + + + + + + + + +    we consider a network of @xmath319 populations each consisting of @xmath18 interconnected neurons of the same type ( the superscript @xmath210 labels the populations ) .",
    "neuron @xmath7 in population @xmath17 receives @xmath269 connections ( synapses ) from a random subset @xmath324 of presynaptic neurons in population @xmath214 . here",
    ", @xmath268 denotes the probability for a connection from a neuron in population @xmath214 to a neuron in population @xmath17",
    ". that is , the connections between any two populations are random with fixed in - degree .",
    "let the spike train of neuron @xmath7 in population @xmath17 be denoted by @xmath325 where @xmath22 is its @xmath91-th spike time and @xmath21 denotes the dirac @xmath21-function .",
    "the neuron receives spike train input from its presynaptic partners in population @xmath214 with a transmission delay @xmath326 and synaptic weight @xmath327 .",
    "more precisely , the synaptic input current @xmath328 is modeled as a sum of post - synaptic currents caused by each spike of presynaptic neurons : @xmath329 where @xmath330 and @xmath331 are the membrane resistance and membrane time constant of a neuron in population @xmath17 , respectively , and @xmath327 sets the synaptic weights in units of mv .",
    "the synaptic kernel @xmath332 is defined as the postsynaptic current ( psc ) normalized by its charge that is induced by one input spike from a neuron of population @xmath214 .",
    "more precisely , @xmath333 is the psc divided by its integral , and therefore it has units of @xmath334 . in eq .",
    ", the first sum runs over all populations @xmath214 , whereas the second sum runs over the set @xmath324 of all neurons in population @xmath214 that project onto neuron @xmath7 in population @xmath17 .    in general , the filtered total synaptic input from population @xmath214 , @xmath335",
    ", may be modeled by a set of differential equations for a finite number of synaptic variables @xmath336 , @xmath337 . in simulations , we model the synaptic kernel by a single exponential with constant delay @xmath338 , @xmath339 , where @xmath340 denotes the heaviside step function .",
    "the synaptic time constants are @xmath341  ms and @xmath342  ms for excitatory and inhibitory synapses , respectively .",
    "this kernel can be realized by a single synaptic variable @xmath343 , which obeys the first - order kinetics @xmath344 with @xmath345 .",
    "[ [ sec : glm - model ] ] generalized integrate - and - fire model .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    neurons are modeled by a leaky integrate - and - fire model with a dynamic threshold @xcite and an escape noise mechanism @xcite .",
    "following @xcite , we refer to this model as the generalized integrate - and - fire ( gif ) model .",
    "the crucial variables of this model are the membrane potential @xmath4 and the dynamic threshold @xmath5 .",
    "the membrane potential obeys the subthreshold dynamics @xmath346 where @xmath331 is the membrane time constant and @xmath347 is the drive in the absence of synaptic input consisting of a constant resting potential @xmath348 and an external stimulus @xmath349 .",
    "the synaptic current @xmath328 has been defined in eq .  .",
    "after each spike the voltage is reset to the potential @xmath39 , where it is clamped for an absolute refractory period @xmath350  ms .",
    "furthermore , each spike @xmath22 adds a contribution @xmath351 to the dynamic threshold : @xmath352 where @xmath353 is a baseline threshold and @xmath31 is called the spike - triggered kernel @xcite .",
    "since the increases in spike threshold accumulate over several spikes , the spike - triggered kernel causes spike - frequency adaptation .",
    "we set @xmath354 for @xmath355 so as to ensure absolute refractoriness .",
    "spikes are elicited stochastically by a conditional intensity ( also called hazard rate , escape rate or conditional rate ) @xmath356 which depends on the momentary distance between the membrane potential and the threshold via the exponential link function @xmath36 .",
    "the parameter @xmath38 is the escape rate at threshold and the parameter @xmath357 characterizes the softness of the threshold ( fig .",
    "[ fig : potjans - scheme]a , inset ) .",
    "intuitively , a neuron fires immediately if its membrane potential is @xmath358 millivolts above the threshold and is unlikely to fire if its membrane potential is @xmath358 millivolts below the threshold @xcite . in the limit @xmath359",
    ", the model turns into a deterministic ( but adaptive ) leaky integrate - and - fire model with a hard threshold .",
    "we emphasize that our standard choice of @xmath360  mv is consistent with the intrinsic stochasticity of neurons in cortical slices @xcite .",
    "alternatively , the softness of the threshold @xmath37 may also be regarded as a phenomenological parameter that accounts for all incoherent noise sources that are individual to each neuron .",
    "this includes , e.g. , any intrinsic noise but also fluctuations of external background input from other neural populations that are not modeled explicitly .",
    "for instance , to account for the external poisson input used in the original cortical column model by potjans an diesmann @xcite , we increase in figs .",
    "[ fig : potjans - scheme ] , [ fig : potjans_psth ] and [ fig : potjans_spectra ] the softness to @xmath361  mv .    the parameters of the model used in simulations ( unless specified differently ) are summarized in tab.[table1 ] .",
    "[ [ mapping - onto - a - generalized - linear - model . ] ] mapping onto a generalized linear model .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we also considered a slightly different variant of the model , called _ spike - response model _",
    "@xcite or _ generalized linear model ( glm ) _ @xcite .",
    "this model does not reqire the reset rule of the integrate - and - fire model but instead relies on spike - triggered kernels to implement refractoriness and other spike - history effects .",
    "specifically , the membrane potential is given by @xmath362 where @xmath363 is the free membrane potential given by @xmath364.\\ ] ] for a membrane filter kernel @xmath365 , where @xmath340 denotes the heaviside step function , the dynamics of @xmath366 is equivalent to the dynamics of @xmath367 ( eq .  ) , except that @xmath366 is not reset upon spiking .",
    "spike - history effects on the level of the membrane potential are captured by the second term in eq .  .",
    "this term represents the convolution @xmath368 of the output spike train with a spike - triggered kernel @xmath369 and generates a spike - after - potential that accumulates over spikes . as before , the threshold @xmath5 obeys eq .  .",
    "given the membrane potential @xmath4 and the dynamic threshold @xmath5 , spikes are generated by the same hazard rate @xmath34 given by eq .  .",
    "at low firing rates , the spike - triggered kernel @xmath370 can be used to approximate the integrate - and - fire dynamics by choosing @xmath371 . however",
    ", this is not an exact mapping because the value of the membrane potential is not reset to a fixed value @xmath39 after spiking , in contrast to the gif model .",
    "this is due to the accumulation of spike - after - potential and threshold and due to the variability in the voltage at the moment of firing .",
    "we also mention that the kernel @xmath370 can be transformed into the kernel @xmath372 of the threshold dynamics @xcite .",
    "this is possible because we are only interested in the spike emissions of the neurons and not the membrane potentials .",
    "in fact , the conditional firing rate , eq .",
    ", is invariant under the transformation @xmath373 , @xmath374 .    .",
    "* default values of parameters used in simulations unless stated otherwise . * [ cols= \" < , < , < \" , ]     [ table1 ]      an important variable that characterizes the internal state of a neuron is the time of its last spike , or , equivalently , the time elapsed since the last spike ( `` age '' of the neuron ) @xcite .",
    "this is because the time since the last spike is a good predictor of the refractory state of a neuron at time @xmath26 .",
    "our approach is to use a population density description for this refractory state @xcite , in which the coupling of neurons as well as the adaptation of single neurons are mediated by the mesoscopic population activities . to this end , let us denote the last spike time of neuron @xmath7 in population @xmath17 by @xmath43 .",
    "the population activities @xmath11 are defined by eq .  .",
    "the main idea of our theory is that the conditional firing rate of a neuron in population @xmath17 can be well approximated by the last spike time @xmath43 and the history of the population activity @xmath375 @xcite .",
    "that is , we use a mean - field approximation of the form @xmath376 here and in the following , the subscript @xmath46 indicates the dependence on the history of @xmath11 . to find such an approximation",
    ", we proceed in two steps @xcite : first , the membrane potential @xmath4 is approximated by a function @xmath377 using a mean - field approximation of the synaptic input .",
    "for fully connected populations , this first approximation turns into an exact statement .",
    "second , the dynamic threshold @xmath5 is approximated by a function @xmath49 using the quasi - renewal approximation @xcite . for renewal neurons ,",
    "the second approximation becomes exact .",
    "once we have found an expression for the mean - field approximation eq .",
    ", we are in a position to use a population density description with respect to the last spike times @xmath43 .    [ [ mean - field - approximation - of - synaptic - input . ] ] mean - field approximation of synaptic input .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    in the special case of a fully connected network ( @xmath378 ) , the membrane potential can be completely inferred from the last spike time @xmath43 and the mean field @xmath379 . in this case , the synaptic input eq .   can be rewritten as @xmath380 thus , in a fully connected network all neurons in population @xmath17 `` see '' the same synaptic input @xmath381 given by the `` mean field '' @xmath64 . from eq .",
    "follows that gif neurons with the same last spike time @xmath50 all have the same membrane potential @xmath382 that obeys the differential equation @xmath383 with @xmath384 .",
    "the initial condition is @xmath385 corresponding to the reset of the membrane potential after the last spike .",
    "if we use this insight for the conditional intensity @xmath386 we see that the explicit dependence upon @xmath4 can be dropped as long as we keep track of the last spike time @xmath43 , cf .",
    "; hence @xmath387 .    in a randomly connected network ( @xmath388 ) , the synaptic input is generally different for each neuron .",
    "however , if the connection probability @xmath268 is not too small , deviations between the actual synaptic input and the mean input defined in eq .",
    "are small . to see this",
    ", we note that in our network with fixed in - degree , each neuron @xmath7 in population @xmath17 has @xmath269 presynaptic neurons in population @xmath214 ( @xmath389 is possible ) .",
    "this means that in eq .",
    "we can approximate the sum @xmath390 over the @xmath269 presynapic neurons by @xmath391 ( cf . definition of @xmath392 in eq .  ) .",
    "this approximation holds true on average , but assumes that fluctuations in the synaptic input are common to all neurons .",
    "apart from these common fluctuation ( captured by @xmath392 ) , there can be incoherent fluctuations caused by a weak heterogeneity in the synaptic input ( quenched random connectivity ) . as a consequence",
    ", the membrane potential @xmath4 will be a noisy version of @xmath377 , which effectively softens the threshold of the escape noise mechanism .",
    "however , if the number of synapses is sufficiently large , this noise is expected to average out , whereas common finite - size fluctuations survive .",
    "[ [ sec : qr ] ] quasi - renewal approximation .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    so far we have reduced the conditional intensity to @xmath393 .",
    "this expression still involves the individual threshold @xmath5 of neuron @xmath7 in population @xmath17 , which depends on the full spike history of that neuron .",
    "this means that the spike - train is generally not a time - dependent renewal process . here",
    ", we employ the quasi - renewal approximation @xcite and average over the spikes before the last spike time assuming that they occurred according to an inhomogeneous poisson process with rate @xmath44 , @xmath394 . averaging the conditional intensity , eq .",
    ", in this way , conditioned on a given last spike time @xmath43 and a given history @xmath44 , @xmath394 , yields @xcite @xmath395 where @xmath49 is an effective dynamic threshold given by @xmath396 here , @xmath397 $ ] is the so - called quasi - renewal kernel @xcite , while @xmath398 describes the increase of the threshold induced by the last spike .",
    "note that as a result of the two approximations , the conditional firing rate no longer depends on the precise spiking history of a given neuron and its presynaptic neurons , but only on its last firing time , cf .",
    "eq .   and eq .  .",
    "this ends our explanation of eq .  .",
    "using the mean - field approximation eq .",
    ", we have reduced the model to a population of time - dependent renewal processes @xcite , where the conditional intensity of neuron @xmath7 is @xmath42 .",
    "neurons are effectively coupled through the dependence of @xmath42 upon the membrane potential @xmath399 , which in turn depends on the activities @xmath400 of all populations @xmath214 that are connected to population @xmath17 .",
    "this is the only place where population labels different from @xmath17 appear . for the sake of notational simplicity",
    ", we will omit the population label @xmath17 and the subscript @xmath46 in this section , keeping in mind that all quantities refer to population @xmath17 and that the coupling with other populations is implicitly contained in @xmath399 .",
    "[ [ microscopic - description . ] ] microscopic description .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    because the firing probability of a neuron only depends on its last spike time and the mesoscopic population activity in the past , we can use a population density description of all last spike times @xmath401 in the population . to derive such representation",
    "it is useful to discretize time by introducing the discrete time points @xmath402 , @xmath403 , and the corresponding intervals @xmath404 .",
    "time is measured relative to a reference time @xmath405 , which , however , is irrelevant for the following arguments .",
    "we require that the size of the intervals @xmath23 is sufficiently small so that each neuron fires at most once during any interval .",
    "specifically , we require that @xmath406 .",
    "furthermore , we identify the discrete time point @xmath208 as the current time , whereas indices @xmath91 with @xmath407 correspond to the past . in the population density approach ,",
    "we do not keep track of the last spike time of each individual neuron but for each past time interval @xmath408 we only track the number of those neurons that have their last spike time in this interval .",
    "this number is denoted by @xmath409 .",
    "the collection @xmath410 of these numbers for all intervals @xmath408 , @xmath407 , represents the current distribution of last spike times @xmath401 in the population at time @xmath208 ( fig .",
    "[ fig : m - n]a ) . because each neuron has exactly one last spike time , the distribution @xmath411 is normalized to the total number of neurons : @xmath412 the distribution of last spike times @xmath411 characterizes the microscopic state of the population , in particular its refractoriness .",
    "we now introduce the number of neurons that fired a spike in the interval @xmath408 ( not necessarily the last spike ) .",
    "this number is denoted by @xmath413 ( fig .",
    "[ fig : m - n]a ) and will be often referred to as simply the `` activity '' at time @xmath414 .",
    "knowing the past activities @xmath415 for @xmath416 , and the last spike time @xmath414 fully determines the membrane potentials @xmath417 and thresholds @xmath418 , and hence the escape rate @xmath419 associated with the interval @xmath408 .",
    "thus , the knowledge of the past activities and the distribution of last spike times at time @xmath208 is sufficient to statistically determine these quantities at time @xmath209 . in other words ,",
    "the evolution of the system can be described by a markov process if we define the microscopic state @xmath420 of the population at time @xmath208 by the sequence of pairs @xmath421 in the following , the main task will be to derive the statistics of the number of spikes @xmath422 in the next time interval @xmath423 and the distribution @xmath424 of last spike times at time @xmath209 given the state @xmath420 at time @xmath208 .",
    "we mention that what we have lost in this population density description is only the information about the identity of the neurons , which , however , is irrelevant for the mesoscopic description of homogeneous populations .",
    "( red line ) . * + ( a ) as a function of @xmath50 ( or as a function of @xmath91 in discrete time ) , @xmath425 represents the distribution of last spike times @xmath401 across the population at time @xmath426 .",
    "( b ) as a function of time @xmath26 ( or as a function of the index @xmath186 in discrete time ) , @xmath425 represents the survival number , i.e. the number of neurons which fired in the interval @xmath190 which survived ( did not fire ) until time @xmath426 .",
    "the activity @xmath427 , i.e. the number of neurons that fired in the @xmath91-th time bin , is depicted by a blue line .",
    "the population size is @xmath292 . ]",
    "there is a second interpretation of @xmath425 : let us consider the group of neurons that have fired in the interval @xmath408 , @xmath407 .",
    "the number of neurons from this group that have `` survived '' ( i.e. that have not fired again ) until time @xmath208 is also given by @xmath425 . as time @xmath208 evolves , the group of surviving neurons diminishes whenever there is a spike in that group ( fig .",
    "[ fig : m - n]b ) .",
    "thus , if the group fires @xmath428 spikes in the time step @xmath423 , then @xmath425 decreases by @xmath428 . for @xmath429 ,",
    "this gives rise to the evolution equation @xmath430 the initial condition is given by @xmath431 , which follows from the absolute refractoriness during the first time step after a spike .",
    "absolute refractoriness also entails that each neuron can fire only one spike per time step ( @xmath406 ) with a firing probability @xmath432 in the last step , we introduced the average hazard rate @xmath433/2 $ ] . because the past activities @xmath427 , @xmath407 , completely determine the probability to fire @xmath434 , each neuron decides independently from the others whether it fires in the next time step .",
    "furthermore , there is a total number of @xmath435 neurons from the considered group that could potentially fire in the interval @xmath423 .",
    "therefore , the number of spikes @xmath428 is the results of @xmath435 independent bernoulli trials with success probability @xmath436 .",
    "this implies that @xmath428 is binomially distributed with mean @xmath437 .",
    "moreover , the random numbers @xmath428 associated with different past time intervals @xmath408 are conditionally independent given the current state of the system @xmath420 ( cf .",
    "eq .  ) . in the following derivation , we assume that @xmath23 can be chosen sufficiently small such that @xmath438 , which is always possible if neurons are stochastic und hence do not perfectly synchronize . under this assumption ,",
    "the numbers @xmath428 for different time intervals @xmath408 are conditionally independent , poisson - distributed random numbers , @xmath439,\\ ] ] with conditional mean and variance @xmath440 here , the notation @xmath441 denotes the conditional average given the microscopic state @xmath420 at time @xmath208 .    the total number of spikes emitted in the current interval @xmath423 is equal to the total reduction of survivals in that interval , hence @xmath442 equations - define the microscopic kinetics in discrete time . in a simulation , for each past time interval @xmath408 one independent poisson random number @xmath428 needs to be drawn per time step and population .",
    "these random numbers determine the current spike count via eq .   and the update of the distribution of last spike times @xmath411 , via eq .",
    "we call this description microscopic because for small time steps , there will be many ( order of @xmath2 ) intervals @xmath408 that contain survived neurons , i.e. for which @xmath443 and for each of which one needs to draw a random number @xmath428 in a simulation . in the limit @xmath27",
    ", such a simulation would be as complex as the original microscopic simulation of @xmath2 neurons .",
    "furthermore , if we consider @xmath411 as a function of time @xmath208 ( fig .",
    "[ fig : scheme - theory]e , f and fig .",
    "[ fig : m - n]b ) , each jump corresponds to the firing of a single neuron highlighting the microscopic nature of this process .",
    "[ [ mesoscopic - description . ] ] mesoscopic description .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    at the mesoscopic level , we want to describe the state of the population at time @xmath208 only by the mesoscopic variables @xmath427 , @xmath407 , that have been observed so far .",
    "therefore , we define the history of @xmath444 at time @xmath208 by @xmath445 which completely determines the mesoscopic state .",
    "in contrast to the microscopic state @xmath420 defined in eq .  , the mesoscopic state does not require the detailed distribution of last spike times @xmath411 .",
    "we call a variable mesoscopic if it only depends on the history @xmath446 .",
    "likewise , an equation is called mesoscopic if it only involves mesoscopic variables .    to derive a mesoscopic equation ,",
    "we want to find an approximate dynamics with only one effective , mesoscopic noise term that summarizes the effect of all microscopic random variables @xmath428 . in a simulation",
    ", this would imply to draw only one random number per time step and per population . towards that end",
    ", we note that eq .   and",
    "eq .   together with the conditional independence of @xmath428 for different @xmath91 imply that the global activity @xmath422 is poisson - distributed given the microscopic state @xmath420 .",
    "specifically , it holds @xmath447,\\ ] ] with mean @xmath448 because of the definition of refractory densities and @xmath449 , we find that @xmath450 is automatically satisfied at any moment in time . however , for the numerical implementation with finite @xmath23 later on we need to keep in mind that the poisson number @xmath134 could become larger than @xmath2 , if @xmath233 is close to @xmath2 . in this case",
    ", using a binomial statistics will be more appropriate , as explained in sec .",
    "equations and suggest the possibility to generate @xmath422 by a _",
    "single _ poisson - distributed random number .",
    "however , eq .   is not a mesoscopic equation yet because it still depends on the dynamics of @xmath411 , eq .  , which contains the microscopic random variables @xmath428 .",
    "intuitively , if we consider the decrease of @xmath411 as a function of @xmath208 , it occurs stepwise with each firing of a neuron .",
    "hence , @xmath411 is a `` microscopic '' process and not a suitable variable in mesoscopic equations .",
    "there is another , more subtle problem if we want to use eqs .   and as a mesoscopic dynamics that generates the activities @xmath422 .",
    "if we regard @xmath422 as an _ independent _ random variable , the conservation of neurons , eq .  , imposes a constraint on the microscopic random numbers @xmath451 , which will therefore not be independent anymore .",
    "conversely , if we consider both @xmath451 and @xmath422 as independent variables , we almost certainly violate the conservation of neurons , eq .  , or equivalently , the normalization condition eq .  .",
    "this problem does not occur in the microscopic dynamics , where @xmath422 is a _ dependent _ variable generated from the independent random variables @xmath451 via eq .  , and hence the correct normalization is guaranteed at any time",
    ". nevertheless , the `` non - normalized '' or `` unconstrained '' process , in which @xmath451 and @xmath422 are drawn independently , will be useful for deriving mesoscopic equations because it allows us to calculate the moments of the survival numbers @xmath411 .",
    "our main strategy is to use these moments in conjunction with the normalization condition to express the expected spike count @xmath233 , eq .",
    ", as a deterministic functional of the past activities .",
    "in this way , @xmath233 will not depend anymore on the actual microscopic realizations of the constrained noise @xmath452 ( constrained by a given history @xmath453 via eq .  ) and can thus be used to generate @xmath422 as a poisson random number from the knowledge of the past activities .    [ [ moment - equations . ] ] moment equations .",
    "+ + + + + + + + + + + + + + + + +    to achieve such deterministic relationship , we first derive mesoscopic equations for the conditional mean and variance of @xmath411 given the history @xmath446 in the so - called _ non - normalized ensemble _ or _",
    "unconstrained _ ensemble .",
    "this means that the history determines the initial conditions of the dynamics of @xmath411 , eq .  , as well as the conditional intensities @xmath454 , but it does not impose the constraint eq .   on the random numbers @xmath455 .",
    "although this unconstrained noise leads to a non - normalized distribution @xmath411 , it still yields a very good approximation of its conditional mean and variance in the actual constrained ensemble .",
    "taking the average of eq .  , and using yields the evolution of the conditional mean : @xmath456\\langle m_{l , k}\\rangle\\ ] ] with initial condition @xmath457 . here and in the following",
    ", @xmath458 is short - hand for @xmath411 to simplify the notation , and @xmath459 denotes the ensemble average of the unconstrained process for a given history @xmath446 .",
    "actually , the condition for the average @xmath460 can be extended to the history @xmath461 ( and to any future activities ) because in the unconstrained ensemble neither @xmath458 nor @xmath462 depend on the most recent activity @xmath422 ( clearly , this also holds for any future activity ) .",
    "importantly , eq .   is a mesoscopic equation because it is fully determined by the past activities .    as a next step",
    "we derive an equation for the conditional variance of @xmath463 . to this end , let @xmath464 denote the deviation from the conditional mean . from eq .   and",
    "it follows that this deviation evolves according to @xmath465.\\ ] ] in contrast to the conditional average @xmath466 given in eq .",
    ", the average @xmath467 is not conditioned on the distribution of last spike times @xmath458 . using the law of total variance",
    ", we find from eq .   that the variance of @xmath428 for the unconstrained ensemble is given by @xmath468 therefore",
    ", the update of the variance during one time step can be written as @xmath469\\rangle+\\langle ( x_{lk}-\\langle x_{lk}\\rangle)^2\\rangle,\\\\ = \\langle\\delta m^2_{l , k}\\rangle-2\\langle\\delta m_{l , k}x_{lk}\\rangle+2\\langle\\delta m_{l , k}\\rangle\\langle x_{lk}\\rangle+p_\\lambda(t_l|t_k)\\langle m_{l , k}\\rangle+p_\\lambda^2(t_l|t_k)\\langle\\delta m^2_{l , k}\\rangle.\\end{gathered}\\ ] ] the second term in the last line can be expanded as @xmath470 applying eq .   and eq .   and exploiting that @xmath471 we find the following update rule for the variance @xmath472 ^ 2\\langle\\delta m^2_{l , k}\\rangle+p_\\lambda(t_l|t_k)\\langle m_{l , k}\\rangle.\\ ] ] this equation together with the initial condition @xmath473 yields the evolution of the conditional variance of @xmath463 . as a function of @xmath208 ( fig .  [",
    "fig : scheme - theory]c bottom ) , the variance @xmath474 is initially zero because all neurons have still survived immediately after firing at time @xmath414 . on the other hand , at long times @xmath475 , the variance also vanishes because according to eq .  , the mean number of survived neurons @xmath476 appearing in eq .",
    "goes to zero . as a consequence ,",
    "the variance obtains a maximum at an intermediate time .",
    "similarly , the dependence of the variance at time @xmath208 for different last spike times @xmath477 shows the same limiting behavior which implies a maximum at an intermediate last spike time @xmath50 ( fig .",
    "[ fig : scheme - theory]b bottom ) .",
    "however , the rugged shape of this function with many local maxima reflects the discontinuity of the driving force @xmath476 as a function of @xmath414 that arises from the stochastic initial condition @xmath478 .",
    "[ [ mesoscopic - population - equations . ] ] mesoscopic population equations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let us return to eq .   for the expected activity @xmath233 , which is used to draw the activity @xmath422 as a poisson random number with mean @xmath233 ( cf .",
    "eq .  ) . because we condition on the history @xmath479 , the processes @xmath458 in this equation belong to the `` constrained '' ensemble , in which the normalization condition , eq .  , is obeyed .",
    "we note that these constrained processes could in principle be generated microscopically by eq .   if at each time",
    "@xmath480 in the past , the microscopic noise @xmath481 was sampled from a joint distribution that ensures the conservation of neurons , eq .  ,",
    "i.e. @xmath482 . however , as we will show in the following , such a construction is not needed because the dependence of the expected activity @xmath233 on a specific realization of @xmath458 can be eliminated by exploiting the normalization condition , eq .  .",
    "to this end , we take advantage of the fact that the conditional mean @xmath483 of the unconstrained process is a mesoscopic variable .",
    "this suggests to split the constrained processes @xmath458 into the conditional mean of the unconstrained process and a fluctuation part : @xmath484 the first contribution is deterministic given the past activities @xmath427 while the second contribution represents the microscopic fluctuations .",
    "we note that the fluctuation @xmath485 is not equivalent to the deviation @xmath486 of the unconstrained process because @xmath487 does not obey the normalization condition , eq .  , whereas @xmath488 does .    to remove the microscopic fluctuations @xmath485 , we require that both eq .   and eq .   are simultaneously satisfied . substituting eq",
    ".   into these equations leads to @xmath489 the microscopic fluctuations @xmath485 enter the dynamics only in the form of two sums .",
    "first , the normalization condition eq .   imposes a strict relation between the summed deviation @xmath490 and the conditional means of the unconstrained processes , @xmath483 , irrespective of the specific , underlying microscopic dynamics of @xmath458 .",
    "in particular , we can solve for @xmath491 with terms on the r.h.s . that are completely determined given the past activities .",
    "second , the total effect of the deviations on the expected activity @xmath233 is given by the weighted sum @xmath492 in eq .",
    "with @xmath493 for all @xmath407 .",
    "the weighted sum @xmath492 is therefore tightly constrained by the value of the summed fluctuation @xmath490 .",
    "these considerations suggest to make the following decoupling approximation : @xmath494 with a still unknown factor @xmath495 , that we call effective firing probability . to determine the effective firing probability , we require that the approximation in eq",
    ".   minimizes the mean squared error @xmath496 where @xmath497 is short - hand for @xmath495 .",
    "note that we use the unconstrained deviations @xmath498 because we are only interested in the typical error .",
    "the derivative of @xmath499 with respect to @xmath497 is @xmath500 where we have exploited that @xmath434 is deterministic given the past activities @xmath427 , @xmath407 .",
    "furthermore , under this condition , the fluctuations @xmath486 and @xmath501 with @xmath502 are conditionally independent . using this property and setting @xmath503",
    "we find that the optimal effective firing probability is @xmath504 the variance @xmath505 in this formula obeys the mesoscopic dynamics derived above in eq .  .",
    "hence , the effective firing probability is itself mesoscopic .    using eq .   and",
    ", @xmath490 can be eliminated in eq .",
    "resulting in @xmath506 thus , we obtain an equation that yields the mean spike count @xmath507 at the present time as a function of the past spike counts @xmath508 .",
    "equation is the desired mesoscopic equation in discrete time . for sufficiently small time steps @xmath23",
    ", the present spike count @xmath422 can be generated by drawing a poisson random number with mean @xmath233 according to eq .  .",
    "in continuous time , we consider the rescaled variables @xmath509 here , @xmath63 can be interpreted as the _ expected population activity _ given the past activity @xmath101 , @xmath45 .",
    "for @xmath23 small but positive , the spike count @xmath134 is an independent poisson number with mean @xmath510 .",
    "thus , on a coarse - grained time scale , the continuum limit of the population activity may be written in the following suggestive way @xmath511 where @xmath129 denotes an infinitesimal ( but temporally coarse - grained ) time step and @xmath512 is an independent poisson - distributed random number with mean @xmath513 . in the limit @xmath514 ,",
    "the spike count is either @xmath515 ( with probability @xmath513 ) or @xmath516 ( with probability @xmath517 ) .",
    "therefore , in this limit the population activity @xmath64 converges to a sequence of dirac @xmath21-functions occurring at random times @xmath143 with rate @xmath197 .",
    "thus , @xmath64 can be written more formally as a population spike train or `` shot - noise '' @xmath518 where @xmath519 is a point process with conditional intensity @xmath520 . here ,",
    "the condition @xmath140 denotes the history of the population activity @xmath521 , or equivalently , the history of spike times @xmath522 , up to ( but not including ) time @xmath26 .    to obtain the dynamics for @xmath63",
    ", we also introduce the rescaled variables @xmath523 the function @xmath56 can be interpreted as the survival probability of neurons that have fired their last spike at time @xmath50 .",
    "furthermore , for small @xmath23 the firing probability is given by @xmath524 .",
    "thus , the continuum limit of eq .",
    "reads @xmath525 the sums in this equation can be regarded as the definition of stochastic integrals , which allows us to rewrite eq .   as @xmath526 here",
    ", @xmath527 is an effective rate corresponding to the effective firing probability @xmath528 .",
    "note that according to eq .  , the stochastic integrals in eq .",
    "extend only over last spike times @xmath114 not including time @xmath238 . taking the continuum limit of eq .",
    "we find that the survival probability satisfies the differential equation @xmath529 this equation has the simple solution @xmath530 similarly , we find from eq .   that the rescaled variance obeys the differential equation @xmath531 the set of coupled equations",
    "   defines the mesoscopic population dynamics .",
    "we emphasize that not only @xmath64 depends on @xmath63 ( cf .",
    "eq .  ) but that there is also a feedback of @xmath64 onto the dynamics of @xmath63 .",
    "in fact , @xmath96 can be regarded as a deterministic functional of the past activities up to but not including time @xmath26 . in particular",
    ", @xmath64 is _ not _ an inhomogeneous poisson spike train because the specific realization of the spike history of @xmath64 determines the conditional intensity function for the point process @xmath532 via eq .  .",
    "furthermore , we note that , in the case of synaptic coupling or adaptation , also the variables @xmath533 and @xmath109 depend on the history of the population activity through the dependence of @xmath534 on the membrane potential @xmath535 and the threshold @xmath536 ( cf . eqs .   and ) .    for large @xmath2 , the population activity can be approximated by a gaussian process . to this end",
    ", we note that in the discrete time description the spike counts @xmath422 are conditionally independent random numbers with mean and variance @xmath537 .",
    "therefore , in the large-@xmath2 limit , the variable @xmath538 is normally distributed with mean zero and variance @xmath23 , and hence corresponds to the increment of a wiener process . using eq .   for the population activity and taking the continuum limit @xmath27",
    ", we obtain @xmath539 where @xmath540 is a gaussian white noise with correlation function @xmath146 .",
    "this gaussian approximation has the advantage that the multiplicative character of the noise in eq .   becomes explicit because @xmath145 is independent of the state of the system .",
    "it also explicitly reveals that the finite - size fluctuations scale like @xmath541 .",
    "we stress again that @xmath64 is not a white - noise process with time - dependent mean , as eq .",
    "might suggest at first glance , but it is a sum of two mutually correlated processes , ( i ) a white - noise term proportional to @xmath145 that reflects the fact that the population activity is a @xmath21-spike train and ( ii ) a colored `` noise '' @xmath63 that arises from the filtering of @xmath145 through the dynamics in eq .  . as a result , the auto - correlation function of @xmath64 contains a @xmath21-peak and a continuous part , consistent with previous theoretical findings @xcite .",
    "in particular , at short lags the auto - correlation function may be negative as a result of refractoriness : in this case , @xmath542 and @xmath543 are anti - correlated in line with the intuitive picture discussed in the results section , fig .",
    "[ fig : scheme - theory ] , that a positive fluctuation @xmath145 is associated with the creation of a `` hole '' in the distribution of last spike times leading to a reduced activity after time @xmath26 . in the frequency domain , refractoriness corresponds to a trough in the power spectrum at low frequencies @xcite as visible , for instance , in fig .",
    "[ fig : lif ] .",
    "these considerations clearly highlight the non - white character of the finite - size fluctuations in our theory .",
    "it is straightforward to generalize the population equations to several populations by adding a population label @xmath210 . for the sake of completeness",
    ", we explicitly state the full set of equations . the activity of population @xmath17",
    "is given by    @xmath544    where @xmath545 is a point process with conditional intensity @xmath546 . here , the expected activity @xmath96 depends explicitly on the history @xmath547 by the following set of equations @xmath548    for each population , the system of equations  contains a family of ordinary differential equations for the variables @xmath533 , @xmath549 and @xmath109 parametrized by the continuous parameter @xmath50 with @xmath550 , and five integrals over this parameter . in the next section , we show that the family of ordinary differential equations is equivalent to three first - order partial differential equations . furthermore , in sec .  `` '' , we reduce the infinite integrals to integrals over a finite range , which will be useful for the numerical implementation of the population equations",
    ".      there is an equivalent formulation of the population equation in terms of first - order partial differential equations for the density of ages @xmath321 @xcite .",
    "the representation in terms of age @xmath551 as a state variable is useful because it parallels the fokker - planck formalism for the membrane potential density @xcite , in which the state variable is the membrane potential of a neuron . to keep the notation simple we consider in the following population @xmath17 but drop the index @xmath17 wherever confusion is not possible .",
    "thus , we write e.g. @xmath533 for @xmath552 and @xmath148 for @xmath379 but we keep the index @xmath214 as well as double indices @xmath553 occurring in eq .  .    the density of ages at time @xmath26 is defined as @xmath554 .",
    "we recall that because of finite - size fluctuations , @xmath555 is not a normalized probability density .",
    "furthermore , we regard the functions @xmath556 , @xmath557 and @xmath558 as functions of @xmath26 and @xmath551 . with these definitions",
    "the population equation , eq .",
    ", can be rewritten as @xmath559 this equation yields the expected population rate at time @xmath26 for a given density of ages . in the fokker - planck formalism",
    ", this would correspond to the calculation of the rate from the membrane potential density as the probability flux across the threshold .    noting that @xmath560",
    ", we find from eq .   the following first - order partial differential equation for the density of ages @xmath561 : @xmath562 similarly , @xmath557 and @xmath558 obey from eq .   and , respectively , @xmath563\\end{aligned}\\ ] ] with boundary conditions @xmath564 and @xmath565 .",
    "these functions , together with the threshold dynamics @xmath566 determine @xmath567 and @xmath568 via eq .",
    ", i.e. @xmath569 the equations  of the previous section can be regarded as the characteristic equations corresponding to the partial differential equations ",
    "( `` method of characteristics '' ) .      to simulate the population activity forward in time , the integrals in eq .",
    "( [ eq : master - cont - a - inf ] ) over the past need to be evaluated , starting at @xmath570 . for biological systems , however , it is sufficient to limit the integrals to a finite history of length @xmath165 .",
    "this history corresponds to the range @xmath166 , where we have to explicitly account for the dependence of the conditional firing rate @xmath534 on the last spike time @xmath50 .",
    "we will call neurons with last spike time in this range `` refractory '' because they still experience some degree of ( relative ) refractoriness caused by the last spike .",
    "the remaining part of the integral corresponding to the range @xmath167 receives a separate , compact evaluation .",
    "we will refer to neurons with their last spike time in this range as `` free '' because their conditional intensity is free of the influence of the last spike .",
    "how should we choose the length of the explicit history @xmath165 ?",
    "first of all , this length can be different for different populations and is mainly determined by the time scale of refractoriness , i.e. the time it needs to forget the individual effect of a single spike in the past .",
    "furthermore , it depends on the properties of the spike - triggered kernel , i.e. the dynamic threshold that is responsible for adaptation .",
    "more precisely , we determine the length of the history by the following conditions : first , the conditional intensity is insensitive to the precise timing of the last spike at @xmath168 if @xmath571.\\ ] ] here , @xmath40 is the absolute refractory period and @xmath572 is the time scale of the relative refractory period . for the gif model @xmath573 .",
    "second , we demand that @xmath165 is chosen such that for @xmath574 , the quasi - renewal kernel @xmath575 $ ] can be well approximated by the original spike - triggered kernel @xmath260 .",
    "taylor expansion of the exponential yields the condition @xmath576 the length of the history @xmath165 needs to be chosen such that both conditions , eq .",
    "( [ eq : t - relativ ] ) and ( [ eq : qr - appr - t ] ) are fulfilled .",
    "it is important to note that condition eq .",
    "( [ eq : qr - appr - t ] ) does not require the time window @xmath165 to be larger than the largest time scale of the spike - triggered kernel .",
    "for instance , consider the kernel @xmath577 , where @xmath578 and @xmath579 are adaptation strength and time scale , respectively . in particular , the adaptation strength @xmath578 sets the reduction in firing rate compared to a non - adapting neuron in the limit of strong drive irrespective of the time scale @xmath579 ( see e.g. @xcite ) .",
    "condition eq .",
    "( [ eq : qr - appr - t ] ) can be fulfilled for a given @xmath165 if either @xmath579 is small enough such that the exponential @xmath580 is small , or , for a fixed adaptation strength @xmath578 , by increasing the adaptation time scale @xmath579 such that @xmath581 .",
    "[ [ dynamic - threshold - of - refractory - and - free - neurons . ] ] dynamic threshold of refractory and free neurons .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    for free neurons , i.e. for @xmath167 , we use the average threshold under the assumption that spikes occurred in the range @xmath167 according to an inhomogeneous poisson process with rate @xmath97 .",
    "this average is given by @xcite @xmath582 where in the last step we used eq .",
    "( [ eq : qr - appr - t ] ) .",
    "we assume that for @xmath574 the spike - triggered kernel can be sufficiently well approximated by a sum of exponentials @xmath583 this allows us to express the threshold for free neurons as    [ eq : thresh - nr - all ] @xmath584 where the variables @xmath585 satisfy the differential equations @xmath586    for refractory neurons ,",
    "i.e. if @xmath166 , we need to evaluate in the effective threshold , eq .  , an integral over the exact quasi - renewal kernel @xmath587 . splitting this integral into the free and refractory part yields the threshold of refractory neurons : @xmath588 we can use the threshold for free and refractory neurons , eq .",
    "and eq .  ,",
    "respectively , to obtain the respective conditional intensities : @xmath589 where @xmath41 is the free membrane potential given by eq .  .",
    "let us remind the reader that @xmath41 obeys the dynamics eq .   but without resetting of the membrane potential after a spike .",
    "[ [ population - equations . ] ] population equations .",
    "+ + + + + + + + + + + + + + + + + + + + +    we now apply the split of the history to the integrals that appear in the population equations , specifically eq .",
    "( [ eq : master - cont - a - inf ] ) and . by definition ,",
    "the conditional intensity of free neurons does not depend explicitly on the last spike time @xmath50 .",
    "that is , @xmath590 for @xmath167 , where the free hazard rate @xmath591 is given by eq .  .",
    "in the free part of the integrals in eq .",
    "( [ eq : master - cont - a - inf ] ) and , the free hazard rate can be pulled out of the integral , which yields    @xmath592    here we have introduced the expected number of free neurons @xmath172 and the partial integral over the variance function @xmath173 . differentiating these new variables and employing eqs .   and , we find that they obey the differential equations    [ eq : x - z ] @xmath593    thus , the integrals no longer run from @xmath594 to @xmath26 but are now limited to the range @xmath595 .",
    "the long tails over the past have been reduced to differential equations .      [",
    "[ discretization - of - time . ] ] discretization of time .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    we discretize the time axis into a grid with step size @xmath23 and grid points @xmath596 because we keep track of a finite history with the oldest last spike time @xmath597 , the history consists of a finite number @xmath183 of bins such that @xmath184 . if the index @xmath205 corresponds to the current time , the oldest last spike time of the explicit history corresponds to an index @xmath598 and the most recent one corresponds to the index @xmath599 .",
    "note that the numerical implementation requires the absolute refractory period @xmath40 to be at least as large as the integration time step @xmath23 ( see below ) .    to facilitate the notation of the update rules , it is convenient to introduce the following notations : @xmath600 in particular , @xmath601 and @xmath602 correspond to the mean and variance of the unconstrained survival numbers , respectively .",
    "we also recall that the population index @xmath17 is dropped wherever confusion is not possible , while the index @xmath214 as well as double indices @xmath553 will be kept .    [ [ choice - of - delta - t . ] ] choice of @xmath23 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a crucial assumption of the derivation of the population equations in discrete time was that the time step @xmath23 is small enough such that each neuron fires at most one spike per time step .",
    "this can be achieved by the condition @xmath603 ( cf .",
    "clearly , this condition implies that the total number of spikes per time step must be bounded by the number of neurons , i.e. the population activity must obey @xmath604 .",
    "the equality sign corresponds to the case that all neurons fire in the same time step .",
    "in addition to condition eq .  , we also had to require that @xmath23 is not larger than the transmission delay @xmath605 , i.e. @xmath606     in order to justify the use of the poisson statistics in the derivation of the population equations , we further assumed that @xmath23 is sufficiently small such that the expected number of spikes per time step , @xmath133 , is much smaller than @xmath2 , or equivalently @xmath607 .",
    "while this does not pose a problem for the theory , which ultimately concerns with the continuum limit @xmath27 , an efficient numerical integration of the population equations benefits from a time step that is as large as possible and should thus not be limited by such a condition .",
    "in particular , we should allow a large fraction of neurons to fire during one time step , either as a result of an external synchronization of many neurons ( e.g. by a strong , sudden stimulus ) or because of synchronous oscillations emerging from the network dynamics . in this case , a poisson - distributed spike count @xmath134 may exceed the number of neurons @xmath2 .",
    "this problem can be remedied by drawing @xmath134 from a binomial distribution with mean @xmath133 and maximal value @xmath2 . for @xmath608 , this binomial",
    "distribution agrees with the poisson distribution used in our theory , whereas at large @xmath133 it ensures that the spike count is bounded by the total number of neurons @xmath2 .",
    "although the binomial distribution does not follow strictly from our theory , it is expected to yield a very good approximation even at large @xmath133 .",
    "the reason is as follows : our argument that the sum of poisson numbers [ eq .  ] yields again a poisson number [ eq .  ]",
    "does not strictly hold for binomial random variables if the firing probabilities @xmath434 are very heterogeneous .",
    "however , if neurons are strongly synchronized , and hence @xmath609 , they fire with a similar probability , which implies indeed a binomial distribution of the spike count @xmath134 .    besides eq .",
    "and , a third condition concerns the approximation of the integral @xmath610 in eq .   by @xmath611 ( trapezoidal rule ) .",
    "this approximation is valid if the membrane potential @xmath549 and threshold @xmath612 do not vary too strongly during a time step .",
    "more precisely , the absolute error of the trapezoidal rule is known to be @xmath613 , which we require to be much smaller than @xmath614 .",
    "thus , the relative error is of order @xmath615 . using the definition of @xmath616 , eq .  , this leads to the condition @xmath617 in summary , @xmath23 should be chosen such that all three conditions , eqs .   ",
    "are satisfied for all populations .",
    "[ [ update - of - the - membrane - potential . ] ] update of the membrane potential .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    to compute the firing probabilities , we need to update both the membrane potential and the threshold . in the presence of an exponential synaptic filter @xmath618 , the membrane potential of free neurons @xmath619 obeys the differential equation @xmath620 assuming that the external stimulus @xmath621 and the population activity @xmath64 are constant during one time step , the solution over one time step is given by @xmath622}e^{-\\delta t/{\\tau_\\text{s}}},&\\beta=1,\\dotsc , m\\end{aligned}\\ ] ] where @xmath623 is the total input of population @xmath17 given by @xmath624}}{{\\tau_\\text{s}}-{\\tau_\\text{m}}}}\\right.\\\\ + \\left.\\frac{{\\tau_\\text{s}}e^{-\\frac{\\delta t}{{\\tau_\\text{s}}}}{\\left [ y^{\\alpha\\beta}(t_l)-a_n^{\\beta}(t_l-\\delta ) \\right]}-e^{-\\frac{\\delta t}{{\\tau_\\text{m}}}}{\\left [ { \\tau_\\text{s}}y^{\\alpha\\beta}(t_l)-{\\tau_\\text{m}}a_n^\\beta(t_l-\\delta ) \\right]}}{{\\tau_\\text{s}}-{\\tau_\\text{m}}}\\right\\}\\end{gathered}\\ ] ]    for refractory neurons , we obtain the membran potential in the glm model by the simple formula @xmath625 . for the gif model , the same update rule as for @xmath41 , eq .",
    ", can be applied for @xmath221 : @xmath626 for @xmath627 , we have @xmath628 ( absolute refractoriness ) .",
    "note that the total integrated input @xmath623 needs to be computed only once per time step .",
    "[ [ update - of - the - threshold . ] ] update of the threshold .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    let us first discuss , how to compute the threshold at time @xmath208 given the values of @xmath629 and @xmath427 for @xmath191 .",
    "for free neurons , the threshold @xmath630 is given by eq",
    ".   evaluated at time @xmath426 . for refractory neurons ,",
    "we find from eq .   that the threshold can be written in the discretized form @xmath631 @xmath632 .",
    "equation can be rewritten as @xmath633 where the variables @xmath634 can be calculated iteratively starting at @xmath598 : @xmath635 with initial condition @xmath636 .",
    "thus , at each time step @xmath208 , the threshold can be rapidly evaluated in one sweep via eq .  , and .",
    "for the computation of the firing probabilities below , it is necessary to compute the threshold one time step ahead , i.e. at time @xmath209 . to this end",
    ", we first update the variables @xmath178 according to eq .",
    ": @xmath637 this yields the threshold @xmath638 of free neurons via the formula eq .  .",
    "for refractory neurons we find from eqs .   and @xmath639 where @xmath224 can be iterated by @xmath640 with initial condition @xmath228 .    [",
    "[ firing - probabilities . ] ] firing probabilities .",
    "+ + + + + + + + + + + + + + + + + + + + +    the firing probabilities for free and refractory neurons are given by @xmath641 respectively . here , @xmath642/2,\\\\",
    "\\bar\\lambda(t_l|t_k)&=[\\lambda_k(t_l)+\\lambda_k(t_{l+1})]/2,\\end{aligned}\\ ] ] are the arithmetic mean of the respective intensities at the beginning and end of the time interval ( cf .",
    "these intensities can be obtained by the formulas @xmath643 for @xmath221 , and @xmath644 for @xmath627 ( absolute refractoriness ) .",
    "a corresponding formula holds for the conditional intensities at @xmath209 .",
    "[ [ population - dynamics . ] ] population dynamics .",
    "+ + + + + + + + + + + + + + + + + + + +    we can directly use the discretized form of the population equations given by eqs .   and .",
    "as in eq .   the infinite sums in eq",
    ".   can be split into an explicit , finite history of length @xmath183 and a remaining part corresponding to @xmath645 .",
    "this results in @xmath646 where @xmath647 is the firing probability of `` neurons '' belonging to the `` holes and overshoots '' @xmath485 ( cf .",
    "results , sec .  `` '' ) .",
    "the variables @xmath0 and @xmath177 have the discrete time definition @xmath648 corresponding to a discretization of their integral definition above .",
    "having calculated the expected spike count @xmath233 , the actual spike count @xmath422 is obtained by drawing a binomially distributed random number @xmath649 as discussed above . in eq .  , @xmath236 denotes the binomial distribution corresponding to @xmath2 bernoulli trials with success probability @xmath235 .",
    "the discrete evolution equations for @xmath650 and @xmath651 are given by eq .   and , respectively , which we repeat here for convenience :    [ eq : m - v - discrete ] @xmath652\\bar{m}_k(t_l ) \\\\ \\label{eq : v - update }    v_k(t_{l+1})&=[1-p_{\\lambda}(t_l|t_k)]^2v_k(t_l ) + p_{\\lambda}(t_l|t_k)\\bar m_k(t_{l}).\\end{aligned}\\ ] ]    to find the update rule for @xmath0 , we use the definition eq .   and the update rule for @xmath650 , eq .  :",
    "@xmath653\\bar{m}_k(t_l ) \\nonumber\\\\    \\label{eq : x - upd - prelim }              & = [ 1-p_{\\text{free}}(t_l)]\\sum_{k=-\\infty}^{l - k-1}\\bar{m}_k(t_l ) + [ 1-p_{\\lambda}(t_l|t_{l - k})]\\bar m_{l - k}(t_l).\\end{aligned}\\ ] ] here , we have exploited that @xmath654 for @xmath645 .",
    "using again eq .",
    "we find @xmath655x(t_l)+\\bar m_{l - k}(t_{l+1}).\\ ] ] this equation is the discrete analog of the continuous - time equation .",
    "note that @xmath656 is given by eq .  .",
    "an update rule for @xmath177 can be found from the definition eq .   and the update rule for @xmath657 , eq .  . a similar calculation that led to eq .",
    "results in @xmath658 ^ 2z(t_l)+p_{\\text{free}}(t_l)x(t_l)+v_{l - k}(t_{l+1}).\\end{aligned}\\ ] ] this equation is the discrete analog of the continuous - time equation . note that @xmath659 is given by eq .  .",
    "finally , the initial conditions can be accounted for by setting @xmath660 the last update step corresponding to the reset of the membrane potential only needs to be performed for the gif model .    [",
    "[ initialization - storage - of - history - and - pseudocode . ] ] initialization , storage of history and pseudocode .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    one possible way to initialize the system at @xmath661 is a sharp initial condition that corresponds to an initial synchronization of all neurons .",
    "specifically , we assume that all neurons have just fire in the time interval @xmath662 , where @xmath405 is the initial time .",
    "this corresponds to the following initialization of the variables : @xmath663 where @xmath204 denotes the kronecker delta .",
    "the last line corresponds to a zero adaptation level at the beginning of the simulation .    for the representation of the variables @xmath664 , @xmath651 , @xmath665 and @xmath666 , @xmath191 , in memory",
    ", it is convenient to employ circular buffers .",
    "that is , the `` running '' range of the explicit history @xmath191 is mapped to a static range @xmath667 in memory by applying the modulo operation @xmath668 to all temporal indices .",
    "an implementation of the algorithm is given by the pseudocode shown in fig .",
    "[ fig : algorithm - main ] and [ fig : algorithm ] .",
    ".,width=720 ]    , the quasi - renewal kernel @xmath669 , eq .  , as well as the exponentials @xmath670 and @xmath671 can be precomputed.,width=720 ]      we characterize the fluctuations of the stationary population activity by the power spectrum defined as @xmath672 where @xmath673 is the fourier transform of the population activity on a time window of length @xmath165 .    for a population of renewal neurons",
    "the power spectrum is known analytically .",
    "it is given by @xcite @xmath674 where @xmath675 is the fourier transform of the interspike interval density @xmath676 and @xmath677 is the stationary firing rate given by @xmath678}^{-1}.\\ ] ] note that the power of the fluctuations in eq .",
    "scales like @xmath3 , vanishing in the macroscopic limit @xmath1 . for the lif model with escape noise , the hazard rate @xmath679 is given by @xmath680 for @xmath681 and @xmath682 for @xmath683 .      to model the cortical column of @xcite in our framework",
    ", we used the parameters of the original publication and modified the model in two ways : first , the background poisson input was replaced by a constant drive and an increased escape noise such that the populations exhibited roughly the same stationary firing rates .",
    "specifically , we set @xmath262  mv , @xmath684  mv and @xmath685  mv ; and , using the mesoscopic dynamics , fitted the resting potentials of the gif model ( here denoted by @xmath686 ) without adaptation @xmath687 to obtain firing rates @xmath688 that roughly match the target firing rates .",
    "second , we introduced adaptation on excitatory cells with strength @xmath578 and time scale @xmath579 , and re - adjusted the resting potential as follows @xmath689 .",
    "this yielded correct stationary firing rates in the presence of adaptation .",
    "the resulting parameters of the modified model are summarized in tab.[parampotjans ] .     & + & + & + & + & + @xmath690 [ mv]&19.149 & 20.362 & 30.805 & 28.069 & 29.437 & 29.33 & 34.932 & 32.081 + @xmath688 [ hz]&0.974 & 2.861 & 4.673 & 5.65 & 8.141 & 9.013 & 0.988 & 7.53 +   + @xmath578 [ mv",
    "s]&1.0&0.0&1.0&0.0&1.0&0.0&1.0&0.0 + @xmath579 [ s]&1.0&-&1.0&-&1.0&-&1.0&- + & 20.123 & 20.362 & 35.478 & 28.069 & 37.578 & 29.33 & 35.92 & 32.081 +   + @xmath691 [ mv]&0 . & 0 . & 19 . &",
    "11.964 & 0 . & 0 . & 9.896 & 3.788 + & +   + @xmath2&20683 & 5834 & 21915 & 5479 & 4850 & 1065 & 14395 & 2948 + & + @xmath692  l2/3e&0.1009 & 0.1689 & 0.0437 & 0.0818 & 0.0323 & 0.0 & 0.0076 & 0.0 + @xmath692  l2/3i&0.1346 & 0.1371 & 0.0316 & 0.0515 & 0.0755 & 0.0 & 0.0042 & 0.0 + @xmath692  l4e & 0.0077 & 0.0059 & 0.0497 & 0.135 & 0.0067 & 0.0003 & 0.0453 & 0.0 + @xmath692  l4i & 0.0691 & 0.0029 & 0.0794 & 0.1597 & 0.0033 & 0.0 & 0.1057 & 0.0 + @xmath692  l5e & 0.1004 & 0.0622 & 0.0505 & 0.0057 & 0.0831 & 0.3726 & 0.0204 & 0.0 + @xmath692  l5i & 0.0548 & 0.0269 & 0.0257 & 0.0022 & 0.06 & 0.3158 & 0.0086 & 0.0 + @xmath692  l6e & 0.0156 & 0.0066 & 0.0211 & 0.0166 & 0.0572 & 0.0197 & 0.0396 & 0.2252 + @xmath692  l6i & 0.0364 & 0.001 & 0.0034 & 0.0005 & 0.0277 & 0.008 & 0.0658 & 0.1443 + @xmath327 [ mv ] , @xmath692  l4e&0.176 & -0.702 & 0.351 & -0.702 & 0.176 & -0.702 & 0.176 & -0.702 + @xmath327 [ mv ] , @xmath693  l4e&0.176 & -0.702 & 0.176 & -0.702 & 0.176 & -0.702 & 0.176 & -0.702 +    [ parampotjans ]",
    "we thank hesam setareh for useful discussions .",
    "this project received funding from the european union s horizon 2020 research and innovation programme under grant agreement no . 720270 and from the european research council under grant agreement no . 268689 , multirules .",
    "wang y , toledo - rodriguez m , gupta a , wu c , silberberg g , luo j , et  al .",
    "anatomical , physiological and molecular properties of martinotti cells in the somatosensory cortex of the juvenile rat .",
    "j physiol .",
    "2004;561(1):6590 .",
    "mensi s , naud r , pozzorini c , avermann m , petersen cch , gerstner w. parameter extraction and classification of three cortical neuron types reveals two distinct adaptation mechanisms .",
    "j neurophysiol .",
    "2012;.                                                    fisch k , schwalger t , lindner b , herz avm , benda j. channel noise from both slow adaptation currents and fast currents is required to explain spike - response variability in a sensory neuron .",
    "j neurosci . 2012;32(48):1733217344 .",
    "gentet lj , kremer y , taniguchi h , huang zj , staiger jf , petersen cch .",
    "unique functional properties of somatostatin - expressing gabaergic neurons in mouse barrel cortex .",
    "nat neurosci .",
    "2012;15(4):607612 .",
    "li l , ji x , liang f , li y , xiao z , tao hw , et  al .",
    "a feedforward inhibitory circuit mediates lateral refinement of sensory representation in upper layer 2/3 of mouse primary auditory cortex .",
    "j neurosci . 2014;34(41):1367013683 .",
    "truccolo w , eden ut , fellows mr , donoghue jp , brown en . a point process framework for relating neural spiking activity to spiking history , neural ensemble , and extrinsic covariate effects .",
    "j neurophysiol . 2005;93(2):10741089 .",
    "gilson m , moreno - bote r , ponce - alvarez a , ritter p , deco g. estimation of directed effective connectivity from fmri functional connectivity hints at asymmetries of cortical connectome .",
    "plos comput biol .",
    "2016;12(3):e1004762 .",
    "pulizzi r , musumeci g , van  den haute c , van de  vijver s , baekelandt v , giugliano m. brief wide - field photostimuli evoke and modulate oscillatory reverberating activity in cortical networks .",
    "2016;6:24701 .",
    "hertg l , durstewitz d , brunel n. analytical approximations of the firing rate of an adaptive exponential integrate - and - fire neuron in the presence of synaptic noise .",
    "front comput neurosci ."
  ],
  "abstract_text": [
    "<S> neural population equations such as neural mass or field models are widely used to study brain activity on a large scale . </S>",
    "<S> however , the relation of these models to the properties of single neurons is unclear . </S>",
    "<S> here we derive an equation for several interacting populations at the mesoscopic scale starting from a microscopic model of randomly connected generalized integrate - and - fire neuron models . </S>",
    "<S> each population consists of 50  2000 neurons of the same type but different populations account for different neuron types . </S>",
    "<S> the stochastic population equations that we find reveal how spike - history effects in single - neuron dynamics such as refractoriness and adaptation interact with finite - size fluctuations on the population level . </S>",
    "<S> efficient integration of the stochastic mesoscopic equations reproduces the statistical behavior of the population activities obtained from microscopic simulations of a full spiking neural network model . </S>",
    "<S> the theory describes nonlinear emergent dynamics such as finite - size - induced stochastic transitions in multistable networks and synchronization in balanced networks of excitatory and inhibitory neurons . </S>",
    "<S> the mesoscopic equations are employed to rapidly integrate a model of a cortical microcircuit consisting of eight neuron types , which allows us to predict spontaneous population activities as well as evoked responses to thalamic input . </S>",
    "<S> our theory establishes a general framework for modeling finite - size neural population dynamics based on single cell and synapse parameters and offers an efficient approach to analyzing cortical circuits and computations . </S>"
  ]
}