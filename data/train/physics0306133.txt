{
  "article_text": [
    "alice ( a large ion collider experiment ) is an experiment that will start in 2007 at the lhc ( large hadron collider ) at cern @xcite",
    ". the experiment will study collisions between heavy ions with energies around 5.5 tev per nucleon .",
    "the collisions will take place at the center of a set of several detectors , which are designed to track and identify the produced particles .",
    "one of the main detectors of the alice experiment is the time projection chamber ( tpc ) .",
    "its task is track finding , momentum measurement and particle identification by d@xmath0/d@xmath1 .",
    "good two - track resolution , required for correlation studies , is one of the main design goals .",
    "the tpc is a large horizontal cylinder , filled with gas , where a suitable axial electric field is present .",
    "when particles pass through , they ionize the gas atoms , and the resulting electrons drift in the electric field . by measuring the arrival of electrons at the end of the chamber",
    ", the tpc can reconstruct the path of the original charged particles .",
    "the electrons are collected by more than 570  000 sensitive pads where they create signals .",
    "these signals are amplified by a preamplifier  shaper and digitalized by a 10-bit a / d converter at a sampling frequency of 5.66  mhz .",
    "the digitalized signal is processed and formatted by an application specific integrated circuit ( asic ) called altro ( alice tpc read - out ) @xcite . at this stage ,",
    "the overall throughput of the 570  000 channels is around 8.4  gbyte / s .",
    "the total amount of the tpc data is expected to be about 1 pby per year . in order to keep the complexity and cost of the data storage equipment as low as possible",
    ", we have to reduce the volume of data using suitable data compression methods .",
    "the cost reduction of the data storage system is roughly proportional to the data compression factor .",
    "furthermore , it is better to implement the compression system in the front - end electronics at the output of the altro circuit , so that the cost for the optical links , which carry data out of the chamber to the following stages of the acquisition chain , could be also reduced.more sophisticated methods for tpc data compression based on online tracking , which will be used further in data acquisition chain are developed in bergen and heidelberg @xcite .",
    "the use of a lossy source model , justified by the fact that generally it can provide significantly higher compression ratios compared to lossless models , has the drawback that some deterioration in the reconstruction of data must be accepted .",
    "lossy source models have become very popular in the last decade in the field of audio and video compression for their remarkable performance .",
    "lossy models have been carefully designed so that reconstruction distortions are not perceived using psychovisual or psychoacoustic models or they remain comparable with the intrinsic signal noise .    obviously , for physical data , psychovisual or psychoacoustic tests are meaningless or even not applicable since the tpc signal is not to be observed by the human eye or ear . in @xcite , the compression noise introduced on the sample values by the described lossy or",
    "quasi lossless techniques has been evaluated in terms of rms of the introduced error ( rmse ) .",
    "however , in this case , the rmse , despite being a simple and well known distortion measure , is not very useful .",
    "the fundamental information that has to be extracted from tpc data are not sample values themselves but the physical quantities that enable the reconstruction of particle trajectories .",
    "therefore , the correct way to evaluate the importance of the distortion introduced by the compression  decompression process has to be related to the high level information that is carried by the data .",
    "in particular , tpc data are collected with the objective of measuring particle energy and trajectory .",
    "therefore , the most effective way to estimate the consequences of the compression distortion error , is to observe how the extraction of energy and trajectories are affected by the compression  decompression process .",
    "a simple way to obtain these estimates is to apply the cluster finding and tracking algorithms on both simulated data and their compressed  decompressed version and compare the results .",
    "this article is arranged in the following way . in section  [ sec : stochastic ] , all stochastic processes relevant for particle detection in alice tpc are briefly described . in section  [ sec : altro ] , tpc data format is specified . in section  [ sec : lossless ] , different lossless compression techniques are described and their efficiencies are compared . in section  [ sec : lossy ] , the fast one dimensional lossy compression technique is shown and the impact of compression  decompression to the distortion of most important physical quantities is demonstrated .",
    "a charged particle that traverses the gas of the chamber leaves a track of ionization along its trajectory .",
    "the collisions with the gas atoms are purely random .",
    "they are characterized by a mean free path @xmath2 between ionizing encounters , which is given by the ionization cross - section per electron @xmath3 and the density _",
    "n _ of electrons : @xmath4 therefore , the number of encounters along the length _",
    "l _ has the mean of @xmath5 , and the frequency distribution is given by poisson distribution @xmath6 the mean free path @xmath2 is given by the properties of the gas and by charged particle characteristics : @xmath7 where @xmath8 is the number of primary electrons per cm produced by a minimum ionizing particle ( mip ) , and @xmath9 is bethe ",
    "bloch curve .",
    "the energy loss @xmath10 released in primary ionization to atomic electrons is a random variable .",
    "it can be described by photo - absorbtion ionization model ( pai ) . in most cases , if one neglects the atomic shell structure , at sufficiently high @xmath10 ( the energy where the atomic shell structure is not more important ) it obeys @xmath11 rule .",
    "if the electron produced by the charged particle has sufficient kinetic energy @xmath10 , it will produce secondary electrons creating thus electron cluster .",
    "the mean total number of electrons in such cluster is given by : @xmath12 where @xmath10 is the energy loss in a primary collision , @xmath13 is the effective energy required to produce an electron ",
    "ion pair and @xmath14 is the first ionization potential .",
    "the random character of the secondary ionization process smears out structures in @xmath10 spectra , atomic shell structure behavior is suppressed .",
    "for example in the gas mixture 90% ne , 10 % co@xmath15 the @xmath16 effective parametrization at lower @xmath10 can be used .",
    "produced electrons drift through the gas with an effective constant drift velocity in the direction given by the electric field @xmath17 and magnetic field @xmath18 ( which we assume are parallel to _ z_-direction ) .",
    "drifting electrons are scattered on the gas molecules so that their direction of motion is randomized in each collision .",
    "the position of the electron , after drifting over a distance @xmath19 , can be described by 3-d gaussian distribution : @xmath20 \\nonumber \\\\ \\frac{1}{\\sqrt{2\\pi}\\sigma_{\\rm{t}}}\\exp\\left[-\\frac{(y - y_0)^2}{2\\sigma_{\\rm{t}}^2}\\right ] \\nonumber\\\\ \\frac{1}{\\sqrt{2\\pi}\\sigma_{\\rm{l}}}\\exp\\left[-\\frac{(z - l_{\\rm{drift}})^2}{2\\sigma_{\\rm{l}}^2}\\right],\\end{aligned}\\ ] ] where @xmath21 is the electron creation point and transversal diffusion @xmath22 respectively longitudinal diffusion @xmath23 are given by drift length @xmath19 and gas coefficient @xmath24 and @xmath25 @xmath26 @xmath27      it has been assumed that the electric and magnetic fields in the drift volume are uniform and parallel .",
    "this , however , is not true close to the anode wires , where the electric field becomes radial .",
    "thus the electrons experience a shift along the wire direction ( due to the lorentz force ) .",
    "if an electron enters the readout chamber at the point @xmath29 , it is displaced in the _ x_-direction ( assuming that the wires are placed along _",
    "y_-axis ) .",
    "the new _ y_-position of the electron is then given by @xmath30 where @xmath1 is the coordinate of the wire on which an electron is collected , and @xmath31 is the tangent of lorentz angle ( @xmath28 effect ) . the drift length which determines _ z",
    "_ coordinate will be also affected , because of change in the path to the anode wire ( unisochronity effect ) .      inside the readout chamber ,",
    "as an electron drifts towards the anode wire , it travels in an increasing electric field . once the electric field is strong enough that between collisions with the gas molecules the electron can pick up sufficient energy for ionization , another electron is created and the avalanche starts . as the number of electrons multiplies in successive generations , the avalanche continues to grow until all the electrons are collected on the wire .",
    "the resulting number of electrons created in the avalanche , can be described by an exponential probability distribution @xmath32 where @xmath33 is the average avalanche amplitude .",
    "an electron avalanche collected on the anode wire induces a charge on the pad plane .",
    "this charge is integrated over the pad area .",
    "the time signal is obtained by folding the pad response to the avalanche with the shaping function of the preampamplifier  shaper .",
    "this signal is then sampled with a constant frequency . on the top of sampled signal a random electronic noise",
    "is superimposed .    as a result",
    "a charged particle interacting with gas generates a cluster of amplitudes .",
    "this cluster is used for later estimation of local track position and of local energy deposition .",
    "the shape of the cluster is used as additional information for the estimation of position uncertainties and for the estimation of the overlap factor between two tracks .",
    "the accuracy of the coordinate measurement is limited by a track angle which spreads ionization and by diffusion which amplifies this spread .",
    "the track direction with respect to pad plane is given by two angles @xmath34 and @xmath35 ( see fig .  [ figtpc ] ) .",
    "for the measurement along the pad - row , the angle @xmath34 between the track projected onto the pad plane and pad - row is relevant . for the measurement of the the drift coordinate ( _ z_direction )",
    "it is the angle @xmath35 between the track and _ z _ axis .",
    "the ionization electrons are randomly distributed along the particle trajectory . fixing the reference _ x _ position of a electron at the middle of pad - row , the _ y _ ( resp .",
    "_ z _ ) position of the electron is random variable characterized by uniform distribution with the width @xmath36 , where @xmath36 is given by the pad length @xmath37 and the angle @xmath34 ( resp .",
    "@xmath35 ) : @xmath38 the diffusion smears out the position of the electron with gaussian probability distribution with @xmath39 .",
    "contribution of the @xmath28 and unisochronity effect is in the case of alice tpc negligible .",
    "the accuracy of the position measurement can be expressed as :    @xmath40 of cluster center in z ( time ) direction : @xmath41    and @xmath42 of cluster center in y(pad ) direction : @xmath43 where @xmath44 is the total number of electrons in cluster , @xmath45 is the number of primary electrons in cluster , @xmath46 is the gas gain fluctuation factor parametrization , @xmath47 is the secondary ionization fluctuation factor and @xmath48 describe the contribution of the electronic noise and adc quantization to the resulting sigma of the cog .",
    "the typical resolution in the case of alice tpc is on the level of @xmath49  0.8 mm and @xmath50  1.0 mm integrating over all clusters in the tpc .",
    "the total charge deposited in the clusters can be used for particle identification . the important value , which is specific for different particle types and different particle momenta , is the number of primary collision per unit length , @xmath51 .",
    "@xmath51 is a random variable described by poisson distribution . due to the secondary ionization and gas gain",
    "fluctuations the total charge is described by very broad landau distribution .",
    "before describing the compression algorithm , it is necessary to spend a few words on the format of data at the output of altro circuit , in order to understand how the compression algorithms are applied .",
    "such data are indeed the input of the compression system @xcite .    in the altro data format only the samples over a given threshold are considered , while the others are discarded .",
    "this means that , if we call _ bunch _ a group of adjacent over - threshold samples coming from one pad , the signal can be represented `` bunch by bunch '' .",
    "more precisely , a bunch is described by three fields : temporal information ( temporal position of the last sample in the bunch ) , one 10-bit word , bunch length ( i.e. the number of samples in the bunch , one 10-bit word ) , and sample amplitude values ( few 10-bit words ) .",
    "the lossless techniques of the data compression are based on the fact that tpc sample values ( adc and temporal ) are not equally probable .",
    "a theoretical lower limit on the average word size using huffman codding , or arithmetic coding lossless technique is given by entropy of the data source :    @xmath52    the lossless techniques described in this paper are based mainly on an appropriate probability model for each data field of the altro data format .",
    "specific probability models for each sample in a bunch were developed .",
    "these models intend to capture both temporal correlation among samples and the characteristic shape of tpc electrical pulses .",
    "as already mentioned , in the altro data format time information is represented as the 10-bit number of the time - bin of the last sample of the bunch .",
    "the probability distribution of this variable is roughly uniform . in order to achieve better compression ratio this variable",
    "is substituted by the distance between two consecutive bunches .",
    "the probability of this variable is described by exponential distribution with much lower entropy factor .",
    "the entropy of temporal information is given by mean distance between two bunches .",
    "it depends on the event multiplicity , noise level and local occupancy , which is known function of the pad - row radius . in order to optimize entropy coding",
    ", it will be necessary to investigate probability distribution as a function of track multiplicity .",
    "this information will be known from other faster alice detectors .",
    "the mean number of bits used for the coding of time information is roughly 4.9 bits for the full event with maximal track density . using different codes in different places inside tpc , an additional 6% reduction in time",
    "information can be achieved .      in the altro data format ,",
    "the bunch length is represented as a 10-bit code number of samples in the bunch .",
    "the bunch length depends on the diffusion , the angular effect and the total deposited energy .",
    "there is no apparent correlation with data coded before .",
    "small diffusion for short drift length is compensated by big angular effect .",
    "the total deposited energy is known only after coding of the bunch length . since no apparent correlation with other data ( e.g. length of adjacent bunches ) exists and no better model ( i.e. a model of events with lower entropy ) could be found ,",
    "this information is coded directly .",
    "sample values are the main contribution to the resulting data volume .",
    "this subsection describes , first a basic model , and then introduces a more sophisticated one , that can provide higher performances in terms of compression efficiency .",
    "data compression can be obtained by directly applying entropy coding to the sample values without any modelling of the information source .",
    "this method will be referred bellow ( in table  [ tablossless ] ) as entropy coding ( ec ) .",
    "improvements in compression performance can be obtained by appropriate modelling .",
    "a first improvement has been achieved by the fact that the statistics of the signal sample values depend on the position of the sample itself in the bunch .",
    ".[tab : sampleentropy]entropy of the sample data as a function of the sample position in the bunch .",
    "frequency of the sample length is given in arbitrary units . [ cols=\"<,^,^,^,^,^,^\",options=\"header \" , ]      in the following study , dynamic precision of sample quantization was investigated .",
    "the quantization was chosen to correspond to the sample deviation , modifying formula ( [ eq : sample ] ) to : @xmath53 where @xmath54 and @xmath55 factors were chosen as free parameters .",
    "@xmath54 is proportional to the electronic noise and @xmath55 is given by statistics of the stochastic processes and by correlations .",
    "different combinations of these factors were investigated .    in table [ tab : cflossy ] the influence of different quantization on the precision of the cluster characteristic determination is shown .",
    "the gain factor @xmath56 ( @xmath57 is the total charge in cluster , @xmath58 is the number of electrons contributing to the cluster ) measures the precision of the local deposited energy determination .",
    "this factor is important for d@xmath0d@xmath1 measurement and consequently for particle identification ( pid ) .",
    "the influence of the compression on the cluster position determination varies between 0 to 4% , depending on the compression factor , as can be expected .",
    "the shape of the cluster ( @xmath59 and @xmath60 ) , important for cluster quality determination , varies between 1 to 6% .    in table",
    "[ tab : trackerlossy ] the influence of the compression on the tracking is shown . reported distortions in @xmath61 and angular resolution are slightly smaller than in the case of the cluster position(0% up to 3.5% ) .",
    "this is due to the other stochastic processes which contribute to the track parameters e.g. the multiple scattering . for high - momentum particles , where the influence of multiple scattering is not so important ,",
    "the expected distortion will be determined by the cluster position distortions .    reducing the number of the possible sample values , vector quantization of bunches",
    "were also investigated .",
    "additional reduction factor of @xmath626% was achieved on top of the results reported in table [ tab : cflossy ] .",
    "several methods of lossless tpc data compression was investigated ( sec .  [ sec : losslescomp ] ) .",
    "the best one dimensional methods provide compression factor down to 49.2% .    a lossy compression approach for the data generated by the tpc chamber in the alice experiment has been also investigated .",
    "the main idea was to preserve , on the level intrinsic noise , the three more important local quantities : the cluster position , the deposited energy and the shape of the cluster . keeping the distortions of the local quantities at a reasonable level ,",
    "the impact on the most interesting physical quantities , particle momenta and d@xmath0d@xmath1 is minimal .",
    "this approach achieves compression rates in the range from 35% down to 30% , depending on the desired precision . in this study",
    "we have focused on methods which are easy to implement in the frontend tpc electronics .",
    "9 alice collaboration , alice technical design report of the time projection chamber l. musa and r. e. bosch , alice tpc readout chip , internal note,2000 tpc data compression , nim a 489(2002),406 - 421 a. nicolaucig , compressione dei dati generati dalla time projection chamber nellesperimento alice presso il cern,2000"
  ],
  "abstract_text": [
    "<S> in this paper lossless and a quasi lossless algorithms for the online compression of the data generated by the time projection chamber ( tpc ) detector of the alice experiment at cern are described .    </S>",
    "<S> the first algorithm is based on a lossless source code modelling technique , i.e. the original tpc signal information can be reconstructed without errors at the decompression stage . </S>",
    "<S> the source model exploits the temporal correlation that is present in the tpc data to reduce the entropy of the source .    </S>",
    "<S> the second algorithm is based on a lossy source code modelling technique , i.e. it is lossy if samples of the tpc signal are considered one by one . nevertheless , the source model is quasi - lossless from the point of view of some physical quantities that are of main interest for the experiment . </S>",
    "<S> these quantities are the shape , the location of the center of gravity as well as the total charge of the signal .    in order to evaluate the consequences of the error introduced by the lossy compression , the results of the trajectory tracking algorithms that process data offline are analyzed , in particular , with respect to the noise introduced by the compression . </S>",
    "<S> the offline analysis has two steps : cluster finder and track finder . </S>",
    "<S> the results on how these algorithms are affected by the lossy compression are reported .    in both compression technique entropy coding </S>",
    "<S> is applied to the set of events defined by the source model to reduce the bit rate to the corresponding source entropy . using tpc simulated data , </S>",
    "<S> the lossless and the lossy compression achieve a data reduction to 49.2% of the original data rate and respectively in the range of 35% down to 30% depending on the desired precision .    in this study </S>",
    "<S> we have focused on methods which are easy to implement in the frontend tpc electronics . </S>"
  ]
}