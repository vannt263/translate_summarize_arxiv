{
  "article_text": [
    "the concept of state means to a situation which a material system maintains , and it is characterized by a group of physical qualities . the process of a system turning from a state to another is called state transition , which can be described by a state transition matrix .",
    "the idea of state transition was created by a russian mathematician named markov when he expected to represent a specific stochastic process ( known as markov process)@xcite .",
    "not only in communication theory but also in modern control theory , state transition matrix is of great importance .",
    "for instance , in modern control theory , it can determine the stability of a system .",
    "+ in almost all branches of engineering , including system design , tactical planning , system analysis , process management and control , and model parameter adjustment , optimization techniques have found wide applications@xcite . generally speaking",
    ", the methods used for solving such optimization problems can be classified into two categories : deterministic and stochastic , in which , stochastic methods are subdivided into evolutionary algorithms and metaheuristic algorithms .",
    "the traditional deterministic algorithms include hooke - jeeves pattern search@xcite and hill - climbing , evolutionary algorithms contain genetic algorithm ( ga)@xcite , evolutionary programming , evolution strategies , and genetic programming , while metaheuristic algorithms consist of simulated annealing , particle swarm optimization ( pso)@xcite , differential evolution(de ) algorithm@xcite , etc . on the other hand , the commonly used numerical algorithms for engineering optimization problems",
    "can also be categorized into two classes : direct search methods and gradient - based methods .",
    "the direct search methods comprise the simplex search , powell s conjugate direction method and random search , while the gradient - based methods include the newton s ( basic- , modified- , quasi- ) and conjugate gradient methods@xcite . in the same time , hybrid methods , combining of deterministic and stochastic or direct search and gradient - based , are also proposed to draw on each other s strengths@xcite . + according to the no free lunch theorem@xcite , no search algorithm is better than other algorithms on the space of all possible problems .",
    "this paper introduces a new method for optimization of continuous nonlinear functions , which belongs to metaheuristic random search . because of its foundation on state and state transition , the method",
    "is called state transition algorithm ( sta)@xcite . the algorithm has roots in three main component methodologies .",
    "one is the random optimization theory , the others are population - based approach and then space transformation method . in this paper , it focuses on four operators named rotation , translation , expansion and axesion transformation as well as the communication strategy in state transition algorithm .",
    "compared with some state - of - the - art optimization algorithms , rcga@xcite , clpso@xcite , and sade@xcite , which are improved versions of ga , pso and de , the experimental results show that stas are comparable and promising algorithms .",
    "considering the following unconstrained optimization problem @xmath0 in a deterministic view , it usually adopts iterative method to solve the problem @xmath1 where , @xmath2 is the _ _ k__th iteration point , @xmath3 is the _ _",
    "k__th step size and @xmath4 is the _ _ k__th search direction . + the common selection of a step is by exact line search or inexact line search . while the techniques of search direction include steepest descent method , conjugate gradient methods , newton s methods , alternating directions , and conjugate direction methods@xcite .",
    "+ in a way , the iterative methods aim to search for a direction and a step in an iteration .",
    "though these methods utilize the gradient information explicitly or implicitly , they have their inherent defects . for one thing , it is computationally difficult . for another , it only indicates the local information . in the view of global optimization ,",
    "the direction of gradient is just a way standing for direction , and it has no substantial effect on searching for a global optimum . if the iterative method is concerned in a state and state transition way , then an iterative point can be regarded as a state , the process of searching for a direction and a step will equate to a state transition process , and through a state transition , a new state will be created . + in the point of stochastic , it can also understand the evolutionary algorithms and metaheuristic algorithms in a state and state transition way .",
    "for example , genetic algorithm , its each individual of a generation can be considered as a state , and the updating process of using genetic operators such as selection , crossover and mutation can equate to state transition processes . in the same way , particle swarm optimization , the flock updating its velocity and position , and differential evolution , adding the difference vector of two randomly chosen vectors to a target vector , can also be regarded as state transition processes .",
    "+ in terms of the concept of state and state transition , a solution to a specific optimization problem can be described as a state , the operators of optimization algorithms can be considered as state transition , and the process to update current solution will become a state transition process . + through the above analysis and discussion , it defines the following form of state transition @xmath5 where , @xmath2 stands for a state , corresponding to a solution to the optimization problem ; then , @xmath6 and @xmath7 are state transition matrixes , which can be regarded as operators of optimization algorithm ; @xmath8 is the function of state @xmath2 and historical states ; while @xmath9 is the cost function or evaluation function .      as a matter of fact",
    ", operators such as reflection , contraction , expansion and rotation are widely used in simplex optimization method@xcite , which is especially popular in the fields of chemistry , chemical engineering , and medicine .",
    "however , they always fail to lead to continued progress and are not applicable to a wide range of functions .",
    "+ in the theory of space and transformation , rotation matrices are only defined for two and three dimensional transformation . for example , the two dimensional rotation matrix is @xmath10 $ ] .",
    "+ using various types of space transformation for reference , in this paper , it defines the following four special state transformation operators to solve continuous function optimization problems .",
    "+ ( 1 ) rotation transformation @xmath11 where , @xmath2 @xmath12 @xmath13 , @xmath14 is a positive constant , called rotation factor ; @xmath15",
    "@xmath12 @xmath16 , is random matrix with its entries obeying the uniform distribution in the range of [ -1 , 1 ] and @xmath17 is 2-norm of vector or euclidean norm .",
    "then , it will prove that the rotation transformation has the function of searching in a hypersphere .",
    "@xmath18    \\(2 ) translation transformation @xmath19 where , @xmath20 is a positive constant , called translation factor ; @xmath21 @xmath22 is a random variable with its components obeying the uniform distribution in the range of [ 0,1 ] .",
    "it is obvious to find the translation transformation has the function of searching along a line from @xmath23 to @xmath2 at the starting point @xmath2 , with the maximum length of @xmath20 .",
    "+ ( 3 ) expansion transformation @xmath24 where , @xmath25 is a positive constant , called expansion factor ; @xmath26 is a random diagonal matrix with its elements obeying the gaussian distribution ( in this study , standard normal distribution ) .",
    "it is also obvious to find the expansion transformation has the function of expanding the components in @xmath2 to the range of [ -@xmath27 , + @xmath27 ] , searching in the whole space .",
    "+ ( 4 ) axesion transformation @xmath29 where , @xmath30 is a positive constant , called axesion factor ; @xmath31 @xmath32 is a random diagonal matrix with its entries obeying the gaussian distribution and only one random position having nonzero value . the axesion transformation aims to search along the axes and strengthens single dimensional search .      before the state transition algorithm",
    ", it is necessary to introduce the basic random optimization@xcite .",
    "considering the above unconstrained optimization problem , the procedure of the basic random optimization can be outlined in the following pseudocode .",
    "+    initialize feasible solution @xmath33 , and set @xmath34 @xmath35 generate a gaussian random number vector @xmath36 @xmath37 @xmath38     + for one thing , as a metaheuristic random method , the state transition algorithm is similar to the basic random optimization@xcite .",
    "the only difference is that a candidate solution set is generated by the four special operators , while a new trail is selected following the same way as that of the basic random optimization , which means that the `` greedy criterion '' is used in selecting the new state . by the way ,",
    "a candidate solution set is created by some times of transformation .",
    "the times of the transformation or the size of the set is called search enforcement ( _ se _ ) , and the translation operator is only performed when a better new trail is found .",
    "+ for another , as a stochastic algorithm@xcite , the dealing with dynamic balance between diversification ( exploration of the solution space ) and intensification ( exploitation of the accumulated knowledge ) is also significant in state transition algorithm . due to their intrinsic properties ,",
    "the rotation is chosen for exploitation , the expansion is for exploration , the translation is selected as to maintain equilibrium between them , and axesion is proposed to strength the single dimensional search .",
    "+ the main process of sta is shown in the pseudocode as follows     + as for detailed explanations , expansion function in above pseudocode is given as follows for example      in state transition algorithm , there are five important parameters , namely search enforcement(_se _ ) , rotation factor @xmath14 , translation factor @xmath20 , expansion factor @xmath25 and axesion factor @xmath30 .",
    "it is easy to understand that the larger the search enforcement , the higher the intensity of search , and vise versa .",
    "however , the larger search enforcement will cause larger computational complexity . in this paper , the search enforcement is recommended to use the same size as the dimension of the optimization problem .",
    "+ when _ se _ is constant , taking the exploration and exploitation into consideration , the strategy of adjusting parameters of the four operators is significant . to make the deeper exploitation , the smaller rotation factor is needed . especially , the rotation factor will vary in a declining way from a positive constant till zero to gain a high precision solution . in the meanwhile ,",
    "there are two schemes to regulate the @xmath14 .",
    "one is to adjust the parameter in an inner loop , namely , decreasing the rotation factor from a start constant to the end in the operation of rotation transformation@xcite .",
    "the other is to adjust the parameters in an outside loop , that is to say , decreasing the rotation factor according to the iterations . to balance the global search and local search timely",
    ", the latter scheme is adopted in the paper ; however , the rotation factor is decreasing itself from a maximum value to a minimum value in an exponential way with base _ fc _ , which is called lessening coefficient@xcite , as described in the pseudocode of sta . by the way ,",
    "extra tests have testified the effectiveness of the scheme . + as for the remained control parameters , for example , the larger the translation factor , the longer sta searches along a straight line .",
    "however , the magnitude of translation factor has great influence on exploitation and exploration .",
    "the large translation factor will facilitate the exploration , while the small translation factor benefits the exploitation .",
    "similarly , the same phenomenon exists in the selection of expansion and axesion factors . taking the complexity of adjusting strategies for these control parameters into consideration , we keep them fixed in current version of sta for simplicity .",
    "the convergence of stochastic optimization algorithms has been heatedly discussed .",
    "for instance , genetic algorithm was analyzed by means of homogeneous finite markov chain@xcite , particle swarm optimization was studied to investigate particle trajectories in a discrete system view@xcite , and convergence property of differential evolution was also discussed in@xcite .",
    "+ as a metaheuristic random optimization algorithm , the convergence analysis of sta will follow the same way as random search methods .",
    "in fact , the probability of random search algorithm for finding global minimum being equal to 1 was stated by solis and wets@xcite .",
    "that is to say , the sta will satisfy the similar convergence performance of random optimization algorithm , and readers who are interested in convergence analysis are referred to their work for details .",
    "in a way , the basic state transition algorithm is individual - based , and an individual searches in its neighborhood .",
    "the difference between the basic state transition algorithm and other random optimizations is that the search space is normalized or specialized .",
    "+ the population - based approach is prevalent in metaheuristic algorithms , such as genetic algorithm , particle swarm optimization and differential evolution . let s name the basic state transition algorithm stai , the improved state transition algorithm based on population is called staii with the number of states denoted as _",
    "sn_. in the meanwhile , some communication strategies are necessary to manage the individuals for sharing information , which is important in population - based methods .",
    "individual communication can be implemented in various ways , of which crossover operation is quite common , especially in genetic algorithms .",
    "+ let @xmath39 and @xmath40 be individual components of current generation , @xmath41 and @xmath42 are the offspring components , some canonical crossover operators are displayed in the following .",
    "+ ( 1 ) michalewicz s arithmetical crossover@xcite @xmath43 where , @xmath14 is either a constant or a variable whose value depends on the age of population . + ( 2 ) wright s linear crossover@xcite @xmath44 ( 3 ) kalyanmoy deb s simulated binary crossover@xcite @xmath45\\\\ y_2= 0.5 [ ( 1+\\beta)x_1 + ( 1-\\beta)x_2 ] \\end{array } , \\right.\\ ] ] where , @xmath20 is a random variable , obeying the following probability distribution @xmath46 here , @xmath47 is the probability density function , @xmath48 is the distribution index , which determine how well spread the children will be inherited from their parents .",
    "+ ( 4 ) the proposed crossover @xmath49 where , @xmath30 and @xmath50 are independent variables , which obey the 0 - 1 distribution .",
    "+ in this proposed crossover , crossover operation means for each component of a pair of individuals , components exchange or maintain their information completely .",
    "different from other population based algorithms , all of the individuals in staii are elites , and they develop themselves trough state transformation , which is referred as self learning .",
    "when the communication strategy is introduced , the individual can contact with each other to better develop themselves .",
    "however , it may bring about some disadvantageous effects .",
    "if the frequency of individual communication is too high , individuals are apt to imitate each other utterly , which will cause premature convergence . in this paper , intermittent exchange",
    "is proposed to solve the issue , that is to say , individual communication occurs at a certain frequency , where the frequency is named communication frequency ( _ cf _ ) .",
    "+ the communication strategy is adopted to share information among individuals , and it is regulated by communication frequency . if _",
    "cf _ is small enough , it will equate the situation without the communication strategy .",
    "cf _ is too large , individuals are easily trapped into imitating each other , causing the premature convergence , that is to say , a moderate _ cf _ is appropriate . in this paper",
    ", we recommend to use the same magnitude as square root of the maximum iterations .",
    "+ when the exchange condition is satisfied , the proposed crossover operator will be performed .",
    "each state will communicate with all of the other states , to make sure that useful information is completely shared .      through the above discussion and analysis , by introducing in communication strategy , the pseudocode of the kernel of state transition algorithm can be described as shown in the following    in the process of the algorithm , the @xmath51 means each state in the state set will be performed on four state transformation operators , while in @xmath52 function , the intermittent exchange is adopted at intervals .",
    "the flowchart of the algorithm is outlined in figure 1 .",
    "to compare the proposed state transition algorithm with previously mentioned rcga , clpso and sade , two experiments are arranged .",
    "the first experiment is mainly for two dimensional functions , and the other focuses on ten dimensional functions test . in the same time , both stai and staii are carried out , for comparison with other algorithms as well as themselves .      in order to test the performance of sta ,",
    "ten common benchmark functions are selected for the experiment .",
    "seven functions are multidimensional functions of various modals and the other three are two dimensional functions , which are listed in table 1 , while the landscapes of two dimensional functions are plotted in figure 2 .",
    "cccc name of function & function definition & range & @xmath53 + spherical & @xmath54 & [ -100,100 ] & 0 + rastrigin & @xmath55 & [ -5.12,5.12 ] & 0 + griewank & @xmath56 & [ -600,600 ] & 0 + rosenbrock & @xmath57 & [ -30,30 ] & 0 + schewefel & @xmath58 $ ] & [ -500,500 ] & -418.9829n + ackley & @xmath59 & [ -32,32 ] & 0 + michalewicz & @xmath60 & @xmath61 $ ] & - + schaffer & @xmath62 & [ -100,100 ] & 0 + easom & @xmath63 & [ -100,100 ] & -1 + goldstein - price & @xmath64\\times [ 30+(2x_{1}-3x_{2})^2\\\\ ( 18 - 32x_{1}+12x_{1}^2 + 48x_{2}-36x_{1}x_{2}+27x_{2}^2 ) ] \\end{array } $ ] & [ -2,2 ] & 3 +     +   +   +      all of the algorithms were run on matlab ( version r2010b ) software platform . for simplicity and normalization , the experiment specifies all the control parameters of transformation operators in stai and staii starting at 1 .",
    "commonly , the variation of a parameter follows a linear , exponential or a logistic way . in this paper ,",
    "the exponential way is accepted for its rapidity , of which the base is 2 in the experiment . in view of the operational precision of matlab in short format , the minimum @xmath14 factor fixed at 1e-4 is enough for the situation . + as for rcga , we use the same parameter settings as in@xcite . then , for clpso and sade , we use the matlab codes provided by the author in@xcite with minor revisions for this experiment .",
    "+ programs were run independently for 30 trails , and for each trail , the population scale is 30 , and the maximum iteration is 1000 .",
    "the detailed parameters of stai and staii are shown in table 2 and table 3 , respectively .",
    "cc _ parameter _ & _ value _ + se & 30 + @xmath14 & 1 @xmath65 1e-4 + @xmath20 & 1 + @xmath25 & 1 + @xmath30 & 1 + fc & 2 +    cc _ parameter _ & _ value _ + sn & 30 + se & 10 + cf & 50 + @xmath14 & 1 @xmath65 1e-4 + @xmath20 & 1 + @xmath25 & 1 + @xmath30 & 1 + fc & 2 +      for comparison , some common statistics are introduced .",
    "best _ means the minimum of the results , the _ worst _ indicates the maximum of the results , and then it follows the _",
    "mean _ , _ median _ and _ st.dev._(standard deviation ) . in some way , these statistics are able to evaluate the search ability and solution accuracy , reliability and convergence as well as stability . to be more specific , the _",
    "best _ indicates the global search ability and solution accuracy , the _ worst _ and the _ mean _ signify the reliability and convergence , while the _ median _ and _ st.dev . _",
    "correspond to the stability .",
    "+ results for two dimensional functions optimization are listed in table 4 , while results for ten dimensional functions optimization can be found in table 5 . on the other hand ,",
    "illustrations of the average fitness in 30 simulations are given in figure 3 and figure 4 for two dimensional and ten dimensional functions , respectively .",
    "the average fitness curve can visually depict the search ability and convergence performance . in the following paragraphs",
    "the analysis of the results for each functions will be discussed separately .",
    "p0.5cmccccccc fcn & statistic & rcga & clpso & sade & stai & staii + & best & 1.5795e-028 & 2.7344e-091 & 2.9229e-196 & 0 & 0 + & median & 4.9090e-024 & 2.6808e-087 & 4.2548e-189 & 0 & 0 + @xmath66 & mean & 1.5458e-022 & 5.9580e-082 & 6.6729e-188 & 0 & 0 + & worst & 2.5849e-021 & 1.7771e-080 & 9.6210e-187 & 0 & 0 + & st.dev . & 4.7939e-022 & 3.2440e-081 & 0 & 0 & 0 + & best & 0 & 0 & 0 & 0 & 0 + & median & 0 & 0 & 0 & 0 & 0 + @xmath67 & mean & 0 & 0 & 0 & 0 & 0 + & worst & 0 & 0 & 0 & 0 & 0 + & st.dev .",
    "& 0 & 0 & 0 & 0 & 0 + & best & 0 & 0 & 0 & 0 & 0 + & median & 0.0074 & 0 & 0 & 0 & 0 + @xmath68 & mean & 0.0042 & 1.2460e-009 & 0 & 0 & 0 + & worst & 0.0074 & 3.7377e-008 & 0 & 0 & 0 + & st.dev . & 0.0037 & 6.8241e-009 & 0 & 0 & 0 + & best & 7.0832e-008 & 9.2890e-010 & 0 & 1.0092e-012 & 4.2592e-014 + & median & 0.0085 & 3.9984e-007 & 0 & 1.0900e-011 & 3.9400e-012 + @xmath69 & mean & 1.0364 & 3.9260e-005 & 0 & 1.2571e-011 & 4.4217e-012 + & worst & 26.2801 & 6.3652e-004 & 0 & 4.7764e-011 & 1.4588e-011 + & st.dev .",
    "& 4.7802 & 1.4088e-004 & 0 & 1.0692e-011 & 3.9023e-012 + & best & -837.9658 & -837.9658 & -837.9658 & -837.9658 & -837.9658 + & median & -837.9658 & -837.9658 & -837.9658 & -837.9658 & -837.9658 + @xmath70 & mean & -822.1740 & -837.9658 & -837.9658 & -837.9658 & -837.9658 + & worst & -719.5274 & -837.9658 & -837.9658 & -837.9658 & -837.9658 + & st.dev . & 40.9496 & 0 & 0 & 1.5939e-013 & 1.0970e-013 + & best & 2.0428e-014 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 + & median & 3.1681e-012 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 + @xmath71 & mean & 4.7516e-011 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 + & worst & 9.6937e-010 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 + & st.dev .",
    "& 1.8319e-010 & 0 & 0 & 0 & 0 + & best & -1.8013 & -1.8013 & -1.8013 & -1.8013 & -1.8013 + & median & -1.8013 & -1.8013 & -1.8013 & -1.8013 & -1.8013 + @xmath72 & mean & -1.8013 & -1.8013 & -1.8013 & -1.8013 & -1.8013 + & worst & -1.8013 & -1.8013 & -1.8013 & -1.8013 & -1.8013 + & st.dev . & 9.0336e-016 & 9.0336e-016 & 9.0336e-016 & 2.2063e-011 & 7.6618e-012 + & best & 0 & 0 & 0 & 0 & 0 + & median & 0.0097 & 9.3299e-012 & 0 & 0 & 0 + @xmath73 & mean & 0.0071 & 4.1836e-004 & 6.4773e-004 & 0 & 0 + & worst & 0.0097 & 0.0097 & 0.0097 & 0 & 0 + & st.dev . & 0.0044 & 0.0018 & 0.0025 & 0 & 0 + & best & -1.0000 & -1.0000 & -1.0000 & -1.0000 & -1.0000 + & median & -1.0000 & -1.0000 & -1.0000 & -1.0000 & -1.0000 + @xmath74 & mean & -1.0000 & -1.0000 & -1.0000 & -1.0000 & -1.0000 + & worst & -1.0000 & -1.0000 & -1.0000 & -1.0000 & -1.0000 + & st.dev . & 0 & 0 & 0 & 1.0124e-012 & 2.6511e-013 + & best & 3.0000 & 3.0000 & 3.0000 & 3.0000 & 3.0000 + & median & 3.0000 & 3.0000 & 3.0000 & 3.0000 & 3.0000 + @xmath75 & mean & 3.0000 & 3.0000 & 3.0000 & 3.0000 & 3.0000 + & worst & 3.0000 & 3.0000 & 3.0000 & 3.0000 & 3.0000 + & st.dev .",
    "& 2.5135e-015 & 1.5317e-015 & 1.2669e-015 & 2.5697e-010 & 1.2191e-010 +     +   +   +    p0.5cmccccccc fcn & statistic & rcga & clpso & sade & stai & staii + & best & 4.0118e-012 & 1.5229e-012 & 1.0686e-053 & 0 & 0 + & median & 4.1019e-011 & 5.3464e-011 & 1.6873e-051 & 0 & 0 + @xmath66 & mean & 8.4302e-011 & 6.0282e-011 & 3.5549e-051 & 0 & 0 + & worst & 5.6332e-010 & 1.6279e-010 & 2.7214e-050 & 0 & 0 + & st.dev . & 1.1766e-010 & 4.9198e-011 & 6.1159e-051 & 0 & 0 + & best & 1.0814e-011 & 1.9806e-006 & 0 & 0 & 0 + & median & 2.9849 & 1.0401e-005 & 0 & 0 & 0 + @xmath67 & mean & 2.6864 & 2.7769e-005 & 0.0332 & 0 & 0 + & worst & 5.9697 & 2.5009e-004 & 0.9950 & 0 & 0 + & st.dev . & 1.5491 & 4.7363e-005 & 0.1817 & 0 & 0 + & best & 3.2914e-010 & 2.6061e-005 & 0 & 0 & 0 + & median & 0.0492 & 0.0019 & 0 & 0 & 0 + @xmath68 & mean & 0.0582 & 0.0038 & 5.7529e-004 & 0.0166 & 0 + & worst & 0.1699 & 0.0166 & 0.0099 & 0.0738 & 0 + & st.dev . & 0.0439 & 0.0045 & 0.0022 & 0.0260 & 0 + & best & 0.0662 & 0.6841 & 8.3515e-012 & 2.6607e-005 & 7.3949e-005 + & median & 7.2483 & 4.0404 & 3.4637e-004 & 1.7823 & 0.2809 + @xmath69 & mean & 7.0110 & 4.3775 & 0.3415 & 2.3266 & 0.4095 + & worst & 9.2754 & 12.3253 & 3.9866 & 21.8603 & 1.5228 + & st.dev .",
    "& 1.4466 & 2.8042 & 1.0098 & 3.7249 & 0.4124 + & best & -3.9530e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 + & median & -3.8345e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 + @xmath70 & mean & -3.7832e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 + & worst & -3.3608e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 & -4.1898e+003 + & st.dev .",
    "& 151.3665 & 5.5006e-008 & 2.7751e-012 & 1.1734e-011 & 1.9256e-012 + & best & 6.6339e-007 & 1.5533e-006 & -8.8818e-016 & -8.8818e-016 & -8.8818e-016 + & median & 2.8352e-006 & 4.0369e-006 & 2.6645e-015 & -8.8818e-016 & -8.8818e-016 + @xmath71 & mean & 3.1524e-006 & 4.8197e-006 & 2.3093e-015 & 2.9606e-016 & -8.8818e-016 + & worst & 9.6980e-006 & 1.3052e-005 & 2.6645e-015 & 2.6645e-015 & -8.8818e-016 + & st.dev . & 2.1010e-006 & 3.2984e-006 & 1.0840e-015 & 1.7034e-015 & 0 + & best & -9.6154 & -9.6601 & -9.6602 & -9.6602 & -9.6602 + & median & -9.2604 & -9.6598 & -9.6602 & -9.6602 & -9.6602 + @xmath72 & mean & -9.2425 & -9.6588 & -9.6513 & -9.1797 & -9.6602 + & worst & -8.7143 & -9.6549 & -9.6135 & -7.6602 & -9.6602 + & st.dev . &",
    "0.2265 & 0.0018 & 0.0173 & 0.6044 & 1.9138e-009 +     +   +     + * spherical function : * as can be seen from the results , all of the algorithms can find the global optimum with high solution precision and have good reliability as well as stability for this function in terms of two and ten dimensions .",
    "but the stai and staii are able to search much deeper than other three algorithms , which can also be observed in subfigure ( a ) of figure 3 and figure 4 . in the subfigure ( a )",
    ", we can see that stas can converge much faster than the remained methods .",
    "while for stai and staii , it is found that stai has a little faster convergence performance than that of staii . +",
    "* rastrigin function : * we can see from the results that all of the algorithms can find the global optimum and have good reliability as well as stability in two dimension .",
    "for the ten dimensional problem , the global optimum can also be found by all algorithms ; however , stai and staii have better statistical performances than other three algorithms especially described by the _",
    "worst_. rcga and sade can not achieve the best occasionally , and the _ mean _ of rcga is not satisfactory .",
    "from subfigure ( b ) of figure 3 and figure 4 , we can also find that stas converge much faster than other algorithms , and higher solution precision can be obtained . in this time , the process of staii is slightly faster than that of stai . +",
    "* griewank function : * from the results , we can find that most algorithms have the ability to achieve the best and have both reliability and stability in the two dimensional function except the rcga .",
    "while for the ten - dimension function , these methods are able to find the global optimum but the statistical performances are not satisfactory except staii , the results of which are excellent . in subfigure ( c ) of figure 3 and figure 4 , it can be found that staii converge fastest and have highest solution precision of all .",
    "+ * rosenbrock function : * all of the algorithms have no problem to find the global optimum for this function in two - dimensional space , but the _ worst _ of rcga indicate that it is not reliable and a bit deficient for the function .",
    "regarding corresponding ten dimensional problem , only sade and stas can find the best with a low probability . in this case",
    ", sade achieves best results , followed by staii .",
    "from subfigure ( d ) of figure 3 and figure 4 , we can find that stas still converge faster than other algorithm but with not higher solution precision than sade . compared with stai , staii have much better statistical performances , which are indicated by the _ worst _ and the _ mean_. + * schewefel function : * as for the function , only rcga can not find the global optimum for both two and ten dimensions ; furthermore , the _ median _ and _ st.dev . _",
    "also show that the rcga is not stable and reliable for this function .",
    "other algorithms achieve the best as well as good reliability and stability because the _ st.dev _ approaches zero for these methods . from subfigure ( e ) of figure 3 and figure 4",
    ", the faster convergence speed belongs to the stas as well . while for stas",
    ", it shows that staii converge faster than stai for the function . + * ackley function : * it seems that all of the algorithms have no problem in finding the global optimum for the function in terms of two and ten dimensions .",
    "the statistical performances of results are satisfactory for all methods because the _ st.dev .",
    "_ approaches zero . in subfigure ( f ) of figure 3 and figure 4 , we can find that stas also have faster convergence speed than other algorithms and the solution precision is also higher for stas when compared with others .",
    "+ * michalewicz function : * all of the algorithms can achieve the global optimum for this function in two dimension , and the statistical performances is satisfactory in this case . while for the function with ten dimension , only staii are able to achieve the same statistics as the results in two dimensional function .",
    "more specifically , rcga and clpso are not able to find the best .",
    "worst _ of stai show that it is not reliable sometimes .",
    "+ * schaffer function : * the global optimum can be found by all the algorithms ; however , only stas can achieve reliable and stable performance for this function , as indicated by the _",
    "mean _ and the _",
    "st.dev._. other methods fail to find the best occasionally , which is described by the _",
    "worst _ , that is to say , other algorithm are not reliable for the function . in the case , staii converge much faster than stai , as illustrated by subfigure ( h ) . + * easom function : * all of the algorithms are able to find the global optimum with a high probability .",
    "the _ st.dev .",
    "_ indicates that the statistical performance are also fine for all methods .",
    "the subfigure ( i ) of figure 3 shows that stas have better convergence performance again .",
    "+ * goldstein - price function : * as described in table 4 , global optimum can be found by all algorithms , the results of which are satisfactory because the _ st.dev .",
    "_ approaches zero .",
    "the subfigure ( j ) of figure 3 shows that the convergence speed is fine for all methods but the stas are much better to some extent .",
    "+ over all , some explanations can be given on the behavior of average fitness curves .",
    "as shown in figure 3 and figure 4 , the curves of stas change steadily during the iteration process in most cases , there are two reasons that account for the phenomenon .",
    "firstly , the rotation guarantees the steady decrease of the curves because the rotation factor changes from a maximum value to a minimum value in a periodical way , which prevents current best state from changing sharply .",
    "if other transformations do not work , then rotation will help searching in depth with a high precision .",
    "secondly , expansion and translation are beneficial for searching in a new area , while the axesion is proposed to strength the single dimensional search , which are all advantageous for the decrease of the curves . +",
    "but every once in a while , especially described by the average fitness of @xmath76 and @xmath77 in ten dimension , stas fail to find the global optimum .",
    "as declared in part 2.2 , rotation transformation is used for local search , expansion , translation , and axesion are helpful for global search . in current stas , their control parameters(transformation factors ) are determined by experimental experience for simplicity .",
    "the failure of stas for @xmath76 and @xmath77 occasionally indicate that the global search transformations need to be deeply studied .",
    "anyway , the smaller rotation factor will facilitate the exploitation and the bigger expansion , translation and axesion factors will benefit the exploration , though how to balance them are still pending . regarding the influence of the _ cf _ , we can find that staii has stronger search ability than stai as the introducing of intermittent exchange .",
    "as illustrated by the average fitness curves , the fitness by staii can still decrease even if that of stai is already steady , that is to say , the communication strategy can help share information and prevent premature convergence . if the _",
    "cf _ is larger , more information will be shared , and if the _ cf _ is small , self development will be enhanced .",
    "+ by the way , the searching time required for stas is infinity in theory , which is the consequence of random search methodology .",
    "however , in practice , we can stop the iteration process by presetting some criteria , for example , the prescribed maximum iterations , or when the fitness is unchanged for a number of times . in this paper ,",
    "the maximum iterations is used .",
    "based on state and state transition , the sta , not only has a simple form but also possess clear geometric significance , which is easy for understanding . concerning the continuous function optimization problems , it presents the state transformations including rotation transformation , translation transformation and expansion transformation as well as axesion transformation .",
    "the paper focuses on the unconstrained optimization problems , and it studies mainly on the approaches of transformations .",
    "furthermore , to enhance its performance in high dimensional functions optimization , communication strategy has been introduced , and the intermittent exchange is proposed to strength the search ability as well as prevent premature convergence . using 10 benchmark functions for testing , compared with some distinguished optimization algorithms , it shows that stas have fine performance in terms of global search ability and convergence accuracy , which confirms the effectiveness of the proposed algorithms . + on the other hand , distinguished from other population - based algorithms , sta is not originated from simulating natural intelligence , but it takes advantages of the space structure of a function , which opens a new window for optimization . in the paper ,",
    "control parameters of stas are not studied deeply , and they are only determined by the experimental experience or for simplicity . in our future work , these problems will be focused on to better develop the state transition algorithms .",
    "we would like to thank the anonymous referees for their valuable comments and suggestions towards the improvement of this paper .",
    "h. a. abbass , a. m. bagirov and j. zhang , _ the discrete gradient evolutionary strategy method for global optimization _ , in  proceedings of ieee congress on evolutionary computation \" , * 1 * ( 2003 ) , 435442 .                ( mr2208016 ) [ 10.1016/j.amc.2005.05.002 ]",
    "c. hamzacebi and f. kutay , _ a heuristic approach for finding the global minimum : adaptive random search technique _ , applied mathematics and computation , * 173 * ( 2006 ) , 13231333 .",
    "j. j. liang , a. k. qin , p. n. suganthan and s. baskar , _ comprehensive learning particle swarm optimizer for global optimization of multimodal functions _",
    ", ieee transaction on evolutionary computation , * 10 * ( 2006 ) , 281295 .",
    "( mr2379918 ) t. w. leung , c. k. chan and m. d. troutt , _ a mixed simulated annealing - genetic algorithm approach to the multi - buyer multi - item joint replenishment problem : advantages of meta - heuristics _",
    ", journal of industrial and management optimization , * 4 * ( 2008 ) , 5366 .",
    "a. k. qin , v. l. huang , and p. n. suganthan , _ differential evolution algorithm with strategy adaptation for global numerical optimization _ , ieee transactions on evolutionary computation , * 13 * ( 2009 ) , 398417 .          ( mr1479553 ) [ 10.1023/a:1008202821328 ] r. storn and k. v. price ,",
    "_ differential evolutionary - a simple and efficient heuristic for global optimization over continous spaces _ , journal of global optimization , * 11 * ( 1997 ) , 341359 .      t. d. tran and g. g. jin , _ real - coded genetic algorithm benchmarked on noiseless black - box optimization testbed _ , in  workshop proceedings of the genetic and evolutionary computation conference \" , ( 2010 ) , 17311738 .",
    "( mr2763309 ) t. zhang , y. j. zhang , q. p. zheng and p. m. pardalos , _ a hybrid particle swarm optimization and tabu search algorithm for order planning problems of steel factories on the make - to - stock and make - to - order management architecture _ , journal of industrial and management optimization , * 7 * ( 2011 ) , 3151 .",
    "x. j. zhou , c. h. yang and w. h. gui , _ a new transformation into state transition algorithm for finding the global minimum _ , in  the 2nd international conference on intelligent control and information processing \" , ( 2011 ) , 674678 ."
  ],
  "abstract_text": [
    "<S> in terms of the concepts of state and state transition , a new heuristic random search algorithm named state transition algorithm is proposed . for continuous function optimization problems , </S>",
    "<S> four special transformation operators called rotation , translation , expansion and axesion are designed . adjusting measures of the transformations are mainly studied to keep the balance of exploration and exploitation . </S>",
    "<S> convergence analysis is also discussed about the algorithm based on random search theory . in the meanwhile , to strengthen the search ability in high dimensional space , communication strategy is introduced into the basic algorithm and intermittent exchange is presented to prevent premature convergence . </S>",
    "<S> finally , experiments are carried out for the algorithms . with 10 common benchmark unconstrained continuous functions used to test the performance , </S>",
    "<S> the results show that state transition algorithms are promising algorithms due to their good global search capability and convergence property when compared with some popular algorithms .    </S>",
    "<S> xiaojun zhou , chunhua yang and weihua gui    ( communicated by hussein a. abbass ) </S>"
  ]
}