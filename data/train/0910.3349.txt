{
  "article_text": [
    "computing the size of set intersections is a fundamental problem in information retrieval , databases , and machine learning . given two sets , @xmath5 and @xmath6",
    ", where @xmath7 a basic task is to compute the joint size @xmath8 , which measures the ( un - normalized ) similarity between @xmath5 and @xmath6 .",
    "the so - called * _ resemblance _ * , denoted by @xmath9 , provides a normalized similarity measure : @xmath10 it is known that @xmath11 , the _ resemblance distance _ , is a metric , i.e. , satisfying the triangle inequality@xcite . in large datasets",
    "encountered in information retrieval and databases , efficiently computing the joint sizes is often highly challenging@xcite .",
    "detecting ( nearly ) duplicate web pages is a classical example@xcite .",
    "typically , each web document can be processed as `` a bag of shingles , '' where a shingle consists of @xmath12 contiguous words in a document . here",
    "@xmath12 is a tuning parameter and was set to be @xmath13 in several studies@xcite .    clearly , the total number of possible shingles is huge .",
    "considering merely @xmath14 unique english words , the total number of possible @xmath15-shingles should be @xmath16 .",
    "prior studies used @xmath17 @xcite and @xmath18@xcite .      in their seminal work , broder and his colleagues developed _ minwise hashing _ and successfully applied the technique to the task of duplicate document removal at the web scale@xcite .",
    "since then , there have been considerable theoretical and methodological developments@xcite .    as a general technique for estimating set similarity , _ minwise hashing _",
    "has been applied to a wide range of applications , for example , content matching for online advertising@xcite , detection of large - scale redundancy in enterprise file systems@xcite , syntactic similarity algorithms for enterprise information management@xcite , compressing social networks@xcite , advertising diversification@xcite , community extraction and classification in the web graph@xcite , graph sampling@xcite , wireless sensor networks@xcite , web spam@xcite , web graph compression @xcite , text reuse in the web@xcite , and many more .    here",
    ", we give a brief introduction to this algorithm .",
    "suppose a random permutation @xmath19 is performed on @xmath20 , i.e. , @xmath21 an elementary probability argument can show @xmath22    after @xmath23 minwise independent permutations , denoted by @xmath24 , @xmath25 , ... , @xmath26 , one can estimate @xmath9 without bias , as a binomial probability , i.e. , @xmath27    throughout the paper , we will frequently use the term `` sample , '' corresponding to the term `` sample size '' ( denoted by @xmath23 ) . in _",
    "minwise hashing _ , a sample is a hashed value , e.g. , @xmath28 , which may require e.g. , 64 bits to store@xcite , depending on the universal size @xmath29 . the total storage for each set would be @xmath30 bits , where @xmath2 is possible .",
    "after the samples have been collected , the storage and computational cost is proportional to @xmath0 .",
    "therefore , reducing the number of bits for each hashed value would be useful , not only for saving significant storage space but also for considerably improving the computational efficiency .      in this paper , we establish a unified theoretical framework for * _ b - bit minwise hashing_*. instead of using @xmath2 bits@xcite or @xmath31 bits@xcite , our theoretical results suggest using as few as @xmath1 or @xmath32 bits can yield significant improvements .",
    "+ in @xmath0-bit minwise hashing , a `` sample '' consists of @xmath0 bits only , as opposed to e.g. , 64 bits in the original minwise hashing .    intuitively , using fewer bits per sample will increase the estimation variance , compared to ( [ eqn_var_m ] ) , at the same `` sample size '' @xmath23 .",
    "thus , we will have to increase @xmath23 to maintain the same accuracy .",
    "interestingly , our theoretical results will demonstrate that , when resemblance is not too small ( e.g. , @xmath33 , the threshold used in@xcite ) , we do not have to increase @xmath23 much .",
    "this means that , compared to the earlier approach , the b - bit minwise hashing can be used to improve estimation accuracy and significantly reduce storage requirements at the same time .",
    "for example , when @xmath1 and @xmath34 , the estimation variance will increase at most by a factor of 3 ( even in the least favorable scenario ) .",
    "this means , in order not to lose accuracy , we have to increase the sample size by a factor of 3 .",
    "if we originally stored each hashed value using 64 bits@xcite , the improvement by using @xmath1 will be @xmath35 .",
    "consider two sets , @xmath5 and @xmath6 , @xmath36 apply a random permutation @xmath19 on @xmath5 and @xmath6 : @xmath37 .",
    "define the minimum values under @xmath19 to be @xmath38 and @xmath39 : @xmath40    define @xmath41th lowest bit of @xmath38 , and @xmath42th lowest bit of @xmath39 . theorem [ the_basic ] derives the analytical expression for @xmath43 : @xmath44    [ the_basic ] assume @xmath29 is large .",
    "@xmath45 where @xmath46^{2^b-1}}{1-\\left[1-r_1\\right]^{2^b}},\\\\ & a_{2,b } = \\frac{r_2\\left[1-r_2\\right]^{2^b-1}}{1-\\left[1-r_2\\right]^{2^b}}.\\end{aligned}\\ ] ]    for a fixed @xmath47 ( where @xmath48 ) , @xmath49 is a monotonically decreasing function of @xmath50 .    for a fixed @xmath0 ,",
    "@xmath49 is a monotonically decreasing function of @xmath51 $ ] , with the limit to be @xmath52 * proof * : see appendix [ app_proof_basic].@xmath53    theorem [ the_basic ] says that , for a given @xmath0 , the desired probability ( [ eqn_basic ] ) is determined by @xmath9 and the ratios , @xmath54 and @xmath55 .",
    "the only assumption needed in the proof of theorem [ the_basic ] is that @xmath29 should be large , which is always satisfied in practice .",
    "@xmath49 ( @xmath56 ) is a decreasing function of @xmath47 and @xmath57 .",
    "as @xmath0 increases , @xmath49 converges to zero very quickly .",
    "in fact , when @xmath58 , one can essentially view @xmath59 .",
    "theorem [ the_basic ] naturally suggests an unbiased estimator of @xmath9 , denoted by @xmath60 : @xmath61 where @xmath62 ( @xmath63 ) denotes the @xmath64th lowest bit of @xmath38 ( @xmath39 ) , under the permutation @xmath65 .    following property of binomial distribution ,",
    "we obtain @xmath66 ^ 2 } = \\frac{1}{k}\\frac{e_b(1-e_b)}{\\left[1-c_{2,b}\\right]^2}\\\\\\label{eqn_var_b } = & \\frac{1}{k}\\frac{\\left[c_{1,b}+(1-c_{2,b})r\\right]\\left[1-c_{1,b}-(1-c_{2,b})r\\right]}{\\left[1-c_{2,b}\\right]^2}\\end{aligned}\\ ] ]    for large @xmath0 ( i.e. , @xmath67 and @xmath68 ) , @xmath69 converges to the variance of @xmath70 , the estimator for the original minwise hashing : @xmath71      as we decrease @xmath0 , the space needed for storing each `` sample '' will be smaller ; the estimation variance ( [ eqn_var_b ] ) at the same sample size @xmath23 , however , will increase .",
    "this variance - space trade - off can be precisely quantified by the * _ storage factor _",
    "* @xmath72 : @xmath73\\left[1-c_{1,b}-(1-c_{2,b})r\\right]}{\\left[1-c_{2,b}\\right]^2}.\\end{aligned}\\ ] ] lower @xmath74 values are more desirable .",
    "figure [ fig_b(b ) ] plots @xmath74 for the whole range of @xmath75 and four selected @xmath76 values ( from @xmath77 to 0.9 ) .",
    "figure [ fig_b(b ) ] shows that when the ratios , @xmath78 and @xmath79 , are close to 1 , it is always desirable to use @xmath1 , almost for the whole range of @xmath9 .",
    "however , when @xmath78 and @xmath79 are close to 0 , using @xmath1 has the advantage when about @xmath80 . for small @xmath9 and @xmath78 , @xmath79 , it may be more advantageous to user lager @xmath0 , e.g. , @xmath81 .",
    "the ratio of storage factors , @xmath82 , directly measures how much improvement using @xmath83 ( e.g. , @xmath84 ) can have over using @xmath85 ( e.g. , @xmath86 or 32 ) .",
    "some algebraic manipulation yields the following theorem .",
    "[ the_br ] if @xmath87 and @xmath88 , then @xmath89 is a monotonically increasing function of @xmath90 $ ] .",
    "if @xmath91 ( which implies @xmath92 ) , then @xmath93    if @xmath76 , @xmath84 , @xmath94 ( hence we treat @xmath95 ) , then @xmath96 * proof : *  we omit the proof due to its simplicity.@xmath53    suppose the original minwise hashing used @xmath2 bits to store each sample , then the maximum improvement of the @xmath0-bit minwise hashing would be 64-fold , attained when @xmath97 and @xmath98 , according to ( [ eqn_bb21 ] ) . in the least favorable situation ,",
    "i.e. , @xmath99 , the improvement will still be @xmath100-fold , which is @xmath101-fold when @xmath34 .",
    "figure [ fig_b(32)/b(b ) ] plots @xmath102 , to directly visualize the relative improvement .",
    "the plots are , of course , consistent with what theorem [ the_br ] would predict .",
    "we conducted three experiments .",
    "the first two experiments were based on a set of 2633 words , extracted from a chuck of msn web pages .",
    "our third experiment used a set of 10000 news articles crawled from the web .",
    "our first experiment is a sanity check , to verify the correctness of the theory .",
    "that is , our proposed estimator @xmath60 , ( [ eqn_r_b ] ) , is unbiased and its variance ( the same as the mean square error ( mse ) ) follows the prediction by our formula in ( [ eqn_var_b ] ) .      for our first experiment , we selected 10 pairs of words to validate the theoretical estimator @xmath70 and the variance formula @xmath103 , derived in in sec .",
    "[ sec_estimator ] .",
    "table [ tab_10pairs ] summarizes the data and also provides the theoretical improvements @xmath104 and @xmath105 . for each word , the data consist of the document ids in which that word occurs .",
    "the words were selected to include highly frequent word pairs ( e.g. , `` of - and '' ) , highly rare word pairs ( e.g. , `` gambia - kiribati '' ) , highly unbalanced pairs ( e.g. ,  a - test  ) , highly similar pairs ( e.g , `` kong - hong '' ) , as well as word pairs that are not quite similar ( e.g. , `` low - pay '' ) .",
    ".ten pairs of words used in the experiments for validating the estimator and theoretical variance ( [ eqn_var_b ] ) .",
    "since the variance is determined by @xmath78 , @xmath79 , and @xmath9 , words were selected to ensure a good coverage of scenarios . [ cols=\"<,<,<,<,<,<,<\",options=\"header \" , ]     [ tab_pr ]      to illustrate the improvements by the use of b - bit minwise hashing on a real - life application , we conducted a duplicate detection experiment using a corpus of 10000 news documents ( 49995000 pairs ) .",
    "the dataset was crawled as part of the blews project at microsoft@xcite . in the news domain ,",
    "duplicate detection is an important problem as ( e.g. ) search engines must not serve up the same story multiple times and news stories ( especially ap stories ) are commonly copied with slight alterations / changes in bylines only .    in the experiments we computed the pairwise resemblances for all documents in the set",
    "; we present the data for retrieving document pairs with resemblance @xmath106 below .",
    "we estimate the resemblances using @xmath60 with @xmath1 , 2 , 4 bits , and the original minwise hashing ( using 32 bits ) .",
    "figure [ fig_news_pr ] presents the precision & recall curves .",
    "the recall values are all very high ( mostly @xmath107 ) and do not well differentiate various estimators .",
    "the precision curves for @xmath108 ( using 4 bits per sample ) and @xmath70 ( using 32 bits per sample ) are almost indistinguishable , suggesting a 8-fold improvement in space using @xmath109 .",
    "when using @xmath1 or 2 , the space improvements are normally around 10-fold to 15-fold , compared to @xmath110 , especially for achieving high precisions ( e.g. , @xmath111 ) .",
    "this experiment again confirms the significant improvement of the @xmath0-bit minwise hashing using @xmath1 ( or 2 ) .",
    "note that in the context of ( web ) document duplicate detection , in addition to shingling , a number of specialized hash - signatures have been proposed , which leverage properties of natural - language text ( such as the placement of stopwords@xcite ) .",
    "however , our approach is not aimed at any specific datesets , but is a general , domain - independent technique . also , to the extent that other approaches rely on minwise hashing for signature computation , these may be combined with our techniques .",
    "figure [ fig_b(b ) ] and figure [ fig_b(32)/b(b ) ] have shown that , for about @xmath80 , using @xmath1 always outperforms using @xmath112 , even in the least favorable situation .",
    "this naturally leads to the conjecture that one may be able to further improve the performance using `` @xmath113 '' , when @xmath9 is close to 1 .",
    "one simple approach to implement `` @xmath113 '' is to combine two bits from two permutations .",
    "recall @xmath114 denotes the lowest bit of the hashed value under @xmath19 .",
    "theorem [ the_basic ] has proved that @xmath115    consider two permutations @xmath24 and @xmath25 .",
    "we store @xmath116 then @xmath117 either when @xmath118 and @xmath119 , or , when @xmath120 and @xmath121 .",
    "thus @xmath122 which is a quadratic equation with solution @xmath123 we can estimate @xmath124 without bias as a binomial . however , the resultant estimator for @xmath9 will be biased , at small sample size @xmath23 , due to the nonlinearity",
    ". we will recommend the following estimator @xmath125 the truncation @xmath126 will introduce further bias ; but it is necessary and is usually a good bias - variance trade - off .",
    "we use @xmath127 to indicate that two bits are combined into one .",
    "the asymptotic variance of @xmath127 can be derived using the `` delta method '' in statistics : @xmath128    one should keep in mind that , in order to generate @xmath23 samples for @xmath127 , we have to conduct @xmath129 permutations .",
    "of course , each sample is still stored using 1 bit , despite that we use `` @xmath130 '' to denote this estimator .",
    "interestingly , as @xmath91 , @xmath127 does twice as well as @xmath131 : @xmath132 recall , if @xmath98 , then @xmath76 , @xmath133 , and @xmath134 .",
    "on the other hand , @xmath127 may not be an ideal estimator when @xmath9 is not too large .",
    "for example , one can numerically show that ( as @xmath135 ) @xmath136    figure [ fig_r_1/2 ] plots the empirical mses for four word pairs in experiment 1 , for @xmath127 , @xmath137 , and @xmath110 :    * for the highly similar pair , `` kong - hong , '' @xmath127 exhibits superb performance compared to @xmath131 .",
    "* for the fairly similar pair , `` of - and , '' @xmath127 is still considerably better . * for `` united - states , ''",
    "whose @xmath138 , @xmath127 performs similarly to @xmath137 . * for `` low - pay , '' whose @xmath139 only , the theoretical variance of @xmath127 is very large .",
    "however , owing to the variance - bias trade - off , the empirical performance of @xmath127 is not too bad .    in a summary , while the idea of combining two bits is interesting , it is mostly useful in applications which only care about pairs of very high similarities .",
    "the _ minwise hashing _ technique has been widely used as a standard approach in information retrieval , for efficiently computing set similarity in massive data sets ( e.g. , duplicate detection ) .",
    "prior studies commonly used @xmath140 or 40 bits to store each hashed value ,    in this study , we propose the theoretical framework of * _ @xmath0-bit minwise hashing _ * , by only storing the lowest @xmath0 bits of each hashed value . we theoretically prove that , when the similarity is reasonably high ( e.g. , resemblance @xmath141 ) , using @xmath1 bit per hashed value can , even in the worse case , gain a space improvement by @xmath142-fold , compared to storing each hashed value using 32 bits",
    ". the improvement would be even more significant ( e.g. , at least @xmath143-fold ) if the original hashed values are stored using 64 bits .",
    "we also discussed the idea of combining 2 bits from different hashed values , to further enhance the improvement , when the target similarity is very high .",
    "our proposed method is simple and requires only minimal modification to the original minwise hashing algorithm .",
    "we expect our method will be adopted in practice",
    ".    10    michael bendersky and w.  bruce croft .",
    "finding text reuse on the web . in _ wsdm _ , pages 262271 , 2009 .",
    "sergey brin , james davis , and hector garcia - molina .",
    "copy detection mechanisms for digital documents . in _ sigmod _ , pages 398409 , san jose , ca , 1995 .    andrei  z. broder . on the resemblance and containment of documents . in _ the compression and complexity of sequences _ , pages 2129 , positano , italy , 1997",
    "andrei  z. broder , moses charikar , alan  m. frieze , and michael mitzenmacher .",
    "min - wise independent permutations .",
    ", 60(3):630659 , 2000 .",
    "andrei  z. broder , steven  c. glassman , mark  s. manasse , and geoffrey zweig .",
    "syntactic clustering of the web . in _",
    "www _ , pages 1157  1166 , santa clara , ca , 1997 .",
    "gregory buehrer and kumar chellapilla .",
    "a scalable pattern mining approach to web graph compression with communities . in _",
    "wsdm _ , pages 95106 , stanford , ca , 2008 .",
    "moses  s. charikar .",
    "similarity estimation techniques from rounding algorithms . in _ stoc _ , pages 380388 ,",
    "montreal , quebec , canada , 2002 .",
    "flavio chierichetti , ravi kumar , silvio lattanzi , michael mitzenmacher , alessandro panconesi , and prabhakar raghavan . on compressing social networks . in _",
    "kdd _ , pages 219228 , paris , france , 2009 .",
    "yon dourisboure , filippo geraci , and marco pellegrini .",
    "extraction and classification of dense implicit communities in the web graph .",
    ", 3(2):136 , 2009 .",
    "dennis fetterly , mark manasse , marc najork , and janet  l. wiener .",
    "a large - scale study of the evolution of web pages . in",
    "budapest , hungary , 2003 .",
    "george forman , kave eshghi , and jaap suermondt .",
    "efficient detection of large - scale redundancy in enterprise file systems .",
    ", 43(1):8491 , 2009 .",
    "michael gamon , sumit basu , dmitriy belenko , danyel fisher , matthew hurst , and arnd  christian knig . : using blogs to provide context for news articles .",
    "sreenivas gollapudi and aneesh sharma .",
    "an axiomatic approach for result diversification . in _",
    "www _ , pages 381390 , madrid , spain , 2009 .",
    "monika  .r .",
    "algorithmic challenges in web search engines . , 1(1):115123 , 2004 .",
    "piotr indyk . a small approximately min - wise independent family of hash functions .",
    ", 38(1):8490 , 2001 .",
    "toshiya itoh , yoshinori takei , and jun tarui .",
    "on the sample size of k - restricted min - wise independent permutations and other k - wise distributions . in _ stoc _ , pages 710718 , san diego , ca , 2003 .",
    "nitin jindal and bing liu .",
    "opinion spam and analysis . in _",
    "wsdm _ , pages 219230 , palo alto , california , usa , 2008 .",
    "konstantinos kalpakis and shilang tang .",
    "collaborative data gathering in wireless sensor networks using measurement co - occurrence .",
    ", 31(10):19791992 , 2008 .",
    "eyal kaplan , moni naor , and omer reingold .",
    "derandomized constructions of k - wise ( almost ) independent permutations . , 55(1):113133 , 2009",
    ".    ping li and kenneth  w. church . a sketch algorithm for estimating two - way and multi - way associations .",
    ", 33(3):305354 , 2007 .",
    "ping li , kenneth  w. church , and trevor  j. hastie .",
    "one sketch for all : theory and applications of conditional random sampling . in _ nips _ ,",
    "vancouver , bc , canada , 2009 .    ludmila , kave eshghi , charles b.  morrey iii , joseph tucek , and alistair veitch .",
    "probabilistic frequent itemset mining in uncertain databases . in _ kdd _",
    ", pages 10871096 , paris , france , 2009 .",
    "marc najork , sreenivas gollapudi , and rina panigrahy .",
    "less is more : sampling the neighborhood graph makes salsa better and faster . in _ wsdm _ , pages 242251 , 2009 .",
    "sandeep pandey , andrei broder , flavio chierichetti , vanja josifovski , ravi kumar , and sergei vassilvitskii .",
    "nearest - neighbor caching for content - match applications . in _ www _ , pages 441450 , madrid , spain , 2009 .",
    "martin theobald , jonathan siddharth , and andreas paepcke .",
    "spotsigs : robust and efficient near duplicate detection in large web collections . in _ sigir _ , singapore , 2008 .",
    "tanguy urvoy , emmanuel chauveau , pascal filoche , and thomas lavergne .",
    "tracking web spam with html style similarities .",
    ", 2(1):128 , 2008 .",
    "consider two sets , @xmath5 and @xmath6 , @xmath36        define @xmath41th lowest bit of @xmath38 , and @xmath42th lowest bit of @xmath39 .",
    "the task is to derive the analytical expression for @xmath145 which can be decomposed to be @xmath146 where @xmath147 is the resemblance .",
    "the expressions for @xmath152 , @xmath153 , and @xmath154 can be understood by the experiment of randomly throwing @xmath155 balls into @xmath29 locations , labeled @xmath156 .",
    "those @xmath155 balls belong to three disjoint sets : @xmath157 , @xmath158 , and @xmath159 . without any restriction ,",
    "the total number of combinations should be @xmath154 .",
    "the next task is to simplify the expression for the probability @xmath164 .",
    "after conducing expansions and cancelations , we obtain @xmath165 for convenience , we introduce the following notation : @xmath166 also , we assume @xmath29 is large ( which is always satisfied in practice ) .",
    "thus , we can obtain a reasonable approximation : @xmath167^{j - i-1}\\left[1-(r_1+r_2-s)\\right]^i\\end{aligned}\\ ] ] similarly , we obtain , for large @xmath29 , @xmath168^{i - j-1}\\left[1-(r_1+r_2-s)\\right]^j\\end{aligned}\\ ] ]    now we have the tool to calculate the probability @xmath169 for example , ( again , assuming @xmath29 is large ) @xmath170+[1-r_2]^3+[1-r_2]^5+ ...",
    "\\right)\\\\\\notag = & r_2(r_1-s)\\frac{1-r_2}{1-[1-r_2]^2}\\end{aligned}\\ ] ] @xmath171\\left([1-r_2]+[1-r_2]^3+[1-r_2]^5+ ... \\right)\\\\\\notag = & r_2(r_1-s)[1-(r_1+r_2-s)]\\frac{1-r_2}{1-[1-r_2]^2}.\\end{aligned}\\ ] ] therefore , @xmath172 ^ 2}\\times \\\\\\notag & \\left(1+[1-(r_1+r_2-s)]+[1-(r_1+r_2-s)]^2+",
    "... \\right)\\\\\\notag = & r_2(r_1-s)\\frac{1-r_2}{1-[1-r_2]^2}\\frac{1}{r_1+r_2-s}.\\end{aligned}\\ ] ] by symmetry , we know @xmath173 ^ 2}\\frac{1}{r_1+r_2-s}.\\end{aligned}\\ ] ] combining the probabilities , we obtain @xmath174 ^ 2}\\frac{r_1-s}{r_1+r_2-s}+\\frac{r_1(1-r_1)}{1-[1-r_1]^2}\\frac{r_2-s}{r_1+r_2-s}\\\\\\notag = & a_{1,1 } \\frac{r_2-s}{r_1+r_2-s } + a_{2,1 } \\frac{r_1-s}{r_1+r_2-s},\\end{aligned}\\ ] ] where @xmath175^{2^b-1}}{1-\\left[1-r_1\\right]^{2^b } } , \\hspace{0.2 in } a_{2,b } = \\frac{r_2\\left[1-r_2\\right]^{2^b-1}}{1-\\left[1-r_2\\right]^{2^b}}.\\end{aligned}\\ ] ]        the final task is to show some useful properties of @xmath180 ( same for @xmath181 ) .",
    "the first derivative of @xmath180 with respect to @xmath0 is @xmath182^{2^b-1}\\log(1-r_1)\\log2\\left(1-[1-r_1]^{2^b}\\right ) } { \\left(1-[1-r_1]^{2^b}\\right)^2}\\\\\\notag & -\\frac{-[1-r_1]^{2^b}\\log(1-r_1)\\log2\\ r_1\\left(1-[1-r_1]^{2^b-1}\\right ) } { \\left(1-[1-r_1]^{2^b}\\right)^2}\\\\\\notag \\leq&0 \\hspace{0.5 in } ( \\text{note that } \\",
    "\\log(1-r_1)\\leq 0)\\end{aligned}\\ ] ] thus , @xmath180 is a monotonically decreasing function of @xmath0 .    also , @xmath183^{2^b-1}-r_1\\left(2^b-1\\right)[1-r_1]^{2^b-2}}{2^b[1-r_1]^{2^b-1}}=",
    "\\frac{1}{2^b},\\end{aligned}\\ ] ] and @xmath184^{2^b-1}-r_1\\left(2^b-1\\right)[1-r_1]^{2^b-2}}{\\left(1-[1-r_1]^{2^b}\\right)}\\\\\\notag & \\hspace{0in}-\\frac{2^b[1-r_1]^{2^b-1}r_1\\left[1-r_1\\right]^{2^b-1}}{\\left(1-[1-r_1]^{2^b}\\right)^2}\\\\\\notag = & \\frac{[1-r_1]^{2^b-2}}{\\left(1-[1-r_1]^{2^b}\\right)^2 } \\left(1 - 2^br_1-[1-r_1]^{2^b}\\right)\\leq0.\\end{aligned}\\ ] ] note that @xmath185 , for @xmath186 and @xmath187 ."
  ],
  "abstract_text": [
    "<S> this paper establishes the theoretical framework of * _ @xmath0-bit minwise hashing_*. the original _ minwise hashing _ </S>",
    "<S> method@xcite has become a standard technique for estimating set similarity ( e.g. , _ resemblance _ ) with applications in information retrieval , data management , social networks and computational advertising .    by only storing the lowest @xmath0 bits of each ( minwise ) </S>",
    "<S> hashed value ( e.g. , @xmath1 or 2 ) , one can gain substantial advantages in terms of computational efficiency and storage space . </S>",
    "<S> we prove the basic theoretical results and provide an unbiased estimator of the resemblance for any @xmath0 . </S>",
    "<S> we demonstrate that , even in the least favorable scenario , using @xmath1 may reduce the storage space at least by a factor of 21.3 ( or 10.7 ) compared to using @xmath2 ( or @xmath3 ) , if one is interested in resemblance @xmath4 . </S>"
  ]
}