{
  "article_text": [
    "motion planning is a common task in robotics and artificial intelligence .",
    "one of the aims is to find a path , which can be traversed by a rigid body ( e.g. a robot ) to get to the destination point and avoid collisions with obstacles @xcite .",
    "dobrowolski @xcite considered the problem of motion planning in @xmath0 space ( i.e. rotations about the origin in the euclidean 3-space ) .",
    "he presented algorithms for constructing the _ cell graph _ ,",
    "i.e. a graph representation of the configuration space .",
    "it is worth noting that these algorithms work for any space , not only for @xmath0 . although the algorithms presented by dobrowolski proved to be significantly faster than the naive approach , their running time was not acceptable for complicated scenes . as the main contribution of this paper , we present and analyze parallel extensions of these algorithms for gpu processors .",
    "one of the parallel algorithms introduced in section  [ sec : parallel ] uses some variation of a _ binary search tree _ , in which all elements are kept in leaves .",
    "there are several known implementations of a binary search tree on the gpgpu ( see for example @xcite ) .",
    "our implementation allows us for an efficient execution of dictionary operations on a set of long vectors over an alphabet of a constant size . as",
    "a dictionary is a fundamental data type , widely used in many applications , we believe that our solution may be interesting and important on its own",
    ".      let @xmath1 .",
    "by @xmath2 $ ] we denote the set @xmath3 . by @xmath2^\\ell$ ] we denote the set of all vectors of length @xmath4 over the alphabet @xmath2 $ ] .",
    "the @xmath5-th coordinate ( for binary vectors called the _",
    "@xmath5-th bit _ ) of a vector @xmath6 is denoted by @xmath7 .",
    "the coordinates are indexed in zero - based convention , i.e. @xmath8 . for @xmath9 such that @xmath10 , by @xmath11 we denote the segment @xmath12 .",
    "the _ hamming distance _ of two binary vectors @xmath13^\\ell$ ] , denoted by @xmath14 , is the number of positions @xmath5 , such that @xmath15 .",
    "observe that @xmath16 is a metric function , so it satisfies the triangle inequality : @xmath17 . from this",
    "it follows that : @xmath18 .",
    "in this section we describe the notion of the cell graph in motion planning .",
    "although we use a very simple example , similar methods can be ( and actually are ) used in much more complicated settings ( see for example @xcite ) .",
    "let us consider a system of inequalities @xmath19 ( constraints ) , describing the boundaries ( see figure [ fig - lines ] ) , that partition the space into a number of pairwise disjoint regions , called _",
    "cells_. we say that two cells are neighboring ( a robot can move directly from one to another ) if their boundaries share some arc ( one point is not enough ) . our task is to unify the cells and say which of them are neighbors .",
    "then an obstacle - free route for a robot can be determined using a graph algorithm ( see for example @xcite ) .",
    "as the scenes ( i.e. the space with the arrangement of obstacles ) in real - life applications tend to be very complicated , an effective construction of the cell graph is a crucial part of this approach .    [ cols=\"<,<\",options=\"header \" , ]     the first step of our algorithm is sorting the vectors in @xmath20 .",
    "as these vectors are binary , the sorting can clearly be done in @xmath21 time , using the _ radix sort _ algorithm . during this step",
    "we also remove all duplicates in @xmath20 .",
    "then we proceed to constructing the search tree @xmath22 .",
    "each level of @xmath22 is constructed in parallel , with synchronization of threads after finishing each level . for each node @xmath23 and",
    "@xmath24 $ ] we introduce the set @xmath25 .",
    "let @xmath23 be a node on level @xmath26 .",
    "the set @xmath27 consists of vectors @xmath28 , such that : i ) @xmath29 is represented by @xmath23 in @xmath22 ( with just a little abuse of notation we assume that for @xmath30 every vector satisfies this condition ) , and ii ) @xmath31 .",
    "this means that the vectors from @xmath27 are exactly the ones , whose search path begins with the path from the root to the @xmath32-th child of @xmath23 .",
    "observe that since the set @xmath20 ( and thus @xmath33 ) is sorted , each set @xmath27 can be represented by just two indices  of the first and of the last vector from this set .",
    "the algorithm [ alg : par - construct ] shows the pseudo - code for this step .",
    "observe that the computational complexity of algorithm [ alg : par - construct ] is @xmath21 ( recall that @xmath34 is a constant ) .",
    "create the root node ( on level 0 ) +    after constructing the search tree , we can proceed to the main step  identifying neighbors . for every vector in @xmath35 and every possible neighbor @xmath36 of @xmath6 we check if @xmath37 ( in fact we check is @xmath38 ) .",
    "again , we do it in parallel . for every vector @xmath39 , each bit of @xmath39 is considered by a separate thread .",
    "observe that each bit of @xmath39 corresponds to a single potential neighbor of @xmath39 .",
    "thus each thread checks if this potential neighbor exists .",
    "the algorithm [ alg : par - treebased ] shows the pseudo - code of this procedure .",
    "sort @xmath20 + @xmath40 +    observe that we do not have to keep the vector @xmath36 explicitly . at each step",
    "we need a segment of @xmath36 ( corresponding to the current level of @xmath22 ) , which can be found in constant time .",
    "the time complexity of the searching procedure is @xmath41 and so is the complexity of the whole algorithm .",
    "the space complexity of the algorithm is determined by the size of the search tree , which is @xmath42 .",
    "recall that during the sorting step we remove all duplicates .",
    "thus this algorithm is robust in the sense that it does not assume that all input vectors are distinct and the same complexity bound holds even if @xmath20 is a multiset .",
    "in this section we discuss the implementation details of parallel algorithms described in the previous section .",
    "we shall omit an introduction to the computational model of gpgpu .",
    "the readers , who are not familiar with gpgpu programming , should refer to cuda c literature @xcite .",
    "there are several limitations of gpu devices which are important from the algorithmic point of view .",
    "we are interested in algorithms which are able to : ( 1 ) use coalesced memory access , ( 2 ) maximize multiprocessor occupancy , ( 3 ) hide memory latency .      in order to achieve high processor occupancy we need to define the number of blocks which is at least three or four times higher than the number of streaming processors .",
    "memory latency may be hidden if there is sufficient number of warps assigned to the same processor and memory accessing is interspersed with computations .",
    "algorithms [ alg : par - compute - dist ] and [ alg : par - heuristic ] contain two nested loops iterating over an array of results ( it is an upper - triangular square array with zeros on the main diagonal ) .",
    "using blocks as the parallel computation units in the outer loop and threads in the inner one gives us a fair number of blocks and threads achieving good occupancy and hiding memory latency .",
    "each thread reads parts of two vectors into registers and then performs comparison .",
    "thus a significant number of computational instructions are executed between reads and writes .    coalesced memory access is automatic if each vector is stored as a continuous array of bytes .",
    "fragmented results of the comparison of two vectors in algorithm [ alg : par - heuristic ] ( one array for each block ) may be stored in a shared memory and added up in parallel by threads of this block using classical parallel reduction pattern .",
    "tree construction in algorithm [ alg : par - construct ] requires a synchronization after each level .",
    "such a global synchronization can only be achieved by finishing a kernel and launching a new one .",
    "the number of threads in each kernel execution is equal to number of tree nodes in the previous level times @xmath43 ( in our experiments we used @xmath44 , so @xmath45 ) .",
    "all threads run independently and their division into blocks may be set arbitrarily in order to achieve best processor occupancy .",
    "algorithm [ alg : par - treebased ] again contains two nested loops .",
    "the outer one is executed for each input vector and the inner one iterates over its coordinates .",
    "similarly as in algorithm [ alg : par - heuristic ] , assigning the outer loop to blocks and the inner one to threads gives good parallelism properties .",
    "each thread performs tree searching and reads in random memory locations .",
    "coalesced memory reads are thus not possible .",
    "however , threads may still benefit from the global memory cache since up to @xmath34 threads may read the same byte from the memory performing independent searches .",
    "in order to evaluate our parallel algorithms we utilized the sample generator developed by dobrowolski @xcite and some real - life scenes . the experiment was performed on a professional computation server ( intel xeon e5 - 2620 2ghz , 15 mb cache , 6 cores , 32 gb ram ) equipped with nvidia tesla k40 computational unit ( 2668 cores , 12 gb memory ) .    in all parallel algorithms",
    "there are parameters which may influence their performance , i.e. the number of blocks and threads and the value of @xmath26 in the heuristic algorithm .",
    "according to nvidia white papers , due to the complication of the parallel processing model , the only way to find optimal values of these parameters for different devices and environments is to perform experiments . in the case of the value of @xmath26 ( for the heuristic algorithm )",
    "our tests indicated that the optimal value for the cpu is 3 , while for k40 it is 5 .",
    "the rest of the experiments for heuristic algorithm were performed with these settings .",
    "an analysis of the size of the kernel grid for the parallel tree - based algorithm ( divided into three stages : sorting , building and searching ) is presented in figure [ fig : blocks ] .",
    "the total processing time was minimal for 4096 blocks of 32 threads .",
    "the analysis of different block sizes for the tree - based algorithm . ]",
    "figure [ fig : results ] ( left ) presents the evaluation of the processing time in three stages of the tree - based algorithm : sorting , tree building , and neighbor searching .",
    "we can clearly see that searching time is growing faster than building , which is related to the @xmath46 factor in the complexity bound .",
    "however , for 44.000 vectors it is still smaller than the building part , due to high constants in the latter .",
    "experiments show that the sorting stage does not influence the total processing time by more than 30% in case of bigger input sets .",
    "the processing time of three stages of the tree - based algorithm ( left ) . the processing time for sequential and parallel algorithms ( right ,",
    "note the logarithmic scale).,title=\"fig : \" ]   the processing time of three stages of the tree - based algorithm ( left ) .",
    "the processing time for sequential and parallel algorithms ( right , note the logarithmic scale).,title=\"fig : \" ]    on the right of the figure [ fig : results ] a comparison of several solutions is presented .",
    "let us first analyze the heuristic methods .",
    "the sequential solution for the optimal value of @xmath26 ( equal to 3 ) is significantly faster than the solution with @xmath26 set to 0 , which corresponds to the naive solution .",
    "similarly , parallel version with @xmath26 set to the optimal value ( 5 ) is much faster than the naive one .",
    "both parallel and sequential procedures show similar growth of processing time for increasing size of the input data set .",
    "this shows that the algorithm scales well .",
    "the best performance is achieved by the parallel tree - based procedure .",
    "sequential version behaves similarly but significantly ( more than two orders of magnitude ) slower .",
    "we presented two important parallel algorithms for construction of the cell graph in the motion planning problem .",
    "our experiments show that the parallel solution based on a search tree is much faster than its sequential counterpart .",
    "this is also one of rare efficient search tree structures for gpu processors .",
    "we show that creating and searching such a structure can be efficient also on a simd - like processors , which were so far identified with vector processing .",
    "this was possible due to proper tree node construction and memory caching available in modern devices .",
    "as a modification of the tree - based algorithm , dobrowolski presented an algorithm , constructing the cell graph in @xmath21 time . using an auxiliary data structure ,",
    "the searching step can be performed in @xmath21 time .",
    "unfortunately , the experiments on the real data ( see section [ sec : experiments ] ) show that constructing the tree takes the majority of the execution time .",
    "moreover , as this improved searching procedure requires lots of synchronization , it may actually lead to worse execution time .",
    "a very natural research direction is to design a scalable parallel algorithm , constructing the cell graph for a given set of vectors in time @xmath21 .",
    "as mentioned before , cell graphs are used in motion planning .",
    "a path in the cell graph corresponding to a given scene is equivalent to some approximate solution of the motion planning problem .",
    "there are several approaches to traversing large graphs using gpgpu ( see @xcite ) .",
    "an interesting problem is to design such an algorithm , taking into consideration its structure ."
  ],
  "abstract_text": [
    "<S> motion planning is an important and well - studied field of robotics . a typical approach to finding </S>",
    "<S> a route is to construct a _ cell graph _ representing a scene and then to find a path in such a graph . in this paper </S>",
    "<S> we present and analyze parallel algorithms for constructing the cell graph on a simd - like gpu processor .    </S>",
    "<S> additionally , we present a new implementation of the dictionary data type on a gpu device . in the contrary to hash tables , which are common in gpu algorithms </S>",
    "<S> , it uses a search tree in which all values are kept in leaves . </S>",
    "<S> with such a structure we can effectively perform dictionary operations on a set of long vectors over a limited alphabet . </S>"
  ]
}