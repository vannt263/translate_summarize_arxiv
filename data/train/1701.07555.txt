{
  "article_text": [
    "the ` _ home field advantage _ ' in sport is well established , as its quantitative study can be traced back to the late 70 s @xcite .",
    "a meta - analysis of 30 research articles by @xcite , including over 30,000 games , found significant home field advantages in each of 10 different sports , be it individual such as tennis or team such as football ( _ soccer _ ) .",
    "yet , there seems to exist a downward trend in this advantage over time .",
    "@xcite analysed more than 400,000 games , dating back to 1876 , from ice hockey , baseball , american football , basketball and football , and found a decline in home field advantage for most sports . nevertheless , the advantage was still positive for all sports in the final year analysed ( 2002 ) .",
    "the exact causes of that advantage are multiple and complex . in an effort to better understand them , an important literature review by @xcite developed a conceptual framework , which was later updated by @xcite .",
    "it incorporates 5 major components : game location ; game location factors ; critical psychological and physiological states ; critical behavioural states ; and performance outcomes .",
    "@xcite posited that each component affects all subsequent ones .",
    "for example , ` game location ' influences ` game location factors ' such as crowd size and composition , which in turn affects the ` psychological state ' and then ` behavioural state ' of the players , etc .",
    "they concluded that further research is necessary in all of the 5 components to better understand the individual impacts , for example there is insufficient research into the effect of crowd density and absolute crowd size and their interaction .",
    "more recently , @xcite reached a similar conclusion , and reiterated their thoughts from an analysis two decades earlier @xcite : `` _ clearly , there is still much to be learnt about the complex mechanisms that cause home advantage , both in soccer and other sports .",
    "the topic remains a fruitful area of research for sports historians , sociologists , psychologists and statisticians alike . _ ''    one aspect of the home field advantage whose existence is still being debated is that of the ` _ second - leg home advantage _ ' ( hereafter : slha ) , when a contest between two teams comprises two matches ( ` legs ' ) , with each team as the home team in one leg , and the final outcome decided on aggregate . at first sight",
    ", one might expect that each team would get their respective home advantage and that the effects would cancel out . yet , a common belief is that the team playing at home for the second leg has a slight advantage over the other team .",
    "one theory to support this claim is that the team playing away on the first game can essentially play it safe there , while taking advantage of playing at home on the decider game when the difference is to be made .",
    "the stake of the second leg being higher , the crowd support and the induced pressure might indeed be more intense then than on the first leg , where getting the upper hand is unlikely to be final anyway .",
    "this may create an asymmetry in home advantage between the two legs @xcite .",
    "those two - legged ties are very common in knockout stages of football international club competitions , such as national team play - offs in some qualification tournaments , including the fifa world cup , and most prominently the european cups , namely the uefa champions league and europa league .",
    "those competitions are big business , especially the uefa champions league .",
    "for instance , from the season 2015 - 2016 onwards , to qualify to the quarter - finals brings in a bonus of 6 millions of euros ; to advance further to the semi - finals brings in an extra bonus of 7 millions of euros ; and to qualify to the final brings in another 10.5 or 15 millions of euros ( depending on the outcome of the final ) .",
    "hence , beyond the sporting aspect , the difference between qualifying or being eliminated at some level of the knockout stage represents a huge amount of money . as a result , an unwarranted advantage for the team playing at home second implies an equally unwarranted economic shortfall for the team playing at home first ,",
    "whose only fault is to have been unlucky at the draw .",
    "the question of existence of the slha is , therefore , of great significance .",
    "consequently , scholars have attempted to evidence or otherwise the slha , with research focussing on the case of uefa administered competitions . yet , none really proved conclusive .",
    "a naive comparison of the fraction of teams qualifying when playing at home on the second leg against when playing at home on the first leg , is not telling .",
    "this is because of the non - random manner in which uefa sometimes seeds teams in knockout stages of their competitions .",
    "for instance , in the first knockout round following the initial group stage , such as the round - of-16 in the champions league or round - of-32 in the europa league , group winners ( supposedly the best teams ) are automatically assigned to play the second game at home .",
    "obviously , this may lead to the spurious result of existence of slha , as stronger teams are preferentially allocated as playing at home second in some instances .",
    "this induces an obvious confounding factor .",
    "@xcite and @xcite adjusted for it by conditioning their analyses on the difference between the uefa coefficients of the two teams , assumed to be a reasonable proxy for their relative strength ( more on this in section [ sec : chap4 ] ) .",
    "@xcite found no evidence of slha and @xcite found a significant effect in seasons before 1994/95 but not afterwards .",
    "by contrast , @xcite and @xcite did find a significant slha effect , however they did not control for the confounding factor , which greatly lowers the value of their study .",
    "it seems indeed clear that the relative strength of the matched teams should be taken into account for meaningful analyses .",
    "hence this paper will focus on the ` conditional ' case only .",
    "specifically , denote @xmath0 the probability of the second - leg home team qualifying given that the difference in ` strength ' between the two teams ( however it is measured ) at the time of the game is @xmath1 .",
    "then , @xmath2 is the probability of the second - leg home team going through , given that the two teams are of the same strength .",
    "the probability @xmath2 is , therefore , the parameter of main interest in this study , with a value for @xmath2 above @xmath3 indicating a second - leg home advantage .",
    "existence of the slha effect can thus be formally tested by checking whether an empirical estimate @xmath4 of @xmath2 significantly lies above @xmath3 .",
    "@xcite and @xcite estimated @xmath0 using a logistic regression model , but failed to provide an examination of goodness - of - fit of this parametric model and just stated regression estimates as - is . to offer an alternate viewpoint on the question , this paper explores the topic using nonparametric techniques , really ` letting the data speak for themselves ' . to this effect , a nadaraya - watson ( nw ) kernel regression model (",
    "* section 4.1.2 ) has been developed to regress the final outcome of the two - legged knockout on a measure of the inequality in team strengths , based again on the uefa club coefficients .",
    "this model allows robust and objective estimation of @xmath0 from historical data .",
    "a measure of statistical significance is provided by the asymptotic normality of the nadaraya - watson estimator , which enables the calculation of pointwise confidence intervals for @xmath0 at any @xmath1 ( * ? ? ?",
    "* section 4.4.1 ) .",
    "however , the working model being essentially a conditional bernoulli model here , the estimated probability @xmath5 is some kind of ` conditional sample proportion ' ( see section [ sec : chap3 ] for details ) .",
    "the above standard confidence intervals for @xmath0 thus amount to some sort of wald intervals , adapted to the conditional case . in",
    "the classical ( i.e. , non - conditional ) framework , it is well known @xcite that the coverage of the wald interval for a proportion @xmath6 can be very poor , and this for any values of @xmath7 and the sample size @xmath8 .",
    "@xcite explained how the coverage probability of the wald interval is affected by both systematic negative bias and oscillations , and recommended three alternatives to the wald interval : the wilson , the agresti - coull and the jeffreys intervals .",
    "the methodological contribution of this paper is twofold .",
    "first , such ` better ' confidence intervals will be obtained for a conditional probability estimated by the nadaraya - watson estimator .",
    "` conditional ' versions of the wilson and agresti - coull confidence intervals will thus be constructed .",
    "when doing so , the inherent bias of the nw estimator will be a major factor to take into account , as often in procedures based on nonparametric function estimation .",
    "consequently , the second contribution will be to devise a careful strategy for efficiently dealing with that bias when computing the above confidence intervals in practice .",
    "finally , those will be used for the interval - estimation of the probability @xmath2 of interest .",
    "this will allow the research question about the existence of some slha to be addressed in a very robust way .",
    "the paper is organised as follows .",
    "section [ sec : chap2 ] provides an overview of the work by @xcite and @xcite about confidence intervals for a proportion",
    ". a particular emphasis will be on the wilson and agresti - coull confidence intervals , in order to prepare for their adaptation to the conditional case in section [ sec : chap3 ] .",
    "there , some background on the standard , wald - type interval for a conditional probability estimated by the nadaraya - watson estimator is provided . then details of the derivations of the wilson and agresti - coull intervals for the conditional case are given .",
    "the problem of the bias is addressed , and a novel way of choosing the right smoothing parameter when constructing the confidence intervals is suggested .",
    "the performance of the new intervals based on this strategy are then analysed through a simulation study .",
    "section [ sec : chap4 ] comes back to the research question and presents the results . a discussion about the implications and limitations of the current study follows , with some suggestions for future research in the field .",
    "finally , section [ sec : chap5 ] concludes .",
    "consider a random sample @xmath9 bernoulli@xmath10 , for some value @xmath7 ( degenerate cases @xmath11 or @xmath12 have very limited interest ) , and say that @xmath13 if individual @xmath14 has a certain characteristic , and @xmath15 otherwise .",
    "denote @xmath16 , the number of sampled individuals with the characteristic .",
    "the sample proportion @xmath17 is known to be the maximum likelihood estimator of @xmath6 , satisfying @xmath18 as @xmath19 from the central limit theorem .",
    "substituting in @xmath20 for the estimation of the standard error , a confidence interval of level @xmath21 for @xmath6 easily follows : @xmath22 , \\label{eqn : waldci}\\ ] ] where @xmath23 is the quantile of level @xmath24 of the standard normal distribution .",
    "this is the _",
    "wald interval_.    unfortunately , this interval reputedly shows poor behaviour in terms of coverage probability , as has been known for quite some time , see for instance @xcite and @xcite .",
    "@xcite provided a thorough understanding of the cause of the phenomenon .",
    "they showed , even for large values of @xmath8 , that the pivotal function @xmath25 can be significantly non - normal with large deviations of bias , variance , skewness and kurtosis .",
    "of particular importance is the bias term ( * ? ? ?",
    "* section 2.1 ) : @xmath26 which is non - zero for @xmath27 and changes sign depending if @xmath28 or @xmath29 .",
    "hence , even though @xmath20 is unbiased for @xmath6 , the estimation of the standard error by substituting in @xmath20 introduces some substantial positive or negative bias in @xmath30 .",
    "this eventually results in systematic negative bias for the coverage probability of the interval based on @xmath30 , a correction of which requiring a shift of the centre of the interval towards @xmath31 .",
    "obviously , this problem is most serious for values of @xmath6 ` far away ' from @xmath3 , i.e.  close to 0 or 1 .",
    "this is the origin of the popular rule - of - thumb ` @xmath32 must be greater than 5 ( or 10 ) ' , supposed to validate the usage of the wald interval , but mostly discredited by ( [ eqn : biasw ] ) . in addition , the coverage probability also suffers from important oscillations across @xmath8 and @xmath6 ( * ? ? ?",
    "* figure 1 ) .",
    "this is essentially due to the discrete nature of @xmath33 : clearly , for finite @xmath8 , @xmath20 can only take on a finite number of different values ( @xmath34 , @xmath35 , @xmath36 , @xmath37 , @xmath38 , @xmath39 ) , and that causes problems when approximating its distribution by a normal smooth curve , see ( * ? ? ?",
    "* section 2.2 ) for details .",
    "hence @xcite went on to investigate a dozen of alternatives , including the ` exact ' clopper - pearson interval , an interval based on the likelihood ratio test , and some intervals based on transformations such as arcsine and logit .",
    "they recommended only three of them as replacements for the wald interval : the wilson , the agresti - coull and the jeffreys intervals .",
    "this is due to their superior performance in coverage probability and interval length , as well as their ease of interpretation .    in this paper the wilson and agresti - coull intervals",
    "will be adapted to the conditional , kernel regression - based , setting .",
    "these two intervals are derived from the asymptotic normality of the sample proportion ( [ eqn : asymptnorm ] ) .",
    "as it is known , the nadaraya - watson estimator of the conditional probability @xmath0 , that will be used in sections [ sec : chap3 ] and [ sec : chap4 ] , is a weighted sample average , which can be regarded as a ` conditional sample proportion ' in this framework . in particular ,",
    "the nadaraya - watson estimator is - under mild conditions - asymptotically normally distributed as well ( * ? ? ?",
    "* theorem 4.5 ) , which allows a natural extension of the wilson and agresti - coull intervals to the conditional case . on the other hand",
    ", the jeffreys interval has a bayesian derivation , being essentially a credible interval from the posterior distribution of @xmath6 when some uninformative ( ` _ jeffreys _ ' ) prior is used .",
    "it is less obvious how this construction would fit in the conditional setting .",
    "it seems , therefore , reasonable to leave the jeffreys interval on the side in this paper .",
    "the wilson interval , first described by @xcite , follows from the inversion of the score test for a null hypothesis @xmath40 , hence it is also known as ` score interval ' . like the wald interval",
    ", it is obtained from ( [ eqn : asymptnorm ] ) .",
    "the main difference , though , is that the variance factor @xmath41 is not estimated and keeps its unknown nature through the derivation .",
    "specifically , from a statement like @xmath42 essentially equivalent to ( [ eqn : asymptnorm ] ) , it follows that the confidence interval for @xmath6 at level @xmath21 should be the set of all values of @xmath6 such that @xmath43 solving this quadratic inequality in @xmath6 yields @xmath44 = \\left[\\frac{\\yy + z_{1-\\alpha/2}^2/2}{n+z_{1-\\alpha/2}^2 } \\pm \\frac{n^{1/2}z_{1-\\alpha/2}}{n+z_{1-\\alpha/2}^2 } \\sqrt{\\hat{p}(1-\\hat{p } ) + \\frac{z_{1-\\alpha/2}^2}{4n } } \\,\\right ] .",
    "\\label{eq : wilson_interval_noncond}\\ ] ] @xcite showed that this interval can be written @xmath45 , \\label{eqn : ciwiom}\\ ] ] where @xmath46 .",
    "this interval is symmetric around @xmath47 , a weighed average of @xmath20 and the uninformative prior @xmath31 , with the weight on @xmath20 heading to 1 asymptotically .",
    "compared to the wald interval ( [ eqn : waldci ] ) , the interval centre is now shifted towards 1/2 which substantially reduces the bias in coverage probability as suggested below ( [ eqn : biasw ] ) .",
    "likewise , the coefficient on @xmath48 in the @xmath49 term is the same weighted average of the variance when @xmath50 and when @xmath51 .",
    "@xcite ` strongly recommend ' the wilson interval as alternative to the wald interval .",
    "however , they acknowledged that the form of this interval is complicated and so suggested a new interval with a simple form which they called the ` adjusted wald interval ' , now better known as the ` agresti - coull ' interval .",
    "they noted that the wilson interval is like a ` shrinking ' of both the midpoint and variance estimate in the wald interval towards @xmath31 and @xmath52 respectively , with the amount of shrinkage decreasing along with @xmath8 .",
    "this lead them to consider the midpoint of the wilson interval , @xmath53 , as another point estimate of @xmath6 , and then continue with the wald interval derivation . for the ` usual ' confidence level @xmath54 , @xmath55 , hence @xmath56 and this procedure is sometimes loosely called the ` _ add 2 successes and 2 failures _ ' strategy .",
    "it combines the idea of shifting the centre toward @xmath3 , _  la _ wilson , with the simplicity of the wald interval derivation which substitutes in an estimate for the standard error .",
    "specifically , define @xmath57 then , given that @xmath58 , it follows from ( [ eqn : asymptnorm ] ) that @xmath59 and acting as in section [ subsec : waldci ] yields @xmath60 .",
    "\\label{eq : agresti_interval_noncond_alt}\\ ] ]    @xcite provided an excellent breakdown of the performance of the wald , wilson and agresti - coull intervals as a whole .",
    "the wilson and agresti - coull intervals behave very similarly . in particular , they are almost indistinguishable around @xmath61 ( * ? ? ?",
    "* figure 5 ) .",
    "most importantly , the wilson and agresti - coull intervals maintain a coverage probability very close to the confidence level @xmath21 , and this for all @xmath6 and even for small values of @xmath8 , as opposed to the wald interval whose coverage probability remains consistently below target , even for large @xmath8 .",
    "the oscillations persist , though , which could be expected : it is the discreteness of the bernoulli distribution that causes the oscillations , not how the intervals are formed .",
    "* theorem 7 ) also proved that both the agresti - coull and the wilson intervals are shorter on average than the wald interval . in the following section ,",
    "conditional versions of these intervals are constructed , and it is analysed if these observations carry over to the case of estimating a conditional probability via nonparametric binary regression .",
    "consider now a bivariate sample @xmath62 of i.i.d .",
    "replications of a random vector @xmath63 such that @xmath64 ( unspecified ) and @xmath65 .",
    "now , the probability of a certain individual having the characteristic of interest is allowed to vary along with another explanatory variable @xmath66 . of interest is the estimation of the conditional probability function @xmath67 assuming that @xmath66 is a continuous variable whose distribution admits a density @xmath68 , the estimation of @xmath0 actually falls within the topic of regression .",
    "indeed , @xmath69 meaning that @xmath0 is actually a conditional expectation function .",
    "the problem is called _",
    "binary regression_.    common parametric specifications for @xmath6 include logistic and probit models .",
    "their use is so customary that their goodness - of - fit is often taken for granted in applied studies .",
    "e.g. , within the application considered in this paper , @xcite and @xcite did not attempt any validation of their logistic model . the primary tool for suggesting a reasonable parametric specification in the ` continuous - response ' context is often the basic @xmath70-graph ( scatter - plot ) .",
    "when the response is binary , though , a scatter - plot is not much informative ( no clear shape for the cloud of data points , see for instance figure [ fig : phat ] below ) , hence binary regression actually lacks that convenient visual tool .",
    "maybe that is the reason why the question of goodness - of - fit of a logistic regression model is so often overlooked in the literature , as if the incapacity of visually detecting departures from a model automatically validates it . yet , without any visual guide , the risk of model misspecification is actually higher in binary regression than in other cases @xcite , with misspecification typically leading to non - consistent estimates , biased analyses and questionable conclusions .    in order to avoid any difficulty in postulating and validating some parametric specification for the function @xmath6 , here a nadaraya - watson kernel regression estimator will be used .",
    "kernel smoothing is a very popular _ nonparametric _ regression method ( * ? ? ?",
    "* chapter 4 ) , and the nadaraya - watson ( nw ) estimator @xcite one of its simplest variants .",
    "given the sample @xmath71 , the nw estimator is defined as @xmath72 where @xmath73 is a ` kernel ' function , typically a smooth symmetric probability density like the standard gaussian , and @xmath74 is a ` bandwidth ' , essentially fixing the smoothness of the final estimate @xmath75 . clearly , ( [ eqn : nwest ] ) is just a weighted average of the binary values @xmath76 s , with weights decreasing with the distance between @xmath1 and the corresponding @xmath77 .",
    "hence it returns an estimation of the ` local ' proportion of the @xmath76 s equal to 1 , for those individuals such that @xmath78 @xcite , which is indeed a natural estimate of ( [ eqn : px ] ) .",
    "it is straightforward to see that @xmath79 always belongs to @xmath80 $ ] , as it is just a ( weighted ) average of 0/1 values .",
    "there exist more elaborated nonparametric regression estimators ( local polynomial or splines , for instance ) , but those usually fail to automatically satisfy this basic constraint on @xmath0",
    ". hence the nw estimator seems a natural choice here .",
    "classical results in kernel regression ( * ? ? ?",
    "* theorem 4.1 ) state that estimator ( [ eqn : nwest ] ) is a consistent one for @xmath0 provided that @xmath81 and @xmath82 as @xmath19 .",
    "moreover , if @xmath83 , it is asymptotically normal .",
    "specifically , adapting theorem 4.5 of @xcite to the binary case gives , at all @xmath1 such that @xmath68 and @xmath6 are twice continuously differentiable , and @xmath84 , @xmath85 where @xmath86 , @xmath87 and @xmath88 are kernel - dependent constants , and @xmath89 balancing squared bias and variance , in order to achieve minimum mean squared error for the estimator , requires to take @xmath90 ( * ? ? ?",
    "* theorem 4.3 ) .",
    "this means @xmath91 , materialising a non - vanishing bias term in ( [ eqn : asnormnw ] ) .",
    "this bias has a major impact on any statistical procedure based on nonparametric function estimation @xcite , and requires careful treatment . in the context of building confidence intervals",
    ", it can be either explicitly estimated and corrected @xcite , or one can act via _ undersmoothing _ : if @xmath92 , hence purposely sub - optimal , then @xmath93 in ( [ eqn : asnormnw ] ) which becomes @xmath94 the bias is seemingly gone ; of course , at the price of an increased variance . @xcite and @xcite theoretically demonstrated the superiority of treating the bias via undersmoothing over explicit correction in terms of empirical coverage of the resulting confidence intervals .",
    "clearly , ( [ eqn : nw_asymp_normal_h_undersmooth ] ) is the analogue of ( [ eqn : asymptnorm ] ) for a conditional probability .",
    "it will consequently serve below as the basis for constructing confidence intervals for @xmath0 at any @xmath1 .",
    "in particular , a wald - type confidence interval at level @xmath21 for @xmath0 is @xmath95 .",
    "\\label{eq : wald_kernel}\\ ] ] it directly follows from the asymptotic normality statement ( [ eqn : nw_asymp_normal_h_undersmooth ] ) with the variance @xmath96 being estimated : @xmath0 is estimated by @xmath79 ( [ eqn : nwest ] ) , and @xmath97 is estimated by its classical kernel density estimator ( * ? ? ?",
    "* chapter 3 ) @xmath98 although it would not necessarily be optimal for estimating @xmath97 itself , here the same kernel @xmath73 and bandwidth @xmath74 as in ( [ eqn : nwest ] ) should be used in ( [ eqn : fhat ] ) .",
    "the reason why a factor @xmath99 arises in the variance of ( [ eqn : asnormnw])/([eqn : nw_asymp_normal_h_undersmooth ] ) is that not all @xmath8 observations , but only a certain fraction ( asymptotically ) proportional to @xmath97 are effectively used by the essentially local estimator ( [ eqn : nwest ] ) for estimating @xmath6 at @xmath1 .",
    "so , the estimation of @xmath68 here should be driven by accurately quantifying that ` local equivalent sample size ' at @xmath1 .",
    "the fact that the quantity @xmath100 is actually that equivalent sample size follows by seeing that @xmath101 is the denominator of ( [ eqn : nwest ] ) , while @xmath102 gives an appreciation of how large is the weight given to those observations ` close ' to @xmath1 , overall .",
    "the wald nature of ( [ eq : wald_kernel ] ) and the shortcomings of its analogue exposed in section [ subsec : waldci ] , though , motivate the adaptation of the wilson and agresti - coull intervals to the conditional context .",
    "the derivation of the ` conditional ' wilson interval follows the same steps and justification as those presented in section [ subsec : wiac ] . from ( [ eqn : nw_asymp_normal_h_undersmooth ] ) , it is seen that a confidence interval of level @xmath21 for @xmath0 should wrap up all those values of @xmath0 such that @xmath103 that is , @xmath104 solving for @xmath0 , and estimating the unknown @xmath97 by its kernel estimator @xmath105 ( [ eqn : fhat ] ) , yields the interval @xmath106 \\notag \\\\ & = \\left [ \\frac{\\frac{\\hat{p}_h(x)nh\\hat{f}_h(x)}{r(k ) } + \\frac{z_{1-\\alpha/2}^2}{2}}{\\frac{nh\\hat{f}_h(x)}{r(k)}+z_{1-\\alpha/2}^2 }   \\pm \\frac{z_{1-\\alpha/2 } \\left(\\frac{nh\\hat{f}_h(x)}{r(k)}\\right)^{1/2}}{\\frac{nh\\hat{f}_h(x)}{r(k)}+z_{1-\\alpha/2}^2 } \\sqrt{\\hat{p}_h(x)(1-\\hat{p}_h(x ) ) + \\frac{z_{1-\\alpha/2}^2r(k)}{4nh\\hat{f}_h(x ) } } \\,\\right ] .",
    "\\label{eqn : wilson_interval_alt } \\end{aligned}\\ ] ] similarly to ( [ eqn : ciwiom ] ) , the centre of this interval can be represented as @xmath107 , where @xmath108 .",
    "this highlights that the adaptation to the conditional case has not altered the interval s nature .",
    "in addition , directly suggests an ` agresti - coull ' , simpler version of it .",
    "indeed , the ( non - conditional ) agresti - coull interval is built around @xmath109 , the centre of the corresponding ( non - conditional ) wilson interval ( [ eq : wilson_interval_noncond ] ) . extending this to the conditional case from ( [ eqn : wilson_interval_alt ] )",
    ", one can define @xmath110 \\label{eqn : accicond}\\ ] ] where @xmath111 the interpretation of @xmath112 as the ` local equivalent sample size ' makes the analogy between this and ( [ eqn : ptilde ] ) obvious .",
    "the three intervals ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) and ( [ eqn : accicond ] ) follow straight from ( [ eqn : nw_asymp_normal_h_undersmooth ] ) , which holds true if and only if @xmath92 ( _ undersmoothing _ ) .",
    "results of @xcite on asymptotic intervals in nonparametric regression , suggest that the coverage probability of the wald - type interval ( [ eq : wald_kernel ] ) is @xmath113 hence , for minimising the coverage error of the confidence interval computed on @xmath79 , one should take @xmath74 such that @xmath114 .",
    "common practice in nonparametric methods requiring such undersmoothing , is to take @xmath74 ` smaller ' than a value , say @xmath115 , supposed to be optimal for estimating @xmath0 .",
    "typically , @xmath115 would be returned by a data - driven selection procedure , such as cross - validation or plug - in , see @xcite for a review .",
    "often , @xmath115 is then just divided by some constant which heuristically looks appropriate . in the present case",
    ", one could take @xmath116 , so as to ( supposedly ) obtain @xmath114 , given that @xmath117 , see comments below ( [ eqn : bx ] ) .",
    "there is actually no justification for doing so in practice . `",
    "undersmoothing ' is a purely asymptotic , hence theoretical , concept .",
    "the ` undersmoothed ' @xmath74 is to tend to 0 quicker than the optimal @xmath115 _ as @xmath8 would tend to @xmath118 _ , but this convergence is obviously meaningless when facing a sample of data of fixed size @xmath8 . indeed expressions like @xmath114 or @xmath117 do not really make sense for fixed @xmath8 .",
    "it is understood that , mainly because of the inherent bias of @xmath79 , the value of @xmath74 leading to confidence intervals with good coverage properties is not , in general , the optimal bandwidth @xmath115 for estimating @xmath0 .",
    "however asymptotic expressions such as ( [ eqn : covprob ] ) can not really be of any practical help .",
    "in fact , there are no effective empirical ways of selecting a right @xmath74 in this framework , as @xcite deplored .",
    "this paper fills this gap , as a sensible way of selecting such a value of @xmath74 is devised . a practical procedure , it does not claim to return an ` undersmoothed ' bandwidth or otherwise .",
    "it just aims to return a numerical value of @xmath74 which guarantees , for the data at hand , the intervals ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) or ( [ eqn : accicond ] ) to have high degree of coverage accuracy .",
    "it is essentially a bootstrap procedure , which in many ways resembles @xcite s idea . a main difference , though , is that @xcite looked for the ( higher ) nominal confidence level that they should target for their intervals , so that their empirical versions have a coverage probability close to @xmath21 . here , the approach is more direct as the constructive parameter @xmath74 is the only focus .",
    "the procedure goes as follows :    1 .   from the initial sample @xmath71 ,",
    "estimate @xmath0 by @xmath119 using an appropriate bandwidth @xmath115 returned by any data - driven procedure ; 2 .",
    "generate a large number @xmath120 of bootstrap resamples @xmath121 ,",
    "@xmath122 , according to @xmath123 ; 3 .   for @xmath124 ,",
    "compute on @xmath125 a collection of intervals denotes a generic confidence interval for @xmath0 , which can be @xmath126 , @xmath127 or @xmath128 . ]",
    "@xmath129 on a fine grid of candidate values of @xmath74 ; 4 .",
    "estimate the coverage probability of the interval @xmath130 by the fraction @xmath131 of intervals @xmath129 which contain the ` true ' value @xmath119 ; 5 .   select for bandwidth one of the values of @xmath74 for which @xmath131 is above @xmath21 . if @xmath131 nowhere takes a value higher than @xmath21 , choose @xmath74 which maximises @xmath131 .",
    "the intervals ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) and ( [ eqn : accicond ] ) heavily depend on the local geometry of the data around @xmath1 , through the ` local equivalent sample size ' @xmath132 ( see comments below ( [ eqn : fhat ] ) ) . in order for the bootstrap intervals to mimic this appropriately , the resampling in 2 .  is done conditionally on the design values @xmath133 and those are kept fixed ; only the @xmath76 s are resampled . also",
    ", theoretical considerations about bootstrap methods for nonparametric curve estimation suggest that resampling such as in 2 .",
    "should be done from an estimate @xmath134 with @xmath135 , this time , an",
    "_ oversmoothed _ bandwidth  with the same caveat about what this really means in practice . again",
    ", the reason behind this is to do with the bias of the estimator , see e.g.  @xcite . as opposed to other procedures , though , here the bootstrap resamples",
    "are only used for identifying another bandwidth , not for direct estimation of quantities of interest .",
    "hence , oversmoothing is not theoretically required ( see @xcite for justification of this ) .",
    "this procedure is tested through simulations in the next section , where it is seen to perform very well .",
    "those simulations show that @xmath131 is essentially a concave function of @xmath74 , up to some minor fluctuations due to sampling ( see figure [ fig : hci ] below ) , and that in almost all situations @xmath131 indeed takes values higher than @xmath21 . because of concavity , the values of @xmath74 for which it is the case forms a convex subset of @xmath136 . the value of @xmath74 chosen in 5",
    ".  can then be the average of those values , for instance .",
    "this guarantees the selected value of @xmath74 to correspond to a value of @xmath131 close to its maximum , hence leaning more to the side of conservatism than otherwise . for the rare cases in which @xmath131 does not go above @xmath21",
    ", its maximum value is very close to @xmath21 , anyway .      in order to test , compare and validate the above construction of confidence intervals for @xmath0 and the suggested bandwidth selection procedure , a twofold simulation study was run .",
    "the data was generated according to the following process : @xmath137 this regression function , shown in figure [ fig : pscen1 ] , was used in example 5.119 in @xcite .",
    "the three confidence intervals ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) or ( [ eqn : accicond ] ) for @xmath0 at @xmath138 and @xmath139 were computed on @xmath140 independent samples generated as above .",
    "all confidence intervals were truncated to @xmath80 $ ] when necessary .",
    "the coverage probabilities of the three intervals , at the two locations , were approximated by the fraction of those @xmath140 intervals which include the true values @xmath141 and @xmath142 . in the non - conditional case",
    ", values of @xmath6 close to 0 or 1 are known to be problematic ( see comments below ( [ eqn : biasw ] ) ) , so comparing how much impact the value of @xmath0 has on the performance of the ` conditional ' intervals is of interest . to isolate that effect ,",
    "a uniform design for @xmath66 was considered , to ensure that the areas ` close to @xmath138 ' and ` close to @xmath143 ' are equally populated by data .    .",
    "dashed lines show the values of the function at @xmath138 and @xmath143.,scaledwidth=40.0% ]    three sample sizes were considered : @xmath144 ( ` small ' sample ) , @xmath145 ( ` medium ' sample ) and @xmath146 ( ` large sample ' ) .",
    "the targeted confidence level was 95% , i.e.  @xmath147 .",
    "for each sample , the values of @xmath74 to use in ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) or ( [ eqn : accicond ] ) were determined by the procedure described in section [ subsec : ush ] .",
    "the initial value of @xmath115 was taken here as the theoretically optimal value of the bandwidth for estimating @xmath6 - in this simulation study it is accessible as we know the ` truth ' : it is @xmath148 .",
    "this allows a fair comparison of the observed results as they are not impacted by other arbitrary decisions .",
    "the number of bootstrap replications was set to @xmath149 and the best value of @xmath74 was looked for on a grid of 200 equispaced values from 0.05 to 2 .",
    "the final value of @xmath74 was taken as the centre ( average ) of the set of values producing an estimated coverage higher than 95% , as suggested at the end of section [ subsec : ush ] .",
    "the ( approximated ) coverage probabilities of the intervals built according to this procedure are given in table [ tab : simcp ] .",
    ".scenario 1 , ( approximated ) coverage probabilities for the three types of confidence intervals ( nominal confidence level : 95% ) at @xmath138 and @xmath143 , for sample sizes @xmath144 , @xmath145 and @xmath146 . [ cols=\"<,<,^,^\",options=\"header \" , ]     it emerges from table [ tab : simcp ] that the wilson and agresti - coull intervals reach an empirical coverage consistently very close to the targeted 95% , and this for all sample sizes and at both locations ( i.e. , both when @xmath150 and @xmath151 ) . a notable exception ,",
    "though , is when @xmath152 and @xmath144 ( ` small ' sample ) .",
    "as explained in section [ subsec : waldcondci ] , the number of observations effectively playing a role in estimating @xmath6 at @xmath1 is @xmath100 . here , with @xmath144 , @xmath153 and @xmath154 )",
    "( for @xmath155 the standard gaussian kernel ) , the local equivalent sample size is roughly 1 observation for the values of @xmath74 around @xmath115 .",
    "that means that the effect of the shrinkage described below ( [ eqn : wilson_interval_alt ] ) is severe here , and the centre of the interval is seriously held back toward 1/2 . at @xmath138 ,",
    "this is a good thing as @xmath156 , and the observed coverage is actually higher than 95% ; at @xmath143 , with @xmath157 close to 1 , this is detrimental to the level of the intervals ( which keep an empirical coverage higher than 90% , though ) .",
    "as expected given the behaviour of its non - conditional counterpart , the wald interval struggles to maintain a reasonable level of coverage , even at large sample sizes or in favourable cases ( @xmath138 ) . only when @xmath138 and @xmath146 does the wald interval produces reasonable results ( but still slightly less accurate in terms of coverage probability than wilson and agresti - coull ) .    another perspective on this",
    "is provided by figures [ fig : lengthh0 ] and [ fig : lengthhpi ] , which show boxplots of the lengths of the @xmath140 confidence intervals computed from each construction for @xmath146 , as well as the selected values of @xmath74 , for @xmath138 and @xmath143 . at @xmath138 ,",
    "the three intervals are always very similar , and so are the values of @xmath74 selected by the procedure described in section [ subsec : ush ] .",
    "the empirical coverage are , therefore , similar as well as shown by table [ tab : simcp ] . at @xmath143 , however , the procedure selects values of @xmath74 much smaller for the wilson and agresti - coull intervals , than for the wald interval ( figure [ fig : lengthhpi ] , right panel ) .",
    "this means that the constructed wilson and agresti - coull intervals are indeed longer than the wald interval ( figure [ fig : lengthhpi ] , left panel ) , but that is the price to pay to keep a coverage probability of 95% . recalling that @xmath74 is selected via a bootstrap procedure ,",
    "the value of @xmath74 guaranteeing a high coverage for the bootstrap replications of the wald interval , is not guaranteed to maintain such high coverage ` in the real world ' . for the wilson and agresti - coull intervals , on the other hand , that is the case .",
    "( right ) for the three types of confidence intervals computed at @xmath138 on @xmath140 independent samples of size @xmath146 .",
    "the dashed line ( right panel ) shows @xmath158.,scaledwidth=60.0% ]     ( right ) for the three types of confidence intervals computed at @xmath143 on @xmath140 independent samples of size @xmath146 .",
    "the dashed line ( right panel ) shows @xmath158.,scaledwidth=60.0% ]    figures [ fig : lengthh0 ] and [ fig : lengthhpi ] also show the optimal value @xmath159 ( for @xmath146 ; dashed line in the right panel ) . according to the boxplots ,",
    "the value @xmath74 supposed to be good for constructing the confidence intervals ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) or ( [ eqn : accicond ] ) is , for many samples , smaller than @xmath115 , in agreement with what ` undersmoothing ' suggests .",
    "it is , however , _ not always _ the case .",
    "oftentimes ( especially at @xmath138 ) , taking @xmath74 ( much ) greater than @xmath115 seems to be the right thing to do .",
    "the fact that a ` small ' @xmath74 is not always ideal is easily understood through the case @xmath138 . in this scenario , due to symmetry , @xmath2 is actually equal to @xmath160 , the non - conditional probability @xmath161 . as a result ,",
    "any confidence interval for @xmath6 such as those described in section [ sec : chap2 ] can be used for @xmath2 as well .",
    "this is advantageous , as the sample average @xmath162 is naturally a better estimator ( smaller variance , no bias ) of the global @xmath6 than any local ( @xmath74 ` small ' ) , conditional attempt .",
    "those ` non - conditional ' intervals are actually recovered from ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) or ( [ eqn : accicond ] ) as @xmath163 .",
    "indeed , it is known that taking a large bandwidth in nonparametric regression essentially makes local estimators into global ones @xcite . intuitively ,",
    "if @xmath74 is very large ( @xmath164 ) in ( [ eqn : nwest ] ) then all observations are equally weighted and @xmath165 just reduces to the sample average @xmath166 .",
    "therefore , it is beneficial to take @xmath74 ` large ' here .",
    "of course , this is a very particular situation , but it exemplifies that the best @xmath74 really depends on the design and is not necessarily ` small ' . hence heuristic rules such as taking @xmath167 , with @xmath168 a small constant ( possibly depending on @xmath8 ) , are thus to be precluded and @xmath74 should be selected by a careful data - driven selection procedure .",
    "this shows the value of the procedure developed in section [ subsec : ush ] .",
    "the purpose of this second scenario is to empirically validate the real data analysis shown in the next section .",
    "essentially the same study as in scenario 1 was repeated , but this time data sets of size @xmath169 were generated as @xmath170 the above mixture of normals is a good parametric approximation of the distribution of the predictor @xmath66 in the application below ( figure [ fig : fhat ] ) , the above function @xmath6 is the best logistic fit for the analysed data ( figure [ fig : phatlogit ] ) , and the sample size @xmath169 is akin to that sample size as well .",
    "hence the results of this simulation gives an appreciation of the validity of the real case analysis described in the next section .",
    "again , @xmath140 independent samples were generated .",
    "for each of them , the values of @xmath74 to use in ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) or ( [ eqn : accicond ] ) were determined by the procedure described in section [ subsec : ush ] .",
    "the coverage probabilities of the three types of confidence intervals for @xmath2 was approximated by the fractions of the @xmath140 such intervals which include the true @xmath171 .",
    "those were @xmath172 for the wald interval , @xmath173 for the wilson interval , and @xmath174 for the agresti - coull interval .",
    "figure [ fig : lengthh2 ] shows the lengths and selected values of @xmath74 for the @xmath140 independent samples generated in this scenario .",
    "the conclusion are very similar to what was said for the case @xmath138 , @xmath146 in scenario 1 .",
    "in particular , both the wilson and agresti - coull intervals show coverage probabilities very close to their nominal level 95% , while , as @xmath175 and @xmath8 is ` large ' , the wald interval is not doing too bad either .",
    "this indicates that the conclusions drawn in section [ subsec : anal ] can be given some credibility .",
    "( right ) for the three types of confidence intervals computed at @xmath138 on @xmath140 independent samples of size @xmath169.,scaledwidth=60.0% ]",
    "the main aim of this analysis is to investigate the existence , or otherwise , of the second leg home advantage ( slha ) in uefa competitions ( champions league and europa league ) .",
    "the slha is described as the advantage in a balanced two - legged knockout tie whereby teams are , on average , more likely to qualify if they play at home in the second leg .",
    "hereafter , the team playing at home on the second leg will be called ` second leg home team ' [ slht ] , and conversely for the ` first leg home team ' [ flht ] .",
    "table 1 in @xcite exemplifies that many players and coaches believe that the slha exists .",
    "maybe more surprising is that the uefa body itself seems to believe in it as well : the design of the uefa champions and europa leagues is such that teams which finished first in their group in the first stage , are _ rewarded _ by being guaranteed to play the second leg at home in the first subsequent knockout round .",
    "if only for that , any serious empirical analysis of the slha effect must adjust for team strengths , as briefly explained in section [ sec : intro ] .",
    "this said , the ` strength ' of a team is a rather vague concept , which in addition is likely to vary over the course of a season according to many imponderable factors ( e.g. , the injury of a key player may seriously affect a team s abilities ) .",
    "a simple proxy for such ` strength ' seems to be the uefa club coefficient .",
    "its calculation is actually based on two elements : first , an individual club index , obtained from the points awarded to the team for their performance during the course of the champions or europa league each year ( details to be found in @xcite ) ; second , a country index , which is the average of the indices of all the clubs of the same country which took part to a european competition that year . the country index for a particular season",
    "is defined as the sum of that country s points from the previous five seasons . since 2009",
    ", the club uefa coefficients have been calculated as the sum of the clubs points from the previous five seasons plus the addition of 20% of the relevant country coefficient for the latest season . ]",
    "the club coefficients take thus into account the recent performance of the club in european competitions , but also the strength of the league from which the team comes .",
    "although not perfect , they form the basis for ranking and seeding teams in the uefa competitions , and should be reasonably representative of the relative overall strengths of the teams over one season .",
    "support for this assertion is indirectly provided in @xcite .",
    "they hypothesised that , as the club coefficients are only updated at the end of each season , group stage performance would provide a more up - to - date measure of team strength for the following knockout rounds .",
    "as such , they included both club coefficients and group stage performance as predictors in their logistic regression model .",
    "it turned out that ` group stage performance ' was not statistically significant either in a model by itself or in a model which also used ` club coefficient ' ( which was significant ) .",
    "it seems , therefore , fair to consider the uefa coefficient of clubs as the main indicator of team strength for a given season , and the modelling below will make use of that index only .",
    "the analysed data , all drawn from @xcite , include all match results from uefa champions and europa leagues from 2009/2010 through to 2014/15 and the uefa coefficients of all clubs which took part to some european competition for those seasons .",
    "initially , data from seasons 1999/00 to 2014/15 were planned to be analysed , however uefa has changed the method for calculating the club coefficients three times during that period .",
    "these changes mean that the time periods ( 1999/00 to 03/04 , 04/05 to 08/09 , and 09/10 onwards ) are no longer directly comparable given that the uefa coefficients would be fundamentally different variables .",
    "this necessitated analysis of only one time period , and the most recent ( 2009/10 to 2014/15 ) was naturally chosen .",
    "it would have been possible to recalculate the uefa coefficients of each club for the years prior to 2009 using the current method , but it is probably meaningful here to focus on the last years only , given the possible fading of the slha over years that have sometimes been suggested by previous studies ( see section [ sec : intro ] ) .",
    "this analysis will consequently evaluate the existence of the slha ` now ' , and not from a historical perspective .",
    "altogether , 4160 matches were played in the champions and europa leagues from 2009/2010 to 2014/2015 .",
    "of course , only the knockout two - legged ties were of interest in this study .",
    "hence , the first , obvious action was to remove group stage games , played in a round robin style and not qualifying as a two - stage knockout , and match - ups where only one game was played such as finals or match - ups where one game was cancelled ( it happened that some games were cancelled due to security concerns , or others ) .",
    "it remained @xmath176 two - legged ties ( i.e. , pairs of matches ) , both in qualifying rounds ( before the group stage ) and in final knockout stage ( after the group stage ) .",
    "in a two - legged knockout tie , the aggregate score over the two matches is tallied and the team which scored the most goals on aggregate is declared the winner and qualifies to the next round . if the teams have scored an equal number of goals , the so - called ` _ away goals rule _ ' applies : the team which scored most ` away from home ' would qualify .",
    "if this criterion does not break the tie , then two extra periods of 15 minutes are played at the end of the normal time of the second leg .",
    "if the teams are still tied then , the result is decided by penalty shoot - out . for games which went to extra - time",
    "( there were @xmath177 of them ) , it is reasonable to hypothesise that some slha may be induced by the fact that the slht plays 30 minutes longer at home than the flht , hence benefiting more from its home advantage @xcite .",
    "this could justify to exclude those games from the study , given that they _ should _ artificially give rise to some sort of slha .",
    "it was , however , decided to keep them in a first time , arguing that it might precisely be the key element to take into account when assessing the slha .",
    "the possibility of playing extra time and/or taking penalties on their home ground might explain why most players favour playing at home on the second leg . in a second time",
    ", those @xmath178 games will be excluded from the analysis , in order to appreciate the real effect of extra - time / shoot - out on the slha ( see section [ subsec : disc ] ) .",
    "call @xmath179 the binary outcome of a two - legged tie , and for the @xmath14th tie define @xmath13 if the slht qualifies and @xmath180 otherwise ( hence , if the flht qualifies ) .",
    "the study is based on the regression of @xmath179 on an explanatory variable @xmath66 quantifying the inequality in strength between the two teams involved .",
    "call @xmath181 and @xmath182 the uefa coefficients of the flht and slht , respectively , at the time of meeting , and define , well below the next smallest coefficient of 0.050 . ]",
    "@xmath183 a positive value of @xmath66 indicates that the slht is stronger than the flht , and conversely for a negative @xmath66 .",
    "the value @xmath184 indicates an exactly balanced tie .",
    "the value @xmath77 is the observed value of @xmath66 for the @xmath14th tie .",
    "note that @xcite and @xcite used the difference @xmath185 as control variable ( @xcite actually used a normalised version of it ) .",
    "the reason why a log transformation is introduced in ( [ eqn : predx ] ) is that @xmath181 and @xmath182 are positive variables .",
    "it turns out that two positive numbers are more naturally compared through their ratio than through their difference .",
    "is a group , @xmath186 is not . the haar measure ( i.e. , the ` natural ' mathematical measure ) on @xmath187 is @xmath188 , translating to the measure of an interval @xmath189 \\subset \\r^+$ ] being @xmath190 . ] as an illustration , in the first qualifying round of the champions league 2014 - 2015 , the sammarinese team of la fiorita ( @xmath191 ) faced the estonian team of levadia tallinn ( @xmath192 ) ; the same year , in the semi - finals , fc barcelona ( @xmath193 ) clashed with bayern mnchen ( @xmath194 ) .",
    "the ( absolute ) difference in coefficients is roughly the same for both ties ( @xmath195 and @xmath196 , respectively ) , however anybody with a slight appreciation for european football would know that the second case , bringing together two giants of the discipline , was to be much tighter than the first one , opposing a new - coming team from one of the weakest leagues in europe ( san marino ) to a more experienced team from a mid - level league .",
    "the ratio of the coefficients @xmath197 , respectively @xmath198 and @xmath199 for the above two ties , is much more representative of the relative forces involved .",
    "figure [ fig : fhat ] shows the kernel estimate @xmath200 ( [ eqn : fhat ] ) of the density @xmath68 of the predictor @xmath66 , overlaid to an histogram .",
    "the bandwidth @xmath201 was selected by direct plug - in ( * ? ? ?",
    "* section 3.3.3 ) and the kernel was the standard gaussian density .",
    "the estimate clearly suggests that @xmath68 is bimodal .",
    "this can be understood the following way . in the qualifying rounds ,",
    "it is very rare to see two teams of very similar strength facing each other : there is often a team ` much stronger ' ( at that level ) than the other .",
    "see the above example la fiorita versus levadia tallinn : although the two teams can be considered ` weak ' and both their uefa coefficients are ` low ' , the ratio of those coefficients unequivocally tells which team is likely to qualify .",
    "a value of @xmath66 close to 0 is actually only observed if the uefa coefficients of the two matched - up teams are _ really of the same order _ , and that typically happens in the final rounds , when the strongest teams meet ( for example , fc barcelona versus bayern mnchen , see above ) .",
    "there are , obviously , much more qualifying games than semi - finals , hence there are comparatively less games characterised by a value of @xmath66 close to 0 , than otherwise . in any case , @xmath200 shows a peak on the positive side noticeably higher than that on the negative side .",
    "in fact , the observed proportion of positive values @xmath77 s is @xmath202 ( wilson confidence interval : @xmath203 $ ] ) .",
    "this means that the stronger team is indeed more often the slht than the contrary , which confirms the existence of the confounding factor described in sections [ sec : intro ] and [ subsec : background ] , and the necessity of taking it properly into account .    ) of @xmath68 , with @xmath201 and @xmath155 the standard gaussian density",
    "the ticks at the bottom of the graph show the observed values @xmath77s.,scaledwidth=50.0% ]    in this application , it is is sensible to treat the observed values @xmath204 of the predictor as known constants set by the design ( ` _ fixed design _ ' ) , and it will be assumed that @xmath205 for @xmath206 , independently of one another .",
    "the function @xmath6 is left totally unspecified except that it is twice continuously differentiable .",
    "the nadaraya - watson estimator @xmath207 ( [ eqn : nwest ] ) was computed on the data set @xmath208 .",
    "the kernel @xmath73 was the standard gaussian density , while the optimal bandwidth was approximated by the method based on aic described in @xcite , which returned @xmath209 .",
    "the resulting estimate is shown in figure [ fig : phat ] ( left ) .",
    "common sense suggests that @xmath6 should be a monotonic function of @xmath1 , hence the little ` bump ' in @xmath207 between @xmath210 and @xmath211 is most certainly due to random fluctuation only .",
    "this happens in an area where data are rather sparse , so it is not surprising that the nonparametric , essentially local , estimator is not the most accurate there .",
    "if the focus of the analysis was that part of the range of values of @xmath66 , then more involved estimation methods could be used ( e.g. , adaptive estimation based on variable bandwidths , robust version of the nw estimator such as loess , or isotonic regression ) . however",
    ", this study is mainly interested by what happens around @xmath138 , where data are abundant .",
    "the nw estimate @xmath207 looks well - behaved and smooth over @xmath212 $ ] , say ( see close - up in figure [ fig : phat ] , right ) , so it is probably enough here . in particular ,",
    "the estimator gives @xmath213 , indicating a potential slha .",
    "the statistical significance of this effect is examined below by computing the confidence intervals ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) and ( [ eqn : accicond ] ) for @xmath2 , using a bandwidth @xmath74 obtained from the procedure described in section [ subsec : ush ] .",
    "details are given below .",
    "( [ eqn : nwest ] ) of @xmath6 , with @xmath214 and @xmath155 the standard gaussian density . global view ( left ) and close - up around @xmath138 ( right ) .",
    "ticks show the observed data . ]",
    ".  is what figure [ fig : phat ] shows . in step 2 . ,",
    "@xmath215 bootstrap resamples were generated as @xmath123 ; @xmath216 , @xmath217 . for step 3 . , an equispaced grid of 200 candidate values for @xmath74 , from @xmath218 to @xmath219 , was built . on each bootstrap resample ,",
    "the 3 confidence intervals ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) and ( [ eqn : accicond ] ) at @xmath138 for each candidate value of @xmath74 were computed .",
    "the appearance of the functions @xmath220 ( step 4 . ) for the three types of intervals is shown in figure [ fig : hci ] .",
    "the returned values of the bandwidth to use ( step 5 . ) were obtained as the average of all the values @xmath74 which give an estimated coverage higher than 95% .",
    "those were : @xmath221 for the wald interval , and @xmath222 for both the wilson and the agresti - coull interval . with these values of @xmath74 in ( [ eq : wald_kernel ] ) , ( [ eqn : wilson_interval_alt ] ) and ( [ eqn : accicond ] )",
    ", we obtain as 95% confidence intervals for @xmath2 : @xmath223 .",
    "\\label{eqn : ciuefa}\\ ] ] interestingly , with this sample size , the three intervals are mostly indistinguishable , as they differ only from the fourth decimal digit .",
    "of course @xmath224 does not belong to this interval , evidencing the statistical significance of the slha ( more on this in section [ subsec : disc ] ) .",
    "for the 3 types of confidence intervals .",
    "the dashed lines show the returned values of @xmath74 , obtained as the average of the set of values for which @xmath220 exceeds 95%.,scaledwidth=100.0% ]    from a methodological point of view , it is interesting to note that the empirically ` optimal ' bandwidth @xmath74 for building the confidence intervals ( here @xmath225 ) is actually _",
    "greater _ than the bandwidth @xmath209 , considered ` best ' for estimating @xmath6 . as already noted in section [ subsec : simstud ] ,",
    "this is in contrast to what a naive interpretation of ` undersmoothing ' would suggest ( to take @xmath74 smaller than @xmath115 ) .",
    "admittedly , @xmath115 still belongs to the acceptable area ( @xmath226 ) , see figure [ fig : hci ] .",
    "however , if one took @xmath227 as it has sometimes been suggested in the literature following ( [ eqn : covprob ] ) , it is here @xmath228 and the so - produced intervals would have a coverage probability much lower than the targeted 95% .",
    "note that taking @xmath74 too small has also an adverse effect of the length of the intervals , given that the standard error of the estimator @xmath79 is essentially inversely proportional to @xmath74 , by ( [ eqn : asnormnw])-([eqn : nw_asymp_normal_h_undersmooth ] ) .",
    "this confirms that _ ad - hoc _ procedures aiming at producing a supposedly ` undersmoothed ' bandwidth need not work well in finite samples , and should not be used .    for completeness",
    ", some elements of analysis based on a parametric logistic model are briefly given below .",
    "importantly , it is noted that a classical goodness - of - fit test for glm based on the deviance and pearson s residuals rejects the logistic model for the data ( @xmath6-value @xmath229 ) .",
    "the le cessie - van houwelingen test @xcite , precisely based on the nadaraya - watson estimator ( [ eqn : nwest ] ) , shows marginal evidence against it as well ( @xmath6-value @xmath230 ) .",
    "therefore , what follows is not fully supported by the data , and is shown for illustration only .",
    "the fitted logistic model is @xmath231 , and the coefficients are estimated at @xmath232 and @xmath233 .",
    "this logistic fit is shown in figure [ fig : phatlogit ] , overlaid to the nadaraya - watson estimator , to appreciate their discrepancy around 0 .",
    "a 95% confidence interval for @xmath234 is @xmath235 \\ni 0 $ ] , indicating the non - significance of the intercept . given that @xmath236 , this translates into a 95% confidence interval @xmath237 \\ni 1/2 $ ] for @xmath2 .",
    "hence an analysis based on logistic modelling would fail to highlight a potential slha .",
    "figure [ fig : phatlogit ] reveals that the constrained logistic specification for @xmath6 forces the estimate to ` take a shortcut ' compared to what the data really say ( i.e. , the nonparametric estimate ) , and that smoothes over the interesting features around 0 . remarkably , the length of the interval for @xmath2 based on this parametric model is @xmath238 , whereas the nonparametric confidence interval ( [ eqn : ciuefa ] ) is only slightly longer ( margin of @xmath239 ) .",
    "the price to pay for the flexibility and robustness granted by the nonparametric approach does not seem to be in terms of precision ( i.e. , length of the confidence intervals ) in this study .",
    "( solid line , same as in figure [ fig : phat ] ) and fitted logistic curve ( dashed line).,scaledwidth=40.0% ]    finally , the nonparametric analysis was repeated , but this time excluding the ties which went to extra - time , in order to appreciate the effect of those on the existence or otherwise of the slha .",
    "there were @xmath177 such occurrences of extra - time , so it remained 1269 two - legged ties .",
    "the estimated nadaraya - watson estimator ( @xmath240 by aic criterion , standard gaussian kernel ) is shown in figure [ fig : phatet ] .",
    "compared to the estimator using all data , the two curves are remarkably close around 0 .",
    "this ` no - extra - time ' version gives @xmath241 .",
    "so , somewhat surprisingly , the magnitude of the slha is actually not influenced at all by the ` extra - time ' element .",
    "what the plot reveals , though , is that the two curves move apart as @xmath1 moves away from 0 . for @xmath242 , the dashed line ( ` no - extra - time ' curve )",
    "is above the solid line , and conversely for @xmath243 .",
    "this can be interpreted the following way : when an underdog playing away on the second leg still manages to qualify , that happens ` often ' after extra - time , i.e. , after a long and though battle .",
    "indeed , one does nt expect an underdog to go and qualify easily at the home ground of a much stronger team .",
    "( solid line , same as in figure [ fig : phat ] ) and fitted logistic curve ( dashed line).,scaledwidth=40.0% ]      this analysis investigated the existence of a second leg home advantage in two - stage knockout matches in the uefa champions and europa leagues from 2009/10 to 2014/15 . _",
    "a significant effect was found_. this finding contrasts with other research where the difference in team strength was controlled for , most relevantly @xcite , who found a significant positive slha that had disappeared by 1995/96 , and @xcite , who found no effect .",
    "obviously , these conflicting conclusions may have many different origins .",
    "first and foremost , the analysed data were not exactly the same . @xcite analysed historical data from all the european cups from their early time ( 1955/56 ) up until 2005/06 ( taking into account a potential effect of time ) , while @xcite looked only at the final knockout stage of the uefa champions league from 1994/95 to 2009/10 .",
    "in this paper it was decided to analyse data from 2009/10 to 2014/15 in order to keep the control variable @xmath66 , based on the uefa club coefficients , homogeneous across the study .",
    "indeed , the way that the uefa calculates those coefficients have drastically changed over time , most recently in 1999 , 2004 and 2009 .",
    "@xcite acknowledged this issue and addressed it by using indicator variables to create three covariates to include in their logistic model : @xmath244 ( where in their case , @xmath1 is the difference in uefa coefficients , as mentioned in section [ subsec : dataprep ] ) .",
    "this allowed them to estimate the second - leg home advantage across all seasons as a whole whilst controlling for team strength via the three calculation methods simultaneously . however",
    "the usefulness of an overall measure is not particularly high as the strength of the effect is known to be changing within the same time period .",
    "their refined time series analysis of the effect essentially breaks the data down into sub - time periods , anyway .",
    "@xcite , on the other hand , did not account for the differences in coefficient calculation methods , or at least they did not mention anything of that sort .",
    "in fact , they incorrectly stated that their entire dataset utilises 20% of the country coefficient and then assume that there are no changes in calculation method [ their section 2.3 ] .",
    "however , there were three changes in the weight that the country index carries over the period that they studied ( see footnote [ foot : coutnry ] . ) .",
    "the control variable was also different , as here the log - difference between the uefa coefficients was used , as opposed to their difference in @xcite and @xcite .",
    "this is arguably more natural for comparing such positive indices .",
    "finally , @xcite and @xcite both used logistic regression modelling , but neither provided , or made reference to , any diagnostics investigating the validity of their models . yet",
    ", there are serious concerns about it .",
    "for instance , figure 2 in @xcite indicates that , for a _ maximum _ ( normalised ) difference in uefa coefficients ( @xmath245 or @xmath39 ) , so in the most unbalanced tie one can imagine , the ` underdog ' team keeps around 20% chance of qualifying .",
    "common sense alone suggests that , if la fiorita was ever to face fc barcelona , they would not have 1 in 5 chances of qualifying .    actually , testing the goodness - of - fit of the logistic model for the data analysed in this paper lead to reject it .",
    "worse , forcing a logistic - based analysis did not allow a significant slha effect to be highlighted , whereas it was picked up by the nonparametric procedure . highlighting a significant slha effect",
    "opens the door for further analyses .",
    "for instance , @xcite analysed 199 two - legged knockout ties from the champions and europa leagues from 1994/95 to 2006/07 , and investigated whether the number of goals scored in each leg is associated with the second - leg home advantage .",
    "table [ tab : goals_scored_lidor ] shows that the average goals scored by the away team in each leg remains similar but the goals scored by the home team increases approximately 33% from the flht to the slht .",
    "this suggests that the cause of any potential second - leg home advantage is not due to any pressures or influences on the flht when playing away on the second leg , but rather it is a boost to the performance of the slht on their own soil relative to the flht on theirs .",
    "admittedly this analysis did not control for the relative team strengths ( see section [ sec : intro ] ) but it does provide an interesting avenue for future research to explore . reproducing this type of analysis whilst controlling for team strengths would probably provide a better understanding of whether the effect is an advantage to the slht or more so a disadvantage to the flht - or both .",
    "@ccc + & first leg & second leg +   + home team & 1.27 & 1.68 + away team & 0.89 & 0.85 +    more specific questions may be asked as well .",
    "for instance , @xcite stated in their review that the home field advantage is apparently universal across all types of sport , yet not universal across all teams _ within _ a sport . investigating",
    "if the second - leg home advantage affects different teams individually would also be of interest .",
    "historically , some clubs have indeed demonstrated expertise in improbable comebacks when playing home on the second leg , what is now known in the football folklore as _ remontada _ ( spanish for ` comeback ' or ` catch - up ' ) .",
    "research could also turn to the realm of psychology and sociology , attempting to develop for the slha a conceptual framework similar to that of @xcite and @xcite and briefly exposed in section [ sec : intro ] .",
    "motivated by a formal analysis of the existence ( or otherwise ) of the so - called ` _ second - leg home advantage _ ' in some international football competitions , this paper aimed to develop better tools for drawing reliable conclusions from a binary regression model , that is , when a conditional probability function @xmath0 is to be empirically estimated .",
    "in particular , a reliable method for constructing pointwise ( i.e. , for a fixed value of @xmath1 ) confidence intervals with good empirical coverage properties was needed .    avoiding rigid and sometimes unwarranted parametric specifications for the function @xmath6",
    ", the method developed here is based on the nadaraya - watson estimator , arguably one of the simplest nonparametric regression estimators . in the case of a binary response , this estimator returns a kind of ` conditional sample proportion ' , from which standard confidence intervals of wald type can easily be constructed . however , in the basic case of estimating a binomial probability , the wald confidence interval is known to perform very poorly , and alternative confidence intervals , such as the wilson and the agresti - coull intervals , have been strongly recommended .    the first main methodological contribution of the paper was to extend those ` better ' confidence intervals to the conditional case .",
    "given that the nadaraya - watson estimator is a locally weighted average of the observed binary responses , that extension was very natural and did not present any problem .",
    "` conditional versions ' of the wilson and agresti - coull intervals were thus proposed .",
    "actually , any estimator of type @xmath246 where @xmath247 is a set of weights , possibly depending on a parameter @xmath248 ( often : a smoothing parameter , such as a bandwidth ) and summing to 1 , can be regarded as a ` local sample proportion ' , and hence could serve as the basis of the methodology _ mutatis mutandis_. nonparametric regression estimators of type ( [ eqn : linest ] ) are known as _ linear smoothers _ , and include many common nonparametric regression estimators such as local linear , splines or basic ( i.e. , without thresholding ) wavelet estimators , for instance . the methodology developed here is thus very general .",
    "as often when nonparametric function estimation is involved , the inherent bias of estimators like ( [ eqn : linest ] ) constitutes a major stumbling block when devising inferential tools .",
    "when building confidence intervals , it has been advocated that proceeding via _ undersmoothing _ , that is , working purposely with a sub - optimal bandwidth , would be beneficial in theory .",
    "however , an attractive and effective data - driven procedure for selecting such an ` undersmoothed ' bandwidth was missing up until now .",
    "the second main methodological contribution of the paper was to suggest such a procedure , based on some bootstrap resampling scheme .    somewhat surprisingly , the bandwidth returned by the procedure and supposed to be optimal for building good confidence intervals , was not seen to be necessarily smaller than what it should be otherwise .",
    "that is in contrast with what a naive interpretation of ` undersmoothing ' would suggest .",
    "the procedure was validated through a simulation study , and proved very efficient at returning a bandwidth guaranteeing empirical coverage very close to the nominal level for the so - constructed intervals in all situations .",
    "importantly , nothing in the procedure pertains to the binary regression framework , so it is clear that the suggested methodology can be used for selecting the right bandwidth for building confidence intervals for a general regression function as well .",
    "these new intervals were finally used for answering the research question as to the existence of the second - leg home advantage in international football competitions . to that purpose ,",
    "data from the uefa champions and europa leagues from 2009/10 to 2014/15 were collected and analysed .",
    "working within the regression framework allowed for the abilities of the teams involved to be taken into account , which , due to uefa seeding regulations , confounds the relationship between playing at home in the second game and the probability of a qualification .",
    "this confounding factor was confirmed by an explanatory analysis of the data . for reasons made clear in the paper",
    ", the relative strength of the matched teams was measured through the log - difference of the uefa coefficients of the clubs .",
    "then , the nonparametric model revealed a significant second - leg home advantage , with an estimated probability of qualifying when playing at home on the second leg of @xmath249 and 95% confidence interval @xmath250 $ ] , after controlling for the teams abilities .",
    "the existence of such an unwarranted advantage for the team playing at home second may call for some system of compensation and/or handicap in knockout stages of uefa administered competitions .",
    "importantly , the analysis provided is this paper is very objective , in the sense that , purely nonparametric in nature , it does not rely on any arbitrary assumption enforced by the analyst and which could orientate the conclusions in one or the other direction . in particular",
    ", no second - leg home advantage effect was evidenced by previous research , exclusively based on parametric models such as logistic regression but without any justification or validation of that parametric specification .",
    "it is revealing to observe that , although not fully supported by the data here , a similar analysis based on logistic modelling was not able to highlight the effect .",
    "model misspecification can , indeed , hide interesting features .",
    "this research was supported by a faculty research grant from the faculty of science , unsw sydney ( australia ) .",
    "99 agresti , a.  and coull , b.a .",
    "( 1998 ) , approximate is better than `` exact '' for interval estimation of binomial proportions , amer .",
    ", 52 , 119 - 126 .",
    "blyth , c.r .  and still , h.a .",
    "( 1983 ) , binomial confidence intervals , j.  amer .  statist .",
    "assoc . , 78 , 108 - 116 .",
    "brown , l.d .",
    ", cai , t.t .  and dasgupta , a.  ( 2001 ) , interval estimation for a binomial proportion , statist .",
    ", 16 , 101 - 133 .",
    "brown , l.d . , cai , t.t .  and dasgupta , a.  ( 2002 ) , confidence intervals for a binomial proportion and asymptotic expansions , ann .",
    ", 30 , 160 - 201 .",
    "carron , a.v . ,",
    "loughhead , t.m .  and bray , s.r .",
    "( 2005 ) , the home advantage in sports competitions : courneya and carron s ( 1992 ) conceptual framework a decade later , j.  sports sci . ,",
    "23 , 395 - 407 .",
    "chen , s.x .",
    "and qin , y.s .  ( 2002 ) , confidence intervals based on local linear smoother , scand .  j.  statist . , 29 , 89 - 99 .",
    "copas , j.b .",
    "( 1983 ) , plotting @xmath6 against @xmath1 , j.  roy .",
    "statist .",
    "c , 32 , 25 - 31 .",
    "courneya , k.s .  and",
    "carron , a.v .",
    "( 1992 ) , the home advantage in sport competitions : a literature review , journal of sport and exercise psychology , 14 , 13 - 27 .",
    "cressie , n.  ( 1978 ) , a finely tuned continuity correction , ann .",
    "statist .",
    ", 30 , 435 - 442 .",
    "eguchi , s. , kim , t.y .  and park , b.u .",
    "( 2003 ) , local likelihood method : a bridge over parametric and nonparametric regression , j.  nonparametr .",
    "stat . , 15 , 665 - 683 .",
    "eubank , r.l .  and",
    "speckman , p.l .",
    "( 1993 ) , confidence bands in nonparametric regression , j.  amer .",
    "statist .",
    ", 88 , 1287 - 1301 .",
    "eugster , m.j.a .",
    ", gertheiss , j.  and kaiser , s.  ( 2011 ) , having the second leg at home : advantage in the uefa champions league knockout phase ? , j.  quant .",
    "sports , 7 , 1 .",
    "flores , r. , forrest , d. , de pablo , c.  and tena , j.  ( 2015 ) , what is a good result in the first leg of a two - legged football match ?",
    "european j.  oper .",
    ", 247 , 641 - 647 .",
    "ghosh , b.k .",
    "( 1979 ) , a comparison of some approximate confidence intervals for the binomial parameter , j.  amer .  statist",
    ".  assoc .",
    ", 74 , 894 - 900 .",
    "hall , p.  ( 1992 ) , on bootstrap confidence intevals in nonparametric regression , ann .  statist .",
    ", 20 , 695 - 711 .",
    "hall , p.  and horowitz , j.  ( 2013 ) , a simple bootstrap method for constructing nonparametric confidence bands for functions , ann .",
    ", 41 , 1892 - 1921 .",
    "hrdle , w.k .  and",
    "bowman , a.w .",
    "( 1988 ) , bootstrapping in nonparametric regression : local adaptive smoothing and confidence bands , j.  amer .",
    "statist .",
    "assoc . , 83 , 102 - 110 .",
    "hrdle , w.k .",
    ", mller , m. , sperlich , s.  and werwatz , a. , nonparametric and semiparametric models : an introduction , springer , 2004 .",
    "horowitz , j.l . and",
    "savin , n.e .",
    "( 2001 ) , binary response models : logits , probits and semiparametrics , j.  econ .",
    "persp . , 15 , 43 - 56 .",
    "hurvich , c.m . ,",
    "simonoff , j.s .  and tsai , c .-",
    "( 1998 ) , smoothing parameter selection in nonparametric regression using an improved akaike information criterion , j.  r.  stat .",
    ".  b stat .",
    ", 60 , 271 - 293 .",
    "jamieson , j.p .",
    "( 2010 ) , the home field advantage in athletics : a meta - analysis , j.  appl .",
    "psychol . , 40 , 1819 - 1848 .",
    "kassies , b.  ( 2016 ) , uefa european cup coefficients database , http://kassiesa.home.xs4all.nl/bert/uefa/data/index.html .",
    "khler , m. , schindler , a.  and sperlich , s.  ( 2014 ) , a review and comparison of bandwidth selection methods for kernel regression , int .",
    ", 82 , 243 - 274",
    ". le cessie , s.  and van houwelingen , j.c .",
    "( 1991 ) , a goodness - of - fit test for binary regression models based on smoothing methods , biometrics , 47 , 1267 - 1282 .",
    "lidor , r. , bareli , m. , arnon , m.  and bareli , a.a .",
    "( 2010 ) , on the advantage of playing the second game at home in the knockout stages of european soccer cup competitions , international journal of sport and exercise psychology , 8 , 312 - 325 .",
    "nadaraya , e.a .",
    "( 1964 ) , on estimating regression , theory probab .  appl . ,",
    "9 , 141 - 142 .",
    "neumann , m.h .",
    "( 1997 ) , pointwise confidence intervals in nonparametric regression with heteroscedastic error structure , statistics , 29 , 1 - 36 .",
    "nevill , a.m.  and holder , r.l .",
    "( 1999 ) , home advantage in sport : an overview of studies on the advantage of playing at home , sports med .",
    ", 28 , 221 - 236 .",
    "olivier , j.  and may , w.l .",
    "( 2006 ) , weighted confidence interval construction for binomial parameters , stat .",
    "methods med .",
    ", 15 , 37 - 46 .",
    "page , l.  and page , k.  ( 2007 ) , the second leg home advantage : evidence from european football cup competitions , j.  sports sci .",
    ", 25 , 1547 - 1556 .",
    "pollard , r.  ( 1986 ) , home advantage in soccer : a retrospective analysis , j.  sports sci . , 4 , 237 - 248 .",
    "pollard , r.  ( 2006 ) , home advantage in soccer : variations in its magnitude and a literature review of the inter - related factors associated with its existence , j.  sport behav . , 29 , 169 - 189 .",
    "pollard , r.  ( 2008 ) , home advantage in football : a current review of an unsolved puzzle , open sports sci .",
    "j. , 1 , 12 - 14 .",
    "pollard , r.  and pollard , g.  ( 2005 ) , long - term trends in home advantage in professional team sports in north america and england ( 1876 - 2003 ) , j.  sports sci . , 23 , 337 - 350 .",
    "rodrguez - campos , m.c .  and cao - abad , r.  ( 1993 ) , nonparametric bootstrap confidence intervals for discrete regression functions , j.  econometrics , 58 , 207 - 222 .",
    "schwartz , b.  and barsky , s.f .",
    "( 1977 ) , the home advantage , social forces , 55 , 641 - 661 .",
    "wasserman , l. , all of nonparametric statistics , springer , 2006 .",
    "watson , g.s .",
    "( 1964 ) , smooth regression analysis , sankhya , 26 , 359 - 372 .",
    "wilson , e.  ( 1927 ) , probable inference , the law of succession , and statistical inference , j.  amer .",
    "statist .",
    "assoc . , 22 , 209 - 212 .",
    "xia , y.  ( 1998 ) , bias - corrected confidence bands in nonparametric regression , j.  r.  stat .",
    "soc .  ser .",
    ", 60 , 797 - 811 ."
  ],
  "abstract_text": [
    "<S> in international football ( _ soccer _ ) , two - legged knockout ties , with each team playing at home in one leg and the final outcome decided on aggregate , are common . </S>",
    "<S> many players , managers and followers seem to believe in the ` second - leg home advantage ' , i.e.  that it is beneficial to play at home on the second leg . a more complex effect than the usual and well - established home advantage , it is harder to identify , and previous statistical studies did not prove conclusive about its actuality . yet , given the amount of money handled in international football competitions nowadays , the question of existence or otherwise of this effect is of real import . </S>",
    "<S> as opposed to previous research , this paper addresses it from a purely nonparametric perspective and brings a very objective answer , not based on any particular model specification which could orientate the analysis in one or the other direction . along the way </S>",
    "<S> , the paper reviews the well - known shortcomings of the wald confidence interval for a proportion , suggests new nonparametric confidence intervals for conditional probability functions , revisits the problem of the bias when building confidence intervals in nonparametric regression , and provides a novel bootstrap - based solution to it . </S>",
    "<S> finally , the new intervals are used in a careful analysis of game outcome data for the uefa champions and europa leagues from 2009/10 to 2014/15 . </S>",
    "<S> a slight ` second - leg home advantage ' is evidenced .    </S>",
    "<S> * keywords : * football ; home advantage ; nonparametric regression ; confidence intervals ; undersmoothing . </S>"
  ]
}