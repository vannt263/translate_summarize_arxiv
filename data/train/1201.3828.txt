{
  "article_text": [
    "a typical object of interest in many fields is the sample covariance matrix @xmath9 of a data matrix @xmath10 , @xmath0 , @xmath11 .",
    "the matrix @xmath12 can be seen as a sample of size @xmath3 of @xmath13-dimensional data vectors . for fixed @xmath13",
    "one can show , as @xmath3 tends to infinity , that under certain assumptions the eigenvalues of the sample covariance matrix converge to the eigenvalues of the true underlying covariance matrix @xcite .",
    "however , the assumption @xmath14 may not be justified if one has to deal with high dimensional data sets , so that it is often more suitable to assume that the dimension @xmath13 is of the same order as the sample size @xmath3 , that is @xmath15 such that @xmath16 for a symmetric matrix @xmath17 with eigenvalues @xmath18 , we denote by @xmath19 the spectral distribution of @xmath17 , where @xmath20 denotes the dirac measure located at @xmath21 .",
    "this means that @xmath22 is equal to the number of eigenvalues of @xmath17 that lie in the set @xmath23 . from now on we will call @xmath24 the sample covariance matrix . due to [ npy ] , this change of normalization can be reversed by a simple transformation of the limiting spectral distribution . for notational convenience",
    "we suppress the explicit dependence of the occurring matrices on @xmath3 and @xmath13 where this does not cause ambiguity .",
    "the distribution of gaussian sample covariance matrices of fixed size was first computed in @xcite .",
    "several years later , it was marchenko and pastur @xcite who considered the case where the random variables @xmath25 are more general i.i.d .  random variables with finite second moments @xmath26 , and the number @xmath13 of variables is of the same order as the sample size @xmath3 .",
    "they showed that the empirical spectral distribution ( esd ) @xmath27 of @xmath24 converges , as @xmath28 , to a nonrandom distribution @xmath29 , called limiting spectral distribution ( lsd ) , given by @xmath30 and point mass @xmath31 if @xmath32 ; in this formula , @xmath33 . here and in the following , convergence of the esd means almost sure convergence as a random element of the space of probability measures on @xmath34 equipped with the weak topology .",
    "in particular , the eigenvalues of the sample covariance matrix of a matrix with independent entries do not converge to the eigenvalues of the true covariance matrix , which is the identity matrix and therefore only has eigenvalue one .",
    "this leads to the failure of statistics that rely on the eigenvalues of @xmath24 which have been derived under the assumption of fixed @xmath13 , and random matrix theory is a tool to correct these statistics @xcite . in the case where the true covariance matrix is not the identity matrix ,",
    "the lsd can in general only be given in terms of a nonlinear equation for its stieltjes transform , which is defined by @xmath35 conversely , the distribution @xmath29 can be obtained from its stieltjes transform @xmath36 via the stieltjes  perron inversion formula ( ( * ? ? ?",
    "* theorem b.8 ) ) , which states that @xmath37)=\\frac{1}{\\pi}\\lim_{\\epsilon\\to 0^+ } \\int_a^b \\im m_{\\hat{f}}(x+ { \\mathrm{i}}\\epsilon ) { \\mathrm{d}}x.\\ ] ] for all continuity points @xmath38 of @xmath39 . for a comprehensive account of random matrix theory",
    "we refer the reader to @xcite , and the references therein .",
    "our aim in this paper is to obtain a marchenko  pastur type result in the case where there is dependence within the rows of @xmath12 .",
    "more precisely , for @xmath0 , the @xmath40th row of @xmath12 is given by a linear process of the form @xmath41 here , @xmath42 is an array of independent random variables that satisfies @xmath43 as well as the lindebergtype condition that , for each @xmath44 , @xmath45 clearly , [ z2 ] is satisfied if all @xmath2 are identically distributed .",
    "the novelty of our result is that we allow for dependence within the rows , and that the equation for @xmath46 is given in terms of the spectral density @xmath47,\\ ] ] of the linear processes @xmath48 only , which is the fourier transform of the autocovariance function @xmath49 potential applications arise whenever data is not independent in time such that the marchenko  pastur law is not a good approximation .",
    "this includes e.g.  wireless communications @xcite and mathematical finance @xcite .",
    "note that a similar question is also discussed in @xcite .",
    "however , they have a different proof which relies on a moment condition to be verified .",
    "furthermore , they assume that the random variables @xmath2 are identically distributed so that the processes within the rows are independent copies of each other .",
    "more importantly , their results do not yield concrete formulas except in the ar(1 ) case and are therefore not directly applicable . in the context of free probability theory , the limiting spectral distribution of large sample covariance matrices of gaussian arma processes is investigated in @xcite .",
    "before we present the main result of this article , we explain the notation used in this article .",
    "the symbols @xmath50 , @xmath51 @xmath34 , and @xmath52 denote the sets of integers , natural , real , and complex numbers , respectively . for a matrix @xmath17",
    ", we write @xmath53 for its transpose and @xmath54 for its trace .",
    "finally , the indicator of an expression @xmath55 is denoted by @xmath56 and defined to be one if @xmath55 is true , and zero otherwise ; for a set @xmath57 , we also write @xmath58 instead of @xmath59 .",
    "[ maintheorem ] for each @xmath60 , let @xmath61 , @xmath62 , be a linear stochastic process with continuously differentiable spectral density @xmath63 .",
    "assume that    a.   [ maintheoremconditionsz ] the array @xmath42 satisfies conditions , b.   [ maintheoremconditionsc ] there exist positive constants @xmath64 and @xmath65 such that @xmath66 for all @xmath67 , c.   [ maintheoremconditionsflevelsets ] for almost all @xmath68 , @xmath69 for at most finitely many @xmath70 $ ] , and d.   [ maintheoremconditionsdfzero ] @xmath71 for almost every @xmath72 .",
    "then the empirical spectral distribution @xmath73 of @xmath6 converges , as @xmath3 tends to infinity , almost surely to a nonrandom probability distribution @xmath29 with bounded support .",
    "moreover , there exist positive numbers @xmath74 such that the stieltjes transform @xmath75 of @xmath39 is the unique mapping @xmath76 satisfying @xmath77:f(\\omega)=\\lambda } \\frac{1}{\\left|f'(\\omega)\\right| } { \\mathrm{d}}\\lambda}.\\ ] ]    the assumptions of the theorem are met , for instance , if @xmath78 is an arma or fractionally integrated arma process ; see [ examples ] for details .    , as it stands , does not contain the classical marchenko  pastur law as a special case . for if the entries @xmath79 of the matrix @xmath12 are i.i.d . , the corresponding spectral density @xmath63 is identically equal to the variance of @xmath80 , and thus condition is not satisfied .",
    "we therefore also present a version of [ maintheorem ] that holds if the rows of the matrix @xmath12 have a piecewise constant spectral density .",
    "[ maintheorempiecewise ] for each @xmath60 , let @xmath61 , @xmath62 , be a linear stochastic process with spectral density @xmath63 of the form @xmath81\\to{\\mathbb{r}}^+,\\quad",
    "\\omega \\mapsto \\sum_{j=1}^k{\\alpha_j { \\mathbf{1}}_{a_j}(\\omega)},\\quad k\\in{\\mathbb{n}},\\ ] ] for some positive real numbers @xmath82 and a measurable partition @xmath83 of the interval @xmath84 $ ] .",
    "if conditions of [ maintheorem ] hold , then the empirical spectral distribution @xmath73 of @xmath6 converges , as @xmath28 , almost surely to a nonrandom probability distribution @xmath29 with bounded support .",
    "moreover , the stieltjes transform @xmath75 of @xmath39 is the unique mapping @xmath76 that satisfies @xmath85 where @xmath86 denotes the lebesgue measure of the set @xmath87 .",
    "in particular , if the entries of @xmath12 are i.i.d .  with unit variance ,",
    "one recovers the limiting spectral distribution of the marchenko  pastur law .    in applications",
    "one often considers processes of the form @xmath88 with mean @xmath89 .",
    "if we denote by @xmath90 the @xmath91th column of the matrix @xmath12 , and define the empirical mean by @xmath92 , then the sample covariance matrix is given by the expression @xmath93 instead of @xmath6 .",
    "however , by ( * ? ? ?",
    "* theorem a.44 ) , the subtraction of the empirical mean does not change the lsd , and thus [ maintheorem , maintheorempiecewise ] remain valid if the underlying linear process has a nonzero mean .",
    "the proof of [ maintheorem , maintheorempiecewise ] can easily be generalized to cover noncausal linear processes , which are defined as @xmath94 . for this case one",
    "obtains the same result except that the autocovariance function is now given by @xmath95 .",
    "if one considers a matrix @xmath12 which has independent linear processes in its columns instead of its rows , one obtains the same formulas as in [ maintheorem , maintheorempiecewise ] except that @xmath7 is replaced by @xmath96 .",
    "this is due to the fact that @xmath97 and @xmath98 have the same nontrivial eigenvalues .    in [ proofs ]",
    "we proceed with the proofs of [ maintheorem , maintheorempiecewise ] .",
    "thereafter we present some interesting examples in [ examples ] .",
    "in this section we present our proofs of [ maintheorem , maintheorempiecewise ] . dealing with infiniteorder moving average processes",
    "directly is dfficult , and we therefore first prove a variant of these theorems for the truncated processes @xmath99 .",
    "we define the @xmath100 matrix @xmath101 , @xmath0 , @xmath11 .",
    "[ maintheoremmod ] under the assumptions of [ maintheorem ] ( [ maintheorempiecewise ] ) , the empirical spectral distribution of the sample covariance matrix of the truncated process @xmath102 converges , as @xmath3 tends to infinity , to a deterministic distribution with bounded support .",
    "its stieltjes transform is uniquely determined by [ eq - stieltjes ] ( [ eq - stieltjespiecewise ] ) .",
    "the proof starts from the observation that one can write @xmath103 , where @xmath104 , @xmath0 , @xmath105 , and @xmath106 in particular , @xmath107 . in order to prove convergence of the empirical spectral distribution @xmath108 and to obtain a characterization of the limiting distribution",
    ", it suffices , by ( * ? ? ?",
    "* theorem 1 ) , to prove that the spectral distribution @xmath109 of @xmath110 converges to a nontrivial limiting distribution .",
    "this will be done in [ lemma - lsdhh ] , where the lsd of @xmath110 is shown to be @xmath111 ; the distribution @xmath112 is computed in [ lemma - densitygamma ] if we impose the assumptions of [ maintheorem ] , respectively in [ lemma - densitygammapiecewise ] if we impose the assumptions of [ maintheorempiecewise ] . inserting",
    "this expression for @xmath113 into equation ( 1.2 ) of @xcite shows that the esd @xmath108 converges , as @xmath28 , almost surely to a deterministic distribution , which is determined by the requirement that its stieltjes transform @xmath114 satisfies @xmath115 using the explicit formulas of @xmath112 computed in [ lemma - densitygamma , lemma - densitygammapiecewise ] , one obtains [ eq - stieltjes , eq - stieltjespiecewise ] .",
    "uniqueness of a mapping @xmath116 solving [ eq - stieltjescharacgamma ] was shown in @xcite .",
    "we complete the proof by arguing that the lsd of @xmath117 has bounded support .",
    "for this it is enough , by ( * ? ? ?",
    "* theorem 6.3 ) , to show that the spectral norm of @xmath110 is bounded in @xmath3 , which is also done in [ lemma - lsdhh ] .",
    "[ lemma - lsdhh ] let @xmath118 be the matrix appearing in [ eq - defh ] , and assume that there exist positive constants @xmath119 such that @xmath66 ( assumption of [ maintheorem ] ) . then the spectral norm of the matrix @xmath110 is bounded in @xmath3 . if , moreover , the spectral distribution of the toeplitz matrix @xmath120 converges weakly to some limiting distribution @xmath121 , then the spectral distribution @xmath109 converges weakly , as @xmath28 , to @xmath122 .",
    "we first introduce the notation @xmath123 as well as the block decomposition @xmath124 $ ] , @xmath125 .",
    "we prove the second part of the lemma first .",
    "there are several ways to show that the spectral distributions of two sequences of matrices converge to the same limit . in our case",
    "it is convenient to use ( * ? ? ?",
    "* corollary a.41 ) which states that two sequences @xmath126 and @xmath127 , either of whose empirical spectral distribution converges , have the same limiting spectral distribution if @xmath128 converges to zero as @xmath3 tends to infinity",
    ". we shall employ this result twice : first to show that the lsds of @xmath129 and @xmath130 agree , and then to prove equality of the lsds of @xmath131 and @xmath132 .",
    "let @xmath133 ; a direct calculation shows that @xmath134 $ ] , and we will consider each of the two terms in turn . from the definition of @xmath135 it follows that the @xmath136th entry of @xmath137 is given by @xmath138 .",
    "the trace of the square of the upper left block of @xmath137 therefore satisfies @xmath139 ^ 2\\\\    { \\leqslant } & \\sum_{i , j , k , l=1}^n{|c_{i+k-1}||c_{j+k-1}||c_{i+l-1}||c_{j+l-1}|}\\\\    { \\leqslant } & c^4 \\sum_{i , j , k , l=2}^{n+1}{i^{-1-\\delta}j^{-1-\\delta}l^{-1-\\delta}k^{-1-\\delta}}\\\\      < & \\left[c\\zeta(1+\\delta)\\right]^4<\\infty,\\end{aligned}\\ ] ] where @xmath140 denotes the riemann zeta function . as a consequence , the limit of @xmath141 as @xmath3 tends to infinity is zero .",
    "similarly , we obtain for the trace of the square of the off - diagonal block of @xmath137 the bound @xmath142 ^ 2\\\\    { \\leqslant } & \\sum_{i=1}^n\\sum_{j=1}^{n}\\sum_{k = j}^{n - i+1}\\sum_{l = j}^{n - i+1}{c_{i+k-1}c_{k - j}c_{i+l-1}c_{l - j}}\\\\    { \\leqslant } & \\sum_{i=1}^n\\sum_{j=1}^n\\sum_{r=0}^n\\sum_{s=0}^n{|c_{i+r+j-1}||c_r||c_{s+j-1}||c_s|}\\\\    { \\leqslant } & c^4 \\sum_{i , j , r , s=1}^{n+1 } { i^{-1-\\delta } r^{-1-\\delta } s^{-1-\\delta } j^{-1-\\delta}}\\\\    < & \\left[c\\zeta(1+\\delta)\\right]^4<\\infty,\\end{aligned}\\ ] ] which shows that the limit of @xmath143 is zero .",
    "it follows that @xmath144 , as defined in [ eq - deltahh ] , converges to zero as @xmath3 goes to infinity , and therefore that the lsds of @xmath137 and @xmath145 coincide .",
    "the latter distribution is clearly given by @xmath146 , and we show next that the lsd of @xmath131 agrees with the lsd of @xmath120 . as before it suffices to show , by ( * ? ? ?",
    "* corollary a.41 ) , that @xmath147 converges to zero as @xmath3 tends to infinity .",
    "it follows from the definitions of @xmath137 and @xmath132 that @xmath148 can be estimated as @xmath149 ^ 2\\\\    = &   \\sum_{i , j=1}^n\\left[\\sum_{k=\\max{(i , j)}}^n{c_{k - i}c_{k - j}}-\\sum_{k=\\max{(i",
    ", j)}}^\\infty{c_{k - i}c_{k - j}}\\right]^2\\\\    = & \\sum_{i , j=1}^n\\sum_{k , l=1}^\\infty{c_{k+i-1}c_{k+j-1}c_{l+i-1}c_{l+j-1}}\\\\    { \\leqslant } & c^4\\sum_{i , j=2}^{n+1}\\sum_{k , l=2}^\\infty{i^{-1-\\delta}j^{-1-\\delta}k^{-1-\\delta}l^{-1-\\delta } } < \\left[c\\zeta(1+\\delta)\\right]^4<\\infty.\\end{aligned}\\ ] ] consequently , @xmath150 converges to zero as @xmath3 goes to infinity , and it follows that @xmath151 .    in order to show that the spectral norm of @xmath129 is bounded in @xmath3 , we use gerschgorin s circle theorem ( ( * ? ? ?",
    "* theorem 2 ) ) , which states that every eigenvalue of @xmath137 lies in at least one of the balls @xmath152 with centre @xmath153 and radius @xmath154 , @xmath155 , where the radii @xmath154 are defined as @xmath156 .",
    "we first note that the centres @xmath157 satisfy @xmath158 ^ 2<\\infty.\\ ] ] to obtain a uniform bound for the radii @xmath154 we first assume that @xmath159 . then @xmath160 ^ 2<\\infty.\\end{aligned}\\ ] ] similarly we find that , for @xmath161 , @xmath162 ^ 2\\end{aligned}\\ ] ] is bounded , which completes the proof .    in the following two lemmas",
    ", we argue that the distribution @xmath112 exists and we prove explicit formulas for it in the case that the assumptions of [ maintheorem ] or [ maintheorempiecewise ] are satisfied .",
    "[ lemma - densitygamma ] let @xmath163 be a sequence of real numbers , @xmath164 , and @xmath165 . under the assumptions of [ maintheorem ] it holds that the spectral distribution @xmath166 of @xmath120 converges weakly , as @xmath28 , to an absolutely continuous distribution @xmath112 with",
    "bounded support and density @xmath167    we first note that under assumption of [ maintheorem ] the autocovariance function @xmath168 is absolutely summable because @xmath169 ^ 2<\\infty.\\ ] ] szeg s first convergence theorem ( @xcite and ( * ? ? ?",
    "* corollary 4.1 ) ) then implies that @xmath112 exists , and that the cumulative distribution function of the eigenvalues of the toeplitz matrix @xmath132 associated with the sequence @xmath170 is given by @xmath171:f(\\omega){\\leqslant}\\lambda\\}),\\ ] ] for all @xmath172 such that the level sets @xmath173:f(\\omega)=\\lambda\\}$ ] have lebesgue measure zero . by assumption of [ maintheorem ] , [ eq - cdfgamma ]",
    "holds for almost all @xmath172 . in order to prove that the lsd @xmath121 is absolutely continuous with respect to the lebesgue measure , it suffices to prove that the cumulative distribution function @xmath174 is differentiable almost everywhere .",
    "clearly , for @xmath175 , @xmath176:\\lambda < f(\\omega){\\leqslant}\\lambda+\\delta\\lambda\\}).\\ ] ] due to assumption of [ maintheorem ] , the set of all @xmath68 such that the set @xmath177:f(\\omega)=\\lambda \\textnormal { and } f'(\\omega)=0\\}$ ] is nonempty is a lebesgue null - set .",
    "hence it is enough to consider only @xmath172 for which this set is empty .",
    "let @xmath178 be the preimage of @xmath172 , which is a finite set by assumption .",
    "the implicit function theorem then asserts that , for every @xmath179 , there exists an open interval @xmath180 around @xmath72 such that @xmath63 restricted to @xmath180 is invertible .",
    "it is no restriction to assume that these @xmath180 are disjoint . by choosing @xmath181 sufficiently small",
    "it can be ensured that the interval @xmath182 $ ] is contained in @xmath183 , and from the continuity of @xmath63 it follows that outside of @xmath184 , the values of @xmath63 are bounded away from @xmath172 , so that @xmath185\\\\ = & \\frac{1}{2\\pi}\\lim_{\\delta\\lambda\\to 0}\\frac{1}{\\delta\\lambda}{\\operatorname{leb}}\\left(\\bigcup_{\\omega\\in f^{-1}(\\lambda)}\\{\\omega'\\in i_\\omega : \\lambda <",
    "f(\\omega'){\\leqslant}\\lambda+\\delta\\lambda\\}\\right)\\\\    = & \\frac{1}{2\\pi}\\sum_{\\omega\\in f^{-1}(\\lambda)}\\lim_{\\delta\\lambda\\to 0}\\frac{1}{\\delta\\lambda}{\\operatorname{leb}}\\left(\\{\\omega'\\in i_\\omega : \\lambda < f(\\omega'){\\leqslant}\\lambda+\\delta\\lambda\\}\\right).\\end{aligned}\\ ] ] in order to further simplify this expression , we denote the local inverse functions by @xmath186 $ ] .",
    "observing that the lebesgue measure of an interval is given by its length , and that the derivatives of @xmath187 are given by the inverse of the derivative of @xmath63 , it follows that @xmath188 = & \\frac{1}{2\\pi}\\sum_{\\omega\\in f^{-1}(\\lambda)}\\lim_{\\delta\\lambda\\to 0}\\frac{1}{\\delta\\lambda}\\left|f_\\omega^{-1}(\\lambda+\\delta\\lambda)-f_\\omega^{-1}(\\lambda)\\right|\\\\    = & \\frac{1}{2\\pi}\\sum_{\\omega\\in f^{-1}(\\lambda)}\\left|\\frac{{\\mathrm{d}}}{{\\mathrm{d}}\\lambda}f_\\omega^{-1}(\\lambda)\\right|\\\\    = & \\frac{1}{2\\pi}\\sum_{\\omega\\in f^{-1}(\\lambda)}\\frac{1}{\\left|f'(\\omega)\\right|}.\\end{aligned}\\ ] ] this shows that @xmath174 is differentiable almost everywhere with derivative @xmath189 .",
    "it remains to argue that the support of @xmath112 is bounded .",
    "the absolute summability of @xmath190 implies boundedness of its fourier transform @xmath63 .",
    "the claim then follows from [ eq - cdfgamma ] , which shows that the support of @xmath191 is equal to the range of @xmath63 .",
    "[ lemma - densitygammapiecewise ] let @xmath192 be the piecewise constant spectral density of the linear process @xmath193 , and denote the corresponding autocovariance function by @xmath194 . under the assumptions of [ maintheorempiecewise ] it holds that the spectral distribution @xmath166 of @xmath120 converges weakly , as @xmath28 , to the distribution @xmath195 .",
    "without loss of generality we may assume that @xmath196 .",
    "as in the proof of [ lemma - densitygamma ] one sees that @xmath112 exists , and that @xmath197 is given by @xmath198:f(\\omega){\\leqslant}\\lambda\\}),\\quad\\forall \\lambda\\in[0,2\\pi]\\backslash \\bigcup_{j=1}^k \\{\\alpha_j\\}.\\ ] ] the special structure of @xmath63 thus implies that @xmath199 , where @xmath200 is the largest integer such that @xmath201 .",
    "since @xmath174 must be rightcontinuous , this formula holds for all @xmath172 in the interval @xmath84 $ ] .",
    "it is easy to see that the function @xmath174 is the cumulative distribution function of the discrete measure @xmath202 , which completes the proof .    of theorems",
    "and it is only left to show that the truncation performed in [ maintheoremmod ] does not alter the lsd , i.e.  that the difference of @xmath73 and @xmath203 converges to zero almost surely . by (",
    "* corollary a.42 ) , this means that we have to show that @xmath204 converges to zero . to this end",
    "we show that @xmath205 has a limit , and that @xmath206 converges to zero , both almost surely . by the definition of @xmath12 and @xmath207 we have @xmath208 we shall prove that the variances of @xmath206 are summable . for this purpose",
    "we need the following two estimates which are implied by the cauchy ",
    "schwarz inequality , the assumption that @xmath209 is finite , and the assumed absolute summability of the coefficients @xmath163 :    [ eq - fubini ] @xmath210 @xmath211    therefore we can , by fubini s theorem , interchange expectation and summation to bound the variance of @xmath206 as @xmath212 considering separately the terms where @xmath213 and @xmath214 , we can write @xmath215 for the expectation in the first sum not to be zero , @xmath216 must equal @xmath217 and @xmath218 must equal @xmath219 , in which case its value is unity .",
    "the expectation in the second term can always be bounded by @xmath220 , so that we obtain @xmath221 due to [ npy ] and the assumed polynomial decay of @xmath222 there exists a constant @xmath223 such that the right hand side is bounded by @xmath224 , which implies that @xmath225 and therefore , by the first borel ",
    "cantelli lemma , that @xmath206 converges to a constant almost surely .",
    "in order to show that this constant is zero , it suffices to shows that the expectation of @xmath206 converges to zero . since @xmath226 , and",
    "the @xmath2 are independent , one sees , using [ eq - fubini1 ] and again fubini s theorem , that @xmath227 , which converges to zero because the @xmath228 are squaresummable .",
    "we now consider factor @xmath205 of expression and define @xmath229 .",
    "then @xmath230 because of @xmath231 and similarly @xmath232 , we have that @xmath233\\notag\\\\   = & { \\underbrace}{\\sum_{i=1}^p \\sum_{t=1}^n \\sum_{k = n+1}^\\infty \\sum_{m = n+1}^\\infty c_k c_m z_{i , t - k } z_{i , t - m}}_{={\\mathrm{ii}}\\to 0\\text { a.s.}}\\notag\\\\ \\label{eq - trdelta }   & + 2\\sum_{i=1}^p \\sum_{t=1}^n \\sum_{k = n+1}^\\infty \\sum_{m=1}^n c_k c_m z_{i , t - k } z_{i , t - m}.\\end{aligned}\\ ] ] allows us to apply fubini s theorem to compute the variance of the second term in the previous display as @xmath234 which is , by the same reasoning as we did for @xmath206 , bounded by @xmath235 for some positive constant @xmath223 . clearly , this is summable in @xmath3 .",
    "having , by [ eq - fubini1 ] , expected value zero , the second term of [ eq - trdelta ] and , therefore , also @xmath236 both converge to zero almost surely .",
    "thus , we only have to look at the contribution of @xmath237 in expression . from [ maintheoremmod ] we know that @xmath203 converges almost surely weakly to some nonrandom distribution @xmath39 with bounded support",
    "hence , denoting by @xmath18 the eigenvalues of @xmath238 , @xmath239 almost surely .",
    "it follows that , in [ eq - iandii ] , factor @xmath205 is bounded , and factor @xmath206 converges to zero , and so the proof of [ maintheorem , maintheorempiecewise ] is complete .",
    "for several classes of widely employed linear processes , [ maintheorem ] can be used to obtain an explicit description of the limiting spectral distribution . in this section",
    "we consider the class of autoregressive moving average ( arma ) processes as well as fractionally integrated arma models .",
    "the distributions we obtain in the case of ar(1 ) and ma(1 ) processes can be interpreted as oneparameter deformations of the classical marchenko  pastur law .",
    "given polynomials @xmath240 and @xmath241 , an arma(p , q ) process @xmath242 with autoregressive polynomial @xmath243 and moving average polynomial @xmath244 is defined as the stationary solution to the stochastic difference equation @xmath245 if the zeros of @xmath243 lie outside the closed unit disk , it is well known that @xmath242 has an infiniteorder moving average representation @xmath193 , where @xmath246 are the coefficients in the power series expansion of @xmath247 around zero .",
    "it is also known ( @xcite ) that there exist positive constants @xmath248 and @xmath223 such that @xmath249 , so that assumption of [ maintheorem ] is satisfied .",
    "while the autocovariance function of a general arma process does not in general have a simple closed form , its fourier transform is given by @xmath250.\\ ] ] since @xmath63 is rational , assumptions of [ maintheorem ] are satisfied as well . in order to compute the lsd of @xmath132 ,",
    "it is necessary , by [ lemma - densitygamma ] , to find the roots of a trigonometric polynomial of possibly high degree , which can be done numerically .",
    "we now consider the special case of the arma(1,1 ) process @xmath251 , @xmath252 , for which one can obtain explicit results . by [ eq - specdensarma ]",
    ", the spectral density of x is given by @xmath253.\\ ] ] implies that the lsd of the autocovariance matrix @xmath132 has a density @xmath191 , which is given by @xmath254:f(\\omega)=\\lambda } \\frac{1}{\\left|f'(\\omega)\\right|}\\\\    = & \\frac{1}{\\pi(\\vartheta+\\varphi\\lambda)\\sqrt{\\left[(1+\\vartheta)^2-\\lambda(1-\\varphi)^2\\right]\\left[\\lambda(1+\\varphi)^2-(1-\\vartheta)^2\\right]}}{\\mathbf{1}}_{(\\lambda_-,\\lambda_+)}(\\lambda),\\end{aligned}\\ ] ] where @xmath255 by [ maintheorem ] , the stieltjes transform @xmath256 of the limiting spectral distribution of @xmath6 is the unique mapping @xmath116 that satisfies the equation @xmath257\\left[(1+\\varphi)^2+m_z(1-\\vartheta)^2\\right]}}.\\notag\\end{aligned}\\ ] ] this is a quartic equation in @xmath258 which can be solved explicitly .",
    "an application of the stieltjes inversion formula then yields the limiting spectral distribution of @xmath6 .",
    "if one sets @xmath259 , one obtains an ma(1 ) process ; plots of the densities obtained in this case for different values of @xmath260 and @xmath7 are displayed in [ fig - densitiesma1 ] .",
    "similarly , the case @xmath261 corresponds to an ar(1 ) process ; see [ fig - densitiesar1 ] for a graphical representation of the densities one obtains for different values of @xmath262 and @xmath7 in this case .",
    "for the special case @xmath263 , @xmath264 , [ fig - histoarma11 ] compares the histogram of the eigenvalues of @xmath6 with the limiting spectral distribution obtained from [ maintheorem ] for different values of @xmath7 .    for the stieltjes transform of the limiting spectral distribution of the sample covariance matrix of an arma(1,1 ) process",
    "should be compared to ( * ? ? ?",
    "* eq . ( 2.10 ) ) , where the analogous result is obtained for an autoregressive process of order one .",
    "they use the notation @xmath265 and consider the spectral distribution of @xmath266 instead of @xmath6 . if one observes that this difference in the normalization amounts to a linear transformation of the corresponding stieltjes transform , one obtains their result as a special case of [ eq - stieltjesarma11 ] .      in many practical situations , data exhibit longrange dependence , which can be modelled by longmemory processes .",
    "denote by @xmath267 the backshift operator and define , for @xmath268 , the ( fractional ) difference operator by @xmath269 a process @xmath270 is called a fractionally integrated arma(p , d , q ) processes with @xmath271 and @xmath272 if @xmath273 is an arma(p , q ) process .",
    "these processes have a polynomially decaying autocorrelation function and therefore exhibit longrangedependence , cf .",
    "* theorem 13.2.2 ) and @xcite .",
    "we assume that @xmath274 , and that the zeros of the autoregressive polynomial @xmath243 of @xmath273 lie outside the closed unit disk .",
    "then it follows that @xmath242 has an infiniteorder moving average representation @xmath193 , where the @xmath163 have , in contrast to our previous examples , not an exponential decay , but satisfy @xmath275 , for some @xmath276 .",
    "therefore , if @xmath274 , one can apply [ maintheorem ] to obtain the lsd of the sample covariance matrix , using that the spectral density of @xmath270 is given by @xmath277.\\ ] ]      both authors gratefully acknowledge financial support from technische universitt mnchen - institute for advanced study funded by the german excellence initiative , and from the international graduate school of science and engineering ."
  ],
  "abstract_text": [
    "<S> we derive the distribution of the eigenvalues of a large sample covariance matrix when the data is dependent in time . </S>",
    "<S> more precisely , the dependence for each variable @xmath0 is modelled as a linear process @xmath1 , where @xmath2 are assumed to be independent random variables with finite fourth moments . if the sample size @xmath3 and the number of variables @xmath4 both converge to infinity such that @xmath5 , then the empirical spectral distribution of @xmath6 converges to a nonrandom distribution which only depends on @xmath7 and the spectral density of @xmath8 . in particular , </S>",
    "<S> our results apply to ( fractionally integrated ) arma processes , which we illustrate by some examples . </S>"
  ]
}