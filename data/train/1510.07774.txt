{
  "article_text": [
    "in techniques for speech enhancement , many a times the noise is assumed to be stationary with a known distribution .",
    "however , in a real world scenario , the noise may be non - stationary or speech may be corrupted with different kinds of noises .",
    "the nature of noise varies with the environment such as traffic , restaurant , railway and bus station .",
    "even competing speakers and music may impair intelligibility of speech . in the case of speech enhancement @xcite and noise source separation , especially for hearing impaired @xcite the suppression of background audio for improving the intelligibility of speech",
    "would be more effective , if the type of audio source can be classified .",
    "other interesting application areas are forensics @xcite , machinery noise diagnostics @xcite , robotic navigation systems @xcite and acoustic signature classification of aircrafts or vehicles @xcite .",
    "this paper addresses the basic problem of classification of the type of audio from a finite set of sources , mostly noise and a couple of musical instruments .",
    "noise classification can be seen as a first step in machine listening @xcite , which enables the system to know the background environment .",
    "classification of noise types has been reported in the case of pure noise sources .",
    "kates @xcite addressed the problem of noise classification for hearing aid applications based on variation of signal envelope as features .",
    "maleh et al .",
    "@xcite used line spectral frequencies as features for classification of different kinds of noise as well as noise and speech classification .",
    "casey @xcite proposed a system to classify twenty different types of sounds using a hidden markov model classifier and a reduced - dimension log - spectral features .",
    "chu et al .",
    "@xcite recognized 14 different environmental sounds using matching pursuit based features combined with mel - frequency cepstrum coefficients .",
    "giannoulis et al .",
    "@xcite conducted a public evaluation challenge on acoustic scene classification ( similar to noise classification ) , where 11 algorithms were evaluated along with a baseline system .",
    "the algorithms use time and frequency domain features extracted from the audio signal followed by a statistical model based or majority vote based classifier .",
    "cauchi @xcite used non - negative matrix factorization for classification of auditory scenes .",
    "representation of audio signals as a linear combination of non - negative sparse vectors called as dictionary atoms has been used for audio source separation @xcite , recognition @xcite , classification @xcite and coding @xcite . in this work ,",
    "we only address the problem of audio classification of pure noise sources using sparse non - negative representation of audio by proposing a novel dictionary learning and a source recovery method .",
    "however , audio classification also works in a mixed audio signal , where segments have higher noise energy than speech .",
    "a dictionary is a matrix @xmath0 ( with @xmath1 as the dimension of the acoustic feature vector ) containing @xmath2 column vectors called atoms , denoted as @xmath3 .",
    "a feature for any real valued signal can be represented as @xmath4 , where @xmath5 is the vector containing weights for each dictionary atom .",
    "the vector @xmath6 is estimated by minimizing the distance @xmath7 , where @xmath8 is a distance metric between @xmath9 and @xmath10 such as @xmath11 norm or kullback - leibler ( kl)-divergence @xcite . in case",
    "the dictionary @xmath12 is overcomplete , the weight vector @xmath13 tends to be sparse .",
    "this method of estimating weights is termed as sparse coding or source recovery .",
    "matching pursuit @xcite , orthogonal matching pursuit ( omp ) @xcite , basis pursuit @xcite and focal underdetermined system solver ( focuss ) @xcite are some of the source recovery algorithms .",
    "the simplest dictionary learning ( dl ) method is a random selection of observations from the training data @xcite .",
    "k - means clustering @xcite has also been used for dl . the relation between vector quantization and dl",
    "was shown by @xcite .",
    "initial work on dl was carried out by olshausen @xcite and lewicki @xcite using probabilistic model of the features .",
    "engal et al .",
    "@xcite performed dl using a simple dictionary update ( minimization of mean square error of the error matrix ) and sparse coding using omp or focuss .",
    "recursive least squares dictionary learning ( rls - dla ) @xcite , k - svd @xcite , simultaneous codeword optimisation ( simco ) @xcite and fast dictionary learning @xcite are other algorithms . dl and source recovery methods have been used for classification of objects in images by learning class - specific dictionaries @xcite .",
    "shafiee et al .",
    "@xcite have used three different dl methods to classify faces and digits in images .    in our work , we have adopted the recently reported active - set newton algorithm ( asna)@xcite for source recovery .",
    "the training phase for the audio classification problem is dl from various noise / instrument sources .",
    "the advantage of this approach is that the audio sources need not be stationary , since the dictionary atoms capture the variation in the spectral characteristics .",
    "the main contributions and the novelty of the paper are :    * using distinct dictionaries with each dictionary representing an audio source as well as a concatenated dictionary . * dictionary learning by using thresholds on the cosine similarity to ensure distinction amongst the atoms of the same as well as different source dictionaries . * proposing two new objective measures , namely , the number of non - zero weights and the sum of weights , for selecting the most likely audio source from a given set .",
    "given a test audio signal @xmath14 $ ] , we need to identify the signal as belonging to one of the noise or instrument sources .",
    "we train @xmath15 dictionaries for the @xmath15 different sources and the test audio signal is classified as that source which has the highest value for an objective measure .",
    "similar to most of the audio source separation approaches @xcite , the magnitude of short - time fourier transform ( mag .",
    "stft ) has been used as the feature vector , which is always non - negative .",
    "feature vectors are @xmath16 normalized for dictionary learning .",
    "a test feature vector can be represented as additive , non - negative , linear combination of dictionary atoms .",
    "each dictionary atom is selected to be as uncorrelated as possible from the rest of the atoms belonging to the same as well as other sources .",
    "the correlation between a pair of atoms @xmath17 is measured using the cosine similarity as :    @xmath18    two types of cosine similarity measures are used : ( a ) intra - class cosine similarity ( intra - cs ) is defined as @xmath19 where @xmath20 is the dictionary for a specific source ; and ( b ) inter - class cosine similarity ( inter - cs ) defined as @xmath21 .",
    "dictionary atoms for each source are learnt such that the cosine similarity between the atoms is below a set threshold , chosen based on the desired performance .",
    "a randomly selected feature vector , denoted as @xmath22 is taken as the first atom for the first source , @xmath23 .",
    "the rest of the atoms are learnt by random selection of the feature vectors ( excluding features already selected as atoms ) : @xmath24 feature , @xmath25 , is selected as the @xmath26 atom , @xmath27 of dictionary @xmath28 if maximum of intra - cs , @xmath29 ( similar to coherence in @xcite ) is less than a threshold @xmath30 .",
    "the selection of dictionary atoms is stopped once the number of dictionary atoms reaches a pre - determined number @xmath31 . in case @xmath31 atoms are not obtained , additional mag .",
    "stft features , which do not satisfy the intra - class threshold @xmath32 are appended in the order of increasing @xmath33 .    for learning dictionaries for subsequent sources",
    ", atoms are learnt using an additional constraint : @xmath25 is selected as the @xmath26 atom @xmath34 for the @xmath35 dictionary @xmath20 , if @xmath36 is less than a threshold @xmath37 .",
    "the threshold @xmath30 ensures that the atoms within the same source dictionary are as uncorrelated as possible , while @xmath38 ensures that atoms from different source dictionaries are maximally uncorrelated .",
    "lower the values of the thresholds @xmath30 and @xmath38 , greater is the uncorrelatedness amongst the dictionary atoms .",
    "the proposed source classification method has been evaluated using ten different noise sources taken from noisex database @xcite and two other instrument sources , one recorded by us and the other , downloaded from an open source portal @xcite .",
    "the total number of atoms in @xmath12 from the 12 sources is 1200 using @xmath39 and @xmath40 . for the sake of illustration , fig .",
    "[ atomsnois ] shows the plots of the first three atoms of babble noise learnt for @xmath41 .",
    "the proposed dl is summarized in algorithm [ dictalgo ] . for the sake of simplicity",
    ", the algorithm does not show the appending of additional dictionary atoms when @xmath31 atoms could not be obtained .",
    "+    dictionary learning[dictalgo ]    * initialize : * dictionary index @xmath42 ; @xmath43 ; atom index @xmath44 ; set @xmath30 and @xmath38 .",
    "extract @xmath45 number of mag.stft features denoted as @xmath46 from the @xmath47 audio source .",
    "if @xmath48 , find the maximum of intra - cs , @xmath49 as :    @xmath50    if @xmath51 , find the maximum of inter - cs , @xmath52 as :    @xmath53 assign randomly selected @xmath25 as the @xmath26 atom : @xmath54 and append to the dictionary : @xmath55 $ ] @xmath56    @xmath57 ; @xmath58     ]      the learnt dictionaries are used to extract measures for identifying the source .",
    "given an unknown audio signal , the mag .",
    "stft features are extracted , which are used to solve a minimization using asna @xcite :    @xmath59    where @xmath60 is the kl divergence between two vectors , @xmath61 is the extracted feature , @xmath62 is the approximation of @xmath9 , @xmath63 is the dictionary using which @xmath9 is approximated and @xmath6 is the weight vector estimated using asna .    since we know the dictionaries for all the sources , we estimate three measures for classification :    1 .   _ signal to distortion ratio _ ( sdr ) @xcite between @xmath9 and @xmath64 for the @xmath15 dictionaries .",
    "the sdr with respect to each dictionary @xmath65 is defined as : @xmath66 + a feature @xmath9 belonging to the @xmath47 source can be approximated to a good accuracy by atoms belonging to @xmath20 , since @xmath20 has been learnt by threshold based selection of atoms from the same source .",
    "so , @xmath67 is expected to be minimum for the @xmath47 source , since @xmath9 may not be approximated well by atoms from the dictionaries of other sources .",
    "thus , the @xmath68 is expected to be maximum for the @xmath47 dictionary . the estimated source index @xmath69 for the feature vector of each frame of the test signal is given as @xmath70 .",
    "we propose a new measure , _ number of non - zero weights _",
    "( nnz ) belonging to a particular source in the weight vector @xmath6 recovered using a dictionary @xmath63 , obtained by concatenating dictionaries from all the @xmath15 individual sources : @xmath71 $ ] .",
    "the vector @xmath72'$ ] obtained by using asna on ( [ asna ] ) is a concatenation of individual weight vectors @xmath73 of @xmath15 sources , which is expected to be sparse . +",
    "a test feature @xmath9 belonging to the @xmath47 source can be represented better by atoms from the @xmath47 dictionary than by atoms from other dictionaries . since @xmath12 contains atoms from all the sources ,",
    "the number of non - zero weights , @xmath74 corresponding to the original dictionary @xmath20 , which is now a sub - matrix of @xmath12 , may be expected to be higher than @xmath75 .",
    "the estimated source index @xmath76 for the test feature @xmath9 is given by @xmath77 .",
    "+ the weight vector @xmath6 is sparse for the dictionary @xmath12 , as shown in fig .",
    "[ weignosum](a ) .",
    "the number of non - zero weights for each source dictionary is illustrated in fig .",
    "[ weignosum](b ) . for a test frame of babble noise",
    ", the highest nnz is 17 corresponding to babble noise dictionary ( atom indices 700 to 800 in @xmath12 ) , while 9 is the next highest for the veena dictionary , a margin of 8 or a factor of 2 , for correct classification is obtained .",
    "sum of weights _ ( sw ) is another scalar measure proposed , defined as the sum of the elements of the vector @xmath78 , which is recovered using the same concatenated dictionary , @xmath63 . in case",
    "the weights are non - sparse , it is observed that @xmath79 is more reliable than @xmath80 .",
    "figure [ weignosum](b ) also illustrates the distribution of sw for each of the dictionaries .",
    "@xmath81 gives the estimated source index for a test feature @xmath9 .",
    "the sum of weights is the highest ( 24.47 ) for babble noise dictionary , while that of veena is 2.33 , a factor of about 10.5 for correct classification .",
    "it is to be noted that the dictionary used for both @xmath82 and @xmath83 is a concatenated dictionary @xmath12 , while the measure @xmath84 is derived using separate dictionaries @xmath65 .    .",
    "( b ) number and sum of non - zero weights in ( a ) as a function of dictionary type for @xmath85 . ]",
    "magnitude stft features are extracted using a frame size of 60 ms and a frame shift of 15 ms from each audio source with a duration of 3 to 4 minutes .",
    "we experimented with different choices and arrived at these values as the optimum . since the number of atoms in each dictionary is constrained to be 100 , only 6 seconds from the training set of each audio type form the dictionaries . for evaluating the method , a test signal of duration 5 seconds , equivalent to 330 frames ,",
    "is taken from the database , and the rest of the audio signal is used in the training stage for learning the dictionaries .",
    "figure [ percentfrms ] shows the plot of percentage of frames of each test signal correctly classified using sdr as the classification measure for various combinations of @xmath30 and @xmath38 .",
    "table [ overiden ] summarizes the overall audio classification accuracy for different choices of @xmath30 and @xmath38 , where the highest accuracy is obtained for @xmath86 using any of the measures sdr , nnz and sw .",
    "random selection of mag .",
    "stft features along with the constraint on the cosine similarity has ensured distinct dictionaries and the capture of the variations in the audio characteristics by the atoms .",
    "the misclassification is marginally higher when either of the thresholds is unity .",
    "so , we have used @xmath39 as the thresholds .",
    "figure [ accallnois ] shows the percentage of frames correctly classified from each of the 12 audio sources for each of the three measures .     and @xmath38 .",
    "]    .overall source classification accuracy ( % ) for different choices of @xmath30 and @xmath38 using sdr , nnz and sw as measures [ cols=\"^,^,^,^,^\",options=\"header \" , ]     [ overiden ]    even though sdr outperforms the other two measures , nnz and sw are promising since they are computationally simple and give a different insight into the distribution of weights . in case the number of audio sources @xmath15 is large , using only sdr as an classification measure is computationally complex , since asna is run @xmath15 number of times . in that case , the measures @xmath82 or @xmath83 can act as the front end for classification ( since asna is run only once ) .",
    "these measures can pick up the top few source dictionaries and then , sdr can be used to find the best fit among them .",
    "two higher level measures are defined for the @xmath87 dictionary , namely , accumulated sdr ( asdr ) and moving asdr ( masdr ) as :    @xmath88    @xmath89    where @xmath90 is the index of the present frame and @xmath91 is the number of frames accumulated .",
    "figure [ accsum ] shows the frame - wise sdr and the corresponding asdr for five test frames of factory and traffic noise ( most misclassified audio sources in fig.[percentfrms ] ) . in each case , only two other audio sources having highest sdr s are shown , for clarity .",
    "it is seen in fig.[accsum](a ) that even though frame - wise sdr for the fourth frame is lower for factory noise , the corresponding asdr is higher and gives correct classification . in our experiment , we find that 100% classification accuracy can be obtained using masdr with @xmath92 for ten of the sources implying that any consecutive six frames ( 135 ms ) of the test noise are sufficient for correct classification .",
    "test factory noise requires @xmath93 and veena , @xmath94 for correct classification .    in a real life scenario ,",
    "the accuracy of classification based on accumulated classification measures is more relevant than individual frame level accuracy , since the classification algorithm gets a stream of test audio signal as input .",
    "so , even though a few frames may be individually misclassified , the accumulated classification measure correctly classifies the source .",
    "al @xcite performed frame - wise noise identification ( frame size of 20 ms ) using line spectral frequencies as features and pattern recognition based classifiers .",
    "they trained using 18.75 minutes of audio data each from 5 noise classes ( three of them from noisex database ) , and tested on 500 frames of data for each class .",
    "al @xcite obtained an overall accuracy of 83.9% in recognizing 14 environmental sounds .",
    "we have used 12 classes , and obtained an overall frame level accuracy of 98.2% using sdr , compared to 89% reported in @xcite .",
    "the highest accuracy given by majority vote classifier in @xcite is around 78% .",
    "the accuracy is 100% using masdr .",
    "a new approach to audio source classification has been proposed adopting asna as the source recovery algorithm .",
    "experiments using very limited training data have shown a good overall frame level accuracy of 98% .",
    "we plan to explore and devise other source recovery algorithms for faster and more efficient background source classification .",
    "also , we are working on classification of type of background noise from noisy speech and the subsequent separation of speech .",
    "r turner , [ online ] _ http://www.wired.co.uk/news/archive/2013-10/02/machine-hearing-cambridge-university _",
    "s. ikram ,  digital audio forensics using background noise , \" _ multimedia and expo ( icme ) _ , july 2010 , pp .",
    "106 - 110 .",
    "s. chu , s. narayanan , c. c. jay kuo , and m. j. matari ,  where am i ?",
    "scene recognition for mobile robots using audio features , \" _ in ieee international conference on multimedia and expo _ , pp .",
    "885 - 888 , 2006 .",
    "a. shirkhodaie , and a. alkilani ,  a survey on acoustic signature recognition and classification techniques for persistent surveillance systems , \" _ proc .",
    "signal processing , sensor fusion , and target recognition _ , may 2012 .",
    "m. casey ,  reduced - rank spectra and minimum - entropy priors as consistent and reliable cues for generalized sound recognition , \" _ proc .",
    "workshop on consistent and reliable acoustic cues for sound analysis , eurospeech _ , aalborg , denmark , 2001 .",
    "d. giannoulis , e. benetos , d. stowell , m. rossignol , m. lagrange and m. d. plumbley ,  detection and classification of acoustic scenes and events : an ieee aasp challenge , \" _ ieee workshop on applications of signal processing to audio and acoustics _ , oct .",
    "2013 .",
    "t. virtanen ,  monaural sound source separation by non - negative matrix factorization with temporal continuity and sparseness criteria , \" _ ieee trans .",
    "audio , speech , and lang .",
    "_ , vol.15 , no.3 , 2007 .",
    "g. j. mysore , p. smaragdis , and b. raj ,  non - negative hidden markov modeling of audio with application to source separation , \" _ lecture notes in computer science , latent variable analysis and signal separation _ ,",
    "vol . 7572 , pp .",
    "186 - 199 , 2012 .",
    "n. bertin , r. badeau , and e. vincent ,  enforcing harmonicity and smoothness in bayesian non - negative matrix factorization applied to polyphonic music transcription , \" _ ieee trans .",
    "audio , speech , and lang .",
    "18 , no . 3 , 2010 .",
    "j. gemmeke , t. virtanen , and a. hurmalainen ,  exemplar - based sparse representations for noise robust automatic speech recognition , \" _ ieee trans .",
    "audio , speech , and lang .",
    "7 , 2011 .",
    "y. c. cho and s. choi ,  nonnegative features of spectro - temporal sounds for classication , \" _ pattern recognition letters _ , vol .",
    "26 , no . 9 , 2005 .",
    "s. zubair , f. yan , w. wang  dictionary learning based sparse coefficients for audio classification with max and average pooling , \" _ elsevier digital signal processing _ , vol .",
    "23 , issue . 3 , 2013 .",
    "m. d. plumbley , t. blumensath , l. daudet , r. gribonval , and m. e. davies ,  sparse representations in audio and music : from coding to source separation , \" _ proceedings of the ieee , _ vol .",
    "98 , no . 6 , pp . 9951005 , 2009 .",
    "j. nikunen and t. virtanen ,  object - based audio coding using non - negative matrix factorization for the spectrogram representation , \" _ proceedings of the 128th audio engineering society convention _ ,",
    "london , uk , 2010 .",
    "t. virtanen , j. f. gemmeke , b. raj ,  active - set newton algorithm for overcomplete non - negative representations of audio \" , _ ieee trans .",
    "audio , speech , and lang . process .",
    "21 , pp . 2277 - 2289 , 2013 .",
    "y. pati , r. rezaiifar , and p. krishnaprasad ,  orthogonal matching pursuit : recursive function approximation with applications to wavelet decomposition , \" _ proceedings of asilomar conference on signals , systems and computers _ , 1993 .",
    "s. kong , and d. wang ,  a dictionary learning approach for classification : separating the particularity and the commonality , \" _ lecture notes in computer science , computer vision _ , vol .",
    "7572 , pp .",
    "186 - 199 , 2012 .",
    "s. shafiee , f. kamangar , v. athitsos , and j. huang ,  the role of dictionary learning on sparse representation - based classification , \" _ proc .",
    "pervasive technologies related to assistive environments _ , no .",
    "47 , 2013 ."
  ],
  "abstract_text": [
    "<S> a dictionary learning based audio source classification algorithm is proposed to classify a sample audio signal as one amongst a finite set of different audio sources . </S>",
    "<S> cosine similarity measure is used to select the atoms during dictionary learning . </S>",
    "<S> based on three objective measures proposed , namely , signal to distortion ratio ( sdr ) , the number of non - zero weights and the sum of weights , a frame - wise source classification accuracy of 98.2% is obtained for twelve different sources . </S>",
    "<S> cent percent accuracy has been obtained using moving sdr accumulated over six successive frames for ten of the audio sources tested , while the two other sources require accumulation of 10 and 14 frames .    * index terms * : dictionary learning , cosine similarity , audio classification , source recovery , sparse representation . </S>"
  ]
}