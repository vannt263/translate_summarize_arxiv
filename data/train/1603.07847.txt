{
  "article_text": [
    "let us consider the function @xmath0 to be an _ experimental _ relationship between the independent - variable vector , @xmath1 , and an experimental output quantity , @xmath2 :    @xmath3    here , the word `` experimental '' will imply that evaluating the corresponding @xmath2 for a given @xmath4 requires carrying out a _ physical _ experiment that _ can not be performed solely with a computer _ , with the evaluation intrinsic to @xmath5 defined as a physical act and not as a series of numerical computations .",
    "such relationships appear virtually everywhere in the sciences @xcite , and are typically accompanied by systematic studies that attempt to discover the nature of the given @xmath5 . among the documented qualitative work on the subject , it is probably john lind s 1747 examination of scurvy patients @xcite that stands out as the earliest . on the quantitative front , it is likely to ronald fisher and his work on the design of experiments @xcite that modern scientific investigation is most indebted , with the foundations for obtaining a mathematical approximation of @xmath5 laid out therein still very much in use today .    in many cases , however ,",
    "simply identifying an experimental relationship is not the end goal .",
    "instead , one is often searching to manipulate experimental conditions in such a way so as to obtain the `` best '' response while satisfying a number of safety or physical restrictions .",
    "in such scenarios , the _ experimental optimization _",
    "problem    @xmath6    usually arises , where @xmath7 denote the cost function to be minimized , the functions @xmath8 denote the @xmath9 constraints , and the constants @xmath10 denote the lower and upper limits on @xmath4 ( now termed `` decision variables '' ) , respectively .",
    "the subscript @xmath11 is used to denote explicitly those relationships that are experimental in nature , its absence indicating that the function is numerical and only requires a computer or basic algebra to evaluate",
    ". a diverse range of practical engineering problems may be cast and solved in the form of ( [ eq : mainprob ] ) @xcite .    because the experimental functions @xmath12 and @xmath13 are unknown and not subject to numerical evaluation , solving ( [ eq : mainprob ] ) entails running a _ series _ of experiments at @xmath14 , where each new experiment is chosen via some algorithmic function , @xmath15 , of the previously applied @xmath4 and the corresponding experimentally evaluated function values :    @xmath16    the index @xmath17 used to denote the latest experimental iteration .",
    "the seminal paper with regard to solving ( [ eq : mainprob ] ) is due to @xcite , where @xmath15 essentially takes the form of a standard gradient - based descent method .",
    "numerous other methods ( @xmath15 ) and frameworks have been proposed in various mathematical and engineering domains since @xcite .    in the present work ,",
    "we explore a single facet of problem ( [ eq : mainprob ] ) and focus on the case where the experimental functions involved are _ lipschitz continuous _ over the explored domain , as we believe that making this assumption may benefit the solution procedure in multiple ways . given the lipschitz continuity of a function , we first state the fundamental law @xcite that there exists a finite _ lipschitz constant _",
    ", @xmath18 , such that    @xmath19    where @xmath20 is the _ experimental space _ to which the experiments are restricted . as with any assumption ,",
    "the practical validity of ( [ eq : lipgen ] ) must be questioned , with the authors empirical experience so far suggesting that the assumption is not unreasonable for many , if not most , practical problems . in these problems ,",
    "the constant @xmath18 may be understood as a maximal _ sensitivity _ of the experimental function @xmath5 to the changes in the decision variables @xmath4 over the experimental space @xmath21 .",
    "let us suppose now that an explicit value of @xmath18 satisfying ( [ eq : lipgen ] ) is _ known _ or , at the very least , that a reliable overestimate is available .",
    "as will be shown in section [ sec : uses ] , such information opens several new doors , thereby making it possible to ( a ) satisfy important experimental constraints during the optimization process , and ( b ) reduce the potentially harmful effects of measurement or estimation uncertainty .",
    "of the two , ( b ) is seen as useful while ( a ) is considered crucial , as it allows the introduction of _ simple _ safety guarantees for problems that traditionally lack them .",
    "a number of simulated case - study examples will be presented to illustrate the potential benefits of the techniques .    following the presentation of these core ideas , we will explore , in section [ sec :",
    "refine ] , the use of additional assumptions to derive an alternate version of ( [ eq : lipgen ] ) that is , in most cases , tighter and thus less conservative .",
    "specifically , it will be shown that    * using multiple lipschitz constants for @xmath5 ( sensitivities with respect to individual decision variables ) , * using local values rather than those valid for _ all _ @xmath22 and @xmath23 in @xmath21 , and * taking into consideration the potential convexity and concavity properties of @xmath5    all allow for a version of ( [ eq : lipgen ] ) that , though visually more complex , can often lead to significant gains in performance . as may be expected ,",
    "the price to pay for the improvement is that of additional assumptions . however , they are not compulsory , and the user may employ as many as can reasonably be made .",
    "finally , section [ sec : estim ] of the paper will focus on the fundamental and important issue of setting the @xmath18 values , which is not so trivial to do well  here , one must remember that since @xmath5 is unknown , so is @xmath18 .",
    "a number of various methods that combine physical principles , model - based estimation , and data - driven refinement are discussed , with a summary of the authors own empirical experience with these methods effectiveness concluding the section .",
    "exploiting the lipschitz constants will , in general , be synonymous with exploiting the corresponding lower and upper _ lipschitz bounds _ ,    @xmath24    of which the lower bound is a symmetrical result easily obtained by switching @xmath25 in ( [ eq : lipgen ] ) . given the experimental nature of @xmath5 ,",
    "the practical implications of ( [ eq : lipgenlu ] ) are important as they allow us to analyze the worst - case behavior of the function with respect to its departure from @xmath22 . in other words , if the experiment at @xmath22 has been conducted but the one at @xmath23 has not , it becomes possible to bound the greatest possible change in @xmath5 if @xmath23 were applied .",
    "this section focuses on the three major uses of ( [ eq : lipgenlu ] ) , outlining their theoretical foundations , discussing their implementation , and providing illustrations via several case - study examples .",
    "in general , there exists no guarantee that the iterates @xmath26 generated by the algorithm @xmath15 of ( [ eq : bigalgo ] ) will satisfy the experimental constraints @xmath27 for all @xmath28 .",
    "the reason is simple  the functions are unknown to the user , and this makes it impossible to know in advance if the next applied set of decision variables , @xmath29 , will satisfy @xmath30 . while different methodologies for solving ( [ eq : mainprob ] ) do employ different techniques for ensuring that these constraints are met in some sense , the current state of the art is not very developed in this regard , with rigorous constraint satisfaction a notable gap in the experimental - optimization literature . when looking at the three prominent domains concerned with solving problem ( [ eq : mainprob ] ) , we notice the following :    * derivative - free optimization methods , developed mostly by the mathematical community and often dealing with numerical optimization problems , only take precautions against constraints _ asymptotically _ ",
    "i.e. , they ensure , usually via penalty - function methods , that @xmath29 satisfies the constraints as @xmath31 @xcite @xcite ; * response - surface optimization methods often deal with experimental systems and are used in a wide number of fields @xcite , but neither do they address the problem of constraint satisfaction during the experiments used to construct the response - surface model , nor do they rigorously attack the potential issue of the model optimum violating the constraints @xcite ; * real - time optimization , as typically done in the chemical - engineering community @xcite , is arguably the most concerned with consistent constraint satisfaction , since @xmath32 may represent a dangerous or economically disastrous operating regime ; however , while both theoretical @xcite and practical @xcite methods have been developed for promoting the satisfaction of constraints , the former are often too complex and restrictive while the latter suffer from a lack of rigorous guarantees , with both types of methods tending to find solutions that are significantly suboptimal because of conservatism @xcite .    in particular , for those problems where",
    "rigorous experimental - constraint satisfaction is highly desired , the above methods are largely inadequate , and only in the real - time optimization community is the rigorous satisfaction of constraints at _ every _ experiment even a concern .",
    "some years ago , the authors proposed a lipschitz approach to this problem @xcite .",
    "striking what we believe to be a good balance between rigor and simplicity , the method suggests to start with an initially feasible @xmath33 , where @xmath34 , and to repeatedly couple this with the upper lipschitz bound of ( [ eq : lipgenlu ] ) to generate a series of conditions that guarantee constraint satisfaction throughout :    @xmath35    where @xmath36 denotes the corresponding lipschitz constant for @xmath13 .",
    "the algorithmic implementation of ( [ eq : lipseq ] ) is straightforward , as at the current iterate @xmath17 the value of @xmath37 has been obtained , @xmath36 is set , @xmath38 has been applied , and @xmath29 is controlled by the user . as such , it suffices to add the constraint    @xmath39    to @xmath15 when selecting the next @xmath29 to apply . clearly , because @xmath40 , one can always bring @xmath29 sufficiently close to @xmath38 so as to ensure that ( [ eq : congamma ] ) is satisfied .",
    "the simplicity of the implementation is particularly attractive since no complex model of the experimental functions is required , which is the case in some of the rigorous constraint - satisfaction methods previously proposed @xcite",
    ".    the rigor of ( [ eq : lipseq ] ) should also be apparent . if @xmath34 and @xmath36 is such that ( [ eq : lipgen ] ) is satisfied",
    ", then ( [ eq : lipseq ] ) guarantees that the sequence of @xmath26 meets the constraints at every experiment . practically speaking ,",
    "this is a very useful result .    of course , this approach is not without its caveats , and it would be dangerous to assume otherwise .",
    "the most major is the correctness of @xmath36 , as setting @xmath36 too small essentially invalidates the method s rigor and makes its guarantees unreliable .",
    "the obvious solution of making @xmath36 `` very big '' comes with the major drawback of conservatism , and so can not be recommended as it would implicitly shrink the distances between @xmath41 and @xmath42 , @xmath43 and @xmath41 , and so on , resulting in the optimization advancing very slowly .",
    "given the importance of this issue , we will return to it in detail in section [ sec : estim ] , assuming until then that a correct choice of @xmath36 is available .",
    "a lesser but important concern lies in the potential issue of _ premature convergence _ that may be experienced by any @xmath15 that adds ( [ eq : congamma ] ) to its definition . more concretely , this refers to the case where the experiments generated by @xmath15 approach an experimental constraint faster than they approach an optimum , as this drives a given @xmath13 to 0 and forces @xmath44 for ( [ eq : congamma ] ) to be met , essentially forcing the algorithm to terminate on some active experimental constraint .",
    "we illustrate the issue geometrically in fig .",
    "[ fig : feasbreaksiam ] .",
    "although the solution to this particular problem will not be addressed in this paper , we do note that it may be attained with the addition of supplementary conditions that force @xmath15 to not approach any constraint `` too quickly '' .",
    "the interested reader is referred to the unpublished document of @xcite for the details .",
    "continuously takes steps in the gradient descent direction while keeping the constraint satisfied via the lipschitz condition ( [ eq : congamma ] ) .",
    "gradually , the algorithm converges to the point @xmath45 on the boundary of an experimental constraint ( @xmath46 ) , after which it can no longer make any progress towards the true optimum @xmath47 , as any step chosen would violate ( [ eq : congamma ] ) .",
    "the green and red areas represent the feasible ( all constraints satisfied ) and infeasible ( some constraints violated ) sets of the problem , respectively.,width=226 ]    finally , the method does rely on the initial experiment satisfying the constraints .",
    "however , this is not expected to be a limitation , since it is typically assumed that the experimental optimization of some given system will start at a point that is safe but suboptimal . indeed ,",
    "if @xmath33 were not safe , then one would not expect optimization to be the user s top priority .      to illustrate how the lipschitz method may be successfully incorporated into the solution of an experimental optimization problem ,",
    "let us take the case - study example of minimizing the batch time of a polystyrene production reactor , originally reported by @xcite . here , we will use the problem formulation of @xcite , where one is interested in choosing the `` switching times '' of the reactor s temperature profile so as to both ( a ) minimize the time required to reach the desired conversion , favored by higher temperatures , and ( b ) meet a terminal lower limit on the molecular weight of the product , favored by lower temperatures .",
    "the original problem is a dynamic optimization problem as it seeks to find an optimal _ profile _ , but the piecewise definition of the profile via prescribed `` arcs '' and switching times essentially turns this into an experimental optimization problem , which can then be solved in a batch - to - batch manner by varying the switching times ( and thus the profile ) from batch to batch until an optimal profile is hopefully found .",
    "as formulated , the problem has an experimental cost function ( the time of the batch ) and a single experimental constraint ( the lower limit on the molecular weight ) .",
    "because the molecular weight is a product specification , it would be very wasteful to run batches that violate this constraint , as all such batches may be discarded as inadequate for failing to meet specifications .",
    "it follows that an effort to satisfy this constraint for all batches should be made .",
    "the exact problem solved is problem p3 from the expopt database @xcite , which the interested reader may access to find a more detailed problem description , the steps taken to place the problem into the standard form ( [ eq : mainprob ] ) , and the actual code used to simulate the case study . only the problem as written in standard form ,    @xmath48    is given here , where @xmath49 denotes the final batch time to be minimized ( in seconds ) , @xmath50 denotes the number average molecular weight ( in grams per mole ) , and @xmath51 and @xmath52 are the two switching times that define the temperature profile ( in seconds ) .",
    "so as to avoid unnecessary numerical complications , ( [ eq : polyprob ] ) is scaled prior to being solved , with @xmath49 divided by 8000 , the constraint function divided by @xmath53 , and the two decision variables normalized to lie in the unit box defined by the coordinates @xmath54 and @xmath55 .",
    "the initial experiment is chosen as @xmath56 .    to solve the problem",
    ", we apply as @xmath15 a constraint - adaptation @xcite , or bias - update @xcite , algorithm . in applying this method",
    ", we suppose the availability of an approximate process model ,    @xmath57    where @xmath58 and @xmath59 are the uncertain model parameters  in this case , the rate constants for propagation and transfer to monomer , respectively . because the values of the model , @xmath60 and @xmath61 ( liters per mole per second ) , differ from the true values of @xmath62 and @xmath63 , solving the model - based optimization problem    @xmath64    directly will not yield the optimal point . in constraint adaptation ,",
    "one aims instead to iteratively approach a better solution by ensuring that the constraint values in the model - based optimization tend to the true measured values by applying a local bias correction term , @xmath65 , and setting each next @xmath29 as    @xmath66    with @xmath65 defined as a weighted sum of the current model error and the previous correction term :    @xmath67 + ( 1-\\alpha ) \\epsilon_{k-1}.\\ ] ]    in this example , we initialize @xmath68 as 0 , and apply a filter gain of @xmath69 . applying ( [ eq : caprob ] ) and ( [ eq : caupdate ] ) repeatedly essentially solves the problem , and it can be seen from the top set of results in fig .",
    "[ fig : caex ] that the algorithm succeeds at finding the neighborhood of the solution fairly quickly .",
    "however , the path taken results in consistent violations of the molecular weight constraint .    ) with the constraint - adaptation algorithms of ( [ eq : caprob ] ) ( top ) and ( [ eq : caproblip ] ) ( bottom).,width=302 ]    to incorporate the lipschitz bound , we simply add condition ( [ eq : congamma ] ) as a constraint in ( [ eq : caprob ] ) :    @xmath70    with a ( correct ) value . for the case - study examples in this section",
    ", we will , for simplicity , use correct lipschitz constants , as may be obtained by exhaustive numerical tests on @xmath5 , available to us in these simulated studies . ] of 3 used for @xmath71 .",
    "the performance of the resulting @xmath15 is given as the bottom set of results in fig .",
    "[ fig : caex ] , and one observes a trajectory of @xmath4 that , though approaching the optimum slower , does so without _ any _ violations .    as an aside",
    ", we note that this way of implementing ( [ eq : congamma ] ) may be used for any @xmath15 that computes @xmath29 by solving a numerical optimization problem .",
    "a more general alternative of employing ( [ eq : congamma ] ) in a line search may be used otherwise @xcite .",
    "the previous section focused on modifying the optimization algorithm @xmath15 so that the constraints remain satisfied at every future @xmath29 .",
    "however , @xmath15 may not be the only law that dictates what experiments are run , as it is often the case that _ additional experiments _ are periodically required to gather information about the experimental function locally .",
    "for example , one may wish to perform experiments in the neighborhood of @xmath38 so as to identify the parameters of a locally valid model @xcite or to estimate the local function derivatives @xcite , either of which may then be used to assist @xmath15 in computing @xmath29 .",
    "naturally , there then arises a conflict between constraint satisfaction and obtaining information when one approaches a constraint , with the information - gathering perturbations becoming a potential constraint - violation hazard .    a viable solution to this conflict",
    "has already been discussed in detail by @xcite , and what we present here is a simple variant .",
    "namely , to guarantee that any point in the perturbation ball of @xmath72 satisfy a given constraint @xmath73 , it is sufficient to enforce that the value @xmath74 satisfy a constraint back - off of @xmath75 :    @xmath76    the validity of ( [ eq : backoff ] ) is easily demonstrated .",
    "for every @xmath77 ,    @xmath78    and thus    @xmath79    note that an analogous result may be derived for the numerical constraints @xmath80 , with the back - off of @xmath81 resulting in the same guarantee if we assume @xmath80 to be lipschitz continuous with a lipschitz constant of @xmath82 . however , more involved numerical techniques are also possible in this case @xcite .    the exact manner in which one may employ ( [ eq : backoff ] ) to allow for perturbation",
    "while robustly satisfying the constraints would almost certainly be method - dependent .",
    "the general principles , however , are quite simple .",
    "because one has the guarantee that satisfying the constraint with a specified back - off allows for one to perturb safely anywhere in a @xmath83-ball around that point , it follows that one can choose @xmath83 _ a priori _ and to then only perturb around those experimental iterates that satisfy the corresponding back - off , since all such information - gathering experiments will satisfy the constraints .",
    "this is now illustrated for a specific case - study example .",
    "one algorithm that depends heavily on perturbations is the modifier - adaptation method @xcite , which solves problem ( [ eq : mainprob ] ) by iteratively solving a corrected model - based problem :    @xmath84    with @xmath85 and @xmath86 denoting the `` modifiers '' used to correct the local zero- and first - order errors of the model , respectively :    @xmath87 + ( 1-\\alpha)\\epsilon_{j , k-1 } \\vspace{1 mm } \\\\",
    "{ \\boldsymbol \\lambda}_{j , k } : = \\alpha \\left [ \\nabla g_{p , j } ( { \\bf u}_k ) - \\nabla g_{\\hat p , j } ( { \\bf u}_k , { \\boldsymbol \\theta } ) \\right ] + ( 1-\\alpha){\\boldsymbol \\lambda}_{j , k-1 } \\vspace{1 mm } \\\\ { \\boldsymbol \\lambda}_{\\phi ,",
    "k } : = \\alpha \\left [ \\nabla \\phi_{p } ( { \\bf u}_k ) - \\nabla \\phi_{\\hat p } ( { \\bf u}_k , { \\boldsymbol \\theta } ) \\right ] + ( 1-\\alpha){\\boldsymbol \\lambda}_{\\phi , k-1}. \\end{array}\\ ] ]    it should be clear that this @xmath15 is a generalization of the constraint - adaptation algorithm employed in section [ sec : poly ] , in that we are now correcting the model _ derivatives _ in addition to the constraint function values . as with constraint adaptation",
    ", the uncertain parameters of the model are not updated between iterations and are kept at some nominal , constant values , although a version of the algorithm that estimates and updates the parameters as well may certainly be used @xcite .    as in the constraint - adaptation case ,",
    "the zero - order modifier values @xmath88 may be easily obtained by physically measuring the experimental function and numerically evaluating the model at @xmath38 .",
    "the first - order corrections , however , require experimental derivative estimates , which may be obtained using a number of approaches @xcite . here",
    ", we will employ the simple method of taking the difference quotients    [ eq : findiff ] @xmath89 or , if @xmath90 , @xmath91    where @xmath92 is the unit vector with unity at the @xmath93 spot and @xmath83 is some non - zero value .",
    "the choice to use @xmath83 as the perturbation step is , of course , not coincidental and is intended to be used in synergy with ( [ eq : backoff ] ) so as to ensure that all perturbations performed for estimating the derivatives satisfy the constraints .    the outline of the employed algorithm , where one starts at the iteration @xmath94 with some @xmath33 that satisfies the constraints on @xmath13 and @xmath80 with the additional back - offs of @xmath75 and @xmath81 , is as follows :    1 .",
    "define the modifiers as in ( [ eq : modifiers ] ) , with the experimental gradients obtained by carrying out an additional @xmath95 experiments and then applying ( [ eq : findiff ] ) .",
    "2 .   compute @xmath29 by solving an augmented version of ( [ eq : mainprobma ] ) that accounts for the back - offs : + @xmath96 3 .",
    "apply the new decision variables to the experimental system , obtain the new measurements , augment the value of @xmath17 , and return to step 1 .",
    "note that the modifications introduced in ( [ eq : mainprobmalip ] ) serve to ensure that the constraint function values ",
    "experimental and numerical  meet the back - offs required to ensure that the perturbations in the ball @xmath97 around the future @xmath29 satisfy the constraints .",
    "this algorithm is applied to problem p11 from the expopt database @xcite .",
    "the problem itself is adapted from the work of @xcite and deals with the minimization of the steady - state production cost of a gold cyanidation leaching process .",
    "only the skeleton of the problem is provided here , with interested readers once more referred to the aforementioned references for more in - depth descriptions .    in our standard form",
    ", the problem may be written as    @xmath98    with @xmath4 consisting of two variables  the flow rate of the sodium cyanide ( in kilograms per hour ) and the concentration of the dissolved oxygen in the liquid ( in milligrams per kilogram ) .",
    "the function @xmath99 is the economical cost function to be minimized ( in chinese rmb per hour ) , while @xmath100 denotes the gold concentration in the ore ( in milligrams per kilograms ; @xmath101 denotes its initial value ) .",
    "the single experimental constraint ensures that the gold recovery is at least 75%  the solution , although not on this constraint , is nevertheless very close to it .",
    "the model used for the case study is that provided in the database and differs from the simulated `` real '' process by virtue of errors in the kinetic parameters . as in the previous case - study example",
    ", the decision variables are scaled down to a unit box , with the cost and constraint values divided by the scaling factors of 200 and 0.04 , respectively . a @xmath83 value of 0.05 ( for the scaled variables )",
    "is chosen , with the lipschitz constant of the scaled problem set as @xmath102 .",
    "the process starts operating at the suboptimal point of @xmath103 , which satisfies the experimental constraint with a slack greater than @xmath104 .",
    "it is chosen not to filter the modifiers , with @xmath105 in ( [ eq : modifiers ] ) .    ) .",
    "the dashed line in the plot on the left shows the @xmath106 back - off sufficient to guarantee that the additional perturbations for derivative estimation satisfy the constraint .",
    "the cross marks show the perturbations , the data for which are omitted from the plot on the right.,width=453 ]    the results of applying the above algorithm to this problem are given in fig .",
    "[ fig : maex ] . as expected",
    ", one sees that the main experimental iterates all satisfy the experimental constraint with the back - off , while the @xmath83-perturbations for derivative estimation all satisfy the original constraint . in this case",
    ", we see that the modifier - adaptation algorithm converges to the neighborhood of the optimum fairly quickly .",
    "the lipschitz constants may play an important supplementary role in the very realistic scenario where the experimental function values @xmath107 are subject to uncertainty , which may be due to ( a ) measurement noise or ( b ) the experimental quantity not being directly measured but estimated . in such cases , it is typical to work with a statistical interval in which the value @xmath108 is expected to lie . to obtain such an interval , one needs to make certain assumptions on the statistical nature of the uncertainty .    a common uncertainty model , and the one that will be considered here , is the additive    @xmath109    where @xmath110 is the observed or estimated value and @xmath111 is the stochastic noise or error .",
    "by bounding the stochastic element in the probability sense to mean `` less than or equal to _ with sufficiently high probability _ '' . ] :    @xmath112    it then becomes possible to compute a high - probability interval for @xmath108 by applying these bounds to a rearranged version of ( [ eq : meas ] ) :    @xmath113    most importantly , these bounds allow us to obtain versions of ( [ eq : congamma ] ) and ( [ eq : backoff ] ) that are robust and do not require the unavailable exact function values :    @xmath114    @xmath115    thereby making it possible to maintain the applicability of the methods in sections [ sec : consat ] and [ sec : excite ] for the realistic case with uncertainty .",
    "however , while these bounds may be fairly rigorous and useful , they can also prove too conservative when the variance of @xmath111 is large . a standard procedure for tightening the interval for a given @xmath116",
    "is to resample the function value at @xmath116 multiple times and to take the mean of the values . under reasonable assumptions on @xmath111 ,",
    "this then yields an estimator whose variance shrinks to 0 with an increasing number of samples @xcite .",
    "alternatively , one may be able to obtain tighter bounding values by assuming a locally valid structure for @xmath5 , such as linear or quadratic , and to fit this structure to the data via maximum - likelihood estimation .",
    "provided that the structure chosen is correct , this too can be shown to yield estimators of @xmath5 values that go to the true value with a variance that decreases with an increasing amount of data @xcite .",
    "the alternative proposed here is to `` trim off '' some of the uncertainty when the resulting interval is actually larger than what would be allowed by the worst - case ( lipschitz - bound ) changes in the function values from one decision - variable set to another .",
    "consider first the robust version of ( [ eq : lipgenlu ] ) for some @xmath117 :    @xmath118    of which ( [ eq : lipgenrob ] ) are the particular case corresponding to @xmath119 .",
    "we may , however , be able to improve the bounds by considering the tightest values over all @xmath120 :    @xmath121    @xmath122    after using ( [ eq : lipgenrobl])-([eq : lipgenrobu ] ) to assign lower / upper bounding values to the measurements at @xmath123 , one may run through the process again , since changes in some of the values may lead to additional changes in the others .",
    "the iterative scheme may be outlined as follows :    1",
    ".   set the nominal @xmath124 and @xmath125 for @xmath126 as given in ( [ eq : lipgenrob ] ) .",
    "2 .   refine these values by applying ( [ eq : lipgenrobl])-([eq : lipgenrobu ] ) for @xmath126 .",
    "3 .   if the largest refinement obtained is negligible ( e.g. , @xmath127 ) , terminate . otherwise , return to step 2 .    a conceptual illustration of reducing the uncertainty via this procedure is given in fig .",
    "[ fig : liprefine ] , where we consider a simple one - dimensional case with white gaussian noise of variance @xmath128 , and high - probability bounds of @xmath129 and @xmath130 on the noise elements .",
    "as shown in the figure , it happens that a very poor nominal upper bounding value is obtained at @xmath131 after a very tight upper bounding value has been obtained at the previous experiment of @xmath132 .",
    "because of the lipschitz bound , the tightness at the latter may then be partially `` inherited '' by the former , thereby leading to significant refinement in the upper bounding value at @xmath131 .",
    "naturally , we may expect this method to lose its effectiveness when the decision - variable points are further apart and when the lipschitz constants used are more conservative .",
    "let us again consider the case - study example of section [ sec : cyan ] , this time supposing a more realistic scenario where all of the measurements obtained , for both the cost and constraint , are corrupted by noise elements from the pdf of @xmath133 .",
    "a value of @xmath134 is used here , and the additive corruption is applied to the problem post - scaling .",
    "the nominal lower and upper bounding values on the noise elements are then chosen as @xmath135 and @xmath136 for all measurements at all iterations , from which the nominal lower and upper bounding values on the true function values are obtained as in ( [ eq : lipgenrob ] ) .",
    "two realizations of the modifier - adaptation algorithm are compared here , with both still setting the modifiers as in ( [ eq : modifiers])-([eq : findiff ] ) , but with the @xmath5 function values replaced by their measured or estimated @xmath110 analogues . to robustify the constraint - satisfaction guarantees against the uncertainty effects , the numerical optimization problem of ( [ eq : mainprobmalip ] )",
    "is modified to    @xmath137    in the first algorithm , the lipschitz constants are _ not _ used to refine the bounding values , with the @xmath138 value obtained from ( [ eq : lipgenrob ] ) used in ( [ eq : mainprobmalip2 ] ) . in the second algorithm ,",
    "the lipschitz - bound refinement procedure as outlined in the preceding section is run through all of the measurements  the `` key '' iterations @xmath139 _ and _ the additional perturbations around the key iterations used for derivative estimation .",
    "the resulting @xmath140 is then used in ( [ eq : mainprobmalip2 ] ) . additionally , the measured values @xmath141 and @xmath142 that are used in estimating the modifiers and derivatives are trimmed in the case that they do not satisfy the tightened bounding values ( e.g. , @xmath143 if @xmath144 ) . the lipschitz constant for the cost is chosen as @xmath145 .    so as to see the average effect that including the lipschitz - based tightening has on the performance of the optimization algorithm , we run the algorithms in parallel for 1000 noise realizations and evaluate the average difference between the corresponding cost function values ,    @xmath146    for each realization , with @xmath147 and @xmath148 denoting the cost function values obtained by the original ( without lipschitz tightening ) and modified ( with lipschitz tightening ) algorithms , respectively .",
    "the scalar @xmath149 is used to denote the number of main experiments run , excluding the perturbations and the initial experiment , and is set as 30 here .",
    "a positive @xmath150 value thus suggests an improvement over the original algorithm .    plotting the results of the thousand trials in a histogram ( fig .",
    "[ fig : hist ] ) , we notice a very positive trend , with noticeably better results obtained by the second algorithm .",
    "a significant price to pay for the use of the lipschitz bounds of ( [ eq : lipgenlu ] ) is their potential conservatism .",
    "namely , if the constant @xmath18 is chosen so that the bounds are satisfied with a very large margin , one is faced with several drawbacks :    * as already mentioned in section [ sec : consat ] , the constraint - satisfaction condition ( [ eq : congamma ] ) may become too restrictive , forcing the algorithm to take overly small steps ; * the back - off , @xmath151 , needed for safe perturbation in ( [ eq : backoff ] ) may become too large and difficult to satisfy , and if satisfied may introduce a large degree of suboptimality ; * the lipschitz - based tightening of the bounding values @xmath152 and @xmath153 obtained in section [ sec : filter ] becomes negligible or disappears altogether .",
    "fortunately , though the function @xmath5 may be experimental and thus unknown , scattered bits of information about its behavior might be available and could be exploited to yield different lipschitz bounds that are often much tighter .    in this section ,",
    "we consider the following types of additional information :    * directional lower and upper lipschitz constants , + @xmath154 * local lipschitz constants over the subspace + @xmath155 + defined as + @xmath156 * the local convexity and concavity properties of @xmath5 , where it is known that @xmath5 is locally convex or concave in certain variables over @xmath157 , with the indices of these variables denoted by the sets @xmath158 and @xmath159 , respectively ; * lower and upper bounds on the local derivatives of @xmath5 : + @xmath160    by integrating the information above , one is able to account for scenarios that would be completely ignored when using ( [ eq : lipgenlu ] ) .",
    "for example , by using @xmath161 lipschitz constants instead of just one , it becomes possible to differentiate between those decision variables that have a large effect on @xmath5 and those whose effect is known to be negligible . additionally , by having both lower ( @xmath162 ) and upper ( @xmath163 ) constants , one can differentiate between the sensitivities as being either positive or negative  e.g. , if it is known that increasing a certain @xmath164 will _ always _ increase the value of @xmath5 , the corresponding @xmath162 can be set as 0 , which , as will be seen , may tighten the corresponding lipschitz bound significantly .    by limiting the analysis to a subspace @xmath165 , it becomes possible to accomodate those problems where the sensitivity of @xmath5 to some @xmath164 is known to change drastically over @xmath21 .",
    "of particular concern may be those @xmath5 that have an inversely proportional relationship with @xmath164 , and whose values may explode as @xmath164 approaches 0 . while it might make sense to include the 0-point in the definition of @xmath21 , actually operating there might be unlikely , and so it would be unnecessarily conservative to use the very large lipschitz constants corresponding to the region around the 0-point when smaller , more reasonable values could be used instead . considering the local subspace",
    "@xmath157 provides us with a convenient mathematical formulation for handling such cases .",
    "finally , the inclusion of convexity / concavity properties , when coupled with derivative bounds , gives greater flexibility for those problems where @xmath5 is known with certainty to behave in a convex / concave manner when only certain variables are changed ( the other variables being kept the same ) .",
    "the relationship between the power and current in a fuel - cell system @xcite , known to be concave , is one example that the authors have encountered .",
    "mathematically , exploiting such relationships allows us to forgo using lipschitz constants for certain directions and to use the less conservative derivative bounds instead .",
    "some results for obtaining such bounds for an experimental function @xmath5 have been reported in @xcite .    combining the information above ,",
    "let us now derive an alternative to ( [ eq : lipgenlu ] ) .",
    "let the experimental function @xmath5 be continuously differentiable ( @xmath166 ) over an open set containing @xmath157 , with its derivatives bounded as in ( [ eq : liplocal])-([eq : derbounds ] ) .",
    "the bounds    @xmath167 + \\hspace{-3 mm } \\sum_{i \\not \\in i_{\\rm cvx}^{{\\bf u}_a , { \\bf u}_b } } \\hspace{-3 mm } \\mathop { \\min } \\left [ \\begin{array}{l } \\underline \\kappa_{i}^{{\\bf u}_a,{\\bf u}_b } ( u_{b , i } - u_{a , i } ) , \\vspace{1 mm } \\\\   \\overline \\kappa_{i}^{{\\bf u}_a,{\\bf u}_b } ( u_{b , i } - u_{a , i } ) \\end{array } \\right ] \\leq f_p ( { \\bf u}_b),\\ ] ]    @xmath168 + \\hspace{-3 mm } \\sum_{i \\not \\in i_{\\rm ccv}^{{\\bf u}_a , { \\bf u}_b } } \\hspace{-3 mm } \\mathop { \\max } \\left [ \\begin{array}{l } \\underline \\kappa_{i}^{{\\bf u}_a,{\\bf u}_b } ( u_{b , i } - u_{a , i } ) , \\vspace{1 mm } \\\\",
    "\\overline \\kappa_{i}^{{\\bf u}_a,{\\bf u}_b } ( u_{b , i } - u_{a , i } ) \\end{array } \\right]\\ ] ]    are then satisfied for all @xmath169",
    ".    we will only prove ( [ eq : lipgenu ] ) and leave ( [ eq : lipgenl ] ) to the reader , as the two proofs are symmetric .",
    "first , let us write the evolution of @xmath5 from @xmath22 to @xmath23 as occurring in `` two steps '' , the first step in the variables in which @xmath5 is concave and the second step in the variables in which @xmath5 is not . for clarity , we will partition @xmath4 as @xmath170 , where @xmath171 are the variables @xmath172 and @xmath173 are the variables @xmath174 .",
    "the two - step evolution may be written as    @xmath175 + \\left [ f_p ( { \\bf v}_b , { \\bf z}_b ) - f_p ( { \\bf v}_b , { \\bf z}_a ) \\right].\\ ] ]    the proof consists in upper - bounding the two differences in the brackets .",
    "for the first difference , we call upon the first - order condition of concavity @xcite :    @xmath176    to further bound the right - hand side , we then consider two cases ,    @xmath177    and account for the worst case via the maximum operator to obtain    @xmath178.\\ ] ]    to place a bound on @xmath179 , we limit our analysis to a single dimension and then apply the mean - value theorem .",
    "first , consider the function @xmath5 over the line connecting @xmath180 and @xmath181 , parameterized as    @xmath182    where    @xmath183.\\ ] ]    because @xmath5 is @xmath166 , @xmath184 is as well , thereby allowing us to apply the taylor series expansion between @xmath185 and @xmath186 , together with the mean - value theorem @xcite , to state that    @xmath187    the derivative term may then be defined in terms of the original function @xmath5 by applying the chain rule :    @xmath188    noting that @xmath189 and @xmath190 , we thus obtain that    @xmath191    because @xmath192 , the constants of ( [ eq : liplocal ] ) may be used to bound the derivatives and , using the same logic as in ( [ eq : posneg ] ) , we go on to obtain    @xmath193,\\ ] ]    which then leads to    @xmath194.\\ ] ]    combining ( [ eq : firstbound ] ) and ( [ eq : secondbound ] ) yields the desired result .",
    "next , we consider the analogue to ( [ eq : backoff ] ) that follows from ( [ eq : lipgenu ] ) .",
    "[ corol : backoff ] let @xmath13 be @xmath166 over an open set containing @xmath195 , where @xmath196 is the vector of @xmath83 values , and let the derivatives be bounded as in ( [ eq : liplocal])-([eq : derbounds ] ) with @xmath197 and @xmath198 . defining the mixed vector of greatest absolute lipschitz constants and derivative bounds as    @xmath199    it follows that    @xmath200    applying ( [ eq : lipgenu ] )",
    ", it follows that    @xmath201 \\vspace{1 mm } \\\\",
    "\\hspace{35 mm } \\displaystyle + \\hspace{-3 mm } \\sum_{i \\not \\in i_{{\\rm ccv},j}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } } \\hspace{-3 mm } \\mathop { \\max } \\left [ \\begin{array}{l } \\underline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } ( u_{i } - u_{k , i } ) , \\vspace{1 mm } \\\\   \\overline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol",
    "\\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } ( u_{i } - u_{k , i } ) \\end{array } \\right ] \\end{array}\\ ] ]    holds for all @xmath202 .",
    "let us use this bound to define a _",
    "lipschitz polytope _ centered at @xmath38 :    @xmath203 \\vspace{1 mm } \\\\   \\hspace{15 mm } \\displaystyle + \\hspace{-3 mm } \\sum_{i \\not \\in i_{{\\rm ccv},j}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } } \\hspace{-3 mm } \\mathop { \\max }",
    "\\left [ \\begin{array}{l } \\underline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } ( u_{i } - u_{k , i } ) , \\vspace{1 mm }",
    "\\\\   \\overline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } ( u_{i } - u_{k , i } ) \\end{array } \\right ] \\leq 0   \\end{array } \\right\\}.\\ ] ]    the remainder of the proof is essentially a `` busier '' version of the proof of theorem 1 in @xcite , with the same concepts at work . from ( [ eq : lipbounde ] ) , it should be clear that any @xmath4 belonging to both @xmath97 and @xmath204 will satisfy @xmath73 , and so we proceed to identify the back - off on @xmath74 that would enforce @xmath205 , and thus @xmath206 ( i.e. , by inscribing @xmath97 in @xmath204 ) .",
    "this is done analytically by building progressively smaller subsets of @xmath204 , all of which include @xmath97 .    from the algebraic relation @xmath207 , we have    @xmath208 \\leq \\mathop { \\max } \\left ( \\big | \\nabla \\underline g_{p , ji}^{{\\bf u}_k } \\big | , \\big | \\nabla \\overline g_{p , ji}^{{\\bf u}_k } \\big",
    "| \\right ) | u_i - u_{k , i } |,\\ ] ]    @xmath209 \\leq \\mathop { \\max } \\left ( \\big |\\underline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } \\big | , \\big |\\overline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } \\big | \\right ) | u_i - u_{k , i } |,\\ ] ]    whence follows    @xmath210 + \\sum_{i \\not \\in i_{{\\rm ccv},j}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } } \\hspace{-3 mm } \\mathop { \\max } \\left [ \\begin{array}{l } \\underline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf",
    "u}_k+{\\boldsymbol \\delta}_e } ( u_{i } - u_{k , i } ) , \\vspace{1 mm } \\\\   \\overline \\kappa_{p , ji}^{{\\bf u}_k-{\\boldsymbol \\delta}_e,{\\bf u}_k+{\\boldsymbol \\delta}_e } ( u_{i } - u_{k , i } ) \\end{array } \\right ] \\vspace{1 mm } \\\\ \\hspace{75mm}\\displaystyle \\leq \\sum_{i = 1}^{n_u } \\tilde \\kappa_{p , ji } | u_i - u_{k , i } | = \\tilde { \\boldsymbol \\kappa}_{p , j}^t \\delta { \\bf u } , \\end{array}\\ ] ]    with @xmath211 . defining the polytope    @xmath212    we see that @xmath213 by virtue of ( [ eq : proofineq ] ) .",
    "consider now the cauchy - schwarz inequality , which states that    @xmath214    and define the next ( ball ) subset as    @xmath215    that @xmath216 follows from ( [ eq : cauchy ] ) .",
    "it now remains to show that @xmath217 , as this implies @xmath205 and completes the proof .",
    "for every @xmath77 , we have , by definition , @xmath218 , and so it follows that any @xmath77 will also be in @xmath219 if    @xmath220    holds , which is precisely what is ensured by ( [ eq : backoff2 ] ) .    employing the above theorem and corollary , we may now state the alternate results of sections [ sec : consat]-[sec : filter ] :    * constraint satisfaction during optimization ( section [ sec : consat ] ) *    @xmath221 \\vspace{2 mm } \\\\",
    "\\hspace{12mm}\\displaystyle + \\sum_{i \\not \\in i_{{\\rm ccv},j}^{{\\bf u}_k,{\\bf u}_{k+1 } } } \\mathop { \\max } \\left [ \\begin{array}{l } \\underline \\kappa_{p , ji}^{{\\bf u}_k , { \\bf u}_{k+1 } } ( u_{k+1,i } - u_{k , i } ) , \\vspace{1 mm } \\\\",
    "\\overline \\kappa_{p , ji}^{{\\bf u}_k , { \\bf u}_{k+1 } } ( u_{k+1,i } - u_{k , i } ) \\end{array } \\right ] \\leq 0 \\rightarrow g_{p , j } ( { \\bf u}_{k+1 } ) \\leq 0 .",
    "\\end{array}\\ ] ]    * constraint satisfaction during perturbation ( section [ sec : excite ] ) *    @xmath222    * bounding values in the presence of uncertainty ( section [ sec : filter ] ) *    @xmath223 \\vspace{2 mm } \\\\ \\hspace{5 mm } \\displaystyle + \\sum_{i \\not \\in i_{\\rm cvx}^{{\\bf u}_{\\tilde k } , { \\bf u}_{\\bar k } } } \\mathop { \\min } \\left [ \\begin{array}{l } \\underline \\kappa_{i}^{{\\bf u}_{\\tilde k } , { \\bf u}_{{\\bar k } } } ( u_{{\\bar k},i } - u_{\\tilde k , i } ) , \\vspace{1 mm } \\\\ \\overline \\kappa_{i}^{{\\bf u}_{\\tilde k } , { \\bf u}_{{\\bar k } } } ( u_{{\\bar k},i } - u_{\\tilde k , i } ) \\end{array } \\right ]    \\end{array } \\right ) \\mathop \\leq \\limits^p f_p ( { \\bf u}_{\\bar k}),\\ ] ]    @xmath224 \\vspace{2 mm } \\\\ \\hspace{5 mm } \\displaystyle + \\sum_{i \\not \\in i_{\\rm ccv}^{{\\bf u}_{\\tilde k } , { \\bf u}_{\\bar k } } } \\mathop { \\max } \\left [ \\begin{array}{l } \\underline \\kappa_{i}^{{\\bf u}_{\\tilde k } , { \\bf u}_{{\\bar k } } } ( u_{{\\bar k},i } - u_{\\tilde k , i } ) , \\vspace{1 mm } \\\\ \\overline \\kappa_{i}^{{\\bf u}_{\\tilde k } , { \\bf u}_{{\\bar k } } } ( u_{{\\bar k},i } - u_{\\tilde k , i } ) \\end{array } \\right ]    \\end{array } \\right ) : = \\overline f_p^{\\bar k}.\\ ] ]    finally , it is worthwhile to show how the simpler bound of ( [ eq : lipgenlu ] ) may be obtained from the alternate ( [ eq : lipgenl])-([eq : lipgenu ] ) . in doing so",
    ", we also present a sufficient condition for which ( [ eq : lipgenl])-([eq : lipgenu ] ) provide tighter bounds over @xmath157 .",
    "let @xmath165 and let @xmath5 be @xmath166 over an open set containing @xmath157 , with its derivatives bounded as in ( [ eq : liplocal])-([eq : derbounds ] ) . defining the mixed vectors of greatest absolute lipschitz constants and derivative bounds as    @xmath225    @xmath226    it follows that @xmath227 implies that ( [ eq : lipgenu ] ) is tighter than the upper bound of ( [ eq : lipgenlu ] ) .",
    "likewise , @xmath228 implies that ( [ eq : lipgenl ] ) is tighter than the lower bound of ( [ eq : lipgenlu ] ) .    for the upper bound",
    ", we borrow the analysis already carried out in the proof of corollary [ corol : backoff ] to state that the bound    @xmath229    is a looser , more conservative bound than ( [ eq : lipgenu ] ) .",
    "clearly , @xmath227 then implies that the upper bound of ( [ eq : lipgenlu ] ) is even more conservative , whence the proof of the first half of the result .    for the lower bound",
    ", we note that    @xmath230 \\geq -\\mathop { \\max } \\left ( \\big |",
    "\\nabla \\underline f_{p , i}^{{\\bf u}_a } \\big | , \\big | \\nabla \\overline f_{p , i}^{{\\bf u}_a } \\big | \\right ) | u_{b , i } - u_{a , i } |,\\ ] ]    @xmath231 \\geq -\\mathop { \\max } \\left ( \\big |\\underline \\kappa_{i}^{{\\bf u}_a,{\\bf u}_b } \\big | , \\big |\\overline \\kappa_{i}^{{\\bf u}_a,{\\bf u}_b } \\big | \\right ) | u_{b , i } - u_{a , i } |,\\ ] ]    which allows us to apply the same analysis as before to obtain    @xmath232    as a looser , more conservative alternative to ( [ eq : lipgenl ] ) . by the same reasoning",
    ", @xmath228 then implies that the lower bound of ( [ eq : lipgenlu ] ) is even more conservative , thus implying that ( [ eq : lipgenl ] ) is tighter .",
    "clearly , we can obtain a valid version of ( [ eq : lipgenlu ] ) from ( [ eq : lipgenl])-([eq : lipgenu ] ) by setting @xmath233 .",
    "setting the lipschitz constants in implementation so that they satisfy ( [ eq : lipgen ] ) or ( [ eq : liplocal ] ) is usually not trivial and requires some care .",
    "as already mentioned , choosing constants that do not satisfy these inequalities potentially makes the aforementioned techniques invalid because of the possibility that the corresponding lipschitz bounds no longer hold . at the same time , as discussed at the start of section [ sec : refine ] , satisfying the inequalities with too much conservatism may affect performance undesirably .",
    "it is thus the goal of this section to offer some insight into how one may set and refine the estimates of the lipschitz constants intelligently .",
    "we begin with the special and desirable case where these constants are easily known from the physical laws governing a given experimental system ( section [ sec : physics ] ) .",
    "unfortunately , as there exists no means to rigorously guarantee that the lipschitz constants chosen for a _ general experimental function _ be correct , one must inevitably turn to heuristic methods in the general case , and some of these are discussed in sections [ sec : modelest]-[sec : lipconsist ] . despite lacking the desired rigor , the methods proposed are not doomed to failure for this reason , and can certainly be applied with success , as has been demonstrated with some empirical evidence from both simulated and experimental case studies .",
    "this last point is discussed in section  [ sec : empirical ] .",
    "virtually all experimental relationships are subject to physical laws , and for some relationships such laws are so well known and documented that they may be assumed to hold . a simple example previously employed by the authors is the exchange of heat between a heating and heated element  e.g. , a jacket ( heating element ) surrounding a reactor ( heated element ) . if the temperature of the heated element is an experimental function , and the temperature of the heating element is one of the decision variables under the user s control , then much can be said about the sensitivity relating the changes in the temperatures of the two . for very many systems , it would be expected that raising the temperature of the heating element will raise the temperature of the heated element , and that , symmetrically , lowering the temperature of one will lead to a lower temperature in the other . as such , the sensitivity would always be positive , and the lower lipschitz constant , @xmath162 , could safely be set to 0 . additionally , heat losses are likely to ensure that a change in the temperature of the heating element will lead to a _ smaller _ change in the temperature in the heated one , thus allowing us to set @xmath163 as @xmath234 .    while this particular example is somewhat trivial , there are others that are less so .",
    "for example , in the solid oxide fuel - cell system where one manipulates the current while needing to respect a lower - limit constraint on the cell voltage @xcite , it is known that the relationship between voltage and current is always inverse proportional , thus allowing one to set the corresponding @xmath163 as 0 .",
    "and although the physical laws could not tell us the value of @xmath162 in this case , one could nevertheless rely on the multitude of available experimental data to come up with a good estimate . for the polymerization example of section [ sec : poly ]",
    ", one may know that extended heating ( increased @xmath51 ) , together with shortened cooling ( decreased @xmath52 ) and thus increased temperature , will generally lead to a favorization of the termination reactions and shorter polymer chains , thus resulting in a final product with a lower average molecular weight .",
    "this knowledge may then be used to set the lipschitz constants for the molecular - weight constraint function accordingly .",
    "identifying such relationships and their relevance to the setting of lipschitz constants may be an important step to include in the experimental and theoretical work that normally goes into understanding a given system prior to optimization .",
    "note , however , that the physical laws are harder to link to the lumped @xmath18 in ( [ eq : lipgen ] ) , which is more abstract than the individual @xmath162 , @xmath163 of ( [ eq : liplocal ] ) .",
    "many of the relationships that appear in experimental optimization problems will have undergone a fair amount of theoretical investigation , resulting in first - principles parametric models ,    @xmath235    being available for them , where the uncertain parameters @xmath236 are assumed to belong to a bounded set , @xmath237 .",
    "if the assumption of parametric uncertainty is not too egregious , and if the uncertainty set @xmath237 is not too erroneously defined , then a reasonable choice of lipschitz constants in ( [ eq : liplocal ] ) may be obtained by minimizing and maximizing the derivatives of the model over @xmath157 and @xmath237 :    @xmath238    @xmath239    with the analogous formulation    @xmath240    for the lumped @xmath18 .",
    "while solving these optimization problems may not be computationally easy , it is conceivable that they would be solved off - line prior to any @xmath15 being applied , thus making the associated computational burdens of lesser concern .",
    "if an additional layer of safety is needed , one can heuristically lower and increase the estimates as required .",
    "for the very general case where no model is available , one could still apply the above approach but in a data - driven fashion .",
    "one could , for example , construct a linear or quadratic model from several obtained measurements , choose @xmath241 as the coefficients of the model , let their confidence intervals define @xmath237 @xcite , and then apply either ( [ eq : lipmin])-([eq : lipmax ] ) or ( [ eq : lipmax2 ] ) .",
    "the previous two sections have addressed the problem of setting lipschitz constants when none are initially provided .",
    "now , let us consider a technique for refining these initial estimates so that they are _ consistent with the obtained data_.    using ( [ eq : lipgen ] ) as an example , suppose now that we have obtained an estimate of a lipschitz constant , denoted by @xmath242 , and as such have the hypothetically valid bound    @xmath243    although there exists no way to prove the validity of ( [ eq : lipboundest ] ) for an experimental function @xmath244 in the general case , we can and should confirm that this bound is at least satisfied for those experimental measurements that have been collected .",
    "letting @xmath245 and @xmath246 denote two ( different ) indices , a basic consistency - check algorithm would consist in the following two steps being carried out for every combination @xmath247 of @xmath248 $ ] :    a.   check if the inequality + @xmath249 + is satisfied . b.",
    "if ( [ eq : lipboundest2 ] ) is satisfied , proceed to the next @xmath250 combination unless no combinations are left , in which case terminate . otherwise , increase the value of @xmath242 by a preset , strictly positive quantity and return to ( i ) .",
    "it is easy to show that such an algorithm will terminate with a @xmath242 value that is consistent with the obtained data . for the more complex case of ( [ eq : liplocal ] )",
    ", one could apply the same concept by lowering @xmath162 and raising @xmath163 until ( [ eq : lipgenl])-([eq : lipgenu ] ) hold . while there is no apparent `` best way '' to increase the @xmath251 , @xmath163 values when inconsistency occurs",
    ", one could employ heuristics , such as doubling the values .",
    "more elegant schemes may also be proposed @xcite .",
    "clearly , since lipschitz constants are often unknown , it is difficult to test , in any sort of closed - loop manner , whether different estimation methods are actually successful at identifying proper values for these constants in practice .",
    "instead , one may apply the methods during the solution procedure of ( [ eq : mainprob ] ) and see if the problem is solved in a satisfactory manner . when the problem comes with experimental constraints ,",
    "the strongest criterion is to verify that the constraints were met during optimization  if they were not , then this is strong evidence for poor estimates , as it suggests that the constraint - satisfaction condition ( [ eq : congamma ] ) was not valid for the constraints violated .",
    "the speed of decrease in the cost function value is another telling criterion ",
    "if progress is very slow , then this may be a sign of the estimates being too conservative .",
    "in other cases , the quality of the estimates may be difficult to evaluate , although different `` strange '' behaviors during optimization may be an indicator that the constants are not being estimated properly . to date , much of the available empirical evidence for the effectiveness of lipschitz - constant estimation methods comes from problems that have been tackled by the scfo solver @xcite , as this solver incorporates almost all of the techniques discussed in this paper and relies heavily on the lipschitz constants to operate .    of the experimental results available , perhaps the most telling",
    "are those obtained in the experimental optimization of a laboratory solid - oxide fuel cell stack @xcite , where no theoretical model was used and the lipschitz constants were initialized using a data - driven model and the methods of section [ sec : modelest ] , before being refined by the consistency checks of section [ sec : lipconsist ] as more data became available . from the limited results obtained , one does see that the estimation is sufficiently good from the safety perspective ",
    "the constants are conservative enough so as to keep the system from violating its two experimental constraints , and a close - to - optimal system efficiency is achieved without requiring too many iterations , which suggests that the constants are not _ too _ conservative .",
    "other experimental results have been obtained by applying an earlier version of the scfo to the problem of run - to - run controller tuning , where the tuning parameters of the controllers were treated as the decision variables , with different trajectory tracking metrics defined to judge controller performance for a given setpoint profile @xcite .",
    "the solver managed to successfully autotune a model - predictive controller for a water - tank system and a fixed - order controller for a mechanical torsional plant  however , these results are less validating since no experimental constraints were present and so it was impossible to evaluate the quality of the lipschitz - constant estimates with regard to their ability to enforce constraints . at the same time , the constants for the experimental cost function _ were _ used to help reduce the effects of variance in the cost - function values ( section [ sec : filter ] ) . while this is likely to have aided in the optimization",
    ", there is no way to say how much , as testing the quality of the lipschitz - constant estimators was not the goal of this largely proof - of - concept study .",
    "once again , no _ a priori _ models were used ",
    "the solver constructed a data - driven model from @xmath252 initial experiments , and then refined the initial estimates via the consistency checks .    in simulated tests ,",
    "a good quantity of results is now available for a number of case - study test problems , including six with experimental constraints , courtesy of the expopt database @xcite . examining the results of the scfo solver for these problems",
    "shows that the current estimation methods employed by the solver are certainly not perfect , and one can indeed have lipschitz - constant estimates that are not valid and that allow for constraint violations , although this varies significantly from problem to problem . for certain problems , the estimates are consistently good and violations are minimal , with the violations being of very small magnitude even when they are present .",
    "for other problems , violations may be larger and more frequent , but it is nevertheless rare to see consistently large constraint violations , suggesting that consistency checks are eventually able to improve on poor initial estimates .    with regard to results obtained for methods other than the scfo",
    ", an application of a data - driven approach of section [ sec : modelest ] has recently been reported by @xcite . here ,",
    "a modified version of g. e. p. box s evolutionary - operation method @xcite was proposed , with the lipschitz bound used to ensure that the experiments carried out by the algorithm would never violate the problem constraints .",
    "after each set of @xmath161 axially distributed experiments , the lipschitz constants were estimated locally as the derivatives of a linear model for the @xmath253 axial - plus - center data points , with additional conservatism added to the estimates to account for noise and nonlinearity effects .",
    "the end result was very satisfactory  in testing the algorithm for three problems from the expopt database , the estimated lipschitz constants were always sufficiently conservative and the experimental constraints were not violated once .",
    "it is the authors hope that the present document has helped convince the reader that lipschitz constants  despite being an implicit , age - old mathematical concept  may be made explicit and thereby bring multiple benefits to the experimental optimization domain .",
    "most importantly , the use of these constants appears to offer an extremely simple way to guarantee constraint satisfaction in problems with experimental constraints , which is something that may be exploited during both the optimization and information - gathering ( perturbation ) phases of the solution process .",
    "because constraint satisfaction may be immensely important in experimental settings , this alone presents a very strong argument for the implementation of lipschitz constants and bounds .",
    "additionally , it has been shown that these constants may play a useful role in reducing the effect of measurement or estimation uncertainty , which , depending on the optimization algorithm , may lead to significant performance improvements .",
    "there are no major implementation difficulties involved with the techniques described , and so it is the authors recommendation that these techniques be given consideration when approaching experimental optimization problems .",
    "this paper has also addressed the two major concerns regarding the use of lipschitz constants in practice  the concern that the set constants may be too conservative and the concern that they may be improperly set or estimated . both are valid and represent potential issues . however , as has been shown in section [ sec : refine ] , there do exist several ways to reduce conservatism ",
    "namely , one may tighten the bounds by exploiting direction , locality , and the potential convexity / concavity properties of the function . with regard to estimation , section [ sec : estim ]",
    "has outlined a number of methods to set and refine the lipschitz - constant estimates , and empirical evidence has shown that such methods can , in fact , be sufficient for many problems .",
    "the authors would like to thank professor dominique bonvin of the laboratoire dautomatique ( cole polytechnique fdrale de lausanne ) for his insights and input .",
    "42 natexlab#1#1[2]#2 ( ) . . .",
    ", , & ( ) . . , _",
    "_ , . , & ( ) . .",
    ". , & ( ) . . ,",
    "_ , . , & ( ) . .",
    ", & ( ) . . .",
    "( ) . . , _",
    "( ) . . , , & ( ) . . , _",
    "_ , . , , &",
    "( ) . . , _",
    ", , & ( ) . . , ( pp . ) . , , & ( ) . . , ( pp . ) . , , , & ( ) .",
    ". in _ _ ( pp . ) . , , &",
    "( ) . . , _",
    ", , & ( ) . . , _",
    ", , & ( ) . . .",
    ", , , & ( ) . .",
    "( ) . . , _",
    "( ) . . . , & ( ) . . , _",
    "_ , . , & ( ) . . in _",
    ", , & ( ) . . , _",
    "_ , . , & ( ) .",
    ", , , & ( ) . . , _",
    "_ , . , & ( ) . . ,",
    "_ , . , , & ( ) .",
    "( ) . . . , & ( ) . . . , , & ( ) . . , _",
    ", , & ( ) . . , _",
    ", , , & ( ) . . , _",
    ", , & ( ) . . ,",
    ", , & ( ) . . , _",
    ", , , , , , , & ( ) . . ,",
    "_ , . , & ( ) . . ,",
    "( ) . . . , , & ( ) . . . , , & ( ) . . , _",
    ", , & ( ) . . , _",
    "_ , . , & ( ) .",
    ", , & ( ) . . , _"
  ],
  "abstract_text": [
    "<S> the lipschitz constant of a response surface function upper bounds the sensitivity of a dependent variable to changes in the independent ones . traditionally , such constants have found much implicit and abstract use in mathematically oriented applications , but their potential for explicit use in more engineering - based domains has not been explored . the latter point is the subject of this paper , where we propose several ways in which the lipschitz constants may be used explicitly in the domain of _ experimental optimization_. specifically , we focus on how they may help ensure the satisfaction of constraints and on their potential role in reducing the negative effects of measurement or estimation uncertainty . a number of refinements to the proposed approaches are also derived , and some techniques for setting the constants are presented .    </S>",
    "<S> keywords : lipschitz constants , upper - bounding functions , experimental optimization , process constraints , real - time optimization </S>"
  ]
}