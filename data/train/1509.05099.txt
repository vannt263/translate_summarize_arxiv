{
  "article_text": [
    "qr models have become increasingly popular since the seminal work of @xcite .",
    "in contrast to the mean regression model , qr belongs to a robust model family , which can give an overall assessment of the covariate effects at different quantiles of the outcome @xcite . in particular , we can model the lower or higher quantiles of the outcome to provide a natural assessment of covariate effects specific for those regression quantiles .",
    "unlike conventional models , which only address the conditional mean or the central effects of the covariates , qr models quantify the entire conditional distribution of the outcome variable .",
    "in addition , qr does not impose any distributional assumption on the error , except requiring the error to have a zero conditional quantile .",
    "the foundations of the methods for independent data are now consolidated , and some statistical methods for estimating and drawing inferences about conditional quantiles are provided by most of the available statistical programs ( e.g. , r , sas , matlab and stata ) .",
    "for instance , just to name a few , in the well - known r package ` quantreg ( ) ` is implemented a variant of the @xcite simplex ( br ) for linear programming problems described in @xcite , where the standard errors are computed by the rank inversion method @xcite . another method implemented in this popular package is lasso penalized quantile regression ( lpqr ) , introduced by @xcite , where a penalty parameter is specified to determine how much shrinkage occurs in the estimation process .",
    "qr can be implemented in a range of different ways .",
    "@xcite provided an overview of some commonly used quantile regression techniques from a `` classical '' framework .",
    "@xcite considered median regression from a bayesian point of view , which is a special case of quantile regression , and discussed non - parametric modeling for the error distribution based on either plya tree or dirichlet process priors .",
    "regarding general quantile regression , @xcite proposed a bayesian modeling approach by using the ald , @xcite developed bayesian semi - parametric models for quantile regression using dirichlet process mixtures for the error distribution , @xcite studied quantile regression for longitudinal data using the ald .",
    "recently , @xcite developed a simple and efficient gibbs sampling algorithm for fitting the quantile regression model based on a location - scale mixture representation of the ald .",
    "an interesting aspect to be considered in statistical modelling is the diagnostic analysis .",
    "this can be carried out by conducting an influence analysis for detecting influential observations .",
    "one of the most technique to detect influential observations is the case - deletion approach .",
    "the famous approach of cook ( 1977 ) has been applied extensively to assess the influence of an observation in fitting a statistical model ; see @xcite and the references therein .",
    "it is difficult to apply this approach directly to the qr model because the underlying observed - data likelihood function is not differentiable at zero .",
    "@xcite presents an approach to perform diagnostic analysis for general statistical models that is based on the q - displacement function .",
    "this approach has been applied successfully to perform influence analysis in several regression models , for example , @xcite considered in multivariate @xmath0 distribution , @xcite obtained case - deletion measures for mixed - effects models following the @xcite s approach and in @xcite we can see some results about local influence for mixed - effects models obtained by using the q - displacement function .    taking advantage of the likelihood structure imposed by the ald , the hierarchical representation of the ald , we develop here an em - type algorithm for obtaining the ml estimates at the @xmath1th level , and by simulation studies our em algorithm outperformed the competing br and lpqr algorithms , where the standard error is obtained as a by - product .",
    "moreover , we obtain case - deletion measures for the qr model .",
    "since qr methods complement and improve established means regression models , we feel that the assessment of robustness aspects of the parameter estimates in qr is also an important concern at a given quantile level @xmath2 .",
    "the rest of the paper is organized as follows .",
    "section 2 introduces the connection between qr and ald as well as outlining the main results related to ald .",
    "section 3 presents an em - type algorithm to proceed with ml estimation for the parameters at the @xmath1th level .",
    "moreover , the observed information matrix is derived .",
    "section [ sec diagnostic ] provides a brief sketch of the case - deletion method for the model with incomplete data , and also develop a methodology pertinent to the ald .",
    "sections [ sec application ] and [ sec simulation study ] are dedicated to the analysis of real and simulated data sets , respectively .",
    "section 6 concludes with a short discussion of issues raised by our study and some possible directions for the future research .",
    "even though considerable amount of work has been done on regression models and their extensions , regression models by using asymmetric laplace distribution have received little attention in the literature . only recently",
    ", the a study on quantile regression model based on asymmetric laplace distribution was presented by tian et al .",
    "( 2014 ) who a derived several interesting and attractive properties and presented an em algorithm . before presenting our derivation ,",
    "let us recall firstly the definition of the asymmetric laplace distribution and after this , we will present the quantile regression model .      as discussed in @xcite",
    ", we say that a random variable y is distributed as an ald with location parameter @xmath3 , scale parameter @xmath4 and skewness parameter @xmath5 , if its probability density function ( pdf ) is given by @xmath6 where @xmath7 is the so called check ( or loss ) function defined by @xmath8 , with @xmath9 denoting the usual indicator function .",
    "this distribution is denoted by @xmath10 .",
    "it is easy to see that @xmath11 follows an exponential distribution @xmath12 .",
    "a stochastic representation is useful to obtain some properties of the distribution , as for example , the moments , moment generating function ( mgf ) , and estimation algorithm . for the ald @xcite , @xcite and",
    "@xcite presented the following stochastic representation : let @xmath13 and @xmath14 be two independent random variables .",
    "then , @xmath15 can be represented as @xmath16 where @xmath17 and @xmath18 , and @xmath19 denotes equality in distribution .",
    "figure [ fig : ald ] shows how the skewness of the ald changes with altering values for @xmath1 .",
    "for example , for @xmath20 almost all the mass of the ald is situated in the right tail . for @xmath21 ,",
    "both tails of the ald have equal mass and the distribution then equals the more common double exponential distribution .",
    "in contrast to the normal distribution with a quadratic term in the exponent , the ald is linear in the exponent .",
    "this results in a more peaked mode for the ald together with thicker tails . on the other hand ,",
    "the normal distribution has heavier shoulders compared to the ald .    ]    from ( [ st - ald ] ) , we have the hierarchical representation of the ald , see @xcite , given by @xmath22 this representation will be useful for the implementation of the em algorithm .",
    "moreover , since @xmath23 , then one can derive easily the pdf of @xmath24 .",
    "that is , the pdf in ( [ pdfal ] ) can be expressed as @xmath25 where @xmath26 , @xmath27 and @xmath28 , with @xmath29 being the modified bessel function of the third kind .",
    "it easy to see that that the conditional distribution of @xmath30 , given @xmath31 , is @xmath32 . here",
    ", @xmath33 denotes the generalized inverse gaussian ( gig ) distribution ; see @xcite for more details .",
    "the pdf of gig distribution is given by @xmath34 the moments of @xmath30 can be expressed as @xmath35=\\left(\\frac{a}{b}\\right)^{k}\\frac{k_{\\nu+k}(ab)}{k_{\\nu}(ab)},\\,\\,\\ k\\in \\mathbb{r}.\\ ] ] some properties of the bessel function of the third kind @xmath36 that will be useful for the developments here are : ( i ) @xmath37 ; ( ii ) @xmath38 ; ( iii ) for non - negative integer @xmath39 , @xmath40 .",
    "a special case is @xmath41 .",
    "+      let @xmath42 be a response variable and @xmath43 a @xmath44 vector of covariates for the @xmath45th observation , and let @xmath46 be the @xmath1th @xmath47 quantile regression function of @xmath42 given @xmath43 , @xmath48 .",
    "suppose that the relationship between @xmath46 and @xmath43 can be modeled as @xmath49 , where @xmath50 is a vector @xmath51 of unknown parameters of interest .",
    "then , we consider the quantile regression model given by @xmath52 where @xmath53 is the error term whose distribution ( with density , say , @xmath54 ) is restricted to have the @xmath1th quantile equal to zero , that is , @xmath55 .",
    "the error density @xmath54 is often left unspecified in the classical literature .",
    "thus , quantile regression estimation for @xmath50 proceeds by minimizing @xmath56 where @xmath7 is as in ( [ pdfal ] ) and @xmath57 is the quantile regression estimate for @xmath50 at the @xmath1th quantile .",
    "the special case @xmath21 corresponds to median regression .",
    "as the check function is not differentiable at zero , we can not derive explicit solutions to the minimization problem . therefore",
    ", linear programming methods are commonly applied to obtain quantile regression estimates for @xmath50 .",
    "a connection between the minimization of the sum in ( [ losseq ] ) and the maximum - likelihood theory is provided by the ald ; see @xcite .",
    "it is also true that under the quantile regression model , we have @xmath58 the above result is useful to check the model in practice , as will be seen in the application section .    now , suppose @xmath59 are independent observations such as @xmath60 @xmath61",
    ". then , from ( [ pdfals ] ) the log  likelihood function for @xmath62 can be expressed as @xmath63 where @xmath64 , with @xmath65 is a constant does not depend on @xmath66 and @xmath67 with @xmath68 and @xmath69 .    note that if we consider @xmath70 as a nuisance parameter , then the maximization of the likelihood in ( [ likel ] ) with respect to the parameter @xmath50 is equivalent to the minimization of the objective function in ( [ losseq ] ) . and hence the relationship between the check function and ald can be used to reformulate the qr method in the likelihood framework .    the log  likelihood function is not differentiable at zero .",
    "therefore , standard procedures the estimation can not be developed following the usual way .",
    "specifically , the standard errors for the maximum likelihood estimates is not based on the genuine information matrix . to overcome this problem we consider the empirical information matrix as will be described in the next subsection .      in this section",
    ", we discuss an estimation method for qr based on the em algorithm to obtain ml estimates .",
    "also , we consider the method of moments ( mm ) estimators , which can be effectively used as starting values in the em algorithm . here",
    ", we show how to employ the em algorithm for ml estimation in qr model under the ald . from the hierarchical representation ( [ hierar1])-([hierar2 ] ) , the qr model in ( [ qrmodel ] )",
    "can be presented as @xmath71 where @xmath72 and @xmath73 are as in ( [ st - ald ] ) .",
    "this hierarchical representation of the qr model is convenient to describe the steps of the em algorithm .",
    "let @xmath74 and @xmath75 be the observed data and the missing data , respectively .",
    "then , the complete data log - likelihood function of @xmath76 , given @xmath77 , ignoring additive constant terms , is given by @xmath78 , where @xmath79 for @xmath61 . in what follows the superscript @xmath80 indicates the estimate of the related parameter at the stage @xmath81 of the algorithm .",
    "the e - step of the em algorithm requires evaluation of the so - called q - function @xmath82 $ ] , where @xmath83 $ ] means that the expectation is being effected using @xmath84 for @xmath66 .",
    "observe that the expression of the q - function is completely determined by the knowledge of the expectations @xmath85,\\,\\,\\ , s=-1,1,\\end{aligned}\\ ] ] that are obtained of properties of the @xmath86 distribution .",
    "let @xmath87 be the vector that contains all quantities defined in ( [ weith ] ) .",
    "thus , dropping unimportant constants , the q - function can be written in a synthetic form as @xmath88 , where this quite useful expression to implement the m - step , which consists of maximizing it over @xmath66 .",
    "so the em algorithm can be summarized as follows : + _ e - step _ : given @xmath89 , compute @xmath90 through of the relation @xmath91=\\left(\\frac{\\delta^{(k)}_i}{\\gamma^{(k)}}\\right)^{s}\\frac{k_{1/2+s}\\big(\\lambda^{(k)}_i\\big)}{k_{1/2}\\big(\\lambda^{(k)}_i\\big ) } , s=-1,1,\\ ] ] where @xmath92 , @xmath93 and @xmath94 ; + _ m - step _ : update @xmath95 by maximizing @xmath96 over @xmath66 , which leads to the following expressions where @xmath97 denotes the diagonal matrix , with the diagonal elements given by @xmath98 and @xmath99 .",
    "a similar expression for @xmath100 is obtained in @xcite .",
    "this process is iterated until some distance involving two successive evaluations of the actual log - likelihood @xmath101 , like @xmath102 or @xmath103 , is small enough .",
    "this algorithm is implemented as part of the r package ` aldqr ( ) ` , which can be downloaded at not cost from the repository cran .",
    "furthermore , following the results given in @xcite , the mm estimators for @xmath50 and @xmath70 are solutions of the following equations : @xmath104 where @xmath72 is as ( [ st - ald ] ) .",
    "note that the mm estimators do not have explicit closed form and numerical procedures are needed to solve these non - linear equations .",
    "they can be used as initial values in the iterative procedure for computing the ml estimates based on the em - algorithm .",
    "standard errors for the maximum likelihood estimates is based on the empirical information matrix , that according to @xcite formula , is defined as @xmath105 where @xmath106 .",
    "it is noted from the result of @xcite that the individual score can be determined as @xmath107 .",
    "asymptotic confidence intervals and tests of the parameters at the @xmath1th level can be obtained assuming that the ml estimator @xmath108 has approximately a normal multivariate distribution .",
    "+ from the em algorithm , we can see that @xmath109 is inversely proportional to @xmath110 .",
    "hence , @xmath111 can be interpreted as a type of weight for the @xmath45th case in the estimates of @xmath112 , which tends to be small for outlying observations .",
    "the behavior of these weights can be used as tools for identifying outlying observations as well as for showing that we are considering a robust approach , as will be seen in sections 4 and 5 .",
    "case - deletion is a classical approach to study the effects of dropping the @xmath45th case from the data set .",
    "let @xmath113 be the augmented data set , and a quantity with a subscript `` @xmath114 $ ] '' denotes the original one with the @xmath45th observation deleted .",
    "thus , the complete - data log - likelihood function based on the data with the @xmath45th case deleted will be denoted by @xmath115})$ ] .",
    "let @xmath116}=(\\widehat{{\\mbox{${\\bm \\beta}$}}}^{\\top}_{p[i ] } , \\widehat{\\sigma^2}_{[i]})^{\\top}$ ] be the maximizer of the function @xmath117}({\\mbox{$ { \\bm \\theta}$}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})= \\textrm{e}_{\\scriptsize{\\widehat{{\\mbox{$ { \\bm \\theta}$}}}}}\\left[\\ell_{c}({\\mbox{$ { \\bm \\theta}$}}|{\\mathbf{y}}_{c[i]})|{\\mathbf{y}}\\right ] $ ] , where @xmath118 is the ml estimate of @xmath66 .",
    "to assess the influence of the @xmath45th case on @xmath108 , we compare the difference between @xmath116}$ ] and @xmath108 . if the deletion of a case seriously influences the estimates , more attention needs to be paid to that case .",
    "hence , if @xmath116}$ ] is far from @xmath108 in some sense , then the @xmath45th case is regarded as influential . as @xmath116}$ ] is needed for every case , the required computational effort can be quite heavy , especially when the sample size is large .",
    "hence , to calculate the case - deletion estimate @xmath119}$ ] of @xmath66 , ( see * ? ? ?",
    "* ) proposed the following one - step approximation based on the q - function , @xmath120}= \\widehat{{\\mbox{$ { \\bm \\theta}$}}}+ \\big\\ { -\\ddot{q}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big\\}^{-1 } \\dot{q}_{[i]}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}}),\\end{aligned}\\ ] ] where @xmath121}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})=\\displaystyle\\frac{\\partial{{q}_{[i]}({\\mbox{$ { \\bm \\theta}$}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})}}{\\partial{{\\mbox{$ { \\bm \\theta}$}}}}\\big\\vert_{{\\mbox{$ { \\bm \\theta}$}}=\\widehat{{\\mbox{$ { \\bm \\theta}$}}}},\\end{aligned}\\ ] ] are the hessian matrix and the gradient vector evaluated at @xmath108 , respectively .",
    "the hessian matrix is an essential element in the method developed by @xcite to obtain the measures for case - deletion diagnosis . for developing the case - deletion measures",
    ", we have to obtain the elements in ( [ theta1 ] ) , @xmath122}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})$ ] and @xmath123 .",
    "these formulas can be obtained quite easily from ( [ eqn qfunction ] ) :    1 .   the components of @xmath122}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})$ ] are 2 .",
    "the elements of the second order partial derivatives of @xmath124 evaluated at @xmath108 are @xmath125\\end{aligned}\\ ] ] and @xmath126 .    in the following result ,",
    "we will obtain the one - step approximation of @xmath116}=(\\widehat{{\\mbox{${\\bm \\beta}$}}}^{\\top}_{p[i ] } , \\widehat{\\sigma}_{[i]})^{\\top}$ ] , @xmath61 based on ( [ theta1 ] ) , viz .",
    ", the relationships between the parameter estimates for the full data set and the data with the @xmath45th case deleted .",
    "[ the;1 ] for the qr model defined in ( [ rephier1 ] ) and ( [ rephier2 ] ) , the relationships between the parameter estimates for full data set and the data with the @xmath45th case deleted are as follows : @xmath127}&= & \\widehat{{\\mbox{${\\bm \\beta}$}}}_p+   \\tau_p^{2 } \\big({\\mathbf{x}}^{\\top}d\\big(\\widehat{{\\mbox{$ { \\bm \\xi}$}}}_{-1}\\big){\\mathbf{x}}\\big)^{-1 } \\textbf{e}_{1[i]}\\,\\,\\ , \\ , \\,{\\rm and } \\,\\ , \\ , \\ , \\ , \\widehat{\\sigma^2}^1_{[i]}= \\widehat{\\sigma^2 } - \\frac{1}{2\\widehat{\\sigma^2}}\\big(\\ddot{q}_{\\sigma}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big)^{-1 } e_{2[i]},\\end{aligned}\\ ] ] where @xmath128}$ ] and @xmath129}$ ] are as in ( [ eqn e1i ] ) and ( [ eqn e2i ] ) , respectively .",
    "to asses the influence of the @xmath45th case on the ml estimate @xmath108 , we compare @xmath116}$ ] and @xmath108 based on metrics , proposed by @xcite , for measuring the distance between @xmath116}$ ] and @xmath108 . for that , we consider here the following ;    1 .   _",
    "generalized cook distance _ : @xmath130}-\\widehat{{\\mbox{$ { \\bm \\theta}$}}})^{\\top}\\big\\ { -\\ddot { q}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big\\}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}_{[i]}-\\widehat{{\\mbox{$ { \\bm \\theta}$ } } } ) , \\quad { i=1,\\ldots , n}.\\ ] ] upon substituting ( [ theta1 ] ) into ( [ gcd ] ) , we obtain the approximation @xmath131}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})^{\\top}\\big\\{-\\ddot{q}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big\\}^{-1 } \\dot{q}_{[i]}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$ } } } ) , \\quad { i=1,\\ldots , n}.\\ ] ] as @xmath123 is a diagonal matrix , one can obtain easily a type of generalized cook distance for parameters @xmath132 and @xmath70 , respectively , as follows @xmath133{\\mbox{${\\bm \\beta}$}}}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})^{\\top}\\big\\{-\\ddot{q}_{\\beta}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big\\}^{-1 } \\dot{q}_{[i]{\\mbox{${\\bm \\beta}$}}}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$ } } } ) , \\quad { i=1,\\ldots , n}.\\ ] ] @xmath134\\sigma}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})^{\\top}\\big\\{-\\ddot{q}_{\\sigma}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big\\}^{-1 } \\dot{q}_{[i]\\sigma}(\\widehat{{\\mbox{$ { \\bm \\theta}$}}}|\\widehat{{\\mbox{$ { \\bm \\theta}$ } } } ) , \\quad { i=1,\\ldots , n}.\\ ] ] 2 .   _ q - distance _",
    ": this measure of the influence of the @xmath45th case is based on the @xmath135-distance function , similar to the likelihood distance @xmath136 @xcite , defined as @xmath137}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big\\}.\\ ] ] we can calculate an approximation of the likelihood displacement @xmath138 by substituting ( [ theta1 ] ) into ( [ qd ] ) , resulting in the following approximation @xmath139 of @xmath138 : @xmath140}|\\widehat{{\\mbox{$ { \\bm \\theta}$}}})\\big\\}.\\ ] ]",
    "we illustrate the proposed methods by applying them to the australian institute of sport ( ais ) data , analyzed by cook and weisberg ( 1994 ) in a normal regression setting .",
    "the data set consists of several variables measured in @xmath141 athletes ( 102 males and 100 females ) . here , we focus on body mass index ( bmi ) , which is assumed to be explained by lean body mass ( lbm ) and gender ( sex ) .",
    "thus , we consider the following qr model : @xmath142 where @xmath53 is a zero @xmath1 quantile . this model can be fitted in the r software by using the package ` quantreg ( ) ` , where one can arbitrarily use the br or the lpqr algorithms . in order to compare with our proposed em algorithm",
    ", we carry out quantile regression at three different quantiles , namely @xmath143 by using the ald distribution as described in section 2 .",
    "the ml estimates and associated standard errors were obtained by using the em algorithm and the observed information matrix described in subsections 2.3 , respectively .",
    "table [ table.application ] compares the results of our em , br and the lpqr estimates under the three selected quantiles .",
    "the standard error of the lpqr estimates are not provided in the r package ` quantreg ( ) ` and are not shown in table [ table.application ] . from this table",
    "we can see that estimates under the three methods only exhibit slight differences , as expected . however , the standard errors of our em estimates are smaller than those via the br algorithm .",
    "this suggests that the em algorithm seems to produce more accurate estimates of the regression parameters at the @xmath1th level .",
    "[ table.application ]     confidence intervals for various values of @xmath1 .",
    "[ fig:2b],title=\"fig : \" ]     to obtain a more complete picture of the effects , a series of qr models over the grid @xmath144 is estimated .",
    "figure [ fig:2b ] gives a graphical summary of this analysis .",
    "the shaded area depicts the @xmath145 confidence interval from all the parameters . from figure [ fig:2b ]",
    "we can observe some interesting evidences which can not be detected by mean regression .",
    "for example , the effect of the two variables ( lbm and gender ) become stronger for the higher conditional quantiles , indicating that the bmi are positively correlated with the quantiles .",
    "the robustness of the median regression @xmath146 can be assessed by considering the influence of a single outlying observation on the em estimate of @xmath66 . in particular",
    ", we can assess how much the em estimate of @xmath66 is influenced by a change of @xmath147 units in a single observation @xmath148 .",
    "replacing @xmath148 by @xmath149 , where @xmath150 denotes the standard deviation .",
    "let @xmath151 be the em estimates of @xmath152 after contamination , @xmath153 .",
    "we are particularly interested in the relative changes @xmath154 . in this study",
    "we contaminated the observation corresponding to individual @xmath155 and for @xmath147 between 0 and 10 .",
    "figure [ fig : change ] displays the results of the relative changes of the estimates for different values of @xmath147 . as expected , the estimates from the median regression model are less affected by variations on @xmath147 than those of the mean regression .",
    "moreover , figure [ fig:2c ] shows the q - q plot and envelopes for mean and median regression , which are obtained based on the distribution of @xmath156 , given in ( [ wi ] ) , that follows @xmath12 distribution . the lines in these figures represent the 5th percentile , the mean and the @xmath157th percentile of @xmath158 simulated points for each observation .",
    "these figures clearly show that the median regression distribution provides a better - fit than the standard mean regression to the ais data set .",
    "+    , @xmath159 and @xmath160 in comparison with the true value , for median @xmath146 and mean regression , for different contaminations @xmath147 .",
    "[ fig : change],title=\"fig : \" ]  , @xmath159 and @xmath160 in comparison with the true value , for median @xmath146 and mean regression , for different contaminations @xmath147 .",
    "[ fig : change],title=\"fig : \" ]  , @xmath159 and @xmath160 in comparison with the true value , for median @xmath146 and mean regression , for different contaminations @xmath147 . [",
    "fig : change],title=\"fig : \" ]    , title=\"fig : \" ]     as discussed at the end of section 2.3 the estimated distance @xmath161 can be used efficiently as a measure to identify possible outlying observations .",
    "figure [ fig : mahal](left panel ) displays the index plot of the distance @xmath162 for the median regression model @xmath146 .",
    "we see from this figure that observations # 75 , # 162 , # 178 and # 179 appear as possible outliers . from the em - algorithm ,",
    "the estimated weights @xmath163 for these observations are the smallest ones ( see right panel in figure [ fig : mahal ] ) , confirming the robustness aspects of the maximum likelihood estimates against outlying observations of the qr models .",
    "thus , larger @xmath162 implies a smaller @xmath164 , and the estimation of @xmath66 tends to give smaller weight to outlying observations in the sense of the distance @xmath162 .",
    "figure [ fig:1b ] shows the estimated quartiles of two levels of gender at each lbm point from our em algorithm along with the estimates obtained via mean regression . from this figure",
    "we can see clear attenuation in @xmath159 due to the use of the median regression related to the mean regression .",
    "it is possible to observe in this figure some atypical individuals that could have an influence on the ml estimates for different values of quantiles . in this figure ,",
    "the individuals @xmath165 and @xmath166 were marked since they were detected as potentially influential .     and the estimated weights @xmath167.[fig : mahal],title=\"fig : \" ]   and the estimated weights @xmath167.[fig : mahal],title=\"fig : \" ]    , title=\"fig : \" ]  , title=\"fig : \" ]     + .",
    "( second row ) .",
    "index plot of approximate likelihood displacement @xmath168 .",
    "the influential observations are numbered.[pert3 ] , title=\"fig : \" ]  .",
    "( second row ) .",
    "index plot of approximate likelihood displacement @xmath168 .",
    "the influential observations are numbered.[pert3 ] , title=\"fig : \" ]  .",
    "( second row ) .",
    "index plot of approximate likelihood displacement @xmath168 .",
    "the influential observations are numbered.[pert3 ] , title=\"fig : \" ] + .",
    "( second row ) .",
    "index plot of approximate likelihood displacement @xmath168 .",
    "the influential observations are numbered.[pert3 ] , title=\"fig : \" ]  .",
    "( second row ) .",
    "index plot of approximate likelihood displacement @xmath168 .",
    "the influential observations are numbered.[pert3 ] , title=\"fig : \" ]  .",
    "( second row ) .",
    "index plot of approximate likelihood displacement @xmath168 .",
    "the influential observations are numbered.[pert3 ] , title=\"fig : \" ] +    in order to identify influential observations at different quantiles when some observation is eliminated , we can generate graphs of the generalized cook distance @xmath169 , as explained in section [ sec diagnostic ] .",
    "a high value for @xmath170 indicates that the @xmath45th observation has a high impact on the maximum likelihood estimate of the parameters .",
    "following @xcite , we can use @xmath171 as benchmark for the @xmath170 at different quantiles .",
    "figure [ pert3 ] ( first row ) presents the index plots of @xmath169 .",
    "we note from this figure that , only observation @xmath172 appears as influential in the ml estimates at @xmath20 and observations @xmath173 as influential at @xmath21 , whereas observations @xmath174 and @xmath175 appear as influential in the ml estimates at @xmath176 .",
    "figure [ pert3 ] ( second row ) presents the index plots of @xmath168 . from this figure",
    ", it can be noted that observations @xmath177 appear to be influential at @xmath20 , whereas observations @xmath178 and @xmath166 seem to be influential in the ml estimates at @xmath20 , and in addition observation @xmath175 appears to be influential at @xmath176 .",
    "in this section , the results from two simulation studies are presented to illustrate the performance of the proposed method .",
    "we conducted a simulation study to assess the performance of the proposed em algorithm , by mimicking the setting of the ais data by taking the sample size @xmath179 .",
    "we simulated data from the model    @xmath180    where the @xmath181 are simulated from a uniform distribution ( u(0,1 ) ) and the errors @xmath182 are simulated from four different distributions : @xmath183 the standard normal distribution @xmath184 , @xmath185 a student - t distribution with three degrees of freedom , @xmath186 , @xmath187 a heteroscedastic normal distribution , @xmath188 and , @xmath189 a bimodal mixture distribution @xmath190 .",
    "the true values of the regression parameters were taken as @xmath191 . in this way",
    ", we had four settings and for each setting we generated @xmath192 data sets .",
    "once the simulated data were generated , we fit a qr model , with @xmath193 and @xmath194 , under barrodale and roberts ( br ) , lasso ( lasso ) and em algorithms by using the `` quantreg ( ) '' package and our ` aldqr ( ) ` package , from the r language , respectively . for the four scenarios",
    ", we computed the bias and the square root of the mean square error ( rmse ) , for each parameter over the @xmath195 replicas .",
    "they are defined as : @xmath196 where @xmath197 and @xmath198 with @xmath199 or @xmath70 , @xmath200 is the estimate of @xmath201 obtained in replica @xmath45 and @xmath201 is the true value .",
    "table [ table.simul1 ] reports the simulation results for @xmath202 and @xmath194 .",
    "we observe that the em yields lower biases and rmse than the other two estimation methods under all the distributional scenarios .",
    "this finding suggests that the em would produce better results than other alternative methods typically used in the literature of qr models .",
    "[ table.simul1 ]      we also conducted a simulation study to evaluate the finite - sample performance of the parameter estimates .",
    "we generated artificial samples from the regression model ( [ simulation_1 ] ) with @xmath191 and @xmath203 .",
    "we chose several distributions for the random term @xmath53 a little different than the simulation study 1 , say , @xmath183 normal distribution @xmath204 ( n1 ) , @xmath185 a student - t distribution @xmath205 ( t1 ) , @xmath187 a heteroscedastic normal distribution , @xmath206 ( n2 ) and , @xmath189 a bimodal mixture distribution @xmath207 ( t2 ) .",
    "finally , the sample sizes were fixed at @xmath208 @xmath209 and @xmath210 .    for each combination of parameters and sample sizes ,",
    "@xmath192 samples were generated under the four different situations of error distributions ( n1 , t1 , n2 , t2 ) .",
    "therefore , 36 different simulation runs are performed .",
    "once all the data were simulated , we fit the qr model with @xmath21 and the bias ( [ bias ] ) and the square root of the mean square error ( [ eqm ] ) were recorded .",
    "the results are shown in figure [ fig:77a ] .",
    "we can see a pattern of convergence to zero of the bias and mse when @xmath211 increases . as a general rule",
    ", we can say that bias and mse tend to approach to zero when the sample size increases , indicating that the estimates based on the proposed em - type algorithm do provide good asymptotic properties . this same pattern of convergence to zero",
    "is repeated considering different levels of the quantile @xmath1 .    , @xmath160 , @xmath212 with @xmath21 ( median regression ) , where @xmath213 , @xmath214 , @xmath215 and @xmath216 .[fig:77a],title=\"fig : \" ]  , @xmath160 , @xmath212 with @xmath21 ( median regression ) , where @xmath213 , @xmath214 , @xmath215 and @xmath216 .[fig:77a],title=\"fig : \" ] + , @xmath160 , @xmath212 with @xmath21 ( median regression ) , where @xmath213 , @xmath214 , @xmath215 and @xmath216 .[fig:77a],title=\"fig : \" ]  , @xmath160 , @xmath212 with @xmath21 ( median regression ) , where @xmath213 , @xmath214 , @xmath215 and @xmath216 .[fig:77a],title=\"fig : \" ] + , @xmath160 , @xmath212 with @xmath21 ( median regression ) , where @xmath213 , @xmath214 , @xmath215 and @xmath216 .[fig:77a],title=\"fig : \" ]  , @xmath160 , @xmath212 with @xmath21 ( median regression ) , where @xmath213 , @xmath214 , @xmath215 and @xmath216 .[fig:77a],title=\"fig : \" ] +",
    "we have studied a likelihood - based approach to the estimation of the qr based on the asymmetric laplace distribution ( ald ) . by utilizing the relationship between the qr check function and the ald",
    ", we cast the qr problem into the usual likelihood framework .",
    "the mixture representation of the ald allows us to express a qr model as a normal regression model , facilitating the implementation of an em algorithm , which naturally provides the ml estimates of the model parameters with the observed information matrix as a by product .",
    "the em algorithm was implemented as part of the r package _ aldqr()_. we hope that by making the code of our method available , we will lower the barrier for other researchers to use the em algorithm in their studies of quantile regression .",
    "further , we presented diagnostic analysis in qr models , which was based on the case - deletion technique suggested by @xcite and @xcite , which are the counterparts for missing data models of the well - known ones proposed by @xcite and @xcite .",
    "the simulation studies demonstrated the superiority of the proposed methods to the existing methods , implemented in the package ` quantreg ( ) ` .",
    "we applied our methods to a real data set ( freely downloadable from r ) in order to illustrate how the procedures can be used to identify outliers and to obtain robust ml parameter estimates . from these results , it is encouraging that the use of ald offers a better alternative in the analysis of qr models .    finally , the proposed methods can be extended to a more general framework , such as , censored ( tobit ) regression models , measurement error models , nonlinear regression models , stochastic volatility models , etc and should yield satisfactory results at the expense of additional complexity in implementation .",
    "an in - depth investigation of such extensions is beyond the scope of the present paper , but these are interesting topics for further research .",
    "the research of v. h. lachos was supported by grant 305054/2011 - 2 from conselho nacional de desenvolvimento cientfico e tecnolgico ( cnpq - brazil ) and by grant 2014/02938 - 9 from fundao de amparo  pesquisa do estado de so paulo ( fapesp - brazil ) ."
  ],
  "abstract_text": [
    "<S> to make inferences about the shape of a population distribution , the widely popular mean regression model , for example , is inadequate if the distribution is not approximately gaussian ( or symmetric ) . </S>",
    "<S> compared to conventional mean regression ( mr ) , quantile regression ( qr ) can characterize the entire conditional distribution of the outcome variable , and is more robust to outliers and misspecification of the error distribution . </S>",
    "<S> we present a likelihood - based approach to the estimation of the regression quantiles based on the asymmetric laplace distribution ( ald ) , which has a hierarchical representation that facilitates the implementation of the em algorithm for the maximum - likelihood estimation . </S>",
    "<S> we develop a case - deletion diagnostic analysis for qr models based on the conditional expectation of the complete - data log - likelihood function related to the em algorithm . </S>",
    "<S> the techniques are illustrated with both simulated and real data sets , showing that our approach out - performed other common classic estimators . </S>",
    "<S> the proposed algorithm and methods are implemented in the r package ` aldqr ( ) ` . </S>",
    "<S> + * keywords * : quantile regression model ; em algorithm ; case - deletion model ; asymmetric laplace distribution . </S>"
  ]
}