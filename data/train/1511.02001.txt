{
  "article_text": [
    "the prediction of wind speed over different time scales is one of the tasks of weather agencies with the widest range of applications .",
    "arguably , the most important application is wind power forecasting , which is gaining enormous significance with many countries and regions introducing policies to increase the use of renewable energy : the european union is aiming ( by 2020 ) to increase the amount of renewable energy to 20% of the energy supply , with wind power playing a key role [ @xcite ] ; the u.s .",
    "department of energy ( doe ) describes a scenario in which wind energy could provide 20% of the u.s .",
    "electricity demand in 2030 [ @xcite ] ; legislation in china declares the usage of renewable energy a prioritized area in energy development [ @xcite ] .",
    "probabilistic wind power forecasts are most useful , as they permit its optimal management and trading [ @xcite ] , and one possibility to obtain them is by converting probabilistic forecasts of wind speed to power based on stochastic power curves [ @xcite ] .",
    "accurate forecasts of wind speed are not only required for wind power prediction , but are crucially important also in connection with severe weather warnings for the general public .",
    "warnings may be issued either based on wind speed forecasts directly or based on forecasts of wind gusts , which can be derived from the former using gust factors [ @xcite ] .",
    "further applications where wind speed forecasts are required include risk assessment and decision making in aviation , ship routing , recreational boating and agriculture .",
    "again , it has been argued that principled risk management should be based on probabilistic forecasts that take the form of predictive probability distributions for future quantities or events [ @xcite ] .    to provide probabilistic forecasts with lead times between a few hours up to several days , an increasing number of weather centers are running ensemble prediction systems ( epss ) . instead of a single forecast , several different forecasts @xmath0a so - called ensemble ",
    "are generated , with ensemble members corresponding to model integrations that differ in the initial conditions and/or the numerical representation of the atmosphere [ @xcite ] .",
    "combinations of ensemble member forecasts are often more accurate than any of these forecasts individually , and their spread provides useful information on the flow - dependent uncertainty . if the forecasts @xmath0 are interpreted as a sample of a predictive distribution , the corresponding empirical cumulative distribution function ( cdf ) can be formed , and probabilistic forecasts can be derived from it .",
    "it turns out , however , that these _ raw ensemble forecasts _ are often underdispersive and capture only part of the forecast uncertainty [ @xcite ] .",
    "moreover , forecasts may suffer from systematic biases due to structural model deficiencies shared among all ensemble members or due to insufficient resolution . to overcome these deficiencies and provide calibrated ,",
    "probabilistic forecasts , methods for statistical post - processing of ensemble forecasts have been proposed . here",
    ", we focus on approaches that transform the ensemble forecasts into a full predictive cdf .",
    "these methods are appealing because one can derive prediction intervals , probabilities of threshold exceedance , etc . from the predictive cdfs in a consistent way .",
    "furthermore , for any decision problem that can be expressed in terms of a scoring function ( loss function ) , an optimal point forecast can be derived from the predictive distribution using the bayes rule [ @xcite ] .",
    "the common idea of all methods for statistical post - processing is that forecast - observation pairs from the past can be used to identify shortcomings of the raw ensemble , and generate predictive distributions that do not suffer from these shortcomings",
    ". examples of such methods for wind speed ensemble forecasts include adaptations of the nonhomogeneous gaussian regression ( ngr ) approach [ @xcite ] and adaptations of the bayesian model averaging ( bma ) technique [ @xcite ] . instead of gaussian distributions , @xcite , @xcite and baran , nemoda and hornyi ( @xcite ) use gamma distributions as the building block for their predictive bma densities .",
    "@xcite use predictive truncated normal distributions ; @xcite further extended this approach and use either truncated normal distributions or generalized extreme value distributions , depending on whether the forecasts suggest a low or high wind regime .",
    "all of these approaches have been demonstrated to be able to generate calibrated and sharp predictive distributions , which is the goal in probabilistic forecasting [ @xcite ] .",
    "they can be applied either to stations individually and use only the local wind speed forecasts and observations as training data , or they can pool data across the forecast domain and estimate a single set of model parameters that is valid on all locations .",
    "@xcite studied both approaches and found that the local method yields better results than the regional method , as it allows the post - processing to adapt to local peculiarities .",
    "it entails , however , a new challenge that none of the above - mentioned articles have dealt with : when forecasts are desired at locations where no wind speed measurements are available , either the post - processing parameters or the parameters of the predictive distributions must be interpolated to those locations . in operational practice ,",
    "forecasts are usually provided on a regular model grid , and the interpolation of local forecasts to this grid is referred to as _",
    "gridding_. @xcite and @xcite have proposed procedures for the gridding of bma- and ngr - based probabilistic forecasts for temperature . in this paper",
    "we will do the following :    * compare three different ngr type approaches for probabilistic wind speed forecasting based on truncated normal , gamma and truncated logistic distributions ; * adapt the model fitting concept by @xcite of splitting post - processing parameters into local and regional ones , thus achieving a good compromise between local adaptivity and parsimony of the ngr model ; * study and compare different geostatistical models for the gridding of probabilistic wind speed forecasts , placing special emphasis on the adequate consideration of spatial heterogeneity and small scale variability of observed wind speeds .    after providing some details on the data used in our study in section  [ sec:2 ]",
    ", some exploratory analysis is performed .",
    "we briefly review the ngr type approach by @xcite in section  [ sec:3 ] , and propose two alternative methods that use predictive gamma and truncated logistic distributions , but are otherwise similar .",
    "a description of the corresponding model fitting procedure , in which the continuous ranked probability score ( crps ) is minimized , is also given in this section . in section  [ sec:4 ] , we address the interpolation problem mentioned above , propose a geostatistical interpolation scheme that incorporates information on local annual mean wind speeds , and use this model for obtaining gridded forecasts .",
    "the performance of the different methods with our data set is assessed in section  [ sec:5 ] , and conclusions are drawn about the optimal training sample size , predictive distribution and interpolation scheme , before summing up and discussing directions for further extensions .",
    "mathematical details about the derivation of closed - form expressions for the crps of gamma and truncated logistic distributions are provided in the .",
    "we consider surface ( 10  m ) wind forecasts by the cosmo - de - eps ( consortium for small - scale modelling ) , a multi - analysis and multi - physics ensemble prediction system based on the high - resolution ( 2.8 km horizontal grid size ) numerical weather prediction model cosmo - de [ @xcite ] .",
    "the cosmo - de - eps has been operational at the german weather service ( dwd ) since may 22 , 2012 .",
    "it was run under the same conditions in a pre - operational phase since 9 december 2010 , consists of @xmath1 ensemble members , covers the area of germany , and produces forecasts with lead times up to 21 hours .",
    "a new model run is started every three hours ; we use the one initialized at 0000 utc and study forecasts at 0600 , 1200 and 1800 utc .",
    "the current setup of the lateral boundary conditions uses forecasts of four different global models , while five different ( fixed ) configurations of the cosmo - de model are used for the variation of model physics [ @xcite ] .",
    "thus , all 20 ensemble members have individually distinguishable physical features and are _ not exchangeable_. the cosmo model uses a rotated spherical coordinate system in order to project the geographical coordinates to the plane with distortions as small as possible [ @xcite , section  3.3 ] , with @xmath2 equidistant gridpoints in longitudinal and latitudinal direction .",
    "we adopt this coordinate system to calculate horizontal distances in the framework of our post - processing method .",
    "both raw and post - processed forecasts are verified against surface wind speed observations ( 10-minute average wind speed 10  m above the ground ) at 286 surface synoptic observation ( synop ) stations in germany .",
    "stations with nonmissing data on less than 200 days in either 2011 or 2012 have been left out .",
    "the station at berlin alexanderplatz has been left out , too , since the magnitude of the observations at this site suggests that measurements have actually been taken at the top of the fernsehturm ( tv tower ) , and hence can not be considered 10  m wind speeds .",
    "the ensemble forecasts are originally given as the zonal and meridional component of 10  m wind vectors , and we take the euclidean norm of these vectors as the overall wind speed forecasts and interpolate them to the observation sites via bilinear interpolation . in this paper ,",
    "the aim is to forecast local observations rather than representative averages over model grid cells , and we neglect measurement errors and take the wind speed observations as the truth .    the gridded high - resolution ( 200  m horizontal grid size ) data of annual mean wind speeds over germany , which is used as a covariate in our spatial interpolation scheme in section  [ sec:4 ] , was also obtained from dwd .",
    "it is constructed based on measurements at 218 synop stations over germany during the period from 1981 to 2000 , which were adjusted for obstacles , and gridded using the statistical wind field model described in the european wind atlas [ @xcite ] .",
    "values at the station locations and the cosmo - de model grid were derived from this high resolution map using bilinear interpolation .",
    "figure  [ fig : timeseries ] shows time series of the 20 ensemble forecasts and the corresponding observations at three different locations in germany . for mannheim , a city in southwestern germany , and helgoland , a small german archipelago in the north sea ,",
    "the forecasts are generally quite accurate , but the spread of the ensemble seems a bit low .",
    "if the ensemble forecasts and the observation were drawn from the same distribution , the observation would be contained within the ensemble range on @xmath3 of all days , which does not quite seem to be the case .",
    "the forecasts at zugspitze , germany s highest mountain ( located at the border to austria ) , suffer from a systematic underforecasting bias as a result of incompletely resolved orography by the numeric weather prediction scheme .",
    "this illustrates why a regional post - processing approach , which assumes constant model parameters over the entire domain of interest , is usually unable to fully remove local biases .",
    "this need for location - specific post - processing is further underscored by the scatterplots in figure  [ fig : scatterplot ] , which also show that the magnitude of forecast error varies from one location to another .",
    "furthermore , we note certain differences in the predictability of wind speeds between different seasons .",
    "for the post - processing of wind speed ensemble forecasts , @xcite proposed an adaptation of the nonhomogeneous gaussian regression approach by @xcite to nonnegative quantities , replacing normal by truncated normal predictive distributions @xmath4 with a cutoff ( lower bound ) at zero .",
    "specifically , given ensemble forecasts @xmath5 , they define the predictive distribution through @xmath6 here , @xmath7 denotes the ensemble variance , and @xmath8 denotes the ensemble mean .",
    "this type of post - processing method that fits a probability distribution model to model output statistics ( mos ) of an ensemble is also referred to as emos . another post - processing approach based on bayesian model averaging [ bma , @xcite ] was proposed by @xcite . in their example , gamma distributions were found to be a good model for the conditional distribution of wind speed observations given the forecast .",
    "while we prefer the emos approach over bma due to its conceptual simplicity , we also study a variant of ( [ eq : truncnorm - model ] ) that uses predictive gamma distributions @xmath9 here , the gamma distribution is parametrized in terms of its mean @xmath10 and variance @xmath11 , which relate to the shape parameter @xmath12 and a rate parameter @xmath13 of the standard parametrization via @xmath14 and @xmath15 .",
    "yet another distribution type for wind speed observations conditional on ensemble forecasts , the left - censored logistic distribution , has recently been proposed by @xcite ( @xcite ) .",
    "left - censoring a distribution at zero entails a positive probability of observed wind speeds being exactly zero .",
    "truncation at zero , on the contrary , implies that observed wind speeds can be very small , but are never exactly zero .",
    "we favor that latter perspective and consider , as a further alternative , an emos approach based on truncated logistic distributions @xmath16 the parameters @xmath10 and @xmath11 are the mean and the variance of the logistic distribution before truncation .",
    "the common parametrization employs a scale parameter @xmath17 , which relates to the variance via @xmath18 .",
    "the truncated logistic distribution resembles the truncated normal distribution but has heavier tails ( higher kurtosis ) .",
    "we apply all three models to wind speed forecasts and observations directly , that is , without any prior transformation of the data .",
    "all of the predictive distribution models considered here depend on the parameters @xmath19 which must be estimated based on training data .",
    "this training data usually consists of forecast - observation pairs from the past , with the exact choice of training days depending on the weather variable under consideration , the geographic location of the forecast domain , etc .",
    "temperature , for example , has a pronounced seasonal cycle , and often also the associated forecast error statistics of the nwp model are different in different seasons . in that case , it is therefore best to use a relatively short rolling training period ( i.e. , typically around 20 to 30 days immediately preceding the forecast day ) , so that the fitted parameters can quickly adapt to seasonal changes .",
    "the scatterplots in figure  [ fig : scatterplot ] suggest that for 10  m wind speeds , too , the optimal model parameters may change over the course of the year , but seasonal differences still seem to be smaller than differences between different locations .",
    "the bias  variance trade - off that has to be made when choosing the training sample size is therefore likely to favor longer training periods than those typically used for temperature .",
    "however , even if a training period of , let s say , 100 days is used for model fitting , estimating a different set of parameters @xmath19 for each location is prohibitive in the present case where we have @xmath1 nonexchangeable ensemble members and thus 23 model parameters overall . to compromise between local adaptivity and stability of the parameter estimates , we therefore adopt a similar approach as @xcite , and reparametrize our models ( [ eq : truncnorm - model ] ) , ( [ eq : gamma - model - mu - sigma ] ) and ( [ eq : trunlogis - model ] ) in such a way that only three parameters are location - specific , while all remaining parameters are assumed constant over the entire domain .",
    "specifically , if we denote by @xmath20 and @xmath21 the mean and variance parameter of the predictive distribution at location @xmath22 , we let @xmath23 additive and multiplicative bias correction is controlled by the location - specific parameters @xmath24 and @xmath25 , while @xmath26 are nonnegative weights that are constrained to sum up to one and constant over the entire domain . the underlying assumption is that biases vary strongly in space ( if they are due to incompletely resolved orography , over- and underforecasting biases may occur in close vicinity ) , while the relative performance of the different ensemble members depends on the weather situation rather than the location . in the same way",
    ", prediction uncertainty is described by a local parameter @xmath27 that will be defined below and two universal parameters @xmath28 and @xmath29 that control the scaling and relative contribution of the ensemble variance @xmath30 .",
    "model fitting is then performed in two steps .",
    "first , a simplified model @xmath31 is fitted separately at each observation location .",
    "this model has only three parameters @xmath32 for which reliable estimates can be obtained even with a training data set of size 30 to 80 .",
    "the estimated local parameters are then kept fixed , data from all locations are pooled , and the weights @xmath26 and variances parameters @xmath33 of the full model ( [ eq : re - parametrization ] ) are estimated in a second step . in this step",
    "the assumption of homoscedasticity implied by ( [ eq : simplified - model ] ) is relaxed , and nonhomogeneous variances are allowed .",
    "in contrast to generalized linear models , the variance is , however , not related to the mean , but becomes nonhomogeneous through the use of the additional predictor variable @xmath30 , which provides information about the flow - dependent forecast uncertainty . in both model fitting steps , parameter estimation is performed as in @xcite , that is , the model parameters are chosen such that the corresponding predictive distributions  calculated with the training forecasts ",
    "attain minimal continuous ranked probability score [ crps , @xcite ] when evaluated with the training observations .",
    "the crps is a proper scoring rule and can be used to rate the sharpness and calibration of a probabilistic forecast [ @xcite ] . for a single predictive cumulative distribution function @xmath34 and a verifying observation @xmath35 , it is defined as",
    "@xmath36 crps minimization is a robust alternative to maximum likelihood estimation , which is equivalent to the minimization of the logarithmic score . for the optimization to be computationally efficient",
    ", a closed - form expression of the above integral must be found .",
    "for truncated normal distributions , @xcite show that @xmath37,\\end{aligned}\\ ] ] where @xmath38 denotes the pdf and @xmath39 denotes the cdf of the standard normal distribution . in appendix",
    "[ sec : a ] we derive the following expression for the crps of a gamma distribution with shape parameter @xmath12 and rate parameter @xmath13 : @xmath40 where @xmath41 denotes the beta function . in appendix",
    "[ sec : b ] we show that the crps of a truncated logistic distribution with location parameter @xmath10 and scale parameter @xmath17 is given by @xmath42,\\end{aligned}\\ ] ] where @xmath43 , and @xmath44 . for the minimization of the average crps over all training data , we use the constrained optimization algorithm l - bfgs - b [ @xcite ] , which allows us to enforce the constraints @xmath45 and @xmath46 for all three predictive distribution models and the additional constraint @xmath47 for the gamma distribution model .",
    "the methods described in section  [ sec:3 ] permit location - specific calibration of ensemble wind speed forecasts . since both local mean and variance parameters @xmath20 and @xmath21 depend on site - specific post - processing parameters @xmath48 and @xmath27 , we face the challenge of interpolating the local predictive distributions to nonobservational sites such as the gridpoints of the forecast model grid . to do that , one can either interpolate @xmath20 and @xmath21 directly , or one can interpolate the model parameters @xmath48 and @xmath27 , and use them to calculate @xmath20 and @xmath21 according to ( [ eq : re - parametrization ] ) .    in this paper",
    "we perform spatial interpolation using a statistical interpolation method referred to as _ kriging_. this technique",
    "is based on the assumption that the quantity to be interpolated can be considered a realization of a gaussian random field ( grf ) , and its success depends on whether the spatial dependence structure of this grf is described appropriately .",
    "figure  [ fig : scalingillustration ] gives an idea about the prospective challenges with the interpolation of the different parameters mentioned above .",
    "although the scale and the units are different , the plots in this figure help us identify patterns in the spatial structure of the depicted parameters .",
    "the intercept parameter @xmath24 , for example , varies rather smoothly in northern germany , and spatial correlations could be modeled well as a function of the geographical distance . in the mountainous regions in central and especially southern germany , however , substantial small - scale variability can be observed , which makes it rather difficult to find a reasonably simple model for spatial dependence .",
    "erratic small - scale departures from an otherwise smooth spatial trend are even more pronounced with the slope parameter @xmath25 . its interrelation with @xmath24 impedes an unambiguous physical interpretation of these parameters .",
    "a large value of @xmath24 can be indicative of limited forecast skill when it is accompanied by a smaller value of @xmath25 .",
    "this is the situation that we would expect for mannheim and zugspitze in spring and summer ( see figure  [ fig : scatterplot ] ) .",
    "however , locations with similar forecast skill can still have different values of @xmath24 if the order of magnitude of wind speeds at these locations is very different , which is the case , for example , with mannheim and helgoland during the winter season .",
    "a large value of @xmath25 can be indicative of good forecast skill but can also result from an underforecasting bias ( e.g. , at zugspitze during winter , see figure  [ fig : scatterplot ] ) . for wind speed",
    "there is no straightforward way to reparametrize equations ( [ eq : truncnorm - model])([eq : trunlogis - model ] ) in such a way that bias , forecast skill and order of magnitude of the observed values can be unambiguously attributed to different parameters . interpolating the parameter @xmath20 rather than",
    "@xmath24 and @xmath25 partly avoids this problem , but small - scale variations are still an issue that has to be dealt with . with @xmath20 having the relatively straightforward interpretation of being the expected wind speed ( up to truncation ) , information about local wind speed climatologies can be used to explain regional and local differences .",
    "such information is available in the form of gridded annual average wind speeds @xmath49 over germany in the reference period from 1981 to 2000 .",
    "while @xmath20 varies strongly from day to day , large values of @xmath20 are much more likely to be observed at locations where wind speeds are also high on the annual average .",
    "indeed , the spatial patterns of @xmath20 and @xmath49 in figure  [ fig : scalingillustration ] are visually similar , and after dividing by @xmath49 , some of the small - scale irregularities of @xmath20 are strongly reduced .     and @xmath50 , and parameters @xmath20 and @xmath51 of the predictive distributions for wind speed at all station locations on 3 january 2012 , 1800 utc .",
    "also shown is the average wind speed @xmath49 at those locations and rescaled versions of @xmath20 and @xmath51 . ]",
    "those that are still present ( or have even been amplified by the scaling ) are often observed in regions where strong small - scale differences are present also in the annual mean , for example , near mountain peaks . an additional way of leveraging the information contained in @xmath49 is therefore to model an increase of variability between pairs of locations not just as a function of geographic distance , but also as a function of their difference in @xmath49 . to formalize these ideas ,",
    "we denote by @xmath52 the set of all locations within the forecast domain and consider @xmath53 , a realization of an intrinsic grf @xmath54 with generalized covariance function @xmath55 .",
    "we then study and compare several models for spatial dependence :    intrinsically stationary brownian surface plus nugget effect @xmath56    intrinsically stationary fractional brownian surface plus nugget effect @xmath57    locally scaled brownian surface plus nugget effect @xmath58    locally scaled brownian surface with an added dimension plus nugget effect @xmath59    in all of these models , @xmath60 denotes the indicator function , @xmath61 is the distance between @xmath22 and @xmath62 , and the model parameters @xmath63 are constrained to be nonnegative .",
    "model ( a ) is our basic model and relatively simple .",
    "it has only two parameters which reflect the relative impact of the brownian surface component and the so - called _ nugget effect _ component , which accounts for unresolved small - scale variability .",
    "the corresponding generalized covariance function is _ conditionally positive definite _ with respect to the linear function space that contains the constant functions [ cf .",
    "@xcite , or @xcite , for technical details on intrinsic grfs ] .",
    "it is closely related to the exponential covariance function which has an additional _ range parameter _",
    "@xmath64 describing how fast correlations decay with distance . the generalized covariance function of model ( a ) can be viewed as a limiting case when @xmath64 tends to infinity and the variance is adjusted such that the local characteristics of the corresponding grf remain unchanged . in our experiments with the exponential covariance ,",
    "model estimates of @xmath64 were very large on most of the days , and so we decided to use the more parsimonious brownian surface model .",
    "the brownian surface model ( a ) is a special case of the fractional brownian surface model ( b ) , which contains an additional model parameter @xmath65 that controls both fractal dimension of the realizations and growth rate of the variability between two locations with distance .",
    "thus , it offers an additional degree of flexibility , but it still assumes intrinsic stationarity of @xmath66 , although the above discussion of figure  [ fig : scalingillustration ] suggests that this assumption is inappropriate .",
    "our next covariance model therefore gets back to the idea of rendering @xmath20 more homogeneous by dividing it by @xmath49 .",
    "this kind of rescaling is equivalent to describing the spatial correlations of the original parameter by covariance model ( c ) , which is again based on the very basic brownian surface model but becomes nonstationary through scaling .",
    "note the difference in the use of covariate information compared to @xcite who use elevation data to explain spatial variations in temperature . in their kriging model ,",
    "the covariate information is used to define an external drift [ e.g. , @xcite , section  5.7.2 ] , imposing restrictions on the kriging weights that force them to be consistent with the covariates . here , the covariates are used for rescaling the interpolated variables , which also affects the covariance structure and accounts for the fact that in regions where @xmath20 tends to be large the magnitude of spatial variability tends to be large as well . as a consequence of rescaling , covariance model ( c ) is conditionally positive definite with respect to the linear function space spanned by @xmath49 ( rather than the constant functions ) , and this must be taken into account when setting up the restricted log likelihood and the kriging system ( see below ) .    our second suggestion from above to leverage the information contained in @xmath49 in order to account for the small - scale variability of @xmath67 is implemented in model  ( d )",
    "the two - dimensional index space @xmath52 is augmented by a further dimension  the average wind speed dimension  which makes it possible to explain large differences between locations that are geographically close by , but have very different wind speed climatologies .",
    "technically , model ( d ) can be thought of as being generated by adding a separate , independent grf ( indexed over the value range of @xmath49 ) to the 2d brownian surface .",
    "the sum of those two grfs is then rescaled with @xmath49 , and so the covariance function of model ( d ) is again conditionally positive definite with respect to the linear function space spanned by @xmath49 .",
    "all of the preceding explanations concern the interpolation of the mean parameter @xmath20 , and we still have to specify appropriate models for interpolating the logarithm ( to ensure positivity ) of the variance parameter @xmath21 .",
    "figure  [ fig : scalingillustration ] suggests that the considerations discussed above also apply to @xmath51 , and we therefore consider @xmath68 , a realization of an intrinsic grf @xmath69 with generalized covariance function @xmath70 , and use the same correlation models ( a)(d ) that were discussed above for the interpolation of @xmath20 .",
    "( left ) , corresponding kriging standard deviation @xmath71 ( middle ) and interpolated predictive standard deviation @xmath72 ( right ) for wind speeds over germany on january 3 , 2012 at 1800 utc . ]",
    "[ fig : interpolationexample ]    having specified the stochastic model on which we base our interpolation scheme , we can use standard techniques from geostatistics such as restricted maximum likelihood ( reml ) estimation and intrinsic kriging [ cf .",
    "@xcite , and references therein ] to estimate the unknown model parameters and carry out the interpolation .",
    "while reml is based on the contestable assumption of a multivariate gaussian distribution of the values of @xmath20 and @xmath51 at the observations sites , the discussion in @xcite suggests that its effectiveness does not depend critically on this assumption .",
    "we finally note that interpolation always involves uncertainty , and this is especially true in the present setting where we face a lot of small - scale variability that makes interpolation rather challenging . using the interpolated value @xmath73 as the predictive mean parameter at a nonobservational location @xmath74 instead of the unknown true value effectively increases the ( interpolated ) predictive variance @xmath75 by the kriging variance @xmath76 .",
    "hence , we take the sum of those two terms as the final predictive variance @xmath77 .",
    "the effect of the uncertainty in the interpolation of @xmath21 itself is more involved and would call for changing the distribution type . within our interpolation scheme there is no obvious way of dealing with this appropriately , and so we ignore this source of uncertainty and accept its adverse effect ( tails of the predictive distribution at nonobservational sites will typically be too light ) on forecast calibration . in figure",
    "[ fig : interpolationexample ] we depict the interpolated fields @xmath78 and @xmath79 for the 1800 utc forecast on january 3 , 2012 .",
    "those fields were obtained with covariance model ( d ) based on the parameter values of truncated logistic distributions at the observation sites .",
    "owing to the covariate @xmath80 , the interpolation scheme can anticipate increased values of wind speeds and high forecast uncertainties even at locations where the neighboring stations alone would not suggest this .",
    "moreover , it enables sharper transitions at the coastline than would be possible with the basic brownian surface model .",
    "we first consider the situation in section  [ sec:3 ] , where predictive distributions are provided and evaluated at observational sites only .",
    "the three different distribution models are used to calibrate ensemble forecasts of wind speeds at 0600 utc , 1200 utc and 1800 utc during the period from 1 january , 2012 to 31 december , 2012 . to fit the respective model parameters",
    ", we consider rolling training periods of different lengths , ranging from 30 to 80 training days .",
    "if more than one third of the training data pairs are missing at a particular location , no model is fitted , and the location is not considered on that verification day . to get a quick overview over the predictive performances of the different methods and different training sample sizes ,",
    "we first only compare the average crps over the verification period .",
    "recall that the crps is a proper scoring rule and evaluates both calibration and sharpness of predictive distributions , with lower scores implying better performance .",
    "the results in table  [ tab : insample ] show that all post - processing methods yield a significant improvement in predictive performance over the raw ensemble .",
    "the differences between the three distribution types are very small , but consistent over all forecast hours and training sample sizes .",
    "they suggest that the truncated logistic distribution yields the same or slightly better results than the truncated normal distribution and both are somewhat superior to predictive gamma distributions . in all cases , the dynamical weighting of the ensemble members and the usage of the ensemble variance as a predictor for the forecast uncertainty yield a slight improvement over the simplified model ( [ eq : simplified - model ] ) , which uses identical weights for all ensemble members and assumes homoscedastic forecast errors .",
    "the results confirm our expectations about the bias  variance trade - off implied by the choice of the training sample size .",
    "the optimal number of training days is around @xmath81 , and thus much larger than the values that are typically used for post - processing ensemble forecasts for temperature .",
    "yet , it can be observed that initially the scores improve with increasing training sample size due to increasing stability of parameter estimates .",
    "this trend is eventually reversed when further improvement in stability becomes negligible compared to the adverse effects that come with a reduced response to seasonal changes . from now",
    ", we will therefore focus on the results obtained with a rolling training period of 70 days .        in order to assess which distribution type yields the best calibration",
    ", we calculate the probability integral transforms ( pits ) @xmath82 for predictive cdfs @xmath83 and observations @xmath84 at all locations and all verification days .",
    "if the forecasts are calibrated , each of those pit values is uniformly distributed on @xmath85 $ ] , and systematic departures from uniformity are indicative of a lack of calibration [ see @xcite and references therein ] .",
    "figure  [ fig : pit - histograms ] shows plots of pit histograms for the three different predictive distribution models and confirms the conclusions from table  [ tab : insample ] .",
    "all three approaches eliminate systematic biases and give a good representation of prediction uncertainty .",
    "however , certain differences can be observed in the tails of those distributions .",
    "the tails  especially the upper one  of the truncated normal distribution model are somewhat too light .",
    "predictive gamma distributions , on the contrary , give a better fit in the upper tail , but their skewness causes the lower tail probabilities to be too low .",
    "the truncated logistic distribution model offers a good compromise between the two former : it is less skewed than the gamma distribution but has higher kurtosis than the truncated normal distribution , thus giving an adequate fit in both lower and upper tail , and resulting in almost perfectly flat pit histograms .",
    "we now turn to the situation where wind speed predictions are sought at locations where no observations are available for local calibration . in practice",
    ", those would usually be the gridpoints of the nwp model grid . here",
    ", in order to be able to measure and compare the performance of the different interpolation schemes proposed in section  [ sec:4 ] , we proceed as follows . from the 286 synop stations used in this study we draw 10 random samples of 50 stations that are left out for verification , with the sampling",
    "being done such as to avoid clusters of left - out stations . at the respective left - out locations , predictive distributions ( here we focus on the truncated logistic distribution model )",
    "are obtained by interpolating the mean and variance parameters of the retained stations , while the local observations are used for verification only .",
    "again , we use the crps as an overall performance measure and compare the average crps values over all verification days and all left - out stations , separately for each of the 10 different setups . in order to see how much accuracy",
    "is lost due to the need for interpolation of mean and variance parameters , we also give the results that are obtained when local observations at the left - out locations are available , and @xmath48 and @xmath27 can be found as described in section  [ sec:3 ] .",
    "the plots in figure  [ fig : interpolationexample ] suggest that the additional uncertainty due to interpolation has about the same magnitude as the meteorological uncertainty about the weather situation , which emphasizes the importance of a good interpolation scheme . from the boxplots in figure  [",
    "fig : crps - out - of - sample ] we can see that there are substantial differences in the predictive performance of the probabilistic forecasts obtained with the different grf models .",
    "using an intrinsically stationary model like the brownian surface , without addressing the systematic regional differences and the strong small - scale variability of @xmath20 and @xmath21 , does not give an appropriate description of the spatial dependence structure , and entails poor interpolants of the predictive distributions .",
    "the fractional brownian surface model , in spite of being more flexible , has the same deficiencies as the brownian surface model and does not improve the predictions . using the annual mean wind speeds for locally rescaling the mean and variance parameters , on the contrary , results in a distinctly superior interpolation scheme , and narrows the performance gap between the predictive distributions obtained by interpolation and those obtained by local calibration .",
    "the added dimension further improves the interpolation accuracy and yields the best predictive performance of all four interpolation schemes .",
    "the aim of themethodology proposed in section  [ sec:4 ] is to produce calibrated predictive distributions for wind speed at any desired location within the forecast domain .",
    "the post - processing methods presented in section  [ sec:3 ] aim at adjusting predictive means and variances at observation locations , and figure  [ fig : pit - histograms ] suggests that this is done quite successfully . do the elimination of ( local ) biases and the correct representation of forecast uncertainty also carry over to locations where no local observations are available , and predictive distributions are obtained through interpolation ? to assess this , we study again pit values , but we no longer pool over different locations since converse local biases may cancel each other out .",
    "instead , we study calibration separately for each location and summarize the information in the pit histograms by considering only two statistics of the local pit values : their mean and their mean absolute deviation ( mad ) from @xmath86 .",
    "if the forecasts are calibrated , these two quantities should be close to @xmath86 and @xmath87 , respectively .",
    "a pit mean larger / smaller than @xmath86 is indicative for an under-/overforecasting bias .",
    "if the forecasts are unbiased but strongly overdispersive , the pit values would be concentrated around @xmath86 , and the mean absolute deviations from this value would be close to zero .",
    "conversely , if the forecasts are strongly underdispersive , the pit values are concentrated near zero and one , and the mad would be close to @xmath86 .",
    "a similar idea of reducing the information in a pit histogram was proposed by @xcite , who fit a beta distribution to each histogram and define a @xmath13-bias and a @xmath13-score which characterize the histogram shape .",
    "the main difference is that our approach does not involve a parametric approximation to the pit histogram but estimates the mean and mad of the pit values directly .",
    "apart from a reduction of information , focusing on those two summary statistics has the advantage that meaningful values can be calculated with relatively few pit values and thus compensate for the reduction of the verification sample size due to not pooling the pit values over different stations .",
    "figure  [ fig : pit - maps ] depicts the two pit summary statistics at both used and left - out stations in the first of our 10 randomly generated setups .",
    "we compare the results for the raw ensemble and predictive truncated logistic distributions at 1800 utc using our best performing interpolation model ( d ) .",
    "the plots for the raw ensemble cdfs confirm our conclusion from the exploratory analysis that the ensemble forecasts are strongly underdispersive , and suffer from local biases that vary over the forecast domain . at the observation locations ,",
    "our post - processing method removes those biases completely and yields an adequate representation of the forecast uncertainty . at locations where predictive distributions are obtained through interpolation , biases are mostly reduced but could not be eliminated completely , which underscores the difficulty in calibrating forecasts in the absence of local observations",
    "however , our interpolation scheme is able to quantify this interpolation uncertainty , and adding the kriging variance to the interpolated forecast variance leads to an adequate representation of forecast uncertainty at almost all locations of left - out stations .",
    "we presented a method for post - processing ensemble forecasts of wind speed which can strongly improve the local calibration of raw ensemble forecasts , even at locations where no observations are available for calibration .",
    "three different types of predictive distributions ",
    "truncated normal , gamma and truncated logistic  were studied , and were found to perform similarly in our data example with some advantages for the truncated logistic distribution , which turned out to give the most adequate representation of predictive uncertainty in the tails . in order to obtain predictive distributions at nonobservational locations , we used geostatistical methods to interpolate the mean and variance parameters of the predictive distributions at surrounding observation locations .",
    "our results show that careful statistical modeling is required to formulate an adequate model for spatial dependence . in our case ,",
    "the thoughtful use of gridded data on mean annual wind speeds was a key step toward a strongly improved interpolation scheme .",
    "the forecasts and observations considered here were for surface wind speeds which are relevant , for example , for severe weather warnings or airport management .",
    "for wind power applications , wind speeds at hub height would be more relevant , and our approach needs to be tested in this latter context , too . while considerably less observations are available at hub height , the wind speed fields are smoother and less affected by land cover or the shape of the terrain . we expect that our geostatistical modeling approach could again be used successfully for generating calibrated gridded forecasts , and we believe that the methods presented here can help improve , for example , the prediction of the total regional wind energy production based on ensemble wind speed forecasts and a few local observations .",
    "to derive a closed form expression for the crps of the gamma distribution , we first note that the crps can also be written as @xmath88 [ @xcite ] , where @xmath89 and @xmath90 are independent random variables with cumulative distribution function @xmath34 and finite first moment . for gamma distributions @xmath91 ,",
    "the first term can be integrated out using the properties of their density @xmath92 , yielding @xmath93 where we have used that @xmath94 , with @xmath95 denoting the gamma function .",
    "the second term in the above crps representation can be calculated by using its relation to the gini concentration ratio @xmath96 [ e.g. , @xcite ] : @xmath97 putting both terms together , replacing the fraction of gamma functions by a beta function and using @xmath98 , yields the expression stated in section  [ sec:3 ] .",
    "for this calculation we take the same approach as @xcite for generalized extreme value distributions and use the quantile score representation of the crps : @xmath99 if we denote by @xmath100 the cdf of the logistic distribution and let @xmath101 , the quantile function of the _ truncated _ logistic distribution is given by @xmath102 after plugging this into the above quantile score representation of the crps and performing integration by substitution , we obtain @xmath103 where @xmath104 . the two integrals can be calculated using @xmath105 and after some rearrangement and simplification we finally obtain the expression stated in section  [ sec:3 ] .",
    "the authors are grateful to tilmann gneiting for helpful comments .",
    "they thank sabrina bentzien and all members of the cosmo - de - eps project at deutscher wetterdienst for their support with the acquisition of the ensemble forecast data ."
  ],
  "abstract_text": [
    "<S> probabilistic forecasts of wind speed are important for a wide range of applications , ranging from operational decision making in connection with wind power generation to storm warnings , ship routing and aviation . </S>",
    "<S> we present a statistical method that provides locally calibrated , probabilistic wind speed forecasts at any desired place within the forecast domain based on the output of a numerical weather prediction ( nwp ) model . </S>",
    "<S> three approaches for wind speed post - processing are proposed , which use either truncated normal , gamma or truncated logistic distributions to make probabilistic predictions about future observations conditional on the forecasts of an ensemble prediction system ( eps ) . in order to provide probabilistic forecasts on a grid , </S>",
    "<S> predictive distributions that were calibrated with local wind speed observations need to be interpolated . </S>",
    "<S> we study several interpolation schemes that combine geostatistical methods with local information on annual mean wind speeds , and evaluate the proposed methodology with surface wind speed forecasts over germany from the cosmo - de ( consortium for small - scale modelling ) ensemble prediction system .    </S>",
    "<S> ./style / arxiv - general.cfg </S>"
  ]
}