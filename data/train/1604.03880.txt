{
  "article_text": [
    "person detection has made tremendous progress over the last decade  @xcite .",
    "standard methods work best on pedestrians : upright people in fairly simple , predictable poses , and with minimal interaction and occlusion between the person instances .",
    "unfortunately , people in real images are not always so well - behaved",
    "! plenty of in - the - wild images contain multiple people close together , perhaps with their limbs intertwined , faces close , bodies partially occluded , and in a variety of poses .",
    "a number of computer vision applications demand the ability to parse such natural images into individual people and their respective body parts  for example , fashion  @xcite , consumer photo analysis , predicting inter - person interactions  @xcite , or as a stepping stone towards activity recognition , gesture , and pose analysis .",
    "current methods for segmenting person instances  @xcite take a top - down approach .",
    "first they use a holistic person detector to localize each person , and then they perform pixel level segmentation . limited by the efficiency and performance of person detectors , such methods are slow when dealing with people at unknown scales and orientations .",
    "furthermore , they suffer when presented with close or overlapping people , or people in unusual non - pedestrian - like body poses @xcite .",
    "we propose a new approach to detangle people and their body parts in multi - person images .",
    "reversing the traditional top - down pipeline , we pose the task as a region assembly problem and develop a bottom - up , purely region - based approach .",
    "given an input image containing an unknown number of people , we first compute a pool of regions using both body - part semantic segmentations and object proposals .",
    "regions in this pool are often fragmented body parts and often overlap . despite their imperfections ,",
    "our method automatically selects the best subset and groups them into human instances .",
    "see fig .",
    "[ fig : teaser](a , b ) . to solve this difficult jigsaw puzzle",
    ", we formulate an optimization problem in which parts are assigned to people , with constraints preferring small overlap , correct sizes and spatial relationships between body parts , and a low - energy association of body part regions to their person instance .",
    "we show that this problem can be solved efficiently using decomposition and a branch and bound method .",
    "[ fig : teaser](c ) shows an example result from the proposed method .",
    "note that we not only estimate pixel - level body part maps , but we also indicate  which part belongs to whom \" , even in a crowded scene with occluding people .",
    "experiments on three datasets show our method strongly outperforms an array of existing approaches , including bounding box detectors , cnn region proposals , and human pose detectors .",
    "furthermore , we show the advantage of the proposed optimization scheme as compared to simpler inference techniques .",
    "finally , we demonstrate our person detangler applied to _",
    "proxemics recognition _",
    "@xcite , where fine - grained estimation of body parts and body part owners is valuable to describe subtle human interactions ( e.g. , is he holding her hand or her elbow ? ) .",
    "[ fig : teaser ]      most previous methods for human instance segmentation require a person detector . in @xcite a multi - part pedestrian detector is combined with an mcmc method for walking crowd segmentation .",
    "a pedestrian detector is used in @xcite to find people instances in bounding boxes before instance segmentation .",
    "joint pose estimation and segmentation for single subjects have been proposed in @xcite .",
    "multiple people instance segmentation in tv shows has been studied in @xcite using the detector crf scheme , which combines a person detector and a pixel - level crf to achieve accurate results . in @xcite ,",
    "people detection bounding boxes are verified using face detections and then grabcut is used to refine the instance segmentation . in @xcite a pictorial structure method @xcite",
    "is used to detect candidate human instances .",
    "sequential assignment is used to fit the human instance masks to image data . from instance masks ,",
    "detailed human segmentation and body part regions are further estimated using the crf . whereas existing methods largely take the strategy of first detecting individual people and then segmenting their parts",
    ", we propose a reversal of this conventional pipeline .",
    "in particular , we propose to start with a pool of regions that are segments or sub - regions of body parts on multiple people , and then jointly assemble them into individuated person segments .",
    "the advantage of not depending on a holistic person detector is not only because these detectors have high computational complexity ( especially if we have to handle people with unknown orientations and scales ) , but also because it is still a difficult problem for person detectors to deal with complex human poses , inter - person interactions , and large occlusions , which our target images may include . compared to previous detector - based methods ,",
    "our approach is more efficient and gives better results .",
    "deep learning approaches have been studied in the joint detection and segmentation scheme @xcite , related to rcnn  @xcite , though the authors target generic pascal object detection as opposed to person individuation and body part labeling .",
    "their method starts from object region proposals such as @xcite , and each region is classified as a target , such as a human subject , by using features on both color images and binary image masks .",
    "potentially , such a method can be scale and rotation invariant and fast .",
    "the challenge is how to propose complete whole object regions , such as the whole mask of a person .",
    "this is often a difficult task due to the variation of color and texture on a single subject , the thin structure of human limbs , and arbitrary human poses .",
    "our proposed method also uses region proposals , but our method allows fragmented sub - regions and is able to reassemble the broken regions back to human body parts .",
    "part voting approaches have been intensively studied for human or object instance segmentation . in @xcite ,",
    "boundary shape units vote for the centers of human subjects . in @xcite , the poselets vote for the centers of people instances .",
    "the poselets that cast the votes are then identified to obtain the object segmentation . in @xcite",
    "the object boundary is obtained by reversely finding the activation parts used in the voting .",
    "similar to the hough transform , such a voting approach is more suitable to targets that have relatively fixed shape .",
    "our proposed method finds the optimal part assembly using articulation invariant constraints instead of simply voting for the person center ; it therefore can be used to segment highly articulated human subjects .    our method is also related to human region parsing , in that we segment and label each person s body part regions .",
    "human region parsing has been mostly studied for analyzing body part regions of a single person @xcite . to handle multiple people , in @xcite a pedestrian detector",
    "is used to find the bounding box of each single person .",
    "finding people with arbitrary poses using a bounding box detector is still a hard problem , whereas our method naturally handles multiple people with complex interactions and poses .",
    "part segmentation has recently been used to improve semantic segmentation of animals in @xcite , but the pairwise crf method can not individuate multiple animal instances .",
    "in contrast , our method is able to individuate tangled people with complex poses .",
    "our work is also distantly related to human pose estimation , which has been intensively studied on depth images @xcite and on color images using pictorial structure methods @xcite and cnns @xcite .",
    "however , unlike our approach , human pose estimation methods usually do not directly give the instance and body part region segmentation .",
    "our method produces multiple human segmentations without extracting human poses .    in summary ,",
    "the main contributions of this paper are : ( 1 ) we tackle the new problem of multiple person instance individuation and body part segmentation from region assembly .",
    "( 2 ) we propose a novel linear formulation . ( 3 )",
    "we propose a lagrangian relaxation method to speed up lower bound estimation , with which we solve the optimization using fast branch and bound .",
    "our experiments show that our method is fast and effective , outperforming an array of alternative methods , and improving the state - of - the - art on proxemics recognition .",
    "we first overview our approach ( sec .  [ sec : overview ] ) , then present the big picture formulation of region assembly as a graph labeling problem ( sec .",
    "[ sec : labeling ] ) .",
    "next we describe in detail how we implement the components of that formulation ( sec .",
    "[ sec : details ] ) . and , we introduce our efficient optimization approach ( sec .",
    "[ sec : opt ] ) .",
    "finally we discuss parameter setting ( sec .",
    "[ sec : params ] ) .",
    "there are different ways to generate regions and sub - regions of human body parts . in this paper , we start with a large set of body part region proposals using three sources : a cnn trained for semantic segmentation of body parts ( details below ) , generic region proposals  @xcite , and the intersection between the previous two kinds of regions",
    ". some of the region proposals may already give body part regions of separate human instances , or more likely they are partial sub - regions of body parts .",
    "many proposal regions do not correspond to body part regions , or may be the union of two individuals body parts .",
    "our goal is to select a subset of regions from these proposals and reassemble them to individuate human instances and the associated body parts .",
    "intuitively , a good configuration should have arm , leg , torso , and head regions in proportional sizes , and part regions should follow correct neighborhood relations .",
    "we show how to search for the best jigsaw puzzle assembly meeting those criteria .",
    "in particular , we search for the optimal set of regions so that they minimize an objective function",
    ". let @xmath0 be the set of overlapped regions or sub - regions of different body parts .",
    "let @xmath1 be a vector of integers that indicate a specific region in @xmath0 is assigned to a person @xmath2 from @xmath3 and @xmath4 is the number of human instance candidates determined by the algorithm during the optimization ( details below ) .",
    "the element of @xmath1 is zero if the corresponding region candidate does not belong to any person and a natural number otherwise .",
    "we find the optimal @xmath1 by jointly optimizing over all potential people instances : @xmath5 here @xmath6 is the cost of assigning part regions to specific human instances .",
    "@xmath7 is a term that encourages the selected region candidates to cover corresponding body part regions .",
    "@xmath8 is a term that enforces the assembled body regions in each detected human instance to have correct sizes .",
    "apart from these terms , we also introduce constraint @xmath9 to limit the intersection area between the selected regions , and @xmath10 to constrain the color histogram between specific region pairs .",
    "we also use constraint @xmath11 to enforce the total body part area of each instance person to be within an upper bound .",
    "all these terms are defined in detail below .",
    "[ fig : ink](a ) illustrates the region assembly problem as graph labeling .",
    "the nodes correspond to the regions or sub - regions of different body parts .",
    "head nodes and head - torso nodes in fig .",
    "[ fig : ink](a ) are also denoted as human instance nodes .",
    "the head - torso nodes represent the head - torso region combinations .",
    "the binary edges correspond to possible region - to - human instance assignments , and the hyper edges constrain the region coupling and assignment consistency .",
    "the binary edges and nodes have weights .",
    "we essentially need to find an optimal node - edge labeling to minimize the total weight .",
    "the optimization is combinatorial .",
    "it is hard to solve due to the large number of edges , loopy structure and high order constraints . instead of directly solving the hard problem",
    ", we decompose it into three optimizations on three simpler graphs in two stages , as shown in fig .",
    "[ fig : ink](b ) .     while satisfying different region constraints on body part assembly .",
    "( b ) we decompose the optimization into three optimizations in two stages .",
    "see text for details . ]",
    "the three optimizations share a common integer program format : @xmath12 here , the vector @xmath13 includes the edge variables and the vector @xmath14 includes the human instance node variables .",
    "the dimension of @xmath13 equals the number of torso regions in stage one or number of arm or leg regions in stage two times the number of candidate head regions .",
    "the dimension of @xmath14 equals the number of head regions .",
    "@xmath15 is an auxiliary variable vector .",
    "@xmath16 are constant coefficient vectors .",
    "@xmath17 is a constant .",
    "@xmath18 is an all - one vector .",
    "@xmath19 is the assignment constraint and @xmath20 represents the region coupling constraints .",
    "how @xmath21 are determined will become clear after sec .",
    "[ sec : details ] .",
    "the optimization finds the pairing of nodes in each augmented bipartite graph in fig .",
    "[ fig : ink](b ) .",
    "the nodes on one side are the regions of torsos , arms or legs .",
    "the nodes on the other side are the human instance representations using head regions ( stage one ) or a head - torso region combination ( stage two ) .",
    "each part region ( arm , leg , torso ) node can be used at most once , and each human instance node may receive zero or multiple region matches .",
    "when selecting multiple part nodes , we assemble corresponding body part regions using `` broken '' region pieces .",
    "the nodes of part regions are coupled by the size and exclusion constraints .",
    "now we flesh out how we instantiate the general formulation presented above .",
    "we start from a semantic segmentation map in which each pixel is classified as one of the four part types ( arms , legs , torso and head ) or the background .",
    "(  background \" =  not any person \" ; all person pixels are  foreground \" . )",
    "the map is obtained by first computing a stack of probability maps from a cnn ( a modified alexnet @xcite ) for each part at different scales .",
    "max - pooling is then applied to compute the body part soft semantic map .",
    "we use graph cuts with alpha - expansion to generate the final semantic segmentation map .",
    "please see appendix  [ app : cnn ] for details .",
    "overall , the goal is to have a large pool of part candidates with high recall , but possibly low precision ; that way , there is a high chance that we can correctly use them to assemble and separate multiple human human instances . with this in mind ,",
    "regions and sub - regions of body parts ( torso , arm , and legs ) are generated as follows .",
    "apart from using the connected components of body part regions from the cnn - derived semantic segmentation map , we use region proposals from @xcite to `` chop '' possibly merged part regions into smaller pieces by intersecting the region proposals with each part region .",
    "the regions therefore include both whole body parts and fragments of body parts .",
    "head regions are generated differently because the above method may not always be able to separate close head regions .",
    "the head regions are circular regions whose radius is determined by the max - response scale at each head point ; the head points are detected by finding peaks in the soft semantic head map using non - maximum suppression .",
    "( more details in appendix [ app : cnn ] . )",
    "while our framework allows multiple head candidates with different scales at the same point , in practice we find selecting the single most likely head candidate at each point is sufficient , and so we take this simpler configuration .",
    "the head candidate regions are further intersected with the person foreground in the semantic map .",
    "the head detections automatically tell our system the candidate people number in the image .",
    "now we are ready to define the energy terms @xmath6 , @xmath7 , @xmath8 and constraints @xmath9 , @xmath10 , @xmath11 in eq .",
    "[ eq : overall ] and derive eq .",
    "[ eq : cm ] .",
    "we introduce a binary variable @xmath22 , the binarized version of @xmath1 in eq .",
    "[ eq : overall ] , to label edges in fig .",
    "[ fig : ink](b ) : @xmath23 if region @xmath2 is selected to be part of person @xmath24 , otherwise @xmath25 .",
    "we have the following constraint on @xmath13 : @xmath26 , which means each region can only be assigned to at most one human instance .",
    "each person instance may connect to multiple regions to handle the region splitting case .",
    "we also introduce variable @xmath27 to indicate whether person / head candidate @xmath24 is selected .",
    "@xmath14 is the human instance node variable .",
    "we enforce @xmath28 . in stage two ,",
    "the head - torso regions come from the solution of stage one , and @xmath14 is all one .",
    "there is a cost @xmath29 to associate region @xmath2 to person instance candidate @xmath24 , and a cost @xmath30 to select instance candidate @xmath24 .",
    "the total assignment cost is @xmath31 .",
    "we optimize @xmath14 only in stage one . in stage two , @xmath14 is fixed to be all ones and can be removed from the optimization .",
    "@xmath30 equals one minus the head region s peak probability on the head map , so as to emphasize costs incurred on more confident heads .",
    "@xmath32 is a constant weight balancing the region association cost against instance selection cost .    in short , the cost @xmath29 aims to associate a person instance with regions that `` look like '' part of the corresponding body parts , mostly fall in the range radius , and are close to the human instance .",
    "we also encode the preference to use a small set of large regions to build the body parts of each human instance , to avoid trivial assemblies ( e.g. ,  @xcite ) .",
    "specifically , the assignment cost @xmath33 is defined as : @xmath34 where @xmath35 equals one minus the mean probability of region @xmath2 belonging to human instance @xmath24 as part of a specific body part ( probability obtained from the soft cnn semantic maps at @xmath24 s scale ) .",
    "the term @xmath36 is the proportion of region @xmath2 exceeding the range radius of instance @xmath24 . to maintain scale - invariance ,",
    "the range radius for each body part is estimated using the instance / head @xmath24 s scale and a reference person height ( 150 pixels ) .",
    "the term @xmath37 is the shortest point - to - point distance between the head region ( stage one ) or head / torso region ( stage two ) @xmath24 and part region @xmath2 , normalized based on the reference height .",
    "the constant @xmath38 penalizes selecting many small regions to construct a body part in each human instance .",
    "the coefficients @xmath39 , @xmath40 , @xmath41 and @xmath38 control the weights among different terms .",
    "the setting of these coefficients are discussed later .",
    "when composing a human instance s body part , the total area of the selected regions is limited by the body part s size : @xmath42 , where @xmath43 is the area of the region @xmath2 , @xmath44 is the scale of the human instance @xmath24 and @xmath45 is largest possible area of a body part for the reference person ( 150-pixel tall ) . in stage",
    "one @xmath45 is the max area of the torso , and in stage two @xmath45 limits the area of arms or legs .",
    "apart from the hard constraint , a soft one encourages the total area of a region assembly to approach a target size of the corresponding body part . we minimize @xmath46 , which can be converted to a linear form : @xmath47 . here",
    "@xmath48 is the the average body part size of the reference person from different view points .",
    "it corresponds to the torso in stage one and arms or legs in stage two .",
    "we also prefer to select regions that are mostly non - overlapping to form each body part region .",
    "thus , we introduce an exclusion constraint @xmath9 to discourage overlap .",
    "let @xmath49 indicate whether region @xmath2 is associated to a human instance . to construct constraint @xmath9 , we let @xmath50 , where @xmath51 is the area intersection to union ratio between region @xmath52 and @xmath53 , @xmath54 is a constant .",
    "apart from intersection exclusion , we also prefer that the color histograms should match if two regions are selected to form the same body part .",
    "we thus enforce the constraint @xmath10 that @xmath55 , where @xmath56 is the @xmath57-distance between the normalized color histogram of region @xmath58 and @xmath59 , @xmath60 is a constant threshold .",
    "if we simply minimize the above terms , @xmath61 will be all zero since all the coefficients in the objective are non - negative .",
    "we introduce an extra covering term to encourage the chosen regions to cover the corresponding body part regions in the semantic segmentation map .",
    "we maximize the total region size @xmath62 , where @xmath63 and @xmath64 is the part type of candidate @xmath2 , @xmath65 is the total area of part @xmath64 in the semantic map .",
    "@xmath7 is proportional to the total region size .",
    "this encourages region covering because we enforce the regions to be mostly disjoint .",
    "combining the above terms , we have our final optimization objective : @xmath66 where @xmath17 and @xmath67 are coefficients that serve to control the weights of size term and cover term .",
    "it is easy to verify that the formulation indeed has the format in eq .",
    "[ eq : cm ] , if we vectorize variables @xmath68 and substitute @xmath69 by @xmath13 terms .",
    "the optimization is a hard combinatorial problem due to the loopy structure and high order constraints .",
    "we next propose an efficient relaxation and branch and bound method to solve the problem .",
    "a direct linear relaxation , in which we replace the binary constraints on @xmath13 with a 0 to 1 soft constraint , gives a good lower bound .",
    "the disadvantage of this approach is that we need a linear programming solver , and as the number of region candidates increases the complexity of solving a large linear program is high . with 1000 candidates and 2 human instances ,",
    "the simplex method takes around 4 seconds to complete , while using the following speedup the time can be reduced to 0.1 seconds using the same cpu .",
    "we obtain the lower bound using the lagrangian dual .",
    "the size constraints and the exclusion constraints complicate the problem .",
    "we move them into the objective function .",
    "to simplify notation we use the compact format of eq .",
    "[ eq : cm ] : @xmath70 where @xmath71 is the lagrangian multiplier vector .",
    "we introduce an upper bound @xmath72 for @xmath15 to avoid unbounded solutions .",
    "since the extra term in the objective is non - positive for all the feasible solutions of the original problem , the lagrangian dual gives a lower bound .",
    "the internal part of the dual is easy to solve because it can be decomposed into three simple problems ( no p2 in stage two ) : @xmath73 : } \\min_{x } ( g^t + \\nu^tb)x , \\mbox { s.t . } \\ ;   ax \\le 1 , \\ ; x \\mbox { is binary}. \\\\ &",
    "\\mbox{[p2 ] : } \\min_{y } ( w^t + \\nu^td)y , \\mbox { s.t . } \\ ;",
    "y \\mbox { is binary}. \\\\ &",
    "\\mbox{[p3 ] : } \\min_e ( \\phi 1^t + \\nu^tc)e , \\mbox { s.t . }",
    "0 \\le e \\le m.\\end{aligned}\\ ] ] p1 can be solved by sequential assignment : in an assignment graph such as fig .",
    "[ fig : ink](b ) , for each body part region node , we check all the links to the human instance node and find the most negative link and let the corresponding @xmath13 variable to be 1 . if there is no negative link , no matching is made and the corresponding @xmath13 is 0 . in p2 and p3 , @xmath14 is set to 0 or 1 and @xmath15 is set to 0 or @xmath72 according to the positiveness of their coefficient .",
    "each set of lagrangian multipliers corresponds to a lower bound of the original problem .",
    "we are interested in the largest lower bound .",
    "the bound with respect to the multipliers is a concave function and can be solved using the subgradient method",
    ". the iteration alternates between solving for @xmath74 and updating @xmath71 by @xmath75 . here",
    "@xmath76 is a small constant @xmath77 .",
    "the initial values of these coefficients in @xmath71 are set to zero .    for this problem ,",
    "the lagrangian relaxation bound is the same as that of the linear program relaxation .",
    "this is due to total unimodularity of the internal problem of the lagrangian dual @xcite .",
    "* example . * fig .",
    "[ fig : example ] shows an example of using the lagrangian relaxation to obtain the lower bound .",
    "the max - pooling result of the initial cnn semantic body part segmentation is shown in fig .",
    "[ fig : example](b - f ) .",
    "we then use graph cuts with alpha - expansion to generate the hard semantic segmentation map ( middle of fig .",
    "[ fig : example](a ) ) .",
    "note how parts are not individuated per person in this map .",
    "arm , leg and torso region proposals are generated from the intersection between semantic part maps and object proposals .",
    "the lagrangian relaxation is applied to three optimizations in two stages . as shown in fig .",
    "[ fig : example](j - l ) , the result converges quickly to the linear program relaxation result ( the red line ) in a few hundred iterations .",
    "the relaxation assignment is illustrated in fig .",
    "[ fig : example](g - i ) .",
    "we see it is indeed very similar to the globally optimal solution in fig .",
    "[ fig : example](a ) .",
    "the complexity of finding the lower bound using the lagrangian relaxation is @xmath78 , where @xmath53 is the number of region proposals times the number of human instance candidates , and we use a fixed number of iterations in the subgradient method .",
    "in contrast , the average complexity of a linear relaxation @xcite using the simplex method is @xmath79 .",
    "the above dual approach can be extended to estimate the lower bound at each node of the search tree . with the lower bounds , we use the branch and bound method to find the global optimum quickly . for most problems in the experiments , where @xmath53 averages around @xmath80 , the branch and bound procedure terminates in a few seconds .",
    "we set the thresholds @xmath81 and @xmath82 .",
    "the weights of the unary cost terms are set to be @xmath83 and the weights for the energy terms as @xmath84 .",
    "we fixed all parameters for all experiments after manually inspecting a few examples . with more labeled data",
    ", we can optimize these parameters for even better performance .",
    "( please see appendix  [ app : para ] for details of how we can automatically set the parameters by maximizing the margin on positive / negative examples via a linear program . )",
    "* overview : * in the following , we compare our approach to 1 ) simpler inference methods , to show the value added over the initial cnn body part maps ; 2 ) bounding box detector methods ; 3 ) cnn methods using region proposals ; 4 ) human pose detection based methods . having established our method s accuracy , we then demonstrate its applicability for a downstream task : proxemics recognition .",
    "* datasets and evaluation metrics : * we evaluate the proposed method on 3 datasets : uci  @xcite , which contains 589 images , 100 images from the mpii dataset  @xcite that contain multiple tangled people , and buffy  @xcite .",
    "the images include complex human poses , interactions , and occlusions among subjects .",
    "the person scales and orientations are unknown .",
    "we manually label the human instances and four part regions in uci and mpii dataset for ground truth evaluation only ( not to train the cnn ) .",
    "we use the area intersection to union ( iou ) ratio against the ground truth labeling to quantify the performance .",
    "we report the iou for the human instances and mean iou over all body part labels within each instance .",
    "to compute forward ( f ) scores , we match each ground truth segment to the best segmentation result . for the backward",
    "( b ) scores , the matching is the other way around .",
    "the forward score is affected by missing detections and the backward score by the false alarms .",
    "the plots in fig .",
    "[ fig : curve ] sweep through overlap thresholds and plot the proportion of results that have instance iou ratios higher than each threshold .",
    "the higher the curve , the better the performance .",
    "table  [ tab1 ] shows average iou scores .",
    "we explain the methods compared below .",
    "[ fig : samples ] shows sample results of our method on uci and mpii .            *",
    "are our initial cnn body part maps enough ?",
    "would a simpler inference method on top of the cnn maps be sufficient ? *",
    "first , we stress that the cnn body part maps are not enough by definition , as they do not individuate which body part blobs go to which person .",
    "the person and part segmentations merge when people are close .",
    "for example , if their arms touch , that yields one connected component in the cnn output ; see fig  [ fig : samples ] , second column in each set .",
    "our cnn semantic segmentation itself is reasonable . on uci and mpii , the average foreground pixel accuracy and part pixel accuracy are @xmath85 and @xmath86 respectively .",
    "however , this does not easily transfer to a good human instance segmentation . to confirm this quantitatively , we test 1 ) a baseline that returns connected components in the cnn map for the body part labels ( * connected * ) , and 2 ) a baseline that greedily finds the grouping of each person sequentially ( * greedy * ) . for the latter ,",
    "after the lowest cost group is found , the regions in that group are removed and we proceed to the next one until all the head regions are exhausted . note that naive exhaustive search is extremely slow due to the huge search space .",
    "[ fig : curve ]  ( a , e ) and table  [ tab1 ] show the results . our full method s strong results relative to both these baselines reveals the role of our region assembly optimization .",
    "our efficient global optimization is necessary .    * comparison with bounding box detector methods : * one widely used method ( e.g. , @xcite ) to extract human instances is to first detect people in a set of bounding boxes , and then obtain pixel - level segmentation . to test such a baseline",
    ", we use a deformable part model ( * dpm * ) person detector  @xcite and poselet ( * poselet * ) person detector  @xcite , and refine the segmentation with grabcut  @xcite .",
    "we adjust the threshold of the person detectors to the lower side so that they can detect more people instances .",
    "we also adjust the parameters of grabcut to achieve the best performance .    as shown in fig .",
    "[ fig : pff_poselet ] ( a ) , when the people have complex poses , interactions , and occlusions , the bounding boxes from person detectors are not accurate .",
    "it is a non - trivial task for a pixel - level segmentation method to correct such errors without manual interaction .",
    "indeed , our method gives consistently superior results to the detector based approach ( see fig .",
    "[ fig : curve](b , f ) and in table  [ tab1 ] ) .",
    "* comparison with cnn object detectors using region proposals : * another method for human instance segmentation is first generating many region proposals and then using a classifier to extract true human instances , e.g. @xcite .",
    "rcnn @xcite can also be modified to achieve such a function .",
    "to compare this idea to our method , we test three kinds of region generation methods : selective search  @xcite , mcg  @xcite and object - independent proposals  @xcite .",
    "each rectangle image patch that encloses a region proposal is then sent to rcnn to determine the probability of the image patch containing a human instance .",
    "for fair comparison , apart from the original dataset for training , we also include the lsp images @xcite in the refinement , which improves the baseline s human classification result .",
    "the rcnn detection threshold is set to 0.1 .",
    "[ fig : pff_poselet ] ( b ) shows sample results . in images with tangled people instances ,",
    "region proposals often have a hard time to obtain full human segmentation , because the human structures are not directly used in these region proposal methods .",
    "[ fig : curve](c , g ) and table  [ tab1 ] show the quantitative comparison .",
    "our method gives better results .",
    "c c instance mean iou : &    .",
    "average person instance and part iou ratio comparison for the uci and mpii dataset . connected :",
    "connected component method .",
    "r - i : rcnn+oip , r - ii : rcnn+mcg , r - iii : rcnn+selectivesearch , cnn - d : cnn pose detector @xcite .",
    "f : forward score .",
    "b : backward score . in part iou table : connected component is denoted as c , greedy method as g , nbest as nb and cnn - d as cd .",
    "the numbers are percentages . [",
    "cols=\"^,^,^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]         * application for proxemics recognition : * finally , we demonstrate the utility of our human region parsing for _ proxemics _ recognition .",
    "proxemics is the study of the spatial separation individuals naturally maintain in social situations .",
    "the uci dataset was created to study proxemics , and is labeled for 6 classes : hand - hand ( hh ) , hand - shoulder ( hs ) , shoulder - shoulder ( ss ) , hand - torso ( ht ) , hand - elbow ( he ) and elbow - shoulder ( es ) .",
    "we use features that include the min and max distances between each pair of upper body part regions of a person pair normalized by the average scale of the two subjects , the normalized horizontal and vertical distance of heads and the scale difference .",
    "the data for training and testing are uniformly split at random , following the setup in  @xcite . to learn the 6 proxemics classes on top of these features",
    ", we use a random forest classifier with 100 trees and unlimited tree depth .",
    "we repeat the experiment 10 times and report the average accuracy",
    ". we do not use ground truth head locations .",
    "[ fig : prox ] shows sample classifications and ap scores . our average ap score is higher than all the competing methods  @xcite .",
    "our weakness vs.  @xcite on ht is likely because not only baby hugging but also other hand - on - torso images are classified as ht .",
    "compared to the prior pose detectors , our method is more resistant to large occlusion , non - pedestrian poses , and complex interaction among people .",
    "we identify the membership of each pixel to each human instance ; local errors , e.g. broken regions , do not cause a big problem .",
    "we propose a novel method to segment human instances and label their body parts using region assembly .",
    "the proposed method is able to handle complex human interactions , occlusion , difficult poses , and is rotation and scale invariant .",
    "our branch and bound method is fast and gives reliable results .",
    "our method s results compare favorably to a wide array of alternative methods .",
    "this research is supported in part by u.s .",
    "nsf 1018641 and a gift from nvidia ( hj ) and onr pecase n00014 - 15 - 1 - 2291 ( kg ) .",
    "we train the semantic segmentation body part cnn on the lsp dataset  @xcite with 27 classes ( including body joints , in - between points and background class ) using caffe @xcite . during training ,",
    "the cnn s input size is 55@xmath8755 and the first convolution layer has stride 1 instead of 4 .",
    "the fully connected layers before the output are replaced by simpler lenet fully connected layers and then converted to fully convolutional networks to facilitate pixel - level semantic segmentation .",
    "the training image patches are rotated and flipped so that the trained classifier is rotation invariant . when testing , all the images are rescaled so that the longest edge is 500-pixels ; the cnn input size is the same as the input image .",
    "the 27 classes are finally merged to 4 part types  head , torso , arm and leg and a background class when obtaining the soft semantic segmentation .    for each input image",
    ", we compute the cnn soft semantic maps of the five classes ( arm , leg , torso , leg and background ) in different scales . for each scale level , the input image is downsized to a specific resolution .",
    "the downsizing factors range from @xmath88 to @xmath89 with the step of @xmath90 .",
    "there are totally 16 different scale levels .",
    "the soft semantic map of each class is then generated using max - pooling .",
    "the soft semantic maps of the five classes are finally normalized so that each value represents a probability .",
    "the head points are localized on the merged soft head map by non - max suppression .",
    "the non - maximum suppression uses the window of @xmath91 and the threshold of 0.2 . after each head point",
    "is localized , we find the head s scale by going through the stack of head maps with different scales and finding the map that gives the largest value at the head point .",
    "we record the head scale as the inverse of the corresponding image downsizing factor .",
    "for instance , if at one head point , the semantic map with the downsizing factor of 0.5 gives the largest response in the cnn head maps , the head candidate has a scale 2 .",
    "we compute the final semantic segmentation map using the graph cuts method , which minimizes the assignment of five labels : head , torso , arm , leg and background to each pixel in the input image .",
    "two passes of graph cuts are used . in the first pass ,",
    "we label each image pixel as human foreground ( body part pixel ) or background ( non - human pixel ) .",
    "the unary term is one minus the pixel level probability of these two classes from the cnn .",
    "the weights are 1 and 0.2 for the unary term and binary term respectively .",
    "the binary term smooths the labeling between neighboring pixels .",
    "each neighbor pixel pair contributes to the binary term ; the contribution equals the weight times the distance between the two neighbor pixels labels .",
    "we define the distance between two labels to be zero if they are the same and otherwise the distance is one . in the second pass ,",
    "we only label the foreground pixels determined from the first pass as the four body part classes : head , arm , leg or torso . we also use one minus the pixel probability from the cnn in the unary term and the same setting in the pairwise term as pass one .",
    "the weights are also 1 and 0.2 for the unary and binary terms . to improve the result",
    ", we include a term that penalizes pixels to be labeled as arm or torso if they fall out of the arm range radius of each detected head in the image .",
    "the arm range radius is computed using the head s scale and a 150-pixel tall reference person s maximum head to hand distance .",
    "the penalty is applied in the alpha - expansion procedure . for a pixel out of the range radiuses of all the detected heads ,",
    "a penalty of 1 is included in the unary term of the alpha node if the alpha label is torso or arm , or a penalty of 1 is included in the unary term of the pixel node if the current pixel label is torso or arm .",
    "the first pass graph cuts can be optimized using the maxflow method . in the second pass ,",
    "20 iterations are used in the alpha - expansion .",
    "we use a push - relabel maxflow algorithm in the implementation .",
    "the maxflow algorithm requires integer edge capacities ; we convert the floating point capacities in the above formulation to integers by multiplying 1000 and then taking the floor .      with enough labeled data",
    ", we can automatically set the parameters in the the proposed method by maximizing the margin on positive / negative examples via a linear program .",
    "@xmath60 can be obtained from the color statistics of the ground truth data .",
    "we assume @xmath54 fixed for now .",
    "we represent all the other weight parameters as a vector @xmath59 .",
    "let @xmath92 be the values of different terms weighted by these coefficients for the positive segmentation sample of image @xmath2 , and @xmath93 be the corresponding values of the @xmath24th negative segmentation sample of image @xmath2 .",
    "positive segmentation exemplars are from ground truth labeling .",
    "negative exemplars can be randomly generated using region proposals , which satisfy the overlap , color exclusion and unique assignment constraints .",
    "we maximize the energy difference between the positive and negative training examples using a similar formulation to @xcite : @xmath94 the optimization can be solved efficiently using linear programming .",
    "@xmath54 has a small range and can be found by exhaustive search to achieve the highest segmentation performance on the training dataset ."
  ],
  "abstract_text": [
    "<S> today s person detection methods work best when people are in common upright poses and appear reasonably well spaced out in the image . however , in many real images , that s not what people do . </S>",
    "<S> people often appear quite close to each other , e.g. , with limbs linked or heads touching , and their poses are often not pedestrian - like . we propose an approach to detangle people in multi - person images . </S>",
    "<S> we formulate the task as a region assembly problem . starting from a large set of overlapping regions from body part semantic segmentation and generic object proposals , our optimization approach reassembles those pieces together into multiple person instances . </S>",
    "<S> it enforces that the composed body part regions of each person instance obey constraints on relative sizes , mutual spatial relationships , foreground coverage , and exclusive label assignments when overlapping . since optimal region assembly </S>",
    "<S> is a challenging combinatorial problem , we present a lagrangian relaxation method to accelerate the lower bound estimation , thereby enabling a fast branch and bound solution for the global optimum . as output , </S>",
    "<S> our method produces a pixel - level map indicating both 1 ) the body part labels ( arm , leg , torso , and head ) , and 2 ) which parts belong to which individual person . </S>",
    "<S> our results on three challenging datasets show our method is robust to clutter , occlusion , and complex poses . </S>",
    "<S> it outperforms a variety of competing methods , including existing detector crf methods and region cnn approaches . </S>",
    "<S> in addition , we demonstrate its impact on a proxemics recognition task , which demands a precise representation of  whose body part is where \" in crowded images .    </S>",
    "<S> = 1 </S>"
  ]
}