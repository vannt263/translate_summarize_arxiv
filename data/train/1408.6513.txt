{
  "article_text": [
    "structural default framework is widely used for assessing credit risk of rate debt .",
    "introduced in its simplest form in a seminal work @xcite , this framework was further extended in various papers , see a survey in @xcite and references therein .",
    "in contrast to reduced - form models , structural default models suffer from the curse of dimensionality when the number of counterparties grows ; however , these models provide a more natural financial description of the default event for a typical firm .",
    "one of the possible extensions of the structural framework , which is of high importance in the current environment , consists in taking into account the fact that banks , in addition to their liabilities to the outside economy , also have some liabilities to each other .",
    "this topic is discussed , e.g. , in @xcite , where it is mentioned that systemic capital requirements for individual banks , determined as the solution to the policymaker s optimization problem , depend on the structure of banks  balance sheets ( including their obligations to other banks ) and the extent to which their asset values tend to move together .",
    "more generally , systemic capital requirements are found to be increasing in banks balance sheet size relative to other banks in the system , as well as their interconnectedness , and , materially , contagious bankruptcy costs .    from this perspective",
    ", an extension of the simplest merton model can be proposed to quantify default risks in an interconnected banking system .",
    "for instance , @xcite consider systemic risk in such a system and attribute it either to correlations between the asset values of the banks , or to interlinkages of the banks balance sheets , which could result in contagious defaults .",
    "an extended merton model can be built as a combination of the correlated merton balance sheet models , calibrated by using observed bank equity returns , and a network of interbank exposures cleared in the spirit of @xcite .    in this paper",
    "we develop a model , which builds upon its predecessors ; yet , it differs from the earlier models in one very important respect .",
    "namely , rather than addressing a point - in - time default event , we consider defaults , which can occur at any time , by introducing a continuous default barrier in the spirit of @xcite .",
    "we feel that this extension is necessary in order to analyze the effect of mutual liabilities properly , especially because we wish to provide not just qualitative , but also quantitative conclusions . to avoid confusion , we emphasize that this effect differs from that of contagion for correlated defaults in reduced - form models , see , e.g. , @xcite .",
    "to achieve our goal , we need to come up with a suitable structural model capable of handling mutual obligation effects at various time scales .",
    "it is well - known that pure diffusion asset dynamics is manifestly inadequate for relatively short time - scales , and we need to introduce jumps into the model , see , e.g. , @xcite .",
    "therefore , we choose a lvy jump - diffusion driver for the asset dynamics .",
    "multi - dimensional lvy processes find various applications in mathematical finance .",
    "they are used in modeling basket equity derivatives , various credit derivatives , etc .",
    "unfortunately , tractability of multi - dimensional lvy processes is rather limited .",
    "in addition , it is difficult to study such processes because they suffer from the curse of dimensionality .",
    "various numerical methods , including analytical , semi - analytical , finite - difference ( fd ) , monte - carlo methods , and their combinations have been used for solving the corresponding problems , again see , e.g. , a survey in @xcite and references therein .",
    "certainly , rather straightforward monte carlo method can be proposed to simulate multi - dimensional lvy processes . however , in general it is both slow or inaccurate .",
    "therefore , finite difference methods seem to be a viable alternative for 2d and 3d problems , despite the fact that in the 3d case such methods can be relatively slow ( but definitely faster than the corresponding monte carlo method ) .",
    "the authors are aware of limited number of papers on mathematical finance , which are using fd methods to solve 2d partial integro - differential equation ( pide ) describing the evolution of two fully correlated assets , see , e.g. , @xcite , @xcite . in @xcite , the authors use a bivariate distribution proposed in @xcite and consider normal and exponentially distributed multivariate jumps . in @xcite ,",
    "the authors consider assets , which are correlated twofold .",
    "first , diffusion components are correlated in the standard manner because they are driven by correlated brownian motions .",
    "second , jump components are correlated because for each asset they are represented as a sum of a ) systemic exponential jumps common for all assets , and b ) idiosyncratic exponential jumps specific for a particular asset . from a historical perspective",
    ", this idea can be traced back to the work of vasicek , who developed a multi - factor structural model assuming that the dynamics of individual assets can be described as a sum of systemic and idiosyncratic parts , @xcite .",
    "however , other lvy models could be of interest as well , see , e.g. , @xcite , where it is shown that generalized hyperbolic models fit the market data pretty well .",
    "therefore , an extended framework which allows for general lvy models to be used when modeling jumps is highly desirable .",
    "below we provide a short survey of various approaches to introduce multivariate correlated jumps via lvy s copula , multivariate subordinators of the brownian motion , etc . , as well as discuss their advantages and pitfalls . our main concerns with regard to the existing approaches",
    "are two - fold : a ) some of them are not flexible enough to meet all the modeling requirements , because they impose some undesirable restrictions on the jump correlation structure ; b ) they suffer from the curse of dimensionality in the sense that their complexity is polynomial rather than linear in each dimension .",
    "another observation is that even in the 1d case traditional methods for solving pides experience some problems , see a survey in @xcite , and references therein . in the multi - dimensional case",
    "these problems become even harder . to deal with these problems ,",
    "we choose a particular way of introducing correlated jumps and combine it with the multi - dimensional version of the matrix exponential method proposed first in @xcite and later further elaborated in @xcite .",
    "the presented construction allows different jumps to be used for modeling the idiosyncratic and common factors .",
    "for example , in the 2d case we can represent idiosyncratic jumps of the first bank by using the meixner model of @xcite , idiosyncratic jumps of the second bank by using the merton model , and simulate their common jumps by using the cgmy model .",
    "we do not claim that such rich choice of lvy processes is necessary in practice , since the actual jump distribution is hard to establish with certainty , merely that it is possible to do . in our experience , hyper - exponential jumps introduced in @xcite are more than adequate for all practical purposes .",
    "we do nt consider every possible combination of lvy processes in this paper , since this could be done based on the general principles described in @xcite .",
    "however , as an example , we do consider a model with gaussian idiosyncratic jumps and exponential systemic jumps . as part of this example , we think of idiosyncratic jumps as two - sided , while systemic jumps as one - sided . in this sense ,",
    "our example should be ideologically similar to that in @xcite .",
    "however , our method is not restricted by this choice and differs from that of @xcite in several important respects : a ) we use gaussian and exponential jumps just as an example , other common jumps and univariate marginals could be used as well ; b ) we use the matrix exponential method , rather than the traditional method for solving the corresponding pide ; c ) we present a splitting method to provide solutions of the 2d and 3d problems with second order of accuracy in both space and time , and prove convergence of the method .",
    "our method is of the linear complexity ( i.e. , @xmath0 in the 2d case and @xmath1 in the 3d case ) provided that the merton , kou , cgmy or meixner lvy models are used .",
    "our method is faster than the fft method used in @xcite .    in this paper , we concentrate on our structural default model for two or three banks with mutual liabilities .",
    "the method can also be used to price basket options .",
    "we show that accounting for these liabilities affects both the joint survival probability of these banks , which is to be expected , as well as their marginal survival probabilities , which is not the case when mutual liabilities are ignored .",
    "this fact has to be taken into account when marginals are calibrated to the market cds spreads .",
    "we provide several numerical examples in order to demonstrate that the presence of mutual obligations could potentially strongly affect the corresponding survival probabilities , and , by implication , the stability of the inter - bank system , especially in the 3d case .",
    "the new results of the paper are as follows : a ) interbank mutual obligations are incorporated in the structural default credit model with correlated jumps , and their impact on the joint and marginal probabilities is investigated both qualitatively and quantitatively ; b ) new splitting method is proposed to solve the corresponding pide with correlated jumps in the 2d and 3d cases .",
    "the method includes new steps that do nt appear in the 1d case . for many popular lvy models",
    "the method provides linear complexity in each dimension and is unconditionally stable .",
    "the rest of the paper is organized as follows . in section  [ stat ]",
    "we describe our multi - dimensional structural model , which is an extension of @xcite . in section [ seccorjumps ]",
    "we provide a short survey of the existing approaches to multivariate correlated jumps , and describe the one we find to be particularly suitable for our goals . in section  [ frac ]",
    "we shortly describe the method of @xcite and extend it to the multi - dimensional case . in section  [ splitting ]",
    "we describe the splitting algorithm , which is adopted for solving the corresponding multi - dimensional pide . in section  [ np ]",
    "we provide a detailed numerical scheme for solving the fractional jump equations and prove the unconditional stability , second order accuracy and convergence of the scheme .",
    "we also emphasize that our scheme preserves positivity of the solution .",
    "the results of our numerical experiments are discussed in sections  [ ne2d ] ( the 2d case ) and [ ne3d ] ( the 3d case ) . in section  [ ne3d ] , we describe necessary details of the numerical scheme used in the 3d case .",
    "we draw our conclusions in section  [ conclusion ] .",
    "similar to @xcite we consider a multi - dimensional structural model inspired by the familiar model of @xcite , see @xcite and references therein .",
    "first , for simplicity , assume that we have just two banks with external assets @xmath2 , @xmath3 and liabilities @xmath4 , and no mutual liabilities . here",
    "@xmath5 is the deterministic growth factor @xmath6 where @xmath7 is the forward rate .",
    "also assume that the default barrier @xmath8 is a deterministic function of time .",
    "in this setup the default boundary has a kink at @xmath9 . ] : @xmath10 where @xmath11 is the average recovery of the bank s liabilities , and @xmath12 is the debt maturity . under normal circumstances , @xmath11 has a typical value @xmath13 .",
    "we define the @xmath14th bank s default time @xmath15 assuming continuous monitoring as follows @xmath16.\\ ] ]    let us extend this approach by assuming that the banks in question do have mutual liabilities , which we denote by @xmath17 ; below we assume that @xmath18 .",
    "thus , the total assets and liabilities of the @xmath14th bank are @xmath19 and @xmath20 , respectively .",
    "accordingly , the default time of the first bank has the form @xmath21 ,   \\label{def1}\\ ] ] where @xmath22 the default time of the second bank has a similar form @xmath23 .",
    "\\label{def2}\\ ] ]    a new situation occurs , however , in case of default of one of the banks . in case when the second bank defaults , it pays back to its creditors only a portion of its liabilities , namely @xmath24 .",
    "however , the first bank pays back to the successors of the second bank the full amount @xmath25 , assuming of course that it does not default simultaneously with the second bank .",
    "thus , at time @xmath26 the first bank receives from the second bank the amount @xmath27 and pays the amount @xmath25 .",
    "therefore , the new asset value @xmath28 of the first bank becomes @xmath29 , while its liability value becomes @xmath30 .",
    "we assume that the actual external assets do not jump in value , while the outside liabilities do get adjusted .",
    "if the amount @xmath31 is positive , i.e. , the first bank gets extra cash , which it spends retiring some of the external liabilities .",
    "if this amount is negative , then it is borrowed from the external sources . in both cases",
    "the total external liabilities become @xmath32 accordingly , the new default barrier for the first bank could be defined as @xmath33 so that its default time has the form @xmath34 . \\label{def1after}.\\ ] ] it is easy to see , that after the default of the second bank , the default boundary of the first bank increases by the amount of @xmath35 similarly , @xmath36 thus , the default boundary of the first bank jumps up by the increment @xmath37 at time @xmath26 , and the default boundary of the second bank jumps up by the increment @xmath38 at time @xmath39 .",
    "mathematically , this means that our problem now has floating boundaries that are deterministic functions of time which could increase at some moment by jumping to a higher value .    to illustrate the above observation ,",
    "let us consider fig .",
    "[ fig1 ] where the situation is depicted at some moment of time @xmath40 .",
    "if we do nt take into account mutual liabilities @xmath25 and @xmath41 , then the default boundaries are : for the first bank - a vertical line along the path `` 5 - 2 - 3 - 6 '' ; for the second bank - a horizontal line along the pass `` 9 - 3 - 7 - 4 '' . in the presence of mutual liabilities ,",
    "the default boundary for the first bank becomes `` 5 - 2 - 3 - 7 - 8 '' , while for the second bank it has the form `` 1 - 2 - 3 - 7 - 4 '' .    a similar consideration can be used to show that the calculation of the marginal survival probabilities ( which are needed to calibrate the model to the market cds spreads ) is strongly impacted by mutual liabilities . to emphasize this point , again consider the domain in fig  [ fig1 ] .",
    "suppose we need to know @xmath42 which is the marginal survival probability of the first bank conditional on the asset value @xmath43 of the second bank .",
    "in the presence of interbank liabilities we observe a new situation since the dynamics the first bank depends on the possible default of the second bank via the boundary conditions .",
    "hence , the problem of computing @xmath44 remains inherently two - dimensional in contrast to the situation with no interbank liabilities .    in what follows",
    "we provide some numerical results that demonstrate this behavior in the case of two and three firms by solving the corresponding 2d and 3d pides describing the evolution of both joint and survival probabilities in time and space .",
    "we also discuss how parameters of the model affect the magnitude of the effect .",
    "to proceed further , we need to specify the dynamics of the external risky assets @xmath45 ; we assume that it could include both diffusion and jumps components .",
    "we also assume that these assets are correlated as follows :    1 .",
    "diffusion components are correlated with the correlation coefficient @xmath46 .",
    "jumps are correlated with the correlation coefficient @xmath47 ( see below for a more precise definition of this correlation coefficient ) .",
    "changes in the firm value due to jumps and diffusion are uncorrelated .",
    "we assume that the underlying asset prices @xmath2 are driven by exponential lvy processes @xmath48 under an appropriate pricing measure , each @xmath49 is characterized by a triplet @xmath50 with the drift @xmath51 , volatility @xmath52 , and lvy measure @xmath53 , @xmath54 where @xmath55 is a standard brownian motion on @xmath56 and @xmath57 is a pure jump process . with the local volatility function @xmath58 .",
    "] we consider this process under the pricing measure , therefore , @xmath59 is a martingale .",
    "this allows us to express @xmath60 as ( @xcite ) ( further on we omit sub - index @xmath14 for simplicity ) @xmath61 with @xmath62 at this stage , the jump measure @xmath63 is left unspecified , because we are open to consider all types of jumps including those with finite and infinite variation , and finite and infinite activity .",
    "let us introduce the logarithmic variables @xmath64 and define the joint survival probability as follows @xmath65.\\ ] ] the joint survival probability solves the following pide , see @xcite and also @xcite @xmath66q   \\label{pide},\\ ] ] where @xmath67 is the backward time , and @xmath68 is the two - dimensional linear convection - diffusion operator of the form @xmath69 and @xmath70 is the jump operator @xmath71 \\nu(d y_1 dy_2 ) , \\nonumber\\end{aligned}\\ ] ] where @xmath72 is the two - dimensional lvy measure .",
    "this pide has to be solved subject to the boundary and terminal conditions .",
    "the terminal condition reads @xmath73 the boundary conditions could be set as the dirichlet conditions at @xmath74 .",
    "obviously , @xmath75 as @xmath76 , @xmath77 should replicate the marginal survival probability @xmath78 .",
    "this condition , however , must be supplemented with the boundary condition when both @xmath79 and @xmath80 .",
    "a natural choice is @xmath81 .",
    "various choices of the lvy measures that could be used for this model as well as an approach to introduce the correlated jumps are discussed in the next section .",
    "there exist at least three known ways of introducing correlated jumps , see @xcite and references therein .",
    "the first one is to explicitly specify a multivariate distribution of the jump process .",
    "this could be achieved , for instance , as in a celebrated marshall - olkin paper ( @xcite ) who use a multivariate exponential distribution as a model for failure times , with the possibility of simultaneous defaults .",
    "see also @xcite for the discussion of this approach .",
    "the other possibility could be to use lvy copula , which in application to the structural credit models was used by @xcite . however , copula - based models impose some restrictive constraints on the jump parameters to preserve marginal distributions , which make it difficult to model arbitrary ( positive and negative ) correlations between jumps . in other words ,",
    "due to restrictions on the parameters controlling marginal distributions , the correlation coefficient does nt cover the entire range @xmath82 $ ] .",
    "the same problem is inherent in @xcite construction as well , since this model does nt allow negative correlations between jumps , see , e.g. , @xcite .",
    "another numerical approach to this problem has been established in @xcite .",
    "the authors develop galerkin methods based on a wavelet - compression using the tensor structure of the multi - dimensional pide operator to cope with the complexity stemming from jumps as well as with the curse of dimensionality .",
    "the multivariate lvy processes in their framework include jump diffusions and further allow for pure jump processes .",
    "the correlation of the processes is constructed based on lvy copulas , see also @xcite .",
    "accordingly , it is a subject of same restrictions on the model parameters .",
    "another construction in @xcite is also partly inspired by the work of @xcite with a significant advantage that both positively and negatively correlated jumps can be represented .",
    "the second approach uses multivariate subordinated brownian motions ( or multivariate subordinators of brownian motions ) , where the lvy subordinator could consist of both common as well as idiosyncratic parts .",
    "it is advocated by @xcite , see also survey in @xcite and references therein . as applied to our problem it provides analytical tractability if the local volatility is ignored . in this case",
    "the characteristic function of the entire jump - diffusion model is known in closed form , and transform methods , like fft or cosine transform could be used . with allowance for the local volatility",
    "this approach becomes inefficient , because the jump integral must be computed at every point in time and space .",
    "in addition , this approach can only accommodate strictly positive correlation values due to restrictions on the parameters controlling the correlation coefficients .",
    "they are required to ensure the existence of the characteristic function of the processes involved , see @xcite .",
    "therefore , we introduce the correlated jumps following the third approach @xcite , which constructs the jump process as a linear combination of two independent lvy processes representing the systematic factor and the idiosyncratic shock , respectively . note , that such an approach was also previously mentioned in @xcite .",
    "it has an intuitive economic interpretation and retains nice tractability , as the multivariate characteristic function in this model is available in closed form .",
    "the main result of @xcite that immediately follows from theorem  4.1 of @xcite ( see also @xcite ) is given by :    [ prop0 ] let @xmath83 be independent lvy processes on a probability space @xmath84 , with characteristic functions @xmath85 and @xmath86 , for @xmath87 respectively .",
    "then , for @xmath88 @xmath89 is a lvy process on @xmath90 .",
    "the resulting characteristic function is @xmath91    by construction every factor @xmath92 includes a common factor @xmath93 .",
    "therefore , all components @xmath92 could jump together , and loading factors @xmath94 determine the magnitude ( intensity ) of the jump in @xmath95 due to the jump in @xmath93 .",
    "thus , all components of the multivariate lvy process @xmath96 are dependent , and their pairwise correlation is given by ( again see @xcite and references therein ) @xmath97 such a construction has multiple advantages , namely :    1 .   as @xmath98",
    ", both positive and negative correlations can be accommodated 2 .   in the limiting case @xmath99 or @xmath100 or @xmath101 the margins become independent , and @xmath102 . the other limit",
    "@xmath103 or @xmath104 represents a full positive correlation case , so @xmath105 .",
    "accordingly , @xmath106 represents a full negative correlation case as in this limit @xmath107 .",
    "one more advantage of this approach becomes apparent if we want the margin distribution @xmath95 to be fixed .",
    "then a set of conditions on convolution coefficients could be imposed to preserve the margin .",
    "this is reasonable from the practical viewpoint as the entire credit product could be illiquid , and , therefore , the market quotes necessary to calibrate the full correlation matrix might not be available . hence , as an alternative",
    ", the marginal distributions could be first calibrated to a more liquid market of the components @xmath95 , and the entire correlation structure should preserve these marginals . as a first step , this defines parameters of the idiosyncratic factors . as the next step ,",
    "the remaining parameters of the entire correlation structure are , based on a separate consideration .",
    "note , that a similar idea is used in another recent paper @xcite , where the authors concentrate on two specific models for the marginals , and achieve tractability by choosing the relevant parameters in such a way that univariate marginals are separated from dependence structure .",
    "however , in the present approach , any model could be treated in a unified way .    according to this setup",
    ", the instantaneous correlation between the log - assets @xmath108 and @xmath109 reads @xmath110    as far as the structural default model is concerned , positive jumps might not be necessary .",
    "however , below we keep them for generality , as the proposed approach to modeling correlated jumps is applicable without any modification in other settings , where both positive and negative jumps are important .",
    "assuming that some particular lvy models are chosen to construct processes @xmath111 and @xmath93 , let us look more closely at . in doing that we follow the method proposed in @xcite ( first presented at global derivatives and risk conference , roma 2009 ) and then further elaborated on in @xcite .",
    "the key idea is to represent the jump integral in the form of a pseudo - differential operator and then formally solve , thus obtained evolutionary partial pseudo - differential equation via a matrix exponential .    to be clear ,",
    "we start with a one - dimensional case .",
    "it is well known from quantum mechanics @xcite that a translation ( shift ) operator in @xmath112 space could be represented as @xmath113 with @xmath114 = const , so @xmath115    therefore , the one - dimensional integral corresponding to can be formally rewritten as @xmath116 \\nu(dy ) = \\mathcal{j } q(x , t ) , \\\\ \\mathcal{j } & \\equiv \\int_\\mathbb{r}\\left [ \\exp \\left ( y \\dfrac{\\partial } { \\partial x } \\right ) - 1 - ( e^y-1 ) \\fp{}{x } \\right ] \\nu(dy ) .",
    "\\nonumber\\end{aligned}\\ ] ]    in the definition of the operator @xmath70 ( which is actually an infinitesimal generator of the jump process ) , the integral can be formally computed under some mild assumptions about existence and convergence if one treats the term @xmath117 as a constant .",
    "therefore , the operator @xmath70 can be considered as some generalized function of the differential operator @xmath118 .",
    "we can also treat @xmath70 as a pseudo - differential operator .",
    "it is important to emphasize that @xmath119\\partial_x = \\mbox{mgf } ( \\partial_x ) - [ \\log \\mbox{mgf}(1)]\\partial_x,\\ ] ] where @xmath120 is the characteristic exponent of the jump process , and @xmath121 is the moment generation function corresponding to this characteristic exponent .",
    "this directly follows from the lvy - khinchine theorem .",
    "note , that the last term on the right hand side of is a compensator as the characteristic exponent is computed using the expectation under a risk - neutral measure @xmath122 . in other words ,",
    "the last term is added to make the forward price to be a true martingale under this measure .",
    "this representation is advantageous because it transforms a linear non - local integro - differential operator ( jump operator ) into a linear local pseudo - differential ( fractional ) operator .",
    "the operator @xmath70 can be analytically computed for various popular lvy models , hence @xmath70 admits an explicit representation in the form of the pseudo - differential operator .",
    "accordingly , a pure jump evolutionary equation @xmath123 could be formally integrated ( under some mild existence conditions ) to provide @xmath124 the operator @xmath125 is the matrix exponential and is understood as a taylor series expansion of @xmath126 .",
    "in @xcite it is shown that the matrix exponential can be efficiently computed on a finite difference grid for various jump models , namely merton , kou , cgmy , nig , general hyperbolic and meixner models .",
    "efficiency of this method in general is not worse than that of the fft , and in many cases is linear in @xmath127 - the number of the grid points . ] .",
    "the proposed method is almost universal , i.e. , it allows solving pides for various jump - diffusion models in a unified form .",
    "second order finite difference schemes in both space and time are constructed in such a way that i ) they are unconditionally stable , and ii ) they preserve positivity of the solution . therefore , we assume this method to be robust and more efficient than constructions proposed in the literature to solve a similar class of problems , e.g. , galerkin methods of @xcite which even for sparse matrices do nt reach the linear complexity in each dimension . in addition , the construction of the correlated jumps using the lvy copulas used in @xcite is restrictive as this was already discussed in section  [ seccorjumps ] .",
    "now let us use the same idea for getting fractional representation of the jump integral in the two - dimensional case .",
    "the translational two - dimensional operator in @xmath128 space could be similarly represented as @xmath129 with @xmath130 = const , so @xmath131 therefore , the whole integral in could be re - written in the form @xmath132 \\nu(d y_1 d y_2).\\ ] ] by using proposition  [ prop0 ] and the lvy - khinchine theorem , similar to how the was derived , we can show that @xmath133\\partial_{x_j},\\ ] ] based on @xcite we know how to deal with all the terms in this expression except the new term @xmath134 which represents a two - dimensional characteristic exponent of the common jump process @xmath93 .",
    "we shall discuss this in the next sections .",
    "to solve we use an fd approach with splitting in financial processes .",
    "we refer the reader to @xcite to the detailed description of the splitting algorithm . splitting ( a.k.a .",
    "the method of fractional steps ) reduces the solution of the original k - dimensional unsteady problem to the solution of @xmath135 one - dimensional equations per time step .",
    "for example , consider a two - dimensional diffusion equation with a solution obtained by using some fd method . at every time step ,",
    "a standard discretization in space variables is applied , such that the fd grid contains @xmath136 nodes in the first dimension and @xmath137 nodes in the second dimension .",
    "then the problem reduces to solving a system of @xmath138 linear equations with a block - diagonal matrix .",
    "in contrast , utilization of splitting results in , e.g. , @xmath136 systems of @xmath137 linear equations , where the matrix of each system is banded ( tridiagonal ) . the latter approach is easy to implement and , more importantly , provides significantly better performance .    a natural choice for the first step would be to split operators @xmath68 and @xmath70 in separately due to their different mathematical nature .",
    "so a special scheme could be applied at every step of the splitting procedure . as operators @xmath68 and @xmath70 are non - commuting , we use strang s splitting scheme , @xcite , which provides second order approximation in time @xmath139 assuming that at every step of splitting the corresponding equations are solved also with the second order accuracy in time . for more details on how to apply strang s splitting to fractional equations see @xcite and references therein",
    ". the entire numerical scheme reads @xmath140    thus , instead of an non - stationary pide , we obtain one pide with no drift and no re - wri diffusion ( the second equation in ) and two non - stationary pdes ( the first and third ones in ) .    proceeding in a similar way ,",
    "the second step is to apply splitting to the second equation in .",
    "we represent in the form @xmath141 where @xmath142\\partial_{x_j } , \\qquad j=1,2 \\\\ \\mathcal{j}_{12 } & = 1 + \\psi_z \\left(-i \\sum_{j=1}^2 b_j \\partial_{x_j } \\right).\\end{aligned}\\ ] ] obviously , operators @xmath143 and @xmath144 commute , so that @xmath145 therefore , replacing the second step in with another strang s splitting using , we finally obtain @xmath146",
    "due to the splitting nature of our entire algorithm represented by , each step of splitting is computed using a separate numerical scheme .",
    "all schemes provide second order approximation in both space and time , are unconditionally stable and preserve positivity of the solution .    for the first and the last step where a pure convection - diffusion two - dimensional problem has to be solved we use a hundsdorfer - verwer scheme ,",
    "see @xcite .",
    "a non - uniform finite - difference grid is constructed similar to @xcite .    for the steps 2,3,5,6 we choose the merton jump model . in other words ,",
    "the idiosyncratic jump part of each component @xmath147 is represented as gaussian .",
    "computation of the matrix exponential @xmath148 could be done with complexity @xmath149 at every time step .",
    "this is because when computing @xmath150 the second variable @xmath109 is a dummy variable , while computation of @xmath151 is @xmath152 , see @xcite .",
    "construction of the jump grid , which is a superset of the finite - difference grid used at the first ( diffusion ) step is also described in detail in @xcite .    for step 4 ( common or systemic jumps )",
    "we choose the kou double exponential jumps model proposed in @xcite .",
    "its density is @xmath153 dx,\\ ] ] where @xmath154 is the jumps intensity , @xmath155 , @xmath156 , @xmath157 ; the first condition was imposed to ensure that the underlying asset price has a finite expectation .    using this model a one - dimensional representation for @xmath70",
    "is given in @xcite .",
    "similarly , in a two dimensional case we obtain @xmath158 , \\\\ \\triangledown_{x_1 } & \\equiv \\partial_{x_1 } , \\quad \\triangledown_{x_2 } \\equiv \\partial_{x_2 } , \\quad -\\theta_2 < re(b_1 \\triangledown_{x_1 } + b_2 \\triangledown_{x_2 } ) < \\theta_1 .",
    "\\nonumber\\end{aligned}\\ ] ] the inequality @xmath159 is an existence condition for the integral defining @xmath70 and should be treated as follows : the discretization of the operator @xmath160 should be such that all eigenvalues of matrix @xmath161 , a discrete analog of @xmath160 , obey this condition .",
    "we proceed in a way similar to the one - dimensional case . to this end",
    "we can use the ( 1,1 ) pde approximation of @xmath162 which provides @xmath163 approximation of the form @xmath164^{-1}[1 + \\frac{1}{2}\\delta \\tau \\mathcal{j}_{12 } ] + o(\\delta \\tau^3).\\ ] ] this scheme can also be re - written as @xmath165,\\ ] ] and this equation could be solved using the picard fixed - point iterations . in doing so , we observe that the entire product @xmath166 with @xmath167 given in can be calculated as follows .      observe that the vector @xmath168 solves the equation @xmath169",
    "this is a two - dimensional linear pde of the first order .",
    "it could be solved numerically with the second order approximation in @xmath170 using the peaceman - rachford adi method , see @xcite @xmath171 z^*(x_1,x_2,\\tau ) & = \\left[\\left(s - \\dfrac{1}{2 } \\theta_1 \\right)+ b_2 \\triangledown_{x_2}\\right ] z^k(x_1,x_2,\\tau ) + b \\\\",
    "\\left[\\left(s + \\dfrac{1}{2 } \\theta_1 \\right)- b_2 \\triangledown_{x_2}\\right ] z^{k+1}(x_1,x_2,\\tau ) & = \\left[\\left(s - \\dfrac{1}{2 } \\theta_1 \\right)+ b_1 \\triangledown_{x_1}\\right]z^*(x_1,x_2,\\tau ) + b   \\nonumber \\\\ b & \\equiv p \\theta_1 q(x_1,x_2,\\tau ) .",
    "\\nonumber\\end{aligned}\\ ] ] here @xmath172 is some parameter that could be chosen in a special way to provide convergence of the method , see appendices .",
    "the number @xmath135 is the iteration number , the whole process starts with @xmath173 .    before constructing a finite difference scheme to solve this equation we need to introduce some definitions . define a one - sided _ forward _ discretization of @xmath160 , which we denote as @xmath174/h$ ] .",
    "also define a one - sided _ backward _ discretization of @xmath160 , denoted as @xmath175/h$ ] .",
    "these discretizations provide first order approximation in @xmath176 , e.g. , @xmath177 . to provide the second order approximations , use the following definitions .",
    "define @xmath178 - the _ central _ difference approximation of the second derivative @xmath179 , and @xmath180 - the _ central _ difference approximation of the first derivative @xmath160 . also define a one - sided second order approximations to the first derivatives : _ backward _ approximation @xmath181/(2 h)$ ] , and _ forward _ approximation @xmath182/(2 h)$ ] .",
    "also @xmath183 denotes a unit matrix .",
    "all these definitions assume that we work on a uniform grid , however this could be easily generalized for the non - uniform grid as well , see , e.g. , @xcite .",
    "the following proposition now solves the problem    [ propkou1 ] consider the following discrete approximation of the adi scheme : @xmath184 z^*(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big)i_{x_2 } + b_2 a(x_2)\\big]z^k(x_1,x_2,\\tau ) + b \\\\",
    "\\big[\\big(s & + \\dfrac{1}{2 } \\theta_1 \\big)i_{x_2 } - b_2 a(x_2)\\big ] z^{k+1}(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big)i_{x_1 } + b_1 a(x_1)\\big]z^*(x_1,x_2,\\tau ) + b   \\nonumber \\\\ b & \\equiv p \\theta_1 q(x_1,x_2,\\tau ) , \\qquad a(x_i ) = \\begin{cases } a_2^f(x_i ) , & b_i > 0 \\\\ a_2^b(x_i ) , & b_i < 0 , \\qquad i=1,2 \\end{cases } \\nonumber\\end{aligned}\\ ] ]    then this scheme is unconditionally stable , approximates the original pde with accuracy @xmath185 and preserves positivity of the solution .    see appendix  [ ap1 ]",
    ".    we can start iterations in by choosing @xmath186 . in our experiments",
    "the scheme converges to the solution after 5 - 6 iterations if we choose @xmath187 in and @xmath188 in .",
    "observe that the vector @xmath189 solves the equation @xmath190 this is also a two - dimensional linear pde of the first order , so",
    "again we apply the peaceman - rachford method @xmath191 z^*(x_1,x_2,\\tau ) & = \\left[\\left(s - \\dfrac{1}{2 } \\theta_2 \\right)- b_2 \\triangledown_{x_2}\\right](1-p ) z^k(x_1,x_2,\\tau ) + b \\\\ \\left[\\left(s + \\dfrac{1}{2 } \\theta_2 \\right)+ b_2 \\triangledown_{x_2}\\right ] z^{k+1}(x_1,x_2,\\tau ) & = \\left[\\left(s - \\dfrac{1}{2 } \\theta_2 \\right)- b_1 \\triangledown_{x_1}\\right]z^*(x_1,x_2,\\tau ) + b   \\nonumber \\\\ b & \\equiv ( 1-p)\\theta_2 q(x_1,x_2,\\tau )   \\nonumber\\end{aligned}\\ ] ]    the next proposition provides a construction of the finite difference scheme to solve the problem    [ propkou2 ] consider the following discrete approximation of the adi scheme : @xmath192 z^*(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big)i_{x_2 } - b_2 a(x_2)\\big]z^k(x_1,x_2,\\tau ) + b \\\\",
    "\\big[\\big(s & + \\dfrac{1}{2 } \\theta_2 \\big)i_{x_2 } + b_2 a(x_2)\\big ] z^{k+1}(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big)i_{x_1 } - b_1 a(x_1)\\big]z^*(x_1,x_2,\\tau ) + b   \\nonumber \\\\ b & \\equiv ( 1-p ) \\theta_2 q(x_1,x_2,\\tau ) , \\qquad a(x_i ) = \\begin{cases } a_2^b(x_i ) , & b_i > 0 \\\\ a_2^f(x_i ) , & b_i < 0 , \\qquad i=1,2\\end{cases } \\nonumber\\end{aligned}\\ ] ] then this scheme is unconditionally stable , approximates the original pde with @xmath185 and preserves positivity of the solution .    see appendix  [ ap2 ] .",
    "overall , our experiments show that the first picard scheme converges after 2 - 3 iterations to the absolute accuracy of @xmath193 .    to summarize , the total complexity of the proposed splitting algorithm at every time step is @xmath194 , where @xmath195 is some constant coefficient . to estimate it ,",
    "observe that the solution of the convection - diffusion equation requires five sweeps , where at every sweep either @xmath136 systems of linear equations with the tridiagonal matrix of size @xmath137 , or @xmath137 systems of size @xmath136 have to be solved , see @xcite .",
    "the idiosyncratic jump parts modeled by the merton jump model are solved with the complexity @xmath149 ( i.e. , at this step @xmath196 ) using the improved fast gauss transform ( ifgt ) , see @xcite . as we need to provide two steps of splitting in the @xmath108 dimension , and two other steps in the @xmath109 ,",
    "the total number of sweeps is four .",
    "finally the above algorithm for computing common jumps using the kou model requires 2 - 3 picard iterations for the matrix exponential , and at every iteration we solve 2 adi systems of linear equations using 5 - 6 iterations , so in total about 30 sweeps .",
    "thus , overall @xmath195 is about 44 .",
    "this is still better than a straightforward application of the fft which usually requires the number of fft nodes to be a power of 2 with a typical value of 2@xmath197 .",
    "it is also better than the traditional approach which considers approximation of the linear non - local jump integral @xmath70 on some grid and then makes use of the fft to compute a matrix - by - vector product . indeed , when using fft for this purpose we need two sweeps per dimension using a slightly extended grid ( with , say , the tension coefficient @xmath198 ) to avoid wrap - around effects , @xcite .",
    "therefore the total complexity per time step could be at least @xmath199 which even for a relatively small fft grid with @xmath200 , and @xmath201 is about 9 times slower than our method .",
    "also traditional approach experiences some other problems for jumps with infinite activity and infinite variation , see survey in @xcite and references therein .",
    "if instead of the kou model one wants to apply the merton jump model for systemic jumps , it becomes a bit more computationally expensive .",
    "indeed , at every time step the multi - dimensional diffusion equation with constant coefficients could be effectively solved by using the ifgt .",
    "suppose , in doing so , we want to achieve the accuracy @xmath202 .",
    "then , roughly , we need to keep @xmath203 terms in the taylor series expansion of ifgt , and the total complexity for the two - dimensional case @xmath204 is @xmath205 , see @xcite .",
    "we start with the one - dimensional model for two reasons .",
    "first , the solution of this model is used as the boundary condition for the two - dimensional problem .",
    "second , in some cases , e.g. , for the exponential jumps , this model could be solved in the closed form , and , therefore , can be utilized for verification of the method .    in the first test",
    "we consider the one - dimensional pure diffusion problem .",
    "we solve it as a limiting case of the two - dimensional problem when the volatility and drift of the second asset vanish .",
    "this solution for the survival probability is compared with the analytical solution which in this case coincides with the price of a digital down - and - out call option , see @xcite .",
    "thus , in this test the robustness of our convection - diffusion fd scheme is validated .",
    "parameters of the model used in this test are given in table  [ tab1dd ] , and the results are presented in fig .  [ dif1dd ] where the absolute value of the relative difference between the analytical price and one computed by our finite - difference method is depicted as a function of @xmath206 . as is shown in this figure",
    "the relative error is below 1% everywhere except in the close vicinity of the barrier where the value of @xmath207 itself is small .",
    "@xmath208 & @xmath209 & @xmath210 & @xmath211 & @xmath212 & @xmath213 & @xmath214 & t & @xmath215 & @xmath216 100 & 40 & 0 & 0 & 0 & 1 & 0 & 0.05 & 1 & 0.2 & 0    in the second test we extend the previous case by adding exponential jumps to the first component . again",
    ", this problem admits an analytical solution which could be expressed via the inverse laplace transform , see @xcite where this problem was solved by using fluctuation identities .",
    "it can also be solved by using a generalized transform of @xcite combined with the wiener - hopf method , see , e.g. , @xcite .",
    "the corresponding solution reads @xmath217 here @xmath218 is the only negative root of the characteristic equation in the wiener - hopf method , @xmath219 , and @xmath220 is the default boundary .    also within the framework of @xcite which we use in this paper ,",
    "exponential jumps were never considered .",
    "therefore , in appendix  [ ap4 ] for completeness , we construct a finite - difference algorithm for exponential jumps .    in fig .",
    "[ dif1dj ] the absolute value of the relative difference between the analytical and numerical solutions is depicted as a function of @xmath206 . in this experiment",
    "we set the intensity of the jumps @xmath221 , and the parameter of the exponential distribution @xmath222 .",
    "the difference is less than 1% except close to the barrier ; see also table  [ tabcomp ] .",
    "@xmath223 & @xmath224 & @xmath225 40.85 & 0.008805 & 0.008909 & -0.000103 41.69 & 0.017710 & 0.017874 & -0.000164 42.53 & 0.026710 & 0.026972 & -0.000262 43.36 & 0.035802 & 0.036188 & -0.000387 44.18 & 0.044982 & 0.045523 & -0.000541 44.99 & 0.054251 & 0.054981 & -0.000729 45.79 & 0.063610 & 0.064563 & -0.000953 46.59 & 0.073058 & 0.074273 & -0.001215 47.38 & 0.082601 & 0.084116 & -0.001515 48.16 & 0.092241 & 0.094094 & -0.001853 48.94 & 0.101984 & 0.104212 & -0.002228 49.70 & 0.111833 & 0.114472 & -0.002639 50.46 & 0.121795 & 0.124878 & -0.003083 51.22 & 0.131876 & 0.135431 & -0.003556 51.96 & 0.142080 & 0.146134 & -0.004054 52.70 & 0.152413 & 0.156985 & -0.004571 53.43 & 0.162881 & 0.167985 & -0.005104 54.16 & 0.173486 & 0.179132 & -0.005646 54.88 & 0.184233 & 0.190423 & -0.006190",
    "55.60 & 0.195123 & 0.201854 & -0.006732      in the first test we solve with parameters of the model given in table  [ tab1 ] .",
    "@xmath226 & @xmath208 & @xmath209 & @xmath210 & @xmath211 & @xmath212 & @xmath213 & @xmath214 & t & @xmath215 & @xmath216 & @xmath46 110 & 100 & 80 & 85 & 10 & 15 & 0.4 & 0.35 & 0.05 & 1 & 0.2 & 0.3 & 0.5    for idiosyncratic jumps we chose the merton model with parameters ( @xmath227 , and for systemic jumps we chose the kou model with parameters @xmath228 , as shown in table  [ tab2 ] .",
    "we use the upper script @xmath229 to mark the @xmath14th bank .",
    "also in these experiments without loss of generality we use @xmath230 .",
    "we computed all tests using a @xmath231 spatial grid for the convection - diffusion problem .",
    "also we use a constant step in time @xmath232 , so that the total number of time steps for a given maturity is also 100 .",
    "the non - uniform grid for jumps in each direction is a superset of the convection - diffusion grid up to @xmath233 .",
    "it is built using a geometric progression and contains 80 nodes .",
    "@xmath234 & @xmath235 & @xmath236 & @xmath237 & @xmath238 & @xmath239 & @xmath240 & @xmath241 & @xmath242 3 & 0.5 & 0.3 & 0.3 & 0.4 & 0.3445 & 3.0465 & 3.0775 & 0.2 & 0.3    in fig .",
    "[ test1 ] the joint survival probability @xmath243 as computed in our experiment is presented at @xmath244 .    to better see the behavior of the graph close to the initial values of @xmath245 we zoom - in this picture in the vicinity of these values , see fig .",
    "[ test1big ] .",
    "we compare these survival probabilities with those obtained when two banks do nt have mutual liabilities .",
    "the difference in the corresponding probabilities is shown in fig .",
    "[ testdif ] .",
    "as expected the maximal difference occurs near default boundaries where the difference could be of order 1 . to see how pronounced this effect is , see fig .",
    "[ testdifbig ] .",
    "obviously , the magnitude depends on the values of the jump parameters used in the test as well as on the other parameters of the model and the default boundaries .",
    "also , the effect becomes more pronounced when the ratio of the mutual liabilities to the other liabilities increases .    to emphasize the role of jumps , the same test was conducted without jumps in a pure diffusion setting .",
    "the results are shown in fig .",
    "[ q2nojumps ] .",
    "clearly , the presence of jumps significantly changes the picture , while still preserving the effect of mutual liabilities .    in the second set of tests we setup a local volatility function for assets 1 and 2 , which is given in tables  [ locvol1 ] , [ locvol2 ]    .local volatility function for @xmath246 . [ cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^ \" , ]     the results of this test are given in fig .",
    "[ q2ddif2locvol ] .",
    "it can be seen that larger volatilities amplify the effect of mutual liabilities , as well as make a shape of @xmath207 highly asymmetric .",
    "we also consider a case of long maturity , @xmath247 years to investigate how the time horizon affects the shape of the joint survival probability @xmath248 in the presence of mutual liabilities .",
    "the corresponding results are shown in fig .",
    "[ q10 ] , fig .",
    "[ rel10 ] .",
    "it is clear that the effect of mutual liabilities significantly decreases when @xmath12 increases .",
    "that is because @xmath248 itself decreases in absolute value with larger @xmath12 , and therefore the absolute value of the effect also drops down .",
    "the following tests show the influence of correlations on the effects caused by mutual liabilities . in fig .",
    "[ rho0 ] the same results as in test 1 are presented when @xmath249 , while in fig .",
    "[ loading0 ] we assume that @xmath250 .    these figures show that both contributions of correlations are important .",
    "[ marg ] represents the marginal survival probability of the first bank as a function of the initial asset value of the second bank under the conditions of the first test in fig .",
    "[ test1 ] . and fig .",
    "[ margdif ] shows the difference in marginal survival probabilities with and without mutual interbank liabilities .",
    "as could be seen mutual interbank liabilities affect both the marginals and joint survival probabilities .",
    "the influence on marginals despite being smaller in magnitude , is still significant .",
    "it is more natural to consider at least three banks , @xmath251 using the same structural default model as above .",
    "also assume that all three banks have mutual liabilities to each other , as well as liabilities with respect to the outside economy .",
    "the advantage of our approach lies in the fact that just minor changes in the computational algorithm need to be done to include the third asset into the whole picture .    since now @xmath252",
    ", we need to replace the two - dimensional matrices with the three - dimensional ones .",
    "therefore , the expected complexity of the method becomes @xmath253 . as idiosyncratic jumps",
    "are still independent , our splitting algorithm remains the same , although we need to add two more steps in the direction @xmath254 to .",
    "hence , the 3d splitting algorithm reads @xmath255 in our test experiments at step 5 , without loss of generality , we again use the kou model for the systemic jumps . that requires solving the corresponding 3d linear equations of the first order similar to and .",
    "the solution could be constructed by using a 3d version of the adi scheme derived in a similar manner to the 2d case ( @xcite ) . for the sake of brevity ,",
    "we formulate two propositions and give just a sketch of the proof since it could be obtained in exactly the same way as in appendices .",
    "[ propkou3d_1 ] consider the following pide @xmath256 and solve it using the following adi scheme @xmath257 z^*({\\bf x},\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big ) + b_2 \\triangledown_{x_2 } + b_3 \\triangledown_{x_3 } \\big]z^k({\\bf x},\\tau ) + b\\\\ \\big[\\big(s & + \\dfrac{1}{2 } \\theta_1 \\big ) - b_2 \\triangledown_{x_2}\\big ] z^{**}({\\bf x},\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big ) + b_1\\triangledown_{x_1 } + b_3 \\triangledown_{x_3}\\big]z^*({\\bf x},\\tau ) + b \\nonumber \\\\ \\big[\\big(s & + \\dfrac{1}{2 } \\theta_1 \\big ) - b_3 \\triangledown_{x_3}\\big ] z^{k+1}({\\bf x},\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big ) + b_1 \\triangledown_{x_1 } + b_2 \\triangledown_{x_2}\\big]z^{**}({\\bf x},\\tau ) + b \\nonumber \\\\ b & \\equiv p \\theta_1 q(x_1,x_2,x_3,\\tau ) \\nonumber\\end{aligned}\\ ] ] then the discrete approximation of this adi scheme @xmath258 z^*({\\bf x},\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big)i_{x_2 } + b_2 a(x_2 ) + b_3 a(x_3 ) \\big]z^k({\\bf x},\\tau ) + b\\\\ \\big[\\big(s & + \\dfrac{1}{2 } \\theta_1 \\big)i_{x_2 } - b_2 a(x_2)\\big ] z^{**}({\\bf x},\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big)i_{x_1 } + b_1 a(x_1 ) + b_3 a(x_3)\\big]z^*({\\bf x},\\tau ) + b \\nonumber \\\\ \\big[\\big(s & + \\dfrac{1}{2 } \\theta_1 \\big)i_{x_3 } - b_3 a(x_3)\\big ] z^{k+1}({\\bf x},\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_1 \\big)i_{x_1 } + b_1 a(x_1 ) + b_2 a(x_2)\\big]z^{**}({\\bf x},\\tau ) + b \\nonumber \\\\ b & \\equiv p \\theta_1 q(x_1,x_2,x_3,\\tau ) , \\qquad a(x_i ) = \\begin{cases } a_2^f(x_i ) , & b_i > 0 \\\\ a_2^b(x_i ) , & b_i < 0 , \\qquad i=1,2 \\end{cases } \\nonumber\\end{aligned}\\ ] ] is unconditionally stable , approximates with @xmath259 and preserves positivity of the solution .",
    "the proof could be obtained following the lines of proof of proposition  [ propkou1 ] given in appendix  [ ap1 ] . in our situation",
    "we apply the same discretization three times ( to each row of the splitting scheme ) .",
    "the remaining part of the proof is exactly same as in appendix  [ ap1 ] .",
    "the second proposition is similar in nature .",
    "[ propkou3d_2 ] consider the following pide @xmath260 and solve it using the following adi scheme @xmath261 z^*(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big ) - b_2 \\triangledown_{x_2 } - b_3 \\triangledown_{x_3}\\big]z^k(x_1,x_2,\\tau ) + b \\\\",
    "\\big[\\big(s & + \\dfrac{1}{2 } \\theta_2 \\big ) + b_2 \\triangledown_{x_2}\\big ] z^{**}(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big ) - b_1 \\triangledown_{x_2 } - b_3 \\triangledown_{x_3}\\big]z^*(x_1,x_2,\\tau ) + b \\nonumber \\\\ \\big[\\big(s & + \\dfrac{1}{2 } \\theta_2 \\big ) + b_3 \\triangledown_{x_3}\\big ] z^{k+1}(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big ) - b_1 \\triangledown_{x_1 } - b_2 \\triangledown_{x_2}\\big]z^{**}(x_1,x_2,\\tau ) + b \\nonumber \\\\ b & \\equiv ( 1-p ) \\theta_2 q(x_1,x_2,x_3,\\tau ) \\nonumber\\end{aligned}\\ ] ]    then the discrete approximation of this adi scheme @xmath262 z^*(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big)i_{x_2 } - b_2 a(x_2 ) - b_3 a(x_3)\\big]z^k(x_1,x_2,\\tau ) + b \\\\",
    "\\big[\\big(s & + \\dfrac{1}{2 } \\theta_2 \\big)i_{x_2 } + b_2 a(x_2)\\big ] z^{**}(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big)i_{x_1 } - b_1 a(x_1 ) - b_3 a(x_3)\\big]z^*(x_1,x_2,\\tau ) + b \\nonumber \\\\ \\big[\\big(s & + \\dfrac{1}{2 } \\theta_2 \\big)i_{x_3 } + b_3 a(x_3)\\big ] z^{k+1}(x_1,x_2,\\tau ) = \\big[\\big(s - \\dfrac{1}{2 } \\theta_2 \\big)i_{x_1 } - b_1 a(x_1 ) - b_2 a(x_2)\\big]z^{**}(x_1,x_2,\\tau ) + b \\nonumber \\\\ b & \\equiv ( 1-p ) \\theta_2 q(x_1,x_2,x_3,\\tau ) , \\qquad a(x_i )   = \\begin{cases } a_2^b(x_i ) , & b_i > 0 \\\\ a_2^f(x_i ) , & b_i < 0 , \\qquad i=1,2 \\end{cases } \\nonumber\\end{aligned}\\ ] ] is unconditionally stable , approximates with @xmath259 and preserves positivity of the solution .",
    "the proof is analogous to that given in appendix  [ ap2 ] if one applies the same discretization three times ( to each row of the splitting scheme ) .",
    "the remaining part of the proof is exactly the same as in appendix  [ ap2 ] , which in turn is analogous to appendix  [ ap1 ] .",
    "the solution of the 3d convection - diffusion problem at the first and the last steps of the scheme is more challenging .",
    "so far the unconditional stability of some schemes ( craig - sneid , modified craig - sneid ( mcs ) , hundsdorfer - verwer ( hv ) , etc . ) was proven only when there is no drift term in the corresponding diffusion equation ( @xcite ) . therefore , this problem requires further attention .",
    "nevertheless , these schemes were successfully used in the 3d setup by @xcite where the mcs and hv schemes demonstrated good stability if the scheme parameter @xmath263 was chosen similar to @xcite .      in our tests we chose parameters of the model similar to the 2d case ,",
    "see tables [ tab3d1 ] , [ tab3d2 ]     @xmath264 & @xmath208 & @xmath209 & @xmath265 & @xmath214 & @xmath12 & @xmath266 & @xmath267 110 & 100 & 120 & 80 & 90 & 100 & 0.05 & 1 & 0.5 & 0.3 @xmath268 & @xmath210 & @xmath211 & @xmath269 & @xmath270 & @xmath271 & @xmath272 & @xmath212 & @xmath213 & @xmath273 @xmath274 & 20 & 15 & 15 & 20 & 10 & 15 & 0.4 & 0.35 & 0.5     @xmath234 & @xmath235 & @xmath275 & @xmath236 & @xmath237 & @xmath276 & @xmath238 & @xmath239 & @xmath240 & @xmath241 & @xmath242 & @xmath277 3 & 0.5 & 0.3 & 0.4 & 0.3 & 0.4 & 0.5 & 0.3445 & 3.0465 & 3.0775 & 0.2 & 0.3 & 0.25    we recall that a correlation matrix @xmath278 of @xmath127 assets can be represented as a gram matrix with matrix elements @xmath279 where @xmath280 are unit vectors on a @xmath281 dimensional hyper - sphere @xmath282 .",
    "using the 3d geometry , it is easy to establish the following cosine law for the correlations between three assets : @xmath283 with @xmath268 being an angle between @xmath284 and its projection on the plane spanned by @xmath285 .",
    "as discussed , e.g. , by @xcite , three variables @xmath286 are independent , but @xmath287 are not .",
    "based on the values given in tab .",
    "[ tab3d1 ] we find @xmath288 .",
    "we compute the test using a @xmath289 spatial grid for the convection - diffusion problem .",
    "also we use a constant time step @xmath290 , so that the total number of time steps for the given maturity is 40 .",
    "the jump non - uniform grid in each direction is a superset of the convection - diffusion grid up to @xmath291 built using a geometric progression .",
    "so the jumps are computed on the grid with @xmath292 nodes .",
    "also we chose @xmath293 $ ] which provided convergence of the adi scheme for the common jumps after 4 iterations .",
    "we again compare the survival probability in the presence of mutual liabilities , @xmath294 , @xmath295 , with that in the absence of mutual liabilities , @xmath296 . to obtain the latter , we first reduce @xmath297 by the amounts @xmath298 , \\",
    "j \\in [ 1,3 ] , i \\ne j$ ] , and then put @xmath299 .",
    "the difference @xmath300 is presented in fig .  [ fig3dxy ] - [ fig3dyz ] .",
    "since the whole picture in this case is four - dimensional , we represent it as a series of 3d projections , namely : fig .",
    "[ fig3dxy ] represents the @xmath301 plane at various values of the @xmath302 coordinate which are indicated in the corresponding labels ; fig .",
    "[ fig3dxz ] does same in the @xmath303 plane , and fig .",
    "[ fig3dyz ] - in the @xmath304 plane .",
    "90   with and without mutual liabilities , @xmath301 plane.,title=\"fig:\",width=9 ]    90   with and without mutual liabilities , @xmath303 plane.,title=\"fig:\",width=9 ]    90   with and without mutual liabilities , @xmath304 plane.,title=\"fig:\",width=9 ]    two observations could be made based on the results obtained in these tests .",
    "first , when three banks have mutual liabilities , their effect on the joint survival probability is more profound than in the 2d case .",
    "second , @xmath225 has an irregular shape as a function of 3 coordinates .",
    "for instance , in the @xmath304 plane it has two local maxima ( in the absolute value ) while in the 2d case it does nt demonstrate such a behavior .",
    "also this effect disappears in the absence of jumps .",
    "this is similar to the effect observed in @xcite where asymmetric positive and negative jumps in the stochastic skew model were described by the cgmy model with different @xmath195 , which produced a qualitatively new effect .",
    "it is evident through the appearance of a big dome close to the atm at the moderate values of the instantaneous variance @xmath305 in addition to a standard arc of the double barrier options which is also close to the atm , but at small values of @xmath305 .",
    "as expected , the whole picture is rather complicated .",
    "moreover , as it is affected by the number of model parameters , which could be difficult to extract from a set of liquid market data , it could be very challenging to calibrate such a model .",
    "a standard recipe is to first calibrate marginals of the distribution to the corresponding market data , and then use some other data for calibration of the remaining parameters .",
    "in this paper we presented three main innovations which seem to be rather general , namely :    1 .",
    "we introduced mutual banks liabilities into the structural default model .",
    "we discussed how these liabilities affect joint and marginal survival probabilities , and provided some numerical test results .",
    "these results demonstrate that the effect of mutual liabilities could be quite significant .",
    "of course , the magnitude of the effect depends on how close the initial asset values are to the default barrier , and parameters which describe the assets dynamics , such as volatility , etc .",
    "these parameters , in principle , could be found by calibrating marginal survival probabilities to market cds spreads .",
    "2 .   to make the above analysis tractable",
    "we developed a solution scheme for the model considering a set of banks with mutual interbank liabilities whose assets are driven by correlated lvy processes . for every asset , the jumps are represented as a weighted sum of the common and idiosyncratic parts .",
    "both parts could be simulated by an arbitrary lvy model which is an extension of the previous approaches where either the discrete or exponential jumps were considered , or a lvy copula approach was utilized .",
    "we provided a novel efficient ( linear complexity in each dimension ) numerical ( splitting ) algorithm for solving the corresponding 2d and 3d jump - diffusion equations , and proved its convergence and second order of accuracy in both space and time .",
    "the joint survival probability of three firms @xmath306 was computed using the above framework . to the best of our knowledge",
    "there were no the similar results reported in literature .",
    "we found that in some cases , the difference between the joint survival probabilities with and without mutual liabilities has a bimodal profile in some projections , and this effect disappears in the pure diffusion setup .",
    "this is similar to what was observed in @xcite where interaction of jumps also produced a bimodal distribution for double barrier option prices .    despite the fact that the present approach is efficient and attractive in low dimensions ,",
    "it is not clear how best to extend it to the case when the number of firms is more than three , unless some simplifications are introduced into the model .",
    "this is a standard limitation of the fd approach which experiences the curse of dimensionality . a possible way to overcome",
    "this could be to combine the analytical and numerical methods , similar to how this was done in , e.g. , @xcite .",
    "we thank peter carr , darrel duffie , peter forsyth , igor halperin and rajeev virmani for useful comments .",
    "we assume full responsibility for any remaining errors .",
    "ballotta , l. and bonfiglioli , e. ( 2014 ) .",
    "multivariate asset models using lvy processes and applications .",
    "ssrn : 1695527 .",
    "baxter , m. ( 2007 ) .",
    "simple structural models . , 10:607631 .",
    "bielecki , t. , crpey , s. , and herbertsson , a. ( 2011 ) .",
    "markov chain models of portfolio credit risk . in rennie , a. l. .",
    "a. , editor , _ the oxford handbook of credit risk _ , pages 327382 .",
    "oxford university press .",
    "black , f. and cox , j. ( 1976 ) . valuing corporate securities : some effects of bond indenture provisions .",
    ", 31(2):351367 .",
    "clift , s. and forsyth , p. ( 2008 ) .",
    "numerical solution of two asset jump difusion models for option valuation .",
    ", 58:743782 .",
    "cont , r. and tankov , p. ( 2004 ) . .",
    "financial matematics series , chapman & hall /crcl .",
    "dash , j. ( 2004 ) . .",
    "world scientific .",
    "de  lange , o.  l. and raab , r.  e. ( 1992 ) . .",
    "oxford science publications . chapter 3 .",
    "deelstra , g. and petkovic , a. ( 2009 - 2010 ) .",
    "how they can jump together : multivariate lvy processes and option pricing .",
    ", 9(1):2942 .",
    ", y. , forsyth , p.  a. , and vetzal , k.  r. ( 2005 ) .",
    "robust numerical methods for contingent claims under jump diffusion processes . , 25:87112 .",
    "eberlein , e. ( 2009 ) .",
    "jump - type lvy processes . in andersen , t.  g. , davis , r.  a. , krei , j .-",
    "p . , and mikosch , t. , editors , _ handbook of financial time series _ , pages 439455 .",
    "springer verlag .",
    "eberlein , e. and keller , u. ( 1995 ) .",
    "hyperbolic distributions in finance . , 1:281299 .",
    "eisenberg , l. and noe , t. ( 2001 ) .",
    "systemic risk in financial systems .",
    ", 47(2):236249 .",
    "elhashash , a. and szyld , d. ( 2008 ) .",
    "generalizations of m - matrices which may not have a nonnegative inverse .",
    ", 429:24352450 .",
    "elsinger , h. , lehar , a. , and summer , m. ( 2006 ) . using market information for banking system risk assessment .",
    ", 2(1):137166 .",
    "garcia , j. , goossens , s. , masol , v. , and schoutens , v. ( 2009 ) .",
    "based correlation .",
    ", 1(2):95100 .",
    "gauthier , g. , lehar , a. , and souissi , m. ( 2010 ) .",
    "macroprudential regulation and systemic capital requirements .",
    "technical report 2010 - 4 , bank of canada .",
    "guillaume , f. ( 2013 ) . the @xmath195vg model for multivariate asset pricing : calibration and extension .",
    ", 16(1):2552 .",
    "haentjens , t. and int hout , k.  j. ( 2012 ) . alternating direction implicit finite difference schemes for the heston ",
    "hull  white partial differential equation .",
    ", 16:83110 .",
    "hilber , n. , reichmann , o. , winter , c. , and schwab , c. ( 2013 ) . .",
    "springer .",
    "howison , s. ( 1995 ) .",
    "barrier options .",
    "available at https://people.maths.ox.ac.uk/howison/barriers.pdf",
    ".    , k.  j. and foulon , s. ( 2010 ) .",
    "finite difference schemes for option pricing in the heston model with correlation . , 7(2):303320 .    , k.  j. and mishra , c. ( 2013 ) .",
    "stability of adi schemes for multidimensional diffusion equations with mixed derivative terms .",
    ", 74:8394 .",
    ", k.  j. and welfert , b.  d. ( 2007 ) .",
    "stability of adi schemes applied to convection - diffusion equations with mixed derivative terms .",
    ", 57:1935 .",
    "itkin , a. ( 2014a ) .",
    "efficient solution of backward jump - diffusion pides with splitting and matrix exponentials .",
    ", forthcoming .",
    "electronic version is available at http://arxiv.org/abs/1304.3159 .",
    "itkin , a. ( 2014b ) . .",
    "available at http://arxiv.org/abs/1403.1804 .",
    "itkin , a. ( 2014c ) .",
    "splitting and matrix exponential approach for jump - diffusion models with inverse normal gaussian , hyperbolic and meixner jumps .",
    ", forthcoming .",
    "available at http://arxiv.org/abs/1405.6111 .",
    "itkin , a. and carr , p. ( 2011 ) . jumps without tears : a new splitting technology for barrier options .",
    ", 8(4):667704 .",
    "itkin , a. and carr , p. ( 2012 ) .",
    "using pseudo - parabolic and fractional equations for option pricing in jump diffusion models .",
    ", 40(1):63104 .",
    "kou , s. and wang , h. ( 2004 ) .",
    "option pricing under a double exponential jump diffusion model .",
    ", 50(9):11781192 .",
    "kuznetsov , a. , kyprianou , a.  e. , and pardo , j.  c. ( 2011 ) .",
    "meromorphic lvy processes and their fluctuation identities .",
    "available at http://arxiv.org/pdf/1004.4671.pdf .",
    "lewis , a.  l. ( 2000 ) . .",
    "finance press , newport beach , california , usa .",
    "lipton , a. ( 2002a ) .",
    "assets with jumps . , pages 149153 .",
    "lipton , a. ( 2002b ) .",
    "the vol smile problem . ,",
    "pages 6165 .",
    "lipton , a. and savescu , i. ( 2014 ) .",
    "pricing credit default swaps with bilateral value adjustments . , 14(1):171188 .",
    "lipton , a. and sepp , a. ( 2009 ) .",
    "credit value adjustment for credit default swaps via the structural default model .",
    ", 5(2):123146 .",
    "lipton , a. and sepp , a. ( 2011 ) .",
    "credit value adjustment in the extended structural default model . in _ the oxford handbook of credit derivatives _ , pages 406463 .",
    "oxford university .",
    "luciano , e. and semeraro , p. ( 2010 ) .",
    "multivariate time changes for lvy asset models : characterization and calibration . , 233:19371953 .",
    "mai , j. , scherer , m. , and schulz , t. ( 2014 ) .",
    "sequential modeling of dependent jump processes .",
    ", 70:5463 .",
    "marshall , a. and olkin , i. ( 1967 ) . a multivariate exponential distribution .",
    ", 2:8498 .",
    "mcdonough , j.  m. ( 2008 ) . .",
    "university of kentucky .",
    "available at http://www.engr.uky.edu/~acfd/me690-lctr-nts.pdf .",
    "merton , r. ( 1974 ) . on the pricing of corporate debt : the risk structure of interest rates .",
    ", 29:449470 .",
    "moosbrucker , t. ( 2006 ) .",
    "copulas from infinitely divisible distributions : applications to credit value at risk . technical report , department of banking - university of cologne .",
    "available at http://gloria-mundi.com/library_journal_view.asp?journal_id=7547 .",
    "roach , p. ( 1976 ) . .",
    "hermosa publishers .",
    "schoutens , w. ( 2001 ) .",
    "meixner processes in finance .",
    "technical report , k.u.leuveneurandom .",
    "strang , g. ( 1968 ) . on the construction and comparison of difference schemes .",
    ", 5:509517 .",
    "sun , y. , mendoza - arriaga , r. , and linetsky , v. ( 2011 ) .",
    "valuation of collateralized debt obligations in a multivariate subordinator model . in jain ,",
    "s. , creasey , r.  r. , himmelspach , j. , white , k.  p. , and fu , m. , editors , _ proceedings of the 2011 winter simulation conference ( wsc ) _ , pages 37423754 .",
    "ieee , phoenix , az .",
    "vasicek , o. ( 1987 ) .",
    "limiting loan loss probability distribution .",
    "technical report , kmv co.    vasicek , o. ( 2002 ) .",
    "loan portfolio value .",
    ", 15(12):160162 .",
    "von petersdorff , t. and schwab , c. ( 2004 ) . numerical solution of parabolic equations in high dimensions .",
    ", 38(1):93127 .",
    "webber , l. and willison , m. ( 2011 ) . systemic capital requirements .",
    "technical report 436 , bank of england .",
    "available at http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1945654 .",
    "winter , c. ( 2009 ) . .",
    "phd thesis , eidgenssische technische hochschule eth zrich .",
    "yang , c. , duraiswami , r. , gumerov , n.  a. , and davis , l. ( 2003 ) .",
    "improved fast gauss transform and efficient kernel density estimation . , pages 464471 .",
    "yu , f. ( 2007 ) . correlated defaults in intensity  based models . , 17:155173 .",
    "zhou , c. ( 2001 ) .",
    "the term structure of credit spreads with jump risk .",
    ", 25:20152040 .",
    "following @xcite , we introduce definition of an em - matrix    an @xmath307 matrix @xmath308 $ ] is called an em - matrix if it can be represented as @xmath309 with @xmath310 , @xmath172 is some constant , @xmath311 is the spectral radius of @xmath312 , and @xmath312 is an eventually nonnegative matrix .",
    "now suppose @xmath313 .",
    "then the matrix @xmath314\\ ] ] in the first row of is an em - matrix , see lemma a.2 in @xcite .",
    "therefore , the inverse of @xmath315 is a non - negative matrix , see lemma a.3 in @xcite .",
    "the matrix @xmath316\\ ] ] is an eventually non - negative matrix the matrix @xmath317 is a lower triangular matrix with three non - zero diagonals .",
    "the main and the first lower diagonals are positive and the second lower diagonal is negative .",
    "however , the former two dominate the latter one . ]",
    "if @xmath318 is chosen to provide @xmath319 therefore , the solution of the first row of is @xmath320 $ ] which by construction is a non - negative vector .",
    "also eigenvalues of @xmath321 are @xmath322\\ ] ] therefore , this scheme converges unconditionally provided is satisfied .",
    "also , by construction the matrix @xmath323 approximates the operator @xmath324 to the second order , i.e. , with @xmath325 .",
    "therefore , the whole scheme provides the second order approximation .",
    "the second row of could be analyzed in the same way .    in all other cases",
    "@xmath326 , @xmath327 and @xmath328 the proof could be done by analogy .",
    "the proof is completely analogous to that in appendix  [ ap1 ] .",
    "in the 1d case we still want to use the splitting algorithm of . to proceed ,",
    "let us define an explicit model for jumps , so the pseudo - differential operator @xmath70 defined in could be computed explicitly .",
    "let us consider only negative exponentially distributed jumps and the term @xmath329 changes to @xmath330 where @xmath331 .",
    "] , see @xcite , i.e. @xmath332 where @xmath333 is the parameter of the exponential distribution . with the lvy measure @xmath334 given in and the intensity of jumps @xmath335 we can substitute @xmath334 into and integrate .",
    "the result reads @xmath336 below for simplicity of notation we introduce @xmath337 .",
    "since @xmath338 , the above expression could be re - written as @xmath339    [ propexp ] consider the following discrete approximation of : @xmath340 then this scheme is a ) unconditionally stable ; b ) approximates the operator @xmath70 in on a certain non - uniform grid in variable @xmath341 with @xmath342 , where @xmath343 are the steps of the grid ; c ) and preserves positivity of the solution .",
    "as shown in @xcite the matrix @xmath344 is an em matrix .",
    "therefore , the matrix @xmath329 is also an em - matrix . therefore , its inverse is a non - negative matrix .",
    "the matrix @xmath345 by construction is the metzler matrix .",
    "a product of the non - negative and metzler matrices is the negative of an em - matrix to guarantee this .",
    "usually , introduction of ghost points at the boundaries helps to increase the accuracy of the method .",
    "alternatively , one could use another approximation of the term @xmath346 in which is @xmath347 .",
    "this reduces the order of approximation from the exact second order to some order in between 1 and 2 , but , at the same time , significantly improves the properties of the resulting matrix @xmath348 . ] . as @xmath333 ,",
    "the matrix @xmath348 is also the negative of an em - matrix",
    ". then unconditional stability and positivity of the solution follows from the main theorem in @xcite . as the matrix @xmath349 is the second order approximation in @xmath176 to @xmath160 , and @xmath350",
    "is the second order approximation in @xmath176 to @xmath179 , the whole scheme approximates the operator @xmath70 with the second order in @xmath176 .    in practical applications the complexity of this scheme could be linear in the number of grid nodes @xmath127 . indeed , suppose we wish to compute @xmath207 with the second order of approximation in the time step @xmath351 , i.e. with the accuracy @xmath352 .",
    "represent @xmath353 in the second step of the splitting algorithm using a pad rational approximation @xmath354 : @xmath355 with allowance for after some algebra this could be re - written in the form @xmath356 q(a , t+\\delta t ) = \\left[\\phi i - a a^f_2 + \\dfrac{\\lambda}{2(\\phi-1 ) } \\delta t a^2 a^c_2\\right ] q(a , t).\\ ] ] matrices in square brackets are banded ( three or five diagonal ) , therefore this system of linear equations could be solved with the complexity @xmath357 ."
  ],
  "abstract_text": [
    "<S> the structural default model of @xcite is generalized for a set of banks with mutual interbank liabilities whose assets are driven by correlated lvy processes with idiosyncratic and common components . the multi - dimensional problem is made tractable via a novel computational method , which generalizes the one - dimensional fractional partial differential equation method of @xcite to the two- and three - dimensional cases . </S>",
    "<S> this method is unconditionally stable and of the second order of approximation in space and time ; in addition , for many popular lvy models it has linear complexity in each dimension . </S>",
    "<S> marginal and joint survival probabilities for two and three banks with mutual liabilities are computed . </S>",
    "<S> the effects of mutual liabilities are discussed , and numerical examples are given to illustrate these effects . </S>"
  ]
}