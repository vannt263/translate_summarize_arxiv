{
  "article_text": [
    "imputation is often used to handle missing data . for inference , if imputed values are treated as if they were observed , variance estimates will generally be underestimates ( @xcite ) . to account for the uncertainty due to imputation , @xcite proposed multiple imputation which creates multiply completed datasets to allow assessment of imputation variability .",
    "multiple imputation is motivated in a bayesian framework ; however , its frequentist validity is controversial .",
    "@xcite claimed that multiple imputation can provide valid frequentist inference in various applications ( for example , @xcite ) . on the other hand , as discussed by @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite , and @xcite , the multiple imputation variance estimator is not always consistent .    for multiple imputation inference to be valid ,",
    "imputations must be proper @xcite . a sufficient condition is given by @xcite , the so - called congeniality condition , imposed on both the imputation model and the form of subsequent complete - sample analyses , which is quite restrictive for general purpose estimation .",
    "rubin s variance estimator is otherwise inconsistent .",
    "@xcite pointed out that multiple imputation that is congenial for mean estimation is not necessarily congenial for proportion estimation .",
    "therefore , some common statistical procedures , such as the method of moments estimators , can be incompatible with the multiple imputation framework .    in this paper",
    ", we characterize the asymptotic bias of rubin s variance estimator when the method of moments estimator is used in the complete - sample analysis .",
    "we also discuss an alternative variance estimator that can provide asymptotically valid inference for method of moments estimation .",
    "the new variance estimator is compared with rubin s variance estimator through two limited simulation studies in @xmath0 .",
    "suppose that the sample consists of @xmath1 observations @xmath2 , which is an independent realization of a random vector @xmath3 .",
    "for simplicity of presentation , assume that @xmath4 is a scalar outcome variable and @xmath5 is a @xmath6-dimensional covariate .",
    "suppose that @xmath7 is fully observed and @xmath8 is not fully observed for all units in the sample .",
    "without loss of generality , assume the first @xmath9 units of @xmath8 are observed and the remaining @xmath10 units of @xmath8 are missing .",
    "let @xmath11 be the response indicator of @xmath8 , that is , @xmath12 if @xmath8 is observed and @xmath13 otherwise . denote @xmath14 and @xmath15 .",
    "we further assume that the missing mechanism is missing at random in the sense of @xcite .",
    "the parameter of interest is @xmath16 , where @xmath17 is a known function .",
    "for example , if @xmath18 , then @xmath19 is the population mean of @xmath4 , and if @xmath20 , then @xmath21 is the population proportion of @xmath4 less than @xmath22 .",
    "assume that the conditional density @xmath23 belongs to a parametric class of models indexed by @xmath24 such that @xmath25 for some @xmath26 and the marginal distribution of @xmath27 is completely unspecified . to generate imputed values for missing outcomes from @xmath28",
    ", we need to estimate the unknown parameter @xmath24 , either by likelihood - based methods or by bayesian methods .",
    "the multiple imputation procedure employs a bayesian approach to deal with the unknown parameter @xmath24 , which unfolds in three steps :    _ step 1 .",
    "_ ( imputation ) create @xmath29 complete datasets by filling in missing values with imputed values generated from the posterior predictive distribution . specifically , to create the @xmath30th imputed dataset ,",
    "first generate @xmath31 from the posterior distribution @xmath32 , and then generate @xmath33 from the imputation model @xmath34 for each missing @xmath8 .",
    "_ step 2 . _",
    "( analysis ) apply the user s complete - sample estimation procedure to each imputed dataset .",
    "let @xmath35 be the complete - sample estimator of @xmath16 applied to the @xmath30th imputed dataset and @xmath36 be the complete - sample variance estimator of @xmath35 .",
    "_ step 3 . _",
    "( summarize ) use rubin s combining rule to summarize the results from the multiply imputed datasets .",
    "the multiple imputation estimator of @xmath37 is @xmath38 , and rubin s variance estimator is @xmath39 where @xmath40 and @xmath41 .",
    "if the method of moments estimator of @xmath16 is used in step 2 , the multiple imputation estimator of @xmath37 becomes @xmath42 where @xmath43 . to derive the frequentist property of @xmath44",
    ", we rely on the bernstein - von mises theorem ( @xcite ; chapter 10 ) , which claims that under regularity conditions and conditional on the observed data , the posterior distribution @xmath32 converges to a normal distribution with mean @xmath45 and variance @xmath46 , where @xmath45 is the maximum likelihood estimator of @xmath24 from the observed data and @xmath46 is the inverse of the observed fisher information matrix with @xmath47 . as a result ,",
    "assume that @xmath48 is sufficiently smooth in @xmath24 , conditional on the observed data , we have @xmath49\\cong e\\{g(y)\\mid x_{i};\\hat{\\theta}\\ } , $ ] where @xmath50 means @xmath51 .",
    "therefore , for @xmath52 , @xmath44 converges to @xmath53 , where @xmath54 .",
    "the variance estimation of @xmath55 needs to appropriately account for the uncertainty associated with the estimate of @xmath24 , which is usually done using linearization methods if the imputation models are known ( @xcite ; @xcite ) . in the multiple imputation procedure , this is characterized in the variability between the multiply imputed datasets without referring to the imputation models .",
    "however , rubin s variance estimator ( [ eq : rubin s var ] ) requires restrictive conditions for valid inference , which we discuss in the next section .",
    "rubin s variance estimator is based on the following decomposition , @xmath56 where @xmath57 is the complete - sample estimator of @xmath37 .",
    "basically , in rubin s variance estimator ( [ eq : rubin s var ] ) , @xmath58 estimates the first term of ( [ eq : rubin s decomp ] ) and @xmath59 estimates the second term of ( [ eq : rubin s decomp ] ) . in particular , @xcite proved that @xmath60 for a fairly general class of estimators .",
    "thus , if the complete - sample variance estimator satisfies the condition @xmath61 for @xmath62 , the bias of rubin s variance estimator is @xmath63    rubin s variance estimator is asymptotically unbiased if @xmath64 , which is called the congeniality condition by @xcite .",
    "however , the congeniality condition does not hold for some common estimators such as the method of moments estimators .",
    "theorem 1 gives this asymptotic bias of rubin s variance estimator for @xmath52 , with the proof outlined in the online supplementary material .",
    "let @xmath65 be the method of moments estimator of @xmath16 under complete response .",
    "assume that @xmath61 holds for @xmath62 .",
    "then for @xmath52 , the bias of rubin s variance estimator is @xmath66-\\dot{m}_{\\theta,0}^{t}\\mathcal{i}_{\\theta}^{-1}\\dot{m}_{\\theta,1}\\right),\\label{eq : bias}\\end{aligned}\\ ] ] where @xmath67 , @xmath68 , @xmath69 , @xmath70 , @xmath71 , and @xmath72 .    under missing completely at random",
    ", the bias in ( [ eq : bias ] ) simplifies to @xmath73 where @xmath74 and @xmath75 , because @xmath76+r^{-1}e[\\mathrm{var}\\{g(y)\\mid x\\ } ] , \\end{aligned}\\ ] ] and @xmath77+r^{-1}\\dot{m}_{\\theta}^{t}\\mathcal{i}_{\\theta}^{-1}\\dot{m}_{\\theta } , \\end{aligned}\\ ] ] where @xmath78 .",
    "result ( [ eq : simo ] ) explicitly shows that rubin s variance estimator is unbiased if and only if the method of moments estimator is as efficient as the maximum likelihood estimator , that is , @xmath79 .",
    "otherwise , rubin s variance estimator is positively biased .    under missing at random , the bias of rubin s",
    "variance estimator can be zero , positive or negative .",
    "consider a simple linear regression model @xmath80 , where @xmath81 .",
    "for @xmath82 , if @xmath5 contains @xmath22 , then the method of moments estimator @xmath83 is identical to the maximum likelihood estimator @xmath84 with @xmath85 being the maximum likelihood estimator of @xmath86 under complete response . by theorem 1 ,",
    "let @xmath87 and @xmath88 , the bias of rubin s variance estimator in ( [ eq : bias ] ) is @xmath89 by direct calculation considering that @xmath5 contains @xmath22 .",
    "this is consistent with the theory in @xcite and @xcite .",
    "now consider a simple linear regression model which contains one covariate @xmath5 and no intercept , then the method of moments estimator is strictly less efficient than the maximum likelihood estimator @xcite .",
    "the bias of rubin s variance estimator is @xmath90 which can be zero , positive or negative depending on the information of @xmath5 in the respondent and non - respondent groups .",
    "see the first simulation study in @xmath0 .",
    "in this section , we consider an alternative variance estimation method that leads to an unbiased variance estimator for multiple imputation regardless of whether the method of moments estimator or the maximum likelihood estimator is used as the complete - sample estimator in the multiple imputation procedure .",
    "we first decompose the multiple imputation estimator as , @xmath91 .",
    "the two terms are uncorrelated using the law of total covariance and the fact that @xmath55 is the conditional expectation of @xmath44 , conditional on the observed data .",
    "therefore , we have @xmath92 note that @xmath93 can be estimated by @xmath94 ( @xcite ; lemma 2 ) .",
    "we now focus on estimating @xmath95 in ( [ 4 - 1 ] ) . for simplicity of presentation ,",
    "all details of derivation are to be found in supplementary material .",
    "we show that the variance of @xmath55 is a sum of two terms , @xmath96 where @xmath97 $ ] , and @xmath98 the first term , @xmath99 , is the variance of the sample mean of @xmath100 . to estimate this term ,",
    "consider @xmath40 as in ( [ eq : rubin s var ] ) , and @xmath101 we have @xmath102 and @xmath103 $ ] .",
    "therefore , the first term @xmath99 can be estimated by @xmath104 . by the strong law of large numbers , @xmath105 as @xmath106 .",
    "the second term , @xmath107 , reflects the variability associated n the imputed values . to estimate this term",
    ", we use over - imputation in the sense that the imputation is carried out not only for the units with missing outcomes , but also for the units with observed outcomes .",
    "over - imputation has been used in model diagnostics for multiple imputation @xcite .",
    "let @xmath108 for @xmath109 and @xmath110 .",
    "define @xmath111 and @xmath112 the key insight is based on the following observations : @xmath113 and @xmath114 ; therefore , the second term of ( [ eq : tvar ] ) can be estimated by @xmath115 . combining the estimators of the two terms in ( [ eq : tvar ] )",
    ", we have the new multiple imputation variance estimator , given in the following theorem .    under the assumptions of theorem 1 ,",
    "the new multiple imputation variance estimator is @xmath116 where @xmath104 , with @xmath117 defined in ( [ cm ] ) and @xmath118 being the usual between - imputation variance in ( [ eq : rubin s var ] ) .",
    "@xmath119 is asymptotically unbiased for estimating the variance of the multiple imputation estimator in ( [ 1b ] ) as @xmath106 .    to account for the uncertainty in the variance estimator with a small to moderate imputation size ,",
    "a @xmath120 interval estimate for @xmath37 is @xmath121 , where @xmath122 is an approximate number of degrees of freedom based on satterthwaite s method ( 1946 ) given in supplementary material . from simulation studies ,",
    "we find that using @xmath123 gives similar satisfactory results as using the formula we provided . as a practical matter , @xmath123 is preferred .",
    "the proposed variance estimator in ( [ eq : new2 ] ) is also asymptotically unbiased when @xmath57 is the maximum likelihood estimator of @xmath16 ( see supplementary material for proof ) .",
    "therefore , the proposed variance estimator is applicable regardless of whether the maximum likelihood estimator or the method of moments estimator is used for the complete - sample estimator .",
    "the price we pay for the better performance of our variance estimator is an increase in computational complexity and data storage space , which requires @xmath124 datasets , with @xmath29 of them including the over - imputations and the last one containing the original observed data .",
    "however , when one s concern is with valid inference of multiple imputation , as in this paper , our proposed variance estimator based on over - imputation is preferred over that of rubins .",
    "in addition , given over - imputations , the subsequent inference does not require the knowledge of the imputation models .",
    "this is important because data analysts typically do not have access to all the information that the imputers used for imputation .",
    "our study would promote the use of over - imputation at the time of imputation , which not only allows the imputers to assess the adequacy of the imputation models , but also enables the analysts to carry out valid inference without knowledge of the imputation models .",
    "to test our theory , we conduct two limited simulation studies . in the first simulation ,",
    "@xmath125 monte carlo samples of size @xmath126 are independently generated from @xmath127 where @xmath128 , @xmath129 and @xmath130 with @xmath131 . in the sample , we assume that @xmath132 is fully observed , but @xmath133 is not .",
    "let @xmath11 be the response indicator of @xmath8 and @xmath134 , where @xmath135 .",
    "we consider two scenarios : ( i ) @xmath136 and ( ii ) @xmath137 , with the average response rate about @xmath138 .",
    "the parameters of interest are @xmath139 and @xmath140 . for multiple imputation , @xmath141 imputed values are independently generated from the linear regression model using the bayesian regression imputation procedure discussed in @xcite , where @xmath86 and @xmath142 are treated as independent with prior density proportional to @xmath143 . in each imputed dataset , we adopt the following complete - sample point estimators and variance estimators : @xmath144 , @xmath145 , @xmath146 , and @xmath147 . the relative bias of the variance estimator is calculated as @xmath148 .",
    "the @xmath120 confidence intervals are calculated as @xmath149 , where @xmath150 is the @xmath151 quantile of the @xmath152 distribution with @xmath153 degrees of freedom . for rubin",
    "s method , @xmath154 with @xmath155 , @xmath156 , @xmath157 , and @xmath158 @xcite .",
    "the coverage is calculated as the percentage of monte carlo samples where the estimate falls within the confidence interval .    from table 1 , for @xmath139 , under scenario ( i ) , the relative bias of rubin s variance estimator is @xmath159 , which is consistent with our result in ( [ eq:1 ] ) with @xmath160 , where @xmath161 , @xmath162 , and @xmath163 . under scenario ( ii ) , the relative bias of rubin s variance estimator is @xmath164 , which is consistent with our result in ( [ eq:1 ] ) with @xmath165 , where @xmath166 , @xmath167 , and @xmath168 . the empirical coverage for rubin s method can be over or below the nominal coverage due to variance overestimation or underestimation . on the other hand , the new variance estimator is essentially unbiased for these scenarios .",
    "in the second simulation , @xmath125 monte carlo samples of size @xmath169 are independently generated from @xmath170 where @xmath171 , @xmath172 and @xmath173 with @xmath174 .",
    "the parameters of interest are @xmath139 and @xmath175 .",
    "we consider two different factors for simulation .",
    "one is the response mechanism : missing completely at random and missing at random . for missing completely at random , @xmath176 . for missing at random , @xmath134 , where @xmath135 and @xmath177 with the average response rate about @xmath138",
    "the other factor is the size of multiple imputation , with two levels @xmath178 and @xmath179 .    from table 2 ,",
    "regarding the relative bias , rubin s variance estimator is unbiased for @xmath139 , with absolute relative bias of less than @xmath180 , and our new variance estimator is comparable with rubin s variance estimator with absolute relative bias of less than @xmath181 .",
    "rubin s variance estimator is biased upward for @xmath175 , with absolute relative bias as high as @xmath182 ; whereas our new variance estimator reduces absolute relative bias to less than @xmath183 .",
    "regarding confidence interval estimates , for @xmath139 , the confidence interval calculated from our new method is slightly wider than that from rubin s method , because our new method uses a smaller number of degrees of freedom in the @xmath152 distribution .",
    "however , for @xmath175 , the confidence interval calculated from our new method is narrower than that from rubin s method even with a smaller number of degrees of freedom in the @xmath152 distribution , due to the overestimation in rubin s method .",
    "rubin s method provides good empirical coverage for @xmath139 in the sense that the empirical coverage is close to the nominal coverage ; however , the empirical coverage for @xmath175 reaches to @xmath184 for @xmath185 confidence intervals , and @xmath186 for @xmath184 confidence intervals , due to variance overestimation .",
    "in contrast , our new method provides more accurate coverage of confidence interval for both @xmath139 and @xmath175 at @xmath185 and @xmath184 levels .",
    "c.i . , confidence interval ; @xmath139 ; @xmath140 ; rubin / new , rubins / new variance estimator .",
    "c.i . , confidence interval ; @xmath139 ; @xmath175 ; rubin / new , rubins / new variance estimator .",
    "our method can be extended to a more general class of parameters obtained from estimating equations .",
    "let @xmath37 be defined as a solution to the estimating equation @xmath187 .",
    "examples of @xmath37 include mean of @xmath188 , proportion of @xmath188 less than @xmath189 , @xmath6th quantile , regression coefficients , and domain means .",
    "a similar approach can be used to characterize the bias of rubin s variance estimator and to develop a bias - corrected variance estimator .",
    "we are grateful to xianchao xie and xiaoli meng for many helpful conversations and to the _ biometrika _ editors and four referees for their valuable comments that helped to improve this paper .",
    "the research of the second author was partially supported by a grant from us national science foundation and also by a cooperative agreement between the u.s .",
    "department of agriculture natural resources conservation service and iowa state university .",
    "the supplementary material available at _ biometrika _ online includes the proof of theorem 1 , the proof of theorem 2 , verification of the new variance estimator being unbiased when @xmath57 is the maximum likelihood estimator of @xmath16 , and an approximate number of degrees of freedom ."
  ],
  "abstract_text": [
    "<S> multiple imputation is a popular imputation method for general purpose estimation . @xcite </S>",
    "<S> provided an easily applicable formula for the variance estimation of multiple imputation . </S>",
    "<S> however , the validity of the multiple imputation inference requires the congeniality condition of @xcite , which is not necessarily satisfied for method of moments estimation . </S>",
    "<S> this paper presents the asymptotic bias of rubin s variance estimator when the method of moments estimator is used as a complete - sample estimator in the multiple imputation procedure . </S>",
    "<S> a new variance estimator based on over - imputation is proposed to provide asymptotically valid inference for method of moments estimation .    </S>",
    "<S> bayesian method ; congeniality ; missing at random ; proper imputation ; survey sampling . </S>"
  ]
}