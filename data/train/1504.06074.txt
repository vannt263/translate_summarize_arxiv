{
  "article_text": [
    "recent advancements in biomedical imaging technologies have provided abundant information and extensive resources for researchers to learn the human brain and neurological diseases .",
    "a variety of imaging modalities , such as magnetic resonance imaging ( mri ) , diffusion tensor imaging ( dti ) , functional magnetic resonance imaging ( fmri ) and positron emission tomography ( pet ) have been developed to measure brain structures and functions from different perspectives , generating various large - scale spatially distributed measurements over a three dimensional ( 3d ) space of the human brain .",
    "we refer to those massive spatial measurements of brain as neuroimages .",
    "this poses great opportunities and new challenges for neuroscientists and statisticians to develop efficient analytical methods that extract useful features from neuroimages to characterize the association between the brain activities and neurological diseases . to this end ,",
    "regression analysis , a general and flexible modeling framework for studying the association among variables , has been investigated and considered as a powerful tool in the analysis of massive neuroimaging data , where neuroimages are modeled as outcome variables ; and the disease status along with the clinical , biological and demographical information can all potentially be predictors .    a pioneer work using the regression model for the neuroimaging data",
    "is the mass univariate analysis ( mua ) .",
    "this approach fits a general linear model ( glm ) at each spatial location in the brain ( to which is referred as a voxel ) and obtains massive test statistics over space to identify voxels / regions that are significantly associated with a specific covariate , which requires multiple comparisons correction .",
    "one standard procedure is to calculate the family - wise error rate ( fwer ) based on the random field theory for statistical parametric maps @xcite .",
    "another approach is to control the false discovery rate ( fdr ) using the observed p - values  @xcite .",
    "a major drawback of mua is that the models do not borrow information from the spatial dependence across brain locations . in practice ,",
    "the neuroimaging data are usually pre - processed by a spatial smoothing procedure using a kernel convolution approach .",
    "performing mua on these pre - smoothed data may lead to inaccuracy and low efficiency in terms of estimating and testing the covariate effects @xcite .",
    "recent development in adaptive smoothing methods for preprocessing @xcite and estimation @xcite may improve the performance in terms of reducing noise and preserving features .",
    "it is especially powerful to detect delicate features such as jump discontinuities , which is one of the universal characteristics for neuroimaging data @xcite .    to achieve a similar goal in the analysis of neuroimaging data",
    ", @xcite recently developed a systematic modeling approach using a novel spatially varying coefficient model ( svcm ) which incorporates both spatial dependence and piecewise smooth covariate effects .",
    "general svcms have been extensively investigated and developed for different applications in environmental heath , epidemiology , ecology and geographical studies as demonstrated in @xcite .",
    "the svcm encompasses a wide range of regression models with the outcome variable observed over space and the regression coefficients modeled as functions varying spatially .",
    "we refer to this type regression coefficients as spatially varying coefficient functions ( svcfs ) .",
    "svcfs are commonly assumed to be smooth functions or @xmath0 times continuously differentiable functions with @xmath1 ( we will not make this distinction throughout the rest of this paper unless noted ) .",
    "to model to svcfs , smooth spatial processes are usually employed to characterize the dependence structure over space .",
    "a pure noise process is typically introduced to capture random variabilities , i.e. the  spatial nugget effect \" .",
    "@xcite extended the general svcms by introducing jump discontinuities into the svcfs , making the model especially useful for neuroimaging data analysis .",
    "based on stepwise multiscale estimating procedures and asymptotic wald tests , @xcite s svcm also can identify the brain regions that are significantly associated with the given covariates , although it is not developed particularly for feature selection .    in this article , we aim to develop a bayesian feature selection method for large - scale neuroimaging data that can directly select imaging features associated with covariates of interest .",
    "regularization methods have been studied extensively for variable selection in regression models @xcite .",
    "bayesian methods have also been developed based on various prior specifications .",
    "@xcite developed a prior model for linear model coefficients using the mixture of a uniform distribution ( slab ) and a point mass at zero ( spike ) , which is broadly referred to as the spike - and - slab type of priors .",
    "@xcite proposed to use the scale mixture of two zero - mean gaussian distributions and developed posterior computation algorithm based on gibbs sampling .",
    "relative works also include but not limited to @xcite .",
    "most of these priors were initially introduced for independent regression coefficients . in light of the needs of integrating complex data structure in many applications , recent development of bayesian variable selection",
    "incorporates dependence structures into the prior model .",
    "@xcite assumed that covariates lay on an undirected graph and used the ising prior to incorporate this information to the model space and applied this method to analyze the genomics data . for the modeling of spatial data , markov random field ( mrf ) is one of the commonly used priors for regression coefficients .",
    "for instance , @xcite applied this type of priors to fmri data analyses .",
    "for the analysis of physical activity and environmental health data , @xcite developed an multivariate svcm along with a bayesian variable selection procedure to identify important svcfs , using the spike - and - slab prior .",
    "their focus , however , was on distinguishing covariate effects that were zero constant , nonzero constant and spatially varying instead of selecting features within the varying coefficient functions .    as the aforementioned variable selection methods can not be directly applied to identify important features for massive neuroimaging data in the svcm framework . to fill this gap",
    ", we develop a novel bayesian nonparametric prior model for the svcf .",
    "we refer to it as the thresholded multiscale gaussian process ( tmgp ) .",
    "the tmgp prior is constructed by thresholding a multiscale gaussian process , which is a combination of two types of gps : a global gp to account for the entire domain spatial dependence and a local gp to accommodate the regional fluctuations .",
    "thus , the tmgp can characterize important common features of the neuroimaging data , including sparsity , global spatial dependence , piecewise smoothness , edge effects and jumps .",
    "the proposed tmgp prior enjoys the large support property , leading to posterior strong consistency in estimation and feature selection for the sparse and piecewise smooth svcfs .",
    "we also develop efficient mcmc posterior computation algorithms based on a kernel convolution approach .",
    "a special choice of the kernel function enables the computation scalable to an ultra - high dimensional case .",
    "the remaining parts of the article is organized as follows : in section 2 , we first introduce the svcms for neuroimaging data analysis and particularly discuss conditions on svcfs in the proposed model",
    ". then we present the construction of tmgp which serves as a prior model for svcfs . in section 3",
    ", we study the theoretical properties of tmgp and the proposed svcms . in section 4",
    ", we develop an efficient and scalable posterior computation algorithm based on a kernel convolution approach .",
    "we evaluate the performance of proposed method via simulation studies and and analyze the abide data in section 5 .",
    "we conclude our work with a brief discussion on the future work in section 6 .",
    "we start with general notations and definitions .",
    "denote by @xmath2 a @xmath3-dimensional real euclidean space for any @xmath4 . for any @xmath5 , write @xmath6 , define @xmath7 , @xmath8 and @xmath9 .",
    "denote by @xmath10 a compact region in the standard brain space .",
    "let @xmath11 be a set of spatial locations where brain signals are measured .",
    "an empirical measure on @xmath12 induced by @xmath13 is defined as @xmath14 $ ] , where the indicator function @xmath15 = 1 $ ] if event @xmath16 occurs , @xmath15 = 0 $ ] , otherwise . for a scalar - valued function @xmath17 ,",
    "define @xmath18 and @xmath19 . for a @xmath3-dimensional vector - valued function @xmath20^{\\rt } : \\mr \\mapsto \\mathbb r^p$ ] , define @xmath21 .",
    "denote by @xmath22 a collection of all the continuous functions defined on @xmath12 .",
    "let @xmath23 be a partial derivative operator on function @xmath24 ( given its existence ) which is given by @xmath25 for @xmath26 .",
    "denote by @xmath27 a set of functions @xmath28 defined on @xmath12 with continuous partial derivatives @xmath29 for all @xmath30 such that @xmath31 .",
    "suppose the data set consists of @xmath32 subjects .",
    "for each subject @xmath33 , let @xmath34 be the brain signal measured from a certain imaging modality at location @xmath35 ; and there are also @xmath3 covariates are collected , denoted @xmath36 , for @xmath37 .",
    "the spatially varying coefficient model ( svcm ) for neuroimaging data is given by [ model ] y_j ( ) = _ j^ ( ) + e_j ( ) , where @xmath38^{\\rt}$ ] is the spatially varying coefficient function ( svcf ) defined on @xmath12 .",
    "it characterizes associations between covariates and imaging outcomes . to be more specific , @xmath39 ( @xmath40 ) quantifies the @xmath41th covariate effects at brain location @xmath42 .",
    "the independent error process @xmath43 is the assumed to be spatially homogeneous across the whole brain for each subject . in our model , we simply assume that @xmath44 for all subjects at all locations .    for neuroimaging data from commonly used imaging modalities , only outcomes at locations @xmath45 , @xmath46 , @xmath47 are observed .",
    "at these locations , the svcm proposed in for the recorded neuroimaging data can be expressed as [ outcome ] [ ( _ i)(_i ) , ^2 ] ~n ( x ( _ i ) ,  ^2i_m)independently for all @xmath48 , where @xmath49^{\\rt}$ ] , @xmath50^{\\rt}$ ] and @xmath51^{\\rt}$ ] .",
    "for simplicity , denote by @xmath52 an @xmath53 matrix recoding all the neuroimaging outcomes involved in the study .",
    "in neuroimaging studies , there exists a natural region partition of the whole brain domain @xmath12 into bounded connected sets @xmath54 with non - empty interiors , such that @xmath55 . in many cases",
    ", one can utilize @xmath56 as neuroanatomical regions from commonly used labeling systems such as the automated anatomical labeling ( aal ) @xcite .",
    "for region of interest ( roi ) based analysis , each roi is one parcellated region . for seed - based region - level analysis",
    ", @xmath56 can be regarded as the clusters showing strong functional connectivities based on preliminary results . in some voxelwise analysis with no regional information to be incorporated",
    ", we can simply consider each voxel ( a 3d cubic ) as a region and the centers of voxels as observed brain locations @xmath57 . to utilize the proposed svcm for analysis of neuroimaging data and feature selection , we state our assumptions for the svcf in model .",
    "specifically , we work with piecewise smooth ( @xmath0-times continuously differentiable to be accurate ) functions with structured sparsity , which can be mathematically expressed as follows : for any function @xmath58 defined on @xmath12 to be a varying coefficient function within model , @xmath58 must satisfy that :    * there exists an index set @xmath59 , such that @xmath60\\in \\mc^\\rho(\\overline\\mr_g)$ ] where @xmath61 is the closure of @xmath56 , for all @xmath62 with @xmath63 + 1 $ ] ; * for any @xmath62 , @xmath58 is bounded away from zero , that is , @xmath64 * let @xmath65 , then @xmath66 for all @xmath67 .",
    "the conditions on the svcfs can be interpreted as follows : ( c1 ) demonstrates that the functions are smooth within each brain region , which implies more homogeneous covariate effects ; ( c2 ) indicates the jump discontinuities at the boundaries of brain regions ; ( c3 ) introduces sparsity into each svcf in model and restricts the sparsity structure at the regional level .",
    "we introduce the notation @xmath68 to represent a set of functions satisfying ( c1)(c3 ) defined on @xmath12 .",
    "the definition @xmath68 carries the information of @xmath69 as well as @xmath70 and @xmath71 . for any function @xmath72 ,",
    "denote by @xmath73 the index of nonzero sets as given in ( c1 ) and by @xmath74 the value @xmath70 defined in ( c2 ) . in the same vein ,",
    "define a set of @xmath3-dimensional vector - valued functions @xmath75^\\top : \\beta_k(\\bs)\\in \\mp , k=1,\\ldots , p\\}$ ] .",
    "a gaussian process ( gp ) can be regarded as a probabilistic measure on certain functional spaces , making it as popular prior models in bayesian nonparametric data analysis . in general , the gp prior , denoted by @xmath76 $ ] , is determined by its mean function @xmath77 and the covariance kernel function @xmath78 .",
    "a draw @xmath79 $ ] is a function defined on @xmath12 such that any finite collection of its function values are jointly multivariate gaussian . to be specific , for any choices of @xmath80 , @xmath81^\\top\\sim n(\\bm\\mu , \\bm c)$ ] with @xmath82^\\top$ ] and @xmath83 .",
    "the boundedness and smoothness of random functions generated from gp are determined through the covariance kernel function .",
    "typical choices for the covariance kernel functions include but not limited to the rational quadratic kernel , matrn class of kernels , the square exponential kernel .",
    "@xcite contain more detailed discussions on the covariance functions .    to enable detailed feature selections within the svcfs @xmath84 in model",
    ", we develop the thresholded multiscale gaussian process ( tmgp ) prior , which can be represented as follows : @xmath85 $ ] implies that [ thres ] ( ) = ( ) i_,[mgp ] ( ) = ( ) + ( ) , [ ggp]()~,[lgp]()~for all @xmath86 , where [ thresfunc]i_=_g=1^g iis the thresholding function that generate region - wise sparse features ; @xmath87 is the thresholding parameter ; @xmath88 and @xmath89 are variance parameters in the gps ; @xmath90 is a kernel correlation function and @xmath91 is constructed from @xmath92 as @xmath93 $ ] .    the thresholding construction of @xmath58 from a particular multiscale gaussian process  ( *",
    "* mgp ) @xmath94 introduces sparsity and enables feature selection . for voxel",
    "- wise analysis without regional information , the thresholding function in can be simplified as @xmath95=i[|\\tbeta(\\bs)|>\\lambda]$ ] , where @xmath42 denotes the center of a voxel .",
    "the mgp @xmath94 in our prior is a combination of one  global \" gp , @xmath96 , which captures the general dependence structures across the whole brain domain and one  local \" gp , @xmath97 , reflecting the dependence and variabilities within each parcellated brain region .",
    "this multiscale construction can also naturally generate jumping discontinuities on the boundaries of the brain regions .",
    "we illustrate the procedure to sample an svcf from our tmgp priors on a two - dimensional square region in figure [ tmgp_eg ] , where the dashed lines partition the whole region into four equally spaced sub - regions .",
    "@xmath96 is smooth over the whole region ; @xmath97 is smooth within each sub - region but has distinct jumps on the boundaries . as we may see from figure [ tmgp_eg ] ,",
    "one particular issue is that the generating processes , @xmath96 and @xmath97 , could vary substantially while results in similar sparse svcfs .",
    "this phenomenon indicates weak identifiability in global and local gps in the tmgp prior model . to resolve this issue",
    ", we impose the certain constraint on the marginal variance of the local gp @xmath97 .",
    "i.e. , @xmath98 .",
    "this implies that we assume that the sampled svcf is constructed from strong global signals and weak local signals .",
    "we first introduce two sets of extra conditions in addition to the conditions ( c1)-(c3 ) for the svcfs . the design matrix @xmath99 as defined in satisfies :    * let @xmath100 and @xmath101 be the smallest and largest eigenvalues of @xmath102 , then @xmath103 .    for the kernel correlation functions",
    "@xmath104 in our proposed tmgp priors , we introduce the following condition :    * @xmath105 for some nowhere zero , continuous , symmetric density function ( up to a normalization constant ) @xmath106 defined on @xmath107 .",
    "* @xmath108 has continuous partial derivates up to order @xmath109 where @xmath110 + 1 $ ] .",
    "[ largsup ] consider an arbitrary svcf @xmath111 , i.e. @xmath112 satisfies conditions ( c1)-(c3 ) .",
    "let @xmath113 $ ] and suppose the partition number @xmath114 .",
    "if @xmath115 and the kernel function @xmath92 satisfies ( k1 ) , then the proposed prior @xmath116\\ ] ] given in - satisfies that @xmath117    theorem [ largsup ] demonstrates that the proposed tmgp prior assign positive measures to arbitrarily small neighborhoods of all elements within @xmath68 , the family of spatially varying coefficient functions defined in our model .",
    "this property is essential , especially for bayesian nonparametric priors , since it is necessary for appropriate posterior behaviors and can not be guaranteed in many cases .",
    "[ poscons ] suppose that our observed data satisfies @xmath118 independently following the notations in , with a known @xmath119 and a fixed @xmath3-dimensional svcf @xmath120^{\\rt } , \\",
    "p < m$ ] , defined on @xmath12 .",
    "suppose @xmath121 satisfies conditions ( c1)-(c3 ) , i.e. @xmath122 , with @xmath114 ; @xmath123 satisfies condition ( x1 ) ; the kernel function in the tmgp priors satisfies ( k1 ) and ( k2 ) . for all",
    "@xmath124 , if @xmath125 and each dimension of @xmath126 follows a tmgp prior independently satisfying the conditions in theorem [ largsup ] , then the posterior distribution satisfies that @xmath127 \\to 0,\\ ] ] as @xmath128 in @xmath129 probability , where @xmath130 .",
    "theorem [ poscons ] justifies the posterior consistency of the proposed tmgp prior given model under the infill asymptotic framework .",
    "it implies that , if a ground truth of the svcfs exists and the data is generated accordingly , then the posterior distribution of @xmath126 can be concentrated to an arbitrarily small @xmath131 neighborhood around the truth as the number of spatial locations goes to infinity .",
    "the conditions of this theory also imply that a small ratio between the number of subjects and the variance of pure noise , i.e. , @xmath132 , is also important to guarantee a good performance of our method .",
    "one limitation of theorem [ poscons ] is that it does not apply to the voxel level analysis where @xmath133 .",
    "however , this type of analysis generally works well empirically .",
    "although the @xmath131 norm is not common in bayesian asymptotic literatures , a direct result based on theorem [ poscons ] is the element - wise posterior consistency for @xmath126 under the commonly used empirical @xmath134 norm for a fixed design of spatial locations @xmath135 @xcite .",
    "[ posconsele ] under the same assumptions and conditions in theorem [ poscons ] , for all @xmath124 , if @xmath136 , then the posterior distribution satisfies that for all @xmath137 , @xmath138 \\to 0\\ ] ] as @xmath128 in @xmath129 probability , where @xmath139 .    of note , in neuroimaging studies , @xmath135 are usually fixed 3d grid points , thus we do not consider the @xmath134 norms with regard to random measures for @xmath42 when proving posterior consistency .",
    "for a fixed design within a finite domain @xmath12 ( the volume of brain is limited ) , another useful direction is to show posterior consistency under the @xmath134 norm with regard to the lebesgue measure . we see this as a potential extension to the theory development in the future work .",
    "now consider the svcm defined in .",
    "for the @xmath3-dimensional multivariate spatially varying coefficient function , @xmath140^{\\rt}$ ] , we assume that @xmath141,\\ ] ] with @xmath104 being a smooth kernel function .",
    "this specification implies that the global processes have distinct flexible variance parameters @xmath142 , while the local fluctuation processes have a small fixed marginal variance @xmath98 .",
    "based on the prior specification for @xmath126 , we have that @xmath143 $ ] for @xmath40 , where [ priormodel ] _ k ( ) = _ k ( ) + _ k(),where @xmath144 $ ] and @xmath145\\right)$ ] . for global gps : @xmath146 in , its karhunen - love ( kl ) expansion can be expressed as [ klexpan]_k ( ) = _ l=1^_l()u_kl , where @xmath147 independently with @xmath148 such that @xmath149 and that @xmath150 based on the mercer s theorem @xcite . in practice , we truncate the infinite sum in into @xmath151 terms such that @xmath152 is close to @xmath153 .",
    "this implies a model representation of the proposed svcm along with the tmgp prior specifications . to be more specific ,",
    "the neuroimaging signal @xmath34 on locations @xmath57 can be modeled through latent mgps : @xmath154^{\\rt}$ ] and the truncated kl expansion coefficients @xmath155 with @xmath156^\\top$ ] by integrating out the local gps @xmath157 in , which is given by [ lvl1 ] [ y_j(_i)(_i ) , ^2 ] ~n ( x_j^g_[(_i ) ] ,   ^2),[lvl2][\\{_k(_i)}__i_gu_k ] ~n ( _ gu_k ,   ^2 k_g ) , [ lvl3 ]  u_kl~n(0 , _",
    "l^2_k ) , for @xmath158 and @xmath159 , where @xmath160 represents a normal distribution with mean @xmath161 and variance @xmath119 , @xmath162 with @xmath163^{\\rt}$ ] and @xmath164 is a correlation matrix .",
    "the @xmath3-dimensional vector value functional operator @xmath165 is defined on the domain of all functions in @xmath166 , which is given by @xmath167=\\left [ \\tbeta_1(\\bs)i_{\\lambda_1}[\\tbeta_1(\\bs)],\\ldots , \\tbeta_p(\\bs)i_{\\lambda_p}[\\tbeta_p(\\bs ) ]   \\right]^{\\rt},\\ ] ] with @xmath168^{\\rt}$ ] .",
    "we assign conjugate priors to variance parameters @xmath119 and @xmath142 in the tmgp model , i.e. @xmath169 and @xmath170 , where @xmath171 represents an inverse gamma distribution with shape @xmath172 and rate @xmath173 .",
    "we fix @xmath174 to restrict local deviations in order to sort out the weakly identifiability in the model , especially for the case that a small number of observations are recorded in each region .",
    "we develop a data - driven method to specify the prior of thresholding parameters @xmath175 .",
    "we consider the log full conditional of @xmath176 which is given by @xmath177 = \\ell[\\lambda_k;{\\mathcal y } , { \\bm\\tbeta}_k , { \\bm\\beta}_{-k}]/\\sigma^2 + c,\\ ] ] where @xmath178 is a constant , @xmath179^{\\rt}$ ] , @xmath180^{\\rt}$ ] , @xmath181^{\\rt}$ ] , and [ logliklmd](_k ) : = = _ i=1^n _ k(_i)i__k[_k(_i ) ] , with @xmath182 $ ] and @xmath183 .",
    "the function @xmath184 is flat when @xmath176 is around zero and dramatically decreases when @xmath176 is greater a certain value , to which we refer as a  turning point \"",
    ". it should be close to the true threshold .",
    "figure [ figlmd ] shows the profiles of @xmath184 for a model with three svcfs on a space of @xmath185 locations from @xmath186 simulated datasets .",
    "the true thresholds @xmath187 for @xmath188 .",
    "the turning points in the profiles of @xmath184 are all around the true thresholds .",
    "thus , we can specify the priors of @xmath176 according to @xmath184 . in practice , we need to provide rough estimates of @xmath189 and @xmath190 in order to evaluate @xmath184 before posterior inferences .",
    "we consider an svcm with smoothed svcfs approximated by the truncated k - l expansion , where we compute the ordinary least squares ( ols ) of the coefficients , i.e. @xmath191 then both @xmath192 and @xmath39 can be approximated by @xmath193 .",
    "thus , we replace @xmath194 and @xmath195 by @xmath196^{\\rt}$ ] and @xmath197^{\\rt}$ ] , respectively , in .",
    "write @xmath198 .",
    "we propose to assign uniform priors to @xmath176 , i.e. @xmath199 , where the half range @xmath200 and center @xmath201 can be determined based on the profile of @xmath202 .",
    "more specifically , we evaluate @xmath202 on a set of grid points @xmath203 , denoted @xmath204 . given an interval @xmath205 ,",
    "define the sample correlation between @xmath176 and @xmath202 within @xmath206 as @xmath207 with @xmath208 , @xmath209 and @xmath210 $ ] . and define @xmath211 where @xmath212 is determined by the rejection region of pearson correlation test .",
    "given @xmath213 , @xmath214 represents the location that @xmath202 and @xmath176 have no significant correlation",
    ". then we specify @xmath215 this leads to an informative prior range @xmath216 $ ] for @xmath176 with a high probability to cover the turning point of @xmath184 .",
    "theoretically , the kl expansion for the gp with kernel function @xmath217 relies on solving the integral equation @xmath218 , which might not admit analytical solutions .",
    "empirically , the expansion is often achieved by calculating the eigenvalues and eigenvectors of the @xmath219 correlation matrix @xmath220 on a set of pre - specified locations . however , in the analysis of massive neuroimaging data that can involve a very large number ( @xmath221 can be hundreds of thousands ) of brain locations , it is computationally infeasible to perform eigen decompositions on @xmath222 . to solve this issue , we introduce the modified square exponential kernel [ mse ] ( ,  ) = \\{-a_2 ^ 2-a_2 ^ 2-b-_2 ^ 2 } ,  a , b>0 with a relatively small value for @xmath223 as a numerical approximation to the square exponential kernel when dealing with massive neuroimaging data .",
    "the major benefit of this kernel function is that it has analytically tractable expansion .",
    "the detailed properties of this kernel is summarized in proposition [ kernel ] .    for a specific @xmath224 ,",
    "define series @xmath225 , @xmath226 and @xmath227 as follows @xmath228 @xmath229 @xmath230 where @xmath231 is the set of nonnegative integers ; @xmath232 if @xmath233 .",
    "define @xmath234 . for @xmath235^\\top\\in\\mathbb r^d$",
    "] , let @xmath236 and @xmath237 be the eigenfunctions and eigenvalues for the modified square exponential kernel @xmath238 as defined in , then @xmath239 @xmath240 where @xmath241 , @xmath242 and @xmath243 ; @xmath244 is the @xmath41th ( @xmath245 ) order normalized hermit polynomial , which is defined by @xmath246 .",
    "[ kernel ]      we developed a generally efficient mcmc sampling algorithm for posterior inference about @xmath247 $ ] based on the representation and approximation for our model with the tmgp priors - .",
    "updating @xmath248 is an essential step in the mcmc algorithm . the metropolis - hasting",
    "( m - h ) algorithm is employed with a block updating scheme separately for @xmath249 , @xmath250 to facilitate efficient chain mixing . under the scenario where region partition structure @xmath251 is available and reliable",
    ", we can directly use this partition information . for voxel level analysis or analysis where no prior knowledge about the regional information are adopted",
    ", we first fit voxel - wise glms and then use certain clustering algorithms to cluster the resulting spatially varying coefficient values .",
    "this initial clustering results for the brain locations ( usually centers of voxels ) are used for block updating .",
    "another m - h step in our algorithm is updating @xmath252 , the thresholding parameters in the tmgp priors .",
    "the remaining parameters ( @xmath253 ) and hyperparameters ( @xmath254 ) are updated by directly drawing samples from their full conditionals due to conjugacy .",
    "more details about the mcmc algorithm are available at the appendix .      with the recorded mcmc samples @xmath255 , @xmath256 and @xmath257 , we can achieve three major goals : 1 ) selecting neuroimaging features ; 2 ) estimating covariate effects at the feature regions ; 3 ) making prediction on the covariate effects at any brain location .    to select the important imaging features at the regional level , we estimate the selection probability of every region , @xmath258 , according to the definition ( c1)-(c3 ) , using the mcmc samples as @xmath259,\\ ] ] then we estimate @xmath260 as follows , if @xmath261 ,    [ estimator]_k(_i)=\\ {    lc e[_k(_i)_1jn , _ j_g |_k(_j)|>_k , y ] , & p(gi_1)>q + 0 , & p(gi_1)q    .",
    ", for all @xmath262 , where @xmath263 is a threshold for the posterior probabilities of being nonzero at certain brain locations .",
    "we use @xmath264 throughout the rest of our analysis .",
    "estimates for the posterior conditional expectations in can be easily calculated based on the posterior samples .    as a special case , to conduct voxel level selection ( i.e. , each voxel is a region with voxel centers being @xmath265 ) , we can simply adapt to [ estimatorvxl]_k(_i)=\\ {    lc e[_k(_i)|_k(_i)|>_k , y ] , & p(|_k(_i)|>_ky)>q + 0 , & p(|_k(_i)|>_ky ) q    .,where @xmath266 $ ] can be regarded as the posterior probability of activation for each voxel .",
    "making predication on @xmath267 at an arbitrary new brain location @xmath268 with the posterior samples is also available .",
    "without loss of generality , suppose @xmath269 , then @xmath270 where @xmath271 represents the probability densities ; @xmath272 is actually @xmath273 ; @xmath274=[\\tbeta_k(\\bs_0)\\mid \\bm \\tbeta_k^g]\\sim n(\\bm\\varphi(\\bs_0)^\\top\\bm u_k + k_g(\\bs_0)^\\top k_g^{-1}(\\bm\\tbeta_k^g-\\bm\\varphi_g\\bm u_k),\\   \\theta^2-\\theta^2k_g(\\bs_0)^\\top k_g^{-1}k_g(\\bs_0))$ ] with @xmath275 .",
    "this indicates that we can predict @xmath276 at an unobserved location @xmath277 as    [ predict]_k(_0)=\\ {    ll _",
    "t=1^_k^g(t ) , & _ g   + 0 , & _",
    "g     .,where @xmath278 is the corresponding vector for @xmath279 based on the @xmath280th recorded mcmc sample .",
    "for demonstration purpose , we consider a 2d case , i.e. @xmath281 ^ 2 $ ] in this simulation .",
    "three covariate functions , @xmath282 and @xmath283 , are created on @xmath12 as shown in figure [ fig1 ] ( the  true \" column ) .",
    "we consider @xmath284 and @xmath285 locations within the fixed domain @xmath12 .",
    "the data is generated from [ simu1 ] y_j(_i ) = _",
    "1(_i)x_j1+_2(_i)x_j2 + _ 3(_i)x_j3+e_j(_i),where @xmath286 and @xmath287 .",
    "we considered two sample sizes @xmath288 and @xmath289 in combination with two different noise levels @xmath290 and @xmath291 . given one combination @xmath292 , @xmath186 datasets are independently generated .",
    "the mcmc algorithm is implemented to fit the svcm model and select informative features for each dataset .",
    "we choose the se kernel for the tmgp priors .",
    "the spatial range parameter , @xmath293 , was fixed as @xmath294 .",
    "the priors for the thresholding parameters were fixed as unif@xmath295 .",
    "all pixels are divided into four subsets for block updating according to @xmath41-means clustering results .",
    "the mcmc iterations are implemented @xmath296 times with the first @xmath297 samples discarded as burn - in . for each simulated dataset , the algorithm usually takes less than @xmath153 minute to complete the @xmath296 iterations on a standard intel i7 quad core desktop pc .",
    "we compare our results to the standard voxelwise glm methods .",
    "the features estimated from the glm method are thresholded based on the @xmath3-values for testing whether @xmath298 .",
    "we considere both the direct thresholding based on nave @xmath280-test ( glm-@xmath280 ) , thresholding using the fdr adjusted @xmath3-values ( glm - fdr ) @xcite and thresholding by controlling fwer based on standard random field theory ( glm - rft ) @xcite .",
    "figure [ fig1 ] presents the estimated covariate effect functions from glm-@xmath280 , glm - fdr , glm - rft and our method based on one simulated dataset from our experiments .",
    "figure [ fig1 ] shows that our method provides more accurate feature selection results by eliminating most false positive signals as well as maintaining high sensitivity .",
    "our estimates also recover the features more accurately by incorporating spatial smoothness .",
    "in addition , our posterior inference procedures can provide , for each pixel in the images , the probability of presenting features that are different from zero , as shown in the last column in figure  [ fig1 ] .",
    "for all the scenarios , we report in table [ table1 ] the relative mean square errors with regard to the glm estimates , which is defined as = , where @xmath299 are the estimates from a certain method , @xmath300 are the voxel - wise glm estimates without any thresholding and @xmath301 represent the true values .",
    "we also reported the false discovery rates ( fdrs ) and the false negative rates ( fnrs ) in table [ table1 ] , which are specified as : = , = .    based on the results from table [ table1 ] , our method performs well consistently in terms of both feature selection ( small fdrs and fnrs ) as well as estimation ( small remse ) ,",
    "especially when the noise level is high or the number of subjects is small .",
    "random field theory based thresholding performs well at low noise level but deteriorates notably as noise level increases due to low sensitivity .",
    "fdr control is also relatively robust but this method consistently generates false positive signals .",
    "the performance of our svcm - tmgp method also increases as the number of spatial locations increases within a fixed domain , which agrees with our posterior consistency theory based on infill asymptotics .    to comprehensively compare the performance of tmgp priors in feature selection with other common methods",
    ", we also conduct the receiver operating characteristic ( roc ) analysis .",
    "since our original method will automatically generate the optimal thresholding values , in this roc analysis , we fix @xmath302 at different values and rerun the mcmc simulation to alternate the specificities .",
    "figure [ roc ] shows the roc curves of our method , glm - fdr and glm - rft with @xmath303 and @xmath288 ( @xmath304 and @xmath305 , respectively ) . to quantify the differences",
    ", we calculate the area under roc curves ( table [ tab : roc ] ) when the false positive rates are smaller than @xmath306 for all three methods .",
    "figure [ roc ] and table [ tab : roc ] show that , under all these three settings , our method ( svcm - tmgp ) achieve the best performance ; as @xmath221 increases , our method proves to have improved performance .",
    "the random field correction based on fwer control ( glm - rft ) suffers from serious false negative problems , leading to low statistical powers .",
    "the fdr control ( glm - fdr ) is a competitive alternative to our method , especially when the number of spatial locations , @xmath221 , is relatively small .    to demonstrate the bayesian learning of the thresholding parameters , we present the histograms for our recorded mcmc samples along with the trace plots for the whole markov chain from one simulated dataset .",
    "it is clear that the marginal posterior distributions of the all thresholding parameters are different from the same prior unif@xmath307 .",
    "this indicates our model can achieve bayesian learning @xcite of all the thresholding parameters .",
    "0.15 in    1.0ccccccccccccccc    & & & remse&fdr(%)&fnr(% ) & & remse&fdr(%)&fnr(% ) +    n=900 & & & & & +    & glm-@xmath280 & & 0.39(0.12 ) & 18.3(4.3 ) & 0.0(0.0 ) & & 0.40(0.23 ) & 17.5(5.3 ) & 1.5(0.2 ) + & glm - fdr & & 0.24(0.07 ) & 5.0(1.0 ) & 0.0(0.0 ) & & 0.32(0.08 ) & 5.4(1.5 ) & 4.1(0.6 ) + & glm - rft & & 0.36(0.17 ) & 0.0(0.0 ) & 4.4(1.5 ) & & 0.80(0.29 ) & 0.0(0.0 ) & 22.7(5.6 ) + & svcm - tmgp & & 0.19(0.08 ) & 0.9(0.4 ) & 0.8(0.2 ) & & 0.12(0.02 ) & 2.8(0.9 ) & 0.7(0.2 ) + n=900 & & & & & + & glm-@xmath280 & & 0.41(0.13 ) & 18.9(3.5 ) & 0.0(0.0 ) & & 0.39(0.11 ) & 19.2(4.9 ) & 0.0(0.0 ) + & glm - fdr & & 0.25(0.06 ) & 5.2(0.7 ) & 0.0(0.0 ) & & 0.22(0.06 ) & 5.1(1.2 ) & 0.0(0.0 ) + & glm - rft & & 0.17(0.10 ) & 0.2(0.0 ) & 0.0(0.0 ) & & 0.31(0.14 ) & 0.5(0.0 ) & 4.6(1.3 )     + & svcm - tmgp & & 0.20(0.08 ) & 0.2(0.0 ) & 0.2(0.0 ) & & 0.19(0.08 ) & 1.3(0.4 ) & 0.6(0.2 ) +    n=2500 & & & & & +    & glm-@xmath280 & & 0.32(0.10 ) & 28.1(5.3 ) & 0.0(0.0 ) & & 0.33(0.16 ) & 28.8(6.5 ) & 0.4(0.1 ) + & glm - fdr & & 0.13(0.02 ) & 2.9(1.0 ) & 0.3(0.1 ) & & 0.20(0.08 ) & 4.3(1.6 ) & 5.0(1.6 ) + & glm - rft & & 0.27(0.14 ) & 0.3(0.0 ) & 6.3(2.1 ) & & 0.61(0.29 ) & 0.4(0.2 ) & 27.9(4.5 ) + & svcm - tmgp & & 0.12(0.06 ) & 0.2(0.0 ) & 0.6(0.1 ) & & 0.08(0.03 ) & 1.2(0.4 ) & 0.9(0.4 ) + n=2500 & & & & & +    & glm-@xmath280 & & 0.34(0.09 ) & 29.4(4.9 ) & 0.0(0.0 ) & & 0.35(0.12 ) & 29.2(5.0 ) & 0.0(0.2 ) + & glm - fdr & & 0.19(0.06 ) & 5.4(0.8 ) & 0.0(0.0 ) & & 0.14(0.03 ) & 4.6(1.3 ) & 0.1(0.0 )     + & glm - rft & & 0.10(0.05 ) & 0.1(0.0 ) & 0.1(0.0 ) & & 0.30(0.14 ) & 0.3(0.0 ) & 7.0(2.3 )     + & svcm - tmgp & & 0.15(0.04 ) & 0.1(0.0 ) & 0.3(0.0 ) & & 0.13(0.05 ) & 0.4(0.1 ) & 0.6(0.1 ) +    n=3600 & & & & & +    & glm-@xmath280 & & 0.33(0.09 ) & 35.2(6.2 ) & 0.0(0.0 ) & & 0.31(0.11 ) & 31.5(7.3 ) & 0.7(0.4 ) + & glm - fdr & & 0.12(0.03 ) & 3.8(1.0 ) & 0.2(0.0 ) & & 0.17(0.04 ) & 3.8(1.3 ) & 5.2(1.4 ) + & glm - rft & & 0.25(0.07 ) & 0.2(0.0 ) & 7.6(2.2 ) & & 0.48(0.10 ) & 0.3(0.1 ) & 28.7(4.6 ) + & svcm - tmgp & & 0.10(0.03 ) & 0.1(0.0 ) & 0.0(0.0 ) & & 0.07(0.02 ) & 1.1(0.3 ) & 1.8(0.6 ) + n=3600 & & & & & +    & glm-@xmath280 & & 0.33(0.06 ) & 34.4(5.1 ) & 0.0(0.0 ) & & 0.33(0.09 ) & 33.5(6.0 ) & 0.0(0.0 ) + & glm - fdr & & 0.18(0.02 ) & 4.3(0.5 ) & 0.0(0.0 ) & & 0.13(0.03 ) & 2.6(0.7 ) & 0.0(0.0 )     + & glm - rft & & 0.09(0.06 ) & 0.0(0.0 ) & 0.2(0.5 ) & & 0.24(0.07 ) & 0.1(0.0 ) & 6.5(1.3 )     + & svcm - tmgp & & 0.12(0.03 ) & 0.0(0.0 ) & 0.5(0.0 ) & & 0.11(0.03 ) & 0.2(0.0 ) & 0.5(0.3 ) +    -0.1 in    @xmath308{roc.pdf } &          \\end{array}$ ]    0.15 in    1.0lccccccccccc & + & @xmath309 & @xmath310 & @xmath311 + glm - fdr & 0.978 ( 0.010)&0.976 ( 0.014 ) & 0.979 ( 0.005 ) + glm - rft & 0.912 ( 0.049)&0.915 ( 0.080 ) & 0.911 ( 0.072 ) + svcm - tmgp&0.982",
    "( 0.012)&0.989 ( 0.007 ) & 0.998 ( 0.001 ) +    -0.1 in    @xmath312{lambda_learning.pdf } &          \\includegraphics[scale=0.35]{lmd_samples.pdf}\\\\          \\mbox{(a ) histograms for posterior samples of}\\   \\bm\\lambda &   \\mbox{(b ) traceplot for posterior samples of } \\ \\bm\\lambda           \\end{array}$ ]",
    "we apply our method to the data from abide , which is a consortium collecting and sharing resting - state fmri data from 1,112 subjects .",
    "covariate information such as age at scan , sex , iq , handedness and diagnostic information are also available from abide studies . among the subjects , 539 individuals have autism spectrum disorders ( asd ) , which are characterized by symptoms such as social difficulties , communication deficits , stereotyped behaviors and cognitive delays .",
    "the remaining subjects are the age - matched normal controls ( nc ) .",
    "all the fmri images are preprocessed through slice - timing , motion correction , nuisance signal regression and temporal filtering .",
    "the resulting fmri data , which are @xmath313 3d matrices , are normalized and registered to montreal neurological institute ( mni ) 152 stereotactic space . we aim to investigate the voxel - wise measures of latent functional architecture of the brains through fractional amplitude of low - frequency fluctuations ( falff)@xcite .",
    "falff is a metric reflecting the percentage of power spectrum within low - frequency domain ( @xmath314hz ) which characterizes the intensity of spontaneous brain activities .",
    "we calculate the falff for each subject at every voxel . since the falff is restricted to @xmath315 , we perform the following monotone transformation y_j ( ) = ( ) , where @xmath316 represents the falff for subject @xmath317 at brain location @xmath42 and treat the transformed data as our outcomes .    0.2 in    @xmath318{grp.png}\\\\          \\includegraphics[scale=0.35]{grpprob.png}\\\\          \\mbox{(a ) covariate effects for the asd group versus the control}\\\\           \\\\",
    "\\includegraphics[scale=0.35]{age.png}\\\\          \\includegraphics[scale=0.35]{ageprob.png}\\\\          \\mbox{(b ) covariate effects for the age}\\\\ \\\\",
    "\\includegraphics[scale=0.35]{grpgend.png}\\\\          \\includegraphics[scale=0.35]{grpgendprob.png}\\\\          \\mbox{(c ) covariate effects for group and gender interaction }          \\end{array}$ ]    -0.2 in    the covariates we choose for fitting model are [ 1 , group , age , gender , group@xmath319 age , group@xmath319 gender ] .",
    "we use all the voxels at the gray matter as the observed spatial locations @xmath265 and all the anatomical parcellation based on mni templates as our brain regions @xmath251 ( @xmath320 and @xmath321 ) .",
    "the imaging outcomes are centered across all subjects at each voxel .",
    "the group variable equals to @xmath153 for the asd subjects ; the ages are all centered and scaled with zero mean and unit variance ; the gender variable equals to @xmath153 for female subjects .",
    "the priors for the thresholding parameters are determined through the method described in subsection [ hyperp ] .",
    "the profiles of @xmath202 are shown in figure [ lmdselec ] .",
    "the priors for the six thresholding parameters are unif@xmath322 , unif@xmath323 , unif@xmath324 , unif@xmath325 , unif@xmath326 and unif@xmath327 according to the plots .",
    "the gaussian kernel we use is the modified square exponential kernel with @xmath328 ( bandwidth fixed without updating ) . to achieve @xmath329 recovery rate of the kl expansion",
    ", we set @xmath330 eigenfunctions .",
    "the mcmc algorithm runs @xmath331 iterations with @xmath332 burn - in .",
    "based on our results , the asd subjects tend to show lower falff outcomes at the median and superior part of the right occipital lobe , which is the visual processing centers of human brains ( the visual cortex ) .",
    "we observe significantly higher activities at the right fusiform gyrus , which has been reported to be related to autism in @xcite .",
    "similar findings are observed at the right median orbitofrontal cortex , the region involved in most human cognition processes , especially decision - making , indicating more spontaneous brain cognition activities among the asd subjects . from the axial view ,",
    "figure [ fig : res](a ) shows the information discussed above .",
    "some other regions that are selected includes the right thalamus and the right anterior cingulum , which we do not discuss here in detail .",
    "another major findings are the age effect on the falffs .",
    "we identified three brain regions that show higher falff outcomes as the age increases : the median occipital lobe , the median temporal lobe and the angular gyrus .",
    "these regions are generally involved in brain functions such as spatial temporal cognition , language , memory , attention and visual processing .",
    "figure [ fig : res](b ) shows the findings above in brain slices from the axial view .",
    "although no specific regions of interest are observed for the  gender \" variable , certain brain regions demonstrate different activation patterns its interaction with the disease group .",
    "specifically , female asd subjects have higher falffs as compared with male asd effects at the left median and superior part of the orbital gyrus but lower falffs at the left frontal lobe gyrus and the left rectus .",
    "figure [ fig : res](c ) shows these findings in three views for the ease of demonstration . beyond these findings",
    ", we also note that the right inferior temporal gyrus displays smaller effects among the female asd subjects as compared with the male autistics .",
    "in this paper , we introduced a new family of prior , the tmgp prior , for feature selections within spatially varying coefficient functions and its applications to massive neuroimaging data analysis .",
    "we demonstrate the prior large support properties of the tmgp prior and its posterior consistency under the spatially varying coefficient models under the spatial infill asymptotics .",
    "simulation studies show that the tmgp prior is especially useful for imaging feature selections with relatively large noise or small sample sizes .    in most spatial statistics literatures such as @xcite , a spatial process",
    "are decomposed into three parts : a deterministic trend process or , in other words , mean process ; a zero - mean variance process with continuous sample path and a zero - mean white noise process , i.e. , the nugget effect .",
    "under this general framework , @xcite considered a more complex model as compared with our model , which could be expressed using our notations as [ modelzhu ] y_j ( ) = _ j^ ( ) + _",
    "j()+ e_j ( ) , for all subjects @xmath333 .",
    "they estimated the additional term @xmath334 for every subject through standard local linear regression techniques , which do not require a pre - specified spatial covariance structure @xmath335 , or equivalently , its karhunen - love basis .",
    "since in this paper , our primary focus is on the glm framework for imaging data , we did not apply our tmgp prior under the setting of model . to enable a similar analysis using the tmgp prior for @xmath126 in under the bayesian framework , there are four major tasks .",
    "first , a proper prior specification for @xmath334 needs to be introduced which should be flexible enough to capture various spatially smooth dynamics .",
    "second , a computationally efficient algorithm for estimating the additional parameters brought by @xmath334 is required since this set of parameters scale with the number of subjects .",
    "third , since for each subject , we will have a subject specific random effect term , we need to carefully monitor the model fitting procedures to avoid potential over - fitting issues .",
    "fourth , the theoretical analysis for posterior consistency in theorem [ poscons ] needs to be adapted to the more challenging model structure .",
    "in addition to applying the tmgp prior to model , our study can be extended to some other directions . with a focus on neuroimaging studies using model",
    ", we can extend the prior constructions to enable self - guided parcellation while conducting feature selection tasks .",
    "this can help relax the region based sparsity assumptions for the svcfs .",
    "we can also explore the bayesian asymptotic theories when the number of brain region partitions diverges . with a focus on general bayesian analysis",
    ", we can extend tmgp for modeling high - dimensional multivariate binary processes or selecting features for scalar - on - image models such as neuropsychiatric disease predictions .",
    "based on the assumptions for @xmath112 , let @xmath336 $ ] and @xmath65 , we have that @xmath337    without loss of generality , we only consider @xmath338 . note that for all @xmath339 , @xmath340 and @xmath341 implies that @xmath342 , then is equivalent to @xmath343    let @xmath344 and @xmath345 be the normalized eigenfunctions and eigenvalues of the kernel function @xmath217 , then the karhunen - love expansions of @xmath96 and @xmath97 can be expressed as @xmath346 , @xmath347 and @xmath348 , @xmath349 , such that @xmath350 , @xmath351 and @xmath352 are all independent . since the rkhs of @xmath217 is @xmath22 , for @xmath42 within any partition @xmath353 , @xmath112 can be represented as @xmath354 where @xmath355 .    for @xmath356 with @xmath62 [ inequ2 ] _",
    "_ g|()-^0()|__g|_l , g()-^0_l , g()|+__g|_l , g^*()|+__g|_l , g^0*()| , where @xmath357 and @xmath358 .",
    "since the rkhs of @xmath217 is @xmath22 , @xmath94 is uniformly continuous on @xmath353 with probability @xmath153 , then by theorem 3.1.2 of @xcite , @xmath359 with probability @xmath153 . by the uniform convergence of the series @xmath360 to @xmath112 as @xmath361 on @xmath353 , @xmath362 .",
    "then we can find a finite integer @xmath363 such that for all @xmath364 , @xmath365 with probability @xmath153 and @xmath366 .",
    "since @xmath367 are all continuous functions in on @xmath12 , we have that @xmath368 where @xmath369 is a certain constant .",
    "let @xmath370 for all @xmath371 and consider @xmath372 in , we have that @xmath373 .",
    "thus , the condition @xmath374 can guarantee that @xmath375 with probability @xmath153 for @xmath376 .",
    "for @xmath356 with @xmath377 , similar to and the definitions above , we have [ inequ3 ] _ _ g|()|__g|_l , g()|+__g|_l , g^*()| .",
    "similarly , we can find @xmath363 and @xmath369 such that @xmath378 guarantees that @xmath379 with probability @xmath153 for all @xmath377 .",
    "then we have @xmath380 due to the positive measures assigned on arbitrary nonempty sets by the @xmath381-dimensional multivariate gaussian distribution : @xmath382 , where @xmath383 .",
    "[ klnbr ] consider our observed data @xmath384 where @xmath385 for some constant @xmath386 .",
    "define @xmath387 ,      \\quad v_i(\\bbeta_0 , \\bbeta ) = var_{f_{i , \\bbeta_0 } } [ d_i(\\bbeta_0 , \\bbeta)].\\ ] ] if we a assign an independent tmgp prior for each dimension of @xmath388 , i.e. , @xmath389 then we have that @xmath390 such that @xmath391 @xmath392    it is trivial to have that @xmath393,\\ ] ] then since @xmath394=\\bx\\bbeta(\\bs_i ) , var_{f_{i , \\bbeta_0}}[\\by]=\\sigma^2\\bm i_m $ ] , @xmath395 @xmath396 now consider @xmath397 and let @xmath398 . since the priors for @xmath399 are independent and @xmath400 due to theorem , @xmath401 .    for all @xmath402 , @xmath403 and similarly @xmath404",
    ". then @xmath405 and @xmath406 for all @xmath402 .",
    "define the set of functions @xmath407,\\",
    "1\\leq \\|\\alpha\\|_1 \\leq \\rho \\right\\},\\ ] ] as our sieve construction .",
    "[ covering ] if @xmath114 , the @xmath408-covering number under the sup - norm for @xmath409 satisfies @xmath410 for some finite constant @xmath178 .",
    "define @xmath411 for all @xmath412 .",
    "theorem 2.7.1 of @xcite implies that @xmath413 for some constants @xmath414 .",
    "then by the definition of @xmath409 , we have that @xmath415 where @xmath416 .    [ seivemr ] consider the tmgp prior for @xmath58 with kernel function satisfying condition ( k1)(k2 ) , then @xmath417 for some constant @xmath418 .",
    "the construction of the tmgp prior implies that @xmath419 where @xmath420 for all @xmath412 . by applying theorem 5 of @xcite",
    ", we have that @xmath421 for some @xmath422 , given that @xmath108 has continuous partial derivatives of order @xmath423 on the compact set @xmath12 .",
    "then we have that @xmath424 where @xmath425 due to the fact that @xmath426 for all @xmath427 and @xmath428 .",
    "now we define @xmath429^\\top : \\beta_k(\\bs)\\in \\mp_n , k=1, ... ,p\\}$ ] here and below",
    ". then we can easily get that [ sievecover ]",
    "n ( , * p*_n , _ ) < \\{cpn^^-d},and if assign tmgp priors independently for all elements in @xmath126 then [ sievesize ] ( * pp*_n^c)dp\\{-bn}.      [ vecbound ] consider @xmath430 , a standard linear model with sample size @xmath32 where @xmath431 $ ] ; @xmath123 is an @xmath432 design matrix satisfying assumption ( x1 ) .",
    "consider the test function @xmath433 for testing @xmath434 where @xmath435 and @xmath436 ; @xmath437 is the ordinary least square estimator .",
    "then for @xmath438 , we have that @xmath439\\leq \\exp\\{-\\omega_m mp\\ } , \\quad e_{p_1}[1-\\phi ] \\leq \\exp\\{-\\omega_m mp\\},\\ ] ] for some @xmath440 depending on @xmath32 , where @xmath441 and @xmath442 represents the probability distributions under @xmath443 and @xmath444 .",
    "note that for @xmath445 , under @xmath446 , @xmath447 , then we have that e_p_0[]=p_0(-_0_2 ^ 2 > ) p_0(_p^2>)\\{-(-)mp } , where the last inequality is simply due to the f act that @xmath448 by letting @xmath449 .",
    "similarly , @xmath450 & = & p_1\\left(\\|\\hat{\\bbeta}-\\bbeta^0\\|_2\\leq\\frac{\\varepsilon\\sqrt p}{2}\\right)\\nonumber\\\\      & \\leq & p_1\\left(\\left|\\|\\hat{\\bbeta}-\\bbeta^1\\|_2 - \\|\\bbeta^0-\\bbeta^1\\|_2\\right | \\leq\\frac{\\varepsilon\\sqrt p}{2}\\right)\\nonumber\\\\      & \\leq &   p_1\\left(\\|\\hat{\\bbeta}-\\bbeta^1\\|_2 \\geq -\\frac{\\varepsilon \\sqrt p}{2 } +   \\|\\bbeta^0-\\bbeta^1\\|_2 \\right)\\nonumber \\\\      & \\leq & p_1\\left(\\|\\hat{\\bbeta}-\\bbeta^1\\|_2 \\geq \\frac{\\varepsilon \\sqrt p}{2 }   \\right)\\nonumber\\\\      & \\leq & \\exp\\left\\{-\\left(\\frac{\\varepsilon^2 d_\\min } { 16\\sigma^2}-\\frac{\\log 2}{2m}\\right)mp\\right\\}.      \\end{aligned}\\ ] ] define @xmath451 here and below .",
    "notice that @xmath438 is equivalent to @xmath440 , we complete the proof .",
    "[ matrixbound ] we consider @xmath452 locations @xmath453 and define @xmath454^\\top$ ] ( @xmath455 and @xmath456 can be defined accordingly ) .",
    "suppose that we have observed the data @xmath457^\\top$ ] generated from the svcm , i.e. @xmath458 . consider testing @xmath459 where @xmath460 for all @xmath461 .",
    "define @xmath462 with @xmath463 .",
    "then for the test function @xmath464 , we have that @xmath465\\leq   \\exp\\{-cn_0\\},\\quad   e_{p_1}[1-\\tilde\\phi]\\leq \\exp\\{-cn_0\\}\\ ] ]    by the results from lemma [ vecbound ] , @xmath466\\leq e^{-\\omega_m mp}$ ] and @xmath467\\leq e^{-\\omega_m mp}$ ] for all @xmath461 .",
    "then [ tp1]e_p_0 [ ] p_0(_i=1^n_0 _ i - _ i=1^n_0e_p_0 [ _ i ] > -n_0 e^-_m mp ) ,    [ tp2]e_p_1[1- ] = p_1(_i=1^n_0 ( 1-_i))p_1(_i=1^n_0 ( 1-_i)- _ i=1^n_0 e[1-_i]-n_0 e^-_m mp ) . by the hoeffding inequality @xcite , the right hand side of both and are bounded by @xmath468 when @xmath469",
    ". that is , @xmath470\\leq   \\exp\\{-cn_0\\},\\   e_{p_1}[1-\\tilde\\phi]\\leq \\exp\\{-cn_0\\ } $ ] where @xmath471 .",
    "[ point ] for two functions @xmath472 , if @xmath473 , we have that @xmath474 where @xmath475 is a constant .",
    "that is , the set @xmath476 has @xmath477 elements .",
    "let @xmath478 , then @xmath479 where @xmath480 ; @xmath481 and @xmath482 are finite constants due to absolute continuity .",
    "thus @xmath483 by letting @xmath484 .",
    "[ matrixfuncbound ] there exists a test @xmath485 for testing @xmath486 against @xmath487 where @xmath488 in our proposed svcm , such that @xmath489\\leq \\exp\\{-cn\\ } , \\quad e_{p_1}[1-\\phi_{\\bbeta^1 , \\bbeta^0}]\\leq \\exp\\{-cn\\},\\ ] ] for some constant @xmath178 with @xmath441 and @xmath442 corresponding to the probability distributions under @xmath443 and @xmath444 .    for two vector - valued functions @xmath490^\\top , t=0,1 $ ] , if @xmath488 , we must have at least one @xmath491 , such that @xmath492 , then due to lemma [ point ] , we can find @xmath477 elements in @xmath493 such that @xmath494 . without loss of generality , we denote these points as @xmath453 .",
    "then for all @xmath495 , we have that @xmath496 .",
    "now define the set @xmath497 . then @xmath498 .",
    "define the test function @xmath499 where @xmath500 .",
    "then by lemma [ matrixbound ] ( replacing @xmath408 by @xmath501 ) we have @xmath489\\leq \\exp\\{-c_0n_0\\},\\quad e_{p_1}[\\phi_{\\bbeta^1 , \\bbeta^0}]\\leq \\exp\\{-c_0n_0\\},\\ ] ] where @xmath502 is a constant .",
    "since @xmath503 for a positive constant @xmath504 , we have that @xmath505\\leq \\exp\\{-cn\\}$ ] and @xmath506\\leq \\exp\\{-cn\\}$ ] .",
    "[ matrixfuncboundall ] there exists a test @xmath507 for testing @xmath486 against @xmath508 in our proposed svcm , such that @xmath509\\leq \\exp\\{-d_0n\\ } , \\quad e_{p_1}[1-\\psi]\\leq \\exp\\{-d_1n\\},\\ ] ] for some constant @xmath510 with @xmath441 and @xmath442 corresponding to the probability distributions under @xmath443 and @xmath444 .",
    "let @xmath511 be the covering number of @xmath512 by @xmath501-balls under the supreme norm .",
    "then for all @xmath513 , we can find @xmath514 such that @xmath515 , which implies that @xmath516 for all @xmath517 . following the notations and results in lemma [ matrixfuncbound ] with regard to @xmath501",
    ", we have that the tests @xmath518 all satisfy that @xmath519\\leq \\exp\\{-d_1 n\\}$ ] and @xmath520\\leq \\exp\\{-d_1 n\\}$ ] for some constant @xmath521 .",
    "now for the test function @xmath522 which only depend on the set @xmath523 instead of specific @xmath126 in the alternative hypothesis , @xmath509\\leq \\sum_{j=1}e_{{\\bbeta^j}}[\\phi_{\\bbeta^j , \\bbeta^0}]\\leq \\mathcal{n}\\exp\\{-d_1",
    "n\\}<\\exp\\{cp n^{\\frac{d}{2\\rho}}\\varepsilon^{-d}-d_1 n\\}\\leq\\exp\\{-d_0n\\},\\ ] ] for some constant @xmath524 due to and the fact that @xmath525 . at the same time @xmath526\\leq e_{{\\bbeta^1}}[1-\\phi_{\\bbeta^1 , \\bbeta^0}]\\leq   \\exp\\{-d_1 n\\},\\ ] ] which complete our proof .    now based on lemma [ klnbr ] , equation and lemma [ matrixfuncboundall ] , theorem [ poscons ] follows from a direct application of theorem a.1 . of @xcite .",
    "we list the details about our mcmc algorithm here .",
    "denote by @xmath527 the density function of @xmath528 .",
    "we normally fix @xmath529 in the inverse - gamma priors and fix @xmath174 for the local gps .",
    "* updating @xmath530 : given the block structures of @xmath531 , we update @xmath532 separately with @xmath533 m - h steps . specifically , the full conditional @xmath534 $ ] is proportional to @xmath535 , \\sigma^2\\right)\\right]\\phi   \\left(\\bm\\tbeta_k^g ; \\bm{\\varphi}_g\\bm u_k , \\theta^2 k_g \\right),\\ ] ] where @xmath536 $ ] .",
    "we adopt a metropolis - hasting ( m - h ) algorithm to update @xmath537 by first generating a proposal , @xmath538 with a zero mean gaussian fluctuation @xmath539",
    ". then we set @xmath540 with probability : @xmath541 .",
    "* updating @xmath119 : draw @xmath119 from its full conditional @xmath542 $ ] which is @xmath543 where @xmath544 and @xmath545 \\right)^2.$ ] * updating @xmath546 : we sequentially update @xmath547 with m - h algorithms . specifically , for @xmath176 , the full conditional @xmath548 $ ] is @xmath549 , \\sigma^2\\right)\\right]\\pi(\\lambda_k),\\ ] ] where @xmath550 is the uniform empirical bayes prior for @xmath176 defined in the previous section .",
    "the proposal for @xmath176 is generate from zero mean gaussian fluctuations as @xmath551 , which will be accepted with probability : @xmath552 . *",
    "updating @xmath553 : we sequentially update @xmath554 by drawing from their full conditionals @xmath555 $ ] .",
    "specifically , we update @xmath256 by drawing from @xmath556 where @xmath557 and @xmath558 , with @xmath559 . *",
    "updating @xmath560 : we sequentially update @xmath561 by drawing from their full conditionals @xmath562 $ ] .",
    "specifically , we update @xmath142 by drawing from @xmath563 where @xmath564 and @xmath565 * updating the spatial range parameter @xmath293 within the se kernel : this parameter can be updated by discretization .",
    "specifically , within a reasonable range of @xmath293 , we can calculate and store the dictionaries of @xmath566 and @xmath567 , the kernel expansion results , with regard to each discrete values of @xmath293 on a grid basis .",
    "then we can update @xmath293 based on grid search within each mcmc iteration ."
  ],
  "abstract_text": [
    "<S> motivated by the needs of selecting important features for massive neuroimaging data , we propose a spatially varying coefficient model ( svcms ) with sparsity and piecewise smoothness imposed on the coefficient functions . a new class of nonparametric priors is developed based on thresholded multiscale gaussian processes ( tmgp ) . </S>",
    "<S> we show that the tmgp has a large support on a space of sparse and piecewise smooth functions , leading to posterior consistency in coefficient function estimation and feature selection . </S>",
    "<S> also , we develop a method for prior specifications of thresholding parameters in tmgps . </S>",
    "<S> efficient posterior computation algorithms are developed by adopting a kernel convolution approach , where a modified square exponential kernel is chosen taking the advantage that the analytical form of the eigen decomposition is available . </S>",
    "<S> based on simulation studies , we demonstrate that our methods can achieve better performance in estimating the spatially varying coefficient . </S>",
    "<S> also , the proposed model has been applied to an analysis of resting state functional magnetic resonance imaging ( rs - fmri ) data from the autism brain imaging data exchange ( abide ) study , it provides biologically meaningful results </S>",
    "<S> .    thresholded multiscale gaussian processes ; bayesian feature selection ; spatially varying coefficient models ; human brain mapping ; markov chain monte carlo </S>"
  ]
}