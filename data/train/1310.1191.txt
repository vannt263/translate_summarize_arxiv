{
  "article_text": [
    "in recent years graphics processors ( gpus ) have gained widespread acceptance as an architecture useful for scientific computing . in many application domains their use brings manyfold increase in performance @xcite .",
    "most often gpus are used for computational kernels , the most computationally intensive parts of applications .    in the finite element method ( fem )",
    "domain , the first cited case of using gpus is @xcite where finite elements are applied in interactive visualisation .",
    "other examples include implementation for gpu clusters of higher order fem approximations in earthquake modelling and wave propagation problems @xcite or gpu implementations of some variants of discontinuous galerkin approximation @xcite .",
    "the finite element solution process can be divided into two parts : creation of the matrix for the system of linear equations , based on a suitable weak statement of the approximated problem and the solution of the system of equations ( or some update of the vector of global degrees of freedom , based on the created matrix  or several matrices like e.g. for certain time stepping schemes  and the right hand side vector ) .",
    "the two parts can be implemented as different software components .",
    "the second component , the solver of linear equations , whose implementation can often neglect numerical and computational details associated with finite element approximation , is more frequently investigated in the context of high performance computing and especially gpu acceleration ( see e.g. @xcite ) . sometimes the main stress is put on computational kernels of linear solvers , particularly linear algebra operations , that are properly optimized @xcite .    as a justification for such an approach",
    ", one can use the fact that quite often the time required for the solution of the system of linear equations strongly dominates the time for the whole solution process .",
    "this always happens in situations where weak statements employed are simple , degree of approximation is low and , moreover , the system of linear equations is ill - conditioned or non - definite , causing iterative solvers to converge slowly or enforcing the use of direct solvers .",
    "however for complex weak formulations and high orders of approximation the time for creation of system of linear equations can be higher than the time for its solution .",
    "the most time consuming part of the system creation is numerical integration of terms from the weak statement . because of that",
    ", optimization of numerical integration routines has been for many years the subject of investigations in the higher order and spectral approximation communities @xcite .    numerical integration in finite element codes",
    "is used to create entries for element stiffness matrices that are further assembled into the global stiffness matrix , the matrix for the associated system of linear equations .",
    "again this two processes can be investigated together or treated separately .",
    "the problem of combined integration and assembly for particular applications ported to gpus has been described e.g. in @xcite for nonlinear elasticity and in @xcite for electromagnetics .",
    "an extensive study presented in @xcite concerns 3d discontinuous galerkin approximations for hyperbolic problems .",
    "higher order tetrahedral elements are considered , with the special focus on particular operators associated with explicit time stepping mechanism and dg discretization .",
    "the approach presented in @xcite for dg problems follows a generally applicable technique that considers numerical integration and global assembly as steps of evaluation of fem operators @xcite .",
    "this technique is important not only in the context of explicit time stepping methods , but also e.g. for the implementation of iterative solvers of linear equations and the application of boundary conditions from fem weak statements .",
    "this approach has formed a basis for the attempts to create tools for automated generation of finite element codes @xcite .",
    "the continuation of these investigations in the context of gpu computing was recently described in @xcite where different assembly techniques for finite element approximations are considered .",
    "the performance of presented techniques is tested for 2d low order approximations .",
    "opencl and cuda programming environments are compared and portability of opencl kernels between gpus and cpus is examined .    in the similar context ( automated code generation and low order approximations ) the problem of finite element integration is presented in @xcite .",
    "the implementation is tested for 2d and 3d elliptic problems ( laplace and elasticity operators ) and the performance obtained for gpus is reported .",
    "the three mentioned above papers suggest automatic generation of optimised code for each processor architecture , based on some abstract specification of computations , as a solution to an important implementation problem of the portability of software in face of diversity of multi - core architectures . the authors confirm the observations from other application domains @xcite , that also in the context of finite element assembly , even in the case of the same programming model ( e.g. opencl ) employed for different architectures , in order to obtain the best performance , it is necessary to produce separate versions of procedures for each architecture .",
    "thorough investigations of the finite element assembly process on gpus were presented in @xcite . in the article several methods of assembly , that imply also numerical integration techniques , were shown .",
    "the performance of the proposed techniques was tested for scalar problems and non - adaptive 2d meshes .",
    "the approach presented in @xcite was extended in @xcite to 3d problems , however for first order polynomials only .",
    "nevertheless , the techniques presented in the papers can form the basis for various implementation strategies of the assembly process , also in the case where numerical integration is performed separately and different types of approximation are considered .",
    "there may be several reasons for considering numerical integration separately from the global assembly .",
    "first , the solver employed for the solution of the system of linear equations may perform itself the conversion of element matrices to some specific sparse format of the global matrix @xcite .",
    "second , the assembly may be performed by a different hardware component ( such an approach for large scale problems has been adopted e.g. in @xcite ) . and",
    "finally , considering numerical integration independently of the global assembly gives software developers more flexibility in designing the final solution strategy .    as an additional argument one may consider also the relative importance of both operations .",
    "the assembly of an element matrix to the global stiffness matrix involves three memory references and one floating point operation . for higher order approximations that we consider in the paper , computing a single entry in the element matrix may require , as we show in detail later in the paper , hundreds of memory accesses and floating point operations . even considering that for numerical integration the references",
    "can be realized using faster local memories without data races , still the proper implementation of numerical integration can be considered as having its own merits and importance , independent of the global assembly .",
    "when porting computations to graphics processors , one encounters another specific problem  the issue of precision .",
    "some gpus do not support double precision arguments , some perform double precision operations much slower than single precision .",
    "it has been proven in many studies that the solution of linear equations , especially for large scale problems , requires the use of double precision unknowns , because of accumulation of round - off errors . when investigating the implementation of that stage of finite element solution process , the solution might be to select the phase of calculations or particular operations that can be performed in single precision and after the single precison phase perform improvement of results @xcite .    sometimes ,",
    "when the solution process does not require the solution of the system of linear equations , due to the requirements of a particular application , the whole finite element simulation process can be performed in single precision .",
    "this can happen for example in the case of explicit algorithms for time dependent problems @xcite .",
    "even in the case of performing the stage of linear system solution , numerical integration can be performed in single precision .",
    "it forms a part of the whole approximation process and has to satisfy specific requirements concerning accuracy , in order to guarantee the convergence of finite element solutions @xcite . for many problems , due to the approximate character of numerical integration itself ,",
    "performing calculations in single precision does not introduce errors large enough to be comparable to discretization errors @xcite .",
    "in such cases numerical integration can be performed in single precision and the resulting entries to element stiffness matrices or the global stiffness matrix can be promoted to double precision before the solution of the system of equations .",
    "for some problems , e.g. for problems with terms of different orders that scale in a different way , double precision is required also for numerical integration @xcite . however , this can be considered a special case , while general purpose calculations should be performed in single precision , due to shorter execution times and lower memory requirements .",
    "the advantages of single precision computations can be especially pronounced for higher order calculations .",
    "we consider the problem of numerical integration for higher order 3d finite element approximations .",
    "the main feature of the problem that we address is the large variation of required resources , processing time and memory , for different orders of approximation , i.e. different degrees of polynomials employed as finite element shape functions .",
    "we investigate the characteristics of the problem and try to design a portable kernel for different problems and different processor architectures .",
    "hence , we restrict ourselves to opencl programming model .",
    "it allows us to construct kernels for graphics processors supporting the model ( currently nvidia , amd and intel hardware ) , as well as for cpus .",
    "our previous investigations @xcite as well as results reported in other papers ( e.g. @xcite ) show that opencl implementations achieve performance only several percent lower than native cuda model for nvidia gpus .",
    "we situate our research in the context of creating a general purpose finite element framework modfem @xcite , for continuous and discontinuous galerkin approximations .",
    "the code has modular structure in which different software components are responsible for different phases of finite element calculations @xcite .",
    "each component can exist in several variants and final applications for different problems and solution strategies are created using suitable compilation options .",
    "the code has also a layered structure with separate modules responsible for shared memory computations , that form a core layer and that are further extended to distributed memory environments by suitable overlays @xcite , belonging to a different layer .",
    "the code operates on unstructured adaptive meshes with proper load balancing for parallel execution @xcite .",
    "the code has abilities to run on clusters with message passing and is currently ported to different new computer architectures , such as gpus and heterogeneous processors , like cbe @xcite .    in each particular code created by modfem framework",
    "there is a separate approximation module that is responsible for the creation of element stiffness matrices .",
    "the matrices are further transferred to linear equations solvers using a generic interface @xcite .",
    "thanks to the layered structure of the code there is only one numerical integration routine , in the core layer , for both , shared and distributed memory environments .",
    "the interface between numerical integration procedure and the solver of linear equations allows for employing different , direct and iterative , solvers of linear equations , possibly using thin adapters @xcite .",
    "the same integration routine is also used for different types of meshes and problems solved .",
    "this approach proved successful in many application domains @xcite . as a main problem of the current investigations we pose the problem whether it possible to maintain this portability and genericity by creating a single kernel executed on gpus for different problems , meshes and computer architectures .",
    "we consider numerical integration only , leaving the problem of assembly ( and also application of boundary conditions ) to different software and possibly hardware components . in our view",
    "this smaller grain of considered gpu code gives more flexibility in designing solution strategies , where cpu and gpu cores can work together , each group performing the tasks it is most suitable for @xcite . in order to maximize this flexibility of the approach we consider different options for passing the results of calculations .",
    "the algorithms presented in the paper do not prevent the use of different assembly techniques , such as e.g. presented in the discussed above studies devoted to the subject .",
    "we attempt to investigate the possibility of creating a general purpose numerical integration procedure executed on graphics processors that can either replace or complement the cpu integration routine .",
    "we do not attempt to create gpu - only code .",
    "considering relatively small sizes of memory for current accelerators with gpus , in the order of several gbytes , this would limit the sizes of problems that we solve . since we aim at large scale problems we want to use large memories , in the range of hundreds of gbytes , for each shared memory node .",
    "the use of gpus as accelerators for cpus , corresponds also to our distributed memory strategy where we assume two separate levels of decomposition .",
    "gpu calculations fit into shared memory level calculations controlled by cpu code and due to the design philosophy can be directly used in distributed memory calculations , based on cpu code and its message passing overlays .    following the arguments presented above",
    ", we assume that our general purpose finite element numerical integration procedure does not require double precision calculations and we restrict our interest to single precision implementations .",
    "we plan to consider extensions to double precision for particular application domains that would pose such requirements .",
    "the investigations presented in the paper form the continuation of an earlier work . in @xcite we presented numerical integration on gpus for 2d linear elasticity , cuda environment and older generations of gpus .",
    "this work was extended to opencl programming model in @xcite and to 3d laplace operators in @xcite .",
    "we investigate separately numerical integration procedures for cbe processors in @xcite and @xcite .",
    "the paper is organised in the following way :    * section [ problem_formulation ] defines the problem of numerical integration for finite element approximations * section [ programming_model ] describes the programming model that we use and its mapping to selected gpu architectures * section [ parallel_implementation ] contains details of several versions of numerical integration procedures for gpus that we developed * section [ computational_tests ] presents results of tests performed to assess the performance of the code * section [ conclusions ] contains final remarks .",
    "in the current section we define the problem of numerical integration for which we will further design gpu kernels . we restrict ourselves to defining the notation that we use and computational aspects of the problem . for more information on numerical aspects of integration",
    "we refer to the works presented in the introduction and for the whole context of higher order finite element approximation to any of the excellent textbooks on the subject ( e.g. @xcite , @xcite ) .",
    "3d finite element numerical integration and assembly consist of a loop over elements and faces and possibly some other mesh entities in order to create entries to the global stiffness matrix and the global right hand side vector .",
    "the creation can involve different operations ",
    "integration over elements , integration over faces and other forms of application of boundary conditions , application of other constraints , etc .",
    "the most time consuming part , especially for higher orders of approximation , is the calculation of element integrals , and following the discussion presented in the introduction , we restrict our attention to this process .    for numerical integration",
    "we use quadratures with the order determined by the order of approximation and the characteristics of the problem solved .",
    "integration is always performed on a reference element , following the suitable change of integration domain from a real element in physical space to the reference element . within a 3d reference element",
    "quadrature points have coordinates @xmath0 : @xmath1[i_s];\\ ; \\ ; i_q = 1 , 2 , ... , n_q ; \\ ;   i_s = 1 , 2 , 3;\\ ] ] and weights @xmath2 @xmath3 , i_q = 1 , 2 , ... , n_q\\ ] ] with @xmath4 denoting the number of quadrature points .",
    "computed integrals correspond to different terms in the weak statement of the problem considered .",
    "the problem dependent contribution consist in defining a set of coefficients for numerical integration .",
    "there is a different coefficient for each combination of indices , that we denote by @xmath5 and @xmath6 , corresponding to different spatial derivatives for test and trial functions respectively , including terms with functions itself , that we associate with @xmath7 and @xmath8 .",
    "moreover , for vector problems , the same approximation may be used for different vector components ( different unknowns in the solved system of pdes ) and hence for each combination of indices @xmath5 and @xmath6 there may be a small matrix of coefficients with the dimension @xmath9 equal to the number of equations in the solved system of pdes .",
    "in such a case the array of coefficients may be defined as : @xmath10[j_{e}][i_d][j_d];\\ ; \\ ;   i_{e},j_{e } = 1 , 2 , ... , n_{e } ; \\ ; i_d , j_d = 0,1,2,3 ; \\;\\ ] ]    in the most general , non - linear or quasi - linear case there may be different values of coefficients at each integration point .",
    "hence for the generic numerical integration algorithm we have to consider an array of coefficients of the form : @xmath11[i_{e}][j_{e}][i_d][j_d];\\ ; \\ ;   i_q = 1 , 2 , ... , n_q ; i_{e},j_{e } = 1 , 2 , ... , n_{e } ; i_d , j_d = 0,1,2,3\\ ] ]    as it was stated above , the integration of terms from the finite element weak statement is performed using the change of variables , from a real element to a reference element , of one of several possible types ( e.g. tetrahedron , prism , cube , to name the most popular ) .",
    "hence the derivatives with respect to physical coordinates , that appear in the weak statement , have to be computed by the chain rule , using derivatives of trial and test functions with respect to reference coordinates .",
    "these calculations involve the jacobian matrix of the transformation from the real element to the reference element .",
    "the matrix is usually obtained by inverting the matrix of its inverse transformation , the transformation from the reference to the real element .",
    "this last transformation can be easily obtained from the description of geometry of real elements .",
    "the jacobian matrix of the transformation from the reference to the real element is also used for computing the volume element in integrals , and later in the paper when the notion of the jacobian matrix is used it denotes this matrix .    the transformation from the reference to the real element",
    "is performed using the representation of the geometry of the real element .",
    "different options are possible here , with the simplest of defining linear or multi - linear elements , whose geometry is determined by the position of their vertices .",
    "more complex cases include popular isoparametric elements , where the geometry is specified using polynomials of the same order as the solution @xcite and recently introduced isogeometric analysis , where elements are geometrically represented using spline approximations @xcite .",
    "element stiffness matrices are computed for finite element approximations to trial and test functions , represented as linear combinations of finite element basis functions , that in turn are constructed using element shape functions .",
    "the number of shape functions for an element , @xmath12 ( equal to the number of local degrees of freedom for the element ) is related to the order of approximation and possible particular choices of approximation . in order to present concisely the numerical integration problem we denote shape functions and their derivatives by a single array @xmath13[i_{dof}];\\ ; \\ ;   i_d = 0,1,2,3 ; \\ ; i_{dof } = 1 , 2 , ... , n_{\\mathrm{sh}}\\ ] ] where for the first index , its value 0 refers to shape functions and the values 1,2,3 refer to derivatives with respect to local , reference element coordinates , @xmath14 , and the second index corresponds to different degrees of freedom .    in order to compute integrals we use the values of shape functions and their derivatives at all integration points : @xmath15[i_d][i_{dof } ] ; \\ ; \\ ; i_q = 1 , 2 , ... , n_q ; \\ ; i_d = 0,1,2,3 ; \\ ; i_{dof } = 1 , 2 , ... , n_{\\mathrm{sh}};\\ ] ]    these values are the same for all real elements of a given approximation order . in calculations of terms from the weak statement",
    "we use the values of shape functions and their derivatives with respect to physical coordinates .",
    "these values will be denoted by : @xmath16[i_d][i_{dof}];\\ ; \\ ; i_q = 1 , 2 , ... , n_q ; \\ ; i_d = 0,1,2,3;\\ ;   i_{dof } = 1 , 2 , ... , n_{\\mathrm{sh}};\\ ] ]    the derivatives of shape functions with respect to physical coordinates are different for each element , since they are computed using the entries of the jacobian matrix of the transformation from the real element to the reference element , that are different for each element . the jacobian matrix of the transformation from the real element to the reference element is also used for computing derivatives of the solution at previous non - linear iterations and/or previous time steps .",
    "this derivatives ( and values of the solution itself ) are used in non - linear and time dependent problems to compute problem dependent coefficients @xmath17 .    the finite element numerical integration problem for a single element can be defined in the following way :    given a set of data defining the geometry of an element , a set of degrees of freedom corresponding to solutions at previous non - linear iterations and/or previous time steps and a set of data specifying problem dependent input to the integration procedure create an element stiffness matrix @xmath18[j_{e}][i_{dof}][j_{dof}];\\ ; \\ ;   i_{e},j_{e } = 1 , 2 , ... , n_{e};\\ ;   i_{dof},j_{dof } = 1 , 2 , ... , n_{\\mathrm{sh}};\\ ] ] corresponding to the finite element formulation of the problem solved .",
    "read problem dependent coefficients , @xmath17 read geometry data for element possibly read  old ",
    "element degrees of freedom from previous iterations / time steps initialize element stiffness matrix , @xmath19 prepare quadrature data , @xmath0 and @xmath2 read values of shape functions and their derivatives with respect to local element coordinates , @xmath20 $ ] read or calculate jacobian matrix , its determinant ( * det * ) and its inverse calculate derivatives of shape functions with respect to physical coordinates , @xmath21 $ ] based on @xmath22 $ ] and  old  degrees of freedom calculate coefficients at quadrature point , @xmath23 $ ] @xmath24[j_{e}][i_{dof}][j_{dof}]+=$ ] @xmath25*det*@xmath26 \\times { \\mbox{\\boldmath $ c$}}^q[i_{e}][j_{e}][i_d][j_d][i_q ] \\times$ ] @xmath27[i_{dof}][i_q ] \\times { \\mbox{\\boldmath $ \\psi$}}^q[j_d][j_{dof}][i_q]$ ]    we conclude the definition of the problem by providing algorithm [ num_int_simple ] , a generic procedure that calculates the entries to the element stiffness matrix .",
    "the procedure corresponds to mathematical expressions involved in numerical integration , indicating necessary summations .    from the mathematical point of view",
    ", the order of performing the three outermost loops of algorithm [ num_int_simple ] is irrelevant ( but implies some changes in details of the algorithm ) . in our implementation",
    "we follow the common practice from classical finite element codes , corresponding directly to algorithm [ num_int_simple ] , where the loop over integration points is the outermost loop .",
    "thanks to this we do not have to store in some fast memory the values of all shape functions at all integration points , instead we need only quickly accessible storage for the values of shape functions and their derivatives at a single integration point .",
    "the other option , with precomputed values of all shape functions at all integration points and the loops over degrees of freedom ( shape functions ) as the outermost loops , is also possible , especially for low order 2d approximations @xcite .    in practice ,",
    "calculations are often performed in a way that is different that specified by algorithm [ num_int_simple ] .",
    "the four innermost loops are small , with the ranges for @xmath5 and @xmath6 equal 4 and usually less or equal 5 for @xmath28 ( 3 for elasticity , 4 for incompressible navier - stokes , 5 for compressible navier - stokes ) .",
    "this suggests to manually unroll all the loops .",
    "moreover arrays @xmath17 are usually sparse and substantial savings can be obtained , when instead of performing the four innermost loops from algorithm [ num_int_simple ] , suitable , optimized calculations are performed for a block of entries of the matrix @xmath19 associated with a single pair @xmath29 .",
    "this leads to algorithm [ num_int_real ] , that we further implement for graphics processors .",
    "read problem dependent coefficients , @xmath17 read geometry data for element possibly read  old ",
    "element degrees of freedom from previous iterations / time steps initialize element stiffness matrix , @xmath19 prepare quadrature data , @xmath0 and @xmath2 read or calculate values of shape functions and their derivatives with respect to local element coordinates , @xmath20 $ ] read or calculate jacobian matrix , its determinant ( * det * ) and its inverse calculate derivatives of shape functions with respect to physical coordinates , @xmath21 $ ] based on @xmath22 $ ] and  old  degrees of freedom calculate coefficients at quadrature point , @xmath23 $ ] update a block of entries of @xmath19 associated with a pair @xmath29 in a manner implied by the structure of non - zero entries of the array of coefficients @xmath17 , multiplying each non - zero entry of @xmath30 associated with a pair @xmath31 by @xmath25*det*@xmath32 \\times   { \\mbox{\\boldmath $ \\psi$}}^q[i_d][i_{dof}][i_q ] \\times { \\mbox{\\boldmath $ \\psi$}}^q[j_d][j_{dof}][i_q]$ ] and performing suitable summations over ranges of @xmath5 and @xmath6    to assess the particular character of the problem of numerical integration for 3d approximations with different orders of approximation @xmath33 , we present in table [ tab_1 ] the sizes of the arrays involved in calculations for an example 3d reference element  the prism with shape functions being products of polynomials from a set of complete polynomials of a given order for triangular bases and 1d polynomials associated with vertical direction . as an example quadrature , the most popular in finite element codes , gaussian quadrature is selected .",
    "as can be seen from the table , the number of times the innermost calculations are performed for @xmath34 equals 27,869,184 .",
    "that is one of reasons why for higher orders of approximation special techniques for integration are designed @xcite .",
    "the order from which it becomes advantageous to switch to different techniques that presented in the current paper depends on the characteristics of the problem statement and the computing environment .",
    "the value of 7 that we choose for our study is to certain extent arbitrary ( in some cases it can be profitable to switch to different techniques of integration even from orders in the range 4 - 5 ) .",
    "nevertheless , for the rest of the paper we consider for our higher order finite element approximations the range of polynomial degrees @xmath33 from 2 to 7 .",
    ".parameters determining the computational characteristics of 3d finite element numerical integration  the number of shape functions and the number of gaussian integration points for the standard prismatic element and different degrees of approximating polynomials [ cols= \" < , > , > , > , > , > , > , > \" , ]        time for : & p=2 & p=3 & p=4 & p=5 & p=6 & p=7 + & 0.06 & 0.08 & 0.1 & 0.7 & 2.9 & 15 + & 2.00 & 5.81 & 7.4 & 14.5 & 24.7 & 46 + & 11.40 & 60.20 & 179.5 & 481.8 & 1144.0 & 2457 + & 0.07 & 0.11 & 0.2 & 0.7 & 3.6 & 11 + & 0.40 & 1.06 & 1.9 & 4.4 & 11.3 & 22 + & 11.18 & 60.12 & 165.2 & 478.8 & 1137.0 & 2439 + & & & & & & + & 0.44 & 6.27 & 29.22 & 163.0 & 614.8 & 1981 + & 2.10 & 27.16 & 124.0 & 679.3 & 3010 & 9894 + & 208 & 230 & 235 & 240 & 204 & 200 + & 24.61 & 147.6 & 469.1 & 1641 & 5298 & 14817 + & & & & & & + & 0.44 & 6.30 & 29.37 & 163.9 & 617.9 & 1990 + & 1.21 & 17.80 & 80.07 & 439.9 & 2117 & 7203 + & 366 & 354 & 366 & 372 & 291 & 276 + & 25.99 & 149.1 & 442.0 & 1433 & 4458 & 12213 + & & & & & & + & 0.43 & 6.23 & 31.42 & 158.9 & 590.5 & 1868 + & 1.91 & 23.06 & 114.2 & 477.4 & 2318 & 7357 + & 228 & 270 & 274 & 274 & 254 & 253 + & 24.41 & 143.5 & 459.4 & 1439 & 4605 & 12280 + & & & & & & + & 0.44 & 6.25 & 33.47 & 159.3 & 592.0 & 1873 + & 1.30 & 19.05 & 94.31 & 490.9 & 1932 & 6199 + & 338 & 328 & 334 & 324 & 306 & 302 + & 26.07 & 150.4 & 456.2 & 1484 & 4273 & 11208 +     time for : & p=2 & p=3 & p=4 & p=5 & p=6 & p=7 + & 0.03 & 0.04 & 0.2 & 1.58 & 4.8 & 22 + & 1.20 & 3.21 & 5.4 & 11.18 & 17.1 & 52 + & 7.50 & 37.12 & 131.5 & 390.4 & 902.9 & 1995 + & 0.10 & 0.41 & 1.7 & 6.2 & 13.6 & 31 + & 0.58 & 1.74 & 4.1 & 16.9 & 27.9 & 60 + & 2.41 & 12.19 & 42.5 & 162.8 & 318.4 & 639 + & & & & & & + & 0.43 & 5.56 & 30.05 & 168.6 & 659.0 & 2206 + & 3.13 & 53.73 & 325.3 & 1779 & 9496 & 34568 + & 139 & 103 & 92 & 94 & 69 & 63 + & 10.77 & 91.32 & 458.9 & 2177 & 10418 & 36618",
    "+ & & & & & & + & 0.44 & 5.62 & 30.36 & 170.2 & 665.1 & 2226 + & 4.06 & 34.61 & 190.8 & 985 & 4684 & 17094 + & 109 & 162 & 159 & 172 & 141 & 130 + & 13.35 & 76.68 & 332.0 & 1404 & 5632 & 19202 + & & & & & & + & 0.43 & 7.02 & 31.57 & 157.8 & 602.5 & 1906 + & 3.90 & 63.74 & 297.5 & 1477 & 6428 & 21359 + & 111 & 110 & 106 & 106 & 93 & 89 + & 11.54 & 101.3 & 431.0 & 1876 & 7350 & 23408 + & & & & & & + & 0.44 & 7.05 & 24.59 & 158.3 & 604.6 & 1912 + & 5.33 & 67.90 & 305.9 & 1519 & 6152 & 20742 + & 82 & 103 & 103 & 104 & 98 & 92 + & 14.62 & 109.9 & 447.1 & 1937 & 7101 & 22850 +    * each presented table contains timing results for subsequent stages of the whole procedure of numerical integration .",
    "this reflects the possibility of arranging the stages in different ways .",
    "the initial stage is important when the first group of elements is sent for integration on gpu .",
    "then , for next groups it is possible not to allocate the gpu memory and send only input data for processed elements . also the stage of copying back",
    "the computed stiffness matrices can be eliminated in certain solution strategies , as we have mentioned already . *",
    "the timing results are presented for a single finite element of a given order .",
    "these results were obtained by running the kernels for a large number of elements ( specified for our test runs in tables [ tab_3 ] and [ tab_4 ] ) and dividing the times of performing different stages of execution by the number of elements .",
    "it should be made clear that the results depend on the total number of elements , since the times for card initialization and data transfers to and from gpu memory does not scale linearly with the number of elements .",
    "* the nonlinear dependence mentioned above can appear for low numbers of elements .",
    "for sufficiently high numbers , the linear dependence should emerge and the results presented in tables [ tab_5][tab_7 ] should be applicable to different problem sizes by simple scaling . the linear scaling should be observed especially for higher orders of approximation where gpu calculations , that scales linearly , take more time than card initialization and data transfers .",
    "the fact of linear scaling of the numerical integration algorithm with respect to the number of elements for sufficiently high numbers of elements has been confirmed experimentally in several studies @xcite . *",
    "as it was mentioned already , for cpu cores and gpu compute units we parallelize the loop over elements .",
    "if the processor resources are sufficient , than , thanks to the embarrassingly parallel character of the loop over elements in the numerical integrations algorithm , the performance of calculations should scale linearly ( even in the strong sense ) with the number of cores and compute units .",
    "we observed such relations for different gpus with the nvidia tesla architecture when performing computational experiments reported in @xcite .",
    "* it should be noted , that both types of scaling , with respect to the number of elements and with respect to the number of cores / compute units , are much more complex when assembly process is taken into account . in such a case also the dependence of performance results on a particular problem solved ( due to the different properties of the global stiffness matrix ) can be observed @xcite . in the case of numerical integration alone , the particular problem solved is irrelevant to the performance obtained .",
    "* execution times were always measured on the host side .",
    "we introduced synchronisation procedures for opencl events in the host code and measured elapsed times for each stage of calculations .",
    "the reason for this was to explicitly indicate the overhead associated with the subsequent stages . in recent modifications to gpu programming models",
    "it is possible to overlap different stages of execution for different kernel invocations and reduce the overheads @xcite . *",
    "measuring elapsed time means adopting a user perspective .",
    "we do it for particular stages of calculations and also for the total execution time of kernels .",
    "the times measured on the host side were always longer than the times reported by execution environment profilers .",
    "hence the performance that we report is the performance observed by the user , which is lower than the actual performance of the hardware .",
    "* times for gpu initialization were relatively constant for all orders of approximation since they were mainly associated with creation of opencl memory objects in gpu memory and the total size of memory objects for each order was similar , due to the assumption that by changing the number of elements per kernel the whole available gpu memory is utilized . however , for each order of approximation the times per element are different , which is implied by the changing size of the stiffness matrix for a single element . * for computing performance in gflops , only the time for kernel execution ( measured on the host side )",
    "was taken into account . * to obtain the total execution time , we measured , in an external procedure responsible in our code for global matrix assembly , the time spent in the host code and the integration kernels .",
    "the main results from tables [ tab_5 ] , [ tab_6 ] and [ tab_7 ] are illustrated in figures [ times ] and [ performance ]                      from 2 to 7.,title=\"fig : \" ]      from 2 to 7.,title=\"fig : \" ]   from 2 to 7.,title=\"fig : \" ]      from 2 to 7.,title=\"fig : \" ]   from 2 to 7.,title=\"fig : \" ]      from 2 to 7.,title=\"fig : \" ]      there are several observations that can be made based on data in tables [ tab_5 ] , [ tab_6 ] and [ tab_7 ] :    observation 1 .",
    ": :    the algorithm of numerical integration for higher order finite    elements has the potential for high performance execution on massively    multi - core architectures .",
    "the performance obtained , above 200 gflops ,    and for some orders of approximation and some variants of the    algorithm above 350 gflops for gtx580 and above 60 gflops with several    results above 150 gflops for hd5870 , can be considered high ,    especially for nvidia where it is in the range of 12%-23.5% of the    peak single precision floating point performance .",
    "observation 2 .",
    ": :    the performance of gtx580 gpu is much higher than that of hd5870 ,    despite the fact that radeon hd5870 theoretical peak performance is    almost twice as big as that of geforce gtx580 .",
    "this can be explained    to certain degree by higher overhead due to driver software for radeon    @xcite and the fact that basic execution units of hd5870 are vector    units , the fact that we do not exploit in our kernels .",
    "observation 3 .",
    ": :    for gpus , the times for global memory initialization and data    transfers from the host memory are comparable to the time of kernel    execution ( for lower values of @xmath33 being even several    times larger ) .",
    "this , once again , here for finite element numerical    integration algorithm , confirms the fact that slow pcie connection is    an obstacle on a way to get higher performance for general purpose    codes executed on gpus . for the algorithm of numerical integration ,    with increasing order of approximation the ratio of operations to    memory transfers grows and hence the influence of low pcie performance    diminishes .",
    "observation 4 .",
    ": :    the times of kernel execution , i.e. the times for numerical    integration calculations are always much lower for gpus than for the    reference cpu , however , the total execution times , including memory    transfers are better for gpus only in the case of higher orders of    approximation .",
    "observation 5 .",
    ": :    there is a large difference between the performance of the gpu as    perceived by an external user and as exhibited during actual    calculations .",
    "one reason for this , data transfer times , was already    mentioned .",
    "the second is the fact , that , in order to ensure proper    mapping of calculations onto the hardware , the gpu had to perform more    operations than the cpu .",
    "observation 6 .",
    ": :    there is no single kernel being the best for all situations ( different    orders of approximation , different hardware ) , although the _ reg_nojac _    variant is the fastest in most of cases .",
    "different kernels exhibit    similar performance , with the best results obtained for medium orders    of approximation .",
    "observation 7 .",
    ": :    the option of sending to gpus , not only reference element shape    functions , but also jacobian terms for all real processed elements and    all integration points ( _ nojac _ versions ) turned out to be more    efficient in most cases than the option of calculating the values on    gpus ( _ jac _ variants ) . despite the fact that _ nojac _ versions require    much longer times for transferring data to gpu memory than _ jac _    variants , this time remains much shorter than gpu initialization time    and time for transfer of output data .",
    "observation 8 .",
    ": :    _ shm _ variants are usually slower than _ reg _ versions , however we    believe it is worth having them both , since for different gpu    architectures this situation may change .",
    "numerical integration for higher order 3d finite element approximations is a complex problem due to the large variation in required processor and memory resources .",
    "thanks to a suitable parametrization of the designed opencl code for integration and a proper management of code execution by the created host side procedures , we have obtained the code that is portable across different gpu architectures and different orders of approximation , in the range of moderate degrees of shape function polynomials , from 2 to 7 . in the computational experiments reported in the paper we run the gpu kernels and the host managing procedures for all presented cases without changing a single line in the source code .",
    "we obtained , for nvidia geforce gtx580 and amd radeon hd5870 graphics processors , the performance of calculations always above 200 gflops and 60 gflops , respectively .",
    "this , especially for hd5870 , falls short to theoretical peak performance of the hardware , however still for many cases reported , the results can be considered satisfactory as for general purpose complex scientific calculations . in particular , for the case of gtx580 and one of the variants of numerical integration ( _ shm_nojac _ ) the performance for all orders of approximation exceeded 300 gflops ( 19% of theoretical peek ) and for another variant ( _ reg_nojac _ ) it reached for three orders ( @xmath33=2 , 4 and 5 ) more than 365 gflops , that is 23% of the theoretical maximum .",
    "the main factor limiting the practical advantages of gpu calculations is the slow pcie connection between the gpu and the host computer . despite much higher gpu performance of calculations , the overall execution times for gpus and standard processors are comparable , because of long times devoted by gpus to memory initialization and data transfers .    taking this into account",
    ", it can be concluded that in the context of numerical integration for higher order finite elements , gpus should not be considered as a replacement for cpus , with all calculations off - loaded to gpus . in particular , when gpus are calculating domain integrals , cpus can do some other useful work , such as performing integration of boundary terms , integration of separate sets of elements or assembly of already created element stiffness matrices . in such scenarios ,",
    "gpus can form valuable accelerators increasing substantially the overall performance of finite element codes .",
    "r.  strzodka , m.  doggett , a.  kolb , scientific computation for simulations on programmable graphics hardware , simulation modelling practice and theory , special issue : programmable graphics hardware 13  ( 8) ( 2005 ) 667680 .",
    "d.  komatitsch , d.  micha , g.  erlebacher , porting a high - order finite - element earthquake modeling application to nvidia graphics cards using cuda , journal of parallel and distributed computing 69  ( 5 ) ( 2009 ) 451460 .",
    "d.  komatitsch , g.  erlebacher , d.  gddeke , d.  micha , high - order finite - element seismic wave propagation modeling with mpi on a large gpu cluster , journal of computational physics 229  ( 20 ) ( 2010 ) 7692  7714 .",
    "d.  gddeke , h.  wobker , r.  strzodka , j.  mohd - yusof , p.  mccormick , s.  turek , co  processor acceleration of an unmodified parallel solid mechanics code with feastgpu , international journal of computational science and engineering 4  ( 4 ) ( 2009 ) 254269 .",
    "d.  gddeke , r.  strzodka , j.  mohd - yusof , p.  mccormick , s.  h. buijssen , m.  grajewski , s.  turek , exploring weak scalability for fem calculations on a gpu - enhanced cluster , parallel computing 33  ( 10 - 11 ) ( 2007 ) 685699 .",
    "v.  volkov , j.  w. demmel , benchmarking gpus to tune dense linear algebra , in : proceedings of the 2008 acm / ieee conference on supercomputing , sc 08 , ieee press , piscataway , nj , usa , 2008 , pp . 31:131:11 .",
    "l.  demkowicz , j.  kurtz , d.  pardo , m.  paszynski , w.  rachowicz , a.  zdunek , computing with _ hp_-adaptive finite elements , vol .",
    "2 : frontiers three dimensional elliptic and maxwell problems with applications , chapman & hall / crc , 2007 .    p.",
    "e.  j. vos , s.  j. sherwin , r.  m. kirby , from h to p efficiently : implementing finite and spectral / hp element methods to achieve optimal performance for low- and high - order discretisations , j. comput .",
    "229 ( 2010 ) 51615181 .",
    "a.  dziekonski , p.  sypek , a.  lamecki , m.  mrozowski , http://dx.doi.org/10.1002/nme.4452[generation of large finite - element matrices on multiple graphics processors ] , international journal for numerical methods in engineering ( 2012 )    c.  cecka , a.  j. lew , e.  darve , http://dx.doi.org/10.1002/nme.2989[assembly of finite element methods on graphics processors ] , international journal for numerical methods in engineering 85  ( 5 ) ( 2011 ) 640669 .    c.  cecka , a.  j. lew , e.  darve , application of assembly of finite element methods on graphics processors for real - time elastodynamics , in : w.  mei w.  hwu ( ed . ) , gpu computing gems",
    ". jade edition , morgan kaufmann , 2011 , pp . 187205 .",
    "g.  r. markall , a.  slemmer , d.  a. ham , p.  h.  j. kelly , c.  d. cantwell , s.  j. sherwin , http://dx.doi.org/10.1002/fld.3648[finite element assembly strategies on multi - core and many - core architectures ] , international journal for numerical methods in fluids 71  ( 1 ) ( 2013 ) 8097 .",
    "d.  gddeke , r.  strzodka , s.  turek , performance and accuracy of hardware - oriented native- , emulated- and mixed - precision solvers in fem simulations , international journal of parallel , emergent and distributed systems 22  ( 4 ) ( 2007 ) 221256 .",
    "m.  baboulin , a.  buttari , j.  dongarra , j.  kurzak , j.  langou , j.  langou , p.  luszczek , s.  tomov , accelerating scientific computations with mixed precision algorithms , computer physics communications 180  ( 12 ) ( 2009 ) 2526  2533 .",
    "s.  rul , h.  vandierendonck , j.  dhaene , k.  de  bosschere , an experimental study on performance portability of opencl kernels , in : application accelerators in high performance computing , 2010 symposium , papers , knoxville , tn , usa , 2010 , p.",
    "k.  bana , a modular design for parallel adaptive finite element computational kernels , in : m.  bubak , g.  van albada , p.  sloot , j.  dongarra ( eds . ) , computational science  iccs 2004 , 4th international conference , krakw , poland , june 2004 , proceedings , part ii , vol .",
    "3037 of lecture notes in computer science , springer , 2004 , pp . 155162 .",
    "k.  bana , a model for parallel adaptive finite element software , in : r.  kornhuber , r.  hoppe , j.  priaux , o.  pironneau , o.widlund , j.  xu ( eds . ) , domain decomposition methods in science and engineering , vol .",
    "40 of lecture notes in computational science and engineering , springer , 2004 , pp . 159166 .",
    "k.  bana , agent architecture for mesh based simulation systems , in : v.  alexandrov , g.  van albada , p.  sloot , j.  dongarra ( eds . ) , computational science  iccs 2006 , 6th international conference , reading , uk , may 28 - 31 , 2006 , proceedings , part iii , vol .",
    "3993 of lecture notes in computer science , springer , 2006 , pp . 743750 .",
    "k.  bana , parallelization of large scale adaptive finite element computations , in : r.  wyrzykowski , j.  dongarra , m.  paprzycki , j.  waniewski ( eds . ) , parallel processing and applied mathematics , proceedings of vth international conference , ppam 2003 , czstochowa , poland , 2003 , vol .",
    "3019 of lecture notes in computer science , springer , 2004 , pp . 431438 .",
    "f.  kruel , k.  bana , finite element numerical integration on powerxcell processors , in : ppam09 : proceedings of the 8th international conference on parallel processing and applied mathematics , springer - verlag , berlin , heidelberg , 2010 , pp .",
    "517524 .                          p.",
    "paszewski , p.  macio , k.  bana , finite element numerical integration on gpus , in : ppam09 : proceedings of the 8th international conference on parallel processing and applied mathematics , springer - verlag , berlin , heidelberg , 2010 , pp .",
    "411420 .              p.  macio , k.  bana , testing tesla architecture for scientific computing : the performance of matrix - vector product , in : proceedings of international multiconference on computer science and information technology , wisa , poland , october , 2008 , polish information processing society , 2008 , pp",
    ". 285291 ."
  ],
  "abstract_text": [
    "<S> the paper considers the problem of implementation on graphics processors of numerical integration routines for higher order finite element approximations . </S>",
    "<S> the design of suitable gpu kernels is investigated in the context of general purpose integration procedures , as well as particular example applications . </S>",
    "<S> the most important characteristic of the problem investigated is the large variation of required processor and memory resources associated with different degrees of approximating polynomials . </S>",
    "<S> the questions that we try to answer are whether it is possible to design a single integration kernel for different gpus and different orders of approximation and what performance can be expected in such a case .    </S>",
    "<S> finite element method , higher order approximation , numerical integration , graphics processors , gpu , opencl </S>"
  ]
}