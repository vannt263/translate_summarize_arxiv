{
  "article_text": [
    "here are important applications in practice where one is confronted with the problem of distinguishing between different hypotheses and , depending on the decision , to proceed and estimate a set of relevant parameters .",
    "characteristic examples are : detection and estimation of objects from images @xcite ; retrospective changepoint detection , where one desires to detect a change in statistics but also estimate the time of the change @xcite ; defect detection from radiographies , where in addition to detecting presence of defects one would also like to find their position and shape @xcite ; finally mimo radar where we are interested in detecting the presence of a target and also estimate several target characteristics as position , speed , etc .",
    "all these applications clearly demand for detection and estimation strategies that address the two subproblems in a _",
    "jointly _ optimum manner .    in the literature ,",
    "there are basically two ( mainly ad - hoc ) approaches that deal with combined problems .",
    "the first consists in treating the two subproblems separately and applying in each case the corresponding optimum technique .",
    "for instance one can use the neyman - pearson optimum test for detection and the optimum bayesian estimator for parameter estimation to solve the combined problem . as we will see in our analysis , and it is usually the case in combined problems , treating each part separately with the optimum scheme , does not necessarily result in optimum overall performance .",
    "the second methodology consists in using the generalized likelihood ratio test ( glrt ) which detects and estimates at the same time with the parameter estimation part relying on the maximum likelihood estimator . both approaches",
    "lack versatility and are not capable of emphasizing each subproblem according to the needs of the corresponding application .",
    "surprisingly , one can find _ very _ limited literature that deals with optimum solutions of the joint detection and estimation problem .",
    "a purely bayesian technique is reported in @xcite , whereas a combination of bayesian and neyman - pearson - like methodology is developed in @xcite . specifically in @xcite",
    "the error probabilities under the two hypotheses , used in the classical neyman - pearson approach , are replaced by estimation costs . mimicking the neyman - pearson formulation and constraining the estimation cost under the nominal hypothesis while optimizing the corresponding cost under the alternative , gives rise to a number of interesting combined tests that can be used in place of glrt .    here",
    "we will build upon the methodology of @xcite but we are going to formulate the combined problem in a more natural way .",
    "in particular we will define a performance measure for the estimation part which we are going to optimize assuring , in parallel , the satisfactory performance of the detection part by imposing suitable constraints on the decision error probabilities .",
    "this idea will lead to two novel combined tests that have no equivalent in @xcite,@xcite .",
    "we would like to point out that the theory in @xcite,@xcite as well as the one we are going to develop in our work , makes sense only when _ both _ subproblems constitute desired goals in our setup , that is , when we are interested in detecting _ and _ estimating",
    ". these results can not provide optimum schemes for the case where one is interested _ only in detection _ and is forced to use parameter estimation due to presence of nuisance parameters .",
    "our article is organized as follows : in sectionii we define the joint detection and estimation problem and propose two different optimal solutions . as a quick example , our results",
    "are then applied to the problem of retrospective change detection . in sectioniii",
    "we make a thorough presentation of the mimo radar problem under a joint detection and estimation formulation and use the results of the previous section in order to solve this problem optimally .",
    "specifically we develop closed form expressions for all quantities that are needed to apply our theory and perform simulations to evaluate the performance of the optimum schemes , addressing also computational issues .",
    "finally , in sectioniv we have our concluding remarks .",
    "let us define the problem of interest .",
    "motivated by most applications mentioned in the introduction , we limit ourselves to the binary hypothesis case with parameters present only under the alternative hypothesis .",
    "suppose we are given an observation signal @xmath0 for which we have the following two hypotheses    @xmath1 + @xmath2 ,    where @xmath3 are known pdfs .",
    "specifically , we assume that under @xmath4 we know the pdf of @xmath0 completely , whereas under @xmath5 the pdf of @xmath0 contains a collection of random parameters @xmath6 for which we have available some prior pdf @xmath7 .",
    "the goal is to develop a mechanism that distinguishes between @xmath8 and , furthermore , every time it decides in favor of @xmath5 it provides an estimate @xmath9 for @xmath6 .",
    "our combined detection / estimation scheme is therefore comprised of a randomized test @xmath10 with @xmath11 denoting the randomization probability for deciding in favor of @xmath12 ; and a function @xmath13 that provides the necessary parameter estimates . clearly @xmath14 and @xmath15 .",
    "let us recall , very briefly , the optimum detection and estimation theory when the two subproblems are considered separately .",
    "_ neyman - pearson hypothesis testing _ : fix a level @xmath16 ; if @xmath17 denotes our decision then we are interested in selecting a test ( namely the randomization probabilities @xmath11 ) so that the detection probability @xmath18 is maximized subject to the false alarm constraint @xmath19 .",
    "equivalently , the previous maximization can be replaced by the minimization of the probability of miss @xmath20 .",
    "the optimum detection scheme is the well celebrated likelihood ratio test , which takes the following form for our specific setup @xmath21 in other words we decide @xmath5 whenever the likelihood ratio @xmath22 exceeds the threshold @xmath23 ; @xmath4 whenever it falls below and randomize with a probability @xmath24 when the likelihood ratio is equal to the threshold .",
    "the threshold @xmath23 and the probability @xmath24 are selected to satisfy the false alarm constraint with equality .",
    "the randomization probabilities @xmath25 corresponding to the neyman - pearson test are given by @xmath26 where @xmath27 denotes the index function of the set @xmath28 .    _ bayesian parameter estimation _ : suppose that we know _ with certainty _ that the observations @xmath0 come from hypothesis @xmath5 , then we are interested in providing an estimate @xmath13 for the parameters @xmath6 .",
    "we measure the quality of our estimate with the help of a cost function @xmath29 .",
    "we would like to select the optimum estimator in order to minimize the average cost @xmath30 $ ] , where expectation is with respect to @xmath0 and @xmath6 .    from ( * ? ? ?",
    "* page 142 ) we have that the optimum bayesian estimator is the following minimizer ( provided it exists ) @xmath31 where @xmath32 is the posterior cost function @xmath33=\\frac{\\int c(u,\\theta)f_1(x|\\theta)\\pi(\\theta)\\,d\\theta}{\\int f_1(x|\\theta)\\pi(\\theta)\\,d\\theta }   = \\frac{\\int c(u,\\theta)f_1(x|\\theta)\\pi(\\theta)\\,d\\theta}{f_1(x ) } ,   \\hfill \\label{b_est2}\\end{gathered}\\ ] ] and expectation , as we can see from the last equality , is with respect to @xmath6 for given @xmath0 .",
    "finally we denote the optimum posterior cost as @xmath34 , that is , @xmath35 this quantity will play a very important role in the development of our theory as it constitutes a genuine quality index for the estimate @xmath36 .",
    "let us now consider the combined problem .",
    "we recall that the hypothesis testing part distinguishes between @xmath4 and @xmath5 .",
    "as we have seen , the neyman - pearson approach provides the best possible detection structure for controlling and optimizing the corresponding decision error probabilities .",
    "however with a decision mechanism that focuses on the decision errors , we can not necessarily guarantee efficiency for the estimation part .",
    "consequently , we understand , that the detection part can not be treated independently from the estimation part .",
    "following this rationale , we propose two possible approaches involving single and two - step schemes that differ in the number of decision mechanisms they incorporate and the way they combine the notion of _ reliable estimate _ with the detection subproblem .",
    "let us begin our analysis by introducing a proper performance measure for the estimation subproblem .",
    "following the bayesian approach we assume the existence of the cost function @xmath29 .",
    "computing the average cost that will play the role of our performance measure , is not as straightforward as in the pure estimation problem and requires some consideration .",
    "note that an estimate @xmath13 is provided only when we decide in favor of @xmath5 . on the other hand averaging of @xmath37",
    "makes sense only under the alternative hypothesis @xmath5 since under the nominal @xmath4 there is no true parameter @xmath6 .",
    "consequently we propose the following performance criterion @xmath38   = \\frac{{{\\sf e}}_1[c(\\hat{\\theta}(x),\\theta){\\mathbbm{1}_{\\{{{\\sf d}}={{\\sf h}}_1\\}}}]}{{{\\sf p}}_1({{\\sf d}}={{\\sf h}}_1 ) } ,   \\hfill \\label{cost}\\end{gathered}\\ ] ] where expectation is with respect to @xmath0 and @xmath6 .",
    "we realize that with our criterion , the estimation performance depends not only on the estimator but also on the detection mechanism . as we can see , we compute the average cost over the event @xmath39 , which is the only case an estimate is available .",
    "one would immediately argue that the measure in does not consider in any sense the decision errors , that is , the quality of the detector .",
    "however , these errors can be efficiently controlled through suitable constraints .",
    "specifically we can impose the familiar false alarm constraint @xmath19 but _ also _ a constraint on the probability of miss @xmath40 where @xmath41 .",
    "with these two constraints we have complete control over the decision mechanism and therefore , now , it makes sense to attempt to minimize the conditional average estimation cost @xmath42 over the decision rule @xmath10 and the estimator @xmath13 .",
    "note that the two constraints guarantee satisfactory performance for the detection part and , by minimizing the criterion , we can enjoy optimum performance in the estimation part .",
    "let us carry out the desired optimization gradually .",
    "we first fix the decision rule @xmath10 and optimize @xmath42 with respect to the estimator @xmath13 .",
    "we have the following lemma that provides the solution to this problem .    [ lem:1 ]",
    "let @xmath43 be a scalar function , then the following functional of @xmath13 @xmath44 is minimized when @xmath13 is the optimum bayesian estimator @xmath36 defined in and .",
    "the proof is simple .",
    "we can write @xmath45 where for the last two equalities we used .",
    "lemma[lem:1 ] is a very interesting result because it demonstrates an extended optimality property for the classical bayesian estimator . in particular by selecting @xmath46 we conclude that @xmath36 continues to be optimum even if estimation is dictated by a decision mechanism and not performed over all data @xmath0 , as is the usual practice with bayesian estimation .",
    "consequently , we can now fix our estimator to the bayesian estimator @xmath36 with corresponding optimized performance measure equal to @xmath47 it is clear that our intention is to further minimize @xmath48 over the class of detectors that satisfy the two error constraints . before addressing this problem however",
    ", we need to make some remarks .",
    "_ remark 1 : _ one can argue that by constraining the false alarm probability to @xmath49 and by using the neyman - pearson optimum test for detection and then the bayesian estimator for estimation ( in other words , treating the two subproblems separately ) has definite optimality properties , since this combination optimizes both the detection and the estimation part . this is indeed true , however with such a scheme the main emphasis is on the detection part . for estimation , after optimizing the corresponding performance ( by using @xmath36 ) , we have no further control .",
    "in fact if the resulting estimation performance is not satisfactory , there is no room for further improvement .",
    "this weakness is clearly circumvented by the proposed formulation which offers , as we discuss next , the additional flexibility to trade detection power for estimation efficiency , according to the needs of the designer .",
    "_ remark 2 : _ we recall that in our setup we have the two constraints @xmath19 and @xmath40 . by fixing the false alarm probability to @xmath49 , the probability of miss is minimized by the neyman - pearson test ; call this minimum value @xmath50 . since no test , with false alarm probability not exceeding @xmath49 ,",
    "can have a probability of miss that goes below @xmath50 , this suggests that in our constraint on the probability of miss , @xmath51 must be selected to satisfy @xmath52 .",
    "we are thus reducing , in a controlled manner , the detection power as compared to the neyman - pearson test ( since we allow more misses ) aiming in improving the effectiveness of our estimation .",
    "we have the following theorem that provides the optimum scheme .    [ th:1 ]",
    "consider the two constraints @xmath19 and @xmath40 , where @xmath53 and @xmath54 with @xmath50 denoting the probability of miss of the neyman - pearson test .",
    "let @xmath55 be the solution of the equation and @xmath56 , when considered as random variables , have no atoms under both hypotheses ( the corresponding pdfs have no delta functions ) .",
    "this avoids the need for randomization every time a test statistic hits a threshold . ]",
    "@xmath57 where @xmath34 is defined in",
    ". then the optimum combined scheme is comprised of the bayesian estimator @xmath36 defined in , , for the estimation part while the decision rule that optimizes the average conditional cost @xmath48 in under the two error constraints is given by @xmath58&{\\underset{{{\\sf h}}_0}{\\overset{{{\\sf h}}_1}{\\gtreqqless}}}\\gamma,~~\\text{if}~\\alpha<{{\\sf p}}_0\\left(\\lambda_o\\ge{\\mathcal{c}}_o(x)\\right ) , \\label{test1b}\\end{aligned}\\ ] ] where in @xmath59 are selected so that the two error probability constraints are satisfied with equality .",
    "the proof is presented in the appendix .    from and",
    "we deduce that the optimum detector takes into account the estimation part through @xmath34 which constitutes a quality index for the estimate @xmath36 .",
    "if this index is sufficiently large then , in both cases , the test decides in favor of @xmath4 .",
    "in particular , in , this decision may occur even if the classical likelihood ratio exceeds the threshold @xmath23 , suggesting decision in favor of @xmath5 .",
    "sumarizing , our first optimum combined test consist in applying or to decide between the two hypotheses and every time we make a decision in favor of @xmath5 we use @xmath36 defined in to provide the optimum parameter estimate .      in the previous setup",
    "our decision was between @xmath4 and @xmath5 and we were sacrificing detection power to improve estimation .",
    "however , in most applications , giving up part of the detection capacity may be regarded as undesirable .",
    "for example in mimo radar it is still helpful to detect a target even if we can not reliably estimate its parameters .",
    "it is possible to _ preserve _ the detection power and at the same time _ ameliorate _",
    "the estimation performance if we follow a slightly different approach that involves _ two - step mechanisms_. specifically we propose the use of an initial detection strategy that distinguishes between @xmath4 and @xmath5 ; whenever we decide in favor of @xmath5 then , at a second step , we compute the estimate @xmath13 and employ a _ second test _ that decides whether the estimate is _ reliable _ or _ unreliable _ , denoted as @xmath60 and @xmath61 respectively .",
    "consequently we propose to make _ three _ different decisions @xmath62 and @xmath61 with the union of the last two corresponding to hypothesis @xmath5 .",
    "as we can see , we `` trust '' the estimate @xmath13 only when we decide in favor of @xmath60 , but we have detection even if we discard the estimate as unreliable , that is , we decide @xmath61 .    for the first test we use our familiar randomization probabilities @xmath10 while for the second we employ a new pair @xmath63 .",
    "the latter functions are the randomization probabilities needed to decide between reliable / unreliable estimation _ given _ that the first test decided in favor of @xmath5 .",
    "therefore we have @xmath64 and @xmath65 . for every combination of the four randomization probabilities we define , similarly to the previous subsection , the corresponding average conditional cost for the estimator @xmath13 , namely @xmath66=\\frac{\\int \\delta_1(x)q_{1r}(x){\\mathcal{c}}(\\hat{\\theta}(x)|x)f_1(x)dx}{\\int \\delta_1(x)q_{1r}(x)f_1(x)dx}.   \\hfill\\end{gathered}\\ ] ] as we can see , we now condition on the event @xmath67 since this is the only case when the estimate @xmath13 is accepted .",
    "we also note that , for given @xmath0 , the probability to decide in favor of @xmath60 is @xmath68 because we must decide in favor of @xmath5 in the first step ( with probability @xmath69 ) and for @xmath60 in the second ( with probability @xmath70 ) .    in the first step we would like to adopt the best possible detector to select between @xmath4 and @xmath5 .",
    "we follow the classical neyman - pearson approach and impose the false alarm probability constraint @xmath19 while we minimize the probability of miss @xmath20 .",
    "this leads to the neyman - pearson test defined in with corresponding randomization probabilities @xmath25 given in .",
    "having identified the first , let us proceed to the second step of our detection / estimation mechanism that involves parameter estimation and a second test that labels the estimate as reliable / unreliable .",
    "consider the average conditional cost @xmath71 , assume @xmath72 fixed , then from lemma[lem:1 ] and by selecting @xmath73 , we conclude that this criterion is minimized when @xmath74 , that is , again with the optimum bayes estimator defined in and . call",
    "@xmath75 the corresponding performance .",
    "it is then clear that we would like to minimize even further this criterion by selecting properly our second decision mechanism which is expressed with the help of the randomization probabilities @xmath63 .",
    "note however that , in addition to this minimization , we are also interested in generating as many `` reliable estimates '' as possible when applying the second test .",
    "these two goals are clearly conflicting , therefore we adopt a neyman - pearson - like approach in order to come up with an optimum scheme . in other words",
    "we constrain one quantity and optimize the other .    to find a suitable constraint , because @xmath76 , the probability @xmath77 of deciding in favor of @xmath60 ( reliable estimate ) satisfies @xmath78 in other words this probability is upper bounded by the detection probability @xmath79 of the neyman - pearson test where , we recall",
    ", @xmath50 denotes the corresponding probability of miss .",
    "this inequality reveals the obvious fact that , only a portion of our initial decisions in favor of @xmath5 provide reliable estimates in the second step .",
    "actually it is this part we intend to control by imposing the following inequality @xmath80 with @xmath81 .",
    "the constraint in expresses our desire that _ at least a fraction of @xmath82 of the initial decisions in favor of @xmath5 must provide reliable estimates_. subject to this constraint the goal is to obtain the best possible estimation performance , that is , minimize the performance measure @xmath83 .",
    "the solution to this optimization problem is given in the next lemma .",
    "[ lem:2 ] let @xmath81 , then the test that minimizes the average conditional cost @xmath83 defined in subject to the constraint in , is given by @xmath84 where @xmath85 is selected to satisfy with equality and @xmath34 is defined in .",
    "the proof follows a methodology which is very similar to the one used in the proof of theorem[th:1 ] .",
    "since it presents no particular difficulties , it is omitted .    as in the previous subsection",
    ", @xmath34 constitutes a quality index for the estimate @xmath36 . with lemma[lem:2 ] we end up with the very plausible decision rule of accepting @xmath36 as reliable whenever this index is below some threshold @xmath85 while the estimate is discarded as unreliable whenever the same quantity exceeds the threshold .    summarizing our second detection / estimation scheme",
    ": we first use the neyman - pearson test to decide between @xmath8 .",
    "whenever we decide in favor of @xmath5 we compute the estimate @xmath36 from and its corresponding quality index @xmath34 from ; then we use the test in to characterize the estimate as reliable / unreliable .",
    "if we call @xmath86 the conditional likelihood ratio , then all quantities entering in the two tests can be expressed with the help of @xmath87 and the prior probability @xmath7 .",
    "we start with the likelihood ratio which is part of both tests and observe that we can write it as @xmath88 from we can see that the posterior cost @xmath32 can be computed as @xmath89 suggesting that the bayes estimator @xmath90 and the corresponding optimum posterior cost @xmath91 can be expressed with the help of the conditional likelihood ratio as well .",
    "let us now examine the special case where for the cost function we adopt the squared error @xmath92 which leads to the mse criterion . from (",
    "* page 143 ) , we know that the optimum estimator @xmath36 is the conditional mean @xmath93 $ ] .",
    "if we also assume the prior @xmath7 to be uniform over some known set @xmath94 with finite lebesgue measure @xmath95 then @xmath96 we can see that @xmath95 does not enter in the computation of the estimate @xmath36 and its quality index @xmath34 .",
    "although @xmath95 does appear in the likelihood ratio @xmath22 , it is easy to verify that , in both tests , it can be transferred to the right hand side and absorbed by the corresponding threshold @xmath97 .",
    "we therefore conclude that no explicit knowledge of this quantity is necessary .",
    "finally , we note that in the mse criterion , @xmath34 is the conditional variance of @xmath36 which clearly constitutes a very reasonable quality index for the corresponding estimate .",
    "we have now completed the development of our theory that addresses the joint detection and estimation problem . to demonstrate the power and originality of our analysis",
    ", first we apply our results to the example of retrospective change detection and then in section[sec : model ] , at a much greater extent , we use them to solve the mimo radar problem .",
    "retrospective change detection is the problem where within a given set of data @xmath98 $ ] there is a possible time instant @xmath99 where the data switch statistics from some nominal pdf @xmath100 before @xmath99 to an alternative pdf @xmath101 after @xmath99 .",
    "we consider @xmath99 as the _ last _ time instant under the nominal regime . given @xmath0",
    "we are interested in detecting the change but also estimating the time @xmath99 the change took place .",
    "we should point out that retrospective change detection methodology is largely dominated by _ sequential _",
    "techniques @xcite .",
    "however , this constitutes a serious misusage of these methods since , in the retrospective formulation , the data are all available at once , whereas in the sequential setup the data become available sequentially .",
    "this means that by adopting sequential tests for the solution of the retrospective problem results in an inefficient utilization of the existing information .",
    "let us now apply our previous theory .",
    "note that for @xmath102 , the two pdfs can be decomposed as @xmath103 we first need to define the data pdf under the two hypotheses .",
    "under @xmath4 we are under the nominal model therefore , clearly , @xmath104 . under @xmath5 and with a change occurring at @xmath99 ,",
    "we define the pdf @xmath105 as follows @xmath106 in other words , from the decompositions in , we combine the first part of the nominal pdf with the second part of the alternative . with this changepoint model ,",
    "the data before the change affect the data after the change through the conditional pdf .",
    "this is the most common model used in change detection theory @xcite .",
    "note that @xmath107 means that all the data are under the nominal regime ( i.e.  there is no change ) whereas @xmath108 that all the data are under the alternative regime .",
    "therefore , under @xmath5 we have @xmath109 with some prior @xmath110 .",
    "let us compute the quantities that are necessary to apply our tests .",
    "using we can write for the conditional likelihood ratio @xmath111 suggesting that the likelihood ratio , from , takes the form @xmath112 .",
    "consider now the estimation problem .",
    "we propose the following cost function @xmath113 , penalizing incorrect estimates by a unit cost .",
    "the average cost is clearly the probability to estimate incorrectly . observing that @xmath114 , from",
    "we can write @xmath115 consequently the optimum estimator that minimizes @xmath32 over @xmath116 is @xmath117 which is the map estimator ( * ? ? ?",
    "* pages 145 - 150 ) ; while the corresponding optimum posterior cost becomes @xmath118    the classical test that treats the two subproblems separately consists in comparing the likelihood ratio @xmath22 to the threshold @xmath23 in order to distinguish between the two hypotheses and use @xmath119 to estimate the time of change .",
    "glrt on the other hand compares @xmath120 to a threshold with the argument of this maximization providing the estimate for the time of change .",
    "applying our theory to this problem , for the single - step test we use @xmath119 for the estimate of the changetime and either @xmath121 or @xmath122 for the decision .",
    "for the two - step scheme we compare the likelihood ratio @xmath22 to the threshold @xmath23 to decide between the two hypotheses ; use @xmath119 for the changepoint estimate and finally apply @xmath123 to label the estimate as reliable / unreliable . both combined schemes resulting from our theory , are completely original and make efficient use of all available information .",
    "a context where performing joint detection and estimation is of particular interest is in radar systems .",
    "radars are often deployed not only to detect a target but also estimate unknown parameters associated with the target , e.g. , position and velocity .",
    "recent developments in radar systems equip radars with multiple transmit and receive arrays that considerably improve their detection power and estimation accuracy compared with the conventional phased - array radars .    in this section",
    "we examine the merits of the tests developed in the previous section for enhancing the detection and estimation quality by employing multiple - input multiple - output ( mimo ) radar systems with widely - separated antennas  @xcite .",
    "in particular we are interested in the detection of a target , and the estimation of its location every time a target is ruled present .",
    "this is somewhat different from the more conventional approaches in mimo radar systems , e.g. , @xcite and references therein , where the probe space is broken into small subspaces and the radar detects the presence of the target in each of the subspaces separately . in this approach as the location to be probed is given , one is only testing whether a target is present in a certain given subspace @xcite .",
    "this necessitates implementing multiple detection tests in parallel , one for each subspace . in this section ,",
    "we develop detectors and estimators based on the optimality theory discussed in the previous section which are used only once for the entire space .      we consider a mimo radar system with @xmath124 transmit and @xmath125 receive antennas that are _ widely _ separated",
    "( satisfy the conditions in ( * ? ? ?",
    "such spacing among the antennas ensures that the receivers capture uncorrelated reflections from the target . both transmit and receive antennas are located at positions @xmath126 , for @xmath127 , and @xmath128 , for @xmath129 , respectively , known at the receiver .",
    "the @xmath130th transmit antenna emits the waveform with baseband equivalent model given by @xmath131 where @xmath132 is the transmitted energy of a single transmit antenna ( assuming to be the same for all transmitters ) ; @xmath133 and @xmath134 denotes the common duration of all signals @xmath135 .",
    "we aim to detect the presence of an _ extended _ target and when deemed to be present also estimate its position .",
    "the extended target consists of multiple scatterers exhibiting random , independent and isotropic scintillation , each modeled with a complex random variable of zero - mean and unknown distribution .",
    "this corresponds to the classical swerling case i model @xcite extended for multiple - antenna systems @xcite .",
    "the reflectivity factors are assumed to remain constant during a scan and are allowed to change independently from one scan to another .",
    "we define @xmath6 as the location of the gravity center of the target and @xmath136 as the aggregate distance that a probing waveform @xmath135 travels from the @xmath130th transmit antenna to the target and from the target to the @xmath137th receive antenna , i.e. , @xmath138 the time delay the waveform @xmath135 is experiencing by traveling this distance @xmath136 is equal to @xmath139 where @xmath140 is the speed of light .",
    "when the target dimensions are considerably smaller than the distance of the target from the transmit and receive antennas , the distance of the antennas to each scatterer of the target can be well - approximated by their distances from the gravity center of the target .",
    "therefore , the received signal at the @xmath137th receive antenna is the superposition of all emitted waveforms and is given by @xcite @xmath141 where @xmath142 is the path - loss with @xmath143 denoting the path - loss exponent ; @xmath144 the additive white gaussian complex valued noise distributed as denotes the distribution of a complex gaussian random variable with mean @xmath145 where the real and imaginary parts are uncorrelated ( and therefore independent ) gaussian random variables with mean @xmath146 respectively and of variance equal to @xmath147 . ] @xmath148 ; and @xmath149 accounts for the reflectivity effects of the scatterers corresponding to the @xmath130th transmit and the @xmath137th receive antennas",
    ". it can be readily verified that @xmath150 are independent and identically distributed ( i.i.d . ) with distribution @xmath148 @xcite .",
    "we note that we have assumed for the noises @xmath151 and the coefficients @xmath149 that they have variance equal to 1 .",
    "in fact if we use any other values e.g.  @xmath152 and @xmath153 respectively then in the final test these quantities are combined with the transmitted signal power @xmath132 in the form of @xmath154 .",
    "consequently , _ provided _ that in the general case @xmath152 and @xmath153 are known then , without loss of generality , we may assume @xmath155 and let @xmath132 express the final combination .",
    "for @xmath129 define @xmath156\\\\ s_{n}'(t,\\theta)&=\\sqrt{e}\\left[\\frac{s_1(t-\\tau_{1n}(\\theta))}{d^\\eta_{1n}(\\theta ) } , \\dots , \\frac{s_m(t-\\tau_{mn}(\\theta))}{d^\\eta_{mn}(\\theta)}\\right ] , \\end{split}\\end{aligned}\\ ] ] where we recall that @xmath136 and @xmath157 are _ known _ functions of @xmath6 defined in , and @xmath158 denote the transpose and hermitian ( transpose and complex conjugate ) respectively of the matrix @xmath159 . under these definitions we can write @xmath160 let us now formulate the joint detection and estimation problem for the specific signal model we just introduced .      for @xmath161 , we distinguish the following two hypotheses satisfied by the received signals @xmath162 ,    @xmath163 + @xmath164 .",
    "we have written the received signals in a stochastic differential equation form , since the @xmath165 are wiener ( white gaussian noise ) processes . as we can see , when there is no target present the measured signals are pure wiener processes , whereas with the appearance of a target we have the emergence of the nonzero drifts @xmath166 .    for simplicity ,",
    "let us use @xmath167 to denote the signal acquired by the @xmath137th receive antenna during the time - interval @xmath168 $ ] , that is , @xmath169 .",
    "the collection of these @xmath125 signals constitutes the complete set of observations , in other words , @xmath170 plays the role of the observation signal @xmath0 of the previous section .",
    "clearly , our goal is to use @xmath170 in order to decide between the presence or absence of a target and , every time a target is detected , to provide a reliable estimate of its position .",
    "to apply the theory developed in the previous section , according to section[ssec:2.c ] , we need to find the conditional likelihood ratio @xmath171 .",
    "the following theorem provides the required formula .",
    "[ th:2 ] the likelihood ratio @xmath171 of the received signals is given by @xmath172 where @xmath173 @xmath174 denotes the identity matrix of size @xmath175 and @xmath176 the determinant of the matrix @xmath159 .",
    "the proof is presented in the appendix .    a final quantity that is of major interest for the next section is the appropriate definition of snr .",
    "note that , depending on the position of the target , the received signals @xmath177 exhibit different snr levels .",
    "this is due to the path - loss effect , which is particularly severe for distant targets .",
    "we therefore propose to measure the snr by aggregating the signal and noise energies at the receivers but also _ averaging _ these quantities over all possible target positions @xmath178 .",
    "specifically , by adopting the uniform model for @xmath6 , we define @xmath179\\,dt\\right)d\\theta}{\\int_{{{\\mit\\omega}}}\\left(\\sum_{n=1}^n{{\\sf e}}[|\\int_0^tdw_n(t)|^2]\\right)d\\theta }   \\approx\\frac{e}{n t}\\frac{1}{\\mu({{\\mit\\omega}})}\\int_{{{\\mit\\omega}}}\\left(\\sum_{n=1}^n\\sum_{m=1}^m\\frac{1}{d_{mn}^{2\\eta}(\\theta)}\\right)\\,d\\theta ,   \\hfill \\label{eq : snr}\\end{gathered}\\ ] ] where from standard it calculus the expectation in the denominator is equal to @xmath180 . for the approximate equality we overlooked the boundary effects in the numerator , that is , we assumed that @xmath181 for all @xmath157 which , of course , is not true when @xmath6 is close to the boundary of @xmath94 .",
    "if there is no path - loss , that is @xmath182 , then the previous equation reduces to the simple formula @xmath183 .",
    "the transmitted energy @xmath132 will be tuned through these equations in order to deliver the appropriate snr level at the receivers .",
    "we have now developed all necessary formulas that enable us to use the results of sectionii in the mimo radar problem . in the next subsection",
    "we evaluate the joint detection / estimation scheme with monte - carlo simulations that cover various combinations of snr values and number of transmit / receive antennas .",
    "we apply only the two - step test developed in section[sec : test2 ] since , as we briefly argued earlier , it is more well suited for the mimo radar problem .",
    "we consider the two - dimensional analog of the mimo radar problem with two configurations consisting of @xmath184 and @xmath185 antennas , where the @xmath130th transmit and the @xmath137th receive antenna are located at @xmath186'$ ] and @xmath187'$ ] ( expressed in km ) , respectively .",
    "the emitted waveforms are @xmath188 for @xmath189 $ ] where @xmath190sec is the signal duration .",
    "moreover , we select an integration time @xmath191sec .",
    "this integration limit can accommodate delays @xmath157 that do not exceed @xmath180 ( for larger delays we simply measure noise during the interval @xmath168 $ ] ) .",
    "the maximal delay defines a region @xmath94 in space where every point @xmath178 has at least one aggregate distance @xmath136 , defined in , from one transmit and one receive antenna that does not exceed the value @xmath192 km .",
    "actually , the points in space that have an aggregate distance from a pair of transmit / receive antennas not exceeding 150 km lie in the interior of a well defined ellipse .",
    "since we have @xmath193 pairs of transmit / receive antennas , we conclude that @xmath94 is the union of an equal number of such ellipses . by considering that all antennas are roughly positioned at the origin , all ellipses become circles and @xmath94",
    "can be approximated by a disc of approximate radius of 75 km .    as is the usual practice in mimo radar literature , we assume @xmath182 , namely , no path - loss .",
    "this means that we are going to tune our energy parameter @xmath132 through the simplified equation @xmath183 .",
    "we consider snr values -20 , -10 , 0 and 10db .    assuming that the target position @xmath6 is uniformly distributed within @xmath94 and that for the cost function we employ the mse criterion",
    ", we can use the formulas in for the joint detection / estimation scheme . from",
    "and we observe the need for space and time integration .",
    "both integrals will be evaluated numerically . for time",
    "integration we use canonical sampling and consider @xmath194 points @xmath195 within the time - interval @xmath168 $ ] .",
    "for integration in space we form a canonical square grid of points for @xmath6 .",
    "denote with @xmath196 the number of points @xmath197 that lie in the interior of the region @xmath94 .",
    "the two integrals are then approximated by sums .",
    "specifically , the quantities in , for @xmath198 , are approximated by @xmath199 and @xmath200 under @xmath4 ( needed to compute the threshold @xmath23 ) takes the form @xmath201 while for the same quantity under @xmath5 we can write @xmath202 parameter @xmath203 denotes the `` true '' target position selected uniformly within @xmath94 and @xmath204 is one of the @xmath196 grid - points in the interior of the same set .",
    "the coefficients @xmath205 are selected randomly from a gaussian @xmath206 while each @xmath207 is also gaussian @xmath208 . for each run , the quantities @xmath209 and @xmath210 are the same for all @xmath204 . for our simulations",
    "we use @xmath211 time samples @xmath195 and a grid with cells 10km@xmath21210 km that generates 179 points @xmath197 in the interior of @xmath94 .    for the test of section[sec : test2 ] , according to , the likelihood ratio test is implemented as @xmath213 every time a decision is made in favor of @xmath5 we provide the following estimate of @xmath203 @xmath214 with corresponding quality index @xmath215 the estimate @xmath216 is characterized as reliable / unreliable depending on whether @xmath217 is below / exceeds the threshold @xmath85 .",
    "we also consider the glrt where we maximize the likelihood ratio @xmath171 in over @xmath6 and compare it to a threshold .",
    "the threshold is selected so that the corresponding false alarm probability is equal to @xmath49 .",
    "we recall that glrt provides ml estimates for @xmath6 and , as we mentioned , can not trade detection power for estimation .",
    "monte carlo simulations were carried out in order to study the performance of the different tests .",
    "for each snr value , 200,000 simulations were implemented to validate our theoretical developments . in our simulations",
    "we fixed the false alarm probability to @xmath218 .",
    "the ( conditional ) mse was computed as @xmath219 where @xmath175 is the total number of cases where the combined test decided in favor of @xmath60 ( that is , @xmath5 in the first step and @xmath60 in the second ) .",
    ": optimum is solid and glrt is @xmath220 ; configuration @xmath185 : optimum is dashed and glrt is @xmath221 . ]    in fig.[fig:1 ] we depict the mse normalized by the ( approximate ) radius of @xmath94 squared ( @xmath222 ) as a function of the fraction of reliable estimates , i.e.  @xmath223 .",
    "the fraction value is controlled through the threshold @xmath85 .",
    "fraction value equal to 1 in our test corresponds to the performance of the classical approach where detection and estimation are treated separately . for the same value we also present the performance of the glrt .",
    "we observe that for @xmath224db we need to sacrifice more than 50% of our detections ( more accurately in these cases we regard the estimates as unreliable ) to reduce the mse by a factor of 2 . for larger snr values we can have significant ( even enormous ) gains .",
    "for example for @xmath225db by sacrificing 50% of the detections , in the @xmath226 case we gain an order of magnitude in estimation performance while the same gain in the @xmath227 configuration is achieved with only 25% reduction .",
    "we conclude from our simulations that apart the very low snr case of @xmath228db , the @xmath227 antenna configuration is preferable to the @xmath226 since it can return significant performance gains .",
    "finally , we observe that glrt and the classical approach that treats the two subproblems separately have very comparable performance .",
    "we have presented two possible formulations of the joint detection and estimation problem and developed the corresponding optimum solutions .",
    "our approach consists in properly combining the bayesian method for estimation with suitable constraints on the detection part .",
    "the resulting optimum schemes allow for the trade - off between detection power and estimation efficiency , thus emphasizing each subproblem according to needs of the original application .",
    "our theory was then applied to the problems of retrospective change detection and mimo radar . in particular in the second application",
    ", intense simulations demonstrated the possibility to experience significant gains in estimation quality with small sacrifices in detection power .",
    "_ proof of theorem[th:1 ] : _ we are interested in minimizing @xmath48 defined in subject to the two constraints @xmath229 and @xmath230 . we first note that if we have a pair @xmath10 for which the second inequality is strict , then we can find another pair @xmath231 which satisfies the second constraint with equality and has exactly the same estimation performance . indeed",
    "if we select @xmath232 , @xmath233 , then we observe that since we assumed @xmath234 we have @xmath235 , suggesting that @xmath236 is a legitimate probability ( because @xmath69 is multiplied by a factor smaller than 1 to produce @xmath236 ) , consequently the complementary probability @xmath237 is legitimate as well .",
    "the fact that the alternative pair has exactly the same estimation performance , namely @xmath238 , can be verified by direct substitution .    with the previous observation",
    "we can limit our search for the optimum within the class of tests that satisfy the constraint on the probability of miss with equality , that is , @xmath239 .",
    "equivalently we consider only tests that satisfy the equality constraint @xmath240 on the detection probability . under this equality ,",
    "minimizing @xmath48 is equivalent to minimizing the numerator @xmath241 in .    due to the nonnegativity of @xmath34 and our assumption that @xmath34 does not contain any atoms we have that has a unique solution @xmath55 .",
    "suppose that we are in the case where @xmath242 and consider a test @xmath10 that satisfies the equality @xmath240 .",
    "we can then write @xmath243f_1(x)dx\\\\ \\ge\\int{\\mathbbm{1}_{{\\mathcal{a}}}}\\,[{\\mathcal{c}}_o(x)-\\lambda_o]f_1(x)dx\\\\ = \\int{\\mathbbm{1}_{{\\mathcal{a}}}}\\,{\\mathcal{c}}_o(x)f_1(x)dx-\\lambda_o{{\\sf p}}_1({\\mathcal{a}})\\\\ = \\int{\\mathbbm{1}_{{\\mathcal{a}}}}\\,{\\mathcal{c}}_o(x)f_1(x)dx-\\lambda_o(1-\\beta),\\end{gathered}\\ ] ] where @xmath244 . comparing the first and the last term yields @xmath245 , which proves that is the optimum since it minimizes the estimation criterion and satisfies both constraints .",
    "we observe in this case that , for the optimum test , the false alarm constraint can be strict .",
    "consider now the case @xmath246 and let us show that there is a pair @xmath59 for which the test in satisfies both constraints with equality .",
    "we are first going to prove that for any @xmath247 we can find @xmath248 to satisfy the equality constraint for the detection probability , namely @xmath249\\ge \\gamma(\\lambda)\\right)=1-\\beta .",
    "\\label{eq : app1}\\ ] ] call @xmath250[\\lambda-{\\mathcal{c}}_o(x)]\\ge \\gamma)-(1-\\beta)$ ] , fix @xmath251 , then we observe that @xmath252 .",
    "furthermore @xmath253 .",
    "consequently there exists @xmath254 such that is true .",
    "there are two pairs @xmath255 which we can describe explicitly . from the definition of @xmath256",
    "we know that when @xmath257 we have @xmath258 .",
    "consider now @xmath259 and assume that @xmath260 , then @xmath261 is the solution to the equation @xmath262 this is true because the test in , after dividing each side by @xmath85 and letting @xmath259 reduces to the likelihood ratio test with threshold @xmath261 .",
    "since by assumption we have @xmath263 where @xmath50 is the probability of miss of the neyman - pearson test , we conclude that @xmath264 .",
    "this suggests that @xmath265    now we need to show that there exists a value for @xmath85 and the corresponding threshold @xmath254 that satisfy the false alarm constraint with equality , namely @xmath266\\ge \\gamma(\\lambda)\\right)=\\alpha .",
    "\\label{eq : app2}\\ ] ] call @xmath267[\\lambda-{\\mathcal{c}}_o(x)]\\ge \\gamma(\\lambda))-\\alpha$ ] . then , because of our previous analysis , it is easy to verify that @xmath268 has opposite signs for @xmath257 and @xmath259 , meaning that there exists a @xmath251 such that @xmath269 , or that the false alarm constraint is satisfied with equality .    to show that the test in is optimum ,",
    "let @xmath255 be the previous pair and consider any test @xmath10 that satisfies the equality constraint for the detection probability and the inequality constraint for the false alarm .",
    "then we can write @xmath270f_1(x)+\\gamma(\\lambda)f_0(x)\\}dx\\\\ \\ge\\int{\\mathbbm{1}_{{\\mathcal{a}}}}\\,\\{[{\\mathcal{c}}_o(x)-\\lambda]f_1(x)+\\gamma(\\lambda)f_0(x)\\}dx\\\\ = \\int{\\mathbbm{1}_{{\\mathcal{a}}}}\\,{\\mathcal{c}}_o(x)f_1(x)dx-\\lambda(1-\\beta)+\\gamma(\\lambda)\\alpha,\\end{gathered}\\ ] ] where @xmath271\\ge \\gamma(\\lambda)\\}$ ] . again comparing the first and the last term ,",
    "proves optimality of the test in and therefore concludes the proof of theorem[th:1 ] .",
    "_ proof of theorem[th:2 ] : _ due to independence across receivers for the noises @xmath165 and the reflection coefficients @xmath272 we deduce @xmath273 it is thus sufficient to show that @xmath274 since @xmath205 is random , we can first compute @xmath275 by conditioning on the coefficients @xmath205 corresponding to the @xmath137th receiver and then average out @xmath205 . for given @xmath205",
    "the received signal @xmath177 under the two hypotheses differs only in the drift , consequently we can apply girsanov s theorem ( * ? ? ?",
    "* page 191 ) to compute the corresponding likelihood ratio .",
    "we can treat the complex valued wiener process @xmath165 as a two dimensional real valued wiener process , with the real and imaginary part of the complex process constituting the two independent components of the two dimensional process . since the corresponding variances , by assumption , are equal to 0.5 , it is straightforward to show that @xmath276dr_n(t)\\right ) }     = e^{-g_n^h{\\mathbf{q}}_n(\\theta)g_n+2{\\text{re}}(r^h_n(\\theta)g_n ) } ,   \\hfill \\label{th : girsanov}\\end{gathered}\\ ] ] where @xmath277 are defined in    in order to compute @xmath278 from @xmath275 we need to average out @xmath205 .",
    "we recall that the real and imaginary parts of @xmath205 are gaussian uncorrelated ( and thus independent ) vectors , each with mean 0 and covariance matrix equal to @xmath279 . for notational simplicity",
    "we drop in all quantities their dependence on @xmath137 and @xmath6 .",
    "let us also define the following decompositions into real and imaginary parts @xmath280 , @xmath281 , @xmath282 and , finally , denote @xmath283'$ ] , @xmath284'$ ] , @xmath285 $ ] ; then we can write the previous likelihood ratio as follows @xmath286 where we used the fact that @xmath287 , by being hermitian , satisfies @xmath288 and @xmath289",
    ". we can now average out @xmath290 by recalling that @xmath291 . by `` completing the square '' we have @xmath292 where the last integral is equal to 1 since it is the integral of a gaussian pdf with mean @xmath293 and covariance matrix @xmath294 .",
    "from the nonegative definiteness of @xmath287 we have @xmath295 for any complex vector @xmath296 . using the observation that for any real vector @xmath297",
    ", it is true that @xmath298 , as a result of @xmath289 , we can show that @xmath299{\\bar{{\\mathbf{q}}}}[y_r',y_i']'=y^h{\\mathbf{q}}y\\ge0 $ ] where @xmath300 .",
    "hence @xmath301 is nonegative definite as well , implying that @xmath302 is positive definite .",
    "define two square matrices @xmath303 of size @xmath304 as the solution to the following two equations : @xmath305 and @xmath306 ( there always exists a solution due to the positive definiteness of @xmath302 ) , then by direct computation we can verify that @xmath307 $ ] and @xmath308 . with the help of the previous equalities we have @xmath309 .",
    "this proves the correctness of the exponential term in .",
    "what is left to show is that @xmath310 .",
    "since @xmath311 $ ] , if @xmath312 is an eigenvalue of this matrix with corresponding eigenvector @xmath299'$ ] then @xmath312 is a double eigenvalue because by direct computation we can verify that @xmath313'$ ] is a second eigenvector ( orthogonal to the first and thus different ) for the same eigenvalue @xmath312 .",
    "consequently the @xmath314 eigenvalues of @xmath302 are of the form @xmath315 with @xmath316 ( because of the positive definiteness of @xmath302 ) , implying @xmath317",
    ".    we can now verify that if @xmath318'$ ] is an eigenvalue - eigenvector pair of @xmath302 then @xmath319 is an eigenvalue - eigenvector pair of @xmath320 .",
    "this suggests that @xmath321 must also be an eigenvalue - eigenvector pair for the same matrix .",
    "however , we observe that @xmath322 , which means that the two eigenvectors are co - linear and therefore coincide .",
    "consequently for the complex matrix @xmath320 the eigenvalues are the @xmath323 , meaning that the corresponding determinant satisfies @xmath324 .",
    "this proves the desired equality for the two determinants , demonstrates the validity of and concludes the proof of theorem[th:2 ] .",
    "a.  tajer , g.  jajamovich , x.  wang , and g.  v.  moustakides , `` optimal joint target detection and parameter estimation by mimo radar , '' _",
    "ieee j. sel .",
    "_ , vol .  4 , no .  1 ,",
    "127 - 145 , feb .  2010"
  ],
  "abstract_text": [
    "<S> we consider a well defined joint detection and parameter estimation problem . by combining the baysian formulation of the estimation subproblem with suitable constraints on the detection subproblem we develop optimum one- and two - step test for the joint detection / estimation case . </S>",
    "<S> the proposed combined strategies have the very desirable characteristic to allow for the trade - off between detection power and estimation efficiency . </S>",
    "<S> our theoretical developments are then applied to the problems of retrospective changepoint detection and mimo radar . in the former case </S>",
    "<S> we are interested in detecting a change in the statistics of a set of available data and provide an estimate for the time of change , while in the latter in detecting a target and estimating its location . </S>",
    "<S> intense simulations demonstrate that by using the jointly optimum schemes , we can experience significant improvement in estimation quality with small sacrifice in detection power .    </S>",
    "<S> joint detection - estimation , retrospective change detection , mimo radar . </S>"
  ]
}