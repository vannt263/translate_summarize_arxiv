{
  "article_text": [
    "critical - point behavior is a manifestation of power - law divergences of the correlation length and the correlation time .",
    "the power laws that describe the divergence of the correlation length on approach of the critical point are expressed by means of critical exponents that are dependent on the _ direction _ of this approach , which may , , be ordering - field - like or temperature - like .",
    "the exponents describing the singularities in _ thermodynamic _ quantities can be expressed in terms of the same exponents .",
    "in addition to the exponents defining these power laws , another critical exponent ,  the dynamic exponent @xmath0 , is required for the singularities in the _ dynamics_. this exponent @xmath0 is defined by the relationship that holds between the correlation length @xmath1 and the correlation time @xmath2 , namely @xmath3 .",
    "one of the directions along which one can approach the critical singularity is the finite - size direction , , one increases the system size @xmath4 while keeping the independent thermodynamic variables at their infinite - system critical values . in this case , @xmath5 so that @xmath6 . this relation has been used extensively to obtain the dynamic exponent @xmath0 from finite - size calculations .    in this paper",
    "we deal with universality of dynamic critical - point behavior .",
    "one would not expect systems in different static universality classes to have the same dynamic exponents , and even within the same static universality class , different dynamics may have different exponents .",
    "for instance , in the case of the ising model , kawasaki dynamics which satisfies a local conservation law @xcite has a larger value of @xmath0 than glauber dynamics,@xcite in which such a conservation law is absent .",
    "also the introduction of nonlocal spin updates , as realized  in cluster algorithms , is known to lead to a different dynamic universal behavior.@xcite    conservation laws and nonlocal updates tend to have a large effect on the numerical value of the dynamic exponents , but until fairly recently , numerical resolution of the expected differences of dynamic exponents of systems in different static universality classes for dynamics with local updates has been elusive .",
    "this is caused by the difficulty of obtaining the required accuracy in estimates of the dynamic critical exponent . under these circumstances",
    "it is evident that only a limited progress has been made with respect to the interesting questions regarding dynamic universality classes .",
    "in this paper we present a detailed exposition of a method of computing dynamic exponents with high accuracy.@xcite we consider single spin - flip glauber dynamics .",
    "this is defined by a markov matrix , and computation of the correlation time is viewed here as an eigenvalue problem , since correlation times can be obtained from the subdominant eigenvalues of the markov matrix .    if a thermodynamic system is perturbed out of equilibrium , different thermodynamic quantities relax back at a different rates . more generally , there are infinitely many independent relaxation modes for a system in the thermodynamic limit .",
    "let us label the models within a given universality class by means of @xmath7 , and denote by @xmath8 the autocorrelation time of relaxation mode @xmath9 of a system of linear dimension @xmath4 .",
    "in this paper we present strong numerical evidence that , as indeed renormalization group theory suggests , at criticality the relaxation times have the following factorization property @xmath10 where @xmath11 is a _ non - universal _ metric factor , which differs for different representatives of the same universality class as indicated ; @xmath12 is a _ universal _",
    "amplitude which depends on the mode @xmath9 ; and @xmath0 is the _ universal _ dynamical exponent introduced above .",
    "while the relaxation time of the slowest relaxation mode is obtained from the second - largest eigenvalue of the markov matrix , lower - lying eigenvalues yield the relaxation times of faster modes . to compute these we construct , employing a  method , variational approximants for several eigenvectors .",
    "these approximants are called optimized trial vectors .",
    "the corresponding eigenvalues can then be estimated by evaluating with  techniques the overlap of these trial vectors and the corresponding matrix elements of the markov matrix in the truncated basis spanned by these optimized trial vectors .",
    "it should be noted that both the optimization scheme and the evaluation of these matrix elements critically depend on the fact that the markov matrix is sparse .",
    "that is , the number of configurations accessible from any given configuration is equal to the number of sites only , rather than the number of possible spin configurations .",
    "given such fixed trial vectors , this approach has the advantage of simplicity and high statistical accuracy , but the disadvantage is that results are subject to systematic , variational errors , which only vanish in the ideal limit where the variational vectors become exact eigenvectors , or span an invariant subspace of the markov matrix . since the condition is rarely satisfied in cases of practical interest , a projection monte carlo method is then used , to reduce the systematic error , but this is at the expense of an increase of the statistical errors .",
    "the methods we use in this paper is a combination and generalization of the work of umrigar _",
    "et al._,@xcite and that of ceperley and bernu .",
    "@xcite    to summarize , the  method discussed here consists of two phases . in the first phase , trial vectors are optimized .",
    "the ultimate , yet unattainable goal of this phase is to construct exact eigenvectors . in this phase of the computation ,",
    "very small  samples are used , consisting typically of no more than a few thousand spin configurations . in the second phase ,",
    "one performs a standard   computation in which one reduces statistical errors by increasing the length of the computation rather than the quality of the variational approximation .",
    "the computed correlation times , derived from the partial solution of the eigenvalue problem as sketched above , are used in a finite - size analysis to compute the dynamic critical exponent @xmath0 .",
    "we verify its universality for several models in the static universality class of the two - dimensional ising model .",
    "we also address another manifestation of dynamic universality .",
    "as was mentioned , in addition to the usual static critical exponents , there is only one new exponent that governs the leading singularities of critical dynamics , . , @xmath0 .",
    "similarly , one would expect that , within the context of glauber dynamics , the description of time - dependent critical - point amplitudes requires only a single non - universal metric factor to determine the time - scale of each different model within a given universality class .",
    "our results corroborate this idea , which is the immediate generalization to critical dynamics of work on static critical phenomena by privman and fisher.@xcite    in this paper we apply the techniques outlined above to three different two - dimensional ising models subject to glauber - like spin dynamics .",
    "these models are defined on a simple quadratic lattice of size @xmath13 with periodic boundary conditions .",
    "the hamiltonian @xmath14 , defined on a general spin configuration @xmath15 , is given by @xmath16 } s_k s_l , \\label{ham}\\ ] ] where the first summation is on all nearest - neighbor pairs of sites of the square @xmath13 lattice ; the second summation is on all next - nearest - neighbor pairs ; the ising variables @xmath17 assume values @xmath18 .",
    "periodic boundaries are used throughout . in particular , we focus on models described by three ratios @xmath19 , namely @xmath20 , 0 ( nearest - neighbor model ) and 1 ( equivalent - neighbor model )",
    ". the non - planar models for @xmath21 are not exactly solvable and their critical points are known only approximately .",
    "yet , it was demonstrated to a high degree of numerical accuracy that that they belong to the static ising universality class.@xcite for the nearest neighbor model the critical coupling is @xmath22 , for the other two models estimates of the critical points are @xmath23 for @xmath24 and @xmath25 for @xmath20.@xcite    we use the dynamics of the heat - bath algorithm with random site selection .",
    "the single - spin - flip dynamics is determined by the markov matrix @xmath26 defined as follows .",
    "the element @xmath27 is the transition probability of going from configuration @xmath28 to @xmath29 .",
    "if @xmath28 and @xmath29 differ by more than one spin , @xmath30 . if both configurations differ by precisely one spin , @xmath31 \\right\\ } , \\label{mar}\\ ] ] where @xmath32 is the total number of spins . the diagonal elements",
    "@xmath33 follow from the conservation of probability @xmath34 where @xmath29 runs over all possible @xmath35 spin configurations .",
    "we denote the probability of finding spin configuration @xmath28 at time @xmath36 by @xmath37 . by design , the stationary state of the markov process is the equilibrium distribution @xmath38}{z } \\equiv \\frac { \\psi_{\\rm b}(s)^2}{z},\\ ] ] where the normalization factor @xmath39 is the partition function .    the dynamical process defined by eq .",
    "( [ mar ] ) is constructed so as to satisfy detailed balance , which is equivalent to the statement that the matrix @xmath40 with elements @xmath41 is symmetric .",
    "therefore the eigenvalues of @xmath26 are real .",
    "the markov matrix determines the time evolution of @xmath37 , , @xmath42 the simultaneous probability distribution @xmath43 that the system is in state @xmath28 at time @xmath44 and in state @xmath29 at time @xmath45 is @xmath46 where @xmath47 denotes the @xmath48 element of the @xmath36-th power of the matrix @xmath26 . for sufficiently large times @xmath44",
    ", one may take @xmath49 so that the autocorrelation function @xmath50 of an observable @xmath51 , the average with respect to time @xmath44 of @xmath52 , can equivalently be written as the ensemble average @xmath53 for large @xmath44 .",
    "thus @xmath54 where @xmath55 denotes the value of @xmath51 in a spin configuration @xmath28 .",
    "after substitution of eq .",
    "( [ eq.autoc ] ) and expansion of @xmath56 in right - hand eigenvectors of the markov matrix , it follows at once that the time - dependent correlation functions of a system of size @xmath4 have the following form @xmath57 , \\label{eq.auto}\\ ] ] where the dependence on the specific model @xmath7 has been suppressed in denoting by @xmath58 the relaxation times of the independent modes of the equilibration process .",
    "the @xmath58 are determined by the eigenvalues of the markov matrix .",
    "we denote these eigenvalues @xmath59 @xmath60 , and order them so that @xmath61 .",
    "note that conservation of probability implies that @xmath62 ; by construction , the corresponding right - hand eigenvector is the boltzmann distribution .",
    "the relaxation times are given by @xmath63 the factor @xmath32 is inserted because , as usual , time is measured units of one flip per spin , which corresponds to @xmath32 iterations of the process described by eq .",
    "( [ eq.rhot ] ) .",
    "note that the stochastic matrix @xmath64 has the same symmetry properties as the hamiltonian and the boltzmann distribution .",
    "in addition to spin inversion , these symmetries include translations , reflections and rotations of the @xmath13 lattice .",
    "it follows that each eigenvector of @xmath64 , as well as its associated relaxation mode , has distinct symmetry properties that can be characterized by a set of `` quantum numbers . ''",
    "for instance , the eigenvector associated with the second - largest eigenvalue is antisymmetric under spin inversion , and invariant under translations , reflections and rotations .",
    "it describes the relaxation of the total magnetization ; this process , with relaxation time @xmath65 , is thus the slowest relaxation mode contained in the stochastic matrix .    in this work ,",
    "we restrict ourselves to relaxation modes that are invariant under geometric symmetries of the spin lattice .",
    "however , in addition to eigenvectors that are symmetric under spin inversion , we include antisymmetric ones , so as to obtain the longest relaxation time . as a consequence of this restriction to geometric invariance ,",
    "spatially non - homogeneous relaxation processes fall outside the scope of this work .    by design , the stationary state of the markov process is the equilibrium state @xmath38}{z } \\equiv \\frac { \\psi_{\\rm b}(s)^2}{z},\\ ] ] where the normalization factor @xmath39 is the partition function .    the dynamical process defined by eq .",
    "( [ mar ] ) is constructed so as to satisfy detailed balance , which is equivalent to the statement that the matrix @xmath40 with elements @xmath41 is symmetric .",
    "the layout of the rest of this paper is as follows . in section [ sec.exhaust ]",
    "we discuss the general principles of the method used in this paper .",
    "the expressions in this section feature exhaustive summation over all spin configurations , which renders them useless for practical computations .",
    "the  summation methods employed instead are discussed in section [ sec.mc.summation ] .",
    "trial vectors , a vital ingredient of the method , are discussed in section [ sec.trial.states ] , and numerical results are discussed in section [ sec.numerical ] .",
    "finally , section [ sec.discussion ] contains a discussion of issues that remain to be addressed by future work .",
    "in this section we discuss trial vector optimization , which is used to reduce the statistical errors in the  computation of eigenvalues of the markov matrix .",
    "first , we review the case of a single eigenvalue,@xcite and then we generalize to optimization of multiple trial vectors . in this section ,",
    "we discuss the exact expressions involving summation over all possible spin configurations . in cases of practical interest ,",
    "these expressions can not be evaluated as written ; for their approximate evaluation one uses the monte carlo methods discussed in section [ sec.mc.summation ] .    a powerful method of optimizing a single , many - parameter trial vector , say @xmath66 , is minimization of the variance of the _ configurational eigenvalue , _ which in the context of quantum monte carlo is called the _ local energy_. that is , define @xmath67 for an arbitrary configuration @xmath28 .",
    "we wish to satisfy the eigenvalue equation @xmath68 where the prime indicates matrix multiplication by @xmath40 , , @xmath69 for any function @xmath70 defined on the spin configurations . even if @xmath71 is not an eigenvector",
    ", one can define the _ configurational eigenvalue _ by @xmath72 if @xmath71 is not an eigenvector , eq .",
    "( [ eq.lamda1 ] ) gives an overdetermined set of equations for @xmath73 , for a given @xmath71 and a sufficiently big set of configurations @xmath28 .",
    "one can obtain a least - squares estimate of the eigenvalue @xmath73 by minimizing the squared residual of eq .",
    "( [ eq.lamda1 ] ) .",
    "this yields the usual variational estimate @xmath74 which is the average of the configurational eigenvalue @xmath75 .    the standard rayleigh - ritz variational method , which can be used for the largest eigenvalue consists in maximization of @xmath76 with respect to the parameters @xmath77 .",
    "however , one can formulate a different optimization criterion as follows .",
    "the gradient of @xmath76 with respect to @xmath78 is @xmath79 clearly , this gradient vanishes for _ any _ eigenvector and this suggests as an alternative optimization criterion minimization of the magnitude of the gradient of a normalized trial vector @xmath71 . with respect to eq .",
    "( [ eq.lamda1 ] ) , this corresponds to minimization of the normalized squared residual @xmath80 ^ 2 \\over \\sum_s \\psit(s)^2 } =   { \\sum_s [ \\lambdac(s)-\\blambda(p)]^2 \\psit(s)^2 \\over \\sum_s \\psit(s)^2 } = { \\psitbra ( \\p-\\blambda)^2 \\psitket \\over \\psitbr \\psitket}. \\label{eq.chi^2}\\ ] ] which equals the variance of the configurational eigenvalue , as shown .",
    "minimization of @xmath81 is a valid criterion for any eigenvector , but if this is used without the equivalent of an orthogonalization procedure , one would in practice simply keep reproducing an approximation to the same eigenvector , the dominant one most of the time .",
    "since orthogonalization is not easily implemented with monte carlo methods , we utilize straightforward generalizations of eqs .",
    "( [ eq.lamda1 ] ) and ( [ eq.lamdabar ] ) to deal with more than one eigenvalue and eigenvector .",
    "( [ eq.chi^2 ] ) is a little problematic in this respect , as will become clear .",
    "suppose we start from a set of @xmath82 trial vectors @xmath83 , @xmath84 .",
    "we can then write eq .",
    "( [ eq.lamda1 ] ) in matrix form @xmath85 as before , the prime on the left - hand side indicates matrix multiplication by @xmath40 , and again eq .  ( [ eq.lam_matrix ] ) for all @xmath9 and @xmath28 form an overdetermined set of equations for the matrix @xmath86 .",
    "these equations have no solution , unless the @xmath82 basis vectors @xmath83 span an invariant subspace of the matrix @xmath40 , which in non - trivial applications of course is never the case .",
    "again , however , one can solve for the matrix elements @xmath86 in a least - squares sense .",
    "this yields @xmath87 where @xmath88 and @xmath89 note that although these matrix elements depend on the normalization of the @xmath90 , the matrix @xmath91 is invariant under an overall change of normalization .    by diagonalization of the @xmath92 matrix @xmath91",
    "one obtains an approximate , partial eigensystem of the markov matrix . more specifically , suppose that @xmath93 the eigenvalues @xmath94 of @xmath91 are variational lower bounds for the exact eigenvalues of the markov matrix @xmath26 , in the sense that @xmath95,@xcite if the exact eigenvalues are numbered such that @xmath96 , in contrast with the convention used in the discussion following eq .",
    "( [ eq.auto ] ) .",
    "this property is a consequence of the interlacing property of the eigenvalues of symmetric matrices and their submatrices , also known as the separation theorem.@xcite note that in denoting the eigenvalues we omit the index @xmath4 indicating system size , where this is not confusing .",
    "the approximate eigenvectors @xmath97 are given by @xmath98 which can be verified as follows : multiply eq .",
    "( [ eq.lam_matrix ] ) through by @xmath99 , and sum on @xmath9 to verify that @xmath100 proportional to @xmath101 .",
    "the expressions derived above are usually@xcite derived by starting from the linear combinations given in this last equation .",
    "the @xmath102 then are treated as variational parameters , and are determined by requiring stationarity of the rayleigh quotient .",
    "this yields the following equation for the @xmath102 @xmath103 a generalized eigenvalue problem equivalent to the eigenvalue problem defined by @xmath91 defined in eq .",
    "( [ eq.lam=p/n ] ) .",
    "next we discuss the generalization to more than one trial vector of minimization of the variance as given by eq .",
    "( [ eq.chi^2 ] ) . in this context",
    "it is important to keep in mind that the variational approximation is invariant under replacement of the basis vectors by a non - singular linear superposition .",
    "this yields a similarity transformation of @xmath91 , and leaves invariant the approximate eigenvalues and eigenvectors . of course",
    ", one would like to have an optimization criterion that shares this invariance .",
    "the squared residual of eq .",
    "( [ eq.lam_matrix ] ) fails in this respect .",
    "this sum is not even invariant under a simple rescaling of the basis functions @xmath83 , and there is no obvious normalization comparable to the one used in eq .",
    "( [ eq.chi^2 ] ) .",
    "one way to perform the optimization in an invariant way is for each choice of the optimization parameters to compute linear combinations @xmath104 , where @xmath105 is the @xmath92 matrix , such that @xmath106 is diagonal .",
    "each of these linear combinations defines a @xmath107 via eq .",
    "( [ eq.chi^2 ] ) , and the parameters in the basis functions can then be optimized by minimization of these @xmath82 sums of squares .",
    "one may define a convex sum of these @xmath108 and optimize all parameters for all basis functions simultaneously with respect to this combined object function , or , as we did in our computations , one can perform the optimization iteratively one vector at a time for eigenvalues with increasing distance from the top of the spectrum .",
    "another approach that also yields invariant results is to perform the optimization by dividing the set of configurations into several subsets , and computing a matrix @xmath91 for each subset .",
    "one can then minimize the variance of the eigenvalues over these subsets .",
    "this is the procedure we followed to produce the results reported in this paper .",
    "we have not investigated which of the two procedures described above is superior .",
    "both do have a problem in common , namely that for a wide class of variational basis vectors , they give rise to a singular or nearly singular optimization problem .",
    "this is a consequence of the fact that the basis states are not unique , even if the eigenvalue problem has a unique solution . for the optimization problem",
    "this means that there are many almost equivalent solutions , a problem commonly encountered in ( non - linear ) when on performs least - squares parameter fits .    more specifically ,",
    "if the basis vectors are such that a linear combination of trial vectors can be expressed exactly ( or to good approximation ) in the same functional form as the trial vectors themselves , then there is a gauge symmetry ( or an approximate gauge symmetry ) that yields a class of equivalent ( or almost equivalent ) solutions of the minimization problem .",
    "that is , if @xmath90 is a solution , @xmath109 is an equivalent ( or almost equivalent ) solution for any @xmath105 .",
    "this problem can be solved straightforwardly by fixing the gauge and performing the optimization subject to the constraint that @xmath110 .",
    "if the gauge symmetry holds only approximately , this additional constraint may produce a sub - optimal solution .",
    "the eigenvalues obtained by the variational scheme discussed in the previous sections have a bias caused by admixture of eigenvectors in that part of the spectrum that is being ignored .",
    "this variational bias can be reduced in principle arbitrarily as follows.@xcite    let us introduce generalized matrices with elements @xmath111 and @xmath112    for @xmath113 these expressions reduce to eqs .",
    "( [ eq.n ] ) and ( [ eq.p ] ) .",
    "one can view the matrix elements for @xmath114 as having been obtained by the substitution @xmath115 .",
    "expansion in the exact eigenvectors immediately shows that the spectral weights are reduced of `` undesirable '' eigenvectors with less dominant eigenvalues , so that the vectors @xmath116 span a more nearly invariant subspace of @xmath40 than the original states .",
    "this process , however becomes numerically unstable as @xmath117 , since in that case all basis vectors of the same symmetry collapse onto the corresponding dominant state .",
    "obviously , the summation over all spin configurations used in the expressions in the previous section can , in general , be done only for small systems . in this section ,",
    "we discuss the monte carlo estimators of the expressions presented above . in principle ,",
    "matrix multiplication involves summation over all configurations and therefore is not practically feasible .",
    "however , for the dynamics we consider in this paper the summation required for the matrix multiplication by @xmath26 in @xmath118 is an exception , since for a given @xmath28 there are only @xmath32 configurations @xmath29 from which @xmath28 can be reached with one or fewer spin flips , and these are the only configurations for which @xmath119 does not vanish . for all",
    "other configuration sums a  method is used .    to produce a  estimate of @xmath81 as given in eq .",
    "( [ eq.chi^2 ] ) , sample @xmath120 spin configurations @xmath121 with @xmath122 from the boltzmann distribution @xmath123 .",
    "this yields a monte carlo estimate of @xmath76 @xmath124 where @xmath125 @xmath126 similarly , @xmath127 ^ 2 \\over \\sum_\\alpha \\hat\\psit(s_\\alpha)^2}. \\label{eq.chi^2.est}\\ ] ]    parameter optimization for a single vector is done by generating a sample of a few thousand configurations and subsequently varying the parameters @xmath77 while keeping this sample fixed .",
    "the same applies to the optimization of more than one vector , in which case estimates of the required matrix elements @xmath128 and @xmath129 are computed by @xmath130 and @xmath131    we attached tildes to the symbols on the right - hand side of eqs .",
    "( [ eq.n.est ] ) and ( [ eq.p.est ] ) to indicate that the corresponding quantities are stochastic variables , which is important to keep in mind for the following discussion .",
    "since the matrix @xmath132 is symmetric , one might be inclined to symmetrize its estimator @xmath133 with respect to @xmath9 and @xmath134 .",
    "this symmetrization , however , destroys the zero - variance principle satisfied by the expressions as written . as mentioned before , the eigensystem of @xmath91 is obtained exactly and without statistical noise , if the basis vectors @xmath83 are linear combinations of @xmath82 exact eigenvectors . in that ideal case , @xmath91 is uniquely determined by eq .",
    "( [ eq.lam_matrix ] ) even if it is applied only to an subset of configurations @xmath28 .",
    "the same holds for a weighted subset as represented by a  sample .",
    "even though the matrices @xmath132 and @xmath135 themselves depend on the weights and the subset , factors responsible for statistical noise cancel in the product @xmath136 .",
    "to demonstrate this , we write the estimator in matrix form @xmath137 and @xmath138 where @xmath139 is a rectangular matrix with elements @xmath140 , and @xmath141 .",
    "( [ eq.lam_matrix ] ) in matrix form becomes @xmath142 clearly , if this last equation holds , @xmath143 without statistical noise , as announced .",
    "we have assumed that one matrix multiplication by the markov matrix can be done exactly ; repeated multiplications rapidly become intractable .",
    "this is a problem for the computation of the matrix elements given in eqs .",
    "( [ eq.nt ] ) and ( [ eq.pt ] ) . to obtain a statistical estimate of these matrix elements ,",
    "one generates a time series with the markov matrix @xmath26 .",
    "one then exploits the fact that in the steady state of the markov process , the relative probability of finding configurations @xmath144 in immediate succession is given by @xmath145    for a  run of length @xmath120 , this property allows us to write @xmath146    similarly , @xmath147 .",
    "\\label{eq.pij.mc}\\end{aligned}\\ ] ] the first term in expression  ( [ eq.pij.mc ] ) follows immediately from expression  ( [ eq.pij.xct ] ) ; to obtain the second term one has to use the time reversal symmetry of a stochastic process that satisfies detailed balance , , @xmath148    again , these estimators satisfy the zero - variance principle mentioned above , as long as the expressions are used as written , , without symmetrization with respect to @xmath9 and @xmath134 .",
    "as we mentioned , the form of the trial vectors used in these calculations is a major factor determining the statistical accuracy of the results . it not too difficult to make an initial guess for the form of the eigenvector corresponding to the second largest eigenvalue of the markov matrix .",
    "numerically exact calculations for small systems show that this eigenvector is antisymmetric under spin inversion , which is a manifestation of the longevity of fluctuations of the magnetization and not a peculiarity of small systems .",
    "this suggests the following initial approximation of the eigenvector belonging to the second largest eigenvector , the first sub - dominant eigenvector of the symmetrized markov matrix @xmath40 : @xmath149 where @xmath150 is the average magnetization .",
    "[ fig.psit13.vs.m]-[fig.psit15.vs.m ] are a plots of @xmath151  the total magnetization @xmath152 for the exact eigenvector @xmath153 computed for @xmath154 , @xmath155 , and @xmath156 nearest - neighbor ising systems . for all three , the pre - factor @xmath150 in eq .",
    "( [ eq.psit.of.m ] ) clearly captures a significant part of the truth , but there are two shortcomings .",
    "first of all , there is scatter , which indicates that @xmath151 is a function of more than just the magnetization .",
    "secondly , the `` curve '' is non - linear .",
    "the latter problem can be cured quite easily by replacing @xmath150 in eq .",
    "( [ eq.psit.of.m ] ) by an odd polynomial @xmath157 with coefficients @xmath158 to be determined variationally .",
    "similarly , computations for small systems ( see section  [ sec.exaxt ] for further details ) suggest that the second largest eigenvalue is associated with an eigenvector that is even under spin inversion , as illustrated in fig .",
    "[ fig.psit25.vs.m ] . a trial vector of this form is readily constructed by replacing @xmath150 on the right - hand side of eq .",
    "( [ eq.psit.of.m ] ) by a polynomial even in @xmath150 .",
    "it turns out that the general picture as just described is largely independent of @xmath4 .",
    "more in general , the plots shown in figs .  [ fig.psit13.vs.m]-[fig.psit55.vs.m ] strongly suggest that the sub - dominant eigenvectors of the markov matrix @xmath26 , subject to the imposed spin , rotation and translation symmetries , are reasonably approximated by the boltzmann distribution multiplied by a mode - dependent function of the magnetization . as can be seen in figs .",
    "[ fig.psit13.vs.m]-[fig.psit55.vs.m ] , the number of nodes of this pre - factor increases by one as one steps down the spectrum , but it is also clear that , especially for the less dominant eigenvectors , the residual variance is significant .    to begin to address the problem of the scatter and to improve the trial vector systematically , it is necessary to identify other important variables besides the magnetization , and to incorporate them in the trial vector .",
    "we tried multi - spin correlations involving nearby spins but after considerable failed experimentation we established that long - wavelength fluctuations of the magnetization are the suitable variables .",
    "this is reasonable when one compares  the eigenvalue equations for @xmath159 and @xmath160 and realizes that the eigenvalues differ only very little from unity except for very small systems .",
    "we therefore used the fourier components of the spin configuration , which are defined by @xmath161\\,s_{l_1l_2}\\ ] ] where @xmath162 with @xmath163 ; and @xmath164 denotes the spin at lattice site @xmath165 .",
    "note that @xmath166 . if we restrict ourselves to eigenvectors that are translationally invariant",
    ", the arguments presented in the previous paragraph yield the following trial odd or even vectors : @xmath167 \\label{eq.psit}\\end{aligned}\\ ] ] the primes attached to the summation signs indicate that terms with @xmath168 are excluded .",
    "the coefficients @xmath169 are polynomials in @xmath150 , which are either odd or even under spin inversion and are to be chosen according to the desired symmetry .",
    "rotation and reflection symmetries of the lattice are imposed by equating coefficients of the appropriate monomials in @xmath150 .",
    "the results reported in ref .   were obtained using a more complicated version of eq .",
    "( [ eq.psit ] ) , namely @xmath170\\nonumber\\\\ & \\times&\\big[a^+(m)+\\mathop{{\\sum}'}_{\\k_1,\\k_2 }   a^+_{\\k_1 \\k_2}(m)\\,m_{\\k_1 } m_{\\k_2 } \\,\\delta_{\\k_1+\\k_2,0 } \\nonumber\\\\ & + & \\mathop{{\\sum}'}_{\\k_1,\\k_2,\\k_3 } a^-_{\\k_1 \\k_2 \\k_3}(m)\\ , m_{\\k_1 } m_{\\k_2 } m_{\\k_3 } \\,\\delta_{\\k_1+\\k_2+\\k_3,0}+\\dots \\big ] \\label{eq.psit2}\\end{aligned}\\ ] ] in those calculations also the coupling constant appearing in the boltzmann factor was treated as variational parameter , but it turned out that the optimal value of this parameter was indistinguishable from the critical coupling .",
    "it does not seem that the more complicated form of expression ( [ eq.psit2 ] ) resulted in a major improvement , but we did not perform a systematic comparison of these trial vectors .",
    "the coefficients in the trial vector are treated as variational parameters .",
    "as in all non - linear fitting problems it is important to use parameters parsimoniously , and to do so one has to establish a hierarchy among these parameters .",
    "the scheme we used was to iterate the following step : _ ( a ) _ systematically add terms of increasing degree in @xmath150 ; _ ( b ) _ when this saturates increase the degree of terms with products of @xmath171 with @xmath172 .",
    "the effectivity of this variational approach using low - momentum fourier components , as described here , becomes apparent when one compares the variational eigenvalues with the exact numerical ones .",
    "for instance , the difference in the case of the second eigenvalue of the @xmath173 nearest - neighbor model was only @xmath174 .",
    "the full , symmetric markov matrix @xmath175 for an @xmath13 ising model is a @xmath176 matrix , so that exact numerical calculations are possible only for very small systems ; see   results for @xmath177 in ref .  .",
    "in the present work , we performed such exact computations for systems up to @xmath173 . in order to restrict the numerical task , we chose representations of @xmath40 in subspaces with the appropriate symmetries .",
    "two distinct symmetries were chosen , both of which impose invariance of the eigenvectors of @xmath40 with respect to geometric translation , rotation and mirror inversion . the vectors were chosen to be either even or odd under spin inversion . this reduced by almost a factor 400 the dimensionality of @xmath40 . in this way , the computation of a restricted set of eigenvectors became feasible for the resulting matrices of order 86,056 for the @xmath173 cases .",
    "for the diagonalization we made use of sparse - matrix methods and the conjugate - gradient method ( see e.g. , ref .  ) which computes the eigenvector with the largest eigenvalue .",
    "subsequent orthogonalization with respect to this eigenvector yields the eigenvector with the second largest eigenvalue , and further eigenvectors can be obtained similarly .",
    "thus we obtained exact numerical solutions for six eigenvalues @xmath59 and their corresponding eigenvectors @xmath178 ( @xmath179 ) of the eigenvalue equation @xmath180 the largest eigenvalue @xmath181 is equal to 1 , in accordance with the conservation of probability ; its corresponding eigenvector satisfies @xmath182 , as follows from detailed balance .",
    "it is even with respect to spin inversion : @xmath183 where @xmath184 is obtained from @xmath28 by inverting all spins . for all system sizes and models included here",
    ", we observed that the six leading eigenvectors , ordered according to magnitude of their eigenvalues , alternate between the odd and even subspaces : the first eigenvector is even , the second one is odd , the third one is even subspace , and so on , with the caveat that for @xmath185  the odd subspace contains only two independent states .",
    "as we discussed above , the resulting eigenvectors provide useful information on how to construct trial vectors ; moreover , the knowledge of accurate eigenvalues for @xmath186 provided an powerful test of the monte carlo method , the results of which are presented in the following subsection .",
    "all simulations took place at the respective critical points of the models considered .",
    "this point is known exactly in the case of the nearest - neighbor model [ @xmath187 , and was determined numerically @xcite for the other two models : @xmath188 for the equivalent - neighbor model , and @xmath189 for the model with antiferromagnetic next - nearest neighbor interactions . the finite - size scaling analysis presented in ref",
    ".   showed that , to the extent they are compatible with the numerical results , deviations from ising universal behavior are extremely small .",
    "the raw simulation data used in this current paper include the data on which were based the numerical results for the largest relaxation time of the nearest - neighbor model , reported in ref .  .",
    "the latter results were obtained from @xmath190 monte carlo samples for systems with finite sizes up to @xmath191 . the trial vector used for these computations consisted was of the form given in expression ( [ eq.psit2 ] ) and used up to 36 variational parameters . also included in the present analysis are the simulations reported in ref .  , which contained @xmath192 monte carlo samples for all three models with system sizes up to @xmath193 .",
    "in addition , new simulations for each of the three models were performed , with a length of @xmath194 monte carlo samples for system sizes up to @xmath193 , and of @xmath195 monte carlo samples for system size @xmath196 .",
    "these new simulations used up to 89 variational parameters in the trial functions for each eigenvector of each model .",
    "the required fourier components of the spatial magnetization distribution were sampled at intervals of one sweep for the smallest systems up to about 15 sweeps for the largest ones .",
    "the monte carlo calculation of the autocorrelation times ( actually the eigenvalues of the markov matrix ) was performed for each run as a whole as well as separately for a number of up to 1024 blocks into which the run was split .",
    "this blocking procedure enabled us to estimate the statistical errors .",
    "furthermore , the calculation of the eigenvalues according to @xmath197 still depends on the time displacements @xmath36 [ see eqs .",
    "( [ eq.nest ] ) and ( [ eq.pij.mc ] ) ] .",
    "the calculation of @xmath198 was performed for time displacements @xmath199 up to 10 or 20 of the above - mentioned intervals . for small @xmath36",
    "these eigenvalue estimates reflect variational bias due to the residual contributions of relaxation modes decaying faster than the mode for which the trial vector was constructed .",
    "if the relaxation times of these faster modes are considerably shorter than that of the mode under investigation , one can clearly see a fast convergence of the eigenvalue estimate as a function of @xmath36 .",
    "convergence , however , occurs to a level that is only approximately constant because of the correlated statistical noise whose effect still depends on @xmath36 . with increasing @xmath36",
    ", one can also observe that the statistical errors increase .",
    "the latter effect , which is as slow as the pertinent relaxation mode , occurs when the autocorrelations of the monte carlo sample are decreasing significantly with @xmath36 .",
    "this situation was indeed observed for the largest eigenvalues ; the data converged well with @xmath36 before the coherence of the sampled data was lost .",
    "it was thus rather simple to select a `` best estimate '' of those eigenvalues .",
    "however , the situation for the smaller eigenvalues investigated here was much more difficult , because the relative differences between subsequent autocorrelation times are much smaller .",
    "the numerical results for the eigenvalues are listed in appendix a.      in two - dimensional ising models , finite - size corrections are known that decay with finite size as @xmath200 , and integral powers thereof may also be expected .",
    "in the absence of information on possible additional finite - size corrections of a different type that could occur in dynamic phenomena , we try to describe the finite - size data for the various autocorrelation times , as given in eq .",
    "( [ tau ] ) , by the formula @xmath201 here @xmath0 is the dynamic exponent , @xmath202 the finite - size amplitude , and @xmath203 is the number of correction - to - scaling terms included . not explicitly shown in this notation is that the autocorrelation times depend on the relaxation mode and the model .",
    "on the basis of eq .",
    "( [ fit ] ) , a considerable number of least - squares fits were applied to the numerical results for the autocorrelation times .",
    "for each model and relaxation mode , one may vary both @xmath204 , the number of correction terms , and the low-@xmath4 cutoff specifying the minimal system size included in the fit .",
    "the smaller the number of corrections , the larger the low-@xmath4 cutoff must be chosen in order to obtain an acceptable squared residual @xmath107 .",
    "a selection of fits that display the numerical trends is presented in appendix b.    the `` best fits '' were chosen on the basis of the @xmath107 criterion , the dependence on the low-@xmath4 cutoff , and the mutual consistency of fits with different @xmath204 .",
    "the fits are summarized in table [ tab : zbest ] . since the errors are not only of a statistical nature , but also depend on residual bias in the autocorrelation times and subjective choices made in the selection of the best fits , we quote error bars equal to two standard deviations as obtained from statistical considerations only .",
    "we believe that these two - sigma error estimates are conservative in the case of the analysis of the second and third largest eigenvalues of the @xmath205 models .",
    "the @xmath20 model was found to be numerically less well - behaved : the statistical errors , as well as the corrections to scaling appear to be larger . also , the construction of trial vectors was somewhat less successful than in the cases of the @xmath205 models .",
    ".best estimates for the dynamic exponent @xmath0 for five relaxation modes in three ising - like models .",
    "these results were selected from a much larger set of least - squares fits , obtained for different choices of the minimum system size and of the number of corrections taken into account ( see appendix b ) . the error estimate in the last decimal place of each entry",
    "is listed in parentheses , and is taken to be two standard deviations in the best fit . [ cols=\"<,<,>,<,>,<,>\",options=\"header \" , ]"
  ],
  "abstract_text": [
    "<S> we investigate aspects of universality of glauber critical dynamics in two dimensions . </S>",
    "<S> we compute the critical exponent @xmath0 and numerically corroborate its universality for three different models in the static ising universality class and for five independent relaxation modes . </S>",
    "<S> we also present evidence for universality of amplitude ratios , which shows that , as far as dynamic behavior is concerned , each model in a given universality class is characterized by a single non - universal metric factor which determines the overall time scale . </S>",
    "<S> this paper also discusses in detail the variational and projection methods that are used to compute relaxation times with high accuracy . </S>",
    "<S> pacs 64.60.ht , 02.70.lq , 05.70.jk , 64.60.fr +    h p # 1| # 1 # 1 # 1 | # 1_t#1 # 1 # 1 # 1 </S>"
  ]
}