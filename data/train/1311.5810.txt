{
  "article_text": [
    "flow analysis @xcite is concerned with the sound approximation of run - time values at compile time .",
    "this analysis gives rise to natural decision problems such as : _ does expression @xmath2 possibly evaluate to value @xmath3 at run - time ? _ or _ does function @xmath4 possibly get applied at call site @xmath5 ? _ the most approximate analysis always answers _",
    "yes_. this crude `` analysis '' takes no resources to compute , and is useless . in complete contrast",
    ", the most precise analysis only answers _ yes _ by running the program to find that out .",
    "while such information is surely useful , the cost of this analysis is likely prohibitive , requiring intractable or unbounded resources .",
    "practical flow analyses occupy a niche between these extremes , and their _ expressiveness _ can be characterized by the computational resources required to compute their results .",
    "examples of simple yet useful flow analyses include shivers 0cfa @xcite and henglein s simple closure analysis @xcite , which are",
    "_ monovariant_functions that are closed over the same @xmath6-expression are identified .",
    "their expressiveness is characterized by the class ptime@xcite .",
    "more precise analyses can be obtained by incorporating context - sensitivity to distinguish multiple closures over the same @xmath6-term .",
    "the @xmath0cfa hierarchy uses the last @xmath0 calling contexts to distinguish closures , resulting in `` finer grained approximations , expending more work to gain more information '' @xcite .",
    "the increased precision comes with an empirically observed increase in cost . as shivers noted in his retrospective on the @xmath0cfa work @xcite :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ it did not take long to discover that the basic analysis , for any @xmath7 , was intractably slow for large programs . in the ensuing years",
    ", researchers have expended a great deal of effort deriving clever ways to tame the cost of the analysis . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    a fairly straightforward calculation  see , for example , @xcite  shows that 0cfa can be computed in polynomial time , and for any @xmath8 , @xmath0cfa can be computed in exponential time .",
    "these naive upper bounds suggest that the @xmath0cfa hierarchy is essentially _ flat _ ; researchers subsequently `` expended a great deal of effort '' trying to improve them . and @xmath9 steps , though both are nominally in exptime .",
    "] for example , it seemed plausible ( at least , to us ) that the @xmath0cfa problem could be in np  by _ guessing _ flows appropriately during analysis .    in this paper , we show that the naive algorithm is essentially the best one , and that the _ lower _ bounds are what needed improving .",
    "we prove that for all @xmath8 , computing the @xmath0cfa analysis requires ( and is thus complete for ) deterministic exponential time .",
    "there is , in the worst case  and plausibly , in practice  no way to tame the cost of the analysis .",
    "exponential time is required .    who cares , and why should this result matter to functional programmers ?    this result concerns a fundamental and ubiquitous static analysis _ of _ functional programs .",
    "the theorem gives an analytic , scientific characterization of the expressive power of @xmath0cfa . as a consequence , the _",
    "empirically observed _ intractability of the cost of this analysis can be understood as being _ inherent in the approximation problem being solved _ , rather than reflecting unfortunate gaps in our programming abilities .",
    "good science depends on having relevant theoretical understandings of what we observe empirically in practice  otherwise , we devolve to an unfortunate situation resembling an old joke about the difference between geology ( the observation of physical phenomena that can not be explained ) and geophysics ( the explanation of physical phenomena that can not be observed ) . or worse  scientific aberrations such as alchemy , or ptolemaic epicycles in astronomy .",
    "this connection between theory and experience contrasts with the similar result for ml type inference @xcite : we confess that while the problem of recognizing ml - typable terms is complete for exponential time , programmers have happily gone on programming .",
    "it is likely that their need of higher - order procedures , essential for the lower bound , is not considerable .",
    "but static flow analysis really has been costly , and our theorem explains why .",
    "the theorem is proved _ by _ functional programming .",
    "we take the view that the analysis itself is a functional programming language , albeit with implicit bounds on the available computational resources .",
    "our result harnesses the approximation inherent in @xmath0cfa as a computational tool to hack exponential time turing machines within this unconventional language .",
    "the hack used here is completely unlike the one used for the ml analysis , which depended on complete developments of let - redexes .",
    "the theorem we prove in this paper uses approximation in a way that has little to do with normalization .",
    "@xmath0cfa can be thought of as an abstraction ( in the sense of a computable approximation ) to an instrumented interpreter , which not only evaluates a program , but records a history of _ flows_. every time a subterm evaluates to a value , every time a variable is bound to a value , the _ flow _ is recorded .",
    "consider a simple example , where @xmath2 is closed and in normal form : @xmath10 we label the term to index its constituents : @xmath11    the interpreter will first record all the flows for evaluating @xmath2 ( there are none , since it is in normal form ) , then the flow of @xmath2 s value ( which is @xmath2 , closed over the empty environment ) into label @xmath12 ( @xmath2 s label ) is recorded .",
    "this value is then recorded as flowing into the binding of @xmath13 .",
    "the body of the @xmath14 expression is evaluated under an extended environment with @xmath13 bound to the result of evaluating @xmath2 .",
    "since it is a variable occurrence , the value bound to @xmath13 is recorded as flowing into this variable occurrence , labeled @xmath15 . since",
    "this is the result of evaluating the body of the function , it is recorded as flowing out of the @xmath6-term labeled @xmath16 . and",
    "again , since this is the result of the application , the result is recorded for label @xmath17 .",
    "the flow history is recorded in a _ cache _ , @xmath18 , which maps labels and variables to values .",
    "if the cache maps a variable to a value , @xmath19 , it means that during evaluation of the program , the variable @xmath13 was bound to the value @xmath3 at some point .",
    "if the cache maps a label to a value , @xmath20 , it means that the subexpression with that label evaluated to that value .    of course , a variable may be bound to any number of values during the course of evaluation .",
    "likewise , a subexpression that occurs once syntactically may evaluate to any number of values during evaluation .",
    "so asking about the flows of a subexpression is ambiguous without further information .",
    "our simple example does not reflect this possible ambiguity , but consider the following example , where @xmath21  and @xmath22  are closed and in normal form : @xmath23 during evaluation , @xmath24 gets bound to both @xmath21  and @xmath22asking `` what was @xmath24 bound to ? ''",
    "is ambiguous .",
    "but let us label the applications in our term : @xmath25 notice that @xmath24 is bound to different values within different contexts .",
    "that is , @xmath24 is bound @xmath21  when evaluating the application labeled 1 , and to @xmath22  when evaluating the application labeled 2 .",
    "both of these occur while evaluating the outermost application , labeled 3 . a string of these application labels , called a _ contour _",
    ", uniquely describes the _ context _ under which a subexpression evaluates .",
    "@xmath26 ^ 1)^2 ) ( \\lambda y.{\\ensuremath{\\mbox{\\tt false}}}))^3\\\\ 3\\cdot 2 & \\mbox{describes } & ( ( \\lambda f.[\\;]^2 ) ( \\lambda y.{\\ensuremath{\\mbox{\\tt false}}}))^3\\end{aligned}\\ ] ]    so a question about what a subexpression evaluates to _ within a given context _ has an unambiguous answer .",
    "the interpreter , therefore , maintains an environment that maps each variable to a description of the context in which it was bound .",
    "similarly , flow questions about a particular subexpression or variable binding must be accompanied by a description of a context .",
    "returning to our example , we would have @xmath27 and @xmath28 .",
    "typically , values are denoted by _",
    "closures_a @xmath6-term together with an environment mapping all free variables in the term to values .",
    ", for example .",
    "we continue with the abuse . ]",
    "but in the instrumented interpreter , rather than mapping variables to values , environments map a variable to a _",
    "contour_the sequence of labels which describes the context of successive function applications in which this variable was bound : @xmath29 by consulting the cache , we can then retrieve the value .",
    "so if under typical evaluation , a term labeled @xmath5 evaluates to @xmath30 within a context described by a string of application labels , @xmath31 , then we will have @xmath32 , where the contour environment @xmath33 , like @xmath34 , closes @xmath35 .",
    "but unlike @xmath34 , it maps each variable to a contour describing the context in which the variable was bound .",
    "so if @xmath36 , then @xmath37 , where @xmath38 is similarly related to @xmath39 .    we can now write the instrumented evaluator .",
    "the syntax of the language is given by the following grammar : @xmath40    @xmath41 evaluates @xmath42 and writes the result into the table @xmath18 at location @xmath43 .",
    "the notation @xmath44 means that the cache is updated so that @xmath45 .",
    "the notation @xmath46 denotes the concatenation of contour @xmath31 and label @xmath5 .",
    "@xmath47}_{\\delta\\ell}}}\\\\ \\ & \\ & \\quad{\\mathsf{c}}(\\ell,\\delta)\\leftarrow{\\mathsf{c}}(\\ell_0,\\delta\\ell ) \\end{array}\\ ] ] the cache constructed by @xmath48 includes the following entries : @xmath49    in a more declarative style , we can write a specification of _",
    "acceptable caches_a cache is acceptable iff it records all of the flows which occur during evaluation . the smallest cache satisfying this acceptability relation is the one that is computed by the above interpreter . @xmath50}_{\\delta\\ell } } t^{\\ell_0}\\ ; \\wedge   \\\\ \\ & \\ & \\quad{\\mathsf{c}}(\\ell_0,\\delta\\ell ) = { \\mathsf{c}}(\\ell,\\delta )   \\end{array}\\ ] ]    clearly , because constructing a cache @xmath18 is equivalent to evaluating a program , such a cache is not effectively computable .",
    "the next section describes @xmath0cfa as a computable _ approximation . _",
    "@xmath0cfa is a computable approximation to this instrumented interpreter .",
    "rather than constructing an _ exact _",
    "cache @xmath18 , it constructs an _ abstract _",
    "cache @xmath51 , which maps labels and variables , not to values , but to _ sets _ of _ abstract values_. @xmath52    approximation arises from contours being bounded at length @xmath0 .",
    "if during the course of instrumented evaluation , the length of the contour would exceed length @xmath0 , then the @xmath0cfa abstract interpreter will truncate it to length @xmath0 .",
    "in other words , only a partial description of the context can be given , which results in ambiguity .",
    "a subexpression may evaluate to two distinct values , but within contexts which are only distinguished by @xmath53 labels .",
    "questions about which value the subexpression evaluates to can only supply @xmath0 labels , so the answer must be _ both _ , according to a sound approximation .    when applying a function , there is now a set of possible closures that flow into the operator position . likewise",
    ", there can be a multiplicity of arguments .",
    "what is the interpreter to do ?",
    "the abstract interpreter applies all possible closures to all possible arguments .",
    "the abstract interpreter , the imprecise analog of @xmath54 , is then : @xmath55}_{\\lceil\\delta\\ell\\rceil_k}}};\\\\ \\ & \\ & \\quad{\\widehat{\\mathsf{c}}}(\\ell,\\delta)\\leftarrow{\\widehat{\\mathsf{c}}}(\\ell_0,\\lceil\\delta\\ell\\rceil_k ) \\end{array}\\ ] ] we write @xmath56 to indicate an updated cache where @xmath43 maps to @xmath57 .",
    "the notation @xmath58 denotes @xmath31 truncated to the rightmost ( i.e. , most recent ) @xmath0 labels .",
    "compared to the exact evaluator , contours similarly distinguish evaluation within contexts described by as many as @xmath0 application sites : beyond this , the distinction is blurred .",
    "the imprecision of the analysis requires that @xmath59 be iterated until the cache reaches a fixed point , but care must taken to avoid looping in an iteration since a single iteration of @xmath60 may in turn make a recursive call to @xmath60 under the same contour and environment .",
    "this care is the algorithmic analog of appealing to the coinductive hypothesis in judging an analysis acceptable .",
    "these judgment rules are given below .",
    "an acceptable @xmath0-level control flow analysis for an expression @xmath2 is written @xmath61 , which states that @xmath51 is an acceptable analysis of @xmath2 in the context of the current environment @xmath62 and current contour @xmath31 ( for the top level analysis of a program , these will both be empty ) .    just as we did in the previous section , we can write a specification of acceptable caches rather than an algorithm that computes .",
    "the resulting specification is what is found , for example , in @xcite : @xmath63}_{\\lceil\\delta\\ell\\rceil_k } } t^{\\ell_0 } \\wedge   \\\\ \\ & \\ & \\quad{\\widehat{\\mathsf{c}}}(\\ell_0,\\lceil\\delta\\ell\\rceil_k ) \\subseteq { \\widehat{\\mathsf{c}}}(\\ell,\\delta ) \\end{array}\\ ] ]    the acceptability relation is given by the greatest fixed point of the functional defined according to the above clauses  and we are concerned only with least solutions.cfa @xcite rather than a @xmath0cfa in which @xmath64 . the differences are immaterial for our purposes .",
    "see @xcite for details and a discussion on the use of coinduction in specifying static analyses . ]",
    "what is the difficulty of computing within this hierarchy ?",
    "what are the sources of approximation that render such analysis ( in)tractable ? we consider these questions by analyzing the complexity of the following decision problem :    control flow problem : : :    given an expression @xmath2 , an abstract value    @xmath65 , and a pair @xmath43 , is    @xmath66 in the flow    analysis of @xmath2 ?    obviously , we are interested in the complexity of control flow analysis , but our investigation also provides insight into a more general subject : the complexity of computing via abstract interpretation .",
    "it stands to reason that as the computational domain becomes more refined , so too should computational complexity . in this instance , the domain is the size of the abstract cache @xmath51 and the values ( namely , _",
    "closures _ ) that can be stored in the cache . as the table size and number of closures increase .",
    "] , so too should the complexity of computation . from a theoretical perspective",
    ", we would like to understand better the tradeoffs between these various parameters .",
    "it is straightforward to observe that in a _ linear _ @xmath6-term , where each variable occurs at most once , each abstraction @xmath35 can be applied to at most one argument , and hence the abstracted value can be bound to at most one argument .",
    "( note that this observation is clearly untrue for the _ nonlinear _",
    "@xmath6-term @xmath67 , as @xmath13 is bound to @xmath68 , and also to @xmath69 . )",
    "generalizing this observation , analysis of a linear @xmath6-term coincides exactly with its evaluation :    for any closed , linear expression @xmath2 , @xmath70 , and thus @xmath71 .    a detailed proof of this lemma appears in @xcite .",
    "a natural and expressive class of such linear terms are the ones which implement boolean logic .",
    "when we analyze the coding of a boolean circuit and inputs to it , the boolean output will flow to a predetermined place in the ( abstract ) cache . by placing that value in an appropriate context ,",
    "we construct an instance of the control flow problem : a function @xmath4 flows to a call site @xmath72 iff the boolean output is @xmath73 .",
    "since we have therefore reduced the circuit value problem @xcite , which is complete for ptime , to an instance of the 0cfa control flow problem , we conclude that the control flow problem is ptime - hard .",
    "further , as 0cfa can be computed in polynomial time , the control flow problem for 0cfa is ptime - complete .",
    "we use some standard syntactic sugar for constructing and deconstructing pairs : @xmath74 booleans are built out of constants @xmath75  and @xmath76 , which are the identity and pair swap function , respectively : @xmath77    the simplest connective is @xmath78 , which is an inversion on pairs , like @xmath76 . a _ linear _ copy connective is defined as : @xmath79 the coding is easily explained : suppose @xmath68 is @xmath21 , then @xmath80 is identity and @xmath3 twists ; so we get the pair @xmath81 .",
    "suppose @xmath68 is @xmath22 , then @xmath80 twists and @xmath3 is identity ; we get @xmath82 .",
    "we write @xmath83 to mean @xmath84-ary fan - out  a straightforward extension of the above .",
    "now we define truth - table implication : @xmath85 notice that if @xmath86 is @xmath21 , then @xmath87 is @xmath75 , so @xmath88 is @xmath75  iff @xmath89 is @xmath21 . and",
    "if @xmath86 is @xmath21 , then @xmath90 is @xmath76 , so @xmath91 is @xmath76  iff @xmath89 is @xmath22 . on the other hand ,",
    "if @xmath86 is @xmath22 , @xmath87 is @xmath76 , so @xmath88 is @xmath75 , and @xmath90 is @xmath75 , so @xmath91 is @xmath76 .",
    "therefore @xmath92 is @xmath21  iff @xmath93 , and @xmath22  otherwise .",
    "can be read as `` if @xmath87 , then @xmath94 else @xmath95''the if - then - else description of the implication @xmath96 and @xmath97 as its demorgan dual @xmath98 .",
    "thus @xmath92 is the answer we want  and we need only dispense with the `` garbage '' @xmath99 and @xmath100 .",
    "demorgan duality ensures that one is @xmath95 , and the other is @xmath101 ( though we do not know which ) , so they always compose to @xmath101 . ]",
    "however , simply returning @xmath92 violates linearity since @xmath102 go unused .",
    "we know that @xmath103 iff @xmath104 and @xmath105 iff @xmath106 .",
    "we do not know which is which , but clearly @xmath107 .",
    "composing @xmath108 with @xmath101 , we are guaranteed to get @xmath95 .",
    "therefore @xmath109 , and we have used all bound variables exactly once .",
    "the @xmath110  and @xmath111  connectives are defined similarly ( as in @xcite ) .",
    "consider a boolean circuit coded as a program : it can only evaluate to a ( coded ) true or false value , but a flow analysis identifies terms by label , so it is possible several different @xmath21  and @xmath22  terms flow out of the program . but our decision problem is defined with respect to a particular term .",
    "what we want is to use flow analysis to answer questions like `` does this program ( possibly ) evaluate to a true value ? ''",
    "we use the widget to this effect .",
    "it is a term expecting a boolean value .",
    "it evaluates as though it were the identity function on booleans , @xmath112 , but it induces a specific flow we can ask about . if a true value flows out of @xmath68 , then @xmath113 flows out of @xmath114 . if a false value flows out of @xmath68 , then @xmath115 flows out of @xmath114 , where @xmath113 and @xmath115 are distinguished terms , and the only possible terms that can flow out .",
    "we usually drop the subscripts and say `` does @xmath21flow out of @xmath114 ? '' without much ado.is affine , but this is only for simplicity in presentation .",
    "a non - affine widget is given @xcite . ]",
    "@xmath116    because the circuit value problem is complete for ptime , we conclude @xcite :    deciding the control flow problem for 0cfa is complete for ptime .",
    "a good proof has , at its heart , a small and simple idea that makes it work . for our proof , the key idea is how the approximation of analysis can be _ leveraged _ to provide computing power _ above and beyond _ that provided by evaluation .",
    "the difference between the two can be illustrated by the following term : @xmath117 consider evaluation : here @xmath118 ( a tautology ) is evaluated twice , once with @xmath13 bound to @xmath21 , once with @xmath13 bound to @xmath22 .",
    "but in both cases , the result is @xmath21 .",
    "since @xmath13 is bound to @xmath21or @xmath22 both occurrences of @xmath13 are bound to @xmath21  or to @xmath22but it is never the case , for example , that the first occurrence is bound to @xmath21 , while the second is bound to @xmath22 .",
    "the values of each occurrence of @xmath13 is dependent on the other .    on the other hand",
    ", consider what flows out of @xmath119 according 1cfa : both @xmath21  and @xmath22 . why ?",
    "the approximation incurs analysis of @xmath119 for @xmath13 bound to @xmath21  and @xmath22 , but it considers _ each occurrence of @xmath13 as ranging over @xmath21  and @xmath22 , independently_. in other words , for the set of values bound to @xmath13 , we consider their _ cross product _ when @xmath13 appears non - linearly .",
    "the approximation permits one occurrence of @xmath13 be bound to @xmath21while the other occurrence is bound to @xmath22 ; and somewhat alarmingly , @xmath120 causes @xmath22  to flow out .",
    "unlike in normal evaluation , where within a given scope we know that multiple occurrences of the same variable refer to the same value , in the approximation of analysis , multiple occurrences of the same variable range over _ all _ values that they are possible bound to _ independent of each other_.    now consider what happens when the program is expanded as follows : @xmath121 here , rather than pass @xmath13 directly to @xmath122 , we construct a unary tuple @xmath123 .",
    "the tuple is used non - linearly , so @xmath124 will range over _ closures _ of @xmath123 with @xmath13 bound to @xmath21and @xmath22 , again , independently .",
    "a closure can be approximated by an exponential number of values .",
    "for example , @xmath125 has @xmath84 free variables , so there are an exponential number of possible environments mapping these variables to program points ( contours of length 1 ) .",
    "if we could apply a boolean function to this tuple , we would effectively be evaluating all rows of a truth table ; following this intuition leads to np - hardness of the 1cfa control flow problem .",
    "generalizing from unary to @xmath84-ary tuples in the above example , an exponential number of closures can flow out of the tuple .",
    "for a function taking two @xmath84-tuples , we can compute the function on the cross product of the exponential number of closures .",
    "this insight is the key computational ingredient in simulating exponential time , as we describe in the following section .",
    "recall the formal definition of a turing machine : a 7-tuple @xmath126 where @xmath127 , @xmath128 , and @xmath129 are finite sets , @xmath127 is the set of machine states ( and @xmath130 ) , @xmath128 is the input alphabet , and @xmath129 the tape alphabet , where @xmath131 .",
    "the states @xmath132 , @xmath133 , and @xmath134 are the machine s initial , accept , and reject states , respectively .",
    "the complexity class exptime  denotes the languages that can be decided by a turing machine in time exponential in the input length .",
    "suppose we have a deterministic turing machine @xmath135 that accepts or rejects its input @xmath13 in time @xmath136 , where @xmath124 is a polynomial and @xmath137 .",
    "we want to simulate the computation of @xmath135 on @xmath13 by @xmath0cfa analysis of a @xmath6-term @xmath138 dependent on @xmath139 , where a particular closure will flow to a specific program point iff @xmath135 accepts @xmath13 .",
    "it turns out that @xmath140 suffices to carry out this simulation .",
    "the construction , computed in logarithmic space , is similar for all constant @xmath141 modulo a certain amount of padding .",
    "the first task is to code machine ids . observe that each value stored in the abstract cache @xmath51 is a _",
    "closure_a @xmath6-abstraction , together with an environment for its free variables .",
    "the number of such abstractions is bounded by the program size , as is the _ domain _ of the environment  while the number of such _ environments _ is exponential in the program size .",
    "( just consider a program of size @xmath84 with , say , @xmath142 free variables mapped to only 2 program points denoting bindings . )    since a closure only has polynomial size , and a turing machine i d has exponential size , we represent the latter by splitting its information into an exponential number of closures .",
    "each closure represents a tuple @xmath143 , which can be read as    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ `` at time @xmath144 , turing machine @xmath135 was in state @xmath145 , the tape position was at cell @xmath146 , and cell @xmath147 held contents @xmath68 . ''",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    @xmath144 , @xmath145 , @xmath146 , and @xmath147 are blocks of bits ( @xmath148 , @xmath149 ) of size polynomial in the input to the turing machine . as such , each block can represent an exponential number of values .",
    "a single machine i d is represented by an exponential number of tuples ( varying @xmath147 and @xmath68 ) .",
    "each such tuple can in turn be coded as a @xmath6-term @xmath150 , where @xmath151 .",
    "we still need to be able to generate an exponential number of closures for such an @xmath152-ary tuple .",
    "the construction is only a modest , iterative generalization of the construction in our toy calculation above : @xmath153 in the final subterm @xmath154 , the function @xmath155 acts as a very important form of _",
    "recall that this is @xmath0cfa with @xmath140the expression @xmath156 is evaluated an exponential number of times  to see why , normalize the term  but in each instance , the contour is always @xmath5 .",
    "( for @xmath141 , we would just need more padding to evade the _ polyvariance _ of the flow analyzer . ) as a consequence , each of the ( exponential number of ) closures gets put in the _ same _ location of the abstract cache @xmath51 , while they are placed in unique , _ different _ locations of the exact cache @xmath18 . in other words , the approximation mechanism of @xmath0cfa treats them as if they are all the same .",
    "( that is why they are put in the same cache location . )",
    "now we define a binary transition function @xmath31 , which does a _ piecemeal _ transition of the machine i d .",
    "the transition function is represented by three rules , identified uniquely by the time stamps @xmath144 on the input tuples .",
    "the first _ transition rule _ is used when the tuples agree on the time stamp @xmath144 , and the head and cell address of the first tuple coincide : @xmath157 this rule _",
    "computes _ the transition to the next i d .",
    "the first tuple has the head address and cell address coinciding , so it has all the information needed to compute the next state , head movement , and what to write in that tape cell .",
    "the second tuple just marks that this is an instance of the _ computation _ rule , simply indicated by having the time stamps in the tuples to be identical .",
    "the boolean functions @xmath158 compute the next state , head position , and what to write on the tape .    the second _ communication rule _ is used when the tuples have time stamps @xmath159 and @xmath144 : in other words , the first tuple has information about state and head position which needs to be communicated to every tuple with time stamp @xmath144 holding tape cell information for an arbitrary such cell , as it gets updated to time stamp @xmath159 : @xmath160 ( note that when @xmath161 , we have already written the salient tuple using the transition rule . )",
    "this rule _ communicates _ state and head position ( for the first tuple computed with time stamp @xmath159 , where the head and cell address coincided ) to all the other tuples coding the rest of the turing machine tape .",
    "finally , we define a _ catch - all rule _ , mapping any other pairs of tuples ( say , with time stamps @xmath144 and @xmath162 ) to some distinguished null value ( say , the initial i d ) .",
    "we need this rule just to make sure that @xmath31 is a totally defined function .",
    "@xmath163    clearly , these three rules can be coded by a single boolean circuit , and we have all the required boolean logic at our disposal .    because @xmath31 is a binary function , we need to compute a _ cross product _ on the coding of ids to provide its input .",
    "the transition function is therefore defined as : @xmath164 the copy functions just copy enough of the input for the separate calculations to be implemented in a linear way .",
    "observe that this @xmath6-term is entirely linear _ except _ for the two occurrences of its parameter @xmath124 . in that sense , it serves a function analogous to @xmath165 in the toy calculation .",
    "just as @xmath13 ranges there over the closures for @xmath73 and for @xmath166 , @xmath124 ranges over all possible ids flowing to the argument position .",
    "since there are two occurrences of @xmath124 , we have two entirely separate iterations in the @xmath0cfa analysis .",
    "these separate iterations , like nested `` for '' loops , create the equivalent of a cross product of ids in the `` inner loop '' of the flow analysis .",
    "the context for the turing machine simulation needs to set up the initial i d and associated machinery , extract the boolean value telling whether the machine accepted its input , and feed it into the flow widget that causes different flows depending on whether the value flowing in is @xmath73 or @xmath166 .",
    "the following context is used for these purposes : @xmath167))^\\ell)^{\\ell'})\\cdots)).\\end{aligned}\\ ] ] in this code , the @xmath155 ( with label @xmath168 on its application ) serve as padding , so that the term within is always applied in the same contour . @xmath169",
    "extracts a final i d , with its time stamp , and checks if it codes an accepting state , returning @xmath21  or @xmath22  accordingly .",
    "@xmath170  is our standard control flow test .",
    "the context is instantiated with the coding of the transition function , iterated over an initial machine i d , @xmath171 , \\end{array}\\ ] ] where @xmath172 is a coding of transition function for @xmath135 .",
    "the @xmath6-term @xmath173 is a fixed point operator for @xmath0cfa , which can be assumed to be either @xmath174 , or an exponential function composer .",
    "there just has to be enough iteration of the transition function to produce a fixed point for the flow analysis .    to make the coding easy , we just assume that @xmath135 starts by writing @xmath13 on the tape , and then begins the generic exponential - time computation",
    ". then we can just have all zeroes on the initial tape configuration .",
    "for any turing machine @xmath135 and input @xmath13 of length @xmath84 , where @xmath135 accepts or rejects @xmath13 in @xmath136 steps , there exists a logspace - constructible , closed , labeled @xmath6-term @xmath2 with distinguished label @xmath5 such that in the @xmath0cfa analysis of @xmath2 ( @xmath8 ) , @xmath73 flows into @xmath5 iff @xmath135 accepts @xmath13 .    deciding the control flow problem for @xmath0cfa with @xmath8 is complete for exptime .      at the heart of the exptime - completeness result",
    "is the idea that the _ approximation _ inherent in abstract interpretation is being harnessed for computational power , quite apart from the power of _ exact _ normalization . to get a good lower bound",
    ", this is necessary : it turns out there is a dearth of computation power when @xmath0cfa corresponds with normalization , i.e.  when the analysis is exact .    as noted earlier",
    ", approximation arises from the truncation of contours during analysis .",
    "consequently , if truncation never occurs , the instrumented interpreter and the abstract interpreter produce identical results for the given program .",
    "but what can we say about the complexity of these programs ?",
    "in other words , what kind of computations can @xmath0cfa analyze exactly when @xmath0 is a constant , independent of the program analyzed ?",
    "an answer to this question provides another point in the characterization of the expressiveness of an analysis . for 0cfa , the answer is ptime  since the evaluation of linear terms is captured .",
    "for @xmath0cfa , the answer remains the same : for any fixed @xmath0 , @xmath0cfa can only analyze polynomial time programs exactly .",
    "it is only through the use of approximation that a exponential time computation can be simulated , but this computation has little to do with the actual running of the program . a program that runs for exponential time can not be analyzed exactly by any fixed @xmath0cfa .",
    "contrast this with ml - typability , for example , where the evaluation of programs that run for exponential time can be simulated via type inference .",
    "note that if the contour is never truncated , every program point is now approximated by at most one closure ( rather than an exponential number of closures ) .",
    "the size of the cache is then bounded by a polynomial in @xmath84 ; since the cache is computed monotonically , the analysis and the natural related decision problem is constrained by the size and use of the cache .",
    "deciding the control flow problem for exact @xmath0cfa is complete for ptime .",
    "this proposition provides a characterization of the computational complexity ( or expressivity ) of the language evaluated by the instrumented evaluator @xmath54 of section [ sec : instrumented ] as a function of the contour length .",
    "it also provides an analytic understanding of the empirical observation researchers have made : computing a more precise analysis is often cheaper than performing a less precise one , which `` yields coarser approximations , and thus induces more merging .",
    "more merging leads to more propagation , which in turn leads to more reevaluation '' @xcite .",
    "@xcite make a similar observation : `` imprecision reinforces itself during a flow analysis through an ever - worsening feedback loop . ''",
    "this ever - worsening feedback loop , in which we can make @xmath22(spuriously ) flow out of @xmath175 , is the critical ingredient in our exptime  lower bound .",
    "finally , the asymptotic differential between the complexity of exact and abstract interpretation shows that abstract interpretation is strictly more expressive , for any fixed @xmath0 .",
    "we observe an `` exponential jump '' between contour length and complexity of the control flow decision problem for every polynomial - length contour , including contours of constant length .",
    "once @xmath176 ( contour length equals program size ) , an exponential - time hardness result can be proved which is essentially a linear circuit with an exponential iterator  very much like @xcite . when the contours are exponential in program length , the decision problem is doubly exponential , and so on .",
    "the reason for this exponential jump is the cardinality of environments in closures .",
    "this , in fact , is the bottleneck for control flow analysis ",
    "it is the reason that 0cfa ( without closures ) is tractable , while 1cfa is not .",
    "if @xmath177 is the contour length and @xmath84 is the program length , then @xmath178 this cardinality of environments effectively determines the size of the universe of values for the abstract interpretation realized by cfa .",
    "when @xmath0 is a constant , one might ask why the inherent complexity is exponential time , and not more  especially since one can iterate ( in an untyped world ) with the @xmath174 combinator .",
    "exponential time is the `` limit '' because with a polynomial - length tuple ( as constrained by a logspace reduction ) , you can only code an exponential number of closures .    finally , we need to emphasize the importance of linearity in static analysis .",
    "static analysis makes approximations to be tractable , but with linear terms , there is not approximation .",
    "we carefully admitted a certain , limited nonlinearity in order to increase the lower bound .",
    "our earlier work on the complexity of compile - time type inference is a precursor of the research insights described here , and naturally so , since type inference is a kind of static analysis .",
    "the decidability of type inference depends on the making of approximations , necessarily rejecting programs without type errors ; in simply - typed @xmath6-calculus , for instance , all occurrences of a variable must have the same type .",
    "( the same is , in effect , also true for ml , modulo the finite development implicit in let - bindings . )",
    "the type constraints on these multiple occurrences are solved by first - order unification .    as a consequence",
    ", we can understand the inherent complexity of type inference by analyzing the expressive power of _ linear _ terms , where no such constraints exist , since linear terms are always simply - typable . in these cases ,",
    "type inference is synonymous with normalization .",
    "this observation motivates the analysis described in @xcite .",
    "the intuition behind the correspondence between evaluation and flow analysis for linear terms can be seen as an instance of _ abstract counting _ in the extreme @xcite .",
    "abstract counting is a technique for reasoning about the behavior of a program that _ must _ occur when a program is run , based solely on abstract information that describes what _ may _ occur .",
    "when an abstract value is a singleton set , the abstract object is effectively rendered concrete @xcite .",
    "in other words , when only one thing may happen , it must .",
    "linearity maintains singularity , and analysis is therefore completely concrete .",
    "our coding of turing machines is descended from earlier work on datalog ( prolog with variables , but without constants or function symbols ) , a programming language that was of considerable interest to researchers in database theory during the 1980s ; see @xcite .    in @xmath0cfa and abstract interpretation more generally",
    ", an expression can evaluate to a set of values from a finite universe , clearly motivating the idiom of programming with sets .",
    "relational database queries take as input a finite set of tuples , and compute new tuples from them ; since the universe of tuples is finite and the computation is monotone , a fixed - point is reached in a finite number of iterations . the machine simulation here follows that framework very closely .",
    "even the idea of splitting a machine configuration among many tuples has its ancestor in @xcite , where a ternary @xmath179 is used to simulate a cons - cell at memory address @xmath180 , with pointers @xmath181 .",
    "it needs emphasis that the computing with sets described in this paper has little to do with normalization , and everything to do with the approximation inherent in the abstract interpretation .",
    "this coding of boolean logic in linear @xmath6-calculus , which was previously given in @xcite and is briefly described again here for completeness , improves upon @xcite in that it allows uniform typing , and does not create garbage .",
    "the encoding in @xcite in turn is an improvement of the church encodings in that they are linear and non - affine .",
    "although @xmath0cfa and ml type inference are two static analyses complete for exptime  @xcite , the proofs of these respective theorems is fundamentally different .",
    "the ml proof relies on type inference simulating exact normalization ( analogous to the ptime - completeness proof for 0cfa ) , hence subverting the approximation of the analysis .",
    "in contrast , the @xmath0cfa proof harnesses the approximation that results from nonlinearity .",
    "recent work by @xcite and @xcite has examined various techniques for reducing the imprecision of flow analysis via _ abstract garbage collection _ and _ abstract counting_. might and shivers observe that by eliminating spurious flows , not only is the precision improved , but this often leads to improved running times of the analyzer .",
    "our theorems reinforce these observations and shed light on what might otherwise seems like a paradoxical situation : `` in many cases , higher speed is a direct consequence of higher precision . ''",
    "when the analysis is at its most precise , it is always computable quickly . on the other hand , wielding the full power of spurious flows results in exptime - completeness .",
    "in essence , @xmath0cfa is hard _ because of _ the spurious flows that it must compute . in this light ,",
    "techniques such as abstract garbage collection undermine our lower bound proofs , making it unclear what complexity bounds exist for these enhanced analyses .",
    "empirically observed increases in costs can be understood analytically as _ inherent in the approximation problem being solved_.      the proof relies on previous insights about linearity , static analysis , and normalization ( namely , when a term is linear , static analysis and normalization are synonymous ) ; coupled with new insights about using non - linearity to realize the full computational power of approximate , or abstract , interpretation .",
    "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ despite all this work on formalising cfa and speeding it up , i have been disappointed in the dearth of work extending its _ power_. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    this work has shown that work spent on speeding up @xmath0cfa is an exercise in futility ; there is no getting around the exponential bottleneck of @xmath0cfa .",
    "the one - word description of the bottleneck is _ closures _ , which do not exist in 0cfa , because free variables in a closure would necessarily map to @xmath182 , and hence the environments are useless .    as for extending its power , from a complexity perspective",
    ", we can see that 0cfa is strictly less expressive than @xmath0cfa . in turn",
    ", @xmath0cfa is strictly less expressive than , for example , mossin s flow analysis @xcite .",
    "mossin s analysis is a stronger analysis in the sense that it is exact for a larger class of programs than 0cfa or @xmath0cfa  it exact not only for linear terms , but for all simply - typed terms . in other words ,",
    "the flow analysis of simply - typed programs is synonymous with running the program , and hence non - elementary .",
    "this kind of expressivity is also found in burn - hankin - abramsky style strictness analysis @xcite .",
    "but there is a considerable gap between @xmath0cfa and these more expressive analyses .",
    "what is in between and how can we build a real _ hierarchy _ of static analyses that occupy positions within this gap ?",
    "lvy s notion of labeled reduction @xcite provides a richer notion of `` instrumented evaluation '' coupled with a richer theory of exact flow analysis , namely the geometry of interaction . with the proper notion of abstraction and simulated reduction",
    ", we should be able to design more powerful flow analyses , filling out the hierarchy from 0cfa up to the expressivity of mossin s analysis in the limit .",
    "g.  l. burn , c.  l. hankin , and s.  abramsky . the theory of strictness analysis for higher order functions . in h.",
    "ganzinger and n.  jones , editors , _ programs as data objects _ , pages 4262 , new york , ny , usa , 1985 .",
    "springer - verlag .",
    "isbn 0 - 387 - 16446 - 4 .",
    "haim gaifman , harry mairson , yehoshua sagiv , and moshe  y. vardi .",
    "undecidable optimization problems for database logic programs .",
    "_ j. acm _ , 400 ( 3):0 683713 , 1993 .",
    "issn 0004 - 5411 .",
    "doi : http://doi.acm.org/10.1145/174130.174142 .",
    "suresh jagannathan , peter thiemann , stephen weeks , and andrew wright .",
    "single and loving it : must - alias analysis for higher - order languages . in _",
    "popl 98 : proceedings of the 25th acm sigplan - sigact symposium on principles of programming languages _ , pages 329341 , new york , ny , usa , 1998 .",
    "isbn 0 - 89791 - 979 - 3 .",
    "doi : http://doi.acm.org/10.1145/268946.268973 .",
    "neil  d. jones .",
    "flow analysis of lambda expressions ( preliminary version ) . in _ proceedings of the 8th colloquium on automata , languages and programming _ , pages 114128 , london , uk , 1981 .",
    "springer - verlag .",
    "isbn 3 - 540 - 10843 - 2 .",
    "harry  g. mairson .",
    "deciding ml typability is complete for deterministic exponential time . in _",
    "popl 90 : proceedings of the 17th acm sigplan - sigact symposium on principles of programming languages _ , pages 382401 , new york , ny , usa , 1990 .",
    "isbn 0 - 89791 - 343 - 4 .",
    "doi : http://doi.acm.org/10.1145/96709.96748 .",
    "matthew might and olin shivers . improving flow analyses via @xmath129cfa : abstract garbage collection and counting . in _",
    "icfp 06 : proceedings of the eleventh acm sigplan international conference on functional programming _ , pages 1325 , new york , ny , usa , 2006 .",
    "isbn 1 - 59593 - 309 - 3 .",
    "doi : http://doi.acm.org/10.1145/1159803.1159807 .",
    "peter  mller neergaard and harry  g. mairson .",
    "types , potency , and idempotency : why nonlinearity and amnesia make a type system work . in _ icfp 04 : proceedings of the ninth acm sigplan international conference on functional programming _ , pages 138149 , new york , ny , usa , 2004 .",
    "acm press .",
    "isbn 1 - 58113 - 905 - 5 .",
    "doi : http://doi.acm.org/10.1145/1016850.1016871 .",
    "flemming nielson and hanne  riis nielson .",
    "infinitary control flow analysis : a collecting semantics for closure analysis . in _",
    "popl 97 : proceedings of the 24th acm sigplan - sigact symposium on principles of programming languages _ , pages 332345 , new york , ny , usa , 1997 .",
    "isbn 0 - 89791 - 853 - 3 .",
    "doi : http://doi.acm.org/10.1145/263699.263745 .",
    "olin shivers . control flow analysis in scheme . in _",
    "pldi 88 : proceedings of the acm sigplan 1988 conference on programming language design and implementation _ , pages 164174 , new york , ny , usa , 1988 .",
    "isbn 0 - 89791 - 269 - 1 .",
    "doi : http://doi.acm.org/10.1145/53990.54007 .",
    "olin shivers .",
    "higher - order control - flow analysis in retrospect : lessons learned , lessons abandoned .",
    "_ sigplan not .",
    "_ , 390 ( 4):0 257269 , 2004 .",
    "issn 0362 - 1340 .",
    "doi : http://doi.acm.org/10.1145/989393.989421 .",
    "david van horn and harry  g. mairson . relating complexity and precision in control",
    "flow analysis . in _",
    "icfp 07 : proceedings of the 2007 acm sigplan international conference on functional programming _ , pages 8596 , new york , ny , usa , 2007 . acm press .",
    "isbn 978 - 1 - 59593 - 815 - 2 .",
    "doi : http://doi.acm.org/10.1145/1291151.1291166 .",
    "david van horn and harry  g. mairson .",
    "linearity , flow analysis , and ptime . in mara alpuente and germn vidal , editors , _ the 15th international static analysis symposium , sas 2008 _ , volume 5079 of _ lecture notes in computer science _ , pages 255269 .",
    "springer , july 2008 .",
    "andrew  k. wright and suresh jagannathan .",
    "polymorphic splitting : an effective polyvariant flow analysis .",
    "acm trans .",
    "_ , 200 ( 1):0 166207 , 1998 .",
    "issn 0164 - 0925 .",
    "doi : http://doi.acm.org/10.1145/271510.271523 ."
  ],
  "abstract_text": [
    "<S> we give an exact characterization of the computational complexity of the @xmath0cfa hierarchy . for any @xmath1 , </S>",
    "<S> we prove that the control flow decision problem is complete for deterministic exponential time . </S>",
    "<S> this theorem validates empirical observations that such control flow analysis is intractable . </S>",
    "<S> it also provides more general insight into the complexity of abstract interpretation .    </S>",
    "<S> [ program analysis ] [ computability theory , computational logic , lambda calculus and related systems ]    languages , theory    flow analysis , complexity </S>"
  ]
}