{
  "article_text": [
    "classification of dynamic radar signals from exo - atmospheric objects is an important problem for military and space applications .",
    "obviously different shapes and sizes can have significantly different meaning .",
    "pebble - sized objects have little direct military interest as potential missiles . however , pebble - sized objects can be of great interest for space craft survival . to keep our problem simple and to allow us to explore a new classification algorithm ,",
    "we will focus on four types of objects ; cylinders , frusta , spheres , and irregular flat polygons , ranging in size from centimeters to meters .",
    "geometric shapes of exo - atmospheric objects can be determined by analysis of the returned radar cross section ( rcs ) signatures  @xcite . though some work has been done on computing the geometry from rcs  @xcite ,",
    "the approach is generally not effective . because the rcs signatures are unique patterns for different geometric types",
    ", this suggests using machine learning techniques for pattern recognition . a vast literature exists for pattern recognition of many types of signals , signatures , and images",
    ". some of the most widely used are neural networks , bayesian networks , and support vector machines ( svm )",
    ". to use these pattern recognition systems generally requires a database of pairs of signatures and classes . in our case",
    "this would be a database of synthesized rcs returns from representative frusta , cylinders , spheres , and polygons .",
    "machine learning techniques generally require two stages : one for training a system to learn how to separate geometric classes and a second for classifying new data as it arrives .",
    "the data used for our studies are simulated rcs returns from multiple geometric shapes .",
    "accuracy is represented as an average of the percent correct , while precision is represented by measuring the standard deviation from a batch of runs consisting of training followed by testing and re - randomizing .",
    "depending on the desired application , we may require pattern recognition from rcs signatures be done quickly so that decisions for dealing with this information can be made in a timely manner .",
    "this requires that the computational burden be minimized while maintaining the highest degree of accuracy .",
    "the three common pattern recognition methods mentioned above could potentially be fast enough for these applications .",
    "each approach has its own advantages and disadvantages .",
    "all three methods require a database of labeled signatures .",
    "generally , neural networks require at least three times as many data samples ( preferably ten times as many ) for training as the input dimensionality .",
    "so if our rcs signatures consist of 1,000 data points , then we need 10,000 labeled signatures .",
    "this is potentially not a problem for synthesized databases .",
    "however , as the input dimensionality increases , the number of samples goes up . in many cases",
    "this is , or will quickly become , a problem . during training of the neural network",
    ", there is invariably a good chance the learning algorithm will converge to a local minimum in the nonlinear hyperspace of the weights .",
    "this can result in poor generalization or poor performance on testing and evaluation samples .",
    "neural networks could be very fast for rcs pattern recognition because once the network is trained , the evaluation simply consists of a few vector - matrix multiplications and some function applications to vectors .",
    "specifically , if we used a single hidden layer perceptron with 1,000 inputs and ten nodes in the hidden layer and one output , a new rcs classification would consist of multiplication of one 1000-element vector with a @xmath0 element matrix to produce a ten - element vector to which we then apply a hyperbolic tangent for each element , followed by another vector - matrix product , in this case a ten - element vector by a @xmath1 element matrix",
    ". the total would be on the order of 10  mflops .",
    "clearly the neural network could provide good speed , but the performance is not adequate for most applications , especially applications requiring significant accuracy .",
    "neural networks also have the advantage that significant preprocessing or feature extraction of the rcs signatures may not necessarily be required .",
    "farhat  @xcite conducted early research on using neural networks for automated target identification , but not from rcs .",
    "his approach was more concerned with image reconstruction from microwave signatures and image recognition . at the image recognition step , he applied the neural networks . a good reference of neural networks and their use is  @xcite .",
    "an alternative pattern recognition method that could be used for our rcs analysis is a bayesian network  @xcite .",
    "the bayesian approach also requires a massive amount of data for training .",
    "it also requires pre - computation of the moments of the distributions of the data .",
    "this would necessarily require a , perhaps massive , reduction in dimensionality to apply bayesian techniques to spectral identification and rcs signature classification .",
    "the approach typically involves extracting some features from the signatures or spectra and using that population of features for the computation by the bayesian methods .",
    "as we will see , the pre - calculation of features often is quite time - consuming .",
    "this paper reports our use of support vector machine ( svm )  @xcite@xcite .",
    "similar to the other methods , it requires a database of labeled rcs signatures .",
    "the svm has a number of distinct advantages over the other two techniques .",
    "unlike the neural network , it is not too likely that the training will get stuck in some nonlinear space , because the data are first transformed to a linear space , albeit , perhaps of very high - dimensionality .",
    "consequently there is a global minimum and the performance results can be far better than a neural network . secondly , unlike the bayesian network the svm can accept very high - dimensional input vectors without preprocessing .    in the following sections we discuss construction of an rcs database for frusta , spheres , cylinders and polygons .",
    "we then discuss an svm for rcs signature classification and compare the results with a bayesian approach .",
    "three synthetic data sets were used to train and test the svm .",
    "the data sets ranged from simple radar cross section ( rcs ) versus viewing aspect angle tables to complex simulations of scenarios incorporating multiple radars operating at different frequencies and locations .",
    "most of the results presented in this paper are based upon a group of data sets of intermediate complexity , incorporating rcs versus viewing aspect for four object shapes of varying size and viewing aspect angle at two commonly used radar wavelengths , 3-ghz ( s - band ) and 10-ghz ( x - band ) .",
    "the four shapes evaluated are :    1 .",
    "spheres with radii varying from 0.0012 m. 2 .   cylinders with diameters from 0.52 m and lengths from 112 times the diameter ( 120 m range ) .",
    "frusta , blunt nosed cones , with heights ( the distance from the nose to the tail ) of 0.52 m , tail diameters from 25100% the height , and nose diameters of 530% the tail diameter .",
    "4 .   flat plate polygons with 3 to 5 edges with a maximum feature size of 0.36 m.      the rcs , @xmath2 ,",
    "for each of these objects is a function of frequency , @xmath3 , and , for all objects except for the sphere , viewing aspect angle @xmath4 .",
    "the rcs models for the objects were drawn from a number of sources and each is unique .",
    "the rcs model for the sphere was adapted from  @xcite and includes three regions :    optical @xmath5 rayleigh @xmath6 and the mie region , where the rcs is approximated using spherical bessel functions .",
    "the rcs model of a right cylinder used in this study is @xmath7 where @xmath8 is the radius of the cylinder , @xmath9 is the cylinder length , and @xmath10 is the angle from broadside incidence .",
    "this solution is derived in knott  @xcite using physical optics . because this solution becomes singular when @xmath11 , we substitute in the exact broadside solution @xmath12 when @xmath13 . because equation [ eqn : cyl ] does not account for the cylinder end caps , we employ the theory of superposition and add the rcs of a circular plate @xmath14 and @xmath15 where @xmath16 corresponds to normal incidence  @xcite .",
    "figure  [ f : cyl ] shows both the s and x band rcs versus aspect angle for a 0.5  m by 5  m long cylinder .    for the frustum , we elected to use a classic set of formulas from  @xcite , which utilizes the geometric theory of diffraction to predict the rcs of a frustum using 4 scattering centers : @xmath17 figure  [ f : scatter ]",
    "shows the locations of the four scattering centers and the key dimensions defining the frustum model .    assuming that the radar is monostatic , the contribution of the 4 scatterers is @xmath18 &   \\theta\\leq\\pi-\\alpha \\\\   0 & \\theta>\\pi-\\alpha \\end{array } \\right .",
    "\\label{eqn : sigma1 } \\\\",
    "\\sqrt{\\sigma_2}&=&\\left\\ { \\begin{array}{cc } g_2 \\left [ \\left(m_2-\\cos\\left(\\frac{3\\pi-2\\theta}{\\eta_2 } \\right)\\right)^{-1}\\mp\\left(m_2 - 1 \\right)^{-1}\\right ] &   \\theta\\geq-\\alpha \\\\   0 & \\theta<\\-\\alpha \\end{array } \\right .",
    "\\label{eqn : sigma2 } \\\\",
    "\\sqrt{\\sigma_3}&=&\\left\\ { \\begin{array}{cc } g_1 \\left [ \\left(m_1-\\cos\\left(\\frac{\\pi-2\\theta}{\\eta_1 } \\right)\\right)^{-1}\\mp\\left(m_1 - 1 \\right)^{-1}\\right ] &   \\theta\\leq\\pi/2 \\\\   0 & \\theta>\\pi/2 \\end{array } \\right .",
    "\\label{eqn : sigma3 } \\\\",
    "\\sqrt{\\sigma_4}&=&\\left\\ { \\begin{array}{cc } g_2 \\left [ \\left(m_2-\\cos\\left(\\frac{3\\pi+2\\theta}{\\eta_2 } \\right)\\right)^{-1}\\mp\\left(m_2 - 1 \\right)^{-1}\\right ] &   \\theta\\leq-\\alpha \\\\   0 & \\pi/2>\\theta>\\alpha",
    "\\\\   g_2 \\left [ \\left(m_2-\\cos\\left(\\frac{-\\pi+2\\theta}{\\eta_2 } \\right)\\right)^{-1}\\mp\\left(m_2 - 1 \\right)^{-1}\\right ] &   \\theta\\leq\\pi/2 \\end{array } \\right .",
    "\\label{eqn : sigma4}\\end{aligned}\\ ] ] with @xmath19 and the phases referenced to the base of the frustum are given by @xmath20+\\pi/2 \\\\",
    "\\rho_2&=&-2ka_2\\sin\\theta+\\pi/4 \\\\ \\rho_3&=&2k[a_1\\sin\\theta-2\\cos\\theta]-\\pi/4",
    "\\\\ \\rho_4&=&2ka_2\\sin\\theta-\\pi/4\\end{aligned}\\ ] ] where @xmath21 is the frustum angle in radians @xmath22 and @xmath23 and where @xmath4 is the viewing aspect as measure along the axis of symmetry from the large end of the frustum ( @xmath24 ) .",
    "the choice of signs in equations [ [ eqn : sigma1]]-[[eqn : sigma4 ] ] relate to the polarization convention ( upper sign for vertical polarization , lower sign for horizontal polarization ) . for this analysis",
    ", we assumed vertical polarization . as is the case for the cylinder , this solution has singularities at @xmath25 .",
    "these singularities have been handled as described in  @xcite .",
    "figure  [ f : frustum ] shows both the s- and x - band rcs versus aspect angle for a frustum where @xmath26  m , @xmath27  m , and @xmath28  m , as shown in figure  [ f : frustum ] .",
    "lastly for the @xmath29-sided polygon , we applied a physical optics solution from  @xcite , where the expression for an arbitrary @xmath29-sided polygon in a local cordinate frame has been evaluated analytically as @xmath30\\ ] ] where @xmath31 are the polygon vertices and @xmath32 are the edge vectors given by @xmath33 and @xmath34 .",
    "figure  [ f : poly ] shows a randomly generated five - sided polygon , typical of those generated for use in this study .",
    "figure  [ f : polyrcs ] shows the calculated rcs for the polygon shown in figure  [ f : poly ] when it is rotated about the axis shown in figure  [ f : poly ] ( @xmath35 represent the edge on condition ) .      now that we have defined the objects that are going to be incorporated into data sets we need to use these models to generate simulated radar data .",
    "ideally we would like to train the svm using data similar to what would be observed in an actual engagement but for simplicity we started with a scenario similar to what one would encounter on a radar test range .",
    "the first set of data consisted of 10,000 randomly generated frusta and cylinders whose rcs versus aspect angle were calculated using 2,000 evenly spaced samples from 0180@xmath36 .",
    "once the performance of the svm had been verified using this data set , we increased the difficulty of the problem by varying the aspect through which each object was rotated .",
    "the second data set consisted of randomly generated frusta , cylinders , spheres , and polygons rotated through an aspect starting at 0@xmath36 and ending at @xmath37 ( the rcs was calculated at 2,000 evenly distributed points through this rotation ) .",
    "there were 5,000 data vectors for each object type , resulting in a total of 20,000 data vectors .",
    "the final data set consisted of 20,000 randomly generated frusta , cylinders , spheres , and polygons rotated from a random start angle with a minimum rotation of 180@xmath36 and a maximum rotation of 1080@xmath36 .",
    "figure  [ f : train ] shows the rcs versus sample for six objects in the final data set , with sample being the sampled aspect angle .    summarizing , our data consisted of three data sets .",
    "the first data set comprised 4930 cylinders and 5070 frusta for a total of 10,000 objects , approximately a 50% distribution between the two classes .",
    "the data for each object consisted of 2,000 rcs values , starting at broad - side specular to an observing monostatic radar and rotating one - half revolution .",
    "the axis of rotation was normal both to the axis of symmetry of the object and the direction of observer .",
    "the frequency was selected at random from one of the following four frequencies : 900  mhz , 3  ghz , 6  ghz , and 10  ghz , simulating four different viewers .",
    "the rcs can be obtained from a radar return given an object s range and the gain from the radar station , and varying it across azimuth simulates the changing perspective an observing ground radar would have of dynamic objects .    the second data set comprised objects from four different classes : cylinders , frusta , spheres , and random polygonal plates .",
    "the data for each object consisted of 2,000 radar cross - section ( rcs ) values for each object at a @xmath38-placement relative to an observing mono - static radar and rotating at a random rate with revolution over the 2,000 values ranging between one and five periods .",
    "five thousand objects were generated in each of the four classes , with varying lengths and radii , resulting in 20,000 total objects .",
    "again the data set consisted of the four frequencies for data set  1 .",
    "the third data set replicated the second data set , except that the starting angle to each observer was chosen randomly . also , the returns for each object at s - band ( 3  ghz ) and x - band ( 10  ghz ) frequencies , effectively simulated the returns from two separate ground radars observing the same object .",
    "this effectively doubles the amount of data for each object , _",
    "i.e. , _ the length of each vector .",
    "our goal was to combine the two radar signatures , via sensor fusion , to improve classification and identification .",
    "having synthesized the rcs data , we are ready to begin the processing with the support vector machine ( svm ) .",
    "the following theoretical outline is similar to vapnik  @xcite .",
    "given our set of labeled training pairs of rcs signatures and class labels for what they represent we can write this as follows : @xmath39 @xmath40 @xmath41 @xmath42 , where @xmath43 represents the rcs signature and @xmath44 represents the class label ( sphere , frustum , cylinder , polygon ) .",
    "to simplify the problem , we will label an rcs signature as @xmath45 if it represents a cylinder and @xmath46 if it represents anything else .",
    "we thus partition our data set into four labeled groups , depending on the object type . as described above in section  [",
    "s : rcs ] , each object - type data set consists of 5,000 rcs signatures .",
    "we can now form a separating hyperplane as follows :    @xmath47    where we see the output classes are @xmath46 and @xmath45 . the inequalities in the above equation can be written as : @xmath48 for @xmath49 training samples .",
    "the relations in this equation become constraints for the optimal hyperplane given by @xmath50 where @xmath51 is a constant known as the bias .",
    "this is the unique hyperplane for maximum separation of the training data .",
    "the vectors ( rcs signatures ) for which the left - hand - side is equal to 1 are called the support vectors .",
    "the optimal separating hyperplane is : @xmath52where @xmath53 .",
    "if we let @xmath54 then we could solve the quadratic programming problem . basically we want to maximize @xmath55\\ ] ] subject to the constraints @xmath56 where @xmath57 is a vector of labels ; @xmath58 is a unit vector ; @xmath59 is an @xmath60 matrix with elements given by @xmath61 with @xmath62 ; and @xmath63 are the weights for the support vectors and @xmath64 is a constant analogous to bias .",
    "the classifier function is now @xmath65 the values @xmath66 are the transformed objects in feature space .",
    "we can rewrite the function as @xmath67 or more compactly as @xmath68    this kernel representation is the conventional way of representing a support vector machine . as pointed out above",
    ", we could find the support vector weights , @xmath69 , by quadratic programming .",
    "instead , we will use the perceptron algorithm when combined with an svm , also known as a kernel adatron .",
    "the algorithm is basically a gradient descent in error space to find the support vectors .",
    "veropoulus  @xcite is a good reference for the kernel adatron method .",
    "there are several available methods for computing kernels for svms .",
    "these include the linear kernel , the polynomial kernel , the radial basis function ( rbf ) kernel , and the hyperbolic tangent kernel . in this analysis ,",
    "only the linear kernel was used .",
    "the linear kernel is computed on the @xmath70 matrix containing the training vectors as a covariance matrix calculation , @xmath71 where @xmath72 is a symmetric , positive definite matrix .",
    "the resulting kernel can then be normalized by : @xmath73    once @xmath72 has been computed , a gradient descent process is used to determine whether or not each vector is a support vector .",
    "@xmath74 support vectors are selected from the initial @xmath75 training vectors .",
    "after the learning process converges the location of the non - zero elements in the @xmath76 vector , an @xmath75-dimensional vector , are pointers to the support vectors .",
    "the actual value of the non - zero elements in this @xmath76 vector are the coefficients for the testing phase .",
    "a vector under test , in this case an rcs signature , @xmath77 , can be classified by computing the dot - product of @xmath77 with each support vector , @xmath78 , scaling each result by @xmath21 and the response , @xmath79 , of each support vector .",
    "the responses for the support vector are @xmath45 for positive cases and @xmath46 for negative cases .",
    "the vector under test is evaluated according to : @xmath80 if @xmath81 , the object under test is classified as belonging in the set ; otherwise it is classified as being outside the set .",
    "from the 10,000 objects in the first data set , two trials of training took place : one with 400 randomly selected objects , with testing on the remaining 9,600 ; and one with 4,000 randomly selected objects , with testing on the remaining 6,000 .",
    "all tests were repeated ten times ( ten - fold cross - validation ) to obtain statistical measurement for accuracy and precision .    from the 20,000 objects in the second set ,",
    "4,000 were randomly selected for training the kernel adatron .",
    "the remaining 16,000 objects were then tested against the support vectors and the weight vector , @xmath76 .",
    "tests were performed for each of these four classes using a separately - trained svm classifier :    * cylinder _ vs. _ non - cylinder * frustum _ vs. _ non - frustum * sphere _ vs. _ non - sphere * polygons _ vs. _ non - polygons    all tests were repeated ten times .    from the 20,000 objects in the third data set ,",
    "8,000 were randomly selected for training the kernel .",
    "the remaining 12,000 objects were then tested against that kernel .",
    "four tests were performed for each of the classes , as in the second data set .",
    "all the tests were repeated twenty times ( twenty - fold cross - validation ) .",
    "we used the kernel adatron algorithm presented on pages  8081 in  @xcite , with fixed values of @xmath82 , @xmath83 , and a threshold of 5,000 .",
    "these values affect the selection of the support vectors , and thus the classification results . however , they remained fixed for the purpose of these numerical trials .",
    "table  [ t : desc ] describes each experiment performed , including the data set used , the number of vectors used for training and testing , the length these each vectors compared to the ones in that data set , and other descriptive information .    .[t",
    ": desc]summary of the experiments ( see text for more details ) . [ cols= \"",
    "> , > , > , > , < , < \" , ]     when using just one - quarter of the 2,000 samples per object , corresponding to @xmath84 of revolution , results could be little better than a random guess ( 50% ) depending on the swath visible to the observer ; these results are not included in table  [ t : results1 ] . at this point ,",
    "testing began on data processed by a fourier transform instead of the raw azimuthal rcs values .",
    "only the magnitude values of the data in the were used .",
    "the data were normalized by the magnitude of the dc component ( the first value ) .",
    "repeating the above tests resulted in @xmath85 with 400 randomly selected training objects and 9600 testing objects , decomposed as shown in experiment  3 of table  [ t : results1 ] .",
    "training over 4,000 objects and testing on 6,000 objects resulted in @xmath86 , with the results shown in experiment  4 of table  [ t : results1 ] .",
    "these results compare well to using the raw rcs values .",
    "when only a quarter of the rcs data were selected , results match those of the raw rcs , which depend on the visible swath of data to contain distinguishing characteristics .",
    "however , an svm is dependent on data being placed in the same place in the data vector . because we will not know the aspect angle to the observer , raw rcs returns are not as useful .",
    "fourier - transformed data places information in the same feature bins of each data vector , and this now removes this issue for svm training .    when a kaiser window was applied to the data , the results do not change significantly . using 4,000 randomly - selected training samples , following a fourier transform , of objects and testing on the remaining 6,000 objects , the results without the window were @xmath87 , as shown in experiment  5 of table  [ t :",
    "results1 ] ; while with the window , the results were @xmath88 , decomposed as shown in experiment  6 of table  [ t : results1 ] ( marked as fft - w in table  [ t : desc ] ) .",
    "this shows that windowing did not significantly affect the results .",
    "testing with this set now shows results when the amount of rotation is not fixed to one revolution but instead corresponds to a random number of full revolutions ( marked as 110 rot . in table",
    "[ t : desc ] ) , up to ten , for each object .",
    "now that we have four objects with equal populations in the data set , a random guess can be considered 75% accurate because stating everything is not in the class would be correct 3/4 of the time .",
    "all testing is performed on data following a fourier transform , with the dc component ( marked as fftdc in table  [ t : desc ] ) normalized to unity .    using the full - length 2,000-point rcs data , training on a randomly - selected 4,000 objects , and testing on the remaining 6,000 objects ,",
    "the results were those shown in experiments  7 of table  [ t : results2 ] .",
    "the svm correctly identified the objects as cylinders 99.6% of the time , frusta 93.2% of the time , spheres 100% of the time , and polygons 83.8% of the time .",
    "tests using the second and third data sets used the four separately - trained svm classifiers .",
    "training on consecutive , one - quarter - length swaths and testing with one - quarter - length data swaths , gave the results shown in experiments  811 of table  [ t : results2 ] .",
    "the results from these tests make sense . keeping in mind that the starting point for all objects in this data set is at @xmath89 , which is nose - on to the observer while @xmath90 is broadside , and the objects each rotate at random speeds , the first quarter contains little useful information to distinguish a cylinder from a frustum .",
    "compare the rcs returns of figure  [ f : cyl ] and figure  [ f : frustum ] for aspect angles @xmath38  @xmath91 to see the difficulty in correctly classifying objects using only the first quarter of the data .",
    "spheres are always easy to distinguish given the uniform rcs returns at every aspect angle .",
    "polygons are expected to be difficult to distinguish given they exhibit different rcs return behavior with their varying sizes and number of sides .",
    "proceeding from quarter to quarter , the chance of including useful rcs information increases , albeit not linearly .",
    "the third data set corrects this by starting at a random aspect angle to the observer .",
    "all the data in the third data set was processed by a fourier transform and normalized to unity dc .",
    "each object has two sets concatenated together , one for s - band returns and one for x - band returns .",
    "the third data set trains on 8,000 randomly selected objects . using",
    "2,000 rcs data points from both ground observers resulted in what is shown in experiment  12 of table  [ t : results2 ] .",
    "the objects were identified correctly as cylinders 99.6% of the time , frusta 84.9% of the time , spheres 100% of the time , and polygons 88.3% of the time .",
    "when using a random swath of 500 consecutive time samples for each object , instead of the full 2,000 , we get the results shown in experiment  13 of table  [ t : results2 ] .",
    "the results for the correct identification of objects fell slightly , with cylinders at 91.8% , frusta at 78.2% , spheres at 100% , and polygons at 85.3% .",
    "the first four moments , mean , variance , skew , and kurtosis , were appended as data points to the fourier - transformed vector for each object .",
    "these are the first four moments of the rcs data normalized so the largest moment has a value of one ( marked as moments in table  [ t : desc ] ) .",
    "these were computed for both the x - band and the s - band data sets , resulting in eight additional data points .",
    "the results of repeating these tests with the augmented data for the quarter - length data are as shown in experiment  14 of table  [ t : results2 ] .",
    "these resulted in significantly improved identification , with cylinders at 99.4% , frusta at 95.3% , spheres at 100% , and polygons at 95.6% .",
    "we have shown that it is possible to obtain very good classification of synthesized rcs signatures following a fourier transform , with little or no other preprocessing .",
    "this reduction in computational load can have significant impact in some applications .",
    "this direct testing on fourier - transformed data obviates handling the starting aspect angle of data collection ; the additional features , such as the first four statistical moments of the rcs data ( mean , variance , skew , and kurtosis ) , may be added to an input vector to improve accuracy .",
    "table  [ t : results2 ] contains a summary of the results for all the numerical experiments .",
    "accuracy is measured as an overall percentage correct , with ten - fold ( data set  1 ) or twenty - fold cross - validation ( data sets  2 and  3 ) . in an actual scenario , knowledge of the aspect angle of the object to the observer would not be known .",
    "also , there is no guarantee that a full revolution of the object will be viewed .",
    "therefore , the results from experiments  13 and 14 are likely closest to actual . because the overall results from experiment  14 are better , using the moments should provide enhanced performance .",
    "experiment  14 provides a start at reasonable results for an actual scenario .    in order to relate our svm results with another technique",
    ", we compared them to a bayesian network .",
    "bayesian networks are a popular technique for pattern recognition and classification  @xcite@xcite .",
    "the basic concept is to combine conditional probabilities using bayes theorem .",
    "donald maurer of johns hopkins university , applied physics laboratory , has applied the bayesian technique to the identification of cones and cylinders  @xcite .",
    "his initial starting point was rcs data from which he extracted several features .    as described in maurer s paper , he used data of this type to build the bayesian network .",
    "data were processed as ten - degree aspect angle increments .",
    "the best overall performance by the bayesian approach classifies cylinders from cones correctly 99% of the time  @xcite .    for comparison",
    ", we used maurer s data and processed it by a svm .",
    "the features of the data were analyzed using the kernel adatron .",
    "the four features that most contributed to identification in a bayesian classifier were selected from both the cone and cylinder data sets  @xcite .",
    "these comprise one object each , with features from azimuths in the range 0 to 180@xmath36 in one - tenth - degree increments .",
    "ten - degree swaths of each of the four features were used to compose the data for each vector , giving each vector a length of 400 features .",
    "1700 vectors were created for the cone , and 1700 for the cylinder .",
    "the kernel adatron trained on 1700 randomly selected vectors , and tested on the remaining 1700 , in a twenty - fold cross - validation process .",
    "the results show that , statistically , they are equivalent to a random guess ( 52.1% correct @xmath92% ) . given that the features at each azimuth do not necessarily correspond to those at other azimuths , this comes as no surprise .",
    "it is difficult to distinguish an object given a swath of features related to an azimuth ; much easier by applying a fourier transform on the data , fixing the data in the bins regardless of the azimuth viewed .",
    "there is nothing exclusive about the bayesian success with these features ; to wit , results from support vector machines on data could be combined with results from bayesian belief networks to arrive at a classification more accurate than either could provide .",
    "our results on our fft - preprocessed , synthesized rcs returns with the kernel adatron that was then processed by the svm results in the following performance : spheres , 100% ; cylinders , 99.4% ; frustum , 95.3% ; polygons , 95.6% .",
    "these results are comparable to the bayesian approach with feature extractions .",
    "further , our results are more comprehensive because the individual svm is classifying the spheres , cylinders , frusta ( more complex than cones ) , and polygons .",
    "the computation load with the svm ( including prior feature extraction of fft ) is about 2 mflops .",
    "the computational load with feature extraction and identification by the bayesian method is 2 gflops  @xcite , a three - orders - of - magnitude greater computational load ) .",
    "the main problem with the work in  @xcite is the significant preprocessing and feature extraction from the rcs data prior to submitting the information to the bayesian network .    in conclusion , the kernel adatron , a support vector machine , classifies objects at least as well as the conventional bayesian network in  @xcite for rcs signature classification , with far fewer computational operations required .",
    "it is especially applicable to time - critical applications where false negatives may have devastating consequences  @xcite@xcite@xcite .",
    "this paper has been approved for public release . achieving these results came from the contributing work of peter nebolsine and peter mayer .",
    "they provided the simulated rcs data , several reviews of the results , and suggestions for proceeding forward .",
    "the authors are grateful for their contributions .",
    "the authors also thank the us army space & missile command for their support in conducting this research .",
    "we thank donald maurer for providing us with feature data , and merlin miller , norman humer , and mark merritt for their assistance .",
    "maurer , schirmer , kalandros , and peri .",
    "_ sensor fusion architectures for ballistic missile defense , _ johns hopkins apl technical digest , volume  27 , number  1 , 2006 ."
  ],
  "abstract_text": [
    "<S> rapid identification of object from radar cross section ( rcs ) signals is important for many space and military applications . </S>",
    "<S> this identification is a problem in pattern recognition which either neural networks or support vector machines should prove to be high - speed . </S>",
    "<S> bayesian networks would also provide value but require significant preprocessing of the signals . in this paper </S>",
    "<S> , we describe the use of a support vector machine for object identification from synthesized rcs data . </S>",
    "<S> our best results are from data fusion of x - band and s - band signals , where we obtained 99.4% , 95.3% , 100% and 95.6% correct identification for cylinders , frusta , spheres , and polygons , respectively . </S>",
    "<S> we also compare our results with a bayesian approach and show that the svm is three orders of magnitude faster , as measured by the number of floating point operations . </S>"
  ]
}