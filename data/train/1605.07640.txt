{
  "article_text": [
    "the recent upgrade of the very large array ( vla ) has resulted in a greatly increased imaging sensitivity due to the availability of large instantaneous bandwidths at the receivers and correlator .",
    "at least two new dish array telescopes ( in particular , askap and meerkat ) are currently under construction to improve upon the vla s specifications in terms of instantaneous sky coverage and total collecting area .",
    "a considerable amount of observing time has been allotted on all three instruments for large survey projects that need deep and sometimes high dynamic range imaging over fields of view that span one or more primary beams .",
    "desired data products include images and high precision catalogs of source intensity , spectral index , polarized intensity and rotation measure , produced by largely automated imaging pipelines .",
    "for these experiments , data sizes range from a few hundred gigabytes up to a few terabytes and contain a large number of frequency channels for one or more pointings .    in this imaging regime ,",
    "traditional algorithms have limits in the achievable dynamic range and accuracy with which weak sources are reconstructed .",
    "narrow - band approximations of the sky brightness and instrumental effects result in sub - optimal continuum sensitivity and angular resolution .",
    "narrow - field approximations that ignore the time- , frequency- , and polarization dependence of antenna primary beams prevent accurate reconstructions over fields of view larger than the inner part of the primary beam .",
    "mosaics constructed by stitching together images reconstructed separately from each pointing often have a lower imaging fidelity than a joint reconstruction . despite these drawbacks , there are several science cases for which such accuracies will suffice .",
    "further , all these methods are easy to apply using readily available and stable software and are therefore used regularly .",
    "more recently - developed algorithms that address the above shortcomings also exist .",
    "wide - field imaging algorithms @xcite include corrections for instrumental effects such as the w - term and antenna aperture illumination functions .",
    "wide - band imaging algorithms such as multi - term multi - frequency - synthesis ( mt - mfs ) @xcite make use of the combined multi - frequency spatial frequency coverage while reconstructing both the sky intensity and spectrum at the same time .",
    "wideband a - projection @xcite , a combination of the two methods mentioned above accounts for the frequency dependence of the sky separately from that of the instrument during wideband imaging .",
    "algorithms for joint mosaic reconstruction @xcite add together data from multiple pointings either in the spatial - frequency or image domain and take advantage of the combined spatial - frequency coverage during deconvolution . such joint mosaic imaging along with a wideband sky model and wideband primary beam correction has recently been demonstrated to work accurately and is currently being commissioned @xcite(in prep ) .",
    "these methods provide superior numerical results compared to traditional methods but they require all the data to be treated together during the reconstruction and need specialized software implementations that are optimized for the large amount of data transport and memory usage involved in each imaging run .    with so many methods to choose from and various trade - offs between numerical accuracy , computational complexity and ease of use , it becomes important to identify the most appropriate approach for a given imaging goal and to quantify the errors that would occur if other methods are used .",
    "the square kilometre array ( ska ) will involve much larger datasets than the vla , askap or meerkat will encounter with even more stringent accuracy requirements , making it all the more relevant to characterize all our algorithmic options and use existing , smaller instruments to derive and validate algorithmic parameters .",
    "this paper describes some preliminary results based on a series of simulated tests of deep wide - band and wide - field mosaic observations with the vla .",
    "section [ sec : sims ] describes how the datasets were simulated .",
    "sections [ sec : algos : single1][sec : algos : mosaic ] list the imaging methods that were compared , for the single pointing as well as the mosaic tests .",
    "section [ sec : metrics ] describes the metrics used to quantify imaging quality .",
    "sections [ sec : results : single ] and [ sec : results : mosaic ] describe the results from several tests performed with the single - pointing and mosaic datasets .",
    "section [ sec : discussion ] summarizes the results , discusses what one can and can not conclude from such tests , and lists several other tests that are required before ska - level algorithmic accuracy predictions can be made .",
    "a sky model was chosen to contain a set of 8000 point sources spanning one square degree in area .",
    "the source list is a subset of that available from the skads / scubed simulated sky project @xcite .",
    "in this sample , intensities ranged between @xmath2 and @xmath3 and followed a realistic source count distribution . for high dynamic range tests , one @xmath4 source was also added .",
    "spectral indices ranged between 0.0 and -0.8 with a peak in the spectral index distribution at -0.7 plus a roughly gaussian distribution around -0.3 with a width of 0.5 .",
    "[ fig : scounts ] shows the source count vs intensity on the top - left panel and intensity vs spectral index on the bottom - left .",
    "two types of datasets were simulated .",
    "one was for a vla single pointing at c - config and l - band with 16 channels ( or spectral windows ) between 1 and 2 ghz .",
    "the @xmath5-coverage was a series of snapshots the hpbw of the primary beam at l - band is 30arcmin and therefore covers the central part of the simulated region of sky .",
    "the second dataset was for a vla mosaic at d - config and c - band with 46 pointings ( of primary beams 6arcmin in hpbw ) spaced 5 arcmin apart to cover roughly the same patch of sky at a comparable angular resolution . at these simulated angular resolutions ( 10arcsec at l - band c",
    "- config and 9arcsec at c - band d - config ) , the expected confusion limit is @xmath6 , and the simulation included only sources brighter than @xmath7 in order to insulate these tests from errors due to main - lobe confusion .",
    "16 channels ( or spectral windows ) were chosen to span the frequency range of 4 - 8 ghz , and the @xmath5-coverage corresponds to one pointing snapshot every 6 minutes , tracing the entire mosaic twice within 8.8 hours .",
    "a true sky image cube was constructed by evaluating wideband point source components from the skads list for a set of frequencies that matched those being observed .",
    "all sources were evaluated as delta functions ( naturally at pixel centers ) using the same cell size as would be later used during imaging .",
    "specific tests with off - pixel - center sources were done by using different image cell sizes during simulation and imaging so that a source at a pixel center during simulation is not at the center during imaging .",
    "visibilities were simulated per pointing for this image cube , using the wb - a - projection de - gridder @xcite which uses complex antenna aperture illumination functions to model primary beams that scale with frequency , have polarization squint and rotate with time ( due to the vla altitude - azimuth mount ) .",
    "noise was not added to these simulations as our first goal was to characterize numerical limits purely due to the algorithms and their software implementations .",
    "only after all observed trends and limits are understood will it be instructive to add gaussian random noise .",
    "theoretically , pure gaussian random noise should not change the behaviour of algorithms other than increase error in predictable ways and it is important to systematically confirm that this is indeed the case in practice .",
    "however , numerical noise will be present in these tests at the @xmath8 level as most image domain operations use single float precision .",
    "all references to signal - to - noise ratio in this analysis therefore relate to numerical precision noise .",
    "the datasets described above were imaged in a variety of ways . in all cases",
    "the data products were continuum intensity images and spectral index maps .",
    "the methods that were tested are several possible combinations of standard clean @xcite for narrow - band imaging , mt - mfs @xcite for wideband imaging , a - projection @xcite to account for direction - dependent effects during gridding , and stitched versus joint mosaics @xcite .",
    "wideband primary beam correction was applied as appropriate using whatever primary beam models were available to the reconstruction algorithms .",
    "all image reconstruction runs used the standard major and minor cycle iterative approach @xcite with different combinations of gridding algorithms for the major cycle ( prolate spheroid , a - projection ) and deconvolution algorithms for the minor cycle ( hogbom clean , mt - mfs ) .",
    "the casa imaging software was used for these simulations and reconstructions as a combination of production tasks and custom c++ code and python scripts .",
    "each frequency channel is reconstructed independently with standard narrow - band imaging algorithms ( clean ) .",
    "there is no intrinsic primary beam correction , but deconvolution is followed by post - deconvolution primary - beam correction done per frequency .",
    "all images are then smoothed to the angular resolution of the lowest frequency in the observation , spectral models are fitted per pixel to extract spectral indices , and channels are collapsed to form a continuum intensity image .    the main advantage of this method is computational simplicity and ease of parallelization , with each channel and pointing being treated independently . the disadvantage of this approach is low angular resolution and possible sub - optimal imaging fidelity as the reconstruction process can not take advantage of the additional constraints that multi - frequency measurements provide .",
    "this procedure is the same as cube , but with projection - based gridding algorithms applied per channel to account for baseline and time dependent primary beam effects .",
    "aw - projection uses models of the antenna aperture illumination functions at different parallactic angles to compute gridding convolution functions per baseline and timestep .",
    "these convolution kernels are constructed to have conjugate phase structure compared to what exists in the visibilities , and this eliminates beam squint during gridding .",
    "the main expected differences from standard cube imaging is in the quality of the primary beam correction , visible in stokes v images all the time ( beam squint ) and at high dynamic range in the stokes i image .",
    "multi - term multi - frequency synthesis was used to simultaneously solve for the sky intensity and spectrum , using the combined wideband @xmath5-coverage . with no intrinsic primary beam corrections ,",
    "the output spectral taylor coefficients represent the time - averaged product of the sky and primary beam spectrum @xmath9 .",
    "a wideband post - deconvolution correction , a polynomial division carried out in terms of taylor coefficients . ] of the average primary beam and its spectrum ( @xmath10 ) was done at the end to produce intensity and spectral index maps that represent only the sky .",
    "this method has the advantage of algorithmic simplicity while taking advantage of the wideband @xmath5-coverage .",
    "the main disadvantage is that the time variability of the antenna primary beam is ignored , which in the case of squinted and rotating beams can result in artifacts and errors in both the intensity and spectrum for sources near the half - power level .",
    "also , since the frequency dependence of the primary beam persists through to the minor cycle modeling stage , the multi - term reconstruction has to model a spectrum that is steeper than just that of the sky .",
    "more taylor terms are required , increasing cost and low snr instabilities .",
    "multi - term multi - frequency synthesis is used along with wideband a - projection @xcite , an adaptation of aw - projection that uses convolution functions from conjugate frequencies to undo the frequency dependent effects of the aperture function during gridding in addition to accounting for beam rotation and squint .",
    "this achieves a clear separation between frequency dependent sky and instrument parameters before the sky intensity and spectrum are modeled .",
    "the output spectral taylor coefficients represent @xmath11 where the effective @xmath12 is no longer frequency dependent . in this case , a post - deconvolution division of only the intensity image by an average primary beam is required .",
    "the output spectrum already represents only that of the sky brightness .",
    "alternatively , a hybrid of cube imaging with narrow - band a - projection and mt - mfs can also be used in which the frequency dependence of the primary beam is removed in the image domain from the residual image cube before combining the frequency planes to form the taylor weighted averages needed for the mt - mfs minor cycle .",
    "these two approaches have different trade - offs in numerical accuracy , computational load , memory use and ease of parallelization and a choice between them will depend on the particular imaging problem at hand .",
    "this general approach has the advantage of accounting for the time and frequency dependence of the primary beam during gridding , and clearly separating sky parameters from instrumental ones .",
    "the required number of taylor coefficients depend only on the spectrum of the sky , which is usually less steep than that of the primary beam . with a - projection , a flat - noise normalization choice can sometimes cause numerical instabilities around the nulls of the primary beam where the true sensitivity of the observations is also the lowest ",
    "work is in progress to find a robust solution to this .",
    "alternate normalization choices will alleviate the problem but they will increase the degree of approximation that the minor cycle must now handle .      in general , a mosaic can be constructed as a weighted average of single pointing images , using an average primary beam model as the weighting function . in this discussion , a combination after deconvolution will be called stitched mosaic , and a combination before deconvolution will be called a joint mosaic .",
    "a joint mosaic can also combine the data in the visibility domain by applying appropriate phase gradients across the gridding convolution functions used by projection algorithms .",
    "several wideband mosaic imaging options exist @xcite as various combinations of imaging with and without dd correction during imaging , cube versus multi - term multi - frequency synthesis imaging , and stitched versus joint mosaics .    for cube clean imaging , joint mosaics",
    "were made by combining data in the visibility domain and applying appropriate phase gradients across gridding convolution functions .",
    "two methods were compared with the first using an azimuthally symmetric primary beam model to construct a single gridding convolution kernel for all visibilities and the second using full aw - projection to account for pb - rotation and beam squint ( per frequency ) .",
    "the first method has the advantage of computational simplicity compared to full aw - projection where convolution functions can potentially be different for every visibility , but it has the disadvantage of ignoring beam squint and pb - rotation .",
    "the primary beam model is also not the same as what was used to simulate the data and this test evaluates the effect of this commonly used simplifying assumption .    for mfs imaging ( with multiple taylor terms )",
    ", a joint mosaic was computed using aw - projection with its wideband adaptation ( to correct for the pb frequency dependence ) along with phase gradients applied to convolution kernels .",
    "an alternate approach is to stitch together sets of pb - corrected output taylor coefficient images , using the time - averaged primary beam as a weighting function , and then recomputing spectral index over the mosaic .",
    "however , initial tests showed that stitched mosaics ( with or without wb - awprojection ) produced larger errors than joint mosaics @xcite and stitched multi - term mfs mosaics were not included in this analysis .",
    "the following metrics were used to evaluate the numerical performance of the different algorithms .    1 .",
    "image rms : the rms of pixel amplitudes from off - source regions in the image , or in the case of no source - free regions , the width of a pixel amplitude histogram .",
    "dynamic range : ratio of peak flux to peak artifact level or image rms when no artifacts are visible .",
    "error distributions ( imaging fidelity ) : the intensity and spectral index maps produced by the above algorithms were compared with the known simulated sky and estimates of error per source were binned into histograms . for each output image ,",
    "the simulated sky model image was first smoothed to match its angular resolution , and then pixel values were read off from both images at all the locations of the true source pixels .",
    "histograms were plotted for @xmath13 where deviations from 1.0 indicate relative flux errors and for @xmath14 where deviations from 0.0 indicate relative errors in spectral index .",
    "all histograms were made with multiple intensity ranges ( e.g.fig .",
    "[ fig.lowdr.hist1 ] ) and over different fields of view ( e.g. fig .",
    "[ fig.lowdr.hist2 ] ) to look for trends .",
    "the l - band ( 1 - 2ghz ) c - configuration simulated data were imaged with the algorithms listed in sec .  [",
    "sec : algos : single1 ] through  [ sec : algos : single4 ] .      [ cols=\"^,^,^,^,^,^ \" , ]      +",
    "the tests described in this paper address the use of wideband data for the deep imaging of crowded fields of compact sources at a sensitivity close to the confusion limit of the observation .",
    "the simulations use a realistic source distribution ( from which only sources a few times brighter than the confusion limit were used ) and include primary beam effects arising from azimuthal asymmetry , parallactic angle rotation and frequency scaling .",
    "imaging results were based on the ability to apply appropriate primary beam corrections and recover intensities and spectral indices of sources out to the 0.2 gain level of the primary beam and down to sensitivities a few times the confusion limit .",
    "bright sources were introduced to evaluate dynamic range limits with and without corrections for the time variability of primary beams .",
    "most observed trends were as expected and we were able to quantify the accuracy with which algorithms performed .",
    "there were also a few surprises that highlight the unpredictability of current algorithms in certain situations .        for a crowded field of compact sources being imaged at a sensitivity close to the confusion limit , the quality of the psf matters a great deal during deconvolution , and multi - frequency synthesis has a clear advantage over subband based imaging especially for weak sources .",
    "the clean bias effect was seen for cube based methods which required careful masking to eliminate the effect .",
    "however , mfs - based wideband algorithms had psfs with narrower main lobes and lower sidelobes and did not suffer from the clean bias thus making complicated masking procedures unnecessary .    for a mosaic of such a field ,",
    "a joint imaging approach is prefered ( within reasonable image size limits ) . for dynamic ranges higher than @xmath15 a - projection",
    "based methods are required to account for baseline and time - dependent primary beam effects .",
    "methods that derive spectral models of the sky while decoupling them from wideband instrumental effects ( mt - mfs with wideband a - projection ) are capable of producing usable spectral indices at all snrs except the lowest snrs ( where all methods fall short ) .",
    "the use of wb a - projection even at dynamic ranges lower than @xmath15 might benefit imaging cases where strong sources exist in the outer parts of the pb where pb - spectral index is higher .",
    "finally , simple data parallelization during the major cycle goes a long way in balancing out the increase in cost due to the more complex algorithms .",
    "given the best possible approach ( multi - term mfs with wideband a - projection ) for the specific problem being studied ( deep widefield imaging of crowded fields at or near the confusion limit ) , we quantified errors in the recovered intensity and spectral index as a function of source snr for both single pointings and a joint mosaic .",
    "note that for these noiseless simulations there still is numerical noise due to the use of single float precision in many image domain calculations .    for our single pointing tests ( at l - band ) , errors in reconstructed intensity",
    "were as follows .",
    "sources brighter than @xmath16 have errors less than 5% , sources between @xmath16 and @xmath17 show errors at the 10% level and sources below @xmath17 show errors at the 20 to 30% level with several sources more than 50% .",
    "errors in reconstructed spectral index were as follows .",
    "sources brighter than @xmath16 show errors of @xmath18 , but sources between @xmath16 and @xmath17 show errors of @xmath19 . in these tests",
    ", the weakest sources did not meet the threshold for spectral index calculation ( for both cube and multi - term mfs methods ) .    for such crowded fields ,",
    "accuracy also depends on the quality of the psf even if source snr is not a problem .",
    "we showed that as psf sidelobe levels decreased ( by choosing different subsets of the data ) sources brighter than @xmath20 are always reconstructed to within a few percent , sources between 8 and 50 @xmath21 improve from 20% errors to less than 5% , and sources between @xmath22 and @xmath23 improve from over 50% errors to about 20% .    for our joint mosaic tests",
    "( at c - band ) , errors in reconstructed intensity were as follows .",
    "sources brighter than @xmath24 had 2% errors , sources between @xmath24 and @xmath25 show errors of 4% and sources below @xmath17 have about @xmath26 errors .",
    "spectral index errors were @xmath27 for sources brighter than @xmath16 but sources between @xmath16 and @xmath28 had errors upto @xmath29 with both cube and mfs methods showing a slight systematic bias of @xmath30 towards flatness .",
    "the difference between the scale of the errors between the single pointing and mosaic tests relate to the amount of data used in the simulation .",
    "there are many sources of error during image reconstruction and the systematic separation of various contributing factors and their eventual combination is crucial to building a complete picture and truly understanding the reasons behind observed effects .",
    "conclusions derived from approximations done in isolation must be treated with caution and trends observed in real data must be reproduced when applicable . in a first step",
    "we include artifacts typical of various instrumental effects ( primary beams , psf sidelobe levels ) and demonstrate clean bias and show how to eliminate it .",
    "in fact , even the simulations done in this paper require the addition of several more effects to become accurate predictors of reality .",
    "for example , this paper quantifies algorithmic limits in the situation of no noise , point sources located at pixel centers , and no differences between the primary beam models used for simulation versus those used during imaging ( except for one of the wideband mosaic tests ) .",
    "these errors are thereforem a lower limit on what one could expect in reality .",
    "effects such as the clean bias were reproduced clearly and its cause and solution understood .",
    "future enhancements ( even just for stokes i imaging ) should include noise as well as residual calibration errors ( some of which may masquerade as effects needing baseline based calibration ) , the use of inaccurate primary beam models during imaging , the presence of extended emission in addition to point sources , etc .",
    "such questions are listed in detail in sec .",
    "[ sec : openqns ] .      sometimes , algorithmic choices and achievable numerical accuracy depend on the type of available computing resources .",
    "this section revisits the various algorithmic options in the context of numerical accuracy versus computational cost .",
    "cube imaging methods are the easiest to parallelize , with both data and images being partitioned across frequency for the entire iterative imaging process .",
    "there is minimal need for special - purpose software for such a setup .",
    "imaging accuracy is limited to that offered by the @xmath5 coverage per channel , deconvolution depth is limited to the single channel sensitivity , and the resolution at which spectral structure can be calculated is limited to that of the lowest frequency .",
    "there is no dependence on any particular spectral model which makes this approach very flexible in its reconstruction of spectral structure .",
    "multi - frequency synthesis is demonstrably superior for continuum imaging due to its increased angular resolution , imaging sensitivity and fidelity , especially for crowded fields with thousands of compact sources .",
    "the multi - term mfs algorithm is useful to compute in - band spectral indices along with intensity but the cost of both the major and minor cycle increase with the order of the polynomials used .",
    "also , the accuracy of the spectral indices depends on the source snr and the choice of the order of the polynomial .",
    "work is in progress to test an approach where the number of taylor terms is snr dependent . for multi - frequency synthesis ,",
    "only the major cycle can be easily parallelized , with a gather step performed before the joint deconvolution step .",
    "the prefered partition axis when the wb - awp algorithm is used is time because of the use of aperture illumination functions from conjugate frequencies during gridding . if narrow - band a - projection is used to form a cube before primary beam correction and the formation of taylor weighted averages in the image domain , the partition axis of choice for the major cycle would be frequency .",
    "projection algorithms are significantly more expensive than the more standard method of using prolate spheroidal functions during gridding , mainly because of the support size of the convolution kernels and the overhead of computing such functions for potentially every visibility .",
    "however , the more useful metric is the _ total _ runtime for imaging and the extra cost of using projection algorithms can be offset by a comparable reduction in the runtime due to its numerical advantages .",
    "for example , wb a - projection increases the computing load for imaging but decreases the computing load and memory footprint of the mt - mfs setup which will need fewer terms to fit the spectral structure since the primary beam spectrum has been eliminated .",
    "also , in practice the roughly 10 fold increase in computation due to the use of a - projection compared to the standard gridder is readily absorbed by simple data parallelization during the major cycle .",
    "in addition , approximations can always be made ( identical antennas , coarser sampling of the aperture illumination function to reduce the size of the convolution functions , etc ) but effects of such approximations are visible beyond the @xmath31 dynamic range level .",
    "another axis along which parallelization is relatively easy is pointing .",
    "however , our tests show that the numerical differences between stitched vs joint mosaics are large enough that ( for crowded fields ) joint mosaics are always preferred .",
    "another basic factor is the use of single vs double precision calculations during imaging and deconvolution .",
    "currently ( in casa ) , all intermediate and output images use single precision , which is not the best option for dynamic ranges @xmath32 .",
    "the simulations and tests described in this paper demonstrate several ways in which imaging accuracy can be sub - optimal even for the simple situation of point sources imaged using both traditional trusted techniques as well as newer ones .",
    "a vast number of open questions and details remain , and a truly accurate picture can be derived only after these avenues are explored carefully and quantified to provide trends and usage guidelines to astronomers .",
    "work is in progress on several of these fronts , and results will be presented in subsequent papers .    1 .",
    "is it better to trade integration time at a single frequency band for shorter samples taken across a wider frequency range ?",
    "for example for the vla , simulations have shown that comparable imaging sensitivities and far more accurate spectral indices are recovered when an observation spans multiple bands ( l - band and c - band for example ) compared with the entire time spent at only one band .",
    "2 .   what is the best algorithm for emission consisting of extended structure as well as compact emission",
    "? algorithms like multiscale clean are usable but relatively more expensive in terms of computing and memory footprint load and require considerable human input .",
    "several newer methods have been shown to produce superior results on their own but do not currently have production - quality optimized implementations that one can use .",
    "3 .   does the addition of noise and residual calibration errors change any of the above conclusions ?",
    "theoretically , one would not expect the addition of gaussian random noise to change any results but it will be instructive to understand how robust these algorithms are to various noise levels .",
    "residual calibration errors on the other hand might cause changes that must be quantified ( e.g. , see @xcite ) . to assess how well such effects can be corrected , traditional self - calibration techniques must be compared with more flexible methods such as direction dependent calibration schemes and peeling ( for example , sage ) , especially to test their effects on the accuracy of the reconstructed sources .",
    "4 .   how does baseline based averaging affect the achievable accuracy in the reconstructed intensity and spectral index ?",
    "a popular mode of data compression is to average time - contiguous visibilities that will all fall on the same @xmath5 grid cell during gridding .",
    "one concern with such an approach is whether it would prevent the handling of time variability of directional dependent instrumental effects or not . a simple test that achieved a data size reduction of 20% for one of the test datasets showed no noticeable effect with a - projection imaging out to twice the hpbw of the pb .",
    "additional tests must be done with more practical data compression ratios .",
    "how effective is the standard p(d ) analyses in predicting source counts below confusion limits ?",
    "simulations similar to those described in this paper with sources weaker than @xmath7 ( or an observation with a larger angular resolution ) can be used to test the effect of main - lobe confusion for the simulated source count distribution and the accuracy of p(d ) analyses on such an image .",
    "what type of software implementation and parallelization strategy is the most appropriate for a particular type of survey ? in the past few years",
    "several new modern imagers have begun to become available and it would be instructive to repeat an imaging test with different algorithms and implementations to evaluate and quantify differences that arise simply from different software implementations and subtle numerical and algorithmic choices within it .",
    "for example , @xcite shows examples of the numerical differences one can achieve simply by using pb models of different kinds and different algorithmic and software implementations for wideband mosaic imaging .",
    "how do these results extend to full polarization imaging and faraday rotation synthesis ?",
    "simulations with polarization dependent primary beams and full - stokes imaging ( with and without a - projection ) can quantify polarization imaging limits and identify appropriate imaging strategies .",
    "work is in advanced stages @xcite .",
    "to analyse this and produce the required algorithms and software to do such imaging .",
    "how accurate do primary beam models need to be for use within a - projection ?",
    "simulations with controlled differences in actual aperture illumination functions can give a useful idea of how much variation can be left unmodeled during imaging .",
    "for example , it is easy to produce a spurious bias in spectral index simply by using a pb model whose shape is slightly different from what is present in the data .",
    "work is in progress @xcite to quantity imaging errors for alma when ( not so ) subtle differences between antenna structures and illumination patterns are ignored at different levels of approximation and for the vla @xcite to carefully model primary beams from holography data and use them during image reconstruction .",
    "these tests probe the limits of commonly used interferometric imaging algorithms in the context of crowded fields of compact sources being imaged at a few times the confusion limit and @xmath33 times the ( numerical ) noise level .      in this regime ,",
    "the quality of the psf is of considerable importance even at signal - to - noise ratios of @xmath34 simply because of the limitations of clean based deconvolution algorithms in crowded fields .",
    "a psf sidelobe of @xmath35 to achieve errors of @xmath36 in intensity and @xmath37 in spectral index across a 1 - 2ghz band for low brightness sources near the confusion limit .",
    "since psfs from the joint imaging of data ( mfs , for example ) typically have lower sidelobes compared to psfs from partitioned pieces of data ( cube , for example ) the former are prefered algorithmic choice in this regime .      for shallow surveys where the emission above thermal noise limits fills the sky sparsely",
    ", we did not find any statistically significant difference between algorithms that partition the data and those that do nt ( like mfs ) .",
    "surveys that require imaging at the native resolution of the data / telescope  particularly where detection and reconstruction of extended emission is important  will still need to use mfs .",
    "computing resources will be another discriminator in choosing algorithms in the shallow regime with algorithms that do nt require data partitioning ( like mfs ) requiring fewer resources than algorithms that do require partitioning .      for wide - field imaging ( dr @xmath38 ) ,",
    "primary beam correction methods need to include details such as its time , frequency and polarization dependence to both reconstruct the bright source accurately and to eliminate artifacts that may contaminate surrounding weaker sources .",
    "our investigation shows that accounting for azimuthal asymmetry of the beams , rotation or pointing jitter as a function of time , scaling with frequency and polarization beam squint due to off - axis feed locations is certainly required .",
    "the imaging performance of joint image reconstruction methods is fundamentally superior to those that work with partitioned data and combining number of reconstructed images each from a fraction of the available data .",
    "hybrid implementations that take advantage of the ease of parallelization of partitioned methods where possible may be useful , but require careful analysis of its final imaging performance .",
    "work presented here also gives a lower limit on the level of detail at which simulations for future surveys and telescopes must be undertaken .",
    "it is important to systematically build up the complexity of the simulation in a way that enables one to efficiently pinpoint the reasons behind observed feature or trends . given the wide range of observation types and analysis methods , simulations must be specific to the parameters of each survey and must be as complete as possible in their inclusion of instrumental effects and observing modes .",
    "in particular , effects of time , frequency and polarization dependence of the antenna primary beams , effects of long baselines and wide fractional bandwidths , and correct sampling of the coherence field in time and frequency to realistically reflect both the data volume and the filling factor in the uv - plane .",
    "clear accuracy requirements are also necessary for each survey in order to choose the optimal analysis procedure based on scientific estimates .",
    "we wish to thank the various nrao staff members for useful discussions at various stages of this project .",
    "we wish to thank the common astronomy software applications ( casa ) group for the use of their imaging libraries in our simulation and imaging scripts ."
  ],
  "abstract_text": [
    "<S> many deep wide - band wide - field radio interferometric surveys are being designed to accurately measure intensities , spectral indices and polarization properties of faint source populations . in this paper </S>",
    "<S> we compare various wideband imaging methods to evaluate the accuracy to which intensities and spectral indices of sources close to the confusion limit can be reconstructed . </S>",
    "<S> we simulated a wideband single - pointing ( c - array , l - band ( 1 - 2ghz ) ) and 46-pointing mosaic ( d - array , c - band ( 4 - 8ghz ) ) jvla observation using realistic brightness distribution ranging from @xmath0jy to @xmath1jy and time- , frequency- , polarization- and direction - dependent instrumental effects . </S>",
    "<S> the main results from these comparisons are ( a ) errors in the reconstructed intensities and spectral indices are larger for weaker sources even in the absence of simulated noise , ( b ) errors are systematically lower for joint reconstruction methods ( such as mt - mfs ) along with a - projection for accurate primary beam correction , and ( c ) use of mt - mfs for image reconstruction eliminates clean - bias ( which is present otherwise ) . </S>",
    "<S> auxiliary tests include solutions for deficiencies of data partitioning methods ( e.g. the use of masks to remove clean bias and hybrid methods to remove sidelobes from sources left undeconvolved ) , the effect of sources not at pixel centers and the consequences of various other numerical approximations within software implementations . </S>",
    "<S> this paper also demonstrates the level of detail at which such simulations must be done in order to reflect reality , enable one to systematically identify specific reasons for every trend that is observed and to estimate scientifically defensible imaging performance metrics and the associated computational complexity of the algorithms / analysis procedures . </S>"
  ]
}