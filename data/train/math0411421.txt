{
  "article_text": [
    "the gaussian @xmath1ensembles are probability spaces on @xmath2-tuples of random variables @xmath3 , with joint density functions @xmath4\\prod_{j < k}|\\lambda_{j}-\\lambda_{k}|^{\\beta}.\\label{jointdensity}\\ ] ] the @xmath5 are normalization constants , and by setting @xmath6 we recover the _ gaussian orthogonal ensemble _ ( @xmath7 ) , _ gaussian unitary ensemble _ ( @xmath8 ) , and _ gaussian symplectic ensemble _ ( @xmath9 ) , respectively .",
    "we restrict ourselves to those three cases in this paper , and refer the reader to @xcite for recent results on the general @xmath1 case .",
    "originally the @xmath10 are eigenvalues of randomly chosen matrices from corresponding matrix ensembles , so we will henceforth refer to them as eigenvalues . with the eigenvalues ordered so that @xmath11 , define @xmath12 to be the rescaled @xmath0 eigenvalue measured from edge of spectrum .",
    "a standard result of random matrix theory about the distribution of the largest eigenvalue in the @xmath1ensembles is that @xmath13 whose law is given by the tracy",
    " widom distributions",
    ".    @xmath14 \\label{guemax},\\ ] ]    @xmath15^{2}=f_{2}\\cdot\\exp\\left[-\\int_{s}^{\\infty}q(x)d\\,x\\right]\\label{goemax},\\ ] ]    @xmath16^{2}=f_{2}\\cdot\\cosh^{2}\\left[-\\frac{1}{2}\\int_{s}^{\\infty}q(x)d\\,x\\right ] \\label{gsemax}.\\ ] ]    the function @xmath17 is the unique ( see @xcite,@xcite ) solution to the painlev ii equation @xmath18 such that @xmath19 as @xmath20 , where @xmath21 is the solution to the airy equation which decays like @xmath22 at @xmath23 .",
    "the density functions @xmath24 corresponding to the @xmath25 are graphed in figure [ twdensities ] .",
    "reflects a normalization chosen in to agree with mehta s original one .",
    "it can be removed by choosing a different normalization . ]",
    "let @xmath26 denote the distribution for the @xmath0 largest eigenvalue in gue .",
    "tracy and widom showed in @xcite that if we define @xmath27 , then    @xmath28    where @xmath29,\\label{d2}\\ ] ] and @xmath30 is the solution to such that @xmath31 as @xmath20 . an intermediate step leading to is to first show that @xmath32 can be expressed as a fredholm determinant @xmath33 where @xmath34 is the integral operator with kernel @xmath35 in the @xmath36 cases a result similar to holds with the difference that the operators in @xmath37 have matrix  valued kernels ( see e.g. @xcite ) .",
    "in fact , the same combinatorial argument used to obtain the recurrence in the @xmath38 case also works for the @xmath36 cases , leading to @xmath39 where @xmath40 . given the similarity in the arguments up to this point and comparing to , it is natural to conjecture that @xmath41 can be obtained simply by replacing @xmath42 by @xmath30 in and .",
    "however the following conjecture , which had long been in the literature , and whose verification is the content of corollary  , hints that this can not be the case :    in the appropriate scaling limit , the distribution of the largest eigenvalue in gse corresponds to that of the second largest in goe . more generally , the joint distribution of every second eigenvalue in the goe coincides with the joint distribution of all the eigenvalues in the gse , with an appropriate number of eigenvalues .",
    "[ baikconj ]    forrester and rains subsequently proved ( see @xcite ) the equivalence of alternate goe eigenvalues and gse eigenvalues at _ finite _ @xmath43 ensemble level , lending weight to conjecture  .",
    "this so  called `` interlacing property '' between goe and gse had been noticed by mehta and dyson ( see @xcite ) .",
    "conjecture   does not agree with the formulae we postulated for @xmath44 .",
    "indeed , combining the two leads to incorrect relationships between derivatives of @xmath30 evaluated at @xmath45 . to be precise , the conjecture is true for @xmath46 but it is false for @xmath47 .",
    "the correct forms for both @xmath44 are given below in theorem  .",
    "this work also extends that of johnstone in @xcite ( see also @xcite ) , since @xmath48 gives the asymptotic behavior of the @xmath0 largest eigenvalue of a @xmath49 variate wishart distribution on @xmath2 degrees of freedom with identity covariance .",
    "this holds under very general conditions on the underlying distribution of matrix entries by soshnikov s universality theorem ( see @xcite for a precise statement ) . in table",
    "[ table ] , we compare our distributions to finite @xmath2 and @xmath49 empirical wishart distributions as in @xcite .",
    "the distributions for the @xmath0 largest eigenvalues in the and satisfy the recurrence with @xmath50 @xmath51 where @xmath52 and @xmath30 is the solution to such that @xmath31 as @xmath20.[mainthm ]    @xmath53    [ interlacingcor ]    in the next section we outline the proof of these theorems . in the last , we present an efficient numerical scheme to compute @xmath54 .",
    "we implemented this scheme using matlab , and compared the results to simulated wishart distributions .",
    "realizations of @xmath55 goe matrices ; the solid curves are , from right to left , the theoretical limiting densities for the first through fourth largest eigenvalue.,height=245 ]",
    "with the joint density function defined as in , let @xmath56 be an interval on the real line , and @xmath57 its characteristic function .",
    "we denote by @xmath58 the characteristic function of the complement of @xmath56 , and define @xmath59 . furthermore , let @xmath60 equal the probability that exactly the @xmath61 largest eigenvalues of a matrix chosen at random from a ( finite @xmath43 ) @xmath1ensemble lie in @xmath56 .",
    "we also define    @xmath62    for @xmath45 this is just @xmath63 , the probability that no eigenvalues lie in @xmath56 .",
    "the following propositions are easy combinatorial facts that can be proved by induction ( see e.g. @xcite ) .",
    "@xmath64    @xmath65    the next step is to find a useful expression for the multiple integral @xmath66 .",
    "it turns out that through standard rmt techniques ( see e.g. @xcite ) , the integral can be expressed as the determinant of an operator on the hilbert space @xmath67 .",
    "let    @xmath68    for @xmath69 here @xmath70 is the integral operator with kernel @xmath71 , and @xmath72 denotes the differentiation operator @xmath73 , @xmath74 is the integral operator with kernel @xmath75 and the functions @xmath76 and @xmath77 are    @xmath78    @xmath79    where @xmath80 and the @xmath81 are the classical hermite polynomials .",
    "this implies that the @xmath82 are orthonormal with respect to the lebesgue measure on @xmath83 .",
    "similarly , let @xmath84 following the same approach as in @xcite and @xcite , we arrive at @xmath85        the above determinants are fredholm determinants of operators on @xmath86 .",
    "our first task will be to rewrite these determinants as those of operators on @xmath87 .",
    "this part follows exactly the proof in @xcite . to begin ,",
    "note that @xmath88}=\\varphi\\otimes\\psi + \\psi\\otimes\\varphi\\label{sdcom}\\ ] ] so that ( using the fact that @xmath89 ) @xmath90 } & = & \\epsilon\\,s - s\\,\\epsilon\\nonumber\\\\ & = & \\epsilon\\,s\\,d\\,\\epsilon-\\epsilon\\,d\\,s\\,\\epsilon = \\epsilon\\,{\\left[\\,s\\,,d\\,\\right]}\\,\\epsilon\\nonumber\\\\   & = & \\epsilon\\,\\varphi\\otimes\\psi\\,\\epsilon + \\epsilon\\,\\psi\\otimes\\varphi\\,\\epsilon\\nonumber\\\\ & = & \\epsilon\\,\\varphi\\otimes\\epsilon^{t}\\psi + \\epsilon\\,\\psi\\otimes\\epsilon^{t}\\,\\varphi\\nonumber\\\\ & = & - \\epsilon\\,\\varphi\\otimes\\epsilon\\,\\psi - \\epsilon\\,\\psi\\otimes\\epsilon\\,\\varphi , \\label{escom}\\end{aligned}\\ ] ] where the last equality follows from the fact that @xmath91 .",
    "we thus have    @xmath92    the expressions on the right side are the top entries of @xmath93 .",
    "thus the first row of @xmath93 is , as a vector ,    @xmath94    now implies that    @xmath95    similarly gives    @xmath96 } = \\epsilon\\,\\varphi\\otimes\\psi + \\epsilon\\psi\\otimes\\varphi,\\ ] ]    so that    @xmath97    using these expressions we can rewrite the first row of @xmath98 as    @xmath99    applying @xmath70 to this expression shows the second row of @xmath98 is given by    @xmath100    now use to show the second row of @xmath93 is    @xmath101    therefore ,    @xmath102    since @xmath93 is of the form @xmath103 , we can use the fact that @xmath104 and deduce that @xmath105 is unchanged if instead we take @xmath98 to be    @xmath106    therefore    @xmath107    now we perform row and column operations on the matrix to simplify it , which do not change the fredholm determinant .",
    "justification of these operations is given in @xcite .",
    "we start by subtracting row 1 from row 2 to get    @xmath108    next , adding column 2 to column 1 yields    @xmath109    then right - multiply column 2 by @xmath110 and add it to column 1 to get    @xmath111    finally we multiply row 2 by @xmath112 and add it to row 1 to arrive at    @xmath113    thus the determinant we want equals the determinant of    @xmath114    so we have reduced the problem from the computation of the fredholm determinant of an operator on @xmath86 , to that of an operator on @xmath87 .",
    "next we want to write the operator in in the form @xmath115 where the @xmath116 and @xmath117 are functions in @xmath87 . in other words , we want to rewrite the determinant for the goe case as a finite dimensional perturbation of the corresponding gue determinant",
    ". the fredholm determinant of the product is then the product of the determinants .",
    "the limiting form for the gue part is already known , and we can just focus on finding a limiting form for the determinant of the finite dimensional piece .",
    "it is here that the proof must be modified from that in @xcite .",
    "a little simplification of yields @xmath118 writing @xmath119}+{\\raisebox{.4ex}{$\\chi$}}$ ] for @xmath120 and simplifying @xmath121 to @xmath122 gives    @xmath123 } - \\lambda\\,\\left(\\epsilon\\,\\varphi\\,\\otimes\\,\\psi\\right)\\,\\left(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}}\\right)\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right ] }   \\\\ & = i -   ( 2\\lambda-\\lambda^{2})\\,s\\,{\\raisebox{.4ex}{$\\chi$}}- ( 2\\lambda-\\lambda^{2})\\,(\\epsilon\\,\\varphi\\,\\otimes\\,{\\raisebox{.4ex}{$\\chi$}}\\,\\psi )    - \\lambda\\,s\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right ] } \\\\",
    "&    \\qquad    -   \\lambda\\,(\\epsilon\\,\\varphi\\,\\otimes\\,\\psi)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]}.\\end{aligned}\\ ] ]    define @xmath124 and let @xmath125 , and @xmath126 so that @xmath127 and goes to @xmath128 } \\\\ & -   \\frac{\\lambda}{\\tilde{\\lambda}}\\,(\\epsilon\\,\\varphi\\,\\otimes\\,\\psi)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]}.\\end{aligned}\\ ] ] now we define @xmath129 ( the resolvent operator of @xmath130 ) , whose kernel we denote by @xmath131 , and @xmath132 . then factors into    @xmath133    where @xmath134 is    @xmath135}\\\\ & -    \\frac{\\lambda}{\\tilde{\\lambda}}\\,(q_{\\epsilon}\\,\\otimes\\,\\psi)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon\\,{\\left[\\,{\\raisebox{.4ex}{$\\chi$}}\\,,d\\,\\right]},\\qquad \\lambda\\neq 1.\\end{aligned}\\ ] ]    hence @xmath136 in order to find @xmath137 we use the identity @xmath138}=\\sum_{k=1}^{2 m } ( -1)^{k}\\,\\epsilon_{k}\\otimes\\delta_{k},\\ ] ] where @xmath139 and @xmath140 are the functions @xmath141 and @xmath142 respectively , and the @xmath143 are the endpoints of the ( disjoint ) intervals considered , @xmath144 .",
    "we also make use of the fact that @xmath145 where @xmath146 is the usual @xmath147inner product . therefore    @xmath148 } & = \\sum_{k=1}^{2 m } ( -1)^{k}q_{\\epsilon}\\otimes\\psi\\cdot ( 1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon_{k}\\otimes\\delta_{k } \\\\ & = \\sum_{k=1}^{2 m } ( -1)^{k}{\\left(\\,\\psi\\,,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,\\epsilon_{k}\\,\\right)}\\,q_{\\epsilon}\\otimes\\,\\delta_{k}.\\end{aligned}\\ ] ]    it follows that    @xmath149    equals the determinant of @xmath150\\otimes\\delta_{k}.   \\end{aligned}\\ ] ] we now specialize to the case of one interval @xmath151 , so @xmath152 , @xmath153 and @xmath154 .",
    "we write @xmath155 , and @xmath156 , and similarly for @xmath140 . writing the terms in the summation and using the facts that @xmath157 and",
    "@xmath158 then yields @xmath159\\otimes(\\delta_{t}-\\delta_{\\infty})\\\\ \\qquad    + \\frac{\\lambda}{\\tilde{\\lambda } } \\left[(s+r\\,s)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}+ { \\left(\\,\\psi\\,,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}\\,\\right)}\\,q_{\\epsilon}\\right]\\otimes\\delta_{t}\\end{aligned}\\ ] ] which , to simplify notation , we write as @xmath160\\otimes(\\delta_{t}-\\delta_{\\infty } ) \\\\ \\qquad    + \\frac{\\lambda}{\\tilde{\\lambda } } \\left[(s+r\\,s)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}+ \\tilde{a}_{1,\\lambda}\\,q_{\\epsilon}\\right]\\otimes\\delta_{t},\\end{aligned}\\ ] ] where @xmath161 now we can use the formula : @xmath162 in this case , @xmath163 , and @xmath164\\nonumber , \\\\",
    "\\alpha_{3}= & -\\frac{\\lambda}{\\tilde{\\lambda } } \\left[(s+r\\,s)\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,{\\raisebox{.4ex}{$\\chi$}}+ \\tilde{a}_{1,\\lambda}\\,q_{\\epsilon}\\right],\\nonumber \\\\ & \\beta_{1}={\\raisebox{.4ex}{$\\chi$}}\\psi , \\qquad   \\beta_{2}=\\delta_{t}-\\delta_{\\infty } , \\qquad \\beta_{3}=\\delta_{t}.\\end{aligned}\\ ] ] in order to simplify the notation , define    @xmath165",
    "@xmath166    @xmath167    note that all quantities in and are functions of @xmath168 alone .",
    "furthermore , let @xmath169 from @xcite we find @xmath170 and at @xmath171 ,    @xmath172    hence @xmath173 , \\\\",
    "{ \\left(\\,\\alpha_{2}\\,,\\beta_{2}\\,\\right ) } & = \\frac{\\lambda}{2\\,\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda } + a_{1,\\lambda}\\,(q_{\\epsilon}-c_{\\varphi})\\right]\\label{example } , \\\\ { \\left(\\,\\alpha_{2}\\,,\\beta_{3}\\,\\right ) } & = \\frac{\\lambda}{2\\,\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda } + a_{1,\\lambda}\\,q_{\\epsilon}\\right ] , \\\\ { \\left(\\,\\alpha_{3}\\,,\\beta_{1}\\,\\right ) } & = -\\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\tilde{\\mathcal{p}}_{1,\\lambda } - \\tilde{a}_{1,\\lambda}\\,(1-\\tilde{v}_{\\epsilon})\\right ] , \\\\ { \\left(\\,\\alpha_{3}\\,,\\beta_{2}\\,\\right ) } & = -\\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\tilde{\\mathcal{r}}_{1,\\lambda}+\\tilde{a}_{1,\\lambda}\\,(q_{\\epsilon } - c_{\\varphi})\\right ] , \\\\   { \\left(\\,\\alpha_{3}\\,,\\beta_{3}\\,\\right ) } & = -\\frac{\\lambda}{\\tilde{\\lambda}}\\ , \\left[\\tilde{\\mathcal{r}}_{1,\\lambda}+\\tilde{a}_{1,\\lambda}\\,q_{\\epsilon}\\right].\\end{aligned}\\ ] ] as an illustration , let us do the computation that led to in detail . as in @xcite , we use the facts that @xmath174 , and @xmath175 which can be easily seen by writing @xmath176 . furthermore we write @xmath177 to mean @xmath178 in general , since all evaluations are done by taking the limits from within @xmath56 , we can use the identity @xmath179 inside the inner products .",
    "thus @xmath180\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[{\\left(\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,,(s+r^{t}\\,s)\\,\\left(\\delta_{t}-\\delta_{\\infty}\\right)\\,\\right ) } + a_{1,\\lambda}\\left(q_{\\epsilon}(t)-q_{\\epsilon}(\\infty)\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[{\\left(\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,,(s+r^{t}\\,s)\\,{\\raisebox{.4ex}{$\\chi$}}\\,\\left(\\delta_{t}-\\delta_{\\infty}\\right)\\,\\right ) } + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[{\\left(\\,(1-\\lambda\\,{\\raisebox{.4ex}{$\\chi$}})\\,,r(x , t)-r(x,\\infty)\\,\\right ) } + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda}(t)-\\mathcal{r}_{1,\\lambda}(\\infty ) + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right]\\\\ & = \\frac{\\lambda}{\\tilde{\\lambda}}\\,\\left[\\mathcal{r}_{1,\\lambda}(t ) + a_{1,\\lambda}\\left(q_{\\epsilon}-c_{\\varphi}\\right)\\right].\\end{aligned}\\ ] ] we want the limit of the determinant @xmath181 as @xmath182 . in order to get our hands on the limits of the individual terms involved in the determinant , we will find differential equations for them first as in @xcite .",
    "row operation on the matrix show that @xmath183 and @xmath184 fall out of the determinant ; to see this add @xmath185 times row 1 to row 2 and @xmath186 times row 1 to row 3 .",
    "so we will not need to find differential equations for them .",
    "our determinant is @xmath187   -\\frac{\\lambda\\,\\mathcal{p}_{1,\\lambda}}{2\\,\\tilde{\\lambda } } & 1 - \\frac{\\lambda\\,\\mathcal{r}_{1,\\lambda}}{2\\,\\tilde{\\lambda } }   & -\\frac{\\lambda\\,\\mathcal{r}_{1,\\lambda}}{2\\,\\tilde{\\lambda } } \\\\[6pt ] \\frac{\\lambda\\,\\tilde{\\mathcal{p}}_{1,\\lambda}}{\\tilde{\\lambda } } & \\frac{\\lambda\\,\\tilde{\\mathcal{r}}_{1,\\lambda}}{\\tilde{\\lambda } } & 1 + \\frac{\\lambda\\,\\tilde{\\mathcal{r}}_{1,\\lambda}}{\\tilde{\\lambda } } \\end{array}\\right).\\ ] ] proceeding as in @xcite we find the following differential equations @xmath188 let us derive the first equation in for example . from @xcite ( equation @xmath189 ) ,",
    "we have @xmath190 therefore @xmath191\\\\ & = q_{_{n } } + \\int_{-\\infty}^{t}\\frac{\\partial q}{\\partial t}\\,d\\,x - ( 1-\\lambda)\\left[q_{_{n}}+\\int_{\\infty}^{t}\\frac{\\partial q}{\\partial t}\\,d\\,x\\right ] \\\\ & = q_{_{n } } - q_{_{n}}\\int_{-\\infty}^{t}r(x , t)\\,d\\,x - ( 1-\\lambda)\\,q_{_{n}}+(1-\\lambda)\\,q_{_{n}}\\,\\int_{\\infty}^{t}r(x , t)\\,d\\,x \\\\ & = \\lambda\\,q_{_{n}}-q_{_{n}}\\,\\int_{-\\infty}^{\\infty}(1-\\lambda)\\,r(x , t)\\,d\\,x\\\\ & = \\lambda\\,q_{_{n}}-q_{_{n}}\\,\\mathcal{r}_{1,\\lambda } = q_{_{n}}\\left(\\lambda-\\mathcal{r}_{1,\\lambda}\\right).\\end{aligned}\\ ] ] now we change variable from @xmath168 to @xmath192 where @xmath193 .",
    "then we take the limit @xmath182 , denoting the limits of @xmath194 and the common limit of @xmath195 and @xmath196 respectively by @xmath197 and @xmath198 .",
    "we eliminate @xmath199 and @xmath200 by using the facts that @xmath201 and @xmath202 .",
    "these limits hold uniformly for bounded @xmath192 so we can interchange @xmath203 and @xmath204 .",
    "also @xmath205 , where @xmath17 is as in .",
    "we obtain the systems    @xmath206    @xmath207    @xmath208    the change of variables @xmath209 transforms these systems into    @xmath210    @xmath211    @xmath212    since @xmath213 , corresponding to the boundary values at @xmath171 which we found earlier for @xmath214 , we now have initial values at @xmath215 . therefore @xmath216 we use this to solve the systems and",
    "get @xmath217 substituting these expressions into the determinant gives , namely @xmath218 where @xmath219 .",
    "the gse case is the easy one .",
    "all calculations in @xcite and @xcite go through essentially unchanged except for the trailing factor of @xmath220 .",
    "therefore we will not reproduce them here .",
    "the following series of lemmas establish corollary  :    define @xmath221 then @xmath222 satisfies the following recursion @xmath223 [ ajlemma ]    consider the expansion of the generating function @xmath224 around @xmath45    @xmath225 since @xmath226 , the statement of the lemma reduces to proving the following recurrence for the @xmath227 @xmath228 let @xmath229 these are the even and odd parts of @xmath230 relative to the reflection @xmath231 or @xmath232 .",
    "recurrence is equivalent to @xmath233 which is easily shown to be true .",
    "[ flemma ] define @xmath234 for @xmath124",
    ". then @xmath235    the case @xmath236 is readily checked .",
    "the main ingredient for the general case is fa di bruno s formula @xmath237 where @xmath238 and the above sum is over all partitions of @xmath2 , that is all values of @xmath239 such that @xmath240 .",
    "we apply fa di bruno s formula to derivatives of the function @xmath241 , which we treat as some function @xmath242 .",
    "notice that for @xmath243 , @xmath244 is nonzero only when @xmath245 , in which case it equals @xmath246 .",
    "hence , in , the only term that survives is the one corresponding to the partition all of whose parts equal @xmath247 .",
    "thus we have @xmath248    @xmath249    therefore , recalling the definition of @xmath222 in and setting @xmath250 , we obtain @xmath251 similarly , using @xmath252 instead yields @xmath253 since @xmath254 . rearranging this last equality leads to .",
    "let @xmath47 and @xmath255 be as in and",
    ". then @xmath256    using the facts that @xmath257 , @xmath258 and @xmath259 we get    @xmath260    for notational convenience , define @xmath261 .",
    "then    for @xmath262 , @xmath263\\,d_{1}(s,\\lambda)\\,\\,\\bigg{\\vert}_{\\lambda=1}=\\frac{(-1)^{n}}{n!}\\,\\frac{\\partial^{n}}{\\partial\\,\\lambda^{n}}\\,d_{4}(s,\\lambda)\\,\\,\\bigg{\\vert}_{\\lambda=1}.\\ ] ] [ dlemma ]    let @xmath264 by the previous lemma , we need to show that @xmath263\\,d_{4}(s,\\tilde{\\lambda})\\,f(s,\\lambda)\\,\\,\\bigg{\\vert}_{\\lambda=1 } = \\frac{(-1)^{n}}{n!}\\,\\frac{\\partial^{n}}{\\partial\\,\\tilde{\\lambda}^{n}}\\,d_{4}(s,\\tilde{\\lambda})\\,\\,\\bigg{\\vert}_{\\lambda=1}.\\ ] ] now formula applied to @xmath265 gives @xmath266 therefore @xmath267 similarly    @xmath268    therefore @xmath269\\,d_{4}(s,\\tilde{\\lambda})\\,f(s,\\lambda)\\,\\,\\bigg{\\vert}_{\\lambda=1}\\\\ & \\qquad\\qquad= \\sum_{j=0}^{n}\\frac{(-1)^{j}}{(2\\,n-2\\,j)!\\,j!}\\,\\frac{\\partial^{j}}{\\partial\\,\\tilde{\\lambda}^{j}}\\,d_{4\\,}(s,\\tilde{\\lambda } ) \\left[\\frac{\\partial^{2\\,n-2\\,j}}{\\partial\\,\\lambda^{2\\,n-2\\,j}}\\,f- \\frac{1}{2\\,n-2\\,j+1}\\,\\frac{\\partial^{2\\,n-2\\,j+1}}{\\partial\\,\\lambda^{2\\,n-2\\,j+1}}\\,f\\right ] \\,\\,\\bigg{\\vert}_{\\lambda=1}\\end{aligned}\\ ] ] now lemma  [ flemma ] shows that the square bracket inside the summation is zero unless @xmath270 , in which case it is @xmath271 .",
    "the result follows .",
    "lemma  [ dlemma ] establishes the inductive step in the proof of corollary  [ interlacingcor ] .",
    "let @xmath272 so that @xmath273 equals @xmath17 from . in order to compute @xmath54",
    "it is crucial to know @xmath274 accurately .",
    "asymptotic expansions for @xmath274 at @xmath275 are given in @xcite .",
    "we outline how to compute @xmath273 and @xmath276 as an illustration . from @xcite , we know that , as @xmath277 @xmath278 quantities needed to compute @xmath279 are not only @xmath273 but also integrals involving @xmath273 , such as @xmath280 instead of computing these integrals afterwards , it is better to include them as variables in a system together with @xmath273 , as suggested in @xcite .",
    "therefore all quantities needed are computed in one step , greatly reducing errors , and taking full advantage of the powerful numerical tools in matlab . since @xmath281 the system closes , and can be concisely written @xmath282 we first use the matlab built  in runge ",
    "kutta based ode solver ` ode45 ` to obtain a first approximation to the solution of between @xmath283 , and @xmath284 , with an initial values obtained using the airy function on the right hand side .",
    "note that it is not possible to extend the range to the left due to the high instability of the solution a little after @xmath285 ; ( this is where the transition region between the three different regimes in the so  called `` connection problem '' lies .",
    "we circumvent this limitation by patching up our solution with the asymptotic expansion to the left of @xmath284 . ) .",
    "the approximation obtained is then used as a trial solution in the matlab boundary value problem solver ` bvp4c ` , resulting in an accurate solution vector between @xmath283 and @xmath286 .",
    "similarly , if we define @xmath287 then we have the first  order system @xmath288 which can be implemented using ` bvp4c ` together with a `` seed '' solution obtained in the same way as for @xmath273 .",
    "work is in progress to provide publicly downloadable versions of the matlab routines .",
    "table  [ table ] shows a comparison of percentiles of the @xmath289 distribution to corresponding percentiles of empirical wishart distributions . here",
    "@xmath290 denotes the @xmath291 largest eigenvalue in the wishart ensemble .",
    "the percentiles in the @xmath290 columns were obtained by finding the ordinates corresponding to the @xmath289percentiles listed in the first column , and computing the proportion of eigenvalues lying to the left of that ordinate in the empirical distributions for the @xmath290 .",
    "the bold entries correspond to the levels of confidence most commonly used in statistical applications .",
    "the reader should compare this table to a similar one in @xcite .",
    ".percentile comparison of @xmath289 vs. empirical distributions for @xmath292 and @xmath293 wishart matrices with identity covariance .",
    "[ cols=\"^,^,^,^,^,^,^ \" , ]",
    "the author would like to thank craig a. tracy for the discussions that initiated this work and for the invaluable guidance and support that helped complete it , as well as eric rains for useful discussions .",
    "this work was supported in part by the national science foundation under grant dms0304414 ."
  ],
  "abstract_text": [
    "<S> we derive painlev  type expressions for the distribution of the @xmath0 largest eigenvalue in the gaussian orthogonal and symplectic ensembles in the edge scaling limit . </S>",
    "<S> the work of johnstone and soshnikov ( see @xcite , @xcite ) implies the immediate relevance of our formulas for the @xmath0 largest eigenvalue of the appropriate wishart distribution . </S>"
  ]
}