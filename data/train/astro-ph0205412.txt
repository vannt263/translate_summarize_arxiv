{
  "article_text": [
    "embedded within the evolution of the three - dimensional distribution of the dark matter lies a wealth of information on the nature of the dark energy and dark matter in the universe .",
    "the growth of its clustering in volumes associated with redshift , along with the abundance of discrete dark matter clumps or halos which it controls , is one of our most direct probes of the expansion history ( e.g.  @xcite ) .",
    "it is certainly the one that is best understood from the theoretical standpoint .",
    "unfortunately , most probes of structure in the low redshift universe rely on luminous matter , e.g.  galaxies and clusters of galaxies , as tracers of dark matter distribution .",
    "such probes are subject to significant uncertainties in the physical processes that govern the formation and evolution of the tracers .",
    "the only exception is the image distortion from gravitational lensing of distant objects by the dark matter . on large scales and for small distortions ,",
    "this is known as weak gravitational lensing @xcite .",
    "the distortion of faint galaxy images by the large - scale structure of the universe has now been detected with high significance by several experimental groups @xcite .",
    "a fundamental obstacle for weak lensing studies of the matter distribution is that the technique is inherently two - dimensional .",
    "all of the matter along the line - of - sight to a distant source contributes to lensing and so the distortion reflects a two - dimensional projection of the dark matter .",
    "unfortunately then the evolution of structure is hidden in the missing radial dimension .",
    "this limitation can in principle be overcome by a tomographic reconstruction of the three - dimensional distribution from sources spanning a range of distances or redshifts .    under fairly restrictive assumptions ,",
    "this tomographic technique has been applied to lensing data to localize the halo associated with a cluster of galaxies @xcite and validated by follow - up studies .",
    "the critical assumption is that the lensing mass be a single halo , well localized in redshift .",
    "taylor @xcite has recently shown that these and other restrictions are unnecessary _ in principle_. in the absence of noise , tomographic mapping of the dark matter is a well - posed problem . in this paper , we study the feasibility of reconstructing three - dimensional dark matter maps in the presence of noise .",
    "we will show that a careful accounting of the noise and in particular its _ covariance _ across the map is essential for extracting information from the map .",
    "tomography also presents a severe data analysis challenge , similar to but potentially far worse than that facing cosmic microwave background ( cmb ) experiments . a full weak lensing data set will have a two - component , two - dimensional megapixel map for each of ten or more source redshift slices .",
    "we also study how techniques developed for the cmb and galaxy redshift surveys may be applied to compress these data to a more manageable size .",
    "the outline of the paper is as follows .",
    "we begin in   [ sec : formalism ] with a brief review of mapmaking techniques and apply them to the two - dimensional lensing observables keeping careful track of the propagation of measurement errors .",
    "we use these techniques to reconstruct the three - dimensional distribution of the dark matter in ",
    "[ sec : los ] .",
    "although the reconstruction is extremely noisy for any realistic situation , the noise has very particular properties that are absent in the signal .",
    "this fact is used to regularize the solution and radically compress the data in the large - scale structure regime in ",
    "[ sec : lss ] , and in the individual dark matter halo regime in ",
    "[ sec : halos ] .",
    "we discuss these results in ",
    "[ sec : discussion ] .",
    "we begin by briefly reviewing general mapmaking techniques in   [ sec : mapmaking ] , establishing notation used throughout the paper .",
    "these techniques are then applied to the two - dimensional weak lensing shear in   [ sec : observables ] for the reconstruction of convergence maps .",
    "the latter follows the well - known kaiser & squires @xcite algorithm but we pay special attention to the propagation of noise into the convergence reconstruction as that will play a central role in the three - dimensional mapping that follows . in   [ sec : sourceplane ] , we discuss the generalization to multiple source planes .",
    "mapmaking can be formulated in terms of the general inverse problem @xcite , where we seek an estimate @xmath0 of a signal vector @xmath1 from a data vector @xmath2 that is a linear projection @xmath3 of the signal plus measurement noise @xmath4 , @xmath5 the projection matrix @xmath3 has dimensions ( @xmath6,@xmath7 ) , the number of elements in the data and signal vectors respectively , and hence need not be square . here and below subscripts are labels and not elements of the vectors and matrices ; elements will be denoted by @xmath8_{ij}$ ] .",
    "we assume that both the signal and the noise have zero mean @xmath9 , that the signal and noise are uncorrelated , @xmath10 , and that the noise covariance is known , @xmath11 the statistical properties of the signal , @xmath12 may or may not be known .",
    "the estimated signal @xmath0 is that which minimizes @xmath13 where @xmath14 and the penalty function @xmath15 is a set of constraints and/or a regularization to choose among degenerate solutions .    minimizing @xmath16 ( with @xmath17 ) returns the linear estimator @xmath18 where @xmath19^{-1 }       { { \\bf p}_{ba}}^t { { \\bf n}_{bb}}^{-1}\\ , , \\label{eqn : minimumchi2}\\ ] ] and this simple reconstruction is well - posed as long as the product in square brackets is invertible . if @xmath3 itself is invertible then @xmath20 and the estimator becomes independent of both the signal and the noise .",
    "the errors in the reconstruction , @xmath21 { { \\bf s}_{a } } +                 { { \\bf r}_{ab } } { { \\bf n}_{b}}\\,,\\ ] ] imply a new noise covariance @xmath22^{-1}\\ , ,   \\label{eqn : estimatornoise}\\end{aligned}\\ ] ] which is independent of the signal .",
    "note that minimizing @xmath16 is not the same as minimizing the reconstruction noise @xmath23 since reconstruction errors are not penalized by @xmath16 in the noise - dominated regime .",
    "in fact , it minimizes @xmath23 subject to the constraint @xmath24 @xcite .    for a noisy reconstruction , prior knowledge of the statistical properties of the signal can be used as to set a penalty function for a new estimator of the signal @xmath25 minimization of eqn .",
    "( [ eqn : minimize ] ) then returns the wiener filtered estimate of the signal @xmath26 , where @xmath27^{-1 } { { \\bf p}_{ba}}^t { { \\bf n}_{bb}}^{-1 } \\nonumber\\\\          & = & { { \\bf s}_{aa } } { { \\bf p}_{ba}}^t [ { { \\bf p}_{ba } } { { \\bf s}_{aa } } { { \\bf",
    "p}_{ba}}^t +                 { { \\bf n}_{bb}}]^{-1}\\ , , \\label{eqn : wiener}\\end{aligned}\\ ] ] which has the heuristic form of signal/(signal+noise ) and so suppresses the signal in the noise - dominated regime .",
    "the estimator @xmath28 has the noise properties @xmath29 { { \\bf s}_{aa } }      [ { { \\bf r}_{wb}}{{\\bf p}_{ba } } - { { \\bf i}}]^t   \\nonumber\\\\ & & \\quad      + { { \\bf r}_{wb } } { { \\bf n}_{bb } } { { \\bf r}_{wb}}^t \\ , .",
    "\\label{eqn : wienernoise}\\end{aligned}\\ ] ] the wiener estimator may alternately be derived as that which minimizes @xmath30 @xcite .    for a well - posed inverse problem the minimum-@xmath16 and wiener",
    "reconstructions are related by an invertible operation .",
    "we can view the result of the former as providing a new data vector @xmath31 having noise @xmath32 with a covariance @xmath23 .",
    "then with the model of the data @xmath33 , eqn .",
    "( [ eqn : wiener ] ) for the wiener filter returns @xmath34 where @xmath35^{-1}\\,.\\ ] ] since this matrix is invertible , the two reconstructions are formally equivalent .    because the minimum-@xmath16 method does not require prior knowledge , we choose it as the primary mapping technique if the inverse problem is well - posed .",
    "alternatively , for an ill - posed inverse problem , where the matrix @xmath36 is not invertible , wiener filtering can serve as the primary technique .",
    "as the wiener example implies , secondary processing operations on the primary map can be viewed as simply another round of mapmaking .",
    "any linear operation that is invertible will retain the same information content as the original so long as the noise covariance is properly propagated .",
    "we will use this technique to go from the observed lensing shear to the convergence to the density field and finally to the wiener , signal - to - noise , or point source filtered density fields .",
    "the distortion of images due to weak gravitational lensing is described by the jacobian matrix of the mapping between the two - dimensional source and image planes ( e.g.  @xcite ) @xmath37 where all components are functions of position on the sky @xmath38 .",
    "the galaxy ellipticities form a noisy estimator of the shear components @xmath39 which are in turn related to the convergence @xmath40 by ( e.g.  @xcite ) @xmath41({\\hat{\\bf n } } ) = -\\frac{1}{\\pi } \\int d{\\hat{\\bf",
    "n } } '   \\frac{e^{\\pm 2i\\phi}}{\\theta^2 } \\kappa({\\hat{\\bf n}}')\\ , , \\label{eqn : shearkappa}\\ ] ] where @xmath42 denotes the length of the pixel separation vector , and @xmath43 denotes its azimuthal angle in the coordinate system that defines the shear components . by constructing a map of @xmath40 from the shear data ,",
    "one compresses the data set by a factor of two and also transforms the data into a form that is more conveniently related to the three - dimensional density field ( see   [ sec : los ] ) .    discretizing the sky into pixels returns eqn .",
    "( [ eqn : shearkappa ] ) in the form of the general mapmaking problem of eqn .",
    "( [ eqn : mapmaking ] ) , where the signal @xmath44 has been linearly projected onto the data space with measurement noise added to form the data vector , @xmath45 .",
    "explicitly , if one orders the data vector as @xmath46 the model becomes @xmath47 with the projection matrix @xmath48_{(2i-1)j } & = & -\\frac{a_j}{\\pi }       \\frac{\\cos 2\\phi_{ij}}{\\theta^2_{ij } }           \\nonumber\\,,\\\\ \\left[{{\\bf p}_{\\gamma\\kappa } } \\right]_{(2i)j }    & = &    -\\frac{a_j}{\\pi }         \\frac{\\sin 2\\phi_{ij}}{\\theta^2_{ij } } \\,,\\end{aligned}\\ ] ] where the indices run over the pixels of area @xmath49 and the angles are defined as averages over the pixel .",
    "if the noise in the shear data is dominated by the intrinsic ellipticity of galaxies , it is given by @xmath50_{ij } = [ { { \\bf i}}]_{ij } \\frac{\\gamma_{\\rm rms}^2 } { [ { \\bf n}_{\\rm gal}]_i}\\ , , \\label{eqn : shearnoise}\\ ] ] where @xmath51 is a vector containing the number of galaxies per pixel . here @xmath52 is the rms error from intrinsic ellipticities and measurement errors per galaxy .",
    "the intrinsic alignment of galaxies on small scales is a potential source of correlated noise @xcite .",
    "while we neglect its currently uncertain contribution here , the framework we establish can handle any source of noise provided its covariance is known .",
    "we have implicitly assumed here a single set of shear data per pixel .",
    "if the full data set includes multiple observations of the shear of varying quality or even simply the unbinned individual galaxy estimates themselves , one merely extends the data vector and the mapmaking algorithm combines them with the appropriate noise weighting .",
    "mapmaking can also test the validity of eqn .",
    "( [ eqn : shearkappa ] ) , or more properly the data model of eqn .",
    "( [ eqn : shearmodel ] ) , through a reconstruction of the complementary `` b - mode '' map .",
    "this procedure amounts to multiplying the kernel in eqn .",
    "( [ eqn : shearkappa ] ) by @xmath53 corresponding to a rotation of the shear vectors by @xmath54",
    ". the reconstructed map should be consistent with noise .",
    "the estimator of @xmath40 and its noise properties then follow from eqns .",
    "( [ eqn : estimator ] ) and ( [ eqn : estimatornoise ] ) aside from two subtleties .",
    "the first subtlety involves the so - called mass - sheet degeneracy : adding a constant to the @xmath40 signal in eqn .  ( [ eqn : shearkappa ] )",
    "yields no effect in the shear data .",
    "there is then a singular value associated with the inversion in eqn .",
    "( [ eqn : minimumchi2 ] ) .",
    "in general , one way to handle unconstrained modes is to add them to the data vector and assign them zero value but a large noise variance @xcite .",
    "the covariance matrix of eqn .",
    "( [ eqn : estimatornoise ] ) then properly accounts for the lack of information on these modes . for the mass - sheet degeneracy ,",
    "one appends : a zero to the data vector in eqn .",
    "( [ eqn : sheardata ] ) ; a row to the projection matrix with uniform elements @xmath55 ; and a diagonal entry to the noise matrix eqn .",
    "( [ eqn : shearnoise ] ) with a value substantially greater than the variance of @xmath40 smoothed across the field size in any reasonable cosmology .",
    "this same procedure applies to the second subtlety . since eqn .",
    "( [ eqn : shearkappa ] ) represents a convolution , the discrete representation is formally ill - defined for non - contiguous regions of the data , including holes and edges of the finite field .",
    "the sharp fall - off of the convolution kernel implies that only neighboring regions will be affected .",
    "again one can account for these problems by assigning to the unmeasured or contaminated regions zero signal but a substantially larger noise variance than either the signal or noise in the neighboring measured region .",
    "the mapping procedure then propagates an appropriately large and correlated noise into the reconstruction .",
    "if the gaps in the data are comparable to the contiguous regions , then wiener filtering should serve as the primary mapping technique .    in the limit of infinitesimal pixels and an infinite contiguous field",
    "both these subtleties disappear and @xmath56 so if the noise in the shear is also uncorrelated and statistically homogeneous , @xmath57 and eqn .",
    "( [ eqn : estimator ] ) becomes @xmath58 which is the discrete form of the kaiser & squires @xcite result .",
    "furthermore , the noise in the @xmath40 reconstruction @xmath59 .",
    "we will use this approximation for illustration purposes .",
    "these limiting behaviors and their mapmaking implications are simplest to derive in the fourier domain ( e.g. @xcite ) .",
    "so far we have implicitly assumed a single source plane for the lensing observables . in reality",
    "the source galaxies will be broadly distributed around some median set by the depth of the survey .",
    "it is this fact that makes three - dimensional mapping possible .    for definiteness we will typically assume a median redshift @xmath60 and a functional form @xcite @xmath61\\,,\\ ] ] where @xmath62 is the comoving distance in the fiducial cosmological model , and @xmath63",
    "is set to reproduce the median redshift .",
    "the normalization constant @xmath64 is chosen to match the number density of faint galaxies on the sky .",
    "we will take @xmath65 deg@xmath66 and @xmath67 for illustration purposes ; this represents an estimate of the usable galaxies and the shear noise per galaxy measured from a space - based platform ( a.  refregier , private communication ) .    to separate the source galaxies into redshift bins , galaxy redshifts with errors that are smaller than the bin size are needed . without spectroscopic redshifts ,",
    "the precision will be limited by photometric techniques .",
    "we will take a minimum redshift bin of @xmath68 to test the potential of future surveys .",
    "current surveys return photometric redshifts with @xmath69 @xcite .",
    "we shall see that reconstruction noise due to the finite number of galaxies per bin dominates before this resolution is reached so that the photometric redshift errors of even current surveys are unlikely to be the limiting source of error .",
    "the mapmaking technique for multiple source planes with independent noise , as is appropriate for the intrinsic ellipticity noise of eqn .",
    "( [ eqn : shearnoise ] ) , is the trivial generalization of a single source plane . with correlated noise in the shear from systematic effects or intrinsic galaxy alignments , one forms a data vector of all the observations and applies the same mapmaking algorithm to estimate @xmath40 in source redshift bins with appropriately correlated noise .",
    "given two - dimensional convergence maps in multiple source planes , it is in principle possible to reconstruct full three - dimensional density maps ( e.g.  @xcite ) .",
    "we shall see that in practice true mapping requires a prohibitively high signal - to - noise ratio in the lensing observables for reasons fundamental to the lensing projection .",
    "we focus here on the radial reconstruction in a single angular pixel since the full three - dimensional distribution may be constructed as a collection of such reconstructions .",
    "we now take as the data vector @xmath70 in @xmath71 source redshift bins ( in a given angular pixel ) and assume that its noise properties @xmath72 are defined by the reconstruction in   [ sec : observables ] . the model for the convergence @xmath40",
    "is a radial projection of the three - dimensional density distribution ( e.g.  @xcite ) @xmath73 where @xmath62 is the comoving distance in a flat universe , subscript @xmath74 denotes evaluation at the redshift of the source @xmath75 , and @xmath76 is the density fluctuation with the growth rate in a matter - dominated universe scaled out .",
    "discretizing eqn .",
    "( [ eqn : kappaint ] ) in redshift bins returns the general equation of mapmaking ( see eqn .",
    "( [ eqn : mapmaking ] ) ) @xmath77 with @xmath78_{ij } =   \\begin{cases } \\frac{3}{2 } h_0 ^ 2 \\omega_m { { \\delta\\!d}}_j \\frac{(d_{i+1 } - d_j)d_j}{d_{i+1 } }       & \\text { $ d_{i+1 } > d_j$ } , \\\\   0 & \\text { $ d_{i+1 } \\le d_j$ } , \\end{cases } \\label{eqn : denproj}\\end{aligned}\\ ] ] where @xmath79 is the width of bin @xmath80 , the distances are measured to the center of the bins , and we have offset the source redshift bins by 1 so that the projection matrix is purely lower triangular .",
    "for notational simplicity we have assumed that the binning in the signal and data space is the same , but the generalization is straightforward .    the reconstructed density field",
    "is then given by the general mapmaking equation @xmath81 where @xmath82 here @xmath83^{-1}\\ , , \\label{eqn : noisedelta}\\ ] ] is the noise covariance of the estimator .",
    "as noted by taylor @xcite , the reconstruction is in principle well - posed and does not require regularization if the density field is to be recovered to the same redshift resolution and range as the convergence data . our more general treatment accounts for inhomogeneities and correlation in the noise , and even gaps in the data ( see   [ sec : observables ] ) .",
    "more importantly , it returns the noise covariance of the estimator .",
    "we shall see in the next section that without knowledge of the noise _ co_variance the reconstructed density field can not be used for any practical purpose .",
    "the multipixel generalization of radial mapmaking concatenates the vectors for each pixel . for uncorrelated noise in @xmath40-pixels ,",
    "the result is simply the application of mapmaking pixel - by - pixel since the noise matrix is then block diagonal in the pixels . for correlated noise , the noise matrices in the multipixel generalization of eqns .",
    "( [ eqn : radialweight ] ) and ( [ eqn : noisedelta ] ) couple neighboring pixels .      to get a feel for the properties of the reconstruction , consider an idealization with redshift bins that are equal in comoving width @xmath84 , and noise in @xmath40 that is both uncorrelated and homogeneous .",
    "then @xmath85 where @xmath86 and @xmath87_{ij } =   \\begin{cases } ( i+1-j ) \\frac{2j-1}{2i+1 } & \\text { $ j < i+1 $ } \\ , , \\\\ 0 & \\text { else } \\ , . \\end{cases}\\ ] ] with these simplifications the reconstruction matrix is @xmath88_{ij } = \\frac{1}{c}\\,\\frac{2j-1}{2i-1 } \\times \\begin{cases }   1 & \\text { $ j = i-2,i$ } \\ , , \\\\",
    "-2 & \\text { $ j = i-1 $    } \\ , , \\\\   0 & \\text { else       } \\ , .   \\end{cases}\\ ] ] note that the projection matrix is lower triangular , and the reconstruction matrix is tridiagonal .    for @xmath89",
    "the reconstructed density field is essentially the finite difference approximation of the second derivative of the convergence data ; this is the same second derivative seen in taylor s continuous method @xcite . to understand this result , consider the response in @xmath40 to a density fluctuation in a single redshift bin",
    "( also see fig .",
    "[ fig : point]b ) . as we move out in redshift ,",
    "the @xmath40 response is zero until we reach the density fluctuation .",
    "as we cross the fluctuation @xmath40 undergoes a sudden `` acceleration , '' and thereafter grows slowly . with perfect data ,",
    "one would identify density fluctuations as regions where the second derivative of @xmath40 is large .",
    "the problem is that the @xmath40 response accelerates from zero and hence will be hidden by noise locally .",
    "this is the fundamental limitation of weak lensing tomography with real data .",
    "taking finite differences of the data amplifies the noise and strongly correlates it between neighboring pixels . for @xmath89",
    "the noise matrix is @xmath90_{ij } = \\frac{\\sigma^2}{c^2 } \\times \\begin{cases } 1 & \\text { $ j = i-2,\\ , i+2$}\\ , , \\\\ -4 & \\text { $ j = i-1,\\ , i+1$}\\ , , \\\\ 6   & \\text { $ j = i$          } \\ , , \\\\ 0   & \\text { else           } \\ , . \\end{cases } \\label{eqn : noisecov}\\ ] ]",
    "the noise covariance has a very particular form , which corresponds to a finite - difference approximation of a fourth derivative ( see fig .  [",
    "fig : radialmap]b ) . that the noise is correlated in this specific way will turn out to be crucial in extracting any information from the reconstruction .    to see this , consider a toy model where the galaxies are equally distributed among @xmath91 redshift bins that extend to a cosmologically interesting distance @xmath92 .",
    "then @xmath93 and @xmath94 , and the rms noise per bin in the reconstruction is @xmath95 where we have scaled the result with numbers from   [",
    "sec : sourceplane ] for degree scale pixels . even with these generous assumptions ,",
    "the signal - to - noise per bin in the reconstruction is generally small and only approaches unity for density fluctuations that approach unity when averaged over these large volumes .",
    "notice that the noise per bin scales as @xmath96 , which seems to suggest that increasing the radial resolution decreases the total signal - to - noise ratio .",
    "but that would be true only if the noise were uncorrelated .",
    "instead , the fact that the noise covariance has a very specific form that is not seen in realistic signals allows it to be filtered out .",
    "the blind reconstruction of primary mapmaking is therefore useful only as a first step in the process . to extract information out of the map",
    ", one must regularize the reconstruction with a prior assumption about the signal that is to be recovered .",
    "for scales greater than about @xmath97 and the depths reached by modern surveys , the convergence field in a typical region of sky is dominated by large - scale structures in the underlying dark matter density field @xcite . moreover , the fluctuations are in the linear to quasilinear regime where theoretical modeling can be expected to give a good prior assumption about the statistics of the field (   [ sec : signal ] ) . in this limit , one can quantify and better represent the information contained in the noisy three - dimensional density map obtained from the primary mapmaking of the previous section .",
    "we apply two well - known techniques : wiener filtering (   [ sec : wiener ] ) to represent the map itself , and the karhunen - loeve transform (   [ sec : kl ] ) whose eigenmodes encapsulate and expose the underlying information contained in the map .      in the linear regime ,",
    "the signal matrix @xmath98 is related to the linear power spectrum as follows .",
    "the average density fluctuation within the @xmath53th redshift window @xmath99 becomes @xmath100 where @xmath101 is the density fluctuation field .",
    "we assume that the windows are normalized so that @xmath102 .",
    "the signal covariance of these density averages is @xmath103_{ij } & = &   \\int d^3 x_i \\int d^3 x_j\\ , w_i ( { \\bf x}_i ) w_j({\\bf x}_j ) \\nonumber\\\\ & & \\quad \\times \\langle \\delta({\\bf x}_i ) \\delta({\\bf",
    "x}_j ) \\rangle   \\\\ & = & \\frac{g_i}{a_i } \\frac{g_j}{a_j }   \\int \\frac{d^3 k}{(2\\pi)^3 } w_i({\\bf k } ) w_j^*({\\bf k } ) p(k)\\,,\\nonumber \\label{eqn : variancesimp}\\end{aligned}\\ ] ] where @xmath104 is the linear power spectrum today , @xmath105 is the linear growth rate of the density field and @xmath106 are the fourier transforms of the windows .",
    "note that in a matter - dominated universe @xmath107 and so @xmath108 then has the interpretation of the density field extrapolated to the present in linear theory .    for definiteness",
    ", we will take the windows to be a series of slices in redshift at comoving distance @xmath109 and width @xmath110 with a sky pixel radius @xmath111 in radians in the small angle approximation and a flat spatial geometry : @xmath112    for pixels smaller than @xmath113 deg@xmath114 , the density field is in the mildly non - linear regime @xcite . here",
    "the signal matrix should be calculated with a numerical simulation of structure but a simpler approximation here suffices to extract the rough scaling .",
    "we replace in eqn .",
    "( [ eqn : variancesimp ] ) @xmath115^{1/2}\\,,\\ ] ] where @xmath116 obtained from @xmath104 through the scaling relations of @xcite .",
    "this approximation says that structures maintain the same coherence as in linear theory across redshift bins .",
    "the signal matrix can then be used to make a gaussian simulation of structure .",
    "consider the cholesky decomposition of the signal matrix @xmath117 and a vector of independent gaussian random numbers of unit variance @xmath118 , i.e.  @xmath119 .",
    "then @xmath120 is a gaussian realization of the correlated signal vector since @xmath121 again , below the degree scale , the gaussian approximation begins to break down .",
    "however as tested in simulations it remains a reasonable approximation down to @xmath97 @xcite .",
    "= 3.5truein    we show a sample realization in fig .",
    "[ fig : radialmap]a ( shaded ) for a @xmath122cdm cosmology with with parameters @xmath123 , @xmath124 , @xmath125 , @xmath126 , @xmath127 , @xmath128 ( @xmath129 ) , pixel area of 4 deg@xmath114 and redshift binning of @xmath68",
    ". we will use this as the fiducial cosmology in the examples that follow .      as discussed in ",
    "[ sec : mapmaking ] , wiener filtering minimizes the reconstruction noise using prior knowledge of @xmath98 , the covariance matrix of the signal . in fig .",
    "[ fig : radialmap ] , we compare the wiener reconstruction with the primary map for a gaussian realization of structure and several choices of the noise variance .",
    "the thinnest lines ( smoothest for wiener , noisiest for primary ) correspond to the fiducial noise specifications ( @xmath130 deg@xmath66 and @xmath67 ; see   [ sec : sourceplane ] ) , and the noise variance decreases by factors of 10 as the lines thicken . note the hundredfold difference in noise scale between the wiener and primary reconstructions .    the primary reconstruction is far too noisy to recover a visual impression of the structure , even for wildly optimistic assumptions about the noise .",
    "however , the noise has a specific oscillatory structure arising from the noise covariance ( see eqn .",
    "( [ eqn : noisecov ] ) ) , which is neither completely random nor present in the true signal .",
    "the wiener filter uses the information in the noise covariance of the primary reconstruction to reveal the hidden signal . for the fiducial noise specification , the wiener filtered map recovers the low order , long - wavelength features in the density field ; it is not until a prohibitively low noise variance is reached that fine - scale features of order the bin width are recovered .",
    "the wiener reconstruction is useful in cases where a map with well - defined statistical properties is needed , for example for cross - correlation studies with luminous tracers of the dark matter .      in the low signal - to - noise regime",
    ", it is more quantitatively useful to express the data in terms of a new set of orthogonal basis functions that are rank ordered by their signal - to - noise ratio .",
    "low signal - to - noise modes may be eliminated from the data set allowing a near lossless compression of the data .",
    "the pixel representation of these modes then tells us their correspondence to the radial density field .",
    "this is accomplished by the karhunen - loeve transform , also known as the signal - to - noise eigenmode technique ( e.g.  @xcite ) .",
    "consider the generalized eigenmode problem , @xmath131 with a cholesky decomposition @xmath132 the generalized eigenmode problem reduces to an ordinary one @xmath133   [ { { \\bf l}_{\\rm n}}^{t } { { \\bf e } } ] = \\epsilon [ { { \\bf l}_{\\rm n}}^{t } { { \\bf e}}]\\,.\\ ] ] the eigenvectors represent linear combination of the data @xmath134 .",
    "if one composes the matrix with rows representing the eigenvectors @xmath135 the new representation of the data vector becomes @xmath136 the important property of the karhunen - loeve transform is that @xmath137       { { \\bf r}_{{\\rm k}{{\\delta}}}}^t\\nonumber\\\\ & \\equiv & { { \\bf s}_{{\\rm k}{\\rm k } } } + { { \\bf n}_{{\\rm k}{\\rm k}}}\\ , , \\label{eqn : klcov}\\end{aligned}\\ ] ] where the the covariance matrices satisfy the important condition @xmath138 such that the modes are uncorrelated separately in each .",
    "furthermore , @xmath139 quantifies the relative contributions of signal and noise in the mode .",
    "= 3.5truein    = 3.5truein    in fig .",
    "[ fig : snlam ] , we show the signal - to - noise ratio per eigenmode @xmath140 .",
    "this ratio is scaled by the square root of the fraction @xmath141 of the sky covered by a survey , to reflect the increase in the signal - to - noise for a statistical detection with independent pixels .",
    "here we have assumed a pixel size of @xmath142 , which is sufficiently small to extract most of the information on large - scale structure .",
    "note the steep decrease in the signal - to - noise ratio as a function of the eigenmode index : the first few eigenmodes contain most of the information .",
    "this fact allows a radical compression of the data , here from 100 bins to a handful . nonetheless , even though the ratio is small for essentially all of the higher eigenmodes on the scale of individual pixels ( @xmath143 ) , a survey comprising 4400 deg@xmath114 ( @xmath144@xmath145 ) has more than enough signal for a statistical detection .    to understand the information stored in the higher modes , we plot the first few eigenmodes in redshift in fig .  [",
    "fig : eigen ] renormalized to have unit norm .",
    "the first eigenvector simply shows the overall lensing efficiency when integrated over the whole source distribution , i.e.  it has a single peak at a distance halfway to the median redshift @xmath146 .",
    "the higher eigenvectors increase the number of nodes with the boundary conditions that the weight is negligible near the observer at @xmath147 and well beyond the median redshift .",
    "they are therefore the analogues of low order fourier wavevectors in the radial direction .",
    "these low order modes are sensitive to the cosmological model itself in that their values depend on the growth rate of structure , the volume element of the pixel - redshift bins , and the distances in the lensing efficiency .",
    "even a statistical measure of their rms amplitude can help constrain cosmology , in particular the dark energy .",
    "a potential problem for this use of three - dimensional mapping is that a cosmology is assumed both in the karhunen - loeve decomposition and in the projection matrix itself eqn .",
    "( [ eqn : denproj ] ) .",
    "the former problem is readily handled in that even if the a priori assumption of the signal matrix in eqn .",
    "( [ eqn : variancesimp ] ) is incorrect , the karhunen - loeve transform is a well - defined linear operation on the data .",
    "the modification comes about in the calculation of the covariance of the estimators in eqn .",
    "( [ eqn : klcov ] ) .",
    "the covariance is still diagonal in the noise but need not be diagonal in the signal nor do its elements have the interpretation of signal - to - noise .",
    "still , it is calculable for the purpose of model fitting and does not present a fundamental problem .",
    "the second problem is apparently more subtle but reduces to the same issue .",
    "errors in our cosmological assumptions in the projection matrix make the primary map not correspond precisely to a density reconstruction .",
    "fortunately the form of the projection matrix is similar in all cosmologies : a broad bell - shaped weighting that peaks halfway to the source distance .",
    "again , the well - defined linear operations involved allow us to predict the statistics of the primary map given a cosmology in spite of the fact that it does not strictly represent the density field .    of course",
    ", if the recovered cosmology differs greatly from the assumed one , then the signal - to - noise eigenmodes will become an inefficient representation of the data .",
    "the best solution to both problems is to iterate the analysis and converge on a fiducial cosmology that fits the data .",
    "below @xmath97 , the convergence field is dominated by individual structures , or dark matter halos , along the line - of - sight to the source galaxies .",
    "the abundance in redshift of such objects is well known to be exceedingly sensitive to the growth rate of structure and hence the dark energy in the universe @xcite .",
    "identification and mass measurement by lensing would be ideal because the association of luminous observables with the dark mass of the halos is always problematic .",
    "indeed there may exist halos that are effectively dark @xcite .",
    "however , the efficacy of a purely lensing - based study is severely compromised by projection effects @xcite , so three - dimensional mapping in principle holds the key to utilizing this fundamental test .    in the discrete halo case ,",
    "one also has a well - motivated prior to regularize the inversion . in [ sec : mem ] , we discuss a modified version of the maximum entropy method .",
    "this method is most useful in the intermediate regime where the signal contains individual objects embedded in the large - scale structure .",
    "we then describe point source regularization , which is the best method when there is good reason to believe that effectively _ all _ of the structures are well localized and the large - scale structure component can be ignored .",
    "the maximum entropy method ( mem ) is widely applied in situations where a noisy image is assumed to contain both discrete objects and a diffuse component ( e.g.  @xcite ) and has been applied to two - dimensional weak lensing data @xcite . in this case",
    "the noisy image is the primary map @xmath134 , the discrete objects are dark matter halos , and the diffuse component is the large - scale structure of the universe .",
    "mem involves adding a penalty function to the mapmaking minimization of eqn .",
    "( [ eqn : minimize ] ) for the recovery of an mem filtered signal @xmath148 , @xmath149_i \\ln     i[{{\\bf s}_{{\\rm e}}}]_i\\,,\\ ] ] where the intensity @xmath150 is some functional of @xmath151 that we require to be positive .",
    "the lagrange multiplier @xmath152 trades off between minimizing @xmath16 and regularizing the solution .",
    "it is here chosen to give @xmath153 , the degrees of freedom .",
    "the main feature of mem is that while it prefers a uniform solution @xmath154const . , it does not additionally penalize bin - to - bin fluctuations as polynomial regularization would .",
    "hence it allows solutions with discrete objects that occupy only one bin .    to apply mem to our mass reconstruction we need to choose @xmath150 . a natural choice would be @xmath155_i$ ] since the density can not fluctuate to negative values",
    "however this prescription would still strongly disfavor placing all of the mass in a single redshift bin . to allow us more freedom in the regularization",
    "let us take a more general form @xmath156 & = & 1+x \\ , , \\nonumber\\\\    x   & = & \\delta_{\\rm thr } \\arctan           \\left ( \\frac{a_i [ { { \\bf s}_{\\rm e}}]_i}{\\delta_{\\rm thr}}\\right)\\,.\\end{aligned}\\ ] ] the parameter @xmath157 places a threshold density above which mem no longer penalizes the reconstruction ; it returns the natural choice when @xmath158 .",
    "= 3.5truein    in fig .",
    "[ fig : mem ] we show an example of the technique for the case of a halo embedded in large scale structure . for a high @xmath157 compared with the true density contrast of the halo , mem seeks to regularize the reconstructed density in pixels and returns a smooth solution . for a @xmath157 that is lower , mem places a density spike at the right position but the wrong amplitude .",
    "it favors a solution where the neighboring bins are all underdense since there is no penalty for further adding to the height of the spike .",
    "a fundamental drawback of mem is the difficulty in assessing the errors in the reconstruction , i.e.  the reality of the discrete objects mem finds .",
    "note that by construction both solutions in fig .",
    "[ fig : mem ] have exactly the same @xmath16 , and the radical change in character of the solution is driven by the prior assumption of @xmath157 which sets the likelihood of having a comparable density spike in the solution . still",
    ", mem can identify interesting regions in the data for further study , perhaps with the point source method below .",
    "conversely , it provides a useful cross check on the robustness of the point source solutions below .      in regions that are known to be atypical of large - scale structure",
    " either as flagged by the mem reconstruction or simply because the signal in @xmath40 is much too large to be generated by large - scale structure  it is reasonable to assume as a prior that the density field is dominated by a collection of discrete massive objects .",
    "ironically , this form of anti - regularization of the density field in redshift bins is itself the most extreme regularization of the ones considered here , i.e.  it has the least number of allowed degrees of freedom .",
    "the single - object form of this technique has been applied to data by @xcite and yields impressively _ precise _ predictions of the redshift or radial location .",
    "whether the predictions are _ accurate _ , however , depends on the validity of the single - object assumption and on the regularization criteria more generally .",
    "let us state the criteria in a more general form .",
    "define the penalty function on a point - source  regularized reconstruction @xmath159 as @xmath160 where @xmath161 is the number of redshift bins occupied by a density fluctuation , and @xmath162 is a prior assumption of the number of discrete objects ( halos ) the reconstruction should have . in other words , the minimization of eqn .",
    "( [ eqn : minimize ] ) is strictly over the position and density amplitude of @xmath162 objects .",
    "the danger in this method of course is that it will return a best fit for the @xmath162 objects even if the solution is in fact a smooth distribution or composed of some other number of objects .",
    "a well - defined procedure that makes minimal use of prior information is to identify sky pixels like to contain one or more massive objects ( as described above ) , and to perform a sequence of minimizations with @xmath163 , stopping when the @xmath16 does not improve significantly .",
    "= 3.5truein    in fig .",
    "[ fig : point]a , we show an example with two very massive cluster - sized halos at @xmath164 and @xmath165 .",
    "( the masses are enclosed entirely within the @xmath142 pixels and their respective redshift bins . )",
    "the fit assuming one point source returns @xmath166 for 100 redshift bins and two parameters  a perfectly good fit .",
    "the fit yields a redshift constraint @xmath167 that is remarkably precise , but wrong .",
    "going to @xmath168 does recover two objects in the proper locations , with @xmath169 for two fewer degrees of freedom . in fig .",
    "[ fig : point]b we show the implied @xmath40 fields plotted against the original data . the residuals for the one - object fit show coherent structure near the true halo locations and so the improvement in @xmath16 is significant .",
    "still , this example warns against blindly interpreting the formal errors of the fit .",
    "it is actually an optimistic example because the large masses and redshift separation @xmath170 yield a signal much larger and much better separated than expected for real weak lensing measurements .    to better distinguish between close alternatives one could fold in prior information . for example",
    ", one could use the theoretically well - understood abundance of massive halos to determine the relative likelihood of the solutions given the recovered masses of the objects , e.g.two halos of @xmath171 @xmath172 may be favored over one halo of @xmath173 @xmath172 due to the predicted exponential suppression in the number density of high mass halos .",
    "one could also use model profiles to create matched filters across smaller pixels that resolve the halo .",
    "finally , prior information from photometric redshifts of galaxies likely to be members of the cluster(s ) could decide between competing solutions @xcite .",
    "we have shown that the evolution of the shear field in source redshift contains large - scale information about the distribution of dark matter , statistical information about its fluctuations on smaller scales , and redshift localization information for massive dark matter halos on the smallest scales where the signal is large .",
    "this information is hidden in the noise of a direct reconstruction , and its extraction requires mild prior assumptions about the statistical properties of the density field .",
    "we have argued for an approach that begins with a lossless direct or primary reconstruction that is followed by regularization by a prior that is appropriate for the information that is to be extracted .    in the large to intermediate scale regime",
    ", the information content can be distilled into signal - to - noise or kl eigenmodes which efficiently compress the data by a factor of 10 or more .",
    "these low - order modes probe the slow evolution of the statistics of the density field and are well suited to studying the properties of the dark energy .",
    "tomographic sensitivity to the dark energy has been previously noted in the two - point correlation of the shear through the improvement of projected measures of the dark energy density and equation of state for future surveys @xcite .",
    "the kl eigenmode decomposition retains information from the higher order correlations in the field @xcite and also establishes a more direct , non - parametric quantification of the information contained in the data .",
    "a full study of the cosmological implications is beyond the scope of this paper , but we believe that it will be a promising approach for the future .",
    "wiener filtering in the large - scale regime returns large scale maps of the density field with well - defined statistical properties",
    ". these should be useful in cross - correlation studies with luminous , biased tracers of the dark matter such as galaxies and galaxy clusters @xcite .",
    "with information on the radial dimension , information on the evolution of the bias can be recovered which in turn constrains the tracers formation and evolution .    in the individual halo regime , tomographic techniques",
    "have already been successfully applied to data @xcite . with a well - motivated prior on the number of discrete halos along the line of sight",
    ", the reconstruction can yield excellent localization of the object(s ) , in principle to a precision that is better than that in the source redshifts themselves .",
    "however the accuracy is compromised by an incorrect assumption of the number of objects . here",
    "we advocate a combined approach of adding discrete objects to the fit , regularizing by maximum entropy , and employing prior information and followup .    while it is unfortunate that these prior assumptions are necessary for extracting information from three - dimensional reconstructions of the density field , they are generally well - motivated and testable .",
    "gravitational lensing therefore remains our most direct , assumption - free means of probing the distribution of the dark matter .",
    "_ acknowledgments : _ we thank j.  frieman and a.  kravtsov for useful conversations .",
    "wh is supported by nasa nag5 - 10840 and the doe oji program .",
    "crk is supported by nasa through hubble fellowship grant hst - hf-01141.01-a from the space telescope science institute , which is operated by the association of universities for research in astronomy , inc .",
    ", under nasa contract nas5 - 26555 .",
    "d.  bacon , a.  refregier , r.  ellis , mon . not .",
    "soc . , * 318 * , 625 ( 2000 ) ; n.  kaiser , g.  wilson , g.a .",
    "luppino , astrophys .",
    ", submitted , astro - ph/0003338 ( 2000 ) ; l.  van waerbeke , _ et al .",
    ", * 358 * , 30 ( 2000 ) ; d.m .",
    "wittman , j.a .",
    "tyson , d.  kirkman , i.  dellantonio , g.  bernstein ,              p.  catelan , m.  kamionkowski , r.d .",
    "blandford , mon . not .",
    "* 323 * , 713 ( 2001 ) ; r.  crittenden , p.  natarajan , u.  pen , t.  theuns , astrophys .",
    "j , * 559 * , 552 ( 2001 ) ; r.a.c .",
    "croft , c.  metzler , astrophys .",
    "j , * 545 * , 561 ( 2000 ) ; a.f .",
    "heavens , a.  refregier , c.  heymans , mon . not .",
    "soc . , * 319 * , 649 ( 2000 ) .",
    "m.  tegmark , a.n .",
    "taylor , a.f .",
    "heavens , astrophys .",
    "j , * 480 * , 22 ( 1997 ) ; m.s .",
    "vogeley , a.s .",
    "szalay , astrophys .",
    "j , * 465 * , 34 ( 1996 ) ; j.r .  bond , phys .",
    "lett . , * 74 * , 4369 ( 1995 ) ; e.f .",
    "bunn , n.  sugiyama , astrophys .",
    "j , * 446 * , 49 ( 1995 ) .",
    "bahcall , x.  fan , astrophys .",
    "j , * 504 * , 1 ( 1998 ) ; a.  blanchard , j.g .",
    "bartlett , astron .",
    "astrophys . , * 332 * , l49 ( 1998 ) ; p.t.p .",
    "viana , a.r .",
    "liddle , mon . not .",
    ", * 303 * , 535 ( 1999 ) ; z.  haiman , j.j .  mohr , g.p .  holder ,",
    "j , * 553 * , 545 ( 2001 ) .",
    "t.  erben , _ et al . _ astron .",
    "astrophys . , * 355 * , 23 ( 2000 ) ; k.  umetsu , t.  futamase , astrophys .",
    "j , * 539 * , 5 ( 2000 ) ; j.m .",
    "miralles , _ et al .",
    "astrophys . ,",
    "submitted , astro - ph/0202122 ( 2002 ) ; n.n .",
    "weinberg , m.  kamionkowski , mon . not .",
    "soc . , submitted , astro - ph/0203061 ( 2002 ) ."
  ],
  "abstract_text": [
    "<S> we study the prospects for three - dimensional mapping of the dark matter to high redshift through the shearing of faint galaxies images at multiple distances by gravitational lensing . </S>",
    "<S> such maps could provide invaluable information on the nature of the dark energy and dark matter . while in principle well - posed </S>",
    "<S> , mapping by direct inversion introduces exceedingly large , but usefully correlated noise into the reconstruction . by carefully propagating the noise covariance </S>",
    "<S> , we show that lensing contains substantial information , both direct and statistical , on the large - scale radial evolution of the density field . </S>",
    "<S> this information can be efficiently distilled into low - order signal - to - noise eigenmodes which may be used to compress the data by over an order of magnitude . </S>",
    "<S> such compression will be useful for the statistical analysis of future large data sets . </S>",
    "<S> the reconstructed map also contains useful information on the localization of individual massive dark matter halos , and hence the dark energy from halo number counts , but its extraction depends strongly on prior assumptions . </S>",
    "<S> we outline a procedure for maximum entropy and point - source regularization of the maps that can identify alternate reconstructions . </S>"
  ]
}