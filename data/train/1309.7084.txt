{
  "article_text": [
    "consider a typical design problem with more than one objectives ( design criteria ) .",
    "for example , we may want to design a network that provides the maximum capacity with the minimum cost , or we may want to design a radiation therapy for a patient that maximizes the dose to the tumor and minimizes the dose to the healthy organs .",
    "in such _ multiobjective _ ( or _ multicriteria _ ) problems there is typically no solution that optimizes simultaneously all the objectives , but rather a set of so - called _ pareto optimal _ solutions , i.e. , solutions that are not dominated by any other solution in all the objectives .",
    "the trade - off between the different objectives is captured by the _ trade - off _ or _",
    "pareto curve _",
    "( surface for three or more objectives ) , the set of values of the objective functions for all the pareto optimal solutions .",
    "multiobjective problems are prevalent in many fields , e.g. , engineering , economics , management , healthcare , etc .",
    "there is extensive research in this area published in different fields ; see @xcite for some books and surveys . in a multiobjective problem",
    ", we would ideally like to compute the pareto curve and present it to the decision maker to select the solution that strikes the ` right ' balance between the objectives according to his / her preferences ( and different users may prefer different points on the curve ) .",
    "the problem is that the pareto curve has typically an enormous number of points , or even an infinite number for continuous problems ( with no closed form description ) , and thus we can not compute all of them .",
    "we can only compute a limited number of solutions ( points ) , and of course we want the computed points to provide a good approximation to the pareto curve so that the decision maker can get a good sense of the range of possibilities in the design space .",
    "we measure the quality of the approximation provided by a computed solution set using a ( multiplicative ) approximation ratio , as in the case of approximation algorithms for single - objective problems .",
    "assume ( as usual in approximation algorithms ) that the objective functions take positive values .",
    "a set of solutions @xmath0 is an _",
    "@xmath1-pareto set _ if the members of @xmath0 approximately dominate within @xmath2 every other solution , i.e. , for every solution @xmath3 there is a solution @xmath4 such that @xmath5 is within a factor @xmath2 or better of @xmath3 in all the objectives @xcite . often , after computing a finite set @xmath0 of solutions and their corresponding points in objective space ( i.e. , their vectors of objective values ) , we ` connect the dots ' , taking in effect also the convex combinations of the solution points . in problems where the solution points",
    "form a convex set ( examples include multiobjective flows , linear programming , convex programming ) , this convexification is justified and provides a much better approximation of the pareto curve than the original set @xmath0 of individual points .",
    "a set @xmath0 of solutions is called an _",
    "@xmath1-convex pareto set _ if the convex hull of the solution points corresponding to @xmath0 approximately dominates within @xmath2 all the solution points @xcite . even for applications with nonconvex solution sets ,",
    "sometimes solutions that are dominated by convex combinations of other solutions are considered inferior , and one is interested only in solutions that are not thus dominated , i.e. , in solutions whose objective values are on the ( undominated ) boundary of the convex hull of all solution points , the so - called _ convex pareto set_. note that every instance of a multiobjective problem has a unique pareto set and a unique convex pareto set , but in general it has many different @xmath1-pareto sets and @xmath1-convex pareto sets , and furthermore these can have drastically different sizes .",
    "it is known that for every multiobjective problem with a fixed number @xmath6 of polynomially computable objective functions , there exist an @xmath1-pareto set ( and also @xmath1-convex pareto set ) of polynomial size , in particular of size @xmath7 , where @xmath8 is the bit complexity of the objective functions ( i.e. , the functions take values in the range @xmath9 $ ] ) @xcite . whether such approximate sets can be constructed in polynomial time is another matter : necessary and sufficient conditions for polynomial time constructibility of @xmath1-pareto and @xmath1-convex pareto sets are given respectively in @xcite .    the most common approach to the generation of pareto points ( called weighted - sum method ) is to give nonnegative weights @xmath10 to the different objective functions @xmath11 ( assume for simplicity that they are all minimization objectives ) and then optimize the linear combining function @xmath12 ; this approach assumes availability of a subroutine @xmath13 that optimizes such linear combinations of the objectives . for any set of nonnegative weights ,",
    "the optimal solution is clearly in the pareto set , actually in the convex pareto set .",
    "in fact , the convex pareto set is precisely the set of optimal solutions for _ all _ possible such weighted linear combinations of the objectives .",
    "of course , we can not try all possible weights ; we must select carefully a finite set of weights , so that the resulting set of solutions provides a good approximation , i.e. , is an @xmath1-convex pareto set for a desired small @xmath1 .",
    "it is shown in @xcite that a necessary and sufficient condition for the polynomial time constructibility of an @xmath1-convex pareto set is the availability of a polynomial time @xmath13 routine for the approximate optimization of nonnegative linear combinations .    in a typical multiobjective problem ,",
    "the @xmath13 routine is a nontrivial piece of software , each call takes a substantial amount of time , thus we want to make the best use of the calls to achieve as good a representation of the solution space as possible .",
    "ideally , we would like to achieve the smallest possible approximation error @xmath1 with the fewest number of calls to the @xmath13 routine .",
    "that is , given @xmath14 , compute an @xmath1-convex pareto set for the instance at hand using _ as few comb calls as possible_. ( in @xcite we study a different cost metric ; we explain the difference at the end of this section , and we note that both metrics are relevant for different aspects of decision making in multiobjective problems . ) we measure the performance of an algorithm by the ratio of its cost , i.e. , the number of calls that it makes , to the minimum possible number required for the instance at hand ( as is usual in approximation algorithms ) .",
    "let @xmath15 be the number of points in the smallest @xmath1-convex pareto set for an instance @xmath16 . clearly , every algorithm that computes an @xmath1-convex pareto set needs to make at least @xmath15 calls .",
    "the _ performance ( competitive ) ratio _ of an algorithm @xmath17 that computes an @xmath1-convex pareto set using @xmath18 calls for each instance @xmath16 is @xmath19 .",
    "an important point that should be stressed here is that , as in the case of online algorithms , the algorithm does not have complete information about the input , i.e. , the ( convex ) pareto curve is _ not _ given explicitly , but can only be accessed indirectly through calls to the @xmath13 routine ; in fact , the whole purpose of the algorithm is to obtain an approximate knowledge of the curve .    in this paper",
    "we investigate the performance of the _ chord _ algorithm , a simple , natural greedy algorithm for the approximate construction of the pareto set .",
    "the algorithm and variants of it have been used often , under various names , for multiobjective problems @xcite as well as several other types of applications involving the approximation of curves , which we will describe later on .",
    "we focus on the bi - objective case ; although the algorithm can be defined ( and has been used ) for more objectives , most of the literature concerns the bi - objective case , which is already rich enough , and covers also most of the common uses of the algorithm .",
    "we now briefly describe the algorithm .",
    "let @xmath20 , @xmath21 be the two objectives ( say minimization objectives for concreteness ) , and let @xmath22 be the ( unknown ) convex pareto curve .",
    "first optimize @xmath20 , and @xmath21 separately ( i.e. , call @xmath13 for the weight tuples @xmath23 and @xmath24 ) to compute the leftmost and rightmost points @xmath25 of the curve @xmath22 .",
    "the segment @xmath26 is a first approximation to @xmath22 ; its quality is determined by a point @xmath27 that is least well covered by the segment .",
    "it is easy to see that this worst point @xmath28 is a point of the pareto curve @xmath22 that minimizes the linear combination @xmath29 , where @xmath30 is the absolute value of the slope of @xmath26 , i.e. , it is a point of @xmath22 with a supporting line parallel to the ` chord ' @xmath26 .",
    "compute such a worst point @xmath28 ; if the error is at most @xmath1 , then terminate , otherwise add @xmath28 to the set @xmath0 to form an approximate set @xmath31 and recurse on the two intervals @xmath32 and @xmath33 . in section  [ sec : prelim ]",
    "we give a more detailed formal description ( for example , in some cases one can determine from previous information that the maximum possible error in an interval is upper bounded by @xmath1 and do not need to call @xmath13 ) .",
    "the algorithm is quite natural , it has been often reinvented and is commonly used for a number of other purposes .",
    "as pointed out in @xcite , an early application was by archimedes who used it to approximate a parabola for area estimation @xcite .",
    "in the area of _ parametric optimization _ , the algorithm is known as the  eisner - severance \" method after @xcite .",
    "note that parametric optimization is closely related to bi - objective optimization .",
    "for example , in the parametric shortest path problem , each edge @xmath34 has cost @xmath35 that depends on a parameter @xmath36 .",
    "the length of the shortest path is a piecewise linear function of @xmath36 whose pieces correspond to the vertices of the convex pareto curve for the bi - objective shortest path problem with cost vectors @xmath37 on the edges .",
    "a call to the @xmath13 routine for the bi - objective problem corresponds to solving the parametric problem for a particular value of the parameter .",
    "the chord algorithm is also useful for the approximation of convex functions , and for the approximation and smoothening of convex and even non - convex curves . in the case of functions ,",
    "an appropriate measure of distance between the function @xmath38 and the approximation is the vertical distance , while for curves a natural measure is the hausdorff distance ; note that for a given curve and approximating segment @xmath39 , the same point @xmath28 of the curve with supporting line parallel to @xmath39 maximizes also the above distances . in the context of smoothening and compressing curves and polygonal lines for graphics and related applications , the chord algorithm is known as the ramer - douglas - peucker algorithm , after  @xcite who independently proposed it .",
    "previous work has analyzed the chord algorithm ( and variants ) for achieving an @xmath1-approximation of a function or curve with respect to vertical and hausdorff distance , and proved bounds on the cost of the algorithm as a function of @xmath1 : for all convex curves of length @xmath40 , ( under some technical conditions on the derivatives ) the algorithm uses at most @xmath41 calls to construct an @xmath1-approximation , and there are curves ( for example , a portion of a circle ) that require @xmath42 calls  @xcite .",
    "note however that these results do not tell us what the performance ratio is , because for many instances , the optimal cost @xmath43 may be much smaller than @xmath44 , perhaps even a constant . for example",
    ", if @xmath22 is a convex polygonal line with few vertices , then the chord algorithm will perform very well for @xmath45 ; in fact , as shown by @xcite in the context of parametric optimization , if there are @xmath46 breakpoints , then the algorithm will compute the exact curve after @xmath47 calls .",
    "( the problem is of course that in most bi - objective and parametric problems , the number @xmath46 of vertices is huge , or even infinite for continuous problems , and thus we have to approximate . )    in this paper we provide sharp upper and lower bounds on the performance ( competitive ) ratio of the chord algorithm , both in the worst case and in the average case setting . consider a bi - objective problem where the objective functions take values in @xmath9 $ ] .",
    "we prove that the worst - case performance ratio of the chord algorithm for computing an @xmath1-convex pareto set is @xmath48 .",
    "the upper bound implies in particular that for problems with polynomially computable objective functions and a polynomial - time ( exact or approximate ) comb routine , the chord algorithm runs in polynomial time in the input size and @xmath49 .",
    "we show furthermore that there is no algorithm with constant performance ratio . in particular ,",
    "every algorithm ( even randomized ) has performance ratio at least @xmath50 .",
    "similar results hold for the approximation of convex curves with respect to the hausdorff distance .",
    "that is , the performance ratio of the chord algorithm for approximating a convex curve of length @xmath40 within hausdorff distance @xmath1 , is @xmath51 .",
    "furthermore , every algorithm has worst - case performance ratio at least @xmath52 .",
    "we also analyze the expected performance of the chord algorithm for some natural probability distributions .",
    "given that the algorithm is used in practice in various contexts with good performance , and since worst - case instances are often pathological and extreme , it is interesting to analyze the average case performance of the algorithm .",
    "indeed , we show that the performance on the average is exponentially better . note that chord is a simple natural greedy algorithm , and is not tuned to any particular distribution .",
    "we consider instances generated by a class of product distributions that are `` approximately '' uniform and prove that the expected performance ratio of the chord algorithm is @xmath53 ( upper and lower bound ) . again",
    "similar results hold for the hausdorff distance",
    ".    * related work .",
    "* there is extensive work on multiobjective optimization , as well as on approximation of curves in various contexts .",
    "we have discussed already the main related references .",
    "the problem addressed by the chord algorithm fits within the general framework of determining the shape by probing @xcite .",
    "most of the work in this area concerns the exact reconstruction , and the analytical works on approximation ( e.g. , @xcite ) compute only the worst - case cost of the algorithm in terms of @xmath1 ( showing bounds of the form @xmath54 ) .",
    "there does not seem to be any prior work comparing the cost of the algorithm to the optimal cost for the instance at hand , i.e. , the approximation ratio , which is the usual way of measuring the performance of approximation algorithms .",
    "the closest work in multiobjective optimization is our prior work @xcite on the approximation of convex pareto curves using a different cost metric .",
    "both of the metrics are important and reflect different aspects of the use of the approximation in the decision making process .",
    "consider a problem , say with two objectives , suppose we make several calls , say @xmath46 , to the @xmath13 routine , compute a number of solution points , connect them and present the resulting curve to the decision maker to visualize the range of possibilities , i.e. , get an idea of the true convex pareto curve .",
    "( the process may not end there , e.g. , the decision maker may narrow the range of interest , followed by computation of a better approximation for the narrower range , and so forth ) . in this scenario ,",
    "we want to achieve as small an error @xmath1 as possible , using as small a number @xmath46 of calls as we can , ideally , as close as possible to the minimum number @xmath15 that is absolutely needed for the instance . in this",
    "setting , the cost of the algorithm is measured by the number of calls ( i.e. , the computational effort ) ; this is the cost metric that we study in this paper , and the performance ratio is as usual the ratio of the cost to the optimum cost .",
    "consider now a scenario where the decision maker does not just inspect visually the curve , but will look more closely at a set of solutions to select one ; for instance a physician in the radiotherapy example will consider carefully a small number of possible treatments in detail to decide which one to follow . since human time is much more limited than computational time ( and more valuable , even small constant factors matter a lot ) , the primary metric in this scenario is the number @xmath55 of selected solutions that is presented to the decision maker for closer investigation ( we want @xmath55 to be as close as possible to @xmath15 ) , while the computational time , i.e. , the number @xmath46 of calls , is less important and can be much larger ( as long as it is feasible of course ) .",
    "this second cost metric ( the size @xmath55 of the selected set ) is studied in @xcite for the convex pareto curve ( and in @xcite in the nonconvex case ) . among other results ,",
    "it is shown there that for all bi - objective problems with an exact @xmath13 routine and a continuous convex space , an optimal @xmath1-convex pareto set ( i.e. , one with @xmath15 solutions ) can be computed in polynomial time using @xmath56 calls to @xmath13 in general , ( though more efficient algorithms are obtained for specific important problems such as bi - objective lp ) .",
    "for discrete problems , a @xmath57-approximation to the minimum size can be obtained in polynomial time , and the factor @xmath57 is inherent . as remarked above , both cost metrics are important for different stages of the decision making .",
    "recall also that , as noted earlier , the chord algorithm runs in polynomial time , and furthermore , one can show that its solution set can be post - processed to select a subset that is a @xmath1-convex pareto set of size at most @xmath58 .",
    "* structure of the paper . * the rest of the paper is organized as follows : section  [ sec : prelim ] describes the model and states our main results , section  [ sec : worst ] concerns the worst - case analysis , and section  [ sec : average ] the average - case analysis .",
    "section  [ sec : concl ] concludes the paper and suggests the most relevant future research directions .",
    "this section is structured as follows : after giving basic notation , in section  [ ssec : defs ] we describe the relevant definitions and framework from multiobjective optimization . in section  [ ssec : chord - description ] we provide a formal description of the chord algorithm in tandem with an intuitive explanation .",
    "finally , in section  [ ssec : results ] we state our results on the performance of the algorithm as well as our general lower bounds .",
    "* notation .",
    "* we start by introducing some notation used throughout the paper . for @xmath59",
    ", we will denote @xmath60 : = \\{1,2,\\ldots , n\\}$ ] and @xmath61 : = \\ { i , i+1 , \\ldots , j \\}$ ] . for @xmath62 , we denote by @xmath63 the line segment with endpoints @xmath64 and @xmath28 , @xmath65 denotes its length , @xmath66 is the triangle defined by @xmath67 and @xmath68 is the internal angle of @xmath66 formed by @xmath63 and @xmath69",
    ".    we will use @xmath70 and @xmath71 as the two coordinates of the plane . if @xmath64 is a point on the plane , we use @xmath72 and @xmath73 to denote its coordinates ; that is , @xmath74 .",
    "we will typically use the symbol @xmath36 to denote the ( absolute value of the ) slope of a line , unless otherwise specified .",
    "sometimes we will add an appropriate subscript , i.e. , we will use @xmath75 to denote the slope of the line defined by @xmath64 and @xmath28 . for a lebesgue measurable set @xmath76",
    "we will denote its area by @xmath77 .",
    "we describe the general framework of a bi - objective problem @xmath78 to which our results are applicable .",
    "a bi - objective optimization problem has a set of valid instances , and every instance has an associated set of feasible solutions , usually called the solution or decision space .",
    "there are two objective functions , each of which maps every instance ",
    "solution pair to a real number .",
    "the problem specifies for each objective whether it is to be maximized or minimized .",
    "consider the plane whose coordinates correspond to the two objectives .",
    "every solution is mapped to a point on this plane .",
    "we denote the objective functions by @xmath70 and @xmath71 and we use @xmath79 to denote the objective space ( i.e. , the set of @xmath57-vectors of objective values of the feasible solutions for the given instance ) . as usual in approximation , we assume that the objective functions are polynomial time computable and take values in @xmath80 $ ] , i.e. , @xmath81 ^ 2 $ ] , where @xmath8 is polynomially bounded in the size of the input . note that this framework covers all discrete combinatorial optimization problems of interest ( e.g. , shortest paths , spanning tree , matching , etc ) , but also contains many continuous problems ( e.g. , linear and convex programs , etc ) . throughout this paper we assume , for the sake of concreteness , that both objective functions @xmath70 and @xmath71 are to be minimized .",
    "all our results hold also for the case of maximization or mixed objectives .",
    "let @xmath82 .",
    "we say that @xmath64 _ dominates _",
    "@xmath28 if @xmath83 ( coordinate - wise ) .",
    "we say that @xmath64 _",
    "@xmath28 ( @xmath85 ) if @xmath86 .",
    "let @xmath87 .",
    "the _ pareto set _ of @xmath88 , denoted by @xmath89 , is the subset of undominated points in @xmath88 ( i.e. , @xmath90 iff @xmath91 and no other point in @xmath88 dominates @xmath64 ) .",
    "the convex pareto set of a @xmath88 , denoted by @xmath92 , is the minimum subset of @xmath88 whose convex combinations dominate ( every point in ) @xmath88 .",
    "we also use the term _ lower envelope _ of @xmath88 to denote the pareto set of its convex hull , i.e. , @xmath93 .",
    "in particular , if @xmath88 is convex its lower envelope is identified with its pareto set .",
    "if @xmath88 is finite , its lower envelope is a convex polygonal chain with vertices the points of @xmath92 .",
    "note that , for any set @xmath88 , the lower envelope @xmath94 is a convex and monotone decreasing planar curve .",
    "for @xmath95 we will denote by @xmath96 the subset of @xmath94 with endpoints @xmath64 , @xmath28",
    ".    an _ @xmath84-convex pareto set _ of @xmath88 ( henceforth @xmath84-cp ) is a subset @xmath97 of @xmath88 whose convex combinations @xmath84-cover ( every point in ) @xmath88 .",
    "note that such a set need not contain points dominated by convex combinations of other points , as they are redundant .",
    "if a set contains no redundant points , we call it non - redundant .",
    "let @xmath98 , @xmath99 and @xmath100 , be a non - redundant set . by definition",
    ", @xmath0 is an @xmath84-cp for @xmath88 if and only if the polygonal chain @xmath101 @xmath84-covers @xmath92 .",
    "we define the _ ratio distance _ from a point @xmath64 to a point @xmath28 as @xmath102 .",
    "( note the asymmetry in the definition . ) intuitively , it is the minimum value of @xmath103 such that @xmath28 @xmath84-covers @xmath64 .",
    "we also define the ratio distance between sets of points . if @xmath104 , then @xmath105 . as a corollary of this definition ,",
    "the set @xmath106 is an @xmath84-cp for @xmath88 if and only if @xmath107 .",
    "the above definitions apply to any set @xmath87 .",
    "let @xmath78 be a bi - objective optimization problem in the aforementioned framework .",
    "for an instance of @xmath78 , the set @xmath88 corresponds to the objective space @xmath79 ( for the given instance ) .",
    "we do not assume that the objective space @xmath79 is convex ; it may well be discrete or a continuous non - convex set .",
    "it should be stressed that the objective space is not given explicitly , but rather implicitly through the instance . in particular , we access the objective space @xmath79 of @xmath78 via an oracle @xmath108 that ( exactly or approximately ) minimizes non - negative linear combinations @xmath109 of the objectives . that is , the oracle takes as input a parameter @xmath110 and outputs a point @xmath111 ( i.e. , a feasible point ) that ( exactly or approximately ) minimizes the combined objective function @xmath112 .",
    "we use the convention that , for @xmath113 , the oracle minimizes the @xmath70 objective .    formally , for @xmath114 , we denote by @xmath115 the problem of optimizing the combined objective @xmath116 over @xmath79 .",
    "let @xmath117 be an accuracy parameter .",
    "then , for @xmath114 , we will denote by @xmath118 a routine that returns a point @xmath111 that optimizes @xmath119 up to a factor of @xmath120 , i.e. , @xmath121 .",
    "in other words , the @xmath122 routine is an `` approximate optimization oracle '' for the objective space @xmath79 .",
    "we say that the @xmath108 problem has a polynomial time approximation scheme ( ptas ) , if for any instance of @xmath78 and any @xmath123 there exists a routine @xmath118 ( as specified above ) that runs in time polynomial in the size of the instance .",
    "as shown in  @xcite , for any bi - objective problem in the aforementioned framework , there is a ptas for constructing an @xmath84-convex pareto set if and only if there is a ptas for the @xmath108 problem .",
    "we now provide a geometric characterization of @xmath118 that will be crucial throughout this paper .",
    "consider the point @xmath111 returned by @xmath118 and the corresponding line @xmath124 through @xmath28 with slope @xmath125 , i.e. , @xmath126 .",
    "then there exists no solution point ( i.e. , no point in @xmath79 ) below the line @xmath127 .",
    "geometrically , this means that we sweep a line of absolute slope @xmath36 , until it touches ( exactly or approximately ) the undominated boundary ( lower envelope ) of the objective space @xmath79 . for @xmath128 ,",
    "the routine returns a point on the lower envelope @xmath129 , while for @xmath123 it returns a ( potentially ) dominated point of @xmath79 `` close '' to the boundary ( where the notion of `` closeness '' is quantitatively defined by the aforementioned condition ) .",
    "see figure  [ fig : comb ] for an illustration .",
    "if @xmath28 is the ( feasible ) point in @xmath79 returned by @xmath118 , then we write @xmath130 .",
    "we assume that either @xmath128 ( i.e. , we have an exact routine ) , or we have a ptas . for @xmath128 , i.e. , when the optimization is exact , we omit the subscript and denote the comb routine simply by @xmath115",
    ".    we will denote by @xmath131 the size of an optimum @xmath84-convex pareto set for the given instance , i.e. , an @xmath84-convex pareto set with the minimum number of points .",
    "note that , obviously every algorithm that constructs an @xmath84-cp , must certainly make at the very least @xmath131 calls to @xmath108 , just to get @xmath131 points  which are needed at a minimum to form an @xmath84-cp ; this holds even if the algorithm somehow manages to always be lucky and call @xmath108 with the right values of @xmath36 that identify the points of an optimal @xmath84-cp .",
    "having obtained the points of an optimal @xmath84-cp , another @xmath131 many calls to comb with the slopes of the edges of the polygonal line defined by the points , suffice to verify that the points form an @xmath84-cp .",
    "hence , the `` offline '' optimum number of calls is at most @xmath132 .",
    "let @xmath133 be the number of @xmath108 calls required by the chord algorithm on instance @xmath79 .",
    "the _ worst - case performance ratio _ of the algorithm is defined to be @xmath134 .",
    "if the inputs are drawn from some probability distribution @xmath135 , then we will use the _ expected performance ratio _",
    "@xmath136 $ ] as a measure ( note that we shall omit the subscript `` @xmath137 '' when the underlying distribution over instances will be clear from the context ) .",
    "while the main focus of this paper is on approximation of multiobjective optimization problems , our analysis also applies ( with minor modifications ) to related settings ( in which the the chord algorithm has been used ) .",
    "consider for example the following classical _ curve simplification _ problem : given a convex curve @xmath138 of length ( at most @xmath139 on the plane , find the minimum number of points on @xmath138 so that the corresponding convex polygonal chain @xmath140 approximates the curve @xmath138 within distance error @xmath84 .",
    "a popular distance measure in this setting is the",
    "_ hausdorff distance _ of @xmath140 from @xmath138 , i.e. , the maximum euclidean distance of a point in the actual curve from the approximating curve .",
    "note that the hausdorff distance is invariant under translation , while our ratio distance is invariant under scaling .",
    "we remark that our upper and lower bounds for the performance of the chord algorithm wrt the ratio distance apply with minor modifications for the hausdorff distance .",
    "this can be seen as follows : a curve of length @xmath40 located anywhere on the plane can be scaled down by @xmath40 and translated to the unit square @xmath141 $ ] . by definition , approximating the original curve within hausdorff distance @xmath84 is equivalent to approximating the new curve within hausdorff distance error @xmath142 .",
    "a simple calculation shows that for a convex curve in the unit square @xmath143 $ ] the two metrics ( hausdorff and ratio distance ) are within a constant factor of each other .",
    "hence , the upper and lower bounds on the approximation wrt ratio distance give immediately corresponding bounds wrt hausdorff .",
    "we also define the horizontal distance .",
    "we use this distance as an intermediate tool for our lower bound construction in section  [ ssec : worst - lower ] .",
    "the _ horizontal distance _ from a point @xmath64 to a point @xmath28 is defined @xmath144 .",
    "the horizontal distance from @xmath64 to a line @xmath145 ( that is not horizontal ) is @xmath146 , where @xmath147 is the @xmath71-projection of @xmath64 on @xmath145 ( i.e. , the point that a horizontal line from @xmath64 intersects @xmath145 ) .    _",
    "all the upper bounds of this paper on the performance of the chord algorithm hold under the assumption that we have a ptas for the comb problem . on the other hand ,",
    "our lower bounds apply even for the special case that an exact routine is available . for the clarity of the exposition",
    ", we describe the chord algorithm and prove our upper bounds for the case of an exact comb routine .",
    "we then describe the simple modifications in the algorithm and analysis for the case of an approximate routine . _",
    "we have set the stage to formally describe the algorithm .",
    "let @xmath78 be a bi - objective problem with an efficient exact @xmath108 routine . given @xmath148 and an instance @xmath79 of @xmath78 ( implicitly via @xmath108 ) , we would like to construct an @xmath84-cp for @xmath79 using as few calls to @xmath108 as possible . as mentioned in the introduction , a popular algorithm for this purpose",
    "is the chord algorithm that is the main object of study in this paper . in table  [",
    "table : chord ] below we describe the algorithm in detailed pseudo - code .",
    "the pseudo - code corresponds exactly to the description of the algorithm in the introduction .",
    "the ( recursively defined ) routine chord is called from the main algorithm and returns a set of points @xmath149 that is an @xmath84-cp for @xmath79 .",
    "the recursive description of the algorithm is quite natural and will be useful in the analysis .",
    "p3inp3.8 in    * chord algorithm * ( _ input : _",
    "@xmath79 , @xmath84 ) +    @xmath150 ; + @xmath151 ; + @xmath152 ; +    * return * @xmath153 .    &    @xmath154 + * if * @xmath155 * return * @xmath156 ; + @xmath157 ; @xmath158 ; + * if * @xmath159 * return * @xmath156 ; + @xmath160 line parallel to @xmath161 through @xmath28 ; + @xmath162 ; @xmath163 ; +    @xmath164 ; @xmath165 ; + * return * @xmath166 .",
    "let us proceed to explain the notation used in the pseudo - code in tandem with some intuitive understanding of the algorithm .",
    "first , the feasible points @xmath167 minimize the @xmath70-objective and @xmath71-objective respectively .",
    "( note that these points may be dominated , i.e. , are not necessarily the extreme points of @xmath168 ; however , this does not affect our analysis . ) by monotonicity and convexity , the lower envelope is contained in the right triangle @xmath169 , i.e. , @xmath170 .",
    "( note that the point @xmath171 is not a feasible point , but is solely defined for the purpose of `` sandwiching '' the lower envelope . )",
    "the chord routine takes as input ( i ) the desired error tolerance @xmath84 , and ( ii ) the ordered @xmath172-set of points @xmath173 . in every recursive call of the chord routine ,",
    "the points @xmath174 ( left ) and @xmath175 ( right ) are ( feasible ) points of the lower envelope , i.e. , @xmath176 .",
    "moreover , the point @xmath3 is a ( not necessarily feasible ) point and the following conditions are satisfied :    * the point @xmath3 lies to the right of @xmath174 , to the left of @xmath175 and below the line segment @xmath161 .",
    "in particular , this implies that the triangle @xmath177 is either right or obtuse , i.e. , @xmath178 .",
    "* the subset of the lower envelope ( convex curve ) with endpoints @xmath174 and @xmath175 is contained in @xmath177 , i.e. , @xmath179 .",
    "see figure  [ fig : chord ] for an illustration .",
    "the red curve represents the lower envelope between the points @xmath174 and @xmath175 , i.e. , the unknown curve we want to approximate .",
    "( note that the feasible points @xmath180 are the results of previous recursive calls . )",
    "the point @xmath158 is the feasible point in @xmath129 computed in the current iteration ( recursive call ) .",
    "we remark that this point is at maximum ratio distance from the `` chord '' @xmath161  among all points of @xmath181 .",
    "the chord routine will recurse on the triangles @xmath182 and @xmath183 . note that , by construction , the line @xmath184 is parallel to @xmath161 .    during the execution of the algorithm ,",
    "we `` learn '' the objective space in an `` online '' fashion .",
    "after a number of iterations , we have obtained information that imposes an `` upper '' and a `` lower '' approximation to @xmath129 . in particular , the computed solution points define a polygonal chain that is an upper approximation to @xmath129 and the supporting lines at these points define a lower approximation . as the number of iterations increases , these bounds become more and more refined , hence we obtain a better approximation to the curve .",
    "consider for example figure  [ fig : chord ] . before the current iteration of the chord routine ,",
    "the only information available to the algorithm is that the lower envelope ( between points @xmath174 and @xmath175 ) lies in @xmath177 , i.e. , @xmath161 is an upper approximation and the polygonal chain @xmath185 is a lower approximation . given the information the algorithm has at this stage , the potential error of this initial approximation is the ratio distance @xmath186 .",
    "( if this distance is at most @xmath84 , then the segment @xmath161 @xmath84-covers the subset of the lower envelope between @xmath187 and the routine terminates .",
    "otherwise , the point @xmath28 is computed and the approximation is refined , if necessary , as explained above . ) after the current iteration , the upper approximation is refined to be @xmath188 and the lower approximation is @xmath189 . the potential error",
    "given the available information now is @xmath190 . by applying these arguments recursively",
    ", we get that the chord algorithm always terminates and , upon termination , it outputs an @xmath84-cp for @xmath79 ( see lemma  [ lem : chord - finds - eps - convex ] for a rigorous proof ) .",
    "consider the recursion tree built by the chord algorithm .",
    "every node of the tree corresponds to a triangle @xmath177 ( input to the chord routine at the corresponding recursive call ) . in the analysis",
    ", we shall use the following convention : there is no node in the recursion tree if , at the corresponding step , the routine terminates without calling @xmath108 ( i.e. , if @xmath155 in the aforementioned description ) .",
    "the pseudo - code of table  [ table : chord ] is specialized for the ratio distance , but one may use other metrics based on the application . in the context of convex curve simplification ,",
    "our upper and lower bounds for the chord algorithm also apply for the hausdorff distance ( i.e. the maximum euclidean distance of a point in the actual curve from the approximate curve ) .",
    "we are now ready to state our main results .",
    "our first main result is an analysis of the chord algorithm on worst - case instances that is tight up to constant factors . in particular , for the ratio distance we prove    [ thm : worst ] the worst - case performance ratio of the chord algorithm ( wrt the ratio distance ) is @xmath191    the lower bound on the performance of the chord algorithm is proved in section  [ ssec : worst - lower ] . in section  [ ssec : worst - lower - gen ] , we also prove a general lower bound of @xmath192 on the performance ratio of _ any _ algorithm in the @xmath108 based model , as well as lower bounds for approximating with respect to the horizontal ( resp .",
    "vertical ) distance .    in section  [ ssec : worst - upper ]",
    "we give a proof of the upper bound . in section  [ sssec : worst - upper - simple ]",
    "we start by presenting the slightly weaker upper bound of @xmath193 ; this result has the advantage that its proof is simple and intuitive .",
    "the proof of the asymptotically tight upper bound requires a more careful analysis and is presented in section  [ sssec : worst - upper - final ] .",
    "_ it turns out that the hausdorff distance behaves very similarly to the ratio distance .",
    "in particular , by essentially identical proofs , it follows that the performance ratio of the chord algorithm for approximating a convex curve of length @xmath40 within hausdorff distance @xmath1 , is @xmath51 .",
    "furthermore , every algorithm has worst - case performance ratio at least @xmath52 . _    in the process , we also analyze the chord algorithm with respect to the horizontal distance metric ( or by symmetry the vertical distance ) . we show that in this setting the performance ratio of the algorithm is unbounded . in fact , we can get a strong lower bound in this case : _ any _ algorithm with oracle access to @xmath108 has an unbounded performance ratio ( theorem  [ thm : hd - lb - gen - ws ] ) , even on instances that lie in the unit square and the desired accuracy is a constant .",
    "our second main result is an asymptotically tight analysis of the chord algorithm in an average case setting ( wrt the ratio distance ) .",
    "our random instances are drawn from standard distributions that have been widely used for the average case analysis of geometric algorithms in a variety of settings .",
    "in particular , we consider ( i ) a poisson point process on the plane and ( ii ) @xmath55 points drawn from an `` un - concentrated '' product distribution .",
    "we now formally define these distributions .",
    "[ def : ppp ] a ( spatial , homogeneous ) _ poisson point process ( ppp ) _ of intensity @xmath194 on a bounded subset @xmath195 is a collection of random variables @xmath196 ( representing the number of points occurring in every subset of @xmath197 ) , such that : ( i ) for any lebesgue measurable @xmath88 , @xmath198 is a poisson random variable with parameter @xmath199 ; ( ii ) for any collection of _ disjoint _ subsets @xmath200 the random variables @xmath201   \\}$ ] are mutually independent .",
    "[ def : delta - balanced distn ] let @xmath88 be a bounded lebesgue - measurable subset of @xmath202 , and let @xmath203 be a distribution over @xmath88 .",
    "the distribution @xmath203 is called @xmath204-_balanced _ , @xmath205 , if for all lebesgue measurable subsets @xmath206 , @xmath207 $ ] , where @xmath208 is the uniform distribution over @xmath88 .",
    "we assume that @xmath204 is an absolute constant and we omit the dependence on @xmath204 in the performance ratio below .",
    "we prove :    [ thm : average ] for the aforementioned classes of random instances , the expected performance ratio of the chord algorithm ( wrt to the ratio distance ) is @xmath209 .    the upper bound proof is given in section  [ ssec : average - upper ] and the lower bound one in section  [ ssec : average - lower ] .",
    "we first present detailed proofs for the case of ppp and then present the ( more involved ) case of product distributions .",
    "( we note that similar results apply also for approximation under the hausdorff distance . )",
    "in section  [ ssec : worst - lower - chord ] we prove a tight lower bound for the chord algorithm for the ratio distance metric . in section  [ ssec : worst - lower - gen ]",
    "we show our general lower bounds , both for the ratio distance and the horizontal distance .",
    "our main result in this section is a proof of the lower bound statement in theorem  [ thm : worst ] .",
    "in fact , we show a stronger statement that also rules out the possibility of constant factor bi - criteria approximations , i.e. , it applies even if the chord algorithm is allowed ( ratio distance ) error @xmath210 and we compare it against the optimal @xmath84-cp set .",
    "[ thm : rd - lb - ws ] let @xmath211 be an absolute constant .",
    "let @xmath148 be smaller than a sufficiently small constant and @xmath212 be large enough .",
    "there exists an instance @xmath213 such that @xmath214 and @xmath215 .",
    "the lower bound applies even if an exact @xmath108 routine is available , hence we restrict ourselves to this case .",
    "before we proceed with the formal proof , we give an explanation of our construction for the case @xmath216 and @xmath217 .",
    "the rough intuition is that the algorithm can perform poorly when the input instance is `` skewed '' , i.e. , we have a triangle @xmath218 where @xmath219 . for such instances one can force the algorithm to select many `` redundant '' points ( hence , perform many calls to @xmath108 ) to obtain a certificate it has found an @xmath84-cp set , even when few points ( calls ) suffice .",
    "for the special case under consideration , the `` hard '' instance has endpoints @xmath220 and @xmath221 , where @xmath84 is sufficiently small ( to be specified later ) .",
    "initially , the only available information to the algorithm is that the convex pareto set for the given instance lies in the right triangle @xmath222 , where @xmath223 . observe that , for an instance with these endpoints , the initial error @xmath224 is roughly equal to @xmath225 and one intermediate point @xmath226 together with the rightmost point of the curve always suffice to form an @xmath84-cp set , i.e. , the optimal size is no more than @xmath227 our construction will define a sequence of points @xmath228 ( ordered in increasing @xmath70-coordinate ) which will form the convex pareto set for the corresponding instance and that force the chord algorithm to select _ all _ the @xmath229 s ( in order of increasing @xmath230 ) , until it finds @xmath231 .",
    "that is , the chord algorithm will monotonically converge to the optimal point by visiting all the vertices of the instance in order ( in increasing @xmath70-coordinate ) .",
    "let @xmath232 be the slope of @xmath39 .",
    "the algorithm starts by calling @xmath233 to find a solution point at maximum ratio distance from the chord @xmath39 .",
    "our construction guarantees that @xmath234 .",
    "that is , if @xmath235 is the line parallel to @xmath39 through @xmath236 , @xmath235 supports the objective space .",
    "the point @xmath236 is selected on the line segment @xmath237 so that @xmath238 , i.e. , it is obtained by subdividing ( the length of ) @xmath237 geometrically with ratio @xmath239  for an appropriate @xmath239 ( to be specified next ) .    consider the point @xmath240 .",
    "the error of the approximation @xmath241 equals @xmath242 ( note that the error to the left of @xmath236 is @xmath243 ) . if @xmath244 , we are already done , since @xmath245 , which implies @xmath246 . on the other hand , if @xmath247 , we are also done since @xmath248 , hence @xmath246 . if @xmath249 , it is not hard to show that @xmath250 hence , after the first call to @xmath108 , the error has decreased by an additive of @xmath251 and the algorithm will recurse on the triangle @xmath252 .",
    "note that @xmath253 .",
    "the algorithm proceeds by calling @xmath254 and this call will return the point @xmath255 .",
    "let @xmath256 be the ( supporting ) line parallel to @xmath257 through @xmath255 .",
    "similarly , @xmath256 supports the objective space .",
    "the point @xmath255 is selected by repeating our `` geometric subdivision trick . '' recall that there are no feasible points below the line @xmath258 .",
    "let @xmath259 be the projection of @xmath255 on @xmath237 .",
    "we select @xmath255 on the segment @xmath258 so that @xmath260 .",
    "the error of the approximation @xmath261 equals @xmath262 , where @xmath263 .",
    "if @xmath264 , we have that @xmath265 i.e. , after the second step of the algorithm , the error has decreased by another additive @xmath266 and the algorithm will recurse on the triangle @xmath267 .",
    "we can repeat this process iteratively , where ( roughly ) in step @xmath230 we select @xmath229 on the line @xmath268 , so that the length of the projection satisfies @xmath269 .",
    "this iterative process can continue as long as @xmath270 . also note that the number @xmath271 of iterations can not be more than @xmath272 because @xmath273 and @xmath274 . since , @xmath275 it turns out that the optimal choice of parameters is @xmath276 .",
    "we stress that the actual construction is more elaborate than the one presented in the intuitive explanation above . also , to show a bi - criterion lower bound , we need to add one more point @xmath277 so that the chord algorithm selects @xmath228 until it forms a @xmath278-cp , while the point @xmath277 ( along with the rightmost point @xmath279 ) suffice to form an @xmath84-cp .",
    "the formal proof comes in two steps .",
    "we first analyze the chord algorithm with respect to the horizontal distance metric .",
    "we show that the performance ratio of the algorithm is unbounded in this setting ( this statement also holds for the vertical distance by symmetry ) .",
    "in particular , for every @xmath280 , there exists an instance @xmath281 ( lying entirely in the unit square ) so that the chord algorithm ( applied for additive error @xmath282 ) has performance ratio @xmath239 .",
    "we then show that , for an appropriate setting of the parameters in @xmath283 , we obtain the instance @xmath284 that yields the desired lower bound with respect to the ratio distance .",
    "_ * step 1 : * _ the instance @xmath285 lies in the triangle @xmath286 , where @xmath287 , @xmath288 and @xmath223 .",
    "the points @xmath289 and @xmath279 are ( the extreme ) vertices of the convex pareto set .",
    "we introduce two additional parameters . the first one , @xmath280 , is the ratio used in the construction to geometrically subdivide the length of the line @xmath237 in every iteration .",
    "the second one , @xmath290 with @xmath291 $ ] , is the number of iterations and equals the number of vertices in the instance .",
    "we define a set of points @xmath292 ordered in increasing @xmath70coordinate and decreasing @xmath71coordinate",
    ". our instance will be the convex polygonal line with vertices the points of @xmath293 .",
    "we set @xmath294 and @xmath295 .",
    "the set of points @xmath296 is defined recursively as follows :    1 .",
    "the point @xmath236 has @xmath297 and @xmath298 .",
    "2 .   for @xmath299 $ ]",
    "the point @xmath229 is defined as follows : let @xmath300 denote the line parallel to @xmath301 through @xmath302 .",
    "the point @xmath229 is the point of this line with @xmath303 .",
    "the algorithm is applied on this instance with desired horizontal distance error @xmath304 also denote @xmath305 note that @xmath306 .",
    "see figures  [ chord - fig - hd1 ] and  [ chord - fig - hd2 ] for a graphic illustration of the worst - case instances for the chord algorithm .",
    "we would like to stress that the figures are not drawn to scale .",
    "in particular , in the figures below we have @xmath307 , while the actual lower bound for the ratio distance applies for @xmath308 ; in particular , for @xmath309 and @xmath310 .    we show the following :    [ claim : chd - hd ] the chord algorithm applied to the instance @xmath281 and error bound @xmath311 wrt horizontal distance selects the sequence of points @xmath312 , while the set @xmath313 attains error @xmath306 .    for",
    "@xmath314 $ ] , let @xmath315 be the intersection of the line @xmath316  the line parallel to @xmath317 through @xmath229with @xmath318 .",
    "the error of @xmath313 is exactly @xmath319 .",
    "observe that @xmath320 . by a simple geometric argument we obtain @xmath321 , which yields the second statement .",
    "for the first statement , we show inductively that the recursion tree built by the algorithm for @xmath281 is a path of length @xmath322 and at depth @xmath323 , for @xmath324 $ ] , the chord subroutine selects point @xmath229 .",
    "the proof amounts to noting that the error of the approximation @xmath325 is @xmath326 , which is @xmath327 for @xmath328 and @xmath329 for @xmath330 .    to provide the details we need some notation . for @xmath324 $ ]",
    ", we denote @xmath331 .",
    "let @xmath332 be the @xmath71-projection of @xmath229 on @xmath317 , so that @xmath333 . recall that @xmath315 denotes the intersection of the line @xmath334  the line parallel to @xmath317 through @xmath229with @xmath318 .",
    "if @xmath335 is the @xmath71-projection of @xmath236 on @xmath336 , we have @xmath337 .",
    "( see figure  [ chord - fig - hd2 ] for an illustration of these definitions . )",
    "we start with the following claim :    [ lem : hd - induction ] for all @xmath324 $ ] , we have @xmath338 .    by induction on @xmath230 . for the induction basis ( @xmath339 ) , we observe that the triangles @xmath340 and @xmath341 are similar , hence @xmath342 which yields @xmath343 as desired .",
    "suppose that the claim is true for @xmath314 $ ] .",
    "we will prove it for @xmath344 .",
    "we similarly exploit the similarity of the triangles @xmath345 and @xmath346 , from which we get @xmath347 where the second equality follows from the collinearity of @xmath348 .",
    "observe that the third term in  ( [ eq : one ] ) is equal to @xmath349 by construction .",
    "now note that , because of the parallelogram @xmath350 , we have @xmath351 .",
    "hence , ( [ eq : one ] ) and the induction hypothesis imply @xmath352 which completes the proof of the claim .    since @xmath353 ( as noted in the proof of claim  [ lem : hd - induction ] ) , it follows that for all @xmath314 $ ] we have @xmath354 we will start by showing that the set @xmath355 is an @xmath356-convex pareto under the horizontal distance .",
    "first , note that the error to the right of @xmath277 , i.e. , the distance of the lower envelope from @xmath357 is in fact zero ( since @xmath358 is the rightmost edge of the lower envelope ) .",
    "it suffices to bound from above the error to its left .",
    "since @xmath359 has absolute slope larger than @xmath39 , the unique point ( of the lower envelope ) at maximum distance from @xmath359 is @xmath236 .",
    "thus , we have that @xmath320 . from the similarity of the triangles @xmath360 and @xmath361 we get @xmath362 hence , @xmath363 as desired .",
    "we now proceed to analyze the behavior of the chord algorithm .",
    "we will show that the algorithm selects the points @xmath364 ( in this order ) till it terminates .",
    "formally , we consider the recursion tree built by the algorithm for the instance @xmath281 and prove that it is a path of length @xmath322 .",
    "in particular , for all @xmath324 $ ] , at depth @xmath323 , the chord subroutine selects point @xmath229 .",
    "we prove the aforementioned statement by induction on the depth @xmath6 of the tree .",
    "recall that the chord algorithm initially finds the extreme points @xmath289 and @xmath279 . for @xmath365 ( first recursive call ) ,",
    "the algorithm selects a point of the lower envelope with maximum horizontal distance from @xmath39 . by construction ,",
    "all the points ( of the lower envelope ) in the line segment @xmath366 have the same ( maximum ) distance from @xmath39 ( since @xmath366 is parallel to @xmath39 ) .",
    "hence , any of those points may be potentially selected .",
    "since @xmath108 is a black - box oracle , we may assume that indeed @xmath236 is selected .",
    "the maximum error after @xmath236 is selected equals @xmath367 .",
    "hence , the algorithm will not terminate after it has selected @xmath236 .    for the inductive step ,",
    "we assume that the recursion tree is a path up to depth @xmath368 $ ] and the algorithm selected the points @xmath369 up to this depth .",
    "we analyze the algorithm at depth @xmath370 . at depth",
    "@xmath370 the information available to the algorithm is that ( i ) the error to the left of @xmath371 is @xmath243 and ( ii ) the error to its right is @xmath372 ( since @xmath373 ) . hence , the algorithm does not terminate and it calls @xmath108 to find a point between @xmath371 and @xmath279 at maximum distance from @xmath374 . by construction , the points of maximum distance are those belonging to the line @xmath375 ( which is parallel to @xmath374 ) ; similarly , we can assume @xmath376 is selected .",
    "at this point of the execution the algorithm has the information that the error to the left of @xmath376 is @xmath243 and the error to its right is @xmath377 , unless @xmath378 .",
    "this completes the induction and the proof of lemma  [ claim : chd - hd ] .    *",
    "_ step 2 : _ * the instance @xmath284 is obtained from @xmath379 by appropriately setting the four relevant parameters . in particular ,    1 .",
    "fix @xmath380 , @xmath381 , @xmath382 and @xmath383 2",
    ".   set @xmath384 3 .   also , define @xmath385 and @xmath386 .",
    "observe that , under this choice of parameters , we have @xmath387 and @xmath388 . our main lemma for this step is the following :    [ claim : chd - rd ] the chord algorithm applied to @xmath284 and error bound @xmath389 wrt ratio distance selects ( a superset of ) the points @xmath390 , while the set @xmath391 forms an @xmath392-convex pareto set .",
    "the main idea of the proof is that for the particular instance under consideration , the horizontal distance metric is a very good approximation to the ratio distance . as a consequence",
    ", one can show that the behavior of the chord algorithm in both metrics is similar .",
    "the reason we `` lose '' a constant factor in the number of points ( i.e. , the chord algorithm selects @xmath393 points under the ratio distance as opposed to @xmath394 under the horizontal distance ) is due to the error term in the approximation between the metrics .",
    "( the factor of @xmath395 is not important ; any constant factor bigger than @xmath396 would suffice . )",
    "we now proceed with the details .",
    "consider the set @xmath397 defining the instance @xmath284 .",
    "we will need the following lemma that quantifies the closeness of the two metrics in our setting .",
    "[ lem : hd - vs - rd ] let @xmath398 , @xmath288 and @xmath223 .",
    "consider a point @xmath399 in @xmath286 and let @xmath36 be the absolute slope of @xmath400 .",
    "if @xmath401 is the @xmath70-projection of @xmath399 on @xmath318 , then for any point @xmath402 in @xmath403 we have @xmath404    the proof , though elementary , requires some careful calculations .",
    "let @xmath405 be the @xmath70-projection of @xmath399 on the segment @xmath318 , that is @xmath406 .",
    "clearly , @xmath407 if @xmath36 is the absolute slope of @xmath400 , we have that @xmath408 fix a point @xmath409 .",
    "we want to show that @xmath410 , the horizontal distance of @xmath402 from @xmath400 , is a good approximation to the corresponding ratio distance @xmath411 when @xmath36 is large .",
    "( see figure  [ chord - fig - hrd ] for an illustration . )",
    "we first calculate the horizontal distance @xmath410 .",
    "observe that @xmath412 where @xmath64 is the @xmath71-projection of @xmath402 on @xmath413 , i.e. , @xmath414 and @xmath415 it is clear that @xmath416 from the similarity of the triangles @xmath417 and @xmath418 it follows @xmath419 since @xmath420 , @xmath421 and @xmath422 we get @xmath423 therefore , @xmath424 the ratio distance @xmath425 by definition is such that @xmath426 . we thus get @xmath427 or equivalently @xmath428 substitution yields that @xmath429 observe that the numerator of the above fraction equals @xmath410 and the denominator is bigger than @xmath396 .",
    "hence , @xmath430 . for the other inequality we can write : @xmath431 as desired",
    ". to obtain  ( [ eq : ineq ] ) , we bound each term in  ( [ eq : prod ] ) separately .",
    "the first term is clearly at most @xmath40 . as for the second term , first note that the denominator is at least @xmath396 . to bound the numerator from above",
    ", we claim that @xmath432 . to see this we use our assumption that @xmath402 lies in @xmath403 .",
    "in particular , this implies that @xmath402 lies below ( or on ) the line segment @xmath400 , i.e. , @xmath433 which gives @xmath434 as desired .",
    "this completes the proof of lemma  [ lem : hd - vs - rd ] .",
    "we may now proceed with the proof of lemma  [ claim : chd - rd ] . by lemma  [ claim : chd - hd ] ,",
    "the set @xmath391 attains horizontal distance error at most @xmath392 . by the first inequality of ( [ eqn : hd - vs - rd ] ) ,",
    "the ratio distance error of @xmath391 is at most as big , hence the second statement of lemma  [ claim : chd - rd ] follows .    by lemma  [ claim : chd - hd ] , the chord algorithm under the horizontal distance metric selects all the points @xmath435 in order until it guarantees an @xmath436-approximation .",
    "in paricular , after the algorithm has selected the subset @xmath325 , for @xmath437 $ ] , the horizontal approximation error is @xmath438 we remark that the error term @xmath439 in the rhs of  ( [ eqn : hd - vs - rd ] ) leads to the `` constant factor loss '' , i.e. , the fact that the chord algorithm under the ratio distance picks @xmath393 ( as opposed to @xmath394 ) points .",
    "( also note that , since the ratio distance is a lower bound for the horizontal distance , the chord algorithm under the former metric will select at most @xmath394 points . )",
    "suppose we invoke the chord algorithm with desired error of @xmath243 , i.e. , we want to reconstruct the lower envelope exactly . then the algorithm will select the points @xmath229 in order of increasing @xmath230 .",
    "it is also clear that the error of the approximation decreases monotonically with the number of calls to @xmath108 .",
    "hence , to complete the proof , it suffices to show that after the algorithm has selected @xmath440 , the ratio distance error will be bigger than @xmath441 . to do this , we appeal to lemma  [ lem : hd - vs - rd ] .    the ratio distance error of the set @xmath442 is @xmath443 .",
    "an application of ( the second inequality of ) ( [ eqn : hd - vs - rd ] ) for @xmath444 , @xmath445 gives @xmath446 for the first term of the rhs , it follows from ( [ eqn : hd - error2 ] ) by substitution that @xmath447 and we similarly get @xmath448 hence , @xmath449 where @xmath450    consider the error term @xmath451 .",
    "we will show that @xmath452 which concludes the proof .",
    "the first summand @xmath453 is negligible compared to @xmath454 , as long as @xmath455 to bound the second summand from above we need a lower bound on the slope @xmath456 .",
    "recall ( equation  ( [ eq : xistar ] ) in lemma  [ lem : hd - induction ] ) that @xmath457 .",
    "it is also not hard to verify that @xmath458 also recall that @xmath459 hence , @xmath460 it is straightforward to check that for the chosen values of the parameters , @xmath461 , hence the second summand will also be significantly smaller than @xmath462 . in conclusion ,",
    "@xmath463 and lemma  [ claim : chd - rd ] follows .",
    "this also completes the proof of theorem  [ thm : rd - lb - ws ] .",
    "we can show an information  theoretic lower bound against any algorithm that uses @xmath108 as a black box with respect to the ratio distance metric . even though the bound we obtain is exponentially weaker than that attained by the chord algorithm , it rules out the possibility of a constant factor approximation in this model .",
    "in particular , we show :    [ thm : rd - lb - ws - gen ] any algorithm ( even randomized ) with oracle access to a @xmath108 routine , has performance ratio @xmath464 with respect to the ratio distance .",
    "let @xmath17 be a general algorithm with oracle access to @xmath108 .",
    "the algorithm is given the desired error @xmath84 , and it wants to compute an @xmath84-cp set . to do this , it queries the @xmath108 routine on a sequence of ( absolute ) slopes @xmath465 and terminates when it has obtained a `` certificate '' that the set of points @xmath466 forms an @xmath84-cp set .",
    "the queries to @xmath108 can be adaptive , i.e. , the @xmath230-th query @xmath467 of the algorithm @xmath17 can depend on the information ( about the input instance ) the algorithm has obtained from the previous queries @xmath468 . on the other hand , the adversary also specifies the input instance adaptively , based on the queries made by the algorithm .    we will define a family of instances @xmath469 and an error @xmath148 with the following properties :    1 .",
    "each instance @xmath470 has @xmath471 2 .   in order for an algorithm @xmath17 to have a certificate it found an @xmath84-cp set for an ( adversarially chosen ) instance @xmath470",
    ", it needs to make at least @xmath472 calls to @xmath108 .",
    "our construction uses the lower bound example for the chord algorithm from section  [ ssec : worst - lower - chord ] essentially as a black box .",
    "consider the instance @xmath473 ( note that for @xmath216 we have that @xmath474 and @xmath475 ) and let @xmath476 be the corresponding set of points , where @xmath294 and @xmath477 and @xmath478 . our family of input instances @xmath469 consists of all `` prefixes '' of @xmath293 , i.e. , @xmath479 , where @xmath480 , @xmath324 $ ] .",
    "by the properties of @xmath293 , each @xmath481 defines a convex monotone decreasing polygonal curve , i.e. , all its points are vertices of the corresponding convex pareto .",
    "moreover , the set @xmath482 is an @xmath483-cp set for @xmath481 , where @xmath484 .",
    "note that @xmath485 , @xmath324 $ ] , and that @xmath486 where the first inequality holds from ( [ eqn : hd - vs - rd ] ) , and the rest follow by construction .",
    "this proves property @xmath487 above .",
    "we now proceed to prove @xmath488 .",
    "we claim that , given an arbitrary ( unknown ) instance @xmath470 , in order for an algorithm @xmath17 to have a certificate it discovered an @xmath84-cp set , @xmath17 must uniquely identify the instance @xmath16 . in turn",
    ", this task requires @xmath489 @xmath108 calls .",
    "indeed , consider an unknown instance @xmath470 and let @xmath229 be the rightmost point of @xmath16 ( excluding @xmath279 ) the algorithm @xmath17 has discovered up to the current points of its execution . at this point",
    ", the information available to the algorithm is that @xmath490 .",
    "hence , the error the algorithm can guarantee for its current approximation is @xmath491 the first inequality above follows from lemma  [ lem : hd - vs - rd ] .",
    "also note that the term in the rhs is minimized for @xmath330 and ( by the same analysis as in lemma  [ claim : chd - rd ] ) the minimum value is bigger than @xmath436 .",
    "it remains to show that an adversary can force any algorithm to make at least @xmath492 queries to @xmath108 until it has identified an unknown instance of @xmath469 .",
    "clearly , identifying an unknown instance @xmath470 , i.e. , finding the index @xmath145 such that @xmath493 , is equivalent to identifying @xmath494  the rightmost point of @xmath16 to the left of @xmath279 .",
    "first , we can assume the algorithm is given the extreme points @xmath495 beforehand .",
    "a general algorithm @xmath17 is allowed to query the @xmath108 routine for any slope @xmath496 .",
    "suppose that @xmath493 .",
    "then , for @xmath497 , the @xmath108 routine returns : ( i ) @xmath229 if @xmath498 , ( ii ) @xmath494 if @xmath499 , and ( iii ) @xmath279 if @xmath500 .. that is , the information obtained from a query @xmath501 is whether @xmath498 , @xmath499 or @xmath500 .",
    "so , for our class of instances , a general deterministic algorithm @xmath17 is equivalent to a ternary decision tree with the corresponding structure .",
    "the tree has @xmath502 many leaf nodes and there are at most @xmath503 leaves at depth @xmath6 .",
    "every internal node of the tree corresponds to a query to the @xmath108 routine , hence the depth measures the worst - case number of queries made by the algorithm .",
    "it is straightforward that any such tree has depth @xmath492 and the theorem follows .",
    "( if we allow randomization , the algorithm is a randomized decision tree .",
    "the expected depth of any such tree remains @xmath492 which yields the theorem for randomized algorithms as well . )",
    "we next show that , for the horizontal distance metric ( or vertical distance by symmetry ) , any algorithm in our model has an unbounded performance ratio , even for instances that lie in the unit square and for desired error @xmath282 .",
    "[ thm : hd - lb - gen - ws ] any algorithm with oracle access to a @xmath108 routine has an unbounded performance ratio with respect to the horizontal distance , even on instances that lie in the unit square and for approximation error @xmath282 .",
    "let @xmath17 be an algorithm that , given the desired error @xmath84 , computes an @xmath84-approximation with respect to the horizontal distance .",
    "fix @xmath504 .",
    "we show that an adaptive adversary can force the algorithm to make @xmath505 queries to @xmath108 even when @xmath506 queries suffice .",
    "that is , the performance ratio of the algorithm is @xmath505 ; since @xmath239 can be arbitrary the theorem follows .",
    "our family of ( adversarially constructed ) instances all lie in the unit square and are obtained by a modification of the lower bound instance @xmath507 for chord under the horizontal distance ( see step 1 in section  [ ssec : worst - lower - chord ] ) . since the horizontal distance is invariant under translation , we can shift our instances so that the points @xmath508 and @xmath509 are the leftmost and rightmost points of the convex pareto set . after this shift ,",
    "the point @xmath171 is identified with the origin .",
    "consider the initial triangle @xmath169 , where @xmath510 , @xmath511 and @xmath512 , and let @xmath513 be the first query made by the algorithm .",
    "given the value of @xmath514 , the adversary adds a vertex @xmath236 to the instance so that @xmath515",
    ". the strategy of the adversary is the following : the point @xmath236 belongs to @xmath237 , i.e. , @xmath516 . if @xmath517 , then the point @xmath236 has @xmath518 otherwise , @xmath519 .",
    "let @xmath235 be the line with slope @xmath514 through @xmath236 and @xmath520 be its intersection with @xmath521 .",
    "the current information available to the algorithm is that the point @xmath236 is a feasible point and that there are no points below the line @xmath235 .",
    "hence , the horizontal distance error it can certify is @xmath522 on the other hand , if the true convex pareto set was @xmath523 , the set @xmath524 would attain error @xmath525 note that @xmath526    after its first query , the algorithm knows that the error to the left of @xmath236 is @xmath243 , hence it needs to focus on the triangle @xmath252 .",
    "therefore , it is no loss of generality to assume that @xmath527 . given @xmath528 , the adversary adds a vertex @xmath255 to the instance so that @xmath529 . its strategy is to place @xmath255 on @xmath530 and to set @xmath531 if @xmath532 and @xmath533 otherwise",
    "let @xmath256 be the line with slope @xmath528 through @xmath255 and @xmath534 be its intersection with @xmath521 .",
    "the information available to the algorithm after its second query is that the point @xmath255 is a feasible point and that there are no points below the line @xmath256 .",
    "hence , the horizontal distance error it can certify is @xmath535 on the other hand , if the true convex pareto set was @xmath536 , the set @xmath537 would attain error @xmath538 similarly , @xmath539    the adversary argument continues by induction on @xmath230 .",
    "the induction hypothesis is the following : after its @xmath230-th query , the algorithm has computed a set of points @xmath325 , @xmath540 , @xmath541 $ ] , where @xmath542 is the @xmath271-th query and @xmath543 .",
    "( the @xmath544 s are vertices of the convex pareto set of the corresponding instance ordered left to right ) .",
    "let @xmath545 be the line with slope @xmath467 through @xmath229 and @xmath546 be its intersection with @xmath521 .",
    "then @xmath547    we now prove the induction step .",
    "we start by noting that the error to the left of @xmath229 is zero , so the algorithm needs to focus on the triangle @xmath548 ; this implies that ( without loss of generality ) @xmath549 .",
    "given @xmath550 , the adversary adds a vertex @xmath551 such that @xmath552 .",
    "similarly , the strategy of the adversary is to place @xmath551 on @xmath553 and to set @xmath554 if @xmath555 and @xmath556 otherwise .",
    "let @xmath557 be the line with slope @xmath550 through @xmath551 and @xmath546 be its intersection with @xmath521 .",
    "the information available to the algorithm after its @xmath558-th query is that the point @xmath551 is a feasible point and that there are no points below the line @xmath557 .",
    "hence , the horizontal distance error it can certify is @xmath559 on the other hand , if the true convex pareto set was @xmath560 , the set @xmath561 would attain error @xmath562 . now note that @xmath563 where the second inequality uses the inductive hypothesis and the definition of @xmath551 .",
    "( see figure  [ fig : gen - lb - hd ] for an illustration ; the figure depicts the case that @xmath564 . )",
    "this completes the induction .",
    "the overall adversary argument is obtained from the above construction for @xmath565 .",
    "that is , the adversarially constructed instance is the set @xmath566 , where @xmath567 ( recall that @xmath467 is the @xmath230-th query ) .",
    "the set @xmath568 has error @xmath569 while the algorithm can certify error @xmath570 thus , after @xmath571 steps , the error of the algorithm remains more than @xmath282 , while @xmath172 queries suffice to attain error @xmath572 .",
    "this completes the proof of theorem  [ thm : hd - lb - gen - ws ] .      in this section",
    "we establish the upper bound statement of theorem  [ thm : worst ] , i.e. , we show that the performance ratio of the chord algorithm for the ratio distance is @xmath573 . for the sake of the exposition",
    ", we start by showing the slightly weaker upper bound of @xmath193 .",
    "the proof of the asymptotically tight upper bound is more involved and builds on the understanding obtained from the simpler argument presented first .",
    "before we proceed with the argument , some comments are in order .",
    "perhaps the most natural approach to prove an upper bound would be to argue that the error of the approximation constructed by the chord algorithm decreases substantially ( say by a constant factor ) in every iteration ( subdivision ) or after an appropriately defined `` epoch '' of a few iterations .",
    "this , if true , would yield the desired result  since the initial error can not be more than @xmath574 .",
    "unfortunately , such an approach badly fails , as implied by the construction of theorem  [ thm : rd - lb - ws ] .",
    "recall that , in the simplest setting of that construction , the initial error is @xmath225 and decreases by an additive @xmath266 in every iteration , where @xmath575 .",
    "hence , the error decreases by a sub - constant factor in every iteration .",
    "in fact , we note that such an argument can not hold for _ any _ algorithm in our setting ( i.e. , given oracle access to @xmath108 ) , as follows from our general lower bound ( theorem  [ thm : rd - lb - ws - gen ] ) .",
    "our approach is somewhat indirect .",
    "we prove that the _ area _ between the ( implicitly constructed ) `` upper '' and `` lower '' approximation decreases by a constant factor in every iteration of the algorithm ( lemma  [ lem : area - half ] ) .",
    "this statement can be viewed as a `` potential function type argument . '' to obtain an upper bound on the performance ratio , one additionally needs to relate the area to the ratio distance .",
    "indeed , we show that , when the area ( between the upper approximation and the lower approximation ) has become `` small enough '' ( roughly at most @xmath576 ) , the error of the approximation ( ratio distance of the lower approximation from the upper approximation ) is at most @xmath84 ( lemma  [ lemma : small - area - means - done ] ) .",
    "we combine the above with a simple charging argument ( lemma  [ lem : opt - lb ] ) to get the desired performance guarantee .",
    "formally , we prove :    [ thm : ws - ub - area ] let @xmath577 be the triangle at the root of the chord algorithm s recursion tree , let @xmath578 be its area , and denote @xmath579 .",
    "the algorithm finds an @xmath84-cp set after @xmath580 calls to @xmath108 , where @xmath581 .",
    "the claimed upper bound on the performance ratio follows from the previous theorem , since @xmath582 ^ 2 $ ] , which implies @xmath583 and @xmath584 .    to prove theorem  [ thm : ws - ub - area ]",
    "we will need a few lemmas .",
    "we start by proving correctness , i.e. , we show that , upon termination , the algorithm computes an @xmath84-cp set for @xmath79",
    ". this statement may be quite intuitive , but it requires a proof .",
    "the following claim formally states some basic properties of the algorithm :    [ clm : sandwich ] let @xmath585 be the triangle processed by the chord algorithm at some recursive step",
    ". then the following conditions are satisfied : ( i ) @xmath586 ; in particular , @xmath587 and @xmath588 , ( ii ) @xmath589 , @xmath590 and @xmath591 lies below the line @xmath592 , and ( iii ) @xmath593 .    that is , whenever the chord routine is called with parameters @xmath173 ( see table  [ table : chord ] ) , the points @xmath174 and @xmath175 are feasible solutions of the lower envelope and the segment of the lower envelope between them is entirely contained in the triangle @xmath177 .",
    "consider the node ( corresponding to ) @xmath594 in the recursion tree built by the algorithm .",
    "we will prove the claim by induction on the depth of the node .",
    "the base case corresponds to either an empty tree or a single node ( root ) .",
    "the chord routine is initially called for the triangle @xmath595 . conditions ( i ) and ( ii )",
    "are thus clearly satisfied .",
    "it follows from the definition of the @xmath108 routine that there exist no solution points strictly to the left of @xmath289 and strictly below @xmath279 .",
    "hence , by monotonicity and convexity , we have @xmath596 , i.e. , condition ( iii ) is also satisfied .",
    "this establishes the base case .    for the induction step , suppose the claim holds true for every node up to depth @xmath597",
    ". we will prove it for any node of depth @xmath370 .",
    "indeed , let @xmath598 be a depth @xmath370 node and let @xmath585 be @xmath598 s parent node in the recursion tree . by the induction hypothesis , we have that ( i ) @xmath586 ; @xmath587 and @xmath588 ( ii ) @xmath589 , @xmath590 and @xmath591 lies below the line @xmath592 and ( iii ) @xmath593 .",
    "we want to show the analogous properties for @xmath598 .",
    "we can assume without loss of generality that @xmath598 is @xmath594 s left child ( the other case being symmetric ) .",
    "then , it follows by construction ( see table  [ table : chord ] ) that @xmath599 where @xmath600 .",
    "we claim that @xmath601 .",
    "indeed , note that @xmath602 ( as follows from property ( ii ) of the induction hypothesis ) . by monotonicity and convexity of the lower envelope , combined with property ( iii ) of the induction hypothesis , the claim follows .",
    "now note that @xmath603 and @xmath604 .",
    "hence , property ( i ) of the inductive step is satisfied .",
    "since @xmath605 has non - positive slope ( as follows from ( ii ) of the inductive hypothesis ) , @xmath606 lies to the left and above @xmath607 ; similarly , since @xmath592 has negative slope , @xmath607 lies to the left and above @xmath229 .",
    "we also have that @xmath608 , where the first inequality follows from the fact that @xmath601 . property ( ii )",
    "follows from the aforementioned . by definition of the chord routine",
    ", we have @xmath604 and there are no solution points below @xmath609 . by convexity , we get that @xmath610 lies below @xmath611 .",
    "hence , property ( iii ) also follows .",
    "this proves the induction and the claim .    by exploiting the above claim",
    ", we can prove correctness :    [ lem : chord - finds - eps - convex ] the set of points @xmath293 computed by the chord algorithm is an @xmath84-cp set .",
    "let @xmath612 be the set of feasible points in @xmath129 output by the algorithm , where the points of @xmath293 are ordered in increasing order of their @xmath70-coordinate ( decreasing order of their @xmath71-coordinate ) .",
    "note that all the @xmath229 s are in convex position .",
    "we have that @xmath613 .",
    "so , it suffices to show that , for all @xmath230 , @xmath614 .",
    "since the algorithm terminates with the set @xmath293 , it follows that , for all @xmath230 , the chord routine was called by the algorithm for the adjacent feasible points @xmath615 and returned without adding a new feasible point between them .",
    "let @xmath591 be the corresponding third point ( argument to the chord routine ) .",
    "then , by claim  [ clm : sandwich ] , we have that @xmath591 is between @xmath229 and @xmath551 in both coordinates and below the segment @xmath616 and moreover @xmath617 .",
    "since the chord routine returns without adding a new point on input @xmath618 , it follows that either @xmath619 or the point @xmath620 satisfies @xmath621 . in the former case , since @xmath622 , we obtain @xmath623 as desired . in the latter case , we have @xmath624 .",
    "that is , we claim that @xmath625 is a point of @xmath626 ( by claim  [ clm : sandwich ] ) with maximum ratio distance from @xmath627 .",
    "since the feasible points in @xmath628 lie between @xmath616 and its parallel line through @xmath625 , the claim follows .",
    "this completes the proof of lemma  [ lem : chord - finds - eps - convex ] .    to bound from above the performance ratio",
    "we need a few more lemmas .",
    "our first lemma quantifies the area shrinkage property .",
    "it is notable that this is a statement independent of @xmath1 .",
    "[ lem : area - half ] let @xmath629 be the triangle processed by the chord algorithm at some recursive step",
    ". denote @xmath630 .",
    "let @xmath631 , @xmath632 be the triangles corresponding to the two new subproblems .",
    "then , we have @xmath633    let @xmath634 be the projections of @xmath229 on @xmath635 and @xmath605 respectively ; see figure  [ fig : chord - area ] for an illustration .",
    "let @xmath636\\ ] ] where the equality holds because the triangles @xmath594 and @xmath637 are similar ( recalling that @xmath638 ) . hence , we get @xmath639 we have @xmath640 where ( [ uses : y ] ) follows from ( [ eq : y ] ) . by using ( [ eq :",
    "y2 ] ) and expanding we obtain @xmath641 as desired .",
    "our second lemma gives a convenient lower bound on the value of the optimum .",
    "[ lem : opt - lb ] consider the recursion tree @xmath642 built by the algorithm and let @xmath643 be the set of lowest internal nodes , i.e. , the internal nodes whose children are leaves .",
    "then @xmath644 .",
    "recall that , by convention , there is no node in the tree if , for a triangle , the chord routine terminates without calling @xmath108 .",
    "each lowest internal node of the tree corresponds to a triangle @xmath645 with the property that the ratio distance of the convex pareto set from the line segment @xmath592 is strictly greater than @xmath84 ( as otherwise , the node would be a leaf ) .",
    "each such triangle must contain a point @xmath646 of an optimal @xmath84-cp set .",
    "any two nodes of @xmath643 are not ancestor of each other , and therefore the corresponding triangles are disjoint ( neighboring triangles can only intersect at an endpoint ) .",
    "thus , each one of them must contain a distinct point of the optimal @xmath84-cp set , and hence the lemma follows .",
    "finally , we need a lemma that relates the ratio distance within a triangle to its area . we stress that the lemma applies only to triangles @xmath585 considered by the algorithm .",
    "[ lemma : small - area - means - done ] consider a triangle @xmath585 considered in some iteration of the chord algorithm such that @xmath647 .",
    "let @xmath648 . if @xmath649 , then @xmath650 .",
    "the basic idea of the argument is that the worst - case for the area - error tradeoff is ( essentially ) when @xmath651 , and the triangle @xmath594 is right and isosceles ( i.e. , @xmath652 ) .",
    "we now provide a formal proof .",
    "let @xmath585 be a triangle considered by the algorithm .",
    "the points @xmath653 and we have @xmath654 , @xmath655 and the point @xmath591 lies below the line @xmath592 .",
    "note the latter imply that @xmath656 ( see figure  [ fig : area - distance ] . )",
    "we will relate the area @xmath657 to the ratio distance @xmath658 .",
    "consider the intersection @xmath659 of the lines @xmath592 and @xmath660 , where @xmath661 denotes the origin .",
    "then we have that @xmath662 . from the definition of the ratio distance",
    "it follows that for any point @xmath663 it holds @xmath664 ( in fact , @xmath659 is the unique minimizer ) .",
    "let @xmath665 be the projection of @xmath591 on @xmath592 .",
    "it follows that @xmath666 for the area we have that @xmath667 . since @xmath594 is either right or obtuse",
    ", the length of its largest base is at least twice the length of the corresponding height , i.e. , @xmath668 .",
    "hence , @xmath669 . by expanding and using ( [ eq : star ] ) , we get @xmath670 and the lemma follows .    at this point",
    "we have all the tools we need to complete the proof of theorem  [ thm : ws - ub - area ] .    lemma  [ lem : chord - finds - eps - convex ] gives correctness . to bound the performance ratio we proceed as follows : first , by lemma  [ lem : area - half ] ,",
    "when a node of the tree is at depth @xmath671 , the corresponding triangle will have area at most @xmath672 .",
    "hence , by lemma  [ lemma : small - area - means - done ] ( noting that @xmath673 ) , it follows that the depth of the recursion tree @xmath642 is @xmath674 .",
    "every internal tree node is an ancestor of a node in @xmath643 .",
    "the chord algorithm makes one query for every node of the tree , hence @xmath675 .",
    "lemma  [ lem : opt - lb ] now implies that @xmath676 , which concludes the proof .      in this subsection , we prove the asymptotically tight upper bound of @xmath677 on the worst - case performance ratio of the chord algorithm .",
    "the analysis is more subtle in this case and builds on the intuition obtained from the simple analysis of the previous subsection .",
    "the proof bounds in effect the length of paths in the recursion tree that consist of nodes with a single child .",
    "it shows that if we consider any @xmath1-convex pareto set @xmath0 , the segment of the lower envelope between any two consecutive elements of @xmath0 can not contain too many points of the solution produced by the chord algorithm .",
    "[ thm : ws - ub - tight ] the worst - case performance of the chord algorithm ( with respect to the ratio distance ) is @xmath677 .",
    "we begin by analyzing the case @xmath678 ( i.e. , the special case that one intermediate point suffices  and is required  for an @xmath84-approximation ) and then handle the general case .",
    "it turns out that this special case captures most of the difficulty in the analysis .",
    "let @xmath289 ( leftmost ) and @xmath279 ( rightmost ) be the extreme points of the convex pareto curve as computed by the algorithm .",
    "we consider the case @xmath678 , i.e. , ( i ) the set @xmath679 is _ not _ an @xmath84-cp and ( ii ) there exists a solution point @xmath226 such that @xmath680 is an @xmath84-cp .",
    "fix @xmath280 with @xmath681 .",
    "we will prove that , for an appropriate choice of the constant in the big - theta , the chord algorithm introduces at most @xmath239 points in either of the intervals @xmath682 $ ] , @xmath683 $ ] .",
    "suppose , for the sake of contradiction , that the chord algorithm adds more points than that in the segment @xmath684 ( the proof for @xmath685 being symmetric . )    we say that , in some iteration of the chord algorithm , a triangle is _ active _ , if it contains the optimal point @xmath226 .",
    "in each iteration , the chord algorithm has an active triangle which contains the optimal point @xmath226 . outside that triangle",
    ", the algorithm has constructed an @xmath84-approximation .",
    "we note that the chord algorithm may in principle go back and forth between the two sides of @xmath226 ; i.e. , in some iterations the line parallel to the chord touches the lower envelope to the left of @xmath226 and in other iterations to the right .",
    "let @xmath686 be the initial triangle .",
    "we focus our attention on the ( not necessarily consecutive ) iterations of the chord algorithm that add points to the left of @xmath226 .",
    "we index these iterations in increasing order with @xmath687 $ ] .",
    "consider the `` active '' triangle @xmath688 generated in each such iteration , where @xmath606 is the new point of the curve added in the iteration .",
    "we let @xmath689 be the initial triangle @xmath686 .",
    "it is clear that ( i ) @xmath690 lies to the right of @xmath606 , ( ii ) @xmath691 lies to the left of ( or is equal to ) @xmath692 and ( iii ) @xmath693 .",
    "also , let us denote @xmath694 , that is @xmath695 is the @xmath279-vertex ( i.e. , the vertex that lies to the right of @xmath226 ) of the active triangle in the last iteration @xmath696 .",
    "note that @xmath695 could be equal to the point @xmath279 ( which would happen if the chord algorithm introduces points only to the left of @xmath226 , i.e. , proceeds towards @xmath226 monotonically ) , but in general this will not be the case .",
    "let @xmath697 be the intersection point of the line @xmath605 with the line @xmath698 ; see figure [ tight - upper ] . note that , to the left of @xmath226 the convex pareto curve has no points below the line @xmath698 .",
    "all the points of the convex pareto curve that are left of @xmath226 and lie in the active triangle @xmath688 ( these are the potentially not @xmath84-covered points ) are actually in the triangle @xmath699 .",
    "consider the line that goes through @xmath606 and is parallel to @xmath700 and let @xmath701 be its intersection with @xmath698 .",
    "note that the line @xmath605 is parallel to @xmath702 ( by construction of the algorithm , this is the line that added the point @xmath606 and formed the active triangle @xmath688 ) and @xmath692 lies to the right of ( or is equal to ) @xmath695 , so the line @xmath703 is to the left of ( or is equal to ) @xmath605 , hence @xmath701 lies to the left of ( or is equal to ) @xmath697 .",
    "now , let @xmath11 be the intersection point of @xmath704 with the line @xmath698 .",
    "clearly , @xmath11 lies to the left of @xmath701 .",
    "furthermore , @xmath11 lies to the right of ( or is equal to ) @xmath705 .",
    "the reason is that , below @xmath706 the curve has no points ( strictly ) to the left of the line @xmath707 , so @xmath606 is to the right of the line ( or on the line ) .",
    "if a point @xmath708 is above a line @xmath145 , in the sense that the segment connecting @xmath64 to the origin @xmath661 intersects @xmath145 , say at some point @xmath28 , then we define the _ excess ratio distance _ of @xmath64 from @xmath145 to be @xmath709 , i.e. , the ratio distance of @xmath28 from @xmath64 .",
    "let @xmath710 be the excess ratio distance of @xmath606 from the line @xmath698 for @xmath711 .",
    "let @xmath712 be the excess ratio distance of @xmath695 from the line @xmath703 for @xmath713 . referring to figure [ tight - upper ] , @xmath714 and @xmath715 .",
    "let @xmath716 and let @xmath717 .    by definition",
    ", we have @xmath718 for all @xmath230 .",
    "furthermore , @xmath719 is the excess ratio distance of @xmath720 from the line @xmath721 .",
    "since the coordinates of the points are in @xmath722 $ ] , it follows that @xmath723 .",
    "thus , we get @xmath724    [ claim : tu1 ] @xmath725 and @xmath726 .",
    "let @xmath727 be the intersection of the segment @xmath728 with the line @xmath698 and @xmath729 the intersection of @xmath730 with @xmath698 . by definition , @xmath731 , and @xmath732 .",
    "let @xmath733 be the intersection of @xmath730 with the line from @xmath606 parallel to @xmath698 . from the similar triangles",
    "@xmath734 and @xmath735 , we have @xmath736 .",
    "therefore , @xmath737 . from the similar triangles @xmath738 and @xmath739 , the latter ratio is equal to @xmath740 , yielding the first equality for @xmath741 in the claim .",
    "the second equality follows from the similar triangles @xmath742 and @xmath743 , since @xmath703 is parallel to @xmath700 .",
    "the second equality implies then the expression for @xmath744 .    from the claim we have , @xmath745 and",
    "since @xmath705 lies left of @xmath11 , we have @xmath746 .",
    "therefore , @xmath747    let @xmath748 be the intersections of @xmath749 with the lines @xmath703 and @xmath707 respectively ; see figure [ tight - upper ] . clearly , @xmath750 , and hence @xmath751 . thus , @xmath752",
    ". therefore , @xmath753    [ claim : tu2 ] @xmath754 and @xmath755 .",
    "since the last iteration of the chord algorithm adds a new point @xmath756 , the segment @xmath757 does not @xmath84-cover all the pareto points left of @xmath226 in the active triangle .",
    "these points are all in the triangle @xmath758 .",
    "the ratio distance of any point in this triangle from @xmath757 is upper bounded by both @xmath759 and by @xmath760 .",
    "it follows that @xmath754 and @xmath755 .",
    "thus , we get @xmath761 and @xmath762    [ claim : tu3 ] @xmath763 .    if @xmath764 then the claim follows from inequality ( [ g - bound ] ) .",
    "so suppose that @xmath765 .",
    "the point @xmath766 is at ratio distance at most @xmath84 from the line @xmath684 since @xmath767 is an @xmath1-convex pareto set .",
    "therefore , @xmath226 is at most excess ratio distance @xmath84 from the line @xmath768 , because @xmath768 is parallel to @xmath769 and @xmath695 is to the right of @xmath226 . since @xmath765",
    ", it follows that @xmath770 and hence @xmath771 .",
    "therefore , @xmath772 since @xmath773 ( as @xmath774 is left of @xmath226 ) , we conclude that @xmath775    thus , we have a lower bound on the product of the @xmath741 s from inequality ( [ p - bound ] ) and on the product of the @xmath776 s from claim [ claim : tu3 ] .",
    "it is easy to see ( and is well - known ) that for a fixed product of the @xmath741 s , the product of the @xmath776 s is maximized if all factors are equal .",
    "we include a proof for convenience .",
    "let @xmath777 for @xmath778 .",
    "the maximum of @xmath779 subject to @xmath780 is achieved when all the @xmath781 are equal .",
    "suppose @xmath782 .",
    "then @xmath783 is maximized subject to @xmath784 , when @xmath785 is minimized , which happens when @xmath786 by the arithmetic - geometric mean inequality ( @xmath787 with equality iff @xmath786 . for general @xmath788 ,",
    "if the @xmath781 s maximize @xmath779 subject to @xmath780 then we must have @xmath789 for all pairs @xmath790 , because otherwise replacing @xmath791 by their geometric mean will increase @xmath779 .",
    "thus , for any value of @xmath792 , the product @xmath793 is maximized when @xmath794 for all @xmath795 and @xmath796 . since @xmath797",
    ", we must have @xmath798 because @xmath799 .",
    "therefore , @xmath800 , hence @xmath801 , which implies that @xmath802 .",
    "we now proceed to analyze the general case , essentially by reducing it to the aforementioned special case .",
    "suppose that the optimal solution has an arbitrary number of points , i.e. , has the form @xmath803 .",
    "charge the points computed by the chord algorithm to the edges of the optimal solution as follows : if a point belongs to the portion of the lower envelope between the points @xmath302 and @xmath804 ( where we let @xmath805 and @xmath806 , then we charge the point to the edge @xmath807 ; if the chord algorithm generates a point @xmath229 of the optimal solution then we can charge it to either one of the adjacent edges .",
    "we claim that every edge of @xmath808 is charged with at most @xmath809 points of the chord algorithm , where @xmath810 is the same number as in the above analysis for the @xmath678 case . to see this , consider any edge @xmath807 of @xmath808 .",
    "let @xmath811 be the first point generated by the chord algorithm that is charged to this edge , i.e. , @xmath811 is the first point that lies between @xmath302 and @xmath804 .",
    "we claim that the chord algorithm will generate at most @xmath239 more points in each of the two portions @xmath812 and @xmath813 of the lower envelope .",
    "the argument for the two portions is symmetric .",
    "consider the portion @xmath814 .",
    "the proof that the chord algorithm will introduce at most @xmath239 points in this portion is identical to the proof we gave above for the @xmath678 case , with @xmath811 in place of @xmath289 and @xmath229 in place of @xmath226 .",
    "the only fact about the assumption @xmath678 that was used there was that the edge @xmath684 @xmath1-covers the portion of the lower envelope between @xmath289 and @xmath226 .",
    "it is certainly true here that the segment @xmath815 @xmath1-covers the portion @xmath814 , since the edge @xmath816",
    "@xmath1-covers @xmath817 . hence ,",
    "by the same arguments , the chord algorithm will generate at most @xmath239 points between @xmath811 and @xmath229 .",
    "thus , the algorithm will generate no more than @xmath818 points overall , and hence its performance ratio is @xmath677 .",
    "this completes the proof .",
    "_ we briefly sketch the differences in the algorithm and its analysis for the case of an approximate comb routine .",
    "first , in this case , the description of the chord algorithm ( table  [ table : chord ] ) has to be slightly modified ; this is needed to guarantee that the set of computed points is indeed an @xmath84-cp .",
    "in particular , in the chord routine , we need to check whether @xmath819 for an appropriate @xmath820 .",
    "in particular , we choose @xmath821 such that @xmath822 , where @xmath823 is the accuracy of the approximate comb routine , i.e. , the routine @xmath122 .",
    "consider the case that the @xmath122 routine always returns feasible points that belong to a @xmath120 scaled version of the lower envelope .",
    "the same analysis as in the current section establishes that the chord algorithm performs at most @xmath824 calls to @xmath122 in this setting .",
    "if @xmath821 is `` close '' to @xmath84 ( say , @xmath825 ) the first term is clearly @xmath826 .",
    "hence , to prove the desired upper bound , it suffices to show that @xmath827 .",
    "( it is clear that @xmath828 , but in principle it may be the case that @xmath829 is arbitrarily larger . )",
    "this is provided to us by a planar geometric lemma from  @xcite ( lemma  5.1 ) which states that if @xmath830 then @xmath831 .",
    "selecting @xmath832 suffices for the above and completes our sketched description . _",
    "in section  [ ssec : average - upper ] we present our average case upper bounds and in section  [ ssec : average - lower ] we give the corresponding lower bound .      in section  [ ssec : ppp - upper ]",
    "we start by proving our upper bound for random instances drawn from a poisson point process ( ppp ) .",
    "the analysis for the case of unconcentrated product distributions is somewhat more involved and is given in section  [ ssec : prod - upper ] .",
    "* overview of the proofs . *",
    "the analysis for both cases has the same overall structure , however each case has its difficulties .",
    "we start by giving a high - level overview of the arguments . for the sake of simplicity ,",
    "in the following intuitive explanation , let @xmath55 denote : ( i ) the expected number of points in the instance for a ppp and ( ii ) the actual number of points for a product distribution .",
    "similarly to the simple proof of section  [ sssec : worst - upper - simple ] for worst - case instances , to analyze our distributional instances we resort to an indirect measure of progress , namely the area of the triangles maintained in the algorithm s recursion tree .",
    "we think that this feature of our analysis is quite interesting and indicates that this measure is quite robust .    in a little more detail , we first show ( see lemma  [ lem : area recursion ] for the case of ppp ) that every subdivision performed by the algorithm decreases the area between the upper and lower approximations by a significant amount ( roughly at an exponential rate ) with high probability .",
    "it then follows that at depth @xmath833 of the recursion tree , each `` surviving triangle '' contains an expected number of at most @xmath833 points with high probability .",
    "we use this fact , together with a charging argument in the same spirit as in the worst - case , to argue that the expected performance ratio is @xmath833 in this case .    to analyze the expected performance ratio in the complementary event , we break it into a `` good '' event , under which the ratio is @xmath834 with high probability , and a `` bad '' event , where it is potentially unbounded ( in the poisson case ) or at most @xmath55 ( for the case of product distributions ) .",
    "the potential unboundedness of the performance ratio in the poisson case creates complications in bounding the expected ratio of the algorithm over the entire space .",
    "we overcome this difficulty by bounding the upper tail of the poisson distribution ( see claim  [ claim : ppp - tail ] ) .    in the case of product distributions , the worst case bound of @xmath55 on",
    "the competitive ratio is sufficient to conclude the proof , but the technical challenges present themselves in a different form . here ,",
    "the `` contents '' of a triangle being processed by the algorithm depend on the information coming from the previous recursive calls making the analysis more involved .",
    "we overcome this by understanding the nature of the information provided from the conditioning .    * on the choice of parameters . *",
    "a simple but crucial observation concerns the interesting range for the parameters of the distributions .",
    "suppose that we run the chord algorithm with desired error @xmath148 on some random instance that lies entirely in the set @xmath835 ^ 2 $ ] . then , it is no loss of generality to assume that the number of random points in the instance ( expected number for the ppp case ) is upper bounded by some fixed polynomial in @xmath836 and @xmath837 . if this is not the case , it is easy to show that the chord algorithm makes at most a constant number of @xmath108 calls in expectation .",
    "for the analysis of the ppp case we will make crucial use of the following technical claim :    [ claim : ppp - tail ] let @xmath838 be a @xmath839 random variable , with @xmath840 , and let @xmath841 be some event .",
    "then @xmath842 \\pr[{\\cal e } ] \\le   \\max\\left\\{{1 \\over \\nu } , o(\\nu^3 ) \\pr[{\\cal e } ] \\right\\}.\\ ] ]    let @xmath843 be such that @xmath844 < \\pr[{\\cal e } ] \\le \\pr[x \\ge k^*]$ ] . clearly , @xmath842 \\pr[{\\cal e } ] \\leq { \\mathop{\\textstyle \\sum}}_{i = k^*}^{+ \\infty } i \\cdot \\pr[x = i ]   =   { \\mathop{\\textstyle \\sum}}_{i = k^*}^{+ \\infty } i \\cdot { e^{- \\nu } \\nu^i \\over i ! }   = \\nu { \\mathop{\\textstyle \\sum}}_{i = k^*-1}^{+ \\infty } { e^{- \\nu } \\nu^{i } \\over i ! } = \\nu \\pr[x \\ge k^*-1].\\ ] ] we distinguish two cases . if @xmath845 , then chebyshev s inequality yields @xmath846 \\le { 1 \\over \\nu^2}$ ] which gives @xmath842 \\pr[{\\cal e } ] \\le { 1\\over \\nu}.\\ ] ] if @xmath847 , then @xmath848 \\le { k^*+1 \\over \\nu } \\pr[x = k^*+1 ] \\le o(\\nu ) \\pr[{\\cal e}]\\ ] ] and @xmath849 \\le { ( k^*+1)^2 \\over \\nu^2 } \\pr[x = k^*+1 ] \\le o(\\nu^2 ) \\pr[{\\cal e}].\\ ] ] hence , @xmath850 \\pr[{\\cal e } ] & \\le &   \\nu   \\cdot   \\pr[x \\ge k^*-1]\\\\ & \\le & \\nu   \\cdot   \\big(\\pr[{\\cal e}]+ \\pr[x = k^*-1 ] + \\pr[x = k^*]\\big)\\\\ & \\le & o(\\nu^3 ) \\cdot \\pr[{\\cal e}].\\end{aligned}\\ ] ] this concludes the proof of the claim .",
    "we start by pointing out that if the intensity of the ppp is very large , the chord algorithm will terminate after a constant number of calls in expectation :    [ fact : dens - ppp ] let @xmath595 be at the root of the chord algorithm s recursion tree and let @xmath194 denote the intensity of the ppp .",
    "let @xmath851 and @xmath852 . if @xmath853 , then @xmath854   = o(1)$ ] .",
    "first note we can clearly assume that @xmath855 and @xmath856 .",
    "let @xmath857 and @xmath858 .",
    "let @xmath859 be the right triangle of maximum area whose hypotenuse is parallel to @xmath39 .",
    "( this is the shaded triangle in figure  [ fig : ub - ac ] . )",
    "we claim that @xmath860 indeed , it is clear that @xmath171 is a vertex of @xmath861 and that either @xmath862 or @xmath863 ( or both ) are vertices .",
    "hence , one of the edges of @xmath861 has length at least @xmath864 . since @xmath30 is the slope of the hypotenuse , the other edge has length at least @xmath865 .",
    "if there is a feasible point in @xmath861 , the chord algorithm will find it by calling @xmath233 and terminate ( since such a point forms an @xmath84-cp set ) .",
    "let @xmath866 be the number of random points that land in the triangle @xmath861 .",
    "note that @xmath866 is a @xmath867 random variable , with @xmath868 .",
    "we can write @xmath869   = { \\mathbb{e}}[{\\mathrm{chord}}_{{\\epsilon}}(t_1 ) \\mid x^{\\ast } = 0 ] \\pr[x^{\\ast}=0 ] +   { \\mathbb{e}}[{\\mathrm{chord}}_{{\\epsilon}}(t_1 ) \\mid x^{\\ast } \\ge 1 ] \\pr[x^{\\ast } \\ge 1].\\ ] ] observe that the second term is bounded from above by a constant , hence it suffices to bound the first term . recall that the number of calls performed by the chord algorithm is at most twice the number @xmath870 of feasible points in the root triangle @xmath577 .",
    "therefore , we can write @xmath871 \\pr[x^{\\ast}=0 ] \\le 2 { \\mathbb{e}}[y_1 \\mid x^{\\ast } = 0 ] \\pr[x^{\\ast}=0].\\ ] ] recall that @xmath870 is a @xmath872 random variable , where @xmath873 and note that we can assume wlog that @xmath874 ( since otherwise the expected number of feasible points in @xmath577 is at most @xmath396 and we are done ) .",
    "hence , by claim  [ claim : ppp - tail ] the rhs above is bounded by @xmath875 \\right\\}.\\ ] ] thus , to complete the proof it suffices to show that @xmath876 = o(1)$ ] .",
    "first note that this quantity equals @xmath877 which is at most @xmath878 by monotonicity ( which holds for our choice of @xmath879 ) .",
    "the latter expression is at most @xmath880 , where @xmath881 , which is easily seen to be absolutely bounded .",
    "the same proposition also applies for the case that we have an approximate @xmath122 routine ( in this case , we replace @xmath84 by an appropriate @xmath882 so that @xmath883 ) .",
    "we remark that a similar proposition can be shown for the hausdorff distance ; this does not hold for the case of the horizontal / vertical distance , which is why the average case bounds of this section do not apply for the latter metrics .",
    "note that by assumption @xmath884 ^ 2 $ ] which implies that @xmath885 and @xmath584 .",
    "we also have that @xmath886 ( since otherwise the set @xmath887 is an @xmath84-cp ) which gives @xmath888 therefore , @xmath889    the main result of this section is the following theorem , which combined with proposition  [ fact : dens - ppp ] , yields the desired upper bound of @xmath890 on the expected performance ratio .",
    "[ th : competitive ratio ppp ] let @xmath577 be the triangle at the root of the chord algorithm s recursion tree , and suppose that points are inserted into @xmath577 according to a poisson point process with intensity @xmath194 .",
    "the expected performance ratio of the chord algorithm on this instance is @xmath891 .",
    "the proof of theorem  [ th : competitive ratio ppp ] will require a sequence of lemmas . throughout this section , we will denote @xmath892 . recall that the number of queries performed by the chord algorithm is bounded from above by twice the total number of points in the triangle @xmath577 .",
    "since the expected number of points in @xmath577 is @xmath893 , we have :    [ lem : super pessimistic competitive ratio ] the expected performance ratio of the chord algorithm is @xmath894 .    hence , we will henceforth assume that @xmath895 is bounded from below by a sufficiently large positive constant .",
    "( if this is not the case , the expected total number of points inside @xmath577 is @xmath506 and the desired bound clearly holds . )",
    "our first main lemma in this section is an average case analogue of our lemma  [ lem : area - half ] : the lemma says that the area of the triangles maintained by the algorithm decreases _ geometrically _ ( as opposed to linearly , as is the case for arbitrary inputs ) at every recursive step ( with high probability ) . intuitively , this geometric decrease is what causes the performance ratio to drop by an exponential in expectation .",
    "[ lem : area recursion ] let @xmath585 be the triangle processed by the chord algorithm at some recursive step .",
    "denote @xmath896 .",
    "let @xmath897 and @xmath898 .",
    "for all @xmath899 , with probability at least @xmath900 conditioning on the information available to the algorithm , @xmath901    it follows from the properties of the chord algorithm ( see e.g. , claim  [ clm : sandwich ] ) that , before the @xmath108 routine on input @xmath594 is invoked , the following information is known to the algorithm , conditioning on the history ( see figure  [ fig : chord - avg ] ) :    * there exist solution points at the locations @xmath544 , for all @xmath902 $ ] .",
    "* there is no point below the line @xmath903 , for all @xmath541 $ ] .",
    "* there is no point below the line @xmath904 , for all @xmath541 $ ] .    by the definition of the poisson point process , conditioning on the above information",
    ", the number of points in a region of area @xmath0 inside @xmath594 follows a poisson distribution with parameter @xmath905 .",
    "hence , letting @xmath906 being parallel to @xmath592 so that the triangle @xmath907 has area @xmath908 , it follows that , with probability at least @xmath909 , @xmath910 ( i.e. , the triangle contains a feasible point ) .",
    "hence , with probability at least @xmath909 the point @xmath229 is contained in @xmath861 .",
    "we bound from above the area of @xmath911 by the area of @xmath912 ( clearly , @xmath913 ) and similarly the area of @xmath914 by the area of @xmath915 . from the similarity of the triangles @xmath594 and @xmath861 we get @xmath916 hence , @xmath917 which gives @xmath918 .",
    "therefore , @xmath919 finally , @xmath920 this concludes the proof of lemma  [ lem : area recursion ] .",
    "let us choose @xmath921 , and let @xmath598 be a triangle maintained by the algorithm at depth @xmath6 of the recursion .",
    "it follows from lemma  [ lem : area recursion ] that , with probability at least @xmath922 , @xmath923 where to bound the probability of the above event we have taken a union bound over the events on the path of the recursion tree connecting @xmath598 to the root of the recursion .",
    "now consider the top @xmath924 levels of the recursion tree of the algorithm .",
    "using lemma  [ lem : area recursion ] and a union bound it follows that , with overall probability at least @xmath925 , the area of _ every _ triangle at depth ( exactly ) @xmath926 of the recursion tree is bounded from above by @xmath927 where we used our assumption on the range of @xmath171 .",
    "let @xmath928 be the event that all the nodes ( triangles ) maintained by the algorithm at depth @xmath926 of the recursion tree ( if any ) have area at most @xmath929 .",
    "in the aforementioned , we argued that the probability of the event @xmath928 is at least @xmath930 .",
    "we now show the following :    [ lem : competitive ratio in the good event ] conditioning on @xmath928 , the expected performance ratio of the chord algorithm is @xmath931 .",
    "let @xmath932 be the recursion tree of the algorithm and @xmath933 be obtained from @xmath932 by pruning it at level @xmath926 .",
    "let @xmath934 be the set of nodes of @xmath933 and let @xmath935 be the subset of nodes in @xmath934 that lie at depth @xmath926 from the root .",
    "clearly @xmath936 is a subset of the leaves of @xmath933 .    for a triangle ( node ) @xmath598 maintained by the algorithm at depth @xmath926 of the recursion , that is @xmath937 , we let the random variable @xmath938 denote the number of points inside @xmath598 . also , denote by @xmath939 the set of lowest internal nodes of the tree @xmath933 . by ( a straightforward analogue of ) lemma  [ lem : opt - lb ] , we have @xmath940 . also , since @xmath933 is a depth @xmath926 binary tree , it holds @xmath941 .",
    "we condition on the information @xmath942 available to the algorithm in the first @xmath926 levels of its recursion - tree ( without the information obtained from processing ",
    "i.e. , calling @xmath108 for  any triangle at depth @xmath926 ) . by assumption",
    ", @xmath942 satisfies the event @xmath943 .",
    "conditioning on the information @xmath942 , for all @xmath937 , @xmath938 follows a poisson distribution with parameter @xmath944 .",
    "so , given that the event @xmath943 holds , we have @xmath945 \\le \\nu \\cdot s^{\\ast \\ast}$ ] .",
    "note that the chord algorithm makes a query to @xmath108 for every node in the tree @xmath933 . also recall that the number of queries performed by the algorithm on a triangle @xmath598 containing a total number of @xmath938 points is at most @xmath946 .",
    "hence , the expected total number of queries made can be bounded as follows : @xmath947 & \\le & |{\\cal v}_{d^{\\ast}}| + 2 \\cdot { \\mathop{\\textstyle \\sum}}_{t \\in { \\cal l}_{d^{\\ast } } } \\mathbb{e}[x_t~|~{\\cal f}]\\\\ & \\le & |{\\cal v}_{d^{\\ast}}| + 2 \\left|{\\cal l}_{d^{\\ast}}\\right| \\cdot \\nu \\cdot s^{\\ast \\ast}\\\\ & \\le & |{\\cal v}_{d^{\\ast}}| +   4 |{\\cal l}'_{d^{\\ast}}| \\cdot \\nu \\cdot s^{\\ast \\ast}\\\\ & \\le & |{\\cal l}'_{d^{\\ast}}|   \\cdot ( 2d^{\\ast}+ 4   \\nu \\cdot s^{\\ast \\ast}),\\end{aligned}\\ ] ] where the third inequality uses the fact that @xmath948 .",
    "so , conditioning on the information @xmath942 , the expected performance ratio of the algorithm is @xmath949 & \\le & \\mathbb{e}\\left [ { { \\mathrm{chord}}_{{\\epsilon } } \\over |{\\cal l}'_{d^{\\ast}}|}~\\vline~{\\cal f}\\right ] \\\\ & \\le & ( 2d^{\\ast}+ 4   \\nu \\cdot s^{\\ast \\ast } ) \\\\ & = & o \\left ( \\log \\log ( \\nu s_1 ) \\right).\\end{aligned}\\ ] ] integrating over all possible @xmath942 in @xmath943 concludes the proof of lemma  [ lem : competitive ratio in the good event ] .    from lemma  [ lem : competitive ratio in the good event ]",
    "it follows that @xmath950=o\\left ( \\log \\log ( \\nu s_1 ) \\right),\\ ] ] and from the preceding discussion we have that @xmath951 \\le { 2 \\over ( { \\ln ( \\nu s_1)})^{c-1}}.$ ] hence , we have established the following .",
    "[ lem : good case competitive ratio ] for @xmath952 , there exists an event @xmath953 , with @xmath954 \\ge 1-{2 \\over ( { \\ln ( \\nu s_1)})^{c-1}}$ ] , such that the expected performance ratio of the algorithm conditioning on @xmath928 is @xmath955 .",
    "let @xmath956 be the event that all the triangles at the level @xmath957 of the recursion tree of the algorithm ( if any ) have area at most @xmath958 . with the same technique , but using different parameters in the argument , we can also establish the following :    [ lem : pessimistic competitive ratio ] for @xmath959 , there exists an event @xmath960 , with @xmath961 \\ge 1-{2 \\over ( { \\nu s_1})^{c'-1}}$ ] , such that the expected performance ratio of the algorithm conditioning on @xmath960 is @xmath962 .",
    "we want to use lemmas  [ lem : good case competitive ratio ] and  [ lem : pessimistic competitive ratio ] together with proposition  [ lem : super pessimistic competitive ratio ] to deduce that the expected performance ratio of the algorithm is @xmath955 .",
    "this may seem intuitive , but it is in fact not immediate . for technical purposes let us define the event @xmath963 , where @xmath943 is the event defined in the proof of lemma  [ lem : good case competitive ratio ] .",
    "it is easy to see that conditioning on @xmath964 the expected performance ratio of the algorithm can still be bounded by @xmath965 , since this expectation is affected only by whatever happens at level @xmath966 of the recursion tree and below . on the other hand , using the fact that @xmath954 \\ge 1-{2 \\over ( { \\ln ( \\nu s_1)})^{c-1}}$ ] , it follows that @xmath967 \\le { 2 \\over ( { \\ln ( \\nu s_1)})^{c-1}}.\\ ] ] we bound the expectation of the performance ratio using the law of total probability as follows : @xmath968   & \\le & \\mathbb{e}\\left [ { { \\mathrm{chord}}_{{\\epsilon } } \\over { \\mathrm{opt}}_{{\\epsilon}}}~\\vline~{\\cal a}\\right ] \\cdot \\pr[{\\cal a } ]   +   \\mathbb{e}\\left [ { { \\mathrm{chord}}_{{\\epsilon } } \\over { \\mathrm{opt}}_{{\\epsilon}}}~\\vline~{\\cal c}\\right ] \\cdot \\pr[{\\cal c } ] \\nonumber \\\\ & + & \\mathbb{e}\\left [ { { \\mathrm{chord}}_{{\\epsilon } } \\over { \\mathrm{opt}}_{{\\epsilon}}}~\\vline~\\overline{{\\cal a}\\cup { \\cal c}}\\right ] \\cdot \\pr\\left[\\overline{{\\cal a}\\cup { \\cal c}}\\right ] \\nonumber \\\\ & \\le & o\\left ( \\log \\log ( \\nu s_1 ) \\right ) \\cdot \\left ( 1-{2 \\over ( { \\ln ( \\nu s_1)})^{c-1}}\\right )   + o\\left ( \\log(\\nu s_1 ) \\right ) \\cdot { 2 \\over ( { \\ln ( \\nu s_1)})^{c-1 } } \\nonumber \\\\   & + & \\mathbb{e}\\left [ { { \\mathrm{chord}}_{{\\epsilon } } \\over { \\mathrm{opt}}_{{\\epsilon}}}~\\vline~\\overline{{\\cal a}\\cup { \\cal c}}\\right ] \\cdot \\pr\\left[\\overline{{\\cal a}\\cup { \\cal c}}\\right ] .",
    "\\label{eqn : ena } \\end{aligned}\\ ] ] where ( [ eqn : ena ] ) follows from lemmas  [ lem : good case competitive ratio ] and  [ lem : pessimistic competitive ratio ] . to conclude",
    ", we need to bound the last summand in the above expression .",
    "note first that @xmath969 .",
    "hence , @xmath970 \\le { 2 \\over ( { \\nu s_1})^{c'-1}}.\\ ] ] we again use the fact that the number of queries made by the chord algorithm ( hence , also the performance ratio ) is bounded by twice the total number of points in the triangle at the root of the recursion tree .",
    "this number @xmath838 follows a poisson distribution with parameter @xmath893 .",
    "hence , we have @xmath971 \\cdot \\pr\\left[\\overline{{\\cal a}\\cup { \\cal c}}\\right ] \\le 2 \\cdot \\mathbb{e}\\left [ x~\\vline~\\overline{{\\cal a}\\cup { \\cal c}}\\right ] \\cdot \\pr\\left[\\overline{{\\cal a}\\cup { \\cal c}}\\right].\\ ] ] to bound the right hand side of the above inequality we use claim  [ claim : ppp - tail ] and obtain : @xmath972 \\cdot \\pr \\left [ \\overline{{\\cal a } \\cup { \\cal c } } \\right ]   & \\le & \\max\\left\\{{1 \\over \\nu s_1 } , o((\\nu s_1)^3 ) \\cdot \\pr\\left[\\overline{{\\cal a}\\cup { \\cal c}}\\right ] \\right\\ } \\\\ &",
    "\\le & \\max \\left\\ { { 1\\over \\nu s_1 } , o((\\nu s_1)^3 ) { 2 \\over ( { \\nu s_1})^{c'-1}}\\right\\}.\\end{aligned}\\ ] ] choosing @xmath973 , the above rhs becomes @xmath506 .",
    "plugging this into with @xmath974 gives @xmath975 = o\\left ( \\log \\log ( \\nu s_1 ) \\right).\\end{aligned}\\ ] ] this concludes the proof of theorem  [ th : competitive ratio ppp ] .",
    "we start by proving the analogue of proposition  [ fact : dens - ppp ] .",
    "[ fact : dens - unif ] let @xmath595 be at the root of the chord algorithm s recursion tree and suppose that @xmath55 points are inserted into @xmath577 independently from a @xmath204-balanced distribution , where @xmath976 . let @xmath851 , @xmath852 and @xmath977 . if @xmath978 , then @xmath854   = o(1)$ ] .    as in proposition  [ fact : dens - ppp ] we have that @xmath979 ( see figure  [ fig : ub - ac ] ) .",
    "the probability that a random point falls into @xmath861 is at least @xmath980 , hence the probability than none of the @xmath55 points falls into @xmath861 is at most @xmath981 .",
    "as before , if there is a feasible point in @xmath861 , the chord algorithm will find it and terminate . in all cases ,",
    "the algorithm terminates after at most @xmath982 calls to @xmath108 .",
    "hence , @xmath983 \\leq 3 + 2n \\cdot ( 1-t^{\\ast})^n$ ] . the last summand is bounded by @xmath984 which is at most @xmath985 for all @xmath986 by monotonicity .",
    "the latter quantity equals @xmath987 , where @xmath988 , which is easily seen to be @xmath506 .    recalling that @xmath885 and @xmath989 we deduce that @xmath990    the main result of this section is devoted to the proof of the following theorem :    [ th : competitive ratio product delta - balanced distribution ]",
    "let @xmath577 be the triangle at the root of the chord algorithm s recursion tree , and suppose that @xmath55 points are inserted into @xmath577 independently from a @xmath204-balanced distribution , where @xmath205 .",
    "the expected performance ratio of the chord algorithm on this instance is @xmath991 .",
    "combined with proposition  [ fact : dens - unif ] , the theorem yields the desired upper bound of @xmath992 .",
    "the proof has the same overall structure as the proof of theorem  [ th : competitive ratio ppp ] , but the details are more elaborate .",
    "we emphasize below the required modifications to the argument .",
    "since the performance ratio of the chord algorithm is at most @xmath982 on any instance with @xmath55 points , we will assume that @xmath55 is lower bounded by a sufficiently large absolute constant ( @xmath993 suffices for our analysis ) .",
    "we start by giving an area shrinkage lemma , similar to lemma  [ lem : area recursion ] .",
    "( see figure  [ fig : chord - avg ] for an illustration . )",
    "[ lem : area recursion product distn ] let @xmath585 be a triangle processed by the chord algorithm at recursion depth at most @xmath994",
    ". denote @xmath995 .",
    "let @xmath897 , @xmath898 and @xmath996 . for all @xmath899 , with probability",
    "at least @xmath997 conditioning on the information available to the algorithm ,",
    "@xmath998    we follow the proof of lemma  [ lem : area recursion ] with the appropriate modifications .",
    "let @xmath594 be the triangle maintained by the algorithm at some node of the recursion tree , and suppose that @xmath594 is at recursion depth at most @xmath999 .",
    "the information available to the algorithm when it processes @xmath594 ( before it makes the query @xmath1000 ) is :    * the location of all points @xmath544 , @xmath902 $ ] is known ; by our assumption on the depth it follows that @xmath1001 .",
    "* there is no point below the line ( defined by ) @xmath903 , or below the line @xmath904 , for all @xmath541 $ ] .    given this information , the probability that , among the remaining @xmath1002 points ( whose location is unknown ) , none falls inside a triangle @xmath598 of area @xmath1003 inside @xmath594 , is at most @xmath1004 indeed ,",
    "let @xmath1005 be the subset of the root triangle which is available for the location of @xmath229 ; this is the convex set below the line @xmath1006 , to the right of all lines @xmath1007 , for @xmath541 $ ] , and above all lines @xmath1008 , for @xmath541 $ ] .",
    "the probability that a point whose location is unknown falls inside @xmath1009 is @xmath1010 \\over { \\cal d}[{t}^{\\ast}_i ] } \\ge { ( 1-\\gamma ) { \\cal u}\\left [ t \\right ] \\over { \\cal u}[{t}^{\\ast}_i ] / ( 1-\\gamma ) } \\ge   { ( 1-\\gamma ) { \\cal u}\\left [ t \\right ] \\over { \\cal u } [ { t_1}]/ ( 1-\\gamma ) } = { ( 1-\\gamma)^2 } { s(t ) \\over s_1}.\\ ] ] choosing @xmath1011 , the probability becomes @xmath1012 hence , the probability that @xmath598 is empty is at most @xmath1013 the proof of the lemma is concluded by identical arguments as in the proof of lemma  [ lem : area recursion ] .    using lemma  [ lem : area recursion product distn ] and the union bound , we can show that , with probability at least @xmath1014 the following are satisfied :    * all triangles maintained by the algorithm at depth @xmath1015 of its recursion tree have area at most @xmath1016 * for every node ( triangle ) @xmath230 in the first @xmath1017 levels of the recursion tree @xmath1018 where @xmath1019 is defined as in the statement of lemma  [ lem : area recursion product distn ] .",
    "the proof of the second assertion above follows immediately from lemma  [ lem : area recursion product distn ] and the union bound .",
    "the first assertion is shown similarly to the analogous assertion of theorem  [ th : competitive ratio ppp ] .",
    "for the above we assumed that @xmath1020",
    ".    now let us call @xmath1021 the event that the above assertions are satisfied .",
    "we can show the following .",
    "[ lem : competitive ratio in the good event - product ] suppose @xmath1022 .",
    "conditioning on the event @xmath1021 , the expected performance ratio of the chord algorithm is @xmath1023 .",
    "the proof is in the same spirit to the proof of lemma  [ lem : competitive ratio in the good event ] , but more care is needed .",
    "we need to argue that , under @xmath1021 , the expected number of points falling inside a triangle at depth @xmath1024 of the recursion tree is @xmath1025 . using rationale similar to that used in the proof of lemma  [ lem : area recursion product distn ] above , we have the following : let @xmath594 be the triangle maintained by the algorithm at a node @xmath230 at depth @xmath1015 of the recursion tree .",
    "let also @xmath64 be a point whose location is unknown to the algorithm ( conditioning on the information known to the algorithm after processing the first @xmath1026 levels of the recursion tree ) .",
    "the probability that the point @xmath64 falls inside @xmath594 is @xmath1027 \\over { \\cal d}[{t}^{\\ast}_i ] }   \\le { { \\cal u}\\left [ t_i \\right ] / ( 1-\\gamma ) \\over ( 1-\\gamma ) { \\cal u}[{t}^{\\ast}_i ] } , \\ ] ] where @xmath1028 is the region below the line @xmath1006 , above the lines @xmath903 , for all @xmath271 in the first @xmath1024 levels of the recursion tree , and above the lines @xmath1008 , for all @xmath271 in the first @xmath1015 levels of the recursion tree . to upper bound the probability that @xmath64 falls inside @xmath594",
    ", we need a lower bound on the size of the area @xmath1029 .",
    "such bound can be obtained by noticing that @xmath1030 where the summation ranges over all @xmath271 in the first @xmath994 levels of the recursion tree .",
    "hence , @xmath1031 where we used that @xmath1022 .",
    "hence , the probability that a point falls inside @xmath594 is at most @xmath1032 / ( 1-\\gamma ) \\over ( 1-\\gamma ) { \\cal u}[{t}^{\\ast}_i ] } \\le { 1 \\over ( 1-\\gamma)^2 } \\cdot { s_1 \\cdot { e \\cdot c \\cdot \\ln \\ln n",
    "\\over n } \\over s_1/2 } \\le   { 2 \\cdot e \\cdot c \\cdot \\ln \\ln n \\over ( 1-\\gamma)^2 n}.\\ ] ] therefore , the expected number of points falling in @xmath594 is at most @xmath1033 the final part of the proof is a charging argument identical to the one in lemma  [ lem : competitive ratio in the good event ] .",
    "we have thus established the following :    [ lem : good case competitive ratio - product ] for @xmath1034 , there exists an event @xmath1021 , with @xmath1035 \\ge 1-{2   \\over \\left ( \\ln n \\right)^{{{0.5 c ( 1-\\gamma)^2}}-1}},$ ] such that the expected performance ratio of the chord algorithm conditioning on @xmath1021 is @xmath1036 .",
    "we can also show the analogue of lemma  [ lem : pessimistic competitive ratio ] .",
    "namely ,    [ lem : pessimistic competitive ratio - product ] for @xmath1037 , there exists an event @xmath1038 , with @xmath1039 \\ge 1-{2 \\over n^{{{0.5 c ' ( 1-\\gamma)^2}}-1}}$ ] , such that the expected performance ratio of the chord algorithm conditioning on @xmath1038 is @xmath1040 .",
    "the proof is similar to the proof of lemma  [ lem : good case competitive ratio - product ] , except that the bound is now a bit trickier . for @xmath1037 ,",
    "let @xmath1038 be the event that    * all the triangles maintained by the algorithm at depth @xmath1041 of its recursion tree have area at most @xmath1042 * for every node @xmath230 inside the first @xmath1043 levels of the recursion tree @xmath1044 where @xmath1045 is defined as in the statement of lemma  [ lem : area recursion product distn ] .    using arguments similar to those in the proof of lemma  [ lem : area recursion product distn ] and the union bound , we obtain that @xmath1046 \\ge 1-{2 \\over n^{{{0.5 c ' ( 1-\\gamma)^2}}-1}}.\\ ] ] now let @xmath1047 and @xmath933 be the recursion tree of the algorithm pruned at level @xmath926 .",
    "we also define the set @xmath1048 as in the proof of lemma  [ lem : competitive ratio in the good event ] , ( but with @xmath1049 replaced by @xmath1050 ) . as in that proof , any @xmath84-cp set needs to use at least @xmath1051 points .",
    "moreover , the total number of nodes inside @xmath933 is at most @xmath1052 whenever the algorithm processes a triangle , a planar region of area at most @xmath1053 is removed from @xmath577 ( the root triangle ) .",
    "therefore , after finishing the processing of the first @xmath1054 levels of the tree , a total area of at most @xmath1055 is removed from @xmath577 .",
    "we distinguish two cases . if @xmath1056 , then the size of the optimum is at least @xmath1057 points . since there is a total of @xmath55 points ( and the algorithm never performs more than @xmath1058 @xmath108 calls ) , it follows that in this case the performance ratio is @xmath1059 .    on the other hand ,",
    "if @xmath1060 , then the total area that has been removed from @xmath577 is at most @xmath1061 hence , the remaining area is at least @xmath1062 , assuming @xmath1063 . given this bound it follows that the expected number of points inside a triangle at level @xmath1064 of the recursion tree is at most @xmath1065 using the aforementioned and noting that the performance ratio `` paid '' within the first @xmath1066 levels of the recursion tree is at most @xmath1067 , we can conclude the proof via arguments parallel to those in the proof of lemma  [ lem : competitive ratio in the good event ] .",
    "now let us choose @xmath1068 and @xmath1069 . from lemmas  [ lem : good case competitive ratio - product ] and",
    "[ lem : pessimistic competitive ratio - product ] we have that @xmath1070 \\ge 1- { 2 \\over ( \\ln n)^3}~~\\text{and}~~\\pr[{\\cal b}_{c ' } ] \\ge 1- { 2 \\over n}.\\ ] ] given this , we can conclude the proof theorem  [ th : competitive ratio product delta - balanced distribution ] .",
    "the argument is the same as the end of the proof of theorem  [ th : competitive ratio ppp ] , except that we can now trivially bound the performance ratio of the algorithm by @xmath982 in the event @xmath1071 .      in this section",
    "we show that our upper bounds on the expected performance of the algorithm are tight up to constant factors .",
    "in particular , for the case of the poisson point process we prove :    [ thm : lower bound ppp ] let @xmath577 be the triangle at the root of the chord algorithm s recursion tree , and suppose that points are inserted into @xmath577 according to a poisson point process with intensity @xmath194 .",
    "there exists an infinite family of instances ( parameterized by @xmath84 and @xmath8 ) on which the expected performance ratio of the chord algorithm is @xmath1072 . in particular",
    ", we can select the parameters so that @xmath1073 , which yields a lower bound of @xmath1074 .",
    "the lower bound construction is reminiscent to the worst - case instance of section  [ ssec : worst - lower ] . in particular",
    ", the initial triangle @xmath1075 ( at the root of the recursion tree ) will be right and @xmath1076 . to avoid clutter in the expressions",
    ", we present the proof for the case @xmath217 .",
    "the generalization for all values of @xmath8 is straightforward .",
    "we fix @xmath1077 , @xmath1078 and @xmath1079 and select the intensity of the poisson process to be @xmath1080 .",
    "note that for this setting of the parameters we have that @xmath1081 , we thus obtain an @xmath1082 lower bound .",
    "given the endpoints @xmath1083 , it is clear that @xmath1084 with probability @xmath396 .",
    "hence , it suffices to show that the chord algorithm makes @xmath1085 @xmath108 calls in expectation before it terminates . to show this ,",
    "we are in turn going to prove that for @xmath84 being a sufficiently small positive constant , with constant probability , there exists a path @xmath1086 of length @xmath1087 in the recursion tree of the algorithm .",
    "as shown in lemma  [ lem : hd - vs - rd ] , for such instances the ratio distance is very well approximated by the horizontal distance .",
    "in particular , consider the triangle @xmath585 ( see figure  [ fig : chord - avg - lb ] ) , where @xmath1088 .",
    "for any point @xmath1089 , we have that @xmath1090 hence , as long as @xmath1091 ( the slope of @xmath592 ) is sufficiently large , we can essentially use the horizontal distance metric as a proxy for the ratio distance .",
    "indeed , this will be the case for our lower bound instance below .",
    "we now proceed to formally describe the construction .",
    "the path @xmath1086 of length @xmath1087 will be defined by the triangles with @xmath1092 , i.e. , the ones corresponding to the right subproblem in every subdivision performed by the algorithm . for notational convenience",
    ", we shift the coordinate system to the point @xmath1093 , so that @xmath1094 , @xmath1095 and @xmath1096 .",
    "( note that the horizontal distance is invariant under translation . )",
    "we label the triangles in the path @xmath1097 by @xmath577 , @xmath1098 , @xmath1099 , and we let the vertices of triangle @xmath594 be @xmath1100 , @xmath1101 , and @xmath1092 .",
    "suppose that when the chord algorithm processes the triangle @xmath594 , the @xmath108 routine returns the point @xmath229 on a line @xmath1102 parallel to @xmath592 ( as in figure  [ fig : chord - avg - lb ] ) .",
    "note that @xmath1103 and @xmath1104 .",
    "let @xmath1105 .",
    "let @xmath1106 .",
    "the theorem follows easily from the next lemma :    [ lem : long path ] let @xmath84 be a sufficiently small positive constant . with probability at least @xmath1107 , for all @xmath437 $ ] , @xmath1108 where @xmath1109 and @xmath1110 .",
    "it is clear that ( [ eqn : rec - bound ] ) is satisfied for @xmath339 .",
    "we are going to show by induction that , if ( [ eqn : rec - bound ] ) holds for some @xmath230 , it also holds for @xmath344 with probability at least @xmath1111 .",
    "the theorem then follows by a union bound over all @xmath437 $ ] .    by the similarity of the triangles",
    "@xmath1112 and @xmath1113 we have @xmath1114 from the properties of the poisson point process we have the following : conditioning on the information available to the algorithm when it processes the triangle @xmath594 , if a measurable region inside @xmath594 has area @xmath1115 , then the number of points inside this region follows a poisson distribution with parameter @xmath1116 . hence , with probability at least @xmath1117 , any such region contains at least one point .",
    "hence , with probability at least @xmath1118 we have that @xmath1119 . note that @xmath1120 . using   and the induction hypothesis",
    ", this implies that , with probability at least @xmath1118 , @xmath1121 hence @xmath1122 as desired .    on the other hand ,",
    "if the area of a region is no more than @xmath1123 the probability that a point is contained in that region is at most @xmath1124 .",
    "similarly , this implies that , with probability at least @xmath1125 , @xmath1126 by the properties of the poisson point process it follows that the point @xmath229 is uniformly distributed on the segment @xmath1102 .",
    "hence , with probability at least @xmath1127 , it holds @xmath1128 a union bound concludes the proof .",
    "we now show how the theorem follows from the above lemma .",
    "first note that , for all @xmath230 it holds @xmath1129 hence , by lemma  [ lem : long path ] and the choice of @xmath394 , it is easy to check that with probability at least @xmath1130 , we have @xmath1131 and @xmath1132",
    "the latter condition implies that the horizontal distance is a very good approximation to the ratio distance .",
    "the latter , combined with the first condition , implies that the node ( corresponding to the triangle ) @xmath1133 is not a leaf of the recursion tree .",
    "that is , all the triangles @xmath1134 survive in the recursion tree , since the chord algorithm does not have a certificate that the points already computed are enough to form an @xmath84-cp set .",
    "this concludes the proof of the theorem .    an analogous result can be shown similarly for the case of @xmath55 points drawn from a balanced distribution",
    "we studied the chord algorithm , a simple popular greedy algorithm that is used ( under different names ) for the approximation of convex curves in various areas .",
    "we analyzed the performance ratio of the algorithm , i.e. , the ratio of the cost of the algorithm over the minimum possible cost required to achieve a desired accuracy for an instance , with respect to the hausdorff and the ratio distance .",
    "we showed sharp upper and lower bounds , both in a worst case and in an average setting . in the worst case",
    "the chord algorithm is roughly at most a logarithmic factor away from optimal , while in the average case it is at most a doubly logarithmic factor away .",
    "we showed also that no algorithm can achieve a constant ratio in the worst - case , in particular , at least a doubly logarithmic factor is unavoidable .",
    "we leave as an interesting open problem to determine if there is an algorithm with a better performance than the chord algorithm ( both in the worst - case and in average case settings ) , and to determine what is the best ratio that can be achieved .",
    "another interesting direction of further research is to analyze the performance of the chord algorithm in three and higher dimensions , and to characterize what is the best performance ratios that can be achieved by any algorithm ."
  ],
  "abstract_text": [
    "<S> the chord algorithm is a popular , simple method for the succinct approximation of curves , which is widely used , under different names , in a variety of areas , such as , multiobjective and parametric optimization , computational geometry , and graphics . </S>",
    "<S> we analyze the performance of the chord algorithm , as compared to the optimal approximation that achieves a desired accuracy with the minimum number of points . </S>",
    "<S> we prove sharp upper and lower bounds , both in the worst case and average case setting . </S>"
  ]
}