{
  "article_text": [
    "data traffic in wireless networks has been increasing exponentially for a long time and is expected to continue this trend .",
    "the emerging data - hungry applications , such as video - on - demand and cloud computing , as well as the exploding number of smart user devices demand the introduction of disruptive technologies .",
    "an analogous situation appears in the case of wireline ( mostly fiber - optical ) traffic , where the currently deployed infrastructure is expected to soon reach its limits , leading to the so - called `` capacity crunch '' @xcite .",
    "one way to counter this trend is the parallelization of information transmission in the spatial domain , thereby transmitting multiple data streams in parallel by using the same infrastructure ( antennas ) over the air in wireless communications or within the same optical fiber .",
    "the challenge is that , unlike the parallel use of orthogonal frequencies , the cross - talk between the different data streams can be significant , since there are no naturally occurring orthogonal modes due to the randomness of the medium . @xcite first developed an algorithm in the context of wireless communications for multiple antennas at the transmitter and receiver that could compensate this additional interference and promise unprecedented increases in data throughput .",
    "the acronym used for this system in the engineering community is `` mimo '' , signifying multiple input and multiple output data streams .",
    "since it was first proposed , the technology has matured enough , at least in the context of wireless communications , so that current projections of what the next generation wireless systems will likely be envision massive ( in terms of their number ) antenna arrays transmitting parallel streams of data to many users nearby ( hence called massive mimo ) @xcite .",
    "not surprisingly , similar projections are made for the case of fiber - optical communications , where fibers with multiple cores have been proposed @xcite .",
    "it is therefore important to analyze the performance of such mimo systems in the environments they are envisioned to operate .",
    "one very useful tool in this direction has been random matrix theory , with the help of which both exact and asymptotic expressions for various quantities of interest have been derived . after all in several of the occurring problems , such as massive mimo mentioned above , the asymptotic limit usually taken in random matrix theory is actually realistic .",
    "therefore , such results are useful for performance prediction and network design , but also to provide intuition to system engineers on the way the network operates .",
    "this is so , because the obtained results show which system parameters are relevant , and which not . as a result ,",
    "research in this field can be rewarding both for its scientific rigor but also for the direct applicability of its results .",
    "the aim of these lectures is to introduce the physics community to a number of relevant problems in communications research and the types of solutions that have been used to tackle them . in the process",
    ", interested readers may be able to further acquaint themselves with research in engineering bibliography cited herein .",
    "after a brief introduction to basic metrics and quantities of interest in section [ sec : itbasics ] , section [ sec : wirelesscomms ] describes the solution to two problems in the context of wireless communications .",
    "more specifically , in section [ sec : capacitycorrelatedantennas ] the statistics of information capacity in wireless mimo systems are analyzed , while section [ sec : mobility ] deals with the effects of macroscopic mobility of users .",
    "section [ sec : opticalcomms ] provides two different ways to calculate the statistics of the mutual information in fiber - optical communications , all using various methods of random matrix theory .",
    "generalizations , similar problems , shortcomings and open problems are also mentioned in the text .",
    "in this section we introduce a few metrics that are relevant in information transmission , and will be used in further sections .",
    "a key quantity in information theory is the mutual information between an input random variable @xmath0 and an output random variable @xmath1 and is defined as @xmath2\\ ] ] where the probability distribution @xmath3 describes the type of noise the input @xmath0 is subjected to , in order to produce the output @xmath1 .",
    "the maximum of this quantity with respect to the input distribution @xmath4 , subject to certain constraints , such as maximum transmitted power , is called information capacity and represents the maximum number of nats ( which are bits in the neperian basis ) that can be transmitted error - free per channel use . for a simple additive gaussian - noise channel of the form @xmath5 where @xmath6 is the noise , and",
    "@xmath7 is the signal to noise ratio , the mutual information is maximized with a gaussian input of unit variance @xmath8 . in this case",
    "the capacity can be expressed as @xcite @xmath9    the above analysis can be generalized in the case of @xmath10 transmit and receive antennas with an average power constraint imposed at the transmitter .",
    "the corresponding channel equation can be expressed as @xmath11 where now @xmath12 is the matrix of channel coefficients between the transmit and receive antennas and @xmath13 and @xmath14 are the @xmath10 dimensional output signal and noise vector respectively , with the latter assumed to be independent and complex gaussian with unit variance . in this case as well , the optimum input distribution is complex gaussian .",
    "if @xmath15 is known at the transmitter the input covariance matrix @xmath16 $ ] can be optimized to take advantage of this knowledge .",
    "however , for simplicity , here we assume that this information is not available at the receiver , in which case the covariance is unity , i.e. @xmath16={\\bf i}_n$ ] .",
    "when the channel is known at the receiver then the information capacity ( in nats ) is @xmath17 note that for convenience , we have absorbed a factor of @xmath18 in the definition of @xmath15 .",
    "this expression is also valid for channels where the transmitter has @xmath19 antennas available and the receiver has @xmath20 antennas , i.e. when @xmath15 is @xmath21 . in this case",
    ", we need to replace @xmath22 by @xmath23 .",
    "the capacity represents the maximum rate that can be transmitted error - free for a given channel matrix @xmath15 .",
    "since the channel matrix is randomly distributed the capacity itself is a random quantity .",
    "its average @xmath24 $ ] provides an estimate of what kind of throughput rate one should expect on average .",
    "however , since @xmath15 varies ( albeit slowly ) over time , the instantaneous rate must be fed back to the transmitter to encode the data accordingly .",
    "if this is not possible , there is always a finite probability that @xmath15 will change in such a way that the encoded rate is not supported in the transmission and errors will occur . in this case",
    "the outage capacity is relevant , which is defined as the value @xmath25 of the cumulative distribution of @xmath26 above for which the probability that @xmath27 is @xmath28 , i.e. @xmath29 therefore , the full distribution of @xmath26 is important to characterize the transmission performance .      in the previous subsection we described the performance of a system of transmit and",
    "receive antenna arrays , assuming that the received signal from the antennas can be jointly processed .",
    "often however the receive antennas are not collocated as they correspond to different mobile users communicating with a multi - antenna base - station .",
    "this is the typical situation in a so - called massive mimo system . in this case",
    "the information capacity of each user takes the form of with @xmath7 substituted by an appropriately defined signal - to - ratio .",
    "however , in this case there is significant interference between users .",
    "one way to counter this is to pre - multiply the signal vector at the transmitter with an appropriately chosen matrix @xmath30 . due to the linearity of matrix multiplication",
    ", this approach is called linear precoding . as a result , the received signal at user @xmath31 can be expressed as @xmath32 where @xmath33 is the @xmath34th row of the matrix @xmath15 .",
    "clearly , this only makes sense if the transmitter has some information about the @xmath15 .",
    "there are several forms of precoding matrices , one of which is the so - called `` zero - forcing '' precoding matrix , which amounts to the pseudo - inverse of @xmath15 , i.e. @xmath35 where @xmath36 is a diagonal matrix with elements the designated receive powers of each user @xmath37 .",
    "clearly , this matrix exists only if @xmath38 .",
    "the benefit of using this precoding matrix is that the signal at each receiver is completely decoupled . indeed plugging into results to the trivial @xmath39 and",
    "therefore the signal - to - noise ratio requirements are immediately met if @xmath40 , where @xmath41 is the requested signal - to - noise ratio .",
    "the price for this is the increased transmitted power , which can be evaluated to be @xmath42\\ ] ] additional precoding techniques exist in the literature @xcite , which tend to trade between interference cancellation at the receiver end and power consumption or channel information at the transmitter .",
    "when more than one antennas exist in the receiver , similar techniques can be applied there as well . however , in all cases one is left with an object , such as in , which depends on the channel randomness .",
    "hence once again , random matrix theory can be of immediate help to get quantitative estimates .",
    "in this section we will provide two specific applications of random matrix theory in wireless communications .    before moving ahead , it is important to introduce the statistics of the propagation channel matrix @xmath15 . a good and reliable model for its elements",
    "@xmath43 is that they are complex gaussian random variables due to multiple scattering .",
    "the correlations of the matrix elements can be evaluated in the diffusion approximation to be @xcite @xmath44 = \\frac{\\rho } { n_t } r_{ij } t_{\\alpha\\beta}\\ ] ] in the above equation , @xmath45 and @xmath46 are the elements of the correlation matrices between the antennas at the receiver and transmitter arrays , respectively .",
    "@xmath45 can be expressed as @xcite @xmath47 where @xmath48 is the response of the antenna @xmath49 at incoming wavevector @xmath50 , @xmath51 the vector between antennas @xmath49 and @xmath52 and @xmath53 the weight of incoming power with a similar expression for @xmath46 ( without the @xmath54-term ) .",
    "thus antennas are more decorrelated the further apart compared to the wavelength they are and the more evenly over angles the incoming ( or relevant outgoing ) power is spread . also , @xmath54 is the average power loss due to propagation and @xmath55 is the distance between receiver and transmitter array .",
    "a typical model for @xmath56 is @xmath57 , where the pathloss exponent is usually taken to be @xmath58 @xcite .",
    "also , we have included the factor @xmath59 here that was absorbed into @xmath15 earlier .      in his section",
    "we introduce a method based on replicas to obtain the asymptotic moments of the capacity distribution in the large antenna limit assuming the above discussed channel model .",
    "this methodology was first developed by @xcite and extended in @xcite . while not rigorous it provides results in a few number of steps , which took a while to be established rigorously @xcite .",
    "the starting point is the moment generating function @xmath60 = e\\left[\\det\\left({\\bf i}_{n_r } + \\rho { \\bf g g}^\\dagger\\right)^{-\\mu}\\right]\\ ] ] the key trick in the calculation is to express the determinant above as a gaussian complex integral , so that the matrices @xmath15 will appear in the exponent and can then averaged over .",
    "after some algebra we obtain @xmath61 } \\\\",
    "\\nonumber    & \\times e\\left[e^{-\\frac{\\sqrt{\\rho}}{2}\\mbox{tr}\\left[{\\bf x}^\\dagger{\\bf g}{\\bf y } - { \\bf y}^\\dagger{\\bf g}^\\dagger{\\bf x}\\right ] } \\right]\\end{aligned}\\ ] ] where @xmath62 and @xmath63 are @xmath64 and @xmath65 dimensional complex matrices with the appropriate integration measure @xmath66 and @xmath67 , respectively . after averaging over @xmath15",
    ", we obtain : @xmath68}\\ ] ] the quartic term in the exponent can not be integrated as such .",
    "however , in the large @xmath19 limit we can treat it in a mean - field way .",
    "we now introduce the @xmath69 matrices @xmath70 and @xmath71 through the following identity @xmath72}\\end{aligned}\\ ] ] where the @xmath73-function appearing above is shorthand for a product of @xmath73-functions on all real and imaginary parts of the elements of the matrix @xmath74 .",
    "the integration of the elements of @xmath74 is over the real axis , while that for the elements of @xmath75 are over the imaginary axis , in agreement with fourier integration .",
    "we then insert this identity into getting @xmath76 } \\iint d{\\bf x}d{\\bf y } \\\\",
    "\\nonumber      & & \\times e^{-\\frac{1}{2}\\mbox{tr}\\left[{\\bf x}^\\dagger{\\bf x } + { \\bf y}^\\dagger{\\bf y } + \\frac{\\rho}{\\sqrt{n_t}}{\\bf x}^\\dagger{\\bf r}{\\bf x}{\\mathcal r } + \\frac{1}{\\sqrt{n_t}}{\\bf y}^\\dagger{\\bf t}{\\bf y}{\\mathcal t}\\right]}\\end{aligned}\\ ] ] which , after integrating over @xmath62 , @xmath63 reduces to @xmath77 \\\\",
    "\\nonumber    & + & \\log\\det\\left[{\\bf i}_{n_r}\\otimes{\\bf i}_{\\mu } + \\frac{\\rho}{\\sqrt{n_t } }   { \\bf r}\\otimes{\\mathcal r } \\right ] - \\mbox{tr}\\left[{\\mathcal tr}\\right]\\end{aligned}\\ ] ] the remaining integrals over the elements of the matrices @xmath74 , @xmath75 will be performed using the saddle - point method .",
    "to do so , we need to `` guess '' the structure of these matrices at the saddle point . in the usual replica literature ,",
    "the dynamic degrees of freedom ( e.g. spin variables ) take discrete values .",
    "hence the corresponding correlation matrices at the replica symmetric saddle - point need to be symmetric over permutations over the replica indices .",
    "in contrast , here the dynamic variables , i.e. @xmath62 , @xmath63 are continuous and thus have @xmath78 rotational symmetry in replica space .",
    "therefore , at the replica - symmetric saddle - point , @xmath74 and @xmath75 need to be scalars , which we express them as @xmath79 plugging these expressions into we get to leading order @xmath80 where @xmath81 \\right.\\\\ \\nonumber    & + & \\left.\\log\\det\\left[{\\bf i}_{n_r } + \\rho   r { \\bf r}\\right ] - n_t rt\\right )   \\label{eq : g(mu)_wireless_mimo6}\\end{aligned}\\ ] ] with @xmath82 satisfying the saddle - point equations @xmath83   \\\\",
    "\\nonumber    t & = & \\frac{1}{n_t } \\mbox{tr}\\left[\\frac{\\rho { \\bf r}}{{\\bf i}_{n_r } + \\rho r{\\bf r}}\\right]\\end{aligned}\\ ] ] since @xmath84 $ ] , we immediately see , that to leading order in @xmath19 , @xmath85=\\gamma_0 $ ] .    to obtain higher moments of the distribution , we need to expand @xmath86 in powers of @xmath87 and @xmath88 .",
    "at the saddle point , the linear terms vanish , hence the leading term is the quadratic one , @xmath89    \\left (      \\begin{array}{cc }        r_2 & 1 \\\\        1 & t_2 \\\\",
    "\\end{array }    \\right )    \\left [    \\begin{array}{c }      \\delta { \\mathcal r}_{\\nu\\mu } \\\\      \\delta { \\mathcal t}_{\\nu\\mu }",
    "\\end{array }    \\right ] \\\\",
    "\\nonumber     & + & { \\mathcal o}\\left(\\delta { \\mathcal r}^3,\\delta { \\mathcal t}^3\\right)\\end{aligned}\\ ] ] where @xmath90   \\\\ \\nonumber    t_2 & = & \\frac{1}{n_t } \\mbox{tr}\\left[\\frac{\\rho^2 { \\bf r}^2}{\\left({\\bf i}_{n_r } + \\rho r{\\bf r}\\right)^2}\\right]\\end{aligned}\\ ] ] integrating over the quadratic term in the exponent by appropriately rotating the contour of integration close to the saddle point , we obtain @xmath91 as a result , the variance of the mutual information takes the following simple form @xmath92 it is worth contrasting this result with the standard central limit theorem for the sum of @xmath10 random variables , in which the mean and the variance of the sum is @xmath93 . here",
    "the mean is @xmath93 , while the variance is @xmath94 .",
    "the underlying reason of these vastly reduced fluctuations can be understood by the fact that the underlying @xmath93 random degrees of freedom , i.e the eigenvalues of the matrix @xmath95 are highly correlated and ( as we shall see in section [ sec : tails ] ) they are constrained to be located very closely in eigenvalue space .",
    "if we continue the perturbation expansion by including cubic and quartic terms in @xmath96 , we obtain a @xmath97 correction term to @xmath85 $ ] and a skewness of the same order @xcite .",
    "in fact , it can be established that all higher moments vanish when @xmath98 , thereby making the distribution asymptotically gaussian .",
    "interestingly , it can also be shown that the replica - symmetric saddle - point is stable @xcite .",
    "one reason these results are quite useful is that they are applicable not only for the case of very large antenna numbers , but also for just a few antennas .",
    "this can be seen explicitly in fig .",
    "[ fig : cdf_wmimo ] , where the agreement with simulations is remarkable even for @xmath99 . in conclusion , we have seen a first example , where random matrix theory can provide useful results in wireless communications .     antennas . in one set of curves",
    "have uncorrelated antennas , while the transmitter antennas of the other are @xmath100 apart with a @xmath101 angle - spread .",
    "two different values of @xmath7 are used .",
    "the theoretical curves are gaussian distributions , with mean and variance calculated as above .",
    "the agreement with the simulated curves is quite good . ]      in addition to traffic growth , another related big challenge is the increasing energy consumption of cellular infrastructure equipment . as a result , energy consumption has to be a key ingredient in the design of future cellular networks , especially in new rural regions of the developing world , where the electrical grid is unreliable or even non - existing . in this section",
    "we will analyse the distribution of energy consumption for a particular case of linear precoding discussed in section [ sec : itbasics ] when we take the mobility of users into account . once again",
    ", the large system size will simplify the analysis considerably .",
    "we consider a base - station ( bs ) with @xmath19 antennas serving @xmath20 mobile single antenna users with @xmath102 , in a square region centered at the bs with side length @xmath103 . here",
    "we focus in the downlink case , where the bs acts as a transmitter . in order to guarantee a certain signal to noise ratio @xmath41 to user @xmath34 ,",
    "the transmitting array precodes the signal using the zero - forcing precoding matrix appearing in . as a result",
    ", the total transmitted power is given by .",
    "this power is time - dependent due to the movement of the users through the temporal variation of the channel coefficients .",
    "this in turn has two components .",
    "one originates form the relatively slow variation of the pathloss due to the macroscopic movement of the users .",
    "the characteristic time for this is @xmath104 , where @xmath105 is the typical velocity of the users .",
    "there is another much faster variation of @xmath15 due to multiple ( or rayleigh ) scattering . in the engineering literature",
    ", these fluctuations are called `` fast - fading '' .",
    "the timescale here is much shorter , @xmath106 .",
    "the analysis below will distinguish between these two processes .    for concreteness",
    ", we employ a simple mobility model for users , namely that of a brownian motion , which is the continuous version of a simple random walk .",
    "hence , @xmath107 , the probability of a user to be at position @xmath108 at time @xmath109 given that he was at @xmath110 at time @xmath111 satisfies the diffusion equation @xmath112 where the diffusion constant @xmath113 characterizes the small scale mobility of the user .",
    "further , we assume periodic boundary conditions at the borders of the square to mimic the existence of other users in neighboring cells entering the current cell .",
    "the total energy consumed by the base - station over time @xmath114 is given by @xmath115 the aim of this section is to calculate the statistics of this quantity .",
    "we start by averaging the power @xmath116 over fast - fading keeping the positions of the users ( roughly ) fixed .",
    "this step can be done by using the results of the previous section .",
    "starting from we redefine the channel matrix @xmath117 hence redefining the receiver correlation matrix @xmath118 .",
    "then we observe that the expression in can obtained from by taking the @xmath119 limit .",
    "more concretely , @xmath120\\right]\\right)\\ ] ] plugging in into the above equation ( and re - introducing the matrix @xmath36 ) gives @xmath121 \\nonumber \\\\     & = &   \\frac{1}{n_t r } \\mbox{tr}\\left[{\\bf r}^{-1}{\\bf p}\\right ] \\nonumber \\\\     & = &   \\frac{\\sigma^2}{n_t r } \\sum_{k=1}^{n_r } \\frac{\\rho_k}{\\ell({\\bf x}_k(t))}\\end{aligned}\\ ] ] the last line results from the fact that since the receive antennas are so far apart , they are uncorrelated , i.e. @xmath122 .",
    "@xmath123 can be found in this limit to be the solution of @xmath124 where @xmath125 are the eigenvalues of the bs antenna correlation matrix @xmath126 .",
    "we see that when the transmitter antennas are uncorrelated @xmath127 .",
    "now , @xmath128 is time dependent only due to the macroscopic movement of the mobile users @xmath129 . averaging over their movements as well ,",
    "we obtain @xmath130 \\frac{1}{n_r}\\sum_{k=1}^{n_r } \\rho_k\\end{aligned}\\ ] ] since the long - time spatial distribution of the brownian motion is uniform the expectation above is over the whole square . as a result , @xmath131 \\frac{1}{n_r}\\sum_{k=1}^{n_r } \\rho_k\\end{aligned}\\ ] ]    to calculate the fluctuations of the consumed energy at the transmitter , we separate them in two parts according to their corresponding time - scales as discussed above .",
    "hence @xmath132 the first part has fluctuations due to fast - fading , while the second due to user mobility .",
    "it can be observed from the relation with the previous section that the fluctuations of the first part scale as @xmath133 .",
    "this has been rigorously established in @xcite .",
    "hence since the decorrelation time is @xmath134 we conclude that the variance of the energy due to fast - fading will be @xmath135 .",
    "in contrast , as we shall see , the fluctuations of @xmath136 are of order @xmath137 .",
    "this is so because @xmath128 , see , has @xmath20 independent degrees of freedom ( the positions of the @xmath20 mobiles users ) . since the decorrelation time of the brownian motion is @xmath138 , the variance of this energy term will be of the order @xmath139 .",
    "indeed , we can express the variance of the energy as @xmath140 which , after expressing the diffusion probabilities in terms of the eigenfunctions of the diffusion equation @xmath141 with eigenvalues @xmath142 , where @xmath143 , we obtain @xmath144 since @xmath145 falls off fast with increasing @xmath146 , the summation in the above equation converges fast and only a few terms are necessary to evaluate it .",
    "all higher moments of the energy can be easily shown to vanish faster in the large @xmath20 limit .",
    "hence , the energy consumption becomes a gaussian variable with mean and variance calculated above .",
    "this model can be used to approximate the probability that a battery - powered bs runs out of energy and also to design the cell radius for minimizing the energy consumption per unit area @xcite .      in this section",
    "we briefly discuss various generalizations of the above results .",
    "the results presented in with section [ sec : capacitycorrelatedantennas ] have been generalized to the calculation of the statistics of the capacity in cases where the channel matrix is not gaussian .",
    "it turns out that only the second moment of the distribution is relevant @xcite , at least for the mean capacity .",
    "also , the methodology can be applied to situations where the interference itself is a random matrix . in this case",
    ", the interference channel appears in two logariths , which have different sign .",
    "in such a case , one needs to rely on supersymmetric methods , introducing integrals over grassman variables @xcite .",
    "this results have still not been proved with more rigorous methods .",
    "another generalization deals with the case , where the input distribution is binary rather than gaussian @xcite , in which case the replica approach is perhaps the only one that can provide an answer .",
    "the random matrix analysis of the behavior of precoders as in section [ sec : mobility ] is currently an active topic of research , due their possible application in next - generation communications , see for example @xcite .",
    "also , since precoders usually involve matrix inversions , a series of works has analyzed the robust representation of precoders in terms of matrix polynomials @xcite .",
    "finally , note that precoders do nt necessarily need to be linear , and optimization over the nonlinear precoders has also been analyzed using replicas and random matrix theory @xcite .",
    "one way to increase the data throughput though optical fibers is to use more channels in each fiber . at a first level one can use more than one electromagnetic mode through existing fibers @xcite . at a later stage ,",
    "engineers envision a new generation of optical fibers , specially designed with multiple cores in each of them @xcite . due to twisting , bending as well as non - linear coupling , these propagation channels mix strongly , especially when the fiber length extends over long distances .",
    "in contrast , backscattering can be assumed to be negligible .",
    "another important difference from free space propagation in wireless communications is that fiber optical transmission is characterized by low loss .",
    "hence the appropriate metric to describe the propagation is the transmission coefficients of the scattering matrix , since there is no reflection .",
    "although the total scattering matrix should be symmetric @xmath147 due to time reversal symmetry @xcite , the transmission matrix @xmath148 itself does not have any other symmetries or constraints , apart from the normalization condition @xmath149 , which is a direct consequence of the unitarity of @xmath150 .",
    "therefore , in the strong mixing limit , we may neglect any bias between the various modes or cores or inhomogeneity in the mixing and assume that @xmath151 is haar random .",
    "it is convenient to define the channel matrix as @xmath152 , where @xmath153 and @xmath154 are the correlations matrices of the transmitted and received signal , respectively .",
    "for example , in the optical fiber case they correspond to reflections and losses at the two edges of the link .    as a result ,",
    "the corresponding mimo channel for this system reads @xmath155 with coherent detection and channel state information only at the receiver @xcite .",
    "@xmath156 , @xmath13 and @xmath14 are the @xmath10-dimensional input , output signal vectors and unit variance noise vector , respectively , all assumed for simplicity to be complex gaussian .",
    "we also assume no differential delays between channels , which effectively leads to frequency flat fading @xcite and no mode - dependent loss . as a result , the mutual information ( in nats ) can be expressed as @xmath157    as in the case of wireless communications , the above expression can be generalized to cases , where the number of active transmitters is @xmath158 and correspondingly the number of receiving elements is @xmath159 .",
    "this can be done by making the matrices @xmath126 and @xmath160 be of rank @xmath19 and @xmath20 respectively .",
    "this may correspond to the situation , where not all transmitting or receiving channels may be available to a given link .      in this section we will calculate in closed form the moment generating function of the mutual information @xmath161\\ ] ] where the expectation is over the channel matrix @xmath12 . to make progress , one could expand the quantity inside the expectation in in terms of products of the matrices @xmath148 and @xmath162 and then average the resulting products over the unitary group .",
    "these averages are however quite complicated and in most cases can only be treated in an asymptotic fashion @xcite .",
    "instead here we employ a different approach first introduced by balantekin @xcite . here",
    ", the expansion is performed using characters of the irreducible representations of the unitary group @xmath163 , the unitary matrices of size @xmath10 . for completeness",
    "we summarize below some basic facts on representation theory of groups .",
    "the interested reader can refer to several textbooks , including @xcite .",
    "a unitary representation @xmath164 of a group @xmath165 is a homomorphism from @xmath165 to @xmath163 .",
    "an irreducible representation has no non - trivial invariant subspaces .",
    "the irreducible representations of the unitary group @xmath163 @xcite can be parameterized by an @xmath10-dimensional vector @xmath166 , with integers @xmath167 .",
    "the dimension @xmath168 of an irreducible representation is the dimension of its invariant subspace . for the case of",
    "@xmath163 it can be shown @xcite that @xmath168 is given by @xmath169 \\left(-1\\right)^{\\frac{n(n-1)}{2 } }    \\delta({\\bf k})\\ ] ] where @xmath170 represents the vandermonde determinant , defined as @xmath171 and the vector @xmath50 has elements @xmath172 where @xmath173 and @xmath174 are the elements of the representation vector @xmath175 .",
    "now , the character @xmath176 of a group element @xmath177 in the representation @xmath164 is equal to the trace of the corresponding matrix , i.e. @xmath178 $ ] .",
    "thus a character of a reducible representation can be written as a sum of characters of irreducible representations .",
    "clearly , @xmath176 depends only on the eigenvalues of @xmath179 . calculating the characters of irreducible representations",
    "is greatly facilitated by weyl s character formula @xcite@xcite , which for @xmath163 takes the form : @xmath180 where the index @xmath175 denotes the irreducible representation @xmath181 and @xmath182 , for @xmath173 , are the eigenvalues of @xmath183 in the fundamental ( @xmath10-dimensional ) representation .",
    "for example , the characters of the one - dimensional unitary group @xmath184 are given by @xmath185 , where the character index @xmath186 takes values @xmath187 and @xmath188 is the ( eigen)value of an arbitrary one - dimensional matrix in @xmath184 .",
    "thus a fourier expansion can be seen as an expansion in the characters of @xmath184 group .",
    "this suggests that the characters of a group can form a good basis of expanding functions , which are invariant under @xmath163 group operations .",
    "@xcite showed that the product of any function @xmath189 of the eigenvalues @xmath190 of an invertible matrix @xmath183 can be expressed in the following form @xmath191 in the above expression , @xmath192 is the character of @xmath193 in the representation @xmath175 and the sum is over all irreducible representations of @xmath163 parameterized with the vector @xmath166 , with integers @xmath167 . in the coefficient for each character ,",
    "@xmath194 is given by @xmath195 where @xmath196 is the coefficient of the taylor expansion of @xmath189 , i.e. @xmath197 in the particular case of @xmath198 and @xmath199 so that @xmath200 note that , as expected , for integer @xmath201 , @xmath196 vanishes for @xmath202 . as a result , we have @xmath203\\ ] ] the expectation of the character @xmath204 $ ] , where @xmath205 etc .",
    ", is the group element of @xmath148 in the representation @xmath175 , can be obtained using the following identity @xcite @xmath206 where @xmath207 is the standard haar integration measure and @xmath168 is the dimension of the representation given above . as a result",
    "we have @xmath208 the above expression can become more transparent by using the characters of @xmath153 and @xmath154 through the weyl character formula so that @xmath209 where @xmath210 and @xmath211 are the eigenvalues of the matrices @xmath154 and @xmath153 , respectively .",
    "we now need to massage the expression of @xmath194 . to do so we start by expressing it in the following form @xmath212\\end{aligned}\\ ] ] where the indices @xmath50 and @xmath175 are related through .",
    "we observe that the @xmath213 element of the matrix inside the square brackets above is a @xmath214-degree polynomial of @xmath215 , indexed by the row @xmath216 , expressed for compactness as @xmath217 . by performing linear operations on the columns of the matrix",
    "we can express the determinant of the matrix as @xmath218 , up to an overall multiplicative factor @xmath219 , independent of @xmath215 , which may be obtained by various ways , and will be discussed at the end .",
    "the key point of this calculation is that @xmath194 is proportional to @xmath218 , which can then cancel the same factor appearing in @xmath168 .",
    "thus , we have @xmath220 where we have absorbed all constant factors in @xmath221 .",
    "the final step consists of using the cauchy - binet formula to sum over the indices @xmath215 and obtain @xmath222}{\\delta({\\bf r})\\delta({\\bf t})}\\ ] ] to obtain the constant @xmath221 , we may take the limit of @xmath223 , successively for @xmath216 . since both numerator and denominator vanish",
    "when we do this , we need to carefully apply the lhospital rule at each step @xcite . after some algebra",
    "we find @xmath224    from the above expression , one can readily obtain the probability distribution of the mutual information @xmath225 , by fourier transformation , i.e. @xmath226 in addition , the moments of the distribution can be evaluated by taking the appropriate derivatives with respect to @xmath201 .",
    "for example , @xmath24=g'(0)$ ] , @xmath227 , etc .",
    "for @xmath228 , one obtains @xmath229   =   -1 \\\\",
    "\\nonumber    & + \\frac{\\left(\\log(1+\\rho a_1 b_1)+\\log(1+\\rho a_2 b_2)\\right)(1+\\rho a_1 b_1)(1+\\rho a_2 b_2)}{\\rho(a_1-a_2)(b_1-b_2 ) } \\\\",
    "\\nonumber    & - \\frac{\\left(\\log(1+\\rho a_1 b_2)+\\log(1+\\rho a_2 b_1)\\right)(1+\\rho a_1 b_2)(1+\\rho a_2 b_1)}{\\rho(a_1-a_2)(b_1-b_2 ) } \\end{aligned}\\ ] ] clearly , these expressions become unappealing for larger @xmath10 and for higher moments due to the determinantal structure of @xmath230 . in the next section",
    ", we will show how the distribution of the mutual information can be evaluated asymptotically for large @xmath10 for a special form of the matrices @xmath153 and @xmath154 .",
    "a similar expression has been derived for correlated gaussian channels @xcite .",
    "the previous section dealt with the exact calculation of the moment generating function of the mutual information .",
    "however , in real communications systems a more important metric is the probability distribution of the mutual information itself and in particular its tails , which quantify the probability of error in decoding a packet that has been sent with too high a coding rate .",
    "this is particularly true in fiber - optical communications , where very low error rates are desirable , since no feedback is available to allow the transmitter to retransmit the packet , as is the case in wireless communications .",
    "in this section we will calculate the distribution of the mutual information of the optical mimo channel in the large channel number @xmath10 regime . by large @xmath10",
    ", we will signify that all @xmath231 go to infinity , but with fixed ratios . to be able to do this calculation , the correlation matrices at the receiver and transmitter",
    "will be take to have a simplified structure , namely @xmath232 and @xmath233 where @xmath234 is the @xmath235 projection matrix on an @xmath186-dimensional subspace .",
    "this simplification corresponds to idealized receiver and transmitter structures , with @xmath19 transmitter channels , @xmath20 receiver channels and several untapped channels , which may used by other transceivers or simply correspond to energy loss @xcite . since the exact nature of the subspaces will be irrelevant due to rotational symmetry , we take the matrices to be of the form @xmath236)$ ] , where the diagonal has @xmath186 ones and @xmath237 zeroes . in this case the joint probability distribution of the eigenvalues of the matrix @xmath238",
    "has been shown to be @xcite for @xmath239 and @xmath240 @xmath241 while the remaining @xmath242 eigenvalues are zero , while for @xmath243 @xcite there are @xmath244 eigenvalues equal to unity , @xmath242 zero eigenvalues , while the remaining eigenvalues have the following density @xmath245 the situation @xmath246 can be obtained directly from the above by interchanging @xmath247 . for simplicity",
    ", we will now assume that @xmath248 and @xmath240 .",
    "now , based on the above expressions , we can readily apply the methodology of the previous section to obtain the moment generating function of the mutual information , which can be expressed directly as @xmath249 however , given the explicit expression of the probability distribution of the eigenvalues , more can be accomplished .",
    "we will follow closely the methodology by @xcite based on the analogy to a coulomb gas pioneered by @xcite .",
    "the key insight is that for large @xmath10 the eigenvalues coalesce to a fluid that can be described as a density given by @xmath250 we start by conjecturing that the support of @xmath251 is compact with borders @xmath252 , which we will check in the end to be the case .",
    "hence the logarithm of the distribution function in can be expressed as @xmath253 where @xmath254 and @xmath255 .    to evaluate the probability density of @xmath225 we express first in the form @xmath256 \\nonumber \\\\ & = & n_r",
    "\\int \\frac{dk}{2\\pi i } e\\left[e^{n_r^2 k\\left(r-\\int n(x)\\log(1+\\rho x)\\right)}\\right ] \\label{eq : p(r)}\\end{aligned}\\ ] ] to ensure the density @xmath251 is properly normalized to unity , it is convenient to add another constraint in the form of a fourier integral as above . as a result , we obtain @xmath257 } \\right]\\end{aligned}\\ ] ] where the expectation is over all positive functions @xmath251 and the corresponding constraint integrals mentioned above , and @xmath258 & = & -\\int n(x ) \\left(\\beta \\log(1-x)+\\alpha \\log(x)\\right ) d x \\nonumber \\\\   & - & \\iint n(x)n(y)\\log{|x - y|}dy dx \\nonumber \\\\   & - & k\\left(\\int n(x)\\log(1+\\rho x)dx -r\\right ) \\nonumber \\\\   & - & c\\left(\\int n(x ) dx -1\\right ) \\label{eq : s[n]}\\end{aligned}\\ ] ] in the large @xmath10 limit , the path - integral is dominated by the contribution around its saddle - point(s ) of @xmath259 $ ] .",
    "convexity arguments for @xmath259 $ ] can assure that any solution will be unique @xcite .",
    "taking the functional derivative on @xmath259 $ ] with respect to @xmath251 and setting the result to zero we obtain @xmath260 it is convenient to differentiate this expression with respect to @xmath261 , which gives @xmath262 where @xmath263 indicates the cauchy principal value of the integral .",
    "the above equation has an appealing physical meaning , namely the balance of forces between the inter - eigenvalue ( intercharge ) repulsions and the forces imposed by external ( one - body ) potentials .",
    "hence , the solution to this equation will provide the equilibrium ( or most probable ) density of eigenvalues consistent with rate @xmath123 .",
    "since both @xmath264 , we expect an infinite force acting the charge density if either @xmath265 or @xmath266",
    ". therefore , neither of this can be the case .",
    "thankfully , this integral equation can be solved ( see @xcite ) with a general solution of the form @xmath267 where @xmath268 is a constant .",
    "assuming continuity at the boundary of the support , i.e. @xmath269 we obtain @xmath270 with the additional constraint @xmath271 the parameters @xmath272 can be evaluated uniquely from the above equation , in addition to the normalization constraint @xmath273 which demands that @xmath274 and the rate constraint @xmath275 \\\\ \\nonumber & + & \\frac{\\alpha}{2\\sqrt{{\\bar a } { \\bar b}}}\\bigg[g\\left({\\bar a}_z,{\\bar a}\\right)-g\\left({\\bar a}_z,{\\bar a}_z\\right)\\bigg]\\end{aligned}\\ ] ] where @xmath276 , @xmath277 . in the above equation ,",
    "we have defined @xmath278 , @xmath279 , @xmath280 , @xmath281 and @xmath282 , @xmath283 , @xmath284 .",
    "the function @xmath285 is given by @xcite @xmath286\\nonumber\\\\ & + & ( 1 + 2 y)\\log\\left[\\frac{\\sqrt{1+x}+\\sqrt{x}}{2}\\right ] -\\frac{1}{2}\\left(\\sqrt{1+x}-\\sqrt{x}\\right)^{2}\\nonumber\\end{aligned}\\ ] ] the probability density in represents the most probable distribution of eigenvalues in the subspace where @xmath287 .",
    "we may now plug in the above expression of @xmath288 into and obtain an expression for @xmath289 as follows @xmath290 as a result , we have for large @xmath10 @xmath291 to find the normalization constant , we may just divide the above expression in the absence of any constraints on @xmath251 in , which corresponds to @xmath292 . in this case , the constraint for the mutual information is relaxed and the corresponding expression in corresponds to the most probable distribution of eigenvalues in . after some work it is easy to see that the density of eigenvalues takes a similar form to the marcenko - pastur equation @xmath293 where @xmath294 which has been obtained using other methods in @xcite .",
    "the corresponding value of @xmath295 can obtained directly by using this expression to evaluate @xmath86 above . analyzing the behavior of @xmath296 close to the value of @xmath297",
    "it can be shown that @xmath298 where @xmath299 is the rate obtained using @xmath300 in , which corresponds to the average ( ergodic ) value of the rate in the large @xmath10 limit and @xmath301 where @xmath302 , @xmath303 are given in .",
    "since the bulk of the probability distribution will be around the value @xmath304 , the normalization is to leading order identical to a gaussian distribution centered at @xmath299 with variance @xmath305 .",
    "hence , @xmath306    a few remarks are in order for the calculations performed above .",
    "first , although the large @xmath10 limit was taken here , the results are valid also for reasonably valued @xmath19 , @xmath20 etc . indeed , in fig .",
    "[ fig : pout_optical ] the cumulative probability density is plotted as a function of @xmath7 for a number of representative values of @xmath19 , @xmath20 . as we see",
    "the agreement between monte - carlo simulations and this approach is pretty good .    .",
    "the agreement with monte carlo simulations is quite good .",
    "the red circle represents the point where the minimum limit of the support of the optimum distribution becomes positive @xmath307 . ]",
    "furthermore , it should be noted that here we only analyzed the generic case , when @xmath264 . when @xmath308 , two possible solutions for the eigenvalue density @xmath288 may occur , depending on the value of @xmath123 .",
    "the first extends all the way to the border @xmath309 , with a square root singularity , while the second has a positive lower limit of its support , i.e. @xmath307 .",
    "however , for a given value of @xmath123 only one solution is acceptable , since the other becomes negative . at some critical value of the rate @xmath123",
    "there is a transition between these two solutions ( see fig .",
    "[ fig : pout_optical ] ) .",
    "interestingly , only the third derivative of @xmath310 is discontinuous at this point .",
    "similar behavior can be seen in the case when @xmath311 at the upper limit of the support of @xmath288 .",
    "this behavior has been observed in other situations @xcite and has been tied to the tracy - widom distribution .",
    "a similar analysis has been performed for complex gaussian channels @xcite .      in this section",
    "we briefly discuss limitations of the above results",
    ".    one possible criticism of the above analysis may be whether the expression of the mutual information used represents the true transmission rate for optical mimo channels .",
    "after all , this expression assumes a complex gaussian input signal , which at this point does not correspond to what is used in current optical communications systems .",
    "nevertheless , complex gaussian input is optimal when the noise is also gaussian , as it happens to be @xcite .",
    "in addition , current modulation techniques are currently not too far from the ones used in wireless communications systems and therefore the above results can be taken as a figure of merit for the optical channel",
    ".    other limitations of the above methodology have to do with the channel model used .",
    "for example , the fiber - optical channel has non - uniform mixing between different modes , as well as mode - dependent loss , in which the attenuation of each channel is different and in fact random @xcite .",
    "such details can in principle be included in the channel , within the current random matrix framework , by appropriately generalizing the statistics of the random matrix .",
    "another important limitation of this analysis is the omission of non - linearities , which are inherently present in fiber optical communications , especially for large distance light propagation . although some models have been applied in this context for single mode fibers @xcite , a coherent approach for the capacity of the non - linear optical mimo channel is currently missing .",
    "however , it is hoped that the large number of channels will provide a small parameter for meaning approximations in the problem .",
    "modern telecommunications systems and algorithms are becoming increasingly complex and there is a need for mathematical tools that can tackle this complexity .",
    "random matrix theory continues to be successful , not only in providing answers relevant in design and performance predictions , but also in providing intuition on the relevant issues .",
    "it is hoped that this introduction to the applicability of random matrix theory in communications and the description of how it can be used to tackle real problems will further inspire the cross - fertilization between these fields .",
    "it is worth mentioning that tools developed in spin - glasses have also seen many applications in communications , signal processing and optimization . nevertheless , both methodologies are essentially mean - field based .",
    "perhaps the `` last '' frontier for physics applications in telecommunications will be in the description of spatial and temporal fluctuations in 2-dimensional wireless networks , where mean - field approaches do not hold .",
    "47ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ]",
    " + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty link:\\doibase 10.1002/bltj.20400 [ * * ,   ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase 10.1109/mcom.2012.6146483 [ * * ,   ( ) ] @noop _ _ ( ,  ,  ) @noop * * , ( ) @noop * * ,   ( ) ,   @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) link:\\doibase    10.1109/mcom.2007.358849 [ * * ,   ( ) ] link:\\doibase 10.1364/oe.19.016680 [ * * , ( ) ] @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _  ( ,  ,  ) @noop * * ,   ( ) @noop _ _  ( ,  ,  ) @noop * * ,   ( ) @noop _ _  ( ,  ,  ) @noop * * ,   ( ) ,   @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _ ,  edited by  and  ,  , vol .",
    "( ,  ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop * * ,   ( ) @noop _ _ , pure appl .",
    "math v  ( ,  ,  ) @noop * * ,   ( ) @noop * * , ( ) @noop * * ,   ( ) @noop * * ,   ( )"
  ],
  "abstract_text": [
    "<S> this report summarizes some of the material that was presented by the author during the 2015 les houches summerschool on `` random matrices and stochastic processes '' . in these lectures , </S>",
    "<S> various applications of random matrix theory in modern telecommunications are reviewed . </S>",
    "<S> the aim is to introduce the physics community to a number of relevant problems that can be analyzed using such tools , while at the same time briefly describing the way these methods are applied . </S>",
    "<S> more specifically , two applications on wireless communications and two on optical communications are presented . </S>"
  ]
}