{
  "article_text": [
    "many distributed systems found in nature have inspired function - maximization algorithms . in some of these the coordinates of the underlying system are viewed as players engaged in a non - cooperative game , whose joint behavior ( hopefully ) maximizes the pre - specified global function of the entire system .",
    "examples of such systems are auctions and clearing of markets . typically in the computer - based algorithms inspired by such `` collectives '' of players ,",
    "each separate coordinate of the system is controlled by an associated machine learning algorithm @xcite , reinforcement - learning ( rl ) algorithms being particularly common  @xcite .    one important issue concerning such collectives",
    "is whether the payoff function @xmath1 of each player @xmath2 is sufficiently sensitive to what coordinates @xmath2 controls in comparison to the other coordinates , so that @xmath2 can learn how to control its coordinates to achieve high payoff .",
    "a second crucial issue is the need for all of the @xmath1 to be `` aligned '' with @xmath0 , so that as the players individually learn how to increase their payoffs , @xmath0 also increases .",
    "previous work in the collective intelligence ( coin ) framework addresses these issues .",
    "this work extends conventional game - theoretic mechanism design  @xcite to include off - equilibrium behavior , learnability issues , @xmath1 with non - human attributes ( e.g. , @xmath1 for which incentive compatibility is irrelevant ) , and arbitrary @xmath0 . in domains from network routing to congestion problems it outperform traditional techniques , by up to several orders of magnitude for large systems  @xcite .",
    "other collective systems found in nature that have inspired search algorithms do not involve players conducting a non - cooperative game .",
    "examples include spin glasses , genomes undergoing neo - darwinian natural selection , and eusocial insect colonies , which have been translated into simulated annealing ( sa  @xcite ) , genetic algorithms  @xcite , and swarm intelligence  @xcite , respectively .",
    "an important issue here is the exploration / exploitation dynamics of the overall collective .",
    "recent analysis reveals how @xmath0 is governed by the interaction between exploration / exploitation , the alignment of the @xmath1 and @xmath0 , and the learnability of the @xmath1  @xcite .",
    "here we use that analysis to motivate a hybrid algorithm , intelligent coordinates for search ( ic ) , that addresses all three issues .",
    "it works by modifying any exploration - based search algorithm so that each coordinate being searched is made `` intelligent '' , its exploration value being the move of a game - playing computer algorithm rather than the random sample of a probability distribution .    like sa",
    ", ic is intended to be used as an `` off the shelf '' algorithm ; rarely will it be the best possible algorithm for some particular domain .",
    "rather it is designed for use in very large problems where parallelization can provide a large advantage , while there is little exploitable information concerning gradients .",
    "we present experiments comparing ic and sa on two archetypal domains : bin - packing and an economic model of people choosing formats for their home music systems .    in the bin - packing domain",
    "ic achieves a given value of @xmath0 up to three orders of magnitude faster than does sa , with the improvement increasing linearly with the size of the problem . in the format choice problem",
    "@xmath0 is the sum of each person s `` happiness '' with her format choices .",
    "each person @xmath2 s happiness with each of her choices is set by three factors : which of her nearest neighbors on a ring network ( @xmath2 s `` friends '' ) make that choice ; @xmath2 s intrinsic preference for that choice ; and the price of music purchased in that format , inversely proportional to the total number of players using that choice . here again , ic improves @xmath0 two orders of magnitude more quickly than does sa .",
    "we also considered an algorithm similar to the groves mechanism of economics ; ic outperformed it by over two orders of magnitude .",
    "we also modified the ring to be a small - worlds network  @xcite .",
    "this barely improved ic s performance ( 3% ) , with no effect on the other algorithms . however if @xmath0 was also changed , so that each @xmath2 s happiness depends on agreeing with her friends friends , the performance increase in changing to a small - worlds topology is significant ( 10% ) .",
    "this underscores the multiplicity of factors behind the benefits of small - worlds networks .",
    "let @xmath3 be the joint move of all agents / players in the collective .",
    "we want the @xmath4 that maximizes the provided world utility @xmath5 .",
    "in addition to @xmath0 we have private utility functions \\{@xmath1 } , one for each agent @xmath2 controlling @xmath6 .",
    "@xmath7 refers to all agents other than @xmath2 .    * intelligence * `` standardizes '' utility functions so that the value they assign to @xmath4 only reflects their ranking of @xmath4 relative to some other @xmath8 .",
    "one form of it is @xmath9 \\ ; , \\end{aligned}\\ ] ]    where @xmath10 is the heaviside function , and where the subscript on the ( normalized ) measure @xmath11 indicates it is restricted to @xmath8 such that @xmath12 .",
    "our uncertainty concerning the system induces a distribution @xmath13 .",
    "all attributes of the collective we can set , e.g. , the private utility functions of the agents , are given by the value of the * design coordinate * @xmath14 .",
    "bayes theorem provides the * central equation * :    @xmath15    where @xmath16 and @xmath17 are the intelligence vectors for all the agents , for utilities @xmath1 and for @xmath0 , respectively .",
    "@xmath18 means that agent @xmath2 s move maximizes its utility , given the moves of the other agents .",
    "so @xmath19 means @xmath4 is a nash equilibrium .",
    "conversely , @xmath20 means that the value of @xmath0 can not increase in moving from @xmath8 along any single ( sic ) coordinate of @xmath21 .",
    "so if these two points are identical , then if the agents do well enough at maximizing their private utilities they must be near an ( on - axis ) maximizing point for @xmath0 .",
    "more formally , say for our @xmath14 the third conditional probability in the integrand in the central equation ( `` term 3 '' ) is peaked near @xmath22 .",
    "then @xmath14 probably induces large ( private utility function ) intelligences ( intuitively , the utilities are learnable ) .",
    "if in addition the second term is peaked near @xmath23 , then @xmath16 will also be large ( intuitively , the private utility is `` aligned with @xmath0 '' ) .",
    "this peakedness is assured if @xmath24 exactly @xmath25 .",
    "such a system is said to be * factored*. finally , if the first term in the integrand is peaked about high @xmath0 when @xmath16 is large , then @xmath14 probably induces high @xmath0 , as desired .",
    "as a trivial example , a * team game * , where @xmath26 , is factored  @xcite .",
    "however team games usually have poor third terms , especially in large collectives .",
    "this is because each @xmath2 has to discern how its moves affect @xmath27 , given the background of the ( varying ) moves of the other agents whose moves comparably affect @xmath0 .",
    "fix some @xmath28 , two moves @xmath29 and @xmath30 , a utility @xmath31 , a value @xmath14 , and a @xmath32 .",
    "the associated * learnability * is @xmath33 ^ 2 } { \\int dz_\\eta [ f(z_\\eta)var(u ; z_{\\;\\hat{}\\;\\eta } , z_\\eta ) ] } } \\ ;   .\\end{aligned}\\ ] ] the averages and variance here are evaluated according to @xmath34 , @xmath35 , and @xmath36 is @xmath2 s training set , formed by sampling @xmath31 .",
    "the denominator in eq .",
    "[ eq : learnability ] reflects the sensitivity of @xmath37 to @xmath32 , while the numerator reflects its sensitivity is to @xmath38 .",
    "so the greater the learnability of @xmath1 , the more @xmath39 depends only on the move of agent @xmath2 , i.e. , the more learnable @xmath1 is .",
    "more formally , it can be shown that if appropriately scaled , @xmath40 will result in better expected intelligence for agent @xmath2 than will @xmath1 whenever @xmath41 for all pairs of moves @xmath42@xcite .    a * difference * utility is one of the form @xmath43 .",
    "any difference utility is factored  @xcite .",
    "in addition , under usually benign approximations , the @xmath44 that maximizes @xmath45 for all pairs @xmath42 is @xmath46 , where the expectation value is over @xmath6 . the associated difference utility is called the * aristocrat * utility ( @xmath47 ) .",
    "if each @xmath2 uses its @xmath47 as its private utility , then we have both good terms 2 and 3 .",
    "evaluating the expectation value in @xmath47 can be difficult in practice .",
    "this motivates the * wonderful life * utility ( wlu ) , which requires no such evaluation : @xmath48 where @xmath49 is the * clamping parameter*. wlu is factored , independent of the clamping parameter .",
    "furthermore , while not matching @xmath47 , @xmath50 typically has far better learnability than does a team game , and therefore typically results in better values of @xmath0 .",
    "it is also often easier to evaluate than is @xmath0 itself @xcite .",
    "one way to address term 1 as well as 2 and 3 is to incorporate exploration / exploitation techniques like sa .",
    "in our version of sa , at the beginning of each time - step @xmath51 a distribution @xmath52 is formed for every @xmath2 by allotting probability 75% to the move @xmath2 had at the end of the preceding time - step , @xmath53 , and uniformly dividing probability 25% across all of its other moves .",
    "the `` exploration '' joint - move @xmath54 is then formed by simultaneously sampling all the @xmath55 . if @xmath56 , @xmath57 is set to @xmath54 .",
    "otherwise @xmath58 is set by sampling a boltzmann distribution having energies @xmath59 and @xmath60 .",
    "many different annealing schedules were investigated ; all results below are for best schedules found .",
    "ic is identical except that each @xmath55 is replaced by @xmath61 , where the distribution @xmath62 is set by an rl algorithm trying to optimize payoffs @xmath1 . here",
    "rl is done using a training set @xmath63 of all preceding move - payoff pairs , \\{@xmath64}. for each possible move by @xmath2 one forms the weighted average of the payoffs recorded in @xmath63 that occurred with that move , where the weights decay exponentially in @xmath65 .",
    "@xmath62 then is the boltzmann distribution , parameterized by a `` learning temperature '' ( that effectively rescales @xmath1 ) over those averages .    in all our experiments the `` au '' version of ic approximated @xmath66 to to be uniform @xmath67 , and then used a mean - field approxmation to pull the expectation inside @xmath0 . unless otherwise specified , the clamping elements used in wlu s were set to @xmath68 .    in bin - packing @xmath69 items ,",
    "all of size @xmath70 , must be assigned into a minimal subset of @xmath69 bins , without assigning a summed size @xmath71 to any one bin .",
    "@xmath0 of an assignment pattern is the number of occupied bins  @xcite , and each agent controls the bin choice of one item . to improve performance all algorithms use a modified `` @xmath0 '' , @xmath72 , even though their performance is measured with @xmath0 : @xmath73                         & \\mbox{if $ x_i \\leq c$}\\\\        \\sum_{i=1}^n        \\left (   x_i   - \\frac{c}{2}\\right)^2 & \\mbox{if $ x_i > c$ }        \\end{array } \\right .",
    ", \\label{eq : gbinpack}\\end{aligned}\\ ] ] where @xmath74 is the summed size of all items in bin @xmath75 .",
    "( use of @xmath72 encourages bins to be either full or empty . )    in the ic runs learning temperature was .2 , and all agents made the transition to rl - based moves after a period of 100 random @xmath4 s used to generate the starting @xmath76 .",
    "exploitation temperature started at .5 for all algorithms , and was multiplied by .8 every 100 exploitation time - steps in each sa run , the distribution @xmath77 was slowly modified to generate solutions that differed in fewer items than the current solution as time progressed .       in table 1",
    "`` best '' refers to the best end - of - run @xmath0 achieved by the associated algorithm , `` worst '' is the worst value , and `` % optimum '' is the percentage of runs that were within one bin of the best value .",
    "[ fig : bin50 ] shows average performances ( over 25 runs ) as a function of time step .",
    "the algorithms that account for both terms 2 and 3  ic wlu and coin wlu  far outperform the others , with the algorithm accounting for all three terms doing best .",
    "the worst algorithms were those that accounted for only a single term ( sa and coin tg ) .",
    "linearly ( i.e. , optimistically ) extrapolating sa s performance from time 15000 indicates it would take over 1000 times as long as ic wlu to reach the @xmath0 value ic wlu reaches at time 200 .",
    "in addition the ratio of wlu s time 1000 performance ( relative to random search ) to sa s grows linearly with the size of the problem . finally , fig .",
    "[ fig : cap ] illustrates that the benefit of addressing terms 2 and 3 grows with the difficulty of the problem .",
    "in both figures sa outperforms ic - tg ; this is due to there being more parameter - tuning with sa .    for the format choice problem",
    "@xmath0 is the sum over all @xmath79 agents @xmath2 of @xmath2",
    "s `` happiness '' with its music formats : @xmath80 where @xmath81 is the numbers of formats ; @xmath82 is the set of players lying @xmath83 hops away from player @xmath2 ; @xmath84 is @xmath2 s intrinsic preferenece for format @xmath75 ( set randomly at initialization @xmath85 $ ] ) ; @xmath86 is the total number of players that choose format @xmath75 ( i.e. , the inverse price for format @xmath75 ) ; and @xmath87 if the choices of players @xmath2 and @xmath88 both include the format @xmath75 , and 0 otherwise ( each agent s move is a selection of three of four total formats , implemented by choosing the one format not to be used ) .",
    "@xmath89 values of both 1 and 3 were investigated .    in fig .",
    "[ fig : sw100 ] , `` ic econ '' refers to wlu ic where clamping means the agent chooses no format whatsoever .",
    "it is essentially the game - theory groves mechanism wherein one sets @xmath1 to @xmath2 s marginal contribution to @xmath0 , here rescaled and interleaved with a simulated annealing step to improve performance .",
    "`` ic - wlu '' instead clamps @xmath2 s move to zero ( in accord with the theory of collectives ) , which means that @xmath2 chooses all formats .",
    "learning temperature was now .4 , and exploitation temperature was .05 ( annealing provided no advantage since runs were short ) .",
    "two network topologies were investigated .",
    "both were @xmath90-node rings with an extra @xmath91 random links added , a new such set for each of the 50 runs giving a plotted average value . ``",
    "short links '' ( l ) means that all extra links connected players two hops apart , while `` small - worlds '' ( w ) means there was no such restriction .",
    "ic econ s inferior performance illustrates the shortcoming of economics - like algorithms .",
    "for @xmath92 sa did not benefit from small worlds connections , and ic variants barely benefited (   3% ) , despite the associated drop in average inter - node hop distance .",
    "however if @xmath89 also increased , so that @xmath0 directly reflected the change in the topology , then the gain with a small worlds topology grew to   10% .",
    "( see the discussion on path lengths in  @xcite . )",
    "r.  h. crites and a.  g. barto . improving elevator performance using reinforcement learning . in d.",
    "s. touretzky , m.  c. mozer , and m.  e. hasselmo , editors , _ advances in neural information processing systems - 8 _ , pages 10171023 . mit press , 1996 ."
  ],
  "abstract_text": [
    "<S> we consider the problem of designing a set of computational agents so that as they all pursue their self - interests a global function @xmath0 of the collective system is optimized . </S>",
    "<S> three factors govern the quality of such design . </S>",
    "<S> the first relates to conventional exploration - exploitation search algorithms for finding the maxima of such a global function , e.g. , simulated annealing ( sa ) . </S>",
    "<S> game - theoretic algorithms instead are related to the second of those factors , and the third is related to techniques from the field of machine learning . </S>",
    "<S> here we demonstrate how to exploit all three factors by modifying the search algorithm s exploration stage so that rather than by random sampling , each coordinate of the underlying search space is controlled by an associated machine - learning - based `` player '' engaged in a non - cooperative game . </S>",
    "<S> experiments demonstrate that this modification improves sa by up to an order of magnitude for bin - packing and for a model of an economic process run over an underlying network . </S>",
    "<S> these experiments also reveal novel small worlds phenomena . </S>"
  ]
}