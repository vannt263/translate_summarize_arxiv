{
  "article_text": [
    "the original goal of _ pattern mining _  @xcite is to efficiently enumerate frequent combinations of binary features , that is , _ patterns _ , from the massive amount of candidate patterns in a database  @xcite .",
    "various types of patterns have been analyzed in applications : _ itemsets _",
    "@xcite , combinations of binary variables , used in market basket analysis to find frequently copurchased items , _ subgraphs _",
    "@xcite , used in drug discovery to detect commonly occurring substructures in a set of molecules modeled as graphs , and _ sequences _",
    "@xcite , employed , for instance , in dna sequence analysis and customer behavior analysis .    as an extension of the traditional pattern mining problem , _ significant _ ( _ discriminative _ ) _ pattern mining _ is recently emerging , which tries to find patterns enriched in one class relative to another class .",
    "the objective is to mine patterns that are statistically significantly associated with class membership while correcting for multiple testing to ensure rigorous control of the _ family - wise error rate _ ( _ fwer _ ) , that is , the probability to detect one or more false positive patterns .",
    "significant pattern mining has been actively studied and applied to various types of data , including itemsets  @xcite , association rules  @xcite , subgraphs  @xcite , and intervals  @xcite , as the method can provide _",
    "@xmath0-values _ that are indispensable in scientific fields such as biology and medicine .",
    "common to all significant pattern mining approaches is that they assume binary ( or binarized ) variables .",
    "how to directly perform significant pattern mining on _ continuous _ data is still an open problem .",
    "several application domains would benefit from such a technique , for instance , microarray data analysis to find highly co - expressed gene combinations  @xcite , brain activity analysis to detect a specific brain region from fmri images  @xcite , and combinations of product features that affect marketing  @xcite .",
    "one can use significant pattern mining techniques  @xcite with prior binarization of the data in these problems , but the common strategies for binarization cause at least one of the two following problems :    first , one common approach @xcite is to record all @xmath1 values of a feature and to then represent each feature value as a @xmath1-dimensional binary vector , whose entries indicate whether this feature value is less than each of the other feature values or not . as a result , a large sample size turns into a large number of binarized features , which significantly deteriorates the efficiency of pattern mining and generates highly redundant patterns .",
    "second , even if we avoid the above efficiency problem by using the median of each feature as a binarization threshold per feature , this coarse binarization approach then can not distinguish correlated from uncorrelated feature combinations ( see figure  [ figure : example ] for an example ) .    in this paper",
    ", we overcome these two drawbacks and enable significant pattern mining directly on continuous variables . more specifically , given a multivariate dataset with continuous values ,",
    "the goal is to enumerate all significant feature combinations ( patterns ) without any binarization , whose multiple - testing - corrected @xmath0-values for association with the class label are below the significance level so that the fwer is controlled .",
    "our approach is to use the _ rank order statistics _ to represent the frequency of a pattern , which is known as _ copula support _",
    "we show that our frequency is easy to compute , well - defined in the sense of probability theory ( equation  ) , and can be interpreted as a multi - dimensional extension of spearman s pairwise rank correlation coefficient ( theorem  [ theorem : spearman ] ) , which means that we can solve the second problem described above and distinguish correlated and uncorrelated feature combinations ( figure  [ figure : example ] ) .",
    "moreover , we compute @xmath0-values by a _ likelihood ratio test _ using the frequencies of patterns , and show that _",
    "tarone s testability trick _",
    "@xcite can be used to prune untestable patterns that can never be significant , which enables us to solve the first problem and achieve efficient pattern mining .",
    "our contribution allows to find all significant feature combinations and to compute their @xmath0-values directly on continuous data .",
    "this paper is organized as follows : we define our problem and introduce the rank based frequency and analyze the connection to spearman s rank correlation in section  [ sec : fpm ] .",
    "then we extend our approach to significant pattern mining and show how to correct for multiple testing , followed by the presentation of an enumeration algorithm in section  [ sec : spm ] . after reviewing related work in section  [ sec : related ] , we experimentally validate our method in section  [ sec : exp ] and summarize our findings in section  [ sec : conclusion ] .",
    "first we consider the problem of frequent pattern mining on continuous variables to introduce the frequency of a pattern , which is fundamental for the pattern mining problem and required to achieve significant pattern mining .",
    "given a set @xmath2 of @xmath1 samples as a dataset , which corresponds to a set of transactions in the context of frequent itemset mining .",
    "each sample @xmath3 is an @xmath4-dimensional real vector @xmath5 @xmath6 . for each feature @xmath7 , we denote by @xmath8 the @xmath1-dimensional vector composed of the @xmath9th feature of the dataset @xmath10 , that is , @xmath11 .    the goal of frequent pattern mining is to find frequently occurring _ patterns _ , each of which is an element @xmath12 of the power set @xmath13 of the set of feature indices @xmath14 .",
    "more specifically , given a user specified threshold @xmath15 , enumerate the set of _ frequent patterns _",
    "@xmath16 such that @xmath17 .",
    "in this setup , the _ frequency _ @xmath18 $ ] should satisfy the _ anti - monotonicity _ with respect to the inclusion relationship : @xmath19 , which is essential to efficiently enumerate @xmath20 based on the well - known apriori principle  @xcite .",
    "the basic strategy is as follows : start from the emptyset @xmath21 , enumerate frequent patterns according to the order of the inclusion relationship and prune all patterns @xmath22 if the condition @xmath23 is satisfied .",
    "we show that the frequency @xmath24 of the pattern @xmath12 , which determines the importance of @xmath12 , is naturally induced from a discrete probability distribution with the alphabet @xmath13 , which has not been analyzed until now .",
    "let us use a function @xmath25 $ ] to represent a distribution on @xmath13 such that @xmath26 , which gives probability @xmath27 to each pattern @xmath12 .",
    "then the frequency @xmath24 is obtained as the sum of probabilities of patterns that include the pattern @xmath12 , i.e. , @xmath28 for example , in itemset mining with binary variables @xmath29 , the probability of each pattern @xmath30 is given as @xmath31 resulting in @xmath32 .",
    "the frequency is obtained from a given dataset @xmath33 as @xmath34 where @xmath35 is the set of indices for `` 1 '' of @xmath36 .",
    "we apply this formulation to pattern mining from continuous data . to estimate the distribution @xmath0 from a given continuous dataset @xmath10",
    ", we use the _ rank product statistics _ , which is a nonparametric statistical approach  @xcite and actively used in gene expression data analysis  @xcite . for each feature",
    "@xmath37 , let @xmath38 be the _ rank _ of @xmath39 with respect to components of the vector @xmath11 , that is , @xmath40 if @xmath39 is the @xmath41th smallest value among @xmath1 values @xmath42 , yielding the increasing sequence @xmath43 we always assume that there is no tie in @xmath10 , which is a natural assumption for continuous data .",
    "assume that a mapping @xmath44 $ ] gives a normalized ranking as @xmath45 then we can obtain the probability distribution as @xmath46 nakahara et al .",
    "@xcite showed that this satisfies @xmath47 $ ] for all @xmath30 and @xmath26 .",
    "although it is not feasible to compute @xmath27 for every pattern @xmath30 to get the frequency @xmath24 due to combinatorial explosion , interestingly , we can derive the following equation by a simple calculation : @xmath48 this means that we can directly compute @xmath24 without computing each @xmath49 with @xmath22 , whose time complexity is @xmath50 , which is independent of @xmath4 . note the similarity between the definition in equation   and that for binary variables in equation  , where the only difference is either each value is binary @xmath51 or the normalized ranking @xmath52 $ ] .",
    "this indicates that the formulation is a direct relaxation of pattern mining on binary variables .",
    "almost the same frequency was first introduced by @xcite as _ copula support _",
    ", where @xmath53 was defined as not in equation   but @xmath54 .",
    "the difference comes from either the frequency is derived from the distribution over _ patterns _ in our case or that over _ thresholds _ in his case .",
    "we firstly show that the frequency in equation   can be viewed as the multidimensional extension of _ spearman s rank correlation coefficient _",
    "@xcite , which is popularly used as a nonparametric method to measure the association between continuous variables .",
    "the spearman s correlation coefficient between a pair features @xmath55 is defined as @xmath56 we show that our frequency @xmath24 with @xmath57 is essentially the same as @xmath58 .",
    "[ theorem : spearman ] for any pattern @xmath59 with @xmath60 , @xmath61    from the definition of spearman s rank correlation in equation  , we have @xmath62 hence @xmath63 follows .",
    "since @xmath64 , it follows that @xmath65    therefore , using @xmath24 defined in equation   in the frequent pattern mining formulation we can enumerate sets of correlated features as frequent patterns .",
    "now we extend our formulation to significant pattern mining , where a given dataset is _ supervised _ , that is , for each sample @xmath66 a corresponding binary class label @xmath67 is additionally given .",
    "the goal is to find patterns whose frequencies are statistically significantly associated with the class partitioning .",
    "our contribution is to theoretically prove the applicability of _",
    "tarone s testability trick _",
    "@xcite to our frequency of continuous values , which is indispensable to efficiently mine significant patterns  @xcite and has been applied to only statistical tests for discrete values to date , including a fisher s exact test , a @xmath68 test , and a cochran  mantel  haenszel ( cmh ) test .      to test the significance of each pattern @xmath12 , fisher",
    "s exact test has been used as the standard statistical test in recent studies ( e.g.  @xcite ) , which applies to only discrete data . instead of fisher s exact test",
    ", we use a _ likelihood ratio test _",
    "@xcite , which is a generalized @xmath68-test and often called g - test  @xcite for testing the independence in a contingency table .",
    ".observed distribution . [ cols=\"^,^,^,^\",options=\"header \" , ]     * final frequency threshold * : we also check the final frequency threshold @xmath69 obtained at the enumeration step of testable patterns , that is , the set of testable pattern @xmath70 coincides with the set of patterns @xmath71 , where @xmath72 is the minimum achievable @xmath0-value at the frequency @xmath69 .",
    "since @xmath69 is always @xmath73 in bonferroni correction , a higher threshold means that we can prune more untestable patterns .",
    "* precision and recall * : to examine the quality of detected patterns , we compute precision and recall in experiments on synthetic data .",
    "we compare our method and binarization - based methods with excluding the bonferroni correction method as it controls the fwer at the different level .",
    "let @xmath74 be the features that are associated with class labels ( see the next subsection for the definition of the association ) . in the binarization - based methods ,",
    "@xmath75 is the set of binarized features such that each of them is generated from a feature in the original @xmath75 .",
    "suppose that @xmath76 is the set of significant patterns .",
    "for each pattern @xmath77 , @xmath12 is true positive if @xmath78 .",
    "thus precision and recall are given as @xmath79 and @xmath80 , respectively , where @xmath81 .",
    "to examine the evaluation criteria , we generate synthetic data , varying the number @xmath1 of samples from @xmath82 to @xmath83 , the number @xmath4 of features from @xmath84 to @xmath85 , and setting the class ratio to @xmath86 or @xmath87 , i.e. , the number @xmath88 of samples in the minor class is @xmath89 or @xmath90 . in each dataset , we generate 20  % of features that are positively correlated with the class labels , where the top-@xmath88 samples with respect to their original continuous values get the class label @xmath73 , while the others have the class label @xmath91 . these 20  % of correlated features are used to compute the true positives .",
    "the other 80  % of features are uninformative features generated from the uniform distribution .",
    "results are plotted in figure  [ figure : synth05 ] for @xmath86 and figure  [ figure : synth01 ] for @xmath87 . in the respective figure , we plot results with varying @xmath1 while fixing @xmath92 on the left column and those with varying @xmath4 while fixing @xmath93 on the right column .",
    "first , two binarization - based methods , interordinal scaling and interval binarization , do not finish their computation even for the smallest dataset with @xmath94 and @xmath95 after @xmath96 hours , and they exceed the memory limit ( 2.0  tb ) for larger datasets .",
    "we also tried a tiny dataset @xmath97 and @xmath98 , then the interordinal scaling approach finishes about 24 hours .",
    "this is why they generate many binarized features as we showed in section  [ sec : related ] and the binarized dataset is dense , resulting in too heavy computation in the itemset mining step .",
    "therefore we exclude these two methods in the following analysis .",
    "the advantage of our method ( plotted in blue in the figures ) is clear if we compare to the bonferroni correction method ( plotted in red ) with respect to both the number of testable patterns and running time .",
    "in particular , if the number @xmath4 of features gets larger and larger , the bonferroni correction method becomes exponentially slower due to combinatorial explosion of the candidate space , while our method can finish mining in a reasonable time by pruning untestable patterns .",
    "we can also confirm the advantage of the testability trick from the final frequency thresholds , which are higher than @xmath73 and hence infrequent patterns are pruned as untestable patterns .    in comparison with the median - based binarization method ( plotted in green )",
    ", our method has a clear advantage regarding the quality of detected significant patterns . in all cases ,",
    "both precision and recall of our method are higher than those of the median - based binarization method .",
    "these results confirm the drawback of binarization based methods , which we discussed in the introduction and illustrated in figure  [ figure : example ] , that is , the binarization based method can not distinguish correlated and uncorrelated patterns . in both methods , precision drops when the number @xmath1 of samples becomes large : as we gain more and more statistical power for larger @xmath1 , many feature combinations , even those with very small dependence to the class labels , tend to reach statistical significance .",
    "in contrast , recall drops when the number @xmath4 of features becomes large , due to the growing number of testable patterns , resulting in a loss of statistical power in finding significant patterns .    to summarize , we observe that our proposal is the only method that efficiently mines significant patterns by avoiding the combinatorial explosion of the number of tests and that effectively finds correlated features .",
    "we evaluate our proposal on real - world datasets shown in table  [ table : real_stat ] , which are benchmark datasets for binary classification from the uci repository .",
    "since the true causal features are unknown in those datasets , we evaluated the number of testable patterns , running time , and the final frequency thresholds .",
    "we summarize results in table  [ table : real_results ] , where we observe the same trend as before : first , our method is more efficient than the bonferroni correction method by pruning untestable patterns .",
    "second , although we can not report precision and recall here , the number of testable patterns in our method is one or two orders of magnitude smaller than that in median - based binarization , which indicates that the median - based binarization method generates many redundant features .",
    "in this paper , we have addressed the challenge of extending significant pattern mining to continuous features .",
    "key to our approach is to represent the frequency of a pattern by means of spearman s rank correlation coefficient .",
    "our experimental results demonstrate that our approach is superior in detecting true patterns compared to all pattern mining approaches that require a prior binarization .",
    "our work opens the door to many applications of significant pattern mining , in which the data is not adequately described by binary features , including large fields such as data analysis for high - throughput technologies in biology and medicine .",
    "our work here addresses the problem of mining continuous _",
    "features_. significant pattern mining on _ continuous class labels _ ( or output variables ) is an equally challenging and practically relevant problem , that we will tackle in future work .",
    "r.  agrawal , t.  imieliski , and a.  swami .",
    "mining association rules between sets of items in large databases . in _ proceedings of the 1993 acm",
    "sigmod international conference on management of data _ , pages 207216 , 1993 .",
    "r.  breitling , p.  armengaud , a.  amtmann , and p.  herzyk .",
    "rank products : a simple , yet powerful , new method to detect differentially regulated genes in replicated microarray experiments . _ febs letters _ , 5730 ( 1 - 3):0 8392 , 2004 .      c.  davatzikos , k.  ruparel , y.  fan , d.  g. shen , m.  acharyya , j.  w. loughead , r.  c. gur , and d.  d. langleben . classifying spatial patterns of brain activity with machine learning methods : application to lie detection .",
    "_ neuroimage _ , 280 ( 3):0 663668 , 2005 .",
    "r.  a. fisher . on the mathematical foundations of theoretical statistics .",
    "_ philosophical transactions of the royal society of london a : mathematical , physical and engineering sciences _ , 2220 ( 594 - 604):0 309368 , 1922 .",
    "w.  hmlinen .",
    "kingfisher : an efficient algorithm for searching for both positive and negative dependency rules with statistical significance measures .",
    "_ knowledge and information systems _ , 320 ( 2):0 383414 , 2012 .",
    "t.  heskes , r.  eisinga , and r.  breitling . a fast algorithm for determining bounds and accurate approximate p - values of the rank product statistic for replicate experiments . _ bmc bioinformatics _ , 150 ( 1):0 367 , 2014 .",
    "m.  kaytoue , s.  o. kuznetsov , and a.  napoli .",
    "revisiting numerical pattern mining with formal concept analysis . in _ proceedings of the 22nd international joint conference on artificial intelligence _",
    ", pages 13421347 , 2011 .",
    "f.  llinares - lpez , d.  g. grimm , d.  a. bodenham , u.  gieraths , m.  sugiyama , b.  rowan , and k.  m. borgwardt . genome - wide detection of intervals of genetic heterogeneity associated with complex traits .",
    "_ bioinformatics _ , 310 ( 12):0 i240i249 , 2015 .",
    "f.  llinares - lpez , m.  sugiyama , l.  papaxanthos , and k.  m. borgwardt .",
    "fast and memory - efficient significant pattern mining via permutation testing . in",
    "_ proceedings of the 21st acm sigkdd conference on knowledge discovery and data mining _ , pages 725734 , 2015 .",
    "s.  minato , t.  uno , k.  tsuda , a.  terada , and j.  sese . a fast method of statistical assessment for combinatorial hypotheses based on frequent itemset enumeration . in _",
    "machine learning and knowledge discovery in databases _ ,",
    "volume 8725 of _ lncs _ , pages 422436 .",
    "springer , 2014 .",
    "p.  k. novak , n.  lavra , and g.  i. webb .",
    "supervised descriptive rule discovery : a unifying survey of contrast set , emerging pattern and subgroup mining . _ the journal of machine learning research _",
    ", 10:0 377403 , 2009 .",
    "l.  papaxanthos , f.  llinares - lopez , d.  bodenham , and k.  m. borgwardt .",
    "finding significant combinations of features in the presence of categorical covariates . in _ advances in neural information processing systems",
    "_ , volume  29 , pages 22712279 , 2016 .",
    "j.  pei , j.  han , b.  mortazavi - asl , h.  pinto , q.  chen , u.  dayal , and m-.c .",
    "refixspan : mining sequential patterns efficiently by prefix - projected pattern growth . in _ proceedings of the 17th international conference on data engineering _ , pages 215224 , 2001 .",
    "m.  sugiyama , f.  llinares - lpez , n.  kasenburg , and k.  m borgwardt .",
    "significant subgraph mining with multiple testing correction . in _ proceedings of 2015 siam international conference on data mining _ , pages 3745 , 2015 .",
    "a.  terada , k.  tsuda , and j.  sese .",
    "fast westfall - young permutation procedure for combinatorial regulation discovery . in _ 2013 ieee international conference on bioinformatics and biomedicine ( bibm ) _ , pages 153158 , 2013 .",
    "a.  terada , d.  duverle , and k.  tsuda .",
    "significant pattern mining with confounding variables . in _ advances in knowledge discovery and data mining ( pakdd 2016 ) _ ,",
    "volume 9651 of _ lncs _ , pages 277289 , 2016 .",
    "t.  uno , t.  asai , y.  uchida , and h.  arimura .",
    "an efficient algorithm for enumerating closed patterns in transaction databases . in _ discovery science _ , volume 3245 of _ lecture notes in computer science _",
    ", pages 1631 , 2004 .",
    "m.  van leeuwen and a.  ukkonen .",
    "expect the unexpected  on the significance of subgroups . in t.  calders , m.  ceci , and d.  malerba , editors , _ discovery science _",
    ", volume 9956 of _ lecture notes in computer science _ , pages 5166 , 2016 .      g.  i. webb and f.  petitjean . a multiple test correction for streams and cascades of statistical hypothesis tests . in _ proceedings of the 22nd acm",
    "sigkdd international conference on knowledge discovery and data mining _ , pages 12551264 , 2016 ."
  ],
  "abstract_text": [
    "<S> significant pattern mining , the search for sets of binary features that are statistically significantly enriched in a class of objects , is of fundamental importance in a wide range of applications from economics to statistical genetics . </S>",
    "<S> still , all existing approaches make the restrictive assumption that the features are _ binary _ and require a binarization of continuous data during preprocessing , which often leads to a loss of information .    here , we solve the open problem of _ significant pattern mining _ on _ continuous _ variables . </S>",
    "<S> our approach detects all patterns that are statistically significantly associated with a class of interest , while rigorously correcting for multiple testing . </S>",
    "<S> key to this approach is the use of spearman s rank correlation coefficient to represent the frequency of a pattern . </S>",
    "<S> our experiments demonstrate that our novel approach detects true patterns with higher precision and recall than competing methods that require a prior binarization of the data .    </S>",
    "<S> = 1 </S>"
  ]
}