{
  "article_text": [
    "the ( binary ) deletion channel accepts bits as inputs , and deletes each transmitted bit independently with probability @xmath0 . computing or providing systematic approximations to its capacity is one of the outstanding problems in information theory @xcite .",
    "an important motivation comes from the need to understand synchronization errors and optimal ways to cope with them .    in this paper",
    "we suggest a new approach .",
    "we demonstrate that capacity can be computed in a series expansion for small deletion probability , by computing the first two orders of such an expansion .",
    "our main result is the following .",
    "[ thm : main_theorem ] let @xmath1 be the capacity of the deletion channel with deletion probability @xmath0 . then , for small @xmath0 and any @xmath2 , @xmath3 where @xmath4 .",
    "further , the iid bernoulli@xmath5 process achieves capacity up to corrections of order @xmath6 .",
    "logarithms here ( and in the rest of the paper ) are understood to be in base @xmath7 .",
    "the constant @xmath8 can be easily evaluated to yield @xmath9 . while one might be skeptical about the concrete meaning of asymptotic expansions of the type ( [ eq : mainformula ] ) , they often prove surprisingly accurate .",
    "for instance at @xmath10 deletion probability , eq .",
    "( [ eq : mainformula ] ) is off the best lower bound proved in @xcite by about @xmath11 bits .",
    "more importantly they provide useful design insight .",
    "for instance , the above result shows that bernoulli@xmath5 is an excellent starting point for the optimal input distribution .",
    "next terms in expansion indicate how to systematically modify the input distribution for @xmath12 @xcite .    )",
    "( continuous line ) with upper bounds from @xcite ( stars @xmath13 ) and lower bounds from @xcite ( squares , @xmath14 ) . the @xmath15 term in ( [ eq : mainformula ] )",
    "was simply dropped . ]",
    "we think the strategy adopted here might be useful in other information theory problems .",
    "the underlying philosophy is that whenever capacity is known for a specific value of the channel parameter , and the corresponding optimal input distribution is unique and well characterized , it should be possible to compute an asymptotic expansion around that value . here",
    "the special channel is the perfect channel , i.e. the deletion channel with deletion probability @xmath16 .",
    "the corresponding input distribution is the iid bernoulli@xmath5 process .",
    "dobrushin @xcite proved a coding theorem for the deletion channel , and other channels with synchronization errors .",
    "he showed that the maximum rate of reliable communication is given by the maximal mutual information per bit , and proved that this can be achieved through a random coding scheme .",
    "this characterization has so far found limited use in proving concrete estimates .",
    "an important exception is provided by the work of kirsch and drinea @xcite who use dobrushin coding theorem to prove lower bounds on the capacity of channels with deletions and duplications .",
    "we will also use dobrushin theorem in a crucial way , although most of our effort will be devoted to proving upper bounds on the capacity .",
    "several capacity bounds have been developed over the last few years , following alternative approaches , and are surveyed in @xcite . in particular , it has been proved that @xmath17 as @xmath18 . however determining the asymptotic behavior in this limit ( i.e. finding a constant @xmath19 such that @xmath20 ) is an open problem . when applied to the small @xmath0 regime , none of the known upper bounds actually captures the correct behavior ( [ eq : mainformula ] ) . as we show in the present paper ,",
    "this behavior can be controlled exactly .    when this paper was nearing submission , a preprint by kalai , mitzenmacher and sudan @xcite",
    "was posted online , proving a statement analogous to theorem [ thm : main_theorem ] .",
    "the result of @xcite is however not the same as in theorem [ thm : main_theorem ] : only the @xmath21 term of the series is proved in @xcite .",
    "further , the two proofs are based on very different approaches .",
    "for the reader s convenience , we restate here some known results that we will use extensively , along with with some definitions and auxiliary lemmas .    consider a sequence of channels @xmath22 , where @xmath23 allows exactly @xmath24 inputs bits , and deletes each bit independently with probability @xmath0 .",
    "the output of @xmath23 for input @xmath25 is a binary vector denoted by @xmath26 .",
    "the length of @xmath26 is a binomial random variable .",
    "we want to find maximum rate at which we can send information over this sequence of channels with vanishingly small error probability .",
    "the following characterization follows from @xcite .",
    "[ lemma : cap_limit ] let @xmath27 then , the following limit exists @xmath28 and is equal to the capacity of the deletion channel .",
    "this is just a reformulation of theorem 1 in @xcite , to which we add the remark @xmath29 , which is of independent interest . in order to prove this fact , consider the channel @xmath30 , and let @xmath31 be its input .",
    "the channel @xmath30 can be realized as follows .",
    "first the input is passed through a channel @xmath32 that introduces deletions independently in the two strings @xmath33 and @xmath34 and outputs @xmath35 where @xmath36 is a marker .",
    "then the marker is removed .",
    "this construction proves that @xmath30 is physically degraded with respect to @xmath32 , whence @xmath37 here the last inequality follows from the fact that @xmath32 is the product of two independent channels , and hence the mutual information is maximized by a product input distribution .",
    "therefore the sequence @xmath38 is sub - additive , and the claim follows from fekete s lemma .",
    "a last useful remark is that , in computing capacity , we can assume @xmath39 to be @xmath24 consecutive coordinates of a stationary ergodic process .",
    "[ lemma : stationary_suffices ] let @xmath40 be a stationary and ergodic process , with @xmath41 taking values in @xmath42 . then the limit @xmath43 exists and @xmath44    take any stationary @xmath45 , and let @xmath46 . notice that @xmath47 form a markov chain .",
    "define @xmath48 as in the proof of theorem [ lemma : cap_limit ] . as before we have @xmath49 .",
    "( the last identity follows by stationarity of @xmath45 ) .",
    "thus @xmath50 and the limit @xmath51 exists by fekete s lemma , and is equal to @xmath52 .",
    "clearly , @xmath53 for all @xmath24 .",
    "fix any @xmath54 .",
    "we will construct a process @xmath45 such that @xmath55 thus proving our claim .",
    "fix @xmath24 such that @xmath56 .",
    "construct @xmath45 with iid blocks of length @xmath24 with common distribution @xmath57 that achieves the supremum in the definition of @xmath58 . in order to make this process stationary ,",
    "we make the first complete block to the right of the position @xmath59 start at position @xmath60 uniformly random in @xmath61 .",
    "we call the position @xmath60 the offset .",
    "the resulting process is clearly stationary and ergodic .",
    "now consider @xmath62 for some @xmath63 and @xmath64 .",
    "the vector @xmath65 contains at least @xmath66 complete blocks of size @xmath24 , call them @xmath67 with @xmath68 .",
    "the block @xmath69 starts at position @xmath60 .",
    "there will be further @xmath70 bits at the end , so that @xmath71 . abusing notation , we write @xmath72 for @xmath73 .",
    "given the output @xmath74 , we define @xmath75 , by introducing @xmath76 synchronization symbols @xmath36",
    ". there are at most @xmath77 possibilities for @xmath78 given @xmath74 ( corresponding to potential placements of synchronization symbols ) .",
    "therefore we have @xmath79 where we used the fact that the @xmath80 s are iid .",
    "further @xmath81 where the last term accounts for bits outside the blocks .",
    "we conclude that @xmath82 provided @xmath83 , @xmath84 . since @xmath85 , this in turn implies eq .",
    "( [ eq : liminf_closeto_limsup ] ) .",
    "in this section we provide the proof of theorem [ thm : main_theorem ] .",
    "we defer the proof of several technical lemmas to the next section .",
    "the first step consists in proving achievability by estimating @xmath86 for the iid bernoulli@xmath5 process .",
    "[ lemma : iidhalf ] let @xmath87 be the iid bernoulli@xmath5 process . for any @xmath88",
    ", we have @xmath89    lemma [ lemma : stationary_suffices ] allows us to restrict our attention to stationary ergodic processes in proving the converse . in light of lemma",
    "[ lemma : iidhalf ] , we can further restrict consideration to processes @xmath45 satisfying @xmath90 and hence @xmath91 ( here and below , for a process @xmath45 , we denote by @xmath92 its _ entropy rate _ ) .    given a ( possibly infinite ) binary sequence ,",
    "a _ run _ of @xmath59 s ( of @xmath93 s ) is a maximal subsequence of consecutive @xmath59 s ( @xmath93 s ) , i.e. an subsequence of @xmath59 s bordered by @xmath93 s ( respectively , of @xmath93 s bordered by @xmath59 s ) .",
    "denote by @xmath94 the set of all stationary ergodic processes and by @xmath95 the set of stationary ergodic processes such that , with probability one , no run has length larger than @xmath96 .",
    "the next lemma shows that we do nt lose much by restricting ourselves to @xmath97 for large enough @xmath98 .",
    "[ lemma : small_loss_by_restricting_runs ] for any @xmath2 there exists @xmath99 such that the following happens for all @xmath100 . for any @xmath101 such that @xmath102 and for any @xmath103 , there exists @xmath104 such that @xmath105    we are left with the problem of bounding @xmath86 from above for all @xmath106 .",
    "the next lemma establishes such a bound .",
    "[ lemma : converse_for_restricted_runs ] for any @xmath2 there exists @xmath99 such that the following happens . for any @xmath107 and any @xmath106 if @xmath108 , then @xmath109    lemma [ lemma : iidhalf ] shows achievability .",
    "the converse follows from lemmas [ lemma : small_loss_by_restricting_runs ] and [ lemma : converse_for_restricted_runs ] with @xmath110 .",
    "in section [ subsec : run_charac ] we characterize any stationary ergodic @xmath45 in terms of its ` bit perspective ' and ` block perspective ' run - length distributions , and show that these distributions must be close to the distributions obtained for the iid bernoulli@xmath5 process . in section [ subsec : modified_deletion ]",
    "we construct a modified deletion process that allows accurate estimation of @xmath111 in the small @xmath0 limit . finally , in section [ subsec : lemma_proofs ] we present proofs of the lemmas quoted in section [ sec : outline ] using the tools developed .",
    "consider a stationary ergodic process @xmath45 . without loss of generality",
    "we can assume that almost surely all runs have finite length ( by ergodicity and stationarity this only excludes the constant @xmath59 and constant @xmath93 processes ) .",
    "let @xmath114 be the length of the run containing position @xmath59 in @xmath45 .",
    "let @xmath115 be the length of first run to occur to the right of position @xmath59 in @xmath45 and , in general , let @xmath116 be the length of the @xmath117-th run to the right of position @xmath59 .",
    "let @xmath118 denote the limit of the empirical distribution of @xmath119 , as @xmath120 .",
    "by ergodicity @xmath118 is a well defined probability distribution on @xmath121 .",
    "we call @xmath118 the _ block - perspective _ run length distribution for obvious reasons , and use @xmath96 to denote a random variable drawn according to @xmath118 .",
    "it is not hard to see that , for any @xmath122 , @xmath123 } \\ ; .\\ ] ] in other words @xmath114 is distributed according to the size biased version of @xmath118 .",
    "we call this the _ bit perspective _ run length distribution , and shall often drop the subscript @xmath45 when clear from the context",
    ". notice that since @xmath114 is a well defined and almost surely finite , we have @xmath124 < \\infty$ ] .",
    "it follows that the empirical distribution of run lengths in @xmath125 also converges to @xmath118 almost surely , since the first and last run do not matter in the limit .",
    "if @xmath126 are the run lengths in the block @xmath127 , it is clear that @xmath128 ( where one bit is needed to remove the @xmath129 ambiguity ) . by ergodicity",
    "@xmath130 $ ] almost surely as @xmath131 .",
    "this also implies @xmath132 .",
    "further , @xmath133 $ ] . if @xmath92 is the entropy rate of the process @xmath45 , by taking the @xmath131 limit , it is easy to deduce that @xmath134 } \\",
    ", , \\label{eq : run_hx_upper_bd}\\end{aligned}\\ ] ] with equality if and only if @xmath45 consists of iid runs with common distribution @xmath135 .    for convenience of notation , define @xmath136 $ ] . we know that given @xmath124=\\mu$ ] , the probability distribution with largest possible entropy @xmath137 is geometric with mean @xmath138 , i.e. @xmath139 for all @xmath140 , leading to @xmath141 } \\leq   -\\big(1 - \\frac{1}{\\mu}\\big ) \\log \\big(1 - \\frac{1}{\\mu}\\big ) - \\frac{1}{\\mu}\\log \\frac{1}{\\mu } \\equiv h(1/\\mu ) \\ , .",
    "\\label{eq : boundmu}\\end{aligned}\\ ] ] here we introduced the notation @xmath142 for the binary entropy function .",
    "there exists @xmath145 such that , for any @xmath146 with @xmath102 , latexmath:[\\ ] ] using lemma [ lemma : l0_tv ] , we have @xmath274 - \\sum_{l=1}^\\infty 2^{-l-1}l\\log l| = o(d^{(1/2)-\\epsilon}\\log l^*)$ ] .",
    "the result follows .",
    "* acknowledgments . *",
    "y. kanoria is supported by a 3com corporation stanford graduate fellowship .",
    "y. kanoria and a. montanari were supported by nsf , grants ccf-0743978 and ccf-0915145 , and a terman fellowship ."
  ],
  "abstract_text": [
    "<S> the deletion channel is the simplest point - to - point communication channel that models lack of synchronization . despite significant effort , </S>",
    "<S> little is known about its capacity , and even less about optimal coding schemes . in this paper </S>",
    "<S> we initiate a new systematic approach to this problem , by demonstrating that capacity can be computed in a series expansion for small deletion probability . </S>",
    "<S> we compute two leading terms of this expansion , and show that capacity is achieved , up to this order , by i.i.d . </S>",
    "<S> uniform random distribution of the input .    </S>",
    "<S> we think that this strategy can be useful in a number of capacity calculations . </S>"
  ]
}