{
  "article_text": [
    "given a channel @xmath0 and an input distribution @xmath1 , let the output distribution be @xmath2 . also , let the @xmath3-fold memoryless extensions of these be denoted @xmath4 , @xmath5 , and @xmath6 .",
    "wyner s soft - covering lemma ( * ? ? ?",
    "* theorem  6.3 ) says that the distribution induced by selecting a @xmath7 sequence at random from an appropriately chosen set and passing this sequence through the memoryless channel @xmath4 will be a good approximation of @xmath6 in the limit of large @xmath3 as long as the set is of size greater than @xmath8 where @xmath9 .",
    "in fact , the set can be chosen quite carelessly  by random codebook construction , drawing each sequence independently from the distribution @xmath5 .",
    "the soft - covering lemmas in the literature use a distance metric on distributions ( commonly total variation or relative entropy ) and claim that the distance between the induced distribution @xmath10 and the desired distribution @xmath6 vanishes in expectation over the random selection of the set . in the literature , @xcite studies",
    "the fundamental limits of soft - covering as `` resolvability , '' @xcite provides rates of exponential convergence , @xcite improves the exponents and extends the framework , @xcite and ( * ? ? ?",
    "* chapter  16 ) refer to soft - covering simply as `` covering '' in the quantum context , @xcite refers to it as a `` sampling lemma '' and points out that it holds for the stronger metric of relative entropy , and @xcite gives a recent direct proof of the relative entropy result .",
    "here we give a stronger claim . with high probability with respect to the set construction",
    ", the distance will vanish exponentially quickly with the block - length @xmath3 .",
    "the negligible probability of the random set not producing this desired result is doubly - exponentially small .",
    "let us define precisely the induced distribution .",
    "let @xmath11 be the set of sequences , which will be referred to as the codebook .",
    "the size of the codebook is @xmath12 .",
    "then the induced distribution is : @xmath13    for any @xmath14 , @xmath0 , and @xmath9 , where @xmath15 has a finite support @xmath16 , there exists a @xmath17 and a @xmath18 such that for @xmath3 large enough @xmath19 where @xmath20 is the relative entropy .",
    "we state the proof in terms of arbitrary distributions ( not necessarily discrete ) .",
    "when needed , we will specialize to the case that @xmath16 is finite .",
    "let the radon - nikodym derivative between the induced and desired distributions be denoted as @xmath21 in the discrete case , this is just a ratio of probability mass functions .",
    "notice that the relative entropy of interest , which is a function of the codebook @xmath22 , is given by @xmath23    define the jointly - typical set over @xmath24 and @xmath25 sequences by @xmath26    we split @xmath27 into two parts , making use of the indicator function denoted by @xmath28 .",
    "let @xmath29 be arbitrary , to be determined later .",
    "@xmath30 the measures @xmath31 and @xmath32 on the space @xmath33 are not probability measures , but @xmath34 for each codebook @xmath22 .",
    "let us also split @xmath35 into two parts : @xmath36    by jensen s inequality ( or the data processing inequality ) we can upper bound the relative entropy of interest : @xmath37 where @xmath38 is the binary entropy function .",
    "notice that @xmath31 will usually contain almost all of the probability . that is , denoting the complement of @xmath39 as @xmath40 , @xmath41 this is an average of exponentially many i.i.d",
    ". random variables bounded between 0 and 1 .",
    "furthermore , the expected value of each one is the exponentially small probability of correlated sequences being atypical : @xmath42 where @xmath43 where @xmath44 is the rnyi divergence of order @xmath45 .",
    "we use units of bits for mutual information and rnyi divergence to coincide with the base two expression of rate .",
    "therefore , the chernoff bound assures that @xmath46 is exponentially small .",
    "that is , for any @xmath47 , @xmath48    similarly , @xmath49 is an average of exponentially many i.i.d . and uniformly bounded functions , each one determined by one sequence in the codebook : @xmath50 for every term in the average , the indicator function bounds the value to be between @xmath51 and @xmath52 .",
    "the expected value of each term with respect to the codebook is bounded above by one , which is observed by removing the indicator function .",
    "therefore , the chernoff bound assures that @xmath53 is exponentially close to one for every @xmath54 . for any @xmath55 : @xmath56 this use of the chernoff bound has been used before for a soft - covering lemma in the proof of lemma  9 of @xcite .    at this point",
    "we will use the fact that @xmath16 is a finite set to obtain two bounds .",
    "first , @xmath57 notice that the maximum is only over the support of @xmath15 , which makes this bound finite .",
    "the reason this restriction is possible is because with probability one a conditional distribution is absolutely continuous with respect to its associated marginal distribution .",
    "next we use the union bound applied to and , taking advantage of the fact that the space @xmath33 is only exponentially large . let @xmath58 be the set of codebooks such that all of the following are true : @xmath59 we see that the probability of not being in @xmath58 is doubly exponentially small : @xmath60    what remains is to show that for every codebook in @xmath58 , the relative entropy is exponentially small .",
    "we begin from . since @xmath61 we have @xmath62 furthermore , @xmath63 finally , @xmath64    note :",
    "relative entropy can be used to bound total variation via pinsker s inequality . with that approach",
    "you lose a factor of two in the exponent of decay . on the other hand ,",
    "the last steps of the proof can be modified to produce a total variation bound instead of relative entropy .",
    "this direct method keeps the error exponents the same for the total variation case as it is for relative entropy .",
    "this stronger version of wyner s soft - covering lemma has important applications , particularly to information theoretic security .",
    "the main advantage of this lemma comes from the union bound .",
    "the usual random coding argument for information theory uses a randomly generated codebook until the final steps of the achievability proof . in this final step ,",
    "it is claimed that there exists a good codebook based on the analysis .",
    "this can be done by analyzing the expected value of the performance for the random ensamble and claiming that at least one codebook is as good as the expected value .",
    "alternatively , one can make the argument based on the probability that the randomly generated codebook has a good performance .",
    "if that probability is greater than zero , then there is at least one good codebook .",
    "the second approach can be advantageous when performance is not captured by one scalar value that is easily analyzed  for example , if `` good '' performance involves a collection of constraints .",
    "this stronger soft - covering lemma gives a very strong assurance that soft - covering will hold . even if the codebook needs to satisfy exponentially many constraints related to soft - covering , the union bound will yield the claim that a codebook exists which satisfies them all simultaneously .",
    "indeed , if you ran the soft - covering experiment exponentially many times , regardless of how the codebooks are correlated from one experiment to the next , the probability of seeing even one fail is still doubly - exponentially small .",
    "wyner s soft - covering lemma has become a standard tool for proving that strong perfect secrecy is achieved in the wiretap channel ( see e.g. @xcite ) . coincidentally ,",
    "wyner introduced both the idea of soft covering @xcite and the wiretap channel @xcite in the same year , but he did nt connect the two together .    according to the usual definition , strong perfect secrecy is achieved if the mutual information ( unnormalized ) between the message and the eavesdropper s channel output can be made arbitrarily small .",
    "an even stronger notion of near - perfect secrecy is semantic security .",
    "this requires that any two messages can not be distinguished , usually measured by total variation .",
    "this is not implied by the above strong secrecy because mutual information is an average quantity .",
    "since there are so many messages , the mutual information can be small even if a few of the messages are perfectly distinguishable .",
    "semantic security is an operationally relevant metric and widely adopted in cryptography . in @xcite",
    "it is shown that semantic security is essentially equivalent to stipulating that the capacity of the channel from the transmitted message to the eavesdropper s observations is negligible , rather than the mutual information with respect to a uniformly distributed message .",
    "they also show that for some binary channels semantic security can be achieved at rates up to wyner s secrecy capacity .",
    "note that contrary to the claim in @xcite , it is not sufficient to analyze the random codebook ensemble for an arbitrary message distribution in order to claim semantic security .",
    "a single codebook must work well for all message distributions .",
    "the soft - covering lemma is used in the proof of the wiretap channel in the following way .",
    "a random codebook is used for communication to the intended receiver ; however , two digital messages are concatenated and fed into the encoder ( mapped to the codewords ) : the actual message to be transmitted ; and a random sequence of bits .",
    "this random sequence of bits is what provides the secrecy .",
    "since the sequence is random , this means that for any individual transmitted message there is a collection of codewords from which one is selected uniformly at random and transmitted .",
    "the soft - covering lemma says that the output at the eavesdropper will look i.i.d . if the size of this set if large enough .",
    "more importantly , this i.i.d .",
    "output distribution does not depend on the message that was transmitted .",
    "this argument , using the standard soft - covering lemma ( expectation with respect to the codebook ) , is good enough to claim that the output distribution is close to the i.i.d .",
    "distribution on average over the messages .",
    "this can then be used to claim that the mutual information is small . however , for semantic security , it must be claimed that the output distribution is close the i.i.d .",
    "distribution for all messages , and there are exponentially many messages . here is where the stronger soft - covering lemma provided in this work is advantageous . using the stronger lemma",
    "we can claim that a single codebook exists that accomplishes this for every message .    for the single - transmitter wiretap setting",
    ", semantic security can be achieved by other means .",
    "the expurgation technique that is used to bound the maximum error probability in channel coding can be used here .",
    "any offending messages , which do not produce the desired output distribution at the eavesdropper , can be removed from the codebook , and this can be shown to only negligibly reduce the message rate .",
    "however , this expurgation technique will not work in all setting , such as the multiple access wiretap channel . on the other hand , the proof method involving this stronger soft - covering lemma will work in that setting .",
    "thus , strong secrecy can be upgraded to semantic security even in situations where vanishing average error probability can not be upgraded to vanishing maximum error probability .      in previous work @xcite",
    ", we characterized the minimum rates of communication and common randomness needed to synthesize a memoryless channel , where the channel inputs are observed at the location of the transmitter , and the channel outputs are produced at the location of the receiver .",
    "this is referred to as distributed channel synthesis .",
    "we say that synthesis is achieved if it is not possible to distinguish the synthetic channel from the genuine memoryless channel that it mimics upon observing the channel inputs and outputs .",
    "the work in @xcite only considers the case where the input is a fixed i.i.d .",
    ". a stronger claim would be to say that the synthetic channel can not be distinguished from the genuine channel even for arbitrary inputs ( perhaps with a statistical constraint ) .",
    "however , the proof in @xcite relies heavily on the soft - covering lemma , and the exponential size of even a single type of input sequences made such a claim elusive",
    ". a single codebook would need to work well for all input sequences , but the soft - covering lemma only showed that it would work well on average .    with this stronger soft - covering lemma , it may be possible to use the union bound to claim that the soft - covering phenomenon will hold for all of the channel inputs simultaneously .",
    "the wiretap channel has been studied in other forms aside from the memoryless channel setting .",
    "one such variation , where the eavesdropper gets to make choices about his own channel noise , has been referred to as the wiretap channel ii @xcite .",
    "the original formulation was a channel where the eavesdropper is allowed to decide which transmission packets to observed while being limited in quantity . if the selection of observed packets is an i.i.d .",
    "process , then this is the standard wiretap channel setting with an erasure channel to the eavesdropper .",
    "the secrecy capacity of the wiretap channel type ii , where the eavesdropper selects the packets to observe , was solved in @xcite only for the case of a noise - free channel to the legitimate receiver .",
    "recent work @xcite investigates the case where the channel to the legitimate receiver is also noisy , for which the secrecy capacity is yet unknown .",
    "the challenge in this setting is that the eavesdropper knows the codebook when it selects the packets to observe .",
    "therefore , secrecy will only be achieved if it is achieved uniformly for all selections of packets , of which there are exponentially many possibilities .    using the lemma provided in this work",
    ", it can be shown that rates all the way up to the secrecy capacity of the memoryless erasure channel can be achieved even in this more stringent setting .",
    "the codebook construction for the wiretap channel is symmetric in time , so the secrecy analysis , with respect to the random codebook , does not depend on the specific choice of packets observed .",
    "the remaining step that is needed is to show that a single codebook exists which will provide secrecy simultaneously for each one of the exponentially many observation sequences .",
    "this is what the stronger soft - covering lemma provides .",
    "this work was supported by the national science foundation ( grant ccf-1350595 ) and the air force office of scientific research ( grant fa9550 - 15 - 1 - 0180 ) .",
    "m. hayashi , `` general nonasymptotic and asymptotic formulas in channel resolvability and identification capacity and their application to the wiretap channel , '' _ ieee trans .",
    "inf . theory _ , 52(4 ) : 1562 - 75 , april 2006 .                      c. bennett , i. devetak , a. harrow , p. shor , and a. winter , `` the quantum reverse shannon theorem and resource tradeoffs for simulating quantum channels , '' _ ieee trans .",
    "inf . theory _ , 60(5 ) : 2926 - 59 , may 2014 ."
  ],
  "abstract_text": [
    "<S> wyner s soft - covering lemma is a valuable tool for achievability proofs of information theoretic security , resolvability , channel synthesis , and source coding . </S>",
    "<S> the result herein sharpens the claim of soft - covering by moving away from an expected value analysis . instead , a random codebook is shown to achieve the soft - covering phenomenon with high probability . </S>",
    "<S> the probability of failure is doubly - exponentially small in the block - length , enabling more powerful applications through the union bound . </S>"
  ]
}