{
  "article_text": [
    "classic optimization settings assume that the problem data are known exactly .",
    "robust optimization , like stochastic optimization , instead assumes some degree of uncertainty in the problem formulation .",
    "most approaches in robust optimization formalize this uncertainty by assuming that all uncertain parameters @xmath0 are described by a set of possible outcomes @xmath1 , the uncertainty set .    for general overviews on robust optimization , we refer to @xcite .",
    "while the discussion of properties of the robust problem for different types of uncertainty sets @xmath1 has always played a major role in the research community , only recently the data - driven design of useful sets @xmath1 has become a focus of research . in @xcite ,",
    "the authors discuss the design of @xmath1 taking problem tractability and probabilistic guarantees of feasibility into account .",
    "the paper @xcite discusses the relationship between risk measures and uncertainty sets .    in distributionally robust optimization",
    ", one assumes that a probability distribution on the data is roughly known ; however , this distribution itself is subject to an uncertainty set @xmath1 of possible outcomes ( see @xcite ) .",
    "another related approach is the globalized robust counterpart , see @xcite .",
    "the idea of this approach is that a relaxed feasibility should be maintained , even if a scenario occurs that is not specified in the uncertainty set .",
    "the larger the distance of @xmath0 to @xmath1 , the further relaxed becomes the feasibility requirement of the robust solution .    in this work we present an alternative to constructing a specific uncertainty set @xmath1 .",
    "instead , we only assume knowledge of a nominal ( undisturbed ) scenario , and consider a set of possible uncertainty sets of varying size based on this scenario",
    ". that is , a decision maker does not need to determine the size of uncertainty ( a task that is usually outside his expertise ) .",
    "our approach constructs a solution for which the worst - case objective with respect to any possible uncertainty set performs well on average over all uncertainty sizes .    the basic idea of variable - sized uncertainty",
    "was recently introduced in @xcite .",
    "there , the aim is to construct a set of robust candidate solutions that requires the decision maker to chose one that suits him best . in our setting",
    ", we consider all uncertainty sizes simultaneously , and generate a single solution as a compromise approach to the unknown uncertainty .",
    "we call this setting the _ compromise approach to variable - sized uncertainty_.    we focus on combinatorial optimization problems with uncertainty in the objective function , and consider both min - max and min - max regret robustness ( see @xcite ) .",
    "this work is structured as follows . in section  [ sec : var ] , we briefly formalize the setting of variable - sized uncertainty .",
    "we then introduce our new compromise approach for min - max robustness in section  [ sec : comp ] , and for the more involved case of min - max regret robustness in section  [ sec : comp2 ] .",
    "we present complexity results for the selection problem , the minimum spanning tree problem , and the shortest path problem in section  [ sec : probs ] . in section  [ sec : exp ] , we evaluate our approach in a computation experiment , before concluding this paper in section  [ sec : conc ] .",
    "we briefly summarize the setting of @xcite .",
    "consider an uncertain combinatorial problem of the form @xmath2 with @xmath3 , and an uncertainty set @xmath4 that is parameterized by some size @xmath5 . for example ,    * interval - based uncertainty @xmath6 } [ ( 1-{\\lambda})\\hat{c}_i,(1+{\\lambda})\\hat{c}_i]$ ] with @xmath7 $ ] , or * ellipsoidal uncertainty @xmath8 with @xmath9 .",
    "we call @xmath10 the _ nominal scenario _ , and any @xmath11 that is a minimizer of p(@xmath10 ) a _ nominal solution_.    in variable - sized uncertainty , we want to find a set of solutions @xmath12 that contains an optimal solution to each robust problems over all @xmath13 . here ,",
    "the robust problem is either given by the min - max counterpart @xmath14 or the min - max regret counterpart @xmath15 in the case of min - max robustness , such a set can be found through methods from multi - objective optimization in @xmath16 , where @xmath17 denotes the complexity of the nominal problem , for many reasonable uncertainty sets",
    ". however , @xmath18 may be exponentially large . furthermore , in some settings , a set of solutions that would require a decision maker to make the final choice may not be desirable , but instead a single solution that represents a good trade - off over all values for @xmath13 is sought .",
    "in this paper we are interested in finding one single solution that performs well over all possible uncertainty sizes @xmath5 . to this end , we consider the problem @xmath19 for some weight function @xmath20 , such that @xmath21 is well - defined .",
    "we call this problem the compromise approach to variable - sized uncertainty .",
    "the weight function @xmath22 can be used to include decision maker preferences ; e.g. , it is possible to give more weight to smaller disturbances and less to large disturbances . if a probability distribution over the uncertainty size were known , it could be used to determine @xmath22 . in the following , we consider ( c ) for different shapes of @xmath23 .",
    "[ th1 ] let @xmath6 } [ ( 1-{\\lambda})\\hat{c}_i,(1+{\\lambda})\\hat{c}_i]$ ] be an interval - based uncertainty set with @xmath24 $ ] . then , a nominal solution @xmath25 is an optimal solution of ( c ) .    as @xmath26",
    ", we get @xmath27 therefore , a minimizer of the nominal problem with costs @xmath10 is also a minimizer of ( c ) .",
    "[ lem1 ] for an ellipsoidal uncertainty set @xmath28 with @xmath29 , it holds that @xmath30    this result has been shown in @xcite for @xmath31 .",
    "the proof holds analogously .",
    "[ th2 ] let @xmath32 be an ellipsoidal uncertainty set with @xmath33 .",
    "then , an optimal solution to ( c ) can be found by solving a single robust problem with ellipsoidal uncertainty .",
    "using lemma  [ lem1 ] , we find @xmath34 to find a minimizer of @xmath21 , we can therefore solve the robust counterpart of ( p ) using an uncertainty set @xmath35 with @xmath36 .",
    "note that @xmath37 , if @xmath38 , i.e. , the compromise solution simply hedges against the average size of the uncertainty .",
    "in general , recall that this formula gives the centroid of the curve defined by @xmath22 .    the results of theorems  [ th1 ] and [ th2 ] show that compromise solutions are easy to compute , as the resulting problems have a simple structure .",
    "this is due to the linearity of the robust objective value in the uncertainty size @xmath13 .",
    "such linearity does not exist for min - max regret , as is discussed in the following section .",
    "we now consider the compromise approach in the min - max regret setting . in classic min - max regret ,",
    "one considers the problem @xmath39 with @xmath40 . in the following ,",
    "we restrict the analysis to the better - researched interval uncertainty sets @xmath6 } [ ( 1-{\\lambda})\\hat{c}_i,(1+{\\lambda})\\hat{c}_i]$ ] .",
    "ellipsoidal uncertainty have been introduced in min - max regret only recently ( see @xcite ) .",
    "the compromise approach to variable - sized uncertainty becomes @xmath41 to simplify the presentation , we assume @xmath42 $ ] and @xmath38 for all @xmath43 in the following .",
    "all results can be directly extended to piecewise linear functions @xmath22 with polynomially many changepoints .",
    "we first discuss the objective function @xmath21 for some fixed @xmath44 .",
    "note that @xmath45 } \\hat{c}_i ( 1-{\\lambda}+ 2{\\lambda}x_i ) y_i.\\ ] ] hence , @xmath46 is a piecewise linear function in @xmath13 , where every possible regret solution @xmath47 defines an affine linear regret function @xmath48 , with @xmath49    .,scaledwidth=60.0% ]    figure  [ fig1 ] illustrates the objective function . in red is the maximum over all regret functions , which defines @xmath21 . on the interval",
    "@xmath50 $ ] , the regret of some solution @xmath51 is defined through @xmath52 , while solution @xmath53 defines the regret on @xmath54 $ ] , and @xmath55 defines the regret on @xmath56 $ ] . in this case , we can hence compute @xmath57 in general , to compute @xmath21 , we need to determine all relevant regret solutions @xmath47 , and the intersections of the resulting regret functions .",
    "let @xmath58 be the set of changepoints of the piecewise linear function @xmath59 . to formulate problem ( c ) as a linear integer program",
    ", we use a set @xmath60 . as",
    "@xmath61 is a finite set , there always exists a set @xmath62 that is finite .",
    "in general , it may contain exponentially many elements .",
    "for the ease of notation , we assume @xmath63 with @xmath64 and @xmath65 . as a first approach",
    ", we model @xmath21 by using all possible regret solutions @xmath66",
    ". @xmath67 }",
    "( 1+{\\overline{\\lambda}}_j)\\hat{c}_i x_i - \\sum_{i\\in[n ] } ( 1-{\\overline{\\lambda}}_j + 2{\\overline{\\lambda}}_jx_i)\\hat{c}_i y^\\ell_i & \\forall \\lambda_j \\in{\\overline{\\lambda } } , y^\\ell\\in{\\mathcal{x}}\\nonumber\\\\ & x\\in{\\mathcal{x}}\\nonumber\\end{aligned}\\ ] ] where @xmath68 .",
    "if ( p ) has a duality gap of zero , i.e. , if solving the dual of the linear relaxation also gives an optimal solution to ( p ) , this formulation can be simplified .",
    "examples where this is the case include the shortest path problem , or the minimum spanning tree problem .",
    "let us assume that the linear relaxation of @xmath61 is given by @xmath69    for the regret problem @xmath70 we may then write the following equivalent problem ( see @xcite ) : @xmath71 using this reformulation , we find the following program for ( c ) @xmath72 for binary variables @xmath51 , the product @xmath73 can then be linearized .",
    "if a set @xmath62 can be found that is of polynomial size , this is a compact formulation .",
    "in general , constraints and variables can be added in an iterative algorithm that generates new candidate values for @xmath74 in problem  .",
    "if the zero duality gap assumption does not hold , we can use formulation  , where both values for @xmath13 and regret solutions @xmath47 need to be generated .",
    "this approach is explained in the following section .      in the following",
    "we describe how to compute the set @xmath75 of changepoints of @xmath59 .",
    "this is then used to solve formulation   in the case of a zero duality gap for ( p ) as described in algorithm  [ alg : c ] .",
    "@xmath76 , @xmath77 [ a1s1 ] solve formulation   using @xmath62 .",
    "let the solution be @xmath78 , and the objective value @xmath79.[algret ] compute @xmath80 .",
    "let the resulting changepoints be @xmath81 , and the objective value @xmath82 .",
    "[ a1s3 ] * end * : @xmath78 is an optimal solution . [ a1s5 ] @xmath83 [ a1s7 ] @xmath84 go to [ algret ]    the algorithm begins with a starting set @xmath85 as a guess for relevant changepoints ( any other set could be used here ) . using the current set @xmath62 , it then solves formulation  .",
    "as not all constraints of the problem are present , this is a problem relaxation .",
    "accordingly , the objective value that is found is only a lower bound @xmath79 on the true optimal objective value of the problem . to evaluate the resulting candidate solution",
    "@xmath78 , we compute @xmath80 in step  [ a1s3 ] . the sub - algorithm for this purpose",
    "is explained below .",
    "as @xmath78 is a feasible solution to ( c ) , @xmath80 gives an upper bound @xmath82 on the optimal objective value .",
    "hence , if lower and upper bound coincide , an optimal solution has been found . otherwise , we extend the set @xmath62 in step  [ a1s7 ] and repeat the procedure .    if ( p ) has a duality gap larger than zero , the same algorithm can be used with the slight adjustment that problem   is solved in step  [ algret ] . to this end , also regret solutions @xmath86 generated in the computation of @xmath80 need to be collected .",
    "we describe the procedure to compute @xmath21 in algorithm  [ alg : val ] .",
    "@xmath87 , @xmath88 @xmath89 [ j1 ] solve ( p ) with costs @xmath90 .",
    "let @xmath47 be the resulting solution .",
    "@xmath91 @xmath92 change @xmath93 false calculate @xmath74 as the point where the affine linear regret functions defined by @xmath94 and @xmath95 intersect .",
    "@xmath97 change @xmath93 true go to [ j1 ] reduce @xmath75 and @xmath98 such that only changepoints and regret functions remain that define the maximum over all affine linear functions .",
    "@xmath75 , @xmath98    we begin with only two regret functions , for the extreme points @xmath99 .",
    "the resulting two regret functions will intersect at one new candidate changepoint @xmath74 .",
    "we find the regret solution @xmath47 maximizing the regret at this point by solving a problem of type ( p ) .",
    "we then repeat this process by iteratively calculating the regret at all current intersection points .",
    "note that if there exists any regret function that is larger than all current regret functions at some point @xmath74 , then it is also larger than all current functions at the intersection point between two of them .",
    "hence , algorithm  [ alg : val ] finds all relevant changepoints @xmath13 .",
    "as it may also produce unnecessary candidates @xmath13 , we reduce the solution sets at the end to contain only those changepoints and regret functions that define the maximum .",
    "the minimum selection problem is given by @xmath100 } x_i = p,\\ x\\in\\{0,1\\}^n\\right\\}\\ ] ] and has been frequently studied in the literature on min - max regret optimization ( see @xcite ) . the min - max regret problem can be solved in @xmath101 time , see @xcite .",
    "we show that also problem ( c ) can be solved in polynomial time .",
    "let @xmath102 } [ ( 1-{\\lambda})\\hat{c}_i,(1+{\\lambda})\\hat{c}_i]$ ] for a fixed @xmath13 .",
    "then @xmath25 is an optimal solution to the min - max regret selection problem .",
    "we assume that items are sorted with respect to @xmath10 .",
    "let @xmath103 be an optimal solution with @xmath104 for an item @xmath105 .",
    "we assume @xmath106 is the smallest such item .",
    "then there exists some @xmath107 with @xmath108 .",
    "consider the solution @xmath109 with @xmath110 for @xmath111 and @xmath112 , @xmath113 .",
    "let @xmath114 be a regret solution for @xmath103 .",
    "we can assume that @xmath115 , as @xmath116 must be one of the @xmath117 cheapest items .",
    "we can also assume @xmath118 , as @xmath119 is not among the @xmath117 cheapest items .",
    "let @xmath120 be the regret solution for @xmath109 .",
    "the solutions @xmath103 and @xmath109 differ only on the two items @xmath106 and @xmath121 .",
    "hence , the following cases are possible :    * case @xmath122 and @xmath123 , i.e. , @xmath124",
    ". we have @xmath125 * case @xmath126 and @xmath127 , @xmath128 for some @xmath129 with @xmath130 .",
    "note that this means @xmath131 , as otherwise , the regret solution of @xmath114 could be improved .",
    "hence , @xmath132 * case @xmath133 and @xmath134 for some @xmath135 with @xmath136 . as the costs of item @xmath106 have increased by using solution @xmath109 instead of @xmath103 ,",
    "the resulting two cases are analogue to the two cases above .",
    "overall , solution @xmath109 has regret less or equal to the regret of @xmath103 .    note that this result does not hold for general interval uncertainty sets , where the problem is np - hard .",
    "it also does not necessarily hold for other combinatorial optimization problems ; e.g. , a counter - example for the assignment problem can be found in @xcite .    finally , it remains to show that @xmath21 can also be computed in polynomial time .",
    "for the compromise min - max regret problem of minimum selection it holds that @xmath137 for any fixed @xmath44 , and there is a set @xmath62 with @xmath138 .    if @xmath51 is fixed , then there are @xmath117 items @xmath106 with costs @xmath139 , and @xmath140 items @xmath106 with costs @xmath141",
    ". the regret solution is determined by the @xmath117 smallest items .",
    "accordingly , when @xmath13 increases , the regret solution only changes if an item @xmath106 with @xmath142 , that used to be among the @xmath117 smallest items , moves to the @xmath140 largest items , and another item @xmath121 with @xmath143 becomes part of the @xmath117 smallest items .",
    "there are at most @xmath144 values for @xmath13 where this is the case .",
    "we define @xmath62 to consist of all @xmath145 $ ] such that @xmath146 for some @xmath147 $ ] , as only for such values of @xmath13 an optimal regret solution may change . hence , @xmath138 .    as the size of @xmath75",
    "is polynomially bounded , @xmath21 can be computed in polynomial time , and we get the following conclusion .",
    "the compromise min - max regret problem of minimum selection can be solved in polynomial time .",
    "the min - max regret spanning tree problem in a graph @xmath148 has previously been considered , e.g. , in @xcite .",
    "the regret of a fixed solution can be computed in polynomial time , but it is np - hard to find an optimal solution .",
    "we now consider the compromise min - max regret counterpart ( c ) .",
    "let any spanning tree @xmath51 be fixed . to compute @xmath21 , we begin with @xmath149 and calculate a regret spanning tree by solving a nominal problem with costs @xmath10 . recall that this can be done using kruskal s algorithm that considers edges successively according to an increasing sorting @xmath150 with respect to costs .",
    "if @xmath74 increases , edges that are included in @xmath51 have costs @xmath151 ( i.e. , their costs increase ) and edges not in @xmath51 have costs @xmath152 ( i.e. , their costs decrease ) .",
    "kruskal s algorithm will only find a different solution if the sorting of edges change .",
    "as there are @xmath153 edges with increasing costs , and @xmath154 edges with increasing costs , the sorting can change at most @xmath155 times ( note that two edges with increasing costs or two edges with decreasing costs can not change relative positions ) .",
    "we have therefore shown :    a solution to the compromise min - max regret problem of minimum spanning tree can be evaluated in polynomial time .",
    "if the solution @xmath51 is not known , we can still construct a set @xmath62 with size @xmath156 that contains all possible changepoints along the same principle .",
    "we can conclude :    there exists a compact mixed - integer programming formulation for the compromise min - max regret problem of minimum spanning tree .",
    "however , we show in the following that solving the compromise problem is np - hard . to this end",
    ", we use the following result :    @xcite the min - max regret spanning tree problem is np - hard , even if all intervals of uncertainty are equal to @xmath157 $ ] .    note that if all intervals are of the form @xmath158 $ ] , then @xmath159 therefore , the min - max regret problem with costs @xmath157 $ ] is equivalent to the min - max regret problem with any other costs @xmath158 $ ] , in the sense that objective values only differ by a constant factor and both problems have the same set of optimal solutions . in particular , a solution @xmath47 that maximizes the regret of @xmath51 with respect to cost intervals @xmath158 $ ] is also a maximizer of the regret for any other cost intervals @xmath160 $ ] .",
    "we can conclude :    the compromise problem of min - max regret minimum spanning tree is np - hard , even if @xmath38 for all @xmath145 $ ] .",
    "let an instance of the min - max regret spanning tree problem with cost intervals @xmath157 $ ] be given .",
    "consider an instance of the compromise problem with @xmath161 for all @xmath162 , and @xmath38 .",
    "then @xmath163 hence , any minimizer of @xmath21 is also an optimal solution to the min - max regret spanning tree problem .",
    "for the shortest path problem , we consider @xmath61 as the set of all simple @xmath164 paths in a graph @xmath148 ( for the min - max regret problem , see , e.g. , @xcite ) . as for the minimum spanning tree problem ,",
    "the regret of a fixed solution can be computed in polynomial time , but it is np - hard to find an optimal solution .    for the compromise problem ( c ) , we have : @xmath165 we can interpret the minimization problem as a weighted sum of the bicriteria problem @xmath166 the number of solutions we need to generate to compute @xmath21 can therefore be bounded by the number of solutions we can find through such weighted sum computations ( the set of extreme efficient solutions @xmath167 ) .    for the compromise shortest path problem , it holds that @xmath168 .    depending on the graph @xmath169",
    ", the following bounds on the number of extreme efficient solutions @xmath167 ( see , e.g. , @xcite ) can be taken from the literature @xcite :    * for series - parallel graphs , @xmath170 * for layered graphs with width @xmath22 and length @xmath171 , @xmath172 * for acyclic graphs , @xmath173 * for general graphs @xmath174    we can conclude :    a solution to the compromise min - max regret problem of shortest path can be evaluated in polynomial time on series - parallel graphs and layered graphs with fixed width or length .    note that the number of extreme efficient solutions is only an upper bound on @xmath75 . unfortunately , we can not hope to find a better performance than this bound , as the following result demonstrates .    for any bicriteria shortest path instance with costs @xmath175 , @xmath176 for all @xmath162",
    ", there is an instance of ( c ) and a solution @xmath51 where @xmath177 .",
    "let an instance of the bicriteria shortest path problem be given , i.e. , a directed graph @xmath148 with arc costs @xmath178 for all @xmath162 .",
    "as @xmath179 for all @xmath162 , we can assume w.l.o.g . that @xmath180 for all @xmath162 .",
    "we create the following instance of ( c ) .",
    "every arc @xmath181 is substituted by three arcs @xmath182 , @xmath183 and @xmath184 .",
    "we set @xmath185 , @xmath186 and @xmath187 ( see figure  [ fignp ] for an example of such a transformation ) .",
    "let @xmath188 , @xmath189 and @xmath190 contain all edges of the respective type .",
    "additionally , we choose an arbitrary order of edges @xmath191 , and create arcs @xmath192 .",
    "we set costs of these arcs to be a sufficiently large constant @xmath193 .",
    "finally , let @xmath51 be the path that follows all edges in @xmath194 and @xmath189 .",
    "note that edges in @xmath190 can be contracted , but are shown for better readability .",
    "+    note that @xmath193 is sufficiently large so that no regret path @xmath47 will use any edge in @xmath194 .",
    "hence , if @xmath47 uses an edge in @xmath188 , it will also have to use the following edges in @xmath189 and @xmath190 , i.e. , @xmath47 corresponds to a path in the original graph @xmath148 .",
    "the regret of @xmath51 is @xmath195 therefore , if @xmath13 goes from @xmath196 to @xmath197 , all extreme efficient paths in the original graph @xmath169 are used to calculate @xmath46 .",
    "we now consider the complexity of finding a solution @xmath44 that minimizes @xmath21 .",
    "note that the reduction in @xcite uses interval costs of the form @xmath157 $ ] and @xmath198 $ ] , which does not fit into our cost framework @xmath199 $ ] .",
    "instead , we make use of the following result :    @xcite the min - max regret shortest path problem is np - hard for layered graphs with interval costs @xmath157 $ ] .    note that for layered graphs , all paths have the same cardinality .",
    "hence , @xmath200 ( see section  [ sec : mst ] ) , and the problem with costs @xmath157 $ ] is equivalent to the problem with costs @xmath158 $ ] for any @xmath201 .",
    "analog to the last section , we can therefore conclude :    finding an optimal solution to the compromise shortest path problem is np - hard on layered graphs , even if @xmath202 for all @xmath145 $ ] .",
    "in this section we present two experiments on compromise solutions to min - max regret problems with variable - sized uncertainty .",
    "the first experiment is concerned with the computational effort to find such a solution using the iterative algorithms presented in section  [ sec : algo ] . in the second experiment",
    "we compare these solutions to the alternatives of using classic regret solutions for various uncertainty set sizes .",
    "both experiments are conducted on shortest path instances of two types .",
    "the first type consists of complete layered graphs .",
    "we parameterize such instances by the number of layers , width and cost types .",
    "each graph consists of a source node , a sink node , and node layers of equal width between . for @xmath203 layers of width @xmath204 ,",
    "an instance has a total of @xmath205 nodes and @xmath206 edges .",
    "we use @xmath207 to @xmath208 in steps of size 5 , and @xmath209 .",
    "graph sizes thus vary from 32 nodes and 130 edges to 1,122 nodes and 22,040 edges .",
    "edges connect all nodes of one layer to the nodes of the next layer . source and sink",
    "are completely connected to the first and last layer , respectively .",
    "we considered two types of cost structures to generate @xmath10 . for type",
    "a , all costs are chosen uniformly from the interval @xmath210 $ ] . for type b costs ,",
    "we generate nominal costs in @xmath211\\cup[70,100]$ ] , i.e. , they are either low or high .    in total , there are @xmath212 parameter combinations . for each combination ,",
    "we generate 20 instances , i.e. , a total of 1,760 instances .",
    "the second type consists of graphs with two paths , that are linked by diagonal edges .",
    "for some length parameter @xmath213 , we generated two separate paths from a node @xmath214 to a node @xmath215 , each with @xmath213 nodes between .",
    "we then generate diagonal edges in the following way . on one of the two paths , we choose the @xmath106th node uniformly randomly .",
    "we then connect this node with the @xmath121th node on the other path , where @xmath216 .",
    "the @xmath121th node is chosen with probability @xmath217 , i.e. , long diagonal edges are unlikely ( ensuring that @xmath121 is at most @xmath213 )",
    ".    edges along the two base paths have length chosen uniformly from the interval @xmath210 $ ] . for diagonal edges ,",
    "we determine their length by sampling from the same interval @xmath218 times , and adding these values , i.e. , all paths have the same expected length .",
    "we generate instances with length @xmath213 from 50 to 850 in steps of 100 , and set the number of diagonal edges to be @xmath219 for @xmath220 .",
    "the smallest instances therefore contain 102 nodes and 105 edges ; the largest instances contain 1,702 nodes and 1,830 edges . for each parameter combination ,",
    "we generate 20 instances , i.e. , a total of @xmath221 instances .",
    "the classic min - max regret shortest path problem on instances of both types is known to be np - hard , see @xcite .",
    "we investigate both types , as we expect the nominal solution to show a different performance : for layered graphs , the nominal solution is also optimal for @xmath222 , as for every path there also exists a disjoint path .",
    "therefore , the regret of a path @xmath223 with respect to @xmath222 is @xmath224 . for the second type of instances , a good solution with respect to min - max regret",
    "can be expected to intersect with as many other paths as possible .",
    "we can therefore expect the nominal solution to be different to the optimal solution of @xmath222 .",
    "all experiments were conducted using one core of a computer with an intel xeon e5 - 2670 processor , running at 2.60 ghz with 20 mb cache , with ubuntu 12.04 and cplex v.12.6 .",
    "we solve the compromise approach to variable - sized uncertainty for each instance using the algorithms described in section  [ sec : algo ] and record the computation times .",
    "average computation times in seconds are presented in table  [ tab1 ] . in each column",
    "we average over all instances for which this parameter is fixed ; i.e. , in column  width 5  we show the results over all 440 instances that have a width of 5 , broken down into classes of different length .",
    "the results indicate that computation times are still reasonable given the complexity of the problem , and mostly depend on the size of the instance ( width parameter ) and the density of the graph , while the cost structure has no significant impact on computation times .",
    ".average computation times to solve ( c ) in seconds . [ cols= \" > ,",
    "> , > , > , > , > , > , > \" , ]        in our second experiment , we compare the compromise solution to the nominal solution ( which is also the min - max regret solution with respect to the uncertainty sets @xmath225 and @xmath222 ) , and to the min - max regret solutions with respect to @xmath226 , @xmath227 and @xmath228 .",
    "to compare solutions , we calculate the regret of the compromise solution for values of @xmath13 in @xmath157 $ ] .",
    "we take this regret as the baseline . for all other solutions",
    ", we also calculate the regret depending on @xmath13 , and compute the difference to the baseline .",
    "we then compute the average differences for fixed @xmath13 over all instances of the same size .",
    "the resulting average differences are shown in figure  [ fig : exp ] for four instance sizes . to set the differences in perspective , the average regret ranges from @xmath225 to @xmath222 of the compromise solutions",
    "are shown in the captions .",
    "+    by construction , a min - max regret solution with respect to @xmath229 has the smallest regret for this @xmath230 .",
    "generally , all presented solutions have higher regret than the nominal solution for small and for large values of @xmath13 , and perform better in between . by construction",
    ", the compromise solution has the smallest integral under the shown curve .",
    "it can be seen that it presents an interesting alternative to the other solutions by having a relatively small regret for small and large values of @xmath13 , but also a relatively good performance in between .",
    "we generate the same plots as in section  [ sec : plots ] using the two - path instances .",
    "recall that in this case , the nominal solution is not necessarily an optimal solution with respect to @xmath222 .",
    "we therefore include an additional line for @xmath222 in figure  [ fig : exp2 ] .",
    "+    it can be seen that the nominal solution performs different to the last experiment ; the regret increases with @xmath74 in a rate that part of the line needed to be cut off from the plot for better readability .",
    "the solution to @xmath227 performs very close to the compromise solution overall .",
    "additionally , the scale of the plots show that differences in regret are much larger than in the previous experiment .",
    "overall , it can be seen that using a robust solution plays a more significant role than in the previous experiment , as the nominal solution shows poor performance .",
    "the solutions that hedge against large uncertainty sets ( @xmath228 and @xmath231 ) are relatively expensive for small uncertainty sets and vice versa .",
    "the compromise solution ( as @xmath227 , in this case ) presents a reasonable trade - off over all uncertainty sizes .",
    "classic robust optimization approaches assume that the uncertainty set @xmath1 is part of the input , i.e. , it is produced using some expert knowledge in a previous step .",
    "if the modeler has access to a large set of data , it is possible to follow recently developed data - driven approaches to design a suitable set @xmath1 . in our approach , we remove the necessity of defining @xmath1 by using a single nominal scenario , and considering all uncertainty sets generated by deviating coefficients of different size simultaneously .",
    "the aim of the compromise approach is to find a single solution that performs well on average in the robust sense over all possible uncertainty set sizes .    for min - max combinatorial problems",
    ", we showed that our approach can be reduced to solving a classic robust problem of particular size .",
    "the setting is more involved for min - max regret problems , where the regret objective is a piecewise linear function in the uncertainty size .",
    "we presented a general solution algorithm for this problem , which is based on a reduced master problem , and the iterative solution of subproblems of nominal structure .    for specific problems ,",
    "positive and negative complexity results were demonstrated .",
    "the compromise selection problem can be solved in polynomial time .",
    "solutions to the compromise minimum spanning tree problem can be evaluated in polynomial time , but it is np - hard to find an optimal solution .",
    "for compromise shortest path problems , the same results hold in case of layered graphs ; however , for general graphs , it is still an open problem if there exist instances where exponentially many regret solutions are involved in the evaluation problem .    in computational experiments we highlighted the value of our approach in comparison with different min - max regret solutions , and showed that computation times can be within few minutes for instances with up to 22,000 edges .",
    "m.  goerigk and a.  schbel .",
    "algorithm engineering in robust optimization . in l.",
    "kliemann and p.  sanders , editors , _ algorithm engineering : selected results and surveys _ , volume 9220 of _ lncs state of the art_. springer , 2016 .",
    "final volume for dfg priority program 1307 .",
    "a.  kasperski and p.  zieliski .",
    "robust discrete optimization under discrete and interval uncertainty : a survey . in _ robustness analysis in decision aiding , optimization , and analytics _ , pages 113143 .",
    "springer , 2016 ."
  ],
  "abstract_text": [
    "<S> in classic robust optimization , it is assumed that a set of possible parameter realizations , the uncertainty set , is modeled in a previous step and part of the input . as recent work has shown , finding the most suitable uncertainty set is in itself already a difficult task . </S>",
    "<S> we consider robust problems where the uncertainty set is not completely defined . </S>",
    "<S> only the shape is known , but not its size . </S>",
    "<S> such a setting is known as variable - sized uncertainty .    in this work we present an approach how to find a single robust solution , that performs well on average over all possible </S>",
    "<S> uncertainty set sizes . </S>",
    "<S> we demonstrate that this approach can be solved efficiently for min - max robust optimization , but is more involved in the case of min - max regret , where positive and negative complexity results for the selection problem , the minimum spanning tree problem , and the shortest path problem are provided . </S>",
    "<S> we introduce an iterative solution procedure , and evaluate its performance in an experimental comparison .    </S>",
    "<S> * keywords : * robust combinatorial optimization ; min - max regret ; variable - sized uncertainty </S>"
  ]
}