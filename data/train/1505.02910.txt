{
  "article_text": [
    "rademacher complexities ( @xcite , @xcite ) play an important role in the widely used concentration - based approach to statistical learning theory @xcite , which is closely related to the analysis of empirical processes @xcite .",
    "they measure a complexity of function classes and provide data - dependent risk bounds in the standard i.i.d .",
    "framework of inductive learning , thanks to symmetrization and concentration inequalities .",
    "recently , a number of attempts were made to apply this machinery also to the _ transductive learning _ setting @xcite .",
    "in particular , the authors of @xcite introduced a notion of _ transductive rademacher complexity _ and provided an extensive study of its properties , as well as general transductive risk bounds based on this new complexity measure .    in the transductive learning",
    ", a learner observes @xmath0 labelled training points and @xmath1 unlabelled test points . the goal is to give correct answers on the test points .",
    "transductive learning naturally appears in many modern large - scale applications , including text mining , recommender systems , and computer vision , where often the objects to be classified are available beforehand .",
    "there are two different settings of transductive learning , defined by v.vapnik in his book ( * ? ? ?",
    "the first one assumes that all the objects from the training and test sets are generated i.i.d . from an unknown distribution @xmath2 .",
    "the second one is _ distribution free _ , and it assumes that the training and test sets are realized by a uniform and random partition of a fixed and finite general population of cardinality @xmath3 into two disjoint subsets of cardinalities @xmath0 and  @xmath1 ; moreover , no assumptions are made regarding the underlying source of this general population .",
    "the second setting has gained much attention ( @xcite , @xcite , @xcite , @xcite , @xcite , and @xcite ) , probably due to the fact that any upper risk bound for this setting directly implies a risk bound also for the first setting ( * ? ? ?",
    "* theorem 8.1 ) .",
    "in essence , the second setting studies uniform deviations of risks computed on two disjoint finite samples . following vapnik s discussion in @xcite , we would also like to emphasize that the second setting of transductive learning naturally appears as a middle step in proofs of the standard inductive risk bounds , as a result of symmetrization or the so - called _",
    "double - sample _ trick .",
    "this way better transductive risk bounds also translate into better inductive ones .",
    "an important difference between the two settings discussed above lies in the fact that the @xmath0 elements of the training set in the second setting are interdependent , because they are sampled uniformly _ without replacement _ from the general population . as a result",
    ", the standard techniques developed for inductive learning , including concentration and rademacher complexities mentioned in the beginning , can not be applied in this setting , since they are heavily based on the i.i.d .",
    "therefore , it is important to study empirical processes in the setting of sampling without replacement .    * previous work . *",
    "a large step in this direction was made in @xcite , where the authors presented a version of mcdiarmid s bounded difference inequality  @xcite for sampling without replacement together with the transductive rademacher complexity ( trc ) . as a main application the authors derived an upper bound on the binary test error of a transductive learning algorithm in terms of trc .",
    "however , the analysis of @xcite has a number of shortcomings .",
    "most importantly , trc depends on the unknown labels of the test set . in order to obtain computable risk bounds",
    ", the authors resorted to the contraction inequality @xcite , which is known to be a loose step @xcite , since it destroys any dependence on the labels .",
    "another line of work was presented in @xcite , where variants of talagrand s concentration inequality were derived for the setting of sampling without replacement .",
    "these inequalities were then applied to achieve transductive risk bounds with fast rates of convergence @xmath4 , following a _ localized _ approach  @xcite .",
    "in contrast , in this work we consider only the worst - case analysis based on the _ global _ complexity measures .",
    "an analysis under additional assumptions on the problem at hand , including mammen - tsybakov type low noise conditions @xcite , is an interesting open question and left for future work .",
    "* summary of our results .",
    "* this paper continues the analysis of empirical processes indexed by arbitrary classes of uniformly bounded functions in the setting of sampling without replacement , initiated by @xcite .",
    "we introduce a new complexity measure called _ permutational rademacher complexity _ ( prc ) and argue that it captures the nature of this setting very well . due to space limitations we present the analysis of prc only for the special case when the training and test sets have the same size @xmath5 , which is nonetheless sufficiently illustrative case , but we defer them to a future extended version of this paper . ] .",
    "we prove a novel symmetrization inequality ( theorem [ thm : tsym ] ) , which shows that the expected prc and the expected suprema of empirical processes when sampling without replacement are equivalent up to multiplicative constants .",
    "quite remarkably , the new upper and lower bounds ( the latter is often called _ desymmetrization inequality _ ) both hold without any additive terms when @xmath5 , in contrast to the standard i.i.d . setting , where an additive term of order @xmath6 is unavoidable in the lower bound . for trc",
    "even the upper symmetrization inequality ( * ? ? ?",
    "* lemma 4 ) includes an additive term of the order @xmath6 and no desymmetrization inequality is known .",
    "this suggests that prc may be a more suitable complexity measure for transductive learning .",
    "we would also like to note that the proof of our new symmetrization inequality is surprisingly simple , compared to the one presented in @xcite .",
    "next we compare prc with other popular complexity measures used in statistical learning theory .",
    "in particular , we provide achievable upper and lower bounds , relating prc to the conditional rademacher complexity ( theorem  [ thm : dagstuhl - relation ] ) .",
    "these bounds show that the prc is upper and lower bounded by the conditional rademacher complexity up to additive terms of orders @xmath4 and @xmath6 respectively , which are achievable ( lemma [ lemma : achievable ] ) .",
    "in addition to this , theorem  [ thm : dagstuhl - relation ] also significantly improves bounds on the complexity measure called _ maximum discrepancy _ presented in ( * ? ? ? * lemma 3 ) .",
    "we also provide a comparison between expected prc and trc ( corollary [ corollary : comparison - prc - trc ] ) , which shows that their values are close up to small multiplicative constants and additive terms of order @xmath6 .",
    "finally , we apply these results to obtain a new computable data - dependent risk bound for transductive learning based on the prc ( theorem [ thm : risk - bound ] ) , which holds for any bounded loss functions .",
    "we conclude by discussing the advantages of the new risk bound over the previously best known one of @xcite .",
    "we will use calligraphic symbols to denote sets , with subscripts indicating their cardinalities : @xmath7 . for any function @xmath8",
    "we will denote its average value computed on a finite set @xmath9 by @xmath10 . in what follows",
    "we will consider an arbitrary space @xmath11 ( for instance , a space of input - output pairs ) and class @xmath12 of functions ( for instance , loss functions ) mapping @xmath11 to @xmath13 .",
    "most of the proofs are deferred to the last section for improved readability .",
    "arguably , one of the most popular complexity measures used in statistical learning theory is the rademacher complexity ( @xcite , @xcite , @xcite ) :    fix any subset @xmath14 .",
    "the following random quantity is commonly known as a _",
    "conditional rademacher complexity _ : @xmath15,\\enspace\\ ] ] where @xmath16 are i.i.d .",
    "rademacher signs , taking values @xmath17 with probabilities @xmath18 . when the set @xmath19 is clear from the context we will simply write @xmath20 .",
    "as discussed in the introduction , rademacher complexities play an important role in the analysis of empirical processes and statistical learning theory .",
    "however , this measure of complexity was devised mainly for the i.i.d . setting , which is different from our setting of sampling without replacement .",
    "the following complexity measure was introduced in @xcite to overcome this issue :    [ def : trc ] fix any set @xmath21 , positive integers @xmath22 such that @xmath23 , and @xmath24 $ ] . the following quantity is called _ transductive rademacher complexity _ ( trc ) : @xmath25,\\enspace\\ ] ] where @xmath26 are i.i.d .",
    "random variables taking values @xmath27 with probabilities @xmath28 and @xmath29 with probability @xmath30 .",
    "we summarize the importance of these two complexity measures in the analysis of empirical processes when sampling without replacement in the following result :    [ thm : overview ] fix an subset @xmath31 and let @xmath32 elements of @xmath19 be sampled uniformly without replacement from @xmath33 . also let @xmath0 elements of @xmath34 be sampled uniformly with replacement from @xmath33 . denote @xmath35 with @xmath36 .",
    "the following upper bound in terms of the i.i.d .",
    "rademacher complexity was provided in @xcite : @xmath37.\\enspace\\ ] ] the following bound in terms of trc was provided in @xcite .",
    "assume that functions in @xmath12 are uniformly bounded by @xmath38 .",
    "then for @xmath39 and @xmath40 : @xmath41    while did not explicitly appear in @xcite , it can be immediately derived using ( * ? ? ?",
    "* corollary 8) and i.i.d .",
    "symmetrization of ( * ? ? ?",
    "* theorem 2.1 ) .",
    "finally , we introduce our new complexity measure :    [ def : prc ] let @xmath42 be any fixed set of cardinality @xmath0 . for any @xmath43 the following quantity will be called a _",
    "permutational rademacher complexity ( prc ) _ : @xmath44 where @xmath45 is a random subset of @xmath19 containing @xmath46 elements sampled uniformly without replacement and @xmath47 .",
    "when the set @xmath19 is clear from the context we will simply write @xmath48 .    the name prc is explained by the fact that if @xmath0 is even then the definitions of @xmath49 and @xmath50 are very similar .",
    "indeed , the only difference is that the expectation in the prc is over the randomly permuted sequence containing _ equal number _ of @xmath51 and @xmath52 , whereas in rademacher complexity the average is w.r.t .",
    "all the possible sequences of signs .",
    "the term  permutation complexity \" has already appeared in @xcite , where it was used to denote a novel complexity measure for a model selection .",
    "however , this measure was specific to the i.i.d . setting and _ binary _ loss . moreover , the bounds presented in @xcite were of the same order as the risk bounds based on the rademacher complexity with worse constants in the slack term .",
    "we start with showing a version of the i.i.d .",
    "symmetrization inequality ( references can be found in @xcite , @xcite ) for the setting of sampling without replacement .",
    "it shows that the expected supremum of empirical processes in this setting is up to multiplicative constants equivalent to the expected prc .",
    "[ thm : tsym ] fix an subset @xmath31 and let @xmath32 elements of @xmath19 be sampled uniformly without replacement from @xmath33 . denote @xmath35 with @xmath36 .",
    "if @xmath5 and @xmath0 is even then for any @xmath53 : @xmath54 \\leq { \\mathop{\\mathbb{e}}}_{{\\mathcal{z}}_m}\\sup_{f\\in f } \\left ( { \\bar{f}}({\\mathcal{z}}_u ) - { \\bar{f}}({\\mathcal{z}}_m ) \\right ) \\leq { \\mathop{\\mathbb{e}}}_{{\\mathcal{z}}_m}\\left[{\\hat{q}}_{m , n}(f,{\\mathcal{z}}_m)\\right].\\enspace\\ ] ] the inequalities also hold if we include absolute values inside the suprema .",
    "the proof can be found in sect .",
    "[ sect : proof - symmetrization ] .",
    "this inequality should be compared to the previously known complexity bounds of theorem  [ thm : overview ] .",
    "first of all , in contrast to and the new bound provides a two sided control , which shows that prc is a  correct \" complexity measure for our setting .",
    "it is also remarkable that the lower bound ( commonly known as the _ desymmetrization inequality _ ) does not include any additive terms , since in the standard i.i.d . setting the lower bound",
    "holds only up to an additive term of order @xmath6 ( * ? ? ?",
    "also note that this result does not assume the boundedness of functions in @xmath12 , which is a necessary assumptions both in and in the i.i.d .",
    "desymmetrization inequality .",
    "next we compare prc with the conditional rademacher complexity :    [ thm : dagstuhl - relation ] let @xmath42 be any fixed set of even cardinality @xmath0 . then : @xmath55 moreover , if the functions in @xmath12 are absolutely bounded by @xmath38 then @xmath56 the results also hold if we include absolute values inside suprema in @xmath57 .    conceptually the proof is based on the coupling between a sequence @xmath58 of i.i.d .",
    "rademacher signs and a uniform random permutation @xmath59 of a set containing @xmath60 plus and @xmath60 minus signs .",
    "this idea was inspired by the techniques used in @xcite .",
    "the detailed proof can be found in sect .",
    "[ sect : proof - dagstuhl ] .",
    "note that a typical order of @xmath20 is @xmath6 , thus the multiplicative upper bound can be much tighter than the upper bound of",
    ". we would also like to note that theorem [ thm : dagstuhl - relation ] significantly improves bounds of lemma 3 in  @xcite , which relate the so - called _ maximal discrepancy _ measure of the class @xmath12 to its rademacher complexity ( for the further discussion we refer to appendix ) .",
    "our next result shows that bounds of theorem [ thm : dagstuhl - relation ] are essentially tight .",
    "[ lemma : achievable ] let @xmath61 with even @xmath0 .",
    "there are two finite classes @xmath62 and @xmath63 of functions mapping @xmath64 to @xmath13 and absolutely bounded by @xmath65 , such that : @xmath66 @xmath67    the proof can be found in sect .",
    "[ sect : proof - lemma - counterex ] .",
    "inequalities simultaneously show that ( a ) the order @xmath6 of the additive bound can not be improved , and ( b ) the multiplicative upper bound can not be reversed . moreover , it can be shown using that the factor appearing in can not be improved to @xmath68 .",
    "finally , we compare prc to the transductive rademacher complexity :    [ lem : comparison ] fix any set @xmath21 .",
    "if @xmath5 and @xmath23 : @xmath69    the upper bound was presented in ( * ? ? ?",
    "* lemma 1 ) . for the lower",
    "bound , notice that if @xmath70 the i.i.d .",
    "signs @xmath71 presented in definition [ def : trc ] have the same distribution as @xmath72 , where @xmath73 are i.i.d .",
    "rademacher signs and @xmath74 are i.i.d .",
    "bernoulli random variables with parameters @xmath18 .",
    "thus , jensen s inequality gives : @xmath75 \\geq \\frac{4}{n } { \\mathop{\\mathbb{e}}}_{\\vec \\epsilon } \\left [ \\sup_{f\\in f } \\sum_{i=1}^{m + u } \\epsilon_i",
    "\\frac12 f(z_i ) \\right].\\enspace\\end{aligned}\\ ] ]    together with theorems [ thm : tsym ] and [ thm : dagstuhl - relation ] this result shows that when @xmath5 the prc can not be much larger than transductive rademacher complexity :    [ corollary : comparison - prc - trc ] using notations of theorem [ thm : tsym ] , we have : @xmath76 \\leq \\left(2 + \\frac{4}{\\sqrt{2\\pi",
    "n } - 2}\\right)\\,{\\hat{r}^{td}}_{m+u}(f , { \\mathcal{z}}_{n } , 1/4).\\enspace\\ ] ] if functions in @xmath12 are uniformly bounded by @xmath38 then we also have a lower bound : @xmath76 \\geq \\frac12{\\hat{r}^{td}}_{m+u}(f , { \\mathcal{z}}_{n } , 1/4 ) + \\frac{2b}{\\sqrt{n}}.\\enspace\\ ] ]    simply notice that @xmath77 = { \\hat{q}}_{n , m}(f,{\\mathcal{z}}_n)$ ] .",
    "next we will use the results of sect . [",
    "section : results ] to obtain a new transductive risk bound .",
    "first we will shortly describe the setting .",
    "we will consider the second , distribution - free setting of transductive learning described in the introduction . fix any finite _ general population _ of input - output pairs @xmath78 , where @xmath79 and @xmath80 are arbitrary input and output spaces .",
    "we make no assumptions regarding underlying source of @xmath33 .",
    "the learner receives the labeled _ training set _",
    "@xmath19 consisting of @xmath32 elements sampled uniformly without replacement from @xmath33 . the remaining _ test set _",
    "@xmath35 is presented to the learner _ without labels _ ( we will use @xmath81 to denote the inputs of @xmath82 ) .",
    "the goal of the learner is to find a predictor in the fixed _ hypothesis class _ @xmath83 based on the training sample @xmath19 and unlabelled test points @xmath81 , which has a small test risk measured using bounded _",
    "loss function _",
    "@xmath84 $ ] .",
    "for @xmath85 and @xmath86 denote @xmath87 and also denote the loss class @xmath88 .",
    "then the test and training risks of @xmath89 are defined as @xmath90 and @xmath91 respectively .",
    "following risk bound in terms of trc was presented in ( * ? ? ?",
    "* corollary 2 ) :    [ thm : risk - bound - ep09 ] if @xmath5 then with probability at least @xmath92 over the random training set @xmath19 any @xmath89 satisfies : @xmath93    using results of sect .",
    "[ section : results ] we obtain the following risk bound :    [ thm : risk - bound ] if @xmath5 and @xmath53 then with probability at least @xmath92 over the random training set @xmath19 any @xmath89 satisfies : @xmath94 + \\sqrt{\\frac{2n\\log(1/\\delta)}{(n-1/2)^2}}.\\enspace\\ ] ] moreover , with probability at least @xmath92 any @xmath89 satisfies : @xmath95    the proof can be found in sect .",
    "[ sect : proof - risk - bound ] .",
    "we conclude by comparing risk bounds of theorems [ thm : risk - bound ] and [ thm : risk - bound - ep09 ] :    \\1 .",
    "first of all , the upper bound of is computable .",
    "this bound is based on the concentration argument , which shows that the expected prc ( appearing in  ) can be nicely estimated using the training set .",
    "meanwhile , the upper bound of   depends on the _ unknown _ labels of the test set through trc . in order to make it computable",
    "the authors of @xcite resorted to the contraction inequality , which allows to drop any dependence on the labels for lipschitz losses , which is known to be a loose step @xcite .",
    "moreover , we would like to note that for binary loss function trc ( as well as the rademacher complexity ) does not depend on the labels at all . indeed , this can be shown by writing @xmath96 for @xmath97 and noting that @xmath71 and @xmath98 are identically distributed for @xmath71 used in definition  [ def : trc ] .",
    "this is not true for prc , which is _ sensitive _ to the labels even in this setting . as a future work",
    "we hope to use this fact for analysis in the low noise setting @xcite .",
    "the slack term appearing in is significantly smaller than the one of  .",
    "for instance , if @xmath99 then the latter is @xmath100 times larger .",
    "this is caused by the additive term in symmetrization inequality . at the same time , corollary [ corollary : comparison - prc - trc ] shows that the complexity term appearing in is at most two times larger than trc , appearing in .",
    "comparison result of theorem [ thm : dagstuhl - relation ] shows that the upper bound of is also tighter than the one which can be obtained using and conditional rademacher complexity .",
    "similar upper bounds ( up to extra factor of 2 ) also hold for the _ excess risk _",
    "@xmath101 , where @xmath102 minimizes the training risk @xmath103 over @xmath83 .",
    "this can be proved using a similar argument to theorem [ thm : risk - bound ] .",
    "finally , one more application of the concentration argument can simplify the computation of prc , by estimating the expected value appearing in definition [ def : prc ] with only one random partition of @xmath19 .",
    "[ lemma : mean ] for @xmath104 let @xmath105 be sampled uniformly without replacement from a finite set of real numbers @xmath106 . then : @xmath107 = \\frac{1}{{n \\choose m}}\\sum_{{\\mathcal{s}}_m \\subseteq { \\mathcal{c}}}\\frac{1}{m}\\sum_{z\\in { \\mathcal{s}}_m } z = \\frac{1}{m { n \\choose m}}\\sum_{i=1}^n \\binom{n-1}{m-1 } c_i = \\frac{1}{n } \\sum_{i=1}^n c_i.\\ ] ]    fix any _ positive _ integers @xmath46 and @xmath108 such that @xmath109 , which implies @xmath110 and @xmath111 . note that lemma [ lemma : mean ] implies : @xmath112,\\quad { \\bar{f}}({\\mathcal{z}}_m)=   { \\mathop{\\mathbb{e}}}_{{\\mathcal{s}}_n}\\left[{\\bar{f}}({\\mathcal{s}}_n)\\right],\\ ] ] where @xmath113 and @xmath114 are sampled uniformly without replacement from @xmath82 and @xmath19 respectively . using jensen s inequality",
    "we get : @xmath115 - { \\mathop{\\mathbb{e}}}_{{\\mathcal{s}}_n}\\left[{\\bar{f}}({\\mathcal{s}}_n)\\right ] \\right)\\\\ \\label{eq : blabla } & \\leq { \\mathop{\\mathbb{e}}}_{({\\mathcal{z}}_m,{\\mathcal{s}}_k,{\\mathcal{s}}_n ) } \\sup_{f\\in f } \\bigl({\\bar{f}}({\\mathcal{s}}_k ) - { \\bar{f}}({\\mathcal{s}}_n)\\bigr).\\end{aligned}\\ ] ] the marginal distribution of @xmath116 , appearing in , can be equivalently described by first sampling @xmath19 from @xmath33 , then @xmath114 from @xmath19 ( both times uniformly without replacement ) , and setting @xmath117 ( recall that @xmath118 ) .",
    "thus @xmath119 \\right],\\ ] ] which completes the proof of the upper bound .",
    "we have shown that for @xmath53 and @xmath120 : @xmath121 = { \\mathop{\\mathbb{e}}}_{({\\mathcal{z}}_k,{\\mathcal{z}}_n ) } \\sup_{f\\in f } \\bigl({\\bar{f}}({\\mathcal{z}}_k ) - { \\bar{f}}({\\mathcal{z}}_n)\\bigr),\\ ] ] where @xmath45 and @xmath122 are sampled uniformly without replacement from @xmath33 and @xmath123 respectively .",
    "let @xmath124 be sampled uniformly without replacement from @xmath125 and let @xmath126 be the remaining @xmath127 elements of @xmath33 .",
    "using lemma [ lemma : mean ] once again we get : @xmath128 = { \\mathop{\\mathbb{e}}}\\left[{\\bar{f}}({\\mathcal{z}}_{u - k})\\big| ( { \\mathcal{z}}_n,{\\mathcal{z}}_k)\\right].\\ ] ] we can rewrite the r.h.s.of as : @xmath129 \\right)\\\\ & \\leq { \\mathop{\\mathbb{e}}}\\sup_{f\\in f } \\left({\\bar{f}}({\\mathcal{z}}_k ) - { \\bar{f}}({\\mathcal{z}}_n ) +   { \\bar{f}}({\\mathcal{z}}_{u - k } ) - { \\bar{f}}({\\mathcal{z}}_{m - n } ) \\right),\\end{aligned}\\ ] ] where we have used jensen s inequality .",
    "if we take @xmath130 we get @xmath76 \\leq { \\mathop{\\mathbb{e}}}\\sup_{f\\in f } \\left ( 2{\\bar{f}}({\\mathcal{z}}_{k^ * } \\cup { \\mathcal{z}}_{u - k^ * } ) -   2{\\bar{f}}({\\mathcal{z}}_{n^ * } \\cup { \\mathcal{z}}_{m - n^ * } ) \\right).\\ ] ] it is left to notice that the random subsets @xmath131 and @xmath132 have the same distributions as @xmath82 and @xmath19 .",
    "let @xmath133 , @xmath134 be i.i.d.rademacher signs , and @xmath135 be a uniform random permutation of a set containing @xmath46 plus and @xmath46 minus signs .",
    "the proof of theorem [ thm : dagstuhl - relation ] is based on the coupling of random variables @xmath136 and @xmath137 , which is described in lemma [ lemma : coupling ] .",
    "we will need a number of definitions .",
    "consider binary cube @xmath138 .",
    "denote @xmath139 , which is a set of all the vectors in @xmath140 having equal number of plus and minus signs . for",
    "any @xmath141 denote @xmath142 and consider the following set : @xmath143 which consists of the points in @xmath144 closest to @xmath145 in hamming metric . for any @xmath141 let @xmath146 be a random element of @xmath147 , distributed uniformly .",
    "we will use @xmath148 to denote @xmath149-th coordinate of the vector @xmath146 .",
    "[ remark : coupling ] if @xmath150 then @xmath151 .",
    "otherwise , @xmath147 will clearly contain more than one element of @xmath144 .",
    "namely , it can be shown , that if for some positive integer @xmath152 it holds that @xmath153 , then @xmath152 is necessarily even and @xmath147 consists of all the vectors in @xmath144 which can be obtained by replacing @xmath154 of @xmath155 signs in @xmath145 with @xmath156 signs , and thus in this case @xmath157 .",
    "[ lemma : coupling ] assume that @xmath158",
    ". then the random sequence  @xmath159 has the same distribution as @xmath137 .",
    "note that the support of @xmath159 is equal to @xmath144 . from symmetry",
    "it is easy to conclude that the distribution of @xmath159 is exchangable .",
    "this means that it is invariant under permutations and as a consequence uniform on @xmath144 .",
    "next result is in the core of the multiplicative upper bound .",
    "[ lemma : coupling - expect ] assume that @xmath133 . for any @xmath160",
    "the following holds : @xmath161 = \\left(1 - 2^{-m}{m \\choose n}\\right )   t_q({\\vec \\epsilon } ) \\geq \\left(1 - 2(2\\pi m)^{-1/2}\\right ) t_q({\\vec \\epsilon}).\\ ] ]    we will first upper bound @xmath162 , where @xmath163 is ( w.l.o.g . ) a sequence of @xmath46 plus signs followed by a sequence of @xmath46 minus signs .",
    "@xmath164 where we have used lemma [ lemma : coupling ] and",
    "the sum is over all different sequences of @xmath0 signs @xmath165 . for any @xmath166 denote @xmath167 and consider terms in corresponding to @xmath166 with @xmath168 , @xmath169 , and @xmath170 :    * case 1 : * @xmath168 .",
    "these terms will be zero , since @xmath171 .",
    "* case 2 : * @xmath169 .",
    "this means that @xmath166 `` has more plus signs than it should '' and according to remark  [ remark : coupling ] the mapping @xmath172 will replace several of  + 1 \" with  -1 \" .",
    "in particular , if @xmath173 then @xmath174 and thus the corresponding terms will be zero . if @xmath175 and in the same time @xmath176 the event @xmath177 also can not hold .",
    "moreover , note that identity @xmath178 can hold only if @xmath179 , which necessarily leads to @xmath180 from this we conclude that if @xmath181 then all the terms corresponding to @xmath166 with @xmath182 are zero .",
    "we will use @xmath183 to denote the subset of @xmath140 consisting of sequences @xmath166 , such that ( a ) @xmath184 , ( b ) @xmath175 , and ( c ) condition holds .",
    "it can be seen that if @xmath185 then : @xmath186 this holds since , according to remark  [ remark : coupling ] , @xmath187 can take exactly @xmath188 different values , while only one of them is equal to @xmath189 .",
    "let us compute the cardinality of @xmath183 for @xmath190 .",
    "it is easy to check that condition @xmath191 for some positive integer @xmath192 implies that @xmath166 has exactly @xmath193 minus signs .",
    "considering the fact that @xmath175 for @xmath185 we have : @xmath194 combining everything together we have : @xmath195 finally , it is easy to show using induction that : @xmath196 * case 3 : * @xmath170 .",
    "we can repeat all the steps of the previous case and get : @xmath197    accounting for these three cases in we conclude that @xmath198 where we have used the upper bound on the binomial coefficient from ( * ? ? ?",
    "* corollary 2.4 ) .",
    "we can conclude the proof of lemma by writing : @xmath199 = t_q({\\vec \\epsilon } ) \\left ( 1 - 2{\\mathbb{p}}\\{\\epsilon_q \\neq t_q({\\vec \\epsilon } ) | t({\\vec \\epsilon})\\}\\right ) \\geq",
    "t_q({\\vec \\epsilon } ) \\left ( 1 - 2(2\\pi m)^{-1/2}\\right).\\end{aligned}\\ ] ]    first we prove .",
    "let @xmath200 .",
    "we can write : @xmath201\\\\ \\label{eq : proof - gilles-2 } & \\leq \\bigl(1 - 2(2\\pi m)^{-1/2}\\bigr)^{-1 } { \\mathop{\\mathbb{e}}}\\left [ \\sup_{f\\in f } \\frac{2}{m } \\sum_{i=1}^m { \\mathop{\\mathbb{e}}}[\\epsilon_i",
    "| t(\\vec \\epsilon ) ] f(z_i ) \\right]\\\\ \\label{eq : proof - gilles-3 } & \\leq \\left(1 + \\frac{2}{\\sqrt{2\\pi m } - 2}\\right ) { \\mathop{\\mathbb{e}}}\\left [ \\sup_{f\\in f } \\frac{2}{m } \\sum_{i=1}^m \\epsilon_i f(z_i ) \\right],\\end{aligned}\\ ] ] where we have used coupling lemma [ lemma : coupling ] in , lemma [ lemma : coupling - expect ] in , and jensen s inequality in .",
    "this completes the proof of .",
    "next we prove .",
    "we have : @xmath202 - { \\mathop{\\mathbb{e}}}_{\\vec \\epsilon}\\left [ \\sup_{f\\in f } \\frac{2}{m } \\sum_{i=1}^m \\epsilon_i f(z_i)\\right ] \\right|.\\ ] ] using lemma [ lemma : coupling ] and jensen s inequality we further get : @xmath203\\right ] - { \\mathop{\\mathbb{e}}}_{\\vec \\epsilon}\\left [ \\sup_{f\\in f } \\frac{2}{m } \\sum_{i=1}^m \\epsilon_i f(z_i)\\right ] \\right|\\\\ \\label{eq : proof - k-1 } & \\leq { \\mathop{\\mathbb{e}}}_{\\vec \\epsilon}\\left [ { \\mathop{\\mathbb{e}}}_{t}\\left [ \\left|\\sup_{f\\in f } \\frac{2}{m } \\sum_{i=1}^m t_i(\\vec \\epsilon ) f(z_i ) - \\sup_{f\\in f } \\frac{2}{m } \\sum_{i=1}^m \\epsilon_i f(z_i)\\right|\\ , \\bigg| \\vec \\epsilon \\right ] \\right],\\end{aligned}\\ ] ] where we have , perhaps misleadingly , denoted the conditional expectation with respect to  the uniform choice from @xmath204 given @xmath205 using @xmath206 $ ] .",
    "next we have : @xmath207 where @xmath208 is a subset of indices , s.t.@xmath209 iff @xmath210",
    ". we can continue by writing @xmath211 note that since functions in @xmath12 are absolutely bounded by @xmath38 : @xmath212 returning to and using remark [ remark : coupling ] we obtain : @xmath213 \\right ] = { \\mathop{\\mathbb{e}}}_{\\vec \\epsilon}\\left[\\frac{1}{2}\\left| \\sum_{i=1}^m \\epsilon_i \\right|\\,\\right].\\ ] ] khinchin s inequality ( * ? ? ?",
    "* lemma 4.1 ) together with the best known constant due to @xcite gives @xmath214 \\leq \\sqrt{m } , $ ] which completes the proof of .",
    "let @xmath215 .",
    "take @xmath62 to be a set of two constant functions , @xmath216 and @xmath217 for all @xmath218 .",
    "clearly , @xmath219 . in the same time : @xmath220 = { \\mathop{\\mathbb{e}}}_{\\vec \\epsilon}\\left[\\max\\left\\{0 , \\frac{2}{m } \\sum_{i=1}^m \\epsilon_i \\right\\}\\right ] \\leq { \\mathop{\\mathbb{e}}}_{\\vec \\epsilon}\\left[\\left| \\frac{2}{m } \\sum_{i=1}^m \\epsilon_i \\right|\\,\\right ] \\leq \\frac{2}{\\sqrt{m}},\\ ] ] where we used khinchin s inequality .",
    "finally , khinchin s inequality also gives : @xmath221 = \\frac{1}{2}{\\mathop{\\mathbb{e}}}_{\\vec \\epsilon}\\left[\\left| \\frac{2}{m } \\sum_{i=1}^m \\epsilon_i \\right|\\,\\right ] \\geq \\frac{1}{\\sqrt{2m}}.\\ ] ] next , let @xmath63 contain @xmath222 functions , such that their projections on @xmath19 recover all the permutations of binary vector containing equal number of @xmath29 and @xmath65 .",
    "clearly , in this case @xmath223 .",
    "straightforward calculations show that in the same time @xmath224 and we conclude the proof using upper and lower bounds on the binomial coefficient from ( * ? ? ?",
    "* corollary 2.4 ) .",
    "the following version of mcdiarmid s bounded difference inequality for the setting of sampling without replacement was presented in ( * ? ? ?",
    "* lemma 2 ) and further improved in ( * ? ? ?",
    "* theorem 5 ) :    [ thm : mcdiarmid ] let @xmath19 be sampled uniformly without replacement from a fixed set @xmath225 of @xmath226 elements .",
    "let @xmath227 be a symmetric function s.t . for all @xmath228 and for all @xmath229 and @xmath230",
    ", @xmath231 then if @xmath5 with probability not less than @xmath92 the following holds : @xmath232 + \\sqrt{\\frac{c^2n^3\\log(1/\\delta)}{8(n-1/2)^2}}.\\ ] ]    note that function @xmath233 maps @xmath234 to @xmath13 and is of course symmetric .",
    "straightforward calculations show that this function satisfies bounded difference condition with @xmath235 ( ( * ? ? ?",
    "* inequality 9 ) ) .",
    "theorem  [ thm : mcdiarmid ] states that with probability not less than @xmath92 : @xmath236 + \\sqrt{\\frac{2n\\log(1/\\delta)}{(n-1/2)^2}}.\\ ] ] using upper bound of theorem [ thm : tsym ] with @xmath237 in place of @xmath12 we complete the proof of  .",
    "next , consider a symmetric function @xmath238 which also maps @xmath234 to @xmath13 .",
    "it can be shown again that it satisfies bounded difference condition with @xmath239 . and",
    "thus , theorem [ thm : mcdiarmid ] gives that with probability not less than @xmath92 : @xmath240 \\leq { \\hat{q}}_{m , n}(l_{{\\mathcal{h}}},{\\mathcal{z}}_m ) + \\sqrt{\\frac{2n\\log(1/\\delta)}{(n-1/2)^2}}.\\ ] ] using this inequality together with in a union bound we obtain the second inequality of the theorem .",
    "let @xmath241 be a probability distribution on @xmath64 and @xmath242 be i.i.d .",
    "samples selected according to @xmath241 . maximal discrepancy of @xmath12 was defined in @xcite as : @xmath243    it was shown in @xcite that if functions in @xmath12 are uniformly bounded by @xmath65 then : @xmath244 - 2\\sqrt{\\frac{2}{m } } \\leq { \\mathop{\\mathbb{e}}}\\left[\\hat{d}_m(f,{\\mathcal{x}}_m)\\right ] \\leq { \\mathop{\\mathbb{e}}}\\left[{\\hat{{r}}}_m(f,{\\mathcal{x}}_m)\\right ] + 4\\sqrt{\\frac{2}{m}}.\\ ] ] since elements in @xmath34 are i.i.d .",
    "the distribution of @xmath245 is invariant under their permutations and thus @xmath246 = { \\mathop{\\mathbb{e}}}\\left[{\\hat{q}}_{m , m/2}(f,{\\mathcal{x}}_m)\\right ] .",
    "$ ] now we can use theorem [ thm : dagstuhl - relation ] to significantly improve bounds in : @xmath247 - \\frac{2}{\\sqrt{m } } \\leq { \\mathop{\\mathbb{e}}}\\left[\\hat{d}_m(f,{\\mathcal{x}}_m)\\right ] \\leq \\left(1 + \\frac{2}{\\sqrt{2\\pi m } - 2}\\right){\\mathop{\\mathbb{e}}}\\left[{\\hat{{r}}}_m(f,{\\mathcal{x}}_m)\\right].\\ ] ]      the authors are thankful to marius kloft and ruth urner for useful discussions and to the anonymous reviewers for their comments .",
    "gb aknowledges support of the dfg through the for-1735 grant .",
    "nz was supported solely by the russian science foundation grant ( project 14 - 50 - 00150 ) .",
    "derbeko , p. , el - yaniv , r. , meir , r. : explicit learning curves for transduction and application to clustering and compression algorithms .",
    "journal of artificial intelligence research , 22(1 ) , 117142 ( 2004 )"
  ],
  "abstract_text": [
    "<S> transductive learning considers situations when a learner observes @xmath0 labelled training points and @xmath1 unlabelled test points with the final goal of giving correct answers for the test points . </S>",
    "<S> this paper introduces a new complexity measure for transductive learning called _ permutational rademacher complexity _ ( prc ) and studies its properties . </S>",
    "<S> a novel symmetrization inequality is proved , which shows that prc provides a tighter control over expected suprema of empirical processes compared to what happens in the standard i.i.d . setting . </S>",
    "<S> a number of comparison results are also provided , which show the relation between prc and other popular complexity measures used in statistical learning theory , including rademacher complexity and transductive rademacher complexity ( trc ) . </S>",
    "<S> we argue that prc is a more suitable complexity measure for transductive learning . </S>",
    "<S> finally , these results are combined with a standard concentration argument to provide novel data - dependent risk bounds for transductive learning .    </S>",
    "<S> learning , rademacher complexity , statistical learning theory , empirical processes , concentration inequalities </S>"
  ]
}