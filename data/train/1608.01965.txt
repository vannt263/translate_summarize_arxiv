{
  "article_text": [
    "statistical methods have long been applied to analyze written texts and language patterns  @xcite , which now include network representations of text to investigate linguistic phenomena  @xcite .",
    "networks generated from text share several features with other complex systems , e.g. transportation networks  @xcite , biological systems  @xcite , social interactions  @xcite .",
    "examples of language - related networks include phonological networks with modular or cut - off power - law behaviors  @xcite , semantic similarity networks with small - world and scale - free properties  @xcite , syntactic dependency networks with hierarchical and small - world organization  @xcite and collocation networks , which also display small - world and scale - free properties  @xcite .",
    "the ubiquity of specific patterns in language networks is believed to account for an easy navigation and acquisition in semantic and syntactic networks  @xcite .",
    "of particular relevance to this study , word co - occurrence networks are a special case of collocation networks where two words ( nodes ) are linked if they appear close to each other in a text .",
    "co - occurrence networks are convenient because they do not require prior linguistic knowledge , apart from that needed to filter relevant information . since most of the syntactic relations occur between adjacent words , co - occurrence networks can be seen as simplified versions of syntactic networks  @xcite .",
    "several patterns have been identified in co - occurrence networks formed from large corpora , such as the power - law regimes for degrees distribution  @xcite and core - periphery structure  @xcite resulting from the complex organization of the lexicon . the overall structure and dynamics of networks representing texts",
    "have been modeled to describe their mechanism of growth and attachment  @xcite , while nuances in the topology of real networks were exploited in practical problems , including natural language processing  @xcite . in this study",
    ", we use the co - occurrence representation to probe how the variation of network topology along a text is able to identify an author s style .",
    "writing style is more subjective than other text characteristics ( e.g. topic ) , making authorship recognition one of the most challenging text mining tasks  @xcite .",
    "it is crucial for practical applications such as text classification  @xcite , copyright resolution  @xcite , identification of terrorist messages  @xcite and of plagiarism  @xcite .",
    "early studies using stylometry were conducted by mosteller and wallace to identify authorship of the so - called federalist papers  @xcite .",
    "a myriad of methods to tackle the problem have been developed since then , typically using statistical properties of words ( e.g. mean length , frequency , burstiness and vocabulary richness ) and characters ( e.g. character counts and long - range correlations )  @xcite , in addition to syntactic and semantic information  @xcite .",
    "methods from statistical physics have also been used for authorship recognition  @xcite , which in recent years included text modeling with co - occurrence networks  @xcite .",
    "the adequacy of co - occurrence networks for the task was confirmed for the first time with the correlation between network topology and authors styles  @xcite . despite this relative success",
    ", some issues concerning the applicability of network methods remain unsolved .",
    "a major issue in network representation is that regular patterns among concepts only emerge when large pieces of texts are available .",
    "furthermore , rigorous network - based similarity estimators usually assume that the networks comprise the same number of nodes and edges , since most measurements are affected by the network size  @xcite .",
    "unfortunately , such strong assumption often does not hold for written texts ranging from small tales to long novels , which may hinder the applicability of models to real situations .",
    "as we shall show , the method presented here obviates these issues with a simple approach based on network dynamics .",
    "written texts were represented as co - occurrence networks , from which a set of network dynamics measurements were obtained .",
    "these measurements were used as attributes in pattern recognition methods in order to identify the author of a given text .",
    "the construction and analysis of the measurements are described in detail in the following subsections .",
    "the texts used for classification come from a collection of novels and tales in english whose details are provided in the supporting information .",
    "the collection comprising @xmath0 authors with @xmath1 texts per author was selected to simulate a real case where the text lengths are varied in a range from @xmath2 to @xmath3 tokens with an average of @xmath4 tokens .",
    "the approach introduced requires a pre - processing step before transforming texts into networks , which consists in the removal of stopwords and lemmatization .",
    "because we are mostly interested in the relationship between content words , stopwords such as function words conveying low semantic information were removed as in many studies of this type  @xcite .",
    "the remaining words were lemmatized so that nouns and verbs were mapped to their singular and infinitive forms , and therefore words related to the same concept were mapped into the same node ( also referred to as one single token ) . since lemmatization requires part - of - speech ( pos ) tagging , we used the maximum - entropy approach described in  @xcite .",
    "the co - occurrence networks were constructed with each distinct word becoming a node and two words being linked if they were adjacent in the pre - processed text  @xcite .",
    "the link is directed from the word appearing first to the second word and is weighted by the number of times the pair is found in the text .",
    "the proposed method for authorship attribution is based on the evolution of the topology of networks , i.e. we exploit the network dynamics .",
    "therefore , unlike previous approaches ( see e.g.  @xcite ) , we do not construct one single network from the whole book . instead , a piece of text is divided into shorter parts comprising the same number of tokens .",
    "then , a co - occurrence network is constructed for each part , which generates a series of independent networks for each book .",
    "the last partition is disregarded from the analysis because it is shorter than the previous ones .",
    "since distinct books have different numbers of tokens , the series length varies from book to book .",
    "each partition is described by the following topological network measurements : clustering coefficient @xmath5 , which gives the fraction of possible triangles that exist for a particular node ; network diameter @xmath6 , which is the largest of all shortest paths ( @xmath7 ) ; network radius @xmath8 , which is the smallest of all shortest paths ( @xmath9 ) ; number of cliques ( complete subgraphs ) @xmath10 ; load centrality @xmath11 , similar to betweenness centrality but considering weights on edges ; network transitivity @xmath12 , which measures the fraction of all connected triples which are in fact triangles , @xmath13 ; betweenness centrality @xmath14 , which measures how many shortest paths pass through a given node ; shortest path length @xmath15 , which is the shortest number of edges between two nodes ; degree @xmath16 or connectivity ( number of edges ) of a node ; intermittency @xmath17 , which measures how periodically a word is repeated  @xcite ; total number of nodes @xmath18 ( i.e. vocabulary size ) ; and total number of edges @xmath19 .",
    "even though intermittency is not a traditional network measurement , we considered it because of its strong relationship with the concept of cycle length in networks .",
    "moreover , this measurement has been proven useful for analyzing text styles  @xcite .",
    "the metrics @xmath6 , @xmath8 , @xmath10 , @xmath12 , @xmath18 and @xmath19 are scalar values for a network , while the other measurements are computed for each node individually . in order to have an overall picture of each partition , we computed the average values of @xmath5 , @xmath11 , @xmath14 , @xmath15 , @xmath16 and @xmath17 .",
    "as such , each partition is characterized by a set of twelve global topological measurements .",
    "the total number of tokens @xmath20 ( equal to the total weight among links ) , in each partition , was selected in a simple optimization procedure , with a compromise between having a long but noisy series ( many small networks ) and a shorter , more stable one ( few large networks ) .",
    "we found that with @xmath21 tokens one ensures a series length with @xmath22 elements on average while keeping the number of nodes over @xmath23 for all networks .",
    "logarithm of the metrics identified in the inset . ]    a set of time series is constructed by extracting the twelve global network metrics defined above for each of the networks from a book .",
    "figure [ fig : ts ] shows the series for moby dick by herman melville , from which one may note that the series oscillate steadily around a fixed value along the text , with no significant trend .",
    "indeed , the analysis is facilitated if the series are stationary .",
    "strong stationarity requires the expected values being constant along time while weak stationarity implies that the mean value ( and sometimes the variance ) is constant .",
    "we confirmed that the time series are stationary , i.e. characterized by low values of autocorrelation .",
    "correlation of a time series with itself shifted by a certain gap measures how much a value in the series depends on the previous ones , implying that the autocorrelation must be almost null for all but the first few values of the gap . in order to assess series stationarity",
    ", we implemented kwiatkowski - phillips - schmidt - shin ( kpss ) , augmented dickey - fuller , and mackinnon ( finite - sample and asymptotic ) unit root tests  @xcite .",
    "these tests assume stationarity as the null hypothesis .",
    "we observed that for ten of the twelve time series , @xmath24-values were larger than @xmath25 , and therefore the stationarity hypothesis can not be rejected . for the two remaining series ( clustering coefficient @xmath5 and transitivity @xmath12 )",
    "two of the four @xmath24-values were less than @xmath25 : those for augmented dickey - fuller and finite - sample mackinnon tests .",
    "mackinnon  @xcite pointed out that @xmath26-tests can lead to unreliable finite - sample @xmath24-values substantially smaller than asymptotic @xmath24-values as we have observed for the clustering coefficient and transitivity .",
    "moreover , autocorrelation drops after a small lag as shown in figure  [ fig : auto+series_hist](a ) for the series of clustering coefficient which can be fitted with an arima(1,1,2 ) model , thus implying that the first derivative of the series is stationary .",
    "the finding that the series can be considered stationary allows one to compare estimated values from series of different lengths . as the distribution in the time series was found to display a bell - shaped form ( shown in figure  [ fig : auto+series_hist](b ) ) , we propose the first four moments of the series distributions as the dynamical measurements , i.e. @xmath27^{1/i},\\ ] ] where @xmath28 , @xmath29 are the series values and @xmath30 is the average of the measurements in the series .",
    "since there are twelve time series , we obtain @xmath31 dynamical measurements to characterize a book .    [ cols=\"^,^ \" , ]     dimensionality reduction using either feature extraction or feature selection increased the success rates for all algorithms .",
    "the results of feature selection are shown in figure  [ fig : feat_sel ] for both variance threshold and score - based selection . in both cases",
    "the best results are obtained with an intermediate number of metrics : we begin by removing misleading attributes , therefore improving classification ; however , at the end of the process most of the attributes which carry important information are removed and then the classification scores are lowered . in figures  [ fig :",
    "feat_sel](a ) and  [ fig : feat_sel](b ) success scores are presented , with the maximum value for each curve marked with a circle .",
    "if there is more than one maximum ( e.g. j48 and nb for variance threshold and j48 and knn for score - based selection ) , we only consider the combinations with the fewest number of attributes , located at the rightmost positions .",
    "0.48        0.48     0.48        0.48     the results of feature selection using a variance threshold are shown in figures  [ fig : feat_sel](a ) and  [ fig : feat_sel](c ) .",
    "there is a single subset ( combination ) of attributes for each variance threshold level . at the lowest threshold in figure  [ fig : feat_sel](c )",
    "all attributes are present ( even though the threshold is larger than zero ) and all cells of the highest row are colored black . as the threshold is gradually increased , attributes are successively removed until there are no attributes left and all the cells in the lowest row are colored white . remarkably , the first and the last attributes removed were respectively the fourth and the third moments of the number of cliques @xmath10 .",
    "note also that for nine of the twelve network metrics , either the third or the fourth moment had the smallest variance .",
    "the maximum scores are marked with circles in figure  [ fig : feat_sel](a ) and listed in table  [ table : scores ] .",
    "the thresholds for maximum scores marked in  [ fig : feat_sel](a ) are located in a narrow range and are represented in figure  [ fig : feat_sel](c ) as dashed lines .",
    "the results of feature selection based on score are shown in figures  [ fig : feat_sel](b ) and  [ fig : feat_sel](d ) .",
    "we start with all the attributes in the left end of figure  [ fig : feat_sel](b ) . as we explore the combinations obtained by removing one attribute at a time the scores increase ( monotonically for j48 and knn ) until a maximum value is reached , after which the scores rapidly decrease reaching zeror score when there are zero attributes .",
    "the maximum scores are marked with circles in figure  [ fig : feat_sel](b ) and listed in table  [ table : scores ] .",
    "it must be noted that the maximum scores can be reached with a few attributes , at most @xmath32 attributes in the case of knn .",
    "the combinations of attributes giving the maximum scores marked are presented in detail in figure  [ fig : feat_sel](d ) .",
    "for knn two combinations of attributes reached the highest score .",
    "again , the four moments of a given network metric are grouped together .",
    "it can be seen that the best scoring combinations for some algorithms did not include any of the four moments from some network metrics . in particular ,",
    "load centrality @xmath11 was not used by any algorithm ( having therefore a blank column for @xmath11 in figure  [ fig : feat_sel](d ) ) .",
    "one should highlight the betweenness centrality @xmath14 , which was extensively used by knn , nb and rbfn even though its mean value ( i.e. first moment , and the leftmost column under the @xmath14 label on figure  [ fig : feat_sel](d ) ) was not used by these algorithms .",
    "two last combinations of attributes were constructed .",
    "the first moments @xmath30 represent the static metrics previously studied ( see e.g.  @xcite ) and define a subset of @xmath33 attributes .",
    "the complementary subset of @xmath34 second , third , and fourth moments represent the dynamical aspects of networks since they describe the extent of variation around the mean value throughout a text .",
    "classification was applied to these two subsets without further dimensionality reduction .",
    "the results are listed in the fourth and fifth rows of table  [ table : scores ] showing that purely dynamical metrics provide better overall performance when compared to the statical counterparts , while both subsets score similarly to the whole set of @xmath31 attributes .",
    "another dimensionality reduction technique implemented was feature extraction , using both linear pca and nonlinear isomap .",
    "the latter uses geodesic distances in an embedded manifold instead of high - dimensional euclidean distances .",
    "there is a free parameter in isomap : the number of neighbors @xmath35 .",
    "the distance between two instances considered neighbors is the traditional euclidean distance while the distance between two farthest instances is the geodesic distance for a path inside the manifold  @xcite .",
    "the results for isomap depend on @xmath35 and on the reduced number of dimensions @xmath36 ; we varied both parameters from @xmath37 to @xmath38 and found similar results for most cases ( see supporting information ) .",
    "the best scores reported below were obtained for @xmath39 and @xmath40 .",
    "figure  [ fig : feat_ext](b ) shows precision ( defined by equation  [ eq : precision ] ) and recall ( success score , defined by equation  [ eq : recall ] ) for original ( without dimensionality reduction ) , pca- , and isomap - treated attributes . dimensionality reduction through pca leads to lower precision and recall , while isomap enhances the classification efficacy of the algorithms .",
    "the best performance is reached with rbfn for which the authorship of @xmath41 of the @xmath42 texts in the collection is correctly identified , thus reaching @xmath43 success score ( recall ) and @xmath44 precision .",
    "this performance is robust among algorithms as both precision and recall surpass @xmath45 using knn , nb and rbfn . for visualization purposes isomap",
    "was also applied to reduce the number of attributes to a two - dimensional space using the projection explorer software @xcite as shown in figure  [ fig : feat_ext](a ) .",
    "for some authors the texts are clearly grouped and separated from the rest ( e.g. texts from a. c. doyle and b. shaw ) while for other authors the separation is not as clear . a common trend exists nevertheless , with texts by the same author located in preferential regions in the attribute space .    even though a direct comparison to related works requires using the same text collection ,",
    "two examples using collections with similar characteristics which use static network metrics are worth mentioning .",
    "a similar study for the same task  @xcite analyzed @xmath46 texts from @xmath0 authors in english reaching a success score of @xmath47 . in another work ,",
    "@xmath34 persian books from @xmath48 authors were classified with an accuracy rate of @xmath49  @xcite .",
    "a myriad of other metrics for authorship identification have been proposed .",
    "argamon and juola  @xcite collected the results of the pan 2011 competition where @xmath50 electronic messages from @xmath51 authors were classified using diverse metrics for which the best micro - averaged recall ( i.e. success score ) was @xmath52 .",
    "these collections have characteristics different to ours such as the number of texts , authors , and the sizes of messages compared to books .",
    "0.48        0.48",
    "network dynamics could be probed in a straightforward manner owing to the stationarity of the series obtained with the network metrics ; as a bonus , some of the problems faced in applying networks to real - life problems are solved .",
    "then , texts of different sizes can be compared , and indeed , the smallest book of the collection ( from a. c. doyle ) was correctly classified repeatedly .",
    "success scores reached @xmath43 , which is outstanding using a collection with such characteristics .",
    "dimensionality reduction through non - linear feature extraction helped to raise the success rates in classification .",
    "although two of the twelve network metrics did not comply with some stationarity tests , they were successfully used for the task .",
    "for instance , transitivity @xmath12 was largely used in the combinations leading to the highest scores shown in figure  [ fig : feat_sel](d ) .",
    "the typical sizes of the networks were slightly more than @xmath53 nodes which are usually considered small .",
    "our approach succeeds because it collects only global metrics , i.e. averages which are still reliable , in contrast to distributions over all nodes .",
    "when the typical network sizes are below a few hundreds of nodes , the scores drop . on the other hand , when network sizes are too large the scores also diminish ( at a slower pace ) , because the number of elements in the series decreases as the network size increases . considering that small books in the collection are not the source of wrong classification , we conclude that the errors are caused by the variability of style of some authors in their books : while for some authors texts are clearly concentrated in a small region of attribute space , the texts from others are scattered .",
    "this reflects that some authors use well - defined structures while others change their narrative resources from one text to another .",
    "converting networks structure information to time series allows one to use the vast knowledge already applied to other series to analyze evolution of network topologies , and in particular , to the way an author uses the structures offered by the language in his / her narrative .",
    "purely dynamical measures , i.e. higher moments of the time series , revealed an aspect hitherto unknown of the close relation between style and network dynamics . because co - occurrence networks are also author - dependent , with network dynamics texts of different sizes can be compared , which further expands the application of networks to real situations .",
    "this work was supported by the brazilian national council for scientific and technological development ( cnpq ) .",
    "dra acknowledges financial support from so paulo research foundation ( fapesp grant no .",
    "14/20830 - 0 ) .",
    "amancio d r , altmann e g , rybski d , oliveira o n jr , costa ldf ( 2013 ) _ probing the statistical properties of unknown texts : application to the voynich manuscript . _ _ plos one _ 8(7 ) : e67310 . amancio d r ( 2015 ) _ a complex network approach to stylometry_. _ plos one _ 10(8 ) : e0136076 .",
    "mukherjee a , choudhury m , basu a , ganguly n ( 2007 ) _ modeling the co - occurrence principles of the consonant inventories : a complex network approach_. _ international journal of modern physics c _ 18(2):281295 .    mukherjee a , choudhury m , basu a , ganguly n ( 2009 ) _ self - organization of the sound inventories : analysis and synthesis of the occurrence and co - occurrence networks of consonants_. _ journal of quantitative linguistics _ 16(2):157184 .",
    "choudhury m , chatterjee d and mukherjee a ( 2010 ) _ global topology of word co - occurrence networks : beyond the two - regime power - law_. _ proceedings of the 23rd international conference on computational linguistics : posters _ 162170 .",
    "segarra s , eisen m , ribeiro a ( 2013 ) _ authorship attribution using function words adjacency networks_. _ acoustics , speech and signal processing ( icassp ) , 2013 ieee international conference on _ , eds ward r , deng l ( ieee , vancouver ) , pp .",
    "55635567 .",
    "kwiatkowski d , phillips p c b , schmidt p , and shin y ( 1992 ) _ testing the null hypothesis of stationarity against the alternative of a unit root : how sure are we that economic time series have a unit root?_. _ elsevier _ 54(1):159178 .",
    "mackinnon j g ( 1996 ) _ numerical distribution functions for unit root and cointegration tests_. _ journal of applied econometrics _ 11(6):601618 .",
    "witten i h , frank e ( 2005 ) _ data mining : practical machine learning tools and techniques _ , ( morgan kaufmann ) .",
    "paulovich f v ; oliveira m c f and minghim r ( 2007 ) _ the projection explorer : a flexible tool for projection - based multidimensional visualization_. _ computer graphics and image processing , 2007 .",
    "sibgrapi 2007 .",
    "xx brazilian symposium on _ 2736 ."
  ],
  "abstract_text": [
    "<S> the identification of authorship in disputed documents still requires human expertise , which is now unfeasible for many tasks owing to the large volumes of text and authors in practical applications . in this study </S>",
    "<S> , we introduce a methodology based on the dynamics of word co - occurrence networks representing written texts to classify a corpus of 80 texts by 8 authors . </S>",
    "<S> the texts were divided into sections with equal number of linguistic tokens , from which time series were created for 12 topological metrics . </S>",
    "<S> the series were proven to be stationary ( p - value>0.05 ) , which permits to use distribution moments as learning attributes . with </S>",
    "<S> an optimized supervised learning procedure using a radial basis function network , 68 out of 80 texts were correctly classified , i.e. a remarkable 85% author matching success rate . </S>",
    "<S> therefore , fluctuations in purely dynamic network metrics were found to characterize authorship , thus opening the way for the description of texts in terms of small evolving networks . </S>",
    "<S> moreover , the approach introduced allows for comparison of texts with diverse characteristics in a simple , fast fashion .    </S>",
    "<S> * keywords : * complex networks ; network dynamics ; text analysis ; authorship identification . </S>"
  ]
}