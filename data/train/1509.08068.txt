{
  "article_text": [
    "multi core chip architectures are emerging as feasible solution to effectively utilizing the ever growing number of chip .",
    "multi - core chip depends on success in system software technology ( compiler and runtime system ) , in order to have thread level parallelism and utilizing on - chip concurrency . with multi - core processors ,",
    "additional speedups can be achieved by the use of parallelism in data - independent tasks .",
    "there is a gradual shift towards making current algorithms and design into parallel algorithms .",
    "it is rather difficult to achieve lock free and low cache contention parallel algorithms .",
    "+ in 70 s papers appeared ideas on parallel compilation of programming languages and parallel execution of programs were expected . in those papers discussions on parallel lexical analysis , syntactic analysis and code generation were done . with vlsi applications ,",
    "prominent increase in research on parallel compilation is observed . +",
    "a compiler contains different phases : lexical analyzer , syntactic analyzer , semantic analyzer and code generator .",
    "parsing or syntax analysis is the phase of compiler which analyses the program code according to the language . after analysis , it converts the code into another formal representation which will act as input for succeeding phases of compiler .",
    "+ complexity of software source code is increasing . an effort to compile large code base",
    "is very time consumable .",
    "@xcite describes two types of parsers : top down and bottom up parsers .",
    "top down parsers have less power as compared to bottom up parser . lr ( k ) ,",
    "slr ( k ) and lalr ( 1 ) are types of bottom up parsers . with more power bottom up parsers also requires more space and more time in parsing a string as compared to top down parsers .",
    "most of the compiler compilers like yacc @xcite and bison @xcite creates lr ( 1 ) parsers and compilers like clang @xcite , mono c # compiler @xcite etc . uses lr(1 ) parsers .",
    "so , it is evident that programming languages can be represented easily by lr ( 1 ) languages .",
    "+ parsing is very time consuming phase of compiler . parsing different files in parallel",
    "is not enough . as programming languages like c and c++ can includes different files",
    "( using # include ) in a single file which results in generation of very long file . if we can parallel the parsing phase of single file , it will give performance benefits in compiling the source code .",
    "many significant techniques are already proposed for making parallel parsers ( @xcite , @xcite , @xcite , @xcite , @xcite ) .",
    "a parallel parsing for programming language is given by @xcite .",
    "+ a block is a section of code which is grouped together . in a language , a block may contain class definition , member or method declaration .",
    "another block could be a block of statements also called compound statement .",
    "this block is usually associated with a function code or if statement or loop .",
    "programming languages such as c , c++ , java , python use the concept of blocks heavily .",
    "one of most important property of parsing blocks is that they all are independent of each other i.e. each block can be parsed independently of other block .",
    "so , we could parse many blocks in a parallel fashion . in this paper , we will propose a technique to parse various blocks of the code in parallel .",
    "it can also work as a block parallel incremental parser .",
    "our parser is termed as block parallelized parser ( bpp , for short ) .",
    "+ our technique of parallel parsing is based on incremental parsing .",
    "an incremental parser is the one that parse only those portions of a program that have been modified .",
    "whereas an ordinary parser must process the entire program when it is modified .",
    "an incremental parser takes only the known set of changes done in a source file and updates its internal representation of source file which may be an abstract syntax tree . by building upon the previously parsed files , the incremental",
    "parser avoids the wasteful re - parsing of entire source file where most of the cod remains unchanged .",
    "+ bpp is based on the properties that an incremental parser can parse any part of a source code without the need of parsing the whole source code and different blocks in a source code can be parsed independently of other blocks . in bpp",
    "these parts are blocks in a source code . using the property of incremental parser , bpp parse each of the blocks independently of other blocks .",
    "each of these blocks are parsed in their own thread .",
    "it can be easily seen that bpp follows a divide and conquer approach .",
    "it divides the source into different blocks , parse each of them in parallel and at the end conquer these blocks . in our scheme",
    "the conquer step does nothing except waiting for all the bpp threads to complete their operations .",
    "+ there have been many works on incremental parsing [ incremental parsing references ] .",
    "we choose to extend on the works of incremental jump shift reduce parser of @xcite .",
    "bpp is derived from incremental jump shift reduce parser . in @xcite , authors defined incremental jump shift reduce parser for slr ( 1 ) languages only .",
    "however , we decided to extend this parser to accept lr(1 ) language because lr(1 ) languages has more power than slr ( 1 ) and nearly all programming languages can be defined in the form of lr(1 ) grammars .",
    "we define the incremental categories to be a statement containing a block like class definition or function definition or if statement or for loop statement .",
    "then , we give a notion of first non - terminal symbols of a non - terminal symbol .",
    "we used this notion to create partitions of a grammar such that a partition includes an incremental category and its first non - terminals .",
    "we observed that this scheme gives us a very interesting property in incremental jump shift reduce parser .",
    "we used this property to create our block parallelized parser .",
    "+ whenever a start of the block symbol is encountered the parser will first check whether the current block is related to any incremental category and can it be parsed independently .",
    "if bpp is able to find the incremental category for it , bpp will start parsing the block in parallel . in this paper we developed this bpp for lr(1 ) languages but we believe it can be easily extended to lr(k ) or can be easily converted to lalr ( 1 ) or slr ( 1 ) grammars .",
    "we also see that no major changes were done to the current lr(1 ) parsing algorithm and hence , it should be easy to create an abstract syntax tree . this parser can also work as an incremental parallel parser which can parse different blocks in parallel .",
    "moreover , it could be seen that there is no requirement of any thread synchronization to communicate between different threads of bpp each of which is parsing a block in parallel .",
    "this is because no two blocks are related in any way for the purpose of parsing .",
    "+ we compiled c # implementation using mono c # compiler 3.12.1 and executed the implementation using mono jit compiler 3.12.1 on machine running fedora 21 with linux kernel 3.19.3 with 6 gb ram and intel core i7 - 3610 cpu with hyperthreading enabled .",
    "we found out that our technique showed 28% performance improvement in the case of including header files and 52% performance improvement in the case of excluding header files . + the following paper is designed as follows .",
    "section 2 shows some previous work done in parallel parsing .",
    "section 3 and 4 provides the terminology we will use and the background required to understand our technique . in section 5 we will extend incremental jump shift reduce parser to accept lr(1 ) grammars . in section 6",
    ", we introduced the concept of first non terminals of a non terminal . in section 7",
    "we will use this concept to create partitions of the grammar .",
    "we also showed that by creating partitions using this concept we get a very interesting property .",
    "this property would be used by bpp .",
    "we have generalized this property in a theorem and also provided a proof for it . in section 8",
    "we presents our block parallelized parser and its parsing algorithm . in section 9",
    "we will compare our algorithm with previous work .",
    "section 10 shows our evaluation and results .",
    "in section 11 and section 12 we complete our document with conclusion and related work .",
    "a lot of previous work has been done in parallel parsing of lr ( 1 ) and context free languages .",
    "the most recent work done by @xcite in parallel parsing of lr(1 ) is an extension of an lr substring parser for bounded context languages ( developed by cormack ) for parallel environment .",
    "@xcite provided a substring parser for bounded context - lr grammars and simple bounded context - lr grammars .",
    "@xcite distributes the work of parsing the substrings of a language over different processors .",
    "the work was extended to different processors in a balanced binary tree fashion and achieved o(log n ) time complexity of parsing . but constructing a bounded context lr grammar for a programming language is also difficult .",
    "c++ is one of the programming languages which can not be parsed by lr ( 1 ) parsing @xcite so creating a bounded context grammar is out of question here .",
    "+ parallel and distributed compilation schemes can be divided into two broad categories , functional decomposition and data decomposition . @xcite and @xcite talks about distributed compilation using a scheme based on functional decomposition .",
    "functional decomposition scheme divides different phases of compiler : lexer , parser , semantic analyzer into functional component and running each of them on separate processors like an instruction pipeline fashion .",
    "the data decomposition scheme divide the input into sections of equal length and parse them in parallel .",
    "bpp is data decomposition scheme which parallel the parser by divide and conquer approach .",
    "the data decomposition scheme was developed by @xcite , @xcite , @xcite , @xcite .",
    "these schemes are parsing lr ( k ) in parallel .",
    "they divide the input into sections of equal length and then parse them in parallel .",
    "@xcite , @xcite , @xcite describes asynchronous algorithms while @xcite develops a synchronous algorithm . @xcite",
    "develops a parallel lr parser algorithm using the error recovery algorithm of @xcite .",
    "+ @xcite has developed an incremental parallel compiler which could be used in interactive programming environment and he developed an incremental parallel parser also .",
    "@xcite improves upon the divide and conquer parsing technique developed by @xcite .",
    "they show that while the conquer step of algorithm in @xcite is @xmath0 but under certain conditions it improves to @xmath1 .",
    "+ @xcite describes a grammar partitioning scheme which would help in parsing the language in parallel . in @xcite",
    "a type of statement level parallelism has been developed .",
    "the grammar is divided into n different sub - grammars corresponding to n subsets of the language which will be handled by each sub - compiler . for each",
    "n sub grammars required to generate parse tables ( using parser generator ) along with driver routine constitute a parser for sub - compiler . for each sub - compiler ,",
    "a requirement of modified scanner is there which recognizes subset of the language .",
    "the technique described in @xcite requires a lot of modification to the lexical analyzer .",
    "a separate lexical analyzer has to be developed for one type of language .",
    "the parser of @xcite requires automatic tools for its implementation .",
    "+ in all the above described techniques constructing abstract syntax tree for a block structured language is difficult . as blocks in a block",
    "are independent on each other , so they can be parsed independently .",
    "moreover this scheme would not involve inter - thread communication before a thread completes its parsing of blocks .",
    "hence , no shared memory synchronization methods are required to coordinate between different threads .",
    "it could be easily seen that the creation of an abstract syntax tree is also very easy . with all these required things in mind",
    "we have developed block parallelized parser for lr ( 1 ) languages .",
    "we assume the notation for context free grammar is represented by @xmath2 where _ n _ is set of non - terminals , _",
    "t _ is set of terminals , _ s _ is start symbol and _ p _ is set of productions of the grammar .",
    "the language generated by _",
    "g _ is given as    @xmath3    we will use the following conventions .",
    "+    @xmath4    @xmath5    @xmath6    @xmath7    @xmath8    given a grammar _",
    "g _ , we represent its augmented grammar as @xmath9 , where +    @xmath10    @xmath11    @xmath12    here @xmath13 is called the augmented start symbol of @xmath14 and $ is the end of string marker .",
    "we denote a set of end of string markers as eos . + in our paper we will represent block parallelized parser as bpp , jump shift reduce parser as jsr and incremental jump shift reduce parser as i_jsr .",
    "an lr(1 ) item is represented as @xmath15 $ ] , where _ a _ is the lookahead symbol .",
    "+ in a programming language , a block represents a section of code grouped together .",
    "this section of code can be a group of statements , or a group of declaration statements .",
    "for example in java , a block corresponding to class definition contains declaration statements for fields and methods .",
    "block corresponding to function definition can contain declaration statement for local variables or expression statements or control flow statements .",
    "a top - level block is the starting block of a program which contains definition for classes , functions , import / include statements etc .",
    "child blocks are contained in either top - level block or another child block .",
    "as we proceed further , block will be in reference to child block .",
    "1 , shows an example of top - level and child blocks of a java program .",
    "a start block symbol could be `` \\ { '' in c style languages , `` begin '' in pascal style languages is represented as terminal @xmath16 . an end block symbol which could be `` } '' in c style languages or `` end '' in pascal style languages",
    "is represented as @xmath17 .",
    "we now survey lr ( 1 ) parsers and their generation algorithm as given by @xcite .",
    "lr ( 1 ) parsers are table driven shift reduce parsers . in lr ( 1 ) , `` l '' denotes left - to - right scanning of input symbols and `` r '' denotes constructing right most derivation in reverse .",
    "some extra information is indicated with each item : the set of possible terminals which could follow the item s lhs .",
    "this set of items is called the lookahead set for the item . here",
    ", `` 1 '' signifies that number of lookahead symbols required are 1 .",
    "+ lr ( 1 ) parser consists of an input , an output , a stack , a driver routine .",
    "a driver routine runs its parsing algorithm which interacts with two tables action and goto . any entry in action and goto tables",
    "are indexed by a symbol which belongs to @xmath18 and the current state .",
    "an entry in both the tables can be any one of the following :    * if action [ j , a ] = @xmath19s , q@xmath20 then a shift action must be taken . *",
    "if action [ j , a ] = @xmath19r , @xmath21 then reduce symbols to a production . * if action [ j , a ] = accept then grammar is accepted . * if action [ j , a ] = error then error has occurred . * if goto [ j , a ] = q then go to state q.    an lr ( 1 ) item is of the form @xmath22 $ ] , where _ a _ is a lookahead symbol .",
    "construction of lr ( 1 ) items requires two procedures closure and goto .",
    "closure takes a set of items as its argument .",
    "goto takes a set of items and a symbol as arguments .",
    "both are defined as follows : +    @xmath23~|~[a \\rightarrow \\alpha .",
    "b\\beta,~a ] \\in i$ ]    @xmath24    @xmath25~|~[a \\rightarrow \\alpha .",
    "x\\beta , a ] \\in i\\})$ ]    collection of set of lr ( 1 ) items is created using closure and goto functions .",
    "items function creates the collection of set of lr ( 1 ) items .",
    "+    @xmath26\\ } ) \\cup \\{goto ( i , x)~|~i",
    "\\in c~and~x \\in p'\\}$ ]    action and goto tables are created using this collection .",
    "following is the procedure to create these tables :    1 .",
    "create collection of set of lr(1 ) items .",
    "let this collection be @xmath27 2 .",
    "let _ i _ be the state of a parser constructed from @xmath28 .",
    "entries in action table are computed as follows : 1 .",
    "action [ _ i _ , _ a _ ] = shift _ j _ , if @xmath29 \\in i_i      $ ] and @xmath30 2 .",
    "action [ _ i _ , _ a _ ] = reduce @xmath31 , if @xmath32 \\in i_i       $ ] and @xmath33 3 .",
    "action [ _ i _ , $ ] = accept , if @xmath34 \\in i_i      $ ] 4 .",
    "goto [ _ i _ , _ a _ ] = _ j _ , if goto ( @xmath35 , a ) = @xmath36 3 .",
    "all other entries not defined by ( b ) and ( c ) are set to error .",
    "the initial state is the one containing the item @xmath37    $ ] .",
    "most of the programming languages could be constructed from lr ( 1 ) grammar .",
    "hence , lr ( 1 ) is the most widely used parser .",
    "many parser generators like yacc and gnu bison generates an lr ( 1 ) parser . + a jump shift reduce @xcite ( jsr in short ) parser is an extension of lr ( 1 ) parser .",
    "lr ( 1 ) parser generates action and goto table for the augmented grammar @xmath38 .",
    "jsr parser first partition the grammar @xmath38 into several sub grammars and creates parsing sub- table of every sub grammar .",
    "hence , the action and goto tables of lr ( 1 ) are split into several action and goto tables in jsr parser .",
    "jsr parser is equivalent to the lr ( 1 ) parser that is it will only accept languages generated by lr ( 1 ) grammar @xcite .",
    "+ let @xmath39 be the augmented grammar of grammar @xmath40 . let us partition the grammar g on the basis of non terminals .",
    "let @xmath41 denotes a partition of the grammar _",
    "g _ , such that we have +    @xmath42     + where ,    @xmath43    @xmath44    @xmath45    @xmath46    @xmath47     + therefore , we have +    @xmath48    for every subgrammar @xmath41 , a parsing subtable named tab(@xmath49 ) is built .",
    "each subtable contains action and goto subtables which are represented by tab(@xmath49).action and tab(@xmath49).goto .",
    "in addition to the shift , reduce and accept action there is an additional jump action .",
    "jump action is associated with a sub - table .",
    "whenever a jump action is encountered then the parsing algorithm jumps to a sub - table and parse the partition related to that sub - table .",
    "+ we will now investigate few points about the incremental jump shift reduce parser @xcite .",
    "incremental jump shift reduce parser ( i_jsr ) @xcite is based upon the jsr parser @xcite . a set of incremental categories will be defined which could be incrementally parsed by i_jsr parser .",
    "given a grammar @xmath40 a set of incremental categories has to be defined @xmath50 and the incremental language of g is +    @xmath51    where @xmath52 and @xmath53 + for every incremental category _ a _ , add a production @xmath54 , where @xmath55 is an end - of - string for _",
    "a_. for a given grammar @xmath40 with a set of incremental categories @xmath56 an incremental grammar is defined as +    @xmath57    where ,    eos is the set of end of string markers = @xmath58     +    @xmath59     + a major change by this extension is that now the strings may contain incremental symbols which are also non - terminal symbols .",
    "the difference between action and goto tables disappears , as an incremental category can also occur in the input string and can be shifted on the stack .",
    "hence , we would have only action table and no need for goto table .",
    "as we have also introduced eos set , the action table can now be indexed with symbols belonging to @xmath60 .",
    "every incremental category will have its own start state and accept action .",
    "we will represent the subtable as tab(@xmath61 ) .",
    "entries of table will be as follows :    * if tab(@xmath61 ) [ _ j _ , _ x _ ] = @xmath19s , q@xmath20 then a shift action must be taken . * if tab(@xmath61 ) [ _ j _ , _ x _ ] = @xmath19r , @xmath62 then a reduce action must be taken . *",
    "if tab(@xmath61 ) [ _ j _ , _ $ _ ] = accept then input is accepted . *",
    "if tab(@xmath61 ) [ _ j _ , @xmath63 = accept then input for incremental category @xmath64 will be accepted . * if tab(@xmath61 ) [ _ j _ , _ a _ ] = @xmath19j , k@xmath20 then jump to a subtable tab(@xmath65 ) . * if tab(@xmath61 ) [ _ j _ , _ a _ ] = error then error occurred .",
    "as jsr generation algorithm was already developed for lr ( 0 ) items and incremental jsr generation algorithm was developed for slr ( 0 ) items @xcite . in this section , we will first extend the jsr parser generation algorithm to accept lr ( 1 ) grammar and then we will extend i_jsr parser to accept lr(1 ) grammar .",
    "+ generation of subtables first requires the generation of canonical collection of sets of augmented items .",
    "an augmented item is a triplet represented as @xmath19i , ff , tf@xmath20 , where i is an lr item , ff called from - field and tf called to - field are the names of parsing sub - tables",
    ". from - field represents the sub - table which contains the last action performed by parser and to - field represent the sub - table which contains the next action to be performed .",
    "although we focus only lr ( 1 ) items but the procedure for lr ( k ) items is very similar .",
    "+ to - field of an augmented item of a state is determined using to function .",
    "let us define the to function .",
    "@xmath66 @xmath67 @xmath68 @xmath69    function to calls function choose_next .",
    "this function selects a parsing table out of those in which the parsing of the remaining string could continue .",
    "let @xmath70 be a total ordering relation over the set @xmath71 of the names of parsing sub - tables , such that @xmath72 +    @xmath73 @xmath74    from - field of an augmented item is enriched using from function .",
    "from takes two arguments @xmath75 , which is a set of items enriched with to - field and @xmath76 , whose items we have to enrich with from - field .",
    "+    @xmath77 @xmath78 @xmath79,~tf >",
    "\\in i_t''$ ] @xmath80,~ff > \\in i_j'$ ] @xmath81    states procedure is used to generate the collection of set of jsr items .",
    "states algorithm first generates the collection of sets of lr(1 ) items using items procedure which was discussed previously .",
    "afterwards , it calls to and from functions to generate set of augmented items from the corresponding set of lr(1 ) items .",
    "+    @xmath82 @xmath83 @xmath84 @xmath85 @xmath86 @xmath87 @xmath88    we will now extend i_jsr parser to accept lr ( 1 ) languages . this extended parser is based on the previous jsr parsing algorithm .",
    "the first function used to compute the set of first symbols related to a non - terminal has to be modified to include the incremental categories also .",
    "the reason being an incremental category can also occur in the input string , can be shifted on the stack while parsing and can reduce to a production .",
    "moreover , first should now also include the eos markers .",
    "hence , the new first becomes +    @xmath89    for an incremental category _",
    "a _ , there will be a set of items containing item @xmath90 $ ] and items @xmath91 $ ] .",
    "then the state corresponding to this set of items will be the start state of the incremental grammar corresponding to a. correspondingly , there will a single set of items that contains the item @xmath92 $ ] .",
    "the state belonging to this set of item is the accepting state of the incremental grammar corresponding to a. the i_jsr parser has initial and final states for every incremental category .",
    "+ now , we can extend the i_jsr parser for accepting languages generated by lr(1 ) grammars .",
    "the procedure i_tabs given below is used to construct the i_jsr parsing table .",
    "@xmath82 @xmath93 = < s , q>~where~goto ( i_j , x ) = i_q$ ] @xmath94=<j , k>$ ] @xmath93 = <",
    "r , a \\rightarrow \\alpha>$ ] @xmath95 = < j , k>$ ] @xmath96=accept$ ] @xmath97 = accept$ ]",
    "in this section we will define the concept of first non terminals .",
    "+ we define a set of first non terminals for a non terminal _ a _ as a set of non - terminals that appear at the beginning of any sentential form derived from _ a _",
    "i.e. a set of non terminals _ b _ such that there exists a derivation of the form @xmath98 .",
    "@xmath99 represents the set of first non terminals for _ a _ and can be represented in set notations as : +    @xmath100    to compute @xmath99 for any non - terminal a , apply the following rules until no more terminals can be added to the @xmath99 set .    1 .",
    "if _ a _ is a terminal , then @xmath101 2 .",
    "if _ a _ is a non - terminal and @xmath102 is a production for some @xmath103 , then place @xmath104 and everything in @xmath105 in @xmath106 if @xmath107 3 .   if @xmath108 is a production , then @xmath101    example 1 : if we have following productions :    * s d a b * s c * a a b * b b * c c * d d    then find @xmath109 ?",
    "solution 1 : + due to first two productions of s we have , +    @xmath110    @xmath111    @xmath112",
    "in this section we will use the concept of first non terminals to create partitions of grammar .",
    "i_jsr parser will use these partitions to develop its tables .",
    "we will see that this kind of partitioning leads to a very interesting property in i_jsr parsing algorithm .",
    "we will generalize this property in a theorem and will also prove it . + we will partition the grammar in such way that :    * every incremental category will have its own partition .",
    "* the partition of incremental category will contain first non terminals of that incremental category also .",
    "* intersection of set of first non - terminals of any two incremental categories must be empty .",
    "* all other remaining non - terminals including the augmented and start symbol are included in the first partition .    given a grammar @xmath113 with a set of incremental category ,",
    "@xmath114 we define partitions of non - terminals as @xmath115 such that : +    @xmath116    and +    @xmath117    and first partition , +    @xmath118    example 2 : partition the grammar given in example 1 using first non terminals as given above and create i_jsr parsing table .",
    "then parse the string `` _ _ dabb _ _ '' and parse string `` _ _ ab _ _ '' incrementally for incremental category _",
    "solution 2 : first we have to create an augmented grammar of the given grammar by adding production @xmath119 .",
    "next we can create two partitions of grammar as given by the following partitions of non terminals .",
    "+    @xmath120    @xmath121    as the incremental category we want is only _",
    "hence , there will be two partitions , @xmath122 containing _ a _ and its first non terminals and @xmath123 will contain the remaining non terminals . moreover , we would also have to add an eos marker for _ a _ , let us say it is @xmath124 .",
    "we can generate the i_jsr table using _",
    "i_tabs _ procedure described in section 5 .",
    "+ let us parse the string `` _ _ dabb _ _ '' .",
    "table 1 shows the series of actions taken while parsing `` _ _ dabb _ _ '' . in this case",
    "the start state will be the start state of table @xmath125 i.e. 0 . table 2 shows the series of actions taken when `` _ _ ab _ _ '' is parsed incrementally with the incremental category _",
    "a_. in this case the start state will be the start state of table tab ( a ) i.e. 2 .",
    "+    .parsing of `` _ _ ab _ _ '' [ cols=\"<,>,<\",options=\"header \" , ]     in table 1 , when stack state reaches 0d2 there is a jump to the table tab ( a ) . from this point until when stack state changes to 0d2a6 , the actions taken are same as the actions of table 2 and in the same table i.e. tab ( a ) .",
    "moreover , in between these stack states in table 1 `` _ _ ab _ _ '' is parsed to _ a_. +",
    "we can generalize this example in the sense that same series of actions are taken when parsing a string and when parsing its substring incrementally for its incremental category . in the current example all the same actions happens in the same table because we created the partitions in such a way that all the first non terminals are in that partition .",
    "if the partitions were not created in the way described , it could have happened that these actions would happen in the different sub tables .",
    "+ this technique is utilized by our bpp and it is generalized and proved in the theorem below .    given an incremental grammar @xmath126 with set of incremental categories @xmath127 such that the non terminal partition , @xmath128 related to incremental category @xmath129contains only @xmath129 and @xmath130 .",
    "for an incremental category @xmath129 and any terminal @xmath131 , if @xmath132 and during parsing of the word @xmath133 the parser reaches at a state _ q _ in the subtable of @xmath129 after performing the shift action on _ b _ then during the incremental parsing of the word @xmath134 for the incremental category @xmath129 the parser will also reach the state _ q _ after performing the shift action on _ b _ in the sub table of @xmath129 .",
    "* outline * : we will divide the proof in 4 cases . for each case",
    ", we will first find two sets of jsr items reached after performing shift on _ b _ one during the parsing of word @xmath135 and other during the incremental parsing of word @xmath136 related to incremental category @xmath129 .",
    "we will then show that both of these sets contains same jsr items which implies the above theorem . + it is given that @xmath129 is an incremental category and @xmath137 and let @xmath128 be the partition containing only @xmath129 and @xmath130 .",
    "let @xmath138 be the sub - table related to @xmath129 .",
    "for any non - terminal @xmath139 and @xmath140 , we must have @xmath141 .",
    "+ during incremental parsing of the word @xmath142 for the incremental category @xmath129 , the state before performing actions related to",
    "_ b _ will be the start state of the sub table @xmath143 .",
    "let that start state be _",
    "m_. + we will have four cases on the basis of whether the grammar has productions of the form , @xmath144 and @xmath145 + * case 1 * : if @xmath146 and @xmath147 + let the set of lr(1 ) items related to the start state of @xmath143 i.e. state _ m _",
    "be @xmath148 and _ x _ lies in some partition other than @xmath128 i.e. @xmath149 and @xmath150 .",
    "as noted by @xcite the start state of @xmath143 must contain the item @xmath151 $ ] , where _ d _ is a lookahead symbol .",
    "so we have @xmath151 \\in i_m$ ] .",
    "it is evident that the item @xmath151 $ ] should be result of a closure of another item .",
    "the only such item we can see is @xmath152 $ ] , where _ j _ is some lookahead symbol .",
    "so , we must have @xmath152 \\in i_m$ ] . as discussed in section 2 , to get a set of lr(1 ) items we have to apply closure ( @xmath152 $ ] ) .",
    "hence , we have +    @xmath153 \\in i_m$ ]     +    @xmath154 \\in i_m$ ]     +    @xmath155 \\in i_m$ ]     +    @xmath156 \\in i_m$ ]     + where _ e _ and _ f _ are some lookahead symbols .",
    "+ let @xmath157 be the set of lr(1 ) items such that @xmath158 .",
    "so , @xmath152 \\in i_o$ ] .",
    "let @xmath159 be a set of jsr items enriched with to fields corresponding to all lr(1 ) items in @xmath157 .",
    "after applying to procedure over @xmath157 we would get the to field for item @xmath152 $ ] as @xmath160 because @xmath149 .",
    "+ to get to fields for all jsr items corresponding to lr ( 1 ) items of the set @xmath148 we have to apply to procedure over @xmath148 .",
    "we could see that the to fields for items @xmath152 $ ] , @xmath154 $ ] , @xmath161 $ ] , @xmath156 $ ] will be @xmath138 .",
    "+ to enrich jsr items for all the lr(1 ) items in @xmath148 with from field , we would apply from procedure as @xmath162 .",
    "now we could see that the from field of jsr item of lr(1 ) item @xmath161 $ ] will be equal to the from field of @xmath152 $ ] which in turn is equal to the to field of @xmath153 $ ] , which is @xmath160 .",
    "so , the set of jsr items ( @xmath163 ) corresponding to @xmath148 contains the following items : +    @xmath164 \\in i_m^a$ ]     +    @xmath165 \\in i_m^a$ ]     +    @xmath166 \\in i_m^a$ ]     +    @xmath167 \\in i_m^a$ ]     + let after performing shift operation in the state _",
    "m _ over the symbol _",
    "b _ , parser reaches state _",
    "n_. so , we must have +    @xmath168~|~\\forall~g \\in first ( \\beta f)\\})$ ]     + moreover , the to and from fields of all items in the above state will be @xmath138 .",
    "we have obtained the set of jsr items reached after performing shift over the symbol _",
    "b _ during incremental parsing of word @xmath136 for incremental category @xmath129 . also , the subtable at this state is @xmath169 .",
    "+ we will now obtain the set of jsr items reached after performing shift over the symbol _",
    "b _ during the parsing of word @xmath135 for incremental category @xmath129 .",
    "let us consider the derivation @xmath170 such that , _",
    "b _ does nt derive @xmath171 . in the above derivation only one production out of @xmath144 and @xmath145 will be used .",
    "hence , we have two cases of the basis of which production is used .",
    "+   + _ case 1.1 _ : if production @xmath144 is used , then the set of items related to state reached just after performing shift on _ c _ in the above derivation say @xmath172 will contain the lr(1 ) item @xmath153 $ ] besides other items of the form @xmath173 $ ] , where @xmath174 .",
    "after applying to procedure on @xmath172 , we should get the to field for lr(1 ) item @xmath153 $ ] as @xmath160 .",
    "let us represent these set of items enriched with to field as @xmath175 .",
    "+ after parsing @xmath176 next state will be obtained by performing goto over @xmath172 with symbol _",
    "x_. let that state be @xmath177 .",
    "now we must have , +    @xmath178    .",
    "after performing goto we get +    @xmath152 \\in i_y$ ]    @xmath154 \\in i_y$ ]    @xmath161 \\in i_y$ ]    @xmath156 \\in i_y$ ]    after applying to procedure over @xmath177 , we get the to fields of items @xmath152 $ ] @xmath154 $ ] @xmath161 $ ] @xmath156 $ ] as @xmath138 . to enrich jsr items of lr(1 )",
    "items in @xmath177 we would apply from procedure as @xmath179 .",
    "now , we could see that the from field of jsr item for @xmath161 $ ] will be equal to the from field of jsr item for @xmath152 $ ] which in turn is equal to the to field of @xmath153 $ ] , which is @xmath160 .",
    "so , the set of jsr items ( @xmath180 ) corresponding to @xmath177 contains the following items : +    @xmath164 \\in i_y^a$ ]    @xmath165 \\in i_y^a$ ]    @xmath166 \\in i_y^a$ ]    @xmath167 \\in i_y^a$ ]    let the state reached after performing shift of _ b _ from the state @xmath177 be @xmath181 .",
    "then , +    @xmath182~|~\\forall~g \\in first ( \\beta f)\\right \\rbrace)$ ]    moreover , the to and from fields of all jsr items of @xmath181 will be @xmath138 .",
    "+ so , we have @xmath183 .",
    "this shows that the states _ z _ and _ n _ are same .",
    "let us name these states as _",
    "q_. also , the to fields for the items of @xmath181 and @xmath184 are same i.e. @xmath138 .",
    "hence , in this case shift on terminal _",
    "b _ in states _ m _ and _ x _ results only in one state _",
    "q _ and in the sub - table for incremental category @xmath129 .",
    "+ theorem is * proved * in this case .",
    "+ _ case 1.2 _ : if @xmath185 is used .",
    "x _ is the state reached before performing the shift on _",
    "b_. then , the set of items , say @xmath172 related to state _ x _ will contain following items : +    @xmath186 \\in i_y^a$ ]    @xmath154 \\in i_y^a$ ]    @xmath161 \\in i_y^a$ ]    @xmath156 \\in i_y^a$ ]     + after applying to operation to @xmath172 , the to fields of all jsr items for above lr(1 ) items will be @xmath138 .",
    "+ let @xmath177 be the state reached after performing shift on _ b _ in the state @xmath172 .",
    "so ,    @xmath187~|~\\forall~g \\in first ( \\beta f)~\\})$ ]    also , the to and from fields of all the jsr items for the above set of lr ( 1 ) items will be @xmath138 .",
    "+ hence , @xmath188 .",
    "this shows that the states _",
    "y _ and _ n _ are same .",
    "let us name the state as _",
    "q_. moreover , the to fields of lr(1 ) items of @xmath177 and @xmath184 are @xmath138 . hence , in this case shift on terminal _",
    "b _ in the states _ m _ and _ x _ results only in one state _",
    "q _ in the subtable of @xmath129 .",
    "+ theorem is proved in this case .",
    "+   + as theorem has been proved in _ case 1.1 _ and _ case 1.2_. so , for * case 1 * also the theorem has been proved .",
    "+ we have proved for the case containing both productions .",
    "two other cases are when only one of these productions is present .",
    "the proof of both of these cases are very similar to the * case 1*. + please note that with the given set of conditions in the theorem , we could nt have the case in which none of the productions belong to this set .",
    "theorem 1 is crucial to bpp . in the succeeding sections we will use this theorem to create our parallel parsing algorithm .",
    "in this section we will present our block parallelized parser for lr ( 1 ) grammars",
    ". we will first give the intuition and working of bpp .",
    "then we will present our algorithm and give a proof that our parser can accept all the lr(k ) and lalr ( k ) languages which can be accepted by a shift reduce lr(k ) and lalr ( k ) parser .",
    "+ let @xmath189 be the augmented grammar .",
    "the incremental categories are the non terminals associated with the blocks to be parsed in parallel .",
    "for example , if we want to parse class definitions in parallel then we can define _ class - definition _ as the incremental category .",
    "other examples can be _ function - definition _ , _ if - statement _ , _ for - loop _ , _ while - loop _ if they can be parsed in parallel . for most of the programming languages",
    "including c , c++ , java , c # above blocks can be parsed in parallel . in general",
    "we can define an incremental category to be the non terminals which derive a string containing the start of the block symbol , @xmath190 and ending with the end of the block symbol @xmath191 .",
    "in mathematical terms , for bpp the set of incremental category _ ic _",
    "is defined as :    @xmath192     + in the c programming language , a _ function - definition _ can be represented by the following context free grammar productions : + @xmath193 + @xmath194 + @xmath195 + @xmath196 + @xmath197 + @xmath198 + @xmath199 + @xmath200 + @xmath201 + according to the definition of incremental categories above , we can see that _ function - definition _ , _ if - stmt _ , _ while - loop _",
    ", _ for - loop _ follows the condition for an incremental category .",
    "+ in a programming language there could be many types of blocks like in java , a block related to the class definition may contain only method definitions and declaration of member variables while a block related to the method definition would contain statements including expression statements , variable declarations , if statement or loop etc .",
    "this means in a programming language not all blocks contains same type of statements .",
    "hence , encountering the start symbol of block does nt give us enough information about what kind of statements the block would contain . to overcome this problem",
    "we will modify the productions of incremental category such that a reduce action will happen when the start symbol is encountered .",
    "modify the productions of @xmath202 in such a way that every production @xmath203 is split into two productions : +    @xmath204    @xmath205    if the productions of incremental category @xmath129 is structured as above then during the parsing of a word related to this incremental category there will be reduce action to reduce the current symbols to production @xmath205 when @xmath190 becomes the look ahead symbol . as each @xmath206",
    "is related to only one @xmath129 and vice - verse , we can easily determine which incremental category has to be parsed next .",
    "+ now we are in a stage to define block parallelized grammar . given a grammar @xmath207 and a set of incremental categories +    @xmath208    we define block parallelized grammar @xmath209 such that +    @xmath210    @xmath211    @xmath212    and @xmath213 is partitioned using firstnt as given in section 7 .",
    "+ now we can use theorem 1 to create bpp .",
    "let us have a string @xmath214 where @xmath215 and @xmath216 . during the parsing _",
    ", when @xmath190 is encountered we should have a reduce action to @xmath206 , based on the production @xmath205 .",
    "now , we can get @xmath129 associated with @xmath206 . according to theorem 1 , during parsing of the word _ w _ if the parser reaches at state _",
    "q _ in the sub table of @xmath129 after performing shift action on _ a _ then during the incremental parsing of the word @xmath217 for the incremental category @xmath129 the parser will also reach the state _",
    "q _ in the sub table of @xmath129 after performing the shift action on _",
    "a_. this means , we can replace the state reached just before performing shift action on _ a _ with the start state of subtable of @xmath129 and @xmath136 can now be parsed incrementally .",
    "+ it is now evident that why the partitions of non terminals should be created as described in section 7 .",
    "if the partitions are not created in this way , then it may happen after a shift on _ a _ during the parsing of _ w _ and incremental parsing of @xmath136 may reach the same state but not in the same sub - table . by creating partitions as described in section 8 ,",
    "we make sure that when @xmath190 is encountered by bpp then the newly created parallel parser knows in which sub - table it has to continue the parsing in . on the other hand",
    "if partitions are not created as described in section 8 , then newly created parallel parser would nt know in which sub - table it has to continue parsing in . + this property is used by bpp to parse the block incrementally .",
    "algorithm 1 is the bpp parsing algorithm of incremental table @xmath138 . if _",
    "= 1 , then the algorithm is for the top level block .",
    "otherwise it is for other incremental category .",
    "+    @xmath218 @xmath219 @xmath220 @xmath221 @xmath222 @xmath223 @xmath224 @xmath225 @xmath226 @xmath227 @xmath228 @xmath229 @xmath230 @xmath231 @xmath232 @xmath233 @xmath234 @xmath235 @xmath236 @xmath237 @xmath238    this parsing algorithm is for any block be it top level block or child block .",
    "lines 1 - 4 initializes different local variables .",
    "lines 5 - 32 is the main loop of algorithm which does the whole work . line 6 , gets the top state on the stack .",
    "lines 7 - 9 pushes the next state on the stack if there is a shift operation .",
    "similarly , lines 10 - 11 changes current table if there is a jump operation .",
    "line 12 - 27 are executed if there is reduce action which reduces according to the production @xmath239 .",
    "line 14 checks if current input symbol is a start of the block symbol and if reduce action reduces @xmath205 for an incremental category @xmath129 .",
    "if yes then lines 15 - 22 gets @xmath129 related to @xmath206 , pops @xmath240 states from stack and pushes these states and start state to a new stack , creates and starts a new bpp for @xmath129 and shifts to the end of block . in this case",
    "next symbol will become @xmath129 .",
    "if check of line 14 fails then it means this is a regular reduce action not associated with any block .",
    "lines 24 - 27 , pops @xmath241 states from stack and shifts to a new state .",
    "line 28 returns if there is an accept action .",
    "accept action can be for both top level block and child block .",
    "line 30 reports error if none of the above cases are satisfied .",
    "2 shows an example of how bpp works .",
    "it will start parsing the block of function _ f_.",
    "when it will encounter an _ if _ block a new bpp in another thread will be created which will parse _ if _ block .",
    "parent bpp will move ahead to the end of _ if _ block and will also create another thread to parse _ else _ block . in this way input is divided into different threads parsing each block .",
    "+        in this algorithm we have tried to minimize the amount of serial work to be done to get to the end of the block for the new block parser .",
    "one bpp does nt have to do any communication with other bpps . also , there are no side effects of the above algorithm .",
    "all the variables which are being modified are local variables .",
    "hence , there is no need of synchronization .",
    "this also reduces any amount of cache contention between different processors .",
    "generation of abstract syntax tree or parsing tree is easy using above algorithm and it requires very little change in the above algorithm .",
    "+ it may be argued that the step `` go to the end of this block '' is a serial bottleneck for the parallel algorithm .",
    "@xcite describes an algorithm to perform lexical analysis of string in _",
    "o(log n ) _ time using _",
    "o(n ) _ processors in a parallel fashion .",
    "when performing lexical analysis in parallel as described in @xcite , lexer could store the start symbols of a block with its corresponding end symbol for that block .",
    "now determining the end of block is just a matter of searching through the data structure .",
    "many ways exist to make this searching as fast as possible like using a binary search tree or a hash table .",
    "in this section we will show how our technique is better than other techniques .",
    "@xcite developed a technique which divides whole grammar into n sub- grammars which are individually handled by n sub - compilers .",
    "each sub - compiler needs its own scanner which can scan a sub - grammar .",
    "it requires an automatic tool to generate sub - compiler .",
    "this technique requires significant changes in not only in parser and grammar but also in lexical analyzer phase .",
    "contrast to this our block parallelized parser is easy to generate as our technique does not require any change in the grammar and lexical analyzer and it is pretty easy to modify current yacc and bison parser generator tools to support the generation of our parser .",
    "+ lr substring parsing technique described in @xcite is specifically for bounded context  ( 1 , 1 ) grammars .",
    "there are no limitations like this to block parallelized parser .",
    "although in this paper we have shown how we can create an lr ( 1 ) block parallelized parser but we believe it can be extended to lr ( k ) class of languages and also could be used by lalr ( 1 ) parser .",
    "hence , our technique accepts a larger class of grammars .",
    "+ @xcite , @xcite , @xcite , @xcite all develops algorithm for parsing lr ( k ) class of languages in parallel . these techniques and in all other techniques the creation of abstract syntax tree is not as easy as itis in our technique .",
    "moreover our technique is simpler than all others .",
    "+ hence , we could see that block parallelized parser is easy to construct , accepts wider class of languages and supports an easy construction of abstract syntax tree .",
    "we implemented lexer , block parallelized parser and shift reduce lr ( 1 ) parser for c programming language supporting a few gnu c extensions required for our tests .",
    "implementation was done in c # programming language . to simplify our implementation",
    "we only included function - definition as the incremental category for bpp .",
    "moreover , function - definition would still give us a sufficient amount of parallelism as we would see in the evaluation .",
    "we modified the lexer phase so that it will keep track of the position of s b and its corresponding e b .",
    "this information was stored in the form of a c # dictionary ( which is implemented as a hash table ) with the position of s b as the key and position of e b as the value .",
    "as , thread creation has significant overhead so we used c # taskparallel library which is thread pool implementation in c#. our implementation does nt have a c preprocessor implementation .",
    "so , we first used gcc to perform preprocessing and the preprocessed file is used as input to our implementation .",
    "+ we evaluated the performance of bpp with shift reduce lr ( 1 ) parser by parsing 10 random files from the linux kernel source code .",
    "we compiled c # implementation using mono c # compiler 3.12.1 and executed the implementation using mono jit compiler 3.12.1 on machine running fedora 21 with linux kernel 3.19.3 with 6 gb ram and intel core i7 - 3610 cpu with hyperthreading enabled .",
    "+ in c programming language , preprocessing ` # include ` could actually generate very long files .",
    "normally , the header files contains declarations not function definitions .",
    "so , this leads to less amount of parallelism being available .",
    "hence we decided to evaluate with including header files and excluding header files .",
    "3 shows the performance improvement with respect to shift reduce lr(1 ) parser of 10 random linux kernel files .",
    "3 shows performance improvement for both cases including the header files and excluding the header files .",
    "as expected we could see that the performance improvement with excluding the header files is more than the performance improvement including the header files .",
    "+        the performance improvement in the case of excluding header files matters most for the programming languages like java , python , c # where most of the program is organized into blocks the results because in these programs the amount of parallelism available is high .",
    "+ the average performance improvement in the case of excluding header files is 52% and including header files is 28% .",
    "in this document we present our block parallelized parser technique which could parse the source code in a parallel fashion .",
    "our approach is a divide and conquer approach in which , the divide step divides the source code into different blocks and parse them in parallel whereas the conquer step only waits for all the parallel parsers to complete their operation .",
    "it is based on the incremental jump shift reduce parser technique developed by @xcite .",
    "our technique does nt require any communication in between different threads and does nt modify any global data .",
    "hence , this technique is free of thread synchronization .",
    "we develop this technique for lr ( 1 ) languages and we believe that it can be extended to accept lr ( k ) languages and could be converted to an lalr ( 1 ) parser easily .",
    "our technique does nt do any major changes in the parsing algorithm of a shift reduce parser hence the abstract syntax tree can be created in the same way as it has been creating in shift reduce parser .",
    "moreover , our parser can also work as an incremental block parallelized parser .",
    "we implemented block parallelized parser and shift reduce lr ( 1 ) parser for c programming language in c#. the performance evaluation of bpp with shift reduce lr ( 1 ) parser was done by parsing 10 random files from the linux kernel source code .",
    "we compiled c # implementation using mono c # compiler 3.12.1 and executed the implementation using mono jit compiler 3.12.1 on machine running fedora 21 with linux kernel 3.19.3 with 6 gb ram and intel core i7 - 3610 cpu with hyperthreading enabled .",
    "we found out that our technique showed 28% performance improvement in the case of including header files and 52% performance improvement in the case of excluding header files .",
    "our parser accepts lr ( 1 ) languages we would like to extend it to accept lr ( k ) languages . in our technique , the parser determines when to create a new parallel parser thread .",
    "if the responsibility of this decision can be given to the lexical analysis phase then the lexical analysis can actually start the parsers in parallel .",
    "this will lead to significant performance advantage .",
    "moreover , our technique has been applied to languages which does nt have indentation in their syntax like the way python has .",
    "@xcite shows an efficient way to parse the language which has indentation as a mean to determine blocks .",
    "our parser can be extended to accept those languages also .",
    "we are working towards developing a block parallelized compiler which could compile different blocks of a language in parallel .",
    "block parallelized parser is one of the components of a block parallelized compiler .",
    "semantic analysis phase also share the same properties as the syntax analysis phase . in programming languages , an entity like variable or type",
    "is declared before using it .",
    "so , in this case also a lot can be done to actually parallelize the semantic analysis phase .",
    "neal m. gafter and thomas j. leblanc .",
    "parallel incremental compilation .",
    "department of computer science , university of rochester : ph .",
    "d. thesis .",
    "113 gwen clarke and david t. barnard .",
    "an lr substring parser applied in a parallel environment , journal of parallel and distributed computing . g. v. cormack .",
    "an lr substring parser for noncorrecting syntax error recovery , acm sigplan notices alfred v. aho , monica s. lam , ravi sethi and jeffery d. ullman .",
    "2007 . compilers principle tools and techniques second edition , prentice hall floyd , r. w. bounded context synctactic analysis .",
    "acm 7 , 21 february 1961 j. h. williams , 1975 . bounded context parsable grammars .",
    "information and control 28 , 314 - 334 r. m. schell , 1979 .",
    "methods for constructing parallel compilers for use in a multiprocessor environment .",
    "d. thesis , univ . of illinois at urbana - champaign j. cohen and s. kolodner .",
    "1985 . estimating the speedup in parallel parsing , ieee trans .",
    "software engrg .",
    "se-11 c. n. fischer , 1975 . on parsing context free languages in parallel environments .",
    "d. thesis , cornell univ .",
    "m. d. mickunas and r. m. schell .",
    "parallel compilation in a multi - processor environment ( extended abstract ) .",
    "comput d. ligett , g. mccluskey , and w. m. mckeeman , parallel lr parsing tech . rep . , wang institute of graduate studies , july 1982 edward d. willink , meta - compilation for c++ , university of surrey , june 2001 pierpaolo degano , stefano mannucci and bruno mojana , efficient incremental lr parsing for syntax - directed editors , acm transactions on programming languages and systems , vol . 10 , no .",
    "3 , july 1988 , pages 345 - 373 .",
    "sanjay khanna , arif ghafoor and amrit goel , a parallel compilation technique based on grammar partitioning , 1990 acm 089791 - 348 - 5/90/0002/0385 w. daniel hillis and guy l. steele , data parallel algorithms , communications of the acm , 1986 bison , http://www.gnu.org/software/bison yacc , http://dinosaur.compilertools.net/yacc clang , http://clang.llvm.org mono , http//mono - project.com el - essouki , w. huen , and m. evans , `` towards a partitioning compiler for distributed computing system '' , ieee first international conference on distributed computing systems , october 1979 .",
    "thomas j. pennello and frank deremer , `` a forward move algorithm for lr error recovery '' , fifth annual acm symposium on principles of programming language .",
    "jean - philipe bernardy and koen claessen ,  efficient divide - and - conquer parsing of practical context - free languages .",
    "l. valiant .",
    "general context - free recognition in less than cubic time .",
    "j. of computer and system sciences , 10(2):308 - 314 , 1975 .",
    "micheal d. adams .",
    "`` principled parsing for indentation - sensitive languages '' , acm symposium on principles of programming languages 2013 .",
    "january 23 - 25 ."
  ],
  "abstract_text": [
    "<S> software s source code is becoming large and complex . compilation of large base code is a time consuming process . </S>",
    "<S> parallel compilation of code will help in reducing the time complexity . </S>",
    "<S> parsing is one of the phases in compiler in which significant amount of time of compilation is spent . </S>",
    "<S> techniques have already been developed to extract the parallelism available in parser . </S>",
    "<S> current lr(k ) parallel parsing techniques either face difficulty in creating abstract syntax tree or requires modification in the grammar or are specific to less expressive grammars . </S>",
    "<S> most of the programming languages like c , algol are block - structured , and in most language s grammars the grammar of different blocks is independent , allowing different blocks to be parsed in parallel . </S>",
    "<S> we are proposing a block level parallel parser derived from incremental jump shift reduce parser by @xcite . </S>",
    "<S> block parallelized parser ( bpp ) can even work as a block parallel incremental parser . </S>",
    "<S> we define a set of incremental categories and create the partitions of a grammar based on a rule . when parser reaches the start of the block symbol it will check whether the current block is related to any incremental category . if block parallel parser find the incremental category for it , parser will parse the block in parallel . </S>",
    "<S> block parallel parser is developed for lr(1 ) grammar . without making major changes in shift reduce ( sr ) </S>",
    "<S> lr(1 ) parsing algorithm , block parallel parser can create an abstract syntax tree easily . </S>",
    "<S> we believe this parser can be easily extended to lr ( k ) grammars and also be converted to an lalr ( 1 ) parser . </S>",
    "<S> we implemented bpp and sr lr(1 ) parsing algorithm for c programming language . </S>",
    "<S> we evaluated performance of both techniques by parsing 10 random files from linux kernel source . </S>",
    "<S> bpp showed 28% and 52% improvement in the case of including header files and excluding header files respectively . </S>"
  ]
}