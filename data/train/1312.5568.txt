{
  "article_text": [
    "temporal or dynamic textures ( dt ) are image sequences that exhibit spatially repetitive and certain stationarity properties in time",
    ". this kind of sequences are typically videos of processes , such as moving water , smoke , swaying trees , moving clouds , or a flag blowing in the wind .",
    "study and analysis of dt is important in several applications such as video segmentation @xcite , video recognition @xcite , and dt synthesizing @xcite .",
    "one classical approach is to model dynamic scenes via the optical flow @xcite .",
    "however , such methods require a certain degree of motion smoothness and parametric motion models @xcite .",
    "non - smoothness , discontinuities , and noise inherence to rapidly varying , non - stationary dts ( e.g. fire ) pose a challenge to develop optical flow based algorithms .",
    "another technique , called particle filter @xcite , models the dynamical course of dts as a markov process . a reasonable assumption in dt modeling is that each observation is correlated to an underlying latent variable , or `` state '' , and then derive the parameter transition operator between these states .",
    "some approaches directly view each observation as a state , and then focus on transitions between the observations in the time domain . for instance",
    ", the work in  @xcite treats this transition as an associated probability problem , and other methods construct a spatio - temporal autoregressive model ( star ) or position affine operator for this transition @xcite .",
    "differently , feature - based models capture the intrinsic law and underlying structures of the data by projecting the original data onto a low - dimensional feature space via feature extracted techniques , such as principle component analysis ( pca ) .",
    "g.  doretto et al .",
    "@xcite model the evolution of the dynamic textured scenes as a linear dynamical system ( lds ) under a gaussian noise assumption . as a popular method in dynamic textures , lds and its",
    "derivative algorithms have been successfully used for various dynamic texture applications @xcite .",
    "however , constraints are imposed on the types of motion and noise that can be modeled in lds .",
    "for instance , it is sensitive to input variations due to various noise .",
    "especially , it is vulnerable to non - gaussian noise , such as missing data or occlusion of the dynamic scenes .",
    "moreover , stability is also a challenging problem for lds @xcite . to tackle these challenges ,",
    "the approach taken here is to explore an alternative method to model the dts by appealing to the principle of sparsity .",
    "instead of using the principle components ( pcs ) as the transition `` states '' in lds , sparse coefficients over a learned dictionary are imposed as the underlying `` states '' . in this way",
    ", the dynamical process of dts exhibits a transition course of corresponding sparse events .",
    "these sparse events can be obtained via a recent technique on linear decomposition of data , called dictionary learning @xcite .",
    "formally , these sparse representations @xmath0 to a signal @xmath1 , can be written as @xmath2 where @xmath3 is a dictionary , and @xmath4 is sparse , i.e. most of its entries are zero or small in magnitude .",
    "that is , the signal @xmath5 can be sparsely represented only using a few elements from some dictionary @xmath6 . in this work ,",
    "we start with a brief review of the dynamic texture model from the viewpoint of convex @xmath7 optimization , and then deduce a combined regression associated with several regularizations for a joint process``states extraction '' and `` states transition '' .",
    "then we treat the solution of the above combined regression as an adaptive dictionary learning problem , which can achieve two distinct yet tightly coupled tasks efficiently reducing the dimensionality via sparse representation and robustly modeling the dynamical process .",
    "finally , we cast this dictionary learning problem as the optimization of a smooth non - convex objective function , which is efficiently resolved via a gradient descent method .",
    "in this section , we start with a brief introduction to the linear dynamical systems ( lds ) model and develop an adaptive dictionary learning framework for sparse coding .",
    "let us denote a given sequence of @xmath8 frames by @xmath9 \\in \\mathbb{r}^{m\\times ( n+1)}$ ] , where the time is indexed by @xmath10 .",
    "the evolution of a lds is often described by the following two equations @xmath11 where @xmath12 , @xmath13 , @xmath14 and @xmath15 denote the observation , its hidden state or feature , state noise , and observation noise , respectively .",
    "the system is described by the dynamics matrix @xmath16 , and the modeling matrix @xmath17 .",
    "here we are interested in estimating the system parameters @xmath18 and @xmath6 , together with the hidden states , given the sequence of observations @xmath19 .",
    "the problem of learning the lds can be considered as a coupled linear regression problem @xcite .",
    "let us denote @xmath20 \\in \\mathbb{r}^{k \\times ( n+1)}$ ] , @xmath21 \\in \\mathbb{r}^{k \\times n}$ ] , and @xmath22 \\in \\mathbb{r}^{k \\times n}$ ] .",
    "the system dynamics and modeling matrix are expected to be caught by solving the following minimization problem , @xmath23 where @xmath24 is a small positive constant . in our approach , we assume that all observations @xmath25 admit a sparse representation with respect to an unknown dictionary @xmath26 , i.e. @xmath27 where @xmath13 is sparse . without loss of generality , we further assume that all columns of the dictionary @xmath6 have unit norm .",
    "we then define the set @xmath28 where @xmath29 is the diagonal matrix whose entries on the diagonal are those of @xmath30 , @xmath31 denotes the identity matrix .",
    "the set @xmath32 is the product of @xmath33 unit spheres , and is hence a @xmath34 dimensional smooth manifold . finally , by adopting the common sparse coding framework to problem",
    ", we have the following minimization problem @xmath35 where @xmath36 , @xmath37 denotes the frobenius norm of matrices , and @xmath38 is the @xmath39 norm , which measures the overall sparsity of a matrix .",
    "the parameter @xmath40 weighs the sparsity measurement against the residual errors .      solving the minimization problem as stated in eq .",
    "is a very challenging task . in this work ,",
    "we employ an idea similar to _ subspace identification methods _",
    "@xcite , which treat the state as a function of @xmath41 . here , we confine ourselves to the sparse solution of an elastic - net problem , which is proposed in @xcite , as @xmath42 where @xmath43 and @xmath44 are regularization parameters , which play an important role in ensuring stability and uniqueness of the solutions .",
    "let us define the set of indices of the non - zero entries of the solution @xmath45^{\\top } \\in \\mathbb{r}^{k}$ ] as @xmath46 then the solution @xmath47 has a closed - form expression as @xmath48 where @xmath49 carries the signs of @xmath50 , @xmath51 is the subset of @xmath6 in which the index of atoms ( rows ) fall into support @xmath52 .",
    "furthermore , it is known that the solution @xmath53 as given in is a locally twice differentiable function at @xmath6 . by an abuse of notation ,",
    "we define @xmath54 .",
    "\\end{split}\\ ] ] in a similar way , @xmath55 is defined .",
    "thus , the cost function reads as @xmath56    it is known that an lds with the dynamic matrix @xmath18 is said to be stable , if the largest eigenvalue of @xmath18 is bounded by @xmath57 @xcite .",
    "let @xmath58 be the largest eigenvalue of @xmath18 , then @xmath59 thus , we enforce the small @xmath58 via imposing a penalty @xmath60 on , and then end up with the cost function as @xmath61      in this section , we firstly derive a gradient descent algorithm to minimize and then discuss some details of the choice of the parameters in the final implementation .",
    "we start with the computation of the first derivative of the sparse solution of the elastic - net problem @xmath53 as given in .",
    "given the tangent space of @xmath32 at @xmath6 as @xmath62 the orthogonal projection of a matrix @xmath63 onto the tangent space @xmath64 with respect to the inner product @xmath65 is given by @xmath66 let us denote @xmath67 .",
    "the first derivative of @xmath68 in the direction @xmath69 is @xmath70    by the product structure of @xmath71 , the riemannian gradient of the function @xmath72 is @xmath73 here , the euclidean gradient @xmath74 of @xmath72 with respect to @xmath18 is computed as @xmath75 with @xmath76 being the @xmath77-th standard basis vector of @xmath78 . using the shorthand notation , @xmath79 , @xmath80 , and @xmath81 ,",
    "the euclidean gradient @xmath82 of @xmath83 with respect to @xmath6 is @xmath84    for a gradient search iteration on manifolds , we employ the following smooth curve on @xmath32 through @xmath85 in direction @xmath69 @xmath86 with @xmath87 .",
    "it essentially normalizes all columns of @xmath88 . for a detailed overview on optimization on matrix manifold ,",
    "refer to @xcite .",
    "training data @xmath19 initialize the parameters @xmath89,@xmath90,@xmath91 , initial dictionary @xmath6 , and initial transition matrix @xmath18 .",
    "_ sparse coding stage _",
    "+ @xmath92 use lasso algorithm to compute @xmath4 via + @xmath92 @xmath93 + @xmath92 compute the active set @xmath52 for each @xmath4 .",
    "+ compute the gradient of @xmath94 according to and .",
    "update the parameters @xmath18 and @xmath6 @xmath95    until now , we have computed the gradient of @xmath72 as defined in with respect to its two arguments @xmath6 and @xmath18 . an iterative scheme ( such as the gradient descent method or conjugate gradient method ) can be used to find the optimal @xmath6 and @xmath18 , using the gradient expression above .",
    "the procedure displayed in algorithm is the version of avdl based on gradient descent procedure .",
    "the learning rate @xmath96 can be computed via the well - known backtracking line search method , similar to @xcite . here , considering the high coherence among the temporal frames , we prefer non - redundant dictionary , that is , @xmath97 for the dictionary @xmath3 . for parameters @xmath98 in the elastic net ,",
    "we put an emphasis on sparse solutions and choose @xmath99 , as proposed in @xcite .    [ cols=\"^,^,^,^,^,^,^,^,^ \" , ]",
    "we carry out a few experiments on natural image sequences data , and demonstrate the practicality of the proposed algorithm .",
    "our test dataset comprises of videos from dyntex++ @xcite , and data from internet sources ( for instance , youtube ) .",
    "firstly , we show the performance on reconstruction and synthesizing with a grayscale video of burning candle , which is corrupted by gaussian noise or occlusion .",
    "this video has 1024 frames with size of @xmath100 , see figure  [ fig_candle_sys_rec ] .",
    "the initial dictionary is @xmath101 .",
    "after the acquisition of the dictionary @xmath6 and the transition @xmath18 , the synthesized data can be generated easily by @xmath102 , or more precisely , using a convex formulation @xmath103 table  [ candle_sys ] shows the performance of synthesizing on burning candle with gaussian noise .",
    "the error pairs @xmath104 are defined as @xmath105 , @xmath106 , and the largest eigenvalue of @xmath18 is denoted by @xmath58 .",
    "the compression rate for avdl is sparsity of @xmath4 to @xmath107 , and for lds is number of pcs to @xmath108 .",
    "table  [ candle_sys ] shows avdl can obtain the stable dynamic matrix @xmath18 @xmath109 , smaller compression rate and smaller error @xmath104 of cost function , by increasing the numbers of main loops in algorithm 1 .",
    "figure  [ fig_candle_sys_rec ] @xmath110 is the visual comparison between lds and avdl .",
    "avdl performs well on denoising against corruption by gaussian noise . in the case of occlusion in figure  [ fig_candle_sys_rec ] ( d ) ,",
    "random 50 frames of the 1024 burning candle video are corrupted by a @xmath111 rectangle .",
    "the length of both synthesizing data is 1024 , based on first frame of the burning candle .",
    "@xmath112 of the synthesizing data from lds are corrupted by this rectangle , but @xmath113 for avdl .",
    "lllll occlusion rate ( % ) & 0 & 5 & 15 & 30 + lds - nn ( 128pcs ) & 69.72 & 45.00 & 25.14 & 14.17 + avdl - src & 70.28 & 64.72 & 44.44 & 22.36 +    the second experiment is about scenes classification on dyntex++ , which contains dts from 36 classes .",
    "each class has 100 subsequences of length 50 frames with @xmath114 pixels .",
    "20 videos are randomly chosen in each class and total 720 videos are used for our experiments . classification for lds",
    "is performed using the martin distance with a nearest - neighbor classifier on its parameters pair @xmath41 @xcite .",
    "another classifier is avdl associated with the sparse representation - based classifier ( src ) @xcite , in which the class of a test sequence is determined by the smallest reconstruction error @xmath115 and transition error @xmath116 .",
    "table  [ table : recognition ] provides the recognition results with increasing occlusion rates for test data .",
    "compared to lds with nearest - neighbor classifier ( lds - nn ) , table  [ table : recognition ] shows the proposed avdl with src ( avdl - src ) performs better while the test videos are corrupted by increasing occlusion .",
    "this paper proposes an alternative method , called avdl , to model the dynamic process of dts . in avdl ,",
    "the sparse events over a dictionary are imposed as transition states .",
    "the proposed method show a robust performance for synthesizing , reconstruction and recognition on dts corrupted by gaussian noise .",
    "especially , avdl exhibits more powerful in the case of test data with non - gaussian noise , such as occlusion .",
    "one possible future extension is to learn a dictionary for large scale dt sequences based on avdl .",
    "payam saisan , gianfranco doretto , ying  nian wu , and stefano soatto , `` dynamic texture recognition , '' in _ computer vision and pattern recognition .",
    "ieee computer society conference on_. ieee , 2001 , vol .  2 , pp .",
    "ii58 .",
    "arno schdl , richard szeliski , david  h salesin , and irfan essa , `` video textures , '' in _ proceedings of the 27th annual conference on computer graphics and interactive techniques_. acm press / addison - wesley publishing co. , 2000 , pp .",
    "489498 .",
    "vivek kwatra , arno schdl , irfan essa , greg turk , and aaron bobick , `` graphcut textures : image and video synthesis using graph cuts , '' in _ graphics ( tog ) , acm transactions on_. acm , 2003 , vol .",
    "277286 .",
    "byron boots , geoffrey  j gordon , and sajid  m siddiqi , `` a constraint generation approach to learning stable linear dynamical systems , '' in _ advances in neural information processing systems _ , 2007 , pp",
    ". 13291336 .",
    "bernard ghanem and narendra ahuja , `` sparse coding of linear dynamical systems with an application to dynamic texture recognition , '' in _ pattern recognition ( icpr ) , 2010 20th international conference on_. ieee , 2010 , pp ."
  ],
  "abstract_text": [
    "<S> video representation is an important and challenging task in the computer vision community . in this paper </S>",
    "<S> , we assume that image frames of a moving scene can be modeled as a linear dynamical system . </S>",
    "<S> we propose a sparse coding framework , named adaptive video dictionary learning ( avdl ) , to model a video adaptively . </S>",
    "<S> the developed framework is able to capture the dynamics of a moving scene by exploring both sparse properties and the temporal correlations of consecutive video frames . </S>",
    "<S> the proposed method is compared with state of the art video processing methods on several benchmark data sequences , which exhibit appearance changes and heavy occlusions .    </S>",
    "<S> dynamic textures modeling , sparse representation , dictionary learning , linear dynamical systems . </S>"
  ]
}