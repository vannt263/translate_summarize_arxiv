{
  "article_text": [
    "the spline has been widely used in signal processing , numerical computation , statistics , etc . in particular , the _ smoothing spline _",
    "gives a smooth curve that has the best fit to given noisy data @xcite .",
    "the smoothness is achieved by limiting the @xmath1 norm of the @xmath2-th derivative of the curve as well as minimizing the squared error ( or empirical risk ) between data and the curve .    the _ control theoretic smoothing spline _",
    "@xcite is generalization of the smoothing spline using control theoretic ideas , by which the spline curve is determined by the output of a linear dynamical system .",
    "it is shown in @xcite that control theoretic splines give a richer class of smoothing curves relative to polynomial curves .",
    "[ fig : cts ] illustrates the idea of the control theoretic spline ; given a finite number of data , the robot modeled by a dynamical system with transfer function @xmath3 is driven by a control input @xmath4 and draws a smooth curve @xmath5 that fits to the data .",
    "the problem of the control theoretic spline is to find control @xmath4 that gives an expected motion of the robot , based on the model @xmath3 and the data set .",
    "furthermore , the control theoretic spline has been proved to be useful for trajectory planning in @xcite , mobile robots in @xcite , contour modeling of images in @xcite , probability distribution estimation in @xcite , to name a few . for more applications and a rather complete theory of control theoretic splines , see @xcite .",
    "conventional design of control theoretic splines is based on @xmath1 optimization @xcite , and has two main drawbacks .",
    "one is that we need the same number of parameters as the data to represent the fitted curve .",
    "if the data set is big , then the number of parameters becomes crucial when for example the actuator system of the robot ( see fig .",
    "[ fig : cts ] ) has just a small area of memory .",
    "the other drawback is that the spline is not robust against outliers in observed data . in other words , conventional control",
    "theoretic splines are sensitive to outliers . to overcome these drawbacks , we propose to use @xmath0 optimality in the design . for reduction of the number of parameters",
    ", we utilize the _ sparsity - promoting property _ of the @xmath0 norm regularization , also known as lasso ( least absolute shrinkage and selection operator ) @xcite . for robustness against outliers",
    ", we adopt the @xmath0 norm for the empirical risk minimization @xcite , assuming that the noise is laplacian , heavier - tailed distribution than gaussian that is assumed in conventional studies .",
    "the problem is then described in convex optimization , which can be efficiently solved by numerical computation software , e.g. ` cvx ` on matlab @xcite . for numerical computation",
    ", we implement the design procedure on matlab programs with ` cvx ` , access @xcite to obtain the programs .",
    "based on the programs , we show a numerical example that illustrates the effectiveness of the proposed method .    the remainder of this article is organized as follows : section  [ sec : l2 ] reviews the conventional @xmath1-optimal control theoretic spline and discusses drawbacks of the @xmath1 spline .",
    "section  [ sec : l1 ] formulates the problem of the proposed @xmath0 spline to overcome drawbacks in the @xmath1 spline , and show a procedure to the solution . a numerical example is included in section [ sec : simulation ] .",
    "section [ sec : conclusion ] draws conclusions .",
    "that draws a smooth curve @xmath5 with a control input @xmath4 based on given data . ]",
    "consider a linear dynamical system @xmath6 defined by @xmath7 where @xmath8 , @xmath9 .",
    "we assume @xmath10 is controllable and @xmath11 is observable .",
    "for this system , suppose that a data set @xmath12 is given , where @xmath13 are sampling instants which satisfy @xmath14 , and @xmath15 are noisy sampled data of the output of .",
    "the objective here is to find control @xmath4 , @xmath16 $ ] for the dynamical system such that @xmath17 for @xmath18 . for this purpose , the following _ quadratic _",
    "cost function has been introduced in @xcite : @xmath19 where @xmath20 is the regularization parameter that specifies the tradeoff between the smoothness of control @xmath4 defined in the first term of and the minimization of the squared empirical risk in the second term . also , @xmath21 is a weight for @xmath22-th squared loss @xmath23",
    ". then the problem of @xmath1 control theoretic smoothing spline is formulated as follows :    find control @xmath4 that minimizes the cost @xmath24 in subject to the state - space equation in .",
    "the optimal control @xmath25 that minimizes @xmath24 is given by @xcite @xmath26 where @xmath27 is defined by @xmath28,\\\\       0,&\\quad \\text{otherwise . }",
    "\\end{cases }   \\label{eq : gi}\\ ] ] note that @xmath29 in @xmath30 is the impulse response of the dynamical system .",
    "the optimal coefficients @xmath31 are given by @xmath32^\\top=(\\lambda i + wg)^{-1}w{{\\boldsymbol{y } } } ,   \\label{eq : l2optimal}\\ ] ] where @xmath33^\\top .",
    "\\label{eq : y_vec}\\ ] ] the matrix @xmath34\\in { { \\mathbb{r}}}^{n\\times n}$ ] in is the grammian defined by @xmath35    an advantage of the @xmath1 control theoretic smoothing spline is that the optimal control can be computed offline via equation .",
    "however , the formula indicates that if the data size @xmath36 is large , so is the number of base functions in @xmath37 , as shown in .",
    "this becomes a drawback if we have only a small memory or a simple actuator for drawing a curve with the optimal control @xmath37 .",
    "another drawback is that the @xmath1 spline is not robust at all against outliers , as reported in @xcite , since the squared empirical risk in assumes that the additive noise is gaussian . to solve these problems",
    ", we adopt @xmath0 optimality for the design of spline .",
    "before formulating the design problem of @xmath0 spline , we prove the following lemma :    assume that control @xmath4 is given by @xmath38 for some @xmath39 , @xmath40 .",
    "then we have @xmath41 .",
    "\\label{eq : y}\\ ] ] in particular , for @xmath42 , we have @xmath43    if @xmath44 for @xmath45 , then the solution of is given by @xmath46 substituting into the above equation gives .",
    "then , from the definition of @xmath47 in , we immediately have .    by this lemma , the error @xmath48 is given by @xmath49 or equivalently @xmath50 where @xmath51^\\top$ ] and @xmath52 is given in . based on this , we consider the following optimization problem :    [ prob : l1 ] find @xmath53 that minimizes @xmath54 where @xmath55 and @xmath56 .",
    "the regularization term , @xmath57 , is for sparsity of coefficients @xmath58 , as used in lasso @xcite .",
    "also , small @xmath57 leads to small @xmath0 norm of control @xmath59 since from we have @xmath60 for some constant @xmath61 . on",
    "the other hand , the empirical risk term , @xmath62 , is for the fidelity to the data . for @xmath63 , additive noise",
    "is assumed to be laplacian , a heavy - tailed distribution , to take outliers into account , while @xmath64 is related to gaussian noise . in each case , cost function @xmath65 is convex in @xmath66 .    unlike @xmath1 spline",
    ", the solution to the optimization in problem [ prob : l1 ] can not be represented in a closed form .",
    "however , by using a numerical optimization algorithm we can obtain an approximated solution within a reasonable time .",
    "for example , for the optimization with @xmath64 , we can adopt fista ( fast iterative shrinkage - thresholding algorithm ) @xcite , which is an extension of nesterov s work @xcite to achieve the convergence rate @xmath67 at @xmath68-th iteration . on the other hand , for @xmath63",
    ", there is no algorithm achieving such a rate , but the optimization is still convex and we can use an efficient convex optimization software , such as ` cvx ` on matlab @xcite .",
    "the optimization is related to the following signal subspace @xmath69 : u=\\sum_{i=1}^n \\theta_ig(t_i-\\cdot),~ \\theta_i\\in{{\\mathbb{r}}}\\biggr\\}.\\ ] ] that is , we seek the optimal control @xmath59 in @xmath70 such that the coefficients minimize .",
    "note that @xmath71 is a basis of @xmath70 due to the controllability and observability of system .",
    "although we have assumed that the initial state @xmath72 is @xmath73 , we can also set the initial state @xmath74 as a design variable in a similar manner . in this case , the output @xmath5 becomes @xmath75 and the optimization is formulated by @xmath76 where @xmath77^\\top$ ] .",
    "this is also a convex optimization problem and can be efficiently solved via numerical optimization softwares .",
    "the choice of parameters @xmath78 and @xmath79 influences the performance of curve fitting .",
    "the regularisation parameter @xmath78 controls the trade - off between the sparsity and fidelity of the solution ; a larger @xmath78 leads to a sparser solution ( i.e. more @xmath80 s are zero ) while a smaller @xmath78 leads to a smaller empirical risk . on the other hand ,",
    "@xmath79 may be chosen to be larger if the data @xmath81 contains smaller error .",
    "these parameters should be chosen by trial and error ( e.g. cross - validation @xcite ) .",
    "in this section , we show a numerical example that illustrates the effectiveness of the proposed @xmath0 control theoretic smoothing spline .",
    "we set the dynamical system @xmath6 with transfer function @xmath82 state - space matrices for @xmath3 are given by @xmath83 we assume the original curve is given by @xmath84 the sampling instants are given by @xmath85 that is , the data are sampled at rate @xmath86 [ hz ] ( 100 samples per second ) from initial time @xmath87 . the observed data @xmath88",
    "are assumed to be disturbed by additive laplacian noise with mean @xmath89 and variance @xmath90 .",
    "see fig .",
    "[ fig : l1result ] for the original curve @xmath91 and the observed data @xmath88 .    for these data ,",
    "we compute the optimal coefficients of the @xmath0 control theoretic spline with @xmath63 corresponding to laplacian noise .",
    "the design parameters are @xmath92 and @xmath93 for all @xmath22 ( i.e. all elements have equal weight ) .",
    "we assume that the initial state @xmath74 is also a design variable , that is , we solve optimization .",
    "[ fig : l1result ] shows the resulting fitted curve @xmath5 computed with the @xmath0-optimal control @xmath4 .",
    "spline : original curve ( dashed line ) , observed data ( circles ) , fitted curve ( solid line ) . ]",
    "we can see that the data are considerably disturbed by laplacian noise , but the reconstructed curve well fits the original curve . to see the sparsity property of the @xmath0-optimal coefficients ,",
    "we plot the value of the coefficients in fig .",
    "[ fig : l1coef ] .",
    "spline ]    as shown in this figure , the @xmath0-optimal coefficients are quite sparse . in fact , the number of coefficients whose absolute values are greater than @xmath94 is just @xmath95 out of @xmath96 coefficients . on the other hand",
    ", we show the @xmath1-optimal coefficients with @xmath97 , see equation , in fig .",
    "[ fig : l2coef ] .",
    "spline ]    this figure indicates that the coefficients are not sparse at all and the @xmath1 spline requires almost all the base functions to represent the fitted curve .     and fitted curve by @xmath0 spline ( solid line ) and @xmath1 spline ( dashed line ) ]",
    "note that the reconstructed curve by the @xmath1 spline also well fits the original curve as shown in fig .",
    "[ fig : error ] , which shows the error between the original curve and the fitted curves .",
    "this figure shows that the @xmath1 spline is almost comparable with the @xmath0 splines spline outperforms an @xmath1 spline in view of outlier rejection . ] .    in summary , we can say by the simulation that the proposed @xmath0 control theoretic smoothing spline can effectively reduce the effect of noise in data and",
    "also give sufficiently sparse representation for the fitted curve .",
    "in this paper , we have proposed the @xmath0 control theoretic smoothing splines for noise reduction and sparse representation .",
    "the design is formulated as coefficient optimization with an @xmath0 regularized term and an @xmath0 or @xmath1 empirical risk term , which can be efficiently solved by numerical computation softwares .",
    "a numerical example has been shown to illustrate the effectiveness of the proposed @xmath0 spline .",
    "future work may include extension to constrained splines as proposed in @xcite , and extension to sparse feedback control as discussed in @xcite .",
    "this research is supported in part by the jsps grant - in - aid for scientific research ( c ) no .  24560543 , mext grant - in - aid for scientific research on innovative areas no .  26120521 , and an okawa foundation research grant .",
    "j.  k. charles , s.  sun , and c.  f. martin , `` cumulative distribution estimation via control theoretic smoothing splines , '' in _ three decades of progress in control sciences_.1em plus 0.5em minus 0.4emspringer , 2010 , pp . 8392 .",
    "m.  nagahara , `` robust design of control theoretic splines via support vector regression , '' in _ proc .",
    "55th annual conference of the institute of systems , control and information engineers ( iscie ) _ , 2011 ,",
    "( in japanese ) .",
    " , `` graph implementations for nonsmooth convex programs , '' in _ recent advances in learning and control _ , ser .",
    "lecture notes in control and information sciences , v.  blondel , s.  boyd , and h.  kimura , eds.1em plus 0.5em minus 0.4emsplinger , 2008 , vol .",
    "371 , pp . 95110 .",
    "m.  nagahara , d.  e. quevedo , and j.  stergaard , `` sparse packetized predictive control for networked control over erasure channels , '' _ ieee trans .",
    "59 , no .  7 , pp .",
    "18991905 , jul ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose control theoretic smoothing splines with @xmath0 optimality for reducing the number of parameters that describes the fitted curve as well as removing outlier data . </S>",
    "<S> a control theoretic spline is a smoothing spline that is generated as an output of a given linear dynamical system . </S>",
    "<S> conventional design requires exactly the same number of base functions as given data , and the result is not robust against outliers . to solve these problems , we propose to use @xmath0 optimality , </S>",
    "<S> that is , we use the @xmath0 norm for the regularization term and/or the empirical risk term . </S>",
    "<S> the optimization is described by a convex optimization , which can be efficiently solved via a numerical optimization software . </S>",
    "<S> a numerical example shows the effectiveness of the proposed method .    </S>",
    "<S> shell : bare demo of ieeetran.cls for journals    control theoretic splines , smoothing splines , @xmath0 optimization , convex optimization . </S>"
  ]
}