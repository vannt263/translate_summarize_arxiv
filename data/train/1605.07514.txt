{
  "article_text": [
    "many areas of the quantitative sciences have witnessed a data deluge in recent years .",
    "this is due to an increased capacity of measuring and storing data in combination with a reduction in costs of acquiring this data .",
    "for instance , in the medical field high - throughput platforms yield measurements of many molecular aspects ( e.g. gene expression ) of the cell . as many as @xmath0 genes of a single patient can be characterized simultaneously .",
    "however , although the costs of such techniques have gone down over the years , the number of patients @xmath1 in a typical clinical study is still small compared to the number of variables @xmath2 measured .",
    "reliable analysis of data of such a `` @xmath3 '' study is difficult . in this paper",
    "we try to solve the problem of few replicate measurements by incorporating external ( or `` prior '' ) data in the analysis .",
    "high - dimensional modelling based on a small data set is particularly challenging in studies of relationships between variables .",
    "already the number of binary relationships between even a modest number of genes is high .",
    "however , to some extent these relationships may be known from the vast body of medical literature available .",
    "for instance , the current beliefs on interactions among genes is condensed in repositories like kegg and reactome .",
    "although such information may not be reliable , or be only partially relevant for the case at hand , its flexible inclusion may help the analysis of high - dimensional data .",
    "methodology that exploits such prior information may accelerate our understanding of complex systems like the cell .",
    "the cohesion of variables constituting a complex system is often represented by a network , also referred to as a _",
    "graph_. a graph @xmath4 consists of a pair @xmath5 where @xmath6 is a set of indices representing nodes ( the variables of the system ) and @xmath7 is the set of edges ( relations between the variables ) in @xmath8 .",
    "an edge can be operationalized in many ways , we concentrate on it representing conditional independence between the node pair it connects .",
    "more formally , a pair @xmath9 if and only if random variables represented by nodes @xmath10 and @xmath11 are conditionally _ _",
    "de__pendent , given all remaining nodes in @xmath12 .",
    "all pairs of nodes of @xmath12 not in @xmath7 are conditionally independent given the remaining nodes .",
    "graphs endowed with this operationalization of the edges are referred to as conditional independence graphs ( whittaker , 1990 ) .",
    "conditional independence graphs are learned from data by graphical models .",
    "graphical models specify how data are generated obeying the relations among the variables as specified by a conditional independence graph .",
    "a gaussian graphical model ( ggm ) assumes data are drawn from a multivariate normal distribution : @xmath13    here @xmath14 is a @xmath2-dimensional random vector comprising the @xmath2 random variables @xmath15 corresponding to the nodes of @xmath12 and @xmath16 is a non - singular @xmath17-dimensional covariance matrix .",
    "the matrix @xmath18 , as opposed to its inverse , is referred to as the _ precision matrix_. for a ggm the edge set @xmath7 of the underlying conditional independence graph corresponds to the nonzero elements of @xmath18 ( lauritzen , 1996 ) .",
    "hence , to reconstruct the conditional independence graph it suffices to determine the support of this matrix .",
    "reconstruction of the conditional independence graph may concentrate on the direct estimation of the precision matrix . here",
    "we choose a different line of attack .",
    "this exploits an equivalence between gaussian graphical models and simultaneous equations models ( sems ) , which we introduce first before pointing out the equivalence .",
    "we treat sems as a system of regression equations , with each equation modelling the conditional distribution of a node given the other nodes .",
    "if we collect all observations on node @xmath19 in a vector @xmath20 , then we can write : @xmath21 where @xmath22 is the @xmath23-matrix with columns the observations of the @xmath24 nodes different from @xmath25 , i.e.  @xmath26 $ ] ( where the square brackets mean `` combine the vectors in a matrix '' ) .",
    "the error vector @xmath27 is defined by the equation , and possesses a multivariate gaussian distribution @xmath28 under the ggm .",
    "( the covariances between the errors of different equations are in general non - zero , but are left unspecified . ) the equivalence between the thus formulated sem and the ggm as specified above stems from the one - to - one relationship between the regression parameters of the sem and the elements of the ggm s precision matrix ( confer e.g. lauritzen ( 1996 ) ) : @xmath29 . in particular ,",
    "( non)zero entries in the @xmath25-th row vector of the precision matrix @xmath18 correspond to the ( non)zero coefficients of @xmath30 .",
    "the problem of identifying ( non)zero entries in @xmath18 can therefore be cast as a variable selection problem in the @xmath2 regression models .",
    "lasso regression ( tibshirani , 1996 ) may be put forward for this purpose ( as is done in meinshausen and bhlmann ( 2006 ) ) , but other variable selection methods have also been employed .",
    "the slight embarassment that every partial correlation appears in two regression equations is usually resolved by post - symmetrization through application of the ` and'-rule : an edge @xmath31 if and only if @xmath32 and @xmath33 ( meinshausen and bhlmann , 2006 ) . in combination with this ` and'-rule , graph structure recovery based on model performs well and is widely used in practice .",
    "previously , we proposed a bayesian formulation of the sem ( leday et al . , 2015 ) . in this bayesian sem ( henceforth bsem )",
    "the structural model is endowed with the following prior : @xmath34 where @xmath35 is an identity matrix , @xmath36 , and @xmath37 denotes a gamma distribution with shape parameter @xmath38 and rate parameter @xmath39 , and @xmath40 and @xmath41 are independent .",
    "the normal - gamma - gamma ( ngg ) prior of model regularizes the parameter estimates ( e.g. operationalized as the posterior mean ) in two distinct ways .",
    "first , due to the normal prior on the regression coefficients @xmath42 ( corresponding to a ridge penalty ) , the estimates of these parameters are shrunken _ locally _",
    "( i.e.  within each equation ) to zero .",
    "second , the estimates are simultaneously shrunken _ globally _",
    "( i.e. across equations ) , due to the fact that the hyperparameters @xmath43 do not depend on the index @xmath25 . here",
    "we have found a vague prior on the error variances ( e.g.  @xmath44 ) to be appropriate to set the general scale of the problem , whereas estimating the parameters @xmath45 in empirical bayes ( eb ) fashion is advantageous , as it further `` borrows information '' across the regression equations .",
    "the resulting global shrinkage improves inference in particular for large networks ( see also section  [ sectionnumericalinvestigation ] ) .",
    "the bsem model can be fit computationally efficiently by a variational method , and generally outperforms the aforementioned lasso regression approach to the estimation of model .",
    "furthermore , variables can be accurately selected based on the marginal posterior distributions of the regression coefficients ( leday et al . , 2015 ) .",
    "the problem of network reconstruction is challenging due to the vast space of possible graphs for even a moderate number of variables .",
    "this endeavour is further complicated by the inherent noise in the measurements used for the reconstruction .",
    "fortunately , network reconstruction need not start from scratch , as often similar networks have been studied previously .",
    "prior information on the network may be available in the literature , repositories , or simply as pilot data .",
    "it is natural to take such information along in network reconstruction .",
    "this is already done in areas of ( dynamic ) bayesian networks . among these studies ,",
    "werhli et al . proposed a framework to incorporate multiple sources of prior knowledge into dynamic bayesian network using mcmc sampling ( werhli and husmeier , 2007 ) .",
    "in bayesian network learning murkherjee and speed ( 2008 ) proposed a method to incorporate network features including edges , classes of edges , degree distributions , and sparsity using mcmc sampling .",
    "isci et al .",
    "( 2013 ) proposed also a framework to incorporate multiple sources of external knowledge in bayesian network learning where the incorporation of external knowledge uses bayesian network infrastructure itself .",
    "however , none of these proposed methods accounts for the relevance of the prior knowledge .    in this paper",
    "we develop a method for incorporating external data or prior information into the reconstruction of a conditional independence network . to this aim",
    "we extend in section  [ sectionmodel ] the bayesian sem framework - .",
    "the extension incorporates prior knowledge in a flexible manner .",
    "next in section  [ sectionvariationalbayes ] we develop a variational bayes approach to approximate the posterior distributions of the regression parameters for given hyperparameters , and show this to be comparable in accuracy to gibbs sampling , although computationally much more efficient . in section  [ sectionglobaleb",
    "] this is complemented by a derivation of an empirical bayes approach to estimate the hyperparameters . using simulations we show in section  [ sectionnumericalinvestigation ] that the method performs better than competing methods that do not incorporate prior information ( including bsem ) when the prior knowledge is relevant , and",
    "is as accurate when it is not . in section  [ sectionillustration ]",
    "we show the full potential of our approach on real data .",
    "we conclude the paper with a discussion .",
    "the bsem approach , comprising model with priors , is modified to incorporate external information on the to - be - reconstructed network .",
    "the resulting model is referred to as bsemed ( bsem with _ _ e__xternal _ _ d__ata ) .",
    "prior knowledge on the network is assumed to be available as a `` prior network '' , which specifies which edges ( conditional independencies ) are present and absent .",
    "this is coded in an adjacency matrix , which contains only zeros and ones corresponding to the absence and presence of an edge in the prior network .",
    "that is , @xmath46 if node @xmath25 is connected with node @xmath47 and @xmath48 otherwise .",
    "note that the adjacency matrix p is symmetric ( for the purpose of undirected network reconstruction ) .",
    "the bsemed approach keeps equation , but replaces the priors of bsem by : @xmath49    the normal - gamma - gamma - gamma ( nggg ) prior retains the ridge - type regularization of the regression parameters @xmath42 of , through gaussian priors on these coefficients .",
    "the crucial difference between the two priors reveals itself in the variances of the latter priors . for each regression equation @xmath25",
    "there are two possible variances : @xmath50 hence , the regression coefficients corresponding to edges that are present according to the prior information share the same variance , and similarly for the other set of regression coefficients .",
    "both variances can be both small and large , as they are themselves modelled through gamma priors , where small values lead to small regression coefficients .",
    "if the prior information on the network were correct , then naturally a small value of @xmath51 would be desirable , smaller than the value of @xmath52 .",
    "however , the construction is open - minded in that the two values , and even their priors , are not fixed a - priori . in the two parameters @xmath51 and @xmath52 receive gamma priors , with different hyperparameters @xmath53 and @xmath54 . for further flexibility",
    "these hyperparameters will be adapted to the data by an empirical bayes method .",
    "then , if the absence of an edge in the prior network is corroborated by the current data , the corresponding regression coefficient @xmath42 may stem from a prior with a small variance , and will tend to be small ; a similar , but opposite , situation will occur for edges that are present in the prior network . indeed in section  [ sectionnumericalinvestigation ]",
    "we shall see that the eb approach will tend to find similar values of @xmath55 and @xmath56 when the prior knowledge is non - informative , and rather different values otherwise .",
    "the fact that model contains the model as a submodel , harnesses against the misspecification of the prior information .",
    "although the number of latent variables in is considerably higher ( namely @xmath24 additional variances , one for each regression equation ) , the actual number of extra parameters is only two ( the pair @xmath54 ) .",
    "this explains that if the prior information is incorrect or irrelevant for the data at hand , then the cost in terms of precision of the estimators is minor .",
    "it is amply compensated by the gains if the prior information is correct .",
    "we corroborate this in our simulation study in section  [ sectionnumericalinvestigation ] . in this connection it is also of interest to note the interchangeable roles of @xmath57 and @xmath58 , which causes pairs of complementary prior networks to lead to exactly the same `` posterior network '' . for instance , the empty and complete graphs ( see figure  [ figurecompletegraph ] ) boil down to the same prior .",
    "in this section we develop a variational bayes approach to approximate the ( marginal ) posterior distributions of the parameters @xmath59 in model .",
    "the algorithm is similar , but still significantly different , from the algorithm developed in leday et al .",
    "( 2015 ) for the model . in the following",
    "we can see that , due to , the variational parameters have a form which renders the implementation of much more challenging .",
    "we also verify that these approximations are accurate by comparing them to the results obtained using a gibbs sampling strategy , which is much slower .",
    "computational efficiency is an important characteristic , especially for fitting large networks .    in this section",
    "we work on a single regression equation , i.e.  for a fixed index @xmath25 , and given hyperparameters @xmath60 , for @xmath61 . in the next section",
    "we combine the regression equations to estimate the hyperparameters .",
    "in general a `` variational approximation '' to a distribution is simply the closest element in a given target set @xmath62 of distributions , usually with `` distance '' measured by kullback - leibler divergence .",
    "the set @xmath62 is chosen both for its computational tractability and accuracy of approximation .",
    "distributions @xmath63 with stochastically independent marginals ( i.e.  product laws ) are popular , and then the `` accuracy '' of approximation is naturally restricted to the marginal distributions .    in our situation",
    "we wish to approximate the posterior distribution of the parameter @xmath64 given the prior and the observation @xmath65 given in , for a fixed @xmath25 . here in",
    "we take @xmath22 ( which depends on @xmath66 for @xmath67 ) as given , as in a fixed - effects linear regression model . for @xmath68 the posterior density in this model , the variational bayes approximation is given as @xmath69 where the expectation is taken with respect to the density @xmath70 . for @xmath71 the joint density of @xmath72 ,",
    "this is equivalent to finding the maximizer of @xmath73 by the nonnegativity of the kullback - leibler divergence , the latter expression is a lower bound on the marginal density @xmath74 of the observation , and consequently is usually referred to as `` the lower bound '' .",
    "solving the variational problem is equivalent to maximizing this lower bound ( over @xmath62 ) .",
    "we choose the collection @xmath62 equal to the set of distributions of @xmath75 for which the components @xmath30 , @xmath76 , @xmath77 and @xmath78 are stochastically independent , i.e.  @xmath79 , where the marginal densities @xmath80 are arbitrary .",
    "given such a factorization of @xmath81 it can be shown in general ( see e.g. ormerod and wand ( 2010 ) ) , that the optimal marginal densities @xmath82 satisfy : @xmath83 it can be shown ( see the supplementary material ) that in model for regression equation @xmath25 , with @xmath84 , this identity can be written in the concrete , `` conjugate '' form @xmath85 where @xmath86^{-1 } , \\\\ \\beta_i^ * & = \\big[x_i^tx_i + { \\bf{d}}_{\\mathbf{e}_{q^\\ast_2\\cdot q^\\ast_3}(\\tau_i^2)}\\big]^{-1}x_i^ty_i,\\end{aligned}\\ ] ] @xmath87 where @xmath88 and @xmath89 are the number of @xmath90 s and @xmath91 s in the @xmath25-th row of the adjacency matrix , not counting the diagonal element ; and @xmath92 and @xmath93 are the coordinates of the vector of regression parameters corresponding to these @xmath90 s and @xmath91 s .",
    "furthermore @xmath94 in these identities the optimal densities @xmath95 appear both on the left and the right of the equations and hence the identities describe the optimal densities only as a fixed point . in practice",
    "the identities are iterated `` until convergence '' from suitable starting values .",
    "the iterations also depend on the hyperparameters @xmath60 . in the next section",
    "we describe how these parameters can be estimated from the data by blending in updates of these parameters in the iterations .      under the true posterior distribution",
    "the coordinates @xmath96 are not independent .",
    "this raises the question how close the variational approximation is to the true posterior distribution . as the latter is not available in closed form",
    ", we investigate this question in this section by comparing the variational approximation to the distribution obtained by running a gibbs sampling algorithm for a long time . as for the network reconstruction we only use the marginal posterior distributions of the regression parameters ,",
    "we restrict ourselves to these marginal distributions .",
    "the full conditional densities of bsemed can be seen to take the explicit form : @xmath97    where the parameters @xmath98 , @xmath99 , @xmath100 and @xmath101 satisfy the same system of equations as in the variational algorithm , except that all expectations @xmath102 must be replaced by the `` current '' values taken from the conditioning ( see supplementary material ) .",
    "thus gibbs sampling of the full posterior @xmath103 is easy to implement , although slow .",
    "we ran a simulation study with a single regression equation ( say @xmath104 ) with @xmath105 , and compared the variational bayes estimates of the marginal densities with the corresponding gibbs sampling - based estimates .",
    "thus we sampled @xmath106 independent replicates from a @xmath107-dimensional normal distribution with mean zero and @xmath17-precision matrix @xmath108 , and formed the vector @xmath109 and matrix @xmath110 as indicated in .",
    "the precision matrix was chosen to be a _ band matrix _ with a lower bandwidth @xmath111 equal to the upper bandwith @xmath112 .",
    "it is @xmath113 , thus a total number of @xmath114 band elements including the diagonal .",
    "for both the variational approximation and the gibbs sampler we used prior hyperparameters @xmath44 and prior hyperparameters @xmath115 fixed to the values set by the _",
    "global _ empirical bayes method described in section  [ sectionglobaleb ] .",
    "the gibbs iterations were run @xmath116 times , after which the first @xmath117 iterates were discarded . in figure  [ figuregibbs ]",
    "we plot histograms based on subsampling every 10th value of the iterations , with the variational bayes approximation to the marginal posterior densities overlaid as a curve . to save space we only plot the densities of @xmath118 and @xmath119 ;",
    "the plots of the densities of @xmath120 are very similar .",
    "the correspondence between the two methods is remarkably good .",
    "we conclude that the variational bayes method gives reliable estimates of the posterior marginal distributions .",
    "table  [ tablegibbs ] compares the computing times for the two methods ( in r ) .",
    "the variational method clearly outperforms the gibbs sampling method , which would hardly be feasible even for @xmath105 .",
    "[ cols=\"^,^,^,^\",options=\"header \" , ]     [ pancreasrepro ]    we observe from tables [ lungrepro ] & [ pancreasrepro ] that the results from the bsemed networks are much more reproducible than that of bsem , which is on its turn more reproducible than the other ones .",
    "clearly , the improvement can partly be explained by overlapping edges that were also part of the prior network .",
    "however , it is clear from figure [ venndiagram ] that the bsemed network estimate in tumor tissue is not just a ` finger print ' of the prior network ( normal tissue network ) : bsemed can even reveal edges that are neither in prior network nor in bsem network estimate .",
    "figure [ lungpriorpost ] ( resp .",
    "figure [ pancreaspriorpost ] ) displays the network in normal tissue against the network in tumor tissue in the lung data ( resp . in the pancreas data ) .",
    "we have presented a new method for incorporating prior information in undirected network reconstrustion based on bayesian sem .",
    "our approach allows the use of two central gaussian distributions per regression equation for coefficients @xmath42 s of our sems , where the prior information determines which of the two applies to a specific @xmath42 . empirical bayes estimation of the parameters of the two hyper priors of the precisions effectuates shrinkage and accommodates the situation where the prior information would not be relevant .",
    "we showed in simulation with different graph structures that bsemed performs clearly better than bsem when the used prior knowledge is relevant and as good as when not .",
    "in addition , for two real data sets we showed better reproducibility of top ranking edges with respect to other methods .    instead of assigning gaussian distributions to the coefficients , other ( e.g. sparse ) priors can be used . however , the fast variational bayes method for posterior density approximation may not be of use anymore .",
    "for instance , would one use horseshoe priors ( carvalho et al . , 2010 ) , the variational marginals are non - existent .",
    "the complement property ( section [ sectionmodel ] ) is preserved whenever the same functional forms of the priors are used for both classes . however , a combination of e.g. a gaussian and a sparse prior ruins this property , which renders such a combination less attractive .",
    "future research also focuses on extending our method to situations with more than two classes .",
    "for example , when considering integrative networks for two sets of molecular markers or two ( related ) pathways , the three class setting is relevant : two classes represent the connections within the two sets and a third one between the two sets",
    ". finally , multiple sources of external data may be at one s disposal and need incorporation in bsemed .",
    "this requires to model the parameter(s ) of the priors in terms of contibutions of those external sources , and weigh those sources in a data - driven manner , as it is unlikely that the sources are equally informative .",
    "10 badea , l. , herlea , v. , dima , s. o. , dumitrascu , t. and popescu , i. ( 2008 ) .",
    "combined gene expression analysis of whole - tissue and microdissected pancreatic ductal adenocarcinoma identifies genes specifically overexpressed in tumor epithelia .",
    "_ hepatogastroenterology _ * 55 * , 20162027 .",
    "landi , m. t. , dracheva , t. , rotunno , m. , figueroa , j. d. , dasgupta a. , liu , h. , mann , f. e. , fukuoka , j. , hames , m. , bergen , a. w. , murphy , s. e. , yang , p. , pesatori , a. c. , consonni , d. , bertazzi , p. a. , wacholder , s. , shih , j. h. , caporaso , n. e. , and jen , j. j. ( 2008 ) .",
    "gene expression signature of cigarette smoking and its role in lung adenocarcinoma development and survival .",
    "_ plos one _ * 3 * , e1651 .",
    "lauritzen , s. ( 1996 ) .",
    "_ graphical models_. the clarendon press , oxford university press , new york .",
    "leday , g. g. r. , de gunst , m. , kpogbezan , g. b. , van der vaart , a. w. , van wieringen , w. n. , and van de wiel , m. a. ( 2015 ) .",
    "gene network reconstruction using global - local shrinkage priors .",
    "_ arxiv preprint arxiv:1510.03771[stat.me]_.                van de wiel , m. a. , leday , g. g. r. , pardo , l. , rue , h. , van der vaart , a. w. , and van wieringen , w. n. ( 2012 ) .",
    "bayesian analysis of rna sequencing data by estimating multiple shrinkage priors",
    ". _ biostatistics _ * * .",
    "werhli , a. and husmeier , d. ( 2007 ) .",
    "reconstructing gene regulatory networks with bayesian networks by combining expression data with multiple sources of prior knowledge .",
    "_ statistical applications in genetics and molecular biology"
  ],
  "abstract_text": [
    "<S> reconstruction of a high - dimensional network may benefit substantially from the inclusion of prior knowledge on the network topology . in the case of gene interaction networks </S>",
    "<S> such knowledge may come for instance from pathway repositories like kegg , or be inferred from data of a pilot study . </S>",
    "<S> the bayesian framework provides a natural means of including such prior knowledge . </S>",
    "<S> based on a bayesian simultaneous equation model , we develop an appealing empircal bayes procedure which automatically assesses the relevance of the used prior knowledge . </S>",
    "<S> we use variational bayes method for posterior densities approximation and compare its accuracy with that of gibbs sampling strategy . </S>",
    "<S> our method is computationally fast , and can outperform known competitors . in a simulation study </S>",
    "<S> we show that accurate prior data can greatly improve the reconstruction of the network , but need not harm the reconstruction if wrong . </S>",
    "<S> we demonstrate the benefits of the method in an analysis of gene expression data from geo . </S>",
    "<S> in particular , the edges of the recovered network have superior reproducibility ( compared to that of competitors ) over resampled versions of the data . </S>"
  ]
}