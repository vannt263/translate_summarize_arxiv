{
  "article_text": [
    "modern erasure codes allow efficient encoding and decoding schemes for use in a wide range of applications .",
    "recent schemes include _ digital fountain _ codes @xcite , raptor codes @xcite and lt codes @xcite .",
    "these codes are rateless erasure codes , in the sense that the encoder produces a practically infinite stream of packets , such that the original data can be efficiently decoded from any sufficiently large subset .",
    "these codes allow linear time encoding and decoding , with high probability .",
    "nevertheless , to the best of our knowledge , such codes are only resilient to _ lossy channels _ , where packets may be lost but not arbitrarily corrupted . as a consequence , such solutions can not cope with _ byzantine _ channels , where an adversary may arbitrarily change packets ; for instance , when communication is done over parallel paths and some paths are under the control of an adversary .",
    "such attacks can not be attended to using standard error correcting codes .",
    "consider , for example , a raptor code , where encoded packets are sent in order to transfer a message .",
    "each packet sent is further encoded by using an error correcting code .",
    "consider an adversary which corrupts a single packet and the packet s error correction padding , such that the error correcting code does not identify the packet as a corrupted packet .",
    "this corrupted packet may well prevent the receiver from correctly decoding the entire original message .    in this work , we design and analyze novel erasure codes which are capable of withstanding malicious packet corruption .",
    "our coding scheme resemble lt codes , yet are information theoretic secure ( in a sense to be rigorously defined ) .",
    "corruption resilient fountain codes have numerous applications .",
    "we present here but a few .",
    "* erasure coding*. consider a peer - to - peer system , where a user would like to receive some content . to alleviate the load on any single peer",
    ", the content may be mirrored at several peers .",
    "on the other hand , to maximize bandwidth usage , the user should be able to receive parts of the content from several mirrors in parallel .",
    "erasure codes , and in particular digital fountain codes , give rise to a simple solution to this problem ; each mirror locally , and independently , generates packets and sends them to the user .    alas",
    ", the system described above is very sensitive to byzantine peers ; when even one of the mirrors intentionally corrupts packets , the receiver will never be able to reconstruct the requested content .",
    "a more robust solution is to use the corruption resilient fountain codes derived herein , such that a constant fraction of byzantine mirrors can be tolerated .",
    "* shared value*. consider a group of sensors which receive and record global inputs .",
    "the inputs may be from a control and command entity , such as a satellite , or a natural event that the sensors sense .",
    "the sensors wish to store such inputs ( or some global history ) for later retrieval .",
    "assume the initially shared value @xmath0 includes @xmath1 bits .",
    "we wish to reduce the storage requirements at each sensor , such that each sensor will only need to store a fraction of the @xmath1 bits .",
    "we require that _ no communication _ takes place during the initial stage , so that each sensor generates its own encoded ( short ) share of @xmath0 independently of other sensors .",
    "the sensors may communicate later to reconstruct @xmath0 from the stored shares .",
    "moreover , the solution should be robust against a constant fraction of byzantine sensors , where a byzantine sensor may introduce arbitrary information into the system .",
    "corruption resilient fountain codes can be used to solve the _ shared value _ problem .",
    "we present a randomized scheme in which shared data is efficiently recorded with _ no communication _ among the sensors .",
    "note that , in some cases , it is also possible to update the encoded data without decoding ( e.g. @xcite ) .",
    "the current literature includes several different strategies for coping with byzantine adversaries , both in erasure coding and network coding scenarios . a common approach to overcome byzantine adversaries when implementing erasure codes is to check each received packet against a pre - computed hash value , to verify the integrity of the packet . when using fixed rate codes , the sender can pre - compute the hash value of each possible packet and publish this hash collection in a secure location .",
    "the receiver first retrieves this pre - computed hash collection and verifies each packet against the packet s hash as the packet arrives .",
    "the hash is a one way function and , therefore , when the adversary is computationally limited , the adversary can not introduce another packet with the same hash .",
    "however , when using rateless codes , such techniques are not feasible ; as there is practically an infinite number of different packets , there is no efficient way to pre - compute the hash value of each possible packet and send these hashes to the receiver .",
    "furthermore , inherent to to hashing technique is secure publication of the hashes .",
    "the sender must devise a way to securely transfer hashes to the receiver , say , by an expensive flooding technique .",
    "in this work , we completely avoid the need for such a secret channel .    in @xcite , a slightly different technique for packet verification in rateless codes",
    "therein , a merkle - tree  @xcite based signature structure is suggested . however , the solution proposed is , still , only valid against computationally bounded adversaries and relies on the existence of homomorphic , collision - resistant hash functions .",
    "furthermore , as the size of a merkle - tree is linear in the size of the original message , the authors propose a process of repeated hashing to reduce the size of the tree .",
    "such recursive application of a hashing function is more likely to be susceptible to attack .",
    "an efficient scheme for signature generation of rateless codes appears in @xcite , where the authors use the computational hardness of the discreet log to provide a pki which enables the sender to efficiently sign each packet transmitted .",
    "the scheme is based on looking at the data being sent as spanning a specific vector space , and looking at packets as valid as long as they belong to the same vector space .",
    "the verification part uses standard cryptographic devices to facilitate the check .    in this paper , however , we provide an _ information theoretically _ secure rateless erasure code , by introducing encoding and decoding techniques which have a provable low probability of not recovering from an attack , assuming sufficiently many packets are collected .",
    "although not immediately apparent , network codes are closely related to rateless erasure codes .",
    "erasure codes may benefit from techniques to cope with byzantine adversaries developed for network coding and vice versa .",
    "several network coding related papers discuss the merits of using hash functions to overcome byzantine adversaries in network coding protocols , all of which require out of band communication or preprocessing .",
    "other protocols employ some kind of shared secret between the sender and receiver to cope with computationally bounded adversaries .",
    "a different solution appears in  @xcite where the only assumption needed to overcome an all - powerful adversary is a shared value between the sender and the receiver , which may also be known to the adversary .",
    "this shared value is , in fact , a parity check matrix , with which a sender inserts redundant bits to the data , enabling the receiver to identify the single correct message from a list generated by a _ list decoder_. using sufficient redundant information , the receiver can overcome a byzantine adversary , as long as the adversary can not control more than half of the network s capacity ( which is the minimal cut between the sender and receiver ) .",
    "however , this solution requires , yet again , out of band communication or preprocessing , as the sender and receiver must share a value before starting the communication .",
    "more importantly , the redundancy matrix , which controls the amount of the redundant information inserted , needs to be _ known at the sender in advance_. in other words , a sender needs to know how strong the adversary is ( how many packets it controls ) in order to know how much redundant information to insert . in the solutions we present herein , the sender is completely oblivious to the strength of the attacker ( or its actual existence ) .",
    "finally , note that the solution presented in  @xcite requires batching packets into groups of predetermined size and is not rateless in nature , especially not when a few senders are involved .    in @xcite , koetter and",
    "kschischang present a different approach , based on high dimensional vector spaces ; a message of @xmath2 bits is encoded into a vector space , @xmath3 , of dimension @xmath4 , which is a subspace of an ambient vector space @xmath5 of dimension @xmath6 .",
    "@xmath7 is a parameter of the encoding scheme , @xmath8 is the number of bits in a message block and @xmath1 is the number of blocks in the message .",
    "each packet the sender creates is a randomly chosen vector ( of @xmath6 bits ) in @xmath3 .",
    "the receiver , upon collecting enough vectors  @xmath7 linearly independent vectors  can proceed to reconstruct the original message from the received vector space @xmath9 .",
    "the authors present a minimal distance decoder , which can recover @xmath3 from @xmath9 provided that , when writing @xmath9 as @xmath10 where @xmath11 is the error space , @xmath12 and @xmath13 , it holds that @xmath14 .",
    "the codes presented in @xcite have theoretical merits .",
    "nevertheless , they suffer from several severe implementation problems ; to boost the error resiliency of the code , one should ( a ) increase @xmath7 or ( b ) decrease @xmath1 . the implications are the need for sending more redundant information in each packet ( increasing @xmath7 ) and having larger packet sizes ( decreasing @xmath1 ) . moreover ,",
    "to recover from a byzantine attack on at most a third of the packets sent , the codes presented require that @xmath15 ( that is , each block must be of length @xmath16 bits ) , where @xmath17 is the size of the message .",
    "in contrast , our codes are not limited by block sizes and can cope with one third of byzantine corrupted packets regardless of the block size .      in this work , we design and analyze rateless codes with the following merits .",
    "first , they are resilient to byzantine attacks . under some mild constraints",
    ", they asymptotically achieve the optimum rate of @xmath18 , where @xmath19 is the channel ( or network ) capacity , and @xmath20 is the number of corrupted packets .",
    "second , the codes use sparse encoding vectors , enabling a decoding complexity of @xmath21 instead of the usual @xmath22 for non - sparse codes .",
    "third , the encoding scheme carried out at the sources does not depend on the strength of the adversary ( the number of packets it can corrupt ) , and hence is universal in this sense .",
    "forth , the codes do not require any secrete channel or shared data between the sources and receivers .",
    "moreover , no communication between the sources is required in case a few sources cooperate to send a common global value .",
    "the rest of the paper is organized as follows .",
    "the system settings and attack strategies on existing codes appear in section [ s : ss ] .",
    "our new coding schemes appear in section [ s : local ] .",
    "the paper is concluded in section [ s : cr ] .",
    "a rateless erasure code is defined by a pair of algorithms , @xmath23 , such that , given a set of input symbols , @xmath24 can produce a practically infinite sequence of different output _",
    "packets_. moreover , from any large enough set of packets , @xmath25 can be used to recover all of the original symbols .",
    "a rateless erasure code is usually used between a _ sender _ and a _ receiver _ , where the sender wishes to send a specific message to the receiver .",
    "the sender starts by dividing the message into symbols , and then uses @xmath24 to generate packets , which are then sent to the receiver over a lossy channel .",
    "the receiver , after collecting enough packets , uses @xmath25 to recover the original symbols and , from them , the message .",
    "next , we define the adversarial model we use .",
    "we assume that the computational power of the adversary is _ unlimited _ , and the adversary may _ sniff all traffic _ in the network .",
    "furthermore , the adversary may forge or alter packets such that the receiver can not differentiate them from legitimate packets .",
    "the only restriction we place on the adversary is the number of packets the adversary may corrupt .",
    "the restriction is defined by looking at all packets arriving at the receiver .",
    "we then say that an adversary is @xmath26-bounded , with a parameter @xmath27 , if , for each @xmath28 and for each set of packets collected by the receiver of size @xmath29 , no more than @xmath30 packets are corrupted .",
    "this property captures the ratio between the number of collected packets and the number of errors allowed .",
    "given the above settings , we discuss possible ways an adversary may influence the belief propagation decoding algorithm used by @xcite .",
    "belief propagation decoding suits the following succinct encoding algorithm : to generate a packet , choose a random subset of input symbols and xor them .",
    "the exact distribution from which input symbols are sampled forms the critical part of the encoding algorithm , and defines the number of packets needed for correctly decoding the input symbols .",
    "belief propagation decoding then works as follows : given a set of packets , define a bipartite graph , @xmath31 , where the bottom layer , @xmath32 , contains the packets and the upper layer , @xmath33 , the input symbols .",
    "an edge exists between a packet @xmath34 and a symbol @xmath35 , if @xmath36 was used in generating @xmath37 .",
    "the belief propagation decoder is described in figure  [ algo : bfd ] , where the successful completion of the decoding process depends on the neighbor distribution .      in the simple scenario depicted in figure  [ fig::simpleattack ]",
    ", the adversary can corrupt each decoded symbol by altering a single encoding packet overall . in general",
    ", it would be interesting to find the best possible strategy for the adversary given that the adversary works either _ offline _ or _ online _ and is _ uniform _ or _",
    "selective_. @xmath38 offline vs. online adversaries . an _ offline _",
    "adversary knows , in advance , the graph generated at the _",
    "receiver_. an _ online _ adversary must base his decision to corrupt / inject a single packet on the information available from the packets that traversed the system so far .",
    "@xmath38 uniform vs. selective adversaries . a @xmath26-bounded",
    "_ uniform _ adversary simulates random noise by uniformly corrupting at most a fraction @xmath26 of all the received packets .",
    "bare in mind that such an adversary , though he can not choose _ which _ packets to corrupt , can choose _ how _ to corrupt them , negating simple solutions such as using crc or hashes .",
    "in contrast , a _ selective _ @xmath26-bounded adversary can choose , non - uniformly , which packets to corrupt ( and , of course , how to corrupt the packets ) .",
    "it seems that the offline , selective adversarial model is the most severe model , and we will target our results appropriately .",
    "we will present more efficient solutions for a weaker model when applicable .    under the definitions above",
    ", an interesting question is what would be the optimal strategy for a given adversary in order to corrupt the largest number of decoded symbols , given that the adversary is @xmath26-bounded .",
    "this immediately translates to an upper bound on the number of symbols the adversary can corrupt , a bound which may be employed in devising techniques to overcome the adversary .    we illustrate the vulnerability of the belief propagation decoder by presenting the following attacks , using an online , selective adversary .",
    "note that we believe that the specific attacks we list and prove are not the most severe ; our tests show that corrupting a very small ( constant ) portion of the packets corrupts almost half of the symbols .",
    "* @xmath38 the vanishing symbol attack*. when using the robust solition distribution to generate packets , one may calculate the fraction of the packets in which each input symbol participates . assuming that each symbol participates in the generation of a fraction of @xmath26 packets , a simple online _ selective",
    "_ @xmath26-bounded adversary can remove all traces of the symbol from the system : fix an input symbol , @xmath33 .",
    "the adversary will then remove from each packet in which @xmath33 participated the indication that @xmath33 was xored into the packet .",
    "the decoder will then never successfully decode the entire message , as @xmath33 will always be missing .    in ( * ? ? ?",
    "* theorem 13 ) , it is shown that the average degree of a packet , when using the robust soliton distribution , is in @xmath39 ( where @xmath40 is the probability of successful decoding ) . as the input symbols for each packet is chosen uniformly , each input symbol has a probability of ( approximately ) @xmath41 to be chosen for each packet .",
    "this further implies that a @xmath26-bounded _ online , selective _ adversary may prevent the receiver from successfully decoding ( approximately ) @xmath42 symbols .",
    "we note that this number of symbols is only a gross estimate , as symbols with smaller degrees than the average are numerous .    *",
    "@xmath38 odd packets attack*. the following simple _ online , selective _ adversary can corrupt all decoded symbols ; consider corrupting all packets which have an odd degree , i.e. , connected to an odd number of symbols .",
    "corrupt each packet by flipping all bits ( or a subset thereof ) . using a simple inductive argument",
    ", we are able to prove that the resulting decoded symbols from the belief propagation decoder will all be flipped .",
    "the proof is by inspecting the sets of odd and even degree packets , throughout the execution of the belief propagation decoder .",
    "packets of odd degree are corrupted , and packets of even degree are not . moreover , as each packet moves from one set to the other , all the packets in the odd degree set remain corrupted and those in the even degree set remain correct .",
    "since each symbol is eventually decoded by copying a packet of degree one , all decoded symbols will be corrupted .",
    "the following proposition shows that indeed , when using the robust soliton distribution from  @xcite , the expected fraction of such odd degree packets is less than one third , and the adversary can corrupt all symbols with a non - zero probability .",
    "one - half ] when using the robust soliton distribution , the odds packets attack has a probability of at least one half to corrupt all decoded symbols .",
    "we start by analyzing the ideal soliton distribution from  @xcite , which specifies that , for @xmath1 input symbols , the degree distribution of each encoded packet is @xmath43=\\rho(i)=\\left\\ {     \\begin{array}{ll } \\frac{1}{k } & i=1\\\\ \\frac{1}{i(i-1 ) } & i\\ge 2 \\end{array } \\right.\\ ] ] the probability that for a given packet @xmath44 , the degree is odd is @xmath45 & = & \\sum_{i\\ge 1 , i \\textrm { is odd}}^k\\rho(i ) \\\\ & \\le & \\frac{1}{k } + \\frac{1}{3\\cdot2}+\\frac{1}{5\\cdot4 } + \\frac{1}{7\\cdot6}+\\cdots \\\\ & = & \\frac{1}{k}+\\sum_{i=2}^\\infty \\frac{(-1)^i}{i } = \\frac{1}{k}+1-\\ln(2).\\end{aligned}\\ ] ] we get that for @xmath46 , the probability for each packet to be of odd degree is less than @xmath47 . now , consider a binomial random variable , @xmath48 , such that @xmath17 equals the number of packets and @xmath49 .",
    "@xmath50 represents the number of packets of odd degree .",
    "the adversary can successfully corrupt all symbols , as long as @xmath51 . using the normal approximation for the binomial distribution ( where @xmath52 ) , we get that : @xmath53 \\approx p[z\\leq \\dfrac{n/3-np}{\\sqrt{np(1-p ) } } ] \\ge \\dfrac{1}{2}.\\ ] ]",
    "therefore , the adversary has a probability of at least half to corrupt all decoded symbols by corrupting at most one third of the packets .",
    "we start the presentation of our codes by discussing the encoding phase .",
    "we then proceed to establish the necessary tools required for successfully decoding an encoded message , and present several decoding alternatives , discussing the merits of each .      to encode a given message of @xmath17 bits , split the message into @xmath8 blocks ( the input symbols ) , @xmath54 , each of length @xmath55 bits .",
    "for each @xmath56 , let @xmath57 be the @xmath58th bit of the @xmath29th message piece .",
    "for a @xmath1 dimensional vector @xmath59 over @xmath60 define the characteristic boolean function ( or linear form ) @xmath61 in the following way : @xmath62 ( in other words , the inner product of @xmath0 and @xmath63 over @xmath60 ) .    to generate a packet @xmath44 , randomly select a @xmath1 dimensional vector @xmath64 ( the distribution used to sample @xmath65 will be discussed later ) , and set @xmath66 .",
    "note that , for brevity , each packet is assumed to be of length @xmath67 bits ; later , we show how to reduce the amount of redundancy needed from @xmath1 to @xmath68 bits , in essence by compressing the vector @xmath65 .",
    "we define the following :    two packets , @xmath69 and @xmath70 , are termed _ independent _ if their associated @xmath71 vectors are independent over @xmath60 .    alternatively , a more efficient decoding ( hardware - wise ) is achieved by setting @xmath72 and then @xmath73 , where @xmath74 .",
    "this representation is more efficient as it is faster to xor entire _ words _ than individual _",
    "bits_. we note that such encoding is similar to the one presented in @xcite .",
    "the decoding procedures below are applicable for both encoding alternatives . for brevity",
    ", we only discuss the first .      before introducing the decoding algorithms ,",
    "we prove the following three lemmas , which discuss the number of uncorrupted packets required in order to have a set @xmath1 independent equations .",
    "these lemmas are required in order to determine how many packets should a decoder collect before attempting to decode , depending on its knowledge on the number of corrupted packets and , of course , the type of the adversary ( random or selective ) .",
    "the first considers the probability that a uniformly random linear system is not of full rank .",
    "[ lemma : prob_uni ] the probability that a system @xmath75 of @xmath8 vectors of dimension @xmath1 ( @xmath76 ) , chosen at random uniformly and independently over @xmath60 , is not of full rank @xmath1 is at most @xmath77 .    the importance of lemma [ lemma : prob_uni ] is clear .",
    "suppose a decoder collects @xmath78 uncorrupted packets , @xmath79 , whose coefficients are drawn from the uniform distribution .",
    "then , with probability at least @xmath80 , the packets include @xmath1 independent equations .",
    "( adapted from @xcite ) : enumerate the vectors of @xmath75 arbitrarily .",
    "consider the case in which the first @xmath1 vectors are not independent .",
    "if so , these vectors span , at most , a half plane of dimension @xmath81 . for the entire system @xmath75 to be of rank less than @xmath1",
    ", each remaining vector should be in this half plane .",
    "the probability of each of these @xmath82 vectors to be uniformly chosen from this half place is at most @xmath83 .",
    "therefore , the probability that all of the remaining @xmath82 vectors are chosen from the same half plane is at most @xmath77 .",
    "the next lemma , however , stands at the basis of our sparsity result .",
    "it states that even when the coding vectors are sparse ( with approximately @xmath84 non - zeros for each vector ) , the same rank result holds . with this lemma",
    ", it will be easy to show that a more efficient decoding is possible ( since sparse matrices are less complex to invert @xcite ) without harming the strength of the code .",
    "[ lemma : prob_log ] the probability that a system @xmath75 of @xmath8 vectors of dimension @xmath85 over @xmath60 , where each coordinate is @xmath86 with probability @xmath44 , independently of the others , with @xmath87 , where @xmath88 slowly , is not of full rank @xmath1 is at most @xmath77 .",
    "we term the distribution in lemma [ lemma : prob_log ] the _ log distribution_.    by ( * ? ? ?",
    "* theorem 1 ) , the required probability , @xmath89 , as @xmath90 , is : @xmath91 =   1-\\prod_{j = m - k+1}^\\infty \\left(1 - 2^{-j}\\right)\\ ] ]    let @xmath92 , and set @xmath93 .",
    "we will first show that @xmath94 .",
    "the proof is by induction over @xmath7 ; it can easily be verified that for all @xmath17 , @xmath95 .",
    "assume the relation holds for all @xmath17 and for a given @xmath7 .",
    "we will show the relation holds for all @xmath17 and @xmath96 : @xmath97    now , for a given @xmath17 , as the series @xmath98 is monotonically decreasing , and according to the above is bounded by @xmath99 , there exists a constant @xmath100 , such that @xmath101 .",
    "we will now show that @xmath102 .",
    "assume , towards contradiction , that @xmath103 .",
    "from the definition of the limit , for each @xmath104 there exists an @xmath7 such that @xmath105 . take @xmath106 , and we get that there exists an @xmath7 such that : @xmath107 .",
    "removing the absolute value , as the series converges from above , results in @xmath108 , that is , @xmath109 , which is a contradiction . as a result",
    ", we get that @xmath110    the third lemma considers the possibility that _ any subset of sufficient size _ , out of the @xmath111 collected packets , includes @xmath1 independent equations",
    ". it will be applicable when one considers decoding under selective attacks , as in these cases it is no longer true that the uncorrupted packets arriving at the decoder have the originally intended distribution , and the previous two lemmas do not apply directly .",
    "let @xmath112 denote the binary entropy function .",
    "we have the following .    [ lemma : prob_selective ] let @xmath113 be a set of packets , all generated using the uniform distribution , or the log distribution of lemma  [ lemma : prob_log ] .",
    "assume @xmath114 , @xmath115 .",
    "then , with probability at least @xmath116 , where @xmath117 , @xmath118 , every subset of @xmath119 packets out of @xmath120 contains an independent subset of size @xmath1 .    for example , for @xmath121 and @xmath122 , this probability is approximately @xmath123 .",
    "since @xmath124 will later denote the number of corrupted packets , and @xmath37 will be a constant chosen by the decoder , depending on @xmath36 , we write @xmath125 to denote the value of @xmath37 chosen by the decoder to ensure that @xmath126 .    using the bounds given in lemmas  [ lemma : prob_uni ] and  [ lemma : prob_log ]",
    ", we have : @xmath127   & \\leq & \\binom{|s|}{|s|-bk}2^{k-(|s|-bk ) } \\\\ & = & \\binom{ak}{bk}2^{k - ak+bk }    \\leq 2^{ak\\cdot h(b / a)}2^{k - ak+bk } \\\\ & = & 2^{-k(a - b-1-a h(b / a))}.\\end{aligned}\\ ] ]      we present several possible ways to decode a value , where the trade off between the number of packets which need to be collected and the decoding time is investigated .",
    "we will limit the discussion to decoding a given message block , @xmath128 , where all message blocks may be decoded in parallel , using the same technique . throughout the discussion ,",
    "it is beneficial to consider both the total number of collected packets at the decoder ( both original and corrupted ) and the number of corrupted packets collected .",
    "hence , we let @xmath129 be the set of all collected packets , and @xmath20 denote the number of corrupted packets collected .",
    "note that @xmath130 .",
    "the first decoding algorithm is a majority test , included here to illustrate a simple , yet deterministic and polynomial , decoding procedure . while the complexity is polynomial in @xmath1 , it is not rate - optimal in terms of the number of packets that needs to be collected for successful decoding .",
    "the randomized algorithm suggested later is superior both in expected rate and expected complexity .",
    "* majority voting*. the decoding algorithm is depicted in figure  [ figure : majority ] , and is applicable to both the uniform and selective adversarial models . to reconstruct a given message block , @xmath128 , given that at most @xmath20 faults occurred , we need to collect @xmath131 pairwise disjoint sets of packets , @xmath132 , such that each set contains exactly @xmath1 independent packets . in lemma",
    "[ lemma : prob_uni ] it was shown that indeed an addition of a constant number of packets to a set of @xmath1 packets , ensures ( with high probability ) @xmath1 independent equations .",
    "this applies to a random adversary , as the packets it corrupts are randomly selected , _ hence the distribution of the uncorrupted packets seen by the decoder is still random_. however , this is not true for a selective adversary .",
    "such an adversary has the ability to chose which packets to corrupt , and , consequently , change the distribution of the uncorrupted packets seen by the decoder , such that lemmas [ lemma : prob_uni ] and [ lemma : prob_log ] will not hold as is . in this case ,",
    "lemma [ lemma : a_selective ] comes in handy , as it assures that if enough packets are collected , with high probability _ any subset of @xmath119 _ packets will give the desired result .",
    "clearly , more packets need to be collected ( @xmath133 packets , where @xmath134 is the number of corrupted packets ) , but the trade - off allows handling a selective adversary .    from each set ,",
    "@xmath135 , we can reconstruct an @xmath136 as a candidate message block .",
    "it then follows that the majority of the values is the correct message block . in other words , @xmath137 .",
    "note that to ensure that @xmath111 , the number of packets collected , will suffice to compose @xmath138 sets of @xmath1 packets , we need @xmath139 .",
    "thus , majority voting decoding may be used only when the adversary is at most @xmath140-bounded .",
    "the running time of such an algorithm is dominated by the need to solve the @xmath141 equation sets , which takes , in general , @xmath142 . however , using the _ sparse coding vectors _ of lemma [ lemma : prob_log ] , the complexity is @xmath143 , as sparse equations can be solved more efficiently @xcite .    at the other extreme of the trade - off between complexity and rate , we present an asymptotically rate optimal algorithm using exhaustive search .    *",
    "exhaustive search algorithm*. similar to the majority test algorithm , we assume the number of packets corrupted , @xmath20 , is known to the decoder , and his goals are to both _ decide how many packets to collect and , of course , decode the original block_.    [ lemma : a_random ] let @xmath144 be a set of packets , such that @xmath145 , drawn using either the uniform distribution or the log distribution . define the following matrix , @xmath146 and let @xmath147 . assuming that no more than @xmath148 packets are corrupted by a uniform adversary , and that with very high probability @xmath78 packets contain a subset of @xmath1 independent packets .",
    "then @xmath128 is the only solution to the following equation system which satisfies at least @xmath149 equations : @xmath150 .",
    "knowing @xmath20 , @xmath1 an @xmath104 , the decoder collects @xmath151 packets .",
    "since there are at most @xmath20 packets corrupted , there is at least one subset of @xmath149 un - corrupted packets .",
    "denote it by @xmath120 .",
    "there is at least one solution ( the true one , denoted @xmath152 ) satisfying all the equations in @xmath120 . however , since @xmath120 includes at least @xmath78 uncorrupted packets , which , in turn , with very high probability , contain @xmath1 independent equations , @xmath152 is actually the only solution satisfying all equations in @xmath120 .",
    "it remains to show that the decoder can not find a different set of @xmath149 packets , all satisfying a different solution .",
    "consider a set of @xmath149 packets , for which there is a solution @xmath153 satisfying all @xmath149 equations .",
    "if this set includes some subset of @xmath78 un - corrpted packets , then , since this subset includes @xmath1 independent un - corrupted equations , @xmath154 . if there is no such subset , then there are more than @xmath20 corrupted equations , which is a contradiction .",
    "note that @xmath148 and hence @xmath155 .",
    "furthermore , note that the proof relies on the uniformity of the adversary since it assumes any set of uncorrupted packets of size @xmath78 satisfies lemma [ lemma : prob_uni ] or [ lemma : prob_log ] , hence include , with hight probability , @xmath1 independent equations . when the adversary is selective , this is not necessarily the case , as the adversary can choose which packets to corrupt , and thus inflect a different distribution of uncorrupted packets at the decoder . in that case",
    ", the following lemma will hold .",
    "[ lemma : a_selective ] assume an encoder generates packets according to the uniform or the log distribution , and that no more than @xmath156 , packets are corrupted by a selective offline adversary .",
    "let @xmath144 be the set of packets collected at the decoder , with @xmath157 .",
    "define @xmath146 and let @xmath147 .",
    "then , with probability at least @xmath116 , @xmath128 is the only solution to the following equation system which satisfies at least @xmath158 equations : @xmath150 .",
    "the proof is similar to that of lemma [ lemma : a_random ] .",
    "the decoder collects @xmath159 packets .",
    "since there are at most @xmath124 corrupted ones , the remaining @xmath158 include an uncorrupted subset of size @xmath119 and by lemma [ lemma : prob_selective ] include @xmath1 independent packets .",
    "this constitutes a valid solution .",
    "any other solution which satisfies at least @xmath158 equations must coincide with that solution since at least @xmath119 of the @xmath158 equations are from uncorrupted packets and hence include @xmath1 independent equations .",
    "it follows from lemma  [ lemma : a_random ] that the solution , @xmath152 , to the system of equations @xmath150 , which correctly solves the largest number of equations is the ( only ) correct solution .",
    "hence , an algorithm which solves the following optimization problem would have been invaluable : given a system of equations over @xmath60 , find the best possible @xmath152 , which solves the maximal number of equations .",
    "obviously , this is an np - complete problem ( by a simple reduction from the max - cut problem , see  @xcite ) .",
    "given lemma  [ lemma : a_random ] and the above argument , a simple exhaustive search over all possible @xmath128 values yields the correct answer , which satisfies at least @xmath149 equations out of @xmath129 ( or @xmath119 out of the @xmath159 in the selective model , according to lemma [ lemma : a_selective ] ) .",
    "exhaustive search decoding is applicable to all @xmath26-bounded adversaries .",
    "nevertheless , as such a search is exponential in @xmath1  in fact , the running time of such an algorithm is in @xmath160  it may not be applicable in all situations .",
    "next , we present better decoding algorithms , which trades decoding time for increased amounts of packets , assuming that the adversary is bounded by values smaller than @xmath161 . *",
    "randomized decoding algorithm*. we use randomization in order to reduce the decoding complexity , given that the adversary is @xmath26-bounded ( for an appropriate @xmath26 , to be defined later ) , and may only corrupt at most @xmath20 packets .",
    "the algorithm is depicted in figure  [ algo : rand : decode ] , and suits the uniform adversarial model , as we follow lemma  [ lemma : a_random ] from the previous section .",
    "an extension to the selective adversary is trivial , with , of course , the right choice of parameters , as given in lemma [ lemma : a_selective ] .",
    "assume that we have collected @xmath129 packets , such that @xmath162 for some @xmath163 to be defined later .",
    "each subset of @xmath78 uncorrupted packets has a very high probability of containing a subset of @xmath1 independent packets .",
    "let this probability be @xmath164 , which can be calculated according to lemma  [ lemma : prob_uni ] . the algorithm will work as follows :",
    "choose a random subset , @xmath165 , such that @xmath166 .",
    "let @xmath167 be the unique solution ( if such exists ) to the equation @xmath168 , defined by @xmath120 .",
    "if the obtained solution , @xmath167 , satisfies more than @xmath149 equations out of @xmath129 , then , according to lemma  [ lemma : a_random ] , @xmath169 and we are done .",
    "now , let @xmath170 be the probability of choosing a subset of @xmath129 with no corrupted packets ( hence , the probability of finding the right solution ) .",
    "it then follows that the expected number of iterations of the algorithm is @xmath171 . as each iteration involves solving an equation system of size @xmath78 and validating the solution against at most @xmath111 packets , the running time of each iteration is @xmath172 , remembering there are approximately @xmath84 non - zeros coefficients in each equation .",
    "this yields an overall expected running time of @xmath173 .    by lemma [ lemma : prob_uni ] , @xmath174 .",
    "let us now approximate @xmath170 .",
    "@xmath175 we can thus choose @xmath176 according to our needs  either minimizing decoding time or minimizing the number of packets we need to collect .",
    "for example , choosing @xmath177 , for a constant @xmath36 , results in @xmath178 .",
    "such a choice minimizes the run time to @xmath179 , at the expense of having to collect many messages ( @xmath180 ) .",
    "furthermore , such a decoding algorithm is only relevant when the adversary is at most @xmath181-bounded .    * reducing packets size*. in section  [ sec : enc ] , we assume that each packet generated is of size @xmath67 bits , where @xmath8 is the size of each message block and @xmath1 is the number of blocks .",
    "the @xmath1 bits of redundancy are used to denote which blocks participated in the creation of the packet . in practice , these @xmath1 bits may be compressed , using several techniques , into a logarithmic size .",
    "first , when choosing which blocks to xor in a uniform fashion , the sender can use a prng to generate the required distribution , as proposed in  @xcite .",
    "the sender will use a different random seed for the prng for every packet generated , and only attach the seed to the packet .",
    "a seed of size logarithmic in @xmath1 suffices , and the receiver can proceed to recover which blocks participated in creating a specific packet using the seed embedded in the packet .    a different approach , in which the use of a prng ( pseudo random number generator ) is not required , can be achieved by using the log distribution to select blocks for each packet ; first generate a binary vector , @xmath182 , of length @xmath1 , in which each index is @xmath86 with probability @xmath183 , for some small constant @xmath184 .",
    "when sending each packet , do not attach @xmath182 to the packet .",
    "rather , attach the indices of @xmath182 which contain @xmath86 .",
    "error correcting codes , erasure correcting codes , communication networks and distributed computing are tightly coupled .",
    "the replication techniques used for obtaining fault - tolerance in distributed computing may be replaced by error and erasure correcting techniques . beyond the memory overhead benefit ,",
    "the dispersal of information can be useful to protect and hide clear - text values when necessary . in this work ,",
    "we have presented efficient encoding and decoding schemes that enhance the correctability of well known rateless erasure correcting codes . + * acknowledgments*. it is a pleasure to thank michael mitzenmacher for helpful inputs and for pointing out relevant related works , and shachar golan for helpful comments .",
    "edoardo amaldi , viggo kann , `` the complexity and approximability of finding maximum feasible subsystems of linear relations '' , _ theoretical computer science _ ,",
    "volume 147 , issues 1 - 2 , august 1995 , pp . 181210 .",
    "shlomi dolev , boris fitingof , avraham melkman , and olga tubman , `` smooth and adaptive forward erasure correcting '' .",
    "_ computer networks journal _ , special edition on overlay networks , volume 36 , issue 2 - 3 , ( july 2001 ) pp .",
    "343355 .",
    "maxwell n. krohn , michael j. freedman and david mazires , `` on - the - fly verification of rateless erasure codes for efficient content distribution '' , pp .",
    "226240 _ proceedings of the ieee symposium on security and privacy , 2004_.              sidharth jaggi , michael langberg , sachin katti , tracy ho , dina katabi , muriel mdard , `` resilient network coding in the presence of byzantine adversaries '' , infocom 2007 : _ 26th ieee international conference on computer communications _ , pp . 616624 , may 2007 .",
    "fang zhao , ton kalker , muriel mdard , keesook j. han , `` signatures for content distribution with network coding '' , isit 2007 : _ ieee international symposium on information theory _ , pp .",
    "556560 , june 2007 ."
  ],
  "abstract_text": [
    "<S> in this paper , we present a new family of fountain codes which overcome adversarial errors . </S>",
    "<S> that is , we consider the possibility that some portion of the arriving packets of a rateless erasure code are corrupted in an undetectable fashion . in practice </S>",
    "<S> , the corrupted packets may be attributed to a portion of the communication paths which are controlled by an adversary or to a portion of the sources that are malicious .    </S>",
    "<S> the presented codes resemble and extend lt and raptor codes . yet , </S>",
    "<S> their benefits over existing coding schemes are manifold . </S>",
    "<S> first , to overcome the corrupted packets , our codes use information theoretic techniques , rather than cryptographic primitives . </S>",
    "<S> thus , no secret channel between the senders and the receivers is required . </S>",
    "<S> second , the encoders in the suggested scheme are oblivious to the strength of the adversary , yet perform as if its strength was known in advance . </S>",
    "<S> third , the sparse structure of the codes facilitates efficient decoding . </S>",
    "<S> finally , the codes easily fit a decentralized scenario with several sources , when no communication between the sources is allowed .    </S>",
    "<S> we present both exhaustive as well as efficient decoding rules . beyond the obvious use as a rateless codes , </S>",
    "<S> our codes have important applications in distributed computing . </S>"
  ]
}