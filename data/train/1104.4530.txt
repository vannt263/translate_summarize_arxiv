{
  "article_text": [
    "large , sparse , symmetric , and indefinite systems arise in a variety of applications .",
    "for example , in the form of saddle point problems , such systems result from mixed finite element discretizations of underlying differential equations of fluid and solid mechanics ; see , e.g. ,  @xcite and references therein . in acoustics ,",
    "large sparse symmetric indefinite systems are obtained after discretizing the helmholtz equation for certain media types and boundary conditions .",
    "often the need to solve symmetric indefinite problems comes as an auxiliary task within other computational routines , such as the inner step in interior point methods in linear and nonlinear optimization  @xcite , or solution of the correction equation in the jacobi - davidson method  @xcite for a symmetric eigenvalue problem .",
    "we consider an iterative solution of a linear system @xmath0 , where the matrix @xmath1 is real nonsingular and symmetric indefinite , i.e. , the spectrum of @xmath1 contains both positive and negative eigenvalues . in order to improve the convergence ,",
    "we introduce a _ preconditioner _ @xmath2 and formally replace @xmath0 by the _ preconditioned system _ @xmath3 .",
    "if @xmath2 is properly chosen , an iterative method for this system can exhibit a better convergence behavior compared to a scheme applied to @xmath0 .",
    "neither the preconditioner @xmath2 nor the _ preconditioned matrix _",
    "@xmath4 is normally explicitly computed .",
    "if @xmath2 is _ not _ symmetric positive definite  ( spd ) , then @xmath4 , in general , is not symmetric with respect to any inner product  ( * ? ? ?",
    "* theorem  15.2.1 ) .",
    "thus , the introduction of a non - spd preconditioner replaces the original _ symmetric _ problem @xmath5 by a generally _ nonsymmetric _ @xmath6 .",
    "specialized methods for _ symmetric _ linear systems are no longer applicable to the preconditioned problem , and must be replaced by iterative schemes for _ nonsymmetric _ linear systems ; e.g. , gmres or gmres(@xmath7 )  @xcite , bi - cgstab  @xcite , and qmr  @xcite .",
    "the approach based on the choice of a non - spd preconditioner , which leads to solving a nonsymmetric problem , has several disadvantages .",
    "first , no short - term recurrent scheme that delivers an _ optimal _ krylov subspace method is typically available for a nonsymmetric linear system  @xcite . in practice",
    ", this means that implementations of the optimal methods ( e.g. , gmres ) require an increasing amount of work and storage at every new step , and hence are often computationally expensive .",
    "second , the convergence behavior of iterative methods for nonsymmetric linear systems is not completely understood . in particular ,",
    "the convergence may not be characterized in terms of reasonably accessible quantities , such as the spectrum of the preconditioned matrix ; see the corresponding results for gmres and gmres(@xmath7 ) in  @xcite .",
    "this makes it difficult to predict computational costs .",
    "if @xmath2 is chosen to be spd , i.e. , @xmath8 , then the matrix @xmath4 of the preconditioned linear system is symmetric with respect to the @xmath9inner product defined by @xmath10 for any pair of vectors @xmath11 and @xmath12 . here",
    "@xmath13 denotes the euclidean inner product @xmath14 , in which the matrices @xmath1 and @xmath2 are symmetric .",
    "due to this symmetry preservation , system @xmath15 can be solved using an _ optimal _ krylov subspace method that admits a _ short - term recurrent _ implementation , such as preconditioned minres ( pminres )  @xcite . moreover , the convergence of the method can be fully estimated in terms of the spectrum of @xmath4 . in light of the above discussion , the choice of an spd preconditioner for a symmetric indefinite linear system can be regarded as natural and favorable , especially if corresponding non - spd preconditioning strategies fail to provide convergence in a small number of iterations .",
    "we advocate the use of spd preconditioning .",
    "the question of constructing spd preconditioners for symmetric indefinite systems has been widely studied in many applications . for saddle point problems ,",
    "the block - diagonal spd preconditioning has been addressed , e.g. , in  @xcite . in  @xcite , it was proposed to use an inverse of the negative laplacian as an spd preconditioner for indefinite helmholtz problems .",
    "this approach was further extended in  @xcite by introducing a shift into the preconditioner .",
    "another strategy was suggested in  @xcite , primarily in the context of linear systems arising in optimization .",
    "it is based on the so - called _ bunch - parlett factorization _",
    "@xcite .",
    "we introduce here a different idea of constructing spd preconditioners that resemble the inverse of the absolute value of the coefficient matrix . throughout",
    ", the absolute value of @xmath1 is defined as a matrix function @xmath16 , where @xmath17 is the eigenvalue decomposition of @xmath1 .",
    "we are motivated by the observation that pminres with @xmath18 as a preconditioner converges to the exact solution in at most two steps .",
    "we refer to the new approach as the _ absolute value _ ( av ) preconditioning and call the corresponding preconditioners the av preconditioners .",
    "the direct approach for constructing an av preconditioner is to approximately solve @xmath19 .",
    "however , @xmath20 is generally not available , which makes the application of standard techniques , such as , e.g. , incomplete factorizations , approximate inverses , problematic .",
    "the vector @xmath21 can also be found using matrix function computations , normally fulfilled by a krylov subspace method  @xcite or a polynomial approximation  @xcite .",
    "our numerical experience shows that the convergence , with respect to the outer iterations , of a linear solver can be significantly improved with this approach , but the computational costs of approximating @xmath22 may be too high , i.e. , much higher than the cost of matrix - vector multiplication with @xmath1 .",
    "introduction of the _ general concept _ of the av preconditioning is the main theoretical contribution of the present work . as a proof of concept example of the av preconditioning",
    ", we use a geometric multigrid ( mg ) framework . to investigate applicability and practical effectiveness of the proposed idea , we choose a model problem resulting from discretization of a shifted laplacian ( helmholtz operator ) on a unit square with dirichlet boundary conditions .",
    "the obtained linear system is real symmetric indefinite .",
    "we construct an mg av preconditioner that , used in the pminres iteration , delivers an efficient computational scheme .",
    "let us remark that the same model problem has been considered in  @xcite , where the authors utilize the coarse grid approximation to reduce the indefinite problem to the spd system .",
    "satisfactory results have been reported for small shifts , i.e. , for slightly indefinite systems .",
    "however , the limitation of the approach lies in the requirement on the size of the coarse space , which should be chosen sufficiently large .",
    "as we show below , the mg av preconditioner presented in this paper allows keeping the coarsest problem reasonably small , even if the shift is large . numerical solution of helmholtz problems is an object of active research ; see , e.g. ,  @xcite . a typical helmholtz problem is approximated by a complex symmetric ( non - hermitian ) system .",
    "the real symmetric case of the helmholtz equation , considered in this paper , is less common .",
    "however , methods for complex problems are evidently applicable to our particular real case , which allows us to make numerical comparisons with known helmholtz solvers .",
    "we test several of solvers , based on the inverted laplacian and the standard mg preconditioning , to compare with the proposed av preconditioning .",
    "in fact , the inverted ( shifted ) laplacian preconditioning  @xcite for real helmholtz problems can be viewed as a special case of our av preconditioning .",
    "in contrast to preconditioners in  @xcite relying on the bunch - parlett factorization , we show that the av preconditioners can be constructed without any decompositions of the matrix , which is crucial for very large or matrix - free problems .",
    "this paper is organized as follows . in section  [ sec : absval_prec ] , we present and justify the general notion of an av preconditioner . the rest of the paper deals with the question of whether av preconditioners can be efficiently constructed in practice . in section  [ subsec :",
    "prec_constr ] , we give a positive answer by constructing an example of a geometric mg av preconditioner for the model problem . the efficiency of this preconditioner is demonstrated in our numerical tests in section  [ sec : numeric ] . we conclude in section  [ sec : conl ] .",
    "given an spd preconditioner @xmath2 , we consider solving a linear system with the _ preconditioned minimal residual method _ , implemented in the form of the preconditioned minres ( pminres ) algorithm  @xcite . in the absence of round - off errors , at step @xmath23 , the method constructs an approximation @xmath24 to the solution of @xmath0 of the form @xmath25 such that the residual vector @xmath26 satisfies the optimality condition @xmath27 here , @xmath28 is the krylov subspace generated by the matrix @xmath4 and the vector @xmath29 , the @xmath2-norm is defined by @xmath30 for any @xmath12 , and @xmath31 is the initial guess .",
    "scheme  ( [ eqn : xkrylov])([eqn : rkrylov ] ) represents an _ optimal _ krylov subspace method and the pminres implementation is based on a _ short - term recurrence_. the conventional convergence rate bound for  ( [ eqn : xkrylov])([eqn : rkrylov ] ) can be found , e.g. , in  @xcite , and relies solely on the distribution of eigenvalues of @xmath4 .    the following trivial , but important , theorem regards @xmath32 as an spd preconditioner for a symmetric indefinite system .",
    "[ thm : opt_prec ] the preconditioned minimal residual method  ( [ eqn : xkrylov])([eqn : rkrylov ] ) with preconditioner @xmath33 converges to the solution of @xmath0 in at most two steps .    theorem  [ thm : opt_prec ] implies that @xmath33 is an _ ideal spd preconditioner_. note that the theorem holds not only for the preconditioned minimal residual method  ( [ eqn : xkrylov])([eqn : rkrylov ] ) , but for all methods where convergence is determined by the degree of the minimal polynomial of @xmath4 .    in practical situations ,",
    "the computation of an _ ideal _ spd preconditioner @xmath34 is prohibitively costly .",
    "however , we show that it is possible to construct inexpensive spd preconditioners that resemble @xmath32 and can significantly accelerate the convergence of an iterative method .",
    "[ def : avp ] we call an spd preconditioner @xmath2 for a symmetric indefinite linear system @xmath0 an _ av preconditioner _ if it satisfies @xmath35 with constants @xmath36 , such that the ratio @xmath37 is reasonably small .",
    "let us remark that definition  [ def : avp ] of the av preconditioner is informal because no precise assumption is made of how small the ratio @xmath38 should be .",
    "it is clear from  ( [ eqn : avp_spectral ] ) that @xmath38 measures how well the preconditioner @xmath2 approximates @xmath32 , up to a positive scaling . if @xmath1 represents a hierarchy of mesh problems then it is desirable that @xmath38 is independent of the problem size . in this case , if @xmath1 is spd , definition  [ def : avp ] of the av preconditioner is consistent with the well known concept of spectrally equivalent preconditioning for spd systems ; see  @xcite .",
    "the following theorem provides bounds for eigenvalues of the preconditioned matrix @xmath4 in terms of the spectrum of @xmath39 .",
    "we note that @xmath2 and @xmath1 , and thus @xmath4 and @xmath39 , do not in general commute .",
    "therefore , our spectral analysis can not be based on a traditional matrix analysis tool , a basis of eigenvectors .",
    "[ thm : avp_spect_bounds ] given a nonsingular symmetric indefinite @xmath40 and an spd @xmath41 , let @xmath42 be the eigenvalues of @xmath43 .",
    "then eigenvalues @xmath44 of @xmath4 are located in intervals @xmath45    we start by observing that the absolute value of the rayleigh quotient of the generalized eigenvalue problem @xmath46 is bounded by @xmath47 , i.e. , @xmath48    now , we recall that the spectra of matrices @xmath43 and @xmath49 are given by the generalized eigenvalue problems @xmath50 and @xmath51 , respectively , and introduce the corresponding rayleigh quotients @xmath52    let us fix any index @xmath53 , and denote by @xmath54 an arbitrary subspace of @xmath55 such that @xmath56 . since inequality  ( [ eqn : f_of_val ] ) also holds on @xmath54 , using  ( [ eqn : rq ] ) we write @xmath57 moreover , taking the maxima in vectors @xmath58 , and after that the minima in subspaces @xmath59 , of all parts of  ( [ eqn : rq_rel ] ) preserves the inequalities , so @xmath60 by the courant - fischer theorem ( see , e.g. ,  @xcite ) for the rayleigh quotients @xmath61 and @xmath62 defined in  ( [ eqn : rq ] ) , we conclude from  ( [ eqn : maxmin_rq_rel ] ) that @xmath63 recalling that @xmath64 has been arbitrarily chosen , we obtain the following bounds on the eigenvalues of @xmath4 : @xmath65    next , in order to derive nontrivial upper and lower bounds for the @xmath66 negative and @xmath67 positive eigenvalues",
    "@xmath68 in  ( [ eqn : spectr_bounds1 ] ) , we use the fact that eigenvalues @xmath69 and @xmath70 of the generalized eigenvalue problems @xmath71 and @xmath72 are the reciprocals of the eigenvalues of the problems @xmath50 and @xmath51 , respectively , i.e. , @xmath73 and @xmath74    similar to  ( [ eqn : f_of_val ] ) , @xmath75 thus , we can use the same arguments as those following  ( [ eqn : f_of_val ] ) to show that relations  ( [ eqn : rq_rel ] ) and  ( [ eqn : maxmin_rq_rel ] ) , with a fixed @xmath53 , also hold for @xmath76 where @xmath77 and @xmath62 are now the rayleigh quotients of the generalized eigenvalue problems @xmath71 and @xmath78 , respectively .",
    "the courant - fischer theorem for @xmath61 and @xmath62 in  ( [ eqn : rq_inv ] ) allows us to conclude from  ( [ eqn : maxmin_rq_rel ] ) that @xmath79 given the arbitrary choice of @xmath64 in the above inequality , by ( [ eqn : xi])([eqn : zeta ] ) we get the following bounds on the eigenvalues of @xmath4 : @xmath80 combining  ( [ eqn : spectr_bounds1 ] ) and  ( [ eqn : spectr_bounds2 ] ) , we obtain  ( [ eqn : spectr_bounds ] ) .",
    "theorem  [ thm : avp_spect_bounds ] suggests two useful implications given by the corresponding corollaries below .",
    "in particular , the following result describes @xmath81 , i.e. , the spectrum of the preconditioned matrix @xmath4 , in terms of @xmath82 and @xmath83 in  ( [ eqn : avp_spectral ] ) .",
    "[ cor : avp_spect ] given a nonsingular symmetric indefinite @xmath40 , an spd @xmath41 , and constants @xmath36 satisfying  ( [ eqn : avp_spectral ] ) , we have @xmath84 \\bigcup \\left [ \\delta_0 , \\delta_1 \\right],\\ ] ] where @xmath81 is the spectrum of @xmath4 .",
    "follows directly from  ( [ eqn : avp_spectral ] ) and  ( [ eqn : spectr_bounds ] ) with @xmath85 .",
    "the next corollary shows that the presence of reasonably populated clusters of eigenvalues in the spectrum of @xmath43 guarantees the occurrence of corresponding clusters in the spectrum of the preconditioned matrix @xmath4 .",
    "[ cor : avp_cluster ] given a nonsingular symmetric indefinite @xmath40 and an spd @xmath41 , let @xmath86 be a sequence of @xmath87 eigenvalues of @xmath88 , where @xmath89 and @xmath90 .",
    "then , if @xmath91 , the @xmath92 positive eigenvalues @xmath93 of @xmath4 are such that @xmath94 .",
    "also , if @xmath95 , the @xmath96 negative eigenvalues @xmath97 of @xmath4 are such that @xmath98 .    follows directly from bounds  ( [ eqn : spectr_bounds ] ) .",
    "corollary  [ cor : avp_spect ] implies that the ratio @xmath37 of the constants from  ( [ eqn : avp_spectral ] ) measures the quality of the av preconditioner @xmath2 . indeed ,",
    "the convergence speed of the preconditioned minimal residual method is determined by the spectrum of @xmath4 , primarily by the intervals of the right - hand side of inclusion .",
    "additionally , corollary  [ cor : avp_cluster ] prompts that a `` good '' av preconditioner should ensure clusters of eigenvalues in the spectrum of @xmath88 .",
    "this implies the clustering of eigenvalues of the preconditioned matrix @xmath4 , which has a favorable effect on the convergence behavior of a polynomial iterative method , such as pminres . in the next section ,",
    "we construct an example of the av preconditioner for a particular model problem .",
    "we apply the mg techniques .",
    "let us consider the following real boundary value problem , @xmath99 where @xmath100 is the laplace operator and @xmath101 denotes the boundary of @xmath102 .",
    "problem ( [ eqn : helmholtz_bvp ] ) is a particular instance of the helmholtz equation with dirichlet boundary conditions , where @xmath103 is a wave number . after introducing a uniform grid of size @xmath104 in both directions and using the standard @xmath105-point finite - difference stencil to discretize continuous problem ( [ eqn : helmholtz_bvp ] ) ,",
    "one obtains the corresponding discrete problem @xmath106 where @xmath107 represents a discrete negative laplacian @xmath108 ( later called `` laplacian '' ) , satisfying the dirichlet boundary condition shifted by a scalar @xmath109 .",
    "the common rule of thumb , see , e.g. ,  @xcite , for discretizing  ( [ eqn : helmholtz_bvp ] ) is @xmath110 below , we call  ( [ eqn : helmholtz_fd ] ) the _ model problem_. we assume that the shift @xmath109 is different from any eigenvalue of the laplacian and is greater than the smallest but less than the largest eigenvalue . thus ,",
    "the matrix @xmath111 is nonsingular symmetric indefinite . in the following subsection",
    ", we apply the idea of the av preconditioning to construct an mg av preconditioner for system ( [ eqn : helmholtz_fd ] ) .",
    "while our main focus throughout the paper is on the 2d problem  ( [ eqn : helmholtz_bvp ] ) , in order to simplify presentation of theoretical analysis , we also refer to the 1d analogue @xmath112 the conclusions drawn from  ( [ eqn : helmholtz_bvp1d ] ) , however , remain qualitatively the same for the 2d problem of interest , which we test numerically .",
    "along with the fine grid of mesh size @xmath104 underlying problem  ( [ eqn : helmholtz_fd ] ) , let us consider a coarse grid of mesh size @xmath113 .",
    "we denote the discretization of the laplacian on this grid by @xmath114 , and @xmath115 represents the identity operator of the corresponding dimension .",
    "we assume that the exact fine - level absolute value @xmath116 and its inverse are not computable , whereas the inverse of the coarse - level operator @xmath117 can be efficiently constructed .",
    "in the two - grid framework , we use the subscript @xmath118 to refer to the quantities defined on the coarse grid .",
    "no subscript is used for denoting the fine grid quantities .    while @xmath116 is not available ,",
    "let us assume that we have its spd approximation @xmath119 , i.e. , @xmath120 and @xmath121 .",
    "the operator @xmath119 can be given in the explicit matrix form or through the action on a vector .",
    "we suggest the following general scheme as a two - grid av preconditioner for model problem  ( [ eqn : helmholtz_fd ] ) .",
    "[ alg : g2 g ] input : @xmath122 , @xmath120 .",
    "output : @xmath123 .    1 .   _",
    "presmoothing_. apply @xmath124 smoothing steps , @xmath125 : @xmath126 where @xmath127 defines a smoother .",
    "set @xmath128 .",
    "_ coarse grid correction_. restrict ( @xmath129 ) @xmath130 to the coarse grid , apply @xmath131 , and prolongate ( @xmath132 ) to the fine grid .",
    "this delivers the coarse grid correction , which is added to @xmath133 : @xmath134 3 .   _",
    "postsmoothing_. apply @xmath124 smoothing steps : @xmath135 where @xmath127 and @xmath124 are the same as in step  1 .",
    "return @xmath136 .",
    "in ( [ eqn : cgc-1 ] ) we assume that @xmath137 is nonsingular , i.e. , @xmath109 is different from any eigenvalue of @xmath114 .",
    "the presmoother is defined by the nonsingular @xmath127 , while the postsmoother is delivered by @xmath138 .",
    "note that the ( inverted ) absolute value appears only on the coarse grid , while the fine grid computations are based on the approximation  @xmath119 .",
    "it is immediately seen that if @xmath139 , algorithm  [ alg : g2 g ] represents a formal two - grid cycle  @xcite for system @xmath140 note that the introduced scheme is rather general in that different choices of approximations @xmath119 and smoothers @xmath127 lead to different preconditioners .",
    "we address these choices in more detail in the following subsections .",
    "it can be verified that the av preconditioner given by algorithm  [ alg : g2 g ] implicitly constructs a mapping @xmath141 , where the operator is @xmath142 with @xmath143 .",
    "the fact that the constructed preconditioner @xmath144 is spd follows directly from the observation that the first term in  ( [ eqn:2grid_struct ] ) is spd provided that @xmath145 for some nonzero scalar @xmath146 , while the second term @xmath147 is spd if the spectral radii of @xmath148 and @xmath149 are less than @xmath47 .",
    "the latter condition requires the pre- and postsmoothing iterations  ( [ eqn : pre ] ) and  ( [ eqn : post ] ) to represent convergent methods for @xmath150 note that the above argument essentially repeats the one used to justify symmetry and positive definiteness of a preconditioner based on the standard two - grid cycle for an spd system ; see , e.g. ,  @xcite . in this paper",
    "we consider two different choices of the approximation @xmath119 .",
    "the first choice is given by @xmath151 , i.e. , it is suggested to approximate the absolute value @xmath152 by the laplacian @xmath108 .",
    "the second choice is delivered by @xmath153 , where @xmath154 is a polynomial of degree at most @xmath7 such that @xmath155 .",
    "if @xmath151 , algorithm  [ alg : g2 g ] can be regarded as a step of a standard two - grid method  @xcite applied to the poisson equation @xmath157 modified by replacing the operator @xmath114 by @xmath158 on the coarse grid . the question remains if the algorithm delivers a form of an approximate solve for absolute value problem  ( [ eqn : av_sys ] ) , and hence is suitable for av preconditioning of  ( [ eqn : helmholtz_fd ] ) . to be able to answer this question",
    ", we analyze the propagation of the initial error @xmath159 of  ( [ eqn : av_sys ] ) under the action of the algorithm .",
    "we start by relating errors of  ( [ eqn : av_sys ] ) and  ( [ eqn : poisson ] ) .",
    "[ lem : error ] given a vector @xmath123 , consider errors @xmath160 and @xmath161 for  ( [ eqn : av_sys ] ) and  ( [ eqn : poisson ] ) , respectively .",
    "then @xmath162 where @xmath163 , @xmath164 is the matrix of eigenvectors of @xmath111 corresponding to the @xmath66 negative eigenvalues @xmath165 , and @xmath166 .",
    "observe that for any @xmath123 , @xmath167 denoting @xmath168 , we use the expression @xmath169 to get  ( [ eqn : error ] )    algorithm  [ alg : g2 g ] transforms the initial error @xmath170 of equation  ( [ eqn : poisson ] ) into @xmath171 where @xmath172 and @xmath173 are pre- and postsmoothing operators , @xmath174 corresponds to the coarse grid correction step , and @xmath175 . denoting the error of absolute value system  ( [ eqn : av_sys ] ) after applying algorithm  [ alg : g2 g ] by @xmath176 and observing that @xmath177 , by  ( [ eqn : error])([eqn : ep ] ) we obtain @xmath178 the last expression gives an explicit form of the desired error propagation operator , which we denote by @xmath179 : @xmath180    below , as a smoother",
    ", we use a simple richardson s iteration , i.e. , @xmath181 , where @xmath182 is an iteration parameter .",
    "the restriction @xmath129 is given by the full weighting and the prolongation @xmath132 by the standard piecewise linear interpolation ; see  @xcite .    at this point , in order to simplify further presentation , let us refer to the one - dimensional analogue  ( [ eqn : helmholtz_bvp1d ] ) of model problem  ( [ eqn : helmholtz_bvp ] ) . in this case",
    ", the matrix @xmath108 is tridiagonal : @xmath183 .",
    "we assume that @xmath184 , the number of interior grid nodes , is odd : @xmath185 .",
    "the coarse grid is then obtained by dropping the odd - numbered nodes .",
    "we denote the size of the coarse grid problem by @xmath186 ; @xmath187 .",
    "the tridiagonal matrix @xmath114 denotes the discretization of the 1d laplacian on the coarse level .",
    "recall that the eigenvalues of @xmath108 are @xmath188 with corresponding eigenvectors @xmath189_{l=1}^n$ ] .",
    "similarly , the eigenvalues of @xmath114 are @xmath190 , and the coarse grid eigenvectors are denoted by @xmath191_{l=1}^n$ ] .",
    "it is clear that operators @xmath111 and @xmath192 have the same sets of eigenvectors as @xmath108 and @xmath114 with eigenvalues @xmath193 and @xmath194 , respectively .",
    "let @xmath195 be the expansion of the initial error in the eigenbasis of  @xmath108 .",
    "since @xmath196 , we are interested in the action of the error propagation operator ( [ eqn : g ] ) on the eigenmodes @xmath197 .    the action of the operators @xmath129 and @xmath132 on @xmath197 and @xmath198 , respectively , is well known ; see , e.g. ,  @xcite .",
    "thus , it is easy to obtain the following expression for  @xmath199 :    @xmath200    since @xmath197 are the eigenvectors of @xmath181 , @xmath201 , @xmath202 and @xmath203 ,  ( [ eqn : g ] ) leads to explicit expressions for @xmath204 .",
    "[ thm : g ] let @xmath205 .",
    "then the error propagation operator @xmath179 in  ( [ eqn : g ] ) acts on the eigenvectors @xmath197 of 1d laplacian as follows : @xmath206 where @xmath207 and @xmath208 .",
    "theorem  [ thm : g ] implies that for relatively small shifts , algorithm  [ alg : g2 g ] with @xmath151 and a proper choice of @xmath182 and @xmath124 reduces the error of  ( [ eqn : av_sys ] ) in the directions of almost all eigenvectors @xmath197 . in a few directions ,",
    "however , the error may be amplified .",
    "these directions are given by the smooth eigenmodes associated with @xmath209 that are close to  @xmath109 on the right , as well as with @xmath209 that are distant from @xmath109 on the left .",
    "the number of the latter , if any , is small if @xmath210 is sufficiently small , and becomes larger as @xmath210 increases .",
    "indeed , let @xmath211 , so that @xmath212 for all @xmath64 and @xmath213 for @xmath214 .",
    "this choice of the parameter provides the least uniform bound for @xmath215 that correspond to the oscillatory eigenmodes  @xcite .",
    "it is then readily seen that  ( [ eqn : g12 ] ) and  ( [ eqn : g22 ] ) can be made arbitrarily small within a reasonably small number  @xmath124 of smoothing steps .",
    "similarly ,  ( [ eqn : g ] ) and  ( [ eqn : g21 ] ) can be made arbitrarily close to  @xmath216 . if @xmath217 , then @xmath218 in  ( [ eqn : g ] ) and  ( [ eqn : g21 ] ) is close to zero .",
    "thus , theorem  [ thm : g ] shows that for relatively small shifts , smoothing provides small values of  ( [ eqn : g12])([eqn : g22 ] ) and , hence , damps of the oscillatory part of the error .",
    "note that the damping occurs even though the smoothing is performed with respect to  ( [ eqn : poisson ] ) , not  ( [ eqn : av_sys ] ) .",
    "now let us consider  ( [ eqn : g11 ] ) .",
    "theorem  [ thm : g ] shows that if @xmath109 is close to an eigenvalue @xmath219 of the coarse - level laplacian , i.e. , if @xmath220 , then the corresponding reduction coefficient  ( [ eqn : g11 ] ) can be large .",
    "this means that algorithm  [ alg : g2 g ] with @xmath221 has a potential difficulty of amplifying the error in the directions of a few smooth eigenvectors .",
    "similar effect is known to appear for standard mg methods applied to helmholtz type problems ; see  @xcite .",
    "below , we analyze  ( [ eqn : g11 ] ) in more detail .",
    "let @xmath222 . then , using the relation @xmath223 , we can write  ( [ eqn : g11 ] ) as @xmath224 here , it is easy to see that as @xmath225 , @xmath226 , meaning that the smooth eigenmodes corresponding to @xmath209 away from @xmath109 on the right are well  damped .",
    "if @xmath227 , then  ( [ eqn : g11 ] ) takes the form @xmath228 since @xmath229 , for any @xmath230 , we can obtain the bound @xmath231 additionally , @xmath232 .",
    "thus , @xmath233 where @xmath234 if @xmath235 , and @xmath236 if @xmath237 .",
    "the inequality implies that @xmath238 for @xmath239 , i.e. , the algorithm reduces the error in the directions of several smooth eigenvectors associated with @xmath209 to the left of @xmath109 . at the same time",
    ", we note that as @xmath240 , @xmath241 , i.e. , the smooth eigenmodes corresponding to @xmath209 that are distant from @xmath109 on the left can be amplified . clearly , if @xmath210 is sufficiently small then the number of such error components is not large ( or none ) , and grows as @xmath210 increases .",
    "the above analysis shows that algorithm  [ alg : g2 g ] with @xmath151 indeed represents a solve for  ( [ eqn : av_sys ] ) , where the solution is approximated everywhere , possibly except for a subspace of a small dimension . in the context of preconditioning",
    ", this translates into the fact that the preconditioned matrix has spectrum clustered around @xmath47 and @xmath242 with a few outliers generated by the amplification of the smooth eigenmodes .",
    "if the shift is sufficiently small , the number of such outliers is not large , which only slightly delays the convergence of the outer pminres iterations and does not significantly affect the efficiency of the overall scheme .",
    "the analysis of the previous subsection suggests that the quality of algorithm  [ alg : g2 g ] with @xmath221 may deteriorate as @xmath210 increases .",
    "this result is not surprising , since for larger @xmath210 the relation @xmath244 becomes no longer meaningful .",
    "below we introduce a different approach for approximating the fine grid absolute value .",
    "in particular , we consider constructing _ polynomial approximations _",
    "@xmath243 , where @xmath245 is a polynomial of degree at most @xmath246 , such that @xmath155 .",
    "let us first refer to the ideal particular case , where @xmath247 .",
    "this can happen , e.g. , if @xmath245 is an interpolating polynomial of @xmath248 on the spectrum of @xmath111 , @xmath249 .",
    "in such a situation , algorithm  [ alg : g2 g ] with @xmath250 results in the following transformation of the initial error : @xmath251 where @xmath252 and @xmath253 are pre- and postsmoothing operators , and @xmath254 corresponds to the coarse grid correction step .",
    "the associated error propagation operator is further denoted by @xmath255 , @xmath256    for the purpose of clarity , we again consider the 1d counterpart  ( [ eqn : helmholtz_bvp1d ] ) of the model problem . as a smoother , we choose richardson s iteration with respect to absolute value system  ( [ eqn : av_sys ] ) , i.e. , @xmath257 .",
    "it is important to note here that the eigenvalues @xmath258 of the absolute value operator are , in general , no longer ascendingly ordered with respect to @xmath64 as is the case for @xmath209 s and @xmath259 s .",
    "moreover , in contrast to @xmath108 and @xmath111 , the top part of the spectrum of @xmath260 may be associated with both smooth and oscillatory eigenmodes . in particular",
    ", this means that richardson s iteration may fail to properly eliminate the oscillatory components of the error , which is an undesirable outcome of the smoothing procedure . to avoid this",
    ", we require that @xmath261 .",
    "it is easy to verify that the latter condition is fulfilled if @xmath262 note that  ( [ eqn : ch_coarse ] ) automatically holds if discretization rule  ( [ eqn : thumb ] ) is enforced . repeating the above argument for the 2d case also leads to  ( [ eqn : ch_coarse ] ) .",
    "let the restriction and prolongation operators @xmath129 and @xmath132 be the same as in the previous subsection .",
    "similar to  ( [ eqn : kv ] ) , we obtain an explicit expression for the action of the coarse grid correction operator @xmath263 on eigenvectors @xmath197 : @xmath264    the following theorem is the analogue of theorem  [ thm : g ] .",
    "[ thm : g - poly ] the error propagation operator @xmath255 in  ( [ eqn : gpoly ] ) acts on the eigenvectors @xmath197 of the 1d laplacian as follows : @xmath265 where @xmath266    we conclude from theorem  [ thm : g - poly ] that in the ideal case where @xmath267 , algorithm  [ alg : g2 g ] with @xmath250 and a proper choice of @xmath182 and @xmath124 reduces the error of system  ( [ eqn : av_sys ] ) in the directions of all eigenvectors @xmath197 , possibly except for a few that correspond to @xmath209 close to the shift @xmath109 . unlike in the case of algorithm  [ alg : g2 g ] with @xmath151 , as @xmath210 grows , no amplified error components appear in the directions of eigenvectors associated with @xmath209 distant from @xmath109 on the left .",
    "this suggests that algorithm  [ alg : g2 g ] with @xmath268 provides a more accurate solve for  ( [ eqn : av_sys ] ) with larger @xmath210 . to see this ,",
    "let us first assume that @xmath269 .",
    "since  ( [ eqn : ch_coarse ] ) implies that @xmath270 for @xmath214 , this choice is known to give the smallest uniform bound on @xmath271 corresponding to the oscillatory eigenmodes @xmath197 , which is @xmath272 with the last inequality resulting from  ( [ eqn : ch_coarse ] ) .",
    "hence , coefficients  ( [ eqn : g12-poly])([eqn : g22-poly ] ) can be reduced within a reasonably small number @xmath124 of smoothing steps .",
    "next , we note that  ( [ eqn : g11-poly ] ) , which is not substantially affected by smoothing , can be large if @xmath109 is close to @xmath219 , i.e. , if @xmath220 . at the same time",
    ", we can write  ( [ eqn : g11-poly ] )  as @xmath273 which shows that @xmath274 approaches @xmath275 as @xmath276 increases , i.e. , smooth error components associated with @xmath209 away from @xmath109 are well damped .",
    "thus , if used as a preconditioner , algorithm  [ alg : g2 g ] with @xmath268 aims at clustering the spectrum of the preconditioned matrix around @xmath47 and @xmath242 , with a few possible outliers that result from the amplification of the smooth eigenmodes associated with @xmath209 close to @xmath109 . unlike in the case where @xmath151 , the increase of @xmath210 does not additionally amplify the smooth error components distant from @xmath109 on the left .",
    "therefore , algorithm  [ alg : g2 g ] with @xmath268 can be expected to provide a more accurate preconditioner for larger shifts .",
    "although our analysis targets the ideal but barely feasible case where @xmath267 , it motivates the use of _ polynomial approximations _ @xmath155 and provides a theoretical insight into the superior behavior of such an option for larger @xmath210 . in the rest of this subsection",
    "we describe a method for constructing such polynomial approximations .",
    "our approach is based on the finding that the problem is easily reduced to constructing _",
    "polynomial filters_. we start by introducing the step function @xmath277 where @xmath146 is a real number , and noting that @xmath278 , so that @xmath279 , where @xmath280 is the matrix of eigenvectors of @xmath111 and @xmath281 is obtained by applying the step function @xmath282 to the diagonal entries of the matrix @xmath283 of the associated eigenvalues",
    ". clearly the number of zeros on the diagonal of @xmath284 equals the number of negative eigenvalues of @xmath111 .",
    "let @xmath285 be a polynomial of degree at most @xmath286 , such that @xmath285 approximates @xmath282 on the interval @xmath287 $ ] , where @xmath288 and @xmath289 are the lower and upper bounds on the spectrum of @xmath111 , respectively . in order to construct an approximation @xmath290 of @xmath260",
    ", we replace the step function @xmath291 in  ( [ eqn : avp_step ] ) by the polynomial @xmath292 .",
    "thus , latexmath:[\\[\\label{eqn : avp_poly }     the matrix @xmath111 is readily available on the fine grid .",
    "therefore , we have reduced the problem of evaluating the polynomial approximation @xmath294 of the absolute value operator to constructing a polynomial @xmath295 that approximates the step function  @xmath296 .",
    "more specifically , since algorithm  [ alg : g2 g ] can be implemented without the explicit knowledge of the matrix @xmath119 , i.e. , @xmath119 can be accessed only through its action on a vector , we need to construct approximations of the form @xmath297 to @xmath298 , where @xmath12 is a given vector .",
    "the task of constructing @xmath299 represents an instance of _ polynomial filtering _ , which is well known ; see , e.g. ,  @xcite . in this context , due to the property of filtering out certain undesirable eigencomponents",
    ", the step function @xmath300 is called a _",
    "filter function_. the approximating polynomial @xmath295 is referred to as a _",
    "polynomial filter_.    state - of - the - art polynomial filtering techniques such as  @xcite would first replace the discontinuous step function @xmath301 by a smooth approximation on @xmath287 $ ] and then approximate the latter by a polynomial in the least - squares sense . in this paper",
    ", we follow a simpler approach based on the direct approximation of @xmath282 using _ chebyshev polynomials _  @xcite .",
    "the constructed polynomial @xmath295 allows defining @xmath299 and hence @xmath302 .",
    "thus , the entire procedure provides means to replace a matrix - vector product with the unavailable @xmath260 by , essentially , a few multiplications with @xmath111 . as we further show , the degree @xmath7 of the approximating polynomial can be kept reasonably low . moreover , in the mg framework discussed in the next subsection , the algorithm has to be invoked only on sufficiently coarse grids .",
    "now let us consider a hierarchy of @xmath303 grids numbered by @xmath304 with the corresponding mesh sizes @xmath305 in decreasing order ( @xmath306 corresponds to the finest grid , and @xmath296 to the coarsest ) .",
    "for each level @xmath307 we define the discretization @xmath308 of the differential operator in ( [ eqn : helmholtz_bvp ] ) , where @xmath309 is the laplacian on grid @xmath307 , and @xmath310 is the identity of the same size .    in order to extend the two - grid av preconditioner given by algorithm  [ alg : g2 g ] to the _ multigrid _ , instead of inverting the absolute value @xmath137 in ( [ eqn : cgc-1 ] )",
    ", we recursively apply the algorithm to the restricted vector @xmath311 .",
    "this pattern is then followed in the v - cycle fashion on all levels , with the inversion of the absolute value of the shifted laplacian on the coarsest grid .",
    "the matrix @xmath119 on level @xmath307 is denoted by @xmath312 .",
    "each @xmath312 is assumed to be spd and is expected to approximate @xmath313 . in the previous subsections we have considered two choices of @xmath119 for the two - grid preconditioner in algorithm  [ alg : g2 g ] . in the mg framework ,",
    "these choices give @xmath314 and @xmath315 , where @xmath316 is a polynomial of degree at most @xmath317 on level @xmath307 .",
    "the advantage of the first option , @xmath314 , is that it can be easily constructed and the application of @xmath312 to a vector is inexpensive even if the size of the operator is very large . according to our analysis for the 1d model problem in subsection  [ subsec : blaplacian ] ,",
    "the approach is suitable for @xmath318 sufficiently small .",
    "typically this is a case for @xmath307 corresponding to finer grids .",
    "however , @xmath319 increases with every new level .",
    "this may result in the deterioration of accuracy of the overall mg preconditioning scheme , unless the size of the coarsest level is kept sufficiently large .",
    "the situation is different for the second option @xmath320 . in this case",
    ", applications of @xmath312 may be expensive on finer grids because they require a sequence of matrix - vector multiplications with large shifted laplacian operators .",
    "however , on coarser levels , i.e. , for larger @xmath318 , this is not restrictive because the involved operators are significantly decreased in size compared to the finest level .",
    "additionally , as suggested by the analysis in subsection  [ subsec : bpoly ] , if @xmath321 represent reasonable approximations of @xmath313 on levels @xmath307 , one can expect a higher accuracy of the whole preconditioning scheme compared to the choice @xmath314 .",
    "our idea is to combine the two options .",
    "let @xmath322 be a `` switching '' parameter , where for finer grids @xmath323 .",
    "we choose @xmath324    summarizing our discussion , if started from the finest grid @xmath325 , the following scheme gives the multilevel extension of the two - grid av preconditioner defined by algorithm  [ alg : g2 g ] .",
    "the subscript @xmath307 is introduced to match quantities to the corresponding grid .",
    "we assume that the parameters @xmath326 , @xmath317 , @xmath327 , and the smoothers @xmath328 are pre - specified .",
    "[ alg : avp - gmg ] input @xmath329 .",
    "output  @xmath330 .    1 .   set @xmath312 by  ( [ eqn : bl ] ) .",
    "presmoothing_. apply @xmath327 smoothing steps , @xmath331 : @xmath332 where @xmath328 defines a smoother on level  @xmath307 .",
    "set @xmath333 .",
    "_ coarse grid correction_. restrict ( @xmath334 ) @xmath335 to the grid @xmath336 , recursively apply av - mg , and prolongate ( @xmath337 ) back to the fine grid .",
    "this delivers the coarse grid correction added to @xmath338 : @xmath339 @xmath340 4 .   _",
    "postsmoothing_. apply @xmath327 smoothing steps : @xmath341 where @xmath328 and @xmath327 are the same as in step 2 .",
    "return @xmath342 .",
    "the described mg av preconditioner implicitly constructs a mapping denoted by @xmath343 , where the operator @xmath344 has the following structure : @xmath345 with @xmath147 as in ( [ eqn:2grid_struct ] ) and @xmath346 defined according to the recursion @xmath347 where @xmath348 .",
    "the structure of the multilevel preconditioner @xmath344 in ( [ eqn : mg_struct ] ) is the same as that of the two - grid preconditioner @xmath144 in ( [ eqn:2grid_struct ] ) , with @xmath349 replaced by the recursively defined operator @xmath350 in ( [ eqn : vcyc ] ) .",
    "thus , the symmetry and positive definiteness of @xmath344 follows from the same property of the two - grid operator through relations  ( [ eqn : vcyc ] ) , provided that @xmath351 and the spectral radii of @xmath352 and @xmath353 are less than @xmath47 throughout the coarser levels .",
    "we remark that preconditioner  ( [ eqn : mg_struct])([eqn : vcyc ] ) is non - variable , i.e. , it preserves the global optimality of pminres .",
    "the simplest possible approach for computing @xmath354 in  ( [ eqn : mg - cgc-1 ] ) is to explicitly construct @xmath355 through the full eigendecomposition of the coarse - level laplacian , and then apply it to @xmath356 .",
    "an alternative approach is to determine @xmath354 as a solution of the linear system @xmath357 , where @xmath358 is the matrix of eigenvectors associated with the negative eigenvalues of @xmath359 contained in the corresponding diagonal matrix @xmath360 . in the latter case ,",
    "the full eigendecomposition of @xmath361 is replaced by the _ partial _ eigendecomposition targeting negative eigenpairs , followed by a linear solve .",
    "since we use richardson s iteration with respect to @xmath321 as a smoother on coarser grids , as motivated by the discussion in subsection  [ subsec : bpoly ] , the guidance for the choice of the coarsest grid is given by condition  ( [ eqn : ch_coarse ] ) .",
    "more specifically , in the context of the standard coarsening procedure ( @xmath362 ) , we select hierarchies of grids satisfying @xmath363 for @xmath364 , and @xmath365 . as shown in the next section , even for reasonably large @xmath109 , the coarsest - level problems are small .    the parameter @xmath326 in  ( [ eqn : bl ] ) should be chosen to ensure the balance between computational costs and the quality of the mg preconditioner .",
    "in particular , if @xmath326 is reasonably large then the choices of @xmath312 are dominated by the option @xmath314 , which is inexpensive but may not be suitable for larger shifts on coarser levels . on the other extreme , if @xmath326 is close to zero then the common choice corresponds to @xmath315 , which provides a better preconditioning accuracy for larger shifts but may be too computationally intense on finer levels . in our numerical experiments ,",
    "we keep @xmath366 $ ] .",
    "as we demonstrate in the next section , the degrees @xmath317 of the occurring polynomials @xmath316 should not be large , i.e. , only a few matrix - vector multiplications with @xmath308 are required to obtain satisfactory approximations of absolute value operators . for properly chosen @xmath326 , these additional multiplications need to be performed on grids that are significantly coarser than the finest grid , i.e. , the involved matrices @xmath308 are orders of magnitude smaller than the original fine grid operator .",
    "as confirmed by our numerical experiments , the overhead caused by the polynomial approximations appears to be marginal and does not affect much the computational cost of the overall preconditioning scheme .",
    "this section presents a numerical study of the mg preconditioner in algorithm  [ alg : avp - gmg ] .",
    "our goal here is twofold . on the one hand ,",
    "the reported numerical experiments serve as a proof of concept of the av preconditioning described in section  [ sec : absval_prec ] . in particular , we show that the av preconditioners can be constructed at essentially the same cost as the standard preconditioning methods ( mg in our case ) . on the other hand , we demonstrate that the mg av preconditioner in algorithm  [ alg : avp - gmg ] combined with the optimal pminres iteration , in fact , leads to an efficient and economical computational scheme , further called minres - av - mg , which outperforms several known competitive approaches for the model problem .",
    "let us briefly describe the alternative preconditioners used for our comparisons . throughout , we use matlab for our numerical examples .",
    "[ [ the - inverted - laplacian - preconditioner ] ] _ * the inverted laplacian preconditioner * _ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this strategy , introduced in  @xcite , is a representative of an spd preconditioning for model problem  ( [ eqn : helmholtz_fd ] ) , where the preconditioner is applied through solving systems @xmath367 , i.e. , @xmath368 .",
    "as has been previously discussed , for relatively small shifts @xmath109 , the laplacian @xmath108 constitutes a good spd approximation of @xmath260 . in this sense , the choice @xmath368 perfectly fits , as a special case , into the general concept of the av preconditioning presented in section  [ sec : absval_prec ] .",
    "we refer to pminres with @xmath368 as minres - laplace .",
    "usually , one wants to solve the system @xmath369 only approximately , i.e. , use @xmath370 .",
    "this can be efficiently done , e.g. , by applying the v - cycle of a standard mg method  @xcite . in our tests , however , we perform the exact solves using the matlab s `` backslash '' , so that the reported results reflect the best possible convergence with the inverted laplacian type preconditioning .    [",
    "[ the - indefinite - mg - preconditioner ] ] _ * the indefinite mg preconditioner * _ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we consider a standard v - cycle for problem  ( [ eqn : helmholtz_fd ] ) .",
    "formally , it can be obtained from algorithm  [ alg : avp - gmg ] by setting @xmath371 on all levels and replacing the first equality in  ( [ eqn : mg - cgc-1 ] ) by the linear solve with @xmath359 .",
    "the resulting mg scheme is used as a preconditioner for restarted gmres and for bi - cgstab .",
    "we refer to these methods as gmres(@xmath87)-mg and bi - cgstab - mg , respectively ; @xmath87 denotes the restart parameter .",
    "a thorough discussion of the indefinite mg preconditioning for helmholtz problems can be found , e.g. , in  @xcite .",
    ".the largest problem sizes satisfying @xmath372 for different values of the shift @xmath109 , `` switching '' parameters @xmath326 , and the standard coarsening scheme @xmath362 .",
    "the last row ( @xmath373 ) corresponds to the sizes of the coarsest problems for different @xmath109 . [ cols=\"^,^,^,^,^,^\",options=\"header \" , ]",
    "we propose a new approach for spd preconditioning for symmetric indefinite systems , based on the idea of implicitly constructing approximations to the inverse of the system matrix absolute value .",
    "a multigrid example of such a preconditioner is presented , for a real - valued helmholtz problem .",
    "our experiments demonstrate that pminres with the new mg absolute value preconditioner leads to an efficient iterative scheme , which has modest memory requirements and outperforms traditional gmres based methods if available memory is tight .",
    "the authors thank michele benzi , yvan notay , and joe  pasciak for their comments on the draft of the manuscript ."
  ],
  "abstract_text": [
    "<S> we introduce a novel strategy for constructing symmetric positive definite ( spd ) preconditioners for linear systems with symmetric indefinite matrices . </S>",
    "<S> the strategy , called absolute value preconditioning , is motivated by the observation that the preconditioned minimal residual method with the inverse of the absolute value of the matrix as a preconditioner converges to the exact solution of the system in at most two steps . </S>",
    "<S> neither the exact absolute value of the matrix nor its exact inverse are computationally feasible to construct in general . </S>",
    "<S> however , we provide a practical example of an spd preconditioner that is based on the suggested approach . in this example </S>",
    "<S> we consider a model problem with a shifted discrete negative laplacian , and suggest a geometric multigrid ( mg ) preconditioner , where the inverse of the matrix absolute value appears only on the coarse grid , while operations on finer grids are based on the laplacian . </S>",
    "<S> our numerical tests demonstrate practical effectiveness of the new mg preconditioner , which leads to a robust iterative scheme with minimalist memory requirements .    </S>",
    "<S> preconditioning , linear system , preconditioned minimal residual method , polar decomposition , matrix absolute value , multigrid , polynomial filtering    15a06 , 65f08 , 65f10 , 65n22 , 65n55 </S>"
  ]
}