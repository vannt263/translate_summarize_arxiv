{
  "article_text": [
    "natural language is one of the most vivid examples of complex systems  @xcite , where the term _ more is different _  @xcite like no other succinctly defines its features .",
    "indeed , the relatively small number of elementary items , the phonemes and letters , allow one to create more complex elements : the words .",
    "they form references to everything that a human can name and describe . however",
    ", the words alone do not constitute the whole essence of language and another complex entity is a prerequisite here : the sentence  @xcite .",
    "the sentential structure is a standard feature of almost all written languages . only at this level",
    "the semantics in its whole richness and with a variety of carriers emerges : words , syntax , phrases , clauses , and punctuation in written language .",
    "statistical analyses of language samples that were carried out since over a century ago  @xcite revealed the existence of laws that describe language quantitatively .",
    "classical statistical study comprises , among others , the empirical word frequency distribution that is compared with the power - law model known as the zipf law  @xcite or its generalized form known as the zipf - mandelbrot law  @xcite , and the functional relation between the length of a text and the number of unique words used to compose it , modelled by the heaps law  @xcite .",
    "a relatively new approach is a description of language in the network formalism  @xcite that , among others , reveals that certain network representations of the lexical structure of texts ( e.g. the word co - occurrence ) belong to the scale - free class , similar to the semantic networks constructed based on the meaning of words  @xcite .",
    "writing requires the use of punctuation ; otherwise some expressions might be ambiguous and deceptive .",
    "punctuation also allows one to denote separate logical units into which any compound message can be divided . from this perspective , the punctuation marks are something more than merely technical signs serving to allow a reader to comprehend the consecutive pieces of texts more easily . if put in between the words , they also acquire meaning and become meaningful not less than , for example , some words playing mainly grammatical role as conjunctions and articles .",
    "for example , even though the full stops do not have clear phonetic expression , they define the length of sentences and thus they can influence a reader s subjective perception of the message content : the speed of events , the descriptive complexity of a given situation , etc .",
    "our recent study shows additionally that punctuation carries long - range correlations in narrative texts  @xcite .",
    "this brings us more quantifiable evidence that punctuation , even though `` silent '' , is no less important than words .",
    "thus , it might seem intuitively natural to include such marks in any analysis , in which the ordinary words are considered : the rank - frequency , the word co - occurrence , and other types of the statistical analyses  @xcite .",
    "it is sometimes done so in the engineering sciences like natural language processing due to practical reasons  @xcite , but without any deeper linguistic justification . on the other hand",
    ", such an inclusion might not be recommended if the statistical properties of the punctuation marks were significantly different from the corresponding properties of the ordinary words as it would actually mean that the punctuation marks were something different than words .",
    "so , this issue appears to be rather a complex one . in order to resolve it , in this work we study the rank - frequency distributions and the word - adjacency networks in the corpora , in which the punctuation marks are treated as words , and compare the results for the punctuation marks with the results for the ordinary words .",
    "we argue that these results , which are complementary to the earlier ones published in  @xcite , can provide one with indication on how to improve reliability of the statistical calculations based on large corpora of the written language samples .",
    "a literary form that is relatively the closest to the spoken language - prose - is expected to reflect the statistical properties of language . in order to analyze it , we selected a set of well - known novels written in one of six indo - european languages belonging to the germanic ( english and german ) , romance ( french and italian ) , and slavic ( polish and russian ) language groups .",
    "our selection criterion was the substantial length of each text sample , i.e. , at least 5,000 sentences , which we have already veryfied to be sufficient for a statistical analysis  @xcite .",
    "the texts were downloaded from the project gutenberg website  @xcite .",
    "apart from the individual texts , we also created 6 monolingual corpora by merging together at least 5 texts written in the same language so that each corpus consisted of about one million words @xmath0 a volume that was sufficient for our statistical analysis ( see appendix for a list of texts ) .",
    "some redundant words residing outside the sentence structure of texts ( such as _ chapter _ , _ part _ , _ epilogue _ , etc . ) , footnotes , page numbers , and typographic marks ( quotation marks , parentheses , etc . ) were deleted .",
    "all standard abbreviations specific to a given language ( like _ mrs . _ and _ dr . _ in english ) were cleaned of dots and counted as separate words .",
    "the following marks were considered the full stops that end a sentence : dots , question marks , exclamation marks , and ellipses .",
    "apart from the full stops , our analysis also included commas , colons , and semicolons .",
    "moreover , the notion of the punctuation marks may be generalized in such a way that it includes new chapters , new parts , and new paragraphs ( that are recognized as the separators stronger than a full stop ) , as well as new lines ( that may further be divided into : comma - new line , colon - new line , etc . ) .",
    "while the division into parts is too sparse to be meaningful in our analysis and the localization of all new paragraphs and new lines is too demanding to be easily done here , we extended our analysis over the chapters . in each text",
    "we found the places , in which new chapters begin , and introduced them into the texts as an additional punctuation mark ( denoted as # chap ) .",
    "we prefered not to consider any specific word as a separator in this context , because different ways of denoting new chapters are used in different texts : the word `` chapter '' , the roman or the hindu - arabic numerals , the asterisks , or even just the voids .",
    "one issue should be kept in mind , however . while the standard punctuation can be viewed as an inherent part of the natural language that helps one to understand the message",
    ", the division of texts into paragraphs , chapters , and parts is purely a writing technique not necessary from the point of view of the language organization .",
    "our first analysis was based on the frequency of word occurrence in a sample , which is a standard approach .",
    "it allowed us to check for possible statistical similarities between the punctuation marks and the ordinary words .",
    "it also aimed at testing whether these additional elements obey the well - known empirical zipf law .",
    "next , in a word - adjacency network representation , where nodes represent words and connections represent the words adjacent positions , the punctuation marks were taken into account like usual words .",
    "doing so has practical importance for the consistency of the network creation process : otherwise there might be a problem whether the node representing a word ending a sentence and the node representing a word that starts the subsequent sentence may be connected to each other . on the one hand , such words are more loosely related semantically than the words within the same sentence are , but , on the other hand , leaving those nodes unconnected can lead to the formation of a disconnected network , for which many useful network measures can not be well - defined .",
    "identification of the punctuation marks as words thus allowed us to overcome this difficulty and to apply all the standard network measures effectively .",
    "all calculations were performed in mathematica and c++ environments independently . for better comparison between the corresponding results ,",
    "all respective figures are shown in the same scale ranges .",
    "the primary characteristics of natural language samples describing its quantitative structure is the zipf distribution .",
    "it states that the probability @xmath1 of encountering the @xmath2th most frequent word scales according to @xmath3 for @xmath4 .",
    "the zipfian scaling in its original formulation holds for the majority of ranks except for a few highest ones , where the power law breaks and the correspodning plots are deflected towards lower frequencies than those expected from the pure power law .",
    "therefore a better agreement with the empirical data one can obtain using the so - called zipf - mandelbrot law ( shifted power - law ) : @xmath5 where @xmath6 is the parameter responsible for the above - mentioned deflection .",
    "there are different hypotheses on the origin of the zipf law , with the principle of least effort  @xcite and the communication optimization  @xcite among them .",
    "it should be noted that this situation occurs only if a language sample is created in the unconstrained and spontaneous conditions .",
    "existing aberrations from a power - law regime have appropriate justifications that have their source in an intellectual disability  @xcite or in sophisticated creative workshops  @xcite .    after calculating the frequency of words , a set of words that are present in almost every sample",
    "is selected . as it turns out , for a sufficiently large sample",
    "they are always the words having grammatical functions .",
    "regardless of the topics covered by a sample text , these words occupy the first ranks in the zipf distribution . additionally",
    ", we count the occurrence numbers of different punctuation marks in each sample and include them in the corresponding zipf distributions as if they were ordinary words . the main plots in fig .",
    "[ fig::zipf ] show such distributions with distinguished punctuation marks ( the special division ) : dot ( # dot ) , question mark ( # qu ) , exclamation mark ( # ex ) , ellipsis ( # ell ) , semicolon ( # scol ) , colon ( # col ) , comma ( # com ) , and new chapter ( # chap ) . in the insets to fig .",
    "[ fig::zipf ] , all the marks that can end sentences are counted together as full stops ( # fs ) .",
    "words and punctuation marks created from a set of novels . for each language ,",
    "dashed lines represent the zipfian power law fitted within the range [ @xmath7 ( and extended over the range @xmath8 ) and a value of the related exponent @xmath9 .",
    "( main ) different punctuation marks are counted separately : comma ( # com ) , dot ( # dot ) , question mark ( # qu ) , exclamation mark ( # ex ) , ellipsis ( # ell ) , semicolon ( # scol ) , colon ( # col ) , and new chapter ( # chap ) . ( inset ) all the punctuation marks that end sentences are counted together as full stops ( # fs ) . in both panels the most frequent words are captioned.,title=\"fig : \" ]   words and punctuation marks created from a set of novels . for each language ,",
    "dashed lines represent the zipfian power law fitted within the range [ @xmath7 ( and extended over the range @xmath8 ) and a value of the related exponent @xmath9 .",
    "( main ) different punctuation marks are counted separately : comma ( # com ) , dot ( # dot ) , question mark ( # qu ) , exclamation mark ( # ex ) , ellipsis ( # ell ) , semicolon ( # scol ) , colon ( # col ) , and new chapter ( # chap ) .",
    "( inset ) all the punctuation marks that end sentences are counted together as full stops ( # fs ) . in both panels the most frequent words are captioned.,title=\"fig : \" ]     words and punctuation marks created from a set of novels . for each language ,",
    "dashed lines represent the zipfian power law fitted within the range [ @xmath7 ( and extended over the range @xmath8 ) and a value of the related exponent @xmath9 .",
    "( main ) different punctuation marks are counted separately : comma ( # com ) , dot ( # dot ) , question mark ( # qu ) , exclamation mark ( # ex ) , ellipsis ( # ell ) , semicolon ( # scol ) , colon ( # col ) , and new chapter ( # chap ) . ( inset ) all the punctuation marks that end sentences are counted together as full stops ( # fs ) . in both panels the most frequent words are captioned.,title=\"fig : \" ]   words and punctuation marks created from a set of novels . for each language ,",
    "dashed lines represent the zipfian power law fitted within the range [ @xmath7 ( and extended over the range @xmath8 ) and a value of the related exponent @xmath9 .",
    "( main ) different punctuation marks are counted separately : comma ( # com ) , dot ( # dot ) , question mark ( # qu ) , exclamation mark ( # ex ) , ellipsis ( # ell ) , semicolon ( # scol ) , colon ( # col ) , and new chapter ( # chap ) .",
    "( inset ) all the punctuation marks that end sentences are counted together as full stops ( # fs ) . in both panels the most frequent words are captioned.,title=\"fig : \" ]     words and punctuation marks created from a set of novels . for each language , dashed lines represent the zipfian power law fitted within the range [ @xmath7 ( and extended over the range @xmath8 ) and a value of the related exponent @xmath9 .",
    "( main ) different punctuation marks are counted separately : comma ( # com ) , dot ( # dot ) , question mark ( # qu ) , exclamation mark ( # ex ) , ellipsis ( # ell ) , semicolon ( # scol ) , colon ( # col ) , and new chapter ( # chap ) . ( inset ) all the punctuation marks that end sentences are counted together as full stops ( # fs ) . in both panels the most frequent words are captioned.,title=\"fig : \" ]   words and punctuation marks created from a set of novels . for each language ,",
    "dashed lines represent the zipfian power law fitted within the range [ @xmath7 ( and extended over the range @xmath8 ) and a value of the related exponent @xmath9 .",
    "( main ) different punctuation marks are counted separately : comma ( # com ) , dot ( # dot ) , question mark ( # qu ) , exclamation mark ( # ex ) , ellipsis ( # ell ) , semicolon ( # scol ) , colon ( # col ) , and new chapter ( # chap ) .",
    "( inset ) all the punctuation marks that end sentences are counted together as full stops ( # fs ) . in both panels the most frequent words are captioned.,title=\"fig : \" ]    commas and the different types of full stops ( except for ellipses ) appear in the same region of the zipf distribution where the highest - ranked words reside , i.e. , the function words , like conjunctions ( especially in the slavic languages ) , articles ( the romance and germanic languages ) , and prepositions . in all the considered languages , comma has @xmath10 , while the rank of dot is typically @xmath11 , except for italian and english ( @xmath12 ) .",
    "the question and exclamation marks as well as semicolons and colons have considerably lower ranks that vary among the languages but in general can be found in the interval @xmath13 ( # qu and # ex ) and in the interval @xmath14 ( # scol and # col ) .",
    "ellispes can behave as lexical words with their ranks sometimes being lower than @xmath15 .",
    "this refers even more to the new chapter marks whose frequency varies strongly from text to text and their rank can be as low as @xmath16 for particular books . for",
    "the general division , the unified full stop becomes the second most frequent object after comma in all languages except for english , where it occupies rank @xmath12 ( after comma and _ the _ ) .",
    "the most interesting observation regarding the plots is that all the punctuation marks in both divisions are placed together with the regular words in the regime that is close to a power - law .",
    "this means that adding the punctuation marks to the zipf analysis results in a substantial improvement of the scaling of the rank - frequency plots in that part ( @xmath8 ) that in a standard analysis deviates from a power - law towards the lower frequencies and that is described by the zipf - mandelbrot distribution . from this point of view ,",
    "the punctuation marks act towards restoring of the zipf distribution .",
    "this effect can be seen in fig .",
    "[ fig::zipf ] , where the zipfian power law fitted within the range [ @xmath7 is geometrically extended over the highest ranks .",
    "for all the languages the corresponding points are closer to the power law and for french , polish , and russian they are placed exactly in the scaling regime . for a comparison , in fig .",
    "[ fig::zipf.odd ] we present analogous zipf plots for two texts where the punctuation differs from the standard pattern ( a lack of the sentence structure of the texts )",
    ". however , except for the distant location or even the absence of # dot , the overall statistical properties of the remaining punctuation marks are normal .    .,title=\"fig : \" ] .,title=\"fig : \" ]    to express the above observation in a quantitative form , we fit the zipf - mandelbrot ( eq .  ( [ eq::zipf.mandelbrot ] ) )",
    "distribution to the rank - frequency plots constructed for words and for words together with the punctuation marks and estimate the corresponding values of the parameter @xmath6 responsible for a deflection from the pure power law @xmath17 .",
    "[ fig::zipf.mandelbrot.fit ] shows such fits for all the considered languages . in each case , the inclusion of the punctuation marks results in the significantly lower values of @xmath6 than those in the case , in which only the words are considered , with the strength of this decrease depending on a language .",
    "it is the strongest for the slavic languages ( essentially @xmath18 ) and the weakest , but still sizeable , for the germanic ones .",
    "this provides a quantitative evidence that the punctuation marks included in a zipfian plot largely restore its scaling , indeed .",
    "]      fig .",
    "[ fig::network ] shows three stages of a word - adjacency network development .",
    "the network was created based on a growing sample of text of length @xmath19 .",
    "the adopted representation allows us to check the adjacency relation between words and punctuation marks . in tab .",
    "[ table ] the chosen network parameters are shown for the corpora .     words . ]",
    ".number of nodes @xmath20 ( vocabulary size ) and unique edges @xmath21 for word - adjacency network created based on monolingual corpora comprising @xmath22 words . since words were not lemmatized , the differences in @xmath20 between the languages come predominantly from inflection . [",
    "cols=\"^,^,^,^,^,^,^,<\",options=\"header \" , ]     the points that denote the ( @xmath23,@xmath24 ) coordinates for the particular items in fig .  [ fig::scatter ] are distributed along this functional dependence .",
    "this means that the item positions on the scatter plots are strongly influenced by these items frequencies , while the actual grammar- and context - related contributions to @xmath24 and @xmath23 are less evident .",
    "therefore , we decided to remove the frequency - based contributions by dividing the empirical values by their average random - model counterparts : @xmath25 and @xmath26 .",
    "the resulting positions of the items are shown in fig .",
    "[ fig::scatter.random ] .",
    "now it is more evident than in fig .",
    "[ fig::scatter ] that both the high - frequency words and the punctuation marks occupy similar positions and no quantitative difference can be identified that is able to distinguish between both groups . in this figure",
    ", we also show these quantities calculated for three sample words chosen randomly from more distant parts of the zipf plot : _ time _ ( @xmath27 in the english corpus ) , _ face _",
    "( @xmath28 ) , and _ home _",
    "( @xmath29 ) , as well as their semantical counterparts in the other languages ( occupying different ranks , see tab .",
    "[ tab::ranks ] ) . obviously , each of these words may also have other , non - equivalent meanings in distinct languages and , while some languages use inflection , the other ones do not , which inevitably contribute to the rank differences .",
    "in contrast to the most frequent words discussed before , these words are significantly less frequent , which can itself lead to some differences in the statistical properties as compared to the top - ranked words . therefore , they are not shown in fig .",
    "[ fig::scatter ] , because their local clustering coefficient significantly exceeds the vertical axis upper limit . in fig .",
    "[ fig::scatter.random ] , the sample lexical words are located in different places for different languages , but typically their average position is more or less shifted towards the upper left corner of the plots . this effect is the most pronounced for french , then for english , russian , italian , and polish , while it is absent for german",
    ". this visible shift may originate from either the statistical fluctuations among the words , the statistical fluctuations among the texts selected for the corpora , or be a geniune effect for the less frequent words , the parts of speech , and/or a general property of the lexical words in specific languages .",
    "however , since our sample of the medium - ranked words is small , at present we prefer not to infer any decisive conclusions from this result as we plan to carry out a related , comprehensive study in near future .",
    "nevertheless , we stress here that such displacements exhibited in fig .",
    "[ fig::scatter.random ] by the words of medium frequency by no means contradict our main statement that the punctuation marks show similar statistical properties as the most frequent words .     and the local clustering coefficient @xmath30 divided by their random - null - model counterparts @xmath26 and @xmath25 , respectively . the same corpora as in fig .  [ fig::scatter ]",
    "in addition to the words ( open circles ) and the punctuation marks ( full circles ) used in fig .",
    "[ fig::scatter ] , the results for three sample lexical words , semantically the same for each language , are also presented ( full triangles).,title=\"fig : \" ]   and the local clustering coefficient @xmath30 divided by their random - null - model counterparts @xmath26 and @xmath25 , respectively .",
    "the same corpora as in fig .",
    "[ fig::scatter ] are used .",
    "in addition to the words ( open circles ) and the punctuation marks ( full circles ) used in fig .",
    "[ fig::scatter ] , the results for three sample lexical words , semantically the same for each language , are also presented ( full triangles).,title=\"fig : \" ]     and the local clustering coefficient @xmath30 divided by their random - null - model counterparts @xmath26 and @xmath25 , respectively .",
    "the same corpora as in fig .",
    "[ fig::scatter ] are used .",
    "in addition to the words ( open circles ) and the punctuation marks ( full circles ) used in fig .  [ fig::scatter ] , the results for three sample lexical words , semantically the same for each language , are also presented ( full triangles).,title=\"fig : \" ]   and the local clustering coefficient @xmath30 divided by their random - null - model counterparts @xmath26 and @xmath25 , respectively .",
    "the same corpora as in fig .",
    "[ fig::scatter ] are used .",
    "in addition to the words ( open circles ) and the punctuation marks ( full circles ) used in fig .",
    "[ fig::scatter ] , the results for three sample lexical words , semantically the same for each language , are also presented ( full triangles).,title=\"fig : \" ]     and the local clustering coefficient @xmath30 divided by their random - null - model counterparts @xmath26 and @xmath25 , respectively .",
    "the same corpora as in fig .",
    "[ fig::scatter ] are used .",
    "in addition to the words ( open circles ) and the punctuation marks ( full circles ) used in fig .",
    "[ fig::scatter ] , the results for three sample lexical words , semantically the same for each language , are also presented ( full triangles).,title=\"fig : \" ]   and the local clustering coefficient @xmath30 divided by their random - null - model counterparts @xmath26 and @xmath25 , respectively . the same corpora as in fig .  [ fig::scatter ] are used .",
    "in addition to the words ( open circles ) and the punctuation marks ( full circles ) used in fig .",
    "[ fig::scatter ] , the results for three sample lexical words , semantically the same for each language , are also presented ( full triangles).,title=\"fig : \" ]    now we consider another property of nodes , i.e. , the indicators how important for the network structure their presence is .",
    "in other words , we study how the removing of particular nodes can impact the overall network stucture expressed in terms of the global network measures .",
    "we look at three such measures : the average shortest path length : @xmath31 , the global clustering coefficient : @xmath32 , and the global assortativity coefficient @xmath33 : @xmath34 where @xmath21 is the number of edges in the network and @xmath35 equals 1 if there is an edge between the nodes @xmath36 and @xmath37 or 0 otherwise . due to the same reason as before , we first calculate the corresponding quantities @xmath38 , @xmath39 , and @xmath40 for the randomized text samples ( 100 independent realizations ) and consider them the reference values determined solely by the frequencies of particular items and by neither grammar nor context .",
    "we thus consider the values of @xmath41 ( fig .",
    "[ fig::aspl.removed ] ) , @xmath42 ( fig .",
    "[ fig::gcc.removed ] ) , and @xmath43 ( fig .",
    "[ fig::gai.removed ] ) and expect them to be related to grammar and context largely . for different text samples ( novels ) , we compare the corresponding values calculated for a complete network with all the nodes present ( denoted by the abscissa @xmath44 ) and for 10 incomplete networks obtained by removing a given highly ranked node according to the zipf distribution ( @xmath45 ) .     with respect to @xmath46 for the networks representing different text samples ( novels ) . for each novel",
    ", the rank @xmath44 denotes the complete network with all the @xmath20 nodes , while the lower ranks @xmath45 denote the incomplete networks with @xmath47 nodes obtained by removing a node corresponding to a word ranked @xmath2 in the zipf distribution for this novel . ]     for the networks representing different novels ( the same as in fig .",
    "[ fig::aspl.removed ] ) divided by its counterpart @xmath48 calculated for the null model of random texts with the same zipf distribution . ]     for the networks representing different novels . for each novel",
    ", the rank @xmath44 denotes the complete network with all @xmath20 nodes , while the lower ranks @xmath45 denote the incomplete networks with @xmath47 nodes obtained by removing a node corresponding to the word ranked @xmath2 in the zipf distribution for this novel . ]     for the networks representing different novels ( the same as in fig .",
    "[ fig::gcc.removed ] ) divided by its counterpart @xmath49 calculated for the null model of random texts with the same zipf distribution . ]     for the networks representing different novels . for each novel , the rank @xmath44 denotes the complete network with all @xmath20 nodes , while the lower ranks @xmath45 denote the incomplete networks with @xmath47 nodes obtained by removing a node corresponding to the word ranked @xmath2 in the zipf distribution for this novel . ]     for the networks representing different novels divided by its counterpart @xmath50 calculated for the null model of random texts with the same zipf distribution . ]    in each case , by removing one of the highly connected nodes , aspl becomes longer than for the complete network and this is not surprising since the network loses one of its hubs .",
    "this increase of @xmath51 is different for different ranks and different novels @xmath0 see fig .",
    "[ fig::aspl.removed ] , but a rule is that , statistically , the lower the rank ( the larger @xmath2 ) is , the smaller is the change in @xmath51 ( for a particular novel there might be some exceptions ) .",
    "this rule comes from the fact that in the word - adjacency networks removing a strong hub is more destructive for the network than removing some less connected node .",
    "this means that in a typical situation @xmath51 alters its value the most for comma and the full stop since they occupy the highest ranks , while the observed changes for the function words are smaller .",
    "this picture substantially changes if we look at the rescaled quantity : @xmath52 that is free of an item s frequency contribution to aspl . fig .",
    "[ fig::aspl.removed.random ] shows that , except for # com , @xmath53 does not exhibit any significant dependence on @xmath2 and excluding a particular node does not alter its value much as compared to the complete network .",
    "typically , the rescaled aspl is restricted to a narrow range of @xmath54 and this means that the correlations present in the text samples shorten effectively the paths between the nodes as compared to the random network , but this is a small effect .",
    "the case of comma is slightly different as , for some texts , the network without this node shows @xmath55 , i.e. , the residual network has the same @xmath51 as the random one .",
    "presence of this property of comma is text - dependent and it does not seem to be a property of written language . moreover , it should be stressed that , even if one considers comma , the range of the @xmath53 variability for different nodes is small .    the global clustering coefficient @xmath56 and the assortativity index @xmath57 present a more variable behaviour after removing a hub as these quantities can either increase , remain stable , or decrease .",
    "this behaviour obviously depends on a contribution of each particular node to @xmath58 and @xmath33 for @xmath44 . for the clustering coefficient",
    ", a statistical rule is that without particular nodes @xmath56 does not differ much from its complete - network counterparts . only for the node representing comma",
    ", @xmath56 can increase more significantly and the network becomes more clustered ( fig .",
    "[ fig::gcc.removed ] ) .",
    "this can partially be explained by an observation that in all the considered languages commas can mediate words whose direct neighbourhood is unlikely due to rules of grammar . since @xmath56 depends on an item s frequency , in fig .",
    "[ fig::gcc.removed.random ] we show the rescaled coefficient : @xmath59 whose values are related to the random model .",
    "now the networks without # com and the ones without other nodes show comparable values of @xmath60 with only small difference ( up to 10% ) for some texts .    as regards the assortativity index @xmath57 , the majority of hubs in the word - adjacency networks ( like , e.g. , # fs , articles , and the most frequent conjunctions ) can be considered disassortative separators , so after their removal , the overall assortativity index increases ( fig .",
    "[ fig::gai.removed ] ) . of course , since this is only a statistical observation , particular cases may show different behaviour like , e.g. , comma , which sometimes acts like a disassortative separator and sometimes like an assortative one . in order to remove the approximately monotonuous dependence of @xmath33 on rank @xmath2 ,",
    "we look at the rescaled assortativity index : @xmath61 .",
    "we see that now this dependence is absent and that both the punctuation marks and the function words exhibit comparable values of @xmath62 ( see the narrow range of the vertical axis in each panel of fig .  [ fig::gai.removed.random ] ) .",
    "punctuation marks are among the most common objects in written language .",
    "they do not play purely grammatical roles , but they also carry some semantic load , similar to such words like articles , conjunctions , and prepositions .",
    "this opens space for putting a question whether the punctuation marks may be included in any lexical analysis on par with the ordinary words . in this work we addressed this question by comparing the statistical properties of the most common punctuation marks and words using two approaches .",
    "we observed that the punctuation marks locate themselves exactly on or in a close vicinity of the power - law zipfian regime as if they were ordinary words .",
    "moreover , their inclusion acts towards restoring of the zipf power - law from the more flat zipf - mandelbrot behaviour .",
    "we drew the same conclusion from an analysis of the word - adjacency networks , in which words , full stops ( the aggregated sentence - ending punctuation marks ) , and commas were considered nodes .",
    "in such networks , the punctuation marks are more important than typical nodes : they play a role of the hubs ( together with the most frequent words ) . despite some minor , quantitative - only differences , topology of such networks and",
    "their growth is similar from the perspective of punctuation marks and from the perspective of words .",
    "quantitatively , it is expressed by the node - specific average shortest path length , the local clustering coefficient , the local assortativity , and their global counterparts .",
    "these results are qualitatively invariant under language change even for the languages belonging to different indo - european groups . regarding the quantitative viewpoint",
    ", we do observe certain systematic differences of the network properties between different text samples ( including different languages ) , but considering them here is beyond the scope of this work .",
    "a related study will be presented and discussed elsewhere .    by taking all these outcomes into consideration , the principal conclusion from this study",
    "is that punctuation marks are almost indistinguishable from other most and medium common words ( both the function and the lexical ones ) if one investigates their statistical properties .",
    "since the punctuation marks have also non - neglectable meaning , we advocate their inclusion in any type of the word - occurrence and the word - adjacency analysis making it to be more complete .",
    "incorporation of the punctuation marks into an analysis extends its dimensionality and , therefore , it opens more space for possible manifestation of some previously unobserved effects . that this can in fact be fruitful and bring important results , the best example is ref .",
    "@xcite where we showed that the sentence length variability can be multifractal for specific ( written with the stream - of - consciousness narration ) group of texts , while for other texts it remains monofractal .",
    "multifractality is inherently accompanied by burstiness . in the present context",
    "this burstiness in the sentence length thus translates itself into analogous effects in the recurrence times ( measured by a separation of two consecutive occurrences of the same item ) of the full stops . at the same time , however , the recurrence times of the most frequent words appear to be much less bursty as it was also documented in the same ref .  @xcite .",
    "this latter effect goes in parallel with an observation made earlier  @xcite for the most frequent words .",
    "interestingly , according to the same paper  @xcite , the burstiness is however often observed for the non - function words of high and medium ranks .",
    "the related intricacy in fact further supports our thesis that , from the statistical point of view , the punctuation marks are surprisingly similar to the regular words , even though at some angles they resemble more the most frequent function words , while at other angles they resemble more the non - function words .",
    "we expect more interesting results will be obtained in future from analyses , in which the punctuation marks are not neglected .",
    "we thank the anonymous referees for very interesting and insightful suggestions that led to significant extensions and improvement of this paper .",
    "the books used in our analysis ( asterisks denote the corpora - forming books ) :    english : george orwell _ 1984@xmath63 _ , mark twain _ adventures of huckleberry finn _ , herman melville _ moby dick@xmath63 _ , jane austen _ pride and prejudice@xmath63 _ , james joyce _ ulysses@xmath63 _ , jonathan swift _",
    "gulliver s travels@xmath63 _ , margaret mitchell _ gone with the wind_.    german : friedrich nietzsche _ also sprach zarathustra@xmath63 _ , franz kafka _ der process@xmath63 _ ,",
    "heinrich mann _",
    "der untertan@xmath63 _ , thomas mann _ der zauberberg@xmath63 _ , christiane vera felscherinow _ wir kinder vom bahnhof zoo@xmath63_.    french : alexandre dumas _ ange pitou@xmath63 _ , albert camus _",
    "la peste@xmath63 _ , mile zola _",
    "la terre@xmath63 _ , _ le docteur pascal _ , gustave flaubert _ madame bovary@xmath63 _ , gaston leroux _",
    "le fantme de lopra@xmath63_.    italian : umberto eco _ il pendolo di foucault@xmath63 _ , gabriele dannunzio _ trionfo della morte@xmath63 _ , giambattista bazzoni _",
    "falco della rupe o la guerra di musso@xmath63 _ , luigi capuana _ giacinta@xmath63 _ , tullio avoledo _",
    "le radici del cielo@xmath63_.    polish : gustaw herling - grudziski _",
    "inny wiat@xmath63 _ , karol olgierd borchardt _",
    "znaczy kapitan@xmath63 _ , walery oziski _",
    "zaklty dwr@xmath63 _ , stefan eromski _",
    "przedwionie@xmath63 _ ,",
    "wadysaw reymont _",
    "ziemia obiecana@xmath63 _ , bolesaw prus _",
    "lalka _ , jerzy andrzejewski _ bramy raju_.          e.g.  altmann , j.b .",
    "pierrehumbert , a.e .",
    "motter , beyond word frequency : bursts , lulls , and scaling in the temporal distributions of words , plos one 4 ( 2009 ) e7678 .",
    "amancio , o.n .",
    "oliveira  jr , l.d.f .",
    "costa , structure - semantics interplay in complex networks and its effects on the predictability of similarity in texts , physica  a 391 ( 2012 ) 4406 - 4419 .",
    "amancio , a complex network approach to stylometry , plos one 10 ( 2015 ) e0136076 .",
    "anderson , more is different , science 177 ( 1972 ) 393 - 396 .",
    "m.  ausloos , punctuation effects in english and esperanto texts , physica a 389 ( 2010 ) 2835 - 2840 .",
    "dorogovtsev , j.f.f .",
    "mendes , language as an evolving word web , proc .",
    "268 ( 2001 ) 2603 - 2606 .",
    "dorogovtsev , a.v .",
    "goltsev , j.f.f .",
    "mendes , pseudofractal scale - free web , phys .",
    "e 65 ( 2002 ) 066122 .",
    "s.  drod , p.  owicimka , a.  kulig , j.  kwapie , k.  bazarnik , i.  grabska - gradziska , j.  rybicki , m.  stanuszek , quantifying origin and character of long - range correlations in narrative texts , inf .",
    "331 ( 2016 ) 3244 .",
    "estoup , gammes stnographiques .",
    "methodes et exercises pour lacquisition de la vitesse , institut stnographique de france , 1916 .",
    "r.  ferrer - i - cancho , r.v .",
    "sol , the small world of human language , proc .",
    "sci . 268 ( 2001 ) 2261 - 2265 .",
    "m.  gerlach , e.g.  altmann , stochastic model for the vocabulary growth in natural languages , phys .",
    "x 3 ( 2013 ) 021006 .",
    "i.  grabska - gradziska , a.  kulig , j.  kwapie , s.  drod , complex network analysis of literary and scientific texts , int . j. mod . phys .",
    "c 23 ( 2012 ) 1250051 .",
    "heaps , information retrieval : computational and theoretical aspects , academic press , orlando , 1978 . g.  herdan , type - token mathematics . a textbook of mathematical linguistics , mouton , s - gravenhage , 1960 .",
    "a.  kao , s.r .",
    "poteet , natural language processing and text mining , springer science & business media , berlin , 2007 .",
    "a.  kulig , s.  drod , j.  kwapie , p.  owicimka , modeling the average shortest - path length in growth of word - adjacency networks , phys .",
    "e 91 ( 2015 ) 032810 .",
    "j.  kwapie , s.  drod , a.  orczyk , linguistic complexity : english vs. polish , text vs. corpus , acta phys . pol .  a 117 ( 2010 ) 716 - 720 .",
    "j.  kwapie , s.  drod , physical approach to complex systems , phys .",
    "515 ( 2012 ) 115 - 226 .",
    "h.  liu , statistical properties of chinese semantic networks , chin .",
    "54 ( 2009 ) 2781 - 2785 .",
    "mandelbrot , an information theory of the statistical structure of language , in : w.  jackson ( ed . ) , communication theory , pp .",
    "503 - 512 , academic press , new york , 1953 .",
    "b.  mandelbrot , information theory and psycholinguistics : a theory of words frequencies , in : p.  lazafeld , n.  henry ( eds . ) , readings in mathematical social science , mit press , cambridge , 1966 . m.  markosova , network model of human language , phys .  a 387 ( 2008 ) 661 - 666 .",
    "masucci , g.j .",
    "rodgers , network properties of written human language , phys .",
    "e 74 ( 2006 ) 026102 .",
    "montemurro , beyond the zipf ",
    "mandelbrot law in quantitative linguistics , physica  a 300 ( 2001 ) 567 - 578 .",
    "w.  piotrowska , x.  piotrowska , statistical parameters in pathological text , j.  quant . ling",
    ". 11 ( 2004 ) 133 - 140",
    ". the project gutenberg website , _",
    "www.gutenberg.org_. g.k .",
    "zipf , selective studies and the principle of relative frequency in language , mit press , cambridge , 1932 .",
    "zipf , human behavior and the principle of least effort , addison - wesley , cambridge , 1949 ."
  ],
  "abstract_text": [
    "<S> from a grammar point of view , the role of punctuation marks in a sentence is formally defined and well understood . in semantic analysis punctuation plays also a crucial role as a method of avoiding ambiguity of the meaning . </S>",
    "<S> a different situation can be observed in the statistical analyses of language samples , where the decision on whether the punctuation marks should be considered or should be neglected is seen rather as arbitrary and at present it belongs to a researcher s preference . </S>",
    "<S> an objective of this work is to shed some light onto this problem by providing us with an answer to the question whether the punctuation marks may be treated as ordinary words and whether they should be included in any analysis of the word co - occurences . </S>",
    "<S> we already know from our previous study ( s.  drod _ et al . </S>",
    "<S> _ , inf . </S>",
    "<S> sci . </S>",
    "<S> 331 ( 2016 ) 32 - 44 ) that full stops that determine the length of sentences are the main carrier of long - range correlations . </S>",
    "<S> now we extend that study and analyze statistical properties of the most common punctuation marks in a few indo - european languages , investigate their frequencies , and locate them accordingly in the zipf rank - frequency plots as well as study their role in the word - adjacency networks . </S>",
    "<S> we show that , from a statistical viewpoint , the punctuation marks reveal properties that are qualitatively similar to the properties of the most frequent words like articles , conjunctions , pronouns , and prepositions . </S>",
    "<S> this refers to both the zipfian analysis and the network analysis . by adding the punctuation marks to the zipf plots </S>",
    "<S> , we also show that these plots that are normally described by the zipf - mandelbrot distribution largely restore the power - law zipfian behaviour for the most frequent items .    </S>",
    "<S> our results indicate that the punctuation marks can fruitfully be considered in the linguistic studies as their inclusion effectively extends dimensionality of an analysis and , therefore , it opens more space for possible manifestation of some previously unobserved effects .    </S>",
    "<S> punctuation , word - adjacency networks , complex networks , word - frequency distribution    89.75.-k , 89.75.da , 89.75.hc , 02.10.ox </S>"
  ]
}