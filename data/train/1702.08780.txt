{
  "article_text": [
    "visual loop closure detection ( lcd ) tries to detect previously visited places based on appearance information of the scene .",
    "lcd can play an important part in global consistent visual simultaneous localization and mapping ( slam ) systems  @xcite and appearance - based robot relocalization  @xcite . for visual slam , state - of - the - art approaches  @xcite only handle a local window of recently added frames while the previous frames are marginalized out due to the limitation of computational complexity , resulting in the accumulation of state ( position and orientation ) error .",
    "lcd is introduced to identify places that have already been visited , thus creating an observation between history state and current state .",
    "the accumulated error can be effectively reduced based on this observation .",
    "the most widely used lcd methods can be summarized as local feature based methods , which try to model image similarity based on hand crafted features .",
    "most methods  @xcite use bag of words ( bow ) scheme to represent image since  @xcite , which extracts feature points from an image and cluster them into different centroids called visual words .",
    "a histogram of appeared visual words is consequently used to represent the image .",
    "the similarity of image pairs is computed based on the difference of the visual words histograms .",
    "one well - known drawback of bow is the perceptual aliasing introduced in cluster step if two dissimilar features are clustered into the same visual word .",
    "the performance of clustering depends on the quality of a previously  @xcite or online  @xcite trained dictionary .",
    "conventional methods  @xcite using real - valued features like sift  @xcite or surf  @xcite suffer from high computational complexity in feature extraction and feature classification . to deal with this problem ,",
    "recent methods like bobw  @xcite , ibuild  @xcite , orbslam  @xcite have proposed to use efficient binary features like orb  @xcite or brisk  @xcite .",
    "while binary feature based lcd methods can run at real time , the accuracy ( typically measured by precision and recall metric  @xcite ) of these methods is not satisfying .",
    "in this paper , mild : multi - index hashing for appearance based loop closure detection is proposed as an appearance based lcd approach exploiting the efficiency of binary features . instead of using bow representation widely adopted by previous methods , image similarity is measured based on direct feature matching without introducing additional computational complexity with the aid of multi - index hashing ( mih )  @xcite .",
    "contributions of this paper include :    * we propose a novel lcd system based on multi - index hashing ( mild ) .",
    "in particular , we do not explicitly find the exact nearest neighbor of each feature or use bow representation for images .",
    "instead , mih is used to approximate the image similarity measurement , so that redundant computations between dissimilar features can be avoided . *",
    "the approximated image similarity measurement based on mih is analyzed from a probabilistic perspective , which effectively reveals the trade - off between the accuracy and complexity in mild , ensuring the superiority of mild in high accuracy and low complexity compared with state - of - the - art algorithms . * the detection of multiple loop closures",
    "is enabled in mild , while most of the previous works  @xcite assume that loop closure only occurs once in the candidate dataset for each query image .",
    "in this work , we focus on lcd by local image feature",
    ". approaches such as global image descriptor  @xcite or exploiting illumination invariant components to improve image similarity measurement under different lighting conditions  @xcite are not discussed , but can be combined for a more robust lcd system .",
    "the accuracy of binary feature based lcd methods is not satisfying , the authors in  @xcite investigate this problem and find that binary features are not straightforward to cluster using existing nearest neighbor search methods , due to the high dimensionality and the nature of the binary descriptor space . to overcome this deficiency ,  @xcite projects binary features into a real - valued vector space and implements nearest neighbor search in this space .",
    "an alternative way for lcd is direct feature match as proposed by  @xcite . instead of using bow representation",
    ",  @xcite proposes to use raw features to represent an image directly ( borf ) , which significantly improves the recall performance .",
    "@xcite adopts locality sensitive hashing ( lsh ) for fast approximate nearest neighbor search based on the sift feature .",
    "these methods suffer from high computational complexity and can not scale well with the increase of candidate images .",
    "we address this problem by multi - index hashing ( mih ) proposed by  @xcite to hash long binary codes for fast information retrieval .",
    "recently  @xcite uses mih for exact nearest neighbor search and tries to find the optimal substring length given the database size , code length and search radius to minimize the upper bound of the search cost .",
    "experiments show that search cost grows rapidly with the increase of search radius .    as a method of nearest neighbor search",
    ", mih has already been used in different applications like image relocalization  @xcite and image search  @xcite .",
    "@xcite follows the same procedure in  @xcite and complains about the inefficiency of mih in finding the exact nearest neighbor for each feature .",
    "while  @xcite only explores the use of partial binary descriptors created in mih as direct codebook indices , and follows a traditional bow method to measure image similarity .    on the contrary to the previous methods ,",
    "we do not explicitly find the exact nearest neighbor of each feature or use bow representation for images .",
    "instead , mih is used to approximate the image similarity function proposed in  @xcite .",
    "the accuracy and efficiency of such approximation are analyzed from a probabilistic perspective .",
    "the framework of mild is shown in fig .  [",
    "fig : flowchart ] , where the mild can be divided into two stages : the first step aims to calculate the similarity between current image @xmath0 and candidate set @xmath1 that are constructed by all the previous images @xmath2 .",
    "we denote @xmath3 as the binary local feature set to represent an image @xmath4 , where @xmath5 stands for the number of features . here the orb feature [ 13 ] is used due to the computation efficiency and rotation invariance , with the descriptor be a 256 bit binary sequence . given the image similarity , a bayesian filter is applied to calculate the probability of loop closure for each candidate .",
    "we define the similarity of image pair ( @xmath6 , @xmath7 ) as @xmath8 where @xmath9 refers to binary feature similarity @xcite , i.e. , @xmath10 here @xmath11 denotes hamming distance between binary features @xmath12 and @xmath13 , @xmath14 is the weighting parameter , and @xmath15 is the pre - defined hamming distance threshold .    a straightforward way to calculate the image similarity is linear search for all the candidates in @xmath1 .",
    "however , the computational cost may be unbearable for large datasets .",
    "given the fact that the number of repeating or highly - similar features is limited between current image and previous images , implying that the valid similarity measurements are highly sparse , we propose to use multi - index hashing ( mih ) to avoid invalid computations , since mih is capable in distinguishing similar features .",
    "more analysis is provided in section  [ sec_analysis ] .    as illustrated in fig .",
    "[ fig : mih ] , in mih , a long binary feature is hashed @xmath16 times based on its @xmath16 disjoint substrings . more precisely ,",
    "if the hamming distance of two features is smaller than @xmath17 , each feature is divided into @xmath16 disjoint substrings , then at least in 1 substring the hamming distance of two features will be smaller than @xmath18 @xcite , implying that for two features with small hamming distance , the probability that they fall into the same entry in at least one hash table will be close to 1 . then , the image similarity measurement in eqn .",
    "( [ eqn : similarity ] ) can be approximated using mih , where the database is constructed online based on the candidate set , and the image similarity is measured during the query stage . in practice , database construction and query are implemented with mih simultaneously .    * database construction : for every input image @xmath19 and its feature set @xmath20 , all features are hashed into the @xmath16 hash tables by separating each feature into @xmath16 substrings @xmath21 , where @xmath22 is the hash index of @xmath23-th hash table . *",
    "query : for the newly arrived query image @xmath0 and its binary feature set @xmath24 , the similarity between @xmath0 and candidates @xmath25 is initialized as @xmath26 .",
    "let @xmath27 be the collection of features that falls into the same entry with the feature @xmath28 , then @xmath29 in eqn .",
    "( [ eqn : similarity ] ) can be approximated by @xmath30    examining eqn .",
    "( [ eqn : approximate ] ) , @xmath31 can be calculated by 1 pass traverse of features in @xmath24 during the hashing process .",
    "@xmath27 is a subset of @xmath24 .",
    "the probability of @xmath32 , j \\in [ 1 , |f_k|]$ ] that falls into @xmath27 ( denoted as the recall probability ) is related to the hamming distance @xmath11 between @xmath33 and @xmath28 , and the number of hashing tables @xmath16 in mih .",
    "the detailed analysis of the approximation error between @xmath31 and @xmath29 is provided in section [ sec_analysis ] .",
    "bayesian inference is used to select true loop closure based on image similarity measurement and temporal coherency of camera movement @xcite . to enable the detection of multiple loop closures , we propose to extend the random variable representing loop closure hypotheses at time @xmath23 ( denoted as @xmath34 ) to be a binary random variable @xmath35 , where @xmath36 is the event that current image @xmath37 closes the loop with the past image @xmath38 . in this way ,",
    "the time evolution model is formulated as @xmath39 where @xmath40\\}$ ] .",
    "thus , the belief can be computed as @xmath41    recall that the image similarity measurement @xmath42 is given by eqn .",
    "[ eqn : approximate ] , the likelihood is computed as  @xcite @xmath43 where @xmath44 and @xmath14 are the mean and standard deviation of sequence @xmath45 . finally , the loop closure probability @xmath46 given all the previous similarity measurements can be computed as @xmath47},\\end{aligned}\\ ] ] where @xmath48 is defined as a fixed value to normalize the output loop closure probability .",
    "the candidates whose loop closure probability is larger than the threshold @xmath49 will be the detected loop closures .",
    "suppose the binary feature is divided into @xmath16 disjoint substrings , the probability that a feature pair with hamming distance @xmath11 falls into the same entry in at least one of the @xmath16 hash tables is denoted as the recall probability @xmath50 .",
    "this is equivalent to the case that @xmath11 independent balls are thrown into @xmath16 bins randomly , where the probability of at least one bin has no ball under the assumption of uniform distribution of hamming errors is a solved problem  @xcite : @xmath51 here @xmath52 is the stirling partition number  @xcite . fig .",
    "[ fig : recallprobability ] shows the recall probability changes along hamming distance @xmath11 , as well as the influence of @xmath16 on the recall probability . as we expected , a larger @xmath11 yields a smaller recall probability , while a larger @xmath16 tends to make the decreasing curve of recall probability more gradual .    in lcd",
    ", for each feature in the query image , features describing the same place in @xmath1 are referred as inliers and the others are outliers .",
    "then the computational complexity of @xmath53 ( denoted as @xmath54 ) is proportional to the average probability of outliers falling into @xmath27 .",
    "the accuracy of @xmath53 ( denoted as @xmath55 ) can be modeled as the average probability of inliers falling into @xmath27 .",
    "the unavoidable computations of similarity calculation for inliers are discarded in @xmath54 . using the statistics of the distance distribution for inliers and outliers of orb feature  @xcite",
    ", the hamming distances of outliers and inliers can be modeled as gaussian distribution @xmath56 and @xmath57 , respectively .",
    "based on this approximation , the accuracy and complexity can be calculated as @xmath58 ,   \\\\",
    "e(m ) & = \\overset{l}{\\underset{d=0}{\\sum } } [ p_{recall}(m , d)\\times p_o(d ) ] . \\end{array } \\label{eqn : r_e}\\ ] ]    given eqn .",
    "( [ eqn : r_e ] ) , the influence of different @xmath16 on the trade - off between accuracy and complexity of mild is further presented in fig .  [",
    "fig : recallcomplexity ] .",
    "a higher @xmath59 indicates that the approximation error between @xmath60 and @xmath61 is smaller , yielding higher accuracy of mild . while a lower @xmath62 indicates more efficiency .",
    "although @xmath59 and @xmath62 grow monotonously with @xmath16 , there exists an interval of @xmath16 to achieve good balance of high accuracy and low complexity .",
    "an appropriate @xmath16 can be chosen for different applications regarding different bias on accuracy and complexity .",
    "for example , in mild , @xmath63 guarantees relatively high accuracy and very low computational cost .",
    "experiments show that mild enables loop closure detection within 15 ms for a database containing more than 1000 images , which is efficient enough for real - time lcd system .",
    "to evaluate the performance of mild , we conduct extensive experiments on different datasets .",
    "citycentre  @xcite contains 1237 images of size @xmath64 .",
    "lip6indoor  @xcite has 388 images of size @xmath65 .",
    "lip6outdoor  @xcite has 1063 images of size @xmath65 . ] and compare with state - of - the - art methods : angeli  @xcite , rtabmap  @xcite and bowp  @xcite which are based on sift / surf feature , as well as bobw  @xcite and ibuild  @xcite that use binary feature , and the loop closure probability threshold @xmath66 . ]",
    ". the implementation of mild will be publicly available online .      for a better understanding of mild ,",
    "we particularly show intermediate results of mild on newcollege dataset @xcite in fig .",
    "[ fig : newcollege ] , where the approximated image similarity measurement using mih is illustrated in fig .",
    "[ fig : a ] . given the image similarity measurement , bayesian inference",
    "is employed to select loop closures among candidates , as shown in fig .",
    "[ fig : b ] . compared with the ground truth of loop closures ( fig .",
    "[ fig : c ] ) , the proposed mild works effectively , as reflected by the fact that image similarity score in fig .",
    "[ fig : a ] is high when image pair @xmath67 is a true loop closure , and the detected loop closures in fig .",
    "[ fig : b ] highly resemble ground truth .",
    "the quantitative comparisons regarding accuracy ( recall rate at precision equals to 100% ) and complexity on different datasets are presented in  table [ tab : comparison ] , where the performance of concerned methods are collected directly from the reference papers . examining table [ tab : comparison ] , we have following observations :    * angeli  @xcite , rtabmap  @xcite and bowp  @xcite require hundreds of milliseconds for lcd per image , due to the using of sift / surf feature .",
    "although rtabmap yields the best recall , it takes 700ms per frame on average to process one query image , which is around * twenty times slower than mild*. * bobw  @xcite and ibuild  @xcite that use binary feature can be implemented in real - time , but suffering from low accuracy , which is around * 50% lower than mild*. * on the contrary , although we do not assume single loop closure in the inference stage , which potentially introduces more outliers , mild still achieves competitive performance in both accuracy and complexity , i.e. , * the accuracy is comparable to sift / surf feature based methods , and can be successfully implemented in realtime .",
    "*        .comparisons with state - of - the - art algorithms [ cols=\"^ \" , ]      + & - & - & 80% & 71% + & - & - & 460ms & 753ms + & 81% & * 89*% & * 98*% & * 95*% + & 700ms & 700ms & 100ms & 400ms + & * 86*% & 77% & 92% & 94% + & 441ms & 393ms & 69ms & 120ms + & 30.6% & 55.9% & - & - + & 20ms & 20ms & - & - + & 38% & - & 41.9% & 25.5%",
    "+ & - & - & - & - + & 83% & 87.3% & 94.5% & 93.4% + & 36ms & 35ms & 7ms & 9ms +    for memory requirement , mih takes 32 bytes to store feature descriptors and 4 bytes to store its corresponding image index and feature index in each hash table per feature .",
    "the only fixed overhead of mild is @xmath68 pointers for each hash table , where @xmath69 is the substring length . in our experiments ,",
    "@xmath70 and there are @xmath71 hash tables in total . for example , the minimum memory required for newcollege dataset is @xmath72 mb , which is acceptable for modern mobile devices .",
    "while mih has shown large potential in exactly nearest neighbor search recently @xcite , we extend its application in approximately nearest neighbor search and propose a novel multi - index hashing scheme for loop closure detection problem ( mild ) .",
    "theoretical analysis successfully reveals the trade - off between accuracy and efficiency of mih in image similarity measurement .",
    "experiments on public datasets show that mild achieves competitive performance regarding high accuracy and low complexity , compared with state - of - the - art lcd approaches .    in our work",
    ", the uniform distribution of binary codes is assumed , but in practice many features fall into the same entry in the hashing process , such entries are discarded for efficiency consideration .",
    "it would be interesting to consider prior knowledge on non - uniform distribution of different features for improving mild ."
  ],
  "abstract_text": [
    "<S> loop closure detection ( lcd ) has been proved to be extremely useful in global consistent visual simultaneously localization and mapping ( slam ) and appearance - based robot relocalization . </S>",
    "<S> methods exploiting binary features in bag of words representation have recently gained a lot of popularity for their efficiency , but suffer from low recall due to the inherent drawback that high dimensional binary feature descriptors lack well - defined centroids . in this paper </S>",
    "<S> , we propose a realtime lcd approach called mild ( multi - index hashing for loop closure detection ) , in which image similarity is measured by feature matching directly to achieve high recall without introducing extra computational complexity with the aid of multi - index hashing ( mih ) . </S>",
    "<S> a theoretical analysis of the approximate image similarity measurement using mih is presented , which reveals the trade - off between efficiency and accuracy from a probabilistic perspective . </S>",
    "<S> extensive comparisons with state - of - the - art lcd methods demonstrate the superiority of mild in both efficiency and accuracy .    </S>",
    "<S> l    place recognition , visual relocalization , loop closure detection , multi - index hashing </S>"
  ]
}