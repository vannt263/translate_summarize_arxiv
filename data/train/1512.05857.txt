{
  "article_text": [
    "index coding @xcite is often studied with the assumption that a single source has all the requested messages .",
    "we call this _ centralized _ index coding . in practice",
    ", messages may be distributed at different sources and the problem of index coding has to be solved with regards to the availability of messages at different sources .",
    "this leads to _ distributed _ index coding . in this context , this paper addressed the following question    * how does the availability of messages at distributed sources affect the solutions and achievable rates of index coding ?",
    "in addition , index coding is often studied with the assumption of a perfect ( noise - free ) unit - capacity link between a single source and receivers . in the case of multiple distributed sources",
    ", one has to take into account the transmission medium when solving the index coding problem . in this paper",
    ", we consider a semi - deterministic ( noise - free ) multiple access channel ( mac ) between distributed sources and a set of _ simultaneous _ receivers and study the following questions    * how does the transmission and scheduling in the mac affect the capacity region of index coding ? * how distributed storage can improve the capacity region of index coding ?    finally , we touch upon the impact of coded storage on the achievable rates in distributed index coding .    to the best of author",
    "s knowledge , the only other work that studies index coding with multiple sources is @xcite .",
    "however , there are four fundamental differences between our work and @xcite .",
    "firstly , the authors in @xcite assume that receivers have _ unipriors _ , which means that they only know one unique message a priori .",
    "we do not require this in our model .",
    "secondly , they assume that each receiver may require more than one message . here",
    "we assume that receiver @xmath0 requires message @xmath1 , which can be extended to more general cases .",
    "thirdly , they use a graph theoretical approach to provide bounds on the multiple source _ linear _",
    "index coding rates . here ,",
    "we do not limit ourselves to linear coding and also adopt the method of composite message encoding in @xcite to directly derive achievable rate regions .",
    "finally , the authors in @xcite assume that there are noiseless orthogonal _ bit pipes _ between each source to the receivers , which will somewhat simplify the problem .",
    "here , we do not assume such channel model and work with a mac where transmissions from sources can interfere with each other .",
    "the distributed index coding problem that we consider in this paper can have applications in wireless storage networks where _ hot content _",
    "( such as popular video ) need to be provided at high rates to a set of wireless clients who already have a priori knowledge of some video files in their caches .",
    "however , we note that the system setup in this paper is fundamentally different from recent work on coded caching @xcite in a number of ways .",
    "first , we do not optimize for the _ placement _ of messages at the end receivers under worst case unique message requests .",
    "in addition , we do not assume a single server containing all messages is involved in the _ delivery phase _",
    "thirdly , we do not consider receiver cache - size versus server delivery rate tradeoffs .",
    "consider @xmath2 distributed sources who wish to communicate @xmath3 messages , where message @xmath4 $ ] , @xmath5 $ ] , is intended for respective receiver @xmath0 . each source @xmath6 $ ] , has access to subset of messages @xmath7 , where @xmath8 $ ] with the condition that @xmath9 $ ] .",
    "each receiver @xmath10 $ ] has prior knowledge of a subset of messages @xmath11 , where @xmath12\\setminus \\{j\\}$ ] .",
    "based on available messages @xmath7 , each source @xmath13 can send a sequence of @xmath14 symbols @xmath15 over a semi - deterministic noise - less discrete memoryless mac where the channel output at time index @xmath16 solely depends on channel inputs at time @xmath16 through a known and fixed function @xmath17 , which is simultaneously received by all receivers .",
    "based on the received sequence @xmath18 , each receiver @xmath0 finds an estimate @xmath19 of the message @xmath1 .",
    "note that this distributed mac index coding problem is fully characterized by source message index sets @xmath20 , @xmath21 $ ] , receiver side information index sets @xmath22 , @xmath5 $ ] and channel function @xmath17 .",
    "we define a @xmath23 code for index coding by @xmath2 encoders of form @xmath24 and @xmath3 decoders @xmath25 .",
    "we assume that the message tuple @xmath26 is uniformly distributed over @xmath27\\times [ 1:2^{nr_2}]\\times\\cdots\\times [ 1:2^{nr_n}]$ ] .",
    "the average probability of error is defined as @xmath28 .",
    "a rate tuple @xmath29 is achievable if there exists a sequence of @xmath23 codes such that @xmath30 .",
    "the capacity region @xmath31 of the index coding problem is the closure of all achievable rate tuples @xmath29 .",
    "the goal is to find an achievable rate region of distributed index coding and the storage and transmission schemes that can achieve it .",
    "before , addressing this problem , we review some known results in the literature .      in the centralized index coding , there is a single server ( @xmath32 ) which has all messages .",
    "hence , @xmath33 $ ] .",
    "also , a noiseless unit capacity common link is assumed between the source and the receivers .",
    "the following example of centralized index coding was presented in @xcite , which will form the basis for new examples of distributed index coding discussed later in the paper .",
    "[ exmp : central:1 ] a single source has 4 messages , @xmath34 , and receiver @xmath5 $ ] wants message indexed by @xmath0 and has messages indexed by @xmath35 , @xmath36 , @xmath37 , @xmath38 , respectively , which is represented compactly as the following collection of @xmath39 @xmath40    an inner bound for the centralized index coding is shown to be achieved through _ composite - coding_. in composite - coding the single sender is replaced by @xmath41 `` virtual '' encoders , each encoding a non - empty subset @xmath42 , @xmath43 $ ] , of the message tuple @xmath44 into a composite message @xmath45 at rate @xmath46 in a `` flat '' manner ( as opposed to layered superposition coding ) .",
    "this part is referred to as dual index coding problem and its capacity region is the set of rate tuples @xmath29 that satisfy @xmath47:\\j ' \\cap \\j \\neq \\emptyset}s_{\\j'}\\end{aligned}\\ ] ] for all @xmath48 $ ] .",
    "having received all composite messages @xmath45 , @xmath43 $ ] , receiver @xmath0 can employ simultaneous non - unique decoding together with its side information to decode any subset @xmath49 of messages where the capacity region @xmath50 is defined by @xmath51 for all @xmath52 . by considering all possible message subsets @xmath49 , @xmath53:j\\in \\k_j$ ] that include the desired message @xmath0 , and all composite message indices that are relevant to the message subset @xmath49 , @xmath54 , achievability of the following rate region is argued in @xcite .",
    "[ th : centralized ] a rate tuple @xmath29 is achievable for centralized index coding problem @xmath55 if @xmath56}\\quad\\bigcup_{\\k_j\\subseteq [ 1:n]:j\\in \\k_j } \\r(\\k_j|\\a_j)\\end{aligned}\\ ] ] for some @xmath57)$ ] such that @xmath58 for all @xmath5 $ ] .",
    "[ exmp : central:1:rr ] the capacity inner bound of example [ exmp : central:1 ] is determined by setting @xmath59 and the set of constraints @xmath60 where after fourier - motzkin elimination results in @xmath61 which was shown in @xcite to be indeed tight .",
    "note that for notational convenience in examples in this paper , we replace notations of the form @xmath62 with @xmath63 .",
    "the encoding schematic is shown in fig . [",
    "fig : cent:1234 ] .",
    "the rates @xmath64 and hence sum rate of @xmath65 can be achieved by alternately encoding @xmath66 and @xmath67 , where the messages and coefficient @xmath68 are chosen from a finite field @xmath69 .",
    "the decoding is shown in fig .",
    "[ fig : cent:1234:decod ] .",
    "in this section , we propose an extension of the centralized composite - coding inner bound for distributed index coding .",
    "we highlight the main differences as we build the ingredients of the inner bound .",
    "the main difference is that each source @xmath13 has now access to only @xmath70 composite messages where @xmath71 is the size of @xmath8 $ ] .",
    "the composite messages at source @xmath13 are of the form @xmath45 corresponding to a given subset @xmath42 of the message tuple @xmath44 for @xmath72 .",
    "denote by @xmath73 , where @xmath74 is the power set of @xmath75 .",
    "then the set of all possibly computable composite messages in the network is @xmath76    each distributed source @xmath13 sends a sequence @xmath15 , which encodes composite messages @xmath45 for all @xmath72 .",
    "then @xmath18 will be simultaneously received by all receivers according to @xmath17 .",
    "let @xmath46 denote the rate with which composite message @xmath45 , @xmath77 is transmitted across the mac .",
    "a rate tuple @xmath78 is achievable if it belongs to the capacity region of this mac denoted by @xmath79 .",
    "note that when the messages of sources are overlapping , then there will be some virtual distributed encoders with identical composite messages .",
    "[ exmp : dist:14:1234:intro ] an example of virtual encoders with @xmath80 sources , @xmath81 , and @xmath82 is shown in fig .",
    "[ fig : dist:14:123 ] with @xmath83 note that @xmath84 is common between two corresponding virtual encoders at sources 1 and 2 .",
    "the rest of the coding scheme follows that of @xcite with appropriate modifications as we now show .",
    "the capacity region of distributed dual index coding problem is the set of rate tuples @xmath29 that satisfy @xmath85 for all @xmath48 $ ] .",
    "compared to , we take into account only rates @xmath46 , @xmath77 of composite messages that are possible to compute in the network .",
    "similarly , @xmath50 in should be modified as    @xmath86    for all @xmath87 . by considering all possible message subsets @xmath49 , @xmath53:j\\in \\k_j$ ] that include the desired message @xmath0 , and",
    "all possible composite message indices that are both relevant to the message subset @xmath49 and can be computed in the network , @xmath88 , the following rate region is achievable for distributed index coding .",
    "a rate tuple @xmath29 is achievable for distributed index coding problem with @xmath89 , @xmath90 , @xmath17 and mac capacity region @xmath79 if @xmath56}\\quad\\bigcup_{\\k_j\\subseteq [ 1:n]:j\\in \\k_j } \\r(\\k_j|\\a_j)\\end{aligned}\\ ] ] for some @xmath91 such that for all @xmath5 $ ] and for all @xmath92 we have @xmath93 belong to the mac capacity region @xmath79 .",
    "[ main : theorem ]",
    "to illustrate the above rate region and better understand the impact of availability of messages at distributed sources , we consider a set of examples of somewhat progressive complexity .",
    "unless otherwise stated , we consider a noiseless binary erasure mac of the form @xmath94 , where @xmath95 and summation is in real domain , the capacity region of which is well known @xcite .",
    "[ exmp : dist:12:34 ] building on example [ exmp : central:1 ] , assume the same receivers message requests and has sets and consider @xmath80 sources with @xmath96 , and @xmath97 and @xmath98 .",
    "note that there is no commonality between source messages and @xmath99 we set @xmath100 and obtain the following constraints on the index coding rates @xmath101 therefore , in theorem [ main : theorem ] , we have @xmath102 . to obtain the constraints on rates",
    "@xmath103 , we proceed as follows . for @xmath104 , excluding element @xmath105 from @xmath106 , @xmath107 , @xmath108 , @xmath109 , and @xmath110 are relevant . for @xmath111 , excluding elements @xmath112 and @xmath105 from @xmath106 , @xmath107 , @xmath113 and @xmath108 are relevant .",
    "similarly , for @xmath114 , @xmath115 and @xmath116 are relevant .",
    "finally , for @xmath117 , @xmath118 , @xmath119 and @xmath120 are relevant .",
    "hence , we obtain the following effective constraints : @xmath121 where after fourier - motzkin elimination results in @xmath122    to verify achievability , consider fig . [",
    "fig : dist:12:34:decod ] .",
    "set @xmath123 at rate @xmath124 , @xmath125 at rate @xmath126 , @xmath127 at rate @xmath128 and @xmath129 at rate @xmath130 . in channel use 1 ,",
    "receivers 1 and 2 decode @xmath131 at rate @xmath132 from @xmath133 since @xmath134 is known to them . in channel use 2 , receivers 3 and 4 decode @xmath135 and @xmath131 , respectively at rates @xmath132 from @xmath136 using their known messages .",
    "then , receiver 4 , uses @xmath131 back in @xmath137 to decode its desired message @xmath134 at rate @xmath132 .",
    "therefore , average rates of @xmath138 are achievable over two channel uses .",
    "[ exmp : dist:14:23 ] building on example [ exmp : dist:12:34 ] , consider @xmath80 sources with @xmath81 , and @xmath139 .",
    "note that there is no commonality between source messages and @xmath140 we set @xmath59 and obtain the following constraints on the index coding rates @xmath141 to obtain the constraints on rates @xmath46 , we proceed as follows . for @xmath104 ,",
    "the effective mac constraints are @xmath142 and @xmath143 . for @xmath111 , the effective mac constraints are @xmath144 and @xmath145 and so on .",
    "overall , the effective constraints are @xmath146 where after fourier - motzkin elimination results in @xmath147 as shown in fig .",
    "[ fig : dist:14:23:decod ] , average rates @xmath148 and @xmath149 are achievable by setting @xmath150 and @xmath151 , resulting in the increased sum rate of @xmath152 , compared to examples [ exmp : central:1:rr ] and [ exmp : dist:12:34 ] . ) refer to erasure block coding of message @xmath1 . ]",
    "note that the relaxed constraints on @xmath153 and @xmath154 come from the fact that receivers 2 and 3 know each other messages and hence , their presence in one source node facilitates transmission of a suitable composite message at rate @xmath151 for both receivers .",
    "[ exmp : dist:14:123 ] consider @xmath80 sources with @xmath81 , and @xmath155 .",
    "the index set of all computable composite messages is @xmath156 similar to example [ exmp : central:1:rr ] we set @xmath59 and obtain the following set of constraints @xmath157 to obtain the constraints on rates @xmath46 , we proceed as follows .",
    "first , we fix @xmath158 for all @xmath159 .",
    "since receiver 1 knows @xmath160 , the mac constraints are @xmath161 , @xmath162 and @xmath163 .",
    "note that since @xmath164 is common between both sources , the constraint @xmath165 does not apply .",
    "overall , we obtain the following effective constraints @xmath166      as shown in fig . [",
    "fig : dist:14:123:decod ] , it can be verified that when @xmath173 ( and hence @xmath174 ) , then receivers 1 , 2 , 3 , and 4 decode @xmath175 , @xmath176 , @xmath177 and @xmath178 , respectively .",
    "when @xmath179 ( and hence @xmath180 ) , then receivers 1 , 2 , 3 , and 4 decode @xmath181 , @xmath176 , @xmath182 and @xmath178 , respectively .",
    "when @xmath183 , then receivers 2 and 4 decode @xmath184 and @xmath185 , respectively .",
    "effectively , receivers 2 and 4 , can suppress unknown message @xmath131 be decoding @xmath186 from @xmath187 - which may be thought of as some form of non - unique decoding .",
    "however , when @xmath188 then @xmath189 , where @xmath190 stands for erasure .",
    "the above examples highlight the impact of distribution of messages across storage nodes on the achievable index coding rates .",
    "it is important that messages are distributed such that `` key '' composite messages can be generated and increased sum rate through mac can be fully utilized . while compared to example [ exmp : central:1:rr ]",
    ", the sum rate has increased in examples [ exmp : dist:14:23 ] and [ exmp : dist:14:123 ] due to mac and repetition ( and hence more storage cost in example [ exmp : dist:14:123 ] ) , we note that unlike centralized index coding example @xmath191 composite message @xmath192 can not be generated in the network . in the following example , we show how we can address this limitation and symmetrically increase all rates without actually increasing storage space .",
    "[ exmp : dist : striping ] consider @xmath80 sources with `` striped '' message sets @xmath193 , and @xmath194 , where @xmath195 and @xmath196 stand for parts ( halves ) 1 and 2 of each message , respectively , and @xmath197 $ ] , @xmath5 $ ] , @xmath198 with corresponding rates @xmath199 and @xmath200 . in this way , required partial composite messages @xmath201 and @xmath202 can be generated at the corresponding source @xmath13 .",
    "this is shown in fig .",
    "[ fig : dist : striping:2 ] .",
    "therefore , following similar steps as in example [ exmp : central:1:rr ] , it can be verified that @xmath203 for @xmath204 . moreover , due to mac constraints , the sum of any two inequalities one with @xmath205 and the other with @xmath206 is upper bounded by @xmath207 .",
    "crucially , we can verify that we can symmetrically achieve @xmath208 compared to example [ exmp : dist:14:123 ] , the limits of @xmath209 no longer exist .",
    "[ rem:1 ] generalizing the above example , we make an important observation .",
    "for @xmath2 sources and @xmath3 messages , `` striping '' or dividing all messages to @xmath2 sub - messages and storing each striped set at one source will ensure that all striped composite messages are computable in the network . assuming a symmetric mac ( such as the considered binary erasure mac ) , if sum rate @xmath210 is achievable in the centralized index coding problem with capacity link @xmath211 , then @xmath212};y)$ ] is achievable in the distributed case .",
    "this separable or multiplicative rate region expansion of striped storage means that there will be no loss in index coding rate region due to distributed storage .",
    "nevertheless , there may be diminishing returns in increasing @xmath2 to the saturation of mac capacity .",
    "for example , by increasing @xmath213 and striping messages into three parts , the sum rate increases to @xmath214 ; around 20% increase compared to @xmath80 .",
    "[ exmp : dist : mds:3:2 ] building on example [ exmp : dist : striping ] , consider @xmath213 sources with @xmath193 , and @xmath194 and a `` coded '' source which has access to two `` precoded '' composite messages of the form @xmath215 for @xmath216 and two precoded messages of the form @xmath217 for @xmath216 . in other words ,",
    "coded storage has access to pre - coded forms of @xmath218 and @xmath219 , where superscript @xmath220 stands for precoded composite message .",
    "the messages and coefficients are chosen from a finite field @xmath69 such that the three sources constitute a ( 3,2 ) mds code which can tolerate any one source failure .",
    "a schematic of source messages is shown in fig .",
    "[ fig : dist : mds:2 ] .    denoting by @xmath221 , @xmath222 partial composite messages that can be computed at sources @xmath205 and @xmath206 , the essential dual index coding constraints are @xmath223 and",
    "the set of mac inequalities are @xmath224 where after fourier - motzkin elimination results in @xmath225 therefore , this example shows that the sum rate of @xmath226 is possible as it is with normal striping of messages into @xmath213 under remark [ rem:1 ] , but with the added advantage of resilience to one source node failure .",
    "the symmetric rates @xmath227 can be achieved if striped sources @xmath204 send striped composite messages @xmath228 and @xmath229 alternately and the coded source @xmath230 sends it 4 pre - coded messages @xmath231 and @xmath232 for @xmath233 or @xmath234 alternately .",
    "s.  e. rouayheb , a.  sprintson , and c.  georghiades , `` on the index coding problem and its relation to network coding and matroid theory , '' _ ieee trans . on inf .",
    "56 , no .  7 , pp . 31873195 , jul .",
    "l.  ong , c.  k. ho , and f.  lim , `` the single - uniprior index - coding problem : the single - sender case and the multi - sender extension . ''",
    "[ online ] .",
    "available : \\url{http://arxiv:1412.1520v1}[\\url\\{http://arxiv:1412.1520v1 } ]"
  ],
  "abstract_text": [
    "<S> index coding is often studied with the assumption that a single source has all the messages requested by the receivers . </S>",
    "<S> we refer to this as _ centralized _ index coding . </S>",
    "<S> in contrast , this paper focuses on _ distributed _ index coding and addresses the following question : how does the availability of messages at distributed sources ( storage nodes ) affect the solutions and achievable rates of index coding ? </S>",
    "<S> an extension to the work of arbabjolfaei et al . in isit 2013 </S>",
    "<S> is presented when distributed sources communicate via a semi - deterministic multiple access channel ( mac ) to simultaneous receivers . </S>",
    "<S> a numbers of examples are discussed that show the effect of message distribution and redundancy across the network on achievable rates of index coding and motivate future research on designing practical network storage codes that offer high index coding rates . </S>"
  ]
}