{
  "article_text": [
    "evaluation of marginal likelihood integrals is central to bayesian statistics .",
    "it is generally assumed that these integrals can not be evaluated exactly , except in trivial cases , and a wide range of numerical techniques ( e.g.  mcmc ) have been developed to obtain asymptotics and numerical approximations @xcite .",
    "the aim of this paper is to show that exact integration is more feasible than is surmised in the literature .",
    "we examine marginal likelihood integrals for a class of mixture models for discrete data .",
    "bayesian inference for these models arises in many contexts , including machine learning and computational biology .",
    "recent work in these fields has made a connection to singularities in algebraic geometry @xcite .",
    "our study augments these developments by providing tools for symbolic integration when the sample size is small .",
    "the numerical value of the integral we have in mind is a rational number , and exact evaluation means computing that rational number rather than a floating point approximation . for a first example",
    "consider the integral @xmath0 where @xmath1 is the @xmath2-dimensional polytope @xmath3 .",
    "the factors are probability simplices , i.e. @xmath4 and we integrate with respect to lebesgue probability measure on @xmath1 .",
    "if we take the exponents @xmath5 to be the entries of the particular contingency table @xmath6 then the exact value of the integral ( [ swissintegral ] ) is the rational number @xmath7 the particular table ( [ swisstable ] ) is taken from ( * ? ? ?",
    "* example 1.3 ) , where the integrand @xmath8 was studied using the em algorithm , and the problem of validating its global maximum over @xmath1 was raised .",
    "see @xcite and @xcite for further discussions . that optimization problem , which was widely known as the _ @xmath9",
    "swiss francs problem _ , has in the meantime been solved by gao , jiang and zhu @xcite .",
    "the main difficulty in performing computations such as ( [ swissintegral ] ) = ( [ swissnumber ] ) lies in the fact that the expansion of the integrand has many terms .",
    "a first naive upper bound on the number of monomials in the expansion of ( [ swissintegrand ] ) would be @xmath10 however , the true number of monomials is only @xmath11 , and we obtain the rational number ( [ swissnumber ] ) by summing the values of the corresponding integrals @xmath12 the geometric idea behind our approach is that the newton polytope of ( [ swissintegrand ] ) is a _ zonotope _ and we are summing over the lattice points in that zonotope .",
    "definitions for these geometric objects are given in section 3 .",
    "this paper is organized as follows . in section 2",
    "we describe the class of algebraic statistical models to which our method applies , and we specify the problem . in section 3 we examine the newton zonotopes of mixture models , and we derive formulas for marginal likelihood evaluation using tools from geometric combinatorics . our algorithms and their implementations are described in detail in section 4 .",
    "section 5 is concerned with applications in bayesian statistics .",
    "we show how _ dirichlet priors _ can be incorporated into our approach , we discuss the evaluation of _ bayes factors _ , we compare our setup with that of chickering and heckerman in  @xcite , and we illustrate the scope of our methods by computing an integral arising from a data set in @xcite .    a preliminary draft version of the present article was published as section 5.2 of the oberwolfach lecture notes @xcite .",
    "we refer to that volume for further information on the use of computational algebra in bayesian statistics .",
    "we consider a collection of discrete random variables @xmath13 where @xmath14 are identically distributed with values in @xmath15 .",
    "the independence model @xmath16 for these variables is a toric model @xcite represented by an integer @xmath17-matrix @xmath18 with @xmath19 the columns of the matrix @xmath18 are indexed by elements @xmath20 of the state space @xmath21 the rows of the matrix @xmath18 are indexed by the model parameters , which are the @xmath22 coordinates of the points @xmath23 in the polytope @xmath24 and the model @xmath16 is the subset of the simplex @xmath25 given parametrically by @xmath26 this is a monomial in @xmath22 unknowns .",
    "the matrix @xmath18 is defined by taking its column @xmath27 to be the exponent vector of this monomial .    in algebraic geometry ,",
    "the model @xmath16 is known as _ segre - veronese variety _",
    "@xmath28 where the embedding is given by the line bundle @xmath29 .",
    "the manifold @xmath16 is the toric variety of the polytope @xmath30 .",
    "both objects have dimension @xmath31 , and they are identified with each other via the moment map @xcite .    consider three binary random variables where the last two random variables are identically distributed . in our notation , this corresponds to @xmath32 , @xmath33 , @xmath34 and @xmath35 .",
    "we find that @xmath36 , and @xmath37 the columns of this matrix represent the monomials in the parametrization ( [ parametrization ] ) .",
    "the model @xmath16 lies in the @xmath38-dimensional subsimplex of @xmath39 given by @xmath40 and @xmath41 , and it consists of all rank one matrices @xmath42 in algebraic geometry , the surface @xmath16 is called a _",
    "rational normal scroll_.    the matrix @xmath18 has repeated columns whenever @xmath43 for some @xmath44 .",
    "it is sometimes convenient to represent the model @xmath16 by the matrix @xmath45 which is obtained from @xmath18 by removing repeated columns .",
    "we label the columns of the matrix @xmath45 by elements @xmath46 of ( [ statespace ] ) whose components @xmath47 are weakly increasing .",
    "hence @xmath45 is a @xmath48-matrix with @xmath49 the model @xmath16 and its mixtures are subsets of a subsimplex @xmath50 of @xmath25 .",
    "we now introduce _ marginal likelihood integrals_. all our domains of integration in this paper are polytopes that are products of standard probability simplices . on each such polytope",
    "we fix the standard lebesgue probability measure . in other words",
    ", our discussion of bayesian inference refers to the uniform prior on each parameter space .",
    "naturally , other prior distributions , such as dirichlet priors , are of interest , and our methods are extended to these in section 5 . in what follows",
    ", we simply work with uniform priors .",
    "we identify the state space ( [ statespace ] ) with the set @xmath51 .",
    "a _ data vector _",
    "@xmath52 is thus an element of @xmath53 .",
    "the _ sample size _ of these data is @xmath54 .",
    "if the sample size @xmath55 is fixed then the probability of observing these data is @xmath56 this expression is a function on the polytope @xmath30 which is known as the _ likelihood function _ of the data @xmath57 with respect to the independence model @xmath16 .",
    "the _ marginal likelihood _ of the data @xmath57 with respect to the model @xmath16 equals @xmath58 the value of this integral is a rational number which we now compute explicitly . the data @xmath57 will enter this calculation by way of the _ sufficient statistic _",
    "@xmath59 , which is a vector in @xmath60 .",
    "the coordinates of this vector are denoted @xmath61 for @xmath62 and @xmath63 .",
    "thus @xmath61 is the total number of times the value @xmath64 is attained by one of the random variables @xmath65 in the @xmath44-th group .",
    "clearly , the sufficient statistics satisfy @xmath66 the likelihood function @xmath67 is the constant @xmath68 times the monomial @xmath69 the logarithm of this function is concave on the polytope @xmath30 , and its maximum value is attained at the point @xmath70 with coordinates @xmath71 .",
    "[ toricintegral ] the integral of the monomial @xmath72 over the polytope @xmath30 equals @xmath73 the product of this number with the multinomial coefficient @xmath74 equals the marginal likelihood of the data @xmath57 for the independence model @xmath16 .",
    "since @xmath30 is the product of simplices ( [ prodofsimp ] ) , this follows from the formula @xmath75 for the integral of a monomial over the standard probability simplex @xmath76 .",
    "our objective is to compute marginal likelihood integrals for the mixture model @xmath77 .",
    "the natural parameter space of this model is the polytope @xmath78 let @xmath79 be the column vector of @xmath18 indexed by the state @xmath20 , which is either in ( [ statespace ] ) or in @xmath80 .",
    "the parametrization ( [ parametrization ] ) can be written simply as @xmath81 .",
    "the mixture model @xmath77 is defined to be the subset of @xmath25 with the parametric representation @xmath82 the likelihood function of a data vector @xmath83 for the model @xmath77 equals @xmath84 the _ marginal likelihood _ of the data @xmath57 with respect to the model @xmath77 equals @xmath85 the following proposition shows that we can evaluate this integral _ exactly_.    [ pr : rational ] the marginal likelihood ( [ marginallikelihood2 ] ) is a rational number .",
    "the likelihood function @xmath86 is a @xmath87-linear combination of monomials @xmath88 .",
    "the integral ( [ marginallikelihood2 ] ) is the same @xmath87-linear combination of the numbers @xmath89 each of the three factors is an easy - to - evaluate rational number , by ( [ gammaproduct ] ) .",
    "the integral ( [ swissintegral ] ) expresses the marginal likelihood of a @xmath90-table of counts @xmath91 with respect to the mixture model @xmath77 .",
    "specifically , the marginal likelihood of the data ( [ swisstable ] ) equals the normalizing constant @xmath92 times the number ( [ swissnumber ] ) .",
    "the model @xmath77 consists of all non - negative @xmath90-matrices of rank @xmath93 whose entries sum to one . here",
    "the parametrization ( [ mixturepara ] ) is not identifiable because @xmath94 but @xmath95 . in this example , @xmath96 , @xmath97 , @xmath98 , @xmath99 , @xmath100 .    in algebraic geometry , the model @xmath77 is known as the first secant variety of the segre - veronese variety ( [ segreveronese ] ) .",
    "we could also consider the higher secant varieties @xmath101 , which correspond to mixtures of @xmath102 independent distributions , and much of our analysis can be extended to that case , but for simplicity we restrict ourselves to @xmath103 .",
    "the variety @xmath77 is embedded in the projective space @xmath104 with @xmath105 as in ( [ nprime ] ) .",
    "note that @xmath105 can be much smaller than @xmath106 .",
    "if this is the case then it is convenient to aggregate states whose probabilities are identical and to represent the data by a vector @xmath107 .",
    "here is an example .",
    "[ cointoss ] let @xmath108 , @xmath109 and @xmath110 , so @xmath16 is the independence model for four identically distributed binary random variables . then @xmath111 and @xmath100 . the corresponding integer matrix and",
    "its row and column labels are @xmath112 however , this matrix has only @xmath113 distinct columns , and we instead use @xmath114 the mixture model @xmath77 is the subset of @xmath115 given by the parametrization @xmath116 in algebraic geometry , this threefold is the secant variety of the rational normal curve in @xmath117 .",
    "this is the cubic hypersurface with the implicit equation @xmath118 in ( * ? ? ?",
    "* example 9 ) the likelihood function ( [ likelihoodfunction2 ] ) was studied for the data vector @xmath119 it has three local maxima ( modulo swapping @xmath120 and @xmath121 ) whose coordinates are algebraic numbers of degree @xmath122 .",
    "using the methods to be described in the next two sections , we computed the exact value of the marginal likelihood for the data @xmath123 with respect to @xmath77 . the rational number ( [ marginallikelihood2 ] ) is found to be the ratio of two relatively prime integers having @xmath124 digits and @xmath125 digits , and its numerical value is approximately @xmath126 .",
    "our starting point is the observation that the newton polytope of the likelihood function ( [ likelihoodfunction2 ] ) is a zonotope .",
    "recall that the _ newton polytope _ of a polynomial is the convex hull of all exponent vectors appearing in the expansion of that polynomial , and a polytope is a _ zonotope _ if it is the image of a standard cube under a linear map .",
    "see @xcite and @xcite for further discussions .",
    "we are here considering the zonotope @xmath127,\\ ] ] where @xmath128 $ ] represents the line segment between the origin and the point @xmath129 , and the sum is a minkowski sum of line segments .",
    "we write @xmath130 for the basic zonotope which is spanned by the vectors @xmath27 .",
    "hence @xmath131 is obtained by stretching @xmath132 along those vectors by factors @xmath133 respectively . assuming that the counts @xmath133 are all positive , we have @xmath134 the zonotope @xmath132 is related to the polytope @xmath135 in ( [ prodofsimp ] ) as follows .",
    "the dimension @xmath136 of @xmath30 is one less than @xmath137 , and @xmath30 appears as the _ vertex figure _ of the zonotope @xmath132 at the distinguished vertex  @xmath138 .    for higher mixtures @xmath101 ,",
    "the newton polytope of the likelihood function is isomorphic to the minkowski sum of @xmath139-dimensional simplices in @xmath140 . only when @xmath141 , this minkowski sum is a zonotope .",
    "the marginal likelihood ( [ marginallikelihood2 ] ) we wish to compute is the integral @xmath142 times the constant @xmath143 .",
    "our approach to this computation is to sum over the lattice points in the zonotope @xmath131 .",
    "if the matrix @xmath18 has repeated columns , we may replace @xmath18 with the reduced matrix @xmath144 and @xmath57 with the corresponding reduced data vector @xmath145 .",
    "if one desires the marginal likelihood for the reduced data vector @xmath145 instead of the original data vector @xmath57 , the integral remains the same while the normalizing constant becomes @xmath146 where @xmath147 is the number of columns in @xmath18 equal to the @xmath44-th column of @xmath144 . in what follows",
    "we ignore the normalizing constant and focus on computing the integral ( [ sec3integral ] ) with respect to the original matrix @xmath18 .    for a vector @xmath148",
    "we let @xmath149 denote its @xmath150-norm @xmath151 .",
    "recall from ( [ parametrization ] ) that all columns of the @xmath17-matrix @xmath18 have the same coordinate sum @xmath152 and from ( [ vectorcomponent ] ) that we may denote the entries of a vector @xmath153 by @xmath154 for @xmath155 and @xmath156 .",
    "also , let @xmath157 denote the image of the linear map @xmath158 .",
    "thus @xmath157 is a sublattice of rank @xmath159 in @xmath160 .",
    "we abbreviate @xmath161 . now , using the binomial theorem , we have @xmath162 therefore , in the expansion of the integrand in ( [ sec3integral ] ) , the exponents of @xmath120 are of the form of @xmath163 .",
    "the other exponents may be expressed in terms of @xmath164 .",
    "this gives us @xmath165 writing @xmath166 , we can see that the coefficient in ( [ integrandexpansion ] ) equals @xmath167 thus , by formulas ( [ gammaproduct ] ) and ( [ integrandexpansion ] ) , the integral ( [ sec3integral ] ) evaluates to @xmath168 we summarize the result of this derivation in the following theorem .",
    "[ thm : formula ] the marginal likelihood of the data @xmath57 in the mixture model @xmath169 is equal to the sum ( [ eq : sum ] ) times the normalizing constant @xmath143 .",
    "each individual summand in the formula ( [ eq : sum ] ) is a ratio of factorials and hence can be evaluated symbolically .",
    "the challenge in turning theorem [ thm : formula ] into a practical algorithm lies in the fact that both of the sums ( [ sumproduct ] ) and ( [ eq : sum ] ) are over very large sets .",
    "we shall discuss these challenges and present techniques from both computer science and mathematics for addressing them .",
    "we first turn our attention to the coefficients @xmath170 of the expansion ( [ integrandexpansion ] ) .",
    "these quantities are written as an explicit sum in ( [ sumproduct ] ) .",
    "the first useful observation is that these coefficients are also the coefficients of the expansion @xmath171 which comes from substituting @xmath172 and @xmath173 in ( [ integrandexpansion ] ) .",
    "when the cardinality of @xmath174 is sufficiently small , the quantity @xmath170 can be computed quickly by expanding ( [ expansion ] ) using a computer algebra system .",
    "we used maple for this purpose and all other symbolic computations in this project .",
    "if the expansion ( [ expansion ] ) is not feasible , then it is tempting to compute the individual @xmath170 via the sum - product formula ( [ sumproduct ] ) .",
    "this method requires summation over the set @xmath175 , which is the set of lattice points in an @xmath176-dimensional polytope .",
    "even if this loop can be implemented , performing the sum in ( [ sumproduct ] ) symbolically requires the evaluation of many large binomials , which causes the process to be rather inefficient .",
    "an alternative is offered by the following recurrence formula : @xmath177 this is equivalent to writing the integrand in ( [ sec3integral ] )  as @xmath178 more generally , for each @xmath179 , we have the recurrence @xmath180 where @xmath181 and @xmath182 consist of the first @xmath44 columns and entries of @xmath18 and @xmath57 respectively .",
    "this corresponds to the factorization @xmath183 this formula gives flexibility in designing algorithms with different payoffs in time and space complexity , to be discussed in section 4 .",
    "the next result records useful facts about the quantities @xmath170 .    [ pr:3 ]",
    "suppose @xmath184 and @xmath185 .",
    "then , the following quantities are all equal to @xmath170 : + ( 1 ) @xmath186 where @xmath187 is the extended matrix @xmath188 ( 2 ) @xmath189 , + ( 3 ) @xmath190 where @xmath191 and @xmath192 .",
    "\\(1 ) this follows directly from ( [ expansion ] ) .",
    "\\(2 ) for each @xmath193 satisfying @xmath194 , note that @xmath195 satisfies @xmath196 , and vice versa .",
    "the conclusion thus follows from ( 1 ) .",
    "\\(3 ) we require @xmath197 and @xmath198 . if @xmath199 then @xmath200 , which implies @xmath201 .",
    "the lower bound is derived by a similar argument .",
    "one aspect of our approach is the decision , for any given model @xmath18 and data set @xmath57 , whether or not to attempt the expansion ( [ expansion ] ) using computer algebra .",
    "this decision depends on the cardinality of the set @xmath202 . in what follows ,",
    "we compute the number exactly when @xmath18 is unimodular . when @xmath18 is not unimodular , we obtain useful lower and upper bounds for @xmath203 .",
    "let @xmath204 be any subset of the columns of @xmath18 .",
    "we call @xmath204 _ independent _ if its elements are linearly independent in @xmath205 . with @xmath204",
    "we associate the integer @xmath206.\\ ] ] this is the index of the abelian group generated by @xmath204 inside the possibly larger abelian group of all lattice points in @xmath207 that lie in the span of @xmath204 .",
    "the following formula is due to r.  stanley and appears in ( * ? ? ?",
    "* theorem 2.2 ) :    the number of lattice points in the zonotope @xmath131 equals @xmath208    in fact , the number of monomials in ( [ integrandexpansion ] ) equals @xmath209 , where @xmath210 is the set @xmath211 , and this set can be different from @xmath212 .",
    "for that number we have the following upper and lower bounds .",
    "the proof of theorem [ thm : uplow ] will be omitted here .",
    "it uses the methods in @xcite .",
    "[ thm : uplow ] the number @xmath209 of monomials in the expansion ( [ integrandexpansion ] ) of the likelihood function to be integrated satisfies the two inequalities @xmath213    by definition , the matrix @xmath18 is _ unimodular _ if @xmath214 for all independent subsets @xmath204 of the columns of @xmath18 . in this case , the upper bound coincides with the lower bound , and so @xmath215 .",
    "this happens in the classical case of two - dimensional contingency tables ( @xmath32 and @xmath216 ) . in general",
    ", @xmath217 tends to @xmath218 when all coordinates of @xmath57 tend to infinity .",
    "this is why we believe that @xmath219 is a good approximation of @xmath209 . for computational purposes",
    ", it suffices to know @xmath220 .",
    "there exist integer matrices @xmath18 for which @xmath221 does not agree with the upper bound in theorem [ thm : uplow ] .",
    "however , we conjecture that @xmath222 holds for matrices @xmath18 of segre - veronese type as in ( [ parametrization ] ) and strictly positive data vectors @xmath57 .",
    "consider the _",
    "@xmath9 swiss francs _ example in section [ introduction ] . here",
    "@xmath18 is unimodular and it has @xmath223 independent subsets @xmath204 .",
    "the corresponding sum of @xmath223 squarefree monomials in ( [ zonotopedimension ] ) gives the number of terms in the expansion of ( [ swissintegrand ] ) .",
    "for the data @xmath57 in ( [ swisstable ] ) this sum evaluates to @xmath224 .",
    "we consider the matrix and data from example [ cointoss ] .",
    "@xmath225 by theorem [ thm : uplow ] , the lower bound is 22,273 and the upper bound is 48,646 . here",
    "the number @xmath226 of monomials agrees with the latter .",
    "we next present a formula for @xmath227 when @xmath204 is any linearly independent subset of the columns of the matrix @xmath18 .",
    "after relabeling we may assume that @xmath228 consists of the first @xmath229 columns of @xmath18 .",
    "let @xmath230 denote the row hermite normal form of @xmath18 . here",
    "@xmath231 and @xmath232 satisfies @xmath233 hermite normal form is a built - in function in computer algebra systems .",
    "for instance , in maple the command is ihermite . using the invertible matrix @xmath234",
    ", we may replace @xmath18 with @xmath232 , so that @xmath235 becomes @xmath236 and @xmath237 is the image over @xmath238 of the upper left @xmath239-submatrix of @xmath232 .",
    "we seek the index of that lattice in the possibly larger lattice @xmath240 . to this end",
    "we compute the column hermite normal form @xmath241 . here",
    "@xmath242 and @xmath243 satisfies @xmath244 the lattice @xmath245 is spanned by the first @xmath229 columns of @xmath243 , and this implies @xmath246",
    "in this section we discuss algorithms for computing the integral ( [ sec3integral ] ) exactly , and we discuss their advantages and limitations . in particular , we examine four main techniques which represent the formulas ( [ eq : sum ] ) , ( [ expansion ] ) , ( [ zonotopedim ] ) and ( [ eq : recurrence ] ) respectively .",
    "the practical performance of the various algorithms is compared by computing the integral in example [ cointoss ] .    a maple library which implements our algorithms",
    "is made available at @xmath247 the input for our maple code consists of parameter vectors @xmath248 and @xmath249 as well as a data vector @xmath83 .",
    "this input uniquely specifies the @xmath17-matrix @xmath18 . here",
    "@xmath22 and @xmath250 are as in ( [ defdn ] ) .",
    "the output features the matrices @xmath18 and @xmath251 , the marginal likelihood integrals for @xmath16 and @xmath77 , as well as the bounds in ( [ eq : uplow ] ) .",
    "we tacitly assume that @xmath18 has been replaced with the reduced matrix @xmath251 .",
    "thus from now on we assume that @xmath18 has no repeated columns .",
    "this requires some care concerning the normalizing constants .",
    "all columns of the matrix @xmath18 have the same coordinate sum @xmath252 , and the convex hull of the columns is the polytope @xmath253 .",
    "our domain of integration is the following polytope of dimension @xmath254 : @xmath255 we seek to compute the rational number @xmath256 where integration is with respect to lebesgue probability measure .",
    "our maple code outputs this integral multiplied with the statistically correct normalizing constant .",
    "that constant will be ignored in what follows . in our complexity analysis ,",
    "we fix @xmath18 while allowing the data @xmath57 to vary .",
    "the complexities will be given in terms of the sample size @xmath257 .",
    "given an integration problem such as ( [ sec4integral ] ) , a first attempt is to use the symbolic integration capabilities of a computer algebra package such as maple .",
    "we will refer to this method as _ ignorant integration _ :    .... u   : = [ 51 , 18 , 73 , 25 , 75 ] : f   : = ( s*t^4         + ( 1-s)*p^4         ) ^u[1 ] *        ( s*t^3*(1-t )   + ( 1-s)*p^3*(1-p )   ) ^u[2 ] *        ( s*t^2*(1-t)^2+(1-s)*p^2*(1-p)^2)^u[3 ] *        ( s*t   * ( 1-t)^3+(1-s)*p   * ( 1-p)^3)^u[4 ] *        ( s     * ( 1-t)^4+(1-s )     * ( 1-p)^4)^u[5 ] : ii : = int(int(int(f , p=0 .. 1),t=0 .. 1),s=0 .. 1 ) ; ....    in the case of mixture models , recognizing the integral as the sum of integrals of monomials over a polytope allows us to avoid the expensive integration step above by using ( [ eq : sum ] ) . to demonstrate the power of using ( [ eq : sum ] ) , we implemented a simple algorithm that computes each @xmath170 using the naive expansion in ( [ sumproduct ] ) .",
    "we computed the integral in example [ cointoss ] with a small data vector @xmath258 , which is the rational number @xmath259 and summarize the run - times and memory usages of the two algorithms in the table below .",
    "all experiments reported in this section are done in maple .",
    "r c c & time(seconds ) & memory(bytes ) + ignorant integration & 16.331 & 155,947,120 + naive expansion & 0.007 & 458,668 +    for the remaining comparisons in this section , we no longer consider the ignorant integration algorithm because it is computationally too expensive .",
    "while ignorant use of a computer algebra system is unsuitable for computing our integrals , we can still exploit its powerful polynomial expansion capabilities to find the coefficients of ( [ expansion ] ) .",
    "a major advantage is that it is very easy to write code for this method .",
    "we compare the performance of this symbolic expansion algorithm against that of the naive expansion algorithm .",
    "the table below concerns computing the coefficients @xmath170 for the original data @xmath260 .",
    "the column `` extract '' refers to the time taken to extract the coefficients @xmath170 from the expansion of the polynomial , while the column `` sum '' shows the time taken to evaluate ( [ eq : sum ] ) after all the needed values of @xmath170 had been computed and extracted .",
    "r c c c c c & & memory + & @xmath170 & extract & sum & total & ( bytes ) + naive expansion & 2764.35 & - & 31.19 & 2795.54 & 10,287,268 + symbolic expansion & 28.73 & 962.86 & 29.44 & 1021.03 & 66,965,528 +      symbolic expansion is fast for computing @xmath170 , but it has two drawbacks : high memory consumption and the long time it takes to extract the values of @xmath170 .",
    "one solution is to create specialized data structures and algorithms for expanding ( [ expansion ] ) , rather using than those offered by maple .",
    "first , we tackle the problem of storing the coefficients @xmath170 for @xmath261 as they are being computed .",
    "one naive method is to use a @xmath22-dimensional array @xmath262 $ ] .",
    "however , noting that @xmath18 is not row rank full , we can use a @xmath263-dimensional array to store @xmath170 , where @xmath264 .",
    "furthermore , by proposition [ pr:3](2 ) , the expanded integrand is a symmetric polynomial , so only half the coefficients need to be stored .",
    "we will leave out the implementation details so as not to complicate our discussions . in our algorithms",
    ", we will assume that the coefficients are stored in a @xmath263-dimensional array @xmath262 $ ] , and the entry that represents @xmath170 will be referred to as @xmath265 $ ] .",
    "next , we discuss how @xmath170 can be computed",
    ". one could use the naive expansion ( [ sumproduct ] ) , but this involves evaluating many binomials coefficients and products , so the algorithm is inefficient for data vectors with large coordinates . a much more efficient solution uses the recurrence formula ( [ eq : recurrence ] ) :    [ al:41 ] @xmath266 + * input : * the matrix @xmath18 and the vector @xmath57 . + * output : * the coefficients @xmath170 .",
    "+ * step 1 * : create a @xmath263-dimensional array @xmath267 of zeros .",
    "+ * step 2 * : for each @xmath268 set @xmath269\\,\\,\\,:=\\,\\,\\ , \\binom{u_1}{x}.\\ ] ] * step 3 * : create a new @xmath263-dimensional array @xmath270 . + * step 4 * : for each @xmath271 do    \\1 . set all the entries of @xmath270 to @xmath138 .",
    "\\2 . for each @xmath272",
    "do    for each non - zero entry @xmath265 $ ] in @xmath267 do    increment @xmath273 $ ] by @xmath274.$ ]    \\3 .",
    "replace @xmath267 with @xmath270 . +",
    "* step 5 * : output the array @xmath267 .",
    "the space complexity of this algorithm is @xmath275 and its time complexity is @xmath276 . by comparison",
    ", the naive expansion algorithm has space complexity @xmath277 and time complexity @xmath278 .",
    "we now turn our attention to computing the integral ( [ sec4integral ] ) .",
    "one major issue is the lack of memory to store all the terms of the expansion of the integrand .",
    "we overcome this problem by writing the integrand as a product of smaller factors which can be expanded separately .",
    "in particular , we partition the columns of @xmath18 into submatrices @xmath279 } , \\ldots , a^{[m]}$ ] and let @xmath280 } , \\ldots , u^{[m]}$ ] be the corresponding partition of @xmath57 .",
    "thus the integrand becomes @xmath281}_v } + \\sigma_1 \\rho^{a^{[j]}_v})^{u^{[j]}_v } , \\ ] ] where @xmath282}_v$ ] is the @xmath20th column in the matrix @xmath283}$ ] .",
    "the resulting algorithm for evaluating the integral is as follows :    [ fastt ] @xmath266 + * input : * the matrices @xmath279 } , \\ldots , a^{[m]}$ ] , vectors @xmath280 } , \\ldots , u^{[m]}$ ] and the vector @xmath284 . + * output : * the value of the integral ( [ sec4integral ] ) in exact rational arithmetic . + * step 1 * : for @xmath285 , compute @xmath286}:={\\rm recurrence}(a^{[j]},u^{[j]})$ ] . + * step 2 * : set @xmath287 .",
    "+ * step 3 * : for each non - zero entry @xmath288}[b^{[1]}]$ ] in @xmath288}$ ] do    @xmath289 + for each non - zero entry @xmath290}[b^{[m]}]$ ] in @xmath290}$ ] do    set @xmath291 } + \\cdots + b^{[m]}$ ] , @xmath292 , @xmath293}[b^{[j]}]$ ]",
    ".    increment @xmath294 by    @xmath295 + * step 4 * : output the sum @xmath294 .    the algorithm can be sped up by precomputing the factorials used in the product in step 3 .",
    "the space and time complexity of this algorithm is @xmath296 and @xmath297 respectively , where @xmath298}$ ] and @xmath299}$ ] . from this",
    ", we see that the splitting of the integrand should be chosen wisely to achieve a good pay - off between the two complexities .    in the table below , we compare the naive expansion algorithm and the fast integral algorithm for the data @xmath300 .",
    "we also compare the effect of splitting the integrand into two factors , as denoted by @xmath301 and @xmath302 . for @xmath301 ,",
    "the fast integral algorithm takes significantly less time than naive expansion , and requires only about 1.5 times more memory .",
    "r c c & time(minutes ) & memory(bytes ) + naive expansion & 43.67 & 9,173,360 + fast integral ( m=1 ) & 1.76 & 13,497,944 + fast integral ( m=2 ) & 139.47 & 6,355,828 +      while our algorithms are optimized for exact evaluation of integrals for mixtures of independence models , they may not be practical for applications involving large sample sizes .",
    "to demonstrate their limitations , we vary the sample sizes in example [ cointoss ] and compare the computation times .",
    "the data vectors @xmath57 are generated by scaling @xmath303 according to the sample size @xmath55 and rounding off the entries .",
    "here , @xmath55 is varied from @xmath304 to @xmath305 by increments of @xmath306 .",
    "figure [ graph1 ] shows a logarithmic plot of the results .",
    "the times taken for @xmath307 and @xmath308 are @xmath309 and @xmath310 seconds respectively .",
    "computation times for larger samples may be extrapolated from the graph .",
    "indeed , a sample size of @xmath311 could take more than @xmath2 days .        for other models , such as the _",
    "@xmath9 swiss francs _ example in section 1 and that of the schizophrenic patients in example [ schizoex ] , the limitations are even more apparent . in the table below , for each example we list the sample size , computation time , rank of the corresponding @xmath18-matrix and the number of terms in the expansion of the integrand .",
    "despite having smaller sample sizes , the computations for the latter two examples take a lot more time .",
    "this may be attributed to the higher ranks of the @xmath18-matrices and the larger number of terms that need to be summed up in our algorithm .",
    "r c c c c & size & time & rank & # terms + coin toss & 242 & 45 sec & 2 & 48,646 + @xmath9 swiss francs & 40 & 15 hrs & 7 & 3,892,097 + schizophrenic patients & 132 & 16 days & 5 & 34,177,836 +    despite their high complexities , we believe our algorithms are important because they provide a gold standard with which approximation methods such as those studied in @xcite can be compared .",
    "below , we use our exact methods to ascertain the accuracy of asymptotic formula derived by watanabe _",
    "et al . _  using desingularization methods from algebraic geometry @xcite .",
    "consider the model from example [ cointoss ] .",
    "choose data vectors @xmath312 with @xmath313 where @xmath55 is a multiple of @xmath314 and @xmath315 let @xmath316 be the integral ( [ sec4integral ] ) .",
    "define @xmath317 according to @xcite , for large @xmath55 we have the asymptotics @xmath318 \\,\\,\\ , = \\,\\,\\",
    ", \\frac{3}{4 } \\log n + o(1)\\end{aligned}\\ ] ] where the expectation @xmath319 is taken over all @xmath57 with sample size @xmath55 under the distribution defined by @xmath320 .",
    "thus , we should expect @xmath321 we compute @xmath322 using our exact methods and list the results below .    [ cols=\"^,^,^\",options=\"header \" , ]     clearly , the table supports our conclusion .",
    "the coefficient @xmath323 of @xmath324 in the formula ( [ coinflipasymp ] ) is known as the _ real log - canonical threshold _ of the statistical model .",
    "the example suggests that our method could be developed into a numerical technique for computing the real log - canonical threshold .",
    "in this section we discuss how the exact integration approach presented here interfaces with issues in bayesian statistics .",
    "the first concerns the rather restrictive assumption that our marginal likelihood integral be evaluated with respect to the uniform distribution ( lesbegue measure ) on the parameter space @xmath1 .",
    "it is standard practice to compute such integrals with respect to _ dirichlet priors _ , and we shall now explain how our algorithms can be extended to dirichlet priors .",
    "that extension is also available as a feature in our maple implementation .",
    "recall that the _ dirichlet distribution _",
    "@xmath325 is a continuous probability distribution which is parametrized by a vector @xmath326 of positive reals .",
    "it is the multivariate generalization of the beta distribution and is conjugate prior ( in the bayesian sense ) to the multinomial distribution .",
    "this means that the probability distribution function of @xmath327 specifies the belief that the probability of the @xmath44th among @xmath328 events equals @xmath329 given that it has been observed @xmath330 times .",
    "more precisely , the probability density function @xmath331 of @xmath327 is supported on the @xmath332-dimensional simplex @xmath333 and it equals @xmath334 here the normalizing constant is the multinomial beta function @xmath335 note that , if the @xmath147 are all integers , then this is the rational number @xmath336 thus the identity ( [ gammaproduct ] ) is the special case of the identity @xmath337 for the density of the dirichlet distribution when all @xmath338 are integers .",
    "we now return to the marginal likelihood for mixtures of independence models . to compute this quantity with respect to dirichlet priors",
    "means the following .",
    "we fix positive real numbers @xmath339 , and @xmath340 and @xmath341 for @xmath62 and @xmath342 .",
    "these specify dirichlet distributions on @xmath343 , @xmath30 and @xmath30 .",
    "namely , the dirichlet distribution on @xmath30 given by the @xmath340 is the product probability measure given by taking the dirichlet distribution with parameters @xmath344 on the @xmath44-th factor @xmath345 in the product ( [ prodofsimp ] ) and similarly for the @xmath341 .",
    "the resulting product probability distribution on @xmath346 is called the _ dirichlet distribution _ with parameters @xmath347 .",
    "its probability density function is the product of the respective densities : @xmath348 by the marginal likelihood with dirichlet priors we mean the integral @xmath349 this is a modification of ( [ marginallikelihood2 ] ) and it depends not just on the data @xmath57 and the model @xmath77 but also on the choice of dirichlet parameters @xmath350 . when the coordinates of these parameters are arbitrary positive reals but not integers , then the value of the integral ( [ marginallikelihood3 ] ) is no longer a rational number .",
    "nonetheless , it can be computed exactly as follows .",
    "we abbreviate the product of gamma functions in the denominator of the density ( [ productdensity ] ) as follows : @xmath351 instead of the integrand ( [ integrandexpansion ] ) we now need to integrate @xmath352 with respect to lebesgue probability measure on @xmath1 . doing this term by term , as before , we obtain the following modification of theorem [ thm : formula ] .      a well - known experimental study by chickering and heckerman @xcite compares different methods for computing numerical approximations of marginal likelihood integrals .",
    "the model considered in @xcite is the _ naive - bayes model _ , which , in the language of algebraic geometry , corresponds to arbitrary secant varieties of segre varieties . in this paper",
    "we considered the first secant variety of arbitrary segre - veronese varieties . in",
    "what follows we restrict our discussion to the intersection of both classes of models , namely , to the first secant variety of segre varieties .",
    "for the remainder of this section we fix @xmath354 but we allow @xmath355 to be arbitrary positive integers .",
    "thus in the model of ( * ? ? ?",
    "* equation ( 1 ) ) , we fix @xmath356 , and the @xmath250 there corresponds to our @xmath229 .    to keep things as simple as possible , we shall fix the uniform distribution as in sections 14 above . thus , in the notation of @xcite , all dirichlet hyperparameters @xmath357 are set to @xmath218 .",
    "this implies that , for any data @xmath83 and any of our models , the problem of finding the maximum a posteriori ( map ) configuration is equivalent to finding the maximum likelihood ( ml ) configuration . to be precise , the _ map configuration _ is the point @xmath358 in @xmath1 which maximizes the likelihood function @xmath359 in ( [ likelihoodfunction2 ] )",
    "this maximum may not be unique , and there will typically be many local maxima . chickering and heckerman @xcite use the expectation maximization ( em ) algorithm @xcite to compute a numerical approximation of the map configuration .",
    "the laplace approximation and the bic score @xcite are predicated on the idea that the map configuration can be found with high accuracy and that the data @xmath57 were actually drawn from the corresponding distribution @xmath360 .",
    "let @xmath361 denote the hessian matrix of the log - likelihood function @xmath362 .",
    "then the laplace approximation ( * ? ? ?",
    "* equation ( 15 ) ) states that the logarithm of the marginal likelihood can be approximated by @xmath363 the bayesian information criterion ( bic ) suggests the coarser approximation @xmath364 where @xmath365 is the sample size .    in algebraic statistics ,",
    "we do not content ourselves with the output of the em algorithm but , to the extent possible , we seek to actually solve the likelihood equations @xcite and compute all local maxima of the likelihood function .",
    "we consider it a difficult problem to reliably find @xmath366 , and we are concerned about the accuracy of any approximation like ( [ laplace ] ) or ( [ bic ] ) .",
    "consider the _",
    "@xmath9 swiss francs _",
    "table ( [ swisstable ] ) discussed in the introduction .",
    "here @xmath32 , @xmath216 , @xmath367 , the matrix @xmath18 is unimodular , and ( [ segreveronese ] ) is the segre embedding @xmath368 .",
    "the parameter space @xmath1 is @xmath2-dimensional , but the model @xmath77 is @xmath369-dimensional , so the given parametrization is not identifiable @xcite .",
    "this means that the hessian matrix * h * is singular , and hence the laplace approximation ( [ laplace ] ) is not defined .",
    "we compute ( [ laplace ] ) and ( [ bic ] ) for the model and data in example [ cointoss ] . according to (",
    "* example 9 ) , the likelihood function @xmath370 has three local maxima @xmath371 in the model @xmath77 , and these translate into six local maxima @xmath372 in the parameter space @xmath1 , which is the @xmath373-cube .",
    "the two global maxima @xmath374 in @xmath1 are @xmath375 both of these points in @xmath1 give the same point in the model : @xmath376 the likelihood function evaluates to @xmath377 at this point .",
    "the following table compares the various approximations . here",
    ", `` actual '' refers to the base-10 logarithm of the marginal likelihood in example [ cointoss ] .",
    "the method for computing the marginal likelihood which was found to be most accurate in the experiments of chickering and heckerman is the _ candidate method _ @xcite .",
    "this is a monte - carlo method which involves running a gibbs sampler .",
    "the basic idea is that one wishes to compute a large sum , such as ( [ eq : sum ] ) by sampling among the terms rather than listing all terms . in the candidate method",
    "one uses not the sum ( [ eq : sum ] ) over the lattice points in the zonotope but the more naive sum over all @xmath378 hidden data that would result in the observed data represented by @xmath57 .",
    "the value of the sum is the number of terms , @xmath378 , times the average of the summands , each of which is easy to compute .",
    "a comparison of the results of the candidate method with our exact computations , as well as a more accurate version of gibbs sampling which is adapted for ( [ eq : sum ] ) , will be the subject of a future study .",
    "one of the applications of marginal likelihood integrals lies in model selection .",
    "an important concept in that field is that of _",
    "bayes factors_. given data and two competing models , the bayes factor is the ratio of the marginal likelihood integral of the first model over the marginal likelihood integral of the second model . in our context",
    "it makes sense to form that ratio for the independence model @xmath16 and its mixture @xmath77 .",
    "to be precise , given any independence model , specified by positive integers @xmath379 and a corresponding data vector @xmath83 , the bayes factor is the ratio of the marginal likelihood in lemma [ toricintegral ] and the marginal likelihood in theorem [ thm : formula ] .",
    "both quantities are rational numbers and hence so is their ratio .",
    "the bayes factor which discriminates between the independence model @xmath16 and the mixture model @xmath77 is a rational number .",
    "it can be computed exactly using algorithm [ fastt ] ( and our maple - implementation ) .",
    "[ schizoex ] we conclude by applying our method to a data set taken from the bayesian statistics literature .",
    "evans , gilula and guttman @xcite analyzed the association between length of hospital stay ( in years @xmath380 ) of @xmath381 schizophrenic patients and the frequency with which they are visited by their relatives .",
    "their data set is the following contingency table of format @xmath382 : @xmath383 they present estimated posterior means and variances for these data , where _ `` each estimate requires a @xmath384-dimensional integration '' _ @xcite . computing their integrals",
    "is essentially equivalent to ours , for @xmath385 and @xmath386 .",
    "the authors emphasize that _ `` the dimensionality of the integral does present a problem '' _",
    "@xcite , and they point out that _",
    "`` all posterior moments can be calculated in closed form .... however , even for modest @xmath55 these expressions are far to complicated to be useful '' _ @xcite .",
    "we differ on that conclusion . in our view , the closed form expressions in section 3 are quite useful for modest sample size @xmath55 . using algorithm [ fastt ] , we computed the integral ( [ sec4integral ] ) .",
    "it is the rational number with numerator @xmath387 and denominator @xmath388 to obtain the marginal likelihood for the data @xmath57 above , that rational number ( of moderate size ) still needs to be multiplied with the normalizing constant @xmath389    * acknowledgements . *",
    "shaowei lin was supported by graduate fellowship from a*star ( agency for science , technology and research , singapore ) .",
    "bernd sturmfels was supported by an alexander von humboldt research prize and the u.s .",
    "national science foundation ( dms-0456960 ) .",
    "zhiqiang xu is supported by the nsfc grant 10871196 and a sofia kovalevskaya prize awarded to olga holtz .",
    "d.m .  chickering and d.  heckerman : efficient approximations for the marginal likelihood of bayesian networks with hidden variables , _ machine learning _ * 29 * ( 1997 ) 181 - 212 ; microsoft research report , msr - tr-96 - 08 .",
    "r.  stanley : a zonotope associated with graphical degree sequences , in _ applied geometry and discrete mathematics : the victor klee festschrift _",
    "p. gritzmann and b. sturmfels ) , amer .",
    "soc . , dimacs series in discrete mathematics * 4 * ( 1991 ) 555570 .",
    "b.  sturmfels : open problems in algebraic statistics , _ emerging applications of algebraic geometry _ ( eds .",
    "m.  putinar and s.  sullivant ) , i.m.a .",
    "volumes in mathematics and its applications * 149 * ( 2008 ) 351364 .",
    "k.  yamazaki and s.  watanabe : newton diagram and stochastic complexity in mixture of binomial distributions , in _ algorithmic learning theorem _ , springer lecture notes in computer science * 3244 * ( 2004 ) 350364 ."
  ],
  "abstract_text": [
    "<S> inference in bayesian statistics involves the evaluation of marginal likelihood integrals . </S>",
    "<S> we present algebraic algorithms for computing such integrals exactly for discrete data of small sample size . </S>",
    "<S> our methods apply to both uniform priors and dirichlet priors . </S>",
    "<S> the underlying statistical models are mixtures of independent distributions , or , in geometric language , secant varieties of segre - veronese varieties . </S>",
    "<S> + * keywords : * marginal likelihood , exact integration , mixture of independence model , computational algebra </S>"
  ]
}