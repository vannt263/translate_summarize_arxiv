{
  "article_text": [
    "engineering problems often involve search for optimal parameters of physical objects ( geometry , chemical composition etc ) or mathematical models ( coefficients , input data sets etc ) . considering the possible complexity of these problems",
    ", it is not always easy or even possible to come up with an analytical approach that answers the question . instead",
    ", trial - and - error search using computer simulation can be performed , which , if done manually , is tedious and inefficient , if feasible at all .",
    "one can build a code interface ( function / procedure ) that has input  set of trial values , and output  some scalar value that represents cost or error .",
    "this value is calculated automatically every time the simulation is performed . from this point of view , the problem is reduced to one of mathematical optimization .",
    "however , the objective function does not have an analytical form and , what is more crucial , is usually expensive ( it can take many hours to evaluate for a single set of input parameters ) , and therefore is called expensive black - box function .",
    "the procedure proposed here allows to perform efficient optimization of expensive black - box functions .",
    "usage of the response surface methodology @xcite based on radial basis functions @xcite allows us to reconstruct ( and subsequently optimize ) a given black - box function with a limited number of function evaluations .",
    "the initial stage of the procedure is based on a custom latin hypercube sampling @xcite .",
    "subsequent stage is based on a modification of cors algorithm @xcite with space rescaling .",
    "in addition , the procedure is designed to scale on multicore processors by mapping the function on sets of arguments in a parallel way ( each core is running its own function evaluation ) , which results in a speedup that is equal to a number of cores available .",
    "the goal of the procedure is to efficiently minimize a non - negative function @xmath0 , with each of its variables having a specified independent range of values . to maximize @xmath0 ,",
    "the procedure can be simply applied on @xmath1 or similar expression .",
    "the procedure proposed here consists of four main steps , which are described in detail in the following sections :    1 .",
    "rescaling of variables 2 .   initial sampling 3 .",
    "rescaling of the objective function 4 .",
    "subsequent iterations      since further analysis will be based on distances between sampled points , it is vital to ensure that the ranges of variables are not very different .",
    "for example , the variables could have different physical nature and might exhibit differences by orders of magnitude .",
    "therefore , the natural step is to normalize each range into a range of @xmath2 $ ] . for a variable @xmath3 that is in range @xmath4",
    "$ ] the following simple transformation is used : @xmath5 after such rescaling , the search space becomes simply a unit cube .",
    "the quality of the response surface that reconstructs a black - box function depends significantly on the initial set of samples .",
    "a uniform mesh , while acceptable for lower dimensions , becomes inefficient for higher dimensions since the number of evaluations grows exponentially with the space size . generating random samples allows the number of samples to be independent of the space size , but the samples will not cover the search space uniformly ( 2d example is in fig .",
    "[ fig : lh_random ] ) .",
    "the problem of placing a given amount of points @xmath6 into a unit cube in a uniform manner can be solved with the latin hypercube ( lh ) @xcite .",
    "essentially , the @xmath6 points are placed at the nodes of a uniform mesh of the same size in such a way that there is exactly one point in each axes - aligned plane containing it .",
    "a simple method for constructing a lh of a reasonable uniformity is presented here . at first all samples",
    "are placed diagonally ( 2d example is in fig .  [",
    "fig : lh_initial ] ) , which forms the initial lh .",
    "subsequently , two random , axes - aligned planes are picked and exchanged . if the lh obtained has an improved uniformity of samples , it is kept , otherwise another random exchange is performed until an improvement is achieved .",
    "the measure of uniformity , or spread ( which has to be minimized ) , used here can be introduced in the following way : @xmath7 where @xmath8 is the distance between two points . by repeating such exchanges",
    "iteratively a reasonable number of times ( for example , @xmath9 ) , a lh with a uniform placement of samples can be obtained ( 2d example is in fig .  [",
    "fig : lh_final ] ) .    0.3   points into a unit square .",
    "( a )  typical placement of random points , ( b )  initial lh , ( c )  eventual lh.,title=\"fig : \" ]    0.3   points into a unit square .",
    "( a )  typical placement of random points , ( b )  initial lh , ( c )  eventual lh.,title=\"fig : \" ]    0.3   points into a unit square .",
    "( a )  typical placement of random points , ( b )  initial lh , ( c )  eventual lh.,title=\"fig : \" ]      the raw values of the objective function might be misleading and hard to interpret ( for example , value of @xmath10 might be high or low depending on reference to compare with ) . to overcome this problem , function values are rescaled into the @xmath2 $ ] range .",
    "this makes it much easier to interpret the values relative to @xmath11 ( the worst value ) and @xmath12 ( the best value ) .",
    "also , sometimes outliers in the form of extremely high values of the objective function may appear .",
    "these values , if kept , can pollute the overall shape of the response surface . to eliminate such possibility , a specified fraction of samples with lowest values obtained on the initial stage is kept ( and corresponding threshold value @xmath13 is introduced ) , while the rest of the values ( that are higher than @xmath13 ) are discarded .    the rescaled function can be defined in the following way : @xmath14        after the initial sampling , a response surface using cubic radial basis functions ( rbf ) can be constructed .",
    "the following expression was used @xcite : @xmath15 where @xmath16 is the response surface reconstructed with @xmath6 sampled points ( @xmath17 ) , @xmath18 is a cubic function ( @xmath19 ) and @xmath20 , @xmath21 , @xmath22 are coefficients that are determined from the fact that the response surface interpolates all samples @xmath17 .",
    "the rbf fit , once constructed , is able to predict the value of the objective function at an arbitrary point @xmath23 .",
    "subsequent iterations are performed in accordance with the modified cors algorithm @xcite .",
    "the concept of this algorithm is the following  while the current fit is minimized , a new sampled point has to be not closer than @xmath24 to each of the previously sampled points . the value of @xmath24 loops over a set of values in a periodic way , which prevents the algorithm from being trapped in a local minimum .",
    "the procedure described here uses the following interpretation of cors algorithm  a ball of radius @xmath24 is placed around each of previously sampled points and the new point is required to minimize the current fit , but to be outside of every ball . such analogy allows us to introduce a density of these balls as the total volume of the balls divided by the total volume of a unit cube .",
    "this density can be assumed to start with an initial value and decrease ( decay ) with iterations with a given rate . by controlling this initial density and rate of decay , different search strategies ( for example , with more attention to global / local search ) can be achieved .    since the volume of a unit cube is @xmath11 ,",
    "the following can be written : @xmath25 where @xmath26 is the density of the balls , @xmath27 is amount of previously sampled points , @xmath28 is a volume a single ball .",
    "the inequality indicates that the actual density can be less than @xmath29  some balls may intersect with each other or may have some fraction of their volume outside of the cube .",
    "the volume of a @xmath30-dimensional ball is equal to @xmath31 , where @xmath32 is a volume of a ball with radius @xmath11 .",
    "the current amount of balls @xmath27 is equal to @xmath33 , where @xmath6 is the amount of initial samples and @xmath34 is the number of current subsequent iteration ( counted from @xmath11 ) .",
    "then : @xmath35 @xmath36 the volume @xmath32 can be expressed with the gamma function : @xmath37 the density can then be introduced in the following form : @xmath38 where @xmath39 is initial density , @xmath40 is a rate of density decay , @xmath41 is a total number of subsequent iterations . if @xmath42 , then density linearly decays with iterations , if @xmath43  slower than linearly , if @xmath44  faster than linearly .    equation ( with equality sign ) together with and allows us to find the current radius @xmath24 on every subsequent iteration .",
    "an application example of the proposed procedure is shown in fig .",
    "[ fig : test ] . the function @xmath45 shown in fig .",
    "[ fig : test_f ] is assumed to be unknown and can only be evaluated at given points .",
    "notice that the function has 1 global and 3 local minima .",
    "[ fig : test_rough ] shows the result of applying the procedure using 15 function evaluations ( 10 on initial stage and 5 on subsequent ) and fig .",
    "[ fig : test_fine ]  using 30 evaluations ( 20 on initial stage and 10 on subsequent ) .",
    "function evaluations are represented with black dots .",
    "it can be seen that the quality of the response surface depends significantly on the number of function evaluations selected .",
    "while in either case it was possible to identify the location of the global minimum , some of the local minima were not captured .",
    "0.3 , ( b)/(c )  results of running a procedure using 15/30 function evaluations.,title=\"fig : \" ]    0.3 , ( b)/(c )  results of running a procedure using 15/30 function evaluations.,title=\"fig : \" ]    0.3 , ( b)/(c )  results of running a procedure using 15/30 function evaluations.,title=\"fig : \" ]      oftentimes the global minimum is located at the bottom of a valley - like feature . in this case , the original function may be represented inaccurately by its rbf fit , which will result in poor accuracy of the resulting optimum that the procedure will yield .",
    "a way to improve the quality of the rbf fit based on space rescaling is discussed here .",
    "first , the rbf expression before rescaling is used to construct the initial fit .",
    "after that , a large number of random samples ( typically @xmath46 or more ) is populated in the unit cube and some fraction of best points ( typically @xmath47 of total number ) is selected based on their rbf values .",
    "this cloud of points roughly approximates the shape of the valley feature and is used for the space rescaling procedure .",
    "the covariance matrix of the cloud can be evaluated as : @xmath48 then eigensystem of the covariance matrix is found as : @xmath49 where @xmath50 are the eigenvalues and @xmath51 are the eigenvectors .",
    "then , a scaling matrix is introduced as : @xmath52 and the rbf expression is updated : @xmath53 to provide an example of the procedure discussed , the simple function @xmath54 shown in fig .",
    "[ fig : rbf_f ] is assumed to be unknown and can only be evaluated at given points . the original rbf fit reconstructed with 20 samples ( black dots )",
    "is shown in fig .",
    "[ fig : rbf_unscaled ] .",
    "an rbf fit with space rescaling is shown in fig .",
    "[ fig : rbf_scaled ] .",
    "it can be seen that the rescaling procedure improves the quality of the fit significantly .",
    "0.3 , ( b )  original rbf fit , ( c )  rbf fit with space rescaling .,title=\"fig : \" ]    0.3 , ( b )  original rbf fit , ( c )  rbf fit with space rescaling .,title=\"fig : \" ]    0.3 , ( b )  original rbf fit , ( c )  rbf fit with space rescaling .,title=\"fig : \" ]",
    "the proposed procedure is designed to scale on multicore processors to handle expensive black - box functions more efficiently .",
    "this is achieved simply by dividing the samples on the initial and subsequent stages into batches that are evaluated simultaneously .",
    "the size of the batch is equal to the number of cores available .",
    "the python package ` multiprocessing ` and its method ` map ` were used in the code to map a given black - box function on a batch of samples in a parallel way .",
    "the resulting speedup is equal to the number of cores available .",
    "a procedure that is able to efficiently optimize expensive black - box functions is described .",
    "it is based on the response surface methodology , uses a powerful sampling technique and is able to scale on multicore processors , all of which allow us to locate the global optimum with a limited number of function evaluations .",
    "this work was performed under the u.s . national science foundation career award ( grant cmmi-1150523 ) .",
    "this support is acknowledged with thanks ."
  ],
  "abstract_text": [
    "<S> this note provides a description of a procedure that is designed to efficiently optimize expensive black - box functions . </S>",
    "<S> it uses the response surface methodology by incorporating radial basis functions as the response model . </S>",
    "<S> a simple method based on a latin hypercube is used for initial sampling . </S>",
    "<S> a modified version of cors algorithm with space rescaling is used for the subsequent sampling . </S>",
    "<S> the procedure is able to scale on multicore processors by performing multiple function evaluations in parallel . </S>",
    "<S> the source code of the procedure is written in python .    * keywords * : optimization , black - box function , latin hypercube , response surface , parallel computing    = 1 </S>"
  ]
}