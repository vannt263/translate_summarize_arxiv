{
  "article_text": [
    "gravitational microlensing is the study of the deflection of light by matter in a regime where high magnification and multiple - imaging occurs , but the individual micro - images are not resolvable .",
    "this includes high magnification events due to lenses in the galactic bulge and halo ( alcock et al . 1993 ; aubourg et al . 1993",
    "; udalski et al .",
    "1993 ) , and microlensing by compact objects within macro - lenses at cosmological distances ( vanderriest et al . 1989 ; irwin et al .",
    "while galactic microlensing projects have focused on searches for dark matter and the detection of planets , cosmological microlensing has led to advances in the understanding of stellar mass functions , mean stellar masses , and the structure of quasars , including constraints on the physical size of the emission regions at different wavelengths .",
    "see wambsganss ( 2006 ) , kochanek et al .",
    "( 2007 ) , gould ( 2008 ) , and mao ( 2008 ) for recent reviews .",
    "the standard signature of cosmological microlensing , especially when applied to observations of active galactic nuclei , is an uncorrelated change in brightness of a single macro - image within a multiply - imaged system ( schneider & weiss 1987 ) .",
    "intrinsic variation in source flux is seen as a correlated change in the brightness of all the images , separated by the ( macro)lensing time - delay .",
    "such observations require accurate light curves to be obtained over long time periods , in many cases decades , as there is a wide variation in the time delay : @xmath0 hours for the quadruple - lensed ( vakulik et al .",
    "2006 ) and 423 days for ( hjorth et al .",
    "2002 )  see saha et al .",
    "( 2006 ) and oguri ( 2007 ) for further examples .",
    "determination of the source size , source intensity profile , and physical properties of the microlenses ( mass function , mean mass ) , requires a statistical comparison between observed light curves and microlensing models .",
    "this is achieved through the use of the gravitational lens equation : @xmath1 which relates the two - dimensional locations of a source , @xmath2 , and an image , @xmath3 , with the deflection angle term , @xmath4 , dependent on the arrangement of lenses .",
    "a common choice for microlensing is the many - schwarzschild lens model : @xmath5 for @xmath6 lenses with masses , @xmath7 , at positions @xmath8 .",
    "the magnification , @xmath9 , due to a gravitational lens system is @xmath10 where @xmath11 is the jacobian matrix of equation ( [ eqn : lens ] ) , which measures the areal distortion between the image and source planes .    while an image position maps uniquely to a source location ( @xmath12 is a one - to - one mapping )",
    ", the converse is not true ( @xmath13 is a one - to - many mapping ) . except for a limited number of special cases",
    "[ see schneider et al .",
    "( 1992 ) for examples ] , the lens equation is not invertible . in the cosmological microlensing case , where many millions of individual stars may contribute to the observed magnification of a macro - image , it is more common to use a numerical technique to solve for @xmath9 over a finite region of the source plane  a magnification map  rather than attempting to find all image locations from equation ( [ eqn : lens ] ) for a given source position ( e.g. paczyski 1986 ) .",
    "inverse ray - shooting provides the most straightforward means to obtain magnification maps for an arbitrary lens distribution [ see kayser et al .",
    "( 1986 ) and schneider & weiss ( 1986 ; 1987 ) for early versions of this technique ] .",
    "inverse ray - shooting follows a large number ( typically millions ) of light rays backwards from the observer , through the lens plane to the source plane , which is represented as a pixellated grid .",
    "the number of light rays falling in each pixel , @xmath14 , compared to the ( average ) number if there was no lensing , @xmath15 , gives an estimate of the per - pixel magnification : @xmath16 a typical magnification map is shown in figure [ fig : map ] , with the characteristic pattern of caustics clearly visible .",
    "caustics are regions of high magnification  formally those points where @xmath17 . the relative motion of the observer , lens plane and source imparts an effective transverse velocity to the source , causing it to move across the caustic network , and resulting in a time - varying change in source brightness .",
    "accordingly , a sample light curve is generated by moving a source profile across a simulated caustic network , and converting the magnification at each point to a magnitude change .",
    "statistical investigations of cosmological microlensing require the generation of many sample light curves , however , the creation of magnification maps poses a significant computational challenge .",
    "the time to calculate a magnification map is directly proportional to the number of pixels in the source plane ( @xmath18 ) , the number of microlenses ( @xmath19 , and the number of floating point operations ( @xmath20 ) per deflection calculation . as a monte carlo technique",
    ", the computation time is extended in direct proportion to @xmath15 , which sets the accuracy of calculated magnifications , and the number of repeat ( @xmath21 ) map generations .",
    "long compute times  @xmath22days  months@xmath23  limit the scope to vary the input parameters , such as the initial stellar mass function , mean stellar mass , and source grid resolution . to keep computation times feasible for a direct implementation of the inverse ray - shooting method ,",
    "the product @xmath24 historically has been constrained to @xmath25 .",
    "a number of approaches have been developed to overcome the processing time problem .",
    "wambsganss ( 1990 ; 1999 ) used a hierarchical tree code ( barnes & hut 1986 ) , where lenses are treated differently depending on their distances from the light ray : lenses at a similar distance from a ray are grouped together and replaced with a single pseudo - lens of higher mass , effectively reducing the @xmath26 factor .",
    "this introduces a slight error in the magnification map , which can be reduced by including higher order moments of the mass distribution .",
    "a parallel version of the tree code , suitable for running billion - lens calculations on a parallel computing cluster  a region of parameter size previously unavailable to microlensing codes  has been implemented by garsden & lewis ( 2009 ) .",
    "mediavilla et al .",
    "( 2006 ) used a lattice of polygonal cells to map areas of the image plane to source plane pixels , rather than using a regular grid in the source plane .",
    "this greatly reduces @xmath15 , resulting in a @xmath27 speed - up to reach a given accuracy compared to standard inverse ray - shooting , however , preparing an appropriate polygonal lattice introduces a significant computation overhead .",
    "a limitation of monte carlo - style methods is that many more magnification values , @xmath18 , are constructed than may actually be required ( e.g. to form a single light curve ) .",
    "a slightly larger ( angular ) size must be used for the image plane than for the source plane , as light rays at large impact parameters can be deflected into the source plane , contributing flux that would otherwise be lost .",
    "consequently , more light rays must be generated than will actually fall within the source grid .",
    "additionally , the finite source grid resolution means that true point source magnifications can not be accurately calculated . to avoid these issues , lewis et al .",
    "( 1993 ) and witt ( 1993 ) independently developed approaches based on imaging an infinite line in the source plane , which maps to a continuous , infinite line in the image plane , plus a number of closed loops - one for each microlens .",
    "wyithe & webster ( 1999 ) developed this technique further for extended sources .    in this work , we demonstrate that the redeployment of the direct inverse ray - shooting algorithm on modern , programmable graphics processing units ( gpus ) can dramatically speed - up the calculation of microlensing magnification maps , without the programming overheads of implementing a more complex code .",
    "gpus are macroscopic semiconductor arrays designed to accelerate the rendering of three - dimensional geometry for display on two - dimensional computer screens .",
    "most modern computers contain a gpu , either on the system board or on a peripheral graphics card , which now regularly provide at least an order of magnitude greater raw computational power than the central processing unit ( cpu ) .",
    "rendering on - screen pixels is a highly parallel task , and this is reflected in the gpu architecture .",
    "modern gpus are primarily composed of stream processors , which are individual arithmetic logic units ( alus ) grouped in sets and controlled by an instruction scheduler with associated shared memory .",
    "consequently , algorithms that lend themselves to the `` stream processing '' paradigm , where many individual data - streams all undergo identical operations , can be moved to the gpu , resulting in significantly shorter computation times .",
    "on - going improvements in the performance of programmable graphics hardware , combined with the notion of general purpose computation on gpus ( gpgpu ) , is heralding a revolution in scientific computing ( fournier & fussell 1988 ; tomov et al .",
    "2003 ; venkatasubramanian 2003 ; owens et al . 2005 ) .",
    "the two major graphics processor manufacturers , nvidia and amd , support gpgpu by providing software development kits for stream computing .",
    "nvidia introduced its compute unified device architecture ( cuda ) in 2006 .",
    "cuda is an extension ( via compiler directives ) of the standard c programming language , designed to simplify the process of gpgpu programming by abstracting the process of writing gpu code .",
    "amd s `` ati stream '' technology is based on an evolved form of brook .",
    "brook was one of the first gpu languages that went beyond the standard shader languages ( particularly cg and glsl ) to provide general purpose computing capabilities .",
    "both cuda and ati stream allow the programmer to define functions that are executed in parallel on one or more gpus attached to a system .",
    "astronomers are just beginning to consider the advantages that gpus can offer for computation .",
    "early work has focused on a few well - known algorithms , with gravitational n - body simulations receiving particular attention .",
    "nyland et al .",
    "( 2004 ) were the first to attempt to move the expensive @xmath28 inter - body force calculations performed during an n - body simulation from the cpu to the gpu , work that was later followed by portegies zwart et al .",
    "both groups found performance increases of @xmath29 times , demonstrating the significant potential of gpus , but their efforts were inhibited by the use of inflexible shader languages .",
    "the arrival of gpgpu languages improved the situation greatly , and measured performances of @xmath30 times over cpu implementations led to a flurry of work in the area using brookgpu ( elsen et al .",
    "2007 ) and cuda ( hamada & iitaka 2007 ; belleman et al .",
    "2007 ; schive et al . 2007",
    "; nyland et al . 2008 ; moore et al .",
    "other astronomy algorithms implemented on the gpu include radio - telescope signal correlation ( schaaf & overeem 2004 ; wayth et al . 2007 ; harris et al . 2008 ;",
    "ord et al . 2009 ) and the solution of kepler s equations ( ford 2008 ) .",
    "gpus have also been used for real - time visualisation of large datasets ( szalay et al . 2008 ) .",
    "we now describe the implementation of gpu - based , direct inverse ray - shooting code for microlensing experiments .",
    "we demonstrate the substantial performance gains in executing our implementation on a system containing one or two nvidia geforce 8800 gt graphics cards , and on a system with an attached ( external ) nvidia s1070 tesla unit .",
    "the remainder of this paper is organised as follows . in section [ sct : implement ] we describe both openmp ( for multiple - core cpu systems ) and our cuda - based approach for single and multi - gpu systems .",
    "we compare processing performance via timing tests in section [ sct : comparison ] . in section",
    "[ sct : discussion ] , we consider advantages and limitations of gpgpu computing relevant to the ray - shooting case , and discuss applications of our approach , including computational steering .",
    "the inverse ray - shooting algorithm is an ideal candidate for moving to a gpu as it is `` trivially parallelisable '' : the deflection of a single light ray is independent of the deflection of all other light rays , and the deflection of a light ray due to one lens is independent of the deflection due to all other lenses .",
    "the former case can be treated by splitting up the total number of light rays , @xmath31 , into @xmath32 batches that are deflected in parallel .",
    "the latter case can be treated by recasting the lens equation as : @xmath33 where @xmath34 for @xmath35 parallel threads , and each processing step considers only a single light ray .",
    "our final solution uses a combination of both parallel options .",
    "the choice of parallel scheme necessitates a trade - off between memory usage and processing speed .",
    "aggregate gpu speed depends on the following characteristics of the architecture : the number of stream processors , which determines how many independent parallel tasks can be performed ( per gpu stream clock cycle ) ; stream processor clock speed , which controls how many instructions can be operated on in a given time period ; memory bandwidth , which specifies how quickly memory can be accessed , and is typically faster on the gpu than the cpu ; and gpu memory ( classified as either device , shared or register memory ) , which limits the amount of data that can be used for parallel processing .      as a step towards the gpu implementation",
    ", we consider openmp .",
    "processing threads are distributed amongst multiple cpus on a single machine , with the run - time environment controlling thread allocation .",
    "compiler directives indicate code blocks to be processed in parallel , requiring minimal changes to the overall program structure . in astronomy",
    ", openmp has been primarily used for gravitational and hydrodynamical simulations ( e.g. thacker 1999 ; semelin & combes 2005 ; merz , pen & trac 2005 ; thacker & couchman 2006 ; and mudryk & murray 2009 ) .",
    "the openmp direct ray - shooting algorithm works as follows :    1 .",
    "@xmath6 lenses are generated on the cpu and stored in system memory .",
    "2 .   @xmath31 light ray positions ( @xmath3 )",
    "are randomly generated in serial on the cpu and stored in system memory ; 3 .",
    "source coordinates are calculated in parallel , with light rays divided evenly between threads by openmp ; 4 .",
    "once complete , a single thread maps the ray locations onto the source pixel grid in order to obtain the magnification map .",
    "this approach avoided potential problems such as multiple threads attempting to write to the same memory location when updating deflection angles , inaccurate or slow random number generation ( the standard libc random number generator rand ( ) is not thread safe ) , and enables a simpler extension to gpu programming with cuda .",
    "we note that this algorithm assumes that all lens positions can be stored in cpu memory at one time , which limits the range of @xmath26 that we can use for timing tests in section [ sct : timing ] .",
    "our gpu ray - shooting algorithm operates in a similar manner to the openmp code , except that lens and light ray positions generated by the cpu and stored in the computer memory must be copied to and from the gpu s memory as part of each processing cycle . for our specific implementation",
    ", we chose cuda over ati stream technology for two main reasons : ( i ) it is available on more architectures ( i.e. windows , linux and mac os / x , compared to ati stream , which only supports windows and linux ) and ( ii ) nvidia has been the first - to - market with desktop , gpgpu - specific , multi - tflop / s products like the tesla .",
    "the c function calls of the openmp code are replaced with calls to the cuda library .",
    "the gpu ray - shooting algorithm works as follows :    1 .",
    "@xmath6 lenses are generated on the cpu and loaded into gpu device memory ; 2 .",
    "@xmath32 light ray coordinates are randomly generated on the cpu and loaded into gpu device memory ; 3 .",
    "gpu computation is initialised ; computation is split into groups of 128 threads ( see below ) ; 4 .",
    "each thread group loads 128 lenses and calculates deflection on 128 rays , this is repeated until all lenses and rays are exhausted ; 5 .",
    "once computation on the gpu is complete , results are copied back from the gpu device memory to system memory ; 6 .",
    "cpu maps the ray locations onto the source pixel grid in order to obtain the magnification map ; 7 .",
    "steps 2 - 6 repeated until @xmath15 rays per source pixel is reached .",
    "ray coordinates are generated and processed in batches , as this minimises memory usage on the gpu while not reducing performance with a significantly large number of rays .",
    "for this work , @xmath32 was set to @xmath36 , as larger sizes did not increase performance . to maximise efficient use of the gpu device memory , source ray coordinates can overwrite the image ray coordinates , as they are still stored on the cpu memory .",
    "128 threads are run per group , which improves throughput , while not exhausting the supply of registers and shared memory .",
    "the gpus on the tesla unit have more registers , allowing 256 threads per group .",
    "this number of 128 or 256 threads was chosen using the nvidia cuda occupancy calculator to determine best utilisation of the gpu , and this number was confirmed with testing .      to make use of multiple gpus or a tesla device ,",
    "multiple cpu threads are used .",
    "one cpu thread is associated with each gpu , handling memory transfer to and from the device , and calls to device functions to perform computation . for our implementation",
    ", cpu thread management was performed by openmp , as it takes care of thread initialisation , destruction and synchronisation .",
    "the multiple gpu algorithm works as follows :    1 .",
    "@xmath6 lenses are generated on the cpu and loaded into all gpus device memory ; 2 .",
    "@xmath37 light ray coordinates are randomly generated in serial on the cpu by the master thread and stored in @xmath38 arrays ; 3 .",
    "@xmath38 threads copy ray coordinates to the gpus and gpu computation is initialised ; 4 .",
    "computation is split into groups of 128 threads ",
    "computation on each gpu is independent of the others ; 5 .",
    "each thread group loads 128 lenses and calculates deflection on 128 rays , this is repeated until all lenses and rays are exhausted ; 6",
    ".   once computation on all gpus is complete , results are copied back from the gpu device memory to system memory ; 7 .",
    "the master cpu thread maps the ray locations onto the source pixel grid in order to obtain the magnification map ; 8 .",
    "steps 2 - 6 repeated until @xmath15 rays per source pixel is reached .    while the best performance for our gpu algorithm was achieved when accessing only registers and shared memory ,",
    "it is not possible to avoid either the transfer from cpu memory to gpu device memory , or from device to shared or register memory . while this may seem like a processing bottleneck , the high latency of a single access of device memory is offset by the significant gain due to multiple streams being able to access device memory in parallel .",
    "to evaluate the relative performance of openmp and cuda inverse ray - shooting codes , a number of timing tests were performed .",
    "we also implemented a single - cpu code : although the parameter space where this can be run is limited , it does provide a check on the accuracy of the parallel codes .",
    "the same base hardware was used throughout , comprising an intel q6600 quad core cpu ( 2.4 ghz ) , with 4 gb of ram and either two nvidia geforce 8800 gts or an nvidia s1070 tesla unit connected via dual pcie x8 , or higher , buses . in table",
    "[ tab : devref ] , we provide a summary of the hardware configurations .",
    "the 8800 gt comprises 112 stream processors , each running at 1.5 ghz , with a peak performance of 336 gflop / s .",
    "this is much higher than a typical high - end cpu , such as the intel core 2 quad q6600 , which is capable of 76.8 gflop / s .",
    "the 8800 gt has 512 mb of memory , which can store up to @xmath39 two - dimensional lens positions as 32-bit ( i.e. single precision ) floating point numbers .",
    "the tesla s1070 comprises four gpus , each with 240 stream processors , running at at 1.296 ghz .",
    "the tesla s processing peak is 2.488 tflop / s , and there is 4 gb available per gpu .",
    ".[tab : devref ] hardware configurations used in the comparison of inverse ray - shooting codes .",
    "the memory column lists the total memory available for each processing option , which sets the problem size ( @xmath26 and @xmath32 light rays ) that can be processed instantaneously .",
    "[ cols= \" < , < , < , < \" , ]"
  ],
  "abstract_text": [
    "<S> gravitational lensing calculation using a direct inverse ray - shooting approach is a computationally expensive way to determine magnification maps , caustic patterns , and light - curves ( e.g. as a function of source profile and size ) . </S>",
    "<S> however , as an easily parallelisable calculation , gravitational ray - shooting can be accelerated using programmable graphics processing units ( gpus ) . </S>",
    "<S> we present our implementation of inverse ray - shooting for the nvidia g80 generation of graphics processors using the nvidia compute unified device architecture ( cuda ) software development kit . </S>",
    "<S> we also extend our code to multiple - gpu systems , including a 4-gpu nvidia s1070 tesla unit . </S>",
    "<S> we achieve sustained processing performance of 182 gflop / s on a single gpu , and 1.28 tflop / s using the tesla unit . </S>",
    "<S> we demonstrate that billion - lens microlensing simulations can be run on a single computer with a tesla unit in timescales of order a day without the use of a hierarchical tree code .    ,    ,    and    gravitational lensing , methods : numerical 95.75.pq , 98.62.sb , 98.62.-g </S>"
  ]
}