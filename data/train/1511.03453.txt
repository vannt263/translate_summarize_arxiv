{
  "article_text": [
    "over the last few decades the fractional calculus has received much attention of both physical scientists and mathematicians since they can faithfully capture the dynamics of physical process in many applied sciences including biology , ecology , and control system .",
    "the anomalous diffusion , also referred to as the non - gaussian process , has been observed and validated in many phenomena with accurate physical measurement @xcite .",
    "the mathematical and numerical analysis of the factional calculus became a subject of intensive investigations . in literature , there are several definitions of fractional time derivatives including the riemann - liouville ( rl ) fractional derivative , the grnwald - letnikov ( gl ) fractional derivative , and the caputo fractional derivative ( see , for example , @xcite for details ) .",
    "it is easy to see that the gl fractional derivative is equivalent to the rl fractional derivative . both require fractional - type initial values , whose physical interpretation is not quite clear . on the other hand ,",
    "the caputo fractional derivative takes the integer - order differential equations as the initial value , and the caputo fractional derivative of a constant is zero , just as one would expect for the usual derivative .    in this paper",
    ", we are concerned with the evaluation of the caputo fractional derivative , which is defined by the formula @xmath23 one of the popular schemes of discretizing the caputo fractional derivative is the so - called @xmath24 approximation @xcite , which is simply based on the piecewise linear interpolation of @xmath25 on each subinterval . for @xmath26 ,",
    "the order of accuracy of the @xmath24 approximation is @xmath27 .",
    "there are also high - order discretization scheme by using piecewise high - order polynomial interpolation of @xmath25 @xcite .",
    "these methods require the storage of all previous function values @xmath28 and @xmath29 flops at the @xmath30th step .",
    "thus it requires on average @xmath9 storage and the total computational cost is @xmath11 with @xmath13 the total number of time steps , which forms a bottleneck for long time simulations , especially when one tries to solve a fractional partial differential equation .    here",
    "we present an efficient scheme for the evaluation of the caputo fractional derivative @xmath31 for @xmath26 .",
    "we first split the convolution integral in into two parts - a local part containing the integral from @xmath32 to @xmath33 , and a history part containing the integral from @xmath34 to @xmath32 .",
    "the local part is approximated using the standard @xmath24 approximation .",
    "for the history part , integration by part leads to a convolution integral of @xmath25 with the kernel @xmath4 .",
    "we show that @xmath4 ( @xmath26 ) admits an efficient sum - of - exponentials approximation on the interval @xmath5 $ ] with a uniform absolute error @xmath6 and the number of exponentials needed is of the order    @xmath35    that is , for fixed precision @xmath6 , we have @xmath36 for @xmath20 or @xmath37 for @xmath22 assuming that @xmath38 .",
    "the approximation can be used to accelerate the evaluation of the convolution via the standard recurrence relation .",
    "the resulting algorithm has nearly optimal complexity - @xmath12 work and @xmath10 storage .",
    "we would like to remark here that sum - of - exponentials approximations have been applied to speed up the evaluation of the convolution integrals in many applications .",
    "in fact , they have been used to accelerate the evaluation of the heat potentials in @xcite , and the evaluation of the exact nonreflecting boundary conditions for the wave , schrdinger , and heat equations in @xcite .",
    "there are also many other efforts to accelerate the evaluation of fractional derivatives ; see , for example , @xcite and references therein .",
    "we then apply the fast evaluation scheme of the caputo fractional derivative to study the fractional diffusion equations ( both linear and nonlinear ) .",
    "we demonstrate that it is straightforward to incorporate the fast evaluation scheme of the caputo fractional derivative into the existing standard finite difference schemes for solving the fractional diffusion equations .",
    "the resulting algorithm for solving the fractional pdes is both efficient and stable .",
    "the computational cost of the new algorithm is @xmath39 as compared with @xmath18 for direct methods and the storage requirement is only @xmath14 as compared with @xmath40 for direct methods , since one needs to store the solution in the whole computational spatial domain at all times .",
    "furthermore , we have carried out a rigorous and detailed analysis to prove that our scheme is unconditionally stable with respect to arbitrary step sizes . with these two properties",
    ", our scheme provides an efficient and reliable tool for long time large scale simulation of fractional pdes .",
    "the paper is organized as follows . in section 2",
    ", we describe the fast algorithm for the evaluation of the caputo fractional derivative and provide rigorous error analysis of our discretization scheme . in section 3 , we apply our fast algorithm to solve the linear fractional diffusion pdes and present the stability and error analysis for the overall scheme . in section 4",
    ", we study the nonlinear fractional diffusion pdes and demonstrate that our fast algorithm has the same order of convergence as the direct method in this case .",
    "finally , we conclude our paper with a brief discussion on the extension and generalization of our scheme .",
    "in this section , we consider the fast evaluation of the caputo fractional derivative for @xmath26 .",
    "suppose that we would like to evaluate the caputo fractional derivative on the interval @xmath41 $ ] over a set of grid points @xmath42 , with @xmath43 , @xmath44 , and @xmath45 .",
    "we will simply denote @xmath46 by @xmath47 .",
    "we first split the convolution integral in into a sum of local part and history part , that is , @xmath48 where the last equality defines the local part and the history part , respectively . for the local part",
    ", we apply the standard @xmath24 approximation , which approximates @xmath49 on @xmath50 $ ] by a linear polynomial ( with @xmath51 and @xmath47 as the interpolation nodes ) or @xmath52 by a constant @xmath53 .",
    "we have @xmath54 for the history part , we apply the integration by part to eliminate @xmath52 and have @xmath55.\\end{aligned}\\ ] ]      we now show that the convolution kernel @xmath4 ( @xmath26 ) can be approximated via a sum - of - exponentials approximation efficiently on the interval @xmath56 $ ] with the absolute error @xmath6 .",
    "that is , there exist positive real numbers @xmath57 and @xmath58 ( @xmath59 ) such that for @xmath26 , @xmath60,\\ ] ] where @xmath7 is given by .",
    "our proof is constructive and the error bound is explicit .",
    "we start from the following integral representation of the power function .",
    "[ soe1 ] for any @xmath61 , @xmath62    this follows from a change of variable @xmath63 and the integral definition of the @xmath64 function @xcite .",
    "can be viewed as a representation of @xmath65 using an infinitely many ( continuous ) exponentials . in order to obtain an efficient sum - of - exponentials approximation , we first truncated the integral to a finite interval , then subdivide the finite interval into a set of dyadic intervals and discretize the integral on each dyadic interval with proper quadratures .",
    "we now assume @xmath66 , which is the case we are concerned with in this paper .",
    "[ soe2 ] for @xmath67 ,",
    "@xmath68    @xmath69    the truncation error can be made arbitrarily small for fixed @xmath70 by choosing sufficiently large @xmath71 .",
    "usually we have @xmath72 and if one would like to bound the truncation error by @xmath73 , then @xmath74 or @xmath75 , and @xmath76 thus , @xmath77 is sufficient to bound the truncation error by @xmath6 .",
    "we now proceed to discuss the discretization error for the integral on the interval @xmath78 $ ] .",
    "similar to @xcite , we will analyze the discretization error on each dyadic interval using the gauss - legendre quadrature .",
    "[ soe3 ] consider a dyadic interval @xmath79 = [ 2^j , 2^{j+1}]$ ] and let @xmath80 and @xmath81 be the nodes and weights for @xmath30-point gauss - legendre quadrature on the interval .",
    "then for @xmath82 and @xmath83 , @xmath84    for any interval @xmath79 $ ] , the standard estimate for @xmath30-point gauss - legendre quadrature @xcite yields @xmath85 ^ 3 } \\max_{s\\in(a , b)}\\left|d^{2n}_s ( e^{-st}s^{\\beta-1})\\right|,\\ ] ] where @xmath86 denotes the derivative with respect to @xmath87 . + applying stirling s approximation @xcite @xmath88 we obtain @xmath89 ^ 3}<2\\sqrt{\\pi}\\left(\\frac{e}{8}\\right)^{2n }      \\frac{\\sqrt{n}}{n^{2n}}.\\ ] ] observe now @xmath90 for @xmath91 , and thus @xmath92 we also have @xmath93 combining , with the leibniz rule , we obtain @xmath94 combining , , and @xmath95 , we have @xmath96 and follows from the fact @xmath97    we now consider the end interval @xmath98 $ ] .    [ soe4 ]",
    "let @xmath80 and @xmath81 ( @xmath99 ) be the nodes and weights for @xmath30-point gauss - jacobi quadrature with the weight function @xmath100 on the interval .",
    "then for @xmath101 , @xmath82 and @xmath83 , @xmath102    the standard estimate for @xmath30-point gauss - jacobi quadrature @xcite yields @xmath103 ^ 2 } { ( 2n)![\\gamma(2n+\\beta)]^2 } \\max_{s\\in ( 0,a)}\\left|d^{2n}_s e^{-st}\\right|.\\ ] ] for @xmath83 , we have @xmath104 , @xmath105 , @xmath106 .",
    "thus , @xmath107 ^ 2 }            { [ ( 2n)!]^3}t^{2n}e^{-st}\\\\ & \\leq 2\\sqrt{\\pi}a^\\beta n^{3/2 } \\left(\\frac{e}{8}\\right)^{2n }   \\left(\\frac{at}{n}\\right)^{2n}. \\end{aligned}\\ ] ]    we are now in a position to combine the last three lemmas to give an efficient sum - of - exponentials approximation for @xmath65 on @xmath108 $ ] for @xmath82 .",
    "the proof is straightforward .",
    "[ soethm ] let @xmath109 ( @xmath110 and @xmath111 ) , let @xmath112 be the desired precision , let @xmath113 , let @xmath114 , and let @xmath115 .",
    "furthermore , let @xmath116 and @xmath117 be the nodes and weights for the @xmath118-point gauss - jacobi quadrature on the interval @xmath119 $ ] , let @xmath120 and @xmath121 be the nodes and weights for @xmath122-point gauss - legendre quadrature on small intervals @xmath123 $ ] , @xmath124 , where @xmath125 , and let @xmath126 and @xmath127 be the nodes and weights for @xmath128-point gauss - legendre quadrature on large intervals @xmath123 $ ] , @xmath129 , where @xmath130 .",
    "then for @xmath131 $ ] and @xmath82 , @xmath132    the important fact which emerges from this theorem is that the total number of exponentials needed to approximate @xmath65 for @xmath133 with an absolute error @xmath6 is given by the formula .",
    "efficient sum - of - exponentials approximation for the power function @xmath65 ( @xmath61 ) has been studied in detail both anaytically and algorithmically in a sequence of papers @xcite . in @xcite",
    ", it has been shown that for any @xmath61 the power function @xmath65 admits an efficient sum - of - exponentials approximation on the interval @xmath134 $ ] with a _ relative _ error @xmath6 , and the number of terms needed is @xmath135 .",
    "the proof in @xcite is constructive and relies on the truncated trapezoidal rule to discretize an integral from @xmath136 to @xmath137 . along the lines of @xcite , it is straightforward to show that the number of exponentials needed will be @xmath138 if one wants to bound the _ absolute _ error on the interval @xmath108 $ ] .    in @xcite , it has been shown that for any @xmath139 the power function @xmath65 admits an efficient sum - of - exponentials approximation on the interval @xmath140 $ ] with an _ absolute _ error @xmath6 , and the number of terms needed is @xmath141 .",
    "the proof in @xcite is also constructive , although it relies on the adaptive gaussian quadrature and utilizes asymptotic error formula for the gauss quadrature .",
    "the important difference between our result and the above theoretical results is that there is only @xmath142 term in , while @xmath143 term appears in both @xcite and @xcite .",
    "[ reduction ] the resulting number of exponentials following the construction in theorem [ soethm ] is unnecessarily large .",
    "one may apply modified prony s method in @xcite to reduce the number of exponentials for nodes on the interval @xmath144 , while standard model reduction method in @xcite can be applied to reduce the number of exponentials for nodes on the interval @xmath145 $ ] .",
    "+ table [ sumnum ] lists the actual number of exponentials needed to approximate @xmath4 with various precisions @xmath6 and @xmath146 after applying the reduction algorithms in remark [ reduction ] .",
    "we observe that the number of exponentials needed is very modest even for high accuracy approximations . indeed , one needs less than @xmath147 terms in order to march one million steps with @xmath148-digit accuracy .",
    "1.8cm0 cm      we replace the convolution kernel @xmath4 by its sum - of - exponentials approxiamtion in to approximate the history part defined in as follows : @xmath149 \\nonumber\\\\ & =   \\frac{1}{\\gamma(1-\\alpha ) } \\left[\\frac{u(t_{n-1})}{\\delta t^\\alpha } - \\frac{u(t_0)}{t_{n}^\\alpha } - \\alpha    \\sum_{i=1}^{{n_{\\text{exp } } } } \\omega_i u_{\\text{hist , i}}(t_{n } )   \\right].\\end{aligned}\\ ] ] to evaluate @xmath150 for @xmath151 , we observe the following simple recurrence relation : @xmath152 at each time step , we only need @xmath153 work to compute @xmath150 since @xmath154 is known at that point .",
    "thus , the total work is reduced from @xmath11 to @xmath12 , and the total memory requirement is reduced from @xmath9 to @xmath10",
    ".    one may compute the integral on the right hand side of by interpolating @xmath25 via a linear function and then evaluating the resulting approximation analytically .",
    "we have @xmath155 .",
    "\\end{aligned}\\ ] ] we note that the weights in front of @xmath51 and @xmath156 in are subject to significant cancellation error when @xmath157 is small . in that case , we can compute the weights by a taylor expansion of exponentials with a small number of terms .",
    "another popular fast method for computing the convolution with exponential functions is to solve the equivalent initial value problem for an ordinary differential equation .",
    "we would like to point out that in our case this may force one to choose a very small time step @xmath158 for the overall scheme .",
    "this is because @xmath57 ( @xmath159 ) usually varies in orders of different magnitudes and the resulting ode system will be very stiff .",
    "thus we prefer to evaluate the convolution via the simple recurrence relation .",
    "it is straightforward to verify that our scheme of evaluating the caputo fractional derivative is equivalent to the following formula    @xmath160\\nonumber\\\\    & = \\frac{\\delta t^{-\\alpha}}{\\gamma(1-\\alpha)}\\left(\\frac{u^n}{1-\\alpha }    -(\\frac{\\alpha}{1-\\alpha}+a_0)u^{n-1}\\right.\\nonumber\\\\    & \\left.-\\sum_{l=1}^{n-2}(a_{n - l-1}+b_{n - l-2})u^l    -(b_{n-2}+\\frac{1}{n^{\\alpha}})u^0\\right)\\nonumber\\\\    & \\triangleq { ^{fc}_{0}}\\mathbb{d}_t^{\\alpha}u^{n } ,   \\quad \\text{for } \\quad n>2 ,    \\label{deff}\\end{aligned}\\ ] ]    where @xmath161 noting that @xmath162 when @xmath163 , we have @xmath164 recall that the l1-approximation ( based on the linear interpolation of the density function ) of the caputo derivative @xmath165 ( see , for example , @xcite ) is defined by the formula @xmath166,\\label{ddiscaputo}\\end{aligned}\\ ] ] where @xmath167 the following lemma , which can be found in @xcite , established an error bound for the l1-approximation .",
    "[ see @xcite][lem4 ] suppose that @xmath168 $ ] and let @xmath169 where @xmath170 .",
    "then @xmath171    the following lemma provides an error bound for our approximation , denoted by @xmath172 in and .",
    "[ lemma6]suppose that @xmath173 $ ] and let @xmath174 where @xmath170 .",
    "then @xmath175    obviously the only difference between our approximation @xmath176 and the l1-approximation @xmath177 is that the convolution kernel admits an absolute error bounded by @xmath6 in its sum - of - exponentials approximation , namely , @xmath178 where @xmath179 . and the triangle inequality leads to @xmath180 where @xmath181 combining lemma [ lem4 ] and , we obtain lemma [ lemma6 ] .",
    "we also have the following useful inequality .",
    "the proof is given in appendix a.    [ lemma3 ] for any mesh functions @xmath182 defined on @xmath183 , the following inequality holds : @xmath184",
    "consider the following pure initial value problem of the linear fractional diffusion equation @xmath185 where the initial data @xmath186 and the source term @xmath187 are assumed to be compactly supported in the interval @xmath188 . to solve this problem using a finite difference scheme",
    ", one needs to truncate the computational domain to a finite interval and impose some boundary conditions at the end points , see @xcite .",
    "the exact nonreflecting boundary conditions for the above problem have been derived in @xcite via standard laplace transform method and it is shown in @xcite that the above problem is equivalent to the following initial - boundary value problem @xmath189      we now incorporate our fast evaluation scheme of the caputo fractional derivative into the existing finite difference scheme to construct a fast and stable fd scheme for solving the aforementioned ivp of the fractional diffusion equation .",
    "we first introduce some standard notations . for",
    "two given positive integers @xmath13 and @xmath16 , let @xmath190 be a equidistant partition of @xmath41 $ ] with @xmath191 and @xmath192 , and let @xmath193 be a partition of @xmath194 with @xmath195 and @xmath196 .",
    "denote @xmath197 , @xmath198 , and @xmath199    [ lem5 ] suppose that @xmath200 $ ] .",
    "then @xmath201 = -\\frac{h}{3 } u_{xxx}(x_0+\\theta_1 h ) , \\quad \\theta_1 \\in ( 0,1 ) , \\\\ & u_{xx}(x_{n_s } ) -\\frac{2}{h } \\left[u_x(x_{n_s})- \\delta_x u_{{n_s}- \\frac{1}{2 } } \\right ] = \\frac{h}{3 } u_{xxx}(x_{n_s } -\\theta_2 h ) , \\quad \\theta_2 \\in ( 0,1).\\end{aligned}\\ ] ]    the finite difference scheme in @xcite for the problem - can be written in the following form @xmath202+f^n_{0},\\label{schm2}\\\\ & { ^{c}_{0}}\\!\\mathbb{d}_t^{\\alpha}u^{n}_{n_s}=\\frac{2 } { h } \\left[-\\delta_x u^{n}_{{n_s}-\\frac{1}{2 } } -{^{c}_{0}}\\!\\mathbb{d}_t^{\\alpha/2}u^{n}_{n_s}\\right]+f^n_{{n_s}},\\label{schm3}\\\\ & u_i^{0}=u_0(x_i ) ,   \\quad   0\\leq i\\leq { n_s}.\\label{schm4}\\end{aligned}\\ ] ] replacing the standard l1-approximation @xmath203 for the caputo derivative by our fast evaluation scheme @xmath204 , we obtain a fast fd scheme of the following form @xmath205+f^n_{0},\\label{fschm2}\\\\ & { ^{fc}_{0}}\\!\\mathbb{d}_t^{\\alpha}u^{n}_{{n_s}}=\\frac{2 } { h } \\left[-\\delta_x u^{n}_{{n_s}-\\frac{1}{2 } } -{^{fc}_{0}}\\mathbb{d}_t^{\\alpha/2}u^{n}_{{n_s}}\\right]+f^n_{{n_s}},\\label{fschm3}\\\\ & u_i^{0}=u_0(x_i ) ,   \\quad   0\\leq i\\leq { n_s}.\\label{fschm4}\\end{aligned}\\ ] ]      let @xmath206 .",
    "we first recall an elementary property of the mesh function @xmath207 .",
    "[ 8 ] for any mesh function @xmath25 defined on @xmath208 , the following inequality holds @xmath209 where @xmath210 is the length of the computational domain and here @xmath211 .",
    "we now show the following prior estimate holds for the solution of the new fd scheme .",
    "[ theorem1 ] suppose @xmath212 is the solution of the finite difference scheme . then for any @xmath213 , @xmath214\\nonumber\\\\ & + \\frac{\\delta t}{8\\nu}\\sum_{k=1}^n\\left[(hf_0^k)^2+(hf_{n_s}^k)^2\\right]+\\frac{\\delta t}{\\mu}\\sum_{k=1}^nh\\sum_{i=1}^{{n_s}-1}(f_i^k)^2\\bigg),\\end{aligned}\\ ] ] where @xmath215    multiplying @xmath216 on both sides of ( [ fschm1 ] ) , and summing up for @xmath217 from 1 to @xmath218 , we have @xmath219 multiplying @xmath220 and @xmath221 on both sides of ( [ fschm2 ] ) and ( [ fschm3 ] ) , respectively , then adding the results with the above identity , we obtain @xmath222\\\\ \\nonumber & + ( { ^{fc}_{0}}\\!\\mathbb{d}_t^{\\frac{\\alpha}{2}}u_0^{k},u_0^{k})+({^{fc}_{0}}\\!\\mathbb{d}_t^{\\frac{\\alpha}{2}}u_{n_s}^{k},u_{n_s}^{k } ) = \\frac{1}{2}(hf_0^k)u_0^k+h\\sum_{i=1}^{{n_s}-1}f_i^ku_i^k+\\frac{1}{2}(f_{n_s}^k)u_{n_s}^k.\\end{aligned}\\ ] ] observing the summation by parts , we have @xmath223 substituting ( [ 4 ] ) into ( [ 5 ] ) , and multiplying @xmath158 on both sides of the resulting identity , and summing up for @xmath224 from 1 to @xmath30 , it follows from lemma [ lemma3 ] that @xmath225+\\delta t\\sum_{k=1}^n\\left\\|\\delta_xu^k\\right\\|^2\\nonumber\\\\ \\leq&\\frac{t_n^{1-\\alpha}-\\alpha(1-\\alpha)\\varepsilon t_{n-1}\\delta t}{\\gamma(2-\\alpha)}\\left\\|u^0\\right\\|^2+\\frac{t_n^{1-\\frac{\\alpha}{2}}-\\frac{\\alpha}{2}(1-\\frac{\\alpha}{2})\\varepsilon t_{n-1}\\delta",
    "t}{\\gamma(2-\\frac{\\alpha}{2})}\\left[(u_0 ^ 0)^2+(u_{n_s}^0)^2\\right]\\nonumber\\\\ & + \\delta t\\sum_{k=1}^n\\left[\\frac{1}{2}(hf_0^k)u_0^k+h\\sum_{i=1}^{{n_s}-1}f_i^ku_i^k+\\frac{1}{2}(f_{n_s}^k)u_{n_s}^k\\right].\\label{7}\\end{aligned}\\ ] ] applying the cauchy - schwarz inequality , we obtain @xmath226+\\frac{\\gamma(1-\\frac{\\alpha}{2})}{8(t_n^{-\\frac{\\alpha}{2}}-\\alpha\\varepsilon t_{n-1})}\\left[(hf_0^k)^2+(hf_{n_s}^k)^2\\right]\\nonumber\\\\ & + h\\sum_{i=1}^{{n_s}-1}\\left[\\frac{t_n^{-\\alpha}-2\\alpha\\varepsilon t_{n-1}}{4\\gamma(1-\\alpha)}(u_i^k)^2+\\frac{\\gamma(1-\\alpha)}{t_n^{-\\alpha}-2\\alpha\\varepsilon t_{n-1}}(f_i^k)^2\\right]\\nonumber\\\\ \\leq&\\frac{t_n^{-\\frac{\\alpha}{2}}-\\alpha\\varepsilon t_{n-1}}{2\\gamma(1-\\frac{\\alpha}{2})}\\left[(u_0^k)^2+(u_{n_s}^k)^2\\right]+\\frac{\\gamma(1-\\frac{\\alpha}{2})}{8(t_n^{-\\frac{\\alpha}{2}}-\\alpha\\varepsilon t_{n-1})}\\left[(hf_0^k)^2+(hf_{n_s}^k)^2\\right]\\nonumber\\\\ & + \\frac{t_n^{-\\alpha}-2\\alpha\\varepsilon t_{n-1}}{4\\gamma(1-\\alpha)}\\left\\|u^k\\right\\|^2+h\\sum_{i=1}^{{n_s}-1}\\frac{\\gamma(1-\\alpha)}{t_n^{-\\alpha}-2\\alpha\\varepsilon t_{n-1}}(f_i^k)^2 . \\label{6}\\end{aligned}\\ ] ] the substitution of ( [ 6 ] ) into ( [ 7 ] ) produces @xmath227 \\nonumber\\\\   & + \\frac{\\delta t}{8\\nu}\\sum_{k=1}^n\\left[(hf_0^k)^2+(hf_{n_s}^k)^2\\right]+\\frac{\\delta",
    "t}{\\mu}\\sum_{k=1}^nh\\sum_{i=1}^{{n_s}-1}(f_i^k)^2.\\end{aligned}\\ ] ] taking @xmath228 such that @xmath229 ( i.e. , @xmath230 ) , and following from lemma [ 8 ] , we have @xmath231 combining ( [ 10 ] ) with ( [ 9 ] ) , we obtain the inequality .",
    "the priori estimate leads to the stability of the new fd scheme .",
    "the scheme ( [ fschm1])-([fschm4 ] ) is unconditionally stable for any given compactly supported initial data and source term .",
    "we now present an error analysis of the new scheme - .",
    "suppose @xmath232\\times[0,t])$ ] and @xmath233 are solutions of the problem ( [ exacta1])-([exacta3 ] ) and the difference scheme ( [ fschm1])-([fschm4 ] ) , respectively .",
    "let @xmath234 .",
    "then there exists a positive constant @xmath235 such that @xmath236 where @xmath237 with @xmath238 is a positive constant ( see - , and @xmath239 , @xmath240 are defined in .",
    "we observe that the error @xmath241 satisfies the following fd scheme : @xmath242+t^k_{0},\\label{eq2}\\\\ & { ^{fc}_{0}}\\!\\mathbb{d}_t^{\\alpha}e^{k}_{{n_s}}=\\frac{2 } { h } \\left[-\\delta_x e^{n}_{{n_s}-\\frac{1}{2 } } -{^{fc}_{0}}\\mathbb{d}_t^{\\alpha/2}e^{k}_{{n_s}}\\right]+t^k_{{n_s}},\\label{eq3}\\\\ & e_i^{0}=0 ,   \\quad   0\\leq i\\leq { n_s}.\\label{eq4}\\end{aligned}\\ ] ] where the truncation terms @xmath243 at the interior and boundary points are given by the formulas @xmath244+\\left[u_{xx}(x_i , t_k)-\\delta_x^2u_i^k\\right],~~1\\leq i\\leq { n_s},~1\\leq k\\leq n_t,\\\\ & t_0^k=\\left\\{u_{xx}(x_0,t_k)-\\frac{2}{h}\\left[\\delta_xu_{\\frac{1}{2}}^k - u_x(x_0,t_k)\\right]-\\frac{2}{h}\\left[{_{0}^{c}\\!}d_t^{\\frac{\\alpha}{2}}u(x_0,t_k)-{^{fc}_{0 } } \\mathbb{d}_t^{\\frac{\\alpha}{2}}u_0^k\\right]\\right\\}\\nonumber\\\\ & \\qquad-\\left[{_{0}^{c}\\!}d_t^{\\alpha}u(x_0,t_k)-{^{fc}_{0 } } \\mathbb{d}_t^{\\alpha}u_0^k\\right],~1\\leq k\\leq n_t,\\\\ & t_{n_s}^k=\\left\\{u_{xx}(x_{n_s},t_k)-\\frac{2}{h}\\left[u_x(x_{n_s},t_k)-\\delta_xu_{{n_s}-\\frac{1}{2}}^k\\right]-\\frac{2}{h}\\left[{_{0}^{c}\\!}d_t^{\\frac{\\alpha}{2}}u(x_{n_s},t_k)-{^{fc}_{0 } } \\mathbb{d}_t^{\\frac{\\alpha}{2}}u_{n_s}^k\\right]\\right\\}\\nonumber\\\\ & \\qquad-\\left[{_{0}^{c}\\!}d_t^{\\alpha}u(x_{n_s},t_k)-{^{fc}_{0 } } \\mathbb{d}_t^{\\alpha}u_{n_s}^k\\right],~1\\leq k\\leq n_t.\\end{aligned}\\ ] ] using lemma [ lem5 ] and taylor expansion , it is easy to show that the truncation terms @xmath243 satisfy the following error bounds @xmath245 with @xmath238 some positive constant .",
    "thus , for @xmath246 and @xmath247 , we have @xmath248+\\frac{2}{\\mu}h\\sum_{i=1}^{{n_s}-1}(t_i^k)^2\\nonumber\\\\ \\leq&\\frac{c_1 ^ 2}{2\\nu}\\big(h\\delta t^{2-\\alpha}+\\delta t^{2-\\frac{\\alpha}{2}}+h^2+{\\varepsilon}\\big)^2+\\frac{2c_1 ^ 2l}{\\mu}\\big(\\delta t^{2-\\alpha}+h^2+{\\varepsilon}\\big)^2\\nonumber\\\\ \\leq&\\frac{2c_1 ^ 2}{\\nu}\\big(\\delta t^{2-\\alpha}+h^2+{\\varepsilon}\\big)^2+\\frac{2c_1 ^ 2l}{\\mu}\\big(\\delta t^{2-\\alpha}+h^2+{\\varepsilon}\\big)^2\\nonumber\\\\ \\leq&4c_1 ^ 2(\\frac{1}{\\nu}+\\frac{l}{\\mu})(\\delta t^{2-\\alpha}+h^2)+4c_1 ^ 2(\\frac{1}{\\nu}+\\frac{l}{\\mu}){\\varepsilon}^2\\end{aligned}\\ ] ] a direct application of theorem [ theorem1 ] to the system ( [ eq1])-([eq4 ] ) produces @xmath249+\\frac{2}{\\mu}h\\sum_{i=1}^{{n_s}-1}(t_i^k)^2).\\end{aligned}\\ ] ] substituting ( [ convergenceeq2 ] ) into ( [ convergenceeq1 ] ) , simplifying the resulting expressions , and taking the square root for both sides , we obtain .",
    "cm    0cm0 cm    ) plot of the cpu time ( in seconds ) versus the total number of time steps @xmath13 for application i. here @xmath250 and @xmath251 .",
    ", scaledwidth=45.0% ]      to test the convergence rates of the new scheme , we take the computational domain @xmath252 $ ] , and set @xmath253\\\\ + 4(3\\pi^2 - 14\\pi x+14x^2)\\},\\quad(x , t)\\in\\omega_i,\\\\ 0,\\quad(x , t)\\notin\\omega_i , \\end{cases } & \\notag\\\\ & u_0(x)= \\begin{cases } x^4(\\pi - x)^4,\\quad(x , t)\\in\\omega_i,\\\\ 0,\\quad(x , t)\\notin\\omega_i .",
    "\\end{cases}\\end{aligned}\\ ] ] it is known that the ivp  has the exact solution given by the formula @xmath254,\\quad(x , t)\\in\\omega_i \\times ( 0,t].\\end{aligned}\\ ] ] to illustrate the performance of the numerical scheme , we define the maximum norm of the error and the convergence rates with respect to temporal and spatial sizes , respectively by the formulas @xmath255 where the error @xmath256 is measured against the exact solution .",
    "first , we check the convergence rate of the new scheme in time .",
    "we fix the spatial mesh size @xmath257 and refine the temporal mesh size @xmath258 from @xmath259 to @xmath260 .",
    "obviously , @xmath261 is chosen so small that the error due to spatial discretization is negligible .",
    "the precision for the sum - of - exponentials approximation for the convolution kernel is set to @xmath262 .",
    "table [ tab1 ] shows the numerical results for two different fractional values : @xmath263 and @xmath251 .",
    "next , we fix the temporal mesh size @xmath264 so that the error due to temporal discretization is neglible .",
    "we then change the spatial step size @xmath261 from @xmath265 to @xmath266 to check the convergence order of the new scheme in space .",
    "table [ tab2 ] shows the numerical results for @xmath263 and @xmath251 .",
    "table [ tab1 ] shows that the convergence order in time is @xmath267 for both the direct scheme - and our fast scheme - . while table [ tab2 ] shows that the convergence order in space is @xmath268 for both the direct scheme and our fast scheme .    to demonstrate the complexity of the two schemes , we plot in fig [ fig1 ] the cpu time of the two schemes in seconds .",
    "we observe that while the direct scheme scales like @xmath11 , the cpu time increases almost linearly with the total number of time steps @xmath13 for the fast scheme .",
    "there is a significant speed - up in fast scheme as compared with the direct scheme even for @xmath13 of modest size .",
    "consider now the initial value problem of the nonlinear fractional diffusion equation of the form @xmath269 this problem has rich applications .",
    "when @xmath270 , is the fisher equation , which is used to model the spatial and temporal propagation of a virile gene in an infinite medium @xcite , the chemical kinetics @xcite , flame propagation @xcite , and many other scientific problems @xcite . when @xmath271 , is the time - fractional huxley equation , which is used to describe the transmission of nerve impulses @xcite with many applications in biology and the population genetics in circuit theory @xcite",
    "when the initial data @xmath272 is compactly supported on @xmath273 $ ] , the following finite difference scheme with artificial boundary conditions imposed on two end points has been proposed in @xcite to solve the problem @xmath274 under the assumption that @xmath275)$ ] , it has been shown in @xcite that the scheme the convergence rate of @xmath276 in @xmath277 norm , defined by @xmath278 . with the l1-approximation @xmath279 replaced by our fast evaluation scheme @xmath280 , we obtain a fast scheme for solving , which is as follows : @xmath281      we will give two examples - the fisher equation and the huxley equation to illustrate the performance of our scheme . for both examples , in order to investigate the convergence orders of our scheme , the reference solution is computed over a large interval @xmath282 $ ] with very small mesh sizes @xmath283 , and @xmath284 .",
    "we then set @xmath285 $ ] and the precision for the sum - of - exponentials approximation of the convolution kernel to @xmath286 .",
    "the temporal step size is fixed at @xmath284 when testing the order of convergence in space ; and the spatial step size is fixed at @xmath287 when testing the order of convergence in time .",
    "[ exm2 ]    we consider the time fractional fisher equation @xmath288 with the double gaussian initial value @xmath289 .",
    "tables [ tab3 ] and [ tab4 ] present the numerical results for @xmath290 , which show that our fast scheme ( [ 3.9f])-([3.11f ] ) has the same convergence order @xmath276 in @xmath277 norm as the direct scheme ( [ 3.8])-([3.11 ] ) , but takes much less computational time .",
    "0cm0 cm    0cm0 cm    we consider the fractional huxley equation @xmath291 with the double gaussian initial value @xmath289 .",
    "tables [ tab5 ] and [ tab6 ] present the numerical results for @xmath290 , which show that our fast scheme ( [ 3.9f])-([3.11f ] ) has the same convergence order @xmath276 in @xmath277 norm as the direct scheme ( [ 3.8])-([3.11 ] ) , but takes much less computational time .    to demonstrate the complexity of the two schemes , we plot in fig .",
    "[ fig2 ] the cpu time in seconds for both schemes .",
    "we observe that our fast scheme has almost linear complexity in @xmath13 and is much faster than the direct scheme .",
    "0cm0 cm    0cm0 cm    ) plot of the cpu time ( in seconds ) versus the total number of time steps @xmath13 for two schemes . here",
    "@xmath292 and @xmath251 .",
    "the left panel shows the results for the fisher equation , and the right panel shows the results for the huxley equation.,title=\"fig:\",scaledwidth=45.0% ] ) plot of the cpu time ( in seconds ) versus the total number of time steps @xmath13 for two schemes . here",
    "@xmath292 and @xmath251 .",
    "the left panel shows the results for the fisher equation , and the right panel shows the results for the huxley equation.,title=\"fig:\",scaledwidth=45.0% ]",
    "we have developed a fast algorithm for the evaluation of the caputo fractional derivative @xmath293 for @xmath26 .",
    "the algorithm relies on an efficient sum - of - exponentials approximation for the convolution kernel @xmath4 with the absolute error @xmath6 over the interval @xmath5 $ ] .",
    "specifically , we have shown that the number of exponentials needed in the approximation is of the order @xmath294 @xmath295 , which removes the term @xmath143 in @xcite .",
    "the resulting algorithm has nearly optimal complexity in both cpu time and storage .",
    "we then applied our fast evaluation scheme of the caputo derivative to solve the fractional diffusion equations .",
    "we first demonstrated that it is straightforward to incorporate our fast algorithm into the existing finite difference schemes for solving the fractional diffusion equations .",
    "we then proved a prior estimate about the solution of our new fd scheme which leads to the stability of the new scheme .",
    "we also presented a rigorous error bound for the new scheme .",
    "finally , the numerical results on linear and nonlinear fraction diffusion equations show that our new scheme has the same order of convergence as the existing standard fd schemes , but with nearly optimal complexity in cpu time and storage .",
    "our work can be extended along several directions .",
    "first , it is straightforward to design high order schemes for the evaluation of fractional derivatives .",
    "second , one may develop fast high - order algorithms for solving fractional pdes which contains fractional derivatives in both time and space when the current scheme is combined with other existing schemes @xcite .",
    "third , efficient and stable artificial boundary conditions can be designed using similar techniques in @xcite for solving fractional pdes in high dimensions .",
    "these issues are currently under investigation and the results will be reported on a later date .",
    "applying the definition of the fast evaluation scheme and the cauchy - schwarz inequality , we have @xmath296.\\end{aligned}\\ ] ] summing the above inequality from @xmath297 to @xmath30 , we obtain @xmath298\\nonumber\\\\ & = \\frac{\\delta t^{1-\\alpha}}{\\gamma(1-\\alpha)}\\sum_{k=1}^n\\bigg(c_k(g^k)^2-c_0(g^0)^2\\bigg),\\end{aligned}\\ ] ]    where the coefficients @xmath299 ( @xmath300 ) are given by the formula @xmath301 from , we have the estimate @xmath302 it is also straightforward to verify that @xmath303 combining and , we obtain @xmath304                  , _ artificial boundary conditions and finite difference approximations for a time - fractional diffusion - wave equation on a two - dimensional unbounded spatial domain _ , j. comput",
    ". phys . , * 276 * ( 2014 ) , 541562 .                                                                                                , _ approximate conditional symmetries and approximate solutions of the perturbed fitzhugh - nagumo equation _ ,",
    "phys , * 46 * ( 2005 ) , 023503 . , _ a fully discrete difference scheme for a diffusion - wave system _ , appl .",
    ", * 56 * ( 2006 ) , 193209 ."
  ],
  "abstract_text": [
    "<S> we present an efficient algorithm for the evaluation of the caputo fractional derivative @xmath0 of order @xmath1 , which can be expressed as a convolution of @xmath2 with the kernel @xmath3 . </S>",
    "<S> the algorithm is based on an efficient sum - of - exponentials approximation for the kernel @xmath4 on the interval @xmath5 $ ] with a uniform absolute error @xmath6 , where the number of exponentials @xmath7 needed is of the order @xmath8 . as compared with the direct method , </S>",
    "<S> the resulting algorithm reduces the storage requirement from @xmath9 to @xmath10 and the overall computational cost from @xmath11 to @xmath12 with @xmath13 the total number of time steps . </S>",
    "<S> furthermore , when the fast evaluation scheme of the caputo derivative is applied to solve the fractional diffusion equations , the resulting algorithm requires only @xmath14 storage and @xmath15 work with @xmath16 the total number of points in space ; whereas the direct methods require @xmath17 ) storage and @xmath18 work . </S>",
    "<S> the complexity of both algorithms is nearly optimal since @xmath7 is of the order @xmath19 for @xmath20 or @xmath21 for @xmath22 for fixed accuracy @xmath6 . </S>",
    "<S> we also present a detailed stability and error analysis of the new scheme for solving linear fractional diffusion equations . </S>",
    "<S> the performance of the new algorithm is illustrated via several numerical examples . </S>",
    "<S> finally , the algorithm can be parallelized in a straightforward manner .    </S>",
    "<S> fractional derivative , caputo derivative , sum - of - exponentials approximation , fractional diffusion equation , fast convolution algorithm , stability analysis .    33c10 , 33f05 , 35q40 , 35q55 , 34a08 , 35r11 , 26a33 . </S>"
  ]
}