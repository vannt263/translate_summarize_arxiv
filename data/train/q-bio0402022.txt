{
  "article_text": [
    "the observed irregularity and relatively low rates of the firing of neocortical neurons suggest strongly that excitatory and inhibitory input are nearly balanced .",
    "such a balance , in turn , finds an attractive explanation in the mean - field descriptions of amit and brunel @xcite and van vreeswijk and sompolinsky @xcite . in their theories ,",
    "the balance does not have to be put in `` by hand '' ; rather , it emerges self - consistently from the network dynamics .",
    "this success encourages us to study firing correlations and irregularity in models like theirs in greater detail .",
    "in particular , we would like to quantify the irregularity and identify the parameters of the network that control it .",
    "this is important because one can not extract the signal in neuronal spike trains correctly without a good characterization of the noise .",
    "indeed , an incorrect noise model can lead to spurious conclusions about the nature of the signal , as demonstrated by oram _",
    "et al _ @xcite .",
    "response variability has been studied for a long time in primary visual cortex @xcite and elsewhere @xcite .",
    "most , though not all , of these studies found rather strong irregularity .",
    "as an example , we consider the findings of gershon _ et al _ @xcite . in their experiments , monkeys were presented with flashed , stationary visual patterns for several hundred ms",
    ". repeated presentations of a given stimulus evoked varying numbers of spikes in different trials , though the mean number ( as well as the psth ) varied systematically from stimulus to stimulus .",
    "the statistical objects of interest to us here are the distributions of single - trial spike counts , for given fixed stimuli .",
    "often one compares the data with a poisson model of the spike trains , for which the count distribution @xmath0 .",
    "this distribution has the property that its mean @xmath1 is equal to its variance @xmath2 .",
    "however , the experimental finding was that the measured distributions were quite generally wider than this : @xmath3 .",
    "furthermore , collecting data for many stimuli , the variance of the spike count was fit well by a power law function of the mean count : @xmath4 , with @xmath5 typically in the range @xmath6 , broadly consistent with the results of many of the other studies cited above .",
    "some of this observed variance could have a simple explanation : the condition of the animal might have changed between trials , so the intrinsic rate at which the neuron fires might differ from trial to trial , as suggested by tolhurst _",
    "et al _ @xcite .",
    "but it is far from clear whether all the variance can be accounted for in this way .",
    "moreover , there is no special reason to take a poisson process as the null hypothesis , so we do nt even really know how much variance we are trying to explain .    in this paper",
    ", we try to address the question of how much variability , or more generally , what firing correlations can be expected as consequence of the intrinsic dynamics of cortical neuronal networks .",
    "the theories of amit and brunel and of van vreeswijk and sompolinsky do not permit a consistent study of firing correlations .",
    "the amit - brunel treatment assumes that the input to neurons is uncorrelated in time ( white noise ) .",
    "thus , although one can calculate the variability of the firing @xcite , it is not self - consistent .",
    "van vreeswijk and sompolinsky use a binary - neuron model with stochastic dynamics which makes it difficult , if not impossible , to study temporal correlations that might occur in networks of spiking neurons .",
    "therefore , in this paper we do a complete mean - field theory for a network of leaky integrate - and - fire neurons , including , as self - consistently - determined order parameters , both firing rates and autocorrelation functions .",
    "a general formalism for doing this was introduced by fulvi mari @xcite and used for an all - excitatory network ; here we employ it for a network with both excitatory and inhibitory neurons .",
    "a preliminary study of this approach for an all - inhibitory network was presented previously @xcite .",
    "the model network , indicated schematically in fig .  [ fig : network ] , consists of @xmath7 excitatory neurons and @xmath8 inhibitory ones . in this work",
    "we use leaky integrate - and - fire neurons , though the methods could be carried over directly to networks of other kinds of model neurons , such as conductance - based ones .",
    "they are randomly interconnected by synapses , both within and between populations , with the mean number of connections from population @xmath9 to population @xmath10 equal to @xmath11 , independent of @xmath10 . in specific calculations ,",
    "we have used @xmath12 from 400 to 6400 , and we take @xmath13 .",
    "the population sizes @xmath14 do not enter directly in the mean field theory , only their ratios ( the connection probabilities ) @xmath15 .",
    "we have used @xmath16 for both excitatory and inhibitory connections , implying @xmath17 .",
    "we scale the synaptic strengths in the way van vreeswijk and sompolinsky did@xcite , with each nonzero synapse from population @xmath9 to population @xmath10 having the value @xmath18 .",
    "the parameters @xmath19 are taken to be of order 1 , so the net input current to a neuron from the @xmath11 neurons in population @xmath9 connected to it is of order @xmath20 . with this scaling , the fluctuations in this current",
    "are of order 1 .",
    "similarly , we assume that the external input to any neuron is the sum of @xmath21 contributions from individual neurons ( in the lgn , if we are thinking about modeling v1 ) , each of order @xmath22 , so the net input is of order @xmath23 . in our calculations ,",
    "we have used @xmath24 .",
    "we point out that this scaling is just for convenience in thinking about the problem . in the balanced asynchronous firing state ,",
    "the large excitatory and inhibitory input currents nearly cancel , leaving a net input current of order 1 .",
    "thus , for this choice , both the net mean current and its typical fluctuations are of order 1 , which is convenient for analysis .",
    "the physiologically relevant assumptions are only that excitatory and inhibitory inputs are separately much larger than their sum and that the latter is of the same order as its fluctuations .",
    "our synapses are not modeled as conductances .",
    "our synaptic strength simply defines the amplitude of the postsynaptic current pulse produced by a single presynaptic spike .    the model is formally specified by the sub - threshold equations of motion for the membrane potentials @xmath25 ( @xmath26 , @xmath27 ) : = - + _ b=0 ^ 2 _ j=1^n_b j_ij^ab s_j^b(t ) , [ eq : model ] together with the condition that when @xmath25 reaches the threshold @xmath28 , the neuron spikes and the membrane potential is reset to a value @xmath29 .",
    "the indices @xmath10 or @xmath30 or 2 label populations : @xmath31 refers to the ( excitatory ) population providing the external input , @xmath32 refers to the excitatory population and @xmath33 to the inhibitory population . in ( [ eq : model ] )",
    ", @xmath34 is the membrane time constant ( taken the same for all neurons , for convenience ) , the strength of the synapse from neuron @xmath35 in population @xmath9 to neuron @xmath36 in population @xmath10 is denoted by @xmath37 , and @xmath38 is the spike train of neuron @xmath35 in population @xmath9 .",
    "we have ignored transmission delays , and we take the thresholds @xmath39 and the reset levels @xmath29 equal to the rest value of the membrane potential , 0 . in our calculations , the thresholds are given a gaussian distribution with a standard deviation equal to 10% of the mean .",
    "analogous variability in other single - cell parameters ( such as membrane time constants ) could also be included in the model , but for simplicity we do not do so here .",
    "we assume that the neurons in the external input population ( @xmath31 ) fire as independent poisson processes",
    ". however , the neurons in the network ( @xmath40 ) are not in general poissonian ; it is their correlations that we want to find in this investigation .",
    "we describe the mean field theory and its computational implementation first for the case of stationary rates .",
    "when the connectivity is large and random , as we will assume here , each of the three terms in the sum on @xmath9 on the right - hand side of ( [ eq : model ] ) can be treated as a gaussian random function with time - independent mean .",
    "the simplest case is @xmath31 , the external input . for simplicity , we assume that all @xmath41 neurons in the external population fire at the same rate , @xmath42 . but",
    "because of the random connectivity , the net time - averaged input current they provide to a neuron in cortical population @xmath10 can vary from neuron to neuron . assuming large ,",
    "dilute connectivity ( @xmath43 and @xmath44 ) , the central limit theorem then implies i_i^a0(t ) = _ j",
    "j_ij^a0 r_0 = _ j ( + j_ij^a0)r_0 = j_a0r_0(+ x_i^a0 ) , eq : invar where @xmath45 is a gaussian - distributed random number of unit variance .",
    "by @xmath46 we mean a time average or , equivalently , an average over  trials \" ( independent repetitions of the poisson processes defining the input population neurons ) .",
    "we will generally use a bar over a quantity to indicate an average over the neuronal population or over the distribution of the @xmath37 .",
    "( note that these two kinds of averages are very different things . )",
    "writing the spike train @xmath47 for neuron @xmath35 in the input population as s_j^0(t ) = r_0 + s_j^0(t ) , eq : rplusds with @xmath48 , we can write the fluctuations around @xmath49 as i_i^a0(t ) = _ j",
    "j_ij^a0 s_j^0(t ) = j_a0 _ i^a0(t ) eq : innoise where @xmath50 is white noise of power @xmath42 : _",
    "i^a0(t ) = r_0 ( t - t ) eq : innoisecorr thus , quite generally , the input has a large mean value , of order @xmath23 , plus gaussian fluctuations of order 1 .",
    "the fluctuations are of two kinds .",
    "one is constant for a given neuron , independent of time and trial and arises from the fact that the connectivity is random and the neurons in the input population have a distribution of rates .",
    "the other fluctuation is a dynamical one , with correlations ( independent of @xmath36 ) reflecting the poisson dynamics of the input population neurons .",
    "the recurrent input terms @xmath51 also have large means and fluctuations , static and dynamic , of order 1 , but certain features of their statistics are slightly different , as a systematic formal derivation @xcite proves .",
    "here we do not give the derivation , but just describe the result , which is that @xmath51 can be written i_i^ab(t ) = j_ab [ r_b + b_b x_i^ab+ _ i^ab(t ) ] , [ eq : decrec ] with r_b = = _ j r_j^b .",
    "eq : meanrate the average rate in population @xmath9 , @xmath52 a unit - variance gaussian random number , b_b = eq : bb and _ i^ab(t ) _",
    "i^ab(t ) = c_b(t - t ) .",
    "eq : recnoise here @xmath53 is the average autocorrelation function of the firing of neurons in population @xmath9 , c_b(t - t ) = _ j s_j^b(t)s_j^b(t ) , eq : corrfn with s_j^b(t)= s_j^b(t)-r_j^b .",
    "eq : dsjb again , @xmath52 is time- and trial - independent , while the noise @xmath54 varies both in time within a trial and randomly from trial to trial .",
    "note that for this model a correct and complete mean field theory has to include rate fluctuations , through @xmath55 , and the firing correlations , given by @xmath53 , as well as the mean rates .",
    "the means of the recurrent input currents @xmath56 are completely analogous to the mean term in @xmath57 , but the effective noise is different in three ways    1 .",
    "the amplitude @xmath58 of the static noise component ( the second term ) contains a factor of the rms rate @xmath59 , not @xmath60 as in ( [ eq : invar ] ) .",
    "the same would be true for the static input noise ( @xmath31 ) if we allowed a distribution of rates in the input population .",
    "so this difference is not an essential one .",
    "it occurs only because we made a simplifying assumption about the input population .",
    "however , we are not allowed to assume that about the neurons in the cortical network , which will always have a distribution of rates because of the random connectivity .",
    "the neurons providing the source of these currents are not generally poissonian , so their correlations appear in the statistics of the noise term .",
    "the noise terms , both static and dynamic , have a factor @xmath61 in front of them .",
    "this can be understood in the following way : it is the randomness in the synaptic connections in the network that generates these noise terms in the effective single - neuron problem ; in general , they are proportional to @xmath62 , which is equal to @xmath63 in our model . in the limit of full connectivity , @xmath64 ,",
    "all @xmath37 are equal and there is no randomness .",
    "therefore there is no noise , as guaranteed here by this factor .",
    "the self - consistency equations of mean field theory are simply the conditions that the average output statistics of the neurons , @xmath65 , @xmath66 and @xmath67 are the same as those used to generate the inputs for single neurons using integrate - and - fire neurons with synaptic input currents given by ( [ eq : invar ] ) , ( [ eq : innoise ] ) and ( [ eq : decrec ] ) .    in an equivalent formulation , the second term in ( [ eq : decrec ] )",
    "can be omitted if the noise terms @xmath54 have correlations equal to the unsubtracted correlation function c_b^tot(t - t ) = _ j s_j^b(t ) s_j^b(t)eq : ctot instead of ( [ eq : corrfn ] ) .",
    "for @xmath68 , @xmath69 , so @xmath54 acquires a random static component of mean square value @xmath55 .    in still another way to do it",
    ", one can use the square of the average rate , @xmath70 in place of @xmath71 in eq.([eq : bb ] ) for @xmath58 and employ noise with correlation function c_b(t - t ) = _ j ( s_j^b(t)-r_b)(s_j^b(t)-r_b ) .",
    "eq : ctilde for @xmath68 , c_b(t - t ) .",
    "eq : ctildelimit there are now two static random parts of @xmath51 , one from the @xmath58 term and one from the static component of the noise . their sum is a gaussian random number with standard deviation equal to @xmath58 as given in ( [ eq : decrec ] ) .",
    "thus these three ways of generating the input currents are all equivalent .      in a stationary , low - rate state",
    ", the mean membrane potential described by ( [ eq : model ] ) has to be stationary .",
    "if excitation dominates , we have @xmath72 , implying a firing rate of order @xmath23 ( or one limited only by the refractory period of the neuron )",
    ". if inhibition dominates , the neuron will never fire .",
    "the only way to have a stationary state at a low rate ( less than one spike per membrane time constant ) is to have the excitation and inhibition nearly cancel .",
    "then the mean membrane potential can lie a little below threshold , and the neuron can fire occasionally due to the input current fluctuations . thus , using ( [ eq : invar ] ) and ( [ eq : decrec ] ) , we have _ b=0 ^ 2 j_abr_b = o(1 ) eq : balance or , up to corrections of @xmath73 , _ b=0 ^ 2 j_ab r_b = 0 eq : normbal with @xmath74 .",
    "these are two linear equations in the two unknowns @xmath65 , @xmath75 , with the solution r_a = _",
    "b=1 ^ 2 [ j^-1]_ab j_b0r_0 , eq : balsoln where @xmath76 is the inverse of the @xmath77 matrix with elements @xmath78 , @xmath79 .",
    "if there is a stationary balanced state , the average rates of the excitatory and inhibitory populations are given by ( [ eq : balsoln ] ) ( in the large-@xmath80 limit ) .",
    "this argument depends only on the rates , not on the correlations , and is exactly the same as that given by amit and brunel and by sompolinsky and van vreeswijk .",
    "this calculation does not say whether this state is stable , however . to determine this",
    ", one can expand around this solution and examine the linear stability of the fluctuations , as done for their model by van vreeswijk and sompolinsky @xcite .",
    "here , we do not do this analytically , but rather check the stability of our states numerically within our algorithm .      for integrate - and - fire neurons in a stationary state , the mean field theory can be carried out analytically if a white - noise ( poisson firing ) approximation is made @xcite .",
    "but if firing correlations are to be taken into account , it is necessary to resort to numerical methods .",
    "thus we simulate single neurons driven by gaussian synaptic currents , collect their firing statistics to compute the rates @xmath65 , rate fluctuations @xmath81 and correlations @xmath67 , and then use these to generate improved input current statistics .",
    "the cycle is repeated until the input and output statistics are consistent .",
    "this algorithm was first used by eisfeller and opper @xcite to calculate the remanent magnetization of a mean field model for spin glasses .",
    "explicitly , we proceed as follows .",
    "we simulate single excitatory and inhibitory neurons over `` trials '' 100 integration timesteps long .",
    "( we will call each timestep a `` millisecond '' .",
    "we have explored using smaller timesteps and verified that there are no qualitative changes in the results . )",
    "we start from estimates of the rates given by the balance condition , which makes the net mean input current vanish .",
    "then the sum of the @xmath82 terms in ( [ eq : invar ] ) and ( [ eq : decrec ] ) vanishes , leaving only the rate fluctuation and noise terms .",
    "we then run 10000 trials of single excitatory and inhibitory neurons , selecting on each trial random values of @xmath52 and @xmath54 .",
    "since at this point we do not have any estimates of either the rate fluctuations @xmath83 or the correlations @xmath53 , we use @xmath70 in place of @xmath71 in eq.([eq : bb])for @xmath58 and use white noise for @xmath54 : @xmath84 .",
    "the random choice of @xmath85 from trial to trial effectively samples across the neuronal populations , so we can then collect the statistics @xmath65 , @xmath66 ( or , equivalently , @xmath81 ) , and @xmath67 from these trials .",
    "these can be used to generate an improved estimate of the input noise statistics to be used in ( [ eq : decrec ] ) in a second set of trials , which yields new spike statistics again .",
    "this procedure is iterated until the input and output statistics agree .",
    "this may take up to several hundred iterations , depending on network parameters and how the computation is organized .",
    "if one tries this procedure in its naive form , i.e. , using the output statistics directly to generate the input noise at the next step , it will lead to big oscillations and not converge .",
    "it is necessary to make small corrections ( of relative order @xmath86 ) to the previous input noise statistics to guarantee convergence .    when one computes statistics from the trials in any iteration , the simplest procedure involves calculating not ( [ eq : corrfn ] ) , but rather @xmath87 ( eq.([eq : ctilde ] ) ) .",
    "from it , we can proceed in two ways . in the first , from its @xmath88 limit we can obtain @xmath83 , and thereby @xmath89 for use in calculating @xmath58 in ( [ eq : bb ] ) .",
    "subtracting this limiting value from @xmath87 give us @xmath53 ( which vanishes for large @xmath90 ) for use in generating the noise @xmath54 .",
    "this is the first of the three methods described above .",
    "alternatively , we can use the third method : at each step of our iterative procedure we can generate noise directly with the correlations @xmath87 ( which are long - ranged in time ) and use @xmath70 in place of @xmath55 in calculating @xmath58 ( [ eq : bb ] ) .",
    "we have verified that the two methods give the same results when carried out numerically , though the second procedure converges more slowly .",
    "while the true rates in the stationary case are time - independent and @xmath91 is a function only of @xmath92 , the statistics collected over a finite set of noise - driven trials will not exactly have these stationarity properties .",
    "therefore we improve the statistics and impose time - translational invariance by averaging the measured @xmath93 and @xmath94 over @xmath95 and averaging over the measured values @xmath91 with a fixed @xmath92 .",
    "after the iterative procedure converges , so that we have a good estimate of the statistics of the input , we want to run many trials _ on a single neuron _ and compute its firing statistics .",
    "this means that _ the numbers @xmath52 ( @xmath96 ) should be held constant over these trials_. in this case it is necessary to subtract out the large @xmath92 limit of @xmath97 and use fixed @xmath52 ( constant in time and across trials ) to generate the input noise .",
    "( if we did it the other way , without the subtraction , we would effectively be assuming that @xmath52 changed randomly from trial to trial , which is not correct . )    in our calculations we have used 10000 trials to calculate these single - neuron firing statistics .",
    "we perform the subtraction of the long - time limit of @xmath97 at @xmath98 , and we have checked that ( [ eq : ctilde ] ) is flat beyond this point in all the cases we have done .    if we perform this kind of measurement separately for many values of the @xmath52 , we will be able to see how the firing statistics vary across the population . here , however , we will confine most of our attention to what we call the  average neuron \" : the one with the average value ( 0 ) of all three @xmath52 .    in particular , we calculate the mean spike count in the 100-ms trials and its variance across trials . from this",
    "we can get the fano factor @xmath99 ( the variance / mean ratio ) .",
    "we also compute the autocorrelation function , which offers a consistency check , since the fano factor can also be obtained from f = _",
    "-^c ( ) d. eq : ffromc ( this formula is valid when the measurement period is much larger than the time over which @xmath100 falls to zero . )    we will study below how these firing statistics vary as we change various parameters of the model : the input rates @xmath42 , parameters that control the balance of excitation and inhibition , and the overall strength of the synapses .",
    "this will give us some generic understanding of what controls the degree of irregularity of the neuronal firing .",
    "when the input population is not firing at a constant rate , almost the same calculational procedure can be followed , except that one does not average measured rates , their fluctuations or correlation function over time . to start out ,",
    "we get initial instantaneous rate estimates from the balance condition , assuming that the time - dependent average input currents do not vary too quickly .",
    "( this condition is not very stringent ; van vreeswijk and sompolinsky showed that the stability eigenvalues are proportional to @xmath23 , so if they have the right sign the convergence to the balanced state is very rapid . )    to do the iterative procedure to satisfy the self - consistency conditions of the theory , it is simplest to use the second of the two ways described above ( not doing any subtraction until the final calculations with single neurons ) . in this case the expression ( [ eq : bb ] ) does not include rate fluctuations , and we get equations for the noise input currents just like ( [ eq : invar ] ) , ( [ eq : innoise ] ) and ( [ eq : decrec ] ) except that the @xmath60 are @xmath95-dependent and the correlation functions @xmath101 and @xmath102 depend on both @xmath95 and @xmath103 , not just their difference .",
    "the only tricky part is the subtraction of the long - time limit of the correlation function , which is not simply defined .",
    "we treat this problem in the following way .",
    "we examine the rate - normalized quantity d_a(t , t ) = .",
    "eq : dhat we find that this quantity is time - translation invariant ( i.e. , a function only of @xmath92 ) to a very good approximation , so we perform the subtraction of the long - time limit on it .",
    "then multiplying the subtracted @xmath104 by @xmath105 gives a good approximation to the true correlation function @xmath91 .",
    "the meaning of this finding is , loosely speaking , that when the rates vary ( slowly enough ) in time , the correlation functions just inherit these rates as overall factors without changing anything else about the problem .",
    "we will use the this time - dependent formulation below to simulate experiments like those of gershon _ et al _ @xcite , where the lgn input @xmath106 to visual cortical cells is time - dependent because of the flashing - on and off of the stimulus .",
    "the results presented in this chapter were obtained from simulations with parameters corresponding to population sizes of @xmath107 40,000 excitatory neurons and @xmath108 10,000 inhibitory neurons . with the above mentioned connection probabilities of @xmath16 , this translates to an average number of @xmath109 excitatory inputs and @xmath110 inhibitory inputs to each neuron . the average number of external ( excitatory ) inputs @xmath111 was chosen to be equal to @xmath112 .",
    "all neurons have the same membrane time constant @xmath34 of @xmath113  ms .",
    "to study the effect of various combinations in synaptic strength , we use the following generic form to define the intra - cortical weights @xmath19 :    (    cc j_11 & j_12 + j_21 & j_22    ) = (    cc & -2 g + 1 & -2 g    ) eq : jmatrix for the synaptic strengths from the external population we use @xmath114 and @xmath115 . with this notation , @xmath116 determines the strength of inhibition relative to excitation within the network , and @xmath117 the strength of intracortical excitation . additionally , we scale the overall strength of the synapses with a multiplicative scaling factor denoted @xmath118 so that each synapse has an actual weight of @xmath119 , regardless of @xmath10 and @xmath9 .    [ cols=\"^ \" , ]     the data look qualitatively like those obtained from _ in - vivo _ experiments @xcite and are similar to the superpoissonian case in figure  [ fig : varmean ] . the neuron fires consistently in a superpoissonian regime with fano factors slightly higher than 1 and an almost linear relationship between the log variance and the log mean for low spike counts . for higher spike counts , the curve bends towards values of lower fano factors , just as for stationary inputs ( figure  [ fig : varmean ] ) .",
    "in both cases , this bend reflects the the decrease in irregularity of firing caused by an increasingly prominent role of refractoriness for shorter interspike intervals .",
    "cortical neurons receive thousands of both excitatory and inhibitory inputs , and despite the high number of inputs from nearby neurons with similar firing statistics and similar connectivity , their observed firing is very irregular @xcite .",
    "dynamically balanced excitation and inhibition through a simple feedback mechanism provides an explanation that naturally accounts for this phenomenon without requiring fine tuning of the parameters @xcite .",
    "moreover , neurons in such model networks show an almost linear input - output relationship ( input current versus firing frequency ) , as do neurons in the neocortex .    here",
    ", we have extended the mean - field description of the dynamically balanced asynchronous firing state to analyze firing correlations .",
    "we found that the relationship between the observed irregularity of firing ( spike count variance ) and the firing rate ( spike count mean ) of the neurons resemble closely data collected from _ in - vivo _ experiments ( see figures [ fig : varmean ] and [ fig : nonstatinput ] ) . to do this",
    ", we developed a complete mean - field theory for a network of leaky integrate - and - fire neurons , in which both firing rates and correlation functions are determined self - consistently . using an algorithm that allows us to find the solutions to the mean - field equations numerically ,",
    "we could elucidate how the strength of synapses within the network influences the expected firing statistics of cortical neurons in a systematic manner ( see figure  [ fig : fanos ] ) .",
    "we have shown that the irregularity of firing , as measured by the fano factor , increases with increasing synaptic strengths ( figure  [ fig : fanos ] ) . nearly poisson statistics ( with @xmath120 ) are observed for moderately strong strengths , but the transition from subpoissonian to superpoissonian statistics is smooth , without a special role for @xmath121 .    the higher irregularity in the spike counts is always accompanied by a tendency toward more  bursty \" firing .",
    "( these bursts are a network effect ; the model contains only leaky integrate - and - fire neurons , which do not burst on their own . )",
    "this burstiness can best be seen in the spike train autocorrelation function ( figure  [ fig : autocorr ] ) , which acquires a hill of growing size and width around zero lag for increasing fano factors .",
    "the interdependence between firing irregularity and bursting can be understood with help of the isi distributions depicted in figure  [ fig : isi ] : when the rate , and thus the average isi , is kept constant , then any higher count for shorter - than - average isis must be accompanied by an accordingly higher count for longer isis ( indicating bursts ) , and vice versa . thus higher irregularity always goes hand in hand with a higher tendency toward temporal clustering of spikes .",
    "why do stronger synapses lead to higher irregularity in firing ?",
    "the size of the input current fluctuations in ( [ eq : decrec ] ) are controlled by the @xmath19 , and so , therefore , are the corresponding membrane potential fluctuations .",
    "thus , for example , the width of the steady - state membrane potential distribution is proportional to @xmath118 .",
    "we next have to consider where this distribution is centered . remembering that , according to the balance condition , the firing rate is independent of @xmath118 , the center of the distribution has to move farther away from threshold as @xmath118",
    "is increased in order to keep the rate fixed .",
    "therefore , for very small @xmath118 almost the entire equilibrium membrane potential distribution will lie well above the post - spike reset value , while for large @xmath118 it will be mostly below reset .    immediately after a spike , the membrane potential distribution is a delta - function centered at the reset ( here 0 ) .",
    "it then spreads and its mean moves up or down toward its equilibrium value .",
    "this equilibration will take about a membrane time constant .",
    "if the equilibrium value is well above zero ( the small-@xmath118 case ) , the probability of reaching threshold will be suppressed during this time , implying a refractory dip in the isi distribution and the correlation function and a tendency toward a fano factor less than 1 .    in the large-@xmath118 case , on the other hand , where the membrane potential is reset much closer to the threshold than to its eventual equilibrium value , the initial rapid spread ( with the width growing proportional to @xmath122 ) leads to an enhanced probability of early spikes . at short times",
    "this diffusive spread dominates the downward drift of the mean ( which is only linear in @xmath95 ) .",
    "thus there is extra weight in the isi distribution and a positive correlation function at these short times , leading to a fano factor greater than 1 .",
    "empirically , an approximate power - law relationship between the mean and variance of the spike count has frequently been observed for cortical neurons ( see , e.g. , @xcite ) .",
    "our model shows the same qualitative feature ( figures [ fig : varmean ] and [ fig : nonstatinput ] ) , though we have no argument that the relation should be an exact power law .",
    "however , this agreement suggests that the model captures at least part of physics underlying the firing statistics .",
    "as already observed , not all of the variability in measured neuron responses has to be explained in the manner outlined above .",
    "changing conditions during the run of a single experiment may introduce extra irregularity , caused by collecting statistics over trials with different mean firing rates .",
    "the present analysis shows why  and how much  irregularity can be expected due to intrinsic cortical dynamics .",
    "our formulation of the mean - field theory is general enough to allow straightforward extensions to greater biological realism and to more complicated network architectures .",
    "we have introduced a generalization of this model with conductance - based synapses in another paper @xcite .",
    "we have also extended the model to include systematic structure in the connections , modeling an orientation hypercolumn in the primary visual cortex @xcite .",
    "moreover , our algorithm for finding the mean - field solutions is not restricted to networks of integrate - and - fire neurons .",
    "it can be applied to any kind of neuronal model .",
    "furthermore , any kind of synaptic dynamics can be incorporated by using synaptically filtered spike trains to compute the self - consistent solutions ."
  ],
  "abstract_text": [
    "<S> we study the spike statistics of neurons in a network with dynamically balanced excitation and inhibition . our model , intended to represent a generic cortical column , </S>",
    "<S> comprises randomly connected excitatory and inhibitory leaky integrate  and  fire neurons , driven by excitatory input from an external population . </S>",
    "<S> the high connectivity permits a mean - field description in which synaptic currents can be treated as gaussian noise , the mean and autocorrelation function of which are calculated self - consistently from the firing statistics of single model neurons . within this description , we find that the irregularity of spike trains is controlled mainly by the strength of the synapses relative to the difference between the firing threshold and the post - firing reset level of the membrane potential . for moderately strong synapses </S>",
    "<S> we find spike statistics very similar to those observed in primary visual cortex . </S>"
  ]
}