{
  "article_text": [
    "covariance structure is of fundamental importance in multivariate analysis and all kinds of applications . while in classical low - dimensional setting , a usually unknown covariance structure can be estimated by the sample covariance matrix , in the high - dimensional setting , it is now well understood that the sample covariance matrix is not a consistent estimator . what is even worse , in many applications the observations are contaminated , and below we explain one such setting that motivates this work .",
    "similar situations certainly arise in many other settings .",
    "our motivating question arises in the context of estimating the so - called integrated covariance matrix of high - dimensional diffusion process , with applications towards the study of stock price processes . more specifically ,",
    "suppose that we have @xmath0 stocks whose ( efficient ) log price processes are denoted by @xmath1 for @xmath2 .",
    "let @xmath3 .",
    "a widely used model for @xmath4 is @xmath5 , \\label{diffusion}\\end{aligned}\\ ] ] where @xmath6 is a @xmath0-dimensional drift process , @xmath7 is a @xmath8 matrix for any @xmath9 , and is called the covolatility process , and @xmath10 is a @xmath0-dimensional standard brownian motion .",
    "the interval @xmath11 $ ] stands for the time period of interest , say , one day .",
    "the integrated covariance ( icv ) matrix refers to @xmath12 the icv matrix , in particular , its spectrum ( i.e. , its set of eigenvalues ) plays an important role in financial applications such as factor analysis and risk management .",
    "a classical estimator of the icv matrix is the so - called realized covariance ( rcv ) matrix , which relies on the assumption that one could observe @xmath4 at high frequency . more specifically ,",
    "suppose that @xmath4 could be observed at time points @xmath13 for @xmath14 .",
    "then , the rcv matrix is defined as @xmath15 where @xmath16 stands for the vector of log returns over the period @xmath17 $ ] .",
    "consistency as well as central limit theorems for rcv matrix under such a setting _ and _ when the dimension @xmath0 is fixed is well unknown , see , for example , @xcite , @xcite , @xcite , @xcite , @xcite , among others .    however , in practice , the observed prices are always contaminated by the market microstructure noise .",
    "the market microstructure noise is induced by various frictions in the trading process such as the bid - ask spread , asymmetric information of traders , the discreteness of price , etc . despite the small size",
    ", market microstructure noise accumulates at high frequency and affects badly the inferences about the efficient price processes . in practice , as is pointed out in @xcite where a careful comparison between various volatility estimators and the 5-min realized volatility is carried out , when the sampling frequency is higher than one observation per five minutes , the microstructure noise is usually no longer negligible , and the following additive model has been widely adopted in recent studies on volatility estimation : @xmath18 where @xmath19 denote the observations , @xmath20 denote the noise , which are , independent of @xmath4 , with @xmath21 and certain covariance matrix @xmath22 .    observe that under , the observed log - returns @xmath23 relates to the true log - returns @xmath24 by the following equation @xmath25 where , as usual , @xmath26 .",
    "we are therefore in a noisy observation setting where the observations are contaminated by additive noise .",
    "such a setting forms the basis of the current work .    besides microstructure noise",
    ", there is another issue which is due to asynchronous trading . in practice ,",
    "different stocks are traded at different times , consequently , the tick - by - tick data are not observed synchronously .",
    "there are several existing methods for synchronizing data , like the refresh times ( @xcite ) and previous tick method ( @xcite ) . compared with microstructure noise ,",
    "asynchronicity is less an issue .",
    "for example , as is pointed out in @xcite , asynchronicity does not induce bias in the two - scales estimator , and even the asymptotic variance is the same as if there is no asynchronicity . while we do not seek a rigorous proof to avoid the paper being unnecessarily lengthy , we believe our methods to be introduced below work just as well for asynchronous data .",
    "the reason , roughly speaking , is as follows .",
    "take the previous tick method for example .",
    "here we choose a ( usually equally spaced ) grid of time points @xmath27 , and for each stock @xmath28 , for each time @xmath29 , let @xmath30 be the latest transaction time before @xmath29 .",
    "one then acts as if one observes @xmath31 at time @xmath29 for stock @xmath28 . with the original additive model at time",
    "@xmath30 : @xmath32 we have at time @xmath29 , @xmath33 in other words , the asynchronicity induces an additional error @xmath34 .",
    "the error is however diminishingly small as the sampling frequency @xmath35 since @xmath36 . to sum up , even though asynchronicity induces an additional error ,",
    "the error is of negligible order compared with the microstructure noise @xmath37 .",
    "henceforth we shall stick to the model .",
    "one striking feature in that differs from most noisy observation settings is that as the observation frequency @xmath38 goes to infinity , the signal , namely , the true log - return @xmath24 becomes diminishingly small , while the noise @xmath39 remains of the same order of magnitude , and therefore the signal - to - noise ratio goes to 0 . in the next section",
    "we will explain a method that fixes this issue .",
    "our first main result , theorem [ thm : lsd_signal_noise ] , applies to a general setting where the signal and noise are of a same order of magnitude .",
    "the pre - averaging ( pav ) approach is introduced in @xcite , @xcite and @xcite to deal with microstructure noise .",
    "other approaches include the two - scales estimator ( @xcite,@xcite ) , realized kernel ( @xcite,@xcite ) and quasi - maximum likelihood method ( @xcite,@xcite ) .",
    "we shall use a slight variant of the pav approach in this work .",
    "first , choose a window length @xmath40 .",
    "then , group the intervals @xmath41 $ ] , @xmath42 into @xmath43 pairs of non - overlapping windows , each of width @xmath44 , where @xmath45 denotes rounding down to the nearest integer .",
    "introduce the following notation for any process @xmath46",
    ", @xmath47 with such notation , the observed return based on the pre - averaged price becomes @xmath48 one key observation is that if @xmath40 is chosen to be of order @xmath49 ( which is the order chosen in @xcite , @xcite and @xcite ) , then in the `` signal '' @xmath50 and `` noise '' @xmath51 can be shown to be of the same order of magnitude .",
    "our version of pav matrix is then just the sample covariance matrix based on these returns : @xmath52      we first recall some concepts in multivariate analysis . for any @xmath8 symmetric matrix @xmath53 ,",
    "suppose that its eigenvalues are @xmath54 , then its _ empirical spectral distribution _",
    "( esd ) is defined as @xmath55 the limit of esd as @xmath56 , if exists , is referred to as the _ limiting spectral distribution _ , or lsd for short .",
    "the matrix @xmath57 can be viewed as the sample covariance matrix based on observations @xmath58 , which model the situation of information vector @xmath59 being contaminated by additive noise @xmath60 . @xcite",
    "consider such information - plus - noise - type sample covariance matrices as @xmath61 where @xmath62 is independent of @xmath63 , and consists of entries with zero mean and unit variance .",
    "write @xmath64 .",
    "the authors show that if @xmath65 converges , then so does @xmath66 .",
    "they further show how the lsd of  @xmath67 depends on that of @xmath68 ( see equation ( 1.1 ) therein ) .    in this article",
    ", we investigate the problem from a different angle .",
    "we shall show how the lsd of @xmath68 depends on that of @xmath67 .",
    "our motivation for seeking such a relationship is that , in practice , we are usually interested in making inferences about signals @xmath69 based on noisy observations @xmath70 . therefore , a more practically relevant result is a relationship that describes how the lsd of @xmath68 depends on that of @xmath67 .",
    "let us mention that inverting the aforementioned relationships is in general notoriously difficult .",
    "for example , the marenko - pastur equation , which is very similar to equation ( 1.1 ) in @xcite and describes how the lsd of the sample covariance matrix depends on that of the population covariance matrix , is long - established , but it was only a few years ago that researchers [ @xcite ; @xcite ; @xcite ] realized how the ( unobservable ) lsd of the population covariance matrix can be recovered based on the ( observable ) lsd of the sample covariance matrix .",
    "our first result , theorem [ thm : lsd_signal_noise ] below , provides an approach that allows one to derive the lsd of @xmath68 based on that of @xmath67 .",
    "we first collect some notation that will be used throughout the article .",
    "for any real matrix @xmath71 , @xmath72 denotes its spectral norm , where @xmath73 is the transpose of @xmath71 , and @xmath74 denotes the largest eigenvalue . for any nonnegative definite matrix @xmath75",
    ", @xmath76 denotes its square root matrix . for any @xmath77 , write @xmath78 and @xmath79 as its real and imaginary parts , respectively , and @xmath80 as its complex conjugate .",
    "for any distribution @xmath81 , @xmath82 denotes its stieltjes transform defined as @xmath83 in particular , for any hermitian matrix  @xmath53 with eigenvalues @xmath54 , the stieltjes transform of its esd , denoted by @xmath84 , is given by @xmath85 where @xmath86 is the identity matrix .",
    "for any vector @xmath87 , @xmath88 stands for its euclidean norm .",
    "finally , `` @xmath89 '' stands for `` equal in distribution '' , @xmath90 denotes weak convergence , @xmath91 means convergence in probability , @xmath92 means that the sequence @xmath93 is tight , and @xmath94 means that @xmath95 .",
    "we now present our first result about how the lsd of @xmath68 depends on that of @xmath67 .",
    "[ thm : lsd_signal_noise ] suppose that @xmath96 , where    [ asm : fa_conv ] @xmath97 is @xmath98 , independent of @xmath62 , and with @xmath99 , we have @xmath100 , where @xmath101 is a probability distribution with stieltjes transform denoted by @xmath102 ;    [ asm : sigma_n_conv ] @xmath103 with @xmath104 ;    [ asm : eps ] @xmath105 is @xmath98 with the entries @xmath106 being and centered with unit variance ; and    [ asm : yn_conv ] @xmath107 with @xmath108 as @xmath56 .",
    "then , almost surely , the esd of @xmath67 converges in distribution to a probability distribution @xmath81 .",
    "moreover , if @xmath81 is supported by a finite interval @xmath109 $ ] with @xmath110 and possibly has a point mass at 0 , then for all @xmath111 such that the integral on the right hand side of below is well - defined , @xmath112 is determined by @xmath81 in that it uniquely solves the following equation @xmath113 in the set @xmath114    [ rmk : alpha_range ] since @xmath115 and @xmath116 as @xmath117 , the imaginary part of the denominator of the integrand on the right hand side of is asymptotically equivalent to @xmath118 as @xmath117 , and so the integral is well - defined for all @xmath119 with @xmath79 sufficiently large . note further that by the uniqueness theorem for analytic functions , knowing the values of @xmath112 for @xmath119 with @xmath79 sufficiently large is sufficient to determine @xmath112 for all @xmath120    in practice , as the esd of @xmath121 is observable , we can replace @xmath81 with @xmath122 and solve equation for @xmath123 . since @xmath123 fully characterizes the esd of @xmath68 , this allows us to make inferences about the covariance structure of the underlying signals @xmath124 .",
    "in the simulation studies we explain in detail about how to implement this procedure in practice .      the term @xmath125 can be written in a more clear form by using the triangular kernel : @xmath126 based on this , one can show that if dimension @xmath0 is fixed , then @xmath127 it is also easy to verify that @xmath128 where @xmath129 s are random vectors with zero mean and covariance matrix @xmath22 .",
    "the following corollary is a direct consequence of theorem [ thm : lsd_signal_noise ] .",
    "[ cor : a_pav ] suppose that    [ asm : x ] for all @xmath0 , @xmath4 is a @xmath0-dimensional process for some drift process @xmath130 and covolatility process @xmath131 defined in ;    [ asm : a_conv ] the esd of @xmath132 converges to a probability distribution @xmath101 with stieltjes transform denoted by @xmath112 ;    [ asm : noise ] the noise @xmath133 are independent of @xmath4 , and are i.i.d . with zero mean and covariance matrix @xmath134 for some @xmath135 and @xmath136 as @xmath56 ;    [ asm : k_pav ] @xmath137 for some @xmath138 , and @xmath139 satisfy that @xmath140 .",
    "then , almost surely , the esd of pav defined in converges in distribution of a probability distribution @xmath81 .",
    "moreover , if @xmath81 is supported by a finite interval @xmath109 $ ] with @xmath110 and possibly has a point mass at 0 , then for all @xmath111 such that the integral on the right hand side of below is well - defined , @xmath112 is determined by @xmath81 in that it uniquely solves the following equation @xmath141 in the set @xmath142    [ rmk : thm_apply_general_case ] although corollary [ cor : a_pav ] is stated for the case when noise components have the same standard deviations , it can readily be applied to the case when the covariance matrix @xmath22 is a general diagonal matrix , say @xmath143 . to see this ,",
    "let @xmath144 .",
    "we can then artificially add additional @xmath145 to the original observations , where @xmath145 are independent of @xmath146 , and are with zero mean and covariance matrix @xmath147 .",
    "the noise components in the modified observations then have the same standard deviation @xmath148 , and corollary [ cor : a_pav ] can be applied .",
    "note that the variances , @xmath149 , can be consistently estimated , see , for example , theorem a.1 in @xcite .",
    "a similar remark applies to theorem [ thm : lsd_signal_noise ] .",
    "corollary [ cor : a_pav ] allows us to estimate the esd of @xmath132 . in light of the convergence ,",
    "this would have been sufficient for us to make inferences about the icv if the convergence held as well in the high - dimensional case .",
    "unfortunately , it is not the case , and a further step to go from @xmath132 to  is needed .",
    "such an inference is generally impossible , as can be seen as follows .",
    "is an integral @xmath150 . in the simple situation where @xmath151 and @xmath7 is deterministic , the building blocks in defining @xmath132 , @xmath152 , are multivariate normals with mean 0 and covariance matrices @xmath153 the bottom line is , all the @xmath38 covariance matrices , @xmath154 for @xmath155",
    ", could be very different from the !",
    "we can easily change the @xmath38 covariance matrices @xmath154 and hence the distributions of @xmath152 _ without _ changing . and as both the dimension @xmath0 and observation frequency @xmath38 go to infinity , there are just too much freedom in the underlying distributions which makes the inference about   impossible . certain structural assumptions are necessary to turn the impossible into the possible .",
    "the simplest one is to assume @xmath156 , in which case @xmath152 are the apparent shortcoming about this assumption is that it could not capture stochastic volatility which is a stylized feature in financial data .",
    "the following class of processes , introduced in @xcite , accommodates both stochastic volatility and leverage effect and in the meanwhile makes the inference about  still possible ( and as we will see soon that the theory is already much more complicated than the setting ) .",
    "[ classc ] suppose that @xmath157 is a @xmath0-dimensional process satisfying  ( [ diffusion ] ) .",
    "we say that @xmath157 belongs to class @xmath158 if , almost surely , there exist @xmath159;{{\\mathbb r}})$ ] and @xmath160 a @xmath8 matrix satisfying tr@xmath161 such that @xmath162 where @xmath163;{{\\mathbb r}})$ ] stands for the space of cdlg functions from @xmath11 $ ] to @xmath164 .",
    "[ rmk : ga_lam ] the convention that tr@xmath161 is made to resolve the non - identifiability built in the formulation , in which one can multiply @xmath165 and divide @xmath160 by a same constant without modifying the process @xmath131 .",
    "it is thus not a restriction .",
    "class @xmath158 incorporates some widely used models as special cases :    * the simplest case is when the drift @xmath166 and @xmath167 , in which case the returns @xmath168 are @xmath169 .",
    "* more generally , again when the drift @xmath166 while @xmath170 is independent of the underlying brownian motion @xmath10 , the returns @xmath168 follow mixed normal distributions . *",
    "* mixed normal distributions , or their asymptotic equivalent form in the high - dimensional setting , elliptic distributions have been widely used in financial applications .",
    "@xcite state that `` elliptical distributions ... provided far superior models to the multivariate normal for daily and weekly us stock - return data '' , and `` multivariate return data for groups of returns of a similar type often look roughly elliptical . ''",
    "* * more recently , el karoui in a series of papers ( @xcite , @xcite and @xcite ) studied the markowitz optimization problem under the setting that the returns follow mixed normal / elliptic distributions . *",
    "furthermore , class @xmath158 allows the drift @xmath130 to be non - zero , and more importantly , the @xmath171 process to be stochastic and even dependent on the brownian motion @xmath10 that drives the price process , thus featuring the so - called leverage effect in financial econometrics , which is an important stylized fact of financial returns and has drawn a lot of attention recent years , see , for example , @xcite and @xcite .",
    "observe that if @xmath172 belongs to class @xmath158 , then the icv matrix @xmath173 furthermore , if the drift process @xmath174 and @xmath171 is independent of @xmath175 , then , conditional on @xmath170 and using , we have @xmath176 where @xmath177 consists of independent standard normals , and @xmath178 it follows that @xmath179      using corollary [ cor : a_pav ] and theorem  1 in @xcite we establish the following result concerning the lsd of @xmath132 .",
    "we put the following assumptions on the underlying process .",
    "they are inherited from proposition 5 of @xcite , and we refer the readers to that article for some further background and explanations .",
    "observe in particular that assumption allows the covolatility process to be dependent on the brownian motion that drives the price processes .",
    "such a dependence allows us to capture the so - called leverage effect in financial econometrics .",
    "assumptions and are about the spectral norm of the  matrix .",
    "we do not require the norm to be bounded , allowing , for example , spike eigenvalues .",
    "* assumption c : *    [ asm : x_in_c ] for all @xmath0 , @xmath157 is a @xmath0-dimensional process in class @xmath158 for some drift process @xmath6 and covolatility process @xmath180 ;    [ asm : mu_bdd ] there exists a @xmath181 such that for all @xmath0 and all @xmath2 , @xmath182 for all @xmath183 almost surely ;    [ asm : sigma_conv ] as @xmath56 , the esd of @xmath184 converges in distribution to a probability distribution @xmath185 ;    [ asm : sigma_bdd ] there exist @xmath186 and @xmath187 such that for all @xmath0 , @xmath188 almost surely ;    [ asm : leverage ] there exists a sequence of index sets  @xmath189 satisfying @xmath190 and @xmath191 such that @xmath171 may depend on @xmath175 but only on @xmath192 ;    [ asm : gamma_conv ] there exists a @xmath193 such that for all @xmath0 and for all @xmath183 , @xmath194 almost surely , and additionally , almost surely , @xmath170 converges uniformly to a nonzero process @xmath195 that is piecewise continuous with finitely many jumps .",
    "[ thm : main ] suppose that assumptions - and hold , then as @xmath56 ,    the esds of  and @xmath132 converge to probability distributions @xmath196 and @xmath101 respectively , where @xmath197    @xmath101 and @xmath196 are related as follows : @xmath198 where @xmath199 , together with another function @xmath200 , uniquely solve the following equations in @xmath201 @xmath202    [ rmk : mainthm_usage]based on corollary [ cor : a_pav ] and theorem [ thm : main ] , we obtain the following two - step procedure to estimate the esd of icv :     and theorem [ thm : main].,width=453 ]    first , based on corollary [ cor : a_pav ] , plug the esd of pav into equation to solve for @xmath203 ;    with the estimated @xmath203 from the first step , use equations and in theorem [ thm : main ] to estimate the esd of   by generalizing the algorithms in @xcite , @xcite , and @xcite    see the simulation studies for more detailed explanations about the estimation procedure .",
    "the aforementioned two - step procedure involves the @xmath204 which needs to be estimated in practice .",
    "moreover , equations and involves three unknowns ( @xmath205 and @xmath206 ) and the numerical solutions of these equations may be unstable .",
    "motivated by this consideration , we draw ideas from @xcite and propose an alternative estimator that overcomes these challenges .",
    "it is also worth mentioning that the alternative estimator allows for rather general dependence structures in the noise process , both cross - sectional and temporal .",
    "the temporal dependence between the microstructure noise has been documented in recent studies , see , for example , @xcite , @xcite and @xcite .",
    "our alternative estimator is an extension of the time - variation adjusted rcv matrix introduced in @xcite to our noisy setting .",
    "to start , we fix an @xmath207 and @xmath138 , and let @xmath208 and @xmath209 . the time - variation",
    "adjusted pav matrix is then defined as @xmath210 where @xmath211    note that here window length @xmath40 has a higher order than in theorem  [ thm : main ] .",
    "the reason is that , after pre - averaging , the underlying returns are @xmath212 and the noises are @xmath213 . in theorem [ thm : main ] , we balance the orders of the two terms by choosing @xmath214 to achieve the optimal convergence rate . in theorem [ thm : b_n ] below , we take @xmath215 for some @xmath216 to eliminate the impact of noise .",
    "we first recall the concept of @xmath217-mixing coefficients .",
    "[ rho_corr ] suppose that @xmath218 is a stationary time series . for @xmath219 ,",
    "let @xmath220 be the @xmath221-field generated by the random variables @xmath222 .",
    "the @xmath217-mixing coefficients are defined as @xmath223 where for any probability space @xmath224 , @xmath225 refers to the space of square - integrable , @xmath224-measurable random variables .",
    "we now introduce a number of assumptions .",
    "observe that assumption   says that we allow for rather general dependence structures in the noise process , both cross - sectional and temporal .",
    "we actually do not put any restrictions on the cross - sectional dependence , and even the dependence between the microstructure noise and the price process is allowed .",
    "note also that @xcite provides an approach to estimate the decay rate of the @xmath217-mixing coefficients .",
    "assumption is again about the dependence between the covolatility process and the brownian motion that drives the price processes .",
    "assumption is about the boundedness of individual volatilities .",
    "[ asm : eps_general ] for all @xmath226 , the noises @xmath227 is stationary , have mean 0 and bounded @xmath228th moments and with @xmath217-mixing coefficients @xmath229 satisfying @xmath230 for some integer @xmath231 as @xmath232 ;    [ asm : leverage_2 ] there exists a @xmath233 and a sequence of index sets @xmath189 satisfying @xmath234 and @xmath235 such that @xmath170 may depend on @xmath10 but only on @xmath236 ;    [ asm : gamma_bdd ] there exists a @xmath186 such that for all @xmath0 , @xmath237 for all @xmath238 almost surely ;    [ asm : vol_bdd ] there exists a @xmath193 such that for all @xmath0 and all @xmath28 , the individual volatilities @xmath239 for all @xmath240 $ ] almost surely ;    [ asm : sigma_bdd_2 ] there exist @xmath241 and @xmath242 such that for all @xmath0 , @xmath243 almost surely ;    the @xmath244 in and @xmath245 in satisfy that @xmath246 ;    [ asm : ym_conv ] @xmath247 for some @xmath138 and @xmath248 , and @xmath139 satisfy that @xmath140 , where @xmath249 is the integer in assumption .",
    "[ rmk : compatibility ] careful readers may have noticed that assumptions and are mathematically incompatible as assumption requires @xmath250 while assumption requires @xmath251 for some @xmath252 .",
    "the two assumptions are , however , perfectly compatible in practice when we deal with finite samples .",
    "in fact , take the choices of @xmath253 in the simulation studies ( section [ sec : simulation ] below ) for example .",
    "there we take @xmath254 . when applying corollary [ cor : a_pav ] and theorem [ thm : main ] , we take @xmath255 , which leads to @xmath256 in assumption ; while when applying theorem [ thm : b_n ] below , we take @xmath257 , which gives @xmath258 in assumption .",
    "we have the following convergence result regarding the esd of the alternative estimator .",
    "[ thm : b_n ] suppose that for all @xmath0 , @xmath157 is a @xmath0-dimensional process in class @xmath158 for some drift process @xmath6 and covolatility process @xmath259 .",
    "suppose also that assumptions ( [ asm : mu_bdd ] ) , and in theorem [ thm : main ] hold . under assumptions - , we have as @xmath56 , the esds of @xmath260 and",
    "@xmath261 converge almost surely to probability distributions @xmath196 and @xmath262 , respectively , where @xmath196 satisfies , and @xmath262 is determined by @xmath196 in that the stieltjes transform of @xmath262 , denoted by @xmath263 , satisfies the following ( standard ) marenko - pastur equation @xmath264    [ rmk : thm3 ] theorem [ thm : b_n ] says that the lsds of icv and @xmath261 are related via the marenko - pastur equation .",
    "several algorithms have been developed to recover @xmath196 by inverting the marenko - pastur equation , see , for example , @xcite we can therefore readily estimate the esd of icv by using these existing algorithms .",
    ".,width=340 ]    the rest of the paper is organized as follows .",
    "section [ sec : simulation ] demonstrates how to implement both the two - step procedure introduced in remark [ rmk : mainthm_usage ] and the more direct method in remark [ rmk : thm3 ] to estimate the spectral distribution of underlying covariance matrix based on noisy observations .",
    "the proof of theorem [ thm : lsd_signal_noise ] is given in section [ sec : proofs ] .",
    "section [ sec : conclusion ] concludes .",
    "the proofs of some lemmas and theorems [ thm : main ] and [ thm : b_n ] are given in the appendix [ appendix : pfs ] .",
    "in this section , we illustrate how to make inferences using corollary [ cor : a_pav ] , theorems [ thm : main ] and [ thm : b_n ] .",
    "in particular , we will show how to estimate the esd of icv by using ( 1 ) corollary [ cor : a_pav ] and theorem  [ thm : main ] based on pav , and ( 2 ) theorem [ thm : b_n ] based on the alternative estimator @xmath261 .",
    "we consider a stochastic u - shaped @xmath170 process as follows : @xmath265,\\ ] ] where @xmath266 , @xmath267 , @xmath268 and @xmath269 with @xmath270 being the @xmath271th component of the brownian motion @xmath10 that drives the price process .",
    "observe that such a formulation makes @xmath170 to be dependent on _ all _ the component of the underlying brownian motion , hence assumptions and are actually both violated .",
    "however , we shall see soon that our methods still work well .",
    "a sample path of @xmath170 is given below .",
    ".,width=377 ]    next , the matrix @xmath272 is taken to be @xmath273 where @xmath274 is a random orthogonal matrix and @xmath275 is a diagonal matrix whose diagonal entries are drawn independently from beta@xmath276 distribution . with such @xmath170 and @xmath272 , the individual daily volatilities are around @xmath277 , which is similar to what one observes in practice .",
    "the latent log price process @xmath4 follows @xmath278 finally , the noise @xmath133 are drawn from @xmath279 .    in the studies below , the dimension , i.e.",
    ", the number of assets @xmath0 is taken to be 100 , and the observation frequency @xmath38 is set to be 23,400 which corresponds to one observation per second on a regular trading day .      in this subsection",
    ", we illustrate how to estimate the esd of icv based on pav matrix by using the two - step procedure that we introduced in remark [ rmk : mainthm_usage ] .    in the first step ,",
    "we replace @xmath81 in equation with the esd of pav and solve for @xmath203 .",
    "the window length @xmath40 in defining pav is set to be @xmath280 .",
    "as to @xmath203 to be solved , we choose a set of @xmath119 s whose real and imaginary parts are equally spaced in the intervals @xmath281 $ ] and @xmath282 $ ] respectively .",
    "denote these @xmath119 s by @xmath283 , and the estimated @xmath284 by @xmath285 .",
    "we then need to estimate the esd of @xmath132 based on @xmath286 , which is done as follows .    inspired by the nonparametric estimation method proposed in @xcite , we approximate @xmath287 with a weighted sum of point masses @xmath288 where @xmath289 is a grid of points to be specified , and @xmath290 s are weights to be estimated . to choose the grid @xmath291 ,",
    "naturally we would like @xmath292 $ ] to cover the support of @xmath287 which , however , is unknown . to overcome such a difficulty , note that by the marenko - pastur theorem , the support of esd of sample covariance matrix always covers that of the population covariance matrix , and since by theorem [ thm : b_n ] , our alternative estimator , @xmath261 , satisfies the same marenko - pastur equation as the sample covariance matrix , @xmath261 inherits such a property with a support covering that of .",
    "( such a feature can be clearly seen in the first plot in figure [ fig : thm3 ] . )",
    "thanks to this property , we choose @xmath293 s be equally spaced between 0 and the largest eigenvalue of @xmath261 , and we are guaranteed that @xmath292 $ ] will cover the support of @xmath287 .    next we discuss how to estimate the weights @xmath294 .",
    "observe that the discretization gives an approximated stieltjes transform of @xmath287 as @xmath295 let @xmath296 be the approximation errors .",
    "the weights @xmath297 are then estimated by minimizing the approximation errors : @xmath298    we move on the estimation of the esd of icv by using theorem [ thm : main ] .",
    "we first need to estimate two unknowns , @xmath199 and @xmath200 , which we do as follows .",
    "first note that multiplying @xmath200 and @xmath199 on both sides of the first and second equations in respectively yields @xmath299and @xmath300where the last step is due to equation .",
    "it follows that @xmath301 and @xmath302 substituting the last expression of @xmath200 into equation yields @xmath303 by plugging the @xmath286 obtained in the first step and solving equation we get @xmath304 .",
    "we are now ready to estimate the esd of .",
    "similarly as in the first step , discretize @xmath305 as @xmath306 where @xmath307 s are weights to be estimated . by equation we expect that @xmath308 to be small .",
    "the @xmath307 s are then estimated by minimizing the approximation errors @xmath309 just as in .",
    "figure [ fig : thm1 - 2 ] below illustrates the estimation procedure .",
    "the left plot shows three esds , those of , @xmath132 and pav respectively .",
    "the three curves are clearly different from each . keep in mind that we only observe that of pav , whereas the esds of both  and @xmath132 are underlying and need to estimated .",
    "the estimation of the esd of @xmath132 is conducted in the first step , and the result is shown in the middle plot .",
    "the second step estimates the esd of , given in the right plot .",
    "we see in both plots that the estimated esds roughly match with their respective targets , showing that our proposed two - step procedure indeed works in practice .     and",
    "based on corollary [ cor : a_pav ] and theorem [ thm : main].,width=491 ]      in this subsection we illustrate how to use our alternative estimator @xmath261 and theorem [ thm : b_n ] to estimate the esd of . according to theorem [ thm : b_n ] ,",
    "asymptotically , the esd of @xmath261 is related to that of icv through the standard marenko - pastur equation .",
    "several algorithms have been developed to estimate the spectra of the population covariance matrices by inverting the marenko - pastur equation , and in the below we adopt the algorithm proposed in @xcite .",
    "set the window length @xmath40 in defining @xmath261 to be @xmath310 .",
    "discretize the esd of icv as . according to theorem [ thm : b_n ] ,",
    "the stieltjes transform of the esd of @xmath261 , denoted by @xmath311 , should approximately satisfy equation with @xmath196 replaced with the esd of icv .",
    "in other words , we again expect the approximation errors @xmath312 to be small .",
    "so again , we estimate the weights @xmath307 s by minimizing the approximation errors @xmath313 as in .    the estimation results are given in figure [ fig : thm3 ] .",
    "observe that the left plot shows clearly that the esd of @xmath261 differs from the ( latent unobserved ) esd of , yet the right plot shows that we can estimate this latent distribution .",
    "theorem [ thm : lsd_signal_noise ] is a consequence of the following proposition .    [",
    "prop : lsd_signal_noise ] under the assumptions of theorem [ thm : lsd_signal_noise ] , there exists a constant @xmath314 such that almost surely , for all @xmath315 we have @xmath316=0,\\ ] ] where for all @xmath0 large enough , @xmath317 is the unique solution to the equation @xmath318 in the set @xmath319 and @xmath320    the proof of proposition [ prop : lsd_signal_noise ] is given in section [ ssec : pf_prop_lsd_signal_noise ] after some preparation works have been done in sections [ ssec : t_n ] and [ ssec : prelim ] . in section [ ssec : thm_lsd_signal_noise ]",
    "we show how to establish theorem [ thm : lsd_signal_noise ] based on proposition [ prop : lsd_signal_noise ] .",
    "to prove proposition [ prop : lsd_signal_noise ] , we shall use the following results from @xcite . by theorem 1.1 therein , the sequence @xmath321 converges weakly to a probability distribution @xmath81 .",
    "moreover , by using the same truncation and centralization technique as in @xcite , we may assume that    [ asm : eps_bd ] @xmath322 for some @xmath323 ,    [ asm : eps_mean_var ] @xmath324 , @xmath325 , and    [ asm : a_bd ] @xmath326 .",
    "+    in addition to equation , we shall also study its limiting equation @xmath327 where @xmath328 is the stieltjes transform of the probability distribution @xmath81 .",
    "it is shown in @xcite that the distribution @xmath81 admits a continuous density on @xmath329 .",
    "since we assume that @xmath81 is supported by a finite interval @xmath109 $ ] with @xmath110 and possibly has a point mass at 0 , we conclude that @xmath81 admits a bounded density  @xmath330 supported by a finite interval @xmath109 $ ] and possibly a point mass at zero .",
    "[ lem : tn_exist ] there exists a constant @xmath331 such that for all @xmath332 , for all @xmath38 large enough , equation ( [ eqn : t_n ] ) admits a unique solution in @xmath333 .",
    "[ lem : t_properties ] suppose that @xmath9 solves equation for @xmath111 .",
    "write @xmath334 and @xmath335 . then @xmath336 ; moreover , as @xmath337 , uniformly in @xmath338 , one has @xmath339 and @xmath340 .",
    "[ lem : t_exist ] there exists a constant @xmath341 such that for any @xmath342 , equation admits a unique solution .",
    "[ lem : t_analytic ] there exists a constant @xmath343 such that the solution @xmath344 to is analytic on @xmath345 .",
    "[ lem : tlimit ] suppose that @xmath317 solves equation for @xmath346 , then @xmath347 and @xmath348 ; moreover if @xmath317 is the unique solution in the set @xmath333 , then with probability one , as @xmath35 , @xmath317 converges to a nonrandom complex number @xmath9 which uniquely solves equation .",
    "the proofs of lemmas [ lem : tn_exist ] - [ lem : tlimit ] are given in the appendix [ appendix : pfs ] .",
    "let @xmath349  @xmath350 for @xmath351 , @xmath352 and @xmath353 defined in lemmas [ lem : tn_exist ] , [ lem : t_exist ] and [ lem : t_analytic ] , respectively . and define @xmath354 .",
    "below we work with @xmath355 .",
    "let @xmath356 and @xmath357 , @xmath358 , be the @xmath28th column of @xmath97 and @xmath62 , and let @xmath359 .",
    "denote @xmath360 so that @xmath361 .",
    "for any complex number @xmath317 such that @xmath362 , define @xmath363    according to equation ( 2.2 ) in @xcite , we have @xmath364 thus using the identity @xmath365 we obtain that @xmath366    next we introduce another definition of @xmath317 , as the solution to the following equation @xmath367 we claim that the definition of @xmath317 in ( [ dfn : t_alternative ] ) is equivalent to the earlier definition of defining @xmath317 to be the solution to equation .",
    "in fact , write @xmath368 right - multiplying both sides by @xmath369 and using yield @xmath370 taking trace on both sides and dividing by @xmath38 one gets that @xmath371 this shows that if @xmath317 satisfies , then @xmath317 satisfies equation . on the other hand ,",
    "if @xmath317 satisfies equation , from we have @xmath372 namely , @xmath317 satisfies .",
    "recall the definitions of @xmath376 , @xmath377 , @xmath378 and @xmath379 in ( [ betaj ] ) . using ( [ rrbeta ] )",
    "we have @xmath380\\\\ & & + \\",
    "\\dfrac{t_n\\sigma_n^2}{p } \\ { \\rm",
    "tr}({\\bf r}_n^{-1}{\\bf b}_n^{-1}).\\end{aligned}\\ ] ] define @xmath381 certainly @xmath382 , but introducing @xmath383 makes the computations below more clear .",
    "recall that @xmath384 , and so @xmath385 . we can then rewrite @xmath386 as @xmath387 where @xmath388 where in the last equality we used the equivalent definition of @xmath317 .",
    "suppose that @xmath317 solves equation ( [ eqn : t_n ] ) for @xmath389 , then for all @xmath358 , @xmath390 is bounded by @xmath391 .",
    "[ betabound ]    suppose that @xmath317 solves equation ( [ eqn : t_n ] ) for @xmath389 , then @xmath392 is bounded by @xmath393 .",
    "[ bbound ]    suppose that @xmath317 solves equation ( [ eqn : t_n ] ) for @xmath389 , then the random variables @xmath394 satisfy @xmath395 where @xmath394 can be any of @xmath396 , @xmath397 , @xmath398 and @xmath399 defined in ( [ etaj ] ) , and @xmath400 is a constant independent of @xmath38 .",
    "[ rv4 ]    suppose that @xmath317 solves equation ( [ eqn : t_n ] ) for @xmath389 , then the random variables @xmath401 and @xmath402 satisfy @xmath403 [ ww ]    the proofs of lemmas [ betabound ] - [ ww ] are also given in the appendix [ appendix : pfs ] .",
    "recall the @xmath404 defined in . the proof will be completed if we show @xmath405 almost surely for all @xmath406 .",
    "by , and lemma [ bbound ] , there exists a constant @xmath400 such that @xmath407 moreover , by lemmas [ lem : t_properties ] , [ lem : tlimit ] and the convergence of @xmath321 , we have as @xmath56 , @xmath408 and @xmath409 . in particular , for all @xmath38 large enough , we have @xmath410    we now show that @xmath411 almost surely . using markov s inequality and hlder s inequality , for any @xmath412 , we have @xmath413 where the last step follows from lemmas [ betabound ] and [ ww ] .",
    "thus @xmath411 almost surely by lemmas [ lem : tlimit ] , [ lem : t_properties ] and the borel - cantelli lemma .",
    "similarly we can prove that @xmath405 almost surely for @xmath414 by using lemmas [ betabound ] , [ bbound ] , [ rv4 ] , [ ww ] and inequalities ( [ rhoj ] ) , ( [ delta0 ] ) .",
    "we first show that equation ( 1.1 ) in @xcite can be derived from proposition [ prop : lsd_signal_noise ] .    for any fixed @xmath355 , by proposition [ prop : lsd_signal_noise ] , lemmas [",
    "lem : tlimit ] , [ lem : t_properties ] , [ bbound ] , and the dominated convergence theorem we obtain that @xmath415 where @xmath9 is the unique solution to equation and @xmath416 .",
    "moreover , if we let @xmath417 , then by the definition of @xmath9 and the convergence we have @xmath418 and @xmath419 substituting the expressions of @xmath9 , @xmath420 and @xmath119 in terms of @xmath421 into equation ( [ rem ] ) yields @xmath422 where @xmath423 .",
    "next we show that holds for all @xmath424 .",
    "in fact , by lemma [ lem : t_analytic ] , @xmath425 is analytic on @xmath426 . in particular , for any convergent sequence @xmath427 such that @xmath428 as @xmath429 , we have @xmath430 , all in @xmath431 ; moreover , @xmath432 and @xmath433 all satisfy equation . noting that equation is well - defined for all @xmath424 , by the analyticity of @xmath434 on @xmath435 and the uniqueness theorem for analytic functions , we conclude that equation ( [ rem_limit ] ) holds for every @xmath424 , in other words , equation  ( 1.1 ) in @xcite holds .    in the following",
    ", we will show that equation ( [ eqn : lsd_signal_to_noisy ] ) in theorem [ thm : lsd_signal_noise ] holds .    for any @xmath355 ,",
    "denote @xmath436 , where , recall that , @xmath437 and @xmath438 .",
    "we further define @xmath439 we will show the following facts :    [ f1 ] @xmath440 ,    [ f2 ] @xmath441 , or @xmath442 .",
    "in fact , we can rewrite equation as @xmath443 noting that @xmath444 we have @xmath445 namely , holds .",
    "besides , @xmath446 implies @xmath447 since @xmath448 by lemma [ lem : t_properties ] .",
    "we now show .",
    "let @xmath449 .",
    "then @xmath450 by substituting and @xmath451 into equation , we obtain @xmath452 that is , @xmath453 therefore , @xmath454 namely , holds .    next , by and the definitions of @xmath455 and @xmath456 and , we have @xmath457 using the facts and we obtain that @xmath458 by plugging in the expression of @xmath459 , we see that for all @xmath460 , @xmath461 satisfies @xmath462 it follows from the uniqueness theorem for analytic functions that the above equation holds for all @xmath447 such that the integral on the right hand side is well - defined .",
    "it remains to show that the solution to equation is unique in the set  @xmath463 defined in .",
    "in fact , suppose otherwise that @xmath464 both satisfy equation .",
    "define for @xmath465 @xmath466 by and , we have @xmath467 hence @xmath468 which implies that @xmath469 using and we can rewrite @xmath455 as @xmath470 observing that the stieltjes transforms @xmath471 and @xmath472 are uniquely determined by equation at points @xmath473 and @xmath474 respectively , together with , we obtain @xmath475 therefore @xmath476 which implies that @xmath477 .",
    "it then follows from that @xmath478 , a contradiction .",
    "rewrite equation ( [ eqn : t_n ] ) as @xmath479    firstly , under the assumptions of theorem [ thm : lsd_signal_noise ] , by theorem 1.1 in @xcite , if we let @xmath480 $ ] be an interval containing the support of  @xmath66 , then we may assume that for all large @xmath38 , @xmath481 .",
    "let @xmath482 , @xmath483 and @xmath484 . since @xmath485 and @xmath486 ,",
    "we have for all large @xmath38 and for all @xmath487 , @xmath488    define @xmath489 we will apply the banach fixed point theorem to show that for all @xmath38 large enough , there exists a unique point @xmath490 such that @xmath491 .",
    "the desired conclusion then follows .",
    "step ( i ) : we prove that the mapping @xmath492 is defined from @xmath493 to @xmath493 . from the definition of @xmath494 and that @xmath487 , we have @xmath495 and hence for all @xmath38 large enough , @xmath496 where the last inequality follows from the fact that for any @xmath497 , @xmath498    step ( ii ) : we shall show that @xmath499 is a contraction mapping .",
    "in fact , for any two points @xmath9 , @xmath500 , @xmath501    using cauchy - schwartz inequality we get that almost surely for all @xmath38 large enough , for all @xmath502 , @xmath503 which is strictly smaller than 1 when @xmath497 .",
    "therefore the mapping @xmath492 is contractive in @xmath493 , and the banach fixed point theorem guarantees the existence of a unique solution to equation ( [ eqn : t_n ] ) .    taking imaginary parts on both sides of equation ( [ eqn : t ] ) yields @xmath504 it is then straightforward to verify that @xmath505 and @xmath506 .",
    "furthermore , since @xmath507 when @xmath508 , we have @xmath509    denote @xmath510 and @xmath511 . by ,",
    "if @xmath81 admits a bounded density @xmath330 and possibly a point mass at 0 , then @xmath512 since @xmath513 is bounded and @xmath514 when @xmath515 , there exists a constant @xmath400 such that @xmath516 this , combined with , implies that @xmath517 in particular , uniformly in @xmath338 , @xmath518    moreover , from ( [ eqn : t ] ) we get @xmath519 thus as @xmath337 , @xmath520 also uniformly in @xmath338 .",
    "firstly , by the same proof as for lemma [ lem : tn_exist ] , one can show that for all @xmath335 with @xmath521 , equation admits a unique solution in @xmath333 defined in .",
    "moreover , by lemma [ lem : t_properties ] , if @xmath334 solves , then @xmath505 ; furthermore , we can find a constant @xmath352 such that if @xmath9 solves   for  @xmath119 with @xmath522 then we must have @xmath523 .",
    "the latter two properties imply that for all @xmath119 with @xmath524 the solution to must lie in @xmath333 . redefining @xmath525 if necessary",
    ", we see that for all @xmath346 , admits a unique solution .",
    "define a function @xmath492 as @xmath526 that @xmath527 solves is equivalent to @xmath528 .",
    "write @xmath335 and @xmath334 . by taking the partial derivative with respect to @xmath9",
    "we get @xmath529 note that @xmath530 which , by , goes to zero as @xmath337 .",
    "thus there exists a constant @xmath531 such that for all @xmath532 , @xmath533 .",
    "it follows from the implicit function theorem and lemma [ lem : t_properties ] that @xmath344 is analytic on @xmath534 .",
    "write @xmath335 and @xmath535 .",
    "similar to the proof of lemma [ lem : t_properties ] , taking imaginary parts on both sides of equation ( [ eqn : t_n ] ) , one can easily show that @xmath536 and @xmath537 .",
    "next we show that @xmath538 is tight , in other words , for any @xmath412 , there exists @xmath539 , such that for all @xmath38 large enough , @xmath540 . since @xmath541",
    ", it suffices to show that @xmath542 is tight .",
    "let @xmath543 , and let @xmath544 be the stieltjes transform of the esd @xmath545 .",
    "the spectra of @xmath67 and @xmath546 differ by @xmath547 number of zero eigenvalues , hence @xmath548 and @xmath549 thus equation ( [ eqn : t_n ] ) can also be expressed as @xmath550 taking real parts on both sides yields @xmath551 solving for @xmath552 yields @xmath553    now suppose that @xmath554 is not tight , then with positive probability , there exists a subsequence @xmath555 such that @xmath556 . by",
    ", we have @xmath557 however , as @xmath40 goes to infinity , if @xmath556 , since @xmath558 is tight and @xmath559 , one gets that the rhs goes to 1 .",
    "this contradicts the supposition that @xmath556 .",
    "next , for any convergent subsequence @xmath560 in set @xmath333 , by , for all  @xmath561 large enough , we have @xmath562 .",
    "we can then apply the dominated convergence theorem to conclude that the limit point of @xmath560 must satisfy equation .",
    "by lemma [ lem : t_exist ] , the solution is unique , hence the whole sequence @xmath538 converges to the unique solution to equation .",
    "write @xmath535 .",
    "note that @xmath563{\\pmb\\xi}_j\\\\ & & = \\dfrac{v - t_{n2}\\sigma_n^2}{|z - t_n\\sigma_n^2|^2 } \\ { \\pmb\\xi}_j^t\\left(\\dfrac{1}{z - t_n\\sigma_n^2}{\\bf s}_{nj}-{{\\bf i}}\\right)^{-1 } { \\bf s}_{nj}\\left(\\dfrac{1}{\\overline{z - t_n\\sigma_n^2}}{\\bf s}_{nj}-{{\\bf i}}\\right)^{-1}{\\pmb\\xi}_j \\\\ & & \\geq 0,\\end{aligned}\\ ] ] where the last inequality is due to lemma [ lem : tlimit ] .",
    "therefore , @xmath564    any eigenvalue of @xmath565 can be expressed as @xmath566 , where @xmath567 is an eigenvalue of @xmath568 .",
    "we have @xmath569 where the last step follows from the fact that @xmath570 thanks to lemma [ lem : tlimit ] .",
    "we shall only establish the inequality for @xmath571 ; the other two variables @xmath397 and @xmath399 can be handled in a similar way by using lemma [ bbound ] .    since for any hermitian matrix @xmath572 and @xmath111 , @xmath573 , we have by lemma [ lem : tlimit ] that @xmath574    recall that @xmath359 , and @xmath357 satisfies @xmath575 .",
    "the strengthened assumption implies that @xmath576 .",
    "note also that @xmath357 is independent of @xmath577 and @xmath356 .",
    "moreover , using lemma [ xtrx ] in appendix [ appendix : lemmas ] , assumption and , we get @xmath578    using , , lemmas [ bbound ] and [ xtrx ] , and lemma 2.6 in @xcite , we obtain @xmath579 the result for @xmath402 can be proved similarly .",
    "the convergence of @xmath305 follows easily from assumption and the fact that @xmath580    next , by theorem 3.2 in @xcite , the assumption that @xmath81 has a bounded support implies that @xmath196 has a bounded support as well .",
    "thus assumption ( a.iii@xmath581 ) in @xcite that @xmath196 has a finite second moment is satisfied .",
    "we proceed to show the convergence of @xmath132 .",
    "as discussed in subsection  [ sssec : inf_pav ] , if the diffusion process @xmath157 belongs to class  @xmath158 , the drift process @xmath174 , and @xmath171 is independent of @xmath175 , then conditional on @xmath582 , we have @xmath583 where @xmath584 is as in and is independent of @xmath585 , and @xmath177 consists of independent standard normals .",
    "hence , @xmath132 has the same distribution as @xmath586 defined as @xmath587    * claim 1*. without loss of generality , we can assume that the drift process @xmath151 and @xmath171 is independent of @xmath175 .",
    "in fact , firstly whether the drift term @xmath130 vanishes or not does not affect the lsd of @xmath132 . to see this , note that @xmath588 , where @xmath589 and @xmath590 since all the entries of @xmath591 are of order @xmath592 , by lemma [ lemma1 ] in appendix [ appendix : lemmas ] , @xmath132 and @xmath593 have the same lsd .    next , by the same argument as in the beginning of proof of theorem 1 in @xcite , we can assume without loss of generality that @xmath170 is independent of @xmath10 .",
    "it follows that @xmath132 and @xmath586 have the same lsd .",
    "* claim 2*. @xmath594 is bounded , and there exists a piecewise continuous process @xmath595 with finitely many jumps such that @xmath596    in fact , using the boundedness of @xmath170 assumed in and that @xmath137 , one can easily show that @xmath594 is bounded .",
    "next we show that is satisfied for @xmath597 .",
    "define @xmath598    suppose that @xmath599 has @xmath600 jumps for @xmath601 . for each @xmath602",
    ", there exists an @xmath603 such that the @xmath28th jump falls in the interval @xmath604 .",
    "then @xmath605    since @xmath606 and @xmath607 are both bounded , for any @xmath608 and for @xmath38 large enough , we have @xmath609    for the second term @xmath610 , since @xmath599 is continuous in @xmath611 $ ] when @xmath612 , and by ( a.vi ) , @xmath170 uniformly converges to @xmath599 , for any @xmath608 and for @xmath613 large enough , we have @xmath614 , \\mbox { and } |{\\gamma}_t-{\\gamma}_t^*|<\\varepsilon\\mbox { for all } t.\\ ] ] moreover , since @xmath615 , for all large @xmath38 we have @xmath616 this completes the proof of .    since @xmath617 and @xmath618 for @xmath619 ,",
    "using claim 2 and applying theorem 1 in @xcite we conclude that the esd of @xmath132 converges to @xmath101 whose stieltjes transform satisfies @xmath620 where @xmath199 , together with another function @xmath200 , uniquely solve the following equations in @xmath201 @xmath621      note that the convergence of the esd of @xmath260 has been proved in theorem [ thm : main ] .",
    "the rest of theorem [ thm : b_n ] is a direct consequence of the following two convergence results .",
    "[ pthm3_a ] under the assumptions of theorem [ thm : b_n ] , we have @xmath622    [ pthm3 ] under the assumptions of theorem [ thm : b_n ] , @xmath623 converge almost surely , and the limit @xmath624 is determined by @xmath185 in that its stieltjes transform @xmath625 satisfies the following equation @xmath626    we will prove proposition [ pthm3 ] first , and then give the proof of lemma  [ pthm3_a ] afterwards .",
    "we now show the convergence of @xmath627 .",
    "the main reason that we choose  @xmath40 in such a way that @xmath628 is to make the noise term negligible . to be more specific , by choosing @xmath629 for some @xmath248 where @xmath249 is the integer as in assumption , we shall show that @xmath630 have the same lsd .",
    "this will follow if we can show that @xmath631 and @xmath632    we start with .",
    "since @xmath633 in order to prove , it suffices to show @xmath634 below we shall prove the following slightly stronger result : @xmath635 where for any vector @xmath636 , @xmath637 denotes its @xmath28th entry .",
    "notice further that for , using lemma [ lemma1 ] in appendix [ appendix : lemmas ] , to prove , it also suffices to show .",
    "we now prove .",
    "we start with the denominator term @xmath59 .",
    "we have @xmath588 for @xmath591 and @xmath638 defined in and respectively .",
    "write @xmath638 as @xmath639 , where @xmath584 is defined in and @xmath640    by assumption , for all @xmath641 , @xmath642 are @xmath643 . by using the same trick as the proof of ( 3.34 ) in @xcite",
    ", we have @xmath644 note that @xmath645 assumption implies that for all @xmath271 , there exist @xmath646 such that @xmath647 therefore by assumption , there exists @xmath539 such that @xmath648 which , together with , implies that there exists @xmath649 such that for all @xmath38 large enough , @xmath650 moreover , by assumption , @xmath651 for all @xmath652 , hence @xmath653 , which , by assumption , is @xmath654",
    ". therefore , there exists a constant @xmath655 such that , almost surely , for all  @xmath38 large enough , @xmath656    it remains to prove that @xmath657 observe that if we can show there exists @xmath539 such that @xmath658 where @xmath659 is the integer satisfying @xmath660 as in assumption , then for any @xmath608 , by markov s inequality , we have @xmath661 where the last equation is due to assumption . since @xmath660 , we have @xmath662 , hence by the borel - cantelli lemma , holds .",
    "we now show , which is a marcinkiewicz - zygmund type inequality .",
    "we will use theorem 1 in @xcite to prove .",
    "for that we need to verify @xmath663 , where @xmath664 where @xmath665    we now verify that @xmath663 . for any @xmath28 and for any @xmath666 , using the definition of @xmath217-mixing coefficients we have @xmath667 by hlder s inequality , we have @xmath668 and similarly for @xmath669 . since @xmath227 s have bounded @xmath228th moments according to assumption and @xmath670 , we get @xmath663 .",
    "finally , by using a similar argument as in the last part of the proof of proposition 8 in @xcite ( see pp.31423143 ) , we have that @xmath671 has the same lsd as @xmath672 where @xmath673 consists of independent standard normals .",
    "it is well known that the lsd of @xmath674 is determined by , hence by the previous arguments , so does that of @xmath675",
    ".    now we prove lemma [ pthm3_a ] .",
    "we have @xmath676 the convergence and that @xmath677 imply that @xmath678 almost surely .",
    "to prove the lemma , it then suffices to show that @xmath679 and @xmath680    we start with .",
    "write @xmath588 as in the proof of proposition  [ pthm3 ] .",
    "the convergence implies that @xmath681 where the error term converges to 0 almost surely . by riemann integration and assumption",
    "it is easy to show that @xmath682 , so we get @xmath683 furthermore by using the bound that @xmath653 one can easily show that @xmath684 we therefore get .",
    "finally , follows from and .",
    "motivated by the inference about the spectra of the matrix based on high - frequency noisy data ,    we establish an asymptotic relationship that describes how the spectral distribution of ( true ) sample covariance matrices depends on that of sample covariance matrices constructed from noisy observations ;    using further a ( generalized ) connection between the spectral distribution of true sample covariance matrices and that of the population covariance matrix , we propose a two - step procedure to estimate the spectral distribution of icv for a class of diffusion processes ;    we further develop an alternative estimator which possesses two desirable properties : it eliminates the impact of microstructure noise , and its limiting spectral distribution depends only on that of the icv through the standard marenko - pastur equation ;    numerical studies demonstrate that our proposed methods can be used to estimate the spectra of the underlying covariance matrix based on noisy observations .",
    "( lemma 2.7 in @xcite ) .",
    "let @xmath685 be a vector where the @xmath686 s are centered random variables with unit variance .",
    "let @xmath71 be an @xmath687 deterministic complex matrix .",
    "then , for any @xmath688 , @xmath689 [ xtrx ]      * @xmath694 with @xmath140 ; * there exists a sequence @xmath695 such that for all @xmath0 and all @xmath696 , all the entries of @xmath697 are bounded by @xmath698 in absolute value ; * @xmath699 almost surely .",
    "barndorff - nielsen , o. e. , hansen , p. r. , lunde a. and shephard n. ( 2008 ) .",
    "designing realized kernels to measure ex - post variation of equity prices in the presence of noise , _ econometrica _ , * 76 * , 1481 - 1536 .",
    "zhang , l. , mykland , p. a. and at - sahalia , y. ( 2005 ) .",
    "a tale of two time scales : determining integrated volatility with noisy high - frequency data , \" _ journal of the american statistical association _ , * 100 * , 1394 - 1411 ."
  ],
  "abstract_text": [
    "<S> in practice , observations are often contaminated by noise , making the resulting sample covariance matrix to be an information - plus - noise - type covariance matrix . aiming to make inferences about the spectra of the underlying true covariance matrix under such a situation </S>",
    "<S> , we establish an asymptotic relationship that describes how the limiting spectral distribution of ( true ) sample covariance matrices depends on that of information - plus - noise - type sample covariance matrices . as an application </S>",
    "<S> , we consider the inference about the spectra of integrated covolatility ( icv ) matrices of high - dimensional diffusion processes based on high - frequency data with microstructure noise . </S>",
    "<S> the ( slightly modified ) pre - averaging estimator is an information - plus - noise - type covariance matrix , and the aforementioned result , together with a ( generalized ) connection between the spectral distribution of true sample covariance matrices and that of the population covariance matrix , enables us to propose a two - step procedure to estimate the spectral distribution of icv for a class of diffusion processes . </S>",
    "<S> an alternative estimator is further proposed , which possesses two desirable properties : it eliminates the impact of microstructure noise , and its limiting spectral distribution depends only on that of the icv through the standard marenko - pastur equation . </S>",
    "<S> numerical studies demonstrate that our proposed methods can be used to estimate the spectra of the underlying covariance matrix based on noisy observations .    </S>",
    "<S> with applications to integrated covolatility matrix inference in the presence of microstructure noise </S>"
  ]
}