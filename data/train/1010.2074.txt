{
  "article_text": [
    "case - control designs are frequently implemented in clinical studies where , instead of taking a random sample of a mixed population of both cases and non - cases , a fixed number of cases and a fixed number of controls are randomly sampled from the respective populations of cases and non - cases . because the resulting samples are no longer random or independently and identically distributed ( i.i.d . )",
    ", the classical large - sample asymptotic theories could fail to apply . in the literature ,",
    "two main approaches are taken in order to adapt the large - sample theory to the case - control setting .",
    "the first approach is highlighted in breslow _",
    "( @xcite ) , where a modified design of the usual case - control study is proposed . the resulting random sample",
    "is then linked to the true case - control sample through using results from mcneney ( @xcite ) , where the similarity between random and non - random sample asymptotic properties is developed by almost establishing the whole asymptotic theory under non - i.i.d .",
    "the second approach is somewhat more direct and is implicitly used by rabinowitz ( @xcite ) . instead of treating the indicator ( @xmath0 ) of case / control as a random variable , @xmath0",
    "is assumed to be known and all the calculations are performed conditionally on @xmath0 . although it does result in the conditional randomness of the case - control samples , the resulting data is not really identically distributed .",
    "specifically , two different distributions are involved and the large - sample theory is still not available . strictly speaking , the asymptotic theory for non - i.i.d .",
    "data rederived in mcneney ( @xcite ) also needs to be applied in order to treat such a combination of two sample cases .",
    "in addition to the complexity arising from a case - control design , the problem considered in this article is also a semiparametric model problem , whose efficient estimator has not yet been explored even in the i.i.d .",
    "data situation . specifically , the problem is as follows .",
    "suppose that in the general population , the occurrence of a disease ( @xmath1 ) follows a logistic model @xmath2 , where @xmath3 represents a person s genetic character and @xmath4 represents the environmental elements .",
    "further , suppose that @xmath3 and @xmath4 are independent of each other and that we are interested in the effect of gene , environment and their interaction on the disease status .",
    "thus , @xmath5 .",
    "the parametric form of the distribution of gene @xmath6 is assumed to be known as @xmath7 , where @xmath8 is an unknown finite - dimensional parameter .",
    "the distribution of the environment , @xmath9 , is unspecified . a special version of this problem is considered in chatterjee and carroll ( @xcite ) , where @xmath10 is assumed to be a discrete distribution .",
    "there , the authors derived a profile maximum likelihood estimator for @xmath11 and showed that it is root-@xmath12 consistent , where @xmath12 is the size of the combined samples .",
    "the estimator is later extended to a more general framework in spinka _",
    "( @xcite ) .",
    "however , it is not investigated whether the estimator achieves the optimal semiparametric efficiency .    in this paper , we first establish in section  [ sec : casecontrol ] that the classical semiparametric theory of bickel _ et al .",
    "_  ( @xcite ) is applicable in general case - control studies , without having to rederive the theory in parallel or having to resort to the results from mcneney ( @xcite ) .",
    "such first order asymptotic equivalence between case - control sampling and random sampling is a new result .",
    "we then proceed to compute the semiparametric efficient score and construct a semiparametric estimator for @xmath13 in section  [ sec : estimator ] .",
    "the computation is carried out in a hypothetical population described in section  [ sec : casecontrol ] .",
    "this differs from the real population from which the cases and controls are drawn .",
    "hence , the derivation has its own interest and novelty . in this section",
    ", we also prove that although the estimation of the nuisance parameter @xmath14 is bypassed in our estimator , the resulting semiparametric estimator still achieves the optimal efficiency .",
    "the proof and treatment is rather non - standard .",
    "numerical examples are included in section  [ sec : simulation ] to demonstrate the performance of the proposed estimator .",
    "the performance of the method in the discrete gene model is close to that of the method in chatterjee and carroll ( @xcite ) and we pointed out the possible equivalence between the two methods in section  [ sec : discuss ] .",
    "some analytical derivations and technical details are included in the .",
    "the samples from a case control study are not random because the disease status is not random . in general , the design randomly samples @xmath15 individuals from the case population and @xmath16 from the non - case population .",
    "however , let us consider a hypothetical population of interest with infinite population size , in which the disease to non - disease ratio is fixed at @xmath17 . here , the reason for introducing the notion of hypothetical population is to be able to use the classical semiparametric theory for i.i.d .",
    "data , developed in bickel _",
    "( @xcite ) .",
    "if the sample of size @xmath18 from a case - control study happens to be a random sample from the hypothetical population of interest , then we have a size-@xmath12 i.i.d",
    ".  random sample and the usual semiparametric analysis will apply .",
    "the asymptotic results hold when @xmath19 and @xmath20 stays fixed .",
    "of course , the problem is that a random sample of size @xmath12 from the hypothetical population of interest does not have to have exactly @xmath16 controls and @xmath15 cases , hence we can not immediately equate a case - control sample and a random sample from the hypothetical population . in general , the number of controls / cases of a random sample from the hypothetical population will have a binomial distribution @xmath21 , @xmath22 , which is very close to a normal distribution when @xmath12 is large , that is , @xmath23 in distribution when @xmath19 . here , the superscript @xmath24 stands for ` random . '",
    "furthermore , the probability of having @xmath25 goes to zero when @xmath19 .",
    "thus , we could think of the case - control sample as obtained by randomly picking a size-@xmath12 sample from the hypothetical population of interest , then deleting a random @xmath26 cases ( controls ) and adding a random @xmath26 controls ( cases ) . or ,",
    "alternatively , we can think of the case - control sample as a random sample of size  @xmath12 , but with a randomly chosen @xmath26 data contaminated in a particular way .",
    "this `` particular '' contamination implies the following three properties : ( i ) the contamination happens only to @xmath27 of the observations",
    "( in the case - control samples , the contamination in fact only happens to @xmath26 observations , but , in general , @xmath27 is already sufficient for our further analysis ) ; ( ii ) the contaminated data is still of order @xmath28 , that is , @xmath29 is bounded in probability for @xmath30 ; ( iii ) the zero expectation holds for the contaminated observations , that is , if an estimating equation for @xmath13 of the form @xmath31 satisfies @xmath32 , then @xmath33 as well .",
    "here , @xmath34 , are i.i.d .",
    "random samples , the superscript @xmath35 stands for ` contaminated ' and the subscript @xmath36 represents the true parameter value .",
    "when the case - control sample is viewed as a contaminated random sample from the hypothetical population of interest , the first two `` particular '' properties certainly hold . for the estimator we will construct",
    ", we shall demonstrate that the third property also holds .",
    "thus , if we can show that the same first order asymptotics apply to both the i.i.d .",
    "sample of size @xmath12 and its contaminated version as long as the three properties hold , then we can treat the case - control sample as an i.i.d .  sample .",
    "the argument is as follows .",
    "assume that we mistakenly treated the contaminated data as i.i.d .  and obtained an efficient estimator : @xmath37 here , @xmath38 is the efficient score function and its derivation is model - dependent .",
    "one obvious aspect of @xmath38 worth emphasizing is that the construction of @xmath38 does not depend on the observations .",
    "regardless of the method of derivation , the efficient score function @xmath38 has the property @xmath39 .",
    "if we had the uncontaminated data , our subsequent estimator for @xmath13 would have been @xmath40 .",
    "working with the contaminated data , ( [ eq : score ] ) is the estimating equation we really have .",
    "suppose that @xmath41 solves ( [ eq : score ] ) .",
    "we then have @xmath42 therefore , @xmath43 where @xmath44 lies on the line connecting @xmath45 and @xmath41 .",
    "note that in our `` particular '' contamination requirement , only @xmath27 terms yield a different @xmath46 from @xmath47 ( requirement ( i ) ) and , for each @xmath48 , the difference is @xmath49 ( requirement ( ii ) ) , so we have @xmath50\\\\[-8pt ] & = & e\\biggl\\{\\frac{\\partial s_{\\mathrm{eff}}(x_i;\\beta_0)}{\\partial\\beta^{\\mathrm{t}}}\\biggr\\}+\\mathrm{o}_p(1).\\nonumber\\end{aligned}\\ ] ] from the third `` particular '' property , we have @xmath51 ( we will prove that this property holds for the case - control data in section  [ sec : estimator ] ) . in conjunction with the fact that only @xmath27 of the terms @xmath52 are non - zero , we can further obtain @xmath53 the detailed argument of ( [ eq : part2 ] ) is the following .",
    "suppose for the first @xmath54 observations , @xmath48 .",
    "then we have @xmath55 note that @xmath56 has mean zero , hence @xmath57 . from @xmath54",
    ", we obtain the result in ( [ eq : part2 ] ) immediately .",
    "thus , plugging ( [ eq : part1 ] ) and ( [ eq : part2 ] ) into ( [ eq : expand ] ) , we obtain @xmath58 the above display is exactly the first order asymptotic expansion of the estimator for @xmath13 if we had performed the estimation procedure on the uncontaminated data .",
    "thus , we have demonstrated that the estimator obtained from contaminated data performs as well as the one obtained from uncontaminated data in terms of first order asymptotic properties .",
    "note that the efficient estimator can be replaced by a consistent estimator , say , a general @xmath59 instead of @xmath38 , as long as @xmath60 holds for @xmath22 .",
    "this ensures that @xmath61 as long as @xmath62 ( shown in section  [ sec : estimator ] ) , so the above derivation will still carry through .",
    "hence , the asymptotic property of the estimator using the contaminated data is indeed the same as if we had the uncontaminated data .",
    "thus , the case - control data can be treated as i.i.d .",
    "data and we can achieve the same efficiency as when the data was indeed i.i.d . in other words ,",
    "a semiparametric estimator using contaminated data is at least as efficient as one using the uncontaminated data .",
    "one question still remains : can we do even better than in the i.i.d .",
    "data case ?",
    "in fact , since case - control sampling is designed to be an efficient way to collect covariate information , it seems to contain more information than a random sample .",
    "however , we claim that for asymptotically linear estimators of the form @xmath63 where @xmath64 , the efficiency in parameter estimation can not be further improved by taking into account the special sampling procedure .",
    "this is because otherwise , we could have obtained a better estimator for the i.i.d .",
    "sample as well , by replacing @xmath47 with @xmath46 .",
    "the detailed derivation is the same as in the above paragraph , where the condition @xmath64 implies @xmath65 for case - control data , which ensures  .",
    "of course , if the condition @xmath66 is not satisfied , the argument does not work .",
    "however , we now show that if @xmath67 achieves the optimal variance for the case - control data @xmath47 , then it has to satisfy @xmath68 .",
    "first , @xmath69 because the probability density function ( p.d.f . ) of @xmath0 does not contain @xmath13 .",
    "if we let @xmath70 , then @xmath71 and @xmath72 .",
    "if @xmath73 , then we can obtain @xmath74+\\operatorname{var}[e\\{\\psi(x_i^c)|d\\ } ] = \\operatorname{var}\\{\\tilde\\psi(x_i^c)\\}+\\operatorname{var}[e\\{\\psi(x_i^c)|d\\ } ] \\\\",
    "& > & \\operatorname{var}\\{\\tilde\\psi(x_i^c)\\},\\end{aligned}\\ ] ] which , together with @xmath72 , contradicts the fact that @xmath75 is optimal .    in summary",
    ", we have shown that the case control samples can be treated as if they were i.i.d .  and all the first order asymptotic results for i.i.d .",
    "data will be inherited for case - control data as well .",
    "we can see that the above establishment is similar to the development in breslow _",
    "_  ( @xcite ) . however , one prominent difference is that in breslow _",
    "et al . _  ( @xcite )",
    ", the case - control sample is viewed as the result of a biased sampling procedure with fixed subsample size , hence they can not use the classical semiparametric theory for i.i.d .  data , but have to refer to mcneney ( @xcite ) for the theoretical properties , where the whole semiparametric theory for fixed - size subsamples is established in parallel to the i.i.d .  framework . here ,",
    "through introducing the notion of hypothetical population and by analyzing the first order equivalence between a random sample and a sample with fixed - size subsamples , we can easily contain the case - control problem in the usual i.i.d .",
    "model framework .",
    "the derivation is much simpler and more elegant .",
    "thus , in the remainder of the paper , we ignore the case - control nature of the data and proceed with our analysis by pretending the data is i.i.d .",
    "from the aforementioned hypothetical population of interest .",
    "a random sample from the hypothetical population of interest has p.d.f .",
    "@xmath76 here , the superscript @xmath77 stands for the p.d.f .  in the true population , whereas expressions without superscripts , including various p.d.f.s and expectation @xmath4 , are quantities in the hypothetical population of interest ; @xmath78 is the unknown infinite - dimensional parameter and @xmath79/[1+\\exp\\{m(g , e)\\ } ] \\\\ & = & \\exp\\{d(\\beta_c+\\beta_1g+\\beta_2e+\\beta_3ge)\\}/\\{1+\\exp(\\beta_c+\\beta_1g+\\beta_2e+\\beta_3ge)\\ } ; \\\\ p_d^t(d ; \\beta,\\eta ) & = & \\int q(g,\\beta_4)\\eta(e)h(d , g , e;\\beta)\\,\\mathrm{d}\\mu(g)\\,\\mathrm{d}\\mu(e).\\end{aligned}\\ ] ] we recognize that estimating the finite - dimensional parameter @xmath13 in the presence of an infinite - dimensional nuisance parameter @xmath14 , using an i.i.d .  sample of size @xmath18 from a hypothetical population of interest , with the p.d.f .  of a random observation given by ( [ eq : pdf ] ) ,",
    "is a classical semiparametric problem .",
    "therefore , we implement the semiparametric estimation methods to derive the semiparametric efficient estimator . the approach we take is geometric , first introduced in bickel _",
    "et al . _  ( @xcite ) . because the general approach and related concepts have been nicely described in several recent papers including tsiatis and ma ( @xcite ) , allen _ et al . _  ( @xcite ) , ma _",
    "et al . _  ( @xcite ) and ma and tsiatis ( @xcite ) , here , we only briefly outline the general approach and the definition of the relevant concepts , referring the reader to these papers for more detailed descriptions .    in general semiparametric problems , one approach to construct estimators for @xmath13",
    "is to obtain some influence function @xmath80 which is subsequently used to form estimating equations for @xmath13 in the form of @xmath81 . here ,",
    "@xmath82 , are i.i.d",
    ".  observations .",
    "the solution of the estimating equation , @xmath41 , is subsequently a semiparametric estimator and its variance has been established to be equal to the variance of @xmath80 .",
    "consequently , the optimal estimator among the class of all such estimators is the one whose influence function has the smallest variance .",
    "this is usually referred to as the _ semiparametric efficient estimator_.    the geometric approach considers the space in which all influence functions belong .",
    "specifically , one considers a hilbert space @xmath83 which consists of all zero - mean measurable functions with finite variance and the same dimension as @xmath13 .",
    "the inner product in @xmath83 is defined as the covariance .",
    "the hilbert space @xmath83 is further decomposed into two spaces , the nuisance tangent space @xmath84 and its orthogonal complement @xmath85 .    to understand the nuisance tangent space @xmath84 , consider first the case where the nuisance parameter , denoted @xmath86 , is finite - dimensional .",
    "then , the nuisance score function , @xmath87 , spans a linear space , which is denoted @xmath84 . in the case of the infinite - dimensional nuisance parameter @xmath14 ,",
    "the corresponding @xmath84 is defined as the mean squared closure of the span of all the nuisance score functions @xmath88 , where @xmath89 is any parametric submodel of @xmath90 .",
    "the orthogonal complement of @xmath84 in @xmath83 is subsequently defined as  @xmath85 .",
    "any function in @xmath85 can be properly normalized to obtain a valid influence function .",
    "on the other hand , every influence function is a function in @xmath85 . among all these functions , the projection of the score function @xmath91 results in the efficient influence function .",
    "if we denote the projection by @xmath38 , then the corresponding optimal variance is @xmath92 .",
    "the projection @xmath38 is usually called the _ efficient score function_.    hence , the geometric approach converts the problem of searching for efficient semiparametric estimators to the problem of calculating @xmath38 .      following the description in section",
    "[ sec : geometry ] , we obtain the efficient score function @xmath38 . viewing the sample as random from the hypothetical population , the p.d.f .  in ( [ eq : pdf ] )",
    "is no longer in a simple multiplicative form , in that the nuisance parameter appears both in the numerator and in the integral in the denominator . since this implies that the nuisance tangent space is not automatically orthogonal to the score functions , the related computation for the nuisance tangent space and associated objects is more involved .",
    "in addition , one needs to be aware that the calculation should be carried out with respect to the hypothetical population , hence quantities such as @xmath93 need to be treated with extra care and not confused with @xmath94 .",
    "the main steps of the derivation are as follows .",
    "we first calculate the score function @xmath95 by taking the derivative of @xmath96 with respect to @xmath13 .",
    "this results in @xmath97 , where @xmath98 we then calculate the two spaces @xmath99 by replacing @xmath14 in ( [ eq : pdf ] ) with a finite - dimensional parameter @xmath86 , taking the derivative of @xmath100 with respect to @xmath86 to obtain @xmath88 , hypothesizing a space of all such @xmath88 and proving that @xmath84 is equivalent to this space .",
    "the results are @xmath101 = [ h(e)-e\\{h(e)|d\\}{}\\dvt",
    "{ } \\forall h(e)],\\\\ \\lambda^\\perp&=&[h(g , e , d){}\\dvt { } e(h|e)=e\\{e(h|d)|e\\}].\\end{aligned}\\ ] ] we finally project the score vector @xmath95 onto @xmath85 to obtain @xmath102 , where @xmath103 represents the projection of @xmath95 onto @xmath84 .",
    "the details of the derivation can be found in the .",
    "note that this form of @xmath38 implies that @xmath104 .",
    "when @xmath105 is replaced by @xmath106 , the non - random case - control sample , we still have @xmath107 because the design itself guarantees that the only non - random component is  @xmath108 , which is held constant . thus ,",
    "viewing @xmath106 as a special contaminated version of @xmath105 , we still have @xmath109 , which is required in section  [ sec : casecontrol ] .    from the",
    ", we can further write @xmath110 where @xmath111 . in terms of the calculation of @xmath38 ,",
    "note that @xmath59 , @xmath112 and @xmath113 , as given in ( [ eq : w ] ) , are all functions with parameters @xmath13 and @xmath114 only .",
    "hence , as long as we can calculate @xmath114 , we will have the ability to evaluate @xmath59 , @xmath112 and @xmath113 .",
    "the computation of @xmath115 requires further arguments . in the following ,",
    "we first obtain an approximation of @xmath114 , then pursue the estimation of @xmath115 . to estimate @xmath114 , using @xmath116 to denote the probability density function of @xmath117 in the hypothetical population",
    ", we observe that @xmath118 replacing the moment @xmath119 with its sample moment through averaging across different observed @xmath120 s , we obtain @xmath121 note that the above two equations are not independent ",
    "one determines the other .",
    "but , in combination with @xmath122 , we can estimate @xmath114 completely .",
    "because the only approximation involved in estimating @xmath114 is replacing the mean with a sample mean , the calculation will produce a root-@xmath12-consistent estimator for @xmath123 and @xmath124 .",
    "we denote the estimators by @xmath125 and @xmath126 . in calculating @xmath127",
    ", we write @xmath128 as @xmath129 , instead of directly using the form in ( [ eq : pdf ] ) . since @xmath116 is the p.d.f .  of the environment variable in the hypothetical population",
    ", this enables us to replace the expectation @xmath119 with the average of the samples.=-1    the estimation of @xmath115 is much more tedious , and involves an almost brute force calculation of @xmath130 and @xmath131 .",
    "if we let @xmath132 and @xmath133 , then @xmath134 .",
    "the calculation of @xmath135 and @xmath136 follows from @xmath137 since @xmath59 can be calculated directly , we simply obtain the approximation of @xmath138 , by replacing the mean with sample mean and plugging in the estimated @xmath114 : @xmath139\\\\[-8pt ] & & { } \\big/ \\sum_{i=1}^n \\frac{\\int q(g)h(0,g , e_i)\\,\\mathrm{d}\\mu(g ) } { \\sum_d\\int n_dq(g)h(d , g , e_i ) \\,\\mathrm{d}\\mu(g)/\\hat p_d^t(d)},\\nonumber \\\\",
    "\\hat b_1&=&\\sum_{i=1}^n\\frac{\\int s(1,g , e_i)q(g)h(1,g , e_i)\\,\\mathrm{d}\\mu(g ) } { \\sum_d\\int n_dq(g)h(d , g , e ) \\,\\mathrm{d}\\mu(g)/\\hat p_d^t(d)}\\label{eq : b1}\\nonumber \\\\[-8pt]\\\\[-8pt ] & & { } \\big/\\sum_{i=1}^n\\frac{\\int q(g)h(1,g , e_i)\\,\\mathrm{d}\\mu(g ) } { \\sum_d\\int n_dq(g)h(d , g , e ) \\,\\mathrm{d}\\mu(g)/\\hat p_d^t(d)}.\\nonumber\\end{aligned}\\ ] ] the calculations of @xmath140 and @xmath141 are a bit more tricky . since @xmath142 taking expectation conditional on , say @xmath143 , we have @xmath144\\end{aligned}\\ ] ] or , equivalently , we obtain @xmath145}{1-e\\{w(e,0)|d=0\\}}.\\end{aligned}\\ ] ] hence , replacing mean by sample mean and using @xmath146 , @xmath147 is estimated by @xmath148}{1-\\hat e\\{w(e,0)|d=0\\}},\\end{aligned}\\ ] ] where @xmath149\\\\[-8pt ] & & { } \\big/ \\sum_{i=1}^n \\frac{\\int q(g)h(0,g , e_i)\\,\\mathrm{d}\\mu(g)}{\\sum_d\\int n_dq(g)h(d , g , e_i ) \\,\\mathrm{d}\\mu(g)/\\hat p_d^t(d)}\\nonumber\\end{aligned}\\ ] ] and @xmath150\\\\[-8pt ] & & { } \\big/ \\sum_{i=1}^n \\frac{\\int q(g)h(0,g , e_i)\\,\\mathrm{d}\\mu(g)}{\\sum_d\\int n_dq(g)h(d , g , e_i ) \\,\\mathrm{d}\\mu(g)/\\hat p_d^t(d)}.\\nonumber\\end{aligned}\\ ] ] similarly to the estimation of @xmath114 , the only approximation involved in obtaining @xmath151 and @xmath152 is replacing mean by sample mean , so @xmath115 is estimated using @xmath153 at the root-@xmath12 rate .",
    "we would like to emphasize that in all of the above calculations , when we replace the expectation with the sample average , we use the result that the case - control sample can be treated as a random sample from the hypothetical population .",
    "hence , for any function @xmath154 , the approximation @xmath155 can only be used to replace @xmath156 , not @xmath157 .",
    "we omitted the parameter @xmath13 in all of the above expressions , in fact , @xmath158 are all functions of @xmath13 .",
    "however , if we replace @xmath13 with @xmath159 , an initial estimator of @xmath13 , we will still obtain @xmath160 that are root-@xmath12-consistent , as long as @xmath161 .",
    "the final estimating equation of @xmath13 has the form @xmath162 where @xmath163 denotes the @xmath164th observation @xmath165 .    to summarize the description of the estimator",
    ", we outline the algorithm here :    1 .   pick a starting value @xmath159 that is root-@xmath12 consistent .",
    "solve for @xmath125 and @xmath166 from ( [ eq : pd ] ) .",
    "3 .   obtain @xmath167 and @xmath168 from ( [ eq : b0 ] ) and ( [ eq : b1 ] ) .",
    "4 .   obtain @xmath169 from ( [ eq : c ] ) and ( [ eq : w0 ] ) , ( [ eq : w1 ] ) . 5 .",
    "calculate @xmath38 using ( [ eq : effscore ] ) and obtain @xmath170 from solving ( [ eq : esteq ] ) .",
    "it is worth pointing out that in order to carry out step 1 , we have used a vital assumption that a root-@xmath12 starting value @xmath159 exists .",
    "fortunately , the existence of @xmath159 is equivalent to the identifiability of @xmath13 and is already well established in chatterjee and carroll ( @xcite ) .",
    "the starting value used there , or in spinka _",
    "et al . _  ( @xcite ) , can be used to obtain the initial estimator @xmath159 .",
    "our algorithm here does not require an iteration of steps 25 upon each update of @xmath13 .",
    "however , in practice , a more accurate @xmath159 can improve the final estimation @xmath41 significantly , hence iterations are almost always implemented .      if we could use the exact @xmath171 and @xmath172 in ( [ eq : esteq ] ) , then , according to section  [ sec : geometry ] , the resulting estimator for @xmath13 would be an efficient estimator , with estimation variance @xmath173 . to first order , @xmath174 can be approximated using @xmath175 , where @xmath41 solves ( [ eq : esteq ] ) .",
    "we claim that using the estimated @xmath176 as in ( [ eq : esteq ] ) , we obtain an estimating equation that yields the same estimator for @xmath13 as using @xmath38 , in terms of its first order asymptotic properties .    [",
    "th : thm ] the algorithm in section  [ sec : construct ] yields a semiparametric efficient estimator for @xmath13 .",
    "that is , @xmath177 in distribution when @xmath19 and @xmath178 is fixed .",
    "the proof of the theorem contains two main steps . in the first step ,",
    "we show the semiparametric efficiency of the estimator if the observations had been i.i.d . in the second step ,",
    "we proceed to show the efficiency in the case - control study using results in section  [ sec : casecontrol ] .",
    "rather complex algebra needs to be employed in the first step .",
    "the proof also involves a split of the data in the final estimation of @xmath13 , and in estimating @xmath114 and @xmath115 , mainly for technical convenience .",
    "the details of the proof appear in the .",
    "we conducted a small simulation study to demonstrate the performance of the estimator . in the first experiment",
    ", we generated 500 cases and 500 controls , where the true environment element @xmath4 is @xmath179 and @xmath105 is generated from a log - normal distribution with mean 0 and variance 1 .",
    "a dichotomous model of the gene is used , where @xmath180 with probability @xmath8 and @xmath181 with probability @xmath182 .",
    "this kind of model for @xmath7 can represent the presence / absence of a certain gene mutation .",
    "we used two different sets of values for @xmath13 : the first set is @xmath183 , where @xmath184 represents a relatively common mutation ; the second set is @xmath185 , where @xmath186 represents a very rare mutation . in both sets , the true parameters",
    "are chosen so that the model results in a population disease rate @xmath187 .",
    "the simulation results are presented in the upper half of table  [ table : simu ] .",
    "@ld2.4d1.4d1.4d1.4d1.4 d2.4d1.4d1.4d1.4d1.4@ & & & & & & & & & & + & + true & -3.2000 & 0.2600 & 0.1000 & 0.3000 & 0.0650 & -3.4500 & 0.2600 & 0.1000 & 0.3000 & 0.2600 + est & -3.8925 & 0.2498 & 0.0995 & 0.3101 & 0.0649 & -3.9263 & 0.2618 & 0.0994 & 0.2998 & 0.2610 + sd & 1.6390 & 0.3110 & 0.0359 & 0.1226 & 0.0111 & 1.3958 & 0.2196 & 0.0445 & 0.0783 & 0.0229 + @xmath188 & 1.6285 & 0.3236 & 0.0364 & 0.1192 & 0.0116 & 1.2534 & 0.1956 & 0.0422 & 0.0723 & 0.0207 + & + true & -3.2000 & 0.2600 & 0.1000 & 0.3000 & 0.3000 & -3.7300 & 0.2600 & 0.1000 & 0.3000 & 1.0000 + est & -3.3128 & 0.2553 & 0.0993 & 0.3126 & 0.2999 & -3.7442 & 0.2589 & 0.0995 & 0.3053 & 0.9986 + sd & 0.7815 & 0.1624 & 0.0352 & 0.0750 & 0.0101 & 0.2906 & 0.0685 & 0.0442 & 0.0405 & 0.0378 + @xmath188 & 0.7969 & 0.1663 & 0.0358 & 0.0789 & 0.0101 & 0.2859 & 0.0676 & 0.0439 & 0.0402 & 0.0373 +    the second experiment differs from the first one in its assumption on @xmath7 . here , we model @xmath7 with a laplace distribution with variance @xmath8 .",
    "this kind of model is typically used to model the gene expression level . to maintain an approximate @xmath189 disease rate in the population , we used @xmath190 and @xmath191 as the true parameter values .",
    "again , in the first set , @xmath192 represents a small variation in the population distribution for the gene expression levels , resulting in a more homogeneous population in terms of this gene . in the second set , @xmath193 represents a larger variation , so the population is more diversified .",
    "the simulation results are presented in the lower half of table  [ table : simu ] . in both experiments ,",
    "1000 simulations are implemented .    from table",
    "[ table : simu ] , it is clear that the estimator for @xmath194 is consistent in all four situations and the estimated standard deviation approximates the true one rather well .",
    "it is worth noting that the first experiment is a repetition of the same setting as in chatterjee and carroll ( @xcite ) and we observe very similar results .",
    "specifically , for @xmath195 in the upper - left table , their results for `` sd '' are 0.322 , 0.037 , 0.128 , 0.0122 , respectively , and those in the upper - right table are 0.198 , 0.043 , 0.075 and 0.0273 , respectively . although some numerical improvement can be observed in certain parameters ( for example @xmath8 ) , it can be a result of finite - sample performance and numerical issues .",
    "we conjecture that the estimator in chatterjee and carroll ( @xcite ) is equivalent to the method proposed here , hence is also efficient , although a rigorous proof is beyond the scope of this paper .",
    "it is also worth noting that the estimation of @xmath196 is more difficult than the remaining components of @xmath13 , in that the estimation has large variability .",
    "this is especially prominent in the discrete model setting for @xmath197 .",
    "indeed , the estimation result for @xmath196 has not been reported elsewhere and , without the gene - environment independence , @xmath196 is known to be unidentifiable ( prentice and pyke ( @xcite ) ) .",
    "this provides an intuitive explanation for the performance of @xmath198 we observe .",
    "the set of estimating equations is solved using a standard newton  raphson algorithm .",
    "semiparametric modeling and estimation to study the occurrence of a disease in relation to gene and environment has attracted much interest recently . however , despite the various estimators proposed in the literature , very little is understood in terms of the efficiency of the estimators .",
    "this is partly due to the fact that most estimators are constructed in rather ingenious ways , instead of following the standard lines of semiparametric theory .",
    "the other reason is that most such problems are set in a case - control design , which violates the i.i.d .",
    "assumption for standard semiparametric theory .    instead of rederiving the whole semiparametric theory under non - i.i.d .",
    "samples , we argue that case - control data can be treated as if they were i.i.d .",
    "data and the standard semiparametric efficiency theory will still apply .",
    "the equivalence of the first order asymptotic theory shown in this article is a new contribution .",
    "the argument is based on rather elementary statistics without involving advanced knowledge or highly specialized techniques .",
    "the establishment of the equivalence of the semiparametric efficiency between i.i.d .",
    "data and case - control data allows us to carry out the estimation using standard , well - established semiparametric theory .",
    "however , these standard analyses are performed under a hypothetical population of interest , hence the detailed derivation often requires special treatment , something which has not previously appeared in the literature . under the gene - environment independence assumption , we are able to explicitly construct a novel semiparametric estimator and show its efficiency .",
    "a  special feature of this estimator is that we never attempted to estimate the infinite - dimensional nuisance parameter @xmath14 itself , neither did we posit a model , true or false , for it .",
    "rather , we avoided its estimation and instead approximated quantities that rely on it .",
    "on the one hand , this enables us to carry out the estimation rather easily ; on the other hand , some asymptotic properties have to be rederived because any result that relies on the convergence properties of the nuisance parameter itself can no longer be used .",
    "finally , our simulation results support the theory we developed , in both discrete and continuous gene distribution cases .",
    "our simulation results in the discrete gene model are very similar to those of chatterjee and carroll ( @xcite ) , which leads us to believe that their estimator is also efficient .",
    "a demonstration of this aspect would be an interesting direction for future work .",
    "the programming of the method in chatterjee and carroll may seem easier .",
    "however , if the two methods are indeed equivalent , then the projection step in the current method should be equivalent to the profiling step in chatterjee and carroll , hence the computational effort and intensity should be equivalent .",
    "although we did not further expand our estimator to stratified case - control data , the method is clearly applicable there as well .",
    "we will use @xmath38 to construct our estimating equation .",
    "we calculate @xmath38 by projecting the score functions with respect to the parameters of interest @xmath199 onto the orthogonal complement of the nuisance tangent space .",
    "we first derive the score functions @xmath200 .",
    "straightforward calculation shows that the score function @xmath201 , where @xmath202 here , @xmath203 and @xmath204 represent partial derivatives with respect to @xmath205 . note that , in general , @xmath95 can be written as @xmath97 .",
    "we next derive the nuisance tangent space @xmath84 and its orthogonal complement @xmath85 . inserting the form of @xmath206 into ( [ eq : pdf ] ) , replacing @xmath9 by an arbitrary submodel @xmath207 and taking the derivative of @xmath208 with respect to @xmath86",
    ", we obtain @xmath209 .",
    "now , recognizing that @xmath210 for an arbitrary submodel can yield an arbitrary function of @xmath117 with mean zero calculated under the true @xmath9 , we obtain the nuisance tangent space : @xmath101 = [ h(e)-e\\{h(e)|d\\}{}\\dvt { } \\forall h(e)],\\\\ \\lambda^\\perp&=&[h(g , e , d){}\\dvt { } e(h|e)=e\\{e(h|d)|e\\}].\\end{aligned}\\ ] ] here , @xmath211 stands for an expectation calculated with respect to the true population distribution .",
    "the second expression for @xmath84 is more convenient because it allows @xmath212 to be an arbitrary function of  @xmath117 , hence this is the form of @xmath84 that we will use .    having obtained @xmath95 and the spaces @xmath84 and @xmath85 , we can proceed to derive the efficient score function @xmath213 . if we let @xmath214 , then @xmath215 .",
    "we now modify the expression of @xmath38 to facilitate its actual computation . letting @xmath216 , we can thus write @xmath217 . note that @xmath59 does not depend on @xmath14 and @xmath218 is either @xmath219 or @xmath220 .",
    "in addition , we have @xmath221 .",
    "this is equivalent to @xmath222=0,\\end{aligned}\\ ] ] which , in turn , is equivalent to @xmath223 let @xmath224 and @xmath225 we have @xmath226 or @xmath227 .",
    "consequently , @xmath228      to simplify notation , we denote @xmath229 , @xmath230 , @xmath231 , @xmath232 and @xmath233 .",
    "suppose we randomly partition the data into two groups : group 1 has @xmath234 observations and group 2 has @xmath235 observations . here , @xmath236 , @xmath237 .",
    "we use the first group to obtain @xmath238 , and @xmath239 , then use the second group to form the following estimating equation to estimate @xmath13 : @xmath240 we will first show that the resulting estimator satisfies @xmath241 in distribution when @xmath242 .",
    "the proof splits into several steps : first , obviously , @xmath243 and @xmath244 , as long as a root-@xmath12-consistent @xmath159 is inserted in the calculation of these quantities . a  standard expansion yields @xmath245 which can be rewritten as @xmath246.\\end{aligned}\\ ] ] the last equality uses the form of @xmath38 in ( [ eq : effscore ] ) and the fact that @xmath59 , @xmath112 and @xmath113 do not depend on @xmath247 . because @xmath248 and @xmath249 we actually have @xmath250 in addition , @xmath251 , so @xmath252    we now proceed to examine @xmath253 by examining each term in ( [ eq : effscore ] ) .",
    "@xmath59 is free of @xmath247 . as a function of @xmath247",
    ", we already have @xmath254 where we define @xmath255 and @xmath256 . using this notation , @xmath257 similarly to the calculation of @xmath258",
    ", we also have that for any function @xmath259 , @xmath260 thus @xmath261 these relations lead to @xmath262 consequently , we obtain @xmath263 since @xmath59 does not contain @xmath247 , @xmath264 is a function of @xmath265 only . because @xmath266 , we have @xmath267 , @xmath268 and @xmath269 . combining these results , we have @xmath270\\\\ & = & e\\biggl[\\frac{-u_2(e,1)u_1(e,0)+u_2(e,0)u_1(e,1 ) } { \\{u_1(e,0)+\\alpha u_1(e,1)\\}^2}\\biggr ] \\\\ & & { } + \\biggl(\\frac{b_2-b_0}{1-b_3}\\biggr)e\\biggl[\\frac{u_1(e,0 ) u_1(e,1)}{\\{u_1(e,0)+\\alpha u_1(e,1)\\}^2}\\biggr].\\end{aligned}\\ ] ] plugging in the expressions for @xmath271 , we obtain @xmath272\\\\ & & { } \\big/ \\biggl[{\\int\\frac{p_e(e)u_1(e,0 ) } { u_1(e,0)+u_1(e,1)\\alpha}\\,\\mathrm{d}\\mu(e)-\\int\\frac{p_e(e)u_1 ^ 2(e,0)}{\\{u_1(e,0)+ u_1(e,1)\\alpha\\}^2}\\,\\mathrm{d}\\mu(e)}\\biggr]\\\\ & = & \\int\\frac{\\alpha p_e(e)\\{u_1(e,0)u_2(e,1)-u_1(e,1)u_2(e,0)\\}}{\\{u_1(e,0)+ u_1(e,1)\\alpha\\}^2}\\,\\mathrm{d}\\mu(e ) \\\\ & & { } \\big/\\biggl[\\int\\frac{\\alpha p_e(e)u_1(e,0)u_1(e,1)}{\\{u_1(e,0)+u_1(e,1)\\alpha\\}^2}\\,\\mathrm{d}\\mu(e)\\biggr ] \\\\ & = & e\\biggl[\\frac{\\{u_1(e,0)u_2(e,1)-u_1(e,1)u_2(e,0)\\}}{\\{u_1(e,0)+u_1(e,1)\\alpha\\}^2}\\biggr]\\big/ e\\biggl[\\frac{u_1(e,0)u_1(e,1)}{\\{u_1(e,0)+u_1(e,1)\\alpha\\}^2}\\biggr],\\end{aligned}\\ ] ] thus , we have @xmath273 .",
    "the fact that @xmath273 , in combination with @xmath274 , yields @xmath275 thus , we indeed have @xmath276 asymptotically .    in fact , the classical @xmath277 also holds .",
    "this is because @xmath278 when @xmath19 .",
    "thus , our estimator is semiparametric efficient . because of the equivalence result developed in section [ sec : casecontrol ] , the estimator is also semiparametric efficient for case - control data .",
    "we split the data set into two groups with sizes @xmath234 and @xmath235 for simplicity of the asymptotic analysis . in reality",
    ", one can certainly use the whole data set in each stage of the estimation .",
    "this work was supported by nsf grant dms-0906341 .",
    "spinka , c. , carroll , r.j . and",
    "chatterjee , n. ( 2005 ) . analysis of case - control studies of genetic and environmental factors with missing genetic information and hyplotype - phase ambiguity .",
    "_ genetic epidemiology _ * 29 * 108127 ."
  ],
  "abstract_text": [
    "<S> we construct a semiparametric estimator in case - control studies where the gene and the environment are assumed to be independent . </S>",
    "<S> a discrete or continuous parametric distribution of the genes is assumed in the model . </S>",
    "<S> a discrete distribution of the genes can be used to model the mutation or presence of certain group of genes . </S>",
    "<S> a continuous distribution allows the distribution of the gene effects to be in a finite - dimensional parametric family and can hence be used to model the gene expression levels . </S>",
    "<S> we leave the distribution of the environment totally unspecified . </S>",
    "<S> the estimator is derived through calculating the efficiency score function in a hypothetical setting where a close approximation to the samples is random . </S>",
    "<S> the resulting estimator is proved to be efficient in the hypothetical situation . </S>",
    "<S> the efficiency of the estimator is further demonstrated to hold in the case - control setting as well . </S>"
  ]
}