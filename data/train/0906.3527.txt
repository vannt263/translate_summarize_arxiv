{
  "article_text": [
    "we show a polynomial - space algorithm that solves general instances of integer - valued max 2-csp(formally defined in section  [ sec : pre ] ) , but that takes advantage of `` simple '' clauses , namely unit - weighted conjunctions and disjunctions , to reduce the running time . in a sense made precise near remark  [ booleanfunctions ] , exclusive - or is the only boolean function we can not treat efficiently .",
    "let us give a simple example . in the max 2-cspinstance",
    "@xmath3 the first two clauses are unit - weighted disjunctive clauses , the third clause is a unit - weighted conjunction , the fourth clause is a disjunction with weight 3 , and the last clause is a general integer - valued csp clause ( any integer - valued 2-by-2 truth table ) .",
    "thus this example has 3 ( the first three clauses ) simple clauses and 2 non - simple clauses , for a fraction of non - simple clauses of @xmath4 .",
    ".[tab : papers]a historical overview of algorithms for max 2-satand max 2-csp [ cols=\"<,<,<,<\",options=\"header \" , ]     thus , starting from @xmath5 , assigning to any two neighbors of @xmath6 their color @xmath7 results in an instance in which @xmath8 , and thus in which an optimal assignment for @xmath6 is @xmath9 .",
    "this proves the lemma .",
    "a half - edge reduction or 1-reduction is `` good '' if the target vertex has degree at least @xmath10 , because ( as the weights will come out ) the measure decrease due to @xmath11 is substantial for @xmath12 , but small ( in fact ,  0 ) for @xmath13 and @xmath14 .",
    "if for example we start with a simplified instance ( in which all vertices must have degree at least @xmath10 ) and reduce on a vertex of degree  d , deleting it and its incident half - edges , each of the @xmath15 remaining half - edges implies a good degree reduction on a neighboring vertex . however , if we deleted several vertices , this might not be the case : if two deleted vertices had a common neighbor of degree  3 , its degree would be reduced from 3 to 2 by one half - edge reduction ( good ) , but then from 2 to 1 by the other ( not good ) .",
    "the following lemma allows us to argue that a certain number of good half - edge reductions occur .",
    "the lemma played a helpful role in our thinking about the case analysis , but in the presentation here we invoke it rarely : the cases dealt with are relatively simple , and explicit arguments are about as easy as applying the lemma .",
    "note that for any half edge incident on a vertex  @xmath16 , we can substitute a full edge between @xmath16 and a newly introduced vertex  @xmath17 : after performing a half - edge reduction on @xmath16 in the first case or a 1-reduction in the second , the same instance results .",
    "( also , the measure increase of @xmath18 when we add the degree-1 vertex and half - edge is canceled by the extra decrease for performing a 1-reduction rather than a half - edge reduction . ) for clarity of expression , the lemma is thus stated in terms of graphs and 1-reductions , avoiding the awkward half edges .",
    "[ 1lemma ] let @xmath19 be a graph with @xmath20 degree-1 vertices , @xmath21 .",
    "it is possible to perform a series of 1-reductions in @xmath19 where each vertex @xmath22 in @xmath23 is either matched one - to - one with a good 1-reduction ( a 1-reduction on a vertex of degree 3 or more ) , or belongs to a component of  @xmath19 containing at least one other vertex of  @xmath23 , where the total order of all such components is at most  @xmath24 plus the number of degree-2 vertices .",
    "in particular , if @xmath19 is a connected graph then there are @xmath20 good 1-reductions . by analogy with the well - definedness of the @xmath25-core of a graph ,",
    "any series of 1-reductions should be equivalent , but the weaker statement in the lemma suffices for our purposes .",
    "the intuition is that each series of reductions originating at some @xmath26 , after propagating through a series of vertices of degree  2 , terminates either at a vertex of degree 3 or more ( reducing its degree ) , establishing a matching between @xmath27 and a good reduction , or at another vertex @xmath28 , in which case the path from @xmath22 to @xmath29 ( or some more complex structure ) is a component .",
    "starting with  @xmath30 , let us 1-reduce from @xmath22 as long as possible before moving on to  @xmath31 .",
    "that is , if we 1-reduce into a vertex of degree  2 we perform a new 1-reduction from that vertex , terminating when we reach a vertex of degree 1 or degree 3 or more . rather than deleting an edge with a 1-reduction ,",
    "imagine that the edges are originally black , and each reduced edge is replaced by a red one ( which of course is not available for further 1-reductions ) .",
    "we assert that just before we start processing any  @xmath22 , the red - edged graph has components consisting of vertices _ all _ of whose edges are red ( in which case this is also a component in @xmath19 itself ) , and components where all vertices but one _ component owner _",
    "are all - red , and the component owner has at least 1 red edge and at least 2 black edges .",
    "we prove this by induction on  @xmath32 , with @xmath30 being trivial .",
    "given that it is true before  @xmath22 , we claim that : ( 1 )  as we reduce starting with  @xmath22 , the reduction sequence is uniquely determined ; ( 2 )  in the red - edged component including  @xmath22 , all vertices are all - red except for a single _ active _ one ; and ( 3 )  the sequence on @xmath22 ends when we reduce a vertex that had at least 3 black edges ( matching @xmath22 with this good reduction ) , or a vertex @xmath28 , @xmath33 ( in which case we will show that the red component including @xmath22 and @xmath29 is also a component of @xmath19 itself ) .",
    "we prove these claims by induction on the step number , the base case again being trivial ( @xmath22 itself is active ) .",
    "if we reduce into a vertex @xmath16 with two black edges ( we will say it has _ black degree  2 _ ) , the next reduction takes us out its other black edge , leaving both red .",
    "if @xmath16 was of degree  2 it is added to @xmath22 s red component ; if not , it must have been a component owner ( these are the only mixed - color vertices ) , and we unite the vertex and its component with @xmath22 s component . if we reduce into a vertex @xmath16 with at least 3 black edges , we match @xmath22 with the good reduction on  @xmath16 , and @xmath34 owns @xmath22 s red component .",
    "the only remaining possibility is that we reduce into a vertex with 1 black edge , which can only be a degree-1 vertex @xmath29 ( with @xmath33 ) , as there are no mixed - color vertices with 1 black edge . in this case",
    "we add @xmath29 to @xmath22 s component , and terminate the sequence of reductions for @xmath22 without a good reduction .",
    "however the red component on @xmath22 now has no black edges on any of its vertices , and is thus a component in the original black graph  @xmath19 .    starting with the @xmath20 vertices @xmath22 as initial red components , as we generate the component for @xmath22 ,",
    "the union of all components is expanded as we pass through ( and use up ) a ( true ) degree-2 vertex , left unchanged if we pass through a vertex of higher degree with black degree  2 , expanded as we enter a terminal all - black degree-3 vertex , and left unchanged if we terminate at another vertex  @xmath29 .",
    "then , recalling that @xmath20 is the number of degree-1 vertices in  @xmath23 and letting @xmath35 be the number of degree-2 vertices , the total number of vertices in the union of all components is at most the number of seeds  ( @xmath20 ) , plus the number of pass - throughs ( at most @xmath35 ) , plus the number of good terminals ( at most  @xmath20 ) . in particular , we can partition @xmath23 into the set of vertices with good terminals in  @xmath19 , and the rest ; the rest lie in components of @xmath19 where the total size of these components is @xmath36 .",
    "recall from algorithm  [ mainalg]that if we have a nonempty simplified instance  @xmath37 , we will apply a splitting reduction to produce smaller instances @xmath38 , simplify each of them , and argue that @xmath39 ( inequality  ) .",
    "we apply splitting reductions in a prescribed order of preference , starting with division into components .",
    "[ largecomponent ] if the constraint graph @xmath19 of @xmath37 has components @xmath40 and  @xmath41 with at least @xmath42 vertices each ( @xmath42 is the same constant as in the simplification rule  ) , decompose @xmath37 into the corresponding instances @xmath43 and  @xmath44 .",
    "the decomposition is the obvious one : monadic score functions @xmath45 of @xmath37 are apportioned to @xmath43 or @xmath44 according to whether @xmath27 is a vertex of @xmath40 or @xmath41 , similarly for dyadic score functions and edges @xmath46 , while we may apportion the niladic score function of @xmath37 to  @xmath43 , setting that of @xmath44 to  0 .",
    "it is clear that this is a valid reduction , but we must show that is satisfied . note that @xmath47 , and @xmath48 since @xmath49 has at least @xmath42 vertices , all degrees are at least  3 , and the @xmath50 are nondecreasing .",
    "thus @xmath51 . also , @xmath52 is constant - bounded . assuming that @xmath53 , then for @xmath42 sufficiently large , @xmath54 the same is of course true for @xmath44 , giving @xmath55 as required .",
    "the non - strict inequality @xmath56 is established by  , and if @xmath57 , a @xmath10-regular ( cubic ) instance would have measure  0 , implying that we could solve it in polynomial time , which we do not know how to do .",
    "thus let us assume for a moment that @xmath58 this strict inequality ( in fact @xmath59 ) will be implied by the constraints for splitting rules for cubic instances , constraint for example .",
    "if @xmath37 s constraint graph is connected the splitting we apply depends on the degree of  @xmath37 , that is , the degree of its highest - degree vertex .",
    "although high - degree cases thus take precedence , it is easier to discuss the low - degree cases first .",
    "sections [ subsec : cubic ] , [ subsec : maxdeg4 ] , [ subsec : maxdeg5 ] , and  [ subsec : maxdeg6 ] detail the splittings for ( respectively ) instances of degree 3 , 4 , 5 , and  6 . for a given degree , we present the reductions in order of priority .",
    "many formulas are not subject to any of the simplification rules above nor to large - component splitting . in this section",
    "we introduce further reductions so that for any formula @xmath37 of maximum degree at most  3 ( which is to say , whose constraint graph has maximum degree at most  3 ) , some reduction can be applied .",
    "if @xmath37 has any vertex of degree strictly less than  3 , we may apply the 0- , 1- , or 2-reductions above . henceforth , then",
    ", we assume that @xmath37 is 3-regular ( cubic ) .",
    "the new reductions will generally be `` atomic '' in the sense that we will carry each through to its stated completion , not checking at any intermediate stage whether an earlier simplification or reduction rule can be applied .",
    "we define @xmath60 to be the decrease of measure resulting from a half - edge reduction ( reduction  [ halfedge ] ) on a vertex of degree  @xmath10 .",
    "[ case3cut ] there is a @xmath10-cut @xmath61 isolating a set @xmath62 of vertices , with @xmath63 .",
    "each cut vertex @xmath22 has at least 1 neighbor in @xmath64 ( otherwise @xmath23 without this vertex is a smaller cut ) , and without loss of generality we may assume that either each cut vertex has 2 neighbors in @xmath64 , or that @xmath65 .",
    "( if a cut vertex , say @xmath66 , has just one neighbor @xmath67 , then @xmath68 is also a 3-cut , isolating the larger set @xmath69 .",
    "repeat until @xmath65 or each cut vertex has two neighbors in @xmath64 . )    with reference to figure  [ figcase11 ] , let @xmath70 be the respective neighbors of @xmath66 , @xmath71 , and  @xmath72 , and let @xmath73 and @xmath74 be the other neighbors of  @xmath66 .",
    "note that @xmath75 , or we should instead apply a 2-cut reduction ( reduction  [ 2cut ] ) : cutting on @xmath76 isolates the set @xmath77 , and @xmath78 satisfies the conditions of the 2-cut reduction .",
    "we treat this case by splitting on @xmath66 , resulting in new instances @xmath43 and  @xmath44 . in each",
    "we apply a 2-cut on @xmath79 ( not @xmath80 ! ) , creating a possibly - heavy edge  @xmath81 .",
    "we then 2-reduce on @xmath82 and @xmath83 in turn to create an edge @xmath84 which is heavy only if @xmath85 and @xmath86 were both heavy . if @xmath87 , the resulting instances satisfy @xmath88 ( recall that for graphs of degree  3 , @xmath89 and @xmath90 are identical . )",
    "the term @xmath91 accounts for the deletion of @xmath66 and @xmath62 ( at least 5 vertices ) with their incident half - edges .",
    "the term @xmath92 accounts for deletion of the `` other halves '' of the edges from @xmath66 to @xmath64 and the degree decrease of their incident vertices ( see definition  ) ; we are using the fact that @xmath93 , and that @xmath23 is an independent set .",
    "there is no need for a term accounting for the deletion of the `` other halves '' of the edges on @xmath71 and @xmath72 and the addition of the new edge @xmath84 : the new @xmath84 is heavy only if both half - edges were heavy , so this change in measure is @xmath94 , and we are free to ignore it .",
    "( since it may in fact be  0 , there is also no gain to including it . )",
    "constraint of lemma   is thus assured if @xmath95 we will henceforth express such constraints by a shorthand , simply saying that the case has splitting number at most @xmath96 we formally define a _ splitting number _ to be @xmath97 note the change of sign : in this notation we show the cost _ decrease _ in each case .    by similar reasoning ,",
    "if @xmath65 the splitting number is at most @xmath98 by this constraint is bound to hold `` for a sufficiently large value of 10 '' ( and since @xmath99 , for 10 itself this constraint is dominated by  ) , so we will disregard it .",
    "= [ minimum size=1mm , circle , fill = black ]    ( 0,1 ) ellipse ( 0.5 and 1.9 ) ; ( -0.8,1.5 ) node @xmath62 ; ( 1,2 ) node[vertex , label = above:@xmath66 ] ( x1 ) ; ( 1,1 ) node[vertex , label = above:@xmath71 ] ( x2 ) ; ( 1,0 ) node[vertex , label = above:@xmath72 ] ( x3 ) ; ( 0,2 ) node[vertex , label = above:@xmath103 ( y1 ) ; ( 0,1 ) node[vertex , label = above:@xmath82 ] ( y2 ) ; ( 0,0 ) node[vertex , label = above:@xmath83 ] ( y3 ) ; ( 2,2.25 ) node[vertex , label = right:@xmath73 ] ( y1 ) ; ( 2,1.75 ) node[vertex , label = right:@xmath74 ] ( y2 ) ;    ( 0,2)(x1 ) ( 0,1)(x2 ) ( 0,0)(x3 ) ( x1)(y1 ) ( x1)(y2 ) ( x2)(2,1.25 ) ( x2)(2,0.75 ) ( x3)(2,0.25 ) ( x3)(2,-0.25 ) ;      [ case1p3 ] there is a vertex @xmath6 such that @xmath108 is an independent set .    with reference to figure  [ figcase1321 ] ,    = [ minimum size=1mm , circle , fill = black ] ( 0,1 )",
    "node[vertex , label = left:@xmath6 ] ( u ) ; ( 1,2 ) node[vertex , label = above:@xmath73 ] ( v1 ) ; ( 1,1 ) node[vertex , label = above:@xmath74 ] ( v2 ) ; ( 1,0 ) node[vertex , label = above:@xmath110 ( v3 ) ; ( 2,2.5 ) node[vertex ] ( x1 ) ; ( 2,1.75 ) node[vertex ] ( x2 ) ; ( 2,1.25 ) node[vertex , label = right:@xmath72 ] ( x3 ) ; ( 2,0.5 ) node[vertex , label = right:@xmath111 ( x4 ) ; ( 2,-0.25 ) node[vertex ] ( x5 ) ;    ( u)(v1 ) ( u)(v2 ) ( u)(v3 ) ( v1)(x2 ) ( v2)(x3 ) ( v2)(x4 ) ( v3)(x4 ) ( v3)(x5 ) ; ( v1)(x1 ) ;    we reduce on  @xmath6 , fixing @xmath112 to @xmath113 and @xmath114 to generate new instances @xmath115 and  @xmath43 , each with constraint graph @xmath116 $ ] .",
    "let @xmath117 and @xmath118 .",
    "let @xmath119 be the number of vertices in @xmath120 with a heavy edge to  @xmath121 , @xmath122 the number of vertices in @xmath120 subject to a super 2-reduction ( deletion ) in  @xmath115 , and @xmath123 the number subject to super 2-reduction in  @xmath43 .",
    "by lemma  [ super2gen ] , each @xmath124 falls into at least one of these cases , so @xmath125 .",
    "we will argue that @xmath126 .",
    "deletion of @xmath6 and reduction of the degree of each of its neighbors immediately reduces the measure by @xmath127 ( more if any edges incident to @xmath6 were heavy ) . in  @xmath49 , first 2-reduce on the @xmath119 vertices in @xmath120 with heavy edges ( reducing the measure by a further @xmath128 ) and on the @xmath129 vertices subject to only plain 2-reductions ( not increasing the measure ) .",
    "note that each vertex in @xmath121 still has degree  3 .    finally , reduce out the @xmath130 vertices which are set constant by a super 2-reduction , by deleting their incident edges one by one .",
    "no vertex @xmath16 in @xmath121 has 3 neighbors in @xmath120 : if it did there would remain only 3 other edges from @xmath120 to  @xmath121 , whence @xmath131 , @xmath132 would be a cut of size @xmath133 isolating @xmath134 , and we would have applied a cut reduction .",
    "thus , deletion of each of the @xmath135 edges in @xmath136 either reduces the degree of a vertex in @xmath121 from 3 to  2 ( a good 1-reduction , reducing the measure by  @xmath137 ) , or creates a vertex of degree  1 .",
    "we wish to show that each degree-1 vertex in the graph @xmath138 $ ] must also result in a good 1-reduction , giving the @xmath139 claimed .",
    "note that @xmath140 must be 4 , 5 , or  6 ( if it were smaller we would have applied a cut reduction instead ) .",
    "if @xmath141 then every vertex in @xmath121 has degree  2 ( in the graph  @xmath142 ) and there is nothing to prove .",
    "if @xmath143 then at most one vertex in @xmath121 has degree  1 , and lemma  [ 1lemma ] implies that it results in a good 1-reduction .",
    "if @xmath144 , every degree-1 vertex in @xmath121 also results in a good 1-reduction : if not , then by lemma  [ 1lemma ] a set @xmath23 of two or more vertices in @xmath121 lies in a small component of  @xmath142 , in which case @xmath145 is a cut of size 2 or less in the original constraint graph  @xmath19 , isolating @xmath146 , and we would have applied a cut reduction instead .",
    "thus , @xmath147 . by convexity ,",
    "if two splitting numbers have equal total , the more unbalanced one is the more constraining ; in this case that means the worst cases come if @xmath148 and @xmath149 ( or vice - versa ) .",
    "thus , the worst - case splitting numbers are @xmath150      [ case1p4 ] given that we are in this case rather than case  [ case1p3 ] , no vertex of @xmath108 has an independent set as neighborhood .",
    "let @xmath152 and suppose without loss of generalitythat @xmath153 .",
    "let @xmath154 .",
    "then , @xmath155 . to avoid a 3-cut ( case  [ case3cut ] ) , @xmath156 ( the 4 rightmost vertices depicted in figure  [ figcase14 ] are truly distinct ) .",
    "= [ minimum size=1mm , circle , fill = black ] ( 0,1 ) node[vertex , label = left:@xmath6 ] ( u ) ; ( 1,2 ) node[vertex , label = above:@xmath73 ] ( v1 ) ; ( 1,1 ) node[vertex , label = above:@xmath74 ] ( v2 ) ; ( 1,0 ) node[vertex , label = below:@xmath110 ( v3 ) ; ( 2,2.5 ) node[vertex , label = above:@xmath66 ] ( x1 ) ; ( 2,1.5 ) node[vertex , label = above:@xmath71 ] ( x2 ) ; ( 2,1 ) node[vertex , label = right:@xmath72 ] ( x3 ) ; ( 2,0 ) node[vertex , label = right:@xmath111 ( x4 ) ; ( 3,2.5 ) node[vertex , label = right:@xmath103 ( y1 ) ; ( 3,1.5 ) node[vertex , label = right:@xmath82 ] ( y2 ) ;    ( u)(v1 ) ( u)(v2 ) ( u)(v3 ) ( v2)(v3 ) ( v1)(x1 ) ( v1)(x2 ) ( v2)(x3 ) ( v3)(x4 ) ( x1)(x2 ) ( x1)(y1 ) ( x2)(y2 ) ;    after splitting on @xmath6 , in each of the two instances @xmath115 and  @xmath43 , first 2-reduce on @xmath73 , then on @xmath66 , then continue with 2-reductions ( the base case ) , or super 2-reductions ( if possible ) , on @xmath74 and  @xmath157 . in the base case this results in the deletion of all 5 of these vertices with their incident edges and the decrease of the degree of @xmath71 to @xmath25 , for a measure decrease of  @xmath158",
    "( vertex @xmath71 will be 2-reduced , which does not increase the measure ; see [ 2reduce ] ) .",
    "if @xmath159 or @xmath160 is heavy , then there is an extra measure decrease of @xmath161 beyond that of the base case , for a splitting number of at most @xmath162    otherwise , @xmath159 and @xmath160 are both light , and we may super 2-reduce on @xmath74 in either @xmath115 or  @xmath43 ( without loss of generalitysay @xmath43 ) .",
    "this reduces the degree of @xmath72 from 3 to  2 , and that of @xmath157 from 2 to  1 , setting up a 1-reduction on @xmath157 that reduces the degree of @xmath163 from 3 to  2 .",
    "this gives a splitting number of at most @xmath164    there are no further cases for cubic graphs . if for a vertex @xmath6 there are 3 edges in @xmath151 $ ] then @xmath165 $ ] is an isolated component ( a complete graph  @xmath166 ) and we apply component - splitting .",
    "if there are 2 edges in @xmath151 $ ] , then some @xmath167 ( either of the vertices having a neighbor outside @xmath168 ) has just 1 edge in @xmath169 $ ] and we are back to case  [ case1p4 ] .      for results on cubic and other instances , we refer to theorem  [ thm : runtimes ] , table  [ tab : runtimes ] , and the discussion in section  [ tuning ] .      if the original cubic instance is a pure 2-sat formula , with no heavy edges , then ( as we show momentarily ) any heavy edges introduced by the procedure we have described can immediately be removed .",
    "thus the `` hybrid formula '' concept gives no gain for cubic 2-sat formulas , but expands the scope to cubic max 2-csp , sacrifices nothing , and is useful for analyzing non - cubic instances .",
    "we now show how heavy edges introduced into a cubic 2-sat formula immediately disappear again .    in a graph with only light edges ,",
    "the only two rules that create heavy edges are 2-reductions and 2-cuts ( and other reductions that apply these ) .",
    "a 2-reduction on @xmath16 introduces a heavy edge only if @xmath16 s neighbors @xmath66 and @xmath71 were already joined by an edge . in that case , though , @xmath66 and @xmath71 have their degrees reduced to 2 ( at most ) .",
    "if the remaining neighbors @xmath170 of @xmath66 and @xmath82 of @xmath71 are distinct , then 2-reducing on @xmath66 gives a light edge @xmath171 : the heavy edge @xmath172 is gone .",
    "otherwise , @xmath173 , and 2-reduction on @xmath66 followed by 1-reduction on @xmath71 deletes @xmath66 and @xmath71 and reduces the degree of @xmath82 to  1 , again leaving no heavy edge .    for a 2-cut on @xmath66 and @xmath71 isolating a set  @xmath62 , if there was an edge @xmath172 then the cut reduction reduces the degrees of both @xmath66 and @xmath71 to  2 , and , just as above , we may 2-reduce on @xmath66 to eliminate the heavy edge .",
    "if @xmath66 and @xmath71 are nonadjacent and @xmath66 has just 1 neighbor outside  @xmath62 , then again a follow - up 2-reduction on @xmath66 eliminates the heavy edge  @xmath172 . dismissing the symmetric case for  @xmath71",
    ", all that remains is the case when @xmath66 and @xmath71 are nonadjacent and each has 2 neighbors outside  @xmath62 , and thus just 1 neighbor in  @xmath62 ; see figure  [ bad2cut ] .",
    "= [ minimum size=1mm , circle , fill = black ]    ( ctre ) at ( 0,1 ) ; ( ctre ) ellipse ( 0.5 and 1 ) ; ( -0.6,1.5 ) node @xmath62 ; ( 1,1.5 ) node[vertex , label = above:@xmath66 ] ( x1 ) ; ( 1,0.5 ) node[vertex , label = below:@xmath71 ] ( x2 ) ; ( 2,1.75 ) node[vertex ] ( y1 ) ; ( 2,1.25 ) node[vertex ] ( y2 ) ; ( 2,0.75 ) node[vertex ] ( y3 ) ; ( 2,0.25 ) node[vertex ] ( y4 ) ;    ( 0,1.5)(x1 ) ( 0,0.5)(x2 ) ( x1)(y1 ) ( x1)(y2 ) ( x2)(y3 ) ( x2)(y4 ) ;    @xmath174    = [ minimum size=1mm , circle , fill = black ]    ( ctre ) at ( 0,1 ) ; ( 1,1.5 ) node[vertex , label = above:@xmath66 ] ( x1 ) ; ( 1,0.5 ) node[vertex , label = below:@xmath71 ] ( x2 ) ; ( 2,1.75 ) node[vertex ] ( y1 ) ; ( 2,1.25 ) node[vertex ] ( y2 ) ; ( 2,0.75 ) node[vertex ] ( y3 ) ; ( 2,0.25 ) node[vertex ] ( y4 ) ;    ( x1)(y1 ) ( x1)(y2 ) ( x2)(y3 ) ( x2)(y4 ) ; ( x1)(x2 ) ;    the @xmath62-neighbors @xmath175 of @xmath66 and @xmath176 of @xmath71 must be distinct , or else we would have applied a 1-cut reduction on  @xmath175 .",
    "( this presumes that @xmath177 , but if it is 0 or  1 , we would have 2-reduced on @xmath175 or 1-reduced on its @xmath62-neighbor  either of which is really a special case of a 1-cut reduction . )    given that @xmath178 , apply a 2-cut reduction not on @xmath66 and @xmath71 but instead on @xmath175 and @xmath176 . following this with 2-reduction on @xmath175 and @xmath176 eliminates the heavy edge @xmath179 , giving a light edge @xmath172 instead ; see figure  [ good2cut ] .",
    "= [ minimum size=1mm , circle , fill = black ]    ( ctre ) at ( 0,1 ) ; ( ctre ) ellipse ( 0.5 and 1 ) ; ( -0.6,1.5 ) node @xmath62 ; ( 1,1.5 ) node[vertex , label = above:@xmath66 ] ( x1 ) ; ( 1,0.5 ) node[vertex , label = below:@xmath71 ] ( x2 ) ; ( 0.25,1.5 ) node[vertex , label = left:@xmath180 ( x1 ) ; ( 0.25,0.5 ) node[vertex , label = left:@xmath181 ( x2 ) ; ( 2,1.75 ) node[vertex ] ( y1 ) ; ( 2,1.25 ) node[vertex ] ( y2 ) ; ( 2,0.75 ) node[vertex ] ( y3 ) ; ( 2,0.25 ) node[vertex ] ( y4 ) ;    ( x1)(x1 ) ( x2)(x2 ) ( x1)(y1 ) ( x1)(y2 ) ( x2)(y3 ) ( x2)(y4 ) ;    @xmath174    = [ minimum size=1mm , circle , fill = black ]    ( ctre ) at ( 0,1 ) ; ( ctre ) ellipse ( 0.5 and 1 ) ; ( 1,1.5 ) node[vertex , label = above:@xmath66 ] ( x1 ) ; ( 1,0.5 ) node[vertex , label = below:@xmath71 ] ( x2 ) ; ( 0.25,1.5 ) node[vertex , label = left:@xmath180 ( x1 ) ; ( 0.25,0.5 ) node[vertex , label = left:@xmath181 ( x2 ) ; ( 2,1.75 ) node[vertex ] ( y1 ) ; ( 2,1.25 ) node[vertex ] ( y2 ) ; ( 2,0.75 ) node[vertex ] ( y3 ) ; ( 2,0.25 ) node[vertex ] ( y4 ) ;    ( x1)(x1 ) ( x2)(x2 ) ( x1)(y1 ) ( x1)(y2 ) ( x2)(y3 ) ( x2)(y4 ) ; ( x1)(x2 ) ;    @xmath174    = [ minimum size=1mm , circle , fill = black ]    ( ctre ) at ( 0,1 ) ; ( 1,1.5 ) node[vertex , label = above:@xmath66 ] ( x1 ) ; ( 1,0.5 ) node[vertex , label = below:@xmath71 ] ( x2 ) ; ( 2,1.75 ) node[vertex ] ( y1 ) ; ( 2,1.25 ) node[vertex ] ( y2 ) ; ( 2,0.75 ) node[vertex ] ( y3 ) ; ( 2,0.25 ) node[vertex ] ( y4 ) ;    ( x1)(x2 ) ( x1)(y1 ) ( x1)(y2 ) ( x2)(y3 ) ( x2)(y4 ) ;      every weight constraint we introduce is of the form @xmath182 , where the sum is finite and each @xmath183 is some linear combination of weights .",
    "( some constraints are simply of the form @xmath184 , but this can also be written as @xmath185 . ) this standard form ( along with the objective of minimizing  @xmath186 ) can be provided , through an interface such as ampl , to a variety of mathematical - programming solvers : we used both ipopt ( part of the free , open - source code repository at ` coin-or.org ` ) and minos ( a commercial solver ) .",
    "furthermore , it is easily verified that the feasible region is convex .",
    "( convexity of @xmath187 means that for any @xmath188 , with @xmath189 , term by term , @xmath190 , and thus a mixture of feasible solutions is feasible . )",
    "this in turn makes it relatively easy for a solver to return a provably optimal solution : convex programs are much easier to solve than general ones or even the quasi - convex programs like eppstein s  @xcite .",
    "ipopt solves the nonlinear program for our general algorithm , to optimality , in a second or two on a typical laptop computer .    to insure that our solutions are truly feasible ,",
    "in the presence of finite numerical accuracy , we replace the `` 1 '' in the right - hand side of each constraint with @xmath191 , fixing @xmath192 ; this allows some margin for error .",
    "the values we show for the key parameters @xmath186 and @xmath193 are rounded up ( pessimistically ) from the higher - precision values returned by the solver , with the other parameter values rounded fairly .",
    "ideally we would also verify , in an unlimited - accuracy tool such as mathematica , that our rounded values satisfy the original `` @xmath194 '' constraints , but we have not performed that final check .",
    "we first introduce one more bit of notation , generalizing our earlier definition of @xmath137 . for any @xmath12",
    ", we define @xmath195 this is the minimum possible decrease of measure resulting from a half - edge reduction ( reduction  [ halfedge ] ) on a vertex of degree  @xmath32 with @xmath196 .",
    "we will find that such deletions always occur with the same sign in our nonlinear program  the larger @xmath197 , the weaker each constraint is  and therefore the above definition can be expressed in our mathematical program by simple inequalities @xmath198    we now consider a formula @xmath37 of ( maximum ) degree  @xmath199 .",
    "the algorithm choses a vertex @xmath6 of degree @xmath199 with  if possible  at least one neighbor of degree  @xmath10 .",
    "the algorithm sets @xmath6 to @xmath113 and  @xmath114 , simplifies each instance as much as possible ( see section  [ simplification ] ) , and recursively solves the resulting instances @xmath115 and  @xmath43 .",
    "the instances @xmath115 and @xmath43 are either @xmath199-regular , of degree at most  @xmath10 , or nonregular . by the arguments presented in section  [ measuresform ] , the case where the degree of the graph decreases can be safely ignored ( the measure decrease @xmath200 can be made as large as necessary ) .",
    "[ casereg4 ] if @xmath37 is 4-regular , first consider the case in which @xmath115 and @xmath43 are @xmath199-regular .",
    "since splitting on @xmath6 decreases the degree of each vertex in @xmath108 , and none of our reduction rules increases the degree of a vertex , every vertex in @xmath108 must have been removed from @xmath115 and @xmath43 by simplification rules .",
    "has a 4-regular component and a component of degree  3 ( although such an example shares with 4-regularity the salient property that no degree-4 vertex has a degree-3 neighbor ) . by definition ,",
    "the `` 4-regular case '' we are considering at this point does not include such an @xmath49 , but it is worth thinking about what happens to an @xmath49 which is not regular but has regular components .",
    "no component of @xmath49 is small ( simplification [ smallcomponent ] has been applied ) , so in the recursive solution of  @xmath49 , algorithm  [ mainalg]immediately applies large - component splitting ( reduction  [ largecomponent ] ) .",
    "this reduces @xmath49 to two connected instances , and is guaranteed to satisfy constraint   ( the penalty for one instance s being 4-regular is more than offset by its being much smaller than  @xmath49 ) .",
    "our machinery takes care of all of this automatically , but the example illustrates why some of the machinery is needed . ]",
    "this gives a splitting number of at most @xmath201    if neither @xmath115 nor @xmath43 is 4-regular , then @xmath6 is removed ( @xmath202 ) , the degree of its neighbors decreases ( @xmath203 ) , and we obtain an additional gain because @xmath115 and @xmath43 are not regular ( @xmath204 ) .",
    "thus , the splitting number is at most @xmath205    if exactly one of @xmath115 and @xmath43 is 4-regular , we obtain a splitting number of @xmath206 .",
    "this constraint is weaker ( no stronger ) than if @xmath207 , and weaker than if @xmath208 , so we may dispense with it .",
    "[ casenonreg4 ] if @xmath37 is not 4-regular , we may assume that @xmath6 has at least one neighbor of degree  @xmath10 .",
    "let us denote by @xmath209 the number degree-@xmath32 neighbors of  @xmath6 .",
    "thus , @xmath210 , and @xmath211 .",
    "further , let us partition the set @xmath212 of degree-3 neighbors into those incident only to light edges , @xmath213 , and those incident to at least one heavy edge , @xmath214 . define @xmath215 and @xmath216 ( so @xmath217 ) .    for each @xmath49 ( @xmath115 and @xmath43 ) ,",
    "splitting on @xmath6 removes @xmath6 ( for a measure decrease of @xmath202 , compared with  @xmath37 ) .",
    "if @xmath49 is not 4-regular , the degrees of the neighbors of @xmath6 all decrease ( @xmath218 ) .",
    "if @xmath49 is regular ( @xmath219 ) , all neighbors of @xmath6 must have been eliminated as well ( @xmath220 ) .",
    "we now argue about additional gains based on the values of @xmath221 and @xmath222 , starting with the heavy edges incident on vertices in @xmath214 .",
    "identify one heavy edge on each such vertex .",
    "if such an edge is between two vertices in @xmath223 associate it with either one of them ; otherwise associate it with its unique endpoint in @xmath223 .",
    "this gives a set of at least @xmath224 vertices in @xmath223 each with a distinct associated heavy edge , which we may think of as oriented out of that vertex .",
    "if such an edge incident on @xmath225 is also incident on @xmath6 then it is deleted along with  @xmath6 , for an additional measure reduction of @xmath161 we credit to  @xmath16 .",
    "this leaves a set of `` out '' edges that may form paths or cycles .",
    "after deletion of @xmath6 all the vertices involved have degree  2 , so any cycle is deleted as an isolated component , for a measure reduction of @xmath161 per vertex .",
    "super 2-reducing on a vertex @xmath16 deletes its outgoing edge , which we credit to  @xmath16 , and possibly also an incoming heavy edge associated with a different @xmath226 , which we credit to  @xmath17 .",
    "finally , if @xmath16 is 2-reduced we consider its outgoing edge ( not its other incident edge ) to be contracted out along with  @xmath16 , crediting this to  @xmath16 ( and correctly resulting in a light edge if the other edge incident on @xmath16 was light , or a heavy one if it was heavy ) .",
    "this means that if the other edge incident to @xmath16 was a heavy edge out of a different @xmath226 , then @xmath17 still has an associated outgoing heavy edge . in short ,",
    "each of the @xmath224 vertices gets credited with the loss of a heavy edge , for an additional measure reduction of at least @xmath227 .",
    "we say that we have a _ good degree reduction _ if the degree of a vertex of degree 3 or more decreases by  1 : for graphs of degree 4 this decreases the measure by at least  @xmath228 .",
    "this measure decrease comes in addition to what we have accounted for so far , unless @xmath49 is regular and the degree reduction is on a vertex in @xmath108 ( since we have accounted for the deletion of those vertices , counting their degree reductions as well would be double counting ) . we will show that a certain number of additional - scoring degree reductions occur altogether , in @xmath115 and @xmath43 combined , as a function of  @xmath221 .",
    "if @xmath229 , super 2-reduction on the sole vertex in @xmath213 is possible in at least one of @xmath115 or @xmath43  without loss of generality say just @xmath115  and reduces the degrees of at least two neighbors . if @xmath115 is nonregular this gives a gain of @xmath230 , while if @xmath115 is regular there may be no gain .",
    "if @xmath231 , then again if either vertex is super 2-reduced in a nonregular branch there is a gain of at least @xmath230 . otherwise , each vertex is super 2-reduced in a regular branch ( both in one branch , or in two different branches , as the case may be ) .",
    "at least one of the vertices has at least one neighbor in @xmath232 , or else @xmath233 would be 2-cut . in whichever @xmath49 the degree of the neighbor is reduced , since @xmath49 is regular the neighbor must eventually be deleted , for a gain of at least @xmath234 .",
    "so there is either a gain of @xmath230 in a nonregular branch or a gain of @xmath234 in a regular branch .",
    "( we can not hope to replace @xmath234 with @xmath235 : figure  [ onegoodred ] shows an example where indeed only one good degree reduction occurs outside @xmath165 $ ] . )    = [ minimum size=1mm , circle , fill = black ] ( 0,0 ) node[vertex , label = left:@xmath6 ] ( u ) ; ( 2,1.5 ) node[vertex , label = above:@xmath73 ] ( v1 ) ; ( 2,0.5 ) node[vertex , label = right:@xmath74 ] ( v2 ) ; ( 2,-0.5 ) node[vertex , label = below right:@xmath110 ( v3 ) ; ( 2,-1.5 ) node[vertex , label = below:@xmath236 ( v4 ) ; ( 4,1 ) node[vertex , label = right:@xmath66 ] ( x1 ) ; ( 4,0 ) node[vertex , label = right:@xmath71 ] ( x2 ) ; ( 4,-1 ) node[vertex , label = right:@xmath72 ] ( x3 ) ;    ( u)(v1 ) ( u)(v2 ) ( u)(v3 ) ( u)(v4 ) ( v1)(v2 ) ( v2)(v3 ) ( v1)(x1 ) ( v3)(x2 ) ( v4)(x3 ) ; ( v3)(v4 ) ;    if @xmath237 , again either there is a gain of @xmath230 in a nonregular branch , or each super 2-reduction occurs in a regular branch .",
    "the 3 vertices in @xmath238 have at least 2 neighbors in @xmath121 , or else these neighbors , along with @xmath233 , would form a cut of size 2 or smaller .",
    "each of these neighbors has its degree reduced , and thus must get deleted from a regular @xmath49 , for a gain of at least @xmath235 .",
    "so there is either a gain of @xmath230 in a nonregular branch , or a gain of @xmath239 altogether in one or two regular branches .",
    "( we can not hope to claim @xmath240 or @xmath241 , per the example in figure  [ twogoodred ] . )    = [ minimum size=1mm , circle , fill = black ] ( 0,0 ) node[vertex , label = left:@xmath6 ] ( u ) ; ( 2,1.5 ) node[vertex , label = above:@xmath73 ] ( v1 ) ; ( 2,0.5 ) node[vertex , label = right:@xmath74 ] ( v2 ) ; ( 2,-0.5 ) node[vertex , label = right:@xmath110 ( v3 ) ; ( 2,-1.5 ) node[vertex , label = below:@xmath236 ( v4 ) ; ( 4,1.5 ) node[vertex , label = right:@xmath66 ] ( x1 ) ; ( 4,0.5 ) node[vertex , label = right:@xmath71 ] ( x2 ) ; ( 4,-0.5 ) node[vertex , label = right:@xmath72 ] ( x3 ) ; ( 4,-1.5 ) node[vertex , label = right:@xmath111 ( x4 ) ;    ( u)(v1 ) ( u)(v2 ) ( u)(v3 ) ( u)(v4 ) ( v1)(v2 ) ( v2)(v3 ) ( v1)(x1 ) ( v3)(x2 ) ( v4)(x3 ) ; ( v4)(x4 ) ;    if @xmath242 , we claim that in the two branches together there are at least 4 good degree reductions on vertices in @xmath121 and @xmath243 .",
    "each contributes a gain of at least @xmath228 if it is in a nonregular branch , @xmath234 in a regular branch .",
    "each vertex in @xmath121 undergoes a good degree reduction in one branch or the other , so if @xmath244 we are done .",
    "since there can be no 2-cut , we may otherwise assume that @xmath245 .",
    "since ( in @xmath37 ) every vertex in @xmath108 has degree  3 , there is an even number of edges between @xmath108 and @xmath121 , thus there are at least 4 such edges .",
    "since each vertex in @xmath121 has an edge from @xmath108 , there must be two such edges incident on one vertex @xmath246 , and one edge each incident on the other vertices @xmath247 .",
    "again we guaranteed 4 good degree reductions unless @xmath66 has degree 3 _ and _ undergoes both of its reductions in one branch ( so that degree 3 to 2 is a good reduction , but 2 to 1 is not ) . in that case , though , @xmath66 has degree  1 , its remaining neighbor must be in @xmath243 ( otherwise @xmath248 is a 2-cut ) , and 1-reducing on @xmath66 gives a good degree reduction on that neighbor .",
    "so there is a total gain of @xmath203 in a nonregular branch and @xmath249 in a regular branch .    by convexity ,",
    "the elementwise average of two pairs of splitting numbers is a constraint dominated by one or the other , so it suffices to write down the extreme constraints , with all the gain from super 2-reductions given to a single nonregular or regular branch .    before counting the super 2-reduction gains , if @xmath49 is nonregular the measure decrease @xmath250 is at least @xmath251 the super 2-reductions give an additional gain , in a nonregular branch , of at least @xmath252 where the tricky floor and ceiling expressions are just a way of writing an explicit expression convenient for passing to the nonlinear solver .",
    "the constraints arising from splitting on a vertex of degree 4 with at least one neighbor of degree 3 are thus dominated by the following , taken over @xmath253 , with @xmath254 and @xmath255 : @xmath256",
    "this section considers formulas of maximum degree  @xmath257 . as an overview ,",
    "if there is a @xmath10-cut isolating a set @xmath62 with @xmath258 or more vertices the algorithm splits on any vertex in the cut .",
    "otherwise , the algorithm chooses a vertex @xmath6 of degree @xmath257 with  if possible  at least one neighbor of degree at most  @xmath199 , and splits on  @xmath6 either as was done in the degree-4 case , or using clause - learning splitting ( see lemma  [ clause ] ) .",
    "we use clause learning when the neighbors of @xmath6 have high degrees , because clause learning sets many variables in @xmath108 , and this is most effective when the degrees are large ( since @xmath259 ) .",
    "we use normal splitting when the neighbors have low degrees , because setting @xmath6 reduces their degrees , and this is effective when the degrees are small ( @xmath260 , with an additional bonus in super 2-reductions for a degree-3 variable ) .",
    "( this is also why we always prefer to split on vertices of maximum degree with neighbors of low degree , and why the regular cases need special attention . )",
    "[ cut53 ] there is a @xmath10-cut @xmath261 isolating a set @xmath62 of vertices such that @xmath262 and @xmath62 contains at least one vertex of degree  @xmath257 .",
    "splitting on the cut vertex @xmath66 leaves constraint graphs where @xmath263 form a @xmath25-cut .",
    "thus @xmath264 are removed from both resulting instances ( @xmath265 ) , a neighbor of @xmath66 outside @xmath266 has its degree reduced ( @xmath267 ) , a heavy edge @xmath84 appears ( in the worst case ) but at least @xmath25 half - edges incident on @xmath71 and @xmath72 disappear ( @xmath268 ) .",
    "additionally , the resulting instances may become @xmath257-regular ( @xmath269 ) .",
    "so , the splitting number is at most @xmath270    in light of reduction  [ cut53 ] we may henceforth assume that each degree-5 variable @xmath6 has @xmath271",
    ".      [ casereg5 ] if every vertex has degree  @xmath257 , the same analysis as for 4-regular instances ( reduction  [ casereg4 ] , constraints and  ) gives a splitting number which is at most one of the following : @xmath272    otherwise , let @xmath6 be a degree-5 vertex with a minimum number of degree-5 neighbors , and as usual let @xmath209 be the number of degree-@xmath32 neighbors of @xmath6 ( since the instance is not regular , @xmath273 ) .",
    "let @xmath274 .",
    "depending on the values of @xmath275 and @xmath209 we will use either regular 2-way splitting ( reduction  [ casenonreg52 ] ) or clause - learning 3-way splitting ( reduction  [ casenonreg51 ] ) .",
    "[ casenonreg52 ] @xmath276 or @xmath277 or @xmath278 .    in this case",
    "we use the usual @xmath25-way splitting , setting @xmath6 to @xmath113 and to  @xmath114 , and simplifying to obtain @xmath115 and @xmath43 .",
    "if @xmath49 is not regular , the measure decrease @xmath250 is at least @xmath279 , and if @xmath49 is @xmath257-regular , it is at least @xmath280 .",
    "thus if both branches are regular the splitting number is at most @xmath281 if both branches are nonregular , we use that if @xmath277 , any degree-3 neighbor of @xmath6 either has a heavy edge not incident to  @xmath6 , giving an additional measure reduction of at least @xmath161 , or in at least one branch may be super 2-reduced , for a measure reduction of at least @xmath282 .",
    "( the latter requires a justification we give explicitly , although lemma  [ 1lemma ] could be invoked . at the start of the first super 2-reduction",
    ", every vertex has degree 2 or more .",
    "each of the two `` legs '' of the super 2-reduction propagates through a [ possibly empty ] chain of degree-2 vertices before terminating either in a good degree reduction or by meeting a vertex that was reduced to degree 1 by the other leg . in the latter case all the vertices involved had degree  2 , thus were neighbors of @xmath6 originally of degree  3 ; also , there must have been at least three of them to form a cycle , and the remaining 2 or fewer vertices in @xmath108 contradict the assumption that @xmath37 was simplified . ) thus , the splitting number is at most @xmath283 @xmath284      [ casenonreg51 ] @xmath285 and @xmath286 and @xmath287 .",
    "let @xmath16 be a degree  @xmath257 ( degree @xmath257 in @xmath19 ) neighbor of @xmath6 with a minimum number of degree-@xmath257 neighbors in @xmath288 .",
    "the clause learning splitting ( see lemma  [ clause ] ) will set @xmath6 in the first branch , @xmath6 and @xmath16 in the second branch , and all of @xmath165 $ ] in the third branch .",
    "in each of the @xmath10 branches , the resulting instance could become @xmath257-regular or not .    in the _ first branch",
    "_ , the measure of the instance decreases by at least @xmath289    in the analysis of the second and third branches we distinguish between the case where @xmath16 has at most one neighbor of degree @xmath257 in  @xmath290 , and the case where @xmath16 ( and thus every degree-@xmath257 neighbor of  @xmath6 ) has at least two neighbors of degree @xmath257 in @xmath290 .    in the _ second branch _",
    ", if @xmath16 has at most one neighbor of degree @xmath257 in  @xmath290 , the measure of the instance decreases by at least @xmath291 ( the degree reductions @xmath292 from the nonregular case do not appear in the regular case because they may pertain to the same vertices as the deletions @xmath293 . )",
    "if @xmath16 has at least two neighbors of degree @xmath257 in @xmath290 , the measure decreases by at least @xmath294    in the _ third branch _ , first take the case where @xmath16 has at most one neighbor of degree @xmath257 in @xmath290 . since @xmath295",
    ", there are at least 4 good degree reductions on vertices in @xmath290 .",
    "if the instance becomes regular , this implies a measure decrease of at least @xmath249 . if the instance remains nonregular , this is a measure reduction of at least @xmath296 , and we now show that if @xmath297 then there is a fifth good degree reduction .",
    "we argue this just as the 4-nonregular case ( section  [ casenonreg4 ] ) with @xmath298 ; we could alternatively apply lemma  [ 1lemma ] . if @xmath299 the desired @xmath300 is immediate",
    "otherwise , @xmath301 , the number of edges between @xmath108 and @xmath290 is at least  4 , and odd ( from @xmath297 and @xmath302 , recalling that @xmath286 ) , so @xmath303 .",
    "at least one edge incident on each vertex in @xmath290 gives a good degree reduction , and we fail to get a fifth such reduction only if the fifth edge is incident on a vertex @xmath304 of degree  3 , leaving it with degree  1 .",
    "but in that case the remaining neighbor of @xmath27 must be in @xmath243 ( otherwise @xmath305 is a 3-cut , a contradiction by reduction  [ cut53 ] ) , and 1-reducing @xmath27 gives the fifth good degree reduction .",
    "thus the measure decreases by at least @xmath306    otherwise , in the third branch , @xmath16 has at least two neighbors of degree @xmath257 in  @xmath290 . for the regular case we simply note that each vertex in @xmath121 has its degree reduced and",
    "must be deleted , @xmath121 has at least four vertices of which at least two are of degree  5 , for a measure reduction of at least @xmath307 .",
    "we now address the nonregular case .",
    "letting @xmath308 be the set of degree-5 vertices in @xmath108 ( so @xmath309 ) , by definition of @xmath16 every vertex in @xmath308 has at least two degree-5 neighbors in  @xmath290 .",
    "let @xmath310 be the set of degree-5 vertices in @xmath290 adjacent to  @xmath308 , and let @xmath311 be the set of edges between @xmath308 and @xmath312 .",
    "there is one last case distinction , according to the value of  @xmath313 .",
    "if @xmath314 there are at least 6 good degree reductions : @xmath315 , each vertex in @xmath312 has at most @xmath316 incident edges from @xmath317 , and thus each such incidence results in a good degree reduction ( the vertex degree is reduced at most from 5 to 4 to 3 to 2 ) .",
    "here we have @xmath318 .",
    "if @xmath297 we claim that the good degree reductions amount to at least @xmath319 . by default the 8 edges in @xmath317 all generate good degree reductions , with fewer only if some of the degree-5 vertices in @xmath312 have more than 3 incident edges from @xmath317 .",
    "the `` degree spectrum '' on @xmath312 is thus a partition of 8 ( the number of incident edges ) into @xmath320 parts , where no part can be larger than @xmath321 .",
    "if the partition is @xmath322 this means two reductions that are not good ( @xmath323 ) , but then this implies that @xmath324 , and the other two vertices in @xmath325 also have their degrees reduced , restoring the total of 8 good reductions . if the partition has exactly one @xmath199 , on a vertex @xmath326 , then just one of the 8 degree reductions is not good , and the 7 good reductions include those on @xmath327 , thus giving a measure reduction of at least @xmath328 .    considering the difference , which we will denote @xmath329 , between these guaranteed measure decreases and the guarantee of @xmath318 when @xmath314 , we constrain @xmath330 and we obtain a measure reduction of at least @xmath331    wrapping up this reduction , the case that @xmath16 has at most 1 degree-5 neighbor in @xmath332 , or at least two such neighbors , respectively impose the constraints ( splitting numbers ) @xmath333",
    "this section considers formulas of maximum degree @xmath258 .",
    "the algorithm chooses a vertex @xmath6 of degree @xmath258 with  if possible  at least one neighbor of lower degree , and splits on @xmath6 by setting it to @xmath113 and  @xmath114 .",
    "[ casereg6 ] if every vertex has degree  @xmath258 , the same analysis as for regular instances of degree @xmath199 gives a splitting number which is at least one of the following : @xmath334      [ casenonreg61 ] vertex @xmath6 has at least one neighbor of degree at most @xmath257 .",
    "it is straightforward that the splitting number is at least as large as one of the following ( only distinguishing if the instance becomes @xmath258-regular or not ) : @xmath335",
    "for any values of @xmath186 and @xmath193 satisfying the constraints we have set down , we have shown that any max 2-cspinstance @xmath37 is solved in time @xmath336 .",
    "for a given instance @xmath37 , the running - time bound is best for the feasible values of @xmath186 and @xmath193 which minimize @xmath337 . as usual",
    "taking @xmath338 and @xmath339 , this is equivalent to minimizing @xmath340 allowing us to obtain a 1-parameter family of running - time bounds  pairs @xmath341 as a function of  @xmath0  tuned to a formula s fraction of conjunctive and general 2-clauses .",
    "reiterating , if a formula s `` p '' value is @xmath342 , and if minimizing for a given @xmath0 gives a pair @xmath343 , then the optimal bound for formula @xmath37 is the one given by @xmath344 , but for _ any _ @xmath343 , the running - time bound @xmath345 is valid for every formula @xmath37 , even if @xmath346 .",
    "this is simply because every such pair @xmath341 is a feasible solution of the nonlinear program , even if it is not the optimal solution for the appropriate objective function .    for cubic instances ,",
    "minimizing with @xmath0 small gives @xmath347 and @xmath348 , while minimizing with @xmath0 close to 1 gives @xmath349 ( the tight constraints are all linear , so the solution is rational ) , matching the best known polynomial space running time for general instances of max 2-csp(see  @xcite ) .",
    "it appears that the first result is obtained for all @xmath350 and the second for all @xmath351 .    for instances of degrees 4 , 5 , and 6 or more ,",
    "the results of minimizing with various values of @xmath0 are shown in table  [ tab : runtimes ] , and the most interesting of these is surely that of degree 6 or more ( the general case ) . here ,",
    "taking @xmath0 small gives @xmath352 and @xmath353 . for instances of max 2-satthis gives a running - time bound of @xmath354 or @xmath355 , improving on the best bound previously known , giving the same bound for mixtures of or and and clauses , and giving nearly as good run times when a small fraction of arbitrary integer - weighted clauses are mixed in .",
    "we observe that any @xmath356 leads to @xmath357 ( as for cubic case with @xmath351 , the tight constraints are linear , so the value is rational ) , matching the best known bound ( for polynomial - space algorithms ) of @xmath358 from  @xcite .",
    "figure  [ p6plot ] shows the values of @xmath186 , @xmath193 , and the objective @xmath359 , as a function of  @xmath0 .",
    "numerically , the values @xmath186 and @xmath193 meet for some value of @xmath0 between @xmath360 and @xmath361 .",
    "the authors are very grateful to alex scott for initiating this project and contributing some of the first key ideas .",
    "kmrr05    nikhil bansal and venkatesh raman , _ upper bounds for maxsat : further improved _ , proceedings of the 10th international symposium on algorithms and computation ( isaac 1999 ) , lecture notes in comput .",
    "1741 , springer , 1999 , pp .",
    "247258 .",
    "david eppstein , _ quasiconvex analysis of multivariate recurrence equations for backtracking algorithms _ , acm trans .",
    "algorithms * 2 * ( 2006 ) , no .  4 , 492509 .",
    "fedor  v. fomin , fabrizio grandoni , and dieter kratsch , _ measure and conquer : domination  a case study _ , proceedings of the 32nd international colloquium on automata , languages and programming ( icalp 2005 ) , lecture notes in comput .",
    "3580 , springer , 2005 , pp .",
    "191203 .",
    "jens gramm , edward  a. hirsch , rolf niedermeier , and peter rossmanith , _ worst - case upper bounds for max-2-sat with an application to max - cut _ , discrete appl . math . *",
    "130 * ( 2003 ) , no .  2 , 139155 .",
    "serge gaspers and gregory  b. sorkin , _ a universally fastest algorithm for max 2-sat , max 2-csp , and everything in between _ , proceedings of the 20th annual acm - siam symposium on discrete algorithms ( soda 2009 ) , siam , 2009 , pp .",
    "606615 .",
    "edward  a. hirsch , _ a new algorithm for max-2-sat _ , proceedings of the 17th annual symposium on theoretical aspects of computer science ( stacs 2000 ) , lecture notes in comput .",
    "1770 , springer , 2000 , pp .",
    "arist kojevnikov and alexander  s. kulikov , _ a new approach to proving upper bounds for max-2-sat _ , proceedings of the 17th annual acm ",
    "siam symposium on discrete algorithms ( soda 2006 ) , acm , 2006 , pp .",
    "alexander  s. kulikov and konstantin kutzkov , _ new bounds for max - sat by clause learning _ , proceedings of the 2nd international symposium on computer science in russia ( csr 2007 ) , lecture notes in comput .",
    "4649 , springer , 2007 , pp .",
    "194204 .",
    "joachim kneis , daniel mlle , stefan richter , and peter rossmanith , _ algorithms based on the treewidth of sparse graphs _ , proceedings of the 31st international workshop on graph - theoretic concepts in computer science ( wg 2005 ) , lecture notes in comput .",
    "3787 , springer , 2005 , pp .",
    "385396 .",
    "mikko koivisto , _",
    "optimal 2-constraint satisfaction via sum - product algorithms _ , information proc .",
    "* 98 * ( 2006 ) , no .  1 , 2428 .    joachim kneis and peter rossmanith , _ a new satisfiability algorithm with applications to max - cut _ , tech .",
    "report aib-2005 - 08 , department of computer science , rwth aachen , 2005 .",
    "oliver kullmann , _ worst - case analysis , 3-sat decision and lower bounds : approaches for improved sat algorithms _",
    ", dimacs series in discrete mathematics and theoretical computer science , vol .",
    "35 , american mathematical society , 1997 , pp .  261313 .",
    "to3em , _ new methods for 3-sat decision and worst - case analysis _ , theoret .",
    "* 223 * ( 1999 ) , no .  1 - 2 , 172 .    rolf niedermeier and peter rossmanith , _ new upper bounds for maximum satisfiability _ , j. algorithms * 36 * ( 2000 ) , no .  1 , 6388 .    daniel raible and henning fernau , _ a new upper bound for max-2-sat : a graph - theoretic approach _ , proceedings of the 33rd international symposium on mathematical foundations of computer science ( mfcs 2008 ) , lecture notes in comput .",
    "5162 , springer , 2008 , pp .",
    "551562 .",
    "alexander  d. scott and gregory  b. sorkin , _",
    "faster algorithms for max cut and max csp , with polynomial expected time for sparse instances _ , proceedings of the 7th international workshop on randomization and approximation techniques in computer science ( random 2003 ) , lecture notes in comput .",
    "2764 , springer , 2003 , pp .",
    "382395 .",
    "to3em , _ a faster exponential - time algorithm for max 2-sat , max cut , and max @xmath20-cut _ , tech . report rc23456",
    "( w0412 - 001 ) , ibm research report , december 2004 , see http://domino .research.ibm.com",
    "/ library/ cyberdig.nsf .",
    "to3em , _ linear - programming design and analysis of fast algorithms for max 2-csp _ , discrete optim .",
    "* 4 * ( 2007 ) , no .  3 - 4 , 260287 .",
    "to3em , _ polynomial constraint satisfaction : a framework for counting and sampling csps and other problems _ , tech .",
    "report cs : dm/0604079v3 , arxiv.org , february 2007 , see http://arxiv.org/abs/ cs.dm/0604079 .",
    "magnus wahlstrm , _ exact algorithms for finding minimum transversals in rank-3 hypergraphs _ , j. algorithms * 51 * ( 2004 ) , no .  2 , 107121 .",
    "ryan williams , _ a new algorithm for optimal 2-constraint satisfaction and its implications _ , theoret .",
    "* 348 * ( 2005 ) , no .  2 - 3 , 357365 .",
    "below we show , in ampl notation , the objective function and all the constraints of the mathematical program we solve to optimize an algorithm for hybrid instances with a fraction ` p ` of non - simple clauses .",
    "constraints are annotated the numbers of the corresponding inequalities in the paper s body .",
    "the parameter ` margin ` is the `` @xmath362 '' discussed in section  [ solver ] to ensure that a solution is truly feasible even in the face of finite - precision arithmetic .",
    "# maximum degree param maxd integer > =3 ; # fraction of non - simple clauses param p ; param margin ; set degrees : = 0 .. maxd ; # weight for edges var we > = 0 ; # weight for degree reductions from degree at most i var h { degrees } > = 0 ; # vertex of degree i + i/2 surrounding half edges var a { degrees } ; # weight for heavy edges var wh ; # regular weights var r4 > = 0 ; \\hfill\\eqref|rpos% var r5 > = 0 ; \\hfill\\eqref|rpos% var r6 > = 0 ; \\hfill\\eqref|rpos% # additional degree reductions in the 3rd branch ( nonregular ) # of the clause learning branching for p5=4 vs p5=3 var nonreg53 ; # change in measure for the 3 branches # 1st argument is the nb of deg-4 nbs of u # 2nd argument distinguishes ( if present ) if v has at most 1 deg-5 nb in n^2 ( 1 ) #      or at least 2 ( 2 ) set two : = 1 .. 2 ; var f1 { two } ; var f2 { two , two } ; var f3 { two , two } ; var d4r { 0 .. 4 , 0 .. 4 } ; var d4n { 0 .. 4 , 0 .. 4 } ; var g4r { 0 .. 4 } ; var g4n { 0 .. 4 } ;                  # constraints for the values of h [ ] subject to hnotation { d in degrees , i in degrees : 3",
    "< = i < = d } :    h[d ] - a[i ] + a[i-1 ] < = 0 - margin ; \\hfill\\eqref|h3def%\\eqref|halfred%    # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # constraints for cubic # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #    # 3-cut subject to cut3 :    2 * 2^(-5*a[3 ] - 2*h[3 ] ) < = 1 - margin ; \\hfill\\eqref|3cut%                                                  # first branch subject to cf1 { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f1[p4 ] > = -a[5]-p4*h[4]-p5*h[5 ] ; \\hfill\\eqref|f1% subject to cf1reg { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f1[p4 ] > = -a[5]-p4*a[4]-p5*a[5]+r5 ; \\hfill\\eqref|f1%    # second branch , v has at most 1 deg-5 neighbor in n^2 subject to cf2a { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f2[p4,1 ] > = -a[5]-p4*h[4]-p5*h[5]-a[4]-3*h[4]-h[5 ] ; \\hfill\\eqref|f2a% subject to cf2areg { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f2[p4,1 ] > = -a[5]-p4*a[4]-p5*a[5]+r5 ; \\hfill\\eqref|f2a%    # second branch , v ( and all other deg-5 nbs of u ) has at least 2 deg-5 nbs in n^2 subject to cf2b { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f2[p4,2 ] > = -a[5]-p4*h[4]-p5*h[5]-a[4]-4*h[5 ] ; \\hfill\\eqref|f2b% subject to cf2breg { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f2[p4,2 ] > = -a[5]-p4*a[4]-p5*a[5]-2*a[3]+r5 ; \\hfill\\eqref|f2b%    # additional degree reductions in the 3rd branch ( nonregular ) for p5=4 vs p5=3 subject to adddegrednr53_1 :    nonreg53 < = 2*h[5 ] ; \\hfill\\eqref|g5a% subject to adddegrednr53_2 :    nonreg53 < = h[4]+h[3]-h[5 ] ; \\hfill\\eqref|g5b%    #",
    "third branch , v has at most 1 deg-5 neighbor in n^2 subject to cf3a { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f3[p4,1 ] > = -a[5]-p4*a[4]-p5*a[5]-(4+((4*p4 + 5*p5 - 5 ) mod 2))*h[5 ] ; \\hfill\\eqref|f3a% subject to cf3areg { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f3[p4,1 ] > = -a[5]-p4*a[4]-p5*a[5]-4*a[3]+r5 ; \\hfill\\eqref|f3a%    # third branch , v ( and all other deg-5 nbs of u ) has at least 2 deg-5 nbs in n^2 subject to cf3b { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f3[p4,2 ] > = -a[5]-p4*a[4]-p5*a[5]-6*h[5]-floor(p5/4)*nonreg53 ; \\hfill\\eqref|f3b% subject to cf3breg { p4 in 1 .. 2 , p5 in 3 .. 4 : p4+p5=5 } :     f3[p4,2 ] > = -a[5]-p4*a[4]-p5*a[5]-2*a[3]-2*a[5]+r5 ; \\hfill\\eqref|f3b%        # 2-way splitting , non - reg in both branches , if p3>0 , then additional heavy edge subject to nonregular51a { p3 in 0 .. 5 , p4 in 0 .. 5 ,                             p5 in 0 .. 4 , h in 0 .. 1 : p3+p4+p5=5                            and ( ( h=1 ) or ( p5 < 3 or p3>0 ) ) } :     2 * 2^(-a[5 ] - p3*h[3 ] - p4*h[4 ] - p5*h[5 ] -h*(wh - we ) -ceil(p3/5)*(wh - we ) )     < = 1 - margin ; \\hfill\\eqref|splittingnonreg54%    # 2-way splitting , non - reg in both branches , if p3>0 , then additional super-2 subject to nonregular51b { p3 in 0 .. 5 , p4 in 0 .. 5 , p5 in 0 .. 4 ,                             h in 0 .. 1 : p3+p4+p5=5                            and ( ( h=1 ) or ( p5 < 3 or p3>0 ) ) } :     2^(-a[5 ] - p3*h[3 ] - p4*h[4 ] - p5*h[5 ] -h*(wh - we ) -ceil(p3/5)*2*h[5 ] )   + 2^(-a[5 ] - p3*h[3 ] - p4*h[4 ] - p5*h[5 ] -h*(wh - we ) )   < = 1 - margin ; \\hfill\\eqref|splittingnonreg53%    # 2-way splitting , becomes reg in both branches subject to nonregular52 { p3 in 0 .. 5 , p4 in 0 .. 5 , p5 in 0 .. 4 ,                            h in 0 .. 1 : p3+p4+p5=5                           and ( ( h=1 ) or ( p5 < 3 or p3>0 ) ) } :     2 * 2^(-a[5 ] - p3*a[3 ] - p4*a[4 ] - p5*a[5 ] -h*(wh - we ) + r5 ) < = 1 - margin ; \\hfill\\eqref|splittingnonreg51%    # 2-way splitting , becomes reg in 1 branch subject to nonregular52b { p3 in 0 .. 5 , p4 in 0 .. 5 , p5 in 0 .. 4 ,                             h in 0 .. 1 : p3+p4+p5=5                            and ( ( h=1 ) or ( p5 < 3 or p3>0 ) ) } :     2^(-a[5 ] - p3*a[3 ] - p4*a[4 ] - p5*a[5 ] -h*(wh - we ) + r5 )   + 2^(-a[5 ] - p3*h[3 ] - p4*h[4 ] - p5*h[5 ] -h*(wh - we ) )   < = 1 - margin ; \\hfill\\eqref|splittingnonreg51%              # nonregular stays nonregular subject to nonregular61 { p3 in 0 .. 6 , p4 in 0 .. 6 , p5 in 0 .. 6 , p6 in 0 .. 5 :                             p3+p4+p5+p6=6 } :    2 * 2^(-a[6 ] - p6*h[6 ] - p5*h[5 ] - p4*h[4 ] - p3*h[3 ] ) < = 1 - margin ; \\hfill\\eqref|splittingnonreg61%    # nonregular becomes regular subject to nonregular62 { p3 in 0 .. 6 , p4 in 0 .. 6 , p5 in 0 .. 6 , p6 in 0 .. 5 :                            p3+p4+p5+p6=6 } :    2 * 2^(-a[6 ] - p6*a[6 ] - p5*a[5 ] - p4*a[4 ] - p3*a[3 ] + r6 ) < = 1 - margin ; \\hfill\\eqref|splittingnonreg62% ...."
  ],
  "abstract_text": [
    "<S> in this paper we introduce `` hybrid '' max 2-cspformulas consisting of `` simple clauses '' , namely conjunctions and disjunctions of pairs of variables , and general 2-variable clauses , which can be any integer - valued functions of pairs of boolean variables . </S>",
    "<S> this allows an algorithm to use both efficient reductions specific to and and or clauses , and other powerful reductions that require the general csp setting . </S>",
    "<S> we use new reductions introduced here , and recent reductions such as `` clause - learning '' and `` 2-reductions '' generalized to our setting s mixture of simple and general clauses .    </S>",
    "<S> parametrizing an instance by the fraction @xmath0 of non - simple clauses , we give an exact ( exponential - time ) algorithm that is the fastest known polynomial - space algorithm for @xmath1 ( which includes the well - studied max 2-satproblem but also instances with arbitrary mixtures of and and or clauses ) ; the only efficient algorithm for mixtures of and , or , and general integer - valued clauses ; and tied for fastest for general max 2-csp(@xmath2 ) . </S>",
    "<S> since a pure 2-sat input instance may be transformed to a general csp instance in the course of being solved , the algorithm s efficiency and generality go hand in hand .    </S>",
    "<S> our algorithm analysis and optimization are a variation on the familiar measure - and - conquer approach , resulting in an optimizing mathematical program that is convex not merely quasi - convex , and thus can be solved efficiently and with a certificate of optimality . </S>",
    "<S> we produce a family of running - time upper - bound formulas , each optimized for instances with a particular value of  @xmath0 but valid for all instances .    </S>",
    "<S> = 1 </S>"
  ]
}