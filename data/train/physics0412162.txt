{
  "article_text": [
    "the present note was initiated by the revisited astumian s paradox . in august 2004 piotrowski and",
    "sladowski @xcite asserted that astumian s analysis was flawed .",
    "however , as shown by astumian @xcite , this statement was wrong .",
    "since the analysis of the problem in a slightly more general frame than it was done earlier could be a good exercise for graduate students , we came to the conclusion that it might be useful to publish our elementary considerations about the properties of markov chains corresponding to astumian type games .    for entirely didactic reasons , in sections ii and",
    "iii we present a brief summary of definitions and statements which are needed for the analysis of the astumian type markov chains . in section iv we analyze the properties of such chains and determine the probabilities of losing and winning .",
    "conclusions are made in section v.",
    "let @xmath0 be a finite set of positive integers , and @xmath1 be a set of non - negative integers .",
    "denote by @xmath2 the random variable which assumes the elements of @xmath3 .",
    "we say that the sequence @xmath4 forms a markov chain if for all @xmath5 and for all possible values of random variables the equation @xmath6 is fulfilled . if @xmath7 then the process is said to be in _ state _",
    "@xmath8 at the @xmath9th ( discrete time instant ) step .",
    "the states @xmath10 define _ the space of states _ of the process . the probability distribution @xmath11 of the random variable @xmath12",
    "is called the _ initial distribution _ and the conditional probabilities @xmath13 are called _",
    "transition probabilities_. if @xmath14 and @xmath7 , then we say that the process made a transition @xmath15 at the @xmath9th step .",
    "the markov chain is _ homogeneous _ if the transition probabilities are independent of @xmath5 . in this case",
    "we may write @xmath16 and it obviously holds that @xmath17 in what follows we shall consider only homogeneous markov chains",
    ". we would like to emphasize that the transition probability matrix @xmath18 which is a _ stochastic matrix _ , and the initial distribution @xmath19 determine the random process uniquely .",
    "for the sake of simplicity , we assume that the process is a random walk of an abstract object , called _ particle _ on the space of states @xmath20 .",
    "the @xmath9th step transition probability @xmath21 satisfies the following equation : @xmath22 where @xmath23 it is to note that @xmath24 is the probability that at the @xmath9th step the particle is in the state @xmath8 provided that at @xmath25 it was in the state @xmath26 . from eq .",
    "( [ 5 ] ) we obtain that @xmath27 and by using the rules of matrix multiplication we arrive at @xmath28 where @xmath29 and @xmath30 is the @xmath31 unit matrix .",
    "making use of the total probability theorem we can determine _ the absolute probabilities _ @xmath32 as follows : @xmath33 where @xmath34 is the initial probability .",
    "clearly , @xmath32 is the probability that the particle is in the state @xmath8 at the @xmath9th step . introducing the row vector @xmath35 eq .",
    "( [ 8 ] ) can be rewritten in the form : @xmath36 where the upper index @xmath37 indicates the transpose of matrix @xmath38 and vector @xmath39 defined by ( [ 7 ] ) and ( [ 9 ] ) , respectively .",
    "if the process starts from the state @xmath26 , then @xmath40 and @xmath41",
    "in order to use clear notions , we introduce several well - known definitions . if there is an integer @xmath42 such that @xmath43",
    ", then we say the state @xmath44 can be reached from the state @xmath8 . if @xmath44 can be reached from @xmath8 and @xmath8 can be reached from @xmath44 , then @xmath8 and @xmath44 are _ connected states_. obviously , if @xmath8 and @xmath44 are not connected , then either @xmath45 , or @xmath46 .",
    "the set of states which are connected forms a _ class of equivalence_. a markov chain is called _ irreducible _ if every state can be reached from every state i.e. , the entire state space consists of only one class of equivalence . in other words , the markov chain is irreducible when all of the states are connected .",
    "the probability @xmath47 of passage from @xmath26 to @xmath8 in exactly @xmath9 steps , that is , without passing through @xmath8 before the @xmath9th step , is given by @xmath48 there exists an important relationship between the probabilities @xmath24 and @xmath47 which is easy to prove .",
    "the relationship is given by @xmath49 one has to note that the expressions @xmath50 are the diagonal elements of the unit matrix @xmath51 .",
    "the proof of ( [ 12 ] ) is immediate upon applying the total probability rule .",
    "the particle passes from @xmath26 to @xmath8 in @xmath9 steps if , and only if , it passes from @xmath26 to @xmath8 for the first time in exactly @xmath52 steps , @xmath53 , and then passes from @xmath8 to @xmath8 in the remaining @xmath54 steps .",
    "these  paths \" are disjoint events , and their probabilities are given by @xmath55 .",
    "summing over @xmath52 one obtains the equation ( [ 12 ] ) .",
    "let us introduce the generating functions @xmath56 taking into account that @xmath50 , from eq .",
    "( [ 12 ] ) we obtain @xmath57,\\ ] ] and from this @xmath58 so we have @xmath59 and in particular @xmath60    @xmath61 defined by ( [ 16 ] ) is the probability that a particle starting its walk from @xmath26 passes through the state @xmath8 at least once .",
    "clearly , @xmath62 is _ the probability of returning to @xmath26 at least once_.    more generally , the probability @xmath63 that a particle starting its walk from @xmath26 passes through @xmath8 _ at least @xmath52 times _ is given by @xmath64\\;f_{jj}(k-1 ) = f_{ij}\\;f_{jj}(k-1).\\ ] ] in particular , the probability of returning to @xmath26 at least @xmath52 times is given by @xmath65 .",
    "its limit @xmath66 is the probability of _ returning to @xmath26 infinitely often_. it follows from the previous relationship that the probability that a particle starting its walk from @xmath67 passes through @xmath8 infinitely many times is @xmath68 so that @xmath69    we say that @xmath26 is a _ return state _ or a _ nonreturn state _ according as @xmath70 or @xmath71 . as a further definition ,",
    "we say that @xmath26 is a _ recurrent state _ or a _ nonrecurrent state _ according as @xmath72 or @xmath73 .",
    "a nonrecurrent state is often called a _ transient state_.    the state @xmath26",
    "is called _ periodic _ with period @xmath74 if a return to @xmath26 can occur only at steps @xmath75 and @xmath76 is the greatest integer with this property .",
    "if @xmath9 is not divisible by @xmath74 , then @xmath77 . if the period of each state is equal to @xmath78 , i.e. , if @xmath79 , then the markov chain is called _ aperiodic_. in the sequel we are dealing with aperiodic markov chains .",
    "a set @xmath80 of states in a markov chain is _ closed _ if it is impossible to move out from any state of @xmath80 to any state outside @xmath80 by one - step transitions , i.e. , @xmath81 if @xmath82 and @xmath83 in this case @xmath77 obviously holds for every @xmath84 . if a single state @xmath26 forms a closed set , then we call this an _ absorbing state _ , and we have @xmath85 .",
    "the states of a closed set @xmath80 are recurrent states since the return probability @xmath86 for any state @xmath87 is equal to @xmath78 .",
    "therefore , the _ set of recurrent states _ is denoted by @xmath80 .",
    "can be decomposed into mutually disjoint closed sets @xmath88 such that from any state of a given set all states of that set and no others can be reached .",
    "states @xmath89 can be reached from @xmath90 , but not conversely . ]",
    "the set of states having return probabilities @xmath91 is the _ set of transient states _ and it is denoted by @xmath90 .",
    "obviously , if @xmath92 and @xmath93 , i.e. , if @xmath8 is an absorbing state , then @xmath61 is the probability that a particle starting at @xmath26 is finally absorbed at @xmath94 .",
    "let @xmath95 be the _ passage time _ of a particle from the state @xmath26 to the state @xmath8 , taking values @xmath96 with probabilities @xmath97 .",
    "if @xmath98 then the _ expected passage time _ @xmath99 from @xmath26 to @xmath8 is defined by @xmath100_{z=1},\\ ] ] while if @xmath101 , one says that @xmath102 with probability @xmath103 , i.e. , if @xmath101 , then the expected passage time @xmath104 . if the state @xmath105 and it is recurrent , i.e. , if @xmath106 , then the expectation @xmath107_{z=1 } = \\tau_{ii } = \\mu_{i}\\ ] ] is called _ mean recurrent time_. if @xmath108 , then we say that @xmath26 is a _ recurrent null - state _ , whereas if @xmath109 , then we say that @xmath26 is a _ recurrent non - null - state_. if @xmath91 , i.e. , the state @xmath26 is transient , then @xmath110 is the probability that the recurrence time is infinitely long , and so @xmath108 .",
    "we say that the recurrent state @xmath26 is _ ergodic _ , if it is not a null - state and is aperiodic , that is , if @xmath111 and @xmath79 .",
    "the first statement is very simple , hence it is given without proof . if @xmath8 is a transient or a recurrent null - state , then for any arbitrary @xmath26 @xmath112 holds .    if @xmath26 and @xmath8 are recurrent aperiodic states due to the same closed set , then @xmath113 irrespective of @xmath26 .  )",
    "tauber s theorem is used instead of the lemma by erds - feller - kac . ]    if @xmath114 , then we have from eq . ( [ 14 ] ) the formula @xmath115 substituting this into ( [ 14 ] ) we obtain the following expression : @xmath116 by using tauber s theorem we can state that @xmath117 since @xmath26 and @xmath8 are aperiodic recurrent states due to the same closed set , @xmath118 i.e. , the limit value we have to determine @xmath119 applying lhospital s rule we find that @xmath120 and thus we obtain ( [ 20 ] ) .",
    "this completes the proof .    as a generalization we would like to consider the case",
    "when @xmath26 is a transient state ( @xmath121 ) and @xmath8 is an aperiodic recurrent state due to the closed set @xmath80 .",
    "it can be shown that @xmath122 where @xmath61 is the probability that a particle starting from @xmath26 will ultimately reach and stay in the state @xmath123 .",
    "in other words , @xmath61 is the _ absorption probability _ that satisfies the following system of equations : @xmath124 clearly , if @xmath125 contains all of the possible states of the particle , then @xmath126 the proof of ( [ 24 ] ) follows immediately from ( [ 22 ] ) .",
    "since @xmath127 we obtain the limit relationship ( [ 24 ] ) .    finally , we would like to present a brief classification of markov chains .    *",
    "a markov chain is called _ irreducible _ if and only if all its states form a closed set and there is no other closed set contained in it . * a markov chain is called _ ergodic _ if the probability distributions @xmath128 always converge to a limiting distribution @xmath129 which is independent of the initial distribution @xmath130 , that is , when @xmath131 .",
    "all states of a finite , aperiodic irreducible markov chain are ergodic . *",
    "the probability distribution @xmath132 is a _ stationary _ distribution of a markov chain if , when we choose it as an initial distribution all the distributions @xmath133 will coincide with @xmath132 .",
    "every stationary distribution of a markov chain satisfies the following system of linear equations : @xmath134 and conversely , each solution @xmath135 of this system is a stationary distribution of the markov chain , if it is a probability distribution .",
    "it is to mention that some parts of this short summary is based on the small but excellent book by takcs @xcite .",
    "in this section we are going to deal with markov chains containing _ two absorbing states _ @xmath136 and @xmath137 , and @xmath138 _ transient states_. in this case , the markov chain is _ reducible _ and _ aperiodic_. the set of its states is the union of _ two closed sets _ @xmath139 and @xmath140 , and of the set of transient states @xmath141 the states @xmath136 and @xmath142 can be reached from each state of @xmath143 but the converse does nt hold , no state of @xmath90 can be reached from the states @xmath136 and @xmath137 .",
    "the states of @xmath90 are _ non - recurrent _ since the particle leaves the set never to return to it . in contrary , the states of @xmath144 and @xmath145 are ergodic .",
    "let us assume that the transition matrix @xmath146 has the following form : @xmath147 where @xmath148 the particle , which starts his walk from one of the states @xmath149 , is captured when it enters the states @xmath136 or @xmath150 . by using the foregoing formulae for @xmath151 and @xmath152",
    ", we can immediately obtain the capture probabilities by the absorbing states @xmath136 and @xmath150 , respectively . in order to have a direct insight into the nature of the process",
    ", we derive the backward equations for the probabilities @xmath24 .",
    "clearly , @xmath153 and by introducing the generating function @xmath154 we obtain the following system of equations : @xmath155 this can be simplified and rewritten in the form : @xmath156 after elementary algebra , we can determine all the generating functions @xmath157 , nevertheless we are now interested only in those functions which correspond to processes starting from the state @xmath158 .",
    "in this case we have @xmath159 where @xmath160 - ( 1 - w_{22 } z ) w_{34 } w_{43 } z^{2}.\\ ] ] applying tauber s theorem we obtain that @xmath161 @xmath162 and @xmath163 performing the substitutions @xmath164 we have @xmath165 and @xmath166 it is elementary to show that @xmath167 in order to prove these equations , let us take into account relationship ( [ 15 ] ) and write @xmath168 and @xmath169 since @xmath170 we have @xmath171 comparing ( [ 43 ] ) and ( [ 45 ] ) with ( [ 49 ] ) we see that eqs .",
    "( [ 48 ] ) are true .",
    "it is convenient to write the absorption probabilities @xmath172 and @xmath173 in the form : @xmath174 where @xmath175 and we see immediately that @xmath176 , as expected .",
    "it seems to be worthwhile to study the history of a particle starting its random walk from the state @xmath158 .",
    "( 8,12 ) ( 0.5 , 1)(2,1)(1,0)7 ( 0.5 , 3)(2,3)(1,0)7 ( 0.5 , 5)(2,5)(1,0)7 ( 0.5 , 7)(2,7)(1,0)7 ( 0.5 ,",
    "9)(2,9)(1,0)7 ( 5.5 , 5)(0,1)2 ( 5.5 , 5)(0,-1)2 ( 3.75 , 3)(0,1)2 ( 3.75 , 3)(0,-1)2 ( 7.25 , 7)(0,1)2 ( 7.25 , 7)(0,-1)2    let us consider a trap containing a special ladder with @xmath177 rungs .",
    "each rung corresponds to a given state of the markov chain under investigation .",
    "the process starts when a particle enters ( say , ) on the third rung of the ladder , i.e. , in the state @xmath178 .",
    "once the particle has entered , it is free to move up and down the rungs randomly .",
    "1 illustrates this random walk .",
    "if the particle reaches the states either @xmath136 or @xmath150 , it is absorbed .",
    "( if the random walk is considered as a game , then the absorption state with probability smaller than @xmath179 is the  winning \" state . )",
    "having chosen the transition matrix @xmath180    [ ht ! ]",
    "-0.3 cm    we calculated the dependencies of probabilities @xmath181 and @xmath182 on the number of steps @xmath9 .",
    "the results of calculation are shown in fig .",
    "we see that the probability to find the particle after @xmath183 steps in the transient state @xmath158 is practically zero .",
    "the same holds for the transient states @xmath184 and @xmath185 .",
    "after @xmath183 steps the particle is absorbed either in @xmath136 with probability @xmath186 or in @xmath150 with probability @xmath187 .",
    "it is instructive to determine also the probabilities @xmath188 and @xmath189 . as a reminder ,",
    "we note that @xmath190 is the probability that a particle starting from @xmath158 passes through @xmath191 _ at least once .",
    "_ by using the transition matrix ( [ 52 ] ) we obtain the following values : @xmath192 and @xmath193 .",
    "3 shows the histogram of these probabilities .",
    "-0.3 cm    it is evident that passing through either @xmath136 or @xmath150 at least once means that the particle is absorbed . as expected in the present case , the probability @xmath194 that the particle starting from @xmath158 returns to @xmath158 at least once , is nearly @xmath78 .",
    "it is to mention that the two absorbing states @xmath136 and @xmath150 are recurrent since @xmath195 .    in what follows",
    "we would like to deal with the _ determination of the absorption time probability_. denote by @xmath196 the number of steps leading to the absorption of a particle starting its random walk from the state @xmath67 . by definition , @xmath197 and @xmath198 are the probabilities that the particle starting from the state @xmath199 is absorbed exactly at the @xmath9th step in @xmath136 or in @xmath150 , respectively .",
    "hence we can write that @xmath200 it is easy to prove that @xmath201 from ( [ 12 ] ) one obtains @xmath202 and by taking into account that @xmath203 one has @xmath204 it follows immediately from these equations that @xmath205 and this completes the proof .",
    "the absorption time probabilities @xmath206 can be determined by the  forward \" equations : @xmath207 and @xmath208 by using these expressions one can write @xmath209,\\ ] ] which in the case of @xmath146 defined by ( [ 27 ] ) has the following form : @xmath210 for the sake of completeness , we would like to show that @xmath211 in the case of eq .",
    "( [ 53 ] ) we see that @xmath212 and by using the expression ( [ 26 ] ) we find ( [ 57 ] ) . in the case of eq .",
    "( [ 55 ] ) @xmath213 \\ ; \\left[\\;w_{\\ell 1 } + \\;w_{\\ell 5}\\right ] = \\ ] ] @xmath214\\;\\left[\\;w_{\\ell 1 } + \\;w_{\\ell 5}\\right ] = \\sum_{\\ell=2}^{4 } g_{i \\ell}(1)\\;\\left[\\;w_{\\ell 1 } + \\;w_{\\ell 5}\\right ] = f_{i1 } + f_{i5 } = 1.\\ ] ]    [ ht ! ] -0.3 cm    using the transition matrix @xmath146 given by ( [ 52 ] ) , we calculated the dependence of the probability @xmath215 on the number of steps @xmath9 .",
    "the results are seen in fig .",
    "4 . as expected ,",
    "if the starting state is @xmath158 , then the probability @xmath216 varies differently with the step number as the probabilities @xmath217 and @xmath218 .",
    "it is characteristic the probabilities have a rather long tail .",
    "since @xmath215 is the probability that a particle starting from @xmath26 is absorbed exactly in the @xmath9th step , the expectation and the standard deviation of the absorption time @xmath196 are given by @xmath219 and @xmath220^{1/2}.\\ ] ] for a transition matrix of the form ( [ 52 ] ) these values are presented in the table i.    .[t1 ] expectations and the standard deviations of the absorption time [ cols=\"^,^,^,^\",options=\"header \" , ]      as it has been shown , @xmath172 is the probability that a particle starting its random walk from the state @xmath158 is finally absorbed in the state @xmath136 .   since @xmath176 . ] if @xmath222 , then @xmath136 is called a  losing \" state , while if @xmath223 , then it is a  winning \" state .",
    "the game is  fair \" when @xmath224 , i.e. when the equation @xmath225 is fulfilled as it follows from eq .",
    "( [ 51 ] ) .",
    "astumian @xcite proposed two transition matrices , namely    @xmath226 resulting in the absorption probability @xmath227 and showed that the arithmetic mean of these two matrices @xmath228 @xmath229 brings about the probability @xmath230 , i.e. , in this case the state @xmath136 becomes  winning \" state .",
    "this property of the transition matrix ( [ 27 ] ) is general _ if the diagonal entries of the matrix are different from zero_. by using a simple example we would like to demonstrate this statement .",
    "let us choose the transition matrix in the following form : @xmath231 one obtains immediately that @xmath232 where @xmath233 if @xmath234 or @xmath235 , then the game is  fair \" , i.e. , @xmath236 the function @xmath237 assumes its minimal value at @xmath238 and this value is @xmath239 introducing the notation @xmath240 one has @xmath241 choosing @xmath242 according to the inequalities @xmath243 i.e. , @xmath244 and @xmath245 one finds that @xmath246 evidently , _",
    "there are infinitely many pairs of transition matrices which result in probabilities of losing in the state @xmath136 but the arithmetic means of corresponding pairs bring about probabilities of winning in the state @xmath247_.    [ ht ! ] -0.3 cm    for the sake of illustration in fig .",
    "5 the probability @xmath248 vs. @xmath249 curve is plotted by the values @xmath250 and @xmath251 .",
    "the black points @xmath252 and @xmath253 correspond to the probabilities @xmath254 = 8/17,\\ ] ] respectively .",
    "it seems to be not superfluous to write down the corresponding transition matrices : @xmath255 and @xmath256    by choosing @xmath242 values in the allowed interval , we can construct infinitely many transition matrices with just described properties .",
    "cm    [ ht ! ]",
    "-0.3 cm    let us now define a markov chain with transition matrix @xmath146 randomly chosen from @xmath257 and @xmath258 defined by ( [ 63 ] ) . in this case",
    "@xmath259 \\times \\mathbf{w}(n-1),\\ ] ] i.e. , @xmath260^{n}.\\ ] ]    in fig .",
    "6 the dependencies of the absorption probabilities @xmath261   is the first entry of the third row of the matrix @xmath262 . ] on the number of steps @xmath9 are shown when the transition matrices are @xmath263 and @xmath146 , respectively .",
    "the last one corresponds to the random selection of the entries from @xmath257 and @xmath258 with probability @xmath264 .",
    "obviously , not all values of @xmath265 $ ] bring about a  winning \" game , i.e. , an absorption probability less than @xmath179 .",
    "taking into account the transition matrices @xmath257 and @xmath258 defined by ( [ 63 ] ) , we determined the dependence of @xmath172 on @xmath266 . as seen in fig .",
    "7 , there is a well defined subinterval @xmath267 \\in [ 0,1]$ ] containing the @xmath266 values which result in absorption probabilities @xmath172 smaller than @xmath179 . in the present case we obtained that @xmath268 and @xmath269",
    "it has been shown that the random walk of a particle defined by the stochastic transition matrix of a markov chain is equivalent to an astumian type game if the diagonal entries of the matrix are different from zero and the first @xmath270 as well as the last @xmath271 entries are equal to @xmath78 . by using a simple example ,",
    "we have proved that there are infinitely many pairs of transition matrices which result in absorption probabilities in the state @xmath136 larger than @xmath179 but the arithmetic means of the corresponding pairs lead to probabilities smaller than @xmath179 ."
  ],
  "abstract_text": [
    "<S> in 2001 astumian @xcite published a very simple game which can be described by a markov chain with absorbing initial and final states . in august 2004 piotrowski and sladowski @xcite asserted that astumian s analysis was flawed . </S>",
    "<S> however , as was shown by astumian @xcite , this statement was wrong . in this comment </S>",
    "<S> the properties of markov chains corresponding to games that are more general than that studied by astumian , are investigated . </S>"
  ]
}