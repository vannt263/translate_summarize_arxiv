{
  "article_text": [
    "frequency analysis of signals @xcite is a classical problem that has broad applications ranging from communications , radar , array processing to seismology and astronomy .",
    "grid - based sparse methods have been vastly studied in the past decade with the development of compressed sensing ( cs ) which exploit signal sparsity ",
    "the number of frequency components @xmath0 is small  but suffer from basis mismatches due to the need of gridding of the frequency interval @xcite .",
    "its research has been recently advanced owing to the mathematical theory of super - resolution introduced by cands and fernandes - granda @xcite , which refers to recovery of fine details of a sparse frequency spectrum from coarse scale time - domain samples only .",
    "they propose a gridless atomic norm ( or total variation norm ) technique , which can be cast as semidefinite programming ( sdp ) , and prove that a continuous frequency spectrum can be recovered with infinite precision given a set of @xmath1 regularly spaced samples . the technical method and theoretical result were then extended by tang _",
    "@xcite to the case of partial / compressive samples , showing that only a number of @xmath2 random samples are sufficient for the recovery with high probability via atomic norm minimization ( anm ) .",
    "moreover , yang and xie @xcite study the multiple - measurement - vector ( mmv ) case , which arises naturally in array processing applications , with similar results proven using extended mmv atomic norm methods .",
    "however , a major problem of existing atomic norm methods is that the frequency spectrum can be recovered only when the frequencies are sufficiently separated , prohibiting commonly known high resolution  the capability of resolving two closely spaced frequency components",
    ". a sufficient minimum separation of frequencies is @xmath3 in theory .",
    "empirical evidences in @xcite suggest that this number can be reduced to @xmath4 , while according to @xcite it also depends on @xmath0 , @xmath5 and the number of measurement vectors .    in this paper",
    ", we attempt to propose a high resolution gridless sparse method for super - resolution to break the resolution limit of existing atomic norm methods .",
    "our method is motivated by the formulations and properties of atomic @xmath6 norm and the atomic norm in @xcite .",
    "in particular , the atomic @xmath6 norm has no resolution limit but is np hard to compute .",
    "to the contrary , as a convex relaxation the atomic norm can be efficiently computed but suffers from a resolution limit as mentioned above .",
    "we propose a novel sparse metric and theoretically show that the new metric fills the gap between the atomic @xmath6 norm and the atomic norm .",
    "it approaches the former under appropriate parameter setting .",
    "with the sparse metric we formulate a nonconvex optimization problem and present a locally convergent iterative algorithm for super - resolution .",
    "the algorithm iteratively carries out anm with a sound reweighting strategy , which determines preference of frequency selection based on the latest estimate and enhances sparsity and resolution , and is termed as reweighted atomic - norm minimization ( ram ) . to the best of our knowledge , ram implements the first reweighting strategy in the continuous dictionary setting while existing reweighted @xmath7 algorithms ( see , e.g. , @xcite ) are for the discrete setting .",
    "extensive numerical simulations are carried out to demonstrate the high resolution performance of ram with application to doa estimation compared to existing arts .",
    "we consider the super - resolution problem in the most general case with partial samples and mmvs .",
    "in particular , we observe the samples of the data matrix @xmath8 on the rows indexed by @xmath9 of size @xmath10 , denoted by @xmath11 .",
    "the @xmath12th element of @xmath13 is ( corrupted by noise in practice ) where @xmath14 denotes a discrete complex sinusoid with frequency @xmath15 $ ] , and @xmath16 is the coefficient vector of the @xmath17th sinusoid .",
    "that is , each column of @xmath13 is superimposed by @xmath0 discrete sinusoids .",
    "we are interested in recovering the frequencies @xmath18 given @xmath11 .",
    "meanwhile , it is also of interest to recover the complete data matrix @xmath13 .",
    "the resulting problem is known as continuous / off - grid cs according to @xcite , which differs from existing cs framework in the sense that every frequency @xmath19 can take any continuous value in @xmath20 rather than constrained on a finite discrete grid .",
    "the single - measurement - vector ( smv ) case where @xmath21 is known as line spectral estimation .",
    "the mmv case where @xmath22 is common in array processing .",
    "therein the sampling index set @xmath23 refers to sensor placement of a linear sensor array and a smaller sample size means use of less sensors .",
    "@xmath11 consists of measurements of the sensor array and each column vector corresponds to one data snapshot .",
    "each frequency corresponds to the direction of one source .",
    "therefore , the frequency estimation problem is known as direction of arrival ( doa ) estimation .",
    "the super - resolution or continuous cs problem is tackled from the perspective of signal recovery .",
    "the frequencies are then retrieved from the computational result . in particular , we seek a _ frequency - sparse _",
    "candidate @xmath24 , which is composed of a few frequency components , in a feasible domain defined by the observed samples . to do this",
    ", we first define a sparse metric of @xmath24 and then optimize the metric over the feasible domain .",
    "a direct sparse metric is the smallest number of frequency components composing @xmath24 , known as the atomic @xmath6 norm and denoted by @xmath25 . according to @xcite @xmath25",
    "can be characterized as the following rank minimization problem : the first constraint in ( [ formu : atom0norm ] ) imposes that @xmath24 lies in the range space of a ( hermitian ) toeplitz matrix @xmath26 whose first row is specified by the transpose of @xmath27 .",
    "the frequencies composing @xmath24 are encoded in @xmath28 .",
    "once an optimizer of @xmath29 , say @xmath30 , is obtained the frequencies can be retrieved from @xmath31 according to the vandermonde decomposition lemma ( see , e.g. , @xcite ) , which states that any positive semidefinite ( psd ) toeplitz matrix @xmath31 can be decomposed as @xmath32 , where the order @xmath33 and @xmath34 ( see a method for realization of the decomposition in ( * ? ? ?",
    "* appendix a ) ) .",
    "the atomic @xmath6 norm directly enhances sparsity , however , it is nonconvex and np - hard to compute and encourages computationally feasible alternatives . in this spirit , the atomic ( @xmath7 ) norm , denoted by @xmath35 ,",
    "is introduced as a convex relaxation of @xmath25 and has the following semidefinite formulation @xcite : from the perspective of low rank matrix recovery ( lrmr ) , ( [ formu : an_sdp ] ) attempts to recover the low rank matrix @xmath28 by relaxing the pseudo - rank norm in ( [ formu : atom0norm ] ) to the nuclear norm or equivalently the trace norm for a psd matrix .",
    "the atomic norm is advantageous in computation compared to the atomic @xmath6 norm , however , it suffers from a resolution limit due to the relaxation which is not shared by the latter @xcite .",
    "inspired by the link between continuous cs and lrmr demonstrated above , we propose the following sparse metric of @xmath24 : where @xmath36 is a regularization parameter that avoids the first term being @xmath37 when @xmath28 is rank deficient .",
    "note that the log - det heuristic @xmath38 is a common smooth surrogate for the matrix rank ( see , e.g. , @xcite ) . from the perspective of lrmr ,",
    "the atomic @xmath6 norm minimizes the number of nonzero eigenvalues of @xmath28 while the atomic norm minimizes the sum of the eigenvalues .",
    "in contrast , the new metric @xmath39 penalizes @xmath40 , where @xmath41 denotes the eigenvalues .",
    "we plot the function @xmath42 with different @xmath43 s in fig .",
    "[ fig : sparsity ] , according to which we expect that the new metric @xmath39 bridges @xmath35 and @xmath25 when @xmath43 varies from @xmath44 to @xmath45 .",
    "formally , we have the following results and we provide their proofs in an extended journal paper @xcite .     with different @xmath43 .",
    "the plotted curves include the @xmath6 and @xmath7 norms corresponding to @xmath46 and @xmath47 respectively , and @xmath48 corresponding to @xmath49 with @xmath50 and @xmath51 .",
    "@xmath48 is translated and scaled such that it equals 0 and 1 at @xmath52 and 1 respectively for better illustration.,width=278 ]    let @xmath53 . then , i.e. , they are equivalent infinitesimals .",
    "[ thm : epsilontoinf ]    let @xmath54 .",
    "then , we have the following results :    1 .   if @xmath55 , then i.e. , they are equivalent infinities . otherwise , @xmath39 is a positive constant depending only on @xmath24 ; 2 .",
    "let @xmath56 be the optimizer of @xmath29 to the optimization problem in ( [ formu : nonconvexrelax ] ) .",
    "then , the smallest @xmath57 eigenvalues of @xmath58 are either zero or approach zero as fast as @xmath43 ; 3 .   for any cluster point of @xmath56 at @xmath59 , denoted by @xmath60 , there exists an atomic decomposition @xmath61 of order @xmath62 such that @xmath63 .",
    "[ thm : epsilontozero ]    theorem [ thm : epsilontoinf ] shows that the new metric @xmath39 plays the same role as @xmath35 in the limiting scenario when @xmath53 , while theorem [ thm : epsilontozero ] says that it is equivalent to @xmath25 as @xmath54 .",
    "consequently , it fills the gap between @xmath35 and @xmath25 and enhances sparsity and resolution compared to @xmath35 as @xmath43 gets small .",
    "moreover , theorem [ thm : epsilontozero ] characterizes the properties of the optimizer @xmath56 as @xmath54 including the convergent speed of the smallest @xmath64 eigenvalues and the limiting form of @xmath31 via the vandermonde decomposition .",
    "in fact , we always observe via simulations that the smallest @xmath64 eigenvalues of @xmath31 become zero once @xmath43 is modestly small .",
    "with the proposed sparse metric @xmath39 , we solve the following optimization problem for signal and frequency recovery : or equivalently , where @xmath65 denotes the feasible domain of @xmath24 .",
    "for example , in the noiseless case , it is the set @xmath66 .",
    "since the log - det term @xmath67 is a concave function of @xmath29 , the problem is nonconvex and no efficient algorithms can guarantee to obtain the global optimum . a majorization - maximization ( mm )",
    "algorithm is introduced as follows .",
    "let @xmath68 denote the @xmath69th iterate of the optimization variable @xmath29 .",
    "then , at the @xmath70th iteration we replace @xmath67 by its tangent plane at the current value @xmath71 . as a result ,",
    "the optimization problem at the @xmath70th iteration becomes since @xmath67 is strictly concave in @xmath29 , at each iteration its value decreases by an amount greater than the decrease of its tangent plane .",
    "it follows that the objective function in ( [ formu : problem ] ) monotonically decreases at each iteration and converges to a local minimum .      to interpret the optimization problem in ( [ formu : problem_j ] ) , let us define a _ weighted continuous dictionary _ w.r.t . the original continuous dictionary @xmath72 , where @xmath73 is a weighting function .",
    "for @xmath74 , we define its _ weighted atomic norm _",
    "@xmath75 as its atomic norm induced by @xmath75 : according to the definition above , @xmath76 specifies preference of the atoms @xmath77 . to be specific ,",
    "an atom @xmath78 , @xmath79 , is more likely selected if @xmath80 is larger .",
    "moreover , the atomic norm is a special case of the weighted atomic norm with a constant weighting function ( i.e. , without any preference ) according to @xcite .",
    "suppose that @xmath81 with @xmath82 .",
    "then , [ thm : weightan ]    let @xmath83 and @xmath84 . by theorem [ thm : weightan ] we can rewrite the optimization problem in ( [ formu : problem_j ] ) as the following _ weighted atomic norm minimization _ problem : as a result",
    ", the proposed iterative algorithm can be interpreted as _ reweighted atomic - norm minimization _ ( ram ) . if we let @xmath85 be a constant function or equivalently , @xmath86 , such that there is no preference of the atoms at the first iteration , then the first iteration coincides with the anm . from the second iteration ,",
    "the preference is defined by the weighting function @xmath87 specified above .",
    "note that @xmath88 corresponds to the power spectrum of capon s beamforming ( see , e.g. , @xcite ) if @xmath89 is interpreted as the covariance of the noiseless data and @xmath43 as the noise variance .",
    "therefore , the reweighting strategy makes the frequencies around those estimated by the current iteration preferable at the next iteration and thus enhances sparsity . at the same time",
    ", the preference leads to finer details of the frequency spectrum in that area and enhances resolution .",
    "since the `` noise variance '' @xmath43 can be translated as the confidence level in the current estimate , from this perspective we should gradually decrease @xmath43 and correspondingly increase the confidence in the solution during the algorithm .",
    "in this subsection , we study the success rate of ram in super - resolution compared to anm . in particular , we fix @xmath90 and @xmath91 with the sampling index set @xmath23 being generated uniformly at random .",
    "we vary the duo @xmath92 and at each combination we randomly generate @xmath0 frequencies such that they are mutually separated by at least @xmath93 .",
    "we randomly generate the amplitudes @xmath94 independently and identically from a standard complex normal distribution . after obtaining the noiseless samples , we carry out super - resolution using anm and ram , both implemented by an off - the - shelf sdp solver sdpt3 @xcite .",
    "the recovery is called successful if both the relative mse of signal recovery and the mse of frequency recovery are less than @xmath95 . at each combination @xmath92 , the success rate",
    "is measured over 20 monte carlo runs . in ram , we first scale the measurements such that @xmath96 and compensate the recovery afterwards .",
    "we start with @xmath86 and @xmath97 as default .",
    "we halve @xmath43 when beginning a new iteration until @xmath98 . we terminate ram",
    "if the relative change ( in the frobenius norm ) of the solution @xmath99 at two consecutive iterations is less than @xmath100 or the maximum number of iterations , set to 20 , is reached .",
    "we plot the success rates of anm and ram with @xmath101 in fig .",
    "[ fig : phasetrans_1 ] , where it is shown that successful recovery can be obtained with more ease with a smaller @xmath0 and a larger frequency separation @xmath93 , leading to a phase transition in the sparsity - separation domain .",
    "it is shown that ram significantly enlarges the success phase and hence enhances sparsity and resolution compared to anm .",
    "at @xmath102 we did not find a single failure in our simulation whenever @xmath103 and @xmath104 .",
    "the phase transitions of both anm and ram are not sharp since the frequencies are separated by _ at least _",
    "@xmath93 and a set of _ well separated _ frequencies can be possibly generated at a small value of @xmath93 .",
    "it is also observed that ram tends to converge in less iterations with a smaller @xmath0 and a larger @xmath93 .",
    "( top ) and @xmath102 ( bottom ) , @xmath90 and @xmath91 .",
    "the grayscale images present the success rates , where white and black colors indicate complete success and complete failure , respectively.,title=\"fig:\",width=158 ]   ( top ) and @xmath102 ( bottom ) , @xmath90 and @xmath91 .",
    "the grayscale images present the success rates , where white and black colors indicate complete success and complete failure , respectively.,title=\"fig:\",width=156 ]   ( top ) and @xmath102 ( bottom ) , @xmath90 and @xmath91 .",
    "the grayscale images present the success rates , where white and black colors indicate complete success and complete failure , respectively.,title=\"fig:\",width=158 ]   ( top ) and @xmath102 ( bottom ) , @xmath90 and @xmath91 .",
    "the grayscale images present the success rates , where white and black colors indicate complete success and complete failure , respectively.,title=\"fig:\",width=156 ]      we apply the proposed ram method to doa estimation .",
    "in particular , we consider a 10-element sparse linear array ( sla ) with sensors positions indexed by @xmath105 , where the distance between the first two sensors is half the wavelength .",
    "hence , we have that @xmath106 and @xmath107 .",
    "we consider that @xmath108 narrowband sources impinge on the sensor array from directions corresponding to frequencies @xmath109 , @xmath110 , @xmath111 and @xmath112 , and powers @xmath113 , @xmath113 , @xmath114 and @xmath115 , respectively . it is challenging to separate the first two sources which are separated by only @xmath116 .",
    "complex normal noise is added to the samples with variance @xmath117 and @xmath65 is defined as @xmath118 , where @xmath119 ( mean + twice standard deviation ) upper bounds the noise energy with high probability .",
    "we consider both the cases of uncorrelated and correlated sources while the later case is usually considered to be more difficult with existing methods such as music ( see , e.g. , @xcite ) . in the latter case ,",
    "sources 1 and 3 are set to be coherent ( completely correlated ) .",
    "assume that @xmath120 data snapshots are collected which are corrupted by i.i.d .",
    "gaussian noise of unit variance .",
    "we propose a dimension reduction technique to reduce the order of the sdp matrix from @xmath121 to @xmath122 and accelerate the computational speed , which is detailed in @xcite .",
    "we terminate ram within maximally 10 iterations and consider music and anm for comparison .",
    "our simulation results of 100 monte carlo runs are presented in fig .",
    "[ fig : noisy_noiselevel ] ( only the first 20 runs are presented for music for better illustration ) . in the absence of source correlations",
    ", music has satisfactory performance in most scenarios .",
    "however , its power spectrum exhibits only a single peak around the first two sources ( i.e. , the two sources can not be separated ) in at least 3 out of the first 20 runs ( indicated by the arrows ) .",
    "moreover , music is sensitive to source correlations and can not detect source 1 when it is coherent with source 3 .",
    "anm can not separate the first two sources in the uncorrelated source case and always produces many spurious sources .",
    "in contrast , the proposed ram always correctly detects 4 sources near the true locations , demonstrating its capabilities in enhancing sparsity and high resolution .",
    "anm and ram take @xmath123s and @xmath124s on average , respectively , while these numbers can be greatly decreased with more sophisticated algorithms ( see @xcite ) .",
    "in this paper , we studied the spectral super - resolution problem with partial samples and mmvs .",
    "motivated by its connection to the topic of lrmr , we proposed reweighted atomic - norm minimization ( ram ) for achieving high resolution compared to currently prominent atomic norm minimization ( anm ) and validated its performance via numerical simulations .",
    "z.  yang and l.  xie , `` on gridless sparse methods for line spectral estimation from complete and incomplete data , '' revised version submitted to _ ieee transactions on signal processing _ , _ available online at http://arxiv.org/abs/1407.2490_ , 2014 .",
    "m.  fazel , h.  hindi , and s.  p. boyd , `` log - det heuristic for matrix rank minimization with applications to hankel and euclidean distance matrices , '' in _ american control conference _ , vol .",
    "3.1em plus 0.5em minus 0.4emieee , 2003 , pp ."
  ],
  "abstract_text": [
    "<S> the super - resolution theory developed recently by cands and fernandes - granda aims to recover fine details of a sparse frequency spectrum from coarse scale information only . </S>",
    "<S> the theory was then extended to the cases with compressive samples and/or multiple measurement vectors . </S>",
    "<S> however , the existing atomic norm ( or total variation norm ) techniques succeed only if the frequencies are sufficiently separated , prohibiting commonly known high resolution . in this paper , a reweighted atomic - norm minimization ( ram ) </S>",
    "<S> approach is proposed which iteratively carries out atomic norm minimization ( anm ) with a sound reweighting strategy that enhances sparsity and resolution . </S>",
    "<S> it is demonstrated analytically and via numerical simulations that the proposed method achieves high resolution with application to doa estimation . </S>"
  ]
}