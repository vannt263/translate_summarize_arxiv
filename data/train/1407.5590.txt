{
  "article_text": [
    "network - based modeling and characterization of brain architectures has provided both a framework for integrating multi - modal imaging data as well as for understanding the function and dynamics of the brain and its subunits .",
    "brain networks are traditionally constructed either from structural or functional imaging data .",
    "structural brain networks represent properties of physical neuronal bundles and employ both invasive methods in animals  @xcite and non - invasive _ in vivo _ methods such as diffusion mri in humans  @xcite .",
    "functional brain networks represent the functional associations between regions estimated by statistical similarities in regional time series , including correlation or coherence  @xcite .",
    "functional brain networks can be extracted from multiple types of neuroimaging data . in the case of fmri data ,",
    "regional gray matter activity is measured by the _ blood oxygenation level dependent ( bold ) _ signal .",
    "eeg or meg data provide regional activity in the form of electrical activity and magnetic flux respectively .",
    "brain networks are commonly studied using techniques drawn from graph theory and machine learning  @xcite .",
    "these techniques provide fundamental and generalizable mathematical representations of complex neuroimaging data : nodes represent brain regions and edges represent structural or functional connectivity .",
    "this simplified graphical representation enables the principled examination of patterns of brain connectivity across cognitive and disease states  @xcite .",
    "while the majority of network - based studies have focused on the brain s default mode or `` resting '' state  @xcite , more recent efforts have turned to understanding brain connectivity elicited by task demands , including visual processing  @xcite and learning  @xcite .",
    "global network analysis of both functional and structural connectivity has demonstrated that brain networks have characteristic topological properties , including dense modular structures and efficient long - distance paths  @xcite .",
    "however , traditional network analysis tools are not always sensitive to small perturbations in functional or structural connectivity .",
    "recent efforts have focused on developing new tools to identify specific subgraphs that are particularly discriminative between brain states ( cognitive or disease ) and therefore critical for an understanding of local neurophysiological processes .",
    "zalesky and colleagues describe a set of methods to identify groups of edges that are significantly different between two groups of networks  @xcite .",
    "motifs , defined as frequently occurring ( across sessions and subjects ) patterns of local connectivity , are groups of edges with particular topological properties that may play specific functional roles  @xcite .",
    "finally , hyperedges are a type of edge set that may discriminate between cognitive states .",
    "hyperedges can be defined as groups of edges that vary significantly in weight over time  @xcite , for example during adaptive functions like learning . in general , these tools seek to associate local network features ( or subgraphs ) with cognitive function , a critical step necessary for informing therapeutic interventions .",
    "here we develop and apply a novel method for identifying subgraphs that discriminate between individuals with differing behavioral variables .",
    "drawing on new machine learning methods , we uncover the subgraphs that maximize the discriminative potential in explaining the differences in the rate of motor learning between individuals .",
    "the data for our analysis comes from a motor learning task experiment in which subjects neural activity was measured using fmri in multiple repeated sessions as they learned a set of new 12-note finger sequences analogous to piano arpeggios  @xcite .",
    "based on the behavioral data , we assign individuals in the study to two categories  `` high '' and `` low '' rate learners  using the exponential rate of decrease in the time required to perform a motor sequence ( also known as _ movement time _ ) .",
    "the fmri data was aligned to the harvard - oxford brain atlas ( part of the fsl tool  @xcite ) involving @xmath0 cortical and subcortical regions . a functional edge strength linking two cortical areas",
    "was estimated as the wavelet - based coherence of the corresponding regional time series .",
    "next , we employ and extend recent techniques from labeled network mining  @xcite to uncover what we call _ biomarkers_connected subgraphs of functional edges  whose strength of connectivity predict whether individuals are learning the task at `` high '' or `` low '' rate .",
    "more specifically , we binarize the weight of each edge at each time point into either high or low states , indicating strong or weak functional coherence between the associated brain areas .",
    "we then build in - network decision trees to guide the discovery of significant motor - learning - related subgraphs , whose edge state dynamics predict individual differences in learning rate . we employ randomized statistical tests to establish the significance of the discovered subgraphs and",
    "demonstrate their relationship to the subject s learning rates .",
    "our work is the first to identify `` biomarkers '' of learning rate . amongst tens of thousands of possible edges between @xmath0 cortical regions ,",
    "we find functional subgraphs comprised of @xmath1-@xmath2 edges that predict whether a subject is a high or low rate learner . at the same time",
    ", we ensure that the obtained subgraphs are statistically significant , by demonstrating that they are unlikely to occur in a non - parametric null model .",
    "our goal is to detect a set of functional edges connecting cortical regions whose state ( high / low coherence ) can predict individual differences in learning rate . we expect that learning - related changes in functional connectivity will be located in coordinated neural circuits  @xcite , and we therefore restrict our attention to predictive edges which form a connected subgraph . as the rate of learning increases , some functional edges within a subgraph of interest will fall into a low coherence state ( i.e. coherence between their adjacent regions activation will approach 0 ) , while others will move into a high coherence state .",
    "we seek to understand this dynamics and extract logical structures ( in the form of decision trees ) that predict the global behavioral state of the session : high / low rate of learning .",
    "we call the sugraphs and their corresponding decision trees _ learning rate biomarkers _ ( or just _ biomarkers _ ) .    _",
    "definition : _ a _ biomarker _ is a statistically significant connected subgraph of functional edges whose state ( high _ vs. _ low coherence ) can collectively _",
    "differentiate _ between high and low learning rate of subjects .",
    "the potential of a biomarker to differentiate between functional networks corresponding to low or high learning rate sessions is called _ discriminative power _ ( and the biomarker is called _ discriminative _ ) .",
    "we employ a discriminative biomarker mining approach to analyze functional networks constructed from fmri scans of 18 subjects performing a motor learning task over 3 learning sessions that occurred on 3 different days ( see methods and data for details ) .",
    "the sessions were divided into low and high learning rate sessions based on the average reduction in movement time for completing the motor task .",
    "the goal of our analysis was to identify biomarkers ( subgraphs ) that were _ discriminative _ of the session type ( high _ vs. _ low rate learners ) and _ minimal _ , while at the same time statistically significant .",
    "minimal , in the context of biomarkers , refers to the requirement that no subgraph of a biomarker can enable a similar accuracy in discriminating low from high learning rate sessions .    in figure",
    "[ fig : example ] , we show two example biomarkers and their corresponding _ decision trees_. both biomarkers involve @xmath3 brain regions interconnected by @xmath1 functional edges ( fig .  [ fig : biomarker1 ] , [ fig : biomarker2 ] ) . a decision tree in our context is a classification model that separates high from low learning rates within training sessions performed by subjects , based on the state of their observed functional edges ( high or low coherence ) .",
    "the decision trees corresponding to our example biomarkers ( fig .",
    "[ fig : dectree1 ] , [ fig : dectree2 ] ) both provide perfect ( @xmath4 ) accuracy in predicting the learning rate . a path from the root to a leaf of the tree corresponds to a logical conjunctive decision rule involving the states ( high / low coherence ) of functional edges that implies a high / low learning rate in task performance .    the decision tree corresponding to the second biomarker example  fig .",
    "[ fig : biomarker2 ] is depicted in fig .",
    "[ fig : dectree2 ] .",
    "one possible decision rule from this tree predicts a high learning rate based on ( 1 ) a high - coherence state of the edge between the left lingual gyrus ( region 36 ) and the right occipital fusiform gyrus ( region 88 ) , ( 2 ) a low - coherence state of the edge between the left lateral inferior occipital cortex ( region 23 ) and the left lingual gyrus ( region 36 ) , ( 3 ) a low - coherence state of the edge between the right occipital fusiform gyrus ( region 88 ) and the right occipital pole ( region 96 ) , and ( 4 ) a high - coherence state of the edge between right lingual gyrus ( region 84 ) and the right occipital pole ( region 96 ) .",
    "our analysis based on discriminative biomarkers involves the following components :    1 .",
    "we establish the _ significance of mined biomarkers_. to this end , we perform non - parametric permutation tests that reassign learning rates and edge states uniformly at random within session - specific networks . we compute the associated @xmath5-value of the number of true discovered biomarkers based on the distribution of number of discriminative small subgraphs in randomly permuted data .",
    "we report significant brain areas and functional edges between them that occur frequently in mined biomarkers .",
    "we visualize and discuss discovered biomarkers in the context of motor learning theory .",
    "biomarkers are significant subgraphs that can accurately discriminate between high and low learning rates of subjects .",
    "the space of potential biomarkers encompasses the set of all possible connected subgraphs of the functional brain network , which is exponential in the number of brain areas .",
    "hence , the fair consideration of all subgraphs is computationally intractable even at the spatial resolution of 112 cortical and subcortical regions .",
    "instead , we develop and employ a sampling approach called _ minds - prune _ that extends a recent network - constrained decision tree inference approach called minds  @xcite . the general idea behind minds - prune",
    "is to use a markov chain monte carlo ( mcmc ) sampling to efficiently extract predictive subgraphs . employing a sampling technique",
    "has several implications : ( i ) it allows us to explore multiple biomarkers of high predictive power ( ii ) in a non - deterministic fashion and ( iii ) in a computationally efficient manner . due to the non - deterministic nature of the approach ,",
    "its output varies across executions and hence we perform multiple runs initiated by different starting subgraphs . in addition , we need to establish the statistical significance of subgraphs in comparison to an appropriate non - parametric null model . to this end ,",
    "we perform two permutation - based tests in which either the state of a functional edge ( high or low coherence ) or the learning state ( high or low rate ) is permuted uniformly at random .",
    "we refer to these two tests as edge permutation and learning rate permutation , respectively .",
    "we compute the number of small ( varying the maximum size between 4 and 14 edges ) and discriminative ( predictive accuracy exceeding 90% ) subgraphs and test the probability of observing the same or higher number of such subgraphs under our edge permutation ( ep ) and learning rate permutation ( lp ) null models ( right @xmath5-values ) .",
    "the input to our analysis is a set of @xmath6 coherence functional networks acquired from @xmath7 subjects over @xmath8 experimental sessions . in these networks",
    ", nodes correspond to cortical and subcortical regions and edges quantify the level of coherence for a pair of regions .",
    "the global state ( label ) of each network corresponds to either high or low learning rate .",
    "note , that we disregard sessions preceded by high learning rate sessions for the same subject , since we expect that once the motor task sequence is learned ( a high - learning rate session has been observed ) subsequent sessions are not informative ( see methods and data section for details ) .",
    "we sample subgraphs common to all networks using minds - prune .",
    "minds - prune is an instance of metropolis hastings mcmc sampling .",
    "it proceeds by drawing a sequence of samples by proposing local moves from a given point in the state space . in the case of subgraphs ,",
    "the current state is an instance of a subgraph and a local move involves addition or removal of a single node without violating the subgraph connectivity .",
    "a move may be rejected or accepted ( depending on the change in classification accuracy ) , and in the case of the latter , the new state ( subgraph ) is added to the set of samples . to initiate the sampling ,",
    "we pick uniformly at random a node and 10 neighbors of this node also chosen uniformly at random ; possible neighbors are identified using a breadth - first - search algorithm .",
    "we use an initial `` burn - in '' period of @xmath9 moves during which samples are discarded ( not added to the sample set ) , a common practice in mcmc - style algorithms to reduce the dependence on the initial state . we than draw @xmath10 sample subgraphs and apply a post - processing phase that retains only high - accuracy and minimal subgraphs .",
    "we analyze and discuss the selection of the above parameters at the end of our methods section .",
    "to adequately `` comb '' the search space , we perform @xmath11 independent runs of minds - prune , using the same parameter settings but different starting state subgraphs to initiate the process . using the state of subgraph edges ( high or low coherence ) as features , we measure the predictive power of each subgraph based on its accuracy in classifying a session as high versus low learning rate . in this search , we retain subgraphs whose accuracy exceeds @xmath12 ,",
    "i.e. a subgraph is retained only if its corresponding decision tree classifies accurately at least @xmath12 of the sessions .",
    "since we are working with a total of @xmath6 sessions , we effectively retain all subgraphs whose decision trees do not mis - classify more than two sessions .",
    "we allow for a few mis - classified examples so as to reduce the possibility of overfitting to the training set .",
    "we also test the generalization ( lack of overfitting ) of our approach using cross validation in sec .",
    "[ sec : mining ] .    to evaluate the significance of the obtained decision trees ,",
    "we perform two types of non - parametric permutation tests : ( i ) a permutation of learning rate labels ( high versus low learning rate ) and ( ii ) a permutation of edge states ( high versus low coherence ) . for both tests",
    ", we measure the probability of obtaining similar - size trees of high accuracy . for the learning rate permutation test ( lp )",
    ", we shuffle the high versus low learning rate labels , while keeping their fractions in the training set of sessions unchanged . for the edge state permutation test ( ep )",
    ", we shuffle the high versus low edge coherence labels , while keeping their fraction constant in each session - specific functional network .",
    "we perform @xmath13 permutations of each test .",
    "then , we perform ( similar to the protocol for the observed data ) @xmath11 runs of minds - prune for each permuted instance and retain subgraphs whose accuracy exceeds @xmath12 . we expect that neurophysiologically relevant subgraphs will provide high accuracy with only a few edges , whereas subgraphs obtained from permuted data will provide comparable or lower accuracy with many edges .",
    "hence , we compute the right - tailed @xmath5-value of the average number of unique subgraphs of size at most @xmath14 edges , using the obtained subgraph sizes in permuted networks to derive a background distribution .    in table  [ tab : pvalue ] , we show the number of unique high - accuracy subgraphs and the corresponding @xmath5-values of observing as many high - accuracy subgraphs in the two different permutation background distributions .",
    "while the mcmc process may traverse the same subgraph more than once , we disregard such multiplicity information and measure the significance of the number of unique accurate trees .",
    "multiple samples of the same subgraph do not necessarily give evidence for its quality as the mcmc process may spend more time near a local optimum .",
    "in addition , the significance of the number of unique accurate trees has a more intuitive interpretation as opposed to counting repeated occurrences .    as evident in table  [ tab : pvalue ] , on average",
    "we observe few accurate subgraphs of size @xmath3 or smaller , and their observation is not significant in the context of random learning rate permutation lp ( @xmath15 ) .",
    "larger accurate subgraphs ( sizes 8 - 14 edges ) are more numerous , and their occurrence is significant based on both the lp and ep background distribution tests ( unadjusted @xmath16 for both random tests and @xmath17 for size 11 ) .",
    "larger accurate subgraphs ( size 16 and higher ) become insignificant according to both randomization tests .",
    "the above analysis , suggests that a coherence level of up to @xmath2 functional edges among cortical regions ( out of approximately @xmath18 at the spatial resolution of 112 regions ) are sufficient to differentiate between high and low learning rate sessions .",
    "next , we discuss the edges and areas that consistently occur in the discriminative biomarkers .      after mining discriminative biomarkers , we ask whether specific brain areas or functional edges are consistently identified as discriminative . for this analysis , we focus on accurate biomarkers of at most @xmath2 edges .",
    "this cut - off size results in a significant number of accurate subgraphs discovered ( p - value @xmath19 ) as compared to other cut - off sizes ( table  [ tab : pvalue ] ) .",
    "simultaneously , the subgraphs are relatively small , involving less than @xmath20 of all 112 brain areas ) .",
    "changing the maximal size of the subgraph while maintaining statistical significance ( e.g. sizes 8 - 14 edges ) does not have a qualitative effect on the set of regions or the set of edges that are frequently identified .",
    "we demonstrate this stability at the end of this section .",
    "we compare the observed frequencies of occurrence of regions and functional edges in biomarkers to their corresponding frequency distributions under the random edge permutation model ( ep discussed in the previous section ) .",
    "we quantify the statistical significance of the observed frequencies by calculating their associated @xmath5-values . since , we compare the real and permuted data in terms of multiple region frequencies , we need to correct for multiple comparisons .",
    "we control for the false discovery rate ( fdr ) at a level of @xmath21 according to the benjamini - hochberg step - up procedure  @xcite . according to the latter ,",
    "the hypotheses ( biomarker regions in our case ) are sorted by their @xmath5-values in ascending order .",
    "regions corresponding to indices up to @xmath14 are declared significant , where @xmath14 is the maximal index such that @xmath22 , @xmath23 is the corresponding @xmath5-value , @xmath24 is the total number of regions ( 112 ) , and @xmath25 is the fdr level set to @xmath21 .    [",
    "fig : significant_regions ]     the most frequent significant regions ( depicted in figure  2 ) in biomarkers are located in the motor and visual cortices , and include the _ occipital fusiform gyrus , left supplemental motor area , left lingual gyrus , left occipital pole , right postcentral gyrus _ and _ left precentral gyrus_. most of these regions play an essential role in visually - guided movement .",
    "for example , the fusiform gyrus contains higher - order visual association areas that control spatial vision and attention processes  @xcite .",
    "the involvement of these regions is parsimonious with the functional requirements of the particular learning task used in this experiment .",
    "subjects were required to play out twelve key presses as indicated on a 4-staff notation system .",
    "this requires subjects to learn to both read a novel visual notation and to remember particular visual patterns that indicate the sequential key presses .",
    "apart from vision , the regional results are noteworthy for the involvement of precentral gyrus ( motor cortex ) and supplementary motor area along with the associated somatosensory cortex .",
    "the primary and supplementary motor cortex are known to be involved in the sequential control of movement and often show changes over time with sequence learning  @xcite .",
    "together , these results make a clear case that fast learners are better able to leverage visiomotor areas to generate perceptual as well as movement related representations of the sequences .",
    "more generally , it suggests that , not surprisingly , successful learning involves the recruitment of appropriate brain systems to represent information that is relevant for sculpting behavior .",
    "note that our method discovers these areas in an unsupervised manner ( in terms of known area functions ) , using only information from fmri and measurements of learning rates in the sensorimotor task .",
    "the alignment of discriminative regions to areas known to be involved in motor learning supports the utility of our approach and its potential applicability in other cognitive domains .    ) , significant functional edges interconnect motor and visual cortex regions.,scaledwidth=90.0% ]    beyond individual cortical or subcortical regions , we also consider _ edges _ that occur more frequently in biomarkers than expected in the random edge permutation null model .",
    "we similarly correct for fdr at a level of @xmath21 . in this case , the number of hypotheses involved in the benjamini - hochberg correction procedure is the number of all possible functional edges : @xmath26 . in figure",
    "[ fig : edges ] , we show the significant most frequent edges .",
    "consistent with the regional findings , these edges tend to connect areas of the motor and visual systems .",
    "the frequently occurring connections between the frontal pole and supplemental motor area are intriguing . given the role of the frontal cortex in executive control , sustained attention to a task and the organization of sequential behavior , we can speculate that these different functional roles are interacting with the actual control of movement in this task .",
    "it is possible that an ability to enhance executive control during the task might facilitate the sustained recruitment of motor areas , keeping the subjects `` on - task '' .",
    "this in turn would enhance the rate of learning .",
    "similarly the numerous connections involving the occipital fusiform gyrus and the visual cortex is another interesting pattern .",
    "the most frequent connection involved in biomarkers relates the lingual gyrus and occipital fusiform gyrus which are both involved in visual processing and their functional interaction is probably needed to encode the visual cues that define a sequence . recognizing a particular visual sequence",
    "can greatly enhance the ability to plan and execute a corresponding motor sequence .",
    "this is an obvious reason why the recruitment of these functional edges could accelerate learning .",
    "[ fig : stability ]    to test the sensitivity of the frequent regions and edges to the setting of the maximal subgraph size , we vary the maximal subgraph size and compute the similarity of the top region / edge sets to the same when considering one - edge smaller or larger maximal sizes ( figs .  [",
    "fig : nodes_stability],[fig : edges_stability ] ) .",
    "as long as subgraphs of 10 edges are considered , the sets of top regions and edges stabilize ( jaccard similarity close to 1 ) .",
    "sizes higher than 14 become less significant ( see tab .  [",
    "tab : pvalue ] . )",
    "the data for our analysis was collected during a motor learning task experiment in which subjects neural activity was measured using fmri  @xcite . the data was originally used to analyze the brain s functional flexibility during learning . here ,",
    "we follow the same protocol for data preparation , but focus on subgraph biomarkers associated with learning .",
    "next , we shortly summarize the performed learning task experiment and data preparation .",
    "for more details , we refer the reader to the original paper introducing the experiment and analyses by bassett and colleagues  @xcite .",
    "the study involved 18 paid participants without formal training in playing a musical instrument , with normal vision , and without neurological or psychiatric disorders . in the motor learning task , subjects responded to a visually cued sequence by generating responses using the four fingers of their non - dominant hand on a custom - built response box .",
    "visual cues were presented as a series of dots on lines , like musical notes , on a pseudo - musical staff with each line corresponding to one of the buttons on the response box to be pressed .",
    "the number and order of sequence trials was identical for all participants .",
    "all participants completed three training sessions in a five - day period , and each session was performed inside the mri scanner ( 3.0 t siemens trio with a 12-channel phased - array head coil ) .",
    "we used the harvard - oxford atlas ( included the fsl tool  @xcite ) that partitions the brain into 112 cortical and subcortical structures for aligning the fmri images . a regional activation level time series",
    "was estimated based on averaging voxel intensities ( details of imaging acquisition and normalization are available in  @xcite ) .",
    "coherence for all pairs of regional time series was then computed and subjected to statistical testing , preserving only values that passed a false discovery rate correction for multiple comparisons .",
    "figure  [ fig : overview ] provides an overview of our approach that transforms the input fmri and learning rate data associated with sessions into a global - state network classification instance .",
    "we then extend the technique by ranu and colleagues  @xcite in order to sample discriminative and minimally connected subgraphs that predict the learning state in a session . in the remainder of this section",
    "we discuss the specifics of each of these steps .",
    "a _ global - state network _ is a graph with local labels on nodes and a global network state indicating the occurrence of an event ( or the network type )  @xcite .",
    "the goal in global state network classification and feature selection is to find small connected subgraphs involving the most discriminative nodes , whose labels predict the global state of network instances in a dataset . in our case , each training session completed by a subject corresponds to a _ functional network _ that links brain regions based on coherence between regional time series .",
    "session - specific network states correspond to high or low rate learning .",
    "edge state labels indicate high or low coherence of the region time series .    in order to transform the data from the motor learning experiment discussed in the previous section to an instance of global network state classification , we ( i )",
    "convert the functional networks derived from training sessions into their edge - dual equivalents and then ( ii ) quantize both the local edge coherence values and global learning rate measurements into binary labels",
    ".        * edge - dual functional network .",
    "* we are interested in using the level of coherence of functional edges as features to inform the identification of discriminative biomarkers . however , the existing methods in global network state classification including minds  @xcite work with node labels as opposed to edge labels . to convert our problem into this common framework , we transform the original functional network into its edge dual graph .",
    "original functional edges become vertices in the edge - dual graph .",
    "two vertices have a link between them if their corresponding edges in the original network share a common end node ( region in the brain ) . to avoid confusion , we will use edges and nodes when discussing the original functional graph among brain regions ( 112 nodes and 6216 edges ) ; vertices and links to refer to the edge - dual graph s elements ( 6216 vertices and 344988 links ) .",
    "the transformation is demonstrated in figure  [ fig : transformation ] for a small example network of 4 nodes and 6 edges that gets transformed into its edge - dual .",
    "if we start with a complete graph @xmath27 of @xmath28 nodes and @xmath29 edges , the corresponding edge - dual graph @xmath30 will have @xmath31 vertices and @xmath32 links . in our example graph , ( fig .  [ fig : transformation ] ) we have 4 nodes and 6 edges and in the corresponding edge - dual graph we obtain 6 vertices and 12 links . in this transformation ,",
    "originally adjacent edges become nodes in the dual graph that are also connected by a link .",
    "note , that this transformation ensures that a subgraph of connected vertices in the dual graph corresponds to a connected subgraph of edges in the original functional network .",
    "next , we discuss how we binarize global networks states ( learning rates ) and local vertex states ( coherence level ) .",
    "* thresholding coherence values .",
    "* we threshold the vertex values in the edge - dual graph to obtain a binary feature corresponding to a vertex being in a high or low coherence state ( note that the vertices correspond to the original functional edges ) .",
    "we choose a coherence value of @xmath33 as the threshold between the low and high coherence states .",
    "effectively , @xmath34 of all nodes in functional networks are labeled as being in a high coherence state . to establish this threshold value , we experimented with lower and higher alternatives and examined the corresponding mined subgraphs .",
    "the latter were either insignificant under the learning state permutation ( lp ) test ( for lower thresholds ) , or the classification accuracy of the obtained subgraphs decreased ( for higher thresholds ) since almost all nodes are reduced to having the same label of low coherence state .",
    "our choice of threshold therefore represents an optimal trade - off between classification accuracy and significance under the learning state permutation test .     and",
    "@xmath35 , the distribution of accurate subgraphs sizes has a relatively smaller variance and subgraphs are smaller on average than for threshold values @xmath33 and @xmath36 , the observed subgraphs are not significant ( see table  [ tab : pvalue_coherence ] ) . a threshold of @xmath33 results in significant number of accurate subgraphs based on both permutation tests .",
    ", scaledwidth=50.0% ]    figure  [ fig : size_threshold ] shows the distribution of obtained accurate subgraph sizes at different thresholds . as can be seen , thresholds @xmath37 and @xmath35 result in relatively small subgraphs on average",
    ". however , the number of mined subgraphs are not significant under the lp or ep permutation tests .",
    "table  [ tab : pvalue_coherence ] summarizes the significance and number of small ( at most 10-edge ) discriminative subgraphs . at a threshold of @xmath38 ( not shown in the figure and table ) ,",
    "about half of the functional edges are deemed to be in the high coherence state , which is physiologically unlikely .",
    "hence , we consider settings of the threshold exceeding @xmath37 that result in small ( @xmath39 ) percentage of all possible edges being in high coherence state .",
    "the lack of significance at lower thresholds ( at approximately @xmath37 ) is due to the fact that each dual graph contains on average @xmath40 of its vertices in the high coherence state ; permutation of vertex labels with this ratio creates very similar size distributions . at a threshold of @xmath33",
    ", we get only about @xmath8 percent of the edges in high coherence state and @xmath5-values for both permutation tests are below @xmath41 .",
    "the percentage of high coherence edges drops to about @xmath42 at the threshold of approximately @xmath35 , which makes the prediction of learning rate difficult ; a small or nonexistent number of accurate subgraphs exist at higher thresholds because vertex coherence values are no longer discriminative .",
    "* global learning rate states . *",
    "the network state mining methodology we adopt works with categorical labels of the global states , i.e. it is formalized as an instance of classification as opposed to one of regression .",
    "while estimating continuous global scores ( regression ) might be of interest as well , here we focus on identifying biomarkers that differentiate between sessions in which subjects progressively increase the speed of completion of the visual cues ( high learning rate sessions ) from those in which no acceleration is observed ( low learning rate sessions ) .",
    "we adopt the exponential rate of decrease of the movement time as a measure of the learning rate .",
    "movement time is the time between the first and last button press of the 12-note sequence .",
    "a larger exponential drop - off in movement time indicates that the subject is learning well , while a smaller exponential drop - off in movement time indicates that the subject is not learning as well .",
    "the exponential drop - off parameters for the 18 subjects are listed in table  [ tab : sessions ] .",
    "the coloring of scores in the table are based on a threshold of @xmath43 ( which we discuss in more detail in the next paragraph ) used to convert the continuous drop - off values into the categorical low versus high learning rate states .",
    "slopes smaller than the chosen threshold correspond to high learning rate ( blue ) and slopes larger than the threshold correspond to low learning rate ( yellow ) . in the first session , 13 of the subjects are `` learning '' the motor task as their rates are below the threshold , while 5 of the subjects are not learning .",
    "because we are only interested in early learning , the 13 subjects that were labeled as being in a high learning state in the first session were discarded from the second and third session data sets . in the third session , 1 subject transitions from a low to a high learning rate state while the remaining 4 low learning rate subjects remain in the low learning rate state .",
    "exponential drop - off parameters could not be fit to subject 16 in session 2 and subject 1 in session 3 due to flat or negative learning rates ; these sessions were therefore excluded .",
    "note that our estimate of learning rate is independent of how fast the the subject is at the beginning of the session , a feature which is driven by biomechanics rather than ability to learn .",
    "[ tab : sessions ]    .exponential drop - off parameters ( rate of decrease ) of movement time for each subject and experimental session .",
    "high - learning rate sessions are colored blue and low learning rate ones yellow .",
    "all but five subjects exhibit a high learning rate in the first session .",
    "one of those five subjects transitions into a high learning rate in their third session .",
    "exponential drop - off of the movement time for two of the sessions ( subject 1 session 3 and subject 16 session 2 ) could not be fitted ( colored gray ) . [",
    "cols=\"^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^,^\",options=\"header \" , ]     [ fig : learning_rate_stability ]    we selected a threshold of @xmath43 to delineate high versus low learning rate states . to choose this threshold , we use a clustering approach with perturbations and estimate the optimal threshold between states based on the stability of multiple clustering solutions . to begin , we randomly perturbed the measured drop - off parameters from all valid sessions by adding gaussian noise with a magnitude of 3 standard deviations of the original learning rates to each parameter value .",
    "we create 100 perturbed instances of the measured exponential drop - off parameters and clustered them using k - means clustering ( k=2 ) .",
    "we compare the different clusterings using the jaccard index as a similarity measure .",
    "a clustering is considered `` stable '' if it is approximately maintained across multiple perturbations .",
    "the vast majority of clustering pairs have a jaccard index of 1 ( perfect similarity ) and @xmath43 is the middle point separating the points in the obtained clusterings .",
    "we show the distribution of the original learning rate values in fig .",
    "[ fig : learning_rate ] and the distribution of the middle point between two perturbed clusters in fig .",
    "[ fig : learning_rate_dist ] . both figures single out @xmath43 as an optimal threshold .    using the selected threshold and discarding sessions preceded by high learning rate sessions of the same subject ,",
    "we obtain 14 high learning rate session - specific networks and 13 low learning rate ones ( color - coded with blue and yellow respectively in tab .",
    "[ tab : sessions ] ) .",
    "we apply our discriminative biomarker approach considering all 27 networks simultaneously together with their global learning state labels .",
    "our discriminative subgraph discovery approach ",
    "minds - prune  is an extension of a recent method by ranu and colleagues  @xcite in which they proposed a method for network - constrained mining of decision trees for global state network label classification . in this setting ,",
    "the available features for a classification problem reside on nodes in a network and the method discovers decision trees , restricted to features that form a connected subgraph in the network ( network - constrained decision trees ) . the method s constraints could be viewed as a way to regularize the learned classifier using the inherent structure among features .",
    "the approach adopts a greedy algorithm to surpass the computational challenge of building optimal network - constrained decision trees ( ncdts ) .",
    "another computational challenge is the exponential subgraph search space . to address this challenge",
    ", minds performs markov chain monte carlo sampling over the space of the possible subgraphs of features .",
    "the transition probabilities are based on improvement of the predictive ability of the currently selected subtree ( for details refer to  @xcite ) .",
    "minds structures the subgraph search space into an edge - weighted meta - graph where each node is a distinct subgraph , each edge is an edit ( either insertion / deletion of a node to / from the subgraph ) and each edge weight is the quantified impact of the edits to the accuracy . by performing a series of edits , a subgraph of the network can be transformed into any other subgraph of the network .",
    "the authors apply the method to gene - expression networks in order to find genes , whose level predicts disease states .    in our setting , we have a shared connectivity structure in the form of edge - dual graphs across networks , and vertices ( features ) have binary states corresponding to high and low coherence states ( associated with the corresponding edges in the original graph ) .",
    "the network instance label is one of high versus low learning rate . to find biomarkers that are small and accurate , we extend minds by a post - processing pruning phase .",
    "first , we execute minds and then we further compact the obtained decision trees by greedily excluding edges while maintaining connectivity and the accuracy of the originally sampled subgraph .",
    "this process is applied to every tree independently and only the smallest accurate trees are maintained .",
    "we term this extended method minds - prune .    * testing the generalization properties of minds - prune . *",
    "the biomarkers we report in the previous sections were obtained by applying minds - prune to the full set of 27 networks .",
    "biomarkers of training accuracy exceeding @xmath44 were kept . while these are the best biomarkers that make use of all of the training data , here we test the generalization properties of our technique using classification cross - validation .",
    "cross validation is a common way of testing if a classifier overfits to the presented training data . as part of the cross - validation test",
    ", the training instances are partitioned in @xmath14 folds ( subsets ) .",
    "a classifier is build based on @xmath45 of the folds ( training ) and its accuracy is then tested on the left - out fold ( testing ) . the same procedure is repeated using each of the @xmath14 folds as testing . naturally , the average accuracy in cross - validation is lower than the training accuracy when using all the annotated data .",
    "however , this test is useful to compare a classifier to baselines and to results of a random classification .    to test minds - prune s generalization properties ,",
    "we perform a 9-fold cross validation .",
    "a common setting for the number of folds is 10 , however , we chose to perform 9-fold validation as our number of instances is small and 9 is a multiple of the total instances ( 27 session - specific global state networks ) .",
    "we compute the subgraphs and their corresponding decision trees by leaving one of the folds ( 3 instances ) out and using the other 8 folds ( 24 instances ) as training .",
    "we then test the accuracy of the obtained biomarker decision trees based on training on the left out testing instance .    for a relative baseline , we compare the testing accuracy of minds - prune with that of an svm classifier that works with the same instances , but is oblivious to the network structure .",
    "all @xmath26 features are given to the svm while performing cross validation .",
    "both svm and minds - prune methods have the same testing accuracy of @xmath46 on average .",
    "importantly , our method minds - prune performs as well as svm while using only a small subset of the features ( i.e. , those included in the discriminative subgraphs ) , while svm uses all features .",
    "minds - prune manages to select the most discriminative features among all features while taking into account the connected structure of features as well .",
    "moreover , it also provides relevant domain insights : the subgraphs identified correspond to connected functional edges relating to regions in the motor and visual systems known to be important in motor learning .",
    "one question of interests is whether the vertices ( corresponding to functional edges ) included in high - accuracy subgraphs agree across folds . to measure this ,",
    "we focus our attention on subgraphs that in testing ( i.e. when classifying the left - out fold ) classify at least 2 out of the 3 testing instances correctly ( i.e. @xmath47 testing accuracy ) .",
    "note that lower accuracy options ( one or zero out of three correct predictions ) would correspond to worse than random classification performance , which for two balanced classes is @xmath48 .",
    "we compare the similarity of obtained accurate - in - testing subgraphs in the 9 folds to analyze their consistency . for this comparison , we compute pairwise subgraph similarities in each pair of folds .",
    "subgraph similarity is defined as the fraction of overlapping nodes between any two subgraphs .",
    "we compute the pairwise subgraph similarity distribution of each fold pair ( 36 pairs from 9 folds ) , and use the kuiper statistic to quantify the agreement of these distributions",
    ". the kuiper statistic will be 0 if the distributions are the same and 1 if the distributions are distinct .",
    "a plot of the kuiper statistic distribution is presented in figure  [ fig : kuiper_folds ] .",
    "the mean of the kuiper statistic is close to 0 which indicates a significant similarity of subgraphs generated in each fold .",
    "moreover , different folds share common cortical regions . table  [ tab : top3nodes ] presents the top 3 frequently identified functional edges ( vertices in the edge - dual graph ) from each fold . while there is some variation across folds , due to the relatively small number of training instances and large feature space",
    ", some identified areas agree across folds .",
    "for example , the occipital fusiform gyrus is frequent in 7 out of the 9 folds and the occipital pole in 5 out of the 9 folds .",
    "while the frequent regions within subgraphs when using all instances for training ( reported in section 2 ) are all identified as frequent in some of the folds , we do not expect a perfect agreement since in cross validation our method works with fewer training instances .",
    "the important consequence of the cross - validation results is that our method retains testing accuracy measurable with that of state - of - the - art complex classifiers such as svm and higher than the accuracy expected at random .",
    "our method has the advantage of incorporating connectivity among the features that in turn enables interpretation of the discovered biomarkers .",
    "our subgraph mining approach minds - prune has several parameters that might affect the quality of obtained results .",
    "next , we test and discuss the sensitivity to some of those parameters and our approach to selecting them .",
    "as discussed earlier we perform sampling runs starting from seed subgraphs of size 10-edges and retain only those that result in good classification accuracy . here",
    "we vary this initial seed size , starting from a 20-edge seed subgraph and perform separate independent sampling runs with random subgraphs of size 15-edge , 10-edge , and 5-edge .",
    "we measure the stability of the most frequent regions and edges obtained from the runs based on different seed sizes .",
    "the top region and edge lists for decreasing subgraph seeds are compared to all other seed sizes using jaccard similarity and the average similarity ( to different sizes and over multiple instantiations of the original 20-edge seed ) is presented in figure  [ fig : seed_size_stability ] . both top regions and edges are stable when starting with seed subgraphs of different sizes .",
    "the list of most frequently occurring edges / regions have average similarity of close to 1 ( unchanged ) , while extending the list to the top 10 , 20 and 30 slightly decreases this average similarity , retaining similarity values of higher than @xmath36 .",
    "[ fig : seed_size_stability ]    in our mcmc sampling , we use a `` burn - in '' period of @xmath9 moves during which samples are discarded ( not added to the sample set ) .",
    "while this is a common practice to reduce the dependence on the initial state , there exists no rigorous theoretical proof of advantages / disadvantages of burn - in period in mcmc sampling .",
    "instead this issue is typically left as a choice for the practitioner .",
    "our experiments have shown that top regions and edges tend to be more stable if burn - in is used . at the same time larger burn - in",
    "has computational costs and as a result we set our burn - in to half of the actual sampling iterations .",
    "we draw @xmath10 actual sample subgraphs and apply a post - processing phase that retains only high - accuracy and minimal subgraphs . while a larger number of sample subgraphs results in denser sampling , the set of those that survive the post - processing accuracy filtering stabilizes at about @xmath10 samples .",
    "similarly , the set of the top most frequent regions and the set of the top most frequent edges also stabilizes at about @xmath10 samples .",
    "we developed a general approach for discovery of brain activity biomarkers from fmri data and applied it to data from sensorimotor task learning . using data from an fmri study coupled with performance ( rate of learning within a session ) , we demonstrate the existence of subgraphs whose edge states are discriminative and",
    "thus can predict the rate of learning within the task .",
    "analysis of the cortical regions and functional edges involved in the most predictive subnetworks demonstrate that the regions we obtain are both statistically significant and domain - relevant . while we focus on data from a learning experiment , our framework",
    "can also be applied to other cognitive tasks , and can further be used to identify biomarkers specific to neurological and psychiatric disease",
    ".    10    d.  s. bassett and e.  bullmore .",
    "small - world brain networks . , 12(6):512523 , 2006 .",
    "d.  s. bassett , n.  f. wymbs , m.  a. porter , p.  j. mucha , j.  m. carlson , and s.  t. grafton .",
    "dynamic reconfiguration of human brain networks during learning . , 2011 .",
    "d.  s. bassett , n.  f. wymbs , m.  a. porter , p.  j. mucha , and s.  t. grafton .",
    "cross - linked structure of network evolution .",
    ", 24(1):013112 , 2014 .",
    "y.  benjamini and y.  hochberg . controlling the false discovery rate : a practical and powerful approach to multiple testing .",
    ", pages 289300 , 1995 .",
    "a.  bischoff - grethe , k.  m. goedert , d.  t. willingham , and s.  t. grafton .",
    "neural substrates of response - based sequence learning using fmri . , 16(1):127138 , 2004 .",
    "m.  m. chun , j.  d. golomb , and n.  b. turk - browne .",
    "a taxonomy of external and internal attention . , 62:73101 , 2011 .",
    "c.  echtermeyer , l.  da  fontoura  costa , f.  a. rodrigues , and m.  kaiser",
    ". automatic network fingerprinting through single - node motifs .",
    ", 6(1):e15765 , 2011 .    p.  fries . a mechanism for cognitive dynamics : neuronal communication through neuronal coherence",
    ", 9(10):474  480 , 2005 .",
    "s.  grafton , e.  hazeltine , and r.  ivry .",
    "functional mapping of sequence learning in normal humans .",
    ", 7(4):497510 , 1995 .",
    "m.  d. greicius , k.  supekar , v.  menon , and r.  f. dougherty .",
    "resting - state functional connectivity reflects structural connectivity in the default mode network .",
    ", 19(1):7278 , 2009 .",
    "p.  hagmann , m.  kurant , x.  gigandet , p.  thiran , v.  j. wedeen , r.  meuli , and j .-",
    "mapping human whole - brain structural networks with diffusion mri .",
    ", 2(7):e597 , 07 2007 .",
    "e.  hazeltine , s.  t. grafton , and r.  ivry .",
    "attention and stimulus characteristics determine the locus of motor - sequence encoding . a pet study .",
    ", 120(1):123140 , 1997 .",
    "m.  jenkinson , c.  f. beckmann , t.  e. behrens , m.  w. woolrich , and s.  m. smith .",
    ", 62(2):782790 , 2012 .",
    "n.  kashtan and u.  alon .",
    "spontaneous evolution of modularity and network motifs .",
    ", 102(39):1377313778 , 2005 .",
    "n.  t. markov , m.  ercsey - ravasz , d.  c. van  essen , k.  knoblauch , z.  toroczkai , and h.  kennedy .",
    "cortical high - density counterstream architectures . , 342(6158 ) , 2013 .",
    "w.  orrison . .",
    "thieme publishers series .",
    "thieme , 2008 .",
    "park and k.  friston .",
    "structural and functional brain networks : from connections to cognition . , 342(6158 ) , 2013 .",
    "h.  j. park , m.  kubicki , c .- f .",
    "westin , i.  f. talos , a.  brun , s.  pieper , r.  kikinis , f.  a. jolesz , r.  w. mccarley , and m.  e. shenton .",
    "method for combining information from white matter fiber tracking and gray matter parcellation .",
    ", 25:13181324 , 2004 .",
    "s.  ranu , m.  hoang , and a.  singh . mining discriminative subgraphs from global - state networks . in _ proceedings of the 19th acm sigkdd international conference on knowledge discovery and data mining _ , kdd 13 , pages 509517 , new york , ny , usa , 2013 .",
    "acm .    c.  stam , b.  jones , g.  nolte , m.  breakspear , and p.  scheltens .",
    "small - world networks and functional connectivity in alzheimer s disease . , 17(1):9299 , 2007 .    c.  summerfield , m.  greene , t.  wager , t.  egner , j.  hirsch , and j.  mangels",
    "neocortical connectivity during episodic memory formation .",
    ", 4(5):e128 , 04 2006 .",
    "n.  b. turk - browne .",
    "functional interactions as big data in the human brain . , 342(6158):580584 , 2013 .    n.  f. wymbs , d.  s. bassett , p.  j. mucha , m.  a. porter , and s.  t. grafton .",
    "differential recruitment of the sensorimotor putamen and frontoparietal cortex during motor chunking in humans .",
    ", 74(5):936946 , 2012 .",
    "n.  f. wymbs and s.  t. grafton .",
    "contributions from the left pmd and the sma during sequence retrieval as determined by depth of training . , 224(1):4958 , 2013 .",
    "a.  zalesky , l.  cocchi , a.  fornito , m.  m. murray , and e.  bullmore .",
    "connectivity differences in brain networks .",
    ", 60(2):10551062 , 2012 .",
    "a.  zalesky , a.  fornito , and e.  t. bullmore .",
    "network - based statistic : identifying differences in brain networks . , 53(4):11971207 , 2010 ."
  ],
  "abstract_text": [
    "<S> it has become increasingly popular to study the brain as a network due to the realization that functionality can not be explained exclusively by independent activation of specialized regions . instead , across a large spectrum of behaviors </S>",
    "<S> , function arises due to the dynamic interactions between brain regions . </S>",
    "<S> the existing literature on functional brain networks focuses mainly on a battery of network properties characterizing the `` resting state '' using for example the modularity , clustering , or path length among regions . </S>",
    "<S> in contrast , we seek to uncover subgraphs of functional connectivity that predict or drive individual differences in sensorimotor learning across subjects . </S>",
    "<S> we employ a principled approach for the discovery of significant subgraphs of functional connectivity , induced by brain activity ( measured via fmri imaging ) while subjects perform a motor learning task . </S>",
    "<S> our aim is to uncover patterns of functional connectivity that discriminate between high and low rates of learning among subjects . </S>",
    "<S> the discovery of such significant discriminative subgraphs promises a better data - driven understanding of the dynamic brain processes associated with brain plasticity . </S>"
  ]
}