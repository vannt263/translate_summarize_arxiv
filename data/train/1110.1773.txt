{
  "article_text": [
    "hermitian positive definite ( hpd ) matrices offer a noncommutative generalization to positive reals .",
    "no wonder they abound in a multitude of applications and exhibit striking theoretical properties .",
    "for instance , they form a differentiable riemannian ( and also a finsler ) manifold @xcite that is the most studied example of a manifold of nonpositive curvature ( * ? ? ?",
    "* ch.10 ) .",
    "hpd matrices possess even more structure : ( i ) they form a closed , self - dual convex cone ; and ( ii ) they serve as a canonical higher - rank symmetric space @xcite .",
    "the conic view enjoys great importance in convex optimization @xcite , symmetric spaces are important in algebra and analysis @xcite , and in optimization @xcite , while the manifold view plays diverse roles  see  ( * ? ? ?",
    "* ch.6 ) for an excellent overview .",
    "the manifold view of hpd matrices comes with a `` natural '' distance function while the conic view does not .",
    "nevertheless , drawing motivation from the convex conic view , we introduce the _ s - divergence _ as a `` natural '' distance - like function on the open cone of positive definite matrices .",
    "indeed , we prove a sequence of results connecting the s - divergenceto the riemannian metric . we show that ( a ) this divergence is the square of a metric ; and ( b ) that it has several geometric properties in common with the riemannian metric , without being numerically as burdensome .",
    "let us begin by fixing notation .",
    "the letter @xmath0 denotes some hilbert space , though usually just @xmath1 .",
    "the inner product between two vectors @xmath2 and @xmath3 in @xmath0 is written as @xmath4 ( where @xmath5 denotes ` conjugate transpose ' ) .",
    "the set of @xmath6 hermitian matrices is denoted as @xmath7 .",
    "a matrix @xmath8 is called _ positive definite _ if @xmath9 which we also denote by writing @xmath10 .",
    "the set of all such matrices is denoted by @xmath11 .",
    "we may also speak of _ positive semidefinite _ matrices , for which @xmath12 for all @xmath2 ; denoted by @xmath13 .",
    "the operator inequality @xmath14 is the usual lwner order and means @xmath15 .",
    "the _ frobenius norm _ of a matrix @xmath16 is defined as @xmath17 , and @xmath18 denotes the operator 2-norm .",
    "let @xmath19 be an analytic function on @xmath20 ; for a matrix @xmath21 , where @xmath22 is unitary , @xmath23 equals @xmath24 .",
    "the set @xmath11 forms a highly - studied differentiable riemannian manifold with the distance function  ( see e.g. ,  ( * ? ? ?",
    "* ch .  6 ) ) : @xmath25 where @xmath26 denotes the matrix logarithm . as a counterpart to",
    ", we introduce the key function of this paper : the _ _ symmetric stein divergence _ _",
    "( s - divergence ) , @xmath27    we advocate   as an alternative to  , and also study several of its properties of independent interest .",
    "the simplicity of   is a major reason for using it as an alternative to  : it is cheaper to compute , as is its derivative , and certain basic algorithms involving it run much faster than corresponding ones that use @xmath28 .",
    "this line of thought originates in  @xcite , where for a an _ image search task _ based on nearest neighbors , @xmath29 is used instead of @xmath28 for measuring nearness , and is shown to yield large speedups without hurting the quality of search results .",
    "although exact details of this search application lie outside the scope of this paper , let us highlight below the two core speedups that were crucial to  @xcite .",
    "the first speedup is shown in the left panel of fig .",
    "[ fig.one ] , which compares times taken to compute @xmath29 and @xmath28 . for computing the latter",
    ", we used the ` dist.m ` function in the matrix means toolbox ( mmt ) .",
    "the second , more dramatic speedup in shown in the right panel which shows time taken to compute the matrix means @xmath30 where @xmath31 are hpd matrices . for details on @xmath32 see section  [ sec.mtxmeans ] ; the geometric mean @xmath33 is also known as the `` karcher mean '' , and was computed using the mmt via the ` rich.m ` script which implements a state - of - the - art method  @xcite .     and @xmath29 .",
    "for @xmath28 , we show times for the implementation in the mmt which uses schur factorization .",
    "the results are averaged over 10 runs to reduce variance .",
    "the plot indicates that @xmath29 can be up to 50 times faster than @xmath28 .",
    "times taken to compute @xmath33 and @xmath32 .",
    "the former was computed using the method of  @xcite , while the latter was obtained via a fixed - point iteration .",
    "the differences are huge : @xmath32 can be obtained up to 1000 times faster!,title=\"fig : \" ]   and @xmath29 . for @xmath28 , we show times for the implementation in the mmt which uses schur factorization .",
    "the results are averaged over 10 runs to reduce variance .",
    "the plot indicates that @xmath29 can be up to 50 times faster than @xmath28 .",
    "times taken to compute @xmath33 and @xmath32 .",
    "the former was computed using the method of  @xcite , while the latter was obtained via a fixed - point iteration .",
    "the differences are huge : @xmath32 can be obtained up to 1000 times faster!,title=\"fig : \" ]    we mention here that several other alternatives to @xmath28 are also possible , for instance the popular `` log - euclidean '' distance  @xcite , given by @xmath34 notice that to compute @xmath35 we require two eigenvector decompositions ; this makes it more expensive than @xmath29 which requires only 3 cholesky factorizations .",
    "even though the matrix mean under @xmath36 can be computed in closed form , its dependency on matrix logarithms and exponentials can make it slower than @xmath32 .",
    "more importantly , for the application in  @xcite , @xmath35 and other alternatives to @xmath28 proved to be less competitive than  , so we limit our focus to @xmath29 ; for more extensive empirical comparisons with other distances , we refer the reader to  @xcite .",
    "while our paper was under review , we became aware of a concurrent paper of chebbi and moakher ( cm )  @xcite , who consider a one parameter family of divergences , of which   is a special case .",
    "we summarize below how our work differs from cm :    @xmath37=3em    cm prove @xmath38 to be a metric only for commuting matrices . as per remark",
    "[ rmk.commute ] , the commuting case essentially reduces to the metricity for scalars .",
    "the general noncommuting case is much harder and was left as an open problem in  @xcite .",
    "we solve the general noncommuting case , fully independent of cm .",
    "we establish several theorems connecting @xmath29 to the riemannian metric @xmath28 .",
    "these connections have not been made either by cm or elsewhere .",
    "a question closely related to metricity of @xmath38 is whether the matrix @xmath39_{i , j=1}^m,\\qquad x_1,\\ldots , x_m \\in { { \\mathbb{p}}}_n,\\ ] ] is positive semidefinite for every integer @xmath40 and scalar @xmath41 .",
    "cm consider only special cases of this question .",
    "we provide a complete characterization of @xmath42 necessary and sufficient for the above matrix to be semidefinite .",
    "cm analyze the `` matrix - means '' problem @xmath43 , whose solution they obtain by solving @xmath44 .",
    "they make a simple but crucial oversight by claiming global optimality of this solution , whereas from their arguments only _ stationarity _ follows .",
    "we prove global optimality .",
    "we proceed now to formally introduce the s - divergence .",
    "we follow the viewpoint of bregman divergences .",
    "consider , therefore , a differentiable strictly convex function @xmath45 ; then , @xmath46 , with equality if and only if @xmath47 . the difference between the two sides of this inequality defines the _ _ bregman divergence _ _ ) . ]",
    "@xmath48 the scalar divergence   can be extended to hermitian matrices , as shown below .",
    "[ prop.breg ] let @xmath19 be differentiable and strictly convex on @xmath49 ; let @xmath50 be arbitrary .",
    "then , we have the inequality @xmath51    inequality   defines a _ matrix bregman divergence_see also  @xcite . by construction @xmath52 is nonnegative , strictly convex in @xmath53 , and equals zero if and only if @xmath54 .",
    "it is typically asymmetric , and may be viewed as a measure of `` directed '' dissimilarity .",
    "[ eg.breg ] let @xmath55 .",
    "then , for @xmath56 , @xmath57 , and   reduces to the squared _ frobenius norm _",
    "@xmath58 if @xmath59 on @xmath60 , then @xmath61 , and   yields the ( unnormalized ) _ von neumann divergence _ of quantum information theory  @xcite : @xmath62 for @xmath63 on @xmath60 , @xmath64 , and we obtain the divergence @xmath65 which is known as the _ logdet divergence _  @xcite , or more classically as",
    "_ stein s loss _",
    "@xcite .",
    "the divergence @xmath66 is of key importance to our paper , so we mention some additional noteworthy contexts where it occurs :    information theory  @xcite , as the relative entropy between two multivariate gaussians with same mean ;    optimization , when deriving the famous broyden - fletcher - goldfarb - shanno ( bfgs ) updates  @xcite ;    matrix divergence theory  @xcite ;    kernel and metric learning  @xcite .    despite the broad applicability of bregman divergences ,",
    "their asymmetry is sometimes undesirable .",
    "this drawback prompted researchers to consider symmetric divergences , among which the most popular is the `` _ _ jensen - shannon _ _ '' divergence @xmath67 this divergence has two attractive and perhaps more useful representations : @xmath68    compare   with  ( [ eq.js1 ] ) : both formulas define divergence as departure from linearity ; the former uses derivatives , while the latter is stated using midpoint convexity . as a result ,",
    "representation   has an advantage over  , , and  , because unlike them , it does not need to assume differentiability of @xmath19 .",
    "the reader must have by now realized that the s - divergence   is nothing but the symmetrized divergence   generated by @xmath63 . alternatively , s - divergencemay be essentially viewed as the jensen - shannon divergence between two multivariate gaussians  @xcite or as the bhattacharya distance between them  @xcite .",
    "let us now list a few basic properties of @xmath69 .",
    "[ lem.basic ] let @xmath70 be the vector of eigenvalues of @xmath53 , and @xmath71 be a diagonal matrix with @xmath70 as its diagonal .",
    "let @xmath72 .",
    "then ,    a.   @xmath73 ; b.   @xmath74 , where @xmath75 , @xmath76 ; c.   @xmath77 ; and d.   @xmath78 .",
    "\\(i ) follows from the equality @xmath79 .",
    "+ ( ii ) follows upon observing that @xmath80^{1/2}[\\det(pbq)]^{1/2 } } =      \\frac{\\det(p)\\cdot\\det(a+b ) \\cdot\\det(q ) }      { \\det(p ) \\cdot [ \\det(a)]^{1/2}[\\det(b)]^{1/2}\\cdot\\det(q)}.\\ ] ] ( iii ) follows after writing @xmath81^{1/2}[\\det(b)^{-1}]^{1/2 } } =       \\frac{\\det(a)\\cdot\\det(a^{-1}+b^{-1 } ) \\cdot\\det(b ) }      { [ \\det(a)]^{1/2}[\\det(b)]^{1/2}}.      \\ ] ] ( iv ) follows from @xmath82 , and @xmath83 .    the most useful corollary to lemma .  [ lem.basic ] is congruence invariance of @xmath29 .",
    "[ corr.cong ] let @xmath84 , and let @xmath53 be any invertible matrix .",
    "then , @xmath85    the next result reaffirms that @xmath86 is a divergence ; it also shows that @xmath29 enjoys some limited convexity and concavity .",
    "[ prop.scvx ] let @xmath84 .",
    "then , ( i ) @xmath87 with equality if and only if @xmath88 ; ( ii ) for fixed @xmath89 , @xmath90 is convex in @xmath91 for @xmath92 , while for @xmath93 , it is concave .",
    "since @xmath69 is a sum of bregman divergences , property  ( i ) follows from definition  ( [ eq.js ] ) .",
    "alternatively , ( i ) follows , since @xmath94^{1/2}[\\det(b)]^{1/2}$ ] , with equality if and only if @xmath88 .",
    "part ( ii ) follows upon analyzing the hessian @xmath95 .",
    "this hessian can be identified with the matrix @xmath96 where @xmath97 is the usual the kronecker product .",
    "matrix @xmath98 is positive definite for @xmath92 and negative definite for @xmath99 , proving  ( ii ) .    below",
    "we show that @xmath29 is richer than a divergence : its square - root @xmath100 is actually a metric on @xmath11 .",
    "this is the first main result of our paper .",
    "previous authors  @xcite conjectured this result but could not establish it , perhaps because both ultimately sought to map @xmath100 to a hilbert space metric .",
    "this approach fails because hpd matrices do not form even a ( multiplicative ) semigroup , which renders the powerful theory of harmonic analysis on semigroups  @xcite inapplicable to @xmath100 .",
    "this difficulty necessitates a different path to proving metricity of @xmath100 .",
    "in this section we prove the following main theorem .",
    "[ thm.metric ] define @xmath102 . then , @xmath101 is a metric on @xmath11 .",
    "the proof of theorem  [ thm.metric ] depends on several results , which we first establish .",
    "[ def.cnd ] let @xmath103 be a nonempty set .",
    "a function @xmath104 is said to be _ negative definite _ if for all @xmath105 , @xmath106 , and the inequality @xmath107 holds for all integers @xmath108 , and subsets @xmath109 , @xmath110 with @xmath111 .",
    "[ thm.schoen ] let @xmath104 be negative definite .",
    "then , there is a hilbert space @xmath112 and a mapping @xmath113 from @xmath114 such that one has the relation @xmath115 moreover , negative definiteness of @xmath116 is necessary for such a mapping to exist .",
    "theorem  [ thm.schoen ] helps prove the triangle inequality for the scalar case .",
    "[ lem.cpd ] define , the scalar version of @xmath100 as @xmath117},\\quad x , y > 0.\\ ] ] then , @xmath118 satisfies the triangle inequality , i.e. , @xmath119    we show that @xmath120 is negative definite . since @xmath121 , theorem  [ thm.schoen ] then immediately implies the triangle inequality  . to prove that @xmath116 is negative definite , by  (",
    "* thm .  2.2 , ch .",
    "3 ) we may equivalently show that @xmath122 is a positive definite function for @xmath123 , and @xmath124 . to that end",
    ", it suffices to show that the matrix @xmath125 = \\left[(x_i+x_j)^{-\\beta}\\right],\\quad 1 \\le i , j \\le n,\\ ] ] is hpd for every integer @xmath126 , and positive numbers @xmath127 .",
    "now , observe that @xmath128 where @xmath129 is the gamma function .",
    "thus , with @xmath130 , we see that @xmath131 $ ] equals the gram matrix @xmath132 $ ] , whereby @xmath133 .    using lemma  [ lem.cpd ] obtain the following `` minkowski '' inequality for @xmath118 .",
    "[ corr.mink ] let @xmath134 ; and let @xmath135 .",
    "then , @xmath136    lemma  [ lem.cpd ] implies that for positive scalars @xmath137 , @xmath138 , and @xmath139 , we have @xmath140 exponentiate , sum , and invoke minkowski s inequality to conclude  .",
    "[ thm.diag ] let @xmath141 be diagonal matrices .",
    "then , @xmath142    for diagonal matrices @xmath53 and @xmath143 , it is easy to verify that @xmath144 now invoke corollary  [ corr.mink ] with @xmath145 .",
    "next , we recall an important determinantal inequality for positive matrices .",
    "[ thm.det ] let @xmath84 .",
    "let @xmath146 denote the vector of eigenvalues of @xmath53 sorted in decreasing order ; define @xmath147 likewise .",
    "then , @xmath148    [ cor.eigs ] let @xmath84 .",
    "let @xmath149 denote the diagonal matrix with @xmath146 as its diagonal ; define @xmath150 likewise .",
    "then , @xmath151    scale @xmath91 and @xmath89 by 2 , divide each term in   by @xmath152 , and note that @xmath153 is invariant to permutations of @xmath70 ; take logarithms to conclude .",
    "the final result we need is well - known in linear algebra ( we provide a proof ) .",
    "[ lem.diag2 ] let @xmath10 , and let @xmath89 be hermitian .",
    "there is a matrix @xmath75 for which @xmath154    let @xmath21 , and define @xmath155 .",
    "the the matrix @xmath156 is hermitian ; so let @xmath157 diagonalize it to @xmath158 .",
    "set @xmath159 , to obtain @xmath160 and by construction , it follows that @xmath161 .",
    "accoutered with the above results , we can finally prove theorem  [ thm.metric ] .",
    "( theorem  [ thm.metric ] ) . we need to show that @xmath101 is symmetric , nonnegative , definite , and that is satisfies the triangle inequality .",
    "symmetry is obvious .",
    "nonnegativity and definiteness were shown in prop .",
    "[ prop.scvx ] .",
    "the only hard part is to prove the triangle inequality , a result that has eluded previous attempts @xcite .",
    "let @xmath141 be arbitrary .",
    "from lemma  [ lem.diag2 ] we know that there is a matrix @xmath75 such that @xmath162 and @xmath163 .",
    "since @xmath164 is arbitrary , and congruence preserves positive definiteness , we may write just @xmath165 instead of @xmath166 .",
    "also , since @xmath167 ( see lemma  [ lem.basic ] ) , proving the triangle inequality reduces to showing that @xmath168 consider now the diagonal matrices @xmath169 and @xmath170 .",
    "theorem  [ thm.diag ] asserts @xmath171 lemma  [ lem.basic](i ) implies that @xmath172 and @xmath173 , while corollary  [ cor.eigs ] shows that @xmath174 .",
    "combining these inequalities , we obtain  .    after discussing metric properties of @xmath101",
    ", we turn our attention to a connection of direct importance to machine learning and related areas : kernel functions arising from @xmath101 .",
    "indeed , some of connections ( e.g. , thm .  [ thm.wallach ] ) have already been successfully applied very recently in computer vision  @xcite .",
    "since @xmath101 is a metric , and lemma  [ lem.cpd ] shows that for scalars , @xmath101 embeds isometrically into a hilbert space , one may ask if @xmath175 also admits such an embedding .",
    "but as mentioned previously , it is the lack of such an embedding that necessitated a different proof of metricity .",
    "let us look more carefully at what goes wrong , and what kind of hilbert space embeddability does @xmath176 admit .",
    "theorem  [ thm.schoen ] implies that a hilbert space embedding exists if and only if @xmath177 is a negative definite kernel ; equivalently , if and only if the map ( _ cf .",
    "_ lemma  [ lem.cpd ] ) @xmath178 is a positive definite kernel for @xmath123 .",
    "it suffices to check whether the matrix @xmath179 = \\left[\\det(x_i+x_j)^{-\\beta } \\right],\\quad 1 \\le i , j \\le m,\\ ] ] is positive definite for every @xmath40 and hpd matrices @xmath180 .",
    "unfortunately , a quick numerical experiment reveals that @xmath181 can be indefinite .",
    "a counterexample is given by the following positive definite matrices ( @xmath182 , @xmath183 ) @xmath184 and by setting @xmath185 , for which @xmath186 .",
    "this counterexample destroys hopes of embedding the metric space @xmath187 isometrically into a hilbert space .",
    "although matrix   is not hpd in general , we might ask : _ for what choices of @xmath42 is @xmath181 hpd ?",
    "_ theorem  [ thm.wallach ] answers this question for @xmath181 formed from symmetric real positive definite matrices , and characterizes the values of @xmath42 necessary and sufficient for @xmath181 to be positive definite .",
    "we note here that the case @xmath188 was essentially treated in  @xcite , in the context of semigroup kernels on measures .",
    "[ thm.wallach ] let @xmath189 be real symmetric matrices in @xmath11 .",
    "the @xmath190 matrix @xmath181 defined by   is positive definite , if and only if @xmath42 satisfies @xmath191    we first prove the `` if '' part .",
    "recall therefore , the gaussian integral @xmath192 define the map @xmath193 , where the inner - product is given by @xmath194 thus , it follows that @xmath195 .",
    "the schur product theorem says that the elementwise product of two positive matrices is again positive .",
    "so , in particular @xmath181 is positive whenever @xmath42 is an integer multiple of @xmath196 . to extend the result to all @xmath42 covered by",
    ", we invoke another integral representation : the _ multivariate gamma function _",
    ", defined as  @xcite @xmath197 let @xmath198 , for some constant @xmath199 ; then , compute the inner product @xmath200 which exists if @xmath201 .",
    "thus , @xmath202 for all @xmath42 defined by  .",
    "the converse is a deeper result that leads into the theory of symmetric cones . more specifically , since the positive matrices form a symmetric cone , and the function @xmath203 is decreasing on this cone ( as @xmath204 for all @xmath205 ) , an appeal to theorem vii.3.1 of  @xcite allows us to conclude our claim.@xmath206    [ rmk.commute ] let @xmath103 be a set of hpd matrices that commute with each other .",
    "then , @xmath207 can be isometrically embedded into a hilbert space .",
    "this claim follows because a commuting set of matrices can be simultaneously diagonalized , and for diagonal matrices , @xmath208 , which is a nonnegative sum of negative definite kernels and is therefore itself negative definite .",
    "theorem  [ thm.wallach ] shows that @xmath209 is not a kernel for all @xmath123 , while remark  [ rmk.commute ] mentions an extreme case for which @xmath209 is always a positive definte kernel .",
    "this prompts us to pose the following problem .    *",
    "open problem 1 . * determine necessary and sufficient conditions on a set @xmath210 , so that @xmath211 is a kernel function on @xmath212 for all @xmath123 .",
    "this section returns to our original motivation : using @xmath29 as an alternative to the riemannian metric @xmath28 . in particular , in this section we show a sequence of results that highlight similarities between @xmath29 and @xmath28 .",
    "table  [ tab.summ ] lists these to provide a quick summary .",
    "thereafter , we develop the details",
    ".    .similarities between @xmath28 and @xmath29 at a glance .",
    "all matrices are assumed to be in @xmath11 .",
    "the scalars @xmath213 satisfy @xmath214 , @xmath215 .",
    "an ` e ' indicates an easily verifiable result .",
    "[ cols=\"<,<,<,<\",options=\"header \" , ]      we end our discussion of relations between @xmath28 and @xmath29 by showing how they directly compare with each other ; here , our main result is the sandwiching inequality  .",
    "[ thm.bnds ] let @xmath216 .",
    "then , we have the following bounds @xmath217    first we establish the upper bound . to that end ,",
    "we first rewrite @xmath28 as @xmath218 since @xmath219 , we may write @xmath220 for some @xmath221 , whereby @xmath222 using the same notation we also obtain @xmath223 to relate the quantities   and  , it is helpful to consider the function @xmath224 if @xmath225",
    ", then @xmath226 holds and @xmath227 ; while if @xmath228 , then @xmath229 holds . for both cases , we have the inequality @xmath230 since @xmath231 , inequality   leads to the bound @xmath232 from hlder s inequality we know that @xmath233 ; so we immediately obtain @xmath234 to obtain the lower bound , consider the function @xmath235 the first and second derivatives of @xmath236 with respect to @xmath237 are given by @xmath238 observe that for @xmath239 , @xmath240 . to ensure that @xmath241 is the minimizer of",
    ", we now determine the largest value of @xmath242 for which @xmath243 .",
    "write @xmath244 ; we wish to ensure that @xmath245 .",
    "since @xmath246 , the arithmetic - geometric inequality shows that @xmath247 .",
    "thus , for @xmath248 , the inequality @xmath249 holds ( or equivalently @xmath250 ) .",
    "hence , @xmath251 , which implies that @xmath252",
    "in this paper we studied the symmetric stein divergence ( s - divergence ) on positive definite matrices .",
    "we derived numerous results that uncovered qualitative similarities between the s - divergenceand the riemannian metric on the manifold of positive definite matrices .",
    "notably , we also showed that the square root of the s - divergenceactually defines a metric ; albeit one that does not isometrically embed into hilbert space .",
    "several directions of future work are open .",
    "we mention some below .    *",
    "deriving refinements of the main inequalities presented in this paper . * studying properties of the metric space @xmath253 * characterizing the subclass @xmath254 of positive matrices for which @xmath255 admits an isometric hilbert space embedding . *",
    "developing better algorithms to compute the mean @xmath32 . * identifying applications where @xmath29 ( or @xmath101 ) can be useful .",
    "we hope that our paper encourages other researchers to also investigate new properties and applications of the @xmath69-divergence .",
    "* numerical comparison against log - euclidean distance * we implemented the log - euclidean distance and its centroid computation carefully .",
    "[ fig.lerm ] plots timing results for computing the distance @xmath256 and centroids based on it .     vs s - divergence , title=\"fig:\",width=264,height=226 ]   vs s - divergence , title=\"fig:\",width=264,height=226 ]    fig .",
    "[ fig.lerm ] illustrates the expected : ( i ) s - divergence is substantially faster to compute than @xmath35 because it does not require any eigenvector decomposition ; ( ii ) the log - euclidean centroid is faster to compute , because it can be done non - iteratively in closed form .",
    "we note in passing that for much larger matrices , say over @xmath257 , the s - divergence mean seems to be only about 34 times slower than the @xmath35-mean !",
    "however , whether it is better to use the log - euclidean centroid , the s - divergence mean , or any other mean for that matter , is highly dependent on the application . in our original application",
    "@xcite , the `` ground - truth '' was given by the riemannian metric , and various proxies for the riemannian metric were tried . for the image retrieval application at hand ,",
    "the s - divergence mimics the `` ground - truth '' the best , and our present paper which explores theoretical properties of the s - divergence , lends some theoretical underpinnings .",
    "i am grateful to jeff bilmes for hosting me at the ee department at the university of washington , during my unforeseen visit in july 2011 .",
    "it was there where i first found the proof of theorem  [ thm.metric ] .",
    "35 [ 1]#1 [ 1]`#1 ` urlstyle [ 1]doi : # 1    t.  ando",
    ". concavity of certain maps on positive definite matrices and applications to hadamard products . _ linear algebra and its applications _ , 260 ( 0):0 203241 , 1979 .",
    "v.  arsigny , p.  fillard , x.  pennec , and n.  ayache . .",
    "_ siam j. matrix analysis and applications _ , 290 ( 1):0 328 , 2008 .    a.  banerjee , s.  merugu , i.  s. dhillon , and j.  ghosh . . in _ siam international conf",
    "mining _ , lake buena vista , florida , april 2004 .",
    "h.  h. bauschke and j.  m. borwein .",
    "legendre functions and the method of random bregman projections .",
    "_ journal of convex analysis _ , 4:0 2767 , 1997 .",
    "a.  ben - tal and a.  nemirovksii .",
    "_ lectures on modern convex optimization : analysis , algorithms , and engineering applications_. siam , 2001 .",
    "c.  berg , j.  p.  r. christensen , and p.  ressel . _ harmonic analysis on semigroups : theory of positive definite and related functions _ , volume 100 of",
    "_ gtm_. springer , 1984 .",
    "r.  bhatia",
    ". _ matrix analysis_. springer , 1997 .",
    "r.  bhatia .",
    "_ positive definite matrices_. princeton university press , 2007 .",
    "r.  bhatia and j.  a.  r. holbrook .",
    "riemannian geometry and matrix geometric means .",
    "_ linear algebra appl .",
    "_ , 413:0 594618 , 2006 .",
    "a.  bhattacharyya . on a measure of divergence between two statistical populations defined by their probability distributions .",
    "calcutta math .",
    "_ , 35:0 99109 , 1943 .",
    "d.  a. bini and b.  iannazzo . computing the karcher mean of symmetric positive definite matrices . _ linear algebra and its applications _ , oct",
    "available online .",
    "p.  bougerol . .",
    "_ siam j. control optim .",
    "_ , 310 ( 4):0 942959 , 1993",
    ".    s.  boyd and l.  vandenberghe .",
    "_ convex optimization_. cambridge university press , 2004 .",
    "m.  r. bridson and a.  haeflinger .",
    "_ metric spaces of non - positive curvature_. springer , 1999 .",
    "y.  censor and s.  a. zenios . _",
    "parallel optimization : theory , algorithms , and applications_. numerical mathematics and scientific computation .",
    "oxford university press , 1997 .",
    "z.  chebbi and m.  moahker .",
    "means of hermitian positive - definite matrices based on the log - determinant @xmath258-divergence function . _ linear algebra and its applications _ , 436:0 18721889 , 2012 .",
    "a.  cherian , s.  sra , a.  banerjee , and n.  papanikolopoulos . .",
    "in _ international conference on computer vision ( iccv ) _ , nov . 2011 .",
    "a.  cherian , s.  sra , a.  banerjee , and n.  papanikolopoulos . .",
    "_ ieee tpami _ , 2012 . .",
    "t.  m. cover and j.  a. thomas .",
    "_ elements of information theory_. wiley - interscience , 1991 .",
    "m.  cuturi , k.  fukumizu , and j.  p. vert .",
    "semigroup kernels on measures .",
    "_ jmlr _ , 6:0 11691198 , 2005 .",
    "i.  s. dhillon and j.  a. tropp . .",
    "_ siam journal on matrix analysis and applications _",
    ", 290 ( 4):0 11201146 , 2007 .",
    "j.  faraut and a.  kornyi .",
    "_ analysis on symmetric cones_. clarendon press , 1994 .",
    "m.  harandi , c.  sanderson , r.  hartley , and b.  lovell . .",
    "european conference on computer vision ( eccv ) _ , 2012",
    ".    s.  helgason .",
    "_ geometric analysis on symmetric spaces_. number  39 in mathematical surveys and monographs .",
    "ams , second edition , 2008 .",
    "f.  hiai and d.  petz . .",
    "_ linear algebra and its applications _ , 430:0 31053130 , 2009 .",
    "b.  kulis , m.  sustik , and i.  dhillon . .",
    "_ journal of machine learning research _ , 10:0 341376 , 2009 .",
    "h.  lee and y.  lim .",
    "invariant metrics , contractions and nonlinear matrix equations .",
    "_ nonlinearity _ , 21:0 857878 , 2008 .    r.  j. muirhead .",
    "_ aspects of multivariate statistical theory_. wiley interscience , 1982 .",
    "nesterov and a.  nemirovskii .",
    "_ interior - point polynomial algorithms in convex programming_. siam , 1987 .",
    "nesterov and m.  j. todd . on the riemannian geometry defined for self - concordant barriers and interior point methods .",
    "_ , 2:0 333361 , 2002 .",
    "f.  nielsen .",
    "sided and symmetrized bregman centroids . _ ieee transactions on information theory _ , 550 ( 6 ) , 2009 .",
    "j.  nocedal and s.  j. wright .",
    "_ numerical optimization_. springer , 1999 .    c.  stein .",
    "inadmissibility of the usual estimator for the mean of a multivariate distribution . in _ proc .",
    "third berkeley symp .",
    "_ , volume  1 , pages 197206 , 1956 .",
    "a.  terras .",
    "_ harmonic analysis on symmetric spaces and applications _ , volume  ii .",
    "springer , 1988 .",
    "h.  wolkowicz , r.  saigal , and l.  vandenberghe , editors .",
    "_ handbook of semidefinite programming : theory , algorithms , and applications_. kluwer academic , 2000 .",
    "let @xmath53 be a solution to  .",
    "previously this nonlinear equation was also considered by  @xcite , who however , erroneously claimed @xmath259 to be strictly convex , and used that to conclude uniqueness .",
    "fortunately , a recent result of  ( * ? ? ?",
    ".  3.10 ) proves uniqueness for a slightly more general version of this nonlinear equation .",
    "we simplify their argument for our setting , and reproduce it below for the reader s convenience .",
    "suppose @xmath53 and @xmath143 are two solutions to  .",
    "denote by @xmath260 and @xmath261 .",
    "then , we have @xmath262 thus , it follows that @xmath263 but notice that @xmath264 , which follows because @xmath265 since @xmath266 , we can rewrite   as @xmath267 using the well - known kronecker product relation @xmath268 ( for hermitian matrices ) , we rewrite   as @xmath269 where @xmath270 and @xmath271 but each @xmath272 being a kronecker product of nonsingular matrices is itself nonsingular .",
    "thus , @xmath273 is also nonsingular , whereby for   to hold , we must have @xmath54 .",
    "thus , the proof is complete ."
  ],
  "abstract_text": [
    "<S> positive definite matrices abound in a dazzling variety of applications . </S>",
    "<S> this dazzle could in part be attributed to their rich geometric structure : they form a self - dual convex cone whose strict interior is a riemannian ( also finslerian ) manifold . </S>",
    "<S> the manifold view comes with a `` natural '' distance function while the conic view does not . </S>",
    "<S> nevertheless , drawing motivation from the convex conic view , we introduce the _ s - divergence _ as a `` natural '' distance - like function on the open cone of positive definite matrices . </S>",
    "<S> we motivate this divergence via a sequence of results that connect it to the riemannian metric . in particular , we show that ( a ) this divergence is the square of a metric ; and ( b ) that it has several geometric properties in common with the riemannian metric , without being numerically as burdensome . </S>",
    "<S> the s - divergenceis even more intriguing : although nonconvex , we show that one can still solve multivariable matrix means using it to global optimality . </S>",
    "<S> we complement our results by listing some open problems .    </S>",
    "<S> * keywords : * stein s loss ; bregman matrix divergence ; log determinant ; affine invariant metric ; hilbert space embedding ; jensen - shannon divergence ; matrix geometric mean </S>"
  ]
}