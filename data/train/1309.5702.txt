{
  "article_text": [
    "aspirations for safety and security of human lives against crimes and natural disasters motivate us to establish smart monitoring systems to monitor surrounding environment . in this",
    "regard , vision sensors are expected as powerful sensing components since they provide rich information about the outer world . indeed , visual monitoring systems have been already commoditized and are working in practice . typically , in the current systems , various decision - making and situation awareness processes are conducted at a monitoring center by human operator(s ) , and partial distributed computing at each sensor is , if at all , done independently of the other sensors . however , as the image stream increases , it is desired to distribute the entire process to each sensor while achieving total optimization through cooperation among sensors .",
    "distributed processing over the visual sensor networks is actively studied in recent years motivated by a variety of application scenarios @xcite@xcite . among them , several papers address optimal monitoring of the environment assuming mobility of the vision sensors @xcite@xcite , where it is required for the network to ensure the best view of a changing environment @xcite .",
    "the problem is related to coverage control @xcite@xcite , whose objective is to deploy mobile sensors efficiently in a distributed fashion . a typical approach to coverage control",
    "is to employ the gradient descent algorithm for an appropriately designed aggregate objective function .",
    "the objective function is usually formulated by integrating the product of a sensing performance function of a point and a density function indicating the relative importance of the point .",
    "the approach is also applied to visual coverage in @xcite@xcite .",
    "the state of the art of coverage control is compactly summarized in @xcite , and a survey of related works in the computer vision society is found in @xcite .    in this paper , we consider a visual coverage problem under the situation where vision sensors with controllable orientations are distributed over the 3-d space to monitor 2-d environment . in the case , the control variables i.e. the rotation matrices must be constrained on the lie group @xmath0 , which distinguishes the present paper from the works on 2-d coverage @xcite@xcite . on the other hand ,",
    "@xcite consider situations similar to this paper .",
    "@xcite take game theoretic approaches which allow the network to achieve globally optimal coverage with high probability but instead the convergence speed tends to be slower than the standard gradient descent approach .",
    "in contrast , @xcite employs the gradient approach by introducing a local parameterization of the rotation matrix and regarding the problem as optimization on a vector space .",
    "this paper approaches the problem differently from @xcite .",
    "we directly formulate the problem as optimization on @xmath0 and apply the gradient descent algorithm on matrix manifolds @xcite .",
    "this approach will be shown to allow one to parametrize the control law for a variety of underactuations imposed by the hardware constraints .",
    "this paper also addresses density estimation from acquired data , which is investigated in @xcite for 2-d coverage .",
    "however , we need to take account of the following characteristics of vision sensors : ( i ) the sensing process inherently includes projection of 3-d world onto 2-d image , and ( ii ) explicit physical data is not provided . to reflect ( i ) , we incorporate the projection into the optimization problem on the embedding manifold of @xmath0 . the issue ( ii ) is addressed technologically , where we present the entire process including image processing and curve fitting techniques . finally , we demonstrate the utility of the present coverage control strategy through simulation of moving objects monitoring .",
    "let us consider a riemannian manifold @xmath1 whose tangent space at @xmath2 is denoted by @xmath3 , and the corresponding riemannian metric , an smooth inner product , defined over @xmath3 is denoted by @xmath4 .",
    "now , we introduce a smooth scalar field @xmath5 defined over the manifold @xmath1 , and the derivative of @xmath6 at an element @xmath2 in the direction @xmath7 , denoted by @xmath8 $ ] .",
    "we see from definition 3.5.1 and ( 3.15 ) of @xcite that the derivative @xmath9 $ ] is defined by @xmath10 = \\left.\\frac{d f(\\gamma(t))}{dt}\\right|_{t = 0},\\ ] ] where @xmath11 is a smooth curve such that @xmath12 .",
    "in particular , when @xmath1 is a linear manifold with @xmath13 , the derivative @xmath9 $ ] is equal to the classical directional derivative @xmath10 = \\lim_{t\\to 0}\\frac{f(x + t\\xi)-f(x)}{t}. \\label{eqn : derivative_lin_m}\\ ] ]    now , the gradient of @xmath6 is defined as follows .",
    "@xcite [ def : grad_m ] given a smooth scalar field @xmath6 defined over a riemannian manifold @xmath1 , the gradient of @xmath6 at @xmath14 , denoted by @xmath15 , is defined as the unique element of @xmath3 satisfying @xmath16\\ \\ { \\forall \\xi}\\in t_x{{\\mathcal m}}.\\ ] ]    suppose now that @xmath1 is a riemannian submanifold of a riemannian manifold @xmath17 , namely @xmath3 is a subspace of @xmath18 and they share a common riemannian metric .",
    "in addition , the orthogonal projection of an element of @xmath18 onto @xmath3 is denoted by @xmath19 .",
    "then , the following remarkable lemma holds true .",
    "@xcite [ lem : grad_proj ] let @xmath20 be a scalar field defined over @xmath17 such that the function @xmath6 defined on @xmath1 is a restriction of @xmath20 .",
    "then , the gradient of @xmath6 satisfies the equation @xmath21",
    "we consider the situation illustrated in fig .",
    "[ fig : scenario ] where @xmath22 vision sensors @xmath23 are located in 3-d euclidean space .",
    "let the fixed world frame be denoted by @xmath24 and the body fixed frame of sensor @xmath25 by @xmath26 .",
    "we also denote the position vector of the origin of @xmath26 relative to @xmath24 by @xmath27 , and the rotation matrix of @xmath26 relative to @xmath24 by @xmath28 .",
    "then , the pair @xmath29 , called _ pose _ , represents the configuration of sensor @xmath30 . in this paper , each sensor s position @xmath31 is assumed to be fixed , and sensors can control only their orientations @xmath32 .",
    "in addition , we suppose that sensors are localized and calibrated _ a priori _ and @xmath33 is available for control .",
    "we use the notation @xmath33 to describe not only the pose but also a coordinate transformation operator similarly to @xcite .",
    "take two frames @xmath34 and @xmath35 .",
    "let the pose of the frame @xmath35 relative to @xmath34 be denoted by @xmath36 , and the coordinates of a point relative to @xmath34 by @xmath37 .",
    "then , the coordinates @xmath38 of the point relative to @xmath34 are given as @xmath39    let us next define the region to be monitored by a group of sensors @xmath40 .",
    "in this paper , we assume that the region is a subset of a 2-d plane ( fig .",
    "[ fig : scenario ] ) , where the 2-d plane is called the environment and the subset to be monitored is called the mission space .",
    "let the set of coordinates of all points in the environment and the mission space relative to @xmath24 are respectively denoted by @xmath41 and @xmath42 . just for simplicity , we suppose that the world frame @xmath24 is attached so that its @xmath43-plane is parallel to the environment ( fig .",
    "[ fig : scenario ] ) .",
    "then , the set @xmath41 is formulated as @xmath44 with some constant @xmath45 , where @xmath46 is an @xmath30-th standard basis .",
    "suppose that a metric @xmath47 , called a density function , indicating the relative importance of every point @xmath48 is defined over @xmath41 . in this paper , the function @xmath49",
    "is assumed to be small if point @xmath50 is important and to satisfy @xmath51 with a constant @xmath52 such that @xmath53 .",
    "a vision sensor has an image plane containing the sensing array , whose elements , called pixels , provide the numbers reflecting the amount of light incident .",
    "we assume that the image plane is a rectangle as illustrated in fig .",
    "[ fig : image_plane1 ] .",
    "the set of position vectors of all points on the image plane relative to the sensor frame @xmath26 is denoted by @xmath54 .",
    "now , the axes of the sensor frame @xmath26 is assumed to be selected so that its @xmath43-plane is parallel to the image plane and @xmath55-axis perpendicular to the image plane passes through the focal center of the lens",
    ". then , the third element of any point in the set @xmath56 must be equal to the focal length @xmath57 .",
    "we next denote the set of pixels of sensor @xmath58 by @xmath59 and the position vector of the center of the @xmath60-th pixel on the image plane of sensor @xmath30 relative to @xmath26 by @xmath61 .",
    "since @xmath60 in @xmath62 and @xmath63 deffer , we may need to use the notation like @xmath64 but we omit the subscript to reduce notational complexity . in addition , the positions of its vertices relative to @xmath26 are denoted by @xmath65 ( fig . [ fig : image_plane2 ] ) .",
    "when a point on the environment with coordinates @xmath66 relative to @xmath26 is captured by a sensor @xmath30 with @xmath33 , the point is projected onto the image plane as illustrated in fig .",
    "[ fig : proj1 ] .",
    "if the coordinates of the projected point are denoted by @xmath67 , it is well known that the projection is formulated as @xmath68 it is not difficult to show that the inverse map @xmath69 of the map @xmath70 ( fig .",
    "[ fig : proj1 ] ) from @xmath71 to @xmath66 is given by @xmath72 note that , while @xmath70 is independent of @xmath32 , the map @xmath69 depends on @xmath32 and hence we describe @xmath69 as @xmath73 .     and @xmath69.,width=245 ]    using the map @xmath69 , we denote by @xmath74 the set of coordinates of the field of view ( fov ) of each sensor @xmath30 relative to @xmath24 , which is also a polytope . its @xmath40-polytope representation is trivial , namely it is given by the convex hull of the four points with coordinates @xmath75 relative to @xmath24 ( fig .",
    "[ fig : fov2 ] ) .",
    "the @xmath76-polytope representation is also computed efficiently as follows .",
    "suppose now that @xmath60-th side line segment ( @xmath77 ) specifying the boundary of the image plane connects the vertices @xmath78 and @xmath79 without loss of generality .",
    "then , the line projected onto the environment is also a line segment whose vertices have coordinates @xmath80 and @xmath81 relative to @xmath24 , and hence the line is formulated as @xmath82 where the matrix @xmath83 is derived as @xmath84 from the fact that @xmath85 and @xmath86 are on the line . since the coordinates @xmath87 for any interior @xmath88 of @xmath89 must be inside the fov , a half space specifying the fov is described by the inequality @xmath90 with @xmath91 in the same way , we can find the pair @xmath92 for all @xmath77 . stacking them",
    "allows one to formulate the fov as @xmath93",
    "in this section , we consider a simple case with @xmath94 .",
    "let us first define the objective function to be _ minimized _ by sensor @xmath30 . in this paper , we basically take the concept of coverage control @xcite , where the objective function is defined by a sensing performance function and a density function at a point @xmath95 .",
    "note however that we accumulate the function only at the center of the pixels projected onto the environment @xmath41 in order to reflect the discretized nature of the vision sensors . in the sequel , the sensing performance function and the density function at @xmath95",
    "are denoted by @xmath96 and @xmath97 , respectively .",
    "let us first define a function @xmath98 providing the coordinates in @xmath24 of the point on @xmath41 which is captured by @xmath60-th pixel as @xmath99 then , the objective function takes the form of @xmath100 where @xmath101 is a weighting coefficient .",
    "if we impose a large @xmath102 on the pixel at around the center of the image , the sensor tends to capture the important area at around the image center .",
    "if we need to accelerate computation , replacing @xmath103 in ( [ eqn : obj_single ] ) by its subset is an option . in order to ensure preciseness",
    ", we need to introduce an extended function allowing @xmath104 , but we will not mention it since it can be easily avoided by choosing @xmath105 appropriately .    ,",
    "width=245 ]    similarly to @xcite , we let the performance function @xmath105 depend only on the distance @xmath106 .",
    "remark however that , differently from @xcite , the third element of @xmath107 is not controllable since the sensor is fixed .",
    "this may cause a problem that penalty of seeing distant area does not work in the case that the element is large enough .",
    "however , the element is not ignorable since it reflects heterogeneous characteristics of vision sensors in the multi - sensor case .",
    "we thus use the weighting distance as @xmath108 with @xmath109 , where @xmath110 is introduced since the distance is scaled by the focal length .",
    "suppose that @xmath111 is set as @xmath112)$ ] .",
    "then , a large @xmath113 imposes a heavy penalty on viewing distant area and a small @xmath113 a light penalty on it .",
    "in particular , when @xmath114 for some @xmath115 , ( [ eqn : perf1 ] ) is rewritten as @xmath116    once the density function @xmath117 is given , the goal is reduced to minimization of ( [ eqn : obj_single ] ) with ( [ eqn : perf2 ] ) under the restriction of @xmath118 . in order to solve the problem , this paper takes the gradient descent approach which is a standard approach to coverage control . for this purpose , it is convenient to define an extension @xmath119 such that @xmath120 if @xmath121 .",
    "we first extend the domain of @xmath122 in ( [ eqn : q_wl ] ) from @xmath0 to @xmath123 as @xmath124 then , the vector @xmath125 is not always on the environment when @xmath126 but the function @xmath127 in ( [ eqn : perf1 ] ) is well - defined even if the domain is altered from @xmath41 to @xmath128 .",
    "we thus denote the function with the domain @xmath128 by @xmath129 , and define the composite function @xmath130     relative to @xmath24 and @xmath26.,width=226 ]    we next focus on the term @xmath131 in ( [ eqn : obj_single ] ) and expand the domain of the composite function from @xmath0 to @xmath132 . here ,",
    "since @xmath133 is not always on @xmath41 , we need to design @xmath134 such that @xmath135 if @xmath95 . in this paper",
    ", we assign to a point @xmath136 the density of a point @xmath137 where the operations are illustrated in fig .",
    "[ fig : proj4 ] .",
    "accordingly , the density function is defined by @xmath138 remark that , differently from @xmath127 , the function @xmath117 is not naturally extended and the selection of @xmath139 is not unique . the motivation to choose ( [ eqn : perf6 ] ) will be clear in the next subsection .",
    "consequently , we define the extended objective function @xmath140 from @xmath132 to @xmath141 by using ( [ eqn : perf5 ] ) and ( [ eqn : perf6 ] ) .",
    "let us finally emphasize that @xmath142 holds for any @xmath143 .",
    "in the gradient descent approach , we update the rotation @xmath32 in the direction of @xmath144}^{so(3 ) } h_i$ ] at each time @xmath145 .",
    "this subsection assumes that the density @xmath117 is not given _ a priori _ and that @xmath117 needs to be estimated from acquired vision data as investigated in @xcite .",
    "let us first consider an ideal situation such that the density function is exactly projected onto the image plane , namely @xmath146(q)\\ { \\forall q",
    "} \\in fov_i({r_{wi}}[k ] ) , \\label{eqn : psi_phi2}\\ ] ] holds with respect to the density @xmath147 over the image plane .",
    "then , the density function value @xmath49 is available at any point in the fov .",
    "we next consider a point @xmath136 which does not always lie on @xmath41 .",
    "then , the value of @xmath148 is also given by the same function as ( [ eqn : psi_phi2 ] ) since @xmath149\\circ \\phi \\circ g_{wi}^{-1}[k ] ( \\bar q ) \\nonumber\\\\ \\!\\!&\\!\\!=\\!\\!&\\!\\ ! \\psi \\circ",
    "\\psi_i \\circ g_{wi}^{-1}[k ] \\circ g_{wi}[k]\\circ \\phi \\circ g_{wi}^{-1}[k ] ( \\bar q ) \\nonumber\\\\ \\!\\!&\\!\\!=\\!\\!&\\!\\",
    "! \\psi \\circ \\psi_i \\circ \\phi \\circ g_{wi}^{-1}[k ] ( \\bar q ) = \\psi \\circ \\psi_i \\circ g_{wi}^{-1}[k ] ( \\bar q ) .",
    "\\nonumber\\end{aligned}\\ ] ] ensuring the equality is the reason for choosing ( [ eqn : perf6 ] ) .",
    "we next consider estimation of the density @xmath150 on the image since assuming ( [ eqn : psi_phi2 ] ) is unrealistic .",
    "rich literature has been devoted to the information extraction from the raw vision data , and a variety of algorithms are currently available even without expert knowledge @xcite .",
    "for example , it is possible to detect and localize in the image plane specific objects like cars or human faces , and even abstract targets such as everything moving or some environmental changes .",
    "the present coverage scheme is indeed applicable to any scenario such that a nonnegative number @xmath151 reflecting its own importance is assigned to each pixel @xmath115 after conducting some image processing .",
    "however , we mainly focus on a specific scenario of monitoring moving objects on the mission space .",
    "suppose that a sensor captures a human walking from left to right in the image as in fig .",
    "[ fig : snapshot ] .",
    "then , a way to localize such moving objects is to compute optical flows from consecutive images as in fig . [",
    "fig : snapshot ] , where the flows are depicted by yellow lines .",
    "we also let the data @xmath151 be the norm of the flow vector at each pixel .",
    "then , the plots of @xmath151 over the image plane are illustrated by green dots in fig .",
    "[ fig : mix_gauss1 ] .",
    "we next fit the data of @xmath151 by a continuous function defined over @xmath89 and use the function as @xmath150 .",
    "such algorithms are also available even in real time @xcite . similarly to @xcite , we employ the mixed gaussian function known to approximate a variety of functions with excellent precision by increasing the number of gaussian functions , and widely used in data mining , pattern recognition , machine learning and statistical analysis .",
    "[ fig : mix_gauss2 ] shows the gaussian function with @xmath152 computed so as to fit the data in fig .",
    "[ fig : mix_gauss1 ] . of course , using a larger @xmath153 achieves a better approximation as shown in fig .",
    "[ fig : mix_gauss_various ] .    as a result",
    ", we obtain a function in the form of @xmath154 over the 2-d image plane coordinates @xmath155 .",
    "note that ( [ eqn : mix_gauss_image2 ] ) is large when @xmath156 captures an important point , which is opposite to the density function .",
    "thus , we define the function @xmath157 where @xmath158 is a positive scalar guaranteeing @xmath159 for all @xmath156 .",
    "it is also convenient to define @xmath160 for all 3-d vectors @xmath161 on the image plane as @xmath162    ( left ) and @xmath163(right).,title=\"fig:\",width=151,height=105 ]    ( left ) and @xmath163(right).,title=\"fig:\",width=151,height=105 ]        here , we will derive the gradient @xmath144}^{so(3 ) } h_i$ ] , given a rotation @xmath164 \\in so(3)$ ] and @xmath150 in ( [ eqn : mix_gauss ] ) .",
    "it is widely known that @xmath165 is formulated as @xmath166 , where @xmath167 is the set of all skew symmetric matrices in @xmath132 .",
    "we also define the operator @xmath168(wedge ) from @xmath128 to @xmath132 such that @xmath169 for the cross product @xmath170 .",
    "the rotational group @xmath0 is known to be a submanifold of a riemannian manifold @xmath123 with @xmath171 and the riemannian metric @xmath172 @xcite .",
    "it is also known that the orthogonal projection @xmath173 of matrix @xmath174 onto @xmath165 in terms of the riemannian metric induced by ( [ eqn : riemannian ] ) is given by @xmath175 see subsection 3.6.1 of @xcite for more details .",
    "now , we have the following theorem , where we use the notation @xmath176 and @xmath177 .",
    "suppose that the objective function @xmath178 is formulated by ( [ eqn : obj_single_fict ] ) with ( [ eqn : perf5 ] ) , ( [ eqn : perf6 ] ) and ( [ eqn : mix_gauss ] ) .",
    "then , the gradient @xmath144}^{so(3 ) } h_i$ ] is given by @xmath179}^{so(3 ) } h_i \\!\\!&\\!\\!=\\!\\!&\\!\\ !",
    "p_{{r_{wi}}[k]}\\left({{\\rm grad}}_{{r_{wi}}[k]}^{{{\\mathbb r}}^{3\\times 3 } } \\bar h_i\\right ) , \\label{eqn : proj2}\\\\ { { \\rm grad}}_{{r_{wi}}[k]}^{{{\\mathbb r}}^{3\\times 3 } } \\bar h_i \\!\\!&\\!\\!=\\!\\!&\\!\\ ! \\tilde \\delta_i   \\eta_i^t({r_{wi}}[k ] ) p_{il}^t ,   \\nonumber\\end{aligned}\\ ] ] where @xmath180    see appendix [ app:1 ] .",
    "namely , just running the dynamics @xmath181 leads @xmath32 to the set of critical points of @xmath182 .",
    "however , in practice , the vision data is usually obtained at discrete time instants and hence we approximate the continuous - time algorithm ( [ eqn : grad_descent1 ] ) by @xmath183 = { r_{wi}}[k]{\\rm exp}\\left({r_{wi}}^t[k ] \\left(\\alpha_k { { \\rm grad}}_{{r_{wi}}[k]}^{so(3 ) } h_i\\right)\\right ) .",
    "\\label{eqn : grad_descent2}\\end{aligned}\\ ] ] see @xcite for the details on the selection of @xmath184 .              in the above discussion , we assume that the sensor can take full 3-d rotational motion . however , the motion of many commoditized cameras is restricted by the actuator configurations .",
    "hereafter , we suppose that the sensor can be rotated around two axes @xmath185 ( @xmath186 ) and @xmath187 ( @xmath188 ) , where these vectors are defined in @xmath26 and assumed to be linearly independent of each other .",
    "these axes may depend on the rotation matrix @xmath32 .",
    "for example , in the case of pan - tilt ( pt ) cameras in figs .",
    "[ fig : pan ] and [ fig : tilt ] , which are typical commoditized cameras , the axis of the pan motion ( fig .",
    "[ fig : pan ] ) is fixed relative to @xmath24 , while that of the tilt motion ( fig .",
    "[ fig : tilt ] ) is fixed relative to the sensor frame @xmath26 .",
    "then , only one of the two axes depends on @xmath32 .",
    "note that even when there is only one axis around which the sensor can be rotated , the subsequent discussions are valid just letting @xmath189 .",
    "let us denote a normalized vector @xmath190 ( @xmath191 ) orthogonal to the @xmath192-plane .",
    "then , the three vectors @xmath185 , @xmath193 and @xmath194 span @xmath128 .",
    "thus , any element @xmath195 of @xmath165 can be represented in the form of @xmath196 .",
    "now , we define a _ distribution _ @xmath197 @xcite assigning @xmath118 to the subspace @xmath198 whose dimension is @xmath79 .",
    "the distribution @xmath197 is clearly regular and hence induces a submanifold @xmath199 of @xmath0 @xcite , called integral manifold , such that its tangent space @xmath200 at @xmath201 is equal to ( [ eqn : submanifold ] ) .",
    "the manifold @xmath199 specifies orientations which the camera can take .    since @xmath199 is a submanifold of @xmath0 , a strategy similar to theorem 1 is available and we have the following corollary .",
    "suppose that the objective function @xmath178 is formulated by ( [ eqn : obj_single_fict ] ) with ( [ eqn : perf5 ] ) , ( [ eqn : perf6 ] ) and ( [ eqn : mix_gauss ] ) .",
    "then , the gradient @xmath144}^{{\\mathcal s}_{ua } } h_i$ ] is given by @xmath179}^{{\\mathcal s}_{ua } } h_i \\!\\!&\\!\\!=\\!\\!&\\!\\ !",
    "p^{ua}_{{r_{wi}}[k]}\\left({{\\rm grad}}_{{r_{wi}}[k]}^{so(3 ) } h_i\\right ) \\label{eqn : proj3}\\end{aligned}\\ ] ] where the orthogonal projection @xmath202 of @xmath203 to @xmath200 is defined by @xmath204 with @xmath205 @xmath206 , where @xmath207 if @xmath208 and @xmath209 if @xmath210 .",
    "we see from this corollary that the gradient @xmath144}^{so(3 ) } h_i$ ] on @xmath0 is utilized as it is and we need only to project it through ( [ eqn : proj4 ] ) .",
    "also , the projection ( [ eqn : proj4 ] ) is successfully parameterized by the vectors @xmath211 and @xmath187 .",
    "in this section , we extend the result of the previous section to the multi - sensor case .",
    "the difference from the single sensor case stems from the overlaps of the fovs with the other sensors as illustrated in fig .",
    "[ fig : overlap ] .",
    "@xcite present sensing performance functions taking account of the overlaps and their gradient decent laws",
    ". however , in this paper , we present another simpler scheme to manage the overlap .",
    "let us first define the set of sensors capturing a point @xmath95 within the fov as @xmath212 where @xmath213 .",
    "we also suppose that , when @xmath214 has multiple elements for some @xmath215 , only the data of the sensor with the minimal sensing performance ( [ eqn : perf1 ] ) among sensors in @xmath214 is employed in higher - level decisions and recognitions .",
    "this motivates us to partition @xmath74 into the two region @xmath216 then , what pixel @xmath60 captures a point in @xmath217 is identified with what it captures a point outside of @xmath42 , whose cost is set as @xmath218 in the previous section , in the sense that both of the data are not useful at all .",
    "this is reflected by assigning @xmath52 to the pixels @xmath219 with @xmath220 .",
    "accordingly , we formulate the function to be minimized by @xmath40 as @xmath221 with @xmath222 remark that ( [ eqn : obj_multi ] ) differs from ( [ eqn : obj_single ] ) only in the set @xmath223 .    strictly speaking , to compute the gradient of ( [ eqn : obj_multi ] ) , we need to expand @xmath224 from @xmath225 to @xmath226 . for this purpose , it is sufficient to define @xmath227 from @xmath132 to a subset of @xmath41 .",
    "for example , an option is to define an extension @xmath228 of ( [ eqn : arxiv1 ] ) similarly to ( [ eqn : arxiv2 ] ) , and to let @xmath227 be the convex full of these points .",
    "however , at the time instants computing the gradient with @xmath229 $ ] , the extension @xmath230 for a sufficiently small perturbation @xmath231 is equivalent to the original set @xmath223 irrespective of the selection of @xmath227 except for the pathological case when a pixel is located on the boundary of @xmath232 .",
    "namely , ignoring such pathological cases which do not happen almost surely for ( [ eqn : grad_descent2 ] ) , the gradient can be computed by using the set @xmath233)$ ] instead of its extension .",
    "hence , the gradient is simply given as theorem 1 by just replacing @xmath234 by @xmath223 .",
    "note that the curve fitting process is run without taking account of whether @xmath235 or not , and @xmath52 is assigned to @xmath236 at the formulation of @xmath150 as in ( [ eqn : mix_gauss ] ) .",
    "this is because letting @xmath237 at the curve fitting stage would degrade the density estimation accuracy at around the boundary of @xmath238 .",
    "the remaining issue is efficient computation of the set @xmath234 .",
    "hereafter , we assume that each sensor acquires @xmath239 , i.e. @xmath240 and @xmath241 for all @xmath242 , and its index @xmath243 through ( all - to - all ) communication or with the help of a centralized computer .",
    "the computation under the limited communication will be mentioned at the end of this section .",
    "in addition , we suppose that every sensor stores the set @xmath244 for all @xmath245 which can be computed off - line since the sensor positions are fixed .",
    "s ( left ) and @xmath246s ( right).,width=151,height=94 ]    s ( left ) and @xmath246s ( right).,width=151,height=94 ]    s ( left ) and @xmath246s ( right).,width=151,height=94 ]    s ( left ) and @xmath246s ( right).,width=151,height=94 ]    s ( left ) and @xmath246s ( right).,width=151,height=94 ]    s ( left ) and @xmath246s ( right).,width=151,height=94 ]    then , the set @xmath217 is computed as @xmath247 in polynomial time with respect to @xmath22 .",
    "namely , checking @xmath248 for all @xmath249 provides @xmath223 .",
    "the computation process including image processing , curve fitting and gradient computation is successfully distributed to each sensor but the resulting fovs need to be shared among all sensors to compute @xmath223 .",
    "a way to implement the present scheme under limited communication is to restrict the fov of each sensor so that the fov can overlap with limited number of fovs of the other sensors .",
    "such constraints on the fovs are easily imposed by adding an artificial potential to the objective function but we leave the issue as a future work due to the page constraints .",
    "in this section , we demonstrate the utility of the present approach through simulation using 4 cameras with @xmath250 mm @xmath251 . here",
    ", we suppose that the view of the environment from @xmath24 with @xmath252 m and focal length @xmath253 mm is given as in fig .",
    "[ fig : initial_image ] , and that the mission space @xmath42 is equal to the fov corresponding to the image .",
    "since the codes of simulating the image acquisition and processing are never used in experiments , we simplify the process as follows , and demonstrate only the present coverage control scheme with the curve fitting process . before running the simulation , we compute the optical flows for the images of fig . [",
    "fig : initial_image ] as in fig .",
    "[ fig : of_image ] , and also fitting functions of the data as in fig .",
    "[ fig : curve_fit ] .",
    "the resulting data is uploaded at http://www.fl.ctrl.titech.ac.jp/paper/2014/data.wmv .",
    "then , we segment the image by the superlevel set of the function using a threshold @xmath254 , and assign a boolean variable @xmath78 to @xmath151 if @xmath255 is inside of the set and assign @xmath256 otherwise .",
    "the experimental system is now under construction , and the experimental verification of the total process will be conducted in a future work .",
    "note however that it is at least confirmed that the skipped image acquisition and processing can be implemented within several milliseconds in a real vision system .",
    ".,width=151,height=94 ]    .,width=151,height=94 ]    .,width=151 ]    let the position vectors of cameras be selected as @xmath257 and the length of each side of the image plane be @xmath258 mm and @xmath259 mm .",
    "the other elements of @xmath31 are set as illustrated by the mark @xmath260 in fig .",
    "[ fig : static ] .",
    "the parameters in @xmath261 is set as @xmath262 , @xmath263 , @xmath264 and @xmath265)$ ] .",
    "the curve fitting process is run with @xmath266 and the gradient is computed by evaluating the objective function not at all points in @xmath103 but at 121 points extracted from @xmath103 . in order to confirm convergence of the orientations ,",
    "we first fix the image as in fig .",
    "[ fig : static ] and run the present algorithm from the initial condition @xmath267 .",
    "then , the evolution of the function @xmath261 is illustrated in fig .",
    "[ fig : obj ] , where we compute the value using not the individually estimated density but the data as in fig .",
    "[ fig : curve_fit ] .",
    "we see from the figure that the function @xmath261 is decreasing through the update process and eventually reaches a stationary point .",
    "the final configuration is depicted in the right figure of fig .",
    "[ fig : static ] .",
    "we next start to play the above movie and check adaptability to environmental changes , where the orientations are assumed to be updated at each frame .",
    "then , the evolution of fovs are shown in http://www.fl.ctrl.titech.ac.jp/paper/2014/sim.wmv whose snapshots at times @xmath268 are depicted in fig .",
    "[ fig : snaps ] .",
    "we see from the movie and figures that the cameras adjust their rotations so as to capture moving humans .",
    "the above results show the effectiveness of the present approach .",
    "in this paper , we have investigated visual coverage control where the vision sensors are assumed to be distributed over the 3-d space to monitor the 2-d environment and to be able to control their orientations .",
    "we first have formulated the problem as an optimization problem on @xmath0 .",
    "then , in order to solve the problem , we have presented the entire process including not only the gradient computation but also image processing and curve fitting , which are required to estimate the density function from the acquired vision data . finally , we have demonstrated the effectiveness of the approach through simulation of moving objects monitoring .",
    "for notational simplicity , we describe @xmath164 $ ] by @xmath269 in the sequel . substituting ( [ eqn : perf5 ] ) , ( [ eqn : perf6 ] ) and ( [ eqn : mix_gauss ] ) into ( [ eqn : obj_single_fict ] )",
    ", the objective function to be minimized is formulated as @xmath270            from lemma 1 and the fact that @xmath0 is a submanifold of @xmath132 , we first compute the gradient @xmath273 . from definition 1 and ( [ eqn : derivative_lin_m ] ) , we need to compute the directional derivative @xmath274 $ ] . from linearity of the directional derivative operator @xmath275 ,",
    "it is sufficient to derive @xmath276 $ ] and @xmath277 $ ] .",
    "we first consider @xmath276 $ ] . by calculation",
    ", we have @xmath278 hence , @xmath279 = \\lim_{t\\to 0}\\frac{\\tilde h^{l}_i(r + \\xi t ) - \\tilde h^{l}_i(r)}{t}$ ] is given by @xmath280 \\!\\!&\\!\\!=\\!\\!&\\!\\ ! \\tilde",
    "\\eta_i^l(r)\\xi p_{il } , \\label{eqn : modify2}\\\\ \\eta_i^l(r ) \\!\\!&\\!\\!=\\!\\!&\\!\\ ! \\frac{2 ( ( { \\bf e}_3^t r p_{il})p_{il}^tr^tw - \\|rp_{il}\\|_w^2 { \\bf e}_3^t ) } { ( { \\bf e}_3^t r p_{il})^3}. \\nonumber\\end{aligned}\\ ] ]    let us next consider @xmath281 $ ] .",
    "we first have the equations @xmath282 hence , we also have @xmath283 we also obtain @xmath284 where @xmath285 , @xmath286 and @xmath287 are introduced for notational simplicity . using @xmath288 , we can decompose low and high order terms in @xmath289 as @xmath290 ( [ eqn : app4 ] ) is also simplified as @xmath291 where @xmath292 substituting ( [ eqn : app4 ] ) and ( [ eqn : app6 ] ) into ( [ eqn : app1 ] ) yields @xmath293    let us now compute @xmath294 $ ] . substituting ( [ eqn : app7 ] ) into the definition of the directional derivative ( [ eqn : derivative_lin_m ] ) , i.e. @xmath295 \\!\\!&\\!\\!=\\!\\!&\\!\\!\\lim_{t \\to 0}\\frac{\\bar h^{lj}_i(r + \\xi t ) - \\bar h^{lj}_i(r)}{t } , \\label{eqn : app8}\\end{aligned}\\ ] ] we have @xmath296 = \\frac{\\|rp_{il}\\|_w^2({\\bf e}_3^t r p_{il } ) } { ( { \\bf e}_3^tr p_{il})^3 } \\left(\\frac{d h_i^{lj}}{dt}\\right)(0 ) \\nonumber\\\\ \\hspace{-1.2 cm } & & \\hspace{.2 cm } + 2h_i^{lj}(0 ) \\frac { ( { \\bf e}_3^tr",
    "p_{il})p_{il}^tr^tw\\xi p_{il } -\\|rp_{il}\\|_w^2{\\bf e}_3^t\\xi p_{il } } { ( { \\bf e}_3^tr p_{il})^3 } \\label{eqn : app9}\\end{aligned}\\ ] ] by calculation , the derivative @xmath297 is given by @xmath298 and hence @xmath299 substituting ( [ eqn : app10 ] ) and definitions of @xmath300 and @xmath301 into ( [ eqn : app9 ] ) yields @xmath302 = \\bar \\eta_{i}^{lj}(r ) \\xi p_{il } \\label{eqn : app13}\\\\ \\hspace{-.8cm}&&\\eta_{i}^{lj}(r ) = \\frac{2e^{-\\|b_{lj}\\|^2_{\\sigma_j } } } { \\lambda_i({\\bf e}_3^tr p_{il})^3 } \\big(({\\bf e}_3^tr p_{il})\\xi^{lj}_i(r ) -\\lambda_i\\|rp_{il}\\|_w^2{\\bf e}_3^t \\big ) \\nonumber\\\\ \\hspace{-.8cm}&&\\xi^{lj}_i(r ) =   \\|rp_{il}\\|_w^2b_{lj}^t \\sigma_j ( p_{il } { \\bf e}_3^t - \\lambda_i i_3)r^t + \\lambda_i p_{il}^tr^tw . \\nonumber\\end{aligned}\\ ] ] note that @xmath286 is constant and @xmath303 is independent of the matrix @xmath304 .    from ( [ eqn : obj_single_fict3 ] ) , ( [ eqn : modify2 ] ) and ( [ eqn : app13 ] ) , we obtain @xmath305 = \\tilde \\delta_i   \\eta_i(r ) \\xi p_{il } = { { \\rm tr}}\\big(\\xi^t",
    "\\big(\\tilde \\delta_i \\eta_i^t(r ) p_{il}^t \\big)\\big ) , \\nonumber\\\\ \\hspace{-.8cm}&&\\eta_i(r ) = \\sum_{l \\in \\tilde { { \\cal l}}_i^c(r)}w_{il } \\bar{\\phi }   \\eta_i^l+\\!\\ ! \\sum_{l \\in \\tilde { { \\cal l}}_i(r)}\\!\\ ! w_{il } \\big ( \\bar{\\psi } \\eta_i^l - \\sum_{j=1}^m \\alpha_j \\eta_{i}^{lj } \\big ) .",
    "\\nonumber\\end{aligned}\\ ] ] from definition [ def : grad_m ] , we have @xmath306 .",
    "combining it with lemma 1 and ( [ eqn : proj_so(3 ) ] ) completes the proof .",
    "b. song , c. ding , a. kamal , j. a. farrell and a. roy - chowdhury , `` distributed camera networks : integrated sensing and analysis for wide area scene understanding , '' _ ieee signal processing magazine _ , vol .",
    "3 , pp . 2031 , 2011 .",
    "t. hatanaka and m. fujita , `` cooperative estimation of averaged 3d moving target object poses via networked visual motion observers , '' _ ieee trans .",
    "automatic control _",
    "3 , pp . 623638 , 2013 .",
    "b. m. schwager , b. j. julian , m. angermann and d. rus , `` eyes in the sky : decentralized control for the deployment of robotic camera networks , '' _ proc . of the ieee _",
    "9 , pp . 15411641 , 2011 .",
    "t. hatanaka , y. wasa and m. fujita game theoretic cooperative control of ptz visual sensor networks for environmental change monitoring _ proc . of 52nd ieee conf . on decision and control",
    "_ , to appear , 2013        j. cortes , s. martinez , and f. bullo , `` spatially - distributed coverage optimization and control with limited - range interactions , '' esaim : control , optimisation & calculus of variations , vol .",
    "691719 , 2005 ."
  ],
  "abstract_text": [
    "<S> this paper investigates coverage control for visual sensor networks based on gradient descent techniques on matrix manifolds . </S>",
    "<S> we consider the scenario that networked vision sensors with controllable orientations are distributed over 3-d space to monitor 2-d environment . </S>",
    "<S> then , the decision variable must be constrained on the lie group @xmath0 . </S>",
    "<S> the contribution of this paper is two folds . </S>",
    "<S> the first one is technical , namely we formulate the coverage problem as an optimization problem on @xmath0 without introducing local parameterization like eular angles and directly apply the gradient descent algorithm on the manifold . </S>",
    "<S> the second technological contribution is to present not only the coverage control scheme but also the density estimation process including image processing and curve fitting while exemplifying its effectiveness through simulation of moving objects monitoring . </S>"
  ]
}