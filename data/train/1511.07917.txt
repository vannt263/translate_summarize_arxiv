{
  "article_text": [
    "common images and videos primarily focus on people .",
    "indeed , about @xmath2 of pixels in movies and youtube videos as well as about @xmath3 of pixels in photographs belong to people  @xcite .",
    "this strong bias together with the growing amount of daily videos and photographs urge reliable methods for person analysis in visual data .",
    "person detection is a key component for many tasks including person identification , action recognition , age and gender recognition , autonomous driving , cloth recognition and many others .",
    "while face detection has reached maturity  @xcite , the more general task of finding people in images and video still remains to be very challenging .",
    "for example , state - of - the - art object detectors  @xcite reach only @xmath4 average precision for the person class on the pascal voc benchmark .",
    "common difficulties arise from variations in human pose , background clutter , motion blur , low image resolution , occlusions and poor lighting conditions .",
    "recent advances in convolutional neural networks ( cnn )  @xcite have brought significant progress in image classification  @xcite and other vision tasks . in particular ,",
    "cnn - based object detectors such as r - cnn  @xcite have shown large gains compared to previous models  @xcite .",
    "most of existing methods , however , treat objects independently and model appearance inside object bounding boxes only .",
    "meanwhile , information available in the scene around objects  @xcite as well as relations among objects  @xcite are known to provide complementary contextual cues for recognition .",
    "such cues are likely to be particularly helpful when object appearance lacks discriminative cues due to low image resolution , poor lighting and other factors .    in this work",
    "we build on the recent cnn model for object detection  @xcite and extend it to contextual reasoning .",
    "we particularly focus on person detection and aim to locate human heads on images coming from video data .",
    "the choice of heads is motivated by frequent occlusions of other body parts . when visible , however , other body parts and the rest of the scene constrain locations of heads in the image .",
    "moreover , interactions between people put constraints on the relative positions and appearance of heads .",
    "we aim to leverage such constraints for detection by introducing the following two models .",
    "first , we propose a _",
    "cnn model which we train to predict coarse locations and scales of objects given the full low - resolution image on the input .",
    "in contrast to our base _ local _ model limited to object appearance only , the global model uses all pixels of the image for prediction .",
    "interestingly , we find this simple model to provide quite accurate localization of heads across positions and scales of the image .",
    "second , we introduce a _ pairwise _",
    "cnn model that explicitly models relations among pairs of objects .",
    "motivated by  @xcite , we build a joint score function for multiple object hypotheses in the image .",
    "this score function considers the relative positions , scales and appearance of heads .",
    "all parameters of the score function depend on the image data and are learned by optimizing a structured - output loss function .",
    "our final joint model combines local , global and pairwise cnn models ( see figure  [ fig : teaser ] ) .    to train and test our model",
    ", we introduce a new large dataset with @xmath0 human heads annotated in @xmath1 video frames from 21 movies .",
    "we show the importance of our large dataset for training and evaluate our method on the new and two existing datasets .",
    "the results demonstrate improvements of the proposed contextual cnn model compared to other recent baselines including r - cnn  @xcite on all three datasets .",
    "we also demonstrate a speed - up of object detection provided by our global model .",
    "our new dataset and the code are publicly available from the project web - page  @xcite .",
    "the rest of the paper is organized as follows .",
    "we review related work in section  [ sec : relatedwork ] .",
    "section  [ sec : model ] describes the parts of our contextual cnn model .",
    "section  [ sec : datasets ] introduces datasets followed by the presentation of experimental results in section  [ sec : experiments ] .",
    "section  [ sec : conclusions ] concludes the paper .",
    "the history of object detection with neural networks dates back to the 90s  @xcite , but methods of these group have started to outperform others , e.g dpm  @xcite , only after the seminal work of  @xcite . @xcite and @xcite applied cnn as a sliding window detector at multiple scales .",
    "the r - cnn model  @xcite is a combination of a cnn and a support vector machine ( svm ) operating on object proposals generated by the selective search  @xcite .",
    "the pipeline of our local model is similar to the one of r - cnn ( see section  [ sec : localmodel ] for details ) .",
    "the use of image context was proposed to support object detection in  @xcite .",
    "contextual information can be modeled at a global scene level as well as at the level of object relations .",
    "for example , @xcite propose a crf model for jointly solving the task of object detection and scene classification .",
    "@xcite uses context forest to predict object location and to speed - up object detection using global scene information .",
    "@xcite uses cnn to predict coordinates of object bounding boxes .",
    "our global cnn model predicts likely locations and scales of objects by producing a multi - scale heat map for the whole image .",
    "@xcite models spatial constellations of objects in the image and constructs an energy with unary and pairwise potentials .",
    "unary potentials represent the confidence of object hypotheses based on the local image evidence , while pairwise potentials model spatial arrangement of objects in the image .",
    "@xcite substitute the pairwise dependencies with a latent variable that represents the preferable configuration of object hypotheses . in both works",
    "@xcite binary potentials do not depend on the actual image data , moreover , unary potentials are trained independently of the joint model . our pairwise model exploits object context , i.e.  builds a graphical model ( an energy function ) reasoning about multiple image locations jointly .",
    "our approach is richer compared to  @xcite and  @xcite as it allows pairwise dependencies to be conditioned on the image data and we can train the base detector jointly with the graphical model on top of it .",
    "our pairwise cnn model incorporates the structured - output loss .",
    "the idea of combining the structured - prediction objective with neural networks has been explored in  @xcite .",
    "recently  @xcite and  @xcite use the dual message passing formulation of the inference task to construct a joint objective of the cnn parameters and the message - passing variables .",
    "this approach was applied to the small scale denoising and binary segmentation tasks in  @xcite and to the image tagging and word recognition tasks  @xcite .",
    "@xcite shows how to directly combine the structured svm ( ssvm )  @xcite objective with the procedure of training a cnn for text recognition .",
    "cnns with structured prediction have been recently explored for the task of human pose estimation . @xcite",
    "propose a model with data - dependent pairwise potentials but the different parts of the model were trained separately .",
    "@xcite construct a specific nn that mimicked the behaviour of several rounds of a message - passing inference algorithm .",
    "our pairwise model is trained with an explicit structured - output surrogate loss with an external inference routine inside and enables to fine - tune all the parameters of the model jointly .",
    "this section presents main components of our contextual cnn model . in section  [ sec : localmodel ] , we describe our local model building on r - cnn  @xcite . in section  [ sec : globalmodel ] , we introduce the global cnn model trained to score object proposals using the context of the full image .",
    "section  [ sec : pairwisemodel ] describes our extension of cnns with a structured - output loss function aimed to model pairwise relations between objects .",
    "+      our local model follows r - cnn  @xcite and uses selective search proposals  @xcite to restrict the set of object hypotheses .",
    "we extend the bounding box of each proposal with a small margin to capture local image context around objects .",
    "the image patch corresponding to each proposal is then resized to fit the input layer of the cnn .",
    "as we are interested in head detection , we select bounding boxes with square - like aspect ratios @xmath5 $ ] and refer to them as candidates .",
    "the r - cnn model is based on the alexnet architecture  @xcite pre - trained on the imagenet dataset  @xcite .",
    "we have considered several alternatives including vgg - s  @xcite , vgg - verydeep-16  @xcite and  @xcite . in our experiments",
    "vgg - s slightly outperformed alexnet but was significantly slower in both training and testing . showed better performance but was much slower .",
    "the network of  @xcite had better accuracy and similar speed compared to alexnet ( see section  [ sec : exp : localarch ] for details ) . for experiments in this paper",
    "we use the pre - trained network of  @xcite extended by one fully - connected layer ( with 2048 nodes ) initialized randomly and followed by relu and dropout . to train the network ,",
    "we optimize parameters by minimizing the sum of independent log - losses using stochastic gradient descent ( sgd ) with momentum . differently from r - cnn which deploys the second pass of training using svm",
    ", we use the outputs of cnn to score candidates .",
    "we found this training procedure to work better for our problem compared to the standard r - cnn training .",
    "more details on our training procedure can be found in appendix  [ sec : app : local ] .",
    "+      our global model uses image - level information to reason about locations of objects in the image .",
    "the global model is a cnn that takes the whole image as input and outputs a score for each cell of a multi - scale heat map .",
    "the input image is isotropically rescaled and zero - padded to fit the standard cnn input of @xmath6 pixels .",
    "the output of the network is defined as a multi - scale grid of scores , corresponding to object hypotheses with coarsely discretized locations and scales in the image ( see figure  [ fig : globalmodel_examples ] ) .",
    "object hypotheses form a grid of @xmath7 square cells of four sizes ( 28x28 , 56x56 , 112x112 and 224x224 pixels ) and the stride corresponding to the @xmath8 of cell size . except the output layer ,",
    "the architecture of the global cnn is identical to our local model described in section  [ sec : localmodel ] .",
    "the global cnn is trained with sgd , minimizing the sum of  @xmath9 log - loss functions , one per each grid cell  @xmath10 , @xmath11 where @xmath12 is the output of the network for grid cell @xmath13 of input image @xmath14 ; @xmath15 is the label indicating the class of the grid cell @xmath13 : _ background _ or _",
    "head_. we set the label of a grid cell to  _ head _ if the intersection - over - union ( iou ) overlap - ratio between the cell and any ground - truth bounding box in the image @xmath14 is larger than  @xmath16 , otherwise the label is set to  _",
    "background_. due to the coarse resolution of grid cells , our global model does not provide accurate localization .",
    "we therefore use the global model to rescore the candidates of local and pairwise models . for this purpose , we match each candidate with the corresponding grid cell and compute affine combination of their scores .",
    "each candidate is matched to a grid cell with the maximum iou overlap - ratio .",
    "the parameters of affine score combination are optimized by cross validation on the validation set .",
    "[ fig : structurednetworkscheme ]      in this section we describe our pairwise model that aims to jointly reason about multiple object candidates .",
    "following  @xcite we formulate the model as a joint score function where variables correspond to object candidates .",
    "in the prior work  @xcite unary potentials of the score function are defined by the response of the local object detector at corresponding locations , whereas higher - order potentials model spatial relations between candidates .",
    "our pairwise model enriches the model of  @xcite by making all potentials of the score function   dependent on the image data and , in contrast to  @xcite , allows to perform the joint training of all parameters .",
    "we describe details of our model in section  [ sec : pairwisemodeldetails ] .",
    "we train parameters of our model by minimizing the structured surrogate loss using stochastic gradient descent algorithm .",
    "the details of our training procedure are presented in section  [ sec : trainingpairwise ] .      [ [ score - function . ] ] score function .",
    "+ + + + + + + + + + + + + + +    consider a set of  @xmath17 candidate bounding boxes ( nodes ) extracted from an image .",
    "let each bounding box have a binary variable  @xmath18 , @xmath19 assigned to it .",
    "we associate label  @xmath20 with the object class and label  @xmath21 with the background class .",
    "we assume that the ground - truth labels  @xmath22 are available for all candidates in training images .    for each pair of nodes",
    "we choose an order based on the coordinates of corresponding bounding boxes : the left box is defined to be the first , the right one   the second .",
    "let  @xmath23 denote the set of oriented pairs of candidates ( set of edges ) .",
    "we cluster all edges based on relative locations and scales of bounding boxes to a subset of oriented edges in training images .",
    "edges in this subset connect object candidates with positive labels as well as any other candidates with high scores of the pre - trained local model . for the clustering we use relative location features ( horizontal and vertical displacements , ratio of sizes ) converted to the log scale and normalized to have zero mean and unit standard deviation .",
    "further details of the clustering are available in appendix  [ sec : app : pairwise ] . ] and denote the cluster index of edge  @xmath24 by  @xmath25 .",
    "inspired by  @xcite , we construct a joint score function  @xmath26 that ties together the labels of candidates in the same ] where @xmath27 denotes trainable parameters , @xmath28 and @xmath29 are unary and pairwise potentials depending on  @xmath27 , and @xmath30   is a vector of all binary variables .    note , that different values of potentials in   can lead to exactly the same score function  @xmath31 .",
    "we rewrite eq .",
    "in the more compact form ( the set of all representable functions of binary variables stays the same ) : @xmath32 where unary potentials  @xmath28 and pairwise potentials  @xmath33 are represented by real values .",
    "[ [ connecting - the - score - function - and - the - image . ] ] connecting the score function and the image .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    now we connect the image with potentials of the score function   using several feed - forward neural networks .",
    "first , from the local model described in section  [ sec : localmodel ] we create a feature extractor ( fe ) , i.e.  a function  @xmath34 that constructs feature vector  @xmath35 for the image data  @xmath36 of candidate  @xmath37 : @xmath38 . here",
    "@xmath39 is a vector of trainable parameters of fe .    to connect features  @xmath35 with potentials in   we construct two additional feed - forward networks : the unary network ( un ) and the pairwise network ( pn ) .",
    "the unary network  @xmath40 maps the feature vector  @xmath35 of a candidate  @xmath37 to the value of the corresponding unary potential , i.e.  @xmath41 .",
    "the pairwise network  @xmath42 maps the concatenated feature vectors of its two candidates to a vector  @xmath43 where the @xmath44-th component  @xmath45 corresponds to the one of  @xmath46 cluster indices , i.e.  @xmath47 .",
    "vectors  @xmath48 and  @xmath49 are the trainable parameters of the un and pn , correspondingly .    in our experiments we found the following architectures to work best .",
    "the fe was of the same structure as our local model ( based on the network of  @xcite ) leading to  @xmath50 features . in both un and",
    "pn we use just one fully - connected layer .",
    "addition of more hidden layers did not improve results .",
    "[ [ precision - recall - evaluation . ] ] precision - recall evaluation .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + +    object detection methods are typically evaluated in terms of precision - recall ( pr ) and average precision ( ap ) values . to construct the precision - recall curve given the joint score  , we follow the approach of  @xcite . for each candidate bounding box  @xmath37",
    ", we compute an individual score  @xmath51 defined as the difference of the max - marginals of the joint score @xmath52 the individual scores are used in the standard precision - recall evaluation pipeline  @xcite .",
    "when the number of candidates is small , i.e.  @xmath53 , both maximization problems of   can be solved exactly using exhaustive search .",
    "when the number of candidates becomes larger , the exhaustive search becomes too slow . in this case",
    "one can use the cascade of qpbo  @xcite and trw - s  @xcite methods to approximate  @xmath54 .",
    "specifically , qpbo allows to quickly determine the optimal label for some candidates . on our dataset",
    "qpbo works surprisingly well , i.e. ,  in many cases it is able to label all nodes .",
    "if some nodes are unlabeled by qpbo , one can apply the exhaustive search when the number of unlabelled nodes is at most 20 and trw - s otherwise .",
    "we have tried using 16 and 32 candidates per image .",
    "the exact inference is tractable only in the first case . in this paper",
    "we use 16 candidates per image as the large number of candidates did not improve performance on our validation set .",
    "we train parameters of our model by minimizing a structured surrogate loss using the stochastic gradient descent algorithm .",
    "the algorithm for parameter update consists of the following four steps :    1 .",
    "[ step : nms]select the set of candidates by applying the non - maximum suppression  @xcite on top of the scores produced by the local model .",
    "[ step : forward ] perform the forward pass through the model to compute potentials of the joint score function .",
    "[ step : inference ] perform the inference to compute the structured loss and its gradient ( see below ) .",
    "[ step : backprop ] back - propagate the gradient through the model .",
    "we explain details of the algorithm below .",
    "[ [ structured - surrogate - loss . ] ] structured surrogate loss .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    a structured loss is a function that maps the current values of parameters , image data @xmath55 and the ground - truth labeling  @xmath56 to a real number . a popular choice for the surrogate loss for structured - prediction tasks is the structured svm ( ssvm ) objective  @xcite : @xmath57 where @xmath58 measures the agreement between the two labelings .",
    "possible choices for  @xmath59 include the hamming loss , the hamming loss with penalties normalized by the frequency of classes , or higher - order losses making use of assumption that each ground - truth object is assigned to exactly one object candidate  @xcite .",
    "notice , that in   the joint score  @xmath31 depends on parameters  @xmath27 and image data  @xmath60 implicitly through potentials @xmath61 and @xmath62 .",
    "however , in our experiments we have observed that the ssvm loss is less suited for the detection task , i.e.  optimizing the objective   does not lead to good results in terms of precision - recall measure . to tackle this problem",
    ", we propose a new surrogate loss which directly imposes penalties on the wrong values of individual scores   extracted from the joint score  @xmath31 .",
    "specifically , this loss can be written as @xmath63 where @xmath64 can be any non - increasing function bounded from below .",
    "we use @xmath65 which brings us closer to the training of conventional detector with a soft - max loss .",
    "[ [ gradient - of - the - structured - loss . ] ] gradient of the structured loss .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    to optimize the structured loss w.r.t .",
    "the model parameters  @xmath27 , we need to compute the gradient of the objective w.r.t .  model parameters .",
    "we can always achieve this goal using the back - propagation method under two assumptions : 1 ) the gradient can be back - propagated through the modules of the model , i.e.  all the partial derivatives of @xmath34 , @xmath40 , @xmath66 w.r.t .",
    "the input and the parameters can be computed ; 2 ) the scores of the candidates   can be computed exactly .    to start the back - propagation procedure , we compute the gradient of structured loss w.r.t .",
    "potentials @xmath28 , @xmath45 of the joint score function  @xmath31 .",
    "@xcite have in details explained how to do this for the ssvm loss  .",
    "here we explain how to differentiate the loss  .",
    "first , the gradient of the loss   w.r.t .  the scores can be expressed as @xmath67 the gradient of the score ( when existent ) w.r.t .",
    "potentials can be computed exactly if we can compute all max - marginals exactly : @xmath68\\ ] ] where @xmath69 is the @xmath70-th component of @xmath71 for @xmath72 . here , @xmath73 $ ] is the iverson bracket notation . combining the two derivatives via the chain rule",
    "we get @xmath74    [ [ back - propagation - of - the - gradient . ] ] back - propagation of the gradient .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the next step of the back - propagation procedure is to compute the derivatives of the loss w.r.t .",
    "parameters of the un and pn @xmath75 and w.r.t .  the output of the feature extractor @xmath76 notice that all the derivatives of potentials w.r.t .",
    "parameters and features can be computed by propagating the gradient through networks @xmath40 and @xmath66 .",
    "finally , propagation of the gradient   through @xmath34 gives us the direction of the update for parameters  @xmath39 of the fe .",
    "in this section we present our new head detection dataset , hollywoodheads ( hh ) , and discuss two other datasets we use for evaluation : tvhi  @xcite and casablanca  @xcite .",
    "hollywoodheads dataset contains @xmath0 human heads annotated in @xmath1 video frames from 21 hollywood movieslist of movies used in hollywoodheads dataset .",
    "training set : _ american beauty _ , _ as good as it gets _ , _ big fish _ ,",
    "_ big lebowski _ , _ bringing out the dead _ , _ capote _ , _ clerks _ , _ crash _ , _ dead poets society _ , _ double indemnity _ , _ erin brockovich _ , _ fantastic 4 _ , _ fargo _ , _ fear and loathing in las vegas _ , _ fight club_. validation set : _ five easy pieces _ , _ forrest gump _ , _ gang related_. test set : _ gandhi _ , _ charade _ , _ i am sam_. ] .",
    "the movies vary in genres and represent different time epochs .",
    "to create annotation , we have manually annotated tracks of human heads in action - rich movie clips . for each head track , head bounding boxes ,",
    "i.e. ,  the smallest axis - parallel rectangles including all visible pixels of the head , were manually annotated on several key frames .",
    "the bounding boxes on remaining frames were linearly interpolated and manually verified to be correct . in total",
    ", we have collected @xmath77 clips with @xmath78 human tracks , spanning over @xmath79 hours of video .",
    "the dataset is divided into the training , validation and test subsets which have no overlap in terms of movies .",
    "given the redundancy of consequent video frames , we have temporally subsampled videos in the validation and test subsets . in summary ,",
    "the training set of hollywoodheads contains @xmath80 frames from @xmath81 movies , the validation set contains @xmath82 frames from @xmath83 movies and the test set contains @xmath84 frames from another set of @xmath83 movies .",
    "human heads with poor visibility ( e.g. ,  strong occlusions , low lighting conditions ) were marked by the `` difficult '' flag and were excluded from the evaluation .",
    "the hollywoodheads dataset is available from  @xcite .",
    "the extended tv human interaction ( tvhi ) dataset  @xcite consists of @xmath85 frames of tv show episodes annotated with bounding boxes of human upper bodies .",
    "frames are split into the two sets : @xmath86 for training and @xmath87 for testing . to evaluate head detection using upper - body annotation ,",
    "we have applied bounding - box regression to the output of head detectors  @xcite .",
    "the parameters of regression were tuned on the tvhi training subset for each tested method .",
    "the casablanca dataset  @xcite contains @xmath88 frames from the movie `` casablanca '' .",
    "the frames are annotated with head bounding boxes , however , the annotation of frontal heads is typically reduced to face bounding boxes and , therefore differs in the scale and aspect ratio from the hollywoodheads annotation .",
    "given some mistakes in the original annotation of  @xcite , we have added missing bounding boxes for heads of all people in the foreground .",
    "we have also applied bounding - box regression  @xcite to compensate for differences in annotation policies .",
    "this section presents our experimental results .",
    "first , we demonstrate the effect of different combinations of proposed models ( section  [ sec : exp : modelvariants ] ) and provide the comparison with the state - of - the - art  ( section  [ sec : exp : rcnncomparison ] ) .",
    "section  [ sec : exp : localarch ] compares different architectures of the local model .",
    "we then justify the need of our new large dataset for training  ( section  [ sec : exp : trainingsize ] ) and show improvements in computational complexity that can be achieved with the global model  ( section  [ sec : exp : speedup ] ) .",
    "to evaluate the detection performance , we use the standard average precision ( ap ) measure based on the precision - recall ( pr ) curve  @xcite . detections having high overlap ratio with the ground truth ( iou  >  0.5 ) are considered as true positives .",
    "multiple detections assigned to the same ground truth are penalized and declared as false positives .",
    "matches to `` difficult '' head annotations are ignored in the evaluation , i.e.  such detections are considered neither as true positives nor as false positives .",
    "we compare performance of the following four models : the local model ( sec  .[sec : localmodel ] ) , the combination of the local and global models ( section  [ sec : globalmodel ] ) , the combination of the local and pairwise models  ( section  [ sec : pairwisemodel ] ) and the combination of all the three proposed models .",
    "the performance of head detection is evaluated on hollywoodheads , casablanca and tvhi datasets .",
    "qualitative results of the global and pairwise models are illustrated in figures  [ fig : globalmodel_examples ] and  [ fig : resultspairwiseterm ] respectively .",
    "table  [ tbl : our_performance_exp ] presents quantitative results for all models .",
    "we observe that the global and pairwise models consistently improve the performance of the baseline local model .",
    "the combination of all three models demonstrates the best performance on all three datasets .    [ cols=\"^,^ \" , ]     [ fig : app : resultspairwiseterm ]",
    "in this section we illustrate multi - scale grids of scores produced by the global model ( see section  [ sec : globalmodel ] ) .",
    "each output consists of @xmath89 , @xmath90 , @xmath91 and @xmath92 score grids corresponding to grids of cells with @xmath93 , @xmath94 , @xmath95 and @xmath96 pixels .",
    "figures  [ fig : globalmodel_qual_examples ] illustrates the output of the global model for a few test examples .",
    "note high responses at positions and scales corresponding to human heads in the image .      in figure",
    "[ fig : app : resultspairwiseterm ] we provide a few qualitative results of our pairwise model .",
    "the bounding boxes and the links in this figure have the same meaning as the ones in figure  4 of the main paper .",
    "we use the same thresholds for the links and the candidates as in figure  [ fig : resultspairwiseterm ] of the main paper .",
    "i.  tsochantaridis , t.  joachims , t.  hofmann , and y.  altun , `` large margin methods for structured and interdependent output variables , '' _ journal of machine learning research ( jmlr ) _ , vol .  6 , pp .",
    "14531484 , 2005 ."
  ],
  "abstract_text": [
    "<S> person detection is a key problem for many computer vision tasks . while face detection has reached maturity , detecting people under a full variation of camera view - points , human poses , lighting conditions and occlusions </S>",
    "<S> is still a difficult challenge . in this work we focus on detecting human heads in natural scenes . </S>",
    "<S> starting from the recent local object detector , we extend it with two types of contextual cues . </S>",
    "<S> first , we leverage person - scene relations and propose a global cnn model trained to predict positions and scales of heads directly from the full image . </S>",
    "<S> second , we explicitly model pairwise relations among objects and train a pairwise cnn model using a structured - output surrogate loss . the local , global and pairwise models </S>",
    "<S> are combined into a joint cnn framework . to train and test our full model , we introduce a large dataset composed of @xmath0 human heads annotated in @xmath1 movie frames . </S>",
    "<S> we evaluate our method and demonstrate improvements of person head detection against several recent baselines in three datasets . </S>",
    "<S> we also show improvements of the detection speed provided by our model . </S>"
  ]
}