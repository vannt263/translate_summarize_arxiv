{
  "article_text": [
    "complex networks are used to represent and analyze a wide range of systems  @xcite .",
    "models of complex networks usually aim for simplicity and attempt to keep the number of parameters as low as possible . however , real data is more complex than any simple model which makes it difficult to draw clear links between data and models . to capture the increasingly available massive real data  @xcite , we need high - dimensional models where the number of parameters grows with the number of nodes .",
    "an example of such a model is the latent space model  @xcite where nodes are assigned independent and identically distributed vectors and the probability of a link connecting two nodes depends only on the distance of their vectors .",
    "while there are plenty of simple ( and not so simple ) network models , little is known as to which of them are really supported by data .",
    "while calibration of complex network models often uses standard statistical techniques , their validation is typically based on comparing their aggregate features ( such as the degree distribution or clustering coefficient ",
    "see  @xcite for detailed accounts on network measurements ) with what is seen in real networks ( see  @xcite for recent examples of this approach ) .",
    "the focus on aggregate quantities naturally reduces the discriminative power of model validation which is often further harmed by the use of inappropriate statistical methods  @xcite . as a result , we still lack knowledge of what is to date the best model explaining the growth of the scientific citation network , for example .    we argue that network models need to be evaluated by robust statistical methods  @xcite , especially by those that are suited to high - dimensional models  @xcite .",
    "this is exemplified in  @xcite where various low - dimensional microscopic mechanisms for evolution of social networks are compared on the basis of their likelihood of generating the observed data .",
    "prohibitive computational complexity of maximum likelihood estimation is often quoted as a reason for its limited use in the study of real world complex networks  @xcite .",
    "however , as we shall see here , even small subsets of data allow to discriminate between models and point clearly to those that are actually supported by the data .",
    "this , together with the ever - increasing computational power at our disposal , opens the door to the likelihood analysis of complex network models .",
    "we analyze here a recent network growth model  @xcite which naturally leans itself to high - dimensional analysis .",
    "this model generalizes the classical preferential attachment ( pa ; often referred to as the barabsi - albert model in the complex networks literature ) ( * ? ? ?",
    "* sections  7 ,  8) by introducing node relevance which decays in time and co - determines ( together with node degree ) the rate at which nodes acquire new links .",
    "if either the initial relevance values or the functional form of the relevance decay are heterogeneous among the nodes , this model is able to produce various realistic degree distributions .",
    "by contrast to  @xcite which modifies preferential attachment by introducing an additive heterogeneous term , in  @xcite relevance combines with degree in a multiplicative way which means that once it reaches zero , the degree growth stops .",
    "this makes the model an apt candidate for modeling information networks where information items naturally lose their pertinence with time and the growth of their degree eventually stops .",
    "( see  @xcite for a review of work on temporal networks . )",
    "this model has been recently used to quantify and predict citation patterns of scientific papers  @xcite .    before methods for high - dimensional parameter estimation",
    "are applied to real data , we calibrate and evaluate them on artificial data where one has full control over global network parameters ( size , average degree , etc . ) and true node parameter values are known . for simplicity ,",
    "we limit our attention to the case where the functional form of relevance decay is the same for all nodes and only the initial relevance values differ .",
    "we present here various estimation methods and evaluate their performance .",
    "plain maximum likelihood  ( * ? ? ?",
    "* chapter  7 ) produces unsatisfactory results , especially in the case of sparse networks which are commonly seen in practice .",
    "we enhance the method by introducing an additional term which suppresses undesired correlation between node age and estimates of initial relevance .",
    "we then introduce a mean - field approach which allows us to reduce high - dimensional estimation to a low - dimensional one .",
    "calibration and evaluation of these parameter - estimation methods is done on artificial data .",
    "real data is then used to employ the established framework and compare the statistical evidence for several low- and high - dimensional network models on the given data .",
    "analysis of small subsets of input data is shown to efficiently discriminative among the available models .",
    "since this work focuses on model evaluation , estimated parameter values are thus of secondary importance to us .",
    "necessary conditions for obtaining precise estimates and the potential risk of large errors  @xcite are therefore left for future research ( see sec .  [",
    "sec : conclusions ] ) .",
    "the original model of preferential attachment with relevance decay ( pa - rd ) has been formulated for an undirected network where the initial node degree is non - zero because of links created by the node on its arrival  @xcite . to allow zero - degree nodes to collect links , some additive attractiveness or random node selection",
    "need to be introduced .",
    "when these two mechanisms are combined with pa - rd , the probability that a new link created at time @xmath0 attaches to node @xmath1 can be written as @xmath2 here @xmath3 and @xmath4 are degree and relevance of node @xmath1 at time @xmath0 , respectively , @xmath5 is the number of nodes present at time @xmath0 , and @xmath6 is the additive attractiveness term . finally , @xmath7 is the probability that the node is chosen by the pa - rd mechanism ; the node is chosen at random with the complementary probability @xmath8 .",
    "when @xmath9 and @xmath10 , a node of zero degree will never attract new links .",
    "( [ pard ] ) can be used to model a monopartite network where nodes link to each other as well as a bipartite network where one set of nodes is unimportant and we can thus speak of outside links attaching to nodes . for example , one can use the model to describe the dynamics of item popularity in a user - item bipartite network representing an e - commerce system  @xcite .",
    "there are now two points to make .",
    "firstly , the model is invariant with respect to the rescaling of all relevance values , @xmath11 .",
    "this may lead to poor convergence of numerical optimization schemes because @xmath4 values can drift in accord without affecting the likelihood value .",
    "the convergence problems can be avoided by imposing an arbitrary normalization constraint on the relevance values as we do below .",
    "secondly , @xmath6 and @xmath7 act in the same direction : they introduce randomness in preferential attachment - driven network growth ( in particular , as @xmath12 and/or @xmath13 , preferential attachment loses all influence ) .",
    "one can therefore expect that @xmath6 and @xmath7 are difficult to be simultaneously inferred from the data .",
    "this is especially true for the original preferential attachment without decaying relevance .",
    "if node relevance decays to zero , node attraction due to @xmath6 eventually vanishes while the random - attachment part proportional to @xmath7 remains  it is therefore possible , at least in principle , to distinguish between the two effects . to better focus on the high - dimensional likelihood maximization of node parameters , we assume @xmath10 in all our simulations .",
    "the pa - rd model has been solved in  @xcite for a case where @xmath10 , @xmath9 , and the initial degree of all nodes equal to one .",
    "it was further assumed that @xmath14 is finite for all nodes and the distribution of @xmath15 values among the nodes , @xmath16 , decays exponentially or faster .",
    "the probability normalization term @xmath17 then eventually fluctuates around a stationary value @xmath18 and the expected final degree of node @xmath1 can be written as @xmath19 .",
    "it has been shown that the network s degree distribution , shaped mainly by @xmath16 , can take on various forms including exponential , log - normal , and power - law .",
    "we begin by describing bipartite network data with temporal information .",
    "we consider a simplified bipartite case where links arrive from outside and thus only their target nodes matter  see fig .",
    "[ fig : network]a for illustration .",
    "links are numbered with @xmath20 and the times at which they are introduced are @xmath21 .",
    "nodes are numbered with @xmath22 and the times at which they are introduced are @xmath23 . at time @xmath0 , there are @xmath5 target nodes in the network",
    ". degree of node @xmath1 at time @xmath24 when link @xmath25 is added is @xmath26 and",
    "the target node of link @xmath25 is @xmath27 .",
    "the average node degree is @xmath28 ( the factor of two is missing here because we consider a bipartite network where @xmath29 edges point to @xmath30 nodes of interest ) .",
    "we use the pa - rd model to create artificial networks with well - defined properties .",
    "there are initially @xmath31 nodes with zero degree . after every @xmath32 time steps",
    ", a new node of zero degree is introduced in the network . in each time step ,",
    "one new link is created and chooses its target node according to eq .",
    "( [ pard ] ) .",
    "the network growth stops once there are @xmath33 links and @xmath34 nodes in the network . at that point , the average node degree is approximately @xmath35 . it must hold that @xmath36 ; in the opposite case , the average degree @xmath35 can not be achieved because new nodes dilute the network too fast .",
    "each node has the relevance decay function @xmath37 $ ] where @xmath38 is the decay time scale and @xmath39 is the initial relevance of node @xmath1 .",
    "initial relevance values are drawn from the exponential distribution @xmath40 .",
    "when the decay parameter @xmath38 is sufficiently high , this setting produces broad degree distributions  @xcite which are similar to distributions often seen in real information networks  ( * ? ? ?",
    "* chapter  4 ) .",
    "we use @xmath41 , @xmath42 , @xmath43 , @xmath44 , and @xmath45 for all artificial networks studied here ; their sample degree distributions are shown in fig .",
    "[ fig : network]b .",
    "we first use the standard maximum likelihood estimation ( mle ) to estimate parameters of the pa - rd model  @xcite . a generic form of log - likelihood of realization @xmath46 for a network growth model @xmath47 has the form @xmath48 where @xmath49 is the probability of link @xmath25 arriving at node @xmath27 at time @xmath24 under model @xmath47 .",
    "it is convenient to transform this quantity into log - likelihood per link by dividing it with the number of links , @xmath50 . for model @xmath47 represented by its attachment probability @xmath49 and a vector of model parameters @xmath51 , log - likelihood",
    "can be maximized with respect to these parameters and yields their estimates @xmath52 .    given a network realization obtained with eq .",
    "( [ pard ] ) , there are several parameters to estimate : initial relevance values of all nodes , additional attractiveness term @xmath6 , and parameters of the relevance decay function .",
    "( note that we make the estimation task easier by assuming that the functional form of relevance decay is known . )",
    "greedy ( uphill ) maximization of log - likelihood is made possible by the profile of the likelihood function which does not feature multiple local maxima in the space of initial relevance values ( see sec .",
    "[ sec : maxima ] for an explanation ) . starting from a random initial guess",
    ", we sequentially update all model parameters by quadratic extrapolation and repeat this process until the difference between new and old estimates is less than some sufficiently small threshold ( we use @xmath53 here ) . due to the scale - invariance of relevance values",
    ", they can be normalized after each iteration so that their average is one , which improves convergence . while each evaluation of log - likelihood is time consuming and this straightforward approach is thus computationally expensive , it is often , as we shall show , viable .      as mentioned in sec .",
    "[ sec : model ] , when the number of nodes is large and their relevance decays to zero , fluctuations of the denominator in eq .",
    "( [ pard ] ) become small and one can therefore replace it with a constant term @xmath18 .",
    "this mean - field approximation decouples the dynamics of nodes which then compete for new links with the external field @xmath18 instead of competing with the other nodes present in the system .",
    "( [ pard ] ) then simplifies to @xmath54 where @xmath55 is a vector of parameters of node @xmath1 and we again assume @xmath10 . in our case , the initial relevance value @xmath39 is the only node - specific parameter and thus @xmath56 . since @xmath18 is the same for all nodes , we can subsume it in @xmath39 due to the aforementioned scale invariance . the likelihood function for node @xmath1",
    "is then constructed by evaluating all links created after this node has been introduced in the network . for link",
    "@xmath25 , we assess whether the link points to node @xmath1 ( then @xmath57 ) or not ( then @xmath58 ) .",
    "we get @xmath59\\end{gathered}\\ ] ] where we ignore links that are older than node @xmath1 .",
    "this function can be maximized with respect to @xmath60 for any given @xmath6 .",
    "global model parameters such as , in our case , @xmath6 and the time scale of relevance decay @xmath38 can be estimated by minimizing @xmath61 with respect to them ( estimates @xmath62 then need to be updated to reflect new values of the global parameters ) .",
    "mf - mle makes it easy to change the functional form of relevance decay @xmath63 for any individual node and thus classify their behavior ( see  ( * ? ? ?",
    "* chapter  8) for more information on classification problems ) .",
    "while we do not pursue this direction here , it is of particular significance to the analysis of real data where various behavioral classes of nodes are likely to coexist .",
    "also , the vector of node parameters can be easily extended by , for example , making the decay time @xmath38 node - dependent , while still maintaining the low - dimensional nature of the resulting likelihood optimization .",
    "to evaluate various estimation methods , we assess the maximal likelihood that they are able to achieve .",
    "parameter estimation is simplified by assuming that the functional form of relevance decay is known and only model parameters @xmath64 are to be estimated .",
    "since the true parameter values are available to us , we also measure pearson s correlation between true values @xmath65 and their estimates @xmath66 , @xmath67 ( the higher the value , the better the estimates ) . in evaluating this correlation ,",
    "nodes with final degree four and less are excluded because their estimates are too noisy due to the lack of data .",
    "the advantage of using pearson s correlation to measure the accuracy of estimates lies in its invariance with respect to rescaling of @xmath68 which fits well with the scale - invariance of the pa - rd model itself .",
    "the accuracy of estimates of @xmath6 and @xmath38 is measured as well .",
    "+    simulations reveal that mle sometimes converges to estimates which are far from the true parameter values .",
    "to explain the reason for this behavior , fig .",
    "[ fig : profile ] shows the results of constrained likelihood maximization where we artificially fix @xmath6 and @xmath38 at various values , many of which are far from the true values @xmath44 and @xmath43 . the corresponding maximal log - likelihood values exhibit a shallow maximum in @xmath6 with the optimal value @xmath69 lying significantly above the true value @xmath70 .",
    "worse , the maximum in @xmath38 is non - existent : as @xmath38 increases , log - likelihood increases too and saturates at a value which is maintained also in the limit @xmath71 ( _ i.e. _ , no relevance decay ) . resulting @xmath72 thus depends on the initial values of model parameters and the procedure in which they are iteratively improved in the search for maximal likelihood . while fig .",
    "[ fig : profile ] shows results for one network realization , the same behavior can be seen for all realizations of the input artificial network .",
    "inspection of the initial relevance values estimated for large @xmath38 makes it clear that the lack of relevance decay is then compensated by later nodes being assigned higher initial relevance than earlier ones . as a result , mle estimates then do not reflect the true initial relevance values but rather the order in which nodes are introduced in the network .",
    "this is demonstrated by the second panel of fig .",
    "[ fig : profile ] where @xmath67 reaches maximum for @xmath38 close to the true value of @xmath73 and then quickly drops to negative values for larger values of @xmath38 .",
    "the negative correlation values are observed here because in this particular network realization , node arrival times are negatively correlated with their initial relevance values .",
    "the overall maximum of @xmath74 lies at @xmath75 and @xmath76 .",
    "the problem of excessive estimated decay time @xmath38 can be solved by introducing an additional term in log - likelihood with the aim to penalize solutions with high @xmath38 .",
    "this is similar to regularization schemes such as lasso  @xcite which are often used to constraint solutions in high - dimensional optimization problems  @xcite .",
    "we choose here to maximize @xmath77\\ ] ] where @xmath78 for @xmath79 and @xmath80 otherwise ; the additional term penalizes positive correlation between nodes arrival times and their estimated initial relevances . as shown in fig .",
    "[ fig : omega ] , mle estimates with the correlation term @xmath81 are superior to the original ones over a broad range of @xmath82 .",
    "the difference is particularly large for sparse networks where standard mle strongly overestimates @xmath38 .",
    "note that unlike for large parts of fig .",
    "[ fig : profile]b , the average correlation value @xmath74 in fig .  [ fig : omega ] is positive even when @xmath72 is large .",
    "this is because while fig .",
    "[ fig : profile ] presents outcome for a single network realization , fig .",
    "[ fig : omega ] averages over many of them and the resulting average correlation is positive .",
    ".estimates obtained with respective methods for @xmath83 ( which corresponds to @xmath84 , @xmath85 ) . numbers in brackets report uncertainty of the last digit given by the standard error of the mean . [ cols=\">,>,>,>,>\",options=\"header \" , ]",
    "to illustrate the potential of high - dimensional statistical analysis of network data , we finally apply it to real data and compare the level of support which it gives to various network models .",
    "the analyzed data originates from the interdisciplinary physics community web site _",
    "econophysics forum _ ( see www.unifr.ch/econophysics ) which is run by the research group of yi - cheng zhang at the university of fribourg since 1998 .",
    "we parsed server web log files collected from 6th july 2010 until 31st march 2013 ( a time span of 1000 days ) .",
    "activities of web bots and other automated access were removed from the data .",
    "while web logs contain all user actions on the web site , we kept only entries corresponding to downloads of papers posted on the econophysics forum .",
    "the corresponding user - paper bipartite network consists of 844 paper - nodes and their 24,581 links  @xcite .",
    "as expected , the degree distribution of paper - nodes is broad ( the maximal degree of 741 is much greater than the average degree of 29 ) , making this data a good candidate for being explained by preferential attachment or related models .",
    "we use this data to evaluate two low - dimensional and four high - dimensional models .",
    "the low - dimensional models are : random attachment to an existing node ( rand ) and the standard preferential attachment ( pa ) .",
    "the high - dimensional models are : preferential attachment with heterogeneous ( node - dependent ) additive term ( pa - h ) , preferential attachment with heterogeneous and decaying additive term ( pa - hd ) which has been introduced in  @xcite , preferential attachment with constant relevance ( pa - r ; such constant relevance is usually referred as fitness in past works  @xcite ) , and finally preferential attachment with relevance decay ( pa - rd ) .",
    "the functional form of the probability of a new link attaching to an existing node at time @xmath0 , @xmath86 , is shown in tab .",
    "[ tab : results ] for each model .",
    "the form of @xmath87 suggested for pa - hd in  @xcite is generalized to @xmath88 $ ] which in our case performs better than the original form without @xmath89 .",
    "note that  @xcite reports a similar behavior in the popularity growth of stories in digg.com . for simplicity",
    ", we assume a similar form of @xmath4 in pa - rd , @xmath90 + r_{\\infty}$ ] , which in fact roughly corresponds to the empirical relevance decay results presented in  @xcite . a non - vanishing absolute term @xmath91 is needed here to allow for links occasionally attaching to old nodes .",
    "the log - normal decay form reported in @xcite does not yield better fit in our case , perhaps as a result of immediate response of the econophysics forum users which makes the increasing relevance phase provided by log - normal curves unfitting . for pa - rd ,",
    "we report results obtained with the penalization term ( @xmath92 ) which , however , differ little from the results obtained with @xmath93 .    to maximize the likelihood functions we use the iterative extrapolating approach described in sec .",
    "[ sec : mle ] .",
    "this procedure is run ten times with independent random initial configurations ; the best result obtained with each method is reported in table  [ tab : results ] .",
    "in addition , the table shows also the number of model parameters @xmath94 and the corrected akaike information criterion @xmath95 where the maximum is taken over the whole parameter space of model @xmath96 .",
    "@xmath97 measures how well model @xmath96 fits the data and corrects for a finite sample size  @xcite .",
    "it can be used to construct model weights  @xcite in the form @xmath98\\ ] ] where the proportionality factor is obtained by requiring the sum of all model weights to equal one . finally , we report the values of global model parameters that maximize data likelihood for each model .",
    "our comparison of models contains several notable outcomes .",
    "firstly , both low - dimensional models are clearly insufficient to explain the data .",
    "in fact , preferential attachment yields only marginally better fit than random attachment .",
    "secondly , high - dimensional models without time decay perform significantly worse than their counterparts with time decay .",
    "this is not surprising because we fit the models to an information network where , as argued in  @xcite , aging of nodes is of prime importance .",
    "thirdly , while the log - likelihood values obtained with pa - hd and pa - rd are both substantially better than those obtained for other models , the difference between them is big enough for the akaike information criterion to assign an overwhelming weight to pa - rd .",
    "( the resulting weight of pa - hd , which has been truncated to zero in table  [ tab : results ] , is around @xmath99 . )    for pa - rd , the effective lifetime corresponding to the obtained relevance decay parameters is @xmath100 where we neglect @xmath91 which is small , yet it formally causes the above - written expression to diverge .",
    "this lifetime well agrees with the fact that papers typically spend one week on the front page of the econophysics forum .",
    "the value of the additive term @xmath101 is relatively high in comparison with the average node degree of @xmath102 which suggests that in the studied dataset , the influence of preferential attachment ( _ i.e. _ , attachment probability proportional to node degree ) is relatively weak .",
    "an alternative explanation is that our assumed relevance decay function @xmath63 disagrees with the data and thus an increased proportion of `` random '' connections is necessary to model the data .",
    "a more detailed analysis is necessary to establish what is the real reason behind this apparent randomness .    since likelihood computation is costly and during its maximization in numerous variables it needs to be carried out many times , obtaining the results presented in table  [ tab : results ] on a standard desktop computer takes several hours .",
    "it is thus natural to ask whether significant evidence in favor of one of the models can not be obtained by analyzing subsets of the data which would save considerable computational time . to this end , we evaluated weights of three representative models ( pa , pa - hd , and pa - rd ) on data subsets corresponding to time spans ( which we refer to as subset lengths , @xmath103 ) ranging from 4 to 100 days ; the starting .",
    "we generated many subsets for each @xmath103 by choosing their starting day at random .",
    "results shown in fig .  [ fig : weights ] demonstrate that while particularly short subsets favor the low - dimensional pa model , the situation quickly changes and this model is virtually eliminated as soon as @xmath104 .",
    "two high - dimensional models , which enjoy comparable support until @xmath105 , are clearly distinguished at @xmath106 and above . meanwhile ,",
    "evaluation of multiple small - scale subsets is fast : the computational time required for one likelihood maximization of pa - rd drops from 10 minutes for the whole 1000-day data spanning to 2 seconds for a 100-day subset .",
    "we can conclude that this approach allows us to efficiently discriminate between models even when no particularly efficient approach to likelihood maximization is available .",
    "we studied the use of maximum likelihood estimation in analysis of high - dimensional models of growing networks .",
    "artificially created networks with preferential attachment and decaying relevance  @xcite were used to show that a near - flat likelihood landscape makes the standard likelihood maximization rather unreliable and sensitive to the initial choice of model parameters . introducing a penalization term effectively modifies the landscape and helps to avoid `` wrong '' solutions .",
    "the resulting mle - based scheme outperforms the standard likelihood maximization for a wide range of model networks . on the other hand ,",
    "both original and modified mle overestimate the additive parameter @xmath6 which is crucial in the early stage of a node s degree growth .",
    "how to improve on that remains an open question .",
    "we then tested the previously developed methods on real data where both preferential attachment and relevance decay are expected to play a role . in this part ,",
    "the focus is on comparing various competing network models that may be used to explain the data .",
    "we show that the data shows overwhelming evidence in favor of one of the models and that sufficiently strong evidence can be achieved by studying small subsets of the data .",
    "model evaluation by such subset sampling is of particular importance to large - scale datasets where straightforward likelihood maximization is prohibitively time - consuming .    up to now",
    ", models of complex networks have been appraised mostly by comparing aggregate characteristics of the produced networks ( degree distribution or clustering coefficient , for example ) with features seen in real data .",
    "the caveat of this approach is that many network characteristics are computed on static network snapshots and are thus of little use for the measurement of growing networks .",
    "empirical node relevance  @xcite is designed especially for growing networks but more metrics , targeted at specific situations and questions , are needed .    despite potential improvements in this direction , to gain _ real _ evaluative and discriminative power over network models , robust statistical methods such as maximum likelihood estimation need to be relied on .",
    "we have made a step in this direction which , hopefully , will contribute to consolidating and further developing the field of network models .",
    "open issues include estimates of parameter uncertainty in the case of real data by bootstrap methods  @xcite , identification of situations where maximum likelihood estimates converge to true parameter values ( including model misspecification as in  @xcite which is of particular importance to parameter estimates in complex systems ) , and improvements of the mean - field likelihood estimation which was introduced in sec .  [ sec : mf - mle ] .",
    "it needs to be stressed that the potential impact of parameter estimation far exceeds the academic problem of model validation : model parameters , once known , can be directly useful in practice . in the case of preferential attachment with relevance decay , for example",
    ", the overall rate of relevance / interest decay is closely connected to the most successful strategy in the competition for attention  @xcite . on the other hand ,",
    "the initial , current , or total relevance values of individual items can be used to detect which items deserve to be examined more closely .",
    "this work was supported by the eu fet - open grant no .",
    "231200 ( project qlectives ) and by the swiss national science foundation grant",
    "200020 - 143272 .",
    "greedy sequential optimization is possible because the likelihood function in our case does not have a large number of disparate local minima .",
    "we explain this fact for the pa - rd model which is parametrized by the initial node relevances @xmath39 and global parameters @xmath6 and @xmath38 .",
    "@xcite shows that the expected final degree of node @xmath1 grows with @xmath39 which implies that @xmath107 has a unique maximum in @xmath39 when all other parameters are fixed .",
    "likelihood of the data thus has a unique maximum in the space of all initial relevance values .",
    "similar behavior can be observed for @xmath6 . when @xmath12 , likelihood of the artificial data is small because the model simplifies to random attachment which is obviously at odds with the data .",
    "as @xmath6 decreases , the likelihood grows but it eventually saturates and decreases when @xmath6 becomes so small that new nodes can not attract their first links .",
    "the case is different for @xmath38 .",
    "its extremely small values can be easily refuted by the data as they would imply links always arriving at the latest node . on the other hand",
    ", large @xmath38 can be accommodated by an appropriate choice of the initial relevance values which is demonstrated by fig .",
    "[ fig : profile ] . to prevent the sequential updating of parameters from converging to a wrong solution",
    ", one can for example add a suitable penalization term as we do in eq .",
    "( [ llpenalized ] ) .",
    "99 s. n. dorogovtsev , j. f. f. mendes , adv . phys . * 51 * , 1079 ( 2002 ) .",
    "s. boccaletti , v. latora , y. moreno , m. chavez , d .- u .",
    "hwanga , physics reports * 424 * , 175 ( 2006 ) .",
    "m. e. j. newman , _ networks : an introduction _ ( oxford university press , 2010 ) .",
    "m. c. gonzlez , a .-",
    "barabsi , nature physics * 3 * , 224 ( 2007 ) .",
    "p. d. hoff , a. e. raftery , m. s. handcock , journal of the american statistical association * 97 * 1090 ( 2002 ) .",
    "l. da f. costa , f. a. rodrigues , g. travieso , p. r. u. boas , adv .",
    "phys . * 56 * , 167 ( 2007 ) .",
    "e. d. kolaczyk , _ statistical analysis of network data _",
    "( springer , 2009 ) . f. papadopoulos , m. kitsak , m.  .",
    "serrano , m. bogua , d. krioukov , nature * 489 * , 537 ( 2012 ) .",
    "m. li , h. zou , s. guan , x. gong , k. li , z. di , c .- h .",
    "lai , scientific reports * 3 * , 2512 ( 2013 ) .",
    "m. p. h. stumpf , m. a. porter , science * 335 * , 665 ( 2012 ) .",
    "a. van den bos , _",
    "parameter estimation for scientists and engineers _ ( wiley - interscience , 2007 ) .",
    "d. a. freedman , _ statistical models : theory and practice _ ( cambridge university press , 2nd  edition , 2009 ) .",
    "p. bhlmann , s. van de geer , _ statistics for high - dimensional data _",
    "( springer , 2011 ) .",
    "j. leskovec , l. backstrom , r. kumar , a. tomkins , in kdd 08 : proceedings of the 14th acm sigkdd international conference on knowledge discovery and data mining , 462 ( acm , new york , 2008 ) .",
    "j. leskovec , d. chakrabarti , j. kleinberg , c. faloutsos , z. ghahramani , the journal of machine learning research * 11 * 985 ( 2010 ) .",
    "m. medo , g. cimini , and s. gualdi , phys .",
    ". lett . * 107 * , 238701 ( 2011 ) .",
    "r. albert , a .-",
    "barabsi , rev .",
    "74 * , 47 ( 2002 ) .",
    "h . eom , s. fortunato , plos one * 6 * : e24926 ( 2011 ) .",
    "p. holme , j. saramki , physics reports * 519 * , 97 ( 2012 ) .",
    "d. wang , c. song , a .-",
    "barabsi , science * 342 * , 127 ( 2013 ) .",
    "h. owhadi , c. scovel , t. sullivan , when bayesian inference shatters , arxiv:1308.6306 ( 2013 )",
    ". m. s. shang , l. l , y .- c .",
    "zhang , t. zhou , epl * 90 * , 48006 ( 2010 ) .",
    "j. han , m. kamber , j. pei , _ data mining : concepts and techniques _ ( morgan kaufmann , 3rd  edition , 2011 ) .",
    "r. tibshirani , j. r. statist .",
    "b * 58 * , 267 ( 1996 ) .",
    "see supplementary material for data download .",
    "g. bianconi , a .-",
    "barabsi , europhys . lett . * 54 * , 436 ( 2001 )",
    ". b. a. huberman , journal of statistical physics * 151 * , 329 ( 2013 ) .",
    "f. radicchi , s. fortunato , c. castellano , pnas * 105 * , 17268 ( 2008 ) .",
    "k. p. burnham ; d. r. anderson , _ model selection and multimodel inference : a practical information - theoretic approach _ ( springer - verlag , 2nd  edition , 2002 ) .",
    "g. claeksens , n. l. hjort , _ model selection and model averaging _ ( cambridge university press , 2008 ) .",
    "a. c. davison , d. v. hinkley , _ bootstrap methods and their application _",
    "( cambridge university press , 1997 ) . c. shalizi , american scientist * 98 * , 186 ( 2010 ) ."
  ],
  "abstract_text": [
    "<S> the abundance of models of complex networks and the current insufficient validation standards make it difficult to judge which models are strongly supported by data and which are not . </S>",
    "<S> we focus here on likelihood maximization methods for models of growing networks with many parameters and compare their performance on artificial and real datasets . while high dimensionality of the parameter space harms the performance of direct likelihood maximization on artificial data , this can be improved by introducing a suitable penalization term . </S>",
    "<S> likelihood maximization on real data shows that the presented approach is able to discriminate among available network models . to make large - scale datasets accessible to this kind of analysis </S>",
    "<S> , we propose a subset sampling technique and show that it yields substantial model evidence in a fraction of time necessary for the analysis of the complete data . </S>"
  ]
}