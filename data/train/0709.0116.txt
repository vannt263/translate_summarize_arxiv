{
  "article_text": [
    "brooks @xcite asserted as a great challenge for contemporary computer science and information theory : `` shannon and weaver performed an inestimable service by giving us a definition of information and a metric for information as communicated from place to place .",
    "we have no theory however that gives us a metric for the information embodied in structure ... this is the most fundamental gap in the theoretical underpinning of information and computer science . ''",
    "the notion of ultrametric information was introduced by @xcite , both to handle interactive as opposed to static information , and by taking a dynamic view of information , with analogies to metric or kolmogorov - sinai information . here",
    "we pursue a view of algorithmic or computational information , which is extended to account for an ultrametric embedding of the object that is computed .",
    "shannon information is oriented towards communication . while shannon information is based on the freedom of choice that is possible when transmitting a message , kolmogorov information , or algorithmic information ,",
    "is a measure of the information content of individual objects .",
    "the kolmogorov complexity of a string is the size of the shortest program in bits that computes the string .",
    "it is concerned therefore with strings , and furthermore ( finite or infinite ) binary strings .",
    "an object , expressed as a binary string , has complexity which is its shortest string description , because this also defines the shortest program , or decision tree , to compute it .",
    "the shortest effective description length has become known as kolmogorov complexity , even if precedence may be due to solomonoff ( @xcite , p.  90 ) . from solomonoff s",
    "work on the `` algorithmic theory of descriptions '' has come the minimum description length , or mdl , principle as a computable and practical information measure @xcite    we approach this problem of expressing information and computability , relating to complexity and generation , respectively , in a new way .",
    "a key role is played by representation , i.e. , object or data encoding .",
    "we need both to consider carefully the data description related to the observing of the object ; and the display associated with the data description",
    ". these two issues amount to , respectively , the mapping of the object to data , and data to object .",
    "there is enormous latitude for representation .",
    "we must choose expeditiously , based on our objectives , which may include interpretation of the data or the event or phenomenon .",
    "our work builds on @xcite in the following ways .",
    "such work points to the crucial role played by data encoding , or representation , for many purposes ( including search and display ) . in @xcite",
    "it is shown how _",
    "if _ we have an ultrametric embedding of our data  otherwise expressed , a hierarchical or tree structuring of our data  then it is possible for search operations to be carried out in constant , or @xmath0 , time . in this article",
    ", we also presuppose a given ultrametric embedding ( or hierarchical structuring ) of our data . in general terms",
    "we are dealing with @xmath1 objects characterized by @xmath2 attributes .",
    "classically , a complete description of an object by means of its attributes leads to an expression for the object s complexity that is defined from the set of its @xmath2 attributes .",
    "given the ultrametric embedding , we look instead at the object s complexity in terms that are relative to the population of @xmath1 objects .",
    "if the hierarchy is a meaningful one , e.g.  expressing biological reproduction , then we have a new perspective on the computability of an object .",
    "section [ sect2 ] provides background on an important tool used in subsequent sections , the haar wavelet transform carried out _ on _ a hierarchy .",
    "it allows us to go well beyond a hierarchy as just a display device or visualization , and instead to carry out operations on the hierarchy , expressing operations in an ultrametric space .",
    "we set the scene for later parts of this article through a discussion of the stepwise approximation scheme that we can establish , for various objects , and that defines the haar wavelet transform , in this case , of a dendrogram .",
    "( a dendrogram is the term used for the particular tree , discussed in the next section , that is induced on , or determined from , object / attribute data . in this article , our use of the term `` hierarchy '' is always as a synomym for these . )    in section [ sect6 ] we consider a hugely simplified face recognition case study .",
    "once we presuppose a representation or encoding of a face , then any given face is generated by very simple calculations on faces .",
    "we link this work with some recent directions of study in the psychology literature of human recognition behavior .    in section [ sectnew4 ]",
    "we use a simple case study of a set of concepts , and show how each is computed or generated from others among these concepts , and/or a superset of nouns .",
    "this study is complemented by the analysis of texts or documents .",
    "in dealing with faces and with texts , we have carefully selected a range of case studies to exemplify a new approach to computability , in the sense of generation of an object and , related to this , the inherent complexity of an object .    in summarizing and concluding , sections [ sect55 ] and [ sect66 ]",
    "provide further discussion on our approach .",
    "a wavelet transform is a decomposition of an object , typically an image or signal , into an ordered set of _ detail _ `` versions '' of the data , and an overall _ smooth _ @xcite . from the details , with the smooth , the data can be exactly reconstructed . in the case of the haar wavelet transform ,",
    "the details and the smooth are defined from , respectively , differences and sums .",
    "we will see how this works using a concrete example .    extending the wavelet transform to ultrametric topologies has been carried out , e.g. , by @xcite .",
    "the wavelet transform has been traditionally used for image and signal processing , based on functions in hilbert space . in @xcite we showed , with a wide range of examples and case studies , how this transform can be easily implemented _ on _ tree structured data . without loss of generality",
    ", we assume that our tree is binary , rank ordered , rooted , and , for practical application , labeled .",
    "such a tree is often referred to as a dendrogram .",
    "the tree distance is an ultrametric and , reciprocally , we endow a data set with an ultrametric by structuring it as a tree .    as a small data set",
    "consider the first 8 observations in the very widely used fisher iris data @xcite .",
    "fisher used this data , taken from @xcite , to introduce the discriminant analysis method that bears his name . by range - normalizing ( i.e. , subtracting the minimum value of each variable , and dividing by the range ) in table [ table5 ] , we obtain table [ table5b ] .",
    "the minimum variance or ward agglomerative clustering hierarchy was built ( with constant weights on the observations ) , and is shown in figure [ fig5b ] .",
    "the minimum variance agglomeration criterion , with euclidean distance , is used to induce the hierarchy on the given data .",
    "we could use some other agglomerative criterion",
    ". however the minimum variance one leads to more balanced dendrograms @xcite , with knock - on implications for computational requirements for average time tree traversal .    from input table [ table5b ] and the dendrogram of figure [ fig5b ] , we carry out the wavelet transform .",
    "the transform is shown in table [ table6b ] , and is also displayed in figure [ fig5c ] .",
    "note that in table [ table6b ] it is entirely appropriate that at more smooth levels ( i.e. , as we proceed through levels d1 , d2 , @xmath3 , d6 , d7 ) the values become more `` fractionated '' ( i.e. , there are more values after the decimal point ) .",
    "each detail signal is of dimension @xmath4 where @xmath2 is the same dimensionality as the given , input , data .",
    "the smooth signal is of dimensionality @xmath2 also .",
    "the number of detail or wavelet signal levels is given by the number of levels in the labeled , ranked hierarchy , i.e.  @xmath5 : cf .",
    "the columns in table [ table6b ] labeled , for details , @xmath6 .    [ cols=\">,>,>,>,>\",options=\"header \" , ]",
    "let @xmath7(word ) be the rank of a word .",
    "we have that :    * we can determine the smooth of word@xmath8 and word@xmath9 , through use of @xmath7(word@xmath8 ) and @xmath7(word@xmath9 ) .",
    "in line with the lifting-2 scheme in table [ tabhaar ] , the smooth is @xmath7(word@xmath8 ) + @xmath7(word@xmath9 ) .",
    "* the detail signal then is @xmath10(word@xmath8 ) @xmath11(word@xmath12 * furthermore there is some word@xmath13 such that @xmath7(word@xmath14(word@xmath15(word@xmath12 so that a detail coefficient is given by @xmath16 word@xmath13 for some @xmath17 .",
    "* in fact , when @xmath16 word@xmath13 is the detail , we have the following linear relationship : + @xmath18 word@xmath8 = smooth(word@xmath8 , word@xmath9 ) @xmath19 word@xmath13 + @xmath18 word@xmath9 = smooth(word@xmath8 , word@xmath9 ) @xmath20 word@xmath13 * finally it is likely that word@xmath13 is not in the word set that we are examining .",
    "we adopt an easy solution to how we represent word@xmath13 through its rank , @xmath7(word@xmath13 ) .",
    "firstly , word@xmath13 can be from a superset of the word set being analyzed ; and we allow multiples of our top rank to help with this representation . figures , to be discussed now ( figures [ arist - ranks-1 ] and [ arist - ranks-2 ] ) , will exemplify this .",
    "our aim is to have a closed system where the dendrogram wavelet transform of words transforms to words .",
    "we will illustrate this generally applicable procedure using an example .",
    "we took aristotle s _ categories _ , which consisted of 14,483 individual words .",
    "for expository purposes , as we will now see , we selected a small subset of words .",
    "the procedure followed , with motivation , is as follows .",
    "we broke the text into 24 files , in order to base the textual analysis on the sequential properties of the argument developed . in these 24 files",
    "there were 1269 unique words .",
    "we selected 66 nouns of particular interest .",
    "a sample ( with frequencies of occurrence ) follows : man ( 104 ) , contrary ( 72 ) , same ( 71 ) , subject ( 60 ) , substance ( 58 ) , ... no stemming or other preprocessing was applied .",
    "the first phase of processing is to construct a hierarchical clustering .    for the hierarchical clustering",
    ", we further restricted the set of nouns to just 8 .",
    "( these will be seen in the figures to be discussed below . )",
    "the data array was _ doubled _",
    "@xcite to produce an @xmath21 array , which with removing 0-valued text segments ( since , in one text segment , none of our selected 8 nouns appeared ) gave an @xmath22 array , thereby enforcing equal weighting of ( equal masses for ) the nouns .",
    "the spaces of the 8 nouns , and of the 23 text segments ( together with the complements of the 23 text segments , on account of the data doubling ) are characterized prior to the correspondence analysis in terms of their frequencies of occurrence , on which the @xmath23 metric is used .",
    "the correspondence analysis then `` euclideanizes '' both nouns and text segments .",
    "such a euclidean embedding is far safer for later processing , including clustering ( and frankly would be most ad hoc , and/or `` customized '' and less general , in terms of any alternative data analysis ) .",
    "we used a 7-dimensional ( corresponding to the number of non - zero eigenvalues ) euclidean embedding , furnished by the projections onto the factors .",
    "a hierarchical clustering of the 8 nouns , characterized by their 7-dimensional ( euclidean ) factor projections , was carried out : figure [ arist - ranks-1 ] .",
    "the ward minimum variance agglomerative criterion was used , with equal weighting of the 8 nouns .",
    "based on the hierarchical clustering , the second phase of processing is to carry out the wavelet transform on it .",
    "using the `` lifting-2 '' scheme in table [ tabhaar ] ensures that haar dendrogram wavelet detail and smooth components will be integers which we can read off as ranks .",
    "the result of this processing is shown in figure [ arist - ranks-2 ] .",
    "the ranks are used here , and are noted in the terminal labels .",
    "the wavelet transform , using the `` key '' of the hierarchy , is based on these ranks .",
    "the overall smooth ( not shown ) at the root of the tree is 282 .",
    "so , @xmath24 . we use the `` lifting-2 '' scheme in order to ensure that integers , that we will interpret as ranks , are used as details and smooths throughout .",
    "let s check how we reconstruct , say , `` disposition '' . from table",
    "[ tabhaar ] , we have , where , as we have noted , the final smooth , 282 , is not shown in figure [ arist - ranks-2 ] : @xmath25 .",
    "we have therefore traced the path from root to the terminal node corresponding to `` disposition '' , accumulating final smooth and details , and carrying out the division by 2 as per table [ tabhaar ] .",
    "our next step is to give a meaning to the details , and final smooth , based on the word set used .",
    "but we have used 66 words in all .",
    "let us therefore define ranks 227 = 3 * 66 + 29 ; 252 = 3 * 66 + 54 ; and 282 = 4 * 66 + 18 .",
    "next , we check what words we in fact have for the ranks that we use here : @xmath26",
    "= @xmath27 `` number '' , `` parts '' , `` affections '' , `` sense '' , `` name '' , `` correlatives '' , `` sense '' , `` knowledge '' , `` qualities '' @xmath28 .",
    "now , back to reading off the trajectory of `` disposition '' .",
    "we can rephrase this in terms of words :    `` disposition '' = ( ( ( ( ( 4 * `` number '' + `` parts '' + 3 * `` number '' + `` affections'')/2 + 3 * `` number '' + `` sense'')/2 + `` name'')/2 @xmath29 `` sense'')/2 )    so we can say that `` disposition '' is a simple linear combination of the following terms : `` number '' , `` parts '' , `` affections '' , and `` sense ''",
    ".    having shown that we can define a word in terms of other words , we can carry out the same calculation for all others here .",
    "let us note that , by using the entire hierarchy of embedded sets , a very simple alternative expression is available for any individual concept . label the non - terminal nodes as follows :",
    "@xmath30 = @xmath27 `` motion '' , `` position '' @xmath28 ; @xmath31 = @xmath27 `` existence '' , `` object '' @xmath28 ; @xmath32 = @xmath27 `` motion '' , `` position '' , `` disposition '' @xmath28 ; etc . then `` name '' = @xmath33",
    ". `` definition '' = @xmath34 .",
    "we can continue straightforwardly to label concepts on this basis .        in the representation used for",
    "our selected set of words from the aristotle text , let us note that this representation is an integer one ( i.e. , ranks , which in the dendrogram wavelet transform , are processed as integers ) .",
    "one important conclusion we draw is that with such a representation we must represent wavelet details and the smooth in terms of words that are not in the selected set .",
    "we must go beyond the selected set . in our chernoff face case study , section [ sect6 ] , we used the reals in our representation , and then the details and the smooth came from the same set ( i.e. , continuous interval ) .",
    "the wavelet transform of rank data has interesting links between details and rank correlation ; and smooth and rank concordance .",
    "spearman s coefficient @xmath35 of rank correlation is defined from the squared differences of ranks .",
    "( take two rankings , @xmath36 . then @xmath37 .",
    "see @xcite . )",
    "using the lifting scheme , the detail coefficients in the haar wavelet transform are differences of ranks .",
    "the energy of the detail coefficients can be viewed therefore as contributions to a spearman s @xmath35 .",
    "kendall ( @xcite , chapter 9 ) , deals with approximations for @xmath35 for @xmath1 large , and close relationship between use of ranks and of equivalent real - valued variates .    to provide an interpretation for such rank correlations ,",
    "consider the case of a perfectly balanced or regular hierarchy .",
    "then the first tranche of detail values will be between successive pairs of our input vectors .",
    "the contributions to spearman s @xmath35 are between these pairs . for the next tranche of nodes in the hierarchy",
    ", we are considering successive pairs of non - terminal nodes , with the implication that our contributions to spearman s @xmath35 deals with correlation between these pairs .",
    "ultimately , therefore , the contributions to spearman s @xmath35 correlation are between successive pairs , of input vectors , and of clusters of them , read off in accordance with the sequence of agglomerations in the hierarchy .",
    "the overall or final smooth is based on repeatedly summing ranks .",
    "the average ranking is used in the concordance of the set of rankings , spearman s coefficient of concordance ( see chapters 6 , 7 of @xcite ) .",
    "in fact , treating the ranks as real - valued variates can allow us , `` with caution ''",
    "( @xcite , p. 125 ) to arrive at the same outcome as if we had used real - valued variates to start with .",
    "in the context of @xmath1 texts , and the earlier face case study , we have considered the following , where @xmath2 is the number of unique attributes ( words ; face attributes ) , and @xmath38 is the maximum object ( text , face ) size or total number ( non - unique ) of attributes .    *",
    "a `` bag of words '' description of a given text , leading to an @xmath2-length representation . directly generating one text requires @xmath39 decisions or operations .",
    "a random , assuming uniformity , text has probability @xmath40 .",
    "a shannon information measure of the object is @xmath2 bits . * a boolean description of a given text , with an @xmath41-length representation for each text .",
    "directly generating one text requires @xmath42 operations .",
    "a random , assuming uniformity , text has probability @xmath43 .",
    "a shannon information measure of the object is @xmath41 bits . * a rank description of a given text , using ranks @xmath44 .",
    "each text has an @xmath38-length represenation . directly generating one text requires @xmath45 operations .",
    "a random , assuming uniformity , text has probability @xmath46 .",
    "a shannon information measure of the object is @xmath47 bits , where @xmath48 is a constant .",
    "* in the face case study , the representation was @xmath2-length and real .",
    "let each real value be discretized into @xmath49 intervals .",
    "each face then is described by a boolean @xmath50-length representation .",
    "directly generating one face requires @xmath51 operations .",
    "a random , assuming uniformity , face has probability @xmath52 .",
    "a shannon information measure of the object is @xmath50 bits .",
    "now we change the context , and assume that we have a hierarchical structuring of the set of @xmath1 objects considered . directly generating one object",
    "requires @xmath53 operations , and worst case @xmath5 .",
    "each operation is of linear computational complexity in the representation used .",
    "a random , assuming uniformity , object has probability @xmath54 .",
    "a shannon information measure of the object is @xmath55 bits .",
    "our interest lies in cases where @xmath56 , i.e.  the total number of objects considered is very much less than the length of their description .    in practice , given a natural macroscopic object class , @xmath1 may be small , whereas we can go to great lengths to characterize the objects in terms of precision or description length .",
    "so the computability of the object is likely to be far more tractable , given our approach based on the hierarchical coding of information .",
    "our approach has been inspired by algorithmic information ( or kolmogorov complexity ) that considers a single , finite object and , more particularly , the length of the shortest binary program from which the object can be effectively reconstructed . as a tool",
    ", we used a novel wavelet transform on a hierarchy to provide a layer - by - layer reconstruction of the object , starting from an average object ( under certain circumstances , a mean object ) .",
    "significant challenges are facing us in regard to how we understand and process objects , as noted by brooks @xcite . a solution that we propose from the work described in this article",
    "is to explore further `` hierarchical coding systems '' ( this characterization is used in @xcite ) of the sort used in this work .",
    "we have described in this work how this can be done , using a range of practical , simplified , case studies .",
    "* generate faces from faces , with a global sum ( or average ) face as our starting point , * generate concepts from concepts , with an average concept as our starting point .",
    "* we have discussed how we can go further , to deal with , say , a document space .",
    "our work is consistent with @xcite , who in a machine learning perspective , concludes that : `` we have recognized a fundamental concept of how the neocortex uses hierarchy and time to create a model of the world and to perceive novel patterns as part of that model . ''",
    "anderson @xcite remarks on how `` it may be the case that the unique reach and power of human ... intelligence is a result not so much of a unique ability to perform complex , symbolic cognition in abstraction from the environment , but is rather due in large measure to the remarkable richness of the environment in which we do our thinking . ''",
    "he elaborates on this as follows .",
    "a central role is played `` by persisting institutions and practices in supporting the possibility of high - level cognition . in cognitive science",
    "such structures are called scaffolds ; a scaffold , in this sense , occurs when an epistemic action results in some more permanent cognitive aid ",
    "symbolic , or social - institutional . ''",
    "so `` we do very complex things , e.g. , building a jumbo jet or running a country only indirectly  by creating larger external structures , both physical and social , which can then prompt and coordinate a long sequence of individually tractable episodes of problem solving , preserving and transmitting partial solutions along the way @xcite .",
    "these structures include language , especially written language , and indeed all physically instantiated representations or cognitive aids ... such scaffolds allow us to break down a complex problem into a series of small , easy ones , ... not just symbol systems , but social structures and procedures can sometimes fill a similar role . ''",
    "all of this is exciting , but it rests on a fundamental bedrock of representation in the sense of data encoding , together with composition operators defined on these codes . we require , as a _ sine qua non _ for this work , a data encoding scheme ( i ) preferably of small , finite length , ( ii ) capable of being efficiently ( low order polynomial ) converted into a display , and ( iii ) capable of being efficiently ( low order polynomial ) determined from a real world exemplar of the object .",
    "mainstream physics proceeds by analyzing the ever smaller and ever larger .",
    "mainstream computer science has its point of departure in the necessary finiteness of that which is computed .",
    "the feasibility of this computer science perspective is based on our finiteness as human beings .",
    "an interesting example from @xcite , discussed in @xcite , is to consider a person monitored by a video camera for their entire life .",
    "the amount of data , for 70 years or @xmath57 seconds , is to an approximation 27.5 terabytes .",
    "let us pose the question of the complexity of a human life , expressed as this particular 27.5 terabytes of information . in a similar vein ,",
    "the work of shakespeare , according to @xcite , amounts to under one million words , and can be spoken in 70 hours .",
    "a further supporting view , for music and literary works , is as follows .",
    "basing himself approvingly on a publication by r. kolisch in 1943 , musical and cultural theorist adorno @xcite considered `` the basic characters to which the types of beethoven s tempi correspond . in this way ,",
    "[ we arrive ] at a discrete number of such basic characters and tempi . at first",
    ", the result is shocking ; it seems a bit mechanistic and overly mathematical in relation to beethoven s gigantic oeuvre .",
    "but if you turn the tables , ... you will find that great ... music actually bears some resemblance to a puzzle .",
    "the movements of the greatest composers are based on a discrete number of _ topoi _ , of more or less rigid elements , out of which they are constructed .",
    "... music represents itself as if one thing were developing out of the other , but without any such development literally occurring .",
    "the mechanical aspect is covered up by the art of composition , ... '' .",
    "adorno s discussion continues with a reference to a similar picture in relation to how `` similarly , with a certain amount of navit , the great philosophical systems beginning with plato have had recourse again and again to such mechanical means ... '' .",
    "our perspective , based on some hierarchically structured , appropriate representation or encoding of our object family , and an associated algebra , is that it is so much easier to grow the object !",
    "algorithmic complexity traditionally is related to the length ( or size ) of the object . for us ,",
    "algorithmic complexity is related to the size of the object class , rather than to the size of the object .",
    "such a perspective is not a replacement for the algorithmic information view .",
    "it is simply a different view .    in physics",
    ", the pursuit of the ever smaller and ever larger , notwithstanding finite and discrete limits , make the computability of physical objects difficult and problematic . on the other hand",
    "the finitary computer science view presented in this work , based on hierarchical coding , is eminently tractable and allows natural and artifact objects to be computable .",
    "khrennikov , a.yu . and kozyrev , s.v .",
    "( 2005 ) pseudodifferential operators on ultrametric space and ultrametric wavelets .",
    "izvestia ran ( communications of the russian academy of sciences ) , ser .",
    ", 69 , 133148 ( in russian ) ; izvestia mathematics , 69 , 9891003 ( in english ) ."
  ],
  "abstract_text": [
    "<S> how best to quantify the information of an object , whether natural or artifact , is a problem of wide interest . </S>",
    "<S> a related problem is the computability of an object . </S>",
    "<S> we present practical examples of a new way to address this problem . by giving an appropriate representation to our objects , based on a hierarchical coding of information , </S>",
    "<S> we exemplify how it is remarkably easy to compute complex objects . </S>",
    "<S> our algorithmic complexity is related to the length of the class of objects , rather than to the length of the object .    </S>",
    "<S> * keywords : * data mining , multivariate data analysis , hierarchical clustering , compression , information , entropy , wavelet transform , computability , topology , ultrametric . </S>"
  ]
}