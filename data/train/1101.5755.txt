{
  "article_text": [
    "@xmath0 be a one - dimensional ( 1d ) signal and @xmath1 an orthonormal transform matrix , where @xmath2 is the set of real numbers .",
    "if @xmath3 and there are only @xmath4 spikes ( nonzero entries ) in @xmath5 , we say that @xmath6 is @xmath7-sparse in @xmath8 domain .",
    "we sample @xmath6 by @xmath9 ( @xmath10 ) to get @xmath11 , where @xmath12 .",
    "if @xmath13 obeys the order-@xmath7 restricted isometry property ( rip ) and has low coherence with @xmath8 , then @xmath5 ( and in turn @xmath6 ) can be effectively recovered from @xmath14 @xcite .",
    "many algorithms have been proposed to recover @xmath6 from its random sample @xmath14 , e.g. linear programming ( lp ) @xcite and orthogonal matching pursuit ( omp ) @xcite . for a detailed overview on recovery algorithms",
    ", please refer to @xcite .    in practice , many signals , e.g. image , video , etc , are two - dimensional ( 2d ) .",
    "a straightforward implementation of 2d compressive sampling ( cs ) is to stretch 2d matrices into 1d vectors .",
    "however , such direct stretching increases exponentially the complexity and memory usage at both encoder and decoder .",
    "an alternative to 1d stretching is to sample rows and columns of 2d signals independently by using separable operators @xcite .",
    "through 2d separable sampling , encoding complexity is exponentially reduced . however , as the recovery problem is converted into a standard 1d @xmath15-minimization problem , decoding complexity is still very high .    as a representative sparse signal recovery algorithm ,",
    "the omp achieves good performance with low complexity .",
    "the omp is originally designed for 1d signal recovery . to reduce the complexity of 2d signal recovery , this paper extends the 1d - omp to obtain the 2d - omp .",
    "we prove that with 2d separable sampling , 2d - omp is in fact equivalent to 1d - omp , so that both algorithms will output exactly the same results .",
    "however , the complexity and memory usage of 2d - omp is much lower than that of 1d - omp .",
    "thus , 2d - omp can be used as an alternative to 1d - omp in 2d sparse signal recovery .",
    "this paper is arranged as follows .",
    "section [ sec:1d_omp ] first briefly reviews the principles of 2d separable sampling and 1d - omp , and then makes a detailed analysis on the complexity of 1d - omp . in section [ sec:2d_omp ] , we deduce the 2d - omp algorithm , reveal the equivalence of 2d - omp to 1d - omp , and compare the complexity and memory usage of 2d - omp with that of 1d - omp . in section [ sec : results ] , simulation results are reported .",
    "finally , section [ sec : conclusion ] concludes this paper .",
    "the principle of 2d separable sampling @xcite is as follows .",
    "let @xmath16 be a 2d signal which is @xmath7-sparse in @xmath8 domain , i.e. @xmath17 and there are only @xmath18 spikes in @xmath19 , where @xmath20 denotes the transpose . for simplicity",
    ", we use the same operator @xmath13 to sample the rows and columns of @xmath21 independently to get @xmath22 .",
    "let @xmath23 be the 1d stretched vector of @xmath24 and @xmath25 the 1d stretched vector of @xmath19 .",
    "it was proved that @xmath26 where @xmath27 denotes the kronecker product @xcite .",
    "it is easy to prove @xmath28 , hence @xmath29 .",
    "now this is just a standard 1d sparse signal recovery problem which can be attacked by the omp .",
    "[ alg:1d_omp ]    * input * :    * @xmath30 : sampling matrix * @xmath23 : sample * @xmath7 : sparsity level    * output * :    * @xmath31 : reconstruction of the ideal signal @xmath5    * auxiliary variables * :     * @xmath32 : residual * @xmath33 : set of the indices of atoms that are allowed to be selected in the future    * initialization * :    * @xmath34 * @xmath35    let @xmath36 , where @xmath37 is the @xmath38-th column of @xmath39 .",
    "we call @xmath39 the _ dictionary _ and @xmath40 an _",
    "atom_. the main idea of 1d - omp is to represent @xmath14 as a weighted sum of as few atoms as possible .",
    "algorithm [ alg:1d_omp ] gives main steps of 1d - omp . to implement 1d - omp",
    ", we need two auxiliary variables . first , to avoid atom reselection , set @xmath33 is defined to record the indices of those atoms that are allowed to be selected in the future ( excluding those already selected atoms ) .",
    "second , vector @xmath32 is defined to hold the residual after removing the selected atoms from @xmath14 .",
    "initially , @xmath41 is set to @xmath14 . then at each iteration",
    ", the decoder picks from the dictionary the atom that best matches the residual and then renews the weights for all the already selected atoms via the least squares .",
    "we decompose the iteration of 1d - omp into the following steps and analyze its complexity step by step .",
    "the projection of residual @xmath41 onto atom @xmath42 is @xmath43 , where @xmath44 denotes the inner product between two vectors and @xmath45 denotes the @xmath46-norm of a vector .",
    "let @xmath47 , then this step can be implemented by @xmath48 , where @xmath49 denotes dot division .",
    "the complexity of this step is dominated by @xmath50 matrix - vector multiplication .",
    "hence the complexity of this step is @xmath51 .",
    "this step selects from unselected atoms the atom with the maximal absolute value of projection . as there are @xmath52 atoms and @xmath18 , the complexity of this step is approximately @xmath53 , negligible compared with the @xmath54 step .",
    "let @xmath55 , then @xmath56 .",
    "according to linear algebra , @xmath57 where @xmath58 and @xmath59 . the complexity to calculate @xmath60 and @xmath61 depends on @xmath62 . for @xmath63 ,",
    "the complexity of this step is negligible compared with the @xmath54 step .",
    "the complexity of this step depends on @xmath62 . for @xmath63 ,",
    "the complexity of this step is negligible compared with the @xmath54 step .",
    "based on the above analysis , we conclude that the complexity of 1d - omp is dominated by the @xmath54 step and its complexity is @xmath51 .",
    "this section develops the 2d - omp algorithm whose main idea is to represent 2d signal @xmath24 as a weighted sum of 2d atoms that are selected from an over - complete dictionary .",
    "we first redefine the concepts of atom , dictionary , and projection for 2d signals .",
    "then we give the 2d - omp algorithm .",
    "we reveal the equivalence of 2d - omp to 1d - omp and compare the complexity and memory usage of 2d - omp with that of 1d - omp .",
    "let @xmath16 be a 2d signal that is @xmath7-sparse in @xmath8 domain and @xmath22 .",
    "let @xmath64 , where @xmath65 is the @xmath38-th column of @xmath66 .",
    "we redefine dictionary , atom , and projection as follows .      in the 2d - omp",
    ", the dictionary contains @xmath52 atoms and each atom is an @xmath67 matrix . let @xmath68 be the ( @xmath38 , @xmath69)-th atom , then @xmath68 is the outer product of @xmath65 and @xmath70 @xmath71 now @xmath24 can be represented by the weighted sum of @xmath68 , i.e. @xmath72      the projection of @xmath24 onto @xmath68 is @xmath73 where @xmath74 and @xmath75 is the frobenius norm of @xmath68 , i.e. @xmath76      [ alg:2d_omp ]    * input * :    * @xmath77 : sampling matrix * @xmath78 : sample * @xmath7 : sparsity level    * output * :    * @xmath79 : reconstruction of the ideal signal @xmath19    * variable * :    * @xmath80 : residual * @xmath81 , @xmath82 : set of the coordinates of atoms that are allowed to be selected in the future , @xmath33 for row indices and @xmath83 for column indices    * initialization * :    * @xmath84 * @xmath81 , @xmath85    algorithm [ alg:2d_omp ] gives main steps of 2d - omp . to implement the 2d - omp algorithm , we also need two auxiliary variables .",
    "first , to avoid atom reselection , set @xmath86 is defined to record the coordinates of those atoms that are allowed to be selected in the future ( excluding those already selected atoms ) , where @xmath33 for row indices and @xmath83 for column indices .",
    "second , @xmath80 is defined to hold the residual after removing the selected atoms from @xmath24 .",
    "initially , @xmath87 is set to @xmath24 . then at each iteration ,",
    "the decoder first searches for the best matched atom in the dictionary and then renews the weights for all the already selected atoms via the least squares .      the weighted sum of @xmath62 selected atoms constructs an approximation to @xmath24 .",
    "let @xmath88 we model the problem as finding the optimal @xmath89 that minimizes the frobenius norm of @xmath87 , which is in fact equivalent to the least squares problem .",
    "as @xmath90 , where @xmath91 is the trace of a matrix , the problem is equivalent to @xmath92 using ( [ eq : r ] ) and @xmath93 , we have @xmath94 where @xmath95 and @xmath96 when @xmath97 takes the minimum , there must be @xmath98 hence @xmath99      it is easy to get @xmath102 let @xmath103 , then @xmath104 similarly , for @xmath101 , because @xmath105 we have @xmath106      obviously , the @xmath107-th atom of @xmath39 is @xmath108 compared with ( [ eq:2d_atom ] ) , it can be found that @xmath109 is just the 1d stretched vector of @xmath68 .",
    "hence , the frobenius norm of @xmath68 will equal the @xmath46-norm of @xmath109 .",
    "then we prove that the projection of @xmath87 onto @xmath68 equals the projection of @xmath41 onto @xmath109 .",
    "obviously , @xmath110 hence @xmath111 it means : at each iteration of 1d - omp and 2d - omp , the same atom will be selected .    finally , as @xmath41 is the 1d stretched vector of @xmath87 , @xmath112 .",
    "hence , the least squares in 1d - omp and 2d - omp will output exactly the same results ( in fact , it can be easily proved that @xmath113 and @xmath114 ) .",
    "based on the above analysis , we draw the conclusion that 2d - omp is equivalent to 1d - omp .",
    "below we analyze the complexity of 2d - omp step by step .",
    "let @xmath115 be an @xmath116 matrix whose @xmath117-th element is @xmath75 .",
    "then this step can be implemented by @xmath118 .",
    "the complexity of this step is dominated by @xmath119 matrix - matrix multiplication and @xmath120 matrix - matrix multiplication .",
    "as @xmath121 , the complexity of this step is @xmath122 .      since there are @xmath52 atoms and @xmath18 , the complexity of this step is approximately @xmath53 , negligible compared with the @xmath54 step .      from ( [ eq : h ]",
    ") , it can be seen that the complexity to calculate @xmath123 is @xmath124 . since @xmath125 , the complexity to calculate",
    "@xmath126 is @xmath127 .",
    "the complexity to calculate @xmath100 and @xmath101 depends on @xmath62 . for @xmath63 ,",
    "the complexity of this step is negligible compared with the @xmath54 step .",
    "the complexity of this step depends on @xmath62 . for @xmath63 ,",
    "the complexity of this step is negligible compared with the @xmath54 step .",
    "based on the above analysis , we draw the conclusion that the complexity of 2d - omp is @xmath122 , roughly @xmath128 of that of 1d - omp .      for 1d - omp ,",
    "an @xmath129 matrix is needed to hold @xmath39 , so the memory usage is @xmath130 , while for 2d - omp , @xmath39 is replaced by @xmath66 , so the memory usage is reduced to @xmath131 .",
    "we have written both 2d - omp and 1d - omp algorithms in matlab @xcite .",
    "we present herein the results under three typical settings , i.e. @xmath132 , @xmath133 , and @xmath134 . for each setting",
    ", we increase sparsity level @xmath7 from 8 to 16 .",
    "the transform matrix @xmath8 is @xmath135 2d discrete cosine transform ( dct ) matrix . the sensing matrix @xmath13 is formed by sampling independent and identically - distributed ( i.i.d . )",
    "entries from standard gaussian distribution by using the @xmath136 function .",
    "2d sparse signal is obtained by using the @xmath137 function with density @xmath138 .",
    "we run the matlab codes on intel(r ) core(tm ) i7 cpu with 12 gb memory and collect the total running time of @xmath139 trials for 1d - omp and 2d - omp respectively . because two algorithms output exactly the same results , only the speedup of 2d - omp over 1d - omp with respect to @xmath7 is reported in fig .",
    "[ fig : speedup ] . from fig .",
    "[ fig : speedup ] , we can draw two conclusions :    1 .   as @xmath7 increases , the speedup of 2d - omp over 1d - omp descends gradually .",
    "this is because for small @xmath7 , the complexity of 2d - omp and 1d - omp is dominated by the _ project _ step . as @xmath7 increases , the complexity of other steps will weight heavier . especially , at the _ renew weights _",
    "step , the complexity of @xmath140 matrix inverse is @xmath141 , which will ascend quickly as @xmath62 increases .",
    "2 .   as @xmath142 increases , the speedup of 2d - omp over 1d - omp becomes more significant .",
    "when @xmath143 , the speedup of 2d - omp over 1d - omp ranges from 10 to 11 times , while when @xmath144 , the speedup of 2d - omp over 1d - omp ranges from 32 to 35 times .",
    "this is because the speedup of 2d - omp over 1d - omp comes mainly from the _ project _ step , while at other steps 2d - omp shows little superiority over the 1d - omp . as @xmath142 increases , the complexity of the _ project _ step weights heavier , which explains the aove phenomenon",
    "for 2d sparse signal recovery , this paper develops 2d - omp algorithm . we prove that 2d - omp is equivalent to 1d - omp , but it reduces recovery complexity and memory usage .",
    "hence , 2d - omp can be used as an alternative to 1d - omp in such scenarios as compressive imaging , image compression , etc .    following the deduction in this paper ,",
    "the extension of 2d - omp to higher dimensional omp is straightforward .",
    "for example , by utilizing 3d separable sampling , 3d - omp can be obtained by defining each atom as a 3d matrix . then at each iteration",
    ", the decoder projects 3d sample matrix onto 3d atoms to select the best matched atom , and then renews the weights for all the already selected atoms via the least squares .",
    "3d - omp can find its use in hyperspectral image compression ."
  ],
  "abstract_text": [
    "<S> recovery algorithms play a key role in compressive sampling ( cs ) . </S>",
    "<S> most of current cs recovery algorithms are originally designed for one - dimensional ( 1d ) signal , while many practical signals are two - dimensional ( 2d ) . by utilizing 2d separable sampling </S>",
    "<S> , 2d signal recovery problem can be converted into 1d signal recovery problem so that ordinary 1d recovery algorithms , e.g. orthogonal matching pursuit ( omp ) , can be applied directly . however , even with 2d separable sampling , the memory usage and complexity at the decoder is still high . </S>",
    "<S> this paper develops a novel recovery algorithm called 2d - omp , which is an extension of 1d - omp . in the 2d - omp , </S>",
    "<S> each atom in the dictionary is a matrix . at each iteration , </S>",
    "<S> the decoder projects the sample matrix onto 2d atoms to select the best matched atom , and then renews the weights for all the already selected atoms via the least squares . </S>",
    "<S> we show that 2d - omp is in fact equivalent to 1d - omp , but it reduces recovery complexity and memory usage significantly . </S>",
    "<S> what s more important , by utilizing the same methodology used in this paper , one can even obtain higher dimensional omp ( say 3d - omp , etc . ) with ease .    </S>",
    "<S> compressive sampling , 2d sparse signal , recovery algorithm , orthogonal matching pursuit . </S>"
  ]
}