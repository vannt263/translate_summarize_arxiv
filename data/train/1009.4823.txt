{
  "article_text": [
    "segmenting an image into multiple regions has for long been considered a plausible precursor of many high level visual recognition routines .",
    "indeed , if plausible image regions could be extracted so they would at least partly overlap the projections of visible surfaces in the scene , it would be conceivable that such interpretations can be later lifted to high - level scene percepts by invoking part - based object models and scene consistency rules .",
    "this has motivated research into ( hierarchical ) multipart image segmentations , for which many excellent methods are available @xcite . but finding good multipart image segmentations in one step has proven difficult , partly due to the inherently local nature of the grouping process .",
    "the competition constraints implicit in various methods make it difficult to integrate scene constraints and mid - level grouping into early computations , and can influence results in ways that do not always correlate with scene properties .",
    "learning segmentation models has also been problematic , partly because of insufficient support for reliable feature extraction and because inference , the inner core of learning , is usually very expensive .",
    "the alternative computational framework we pursue assembles multipart image interpretations by tiling multiple figure - ground image segment hypotheses using mid - level scene constraints .",
    "the problem of hypothesis selection and consistent ( full ) image segmentation is formulated as optimization over sets of maximal cliques , sampled from a graph that connects non - overlapping image segments . by designing and learning clique potentials that encode both intrinsic , unary gestalt segment properties and pairwise spatial compatibilities that account for plausible configurations of neighboring , spatially non - overlapping segments , we are able to eliminate many implausible image segments and tilings that can not possibly arise from the projection of surfaces in typical , structured 3d scenes .",
    "we show that such a strategy achieves the state of the art in benchmarks like berkeley and voc2009 .",
    "approaches to image segmentation include normalized cuts @xcite , mean shift @xcite and minimum spanning trees @xcite .",
    "they are usually computed multiple times , to increase the probability that some of the retrieved segments capture full objects , or their significant parts in images .",
    "another methodology to obtain multiple segmentations is to aggregate in a hierarchy , two well - known examples being multigrid methods @xcite and the ultrametric contour maps @xcite .",
    "the latter achieved state - of - the - art results in a number of challenging segmentation datasets .",
    "these algorithms partition the image into a number of regions by using pairwise pixel dependencies .",
    "direct learning is usually targeted at finding the parameters of local affinities  @xcite .",
    "other techniques work at coarser scales by optimizing over superpixels .",
    "this allow features to be computed over a larger spatial support .",
    "ren and malik @xcite learn a classification model to combine superpixels based on their gestalt properties .",
    "hoiem et al @xcite proposed a model that reasons jointly over scene geometry and occlusion boundaries , progressively merging superpixels so as to maximize the likelihood of a qualitative 3d scene interpretation .",
    "instead our goal is complementary : a set of consistent full image segmentation hypotheses , computed based on mid - level gestalt cues and implicit 3d constraints .",
    "while multi - part image segmentation algorithms are most commonly used , a number of figure - ground methods have been recently pursued .",
    "bagon et al @xcite proposed an algorithm that generates figure - ground segmentations by maximizing a self - similarity criterion around a user selected image point .",
    "malisiewicz and efros @xcite showed that good object - level segments could be obtained by merging pairs and triplets of segments from multi - part segmentations , but at the expense of generating also a large quantity of implausible ones .",
    "carreira and sminchisescu @xcite generate a compact set of segments using parametric minimum cuts and learn to score them using region and gestalt - based features .",
    "these algorithms were shown to be quite successful in extracting full object segments , suggesting that a promising research direction is to develop methods that combine multiple figure - ground segmentations ( or just segments obtained at multiple scales , potentially from different methods ) , into plausible full image segmentations .",
    "still missing is a formal multiple hypothesis computational framework for consistent selection ( tiling ) and learning , which we pursue here . providing a compact set of multiple hypotheses rather than",
    "a single answer is desirable for learning , for high - level , informed processing and for graceful performance degradation .",
    "[ [ organization ] ] organization : + + + + + + + + + + + + +    in sec .",
    "[ sec : tile ] we present our maximal clique formulation framework including both the search procedure and the parameterization of the clique potentials .",
    "[ sec : learning ] describes our ranking - based learning framework that alternates between sampling new tilings ( a discrete optimization method ) and optimizing the parameters of our clique potentials ( a continuous problem ) against the test error measure , here the full image segmentation quality .",
    "sec  [ sec : features ] discusses our segment , mid - level unary and pair - wise terms based on gestalt measures and the statistics of projected boundaries of 3d surfaces , including t - junctions and extremal edges .",
    "we show inference and learning statistics as well as experiments on the berkeley and pascal voc 2009 segmentation datasets in sec .",
    "[ sec : experiments ] .",
    "we conclude with ideas for future work in sec .",
    "[ sec : concl ] .",
    "given a set @xmath0 of @xmath1 segments our aim is to generate several tilings @xmath2 such that no two segments on @xmath2 overlap and @xmath2 has a high score @xmath3 .",
    "consider for that a graph @xmath4 , called the _ consistency graph _",
    ", where the vertices are the segments in @xmath0 .",
    "two vertices are connected by an edge if the corresponding segments do not overlap .",
    "a _ clique _ of @xmath5 , which is a fully connected subgraph of @xmath5 , corresponds to a set of segments that can form a tiling .",
    "a clique is called _ _ maximal _ _ if it is not included into any other clique and hence a larger clique can not be obtained by adding vertices to it . in our case",
    "a maximal clique corresponds to a tiling that can not be extended using any other segment in @xmath0 .",
    "a _ maximum clique _ of a graph is a clique with the largest number of vertices .",
    "maximum weighted clique _ is a clique that maximizes the sum of weights associated to its vertices .",
    "we formulate the search for tilings as finding _ maximal cliques _",
    "@xmath6 with high potential @xmath3 @xmath7 where @xmath8 , @xmath9 are feature vectors extracted for , respectively , segment @xmath10 and _ image neighbors _ @xmath11 ( denoted @xmath12 ) .",
    "@xmath13 are the corresponding weights learned as mentioned in section  [ sec : learning ] .    the problem of finding the _ maximum _ ( weighted ) clique of a general graph is known to be both np - complete and hard to approximate to a given bound  @xcite .",
    "existing algorithms produce one single solution which equals or approximates the maximum clique . in the weighted case maximization",
    "is done only over unary terms associated to vertices .",
    "this is different from our case .",
    "we desire multiple tilings for each image and the potential of a clique ( tiling ) depends on both unary and pairwise terms .",
    "enumerating all cliques to find the optimum is not feasible as we deal with many vertices ( over 150 ) and the complexity to enumerate all cliques of size @xmath14 of a graph with @xmath1 vertices is @xmath15 .",
    "finding a _ maximal _ clique can be done in linear time in the number of vertices , by starting with one vertex and adding each of the other vertices in some order .",
    "but graphs that have a large maximum clique can have maximal cliques of arbitrary small size . to obtain multiple estimates",
    "we follow a two step greedy approach : _ _ ( _ _ i ) starting with each vertex generate a maximal clique ; _ _ ( _ _ ii ) refine each solution using a local search in the space of maximal cliques based on the trained cost function .",
    "we generate up to @xmath1 different tilings , ranked in decreasing order of @xmath16 .",
    "notice that our approach is based on established strategies to find approximations of the maximum clique ( step 1 is known as a _ sequential greedy heuristic _ and step 2 as a _ local search heuristic _",
    "_ algorithm _  [ alg : greedy - tiling ] describes the proposed method .",
    "* input * : pool of @xmath1 segments @xmath0 , weights @xmath13 , features @xmath17 .",
    "+    @xmath18 segments in @xmath0 in decreasing order of @xmath19 [ lin : start ] @xmath20 [ lin : step1-st ] [ lin : step1-test ] @xmath21 [ lin : step1-end ]    @xmath22    @xmath23 @xmath24    * output * : pool of tilings @xmath25 for the current image ranked in decreasing order of @xmath26 .",
    "[ [ complexity ] ] complexity : + + + + + + + + + + +    the size of the largest clique that can be formed with a certain vertex is bounded by the degree of this vertex , in our case @xmath27 .",
    "if a set @xmath28 is kept , containing the segments in @xmath29 which are not overlapping any segment in @xmath30 , the complexity of step 1 is @xmath31 .",
    "maximum @xmath1 steps are needed to build @xmath28 from the list of sorted segments and @xmath32 is an upper bound for the loop in step 1 and the verification inside .",
    "step 2 can be executed in @xmath33 where @xmath34 is the maximum number of iterations allowed . ] .",
    "the inner loop over all @xmath35 is bounded by @xmath36 as @xmath35 must not overlap @xmath10 . rejecting segments in @xmath37 overlapping with @xmath35",
    "is also bounded by @xmath36 as all segments previously in @xmath37 are not overlapping @xmath10 . finally , extending @xmath37 to a maximal clique has the same complexity as step 1 , namely @xmath31 .    ordering the segments",
    "is done only once , thus the complexity for running _ fg - tiling _  for all segments @xmath38 is @xmath39 where the dominant worst case component is @xmath40 if @xmath34 is fixed . in practice",
    "our matlab implementation using @xmath41 takes on average 20 seconds per image for the bsds test set .",
    "assume we are given a set of features @xmath42 computed , respectively , for segments @xmath38 and pairs of segments @xmath43 which are neighbors in the image , i.e. @xmath11 share a common boundary and do not overlap .",
    "we search for the weights @xmath13 such that the ranking of tilings induced by @xmath16 ( eq .  [ eq : score - tiling ] ) is as close as possible to the ranking induced by the quality of the tilings with respect to the ground truth .",
    "* input * : segments @xmath44 for the images in the training set @xmath45 , features @xmath17 , rank @xmath46 .",
    "+    @xmath47 @xmath48 _ fg - tiling_(@xmath49 ) [ lin : outer - start ] @xmath50 [ lin : inner - loop ] @xmath48 _ fg - tiling_(@xmath51 ) [ lin : outer - end ]    * output * : weights @xmath13 .",
    "the learning process alternates between the discrete optimization of tilings , where it runs _ fg - tiling _  with the existing parameters @xmath52 to create a new pool of tilings for each of the images in the training set , and a continuous parameter optimization step that finds parameters @xmath52 which maximize an objective function @xmath53 on the produced tilings , as used for testing : the overlap with ground truth ( _ algorithm _  [ alg : learning ] ) . instead of aiming to enforce only the best tiling in the first position , which might be impossible",
    ", we design a scoring ( with best as special case ) that aims at ranking tilings in decreasing order of their quality . for an image @xmath54 , weights @xmath52 , and a pool of tilings @xmath55 where @xmath30 is the tiling at rank @xmath56 when sorting @xmath57 in decreasing order of the value of @xmath26 , the objective function @xmath58 is : @xmath59 where @xmath60 is the quality of @xmath30 measured using the ground truth ,",
    "@xmath61 is the weighting of rank @xmath56 , and @xmath46 is the rank parameter which determines the constraint we want to enforce ( e.g. @xmath62 for only the best ranked , @xmath63 for a full k - ordering ) .",
    "we define @xmath60 as the average _ covering _ of @xmath30 with all ground truth segmentations as in  @xcite .",
    "the covering is the sum of overlaps between each individual segment in a ground truth segmentation and the closest segment in a tiling , multiplied by the area of the ground truth segment .",
    "@xmath64 is the standard overlap measure between @xmath10 and @xmath65  @xcite . for rank weighting ,",
    "we use : @xmath66 $ ] .",
    "this decay is similar to the _ discounted cumulative gain _ ( dcg )  @xcite that uses a logarithmic reduction factor of the form @xmath67 .",
    "dcg penalizes more aggressively the error in the first ranks .",
    "we found this to work slightly less well in our tests . with @xmath1 nodes ,",
    "clique potentials can be used to define a constrained probability distribution over partitions .",
    "we can write a gibbs distribution over cliques as @xmath68 , and can learn using ml , with partition functions approximated by summing only over @xmath69 cliques , computed by _ fg - tiling _  ( this approach will be presented in an upcoming technical report . ) . here",
    "we choose a different loss that directly optimizes the overlap measure used during test time .",
    "notice however , our very different use of cliques compared to product expansions in graphical models . along this path , modeling the nodes as binary variables in a random field would neither produce the semantics we need , nor would necessarily lead to clique consistent inference . ]",
    "our model aims to generate full image tilings that have properties similar to the ones of ground truth segmentations produced by human annotators .",
    "we use both unary features inspired by gestalt properties and pairwise features sensitive to the boundary statistics arising from projections of 3d surfaces , for a total of @xmath70 unary and @xmath71 pairwise features .",
    "these features are computed once and do not change during learning and inference .",
    "all features are individually normalized to zero mean and standard deviation @xmath72 .",
    "* unary descriptors : * as unary features , we primarily use the ones proposed in @xcite , that include the amount of * contrast along the boundary * of the segment ( 8 features ) , @xmath73 , region properties such as position in the image , area and orientation , @xmath74 ( 18 features ) , as well as * gestalt * properties such as convexity and dissimilarity between the segment interior and the rest of the image in terms of intensity and texture , @xmath75 ( 8 features ) .",
    "we complemented the unary features in @xcite with a novel set of @xmath76 responses quantifying * center - surround dissimilarity * , @xmath77 .",
    "we define three image strips of width @xmath78 , @xmath79 and @xmath80 pixels around each segment .",
    "we compute how dissimilar each strip and the segment are according to @xmath81 different local features : hue , rgb , sift and textons .",
    "for each type of local feature and each strip , dissimilarity is determined as the chi - square distance between the histogram of quantized local features in the strip and in the segment , resulting in the @xmath76 features .",
    "the local features are sampled on a regular grid , every @xmath82 pixels .",
    "the color histograms use patches @xmath81 and @xmath83 pixels wide , while the sift patches are @xmath83 and @xmath78 pixels wide .",
    "the textons are the ones used in globalpb  @xcite quantized into @xmath84 bins .",
    "we quantize the other features into @xmath79 bins , with the codebook being obtained _ in each image _ at test time by k - means .",
    "+ * pairwise descriptors : * we define a segment neighborhood between pairs of segments sharing a boundary and not overlapping .",
    "the occurrence of such pairs is usually non - accidental , particularly in our pool of figure - ground segmentations , because we do nt consider the _",
    "ground_. segments that are artifacts of the particular parameter and location constraint that generated them will tend to have few neighbors . computing this type of neighborhoods",
    "can be done robustly by growing all segments by a small amount ( 4 pixels in our implementation ) and then detecting the pairs that overlap .",
    "the pairwise features capture the configuration of pairs of segments .",
    "we use two sets of pairwise features .",
    "the first encodes * pairwise region properties * such as relative area , position and orientation and is simply defined by @xmath85 ( 18 features ) .",
    "we also employ @xmath81 features which signal occlusion . in ground truth segmentations",
    ", neighboring segments often correspond to projections of objects at different depths , which result in distinctive image statistics .",
    "these are sufficiently informative even for determining which of the two neighboring regions corresponds to the occluding surface in 3d space , the so called figure - ground assignment problem @xcite @xcite .",
    "the occluding segment usually has a higher convexity coefficient and is often surrounded by the occluded segment .",
    "let @xmath86 be the unary convexity feature in @xmath75 .",
    "then the * relative convexity * feature is implemented as @xmath87 .",
    "let the length of the adjacent boundary between two segments be @xmath88 , and the segment perimeters be @xmath89 and @xmath90 . then * surroundedness * is defined as @xmath91 .",
    "another important occlusion features are * t - junctions * , boundary patterns shaped as a t , usually caused by the intersection of the boundaries of two objects in an occlusion relationship .",
    "typically the location of the leg of the t indicates which segment is occluding the other .",
    "t - junctions were used in recent approaches to figure - ground assignment , as an energy term for triplets of regions in crfs @xcite @xcite @xcite . here",
    "we model them directly as a pairwise segment compatibility feature , by measuring the consistency with which the leg of the t - junctions belongs to the same segment , weighted by the quality of the fitting of the junction to a t , as opposed to being y - like .",
    "the feature is defined as @xmath92}|$ ] , with the sums being over all junctions between the pair of segments .",
    "the weighting is @xmath93 , @xmath94 being the angle formed by the leg of the junction @xmath95 with the base .",
    "when the leg of the junction is on the boundary separating both segments , or the leg is not on the boundary of segment @xmath56 then @xmath96 is set to @xmath97 .",
    "junctions are hard to detect when considering pixel intensities locally , even for humans @xcite . but given a pair of neighboring segments this can be done robustly , as illustrated in fig .",
    "[ fig : tjunction ] .",
    "the * shading along region borders * was shown to provide information about occlusion in both computational @xcite and psychophysical tests , under the name of _ extremal edges _ @xcite .",
    "the phenomenon is explained by the illumination gradient tending to be orthogonal to the boundary , on the occluding side .",
    "we implement the gradient orthogonality feature @xmath98 as in @xcite and produce the compatibility feature as @xmath99 .",
    "the absolute value is computed because we re not interested here in determining which segment is in front , just in having an occlusion indicator .",
    "[ fig : tjunction ]",
    "our inference and learning methods were tested on the berkeley dataset ( bsds ) @xcite and on the pascal voc 2009 segmentation dataset ( voc2009 ) @xcite . for comparison",
    "we show results of the oriented watershed transform ultrametric contour maps using globalpb as contour detector ( gpb - owt - ucm ) @xcite .",
    "we generate a pool of segments using the publicly available implementation of constrained parametric min - cuts ( cpmc ) @xcite , which produces nested sets of segments around rectangular seeds on a regular grid with predicted qualities for each segment . per image",
    "an average of 194 segments is generated for the bsds test set and 156 segments for the voc2009 validation set .",
    "this algorithm was recently shown to produce compact sets of segments that accurately cover ground truth objects .",
    "[ fig : plots - tilings ] shows the evaluation of _ fg - tiling _  and two baselines , _ enum-1min _  and _ constrained - random _",
    ", on the bsds dataset ( see sec .  [",
    "sec : experiments ] ) .",
    "all methods produce maximal cliques i.e. tilings with segments that do not overlap and the cliques can not be extended using the current pool of segments . for each method",
    "the produced tilings are ranked using the scoring function in eq .",
    "[ eq : score - tiling ] .",
    "_ enum-1min _  is an algorithm that recursively , exhaustively , enumerates maximal cliques until the given time of 1 minute per image is reached and returns the highest scoring @xmath1 cliques that have been found the average time of _ fg - tiling _  on the bsds test set . without the time constraint",
    "the algorithm did not finish enumerating cliques after 48 hours on a test image where a pool of @xmath100 figure - ground segmentations had been used . ] .",
    "similar to line  [ lin : start ] of _ fg - tiling _ , _ enum-1min _",
    "first sorts the segments based on @xmath19 . during enumeration , it quickly finds one tiling similar to the result of step 1 in _ fg - tiling_. however , within 1 minute , it produces only small variations of the same tiling , as seen also in fig .",
    "[ fig : plots - tilings ] , right .",
    "_ constrained - random",
    "_  is similar to step 1 in _ algorithm _  [ alg : greedy - tiling ] with the difference that in line  [ lin : start ] the order of the segments is randomized .",
    "the method gets a few  lucky shots  which explains the quite high values in the plot in fig .",
    "[ fig : plots - tilings ] left , but overall the average quality of the produced tilings is much lower than the other two methods ( 23% less than _ fg - tiling _  on the test set of bsds ) . _ fg - tiling _  balances the diversity and quality of the produced tilings to give the best results of all methods .     for number of tilings considered .",
    "_ center _ : average quality for given rank ( if exists ) .",
    "the quality @xmath101 was measured with respect to the ground truth using the _ covering _ measure ( see sec .",
    "[ sec : experiments ] for details ) .",
    "_ right _ : histogram of pairwise similarity between produced segmentations .",
    ", title=\"fig:\",width=181 ]   for number of tilings considered .",
    "_ center _ : average quality for given rank ( if exists ) .",
    "the quality @xmath101 was measured with respect to the ground truth using the _ covering _ measure ( see sec .  [",
    "sec : experiments ] for details ) .",
    "_ right _ : histogram of pairwise similarity between produced segmentations .",
    ", title=\"fig:\",width=181 ]   for number of tilings considered .",
    "_ center _ : average quality for given rank ( if exists ) . the quality @xmath101 was measured with respect to the ground truth using the _ covering _ measure ( see sec .  [ sec : experiments ] for details ) .",
    "_ right _ : histogram of pairwise similarity between produced segmentations .",
    ", title=\"fig:\",width=181 ] +    during learning , for the initial run of _ fg - tiling _  we set the weights @xmath102 corresponding to the pairwise terms to zero . the weights @xmath103 corresponding to the unary terms are set using linear regression s.t . @xmath19 approximates the response @xmath104 where @xmath105 is the set of ground truth segments for the image .",
    "parameter optimization is done using a quasi - newton method . during this step ,",
    "the sum of @xmath53 over all images in the training set and their corresponding pools of tilings is maximized .",
    "the first time this step is executed , the initial weight estimates @xmath13 required to initialize the search are obtained using linear regression over all tilings produced for the training set .",
    "regression uses targets @xmath101 for each tiling @xmath2 .",
    "the inner loop ( line  [ lin : inner - loop ] ) needs on average 15 iterations to converge .",
    "the outer loop ( lines  [ lin : outer - start][lin : outer - end ] ) saturates after a few iterations ( 34 ) and both the quality of the first ranked tiling as well as the highest quality over all tilings for each image are maximized .",
    "rank optimization on the bsds dataset .",
    "_ left _ : progress of the first ranked and the highest quality tilings on the training and testing sets .",
    "iteration 0 corresponds to the results with the initial weights @xmath106 , iteration 1 : the same tilings after the first optimization step , iterations 23 : after new tilings and learned weights .",
    "_ center _ : highest quality vs. number of segmentations retained on the bsds test set .",
    "_ right _ : highest quality vs. number of segmentations retained with no rank learning , learning with rank parameter @xmath107 and @xmath108.,title=\"fig:\",width=181 ]   rank optimization on the bsds dataset .",
    "_ left _ : progress of the first ranked and the highest quality tilings on the training and testing sets .",
    "iteration 0 corresponds to the results with the initial weights @xmath106 , iteration 1 : the same tilings after the first optimization step , iterations 23 : after new tilings and learned weights .",
    "_ center _ : highest quality vs. number of segmentations retained on the bsds test set .",
    "_ right _ : highest quality vs. number of segmentations retained with no rank learning , learning with rank parameter @xmath107 and @xmath108.,title=\"fig:\",width=181 ]   rank optimization on the bsds dataset .",
    "_ left _ : progress of the first ranked and the highest quality tilings on the training and testing sets .",
    "iteration 0 corresponds to the results with the initial weights @xmath106 , iteration 1 : the same tilings after the first optimization step , iterations 23 : after new tilings and learned weights .",
    "_ center _ : highest quality vs. number of segmentations retained on the bsds test set .",
    "_ right _ : highest quality vs. number of segmentations retained with no rank learning , learning with rank parameter @xmath107 and @xmath108.,title=\"fig:\",width=181 ] +    fig .",
    "[ fig : plots - learning ] shows the progress of learning on the berkeley segmentation dataset ( bsds )  @xcite using @xmath108 and a comparison of the results : without learning , learning with @xmath107 and with @xmath108 .",
    "we observe that compared to @xmath107 , @xmath108 produces a slightly better ranking also on the first position , presumably due to the additional constraints from lower ranks .",
    "c|c|c|c|c bsds & ois & first & ods & bis + [ 0.5ex ] max .",
    "possible & 0.73 & 0.73 & 0.73 & 1.00 + gpb - owt - ucm & 0.64 & - & 0.58 & 0.74 + [ 1ex ] _ fg - tiling _ & 0.64 & 0.58 & - & 0.78 +    c|c|c|c|c voc2009 & ois & first & ods & bis + [ 0.5ex ] max .",
    "possible & 1.00 & 1.00 & 1.00 & 1.00 + gpb - owt - ucm & 0.58 & - & 0.45 & 0.61 + [ 1ex ] _ fg - tiling _ & 0.74 & 0.52 & - & 0.78 +    table  [ table : results_voc_berkeley ] shows results of benchmarks on the test set of bsds and on the validation set of voc2009 .",
    "the values represent average covering scores of ground truth segmentations by the output segmentations .",
    "bis measures the best covering of the ground truth segmentations by individual segments from any segmentation produced by the evaluated method .",
    "ois and ods have been used in  @xcite to evaluate the results of gpb - owt - ucm .",
    "they have been introduced in the context of hierarchical segmentation , where scale is used to navigate from coarser to finer segmentations .",
    "the optimal image scale ( ois ) measures for each image the quality of the produced segmentation that best covers the ground truth .",
    "the optimal dataset scale ( ods ) measures the quality of the segmentations when the same scale is selected for all images .",
    "the scale to be evaluated is chosen to maximize the score on the test set . ",
    "first `` evaluates the results using the predicted best segmentation for each image . ' ' first `` is only applicable to our method , since the segmentations from gpb - owt - ucm do nt have associated scores to select a single segmentation .",
    "ods is not applicable to our method , as _ fg - tiling _  generates independent segmentations . note that ' ' first  does not use any ground truth information to select the tiling to be evaluated for each image .",
    "the bsds dataset has multiple ground truth ( human ) segmentations for each image .",
    "to evaluate the quality of a segmentation , the average over all ground truth segmentations for that image is considered . as the provided",
    "human segmentations are different , the upper bound for ois ,  first  , and ods on the bsds test set are 0.73",
    ". a score of 1.00 for bis could be obtained by generating segments that perfectly cover all ground truth segments .",
    "the results obtained by _ fg - tiling _   are competitive on bsds and superior on the voc2009 .",
    "note that the given voc2009 scores are not using the  segmentation challenge  evaluation which requires recognition , but evaluating the quality of unlabeled segmentations like the method we compare with  @xcite .",
    "the results of gpb - owt - ucm on voc2009 have been computed by us using the code provided by the authors and are consistent with their published results on voc2008 .",
    "we have proposed a mid - level computational learning and inference framework for image segmentation that tiles multiple figure - ground hypotheses into a complete interpretation .",
    "the inference problem is formulated as searching for high - scoring maximal cliques in a graph connecting non - overlapping putative figure / ground hypotheses .",
    "clique potentials are based on both intrinsic gestalt segment quality and compatibilities among neighboring image segments , as derived from statistics of 3d scene boundaries .",
    "learning is formulated as optimizing the ranking of the best - k hypotheses , directly on the testing error , measuring the overlap between image tilings and the ground truth human annotations .",
    "we have empirically analyzed the performance of our learning and inference components and have shown that these achieve state of the art results in the berkeley and the voc2009 segmentation benchmarks . in the latter the proposed method improves on the state - of - the - art by 28% when considering the full set of generated tilings , and by 16% for the predicted best tiling . in future work we plan to combine segmentation and partial recognition in order to be able to interpret images that contain both familiar and unknown objects .",
    "m.  everingham , l.  van  gool , c.  k.  i. williams , j.  winn , and a.  zisserman",
    ". the pascal visual object classes challenge 2009 ( voc2009 ) results .",
    "http://www.pascal-network.org/challenges/voc/voc2009/workshop/index.html .",
    "d.  martin , c.  fowlkes , d.  tal , and j.  malik .",
    "a database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics . in _",
    "ieee international conference on computer vision _ , 2001 ."
  ],
  "abstract_text": [
    "<S> we propose a mid - level image segmentation framework that combines multiple figure - ground hypothesis ( fg ) constrained at different locations and scales , into interpretations that tile the entire image . </S>",
    "<S> the problem is cast as optimization over sets of maximal cliques sampled from the graph connecting non - overlapping , putative figure - ground segment hypotheses . </S>",
    "<S> potential functions over cliques combine unary gestalt - based figure quality scores and pairwise compatibilities among spatially neighboring segments , constrained by t - junctions and the boundary interface statistics resulting from projections of real 3d scenes . learning the model parameters </S>",
    "<S> is formulated as rank optimization , alternating between sampling image tilings and optimizing their potential function parameters . </S>",
    "<S> state of the art results are reported on both the berkeley and the voc2009 segmentation dataset , where a 28% improvement was achieved . </S>"
  ]
}