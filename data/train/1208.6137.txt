{
  "article_text": [
    "we have created pixel level annotation of word images publicly available for download , specifically for word image segmentation . we have annotated different datasets consisting of different kinds of word images . to our knowledge ,",
    "annotation at pixel level and among several datasets has not been carried out , until now .",
    "small subsets from different datasets have been annotated and utilized for algorithms @xcite .",
    "we have annotated 3606 word images at pixel level .",
    "annotation is not fully automated .",
    "hence , it is a huge task as compared to similar tasks in computer vision or document imaging community .",
    "a human being requires a very short time to analyze any given image . to perform similar analysis by a computer algorithm",
    "is not simple .",
    "people analyze images using both top - down and bottom - up paradigms . combining these two approaches",
    "is not an easy task .",
    "we often read that top - down is far better than bottom - up approach in image analysis .",
    "the relative contribution of top - down and bottom - up approaches in human vision is clearly unknown .",
    "an approach is developed to understand this contribution . for this approach",
    ", it was essential to annotate word images at the pixel level .",
    "we split the recognition of word from images into segmentation and recognition tasks .",
    "the term ` binarization ' is commonly used in place of segmentation .",
    "we require complex algorithms to segment an image . in document imaging community ,",
    "conventional research primarily focused on digitization of scanned documents .",
    "it involved binarization of document image and recognition . in the section on annotation , we discuss known algorithms for segmentation of word images . these algorithms were helpful in improving the speed of pixel level annotation .",
    "annotated pixel level word images can be used to train and test any classifier .",
    "however , several good optical character recognition ( ocr ) engines are already available for roman script @xcite .",
    "hence , we focus only on the annotation algorithm and annotating datasets",
    ".    necessity of annotation arises during benchmarking datasets .",
    "earlier to our pixel level approach , scene - text images have largely been annotated using bounding box approach .",
    "it makes annotation an easier task . of course",
    "few datasets do provide pixel level annotation , but they do not cover thousands of images .",
    "the annotated images are passed on to the recognition stage .",
    "the recognition step can be performed using a training dataset or an ocr engine .",
    "we use the trial version of omnipage professional 16 ocr for recognition of characters in the binarized image @xcite to create the benchmark recognition result . definitely the numbers will slightly vary if we use any other standard ocr and hence the benchmark results we report here indicate a rough level of recognition that can be achieved , rather than the exact maximum value attainable in current circumstances .    if a single dataset is used in the experiments , it may lead to a dataset specific approach .",
    "so , to justify our approach that annotation is dataset independent , we cover five datasets for benchmarking .",
    "either top - down or bottom - up approach is used in some datasets and both in others .",
    "these datasets are from icdar 2003 competition @xcite , icdar 2011 competition @xcite , street view @xcite and sign evaluation datasets @xcite .",
    "when a camera captured image is presented to an ocr engine , the recognition performance is not necessarily very good . this led to spliting",
    "the process of word recognition in camera captured images into two parts , namely localization ( or detection ) and recognition by lucas et .",
    "al @xcite .",
    "in international conference on document analysis and recognition ( icdar ) 2003 , they organized separate competitions for text localization on camera captured images and recognition from the word images extracted by placing a bounding box on the image .",
    "they received five entries for text localization and none for word recognition . in the following icdar 2005 conference ,",
    "text localization was the main theme and word recognition was skipped @xcite .",
    "there are several publicly available datasets for text localization @xcite .",
    "these datasets are known as iapr tc11 reading systems - datasets .",
    "one may assume that the bounding box information of a word is sufficient for any ocr to recognize .",
    "however we see that the best performing algorithm on icdar 2003 sample word image dataset ( not the test set ) has the word recognition rate of only around 52% , without post processing using lexicon @xcite .",
    "recently held icdar 2011 , robust reading challenge 2 reports that the best word recognition rate is 41.2% @xcite .",
    "figure [ examples ] shows sample word images from this challenge .",
    "+   +    karatzas et .",
    "al initiated another robust reading challenge in icdar 2011 for born - digital images @xcite .",
    "born - digital images are formed by a software by overlaying text on an image .",
    "for the competition , these images were collected from web pages and email .",
    "most words present in this dataset are oriented horizontally .",
    "the reason behind horizontal placement of text may be the simplicity involved in creating the born - digital image using standard softwares .",
    "low resolution of text and anti - aliasing are the main issues to be tackled in born - digital images , whereas illumination changes and motion blur are difficult problems in the case of camera captured images .",
    "these issues indicate the complexity involved in processing born - digital and camera captured scenic images .",
    "an attempt for using top - down approach in word recognition can be observed in , sparse belief propagation with lexicon for word recongition by weinmann et .",
    "al @xcite .",
    "similarly , wang et .",
    "al use limited lexicon on street view text ( svt ) dataset @xcite . both , weinmann et .",
    "al and wang et .",
    "al , use top - down approach for word recognition .",
    "they use an unsegmented character dataset to train a classifier .",
    "if the confidence of the character classifier is less , then top - down approach helps in classification using lexicon .",
    "weinmann et .",
    "al use character level image annotation of the training data and textual features to classify the testing dataset .",
    "a limitation of this method is that it requires good quality character images with high resolution for training ; else the classification will be erroneous .",
    "al used amazon s mechanical turk for annotation of svt images .",
    "bounding box was placed around the word spotted .",
    "the placement of these bounding boxes was not defined rigorously .",
    "the resulting irregularities in the word bounding boxes add additional complexity to the segmentation task and can be inferred from the low f - score reported . in the section on benchmark results of svt dataset , we discuss as to how one can avoid this complexity .",
    "benchmarking is not a good idea , if annotation is not explicitly defined rigorously .",
    "we took five different datasets which have different definitions for bounding box and contain human errors while annotating bounding boxes for words . our pixel level segmentation and annotation",
    "has been cross - checked thoroughly to reduce human errors to a minimum .",
    "a multi - script annotation toolkit for scenic text ( mast ) was developed by mile lab in 2011 @xcite .",
    "it can be used to annotate scenic images .",
    "mast has the facilities to annotate multiple scenic images or scenic word images .",
    "it has options for annotating multiple scripts .",
    "it has the additional capability for adding plug - ins with suitable layout for new scripts during annotation .",
    "it is publicly available for download .",
    "mast - ch , an enhanced version of character annotation tool kit has been recently developed by us .",
    "we discuss the differences between the two programs .",
    "mast is designed to annotate scenic images with multiple word images with reasonably good resolution . using seed points input by the user ,",
    "the tool uses region growing and annotates at the pixel level , with a bounding box and text annotation for multiple scripts . on the other hand ,",
    "mast - ch handles a single word image at a time and annotates characters at the pixel level using multiple segmentation methods and user selection of output .",
    "it does not have provision to generate the text annotation for different scripts .",
    "since some of the images in the datasets used contain low resolution images and truthed text is already available , we use mast - ch toolkit to perform pixel level annotation .",
    "+    we have added new functionalities based on feedback from mile lab project staff , who helped annotate the various datasets .",
    "a gui of the tool kit with the buttons and a single window for image is shown in figure [ mgui ] . `",
    "load ' button enables us to load images from a particular directory .",
    "if a word image is highly degraded , and hence requires more time to annotate , it can be skipped .",
    "those skipped images will not be tagged .",
    "` next ' and ` prev ' buttons provide the user options for such skipping and going back during annotation , that help in rapid annotation of clean word images . `",
    "save ' button saves an annotated word image in .bmp format , also containing component ordering information and in .tiff format , containing colour map for individual components segmented ) .",
    "gui also displays whether the currently loaded word image has already been tagged or not . `",
    "view mask ' button overlays the obtained segmentation mask on the original word image .      in mast , we",
    "segment words by region growing on the seeds placed by the user and then annotate the segmented words @xcite .",
    "difficulty crops up when low resolution characters are to be annotated . to reduce the manual task and also to improve segmentation , we have removed the seed growing option . in place of it , we now use known segmentation algorithms .    for segmentation , we have provided a drop down button giving ` binarize ' and ` invert ' options . the user can invoke the suitable option based on the relative colors of the foreground and background . using multiple approaches ,",
    "we create 16 different segmentation outputs .",
    "first , we split a colour image into the r , g , b planes and apply otsu s threshold on each plane @xcite .",
    "we also convert the rgb image to hsv and cie lab space formats .",
    "then , we split each of them into three planes and apply otsu s threshold .",
    "in addition , we form three clusters using the rgb information directly and obtain the permutations for the clusters formed ( each of the 3 clusters and union of any two clusters at a time ) . finally , we apply robust automatic threshold selection algorithm on intensity of word image @xcite .",
    "we display all of these segmentation results in another window and provide a manual keyboard input for the user to select one of the results .",
    "once a user input is fed , a mask is generated and overlaid on the original image . by this way , we have removed manual seeding technique , which has improved the speed of segmentation task and reduced the fatigue of the annotators",
    ". if the mask generated has distinct or well separated characters , then the user can save the annotated result by clicking the ` save ' button .",
    "if none of the segmentation results are satisfactory , the user can choose ` 0 ' and thus no mask will be generated .",
    "` reload ' button is used to load a saved mask and the corresponding original image .",
    "this is useful to examine annotated images . to minimize human errors ,",
    "we cross - checked the annotated datasets three times .",
    "a degraded image may not get segmented properly .",
    "this may be due to illumination changes , occlusion or low resolution of characters . to overcome these degradations",
    ", we provide a polygonal mask .",
    "these masks can be used to add parts of characters which are merged to the background or delete parts of the background that get added to a character . ` add patch ' button provides the option for adding pixels to the annotated mask in the polygonal format . `",
    "delete patch ' button facilitates deletion of the background segmented as characters or splitting merged characters .",
    "when add or delete option is selected , we can place a single polygon at a given time .",
    "mask will be modified based on the operation performed and the annotation tool asks whether to continue the same operation .",
    "if user chooses ` yes ' , then the user can place another polygon to modify the annotated characters .",
    "if the choice is ` no ' , then the tool exits this edit loop .     +",
    "the pixel - level segmented images are fed to the recognition engine .",
    "tesseract @xcite , omnipage @xcite , adobe reader @xcite and abbyy fine reader @xcite are examples of readily available ocr engines . any of these ocr softwares can be used to recognize the binarized word image . in our experiment",
    ", we use the trial version of omnipage professional 16 ocr for recognizing the word images .",
    "the recognition rate of the ocr on the above segmented word images is compared with the recognition results of the methods reported in the literature . in all these datasets",
    ", we can observe that the recognition rate on human segmented images is better than the rest .",
    "normally , any scanned document image contains top , left , right and bottom margins .",
    "however , as shown in figure [ recpreprocess](a ) , when we binarize a scene or a born - digital word image , margins do not exist since we have segmented at the word boundary .    in such cases , where characters touch the boundary , we observe difficulty in recognition with the ocr engine .",
    "to avoid this difficulty and also to provide margin in all directions , we add zero rows at the top and the bottom of the image , equal to half the original number of rows in the word image .",
    "similarly , we pad zero columns on both the left and right sides of the word image .",
    "we refer these images as _ preprocessed _",
    "binarized images [ see figure [ recpreprocess](b ) ] . preprocessed binarized images are sent to the ocr for recognition .",
    "recognition rates on binarized images are reported in the experimental section .",
    "we consider five word image datasets for experimentation .",
    "all these datasets are tagged using the annotation tool explained in section 3 .",
    "icdar , svt and born - digital word images have been annotated .",
    "images with visually distinguishable boundaries between characters and background are tagged .",
    "others have been ignored , since if a human can not tag the text , we can not expect an algorithm to either segment or recognize it .",
    "the annotated dataset is available for download from our mile laboratory website .",
    "if any errors are observed , please report to the authors .",
    "these datasets cover different types of degradations except for motion blurs .",
    "all words in the dataset are tagged appropriately such that the visual distortion with respect to original image is minimum . in all the datasets , we have considered the testing set .",
    "we can improve the character segmentation using word images from the training set .",
    "we give below the recognition results for the five different datasets experimented upon .",
    "robust reading competition was first conducted in icdar 2003 @xcite .",
    "there were five entries for text localization and none for word recognition .",
    "mishra et .",
    "al express the importance of binarization for word images and show 52% as word recognition on sample dataset @xcite .",
    "this result explains that an equal importance should be given to word recognition .",
    "if we compare recognition rates of existing methods , this becomes more obvious .",
    "icdar 2003 test dataset consists of 1110 word images , all of which are segmented by the authors .",
    "the word recognition rates are tabulated in table [ icdar03table ] .",
    "table [ icdar03table ] shows a large gap in recognition rate between the preprocessed and non - processed images .",
    "this is because the low resolution text images are not recognized properly without proper margins formed by the background .",
    "wang and mishra et .",
    "al have used 829 images , a subset of icdar 2003 image dataset @xcite .",
    "hence , the reported result is averaged to the total number of images in the dataset .",
    ".recognition rates on word images binarized by methods reported in the literature for icdar 2003 dataset .",
    "[ cols=\"^,^\",options=\"header \" , ]      this dataset , a subset of icdar 2003 dataset , was used in icdar 2011 robust reading challenge task 2 .",
    "it consists of 716 word images . in this dataset ,",
    "a few additions have been made and repeated words from the icdar 2003 dataset have been removed .",
    "those removed images are from the scene images and were not considered either in the testing or training of icdar 2011 competition .",
    "the recognition rates of existing methods are shown in table [ icdar11table ] .",
    "we can observe that the recognition rate has improved with respect to icdar 2003 dataset .",
    "there were three entries for word recognition competition in icdar 2011 : robust reading competition challenge 2 .",
    "so , we have included this dataset for discussion .    here , we could not access the recognition rate of non - preprocessed binarized image .",
    "due to polarity reversal of some images by ocr itself , this resulted in erroneous text .",
    "the reason is that the bounding boxes specified are tight .",
    "word images in the test dataset do not have any additional pixels around the word boundary , as discussed in born - digital 2011 dataset .",
    "we have prepared pixel level annotation for five word image datasets .",
    "we took this huge task of annotation , in order to show that segmentation of word images is important to recognize characters / words . even though top - down analysis is useful in improving the recognition rate on specific datasets using a limited lexicon , it is not practical in real world situation . weinmann et .",
    "al showed that the recognized word rate reduces with full lexicon .",
    "+   +    around 85% of word recognition is achieved with manual segmentation .",
    "thus , if we provide more importance to proper segmentation of characters countering all degradations , we can improve the recognition . here",
    ", all word images were segmented in such a way that individual components in the segmented image can be properly recognized or classified by a classifier or an ocr engine .    in this paper",
    ", we infer that if we train dataset specific classifier with annotated word images , then we can use the training dataset for word recognition .",
    "skewed or curved words in the images can be classified better by a custom - built classifier than an ocr engine .",
    "we can observe that in street view dataset , the recognition rate of words is often poor due to skew or curvy nature of words .",
    "figure [ svtimages ] shows sample images from street view dataset with different degradations .",
    "hence , the trained classifier will help in improving the recognition rate .",
    "in the case of skewed or curved words , a trained classifier is less affected and with minimal processing , we can improve the recognition rate .",
    "standard ocr engines do not provide this functionality . also we use individual test characters segmented to measure stroke width of the characters , which helps in improving the segmentation as a top - down approach .",
    "we have completed the annotation of five standard databases .",
    "we have made the annotated datasets publicly available for download from our mile website .",
    "any one can download and test them using any ocr engine .",
    "the recognition rate differs across ocr engines and also with the versions . from all the tabulated results ,",
    "it is evident that we need to improve the segmentation algorithms to get better word recognition .",
    "our approach indicates the requirement for good segmentation , since it is the major part of the bottom - up approach .",
    "we can use lexicon information to improve the recognition rate reported .",
    "the validity of our good segmentation can be indirectly seen from the achieved word recognition rates .",
    "we express our heartfelt thanks to shanti devaraj , shanti s and saraswathi s , who were involved in the segmentation of word images .",
    "improvement in ui for word image annotation was possible only from their feedback .",
    "the annotation work has minimal errors .",
    "the credit goes to them for careful annotation and committed interaction with the authors .",
    "finally , without them , our dream to annotate all the images at the pixel level would not have been accomplished .",
    "s.  m.  lucas et .",
    "al ,  `` icdar 2003 robust reading competitions : entries , results , and future directions '' , _ international journal on document analysis and recognition _ , vol . 7 , no .",
    "2 , pp . 105122 , june 2005 .",
    "h.  liu , x.  ding ,  `` handwritten character recognition using gradient feature and quadratic classifier with multiple discrimination schemes '' , proc .",
    "8th _ int .",
    "document analysis and recognition _ , pp.19 - 25 , 2005 .",
    "s.  lee , m.  s.  cho , k.  jung and j.  h.  kim , `` scene text extraction with edge constraint and text collinearity , '' _ international conference on pattern recognition _ , pp . 39833986 , 2010 .",
    "d.  karatzas , s.  robles  mestre , j.  mas , f.  nourbakhsh and p.  pratim  roy ,  `` icdar 2011 robust reading competition - challenge 1 : reading text in born - digital images ( web and email ) '' , proc .",
    "11th _ international conference of document analysis and recognition _ , pp . 14851490 , 2011 .",
    "http://www.cv.uab.es/icdar2011competition/    a.  shahab , f.  shafait and a.  dengel ,  `` icdar 2011 robust reading competition - challenge 2 : reading text in scene images '' , proc .",
    "11th _ international conference of document analysis and recognition _ , pp . 14911496 , 2011 .",
    "t.  kasar , d.  kumar , m.  n.  anil prasad , d.  girish and a.  g.  ramakrishnan ,  `` mast : multi - script annotation for scenic images toolkit '' , proc .",
    "_ joint workshop on multilingual ocr and analytics for noisy and unstructured text data _ , pp .",
    "18 , beijing , china , september 2011 .",
    "t.  kasar and a.  g.  ramakrishnan,``multiscript and multioriented text localization from scene images '' , proc .",
    "4th _ international workshop on camera - based document analysis and recognition _ , pp .",
    "1520 , beijing , china , 2011 ."
  ],
  "abstract_text": [
    "<S> _ we have benchmarked the maximum obtainable recognition accuracy on various word image datasets using manual segmentation and a currently available commercial ocr . </S>",
    "<S> we have developed a matlab program , with graphical user interface , for semi - automated pixel level segmentation of word images . </S>",
    "<S> we discuss the advantages of pixel level annotation . </S>",
    "<S> we have covered five databases adding up to over 3600 word images . </S>",
    "<S> these word images have been cropped from camera captured scene , born - digital and street view images . </S>",
    "<S> we recognize the segmented word image using the trial version of nuance omnipage ocr . </S>",
    "<S> we also discuss , how the degradations introduced during acquisition or inaccuracies introduced during creation of word images affect the recognition of the word present in the image . </S>",
    "<S> word images for different kinds of degradations and correction for slant and curvy nature of words are also discussed . </S>",
    "<S> the word recognition rates obtained on icdar 2003 , sign evaluation , street view , born - digital and icdar 2011 datasets are 83.9% , 89.3% , 79.6% , 88.5% and 86.7% respectively . _    * keywords : * word images , pixel level segmentation , annotation , graphical user interface , word recognition , benchmarking , scenic images , born - digital images . </S>"
  ]
}