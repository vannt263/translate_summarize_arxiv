{
  "article_text": [
    "let me start by briefly introducing in a greatly simplified manner the concepts of _ master equation _ and _ steady states_. consider a system endorsed with a hilbert space @xmath0 of dimension @xmath1 ( since we are interested in doing numerics , we will always assume that @xmath1 is finite , what might need truncating the hilbert space dimension when this is infinite in reality ) .",
    "we say that the system is open when it is part of a larger space with which it exchanges energy , information , etc ... , and generically we call _ environment _ to the rest of this larger space . in many situations , most notably when the environment is much larger or evolves much faster than the system , it is possible to describe the dynamics of the latter via a linear differential equation for its individual state , which of course is generally mixed since eliminating the environment means loosing information , hence requiring a description in terms of a density operator @xmath2 .",
    "we call master equation to the evolution equation for the system s density operator , and in the following we will be guided by the generic form , or even to terms of different form.]@xmath3 + \\gamma(2\\hat{j}\\hat{\\rho}\\hat{j}^{\\dagger}-\\hat{j}^{\\dagger}\\hat{j}\\hat{\\rho } -\\hat{\\rho}\\hat{j}^{\\dagger}\\hat{j})\\equiv\\mathcal{l[}\\hat{\\rho } ] , \\label{mastereq}\\ ] ] where @xmath4 is an hermitian operator containing the system hamiltonian and coherent or reversible exchange processes with the environment , while @xmath5 is a so - called jump operator ( with associated rate @xmath6 ) which describes irreversible processes such as excitations which are lost to the large environment never to come back to the system .",
    "@xmath7 is then an linear map usually called _",
    "liouvillian superoperator _ , whose name comes from the fact that it acts on operators to give operators .    consider a basis @xmath8 , which allows us to represent the density operator as@xmath9 with @xmath10 .",
    "the master equation , once projected into this basis , just provides a linear system of ordinary differential equations for the components of the density matrix , that is@xmath11 with@xmath12 in a more compact notation , it is customary to take the columns of the density matrix , and pile them one below the previous one , transforming the matrix into a vector@xmath13 and the multidimensional array @xmath14 into a matrix @xmath15 , so that the previous equation is turned into the linear system@xmath16 with solution@xmath17 it is interesting to note the correspondence between the elements of the density matrix , and the elements of its _ vectorized _ form : @xmath18 . in the next section",
    "we will see that these expressions are much more than just a convenient way of reordering things .    from a practical point of view , if the hilbert space dimension is not too large , then @xmath19 can be efficiently evaluated , and the main problem consists in how to write the matrix @xmath15 in an easy way , starting from the expression of the liouvillian in the master equation ( [ mastereq ] ) .",
    "this is where superspace enters into play , and we will explain in the next section how it allows for a simple way of coding @xmath15 in the computer ( matlab in particular ) .",
    "let us now pass to discuss the important concept of _ steady state_. for problems without selective measurements involved in the system+environment , the master equation must map states into states ; this means that it is a trace preserving differential map , so that the condition @xmath20 is satisfied at all times , and hence the equations of ( [ vectorizedmastereq ] ) are not independent , but satisfy the constrain @xmath21 , the dot denoting time - derivative .",
    "this makes the rows ( or columns ) of the matrix @xmath15 linearly dependent , what ensures @xmath22 and hence that it exists at least one eigenvector with zero eigenvalue , which we will denote by @xmath23 , satisfying @xmath24 , where @xmath25 is a vector of zeros .",
    "the corresponding operator @xmath26 is called the _ steady state _ of the system , since in the absence of any other zero eigenvalue , this is the state towards which the system tends to as time evolves ( the trace - preservation condition ensures also that all the other eigenvalues have negative real part , and hence for long times only @xmath23 survives ) .",
    "one useful way of finding this steady state is as follows .",
    "first , given its defining equation @xmath24 , where @xmath25 is a vector of zeros , we replace one of the equations coming from the evolution equation of some some chosen diagonal element @xmath27 by the normalization condition @xmath28 , which can be additionally multiplied by any number @xmath29 , what is sometimes useful for numerical purposes ; this means replacing the row number @xmath30 of @xmath15 by a vector of @xmath29 s in the elements multiplying the diagonal elements of @xmath31 , obtaining a new matrix @xmath32 , also replacing the @xmath25 vector by a vector @xmath33 containing a single non - zero entry @xmath29 at position @xmath30 .",
    "the steady state can then be found by solving the linear system @xmath34 , for example by inversion : @xmath35 .",
    "later we will learn how to do this explicitly in matlab .",
    "the space where the density matrix is turned into a vector and the liouvillian into a matrix is usually called _",
    "superspace_. having operators as its elements , superspace can be defined formally as the tensor product of the hilbert space and its dual , which indeed has vector space structure when endorsed with the trace product .",
    "as we will see in the next section , this gives us a simple way of representing superoperators by using simple tools of computer programs such as the kronecker product , which is a built - in operation in both in matlab and mathematica .",
    "instead of recalling the dual space , it is computationally more convenient to define superspace in a slightly simpler way : given an operator @xmath36 with matrix elements @xmath37 , we just associate to every index a fictitious @xmath1-dimensional hilbert space @xmath38 with basis @xmath39 , in which we describe the operator as a vector@xmath40 we will say that @xmath41 is the abstract superspace representation of the operator @xmath36 . note that its representation in the basis @xmath42 of superspace is the vector @xmath43 obtained by piling up the columns of the matrix formed by the elements @xmath44 one below the previous one , but only provided that the order of the superspace basis @xmath45 is chosen as , should correspond to the @xmath46 element in the superspace vector , @xmath47 , and this is precisely what the map @xmath48 provides . ] @xmath49 .",
    "consider now two operators @xmath50 and @xmath51 , and a superoperator @xmath52 acting on an operator @xmath36 as @xmath53=\\hat { a}\\hat{o}\\hat{b}=\\sum_{nmkl=1}^{d}o_{nm}a_{kn}b_{ml}|k\\rangle\\langle l|$ ] , expression which reads in superspace as @xmath54\\rangle=\\sum_{nmkl=1}^{d}o_{nm}a_{kn}b_{ml}|k\\rangle\\otimes|l\\rangle.\\ ] ] taking into account that @xmath50 and @xmath51 are operators defined in the original @xmath1-dimensional hilbert space @xmath0 , so that they act on basis elements of the new fictitious spaces @xmath38 in the usual way ( e.g. , @xmath55 ) , we can alternatively write @xmath54\\rangle=\\sum_{nm=1}^{d}o_{nm}(\\hat{a}|n\\rangle\\otimes \\hat{b}^{t}|m\\rangle)=(\\hat{a}\\otimes\\hat{b}^{t})|\\hat{o}\\rangle,\\ ] ] showing that in superspace the action of operators on the left ( right ) , corresponds to actions of the ( transpose ) operator on the first ( second ) fictitious hilbert space .",
    "hence , in superspace the master equation can be written as@xmath56|\\hat{\\rho}\\rangle,\\ ] ] where @xmath57 is the identity operator .",
    "let s pass now to discuss how to implement the previous ideas in one particular program , matlab , although similar tricks can be used in mathematica , for example .",
    "first , let us remind the notation , since i would nt be surprised if everyone is lost on it at this point ; to complicate things a bit , we will even need to introduce some more",
    ". the ( column ) vector representation of the basis elements @xmath8 of the hilbert spaces @xmath0 or @xmath38 will be denoted by @xmath58 , with self - representation elements @xmath59 .",
    "similarly , the superspace basis @xmath45 will have a vector representation @xmath60 , with self representation @xmath61 .",
    "given an operator @xmath36 , its matrix elements are denoted by @xmath62 @xmath63 , and the @xmath64 matrix that they form by @xmath65 , which is nothing but the matrix representation of the operator in the chosen basis .",
    "the ` vectorized ' form of this matrix , that is , the vector formed by piling up the columns of the matrix one below the next , is denoted by @xmath43 , and , as explained above , it can be seen as the representation of the operator in superspace , which we will still denote as @xmath41 , provided that the basis elements of superspace are ordered in the proper way . hence , summing up , @xmath36 is the abstract notation for the operator acting on the original space @xmath0 and @xmath41 the one for the operator defined in superspace @xmath66 , with corresponding matrix and vector representations @xmath65 and @xmath43 , respectively . as for superoperators ,",
    "take the liouvillian as an example , we will refer to them as @xmath7 in calligraphic font when talking about them in an abstract way , and @xmath15 in blackboard font when referring to their matrix representation in superspace .",
    "for example , the right hand side of master equation ( [ mastereq ] ) reads @xmath67 $ ] in an abstract way , and as @xmath68 once represented in superspace .",
    "let s start from the basics of coding things in matlab .",
    "the matrix representation of an operator @xmath36 can be written in matlab ( known their matrix elements @xmath44 ) as @xmath69,\\ ] ] where the commas can be replaced by a space .",
    "if we want to work with sparse matrices to save memory ( useful for hilbert spaces with large dimension , e.g. , @xmath70 ) , we can do so by replacing the matrix @xmath65 by ` sparse`(@xmath65 ) ; once in sparse form , we can always come back to the non - sparse one as ` full`(@xmath65 ) .",
    "let s talk about basic matrix operations .",
    "element @xmath44 is accessed as @xmath71 , while the whole column @xmath72 can be accessed as @xmath73 , and similarly for row @xmath74 , @xmath75 .",
    "we can access its @xmath74-th diagonal as @xmath76 which generates a column vector with the desired diagonal .",
    "given another matrix @xmath77 , @xmath78 is the matrix sum or difference , @xmath65*@xmath77 is the matrix multiplication , @xmath79*@xmath77 is the element - by - element multiplication , @xmath80 is the matrix multiplication of @xmath81 and @xmath77 , and @xmath82 is the matrix multiplication of @xmath65 and @xmath83 , where the inverse of @xmath65 can also be obtained as ` inv`@xmath84 ( but it is not recommended by matlab , since it is slower than @xmath85 or @xmath86 ) .",
    "we can find the determinant and trace as ` det`@xmath84 and ` trace`@xmath84 .",
    "the hermitian conjugate of @xmath65 is obtained in matlab as @xmath87 , while @xmath88 generates the transpose of @xmath65 .",
    "the exponential matrix is obtained as ` expm`@xmath84 , while ` exp`@xmath84 just exponentiates the elements of the matrix individually . as for the eigensystem",
    ", @xmath89 generates a vector with the eigenvalues of @xmath65 , while if we write @xmath90=$]`eig`@xmath84 , the eigenvectors are codified as columns of @xmath91 and @xmath92 is a diagonal matrix containing the corresponding eigenvalues .",
    "this operation can not be used when @xmath65 is sparse , in which case we need to use ` eigs`@xmath84 , which by default gives the 6 eigenvalues with largest magnitude ; if we want a different number of eigenvalues , say @xmath93 , we can write ` eigs`@xmath94`@xmath95'@xmath96 , where @xmath97 ` l ` ( ` s ` ) means that we want the eigenvalues with the largest ( smallest ) magnitude if @xmath98 ` m ` , or real part if @xmath98 ` r ` .",
    "it is very useful to type ` help f ` in matlab s command window to get more info about some function ` f ` ( for example , try ` help eig ` to find what else can be done with ` eig ` ) .",
    "the vectorized form of the operator is obtained as @xmath99 .",
    "this is one of the reasons why we chose to pile columns instead of rows when vectorizing matrix representations of operators : in matlab this operation is written with a single order , while in the case of rows , we would need to first transpose the matrix , and then give the order . on the other hand ,",
    "given the matrix in vectorized form , we can always bring it back to matrix form as @xmath100 ` reshape`@xmath101 .",
    "the matrix representation of the identity operator @xmath57 can be written as @xmath102 ` eye`@xmath103 , or @xmath102 `",
    "speye`@xmath103 when working with sparse matrices .",
    "the basis vector @xmath104 can be defined as @xmath105 .",
    "similarly , defining the identity matrix in @xmath106 dimensions @xmath107 ` eye`@xmath108 , the basis vector @xmath109 in superspace is obtained as @xmath110 .",
    "let s move on to the tensor product operation .",
    "it is customary in quantum mechanics to represent the tensor product of two operators or vectors as the kronecker product of their representations . in particular , given the matrix representations @xmath111 and @xmath112 of two operators @xmath50 and @xmath51 , their kronecker product is defined as@xmath113{cccc}a_{11}\\mathbf{b } & a_{12}\\mathbf{b } & \\cdots & a_{1d}\\mathbf{b}\\\\ a_{21}\\mathbf{b } & a_{22}\\mathbf{b } & \\cdots & a_{2d}\\mathbf{b}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ a_{d1}\\mathbf{b } & a_{d2}\\mathbf{b } & \\cdots & a_{dd}\\mathbf{b}\\end{array } \\right )   , \\ ] ] and this is usually the representation chosen for the tensor product operator @xmath114 . however , it is important to understand that this is just one possible representation of the tensor product , corresponding to one particular ordering of the tensor product basis latexmath:[$\\{|n\\rangle\\otimes    in our case ) .",
    "more concretly , note that according to the previous definition , given the vector representation @xmath104  of the basis element @xmath116 ( or @xmath38 ) , the kronecker product representation of the basis element @xmath117 ( or @xmath118 ) generates a vector with a single nonzero entry at position @xmath119 , that is , the superspace basis vector ) , the kronecker product of @xmath120 and @xmath121 , generates the vector @xmath122 , while the kronecker product of @xmath123 and @xmath124 generates @xmath125 .",
    "these examples coincide precisely with the mapping @xmath126 . ]",
    "however , as explained in the previous section , we would like to associate instead the superspace basis vector @xmath128 to the tensor product basis element @xmath129 , what means that we will not be using the usual kronecker product representation of the tensor product , but one in reversed order : given the matrix representations @xmath111 and @xmath112 of two operators @xmath50 and @xmath51 , the representation of their tensor product @xmath114 is taken as their kronecker product in reversed order , that is,@xmath113{cccc}b_{11}\\mathbf{a } & b_{12}\\mathbf{a } & \\cdots & b_{1d}\\mathbf{a}\\\\ b_{21}\\mathbf{a } & b_{22}\\mathbf{a } & \\cdots & b_{2d}\\mathbf{a}\\\\ \\vdots & \\vdots & \\ddots & \\vdots\\\\ b_{d1}\\mathbf{a } & b_{d2}\\mathbf{a } & \\cdots & b_{dd}\\mathbf{a}\\end{array } \\right )   .\\ ] ] with this choice , the representation of the basis element @xmath130 corresponds to @xmath128 as we wanted to .",
    "the kronecker product is already implemented in matlab through the operation ` kron ` ( and same in mathematica ) , which preserves the sparse character of the matrices .",
    "hence , we can generate the vector representation of @xmath131 , by applying the ` kron ` operation in the reversed order @xmath132 ` kron`@xmath133 .",
    "consider now two operators @xmath50 and @xmath51 , and a superoperator @xmath52 which acts on a third operator @xmath36 as @xmath134=\\hat{a}\\hat{o}\\hat{b}$ ] .",
    "as explained in the previous section , in superspace this is rewritten as @xmath135\\rangle=(\\hat{a}\\otimes\\hat{b}^{t})|\\hat{o}\\rangle$ ] in an abstract way , expression which can be represented in the basis of superspace @xmath136 as @xmath137 ` kron`@xmath138*@xmath139 in matlab code .",
    "hence , the matrix representation of @xmath52 in superspace is written in matlab as @xmath140 ` kron`@xmath138 .",
    "let me remark that the choice of using the reversed ` kron ` order for the representation of the tensor product has been made for convenience in matlab ( to create the vectorized form of any operator with a single instruction , and for more things that will appear in the next section when dealing with composite hilbert spaces ) .",
    "however , in other languages such as mathematica , it can be better to stick to the traditional kronecker product representation of the tensor product .",
    "but above all , what is important to understand what one is doing , and hence i strongly encourage the reader to think deeply about this , and play with some examples to interiorize this tricky point .",
    "hence , as promised , the matrix representation of the liouvillian superoperator admits a very simple coding in matlab:@xmath141 where ` 1i ` is the proper way of writing the imaginary unit in matlab , while ` conj`@xmath142`z`@xmath96 is how the complex conjugate of ` z ` looks in matlab .",
    "once we have the liouvillian superoperator , the next issue concerns finding the steady state of the system . if the hilbert space dimension is not too large , we can try diagonalizing @xmath15 fully using @xmath143=$ ] ` eig`@xmath144 . to access the steady state",
    "we can just find the index of the zero eigenvalue and get the corresponding column of @xmath145 , or proceed in a more elegant and automatic way , by sorting the order in which the eigenvalues appear .",
    "in particular , given the vector of eigenvalues @xmath146 ` diag`@xmath147 , we generate a vector @xmath148 containing the indices of the permutation which we need to apply to reorder the eigenvectors in decreasing real part as @xmath149=$ ] ` sort`@xmath142`real`@xmath150``descend`'@xmath96 , where we additionally get the vector of sorted real parts @xmath151 , which we wo nt use ; once we have @xmath148 , we can sort the eigensystem as @xmath152 and @xmath153 , and the first column of the sorted @xmath145 should correspond now to the steady state @xmath154 , most likely requiring the additional normalization @xmath155`trace`@xmath142`reshape`@xmath156 to ensure it has unit trace .",
    "now , for larger size problems , we will need to use sparse matrices , in which case the simplest way of finding the steady state would be as @xmath157 ` eigs`@xmath158``lr`'@xmath96 , which might require additional normalization as in the previous line .",
    "the density matrix of the steady state can then be found as @xmath159 ` reshape`@xmath160 .",
    "even though in most cases the previous way of finding @xmath23 is enough , it is interesting to know how to implement the method which we introduced at the end of the first section , which consisted in replacing one equation of @xmath24 by the normalization condition @xmath28 , where @xmath161 is a parameter which we can choose as we wish .",
    "this is easily done in matlab as follows ( there are indeed many different ways of doing this , here i just pick the one i find simplest and most direct to code ) .",
    "first , we pick the index @xmath162 of the diagonal element @xmath27 whose equation we want to replace , with corresponding superindex @xmath163 . then",
    ", we just define the matrix @xmath164 , and replace the corresponding row as @xmath165*@xmath166 , which simply puts @xmath29 on the entries multiplying the diagonal elements of the density matrix .",
    "then we define the vector @xmath33 with a single @xmath29 on element @xmath167 , which indeed corresponds to the superspace basis element @xmath168 multiplied by @xmath29 , that is , we can simply code it as @xmath169*@xmath170 .",
    "once we have done this , @xmath23 can be found as @xmath157 ` inv`@xmath171*@xmath33 , or by asking matlab to solve the linear system @xmath34 as @xmath157 ` linsolve`@xmath172 , which uses lu factorization .",
    "note that we need to check that ` det`@xmath173 , as otherwise we will have degenerate steady states , and the method will fail .",
    "everything we introduced up to now is general , in the sense that it applies to a system with any hilbert space @xmath0 . here",
    "i want to discuss some special features that appear when the system is a composition of @xmath93 simpler subsystems ( two- or three - level systems , harmonic oscillators , etc ... ) , in which case the hilbert space has the tensor product structure @xmath174 .",
    "this is the scenario that we usually find in quantum optics , where typical systems are composed of atoms ( maybe artificial such as superconducting qubits or quantum dots ) , and/or photonic , phononic , or motional modes .",
    "given a basis @xmath175 of subspace @xmath176 with dimension @xmath177 , a basis of the full hilbert space can be built as @xmath178 is the dimension of the complete hilbert space .",
    "hence , each value of the index @xmath74 which we were using in the previous sections corresponds now to some multi - index @xmath179 labeling the basis elements of the hilbert space of each subsystem .",
    "the point is that in many cases ( for example when wanting to evaluate partial traces or transpositions ) it is important to keep track of all the indices , and here i want to discuss how to deal with these issues by using efficient computational tools .",
    "we have already encountered tensor products before when building the superspace , and we saw how to code them efficiently using the kronecker product ; we will again use the ` kron ` operation to deal with composite hilbert spaces , but with a few subtle points .",
    "let us start with the simplest structure in the composite hilbert space : let s represent its basis .",
    "consider again the basis @xmath175 of subspace @xmath176 , and define the identity matrix of the corresponding dimension , @xmath180 ` eye`@xmath181 , from which we build the vector representation of @xmath182 as @xmath183 .",
    "then , we will represent a basis element @xmath74 of the complete hilbert space corresponding to some multi - index @xmath179 , that is , @xmath184 , as the vector @xmath185 ` kron`@xmath186`kron`@xmath187`kron`@xmath188 , where we use again a reversed order in the ` kron ` operations for future convenience , see the next paragraph .",
    "taking into account that we still want to define @xmath104 as a vector with @xmath189 zeros and a one at position @xmath74 , which is the natural self - representation of the basis elements in the complete hilbert space , the previous definition fixes the relation between @xmath74 and the multi - index @xmath179 to@xmath190    consider now a pure state @xmath191 in the complete hilbert space .",
    "as explained , it would be useful to be able to move between this expression , and the one making explicit reference to the indices of each subspace , that is , @xmath192 .",
    "this is very easy to do in matlab once we have made all the previous definitions . in particular , given the ( column ) vector representation of the state @xmath193 or better @xmath194 $ ] in matlab code , we can transform it into a multidimensional array as @xmath195 ` reshape`@xmath196 , from which @xmath197 is simply accessed as @xmath198 ; in the following we will use the double dot on top of the bold - faced symbol to denote that it is a multidimensional array .",
    "the multidimensional array can be transformed back to its vector form in the full hilbert space just vectorizing it as @xmath199 .",
    "note that the dimensions @xmath200 used to reshape the vector and the indices @xmath201 of the multidimensional array , follow the intuitive order that one would assign ; this is thanks to using the reversed order in the ` kron ` operation , and would not be the case if we would have chosen the intuitive one .    at this point",
    "it should be clear that , given substates @xmath202 with vector representation @xmath203 or @xmath204 $ ] in matlab code , the vector representation of the tensor product state @xmath205 can be obtained in matlab as @xmath206 ` kron`@xmath207`kron`@xmath208`kron`@xmath209 , with elements @xmath210 , @xmath74 given by ( [ indxtosuperindx ] ) .",
    "we see then that dealing with vectors is not so difficult .",
    "now let s consider operators , which are a bit more tricky .",
    "let s start with a simple generalization of what we did for vectors .",
    "consider an operator @xmath211 in the complete hilbert space .",
    "given its matrix representation @xmath65 in matlab ( with elements @xmath44 ) we would like to be able to retrieve the multi - index elements @xmath212 defined from@xmath213 similarly to vectors , this can be done by redefining @xmath65 as a multi - dimensional array @xmath214 ` reshape`@xmath215 , from which we can then get the desired multi - index elements as @xmath216 .",
    "we can always go back to the original matrix representation in the complete hilbert space by reshaping the multidimensional array as @xmath100 ` reshape`@xmath217 .",
    "sometimes it is useful to have access to a different set of multi - index elements @xmath218 defined by@xmath219 as we explained above , and then use the extremely useful ` permute ` operation , which allows to permute indices of multidimensional arrays . in particular , defining another multidimensional array @xmath220",
    "` permute`@xmath221)$ ] , we then access the desired multi - index elements as @xmath222 . in the following",
    "we will use the notation @xmath223 for the multidimensional array corresponding to the order @xmath212 of the multi - index elements , and the notation @xmath224 for the one corresponding to the @xmath218 order .",
    "imagine now that we are given a set of operators @xmath225 acting on the subspaces @xmath226 , with corresponding matrix representations @xmath227 .",
    "our goal now is finding the different representations of the operator @xmath228 acting on the complete hilbert space .",
    "our starting point will be the kronecker product @xmath229 ` kron`@xmath230`kron`@xmath231`kron`@xmath232 ; even though this is a @xmath64 matrix containing the elements of the representation of @xmath36 in the complete basis @xmath8 , it is easy to see that these elements are not ordered in the right way , and hence , in order for @xmath233 to coincide with the proper matrix representation of @xmath36 we need to reorder its elements . to this aim ,",
    "we first build the multidimensional array @xmath220 `",
    "reshape`@xmath234 which has @xmath235 as its elements .",
    "then , we can reorder its indices as @xmath214 ` permute`@xmath236)$ ] , creating a multidimensional array which has @xmath237 as its elements . finally , we find the matrix representation of @xmath36 in the complete hilbert space as @xmath100 ` reshape`@xmath217 . hence ,",
    "essentially we have followed the path of the previous paragraphs , but in reverse order .",
    "i hope all the manipulations have served to gain intuition about the operations ` kron ` , ` reshape ` , and ` permute ` , which allow for efficient and clean ways of representing hilbert space objects in the computer .",
    "finally , i would like to discuss two operations very relevant in the context of composite hilbert spaces : the partial transposition and the partial trace of an operator .",
    "consider an operator @xmath36 acting on the complete hilbert space .",
    "we define the operator corresponding to a partial transpose of @xmath238 with respect to subspace @xmath176 as@xmath239 the different multidimensional array representations of this operator are easily obtained in matlab from the ones of the original operator as @xmath240 ` permute`@xmath241)$ ] or @xmath242 ` permute`@xmath243)$ ] , and its matrix representation in the complete hilbert space is then obtained as @xmath244 ` reshape`@xmath245 .",
    "this is intuitively generalized to the case in which we want to perform partial transposition with respect to several subspaces ; for example , if we want to transpose subspaces @xmath176 and @xmath246 ( @xmath247 ) , then    @xmath248),\\\\ \\mathbf{\\ddddot{o}}^{t_{j}t_{l } }   &   = \\mathtt{permute}(\\mathbf{\\ddddot{o}},[1, ... ,2(j-1),2j,2j-1, ... ,2(l-1),2l,2l-1, ... ,2n]),\\\\ \\mathbf{o}^{t_{j}t_{l } }   &   = \\mathtt{reshape}(\\mathbf{\\ddot{o}}^{t_{j}t_{l}},d , d).\\end{aligned}\\ ] ]    as for the partial trace over subspace @xmath176 , denoted by @xmath249 or @xmath250 , it is defined as the operator    @xmath251    that is , as the operators with elements corresponding to the contraction of the indices associated to the @xmath176 subspace",
    ". we can find again the different representations of this operator efficiently using matlab s built - in functions .",
    "in particular , we can find the multidimensional array @xmath252 corresponding to this operator as follows ( we proceed by sequentially updating its definition ) : first , we bring the indices that we want to contract to the end of the array , @xmath253 ` permute`@xmath254)$ ] ; defining the dimension of the total hilbert space after tracing out the desired subspace by @xmath255 , we reshape the previous array as a @xmath256 dimensional matrix , @xmath253 ` reshape`@xmath257 ; given the identity matrix of dimension @xmath177 denoted by @xmath180 ` eye`@xmath181 , in terms of the previous matrix the contraction we are looking for is just @xmath258*@xmath259 ; the previous operation leaves us with a column vector with @xmath260 components , which we can finally reshape to give the multidimensional array we are looking for , @xmath253 ` reshape`@xmath261 ; finally , we find the matrix representation of the operator in the ( remaining ) complete hilbert space as @xmath253 ` reshape`@xmath262 .",
    "of course , a similar trick can be done starting from the other multidimensional array @xmath263 ; also , the method is straightforwardly generalized to when we want to trace out several subspaces at once ( maybe it s a good thing to try these two things out as an exercise , to really discover if you understood all these constructions properly ) .",
    "let me finally remark once more that the only reason why we have choosen the reversed order in the ` kron ` operation is to make the coding simpler in matlab . in particular , by just sticking to the simple rule every time a tensor product appears , it is coded as the ` kron ` product in the reversed order , the rest of manipulations are compactly and intuitively coded in matlab as shown above , what would not be the case otherwise .",
    "in order to fix ideas , let s consider one example consisting in a three - level cascade @xmath264 system interacting with two driven modes of a cavity which we call @xmath265 and @xmath266 , see fig .",
    "[ figscheme ] .",
    "let us first discuss the structure of this system s hilbert space as well as a convenient way of writing the master equation governing its evolution , and then we will show how to code what we need in matlab .",
    "the complete hilbert space of this system can be written as @xmath267 .",
    "@xmath268 is the subspace of the @xmath264 system , with basis @xmath269 , which allows us to define the  operators @xmath270 . @xmath271 and @xmath272 are the subspaces of the cavity modes , both spanned by fock states @xmath273 , from which we define the basic annihilation operator @xmath274 for mode @xmath265 , and similarly for mode @xmath266 , whose corresponding annihilation operator we denote by @xmath275 .",
    "note that @xmath271 and @xmath272 are hilbert spaces of infinite dimension , but the computer can only deal with finite dimension ; hence , we need to truncate the fock state bases to a certain maximum photon number , which we will denote by @xmath276 and @xmath277 for the corresponding modes , leading to finite - dimensional bases @xmath278 and @xmath279 which approximately span @xmath271 and @xmath272 , respectively .",
    "as shown in the figure , we order the states of the @xmath264 system such that @xmath280 corresponds to the excited state , @xmath281 to the middle one , and @xmath282 to the ground one , taking the energy origin in the middle state ; we name @xmath283 and @xmath284 the frequencies of the corresponding transitions .",
    "mode @xmath265 connects the @xmath285 , detuned by @xmath286 from the transition of the @xmath264 system .",
    "mode @xmath266 connects the @xmath287 transition and has resonance frequency @xmath288 .",
    "we assume that both modes are driven by resonant lasers and decay through the partially reflecting mirror at rates @xmath289 and @xmath290 ( the other mirror is assumed to have perfect reflectivity , although that s not important for this simple example ) .",
    "levels @xmath280 and @xmath281 of the @xmath264 system might decay through modes different than the cavity ones , what causes them spontaneous emission to levels @xmath281 and @xmath282 , respectively , at rates @xmath291 and @xmath292 .",
    "all these processes are captured by the following master equation in the schrdinger picture:@xmath293",
    "+ \\gamma_{a}\\mathcal{l}_{a}[\\hat{\\rho}]+\\gamma_{b}\\mathcal{l}_{b}[\\hat{\\rho } ] + \\gamma_{12}\\mathcal{l}_{\\sigma_{12}}[\\hat{\\rho}]+\\gamma_{23}\\mathcal{l}_{\\sigma_{23}}[\\hat{\\rho}],\\ ] ] where @xmath294 , with      and where we have introduced the notation @xmath296=2\\hat{c}\\hat{\\rho}\\hat{c}^{\\dagger}-\\hat{c}^{\\dagger}\\hat{c}\\hat{\\rho}-\\hat{\\rho}\\hat{c}^{\\dagger}\\hat{c}$ ] , given an operator @xmath297 .",
    "note that we are not writing tensor products explicitly , and hence objects like @xmath298 must be understood as @xmath299 ; we will stick to this economic notation except when it can lead to a misunderstanding or we want to show the underlaying tensor product structure of the hilbert space explicitly for some reason .",
    "unfortunately , there are two properties of this master equation that make it very difficult to deal with numerically .",
    "first , it is explicitly time - dependent through @xmath300 .",
    "second , for large driving amplitudes @xmath301 it is to be expected that the cavity modes will get highly populated , and we will not be able to truncate the fock bases to small enough @xmath276 and @xmath277 . both these problems appear typically in many systems , and up to a point can be solved by moving to a different picture ) , where the hamiltonian can even be time - dependent , and a general time - dependent unitary @xmath302 , it is simple to prove that the transformed state @xmath303 evolves according to the master equation@xmath304",
    "+ \\gamma(2\\hat{j}_{u}\\hat{\\rho}_{u}\\hat{j}_{u}^{\\dagger}-\\hat { j}_{u}^{\\dagger}\\hat{j}_{u}\\hat{\\rho}_{u}-\\hat{\\rho}_{u}\\hat{j}_{u}^{\\dagger } \\hat{j}_{u}),\\ ] ] with new hamiltonian @xmath305 and jump operators @xmath306 . ] , as we will learn now .",
    "the idea consists in doing two changes of picture ( it can be done at once , but it s more clear in two steps ) .",
    "first , we move to a picture rotating at the laser frequencies ( which in this example coincide with the cavity frequencies ) ; this is defined by the unitary transformation @xmath307 with @xmath308 , so that the transformed state @xmath309 evolves according to , and@xmath310 easy to prove from the baker - campbell - haussdorf lemma@xmath311 ... ]]}},\\ ] ] and the commutators @xmath312=1 $ ] and @xmath313=\\delta_{kl}\\hat{\\sigma}_{jm}-\\delta_{mj}\\hat{\\sigma } _ { lk}$ ] . ]",
    "@xmath304   + \\gamma_{a}\\mathcal{l}_{a}[\\hat{\\rho}_{u}]+\\gamma_{b}\\mathcal{l}_{b}[\\hat{\\rho}_{u}]+\\gamma_{12}\\mathcal{l}_{\\sigma_{12}}[\\hat { \\rho}_{u}]+\\gamma_{23}\\mathcal{l}_{\\sigma_{23}}[\\hat{\\rho}_{u}],\\ ] ]    with @xmath314 , where@xmath315 hence , we see that in this picture the master equation becomes time - independent . from this new picture",
    "we move to another one in which , in loose terms , the photons generated by the coherent drivings are already taken into account , so that we do nt need to ` count ' them in the simulation .",
    "more specifically , this picture is defined by the unitary ( displacement ) transformation @xmath316=\\exp[\\alpha(t)\\hat{a}^{\\dag } -\\alpha^{\\ast}(t)\\hat{a}+\\beta(t)\\hat{b}^{\\dag}-\\beta^{\\ast}(t)\\hat{b}]$ ] , which depends on two time - dependent amplitudes @xmath317 and @xmath318 that will be chosen later . in this case",
    ", the transformed state @xmath319 evolves according to ] together with@xmath320]@xmath321   + \\gamma_{a}\\mathcal{l}_{a}[\\hat{\\rho}_{d}]+\\gamma_{b}\\mathcal{l}_{b}[\\hat{\\rho}_{d}]+\\gamma_{12}\\mathcal{l}_{\\sigma_{12}}[\\hat { \\rho}_{d}]+\\gamma_{23}\\mathcal{l}_{\\sigma_{23}}[\\hat{\\rho}_{d}]\\\\ &   + \\left [   ( \\mathcal{e}_{a}-\\gamma_{a}\\alpha-\\dot{\\alpha})\\hat{a}^{\\dag } + ( \\mathcal{e}_{b}-\\gamma_{b}\\beta-\\dot{\\beta})\\hat{b}^{\\dag}-\\mathrm{h.c.},\\hat{\\rho}_{d}\\right ]   , \\nonumber\\end{aligned}\\ ] ] where @xmath322 , with@xmath323+g_{b}[\\beta^{\\ast}(t)\\hat{\\sigma}_{23}+\\beta(t)\\hat{\\sigma}_{23}^{\\dagger}]\\text{.}\\ ] ] this master equation suggests choosing @xmath324 and @xmath325 such that its last term is cancelled , that is , as solutions of @xmath326 and @xmath327 : @xmath328 note that with this change of picture we have introduced time dependence in the master equation ; however , since we are only interested in the long - time behavior of the system ( steady state ) , and moreover , we can choose @xmath324 and @xmath325 at will , we can take the @xmath329 limit in the previous equation , in which case the displacements become time independent , @xmath330 and @xmath331 , and so does the master equation , which takes the final form@xmath332   + \\gamma_{a}\\mathcal{l}_{a}[\\hat{\\rho}_{d}]+\\gamma_{b}\\mathcal{l}_{b}[\\hat{\\rho}_{d}]+\\gamma_{21}\\mathcal{l}_{\\sigma_{12}}[\\hat { \\rho}_{d}]+\\gamma_{32}\\mathcal{l}_{\\sigma_{23}}[\\hat{\\rho}_{d } ] , \\label{mastereqexample}\\ ] ] with @xmath333 , being          in the following we will learn how to code the previous problem in matlab , with the aim of finding the steady state of master equation ( [ mastereqexample ] ) , and compute certain interesting objects and quantities derived from it .",
    "one usually starts by defining the basic operators in the complete hilbert space .",
    "for this , we first need to choose the bases of the different subspaces and order their elements ; in our case , we take the bases that we introduced at the beginning of the previous section , ordered as we did ( in increasing number of their excitation number ) .",
    "in particular , the basis @xmath337 associated to the energy levels of the @xmath264 system spans @xmath268 , while the fock bases @xmath338 and @xmath339 span @xmath271 and @xmath272 , respectively . defining the identity of dimension 3",
    ", the representation of eigenvector @xmath340 corresponds to its first column , while the one of @xmath341 to its third column .",
    "similarly , defining the identity of dimension @xmath342 , the representation of fock state @xmath343 corresponds to its first column , while that of @xmath344 to its last column , and the same for mode @xmath266 .    as for the basic operators ,",
    "let s start from the ones acting on the cascade subspace , the transition operators @xmath270 .",
    "given the vector representations @xmath345 of the basis elements @xmath346 , the matrix representation of these operators is obtained in matlab as @xmath347 , which has a single one at position @xmath348 .",
    "as for the bosonic operators @xmath349 and @xmath275 , note that their matrix elements are @xmath350 and @xmath351 , where in these expressions the basis vectors are fock states in the corresponding subspaces ; hence , their matrix representations are    @xmath352{ccccc}0 & 1 & 0 & \\cdots & 0\\\\ 0 & 0 & \\sqrt{2 } & \\cdots & 0\\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\ 0 & 0 & 0 & \\cdots & \\sqrt{n_{a}}\\end{array } \\right )   \\text { \\ \\ \\ \\ and \\ \\ \\ } \\mathbf{b}=\\left ( \\begin{array } [ c]{ccccc}0 & 1 & 0 & \\cdots & 0\\\\ 0 & 0 & \\sqrt{2 } & \\cdots & 0\\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\ 0 & 0 & 0 & \\cdots & \\sqrt{n_{b}}\\end{array } \\right )   \\text{,}\\ ] ]    with the square root of the excitation numbers in the first upper diagonal .",
    "note that these are the representations of the operators in their respective subspaces , and they have to be ( tensor ) multiplied by the identity in the rest of subspaces to get their representations in the complete hilbert space , e.g. , @xmath353 in the case of the annihilation operator of the @xmath265 cavity mode .    with all these considerations and the general constructions of the previous sections",
    ", we can start writing the matlab code . in the following",
    ", we will go through the main parts of the code , explaining it and writing it explicitly so that it can be copied directly to a matlab script ( a simple text file saved with .m  extension ) ; in any case , the whole script can be found as part of the supplemental material .",
    "note that anything written after the ` % `  symbol ( in the same line ) is understood as a comment by matlab , and not executed . on the other hand , the semicolons ` ; `  prevent the expression from appearing in the main command window ( try removing one , and you ll see how the output of the line is printed on screen ) .",
    "we have chosen simple values for the parameters , leading to intuitive physical behavior of the system .",
    "in particular , the cavity modes are on resonance with their corresponding transitions , the couplings and spontaneous emission rates are on the same order , but smaller than the damping through the mirrors , and the rabi frequencies are the dominant parameters , but with the lower transition driven more strongly . under such conditions , it is to be expected that the population of the @xmath264 system will be almost equally distributed between its ground and middle states , with just a little bit in the excited state , and this is exactly what we will see later .",
    "note that we have chosen to define them in sparse form to save memory ( in full form we would just replace ` speye ` by ` eye ` ) .",
    "the annihilation operators for the cavity modes are then written in their respective subspaces as                                            having the matrix representations of the fundamental operators , we are in conditions to code the liouvillian as a matrix in superspace .",
    "for this , it is convenient to first code the hamiltonian , what we do as                                        _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ` l = -1i*kron(itot , h)+1i*kron(h.,itot)+la+lb+l12+l23 ; % total liouvillian ` _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _      at this point we have managed to code the matrix representation of the liouvillian in superspace .",
    "now , we proceed to evaluate its steady state in the different ways that we introduced in section [ matlabimp ] . for each method ,",
    "given the steady state which we denote here by @xmath361 , we compute the populations @xmath362 , @xmath363 , and @xmath364 . at the end we will see that all the methods give the same populations .                        note that this is basically zero within the numerical error , just as expected .",
    "note also that we have introduced the three dots ` ... ` , which is just a way of telling matlab that the expression is too long , and it continues in the next line , so lines connected by three dots are understood as a single line by matlab .",
    "we have introduced the functions ` tic ` and ` toc ` , which allow to check the time that matlab needed to evaluate the instructions between them .",
    "the rest just follows the recipe that we learned in section [ matlabimp ] .",
    "this piece of the code prints out the following lines in matlab s command window :                    the first quantity is the time needed to perform the full diagonalization of the liouvillian ( in seconds ) ; you can check when running the whole code that 35 seconds is approximately 90% of the whole time .",
    "the next quatities correspond to the eigenvalues with the largest real part ; note that only one is zero ( within the numerical error ) , and the rest have all negative real parts , so we see that we really have a unique steady state .",
    "you can check that the instruction ` eigs(l,5,lr ) ` gives the same 5 eigenvalues , but 60 times faster , showing the power of working with sparse matrices .",
    "note that we find the steady state by solving its defining equation in the two different ways explained in section [ matlabimp ] : either by inversion of the modified liouvillian or using matlab s linear solver .",
    "the code prints out in matlab s command window the trace of the density matrices obtained through both methods , which should be 1 by construction .",
    "you can check that this is indeed the case .",
    "next in the code , we evaluate some reduced states as an example of how to code the partial trace . we start from the steady state evaluated via sparse diagonalization , rearranged as a multidimensional array as                                                                                    then , we build a matrix containing the populations from all the methods as columns ( note that we take the real parts , so that the imaginary parts are not printed out to save space on screen , but check yourself that the latter are zero as they should be ) :          @xmath365{rrrrr}\\mathtt{0.45882 } & \\mathtt{0.45882 } & \\mathtt{0.45882 } & \\mathtt{0.45882 } & \\mathtt{0.45882}\\\\ \\mathtt{0.48438 } & \\mathtt{0.48438 } & \\mathtt{0.48438 } & \\mathtt{0.48438 } & \\mathtt{0.48438}\\\\ \\mathtt{0.056796 } & \\mathtt{0.056796 } & \\mathtt{0.056796 } & \\mathtt{0.056796 } & \\mathtt{0.056796}\\\\ \\mathtt{0.019165 } & \\mathtt{0.019165 } & \\mathtt{0.019165 } & \\mathtt{0.019165 } & \\mathtt{0.019165}\\\\ \\mathtt{0.0012705 } & \\mathtt{0.0012705 } & \\mathtt{0.0012705 } & \\mathtt{0.0012705 } & \\mathtt{0.0012705}\\end{array } $ ] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    showing that all the steady states give exactly the same populations . note that the populations of the @xmath264 system are what we were expecting from the system parameters .",
    "on the other hand , note also that we have computed is not the true cavity populations , since our state is not in the schrdinger picture , but in a displaced picture where the external driving is subtracted .",
    "taking into account that the steady state is @xmath366 in the schrdinger picture , we can get the true cavity populations as                          hence , we see that with such strong drivings , the @xmath264 system does nt change too much the cavity populations from their values expected in the absence of coupling , @xmath368 for mode @xmath265 and @xmath369 for mode @xmath266 .    finally in the code",
    ", we proceed to check the entanglement between various bipartitions of the complete system , what will give us a perfect excuse to compute some partial transpositions . given the state @xmath2 of a system whose hilbert space we divide in two as @xmath370 , a necessary condition for it to be separable with respect to that bipartition is that the partial transpose @xmath371 is semi - positive definite , that is , it has only positive or zero eigenvalues . given the eigenvalues @xmath372 of @xmath371 , we can evaluate the level of violation of such condition via the logarithmic negativity @xmath373 $ ] , which is one of the most common entanglement measures available for mixed states . in the following",
    "we evaluate this quantity for various bipartitions of our system .",
    "this shows that there is indeed entanglement between all the bipartitions , although it is not very big in any case ( take a bell state as an example , which has logarithmic negativity equal to @xmath374 ) , consistent with the fact that the cavity populations are not very much affected by the coupling to the @xmath264 system . note in particular",
    "that the largest entanglement is between the @xmath264 system and the cavity modes , while there is almost no entanglement between the cavity modes themselves . on the other hand ,",
    "the entanglement of the @xmath264 system with the @xmath265 mode is much larger than that with the @xmath266 mode ."
  ],
  "abstract_text": [
    "<S> master equations are probably the most fundamental equations for anyone working in quantum optics in the presence of dissipation . in this context </S>",
    "<S> it is then incredibly useful to have efficient ways of coding and simulating such equations in the computer , and in this notes i try to introduce in a comprehensive way how do i do so , focusing on matlab , but making it general enough so that it can be directly translated to any other language or software of choice . </S>",
    "<S> i inherited most of my methods from juan jos garca - ripoll ( whose numerical abilities i can not praise enough ) , changing them here and there to accommodate them to the way my ( fairly limited ) numerical brain works , and to connect them as much as possible to how i understand the theory behind them . at present , the notes focus on how to code master equations and find their steady state , but i hope soon i will be able to update them with time evolution methods , including how to deal with time - dependent master equations . during the last 4 years i ve tested these methods in various different contexts , including circuit quantum electrodynamics , the laser problem , optical parametric oscillators , and optomechanical systems . </S>",
    "<S> comments and ( constructive ) criticism are greatly welcome , and will be properly credited and acknowledged . </S>"
  ]
}