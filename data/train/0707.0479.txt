{
  "article_text": [
    "information transmission over channels with known interference at the transmitter has received a great deal of attention . a remarkable result on such channels",
    "was obtained by costa who showed that the capacity of the additive white gaussian noise ( awgn ) channel with additive gaussian i.i.d .",
    "interference , where the sequence of interference symbols is known non - causally at the transmitter , is the same as the capacity of awgn channel @xcite .",
    "therefore , the interference does not incur any loss in the capacity .",
    "this result was extended to arbitrary interference ( random or deterministic ) by erez _",
    "the result obtained by costa does not hold for the case that the sequence of interference symbols is known causally at the transmitter .",
    "channels with known interference at the transmitter are special case of channels with side information at the transmitter which were considered by shannon @xcite in causal knowledge setting and by gelfand and pinsker @xcite in non - causal knowledge setting .",
    "shannon considered a discrete memoryless channel ( dmc ) whose transition matrix depends on the channel state . a state - dependent discrete memoryless channel ( sd - dmc ) is defined by a finite input alphabet @xmath7 , a finite output alphabet @xmath8 , and transition probabilities @xmath9 , where the state @xmath10 takes on values in a finite alphabet @xmath11 .",
    "shannon @xcite showed that the capacity of an sd - dmc where the i.i.d .",
    "state sequence is known causally at the encoder is equal to the capacity of an _ associated _ regular ( without state ) dmc with an extended input alphabet @xmath12 and the same output alphabet @xmath13 .",
    "the input alphabet of the associated channel is the set of all functions from the state alphabet to the input alphabet of the state - dependent channel .",
    "there are a total of @xmath14 denotes the cardinality of a set .",
    "any of the functions can be represented by a @xmath15-tuple @xmath16 composed of elements of @xmath0 , implying that the value of the function at state @xmath10 is @xmath17 .",
    "the capacity is given by @xcite @xmath18 where the maximization is taken over the probability mass function ( pmf ) of the random variable @xmath19 .    in the capacity formula ( [ causal - cap ] ) , we can alternatively replace @xmath19 with @xmath20 , where @xmath21 is the random variable that represents the input to the state - dependent channel when the state is @xmath22 .",
    "this paper is organized as follows . in section",
    "[ bound ] , we derive an upper bound on the cardinality of the shannon s associated channel input alphabet to achieve the capacity . in section [ chanmodel ] , we introduce our channel model . in section [ nf ] ,",
    "we investigate the capacity of the channel in the absence of noise . in section [ uniform ] , we consider maximizing the transmission rate under the constraint that the channel input given any current interference symbol is uniformly distributed over the channel input alphabet .",
    "we present the general structure of a communication system for the channel with causally - known discrete interference in section [ optprecode ] .",
    "we conclude this paper in section [ conclude ] .",
    "we can obtain the pmf of the channel output @xmath23 as @xmath24 the capacity of the associated channel , which is the same as the capacity of the original state - dependent channel , is the maximum of @xmath25 over the joint pmf values @xmath26 , i.e. , @xmath27 the mutual information between @xmath28 and @xmath29 is the difference between the entropies @xmath30 and @xmath31 .",
    "it can be seen from ( [ py ] ) that @xmath32 , and hence @xmath33 , are uniquely determined by the marginal pmfs @xmath34 , @xmath35 .",
    "the conditional entropy @xmath36 is given by @xmath37 where @xmath38 .",
    "there are @xmath3 variables involved in the maximization problem ( [ capg ] ) .",
    "each variable represents the probability of an input symbol of the associated channel .",
    "the following theorem regards the number of nonzero variables required to achieve the maximum in ( [ capg ] ) .",
    "[ th1 ] the capacity of the associated channel is achieved by using at most @xmath2 out of @xmath3 input symbols with nonzero probabilities .",
    "denote by @xmath39 the pmf of @xmath21 , @xmath40 , induced by a capacity - achieving joint pmf @xmath41 .",
    "we limit the search for a capacity - achieving joint pmf to those joint pmfs that yield the same marginal pmfs as @xmath42 . by limiting the search to this smaller set ,",
    "the maximum of @xmath43 remains unchanged since the capacity - achieving joint pmf @xmath41 is in the smaller set .",
    "but all joint pmfs in the smaller set yield the same @xmath33 since they induce the same marginal pmfs on @xmath44 .",
    "therefore , the maximization problem in ( [ capg ] ) reduces to the linear minimization problem @xmath45 there are @xmath46 equality constraints in ( [ lp ] ) out of which @xmath2 are linearly independent . from the theory of linear programming ,",
    "the minimum of ( [ lp ] ) , and hence the maximum of @xmath47 , is achieved by a feasible solution with at most @xmath2 nonzero variables .",
    "theorem [ th1 ] states that at most @xmath2 out of @xmath3 input symbols of the associated channel are needed to be used with positive probability to achieve the capacity .",
    "however , in general one does not know which of the inputs must be used to achieve the capacity . if we knew the marginal pmfs for @xmath44 induced by a capacity - achieving joint pmf",
    ", we could obtain the capacity - achieving joint pmf itself by solving the linear program ( [ lp ] ) .",
    "we consider data transmission over the channel @xmath48 where @xmath49 is the channel input , which takes on values in a fixed real constellation @xmath50 @xmath29 is the channel output , @xmath51 is additive white gaussian noise with power @xmath52 , and the interference @xmath53 is a discrete random variable that takes on values in @xmath54 with probabilities @xmath55 , respectively . the sequence of i.i.d .",
    "interference symbols is known causally at the encoder .",
    "the above channel can be considered as a special case of state - dependent channels considered by shannon with one exception , that the channel output alphabet is continuous . in our case , the likelihood function @xmath56 is used instead of the transition probabilities .",
    "we denote the input to the associated channel by @xmath28 , which can also be represented as @xmath57 , where @xmath58 is the random variable that represents the channel input when the current interference symbol is @xmath59 , @xmath60 .",
    "the likelihood function for the associated channel is given by @xmath61 where @xmath62 denotes the pdf of the noise @xmath51 , and @xmath63 is the input symbol of the associated channel represented by @xmath64 .    according to theorem [ th1 ] ,",
    "the capacity of our channel is obtained by using at most @xmath65 out of @xmath66 input symbols of the associated channel .",
    "we consider a special case where the noise power is zero in ( [ chmodel ] ) . in the absence of noise ,",
    "the channel output @xmath23 takes on at most @xmath67 different values since different @xmath68 and @xmath69 pairs may yield the same sum .",
    "if @xmath23 takes on exactly @xmath67 different values , then it is easy to see that the capacity is @xmath6 bits : the decoder just needs to partition the set of all possible channel output values into @xmath4 subsets of size @xmath5 corresponding to @xmath4 possible inputs , and decide that which subset the current received symbol belongs to .    in general , where the cardinality of the channel output symbols can be less than @xmath67",
    ", we will show that under some condition on the channel input alphabet there exists a coding scheme that achieves the rate @xmath6 in one use of the channel .",
    "we do this by considering a one - shot coding scheme which uses only @xmath4 ( out of @xmath66 ) inputs of the associated channel .    in a one - shot coding scheme",
    ", a message is encoded to a single input of the associated channel .",
    "any input of the associated channel can be represented by a @xmath5-tuple composed of elements of @xmath0 .",
    "given that the current interference symbol is @xmath59 , the @xmath70th element of the @xmath5-tuple is sent through the channel .",
    "therefore , one single message can result in ( up to ) @xmath5 symbols at the output . for convenience ,",
    "we consider the output symbols corresponding to a single message as a multi - set is a multi - set of size four where 3 has multiplicity two . ] of size ( exactly ) @xmath5 .",
    "if the @xmath4 multi - sets at the output corresponding to @xmath4 different messages are mutually disjoint , reliable transmission through the channel is possible .",
    "unfortunately , we can not always find @xmath4 inputs of the associated channel such that the corresponding multi - sets are mutually disjoint .",
    "for example , consider a channel with the input alphabet @xmath71 and the interference alphabet @xmath72 .",
    "it is easy to check that for this channel we can not find four triples composed of elements of @xmath0 such that the corresponding multi - sets are mutually disjoint .",
    "in fact , by entropy calculations we can show that the capacity of the channel in this example is less than @xmath73 bits .    however , if we put some constraint on the channel input alphabet , the rate @xmath6 is achievable .",
    "[ th2 ] suppose that the elements of the channel input alphabet @xmath0 form an arithmetic progression .",
    "then the capacity of the noise - free channel @xmath74 where the sequence of interference symbols is known causally at the encoder equals @xmath6 bits .",
    "let @xmath75 be the set of all possible outputs of the noise - free channel when the interference symbol is @xmath76 , i.e. , @xmath77 the union of @xmath75s is the set of all possible outputs of the noise - free channel .",
    "without loss of generality we can assume that @xmath78 .",
    "the elements of @xmath75 form an arithmetic progression , @xmath79 .",
    "furthermore , these @xmath5 arithmetic progressions are shifted versions of each other .",
    "we prove by induction on @xmath5 that there exist @xmath4 mutually - disjoint multi - sets of size @xmath5 composed of the elements of @xmath80 ( one element from each ) .",
    "if we can find such @xmath4 multi - sets of size @xmath5 , then we can obtain the corresponding @xmath4 @xmath5-tuples of elements of @xmath0 by subtracting the corresponding interference terms from the elements of the multi - sets .",
    "these @xmath4 @xmath5-tuples can serve as the inputs of the associated channel to be used for sending any of @xmath4 distinct messages through the channel without error in one use of the channel , hence achieving the rate @xmath6 bits per channel use .    for @xmath81 ,",
    "the statement of the theorem is true since we can take @xmath82 as mutually - disjoint sets of size one .",
    "assume that there exist @xmath4 mutually - disjoint multi - sets of size @xmath83 .",
    "for @xmath84 , we will have the new set of channel outputs @xmath85 .",
    "we consider two possible cases :    _ case 1 _ : none of the elements of @xmath86 appear in any of the multi - sets of size @xmath83 .    in this case",
    ", we include the elements of @xmath87 in the @xmath4 multi - sets arbitrarily ( one element is included in each multi - set ) .",
    "it is obvious that the resulting multi - sets of size @xmath84 are mutually disjoint .",
    "_ case 2 _ : some of the elements of @xmath86 appear in some of the multi - sets of size @xmath83 .",
    "suppose that the largest element of @xmath86 which appears in any of the sets @xmath88 , @xmath75 ( or equivalently , in any of the multi - sets of size @xmath83 ) is @xmath89 for some @xmath90 .",
    "then since @xmath86 is shifted version of each @xmath91 and @xmath92 , exactly one of the sets @xmath93 , say @xmath94 for some @xmath95 , contains all elements of @xmath86 up to @xmath96 .",
    "[ demo ] . since any of the disjoint multi - sets of size @xmath5 contain just one element of @xmath94 , the elements of @xmath86 up to @xmath96 appear in different multi - sets of size @xmath83 .",
    "we can form the disjoint multi - sets of size @xmath97 by including these common elements in the corresponding multi - sets and including the elements of @xmath98 in the remaining multi - sets arbitrarily .",
    "the condition on the channel input alphabet in the statement of theorem [ th2 ] is a sufficient condition for the channel capacity to be @xmath6 .",
    "however , it is not a necessary condition .",
    "for example , the statement of theorem [ th2 ] without that condition is true for the case of @xmath99 .",
    "because in the second iteration , we do not need the arithmetic progression condition to form @xmath4 mutually - disjoint multi - sets of size two .",
    "the proof of theorem [ th2 ] is actually a constructive algorithm for finding @xmath4 ( out of @xmath66 ) inputs of the associated channel to be used with probability @xmath100 to achieve the rate @xmath101 bits .",
    "it is interesting to see that the set containing the @xmath102th elements of the @xmath4 @xmath5-tuples obtained by the constructive algorithm is @xmath0 , @xmath103 .",
    "this is due to the fact that each multi - set contains one element from each @xmath104 .",
    "therefore , a uniform distribution on the @xmath4 @xmath5-tuples induces uniform distribution on @xmath105 .",
    "in the sequel , we study the maximization of the rate @xmath106 over joint pmfs @xmath107 that induce uniform marginal distributions on @xmath108,@xmath109 , i.e. , @xmath110 for which we show how to obtain the optimal input probability assignment .",
    "we call a transmission scheme that induces uniform distribution on @xmath105 as _ uniform transmission_. the uniform distribution for @xmath105 implies uniform distribution for @xmath68 , the input to the state - dependent channel defined in ( [ chmodel ] ) .    in the previous section , we established that the capacity achieving pmf for the asymptotic case of noise - free channel induces uniform distributions on @xmath105 ( provided that we can find @xmath4 @xmath5-tuples such that the corresponding multi - sets are mutually disjoint ) .",
    "considering the constraints in ( [ margin ] ) , the maximization of @xmath111 is reduced to the linear minimization problem @xmath112 the same argument used in the last part of the proof of theorem [ th1 ] can be used to show that the maximum is achieved by using at most @xmath65 inputs of the associated channel with positive probabilities .",
    "this is restated in the following corollary .",
    "[ coro1 ] the maximum of @xmath113 over joint pmfs @xmath114 that induce uniform marginal distributions on @xmath115 is achieved by a joint pmf with at most @xmath65 nonzero elements .",
    "this result is independent of the coefficients @xmath116 .",
    "however , which probability assignment with at most @xmath65 nonzero elements is optimal depends on the coefficients @xmath117 .",
    "the coefficient @xmath118 is determined by the interference levels @xmath119 , the probability of interference levels @xmath120 , the noise power @xmath121 , and the signal points @xmath122 .",
    "the optimal probability assignment is obtained by solving the linear programming problem ( [ lpun ] ) using the simplex method @xcite .",
    "if the number of interference levels is two , i.e. , @xmath99 , we can make a stronger statement than corollary [ coro1 ] .",
    "[ th3 ] the maximum of @xmath123 over @xmath124 with uniform marginal pmfs for @xmath125 and @xmath126 is achieved by using exactly @xmath4 out of @xmath127 inputs of the associated channel with probability @xmath100",
    ".    the equality constraints of ( [ lpun ] ) can be written in matrix form as @xmath128 where @xmath129 is a zero - one @xmath130 matrix , @xmath131 is @xmath4 times the vector containing all @xmath132s in lexicographical order , and @xmath133 is the all - one @xmath134 vector .    for @xmath99 , it is easy to check that @xmath129 is the vertex - edge incidence matrix of @xmath135 , the complete bipartite graph with @xmath4 vertices at each part . therefore , @xmath129 is a totally unimodular matrix,@xmath136 , or @xmath137 . ]",
    "hence , the extreme points of the feasible region @xmath138 are integer vectors .",
    "since the optimal value of a linear optimization problem is attained at one of the extreme points of its feasible region , the minimum in ( [ lpun ] ) is achieved at an all - integer vector @xmath139 . considering that @xmath139 satisfies ( [ matrix ] )",
    ", it can only be a zero - one vector with exactly @xmath4 ones .",
    "[ mi1 ] depicts the maximum mutual information ( for the uniform transmission scenario ) vs. snr for the channel with @xmath140 and equiprobable interference symbols .",
    "the mutual information vs. snr curve for the interference - free awgn channel with equiprobable input alphabet @xmath141 is plotted for comparison purposes .",
    "as it can be seen , for low snrs , the input probability assignment @xmath142 is optimal , whereas at high snrs , the input probability assignment @xmath143 is optimal .",
    "the maximum achievable rate for uniform transmission is the upper envelope of the two curves corresponding to different input probability assignments .",
    "also , it can be observed that the achievable rate approaches @xmath144 bit per channel use as snr increases complying with the fact that we established in section [ nf ] for the noise - free channel .",
    "it turns out from the proof of theorem [ th3 ] that the optimum solution of the linear optimization problem , @xmath139 , is a zero - one vector .",
    "so , if we add the integrality constraint to the set of constraints in ( [ matrix ] ) , we still obtain the same optimal solution .",
    "the resulting integer linear optimization problem is called the _ assignment problem _ @xcite , which can be solved using low - complexity algorithms such as the _ hungarian method _ @xcite .",
    "the fact that for the case @xmath99 , there exists an optimal @xmath131 which is a zero - one vector with exactly @xmath4 ones simplifies the encoding operation . because any encoding scheme just needs to work on a subset of size @xmath4 of the associated channel input alphabet with equal probabilities @xmath100 .    for @xmath145 ,",
    "@xmath129 is not a totally unimodular matrix .",
    "therefore , not all extreme points of the feasible region defined by @xmath146 , are integer vectors . however , at the expense of possible loss in rate , we may add the integrality constraint in this case .",
    "the resulting optimization problem is called the _ multi - dimensional assignment problem _ @xcite .",
    "the optimal solution of ( [ lpun ] ) with the integrality constraint , will be a vector with exactly @xmath4 nonzero elements with the value @xmath100 .",
    "therefore , any encoding scheme just needs to use @xmath4 symbols of the associated channel with equal probabilities , simplifying the encoding operation .",
    "the general structure of a communication system for the channel defined in ( [ chmodel ] ) is shown in fig .",
    "[ fig6 ] . any encoding and decoding scheme for the associated channel",
    "can be translated to an encoding and decoding scheme for the original channel defined in ( [ chmodel ] ) .",
    "a message @xmath147 is encoded into a block of length @xmath148 composed of input symbols of the associated channel @xmath149 .",
    "there are @xmath66 input symbols .",
    "however , we showed that the maximum rate with uniformity and integrality constraints can be achieved by using just @xmath4 input symbols of the associated channel with equal probabilities .",
    "the optimal @xmath4 input symbols of the associated channel are obtained by solving the linear programming problem ( [ lpun ] ) with the integrality constraint .",
    "those @xmath4 input symbols of the associated channel define the optimal precoding operation : for any @xmath63 that belongs to the set of @xmath4 optimal input symbols , the precoder sends the @xmath102th component of @xmath63 if the current interference symbol is @xmath76 , @xmath103 .",
    "based on the received sequence , the receiver decodes @xmath150 as the transmitted message .",
    "in this paper , we proved that the capacity of an sd - dmc with finite input alphabet @xmath0 and finite state alphabet @xmath1 and with causally known i.i.d .",
    "state sequence at the encoder can be achieved by using at most @xmath2 out of @xmath3 input symbols of the associated channel . as an example of state - dependent channels with",
    "side information at the encoder , we investigated @xmath4-ary signal transmission over awgn channel with additive @xmath5-level interference , where the sequence of interference symbols is known causally at the transmitter .    for the noise - free channel , provided that the signal points are equally spaced , we proposed a one - shot coding scheme that uses @xmath4 input symbols of the associated channel to achieves the capacity @xmath6 bits .",
    "we considered the transmission schemes with uniform pmfs for @xmath151 .",
    "for this so called uniform transmission , the optimal input probability assignment with at most @xmath65 nonzero elements can be obtained by solving the linear optimization problem ( [ lpun ] ) . the optimal solution to ( [ lpun ] ) with the integrality constraint",
    "has exactly @xmath4 nonzero elements .",
    "for the case @xmath99 , we showed that the integrality constraint does not reduce the maximum achievable rate . the loss in rate ( if there is any ) by imposing the integrality constraint for the general case is a problem to be explored .",
    "the authors would like to thank gerhard kramer and syed ali jafar for pointing out that the proof of theorem [ th1 ] , which was originally given for the channel model considered in this paper , works for any sd - dmc with causal side information at the encoder ."
  ],
  "abstract_text": [
    "<S> for a state - dependent dmc with input alphabet @xmath0 and state alphabet @xmath1 where the i.i.d . </S>",
    "<S> state sequence is known causally at the transmitter , it is shown that by using at most @xmath2 out of @xmath3 input symbols of the shannon s _ associated _ channel , the capacity is achievable . as an example of state - dependent channels with side information at the transmitter , @xmath4-ary signal transmission over awgn channel with additive @xmath5-ary interference where the sequence of i.i.d . </S>",
    "<S> interference symbols is known causally at the transmitter is considered . </S>",
    "<S> for the special case where the gaussian noise power is zero , a sufficient condition , which is independent of interference , is given for the capacity to be @xmath6 bits per channel use . </S>",
    "<S> the problem of maximization of the transmission rate under the constraint that the channel input given any current interference symbol is uniformly distributed over the channel input alphabet is investigated . for this setting , the general structure of a communication system with optimal precoding is proposed . </S>"
  ]
}