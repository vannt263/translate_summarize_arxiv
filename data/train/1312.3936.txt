{
  "article_text": [
    "consider the discrete three dimensional schrdinger operator , given by : @xmath0 when @xmath1 is of the form @xmath2 , and consider an element @xmath3 of @xmath4 given by @xmath5 let the random variables @xmath6 be i.i.d .  with uniform distribution in",
    "@xmath7 $ ] , i.e.  according to the probability distribution @xmath8 } } } dx$ ] .",
    "the 3d random discrete schrdinger operator , formally given by @xmath9 is the main object of study .",
    "this operator has been studied extensively , see e.g.  @xcite and the references therein .",
    "the first part of the operator @xmath10 describes the movement of an electron inside a crystal with atoms located at all integer lattice points @xmath11 .",
    "the perturbation @xmath12 can be interpreted as having the atoms randomly displaced around the lattice points .",
    "it is important to notice that the perturbation is almost surely non - compact , so that classical perturbation theory ( e.g.  kato  rosenblum theorem , which states the invariance of the absolutely continuous spectrum under compact perturbations ) can not be applied almost surely .",
    "it is known that the absolutely continuous spectrum is deterministic , i.e.  it occurs with probability one or zero , see e.g.  @xcite .",
    "localization in the sense of exponentially decaying eigenfunctions was proved analytically for disorders @xmath13 _ above _ some threshold @xmath14 ( see e.g.  @xcite , @xcite , and @xcite ) .",
    "currently , the smallest threshold in 3 dimensions is @xmath15 ( see table 1 in @xcite ) .",
    "diffusion is expected but not proved for small disorder @xmath16 .",
    "we numerically determine a regime of disorders for which the three dimensional discrete random schrdinger operator does not exhibit localization .",
    "our calculations are based on the lanczos algorithm  @xcite for determining orthogonal bases for krylov spaces  @xcite .",
    "although we are not the first to use this method ( see e.g.  @xcite and the references therein ) , our application of it is quite different . in particular , our method is not based on scaling theory ( for further discussion see @xcite ) . in  @xcite ,",
    "the lanczos algorithm is employed to compute a set of eigenvalues and eigenvectors .",
    "however , we test for localization without computing eigenvalues or eigenvectors , but only compute the distance between @xmath17 and the orbit of @xmath18 .",
    "the orbit is the span of @xmath19 , which is exactly a krylov subspace . at each step of the lanczos iteration",
    ", we use the orthogonality of the generated vectors to update the distance of interest . in this way",
    ", we maintain the low memory cost of a three - term recurrence , bypassing the need to store any eigenvectors at all .",
    "in addition to this , we have performed some _ a posteriori _ tests of the lanczos algorithm on smaller cases to measure the degree to which orthogonality may be lost .",
    "besides computational advantages , our approach also offers a different mathematical perspective . by utilizing eigenvectors ,",
    "it is ( tacitly ) assumed that all spectral points are in fact eigenvalues , while our approach merely generates an orbit without attempting to rule out other kinds of spectral points .",
    "while the contributions of this paper are numeric , the method ( see @xcite ) provides an explicit analytic expression , which may yield a proof of the following numerically supported main result .",
    "[ t - mr ] for disorder @xmath20 , numerical experiments indicate that the three dimensional discrete random schrdinger operator does not exhibit anderson localization with positive probability , in the sense that it has non - zero absolutely continuous spectrum with probability 1 .",
    "( in particular , we do not have what is usually referred to as  strong dynamical localization \" implying delocalization in most or even all of the other senses , see @xcite . )    the key analytical tool to our method is stated in proposition [ c - tool ] below .",
    "section [ s - setup ] is devoted to a description of the numerical experiment .",
    "the numerical testing criterion we applied is given by numerical criterion [ nc ] below .",
    "our numerical findings and the conclusions can be found in section [ ss - results ] . in subsections [ ss - averages ] and [ ss - compare ]",
    ", we study the averaged data and find further numerical validation of our method . in section [ s - supp ]",
    "we verify the performance of the method in many examples . in subsection",
    "[ ss - thouless ] , we present the distribution of energies after repeated application of the random operator of a wave packet initially located at the origin .",
    "we briefly remark on computing and memory requirements in section [ s - final ] .",
    "recall that an operator in a separable hilbert space is called normal if @xmath21 . by the spectral theorem operator @xmath22 is unitarily equivalent to @xmath23 , multiplication by the independent variable @xmath24 , in a direct sum of hilbert spaces @xmath25 where @xmath26 is a scalar positive measure on @xmath27 , called a scalar spectral measure of @xmath22 .",
    "if @xmath22 is a unitary or self - adjoint operator , its spectral measure @xmath26 is supported on the unit circle or on the real line , respectively . via radon decomposition",
    ", @xmath26 can be decomposed into a singular and absolutely continuous parts @xmath28 .",
    "the singular component @xmath29 can be further split into singular continuous and pure point parts . for unitary or self - adjoint @xmath22",
    "we denote by @xmath30 the restriction of @xmath22 to its absolutely continuous part , i.e.  @xmath30 is unitarily equivalent to @xmath31 similarly , define the singular , singular continuous and the pure point parts of @xmath22 , denoted by @xmath32 , @xmath33 and @xmath34 , respectively .      as mentioned above delocalization",
    "is deterministic . therefore demonstrating that it does not occur with probability zero is sufficient to determine delocalization .",
    "this following result makes our numerical experiment possible as it suffices to check the evolution of only one vector through repeated operations by the anderson hamiltonian and 3 dimensional random schrdinger operator .",
    "fix the vectors @xmath35 and @xmath36 , i.e.  3tensors with zero entries , except for the @xmath37position and the @xmath38position , respectively , which equal @xmath39 .",
    "notice that @xmath40 describes the distance between the unit vector @xmath17 and the subspace obtained taking the closure of the span of the vectors @xmath41 .    in numerical linear algebra ,",
    "this space is called a krylov subspace , and the lanczos algorithm  @xcite provides a classical approach for finding an orthonormal basis .",
    "our distance calculation   relies on the orthogonality of these vectors , iteratively updating the distance with each new krylov vector .",
    "[ c - tool ] consider the discrete random schrdinger operator given by equation .",
    "let @xmath6 , @xmath42 , be i.i.d .",
    "random variables with uniform ( lebesgue ) distribution on @xmath43 $ ] , @xmath16 . to prove delocalization ( i.e.  the existence of absolutely continuous spectrum with positive probability )",
    ", it suffices to find @xmath16 for which the distance @xmath44 with non - zero probability .",
    "( notice that the limit exists by the monotone convergence theorem . )",
    "the proposition follows immediately from theorems 1.1 and 1.2 of @xcite and is stated in more generality in @xcite .",
    "[ remark ] the converse of proposition [ c - tool ] is not true . and",
    "we can not draw any conclusions , if the distance between a fixed ( unit ) vector and the subspace generated by the orbit of another vector tends to zero .",
    "in particular , we can not conclude that there must be localization .",
    "even if we show for many or ` all ' vectors ( instead of just @xmath17 ) , it could be possible that the absolutely continuous part has multiplicity one and that @xmath18 is cyclic , that is , @xmath45 .",
    "consider the discrete schrdinger operator given by with random variable @xmath46 distributed according to the hypotheses of proposition [ c - tool ] .    by proposition [ c - tool ]",
    ", we obtain delocalization if we can find @xmath16 for which happens with non - zero probability .",
    "let us now explain precisely how we verify delocalization numerically , leading up to the numerical criterion [ nc ] below .",
    "in the numerical experiment , we initially fix @xmath13 and fix one computer - generated realization of the random variable @xmath46 ( with distribution in accordance to the hypotheses of proposition [ c - tool ] ) .",
    "we then calculate the distances @xmath47 for @xmath48 . assuming that we know @xmath49 for @xmath50 , let us find a lower estimate for the limit @xmath51     for @xmath52 iterations and @xmath53 . ]",
    "figure [ c0 ] displays a typical trend for the distance @xmath49 as @xmath54 increases . because the first @xmath55 points were irregular and do not contribute to the above limit",
    ", they were omitted .",
    "notice that the graph is decreasing , as is expected .",
    "although it certainly appears that the limit does not go to 0 , the graph could have logarithmic decay , approaching zero very slowly . to attain an estimate for @xmath56 , which excludes the case of such slow decay ,",
    "we re - scaled the graph by @xmath57 , @xmath58 , so that the x - axis is inverted and the @xmath59intercept , @xmath60 , of a line of best fit will estimate @xmath56 .",
    "re - scaled using @xmath61 .",
    "notice the fine @xmath59scale and proximity to the @xmath59axis .",
    "]    figure [ c0a ] shows the re - scaled graph for @xmath62 .",
    "subsection [ ss - a ] describes the choice of @xmath63 and why , for small values of @xmath13 , @xmath56 does not decay to 0 .",
    "since an approximating line is only an estimate , for further confidence in our results , we also calculated the minimum @xmath59intercept of all lines through two consecutive points and call it @xmath64 ( see the steep line in figure [ betterc0 ] ) .",
    "this is essentially the  worst case , \" and ought to underestimate @xmath56 , yielding the relationship @xmath65    .",
    "the steeper line is used to determine @xmath66 , and the line of best fit provides @xmath67 . for this realization",
    "we have @xmath68 and @xmath69 . ]",
    "we repeated this process for many values of @xmath13 and multiple , different , computer - generated instances of the random variable @xmath46 .",
    "we took the minimum of @xmath60 and @xmath64 across all instances of @xmath46 , with the intent to demonstrate that @xmath56 is above 0 for many different @xmath46 .    in order to give confidence to our calculations to account for random error occurring in the computer , we introduce the following restrictions even though proposition [ c - tool ] only requires that @xmath70 .",
    "[ nc ] for a fixed value of @xmath13 , we say that we have delocalization , if for at least 90% realizations we obtain @xmath71 and @xmath72 is of order @xmath73 .",
    "( notice that we only need non - zero probability by proposition [ c - tool ] , and remark [ remark ] . )      for each fixed @xmath13 and @xmath46 , the re - scaling exponent @xmath63 is chosen so that the re - scaled graph of the distance function ( see figure [ c0a ] ) satisfies the least square property ; that is , the error with respect to square ",
    "norm when approximating the graph by a line is minimal . with this exponent",
    "we then find the corresponding linear approximation for the re - scaled distance function .    to find optimal @xmath63 , we used the mesh @xmath74 .",
    "below is a table , see equation , for many values of @xmath13 , giving the percentage of usable trials ( those for which an optimal @xmath75 was found ) for each value of @xmath13 .",
    "trials are not usable if the re - scaling parameter @xmath76 yields a concave graph . if this happens , we do not obtain any information ( according to remark [ remark ] ) . see figure [ c6 ] below . note that a small value ( @xmath77 ) of @xmath63 is  bad \" , since the graph rescaled with @xmath76 will be concave , and thus it is not expected for a line of best fit to underestimate the limit of the distance .    ) .",
    "the concave shape of the data implies that @xmath60 is not necessarily a lower bound for @xmath56 . ]",
    "a positive re - scaling factor implies that the graph in figure [ c0 ] will not decay to zero .",
    "indeed , using a re - scaling factor smaller than the optimal one will result in a convex graph for the distances @xmath49 .",
    "and the @xmath59intercept of the line lies below the value expected for @xmath78 .",
    "as mentioned in section [ s - setup ] , for a fixed @xmath13 we chose many realizations @xmath46 . for every value of @xmath13 , we took the minimum of the resulting quantities for @xmath64 and @xmath60 ( the @xmath59intercept of the approximating line and the minimum @xmath59intercept of the lines passing through any two consecutive points , respectively ) .",
    "we present our observations for the numerical criterion [ nc ] for @xmath52 . for fixed disorder",
    ", we will comment in subsection [ ss - averages ] on the re - scaling parameters of averages over the distances @xmath47 , @xmath79 and @xmath80 .",
    "the following tables document the data obtained for n=200 by taking 15 realizations for each @xmath13 between @xmath81 and @xmath82 , and 4 realizations for each @xmath83 and @xmath84 . by @xmath85",
    "we denote the probability of finding a re - scaling factor @xmath86 $ ] .",
    "@xmath87    @xmath88    @xmath89    @xmath90    while for some @xmath91 , we have @xmath92 the difference between @xmath60 and @xmath66 is relatively large , which means that the line from taking the least square approximation is likely not a good approximation for the distances .",
    "we also repeated the experiment for @xmath52 and the tables in equation below documents the findings . in these trials ,",
    "the first 119 entries were removed instead of the first 44 , as in the @xmath93 case .",
    "this larger crop makes the data more stable by giving better estimates for @xmath60 and @xmath66 and by more consistently finding a usable rescaling factor @xmath63 .",
    "we ran 13 trials for @xmath94 and 4 trials for all other values .",
    "@xmath95    @xmath96    @xmath97    @xmath98    a good rescaling factor @xmath63 was found for all 143 of the trials for @xmath99 and all @xmath100 satisfy criterion [ nc ] , an improvement from the @xmath93 case .",
    "hence the final conclusion of this numerical experiment is precisely the main result [ t - mr ] .",
    "according to remark [ remark ] and criterion [ nc ] , for @xmath101 , we do not have any conclusion .      in the tables in equation",
    "below , for each fixed @xmath13 , we averaged the distances @xmath49 , @xmath102 , of all our realizations . for those averaged distances",
    ", we determined the re - scaling parameters @xmath103 , as well as @xmath104 and @xmath105 in analogy .",
    "the significance of our findings is that the re - scaling factors @xmath106 are  roughly \" decreasing and rather well - behaved for @xmath107 . for larger disorder",
    ", @xmath106 becomes even less stable , and ca nt even be found for large enough disorder .",
    "@xmath108    @xmath109    @xmath110    @xmath111    in equation below we document the analogous quantities for the @xmath52 trials .",
    "note that there is no rescaling factor for @xmath112 , while there is for that @xmath13 in the @xmath93 trials .",
    "the data sets are not related to each other , aside from sharing the same disorder @xmath13 .",
    "@xmath113    @xmath114    @xmath115    @xmath116      the @xmath52 data gave better results than the @xmath93 data .",
    "the probability of finding a useable rescaling factor for @xmath52 was higher than that of @xmath93 for all but two values of @xmath13 .",
    "the average rescaling factor @xmath106 was similar between the two data sets .",
    "finally , @xmath117 was smaller for the @xmath52 data for small @xmath13 , suggesting that the approximation given by @xmath60 is better .",
    "apart from the usual tests ( the program is running stably , checking all subroutines , many verifications for small @xmath54 ) , we have conducted the following tests .",
    "most important is the a posteriori test of orthogonality in the lanczos algorithm in subsection [ ss - ortho ] .",
    "when we apply the free discrete schrdinger operator @xmath118 to the vector @xmath18 , it immediately becomes clear that @xmath119 as well as all vectors @xmath120 , @xmath121 , are symmetric with respect to the origin . in dimension",
    "@xmath122 , it is not hard to see that the distance between @xmath17 and the orbit of @xmath18 under @xmath123 is at least @xmath124 .",
    "indeed , we have @xmath125 where @xmath126 the eight vertices of the length 2 cube centered at @xmath127 .    in the experiments for the free discrete two dimensional schrdinger operator we obtained a @xmath59intercept of the approximating line",
    "approximately equals @xmath128 .",
    "the re - scaled graph of distances still had a convex shape , so the actual distance as @xmath129 would be bigger .",
    "in fact , we have extracted our data an upper estimate of @xmath130 .",
    "therefore , the distance must lie in the interval @xmath131 $ ] .",
    "the @xmath84 case shows a decrease in distance on only every other step .",
    "the symmetry caused by the absence of random perturbations means the 3-tensor after orthogonalization has alternating diamonds of zero and nonzero entries radiating from the origin , meaning the distance decreases every second application of the operator , when there is a nonzero entry in the @xmath38position .",
    "we observe the bulk distribution which determines the distance from the origin where we are most likely to find an electron . here",
    ", distance is measured by the taxicab method , so elements of the same distance form a diamond in the 3-d integer lattice .",
    "the bulk at this distance is the euclidean norm of the elements constituting the diamond .    to be precise , we consider the elements of the vector @xmath133 and define @xmath134 for the bulk @xmath135 of the vector @xmath136 at taxicab distance @xmath137 from the origin . here",
    "@xmath138 refers to the @xmath139entry of the @xmath140tensor @xmath136 . slightly abusing notation",
    ", we normalize @xmath136 and use the same notation for the normalized sequence of vectors .    figure [ n500energya ]",
    "is the result of averaging four sets of data for values of @xmath13 ranging from @xmath81 to @xmath39 .",
    "as expected , the energy remains closer to the origin as disorder increases .     for the disorders @xmath141 , averaged over the 11 realizations for each value of @xmath13 .",
    "]      the lanczos algorithm is known to lose orthogonality in many instances , which could cast doubt on our distance calculations . to test the accuracy for our problem",
    ", we stored the entire krylov subspace generated on a smaller problem instance ( @xmath142 ) and stored these as columns of a matrix @xmath143 .",
    "the quantity @xmath144 should deviate with zero in proportion to the loss of orthogonality . in tables   and , we measure the matrix @xmath145 norm for realizations for several cases of @xmath13 near the critical value .",
    "we see that the krylov vectors in these cases are in fact quite close to orthogonal especially for @xmath146 , although the orthogonality seems to decrease as @xmath13 grows .",
    "@xmath147    @xmath148",
    "using methodology similar to that in @xcite , all of the information contained in the 3-tensor is stored in one information vector . for this method , because of how the hamiltonian acts , it is important for computing purposes that each point in the 3-tensor is stored in a position such that its neighbors along a coordinate axis are a consistent distance from that point in the vector .",
    "this methodology allows the vector to be half the size necessary for containing every point in a 3-tensor , but still approximately twice as large as is necessary . in order to explore localization in higher dimensions ,",
    "a more efficient method is needed since a generalization of this code for dimension @xmath149 has time complexity @xmath150 .",
    "after prototyping our approach in matlab , we translated the code into fortran90 .",
    "this allowed us a smaller memory footprint and hence larger and more efficient runs .",
    "we then wrapped this routine into python using the ` f2py ` package  @xcite . by doing so",
    ", we were able to run several cases concurrently on our workstation by using python s ` multiprocessing ` module .",
    "our simulations were run on a dell precision workstation with dual eight - core intel xeon e5 - 2680 processors running at 2.7ghz with 128 gb of ram .",
    "we used gfortran version 4.4.7 with flags ` -o3 -ftree - vectorizer - verbose=2 -msse2 -funroll - loops -ffast - math ` , + which , among other optimizations , enables instruction - level superscalar parallelism .",
    "an immediate area for further exploration would be to consider various geometries , rather than simply the n - dimensional lattice .",
    "one geometry of interest is the sierpinski gasket , starting at one corner and building the various triangles as @xmath54 increases .",
    "preliminary results indicate that a program modeling the free random schrdinger operator on this geometry should run with time complexity @xmath151                simsule r.  del rio , s.  jitomirskaya , y.  last , b.  simon , _ operators with singular continuous spectrum .",
    "hausdorff dimensions , rank - one perturbations , and localization _",
    ", j. anal . math .",
    "* 69 * ( 1996 ) , 153200 .",
    "mr 1428099 ( 97m:47002 )            hundertmark d.  hundertmark , _ a short introduction to anderson localization _ , analysis and stochastics of growth processes and interface models , 194218 , oxford univ .  press , oxford , 2008 .",
    "mr 2603225 ( 2011c:82038 )                              simwol b.  simon and t.  wolff , _ singular continuous spectrum under rank - one perturbations and localization for random hamiltonians _",
    ", comm .  pure appl .",
    ", * 39 * ( 1986 ) , no .  1 , 7590 .",
    "mr 820340 ( 87k:47032 ) ."
  ],
  "abstract_text": [
    "<S> we apply a recently developed approach @xcite to study the existence of extended states for the three dimensional discrete random schrdinger operator at small disorder . </S>",
    "<S> the conclusion of delocalization at small disorder agrees with other numerical and experimental observations ( see e.g.  @xcite ) . </S>",
    "<S> further the work furnishes a verification of the numerical approach and its implementation . + </S>",
    "<S> not being based on scaling theory , this method eliminates problems due to boundary conditions , common to previous numerical methods in the field . at the same time , as with any numerical experiment , one can not exclude finite - size effects with complete certainty . </S>",
    "<S> our work can be thought of as a new and quite different use of lanczos algorithm ; a posteriori tests to show that the orthogonality loss is very small . </S>",
    "<S> + we numerically track the  bulk distribution \" ( here : the distribution of where we most likely find an electron ) of a wave packet initially located at the origin , after iterative application of the discrete random schrdinger operator . </S>"
  ]
}