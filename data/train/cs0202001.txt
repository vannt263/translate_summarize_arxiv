{
  "article_text": [
    "the + + system , which was completed at ucla in the summer of 2000 , concludes a research project that was started at mcc in 1989 in response of the lessons learned from of its predecessor , the system . the system , which was completed 1988 , featured many technical advances in language design @xcite , and implementation techniques @xcite .",
    "however , its deployment in actual applications @xcite revealed many problems and needed improvements , which motivated the design of the new + + system .",
    "many of these problems were addressed in the early versions of the + + prototype that were built at mcc in the period 19901993 ; but other problems , particularly limitations due to the stratification requirement , called for advances on nonmonotonic semantics , for which solutions were discovered and incorporated into the system over time  till the last version ( version 5.1 ) completed at ucla in the summer of 2000 .    in this paper , we will concentrate on the most innovative and distinctive features of + + , which can be summarized as follows :    * its new language constructs designed to extend the expressive power of the language , by allowing negation and aggregates in recursion , while retaining the declarative semantics of horn clauses , * its execution model designed to support ( i ) the new language constructs , ( ii ) data - intensive applications via tight coupling with external databases , and ( iii ) an open architecture for extensibility to new application domains , * its extensive application testbed designed to evaluate the effectiveness of deductive database technology on data intensive applications and new domains , such as middleware and data mining .",
    "a challenging research objective pursued by + + was that of extending the expressive power of logic - based languages beyond that of while retaining a fully declarative model - theoretic and fixpoint semantics .",
    "as many other deductive database systems designed in the 80s  @xcite , the old system required programs to be stratified with respect to nonmonotonic constructs such as negation and set aggregates  @xcite . while stratification represented a major step forward in taming the difficult theoretical and practical problems posed by nonmonotonicity in logic programs , it soon became clear that it was too restrictive for many applications of practical importance .",
    "stratification makes it impossible to support efficiently even basic applications , such as bill of materials and optimized graph - traversals , whose procedural algorithms express simple and useful generalizations of transitive closure computations . thus , deductive database researchers have striven to go beyond stratification and allow negation and aggregates in the recursive definitions of new predicates .",
    "+ + provides a comprehensive solution to this complex problem by the fully integrated notions of ( i ) @xmath0 , ( ii ) user defined aggregates ( udas ) , and ( iii ) xy - stratification .",
    "now , xy - stratification generalizes stratification to support negation and ( nonmonotonic ) aggregates in recursion .",
    "however , the choice construct ( used to express functional dependency constraints ) defines mappings that , albeit nondeterministic , are monotonic and can thus be used freely in recursion .",
    "moreover , this construct makes it possible to provide a formal semantics to the notion of user - defined aggregates ( udas ) , and to identify a special class of udas that are monotonic @xcite ; therefore , the + + compiler recognizes monotonic udas and allows their unrestricted usage in recursion . in summary , + + provides a two - prong solution to the nonmonotonicity problem , by ( i ) enlarging the class of logic - based constructs that are monotonic ( with constructs such as choice and monotonic aggregates ) , and ( ii ) supporting xy - stratification for hard - core nonmonotonic constructs , such as negation and nonmonotonic aggregates .",
    "these new constructs of + + are fully integrated with all other constructs , and easy to learn and use .",
    "indeed , a user needs not to know abstract semantic concepts , such as stable models or well - founded models ; instead , the user only needs to follow simple syntactic rules  the same rules that are then checked by the compiler .",
    "in fact , the semantic well - formedness of + + programs can be checked at compile time  a critical property of stratified programs that was lost in later extensions , such as modular stratification @xcite .",
    "these new constructs are described next .",
    "say that we have a database containing the relations @xmath1 and @xmath2 .",
    "in fact , let us take a toy example that only has the following facts    @xmath3    now , the rule is that the major of a student must match his / her advisor s major area of specialization .",
    "then , eligible advisors can be computed as follows :    this yields    but , since a student can only have one advisor , the goal @xmath4 must be added to our rule to force the selection of a unique advisor for each student :    _ computation of unique advisors by a choice rule _ [ advex ]    the goal @xmath5 can also be viewed as enforcing a _ functional dependency _ ( fd ) @xmath6 on the results produced by the rule ; thus , in @xmath7 , the second column ( professor name ) is functionally dependent on the first one ( student name ) .",
    "therefore , we will refer to s and p , respectively , as the left side and the right side of this fd , and of the choice goal defining it .",
    "the right side of a choice goal can not be empty , but its left side can be empty , denoting that all tuples produced must share the same values for the right side attributes .",
    "the result of the rule of example  [ advex ] is _ nondeterministic _ : it can either return a singleton relation containing the tuple @xmath8 , or one containing the tuple @xmath9 .    a program where the rules contain choice goals is called a _",
    "choice program_. the semantics of a choice program @xmath10 can be defined by transforming @xmath10 into a program with negation , @xmath11 , called the _ first order equivalent _ of @xmath10 .",
    "now , @xmath11 exhibits a multiplicity of stable models , each obeying the fds defined by the choice goals ; each such stable model corresponds to an alternative set of answers for @xmath10 and is called a _ choice model _ for @xmath10 .",
    "the first order equivalent of example  [ advex ] is as follows :    the first order equivalent for example  [ advex ] [ order ] @xmath12    this can be read as a statement that a professor will be assigned to a student whenever a different professor has not been assigned to the same student . in general , @xmath11 is defined as follows :    [ sv ] let @xmath10 denote a program with choice rules : its first order equivalent @xmath13 is obtained by the following transformation .",
    "consider a choice rule @xmath14 in @xmath10 : @xmath15 where ,    1 .",
    "@xmath16 denotes the conjunction of all the goals of @xmath14 that are not choice goals , and 2 .",
    "@xmath17 , @xmath18 , denote vectors of variables occurring in the body of @xmath14 such that @xmath19 and @xmath20 .",
    "then , @xmath13 is constructed from @xmath10 as follows :    1 .",
    "replace @xmath14 with a rule  @xmath21 obtained by substituting the choice goals with the atom @xmath22 : @xmath23 where @xmath24 is the list of all variables appearing in choice goals , i.e. , @xmath25 .",
    "2 .   add the new rule @xmath26 3 .",
    "for each choice atom @xmath27 ( @xmath18 ) , add the new rule @xmath28 where ( i ) the list of variables @xmath29 is derived from @xmath30 by replacing each @xmath31 with a new variable @xmath32 ( i.e. , by priming those variables ) , and ( ii ) @xmath33 denotes the inequality of the vectors ; i.e. , @xmath33 is true when for some variable @xmath34 and its primed counterpart @xmath35 , @xmath36 .",
    "@xmath12      let @xmath10 be a positive program with choice rules .",
    "then the following properties hold  @xcite :    * @xmath13 has one or more total stable models . *",
    "the _ chosen _ atoms in each stable model of @xmath13 obey the fds defined by the choice goals .",
    "observe that the @xmath13 of a program with choice does not have total well - founded models ; in fact , for our example  [ advex ] , the well - founded model yields undefined values for advisors .",
    "therefore , the choice construct can express nondeterministic semantics , which can be also expressed by stable models , but not by well - founded models . on the other hand",
    ", the choice model avoids the exponential complexity which is normally encountered under stable model semantics .",
    "indeed , the computation of stable models is @xmath37-hard @xcite , but the computation of choice models for positive programs can be performed in polynomial time with respect to the size of the database .",
    "this , basically , is due to the monotonic nature of the choice construct that yields a simple fixpoint computation for programs with choice @xcite .",
    "indeed , the use of choice rules in positive programs preserves their monotonic properties .",
    "a program @xmath10 can be viewed as consisting of two separate components : an extensional component ( i.e. , the database facts ) , denoted @xmath38 , and an intensional one ( i.e. , the rules ) , denoted @xmath39 .",
    "then , a positive choice program defines a monotonic multi - valued mapping from @xmath38 to @xmath39 , as per the following theorem proven in @xcite :    [ th : jcss ] let @xmath10 and @xmath40 be two positive choice programs where @xmath41 and @xmath42 .",
    "then , if @xmath43 is a choice model for @xmath10 , then , there exists a choice model @xmath44 for @xmath40 such that @xmath45 .",
    "two concrete semantics are possible for choice programs : one is an all - answers semantics , and the other is the semantics under which any answer will do ",
    "dont care nondeterminism .",
    "while an all - answers semantics for choice is not without interesting applications @xcite , the single - answer semantics was adopted by + + , because this is effective at supporting _ db - ptime _ problems @xcite .",
    "then , we see that theorem 2 allows us to compute results incrementally as it is done in differential fixpoint computations ; in fact , to find an answer , a program with choice can be implemented as an ordinary program , where the choice predicates are memorized in a table ; then newly derived atoms that violate the choice fds are simply discarded , much in the same way as duplicate atoms are discarded during a fixpoint computation .",
    "thus positive choice programs represent a class of logic programs that are very well - behaved from both a semantic and a computational viewpoint .",
    "the same can be said for choice programs with stratified negation that are defined next .",
    "let @xmath10 be a choice program with negated goals .",
    "then , @xmath10 is said to be stratified when the program obtained from @xmath10 by removing its choice goals is stratified .",
    "the stable models for a stratified choice program @xmath10 can be computed using an _ iterated choice fixpoint _ procedure that directly extends the iterated fixpoint procedure for programs with stratified negation  @xcite ; this is summarized next .",
    "let @xmath46 , denote the rules of @xmath10 ( whose head is ) in stratum @xmath47 , and let @xmath48 be the union of @xmath49 .",
    "now , if @xmath50 is a stable model for @xmath51 , then every stable model for @xmath52 is a stable model for the program @xmath53 .",
    "therefore , the stable models of stratified choice programs can be computed by modifying the iterated fixpoint procedure used for stratified programs so that choice models ( rather than the least models ) are computed for strata containing choice rules  @xcite .",
    "the expressive power of choice was studied in @xcite , where it was shown that stratified datalog with choice can express all computations that are polynomial in the size of the database ( i.e. , db - ptime queries  @xcite ) . without choice , db - ptime",
    "can not be expressed in stratified datalog , unless a predefined total order is assumed for the universe , an assumption that would violate the _ genericity _ principle @xcite . in terms of computational power ,",
    "non - determinism and order fulfill a similar function  @xcite ; in fact , the application of choice can also be viewed as non - deterministically and incrementally generating a possible order on the universe  an order that is made explicit by the predicate @xmath54 discussed in example  [ ex4 ] .    before moving to example  [ ex4 ] ,",
    "however , we would like to observe that the version of choice supported in + + is more powerful than other nondeterministic constructs , such as the witness operator  @xcite , and an earlier version of choice proposed in  @xcite ( called static choice in @xcite ) .",
    "for instance , the following query can not be expressed in standard datalog ( since the query is nondeterministic ) nor it can be expressed by the early version of choice  @xcite or by the witness construct  @xcite .",
    "these early constructs express nondeterminism in nonrecursive programs , but suffer from inadequate expressive power in recursive programs  @xcite .",
    "in particular , they can not express the query in example [ span1 ] .",
    "[ span1 ] _ rooted spanning tree._we are given an undirected graph where an edge joining two nodes , say @xmath55 and @xmath56 , is represented by the pair @xmath57 and @xmath58 .",
    "then , a spanning tree in this graph , starting from the source node @xmath59 , can be constructed by the following program :    to illustrate the presence of multiple total choice models for this program , take a simple graph consisting of the following arcs :    after the exit rule adds @xmath60 , the recursive rule could add @xmath61 and @xmath62 , along with the two tuples @xmath63 and @xmath64 in the @xmath65 table .",
    "no further arc can be added after those , since the addition of @xmath66 or @xmath67 would violate the fd that follows from @xmath68 enforced through the @xmath65 table . however , since @xmath69 @xmath70 was produced by the first rule ( the exit rule ) , rather than the second rule ( the recursive choice rule ) , the table @xmath65 contains no tuple with second argument equal to the source node @xmath59 .",
    "therefore , to avoid the addition of @xmath71 or @xmath72 , the goal @xmath73 was added to the recursive rule .    by examining all possible solutions ,",
    "we conclude that this program has three different choice models , for which we list only the @xmath74-atoms , below :    1 .   2 .   3 .",
    "@xmath12    in addition to supporting _",
    "nondeterministic _ queries , the introduction of the choice extends the power of datalog for _ deterministic _ queries .",
    "this can be illustrated by the following choice program that places the elements of a relation @xmath75 into a chain , thus establishing a random total order on these elements ; then checks if the last element in the chain is even .",
    "[ ex4 ] the odd parity query by arranging the elements of a set in a chain . the elements of the set are stored by means of facts of the form @xmath76 . @xmath12    here @xmath77 is the root of a chain linking all the elements of @xmath75thus inducing a total order on elements of @xmath78 .    the negated goal in the last rule defines the last element in the chain .",
    "observe that the final @xmath79 answer does not depend on the particular chain constructed ; it only depends on its length that is equal to the cardinality of the set .",
    "thus stratified datalog with choice can express deterministic queries , such as the parity query , that can not be expressed in stratified datalog without choice @xcite .",
    "the parity query can not be expressed in datalog with stratified negation unless we assume that the underlying universe is totally ordered ",
    "an assumption that violates the data independence principle of _ genericity _ @xcite .",
    "the benefits of this added expressive power in real - life applications follows from the fact that the chain program used in example [ ex4 ] , above , to compute the odd parity query can be used to stream through the elements of a set one by one , and compute arbitrary aggregates on them .",
    "for instance , to count the cardinality of the set @xmath75 we can write : the negated goal in the last rule qualifies the element(s ) @xmath80 without a successor in the chain , i.e. , @xmath80 for which @xmath81 holds for all @xmath82s .",
    "therefore , count is defined by a program containing ( and stratified with respect to ) negation ; thus , if @xmath83 is then used as a builtin aggregate , the stratification requirement must be enforced upon every program that uses @xmath83 .    however , if we seek to determine if the base relation @xmath75 has more than @xmath84 elements , then we can use the @xmath85 aggregate instead of @xmath83 , as follows :    now , @xmath85 is what is commonly known as an _ online _ aggregate @xcite : i.e. , an aggregate that produces _ early returns _ rather than final returns as traditional aggregates .",
    "the use of @xmath85 over @xmath83 offers clear performance benefits ; in fact , the computation of @xmath86 can be terminated after 14 items , whereas the application of @xmath83 requires visiting all the items in the chain . from a logical viewpoint ,",
    "the benefits are even greater , since @xmath83 is no longer needed and the rule defining it can be eliminated  leaving us with the program defining @xmath85 , which is free of negation .",
    "thus , no restriction is needed when using @xmath85 in recursive programs ; and indeed , @xmath85 ( and @xmath86 ) define monotonic mappings in the lattice of set - containment .    in summary ,",
    "the use of choice led us to ( i ) a simple and general definition of the concept of aggregates , including user defined aggregates ( udas ) , and ( ii ) the identification of a special subclass of udas that are free from the yoke of stratification , because they are monotonic .",
    "this topic is further discussed in the next section .",
    "the importance of aggregates in deductive databases has been recognized for a long time  @xcite . in particular , there have been several attempts to overcome the limitations placed on the use of aggregates in programs because of their nonmonotonic nature  @xcite . of particular interest is the work presented in @xcite , where it shown that rules with aggregates often define monotonic mappings in special lattices  i.e . , in lattices different from the standard set - containment lattice used for @xmath87 .",
    "furthermore , programs with such monotonic aggregates can express many interesting applications @xcite .",
    "unfortunately , the lattice that makes the aggregate rules of a given program monotonic is very difficult to identify automatically  @xcite ; this problem prevents the deployment of such a notion of monotonicity in real deductive database systems .",
    "a new wave of decision support applications has recently underscored the importance of aggregates and the need for a wide range of new aggregates  @xcite .",
    "examples include rollups and datacubes for olap applications , running aggregates and window aggregates in time series analysis , and special versions of standard aggregates used to construct classifiers or association rules in datamining @xcite .",
    "furthermore , a new form of aggregation , called online aggregation , finds many uses in data - intensive applications @xcite . to better serve this wide new assortment of applications requiring specialized aggregates , a deductive database system should support user defined aggregates ( udas ) .",
    "therefore , the new + + system supports powerful udas , including online aggregates and monotonic aggregates , in a simple rule - based framework built on formal logic - based semantics .    in + + users",
    "can define a new aggregate by writing the single , multi , and freturn rules ( however , ereturn rules can be used to supplement or replace freturn rules ) .",
    "the single rule defines the computation for the first element of the set ( for instance @xmath85 has its second argument set to @xmath88 ) , while multi defines the induction step whereby the value of the aggregate on a set of @xmath89 elements is derived from the aggregate value of the previous set with @xmath90 elements and the value of @xmath91 element itself .",
    "a unique aggregate name is used as the first argument in the head of these rules to eliminate any interference between the rules defining different aggregates .",
    "for instance , for computing averages we must compute both the count and the sum of the elements seen so far :    then , we write a freturn rule that upon visiting the final element in @xmath75 produces the ratio of sum over count , as follows :    after an aggregate is defined by its @xmath92 , @xmath93 , @xmath94 and/or @xmath95 rules , it can be invoked and used in other rules .",
    "for instance , our the newly defined @xmath96 can be invoked as follows :    thus + + uses the special notation of pointed brackets , in the head of rules , to denote the application of an aggregate .",
    "this syntax , that has been adopted by other languages @xcite , also supports an implicit ` group by ' construct , whereby the aggregate arguments in the head are implicitly grouped by the other arguments in the head . thus , to find the average salary of employees grouped by department a user can write the following rule :    the formal semantics of udas was introduced in @xcite and is described in the appendix : basically , the aggregate invocation rules and the aggregate definition rules are rewritten into an equivalent program that calls on the chain predicate defined as in example [ ex4 ] .",
    "( naturally , for the sake of efficiency , the + + system shortcuts the full rewriting used to define their formal semantics , and implement the udas by a more direct implementation . )    + + udas have also been extended to support online aggregation  @xcite .",
    "this is achieved by using @xmath97 rules in the definition of udas , to either supplement , or replace @xmath95 rules .",
    "for example , the computation of averages normally produces an approximate value long before the whole data set is visited .",
    "then , we might want to see the average value obtained so far every 100 elements .",
    "then , the following rule will be added :    thus the @xmath94 rules produce _ early returns _ , while the freturn rules produce final returns .",
    "as second example , let us consider the well - known problem of coalescing after temporal projection in temporal databases @xcite .",
    "for instance in example 5 , below , after projecting out from the employee relation the salary column , we might have a situation where the same @xmath98 appears in tuples where their valid - time intervals overlap ; then these intervals must be coalesced . here",
    ", we use closed intervals represented by the pair @xmath99 where @xmath100 is the start - time , and @xmath101 is the end - time . under the assumption that tuples are sorted by increasing start - time",
    ", then we can use a special @xmath102 aggregate to perform the task in one pass through the data .    coalescing overlapping intervals sorted by start time .",
    "[ coalesc ]    since the input intervals are ordered by their start time , the new interval @xmath103 overlaps the current interval @xmath104 when @xmath105 ; in this situation , the two intervals are merged into one that begins at @xmath106 and ends with the larger of @xmath107 and @xmath108 .",
    "when , the new interval does not overlap with the current interval , this is returned by the ereturn rule , while the new interval becomes the current one ( see the last multi rule ) .",
    "let @xmath10 be a program .",
    "a rule @xmath14 of @xmath10 whose head contains aggregates is called an _",
    "aggregate rule_. then , @xmath10 is said to be stratified w.r.t .",
    "aggregates when for each aggregate rule @xmath14 in @xmath10 , the stratum of @xmath14 s head predicate is strictly higher than the stratum of each predicate in the head of @xmath14 .",
    "therefore , the previous program is stratified with respect to @xmath102 which is nonmonotonic since it uses both early returns and final returns .",
    "while , programs stratified with respect to aggregates can be used in many applications , more advanced applications require the use of aggregates in more general settings .",
    "thus , + + supports the usage of arbitrary aggregates in xy - stratified programs , which will be discussed in section 3 .",
    "furthermore + + supports the monotonic aggregates that can be used freely in recursion .",
    "an important result that follows from the formalization of the semantics of udas @xcite ( see also appendix ) , is that uda defined without final return rules , i.e. , no freturn rule , define monotonic mappings , and can thus be used without restrictions in the definition of recursive predicates .",
    "for instance , we will next define a continuous count that returns the current count after each new element ( thus final returns are here omitted since they are redundant ) .",
    "monotonic aggregates allow us to express the following two examples taken from @xcite .",
    "[ [ join - the - party ] ] join the party + + + + + + + + + + + + + +    some people will come to the party no matter what , and their names are stored in a @xmath109 relation . but others will join only after they know that at least @xmath110 of their friends will be there . here , @xmath111 denotes that @xmath112 is a friend of person @xmath113 .",
    "consider now a computation of these rules on the following database .",
    "then , the basic semi - naive computation yields : @xmath114 @xmath115 @xmath116 @xmath117    this example illustrates how the standard semi - naive computation can be applied to queries containing monotone udas .",
    "another interesting example is transitive ownership and control of corporations .",
    "[ [ company - control ] ] company control + + + + + + + + + + + + + + +    say that @xmath118 denotes the percentage of shares that corporation @xmath119 owns of corporation @xmath120 . then , @xmath119 controls @xmath120 if it owns more than , say , @xmath121 of its shares . in general , to decide whether @xmath119 controls @xmath122 we must also add the shares owned by corporations , such as @xmath120 , that are controlled by @xmath119 .",
    "this yields the transitive control rules defined with the help of a continuous sum aggregate that returns the partial sum for each new element :    thus , every company controls itself , and a company @xmath119 that has transitive ownership of more than @xmath121 of @xmath120 s shares controls @xmath120 . in the last rule",
    ", @xmath123 computes transitive ownership with the help of @xmath124 that adds up the shares of controlling companies .",
    "observe that any pair @xmath125 is added at most once to @xmath126 , thus the contribution of @xmath119 to @xmath127 s transitive ownership of @xmath120 is only accounted once .",
    "[ [ bill - of - materials - bom - applications ] ]   bill - of - materials ( bom ) applications + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    bom applications represent an important application area that requires aggregates in recursive rules .",
    "for instance , let us say that @xmath128 denotes that @xmath129 contains part @xmath130 in quantity @xmath131 .",
    "we also have elementary parts described by the relation @xmath132 .",
    "then , the following program computes the cost of a part as the sum of the cost of the basic parts it contains :    thus , the key condition in the body of the second rule is that a subpart @xmath133 is counted in @xmath134 only when all @xmath135 s children have been counted .",
    "this occurs when the number of @xmath135 s children counted so far by @xmath85 is equal to the out - degree of this node in the graph representing @xmath136 .",
    "this number is kept in the prolificacy table , @xmath137 , which can be computed as follows :    therefore the simple and general solution of the monotonic aggregation problem introduced by + + allows the concise expression of many interesting algorithms .",
    "this concept can also be extended easily to sql recursive queries , as discussed in @xcite where additional applications are also discussed .",
    "the need to go beyond stratification has motivated much recent research .",
    "several deductive database systems have addressed it by supporting the notion of modular stratification @xcite .",
    "unfortunately , this approach suffers from poor usability , since the existence of a modular stratification for a program can depend on its extensional information ( i.e. , its fact base ) and , in general , can not be checked without executing the program .",
    "the standard notion of stratification is instead much easier to use , since it provides a simple criterion for the programmer to follow and for the compiler to use when validating the program and optimizing its execution .",
    "therefore , + + has introduced the notion of xy - stratified programs that preserves the compilability and usability benefits of stratified programs while achieving the expressive power of well - founded models @xcite .",
    "xy - stratified programs are locally stratified explicitly by a temporal argument : thus , they can be viewed as datalog@xmath138 programs , which are known to provide a powerful tool for temporal reasoning @xcite , or as statelog programs that were used to model active databases  @xcite .",
    "the deductive database system aditi @xcite also supports the closely related concept of explicitly locally stratified programs , which were shown to be as powerful as well - founded models , since they can express their alternating fixpoint computation  @xcite .",
    "for instance , the ancestors of marc , with the number of generations that separate them from marc , can be computed using the following program which models the differential fixpoint computation :    computing ancestors of marc and their remoteness from marc using differential fixpoint approach .",
    "[ deltagap ] r_1 : r_2 : r_3 : r_4 :    this program is locally stratified by the first arguments in @xmath139 and @xmath140 that serve as temporal arguments ( thus + 1 is a postfix successor function symbol , much the same as @xmath141 that denotes the successor of @xmath142 in datalog@xmath138 @xcite ) .",
    "the zero stratum consists of atoms of nonrecursive predicates such as @xmath143 and of atoms that unify with @xmath144 or @xmath145 .",
    "the @xmath146 stratum consists of atoms of the form @xmath147 , @xmath148 .",
    "thus , the previous program is locally stratified @xcite , since the heads of recursive rules belong to strata that are one above those of their goals .",
    "alternatively , we can view the previous program as a compact representation for the stratified program obtained by instantiating the temporal argument to integers and attaching them to the predicate names , thus generating an infinite sequence of unique names .",
    "also observe that the temporal arguments in rules are either the same as , or one less than , the temporal argument in the head .",
    "then , there are two kinds of rules in our example : ( i ) x - rules ( i.e. , a horizontal rules ) where the temporal argument in each of their goals is the same as that in their heads , and ( ii ) y - rules ( i.e. , a vertical rules ) where the temporal arguments in some of their goals are one less than those in their heads",
    ". formally , let @xmath10 be a set of rules defining mutually recursive predicates , where each recursive predicate has a distinguished temporal argument and every rule in @xmath10 is either an x - rule or a y - rule .",
    "then , @xmath10 will be said to be an xy - program .",
    "for instance , the program in example [ deltagap ] is an xy - program , where @xmath149 and @xmath150 are x - rules , while @xmath151 and @xmath152 are y - rules .",
    "a simple test can now be used to decide whether an xy - program @xmath10 is locally stratified .",
    "the test begins by labelling all the head predicates in @xmath10 with the prefix ` new ' .",
    "then , the body predicates with the same temporal argument as the head are also labelled with the prefix ` new ' , while the others are labelled with the prefix ` old ' .",
    "finally , the temporal arguments are dropped from the program .",
    "the resulting program is called the _ bistate version _ of @xmath10 and is denoted @xmath153 .    the bistate version of the program in example [ deltagap ] [ bistate ]    now we have that  @xcite :    let @xmath10 be an xy - program .",
    "@xmath10 is said to be xy - stratified when @xmath153 is a stratified program .",
    "let @xmath10 be an xy - stratified program",
    ". then @xmath10 is locally stratified .",
    "the program of example [ bistate ] is stratified with the following strata : @xmath154 @xmath155 @xmath156 , @xmath157 , and @xmath158 .",
    "thus , the program in example [ deltagap ] is locally stratified .    for an xy - stratified program @xmath10 , the general iterated fixpoint procedure @xcite used to compute the stable model of locally stratified programs",
    "@xcite becomes quite simple ; basically it reduces to a repeated computation over the stratified program @xmath153 .",
    "for instance , for example [ bistate ] we compute @xmath159 from @xmath160 and then @xmath161 from this .",
    "then , the ` old ' relations are re - initialized with the content of the new ones so derived , and the process is repeated . furthermore ,",
    "since the temporal arguments have been removed from this program , we need to    1 .",
    "store the temporal argument as an external fact @xmath162 , 2 .",
    "add a new goal @xmath163 to each exit rule @xmath14 in @xmath153 , where @xmath164 is the variable from the temporal arguments of the original rule @xmath14 , and 3 .",
    "for each recursive predicate @xmath165 add the rule : +    the program so constructed will be called the _ synchronized _ bistate version of @xmath10 , denoted @xmath166 .",
    "for instance , to obtain the synchronized version of the program in example [ bistate ] , we need to change the first rule to since the temporal argument in the original exit rule was the constant @xmath167 .",
    "then , we must add the following rules :     +    then , the iterated fixpoint computation for an xy - stratified program can be implemented by the following procedure :    _ computing a stable model of an xy - stratified program @xmath10 : _ [ xycomp ] add the fact @xmath168 .",
    "then , forever repeat the following two steps :    1 .   compute the stable model of @xmath166 .",
    "2 .   for each recursive predicate @xmath165 , replace @xmath169 with @xmath170 , computed in the previous step .",
    "then , increase the value of @xmath171 by one .",
    "since @xmath166 is stratified , we can then use the iterated fixpoint computation to compute its stable model .",
    "since each xy - stratified program is locally stratified @xcite , it is guaranteed to have a unique stable model , which is also known as its perfect model @xcite .",
    "but the special syntactic structure of xy - stratified programs allows an efficient computation of their perfect models using procedure 4 ; moreover , in the actual + + implementation , this computation is further improved with the optimization techniques discussed next .",
    "for instance , the replacement of @xmath169 with @xmath170 described in the last step of procedure [ xycomp ] becomes an operation of ( small ) constant cost when it is implemented by switching the pointers to the relations .",
    "a second improvement concerns _ copy rules _ , such as the last rule in example [ deltagap ] . for instance @xmath152 in example 6 is a copy rule that copies the new values of @xmath140 from its old values .",
    "observe that the body and the head of this rule are identical , except for the prefixes @xmath172 or @xmath173 , in its bistate version ( example [ bistate ] ) .",
    "thus , in order to compute @xmath174 , we first execute the copy rule by simply setting the pointer to @xmath174 to point to @xmath175a constant - time operation .",
    "rule @xmath149 that adds tuples to @xmath174 is then executed after @xmath152 .    in writing xy - stratified programs ,",
    "the user must also be concerned with termination conditions , since e.g. , a rule such as @xmath152 in example [ deltagap ] could , if left unchecked , keep producing @xmath140 results under a new temporal argument , after @xmath176 becomes empty .",
    "one solution to this problem is for the user to add the goal @xmath177 to rule @xmath152 .",
    "then , the computation @xmath140 stops as soon as no new @xmath177 is generated . alternatively , our program could be called from a goal such as @xmath178 . in this case , if @xmath151 fails to produce any result for a value @xmath179 , no more results can be produced at successive steps , since @xmath178 is a positive goal of @xmath151 .",
    "the + + system is capable of recognizing these situations , and it will terminate the computation of procedure [ xycomp ] when either condition occurs .",
    "example [ overlap ] solves the coalescing problem without relying on tuples being sorted on their start - time  an assumption made in example [ coalesc ] .",
    "therefore , we use the xy - stratified program of example  [ overlap ] , which iterates over two basic computation steps .",
    "the first step is defined by the overlap rule , which identifies pairs of distinct intervals that overlap , where the first interval contains the start of the second interval .",
    "the second step consists of deriving a new interval that begins at the start of the first interval , and ends at the later of the two endpoints . finally , a rule @xmath180 returns the intervals that do not overlap other intervals ( after eliminating the temporal argument ) . +    coalescing overlapping periods into maximal periods after a projection [ overlap ]    as demonstrated by these examples , xy - stratified programs allow an efficient logic - based expression of procedural algorithms .",
    "for instance , the alternating fixpoint procedure used in the computation of well - founded models can also be expressed using these programs @xcite . in general ,",
    "xy - stratified programs are quite powerful , as demonstrated by fact that these programs ( without choice , aggregates , and function symbol ) are known to be equivalent to statelog programs @xcite , which have pspace complexity and can express the while queries @xcite . finally , observe that the bistate programs for the examples used here are nonrecursive . in general , by making the computation of the recursive predicate explicit as it was done for the anc example , it is possible to rewrite an xy - stratified program @xmath10 whose bistate version @xmath153 is recursive into an xy - stratified program @xmath40 whose bistate version @xmath181 is nonrecursive .      as described in section [ sec : choice ] , choice can be used in stratified programs with no restriction , and its stable model can be computed by an iterated choice fixpoint procedure . generalizing such notion , the + + system supports the use of choice in programs that are xy - stratified with respect to negation .",
    "the following conditions are however enforced to assure the existence of stable models for a given program @xmath10 @xcite :    * the program obtained from @xmath10 by removing its choice goals is xy - stratified w.r.t .",
    "negation , and * if @xmath14 is a recursive choice rule in @xmath10 , then _ some _ choice goal of @xmath14 contains @xmath14 s temporal variable in its left side .    after checking these conditions , the +",
    "+ compiler constructs @xmath166 by dropping the temporal variable from the choice goals and transforming the rest of the rules as described in the previous section .",
    "then , the program @xmath166 so obtained is a stratified choice program and its stable models can be computed accordingly ; therefore , each stable model for the original xy - stratified program @xmath10 is computed by simply applying procedure  [ xycomp ] with no modification @xcite .    using the simple syntactic characterization given in section  [ sec : udas ] , +",
    "+ draws a sharp distinction between monotonic and nonmonotonic aggregates .",
    "no restriction is imposed on programs with only monotonic aggregates and no negation . but",
    "recursive programs with nonmonotonic aggregates must satisfy the following conditions ( which assure that once the aggregates are expanded as described in section  [ sec : udas ] the resulting choice program satisfies the xy - stratification conditions for choice programs discussed in the previous paragraph ) :    * for each recursive rule , the temporal variable must be contained in the group - by attributes .",
    "* the bistate version of @xmath10 must be stratified w.r.t .",
    "negation and nonmonotonic aggregates , and    after checking these simple conditions , the + + compiler proceeds with the usual computation of @xmath166 as previously described .",
    "for instance , the following xy - stratified program with aggregates expresses floyd s algorithm to compute the least - cost path between pairs of nodes in a graph .",
    "here , @xmath182 denotes an arc from @xmath80 to @xmath82 of cost @xmath183 :    floyd s least - cost paths between all node pairs .",
    "the fourth rule in this example uses a nonmonotonic min aggregate to select the least cost pairs among those just generated ( observe that the temporal variable @xmath179 appears among the group - by attributes ) .",
    "the next two rules derive the new @xmath176 pairs by discarding from @xmath172 those that are larger than any existing pair in @xmath184 .",
    "this new @xmath176 is then used to update @xmath184 and compute new pairs .    by supporting udas , choice , and xy - stratification + +",
    "provides a powerful , fully integrated framework for expressing logic - based computation and modelling .",
    "in addition to express complex computations  @xcite , this power has been used to model the ai planning problem @xcite , database updates , and active database rules  @xcite .",
    "for instance , to model ai planning , preconditions can simply be expressed by rules , choice can be used to select among applicable actions , and frame axioms can be expressed by xy - stratified rules that describe changes from the old state to the new state @xcite .",
    "the main objectives in the design of the + + system , were ( i ) strengthening the architecture of the previous system  @xcite , ( ii ) improving the system s usability and the application development turnaround time , and ( iii ) provide efficient support for the new language constructs .",
    "while the first objective could be achieved by building on and extending the general architecture of the predecessor system , the second objective forced us to depart significantly from the compilation and execution approach used by the system .",
    "in fact , the old system adhered closely to the set - oriented semantics of relational algebra and relational databases ; therefore , it computed and accumulated all partial results before returning the whole set to the user . however , our experience in developing applications indicated that a more interactive and incremental computation model was preferable : i.e. , one where users see the results incrementally as they are produced .",
    "this allows developers to monitor better the computation as it progresses , helping them debugging their programs , and , e.g. , allowing them to stop promptly executions that have fallen into infinite loops .",
    "therefore , + + uses a pipelined execution model , whereby tuples are generated one at a time as they are needed ( i.e. , lazily as the consumer requests them , rather than eagerly ) .",
    "this approach also realizes objective ( iii ) by providing better support for new constructs , such as choice and on - line aggregation , and for intelligent backtracking optimization ( discussed in the next section ) .",
    "the + + system also adopted a shallow - compilation approach that achieves faster turnaround during program development and enhances the overall usability ; this approach also made it easier to support on - line debugging and meta - level extensions .",
    "the previous system was instead optimized for performance ; thus , it used a deep - compilation approach where the original program was translated into a ( large ) c program  whose compilation and linking slowed the development turnaround time .",
    "the architecture of the system is summarized in the next section ; additional information , a web demo , and instructions on downloading for noncommercial use can be found in  @xcite .      the overall architecture of the + + system and its main components",
    "are shown in figure  1 .",
    "the major components of the system are :    [ [ the - compiler ] ] the compiler + + + + + + + + + + + +    the compiler reads in + + programs and constructs the _ global predicate connection graph _ ( pcg ) . for each query form",
    ", the compiler partially evaluates the pcg , transforming it into a network of objects that are executed by the interpreter .",
    "the compiler is basically similar to that of the old system @xcite , and is responsible for checking the safety of queries , and rewriting the recursive rules using techniques such the magic sets method @xcite , and the more specialized methods for left - linear and right - linear rules @xcite .",
    "these rewriting techniques result in an efficient execution plan for queries .",
    "[ [ the - database - managers ] ] the database managers + + + + + + + + + + + + + + + + + + + + + +    the experience confirmed the desirability supporting access to ( i ) an internal ( fast - path ) database and ( ii ) multiple external dbmss in a transparent fashion .",
    "this led to the design of a new system where the two types of database managers are fully integrated .",
    "the internal database is shown in figure [ ldl_arch ] as fact base manager .",
    "this module supports the management and retrieval of + + complex objects , including sets and lists , and of temporary relations obtained during the computation .",
    "in addition to supporting users data defined by the schema as internal relations , the interpreter relies on the local database to store and manage temporary data sets . the internal database is designed as a virtual - memory record manager : thus its internal organization and indexing schemes are optimized for the situation where the pages containing frequently used data can reside in main memory .",
    "data is written back onto disk at the commit point of each update transaction ; when the transaction aborts the old data is instead restored from disk .",
    "the system also supports an external database manager , which is designed to optimize access to external sql databases ; this is described in section [ sec : externaldb ] .",
    "[ [ interpreter ] ] interpreter + + + + + + + + + + +    the interpreter receives as input a graph of executable objects corresponding to an + + query form generated by the compiler , and executes it by issuing get - next , and other calls , to the local database .",
    "similar calls are also issued by the external database manager and the external predicate manager to , respectively , external databases , and external functions or software packages that follow the c / c++ calling conventions .",
    "details on the interpreter are presented in the next section .",
    "[ [ user - interface ] ] user interface + + + + + + + + + + + + + +    all applications written in c / c++ can call the + + system via a standard api ; thus applications written in + + can be embedded in other procedural systems .",
    "one such application is a line - oriented command interpreter supporting a set of predefined user commands , command completion and on - line help .",
    "the command interpreter is supplied with the system , although it is not part of the core system .",
    "basically , the interface is an application built in c++ that can be replaced with other front - ends , including graphical ones based on a gui , without requiring any changes to the internals of the system . in particular ,",
    "a java - based interface for remote demoing was added recently @xcite .",
    "the abstract machine for the + + interpreter is based upon the architecture described in @xcite .",
    "an + + program is transformed into a network of active objects and",
    "the graph - based interpreter then processes these objects .",
    "[ [ code - generation - and - execution ] ] code generation and execution + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    given a query form , an + + program is transformed into a predicate connection graph ( pcg ) , which can be viewed as an and/or graph with annotations .",
    "an or - node represents a predicate occurrence and each and node represents the head of a rule .",
    "the pcg is subsequently compiled into an evaluable data structure called a lam ( for + + abstract machine ) , whose nodes are implemented as instances of c++ classes .",
    "arguments are passed from one node to the other by means of variables .",
    "unification is done at compile time and the sharing of variables avoids useless assignments .",
    "each node of the generated lam structure has a virtual `` gettuple '' interface , which evaluates the corresponding predicate in the program .",
    "each node also stores a state variable that determines whether this node is being `` entered '' or is being `` backtracked '' into .",
    "the implementation of this `` gettuple '' interface depends on the type of node .",
    "the most basic c++ classes are or - nodes and and - nodes ; then there are several more specialized subclasses of these two basic types .",
    "such subclasses include the special or - node that serves as the distinguished _ root _",
    "node for the query form , internal relations and - nodes , external relations and - nodes , etc .",
    "[ [ andor - graph ] ] and/or graph + + + + + + + + + + + +    for a generic or node corresponding to a derived relation , the `` gettuple '' interface merely issues `` gettuple '' calls to its children ( and nodes ) .",
    "each successful invocation automatically instantiates the variables of both the child ( and node ) and the parent ( or node ) . upon backtracking , the last and node which was successfully executed",
    "is executed again .",
    "the `` gettuple '' on an or node fails when its last and node child fails .",
    "the _ dataflow points _ represent different entries into the and/or nodes , each entry corresponding to a different state of the computation .",
    "the dataflow points associated with each node are shown in the following table ( observe their similarity to ports in byrd s prolog execution model @xcite ) : +    [ cols=\"<,<,<\",options=\"header \" , ]     a dataflow point of a node can be directed to a dataflow point of a different node by a _",
    "dataflow destination_. the _ entry destination ( e_dest ) _ of a given node is the dataflow point to which its entry point is directed .",
    "similarly , _ backtrack ( b_dest ) , success ( s_dest ) _ , and _",
    "fail destinations ( f_dest ) _ can be defined .",
    "the dataflow destinations represent logical operations between the nodes involved ; for example a join or union of the two nodes .",
    "the dataflow points and destinations of a node describe how the tuples of that node are combined with tuples from other nodes ( but not how those tuples are generated ) . to obtain the first tuple of an or node we get the first tuple of its first child and node . to obtain the next tuple from an or node we request it from the and node that generated the previous tuple .",
    "observe that the currently `` active '' and node must be determined at run - time .",
    "when no more tuples can be generated for a given and node , then we go to the next and node , till the last child and node is reached ( at this point no more tuples can be generated for the or node ) .",
    "thus , we have :    _ e_dest _ : = the e_dest of the first child and - node + : the b_dest of the `` active '' child and node + : node is first or node in rule + the f_dest point of parent and node + the b_dest of previous or node + : node is last or node in a rule + the s_dest of parent and node + the e_dest of next or node .",
    "the execution of an and node is conceptually less complicated .",
    "intuitively , the execution corresponds to a nested loop , where , for each tuple of the first or node , we generate all matching tuples from the next or node .",
    "this continues until we reach the last or node .",
    "thus , when generating the next tuple of an and node , we generate the next matching tuple from the last or node . if there are no more matching tuples , we generate the next tuple from the previous or node .",
    "when there are no more tuples to be generated by the first or node , we can generate no more tuples for the and node .",
    "thus we have :    _ e_dest _ : = the e_dest of first or child + : the b_dest of last or child + : = node is last and child + f_dest of parent or node + e _ dest of next and node + : s_dest of parent or node",
    ".    given a query , the + + system first finds the appropriate lam graph for the matching query form , then stores any constant being passed to the query form by initializing the variables attached to the _ root _ node of the lam graph .",
    "finally , the system begins the execution by repeatedly calling the `` gettuple '' method on the root of this graph .",
    "when the call fails the execution is complete .",
    "[ [ lazy - evaluation - of - fixpoints ] ] lazy evaluation of fixpoints + + + + + + + + + + + + + + + + + + + + + + + + + + + +    + + adopts a lazy evaluation approach ( _ pipelining _ ) as its primary execution model , which is naturally supported by the and/or graph described above .",
    "this model is also supported through the lazy evaluation of fixpoints .",
    "the traditional implementation of fixpoints @xcite assumes an eager computation where new tuples are generated till the fixpoint is reached .",
    "+ + instead supports lazy computation where the recursive rules produce new tuples only in response to the goal that , as a consumer , calls the recursive predicate .",
    "multiple consumers can be served by one producer , since each consumer @xmath185 uses a separate cursor @xmath186 to access the relation @xmath187 written by the producer .",
    "whenever @xmath185 needs a new tuple , it proceeds as shown in figure [ lazy ] .",
    ": :    move the cursor @xmath186 to the next tuple of    @xmath187 , and consume the tuple .",
    ": :    if step 1 fails ( thus , @xmath186 is the last tuple of    @xmath187 ) , check the fixpoint flag @xmath188 .",
    ": :    if the fixpoint is reached , return failure .",
    ": :    if the fixpoint is not reached , call the current rule to generate a    new tuple .",
    ": :    if a new tuple is generated , add it to the relation @xmath187 ,    advance @xmath186 and return the tuple .",
    ": :    otherwise , repeat step 2",
    ". +    a limitation of pipelining is that the internal state of each node must be kept for computation to resume where the last call left off .",
    "this creates a problem when several goals call the same predicate ( i.e. the same subtree in the pcg is shared ) .",
    "multiple invocations of a shared node can interfere with each other ( non - reentrant code ) . solutions to this problem include ( i ) using a stack as in prolog , and ( ii ) duplicating the source code as in the system  thus ensuring that the pcg is a tree , rather than a dag  @xcite . in the + + system",
    ", we instead use the lazy producer approach described above for situations where the calling goals have no bound argument . if there are",
    "bound arguments in consuming predicates we duplicate the node .",
    "however , since each node is implemented as a c++ class , we simply generate multiple instances of this class  i.e . , we duplicate the data but still share the code .",
    "[ [ intelligent - backtracking ] ] intelligent backtracking + + + + + + + + + + + + + + + + + + + + + + + +    pipelining makes it easy to implement optimizations such as existential optimization and intelligent backtracking @xcite .",
    "take for instance the following example :    intelligent backtracking .",
    "take the situation where the first @xmath189-value generated by @xmath190 is passed to @xmath191 , which succeeds and passes the value of @xmath189 to @xmath192 .",
    "if the first call to this third goal fails , there is no point in going back to @xmath193 , since this can only return a new value for @xmath194 .",
    "instead , we have to jump back to @xmath190 for a new value of @xmath189 . in an eager approach ,",
    "all the @xmath194-values corresponding to each @xmath189 are computed , even when they can not satisfy @xmath195 .",
    "similar optimizations were also supported in @xcite , but with various limitations : e.g. , existential optimization was not applied to recursive predicates , since these were not pipelined . in + + ,",
    "the techniques are applied uniformly , since pipelining is now used in the computation of all predicates , including recursive ones .",
    "a most useful feature of the system is that it supports convenient and efficient access to external databases .",
    "as shown in figure [ ldl_arch ] , the external database interface ( edi ) provides the capability to interact with external databases .",
    "the system is equipped with a generic sql interface as well as an object - oriented design that allows easy access to external database systems from different vendors . to link the system with a specific external database , it is only necessary to write a small amount of code to implement vendor - specific drivers to handle data conversion and local sql dialects .",
    "the current system can link directly with sybase , oracle , db2 , and indirectly with other databases via jdbc .",
    "the rules in a program make no distinction between internal and external relations .",
    "relations from external sql databases are declared in the schema just like internal relations , with the additional specification of the type and the name of the sql server holding the data . as a result , these external resources are transparent to the inference engine , and applications can access different databases without changes .",
    "the edi can also access data stored in files .",
    "the following example shows the schema declarations used to access an external relation employee in the database payroll running on the server sybase_tarski .",
    "schema declaration to external sybase server .",
    ".... database ( {          sybase::employee(name : char(30),salary : int , manager : char(30 ) )                  from sybase_tarski                  use payroll                  user_name ' john '                  application_name ' downsizing '                  interface_filename ' /tmp",
    "/ ldl++/demo / interfaces '                  password nhoj            } ) .",
    "....    the system generates sql queries that off - loads to the external database server the computation of ( i ) the join , select , project queries corresponding to positive rule goals , ( ii ) the set differences corresponding to the negated goals , and ( iii ) the aggregate operations specified in the heads of the rules .    in the following example",
    "the rule defines expensive employees as those who make over 75,000 and more than their managers :    sql generation    ....     expensive_employee(name ) < -                  employee(name , salary1 , manager ) ,                  salary1 > 75000 ,                  employee(manager , salary2 , _ ) ,                  salary1 > salary2 . ....",
    "the compiler collapses all the goals of this rule and transforms it into the following sql node :    ....          expensive_employee(name ) < - sql_node(name ) . ....    where @xmath196 denotes the following sql query sent to external database server :    ....          select   employee_0.name          from     employee employee_0 , employee employee_1          where    employee_0.salary > 75000 and                employee_1.name = employee_0.manager and                employee_0.salary > employee_1.salary ....    consequently , access to the external database via is as efficient as for queries written directly in sql",
    ". rules with negated goals are also supported and implemented via the not exist construct of sql .",
    "the  sql interface also supports updates to external databases , including set - oriented updates with qualification conditions .",
    "updates to external relations follow the same syntax and semantics as the updates to local relations . the execution of each query form is viewed as a new transaction : either it reaches its commit point or the transaction is aborted .    to better support middleware applications , the coupling of + + with external databases",
    "was further enhanced as follows :    * _ literal collapsing _ :",
    "the goals in the body of a rule are reordered to ensure that several goals using database relations can now be supported as a single sql subquery to be offloaded to the dbms . *",
    "_ rule compression _",
    ": to offload more complex and powerful queries the remote database , literals from multiple levels of rules are combined and the rules are compressed vertically .",
    "* _ aggregates _ : rules that contain standard sql aggregates in their heads can also be offloaded to the remote sql system .      as shown in figure [ ldl_arch ] , the system is designed to achieve an open architecture where links with procedural languages , such c / c++ , can be established in two ways :    * via the application programming interface ( api ) which allows applications to drive the system , and * via the external predicate manager which allows c / c++ functions to be imported into the inference engine as external predicates .    via the api , any c / c++ routine can call the inference engine .",
    "the api provides a set of functions that enable applications to instruct the engine to load a schema , load rules , compile query forms , send queries , and retrieve results .    via the external predicate manager ,",
    "function defined in c / c++ can be imported into + + and treated as logical predicates callable as rule goals .",
    "a library of c / c++ functions is also provided to facilitate the manipulation of internal + + objects , and the return of multiple answers by the external functions .",
    "therefore , external functions can have the same behavior as internal predicates in all aspects , including flow of control and backtracking .",
    "details on these interfaces can be found in @xcite .",
    "the deployment of the and + + prototypes in various real - life applications have much contributed to understanding the advantages and limitations of deductive databases in key application domains @xcite .",
    "moreover , this experience with application problems , has greatly influenced the design of the + + system and its successive improvements .",
    "[ [ recursive - queries . ] ] recursive queries .",
    "+ + + + + + + + + + + + + + + + + +    our first focus was to compute transitive closures and to solve various graph problems requiring recursive queries , such as bill - of - materials  @xcite .",
    "unfortunately , many of these applications also require that set - aggregates , such as counts and minima , be computed during the recursive traversal of the graph .",
    "therefore , these applications could not be expressed in which only supported stratified semantics , and thus disallowed the use of negation and aggregation within recursive cliques . going beyond stratification thus became a major design objective for + + .",
    "[ [ rapid - prototyping - of - information - systems . ] ] rapid prototyping of information systems .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    rapid prototyping from e - r specifications has frequently been suggested as the solution for the productivity bottleneck in information system design .",
    "deductive databases provide a rule - based language for encoding executable specifications , that is preferable to prolog and 4gl systems used in the past , because their completely declarative semantics provides a better basis for specifications and formal methods .",
    "indeed , proved to be the tool of choice in the rapid _ prototyping of information systems _ in conjunction with a structured - design methodology called _ pos _ ( process , object and state ) @xcite .",
    "our proof - of - concept experiment confirmed the great potential of deductive databases for the rapid prototyping of information systems ; but this also showed the need for a richer environment that also supports prototyping of graphical interfaces , and the use of e - r based case tools . a large investment in producing such tools is probably needed before this application area can produce a commercial success for deductive databases .",
    "[ [ middleware ] ] middleware + + + + + + + + + +    at mcc , + + was used in the carnot / infosleuth project to support semantic agents that carry out distributed , coordinated queries over a network of databases  @xcite . in particular , + + was used to implement the ontology - driven mapping between different schemas ; the main functions performed by + + include ( i ) transforming conceptual requests by users into a collection of cooperating queries , ( ii ) performing the needed data conversion , and ( iii ) offloading to sql statements executable on local schemas ( for both relational and o - o databases ) .    [ [ scientific - databases ] ] scientific databases + + + + + + + + + + + + + + + + + + + +    the + + system provided a sound environment on which to experiment with next - generation database applications , e.g. , to support domain science research , where complex data objects and novel query and inferencing capabilities are required .",
    "a first area of interest was molecular biology , where several pilot applications relating to the human genome initiative @xcite were developed @xcite .",
    "+ + rules were also used to model and support taxonomies and concepts from the biological domain , and to bridge the gap between high - level scientific models and low - level experimental data when searching and retrieving domain information @xcite .",
    "a second research area involves geophysical databases for atmospheric and climatic studies @xcite .",
    "for instance , there is a need for detecting and tracking over time and space the evolution of synoptic weather patterns , such as cyclones .",
    "the use of + + afforded the rapid development of queries requiring sophisticated spatio - temporal reasoning on the geographical database .",
    "this first prototype was then modified to cope with the large volume of data required , by off - loading much of the search work to the underlying database .",
    "special constructs and operators were also added to express cyclone queries  @xcite .    [ [ knowledge - discovery - and - decision - support - applications ] ] knowledge discovery and decision support applications + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the potential of the + + technology in this important application area was clear from the start @xcite , when our efforts concentrated on providing the analyst with powerful tools for the verification and refinement of scientific hypotheses @xcite . in our early experiments , the expert would write complex verification rules that were then applied to the data .",
    "+ + proved well - suited for the rapid prototyping of these rules , yielding what became known as the ` data dredging ' paradigm @xcite .    a more flexible methodology was later developed combining the deductive rules with inductive tools , such as classifiers or bayesian estimation techniques .",
    "a prototype of a system combining both the deductive and inductive methods is the  knowledge miner \" @xcite , which was used in the discovery of rules from a database of chemical process data ; + + meta predicates proved very useful in this experiment  @xcite .",
    "other experiments demonstrated the effectiveness of the system in performing important auxiliary tasks , such as data cleaning  @xcite . in these applications ,",
    "the declarative power of + + is used to specify the rules that define correct data .",
    "these allow record - by - record verification of data for correctness but also the identification of _ sets _ of records , whose combination violates the integrity of the data .",
    "finally , the rules are used to clean ( i.e. , correct ) inconsistent data .",
    "this capability can either be used prior to the loading of data into the database , or during the updating of the data after loading .",
    "this early investigations paved the way for a major research project discussed next focusing on using + + in datamining applications .",
    "[ [ developing - data - mining - applications ] ] developing data mining applications + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the results of extensive experiences with an + + based environment for knowledge discovery were reported in  @xcite .",
    "the first study  @xcite describes the experience with a fraud detection application , while the second one reports on a marketing application using market basket analysis techniques  @xcite . in both studies , + + proved effective at supporting the many diverse steps involved in the kdd process . in  @xcite ,",
    "the authors explain the rationale for their approach and the reasons for their success , by observing that the process of making decisions requires the integration of two kinds of activities : ( i ) knowledge acquisition from data ( inductive reasoning ) , and ( ii ) deductive reasoning about the knowledge thus induced , using expert rules that characterize the specific business domain . activity ( i ) relies mostly on datamining functions and algorithms that extract implicit knowledge from raw data by performing aggregation and statistical analysis on the database . a database - oriented rule - based system , such as + + , is effective at driving and integrating the different tasks involved in ( i ) and very effective in activity ( ii ) where the results of task ( i ) are refined , interpreted and integrated with domain knowledge and business rules characterizing the specific application .    for instance ,",
    "association rules derived from market basket analysis are often too low - level to be directly used for marketing decisions .",
    "indeed , market analysts seek answers to higher - level questions , such as  is the supermarket assortment adequate for the company s target customer class ? \" or  is a promotional campaign effective in establishing a desired purchasing habit in the target class of customers ? \" .",
    "+ + deductive rules were used in @xcite to drive and control the overall discovery process and to refine the raw association rules produced by datamining algorithms into knowledge of interest to the business .",
    "for instance , + + would be used to express queries such as  which rules survive / decay as one moves up or down the product hierarchy ? \" or ",
    "what rules have been effected by the recent promotions \" @xcite .",
    "the most useful properties of + + mentioned in these studies  @xcite were flexibility , capability to adapt to the analyst s needs , and modularity , i.e. , the ability to clearly separate the different functional components , and provide simple interfaces for their integration . in particular , the user defined aggregates described in section 2.2 played a pivotal roles in these datamining applications since datamining functions ( performing the inductive tasks ) were modelled as user - defined aggregates which could then be conveniently invoked by the + + rules performing the deductive tasks  @xcite .",
    "the performance and scalability challenge was then addressed by encoding these user - defined aggregates by means of + + procedural extensions , and , for database resident data , offloading critical tasks to the database system containing the data  @xcite .",
    "[ [ lessons - learned ] ] lessons learned + + + + + + + + + + + + + + +    the original motivations for the development of the original system was the desire to extend relational query languages to support the development of complete applications , thus eliminating the impedance mismatch from which applications using embedded sql are now suffering .",
    "in particular , data intensive expert systems were the intended ` killer ' applications for .",
    "it was believed that such applications call for combining databases and logic programming into a rule - based language capable of expressing reasoning , knowledge representation , and database queries . while the original application area failed to generate much commercial demand , other very promising areas emerged since then . indeed",
    "the success of + + in several areas is remarkable , considering that + + is suffering from the combined drawbacks of ( i ) being a research prototype ( rather than a supported product ) , and yet ( ii ) being subject to severe licensing limitations . unless the situation changes and these two handicaps are removed , the only opportunities for commercial deployments will come from influencing other systems ; i.e. , from system that borrow the + + technology to gain an edge in advanced application areas , such as datamining and decision support systems .",
    "among the many remarkable projects and prototypes developed in the field of logic and databases @xcite , the /++ project occupies a prominent position because the level and duration of its research endeavor , which brought together theory , systems , and applications . by all objective measures , the + + project succeeded in its research objectives .",
    "in particular , the nondeterministic and nonmonotonic constructs now supported in + + take declarative logic - based semantics well beyond stratification in terms of power and expressivity ( and stratified negation is already more powerful than sld - nf ) .",
    "the + + system supports well the language and its applications .",
    "in particular , the pipelined execution model dovetails with constructs such as choice and aggregates ( and incremental answer generation ) , while the system s open architecture supports tight coupling with external databases , jdbc , and other procedural languages .",
    "the merits of the + + technology , and therefore of deductive databases in the large , have been demonstrated in several pilot applications  particularly datamining applications .",
    "although there is no current plan to develop + + commercially , there remain several exciting opportunities to transfer its logic - oriented technology to related fields .",
    "for instance , the new query and data manipulation languages for web documents , particularly xml documents , bear affinity to logic - based rule languages .",
    "another is the extension to sql databases of the new constructs and non - stratified semantics developed for + + : in fact , the use of monotonic aggregates in sql has already been explored in @xcite .",
    "abiteboul , s. , hull , r. and vianu , v. ( 1995 ) .",
    "addison - wesley , reading , ma , 1995 .",
    "ackley , d. , et al .",
    "( 1990 ) system analysis for deductive database environments : an enhanced role for aggregate entities , _ procs .",
    "conference on entity - relationship approach _ , lausanne , ch , oct .",
    "8 - 10 , 1990 .",
    "bancilhon , f. , maier d. , sagiv , y. and ullman , j. ( 1986 ) magic sets and other strange ways to implement logic programs , in _ proc .",
    "sigact - sigmod principles of database systems conference ( pods ) _ , pp",
    ". 1 - 16 , 1986 .",
    "baudinet , m. , chomicki , j. , and wolper , p. ( 1994 ) temporal deductive databases , chapter 13 of _ temporal databases : theory , design , and implementation _ , a. tansel et al .",
    "( eds ) , pp .",
    "294 - 320 , benjamin / cummings , 1994 .",
    "giannotti , f. , manco , g. , nanni , m. , pedreschi , d. ( 1998 ) on the effective semantics of nondeterministic , nonmonotonic , temporal logic databases , pp .",
    "58 - 72 , lecture notes in computer science , vol .",
    "1584 , springer , 1999 .",
    "giannotti , f. , manco , g. , pedreschi , d. , turini , f. ( 1999 ) experiences with a logic - based knowledge discovery support environment , acm sigmod workshop on research issues in data mining and knowledge discovery , dmkd99 , philadelphia , usa , may 30 , 1999      giannotti , f. , pedreschi , d. and zaniolo , c. ( 2001 ) semantics and expressive power of non - deterministic constructs in deductive databases , _ journal of computer and system science _ , vol .",
    "1 , pp . 15 - 42 , 2001 .",
    "kemp , d. , ramamohanarao , k. , and stuckey , p. ( 1995 ) els programs and the efficient evaluation of non - stratified programs by transformation to els , in _ proc .",
    "fourth int . conf . on deductive and object - oriented databases : dood95 _ , t. w. ling , a. o. mendelzon , l. vieille ( eds . ) , pp .  91108 , springer , 1995 .",
    "lausen , g. ludscher , b. , may , w. ( 1998 ) on active deductive databases : the statelog approach , in _ transactions and change in logic databases _ , b. freitag , h. decker , m. kifer , a. voronkov ( eds . ) , lcns 1472 , springer , pp . 69106 , 1998 .",
    "lausen , g. , ludscher , b. and may , w. ( 1998 ) on logical foundations of active databases , _ in logics for databases and information systems _ , j. chomicki and g. saake ( eds . ) , kluwer academic publishers , pp . 375398 , 1998 .",
    "przymusinski , t. ( 1988 ) on the declarative and procedural semantics of stratified deductive databases , in j.  minker ( ed . ) , _ foundations of deductive databases and logic programming _ , pp .",
    "morgan - kaufman , los altos , ca , 1988 .",
    "sacc , d. , and zaniolo , c. ( 1990 ) stable models and nondeterminism in logic programs with negation , _ proc .",
    "9th , acm sigact - sigmod - sigart symposium on principles of database systems _ , pp . 205218 , 1990 .",
    "schlipf , j.s .",
    "( 1993 ) a survey of complexity and undecidability results in logic programming , _ proc .",
    "workshop on structural complexity and recursion - theoretic methods in logic programming _ ,",
    "pp.143164 , 1993 .",
    "shen w. , mitbander w. , ong k. and zaniolo , c , ( 1994 ) using metaqueries to integrate inductive learning and deductive database technology , , in _ aaai workshop on knowledge discovery from databases _ , seattle 1994 .",
    "shmueli , o. , tsur , s. and zaniolo , c. ( 1988 ) rewriting of rules containing set terms in a logic database language ( ldl ) , _ proc . of the seventh acm symposium on principles of database systems",
    "15 - 28 , 1988 .",
    "van  gelder , a. ( 1993 ) foundations of aggregations in deductive databases , _ proc . of int .",
    "conf . on deductive and object - oriented databases _",
    ", , s. ceri , k. tanaka , s. tsur ( eds . ) , pp .",
    "13 - 34 , springer , 1993 .",
    "zaniolo c. , arni n. and ong , k. ( 1993 ) negation and aggregates in recursive rules : the + + approach , _ proceedings third int . conference on deductive and object - oriented databases : dood 1993 _ , pp .",
    "204 - 221 , springer , 1993 .",
    "zaniolo , c. ( 1994 ) a unified semantics for active and deductive databases , in _ proceedings workshop on rules in database systems , rids93 _ , norman w. paton , m. howard williams ( eds . ) , pp . 271 - 287 springer verlag , 1994 .",
    "zaniolo , c. and wang , h. ( 1999 ) logic - based user - defined aggregates for the next generation of database systems , in _ the logic programming paradigm : current trends and future directions .",
    "_ apt , k.r . ,",
    "marek , v. , truszczynski , m . ,",
    "warren , d.s .",
    "( eds . ) , springer verlag , pp . 401 - 424 , 1999 .",
    "the expressive power of choice can be used to provide a formal definition of aggregates in logic .",
    "say for instance that we want to define the aggregate avg that returns the average of all @xmath82-values that satisfy @xmath75 . by the notation used in  @xcite , @xmath197 @xcite , and + +",
    ", this computation can be specified by the following rule :          thus , the @xmath199 rules are used to memorize the previous results , and to apply ( i ) single to the first element of @xmath75 ( i.e. , for the pattern @xmath201 ) and ( ii ) @xmath93 to the successive elements .",
    "the return rules are as follows :    therefore , we first compute @xmath54 , and then @xmath199 that applies the @xmath92 and @xmath93 rules to every element in the chain",
    ". concurrently , the first results rule produces all the results that can be generated by the application of the @xmath94 rules to the element in the chain .",
    "the final returns are instead computed by the second @xmath202 rule that calls on the @xmath95 rules once the last element in the chain ( i.e. , the element without successors ) is detected .",
    "the second @xmath202 rule is the only rule using negation ; in the absence of @xmath95 this rule can be removed yielding a positive choice program that is monotonic by theorem 2 .",
    "thus , every aggregate with only early returns is _ monotonic with respect to set containment _ and can be used freely in recursive rules .",
    "[ lastpage ]"
  ],
  "abstract_text": [
    "<S> this paper describes the + + system and the research advances that have enabled its design and development . </S>",
    "<S> we begin by discussing the new nonmonotonic and nondeterministic constructs that extend the functionality of the + + language , while preserving its model - theoretic and fixpoint semantics . </S>",
    "<S> then , we describe the execution model and the open architecture designed to support these new constructs and to facilitate the integration with existing dbmss and applications . </S>",
    "<S> finally , we describe the lessons learned by using + + on various tested applications , such as middleware and datamining .    </S>",
    "<S> [ firstpage ] </S>"
  ]
}