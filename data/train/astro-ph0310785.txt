{
  "article_text": [
    "analysis of spatial fluctuations in the level of background radiation has been used by radio @xcite and x - ray astronomers to gain information on number count - flux relation below the detection limit .",
    "recently , fluctuations in the infrared background were first detected in maps of the firback survey at wavelength of 170@xmath6 m .",
    "spatial resolution currently available at the far infra - red is of the order of arcminutes . as a result observations at this wavelength are confusion limited",
    "this means that the dominant contribution to noise on sky maps at these wavelengths comes not from detector or photon noise but from the superposition of light originating from galaxies which are too close on the sky to be resolved individually .",
    "it has been shown @xcite that the energy coming from resolved sources on the firback maps comprise only 10@xmath7 of the total energy while the rest is due to the unresolved background radiation .",
    "this means that other than fluctuation analysis ( p(d ) analysis ) , not much else can be done to study the n(s ) of the unresolved infrared sources at the far infra - red .",
    "this study investigates under which conditions p(d ) analysis can usefully constrain galaxy evolution scenarios .",
    "@xcite have introduced a semi - analytical model of galaxy formation and evolution , and within this model suggested several scenarios including different amounts of ultra luminous infrared galaxies . for each of the scenarios they calculated , among other things , faint galaxy counts .",
    "they show that at 175 @xmath6 m the source counts at fluxes 10 - 100 mjy are quite sensitive to the details of the galaxy evolution ; therefore knowing n(s ) to high precision can help choosing between the different scenarios of their galaxy evolution models .",
    "similarly @xcite show that at 175 @xmath6 m the number counts at fluxes 10 - 100 mjy are very dependent on the galaxy evolution models they are suggesting .",
    "when using a simple power law parametrization for the source counts , errors of few percent in the parameters can give an error of  50@xmath7 in the number counts at fluxes of few 10s of mjys , i.e. one anticipates that such counts at these flux levels will easily constrain the parameters .",
    "additionally , at least in the above mentioned families of models at this flux range , the n(s ) due to the different models differ by an order of magnitude .",
    "this justifies attempting to measure the n(s ) parameters to high precision down to few 10s mjy .",
    "note that the flux range of few 10s mjy is far below the detection limit of firback ( 180 mjy ) and therefore , at the moment , can be probed only via p(d ) analysis .",
    "additionnally one would also like to know how much information one can gain about the number counts from specific confusion limited surveys like firback or sirtf using a p(d ) analysis .",
    "this kind of study can be done using a fisher matrix analysis where one calculates the minimal errors of extracted parameters given the experiment and a parameterized theoretical model .",
    "the analysis we make here does not take into account clustering of sources .",
    "some clustering of the far infrared sources is of course expected @xcite , but its amplitude is not yet determined at 175 @xmath6 m .",
    "the small area of the firback fields might not enable to accurately constrain the source clustering but this situation might change with the sirtf observations which cover larger areas of the sky @xcite .",
    "the resolved sources on the firback maps show a level of clustering consistent with zero .",
    "this is probably due to the small number of resolved sources ( guiderdoni and lagache , private communication ) .",
    "hence we are assuming , at this stage , that sources are distributed poissonianly on the sky .",
    "we find that we can constrain the slope of the number counts of sources with high fluxes ( @xmath8 mjy ) at least as well as has been done by extracting individual strong sources .",
    "other parameters ( slope of the number counts at low fluxes , normalization and break flux ) are not as well constrained in the firback type of experiment . however , in an experiment with smaller pixels and more of them ( e.g. sirtf ) we can extract all the parameters to within several percent .",
    "we also found some degeneracies between the different parameters and saw that better experiment like sirtf can not resolve these degeneracies .",
    "the paper is arranged as follows .",
    "we give an explanation of the nature of confusion in sky surveys in section 2 . in section 3",
    "we describe how we model the n(s ) in order to extract it from the data . in section 4",
    "we outline the method of analyzing sky maps in order to extract the parameters of the model .",
    "we describe the implementation of the method and the results of analyzing simulated skies in section 5 .",
    "the spatial fluctuations in the level of background radiation due to spatial distribution of the discrete sources which contribute to the background are called confusion noise . in the far infra - red wavelengths",
    "the level of the confusion noise dominates over any photon or instrumental detector noise existing in today s instruments .",
    "thus while one can reduce the level of instrumental or photon noise by long integration times , the confusion remains a strong characteristic of far - infrared observations .",
    "the full calculation of the probability distribution of the fluctuations ( p(d ) for short ) is classical ( see ) and given in the appendix . here we only give the final result : @xmath9 where d is the deflection from the mean level of flux and @xmath10.\\ ] ]    the shape of the p(d ) depends on several inputs .",
    "first is the differential n(s ) relation , @xmath11 .",
    "this is the number of sources per steradian with fluxes in [ s , s+ds ] .",
    "it also depends on the shape of the beam , which is described by @xmath12 .",
    "@xmath12 is the point spread function of the telescope and @xmath13 is the pixel size .. in general the p(d ) will also depend on clustering of the sources if it is strong enough @xcite but as mensioned before , we are going to deal with a source distribution which is not clustered but poissonian .",
    "it was shown in @xcite that the width of the curve ( the 1@xmath14 of the noise ) is of the order of the flux for which there is one source per beam .",
    "the very faint sources do not contribute at all to the shape of the curve , but only to the mean level of the flux .",
    "this is because there are very many of them within each beam and the change of their number from beam to beam is relatively small and so does not contribute to the fluctuations .",
    "the very strong sources contribute only to the tail of the distribution .",
    "typically the flux where there is one source per beam is much lower then the resolution limit .",
    "since this work is motivated by the firback survey we will give in the following a short description of the survey and of the @xmath11 found for the resolved sources .",
    "these details will guide us when we construct simulations to check our method of deriving @xmath11 from the observed p(d ) .",
    "the firback @xcite is a deep survey of 4 square degrees of the sky at 170@xmath6 m .",
    "the 4 degrees were chosen in such a way that the foreground cirrus contamination was as small as possible .",
    "thus one can get information on the extra - galactic radiation . in the firback survey",
    "there were 106 sources detected above the sensitivity limit of the experiment at 4@xmath14 , with fluxes between 180 mjy to 2400 mjy .",
    "the slope of the logn - logs curve was measured by @xcite to be @xmath15 between 180 and 500 mjy .      in view of the above",
    "we will assume a broken power law for the source - count model : the slope at low fluxes has to become shallower than 3.0 or the flux per pixel will diverge .",
    "another motivation for this two slope model is the predictions coming from galaxy evolution models discussed earlier . in all of the predictions",
    "the number counts exhibit a relative flattening at low fluxes .",
    "therefore we write @xmath16 as follows :    @xmath17    the parameters to be determined are the normalization , @xmath18 , the flux of the break in the power - law , @xmath19 , and the two slopes , @xmath20 and @xmath21 .",
    "since @xmath22 does not change the shape of the distribution and only affects the mean flux , and since we will be fitting for the shape of the distribution and not for the mean flux , @xmath22 becomes irrelevant to the fitting process .",
    "it comes into play only in order to fine tune the mean flux to its value from data . in the following",
    "we will refer to the four parameters commonly as @xmath23 , and the probability distribution of the deflection will be written as p(d;@xmath23 ) .",
    "our data set is composed of several thousand measurements of incoming flux received by 46@xmath2546 arcsec@xmath4 pixels which are pointed to different directions in the sky .",
    "we will bin the data according to flux . in this way we can compare the experimental distribution of the fluctuations to a calculated p(d;@xmath23 ) .",
    "binning data may proceed in two ways .",
    "one way is such that the bins are equal in length and the number of events vary from bin to bin . or one may bin the data such that there is the same number of events in each of the bins and the size of the bins changes accordingly .",
    "we use the former method but we manually increase the bin size at the two tails of the distribution where there are very few events , so as not to have bins with zero events .",
    "we have thus 3 bins where there are around 5 events per bin , out of a total of  60 bins .",
    "a histogram is in fact a multinomial distribution .",
    "this is the generalization of the binomial distribution to the case where it is possible to have more then two outcomes for the experiment . in our case",
    "the flux received by a pixel pointing in one of the directions in the sky will be one result of the experiment , and the outcome might fall in any one of the bins .",
    "let s call @xmath26 the @xmath27 possibilities for the outcome of the experiment ( in our case @xmath27 different flux ranges from the minimal to the maximal flux received in the map ) , and let @xmath28 be the probability for a pixel to fall in bin @xmath29 .",
    "the sum of all these probabilities is of course 1 since every pixel falls in one of the bins .",
    "we assume that the different pixels are independent ( we will justify this assumption in section 5.2 ) .",
    "then , after n experiments of measuring the incoming flux ( n pixels in the map ) , the probability that the fluxes will distribute with @xmath30 pixels falling in the bins will be given by @xmath31 some important properties of this distribution are that @xmath32 , the expectation value for the bin i , is given by @xmath33 and @xmath34 , the variance for bin i is given by @xmath35 .",
    "when the number of experiments becomes large the multinomial distribution tends to the multi - normal distribution . in the case",
    "when there are many bins and @xmath36 , the variance tends to be the expectation value .",
    "thus when we bin the fluxes we must take care to have enough bins such that on the one hand @xmath36 and on the other , there are enough pixels per bin so that the distribution of the number of pixels per bin will be close to gaussian",
    ". then the overall likelihood of the data can be written as follows : @xmath37 where @xmath38 , the quadratic form , is @xmath39 @xmath40 are the elements of the inverse covariance matrix c , given by @xmath41\\ ] ] @xmath42 is the number of pixels within flux bin i , @xmath43 is the expected number of pixels in the bin according to the model , and @xmath44 is the square root of the variance , in our case it is @xmath45 .",
    "the correlation @xmath46 between bins i , j is given by @xmath47 if we assume that there are no or only negligible correlations between the errors in the bins then the covariance matrix will be almost diagonal .",
    "therefore the quantity we need to minimize becomes @xmath48 this method is the `` minimum chi - square method '' applied to histogram fits . when there are many events in each bin then @xmath38 has asymptotically a @xmath24 distribution with [ n-(number of fitted parameters ) ] degrees of freedom and the method is equivalent to a maximum likelihood estimation method .",
    "therefore from now on we will use the notation @xmath49 .",
    "we are assuming that our way of binning allows @xmath38 to behave close enough to @xmath24 .",
    "as described before , we have several thousand measurements of the flux s , and a model for n(s ) which leads to a p(d , @xmath23 ) and we estimate the parameters @xmath23 using maximum likelihood method with the binned data . there is a lower bound to the variance of an estimator , which is related to the fisher matrix , @xmath50 @xmath51\\ ] ] the rao - cramer - frechet inequality states that for any unbiased estimator , @xmath52 where @xmath53 is the 1@xmath14 error of the parameter @xmath54 .",
    "this inequality was used by several authors ( * ? ? ?",
    "* ; * ? ? ?",
    "* ; * ? ? ?",
    "* e.g. ) to assess how well may different parameters be estimated in future experiments .    in our case , where the the likelihood is multinormal , and the errors depend on the parameters , the fisher matrix becomes @xcite : f_ij=_k=1^n_bins|__ml [ fm ] as we can see",
    ", the fisher matrix depends solely on the model and on the estimated parameters , @xmath55 .",
    "we can now calculate the minimal variance for different experimental setups , namely as a function of the number of pixels in the maps , or as a function of the size of the pixel . in this way",
    "we can foresee how well we could extract the 4 parameters from future experiments .",
    "the inverse of the fisher matrix is an estimate of the covariance matrix , so by investigating f@xmath56 one can locate degeneracies between parameters and see if they might be resolved in different experimental setups .",
    "in this section we describe the analysis of simulated skies that we have made in order to check theoretically the limits of our method using the fisher matrix analysis .",
    "we use mock images to check our algorithm .",
    "these images are built in two steps .",
    "first we build a mock sky .",
    "this is a high resolution projected image of a given spatial distribution of sources .",
    "it is constructed by distributing point sources randomly on a @xmath57 square degree field .",
    "each source is assigned a flux such that the overall number counts are consistent with our predetermined two - slope n(s ) .",
    "we chose to model n(s ) such that the main traits of the firback maps are realized , such as the number of sources above 180mjy and the mean level of the background .",
    "then we convolve it with the instrumental effects in order to produce an image as close as possible to real data .",
    "finally we extract only the central 1 square degree as our map .",
    "a map produced this way is presented in figure [ map ] ( a ) , and its histogram is shown in [ map](b ) .",
    "the map includes some @xmath58 sources with fluxes ranging from 0.01 to 2000 mjy , and the parameters chosen were @xmath59 , @xmath60 and @xmath61mjy and the normalization was 0.18*@xmath62 .",
    "@xmath63{marveloustest.ps } & \\includegraphics[width=7cm]{histo9_4.ps } \\\\ % [ 0.50 cm ] \\end{array}$ ]",
    "the total extent of the psf of the firback instrument and of the upcoming sirtf is bigger then the size of a pixel in these experiments . in firback the full width at half maximum of",
    "the psf is equal to the pixel size . for sirtf",
    "it is twice as wide @xcite . in such cases",
    "we expect there to be some correlation between adjacent pixels on the map . given this , we want to quantify to what extent these correlations may be manifested as correlations between the different bins in the histogram .    to this end",
    "we should measure the correlation coefficients of the histogram given different sized psfs .",
    "the different psfs we used were constructed from the original one by rebinning again and again .",
    "we quantify their extent with respect to the pixel size by defining variable x which is the ratio of the fwhm to the pixel size .",
    "the x we used are 2.7 , 1.1 , 0.5 , 0.3 and 0.1 . following this we produced hundreds of sky maps based on the same underlying n(s ) relation .",
    "we convolved each with a fsf , produced a histogram , and measured the sample correlation matrix .",
    "the process was repeated for the different psfs , and was done once without convolving with any psf but instead we rebinned the sky to the size of the pixel , 46@xmath25 46  .",
    "if bins were not correlated at all , the correlation matrix would have been the identity matrix .",
    "we found that there is a negligible level of correlations with any of the psfs , mostly less than 10@xmath7 .",
    "the largest correlation seen was between few neighboring bins for the largest psf , near the center of the histogram , at a level of  20@xmath7 .",
    "there is also no clear behavior of @xmath64 as a function of the total coverage area of the psf .",
    "this can be seen in figure @xmath65 , where 3 randomly selected elements of the correlation matrix are plotted as a function of the total coverage area of the psf .        in light of this",
    "we will neglect the correlations between the bins and estimate the parameters as described in the next section .      in order to find estimates for the 4 parameters",
    "@xmath66 , we first choose a small enough value for @xmath22 .",
    "on the one hand it should be smaller then reasonable values of @xmath19 , and on the other hand it should be big enough to avoid numerical problems of integration .",
    "we then grid a large enough part of parameter space around a reasonable point found by trial and error .",
    "each of these grid points will serve as a starting point for the minimization procedure . this way we have more chance of catching the lowest minimum .",
    "the minimization procedure calculates the @xmath24 and uses the derivatives of the model to go downhill in parameter space until a lowest local @xmath24 is found .",
    "we looked at the estimated parameters and their errors to see whether they are all situated in the same part of the parameter space .",
    "we repeated the procedure with several different binning to make sure that the results are not dependent on the binning .",
    "the best fit is shown in figure [ mapandfit ] .",
    "the reduced @xmath24 for this model is 0.96 .",
    "the errors of the estimated parameters will be discussed below .",
    "once we have a best fit set of parameters , we assume that it is a good enough approximation of the real parameters",
    ". then we can continue to calculate the fisher matrix elements for different experimental parameters .",
    "we will calculate the minimal errors of the different parameters as a function of pixel size and as a function of the number of pixels in the map .        in fig .",
    "[ mapsize]a one sees how the errors reduce when we add more pixels to the map .",
    "in fact they reduce as ( number of pixels)@xmath56 - and this behavior is what we expect from the definition of the fisher matrix , equation [ fm ] .",
    "@xmath67{all_errors_vs_map_size_17_9.ps } & \\includegraphics[width=7cm]{all_errors_vs_pix_size_17_9.ps } \\\\ % [ 0.50 cm ] \\mbox{(a ) } & \\mbox{(b ) } \\end{array}$ ]    in fig .",
    "[ mapsize]b one sees that the errors greatly reduce once we use smaller pixel sizes in the experiment , with all errors at the level of only few percent once we reach pixel size of 15 arcsec@xmath4 .",
    "this is very encouraging because in the upcoming sirtf experiment the pixels will be of size @xmath68 arcsec@xmath4 .",
    "another point to look at is the comparison between the errors on the estimated parameters in our algorithm , and the minimal errors given from the fisher matrix analysis . to this end we plotted , on both [ mapsize]a and [ mapsize]b a vertical line indicating the properties of the firback and our simulations .",
    "on top of this line we put the parameter errors we got from the minimization procedure .",
    "it is encouraging to see that these errors are only very slightly larger than the minimal errors possible according to the cramer - rao - frechet lower bound .    another way to see",
    "the great improvement in the precision of the estimation is when one looks at the 1@xmath14 contours which enclose 68@xmath7 of the joint distribution of several pairs of estimators while we marginalize over the other two parameters , as in fig .",
    "[ ellipses ] .",
    "the contours , independent of which plane we look at , encompass a shrinking patch of the parameter space as we add pixels to the map or use smaller pixels .",
    "we have plotted the original parameters as filled hexagons on top of the ellioses .",
    "it is important to note , also , that except for the normalization , the true parameters of the simulation are enclosed within the 1@xmath14 contours of the original experiment .",
    "figure [ ellipses ] also shows us that there are degeneracies between the different parameters .",
    "these degeneracies are not broken when we use a more accurate experiment , they are `` built in '' through the definition of the model n(s ) .",
    "for example , as the model is defined , the normalization is the number of sources with fluxes greater than 1mjy .",
    "naturally , if we increase @xmath20 we should increase the normalization in order to remain within the error bars for n(s ) .",
    "@xmath69{ellipse_norm_g1_18_9.ps } & \\includegraphics[width=5.0cm]{ellipse_sb_g2_18_9.ps } & \\includegraphics[width=5.0cm]{ellipse_sb_g1_18_9.ps } \\\\ % [ 0.50 cm ] \\mbox{(a ) } & \\mbox{(b ) } & \\mbox{(c ) } \\end{array}$ ]    in the following we will look further into the degeneracies by looking at the derivatives of the model with respect to the parameters we are interested in @xcite .",
    "the reason for this can be seen if we look again at the expression for the elements of the fisher matrix ( eq.[fm ] ) : they have the structure of a dot product between vectors @xmath70 and @xmath71 .",
    "if one of these vectors is a linear combination of another , the fisher matrix elements will be singular , and the errors of the estimated parameters will be infinite",
    ". if the vectors are completely orthogonal then f and f@xmath56 will be diagonal and thus there will be no correlation between different parameters and their errors .",
    "usually there will be some level of correlation which will be manifested by a somewhat similar shape between the functional shape of the different derivatives . by looking at the functional shape of the derivatives one may recognize such degeneracies .",
    "the way to avoid any degeneracies between parameters will be to diagonalize the fisher matrix , thus changing the parameters into new ones which are linear combinations of the originals .",
    "these parameters , however , are not always physical , and thus do not have much meaning unless they are very similar to the old ones , with not much ` contamination ' from other parameters .    it is worthwhile to check whether under improved experimental conditions these degeneracies , if they exist , are removed or not . in fig [ degen ]",
    "we plot the derivatives with respect to the usual 4 parameters and the derivatives with respect to the new , `` diagonalised '' parameters ( called principal components - pc1 - 4 ) . on the left panel we have the case for a pixel of 20 * 20 arcsec@xmath4 , and on the right , 46 * 46 arcsec@xmath4 .",
    "again we can see that the degeneracies are not removed by improving the experiment . only diagonalizing the fisher matrix",
    "allows us to remove them .",
    "@xmath72{n_ders_20_together.ps }   & \\includegraphics[width=7cm]{n_ders_46_together.ps } \\\\ % [ 0.50 cm ] \\includegraphics[width=7cm]{n_pc_ders_20.ps }   & \\includegraphics[width=7cm]{n_pc_ders_46.ps } \\\\ % [ 0.50 cm ] \\mbox{(a ) } & \\mbox{(b ) } \\end{array}$ ]    we also add a table which specifies how the new parameters are built from the old ones . in the first row",
    "we have the 4 parameters and in the first column we have the 4 principal components . in each of the 4 rows we have the coefficients of the linear combination .",
    "the strongest coefficients are marked in bold .",
    "@xmath73 pc1 has the highest weight from @xmath20 with some contribution from @xmath74 and @xmath21 .",
    "pc2 has the highest contribution from @xmath74 and some contribution from @xmath20 .",
    "pc3 is mostly @xmath21 and some @xmath20 , and pc4 is almost exclusively @xmath19 .",
    "the degeneracies are to be expected since as mentioned before , p(d ) analysis can not give information at fluxes much below the one source per beam flux level . in our simulation",
    "this level is of the order of 7mjy and therefore it is reasonable that for example @xmath21 , which is the slope of the counts below a few mjy is degenerate with the other parameters .",
    "in this work we have explored the extent to which one can use a p(d ) analysis to gather information from far infra red sky maps .",
    "these maps are characterized by a very high level of confusion noise which arises due to the relatively poor resolution power available at these wavelengths .",
    "we created a simulated map of the sky with an underlying modeled n(s ) .",
    "the model consisted of a two slope model with a high flux slope greater than 3 and a shallower low - flux slope .",
    "it was chosen this way following the finding of a steep slope of the number counts of resolved objects in the firback maps and in agreement with predictions of galaxy evolution models .",
    "the parameters of the model are the two slopes , the break flux ( where the slope changes ) and the normalization .",
    "we then created the histogram of the simulated map and used it to find the best fit parameters of the n(s ) model and their errors . after finding the best fitted parameters",
    ", we used the fisher matrix analysis to calculate the minimal errors possible of these parameters in experiments with different pixel sizes and in experiments with different total number of pixels , including those of the firback .",
    "we found that our algorithm gives fitted parameters with almost the minimal errors possible theoretically .",
    "the underlying parameters of the simulated map were within 1@xmath14 of the best fitted ones ( except for the normalization ) .",
    "this means that the tool we have constructed in order to find number counts is quite reliable .",
    "the fisher matrix analysis shows that in an experiment with pixel size of the order  10 arcsec we will be able to find all parameters with errors of only about a few percent .",
    "the situation of the firback experiment is quite different : it is only the high flux slope which can be found with a small error bar of @xmath754@xmath7 .",
    "this is somewhat better than what was found by individual source extraction from the maps ( error of @xmath7520@xmath7 ) .    the advantage of the p(d )",
    "analysis that it is sensitive down to the flux for which there is one source per beam - in the firback case this is around few mjy , much below the detection limit which is 180mjy .",
    "also , the extraction of even the high flux slope is straightforward and does not warrant an a - priory extraction of sources or other manipulation of the maps .    in order to be able to extract the other parameters of the number counts",
    ", we will have to wait for the sirtf experiment . in that experiment ,",
    "the pixel size is 16*16  and the number of different points measured on the sky is up an order of magnitude larger then for firback . in this case",
    "the precision of estimation is enhanced due to both factors : smaller pixels and more of them .",
    "we would like to thank jeremy blaizot for coding the instrumental effects of isophot and for many discussions . y.f",
    "thanks michel fioc , stephane colombi , bruno guiderdoni , guilaine lagache , herve dole , ofer lahav , roberto trotta , jean - pierre eckmann , andreas malaspinas , tsvi piran , avishai dekel and yehuda hoffman for helpfull discussions .",
    "y.f was funded by a chateaubriand fellowship , a marie curie grant and a marie heim - voegtlin grant .",
    "the shape of the curve describing the probability that a pixel will accumulate a certain level of flux depends on a few factors .",
    "these are the point spread function of the telescope , the pixel size and shape , and the source number counts n(s ) .",
    "we are assuming some properties for the sources which make up the background : that the sources are point - like , they are not clustered , and once a source is `` found '' its flux is a random variable distributed according to the number - count - flux relation , @xmath76 .",
    "@xmath79 is the solid angle in direction @xmath77 .",
    "g@xmath80 is the beam profile - it is the convolution of the point spread function of the imaging instrument and the pixel profile .",
    "@xmath81 is the flux per unit solid angle coming from direction @xmath77 .",
    "now we can calculate the probability density of @xmath82 ( the probability that a certain pixel will receive flux @xmath82 ) . in order to do",
    "that one first calculates the characteristic function of @xmath82 which is given by @xmath83      say there are k sources .",
    "then the total flux received by a pixel should be written as the following discrete sum : @xmath85 the probability of finding k sources in the sky , with fluxes @xmath86 and in directions @xmath87, ... @xmath88 , is @xmath89 @xmath6 is the mean number of sources per unit solid angle , and @xmath90 is the probability that a source has a flux in the range @xmath91 $ ] .",
    "this is a product of the poissonian probability to find k sources while the mean number of sources is expected to be @xmath6 and the probability to find a source with flux @xmath92 given the model n(s ) , all this per steradian ( hence the term @xmath93 .",
    "the normalization condition is that the sum of the probabilities to find any number of sources in any direction is one : @xmath94 using the normalization condition and the form of @xmath82 we may now calculate the characteristic function , which becomes : @xmath10\\ ] ] @xmath12 is the pixelized psf and @xmath13 is the area of the pixel in steradians .",
    "the integration over the angles is separate from that over flux and gives @xmath13 .",
    "this is justified in our case because although the psf is quite extended , outside of the pixel it has very small values .",
    "so now we may write the expression for the p(@xmath82 ) , as the fourier transform of the characteristic function :      the above expression gives the probability that a pixel will receive an amount of flux equal to @xmath82 .",
    "we will be working with a slightly different expression - the probability to get a certain flux above or below the mean flux on the map , @xmath96 , defined as @xmath97                          , h. , gispert , r. , lagache , g. , puget , j .- l .",
    ", bouchet , f.  r. , cesarsky , c. , ciliegi , p. , clements , d.  l. , dennefeld , m. , d ' esert , f .- x .",
    ", elbaz , d. , franceschini , a. , guiderdoni , b. , harwit , m. , lemke , d. , moorwood , a.  f.  m. , oliver , s. , reach , w.  t. , rowan - robinson , m. , & stickel , m. ( 2001 ) . . ,",
    "* 372 * , 364376 .                    , g. , puget , j. , abergel , a. , desert , f. , dole , h. , bouchet , f.  r. , boulanger , f. , ciliegi , p. , clements , d.  l. , cesarsky , c. , elbaz , d. , franceschini , a. , gispert , r. , guiderdoni , b. , haffner , l.  m. , harwit , m. , laureijs , r. , lemke , d. , moorwood , a.  f.  m. , oliver , s. , reach , w.  t. , reynolds , r.  j. , rowan - robinson , m. , stickel , m. , & tufte , s.  l. ( 2000 ) .",
    ". in _ iso survey of a dusty universe , proceedings of a ringberg workshop held at ringberg castle , tegernsee , germany , 8 - 12",
    "november 1999 , edited by d. lemke , m. stickel , and k. wilke , lecture notes in physics , vol .",
    "548 , p.81 _ , pages 81+ .",
    ", j.  l. , lagache , g. , clements , d.  l. , reach , w.  t. , aussel , h. , bouchet , f.  r. , cesarsky , c. , d ' esert , f.  x. , dole , h. , elbaz , d. , franceschini , a. , guiderdoni , b. , & moorwood , a.  f.  m. ( 1999 ) . . ,",
    "* 345 * , 2935 ."
  ],
  "abstract_text": [
    "<S> we are investigating to what extent one can use a p(d ) analysis to extract number counts of unclustered sources from maps of the far infrared background . </S>",
    "<S> currently available such maps , and those expected to emerge in near future are dominated by confusion noise due to poor resolution . </S>",
    "<S> we simulate background maps with an underlying two slope model for n(s ) and we find that in an experiment of firback type we can extract the high flux slope with an error of few percent while other parameters are not so well constrained . </S>",
    "<S> we find , however , that in a sirtf type experiment all parameters of this n(s ) model can be extracted with errors of only few percent .    </S>",
    "<S> * fluctuation analysis of the far - infrared background - *    0.2 cm    * information from the confusion *    0.5 cm    yasmin friedmann@xmath0 and fran@xmath1ois bouchet@xmath2    0.4 cm    @xmath3 racah institute , the hebrew university , jerusalem , 91904 , israel    0.1 cm    @xmath4departement de physique theorique , university of geneva    0.1 cm    24 , quai e. ansermet , 1211 geneve 4 , switzerland    0.1 cm    @xmath5 iap , 98bis , bd arago 75014 paris , france    1.5 cm </S>"
  ]
}