{
  "article_text": [
    "the goal of this article is to study weak convergence results for the tail empirical process associated with some long memory sequences . besides of theoretical interests on its own ,",
    "the results are applicable in different statistical procedures based on several extremes .",
    "a similar problem was studied in case of independent , identically distributed random variables in @xcite , or for weakly dependent sequences in @xcite , @xcite , @xcite , @xcite .",
    "our set - up is as follows .",
    "assume that @xmath0 , is a stationary gaussian process with unit variance and covariance @xmath1 where @xmath2 is the hurst exponent and @xmath3 is a slowly varying function at infinity , i.e. @xmath4 for all @xmath5 .",
    "the sequence in this case is referred to as an _ lrd _ gaussian sequence .",
    "we also consider weakly dependent gaussian sequences , i.e. such that @xmath6 .",
    "we shall consider a stochastic volatility process defined as @xmath7 where @xmath8 is a nonnegative , deterministic function and that @xmath9 , @xmath10 , is a sequence of i.i.d .",
    "random variables , independent of the process @xmath11 .",
    "we note , in particular , that if @xmath12<\\infty$ ] and @xmath13=0 $ ] , then the @xmath14s are uncorrelated , no matter the assumptions on dependence structure of the underlying gaussian sequence .",
    "stochastic volatility models have become popular in financial time series modeling .",
    "in particular , if @xmath2 , these models are believed to capture two standardized features of financial data : long memory of squares or absolute values , and conditional heteroscedascity . if @xmath15 , then the model is referred to in the econometrics literature as _ long memory in stochastic volatility _",
    "( lmsv ) and was introduced in @xcite . for an overview of stochastic volatility models with long memory",
    "we refer to @xcite .",
    "let @xmath16 , @xmath17 , be the marginal distribution of @xmath14 .",
    "we want to consider the case where @xmath18 belongs to the domain of attraction of an extreme value distribution with positive index @xmath19 , i.e. there exist sequences @xmath20 , @xmath21 , @xmath22 , and @xmath23 , @xmath21 , such that the associated conditional tail distribution function @xmath24 satisfies @xmath25 for the stochastic volatility model , this will be obtained through a further specification .",
    "let @xmath26 be the marginal distribution of the noise sequence .",
    "we will assume that for some @xmath27 , @xmath28 where @xmath29 is again a slowly varying function .",
    "assuming ( [ eq : pareto - assumption ] ) and @xmath30<\\infty$ ] for some @xmath31 , we conclude by breiman s lemma @xcite ( see also ( * ? ? ?",
    "* proposition 7.5 ) ) that @xmath32 { { \\mathbb p}}(z_1>x ) \\ ; , \\",
    "\\mbox { as } x\\to\\infty.\\ ] ] consequently , @xmath33 satisfies ( [ eq : cond - tail ] ) with @xmath34 and @xmath35 .",
    "similarly to @xcite , we define the tail empirical distribution function and the tail empirical process , respectively , as @xmath36 and @xmath37 from @xcite we conclude that under appropriate mixing and other conditions on a stationary sequence @xmath14 , @xmath17 , the tail empirical process converges weakly and the limiting covariance is affected by dependence . in our case ,",
    "the results @xcite do not seem applicable .",
    "in fact , it will be shown that we have two different modes of convergence . if @xmath20 is _ large _ , then @xmath38 is the proper scaling factor and the limiting process is gaussian with the same covariance structure as in case of i.i.d .",
    "random variables @xmath14 .",
    "otherwise , if @xmath20 is _ small _ , then the limit is affected by long memory of the gaussian sequence . the scaling is different and the limit may be non - normal . these results are presented in section [ sec : general ] .",
    "note that a similar dichotomous phenomenon was observed in the context of sums of extreme values associated with long memory moving averages , see @xcite for more details . on the other hand ,",
    "this dichotomous behaviour is in contrast with the convergence of point processes based on stochastic volatility models with regularly varying innovations , where ( long range ) dependence does not affect the limit ( see @xcite ) .",
    "the process @xmath39 is unobservable in practice , since the parameter @xmath20 depends on the unknown distribution @xmath18 .",
    "also , @xmath20 being _ large _ or _ small _ depends on a delicate balance between the tail index @xmath40 and the hurst parameter @xmath41 . in order to overcome this",
    ", we consider as in @xcite a process with random levels .",
    "there , we set @xmath42 and replace the deterministic level @xmath20 by @xmath43 , where @xmath44 are the increasing order statistics of the sample @xmath45 .",
    "the number @xmath46 can be thought as the number of extremes used in a construction of the tail empirical process .",
    "it turns out that if the number of extremes is _ small _ ( which corresponds to a _ large _",
    "@xmath20 above ) , then the limiting process changes as compared to the one associated with @xmath39 , but the speed of convergence remains the same .",
    "this has been already noticed in @xcite in the weakly dependent case . on the other hand , if @xmath46 is _ large _ , then the scaling from @xmath39 is no longer correct ( see corollary [ cor : practical ] ) .",
    "in fact , the process with random levels has a faster rate of convergence and we claim in theorem [ thm : practical-1 ] that the rate of convergence and the limiting process are not affected at all by long memory , provided that a technical second order regular variation condition is fulfilled .",
    "the reader is referred to section [ sec : random - levels ] . on the other hand , it should be pointed out that our results are for _ the _ long memory stochastic volatility models .",
    "it is not clear for us whether such phenomena will be valid for example for subordinated long memory gaussian sequences with infinite variance .    the results for",
    "the tail empirical process @xmath39 allow us to obtain asymptotic normality and non - normality of intermediate quantiles , as described in corollary [ coro : intermediate ] .",
    "on the other hand , the tail empirical process with random levels allows the study of the hill estimator of the tail index @xmath40 ( section [ sec : hill ] ) .",
    "consequently , as shown in corollary [ cor : hill ] , long memory does not have influence on its asymptotic behaviour .",
    "these theoretical observations are justified by simulations in section [ sec : numstudies ] .",
    "last but not least , we have some contribution to the theory of regular variation . to establish our results in the random level case , we need to work under a second order regular variation condition .",
    "consequently , one has to establish in a breimans - type lemma that such a condition is transferable from @xmath47 to @xmath48 .",
    "this is done in section [ sec : s - o - c ] .",
    "let us define a function @xmath49 on @xmath50 by @xmath51 by breiman s lemma and the regular variation of @xmath47 , we conclude that for each @xmath52 $ ] , this function converges pointwise to @xmath53 , where @xmath54 .",
    "a stronger convergence can actually be proved ( see section [ sec : proof - s - o - c ] for a proof ) .",
    "[ lem : convergence - uniforme - hermite ] if  ( [ eq : pareto - assumption ] ) holds and @xmath55<\\infty$ ] for some @xmath31 , then @xmath56 = 0 \\ ;    \\end{aligned}\\ ] ] for all @xmath57 such that @xmath58 .    in order to introduce our assumptions , we need to define the hermite rank of a function .",
    "recall that the hermite polynomials @xmath59 , @xmath60 , form an orthonormal basis of the set of functions @xmath61 such that @xmath62<\\infty$ ] , where @xmath63 denotes a generic standard gaussian random variable ( independent of all other random variables considered here ) , and have the following properties : @xmath64 = 0 \\ ; , \\ m\\geq 1 \\ ; , \\ { { \\mathrm { cov}}}(h_j(x),h_k(x ) ) =    \\delta_{j , k } k ! \\;\\end{aligned}\\ ] ] where @xmath65 is kronecker s delta , equal to 1 if @xmath66 and zero otherwise .",
    "then @xmath61 can be expanded as @xmath67 with @xmath68 $ ] and the series is convergent in the mean square .",
    "the smallest index @xmath69 such that @xmath70 is called the hermite rank of @xmath61 . note that with this definition , the hermite rank is always at least equal to one and the hermite rank of a function @xmath61 is the same as that of @xmath71 $ ] .",
    "let @xmath72 denote the hermite coefficients of the function @xmath73 .",
    "since @xmath74<\\infty$ ] for all @xmath75 , lemma  [ lem : convergence - uniforme - hermite ] implies that the hermite coefficients @xmath72 converge to @xmath76 , where @xmath77 is the @xmath78-th hermite coefficient of @xmath79 , uniformly with respect to @xmath80 .",
    "this implies that for large @xmath81 , the hermite rank of @xmath82 is not bigger than the hermite rank of @xmath79 . in order to simplify the proof of our results",
    ", we will use the following assumption , which is not very restrictive .",
    "[ [ assumption - h ] ] assumption ( h ) + + + + + + + + + + + + + +    denote by @xmath83 , @xmath84 , the hermite coefficients of @xmath82 and let @xmath85 be the hermite rank of @xmath82 .",
    "define @xmath86 the hermite rank of the class of functions @xmath87 .",
    "in other words , the number @xmath88 is the smallest @xmath78 such that @xmath89 for at least one @xmath90 .",
    "furthermore , let @xmath91 be the hermite rank of @xmath79 .",
    "we assume that @xmath92 for @xmath81 large enough .    _",
    "remark_.  since for large enough @xmath81 it holds that @xmath93 for all @xmath90 , the assumption is fulfilled , for example , when @xmath79 has hermite rank 1 ( as is the case for the function @xmath94 ) , or if the function @xmath95 is even with the hermite rank  2 .",
    "the result for the general tail empirical process is as follows .",
    "[ thm : general ] assume ( h ) with @xmath96 ,  ( [ eq : lrd ] ) , ( [ eq : pareto - assumption ] ) , @xmath97 and that there exists @xmath31 such that @xmath98<\\infty \\ ; .",
    "\\end{aligned}\\ ] ]    a.   [ item : big - u ] if @xmath99 as @xmath100 or if @xmath101 is weakly dependent , then @xmath102 converges weakly in @xmath103 to the gaussian process @xmath104 , where @xmath105 is the standard brownian motion . b.   [ item : small - u ] if @xmath106 as @xmath100 then @xmath107 converges weakly in @xmath103 to the process @xmath108)^{-1 } j(q ) t l_q$ ] , where the random variable @xmath109 is defined in  ( [ eq : def - l_q ] ) .      1 .",
    "we rule out the borderline case @xmath110 for the sake of brevity and simplicity of exposition .",
    "it can be easily shown that if @xmath110 , then @xmath111 converges to @xmath112 provided @xmath113 tends to infinity faster than a certain slowly varying function ( e.g. if @xmath114 for some @xmath115 ) , even though it may hold in this case that @xmath116 .",
    "the reason is that the variance of the partial sums of @xmath117 is of order @xmath81 times a slowly varying function which dominates @xmath118 .",
    "@xmath119 is endowed with skorohod s @xmath120 topology , and tightness is checked by applying ( * ? ? ?",
    "* theorem 15.6 ) .",
    "since the limiting processes have almost surely continuous paths , this convergence implies uniform convergence on compact sets of @xmath121 .",
    "see also @xcite .",
    "the meaning of the above result is that for @xmath20 _ large _ , long memory does not play any role .",
    "however , if @xmath20 is _ small _ , long memory comes into play and the limit is degenerate .",
    "furthermore , in the case of theorem [ thm : general ] , _ small _ and _ large _ depend on the relative behaviour of the tail of @xmath122 and the memory parameter .",
    "note that the condition @xmath123 implies that @xmath124 , in which case the partial sums of the subordinate process @xmath125 weakly converge to the hermite process of order @xmath91 ( see section  [ sec : lrd - gaussian ] ) .",
    "the cases ( [ item : big - u ] ) and ( [ item : small - u ] ) will be referred to as the limits _ in the i.i.d .",
    "zone _ and _ in the lrd zone _ , respectively .",
    "condition @xmath30<\\infty$ ] is standard when one deals with regularly varying tails .",
    "however , we need the condition @xmath126<\\infty$ ] in order to obtain the limiting distributions in the i.i.d . and lrd zones .",
    "see section  [ sec : fidi ] .",
    "the result should be extendable to general , not necessary gaussian , long memory linear sequences .",
    "instead of the limit theorems and covariance bounds of section [ sec : lrd - gaussian ] , one can use limit theorems from @xcite , and the covariance bounds of ( * ? ? ?",
    "* lemma 3 ) . 6 .",
    "rootzen @xcite obtained asymptotic the behaviour of the tail empirical process of a general stationary sequence @xmath127 under , in particular , the following conditions ( see ( * ? ? ?",
    "* section 4 ) ) : * @xmath128 , @xmath129 ; * @xmath130\\le \\infty$ ] , where @xmath131 and @xmath132 is the point process of exceedances ; * @xmath133 , where @xmath134 is the @xmath135-mixing coefficient w.r.t .",
    "sigma field generated by the random variables @xmath136 ; * @xmath137 for some function @xmath138 .",
    "+ assume that @xmath139 , @xmath129 .",
    "for the sequence @xmath140 under consideration here , it can be computed ( see section [ sec : heuristic ] ) @xmath141q!(1 - 2q(1-h ) ) } \\ ; . \\ ] ] now , using ( [ eq : lrd ] ) , @xmath142 . since @xmath129",
    ", then the second part converges 0 under the condition @xmath143 .",
    "consequently , case ( [ item : big - u ] ) guarantees that the condition ( c3 ) is fulfilled . as for the mixing property ( c2 ) ,",
    "it is usually established by proving the standard @xmath135-mixing , i.e. the one defined in terms of random variables @xmath144 , not @xmath145 .",
    "now , if @xmath101 is @xmath135-mixing ( in the latter sense ) with rate @xmath146 , then the same holds for @xmath140 . in our case",
    ", the sequence @xmath101 has long memory , and thus it can not be @xmath135-mixing .",
    "therefore , it is very doubtful that ( c2 ) can be verified .",
    "+ note also that in the case latexmath:[$\\sum_{j=1}^\\infty    memory case , the conclusion of part   of theorem holds without any additional ( mixing ) assumption on the gaussian process @xmath101 .",
    "+ moreover , results in the lrd zone can not be obtain by applying rootzen s or any other results for weakly dependent sequences .",
    "similarly to @xcite , we consider the case of random levels .",
    "let @xmath148 denote weak convergence in @xmath103 .",
    "define the increasing function @xmath149 on @xmath150 by @xmath151 , where @xmath152 is the left - continuous inverse of @xmath18 .",
    "let @xmath46 denote a sequence of integers depending on @xmath81 , where the dependence in @xmath81 is omitted from the notation as customary , and such that @xmath153 such a sequence is usually called an intermediate sequence .",
    "define @xmath154 .",
    "if @xmath18 is continuous , then @xmath155 , otherwise , since @xmath156 is regularly varying , it holds that @xmath157 .",
    "thus , we will assume without loss of generality that @xmath42 holds .",
    "then the statements of theorem [ thm : general ] may be written respectively as @xmath158 } \\ ; t \\cdot l_q \\ ; .",
    "\\label{eq : lrd - zone - k}\\end{gathered}\\ ] ] let us rewrite the statements of ( [ eq : iid - zone - k ] ) , ( [ eq : lrd - zone - k ] ) as @xmath159 where @xmath160 and @xmath161 if  ( [ eq : small - k ] ) holds ( i.i.d .",
    "zone ) and @xmath162)^{-1 } j(q ) t l_q$ ] if  ( [ eq : big - k ] ) holds ( lrd zone ) .",
    "we now want to center the tail empirical process at @xmath163 instead of @xmath164 .",
    "to this aim , we introduce an unprimitive second order condition .",
    "@xmath165 where @xmath166 the following result is a straightforward corollary of theorem  [ thm : general ] .",
    "[ coro : centre ] under the assumptions of theorem  [ thm : general ] , if moreover  ( [ eq : second - ordre - unprimitive ] ) holds , then @xmath167 converges weakly in @xmath103 to the process @xmath168 .",
    "let @xmath169 be the increasing order statistics of @xmath170 .",
    "the former result and verwaat s lemma ( * ? ? ?",
    "* proposition 3.3 ) yield the convergence of the intermediate quantiles .",
    "[ coro : intermediate ] under the assumptions of corollary  [ coro : centre ] , @xmath171 converges weakly to @xmath172 .",
    "define @xmath173 in this section we consider the _ practical _ process @xmath174 for the process @xmath175 , the previous results yield the following corollary .",
    "[ cor : practical ] assume ( h ) , ( [ eq : lrd ] ) , ( [ eq : pareto - assumption ] ) , ( [ eq : moment-2alpha+epsilon ] ) and ( [ eq : second - ordre - unprimitive ] ) .",
    "then @xmath176 converges weakly in @xmath103 to @xmath177 , i.e.    * if @xmath178 or @xmath101 is weakly dependent , then @xmath179 where @xmath180 is the brownian bridge . * if @xmath181 , then @xmath182    the convergence of @xmath183 to @xmath184 is standard .",
    "the surprising result is that in the lrd zone the limiting process is 0 , because the limiting process of @xmath185 has a degenerate form , i.e. the limit is the random @xmath109 , multiplied by the deterministic function @xmath186 . in fact , as we will see below , there is no dichotomy for the process with random levels , and the rate of convergence of @xmath187 is the same as in the i.i.d . case .",
    "to proceed , we need to introduce a more precise second order conditions on the distribution function @xmath26 of @xmath188 .",
    "several types of second order assumptions have been proposed in the literature .",
    "we follow here @xcite .",
    "[ [ assumption - so ] ] assumption ( so ) + + + + + + + + + + + + + + +    there exists a bounded non increasing function @xmath189 on @xmath121 , regularly varying at infinity with index @xmath190 for some @xmath191 , and such that @xmath192 and there exists a measurable function @xmath193 such that for @xmath194 , @xmath195 if  ( [ eq : representation ] ) and ( [ eq : borne - eta ] ) hold , we will say that @xmath47 is second order regularly varying with index @xmath196 and rate function @xmath189 , in shorthand @xmath197 .",
    "[ thm : practical-1 ] assume ( h ) , ( [ eq : lrd ] ) , ( [ eq : pareto - assumption ] ) , ( so ) with rate function @xmath189 regularly varying at infinity with index @xmath190 and there exists @xmath198 such  that @xmath199<\\infty \\ ; .\\ ] ] if @xmath200 then @xmath201 converges weakly in @xmath103 to @xmath202 , where @xmath180 is the brownian bridge ( regardless of the behaviour of @xmath203 ) .",
    "_ remark_. the additional moment condition ( [ eq : additional - moment ] ) ensures that the distribution of @xmath204 satisfies a second order condition .",
    "see section [ sec : s - o - c ] for more details .",
    "it is also used in a proof of tightness argument ( see ( [ eq : uniform - conv ] ) below ) .",
    "the behaviour described in theorem [ thm : practical-1 ] is quite unexpected , since the process with _ estimated _ levels @xmath43 has a faster rate of convergence than the one with the deterministic levels @xmath20 .",
    "a similar phenomenon was observed in the context of lrd based empirical processes with estimated parameters .",
    "we refer to @xcite for more details .      a natural application of the asymptotic result for the tail empirical process",
    "@xmath187 is the asymptotic normality of the hill estimator of the extreme value index @xmath19 defined by @xmath205 since @xmath206 , we have @xmath207 thus we can apply theorem  [ thm : practical-1 ] to obtain the asymptotic distribution of the hill estimator .",
    "[ cor : hill ] under the assumptions of theorem  [ thm : practical-1 ] , @xmath208 converges weakly to the centered gaussian distribution with variance @xmath209 .",
    "it is known that the above result gives the best possible rate of convergence for the hill estimator ( see @xcite ) .",
    "the surprising result is that it is possible to achieve the i.i.d .",
    "rates regardless of @xmath41 .",
    "whereas the transfer of the tail index of @xmath188 to @xmath204 is well known , the transfer of the second order property seems to have been less investigated .",
    "we state this in the next proposition , as well as the rate of convergence of @xmath164 to @xmath163 and @xmath49 to @xmath210 .",
    "[ prop : transfert - second - ordre ] if @xmath211 , where @xmath189 is regularly varying at infinity with index @xmath190 , for some @xmath191 , and if @xmath212 < \\infty \\ ; ,     \\end{aligned}\\ ] ] for some @xmath31 , then @xmath213 , and @xmath214 moreover , for any @xmath215 such that @xmath216 , @xmath217 = o(\\eta^*(u_n)^p ) \\ ; .",
    "\\label{eq : rate - g_n }       \\end{gathered}\\ ] ]    [ [ examples ] ] examples + + + + + + + +    the most commonly used second order assumption is that @xmath218 for some @xmath219 .",
    "then @xmath220 for some constant @xmath221 .",
    "then , @xmath222 , and the second order condition  ( [ eq : second - ordre - unprimitive ] ) becomes @xmath223 and @xmath224 condition  ( [ eq : negligibility-1 ] ) holds if both @xmath225 and @xmath226 .",
    "the central limit theorem with rate @xmath227 holds if @xmath228 with @xmath229 condition  ( [ eq : negligibility-2 ] ) holds if @xmath230 .",
    "this may happen only if @xmath231 or equivalently @xmath232 as @xmath233 , only for very long memory processes ( i.e. @xmath41 close to 1 ) will the lrd zone be possible .",
    "the extreme case is the case @xmath234 , i.e. @xmath189 slowly varying .",
    "for instance , if @xmath235 ( for @xmath236 large ) , then the tail @xmath237 belongs to @xmath238 and @xmath239 .",
    "the second order condition  ( [ eq : second - ordre - unprimitive ] ) holds if @xmath240 if this condition holds , then @xmath241 for any @xmath242 and the lrd zone never arises , because the lrd term in the decomposition  ( [ eq : decomposition - sv ] ) is always dominated by the bias .",
    "we conducted some simulation experiments to illustrate our results .",
    "we used r functions hillmse ( ) and hillplot available on the authors webpages .    our first experiment deals with the mean squared error",
    ".    1 .   using r - fracdiff package we simulated fractional gaussian noises sequences",
    "@xmath243 with parameters @xmath244 . here , @xmath245 , so that @xmath246 corresponds to the case of an i.i.d . sequence .",
    "we simulated @xmath247 i.i.d .",
    "pareto random variables @xmath248 with parameters @xmath249 and @xmath250 .",
    "we set @xmath251 .",
    "hill estimator was constructed for different number of extremes .",
    "this procedure was repeated 10000 times .",
    "the results are displayed on figure [ fig:1 ] , for @xmath249 and @xmath252 , respectively . on each plot",
    ", we visualise mean square error ( with the true centering ) w.r.t . the number of extremes .",
    "solid lines represent different lrd parameters : black for @xmath246 , blue for @xmath253 , red for @xmath254 and green for @xmath255 .",
    "( left panel ) , @xmath252 ( right panel ) ; color codes : black - @xmath246 , blue - @xmath253 , red - @xmath254 , green - @xmath255,title=\"fig:\",scaledwidth=45.0% ]   ( left panel ) , @xmath252 ( right panel ) ; color codes : black - @xmath246 , blue - @xmath253 , red - @xmath254 , green - @xmath255,title=\"fig:\",scaledwidth=45.0% ]    we note that for @xmath249 , when a small number of extreme order statistics @xmath46 is used to build the hill estimator , there is not much influence of the lrd parameter , and in particular the mse is minimal for more or less the same values of @xmath46 through all the range of values of @xmath256 .",
    "this is in accordance with our theoretical results . for @xmath252 , the influence of the memory parameter",
    "is more significant .",
    "these two features can be interpreted .",
    "first , it seems natural that the long memory effect appears when a greater number of extreme order statistics is used , since our result is of an asymptotic nature .",
    "for a small number of extremes the i.i.d .",
    "type of behaviour dominates ( see @xmath257 in ( [ eq : decomposition - sv ] ) ) , so the asymptotic result is seen ; for a larger number of extremes , the long memory term @xmath258 in ( [ eq : decomposition - sv ] ) starts to dominate .",
    "for an extremely large number of order statistics ( i.e. @xmath259 ) , the bias dominates .",
    "the influence of @xmath40 on the quality of the estimation is twofold . on one hand ,",
    "the asymptotic variance of the hill estimator is @xmath260 , so that the mse increases with @xmath40 .",
    "also , for very small values of @xmath40 , the peaks observed are extremely high and completely overshadow the effect of long memory .",
    "next , we show hill plots for several models , since in practice one usually deals with just a single realization .    1 .",
    "we consider the model @xmath261 , where @xmath11 is as above a fractional gaussian noise and @xmath262 or @xmath250 .",
    "we simulated @xmath247 i.i.d .",
    "pareto random variables @xmath248 with parameter @xmath252 .",
    "3 .   we simulated fractional gaussian noise sequences @xmath11 with parameters @xmath246 ( i.i.d .",
    "case ) , 0.2 , 0.4 , @xmath255 .",
    "the estimators are plotted on figures [ fig:2 ] and [ fig:3 ] .",
    "the left panel corresponds to the hill estimator for iid pareto random variables @xmath263 , and the right one for the long memory stochastic volatility process @xmath264 . recall that the @xmath14 are dependent asympotically pareto random variables , so that there are two sources of bias for the hill estimator .     and",
    "pareto iid ( left panel ) , @xmath262 ( right panel ) ; color codes : black - @xmath246 , blue - @xmath253 , red - @xmath254 , green - @xmath255,scaledwidth=100.0% ]     and pareto iid ( left panel ) , @xmath265 ( right panel ) ; color codes : black - @xmath246 , blue - @xmath253 , red - @xmath254 , green - @xmath255,scaledwidth=100.0% ]    we may observe that for a small volatility parameter @xmath266 there is not too much difference between the two plots .",
    "however , if @xmath266 becomes bigger , the estimation with a large number of extremes is completely inappropriate if @xmath267 , though without much influence of the strength of the dependence ( i.e. increase of @xmath256 ) on this degradation .",
    "the reason is that the second order condition satisfied by the stochastic volatility model yields the same rate of convergence as in the i.i.d .",
    "case , but an increase in the variance of the gaussian process @xmath268 entails a bigger bias in finite sample .",
    "recall that each function @xmath269 in @xmath270 , with @xmath271 can be expanded as @xmath272 + \\sum_{m=1}^{\\infty}\\frac{j(m)}{m!}h_m(x ) \\ ; , \\ ] ] where @xmath273 $ ] and @xmath63 is a standard gaussian random variable .",
    "recall also that the smallest @xmath274 such that @xmath275 is called the hermite rank of @xmath79 .",
    "we have @xmath276 = { { \\mathbb e}}[g(x_0 ) ] + \\sum_{m = q}^{\\infty } \\frac{j^2(m)}{m ! } \\ , \\rho_k^m \\ ; , \\ ] ] where @xmath277 .",
    "thus , the asymptotic behaviour of @xmath278 $ ] is determined by the leading term @xmath279 .",
    "in particular , if @xmath280 , which implies that @xmath281 , @xmath282 and @xmath283 where @xmath284 and @xmath285 is the so - called hermite or rosenblatt process of order @xmath91 , defined as a @xmath91-fold stochastic integral @xmath286 where @xmath105 is an independently scattered gaussian random measure with lebesgue control measure . for more details ,",
    "the reader is referred to @xcite . on the other hand ,",
    "if @xmath287 or @xmath101 is weakly dependent , then @xmath288 where @xmath289 .",
    "we will also need the following variance inequalities of @xcite :    * if @xmath280 , then for any function @xmath79 with hermite rank @xmath91 , @xmath290 * if @xmath287 , then for any function @xmath79 with hermite rank @xmath91 , @xmath291    in all these cases , the constant @xmath292 depends only on the gaussian process @xmath101 and not on the function @xmath79 .",
    "the bounds  ( [ eq : variance - inequality - lrd ] ) and  ( [ eq : variance - inequality - weak - dependence ] ) are equation  3.10 and  2.40 in @xcite , respectively",
    ".      the main ingredient of the proof of our results will be the following decomposition .",
    "let @xmath293 be the @xmath95-field generated by the gaussian process @xmath294 .",
    "@xmath295 conditionally on @xmath296 , @xmath297 is the sum of independent random variables , so it will be referred to as the i.i.d .",
    "part ; the term @xmath258 is the partial sum process of a subordinated gaussian process , so it will be referred to as the lrd part .",
    "we first give a heuristic behind the dichotomous behaviour in theorem [ thm : general ] .",
    "then , we prove convergence of the finite dimensional distributions of the i.i.d .",
    "and lrd parts . finally , we prove tightness and asymptotic independence .      to present some heuristic , let us compute covariance of the tail empirical process .",
    "we have @xmath298 recall ( [ eq : cond - tail ] ) .",
    "if @xmath30<\\infty$ ] holds , we apply breiman s lemma to both nominator and denominator to get @xmath299p(z_1>u_n(1+s)\\vee      u_n(1+t))}{{{\\mathbb e}}[\\sigma^{\\alpha}(x_1)]p(z_1>u_n)}=t(s\\vee t ) \\ ; .\\end{gathered}\\ ] ] furthermore , if @xmath300<\\infty$ ] holds ( which is guaranteed by ( [ eq : moment-2alpha+epsilon ] ) ) , then a generalization of breiman s lemma yields @xmath301 } { { { \\mathbb e}}[\\sigma^{\\alpha}(x_1 ) ]        { { \\mathbb e}}[\\sigma^{\\alpha}(x_{j+1 } ) ] } - 1 \\right ) \\ ; .\\end{aligned}\\ ] ] therefore , for fixed @xmath90 and @xmath302 , using ( [ eq : var - sum ] ) in the case @xmath303 , we obtain @xmath304 } \\frac{1}{n }    \\sum_{j=1}^{n-1}\\left(1-\\frac jn \\right )    { \\mathrm { cov}}(\\sigma^{\\alpha}(x_1),\\sigma^{\\alpha}(x_{j+1 } ) )    \\\\    & = ( 1+o(1 ) ) \\left ( \\frac{t(s\\vee t)}{n\\bar f(u_n ) } + \\frac { t(s ) t(t )        j^2(q)\\rho_n^q}{q!(1 - 2q(1-h)){{\\mathbb e}}^2[\\sigma^{\\alpha}(x_1)]}\\right).\\end{aligned}\\ ] ] in particular , setting @xmath305 , then we conclude that the normalization factor for @xmath39 should be @xmath306 or @xmath307 depending whether @xmath308 or @xmath106 holds .",
    "the asymptotic variance also suggests the form of limiting distributions in theorem [ thm : general ] .",
    "let @xmath309 denote weak convergence of finite dimensional distributions .",
    "it will be shown in section [ sec : iid - limit ] and [ sec : lrd - limit ] , respectively , that for each @xmath84 and @xmath310 , @xmath311 , @xmath312 , @xmath313 where the normal random variables are independent , and @xmath314 } ( t(s_1),\\ldots , t(s_m ) )    l_q \\ ; , \\ ] ] if @xmath280 .",
    "on the other hand , if @xmath287 , then the second term @xmath315 is of smaller order than the first one , @xmath257 .",
    "define @xmath316 then @xmath317 set @xmath318 and @xmath319 $ ] .",
    "note that @xmath320=0 $ ] and @xmath321 let @xmath322 .",
    "therefore , for fixed @xmath302 , @xmath323 \\nonumber \\\\    & = \\sum_{j=1}^n \\log { { \\mathbb e}}\\left [ \\exp\\left(\\frac{\\mathrm          it}{\\sqrt{n \\bar",
    "f(u_n ) } } \\ {   1_{\\{y_j > u_n\\ } } -        { { \\mathbb p}}(y_j > u_n \\mid { \\cal x } ) \\ }",
    "\\right ) \\mid { \\cal x } \\right ]    \\nonumber   \\\\    & = \\sum_{j=1}^n \\log{{\\mathbb e}}\\left [ 1 - \\frac {   it}{\\sqrt{n\\bar          f(u_n ) } } l_{n , j}(x_j ) - \\frac{t^2}{2n \\bar",
    "f(u_n ) }      l_{n , j}^{2}(x_j ) + l_{n , j}^{3}(x_j ) o\\left(\\frac{1}{(n \\bar          f(u_n))^{3/2 } } \\right )      \\mid { \\cal x } \\right ] \\nonumber   \\\\    & = \\frac{-t^2}{2n\\bar      f(u_n)}\\sum_{j=1}^nv_n^{(2)}(x_j)+o\\left(\\frac{1}{n\\bar        f(u_n)}\\right)\\sum_{j=1}^nv_n^{(2)}(x_j)+o\\left(\\frac{1}{(n\\bar        f(u_n))^{3/2}}\\right ) \\sum_{j=1}^n |v_n^{(3)}(x_j)| \\ ; .",
    "\\label{eq : decomp - chf}\\end{aligned}\\ ] ] we will show that @xmath324 given that @xmath325<\\infty$ ] .",
    "this also shows that the second term in ( [ eq : decomp - chf ] ) is negligible .",
    "furthermore , since for sufficiently large @xmath81 and @xmath326 ( cf .",
    "( [ eq : bound-1 ] ) ) , @xmath327 the expected value of the last term in ( [ eq : decomp - chf ] ) is @xmath328   \\ ; .\\ ] ] consequently , the last term in  ( [ eq : decomp - chf ] ) converges to 0 in @xmath329 and in probability .",
    "therefore , on account of ( [ eq : lln ] ) and the negligibility , we obtain , @xmath330    { \\stackrel{\\mbox{\\small\\tiny p}}{\\to}}-t^2/2\\ ] ] and from bounded convergence theorem we conclude ( for @xmath331 and @xmath332 ) .",
    "it remains to prove ( [ eq : lln ] ) . by lemma  [ lem : convergence - uniforme - hermite ] , for each @xmath333 , @xmath334 converges in probability and in @xmath329 to @xmath335 .",
    "therefore , @xmath336",
    "= 0 \\ ; .\\ ] ] next , since @xmath337 , @xmath333 , is ergodic , we have @xmath338 \\ ; .\\ ] ] thus , ( [ eq:1 ] ) , ( [ eq:2 ] ) and breiman s lemma yields @xmath339 write now @xmath340 by lemma  [ lem : convergence - uniforme - hermite ] , we have , for some @xmath326 small enough , @xmath341 this proves ( [ eq : lln ] ) and ( [ eq : iid - limit ] ) follows with @xmath331 and @xmath342 . the case of a general @xmath343",
    "is obtained analogously .",
    "recall the definition ( [ eq : function - gn ] ) of @xmath82 and that @xmath54 .",
    "define @xmath344 , \\quad j(m)={{\\mathbb e}}[h_m(x_1)g(x_1)],\\ ] ] the hermite coefficients of @xmath82 and @xmath269 , respectively .",
    "let @xmath91 be the hermite rank of @xmath269 .",
    "we write ( recall assumption ( h ) ) , @xmath345 ) } \\nonumber    \\\\    & = & \\sum_{j=1}^n \\sum_{m = q}^{\\infty } \\frac{t(s)j(m)}{m ! }",
    "h_m(x_j ) +    \\sum_{j=1}^n \\sum_{m = q}^{\\infty } \\frac{j_n(m , s)-t(s)j(m)}{m ! }",
    "h_m(x_j )   \\nonumber \\\\    & = : & t(s ) s_n^ * + \\tilde s_n(s ) \\ ; ,    \\label{eq : expansion}\\end{aligned}\\ ] ] with @xmath346 . on account of rozanov s equality ( [ eq : rozanov ] )",
    ", we have that the variance of the second term is @xmath347 since @xmath348<\\infty$ ] , by lemma  [ lem : convergence - uniforme - hermite ] , @xmath82 converges @xmath349 in @xmath350 , uniformly with respect to @xmath90 .",
    "we conclude that the second term on the right handside of ( [ eq : expansion ] ) is @xmath351 , i.e. it is asymptotically smaller than the first term .",
    "furthermore , @xmath352\\right),\\ ] ] so that via ( [ eq : lim - sums ] ) and ( [ eq : bound-2 ] ) @xmath353 } l_q \\ ; , \\ ] ] if @xmath280 . consequently , ( [ eq : lrd - limit ] ) holds for @xmath331 .",
    "the multivariate case follows immediately . on the other hand , if @xmath287 , then via ( [ eq : lim - sums - iid ] ) and ( [ eq : bound-2 ] ) , @xmath354 } s_n(s ) { \\stackrel{\\mbox{\\tiny\\rm d}}{\\to}}\\frac{1}{{{\\mathbb e}}[\\sigma^{\\alpha}(x_1)]}{\\cal n}(0,\\sigma_0 ^ 2 ) \\ ; , \\ ] ] which proves negligibility with respect to the term @xmath257 .      in this section",
    "we prove asymptotic independence of @xmath257 and @xmath315 .",
    "we will carry out a proof for the joint characteristic function of @xmath355 .",
    "extension to multivariate case is straightforward . on account of ( [ eq : chf-1 ] ) , ( [ eq : chf-2 ] ) and the bounded convergence theorem , we have @xmath356}\\\\         & = & { { \\mathbb e}}\\left [      { { \\mathbb e } } [ \\exp\\{\\mathrm i s \\sqrt{n\\bar f(u_n ) } r_n\\ } \\mid { \\cal x } ]      \\exp \\left ( \\mathrm i t \\rho_n^{-q/2 } s_n     \\right ) \\right ] \\\\    & \\to & \\exp(-s^2/2 ) \\ , \\psi_{l_q }    \\left(\\frac{j(q)}{{{\\mathbb e}}[\\sigma^{\\alpha}(x_1 ) ] } \\ , t \\right ) \\",
    "\\mbox { as } n \\to \\infty \\ ; , \\end{aligned}\\ ] ] where @xmath357 is the characteristic function of @xmath109 .",
    "this proves asymptotic independence .",
    "in order to prove the tightness in @xmath358 endowed with skorokhod s @xmath120 topology of the sequence of processes @xmath359 , we apply the tightness criterion of ( * ? ? ? * theorem 15.4 ) .",
    "we must prove that for each @xmath360 and @xmath31 , @xmath361 where for any function @xmath362 , @xmath363 since the @xmath14s are independent conditionally on @xmath296 , by elementary computations similar to those that lead to ( * ? ? ?",
    "* inequality 13.17 ) , we obtain that @xmath364      \\leq 3     \\{q_n(t_1)-q_n(t_2)\\}^2 \\ ; , \\end{aligned}\\ ] ] where @xmath365 note that @xmath366 converges in probability to @xmath367 which is a continuous decreasing function on @xmath121 .",
    "let @xmath69 be an integer and set @xmath368 . applying ( * ? ? ?",
    "* theorem 12.5 ) and using the same arguments as in the proof of ( * ? ? ?",
    "* theorem 15.6 ) ( p. 129 , eq .",
    "( 15.26 ) ; note that the assumed continuity of the function @xmath18 that appears therein is not used to obtain ( 15.26 ) ) , we see that the bound  ( [ eq:3qn ] ) yields , for some constant @xmath292 ( whose numerical value may change upon each appearance ) , @xmath369 letting now @xmath100 yields @xmath370 by bounded convergence , this yields @xmath371 and  ( [ eq : bill - criterion-15.4 ] ) follows .",
    "we prove now tightness of @xmath258 .",
    "assume first @xmath280 and define @xmath372 . applying ( [ eq : variance - inequality - lrd ] ) there exists a constant @xmath292 , which depends only on the gaussian process @xmath101 , such that we have , for @xmath373 , @xmath374\\end{aligned}\\ ] ] let the expectation in last term be denoted by @xmath375 . by the same adaptation of the proof of ( * ? ? ?",
    "* theorem 15.6 ) as previously ( see also @xcite for a more general extension ) , we obtain , for each @xmath360 , and for @xmath368 for an integer @xmath69 , @xmath376 thus , letting @xmath81 tend to infinity while keeping @xmath78 fixed , we get @xmath377 thus @xmath378 and this concludes the proof of tightness .      as in case of theorem [ thm : general ] , we start some heuristic .",
    "recall computation from section [ sec : heuristic ] and the form of the limiting distribution @xmath379 .",
    "then @xmath380 this suggests that in lrd zone @xmath381 converges to 0 .",
    "+ to prove it formally , denote @xmath382 and @xmath383 .",
    "then @xmath384 , and we have @xmath385 thus , @xmath386 for any @xmath387 , @xmath388 and @xmath389 , thus @xmath390 plugging  ( [ eq : ecriture - xi_n ] ) into this decomposition of @xmath391 , we get @xmath392 in order to prove corollary  [ cor : practical ] , we write @xmath393 since the convergence in theorem [ thm : general ] is uniform , and by corollary [ coro : intermediate ] @xmath394 , the first term in  ( [ eq : proof - practical ] ) converges in @xmath103 to @xmath379 . under the second order condition  ( [ eq : second - ordre - unprimitive ] ) , the second term is @xmath395 .",
    "this concludes the proof of theorem  [ cor : practical ] .",
    "we now prove theorem  [ thm : practical-1 ] . in order to study the second - order asymptotics of @xmath396 , we need precise expansion for @xmath397 and @xmath398 . for this we will use the expansions of the tail empirical process in section  [ sec : fidi ] .",
    "since @xmath399 , using  ( [ eq : decomposition - sv ] ) , ( [ eq : expansion ] ) and ( [ eq : claim-2 ] ) , we have @xmath400 which , noting again that @xmath389 , yields @xmath401 and @xmath402 similarly to ( [ eq : control - hermite ] ) , and utilising @xmath403 , @xmath404 using the second order assumption ( so ) through  ( [ eq : rate - g_n ] ) , we obtain @xmath405 using ( [ eq : expansion-4 ] ) in the representation ( [ eq : expansion - clean ] ) and since proposition  [ prop : transfert - second - ordre ] implies that @xmath406 , we obtain : @xmath407 since we have already proved that the convergence of @xmath408 is uniform , we obtain that @xmath409 converges in the sense of finite dimensional distribution to @xmath410 , where @xmath180 is the brownian bridge , if the second order condition  ( [ eq : negligibility-1a ] ) holds .",
    "to prove tightness , we only have to prove that @xmath411 converges uniformly to zero on compact sets . for @xmath80 and @xmath412 , denote @xmath413 and recall that we have shown in section  [ sec : tightness - deterministic - level ] that @xmath414 applying  ( [ eq : pour - th - random ] ) , we get @xmath415    ( s - s')^2\\ ; , \\ ] ] which proves that @xmath416 converges uniformly to zero on compact sets .      using the decomposition  ( [ eq : decomp - non - uniform ] ) , and the identity @xmath417 , we have @xmath418 we must prove that the terms in  ( [ eq : toto-1 ] ) and  ( [ eq : toto-2 ] ) are @xmath419 and that @xmath420 to prove  ( [ eq : int - w ] ) , we follow the lines of ( * ? ? ? * section 9.1.2 )",
    ". we must prove that we can apply continuous mapping . to do this",
    ", it suffices to establish that for any @xmath326 we have @xmath421 where @xmath422 by markov s inequality , conditional independence and potter s bound ( * ? ? ?",
    "* theorem 1.5.6 ) , we have , for some @xmath31 , @xmath423 as @xmath424 , since @xmath42",
    ". this proves  ( [ eq : int - w ] ) . to get a bound for  ( [ eq : toto-2 ] )",
    ", we use  ( [ eq : rate - non - uniform ] ) which yields , for all @xmath425 , @xmath426 thus @xmath427 and @xmath428 , thus @xmath429 we finally bound  ( [ eq : toto-1 ] ) .",
    "@xmath430 since @xmath394 , we can write @xmath431}{1+s } \\ ; \\d s\\end{aligned}\\ ] ] applying  ( [ eq : control - hermite ] ) and  ( [ eq : rate - g_n - nonuniform ] ) yields @xmath432}{1+s } \\ , \\d s    & \\leq c \\rho_n^{q/2 } \\eta^*(u_n ) \\int_0^\\infty    s^{-\\alpha(\\beta+1)/2+\\epsilon-1 } \\ , \\d s = o_p(k^{-1/2 } ) \\ ; .\\end{aligned}\\ ] ] thus the first term in  ( [ eq : toto-1 ] ) is @xmath433 , and so is the second term since @xmath434 converges uniformly to zero on compact sets .",
    "this concludes the proof of corollary  [ cor : hill ] .",
    "the main tool in the study of the tail of the product @xmath435 is the following bound .",
    "for any @xmath31 , there exists a constant @xmath292 such that , for all @xmath436 , @xmath437 this bound is trivial if @xmath438 and follows from potter s bounds if @xmath439 .    by breiman s lemma , we know that for any sequence @xmath20 such that @xmath440 , @xmath441 if @xmath55<\\infty$ ] , then the bound  ( [ eq : bound-1 ] ) implies that the convergence  ( [ eq : bound-2 ] ) holds in @xmath442 for any @xmath57 such that @xmath58 , uniformly with respect to @xmath90 , i.e. @xmath443 = 0 \\ ; .\\end{aligned}\\ ] ]    before proving proposition  [ prop : transfert - second - ordre ] , we need the following lemma which gives a non uniform rate of convergence .    [",
    "lem : rate - excess - eta ] if  ( [ eq : pareto - assumption ] ) ,  ( [ eq : representation ] ) and  ( [ eq : borne - eta ] ) hold , if @xmath189 is regularly varying at infinity with index @xmath444 , for some @xmath445 , then   for any @xmath31 , there exists a constant @xmath292 such that @xmath446    since @xmath189 is decreasing , using the bound @xmath447 with @xmath448 , we have , for all @xmath194 , @xmath449 we now distinguish three cases .",
    "recall that @xmath189 is decreasing .    * if",
    "@xmath450 , then @xmath451 is a slowly varying function by karamata s representation theorem , and is @xmath452 for any @xmath31 . plugging this bound into  ( [ eq : reste - un - bout ] ) yields  ( [ eq : rate - non - uniform ] ) . * if @xmath453 and @xmath454 , then @xmath455 for any @xmath31 by the same argument as above and this yields  ( [ eq : rate - non - uniform ] ) . *",
    "if @xmath456 , then @xmath457 for any @xmath458 and @xmath459 for any @xmath31 .",
    "thus @xmath460    this concludes the proof of  ( [ eq : rate - non - uniform ] ) .    the following bound is used in the proof of prove theorem  [ thm : practical-1 ] .",
    "if  ( [ eq : pareto - assumption ] ) ,  ( [ eq : representation ] ) and  ( [ eq : borne - eta ] ) hold , if @xmath189 is regularly varying at infinity with index @xmath444 , for some @xmath445 , then there exists a constant @xmath292 such that for all @xmath461 and @xmath462 , @xmath463    the bound  ( [ eq : pour - th - random ] ) follows from the following one and  ( [ eq : bound-1 ] ) applied to the function @xmath189 .",
    "@xmath464 let @xmath29 be the function slowly varying at infinity that appears in  ( [ eq : pareto - assumption ] ) , defined on @xmath121 by @xmath465 .",
    "assumption ( so ) implies that @xmath466 where the function @xmath193 is measurable and bounded .",
    "this implies that the function @xmath29 is the solution of the equation @xmath467 conversely , if @xmath29 satisfies  ( [ eq : equation ] ) then  ( [ eq : representation - ell ] ) holds .",
    "we first prove the following useful bound . for any @xmath31",
    ", there exists a constant @xmath292 such that for any @xmath461 and all @xmath468 , @xmath469 where we denote @xmath470 . indeed , if @xmath471 , then , @xmath189 being decreasing , we have @xmath472 since the latter function is slowly varying by karamata s representation theorem . if @xmath473 , then @xmath474 and @xmath475 .",
    "this proves  ( [ eq : ell(at)/ell(t ) ] ) .",
    "next , applying  ( [ eq : equation ] ) and  ( [ eq : ell(at)/ell(t ) ] ) , for any @xmath31 and @xmath476 , we have @xmath477 applying  ( [ eq : ell(at)/ell(t ) ] ) and  ( [ eq : l / l ] ) , we also obtain @xmath478 for @xmath31 and @xmath476 , we have @xmath479 which yields @xmath480    define the function @xmath481 by @xmath482 .",
    "applying  ( [ eq : rate - non - uniform ] ) with @xmath483 instead of @xmath484 and @xmath20 for @xmath302 , we get @xmath485 this implies , for all @xmath57 such that @xmath486<\\infty$ ] , that @xmath487 = o(\\{\\eta^*(u_n)\\}^p ) \\ ; .\\end{aligned}\\ ] ] this proves  ( [ eq : rate - g_n ] ) which in turn implies  ( [ eq : rate - t_n ] ) since @xmath488 $ ] . in order to prove that @xmath489 , denote @xmath490 .",
    "we will prove that there exists a measurable function @xmath491 such that  ( [ eq : equation ] ) holds with @xmath492 and @xmath493 .",
    "denote @xmath494 . applying  ( [ eq : equation ] ) and using the independence of @xmath495 and @xmath188 , we have @xmath496 = \\ell(1 )    { { \\mathbb e}}[\\xi^\\alpha ] + { { \\mathbb e}}\\left[\\xi^\\alpha \\int_1^{y/\\xi } \\eta(s )      \\ell(s ) \\frac{\\d s}s \\right ] \\\\    & = \\ell(1 ) { { \\mathbb e}}[\\xi^\\alpha ] + { { \\mathbb e}}\\left[\\xi^\\alpha \\int_\\xi^{y }      \\eta(s/\\xi ) \\ell(s/\\xi ) \\frac{\\d s}s \\right ] \\\\    & = { { \\mathbb e}}\\left [ \\xi^\\alpha \\left\\ { \\ell(1 ) -\\int_1^\\xi \\eta(s/\\xi )        \\ell(s/\\xi ) \\frac{\\d s}s \\right\\ } \\right ] + { { \\mathbb e}}\\left[\\xi^\\alpha      \\int_1^{y } \\eta(s/\\xi ) \\ell(s/\\xi ) \\frac{\\d s}s \\right ] \\\\    & = { { \\mathbb e}}\\left [ \\xi^\\alpha \\left\\ { \\ell(1 ) + \\int_{1/\\xi}^1 \\eta(s )        \\ell(s ) \\frac{\\d s}s \\right\\ } \\right ] + \\int_1^{y }    { { \\mathbb e}}[\\xi^\\alpha \\eta(s/\\xi ) \\ell(s/\\xi ) ] \\frac{\\d s}s \\\\    & = { { \\mathbb e}}\\left [ \\xi^\\alpha \\ell(1/\\xi ) \\right ] + \\int_1^{y }    { { \\mathbb e}}[\\xi^\\alpha \\eta(s/\\xi ) \\ell(s/\\xi ) ] \\frac{\\d s}s = \\tilde    \\ell(1 ) + \\int_1^t \\tilde \\eta(s ) \\tilde \\ell(s ) \\frac{\\d s}s \\ ; , \\end{aligned}\\ ] ] where we have defined @xmath497 } { { { \\mathbb e}}[\\xi^\\alpha \\ell(s/\\xi ) ] } =    \\frac{{{\\mathbb e}}[\\xi^\\alpha \\eta(s/\\xi ) \\ell(s/\\xi)/\\ell(s ) ] }    { { { \\mathbb e}}[\\xi^\\alpha \\ell(s/\\xi)/\\ell(s ) ] } \\ ; .\\end{aligned}\\ ] ] the denominator of the last expression is bounded away from zero .",
    "indeed , let @xmath31 be such that @xmath498 . then @xmath499 = \\frac{{{\\mathbb p}}(\\xi      z >",
    "s)}{{{\\mathbb p}}(z > s ) } \\geq \\frac{{{\\mathbb p}}(\\xi\\geq\\epsilon ) { { \\mathbb p}}(z > s/\\epsilon ) }    { { { \\mathbb p}}(z > s ) } \\ ; .\\end{aligned}\\ ] ] since @xmath188 has a regularly varying tail , it holds that @xmath500 .",
    "this proves our claim .",
    "thus , applying  ( [ eq : bound-1 ] ) with the regularly varying function @xmath189 , we get , for @xmath31 such that @xmath501<\\infty$ ] , @xmath502 \\leq c    \\eta^*(x ) \\ , { { \\mathbb e}}[\\xi^\\alpha(\\xi\\vee1)^{-\\rho+\\epsilon}]\\ ; .\\end{aligned}\\ ] ] thus @xmath503 satisfies equation  ( [ eq : equation ] ) with @xmath491 such that @xmath504 , thus @xmath505 .",
    "the research of the first author was supported by nserc grant .",
    "the research of the second author is partially supported by the anr grant anr-08-blan-0314 - 02 .",
    "richard  a. davis and thomas mikosch .",
    "point process convergence of stochastic volatility processes with application to sample autocorrelation .",
    ", 38a:93104 , 2001 .",
    "probability , statistics and seismology .",
    "rohit deo , mengchen hsieh , clifford  m. hurvich , and philippe soulier .",
    "long memory in nonlinear processes . in _ dependence in probability and statistics _ ,",
    "volume 187 of _ lecture notes in statist .",
    "_ , pages 221244 .",
    "springer , new york , 2006 ."
  ],
  "abstract_text": [
    "<S> this paper describes the limiting behaviour of tail empirical processes associated with long memory stochastic volatility models . </S>",
    "<S> we show that such a process has dichotomous behaviour , according to an interplay between the hurst parameter and the tail index . on the other hand , </S>",
    "<S> the tail empirical process with random levels never suffers from long memory . </S>",
    "<S> this is very desirable from a practical point of view , since such a process may be used to construct the hill estimator of the tail index . to prove our results we need to establish new results for regularly varying distributions , which may be of independent interest </S>"
  ]
}