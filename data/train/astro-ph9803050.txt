{
  "article_text": [
    "the mk classification of stellar spectra ( morgan , keenan & kellman 1943 ; keenan & mcneil 1976 ; morgan , abt & tapscott 1978 ) is an important tool in stellar and galactic astrophysics .",
    "in addition to providing fundamental stellar information it was , for example , central to the discovery of nearby galactic spiral arms ( morgan , sharpless & osterbrock 1952 ; morgan , whitford & code 1953 ) .",
    "mk classification is usually performed by a trained expert visually matching the overall appearance of a spectrum to the ` closest ' mk standard spectrum .",
    "such a qualitative method of classification suffers from subjective decisions and may differ from person to person : what is deemed as ` close ' by one person may not be ` close ' for another .",
    "in addition , visual classification is very time consuming , with an expert classifying a few @xmath5 stars in a dedicated lifetime .",
    "spectra collected from large spectral surveys , often as a by - product of other surveys ( e.g.  the sloan digital sky survey ( kent 1994 ) ) will have to be classified by automated means .",
    "thus if stellar classification is to continue to be useful to the astronomical community , it has to be made faster and put on a more quantitative and objective basis .    in this paper",
    "we investigate the application of neural networks to the mk classification of optical stellar spectra .",
    "the so - called ` supervised ' neural networks used in this project are implemented to yield an accurate mapping between a data domain ( the stellar spectra ) and a classification domain ( the mk classifications ) .",
    "while visual classifiers have mentally determined this mapping , they have not quantified it .",
    "this mapping is , however , present intrinsically in a large set of classified spectra .",
    "the neural network s resultant classification criteria will be essentially equivalent to the human s criteria . however , whereas a human s criteria may vary from adverse physiological and psychological factors such as health and mood , the network will retain a consistent set of classification criteria .",
    "we will also demonstrate how the technique of principal components analysis ( pca ) can be used to optimally compress the spectra .",
    "this has a number of advantages including the preferential removal of noise and an ability to isolate bogus spectra .",
    "furthermore , using pca - compressed spectra ( rather than complete spectra ) in the neural network classifiers leads to reduced training times and better convergence stability .    while mk classification will continue to be a useful tool to astronomers",
    ", it becomes increasingly desirable to obtain physical parameters ( , , etc . )  for stars .",
    "bailer - jones et  al.(1997b ) describe a neural network approach to the parametrization of stellar spectra by training a neural network on synthetic spectra .",
    "there have been a number of attempts in the past to automate stellar spectral classification .",
    "kurtz ( 1982 ) classified low ( 14 ) resolution spectra using cross - correlation with standard spectra and achieved a mean classification error of 2.2 spectral subtypes for stars in the range b0 to m2 .",
    "the same technique gave poor luminosity classification results .",
    "lasala ( 1994 ) used the related technique of minimum distance classification to classify a set of 350 b - star spectra , and achieved a mean error of 1.14 spectral subtypes .",
    "the classification work of von hippel et  al .",
    "( 1994 ) ( paper i ) was one of the first applications of neural networks to stellar spectral classification .",
    "their neural network solution based on a set of 575 spectra gave an rms classification error of 1.7 spectral subtypes ( and a 68-percentile error of 1.4 spectral subtypes ) for spectra in the range b3 to m4 .",
    "gulati et  al.(1994 ) trained a neural network on a set of 55 spectra giving an incomplete coverage of spectral classes o through to m. while they reported classification errors of 2 subtypes , it should be noted that they used a very complex neural network with over 18,000 free parameters ( network weights ) , with no justification of why such a complex network was required .",
    "the result is that the determination of these weights was likely to be poorly constrained by the small amount of training data used .",
    "there have also been attempts to classify spectra beyond the visual .",
    "weaver & torres - dodgen ( 1995 ) used neural networks to classify infrared spectra ( 5800  to 8900 ) of a stars at 15 , and achieved spectral type and luminosity class classification precisions of 0.4 subtypes and 0.15 luminosity classes respectively .",
    "they have recently achieved good results in the infrared for a wide - range of spectral types ( o  m ) and luminosity classes ( i  v ) ( weaver & torres - dodgen 1997 ) .",
    "vieira & pons ( 1995 ) used a neural network trained on a set of 64 iue ultraviolet spectra ( 150  to 3200 ) in the range o3 to g5 , and reported a classification error of 1.1 spectral subtypes .",
    "it was unclear , however , why a network with 110,000 weights was required .",
    "whitney ( 1983 ) has examined the use of principal components analysis for spectral classification of a set of 53 a and f stars .",
    "his data set consisted of 47 photoelectric measurements of spectra over the wavelength range 3500  to 4000 .",
    "he applied pca to his data set and then performed a regression on the three most significant components , achieving an average classification error of 1.6 spectral subtypes .",
    "the classification techniques described in this paper were developed using a set of 5000 spectra taken from the michigan spectral survey ( houk 1994 ) .",
    "the data reduction method is described in paper i and in more detail in bailer - jones et  al .",
    "( 1997a ) .",
    "the present work expands the data set of paper i by a factor of ten and doubles the spectral resolution .",
    "the wavelength range is also slightly different , with the details summarized in table  [ plt_det ] .",
    ".the spectral data . [ cols= \" < , < \" , ]     [ anal06_tab ]    to prove that the pca was not limiting the performance of the neural network classifiers , we trained a committee of neural networks on the original ( non - pca ) 820-bin spectra .",
    "the mean classification error of @xmath6 spt shown in table  [ tempsum ] is no better than the pca - input results for comparable numbers of hidden nodes , confirming that the pca compression has not resulted in the loss of any classification - significant information . strictly speaking",
    ", this 820:5:5:1 network has too many weights to be well - determined by the data ( 4141 weights ( unknowns ) vs.  2500 spectra ( equations ) ) , so it may be surprising that such a network can generalize .",
    "however , due to correlations between the spectral features , some input weights will be correlated , effectively reducing the number of parameters which must be determined by the data .",
    "indeed , the principal components analysis showed that the effective dimensionality of the spectra is only about 25 .",
    "the internal and external error measures we have been using are averages over all spectral types .",
    "figure  [ serr05_p1 ] shows that 68  and  vary considerably as a function of spectral type .",
    "this is influenced by the frequency distribution of spectral types : as we can see from comparison with figure  [ dist_b ] , where there are relatively few spectra in the training set the classification errors are correspondingly higher .",
    "this is because the neural network has been presented with relatively little information about these regions , and the few spectra are unlikely to give adequate information on the intra - class variability . indeed , if we remove the few spectra at the earliest and latest spectral types , our overall error drops towards the limit imposed by the training data .",
    "we have also experimented using neural networks in probabilistic mode for spectral type classification .",
    "a committee of ten such 50:5:5:57 networks applied to the line+continuum spectra gave @xmath7 spt , which is somewhat inferior to continuous output results .",
    "however , the probabilistic approach does offer some advantages , such as the ability to recognise composite spectra ( weaver 1994 ) .",
    "neural networks were applied to the luminosity class problem in probabilistic mode ( see section  [ ann ] ) using data set b. the spectrum is classified as that class for which the output is highest .",
    "we only consider two - hidden layer networks .",
    "the measure of network performance when we have a few discrete classes is by means of the _ confusion matrix_. this reports the fraction of spectra which have been correctly and incorrectly classified for each class .",
    "[ lumres ]    table  [ lumres ] compares the results from different committees of networks , with the four combinations of line - only or line+continuum spectra represented with 25 or 50 principal components .",
    "we see that there is little difference in performance between any of these combinations .",
    "this is in agreement with the spectral type classifications and confirms that most of the luminosity class information is contained within the first 25 admixture coefficients .",
    "the networks give very good results for classes iii and v ( but not class iv ) , although the better results for class v than class iii may be due to larger fraction of class vs in the data set ( 1.6 times as many ) .",
    "figure  [ lum08 ] shows the distribution of the probabilities which the committee assigns for each class .",
    "while most of the class iii and v objects are correctly classified with large confidence , the opposite is true for class ivs .",
    "the nework is not classifying ivs at random ( otherwise we would expect it to classify about 33% correct ) .",
    "rather , the networks have a preference for classifying ivs as either iiis or vs. while the relative paucity of class ivs in the training set will have some influence , they are not so rare to give such poor performance . nor are the ivs lower quality spectra .    referring back",
    "to figure  [ dist_b ] we see that there is a fairly strong correlation between spectral type and luminosity class .",
    "is the network using spectral type information to produce luminosity classifications ?",
    "it would do quite well if it simply classified all spectra later than about k0 as giants and the rest as dwarfs .",
    "( note that much of this correlation is real , because the hr diagram is not uniformly populated . )",
    "[ ovlap08 ]    to find out what spectral information the networks are using , an ` overlap ' data set was created by selecting spectra of classes iii , iv and v in roughly equal numbers for that range of spectral types where their frequency distributions overlap ( around g6 ) .",
    "these spectra were then classified using a committee previously trained on all the data .",
    "we see from table  [ ovlap08 ] that the committee still yields good classifications of classes iii and v , for which it can not be using spectral type information as there is no correlation between spectral type and luminosity class over this specifically chosen and narrow spectral range .",
    "there must , therefore , be independent luminosity information present in this 50-component reconstruction of the stellar spectra . the class iv classifications are still poor .",
    "the failure on class iv spectra implies that , at the resolution of these spectra , class iv stars are not spectroscopically distinct from either class iii or class v. certainly , visual classifiers find it hard to distinguish class ivs from iiis and vs around late g - type stars ( n.  houk , private communication , 1996 ) .",
    "it can not be due to the pca compression as complete spectrum classification gives almost exactly the same results as shown in figure  [ lumres ] .",
    "problems with the data reduction , e.g.  imperfectly registering the spectra in wavelength , could also contribute .",
    "an alternative explanation is as follows .",
    "visual classifiers can focuse on certain lines in a spectrum and disregard all others . in principal",
    ", neural networks can do this too by altering their weights .",
    "however , when there is noise in the spectrum some inputs will show random correlations with the target outputs .",
    "thus the network will make a small level of false inference about the relevance of certain inputs in determining the outputs . with class",
    "iv discrimination the relevance of the few truly important features may have been washed out this false ` noise association ' .",
    "a solution to this problem is to use prior knowledge of which lines are relevant and train the network only on those features .",
    "another approach is _ automatic relevance determination _",
    "( mackay 1995 ) , which is a bayesian technique for assessing the relevance of the inputs using the evidence in the data .",
    "we attempted to use networks with two continuous outputs to tackle the spectral type and luminosity class problems simulataneously .",
    "however , the results were inferior , with the best results being 68  = 1.53 spt (  = 2.02 spt ) for the spectral type and 68  = 0.15 (  = 0.4 ) luminosity classes ( bailer - jones 1996 ) . due to the spectral type ",
    "luminosity class correlation in the data set , the network may be unable to adequately separate out luminosity effects from temperature ones .",
    "this is not helped by the weakness of the luminosity distiguishing features in this wavelength region . in order to tackle both problems simultaneously",
    ", we may need a more complex model , and such complexity may not be available with modest - sized networks .",
    "we have produced a system for the automated two - parameter classification of stellar spectra over a wide range of spectral types ( b2m7 ) based on a large ( @xmath8 ) , homogenous set of spectra .",
    "we have shown that we can achieve classification errors of 68  = 0.82 subtypes (  = 1.09 subtypes ) over this complete range of spectral subtypes .",
    "this result compares favourably with the intrinsic errors of 68 = 0.63 subtypes in our training data .",
    "once a neural network has been trained , its classification results are completely reproducible .",
    "moreover , the low values of their internal errors ( @xmath9 spectral subtypes ) demonstrate that networks can be re - trained to give sufficiently consistent classifications .",
    "we have achieved correct luminosity class classification for over 95% of dwarfs ( class v ) and giants ( class iii ) .",
    "results for luminosity class iv spectra were considerably worse .",
    "it is believed that the data themselves could be a limiting factor and methods for improving these results were discussed . despite the correlation in the data set between spectral type and luminosity class , it was demonstrated that the neural networks were using luminosity features to do dwarf - giant discrimination .",
    "network with two hidden layers performed considerably better ( @xmath10 subtypes ) than ones with only one hidden layer .",
    "the best classification results were achieved by tackling the spectral type and luminosity class problems separately , using continuous and probabilistic networks respectively .",
    "we used principal components analysis to compress the spectra by a factor of over 30 while retaining 96% of the variance in the data .",
    "it was shown that this compression predominantly removes noise .",
    "in addition the pca preprocessing reduces the dimensionality of the data and can be used to filter out bogus spectral features or identify unusual spectra . however , pca has the drawback that very weak or rare features will not be well - reconstructed .",
    "more complex non - linear preprocessing schemes could no doubt be devised , but the strength of pca is its analytic simplicity and its robustness .",
    "the automated classifiers presented in this paper have been used to produce classifications for several thousand stars which do not have classifications listed in the mhd catallogue .",
    "these will be presented in a future paper ( bailer - jones 1998 ) .",
    "we would like to thank nancy houk for kindly loaning us her plate material .",
    "rumelhart d.e . ,",
    "hinton g.e .",
    ", williams r.j .",
    ", 1986a , in rumelhart d.e .",
    ", mcclelland j.l , the pdp research group , eds , parallel distributed processing : explorations in the microstructure of cognition , mit press , boston , p.  318"
  ],
  "abstract_text": [
    "<S> we investigate the application of neural networks to the automation of mk spectral classification . </S>",
    "<S> the data set for this project consists of a set of over 5000 optical ( 38005200 ) spectra obtained from objective prism plates from the michigan spectral survey . </S>",
    "<S> these spectra , along with their two - dimensional mk classifications listed in the michigan henry draper catalogue , were used to develop supervised neural network classifiers . </S>",
    "<S> we show that neural networks can give accurate spectral type classifications ( 68 = 0.82 subtypes , = 1.09 subtypes ) across the full range of spectral types present in the data set ( b2m7 ) . </S>",
    "<S> we show also that the networks yield correct luminosity classes for over 95% of both dwarfs and giants with a high degree of confidence .    </S>",
    "<S> stellar spectra generally contain a large amount of redundant information . </S>",
    "<S> we investigate the application of principal components analysis ( pca ) to the optimal compression of spectra . </S>",
    "<S> we show that pca can compress the spectra by a factor of over 30 while retaining essentially all of the useful information in the data set . </S>",
    "<S> furthermore , it is shown that this compression optimally removes noise and can be used to identify unusual spectra .    </S>",
    "<S> this paper is a continuation of the work done by von hippel et  al.(1994 ) ( paper i ) .    </S>",
    "<S> pos@xmath0 pos@xmath1 pos@xmath2 pos@xmath3    68@xmath4    methods : analytical , data analysis , numerical - stars : fundamental parameters </S>"
  ]
}