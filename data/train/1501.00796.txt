{
  "article_text": [
    "an explanation for the observed accelerated expansion of the universe still eludes cosmologists .",
    "the evidence for the existence of dark energy ( de ) , which is believed to source this acceleration @xcite , has been continuously piling since the first indications from supernovae ( sneia ) observations @xcite .",
    "thanks to the abundance of good quality data cosmology has become a precision science . but even in this era of data driven cosmology we know little about constituents of our universe .",
    "there are several large cosmological surveys that are aiming to answer some of the key question in cosmology today , like : what is the source of the acceleration of the universe and what are the properties of this mysterious source .",
    "further , there are many ambitious projects that are planned for the future @xcite . in this scenario",
    "it is important to check whether the measurements coming from various surveys are consistent with each other .",
    "this is crucial since multiple probes are often combined to put better constraints on cosmological parameters .",
    "considered together , one data set resolves the difficulties of the other , allowing certain degenerate parameters to be determined with far greater precision .",
    "a consistency check would also help us to examine different data sets for the presence of systematics .",
    "knox et al . , examined consistency of the different cosmic microwave background data sets to check whether the data are contaminated by some residual non - cosmological signals @xcite .",
    "avgoustidis et al . , studied the consistency among sneia , measurements of the hubble parameter , and the baryon acoustic oscillation scale . regarding the tension between the baryon acoustic oscillation scale and sneia data in light of possible deviations from transparency",
    ", they concluded that the source of the discrepancy may most likely be found among systematic effects of the modelling of the low redshift data , or it may be a statistical fluke @xcite .",
    "shafieloo et al . , compared two different probes of the expansion history of the universe , namely , luminosity distances from sneia and angular diameter distance from galaxy clusters .",
    "they proposed a model independent method to search for inconsistencies between sneia and galaxy cluster data sets @xcite .",
    "more recently , hazra and shafieloo studied the consistency of the angular power spectrum data from wmap and planck looking for possible systematics @xcite .",
    "cao and zhu used observational data with four angular diameter distance measurements and synthetic sneia+grb observations for luminosity distance data , to investigate the tension between these two cosmological distances considering three classes of dark energy equation of state reconstruction .",
    "they found that the angular diameter distance measurements and the luminosity distance data are compatible at @xmath4 level @xcite .",
    "ruiz and huterer tested the consistency of the standard @xmath5cdm model in the framework of general relativity by separating information between the geometry and growth of structure . using data from sneia , baryon acoustic oscillations , the peak locations in the cosmic microwave background angular power spectrum , redshift space distortions , weak gravitational lensing and the abundance of galaxy clusters , and found that both geometry and growth separately favour the @xmath6cdm cosmology @xcite .    in this work",
    "we look for consistency in distance and age measurement data sets using the distance duality ( dd ) relation .",
    "we use baryon acoustic oscillation ( bao ) and sneia data for distance measurements and observational hubble data as age measurement .",
    "the plan of the paper is as follows : we begin with a brief overview of dd relation in section [ ddr ] , in section [ met ] we discuss data sets used and a quick over - view of gaussian processes which is the methodology used here , we discuss our results in section [ res ] .",
    "in 1933 etherington proved the reciprocity relation in area distances , between a source and an observer in relative motion with each other @xcite .",
    "this relation is valid for any curved spacetime , and even basic symmetry assumptions like homogeneity and isotropy are not required .",
    "the relation holds as long as gravity is described by a metric theory , photons travel on null geodesics and the geodesic deviation equation is valid @xcite .",
    "if photon number is conserved this further reduces to a relation between the angular diameter distance and the luminosity distance @xcite : @xmath7 this is termed as the dd relation and plays an important role in galaxy cluster observations and lensing studies @xcite .",
    "since dd is crucial to cosmological studies and plays a key role in how galaxy observations are analysed , it is important to check its validity . since both the distances in the duality relation are observable quantities it is possible to test this relation .",
    "now , there are many ways in which cosmic distances are measured .",
    "one can look for sources that can be used as standard candles for deriving luminosity distance , and standard rulers can be used to derive angular diameter distance .",
    "sneia can be used as standard candles since they have a peak luminosity that is tightly correlated with the shape of their light curves and hence they can be calibrated . on the other hand , combined measurements of the sunyaev - zeldovich effect and x - ray analysis ( sze / x - ray ) provides a measure of the angular diameter distance to a cluster .",
    "the baryon acoustic feature in the matter clustering is another independent distance indicator and can be used as a standard ruler . as observed in previous works ( @xcite ) ,",
    "the constraints on the dd obtained from galaxy cluster measurements , depend on the assumptions of cluster geometry ( spherical or elliptical ) . hence assuming dd to be true , one can use it as a probe of cluster geometry .",
    "dd has also been used to constrain the cosmic opacity between different redshifts .",
    "one of the assumptions in dd , is the conservation of photon number .",
    "hence , the temperature redshift relation , relating the observed and emitted temperature of the cosmic microwave background photons , which derives from dd , also assumes photon conservation .",
    "the relation will be modified if this assumption was violated .",
    "there are many mechanisms that have been proposed in literature which give rise to such a violation , for example decaying vacuum cosmology , photon axion coupling etc .. in this regard , there have been several attempts to measure the cosmic microwave background temperature at different redshifts , using , for example , quasar absorption line spectra and this can be used to test the validity of the temperature shift relation .",
    "but since the uncertainties are large , more data is required to put robust constraints .",
    "testing the dd offers another way to confirm photon conservation .",
    "assuming there are some unclustered sources of photon attenuation in the universe , one can use dd to put constraints on the difference in opacity between two redshifts . refer to @xcite for details of such studies .",
    "as mentioned earlier , we use sneia , bao and observational hubble data to constrain dd ( details of the data sets given in [ data ] ) . since sneia are expected to form from standard explosion of a white dwarf , they are assumed to have homogeneous light curve and uniform luminosity .",
    "although there is an intrinsic scatter in the peak luminosities of sneia , an empirical correlation exists between the shape of the sneia light curve and the sneia luminosity .",
    "hence these candles can be standardized , and are used as standard candles for estimating luminosity distances .",
    "observational hubble data is obtained from the measurement of the relative ages of passively evolving galaxies .",
    "the hubble rate depends on the differential age of the universe as : @xmath8 and hence the determination of @xmath9 gives an estimate of @xmath2",
    ". for this one has to look for the variation of ages , @xmath10 , with redshift @xmath11 .",
    "collection of galaxy samples of passively evolving galaxies with high quality spectroscopy , are used and differential ages for the samples are computed .",
    "these are then used as estimates of @xmath9 which eventually gives an estimate of @xmath2 .",
    "bao refers to a length scale in the distribution of the photons and baryons .",
    "this scale is imprinted in the matter distribution due to the stalling of sound waves in the plasma of the early universe , and hence they can be treated as cosmological standard rulers . enough bao data has not been accumulated to separately measure the tangential and radial components of the signal , and hence the two distances .",
    "but it is possible to constrain an angle - averaged clustering measurement , obtained from the combination of two spatial dimensions orthogonal to the line of sight and one dimension along the direction of sight , as defined below @xcite : @xmath12 where , @xmath13 is the angular diameter distance , @xmath14 is the redshift and @xmath15 is the hubble rate .",
    "if the dd relation holds , then we know that the luminosity distance and the angular diameter distance are related as @xmath16 .",
    "let us assume @xmath17 where @xmath18 if the dd relation holds .",
    "using this we can rewrite ( [ dv ] ) as @xmath19 now , if the distance measurements and the age measurements are consistent with each other , and the dd holds then @xmath20 in ( [ eta ] ) should be equal to @xmath21 .",
    "a deviation from @xmath21 may imply the breakdown of one or more of the assumptions mentioned earlier or it may indicate the presence of some systematic in the data sets used .",
    "many authors have studied the dd relation using various data sets ( @xcite ) .",
    "constraints obtained from using cluster data for the angular diameter distance estimate depends on the galaxy cluster model assumed .",
    "since we are using bao data for the angular diameter distance estimate our constraints does not contain such biases .",
    "another source of error in the analysis of dd is that it is not always possible to obtain a luminosity distance estimate and an angular diameter distance estimate at the same redshift , and some kind of redshift - matching criteria is adopted . in this work",
    "we reconstruct all the observable quantities ( @xmath2 , @xmath1 and @xmath0 ) in the redshift range of interest using a non - parametric method called gaussian processes and then estimate @xmath20 using these quantities .",
    "as mentioned earlier we take @xmath1 measurements from bao data , @xmath0 measurements from sneia data , and @xmath2 measurements from the observational hubble data obtained from differential ages of passively evolving galaxies , to check the above relation .",
    "the details of the data sets are given in the next section .      *",
    "to estimate the luminosity distance @xmath0 at various redshifts we use the distance modulus measurements from sneia union2.1 sample , as given in @xcite .",
    "this sample contains @xmath22 supernovae and spans @xmath23 . in the data set , the distance modulus is given in terms of the redshift , and this is used to estimate the luminosity distance .",
    "the relation between the distance modulus @xmath24 and the luminosity distance @xmath25 is : @xmath26 where @xmath27 is the absolute magnitude of the source and @xmath28 is the apparent magnitude ( @xmath29 is for @xmath29-band ) .",
    "* we use eight measurements from bao data compiled from different groups in the redshift range @xmath30 .",
    "we use data from sdss ( @xmath31 and @xmath32 ) , 6dfgs(@xmath33 ) , wigglez(@xmath34 ) and boss(@xmath35 ) for estimating the distance @xcite .",
    "* we also use the observational hubble data as compiled in @xcite . note here that we only use those data points which are obtained from the analysis of differential ages of galaxies .      a gaussian process ( gp ) is a collection of random variables , any finite number of which have a joint gaussian distribution @xcite .",
    "just like a gaussian distribution is a distribution of a random variable ( characterized by a mean and a covariance ) , a gp is a distribution over functions .",
    "it is characterized by a mean function and a covariance matrix . in a regression analysis",
    "the aim is to infer the relation between independent and dependent variables , given some set of observations . in parametric regression",
    "we assume some functional relation between the output and the input @xmath36 , where @xmath37 represents the set of model parameters , and regression requires finding the values of @xmath37 which best describe the data .",
    "usually , the chi - squared merit function is minimized to obtain the best fit parameters .",
    "similarly in gp regression , the function @xmath38 is represented as @xmath39 which means that the value of @xmath38 at any point @xmath40 , is a gaussian random variable with mean @xmath41 and covariance @xmath42 : @xmath43 there are many choices for the covariance functions : squared exponential , spline , polynomial etc .",
    "here we chose the commonly used squared exponential function for its simplicity .",
    "the squared exponential covariance function is expressed as : @xmath44 this covariance functions is parameterized by the two parameters , @xmath45 and @xmath46 ( known as hyperparameters ) , which represent the length scales in the gp .",
    "@xmath45 controls the variation in @xmath38 relative to the mean and @xmath46 corresponds to the correlation length along which the successive @xmath38 values are correlated . as desired , the covariance is maximum for variables whose inputs are very close which is expected for smooth functions .",
    "the matrix elements of the covariance matrix for the gp : @xmath47 , are given by @xmath48_{i , j}=k(x_i , x_j).\\ ] ] similar to the function @xmath38 , the data @xmath49 can also be represented using gp : @xmath50 now , given a set of inputs @xmath51 ( also called training vectors ) , outputs @xmath49 ( the data set , also called target ) , and the covariance matrix @xmath52 , our aim is to make inference about the function @xmath38 at some other points @xmath53 .",
    "the joint probability distribution for the data @xmath49 and the reconstructed function @xmath54 is given by @xmath55 where @xmath56 and @xmath57 are the assumed means ( initial guesses ) and @xmath58 is the covariance matrix of the data , which is diagonal if the data points are uncorrelated .",
    "after some matrix algebra one can rewrite the joint probability distribution as ( please see @xcite or @xcite for more details of the calculations ) @xmath59\\\\ \\frac{1}{(2\\pi)^{q/2 } |{\\bf a}|^{1/2 } } \\exp [ -\\frac{1}{2 } ( { \\bf \\hat{f}}-{\\bf a})^t { \\bf a}^{-1}({\\bf \\hat{f}}-{\\bf a})],\\end{gathered}\\ ] ] where @xmath60 @xmath61 and @xmath62 here @xmath63 and @xmath64 are the number of points in @xmath51 and @xmath53 respectively",
    ". the marginal distribution of @xmath49 is given by @xmath65 , \\label{margp}\\ ] ] and the conditional distribution @xmath66 is @xmath67,\\ ] ] which implies that the reconstructed function @xmath68 has a gaussian normal distribution given by @xmath69 here @xmath45 and @xmath46 are unknown parameters of the gp and training of a gp involves selecting appropriate values for these parameters .",
    "this is usually done by maximising the marginal log - likelihood probability @xmath70 ( from ( [ margp ] ) ) @xmath71^{-1 } ( { \\bf y}-{\\boldsymbol \\mu } ) \\\\",
    "-\\frac{1}{2 } \\ln |{\\bf k(x , x)+c}|-\\frac{p}{2 } \\ln 2 \\pi .",
    "\\label{gpe}\\end{gathered}\\ ] ] further , to do the analysis one needs to specify an input mean function .",
    "we chose the initial mean function for all quantities to correspond to a flat @xmath6cdm model with @xmath72 , and @xmath73 km / sec / mpc .",
    "the means are adjusted during the analysis and replaced by posterior means suggested by preliminary runs .",
    "our redshift range of interest is @xmath3 ( governed by the bao data range ) .",
    "we divide this redshift range into intervals of @xmath74 .",
    "this gives us @xmath75 target points ( @xmath14 values at which the functions are reconstructed ) .",
    "we then reconstruct @xmath2 , @xmath0 and @xmath1 at these points using gp regression .",
    "this implies that for each @xmath14 target point we have a mean and a variance of the reconstructed functions given by ( [ mean ] ) and ( [ var ] ) respectively .",
    "note that maximising ( [ gpe ] ) is an approximation , and can be used if the posterior for @xmath37 , is fairly well peaked .",
    "since this is not always guaranteed , in our analysis , we sample the hyperparameter space and the probability distributions of the reconstructed function are weighted by the posterior distributions of the hyperparameters ( in effect we marginalize over the hyperparameters ) .",
    "samples from these weighted distributions of @xmath2 , @xmath0 and @xmath1 are used to eventually construct @xmath76 as given in ( [ eta ] ) .",
    "note here that @xmath76 itself is not a gp , i.e. it is not constructed with gp methodology .",
    "it is derived using and the errors on @xmath76 are obtained using error propagation ( including covariances at different redshifts ) .",
    "( solid blue curve ) as function of @xmath14 .",
    "the dashed , dotted and dot - dashed black curve represent @xmath21 , @xmath77 and @xmath78 confidence levels respectively .",
    "solid red line represents @xmath79,scaledwidth=45.0% ]",
    "in this paper we have used dd relation as a check for consistency between different data sets .",
    "the main result of the paper is summarised in figure [ etafig ] , where we plot the variation of @xmath20 with redshift , as estimated from the gp reconstruction of the luminosity distance , angle averaged distance and the hubble rate .",
    "the solid blue line is the best fit curve and the black curves around it represent the confidence intervals .",
    "the red horizontal line is the value of @xmath20 when dd holds ( and all the data sets are consistent with each other ) .",
    "note that the error bars in this plot should be understood as point by point along the redshift .",
    "the estimates of the three reconstructed quantities ( @xmath2 , @xmath0 and @xmath1 ) have correlations at different redshifts and so will the estimates of @xmath76 , but these correlations are not visible in this plot .",
    "we observe that the dd holds within 3@xmath80 confidence level .",
    "these model independent constraints are better than our previous constraints on @xmath20 ( @xcite ) , where we took some simple parametrization for @xmath20 and fixed @xmath2 assuming @xmath6cdm cosmology .",
    "further the mean value of @xmath20 is slightly less than unity .",
    "this is similar to results obtained in earlier works in this direction .",
    "uzan et al .",
    "@xcite , found a best fit value for @xmath20 which was slightly less than one and related this trend to the systematics in the sze / x - ray analysis of galaxy clusters , assuming @xmath6cdm cosmology .",
    "bassett and kunz @xcite , in their three parameter model of dd violation , also found that the sneia sample they used were brighter relative to their @xmath81 data , .",
    "gravitational lensing of the high - z supernovae was suggested as a possible explanation .",
    "nesseris and garcia - bellido recently used genetic algorithm approach to extract model independent and bias- free reconstruction information from sneia , bao and the growth rate of matter perturbations @xcite .",
    "our result is moderately consistent with their analysis , but we do not recover the dip in @xmath20 in the range @xmath82 , that they obtain in their reconstruction .",
    "@xmath20 can also be assumed to be a constant ( other than unity ) and the value of the constant can be estimated from observations , see for example one of our previous works @xcite , uzan et al . , @xcite or bernadis et al @xcite .",
    "our model independent method can also be used to test dd relation if the data sets are known to be consistent with each other .",
    "if this relation is found to be inconsistent with observations , it would be a major problem for observational cosmology , since the optical theorem that relates surface brightness of an object at the source and observer , and the temperature shift relation of the cosmic microwave background are derived from this relation ( @xcite ) . in the event that the dd relation is not valid , these key relations in cosmology would have to be modified .",
    "future surveys ( especially the increase in bao data points ) would better constrain @xmath20 and this method can be used to look for the presence of systematics within the data sets .",
    "rn acknowledges support under csir - srf scheme ( govt . of india ) .",
    "dj thanks a. mukherjee and s. mahajan for providing the facilities to carry out research , and ctp ( jmi ) for research support .",
    "sj acknowledge support from grant under isro - respond program ( isro / res/2/384/2014 - 15 ) .",
    "supernova search team collaboration , riess a. g. et al .",
    ",  * 116 * ( 1998 ) 1009 [ astro - ph/9805201 ] ; supernova cosmology project collaboration , perlmutter s. et al . ,  * 517 * ( 1999 ) 565 [ astro - ph/9812133 ] ; snls collaboration , astier p. et al . ,  * 447 * ( 2006 ) 31 [ astro - ph/0510447 ] .",
    "sloan digital sky survey ( sdss ) : http://www.sdss3.org ; + giant magellan telescope ( gmt ) : http://www.gmto.org ; + james webb space telescope ( jwst ) : www.jwst.nasa.gov ; + euclid survey : http://sci.esa.int/euclid ; + dark energy survey : http://sci.esa.int/euclid ; + large synoptic survey telescope ( lsst ) : http://www.lsst.org .",
    "temple g. , _ proc .",
    "_ a  * 168 * ( 1938 ) 122 ; kristian j. & sachs r. k. ,  * 143 * ( 1966 ) 379 ; linder e. v. ,  * 206 * ( 1988 ) 190 ; schneider p. , ehlers j. & falco e. e. , _ gravitational lenses _ , springer - verlag , berlin germany ( 1992 ) .",
    "holanda r. f. l. , lima j.a.s . &",
    "ribeiro m.b . ,  * 528 * ( 2011 ) l14 ; li z. et al . ,  * 729 * ( 2011 ) l14 ; holanda r.f.l .",
    ", goncalves r. s. , & alcaniz j.s , jcap  * 06 * ( 2012 ) 022 ; cardone v.f .",
    "et al . ,  * 85 * ( 2012 ) 123510 [ arxiv:1205.1908 ] ; meng xiao - lei et al . ,  * 754 * ( 2012 ) 98 [ arxiv:1104.2833 ] ; zhang y. , [ arxiv:1408.3897 ] .",
    "rasmussen c. and williams c. , _",
    "gaussian processes for machine learning _ , mit press , cambridge u.s.a .",
    "( 2006 ) ; williams c. , _ prediction with gaussian processes : from linear regression to linear prediction and beyond , in learning in graphical models _ , m.i .",
    "jordan eds . , mit press , cambridge u.s.a . ( 1999 ) ; mackay d. , _ information theory , inference and learning algorithms _ , cambridge university press , cambridge u.k ."
  ],
  "abstract_text": [
    "<S> we present a model independent method to test the consistency between cosmological measurements of distance and age , assuming the distance duality relation . </S>",
    "<S> we use type ia supernovae , baryon acoustic oscillations , and observational hubble data , to reconstruct the luminosity distance @xmath0 , the angle averaged distance @xmath1 and the hubble rate @xmath2 , using gaussian processes regression technique . </S>",
    "<S> we obtain estimate of the distance duality relation in the redshift range @xmath3 and we find no evidence for inconsistency between the data sets used . </S>"
  ]
}