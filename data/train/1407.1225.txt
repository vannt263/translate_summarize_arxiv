{
  "article_text": [
    "there is a vast literature on the nonparametric location - scale model @xmath0 , where @xmath1 , and @xmath2 are the covariates , response , and error , respectively .",
    "given observations @xmath3 , the latter model has been studied under various settings of data structure . in terms of the dependence structure , there are independent data and time series data scenarios ; in terms of the design point @xmath4 , there are random - design and fixed - design @xmath5 settings . in these settings",
    ", we usually assume that either @xmath6 are independent observations from subjects @xmath7 , or @xmath3 is a sequence of time series observations from the same subject .",
    "we refer the reader to fan and yao @xcite and li and racine @xcite for an extensive exposition of related works .    in this article , we are interested in the following nonparametric location - scale model with serially correlated data from multiple subjects : @xmath8 where , for each subject @xmath9 , @xmath10 is the sequence of covariates and responses , and @xmath11 is the corresponding error process .",
    "we study ( [ eq : model ] ) under a general dependence framework for @xmath12 that allows for both longitudinal data and some spatially correlated data . in typical longitudinal studies",
    ", @xmath13 represents measurement time or covariates at time @xmath14 , then it is reasonable to assume that @xmath15 is a causal time series , that is , the current observation depends only on past but not future observations .",
    "in other applications , however , measurements may be dependent on both the left and right neighboring measurements , especially when @xmath13 represents measurement location .",
    "a good example of this type of data is the vertical density profile data in walker and wright @xcite ; see also section  [ sec : exm ] for more details . to accommodate this",
    ", we propose a general error dependence structure , which can be viewed as an extension of the one - sided causal structure in wu @xcite and dedecker and prieur @xcite to a two - sided noncausal setting .",
    "the proposed dependence framework allows for many linear and nonlinear processes .",
    "we are interested in nonparametric estimation of the location function @xmath16 and the scale function @xmath17 .",
    "least - squares based nonparametric methods have been extensively studied for both time series data ( fan and yao @xcite ) and longitudinal data ( hoover _ et al . _",
    "@xcite , fan and zhang @xcite , wu and zhang @xcite , yao , mller and wang @xcite ) .",
    "while they perform well for gaussian errors , least - squares based methods are sensitive to extreme outliers , especially when the errors have a heavy - tailed distribution .",
    "by contrast , robust estimation methods impose heavier penalty on far - deviated data points to reduce the impact from extreme outliers . for example , median quantile regression uses the absolute loss and the resultant estimator is based on sample local median . since koenker and bassett @xcite , quantile regression has become popular in parametric and nonparametric inferences and we refer the reader to yu , lu and stander @xcite and koenker @xcite for excellent expositions .",
    "recently , he , fu and fung @xcite , koenker @xcite and wang and fygenson  @xcite applied quantile regression techniques to parameter estimation of parametric longitudinal models , he , zhu and fung @xcite studied median regression for semiparametric longitudinal models , and wang , zhu and zhou @xcite studied inferences for a partially linear varying - coefficient longitudinal model . here",
    "we focus on quantile regression based estimation for the nonparametric model ( [ eq : model ] ) .",
    "we aim to study the asymptotic properties , including uniform bahadur representations and asymptotic normalities , of the least - absolute - deviation or median quantile estimates for model  ( [ eq : model ] ) under a general dependence structure .",
    "nonparametric quantile regression estimation has been studied mainly under either the i.i.d . setting ( bhattacharya and gangopadhyay  @xcite , chaudhuri @xcite , yu and jones @xcite ) or the strong mixing setting ( truong and stone  @xcite , honda  @xcite , cai @xcite ) .",
    "there are relatively scarce results on bahadur representations of conditional quantile estimates .",
    "bhattacharya and gangopadhyay @xcite and chaudhuri @xcite obtained point - wise bahadur representations for conditional quantile estimation of i.i.d . data . for mixing stationary processes , honda @xcite obtained point - wise and uniform bahadur representations of conditional quantile estimates . for stationary random fields , hallin , lu and",
    "yu @xcite obtained a point - wise bahadur representation for spatial quantile regression function under spatial mixing conditions . due to the nonstationarity and dependence structure",
    ", it is clearly challenging to establish bahadur representations in the context of ( [ eq : model ] ) .",
    "our contribution here is mainly on the theoretical side .",
    "we establish uniform bahadur representations for the least - absolute - deviation estimates of @xmath16 and @xmath18 in ( [ eq : model ] ) . to derive the uniform bahadur representations ,",
    "the key ingredient is to study the modulus of continuity of certain kernel weighted empirical processes of the nonstationary observations @xmath19 in ( [ eq : model ] ) .",
    "empirical processes have been extensively studied under various settings , including the i.i.d . setting ( shorack and wellner @xcite ) , linear processes ( ho and hsing @xcite ) , strong mixing setting ( andrews and pollard @xcite , shao and yu @xcite ) , and general causal stationary processes ( wu @xcite ) . using a coupling argument to approximate the dependent process by an @xmath20-dependent process with a diverging @xmath20 , we study the modulus of continuity of weighted empirical processes , and the latter result serves as a key tool in establishing our uniform bahadur representations .",
    "these bahadur representations provide deep insights into the asymptotic behavior of the estimates , and in particular they provide theoretical justification for the profile control chart methodologies in wei , zhao and lin @xcite .",
    "these technical treatments are also of interest in other nonparametric problems involving dependent data .",
    "the article is organized as follows . in section  [ sec : dependence ] , we introduce the error dependence structure with examples . in section  [ sec : coupling ] , we study weighted empirical process through a coupling argument . section  [ sec : main ] contains uniform bahadur representations and asymptotic normality .",
    "section  [ sec : app ] contains an illustration using progesterone data .",
    "possible extensions to spatial setting are discussed in section  [ sec : dis ] .",
    "proofs are provided in section  [ sec : proof ] .",
    "first , we introduce some notation used throughout this article . for @xmath21 ,",
    "let @xmath22 be the integer part of @xmath23 , @xmath24 , and @xmath25 . for a random variable @xmath26 ,",
    "if @xmath27^{1/q } < \\infty$ ] .",
    "let @xmath28 be the set of functions with bounded derivatives up to order @xmath29 on a set @xmath30 .",
    "assume that , for each @xmath9 , the error process @xmath31 in ( [ eq : model ] ) is an independent copy from a stationary process @xmath32 which has the representation @xmath33 where @xmath34 , are i.i.d .",
    "random innovations , and @xmath35 is a measurable function such that @xmath36 is well defined",
    ". we can view ( [ eq : error ] ) as an input - output system with @xmath37 , and @xmath36 being , respectively , the input , filter , and output .",
    "wu @xcite considered the causal time series case that @xmath36 depends only on the past innovations @xmath38 in contrast , ( [ eq : error ] ) allows for noncausal models and is particularly useful for applications that do not have a time structure .",
    "for example , if @xmath13 are locations , then the corresponding measurement @xmath39 depends on both the left and right neighboring measurements .",
    "[ con : dc ] let @xmath40 be i.i.d .",
    "copies of @xmath41 .",
    "there exist constants @xmath42 and @xmath43 such that @xmath44    in ( [ eq : gmc ] ) , @xmath45 can be viewed as a coupling process of @xmath46 with @xmath47 replaced by the i.i.d .",
    "copy @xmath48 while keeping the nearest @xmath49 innovations @xmath50 . in particular ,",
    "if @xmath46 does not depend on @xmath47 , then @xmath51 .",
    "thus , @xmath52 quantifies the contribution of @xmath47 to @xmath46 , and ( [ eq : gmc ] ) states that the contribution decays exponentially in @xmath53 .",
    "shao and wu  @xcite and dedecker and prieur @xcite [ cf .",
    "equation ( 4.2 ) therein ] considered one - sided causal version of ( [ eq : gmc ] ) where @xmath46 depends only on @xmath54 .",
    "propositions [ pro : h][pro : e ] below indicate that , if @xmath55 satisfies ( [ eq : gmc ] ) , then its properly transformed process also satisfies ( [ eq : gmc ] ) .    [ pro : h ] for @xmath56 and @xmath57 , define the collection of functions @xmath58 @xmath59 is a constant .",
    "suppose @xmath60 satisfies ( [ eq : gmc ] ) .",
    "then the transformed process @xmath61 satisfies ( [ eq : gmc ] ) with @xmath62 replaced by @xmath63 and @xmath64 .    in ( [ eq : hfunc ] ) ,",
    "@xmath65 is the class of uniformly hlder - continuous functions with index @xmath66 . if @xmath67 , then @xmath68 .",
    "clearly , all functions in @xmath65 are continuous .",
    "interestingly , for noncontinuous transformations , the conclusion may still hold ; see proposition [ pro : e ] below , where @xmath69 is the indicator function .",
    "[ pro : e ] let @xmath46 have a bounded density .",
    "suppose @xmath60 satisfies ( [ eq : gmc ] ) .",
    "then , for any given  @xmath70 , @xmath71 satisfies ( [ eq : gmc ] ) with @xmath72 replaced by @xmath73 .    propositions [ pro : h][pro : e ] along with the examples below show that the error structure ( [ eq : error ] ) and condition [ con : dc ] are sufficiently general to accommodate many popular linear and nonlinear time series models and their properly transformed processes .",
    "[ exmp : mdep ] assume that @xmath74 for a measurable function @xmath35 .",
    "then @xmath36 depends only on the nearest @xmath75 innovations @xmath76 .",
    "clearly , @xmath77 form a @xmath78-dependent sequence , @xmath79 for @xmath80 , and ( [ eq : gmc ] ) trivially holds .",
    "if @xmath81 , then @xmath36 are i.i.d . random variables .",
    "[ exmp : vlp ] consider the noncausal linear process @xmath82 . if @xmath83 and @xmath84 , then it is easy to see that ( [ eq : gmc ] ) holds .",
    "[ exmp : irf ] consider random variables @xmath36 defined by @xmath85 where @xmath34 , are i.i.d .",
    "random innovations , and @xmath86 is a random map .",
    "many widely time series models are of form ( [ eq : nar ] ) , including threshold autoregressive model @xmath87 , autoregressive conditional heteroscedastic model @xmath88 , random coefficient model @xmath89 , and exponential autoregressive model @xmath90 e_{j-1 } + \\varepsilon_j$ ] , among others .",
    "suppose there exists @xmath91 such that @xmath92 and there exist constants @xmath93 such that @xmath94 holds for all @xmath95 . by shao and",
    "wu @xcite , ( [ eq : gmc ] ) holds .      the imposed dependence structure and hence the developed results in sections  [ sec : coupling][sec : main ] below are potentially applicable to a wide range of practical data types .",
    "we briefly mention some below .",
    "( _ time series data _ ) . in the special case of @xmath96 , @xmath97 and @xmath98 for a stationary time",
    "series @xmath60 , ( [ eq : model ] ) becomes the usual nonparametric location - scale model @xmath99 with time series data .",
    "the latter model has been extensively studied under both the random - design case and the fixed - design case @xmath100 .",
    "see fan and yao @xcite for an excellent introduction to various local least - squares based methods under mixing settings .",
    "quantile regression based estimations have been studied in truong and stone @xcite , honda @xcite , and cai @xcite for mixing processes . despite the popularity of mixing conditions , it is generally difficult to verify mixing conditions even for linear processes .",
    "for example , for the autoregressive model @xmath101 $ ] , where @xmath102 are i.i.d .",
    "bernoulli random variables @xmath103 , the stationary solution is not strong mixing ( andrews  @xcite ) .",
    "by contrast , as shown above , the imposed condition [ con : dc ] is easily verifiable for many linear and nonlinear time series models and their proper transformations .",
    "( _ longitudinal data _ ) . for each subject @xmath9 , if @xmath13 is the @xmath14th measurement time or the covariates at time @xmath14 , @xmath19 is the corresponding response , and @xmath12 is a stationary causal process [ e.g. , @xmath104 in ( [ eq : error ] ) depends only on the past ] , then ( [ eq : model ] ) becomes a typical longitudinal data setting .",
    "for example , section  [ sec : app2 ] re - examines the well - studied progesterone data using the proposed methods .",
    "another popular longitudinal data example is the cd4 cell percentage in hiv infection from the multicenter aids cohort study .",
    "based on least - squares methods , this data has been studied previously in hoover _",
    "_ @xcite and fan and zhang @xcite .",
    "we can examine how the response function ( cd4 cell percentage ) varies with measurement time ( age ) using the proposed robust estimation method in section  [ sec : main ] .",
    "( _ spatially correlated data _ ) . in the vertical density data of walker and wright @xcite",
    ", manufacturers are concerned about engineered wood boards density , which determines fiberboard s overall quality .",
    "for each board , densities are measured at various locations along a designated vertical line . in this example , measurements depend on both the left and right neighboring measurements , and it is reasonable to impose the dependence structure ( [ eq : error ] ) .",
    "see wei , zhao and lin @xcite for a detailed analysis .",
    "also , as will be discussed in section  [ sec : dis ] , the two - sided framework ( [ eq : error ] ) can be extended to spatial lattice settings .",
    "we point out that the structure in ( [ eq : model ] ) and ( [ eq : error ] ) differs from the usual spatial model setting in the sense that ( [ eq : model ] ) allows for observations from multiple independent subjects whereas the latter usually assumes that all observations are spatially correlated ( see , e.g. , hallin , lu and yu @xcite for quantile regression of spatial data ) .",
    "in this section , we study weighted empirical processes through a coupling argument . dependence is the main difficulty in extending results developed for independent data to dependent data . for mixing processes , the widely used large - block - small - block technique partitions the data into asymptotically independent blocks . here",
    ", we adopt a coupling argument which copes well with the dependence structure in section  [ sec : dependence ] .",
    "we now illustrate the basic idea . by ( [ eq : error ] ) , the error @xmath105 in ( [ eq : model ] ) has the representation @xmath106 for i.i.d .",
    "innovations @xmath107 .",
    "thus , @xmath108 is a dependent series for each fixed @xmath9 , whereas @xmath109 and @xmath110 are two independent series for @xmath111 .",
    "let @xmath112 , be i.i.d .",
    "copies of @xmath113 . for @xmath114 , define the coupling process of @xmath105 as @xmath115 by replacing all but the nearest @xmath116 innovations with i.i.d . copies .",
    "we call @xmath117 the coupling lag . clearly , @xmath118 has the same distribution as @xmath105 .    by construction , for each fixed @xmath9 , @xmath119 form @xmath120-dependent sequence in the sense that @xmath118 and @xmath121 are independent if @xmath122 .",
    "consequently , for each fixed @xmath9 and @xmath123 , @xmath124 are i.i.d .",
    "the latter property helps us reduce the dependent data to an independent case . on the other hand , under ( [ eq : gmc ] ) , @xmath125 is sufficiently small with properly chosen @xmath117 and hence the coupling process is close enough to the original one .",
    "similarly , for @xmath19 in ( [ eq : model ] ) , define its coupling process : @xmath126    first , we present a general result regarding the sum of functions of the coupling process @xmath127 .",
    "let @xmath128 be any finite set . for real - valued functions",
    "@xmath129 , defined on @xmath130 such that @xmath131=0 $ ] for all @xmath132 , define @xmath133 throughout , let @xmath134 be the total number of observations .",
    "[ thmm : cp ] assume that the cardinality @xmath135 of @xmath128 and the coupling lag @xmath117 grow no faster than a polynomial of @xmath136 .",
    "further assume @xmath137 for a constant @xmath138 , and for some sequence @xmath139 , @xmath140 \\le \\chi_n.\\ ] ]    if @xmath141 , then @xmath142 .    if @xmath143 , then @xmath144 $ ] .    by theorem [ thmm : cp ] ,",
    "the magnitude of latexmath:[$\\max_{v\\in\\mathcal{v}_n }    intuitively , as @xmath117 increases , there is stronger dependence in the coupling process @xmath127 and consequently a larger bound for @xmath146 . therefore , a small @xmath117 is preferred in order to have a tight bound for @xmath146 . on the other hand ,",
    "a reasonably large @xmath117 is needed in order for the coupling process to be sufficiently close to the original process . under ( [ eq : gmc ] ) , for @xmath147 , the coupling process converges to the original one at a polynomial rate , and meanwhile the maximum bound in theorem [ thmm : cp ] is optimal up to a logarithm factor .",
    "for example , if @xmath141 , then @xmath148 $ ] ; if @xmath143 , then @xmath149^{1/2}\\}$ ] .    in what follows",
    ", we consider the special case of weighted empirical process , which plays an essential role in quantile regression .",
    "let @xmath150 be nonrandom weights that may depend on  @xmath70 .",
    "consider the weighted empirical process @xmath151 to study @xmath152 , recall @xmath127 in ( [ eq : yij2 ] ) and define the coupling empirical process @xmath153 under mild regularity conditions , theorem [ lem : appr ] below states that @xmath152 can be uniformly approximated by @xmath154 with proper choice of the coupling lag @xmath117 .",
    "[ assump : r ] @xmath155 uniformly for some constant @xmath138 .",
    "@xmath156 is uniformly bounded .",
    "@xmath157 is uniformly bounded away from zero and infinity .",
    "[ lem : appr ] assume that conditions [ con : dc ] and [ assump : r ] hold . in ( [ eq : couple ] ) ,",
    "let the coupling lag @xmath158 for some @xmath159 $ ] , where @xmath134",
    ". then @xmath160.\\ ] ]    to study asymptotic bahadur representations of quantile regression estimates , a key step is to study the modulus of continuity of @xmath152 , defined by @xmath161 \\bigr\\ } - \\bigl\\ { f_n(x , y ) - { { \\mathbb{e}}}\\bigl [ f_n(x , y)\\bigr ] \\bigr\\}.\\end{aligned}\\ ] ] intuitively , @xmath162 measures the oscillation of the centered empirical process @xmath163 $ ] in response to a small perturbation @xmath164 in @xmath165 .    the dependence structure in section  [ sec : dependence ] along with the coupling argument provides a convenient framework to study @xmath162 .",
    "recall @xmath154 in ( [ eq : fn2 ] ) . for @xmath162 in ( [ eq : empdiff ] ) ,",
    "define its coupling process @xmath166 \\bigr\\ } - \\bigl\\ { \\tilde{f}_n(x , y ) - { { \\mathbb{e}}}\\bigl [ \\tilde{f}_n(x , y)\\bigr ] \\bigr\\}.\\end{aligned}\\ ] ] notice that @xmath118 and @xmath105 have the same distribution , so @xmath167={{\\mathbb{e}}}[\\tilde{f}_n(x , y)]$ ] . by theorem [ lem : appr ] , it is easy to see that , uniformly over @xmath168 , @xmath169.\\end{aligned}\\ ] ] therefore , the asymptotic properties of @xmath162 are similar to that of @xmath170 , which can be studied through theorem [ thmm : cp ] .",
    "[ assump : r2 ] @xmath171 outside a common bounded interval for all @xmath172 .",
    "there exist @xmath173 and @xmath174 such that @xmath175    [ pro : osc ] assume that conditions [ con : dc ] and [ assump : r][assump : r2 ] hold .",
    "further assume @xmath176,@xmath177 , and that @xmath178 grows no faster than a polynomial of @xmath136 . then @xmath179^{1/2}\\bigr\\}.\\end{aligned}\\ ] ]",
    "for a random variable @xmath180 , denote by @xmath181 the median of @xmath180 , and similarly denote by @xmath182 the conditional median operator . to ensure identifiability of @xmath183 and @xmath123 in ( [ eq : model ] ) , without loss of generality we assume @xmath184 and @xmath185 .",
    "note that @xmath186 . applying a kernel localization technique , we propose the following least - absolute - deviation or median quantile estimate of @xmath187 : @xmath188 for a nonnegative kernel function @xmath189 satisfying @xmath190 , and @xmath191 is a bandwidth .",
    "the estimate @xmath192 pools together information across all subjects , an appealing property especially when some subjects have sparse observations . by the bahadur representation in theorem [ thmm : m ] below",
    ", the bias term of @xmath193 is of order @xmath194 .",
    "following wu and zhao @xcite , we adopt a jackknife bias - correction technique . in ( [ eq : muest ] ) , denote by @xmath195 and @xmath196 the estimates of @xmath187 using bandwidth @xmath197 and @xmath198 , respectively .",
    "the bias - corrected jackknife estimator is @xmath199 which can remove the second - order bias term @xmath194 in @xmath200 .    after estimating @xmath16",
    ", we estimate @xmath17 based on residuals .",
    "notice that @xmath185 implies @xmath201 .",
    "therefore , we propose @xmath202 where @xmath203 is another bandwidth , and @xmath204 is the bias - corrected jackknife estimator in ( [ eq : mbias ] ) . as in ( [ eq : mbias ] ) , we adopt the following bias - corrected jackknife estimator @xmath205    [ rem : other ] by @xmath206 , an alternative estimator of @xmath207 is @xmath208 the difference between ( [ eq : sest ] ) and ( [ eq : sestot ] ) is that ( [ eq : sest ] ) uses @xmath204 whereas ( [ eq : sestot ] ) uses @xmath209 .",
    "since  @xmath189 has bounded support , only those @xmath13 s with @xmath210 contribute to the summation in  ( [ eq : sestot ] ) . thus , as @xmath211 so that @xmath212 and @xmath213 , the two estimators in ( [ eq : sest ] ) and  ( [ eq : sestot ] ) are expected to be asymptotically close .",
    "our use of ( [ eq : sest ] ) has some technical and computational advantages .",
    "first , the estimation error @xmath214 varies with @xmath215 , and thus it is technically more challenging to study ( [ eq : sestot ] ) .",
    "second , to implement ( [ eq : sestot ] ) , we need to compute @xmath216 at each point @xmath13 , which requires solving a large number of optimization problems in ( [ eq : muest ] ) for a large data set .",
    "by contrast , ( [ eq : sest ] ) only requires estimation of @xmath217 at those grid points @xmath70 at which we wish to estimate @xmath17 .    to study asymptotic properties , we need to introduce some regularity conditions .",
    "throughout we write @xmath218)=[a+\\epsilon , b-\\epsilon]$ ] for an arbitrarily fixed small @xmath219 .",
    "denote by @xmath220 and @xmath221 the distribution and density functions of @xmath46 in ( [ eq : error ] ) , respectively .",
    "the assumption @xmath222 and @xmath223 implies @xmath224 and @xmath225 .",
    "[ con : reg ] suppose that all measurement locations @xmath13 are within an interval @xmath226 $ ] , and order them as @xmath227 .",
    "assume that @xmath228    condition [ con : reg ] requires that the pooled covariates @xmath13 should be approximately uniformly dense on @xmath226 $ ] , which is a natural condition since otherwise it would be impossible to draw inferences for regions with very scarce observations .",
    "pooling all subjects together is an appealing procedure to ensure this uniform denseness even though each single subject may only contain sparse measurements .    in nonparametric regression problems , there are two typical settings on the design points : fixed - design and random - design points . for fixed - design case",
    ", it is often assumed that the design points are equally spaced on some interval .",
    "for example , for the vertical density profile data of walker and wright @xcite , the density was measured at equispaced points along a designated vertical line of wood boards .",
    "condition [ con : reg ] can be viewed as a generalization of the fixed - design points to allow for approximately fixed - design points . for random - design case ,",
    "the design points are sampled from a distribution .",
    "for example , assumption ( a ) in appendix a of fan and zhang  @xcite imposed the random - design condition . in practice ,",
    "both settings have different range of applicability .",
    "for example , for daily or monthly temperature series , the fixed - design setting may be appropriate ; for children s growth curve studies , it may be more reasonable to use the random - design setting since the measurements are usually taken at irregular time points .",
    "[ rem : random ] all our subsequent theoretical results are derived under the approximate fixed - design setting in condition [ con : reg ] , but the same argument also applies to the random - design case . specifically , assume that the design - points @xmath229 are random samples from a density @xmath230 with support @xmath226 $ ] and that @xmath70 is an interior point .",
    "then , for the design - adaptive local linear median quantile regression estimates , the subsequent theorems [ thmm : m][thmm : v ] and corollaries [ con : reg][con : lc ] still hold with @xmath231 therein replaced by @xmath232 . in fact , given the i.i.d .",
    "structure of @xmath229 , the technical argument becomes much easier .",
    "for example , to establish lemma [ lem:1 ] ( again , with @xmath231 therein replaced by @xmath232 ) , elementary calculations can easily find the mean and variance for the right - hand side of ( [ eq : lem1a ] ) .",
    "all other proofs can be similarly modified and we omit the details .",
    "conditions [ con : lc][con : regularity ] below are standard assumptions in nonparametric estimation .",
    "[ con : lc ] @xmath189 is symmetric and has bounded support and bounded derivative .",
    "write @xmath233    [ con : regularity ] @xmath234 ) , \\inf_{x\\in[a , b ] } s(x)>0 , f_e\\in { \\cal c}^4({{\\mathbb{r } } } ) , f_e(0 ) > 0 , f_e(1)+\\break f_e(-1)>0 $ ] .",
    "theorem [ thmm : m ] below provides an asymptotic uniform bahadur representation for @xmath200 in ( [ eq : muest ] ) , and its proof in section  [ sec : pfthm ] relies on the arguments and results in section  [ sec : coupling ] .",
    "[ thmm : m ] let @xmath200 be as in ( [ eq : muest ] ) .",
    "assume that conditions [ con : dc ] and [ con : reg][con : regularity ] hold .",
    "further assume @xmath235 and @xmath236 .",
    "then    we have the uniform consistency : @xmath237 ) } \\bigl|\\hat\\mu(x)-\\mu(x)\\bigr| = \\mathrm{o}_\\mathrm{p } \\biggl\\ { b^2_n + \\frac{(\\log n_n)^{3/2}}{(n_nb_n)^{1/2 } } \\biggr\\}.\\ ] ]    moreover , the bahadur representation @xmath238 holds uniformly over @xmath239)$ ] , where @xmath240 \\frac{\\mu'(x)}{s(x ) } , \\\\",
    "q_{b_n}(x ) & = & - \\sum^{n}_{i=1 } \\sum^{m_i}_{j=1 } \\bigl\\ { \\mathbf{1}_{y_{i , j}\\le\\mu(x ) } - { { \\mathbb{e}}}[\\mathbf{1}_{y_{i , j}\\le\\mu ( x)}]\\bigr\\ } k_{b_n}(x_{i , j}-x ) , \\\\ r_n & = & b^4_n + \\frac{b_n^{1/2 } ( \\log n_n)^{3/2}}{n_n^{1/2 } } + \\frac{(\\log n_n)^{9/4}}{(n_nb_n)^{3/4}}.\\end{aligned}\\ ] ]    in the bahadur representation ( [ eq : mbahadur ] ) , @xmath241 is the bias term , @xmath242 determines the asymptotic distribution of @xmath243 , and @xmath244 is the negligible error term .",
    "such a bahadur representation provides a powerful tool in studying the asymptotic behavior of @xmath200 .",
    "based on theorem [ thmm : m ] , we obtain a central limit theorem ( clt ) for @xmath245 in corollary [ cor : m ] .",
    "clearly , the variance of @xmath242 is a linear combination of @xmath246 .",
    "the following regularity condition is needed to ensure the negligibility of the cross - term @xmath246 for @xmath247 .    [",
    "con : clt ] assume that , for all given @xmath239)$ ] and @xmath147 , there exits @xmath248 such that @xmath249 and @xmath250,\\qquad   m_n=\\max_{1\\le i\\le n } m_i\\quad\\ ] ] for all @xmath251 , where @xmath252 .",
    "further assume that @xmath253 .",
    "condition [ con : clt ] is very mild .",
    "intuitively , we consider @xmath254 , being random locations , then @xmath255=\\mathrm{o}(b^2_n)$ ] for @xmath247 . thus , under the mild condition @xmath256 , ( [ eq : conclt ] ) holds with @xmath257 .",
    "[ cor : m ] let the conditions in theorem [ thmm : m ] be fulfilled and condition [ con : clt ] hold .",
    "further assume that @xmath258 and @xmath259 , where @xmath260 is defined as in ( [ eq : conclt ] ) .",
    "then , for any @xmath261)$ ] , we have @xmath262 \\rightarrow n \\biggl(0 , \\frac { \\varphi_k ( b - a)s^2(x ) } { 4 f^2_e(0 ) } \\biggr).\\ ] ]    the proof of corollary [ cor : m ] , given in section  [ sec : clt ] , uses the coupling argument in section  [ sec : coupling ] .",
    "the condition @xmath263 is in line with the classical clt lindeberg condition that none of the subjects dominates the others .",
    "if @xmath197 is of the order @xmath264 , then the bandwidth condition in corollary [ cor : m ] holds if @xmath265 . by corollary [ cor : m ] ,",
    "the optimal bandwidth minimizing the asymptotic mean squared error is @xmath266^{1/5 } n^{-1/5}_n.\\ ] ] for this optimal bandwidth , the bias term is of order @xmath267 and contains the derivatives @xmath268 and @xmath269 that can be difficult to estimate .",
    "based on the bahadur representation ( [ eq : mbahadur ] ) , we can correct the bias term @xmath241 via the jackknife estimator @xmath270 in ( [ eq : mbias ] ) .",
    "then the bias term for @xmath270 becomes @xmath271 . by ( [ eq : mbahadur ] ) , following the proof of corollary [ cor : m ] , we have @xmath272 \\rightarrow n \\biggl(0 , \\frac { \\varphi_{k^ * } ( b - a ) s^2(x ) } { 4f^2_e(0 ) } \\biggr),\\ ] ] where @xmath273 .      theorem",
    "[ thmm : v ] below provides a uniform bahadur representation for @xmath274 in ( [ eq : sest ] ) .",
    "[ thmm : v ] let @xmath274 be as in ( [ eq : sest ] ) .",
    "assume that the conditions in theorem [ thmm : m ] hold .",
    "further assume @xmath275 .",
    "then    we have the uniform consistency : @xmath276 ) } \\bigl|\\hat{s}(x)-s(x)\\bigr| = \\mathrm{o}_\\mathrm{p } \\biggl\\ { b^2_n + h^2_n + \\frac{(\\log n_n)^{3/2}}{(n_nb_n)^{1/2 } } + \\frac{(\\log n_n)^{3/2}}{(n_nh_n)^{1/2 } } \\biggr\\}.\\end{aligned}\\ ] ]    moreover , the bahadur representation @xmath277 + \\mathrm{o}_\\mathrm{p}(\\tilde{r}_n),\\end{aligned}\\ ] ] holds uniformly over @xmath239)$ ] , where @xmath278/\\kappa_+$ ] , @xmath279 is defined as in theorem [ thmm : m ] , @xmath280 \\\\ & & { } - \\frac { f'_{e}(1 ) [ s'(x)+\\mu'(x ) ] ^2 -f'_{e}(-1 ) [ s'(x)-\\mu'(x ) ] ^2}{\\kappa_+ s(x ) } , \\\\ w_{h_n } ( x ) & = & - \\sum^{n}_{i=1 } \\sum ^{m_i}_{j=1 } \\bigl\\ { \\mathbf{1}_{|y_{i , j}-\\mu(x)|\\le s(x ) } - { { \\mathbb{e } } } [ \\mathbf{1}_{|y_{i , j}-\\mu(x)|\\le s(x ) } ] \\bigr\\ } k_{h_n}(x_{i , j}-x ) , \\\\",
    "\\tilde{r}_n & = & b^4_n + h^4_n + \\frac{h_n^{1/2 } ( \\log n_n)^{3/2}}{n_n^{1/2 } } + \\frac{(\\log n_n)^{9/4}}{(n_nh_n)^{3/4 } } \\\\ & & { } + \\frac{(\\log n_n)^{9/4}}{n_n^{3/4 } b_n^{1/4 } h_n^{1/2 } } + \\frac{b_n ( \\log n_n)^{3/2}}{(n_n h_n)^{1/2}}.\\end{aligned}\\ ] ]    as in corollary [ cor : m ] , we can use the bahadur representation ( [ eq : vbahadur ] ) to obtain a clt for @xmath281 .",
    "however , the convergence rate depends on the ratio @xmath282 . if @xmath283 , then the term @xmath284 dominates and we have @xmath285-convergence ; if @xmath286 , then the term @xmath287 dominates and we have @xmath288-convergence ; if @xmath289 for a constant @xmath290 , then both terms contribute .    [ cor : v ] let the conditions in theorem [ thmm : v ] be fulfilled and condition [ con : clt ] and its counterpart version with @xmath197 being replaced by @xmath291 hold .",
    "further assume that @xmath292 and @xmath293 , where @xmath260 is defined as in ( [ eq : conclt ] ) .",
    "recall @xmath294 in ( [ eq : mjackclt ] ) and @xmath295 in theorem [ thmm : v ] .",
    "let @xmath261)$ ] be a fixed point .",
    "suppose @xmath296 .",
    "if @xmath297 and @xmath298 , then @xmath299 \\rightarrow n \\biggl(0 , \\frac { \\varphi_{k^ * } \\kappa^2 ( b - a ) s^2(x ) } { 4 f^2_e(0 ) } \\biggr).\\ ] ]    if @xmath297 and @xmath300 , then @xmath301 \\rightarrow n \\bigl(0 , \\sigma_c^2\\bigr),\\ ] ] where @xmath302 } { \\kappa_{+ } f_e(0 ) } \\int _ { { { \\mathbb{r } } } } k(u ) k^*(c u ) \\,\\mathrm{d}u \\biggr\\}.\\ ] ]    if @xmath303 , then for all @xmath304 $ ] , ( [ cor : vcltii ] ) holds with @xmath305",
    ".    one can similarly establish clt results for @xmath306 in ( [ eq : vbias ] ) .",
    "we omit the details .",
    "for least - squares based estimation of longitudinal data , rice and silverman @xcite suggested the subject - based cross - validation method .",
    "the basic idea is to use all but one subject to do model fitting , validate the fitted model using the left - out subject , and finally choose the optimal bandwidth by minimizing the overall prediction error : @xmath307 where @xmath308 represents the estimator of @xmath187 based on data from all but @xmath9th subject . as in wei , zhao and lin @xcite ,",
    "we replace the square loss by absolute deviation : @xmath309      urinary metabolite progesterone levels are measured daily , around the ovulation day , over 22 conceptive and 69 nonconceptive women s menstrual cycles so that each curve has about 24 design points ; see the left panel of figure  [ fig1 ] for a plot of the trajectories of the 22 conceptive women .",
    "previous studies based on least - squares ( ls ) methods include brumback and rice @xcite , fan and zhang @xcite , and wu and zhang @xcite .",
    "here we reanalyze the conceptive group using our least - absolute - deviation ( lad ) estimates .    from the left plot in figure  [ fig1 ] , subject 14 ( dashed curve ) has two sharp drops in progesterone levels at days @xmath310 and 9 .",
    "similarly , subject 13 ( dotted curve ) has unusually low levels on days @xmath311 .",
    "while such sharp drops or `` outliers '' may be caused by incorrect measurements or other unknown reasons , we investigate the impact of such `` outliers '' on the ls and lad estimates . in the right plot of figure  [ fig1 ] ,",
    "the thick solid and thin solid curves are the lad and ls estimates of @xmath16 .",
    "the two estimates are reasonably close except during the periods @xmath312 $ ] and @xmath313 $ ] .",
    "notice that the latter periods contain the `` outliers '' from subjects 13 , 14 .    to understand the impact of such possible `` outliers '' , we consider two scenarios of perturbing the data below .",
    "scenario i : remove subjects 13 and 14 and estimate @xmath16 using the remaining subjects .",
    "the thick dotted and thin dotted curves are the corresponding lad and ls estimates .",
    "clearly , the discrepancy is largely diminished .",
    "scenario ii : make the two outlier subjects 13 and 14 even more extreme by shifting their curves three units down .",
    "we see that the discrepancy between the lad ( thick dashed ) and ls ( thin dashed ) estimates becomes even more remarkable .",
    "compared with the estimate based on the original data , the ls estimates under the two perturbation scenarios differ significantly . by contrast , the lad estimates under the three cases are similar , indicating the robustness in the presence of outliers .",
    "we conclude that , for the progesterone data with several possible outliers , the proposed lad estimate offers an attractive alternative over the well - studied ls estimates . in practice , we recommend the lad estimate if the data has suspicious , unusual observations or extreme outliers .     using both the original data and perturbed data .",
    "thin solid , dotted , and dashed curves are the least - squares estimates of @xmath16 based on the original data , perturbation scenario i ( remove subjects 13 and 14 ) , and perturbation scenario ii ( shift subjects 13 and 14 down by three units ) , respectively .",
    "similarly , thick solid , dotted , and dashed curves are least - absolute - deviation estimates . ]",
    "this paper studies robust estimations of the location and scale functions in a nonparametric regression model with serially dependent data from multiple subjects . under a general error dependence structure that allows for many linear and nonlinear processes",
    ", we study uniform bahadur representations and asymptotic normality for least - absolute - deviation estimations of a location - scale longitudinal model . in the large literature on nonparametric estimation of longitudinal models , most existing works use least - squares based methods , which are sensitive to extreme observations and",
    "may perform poorly in such circumstances . despite the popularity of quantile regression methods in linear models and nonparametric regression models ,",
    "little research has been done in quantile regression based estimations for nonparametric longitudinal models , partly due to difficulties in dealing with the dependence .",
    "therefore , our work provides a solid theoretical foundation for quantile regression estimations in longitudinal models .",
    "the study of asymptotic bahadur representations is a difficult area and has focused mainly on the i.i.d . setting or stationary time series setting . for longitudinal data , deriving bahadur representations",
    "is more challenging due to the nonstationarity and dependence . to obtain our bahadur representations ,",
    "we develop substantial theory for kernel weighted empirical processes via a coupling argument .",
    "the proposed error dependence structure and coupling argument provide a flexible and powerful framework for asymptotics from dependent data , such as time series data , longitudinal data and spatial data , whereas similar problems have been previously studied mainly for either independent data or stationary time series . in ( [ eq : error ] )",
    ", @xmath36 depends on the innovations or shocks @xmath314 indexed by integers on a line .",
    "a natural extension is the function of innovations indexed by bivariate integers on a square : @xmath315 the coupling argument still holds by replacing the innovations @xmath316 , outside the @xmath53 nearest squares with i.i.d . copies . as in condition [ con : dc ] , we can assume that the impact of perturbing the distant innovations decays exponentially fast ( or polynomially fast with slight modifications of the proof ) .",
    "more generally , the coupling argument holds for function of innovations indexed by multivariate spatial lattice , and such setting may be useful in studying asymptotics for spatial data .",
    "throughout @xmath317 are generic constants .",
    "first , we give an inequality for the indicator function .",
    "let @xmath318 be two random variables and @xmath319 . for @xmath320",
    ", we have @xmath321 similarly , @xmath322 . therefore ,",
    "@xmath323      proof of proposition [ pro : h ] let @xmath324 , and @xmath325 so that @xmath326 , and @xmath327 . for convenience ,",
    "write @xmath328 . by assumption ,",
    "@xmath329 . by ( [ eq : hfunc ] ) and",
    "the hlder inequality @xmath330 , @xmath331 \\cr & \\le & \\mathrm{o}(1 ) \\bigl\\{{{\\mathbb{e}}}\\bigl[\\bigl|e_0-e'_0\\bigr|^{\\varsigma q^ * \\cdot p_1 } \\bigr]\\bigr\\}^{1/p_1 } \\bigl\\ { { { \\mathbb{e}}}\\bigl[\\bigl(1+|e_0|+\\bigl|e'_0\\bigr| \\bigr)^{\\upsilon q^ * \\cdot p_2}\\bigr]\\bigr\\}^{1/p_2 } \\cr & = & \\mathrm{o}(1 ) \\bigl\\|e_0-e'_0\\bigr\\|_{q}^{q / p_1 } \\|e_0\\|_{q}^{q / p_2}=\\mathrm{o}\\bigl(\\rho^{k q / p_1 } \\bigr).\\end{aligned}\\ ] ] the above expression gives @xmath332^k=\\mathrm{o}(\\rho^{k\\varsigma})$ ] .",
    "proof of proposition [ pro : e ] let @xmath333 . by ( [ eq : zineq ] ) and the triangle inequality , @xmath334^{1/q } + \\bigl[{{\\mathbb{p}}}\\{x-\\alpha\\le e_0 \\le x+\\alpha\\}\\bigr]^{1/q}.\\end{aligned}\\ ] ] by the markov inequality , @xmath335/\\alpha^q=\\mathrm{o}(\\rho^{kq}/\\alpha^q)$ ] . since @xmath46 has a bounded density , @xmath336 .",
    "the result then follows .",
    "proof of theorem [ thmm : cp ] for @xmath337 , let @xmath338 using the identity @xmath339 for all @xmath340 , we can rewrite @xmath146 as @xmath341 now we consider @xmath342 . by the discussion in section  [ sec : coupling ] , the summands in @xmath342 are independent . by ( [ eq : thmcpcon ] ) , @xmath343 & = & \\sum _ { ( i , j)\\in{\\cal i}_r } { { \\mathbb{e}}}\\bigl [ g^2_{i,(j-1)(2k_n+1)+r } ( \\tilde{y}_{i,(j-1)(2k_n+1)+r},v ) \\bigr ] \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & \\le & \\sum^{n}_{i=1 } \\sum^{m_i}_{j=1 } { { \\mathbb{e}}}\\bigl [ g^2_{i , j}(\\tilde{y}_{i , j},v ) \\bigr ] \\le \\chi_n,\\end{aligned}\\ ] ] uniformly over @xmath344 .",
    "\\(i ) consider the case @xmath141 .",
    "recall the condition @xmath137 . by berstein s exponential inequality ( bennett @xcite ) for bounded and independent random variables , for any given @xmath345 , when @xmath136 is sufficiently large , @xmath346 + c c_1 \\log n_n } \\biggr\\ } \\le2 n_n^{-c_1/(3c)},\\end{aligned}\\ ] ] uniformly over @xmath29 and @xmath58 . here",
    "the second inequality follows from @xmath347\\le\\chi_n=\\mathrm{o}(1)\\le cc_1 \\log n_n$ ] for large enough @xmath136 .",
    "thus , @xmath348 by the assumption that both @xmath135 and @xmath117 grow no faster than a polynomial of @xmath136 , we can make the above probability go to zero by choosing a large enough @xmath349 .",
    "therefore , @xmath350",
    "\\(ii ) consider the case @xmath351 . as in ( [ eq : berstein ] ) , @xmath352,\\end{aligned}\\ ] ] uniformly over @xmath29 and @xmath58 , where @xmath353^{1/2}<\\infty$ ] .",
    "the rest of the proof follows from the same argument as in the case ( i ) by choosing a sufficiently large @xmath349 .",
    "proof of theorem [ lem : appr ] let @xmath354 .",
    "since @xmath155 , applying ( [ eq : zineq ] ) , we obtain @xmath355 \\\\ & : = & 2c \\bigl [ \\omega_n + \\lambda_n(y ) \\bigr].\\nonumber\\end{aligned}\\ ] ] notice that , @xmath356 . by ( [ eq : gmc ] ) and the markov inequality , @xmath357 thus , @xmath358=\\mathrm{o}_\\mathrm{p}(1)$ ] for @xmath359 $ ] .    for @xmath360 over @xmath319 ,",
    "consider two cases : @xmath361 and @xmath362 .",
    "for @xmath361 , since @xmath363 , @xmath156 and @xmath364 are bounded , @xmath365 for some constant @xmath345 .",
    "therefore , by @xmath366 and the markov inequality , @xmath367&\\le&{{\\mathbb{e}}}\\biggl [ \\sum^{n}_{i=1 } \\sum ^{m_i}_{j=1 } \\mathbf { 1}_{|e_{i , j}(k_n)|>c_1 n_n^{1/q } } \\biggr ] \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber   & \\le&\\sum^{n}_{i=1 } \\sum ^{m_i}_{j=1 } \\frac{\\|e_{i , j}(k_n)\\|^q_q}{(c_1 n_n^{1/q})^q}=\\mathrm{o}(1).\\end{aligned}\\ ] ] we conclude that @xmath368 .",
    "in what follows , we use a chain argument to prove @xmath369 } \\lambda_n(y)=\\mathrm{o}_\\mathrm{p}[(\\log n)^2]$ ] . without loss of generality , consider @xmath370 $ ] . write @xmath371 and",
    "let @xmath372 be the set of @xmath373 grid points uniformly spaced over @xmath374 $ ] .",
    "partition @xmath374 $ ] into intervals @xmath375 , v=1,\\ldots , \\ell_n$ ] . for any @xmath376",
    ", we have @xmath377 .",
    "since @xmath364 is bounded away from zero , @xmath378 , and @xmath379 , we have @xmath380 uniformly for some constant @xmath381 .",
    "consequently , for any @xmath376 , we have @xmath382 = \\lambda^*_n(v ) + c_2.\\end{aligned}\\ ] ] we apply theorem [ thmm : cp ] to @xmath383 . for @xmath139",
    "in ( [ eq : thmcpcon ] ) , using @xmath380 , we have @xmath141 and thus @xmath384 $ ] , completing the proof .    proof of theorem [ pro : osc ] recall the coupling process @xmath170 in ( [ eq : empdiff2 ] ) . under the assumption @xmath385 , @xmath386^{1/2}\\}$ ] .",
    "thus , by ( [ eq : dd2 ] ) , it suffices to show @xmath387^{1/2}\\}$ ] .    without loss of generality ,",
    "assume @xmath388 $ ] .",
    "recall @xmath127 in ( [ eq : fn2 ] ) .",
    "rewrite @xmath389\\bigr\\},\\qquad \\tilde\\xi_{i , j}(\\delta , y ) = \\mathbf{1}_{y<\\tilde{y}_{i , j}\\le y+\\delta}.\\end{aligned}\\ ] ] as in the proof of theorem [ lem : appr ] , consider @xmath361 and @xmath362 .    for @xmath361 , since",
    "@xmath156 and @xmath364 are bounded and @xmath390 , @xmath391 for some @xmath345 .",
    "therefore , by the boundedness of @xmath392 , the same argument in ( [ eq : pthm1a ] ) shows @xmath393 uniformly over @xmath394 .",
    "next , we consider @xmath362 . since @xmath395 vanishes for @xmath70 outside a bounded interval , without loss of generality",
    "we only consider @xmath396 $ ] for some @xmath397 , @xmath370 $ ] , and @xmath398 $ ] . as in the proof of theorem [ lem : appr",
    "] , we use the chain argument .",
    "let @xmath399 , and @xmath400 be uniformly spaced grid points .",
    "partition @xmath401\\times[0,n_n^{1/q}]\\times [ 0,\\delta_n]$ ] into intervals @xmath402\\times [ y_{v_2 - 1},y_{v_2}]\\times[t_{v_3 - 1},t_{v_3 } ] , v_1,v_2,v_3=1,\\ldots , \\ell_n$ ] .",
    "let @xmath403 clearly , for any @xmath404 , we have @xmath405 . since @xmath406 and @xmath407 , there exists a constant @xmath381 such that @xmath408 - { { \\mathbb{e } } } [ \\underline{\\xi}_{i , j}(v_2,v_3 ) ] \\le c_2 n_n^{1/q } /\\ell_n $ ] .",
    "additionally , for @xmath409 $ ] , by condition [ assump : r2],@xmath410 .",
    "thus , there exists a constant @xmath411 such that @xmath412\\bigr\\ } \\nonumber\\\\ & & \\quad \\le \\varpi_{i , j}(x_{v_1 } ) \\bigl\\ { \\overline{\\xi}_{i , j}(v_2,v_3 ) - { { \\mathbb{e}}}\\bigl [ \\underline{\\xi}_{i , j}(v_2,v_3 ) \\bigr ] \\bigr\\ } + \\tau_n b/\\ell_n \\\\ & & \\quad\\le \\varpi_{i , j}(x_{v_1 } ) \\bigl\\ { \\overline{\\xi}_{i , j}(v_2,v_3 ) - { { \\mathbb{e}}}\\bigl [ \\overline{\\xi}_{i , j}(v_2,v_3 ) \\bigr ] \\bigr\\ } + c_3 \\bigl(\\tau_n + n_n^{1/q } \\bigr)/\\ell _ n,\\nonumber\\end{aligned}\\ ] ] uniformly over @xmath172 , and @xmath404 .",
    "similarly , @xmath413\\bigr\\ } \\nonumber \\\\[-8pt ] \\\\[-8pt ] \\nonumber & & \\quad \\ge \\varpi_{i , j}(x_{v_1 } ) \\bigl\\ { \\underline{\\xi}_{i , j}(v_2,v_3 ) - { { \\mathbb{e}}}\\bigl [ \\underline{\\xi}_{i , j}(v_2,v_3 ) \\bigr ] \\bigr\\ } - c_3 \\bigl(\\tau_n + n_n^{1/q } \\bigr)/\\ell_n.\\end{aligned}\\ ] ] combining ( [ eq : upper ] ) and ( [ eq : lower ] ) and using @xmath414 , we have @xmath415 where @xmath416 , @xmath417 \\bigr\\ } , \\\\",
    "\\overline{\\delta}_n(v ) & = & \\sum ^n_{i=1 } \\sum^{m_i}_{j=1 } \\varpi_{i , j}(x_{v_1 } ) \\bigl\\ { \\overline{\\xi } _ { i , j}(v_2,v_3 ) - { { \\mathbb{e}}}\\bigl [ \\overline { \\xi}_{i , j}(v_2,v_3 ) \\bigr ] \\bigr\\}.\\end{aligned}\\ ] ] we now apply theorem [ thmm : cp ] to @xmath418 and @xmath419 . for @xmath139",
    "in ( [ eq : thmcpcon ] ) , with @xmath174 in ( [ eq : conr2 ] ) and @xmath420=\\mathrm{o}(\\delta_n+n_n^{1/q}/\\ell _ n)=\\mathrm{o}(\\delta_n)$ ] , we can take @xmath421 . by theorem [ thmm :",
    "cp](ii ) , @xmath422^{1/2}\\}$ ] .",
    "the latter bound also holds for @xmath423 .",
    "the desired result then follows from ( [ eq : upperlower ] ) .      throughout the proofs",
    ", we use the following notation : @xmath424 , \\\\",
    "l_{s } ( \\delta_1,\\delta_2,x ) & = & \\sum ^{n}_{i=1 } \\sum ^{m_i}_{j=1 } k_{h_n}(x_{i , j}-x ) \\mathbf{1 } _ { |y_{i , j}-\\mu(x)-\\delta_1|\\le s(x ) + \\delta_2 } , \\\\",
    "l_{s}(x ) & = & \\sum^{n}_{i=1 } \\sum^{m_i}_{j=1 } k_{h_n } ( x_{i , j}-x ) , \\\\",
    "j_{s}(\\delta_1,\\delta_2,x)&=&{{\\mathbb{e}}}\\bigl [ l_{s}(\\delta_1,\\delta_2,x ) \\bigr].\\end{aligned}\\ ] ]    [ lem:1 ] assume that conditions [ con : reg][con : lc ] hold .",
    "then , we have    uniformly over @xmath425 $ ] , @xmath426    let @xmath427 be a measurable bivariate function on @xmath226 ^ 2 $ ] .",
    "define @xmath428 further assume that @xmath429}|\\partial^{s } ( x , v)/\\partial v^s|<\\infty , s=0,1,\\ldots , r$ ] for some @xmath430 .",
    "then uniformly over @xmath425 $ ] , @xmath431    \\(i ) recall the ordered locations @xmath432 in condition [ con : reg ] .",
    "define @xmath433 \\bigr\\}. \\label{eq : ix}\\end{aligned}\\ ] ]    assume without loss of generality that @xmath189 has support @xmath434 $ ] .",
    "condition ( [ eq : dense ] ) implies that @xmath435}|{\\cal i}(x)|=\\mathrm{o}(n_nb_n)$ ] , where and hereafter @xmath436 is the cardinality of a set @xmath437 . because @xmath189 has support @xmath434 $ ] , @xmath438 for @xmath439 .",
    "additionally , for @xmath440 , the summands in @xmath441 are uniformly bounded .",
    "thus , @xmath442 = \\mathrm{o}(n_nb_n),\\end{aligned}\\ ] ] uniformly over @xmath443 $ ] .    by ( [ eq : dense ] )",
    ", elementary calculation shows that , uniformly over @xmath425 $ ] , @xmath444 \\\\[-8pt ] \\nonumber & = & \\mathrm{o } ( \\varrho_n ) \\sup_{x\\in[a , b ] } \\bigl|s_n(x)\\bigr| = \\mathrm{o}(b_n / n_n).\\end{aligned}\\ ] ]    write @xmath445 .",
    "observe that @xmath446 .",
    "thus , by the triangle inequality , we have @xmath447 \\\\[-8pt ] \\eqntext{\\mbox{where } v_k = \\displaystyle\\int^{\\tilde{x}_{k+1}}_{\\tilde{x}_k } \\biggl{\\vert}u^r_k k(u_k)- \\biggl ( \\frac{v - x}{b_n } \\biggr)^r k \\biggl(\\frac{v - x}{b_n } \\biggr ) \\biggr{\\vert}\\,\\mathrm{d}v.\\qquad\\qquad}\\end{aligned}\\ ] ] since @xmath189 has bounded derivative , @xmath448 for @xmath449 $ ] .",
    "also , @xmath450 .",
    "thus , under condition [ con : reg ] , @xmath451}{b_n } = \\frac{\\mathrm{o}(1)}{n^2_n b_n}.\\ ] ] furthermore , it is easily seen that , for @xmath452 , @xmath453 , which implies @xmath454 for @xmath455 $ ] , and consequently @xmath456 .",
    "thus , by ( [ eq : vka ] ) and  ( [ eq : vkb ] ) , @xmath457 uniformly over @xmath425 $ ] ,    notice that @xmath458^r k_{b_n}(x_{i , j}-x ) = s_n(x)$ ] .",
    "recall that @xmath459 and @xmath460 .",
    "the desired result then follows from ( [ eq : snapp ] ) and ( [ eq : experr ] ) in view of @xmath461 for all @xmath425 $ ] and large enough @xmath462 .",
    "\\(ii ) the expression ( [ eq : lem1b ] ) easily follows from ( i ) in view of the taylor expansion @xmath463 for @xmath464 .",
    "[ lem : expansion ] assume that conditions [ con : reg][con : lc ] hold .",
    "let @xmath465 be as in theorems  [ thmm : m][thmm : v ] .",
    "then , for @xmath466 , we have uniformly over @xmath467 $ ] , @xmath468+\\mathrm{o}\\bigl(1+n_nb^5_n\\bigr ) , \\label{eq : jsx2 } \\\\",
    "j_\\mu(\\delta_1,x ) & = & j_\\mu(0,x ) + n_n b_n \\delta_1 \\bigl\\ { f_e(0)/\\bigl[(b - a)s(x)\\bigr ] + \\mathrm{o}\\bigl[(n_nb_n)^{-1}+b^2_n+ \\delta_1\\bigr ] \\bigr\\ } , \\label { eq : jsxdiff } \\\\ j_s(\\delta_1,0,x ) & = & l_s(x)/2 - n_n h_n\\kappa_{+ } \\bigl\\ { \\bigl [ { h_n^2 } \\psi_k \\rho_s(x ) - \\delta_1 \\kappa\\bigr ] /\\bigl[(b - a)s(x)\\bigr ] + \\mathrm{o}\\bigl(h_n^4 + \\delta_1 ^ 2\\bigr ) \\bigr\\ } , \\\\",
    "j_s(\\delta_1,\\delta_2,x ) & = & j_s(\\delta_1,0,x ) + n_n h_n \\delta_2 \\bigl\\ { \\kappa_{+ } /\\bigl[(b - a ) s(x)\\bigr ] + \\mathrm{o } \\bigl ( h_n^2 + \\delta_1 + \\delta_2\\bigr ) \\bigr\\}.\\end{aligned}\\ ] ]    recall that @xmath220 and @xmath469 are the distribution and density functions of @xmath105 .",
    "the assumption @xmath184 implies that @xmath224 . notice that @xmath470 \\\\ & = & \\sum^n_{i=1 } \\sum^{m_i}_{j=1 } k_{b_n}(x_{i , j}-x ) g(x , x_{i , j}),\\end{aligned}\\ ] ] where @xmath471/s(v ) \\ } - f_e(0)$ ] .",
    "the symmetry of @xmath189 entails @xmath472 .",
    "the first expression then follows from lemma [ lem:1](ii ) with @xmath473 .",
    "similarly , we can show @xmath474+\\mathrm{o}(1+n_nb^3_n)$ ] and @xmath475 uniformly over @xmath476 .",
    "so , the second expression follows from the taylor expansion @xmath477 .",
    "the other two expressions can be similarly treated .",
    "we omit the details .",
    "let @xmath478 and @xmath479 be as in section  [ sec : expansion ] .",
    "proof of theorem [ thmm : m ] let @xmath480^{1/2 } + b_n^2\\to0 $ ] .",
    "let @xmath481 be a positive sequence satisfying @xmath482 .",
    "first , we show @xmath483 uniformly over @xmath239)$ ] . since @xmath484 is a solution to ( [ eq : muest ] ) , by koenker ( @xcite , pages  3233 ) , @xmath485 uniformly over @xmath70 .",
    "let @xmath486 - \\bigl[l_\\mu(0,x)-j_\\mu(0,x)\\bigr].\\ ] ] we can apply theorem [ pro : osc ] with @xmath487 to @xmath488 . for @xmath173 and @xmath489 incondition  [ assump : r2 ] , @xmath490 and @xmath491 ( see lemma [ lem:1 ] ) . by theorem",
    "[ pro : osc],@xmath429 } |\\omega_n(x)|= \\mathrm{o}_\\mathrm{p}\\{[n_nb_n l_n\\delta_n(\\log n_n)^3]^{1/2}\\}$ ] . by the same argument , we can show @xmath492 } \\bigl|l_\\mu(0,x)-j_\\mu(0,x)\\bigr| = \\mathrm{o}_\\mathrm{p}\\bigl\\{\\bigl[n_nb_n ( \\log n_n)^3\\bigr]^{1/2}\\bigr\\}.\\ ] ] hence , by ( [ eq : osc2 ] ) and lemma [ lem : expansion ] , uniformly over @xmath261)$ ] , @xmath493 + \\bigl [ j_\\mu(0,x ) - l_\\mu(x)/2 \\bigr ] \\nonumber\\\\ & & { } + \\bigl [ l_\\mu(0,x ) - j_\\mu(0,x ) \\bigr ] + \\omega_n(x ) \\\\ & = & n_nb_n l_n \\delta_n f_e(0)/\\bigl[(b - a)s(x)\\bigr ] \\bigl [ 1 + \\mathrm{o}(1 ) \\bigr ] + \\mathrm{o}_\\mathrm{p}(\\nu_n),\\nonumber\\end{aligned}\\ ] ] where @xmath494^{1/2 } + [ n_nb_nl_n\\delta_n(\\log n_n)^3]^{1/2}$ ] . because @xmath495 and @xmath496 , it is easy to see that @xmath497 and @xmath498 , which implies @xmath499 uniformly over @xmath425 $ ] in view of @xmath500 .",
    "since @xmath501 is nondecreasing in @xmath502 , ( [ eq : koenker ] ) and ( [ eq : consis ] ) entail @xmath503 .",
    "similarly , @xmath504 .",
    "so , @xmath505 can be arbitrarily slow , @xmath506 ) and lemma [ lem : expansion ] , uniformly over @xmath261)$ ] , @xmath507 \\\\",
    "& = & \\bigl[l_\\mu\\bigl(\\hat\\delta_\\mu(x),x\\bigr ) - l_\\mu(x)/2\\bigr ] + \\bigl [ l_\\mu(x)/2-j_\\mu(0,x ) \\bigr ] \\\\ & & { } - \\bigl[j_\\mu\\bigl(\\hat\\delta_\\mu(x),x \\bigr ) - j_\\mu(0,x ) \\bigr ] + \\mathrm{o}_\\mathrm{p } \\bigl [ \\sqrt{n_nb_n \\delta_n ( \\log n_n)^3 } \\bigr ] \\\\ & = & \\mathrm{o}_\\mathrm{p}(1 ) + n_n b^3_n \\rho_\\mu(x)f_e(0 ) \\psi_k/\\bigl[(b - a)s(x)\\bigr ] + \\mathrm{o}\\bigl(1+n_nb^5_n \\bigr ) \\\\ & & { } - n_nb_n \\hat\\delta_\\mu(x ) \\bigl \\ { f_e(0)/\\bigl[(b - a)s(x)\\bigr ] + \\mathrm{o}(\\delta_n)\\bigr\\ } \\\\ & & { } + \\mathrm{o}_\\mathrm{p } \\bigl [ \\sqrt{n_nb_n \\delta_n ( \\log n_n)^3 } \\bigr].\\end{aligned}\\ ] ] the representation ( [ eq : mbahadur ] ) then follows by solving @xmath508 from the above equation .",
    "proof of theorem [ thmm : v ] we use the argument in theorem [ thmm : m ] and only sketch the outline .",
    "let @xmath509- \\bigl[l_s(0,0,x)-j_s(0,0,x ) \\bigr].\\ ] ] using theorem [ pro : osc ] , we can show that @xmath510}\\bigl|l_s(0,0,x)-j_s(0,0,x)\\bigr|&=&\\mathrm{o}_\\mathrm{p } \\bigl\\{\\bigl[n_nh_n ( \\log n_n)^3 \\bigr]^{1/2}\\bigr\\ } , \\label{eq : oscaa } \\\\",
    "\\sup_{|\\delta_1|+|\\delta_2|\\le\\delta_n , x\\in[a , b ] } \\bigl|d_s(\\delta _ 1 , \\delta_2,x)\\bigr|&=&\\mathrm{o}_\\mathrm{p}\\bigl\\{\\bigl[n_nh_n ( \\log n_n)^3\\bigr]^{1/2}\\bigr\\ } , \\label{eq : oscs}\\end{aligned}\\ ] ] hold for all @xmath511 and @xmath176 satisfying @xmath512<\\infty$ ] .",
    "let @xmath513^{1/2 } + [ ( \\log n_n)^3/(n_nh_n)]^{1/2}$ ] and @xmath495 be a sequence such that @xmath496 . by theorem [ thmm : m ] , @xmath514 . using ( [ eq : oscs ] ) and lemma  [ lem : expansion ] , we can derive the following counterpart of ( [ eq : consis ] ) @xmath515 \\\\ & & { } + \\bigl[j_s\\bigl(\\tilde\\delta_\\mu(x),0,x \\bigr)-l_s(x)/2\\bigr ] + l_s(0,0,x)-j_s(0,0,x ) \\\\ & & { } + \\mathrm{o}_\\mathrm{p } \\bigl\\{\\bigl [ n_nh_n l_n \\delta_n ( \\log n_n ) ^3 \\bigr]^{1/2 } \\bigr\\ } \\\\ & = & n_nh_n l_n \\delta_n \\kappa_{+}/\\bigl[(b - a)s(x)\\bigr ] \\bigl [ 1 + \\mathrm{o}_\\mathrm{p}(1 ) \\bigr ] \\to\\infty.\\end{aligned}\\ ] ] let @xmath516 . by the same argument in ( [ eq : koenker ] ) ,",
    "notice that @xmath518 is nondecreasing in @xmath70 .",
    "thus , @xmath519 . similarly , @xmath520 . then @xmath521 .",
    "write @xmath522^{1/2}$ ] . to derive the bahadur representation ( [ eq : vbahadur ] ) , we use ( [ eq : oscs ] ) and lemma [ lem : expansion ] to obtain @xmath523 + \\bigl[l_s(x)/2-j_s \\bigl(\\hat\\delta_\\mu(x),0,x\\bigr)\\bigr ] \\\\ & & \\qquad { } -\\bigl[j_s \\bigl(\\tilde\\delta_\\mu(x),\\hat\\delta_s(x),x \\bigr)-j_s\\bigl(\\tilde\\delta_\\mu(x),0,x\\bigr)\\bigr ] + \\mathrm{\\mathrm{o}}_\\mathrm{p } ( \\varpi_n ) \\\\ & & \\quad= \\mathrm{o}_\\mathrm{p}(1 ) + n_n h_n \\kappa_{+ } \\bigl\\ { \\bigl[h^2_n\\psi_k \\rho_s(x ) - \\kappa\\tilde\\delta_u(x)\\bigr]/\\bigl[(b - a)s(x)\\bigr ] + \\mathrm{o } \\bigl(h^4_n + \\delta^2_n\\bigr ) \\bigr\\ } \\\\ & & \\qquad { } - n_n h_n \\hat\\delta_s(x ) \\bigl\\{\\kappa_{+}/\\bigl[(b - a)s(x)\\bigr]+\\mathrm{o}(\\delta_n)\\bigr\\ } + \\mathrm{o}_\\mathrm{p } ( \\varpi_n).\\end{aligned}\\ ] ] solving @xmath524 from the above equation , we obtain the bahadur representation ( [ eq : vbahadur ] ) .",
    "again we use the coupling argument to convert the dependent data to @xmath20-dependent case .",
    "theorem [ thmm : romanowolf ] below presented a clt for @xmath20-dependent sequence with unbounded @xmath20 .",
    "[ thmm : romanowolf ] let @xmath525 , be a triangular array of mean zero @xmath117-dependent random variables .",
    "define @xmath526 assume that there exist some @xmath527 such that @xmath528 then @xmath529 .",
    "proof of corollaries [ cor : m][cor : v ] we only prove corollary [ cor : m ] since corollary [ cor : v ] can be similarly treated . by the bahadur representation ( [ eq : mbahadur ] ) , under the specified condition , @xmath530 .",
    "thus , it suffices to show @xmath531)$ ] .",
    "recall @xmath118 and @xmath127 in ( [ eq : couple ] ) and ( [ eq : fn2 ] ) .",
    "define the coupling process @xmath532\\bigr\\ }",
    "k_{b_n}(x_{i , j}-x).\\ ] ] let the coupling lag @xmath533 be chosen as in theorem [ lem : appr ] . by theorem [ lem : appr ] , @xmath534=\\mathrm{o}_\\mathrm { p}[(n_nb_n)^{1/2}]$ ] .",
    "it remains to show @xmath535)$ ] .",
    "recall @xmath536 .",
    "set @xmath537 for @xmath538 .",
    "define @xmath539\\bigr\\ } k_{b_n}(x_{i , j}-x).\\end{aligned}\\ ] ] then we can write @xmath540 . notice that @xmath541 are @xmath120-dependent , and @xmath542 are independent for each fixed @xmath14 .",
    "let @xmath543 and @xmath544 be defined in theorem [ thmm : romanowolf ] .",
    "we shall verify the conditions in theorem [ thmm : romanowolf ] . by the independence of the summands @xmath545 in @xmath546",
    ", @xmath547 ^ 2 \\biggr\\ } = \\mathrm{o } \\bigl ( 1/m_n^2\\bigr),\\end{aligned}\\ ] ] in view of @xmath263 . since @xmath127 and @xmath19 have same distribution , we have @xmath548/s(x_{i , j})\\}-f^2_e\\{[\\mu(x)-\\mu ( x_{i , j})]/s(x_{i , j})\\}$ ] .",
    "recall @xmath224 . then @xmath549 .",
    "thus , by ( [ eq : conclt ] ) and the @xmath120-dependence of @xmath550 , applying lemma [ lem : expansion](ii ) with @xmath551 produces @xmath552 + \\frac{\\mathrm{o}(nm_n k_n b_n \\iota_n)}{n_nb_n } \\to\\frac { \\varphi_k}{4(b - a)},\\end{aligned}\\ ] ] in view of @xmath263 and @xmath553 .",
    "similarly , we can show @xmath554 .",
    "therefore , it is easy to see that the conditions in theorem [ thmm : romanowolf ] hold with @xmath555 , and straightforward choices of @xmath556 , completing the proof .",
    "we are grateful to an associate editor and three anonymous referees for their insightful comments .",
    "wei s research was supported by the national science foundation ( dms-09 - 06568 ) and a career award from niehs center for environmental health in northern manhattan ( es-009089 ) .",
    "zhao s research was supported by a nida grant p50-da10075 - 15 .",
    "the content is solely the responsibility of the authors and does not necessarily represent the official views of the nida or the nih ."
  ],
  "abstract_text": [
    "<S> we investigate asymptotic properties of least - absolute - deviation or median quantile estimates of the location and scale functions in nonparametric regression models with dependent data from multiple subjects . under a general dependence structure that allows for longitudinal data and some spatially correlated data , we establish uniform bahadur representations for the proposed median quantile estimates . </S>",
    "<S> the obtained bahadur representations provide deep insights into the asymptotic behavior of the estimates . </S>",
    "<S> our main theoretical development is based on studying the modulus of continuity of kernel weighted empirical process through a coupling argument . </S>",
    "<S> progesterone data is used for an illustration .    , </S>"
  ]
}