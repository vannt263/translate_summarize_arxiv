{
  "article_text": [
    "pan - tilt - zoom ( ptz ) cameras are powerful to support object identification and recognition in far - field scenes .",
    "they are equipped with adjustable optical zoom lenses that can be manually or automatically controlled to permit both wide area coverage and close - up views at high resolution .",
    "this capability is particularly useful in surveillance applications to permit tracking of targets in high resolution and zooming in on biometric details of parts of the body in order to resolve ambiguities and understand target behaviors .",
    "however , the practical use of ptz cameras in real contexts of operation is complicate due to several reasons .",
    "first , the geometrical relationship between the camera view and the 3d observed scene is time - varying and depends on camera calibration .",
    "unfortunately , the absolute pan tilt and zoom positional values provided by the camera actuators , even when they are sufficiently precise , in most cases are not synchronized with the video stream , and , for ip cameras , a constant frame rate can not be assumed .",
    "so , accurate calibration must be extracted from the visual content of the frames .",
    "second , the pan tilt and zooming facility may determine large and abrupt scale changes .",
    "this prevents the assumption of smooth camera motion .",
    "moreover , since the scene background is continuously changing , some adaptive representation of the scene under observation becomes necessary .",
    "all these facts have significant impact also on the possibility of having effective target detection and tracking in real - time . due to this complexity",
    ", there is a small body of literature on tracking with ptz cameras and most of the solutions proposed were limited to either unrealistic or simple and restricted contexts of application .    in the following , we present a novel solution that provides continuous adaptive calibration of a ptz camera and enables real - time tracking of targets in 3d world coordinates in general contexts of application .",
    "we demonstrate that the method is effective and is robust over long time periods of operation .",
    "the solution has two distinct stages . in the off - line stage , we collect a finite number of keyframes taken from different viewpoints , and for each keyframe detect and store the scene landmarks and the camera pose . in the on - line stage , we perform camera calibration by estimating the homographic transformation between the camera view and the 3d world plane at each time instant from the matching between the current view and the keyframes .",
    "changes in the scene that have occurred over time due to illumination or objects are accounted with an adaptive representation of the scene under observation by updating the uncertainty in landmark localization .",
    "the relationship between target position in the 3d world plane and its position in the 2d image allows us to estimate the scale of target in each frame , compensate camera motion and perform accurate multi - target detection and tracking in 3d world coordinates .",
    "in the following , we review the research papers that are most relevant for the scope of this work . in particular , we review separately solutions for self - calibration and target tracking with moving and ptz cameras .",
    "hartley et al .",
    "@xcite were the first to demonstrate the possibility of performing self - calibration of ptz cameras based on image content .",
    "however , since calibration is performed off - line , their method can not be applied in real - time contexts of operation .",
    "the method was improved in  @xcite with a global optimization of the parameters .",
    "solutions for on - line self - calibration and pose estimation of moving and ptz cameras were presented by several authors . among them , the most notable contributions were in  @xcite .",
    "sinha and pollefeys in  @xcite used the method of  @xcite to obtain off - line a full mosaic of the scene .",
    "feature matching and bundle adjustment were used to estimate the values of the intrinsic parameters for different pan and tilt angles at the lowest zooming level , and the same process is repeated until the intrinsic parameters are estimated for the full range of views and zoomings . in  @xcite the same authors suggested that on - line control of a ptz camera in closed loop could be obtained by matching the current frame with the full mosaic .",
    "however , their paper does not include any evidence of the claims nor provides any evaluation of the accuracy of the on - line calibration .",
    "civera et al .",
    "@xcite , proposed a method that exploits real - time sequential mosaicing of a scene .",
    "they used simultaneous localization and mapping ( slam ) with extended kalman filter ( ekf ) to estimate the location and orientation of a ptz camera and included the landmarks of the scene in the filter state .",
    "this solution can not scale with the number of scene landmarks .",
    "moreover , they only considered the case of camera rotations , and did not account for zooming .",
    "lovegrove et al .",
    "@xcite obtained the camera parameters between consecutive images by whole image alignment .",
    "as an alternative to using ekf sequential filtering , they suggested to use keyframes to achieve scalable performance .",
    "they claimed to provide full ptz camera self - calibration but did not demonstrate calibration with variable focal length .",
    "the main drawback of all these methods is that they assume that the scene is almost stationary and changes are only due to camera motion , which is a condition that is unlikely to happen in real contexts .",
    "wu and radke  @xcite presented a method for on - line ptz camera self - calibration based on a camera model that accounts for changes of focal length and lens distortion at different zooming levels .",
    "the authors claimed robustness to smooth scene background changes and drift - free operation , with higher calibration accuracy than  @xcite especially at high zoom levels .",
    "however , as reported by the authors , this method fails when a large component in the scene abruptly modifies its position or the background changes slowly .",
    "it is therefore mostly usable with stationary scenes .",
    "a similar strategy was also applied in  @xcite , but accounts for pan and tilt camera movements , only .",
    "other authors developed very effective methods for pose estimation of moving cameras with pre - calibrated internal camera parameters  @xcite . in  @xcite ,",
    "klein and murray applied on - line bundle adjustment to the five nearest keyframes sampled every ten frames of the sequence . in  @xcite , williams et al . used a randomized lists classifier to find the correspondences between the features in the current view and the ( pre - calculated ) features from all the possible views of the scene , with ransac refinement .",
    "however both these approaches , if applied to a ptz camera , are likely to produce over - fitting in the estimation of the camera parameters at progressive zoomings in .      solutions to perform general object tracking with ptz cameras were proposed by a few authors .",
    "hayman et al .",
    "@xcite and tordoff et al .",
    "@xcite proposed solutions to adapt the ptz camera focal length to compensate the changes of target size , assuming a single target in the scene and fixed scene background .",
    "in particular , in  @xcite , the authors used the affine transform applied to lines and points of the scene background ; in  @xcite the ptz camera focal length is adjusted to compensate depth motion of the target .",
    "kumar et al .",
    "@xcite suggested to adapt the variance of the kalman filter to the target shape changes .",
    "they performed camera motion compensation and implemented a layered representation of spatial and temporal constraints on shape , motion and appearance .",
    "however , the method is likely to fail in the presence of abrupt scale changes . in @xcite , varcheie and",
    "bilodeau addressed target tracking with ip ptz cameras , in the presence of low and irregular frame rate . to follow the target",
    ", they commanded the ptz motors with the predicted target position .",
    "a fuzzy classifier is used to sample the target likelihood in each frame . since zooming",
    "is not managed , this approach can only be applied in narrow areas .",
    "the authors in @xcite assumed that ptz focal length is fixed and coarsely estimated from the camera ccd pixel size .",
    "they performed background subtraction by camera motion compensation to extract and track targets .",
    "this method is therefore unsuited for wide areas monitoring and highly dynamic scenes .",
    "solutions for tracking with ptz cameras in specific domains of application were proposed in  @xcite .",
    "all these methods exploit context - specific fiducial markers to obtain an absolute reference and compute the time - varying relationship between the positions of the targets in the 2d image and those in the 3d world plane . in  @xcite ,",
    "the authors used the a - priori known circular shape of the hockey rink and playfield lines to locate the reference points needed to estimate the world - to - image homography and compute camera motion compensation .",
    "the hockey players were tracked using a detector specialized for hockey players trained with adaboost and particle filtering based on the detector s confidence  @xcite .",
    "the changes in scale of the targets was managed with simple heuristics using windows slightly larger / smaller than the current target size .",
    "similar solutions were applied in soccer games  @xcite .",
    "beyond the fact that these solutions are domain - specific and have no general applicability , the main drawback is that fiducial markers are likely to be occluded and impair the quality of tracking .",
    "the main contributions of the solution proposed are :    * we define a method for on - line ptz camera calibration that jointly estimates the pose of the camera , the focal length and the scene landmark locations . under reasonable assumptions ,",
    "such estimation is bayes - optimal , is very robust to zoom and camera motion and scales beyond thousands of scene landmarks .",
    "the method does not assume any temporal coherence between frames but only considers the information in the current frame .",
    "* we provide an adaptive representation of the scene under observation that makes ptz camera operations independent of the changes of the scene . * from the optimally estimated camera pose we infer the expected scale of a target at any image location and compute the relationship between the target position in the 2d image and the 3d world plane at each time instant .    differently from the other solutions published in the literature like  @xcite ,  @xcite ,  @xcite and  @xcite our approach allows performing on - line ptz camera calibration also in dynamic scenes .",
    "estimation of the relationship between positions in the 2d image and the 3d world plane permits more effective target detection , data association and real - time tracking .",
    "some of the ideas for calibration contained in this paper were presented with preliminary results under simplified assumptions in  @xcite .",
    "targets were detected manually in the first frame of the sequence and the scene was assumed almost static through time .",
    "therefore we could not maintain camera calibration over hours of activity , neither support rapid camera motion .",
    "in the following , we introduce the scene model and define the variables used .",
    "then we discuss the off - line stage , where a scene map is obtained from the scene landmarks of the keyframes , and the on - line stage , where we perform camera pose estimation and updating of the scene map .",
    "we consider an operating scenario where a single ptz camera is allowed rotating around its nodal point and zooming , while observing targets that move over a planar scene .",
    "the following entities are defined as time - varying random variables :    * the _ camera pose _ @xmath0 .",
    "camera pose is defined in terms of the pan and tilt angles ( @xmath1 and @xmath2 , respectively ) , and focal length @xmath3 of the camera .",
    "since the principal point is a poorly conditioned parameter , it is assumed to be constant in order to obtain a more precise calibration  @xcite .",
    "radial distortion was not considered since it can be assumed to be negligible for zooming operations  @xcite . * the _ scene landmarks _ @xmath4 .",
    "these landmarks account for salient points of the scene background . in the off - line stage surf keypoints  @xcite",
    "are detected in keyframe images sampled at fixed intervals of pan , tilt and focal length .",
    "a surf descriptor is associated to each landmark .",
    "these landmarks change during the on - line camera operation .",
    "* the _ view map _ @xmath5 and _ scene map _ @xmath6 .",
    "a view map is created for each keyframe that collects the scene landmarks ( i.e. @xmath5 = @xmath7 ) .",
    "the scene map is obtained as the union of all the view maps and collects all the scene landmarks that have been detected at different pan , tilt and focal lengths values ( i.e. @xmath6 = @xmath8 ) .",
    "since the scene landmarks change through time , these maps will change accordingly .",
    "* the _ landmark observations _ @xmath9 .",
    "these landmarks account for the salient points that are detected in the current frame .",
    "they can either belong to the scene background or to targets .",
    "the surf descriptors of the landmark observations @xmath9 are matched with the descriptors of the scene landmarks @xmath4 , in order to estimate the camera pose and update the scene map .",
    "* the _ target state _ @xmath10 .",
    "the target state is represented in 3d world coordinates and includes both the position and speed of a target .",
    "it is assumed that targets move on a planar surface , i.e. @xmath11 , so that @xmath12 $ ] . * the _ target observations _ in the current frame , @xmath13 .",
    "this is a location in the current frame that is likely to correspond to the location of a target . at each time",
    "instant @xmath14 there is a non - linear and time varying function @xmath15 relating the position of the target in world coordinates @xmath10 to the location @xmath13 of the target in the image .",
    "its estimation depends on the camera pose @xmath0 and the scene map @xmath6 at time @xmath14 .",
    "[ fig_fullhomo ] provides an overview of the main entities of the scene model and their relationships .      in the off - line stage ,",
    "image views ( keyframes ) are taken at regular samples of pan and tilt angles and focal length , and view maps @xmath16 are created so to cover the entire scene .",
    "surf keypoints  @xcite are organized in a k - d tree for each view map .",
    "given a reference keyframe and the corresponding view map @xmath17 , the homography that maps each @xmath16 to @xmath17 can be estimated as in the usual way of planar mosaicing  @xcite : @xmath18 the optimal values of both the external camera parameter matrix @xmath19 and the internal camera parameter matrix @xmath20 are estimated by bundle adjustment for each keyframe @xmath21 .    differently from  @xcite , we use bundle adjustment for off - line scene map initialization and use the whole set of keyframes of the scene at multiple zoomings . since keyframes were taken by uniform sampling of the parameter space , over - fitting of camera parameters is avoided .",
    "this results in a more accurate on - line estimation of the ptz parameters .",
    "the difference in the accuracy of the estimation is especially sensible in the case in which ptz operates at high zooming .",
    "[ fig_panos2 ] shows an example of estimation of the focal length with the two approaches for a sample sequence with right panning and progressive zooming - in .",
    "( a )  ( b )    the pan , tilt , zoom values of the camera actuators are stored in order to uniquely identify each view map .",
    "the complete scene map @xmath6 is obtained as the union of all the view maps . differently from  @xcite , a forest of k - d trees is used for matching .",
    "the positional values provided by the camera actuators at each time instant , although not directly usable for on - line camera calibration , are nevertheless sufficiently precise to retrieve the view map @xmath22 with the closest values of pan , tilt and focal length .",
    "this map is likely to have almost the same content as the current frame and many landmarks will match .",
    "the landmarks matched can be used to estimate the homography @xmath23 from the current view to @xmath24 .",
    "matching is performed according to nearest neighbor distance ratio as in  @xcite and ransac . to reduce the computational effort of matching ,",
    "only a subset of the landmarks in @xmath22 is taken by random sampling .",
    "the descriptors of the landmarks matched are updated using a running average with a forgetting factor .",
    "the optimal estimation of @xmath23 on the basis of the correspondences between landmark observations @xmath25 and scene landmarks @xmath26 is fundamental for effective camera pose ( pan , tilt , focal length ) estimation and mapping in real conditions .",
    "however , changes of the visual environment due to illumination or to objects entering , leaving or changing position in the scene induce modifications of the original scene map as time progresses .",
    "moreover , imprecisions in the detection and estimation process might affect scene landmark estimation and localization .",
    "to this end , under reasonable assumptions , we derive a linear measurement model that accounts for all the sources of error of landmark observations , that permits to obtain the optimal localization of the scene landmarks . permanent modifications of the scene are accounted through a landmark birth - death process that includes new landmarks and discards temporary changes .",
    "camera pose estimation and mapping requires inference of the joint probability of the camera pose @xmath27 and scene landmark locations in the map @xmath28 , given the landmark observations @xmath29 until time @xmath14 and the initial scene map @xmath30 : @xmath31 in order to make the problem scalable with respect to the number of landmarks , eq .",
    "( [ eq_slam ] ) is approximated by decoupling camera pose estimation from map updating : @xmath32    considering the the view map @xmath22 with the closest values of pan , tilt and focal length and applying bayes theorem to the map updating term , eq .",
    "( [ eq_slam_decoupled ] ) can be rewritten as : @xmath33 where the term @xmath34 indicates that view map @xmath35 at time @xmath14 depend only on @xmath36 . assuming that for each camera pose the observation landmarks @xmath37 that match the scene landmarks @xmath38 in @xmath35 are independent of each other , i.e. : @xmath39 eq .",
    "( [ new_eq_map_update_bayes ] ) modifies in : @xmath40 where @xmath41 is the prior pdf of the @xmath42-th scene landmark at time @xmath14 given its state at time @xmath43 . under the assumptions that both scene landmarks @xmath44 and the keypoint localization error have a gaussian distribution , and that direct linear transform is used",
    ", the observation model @xmath45 can be expressed as : @xmath46 where @xmath47 is the @xmath48 matrix obtained by linearizing the homography @xmath23 at @xmath49 and @xmath50 is an additive gaussian noise term with covariance @xmath51 that represents the whole error in the landmark mapping process .",
    "this covariance can be expressed in closed form and in homogeneous coordinates as : @xmath52 where  the three terms account respectively for the spatial distribution of the matched landmarks , the covariance of keypoint localization in the current frame and the uncertainty associated to the scene landmark positions in the view map . in eq .",
    "( [ eq : eq_cov ] ) , @xmath53 is the @xmath54 homography covariance matrix ( calculated in closed form according to  @xcite ) and @xmath55 is the @xmath56 block matrix of landmark observations ; @xmath57 models the keypoint detection error covariance ; @xmath58 is the covariance of the estimated landmark position on the nearest view map , and @xmath59 is obtained from the direct linear transform .",
    "covariance @xmath51 can be directly obtained as the @xmath60 principal minor of @xmath61 .",
    "the optimal localization of the scene landmarks is therefore obtained in closed form through multiple applications of the extended kalman filter to each landmark observation , with the kalman gain being computed as :    @xmath62^{-1 } ,    $ } \\ ] ]    where @xmath63 is the kalman covariance of the @xmath42-th scene landmark .",
    "objects that enter or leave the scene introduce modifications of the original scene map .",
    "their landmarks are not taken into account in the computation of @xmath23 at the current time ( they are the ransac outliers in the matching process ) , but are taken into account in the long term , in order to avoid that the representation of the original scene becomes drastically different from that of the current scene .",
    "we assume that new landmarks that persist in 20 consecutive frames and are closest to the already matched landmarks have higher probability of belonging to a new scene element ( they have smaller covariance according to eq .",
    "( [ eq : eq_cov ] ) ) .",
    "according to this , we implemented a _",
    "proximity check _",
    "[ fig_landinout ] ) that computes such probability as the ratio between the bounding box of the landmarks matched and the extended bounding box of the new landmark ( respectively box a and b in fig .  [ fig_landinout ] ) .",
    "such candidate landmarks are included in @xmath22 using the homography @xmath23 .",
    "landmarks are terminated when they are no more matched in consecutive frames .",
    "since the transformation between two near frames under pan tilt and zoom can be locally approximated by a similarity transformation , the asymptotic stability of the updating procedure is guaranteed by the multiplicative ergodic theorem  @xcite .",
    "therefore , we can assume that no sensible drifting is introduced in the scene landmark updating .",
    "looking at fig .",
    "[ fig_fullhomo ] , the time varying homography @xmath64 ( in homogeneous coordinates ) , mapping a target position in the world plane to its position @xmath65 in the current frame , can be represented as : @xmath66 where @xmath67 is the stationary homography from the mosaic plane to the 3d world plane : @xmath68 that can be obtained as the product of the rectifying homography @xmath69 ( derived from the projections of the vanishing points by exploiting the single view geometry of the planar mosaic that puts in relation vanishing lines and vanishing points between the images . ]",
    "@xcite ) and transformation @xmath70 from pixels in the mosaic plane to 3d world coordinates ( estimated from the projection of two points at a known distance @xmath71 in the world plane onto two points in the mosaic plane as in fig .",
    "[ fig_mosaic2world ] ) .",
    "we perform multi - target tracking in 3d world coordinates using the extended kalman filter .",
    "data association to discriminate between target trajectories is implemented according to the cheap - jpdaf model  @xcite .",
    "the relationship between the image plane and the 3d world plane of eq .",
    "( [ eq_homo_mosa_image ] ) allows us to obtain the target scale and perform tracking in the 3d world plane . as it will be shown in section [ sec : expsection ] , tracking in the 3d world plane allows a better discrimination between targets .      at each time instant @xmath14 , the homography @xmath64 permits to derive the homology relationship that directly provides the scale at which the target is observed in the current frame : @xmath72 where @xmath73(t ) and @xmath13(t ) are respectively the position of the target top and bottom in the image plane and @xmath74 is defined as : @xmath75 where @xmath76 is the identity matrix , @xmath77 is the world plane vanishing line , @xmath78 is the vanishing point of the world normal plane direction , and @xmath79 is the cross - ratio . the vanishing point @xmath78 is computed as @xmath80 , with @xmath81^\\top$ ] and @xmath82 is derived from @xmath23 as in  @xcite .",
    "estimation of the target scale allows us to apply the detector at a single scale instead of multiple scales and improve in both recall and computational performance for detection and tracking .",
    "the extended kalman filter observation model for each target is defined as : @xmath83 \\mathbf{s}(t ) + \\zeta(t ) , \\label{eq_obs_model_target}\\ ] ] where @xmath84 is a gaussian noise term with zero mean and diagonal covariance that models the target localization error in the current frame ; @xmath85 is the target state , represented in 3d world coordinates , @xmath86 is the homography @xmath64 linearized at the predicted target position and @xmath87 is the @xmath48 zero matrix . assuming constant velocity , the motion model in the 3d world plane is defined as : @xmath88 where @xmath89 is the @xmath90 constant velocity transition matrix and @xmath91 is the @xmath90 process noise matrix . for multiple target tracking",
    ", @xmath92 influences the target covariance of the cheap - jpdaf respectively for the kalman gain expression : @xmath93 and the target covariance on the image plane : @xmath94 where @xmath95 is the covariance matrix of the measurement error of eq .",
    "( [ eq_obs_model_target ] ) .",
    "in this section we report on an extensive set of experiments to assess the accuracy of our ptz camera calibration method and its effective exploitation for real - time multiple target tracking .      in the following ,",
    "we summarize the experiments that validate our approach for camera calibration .",
    "we justify the use of motor actuators to retrieve the closest scene map ; we report on the precision of the off - line scene map initialization and the on - line camera pose estimation and mapping .",
    "we validated the use of pan tilt and zoom values provided by the camera motor actuators to retrieve the closest view map , by checking their precision with the same experiment as in  @xcite .",
    "we placed four checkerboard targets at different positions in a room .",
    "these positions corresponded to different pan , tilt and zoom conditions .",
    "a sony snc - rz30p ptz camera was moved to a random position every 30 seconds and returned at the initial positions every hour . for each image",
    "view the corners of the checkerboard were extracted and compared to the reference image .",
    "the errors were collected for 200 hours .",
    "we have measured an average error of 2 pixels at the lowest zooming and 9 pixels for the maximum zooming .",
    "[ fig : ptzact ] shows the plots of the errors and the initial and final camera view for each target .",
    "off - line scene map initialization as discussed in sect .",
    "[ sec : scenemapinit ] is accurate and produces repeatable results .",
    "[ fig : offlinedev ] reports the mean and standard deviation of the focal length estimated during the scene map initialization . in this experiment , we acquired images of the same outdoor scene in 43 consecutive days at different time of the day , at 202 distinct values of pan tilt zoom .",
    "the ptz camera was driven using motor actuators .",
    "we can notice that the standard deviation of the focal length that is estimated through off - line bundle adjustment increases almost proportionally with focal length .",
    "the maximum standard deviation value observed is 23 pixels at focal length of about 1700 pixels .      in this experiment",
    ", we report on the average reprojection error and calibration errors with our method .",
    "we discuss the influence of the number of landmarks and ransac inlier threshold on the reprojection error and the effectiveness of scene landmark updating .    as in  @xcite , we recorded 10 outdoor video sequences of 8 hours each ( 80 hours in total ) . due to the long period of observation ,",
    "all the sequences include slow background changes due to shadows or illumination variations , as well as large changes due to moving objects entering or exiting the scene .",
    "the ptz camera was moved continuously using the motor actuators and stopped for a few seconds at the same pan tilt zoom values , so to have a large number of keyframes at the same scene locations and different conditions , in all the sequences . on average",
    "we performed about @xmath96 measurements per sequence . for each keyframe ,",
    "a grid of points was superimposed and the average reprojection error was measured between the grid points as obtained by the estimated homography and the same points by the off - line bundle adjustment .    tab .",
    "[ table : errcalib ] shows the average reprojection error , the errors in the estimation of pan , tilt and focal length and the improvements that are obtained with the _ proximity checking _",
    ", for the outdoor sequences under test . as in  @xcite , the errors in pan and tilt angles were computed as @xmath97 and @xmath98 , respectively , and the focal length error as @xmath99 ( in percentage ) .",
    "pan and tilt angles estimated and those calculated with bundle adjustment were obtained from the rotation matrices @xmath100 ( see eq .",
    "( [ eq_homo_mosa_image ] ) ) and @xmath101 ( see eq .",
    "( [ eq : offline ] ) ) , respectively .",
    "the results confirm that _ proximity checking _ avoids to select landmarks that introduce drifting in the homography estimation .",
    "it can be observed that errors in focal length measured with our method over a long period in an outdoor scenario are similar to those obtained in  @xcite , and lower than those in  @xcite ( as reported in  @xcite ) , for an indoor experiment with a few keyframes .",
    "the reprojection error depends on both the number of landmarks extracted and the ransac threshold for inliers as shown in fig .",
    "[ fig : param ] for one of the sequences under test ( sequence 1 ) .",
    "it can be observed that a large reprojection error with high standard deviation ( plotted at one sigma ) is present below 200 landmarks .",
    "instead , such error is low when the number of landmarks is between 200 and 1500 ( fig .  [ fig : param](a ) ) .",
    "[ fig : param](b ) shows that a ransac thresholds between 1 and 3 pixels for the inliers used in the homography estimation assures small reprojection errors .",
    "values of 1000 and 3 pixels were used respectively for the number of landmarks extracted and ransac threshold in our experiments .",
    "scene map updating significantly contributes to the robustness of our camera calibration to both slow and sudden variations of the scene , maintaining a high number of ransac inliers through time .",
    "[ fig : inliers](a ) shows the cumulative sum of the inliers with and without scene landmark updating .",
    "it is possible to observe that without scene landmark updating the number of inliers decreases ( the cumulative curve is almost flat ) as the initial landmarks do not match anymore with the landmarks observed due to scene changes . fig .",
    "[ fig : inliers](b ) shows the distribution of the inliers in the two cases . with no scene landmark updating ,",
    "typically only few of the original landmarks are taken as inliers for each keyframe , that is insufficient to assure a robust calibration over time . with scene landmark updating , a higher number of inliers is taken for each frame that include both the original and the new scene landmarks . as can be inferred from fig .",
    "[ fig : inliers ] , in a dynamic scene few of the original scene landmarks survive at the end of the observation period .",
    "[ fi : stimageometry ] highlights the scene landmark lifetime over a 20 minutes window , for one keyframe ( randomly chosen ) .",
    "the scene landmarks with i d @xmath102 $ ] are the original landmarks .",
    "landmarks with i d @xmath103 are those observed during the 20 minutes .",
    "our ptz camera calibration keeps sufficiently stable over long periods of observation .",
    "[ error_repr ] shows a typical plot of the reprojection error over 8-hour operation for a sample keyframe .",
    "camera calibration at different time of the day without and with scene landmark updating is shown in fig .",
    "[ fig : inliers2](a - b ) for a few sample frames .",
    "it can be observed that with scene landmark updating , camera calibration ( represented by the superimposed grid of points ) is still accurate despite of the large illumination changes occurred in the scene .          in the following ,",
    "we summarize experiments on multi - target tracking in 3d world coordinates using our on - line ptz camera calibration , and compare our method with a few methods that appeared in the literature on a standard ptz video sequence . in our experiments targets were detected automatically using the detector in  @xcite .",
    "to evaluate the impact of our ptz calibration on tracking , we recorded a 8-hour sequence in a parking area during a working day and extracted three videos with one , two and three targets .",
    "this is a dynamic condition , with both smooth and abrupt scene changes .",
    "multi - target tracking performance was evaluated according to both the clear mot  @xcite and usc metrics  @xcite . the clear mot metrics measures tracking accuracy ( mota ) :",
    "@xmath104    and precision ( motp ) : @xmath105 where @xmath106 and @xmath107 are respectively the false negatives and positives , @xmath108 are the identity switches , @xmath109 is the number of targets and @xmath110 is the voc score of the @xmath42-th target at time @xmath14 .",
    "the usc metric reports the ratio of the trajectories that were successfully tracked for more than 80% ( mt ) , the ratio of mostly lost trajectories that were successfully tracked for less than 20% ( ml ) , the rest partially tracked ( pt ) and the average count of false alarms per frame ( faf ) .",
    "we measured the performance for the method with no scene map updating , with no _ proximity checking _ and for the full method .    from tab .",
    "[ table : mota1 ] it is apparent that scene map updating has a major influence on the number of false negatives and false positives and therefore on the tracking accuracy . _ proximity checking _ has also a positive impact on the reduction of false positives and determines an average increase of the accuracy of about @xmath111 .      to analyze the effect of using 3d world",
    "coordinates we run our method in 2d image coordinates ( not applying mapping in the 3d world plane ) . in this case",
    ", the target scale could not be evaluated directly and was estimated within a range from the scale at the previous frame .",
    "[ table : mota2 ] reports the performance of our multi - target tracking performed in the two cases .",
    "it can be observed that tracking in 3d world coordinates lowers the number of false positives and contributes to a sensible improvement in both accuracy and precision , with respect to tracking in the 2d image plane .",
    "this improvement is even greater as the number of targets increases since the tracker has to discriminate between them .",
    "we compared our calibration and tracking against the results reported by a few authors , namely  @xcite ,  @xcite and  @xcite , on the _ ubc hockey _",
    "sequence  @xcite .",
    "this is the only publicly available dataset recorded from a ptz camera .",
    "it is very short and includes frames of a hockey game .",
    "all these authors performed tracking in the 2d image plane .",
    "for the sake of completeness we have compared both the 2d and 3d version of our tracking method .",
    "the scene map was obtained by uniformly sampling the video sequence every ten frames so to have a full coverage of the scene .",
    "for a fair comparison , in a first experiment we compared our method against  @xcite using the original detections provided by okuma . in a second experiment we compared with  @xcite and  @xcite using the ism detector  @xcite .",
    "the results are reported in tab .",
    "[ table : mota3 ] .",
    "as it is possible to observe , in the first experiment our calibration and tracking in 2d coordinates obtains comparable performance as  @xcite , while tracking in 3d world coordinates has significantly superior performance . in the second experiment",
    ", we observed that the ism detector fails to detect a target in the entire sequence and determines a large number of false negatives in all the methods .",
    "notwithstanding calibration and tracking in 3d coordinates still reports some improvement in performance with respect to the 2d solutions .",
    "we analyzed the operational constraints and computational requirements of our solution using a sony snc - rz30p ptz camera and intel xeon dual quad - core at 2.8ghz and 4 gb of memory , with no gpu processing . from tab .",
    "[ tab : timings ] we can see that we perform real - time calibration and tracking ( in 3d world coordinates ) at 12 fps .",
    "the current implementation of the method exploits multiple cores and was developed in c / c .",
    "frame grabbing , camera calibration and scene map updating are performed in one thread , detection and tracking are performed in a separate thread .",
    "in this paper , we have presented an effective solution for on - line ptz camera calibration that supports real - time multiple target tracking with high and stable degree of accuracy .",
    "calibration is performed by exploiting the information in the current frame and has proven to be robust to camera motion , changes of the environment due to illumination or moving objects and scales beyond thousands of landmarks .",
    "the method directly derives the relationship between the position of a target in the 3d world plane and the corresponding scale and position in the 2d image .",
    "this allows real - time tracking of multiple targets with high and stable degree of accuracy even at far distances and any zooming level ."
  ],
  "abstract_text": [
    "<S> pan - tilt - zoom ( ptz ) cameras are powerful to support object identification and recognition in far - field scenes . </S>",
    "<S> however , the effective use of ptz cameras in real contexts is complicated by the fact that a continuous on - line camera calibration is needed and the absolute pan , tilt and zoom positional values provided by the camera actuators can not be used because are not synchronized with the video stream . </S>",
    "<S> so , accurate calibration must be directly extracted from the visual content of the frames . </S>",
    "<S> moreover , the large and abrupt scale changes , the scene background changes due to the camera operation and the need of camera motion compensation make target tracking with these cameras extremely challenging . in this paper </S>",
    "<S> , we present a solution that provides continuous on - line calibration of ptz cameras which is robust to rapid camera motion , changes of the environment due to illumination or moving objects and scales beyond thousands of landmarks . </S>",
    "<S> the method directly derives the relationship between the position of a target in the 3d world plane and the corresponding scale and position in the 2d image , and allows real - time tracking of multiple targets with high and stable degree of accuracy even at far distances and any zooming level . </S>"
  ]
}