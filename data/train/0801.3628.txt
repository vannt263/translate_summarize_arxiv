{
  "article_text": [
    "many problems of relevance in physics , chemistry and biology are appropriately described as systems of interacting , discrete entities which evolve according to stochastic rules .",
    "these entities may be not all equal , for example they may be molecules of different chemical species .",
    "when a ) there is spatial homogeneity and other continuous degrees of freedom are irrelevant for the description , and b ) the markovian property holds , such systems are well described by master equations , @xmath0 here @xmath1 denotes the state of the system , @xmath2 is the probability of being in state @xmath1 at time @xmath3 , and @xmath4 is the transition rate from state @xmath5 to state @xmath1 .",
    "for instance in multi - species chemical systems , @xmath1 is a vector @xmath6 , the component @xmath7 being the number of molecules of the @xmath8-th specie .",
    "the description of chemical and biological processes in terms of master equations is usually rather accurate .",
    "however , it can have rather severe problems , even in the numerical treatment , if the number of states is large and overall if many degrees of freedom are involved . when the number of particles is large enough",
    ", a possibility is to describe the dynamics in terms of concentrations : there are several methods to move from a master equation to a partial differential equation , like the van kampen system size expansion @xcite .",
    "the most common result of such a procedure is a fokker - plank equation .",
    "on the other hand there are systems which are fundamentally discrete and , therefore , the continuous approximation may give answers which are quite different from that of the discrete case , like enzymatic reactions which are often studied in the limit where one has many substrate molecules but very few enzymes @xcite .",
    "other notable examples are genetic systems working with low molecules copy numbers @xcite and ecological systems close to the extinct absorbing state @xcite .    a common features of many of these problems which can be used to simplify the description is the presence of many relevant timescales .",
    "sometimes the timescale of the interactions is fast , but due to the many degrees of freedom the timescale of the global dynamics is much slower .",
    "this is the case of protein folding : while the elementary time scale of vibration of covalent bonds is @xmath9 , the folding time for a protein may be of order of seconds .",
    "another problematic situation is when the degrees of freedom are not so many , but the interactions are of diverse nature , resulting in entries in the transition matrix @xmath4 of very different orders of magnitude .",
    "an example of the latter case comes from many cell regulatory systems : proteins in a cell can interact chemically , again on molecular timescales , and via transcription regulation , on timescales of seconds or even minutes . in all these situations",
    "one says that the system has a _ multiscale _",
    "character @xcite .",
    "the necessity of treating the `` slow dynamics '' in terms of effective equations is both practical ( even modern supercomputers are not able to simulate all the relevant scales involved in certain difficult problems ) and conceptual : effective equations are able to catch some general features and to evidence key controls and basic ingredients which can remain hidden in the detailed description .",
    "the study of multiscale problems has a long history in science : perhaps the first example is the study , due to newton , of the precession of the equinoxes , which was basically a special version of the averaging method in mechanics @xcite . in fluid dynamics",
    "an example of the multiscale procedure is the derivation of an effective fick equation for the large scale and long time behavior starting from the transport equation @xcite : the diffusion tensor depends , often in a non intuitive way , on the velocity field .",
    "finally , in quantum mechanics , since the nuclei are much heavier than the electrons , one can simplify the treatment `` splitting '' the electronic and nuclear degrees of freedom , like in the born - oppenheimer approximation @xcite , or in its modern generalization due to car and parrinello @xcite .",
    "multiscale systems described by master equations can be difficult to deal with .",
    "gillespie s stochastic simulation algorithm @xcite , which is an exact and well established method for numerical simulations of master equations , is not very efficient to simulate multiscale systems .",
    "the reason is that gillespie algorithm treats fast and slow dynamics on equal footing , while if one is interested in the slow dynamics it is usually not necessary ( and computationally demanding ) to exactly integrate the fast dynamics .",
    "in recent years , several authors introduced modifications and approximations of the gillespie algorithm that allow to improve its efficiency when applied to multiscale problems .",
    "many approaches have been developed like the quasi - steady state approximation @xcite , fast variables elimination methods @xcite , finite state projection techniques @xcite , or continuous approximations of fast variables @xcite .",
    "the method developed in this paper follows a different idea .",
    "we want to study master equation containing states with fast and slow dynamics ( evolving with different characteristic times ) .",
    "our approach is to write down an effective master equation describing the evolution of the slow states only .",
    "the physical recipe we are going to impose is that , looking at the system on a slow timescale , the time spent on the fast states can be neglected .",
    "these states are thus eliminated from the description and this brings to new effective transitions among the slow states .",
    "clearly this approximation gives better results when the separation of timescales between fast and slow states becomes large .",
    "our procedure , by reducing the number of states , may allow for a large gain in simulation time . however , our main goal is to obtain in a systematic way a simple description of a system obeying a master equation on a slow timescale .",
    "indeed , we will show that in some cases our method does not correspond only to a numerical recipe , but allows for analytical predictions .",
    "the plan of the paper is the following . in section [ methodsection ]",
    "we introduce our method .",
    "section [ onedsection ] is devoted to the one dimensional examples : a random walk in a double - well potential and a random walk in a lattice with defects .",
    "section [ enzymesection ] we apply our method to a common model of enzymatic reaction and show how it can predict its behavior far from the steady state regime .",
    "conclusions and perspectives are in section [ conclsection ] .",
    "let us introduce the intuitive idea of the method with a schematic example .",
    "we consider the motion of a brownian particle in a potential @xmath10 having @xmath11 minima , like the one sketched in fig .",
    "[ figesempio ] .",
    "when the temperature @xmath12 is not too large the probability distribution function of the particle is concentrated only around the the minima @xmath13 and @xmath14 .",
    "therefore , instead of the complete fokker - planck description , it is sensible to study the system in terms of a master equation with @xmath11 states : we say that the system is in the state @xmath15 when @xmath16 is close to @xmath17 .",
    "moreover , we consider the case in which the barriers between states @xmath18 , @xmath19 and @xmath20 , @xmath11 have the same height @xmath21 , being smaller than the height @xmath22 of the barrier between states @xmath19 and @xmath20 . in this case , one has two very different typical times : the transition time between states @xmath18 , @xmath19 and @xmath20 , @xmath11 @xmath23 and the transition time between @xmath19 and @xmath20 , @xmath24 .",
    "if one is interested to properties on times much longer than @xmath25 , it is quite natural to devise a model of the system with only two states , say @xmath26 which includes @xmath18 and @xmath19 and @xmath27 which includes @xmath20 and @xmath11 .",
    "this simple example suggests how the study of a system on a slower timescale may lead to a reduction in the number of states one has to consider .",
    "consider now a generic master equation @xmath28    the standard way to simulate the above equation would be of course the gillespie algorithm @xcite , which is exact and does not imply a choice of a timestep . on the other hand , we would like to select a ( slow ) timescale , so let us discuss what happens if we integrate naively the equation , for example discretizing the time via the euler algorithm :    @xmath29    in this case , the application of the euler algorithm corresponds to approximate the master equation with a markov chain , defined by the markov transition matrix @xmath30 @xmath31 where we introduced for convenience of notation the total out - rate of state @xmath1 , @xmath32 when integrating eq.([mastereq ] ) , @xmath33 should be chosen to be small compared to the timescales of the system dynamics .",
    "however , notice that eq.([mastereq ] ) and ( [ markov ] ) share the same stationary condition independently on @xmath33 .",
    "this means that they have the same stationary state for any @xmath33 , even though they can have in principle quite different dynamics when @xmath33 increases .",
    "a natural question is what happens when @xmath33 becomes large .",
    "the problem one encounters is that the diagonal element of the matrix ( [ markovmatrix ] ) can become negative .",
    "this starts happening when @xmath34 on the other hand , when @xmath35 , the markov chain and the original master equation are closely related .",
    "not only they share the same stationary state , but one can easily write a relation between their eigenvalues , which are in a one to one correspondence . we can write the markov matrix @xmath36 : @xmath37 where @xmath38 is the identity and @xmath39 is the matrix having as non - diagonals elements the transition rates and on the diagonal minus the total out - rates .",
    "this implies that , calling @xmath40 and @xmath41 the eigenvalues of the matrices @xmath42 and @xmath39 , one has @xmath43 another way of seeing it is that @xmath36 is the first - order expansion of the evolution operator of the master equation @xmath44 .",
    "this implies the error one makes on the eigenvalues is order @xmath45 and should be negligible for the slower modes when @xmath33 is not too large .",
    "( [ dtstates ] ) suggests a strategy to identify `` fast states '' on a given timescale .",
    "the idea is that , every time a generic state @xmath1 is reached , the average time spent in it is @xmath46 . as a consequence ,",
    "if we choose the parameter @xmath33 representing the smaller timescale we aim to describe , then all states @xmath1 having @xmath47 should not enter into the description . in order to eliminate them ,",
    "the physical recipe we impose is simply that the time spent on these states is zero . in this way",
    ", the states disappear from the dynamics and the transition rates from a generic state @xmath48 to a generic state @xmath8 are modified according to : @xmath49 this procedure corresponds to adding to the rate the process of @xmath48 going to @xmath1 with the proper rate and then instantaneously going to @xmath8 with the proper probability .",
    "a graphical example of the application of the method is shown in fig .",
    "( [ figscheme ] ) .     states . here",
    ", the state @xmath50 on the left is a fast states and is eliminated from the description . on the right",
    "we represent the renormalized transition in terms of the original rates .",
    "the new transition rate from @xmath27 to @xmath51 contains the original one plus an additional contribution coming from the elimination of @xmath50 .",
    "the transition rate from @xmath26 to @xmath51 , equal to zero in the original graph , contains only the effect of the decimation.,width=313 ]      a natural question at this point is whether the order of elimination of the `` fast states '' matters for the resulting dynamics . in presence of two fast `` linked '' states , say @xmath1 and @xmath5 , such that @xmath52 , @xmath53 and @xmath54 or @xmath55 , the result of decimation could be different , in principle , depending on the order of elimination of the `` fast states '' , i.e. before @xmath1 and them @xmath5 or viceversa .    to show that our procedure commutes in general and clarify the connection with adiabatic approximations ,",
    "let us rearrange the vector @xmath56 into two vectors @xmath57 where @xmath58 is a vector containing the probabilities of the slow states and @xmath59 contains the probabilities of the fast states .",
    "we rewrite the master equation as : @xmath60    the adiabatic approximation corresponds to set @xmath61 , that is @xmath62    we can safely assume @xmath63 since otherwise the probabilities of the slow states would be zero at equilibrium .",
    "so we can solve the above equation for @xmath59 and substitute it into the equation for @xmath58 : @xmath64 notice that eq .",
    "( [ eqadiabatic ] ) preserves normalization since @xmath65 = \\frac{d}{dt } \\sum_n p_n(t)=0\\ ] ] in other words , within the adiabatic approximation there is no probability flow between fast and slow states .",
    "eq.([eqadiabatic ] ) may thus be considered a _",
    "bona fide _ reduced master equation for the slow degrees of freedom , with the transition rates being renormalized due to the effect of the fast states .",
    "notice that , at variance with fast variables elimination methods @xcite , the probabilities @xmath58 are not marginalized probabilities , meaning that we did nt average over fast states .",
    "the probabilities of fast states can be eventually reconstructed as a function of time after solving the equations for the slow states .    to clarify the relationship between eq .",
    "( [ eqadiabatic ] ) and our method , notice that condition ( [ adcondition ] ) is a linear set of equations for the fast degrees of freedom .",
    "let us consider the solution obtained by the substitution method : we start eliminating a particular fast state @xmath8 by computing its probability from the @xmath8-th equation : @xmath66    it should be clear at this point that , by substituting the above expression in the evolution equation of a fast state , the original rule of eq .",
    "( [ ourrule ] ) is retrieved ; the same procedure can be iterated to solve the probabilities of all the fast states and substitute it into the remaining equations .",
    "the conclusion is that our method is equivalent to solve the condition ( [ adcondition ] ) using the substitution method .",
    "but since the solution of that condition is unique , the resulting master equation will be eq.([eqadiabatic ] ) , independently on the order of elimination of the fast variables .",
    "now we apply our decimation procedure to some one dimensional random processes .",
    "the first example is the well known problem of the double well ; in this case the decimation procedure can be carried out analytically and predict the correct transition rate between the two minima .",
    "the second example is a one dimensional random walk with defect .",
    "let us consider the problem of a random walk in a double - well potential .",
    "this example is paradigmatic both in physics and in kinetic chemistry , in the latter case the one - dimensional axis represents the reaction coordinate and one is interested the rate of jumping from one minimum to the another , i.e. of the reaction to occur .",
    "again , we assume that this axis is subdivided in discrete states @xmath67 .",
    "we can introduce the potential @xmath68 , which determines the following transition probabilities : @xmath69\\ ] ]     and @xmath27 are the states corresponding to the two minima of the potential.,width=313 ]    being @xmath70 the usual boltzmann factor .",
    "notice that the above transition rates ensure that at equilibrium the probability of being in state @xmath1 is proportional to @xmath71 .",
    "we do not restrict ourself to a particular choice of the potential , we just assume that the potential has two minima which we denote with @xmath72 and @xmath73 , as sketched in fig.([figuradw ] ) . as usual",
    ", we are free to choose a value of @xmath33 and eliminate all the states whose inverse out - rate is smaller than @xmath33 : @xmath74    by increasing @xmath33 , the two minima are the last two surviving states since in a minumum both the exponentials in eq.([surviving ] ) have negative arguments .",
    "this means that with a proper choice of the time scale we can end up with a two state markov chain and calculate the transition rate between the two minima .    by alling @xmath75 the number of states between @xmath26 and @xmath27 ,",
    "the transition rate writes : @xmath76 in the denominator we indicate with the notation @xmath77 the total out - rate of state @xmath78 to remember that this out - rate changes when a neighboring state is eliminated .",
    "this means that the product of out - rates has to be evaluated by eliminating the states one after the other . to evaluate the expression ( [ renortrans ] ) , we make use of the following equality , which is demonstrated in the appendix : @xmath79 with the convention that products of less than one terms are always equal to one , @xmath80 . substituting ( [ potential ] ) and ( [ equality ] ) into ( [ renortrans ] ) one obtains : @xmath81 } { \\sum_{j=0}^n   \\exp[\\frac{\\beta}{2}(\\!v_{a+j}\\!-\\!v_{a}\\!+\\!v_{a+j+1}\\!-\\!v_{b})]}= \\\\",
    "\\!\\!\\!\\!\\!\\!=\\frac{1}{\\sum\\limits_{j=0}^n \\exp[\\frac{\\beta}{2}(v_{a+j}\\!+\\!v_{a+j+1 } ) ] } \\sim \\frac{1}{\\sum\\limits_{j=0}^n \\exp(\\beta v_{a+j})}\\nonumber\\end{aligned}\\ ] ] where in the last step we assumed that the potential does not change much between adjacent states .",
    "the last expression is basically the well known result for the transition rate in a double well potential in a continuous system described by a fokker - planck @xcite .",
    "considered now a random walker in a one dimensional geometry with periodic boundary conditions ; the number of its possible states is fixed to @xmath82 . the transition rate between two adjacent states is @xmath83 except for a fraction @xmath84 of the states ( the `` defects '' ) , having @xmath85 .",
    "the defects are placed at random at the beginning and kept the same in all the simulations ( quenched disorder ) . in solid state physics",
    "the master equation of this system corresponds to the schrdinger equation ( at imaginary time and with disorder ) in the limit of tight binding approximation @xcite .",
    "clearly one has @xmath86 for the normal states and @xmath87 for the defects .",
    "this means that the defects are the fast states and we will test what happens when eliminating them from the description . for comparison , we will see also the differences with the ideal case without defects , that is @xmath83 for all the states .",
    "it is easy to analytically calculate the eigenvalues in the case without defects @xcite : @xmath88\\qquad j=0,\\pm 1,\\pm 2\\ldots\\pm\\left(\\frac{n}{2}-1\\right).\\ ] ]    notice that all the eigenfunction are non - localized , which in solid state physics corresponds to a conductive system . on the contrary , in the case with defects ( for any positive value of @xmath89 ) the eigenfunctions are localized , i.e. one has a transition from a metal to an insulator @xcite .    .",
    "black circles : no defects , the jump rate is @xmath90 .",
    "red squares : with probability @xmath91 the sites have defects and their jump probability is @xmath92 .",
    "green diamonds : random walk with defects after applying the decimation scheme to all the fast states .",
    "all the eigenvalues are real .",
    "the difference between the figure and the inset is just the axis scale .",
    "notice in the main figure that the first @xmath93 eigenvalues of the decimated problem follow very closely the case with the defects . in the inset",
    "the eigenvalues corresponding to the fast states are evident ; notice that their number is the same as the average number of defects @xmath94.,width=313 ]    in fig.([figeigenvalues ] ) we show the eigenvalues of the master equation in the three cases : random walk without defects , with defects and after decimation .",
    "being the master equation linear , the eigenvalues spectrum contain all the informations about the dynamics .",
    "the spectrum shows an interesting property : the most negative eigenvalues are much larger in modulus and correspond to fast decaying eigenfunctions concentrated on the defects .",
    "it is clear from the figure that the effect of our algorithm is to eliminate these eigenvalues ( and the corresponding eigenfunctions ) .",
    "it is clear in the figure that the 100 eigenvalues smaller in modulus , corresponding to the slower dynamics of the system , are very similar in the model with defects and the decimated one .",
    "a further check comes from the correlation functions .",
    "we performed the simulations starting from a slow state @xmath95 and plotted in fig .",
    "[ figcorr ] the probability of being in the state @xmath78 as a function of time in the three cases we considered .",
    "after an initial time , the correlation functions for the decimated model and the model with defects are very close to each other .    ) prepared in the initial state @xmath95 and the probability of being in state @xmath78 , averaged over @xmath96 realization , is plotted as a function of time .",
    "the three curves are : ( black , continuous ) the system without defects , ( red , dashed ) system with defects , and ( green , dot - dashed ) the decimated system.,width=302 ]",
    "in this section we apply our method to a model of enzymatic reactions .",
    "enzymatic reactions are widely studied in kinetic chemistry and many methods have been derived to predict the steady - state kinetics in cases in which the reaction is close to an equilibrium , or at least in a non equilibrium steady state @xcite . to exemplify the relevance of our method in this case",
    ", we will consider in the following the simplest model of an enzymatic reaction :    @xmath97 { } } es \\xrightarrow{k_2 } e + p\\ ] ]    where as usual @xmath98 denotes the enzyme , @xmath99 the substrate and @xmath100 the reaction product .",
    "this correspond to the following master equation : @xmath101 where we called @xmath102 the number of free ( non binded ) substrate molecules , @xmath103 the number of free enzymes molecules , and @xmath104 the total number of enzyme molecules .",
    "we also introduced , as usual , the total out - rate of a general state : @xmath105.\\quad\\end{aligned}\\ ] ]    the quantity of interest is usually the production rate , that is the velocity of the rightmost reaction as a function of the concentration of enzymes and substrate .",
    "it is easy to estimate it in the quasi - equilibrium approximation , that is when @xmath106 , meaning that the leftmost part of the reaction can be considered at equilibrium .",
    "another thing one can assume is steady state dynamics : the calculation is simple even if the complex is not at equilibrium but the concentration of the complex @xmath107 does not vary much with time , @xmath108/dt\\approx 0 $ ] .",
    "the steady state approximation is known to hold very well when the concentration of enzymes is much smaller than that of substrate .    in this case",
    "the reaction velocity follows the michaelis - menten formula : @xmath109 where @xmath110 . in order to apply our method",
    ", we start from eq .",
    "( [ outratesenzyme ] ) .",
    "the expression for the out - rates suggests two limiting cases in which there is separation of scales between fast and slow states .",
    "the first case is @xmath111 . in this case",
    ", states having @xmath112 have a much greater out - rate than those with @xmath113 and can be coarse - grained .",
    "physically it corresponds to the situation in which the complex is efficiently processed , so that its concentration is always very close to zero . in this case",
    "the application of our method yields : @xmath114 notice that we wrote the rate in term of @xmath115 ( the total number of substrate molecules ) and not @xmath102 since with the coarse graining we grouped together states with bounded and free substrates as long as the total number is the same .",
    "notice also that this rate correctly corresponds to the michaelis menten formula , eq .",
    "( [ mmformula ] ) taken in the limit @xmath116 .",
    "the new information provided by our method is that in this limit the linear dependence on the number of substrates is valid also beyond the steady state approximation , that is when the enzymes concentration becomes large .",
    "the second limiting case is @xmath117 . in this case , all states having @xmath112 and @xmath118 are fast .",
    "this means that , for a fixed @xmath115 , the slow state is characterized by @xmath119 .",
    "when @xmath120 we retrieve again the steady state result : @xmath121 the above expression , again , is consistent with the michaelis - menteen equation , this time in the limit @xmath116 when the reaction rate does not depend anymore on the substrate concentration . on the other hand ,",
    "when @xmath122 one has : @xmath123 this last case is radically different with the steady state prediction : we have a linear dependence on the number of substrate molecules while michaelis - menteen formula predicts a rate which is independent on @xmath115 .",
    "the physical reason is that this is a case in which the complex never reaches a steady state : on a fast timescale , order @xmath124 the free substrate is completely converted into the complex @xmath107 .",
    "then it is depleted on much slower times , and the depletion speed is limited by the lower between the enzyme and the substrate concentration .    ) . in all simulations",
    "we start with @xmath125 molecules of free substrate and let the system evolve : the rate as a function of the number of molecules is evaluated by averaging over @xmath126 realizations of the process .",
    "the number of enzymes is @xmath127 in the top figures and @xmath128 in the bottom figures .",
    "the reaction rates are ( left ) @xmath129 , @xmath130 and ( right ) @xmath131 , @xmath132 .",
    "the lines in the black and white versions of the right figures are barely visible since the points fall very close to them.,width=302 ]    in fig .",
    "( [ figenzim ] ) we plot simulations of the reaction ( [ reaction ] ) in four different situations .",
    "the top left figure corresponds to the situations in which @xmath133 and @xmath134 ( numerical values of the parameters are in the figure caption ) , together with the prediction of eq .",
    "( [ lowdensityformula ] ) , while on the top - right we show @xmath135 and @xmath117 with the prediction of eq .",
    "( [ highdensityformula ] ) .",
    "these two are the cases in which steady state approaches are known to work and our approach simply corresponds to the limiting cases of michaelis - menten formula . on the bottom figures we show the same cases , but with @xmath136 .",
    "notice that the left one correspond to the top / left one , rescaled with the higher number of enzymes ; in particular , it is still described by eq .",
    "( [ lowdensityformula ] ) . on the other hand ,",
    "the bottom - right is even qualitatively different from the corresponding top figure . eq.([highdensitynostat ] ) correctly describes the behavior , while michaelis menten formula would predict the rate to be independent of @xmath115 .    in order to study also the fluctuations of the process , we simulated both the full master equation and the simplified processes defined by eq .",
    "( [ lowdensityformula ] ) , ( [ highdensityformula ] ) and ( [ highdensitynostat ] )",
    ". then we compare in fig .",
    "( [ figvar ] ) the variance of the number of product molecules as a function of time .",
    "the result of the simulations is that the fluctuations are almost indistinguishable in the reduced processes : the intuitive reason is that most of the fluctuations are related to the slow states and thus unaffected by the coarse graining procedure",
    ".     realizations .",
    "the four figures correspond to the same parameter choices of fig .",
    "( [ figenzim ] ) .",
    "black continuous lines correspond to simulation of the full master equation , red dashed lines are simulations of the reduced processes defined by eq.([lowdensityformula ] ) , ( [ highdensityformula ] ) and ( [ highdensitynostat]).,width=302 ]    we conclude this section with some remarks .",
    "the condition @xmath111 has a physical interpretation : it corresponds to the situation in which the concentrations are very low .",
    "indeed @xmath137 is the only rate that depends on the volume since it is essentially determined by the search time .",
    "conversely , the condition @xmath138 corresponds to large concentrations .",
    "this means that all the four cases we discuss are , in general , experimentally accessible .",
    "this kind of approach may be useful in the study of enzymatic reactions inside the cells .",
    "such reactions are often characterized by low number of molecules @xcite , and probably the michaelis - menten picture is appropriate even with a low number of substrate molecules . on the other hand",
    ", one can study situations in which concentrations are very high , or cases in which the changes that can occur in the cell environment , for example as a response to a rapidly varying external signal @xcite , can bring the reaction outside the steady state regime and make a description of this kind more appropriate .",
    "in this paper we introduced a general method for the decimation of `` fast modes '' in systems evolving according to a master equation via a coarse graining procedure .",
    "our method is general , and somehow , in the spirit of the renormalization group ( rg ) approach . indeed ,",
    "similar approaches have been proposed in statistical mechanics for the study of disordered systems @xcite . at variance with the rg ,",
    "we do not aim at reaching a fixed point by repeating the decimation procedure .",
    "in general , the method is applied only once : a sensible value of the parameter @xmath33 , which selects the coarse graining level , may be easily chosen by looking at the magnitude of the total out rates @xmath139 .",
    "we show that the procedure is commutative and brings to consistent results for a general master equation , independently of the dimensionality . however , for the sake of simplicity , we discussed in details low dimensional examples , where the method brings also to analytical predictions . in the discrete version of the double well potential , the decimation procedure is able to reproduce the well known result for the transition time .",
    "a numerical analysis shows that the method gives a very good approximation of the original system in the case of a random walk with defects . in the case of an enzymatic reaction",
    ", we show that the method allows for predictions only in some well defined limiting cases",
    ". however , in these cases , the prediction are more general than those obtained within a steady - state approximation .",
    "let us conclude with a short comparison with other approaches to multiscale master equations .",
    "our method is more similar in spirit to projection methods@xcite than to other quasi - steady states methods @xcite .",
    "the reason is that the result of our procedure is still a master equation while the other method describe the fast dynamics in a different way ( with a differential or langevin equation ) .",
    "the main difference between our method and the finite state projection is that our procedure is `` local '' ( we consider fast and slow states ) while projection methods generally consider eigenvalues and eigenvector of the transition matrix .",
    "projection methods are usually of more general applicability , however our procedure may allow a more transparent interpretation of the surviving states , as we show in the examples we considered .    on the other hand , fast variables elimination methods @xcite aim at writing an evolution equation for the probability of slow states summed over the probability of the fast ones .",
    "in this way one loses informations about the fast states and , if there is separation of scales , may write a closed equation for the slow ones .",
    "we show that our approach does not imply such coarse graining .",
    "in fact , no information about the fast states is lost in our case and their dynamics can be reconstructed after solving the problem involving the slow states only .",
    "there are also analogies between our method and some coarse graining procedure that have been proposed in the field of complex networks . in this field ,",
    "a relevant problem is the identification of communities @xcite and a possible way to do it is to consider a diffusion process on the network and try to coarse grain the graph while keeping the long timescale properties of this dynamics @xcite .",
    "the difference is that in these cases the procedure allows for a spatial simplification of the links , while our decimation procedure in a system whose states are seen as elements of a graph brings a suppression of the fast states but without a relevant simplification of the surviving connections .",
    "in this appendix we prove that , when decimating a cluster of @xmath75 consecutive states , the product of their out rates can be written as : @xmath141 remembering the convention that the product of less than one object is equal to one , and it is independent of the order of decimation .",
    "we will show that the above formula holds when decimating states in consecutive order , say from state @xmath143 one after the other to state @xmath144 ( see fig.([figapp ] ) ) , remembering that the result does not depend on the order of decimation due to the commutative property",
    ". we will demonstrated it by induction : first of all , the above formula is obviously true for @xmath145 :            we are grateful to m. cencini and a. puglisi for useful remarks and a detailed reading of the manuscript .",
    "wishes to thank _ universitad de las islas baleares _",
    "( palma de mallorca , spain ) for hospitality during the first stage of this work . s.p . wishes to thank a.d .",
    "jackson for stimulating discussions and help with the commutativity argument ."
  ],
  "abstract_text": [
    "<S> we propose a general method for simplifying master equations by eliminating from the description rapidly evolving states . the physical recipe </S>",
    "<S> we impose is the suppression of these states and a renormalization of the rates of all the surviving states . in some cases , </S>",
    "<S> this decimation procedure can be analytically carried out and is consistent with other analytical approaches , such as in the problem of the random walk in a double - well potential . </S>",
    "<S> we discuss the application of our method to nontrivial examples : diffusion in a lattice with defects and a model of an enzymatic reaction outside the steady state regime . </S>"
  ]
}