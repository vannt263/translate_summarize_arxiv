{
  "article_text": [
    "the well - known lll lattice reduction algorithm was presented in 1982 by lenstra , lenstra , lovsz @xcite . apart from various other applications ( e.g.  ( * ? ? ?",
    "* chapter 9,10 ) ) it has already at an early stage been used to attack various public key cryptosystems .",
    "nevertheless lattice problems remain popular when it comes to the construction of provably secure cryptosystems ( e.g.  ( * ? ? ?",
    "* chapter  13 ) ) .",
    "consequently improvements in lattice reduction still have a direct impact on the security of many cryptosystems and rise high interest in the crypto - community .",
    "many lattice reduction algorithms used in practice are generalizations of the lll algorithm . the block - korkine - zolotarev ( bkz ) reduction algorithm by schnorr and euchner  @xcite is probably the most used algorithm when stronger reduction than the one achieved by lll is required .",
    "it can be seen as a generalization of lll to higher blocksizes , and while the running time seems to behave well for small blocksizes  @xcite , no useful upper bound has been proven so far .",
    "another improvement of the lll algorithm has also been suggested in  @xcite . while in lll",
    "adjacent basis vectors are swapped if certain conditions are satisfied , in the so called lll with deep insertions ( deeplllin the sequel ) , basis vectors can be swapped even when not adjacent .",
    "the practical behavior of  deeplllwhen it comes to the reducedness of the output basis is superior the one of lll .",
    "unfortunately also the running time explodes and does not seem to be polynomial in the dimension of the lattice .",
    "one attempt get across this problem , is to restrict the insertions to certain blocks of basis vectors . while the authors in @xcite claim that these blockwise restriction variants of  deeplllrun in polynomial time , we are not aware of any proof thereof . for an overview on the practical behavior of the different variants and improvements on lll , we refer to  @xcite .",
    "there the practical behavior of the reduction algorithms is investigated using the widely used  ntllibrary .    in this paper",
    "we present a new version of  deeplll , called  potlll . to our knowledge",
    "it is the first improvement of lll with regard to deep insertions which provably runs in polynomial time .",
    "the practical behavior of  potlllregarding both the output quality and running time is empirically tested and compared to bkz and  deeplllwith different blocksizes .",
    "the tests are performed with a completely new implementation of the different reduction algorithms .",
    "this additionally allows an independent review of the results in  @xcite .",
    "the tests indicate that our algorithm can serve as a serious alternative to bkz with low blocksizes .",
    "the paper is organized as follows . in section  [ sec : prelim ] all necessary notations and definitions are given . in section  [ sec :",
    "algorithm ] the reduction notion and the new algorithm is presented and a theoretical analysis is provided .",
    "section  [ sec : experiments ] contains the empirical results and conclusions are drawn in section  [ sec : conclusion ] .",
    "a lattice @xmath0 of rank @xmath1 and dimension @xmath2 is a discrete subgroup of @xmath3 generated by integer linear combinations of @xmath1 linearly independent vectors @xmath4 in @xmath3 : @xmath5 we will often write the basis @xmath4 as rows of a matrix @xmath6 in the following way @xmath7 $ ] . in order to have exact representations in computers , only lattices in @xmath8",
    "are considered .",
    "simple scaling by the least common multiple of the denominators allows us to restrict ourselves to integer lattices @xmath9 .",
    "the volume of a lattice @xmath10 equals the volume of its fundamental parallelepiped @xmath11 . for @xmath12 ,",
    "a lattice has infinitely many bases as @xmath13 if and only if @xmath14 .",
    "therefore , the volume of a lattice is well defined . by @xmath15",
    "we denote the orthogonal projection from @xmath3 onto the orthogonal complement of @xmath16 . in particular",
    ", @xmath17 and @xmath18 equals the @xmath19-th basis vector of the gram - schmidt orthogonalization @xmath20 $ ] of @xmath6 . by @xmath21 , @xmath22 ,",
    "we denote the gram - schmidt coefficients .",
    "the gram - schmidt vectors can iteratively be computed by @xmath23 .    throughout this paper , by @xmath24 we denote the euclidean norm and by @xmath25 we denote the length of a shortest non - zero vector in @xmath26 with respect to the euclidean norm : @xmath27 . determining @xmath25 is commonly known as the shortest vector problem ( svp ) and is proven to be np - hard ( under randomized reductions ) ( see e.g. @xcite ) .",
    "upper bounds with respect to the determinant exist , for all rank @xmath1 lattices @xmath26 we have @xcite @xmath28 where @xmath29 is the _ hermite constant _ in dimension @xmath1 .",
    "given a relatively short vector @xmath30 , one measures its quality by the _ hermite factor _ @xmath31 it achieves .",
    "modern lattice reduction algorithms achieve a hermite factor which is exponential in @xmath1 and no polynomial time algorithm is known to achieve linear or polynomial hermite factors .",
    "let @xmath32 denote the group of permutations of @xmath1 elements . by applying @xmath33 to a basis @xmath34 $ ] , the basis vectors are reordered @xmath35 $ ] . for @xmath36",
    "we define a class of elements @xmath37 as follows : @xmath38 note that @xmath39 and that @xmath40 is swapping the two elements  @xmath41 and @xmath42 .",
    "let @xmath43 $ ] .",
    "a basis @xmath34 $ ] of a lattice @xmath44 is called _",
    "@xmath45-lll reduced _ if and only if it satisfies the following two conditions :    1 .",
    "@xmath46 ( size - reduced ) .",
    "2 .   @xmath47 ( lovsz - condition ) .",
    "a @xmath45-lll reduced basis @xmath34 $ ] can be computed in polynomial time @xcite and provably satisfies the following bounds : @xmath48 while these bounds can be reached , they are worst case bounds . in practice ,",
    "lll reduction algorithms behave much better @xcite .",
    "one early attempt to improve the lll reduction algorithm is due to schnorr and euchner @xcite who came up with the notion of a deeplllreduced basis :    let @xmath43 $ ] .",
    "a basis @xmath34 $ ] of a lattice @xmath44 is called _ @xmath45-deeplllreduced with blocksize @xmath49 _ if and only if it satisfies the following two conditions :    1 .   @xmath50 ( size - reduced ) .",
    "2 .   @xmath51 .",
    "if @xmath52 we simply call this a deeplllreduced basis .",
    "while the first basis vector of deeplllreduced bases in the worst case does not achieve a better hermite factor than classical lll ( see section [ sec : critical ] ) , the according reduction algorithms usually return much shorter vectors than pure lll . unfortunately no polynomial time algorithm to compute deeplllreduced bases",
    "is known .",
    "the following definition is used in the proof ( see e.g. @xcite ) of the polynomial running time of the lll reduction algorithm and will play a main role in our improved variant of lll .",
    "the _ potential _ @xmath53 of a lattice basis @xmath34 $ ] is defined as @xmath54    here it is used that @xmath55 . note that , unlike the volume of the lattice , the potential of a basis is variant under basis permutations .",
    "the following lemma describes how the potential changes if @xmath56 is applied to the basis .",
    "[ lem : pot ] let @xmath34 $ ] be a lattice basis . then for @xmath36 @xmath57    first note that it is well - known that @xmath58 .",
    "this property is used in the proofs of the polynomial running time of lll @xcite .",
    "we prove the claim by induction over @xmath59 .",
    "the claim is true for @xmath60 . for @xmath61 , @xmath62 .",
    "as @xmath63 is the @xmath64-th basis vector of @xmath65 , with the above identity we get @xmath66 , which completes the proof .",
    "in this section we present our polynomial time variant of deeplll .",
    "we start with the definition of a @xmath45-potlll  reduced basis",
    ". then we present an algorithm that outputs such a basis followed by a runtime proof .",
    "[ def : potlll ] let @xmath67 $ ] . a lattice basis @xmath34 $ ] is",
    "_ @xmath45-potlllreduced _ if and only if    1 .",
    "@xmath50 ( size - reduced ) .",
    "2 .   @xmath68 .",
    "a @xmath45-potlllreduced basis @xmath6 is also @xmath45-lll reduced .",
    "lemma  [ lem : pot ] shows that @xmath69 if and only if @xmath70 .",
    "thus the lovsz condition is implied by the second condition in definition  [ def : potlll ] restricted to consecutive pairs , i.e.  @xmath71 .",
    "[ lem : dlllplll ] a @xmath45-deeplllreduced basis @xmath6 is also @xmath72-potlllreduced .",
    "we proceed by contradiction .",
    "assume that @xmath6 is not @xmath72-potlllreduced , i.e. there exist @xmath73 such that @xmath74 .",
    "by lemma  [ lem : pot ] this is equivalent to @xmath75 it follows that there exist a @xmath76 $ ] such that @xmath77 which implies that @xmath6 is not @xmath45-deeplllreduced .      a high - level version of the algorithm is presented as algorithm  [ alg : potlll ] .",
    "the algorithm is very similar to the classical lll algorithm and the classical deeplllreduction by schnorr and euchner @xcite . during its execution ,",
    "the first @xmath78  basis vectors are always @xmath45-potlllreduced ( this guarantees termination of the algorithm ) . as opposed to classical lll , and similar to deeplll , @xmath79 might decrease by more than one .",
    "this happens precisely during deep insertions : in these cases , the @xmath79-th vector is not swapped with the @xmath80-th one , as in classical lll , but with the @xmath41-th one for @xmath81 . in case @xmath82 , this equals the swapping of adjacent basis vectors as in classical lll .",
    "the main difference of potlll  and deeplll  is the condition that controls insertion of a vector .",
    "@xmath83 @xmath6      there are two details to consider when implementing algorithm  [ alg : potlll ] .",
    "the first one is that since the basis vectors  @xmath84 are already @xmath45-potlllreduced , they are in particular also size - reduced .",
    "moreover , the basis vectors @xmath85 will be considered later again .",
    "so in line  [ alg : potlll : sizereduce ] of the algorithm it suffices to size - reduce @xmath63 by @xmath84 as in classical lll . upon termination ,",
    "when @xmath86 , the whole basis will be size - reduced .",
    "another thing to consider is the computation of the potentials of @xmath6 and @xmath87 for @xmath88 in line  [ alg : potlll : min ] .",
    "computing the potential of the basis is a rather slow operation .",
    "but we do not need to compute the potential itself , but only compare @xmath89 to @xmath53 ; by lemma  [ lem : pot ] , this quotient can be efficiently computed .",
    "define @xmath90 .",
    "the `` if''-condition in line  [ alg : potlll : if ] will then change to @xmath91 , and the minimum in line  [ alg : potlll : min ] will change to @xmath92 . using @xmath93 and @xmath94 for @xmath95 ( lemma  [ lem : pot ] )",
    ", we can quickly determine @xmath96 and check whether @xmath91 if @xmath97 minimizes @xmath98 .",
    "a detailed version of algorithm  [ alg : potlll ] with these steps filled in is described as algorithm  [ alg : potlll : full ] . on line  [ alg : potlll : full : potmod ] of algorithm  [ alg : potlll : full ] , @xmath98 is iteratively computed as in equation  .",
    "clearly , the algorithm could be further improved by iteratively computing @xmath99 from @xmath100 .",
    "depending on the implementation of the gram - schmidt orthogonalization , this might already have been computed and stored .",
    "for example , when using the gram - schmidt orthogonalization as described in figure  4 of  @xcite , then @xmath101 after computation of @xmath102 and @xmath103 for @xmath104 .",
    "@xmath83 @xmath6      here we show that the number of operations in the potlllalgorithm are bounded polynomially in the dimension @xmath1 and the logarithm of the input size .",
    "we present the runtime for algorithm  [ alg : potlll : full ] .",
    "[ prop : potlll2 ] let @xmath105 and @xmath106 .",
    "then algorithm  [ alg : potlll : full ] performs @xmath107 iterations of the ` while ` loop in line  [ alg : potlll : full : while ] and a total of @xmath108 arithmetic operations .",
    "let us start by upper bounding the potential @xmath109 of the input basis with respect to @xmath110 .",
    "let @xmath111 for @xmath112 . recall that @xmath113 for @xmath114 and hence @xmath115 .",
    "consequently we have the following upper bound on the potential @xmath116 now , by a standard argument , we show that the number of iterations of the while loop is bounded by @xmath107 . in each iteration , either the iteration counter  @xmath79 is increased by 1 , or a swapping takes place and @xmath79 is decreased by at most @xmath117 . in the swapping case , the potential is decreased by a factor at least @xmath45 .",
    "so after @xmath118 swaps the potential @xmath119 satisfies @xmath120 using the fact that @xmath121 .",
    "consequently the number of swaps  @xmath118 is bounded by @xmath122 . by equation ( [ equ : i ] )",
    "we get that @xmath123 .",
    "now note that the number  @xmath124 of iterations where  @xmath79 is increased by 1 is at most @xmath125 .",
    "this shows that the number of iterations is bounded by @xmath126 .",
    "next we show that the number of operations performed in each iteration of the ` while ` loop is dominated by @xmath127 operations .",
    "size - reduction ( line  [ alg : potlll : full : sizereduce ] ) and the first update step ( line  [ alg : potlll : full : update1 ] ) can be done in @xmath128 steps .",
    "the for - loop consists of @xmath129 iterations where the most expensive operation is the update of p in line  [ alg : potlll : full : potmod ] .",
    "therefore the loop requires @xmath130 arithmetic operations .",
    "swapping can be done in @xmath129 operations , whereas the second update in line  [ alg : potlll : full : update2 ] requires again @xmath130 operations .",
    "it follows that each iteration costs at most @xmath131 arithmetic operations .",
    "this shows that in total the algorithm performs @xmath132 operations .      for @xmath133 ,",
    "there exist so called _ critical bases _ which are @xmath45-lll reduced bases and whose hermite factor reaches the worst case bound in  ( [ equ : hermitelll ] )  @xcite .",
    "these bases can be adapted to form a deeplllreduced basis where the first vector reaches the worst case bound in  ( [ equ : hermitelll ] ) .",
    "[ prop : critical ] for @xmath134 , the rows of @xmath135 ( see below ) define a @xmath45-deeplllreduced basis with @xmath133 and @xmath136 .",
    "@xmath137    from the diagonal form of @xmath138 it is easy to see that @xmath139 .",
    "hence @xmath140 .",
    "it remains to show that @xmath138 is deeplllreduced .",
    "note that @xmath141 is a diagonal matrix with the same entries on the diagonal as @xmath6 .",
    "note that it is size reduced as for all @xmath142 we have @xmath143 .",
    "further , using that @xmath144 , we have that @xmath145 as for @xmath146 , we have that @xmath147 , and hence @xmath148 . therefore , the norms of the projections for fixed  @xmath97 are all equal , and @xmath149 is @xmath45-potlll - reduced with @xmath133 .    using lemma  [ lem : dlllplll ] ,",
    "we obtain :    for @xmath134 , the rows of @xmath149 define a @xmath45-potlllreduced basis with @xmath133 and @xmath136 .",
    "extensive experiments have been made to examine how the classical lll reduction algorithm performs in practice @xcite .",
    "we ran some experiments to compare our potlllalgorithm to our implementations of lll , deeplll , and bkz .",
    "we run the following algorithms , each with the standard reduction parameter @xmath150 :    1 .",
    "classical lll , 2 .",
    "potlll , 3 .",
    "deeplllwith blocksize @xmath151 and @xmath152 ( the latter up to dimension 240 only ) , 4 .",
    "bkz with blocksize @xmath153 ( bkz-5 ) and @xmath154 ( bkz-10 ) .",
    "the implementations all use the same arithmetic back - end .",
    "integer arithmetic is done using gmp , and gram - schmidt arithmetic is done as described in  ( * ? ? ?",
    "* figures  4 and 5 ) . as floating point types ,",
    "` long double ` ( x64 extended precision format , 80  bit representation ) and mpfr arbitrary precision floating point numbers are used with a precision as described in @xcite .",
    "the implementations of deepllland bkz follow the classical description in @xcite .",
    "potlllwas implemented as described in algorithm  [ alg : potlll : full ] ( page  ) .",
    "we ran experiments in dimensions 40 to 300 , considering the dimensions which are multiples of  10 from 40 to 200 and dimensions that are multiples of  20 from 200 to 300 . in each dimension , we considered 50 random lattices .",
    "more precisely , we used the lattices of seed 0 to 49 from the svp challenge . for each lattice",
    ", we used two bases : the original basis and a @xmath155-lll reduced basis .",
    "all experiments were run on intel^^ xeon^^ x7550 cpus at 2  ghz on a shared memory machine . for dimensions 40 up to 160 , we used ` long double ` arithmetic , and for dimensions 160 up to 300 , we used mpfr . in dimension 160 , we did the experiments both using ` long double ` and mpfr arithmetic .",
    "the reduced lattices did not differ . in dimension  170",
    ", floating point errors prevented the ` long double ` arithmetic variant to complete on some of the lattices .",
    "for each run , we recorded the length of the shortest vector as well as the required cpu time for the reduction .",
    "our main interest lies in the @xmath1-th root of the _ hermite factor _",
    "@xmath156 , where @xmath157 is the shortest vector of the basis of @xmath26 returned .",
    "figure  [ fig : overview ] ( see pages  - for all figures ) compares the average @xmath1-th root of the hermite factor and average logarithmic running time of the algorithms for all dimensions .",
    "the graphs also show confidence intervals for the average value with a confidence level of 99.9% .",
    "as one can see , there is a clear hierarchy with respect to the achieved hermite factor .",
    "our potlllperforms better than bkz-5 , though worse than deeplllwith @xmath158 and bkz-10 , which in turn perform worse than deeplllwith @xmath159 .",
    "the behavior for preprocessed bases and bases in hermite normal form is very similar .",
    "we collected the average @xmath1-th root hermite factors @xmath160 in table  [ table : red ] and compared them to the worst - case bound in equation  .",
    "our data for lll is similar to the one in @xcite and ( * ? ? ?",
    "* table  1 ) .",
    "however , we do not see convergence of the @xmath1-th root hermite factors in our experiments , as they are still increasing even in high dimensions @xmath161 .",
    ".worst case bound and average case estimate for @xmath45-lll reduction , @xmath45-deeplll reduction , @xmath45-potlllreduction and @xmath45-bkz reduction of the @xmath1-th root hermite factor @xmath162 .",
    "the entries are sorted in descending order with respect to the observed hermite factors . [ cols=\"<,<,<,<,<,<,<\",options=\"header \" , ]     for the running time comparison , figure  [ fig : overview : time ] shows that the observed order is similar to the order induced by the hermite factors .",
    "lll is fastest , followed by bkz-5 and potlll , then by bkz-10 and deeplllwith @xmath158 , and finally there is deeplllwith @xmath159 .",
    "the running time of potllland bkz-5 is very close to each other for higher dimensions , while potlllis clearly slower for smaller dimensions . while figure  [ fig : overview : time ] shows that bkz-5 is usually slightly faster than potllland bkz-10 slightly faster than deeplllwith @xmath158 , the behavior is more interesting if one considers preprocessed and non - preprocessed bases separately .",
    "we do this in figures  [ fig : comparism : up ] and [ fig : comparism : pp ] . recall that the unprocessed bases are bases in hermite normal form , and the processed bases are the same bases run through 0.75-lll .    in figures  [ fig : comparism : up ] , we compare the behavior for unprocessed bases in hermite normal form .",
    "every line connecting bullets corresponds to the behavior of one algorithm for different dimensions .",
    "again , the box surrounding a bullet is a confidence interval with confidence level 99.9% .",
    "the shaded regions show which hermite factors can be achieved in every dimension by these algorithms .",
    "algorithms on the border of the region are optimal for their hermite factor : none of the other algorithms in this list produces a better average hermite factor in less time . in figure",
    "[ fig : comparism : up : ld ] , one can see that bkz-5 produces worse output slower than potlllup to dimension  160 . also , bkz-10 is inferior to deeplllwith @xmath158 as it is both slower and produces worse hermite factors .",
    "as the dimension increases , the difference in running time becomes less and less .",
    "in fact , for dimension  180 and larger , bkz-10 becomes faster than deeplllwith @xmath163 ( figure  [ fig : comparism : up : real ] ) .    on the other hand , for preprocessed bases , the behavior is different , as figure  [ fig : comparism : pp ] shows .",
    "here , bkz-5 is clearly faster than potllland bkz-10 clearly faster than deeplllwith @xmath158 .",
    "in fact , for dimensions 60 , 80 and 100 , potlllis slower than bkz-10 while producing worse output ( figure  [ fig : comparism : pp : ld ] ) . for higher dimensions ,",
    "potlllis again faster than bkz-10 ( figure  [ fig : comparism : pp : real ] ) , though not substantially .",
    "therefore , for preprocessed bases , it seems that bkz-10 is more useful than potllland deeplllwith @xmath158 .",
    "( @xmath164 axis ) from 40 to 300 ( using mpfr for @xmath165 ) . ]",
    "( @xmath164 axis ) from 40 to 300 ( using mpfr for @xmath165 ) . ]",
    "-th root hermite factor ( @xmath166 axis ) vs. running times ( @xmath164 axis ) for both arithmetics for the original bases . ]",
    "-th root hermite factor ( @xmath166 axis ) vs. running times ( @xmath164 axis ) for both arithmetics for the original bases . ]",
    "-th root hermite factor ( @xmath166 axis ) vs. running times ( @xmath164 axis ) for both arithmetics for preprocessed bases ( 0.75-lll - reduced bases ) .",
    "]    -th root hermite factor ( @xmath166 axis ) vs. running times ( @xmath164 axis ) for both arithmetics for preprocessed bases ( 0.75-lll - reduced bases ) . ]",
    "we present a first provable polynomial time variant of schnorr and euchner s deeplll . while the provable bounds are not better than for classical lll  in fact , for reduction parameter  @xmath167 , the existence of critical bases shows that better bounds do not exist ",
    "the practical behavior is much better than for classical lll .",
    "we see that the @xmath1-th root hermite factor of an @xmath1-dimensional basis output by potlllin average does not exceed @xmath168 for @xmath169",
    ".    for unprocessed random bases in hermite normal form , potllleven outperforms bkz-5 .",
    "our experiments also show that for such bases , deeplllwith @xmath158 outperforms bkz-10 . on the other hand , for bases which are already reasonably preprocessed , for example by applying 0.75-lll to a basis in hermite normal form ,",
    "our algorithm is only slightly faster and sometimes even slower than bkz-10 , while producing longer vectors .",
    "it is likely that the improvements of the @xmath170 algorithm  @xcite and the @xmath171 algorithm  @xcite can be used to improve the runtime of our potlll  algorithm , in order to achieve faster runtime .",
    "we leave this for future work .",
    "moreover , deep insertions can be used together with bkz as well . in particular ,",
    "potential minimizing deep insertions can be used .",
    "we added classical deep insertions and potential minimizing deep insertions to bkz .",
    "first experiments up to dimension  120 suggest that with regard to the output quality , bkz-5 with potential minimizing deep insertions is better than potlll , but worse than bkz-5 with classical deep insertions , which in turn comes close to bkz-10 .",
    "bkz-10 with potential minimizing deep insertions is close to deeplllwith @xmath158 , and bkz-10 with classical deep insertions close to deeplllwith @xmath159 . for dimensions around 100",
    ", the speed of similarly performing algorithms also behaves similarly .",
    "this work was supported by cased ( http://www.cased.de ) .",
    "michael schneider is supported by project bu  630/23 - 1 of the german research foundation ( dfg ) .",
    "urs wagner and felix fontein are supported by snf grant no ."
  ],
  "abstract_text": [
    "<S> lattice reduction algorithms have numerous applications in number theory , algebra , as well as in cryptanalysis . the most famous algorithm for lattice reduction </S>",
    "<S> is the lll algorithm . in polynomial time it computes a reduced basis with provable output quality . </S>",
    "<S> one early improvement of the lll algorithm was lll with deep insertions ( deeplll ) . </S>",
    "<S> the output of this version of lll has higher quality in practice but the running time seems to explode . </S>",
    "<S> weaker variants of deeplll , where the insertions are restricted to blocks , behave nicely in practice concerning the running time . </S>",
    "<S> however no proof of polynomial running time is known . in this paper a new variant of deeplllwith provably polynomial running time is presented . </S>",
    "<S> we compare the practical behavior of the new algorithm to classical lll , bkz as well as blockwise variants of deeplllregarding both the output quality and running time .    </S>",
    "<S> keywords : lattice reduction , lll algorithm , deep insertion    mathematics subject classification ( 2000 ) : 68r05 and 94a60 </S>"
  ]
}