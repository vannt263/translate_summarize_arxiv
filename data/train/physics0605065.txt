{
  "article_text": [
    "complex adaptive systems ( cas ) are of great theoretical interest because they comprise large numbers of interacting objects or ` agents ' which , unlike particles in traditional physics , change their behaviour based on experience @xcite .",
    "such adaptation yields complicated feedback processes at the microscopic level , which in turn generate complicated global dynamics at the macroscopic level .",
    "cas also arguably represent the ` hard ' problem in biology , engineering , computation and sociology@xcite . depending on the application domain ,",
    "the agents in cas may be taken as representing species , people , cells , computer hardware or software , and are typically quite numerous , e.g. @xmath0@xcite .",
    "there is also great practical interest in the problem of predicting and subsequently controlling a complex adaptive system .",
    "consider the enormous task facing a complex adaptive systems ` manager ' in charge of overseeing some complicated computational , biological , medical , sociological or even economic system .",
    "he would certainly like to be able to predict its future evolution with sufficient accuracy that he could foresee the system heading towards any ` dangerous ' areas .",
    "however , prediction is not enough  he also needs to be able to steer the system away from this dangerous regime .",
    "furthermore , the cas manager needs to be able to achieve this @xmath1 detailed knowledge of the present state of its thousand different components , nor does he want to have to shut down the system completely .",
    "instead he is seeking for some form of ` soft ' control which can be applied ` online ' while the system is still evolving .",
    "such online management of a complex system therefore represents a significant theoretical and practical challenge .",
    "however , the motivation for pursuing such a goal is equally great given the wide range of important real - world systems that can be regarded as complex  from engineering systems through to human health , social systems and even financial systems .    in purely deterministic systems with only a few degrees of freedom",
    ", it is well known that highly complex dynamics such as chaos can arise @xcite making any control very difficult .",
    "the ` butterfly effect ' whereby small perturbations can have huge uncontrollable consequences , comes to mind .",
    "one would think that things would be considerably worse in a cas , given the much larger number of interacting objects . as an additional complication",
    ", a cas may also contain stochastic processes at the microscopic and/or macroscopic levels , thereby adding an inherently random element to the system s dynamical evolution .",
    "the central limit theorem tells us that the combined effect of a large number of stochastic processes tends fairly rapidly to a gaussian distribution .",
    "hence , one would think that even with reasonably complete knowledge of the present and past states of the system , the evolution would be essentially diffusive and hence difficult to control without imposing substantial global constraints .    in this paper",
    ", we address this question of dynamical control for a simplified yet highly non - trivial model of a cas .",
    "we show that a surprising level of prediction and subsequent control can be achieved by introducing small perturbations to the agent heterogeneity , i.e. ` population engineering ' . in particular , the system s global evolution can be managed and undesired future scenarios avoided . despite the many degrees of freedom and inherent stochasticity both at the microscopic and macroscopic levels , this global control requires only minimal knowledge on the part of the ` system manager ' . for the somewhat simpler case of cellular automata , israeli and goldenfeld@xcite",
    "have recently obtained the remarkable result that computationally irreducible physical processes can become computationally reducible at a coarse - grained level of description .",
    "based on our findings , we speculate that similar ideas may hold for a far wider class of system comprising populations of decision - taking , adaptive agents .    it is widely believed ( see for example , ref .",
    "@xcite ) that arthur s so - called el farol bar problem @xcite provides a representative toy model of a cas where objects , components or individuals compete for some limited global resource ( e.g. space in an overcrowded area ) . to make this model more complete in terms of real - world complex systems ,",
    "the effect of network interconnections has recently been incorporated @xcite .",
    "the el farol bar problem concerns the collective decision - making of a group of potential bar - goers ( i.e. agents ) who use limited global information to predict whether they should attend a potentially overcrowded bar on a given night each week .",
    "the statistical mechanics community has adopted a binary version of this problem , the so - called minority game ( mg ) ( see refs.@xcite through @xcite ) , as a new form of ising model which is worthy of study in its own right because of its highly non - trivial dynamics . here",
    "we consider a general version of such multi - agent games which ( a ) incorporates a finite time - horizon @xmath2 over which agents remember their strategies past successes , to reflect the fact that the more recent past should have more influence than the distant past , and ( b ) allows for fluctuations in agent numbers , since agents only participate if they possess a strategy with a sufficiently high success rate@xcite .",
    "the formalism we employ is applicable to any cas which can be mapped onto a population of @xmath3 objects repeatedly taking actions in the form of some global ` game ' .",
    "the paper has several parts . initially",
    "( section  [ sec : dice ] ) , we discuss a very simple two state ` game ' to introduce and familiarise the reader to the nature of the mathematics which is explored in further detail in the rest of the paper .",
    "we then more formally establish a common framework for describing the spectrum of future paths of the complex adaptive system ( section  [ sec : formal ] ) .",
    "this framework is general to any complex system which can be mapped onto a general b - a - r ( binary agent resource ) model in which the system s future evolution is governed by past history over an arbitrary but finite time window @xmath2 ( the @xmath4 ) .",
    "in fact , this formalism can be applied to any cas whose internal dynamics are governed by a markov process@xcite , providing the tools whereby we can monitor the future evolution both with and without the perturbations to the population s composition . in section  [ sec : bar ] , we discuss the b - a - r model in more detail , further information is provided in @xcite .",
    "we emphasize that such b - a - r systems are _ not _ limited to the well - known el farol bar problem and minority games - instead these two examples are specific limiting cases .",
    "initial investigations of a finite time - horizon version of the minority game were first presented in @xcite . in section  [",
    "sec : natural ] , we consider the system s evolution in the absence of any such perturbations , hence representing the system s natural evolution . in section  [ sec : evolution ] , we revisit this evolution in the presence of control , where this control is limited to relatively minor perturbations at the level of the heterogeneity of the population . in section  [ sec : reduction ] we revisit the toy model of section  [ sec : dice ] to provide a reduced form of formalism for generating averaged quantities of the future possibilities . in section  [ sec : conclusion ] we discuss concluding remarks and possible extensions .",
    "in this section we examine a very simple toy model employed to generate a time series ( analogue output ) and introduce the future - cast formalism to describe the model s properties .",
    "this toy model comprises two internal states , * _ a _ * and * _ b _ * , and two dice also denoted * _ a _ * and * _ b_*. we make these dice generic in that we assign their faces values and these are not equal in likelihood .",
    "the rules of the model are very simple .",
    "when the system is in state * _ a _ * , dice * _ a _ * is rolled and similarly for dice * _ b_*. the outcome , @xmath5 , of the relevant dice is used to increment a time ( price ) series , whose update can be written @xmath6     the internal state transitions on the de bruijn graph.,scaledwidth=65.0% ]    the model employs a very simple rule to govern the transitions between its internal states . if the outcome @xmath5 is greater than zero ( recall that we have re - assigned the values on the faces ) the internal state at time @xmath7 is * _ a _ * and consequently dice * _ a _ * will be used at the next step regardless of the dice used at this time step .",
    "conversely , if @xmath8 , the internal state at @xmath7 will be * _ b _ * and dice * _ b _ * used for the next increment .",
    "these transitions are shown in figure  [ fig : dicetransitions ] .     the outcomes and associated probabilities of our two dice.,scaledwidth=75.0% ]",
    "let us prescribe our dice some values and observe the output of the system , namely rolling dice * _ a _ * could yield values @xmath9 with probabilities @xmath10 and * _ b _ * yields values @xmath11 with probabilities @xmath12 .",
    "these are shown in figure  [ fig : diceprobs ] .",
    "let us consider that at some time @xmath13 the system is in state * _ a _ * with the value of the time series being @xmath14 and we wish to investigate the possible output over the next @xmath15 time - steps ( @xmath16 ) .",
    "some examples of the system s change in output over the next @xmath17 time - steps are shown in figure  [ fig : output ] .",
    "the circles represent the system being in state * _ a _ * and the squares the system in * _ b_*.     the toy model s output over 10 time - steps for 20 realisations where the state at time @xmath13 is * _ a _ * for all paths .. the circles represent the system being in state * _ a _ * and the squares the system in * _ b_*. , scaledwidth=75.0% ]    the stochasticity inherent in the system is evident in figure  [ fig : output ] .",
    "many possible paths could be realised even though they all originate from state * _ a _ * , and only a few of them are depicted . if one wanted to know more about system s output after these @xmath17 time - steps , one could look at many more runs and look at a histogram of the output for @xmath18 .",
    "this monte - carlo@xcite technique has been carried out in figure  [ fig : output2 ] .",
    "it denotes the possible change in value of the systems analogue output after @xmath17 time - steps and associated probability derived from @xmath19 runs of the system all with the same initial starting state ( * _ a _ * ) at time @xmath13 .",
    "however , this method is a numerical approximation . for accurate analysis of the system over longer time scales , or for more complex systems",
    ", it might prove both inaccurate and/or computationally intensive .",
    "the change in the system s output @xmath20 at @xmath21 , and associated probability as calculated for @xmath19 time - series realisations.,scaledwidth=75.0% ]    for a more detailed analysis of our model , we must look at the internal state dynamics and how they map to the output .",
    "let us consider all possible eventualities over @xmath22 time - steps , again starting in state * _ a _ * at time @xmath13 .",
    "all possible paths are denoted on figure  [ fig:2step ] .",
    "the resulting possible values of change in the output at time @xmath23 time - steps and their associated probabilities are given explicitly too .",
    "these values are exact in that they are calculated from the dice themselves .",
    "the @xmath24 frame work which we now introduce will allow us to perform similar analysis over much longer periods .",
    "all possible paths after @xmath22 time - steps and associated probability.,scaledwidth=75.0% ]    first consider the possible values of @xmath25 , which result in the system being in state * _ a_*. the state transitions that could have occurred for these to arise are * _ a _ * @xmath26 * _ a _ * @xmath26 * _ a _ * or * _ a _ * @xmath26 * _ b _ * @xmath26 * _ a_*. the paths following the former can be considered a convolution ( explores all possible paths and probabilitieswe define and use the discrete convolution operator @xmath27 such that @xmath28 . ] ) of the distribution of possible values of @xmath29 in state * _ a _ * with the distribution corresponding to the * _ a _ * @xmath26 * _ a _ * transition .",
    "likewise , the latter a convolution of the distribution of @xmath29 in state * _ b _ * with the distribution corresponding to a * _ b _ * @xmath26 * _ a _ * transition .",
    "the resultant distribution of possibilities in state * _ a _ * at time @xmath23 is just the superposition of these convolutions as described in figure  [ fig : conv ] .",
    "we can set the initial value @xmath14 to zero because the absolute position has no bearing on the evolution on the system .",
    "as such @xmath30 .",
    "all possible paths after @xmath22 time - steps which could result in the system being in state * _ a_*.,scaledwidth=95.0% ]    so we note that if at some time @xmath31 there exists a distribution of values in our output which are in state * _ a _ * then the convolution of this with the * _ b _ * @xmath26 * _ a _ * transition distribution will result in a contribution at @xmath32 to our distribution of @xmath33 which will also be in * _",
    "a_*. this is evident in the right hand side of [ fig : conv ] .",
    "let us define all these distributions .",
    "we denote all possible values in our output @xmath15 time - steps beyond the present ( time @xmath13 ) that are in state * _ a _ * as the function @xmath34 and @xmath35 is the function that describes the values of our output time series that are in state * _ b _ * ( as shown in figure  [ fig : conv ] ) .",
    "we can similarly describe the transitions as prescribed by our dice .",
    "the possible values allowed and corresponding likelihoods for the * _ a _ * @xmath26 * _ a _ * transition are denoted @xmath36 and similarly @xmath37 for * _ a _ * @xmath26 * _ b _ * , @xmath38 for * _ b _ * @xmath26 * _ a _ * and @xmath39 for the * _ b _ * @xmath26 * _ b _ * state change .",
    "these are shown in figure  [ fig : dicetrans ] .",
    "the state transition distributions as prescribed by our dice.,scaledwidth=75.0% ]    we can now construct the future - cast . we can express the evolution of the output in their corresponding states as the superposition of the required convolutions : @xmath40 where @xmath27 is the discrete convolution operator as defined in footnote  [ foot : conv ] . recall that @xmath41 has been set to zero such that we can consider the possible changes in output and the output itself to be identical .",
    "we can write this more concisely : @xmath42 where the element @xmath43 contains the function @xmath44 and the operator @xmath27 and the element @xmath45 is the distribution @xmath46 .",
    "we note that this matrix of functions and operators is static , so only need computing once . as such we can rewrite equation  [ eqn : fut2 ] as @xmath47 such that @xmath48 contains the state - wise information of our starting point ( time @xmath13 ) .",
    "this is the future - cast process . for a system starting in state * _ a _ * and with the start value of the time series of zero , the elements of @xmath48 are as shown in figure  [ fig : start1 ] .",
    "the initial elements of our output distributions vector , @xmath48 when starting the system in state * _ a _ * with initial value of zero in our time series.,scaledwidth=75.0% ]    applying the future - cast process , we can look precisely at the systems potential output at any number of time - steps into the future . if we wish to consider the process over 10 steps again , we applying as following : @xmath49 the resultant distribution of possible outputs ( we denote @xmath50 ) is then just the superposition of the contributions from each state .",
    "this distribution of the possible outputs at some time into the future is what we call the @xmath24 .",
    "@xmath51 this leads to distribution shown in figure  [ fig : dicefutcast ] .",
    "the actual probability distribution @xmath52 of the output after 10 time - steps starting the system in state * _ a _ * with initial value of zero in our time series.,scaledwidth=75.0% ]    although the exact output as calculated using the future - cast process demonstrated in figure  [ fig : dicefutcast ] compares well with the brute force numerical results of the monte - carlo technique in figure  [ fig : output2 ] , it allows us to perform some more interesting analysis without much more work , let alone computational exhaustion .",
    "consider that we do nt know the initial state of the system or that we want to know characteristic properties of the system .",
    "this might include wanting to know what the system does , on average over one time - step increments .",
    "we could for example look run the system for a very long time and investigate a histogram of the output movements over single time - steps as shown in figure  [ fig : hist1 ] .",
    "the one step increments of our time - series as run over 10000 steps.,scaledwidth=75.0% ]    however , we can use the formalism to generate this result exactly .",
    "imagine that model has been run for a long time but we do nt know which state it is in . using the probabilities associated with the transitions between the states , we can infer the likelihood that the system s internal state is either * _ a _ * or * _ b_*. let the element @xmath53 represent the probability that the system is in state * _ a _ * at some time @xmath13 and @xmath54 that the system is in state * _ b_*. we can express these quantities at time @xmath7 by considering the probabilities of going between the states : @xmath55 where @xmath56 represents the probability that when the system is in state * _ a _ * it will be in state * _ a _ * at the next time - step .",
    "we can express this more concisely : @xmath57 such that @xmath58 is equivalent to @xmath56 .",
    "this is a markov chain . from the nature of our dice",
    ", we can trivially calculate the elements of @xmath59 .",
    "the value for @xmath56 is the sum over all elements in @xmath44 or more precisely : @xmath60 the markov chain transition matrix @xmath59 for our system can thus be trivially written : @xmath61 the static probabilities of the system being in either of its two states are given by the eigenvector solution to equation  [ eqn : eig ] with eigenvalue @xmath62 .",
    "this is equivalent to looking at the relative occurrence of the two states if the system were to be run over infinite time .",
    "@xmath63 for our system , the static probability associated with being in state * _ a _ * is @xmath64 and obviously @xmath65 for state * _ b_*. to look at the characteristic properties we are going to construct an initial vector similar to @xmath66 in equation  [ eqn : fut1 ] ) for our future - cast formalism to act on but which is related to the static probabilities contained by the solution to equation  [ eqn : eig ] .",
    "this vector is denoted @xmath67 and its form is described in figure  [ fig : kappa ] .",
    "explicit depiction of the elements of vector @xmath67 which is used to analyse characteristic behaviour of the system.,scaledwidth=50.0% ]    we use employ @xmath67 in the future - cast over one time - step as in equation  [ eqn : fut6 ] : @xmath68 the resulting distribution of possible outputs from superimposing the elements of @xmath69 is the exact representation of the one time - step increments ( @xmath70 ) of the system if it were allowed to be run infinitely .",
    "we call this characteristic distribution @xmath71 . applying the process",
    "a number of times will yield the exact distributions @xmath72 equivalent to looking at all values of @xmath73 which is a rolling window length @xmath15 over an infinite time series as in figure  [ fig : pis ] .",
    "this is also equivalent to running the system forward in time @xmath15 time - steps from unknown initial state , investigating all possible paths .",
    "the markovian nature of the system means that this is not the same as the convolution of the one time - step characteristic future - cast convolved with it self @xmath15 times .",
    "the characteristic behaviour of the system for @xmath74 time - steps into the future from unknown initial state .",
    "this is equivalent to looking at the relative frequency of occurrence of changes in output values over 1,2 , and 3 time - step rolling windows , scaledwidth=80.0% ]    clearly the characteristic future - cast over one time - step in figure  [ fig : pis ] compares well with that of figure  [ fig : hist1 ] .",
    "here we provide a general formalism applicable to any complex system which can be mapped onto a population of @xmath3 species or ` agents ' who are repeatedly taking actions in some form of global ` game ' . at each time - step",
    "each agent makes a ( binary ) decision @xmath75 in response to the global information @xmath76 which may reflect the history of past global outcomes .",
    "this global information is of the form of a bitstring of length @xmath77 . for a general game",
    ", there exists some winning outcome @xmath78 based on the aggregate action of the agents .",
    "each agent holds a subset of all possible strategies - by assigning this subset randomly to each agent , we can mimic the effect of large - scale heterogeneity in the population .",
    "in other words , we have a simple way of generating a potentially diverse ecology of species , some of which may be similar but others quite different .",
    "one can hence investigate a typically - diverse ecology whereby all possible species are represented , as opposed to special cases of ecologies which may themselves generate pathological behaviour due to their lack of diversity .",
    "the aggregate action of the population at each time - step @xmath13 is represented by @xmath79 , which corresponds to the accumulated decisions of all the agents and hence the ( analogue ) output variable of the system at that time - step .",
    "the goal of the game , and hence the winning decision , could be to favour the minority group ( mg ) , the majority group or indeed any function of the macroscopic or microscopic variables of the system .",
    "the individual agents do not themselves need to be conscious of the precise nature of the game , or even the algorithm for deciding how the winning decision is determined .",
    "instead , they just know the global outcome , and hence whether their own strategies predicted the winning action .",
    "the agents then reward the strategies in their possession if the strategy s predicted action would have been correct if that strategy was implemented . the global history",
    "is then updated according to the winning decision .",
    "it can be expressed in decimal form as follows : @xmath80\\\\ ] ] the system s dynamics are defined by the rules of the game .",
    "we will consider here the class of games whereby each agent uses his highest - scoring strategy at each timestep , and agents only participate if they possess a strategy with a sufficiently high success rate .",
    "[ n.b . both of these assumptions can be relaxed , thereby modifying the actual game being played ] .",
    "the following two scenarios might then arise during the system s evolution :    * an agent has two ( or more ) strategies which are tied in score and are above the confidence level , and the decisions from them differ . * the number of agents choosing each of the two actions is equal , hence the winning decision is undecided .",
    "we will consider these cases to be resolved with a fair ` coin toss ' , thereby injecting stochasticity or ` noise ' into the system s dynamical evolution .",
    "in the first case , each agent will toss his own coin to break the tie , while in the second the game - master tosses a single coin . to reflect the fact that evolving systems will typically be non - stationary , and hence the more distant past",
    "will presumably be perceived as less relevant to the agents , the strategies are rewarded as to whether they would have made correct predictions over the last @xmath2 time - steps of the game s running .",
    "there is no limit on the size of @xmath2 other than it is finite and constant .",
    "the time - horizon represents a trajectory of length @xmath2 on the de bruijn graph in @xmath76 ( history ) space@xcite as shown in figure  [ fig : debruijn ] .",
    "the stochasticity in the game means that for a given time - horizon @xmath2 and a given strategy allocation in the population , the output of the system is not always unique .",
    "we will denote the set of all possible outputs from the game at some number of time - steps beyond the time - horizon @xmath2 , as the future - cast .     a path of time - horizon length @xmath81 ( dashed line ) superimposed on the de bruin graph for @xmath82 .",
    "the 8 global outcome states represent the 8 possible bitstrings for the global information , and correspond to the global outcomes for the past @xmath82 timesteps.,scaledwidth=75.0% ]    it is useful to work in a time - horizon space @xmath83 of dimension @xmath84 .",
    "an element @xmath85 corresponds to the last @xmath86 elements of the bitstring of global outcomes ( or equivalently , the winning actions ) produced by the game .",
    "this dimension is constant in time whereas for a non - time - horizon game it would grow linearly . for any given time - horizon state ,",
    "@xmath85 , there exists a unique score vector @xmath87 which is the set of scores @xmath88 for all the strategies which an agent could possess .",
    "as such , for each particular time - horizon state , there exists a unique probability distribution of the aggregate action , @xmath79 .",
    "this distribution of possible actions when a specified state is reached will necessarily be the same each time that state is revisited .",
    "thus , it is possible to construct a transition matrix ( c.f .",
    "markov chain@xcite ) @xmath59 of probabilities for the movements between these time - horizon states such that @xmath89 can be expressed as @xmath90 where @xmath89 is a vector of dimension @xmath84 containing the probabilities of being in a given state @xmath91 at time @xmath13    the transition matrix of probabilities is constant in time and necessarily sparse . for each state",
    ", there are only two possible winning decisions .",
    "the number of non - zero elements in the matrix is thus @xmath92 .",
    "we can use the transition matrix in an eigenvector - eigenvalue problem to obtain the stationary state solution of @xmath93 .",
    "this also allows calculation of some time - averaged macroscopic quantities of the game @xcite by @xmath94 .",
    "this effectively results in a probability state vector which is time - averaged over an infinite time - interval . ] .    to generate the future - cast",
    ", we want to calculate the quantities in output space . to do this , we require ;    * the probability distribution of @xmath79 for a given time - horizon ; * the corresponding winning decisions , @xmath78 , for given @xmath79 ; * an algorithm generating output in terms of @xmath79 .",
    "to implement the future - cast , we need to map from the transitions in the state space internal to the system to the macroscopic observables in the output space ( often cumulative excess demand ) .",
    "we know that in the transition matrix , the probabilities represent the summation over a distribution of possible aggregate actions which is binomial in the case where the agents are limited to two possible decisions . using the output generating algorithm",
    ", we can construct an ` adjacency ' matrix @xmath95 analogous to the transition matrix @xmath59 , with the same dimensions .",
    "the elements of @xmath95 , contain probability distribution functions of change in output corresponding to the non - zero elements of the transition matrix together with the discrete convolution operator @xmath27 whose form depends on that of the output generating algorithm .",
    "the adjacency matrix of functions and operators can then be applied to a vector , @xmath96 , containing information about the current state of the game and of the same dimension as @xmath83 .",
    "@xmath96 not only describes the time - horizon state positionally through its elements but also the current value in the output quantity @xmath33 within that element . at @xmath97 ,",
    "the state of the system is unique so there is only one non - zero element within @xmath96 .",
    "this element corresponds to a probability distribution function of the current output value , its position within the vector corresponding to the current time - horizon state .",
    "the probability distribution function is necessarily of value unity at the current value or , for a future - cast expressed in terms of change in output from the current value , unity at the origin .",
    "the future - cast process for @xmath15 time - steps beyond the present state can then be described by @xmath98    the actual future - cast , @xmath99 , is then computed by superimposing the elements of the output / time - horizon state vector : @xmath100 thus the future - cast , @xmath101 , is a probability distribution of the outputs possible at @xmath15 time - steps in the future .",
    "as a result of the state dependence of the markov chain , @xmath102 is non - gaussian . as with the steady - state solution of the state space transition matrix , we would like to find a ` steady - state ' equivalent for the output space of the form @xmath103 where the one - timestep future - cast is time - averaged over an infinitely long period .",
    "fortunately , we have the steady state solutions of @xmath93 which are the ( static ) probabilities of being in a given time - horizon state at any time . by representing these probabilities as the appropriate functions",
    ", we can construct an ` initial ' vector , @xmath67 , similar in form to @xmath104 in equation  [ eqn : formal3 ] but equivalent to the eigenvector solution of the markov chain .",
    "we can then generate the solution of equation  [ eqn : formal5 ] for the @xmath105 future - cast , @xmath71 , for a given initial set of strategies .",
    "an element @xmath106 is again a probability distribution which is simply the point ( 0 , @xmath107 ) , the static probability of being in the time - horizon state denoted by the elements position , @xmath108 .",
    "we can then get back to the future - cast @xmath109 we can also generate characteristic future - casts for any number of time - steps , @xmath15 , by pre - multiplying @xmath67 by @xmath110 @xmath111 we note that @xmath112 is not equivalent to the convolution of @xmath71 with itself @xmath15 times and as such is not necessarily gaussian .",
    "the characteristic future - cast over @xmath15 time - steps is simply the future - cast of length @xmath15 from all the @xmath84 possible initial states where each contribution is given the appropriate weighting factor .",
    "this factor corresponds to the probability of being in that initial state .",
    "the characteristic future - cast can also be expressed as @xmath113    where @xmath114 is a normal future - cast from an initial time - horizon state @xmath91 and @xmath115 is the static probability of being in that state at a given time .",
    "the general binary framework of the b - a - r ( binary agent resource ) system was discussed in section  [ sec : formal ] .",
    "the global outcome of the ` game ' is represented as a binary digit which favours either those choosing option @xmath116 or option @xmath117 ( or equivalently @xmath62 or @xmath118 , a or b etc . ) .",
    "the agents are randomly assigned @xmath119 strategies at the beginning of the game .",
    "each strategy comprises an action @xmath120 in response to each of the @xmath121 possible histories @xmath122 , thereby generating a total of @xmath123 strategies in the full strategy space",
    ". strategies , containing strategies which are either anti - correlated or uncorrelated with each other@xcite .",
    "the framework established in the present paper is general to both the full and reduced strategy spaces , hence the full strategy space will be adopted here .",
    "] at each turn of the game , the agents employ their most successful strategy , being the one with the most virtual points .",
    "are thus adaptive if @xmath124 .     schematic diagram of the binary agent resource ( b - a - r ) system.,scaledwidth=90.0% ]    we have already extended the b - a - r system by introducing the time - horizon @xmath2 , which determines the number of past time - steps over which virtual points are collected for each strategy .",
    "we further extend the system by the introduction of a confidence level .",
    "the agents decide whether to participate or not depending on the success of their strategies .",
    "as such , the number of active agents @xmath125 is less than or equal to @xmath126 at any given time - step .",
    "this results in a variable number of participants per time - step @xmath127 , and constitutes a ` grand canonical ' game .",
    "the threshold , @xmath128 , denotes the confidence level : each agent will only participate if he has a strategy with at least @xmath129 points where @xmath130 agents without an active strategy become temporarily inactive .    in keeping with typical biological , ecological , social or computational systems ,",
    "the game - master takes into account a finite global resource level when deciding the winning decision at each time - step . for simplicity",
    ", we will here consider the specific case itself could be actually be a stochastic function of the known system parameters .",
    "] whereby the resource level @xmath131@xmath127 with @xmath132@xmath133@xmath134@xmath62 .",
    "we denote the number of agents choosing action @xmath116 ( or equivalently a ) as @xmath135 , and those that choose action -1 ( or equivalently b ) as @xmath136 . if @xmath137 the winning action is @xmath116 and vice - versa .",
    "we define the winning decision @xmath62 or @xmath118 as follows : @xmath138\\ ] ] where we define @xmath139 $ ] to be @xmath140",
    "= \\left\\{\\begin{array}{lll } 1 & \\textrm{if } x>0,\\\\ 0 & \\textrm{if } x<0,\\\\ \\textrm{fair coin toss } &           \\textrm{if } x           = 0.\\end{array }           \\right.\\ ] ] when @xmath141 , there is no definite winning option since @xmath142 , hence the game - master uses a random coin - toss to decide between the two possible outcomes .",
    "we use a binary payoff rule for rewarding strategy scores , although more complicated versions can , of course , be used .",
    "however , we note that non - binary payoffs ( e.g. a proportional payoff scheme ) will decrease the probability of tied strategy scores , hence making the system more deterministic .",
    "since we are interested in seeing the extent to which stochasticity can prevent control , we are instead interested in preserving the presence of such stochasticity . the reward function @xmath143 can be written @xmath144           = \\left\\{\\begin{array}{ll } 1 & \\textrm{for }          w(t)=1,\\\\ -1 & \\textrm{for } w(t)=0,\\end{array }           \\right.\\ ] ] namely + 1 for predicting the correct action and -1 for predicting the incorrect one . for a given strategy , @xmath145 , the virtual points score",
    "is given by@xmath146,\\ ] ] where @xmath147 is the response of strategy , @xmath145 , to the global information @xmath76 summed over the rolling window of width @xmath2 .",
    "the global output signal @xmath148 is calculated at each iteration to generate an output time series .",
    "to realize all possible paths within a given game is necessarily computationally expensive . for a future - cast @xmath15 timesteps beyond the current game state , there are necessarily @xmath149 winning decisions to be considered .",
    "fortunately , not all winning decisions are realized by a specific game and the numerical generation of the future - cast can be made reasonably efficient .",
    "fortunately we can approach the future - cast analytically _ without _ having to keep track of the agents individual microscopic properties .",
    "instead we group the agents together via the population tensor of rank @xmath119 given by @xmath150 , which we will refer to as the quenched disorder matrix ( qdm ) @xcite .",
    "this matrix is assumed to be constant over the time - scales of interest , and more typically is fixed at the beginning of the game .",
    "the entry @xmath151 represents the number of agents holding the strategies @xmath152 such that @xmath153 for numerical analysis , it is useful to construct a symmetric version of this population tensor , @xmath154 . for the case @xmath155",
    ", we will let @xmath154 = @xmath156 + @xmath157 @xcite .",
    "the output variable @xmath79 can be written in terms of the decided agents @xmath158 who act in a pre - determined way since they have a unique predicted action from their strategies , and the undecided agents @xmath159 who require an additional coin - toss in order to decide which action to take .",
    "we focus on @xmath155 strategies per agent although the approach can be generalized .",
    "the element @xmath161 represents the number of agents holding both strategy @xmath145 and @xmath162 .",
    "we can now write @xmath158 as @xmath163\\sum_{r'=1}^{q}(1+\\mbox{sgn}[g_{r}(t)-g_{r'}(t)])\\psi_{r , r'}\\ ] ] where @xmath164 is the size of the strategy space , @xmath165 is the heaviside function and @xmath166 $ ] is defined as @xmath167 = \\left\\{\\begin{array}{lll } 1 & \\textrm{if } x>0,\\\\ -1 & \\textrm{if } x<0,\\\\ \\textrm{0 } &           \\textrm{if } x           = 0.\\end{array }           \\right.\\ ] ] the volume @xmath127 of active agents can be expressed as @xmath168\\big\\{sgn[g_{r}(t)-g_{r'}(t)]+\\frac{1}{2}\\delta[g_{r}(t)-g_{r'}(t ) ] \\big\\}\\psi_{r , r'}\\ ] ] where @xmath169 is the dirac delta . the number of undecided agents @xmath170 is given by @xmath171\\delta(g_{r}(t)-g_{r'}(t))[1-\\delta(a_{r}^{\\mu(t)}-a_{r'}^{\\mu(t ) } ) ] \\psi_{r , r'}\\ ] ] we note that for @xmath155 , because each undecided agent s contribution to @xmath79 is an integer , hence the demand of all the undecided agents @xmath159 can be written simply as @xmath172 where @xmath173 is a sample from a binomial distribution of @xmath174 trials with probability of success @xmath175 .",
    "for any given time - horizon space - state @xmath85 , the score vector @xmath87 ( i.e. , the set of scores @xmath88 for all the strategies in the qdm ) is unique .",
    "whenever this state is reached , the quantity @xmath158 will necessarily always be the same , as will the distribution of @xmath159 .",
    "we can now construct the transition matrix @xmath59 giving the probabilities for the movements between these time - horizon states .",
    "the element @xmath176 which corresponds to the transition from state @xmath177 to @xmath85 , is given for the ( generalisable ) @xmath155 case by @xmath178~+    { } \\nonumber\\\\{}^{n_{ud}}c_x(\\frac{1}{2})^{(n_{ud}+1)}\\delta\\bigg[sgn(d_d+2x - n_{ud}+v(1 - 2\\phi))~+~0\\bigg ]    \\bigg\\}\\end{aligned}\\ ] ] where @xmath179 , @xmath180 implies @xmath181 and @xmath182 , @xmath183 implies @xmath184 , @xmath133 sets the resource level as described earlier and @xmath185 is the required winning decision to get from state @xmath177 to state @xmath85 .",
    "we use the transition matrix in the eigenvector - eigenvalue problem to obtain the stationary state solution of @xmath93 .",
    "the probabilities in the transition matrix represent the summation over a distribution which is binomial in the @xmath155 case .",
    "these distributions are all calculated from the qdm which is fixed from the outset . to transfer to output - space , we require an output generating algorithm .",
    "here we use the equation @xmath186 hence the output value @xmath14 represents the cumulative value of @xmath79 , while the increment @xmath29 is simply @xmath79 .",
    "again , we use the discrete convolution operator @xmath27 defined as @xmath187 the formalism could be extended for general output algorithms using differently defined convolution operators .",
    "an element in the adjacency matrix for the @xmath155 case can then be expressed as @xmath188+{}\\nonumber\\\\   { } ^{n_{ud}}c_x(\\frac{1}{2})^{(n_{ud}+1)}\\delta\\bigg[sgn(d_d+2x - n_{ud}+v(1 - 2\\phi))+0\\bigg ]     \\bigg)\\bigg\\}\\otimes~~ \\end{aligned}\\ ] ] where @xmath179 , @xmath180 again implies @xmath181 and @xmath189 , @xmath183 implies @xmath184 , and @xmath190 is the winning decision necessary to move between the required states .",
    "the future - cast and characteristic future - casts ( @xmath101 , @xmath191 ) @xmath15 time - steps into the future can then be computed for a given initial quenched disorder matrix ( qdm ) .",
    "we now consider an example to illustrate the implementation .",
    "in particular , we provide the explicit solution of a future - cast in the regime of small @xmath77 and @xmath2 , given the randomly chosen quenched disorder matrix    @xmath192    we consider the full strategy space and the the following game parameters :    [ cols=\"^,^,^ \" , ]     the dimension of the transition matrix is thus @xmath193 .",
    "@xmath194    each non - zero element in the transition matrix corresponds to a probability function in the output space in the future - cast operator matrix .",
    "consider that the initial state is @xmath195 i.e. the last 4 bits are @xmath196 ( obtained from running the game prior to the future - casting process ) .",
    "the initial probability state vector is the point ( 0,1 ) in the element of the vector @xmath197 corresponding to time - horizon state @xmath17 .",
    "we can then generate the future - cast for given @xmath15 ( shown in figure  [ fig : res1 ] ) .",
    "the ( un - normalized ) evolution of a future - cast for the given @xmath198 , game parameters and initial state @xmath91 .",
    "the figure shows the last 10 time - steps prior to the future - cast , the means of the distributions within the future - cast itself , and also an actual realization of the game run forward in time.,scaledwidth=75.0% ]    clearly the probability function in output space becomes smoother as @xmath15 becomes larger and the number of successive convolutions increases , as highlighted by the probability distribution functions at @xmath199 and @xmath200 ( figure  [ fig : res2 ] ) .     the probability distribution function at @xmath201 time - steps beyond the present state.,title=\"fig:\",scaledwidth=45.0% ]   the probability distribution function at @xmath201 time - steps beyond the present state.,title=\"fig:\",scaledwidth=45.0% ]    we note the non - gaussian form of the probability distribution for the future - casts , emphasising the fact that such a future - cast approach is essential for understanding the system s evolution .",
    "an assumption of rapid diffusion toward a gaussian distribution , and hence the future spread in paths increasing as the square - root of time , would clearly be unreliable .",
    "for less simple parameters , the matrix dimension required for the future - cast process become very large very quickly . to generate a future - cast appropriate to larger parameters e.g. @xmath202 , @xmath203 , it is still however possible to carry out the calculations numerically quite easily . as an example , we generate a random @xmath150 ( the form of which is given in figure  [ fig : figpet ] ) and initial time - horizon appropriate to these parameters .",
    "this time - horizon is obtained by allowing the system to run prior to the future - cast . for visual representation reasons ,",
    "the reduced strategy space@xcite is employed .",
    "the other game parameters are as previously stated .",
    "the game is then instructed to run down every possible winning decision path exhaustively .",
    "the spread of output at each step along each path is then convolved with the next spread such that a future - cast is built up along each path .",
    "fortunately , not all paths are realized at every time - step since the stochasticity in the winning - decision / state - space results from the condition @xmath204 .",
    "the future - cast as a function of @xmath15 and @xmath33 , can thus be built up for a randomly chosen initial quenched disorder matrix ( qdm ) ( [ fig : thesis3d ] ) .",
    "evolution of @xmath205 for a typical quenched disorder matrix @xmath198.,scaledwidth=75.0% ]    we now wish to consider the situation where it is required that the system should not behave in a certain manner .",
    "for example , it may be desirable that it avoid entering a certain regime characterised by a given value of @xmath14 .",
    "specifically , we consider the case where there is a barrier in the output space that the game should avoid , as shown in figure  [ fig : figbarrier1 ] .     the evolution of the future - casts , and the barrier to be avoided . for simplicity the barrier is chosen to correspond to a fixed @xmath14 value of 110 , although there is no reason that it could nt be made time - dependent .",
    "superimposed on the ( un - normalised ) distributions , are the means of the future - casts , while their variances are shown below.,scaledwidth=75.0% ]    the evolution of the spread ( i.e. standard deviation ) of the distributions in time , confirms the non - gaussian nature of the system s evolution  we note that this spread can even decrease with time . in the knowledge that this barrier will be breached by this system , we therefore perturb the quenched disorder at @xmath206",
    ". this perturbation corresponds in physical terms to an adjustment of the composition of the agent population .",
    "this could be achieved by ` re - wiring ' or ` reprogramming ' individual agents in a situation in which the agents were accessible objects , or introducing some form of communication channel , or even a more ` evolutionary ' approach whereby a small subset of species are removed from the population and a new subset added in to replace them .",
    "interestingly we note that this ` evolutionary ' mechanism need neither be completely deterministic ( i.e. knowing exactly how the form of the qdm changes ) nor completely random ( i.e. a random perturbation to the qdm ) . in this sense , it seems tantalisingly close to some modern ideas of biological evolution , whereby there is some purpose mixed with some randomness .",
    "the initial and resulting quenched disorder matrices ( qdm ) , shown in schematic form .",
    "the x - y axes are the strategy labels for the two strategies .",
    "the absence of a symbol denotes an empty bin ( i.e. no agent holding that particular pair of strategies).,scaledwidth=75.0% ]    figure  [ fig : figbarrier2 ] shows the impact of this relatively minor microscopic perturbation on the future - cast and global output of the system .",
    "in particular , the system has been steered away from the potentially harmful barrier into ` safer ' territory .",
    "the evolution as a result of the microscopic perturbation to the population s composition ( i.e. the qdm).,scaledwidth=75.0% ]    this set of outputs is specific to the initial state of the system .",
    "more typically , we may not know this initial state .",
    "fortunately , we can make use of the characteristic future - casts to make some kind of quantitative assessment of the robustness of the quenched disorder perturbation in avoiding the barrier , since this procedure provides a picture of the range of possible future scenarios .",
    "the characteristic evolution of the initial and perturbed qdms.,scaledwidth=75.0% ]    this evolution of the characteristic future - casts , for both the initial and perturbed quenched disorder matrices , is shown in figure  [ fig : charev ] a quantitative evaluation of the robustness of this barrier avoidance could then be calculated using traditional techniques of risk analysis , based on knowledge of the distribution functions and/or their low - order moments .",
    "we introduced the future - cast formalism to map from the internal state space of a complex system to the observable output space .",
    "although the formalism exactly generates the probability distributions of the subsequent output from the system , it s implementation is far from trivial .",
    "this involves keeping track of numerous distributions and performing appropriate convolutions between them .",
    "often , however it is only the lowest order moments which are of immediate concern to the system designer . here ,",
    "we show how this information can be generated without the computational exhaustion previously required .",
    "we demonstrate this procedure for a very simple two state system , although the formalism is general to a system of any number of states , governed by a markov chain .",
    "recall the toy model comprising two dice of section  [ sec : dice ] .",
    "we previously broke down the possible outputs of each according to the state transition as shown in figure  [ fig : reddicestates2 ] .",
    "the state transition distributions as prescribed by our dice.,scaledwidth=75.0% ]    these distributions were used to construct the matrix @xmath207 to form the future - cast process as denoted in equation  [ eqn : fut2 ] .",
    "this acted on vector @xmath208 to generate @xmath209 .",
    "the elements of these vectors contain the partial distribution of outputs which are in the state denoted by the element number at that particular time , so for the two dice model , @xmath210 contains the distribution of output values at time @xmath31 ( or @xmath15 time - steps beyond the present ) which correspond to the system being in state * _ a _ * and @xmath211 contains those for state * _ b_*. to reduce the calculation process , we will consider only the moments of each of these individual elements about zero . as such",
    "we construct a vector , @xmath212 , which takes the form :    @xmath213    the elements are just the @xmath174th moments about zero of the partial distributions within the appropriate state . for @xmath214",
    "this vector merely represents the probabilities of being in either state at some time @xmath31 .",
    "we note that for the @xmath214 case , @xmath215 where @xmath59 is the markov chain transition matrix as in equation  [ eqn : trans2 ] .",
    "we also note that the transition matrix @xmath216 where we define the ( static ) matrix @xmath217 in a similar fashion using the partial distributions ( described in figure  [ fig : reddicestates2 ] ) to be    @xmath218    again , this contains the moments ( about zero ) of the partial distributions corresponding to the transitions between states .",
    "the evolution of @xmath219 , the state - wise probabilities with time is trivial as described above .",
    "for higher orders , we must consider the effects of superposition and convolution on their values .",
    "we know that the for the superposition of two partial distributions , the resulting moments ( any order ) about zero will be just the sum of the moments of the individual distributions , it is just a summation .",
    "the effects of convolution , however must be considered more carefully .",
    "the elements of our vector @xmath220 are the first order moments of the values associated with either of the two states at time @xmath31 .",
    "the first element of which corresponds to those values of output in state * _ a _ * at time @xmath31 .",
    "consider that element one step later , @xmath221 .",
    "this can be written as the superposition of the two required convolutions .",
    "@xmath222    in simpler terms , @xmath223 the @xmath224 term in the expression relates to the nature of series generating algorithm , @xmath225 .",
    "if the series updating algorithm were altered , this would have to be reflected in this convolution .",
    "the overall output of the system is the superposition of the contributions in each state . as such , the resulting first moment about zero ( the mean ) for the overall output at @xmath15 time - steps into the future",
    "is simply @xmath226 where @xmath227 is a vector containing all ones and @xmath228 is the familiar dot product .",
    "the other moments about zero can be obtained similarly .",
    "@xmath229    more generally @xmath230 where @xmath231 is the conventional @xmath232 function .    to calculate time - averaged properties of the system , for example the one - time - step mean or variance , we set the initial vectors such that @xmath233    and @xmath234 for @xmath235 . the moments about zero can then be used to calculate the moments about the mean .",
    "the mean of the one time - step increments in output averaged over an infinite run will then be @xmath236 and @xmath237 will be @xmath238 these can be calculated for any size rolling window .",
    "the mean of all @xmath15-step increments , @xmath239 or conversely the mean of the future - cast @xmath15 steps into the future from unknown current state is simply @xmath240and @xmath241 will be @xmath242 again with initial vectors calculated from @xmath243 and @xmath234 for @xmath235 . examining this explicitly for our two dice model ,",
    "the initial vectors are : @xmath244 and the ( static ) matrices are : @xmath245    these are all we require to calculate the means and variances for our system s potential output at any time in the future .",
    "to check that all is well , we employ the future - cast to generate the possible future distributions of output up till 10 time - steps , @xmath246 to @xmath247 .",
    "the means and variances of these are compared to the reduced future - cast formalism and also a numerical simulation .",
    "this is a single run of the game over 100000 time - steps .",
    "the means and variances are then measured over rolling windows of between 1 and 10 time - steps in length . the comparison is shown in figure  [ fig : compare ] .     the means and variances of the characteristic distributions @xmath246 to @xmath247 as compared to a numerical evaluation and the reduced future - cast.,scaledwidth=75.0% ]    fortunately they all concur . the reduced future - cast formalism and the moments about either the mean or zero from the distributions generated by the future - cast formalism",
    "are identical .",
    "clearly numerical simulations require progressively longer run times to investigate the properties of distributions further into the future , where the total number of possible paths gets large .",
    "we have presented an analytical formalism for the calculation of the probabilities of outputs from the b - a - r system at a number of time - steps beyond the present state . the construction of the ( static ) future - cast operator matrix allows the evolution of the systems output , and other macroscopic quantities of the system , to be studied without the need to follow the microscopic details of each agent or species .",
    "we have demonstrated the technique to investigate the macroscopic effects of population perturbations but it could also be used to explore the effects of exogeneous noise or even news in the context of financial markets .",
    "we have concentrated on single realisations of the quenched disorder matrix , since this is appropriate to the behaviour and design of a particular realization of a system in practice .",
    "an example could be a financial market model based on the b - a - r system whose derivatives could be analysed quantitatively using expectation values generated with the future - casts .",
    "we have also shown that through the normalised eigenvector solution of the markov chain transition matrix , we can use the future - cast operator matrix to generate a characteristic probability function for a given game over a given time period .",
    "the formalism is general to any time - horizon game and could , for example , be used to analyse systems ( games ) where a level of communication between the agents is permitted , or even linked systems ( i.e. linked games or ` markets ' ) . in the context of linked systems , it will then be interesting to pursue the question as to when adding one ` safe ' complex system to another ` safe ' complex system , results in an ` unsafe ' complex system . or thinking more optimistically , when can we put together two or more ` unsafe ' systems and get a ` safe ' one ?",
    "we have also presented a simplified and altogether more usable interpretation of the future - cast formalism for tracking the evolution of the output variable from a complex system whose internal states can be described as a markov process .",
    "we have illustrated the application of the results for an example case both for the evolution from a known state or when the present state is unknown , to give characteristic information about the output series generated by such a system .",
    "the formalism is generalizable to markov chains whose state transitions are not limited to just two possibilities and also to systems whose mapping from state transitions to output - space are governed by continuous probability distributions .",
    "future work will focus on the ` reverse problem ' of the broad - brush design of multi - agent systems which behave in some particular desired way  or alternatively , ones which will avoid some particular undesirable behaviour .",
    "the effects of any perturbation to the system s heterogeneity could then be pre - engineered in such a system .",
    "one possible future application would be to attack the global control problem of discrete actuating controllers@xcite .",
    "we will also pursue our goal of tailoring multi - agent model systems to replicate the behaviour of a range of real - world systems , with a particular focus on ( 1 ) biological and human health systems such as cancer tumours and the immune system , and ( 2 ) financial markets .",
    "we originally introduced the finite time - horizon mg , plus its ` grand canonical ' variable-@xmath3 and variable-@xmath249 generalizations , to provide a minimal model for financial markets .",
    "hart , p. jefferies and n.f .",
    "johnson , physica a * 311 * , 275(2002 ) ; m.l .",
    "hart , d. lamper and n.f .",
    "johnson , physica a * 316 * , 649 ( 2002 ) ; d. lamper , s. d. howison , and n. f. johnson , phys .",
    "* 88 * , 017902 ( 2002 ) ; n.f .",
    "johnson , p. jefferies , and p.m. hui,_financial market complexity _",
    "( oxford university press , 2003 ) .",
    "see also d. challet and t. galla , cond - mat/0404264,which uses this same model ."
  ],
  "abstract_text": [
    "<S> we discuss the feasibility of predicting , managing and subsequently manipulating , the future evolution of a complex adaptive system . </S>",
    "<S> our archetypal system mimics a population of adaptive , interacting objects , such as those arising in the domains of human health and biology ( e.g. cells ) , financial markets ( e.g. traders ) , and mechanical systems ( e.g. robots ) . </S>",
    "<S> we show that short - term prediction yields corridors along which the model system will , with high probability , evolve . </S>",
    "<S> we show how the widths and average direction of these corridors varies in time as the system passes through regions , or _ pockets _ , of enhanced predictability and/or risk . </S>",
    "<S> we then show how small amounts of ` population engineering ' can be undertaken in order to steer the system away from any undesired regimes which have been predicted . despite the system s many degrees of freedom and inherent stochasticity , this dynamical , ` soft ' control over future risk requires only minimal knowledge about the underlying composition of the constituent multi - agent population . </S>"
  ]
}