{
  "article_text": [
    "information about the health outcomes in many epidemiological studies is obtained from multiple data sources or over a certain time - period with multiple observations . the multiple data sources provide multiple measures of the same underlying variable , measured on a similar scale . as an example @xmath0",
    "adults are chosen for high - blood pressure study at the age of @xmath6 and are asked about their diet , smoking and drinking habits and their blood pressures are measured .",
    "the same subjects over the course of time are monitored again on the basis of the same variables choice as before .",
    "this illustrates the standard data collecting exercise to measure health risk .",
    "once such a data is available we can begin the risk modelling to ascertain the factors which contribute towards high - blood pressure and those that contribute towards low - blood pressure .",
    "to put it mathematically , given @xmath0 subjects and @xmath1 data sources or time - points the data is collected as a @xmath7 dimensional vector of covariates , @xmath8 where @xmath9 and @xmath10 .",
    "given such a vector the outcome is reported as a variable @xmath4 for the @xmath2 subject and from the @xmath11 data source .",
    "then we can construct a @xmath1 dimensional vector @xmath12 as @xmath3 . in a @xmath1 dimensional space the above vector for a given value of @xmath13 is a point . since @xmath9 the total number of points in the @xmath1 dimensional space equal @xmath0 .",
    "these @xmath0 points follow a certain distribution which is a - priori unknown . in the conventional analysis the outcome variables @xmath5s are treated as independent variables and nothing",
    "is assumed about the joint distribution in the @xmath1 dimensional space .",
    "the assumption about the independence is not correct but as we will see in section [ [ tradition ] ] this does not affect the statistical analysis that we intend to carry out . + we propose a novel analysis tool to carry out health risk modelling by transforming the @xmath1 dimensional a - priori unknown density to that of a gaussian density whilst keeping the shannon entropy constant . to do",
    "so we transform the @xmath0 number of @xmath1 dimensional vectors in a basis set consisting of divergence - free vector fields .",
    "the condition that the basis set can only consist of divergence - free vector fields enforces the entropy conserving condition .",
    "entropy conserving condition can be enforced by having volume preserving maps and our choice of the basis set represents a flow of incompressible fluid @xcite hence is a volume preserving map .    to determine the coefficients of these basis vectors such that the @xmath1 dimensional density is a gaussian , karplus theorem",
    "is used @xcite .",
    "we will demonstrate in section[[vecs ] ] that how this theorem allows for determination of the basis coefficients in such a way that the @xmath1 dimensional density is transformed to a gaussian .",
    "+ the paper is divided as follows , in section[[tradition ] ] the traditional approach to model health risk is reviewed and a novel approach is proposed . in section[[basis ] ] the construction of basis set consisting of high dimensional vector fields is shown . in section[[vecs ] ] the question of determining the coefficients of the basis set is settled .",
    "the algorithm and program structure is discussed in section[[algo ] ] . in section[[test ] ] a test case is computed to see how the transformation works in practice .",
    "finally we conclude our work done so far and make proposals for the future work .",
    "consider a trial to model high - blood pressure with @xmath0 subjects monitored over @xmath1 time - period .",
    "the response obtained from the @xmath2 subject can be written as a @xmath1 dimensional vector as    @xmath14    traditionally a joint distribution for @xmath0 subjects is not specified .",
    "instead a working generalized linear model ( glm ) to describe the marginal distribution of @xmath4 as in liang , zeger ( 1986 ) @xcite is used , @xmath15\\label{marginal}\\ ] ]    if the output @xmath4 is a binary random variable then the parameters for the above exponential family are @xmath16 , \\theta_{ij}=log\\left [ \\frac{\\mu_{ij}}{1-\\mu_{ij } }   \\right ] , b(y_{ij},\\theta_{ij})=0\\ ] ] the probability of a favorable outcome if @xmath4 is a binary random variable can be modelled via a logit function as    @xmath17 ) = \\vec{x}_{ij}\\vec{\\beta},\\label{logit}\\ ] ]    where @xmath18 represents the favourable outcome _",
    "i.e _ low risk of high - blood pressure whereas @xmath19 corresponds to high - risk of high - blood pressure .",
    "+ given eq[[marginal ] ] the log - likelihood function can be written as @xmath20 to determine the regression parameters @xmath21 we differentiate the log - likelihood with respect to @xmath21 , this gives the following equation to estimate @xmath22s    @xmath23    this is the traditional approach to determine the regression parameters that help us evaluate the factors which contribute towards high or low health risks given the data .",
    "equation[[assump ] ] was derived assuming that the outcome @xmath4 is a binary random variable , however similar equation can be derived when the outcome @xmath4 is of any other type .",
    "+ in this approach it is assumed that all the @xmath5s are independent observations . this assumption although not correct , yields the estimates for @xmath21 which are valid but their variances are not .",
    "however using techniques such as empirical variance estimator valid standard errors can be obtained@xcite .",
    "having reviewed the traditional approach we now present our idea .",
    "as remarked earlier the joint distribution of the @xmath0 subjects is not specified in the @xmath1 dimensional space as this is an a - priori unknown .",
    "however if the unknown distribution is transformed to that of a @xmath1 dimensional gaussian then a valid analysis tool can be developed .",
    "we have developed an algorithm and a program which does this transformation in an entropy conserving way _ i.e _ the shannon entropy is preserved during the transformation .",
    "+ to preserve the shannon entropy requires transformation of the high dimensional vectors in a basis set consisting of divergence - free vector fields as that represents a volume preserving map thereby preserving shannon entropy .",
    "such a construction of orthocomplete basis set is available in any dimensions @xcite .",
    "we use this mathematical construct to transform then @xmath0 number of @xmath1 dimensional vectors . to determine the basis coefficients such that the @xmath1 dimensional density is transformed to that of a gaussian karplus theorem discussed in section[[vecs ] ]",
    "is invoked .",
    "once the coefficients are determined the @xmath1 dimensional joint distribution of the subjects is a gaussian having the same shannon entropy as the starting distribution .",
    "this has been implemented in entra .",
    "+ once the joint distribution for the @xmath0 subjects is known log - likelihood function can be written for such a distribution and the regression parameters determined thereby . in the next section",
    "we show the construction of the divergence - free vector fields used in our program entra .",
    "a mathematically rigorous construction of divergence free smooth vector fields in any dimensions was provided in @xcite .",
    "we use it to construct a basis set consisting of @xmath1 dimensional divergence free vector fields . to do",
    "so we define the following @xmath24 matrix valued operator @xmath25 here the first term is a @xmath24 dimensional laplacian operator , @xmath26 being the @xmath24 identity matrix and the second term consists of column and row vectors of the gradient operator in @xmath1 dimensions .",
    "this operator acts on a smooth scalar function which we construct from a @xmath1 dimensional vector @xmath27 as    @xmath28    where the symbol @xmath29 is the euclidean distance between two @xmath1 dimensional vectors .",
    "@xmath30 is chosen to be @xmath31 where @xmath32 is the spacing between the basis vectors .",
    "the vector @xmath33 is chosen as a constant @xmath34 where @xmath35 goes from @xmath36 .",
    "now we define a matrix valued function by applying the operator in eq[[operator ] ] to the scalar field in eq[[scalar ] ] as    @xmath37 e^{- \\arrowvert\\arrowvert \\vec{x}-\\vec{x}_l\\arrowvert\\arrowvert^2/(2\\sigma^2 )   } \\end{aligned}\\ ] ]    it was proven rigorously that the columns of the above matrix consist of divergence free vector fields @xcite . for a given choice of centre we therefore obtain @xmath24 dimensional vector field . from the results in @xcite @xmath38 .",
    "+ for a given centre @xmath33 there are @xmath1 number of @xmath1 dimensional mutually orthogonal basis vectors .",
    "hence for each centre we have a complete basis set .",
    "due to such a construction the basis vectors enforce the divergence free condition strictly .",
    "each vector has a unique coefficient @xmath39 attached to it,@xmath40 .    in the next section",
    "we demonstrate this for a simple @xmath41 case .",
    "to demonstrate how the vector field looks like we take a simple 2d case and define the scalar operator in eq[[scalar ] ] as    @xmath42    the matrix valued function @xmath43 becomes    @xmath44    the vectors @xmath45 and @xmath46 defined from the columns of the above matrix as below are then divergence free ,    @xmath47    @xmath48    any linear combination of these divergence free fields is also divergence free .",
    "we plot these fields in fig.[div ] for @xmath49 and @xmath50 .     and @xmath46 respectively . ,",
    "title=\"fig:\",scaledwidth=52.0% ] ;   and @xmath46 respectively .",
    ", title=\"fig:\",scaledwidth=52.0% ]    from the above plot we can see that for the @xmath41 case we have two mutually orthogonal divergence free basis vectors which constitute the complete basis set in two dimensions .",
    "the result holds in general for any dimensions @xcite .",
    "in the @xmath1 dimensional space of the outcome variable the @xmath0 subjects are represented by @xmath0 points .",
    "these @xmath0 points are arranged according to a certain density @xmath51 .",
    "karplus theorem states that for a given covariance gaussian distribution maximizes entropy .",
    "mathematically this can be written as    @xmath52=s[\\rho_g]-s[\\rho]\\geq 0.\\label{basic}\\ ] ]    here @xmath53 is the gaussian density .",
    "the covariance matrix is defined as @xmath54 here the symbol @xmath55 denotes the ensemble average over the @xmath0 subjects implying that @xmath56 is a @xmath24 dimensional matrix .",
    "@xmath27 denotes a @xmath1 dimensional vector or a point in the configuration space . + the equality sign in eq[[basic ] ] holds only if the underlying density distribution is a gaussian .",
    "now we introduce the transformation @xmath57 that preserves the entropy , i.e ,    @xmath58=s[\\rho].\\ ] ]    with this transformation we want to deform the density @xmath51 towards a gaussian density , this then becomes the following minimization problem @xcite    @xmath59    \\right).\\ ] ]    here @xmath60 is the group of all the smooth entropy preserving transforms .",
    "since the transformation leaves the entropy unchanged and as the entropy of a gaussian density is proportional to the determinant of the covariance matrix , to solve the above minimization problem we have to minimize the determinant of the covariance matrix of the gaussian density .",
    "since by karplus theorem the covariance of @xmath53 is same as that of @xmath51 , we can use the covariance in eq[[covar ] ] and write the above minimization problem as    @xmath61.\\ ] ]    as a consequence of the above corollary if we have a basis set consisting of divergence free vector fields under which @xmath1 dimensional vectors for @xmath0 subjects are transformed , then the basis coefficients can be determined by minimizing the covariance matrix determinant of the transformed vectors with respect to the basis coefficients .    in the next section",
    "we describe the construction of the basis set consisting of divergence free smooth vector fields .",
    "this construction is implemented in the program package entra , that i have developed .",
    "given @xmath0 subjects the outcome variable for each subject is a @xmath1 dimensional vector[[master ] ] .",
    "we compute the covariance matrix eq[[covar ] ] which is a @xmath24 dimensional matrix . the matrix is then diagonalized by an orthogonal transformation @xmath62 .",
    "the covariance matrix @xmath56 can then be written as    @xmath63    with @xmath64 being the eigenvalue matrix and columns of @xmath62 matrix being the eigenvectors of @xmath56 .",
    "we construct a @xmath65 dimensional vector by appending all the @xmath0 number of @xmath1 dimensional vectors and label it as trajectory @xmath66 . to transform the trajectory to principal coordinates where the mean of the trajectory is centered at @xmath67 we project the eigenvectors onto the trajectory to get mean - centered trajectory as    @xmath68    for the trajectory @xmath69 we choose two @xmath1 dimensional vectors @xmath70 and @xmath71 and transform them in the vector field shown before as @xmath72 @xmath73 the coefficients are chosen by minimizing the determinant of matrix @xmath56 with respect to the basis coefficients @xmath74 .",
    "the minimization is performed via conjugate gradients method @xcite .",
    "the process is repeated for all the @xmath0 number of @xmath1 dimensional vectors .",
    "this in the end yields a trajectory @xmath75 which has the least determinant of the covariance matrix and the underlying density has the same shannon entropy as that of our starting system .",
    "+      the classes that build up the core of the program are entra , trajectory and grid",
    ". objects of class trajectory represent real - valued arrays .",
    "the arrays are stored as high dimensional vectors and the dimensionality of the vectors is defined by the grid class .",
    "the grid class also defines the number and spacing of the basis vectors .",
    "the methods provided by trajectory and grid classes allow to initialize the corresponding arrays , to manipulate them , and to store ( load ) them to ( from ) files .",
    "to start using the program few parameters have to be provided these are : + long nsources = j ; + long nsubjects = n ; + double deltx = spacing between basis functions ; + long ngpsx = number of basis functions = l ; + long max iter = maximum iteration to find basis coefficients ; +",
    "the goal of this example is to generate a trajectory having a random underlying density and then to transform it towards a trajectory having gaussian underlying density . to generate a random trajectory we use the utility @xmath76 of eigen to generate random matrix of any dimension .",
    "the parameters chosen for this test are as follows : + long nsources=10 ; + long nsubjects=1000 ; + double deltx = 0.05 ; + long ngpsx=80 ; + long maxiter=500 ;    results of the transformation ( after a single iteration cycle ) are shown in fig.[[results ] ] . in this example",
    "we transform a @xmath77 dimensional vector having @xmath78 configurations .",
    "the data is along these @xmath77 axises which are labelled as @xmath79 .",
    "here @xmath80 , _",
    "i.e _ @xmath81 component of the @xmath1 dimensional vector .",
    "we plot two dimensional subspace of original @xmath77 dimensional space along different axises as labelled in fig.[[results ] ] .    to prove that the transformation is indeed entropy conserving , we computed subspace entropy via histogramming for the 2d subspaces shown in fig.[[results ] ] for the original and the transformed subspaces .",
    "+        the matlab code file along with the output to compute entropy of subspaces is provided here : + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * + matlab file to estimate entropy via histogramming for the plot in fig.[[results]]a + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * + load simulation_examplehist.dat    x1=simulation_examplehist(:,8 ) ;    x2=simulation_examplehist(:,9 ) ;    x3=simulation_examplehist(:,11 ) ;    x4=simulation_examplehist(:,12 ) ;    x11=[x1;x3 ] ; x12=[x2;x4 ] ;    x = [ x11,x12 ] ;    plotmatrix(x ) ;    defaultn=500 ; error(nargchk(1 , 2 , nargin ) ) ; if nargin @xmath82 n = defaultn ; end    x = double(x ) ; xh = hist(x ( : ) , n ) ; xh = xh / sum(xh ( : ) ) ;",
    "i = find(xh ) ;    h = -sum(xh(i ) .",
    "* log2(xh(i ) ) ) ;    initialentropy = h ;    display(initialentropy ) ;    y1=simulation_examplehist(:,2 ) ;    y2=simulation_examplehist(:,3 ) ;    y3=simulation_examplehist(:,5 ) ;    y4=simulation_examplehist(:,6 ) ;    y11=[y1;y3 ] ; y12=[y2;y4 ] ;    y=[y11,y12 ] ;    plotmatrix(y ) ;    error(nargchk(1 , 2 , nargin ) ) ; if nargin @xmath82 n = defaultn ; end    y = double(y ) ; yh = hist(y ( : ) , n ) ; yh = yh / sum(yh ( : ) ) ; i = find(yh ) ;    htwo = -sum(yh(i ) .",
    "* log2(yh(i ) ) ) ;    transformedentropy = htwo ; display(transformedentropy ) ;    entropydifference = initialentropy - transformedentropy ;    display(entropydifference ) ;    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * + result of the above file + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * + @xmath83 run simpleentropy initialentropy =    8.7636    transformedentropy =    7.5625    entropydifference =    @xmath84 + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    result for the plot fig.[[results]]b + @xmath83 run simpleentropy    initialentropy =    8.7770    transformedentropy =    7.6632    entropydifference =    @xmath85 + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    result for the plot fig.[[results]]c + @xmath83 run simpleentropy    initialentropy =    8.7754    transformedentropy =    7.6483    entropydifference =    @xmath86    two dimensional histogram plots for initial and transformed configurations are shown in fig.[[results ] ] .",
    "now we can also compute entropy in higher dimension via histogramming . as the data is 30 dimensional",
    "we now look at the data along first three axises @xmath87 as seen in fig.[[threedorg ] ] , in this plot we plot the data along one axis versus another as labelled along with histogram along each axis .",
    "we also plot the same plot for the transformed data as seen in fig.[[threedtrans ] ] .",
    "we compute the entropy of the three dimensional data using a matlab code similar to above and its results are shown here :    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *    result for computation of entropy for 3d data    @xmath83 run highdimentropy    initialentropy =    8.8220    transformedentropy =    7.5756    entropydifference =    @xmath88    .",
    "more details in the text , scaledwidth=100.0% ]    .",
    "more details in the text , scaledwidth=100.0% ]    these results imply that in just a single iteration cycle the unknown configuration space density is transformed to a gaussian density with entropy being conserved approximately . clearly @xmath78 points are not sufficient to get an accurate entropy estimate and more statistics is required .",
    "this will form part of the work to be done .",
    "entra package has been presented . the aim of this package is to do data transformation on high dimensional data sets as found in epidemiology . with this transformation",
    "the underlying high dimensional density function is transformed that to a high dimensional gaussian and due to the nice properties associated with a gaussian distribution the further data analysis can be accomplished easier than before .",
    "\\1 ) the appropriate choice of the basis set vectors .",
    "the number of basis vectors depend on the data and need to be appropriately estimated beforehand .",
    "how exactly that can be achieved needs to be determined .",
    "+ 2 ) building an example with enough statistics to be able to prove that the entropy conservation is maintained to a high degree of accuracy .",
    "+ 3 ) furthermore developing full file support for epidemiologists to enable them to load their data and get the transformed data .",
    "+ 4 ) also , developing complete regression analysis to estimate conditional probabilities of the likes in equation[[logit ] ] in the ecosystem of entra .",
    "i. andricioaei , and m. karplus , on the calculation of entropy from covariance matrices of the atomic fluctuations , j. chem .",
    "phys . , 115:6289 - 6292 , 2001 . m. karplus and j.n .",
    "kushick , method for estimating the configurational entropy of macromolecules .",
    "macromolecules , 14(2):325332 , 1981 .",
    "schlitter , j. ( 1993 ) .",
    "estimation of absolute entropies of macromolecules using the covariance matrix",
    ". chemical physics letters , * 215 * , 617621 .",
    "liang k - y , zeger sl .",
    "longitudinal data analysis using generalized linear models .",
    "biometrika 1986 ; * 73*:13  22 ."
  ],
  "abstract_text": [
    "<S> the traditional approach of health risk modelling with multiple data sources proceeds via regression - based methods assuming a marginal distribution for the outcome variable . </S>",
    "<S> the data is collected for @xmath0 subjects over a @xmath1 time - period or from @xmath1 data sources . </S>",
    "<S> the response obtained from @xmath2 subject is @xmath3 . for @xmath0 subjects </S>",
    "<S> we obtain a @xmath1 dimensional joint distribution for the subjects . in this work </S>",
    "<S> we propose a novel approach of transforming any @xmath1 dimensional joint distribution to that of a @xmath1 dimensional gaussian keeping the shannon entropy constant . </S>",
    "<S> this is in stark contrast to the traditional approaches of assuming a marginal distribution for each @xmath4 by treating the @xmath5s as independent observations . </S>",
    "<S> the said transformation is implemented in our computer package called entra . </S>"
  ]
}