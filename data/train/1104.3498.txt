{
  "article_text": [
    "shannon s entropy quantifies information @xcite .",
    "it measures how much uncertainty an observer has about an event being produced by a random system .",
    "another important concept in the theory of information is the mutual information @xcite .",
    "it measures how much uncertainty an observer has about an event in a random system * x * after observing an event in a random system * y * ( or vice - versa ) .",
    "mutual information is an important quantity because it quantifies not only linear and non - linear interdependencies between two systems or data sets , but also is a measure of how much information two systems exchange or two data sets share . due to these characteristics",
    ", it became a fundamental quantity to understand the development and function of the brain @xcite , to characterise @xcite and model complex systems @xcite or chaotic systems , and to quantify the information capacity of a communication system @xcite . when constructing a model of a complex system ,",
    "the first step is to understand which are the most relevant variables to describe its behaviour .",
    "mutual information provides a way to identify those variables @xcite .",
    "however , the calculation of mutual information in dynamical networks or data sets faces three main difficulties@xcite .",
    "mutual information is rigorously defined for random memoryless processes , only .",
    "in addition , its calculation involves probabilities of significant events and a suitable space where probability is calculated .",
    "the events need to be significant in the sense that they contain as much information about the system as possible .",
    "but , defining significant events , for example the fact that a variable has a value within some particular interval , is a difficult task because the interval that provides significant events is not always known .",
    "finally , data sets have finite size .",
    "this prevents one from calculating probabilities correctly . as a consequence , mutual information",
    "can often be calculated with a bias , only @xcite .    in this work ,",
    "we show how to calculate the amount of information exchanged per unit of time [ eq .",
    "( [ mir_introduction ] ) ] , the so called mutual information rate ( mir ) , between two arbitrary nodes ( or group of nodes ) in a dynamical network or between two data sets .",
    "each node representing a d - dimensional dynamical system with @xmath0 state variables .",
    "the trajectory of the network considering all the nodes in the full phase space is called `` attractor '' and represented by @xmath1 .",
    "then , we propose an alternative method , similar to the ones proposed in refs .",
    "@xcite , to calculate significant upper and lower bounds for the mir in dynamical networks or between two data sets , in terms of lyapunov exponents , expansion rates , and capacity dimension .",
    "these quantities can be calculated without the use of probabilistic measures . as possible applications of our bounds calculation",
    ", we describe the relationship between synchronisation and the exchange of information in small experimental networks of coupled double - scroll circuits .    in previous works of refs .",
    "@xcite , we have proposed an upper bound for the mir in terms of the positive conditional lyapunov exponents of the synchronisation manifold . as a consequence , this upper bound could only be calculated in special complex networks that allow the existence of complete synchronisation . in the present work",
    ", the proposed upper bound can be calculated to any system ( complex networks and data sets ) that admits the calculation of lyapunov exponents .",
    "we assume that an observer can measure only one scalar time series for each one of two chosen nodes .",
    "these two time series are denoted by @xmath2 and @xmath3 and they form a bidimensional set @xmath4 , a projection of the `` attractor '' into a bidimensional space denoted by @xmath5 . to calculate the mir in higher - dimensional projections @xmath5 , see supplementary information .",
    "assume that the space @xmath5 is coarse - grained in a square grid of @xmath6 boxes with equal sides @xmath7 , so @xmath8 .",
    "mutual information is defined in the following way @xcite . given two random variables , * x * and * y * , each one produces events @xmath9 and @xmath10 with probabilities @xmath11 and @xmath12 , respectively , the joint probability between these events is represented by @xmath13 .",
    "then , mutual information is defined as @xmath14 @xmath15 = @xmath16}$ ] , @xmath17 = @xmath18}$ ] , and @xmath19}$ ] . for simplification in our notation for the probabilities ,",
    "we drop the subindexes @xmath20 , @xmath21 , and @xmath22 , by making @xmath23 , @xmath24 , and @xmath25 . when using eq .",
    "( [ is ] ) to calculate the mutual information between the dynamical variables @xmath2 and @xmath3 , the probabilities appearing in eq .",
    "( [ is ] ) are defined such that @xmath26 is the probability of finding points in a column @xmath9 of the grid , @xmath27 of finding points in the row @xmath10 of the grid , and @xmath28 the probability of finding points where the column @xmath9 meets the line @xmath10 of the grid .",
    "the mir was firstly introduced by shannon @xcite as a `` rate of actual transmission '' @xcite and later more rigorously redefined in refs .",
    "it represents the mutual information exchanged between two dynamical variables ( correlated ) per unit of time . to simplify the calculation of the mir ,",
    "the two continuous dynamical variables are transformed into two discrete symbolic sequences @xmath2 and @xmath3 .",
    "then , the mir is defined by @xmath29 where @xmath30 represents the usual mutual information between the two sequences @xmath2 and @xmath3 , calculated by considering words of length @xmath31 .",
    "the mir is a fundamental quantity in science .",
    "its maximal value gives the information capacity between any two sources of information ( no need for stationarity , statistical stability , memoryless ) @xcite .",
    "therefore , alternative approaches for its calculation or for the calculation of bounds of it are of vital relevance . due to the limit to infinity in eq .",
    "( [ original_mir ] ) and because it is defined from probabilities , the mir is not easy to be calculated especially if one wants to calculate it from ( chaotic ) trajectories of a large complex network or data sets . the difficulties faced to estimate the mir from dynamical systems and networks are similar to the ones faced in the calculation of the kolmogorov - sinai entropy , @xmath32 @xcite , ( shannon s entropy per unit of time ) .",
    "because of these difficulties , the upper bound for @xmath32 proposed by ruelle @xcite in terms of the lyapunov exponents and valid for smooth dynamical systems ( @xmath33 , where @xmath34 represent all the @xmath9 positive lyapunov exponents ) or the pesin s equality @xcite ( @xmath35 ) proved in ref .",
    "@xcite to be valid for the large class of systems that possess a srb measure , became so important in the theory of dynamical systems .",
    "our upper bound [ eq .",
    "( [ i_c ] ) ] is a result equivalent to the work of ruelle .",
    "one of the main results of this work ( whose derivation can be seen in sec .",
    "[ methods_mir ] ) is to show that , in dynamical networks or data sets with fast decay of correlation , @xmath36 in eq .",
    "( [ is ] ) represents the amount of mutual information between @xmath2 and @xmath3 produced within a special time interval @xmath37 , where @xmath37 represents the time for the dynamical network ( or data sets ) to lose its memory from the initial state or the correlation to decay to zero .",
    "correlation in this work is not the usual linear correlation , but a non - linear correlation defined in terms of the evolution of spatial probabilities , the quantity @xmath38 in sec . [ mixing ] .",
    "therefore , the mutual information rate ( mir ) , between the dynamical variables @xmath2 and @xmath3 ( or two data sets ) can be estimated by @xmath39 in systems that present sensitivity to initial conditions , e.g. chaotic systems , predictions are only possible for times smaller than this time @xmath37 .",
    "this time has other meanings .",
    "it is the expected time necessary for a set of points belonging to an @xmath7-square box in @xmath5 to spread over @xmath40 and it is of the order of the shortest poincar return time for a point to leave a box and return to it @xcite .",
    "it can be estimated by @xmath41}. \\label{t}\\ ] ] where @xmath42 is the largest positive lyapunov exponent measured in @xmath40 .",
    "chaotic systems present the mixing property ( see sec . [ mixing ] ) , and as a consequence the correlation @xmath43 always decays to zero , surely after an infinitely long time .",
    "the correlation of chaotic systems can also decay to zero for sufficiently large but finite @xmath44 ( see supplementary information ) .",
    "@xmath37 can be interpreted to be the minimum time required for a system to satisfy the conditions to be considered mixing .",
    "some examples of physical systems that are proved to be mixing and have exponentially fast decay of correlation are nonequilibrium steady - state @xcite , lorenz gases ( models of diffusive transport of light particles in a network of heavier particles ) @xcite , and billiards @xcite .",
    "an example of a `` real world '' physical complex system that presents exponentially fast decay of correlation is plasma turbulence @xcite .",
    "we do not expect that data coming from a `` real world '' complex system is rigorously mixing and has an exponentially fast decay of correlation .",
    "but , we expect that the data has a sufficiently fast decay of correlation ( e.g. stretched exponential decay or polynomially fast decays ) , implying that the system has sufficiently high sensitivity to initial conditions and as a consequence @xmath45 , for a reasonably small and finite time @xmath44 .",
    "the other two main results of our work are presented in eqs .",
    "( [ i_c_intro ] ) and ( [ icl_intro ] ) , whose derivations are presented in sec .",
    "[ methods_bounds ] .",
    "the upper bound for the mir is given by @xmath46 where @xmath42 and @xmath47 ( positive defined ) represent the largest and the second largest lyapunov exponent measured in @xmath40 , if both exponents are positive .",
    "if the @xmath9-largest exponent is negative , then we set @xmath48 .",
    "if the set @xmath40 represents a periodic orbit , @xmath49 , and therefore there is no information being exchanged .",
    "the quantity @xmath50 is defined as @xmath51 where @xmath52 is the number of boxes that would be covered by fictitious points at time @xmath37 . at time @xmath53 , these fictitious points are confined in an @xmath7-square box .",
    "they expand not only exponentially fast in both directions according to the two positive lyapunov exponents , but expand forming a compact set , a set with no `` holes '' . at @xmath44 , they spread over @xmath40 .",
    "the lower bound for the mir is given by @xmath54 where @xmath55 represents the capacity dimension of the set @xmath40 @xmath56 ,    \\label{tildad}\\ ] ] where @xmath57 represents the number of boxes in @xmath5 that are occupied by points of @xmath40 .",
    "@xmath50 is defined in a way similar to the capacity dimension , thought it is not the capacity dimension .",
    "in fact , @xmath58 , because @xmath55 measures the change in the number of occupied boxes in @xmath5 as the space resolution varies , whereas @xmath50 measures the relative number of boxes with a certain fixed resolution @xmath7 that would be occupied by the fictitious points ( in @xmath5 ) after being iterated for a time @xmath37 . as a consequence , the empty space in @xmath5 that is not occupied by @xmath40 does not contribute to the calculation of @xmath55 , whereas it contributes to the calculation of the quantity @xmath50 .",
    "in addition , @xmath59 ( for any @xmath7 ) , because while the fictitious points form a compact set expanding with the same ratio as the one for which the real points expand ( ratio provided by the lyapunov exponents ) , the real set of points @xmath40 might not occupy many boxes .",
    "denote by @xmath60 a mixing transformation that represents how a point @xmath61 is mapped after a time @xmath37 into @xmath40 , and let @xmath62 to represent the probability of finding a point of @xmath40 in @xmath63 ( natural invariant density ) .",
    "let @xmath64 represent a region in @xmath5 .",
    "then , @xmath65 , for @xmath66 represents the probability measure of the region @xmath64 .",
    "given two square boxes @xmath67 and @xmath68 , if @xmath69 is a mixing transformation , then for a sufficiently large @xmath37 , we have that the correlation @xmath70 - \\mu[i^{\\prime}_1]\\mu[i^{\\prime}_2]$ ] , decays to zero , the probability of having a point in @xmath64 that is mapped to @xmath71 is equal to the probability of being in @xmath64 times the probability of being in @xmath71 .",
    "that is typically what happens in random processes .    if the measure @xmath72 is invariant , then @xmath73=\\mu(\\sigma_{\\omega})$ ] . mixing and ergodic systems produce measures that are invariant .",
    "we consider that the dynamical networks or data sets to be analysed present either the mixing property or have fast decay of correlations , and their probability measure is time invariant . if a system that is mixing for a time interval @xmath37 is observed ( sampled ) once every time interval @xmath37 , then the probabilities generated by these snapshot observations behave as if they were independent , and the system behaves as if it were a random process .",
    "this is so because if a system is mixing for a time interval @xmath37 , then the correlation @xmath38 decays to zero for this time interval . for systems that have some decay of correlation",
    ", surely the correlation decays to zero after an infinite time interval .",
    "but , this time interval can also be finite , as shown in supplementary information .",
    "consider now that we have experimental points and they are sampled once every time interval @xmath37 .",
    "the probability @xmath74 of the sampled trajectory to follow a given itinerary , for example to fall in the box with coordinates @xmath75 and then be iterated to the box @xmath76 depends exclusively on the probabilities of being at the box @xmath75 , represented by @xmath77 , and being at the box @xmath76 , represented by @xmath78 .",
    "therefore , for the sampled trajectory , @xmath79 .",
    "analogously , the probability @xmath80 of the sampled trajectory to fall in the column ( or line ) @xmath9 of the grid and then be iterated to the column ( or line ) @xmath10 is given by @xmath81 .",
    "the mir of the experimental non - sampled trajectory points can be calculated from the mutual information @xmath82 of the sampled trajectory points that follow itineraries of length @xmath31 : @xmath83    due to the absence of correlations of the sampled trajectory points , the mutual information for these points following itineraries of length @xmath31 can be written as @xmath84 , \\label{original_mir_sampled1}\\ ] ] where @xmath85 = @xmath86}$ ] , @xmath87 = @xmath88}$ ] , and @xmath89}$ ] , and @xmath90 , @xmath91 , and @xmath77 represent the probability of the sampled trajectory points to fall in the line @xmath9 of the grid , in the column @xmath10 of the grid , and in the box @xmath75 of the grid , respectively .",
    "due to the time invariance of the set @xmath40 assumed to exist , the probability measure of the non - sampled trajectory is equal to the probability measure of the sampled trajectory . if a system that has a time invariant measure is observed ( sampled ) once every time interval @xmath37 , the observed set has the same natural invariant density and probability measure of the original set . as a consequence ,",
    "if @xmath40 has a time invariant measure , the probabilities @xmath26 , @xmath27 , and @xmath28 ( used to calculate @xmath36 ) are equal to @xmath90 , @xmath91 , and @xmath77 .    consequently , @xmath92 , @xmath93 , and @xmath94 , and therefore @xmath95 . substituting into eq .",
    "( [ original_mir_sampled ] ) , we finally arrive to @xmath96 where @xmath36 between two nodes is calculated from eq .",
    "( [ is ] ) .",
    "therefore , in order to calculate the mir , we need to estimate the time @xmath37 for which the correlation of the system approaches zero and the probabilities @xmath26 , @xmath27 , @xmath28 of the experimental non - sampled experimental points to fall in the line @xmath9 of the grid , in the column @xmath10 of the grid , and in the box @xmath75 of the grid , respectively .",
    "consider that our attractor @xmath1 is generated by a 2d expanding system that possess 2 positive lyapunov exponents @xmath42 and @xmath47 , with @xmath99 .",
    "imagine a box whose sides are oriented along the orthogonal basis used to calculate the lyapunov exponents .",
    "then , points inside the box spread out after a time interval @xmath101 to @xmath102 along the direction from which @xmath42 is calculated . at @xmath44 , @xmath103 , which provides @xmath37 in eq .",
    "( [ t ] ) , since @xmath104 .",
    "these points spread after a time interval @xmath101 to @xmath105 along the direction from which @xmath47 is calculated .",
    "after an interval of time @xmath44 , these points spread out over the set @xmath40 .",
    "we require that for @xmath106 , the distance between these points only increases : the system is expanding .",
    "imagine that at @xmath44 , fictitious points initially in a square box occupy an area of @xmath107 .",
    "then , the number of boxes of sides @xmath7 that contain fictitious points can be calculated by @xmath108 . from eq .",
    "( [ t ] ) , @xmath109 , since @xmath8 .",
    "we denote with a lower - case format , the probabilities @xmath110 , @xmath111 , and @xmath112 with which fictitious points occupy the grid in @xmath5 .",
    "if these fictitious points spread uniformly forming a compact set whose probabilities of finding points in each fictitious box is equal , then @xmath113 ( @xmath114 ) , @xmath115 , and @xmath116 .",
    "let us denote the shannon s entropy of the probabilities @xmath112 , @xmath110 and @xmath111 as @xmath117 , @xmath118 , and @xmath119 .",
    "the mutual information of the fictitious trajectories after evolving a time interval @xmath37 can be calculated by @xmath120 . since , @xmath121 and @xmath116 , then @xmath122 . at @xmath44 , we have that @xmath109 and @xmath123 , leading us to @xmath124 .",
    "therefore , defining , @xmath125 , we arrive at @xmath126 .",
    "we defining @xmath50 as @xmath127 where @xmath52 being the number of boxes that would be covered by fictitious points at time @xmath37 . at time",
    "@xmath53 , these fictitious points are confined in an @xmath7-square box .",
    "they expand not only exponentially fast in both directions according to the two positive lyapunov exponents , but expand forming a compact set , a set with no `` holes '' . at @xmath44 , they spread over @xmath40 .    using @xmath128 and @xmath129 in eq .",
    "( [ d ] ) , we arrive at @xmath130 , and therefore , we can write that @xmath131    to calculate the maximal possible mir , of a random independent process , we assume that the expansion of points is uniform only along the columns and lines of the grid defined in the space @xmath5 , i.e. , @xmath132 , ( which maximises @xmath133 and @xmath134 ) , and we allow @xmath28 to be not uniform ( minimising @xmath135 ) for all @xmath9 and @xmath10 , then @xmath136}. \\label{is_lower}\\ ] ] since @xmath137 , dividing @xmath138 by @xmath139 , taking the limit of @xmath140 , and reminding that the information dimension of the set @xmath40 in the space @xmath5 is defined as @xmath141=@xmath142}}{\\log{(\\epsilon)}}$ ] , we obtain that the mir is given by @xmath143    since @xmath144 ( for any value of @xmath7 ) , then @xmath145 , which means that a lower bound for the maximal mir [ provided by eq .",
    "( [ almost_true1 ] ) ] is given by @xmath146    but @xmath58 ( for any value of @xmath7 ) , and therefore @xmath97 is an upper bound for @xmath98 .    to show why @xmath97 is an upper bound for the maximal possible mir , assume that the real points @xmath40 occupy the space @xmath5 uniformly .",
    "if @xmath147 , there are many boxes being occupied .",
    "it is to be expected that the probability of finding a point in a line or column of the grid is @xmath148 , and @xmath149 .",
    "in such a case , @xmath150 , which implies that @xmath151 . if @xmath152 , there are only few boxes being sparsely occupied .",
    "the probability of finding a point in a line or column of the grid is @xmath153 , and @xmath149 .",
    "there are @xmath57 lines and columns being occupied by points in the grid .",
    "in such a case , @xmath154 . comparing with @xmath122 , and since @xmath155 and @xmath59 , then we conclude that @xmath156 , which implies that @xmath151 .",
    "notice that if @xmath157 and @xmath158 , then @xmath159 .      in order to extend our approach for the treatment of data sets coming from networks whose equations of motion",
    "are unknown , or for higher - dimensional networks and complex systems which might be neither rigorously chaotic nor fully deterministic , or for experimental data that contains noise and few sampling points , we write our bounds in terms of expansion rates defined in this work by @xmath160 } ,    \\label{define_exp_rates}\\ ] ] where we consider @xmath161 .",
    "@xmath162 measures the largest growth rate of nearby points . in practice",
    ", it is calculated by @xmath163 , with @xmath164 representing the largest distance between pair of points in an @xmath7-square box @xmath9 and @xmath165 representing the largest distance between pair of the points that were initially in the @xmath7-square box but have spread out for an interval of time @xmath101 .",
    "@xmath166 measures how an area enclosing points grows . in practice",
    ", it is calculated by @xmath167 , with @xmath168 representing the area occupied by points in an @xmath7-square box , and @xmath169 the area occupied by these points after spreading out for a time interval @xmath101 .",
    "there are @xmath57 boxes occupied by points which are taken into consideration in the calculation of @xmath170 . an order-@xmath171 expansion rate , @xmath172 , measures on average how a hypercube of dimension @xmath171 exponentially grows after an interval of time @xmath101 .",
    "so , @xmath173 measures the largest growth rate of nearby points , a quantity closely related to the largest finite - time lyapunov exponent @xcite . and",
    "@xmath174 measures how an area enclosing points grows , a quantity closely related to the sum of the two largest positive lyapunov exponents . in terms of expansion rates , eqs .",
    "( [ t ] ) and ( [ i_c ] ) read @xmath175}$ ] and @xmath176 , respectively , and eqs .",
    "( [ d ] ) and ( [ icl ] ) read @xmath177 and @xmath178 , respectively .    from the way we have defined expansion rates",
    ", we expect that @xmath179 . because of the finite time interval and the finite size of the regions of points considered , regions of points that present large derivatives , contributing largely to the lyapunov exponents , contribute less to the expansion rates . if a system has constant derivative ( hyperbolic ) and has constant natural measure , then @xmath180 .",
    "there are many reasons for using expansion rates in the way we have defined them in order to calculate bounds for the mir .",
    "firstly , because they can be easily experimentally estimated whereas lyapunov exponents demand huge computational efforts .",
    "secondly , because of the macroscopic nature of the expansion rates , they might be more appropriate to treat data coming from complex systems that contains large amounts of noise , data that have points that are not ( arbitrarily ) close as formally required for a proper calculation of the lyapunov exponents .",
    "thirdly , expansion rates can be well defined for data sets containing very few data points : the fewer points a data set contains , the larger the regions of size @xmath7 need to be and the shorter the time @xmath37 is .",
    "finally , expansion rates are defined in a similar way to finite - time lyapunov exponents and thus some algorithms used to calculate lyapunov exponents can be used to calculate our defined expansion rates .",
    "to illustrate the use of our bounds , we consider the following two bidirectionally coupled maps@xmath181 where @xmath182 $ ] . if @xmath183 , the map is piecewise - linear and quadratic , otherwise .",
    "we are interested in measuring the exchange of information between @xmath184 and @xmath185 .",
    "the space @xmath5 is a square of sides 1 .",
    "the lyapunov exponents measured in the space @xmath5 are the lyapunov exponents of the set @xmath40 that is the chaotic attractor generated by eqs .",
    "( [ network_maps ] ) .",
    "the quantities @xmath186 , @xmath97 , and @xmath98 are shown in fig .",
    "[ figure4 ] as we vary @xmath187 for @xmath183 ( a ) and @xmath188 ( b ) .",
    "we calculate @xmath36 using in eq .",
    "( [ is ] ) the probabilities @xmath28 in which points from a trajectory composed of @xmath189 samples fall in boxes of sides @xmath7=1/500 and the probabilities @xmath26 and @xmath27 that the points visit the intervals @xmath190 of the variable @xmath191 or @xmath192 of the variable @xmath193 , respectively , for @xmath194 . when computing @xmath186 , the quantity @xmath37 was estimated by eq .",
    "( [ t ] ) .",
    "indeed for most values of @xmath187 , @xmath195 and @xmath196 .    for @xmath197",
    "there is no coupling , and therefore the two maps are independent from each other .",
    "there is no information being exchanged .",
    "in fact , @xmath49 and @xmath198 in both figures , since @xmath199 , meaning that the attractor @xmath40 fully occupies the space @xmath5 .",
    "this is a remarkable property of our bounds : to identify that there is no information being exchanged when the two maps are independent .",
    "complete synchronisation is achieved and @xmath97 is maximal , for @xmath200 ( a ) and for @xmath201 ( b ) . a consequence of the fact that @xmath202 , and therefore , @xmath203 .",
    "the reason is because for this situation this coupled system is simply the shift map , a map with constant natural measure ; therefore @xmath204 and @xmath28 are constant for all @xmath9 and @xmath10 . as usually happens when one estimates the mutual information by partitioning the phase space with a grid having a finite resolution and data sets possessing a finite number of points , @xmath36 is typically larger than zero , even when there is no information being exchanged ( @xmath197 ) .",
    "even when there is complete synchronisation , we find non - zero off - diagonal terms in the matrix for the joint probabilities causing @xmath36 to be smaller than it should be .",
    "due to numerical errors , @xmath205 , and points that should be occupying boxes with two corners exactly along a diagonal line in the subspace @xmath5 end up occupying boxes located off - diagonal and that have at least three corners off - diagonal .",
    "the estimation of the lower bound @xmath98 suffers from the same problems .",
    "our upper bound @xmath97 is calculated assuming that there is a fictitious dynamics expanding points ( and producing probabilities ) not only exponentially fast but also uniformly .",
    "the `` experimental '' numerical points from eqs .",
    "( [ network_maps ] ) expand exponentially fast , but not uniformly .",
    "most of the time the trajectory remains in 4 points : ( 0,0 ) , ( 1,1 ) , ( 1,0 ) , ( 0,1 ) . that is the main reason of why @xmath97 is much larger than the estimated real value of the @xmath206 , for some coupling strengths . if a two nodes in a dynamical network , such as two neurons in a brain , behave in the same way the fictitious dynamics does , these nodes would be able to exchange the largest possible amount of information .",
    "we would like to point out that one of the main advantages of calculating upper bounds for the mir ( @xmath186 ) using eq .",
    "( [ i_c ] ) instead of actually calculating @xmath186 is that we can reproduce the curves for @xmath97 using much less number of points ( 1000 points ) than the ones ( @xmath189 ) used to calculate the curve for @xmath186 .",
    "if @xmath183 , @xmath207 can be calculated since @xmath208 and @xmath209 .",
    "we illustrate our approach for the treatment of data sets using a network formed by an inductorless version of the double - scroll circuit @xcite .",
    "we consider four networks of bidirectionally diffusively coupled circuits .",
    "topology i represents two bidirectionally coupled circuits , topology ii , three circuits coupled in an open - ended array , topology iii , four circuits coupled in an open - ended array , and topology iv , coupled in an closed array .",
    "we choose two circuits in the different networks ( one connection apart ) and collect from each circuit a time - series of 79980 points , with a sampling rate of @xmath210 samples / s .",
    "the measured variable is the voltage across one of the circuit capacitors , which is normalised in order to make the space @xmath5 to be a square of sides 1 .",
    "such normalisation does not alter the quantities that we calculate .",
    "the following results provide the exchange of information between these two chosen circuits .",
    "the values of @xmath7 and @xmath101 used to course - grain the space @xmath5 and to calculate @xmath174 in eq .",
    "( [ define_exp_rates ] ) are the ones that minimises @xmath211 and at the same time satisfy @xmath212 , where @xmath213 represents the number of fictitious boxes covering the set @xmath40 in a compact fashion , when @xmath44 .",
    "this optimisation excludes some non - significant points that make the expansion rate of fictitious points to be much larger than it should be . in other words , we require that @xmath174 describes well the way most of the points spread .",
    "we consider that @xmath101 used to calculate @xmath214 in eq .",
    "( [ define_exp_rates ] ) is the time for points initially in an @xmath7-side box to spread to 0.8@xmath215 .",
    "that guarantee that nearby points in @xmath40 are expanding in both directions within the time interval @xmath216 $ ] .",
    "using @xmath217 produces already similar results . if @xmath218 , the set @xmath40 might not be only expanding .",
    "@xmath37 might be overestimated .",
    "results for experimental networks of double - scroll circuits . on the left - side upper corner pictograms represent how the circuits ( filled circles ) are bidirectionally coupled . @xmath219 as ( green online ) filled circles , @xmath97 as the ( red online ) thick line , and @xmath98 as the ( brown online ) squares , for a varying coupling resistance @xmath220 .",
    "the unit of these quantities shown in these figures is ( kbits / s ) .",
    "( a ) topology i , ( b ) topology ii , ( c ) topology iii , and ( d ) topology iv . in all figures , @xmath55 increases smoothly from 1.25 to 1.95 as @xmath220 varies from 0.1k@xmath5 to 5k@xmath5 .",
    "the line on the top of the figure represents the interval of resistance values responsible to induce almost synchronisation ( as ) and phase synchronisation ( ps).,width=264,height=264 ]    @xmath36 has been estimated by the method in ref .",
    "since we assume that the space @xmath5 where mutual information is being measured is 2d , we will compare our results by considering in the method of ref .",
    "@xcite a 2d space formed by the two collected scalar signals . in the method of ref .",
    "@xcite the phase space is partitioned in regions that contain 30 points of the continuous trajectory . since that these regions do not have equal areas ( as it is done to calculate @xmath97 and @xmath98 ) , in order to estimate @xmath37 we need to imagine a box of sides @xmath221 , such that its area @xmath222 contains in average 30 points . the area occupied by the set @xmath40 is approximately given by @xmath223 , where @xmath57 is the number of occupied boxes .",
    "assuming that the 79980 experimental data points occupy the space @xmath5 uniformly , then on average 30 points would occupy an area of @xmath224 .",
    "the square root of this area is the side of the imaginary box that would occupy 30 points .",
    "so , @xmath225 .",
    "then , in the following , the `` exact '' value of the mir will be considered to be given by @xmath219 , where @xmath226 is estimated by @xmath227 .",
    "the three main characteristics of the curves for the quantities @xmath219 , @xmath97 , and @xmath98 ( appearing in fig . [ figure4_letter00 ] ) with respect to the coupling strength are that ( i ) as the coupling resistance becomes smaller , the coupling strength connecting the circuits becomes larger , and the level of synchronisation increases followed by an increase in @xmath219 , @xmath97 , and @xmath98 , ( ii ) all curves are close , ( iii ) and as expected , for most of the resistance values , @xmath228 and @xmath229 .",
    "the two main synchronous phenomena appearing in these networks are almost synchronisation ( as ) @xcite , when the circuits are almost completely synchronous , and phase synchronisation ( ps ) @xcite . for the circuits considered in fig .",
    "[ figure4_letter00 ] , as appears for the interval @xmath230 $ ] and ps appears for the interval @xmath231 $ ] . within this region of resistance values the exchange of information between the circuits becomes large .",
    "ps was detected by using the technique from refs .",
    "@xcite .      to analytically demonstrate that the quantities @xmath97 and @xmath186 can be well calculated in stochastic systems , we consider the following stochastic dynamical toy model illustrated in fig . [ toy_model ] . in",
    "it points within a small box of sides @xmath7 ( represented by the filled square in fig .",
    "[ toy_model](a ) ) located in the centre of the subspace @xmath5 are mapped after one iteration of the dynamics to 12 other neighbouring boxes .",
    "some points remain in the initial box .",
    "the points that leave the initial box go to 4 boxes along the diagonal line and 8 boxes off - diagonal along the transverse direction .",
    "boxes along the diagonal are represented by the filled squares in fig .",
    "[ toy_model](b ) and off - diagonal boxes by filled circles . at the second iteration ,",
    "the points occupy other neighbouring boxes , as illustrated in fig .",
    "[ toy_model](c ) , and at the time @xmath232 the points do not spread any longer , but are somehow reinjected inside the region of the attractor .",
    "we consider that this system is completely stochastic , in the sense that no one can precisely determine the location of where an initial condition will be mapped .",
    "the only information is that points inside a smaller region are mapped to a larger region .    at the iteration @xmath31",
    ", there will be @xmath233 boxes occupied along the diagonal ( filled squares in fig .",
    "[ toy_model ] ) and @xmath234 ( filled circles in fig .",
    "[ toy_model ] ) boxes occupied off - diagonal ( along the transverse direction ) , where @xmath235 for @xmath236=0 , and @xmath237 for @xmath238 and @xmath239 .",
    "@xmath240 is a small number of iterations representing the time difference between the time @xmath37 for the points in the diagonal to reach the boundary of the space @xmath5 and the time for the points in the off - diagonal to reach this boundary .",
    "the border effect can be ignored when the expansion along the diagonal direction is much faster than along the transverse direction .    at the iteration @xmath31",
    ", there will be @xmath241 boxes occupied by points . in the following calculations we consider that @xmath242 .",
    "we assume that the subspace @xmath5 is a square whose sides have length 1 , and that @xmath100 , so @xmath104 . for @xmath243",
    ", the attractor does not grow any longer along the off - diagonal direction .",
    "the time @xmath232 , for the points to spread over the attractor @xmath1 , can be calculated by the time it takes for points to visit all the boxes along the diagonal .",
    "thus , we need to satisfy @xmath244 . ignoring the 1 appearing in the expression for @xmath245 due to the initial box in the estimation for the value of @xmath37",
    ", we arrive that @xmath246 .",
    "this stochastic system is discrete . in order to take into consideration the initial box in the calculation of @xmath37 ,",
    "we pick the first integer that is larger than @xmath247 , leading @xmath37 to be the largest integer that satisfies @xmath248    the largest lyapunov exponent or the order-1 expansion rate of this stochastic toy model can be calculated by @xmath249 , which take us to @xmath250 therefore , eq . ( [ tm_t ] ) can be rewritten as @xmath251 .",
    "the quantity @xmath50 can be calculated by @xmath252 , with @xmath232 .",
    "neglecting @xmath253 and the 1 appearing in @xmath254 due to the initial box , we have that @xmath255 $ ] . substituting in the definition of @xmath50",
    ", we obtain @xmath256 . using @xmath37 from eq .",
    "( [ tm_t ] ) , we arrive at @xmath257 where @xmath258 placing @xmath50 and @xmath42 in @xmath259 , give us @xmath260    let us now calculate @xmath186 . ignoring the border effect , and assuming that the expansion of points is uniform , then @xmath261 and @xmath262 . at the iteration @xmath232 , we have that @xmath263 . since @xmath264 $ ] , we can write that @xmath265 . placing @xmath37 from eq .",
    "( [ tm_t ] ) into @xmath36 takes us to @xmath266 . finally , dividing @xmath36 by @xmath37",
    ", we arrive that @xmath267 \\nonumber \\\\       & = &      \\log{(2)}(1-r ) .",
    "\\label{tm_ist}\\end{aligned}\\ ] ] as expected from the way we have constructed this model , eq .",
    "( [ tm_ist ] ) and ( [ tm_ic ] ) are equal and @xmath268 .",
    "had we included the border effect in the calculation of @xmath97 , denote the value by @xmath269 , we would have typically obtained that @xmath270 , since @xmath47 calculated considering a finite space @xmath5 would be either smaller or equal than the value obtained by neglecting the border effect . had we included the border effect in the calculation of @xmath186 , denote the value by @xmath271 , typically we would expect that the probabilities @xmath28 would not be constant .",
    "that is because the points that leave the subspace @xmath5 would be randomly reinjected back to @xmath5 .",
    "we would conclude that @xmath272 .",
    "therefore , had we included the border effect , we would have obtained that @xmath273 .    the way we have constructed this stochastic toy model results in @xmath274 .",
    "this is because the spreading of points along the diagonal direction is much faster than the spreading of points along the off - diagonal transverse direction .",
    "in other words , the second largest lyapunov exponent , @xmath47 , is close to zero .",
    "stochastic toy models which produce larger @xmath47 , one could consider that the spreading along the transverse direction is given by @xmath275 , with @xmath276 $ ] .      in terms of the order-1 expansion rate , @xmath173 , our quantities read @xmath176 , @xmath277}$ ] , and @xmath178 .",
    "in order to show that our expansion rate can be used to calculate these quantities , we consider that the experimental system is uni - dimensional and has a constant probability measure .",
    "additive noise is assumed to be bounded with maximal amplitude @xmath278 , and having constant density .",
    "our order-1 expansion rate is defined as @xmath279}.   \\label{define_exp_rates_sup}\\ ] ] where @xmath280 measures the largest growth rate of nearby points .",
    "since all it matters is the largest distance between points , it can be estimated even when the experimental data set has very few data points . since , in this example , we consider that the experimental noisy points have constant uniform probability distribution , @xmath281 can be calculated by @xmath282}.   \\label{define_exp_rates_sup1}\\ ] ] where @xmath283 represents the largest distance between pair of experimental noisy points in an @xmath7-square box and @xmath284 represents the largest distance between pair of the points that were initially in the @xmath7-square box but have spread out for an interval of time @xmath101 . the experimental system ( without noise )",
    "is responsible to make points that are at most @xmath164 apart from each other to spread to at most to @xmath165 apart from each other .",
    "this points spread out exponentially fast according to the largest positive lyapunov exponent @xmath42 by @xmath285    substituting eq .",
    "( [ delta ] ) in ( [ define_exp_rates_sup1 ] ) , and expanding @xmath286 to first order , we obtain that @xmath287 , and therefore , our expansion rate can be used to estimate lyapunov exponents .",
    "as rigorously shown in @xcite , the decay with time of the correlation , @xmath43 , is proportional to the decay with time of the density of the first poincar recurrences , @xmath288 , which measures the probability with which a trajectory returns to an @xmath7-interval after @xmath101 iterations .",
    "therefore , if @xmath288 decays with @xmath101 , for example exponentially fast , @xmath43 will decay with @xmath101 exponentially fast , as well .",
    "the relationship between @xmath43 and @xmath289 can be simply understood in chaotic systems with one expanding direction ( one positive lyapunov exponent ) . as shown in @xcite , the `` local '' decay of correlation ( measured in the @xmath7-interval )",
    "is given by @xmath290 , where @xmath291 is the probability measure of a chaotic trajectory to visit the @xmath7-interval .",
    "consider the shift map @xmath292 .",
    "for this map , @xmath293 and there are an infinite number of possible intervals that makes @xmath294 , for a finite @xmath101 .",
    "these intervals are the cells of a markov partition . as recently demonstrated by [ p. pinto , i. labouriau , m. s. baptista ] , in piecewise - linear systems as the shift map , if @xmath7 is a cell in an order-@xmath101 markov partition and @xmath295 , then @xmath296 and by the way a markov partition is constructed we have that @xmath297 .",
    "since that @xmath298 , we arrive at that @xmath299 , for a special finite time @xmath101 .",
    "notice that @xmath297 can be rewritten as @xmath300 .",
    "since for this map , the largest lyapunov exponent is equal to @xmath208 , then @xmath301 , which is exactly equal to the quantity @xmath37 , the time interval responsible to make the system to lose its memory from the initial condition and that can be calculated by the time that makes points inside an initial @xmath7-interval to spread over the whole phase space , in this case @xmath302 $ ] .",
    "imagine a network formed by @xmath303 coupled oscillators .",
    "uncoupled , each oscillator possesses a certain amount of positive lyapunov exponents , one zero , and the others are negative .",
    "each oscillator has dimension @xmath0 .",
    "assume that the only information available from the network are two @xmath304 dimensional measurements , or a scalar signal that is reconstructed to a @xmath304-dimensional embedding space .",
    "so , the subspace @xmath40 has dimension @xmath305 , and each subspace of a node ( or group of nodes ) has dimension @xmath304 . to be consistent with our previous equations , we assume that we measure @xmath306 positive lyapunov exponents on the projection @xmath40 .",
    "if @xmath307 , then in the following equations @xmath305 should be replaced by @xmath308 , naturally assuming that @xmath309 .    in analogy with the derivation of @xmath97 and @xmath98 in a bidimensional projection , we assume that if the spreading of initial conditions is uniform in the subspace @xmath5 .",
    "then , @xmath310 represents the probability of finding trajectory points in @xmath304-dimensional space of one node ( or a group of nodes ) and @xmath311 represents the probabilities of finding trajectory points in the @xmath305-dimensional composed subspace constructed by two nodes ( or two groups of nodes ) in the subspace @xmath5 . additionally , we consider that the hypothetical number of occupied boxes @xmath254 will be given by @xmath312 .",
    "then , we have that @xmath313 , which lead us to @xmath314 similarly to the way we have derived @xmath98 in a bidimensional projection , if @xmath40 has more than 2 positive lyapunov exponents , then @xmath315    to write eq .",
    "( [ ic_hd ] ) in terms of the positive lyapunov exponents , we first extend the calculation of the quantity @xmath50 to higher - dimensional subspaces that have dimensionality 2q , @xmath316 where @xmath317 are the lyapunov exponents measured on the subspace @xmath5 . to derive this equation",
    "we only consider that the hypothetical number of occupied boxes @xmath254 is given by @xmath318 .",
    "we then substitute @xmath50 as a function of these exponents ( eq .",
    "( [ dk ] ) ) in eq .",
    "( [ ic_hd ] ) .",
    "we arrive at @xmath319      consider a network whose attractor @xmath1 possesses @xmath320 positive lyapunov exponents , denoted by @xmath321 , @xmath322 . for a typical subspace @xmath5 , @xmath42 measured on @xmath5 is equal to the largest lyapunov exponent of the network .",
    "just for the sake of simplicity , assume that the nodes in the network are sufficiently well connected so that in a typical measurement with a finite number of observations this property holds , i.e. , @xmath323 .",
    "but , if measurements provide that @xmath324 , the next arguments apply as well , if one replaces @xmath325 appearing in the further calculations by the smallest lyapunov exponent , say , @xmath326 , of the network that is still larger than @xmath42 , and then , substitute @xmath327 by @xmath328 , and so on . as before , consider that @xmath306 .",
    "then , for an arbitrary subspace @xmath5 , @xmath329 , since a projection can not make the lyapunov exponents larger , but only smaller or equal",
    ".    defining @xmath330 since @xmath331 , it is easy to see that @xmath332    so , @xmath97 , measured on the subspace @xmath40 and a function of the @xmath305 largest positive lyapunov exponents measured in @xmath40 , is an upper bound for @xmath333 , a quantity defined by the @xmath305 largest positive lyapunov exponents of the attractor @xmath1 of the network . therefore , if the lyapunov exponents of a network are know , the quantity @xmath333 can be used as a way to estimate how much is the mir between two measurements of this network , measurements that form the subspace @xmath5 .    notice that @xmath97 depends on the projection chosen ( the subspace @xmath5 ) and on its dimension , whereas @xmath333 depends on the dimension of the subspace @xmath40 ( the number 2q of positive lyapunov exponents ) . the same happens for the mutual information between random variables that depend on the projection considered .",
    "equation ( [ icu_new ] ) is important because it allows us to obtain an estimation for the value of @xmath97 analytically .",
    "as an example , imagine the following network of coupled maps with a constant jacobian    @xmath334    where @xmath335 $ ] and @xmath336 represents the connecting adjacent matrix . if node @xmath10 connects to node @xmath9 , then @xmath337 , and 0 otherwise .",
    "assume that the nodes are connected all - to - all .",
    "then , the @xmath303 positive lyapunov exponents of this network are : @xmath338 and @xmath339}$ ] , with @xmath340 .",
    "assume also that the subspace @xmath5 has dimension @xmath305 and that @xmath305 positive lyapunov exponents are observed in this space and that @xmath341 .",
    "substituting these lyapunov exponents in eq .",
    "( [ icu_new ] ) , we arrive at @xmath342 we conclude that there are two ways for @xmath333 to increase",
    ". either one considers larger measurable subspaces @xmath5 or one increases the coupling between the nodes .",
    "this suggests that the larger the coupling strength is the more information is exchanged between groups of nodes .    for arbitrary topologies",
    ", one can also derive analytical formulas for @xmath333 in this network , since @xmath321 for @xmath343 can be calculated from @xmath327 @xcite .",
    "one arrives at @xmath344 where @xmath345 is the @xmath9th largest eigenvalue ( in absolute value ) of the laplacian matrix @xmath346 .",
    "concluding , we have shown a procedure to calculate mutual information rate ( mir ) between two nodes ( or groups of nodes ) in dynamical networks and data sets that are either mixing , or present fast decay of correlations , or have sensitivity to initial conditions , and have proposed significant upper ( @xmath97 ) and lower ( @xmath98 ) bounds for it , in terms of the lyapunov exponents , the expansion rates , and the capacity dimension . since our upper bound is calculated from lyapunov exponents or expansion rates , it can be used to estimate the mir between data sets that have different sampling rates or experimental resolution ( e.g. the rise of the ocean level and the average temperature of the earth ) , or between systems possessing a different number of events .",
    "additionally , lyapunov exponents can be accurately calculated even when data sets are corrupted by noise of large amplitude ( observational additive noise ) @xcite or when the system generating the data suffers from parameter alterations ( `` experimental drift '' ) @xcite .",
    "our bounds link information ( the mir ) and the dynamical behaviour of the system being observed with synchronisation , since the more synchronous two nodes are , the smaller @xmath47 and @xmath347 will be",
    ". this link can be of great help in establishing whether two nodes in a dynamical network or in a complex system not only exchange information but also have linear or non - linear interdependences , since the approaches to measure the level of synchronisation between two systems are reasonably well known and are been widely used .",
    "if variables are synchronous in a time - lag fashion @xcite , it was shown in ref .",
    "@xcite that the mir is independent of the delay between the two processes .",
    "the upper bound for the mir could be calculated by measuring the lyapunov exponents of the network ( see supplementary information ) , which are also invariant to time - delays between the variables .    *",
    "acknowledgments * m. s. baptista was partially supported by the northern research partnership ( nrp ) and alexander von humboldt foundation .",
    "m. s. baptista would like to thank a. politi for discussions concerning lyapunov exponents .",
    "rubinger , e.r .",
    "v. junior and j.c .",
    "sartorelli thanks the brazilian agencies capes , cnpq , fapemig , and fapesp ."
  ],
  "abstract_text": [
    "<S> the amount of information exchanged per unit of time between two nodes in a dynamical network or between two data sets is a powerful concept for analysing complex systems . </S>",
    "<S> this quantity , known as the mutual information rate ( mir ) , is calculated from the mutual information , which is rigorously defined only for random systems . moreover , </S>",
    "<S> the definition of mutual information is based on probabilities of significant events . </S>",
    "<S> this work offers a simple alternative way to calculate the mir in dynamical ( deterministic ) networks or between two data sets ( not fully deterministic ) , and to calculate its upper and lower bounds without having to calculate probabilities , but rather in terms of well known and well defined quantities in dynamical systems . as possible applications of our bounds </S>",
    "<S> , we study the relationship between synchronisation and the exchange of information in a system of two coupled maps and in experimental networks of coupled oscillators . </S>"
  ]
}