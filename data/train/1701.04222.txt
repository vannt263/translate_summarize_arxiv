{
  "article_text": [
    "we consider multi - armed bandit problems in the adversarial setting whereby an agent selects one from a number of alternatives ( called arms ) at each round and receives a gain that depends on its choice .",
    "the agent s goal is to maximize its total gain over time .",
    "there are two main settings for the bandit problem . in the stochastic one ,",
    "the gains of each arm are generated i.i.d by some unknown probability law . in the adversarial",
    "setting , which is the focus of this paper , the gains are generated adversarially .",
    "we are interested in finding algorithms with a total gain over @xmath3 rounds not much smaller than that of an oracle with additional knowledge about the problem . in both settings , algorithms that achieve the optimal ( problem - independent )",
    "regret bound of @xmath7 are known  @xcite .",
    "this problem is a model for many applications where there is a need for trading - off exploration and exploitation .",
    "this is so because , whenever we make a choice , we only observe the gain generated by that choice , and not the gains that we could have obtained otherwise .",
    "an example is clinical trials , where arms correspond to different treatments or tests , and the goal is to maximize the number of cured patients over time while being uncertain about the effects of treatments .",
    "other problems , such as search engine advertisement and movie recommendations can be formalized similarly @xcite .",
    "privacy can be a serious issue in the bandit setting ( c.f .",
    "for example , in clinical trials , we may want to detect and publish results about the best drug without leaking sensitive information , such as the patient s health condition and genome . _ differential privacy _",
    "@xcite formally bounds the amount of information that a third party can learn no matter their power or side information .",
    "differential privacy has been used before in the stochastic setting  @xcite where the authors obtain optimal algorithms up to logarithmic factors . in the adversarial",
    "setting , @xcite adapts an algorithm called _ follow the approximate leader _ to make it private and obtain a regret bound of @xmath5 . in this work",
    ", we show that a number of simple algorithms can satisfy privacy guarantees , while achieving nearly optimal regret ( up to logarithmic factors ) that scales naturally with the level of privacy desired .",
    "our work is also of independent interest for non - private multi - armed bandit algorithms , as there are competitive with the current state of the art against switching - cost adversaries ( where we recover the optimal bound ) .",
    "finally , we provide rigorous empirical results against a variety of adversaries .    the following section gives the main background and notations .",
    "section [ sec : noise ] describes meta - algorithms that perturb the gain sequence to achieve privacy , while section  [ sec : lever - inher - priv ] explains how to leverage the privacy inherent in the exp3 algorithm by modifying the way gains are used .",
    "section  [ sec : experiments ] compares our algorithms with exp3 in a variety of settings .",
    "the full proofs of all our main results are in the full version .",
    "formally , a bandit game is defined between an adversary and an agent as follows : there is a set of @xmath8 arms @xmath9 , and at each round @xmath10 , the agent plays an arm @xmath11 .",
    "given the choice @xmath12 , the adversary grants the agent a gain @xmath13 $ ] .",
    "the agent only observes the gain of arm @xmath12 , and not that of any other arms .",
    "the goal of this agent is to maximize its total gain after @xmath3 rounds , @xmath14 . a randomized bandit algorithm @xmath15)^ { * } \\to \\mathscr{d}({{{\\mathcal{a}}}})$ ] maps every arm - gain history to a distribution over the next arm to take .",
    "the nature of the adversary , and specifically , how the gains are generated , determines the nature of the game . for the _",
    "stochastic _ adversary  @xcite , the gain obtained at round @xmath10 is generated i.i.d from a distribution @xmath16 .",
    "the more general _ fully oblivious",
    "_ adversary @xcite generates the gains independently at round @xmath10 but not necessarily identically from a distribution @xmath17 .",
    "finally , we have the _ oblivious _ adversary  @xcite whose only constraint is to generate the gain @xmath18 as a function of the current action @xmath12 only , i.e. ignoring previous actions and gains .    while focusing on oblivious adversaries , we discovered that by targeting differential privacy we can also compete against the stronger _ @xmath19-bounded memory adaptive adversary _",
    "@xcite who can use up to the last @xmath19 gains .",
    "the oblivious adversary is a special case with @xmath20 .",
    "another special case of this adversary is the one with _ switching costs _ , who penalises the agent whenever he switches arms , by giving the lowest possible gain of 0 ( here @xmath21 ) .    [",
    "[ regret . ] ] regret .",
    "+ + + + + + +    relying on the cumulative gain of an agent to evaluate its performance can be misleading . indeed , consider the case where an adversary gives a zero gain for all arms at every round .",
    "the cumulative gain of the agent would look bad but no other agents could have done better .",
    "this is why one compares the gap between the agent s cumulative gain and the one obtained by some hypothetical agent , called _ oracle _ , with additional information or computational power .",
    "this gap is called the _",
    "regret_.    there are also variants of the oracle that are considered in the literature .",
    "the most common variant is the _ fixed oracle _ , which always plays the best fixed arm in hindsight .",
    "the regret @xmath22 against this _ oracle _ is : @xmath23 in practice , we either prove a high probability bound on @xmath22 or an expected value @xmath24 with : @xmath25\\ ] ] where the expectation is taken with respect to the random choices of both the agent and adversary .",
    "an alternative notion , the _ pseudo - regret _ , is defined as : @xmath26\\ ] ] while the _ pseudo regret _ compares an agent against the expected gain of the oracle over all possible gains sequences , the _ expected regret _ compares the agent against the oracle on the actual game ( or actual realization of the gains ) .",
    "this means that a bound on the _ pseudo regret _ does not guarantee a bound on the _ expected regret _ .",
    "more formally , @xmath27 there are other oracles like the _ shifting oracle _ but those are out of scope of this paper .",
    "[ [ exp3 . ] ] exp3 .",
    "+ + + + +    the exponential - weight for exploration and exploitation ( exp3 @xcite ) algorithm achieves the optimal bound ( up to logarithmic factors ) of @xmath28 for the weak regret ( i.e. the expected regret compared to the _ fixed oracle _ ) against an _",
    "oblivious adversary_. exp3 simply maintains an estimate @xmath29 for the cumulative gain of arm @xmath30 up to round @xmath10 with @xmath31 where    @xmath32    with @xmath33 a well defined constant .",
    "finally , exp3 plays one action randomly according to the probability distribution @xmath34 with @xmath35 as defined above .",
    "the following definition ( from @xcite ) specifies what is meant when we called a bandit algorithm differentially private at a single round @xmath10 :    a randomized bandit algorithm @xmath36 is @xmath37-differentially private at round @xmath10 , if for all sequence @xmath38 and @xmath39 that differs in at most one round , we have for any action subset @xmath40 : @xmath41 where @xmath42 denotes the probability distribution specified by the algorithm and @xmath43 with @xmath44 the gains of all arms at round @xmath45 .",
    "when @xmath46 , the algorithm is said to be _ @xmath0-differential private_. [ def : dp ]",
    "the @xmath0 and @xmath47 parameters quantify the amount of privacy loss .",
    "lower ( @xmath0,@xmath47 ) indicate higher privacy and consequently we will also refer to ( @xmath0,@xmath47 ) as the privacy loss .",
    "definition [ def : dp ] means that the output of the bandit algorithm at round @xmath10 is almost insensible to any single change in the gains sequence .",
    "this implies that whether or not we remove a single round , replace the gains , the bandit algorithm will still play almost the same action . assuming the gains at round @xmath10 are linked to a user private data ( for example his cancer status or the advertisement he clicked )",
    ", the definition preserves the privacy of that user against any third parties looking at the output .",
    "this is the case because the choices or the participation of that user would not almost affect the output .",
    "equation specifies how much the output is affected by a single user .",
    "we would like definition [ def : dp ] to hold for all rounds , so as to protect the privacy of all users .",
    "if it does for some @xmath37 , then we say the algorithm has _ per - round _ or _",
    "instantaneous _ privacy loss @xmath37 .",
    "such an algorithm also has a _ cumulative _ privacy loss of at most @xmath48 with @xmath49 and @xmath50 after @xmath3 steps .",
    "our goal is to design bandit algorithm such that their cumulative privacy loss @xmath48 are as low as possible while achieving simultaneously a very low regret . in practice",
    ", we would like @xmath51 and the regret to be sub - linear while @xmath52 should be a very small quantity .",
    "definition [ def : dp : cumul ] formalizes clearly the meaning of this cumulative privacy loss and for ease of presentation , we will ignore the term `` cumulative '' when referring to it .",
    "a randomized bandit algorithm @xmath36 is @xmath37-differentially private up to round @xmath10 , if for all @xmath38 and @xmath39 that differs in at most one round , we have for any action subset @xmath53 : @xmath54 where @xmath42 and @xmath55 are as defined in definition [ def : dp ] .",
    "[ def : dp : cumul ]    most of the time , we will refer to definition [ def : dp : cumul ] and whenever we need to use definition [ def : dp ] , this will be made explicit .",
    "the simplest mechanism to achieve differential privacy for a function is to add laplace noise of scale proportional to its sensitivity .",
    "the sensitivity is the maximum amount by which the value of the function can change if we change a single element in the inputs sequence .",
    "for example , if the input is a stream of numbers in @xmath56 $ ] and the function their sum , we can add laplace noise of scale @xmath57 to each number and achieve @xmath0-differential privacy with an error of @xmath58 in the sum .",
    "however , @xcite introduced _ hybrid mechanism _ , which achieves @xmath0-differential privacy with only poly - logarithmic error ( with respect to the true sum ) .",
    "the idea is to group the stream of numbers in a binary tree and only add a laplace noise at the nodes of the tree .    as demonstrated above ,",
    "the main challenge with differential privacy is thus to trade - off optimally privacy and utility .",
    "[ [ notation . ] ] notation .",
    "+ + + + + + + + +    in this paper , @xmath30 will be used as an index for an arbitrary arm in @xmath59 $ ] , while @xmath60 will be used to indicate an optimal arm and @xmath12 is the arm played by an agent at round @xmath10 .",
    "we use @xmath61 to indicate the gain of the @xmath30-th arm at round @xmath10 .",
    "@xmath62 is the regret of the algorithm @xmath36 after @xmath3 rounds .",
    "the index and @xmath3 are dropped when it is clear from the context .",
    "unless otherwise specified , the regret is defined for oblivious adversaries against the fixed oracle .",
    "we use `` @xmath63 '' to denote that @xmath64 is generated from distribution @xmath65 .",
    "@xmath66 is used to denote the laplace distribution with scale @xmath67 while @xmath68 denotes the bernoulli distribution with parameter @xmath69 .",
    "we start by showing that the obvious technique to achieve a given @xmath0-differential privacy in adversarial bandits already beat the state - of - the art .",
    "the main idea is to use any base bandit algorithm @xmath71 as input and add a laplace noise of scale @xmath57 to each gain before @xmath71 observes it .",
    "this technique gives @xmath0-dp differential privacy as the gains are bounded in @xmath56 $ ] and the noises are added i.i.d at each round .",
    "however , bandits algorithms require bounded gains while the noisy gains are not . the trick is to ignore rounds where the noisy gains fall outside an interval of the form @xmath72 $ ] .",
    "we pick the threshold @xmath73 such that , with high probability , the noisy gains will be inside the interval @xmath72 $ ] .",
    "more precisely , @xmath73 can be chosen such that with high probability , the number of rounds ignored is lower than the upper bound @xmath74 on the regret of @xmath71 . given that in the standard bandit problem , the gains are bounded in @xmath75 $ ] , the gains at accepted rounds are rescaled back to @xmath56 $ ] .",
    "theorem [ theo : dp : dp_a_laplace ] shows that all these operations still preserve @xmath0-dp while theorem [ theo : regret : dp_a_laplace ] demonstrates that the upper bound on the expected regret of @xmath70 adds some small additional terms to @xmath74 . to illustrate how small those additional terms are , we instantiate @xmath70 with the _ exp3 _ algorithm .",
    "this leads to a mechanism called _ dp - exp3-lap _ described in algorithm [ alg : dpexplaplace ] . with a carefully chosen threshold @xmath73 , corollary",
    "[ cor : dpexplap ] implies that the additional terms are such that the expected regret of _ dp - exp3-lap _ is @xmath76 which is optimal in @xmath3 up to some logarithmic factors .",
    "this result is a significant improvement over the best known bound so far of @xmath77 from @xcite and solves simultaneously the challenge ( whether or not one can get @xmath0-dp mechanism with optimal regret ) posed by the authors .",
    "let @xmath78 for all arms and @xmath79 , @xmath80    compute the probability distribution @xmath69 over the arms @xmath81 with @xmath82 and @xmath35 as in eq .",
    "draw an arm @xmath12 from the probability distribution @xmath69 .",
    "receive the reward @xmath83    let the noisy gain be @xmath84 @xmath81 with @xmath85    scale @xmath86 to @xmath56 $ ] update the estimated cumulative gain of arm @xmath12 : @xmath87    [ alg : dpexplaplace ]    if @xmath70 is run with input a base bandit algorithm @xmath71 , the noisy reward @xmath86 of the true reward @xmath83 set to @xmath84 with @xmath88 , the acceptance interval set to @xmath72 $ ] with the scaling of the rewards @xmath89 outside @xmath56 $ ] done using @xmath90 ; then the regret @xmath91 of @xmath70 satisfies :    @xmath92    where @xmath93 is the upper bound on the regret of @xmath71 when the rewards are scaled from @xmath72 $ ] to @xmath56 $ ] [ theo : regret : dp_a_laplace ]    we observed that @xmath70 is an instance of @xmath71 run with the noisy rewards @xmath94 instead of @xmath95 .",
    "this means @xmath93 is an upper bound of the regret @xmath96 on @xmath94 .",
    "then , we derived a lower bound on @xmath96 showing how close it is to @xmath91 .",
    "this allows us to conclude .",
    "if @xmath70 is run with exp3 as its base algorithm and @xmath79 , then its expected regret @xmath97 satisfies @xmath98 [ cor : dpexplap ]    the proof comes by combining the regret of _ exp3 _",
    "@xcite with theorem [ theo : regret : dp_a_laplace ]    [ theo : dp : dp_a_laplace ] @xmath70 is @xmath0-differentially private up to round @xmath3 .",
    "combining the privacy of laplace mechanism with the parallel composition @xcite and post - processing theorems @xcite concludes the proof .",
    "[ [ on - the - differential - privacy - of - exp3 ] ] on the differential privacy of _",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    @xcite shows that a variation of exp3 for the full - information setting ( where the agent observes the gain of all arms at any round regardless of what he played ) is already differentially private .",
    "their results imply that one can achieve the optimal regret with only a sub - logarithmic privacy loss ( @xmath99 ) after @xmath3 rounds .",
    "we start this section by showing a similar result for exp3 in theorem [ theo : exp3-privacy ] .",
    "indeed , we show that exp3 is already differentially private but with a per - round privacy loss of @xmath100 . ]",
    "our results imply that exp3 can achieve the optimal regret albeit with a linear privacy loss of @xmath101-dp after @xmath3 rounds .",
    "this is a huge gap compared with the full - information setting and underlines the significance of our result in section [ sec : noise ] where we describe a concrete algorithm demonstrating that the optimal regret can be achieved with only a logarithmic privacy loss after @xmath3 rounds .",
    "[ theo : exp3-privacy ] the _ exp3 _ algorithm is : @xmath102 differentially private up to round @xmath3 .    in practice , we also want _",
    "exp3 _ to have a sub - linear regret .",
    "this implies that @xmath103 and _ exp3 _ is simply @xmath104-dp over @xmath3 rounds .",
    "the first two terms in the theorem come from the observation that exp3 is a combination of two mechanisms : the exponential mechanism @xcite and a randomized response .",
    "the last term comes from the observation that with probability @xmath33 we enjoy a perfect @xmath105-dp .",
    "then , we use chernoff to bound with high probability the number of times we suffer a non - zero privacy loss .",
    "we will now show that the privacy of exp3 itself may be improved without any additional noise , and with only a moderate impact on the regret .",
    "[ [ on - the - privacy - of - a - exp3-wrapper - algorithm ] ] on the privacy of a _",
    "exp3 _ wrapper algorithm + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the previous paragraph leads to the conclusion that it is impossible to obtain a sub - linear privacy loss with a sub - linear regret while using the original _",
    "exp3_. here , we will prove that an existing technique is already achieving this goal . the algorithm which we called @xmath106 is from @xcite .",
    "it groups the rounds into disjoint intervals of fixed size @xmath107 where the @xmath108th interval starts on round @xmath109 and ends on round @xmath110 . at the beginning of interval @xmath108",
    ", @xmath106 receives an action from _",
    "exp3 _ and plays it for @xmath107 rounds . during that time , _",
    "exp3 _ does not observe any feedback . at the end of the interval , @xmath106 feeds _",
    "exp3 _ with a single gain , the average gain received during the interval .",
    "theorem [ theo : regret : exp3tau ] borrowed from @xcite specifies the upper bound on the regret @xmath106 .",
    "it is remarkable that this bound holds against the _ m - memory bounded adaptive adversary_. while in theorem [ theo : privacy : wrapper ] , we show the privacy loss enjoyed by this algorithm , one gets a better intuition of how good those results are from corollary [ cor : exp : tau ] and [ cor : exp : tau : inv ] .",
    "indeed , we can observe that @xmath106 achieves a sub - logarithmic privacy loss of @xmath4 with a regret of @xmath5 against a special case of the _ m - memory bounded adaptive adversary _ called the _ switching costs adversary _ for which @xmath21 .",
    "this is the optimal regret bound ( in the sense that there is a matching lower bound @xcite ) .",
    "this means that in some sense we are getting privacy for free against this adversary .",
    "the expected regret of @xmath106 is upper bounded by : @xmath111 against the _ m - memory bounded adaptive adversary _ for any @xmath112 .",
    "[ theo : regret : exp3tau ]    @xmath106 is @xmath113-dp up to round @xmath3 .",
    "[ theo : privacy : wrapper ]    the sensitivity of each gain is now @xmath114 as we are using the average .",
    "combined with theorem , it means the per - round privacy loss is @xmath115 .",
    "given that _",
    "exp3 _ only observes @xmath116 rounds , using the advanced composition theorem @xcite ( theorem iii.3 ) concludes the final privacy loss over @xmath3 rounds .",
    "@xmath106 run with @xmath117 is @xmath118 differentially private up to round @xmath3 with @xmath119 , @xmath120 .",
    "its expected regret against the _ switching costs adversary _ is upper bounded by @xmath121 .",
    "[ cor : exp : tau ]    the proof is immediate by replacing @xmath107 and @xmath52 in theorem [ theo : regret : exp3tau ] and [ theo : privacy : wrapper ] and the fact that for the _ switching costs adversary _ , @xmath21 .",
    "@xmath106 run with @xmath122 is @xmath37 differentially private and its expected regret against the _ switching costs adversary _ is upper bounded by : @xmath123 [ cor : exp : tau : inv ]",
    "we tested _ dp - exp3-lap _ , @xmath124 together with the non - private _ exp3 _ against a few different adversaries . the privacy parameter @xmath0 of _ dp - exp3-lap _ is set as defined in corollary [ cor : exp : tau ] .",
    "this is done so that the regret of _ dp - exp3-lap _ and @xmath124 are compared with the same privacy level .",
    "all the other parameters of _ dp - exp3-lap _ are taken as defined in corollary [ cor : dpexplap ] while the parameters of @xmath124 are taken as defined in corollary [ cor : exp : tau ] .",
    "for all experiments , the horizon is @xmath125 and the number of arms is @xmath126 .",
    "we performed @xmath127 independent trials and reported the _ median - of - means _ estimator of the cumulative regret .",
    "it partitions the trials into @xmath128 equal groups and return the median of the sample means of each group .",
    "proposition [ prop : median - means ] is a well known result ( also in @xcite ) giving the accuracy of this estimator .",
    "its convergence is @xmath129 , with exponential probability tails , even though the random variable @xmath64 may have heavy - tails . in comparison",
    ", the empirical mean can not provide such guarantee for any @xmath130 and confidence in @xmath131 $ ] @xcite .",
    "[ prop : median - means ] let @xmath64 be a random variable with mean @xmath132 and variance @xmath133 .",
    "assume that we have @xmath134 independent sample of @xmath64 and let @xmath135 be the _ median - of - means _ computed using @xmath128 groups .",
    "with probability at least @xmath136 , @xmath135 satisfies @xmath137 .",
    "we set the number of groups to @xmath138 , so that the confidence interval holds w.p .",
    "at least @xmath139 .",
    "we also reported the deviation of each algorithm using the gini s mean difference ( gmd hereafter ) @xcite .",
    "gmd computes the deviation as @xmath140 with @xmath141 the @xmath108-th order statistics of the sample ( that is @xmath142 ) .",
    "as shown in @xcite , the gmd provides a superior approximation of the true deviation than the standard one . to account for the fact that the cumulative regret of our algorithms might not follow a symmetric distribution , we computed the gmd separately for the values above and below the _ median - of - means_.    at round @xmath10 , we computed the cumulative regret against the fixed oracle who plays the best arm assuming that the end of the game is at @xmath10 .",
    "the oracle uses the actual sequence of gains to decide his best arm . for a given trial",
    ", we make sure that all algorithms are playing the same game by generating the gains for all possible pair of round - arm before the game starts .",
    "[ [ deterministic - adversary . ] ] deterministic adversary .",
    "+ + + + + + + + + + + + + + + + + + + + + + + +    as shown by @xcite , the expected regret of any agent against an oblivious adversary can not be worse than that against the worst case deterministic adversary . in this experiment ,",
    "arm @xmath100 is the best and gives @xmath143 for every even round . to trick the players into picking the wrong arms",
    ", the first arm always gives @xmath144 whereas the third gives @xmath143 for every round multiple of @xmath145 .",
    "the remaining arms always give @xmath105 . as shown by the figure , this simple adversary is already powerful enough to make the algorithms attain their upper bound .    [",
    "[ stochastic ] ] stochastic adversary + + + + + + + + + + + + + + + + + + + +    this adversary draws the gains of the first arm i.i.d from @xmath146 whereas all other gains are drawn i.i.d from @xmath147 .",
    "[ [ full_oblivious ] ] fully oblivious adversary .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    for the best arm @xmath60 , it first draws a number @xmath69 uniformly in @xmath148 $ ] and generates the gain @xmath149 .",
    "for all other arms , @xmath69 is drawn from @xmath150 $ ] .",
    "this process is repeated at every round . in our experiments ,",
    "@xmath151    [ [ an - oblivious - adversary . ] ] an oblivious adversary .",
    "+ + + + + + + + + + + + + + + + + + + + + + +    this adversary is identical to the fully oblivious one for every round multiple of @xmath152 . between two multiples of @xmath152 the last gain of the arm",
    "is given .",
    "[ [ the - switching - costs - adversary ] ] the switching costs adversary + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    this adversary ( defined at figure 1 in @xcite ) defines a stochastic processes ( including simple gaussian random walk as special case ) for generating the gains . it was used to prove that any algorithm against this adversary must incur a regret of @xmath5 .",
    "[ [ discussion ] ] discussion + + + + + + + + + +    figure  [ fig : experiments ] shows our results against a variety of adversaries , with respect to a _ fixed oracle_. overall , the performance ( in term of regret ) of _ dp - exp3-lap _ is very competitive against that of exp3 while providing a significant better privacy .",
    "this means that _ dp - exp3-lap _ allows us to get privacy for free in the bandit setting against an adversary not more powerful than the oblivious one .",
    "the performance of @xmath124 is worse than that of _ dp - exp3-lap _ against an oblivious adversary or one less powerful .",
    "however , the situation is completely reversed against the more powerful switching cost adversary . in that setting , @xmath124 outperforms both exp3 and _ dp - exp3-lap _ confirming the theoretical analysis .",
    "we can see @xmath124 as the algorithm providing us privacy for free against switching cost adversary and adaptive m - bounded memory one in general .",
    "we have provided the first results on differentially private adversarial multi - armed bandits , which are optimal up to logarithmic factors .",
    "one open question is how differential privacy affects regret in the full reinforcement learning problem . at this point in time , the only known results in the mdp setting obtain differentially private algorithms for monte carlo policy evaluation  @xcite . while this implies that it is possible to obtain policy iteration algorithms , it is unclear how to extend this to the full online reinforcement learning problem .",
    "this research was supported by the snsf grants `` adaptive control with approximate bayesian computation and differential privacy '' and `` swiss sense synergy '' , by the marie curie actions ( rea 608743 ) , the future of life institute `` mechanism design for ai architectures '' and the cnrs specific action on security .",
    "dekel , o. ; ding , j. ; koren , t. ; and peres , y. 2014 .",
    "bandits with switching costs : t2/3 regret . in _ proceedings of the 46th annual acm symposium on theory of computing _",
    ", stoc 14 , 459467 .",
    "new york , ny , usa : acm .                    mcsherry , f. , and talwar , k. 2007 .",
    "mechanism design via differential privacy . in _ proceedings of the 48th annual ieee symposium on foundations of computer science _ , focs 07 , 94103 .",
    "washington , dc , usa : ieee computer society .",
    "mcsherry , f.  d. 2009 .",
    "privacy integrated queries : an extensible platform for privacy - preserving data analysis . in _ proceedings of the 2009 acm",
    "sigmod international conference on management of data _ , sigmod 09 , 1930 .",
    "new york , ny , usa : acm ."
  ],
  "abstract_text": [
    "<S> in this paper , we improve the previously best known regret bound to achieve @xmath0-differential privacy in oblivious adversarial bandits from @xmath1 to @xmath2 . </S>",
    "<S> this is achieved by combining a laplace mechanism with exp3 . </S>",
    "<S> we show that though exp3 is already differentially private , it leaks a linear amount of information in @xmath3 . however , we can improve this privacy by relying on its intrinsic exponential mechanism for selecting actions . </S>",
    "<S> this allows us to reach @xmath4-dp , with a regret of @xmath5 that holds against an adaptive adversary , an improvement from the best known of @xmath6 . </S>",
    "<S> this is done by using an algorithm that run exp3 in a mini - batch loop . </S>",
    "<S> finally , we run experiments that clearly demonstrate the validity of our theoretical analysis . </S>"
  ]
}