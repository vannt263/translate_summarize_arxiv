{
  "article_text": [
    "advances in quantum information science herald a new era of information technology .",
    "quantum information science has recently penetrated interdisciplinary science and engineering fields . in particular , a current research topic is to adapt the basic idea of machine learning for quantum information processing . although `` learning '' is a behavior of humans and other living things , a device or a machine can also learn a task according to the theory of machine learning , which was developed as a subfield of artificial intelligence @xcite .",
    "in fact , the optimization of control parameters without any pre - programmed knowledge can be referred to as a typical task of machine learning . in this context , the techniques of machine learning have recently been applied to various quantum information protocols @xcite .    following this trend ,",
    "here we formulate an intriguing problem .",
    "suppose that one intends to construct an operation to execute a particular quantum task .",
    "for this purpose , a quantum machine learning technique can be used to train the operation devices for the desired task . however , these devices are not necessarily located at the same place as the one who is designing the task to be taught ( called a provider hereafter ) . to realize scalable quantum devices or networks , joint work between different parts of a composite architecture or between separated participants may be necessary . for the purpose ,",
    "several protocols of distributed quantum information processing have been developed @xcite .",
    "therefore , a quantum learning protocol performed by a separated learner and provider will also be required in some realistic application scenarios .    in this study",
    ", we design a protocol to prepare an arbitrary quantum device at a distant place by machine learning .",
    "we first assume an arbitrarily initialized device installed at one place where the learner ( say alice ) is located .",
    "the other , spatially separated , provider ( say bob ) determines the target quantum task , which can not be directly accessed by alice .",
    "note that the target information does not open to any other people .",
    "alice and bob use mainly quantum channels to communicate their quantum states .",
    "the output state from the device at alice s location is sent to bob so that he can assess the learning progress . to obtain feedback from bob",
    ", alice also sends reference quantum states , and bob returns them to alice after performing his task . in designing such a protocol",
    ", we employ a specific learning algorithm called single measurement and feedback @xcite .",
    "when learning is complete , we say that alice s operation device has learned to perform the desired quantum task .",
    "we also consider another issue that will be very important in the related field of called `` secure machine learning '' @xcite , which significantly highlighted that the machine learning process itself could be a target of any malicious attack .",
    "the aforementioned works classified the possible attack scenarios and defenses against those providing the theoretical analyses of the lower bound on attacker s work function .",
    "here we approach to this issue in a quantum manner , rather focusing on the scenario where alice and bob do not want any other external learner .",
    "thus , we design the protocol such that any malicious attempts to participate in or disturb the learning can be prohibited or noticed , as long as alice s learning elements ( i.e. , controllable unitary and measurement devices ) are not initially correlated",
    ". we will demonstrate by monte carlo simulations that our protocol works well when learning tasks for qubit states . the learning time and inaccuracy",
    "are also analyzed in the demonstration .",
    "here we describe our scenario for developing a remote learning protocol .",
    "suppose that two separated parties , alice and bob , intend to teach a device at alice s location to perform a quantum task .",
    "the target quantum task learned by the device can generally be identified as a unitary transformation from a given initial state @xmath0 to a specific final state @xmath1 determined by bob , i.e. , the provider .",
    "alice and bob communicate through quantum and classical channels .",
    "the process of our protocol is illustrated in fig .",
    "[ fig : method ] . the tasks performed by alice and bob and",
    "the channels are described in detail below .",
    "( which is also known to bob ) and initializes her own ( unitary ) device @xmath2 for learning .",
    "bob determines the state @xmath1 of the target ( which is known only to bob ) at a distant place so that alice s device @xmath2 learns a desired quantum operation ( see the main text for details).,scaledwidth=45.0% ]    \\(i ) _ alice s elements _  alice prepares a _ controllable _ device @xmath2 to learn a unitary transformation task from a fiducial state @xmath0 ( known to only alice and bob ) . here",
    "@xmath2 can be expressed as the unitary operator @xmath3 where @xmath4 is a ( @xmath5)-dimensional ( real ) vector , and @xmath6 is a vector operator whose components are su(@xmath7 ) group generators @xcite .",
    "we assume that @xmath7 is the dimension of the hilbert space of both @xmath1 and @xmath0 . in the process",
    ", alice controls the components @xmath8 $ ] ( @xmath9 ) of the vector @xmath10 .",
    "can generally be constructed in any @xmath7 .",
    "hence such parameterization is quite general ( see appendix a ) . the real components @xmath11 can be matched to some real control parameters in experiments , e.g. , beam - splitter and phase - shifter alignments in a linear optical system @xcite or radio frequency ( rf ) pulse sequences in a nuclear magnetic resonance ( nmr ) system @xcite . ] measurement devices and a feedback system to update the control parameters according to a learning algorithm are also placed on alice s side .",
    "alice also prepares to generate either @xmath12 ( @xmath13 ) or @xmath14 , which will be used as a reference state in our protocol .",
    "alice sends both her output state obtained by applying @xmath2 to the state @xmath0 and a reference state to bob for each trial .",
    "\\(ii ) _ quantum channels _ ",
    "alice and bob are connected by three _",
    "one - way _ quantum channels ( drawn as gray lines in fig .  [ fig : method ] ) .",
    "two of the channels are from alice to bob ( @xmath15 and @xmath16 ) , and the remaining one is from bob to alice ( @xmath17 ) .",
    "the channel @xmath15 carries the reference states , either @xmath12 ( @xmath13 ) or @xmath14 , and @xmath16 transmits alice s output states to bob .",
    "the channel @xmath17 is used to deliver the reference state from bob s task back to alice .",
    "\\(iii ) _ bob s elements _  bob , the provider , determines the target state @xmath1 ( known only to bob ) and prepares it for each trial .",
    "note that bob does not transmit any information on the target state @xmath1 directly to alice . after receiving alice s output state and a reference state",
    ", bob operates a full - fledged quantum module , which consists of two hadamard gates @xmath18 and a control - swap ( c - swap ) gate , as illustrated in fig .",
    "[ fig : method ] .",
    "the c - swap gate acts as @xmath19 , where @xmath20 is a @xmath21-dimensional identity , and @xmath22 is a swap operator , defined as @xmath23 @xcite .",
    "we now illustrate how our protocol runs .",
    "first , alice publicly declares the commencement to bob . here",
    ", the fiducial state @xmath0 is one element of a predetermined set of initial states , which are agreed upon only by alice and bob in advance .",
    "could be used as a cryptographic name ( i.e. , identity ) of alice in a modified protocol , as described in sec .",
    "thus , it may be more efficient that @xmath0 is prepared as an arbitrarily superposed state , e.g. , @xmath24 . ] . bob then determines the target state @xmath1 according to the input @xmath0 and informs alice that he is also ready . when alice and bob identify their signs , the process starts :    [ * p.1 * ] for every trial , alice generates a reference state , either @xmath12 ( @xmath13 ) or @xmath14 . for the @xmath12 state , alice applies the learning unitary operator @xmath25 to her input state as @xmath26 where @xmath10 is selected on the basis of alice s learning algorithm .",
    "note that @xmath10 is initially chosen at random . for either @xmath27 or @xmath28",
    ", alice applies a random unitary operator @xmath29 , such that @xmath30 where @xmath31 is a randomly generated vector ( known only to alice ) .",
    "thus , the states @xmath32 and @xmath33 are _ sequentially changed _ in each trial , depending on the choice of reference states .",
    "alice sends both the reference state and the output state @xmath34 , prepared as either @xmath35 or @xmath36 , to bob via @xmath15 and @xmath16 , respectively . here",
    ", we use the subscripts `` @xmath37 '' and `` @xmath38 '' to denote the reference and output modes , respectively .",
    "note that alice does not open the states that are being sent .",
    "[ * p.2 * ] then , bob applies the delivered state @xmath34 and the target state @xmath39 to his module , where the subscript `` @xmath40 '' denotes the target mode .",
    "it yields the state @xmath41 as @xmath42 here , for @xmath43 , the output state @xmath41 is given as    @xmath44    whereas for @xmath45 , we have @xmath46    note again that only alice knows whether the output @xmath41 is equal to eq .",
    "( [ eq : outs1 ] ) or eq .",
    "( [ eq : outs2 ] ) .",
    "bob resends the reference state after performing his task , written as @xmath47 , back to alice through @xmath17 .",
    "[ * p.3 * ] then , alice checks the returning state @xmath48 as follows : first , if the prepared reference state was @xmath27 or @xmath28 , alice performs the measurement @xmath49 with the bases @xmath50 on @xmath48 .",
    "note that bob s operation does not alter the reference states @xmath27 and @xmath28 [ see eq .",
    "( [ eq : outs2 ] ) ] .",
    "thus , if an unexpected outcome , i.e. , `` @xmath51 '' ( or `` @xmath52 '' ) for the initially prepared reference state @xmath27 ( or @xmath28 ) , appears in @xmath53 , alice can immediately notice that the state transmitted in @xmath15 or @xmath17 has been altered by an external learner . and @xmath17 .",
    "] second , for the reference state @xmath12 ( @xmath13 ) , alice applies the operation @xmath54 to the returned state @xmath48 and performs the measurement @xmath55 with the bases @xmath56 . in this case",
    ", the measurement results are delivered to the feedback system for _ effective _ quantum learning .    by iterating steps [ * p.1*][*p.3 * ] , alice s device @xmath25 is supposed to learn the desired task , @xmath57 where @xmath58 denotes the optimal vector achieved after learning is complete .",
    "to realize this learning process , we can use the following property : if @xmath59 , bob s output state @xmath41 for the reference state @xmath12 is to be @xmath60 just before the measurement @xmath55 [ see eq .",
    "( [ eq : outs1 ] ) ] , so alice can not obtain the outcome of @xmath61 .",
    "more generally , the probability @xmath62 that alice measures @xmath63 ( @xmath64 ) in @xmath55 can be calculated as @xmath65 where @xmath66 . our learning strategy is thus to update @xmath25 until @xmath67 is _ successively _ measured , without any single outcome of @xmath61 , in @xmath55 .",
    "this strategy is conceptually equivalent to the maximization of @xmath68 .",
    "to realize the above - mentioned strategy , we employ the quantum learning algorithm based on single measurement and feedback introduced in ref .",
    "this algorithm requires a _ finite _",
    "@xmath69-bit classical first - in - first - out ( fifo ) memory in which the measurement results are recorded as `` fail '' or `` not - fail '' data . note that , as the memory size is finite , the newest data have to push the old data out of the memory ( see fig .",
    "[ fig : cm ] ) .",
    "thus , the memory retains the latest data for the learning process .    in our case ,",
    "the learning algorithm is programmed in alice s feedback system with the rule for updating the vector @xmath10 of @xmath2 .",
    "the learning algorithm runs as follows : if alice measures @xmath67 in @xmath55 ( that is , `` not - fail '' ) , the feedback system reserves judgment regarding whether the current @xmath25 is appropriate and thus leaves the vector @xmath10 unchanged .",
    "otherwise , if @xmath61 is measured ( that is , `` fail '' ) , @xmath10 is updated according to @xmath70 where @xmath71 denotes the number of iterations of the effective learning process ( or the total number of measurements @xmath55 performed ) , @xmath72 is a vector randomly generated at the @xmath73 iteration step , and @xmath74 . here",
    ", @xmath75 and @xmath76 are the number of `` fail '' and `` not - fail '' data recorded in the memory , respectively .",
    "our learning algorithm is intuitively understandable : _ the greater the number of `` fail '' events is , the more changes are imposed_. note that the random vector @xmath77 , rather than any pre - programmed knowledge , is used to develop @xmath10 .",
    "this feature , i.e. , using no pre - programmed knowledge , is a typical trait of the `` learning '' in a broad sense , and is of particular importance in our task , as it implies that any information about the target @xmath1 is not directly referenced to find the optimal vector @xmath58 .",
    "the learning process is continued until all the `` fail '' data are eliminated in the @xmath69 memory blocks .",
    "we call this the halting condition . after learning",
    "is complete , i.e. , the halting condition is satisfied , alice s final output state @xmath78 is supposed to be well matched to the target state @xmath1 , with @xmath79 ( @xmath80 ) . here , we can infer that the learning error @xmath81 becomes small for large @xmath69 , but a large @xmath69 requires a longer learning time , as explicitly shown later .",
    "and ( b ) survival probability @xmath82 for @xmath83 . @xmath84 and @xmath82 ( red solid line ) are obtained by performing @xmath85 simulations . in each simulation ,",
    "the target state @xmath1 is randomly chosen .",
    "the survival probability @xmath82 is well fitted to the exponential decay function @xmath86 ( green dashed line ) , where @xmath87 is a characteristic constant that characterizes the average number of effective iterations @xmath88 required to complete the learning process ; @xmath89 .",
    "we obtain @xmath90 and thus @xmath91 .",
    "the actual average iteration number in the simulations is @xmath92.,title=\"fig:\",scaledwidth=23.0% ]   and ( b ) survival probability @xmath82 for @xmath83 . @xmath84 and @xmath82 ( red solid line )",
    "are obtained by performing @xmath85 simulations . in each simulation ,",
    "the target state @xmath1 is randomly chosen .",
    "the survival probability @xmath82 is well fitted to the exponential decay function @xmath86 ( green dashed line ) , where @xmath87 is a characteristic constant that characterizes the average number of effective iterations @xmath88 required to complete the learning process ; @xmath89 .",
    "we obtain @xmath90 and thus @xmath91 . the actual average iteration number in the simulations",
    "is @xmath92.,title=\"fig:\",scaledwidth=23.0% ]    we perform numerical simulations to analyze our learning protocol . here , we consider the single - qubit target states ( i.e. , @xmath93 ) for a numerical proof - of - principle demonstration . in the simulations , we investigate mainly the learning and survival probabilities .",
    "the learning probability @xmath84 is defined as the probability that learning is completed before or at a certain number @xmath71 of effective iteration steps .",
    "the survival probability @xmath82 is defined as @xmath94 ; thus , it is the probability that learning is not completed until @xmath71 @xcite . in fig .",
    "[ grp : ls_prob ] , we draw @xmath84 and @xmath82 for @xmath95 by averaging over @xmath85 simulation data . in each simulation , the target state @xmath1 is randomly chosen .",
    "we find that @xmath82 is well fitted to the exponential decay function @xmath96 where @xmath87 is a characteristic constant , and @xmath97 because of the definition of the halting condition .",
    "as @xmath84 is an accumulate distribution function ( by definition ) , the average number @xmath88 of iterations to complete the ( effective ) learning process can be estimated from the characteristic constant @xmath87 as @xmath98 . in our case , we obtain @xmath90 by fitting the simulation data and thus @xmath91 with @xmath95 , whereas the actual average iteration number counted in the simulations is @xmath92 ( see tab .  [ tab : data_n ] in appendix b ) . note that @xmath87 has a finite value , which means that learning can be completed in a finite time .",
    "the identified states @xmath78 after learning are close to their target states , and @xmath99 is as small as @xmath100 on average .     versus @xmath88 ( red circles ) .",
    "we consider the fitting function @xmath101 ( green dashed line ) and find that @xmath102 and @xmath103 .",
    "( b ) @xmath104 ( red circles ) with respect to @xmath69 . in this case , the data are well fitted to @xmath105 ( green dashed line ) with @xmath106 and @xmath107 . each point in ( a ) and ( b ) is obtained by averaging @xmath85 simulation data.,title=\"fig:\",scaledwidth=23.0% ]   versus @xmath88 ( red circles ) .",
    "we consider the fitting function @xmath101 ( green dashed line ) and find that @xmath102 and @xmath103 .",
    "( b ) @xmath104 ( red circles ) with respect to @xmath69 . in this case , the data are well fitted to @xmath105 ( green dashed line ) with @xmath106 and @xmath107 . each point in ( a ) and ( b ) is obtained by averaging @xmath85 simulation data.,title=\"fig:\",scaledwidth=23.0% ]     versus @xmath88 ( red circles ) .",
    "each point is the average value of @xmath85 simulation data ; error bars indicate the standard deviation .",
    "we obtain @xmath108 by data fitting ( green dashed line).,scaledwidth=41.0% ]    for further analysis , simulations are also performed by increasing @xmath69 from @xmath109 to @xmath110 at intervals of @xmath109 . in fig .",
    "[ grp : nc_f](a ) , we plot @xmath88 with respect to @xmath69 .",
    "each point in the graph is obtained by averaging @xmath85 simulation data .",
    "the data points are very well fitted to @xmath101 with @xmath102 and @xmath103 ( for details of the fitting function , see appendix c ) .",
    "we also plot the learning error @xmath104 ( averaged over @xmath85 data ) in fig .",
    "[ grp : nc_f](b ) .",
    "the data points are also well fitted to @xmath105 , and we find @xmath106 and @xmath107 . from these results , we can see the trade - off relation between the inaccuracy ( i.e. , @xmath104 ) and the learning time ( i.e. , @xmath88 ) depending on @xmath69 . to see this more clearly , we draw the graph of @xmath104 versus @xmath88 in fig .",
    "[ grp:2n_e ] ( see appendix b ) . by data fitting , we obtain @xmath108 ( green dashed line in fig .  [ grp:2n_e ] ) .",
    "we briefly discuss that our learning protocol is secure against any other external learner ( say eve ) .",
    "one may explore large questions related to the security on the machine learning . here , we consider a specific question : ` can eve learn the quantum task originally designed by bob without being discovered ? ' to deal with this question , we consider the two scenarios .",
    "we first note that the target state @xmath1 is neither directly moved to alice nor removed from bob s side .",
    "note further that the optimized vector @xmath58 can not be viewed on alice s side after learning is complete .",
    "thus , a strategy that eve follows would be to intercept the transmitted particles in the channels @xmath111 , @xmath112 , and @xmath113 , and to learn @xmath1 or @xmath78 from the intercepted particles .",
    "eve then attempts to resend the particles of the copies instead of the stolen ones so that alice and bob would not notice it .",
    "this , often called `` intercept - and - resend attack , '' is typical scheme for breaking a qkd system .",
    "however , this is quite formidable owing to the following complications :    [ * sc.1 * ] if the qubit states transmitted through @xmath114 or @xmath115 are altered , alice immediately perceives the alterations by the measurement @xmath49 , as described above .",
    "this method of using a `` cheat - sensitive '' ( sub)system is often used in quantum cryptographic tasks .",
    "[ * sc.2 * ] even though eve can intercept the states moving through @xmath114 , @xmath116 , and @xmath115 without being discovered , it is still impossible to learn @xmath1 or @xmath78 because the intercepted particles , @xmath117 and @xmath118 , are highly mixed and indistinguishable . actually , in such case , the state of @xmath119 intercepted particles is close to the random mixture @xmath120 when @xmath121 because @xmath10 and @xmath122 are continuously changed in each trial of the learning process .",
    "[ * sc.3 * ] we finally note that learning is very sensitive to any external alteration of alice s estimation states @xmath32 transmitted in @xmath112 ( see appendix b ) . thus , even for any super - eve who can sort out @xmath32 in @xmath112 , alice can be aware of any ill - intentioned attempts by monitoring the learning time ; any alteration is indicated by learning that is too late or can not be completed , even though unexpected outcomes do not appear in @xmath49 .",
    "we then consider another scenario , called `` man - in - the - middle attack '' , where eve communicates with alice pretending to be bob , and at the same time performs the learning with bob pretending to be alice over the public channels .",
    "in such an attack , eve can guide alice s unitary device(s ) into an irrelevant task , e.g. , @xmath123 , and can extract bob s target state @xmath1 from the identified task , e.g. , @xmath124 , in the learning with bob .",
    "and @xmath125 are eve s own fiducial and target state , respectively . ]",
    "nevertheless , it is impossible for eve to learn the target task , i.e. , @xmath126 , since alice s input state @xmath0 is not opened .",
    "we thus note that in this sense eve s strategy to learn the original task designed by bob will end in failure .",
    "operation , defined by @xmath127 ( red dashed box ) in bob s side and by small change of the rule [ * p.1 * ] in alice s side ( see the main text for details).,scaledwidth=35.0% ]    however , due to the fact that eve can still maliciously interfere the learning process to separate the two legitimate parts , alice and bob , any strategy to detect a man - in - the - middle attack may be necessary . for this purpose",
    ", we can modify our protocol slightly further : first , bob mounts a safeguard , identified as a controlled operation @xmath127 , in the front of c - swap ( see fig .",
    "[ fig : protocol_mod ] ) . here",
    ", @xmath128 is an example operation of the target task , i.e. , @xmath129 .",
    ", in his side , but this advantage may be weaken in the case where the security issue becomes more important . ]",
    "then , alice changes the rule [ * p.1 * ] a bit such that , in case the reference state is @xmath61 , alice sends the state @xmath0 to bob without any altering so that the delivered state to bob is @xmath130 . in this case , bob yields the final output state @xmath131 , by applying his module , as @xmath132 where the reference state @xmath133 goes back to alice through @xmath115 . has no influence on alice s learning in the case where @xmath134 , it is easily checked that our previous analyses remain valid .",
    "] however , eve can never produce such an output @xmath131 in eq .",
    "( [ eq : out_m1 ] ) for the case where @xmath135 , because eve can not make a valid example of @xmath136 without knowing @xmath0 . in @xmath114 nor alice s state @xmath0 in @xmath116 ( see also [ * sc.1 * ] and [ * sc.2 * ] ) . ]",
    "thus , if eve intrudes into the learning , an unexpected outcome @xmath67 will appear in alice s measurement @xmath55 when @xmath135 .",
    "therefore , alice can detect a man - in - the - middle attack by monitoring whether the reference state initially prepared in @xmath61 would come back without changes ; a measures of @xmath67 may indicate the possible existence of a middle - man , eve .",
    "in summary , we presented a protocol for a quantum machine learning , where a learner ( alice ) could learn a unitary transformation corresponding to the quantum task determined by a provider ( bob ) at a distant place .",
    "we clarify here that the presented method is also applicable in the case of non - unitary task , as a general quantum process can be described by an overall unitary transformation in a quantum system composed of a main and an extra system , followed by a partial measurement . in such case",
    ", alice will learn the overall unitary with arbitrarily designed extra system and partial measurement in her side .",
    "what is more remarkable is that our protocol was designed such that an external learner can not participate in the learning process .",
    "we demonstrated by monte carlo simulations that learning can be faithfully completed for single - qubit target states , and analyzed the trade - off between the inaccuracy and the learning time .",
    "we then gave brief discussions on the security issues under the scenarios constructed by the terms of intercept - and - resend and man - in - the - middle attack .",
    "we expect that our protocol will be developed for realistic applications in quantum information and cryptography tasks .",
    "we thank professor jinhyoung lee for helpful discussion .",
    "jb thanks chang - woo lee for comments .",
    "we acknowledge the financial support of the basic science research program through a national research foundation of korea ( nrf ) grant funded by the ministry of science , ict & future planning ( no .",
    "2010 - 0018295 ) .",
    "for any given @xmath7 , we can generally define @xmath137 in eq .",
    "( [ eq : u_op ] ) , systematically constructing ( @xmath5 ) hermitian operators as follows @xcite : @xmath138 where @xmath139 and @xmath140 . here",
    ", @xmath141 is a general projector .",
    "then , the elements @xmath142 of @xmath137 can be given from the set @xmath143 , satisfying ( i ) hermiticity @xmath144 , ( ii ) traceless @xmath145 and ( iii ) orthogonality @xmath146 .",
    "the elements @xmath147 hold the relation , @xmath148 = 2i \\sum_l f_jkl \\hat{g}_l,\\end{aligned}\\ ] ] where @xmath149 is the ( antisymmetric ) structural constant of @xmath150 algebra . here ,",
    "if @xmath93 ( single qubit ) , we have pauli spin operators as @xmath151 .",
    "= 0.1 in       here we briefly note that , in a realistic application , alice should evaluate and analyze the learning time , i.e. , @xmath87 , by performing the learning with her own devices , before starting the protocol with bob .",
    "such task is carried out taking into account the errors due to the imprecise control or contaminated devices . the maximum tolerable noise in the channels",
    "should also be estimated in this stage ."
  ],
  "abstract_text": [
    "<S> the application of machine learning to quantum information processing has recently attracted keen interest , particularly for the optimization of control parameters in quantum tasks without any pre - programmed knowledge . by adapting the machine learning technique </S>",
    "<S> , we present a novel protocol in which an arbitrarily initialized device at a learner s location is taught by a provider located at a distant place . </S>",
    "<S> the protocol is designed such that any external learner who attempts to participate in or disrupt the learning process can be prohibited or noticed . </S>",
    "<S> we numerically demonstrate that our protocol works faithfully for single - qubit operation devices . a trade - off between the inaccuracy and the learning time </S>",
    "<S> is also analyzed . </S>"
  ]
}