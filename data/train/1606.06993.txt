{
  "article_text": [
    "let @xmath0 be a sample of independent , identically distributed random variables with an absolutely continuous distribution function ( cdf ) @xmath1 and density @xmath2 .",
    "the kernel estimator of @xmath1 ( kdfe ) at a point @xmath3 is @xmath4 where @xmath5 is the kernel , with @xmath6 being symmetric about the origin and integrating to unity , and @xmath7 is the bandwidth sequence which determines the degree of smoothing @xcite . the empirical distribution function ( edf ) can be obtained as a special case of with @xmath8 , viz .",
    "hereinafter kdfe will refer to with @xmath10 to distinguish it from the edf .",
    "it is well known that under very mild conditions @xmath11 is a uniformly strongly consistent and asymptotically normal estimator of @xmath1 @xcite .",
    "relative to edf , kdfe is an asymptotically more efficient estimator in the mean integrated squared error and hodges - lehmann sense @xcite .",
    "smoothness of the kernel estimates and the reduction in mise are the two main reasons to prefer kdfe .",
    "it is also reasonable to expect that replacing the edf with the kdfe will improve performance of the resultant estimators and test statistics .",
    "examples include quantile estimation @xcite and smoothed cdf - based goodness - of - fit and symmetry tests @xcite , to mention just a few scenarios wherein there are benefits to using kdfe rather than the edf or the corresponding ( kernel ) density estimators .",
    "the mean integrated squared error , @xmath12=\\operatorname{e}[\\int_{-\\infty}^{\\infty}\\{\\widehat{f}(x;h)-f(x)\\}^{2}dx]$ ] , is a commonly used global measure of performance of kdfe .",
    "the optimal bandwidth , @xmath13 , is then defined as the value minimising @xmath12 $ ] over @xmath14 . since @xmath15 and hence @xmath12 $ ] are , of course , unknown , feasible bandwidth selection methods rely either on cross - validation @xcite or an asymptotic approximation to mise ( this class includes simple rule of thumb as well as single- or multistage plug - in estimators ; see e.g. @xcite , @xcite , and @xcite )",
    ". the latter , however , may underperform in situations where the asymptotic approximation to mise is poor in finite samples .",
    "exact mise expressions derived in this paper can be used to define an alternative ` plug - in ' method of bandwidth selection which has the advantage that the optimal kernel order can be selected simultaneously ( section [ sec : bandwidth.selection ] ) .    to obtain exact finite sample mise expressions of practical interest ,",
    "it is necessary to restrict attention to specific classes of distributions and kernel functions . for the case of density estimation ,",
    "exact mise has been derived in @xcite for the normal distribution and gaussian kernel , and later extended to the class of finite normal mixture distributions and gaussian - based kernels of @xcite in @xcite , hereinafter mw , and to the class of polynomial kernels in @xcite .",
    "this paper extends the results of mw to kernel estimation of a distribution function , restricting attention to finite normal mixture ( nm ) distributions and arbitrary order gaussian - based kernels .",
    "the latter are convenient as the convolutions with normal density have explicit closed form expressions .",
    "we also find that gaussian - based kernels result in kdfe with mise very close to the infeasible minimum mise for distributions close to normal and generally perform remarkably well in very small and large samples .",
    "expressions for the exact mise components , integrated squared bias ( isb ) and integrated variance ( iv ) , are given in section [ sec : main.results ] .",
    "the proofs are given in appendix [ app : proofs ] , and alternative , computationally convenient expressions are given in appendix [ app : computational.aspects ] . for comparison ,",
    "expressions for the asymptotic mise and mise with the infinite order kernel are also given for the special case of nm distributions .",
    "a brief analysis of mise is provided in section [ sec : analysis.of.mise ] , where the comparisons are made with the empirical distribution function and the infeasible minimum mise of kernel estimators @xcite .",
    "section [ sec : bandwidth.selection ] discusses the proposed plug - in bandwidth selection method and its performance in small samples , evaluated using a simulation study .",
    "performance of the simple normal reference and silverman s rule of thumb bandwidths is discussed in appendix [ sec : nrr.bandwidth ] .",
    "section [ sec : conclusions ] concludes .",
    "in what follows @xmath16 and @xmath17 denote the standard normal density and cdf , respectively ; and @xmath18 denotes the density of a normal distribution with mean @xmath19 and variance @xmath20 .",
    "the derivatives of @xmath16 with respect to @xmath3 are denoted by @xmath21 . also let @xmath22 and @xmath23 be the first two antiderivatives of @xmath16 .",
    "the class of finite @xmath24-component normal mixture distributions considered in this paper is defined by the density function @xmath25 where for all @xmath26 , @xmath27 , @xmath28 , and @xmath29 , @xmath30 .",
    "the corresponding cdf is @xmath31 .",
    "the nm class is sufficiently large to be of practical interest as the examples in figure [ fig : mwnmdens1 - 15 ] demonstrate ; see also examples in e.g. @xcite .",
    "the results derived in this paper can be used to study the finite sample performance of kernel estimators of a broad variety of distribution functions well approximated by normal mixtures .",
    "one important exception which will require separate treatment is the class of distributions on the bounded support with non - zero densities at the boundaries",
    ".    of course , if the true density is of the form , better estimators of @xmath1 than may exist .",
    "however , the purpose of this paper is not to analyse such estimators , but rather to provide a tool which can usefully complement asymptotic analysis and simulation studies .",
    "nevertheless , as shown in section [ sec : bandwidth.selection ] , even when when the true distribution is known to be the normal mixture , and even when the true number of mixture components is known , smoothed estimators can have a significantly smaller mise than parametric normal mixture cdf estimators .      for @xmath32 , the @xmath33 order gaussian - based kernels for density estimation @xcite are given by @xmath34 the corresponding gaussian - based kernels of order @xmath35 for estimation of a distribution function are obtained by integrating @xmath36 , viz .",
    "@xmath37 kernels @xmath38 are of the form @xmath39 , where @xmath40 are polynomials in @xmath3 ; for example , @xmath41 , @xmath42 , @xmath43 , and @xmath44 . when @xmath45 is large , expression in appendix [ app : computational.aspects ] can be used to compute the terms @xmath46 recursively .    to obtain the limiting kernel as @xmath47 ,",
    "let @xmath48 and @xmath49 , and for @xmath50 , define the rescaled kernels as @xmath51 then the corresponding infinite order kernels are @xmath52 , where @xmath53 for @xmath54 and @xmath55 is the cardinal sine function ( see e.g. ( * ? ?",
    "* thm.3 ) ) .",
    "thus we can define @xmath56 , where @xmath57 is the sine integral @xcite .",
    "the rescaling is only necessary to obtain the limiting kernel ; it has no effect on mise computations for a finite @xmath45 as the results for @xmath58 can be obtained from those for @xmath59 by rescaling the bandwidth @xmath60 .",
    "since kernels @xmath59 of order greater than two are not monotone ( kernels @xmath36 take negative values ) , the resultant estimates may not themselves be distribution functions .",
    "however , if necessary , the estimates can be corrected by rearrangement @xcite or the methods described in @xcite .",
    "the rearrangement ( which is effectively sorting ) is particularly simple to use , and the mise of the rearranged estimator can be at most equal to , and is often strictly smaller than the mise of the original estimator .",
    "let @xmath61 denote the kernel estimator of the distribution function @xmath1 using the @xmath33 order kernel , and let @xmath62=\\int_{-\\infty}^{\\infty}\\{\\operatorname{e}[\\widehat{f}_{2r}(x;h)]-f(x)\\}^{2}dx$ ] and @xmath63 = \\int_{-\\infty}^{\\infty}\\operatorname{var}[\\widehat{f}_{2r}(x;h)]dx$ ] be the integrated squared bias and integrated variance , respectively ; @xmath64=\\operatorname{isb}[\\widehat{f}_{2r}(\\cdot;h)]+\\operatorname{iv}[\\widehat{f}_{2r}(\\cdot;h)]$ ] .",
    "let @xmath65 denote the odd factorial , i.e. for @xmath66 , @xmath67 , @xmath68 , @xmath69 , and for @xmath70 odd , @xmath71 .",
    "[ thm : exact.mise ] ( exact mise ) + let @xmath0 be a random sample from a normal mixture distribution , and @xmath72 be the @xmath33-order gaussian - based kernel .",
    "then for @xmath10 , @xmath32 , @xmath73    =   -\\sum_{s=0}^{r-1}\\sum_{t=0}^{r-1}\\frac{(-1)^{s+t}}{2^{s+t}s!t!}v(h;s+t,2 ) + 2\\sum_{s=0}^{r-1}\\frac{(-1)^{s}}{2^{s}s!}v(h;s,1 ) - v(h;0,0),\\ ] ] @xmath74   = -\\frac{h}{n\\sqrt{\\pi}}c(r ) + \\frac{1}{n}\\sum_{s=0}^{r-1}\\sum_{t=0}^{r-1}\\frac{(-1)^{s+t}}{2^{s+t}s!t!}v(h;s+t,2),\\ ] ] where @xmath75 @xmath76 , and @xmath77 where @xmath78 denotes the regularized incomplete beta function and it is understood that the sum over @xmath79 in is zero when @xmath80 . @xmath81    the proof of the theorem , given in appendix [ app : proofs ] , is based on the convolution formulae in @xcite which apply after a judiciously chosen change of coordinates .",
    "alternative , computationally convenient expressions for @xmath82 and @xmath64 $ ] are given in appendix [ app : computational.aspects ] .",
    "all the quantities can be computed recursively , which is particularly useful when @xmath45 is large .",
    "the only special function that needs to be evaluated is the standard normal cdf .",
    "the minimiser of mise , @xmath83 , can be obtained by standard numerical optimisation techniques with the caveat that there may be multiple local minima .",
    "( existence of the global minimiser @xmath84 $ ] follows from theorem 1 in @xcite ) .",
    "calculations reported in section [ sec : analysis.of.mise ] were performed by first obtaining the optimal bandwidth for the second order kernel and then using it as the starting value for @xmath85 , and so on .",
    "a special case of theorem [ thm : exact.mise ] worth stating separately is the second order gaussian kernel which is commonly used in practice .",
    "since @xmath86 , with @xmath80 the expressions simplify to @xmath87   =   -u(h;2 ) + 2u(h;1 ) - u(h;0)$ ] and @xmath88 =   -n^{-1}h\\pi^{-1/2 } + n^{-1}u(h;2)$ ] , where @xmath89.\\ ] ] expressions in theorem [ thm : exact.mise ] are also valid with @xmath8 , which corresponds to the edf . in this case",
    "@xmath90 , where @xmath91    = \\int_{-\\infty}^{\\infty}f(x)\\left[1-f(x)\\right]dx,\\ ] ] and we recover the well - known result that @xmath92   = 0 $ ] and @xmath93 = n^{-1}v_{0}$ ] .",
    "the constant @xmath82 depends on the kernel only via the quantity @xmath94 .",
    "it is evident from that for gaussian kernels @xmath95 for all @xmath32 , and this property implies that asymptotically the kdfe @xmath61 provides a second order improvement in mise relative to edf ( via the second term in ) . as @xmath47 , @xmath96 ( appendix [ app : proofs ] ) , and in particular , @xmath97 as @xmath47 ( cf .",
    "second term in ) .",
    "let @xmath6 be a general symmetric @xmath33 order kernel , i.e. @xmath6 satisfies @xmath98 , @xmath99 for @xmath100 , and @xmath101 , where @xmath102 . then , under the standard smoothness and integrability conditions on @xmath1 which are satisfied by nm distributions , as @xmath103 , @xmath104 = \\frac{1}{n}v_{0}-\\frac{h}{n}\\psi_{1}(k)+\\frac{\\mu_{2r}(k)^{2}}{(2r)!^{2}}r(f^{(2r)})h^{4r}+o(hn^{-1}+h^{4r}),\\ ] ] where @xmath105 .",
    "for the nm distribution and gaussian - based kernel @xmath59 , @xmath106 @xmath107 , and @xmath108 .",
    "thus , the asymptotically optimal bandwidth is @xmath109      exact mise of a kdfe with the sinc kernel has been derived in @xcite and @xcite . for the nm distribution",
    "the absolute square of the characteristic function is @xmath110\\mathrm{e}^{-(\\sigma_{i}^{2}+\\sigma_{j}^{2})t^{2}/2}$ ] .",
    "thus , the mise is @xmath111   = \\frac{1}{n}v_{0 } -\\frac{h}{n\\pi } + \\frac{1}{\\pi}\\left(1+\\frac{1}{n}\\right ) \\sum_{i=1}^{m}\\sum_{j=1}^{m}w_{i}w_{j}j(h;\\mu_{i}-\\mu_{j},\\bar{\\sigma}_{ij } ) , \\ ] ] where @xmath112 is defined in , @xmath113 , and @xmath114 . whenever @xmath115 , the integral in can be computed as @xmath116 $ ] .",
    "otherwise , numerical integration techniques such as the gauss - kronrod quadrature can be used to evaluate @xmath117 .",
    "the optimal bandwidth solves @xmath118 . for the normal distribution",
    "the solution is @xmath119 . in general , however , there does not appear to be a way of obtaining a closed form solution for @xmath13 , and it has to be found using numerical techniques with the caveat that the solution may not be unique ( existence of a global minimiser of has been established in ( * ? ? ?",
    "* thm.3 ) ) ; see also related discussion in @xcite .",
    "this section provides a brief analysis of mise using the fifteen nm distributions shown in figure [ fig : mwnmdens1 - 15 ] as examples ( see table 1 of mw for the definitions of these mixtures ) .",
    "since mise itself is not a unitless quantity , it is natural to perform comparisons relative to the mise of the edf ; hereinafter the relative mise , in percentages .",
    "indeed , if mise of a kernel estimator is larger than that of the edf , kdfe loses much of its appeal , even though a case can still be made for the benefits offered by smoothness alone .",
    "on the other hand , if an estimator achieves ( or is reasonably close to ) the infeasible minimum mise , @xmath120^{-1}dt\\ ] ] ( * ? ? ? * proposition 2 ) , one can be satisfied that no further improvements are possible ( or are of practical interest ) .",
    "relative @xmath121 is shown as dashed lines in figure [ fig : reloptmise.1 ] ( left vertical axes ) .",
    "one immediate observation to be made is that for some distributions the best achievable reduction in mise is quite small ; e.g. for distributions # 3&4 and sample sizes more than about one thousand , no more than 2 - 3% reduction is possible . nonetheless , for the small sample sizes the available improvement in mise is substantial .",
    "of course , any such improvement comes from a decrease in variance at the cost of introducing a non - zero bias .",
    "[ cols=\"^,^,^ \" , ]     the @xmath122 ( solid line , right vertical axes ) and @xmath123 ( solid line , left vertical axes ) in figure [ fig : reloptmise.1 ] show the optimal @xmath45 and the resultant relative mise for the class of gaussian - based kernels of order @xmath35 .",
    "optimisation was performed over @xmath14 for a given @xmath45 and then over @xmath124 for a sufficiently large pre - specified @xmath125 . the kernel order necessary to achieve the best mise generally increases with the sample size , but",
    "not necessarily in a monotone fashion .    for the relatively ` uninteresting ' , i.e. close to normal distributions ( # 15 ) , the gaussian - based kernels offer performance remarkably close to the best achievable ( infeasible ) mise ; the largest difference ( shown by dimension lines ) is less than 1% for the gaussian and skewed unimodal distributions , and between 2.7 and 4.5% for the strongly skewed , kurtotic unimodal and outlier distributions . for distributions with more complicated features ( # 615 )",
    "the differences can be as large as 10 - 20% at the sample sizes of practical interest .",
    "@>c@@>c@@>c@ # 1 : gaussian & # 2 : skewed unimodal & # 3 : strongly skewed +   &   &   + # 4 : kurtotic unimodal & # 5 : outlier & # 6 : bimodal +   &   &   +    legend : horizontal axes : common logarithm of the sample size , @xmath126 .",
    "+ right vertical axes : @xmath127 , optimal @xmath45 , integer @xmath128 .",
    "+ left vertical axes , % : @xmath80 , @xmath129 , and @xmath123minimum relative @xmath130 with 2^nd^ ( @xmath80 ) , infinite , and optimal ( @xmath123 ) order kernels , respectively ; @xmath121minimum achievable relative mise ( infeasible ) .",
    "@>c@@>c@@>c@ # 7 : separated bimodal & # 8 : skewed bimodal & # 9 : trimodal +   &   &   + # 10 : claw & # 11 : double claw & # 12 : asymmetric claw +   &   &   + # 13 : asymmetric double claw & # 14 : smooth comb & # 15 : discrete comb +   &   &   +    there is little surprising about the performance of the second ( @xmath80 ) and infinite ( @xmath129 ) order kernels .",
    "the former performs well for small @xmath70 , but as the bandwidth converges to zero at the fastest rate , the mise of the kdfe quickly approaches that of the edf . in contradistinction , the sinc kernel is expected to deliver best results as the sample size approaches infinity , but underperforms for finite @xmath70 thus rendering its practical usefulness questionable unless the sample size is very large .",
    "importantly , for distributions # 1,2,5 , which are close to normal , the benefits of using higher order kernels are realized for sample sizes as small as 10 observations ( for the gaussian distribution the @xmath131 order kernel becomes optimal when @xmath132 ) .",
    "the benefits are still clear for distributions # 3,4,69 , albeit higher order kernels become optimal at sample sizes of around 1000 . for the remaining distributions ( # 1015 )",
    "the picture is less clear .",
    "while the optimal @xmath45 is bigger than one over a range of sample sizes , the reduction in mise it confers is either too small to matter in practice or occurs over a limited range of sample sizes ( which , of course , would not be known a priori ) .",
    "finally , the optimal @xmath45 if one were to use the asymptotically optimal bandwidth @xmath133 instead of the exact mise - minimising bandwidth also increases with the sample size , but monotone and much slower ( results omitted from figure [ fig : reloptmise.1 ] for better readability ) .",
    "the corresponding relative mise is always bigger than mise with @xmath83 and @xmath122 , and usually much bigger in small and medium size samples illustrating the fact that the choice of the asymptotic bandwidth may lead to poor performance .",
    "interesting exceptions occur with distributions # 1,2,5 ( and less so with # 6 and 8) , where in sample sizes less than about 20 the asymptotically optimal bandwidth delivers results almost as good as the exact mise - minimising bandwidth .",
    "exact mise results for nm distributions lend themselves naturally to the possibility of estimating the optimal bandwidth _ and _ kernel order by parametrically fitting a finite normal mixture distribution to the data and plugging this preliminary estimate into the exact mise expression which can then be minimised over @xmath60 and @xmath45 .",
    "the main competitor of the proposed nm plug - in approach is the cross - validation ( cv ) bandwidth of @xcite which directly minimises an estimate of mise .",
    "( cv criterion is an unbiased estimator of mise for sample size @xmath134 , up to an additive constant which does not depend on @xmath60 ) .",
    "cv approach performs well in simulations and has the advantage that it does not require any preliminary estimates .",
    "however , it does not provide a way to select the optimal kernel order .    in contradistinction ,",
    "the nm plug - in approach yields estimates of @xmath60 and @xmath45 , and thus can be expected to outcompete cv in cases where higher order kernels provide a substantial improvement in mise and the underlying distribution can be well approximated by a finite normal mixture .",
    "the presence of the approximation error and the need to fit a mixture distribution , including determining the number of components , are the main drawbacks of the proposed procedure .    in the remainder of this section the performance of the nm plug - in approach",
    "is assessed via a simulation study using the same fifteen nm distributions as in section [ sec : analysis.of.mise ] ( figure [ fig : mwnmdens1 - 15 ] ) and three non - nm distributions : a gamma(2,1 ) distribution ( cf .",
    "* ) and student s @xmath135 distributions with @xmath136 and @xmath137 degrees of freedom .    at a preliminary stage ,",
    "an @xmath24-component normal mixture distribution is fitted to the data using the expectation maximization ( em ) algorithm ( see e.g. * ? ? ?",
    "* ) with the number of components chosen  by the akaike ( aic ) and bayesian ( bic ) information criteria .",
    "the resultant estimates of @xmath24 are denoted by @xmath138 and @xmath139 , respectively .",
    "there is considerable evidence that supports the use of bic to select the number of components . in particular",
    ", @xcite showed that if the goal is to estimate a density @xmath140 by a univariate normal mixture , choosing @xmath24 by bic yields a consistent estimator of @xmath140 ; see also ( * ? ? ?",
    "* sec.6.9.3 ) , @xcite , and references therein . for the nm distributions , the true number of components , @xmath141 , is also included for comparison .    at the main stage , the preliminary estimate @xmath142 is treated",
    "as if it were the known true nm distribution to find the optimal bandwidth , @xmath143 , and kernel order , @xmath144 , by minimising the exact mise expression . as in section",
    "[ sec : analysis.of.mise ] , optimisation was performed over @xmath145 , where guided by the results presented in figure [ fig : reloptmise.1 ] , @xmath125 was set to 8 , 9 , 10 , and 13 for sample sizes 50 , 100 , 200 , and 400 , respectively .",
    "performance of the resultant kdfe , @xmath146 , is evaluated by its integrated squared error , @xmath147=\\int_{-\\infty}^{\\infty}\\{\\widehat{f}(x;\\hat{h})-f(x)\\}^{2}dx$ ] .",
    "comparisons are also made with the case where @xmath45 is set to 1 and only the bandwidth is estimated .",
    "cv bandwidth is also computed for the second order kernel only as there is no clear way to choose optimal @xmath45 in this case .",
    "simulation results are reported in table [ tab : bw.relmise.and.pairwise.t.tests ] . in all cases these",
    "are based on 10,000 random draws .",
    "the columns correspond to different combinations of @xmath45 and @xmath24 used to construct @xmath146 .",
    "these are compared to the edf and kdfe with cv bandwidth .",
    "the last six columns correspond to comparisons between the kdfe and the parametrically fitted @xmath24-component nm distribution with the same choice of the number of components ( the preliminary estimate ) .",
    "the entries in the table show the relative reduction in mise of kdfe versus the benchmark , in percentages ( positive entries  shown in italics  correspond to cases where kdfe performs worse than the benchmark ) . for comparison , column lb ( lower bound ) reproduces the best achievable reduction in mise of kdfe relative to edf obtainable with the optimal order gaussian - based kernel when @xmath1 is known and the infeasible exact mise - minimising bandwidth is used ( line @xmath123 in figure [ fig : reloptmise.1 ] , minus 100 ) .",
    "l|rrrrrrrr|rrrr|rrrrrr & lb & 1 , @xmath141&1 , @xmath138&1 , @xmath139 & cv & @xmath144 , @xmath141&@xmath144 , @xmath138&@xmath144 , @xmath139 & 1 , @xmath138&1 , @xmath139&@xmath144 , @xmath138&@xmath144 , @xmath139 & 1 , @xmath141&1 , @xmath138&1 , @xmath139 & @xmath144 , @xmath141&@xmath144 , @xmath138&@xmath144 , @xmath139 + & & & with the same @xmath148 +   + 50&-30.13&-22.41&-20.46&-21.96&-19.82&-26.93&-22.53&*-26.06*&-0.80&-2.67&-3.38&*-7.79*&_23.80_&-0.03  * * & _ 19.74_&_16.60_&-2.64&_13.44 _ + 100&-27.55&-19.11&-17.89&-19.02&-17.35&-25.61&-21.76&*-25.35*&-0.65&-2.02&-5.34&*-9.68*&_28.48_&_5.58_&_26.90_&_18.16_&_0.61 _  * * & _ 16.98 _ + 200&-25.47&-15.71&-15.01&-15.67&-14.51&-23.89&-20.68&*-23.75*&-0.59&-1.36&-7.22&*-10.81*&_34.36_&_12.52_&_33.46_&_21.32_&_5.02_&_20.68 _ + 400&-23.77&-12.67&-12.30&-12.67&-11.85&-22.75&-20.26&*-22.73*&-0.51&-0.92&-9.54&*-12.34*&_38.80_&_19.63_&_38.65_&_22.78_&_8.77_&_22.67 _ +   + 50&-25.58&-18.27&-17.93&*-17.95*&-17.49&-18.16&-17.35&-17.32&-0.52&*-0.55*&_0.17 _  * * & _ 0.21 _  * * & -10.67&-11.65&-15.24&-10.55&-11.03&-14.59 + 100&-22.77&-15.79&-15.52&-15.39&-15.27&-16.65&*-15.91*&-14.51&-0.29&-0.14&*-0.76*&_0.90_&-7.01&-10.13&-25.55&-7.95&-10.55&-24.77 + 200&-20.54&-13.15&-12.96&-12.85&-12.57&-15.54&*-15.27*&-13.94&-0.44&-0.32&*-3.09*&-1.56&-2.81&-3.44&-28.01&-5.48&-6.00&-28.91 + 400&-18.81&-11.25&-11.25&-11.44&-10.97&-15.03&-15.21&*-16.17*&-0.31&-0.53&-4.76&*-5.85*&_0.50_&_2.21_&-5.34&-3.78&-2.35&-10.40 +   + 50&-8.64&-6.78&*-6.22*&-6.12&-5.17&-6.78&-6.18&-5.77&*-1.11*&-1.00&-1.06&-0.63&-4.36&-5.91&-16.12&-4.36&-5.87&-15.81 + 100&-6.36&-5.31&*-4.82*&-4.75&-4.41&-5.31&-4.82&-4.51&*-0.43*&-0.36&-0.43&-0.10&-2.94&-4.37&-17.40&-2.94&-4.37&-17.19 + 200&-4.79&-3.84&-3.98&*-3.99*&-3.83&-3.84&-3.98&-3.87&-0.16&*-0.16*&-0.16&-0.04&-1.71&-3.41&-15.06&-1.71&-3.41&-14.96 + 400&-3.68&-3.32&*-3.16*&-3.16&-3.09&-3.32&-3.15&-2.95&*-0.08*&-0.08&-0.07&_0.14_&-0.64&-2.07&-14.89&-0.63&-2.06&-14.70 +   + 50&-9.25&-1.57&*-4.60*&_0.29 _  * * & -3.01&_0.39 _  * * & -3.93&_4.85_&*-1.64*&_3.40_&-0.95&_8.11_&_12.37_&_5.87_&_6.80_&_14.61_&_6.61_&_11.66 _ + 100&-6.99&-3.41&*-4.81*&-4.06&-4.26&-2.19&-4.73&-3.17&*-0.57*&_0.21_&-0.49&_1.14_&_24.71_&_10.48_&_24.59_&_26.29_&_10.57_&_25.74 _ + 200&-5.42&-4.20&-4.24&*-4.26*&-4.04&-4.04&-4.15&-4.16&-0.20&*-0.22*&-0.11&-0.12&_32.28_&_14.45_&_32.01_&_32.50_&_14.56_&_32.14 _ + 400&-4.26&-3.54&-3.52&*-3.54*&-3.45&-2.42&-2.55&-2.42&-0.08&*-0.10*&_0.93_&_1.06_&_33.11_&_17.18_&_32.74_&_34.66_&_18.36_&_34.28 _ +   + 50&-14.32&-8.86&-9.11&*-9.40*&-9.32&-10.91&-4.93&-5.94&_0.22 _  * * & * -0.10 *  * * & _ 4.84_&_3.72_&_19.82_&-12.03&-6.89&_17.13_&-7.98&-3.34 + 100&-12.97&-9.03&-8.59&-8.93&-8.25&-11.57&-9.84&*-11.16*&-0.37&-0.74&-1.73&*-3.16*&_22.81_&_8.64_&_20.17_&_19.38_&_7.16_&_17.23 _ + 200&-11.92&-7.69&-7.44&-7.68&-7.19&-10.95&-9.77&*-10.91*&-0.28&-0.53&-2.79&*-4.02*&_25.78_&_12.97_&_25.23_&_21.33_&_10.13_&_20.84 _ + 400&-11.09&-6.32&-6.17&-6.31&-5.96&-10.51&-9.56&*-10.50*&-0.22&-0.37&-3.82&*-4.82*&_28.81_&_17.07_&_28.60_&_23.04_&_12.84_&_22.86",
    "_ +   + 50&-22.66&-20.05&-19.08&*-19.78*&-19.47&-19.45&-18.28&-16.92&_0.48_&*-0.38*&_1.49_&_3.17_&-9.00&-15.77&-20.73&-8.32&-14.93&-17.91 + 100&-18.25&-16.65&-15.93&*-16.47*&-15.99&-15.63&-14.99&-10.24&_0.07 _  * * & * -0.57*&_1.19_&_6.84_&-4.59&-9.70&-25.58&-3.43&-8.69&-20.03 + 200&-15.15&-13.70&-13.26&*-13.67*&-13.11&-13.21&-12.66&-11.14&-0.16&*-0.64*&_0.52_&_2.28_&_0.28 _  * * & -3.66&-11.10&_0.85_&-3.00&-8.49 + 400&-13.24&-11.09&-10.83&-11.08&-10.65&-11.30&-10.71&*-11.26*&-0.21&-0.49&-0.07  * * & * -0.69*&_4.14_&_0.45_&_3.94_&_3.89_&_0.59_&_3.73 _ +   +   +    l|rrrrrrrr|rrrr|rrrrrr & lb & 1 , @xmath141&1 , @xmath138&1 , @xmath139 & cv & @xmath144 , @xmath141&@xmath144 , @xmath138&@xmath144 , @xmath139 & 1 , @xmath138&1 , @xmath139&@xmath144 , @xmath138&@xmath144 , @xmath139 & 1 , @xmath141&1 , @xmath138&1 , @xmath139 & @xmath144 , @xmath141&@xmath144 , @xmath138&@xmath144 , @xmath139 + & & & with the same @xmath148 +   + 50&-11.51&-10.46&-9.94&*-10.34*&-9.90&-10.39&-9.91&-10.28&-0.04  * * & * -0.49*&-0.01  * * & -0.42&_0.30_&-4.01&-0.40&_0.37_&-3.97&-0.32 + 100&-9.87&-8.67&-8.35&-8.64&-8.25&-9.54&-8.60&*-9.46*&-0.11&-0.42&-0.38&*-1.32*&_3.11_&-1.46&_2.82_&_2.13_&-1.73&_1.88 _ + 200&-8.85&-6.96&-6.77&-6.95&-6.66&-8.41&-7.63&*-8.38*&-0.12&-0.32&-1.04&*-1.85*&_4.96_&_0.78_&_4.86_&_3.32_&-0.15&_3.25 _ + 400&-8.03&-5.74&-5.65&-5.73&-5.53&-7.72&-7.22&*-7.71*&-0.13&-0.21&-1.78&*-2.30*&_6.59_&_2.99_&_6.55_&_4.35_&_1.29_&_4.31",
    "_ +   + 50&-22.16&-19.32&-18.43&*-18.95*&-18.62&-18.75&-17.91&-17.50&_0.23_&*-0.41*&_0.87_&_1.37_&-8.73&-14.47&-17.69&-8.09&-13.92&-16.22 + 100&-17.55&-15.79&-15.15&*-15.49*&-15.20&-14.80&-14.32&-11.00&_0.05 _  * * & * -0.34*&_1.03_&_4.95_&-3.06&-9.02&-23.05&-1.92&-8.14&-18.97 + 200&-13.93&-12.61&-12.28&*-12.55*&-12.22&-11.68&-11.59&-9.49&-0.07  * * & * -0.38*&_0.71_&_3.11_&_3.86_&-1.86&-10.99&_4.97_&-1.08&-7.88 + 400&-11.20&-10.30&-10.14&*-10.30*&-10.00&-9.69&-9.59&-9.59&-0.16&*-0.34*&_0.45_&_0.45_&_9.34_&_3.81_&_8.53_&_10.08_&_4.44_&_9.38 _ +   + 50&-21.32&-18.19&-17.92&*-18.64*&-18.54&-17.80&-17.34&-14.97&_0.77_&*-0.12 *  * * & _ 1.48_&_4.39_&-12.25&-14.89&-24.08&-11.84&-14.29&-20.66 + 100&-16.84&-15.06&-14.80&*-15.45*&-15.03&-14.67&-14.29&-11.20&_0.27_&*-0.50*&_0.88_&_4.51_&-8.79&-10.51&-22.78&-8.37&-9.96&-18.89 + 200&-13.30&-12.09&-11.89&*-12.30*&-11.81&-11.72&-11.33&-10.78&-0.09&*-0.55*&_0.54_&_1.17_&-4.91&-7.38&-11.12&-4.50&-6.79&-9.58 + 400&-10.62&-9.89&-9.76&*-9.94*&-9.64&-9.50&-9.19&-7.61&-0.13&*-0.33*&_0.50_&_2.25_&-2.10&-4.97&-12.71&-1.67&-4.37&-10.45 +   + 50&-24.28&-11.82&-15.49&-17.11&-16.33&-11.82&-16.20&*-19.41*&_1.01_&-0.93&_0.16 _  * * & * -3.67*&-12.04&-8.88&_2.27_&-12.04&-9.65&-0.56  * * + 100&-15.71&-9.28&-9.80&-11.07&-10.34&-9.20&-9.80&*-11.81*&_0.61_&-0.80&_0.61_&*-1.63*&-8.71&-8.15&-1.79&-8.63&-8.15&-2.61 + 200&-7.30&-6.05&*-5.80*&-3.52&-5.23&-5.88&-5.30&_0.86_&*-0.60*&_1.80_&-0.07  * * & _ 6.43_&-7.91&-7.05&-12.24&-7.75&-6.56&-8.26 + 400&-5.36&-3.87&*-4.52*&_2.12_&_3.71 _  * * & -3.66&-4.31&_13.05_&*-7.94 *  * * & -1.53  * * & -7.74  * * & _ 9.01 _  * * & -10.95&-4.90&-25.23&-10.76&-4.69&-17.23 +   + 50&-22.67&-18.05&-18.72&*-19.56*&-19.27&-17.67&-18.08&-16.90&_0.68_&*-0.36*&_1.48_&_2.94_&-16.09&-15.44&-20.26&-15.70&-14.77&-17.62 + 100&-18.24&-15.45&-15.93&*-16.60*&-16.12&-15.02&-14.97&-10.32&_0.23_&*-0.57*&_1.38_&_6.92_&-12.91&-10.12&-26.18&-12.47&-9.10&-20.62 + 200&-15.13&-12.31&-13.23&*-13.70*&-13.14&-11.98&-12.67&-11.26&-0.10&*-0.64*&_0.54_&_2.17_&-9.55&-3.99&-11.37&-9.21&-3.37&-8.86 + 400&-13.18&-10.22&-10.63&-10.90&-10.44&-10.07&-10.47&*-11.02*&-0.22&-0.51&-0.04  * * & * -0.65*&-6.20&_0.12 _  * * & _ 3.79_&-6.04&_0.30_&_3.64 _ +   + 50&-25.13&-16.03&-16.87&-18.38&-16.77&-15.93&-16.64&*-19.65*&-0.12  * * & -1.94&_0.16 _  * * & * -3.47*&-13.10&-13.97&-10.14&-13.00&-13.73&-11.54 + 100&-17.76&-11.92&-12.41&-12.92&-12.00&-11.70&-12.04&*-12.94*&-0.47&-1.04&-0.04  * * & * -1.07*&-9.37&-12.26&-21.44&-9.14&-11.89&-21.46 + 200&-10.43&-9.13&*-8.86*&-8.08&-8.83&-8.91&-8.50&-4.66&*-0.04 *  * * & _ 0.83_&_0.36_&_4.58_&-6.66&-8.28&-32.07&-6.43&-7.92&-29.54 + 400&-7.33&-6.49&-6.52&-4.80&*-6.53*&-6.27&-6.36&_0.85_&_0.00 _  * * & _ 1.85_&_0.18_&_7.90_&-6.06&-4.97&-27.29&-5.83&-4.81&-22.98 +   +   +    l|rrrrrrrr|rrrr|rrrrrr & lb & 1 , @xmath141&1 , @xmath138&1 , @xmath139 & cv & @xmath144 , @xmath141&@xmath144 , @xmath138&@xmath144 , @xmath139 & 1 , @xmath138&1 , @xmath139&@xmath144 , @xmath138&@xmath144 , @xmath139 & 1 , @xmath141&1 , @xmath138&1 , @xmath139 & @xmath144 , @xmath141&@xmath144 , @xmath138&@xmath144 , @xmath139 + & & & with the same @xmath148 +   + 50&-21.73&-16.79&-18.08&*-18.74*&-18.50&-16.42&-17.31&-15.18&_0.52_&*-0.29*&_1.45_&_4.07_&-15.11&-15.11&-21.88&-14.74&-14.32&-18.46 + 100&-17.22&-14.49&-14.86&*-15.51*&-15.08&-14.19&-14.07&-9.29&_0.26_&*-0.51*&_1.19_&_6.81_&-11.79&-9.14&-24.37&-11.47&-8.30&-18.80 + 200&-13.72&-11.17&-11.84&*-12.41*&-11.83&-10.96&-11.23&-10.38&-0.02  * * & * -0.66*&_0.67_&_1.64_&-8.49&-3.88&-6.49&-8.27&-3.21&-4.33 + 400&-11.29&-9.08&-9.29&*-9.62*&-9.13&-8.82&-9.00&-9.58&-0.17&*-0.54*&_0.15 _  * * & -0.49&-5.67&-0.76&_3.52_&-5.40&-0.44&_3.57 _ +   + 50&-9.41&-8.16&-7.83&*-8.04*&-7.52&-8.16&-7.83&-8.02&-0.33&*-0.56*&-0.33&-0.54&-5.66&-5.20&-5.47&-5.66&-5.19&-5.45 + 100&-6.64&-6.10&-5.98&*-6.12*&-5.92&-6.09&-5.96&-6.03&-0.06&*-0.21*&-0.04  * * & -0.11&-3.54&-3.16&-2.14&-3.52&-3.15&-2.04 + 200&-4.70&-4.62&-4.44&*-4.48*&-4.42&-4.62&-4.39&-4.25&-0.02  * * & * -0.05*&_0.03_&_0.18_&-1.70&-1.38&-0.51&-1.69&-1.34&-0.27 + 400&-3.34&-3.29&*-3.24*&-3.24&-3.24&-3.23&-3.23&-3.08&*-0.01 *  * * & -0.00  * * & _ 0.01 _  * * & _ 0.16_&-0.67&_0.21_&_1.33_&-0.62&_0.23_&_1.49 _ +   + 50&-8.15&-6.79&*-7.12*&-7.07&-7.04&-6.79&-7.12&-6.99&*-0.09*&-0.03  * * & -0.09&_0.05 _  * * & -4.86&-4.87&-7.38&-4.86&-4.87&-7.30 + 100&-6.03&-5.49&-5.43&*-5.58*&-5.47&-5.49&-5.43&-5.58&_0.04_&*-0.11*&_0.04_&-0.11&-2.99&-2.91&-3.00&-2.99&-2.91&-3.00 + 200&-4.33&-4.17&-4.06&*-4.14*&-4.02&-4.16&-4.00&-3.84&-0.04&*-0.12*&_0.02_&_0.19_&-1.61&-1.56&-0.30&-1.59&-1.50&_0.01 _  * * + 400&-2.95&-2.78&*-2.86*&-2.80&-2.82&-2.55&-2.78&-2.62&*-0.03*&_0.02_&_0.05_&_0.22_&-1.27&-0.67&_0.02 _  * * & -1.03&-0.59&_0.21 _ +   +   +   +   + 50 & &  &",
    "* -15.41*&-15.28&-15.36 &  & -14.12&-11.30&*-0.06 *  * * & _ 0.09 _  * * & _ 1.47_&_4.80 _ & & & & & & + 100 & &  & -12.43&*-12.75*&-12.30 &  & -11.74&-10.89&-0.14  * * & * -0.50*&_0.65_&_1.61 _ & & & & & & + 200 & &  & -10.75&*-11.10*&-10.88 &  & -10.23&-10.07&_0.15_&*-0.25*&_0.73_&_0.91 _ & & & & & & + 400 & &  & -9.07&*-9.33*&-9.20 &  & -8.63&-8.95&_0.15_&*-0.14*&_0.63_&_0.28 _ & & & & & & +   + 50 & &  & -10.86&-10.02&*-14.16 * &  & -4.61&-1.66  * * & _ 3.84_&_4.82_&_11.12_&_14.56 _ & & & & & & + 100 & &  & -10.62&-10.07&*-12.15 * &  & -5.04&-1.95  * * & _ 1.74_&_2.36_&_8.09_&_11.61 _ & & & & & & + 200 & &  & -10.10&-10.07&*-10.46 * &  & -8.22&-7.03&_0.40 _  * * & _ 0.44_&_2.51_&_3.84 _ & & & & & & + 400 & &  & -8.95&-9.01&-8.98 &  & * -9.51*&-8.70&_0.03 _  * * & -0.03  * * & * -0.58 *  * * & _ 0.31 _  * * & & & & & & +   + 50 & &  & -14.32&-13.99&*-15.51 * &  & -11.71&-10.31&_1.40_&_1.80_&_4.50_&_6.15 _ & & & & & & + 100 & &  & -12.87&-12.33&*-13.41 * &  & -10.87&-7.91&_0.62_&_1.25_&_2.94_&_6.36 _ & & & & & & + 200 & &  & -11.60&-11.38&-11.68 &  & * -11.87*&-9.57&_0.09 _  * * & _ 0.34_&*-0.21 *  * * & _ 2.39 _ & & & & & & + 400 & &  & -9.86&-9.93&-9.87 &  & * -11.08*&-10.96&_0.02 _  * * & -0.06  * * & * -1.33 *  * * & -1.20  * * & & & & & & +   +   +    two - sided paired @xmath135-tests for equality of the considered ise means were also performed . in the majority of cases",
    "the mean of ise differences is significantly different from zero at less than 1% , and hence only those cases where p - values are more than 1% are highlighted (  if p - value is between 1 and 5% ,  if p - value is more than 5% ) .",
    "with very few exceptions , all considered methods of bandwidth selection result in estimators with significantly smaller mise than edf , and the reduction in mise achieved by the best out of the feasible estimators ( emphasised in bold ) is very close to lb .",
    "exceptions occur for distribution # 4 with @xmath149 and # 10 with @xmath150 ; for student s @xmath151 distribution with @xmath152 the method selecting the bandwidth and @xmath144 based on @xmath139 improves on edf slightly , but not significantly so .",
    "another immediate observation is that for nm distributions , with the exception of # 12 with @xmath153 , cv is never the best method .",
    "cv does outperform other methods for the student s @xmath135 distributions in small samples though .",
    "unfortunately , no other bandwidth selection method is uniformly best either . selecting the number of mixture components for the preliminary estimator by bic is superior to the aic - based procedure for distributions # 1,5,7 , and",
    " if attention is restricted to second order kernel#6,8,9,11 , and 13 .",
    "aic - based procedure delivers better results with optimal order kernels for distributions # 3,8,9 , and student s @xmath151 and @xmath154 distributions , but in many of these cases it is better to use second order kernel .",
    "interestingly , knowing the true number of mixture components is not necessarily advantageous to bandwidth selection for many nm distributions .",
    "this is most notable for the kurtotic unimodal distribution with @xmath149 .",
    "the conclusion about the benefits of using higher order kernels is similar to that reached in section [ sec : analysis.of.mise ] , but the potential reduction in mise higher order kernels can confer is achieved in fewer cases .",
    "the benefits are very clear for the normal distribution , as well as for the outlier and separated bimodal distributions with @xmath155 .",
    "overall , if one were to chose a single method , the combination of the bic - based procedure and second order kernel would deliver good results .",
    "finally , it is worth noting that smoothing often improves on parametric normal mixture cdf estimators in terms of their mise when the sample sizes are small , and even when the true number of mixture components is known ( last six columns in table [ tab : bw.relmise.and.pairwise.t.tests ] ) .",
    "the exact mise expressions derived in this paper can usefully complement asymptotic analysis and simulation studies to investigate the finite sample performance of kernel estimators of a broad variety of distribution functions . in the examples considered here ,",
    "the gaussian - based kernels are found to perform well in general , and remarkably so for the regularly shaped distributions .",
    "the analysis also offers a guide on when to use higher order kernels in distribution function estimation .    as in the case of density estimation , the asymptotic approximation to mise",
    "can be poor in finite samples , and bandwidth selection methods based on such approximations , including the simple rule of thumb bandwidths popular in applied work ( appendix [ sec : nrr.bandwidth ] ) , should be used with caution .",
    "the normal - mixture plug - in method of jointly selecting the optimal bandwidth and kernel order proposed in this paper offers a simple practical alternative to existing bandwidth selection procedures . using bic to determine the number of mixture components to fit at a preliminary stage delivers good results , but does not uniformly outperform other methods .",
    "fine - tuning the rules for selecting the number of components is one issue that future research could usefully address .",
    "throughout the appendices , ampw refers to @xcite , and dlmf to the nist digital library of mathematical functions , an online companion to @xcite , release 1.0.10 , available at http://dlmf.nist.gov/[dlmf.nist.gov ] .",
    "in what follows @xmath156 derivatives of @xmath157 with respect to @xmath3 are denoted by @xmath158 , @xmath159 .",
    "the formula is also valid for the first two antiderivatives , viz . @xmath160 and @xmath161 .",
    "we will use the fact that even order derivatives of @xmath162 are even functions , i.e. @xmath163 , @xmath159 , and @xmath164 .",
    "we will also use results in ampw , in particular , corollary 5.2 , @xmath165    with @xmath166 defined by we can write @xmath167 . thus with @xmath168 given by , for a fixed @xmath3 and @xmath10 , by we have @xmath169   = \\operatorname{e}[g_{2r}(h^{-1}(x - x_{1 } ) ) ]   =   \\int_{-\\infty}^{x}du \\sum_{j=1}^{m}w_{j}\\sum_{s=0}^{r-1}\\frac{(-1)^{s}h^{2s}}{2^{s}s ! } \\int_{-\\infty}^{\\infty}\\phi^{(2s)}(z;u , h^{2})\\phi(z;\\mu_{j},\\sigma_{j}^{2})dz = \\psi^{(-1)}(x),\\ ] ] where @xmath170 .",
    "* isb*. using , the integrated squared bias of @xmath11 , @xmath62   = \\int_{-\\infty}^{\\infty}\\{\\operatorname{e}[\\widehat{f}_{2r}(z;h)]-f(z)\\}^{2}dz$ ] , can be expressed as @xmath171 & =      \\int_{-\\infty}^{\\infty}dz \\int_{-\\infty}^{0}dx\\int_{-\\infty}^{0 } \\left[\\psi(x+z)\\psi(y+z ) - 2\\psi(x+z)f(y+z ) + f(x+z)f(y+z)\\right]dy \\\\ \\label{a.t1.p.isb }   & = \\frac{1}{2}\\int_{-\\infty}^{0}dv\\int_{v}^{-v } \\xi(u ) du = -\\xi^{(-2)}(0),\\end{aligned}\\ ] ] where @xmath172dw \\\\",
    "\\notag   & = \\sum_{i=1}^{m}\\sum_{j=1}^{m}w_{i}w_{j}\\sum_{s=0}^{r-1}\\sum_{t=0}^{r-1}\\frac{(-1)^{s+t}h^{2s+2t}}{2^{s+t}s!t!}\\phi^{(2s+2t)}(u;\\mu_{i}-\\mu_{j},\\sigma_{ij,2}^{2 } ) \\\\",
    "\\label{a.t1.p.isb.xi } & \\qquad -2\\sum_{i=1}^{m}\\sum_{j=1}^{m}w_{i } w_{j}\\sum_{s=0}^{r-1}\\frac{(-1)^{s}h^{2s}}{2^{s}s ! } \\phi^{(2s)}(u;\\mu_{i}-\\mu_{j},\\sigma_{ij,1}^{2 } ) + \\sum_{i=1}^{m}\\sum_{j=1}^{m}w_{i}w_{j}\\phi(u;\\mu_{i}-\\mu_{j},\\sigma_{ij,0}^{2}).\\end{aligned}\\ ] ] the second equality in follows by rotating about the @xmath173-axis counterclockwise by @xmath174 and stretching the resultant @xmath3 and @xmath175 axes by @xmath176 . integrating over @xmath177 using yields the expression for @xmath178 in .",
    "the final equality in then follows because @xmath179 and @xmath180 ( for @xmath181 , @xmath182 by ampw corollary 3.3 , and the terms involving @xmath162 cancel out ) , and hence @xmath183 .",
    "equation is a rearrangement of @xmath184 using @xmath185 , @xmath186 .",
    "* iv*. the derivation of the integrated variance of @xmath11 follows the same steps as the derivation of isb .",
    "using and the expression for @xmath187 above we obtain @xmath188 & =    n^{-1}\\int_{-\\infty}^{\\infty}\\left\\{\\operatorname{e}[g_{2r}(h^{-1}(z - x_{1}))^{2 } ] -\\left(\\operatorname{e}[g_{2r}(h^{-1}(z - x_{1}))]\\right)^{2}\\right\\}dz\\\\ \\label{a.t1.p.ivar } & = n^{-1}\\frac{1}{2}\\int_{-\\infty}^{0}dv\\int_{v}^{-v } \\zeta(u)du   = -n^{-1}\\zeta^{(-2)}(0),\\end{aligned}\\ ] ] where , using , @xmath189 and the final equality in follows because @xmath190 and @xmath191 .",
    "equation obtains since for @xmath192 , @xmath193 ( ampw eq.2.13 , and by verification for @xmath194 ) , which gives @xmath195 the first equality in , @xmath196 , can be obtained using ampw corollary 6.2.2 , viz . for @xmath197 , @xmath198 , @xmath199 verifying by direct integration that holds with @xmath200 , we obtain from and , @xmath201 which equals @xmath82 since the last double sum is zero .    expression for @xmath82 can be derived from by changing the summation over rows to summation over the diagonals and using @xmath202 to obtain @xmath203 where @xmath204 is the beta function . using the integral representation of @xmath204 ( dlmf http://dlmf.nist.gov/5.12.e1[5.12.1 ] )",
    "it is easy to see that @xmath205 .",
    "finally , substituting @xmath206 ( dlmf http://dlmf.nist.gov/8.17.e4[8.17.4 ] , http://dlmf.nist.gov/8.17.e5[8.17.5 ] ) gives .",
    "* @xmath82 as @xmath47*. the second term in can be approximated for large @xmath45 by applying the euler - maclaurin sum formula ( dlmf http://dlmf.nist.gov/2.10.e1[2.10.1 ] ) , approximating @xmath207 by @xmath208 $ ] ( normal approximation to the binomial distribution ) , and expanding the ratio of gamma functions as @xmath209 $ ] ( dlmf http://dlmf.nist.gov/5.11.e13[5.11.13 ] ) .",
    "this gives @xmath210\\phi\\left(\\frac{s-2r+1}{\\sqrt{s}}\\right)ds+o(r^{-3/2}).\\ ] ] integrating by parts , changing the variables as @xmath211 , @xmath212 , and expanding @xmath213 into a taylor series around @xmath214 gives the leading term as @xmath215 , and thus .",
    "for computational reasons , especially when @xmath45 is large , it is convenient to express the kernels and the exact mise formulae in theorem [ thm : exact.mise ] using the kummer confluent hypergeometric function , @xmath216 . specifically , since for @xmath217 , @xmath218 ( dlmf http://dlmf.nist.gov/13.6.e17[13.6.17 ] , http://dlmf.nist.gov/13.2.e39[13.2.39 ] ) , can be written as @xmath219    similarly , using @xmath220 , @xmath217 ( dlmf http://dlmf.nist.gov/13.6.e16[13.6.16 ] ) , and changing the double summation over @xmath221 in and to summation over diagonals , the exact mise can be evaluated as @xmath222   =   \\frac{1}{\\sqrt{2\\pi}}\\left(\\frac{n-1}{2n}a_{2 } - a_{1}\\right ) -\\frac{h}{n\\sqrt{\\pi}}c(r ) -v_{0},\\ ] ] where @xmath112 is defined in , and with @xmath223 defined in , @xmath224 , and @xmath225 , @xmath226,\\\\\\label{thm1.mise.2.a2 } a_{2}&= -2\\sqrt{2\\pi}u(h;2 )   + \\sum_{i=1}^{m}\\sum_{j=1}^{m}w_{i}w_{j}\\sigma_{ij,2 } \\left[\\sum_{s=1}^{2r-2}r_{s}\\omega_{r , s}\\left(\\frac{h^{2}}{\\sigma_{ij,2}^{2}/2}\\right)^{s } { \\prescript{}{1}{f}^{}_{1}}\\left(s-\\frac{1}{2},\\frac{1}{2};-\\frac{1}{2}\\frac{(\\mu_{j}-\\mu_{i})^{2}}{\\sigma_{ij,2}^{2}}\\right)\\right].\\end{aligned}\\ ] ] for the normal distribution ( @xmath227 ) , expressions - simplify to @xmath228 , @xmath229    the ratios of gamma functions can be evaluated either recursively , or as @xmath230 to avoid overflows with large positive @xmath231 .",
    "the kummer confluent hypergeometric function can be evaluated recursively in @xmath79 ( dlmf http://dlmf.nist.gov/13.3.e1[13.3.1 ] ) .",
    "thus , using the recurrence dlmf http://dlmf.nist.gov/8.17.e17[8.17.17 ] for the incomplete beta function appearing in @xmath232 , the quantities @xmath233 and @xmath234 in can be computed recursively in @xmath79 .",
    "a matlab ( http://www.mathworks.com/[www.mathworks.com ] ) implementation is available from the author upon request .",
    "results presented in this paper were computed with advanpix multiprecision computing toolbox for matlab ( http://www.advanpix.com/[www.advanpix.com ] ) . in the multi - precision implementation",
    ", a backward recursion is used to compute @xmath232 starting with @xmath235 and @xmath236 . in the standard double precision version",
    ", it is better to use the matlab built - in incomplete beta function instead , as the errors accumulate fast .",
    "same applies to computation of @xmath82 in and @xmath59 in .",
    "in practice it is common to choose the bandwidth by simple plug - in or reference rules , such as the normal reference rule ( nrr ) . for example , with the second order gaussian kernel , the asymptotically optimal bandwidth for the normal distribution with variance @xmath20 is @xmath237 .",
    "an exact mise nrr bandwidth can be defined in a similar fashion . for the normal distribution ,",
    "the exact mise - minimising bandwidth is of the form @xmath238 , where @xmath239 is the bandwidth optimal for the standard normal distribution , which is straightforward to compute .",
    "following @xcite , let @xmath240 , where @xmath241 is the interquartile range of the distribution @xmath1 and @xmath242 is the gaussian quantile function ; @xmath243 .",
    "then the version of the nrr ( or silverman s rule of thumb ) bandwidth based on the exact mise can be defined as @xmath244 , where @xmath245 is the standard deviation of @xmath1 .",
    "analogous definition for the infinite order kernel is simply @xmath246 .",
    "figure [ fig : nrrmise ] shows the relative mise achievable  with the second order kernel and the nrr bandwidth . using the @xmath247 rather than either @xmath245 or @xmath248 alone turns out to better in virtually all examples and sample sizes considered . as expected , the nrr bandwidth performs well for the moderately skewed unimodal distribution # 2 ( it coincides with the optimal bandwidth for the normal distribution ) .",
    "surprisingly , it also performs well for the outlier , bimodal , skewed bimodal , and trimodal distributions , as well as generally for very small sample sizes .",
    "kdfe with the nrr bandwidth will also level off with the edf in terms of mise asymptotically .",
    "however , as is clearly seen for the strongly skewed and comb - like distributions , performance in samples as large as a million observations can be extremely poor .",
    "performance of the nrr bandwidth with higher order kernels and/or asymptotic nrr bandwidth is generally much worse and is therefore not shown .",
    "@>c@@>c@@>c@ # 1 : gaussian & # 2 : skewed unimodal & # 3 : strongly skewed + & &   + # 4 : kurtotic unimodal & # 5 : outlier & # 6 : bimodal + & &   + # 7 : separated bimodal & # 8 : skewed bimodal & # 9 : trimodal + & &   + # 10 : claw & # 11 : double claw & # 12 : asymmetric claw + & &   + # 13 : asymmetric double claw & # 14 : smooth comb & # 15 : discrete comb + & &   +    legend : horizontal axes : @xmath126 . vertical axes , % : minimum relative mise with the second order kernel and ( i ) the optimal bandwidth ( @xmath80 ) , ( ii ) the nrr bandwidth ( the smaller of @xmath249 and @xmath250 in parentheses ) . for reference ,",
    "grey dashed and dash - dot lines show the @xmath121 and the minimum relative @xmath130 with the optimal order kernel as in figure [ fig : reloptmise.1 ] .",
    "the author would like to thank anonymous referees for helpful comments .",
    "abdous , b. 1993 , ` note on the minimum mean integrated squared error of kernel estimates of a distribution function and its derivatives ' , _ communications in statistics - theory and methods _ * 22*(2 ) ,  603609 .",
    "doi : http://dx.doi.org/10.1080/03610929308831040[10.1080/03610929308831040 ] aldershof , b. , marron , j.  s. , park , b.  u.  wand , m.  p. 1995",
    ", ` facts about the gaussian probability density function ' , _ applicable analysis _ * 59*(1 ) ,  289306 .",
    "doi : http://dx.doi.org/10.1080/00036819508840406[10.1080/00036819508840406 ] altman , n.  lger , c. 1995 , ` bandwidth selection for kernel distribution function estimation ' , _ journal of statistical planning and inference _ * 46*(2 ) ,  195214 .",
    "doi : http://dx.doi.org/10.1016/0378-3758(94)00102-2[10.1016/0378-3758(94)00102-2 ] azzalini , a. 1981 , ` a note on the estimation of a distribution function and quantiles by a kernel method ' , _ biometrika _ * 68*(1 ) ,  326328 .",
    "doi : http://dx.doi.org/10.1093/biomet/68.1.326[10.1093/biomet/68.1.326 ] bowman , a. , hall , p.  prvan , t. 1998 , ` bandwidth selection for the smoothing of distribution functions ' , _ biometrika _ * 85*(4 ) ,  799808 .",
    "doi : http://dx.doi.org/10.1093/biomet/85.4.799[10.1093/biomet/85.4.799 ] butorina , y.  o.  nikitin , y.  y. 2011 , ` on large deviations of smoothed kolmogorov - smirnov s statistics ' , _ vestnik st .",
    "petersburg university : mathematics _ * 44*(2 ) ,  97102 .",
    "doi : http://dx.doi.org/10.3103/s106345411102004x[10.3103/s106345411102004x ] chacn , j.  e. , monfort , p.  tenreiro , c. 2014 , ` fourier methods for smooth distribution function estimation ' , _ statistics and probability letters _ * 84 * ,  223230 .",
    "doi : http://dx.doi.org/10.1016/j.spl.2013.10.010[10.1016/j.spl.2013.10.010 ] chernozhukov , v. , fernndez - val , i.  galichon , a. 2009 , ` improving point and interval estimators of monotone functions by rearrangement ' , _ biometrika _ * 96*(3 ) ,  559575 .",
    "doi : http://dx.doi.org/10.1093/biomet/asp030[10.1093/biomet/asp030 ] falk , m. 1983 , ` relative efficiency and deficiency of kernel type estimators of smooth distribution functions ' , _ statistica neerlandica _ * 37*(2 ) ,  7383 .",
    "doi : http://dx.doi.org/10.1111/j.1467-9574.1983.tb00802.x[10.1111/j.1467-9574.1983.tb00802.x ] fraley , c.  raftery , a.  e. 2002 , ` model - based clustering , discriminant analysis , and density estimation ' , _ journal of the american statistical association _ * 97*(458 ) ,  611631 .",
    "doi : http://dx.doi.org/10.1198/016214502760047131[10.1198/016214502760047131 ] fryer , m.  j. 1976 , ` some errors associated with the non - parametric estimation of density functions ' , _ journal of the institute of mathematics and its applications _ * 18*(3 ) ,  371380 .",
    "doi : http://dx.doi.org/10.1093/imamat/18.3.371[10.1093/imamat/18.3.371 ] glad , i.  k. , hjort , n.  l.  ushakov , n.  g. 2003 , ` correction of density estimators that are not densities ' , _ scandinavian journal of statistics _ * 30*(2 ) ,  415427 .",
    "doi : http://dx.doi.org/10.1111/1467-9469.00339[10.1111/1467-9469.00339 ] glad , i.  k. , hjort , n.  l.  ushakov , n.  g. 2007 , density estimation using the sinc kernel , preprint statistics 2/2007 , norwegian university of science and technology .",
    "url : https://www.math.ntnu.no/preprint/statistics/2007/s2-2007.pdf    hansen , b.  e. 2005 , ` exact mean integrated squared error of higher order kernel estimators ' , _ econometric theory _ * 21*(6 ) ,  10311057 .",
    "doi : http://dx.doi.org/10.1017/s0266466605050528[10.1017/s0266466605050528 ] marron , j.  s.  wand , m.  p. 1992 , ` exact mean integrated squared error ' , _ annals of statistics _ *",
    "20*(2 ) ,  712736 .",
    "doi : http://dx.doi.org/10.1214/aos/1176348653[10.1214/aos/1176348653 ] mclachlan , g.  peel , d. 2000 , _ finite mixture models _ , john wiley & sons .",
    "nadaraya , e.  a. 1964 , ` some new estimates for distribution functions ' , _ theory of probability and its applications _ * 9*(3 ) ,  497500 .",
    "doi : http://dx.doi.org/10.1137/1109069[10.1137/1109069 ] olver , f.  w.  j. , lozier , d.  w. , boisvert , r.  f.  clark , c.  w. , eds 2010 , _ nist handbook of mathematical functions _ ,",
    "cambridge university press , new york , ny .    polansky , a.  m.  baker , e.  r. 2000 , ` multistage plug - in bandwidth selection for kernel distribution function estimates ' , _ journal of statistical computation and simulation _ * 65*(1 - 4 ) ,  6380 .",
    "doi : http://dx.doi.org/10.1080/00949650008811990[10.1080/00949650008811990 ] reiss , r. 1981 , ` nonparametric estimation of smooth distribution functions ' , _ scandinavian journal of statistics _ * 8*(2 ) ,  116119 .",
    "url : http://www.jstor.org/stable/4615820    roeder , k.  wasserman , l. 1997 , ` practical bayesian density estimation using mixtures of normals ' , _ journal of the american statistical association _ * 92*(439 ) ,  894902 .",
    "doi : http://dx.doi.org/10.1080/01621459.1997.10474044[10.1080/01621459.1997.10474044 ] silverman , b.  w. 1986 , _ density estimation _ , chapman and hall .",
    "swanepoel , j. w.  h. 1988 , ` mean intergrated squared error properties and optimal kernels when estimating a distribution function ' , _ communications in statistics  theory and methods _ * 17*(11 ) ,  37853799 .",
    "doi : http://dx.doi.org/10.1080/03610928808829835[10.1080/03610928808829835 ] tenreiro , c. 2006 , ` asymptotic behaviour of multistage plug - in bandwidth selections for kernel distribution function estimators ' , _ journal of nonparametric statistics _ * 18*(1 ) ,  101116 .",
    "doi : http://dx.doi.org/10.1080/10485250600578334[10.1080/10485250600578334 ] wand , m.  p.  schucany , w.  r. 1990 , ` gaussian - based kernels ' , _ canadian journal of statistics _ * 18*(3 ) ,  197204 .",
    "doi : http://dx.doi.org/10.2307/3315450[10.2307/3315450 ] watson , g.  s.  leadbetter , m.  r. 1964 , ` hazard analysis ii ' , _ sankhy : the indian journal of statistics , series a _ * 26*(1 ) ,  101116 .",
    "url : http://www.jstor.org/stable/25049316"
  ],
  "abstract_text": [
    "<S> an exact , closed form , and easy to compute expression for the mean integrated squared error ( mise ) of a kernel estimator of a normal mixture cumulative distribution function is derived for the class of arbitrary order gaussian - based kernels , extending the results of @xcite ( @xcite ) , ` exact mise ' , _ ann . </S>",
    "<S> stat . _ 20(2 ) , 712736 , to estimation of distribution functions . </S>",
    "<S> comparisons are made with mise of the empirical distribution function and the infeasible minimum mise of kernel estimators . </S>",
    "<S> the analysis also offers a guide on when to use higher order kernels in distribution function estimation .    </S>",
    "<S> a simple plug - in method of simultaneously selecting the optimal bandwidth and kernel order is proposed , wherein a normal mixture distribution is fitted to the data at a preliminary stage and the resultant estimate is plugged into the exact mise formula . </S>",
    "<S> a simulation study conducted to evaluate performance of this method in finite samples suggests that it works well , although it does not always outperform existing bandwidth selection procedures .    </S>",
    "<S> * keywords * : smoothing , normal mixture , gaussian - based kernel , plug - in rule , finite samples .    </S>",
    "<S> * ams subject classification * : 62g05 </S>"
  ]
}