{
  "article_text": [
    "in financial risk management , estimation of the operational risk capital under the loss distribution approach requires evaluation of the _ aggregate loss distribution _ ( ald ) .",
    "similarly , the collective risk models ( crm ) in insurance require evaluation of insurance portfolio ald in a certain period of time , defined as a compound distribution of the intensity of the claims ( frequency ) and their sizes ( severity ) . for more details",
    "see , e.g. , @xcite , @xcite , @xcite , and also @xcite , @xcite , @xcite .",
    "an important measure of interest in such cases is the value at risk ( var ) which is typically defined as the @xmath0 quantile of the ald .",
    "frequently , the exponential , gamma , log - normal , log - logistic or pareto distributions are used as the continuous severity distributions , and the poisson , binomial , or negative binomial distributions are used as the discrete frequency distributions , with their respective parameters fitted from the available observed data and/or derived based on the expert knowledge / judgment .    the _ aggregate loss _ in collective risk models , say , @xmath1 is modeled as a sum of stochastic number @xmath2 of identically independently distributed ( i.i.d . ) random variables ( rvs ) @xmath3 which represent the claim sizes further modeled by @xmath4 . by @xmath5",
    "we denote the probability distribution , in particular the cumulative distribution function ( cdf ) of a continuous severity distribution which is independent of @xmath6 , the random number of insurance claims generated in the given time period , and @xmath7 denotes the probability distribution of a discrete frequency distribution . obviously , the aggregate loss @xmath8 if @xmath9 .",
    "the probability distribution of the aggregate loss ( [ eq01 ] ) is then a mixture distribution , @xmath10 where @xmath11 denotes the probability of the random event that @xmath12 , and @xmath13 denotes the @xmath14-times convolved distribution function @xmath5 ( with @xmath15 being the degenerate dirac distribution concentrated at @xmath16 , by definition ) .    in general ,",
    "assuming portfolio with @xmath17 independent event type and/or business line cells ( with their aggregate losses @xmath18 , @xmath19 ) , we define the _ aggregate loss of the ( compound ) portfolio _ , say @xmath20 , as @xmath21 where @xmath22 are mutually independent , with independent claim frequencies , @xmath23 , and claim severities , @xmath24 , for all @xmath19 and @xmath25 .    the requirement on mutual independence of the involved rvs can be relaxed and naturally generalized for situations where the claim frequencies @xmath23 , @xmath19 , are correlated and their joint distribution is given .",
    "in particular , @xcite considered a family of discrete multivariate distributions , where the @xmath17-variate discrete random vector @xmath26 can be represented by @xmath27 , and where @xmath28 is a @xmath29 non - negative integer element matrix and @xmath30 is a @xmath31 column vector whose components rvs are independent .",
    "the situation with combining the correlated rvs is , however , not discussed in more details in this paper .",
    "the closed - form expression of the cdf , such as defined in ( [ eq02 ] ) , is typically not available for the aggregate loss @xmath32 or @xmath20 in ( [ eq01 ] ) and ( [ eq03 ] ) .",
    "thus , evaluation of these distributions relies on numerical methods .",
    "see @xcite for an overview of available numerical algorithms that can be successfully used to calculate the ald , including the monte carlo , panjer recursion and fourier transformation methods .",
    "@xcite described a specific ( mathematically convenient ) model and method that numerically inverts the characteristic function ( cf ) of an ald .",
    "in general , methods for approximate numerical inversion of cf , based on discrete fourier transform and the fast fourier transform ( fft ) algorithm , can be used alternatively , see , e.g. , @xcite or @xcite . for further details on the fft - based approach",
    "see the results in @xcite . for methods based on fractional fast fourier transform ( frft ) ,",
    "see @xcite , @xcite , @xcite , @xcite , @xcite .    here",
    "we shall discuss in more details the methods and the algorithms for evaluating the required probability density function ( pdf ) and the cdf by numerical inversion of the associated cf using a trapezoidal quadrature rule , which is sufficiently precise for most practical situations , as well as their matlab implementation , the _ characteristic functions toolbox _ ( ` cf toolbox ` ) .",
    "numerically more accurate matlab algorithms for inversion of the cfs used in specific crm with selected parametric frequency and severity distributions are suggested and implemented elsewhere , see @xcite .    in this paper , we focus primarily on non - parametric considerations , i.e. , on models based on combining the empirical cfs of claims frequency and severity in the actuarial risk applications , and their numerical inversion for evaluating the cdf and/or var .",
    "the basic non - parametric methods can be naturally generalized to a more complex semi - parametric modeling approach .",
    "for example , by combining the parametric frequency distributions with the empirical severity distributions , and/or by incorporating the generalized pareto distribution fit of the severity distribution heavy tails . or , by considering the weighted mixture of the parametric cfs ( this is used to model and incorporate the expert knowledge ) and the empirical cfs ( used to include the knowledge based on internal and/or external historical data ) .",
    "in fact , the components of the compound ald cfs can be represented either by parametric or empirical cfs and/or by their weighted mixtures .    as we shall argue and illustrate by analysis of a real data example in section  [ sec04 ] , the suggested approach based on empirical distributions in combination with parametric models used to model the heavy tails of the severity distributions and/or to include expert knowledge , gives better modeling flexibility than the standard parametric modeling approach . moreover , evaluating the ald by numerical inversion of the associated cf is computationally more efficient in comparison with other numerical methods , as , e.g. , the monte carlo methods or the panjer recursion .",
    "the rest of the paper is organized as follows : in section  [ sec02 ] we shall present methods for computing and combining the characteristic functions used for modeling the alds . in section  [ sec03 ]",
    "we introduce the gil - pelaez inversion and its implementation based on using the trapezoidal rule .",
    "their applicability is illustrated in section  [ sec04 ] , where the adls and vars are computed for real data .",
    "discussion and concluding remarks are in section  [ sec05 ] .",
    "for a scalar rv @xmath33 the characteristic function is defined as the expectation value of the transformed rv @xmath34 , i.e. @xmath35 where @xmath36 denotes the imaginary unit defined by @xmath37 , and @xmath38 is the argument of the cf .    in particular , cf of a continuous univariate rv @xmath33 , @xmath39 , with its probability distribution @xmath5 ( i.e.  @xmath40 ) and its probability density function @xmath41 ,",
    "is given as the ( inverse ) fourier transform of its pdf , @xmath42 note that since pdf is a real function , the cf is hermitian , i.e.  @xmath43 .",
    "analytical expressions of the cf are known for many standard probability distributions , see e.g.  @xcite , or can be derived by using a suitable computer algebra system , as e.g.  mathematica . on the other hand ,",
    "if the analytical form of the cf is unknown or it is too complicated , as it depends on nonstandard special functions and/or complicated series expansions ( as is the case for the log - normal , log - logistic and pareto distributions ) , such cfs can be still evaluated numerically , either directly from its definition ( [ eq04 ] ) or ( [ eq05 ] ) , or other suitable alternative representation .    for example , by using the half - space fourier integral transformation for a positive continuous random variable @xmath33 ( i.e. with @xmath44 ) with its pdf given by an analytical function @xmath45 , which is well defined for complex @xmath46 and decays at infinity , we get @xmath47 see , e.g. , @xcite . moreover , by using a suitable stabilizing transformation from @xmath48 to @xmath49 , the cf can be numerically evaluated at arbitrary @xmath38 by using any simple ( gaussian ) quadrature rule of a well behaved integral , @xmath50 this method can be used to evaluate cf of several continuous distributions listed in table  [ tab1 ] .",
    "in general , the cf of a weighted sum of independent random variables is calculated in the following way :    let @xmath51 be a weighted sum of independent rvs @xmath52 , with @xmath53 known positive constants for fixed @xmath14 , and known cfs @xmath54 .",
    "then the cf of rv @xmath55 , @xmath56 , is given by @xmath57    cf of a stochastic convolution defined by @xmath58 , where @xmath59 are i.i.d .",
    "rvs with common @xmath39 and @xmath2 is an independent discrete rv with @xmath60 , is given by @xmath61 equivalent expressions based on using the moment generating functions ( mgfs ) and/or the probability generating functions ( pgfs ) have been derived elsewhere , see , e.g. , equation ( 3.7 ) in @xcite and/or equation ( 7 ) in @xcite .    hence , cf of the ald defined in ( [ eq01 ] ) and ( [ eq02 ] ) , say @xmath62 or @xmath63 , is given by @xmath64 where @xmath60 and @xmath39 denote the known cfs of frequency and severity distributions . moreover , using equation ( [ eq08 ] ) cf of the ald of the ( compound ) portfolio , @xmath20 , as defined in ( [ eq03 ] ) , is @xmath65 where @xmath66 with @xmath18 , @xmath67 , and @xmath68 , for @xmath19 , as specified in ( [ eq03 ] ) .    -5pt",
    "p.4 p.5 probability distribution & characteristic function dirac @xmath69 , @xmath70 location & @xmath71 binomial @xmath72 , @xmath73 number of trials , @xmath74 success probability & @xmath75 negative binomial @xmath76 , @xmath77 , @xmath74 success probability & @xmath78 poisson @xmath79 , @xmath80 rate & @xmath81 exponential @xmath82 , @xmath80 rate & @xmath83 gamma @xmath84 , @xmath85 shape , @xmath86 rate , with scale @xmath87 & @xmath88 log - normal @xmath89 , @xmath70 location , @xmath90 scale & @xmath39 evaluated by combination of methods ( [ eq05 ] ) and/or ( [ eq07 ] ) with @xmath91 log - logistic @xmath92 , @xmath85 scale,@xmath86 shape , & @xmath39 evaluated by combination of methods ( [ eq05 ] ) and/or ( [ eq07 ] ) with @xmath93 pareto type i ( european)@xmath94 , @xmath85 shape , @xmath90 scale & @xmath95 or @xmath96 , where @xmath97 evaluated by combination of methods ( [ eq05 ] ) and/or ( [ eq07 ] ) with @xmath98 pareto type ii ( american , lomax)@xmath99 , @xmath85 shape , @xmath90 scale & @xmath100 or @xmath39 evaluated by combination of methods ( [ eq05 ] ) and/or ( [ eq07 ] ) with @xmath98 generalized pareto @xmath101 , here @xmath102 shape , @xmath90 scale , @xmath103 threshold & @xmath104 , where @xmath97 evaluated by combination of methods ( [ eq05 ] ) and/or ( [ eq07 ] ) with @xmath105    -15pt    finally , cf of a weighted mixture distribution , defined by @xmath106 with @xmath107 , is @xmath108 where @xmath56 denotes the cf of the distribution @xmath109 and @xmath110 denotes the cf of the distribution @xmath111 , for @xmath112 .    for illustration , table  [ tab1 ] presents selected cfs of the discrete and the continuous univariate distributions frequently used as the building blocks of the compound cfs of the aggregate loss distributions , as defined in ( [ eq10 ] ) , ( [ eq11 ] ) and ( [ eq12 ] ) .",
    "let @xmath52 are i.i.d .  random variables with the common distribution function @xmath5 .",
    "the empirical distribution based on the random sample @xmath52 is a mixture distribution of equally weighted degenerate dirac distributions , concentrated at @xmath52 .",
    "hence , the observed empirical characteristic function ( ecf ) is equally weighted mixture of the characteristic functions of the dirac random variables concentrated at the observed values @xmath113 of @xmath59 , i.e.  mixture of cfs given by @xmath114 , @xmath115    let @xmath116 denotes the empirical cdf ( ecdf ) of the observed historic numbers ( frequency ) of claims @xmath117 , in each of @xmath118 historic years , with its empirical cf given by @xmath119 further , let @xmath120 denotes the ecdf based on @xmath121 observed historic values ( severity ) of claims @xmath122 , with its ecf given by @xmath123 then , in analogy with ( [ eq10 ] ) , the compound empirical cf , say @xmath124 , of the collective risk @xmath32 distribution is @xmath125    similarly , and in analogy with ( [ eq11])-([eq12 ] ) , we can also derive the empirical cf of the ald of the ( compound ) portfolio , @xmath20 , as defined in ( [ eq03 ] ) , say @xmath126 .",
    "combination of the ecdf @xmath120 and the fitted generalized pareto cdf is frequently used for modeling the heavy tailed ( severity ) distributions , based on the observed data , see , e.g. , @xcite and @xcite . using equation ( [ eq13 ] )",
    "the cf of such distribution , say @xmath127 , can be expressed as a weighted mixture of the empirical cf and the generalized pareto cf , @xmath128 where @xmath74 is chosen probability level specifying the tail part of the distribution , typically with @xmath129 or greater , @xmath130 is the empirical cf based on the lower @xmath17-part of the observed values ( @xmath131 , where @xmath132 is the threshold selected as the @xmath17-quantile of the distribution ) , and @xmath133 is cf of the fitted generalized pareto distribution @xmath101 , with the parameters @xmath134 and @xmath135 estimated ( e.g. , by the maximum likelihood estimation method ) from the observed values @xmath136 , @xmath137 .",
    "finally , notice that the ald defined by the cf ( [ eq10 ] ) or ( [ eq11])-([eq12 ] ) is a discrete distribution , if all of the severity component distributions ( @xmath32 or @xmath138 for all @xmath139 ) are discrete distributions ( e.g. , based on their empirical cfs ) . otherwise , the ald distribution is a continuous distribution ( although with possibly highly erratic shape ) . in particular , the aggregate loss distribution defined by the empirical cf ( [ eq17 ] )",
    "is in principal a discrete one with cumulative distribution function being a step - function ( similarly as is the empirical cdf ) .",
    "the standard inversion theorems , including the gil - pelaez inversion formulae introduced below , are based on the assumption that the pdf exists ( i.e. assuming the absolutely continuous distribution ) and that the characteristic function is absolutely integrable over @xmath140 . in section  [ sec03 ]",
    "we present methods and algorithms that are based on this theoretical assumption , however , for most practical purposes , their numerical implementation is typically also well suited ( as an approximate method ) for evaluation of the ald cdfs defined by the empirical cfs .    in any case , smoothing the compound loss empirical ald , @xmath20 , is still possible by using the appropriately smoothed cf , obtained by convolution of the empirical distribution with suitable continuous distribution , as @xmath141 where @xmath126 is the empirical or otherwise corrupted cf , and @xmath142 represents cf of a suitable _ smoothing _ continuous distribution , e.g. , zero - mean gaussian distribution with its standard deviation @xmath135 proportional to the selected bandwidth of the smoothing kernel , @xmath143 .",
    "computing the ( inverse ) fourier transform numerically is a well - known problem , frequently connected with computing integrals of highly oscillatory ( complex ) functions .",
    "it was studied for a long time in general , but also with focus on specific applications , see , e.g. , @xcite , to show just a few . in particular , the methods suggested for inverting the characteristic function for obtaining the probability distribution function include @xcite , and @xcite .    here",
    "we shall assume that the considered ald characteristic function , say @xmath144 or @xmath145 , which is associated with the distribution of the specific aggregate loss @xmath146 , is known and can be easily evaluated for arbitrary @xmath147 .",
    "@xcite derived the inversion formulae of the absolutely integrable cfs over @xmath140 , suitable for numerical evaluation of the pdf and/or the cdf , which require integration of a real - valued functions only , for more details see @xcite .",
    "in particular , pdf of the absolutely continuous distribution ( assuming that it exists ) , with characteristic function @xmath144 , is given by @xmath148 and further , if @xmath149 is a continuity point of the cumulative distribution function of @xmath20 , defined by @xmath150 , then the cdf is given by @xmath151 by @xmath152 and @xmath153 we denote the real and imaginary part of the complex function @xmath154 , respectively .    in statistics , numerical inversion of the characteristic function based on ( [ eq20 ] ) and ( [ eq21 ] ) was successfully implemented in another context for evaluation of the distribution function of a linear combination of independent chi - squared rvs in @xcite and @xcite .",
    "further , the gil - pelaez s method was used to compute the distribution of a linear combination of independent student s @xmath155 random variables and also for the distribution of a linear combination of independent inverted gamma random variables , see @xcite , @xcite , and also @xcite .    in general ,",
    "the integrals in ( [ eq20 ] ) and ( [ eq21 ] ) can be computed by a number of numerical quadrature methods . in some",
    "the integral is subdivided into subintervals between consecutive zeroes of the integrand , integrated over them using , for example , gaussian quadrature , and the summation of the obtained alternating series is accelerated by known methods , see , e.g. , @xcite .",
    "frequently , however , the integral ( [ eq20 ] ) and in particular ( [ eq21 ] ) can be efficiently approximated by a trapezoidal quadrature , i.e. @xmath156 and/or @xmath157 where @xmath2 is sufficiently large integer , say @xmath158 , @xmath159 are the appropriate trapezoidal quadrature weights ( i.e.  @xmath160 , and @xmath161 for @xmath162 ) , and @xmath163 for @xmath164 are the equidistant nodes ( with their mutual distance @xmath165 ) from the interval @xmath166 $ ] , for sufficiently large @xmath167 ( i.e.  such @xmath167 that the integrand function @xmath168 and/or @xmath169 is sufficiently small for all @xmath170 )",
    ".    particular selection of the values @xmath2 and @xmath167 influences the total approximation error , i.e.  combination of the truncation error and the integration error . the trade - off between them",
    "strongly depends on @xmath171 .    if the optimum values of @xmath2 and @xmath167 are unknown , we suggest , as a simple rule of thumb , to start with the application of the following _ six - sigma - rule_.    for that , set @xmath172 , where the interval @xmath173 with @xmath174 ( or other more suitable value of the multiplication coefficient @xmath175 ) specifies the substantial part of the distribution support of the random variable @xmath20 , and then set @xmath2 and @xmath176 such that the absolute value of the integrand function is sufficiently small for all @xmath170 , say @xmath177 with , e.g. , @xmath178 .",
    "further , for computing the first term in ( [ eq23 ] ) , we can use the result from @xcite : if the mean ( expectation ) of @xmath20 exists , then @xmath179    the required location and dispersion parameters , the expectation @xmath180 and the variance @xmath181 , can be evaluated either analytically , from the moments of the distribution ( i.e.  the expectation and the variance of @xmath20 , if they exist and are known ) , or approximately , by numerical differentiation of the ( known ) @xmath144 . in particular , for any small @xmath182 , e.g. , @xmath183 , we get @xmath184 and , @xmath185 where @xmath186    such approximation , based on numerical differentiation of the characteristic function , serve as a reasonably good approximation of the required location and scale parameters also in situations when the theoretical moments ( expectation and variance ) formally do not exist .    note that the presented quadrature is efficient fot computing @xmath187 and @xmath188 for any @xmath189 as it requires only one evaluation of @xmath190 for @xmath191 .    finally ,",
    "the _ quantile function _ ( qf ) used for computing the vars can be evaluated either by simple interpolation from values calculated by ( [ eq23 ] ) , or ( for sufficiently smooth continuous distributions ) by the iterative newton - raphson scheme .",
    "it requires repeated evaluations of the pdf / cdf ( [ eq22])-([eq23 ] ) .",
    "in particular , for fixed probability level @xmath74 , the @xmath17-quantile of the ( continuous ) distribution of @xmath20 , say @xmath192 , is given as a solution ( fixed point ) of the following iterative scheme , @xmath193 where @xmath194 , and the starting value @xmath195 is set as , e.g. , @xmath196 , given by ( [ eq25 ] ) .",
    "we have implemented the above mentioned methods and algorithms into the matlab _ characteristic functions toolbox _ ( ` cf toolbox ` ) .",
    "it is a set of algorithms for computing and combining the characteristic functions and further for computing the pdf , cdf , and qf , by numerical inversion of the associated cf .",
    "the toolbox is available from the authors at the web page : https://goo.gl/gbfdwy .",
    "the ` cf toolbox ` includes also the easy to use application , the _ collective risk model tool _ ( ` crm tool ` ) .",
    "the ` crm tool ` is a fast and for most practical situations reasonably precise calculator of the aggregate claim / loss distribution and the associated value at risk , specified and computed by numerical inversion of its characteristic function .",
    "the algorithms used in the ` cf toolbox ` are based on trapezoidal rule for computing the integrals defined by the gil - pelaez formulae , or by using the fft algorithm for computing the fourier transform integrals . as already mentioned , in more complicated situations or if the highest numerical precision is required , a more advanced quadrature methods combined with accelerated computing of limits of series with alternating signs are typically required . for more details on possible alternative approaches and matlab implementation",
    "see @xcite .",
    "lrrrrrrrrrrr year & 1980 & 1981 & 1982 & 1983 & 1984 & 1985 & 1986 & 1987 & 1988 & 1989 & 1990 number of claims & 166 & 170 & 181 & 153 & 163 & 207 & 238 & 226 & 210 & 235 & 218 +    for illustration purposes , here we present the analysis of a well known insurance dataset frequently used for comparison of methods : the data on major danish fire insurance losses , see @xcite and references therein .",
    "the dataset is comprised of danish fire losses originally analyzed in @xcite and @xcite .",
    "the data represents fire losses in million danish krones ( dkk ) and was collected by a danish reinsurance company .",
    "the dataset contains individual losses above 1 million dkk , a total of @xmath197 individual losses , covering the period from january 3 , 1980 to december 31 , 1990 .",
    "it is adjusted for inflation to reflect 1985 values .",
    "the dataset can be found in the r packages ` fecofin ` and ` fextremes ` and is also included in the matlab ` cf toolbox ` .",
    "the empirical frequency distribution , the number of claims per year during the period 1980 - 1990 , is given in the table  [ tab01 ] ( mean value of @xmath198 claims per year ) .",
    "however , it is clearly visible that during the period 1980 - 1985 the number of claims was lower ( mean value @xmath199 ) than the number of claims during the period 1986 - 1990 ( mean value @xmath200 ) .",
    "this suggest possible mixture of different random mechanisms generating the number of claims , which are difficult to model by a standard discrete distribution .",
    "the empirical severity distribution , based on losses of @xmath197 individual claims greater than 1 million dkk observed during this period is presented as a histogram ( in logarithmic scale ) in the upper left panel of figure  [ fig01 ] .",
    "the descriptive statistics show that the distribution of the individual fire losses are significantly skewed to the right and exhibit high kurtosis , with the observed mean of @xmath201 and standard deviation of @xmath202 ( millions dkk ) , skewness @xmath203 and kurtosis of @xmath204 .",
    "this suggest to consider a heavy tail distribution as a model of the severity distribution .",
    "the first modeling approach for deriving the ald is based on a purely nonparametric approach for deriving the aggregate loss distribution from the compound empirical characteristic functions ( [ eq15 ] ) , ( [ eq16 ] ) , and ( [ eq17 ] ) by numerical inversion ( [ eq22])([eq23 ] ) .    with ` cf toolbox ` the evaluation of the aggregate loss distribution ( pdf / cdf ) specified by its cf as well as of the required vars is a simple task , which can be formulated by several lines of matlab code :    .... % danish fire losses data : load('danishfiredata.mat ' )    % empirical characteristic functions : cfn   = @(t ) cfe_empirical(t , frequency ) ; cfx   = @(t ) cfe_empirical(t , severity ) ; cf    = @(t ) cfn(-1i*log(cfx(t ) ) ) ;    % parameters / options : prob = [ 0.9 0.99 0.999 ] ; loss = linspace(0,2000,201 ) ' ; options.iscompound = true ;    % numerical inversion of cf by cf2distgp : result = cf2distgp(cf , loss , prob , options ) ;   ....    the outcome of the calculation is a matlab structure array ( ` result ` ) with specified fields and values which contain the values of pdf and cdf evaluated at required values ( specified by the variable ` loss ` ) , as well as the values of the vars evaluated at the required probabilities ( specified by the variable ` prob ` ) . in particular , the calculated values at risk ( vars )",
    "evaluated for the probabilities @xmath205 , @xmath206 , and @xmath207 are : @xmath208 , @xmath209 , and @xmath210 ( in millions dkk ) .",
    "the second modeling approach for deriving ald is based on a semi - parametric approach , by incorporating the generalized pareto distribution fit of the severity distribution heavy tails . here",
    ", the compound cf is @xmath211 where @xmath212 is given by ( [ eq15 ] ) and @xmath213 is a weighted mixture of the empirical cf and the fitted generalized pareto cf , given by ( [ eq18 ] ) .",
    "then , the ald is derived by numerical inversion ( [ eq22])([eq23 ] ) from the compound cf ( [ eq29 ] ) .",
    "choice of the optimum threshold @xmath132 , which divides the observed losses ( severity data ) into the head ( main body ) area and the tail area used for fitting the generalized pareto tail distribution , is the hard part of this modeling approach , which is discussed in more details elsewhere , see , e.g. , @xcite where the threshold values between @xmath214 and @xmath215 have been considered . for simplicity , however , here we consider the threshold derived as a @xmath17-quantile of the empirical severity distribution , specified by the probability value @xmath216 . for given fire losses data we get the estimate @xmath217 ( millions dkk ) .",
    "then the fitted generalized pareto distribution @xmath218 has the parameters ( estimated by the maximum likelihood estimation method from the observed losses greater than @xmath219 ) : @xmath220 and @xmath221 .",
    "based on that , we can construct the severity distribution characteristic function @xmath213 , defined as a mixture of the empirical cf and the fitted generalized pareto cf , as given in ( [ eq18 ] ) , and with the empirical frequency cf @xmath212 also the compound characteristic function @xmath222 .",
    "as before , evaluation of the aggregate loss distribution specified by this compound cf can be formulated by several lines of matlab code :    .... % set the threshold parameter theta p      = 0.95 ; theta = quantile(severity , p ) ;    % fit the gp ( generalized pareto ) distribution gpfit = paretotails(severity,0,p ) ; pars   = gpfit.upperparameters ; xi     = pars(1 ) ; sigma = pars(2 ) ;    % cf of the fitted tail gp distribution   pdfgp = @(x ) gppdf(x , xi , sigma ) ; cfgp   = @(t ) cfx_pdf(t , pdfgp ) . *",
    "exp(1i*t*theta ) ;    % cf of the mixture severity distribution xl     = severity(severity < = theta ) ; cfxl   = @(t ) cfe_empirical(t , xl ) ; cfx    = @(t ) p * cfxl(t ) + ( 1-p ) * cfgp(t ) ;    % empirical cf of the frequency distribution cfn    = @(t ) cfe_empirical(t , frequency ) ;    % compound cf of the aggregate loss distribution cf     = @(t ) cfn(-1i*log(cfx(t ) ) ) ;    % parameters prob = [ 0.9 0.99 0.999 ] ; loss = linspace(0,2500,201 ) ' ;    % options clear options options.n = 2 ^ 16 ; options.sixsigmarule = 15 ; options.iscompound = true ;    % numerical inversion of cf by cf2distgp result = cf2distgp(cf , loss , prob , options ) ;   ....    the calculated vars ( values at risk ) evaluated for the probabilities @xmath205 , @xmath206 , and @xmath207 are : @xmath223 , @xmath224 , and @xmath225 ( in millions dkk ) .",
    "these vars ( especially the higher quantiles ) are different if compared with the vars estimated from the purely nonparametric approach based on inverting the empirical compound cf . in general , as pointed out in @xcite : _ every dataset is unique and the data analyst must consider what the data mean at every step .",
    "the process can not and should not be fully automated_.",
    "we propose numerical inversion methods for derivation of the aggregate loss distribution from its characteristic function , derived as compound characteristic function of the frequency cf and the severity cf .    in particular ,",
    "in this paper we emphasize the nonparametric approach based on using the empirical characteristic functions of the frequency distribution and the severity distribution of the claims in the actuarial risk applications .",
    "as was illustrated , this can be generalized into a more complex semi - parametric modeling approach by incorporating the generalized pareto distribution fit of the severity distribution heavy tails , and/or by considering the weighted mixture of the parametric cfs ( used to model the expert knowledge ) and the empirical cfs ( used to incorporate the knowledge based on the historical data ) .",
    "the presented numerical inversion method is based on combination of the gil - pelaez inversion formulae and the simple trapezoidal rule used for numerical integration .",
    "the methods and algorithms are incorporated in the matlab _ characteristic functions toolbox _ ( ` cf toolbox ` ) , which is available at the web page https://goo.gl/gbfdwy .",
    "the applicability of the suggested approach was illustrated by analysis of a well know insurance dataset , the danish fire loss data .",
    "as it was emphasized in @xcite , such inference is very sensitive to the choice of the threshold and also to the largest observed losses , and thus , the process can not and should not be fully automated .",
    "there is a role for stress scenarios in such loss severity analyses , whereby historical loss data are enriched by hypothetical losses to investigate the consequences of unobserved , adverse events .",
    "the suggested methods and algorithms could serve very well for this purpose .",
    "the work was supported by the slovak research and development agency , project apvv-15 - 0295 , and by the scientific grant agency vega of the ministry of education of the slovak republic and the slovak academy of sciences , by the projects vega 2/0047/15 and vega 2/0011/16 .",
    "41 natexlab#1#1[1]`#1 ` [ 2]#2 [ 1]#1 [ 1]http://dx.doi.org/#1 [ ] [ 1]pmid:#1 [ ] [ 2]#2 , . .",
    "; ( ): . . . ; ( ): . , .",
    "; ( ): . . . ; ( ): . , , .",
    ". volume  . , . , . .",
    ". in : . volume  ; .",
    ". . ; ( ): . .",
    "; : . , , , .",
    "volume . , .",
    "; ( ): . . . ; ( ): . . . , . . . ;",
    ". ; ( ): . . . ; ( ): . , , , .",
    "volume . , . . .",
    ". in : , editor .",
    ". ; ( ): . . . ; ( ): . . . ; ( ): . . . ; ( ): . . . ; ( ): . . .",
    "( ): . , , ."
  ],
  "abstract_text": [
    "<S> a non - parametric method for evaluation of the aggregate loss distribution ( ald ) by combining and numerically inverting the empirical characteristic functions ( cfs ) is presented and illustrated . this approach to evaluate ald is based on purely non - parametric considerations , i.e. , based on the empirical cfs of frequency and severity of the claims in the actuarial risk applications . </S>",
    "<S> this approach can be , however , naturally generalized to a more complex semi - parametric modeling approach , e.g. , by incorporating the generalized pareto distribution fit of the severity distribution heavy tails , and/or by considering the weighted mixture of the parametric cfs ( used to model the expert knowledge ) and the empirical cfs ( used to incorporate the knowledge based on the historical data  internal and/or external ) . here </S>",
    "<S> we present a simple and yet efficient method and algorithms for numerical inversion of the cf , suitable for evaluation of the alds and the associated measures of interest important for applications , as , e.g. , the value at risk ( var ) . the presented approach is based on combination of the gil - pelaez inversion formulae for deriving the probability distribution ( pdf and cdf ) from the compound ( empirical ) cf and the trapezoidal rule used for numerical integration . </S>",
    "<S> the applicability of the suggested approach is illustrated by analysis of a well know insurance dataset , the danish fire loss data .    </S>",
    "<S> aggregate loss distribution , value at risk , heavy tail distribution , empirical characteristic function , numerical inversion 91b30 , 62g32 </S>"
  ]
}