{
  "article_text": [
    "several groups ( e.g. eisenstein et al . 1999 , gawiser & silk 1998 , bridle et al . 1999 , bahcall et al .",
    "1999 , bond & jaffe 1998 , lineweaver 1998 ) have recently estimated cosmological parameters by joint analysis of data sets ( e.g. cmb , sne ia , redshift surveys , cluster abundance and peculiar velocities ) .",
    "a complication that arises in combining data sets is that there is freedom in assigning the relative weights of different measurements . some approaches to this problem",
    "have been suggested in the astronomical literature ( e.g. godwin & lynden - bell 1987 ; press 1996 ) .",
    "here we propose a bayesian approach utilizing ` hyper parameters ' ( hereafter hps ) .",
    "assume that we have 2 independent data sets , @xmath7 and @xmath8 ( with @xmath9 and @xmath10 data points respectively ) and that we wish to determine a vector of free parameters @xmath11 ( such as the density parameter @xmath12 , the hubble constant @xmath13 etc . ) .",
    "this is commonly done by minimising @xmath14 ( or maximizing the sum of log likelihood functions ) .",
    "such procedures assume that the quoted observational random errors can be trusted , and that the two ( or more ) @xmath0s have equal weights .",
    "however , when combining ` apples and oranges ' one may wish to allow freedom in the relative weights .",
    "one possible approach is to generalise eq .",
    "[ chi2_simple ] to be @xmath15 where @xmath16 and @xmath17 are ` lagrange multipliers ' , or ` hyper - parameters ' , which are to be evaluated in a bayesian way .",
    "there are a number of ways to interpret the meaning of the hps .",
    "a simple example of the hps is the case that @xmath18 ^ 2\\ ; , \\label{chi2_example}\\ ] ] where the sum is over @xmath9 measurements and corresponding predictions and errors @xmath19 . hence by multiplying @xmath0 by @xmath16 each error effectively becomes @xmath20 . but",
    "even if the measurement errors are accurate , the hps are useful in assessing the relative weight of different experiments .",
    "it is not uncommon that astronomers discard measurements ( i.e. by assigning @xmath21 ) in an ad - hoc way .",
    "the procedure we propose gives an objective diagnostic as to which measurements are problematic and deserve further understanding of systematic or random errors .",
    "we show below that if the prior probabilities for @xmath22 and @xmath23 are uniform then one should consider the quantity @xmath24 instead of eq .",
    "[ chi2_simple ] .",
    "it is as easy to calculate this statistic as the standard @xmath0 .",
    "the effective hps can then be identified as @xmath25 and @xmath26 , where @xmath27 and @xmath28 are computed at the values of the parameters @xmath29 that minimise eq . [ chi2_new ] .",
    "the derivation and interpretation of these results are given in section 2 . in section 3",
    "we apply the method to a set of cmb experiments and estimate the best fit hubble constant .",
    "extensions of the methods are discussed in section 4 .",
    "how do we eliminate the unknown hps @xmath16 and @xmath17 ?",
    "we follow here the bayesian formalism given in gull ( 1989 ) , mackay ( 1994 ) and bishop ( 1995 ) .",
    "the formalism in these references was given in the context of maximum entropy and artificial neural networks .",
    "by marginalisation over @xmath16 and @xmath17 we can write the probability for the parameters @xmath30 given the data : @xmath31 using bayes theorem we can write the following relations : @xmath32 and @xmath33    we now make the following assumptions : @xmath34    @xmath35    @xmath36    with the choice of ` non - informative ' uniform priors in the log , @xmath37 ( jeffreys 1939 ) we get @xmath38 and @xmath39 .",
    "note that the integral over priors of this kind diverges ( such a prior is called ` improper ' , see bishop 1995 ) .",
    "these are very conservative prior , essentially stating that we are ignorant about the scale of measurements and errors .",
    "the other extreme is obviously @xmath40 , i.e. when the measurements and errors are taken faithfully .",
    "one can try other forms ( see below ) , but it is likely that these 2 extreme forms reasonably bracket the probability space .",
    "hence : @xmath41 where @xmath42 and @xmath43    it is common to have a likelihood function of the form of a gaussian in @xmath9 dimensions : @xmath44\\ ; ,    \\label{mvgauss}\\ ] ] where we assume for simplicity that the normalization constant is independent of the parameters @xmath30 ( this is indeed the case in our application for the cmb measurements in the next section ) .",
    "we generalise this form to incorporate @xmath16 as follows : @xmath45 the integral of eq .",
    "[ pda ] then gives @xmath46 and similarly for eq .",
    "we note that it is the specific choice of prior for @xmath47 that has led to a change from a gaussian distribution ( eq .",
    "[ mvgauss ] ) to a power - law ( eq . [ power - law ] ) .",
    ". [ pwdadb ] can then be written ( ignoring constants ) as @xmath48 to find the best fit parameters @xmath30 requires us to minimise the above probability in the @xmath30 space .",
    ". [ lnpwdadb ] generalises a similar equation derived by cash ( 1979 ) .",
    "cash used a very different set of arguments based on maximum likelihood and he assumed that the error per group of data is the same ( in this special case the original quoted errors drop out in the minimisation ) . we emphasize that our bayesian framework is more general and ` principled ' , and therefore we can derive alternative equations by assuming different priors .    since",
    "@xmath16 and @xmath17 have been eliminated from the analysis by marginalisation they do not have particular values that can be quoted .",
    "rather , each value of @xmath16 and @xmath17 has been considered , and weighted according to the probability of the data given the model .",
    "however , it may be useful to know which values of @xmath16 and @xmath17 were given the most weight .",
    "this can be estimated by finding the values of @xmath16 and @xmath17 at which eq [ gauss_alpha ] peaks : @xmath49 and similarly @xmath50 both evaluated at the joint peak .",
    "we note that if we substitute these effective @xmath16 and @xmath17 in eq .",
    "[ chi2_hp ] we obtain @xmath51 , i.e. a reduced @xmath0 of unity ( for the case when the number of degrees of freedom is dominated by the number of data points ) .",
    "there is of course freedom in choosing the prior .",
    "for example , if we take @xmath52 ( instead of jeffreys prior @xmath38 ) we find that the function to be minimised is @xmath53 , instead of @xmath54 .",
    "thus these two priors give very similar results for large @xmath55 .",
    "numerous other priors are possible ( e.g. a top - hat centred on a plausible value ) , but at the expense of more free hps ( e.g. the width of the top - hat ) .",
    "we illustrate the effect of using hps by application to measurements of the angular power spectrum of the cosmic microwave background ( cmb ) . numerous groups have now used cmb data to estimate cosmological parameters ( see rocha 1999 for a review ) .",
    "the most common method is the flat bandpower method ( bond 1995a ; bond 1995b ) in which the difference between observed and predicted flat bandpowers are compared using the @xmath0 statistic ( eq .",
    "[ chi2_example ] ) .",
    "there is a question as to whether one should use all measurements from all groups of observers , independent of whether a given data set is consistent with the other data .",
    "dodelson and knox ( 1999 ) do address this issue by assigning a calibration coefficient to each data point , the values of which are optimised for each cosmological model investigated .",
    "the hps method offers a bayesian alternative to ad - hoc selection of data sets or the problems associated with using incompatible data sets and a conventional approach .",
    "there are clearly a large number of possible combinations of cmb data sets that could be investigated . for the purpose of illustration",
    "we divide a selection of the current cmb power spectrum estimates into six subsets .",
    "the subsets are ( i ) saskatoon ( netterfield et al .",
    "1997 , including the five per cent calibration error ; leitch , private communication ) , ( ii ) python v ( coble et al . 1999 ) , ( iii ) msam1 ( wilson et al 1999 ) , ( iv ) toco ( torbet et al . 1999 ,",
    "miller et al . 1999 ) , ( v ) boomerang / na ( mauskopf et al . 1999 , assuming gaussian window functions which fall by a factor of @xmath56 at @xmath57 and @xmath58 as specified in the paper ) and ( vi ) we group all of the remaining data into the fifth subset and refer to it as ` other ' .",
    "this subset contains cobe , tenerife , south pole , argo , max , qmap , ovro and cat ( see hancock et al .",
    "1998 , webster et al . 1998 and efstathiou et al .",
    "1999 for more details ) .",
    "these data are plotted in fig .",
    "[ cmbdata ] .",
    "[ eachalone ]    [ tableeachalone ]    in addition , for simplicity we restrict ourselves to a very limited set of cosmological models .",
    "we assume cmb fluctuations arise from adiabatic initial conditions with cold dark matter and negligible tensor component , and that @xmath59 , @xmath60 , @xmath61 , @xmath62k and @xmath63 .",
    "we then investigate the constraints on the remaining parameter , the dimensionless hubble constant , @xmath64  @xmath65 .",
    "theoretical power spectra for three different values of @xmath66 are shown in fig .",
    "[ cmbdata ] : increasing @xmath66 decreases the height of the first acoustic peak , and makes few other significant changes for the purpose of our analysis .",
    "the range in @xmath66 investigated here ( @xmath67 ) takes the peak height from above the saskatoon upper error bars down to the msam1 points .    to aid qualitative understanding of the analysis that follows , it is helpful to first calculate the value of @xmath66 preferred by each data subset .",
    "the results are plotted in fig . 2 and shown in table 1 .",
    "as expected from the range of first acoustic peak heights preferred by the data , the @xmath66 values also vary considerably .",
    "the boomerang / na data alone prefers an intermediate value of @xmath66 , as does the ` other ' data .",
    "toco and saskatoon both agree on a relatively high first acoustic peak and so on a low @xmath66 .",
    "the msam1 points are quite low and thus fit a high value of @xmath66 , and the pythonv points also prefer a high value of @xmath66 , although the @xmath0 value is very high , indicating a bad fit to the model .    clearly there are a large number of possible groupings of the data subsets .",
    "we show here the results from just five groupings , which are a fair sample and also highlight some of the properties of hps .",
    "firstly we consider the case of two relatively discrepant data sets , saskatoon and boomerang / na ; the @xmath66 values that they prefer do not overlap significantly .",
    "combining their @xmath0 values for each @xmath66 in the conventional manner ( eq . [ chi2_simple ] ) yields the likelihood function plotted with the dotted line in fig .",
    "[ constraints ] ( top ) .",
    "an intermediate value of @xmath66 is preferred , and in fact the best fitting @xmath66 values for each data set alone are essentially ruled out .",
    "in contrast , when hps are used , i.e. the @xmath0 values are combined using eq .",
    "[ lnpwdadb ] , the dotted line in fig .",
    "[ constraints ] ( bottom ) is obtained .",
    "there are two peaks in the probability distribution corresponding to the two different values of @xmath66 preferred by each data set alone .",
    "this is perhaps closer to what we would actually believe given just these two data subsets .",
    "next we consider the effect of adding in a data subset that agrees strongly with one of the above two data subsets .",
    "that is , we consider toco with saskatoon and boomerang / na . the probability distribution calculated using hps now loses its second peak , retaining the one that agrees with toco and saskatoon . the theoretical cmb power spectrum for the preferred value of @xmath68 is shown in fig .",
    "[ cmbdata ] .    on combining two data sets that do agree well , boomerang / na and ` other ' , there is little difference between the conventional and hp analyses , although the error bar on @xmath66 is slightly decreased when using hps .",
    "adding in a data subset that has a poor @xmath0 ( given the range of models considered ) , pythonv , makes a large difference to the conventional analysis but only a very small difference to the hp analysis .",
    "this can also be seen from the effective hp value at the best fit @xmath66 , calculated from eq .",
    "[ alpha1 ] , which is much less than unity for the pythonv data , indicating that it has been down weighted .",
    "finally we use all of the data subsets , obtaining the solid lines in fig .",
    "[ constraints ] .",
    "it turns out that the best fitting value of @xmath66 is similar in both the conventional and hp analyses , but the error bars are significantly wider in the hp analysis , which corresponds better to what we would naturally believe .",
    "[ table ]    [ table ]",
    "we have presented a formalism for analyzing a set of different measurements . by using a bayesian analysis , and by using a ` non - informative ' prior for the ` hyper - parameters '",
    ", we find that for @xmath69 data sets one should minimise @xmath70 where @xmath5 is the number of measurements in data set @xmath71 .",
    "it is as easy to calculate this statistic as the standard @xmath0 .",
    "the corresponding hps @xmath72 provide useful diagnostics on the reliability of different data sets .",
    "we emphasize that a low hp assigned to an experiment does not necessarily mean that the experiment is ` bad ' , but rather it calls attention to look for systematic effects or better modelleing .",
    "we have applied the hp analysis to a set of various cmb measurements and estimated the hubble constant @xmath6 ( for a fixed flat cdm @xmath73 model ) .",
    "while the standard @xmath0 approach gives a wide range for @xmath13 , the hyper - parameter analysis suggests two distinct values of @xmath13 , @xmath74 and @xmath75 km / sec / mpc .",
    "it remains to be understood why the ensemble of cmb experiments tends to give two competing values ( quite common in the history of the hubble constant ! ) .",
    "it would be most interesting to see how these values change when combined with other cosmological probes ( and their corresponding hps ) .    in estimating @xmath13 we have assumed that the other cosmological parameters ( like @xmath12 and @xmath76 ) were known and ,",
    "consequently , such an estimate is conditional on the assumed values of these parameters .",
    "this is not strictly necessary , actually , since we may obtain a more general estimation of @xmath13 by marginalising over @xmath12 , @xmath77 , and the other cosmological parameters , in a way similar to what we have done with the hps .",
    "one may also generalise the above method for more specific applications .",
    "two aspects which can be modified according to specific problems are the priors @xmath78 and the probability functions @xmath79 .",
    "we shall discuss elsewhere these extensions in application to various cosmological probes .",
    "* acknowledgments : * we thank g. rocha for her contribution to the data analysis , and a. dekel and i. zehavi for helpful discussions .",
    "slb acknowledges the receipt of a pparc studentship .",
    "ol thanks the iag ( so paulo ) for hospitality .",
    "lsj thanks fapesp , cnpq and pronex / finep for the support to his work ."
  ],
  "abstract_text": [
    "<S> recently several studies have jointly analysed data from different cosmological probes with the motivation of estimating cosmological parameters . here </S>",
    "<S> we generalise this procedure to take into account the relative weights of various probes . </S>",
    "<S> this is done by including in the joint @xmath0 function a set of ` hyper - parameters ' , which are dealt with using bayesian considerations . </S>",
    "<S> the resulting algorithm ( in the case of uniform priors on the log of the hyper - parameters ) is very simple : instead of minimising @xmath1 ( where @xmath2 is per data set @xmath3 ) we propose to minimise @xmath4 ( where @xmath5 is the number of data points per data set @xmath3 ) . </S>",
    "<S> we illustrate the method by estimating the hubble constant @xmath6 from different sets of recent cmb experiments ( including saskatoon , python v , msam1 , toco and boomerang ) .    # </S>",
    "<S> 1#1 8_8 2h^2    cosmology , cmb , hubble constant , statistics </S>"
  ]
}