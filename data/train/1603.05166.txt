{
  "article_text": [
    "the search techniques used to isolate the radio emission of pulsars , are designed to find periodic broadband signals exhibiting signs of dispersion caused by travel through the interstellar medium .",
    "signals meeting these criteria are recorded as a collection of diagnostic plots and summary statistics , in preparation for analysis .",
    "together these plots and statistics are referred to as a pulsar ` candidate ' , a possible detection of a new pulsar .",
    "each candidate must be inspected by either an automated method , or a human expert , to determine their authenticity .",
    "those of likely pulsar origin are highlighted for further analysis , and possibly allocated telescope time for confirmation observations .",
    "the remainder are typically ignored .",
    "the process of deciding which candidates are worthwhile investigating has become known as candidate ` selection ' .",
    "it is an important step in the search for pulsars since it allows telescope time to be prioritised upon those detections likely to yield a discovery . until recently ( early 2000 s )",
    "candidate selection was a predominately manual task .",
    "however advances in telescope receiver design , and the capabilities of supporting computational infrastructures , significantly increased the number of candidates produced by modern pulsar surveys @xcite .",
    "manual approaches therefore became impractical , introducing what has become known as the ` candidate selection problem ' . in response , numerous graphical and automated selection methods were developed @xcite , designed to filter candidates in bulk .",
    "the filtering procedure used ranged in complexity from a simple signal - to - noise ratio ( s / n ) cut , through to more complex functions @xcite . in either case , automated approaches enabled large numbers of candidates to be selected at speed in a reproducible way .    despite these advances",
    "the increasing number of candidates produced by contemporary pulsar surveys , tends to necessitate a pass of manual selection upon the candidates selected by software .",
    "many have therefore turned to machine learning methods to build ` intelligent ' filters @xcite , capable of reducing the dependence on human input .",
    "this has achieved some success .",
    "however these methods are often developed for a specific pulsar survey search pipeline , making them unsuitable for use with other surveys without modification . as a consequence ,",
    "new selection mechanisms are often designed and implemented per survey . as more methods continue to emerge",
    ", it becomes increasingly unclear which of these best address the candidate selection problem , and under what circumstances .",
    "it is also unclear which are best equipped to cope with the trend for increasing candidate numbers , the overwhelming majority of which arise from noise .",
    "existing approaches are not explicitly designed to mitigate noise , rather they are designed to isolate periodic detections .",
    "this does not achieve the same effect as explicitly mitigating noise .",
    "for example , isolating periodic candidates as potential pulsars , does not necessarily mitigate the impact of periodic noise .",
    "thus it is possible that these techniques will become less effective over time , as noise becomes responsible for an increasing proportion of all candidates detected .",
    "existing ` intelligent ' approaches are also ill - equipped to deal with the data processing paradigm shift , soon to be brought about by next - generation radio telescopes .",
    "these instruments will produce more data than can be stored , thus survey data processing , including candidate selection , will have to be done on - line in real - time ( or close to ) . in the real - time scenario it is prohibitively expensive to retain all data collected ( see section 4.3.1 ) .",
    "it therefore becomes important to identify and prioritise data potentially containing discoveries for storage .",
    "otherwise such data could be discarded and discoveries missed .",
    "thus new techniques are required @xcite to ensure preparedness for this processing challenge .",
    "in this paper we describe a new candidate selection approach designed for on - line operation , that mitigates the impact of increasing candidate numbers arising from noise .",
    "we develop our arguments for producing such a technique in progressive stages . in section  2",
    "we describe the candidate generation process .",
    "we show that improvements in pulsar survey technical specifications have led to increased candidate output , and infer a trend for exponential growth in candidate numbers which we show to be dominated by noise .",
    "we also demonstrate why restricting candidate output based on simple s / n cuts , runs the risk of omitting legitimate pulsar signals . the trend in candidate numbers and the ineffectiveness of s / n filters , allows us to identify what we describe as a ` crisis ' in candidate selection .",
    "in section  3 we review the different candidate selection mechanisms employed during the past fifty years , to look for potential solutions to the issues raised in section  2 .",
    "based on this review , in section  4 , we discuss these methods .",
    "we identify how all will be challenged by the transition to on - line processing required by telescopes such as the square kilometre array ( ska ) , motivating the development of new approaches .",
    "in addition we critique the existing features used to describe pulsar candidates , fed as inputs to the machine learning methods employed by many to automate the selection process . in section 5",
    "we present our own set of eight candidate features , which overcome some of these deficiencies .",
    "derived from statistical considerations and information theory , these features were chosen to maximise the separation between noise and non - noise arising candidates . in section  6 we describe our new data stream classification algorithm for on - line candidate selection which uses these features .",
    "section  6 also presents classification results that demonstrate the utility of the new approach , and its high level of pulsar recall . finally in section  7",
    "we summarise the paper , and comment on how the use of our method has helped to find 20 new pulsars during the lofar tied - array all - sky survey ( lotaas ) , though discovery details will be published elsewhere .",
    "since the adoption of the fast fourier transform ( fft ) @xcite the general pulsar search procedure has remained relatively unchanged .",
    "signals focused at the receiver of a radio telescope observing at a central frequency @xmath1 ( mhz ) , with bandwidth @xmath2 ( mhz ) , are sampled and recorded at a predetermined rate at intervals of @xmath3 ( @xmath4 ) , chosen to maximise sensitivity to the class of signals being searched for .",
    "the data are subsequently split in to @xmath5 frequency channels , each of width @xmath6 ( khz ) .",
    "an individual channel contains @xmath7 samples of the signal taken at the interval @xmath3 , over an observational period of length @xmath8 seconds , such that @xmath9 .",
    "each unique observation is therefore representable as an @xmath10 matrix @xmath11 .",
    "a pulsar search involves a number of procedural steps applied to the data in @xmath11 .",
    "the principal steps are similar for all searches , however the order in which these are undertaken can vary , as too can their precise implementation . in general , the first step involves radio frequency interference ( rfi ) excision , via the removal of channels ( rows of the matrix ) corresponding to known interference frequencies @xcite .",
    "subsequently ` clipping ' @xcite may be applied to the data , which aims to reduce the impact of strong interference .",
    "this is achieved by setting to zero ( or to the local mean ) those samples which exhibit intensities higher than some pre - determined threshold in a given column in @xmath11 ( e.g. an intensity @xmath12 above the mean ) .",
    "once these initial steps are complete , processing enters a computationally expensive phase known as de - dispersion .",
    "dispersion by free electrons in the interstellar medium ( ism ) causes a frequency dependent delay in radio emission as it propagates through the ism .",
    "this delay temporally smears legitimate pulsar emission @xcite reducing the s / n of their pulses .",
    "the amount of dispersive smearing a signal receives is proportional to a quantity called the dispersion measure ( dm , * ? ? ?",
    "this represents the free electron column density between an observer and a pulsar , integrated along the line of sight .",
    "the degree to which a signal is dispersed for an unknown pulsar can not be known _ a priori _ ( e.g. * ? ? ?",
    "* ; * ? ? ?",
    "* ) , thus several dispersion measure tests or ` dm trials ' must be conducted to determine this value .",
    "this can be used to mitigate the dispersive smearing , thereby increasing the s / n of a signal @xcite . for a single trial , each frequency channel ( row in @xmath11 )",
    "is shifted by an appropriate delay before each time bin is integrated in frequency .",
    "this produces 1 de - dispersed time series for each dm trial value .",
    "periodic signals in de - dispersed time series data , can be found using a fourier analysis .",
    "this is known as a periodicity search @xcite .",
    "the first step after performing the fft of a periodicity search usually involves filtering the data to remove strong spectral features known as ` birdies ' @xcite .",
    "these may be caused by periodic or quasi - periodic interference .",
    "summing techniques are subsequently applied , which add the amplitudes of harmonically related frequencies to their corresponding fundamentals .",
    "this step is necessary as in the fourier domain , the power from a narrow pulse is distributed between its fundamental frequency and its harmonics @xcite . thus for weaker pulsars the fundamental may not rise above the detection threshold , but the harmonic sum generally will .",
    "periodic detections with large fourier amplitudes post summing ( above the noise background or a threshold level ) , are then considered to be ` suspect ' periods . a further process known as sifting ( e.g. * ? ? ?",
    "* ) is then applied to the collected suspects , which removes duplicate detections of the same signal at slightly different dms , along with their related harmonics .",
    "a large number of suspects survive the sifting process . diagnostic plots and summary statistics",
    "are computed for each of these remaining suspects forming candidates , which are stored for further analysis .",
    "the basic candidate consists of a small collection of characteristic variables .",
    "these include the s / n , dm , period , pulse width , and the integrated pulse profile .",
    "the latter is an array of continuous variables that describe a longitude - resolved version of the signal that has been averaged in both time and frequency .",
    "more detailed candidates also contain data describing how the signal persists throughout the time and frequency domains @xcite .",
    "this can be seen in plots ( a ) and ( b ) in figure [ fig : candidate ] . here",
    "persistence in frequency ( a ) is represented by a two - dimensional matrix showing pulse profiles integrated in time , for a set of averaged frequency channels ( i.e. not full frequency resolution ) .",
    "persistence through time ( b ) , is represented by a two - dimensional matrix showing the pulse profile integrated across similarly averaged frequency channels as a function of time .",
    "[ cols=\"<,^,^,^\",options=\"header \" , ]      information theory uses the standard rules of probability to learn more about features and their interactions . features which at first appear information - poor , may when combined with one or more other features , impart new and meaningful knowledge @xcite . applying this theory to candidate features",
    "enables their comparison , evaluation , and selection within an established framework for the first time .",
    "information theory describes each feature @xmath13 in terms of @xmath14 .",
    "entropy is a fundamental unit of information borrowed from thermodynamics by @xcite , that quantifies the uncertainty present in the distribution of @xmath13 .",
    "the entropy of @xmath13 is defined as , @xmath15 where @xmath16 corresponds to each value that @xmath13 can take , and @xmath17 the probability of @xmath16 occurring .",
    "if a given value of @xmath16 occurs with a high probability , then the entropy of @xmath13 is low .",
    "conceptually this can be understood to mean that there is little uncertainty over the likely value of @xmath13 .",
    "likewise if all possible values of a feature are equally likely , then there is maximum uncertainty and therefore maximum entropy possible values is given by @xmath18 . ] .",
    "whilst entropy can provide an indication of the uncertainty associated with a feature variable , its main usefulness arises when conditioned on the target variable ( true class label ) @xmath19 .",
    "the conditional entropy of @xmath13 given @xmath19 is ,    @xmath20    where @xmath21 is the probability of @xmath16 given @xmath22 such that ,    @xmath23    this quantifies the amount of uncertainty in @xmath13 once the value of @xmath19 is known . using equations",
    "9 - 11 it is possible to define the mutual information ( mi , brown et al .",
    "2012 ) between the feature @xmath13 , and the class label @xmath19 .",
    "this can be considered another method of measuring the correlation between a feature and the target variable which detects non - linearities .",
    "mutual information is defined as , @xmath24 the mi expresses the amount of uncertainty in @xmath13 removed by knowing @xmath19 . if @xmath25 then @xmath13 and @xmath19 are independent . whereas if @xmath26 , then knowing @xmath19 helps to better understand @xmath13 . as mutual information",
    "is symmetric , knowing @xmath13 equivalently helps to better understand @xmath19 .",
    "thus mi is often described as the amount of information that one variable provides about another @xcite .",
    "it is desirable for features to possess high mi with respect to pulsar / non - pulsar labelling .",
    "the mi metric helps identify relevant features , by enabling them to be ranked according to those that result in the greatest reduction of uncertainty .",
    "it is one of the most common filter methods @xcite used for feature selection @xcite .",
    "the entropy and mi of our features are listed in table [ tab : inftheory2 ] , ranked according to their mean mi content , where higher mi is desirable . to produce this table feature data",
    "was discretised , for reasons set out by @xcite , enabling use with the information - theoretic feast and mitoolbox toolkits developed by @xcite .",
    "the data was discretised using 10 equal - width bins using the filters within the weka data mining tool .",
    "simple binning was chosen ahead of more advanced minimum description length ( mdl ) based discretization procedures @xcite , to simplify feature comparisons .",
    "the four features extracted from the integrated profile contain the largest amounts of mi .",
    "these are the most relevant features .",
    "the mi content of features extracted from the dm - snr is much lower .",
    "it is tempting therefore to write off these low scoring features since their linear correlation coefficients were also shown to be low in section [ sec : corr ] .",
    "however whilst mutual information indicates which features are relevant , it is entirely possible for these to contain redundant information @xcite . thus choosing the most relevant features may not produce optimal feature subsets @xcite , since these could contain the same information . the joint mutual information criterion ( jmi , * ? ? ?",
    "* ) can detect and minimise such redundancy @xcite .",
    "given a set of features the jmi selects those with complementary information , starting with the feature possessing the most mutual information @xmath27 . in",
    "` forward selection ' @xcite , a common method of feature selection , a greedy iterative process is used to decide which additional features are most complementary to @xmath27 , using the notion of the jmi score , @xmath28 where @xmath29 can be understood as a joint probability , and @xmath30 is the set of features .",
    "the iterative process continues until a desired number of features are selected .",
    "this produces a feature set that minimises redundancy . alternatively , if the desired number of features to select equals the total number of those available , features are ranked according to the jmi . using the jmi in this manner ,",
    "our features have been ranked such that a lower rank is preferable . upon applying this criterion poor features",
    "are revealed to be useful .",
    "this is shown in table [ tab : jmi ] which demonstrates that features extracted from the dm - snr curve impart complementary information , and are therefore ranked higher than profile features which possess greater mutual information .",
    "the standard deviation of the dm - snr curve in particular , is ranked as the 2nd ` best ' feature on two of the three test datasets .",
    "likewise the excess kurtosis and skewness of the dm - snr curve , are the second and fourth ` best ' features for lotaas data respectively . in the next section",
    "we describe a new data stream classification algorithm , which takes advantage of these features .",
    "data streams are quasi - infinite sequences of information , which are temporally ordered and indeterminable in size @xcite .",
    "data streams are produced by many modern computer systems @xcite and are likely to arise from the increasing volumes of data output by modern radio telescopes , especially the ska .",
    "however many of the effective supervised machine learning techniques used for candidate selection do not work with streams @xcite .",
    "adapting existing methods for use with streams is challenging , it remains an active goal of data mining research @xcite . until that goal is realised",
    ", new stream - ready selection approaches are required .",
    "supervised machine learning methods induce classification models from labelled training sets @xcite .",
    "provided these are large , representative of rare and majority class examples , and independent & identically distributed ( i.i.d . ) to the data being classified @xcite good classification performance can be expected to result .",
    "however the notion of a training set does not exist within a data stream .",
    "there are instead two general processing models used for learning .",
    "[ batch ]    * * batch processing model : * at time step @xmath31 a batch @xmath32 of @xmath33 unlabelled instances arrives , and is classified using some model trained on batches @xmath34 to @xmath35 . at time",
    "@xmath36 labels arrive for batch @xmath37 , along with a new batch of unlabelled instances @xmath38 to be classified . *",
    "* incremental processing model : * a single data instance arrives at time step @xmath31 defined as @xmath39 , and is classified using some model trained on instances @xmath40 to @xmath41 . at time @xmath36 a label arrives for @xmath39 , along with a new unlabelled instance @xmath42 to be classified .    in both models",
    "learning proceeds continually , as labelled data becomes available .",
    "this allows for adaptive learning .",
    "standard supervised classifiers simply can not be trained in this way .",
    "even if they could , the cpu and memory costs of their training phases make them impractical for streams @xcite .",
    "this was recognised by @xcite with respect to their pics system .    given these problems",
    "how should candidate selection be addressed in streams ?",
    "one may consider training an existing supervised candidate classifier off - line , which could then be applied to a candidate stream .",
    "this is a plausible approach , provided the classifier processes each example before the next one arrives . for this to be viable ,",
    "the classifier must also be trained with data that is i.i.d . with respect to the data in the stream .",
    "however data streams are known to exhibit distributional shifts over varying time periods .",
    "for example a changing rfi environment can exhibit shifts over both short ( minutes / hours ) , and/or long ( days / weeks / years ) time - scales . in either case",
    "the shifts cause violations of the i.i.d .",
    "assumption , a phenomena known as ` concept drift ' @xcite . to mitigate the impact of drift , adaptive algorithms able to learn from distributional changes",
    "are required , as pre - existing training data no longer characterises the post - drift data distribution @xcite .",
    "such algorithms must be capable of completely reconstructing their internal learning models in an efficient manner per each significant distributional shift .",
    "standard supervised learning models are ` static ' , i.e. they remain unchanged once learned .",
    "a static classifier applied to streaming data subject to drifts , will exhibit a significant deterioration in classification performance over time @xcite .",
    "this makes standard supervised learning unsuitable for data streams . in the next section",
    "we describe our new ` intelligent ' data stream classifier , which overcomes these deficiencies .              the gaussian - hellinger very fast decision tree ( gh - vfdt ) is an incremental stream classifier , developed specifically for the candidate selection problem @xcite . it is a tree - based algorithm based on the very fast decision tree ( vfdt ) developed by @xcite .",
    "it is designed to maximise classification performance on candidate data streams , which are heavily imbalanced in favour of the non - pulsar class .",
    "it is the first candidate selection algorithm designed to mitigate the imbalanced learning problem @xcite , known to reduce classification accuracy when one class of examples ( i.e. non - pulsar ) dominates the other .",
    "the algorithm uses tree learning @xcite to achieve this , whereby the data is partitioned using feature split point tests ( see figures [ fig : tree ] and [ fig : split ] ) that aim to maximise the separation of pulsar and non - pulsar candidates .",
    "this involves first choosing the variable that acts as the best class separator , and then finding a numerical threshold ` test point ' for that variable that maximises class separability .",
    "the tree is ` grown ' with labelled data to determine optimal splits , using the hoeffding bound @xcite .",
    "the bound is used to choose statistically with high probability , those split points that would have been selected , if given access to all training data in advance ( as in the traditional learning scenario ) . by calculating the observed mean @xmath43 of a feature , the bound is able to determine with confidence @xmath44 ( where @xmath45 is user supplied ) , that the true mean of the feature is at least @xmath46 where , @xmath47 and @xmath48 is the feature range squared .",
    "this ensures that the statistically optimal split is always chosen .",
    "a split is not made until enough examples in the stream have been seen , i.e. until there is enough evidence to advocate its use .",
    "the quality of the splits , and therefore the accuracy of the approach , improve over time .",
    "this is because the model of the underlying data distributions improves as more examples are observed .",
    "the performance of the algorithm approaches that of a non - streamed classifier as the number of examples observed approaches infinity @xcite .",
    "the tree is also able to adapt to change @xcite by updating the data distributions with each observed labelled example .",
    "once there is evidence to suggest an alternative split point is better than one in use , the tree replaces the sub - optimal split .",
    "this is achieved by pruning the branch of the tree containing the sub - optimal split , and replacing it with a new branch which begins to ` grow ' from the new split point .",
    "the key feature of the gh - vfdt , is its use of the skew - insensitive hellinger distance measure @xcite to evaluate split points during learning .",
    "this measure makes the classifier robust to the imbalanced learning problem , preventing the classifier from becoming biased towards the abundant non - pulsar class @xcite . by modelling each feature distribution as a gaussian , the hellinger distance between the pulsar and non - pulsar distributions can be measured .",
    "if @xmath49 and @xmath50 are the pulsar and non - pulsar distributions respectively , the distance for a single feature is given by , @xmath51 where @xmath49 has mean @xmath52 , variance @xmath53 and standard deviation @xmath54 , with @xmath50 defined similarly .",
    "the goal of split evaluation is to choose the split which maximises the hellinger distance , maximising pulsar and non - pulsar separation .",
    "this approach requires that only the mean and standard deviation of each feature be known .",
    "this significantly reduces the gh - vfdt memory overheads , as knowledge of the entire feature distribution(s ) is not required for learning .",
    "therefore the runtime and memory requirements of the algorithm are sub - linear with respect to the number of examples processed , and grow in only constant time for each new node added to the tree .",
    "this makes the algorithm suitable for use upon very high throughput data streams such as those described in section 4.3 .",
    "an input stream @xmath55 , such that each @xmath39 is a candidate , @xmath56 its @xmath57-th feature and @xmath58 its class label .",
    "the parameter @xmath59 is the confidence desired , and @xmath60 a parameter which if set , prevents split point ties .",
    "let @xmath61 be a decision tree with leaf @xmath62 for each stream instance .",
    "@xmath63sort instance @xmath39 to leaf @xmath64 .",
    "@xmath65 get class .",
    "for each feature .",
    "update @xmath66 update observed @xmath67 at leaf .",
    "update @xmath68 update observed @xmath69 at leaf .",
    "label @xmath64 with majority class of instances seen at @xmath64 @xmath70best feature",
    ". @xmath712nd best feature . for each feature .",
    "@xmath72 from equation [ eq : gaussianhellinger ] .",
    "@xmath73 @xmath74 hoeffding bound .",
    "replace @xmath64 with new leaf that splits on @xmath75 add new leaf @xmath76 for each class . for each @xmath56 .",
    "@xmath77 @xmath78 @xmath61    a complete outline of the gh - vfdt is given in algorithm 1 .",
    "on line 7 tree statistics used to compute the hellinger distance are updated .",
    "in particular the running mean and standard deviation maintained at each leaf , for feature @xmath57 , and class @xmath79 are updated .",
    "the call to @xmath80 returns the best and second best features found at a leaf .",
    "this is achieved by choosing those that maximise the hellinger distance via an iterative process .",
    "on line 18 tree split points are first generated and evaluated . here",
    "data is discretized using 10 equal - width bins , and a binary split point chosen .",
    "this approach has already been shown to significantly improve recall rates for pulsar data , above the levels achieved by established stream classifiers . when applied to a data stream containing 10,000 non - pulsar candidates for every legitimate pulsar ( htru data obtained by @xcite )",
    ", it raised the recall rate from 30 to 86 per cent @xcite .",
    "this was achieved using candidate data described using the features designed by @xcite and @xcite .",
    "a full implementation of the algorithm can be found on - line for public use .",
    "existing features and algorithms have been evaluated predominantly in terms of classification accuracy .",
    "such an analysis considers candidate selection as a binary classification problem , whereby candidates arising from pulsars are considered positive ( + ) , and those from non - pulsars negative ( - ) .",
    "there are then four possible outcomes for an individual classification decision .",
    "these outcomes are summarised in table [ tab : confusionmatrix1 ] and are evaluated using standard metrics such as those outlined in table [ tab : metrics ] .",
    "the goal of classification is to minimise the number of false positives , whilst maximising the true positives .",
    "features in this domain are most often chosen according to how well they maximise classifier recall ( the fraction of legitimate pulsar candidates correctly classified ) and specificity ( fraction of non - pulsar candidates correctly classified ) evaluate in this manner . ] .",
    "those classifiers with high recall and specificity exhibit high accuracy , often interpreted to mean that underlying features are good discriminators .",
    "accuracy & measure of overall classification accuracy .",
    "& @xmath81 + false positive rate ( fpr ) & fraction of negative instances incorrectly labelled positive . &",
    "@xmath82 + g - mean & imbalanced data metric describing the ratio between positive and negative accuracy . &",
    "@xmath83 + precision & fraction of retrieved instances that are positive . & @xmath84 + recall & fraction of positive instances that are retrieved . &",
    "@xmath85 + f - score & measure of accuracy that considers both precision and recall .",
    "& @xmath86 + specificity & fraction of negatives correctly identified as such . & @xmath87 +    this form of evaluation enables approaches to be tested quickly , with readily interpretable results .",
    "however using classifier performance as a proxy to measure feature - separability tests the classification system used as much as the features under investigation @xcite .",
    "the choice of classifier can influence the outcome of the evaluation giving misleading results .",
    "evaluation metrics themselves can also be misleading .",
    "pulsar data sets are imbalanced with respect to the total number of pulsar and non - pulsar candidates within them @xcite . thus for data sets consisting of almost entirely non - pulsar examples , high accuracy can often be achieved by classifying all candidates as non - pulsar . in these situations",
    "it is an unhelpful metric .",
    "|cc|c|c| & + & & _ - _ & _ + _ + & & true negative ( tn ) & false positive ( fp ) + & & false negative ( fn ) & true positive ( tp ) +    to overcome these possible sources of inaccuracy when evaluating the gh - vfdt , we make use of the g - mean metric @xcite .",
    "this describes the ratio between positive and negative accuracy , a measure insensitive to the distribution of pulsar and non - pulsar examples in test data sets .",
    "additionally we employ multiple classifiers in our evaluation which differ greatly in terms of their internal learning models .",
    "this allows for a more general view of feature performance in practice to be revealed .",
    "this is also useful for evaluating the performance of the gh - vfdt with respect to standard static supervised classifiers , which are at an advantage in such tests . here",
    "we make use of four standard classifiers found in the weka tool .",
    "these include the decision tree algorithm c4.5 @xcite , mlp neural network @xcite , a simple probabilistic classifier nave bayes ( nb , * ? ? ?",
    "* ) , and the standard linear soft - margin support vector machine ( svm , * ? ? ?",
    "= 0.11 cm      feature data was extracted from the data sets listed in table [ tab : data ] , and then independently sampled 500 times .",
    "each sample was split into test and training sets . for htru 1 & 2 ,",
    "sampled training sets consisted of 200 positive and 200 negative examples , with remaining examples making up the test sets .",
    "lotaas 1 training sets contained 33 positive examples and 200 negative , with remaining examples similarly making up the test sets .",
    "each classifier ( five in total ) was then trained upon , and made to classify each independent sample , therefore there were @xmath88 tests in total .",
    "the performance of each algorithm per data set was then averaged to summarise overall performance . to evaluate classifier performance results , one - factor analysis of variance ( anova ) tests were performed , where the algorithm used was the factor .",
    "tukey s honestly significant difference ( hsd ) test @xcite , was then applied to determine if differences in results were statistically significant at @xmath89 .",
    "the full results are shown in table  [ tab : classifierresults ] .",
    "these results indicate that it is possible to achieve high levels of classifier performance using the features described in section [ sec : new_features ] .",
    "what s more , the classification results are consistent across all three data sets .",
    "recall rates on all three test data sets are high , with @xmath90 per cent recall achieved by the mlp on htru 1 and lotaas 1 data .",
    "high levels of accuracy were observed throughout testing and g - mean scores on htru 1 were particularly high .",
    "the algorithms also exhibited high levels of specificity and generally low false positive rates .",
    "the exception being the @xmath91 per cent false positive rate achieved by the nb classifier on htru 2 data .",
    "this outcome is unremarkable for nb , the simplest classifier tested , as the htru 2 data set is populated with noise and borderline candidates .",
    "thus we suggest that these represent the first survey independent features developed for the candidate selection problem .",
    "the results also show that the gh - vfdt algorithm consistently outperformed the static classifiers , in terms of both specificity and false positive return rate .",
    "this is a highly desirable outcome for a stream classifier , since assigning positive labels too often will return an unmanageable number of candidates .",
    "the classifier does not always predict ` non - pulsar ' to give this result .",
    "it is precise , achieving the best precision on two out of the three data sets .",
    "g - mean and recall rates were also high for the gh - vfdt , the latter reaching @xmath92 per cent on htru 1 data .",
    "the recall rates are lower on the remaining two data sets .",
    "however it is worth noting that these data sets are considerably smaller than htru 1 .",
    "this is important , since the performance of the gh - vfdt ( and of other stream algorithms ) improves as more examples are observed .",
    "the lower levels of recall on htru 2 and lotaas 1 are therefore to be expected given the smaller dataset size . in terms of the usefulness of this algorithm for ska data streams , the gh - vfdt returns consistently less than 1 per cent of candidates as false positives .",
    "this greatly reduces the quantity of candidates to be analysed .",
    "the gh - vfdt also classifies candidates rapidly .",
    "it classified candidates at a rate of @xmath93 per second using a single 2.2 ghz quad core mobile cpu ( intel core i7 - 2720qm processor ) when applied to a larger sample of htru 2 data consisting of @xmath94 million examples . a discussion of the statistics of the pulsars incorrectly classified by the new methods will be discussed in a future paper .",
    "this paper has described the pulsar candidate selection process , and contextualised its almost fifty year history . during this time candidate selection procedures",
    "have been continually adapting to the demands of increased data capture rates and rising candidate numbers , which has proven to be difficult .",
    "we have contributed a new solution to these problems by demonstrating eight new features useful for separating pulsar and non - pulsar candidates , and by developing a candidate classification algorithm designed to meet the data processing challenges of the future . together",
    "these enable a high fraction of legitimate pulsar candidates to be extracted from test data , with recall rates reaching almost @xmath95 per cent . when applied to data streams ,",
    "the combination of these features and our algorithm enable over @xmath96 per cent of legitimate pulsar candidates to be recovered .",
    "the corresponding false positive return rate is less than half a percent .",
    "thus together these can be used to significantly reduce the problems associated with high candidate numbers which make pulsar discovery difficult , and go some way towards mitigating the selection problems posed by next generation radio telescopes such as the ska .",
    "the combination of these features and our classification algorithm has already proven useful , aiding in the discovery of 20 new pulsars in data collected during the lofar tied - array all - sky survey @xcite .",
    "details of these discoveries will be provided elsewhere , demonstrating the utility of our contributions in practice .",
    "the features described in this paper are amongst the most rigorously tested in this domain .",
    "however whilst we advocate their use on statistical grounds , we do not demonstrate their superiority to other features",
    ". future work will consider how these compare to those used previously , and determine if combining them with those already in use is worthwhile .",
    "thus for the time being it is advisable to construct as large a set of features as possible , and use the tools described herein to select feature sets statistically .",
    "this work was supported by grant ep / i028099/1 from the uk engineering and physical sciences research council ( epsrc ) .",
    "htru 2 data was obtained by the high time resolution universe collaboration using the parkes observatory , funded by the commonwealth of australia and managed by the csiro .",
    "lofar data was obtained with the help of the dragnet team , supported by erc starting grant 337062 ( pi hessels ) .",
    "we would also like to thank konstantinos sechidis for some insightful discussions with respect to information theoretic feature selection , dan thornton for initially processing htru 2 data , and our reviewer for their helpful feedback .",
    "e.  d. , 2014 , presentation at `` extreme - astrophysics in an ever - changing universe : time - domain astronomy in the 21st century '' , ierapetra , crete , 16 - 20 june 2014 .",
    "http://www3.mpifr-bonn.mpg.de/div/jhs/program_files/ ewanbarrcrete2014.pdf ( accessed january 6th , 2016 )                b. , 2014 , presentation at `` transient key science project meeting 2014 '' , manchester , uk , 9 - 10",
    "september 2014 .",
    "pdfs / bhaswati.pdf ( accessed january 6th , 2016 )                                  s. , 2014 , presentation at lofar science 2014 , amsterdam , the netherlands , 7 - 11 april 2014 .",
    "http://www.astron.nl/lofarscience2014/documents/ tuesday / session%20iii / cooper.pdf ( accessed january 6th , 2016 )                              g. , cognard i. , champion d. , lazarus p. , lespagnol p. , smith d.  a. , theureau , g. , 2012 , iau symposium 291 , astro - ph/1211.3936 r.  j. , taylor j.  h. , weisberg j.  m. , stokes g.  h. , 1985 , apj , 294 , 1 , l25-l29                                                                                              , 2013 , presentation at lofar status meeting , dwingeloo , the netherlands , march 6th , 2013 http://www.lofar.org / wiki / lib / exe / fetch.php?media= public : lsm_new:2013_03_06_hesself.pdf ( accessed january 6th , 2016 )"
  ],
  "abstract_text": [
    "<S> improving survey specifications are causing an exponential rise in pulsar candidate numbers and data volumes . </S>",
    "<S> we study the candidate filters used to mitigate these problems during the past fifty years . </S>",
    "<S> we find that some existing methods such as applying constraints on the total number of candidates collected per observation , may have detrimental effects on the success of pulsar searches . </S>",
    "<S> those methods immune to such effects are found to be ill - equipped to deal with the problems associated with increasing data volumes and candidate numbers , motivating the development of new approaches . </S>",
    "<S> we therefore present a new method designed for on - line operation . </S>",
    "<S> it selects promising candidates using a purpose - built tree - based machine learning classifier , the gaussian hellinger very fast decision tree ( gh - vfdt ) , and a new set of features for describing candidates . </S>",
    "<S> the features have been chosen so as to i ) maximise the separation between candidates arising from noise and those of probable astrophysical origin , and ii ) be as survey - independent as possible . </S>",
    "<S> using these features our new approach can process millions of candidates in seconds ( @xmath01 million every 15 seconds ) , with high levels of pulsar recall ( 90%+ ) . </S>",
    "<S> this technique is therefore applicable to the large volumes of data expected to be produced by the square kilometre array ( ska ) . </S>",
    "<S> use of this approach has assisted in the discovery of 20 new pulsars in data obtained during the lofar tied - array all - sky survey ( lotaas ) .    </S>",
    "<S> [ firstpage ]    pulsars : general , methods : statistical , methods : data analysis </S>"
  ]
}