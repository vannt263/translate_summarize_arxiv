{
  "article_text": [
    "a core component of the work performed by general insurance actuaries involves the assessment , analysis and evaluation of the uncertainty involved in the claim process with a view to assessing appropriate risk margins for inclusion in insurance liabilities .",
    "an appropriate valuation of insurance liabilities including risk margin is one of the most important issues for a general insurer .",
    "risk margin is the component of the value of claims liability that relates to the inherent uncertainty .",
    "the significance of this task is well understood by the actuarial profession and has been debated by both practitioners and academic actuaries alike .",
    "much of the attention involves the non prescriptive nature of risk margin requirements discussed in regulatory guidelines such as article 77 and article 101 of the solvency ii directives . in australia a general task force was established , developing a report on risk margin evaluation methodologies presented to the australian actuarial profession at the institute of actuaries of australia during the 16-th general insurance seminar in 2008 .",
    "this report aimed to highlight approaches to risk margin calculations that are often considered . before briefly discussing these aspects we first note the following solvency ii items which relate to the solvency capital requirement ( scr ) and the risk margin .",
    "article 101 of the solvency ii directive states ,     _ the solvency capital requirement ( scr ) shall correspond to the value - at - risk ( var ) of the basic own funds of an insurance or reinsurance undertaking subject to a confidence level of 99.5% over a one - year period .  _    essentially , the basic own funds are defined as the excess of assets over liabilities , under specific valuation rules . in this regard ,",
    "a core challenge is the capital market - consistent value of insurance liabilities , which requires a best estimate typically defined as the expected present value of future cash flows under solvency ii plus a risk margin calculated using a cost - of - capital approach .",
    "furthermore , under article 77 of the 2009 solvency ii directive it states that the risk margin calculation is described as     _ the risk margin shall be such as to ensure that the value of the technical provisions is equivalent to the amount insurance undertakings would be expected to require in order to take over and meet the insurance obligations ...  it shall be calculated by determining the cost of providing an amount of eligible own funds equal to the solvency capital requirement necessary to support the insurance obligations over the lifetime thereof ...  _    as can be seen from such specifications , the recommendations to be adopted are not prescriptive in the required model approaches .",
    "therefore , as discussed in the white paper produced by the risk margins taskforce 1998 , there have been several approaches considered which range from those that involve little analysis of the underlying claim portfolio to those that involve significant analysis of the uncertainty using a wide range of information and techniques , including stochastic modelling",
    ". they highlighted approaches adopted in practice in the assessment of risk margins and pointed to percentile or quantile methods as being most prevalent in practice , this provides a good foundation for the methods we consider .",
    "traditionally , actuaries that adopt a stochastic framework would evaluate claims liability using a central estimate which is typically defined as the expected value over the entire range of outcomes .",
    "however with the inherent uncertainty that may arise from such an estimator which is not statistically robust and therefore sensitive to outlier claims , claims liability measures often differ from their central estimates . in practice ,",
    "the approach adopted is typically to then set an insurance provision so that , to a specified probability , the provision will eventually be sufficient to cover the run - off claims .",
    "for instance , in order to satisfy the requirement of the australian prudential regulation authority ( apra ) to provide sufficient provision at a 75% probability level , the risk margin should be modelled statistically so that it can capture the inherent uncertainty of the mean estimate .",
    "when this margin is then added to the central estimate , it should provide a reasonable valuation of claims liability and therefore increases the likelihood of providing sufficient provision to meet the level required in gps 320 . in this regard ,",
    "it is worth noting that the more volatile a portfolios runoffs or those that display heavy tailed features may require a higher risk margin , since the potential for large swings in reserves is greater than that of a more stable portfolio .    to accommodate these ideas , two common methods for risk margin estimation have been proposed in practice .",
    "these are the cost of capital and the percentile methods . under the cost of capital method",
    "the actuary determines the risk margin by measuring the return on the capital required to protect against adverse development of those unpaid claim liabilities .",
    "it is evident that application of the cost of capital method requires an estimate of the initial capital to support the unpaid claim liabilities and also the estimate of return on that capital .",
    "alternatively , under the percentile or quantile method that we consider in this paper , which is currently used in australia the actuary takes the perspective that the insurer must be able to meet its liability with some probability under some assumptions on the distribution of liabilities .",
    "risk margin is then calculated by subtracting the central estimate from a predefined critical percentile value .",
    "what we bring to the percentile and quantile based framework in our proposed methods is the ability to incorporate in a rigorous statistical manner , regression factors that may be related to both exogenous features directly related to the insurance claims run - off stochastic process as well as endogenous factors that are related to for instance the current micro or macro economic conditions and the regulatory environment . these will be incorporated into a statistical model that allows one to explain the proportion of variation in the risk margin that is attributed to such features in a principled manner , as we shall demonstrate allowing for accurate estimation and prediction .",
    "we argue that since the percentile - based method involves the estimation of quantiles , it is therefore somewhat natural to consider quantile regression , which is a statistical technique to estimate conditional quantile functions , which can be used to estimate risk margin .    just as classical linear regression methods based on minimizing sums of squared residuals enable one to estimate models for conditional mean functions , quantile regression methods offer a mechanism for estimating models for the conditional median function , and the full range of other conditional quantile functions .",
    "this model allows studying the effect of explanatory variables on the entire conditional distribution of the response variable and not only on its center .",
    "hence we may develop factors and covariates which are explanatory of the risk margin variation directly through the proposed quantile regression framework . by supplementing the estimation of conditional mean functions with techniques for estimating an entire family of conditional quantile functions ,",
    "quantile regression is capable of providing a more complete statistical analysis of the stochastic relationships among random variables .",
    "quantile regression has been applied to a wide range of applications in economics and finance , but has not yet been developed in a claim reserving context for risk margin estimation .",
    "we will demonstrate the features of quantile regression that have been popularized in finance and explain how they can be adopted in important applications in insurance , such as risk margin calculations . in quantitative investment ,",
    "least square regression - based analysis is extensively used in analyzing factor performance , assessing the relative attractiveness of different firms , and monitoring the risks in their portfolios .",
    "engle and manganelli ( 2004 ) consider the quantile regression for the value at risk ( var ) model .",
    "they construct a conditional autoregressive value at risk model ( cavar ) , and employ quantile regression for the estimation .",
    "the risk measure , var is defined as a quantile of the loss distribution of a portfolio within a given time period and a confidence level",
    ". accurate var estimation can help financial institutions maintain appropriate capital levels to cover the risk from the corresponding portfolio .",
    "taylor ( 2006 ) estimate percentile - based risk margins via a parametric model based on the assumption of a log normal distribution of liability .",
    "other sophisticated distributions to capture flexible shapes and tail behaviors are also proposed to model severity distribution on aggregated claim data .",
    "these distributions include the generalized-@xmath0 ( mcdonald and newey , 1988 ) , pareto ( embrechts _ et al . _ , 1997 ) , the stable family ( paulson and faris , 1985 ; peters , byrnes and shevchenko 2011 ; peters , shevchenko , young and yip , 2011 ) , the pearson family ( aiuppa , 1988 ) , the log - gamma and lognormal ( ramlau and hansen , 1988 ) and the lognormal and burr 12 ( cummins _ et al .",
    "_ , 1999 ) , and type ii generalized beta ( gb2 ) distribution ( cummins _ et al .",
    "_ , 1990 , 1999 , 2007 ) .",
    "while these distributions on real support are flexible to model both leptokurtic and platykurtic data , they require log - transformation for claims data and the resulting log - linear model may be more sensitive to low values than large values ( chan _ et al . _ , 2008 ) .    in peters , wuethrich and shevchenko ( 2009 )",
    "they adopt a poisson - tweedie family of models which incorporates families such as normal , compound poisson gamma , positive stable and extreme stable distributions into a family of models .",
    "it was shown how such a generalized regression structure could be used in a claims reserving setting to model the claims process whilst incorporating covariate structures from the loss reserving structure . in this instance",
    "a multiplicative structure for the mean and variance functions was considered and quantiles were derived from modelling the entire distribution , rather than specifically targeting a model at the conditional quantile function .",
    "recently , in dong and chan ( 2013 ) an alternative class of flexible skew and heavy tail models was considered involving the gb2 distribution with positive support adopting dynamic mean functions and mixture model representation to model long tail loss reserving data and showed that gb2 outperforms some conventional distributions such as gamma and generalised gamma .",
    "the gb2 distribution family is very flexible as it includes both heavy - tailed and light - tailed severity distributions , such as gamma , weibull , pareto , burr12 , lognormal and the pearson family , hence providing convenient functional forms to model claims liability . from the perspective of quantile specific regression models , recently cai ( 2010 ) proposed a power - pareto model which allows for flexible quantile functions which can provide a combination of quantile functions for both power and pareto distributions .",
    "these combinations enable the modelling of both the main body and tails of a distribution .",
    "the difference with our current methodology is that instead of developing a statistical model to capture all features of the claims run - off stochastic structure , with the incorporation of regression components , we propose , in this work , to target explicitly the conditional quantile functions in a regression structure . from a statistical perspective , this is a fundamentally different approach to these previously mentioned reserving model approaches .",
    "however we will illustrate that we can borrow from such models in developing our risk margin quantile regression framework .",
    "in fact the associate parameter estimation loss functions , parameter estimator properties and the resulting quantile in sample and out of sample forecasts will significantly differ to those achieved when trying to develop a model for the entire process rather than targeting the quantity of interest in this case , the particular quantile level .",
    "this is clear from the perspective that only under a gaussian distributional assumption for such reserve models ( on log scale ) would a standard least squares approach be optimal from the perspective of gauss - markov theory . in situations where returns are heavy tailed and skewed alternative models will prove more appropriate as we will discuss .",
    "traditional approaches , both frequentist and bayesian , to quantile regression have involved parametric models based on the asymmetric laplace ( al ) distribution . using asymmetric laplace distribution",
    "provides a mechanism for bayesian inference of quantile regression models .",
    "hu et al . (",
    "2012 ) develop a fully bayesian approach for fitting single - index models in conditional quantile regression .",
    "the benefit of using a bayesian procedure , lies in the adoption of available prior information and the provision of a complete predictive distribution for the required reserves ( de alba , 2002 ) .",
    "different bayesian loss reserve models have been proposed for different types of claims data .",
    "( 2012 ) propose a bayesian non linear hierarchical model with growth curves to model the loss development process , using data from individual companies forming various cohorts of claims .",
    "ntzoufras and dellaportas ( 2002 ) investigate various models for outstanding claims problems using a bayesian approach via markov chain monte carlo ( mcmc ) sampling strategy and show that the computational flexibility of a bayesian approach facilitated the implementation of complex models .",
    "the contribution of this paper is three - fold .",
    "first , we propose using quantile regression for loss reserving .",
    "the proposed method , relating the provision to quantile regression allows a direct modelling of risk margin , and hence provision , instead of estimating the mean then applying a risk margin .",
    "it provides a richer characterization of the data , especially when the data is heavy tailed , allowing us to consider the impact of a covariate on the entire distribution , not merely its conditional mean .",
    "secondly , we develop a range of parametric quantile regression models in bayesian framework , each with their own distribution features .",
    "especially , in particular we generalize the al distribution model to incorporate a dynamic mean , variance and the shape parameters to model risk margin via a user friendly bayeisan software winbugs , which is easy for users without much bayeisan background or specialized knowledge of markov chain monte carlo ( mcmc ) methodology .",
    "furthermore , the estimation of shape parameter by accident year gives us an analytical framework to estimate risk margin .",
    "this allows us to capture the feature that the cohort of claims in different accident year may be heterogeneous , and hence applying different different risk margin to different accident year gives us an explicit provision in reserving .",
    "finally , we compare the performance of parametric and nonparametric quantile regressions in the context of loss reserving .",
    "the rest of the paper is organized as follows .",
    "section 2 explains the parametric and non - parametric models proposed .",
    "section 3 presents the posterior quantile regression models in a bayesian framework .",
    "section 4 details the way to calculate risk measures and risk margin using our models .",
    "then we apply the methodology to two real loss reserve data sets in section 5 and 6 .",
    "section 7 concludes .",
    "in this section , we present quantile regression models and explain their relevance to loss reserving , this will be undertaken in both a non - parametric and a parametric modelling framework under the bayesian paradigm . in the process",
    "we propose a novel analytical approach to perform estimation of the risk margin under various quantile regression model structures .",
    "of particular focus in this paper is the class of models based on the asymmetric laplace ( al ) distributional family . in the special case of the al distribution",
    "we demonstrate that risk margin estimation is achieved naturally through the modelling the shape parameters of the al distribution and hence the inference on the model parameters directly informs the inference of the risk margin .    in developing a quantile regression framework for",
    "general insurance claims development triangles we will assume that there is a run - off triangle containing claims development data in which @xmath1 will denote the cumulative claims with indices @xmath2 and @xmath3 , where @xmath4 denotes the accident year and @xmath5 denotes the development year ( cumulative claims can refer to payments , claims incurred , etc ) .",
    "furthermore , without loss of generality , we make the simplifying assumption that the number of accident years is equal to the number of observed development years , that is , @xmath6 with @xmath7 observations . at time",
    "@xmath8 the index set in the _ upper _ triangular is @xmath9 and for claims reserving at time @xmath8 the index set to predict the future claims in the _ lower _ triangle is : @xmath10 therefore the vector of observed @xmath1 in the upper triangle is given by @xmath11 and the corresponding vector of covariates is denoted by @xmath12 . similarly @xmath13 and @xmath14 are the vectors of claims and covariates in the lower triangle .    in the quantile regression structures we will aim to make inference on the quantile function of the data within sample , in each cell of @xmath15 as well as predictive out - off sample quantile function estimation based on the claim cells in @xmath16 in lower triangle .",
    "the estimation of the quantile function regression has three main components :    * the conditional distribution and in this case conditional quantile function of the dependent variables given by the claims data , given the explanatory variables . ; * the structural component of the regression structure based on the link functions and imposed model structures linking the regression structures with the covariates to the location and scale of the conditional distribution and conditional quantile functions of the response . ; * the actual choice of independent variables i.e. the covariates in the regression model , in this case we will also consider some basis function regression structures in some of the models proposed .    in the following sub - sections we discuss each of these components in term , starting with the distributional aspects of the quantile regression models we consider .      in a non - parametric quantile regression approach ,",
    "we perform estimation of regression coefficients without the need to make any assumptions on the distribution of the response , or equivalently the residuals .",
    "if @xmath17 is a set of observed losses and @xmath18 is a vector of covariates that describe @xmath1 .",
    "the quantile function for the log transformed data @xmath19 is @xmath20 where @xmath21 is the quantile level , @xmath22 are the linear model coefficients for quantile level @xmath23 which are estimated by solving @xmath24\\ ] ] and @xmath25 . then the quantile function for the original data is @xmath26 .",
    "koenker and hallock ( 2001 ) illustrate the loss function @xmath27 for quantile regression as we represent in figure [ lossfcn ] .",
    "[ lossfcn ]    koenker and machado ( 1999 ) and yu and moyeed ( 2001 ) show that the solution to minimization of the loss function in equation ( [ eqnlossnonparquant ] ) for estimating the parameter vector @xmath28 is equivalent to maximum likelihood estimation of the parameters of the al distribution .",
    "hence , the parameter vector @xmath28 can be estimated via an al distribution with pdf @xmath29 \\right)\\ ] ] where the skew parameter @xmath30 gives the quantile level @xmath23 , @xmath31 is the scale parameter and @xmath32 is the location parameter .",
    "since the pdf ( [ pdfal ] ) contains the loss function ( [ eqnlossnonparquant ] ) , it is clear that parameter estimates which maximize ( [ pdfal ] ) will minimize ( [ eqnlossnonparquant ] ) .    in this formulation",
    "the al distribution represents the conditional distribution of the observed dependent variables ( responses ) given the covariates .",
    "more precisely , the location parameter @xmath33 of the al distribution links the coefficient vector @xmath28 and associated independent variable covariates in the linear regression model to the location of the al distribution .",
    "it is also worth noting that under this representation it is straightforward to extend the quantile regression model to allow for heteroscedasticity in the response which may vary as a function of the quantile level @xmath23 under study . to achieve this one",
    "can simply add a regression structure linked to the scale parameter @xmath34 in the same manner as was done for the location parameter .",
    "equivalently , we assume @xmath35 conditionally follows an al distribution denoted by @xmath36",
    ". then @xmath37 where @xmath38 , @xmath39 and @xmath40 .",
    "discussion on the choice of link function and structure of regression terms will be undertaken in later sections . in presenting the model in this fashion",
    "we already start to move towards the representation of a parametric quantile regression structure .      alternatively",
    ", we may adopt a parametric approach to study the quantile regression structure .",
    "two types of distributions , on real support @xmath41 or positive support @xmath42 can be considered and we begin with distributions on @xmath41 . in this case , we assume that @xmath43 where @xmath44 is the conditional cumulative distribution function ( cdf ) and @xmath45 is a vector of model parameters including all unknown coefficient parameters and distributional parameters . the quantile function for the conditional distribution of @xmath46 given @xmath47 at a quantile level @xmath48 is given by : @xmath49 under this formulation , the conditional quantile function in ( [ quan ] ) can be written as @xmath50 where @xmath51 is the inverse cdf for the standardized variable @xmath52 and again one may incorporate regression structures given as follows for location and scale functions : @xmath53 to transform the quantile function",
    "@xmath54 back to the original scale of the data @xmath55 , we suggest @xmath26 .",
    "we note that there is no unique way to transform the quantile function @xmath54 for @xmath46 back to @xmath1 and the proposed transformation @xmath26 does not equal in general to the quantile function for the log - al distribution .",
    "* remark : * _ we observe that the difference between the non - parametric and the parametric quantile regression models is that in the parametric structure we make explicit the quantile function of the `` residual '' denoted by @xmath56 . _    for distributions on @xmath42",
    ", we assume that @xmath57 with mean @xmath58 where @xmath59 is given in ( [ eqnloc ] ) .",
    "next we make explicit several possible parametric models one may consider in quantile regressions for risk margin .",
    "each model has different associated properties with regard to the relationship of the skewness , kurtosis and heaviness of the tail that it imposes on the quantile function of the response given the covariates .      as discussed above ,",
    "the al distributional family is a useful model structure which naturally fits into a quantile regression framework .",
    "as made explicit above , the al distribution is a three parameter distribution which has been shown to be directly linked to the estimation of quantiles in a quantile regression framework , see further details in yu and zhang ( 2005 ) .    since this realization",
    ", the al family has been utilized in several financial risk and econometric settings such as guermat and harris ( 2001 ) who use the symmetric laplace distribution with garch volatility to model short - horizon asset returns .",
    "( 2010 ) extend this to allow skewness via al distribution .",
    "yu and moyeed ( 2001 ) apply al distribution for quantile regression purposes , though as yet , no such developments have been made in the insurance and particularly the risk margin context . here",
    "we propose such a model for risk margin estimation .",
    "if we model the residuals @xmath60 by an al distribution , the quantile function for observed data @xmath35 is given by ( [ quanfcnpar ] ) where @xmath61 is the inverse cdf ( quantile function ) @xmath62 to understand how the three location , shape and scale parameters of the al distribution affect the shape and tails of the distribution it is also useful to note the following relationship between the parameters and the mean , variance , skewness @xmath63 and kurtosis @xmath64 of al distribution : @xmath65}{((1-p)^{2}+p^{2})^{3/2 } } , \\hspace{5 mm } k(y ) = \\frac{9p^{4}+6p^{2}(1-p)^{2}+9(1-p)^{4}}{(1 - 2p+2p^{2})^{2}}. \\label{alskew}\\end{aligned}\\ ] ] note that the shape parameter @xmath66 of the al distribution gives the magnitude and direction of skewness .",
    "al distribution is skewed to left when @xmath67 and skewed to right when @xmath68 and hence it can model the left skewness of most log transformed loss data directly through this shape parameter @xmath66 .",
    "moreover as the risk margin adopted in insurance industry is mostly greater than 50 percent , al distribution allows the calculation of quantiles rather than mean estimates fairly easily .",
    "figures [ alpdf](a ) and [ alpdf](b ) show a variety of pdf for al distribution and its skewness and kurtosis respectively .",
    "figure 2 : ( b ) the skewness and kurtosis of asymmetric laplace distribution        [ alpdf ]      as the second choice of parametric quantile regression model we consider the framework of cai ( 2010 ) . in this approach a polynomial power - pareto ( pp )",
    "quantile function model is developed .",
    "this model combines a power distribution with a pareto distribution , which enables us to model both the main body and the tails of a distribution . in considering the pp model the conditional quantile function of the response ( reserve in each cell )",
    "are comprised of two components :    * component 1 : a power distribution @xmath69 where @xmath70 $ ] and @xmath71 with a corresponding quantile function then given by @xmath72 for @xmath73 $ ] ; and * component 2 : a pareto distribution function @xmath74 where @xmath75 and @xmath76 with a corresponding quantile function then given by @xmath77 .",
    "one may use the fact that the product of the two quantile functions will remain a strictly valid quantile function producing the new quantile function family known as the polynomial - power pareto model . the resulting structural form given by the inverse cdf of the pareto distribution with an additional polynomial power term : @xmath78 hence the quantile function",
    "is again given by ( [ quanfcnpar ] ) where @xmath79 and @xmath80 .    from the specification of this quantile function , one",
    "may then derive the resulting pdf of the pp model for @xmath81 which is given by @xmath82 } \\label{pppdf}\\end{aligned}\\ ] ] where @xmath83 is given by solving the system of equations defined for each observation by @xmath84 where again we treat the location @xmath85 in ( [ eqnloc ] ) and scale @xmath86 in ( [ eqnscale ] ) as functions of the regression coefficients and associated covariates .",
    "we note that in this case the @xmath83 is really an implicit function of the regression structure as each @xmath83 is found as the solution to the system of equations in ( [ eqnppcqf ] ) . to complete the specification of the polynomial power pareto model we plot the shape of the density that can be obtained for a range of different power parameters for the power and pareto components with a unit scale factor @xmath87 . these plots in figure [ pppdf ]",
    "demonstrate the flexible skewness , kurtosis and tail features that can be obtained from such a model by varying the parameters @xmath88 and @xmath89 .",
    "[ pppdf ]      we note that the al and pp families of quantile regression models require a log transformation of the data before the modelling to ensure the data has real support @xmath41 that these distributions are defined upon . in performing this transformation , one must analyze carefully the effect of the transformation on the ability to fit such models and the resulting model interpretability must be interpreted with regard to the transformation .",
    "this is particularly the case if zero counts are present in the data for some accident and development years .",
    "moreover , in the context of claims reserving , loss data often exhibits heavy - tailed behavior , particularly for long tail business classes . to account for such features and to remove the need to consider pre - transformation of the data",
    "one may consider the family of generalized beta ( gb2 ) distributions of the second kind .",
    "the type two generalized beta distribution ( gb2 ) has attractive features for modelling loss reserve data , as it has a positive support @xmath42 and nests a number of important distributions as its special cases .",
    "the gb2 distribution has four parameters , which allows it to be expressed in various flexible densities .",
    "see dong and chan ( 2013 ) for a more detailed description of gb2 distribution including its pdf and distribution family .",
    "if @xmath90 conditionally follows a gb2 distribution , then it can be characterized by the density given by @xmath91^{p+q } } , \\hspace{3mm}\\mbox{for $ y_{ij}\\geq0 $ } \\label{gb2pdf}\\ ] ] where @xmath92 and @xmath93 are shape parameters and @xmath94 is the scale parameter .",
    "in particular , @xmath94 can be linked to the mean @xmath33 of the distribution as follows : @xmath95 where @xmath33 is log - linked to a linear function of covariates @xmath59 in ( [ eqnloc ] ) according to the relationship : @xmath96 then the variance is given by : @xmath97 ^ 2 } -1\\right\\}.   \\label{gb2var}\\ ] ] the gb2 distribution is a generalization from the beta distribution with pdf : @xmath98 via the transformation @xmath99 .",
    "hence the cdf of gb2 distribution is given by : @xmath100 where @xmath101 is the incomplete beta function .",
    "the gb2 is directly relevant for quantile regression models since one may also find its quantile function in closed form according to the following expression : @xmath102    there are many widely known and utilized sub - families of the gb2 family , we present two examples of relevance to the context of risk margin estimation that we will explore , corresponding to the generalized gamma and the gamma distribution sub - families .      to understand the flexibility of the gb2 family of models , we consider the case when @xmath103 , then the resulting gb2 distribution sub - family becomes the generalized gamma ( gg ) distribution , see discussion in mcdonald et al .",
    "the gg family of models was independently introduced by stacy ( 1962 ) , as a three parameter distribution with pdf given by : @xmath104^{p+q}}=\\frac{a(\\frac{y_{ij}}{b_{ij}})^{ap}\\exp[-(\\frac{y_{ij}}{b_{ij}})^a]}{y_{ij}\\gamma(p ) } , \\hspace{3mm}\\mbox{for $ y_{ij}>0 $ } \\label{tb}\\ ] ] where @xmath105 and @xmath66 are shape parameters and @xmath94 is scale parameter linked to the mean of the distribution as : @xmath106 and the mean is again log - linked to a linear function of covariates in ( [ mfcn ] ) .",
    "the cdf is @xmath107 where @xmath108 is the lower incomplete gamma function and @xmath109 .",
    "hence , the quantile function is given by : @xmath110    the second case is nested within the gg family and corresponds to the two parameter gamma distribution which is obtained by further restricting @xmath111 .",
    "its pdf and quantile function are well - known and can be expressed using equations ( [ tb ] ) and ( [ tbq ] ) by replacing @xmath105 with 1 .",
    "having defined clearly the three different quantile regression distributional families that will be considered in the parametric quantile regression framework , we now introduce the different regression structures we consider in the quantile regression under each distributional assumption .      in the model structures we will adopt , as is standard practice in regression modelling ,",
    "once we believe we have suitable explanatory variables for the dependent variable quantity of interest , in this case the conditional quantile function , we will assume the observations are independent . in the following subsections",
    "we explain how under each different distributional assumption for the conditional quantile regression structure , one may introduce a link function to relate regression models using independent covariates to the response quantiles in order to model trend behaviors in the location and scale of the quantile function . to simplify all the possible different model considerations we consider only log link functions in all regressions .",
    "the possible regression structures we consider will be classified as : location based explanatory factors i.e. trends in accident and development years ; and scale ( heteroskedascity / variance ) based explanatory factors for accident and development years .",
    "we note that when it comes to different distributional choices since we may transform the observations , we are actually considering both additive and multiplicative ( mixed interaction ) terms in our regressions and as such we explore aspects of anova as well as ancova regression structures in the quantile regression setting .",
    "a summary of the model structures we consider for the location and scale components of each model is provided in table [ tabmodelstruct ] in appendix 1 .",
    "we note that in general one may consider that a version of the ancova model was applied to the pp and al models and a version of the anova model was effectively applied to the al and gb2 families . in addition",
    "we will allow the influence of covariates to affect different quantile levels to different extents , making for an interesting analysis on the effect of model structure on quantile level .",
    "we note that since the focus of this manuscript differs to that undertaken in the poisson - tweedie regression context of peters , shevchenko and wuethrich ( 2009 ) , in that the focus of the regression model comparison will be primarily concerned with the model choice for the distributional form of the conditional quantile function , not so much on the model structure uncertainty related to all possible covariate model sub - space structures and nested models , therefore we limit the analysis to the anova and ancova structures given below . if one is interested in specialized techniques to explore and compare all possible models sub - spaces within each distributional model , we suggest the approach adopted in peters , shevchenko and wuethrich ( 2009 ) or recently in verrall , r.j . and wuthrich , m. ( 2013 )      the primary sets of covariates we consider correspond to the accident year and the development year in the claims reserving structure , as well as transformations of these through basis functions .",
    "from table [ tabmodelstruct ] one may observe that we label models using two subscripts according to their mean and variance functions respectively .",
    "models 0@xmath112 ( denoted by @xmath113 ) and 1@xmath112 ( denoted by @xmath114 ) are parsimonious location structure specifications for the general model in ( [ eqnloc ] ) with @xmath115 , that is , the additive structure is given by : @xmath116 under @xmath113 one assumes a linear trend across accident and development years .",
    "if a non - linear trend across development years is considered with an assumption of common behavior down the accident years , on may consider @xmath114 which is a basis regression model popular in term structure models and known as the nelson - seigel model ( nelson and siegel , 1987 ) .",
    "examples of typical basis functions we considered under this choice for the location are given in figure [ fignsbasis ] below , where we show the ` level ' , ` slope ' and ` curvature ' structure of the location trend from such a model .    ) .",
    "decomposition of the role the level , slope and curvature basis functions play in the regression with example coefficients : @xmath117 , @xmath118 , @xmath119 and @xmath120 with @xmath121 in years.,title=\"fig:\",height=226 ] [ fignsbasis ]    in the context of an anova model specification for the location one can assume a form given by : @xmath122 this location ( trend ) function corresponds to the general model in ( [ eqnloc ] ) with @xmath115 , @xmath123 the parameters @xmath124 and @xmath125 denote the accident year and development year effects respectively and they satisfy the following constraints : @xmath126 this parametrization is set up in the context of loss reserving so that all parameters are relative to the first accident year which has the most information .",
    "these location functions ( [ u0 ] ) to ( [ u1 ] ) apply to both al and pp distributions in general . for gamma ,",
    "gg and gb2 distributions with positive support @xmath42 , a log link function is considered and the location functions become @xmath127 .",
    "when the al distribution , with the shape parameter @xmath128 is applied , model 3@xmath112 ( @xmath129 ) corresponds a nonparametric quantile function @xmath130 where @xmath131 are parameters at quantile level @xmath23 .",
    "there are different choices for the structure of the variance function for the al and pp distributions but gamma , gg and gb2 distributions do not have a component to model @xmath132 directly . model @xmath1120 ( @xmath133 )",
    "assumes homoscedastic variance @xmath134 . models @xmath1120 ( @xmath133 ) to @xmath1123 ( @xmath135 ) are specified below : @xmath136 where the parameters @xmath137 and @xmath138 which denote the accident year and development year effects respectively satisfy the following constraints : @xmath139 again models @xmath1121 to @xmath1122 corresponds to ( [ eqnscale ] ) with @xmath140 and @xmath141 .",
    "furthermore , for model 23 , the shape parameter in the al distribution is further modelled by the accident year effect , which is specified as follows : @xmath142 where the parameters @xmath143 denote the accident year effect and satisfy the following constraints : @xmath144",
    "the estimation of quantile regression models is straightforward to adopt under a bayesian formulation .",
    "one of the key advantage of using bayesian procedures for practical models such as those we develop above lies in the adoption of available prior information and the provision of a complete predictive distribution for the required reserves ( de alba , 2002 ) .    to complete the posterior distribution specification in each model it suffices to consider the representation of two components : the likelihood of the data for the regression structure ( that is , the density not the quantile function ) ; and the prior specifications for the model parameters . in the above sections ,",
    "the quantile function of the likelihood is presented , along with the associated density for the observations conditional upon the parameters and covariates , that is , the likelihood for each model .",
    "therefore , to formulate the bayesian structure we simply need to present the prior structures we consider for the parameters in each model .",
    "this will be relatively straightforward for models formed from the al distribution structure and the gb2 structures , but not so trivial for the case of the pp model .    in the real data examples we consider below , we adopt an objective bayesian perspective in which we consider relatively uninformative priors .",
    "this reflects our lack of prior knowledge for the model parameters likely ranges or magnitudes .",
    "for instance , the priors for parameters ( coefficients ) in mean , variance and skewness quantile regression functions are all selected as gaussian : @xmath145 and for the shape parameters of the gb2 distribution are : @xmath146 normal and gamma distributions are standard choices of priors for parameters with a real and positive support respectively , see discussions on possible choices in denison et .",
    "2002 ) . in the case of the al and gb2 models , these priors combined with the resulting likelihoods",
    "produce in each case standard and well defined posterior distributions",
    ".    in the case of the pp model one has to be careful to define the posterior support to ensure the resulting distribution is normalized and therefore a proper posterior density . to ensure this is the case one must impose constraints on the posterior support which can be uniquely characterized by the three sets of parameter space constraints @xmath147 , @xmath148 and",
    "@xmath149 , for coefficient vectors @xmath150 , @xmath151 and @xmath152 respectively , given by : @xmath153\\times ( 0,\\infty ) , \\;\\ ; m \\in \\re^+.\\\\ \\end{split}\\ ] ] under these parameter space restrictions the resulting posterior for the pp model can be shown to be well defined as a proper density , see a derivation and proof in theorem 1 of cai ( 2010 ) .",
    "in cai ( 2010 ) they consider an mcmc scheme for the resulting posteriors based on standard metropolis - hastings steps with rejection when the proposed parameter values fail to satisfy the posterior support constraints .",
    "in general this results in a very slowly mixing mcmc chain which will have very poor properties .",
    "we replace this idea with simple block metropolis within gibbs updates which allow for smaller moves in each component of the constrained posterior support making it more likely to satisfy the constraints and also simpler to design and tune the proposal for the mcmc scheme .",
    "this was a significant improvement compared to the approach proposed in cai ( 2010 ) .",
    "we implement this sampler in r. for the other bayesian models from the al and gb2 models , sampling from the intractable posterior distributions involved the gibbs sampling algorithm ( smith and roberts , 1993 ; gilks et al . , 1996 ) and",
    "metropolis - hastings algorithm ( hastings , 1970 ; metropolis et al . , 1953 ) are the most popular mcmc techniques . for readers who are less familiar with bayesian computation techniques , we suggest the winbugs ( bayesian analysis using gibbs sampling ) package , see spiegelhalter et al .",
    "the mcmc algorithms that are implemented for each model in winbugs and r are available upon request .    in the gibbs sampling scheme",
    ", a single markov chain is run for 60,000 to 110,000 iterations , discarding the initial 10,000 iterations as the burn - in period to ensure convergence of parameter estimates .",
    "convergence is also carefully checked by the history and autocorrelation function ( acf ) plots .",
    "the every 10-th simulated values from the gibbs sampler after the burn - in period are sampled to mimic a random sample of size 5000 to 10,000 from the joint posterior distribution for posterior inference .",
    "parameter estimates are given by the posterior means .",
    "[ sectionquantilepred ] as discussed in the introduction , the predicted reserves are typically performed in a claims reserving setting by predicting the mean reserve in each cell in the lower triangle @xmath154 .",
    "other methods for reserving may involve the quantification of a risk measure based on the distribution of the predicted reserves , in place of the mean predicted reserve , such as var , expected shortfall ( es ) or spectral risk measures ( srm ) , see discussions in the tutorial review of peters et.al .",
    "in addition , in order to quantify the uncertainty in a central measure for the predicted reserve , one may alternatively take the central measure of reserve and make a risk margin adjustment based on the distribution of the predicted reserves in the form of a quantile function .",
    "when calculating any of these required measures for the resulting total outstanding reserves one requires to first obtain the predictive density , which under the bayesian setting can be obtained for instance in one of the following two ways for each @xmath155 :    * * full predictive posterior distribution : * @xmath156 here , all posterior parameter uncertainty is integrated out of the predictive distribution . *",
    "* conditional predictive posterior distribution : * @xmath157 where the point estimator @xmath158 contains the information from the upper triangle . examples of common estimators include the posterior mean @xmath159 or mode @xmath160 .    using these predictive distributions ,",
    "one may also be interested in quantities such as the distribution of the total outstanding claim given by the sum of the losses in the lower triangle according to the random variable @xmath161 which has distribution given under the full predictive posterior distribution according to convolution given by @xmath162 where , one convolves the distributions for the loss elements in the lower triangle with @xmath163 the convolution operator .",
    "one can then state several features about the tail behavior of the total loss distribution and also therefore of the high quantiles as @xmath164 , depending on the properties of the individual loss random variables in the sum .",
    "for instance , if one has loss distributions on @xmath42 then one can obtain the lower bound given by @xmath165 for some @xmath166 .",
    "note , if at least one of the lower triangle losses @xmath1 is distributed according to a heavy tailed loss distribution , such as sub - exponential , regularly varying or long tailed loss distributions then one can find the precise value for @xmath167 .",
    "for instance if the total loss is max - sum equivalent , then @xmath168 , see definitions for regular variation , sub - exponential , long tailed and max - sum equivalence in bingham et al .",
    "( 1989 ) and in the context of insurance and quantile function approximations as discussed here , see the recent tutorial and references therein from peters et al .",
    "( 2013 ) .    these conditional predictive distributions can be obtained for any model approximately by solving the integrals using the markov chain monte carlo samples obtained from the posterior @xmath169 .",
    "then , given a predictive distribution , one can then find quantile functions according to the following approaches :    * * full predictive posterior quantile function : * is given by @xmath170 which is the solution to the second order ordinary differential equation : @xmath171 which is obtained by twice differentiating the following identity : @xmath172 the solution to this second order ordinary differential equation can often be found in the form of a power series , see discussions in gyorgy and shaw ( 2008 ) .",
    "* * conditional predictive posterior quantile function : * @xmath173 which is the most convenient choice that we recommend since the inverse of the predictive distribution in this case takes the closed form expressions for the particular model considered as detailed in section 2.2 .",
    "* * conditional total reserve posterior quantile function : * in many cases one is also interested in finding the quantile function of the distribution corresponding to the total reserve , which under conditional independence is given by @xmath174 where this is given by the quantile function of the distribution in equation [ eqnconvexp ] . in general",
    "finding the convolution and inverse of this convolved distribution must be done numerically .",
    "there are many basic results known about these quantities such as asymptotic results and bounds for different properties of light and heavy tailed random variables , independent or dependent , see a discussion in kaas et al .",
    "( 2000 ) . + * light tailed run - off for claims process : * in the case in which no loss cells in the claims triangle are heavy tailed , then in general one would need to approximate the tail quantile for the partial sum of all losses . in kaas",
    "et al . ( 2000 ) they study partial sums of random variables with no assumption of independence or of identical marginal distributions .",
    "the only assumption is that the tails are not so heavy for each marginal , such that each marginal has finite mean",
    ". it will be useful to recall that for two random variables @xmath175 and @xmath176 , @xmath175 proceeds @xmath176 under convex ordering @xmath177 iff for all convex real functions @xmath178 with finite expectations one has",
    "@xmath179 \\leq \\mathbb{e}\\left[g(y)\\right].\\ ] ] thus , two random variables x and y with equal mean are convex ordered if their cdfs cross once .",
    "+ then one can show that in such cases for any sequence of loss distributions @xmath180 the following convex order relationship holds @xmath181 for @xmath182 $ ] , see derivations in goovaerts et al .",
    "this result means that the total loss @xmath183 in the convex order sense , comprised of the most risky joint vector of losses with given marginals , has the comonotonous joint distribution .",
    "the components of which are maximally dependent since all components are non - decreasing functions of a common random variable @xmath184 .",
    "+ hence , we consider the following quantile function approximation for the total loss based on the most conservative estimate using the above bound , given by @xmath185 note , in the case of heavy tailed losses this can be refined for large quantiles as follows .",
    "+ * heavy tailed run - off for claims process : * alternatively , if additional features of the loss distributions in the lower triangle are known , such as these loss models contain at least one heavy tailed loss distribution , then one can bound the total quantile function result .",
    "this can be done conservatively by instead considering the @xmath186-fold convolution of the distribution , say @xmath187 which correspond to the loss distribution amongst all the lower trianglular loss elements with the dominant index of regular variation ( that is , with the heaviest tails ) .",
    "in such cases it would be popular to utilize an asymptotic result for the quantile function of the sum , as the quantile level becomes large @xmath188 .",
    "for instance , one could use the first order or second order asymptotic results , see discussions in peters et al .",
    "( 2013 ) and cruz et al .",
    "( 2014 ) . as an example , if the quantile regression was structured such that the distribution of the partial sum @xmath189 is regularly varying with index @xmath190 with conditionally i.i.d .",
    "@xmath1 with each @xmath1 taking positive support , then one can write the first order tail approximation which is asymptotically equivalent to the following @xmath191 see detailed tutorial in peters et al .",
    "this would lead to the approximation of the required quantile asymptotically by the expression @xmath192",
    "in this section we perform two core studies : the first involves isolating the structural components for the quantile regressions , in order to perform a study on the mean function and variance functions that are most suitable for an example of a representative claims reserving data set .",
    "this is therefore performed using the non - parametric and bayesian formulations of the al model with different assumptions on the mean and variance functions .",
    "the second involves isolating the distributional choices of the quantile regression , where we take the best fitting parametric model mean and variance function structures and use these to study distributional properties under the different quantile function choices .",
    "the data set used throughout this section is interesting for such a benchmark exercise as it has been previously studied and its features are reasonably well known , see chan et al .",
    "( 2008 ) for more details on the israel data set .",
    "the data is available in figure [ israeldata ] in appendix i and represents the paid out claim amounts @xmath193 for an israel insurance company , covering periods from 1978 to 1995 , containing 171 observations . for mathematical convenience ,",
    "two zero claim amounts have been replaced with 0.01 .",
    "some general trends are observed in this data .",
    "given an accident year , the claim development amounts generally increase between the first 4 to 6 development years then this increase is followed by a generally decreasing trend thereafter .",
    "the mean , median , variance and kurtosis of this data are 4459.7 , 3,871 , 12,059,232.6 and -0.4 respectively .",
    "the overall skewness is 0.58 and on a log scale is -2.67 .",
    "this data has been studied in chan et al .",
    "( 2008 ) using the generalized-@xmath0 ( gt ) distribution expressed as scale mixtures of uniform which facilitates the bayesian implementation .",
    "they adopt the anova and ancova mean structures to study the accident year and development year effects on the conditional mean functions but not on any quantile level .",
    "moreover they also remark that the log transformed data become negatively skewed which the symmetric gt distribution fails to accommodate .",
    "hence , they suggest to adopt some skewed error distributions to improve the model performance .    our primary point of departure for these previous studies on this data is the conjecture that using a measure of average effects may not be appropriate for understanding loss reserves at higher quantiles .",
    "higher quantile projection is critical in loss reserving , for reinsurance premium calculations and also in deriving the risk margin . in this section",
    ", we use all the models in section 2 for quantile projection with an aim to provide a more comprehensive study on model performance with a wide range of distributions having different tails behavior and model structures for the quantile trends and heteroscedasticity in the accident and development years .      to investigate the model structures for location ( mean ) and scale ( variance ) functions , we consider two settings : the first class of models involves the parametric models using the al distribution with @xmath66 either fixed ( denoted by fix ) or left to be estimated ( denoted by est ) , the mean functions given by ( [ u0 ] ) to ( [ u1 ] ) and variance being constant ( models 00 - 20 ) or given by ( [ varij ] ) ( models 03 - 23 ) ; the second class of models involves a set of nonparametric models which are also studied with mean function ( [ u1 ] ) and variance being constant or given by ( [ varij ] ) ( models 30 and 33 ) using al as a proxy distribution with @xmath66 fixed at different quantile levels .    for model comparison , deviance information criterion ( dic )",
    "is adopted , see appendix iii for details . since , models with smaller @xmath194 are preferred to those with larger @xmath194 , then the results of the model comparisons provided in table [ npparmodelfit ] show that among the parametric models , @xmath195 which incorporates an anova model for both accident and development years in modelling both the mean and variance functions is the best fitting model according to @xmath194 .",
    "this show that the accident year and development year effects are both important in describing the dynamics of the mean and variance .",
    "hence , these anova - type mean and variance functions are applied to most of the subsequent analyses whenever possible . for",
    "the nonparametric models , @xmath196 with anova variance provide better fit than @xmath197 with constant variance .",
    "@xmath198   &  @xmath199   & @xmath66 & models &  @xmath194   &  @xmath198   &  @xmath199   &  @xmath66   + & & & + @xmath200 & 195.41 & 255.21 & 315.02 & 0.85 ( est ) & @xmath201 & 272.82 & 334.74 & 396.66 & 0.93 ( est ) + @xmath202 & 223.30 & 284.10 & 344.91 & 0.88 ( est ) & @xmath203 & 199.14 & 247.49 & 295.85 & 0.95 ( est ) + @xmath204 & 50.94 & 120.17 & 189.40 & 0.81 ( est ) & @xmath195 & -20.81 & 24.91 & 70.63 & 0.75 ( est ) + @xmath197 & 55.94 & 125.61 & 195.28 & 0.30 ( fix ) & @xmath196 & -37.06 & 38.34 & 113.74 & 0.30 ( fix ) + @xmath197 & 73.10 & 152.26 & 231.43 & 0.50 ( fix ) & @xmath196 & -38.80 & 35.51 & 109.82 & 0.50 ( fix ) + @xmath197 & 55.26 & 132.56 & 209.87 & 0.75 ( fix ) & @xmath196 & -17.33 & 53.40 & 124.12 & 0.75 ( fix ) + @xmath197 & 44.86 & 116.38 & 187.91 & 0.95 ( fix ) & @xmath196 & -64.26 & 3.68 & 71.62 & 0.95 ( fix ) +    between parametric model @xmath195 and nonparametric models @xmath196 , the nonparametric models provide better model performance according to @xmath194 .",
    "these models correspond to the al models with mean and variance functions and we study their performances for a range of fixed quantile levels @xmath205 as shown in figure [ qqplot ] .",
    "this plot demonstrates the quantile - quantile plot for the fitted models at different quantile levels , indicating appropriate fits from the specified model structures for a range of different quantile levels .     at different quantile levels , width=529,height=377 ]    [ qqplot ]    in addition , we investigate the trends of development year effects as depicted in figure [ yearonequan ] which reports the fitted loss @xmath206 where @xmath207 is given by ( [ u1 ] ) and calculated using the conditional predictive posterior quantile function in ( [ eqn : pred2 ] ) for the first accident year ( @xmath208 ) .",
    "the quantile levels @xmath23 correspond to the shape parameter @xmath66 set to 0.3 , 0.5 , 0.75 and 0.95 respectively in al distribution .",
    "the figure demonstrates that there is a clear requirement for a nonlinear trend in the development year covariate at all quantile levels which uniformly increases up until @xmath209 and subsequently decreases thereafter at all quantile levels .",
    "furthermore , the trends of fitted loss at all quantile levels agree with this observed trend .     with al distribution , title=\"fig:\",width=453,height=207 ] [ yearonequan ]    to conclude the benchmark analysis on model structure we also present for the best model @xmath196 with mean and variance functions the estimated model trends for all accident years , depicted in figure [ heatmap ] as five triangular heat maps .",
    "the heat maps each depict the fitted loss by accident and development years in the upper triangle at all five quantile levels , where the first row corresponds to that which was studied in figure [ yearonequan ] .",
    "all heat maps show a consistent trend across development years for all accident years and quantile levels with high levels of loss as indicated by light colours being around the fourth development year , particularly for lower accident years . with increasing quantile levels , the width of light colours for each accident year increases showing higher levels of fitted losses around the peak .     with al distribution , title=\"fig:\",width=302,height=170 ]   with al distribution , title=\"fig:\",width=302,height=170 ]     with al distribution , title=\"fig:\",width=302,height=170",
    "]   with al distribution , title=\"fig:\",width=302,height=170 ]    [ heatmap ]    although nonparametric models have lower @xmath194 values , table [ npparmodelfit ] shows that parametric model @xmath195 actually provides comparable model fit according to @xmath210s before model complexity penalty was applied .",
    "this is because parametric models with additional shape parameters are subject to heavier model complexity penalty .",
    "however it should be noted that parametric models provide better model fit in general over a range of models and quantile levels .",
    "in addition , the parametric models have a significant advantage that they will be more readily interpretable as well as directly usable when calculating risk margins and quantile based risk measures as long as the quantile functions are in closed form , as was discussed in section [ sectionquantilepred ] . for the mean structure corresponding to model choice @xmath211 under parametric model we also studied different variance structures , in order to explore the different choices of variance functions under the al distribution .",
    "@xmath212   &  @xmath213   &  @xmath214   &  @xmath66   &   @xmath132   + @xmath204 & 50.94 & 120.17 & 189.40 & 1015.71 & 0.80 & 0.02 + @xmath215 & -4.32 & 56.66 & 117.64 & 849.91 & 0.74 & 0.04 + @xmath216 & 6.63 & 54.29 & 101.95 & 755.66 & 0.68 & 0.19 + @xmath195 & -20.81 & 24.91&70.63 & 850.10 & 0.75 & 0.17 +    again , we confirm that amongst all models with al distribution , @xmath195 which incorporates both accident and development year effects for the mean and variance demonstrates the best model fit according to @xmath194 . on the other hand",
    ", @xmath214 favors @xmath216 which adopts only development year effect for the variance .",
    "one possible reason might be that the payments made in different accident years are relatively stable compared to those across development years , and hence the development year effect dominates in the variance estimation .      in this section",
    "we analyze the different model choices from the distributional perspective .",
    "this is not directly trivial to achieve , since each model has different features that must be taken into consideration in the comparison .",
    "it is clear from previous studies that one should always utilize an anova - type mean function with accident and development years effect ( @xmath211 ) , or at a minimum incorporate a quadratic or basis function form for the development year effects such as @xmath217 . in the case of the gb2 and al models we will therefore consider mean structures in @xmath211 .",
    "however , in the case of the pp model we will consider @xmath217 , since purely from a computational perspective it will be easier to implement an efficient mcmc sampler for @xmath217 compared to @xmath211 .",
    "the reason for this is due to the rejection stage in the metropolis - hastings acceptance probability where under the pp model the posterior constraint regions will be easier to satisfy with less model complexity . in terms of the variance functions ,",
    "when working with the gb2 models , we will consider @xmath211 in which we do not specify variance functions as there is no variance parameter in the distribution to model the variance directly .",
    "the variance of the models are given by ( [ gb2var ] ) .",
    "then in the case of the al model we consider @xmath204 as well as @xmath195 and for the pp model we consider @xmath202 and @xmath203 .",
    "table [ parmodelfit ] reports the results split according to models with constant , unspecified and dynamic variance functions . in the case of constant or unspecified variance ,",
    "the best performing model is again the al model , followed by the gg model . among distributions in the gb2 family with positive support ,",
    "gg provides the best model fit according to @xmath194 with model complexity penalty while gb2 model provides the best model prediction according to @xmath214 . comparing @xmath210s without model complexity penalty , gg and gb2",
    "provide very similar model fit .",
    "besides , it is clear that the pp model with only the basis function regression structure for the mean , given by a quadratic polynomial for the trend in the development year covariate , and a constant variance was not sufficient to capture all the features required .",
    "we believe that this is largely due to the fact that such a model is more suitable for heavy tailed run - off in the claims development and the israel data clearly does not display such a feature .",
    "it is therefore expected that such a heavy tailed quantile regression model will not perform as well for this data .",
    "when the variance is also modeled , the al model is clearly significantly better than all the other models considered , again making @xmath195 with al model optimal compared to all choices . since",
    ", the pp model is shown to be not suitable for this data , we will consider analyses going forward with only the gb2 and al models .",
    "@xmath212   &  @xmath213   &  @xmath214   &  @xmath105   &  @xmath66   &  @xmath93   & @xmath132   +   + @xmath211 gamma & 3064.50 & 3028.93 & 2993.36 & 537.82 & 1 & 1.87 & @xmath218 & - + @xmath211 gg & 2707.42 & 2932.97 & 3158.52 & 582.78 & 33.22 & 0.08 &",
    "@xmath218 & - + @xmath211 gb2 & 3002.82 & 2964.60 & 2926.37 & 526.65 & -7.94 & 1.78 & 0.17 & - +   + @xmath202 pp & 3272.14 & 1021.71 & 1230.01 & 1132.12 & - & - & - & 14.15 + @xmath204 al & 50.94 & 120.17 & 189.40 & 1015.71 & - & 0.80 & - & 0.02 +   + @xmath203 pp & 1502.19 & 1906.49 & 2310.98 & 923.00 & - & - & - & 9.10 + @xmath195 al & -20.81 & 24.91 & 70.63 & 850.10 & - & 0.75 & - & 0.17 +    next , we compare the standardized residuals for the gb2 , gamma and gg models under structure in @xmath211 against the best fitting al model , that is @xmath195 with @xmath219 .",
    "we first assess how well these models perform in sample , by looking at the following fitted model densities , versus the histograms of standardized residuals , displayed in figure [ residplot ] .",
    "this plot shows that @xmath211 with gb2 distribution and @xmath195 with al distribution and @xmath219 provide good fit to the standardized residuals whereas gamma distribution provides the worst fit .",
    "[ residplot ]    then , for out of sample analysis we display in figure [ percentile ] the median predicted total claim reserve under the gb2 and al ( @xmath220 ) models . to compare these models for the out - of sample predictions we compare fitted losses of the four models by plotting @xmath221 against the percentile p where @xmath221 refers to the p - th percentile of all @xmath222 in the upper triangle arranged in ascending order .",
    "we can see that the fitted losses using al model are closest to the observed losses , gg and gb2 models provide very similar fitted losses and gamma model provides the poorest fit .",
    "[ percentile ]     @xmath223   &  @xmath224   &  @xmath225   &  @xmath226   + observed & 1,985 & 3,871 & 6,990 & 9,327 & 10,200 + @xmath211 gamma & 2,760 & 4,496 & 8,036 & 9,600 & 10,700 + @xmath211 gg & 2,378 & 4,498 & 6,451 & 7,486 & 8,040 + @xmath211 gb2 & 2,480 & 4,463 & 6,526 & 7,737 &",
    "8,247 + @xmath195 al ( @xmath220 ) & 2,255 & 3,734 & 6,422 & 8,696 & 9,715 +    table [ ppredquan ] reports the observed and fitted loss @xmath221 for p = 0.3 , 0.5 , 0.75 , 0.9 and 0.95 using the four models . as the model assessments show adequate model fits , we apply the models to predict losses at different quantile levels .",
    "figure [ boxplot ] presents boxplots of quantiles @xmath227 for losses in each cell of the upper triangle for a given quantile level @xmath23 and model . comparing across models , the boxplots for al model have the heaviest right tails and the ranges of boxplots differ more at higher quantile level .",
    "in particular , the ranges for gamma and al models increase much faster across quantile levels than the gg and gb2 models .",
    "[ boxplot ]    these features can also be observed in figure [ qpredquan ] which plot quantiles @xmath227 in each boxplot in ascending order .",
    "this is similar to figure [ percentile ] but the percentile of quantiles @xmath228 instead of fitted @xmath229 is plotted against the percentile p. each line in figure [ qpredquan ] corresponds to a quantile level @xmath230 and 0.95 .",
    "these so called empirical quantile lines are dense for gg model , sparse for gamma model and moderate for gb2 model indicating that gb2 distribution provides quantile estimates which can reasonably cover the observed losses across percentile p when the quantile level @xmath23 gradually increases .",
    "we also remark that the empirical quantiles for al model in the log scale are convex rather than concave and are more dense because of the log transformation .",
    "[ qpredquan ]    then figure [ quanfcnmean ] plots the quantile functions @xmath231 across quantile levels @xmath21 using ( [ quanfcngb2 ] ) for gamma , gg and gb2 in the gb2 family of distributions and @xmath232 in ( [ quanfcnpar ] ) where @xmath233 is given by ( [ invcdfal ] ) for al distribution . note that the mean @xmath234 in @xmath231 or @xmath235 in @xmath232 is given by the average of @xmath236 or @xmath237 over risk cells in the upper triangle .",
    "again al distribution has the heaviest right tail because of the log transformation .",
    "[ quanfcnmean ]    we further adopt these models to calculate the outstanding reserves ( or ) as reported in table [ predosquan ] using the conditional predictive posterior approach in ( [ quantilefortotal ] ) where the conditional total reserve posterior quantile function is adopted for the case of light tailed run - off in the claim process because the claim distribution was shown to be light tailed in the previous analyses . under the solvency ii framework",
    ", insurers will have to establish technical provisions to cover future claims expected from policyholders .",
    "insurers must also have available financial resources sufficient to cover both a minimum capital requirement and a scr .",
    "the scr is based on a var measure calibrated to a 99.5 percent confidence level over a one - year time horizon .",
    "results in table [ predosquan ] show that the or projection increases gradually up to 95 percentile quantile levels but increases dramatically at 99.5 percentile .",
    "@xmath223   &  @xmath224   &  @xmath225   &  @xmath226   &  @xmath238   + @xmath211 gamma & 127,816 & 198,907 & 324,515 & 474,073 & 581,302 & 920,142 + @xmath211 gg & 203,207 & 248,409 & 291,457 & 314,482 & 323,346 & 337,658 + @xmath211 gb2 & 152,315 & 225,017 & 311,625 & 377,154 & 413,525 & 512,731 + @xmath195 al & 145,031 & 176,926 & 314,454 & 435,402 & 462,980 & 560,430 +",
    "in general the guidance on calculation of risk margin by regulators leaves flexibility in the practical modelling approach adopted by practitioners .",
    "there are a few popular approaches considered in practice , some of which involve a degree of expert opinion . in this section",
    "we aim to consider only approaches based on statistical models and in particular percentile and quantile based methods . in this context",
    "the standard practice is to consider the reserve estimate and then try to quantify the uncertainty associated with the reserve estimator .",
    "this uncertainty is typically measured via a standard error , which is utilized to adjust the reserve .",
    "traditionally , if a loss distribution produces an estimator for the reserve which admits a normal distribution ( approximately under a central limit theorem result ) , then setting the risk margin to equal the sample estimator for the reserve plus 0.675 times the sample estimators standard deviation would result in risk margins calibrated to approximately the 75th percentile .",
    "note , whilst the total loss distribution may not have finite second moment if a heavy tailed run - off is present , the variance of the sample estimator for the distribution of the reserve will always be well defined .",
    "it should be noted that this method suffers from drawbacks as there is both an influential judgment in determining the appropriate multiple , especially when the normality assumption is not present due to sample estimators distribution being skewed .",
    "alternatively , one may utilize the quantile regression model obtained for the total loss distribution .",
    "there are two basic ways this may be achieved , for instance one could take instead of a mean reserve , a quantile based reserve",
    ". this could be via a risk measure such as var which represents a tail quantile of the total loss distribution at say 99.95% , in which case one may judge that a conservative measure of reserve is obtained from such a tail measure and so no additional risk margin is required .",
    "this is standard in banking regulations such as basel ii / iii and being considered in insurance regulations .",
    "alternatively , one may take a central measure as the reserve such as the median of the total loss distribution and make a risk margin adjustment based on the tail quantile of the total loss distribution at say 75% ( as is considered in practice ) .",
    "thirdly , if the traditionally utilized estimate of reserve based on the mean of the loss distribution is considered , then two scenarios may arise if one uses the risk margin adjustment based on the tail quantile of the total loss distribution at say 75% . in this case",
    "the estimated mean reserve could be below the desired risk margin quantile level of the total loss distribution , in which case it may be reasonable to make no further adjustment if the risk margin is already at a tail quantile such as 75% .",
    "alternatively , if the estimated mean reserve is below the desired risk margin quantile level of the total loss distribution , then the difference would be the resulting risk margin .    in this section , we are going to extend the best model , model @xmath195 with al distribution , in the previous sections to model risk margin statistically . to achieve this ,",
    "we generalise the al distribution to model the shape parameter @xmath66 via the following regression @xmath239 where @xmath240 is the intercept and @xmath241 denotes accident year effect .",
    "accident year effect is chosen because risk capital allocation is by accident years .",
    "it is worth noting an important assumption which are stated as underlying this method : actual outstanding claim payments are assumed to be uncorrelated between accident years .",
    "therefore , the estimated shape parameter @xmath66 , which presents quantile in al distribution , and also infers risk margin in the percentile method , is an applicable risk margin estimate for outstanding claims payments .",
    "the difference between our proposed method and the traditional method is also demonstrated in figure [ d1 ] .",
    "[ d1 ]    the data that we used to demonstrate our model is the amount of payments for all the compulsory third party ( ctp ) policies in queensland ( qld ) as of june 2008 .",
    "ctp insurance policy covers risk that would be referred to as auto bodily injury in the u.s . and motor bodily injury in the u.k .. the data are in the units of millions summarized by accident and development quarters covering periods from december 2002 to june 2008 .",
    "it contains 276 observations over 23 accident quarters . in order to remove the influence of inflation for reserving purposes",
    ", we utilize the average weekly earning index from the australian bureau of statistics ( abs ) to inflate all the values to december 2008 dollars .",
    "hence , the data used in this analysis represents the inflated cumulative payment for qld ctp portfolio as reported in figure [ qldctppayment ] in appendix i.    to review features of the data , figure [ qldctpvar ] plots the observed variance across accident year on original and log scale .",
    "it shows that the variance fluctuates a lot across accident year on the original scale but displays a sharp drop on the log scale .",
    "figure [ qldctpskew ] shows that the skewness are mostly negative on the original and log scales .",
    "the overall skewness of the data is 0.61 and that on a log scale is -1.08 .",
    "trend of skewness reveals a sharp drop at the start and then it fluctuates across accident years for data on the original scale but increases monotony for data on the log scale .",
    "these changes confirm the necessity of adopting dynamic variance and skewness in modelling the data .    among choices of distributions ,",
    "the al distribution allow flexibility in modelling variance and skewness through modelling directly the scale and shape parameters @xmath132 and @xmath66 respectively .",
    "furthermore , in the context of nonparametric regression using al as a proxy distribution for model implementation , @xmath66 indicates the quantile level of a model which corresponds to risk margin in loss reserving . in the analysis of qld ctp data , we adopt the anova type model ( @xmath195 ) for the mean and variance as it has been shown to provide the best model performance .",
    "we further propose modelling the risk margin @xmath66 as a linear function of accident year .",
    "one reason is that as accident year increases , there are more uncertainty involved in estimating the reserves ; hence it is an important factor in risk margin estimation .",
    "this model is called @xmath242 in the appendix .",
    "[ qldctpvar ]        [ qldctpskew ]    then @xmath242 with dynamic variance and skewness is compared to two models , @xmath204 with constant variance and skewness and @xmath195 with just dynamic variance in table [ riskmargin ] .",
    "although @xmath204 outperform @xmath242 according to @xmath194 , @xmath242 provides the best model fit according to @xmath210 which measures model fit alone , discounting model complexity penalty . as our aim is to provide the most accurate risk margin estimates , we adopt @xmath242 in the subsequent risk margin analysis . from a modelling perspective",
    ", it reconciles with our risk margin estimation approach .",
    "@xmath212   &  @xmath213   & @xmath243 & @xmath244 & @xmath245 + @xmath204 constant variance & skewness & -322.55 & -215.65 & -108.75 & 4.33 & 0.008 & -0.28 + @xmath195 dynamic variance & -311.36 & -197.71 & -84.06 & 7.67 & 0.22 & -0.57 + @xmath242 dynamic variance & skewness & -255.03 & -229.46 & -203.90 & 4.77 & 0.10 & -0.18 +    figure [ m20 ] demonstrates how the estimated risk margin @xmath246 changes across accident years , superimposed with its creditable interval .",
    "figure [ m200 ] displays the corresponding changes in estimated variance and skewness using the variance and skewness equations in ( [ alvar ] ) and ( [ alskew ] ) respectively .",
    "the risk margin @xmath247 starts at 0.895 at accident year 1 when the variance is quite high .",
    "afterwards , it decreases gradually to 0.439 in accident year 8 when the variance is much smaller . from accident year",
    "17 onwards , the risk margin increases again when the variance is large and there are more development years ahead . in actuarial practice , the calculation of the risk margin is often not based on a sound model but various simplified methods are used .",
    "this approach enables us to calculate a risk margin for non - life insurance run - off liabilities in a mathematically consistent way , and provides reasonable risk margin estimates .     across accident year using @xmath242 for risk margin analysis , width=377,height=188 ]    [ m20 ]     for risk margin analysis , width=377,height=188 ]    [ m200 ]",
    "we have applied the quantile regression model to estimate loss reserve and risk margin .",
    "quantile regression reveals relationships between responses at the upper or lower quantiles , which is of significant interest in estimating risk margin and var in insurance and finance applications .",
    "compared to mean regression , it is more robust to heavy tailed data .",
    "we compare the performance of parametric and non - parametric quantile regression . in the parametric framework",
    ", we built five models , namely al , pp , gb2 , gg and gamma .",
    "the al model provides the best fit .",
    "we also investigate three different regression structures , namely ancova , anova and poisson - tweedie regression .",
    "the anova model performs the best in our empirical data study .",
    "furthermore , we adopt the best performed model , which is the al model with anova mean and variance functions , to estimate risk margin .",
    "the generalized al model with a dynamic shape parameter @xmath66 provides us a mathematically consistent way of estimating risk margin .",
    "overall , the results of our studies indicate that this new risk margins framework offers considerable potential benefits for reserving purpose . however , the drawback is that quantile functions may cross over particularly at extreme quantiles when data are rare .",
    "extreme quantile may not be estimated precisely .",
    "although there is no simple solution to this problem yet , we believe it is important to be aware of this limitation when using this framework .",
    "10 australian prudential regulatory authority , prudential standard gps 320 , actuarial and related matters .",
    "( may 2012 ) .",
    "bingham , n.h . ,",
    "goldie , c.m . , and teugels , j.l .",
    "( 1989 ) regular variation .",
    "cambridge university press .",
    "cai , y. ( 2010 ) polynomial power - pareto quantile function models .",
    "_ extremes _ , * 13 * , 291 - 314 .",
    "claeskens , g , and hjort , n.l .",
    "model selection and model averaging , cambridge .",
    "cruz ,  m.  g. and peters ,  g.  w. and shevchenko ,  p.  v. ( 2014 ) advances in heavy tailed risk modeling : a handbook of operational risk , john wiley & sons .",
    "cummins , j.d . , mcdonald , j.b . and craig , m. ( 2007 ) risk loss distributions and modelling the loss reserve pay - out tail",
    ". _ review of applied economics _ , * 3 ( 1 - 2 ) * , 1 - 23 .",
    "chan , j.s.k . ,",
    "choy , s.t.b . and makov , u.e .",
    "( 2008 ) robust bayesian analysis of loss reserves data using the generalized - t distribution .",
    "_ astin bulletin _",
    ", * 38 ( 1 ) * , 207 - 230 .",
    "dong , a.x.d . and",
    "chan , j.s.k .",
    "( 2013 ) bayesian analysis of loss reserving using dynamic models with generalized beta distribution .",
    "_ insurance : mathematics and economics _ , * 53 ( 2 ) * , 355 - 365 .",
    "denison , d.g.t .",
    ", holmes , c.c . , mallick , b.k . and smith , a.f.m .",
    "( 2002 ) bayesian methods for nonlinear classification and regression _",
    "wiley_. de alba , e. ( 2002 ) bayesian estimation of outstanding claim reserves . _ north american actuarial journal _ ,",
    "* 6 ( 4 ) * , 1 - 20 .",
    "engle , r. and manganelli , s. ( 2004 ) caviar : conditional autoregressive value at risk by regression quantiles .",
    "_ journal of business and economic statistics _ , * 22 ( 4 ) * , 367 - 381 . goovaerts , m.j . ,",
    "dhaene , j. , de schepper , a. , ( 2000 ) .",
    "stochastic upper bounds for present value functions .",
    "_ journal of risk and insurance theory _ , * 67 ( 1 ) * , 1 - 14 .",
    "hu , y. , grimacy , r. b. , and lian , h. ( 2012 ) .",
    "bayesian quantile regression for single - index models .",
    "_ statistics and computing _ , * 23 ( 4 ) * , 437 - 454 .",
    "kaas , r. , dhaene , j. , and goovaerts m. ( 2000 ) upper and lower bounds for sums of random variables .",
    "_ insurance : mathematics and economics _ , * 27 ( 2 ) * , 151 - 168 .",
    "koenker , r. , and k. hallock ( 2001 ) quantile regression : an introduction . _ journal of economic perspectives _ ,",
    "* 15 * , 143 - 156 .",
    "marshall , k. , collings , s. , hodson , m. and odowd c. ( 2008 ) a framework for assessing risk margins .",
    "_ prepared by the risk margins task force for institute of actuaries of australia , 16-th general insurance seminar , 9 - 12 november , 2008 , coolum , australia .",
    "_ nelson , charles r. , and andrew f. siegel .",
    "( 1987 ) parsimonious modeling of yield curves .",
    "_ journal of business _ * 60 ( 4 ) * , 473 - 489 .",
    "ntzoufras , i. and dellaportas , p. ( 2002 ) bayesian modeling of outstanding claim reservesliabilites incorporating claim count uncertainty . _ north american actuarial journal _ , * 6 ( 1 ) * , 113 - 128 .",
    "paulson , a.s . and",
    "faris , n.j .",
    "( 1985 ) a practical approach to measuring the distribution of total annual claims . in cumins , j.d .",
    ", _ strategic planning and modeling in property - liability insurance_. norwell , ma : kluwer academic publishers .",
    "peters g.w . ,",
    "shevchenko p.v .",
    ", wuthrich m.v .",
    "( 2009 ) model uncertainty in claims reserving within tweedie compound poisson models",
    ". astin bulletin , * 39 ( 1 ) * , 1 - 33 . peters , g.w . ,",
    "byrnes , a.d . and shevchenko , p.v .",
    "( 2011 ) impact of insurance for operational risk : is it worthwhile to insure or be insured for severe losses ? .",
    "_ insurance : mathematics and economics _ , * 48 ( 2 ) * , 287303 . peters , g.w . , shevchenko , p.v .",
    ", young , m. and yip , w. ( 2011 ) analytic loss distributional approach models for operational risk from the @xmath248-stable doubly stochastic compound processes and implications for capital allocation . _",
    "insurance : mathematics and economics _ , * 49 ( 3 ) * , 565 - 579 . peters , g.w . , targino , r.s . and shevchenko p.v .",
    "( 2013 ) understanding operational risk capital approximations : first and second orders .",
    "_ governance and regulation ( invited special issue 8th international conference `` international competition in banking : theory and practice '' , sumy , ukraine ) _ , * 2 ( 3 ) * , 58 - 79 .",
    "smith , a.f.m . and roberts , g.o .",
    "( 1993 ) bayesian computation via the gibbs sampler and related markov chain monte carlo methods .",
    "_ journal of the royal statistical society , series b _ , * 55 * , 3 - 23 .",
    "spiegelhalter , d. , thomas , a. and best , n. ( 2000 ) bayesian inference using gibs sampling for windows version ( winbugs ) , software for bayesian analysis using mcmc method and gibbs sampler .",
    "- bsu.cam.ac.uk / bugs/. spiegelhalter , d. , best , n.g . ,",
    "carlin , b.p . and van der linde , a. ( 2002 ) bayesian measures of model complexity and fit .",
    "( with discussion ) , _ journal of the royal statistical society b _ , * 64 * , 583616 .",
    "stacy , e.w .",
    "( 1962 ) a generalization of the gamma distribution , _ the annals of mathematical statistics _ ,",
    "* 33 * , 1187 - 92 .",
    "gyorgy , s. and shaw w.t .",
    "( 2008 ) quantile mechanics . _",
    "european journal of applied mathematics _ , * 19 ( 2 ) * , 87 - 112",
    ". taylor , g.c .",
    "loss reserving : an actuarial perspective _",
    "( boston : kluwer academic publishers ) .",
    "verrall , r.j . and wuthrich , m. ( 2013 ) reversible jump markov chain monte carlo method for parameter reduction in claims reserving .",
    "_ north american actuarial journal _",
    "( to appear ) yu , k. , zhang , j. ( 2005 ) . a three - parameter asymmetric laplace distribution and its extension .",
    "_ communications in statistics theory and methods _ , * 34 ( 9 ) * , 1867 - 1879 .",
    "zhang y. , dukic v. and guszcza j. ( 2012 ) . a bayesian nonlinear model for forecasting insurance loss payments .",
    "_ journal of the royal statistical society a _ , * 175 * , 1 - 20 .",
    "yu , k. , moyeed , r.a .",
    "bayesian quantile regression .",
    "_ statists and probability letters _ , * 54 * , 437 - 447 ."
  ],
  "abstract_text": [
    "<S> we develop quantile regression models in order to derive risk margin and to evaluate capital in non - life insurance applications . by utilizing the entire range of conditional quantile functions , especially higher quantile levels , </S>",
    "<S> we detail how quantile regression is capable of providing an accurate estimation of risk margin and an overview of implied capital based on the historical volatility of a general insurers loss portfolio . </S>",
    "<S> two modelling frameworks are considered based around parametric and nonparametric quantile regression models which we develop specifically in this insurance setting .    in the parametric quantile regression framework , </S>",
    "<S> several models including the flexible generalized beta distribution family , asymmetric laplace ( al ) distribution and power pareto distribution are considered under a bayesian regression framework . </S>",
    "<S> the bayesian posterior quantile regression models in each case are studied via markov chain monte carlo ( mcmc ) sampling strategies .    in the nonparametric quantile regression framework , that we contrast to the parametric bayesian models </S>",
    "<S> , we adopted an al distribution as a proxy and together with the parametric al model , we expressed the solution as a scale mixture of uniform distributions to facilitate implementation . </S>",
    "<S> the models are extended to adopt dynamic mean , variance and skewness and applied to analyze two real loss reserve data sets to perform inference and discuss interesting features of quantile regression for risk margin calculations .    </S>",
    "<S> asymmetric laplace distribution , bayesian inference , markov chain monte carlo methods , quantile regression , loss reserve , risk margin , central estimate . </S>"
  ]
}