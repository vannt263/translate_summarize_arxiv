{
  "article_text": [
    "we consider here the problem of image reconstruction .",
    "suppose a multicolor or gray - scale picture is subjected to noise and an observer has access only to this corrupted version .",
    "how can she estimate the original picture ?",
    "the analysis of this kind of problem has attracted a lot of interest and many approaches have been considered ( [ g ] ) .",
    "one of the methods proposed is the so called map estimator . in this method",
    "one assumes that the original image is a random realization of a markov random field that has been corrupted by some site independent noise .",
    "one assumes that the distribution of the field ( a priori distribution ) is known as well as the distribution of the noise , that is , the conditional distribution of the observed image given the original one .",
    "the map estimator is the image that has the largest probability of have produced the observed one .",
    "this is the mode of the posterior distribution .    in multicolor images the literature proposes to use the so called potts model as a priori distribution .",
    "roughly speaking , this model is a measure on the set of images that gives more weight to images that have neighboring pixels of the same color .",
    "this choice has a number of advantages and disadvantages .",
    "an important disadvantage is the fact that the algorithms used to compute the map estimator operate in exponential time in the number of pixels ( [ gj ] ) .",
    "our main point in this paper is to propose an alternative a priori measure with the property that the computation time of the exact map estimator is polynomial in the number o pixels . using this approach",
    "we have produced an algorithm and a program that reconstruct dirty images in polynomial time in the number of pixels .    in the remaining of this section",
    "we explain these ideas in some detail . in the next section we present some _",
    "experimental _ results obtained from the implementation of our method to some images .",
    "the next section is more technical in nature .",
    "it explains why our map estimator can be computed efficiently ( polynomial time ) and provides a proof for the theoretical result presented below .",
    "the question of how to obtain estimators for some important parameters associated to the observed image is discussed in the appendix .",
    "we close this paper with some final remarks .    in order to motivate the discussion we have to introduce some notation .",
    "assume the image is a point of @xmath2 , where @xmath3 is a finite subset of @xmath4 ( e.g. a square ) with @xmath5 sites .",
    "the image associates to each site or pixel in @xmath3 one of @xmath6 possible colors . typically values for @xmath6 are @xmath7 or @xmath8 .",
    "assume @xmath9 and let @xmath10 for @xmath11 , @xmath12 , represent the true unknown ( random ) image .",
    "denote the observed image by @xmath13 .",
    "we denote the space of pictures @xmath14 by @xmath15 . in this notation",
    "we have @xmath16 possible colors in each pixel",
    ". each @xmath17 may correspond to a single binary number which gives the intensity of black in pixel @xmath18 as @xmath19 ( in the case of gray - scale picture ) or it may correspond to three binary numbers , each giving the intensity of one of the three _ basic colors_. in this second case , for instance , we could have @xmath20 and @xmath21 , for @xmath22 and @xmath23 giving the intensity of , respectively , red , green and blue at site @xmath18 . to simplify the discussion we assume , without loss , the first case since our approach in the second one is to reconstruct each color separately in order to reconstruct the whole picture .    in the bayesian setting we assume ( a ) that the original picture @xmath24 is random with a known distribution which is called the _ a priori measure _ and ( b ) that we know how to model the noise .",
    "to start we consider the noise .",
    "we fix an @xmath25 .",
    "conditional on @xmath24 , at each bit @xmath26 of each pixel @xmath18 , independently , the observed value in bite @xmath26 of pixel @xmath18 , called @xmath27 , is equal to the true value @xmath28 with probability @xmath29 or , with probability @xmath30 , it corresponds to the switched value :    [ error ] p_i(y_i^k|x_i^k ) = \\ {    cl 1- & _",
    "i^k = y_i^k + &    . hence p(y|x ) = _ i _ k \\{1,  ,k } p_i(y_i^k|x_i^k ) [ lik ] = \\ { h _ i _ k \\{1,  ,k } _ \\ { x_i^k = y_i^k } ( y ) } where [ h ] h = . and @xmath31 is the normalization constant",
    ".    note that this hypothesis is not the same as the one in [ ffg ] where each pixel was either observed correctly with probability @xmath29 or chosen uniformly among the other @xmath32 colors .",
    "now we define the map ( _ maximum a posteriori _ ) estimator .",
    "denote by @xmath33 the _ a priori _ measure , that is , the distribution of @xmath24 .",
    "then the map estimator after observing the image @xmath34 , @xmath35 is any image which maximizes the posterior distribution @xmath36 , that is    [ map ] p(| ) = _ _ k p(| )    now we discuss the _ a priori measure_. we want to consider here the situation on which very little is known about the original picture before the observation besides the information that it is some kind of real photo , perhaps taken by a satellite , as opposed to being a photo of something like a geometrical drawing , a cubist oil painting or a cell of a cartoon picture .",
    "we suppose that the only prior information available is that the original picture is _",
    "locally smooth_. by this we mean that the measure should be such that neighbor pixels on the picture are more likely to have colors which are near in some sense .",
    "more precisely we assume that there exists a real valued function @xmath37 which indicates how _ smooth _ is an image and take the _ a priori measure _ to be :    [ gibbs ] ( ) = where @xmath38 , with the sum taken over all possible images , is a normalization constant and @xmath39 is a real parameter .",
    "this parameter measures the tendency to be smooth since if @xmath40 is large @xmath33 is concentrated on images with small values of @xmath37 while if @xmath40 is small @xmath33 is close to the uniform distribution on @xmath15 , the set of all images .",
    "the motivation for this formula , in particular the minus sign in front of @xmath40 , comes from statistical mechanics where it would be called gibbs measure , @xmath40 would be the inverse temperature and @xmath37 would be the hamiltonian ( or energy ) function .    plugging ( [ lik ] ) into ( [ map ] ) , and taking logarithms , we get that the images which maximize the posterior distribution ( [ map ] ) are those which maximize [ loglike ] h(x ) + h _ i _ k \\{1,  ,k } _ \\ { x_i^k = y_i^k } ( y )    the image that maximizes this expression makes the best compromise between being globally _ smooth _ , regulated by @xmath41 , and agreeing as much as possible with the observed image which is regulated by @xmath42 .",
    "of course there exists only one relevant parameter in the maximization problem , say @xmath43 .    although _ any _ strictly positive measure @xmath33 on @xmath15 can be written as above _ for some _ @xmath37 , and thus ( [ gibbs ] )",
    "can be safely assumed for a generic _ a priori _ measure , we are interested only in the case on which @xmath37 is both _",
    "simple _ and _ reasonable _ as a measurement of smoothness .",
    "this simplicity requirement will basically mean the assumption that @xmath37 has only local dependence as follows    [ genham ] h ( ) = _",
    "< i , j > d(x_i , x_j ) where @xmath44 is a measure for the _ distance _ between the colors at pixel @xmath18 and @xmath45 and the sum is taken over all pairs of _ neighbor _ pixels in the picture",
    ". that is , @xmath46 .",
    "the choice of @xmath44 depends on what kind of local properties one expects in the original picture .",
    "one choice which is common in the literature ( see , for instance [ ffg ] and its quotations ) is [ potts ] h_p ( ) = _",
    "< i , j > _",
    "\\{x_i x_j } where the sum is taken over all pairs of neighbor sites in the lattice .",
    "this choice is related to the potts model in statistical mechanics ( see for instance [ m ] ) and explains the subscript .",
    "it is a model with very interesting properties that corresponds , in the two - color case , to the ising model [ mw ] . to find a solution to ( [ map ] ) we have to find what is called in the physics literature a _ ground state _ for the ising model with random magnetic field",
    "this field is induced by the observed image .",
    "most of the interesting properties of those statistical mechanics models , like _ phase transition _",
    ", appear in the so called _ thermodynamic limit _ , the limit on which the size of the system grows to the whole lattice ( [ r ] , [ mw ] ) .",
    "even though in our discussion the lattice size is kept fixed we will need in section 4 some exact results on the thermodynamic limit in the two - color case ( ising model ) .",
    "also some finite size considerations like the effect of boundary conditions ( in our case we chose _",
    "free _ boundary conditions ) may be important .",
    "the measure defined by ( [ gibbs ] ) , with ( [ potts ] ) plugged in , would describe images on which neighbor pixels tend to be equal but if two pixels have different colors the cost of this _ interface _ does not depend on _ how different _ they are .",
    "if two pixels have different colors the most likely is that each one belongs to a single - color region separated by a _ sharp _ interface .",
    "we could also try to represent the situation on which this is not necessarily the case choosing a finer notion of distance between @xmath17 and @xmath47 .",
    "two somewhat natural choices would be    [ dist ] h_1 ( ) = - _ <",
    "i , j > |_k=1^k ( x_i^k - x_j^k)|    or    [ dist2 ] h_2 ( ) = - _ < i , j > ( _ k=1^k ( x_i^k - x_j^k))^2 .    note that , for any choice of @xmath37 , the map problem is well posed since we could , at least in principle , check the finitely many values in the right hand side of ( [ loglike ] ) and choose a image that maximizes it .",
    "but since @xmath48 with something like @xmath20 and @xmath49 this approach is not computationally feasible .",
    "the problem with all the above choices is that it is not known how to do better than this time - consuming maximization by inspection in the multicolor case ( @xmath50 ) and thus the problem is , in practice , not solvable .",
    "we propose another choice for @xmath37 , intermediate between the potts and the other two mentioned above , which respects nicely the notion of smoothness which led to the choice ( [ dist ] ) but nevertheless induces to a polynomial time maximization problem .",
    "this choice is :    [ h ] h ( ) = _ k=1^k _ < i , j >",
    "|x_i^k - x_j^k|= + _ k=1^k _ < i , j > _ \\{x_i^k x_j^k }    with this , the problem of finding the @xmath51-color image which maximizes the posterior distribution @xmath36 is decomposed into @xmath52 binary color maximization problems .",
    "namely one has to solve    [ mapk ] p(_k|_k ) = _ _ 2 p(| ) _ k ( ) for each @xmath26 , @xmath53 where @xmath54 is the @xmath26-th component of the observed image and @xmath55 is the gibbs measure defined on the space of binary color images , @xmath56 , by ( [ gibbs ] ) with    [ hk ] h^k(_k ) = _",
    "< i , j > _ \\{x_i^k x_j^k}.    the @xmath52 color image given by @xmath34 is a solution of ( [ map ] )",
    ". each one of these @xmath52 binary images is called a _",
    "layer_. the weighted sum of the map for each layer gives our ( gray - scale ) image estimator : @xmath57    on the multicolor case one solves a _ gray - scale _",
    "problem for each basic color .",
    "each binary problem can be solved in polynomial time using the results by greig , porteous and seheult who reformulated it as one involving finding a minimum cut on a capacitated network [ ff ] for which there exist fast algorithms .",
    "these ideas are presented briefly in the next section . from the statistical point of view",
    "the approach is different whether the parameters @xmath40 and @xmath30 are known or not .",
    "a truly bayesian approach would associate an a priori measure to each one of the parameters @xmath40 and @xmath30 .",
    "we leave this alternative to future work .",
    "another possibility is to estimate these parameters from the observed image using classical frequentist analysis .",
    "this is possible under the hypothesis on the noise and on the original image being a sample of a gibbs measure for the potts hamiltonian ( [ potts ] ) ( which is always the case after the decomposition in binary colors ) using exact results for the two - dimensional ising model obtained by frigessi and piccioni [ fp ] .",
    "we have produced an algorithm based on [ fp ] for estimating the parameters @xmath30 and @xmath40 .",
    "this is explained in section 4 below .",
    "once one has a fast algorithm to reconstruct images it is natural to ask what is the effect of iterating the whole process .",
    "more precisely , what happens if one takes the reconstructed image and applies the method again , perhaps updating the value of @xmath58 ?",
    "note that to apply the method again for the ( already ) reconstructed image is equivalent to assume that the reconstructed image could be thought as obtained from some original picture which was chosen with respect to @xmath33 and then subjected to noise . even though it is not difficult to verify that this assumption is false the question is interesting both from the mathematical and from the applied point of view . on the mathematical side one has a mapping , @xmath59 , from @xmath15 into itself , a discrete time dynamical system , and it is natural to ask about iteration properties . on the practical minded side one can ask about the effect of iteration on the _ quality _ of reconstruction even if this can only be judged subjectively .",
    "if we decide to update @xmath43 before each iteration the natural thing to do would be to chose a larger value at each step since we assume the procedure did a good job and removed some of the noise , therefore @xmath60 would be more reliable than @xmath61 .",
    "it would then be natural to increase @xmath62 , without changing @xmath40 . a natural procedure to find each updated value is to use again the estimators given by frigessi and piccioni ( [ fp ] ) . in doing this",
    "we find , in fact , that this parameter increases , after one iteration , as expected .",
    "what is rather surprising is that once one tries this iteration procedure , either keeping @xmath43 fixed or increasing it , at each step , one finds that _ it has no effect et all_. the twice reconstructed image is _ exactly _ equal to the once reconstructed one .",
    "in other words , @xmath63 as a function from @xmath15 into itself has a fixed point in each once - reconstructed image .",
    "more precisely write @xmath64 for the function from @xmath65 into itself defined in ( [ map ] )",
    ". then we have the following    * proposition : * @xmath66 for all @xmath67 .",
    "we prove this proposition in the next section after reviewing some results on networks and the connection with the maximization problem considered in this note .    given this result",
    "a natural question arises .",
    "is this property not true _ in general _ ?",
    "suppose one has a random function assuming values in some space @xmath68 with some unknown parameter @xmath69 which itself belongs to @xmath68 chosen according to some _ a priori _ measure ( in our case , @xmath70 corresponds to the original image ) .",
    "define the map estimator as usual to obtain a function from @xmath68 into itself .",
    "does it always satisfy the this fixed point property ?",
    "one could argue that since all the information about the original image which is contained in the observed one should be still present in the reconstructed image then this iteration should give no further results and the _ twice _ reconstructed image should _ always _ be equal to the once - reconstructed one . as it turns out",
    "this is not the case and it is not difficult to find counterexamples .",
    "we developed a program ( ` map ` ) in _ c _ to reconstruct images according to the method proposed .",
    "this program reads an image in the _ portable bit map _ format for true - color ( _ .ppm _ ) or gray - scale ( _ .pgm _ ) pictures .",
    "the intensity of each color in each pixel ( or the single gray scale intensity there ) is written as a ( eight bits ) binary number .",
    "the program then constructs a graph for each one of those layers ( as defined after equation ( [ hk ] ) ) , construct the corresponding graphs and finds the minimum cut for each one of them using a standard implementation of the ford fulkerson algorithm .",
    "the program uses integer arithmetic scaled by a factor of 10000 .",
    "the values for @xmath40 and @xmath37 are supplied by command line switches .",
    "it is also possible to supply a bit mask to select which planes to reconstruct .",
    "the program is portable and it has been tested on _ sunos _ , _ solaris _ and _",
    "linux_.    the main problem in developing the program was the large amount of memory to hold the image , the graph and the auxiliary data structures .",
    "the solution was to use a compact representation of the graph , namely a matrix where each cell has a pixel and the values for the flow in each of 5 directions ( 4 neighbors plus @xmath71 or @xmath72 ) .",
    "this avoided the explicit representation of the edges and the extra space for the image itself .",
    "a series of tests were made on a 700mhz _ pentium iii _",
    "machine , with 128 mb of main memory , running linux debian potato 2.2 , kernel version 2.4 .",
    "the running times for restoration of six sample images are presented in table [ times ] .",
    "these images are shown in tables [ img1 ] , [ img2 ] and [ img3 ] .",
    "the images were obtained from a picture shot with a digital camera and converted to 8 bit gray - scale .",
    "the final result was saved in the file `` ` fish.pgm ` '' .",
    "two aditional files were obtained by clipping the image to a rectangle with half of the area ( `` ` fish2.pgm ` '' ) and to another one with a quarter of the total area ( `` ` fish3.pgm ` '' ) .",
    "the noise was added `` artificially '' by a program which scan every bit in the image and inverts it with a given probability .",
    "the probabilies used were 10% and 15% .",
    "the modified files were named ` fish.10.pgm ` , ` fish2.10.pgm ` , ` fish3.10.pgm ` and ` fish.15.pgm ` , ` fish2.15.pgm ` , ` fish3.15.pgm ` , respectively .",
    "each image was restored in all bit planes using 3 values of @xmath40 , namely 0.1 , 0.3 , 0.5 .",
    "an aditional restoration , just on the most significant bit plane were made using the estimated @xmath73 as indicated in the appendix .",
    "the values are presented in the tables [ img1 ] , [ img2 ] and [ img3 ] .",
    "we did not try to define a metric to measure the quality of the reconstruction , relying on a subjective analysis .",
    "besides the removal of noise , it was observed an improvement in the shades and ( consequently ) in the third dimension perception , even if some blurring is introduced .",
    "these and other examples are available directly from the authors or at ` http://www.ime.usp.br/~gubi/map/index.html `    .restoration running times for three sample images with two noise levels ( 10% and 15% per bit ) [ cols= \" < , > , > , > \" , ]",
    "in this section we present some capacitated network ideas which are used to solve the two - color maximization problem described before as discovered by greg , porteous and seheult [ gps ] and use them to prove proposition .    as mentioned before with the choice of @xmath37 given by ( [ h ] ) the maximization in ( [ map ] ) is decomposed into @xmath52 two - color problems .",
    "therefore we assume in this section that we are in the binary color case @xmath74 .",
    "the map estimator given @xmath75 is the image @xmath76 which gives the maximum of [ l ] l_(|)= _ i _ \\ { x_i = y_i } ( x ) + _ < i , j > _",
    "\\{x_i = x_j } ( ) where @xmath77 .",
    "a network @xmath5 is a graph @xmath78 , where @xmath79 is a finite set of vertices and @xmath80 is a set of couples of vertices , with a capacity @xmath81 associated with each edge @xmath82 .",
    "we define networks on the set of vertices @xmath79 , given by the sites in @xmath3 plus two extra ones denoted by @xmath71 ( source ) and @xmath72 ( sink ) , that is @xmath83 for the set of arcs we take @xmath84 where the first two unions are taken on @xmath85 and the last one is taken over pairs of nearest neighbor sites in @xmath3 .",
    "given the observed image @xmath34 and a real number @xmath86 we define the capacities of the network @xmath87 as follows .",
    "if @xmath88 we set @xmath89 as its capacity , otherwise set @xmath90 ; to each arc @xmath91 of neighbor sites in @xmath3 we associate @xmath92 . all other arcs have capacity zero .    for each image @xmath93 let @xmath94 @xmath95 these two sets define a _ cut _ of the network @xmath96 notice that the cut @xmath97 consists of a set of arcs whose removal ( cut ) makes it impossible to find a path going from @xmath71 to @xmath72 through arcs with non - zero capacity . if we now define the _ capacity of the cut _ @xmath97 by the quantity [ cut ] c_,()= _ ( i , j ) ( ) c_,(i , j ) it is very simple to check that @xmath98 where @xmath99 is a constant which does not depend on @xmath93 . therefore to find the map estimator one has to find the cut which minimizes ( [ cut ] ) : the so called _ minimum cut _ [ ff ]",
    ".    ford and fulkerson showed that the value of the capacity of the minimum cut is equal to the _ maximum flow _ through the network from source to sink . recall that a flow @xmath100 in a network @xmath5 ( on @xmath101 with capacity @xmath102 ) from @xmath71 to @xmath72 is a collection of real numbers @xmath103 , where @xmath104 can be thought as the amount of fluid per unit time going through the _ pipeline _ @xmath105 , such that the flow on each arch does not exceed its capacity , @xmath106 , for all @xmath82 , and such that the flow is conserved    _ j v*f*(i , j ) - _ j v * f*(j , i ) = 0 for all @xmath107 .",
    "well known fast algorithms to find this maximum flow exist and therefore the problem is solved in practice .",
    "the algorithm presented in this paper uses this method to reconstruct each one of the ( 8 or 24 ) layers .",
    "* proof of the proposition . * to simplify the notation write @xmath108 .",
    "let @xmath109 .",
    "the networks defined by the pair @xmath110 , denoted by @xmath87 , and by @xmath111 , @xmath112 , can differ only in the capacities assigned to each arc .",
    "the proposition asserts that the cut defined by @xmath113 also has minimum capacity in @xmath112 , that is we want to prove that [ * ] c_, ( ) c_, ( ) , for any image @xmath114 .",
    "fix @xmath115 and let @xmath116 , @xmath117 and @xmath118 .",
    "by definition of map estimator we have [ inalpha ] c _ , ( ) c _ , ( ) , which implies [ 1 ] d_,(e_i ) d_,(e_iii ) .",
    "where , for a set of edges @xmath80 , @xmath119    therefore to check ( [ * ] ) it is enough to verify [ 2 ] d_,(e_i ) d_,(e_i ) [ 3 ] d_,(e_iii ) ) d_,(e_iii ) .",
    "we start with inequality ( [ 2 ] ) .",
    "assume @xmath120 .",
    "if @xmath105 is an external edge ( connecting some site @xmath18 with either the source @xmath71 or the sink @xmath72 ) , then , since @xmath121 , it must be @xmath122 which is less or equal than @xmath123 . on the other hand , if @xmath105 is an internal edge ( i.e. @xmath124 for @xmath18 and @xmath45 nearest neighbors in @xmath3 ) then its capacity equals @xmath125 in both cases .",
    "this concludes the proof of ( [ 2 ] ) .",
    "suppose now @xmath126 .",
    "inequality ( [ 3 ] ) follows from the observation that @xmath127 can not be zero .",
    "the different approaches used in image reconstruction are based in quite different set of theoretical ideas and it is not clear how to compare their results . one possible measure for the _ quality _ of the reconstruction , used in [ fp ] to compare 9 algorithms , is to evaluate the proportion of pixels classified correctly . since our main goal here was to present a method for the reconstruction of multicolor images we leave the comparison with other methods for future work . in any case , since we are working with exact map s for the chosen hamiltonian , our method will be as good ( and as bad ) as the usual two colors map estimators , regarding the proportion of bits reconstructed .",
    "for the usual map reconstruction problem in the multicolor case no fast algorithm is known ( [ ffg ] ) . for a probabilistic approach via _ simulated annealing _ in order to get the exact estimator one needs to decrease very slowly some parameter while the computation goes on and thus needs a prohibitively large amount of time [ gi ] .",
    "one possibility is to accept approximated map estimators which can be obtained fast enough .",
    "one can do this with simulated annealing by updating the parameter fast enough but then we lose control on how close the approximation is to the exact one .",
    "an approximate of the map estimator with a probabilistic analysis of the error in the three color case was developed in [ ffg ] .",
    "another approach can be found in [ j ] .",
    "our approach is not completely bayesian as we also consider a situation on which the _ a priori _ measure has some unknown parameters but do not assume any prior knowledge about them . in the appendix we describe a method to estimate these parameters from the picture itself using _ classical statistical methods _ , as proposed by frigessi and piccioni [ fp ] . in those cases we verify that plugging those estimated values into the formulas used to get the map estimator provides a reconstruction which appears to be the best . as mentioned before we do not try to quantify this .",
    "ricardo maronna proposed that instead of estimating @xmath40 and @xmath62 one could look for the @xmath128 that maximizes ( [ loglike ] ) .",
    "the estimator for the true image will then be the @xmath129 which realizes this maximum with the best @xmath86 .",
    "it is not clear yet how to justify this theoretically .",
    "another alternative would be to choose the uniform distribution on an appropriate range as a priori distribution for @xmath30 and @xmath40 .",
    "however the computation of the map estimator in this case seems prohibitive .",
    "as an experimental observation we remark that reconstructing only the first layer of a dirty image ( and leaving the others as they are ) gives a quite good visual result .",
    "a possible explanation of this fact is that , as a consequence of the binary decomposition , each layer is `` half '' as important as the previous one .",
    "looking for algorithms which give smooth solutions we propose the following hierarchical procedure .",
    "first consider layer @xmath125 and find @xmath130 , as before for @xmath131 .",
    "then given layer @xmath132 , for @xmath133 , define @xmath134 as the ( binary ) image that maximizes [ ll ] l_(_k|)= _ i _ \\ { x^k_i = y^k_i } ( x ) + _ < i , j > _",
    "= 1^k _ \\ { x^_i = x^_i } ( ) . in words , this algorithms will try to get the same value for two neighbors in layer @xmath26 if these neighbors have the same value for all previous layers . if not they are not coupled .",
    "visual realizations of this algorithm give also good results .",
    "although there is no hamiltonian for this model , the algorithm is well defined .",
    "moreover each layer corresponds to the so called diluted ising model .",
    "assume that we get @xmath5 independent samples of the same image @xmath135 .",
    "this means that the original realization @xmath129 of the image is the same but the noises are independent .",
    "a generalization of our approach deals with this problem in the following way .",
    "we modify the capacities associated to the graph @xmath136 . to each arc",
    "@xmath137 connected to the source we associate the capacity @xmath138 and then to each arc @xmath139 connected to the sink we associate the capacity @xmath140 in the same vein one could use the remaining two colors to get information about the color being reconstructed .",
    "in this section we apply ideas from frigessi and piccioni ( [ fp ] ) which exploit well known ( but highly nontrivial ) results from statistical mechanics ( [ r ] , [ mw ] ) to obtain estimators for the parameters @xmath40 and @xmath141 .",
    "the measure defined in ( [ gibbs ] ) with @xmath37 given by ( [ potts ] ) in the two - color case ( ising model ) in the thermodynamic limit gives rise to a translation invariant measure which may be ergodic or not according to the value of @xmath40 .",
    "this choice of @xmath37 does not favor zeros or ones .",
    "this symmetry is perhaps easier to see if we represent a configuration as an element @xmath142 in @xmath143 with @xmath144 replacing zeros .",
    "this is the usual ising notation while the one using zeros and ones is known in statistical mechanics as _ lattice gas _ representation . in the situation considered here",
    "they are equivalent .",
    "the corresponding infinite volume limit measure is not ergodic if @xmath40 is smaller than some ( known ) critical value @xmath147 . in this case",
    "the limit measure is a mixture with equal weights of two measures @xmath148 and @xmath149 , the first favoring configurations with more @xmath150 s than @xmath144 s and the other favoring configurations with more @xmath144 s than @xmath150 s . if @xmath151 then @xmath152 . if we denote by @xmath153 ( @xmath154 ) the expected value of a function @xmath155 defined on @xmath143 the symmetry between @xmath148 and @xmath149 imply      @xmath156 is called the two point correlation function for the infinite volume system at inverse temperature @xmath40 .",
    "we will need two of those correlation functions in what follows : @xmath157 , for nearest neighbors , and @xmath158 for neighbors along the diagonal on the lattice .",
    "= ^-1 ( ) and = \\{1-()^ } with g^a()= where for a = 1 the sum is taken over pairs of nearest neighbor sites along the lattice directions in @xmath164 , the interior of @xmath3 , and for a = 2 the sum is over neighbor sites along the two lattice diagonals again in the interior of @xmath3 .",
    "expressions for @xmath157 and @xmath158 are complicated involving elliptic integrals with different formulas for @xmath40 smaller , equal and larger than @xmath165 and the function @xmath166 must be computed numerically .",
    "our program * estima * finds these estimators from a observed image .",
    "we thank ricardo maronna for comments on a draft of this paper .",
    "we thank eric soares da costa and lucas meyer dos santos for developing and debugging the first version of the program .",
    "this research is part of fapesp  projeto temtico \" grant number 90/3918 - 5 .",
    "partially supported by cnpq .",
    "[ gi ] b. gidas _ metropolis type monte carlo simulation algorithm and simulated annealing _ , topics in contemporary probability and its applications , 159232 , probab .",
    "stochastics ser . ,",
    "crc , boca raton , fl ( 1995 ) ."
  ],
  "abstract_text": [
    "<S> we present an algorithm to reconstruct gray scale images corrupted by noise . </S>",
    "<S> we use a bayesian approach . the unknown original image is assumed to be a realization of a markov random field on a finite two dimensional region @xmath0 . </S>",
    "<S> this image is degraded by some noise , which is assumed to act independently in each site of @xmath1 and to have the same distribution on all sites . for the estimator we use the mode of the posterior distribution : the so called _ maximum a posteriori _ ( map ) estimator . </S>",
    "<S> the algorithm , that can be used for both gray - scale and multicolor images , uses the binary decomposition of the intensity of each color and recovers each level of this decomposition using the identification of the problem of finding the two color map estimator with the min - cut max - flow problem in a binary graph , discovered by greig , porteous and seheult ( 1989 ) . </S>",
    "<S> * experimental results and a detailed example are given in the text . </S>",
    "<S> we also provide a web page where additional information and examples can be found . </S>",
    "<S> *     s     62h11 62m40 68u10 .    _ key words and phrases : _ multicolor reconstruction , maximum a posteriori , bayesian approach , fast algorithms </S>"
  ]
}