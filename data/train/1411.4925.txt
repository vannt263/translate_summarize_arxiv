{
  "article_text": [
    "in recent years , governments and agencies from many countries have increasingly focused efforts on improving the accessibility of their citizens to public data , i.e. , all the data that public bodies in a given country produce , collect or pay for , which is widely known as the open data paradigm @xcite .",
    "these resources , which come from many different fields of knowledge , offer a high potential for re - use in new products and services .",
    "this scenario has been described very graphically with the following statement `` data is the new oil for the digital age '' @xcite .",
    "however , there is still a significant gap between the resources offered by public institutions and the necessities of their potential consumers .",
    "one reason is that the publishing bodies are usually focused on the availability of their datasets rather than on providing tools or means for accessing and processing them .",
    "this often results in extensive catalogues of heterogeneous data which have almost no direct value for the potential consumers of that data .    besides a lack of standardization",
    ", there is also a lack of tools and services which allow a better access and comprehension of the raw data provided by the public institutions .",
    "an interesting and illustrative example of this kind of services can be found in meteorology , where meteorological agencies offer both raw data and also several types of information pieces ( such as forecasts , reports or meteorological warnings ) that are elaborated by meteorologists from these raw data .",
    "artificial intelligence provides us with tools which allow us to process and understand this massive availability of huge quantities of data .",
    "originally , this objective has been assumed by the knowledge discovery in databases ( kdd ) field , but more specifically by its core stage , the data mining field @xcite , which assembles several tasks such as classification , association , clustering , trend analysis or summarization @xcite .",
    "summarization is of particular interest , since it abstracts data into useful information at different levels and dimensions .",
    "the abstracted information can adopt many forms , although the most common services come in the form of web - based visualization tools . however , other approaches taken by research fields such as natural language generation ( nlg ) or soft computing offer solutions to convert and summarize data into textual information which can be easily consumed by human users .",
    "the creation of automatic textual summaries of data is a task which originally started within the nlg field .",
    "several nlg approaches which generated summaries of data include ana @xcite , which generated summaries of stock market activity ; lfs @xcite , which generated summaries of statistical data ; sumgen @xcite , which generated summaries of events in a battle simulation ; temsis @xcite , which generated summaries of environmental data ; trend @xcite , which generated summaries of historical weather data ; and , more recently , babytalk @xcite , which generates medical reports for neonatal intensive care data .",
    "however , the most successful nlg systems for data summarization , at least in terms of public impact and usefulness , generate automatic textual weather forecasts from numerical prediction data . a few systems , such as fog @xcite , multimeteo @xcite and sumtime - mousam @xcite , @xcite , have been used by meteorological agencies to automatically produce public weather forecasts .    at the same time , within the fuzzy logic and soft computing field , the paradigm of computing with words ( cww ) @xcite , and its later evolution computing with perceptions ( cwp ) @xcite , @xcite , made their appearance in the 1990s .",
    "as opposed to other classical approaches , these paradigms involve a fusion of natural languages and computation with linguistic variables @xcite .",
    "although many new approaches based on cww have emerged , one of the most promising tools is linguistic data summarization @xcite , @xcite , which employs fuzzy quantified propositions to obtain linguistic summaries involving one variable ( as in `` most of the dogs are brown '' or `` a few trees are tall '' ) or more than one variable ( as in `` some of the brown dogs are heavy '' or `` most of the tall trees are very old '' ) .",
    "since then , linguistic summarization from cww has been applied in several practical cases and , with the appearance of cwp , some authors have started to refer to linguistic summaries as linguistic descriptions of data ( ldd ) @xcite , which understand linguistic summaries as a tool to describe human perceptions . for reasons of clarity , we will use in this paper the term linguistic descriptions of data .",
    "examples of fields of application of linguistic description approaches include descriptions of the patient inflow in health centers @xcite , domestic electric consumption reports @xcite , human activity based on mobile phone accelerometers @xcite or human gait quality @xcite .",
    "other approaches use more complex expressions involving relationships among different attributes ( in economic data @xcite , in sales data @xcite or the analysis of investment fund quotations @xcite ) .",
    "most of these approaches are very strongly dependent on the field of application and the users needs of information .",
    "a more general approach which is able to construct different kinds of linguistic descriptions regardless of the application domain is still an open challenge in this field .",
    "nevertheless , steps in this direction have been taken by providing general criteria on how to structure quantified sentences in order to obtain more complex descriptions @xcite or on how to build and evaluate linguistic descriptions @xcite , @xcite , @xcite .",
    "another open challenge is the relationship between linguistic descriptions in cwp and nlg . until now , both have followed separate paths , although it remains clear that both can contribute to each other in a substantial way @xcite .    with both linguistic descriptions from cwp and textual summaries from nlg as inspiration , we present in this paper galiweather @xcite , an application which automatically generates short - term weather forecasts in the form of natural language texts for the galician meteorological agency ( meteogalicia ) @xcite .",
    "this solution employs in an innovative way a ldd computational method combined with a nlg system in order to solve a real life information need , as opposed to other approaches which only present test use cases and do not address the whole problem of adapting their solutions to real final user needs and demands . for this",
    ", the use of fuzzy procedures through linguistic variables and quantifiers allows the application to model imprecise concepts included in the linguistic descriptions .",
    "furthermore , the quality of these descriptions , which are generated as natural language texts by the nlg system , has been assessed by an expert meteorologist in two key dimensions , verifying that the textual forecasts are both correct and properly expressed .",
    "the next section introduces the context in which this solution has been devised . in section",
    "iii a formal description of the forecast input data and the linguistic description computational method is provided , followed by an extensive overview of the nlg system .",
    "section iv addresses the validation process and results obtained for our application .",
    "section v contains some insights about a methodological conceptualization of our approach and finally in section vi we present the most relevant conclusions .",
    "the operative weather forecasting offered by the galician ( nw spain ) meteorology agency through its website ( meteogalicia @xcite ) consisted until now of a global description of the short - term meteorological trend ( fig .",
    "[ forecastapril ] ) .",
    "this service has been recently improved in order to provide visitors with symbolic forecasts for each of the 315 municipalities in galicia , thus improving its quality and allowing users to obtain more precise information about specific locations of the galician geography .",
    "figure [ webforecast ] shows the current web application for consulting municipality forecasts @xcite , which has been graphically divided in blocks for an easier explanation .",
    "block 1 contains a shortcut list to the seven most important municipalities in galicia , which allows a direct access to their forecast data ( the user can select a favorite municipality , which is loaded by default in posterior visits ) .",
    "block 2 allows the user to search for the rest of the municipalities , which are grouped according to the galician province they belong to .",
    "it also allows to add to the shortcut list in block 1 the selected municipality .",
    "the short - term forecast is shown in block 3 , which offers symbolic data for wind and sky state and numeric data for temperatures for four days , including morning , afternoon and night each day .",
    "block 4 shows the mid - term forecast for several days and includes a global comment about the weather in galicia in general , which consequently remains the same for every municipality .",
    "this increase in the quantity of available numerical - symbolic data has a main downside , which resides in the lack of natural language forecasts which describe this set of data .",
    "this issue makes forecasts harder to understand , since users need to look at every symbol and detect which phenomena are relevant and when they will occur , whereas natural language descriptions directly provide all this information . in the case of a mid - term forecast , its uncertainty allows the inclusion of a global description , which is written by a meteorologist .",
    "however , for short - term forecasts , which are much more accurate , the meteorological diversity causes that several meteorological phenomena may occur at the same time in different areas .",
    "thus , to issue daily textual forecasts upon 315 municipalities is not feasible .    in order to address this issue",
    "we have developed an application which , from short - term data , generates linguistic descriptions which highlight meteorological phenomena considered important by an expert meteorologist .",
    "the style and contents of the natural language linguistic descriptions for each location are similar to the general one presented in fig .",
    "[ forecastapril ] .",
    "the solution we have devised employs numerical - symbolic forecast data and additional expert information to generate the final output textual weather forecasts in two separate tasks .",
    "the first task converts the numerical - symbolic input data into linguistic descriptions ( encoded in an intermediate language ) .",
    "these descriptions are created through a computational method which abstracts data values into linguistic labels dealing with uncertainty and temporal references . in the second stage ,",
    "a nlg system translates the intermediate codes into a natural language forecast for one of the available final output natural languages , which is ready for human consumption . a general schema of this process is shown in fig . [ methodschema ] .",
    "meteogalicia s database offers a dataset which covers all the 315 galician municipalities and includes forecast data associated to several items in a four - day temporal window .",
    "this data is heterogeneous in its nature and includes values in degrees celsius and weather symbols represented by codes .",
    "for instance , the meteorologists have characterized the sky state phenomena as 21 numerical codes ( values in the interval [ 101,121 ] ) and the wind phenomena as 34 numerical codes ( values associated to a given intensity and direction in the interval [ 299,332 ] ) .",
    "these numerical codes are used to display graphical symbols in the forecast website .",
    "figure [ short ] shows an example of a real short - term forecast data series .",
    "formally , each municipality @xmath0 has an associated forecast data series set @xmath1 , which includes data series for the input variables considered : sky state ( @xmath2 ) , wind ( @xmath3 ) and maximum ( @xmath4 ) and minimum ( @xmath5 ) temperatures . for clarity reasons , without loss of generality",
    ", we will consider a single municipality data series in the explanations that follow ( @xmath6 ) .",
    "each data series element in @xmath7 is characterized in what follows :    * * sky state ( @xmath8)*. it provides three numerical codes per day ( morning , afternoon , night ) about two meteorological variables of interest , namely and . from a formal point of view , @xmath9 , where @xmath10 \\forall ss_i \\in ss$ ] .",
    "each code in the interval @xmath11 $ ] has a specific sky state meaning ( for example , 111 means `` covered with rain '' ) . * * wind ( @xmath12)*. it provides three numerical codes per day about the wind intensity and direction .",
    "@xmath13 , where @xmath14 \\forall w_i \\in w$ ] .",
    "each code in the interval @xmath15 $ ] has an associated wind direction and intensity ( for instance , 317 means `` strong wind from the north '' ) .",
    "* * temperature * ( @xmath16 and @xmath17 ) .",
    "maximum and minimum forecasted temperatures are given in degrees celsius with a resolution of 1 degree and one value per day : * * @xmath18 , where @xmath19 \\forall tmax_i \\in tmax$ ] .",
    "* * @xmath20 , where @xmath21 \\forall tmin_i \\in tmin$ ] .    for each forecast data",
    "series @xmath7 , our application obtains linguistic descriptions about seven forecast variables , namely cloud coverage , precipitation , wind , maximum and minimum temperature variation and maximum and minimum temperature climatic behavior . for this , we have devised a computational method divided in several linguistic description generation operators .",
    "the first stage of our application obtains a linguistic description for every variable , which consists in sets of linguistic labels and temporal references which contain the relevant information extracted from the raw data .",
    "this process , as it can be seen in fig .",
    "[ firstphase ] , consists of providing each linguistic description operator with its corresponding data and expert knowledge ( in the form of crisp and fuzzy partition sets and numeric categories ) in order to generate the intermediate linguistic descriptions .",
    "each operator is formally described in what follows .",
    "two different fuzzy operators are used in the linguistic description generation of the cloud coverage variable .",
    "the first one provides a chronological description , while the second one provides a short - term global description when the previous description is not appropriate .    1 .   .",
    "* * input * : * * sky state data series @xmath9 . * * a temporal fuzzy linguistic partition @xmath22 , where each temporal linguistic term @xmath23 has an associated fuzzy membership function @xmath24 $ ] . for our application , @xmath25 ( fig . [ fuzzytime ] ) . * * a cloud coverage linguistic variable , defined as a set of cloud coverage categories @xmath26 .",
    "each linguistic term @xmath27 has an associated crisp membership function @xmath28 , defined as : @xmath29 + in our application , @xmath30 ( `` clear '' , `` partly cloudy '' , `` very cloudy '' ) , as shown in fig .",
    "[ fuzzytime ] . *",
    "* procedure*. this operator provides the most appropriate cloud coverage linguistic term @xmath31 for each temporal subdivision @xmath23 .",
    "a relevance degree is calculated for each pair of cloud coverage and temporal labels and the label pairs with the highest degree are then selected ( one per temporal label ) : * * relevance degree matrix @xmath32 , where each value @xmath33 determines the importance a cloud coverage linguistic term @xmath31 has within a temporal sub period @xmath23 : @xmath34 * * set of the most appropriate cloud coverage label for each temporal label , ordered by the temporal partition index @xmath35 : @xmath36 * * output*. a chronological cloud coverage linguistic description as an intermediate code characterized by the following concatenation : @xmath37 + figure [ fuzzytime ] shows the definitions of both linguistic variables for our application and an example of the chronological cloud coverage linguistic description process .",
    "this description is provided only if the following experimental condition is fulfilled : @xmath38 .",
    "this condition ensures that every @xmath23 has an associated predominant cloud coverage type @xmath31 , while maintaining tolerance to the appearance of other cloud coverage categories in @xmath8 .",
    "otherwise , the linguistic description generated by the second operator is provided .",
    "+    2 .   .",
    "this operator provides a global description of the cloud coverage state for the whole short - term period . * * input * : * * sky state data series @xmath9 . *",
    "* a cloud coverage predominance linguistic label @xmath39 , where each linguistic term @xmath40 has an associated fuzzy quantifier @xmath41 \\rightarrow [ 0,1]$ ] . in our case , @xmath42 @xmath43 ( fig .",
    "[ fuzzyquant ] ) . * * a cloud coverage linguistic variable @xmath44 , as defined in the previous operator . *",
    "* procedure*. this operator quantifies the occurrence of the different cloud coverage categories @xmath31 using zadeh s quantification model @xcite : * * fuzzy fulfillment degree matrix @xmath7 , where @xmath45 * * set of cloud coverage label and quantifier label pairs with the highest fulfillment degree : @xmath46 , where @xmath35 is minimum . * * output*. a cloud coverage linguistic description as an intermediate code characterized by the following concatenation : @xmath47 + figure [ fuzzyquant ] shows the definition of the fuzzy quantifiers @xmath48 and an example of this linguistic description process",
    ".          this operator extracts precipitation episodes from the sky state values .",
    "these periods are classified according to the kind of precipitations detected :    * * input * : * * sky state data series @xmath9 . * * a precipitation linguistic variable , defined as a set of precipitation categories @xmath49 , where each linguistic term @xmath50 has an associated crisp membership function @xmath51 , where @xmath52 is defined identically as @xmath53 in expression ( [ eq1 ] ) .",
    "* * procedure*. this operator extracts an ordered set of precipitation episodes @xmath54 , where each episode is characterized as @xmath55 .",
    "the algorithm in fig .",
    "[ precipprocedure ] describes how the precipitation operator extracts the relevant episodes from @xmath8 : + @xmath56 @xmath57 @xmath58 @xmath59 @xmath60 @xmath61 @xmath62 @xmath63 @xmath64 break @xmath65 @xmath57 @xmath66 @xmath67 * return * @xmath68 * * output*. a precipitation linguistic description for each precipitation episode @xmath69 as an intermediate code characterized by the following concatenation of terms : @xmath70    in this case , @xmath71 ( `` intermittent'',``persistent'',``snow'',``storm'',``hail '' ) is defined for precipitation ( although `` intermittent '' and `` persistent '' are not explicitly included in the final natural language forecasts , as required by the meteorologists ) .",
    "figure [ precipitation ] shows the definition of @xmath72 and provides a graphical example of the precipitation linguistic description generation process .",
    "it follows a similar strategy to the precipitation operator , although in this case it does not convert the original values into labels .    *",
    "* input * : * * wind data series @xmath73 . * * a numeric interval @xmath74 | aw \\subset [ 299,332]$ ] ( as indicated in section iii - a ) , which specifies the relevant wind values to be extracted by the operator . in our application , @xmath75 $ ] .",
    "this interval corresponds to strong and very strong winds , which are the only relevant wind conditions to be included in the descriptions according to the meteorologists . * * procedure*. this operator extracts an ordered set of wind episodes @xmath76 , where each episode is characterized as @xmath77 .",
    "the algorithm in fig . [ windprocedure ] describes how the wind operator extracts the relevant episodes from @xmath12 .",
    "+ @xmath78 @xmath79 @xmath58 @xmath80 @xmath81 @xmath82 @xmath83 @xmath84 @xmath64 @xmath85 @xmath79 @xmath66 @xmath86 * return * @xmath87 * * output*. a wind linguistic description for each wind episode @xmath88 as an intermediate code characterized by the following concatenation : @xmath89 @xmath90 @xmath91 @xmath92 .",
    "for example , if there is a period of strong wind within @xmath12 , we could obtain a linguistic description such as `` start=2 end=4 labels=322,322,322 '' , meaning `` from tonight ( @xmath93 ) until tomorrow afternoon ( @xmath94 ) there will be strong wind from the southwest ( @xmath95 ) '' .",
    "this operator generates a linguistic description which reflects the temperature trend for the 4-day period and also obtains information about the climatic behavior of the forecasted temperatures .",
    "thus , four variables are considered : maximum and minimum temperature variations and maximum and minimum climatic behavior .    * * input * : * * maximum temperature data series @xmath96 . *",
    "* minimum temperature data series @xmath97 .",
    "* * a temperature variation linguistic variable , defined as @xmath98 , where each linguistic term @xmath99 has an associated crisp membership function @xmath100 . in our application , @xmath101 ( `` extreme decrease '' , `` notable decrease '' , `` moderate decrease '' , `` slight decrease '' , `` without changes '' , `` slight increase '' , ... , `` extreme increase '' ) . * * a temperature climatic behavior linguistic variable , defined as @xmath102 , where each linguistic term @xmath103 has an associated crisp membership function @xmath104 . in our case , @xmath105 ( `` very low '' , `` low '' , `` normal '' , `` high '' , `` very high '' ) . *",
    "* procedure*. this operator provides the linguistic terms with the highest membership degree from @xmath106 and @xmath107 for the four temperature variables considered : * * temperature variation : for maxima @xmath108 , and minima @xmath109 .",
    "* * temperature climatic behavior : for maxima @xmath110 , and minima @xmath111 . * * output*. a temperature linguistic description as an intermediate code characterized by the following term concatenation : @xmath112 @xmath113        the definition of @xmath106 and a graphical example of the temperature operator are shown in figure [ temperature ] .",
    "as for @xmath107 , its associated crisp membership functions @xmath114 are not shown in this example , since they vary for each municipality .",
    "the natural language generation ( nlg ) stage of this application consists of a domain - specific system which , following standard nlg techniques , has also been divided into different modules for each variable , so that changes in one of them do not affect the rest of the system . from a global perspective , each of these modules receives the intermediate linguistic description generated by their corresponding operator , parses it and generates the final textual forecast for its associated variable .",
    "if we delve deeper into the natural language generation stage structure , the complexity of the final natural language descriptions is a factor which has determined the design and implementation approach we have followed .",
    "this includes evaluation criteria applicable to linguistic descriptions @xcite such as the description length , but also nlg systems design methodologies as in @xcite and @xcite .",
    "thus , since the quantity of information in the descriptions is variable and the diversity of situations for each variable to be included ranges from simple to more complex , we have adopted two different nlg solutions .",
    "on one hand , we have defined templates in structured text files which contain generic natural language sentences for the simpler variables ( cloud coverage , temperatures and wind ) . on the other hand ,",
    "we have designed and implemented the generation of natural language sentences for precipitation inspired by standard nlg methodologies @xcite , @xcite .",
    "this approach has been devised as a solution for variables whose corresponding natural language sentences have rather static structure and length , such as temperatures or cloud coverage .",
    "for example , a textual forecast for temperatures usually includes information about variation of maxima and minima and their climate behavior , and the only elements that differ from one forecast to another are the labels assigned to the variations and the behavior , whereas the syntactic structure and length of the forecasts remain the same .        in this context , structured text files , such as xml , allow to model and build templates of natural language sentences , where static text can be mixed with other elements , such as variables or optional texts within a sentence .",
    "we have taken advantage of this flexibility by designing templates for temperature , cloud coverage and wind variables .",
    "these templates are included in a document which also contains natural language label sets for variables , time expressions or other kind of language - dependent text resources .",
    "figure [ xml ] shows parts of a template document ( in this case for english language ) , whose structure ( fig . [ nlg_structures ] )",
    "is comprised of the following elements :    * * variable templates * , which include the generic natural language forecast structures for several variables , such as cloud coverage or temperature . * * label sets * , which contain the natural language vocabulary and expressions used to fill in the variable elements .",
    "they are the natural language equivalent to the crisp and fuzzy partition sets used in the linguistic description extraction stage .",
    "for example , in fig .",
    "[ temperature ] the temperature variation labels in @xmath106 correspond to the label identifiers in the temperature variation label set in fig .",
    "[ xml ] .",
    "the template documents for the supported languages are loaded into structured objects within the application .",
    "once the intermediate codes for the nlg template - based variables have been obtained , each nlg module ( one per meteorological variable ) parses its corresponding code and executes expert rules incorporated into the implementation code , so that according to certain detectable events in the intermediate language , different cases and options can be selected .",
    "then , the template variables are filled with the natural language labels which correspond to the linguistic labels found in the intermediate code .",
    "finally , the nlg template structures are translated into a natural language forecast text through the concatenation of the text values of each of their elements .",
    "the previous nlg approach is not suitable for variables such as precipitation , where several episodes can occur within a forecast term .",
    "this can lead to the generation of several natural language sentences which , although may reflect faithfully the meteorological data , are repetitive and tedious to read . since the purpose of building linguistic descriptions in natural language is to provide users with textual information which should be easy to read and to understand , another nlg approach is required in order to achieve this goal .",
    "based on the concepts of a nlg system architecture described in @xcite and @xcite , we have designed and developed a nlg module for precipitation which addresses redundancy or length excess in the obtained descriptions .        in @xcite , a nlg system is depicted as a six stage task , where one subtask is performed per stage . however ,",
    "some of these subtasks may be merged or might not even be necessary , depending on the nlg requirements .",
    "consequently , we have adapted some of these subtasks for the precipitation nlg module : content determination , sentence aggregation , lexicalization and linguistic realization .",
    "others such as document planning were not considered , since in our case the nlg complexity is aimed at a sentence level .",
    "this process is summarized in figure [ precnlg ] .",
    "content determination is defined in @xcite as the process which decides what information should be communicated in the text .",
    "this is done by creating a set of data objects ( messages ) which contain the filtered and summarized data . in our method , this task is partially performed in the linguistic description stage by the precipitation operator , which extracts the relevant data from the raw data and converts it into an intermediate language . the remaining task is to convert the intermediate code into data objects , which is done by the precipitation nlg module parser . as a result , a list of precipitation episodes , whose structure is shown in fig .",
    "[ precstructure ] , is created and used by the subsequent natural language generation subtasks .        the precipitation data object structure in fig .",
    "[ precstructure ] shows that a precipitation episode has a duration ( which can range from a single instant to the whole term ) .",
    "furthermore , it might have associated nuances , which are subintervals within the episode in which the precipitation can be of different nature than rain ( of snow , of hail or stormy ) .",
    "the next nlg subtask we have adopted in our approach is sentence aggregation , which consists in grouping messages into sentences .",
    "we have contemplated three different ways of aggregating the precipitation episodes : by episodes , by days and whole - term aggregation .",
    "consequently , we have created three different submodules which perform not only sentence aggregation , but also lexicalization and linguistic realization .",
    "lexicalization , which is the process of deciding which specific words and phrases should be chosen to express the concepts and relations in the messages , employs label sets defined in the nlg templates described in the previous approach .",
    "linguistic realization produces a text which is syntactically , morphologically and orthographically correct .",
    "our precipitation approach obtains three candidate natural language precipitation sentences which describe the same input meteorological data set .",
    "the final output sentence for precipitation will be the shortest of the three , since we want to ensure that the obtained natural language forecasts remain as concise and brief as possible @xcite .",
    "this application has been developed in the cross - platform coding language python , with the use of libraries for mathematical and fuzzy calculations ( _ numpy _ , _ pyfuzzy _ ) or text pattern recognition by grammars ( _ pyparsing _ ) .",
    "the current implementation supports both linux and windows systems .",
    "the initially supported languages include spanish and galician .",
    "english was also included for research and scientific exposure purposes .",
    "in this section we address the validation process for galiweather , which consists in an exhaustive expert - based revision and quality assessment of a set of automatically generated text forecasts obtained by the application . for this",
    ", we briefly discuss the state of the art in validation methodologies for both nlg and ldd fields and , based on these approaches , we explain in detail the validation methodology we have followed and its associated results . for illustration purposes , we present beforehand three examples of linguistic descriptions from the validation set obtained with the application .",
    "although the short - term prediction data series are limited to 32 values , the number of phenomena which must be considered and its temporal variability ensures a high richness in the obtained linguistic descriptions . as a proof of this richness",
    ", we present in this section the following examples covering several meteorological situations .",
    "the example shown in fig .",
    "[ example3 ] includes real forecast data for the town of pontevedra , issued the 9th of december by meteogalicia .",
    "this case shows how galiweather performs in common meteorological situations , where the weather changes progressively .",
    "the examples shown in fig .",
    "[ example1 ] and fig .",
    "[ example2 ] present unusual and odd meteorological conditions , which were generated using synthetic data forecasts .",
    "these cases were created to test the application robustness under uncommon situations .",
    "both examples include several meteorological phenomena , such as snow , storm , strong winds and temperature variations .",
    "furthermore , each example shows a different precipitation sentence which aggregates the precipitation periods in a different way , as described in section iii - c .",
    "validating automatic natural language generated texts is still an open challenge , even within the nlg field @xcite .",
    "several validation approaches do exist , both human and automatic , although in general , the human validation by experts is considered the most reliable @xcite , @xcite . consequently , the vast majority of nlg systems are validated using expert assessment , which usually implies answering questions about different aspects of the output texts . in the case of the ldd field",
    "several criteria have been proposed for evaluating and measuring the quality of the linguistic descriptions objectively @xcite , but they are not applicable in every approach and the information they provide is very limited compared to that of an expert , besides the fact that many ldd approaches do not reach the nlg stage and are not subject to a full validation process .",
    "meteogalicia s meteorologists have provided support for a human expert validation of the results , which has allowed us to refine the proposed solution in a way that ensures it works under realistic conditions and cases .",
    "for this , we have performed the following validation process :    1 .",
    "* dataset collection creation*. a collection of 45 forecast datasets was created by the meteorologists .",
    "this collection includes synthetic and real forecast data , which covers common as well as unusual meteorologic scenarios , similar to the ones presented in the examples in section iv - a . 2 .",
    "* natural language forecast automatic generation*. from this collection of forecast datasets , 45 automatically generated natural language forecasts were obtained .",
    "* polishing stage*. these 45 natural language forecasts generated by our application were evaluated by a meteorologist who assessed their quality taking into account their most relevant aspects and dimensions of interest .",
    "this initial evaluation was made to obtain preliminary conclusions and polish our approach in those aspects which needed to be improved .",
    "natural language forecast automatic generation*. once the changes to our approach were implemented , new 45 automatically generated language forecasts have been obtained from the original collection of forecast datasets . 5 .",
    "* validation stage*. we have requested the expert to assess the new 45 automatically generated natural language forecasts . as opposed to the results from the polishing stage , which served to identify certain issues and potential improvements , the results of this stage allow to discern if the improvements in our approach are effective and , more importantly , if our application meets the expert s requirements and is consequently prepared to be released as a public service .        in order to assess the quality of the automatically generated forecasts , we have provided the expert meteorologist with a questionnaire which follows the approach presented in @xcite .",
    "this questionnaire covers three key dimensions about the generated weather forecasts , as shown in fig .",
    "[ evaldiagram ] :    * relevance : does the forecast include all the kind of information the expert would include ? * truthfulness : does the included information in the forecast reflect the numeric - symbolic forecast correctly ?",
    "* manner : does the forecast express the information properly ? is it well formatted ?",
    "these three dimensions are directly classified into two higher level categories , `` what the text implicates '' and `` what the text says '' , which altogether determine the quality of the generated forecast .",
    "more specifically , the questionnaire we propose consists of five questions which deal in more depth with the previous three dimensions :    * * question 1 * : `` indicate in which degree you identify the type of results expressed as the type of results expressed by yourself : a ) for sky coverage b ) for precipitations c ) for wind d ) for temperatures '' .",
    "+ this question determines the grade in which an expert identifies the generated forecast with the ones he creates . for reasons of precision , and in order to identify more specific issues in each forecast variable , question 1 was divided into four subquestions , one for each forecast variable . * * question 2 * : `` do you agree with the provided descriptions ?",
    "a ) for sky coverage b ) for precipitations c ) for wind d ) for temperatures '' .",
    "+ this question considers the degree of truthfulness of the generated description , this is , the degree in which the content of the forecast reflects faithfully the information within the numeric - symbolic forecast data . similar to question 1 ,",
    "question 2 is divided into four subquestions . with the ratings of questions 1 and 2 ,",
    "we obtain the partial rating of the forecast related to `` what the text implicates '' .",
    "* * question 3 * : `` indicate in which degree the vocabulary is used correctly '' .",
    "+ this question evaluates if the vocabulary from the meteorology domain is used properly . * * question 4 * : `` indicate in which degree the content is correctly grouped to facilitate the comprehension of the description '' .",
    "+ this question evaluates if the information in the natural language description is properly grouped and not repetitive . * * question 5 * : `` indicate in which degree the format of the report , including the punctuation , is the most adequate '' .",
    "+ question 5 considers aspects related to the forecast text presentation , such as punctuation . with the ratings of questions 3 , 4 and 5",
    "we obtain the partial rating `` what the text says '' .",
    "each of these questions must be answered as a number in a 1 - 5 scale ( from 1 `` very negative '' to 5 `` very positive '' ) .",
    "thus , in order to calculate the global score for the collection of automatically generated forecasts , we follow the global aggregation schema defined in expression ( 2 ) . following this quality measure approach ,",
    "the quality @xmath115 of an automatically generated natural language weather forecast @xmath116 is defined as the arithmetic mean of the two dimensions in layer 3 ( fig .",
    "[ evaldiagram ] ) :    @xmath117    the terms @xmath118 and @xmath119 correspond to the average score of the subquestions a , b , c and d for question 1 and question 2 , respectively .",
    "the remaining terms , @xmath120 , @xmath121 and @xmath122 are the scores for questions 3 , 4 and 5 . as [ score_e ] shows , the average of @xmath118 and @xmath119 ( `` what the text implicates '' ) and the average of @xmath120 , @xmath121 and @xmath122 ( `` what the text says '' ) determine the quality of a forecast .",
    "thus , the global quality score @xmath123 for our collection of automatically generated natural language forecasts is obtained as the average of the validation cases quality score : @xmath124 , where @xmath125 in our case .",
    ".polishing stage questionnaire score [ cols=\"<,^,^\",options=\"header \" , ]     [ results2 ]    based on the results obtained for the polishing stage , we have improved the nlg modules to address the issues found in our first approach and a validation test has been performed by the meteorologist with new 45 automatically generated natural language forecasts . with an average score of 4.83 out of 5 and a deviation of 0.18 ( as table [ results2 ] shows ) ,",
    "the quality increase is substantial . in particular , the results in question 1 show that the expert fully identifies the automatically generated forecasts as if they were produced manually by him .",
    "the fact that both content and language from the automatic forecasts are almost indistinguishable from those that an expert would produce are the most important among the several quality aspects which can be measured for a nlg approach .",
    "the remaining questions also show increased scores compared to the first assessment .",
    "the solution we have presented addresses a specific practical problem by solving the need for providing 315 daily short term weather forecasts , which otherwise would not be possible to produce if they were manually created by a single meteorologist . as a consequence , the nlg stage is problem - oriented and is mostly not reusable . in spite of this , we want to stress the role that linguistic descriptions of data ( ldd ) techniques can play as a generic toolset which can be applied to many domains and give some insights into the generic methodology we are following for this ldd approach .",
    "for example , our application includes highly configurable linguistic description operators , which allow data series of any length and linguistic variables ( implemented as fuzzy or crisp membership functions ) with any number of labels as input .",
    "in fact , most of the changes made to improve the application during the whole development process were made to the linguistic variable definitions used by these operators ( some of which are shown in fig .",
    "[ partitionsample ] ) rather than to the operators themselves .        from our point of view",
    ", the main purpose of creating linguistic description solutions is to provide users with descriptions which make use of easily understandable familiar concepts found in natural language , imprecise and ambiguous in their nature .",
    "these concepts are usually modeled by employing some of the theoretical tools provided by the computation with perceptions field , such as fuzzy quantifiers , linguistic variables and others .",
    "however , the fact that these descriptions include linguistic terms neither implies they are actually expressed in natural language nor means they should be , as it occurs in nlg systems .",
    "in fact , both research fields seem rather complementary , in such a way that ldd provides tools for extracting the most relevant information in the form of ( imprecise ) linguistic terms , which then are used as an input to a nlg system to produce well - constructed sentences which are ready for human consumption .",
    "this is the approach we have followed in our solution , where ldd operators create input descriptions for an independent nlg system which generates natural language forecasts",
    ".    with a clearer view of which aspects ldd , in our opinion , should cover , we can abstract the basic elements which serve as pillars for a general ldd methodology .",
    "many of the approaches described in the literature ( e.g. those referred to in section i ) share several elements in common that can be taken into account for a flexible and reusable methodology for generating linguistic descriptions approaches :    * * operators*. operators extract information from raw data , converting numeric measurements into structures composed of linguistic terms .",
    "originally , linguistic descriptions were conceived as quantified sentences , which resulted from applying fuzzy quantification models to data series .",
    "therefore , many of the existing approaches use some kind of fuzzy quantification to obtain descriptions over one or several variables .",
    "for example , we can apply zadeh s or other quantification models to produce a summary like `` most days of the month were dry '' ( in the case of rain data time series ) .",
    "however , many other operators which extract different pieces of information can be defined and implemented @xcite , such as : evaluation of a fuzzy label over the data series ( e.g. `` most of the temperatures were high in march '' ) , search of data sequences fulfilling a given fuzzy label ( e.g. `` energy consumption was low between days 3 and 10 '' ) , search of increasing or decreasing patterns ( e.g. `` there was a slight increase of valve pressure during the morning '' ) , search of pitches in the dataset or of oscillation patterns ( e.g. `` the system got unstable between 10:00 and 10:30 '' ) , event - counting operators ( e.g. `` there were too many high pitches within the last hours '' ) or summarizing operators based on temporal / spatial hierarchies ( e.g. `` the month was hot but the first week was cold '' ) . for instance , for our ldd approach we have created highly configurable operators for each weather variable , according to the type of information that we needed to extract .",
    "these operators can be applied straight - forwardly to other variables by just replacing the partition sets for the current variables with partition sets for the new ones . * * use of temporal / spatial hierarchies*. in the majority of cases , the numeric data series have an associated temporal and/or spatial component .",
    "this allows to arrange the data in hierarchies , which are usually defined by the experts in the application field .",
    "for example , in a temperature data series which covers one year , with one measurement per day , we can define a temporal hierarchy which would group the individual days in months , the months in seasons and so on .",
    "this considerably improves the exploitation of the available data , allowing to extract richer and more complex information . in our case , we have employed a time hierarchy which divides the short - term forecast temporal window into three subperiods for cloud coverage . * * operator compositions*. operators can be considered as the core primitives or atomic logical units of a framework which generates linguistic descriptions .",
    "these units can be combined in order to build more complex descriptions , depending on the requirements of the specific linguistic description problem .",
    "therefore , means for mixing their outputs should be taken into account as additional elements in our framework .",
    "our ldd approach does not make use of this concept , since the linguistic descriptions we obtain for each variable are independent .",
    "* * evaluation criteria*. the raw output of linguistic description approaches usually consists of several candidate descriptions which must be filtered according to some pre - defined criteria , in order to ensure the quality and truthfulness of the selected final summary .",
    "again , every specific problem needs its own set of adapted criteria , but also some general objective and reusable evaluation criteria , such as the description length , truth or fulfillment degree , data coverage , ambiguity , etc .",
    "should be used @xcite . in our case , we have employed the aggregation of fulfillment degrees of each fuzzy subperiod with respect to each cloud coverage label to obtain the best cloud coverage for each subperiod .",
    "furthermore , we have also used the length of descriptions in order to discriminate the final precipitation text forecast .",
    "although all of these are concepts and notions taken from experience , we believe the main value of this methodology lies in the operators as the building blocks of the ldd approaches .",
    "if a collection of well - tested both in quality and usefulness operators for linguistic description of data is gathered , the viability of a generic ldd framework to create domain - specific approaches is highly ensured . in order to achieve this",
    ", we propose a feedback process which combines bottom - up and top - down approaches . on one hand , we believe that the best way to ensure the usefulness of the operators is to generalize specific solutions taken from real life problems and test them in other contexts . on the other hand , intuition - based operators can also be proposed and tested to check whether the information they produce is relevant to the experts .",
    "this loop which goes from concrete to abstract and then vice versa would help to improve in a correct direction the general ldd framework .",
    "we have presented galiweather , an application which obtains textual short - term weather forecasts for the 315 municipalities in galicia , using the real data provided by meteogalicia .",
    "as opposed to other linguistic descriptions approaches , this solution is based on an applied development in a realistic application , whose definition and structure is inspired by the linguistic descriptions research field by using both fuzzy and crisp operators which extract relevant information , and also by the natural language generation field .    furthermore , the automatically generated textual forecasts were thoroughly evaluated by a meteorologist in order to assess the quality of their contents and to check whether his expert knowledge was included correctly .",
    "the obtained results show that the textual forecasts fulfill the expert s requirements in a very high degree ( 4.83 out of 5 ) .",
    "galiweather is to be released as a real service in a very near future , since the application fully meets the meteorologists requirements .",
    "the automatic linguistic descriptions will be displayed as a new information service at meteogalicia s website @xcite .",
    "the main value of galiweather resides in its ability to cover and support a service of high interest for a wide number of users , which can only be provided by generating descriptions of data in an automatic manner , due to the high number of textual forecasts ( 315 in this case ) which must be obtained .    in a longer term we are considering other application fields in which linguistic descriptions will prove useful . among them",
    ", we have identified linguistic descriptions on information and decision support environmental systems as a promising research line , where not only linguistic descriptions for single location data are interesting , but also descriptions which geographically aggregate data in order to provide region - wide information .",
    "this is a complex challenge which will include the description of data in both time and space dimensions .",
    "this will lead us to develop a general model which can be applied to application fields in other areas .",
    "the authors would like to thank the editors and referees for their comments and suggestions , which have led to a substantial improvement in the paper quality .",
    "we would also like to thank citius and meteogalicia for their support and for providing personal and material means for the development of this application .",
    "n.  kroes .",
    "( 2012 , march ) speech/12/149 digital agenda and open data from crisis of trust to open governing .",
    "presentation of the action plan of the slovak republic in favour of open democracy .",
    "[ online ] .",
    "available : http://europa.eu/rapid/press-release_speech-12-149_en.htm        k.  kukich , `` design and implementation of a knowledge - based report generator , '' in _ proceedings of the 21st annual meeting of the association for computational linguistics ( acl-1983 ) _ , 1983 , pp .",
    "145150 .",
    "l.  iordanskaja , m.  kim , r.  kittredge , b.  lavoie , and a.  polgure , `` generation of extended bilingual statistical reports , '' in _ proceedings of the 14th international conference on computational linguistics ( coling-1992 ) _ , vol .  3 , 1992 , pp .",
    "10191023 .",
    "s.  busemann and h.  horacek , `` generating air - quality reports from environmental data , '' in _ dfki workshop on natural language generation , dfki document d-97 - 06 _ , s.  busemann , t.  becker , and w.  finkler , eds .",
    ", 1997 .",
    "f.  portet , e.  reiter , a.  gatt , j.  hunter , s.  sripada , y.  freer , and c.  sykes , `` automatic generation of textual summaries from neonatal intensive care data , '' _ artif .",
    "_ , vol . 173 , no .",
    "7 - 8 , pp .",
    "789816 , may 2009 .",
    " , `` from computing with numbers to computing with words : from manipulation of measurements to manipulation of perceptions , '' in _ intelligent systems and soft computing : prospects , tools and applications_.1em plus 0.5em minus 0.4emspringer - verlag , 2000 , pp",
    ". 340 .",
    "r.  r. yager , k.  m. ford , and a.  j. caas , `` an approach to the linguistic summarization of data , '' in _ uncertainty in knowledge bases , 3rd international conference on information processing and management of uncertainty in knowledge - based systems , ipmu 90 , paris , france , july 2 - 6 , 1990 , proceedings _ , ser .",
    "lecture notes in computer science , b.  bouchon - meunier , r.  r. yager , and l.  a. zadeh , eds .",
    "521.1em plus 0.5em minus 0.4emspringer , 1990 , pp",
    ". 456468 .",
    "j.  kacprzyk and s.  zadrozny , `` linguistic database summaries and their protoforms : towards natural language based knowledge discovery tools , '' _ inf .",
    "173 , no .  4 , pp . 281304 , 2005 .",
    "d.  sanchez - valdes , l.  eciolaza , and g.  trivino , `` linguistic description of human activity based on mobile phone s accelerometers , '' in _ ambient assisted living and home care _",
    "lecture notes in computer science , j.  bravo , r.  hervs , and m.  rodrguez , eds.1em plus 0.5em minus 0.4emspringer berlin heidelberg , 2012 , vol . 7657 , pp .",
    "346353 .          j.  kacprzyk and a.  wilbik , `` using fuzzy linguistic summaries for the comparison of time series : an application to the analysis of investment fund quotations , '' in _ proceedings ifsa / eusflat conf .",
    "2009 _ , 2009 , pp .",
    "13211326 .",
    "j.  kacprzyk and s.  zadrozny , `` linguistic data summarization : a high scalability through the use of natural language ? '' _ scalable fuzzy algorithms for data management and analysis : methods and design _ , pp . 214237 , 2010 .",
    "f.  daz - hermida , a.  ramos - soto , and a.  bugarn , `` on the role of fuzzy quantified statements in linguistic summarization , '' in _ proceedings of 11th international conference on .",
    "intelligent systems design and applications ( isda ) _ , 2011 , pp .",
    "166171 .",
    "r.  castillo - ortega , n.  marn , d.  snchez , and a.  tettamanzi , `` quality assessment in linguistic summaries of data , '' in _ advances in computational intelligence _ , ser .",
    "communications in computer and information science , s.  greco , b.  bouchon - meunier , g.  coletti , m.  fedrizzi , b.  matarazzo , and r.  yager , eds.1em plus 0.5em minus 0.4emspringer berlin heidelberg , 2012 , vol .",
    "285294 .    c.  menendez and g.  trivino , `` selection of the best suitable sentences in linguistic descriptions of data , '' in _ advances in computational intelligence _ , ser .",
    "communications in computer and information science , s.  greco , b.  bouchon - meunier , g.  coletti , m.  fedrizzi , b.  matarazzo , and r.  yager , eds.1em plus 0.5em minus 0.4emspringer berlin heidelberg , 2012 , vol .",
    "295304 .",
    "e.  reiter , `` task - based evaluation of nlg systems : control vs real - world context , '' in _ proceedings of the ucnlg+eval : language generation and evaluation workshop _",
    "ucnlg+eval 11 , 2011 , pp .",
    "2832 .",
    "r.  sambaraju , e.  reiter , r.  logie , a.  mckinlay , c.  mcvittie , a.  gatt , and c.  sykes , `` what is in a text and what does it do : qualitative evaluations of an nlg system  the bt - nurse  using content analysis and discourse analysis , '' in _ proceedings of the 13th european workshop on natural language generation _ , ser .",
    "enlg 11.1em plus 0.5em minus 0.4em association for computational linguistics , 2011 , pp .",
    "2231 .",
    "alejandro ramos received the m.s.c .",
    "degree in computer science from the university of santiago de compostela ( usc ) , spain , in 2011 .",
    "he is currently a ph.d .",
    "student at its research centre on information technologies ( citius ) .",
    "his research interests include linguistic descriptions of data and natural language generation .",
    "alberto j. bugarn received the ph.d .",
    "degree in physics from the university of santiago de compostela ( usc ) , spain , in 1994 .",
    "he is currently a full professor at its research centre on information technologies ( citius ) .",
    "his research interests mainly focus on linguistic data description of data using natural language generation , machine learning techniques for fuzzy knowledge bases discovery and fuzzy temporal knowledge representation and reasoning . on these and related topics and their applications",
    "he has published more than 150 scientific refereed papers and participated in more than 40 r+d projects and contracts .",
    "senn barro received the ph.d . in physics with distinction from the university of santiago de",
    "compostela ( usc ) , spain , in 1988 .",
    "he is professor in the area of computer science and artificial intelligence .",
    "he was head of the computer and electronic department of the university of santiago de compostela from 1993 to 2002 , and the rector of this university from 2002 to 2010 .",
    "since may 2008 he is the president of redemprendia , which is made of 24 european and latin american universities , focused on transfer on r&d , innovation and entrepreneurship .",
    "he founded the usc intelligent systems group , which he also directs , and which currently has more than 40 members and is one of the first artificial intelligence groups in spain .",
    "he has been editor or author of seven books and author of more than 200 scientific articles .",
    "he has also been member of organizing , scientific and publishing committees of international conferences and journals .",
    "juan taboada received the ph.d .",
    "degree in physics from the university of santiago de compostela ( usc ) , spain , in 1999 , after a two - year stage in the university of paris vi .",
    "he currently leads the operational weather forecast department in meteogalicia , the galician ( nw spain ) meteorological agency .",
    "his research areas include climate variability and change , and seasonal and weather forecasting ."
  ],
  "abstract_text": [
    "<S> we present in this paper an application which automatically generates textual short - term weather forecasts for every municipality in galicia ( nw spain ) , using the real data provided by the galician meteorology agency ( meteogalicia ) . </S>",
    "<S> this solution combines in an innovative way computing with perceptions techniques and strategies for linguistic description of data together with a natural language generation ( nlg ) system . </S>",
    "<S> the application , named galiweather , extracts relevant information from weather forecast input data and encodes it into intermediate descriptions using linguistic variables and temporal references . </S>",
    "<S> these descriptions are later translated into natural language texts by the natural language generation system . </S>",
    "<S> the obtained forecast results have been thoroughly validated by an expert meteorologist from meteogalicia using a quality assessment methodology which covers two key dimensions of a text : the accuracy of its content and the correctness of its form . following this validation galiweather </S>",
    "<S> will be released as a real service offering custom forecasts for a wide public .    at ( [ yshift=1cm]current page text area.north ) </S>",
    "<S> this article has been accepted for publication in a future issue of this journal , but has not been fully edited . </S>",
    "<S> content may change prior to final publication . </S>",
    "<S> + citation information : doi 10.1109/tfuzz.2014.2328011 , ieee transactions on fuzzy systems ; at ( [ yshift=-1cm]current page text area.south ) 1063 - 6706 ( c ) 2013 ieee . </S>",
    "<S> personal use is permitted , but republication / redistribution requires ieee permission . </S>",
    "<S> + see http://www.ieee.org/publications_standards/publications/rights/index.html for more information . ;    linguistic descriptions of data , natural language generation , computing with perceptions , open data </S>"
  ]
}