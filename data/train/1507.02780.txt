{
  "article_text": [
    "receding horizon optimal control ( rhc ) is a strategy for controlling a dynamical system over an ( possibly ) infinite horizon where the control input at any instant is derived by solving a finite horizon optimal control problem over a fixed length horizon from that instant forwards .",
    "an introduction to rhc can be found in @xcite .",
    "rhc is a natural extension of finite - horizon optimal control and a natural simplification of infinite - horizon optimal control .",
    "the term model predictive control is often used interchangeably with rhc .",
    "the contribution of this work is :    1 : :    we study the stability of continuous - time receding horizon control of    nonlinear stochastic systems when the optimal controller computation    is only approximate .",
    "in particular , we consider a number of classes of    controller approximation error including deterministic and    probabilistic errors .",
    "we also consider controller sample and hold    errors , that arise due to real - time computing limitations etc .",
    "2a : :    we outline a ( monte carlo ) simulation algorithm for approximating the    optimal receding horizon control for nonlinear stochastic    continuous - time systems .",
    "2b : :    we connect the controller approximation technique to the stability    analysis detailed in this work and show that this monte carlo    simulation method for controller approximation stabilises the process    ( in a sense to be made precise ) . in particular , the approximation    errors do not accumulate nor destabilise the system .",
    "the analysis of rhc for nonlinear ( deterministic ) systems started , largely , with the analysis of mayne et .",
    "even in this early work , stability was considered for rhc in the presence of a number of controller approximation errors . broad work on this topic in the nonlinear realm is covered in @xcite .",
    "much work in this area has focused on the incorporation of ( deterministic ) model uncertainty @xcite and/or controller and state constraints @xcite .",
    "this latter focus concerning constraints is largely beyond the scope of this study , although we comment on possible extensions in our concluding remarks .    in the stochastic realm ,",
    "the foundations of optimal control of nonlinear ( continuous - time ) systems are studied in , e.g. , @xcite .",
    "computational methods for general nonlinear stochastic rhc are given in , e.g. , @xcite .",
    "in continuous - time cases , optimal nonlinear rhc has been shown @xcite to be stabilising under the assumption that an optimal controller is applied ( exactly ) . in this work ,",
    "we extend @xcite by showing that stability is retained even in the presence of controller approximation errors .",
    "we consider a number of general classes of controller approximation error , including deterministic and probabilistic errors and also controller sample and hold errors . to the best of our knowledge",
    ", there has been no investigation on the stochastic stability of ( nonlinear stochastic ) rhc in the presence of controller approximation errors .    in this work",
    "we also outline an approximation method for computing the optimal rhc for nonlinear stochastic continuous - time systems .",
    "this method is based on monte carlo integral approximation and originates in the work of kappen @xcite where such techniques were applied in finite - horizon optimal control for nonlinear stochastic systems .",
    "the broad idea is that a solution to the hamilton - jacobi - bellman partial differential equation associated with a typical optimal control problem @xcite can be formulated in terms of an expectation over a stochastic trajectory defined by an uncontrolled stochastic differential equation ( sde ) .",
    "indeed , this relationship between partial differential equations and so - called path - integrals is just a consequence of feynman - kac s formula @xcite . this expectation ( or path - integral ) can then be approximated via monte carlo simulation , and since this defines the solution to the hamilton - jacobi - bellman equation , it is a short leap from there to the optimal controller ( or its approximation ) .",
    "this numerical algorithm for optimal control has received interest in , e.g. , @xcite where a number of generalisations ( and applications ) have been investigated . to the best of our knowledge ,",
    "no investigation of the stochastic stability of this approximation method has been considered .",
    "a contribution of this work is the analysis of this monte carlo based controller approximation method , as it applies to rhc of nonlinear stochastic continuous - time systems .",
    "in particular , we relate this approximation method to the more general stability analysis provided in this work and we show that this method stabilises the system ( in a specific sense to be defined ) .",
    "this stability analysis justifies application of this control algorithm over an extended , possibly infinite , time interval .",
    "the remainder of this work is organised as follows : in section 2 we outline the basic nonlinear stochastic rhc problem and some related notation . in section 3",
    "we consider the stability of the nonlinear stochastic rhc regime .",
    "in particular , we note the stabilisation properties of the optimal ( ideal ) controller and we analyze the stability properties of a number of controller approximation methods . in section 4 we introduce the monte carlo based algorithm for controller approximation and we relate this algorithm and its stability properties to the results given in the previous section . in section 5",
    "we provide some concluding remarks and comment on a number of possible extensions .",
    "let @xmath0 be a complete probability space equipped with the natural filtration @xmath1 generated by a fixed , standard , wiener process @xmath2 .",
    "we consider a nonlinear controlled process @xmath3",
    "@xmath4 with @xmath5 .",
    "we assume @xmath6 and @xmath7 to be continuous .",
    "the stochastic integrals in this paper are to be read in the ito sense @xcite .",
    "moreover we assume that @xmath8 @xmath9 for some finite constant @xmath10 .",
    "let @xmath11 , then the superscripts @xmath12 denote that the initial state at @xmath13 is @xmath14 and the control history is @xmath15 .    fix a time interval @xmath16 $ ] .",
    "then a control @xmath17\\times\\omega\\to u$ ] is said to be admissible if it is borel measurable and @xmath18 < \\infty , \\quad \\forall x \\in { \\mathbb{r}}^n,~ q{\\geqslant}1\\ ] ] we denote by @xmath19}$ ] the class of admissible controls on @xmath16 $ ] .",
    "these conditions are sufficient for the existence of a unique , continuous , ( strong ) solution to the stochastic process ; e.g. see @xcite .    here",
    "we consider control and stabilisation to ( a neighbourhood of ) the origin ; any other desired set point can be substituted via a simple change of coordinates . to this end , we fix @xmath20 , i.e. the origin is an equilibrium point for the nominal deterministic system .",
    "let @xmath21 be fixed .",
    "we associate with ( [ generalsystemcontrol ] ) the following receding horizon cost functional @xmath22,~~\\quad \\mathrm{for}~s\\in[0,t ] \\nonumber\\ ] ] where @xmath23 and @xmath24 are non - negative continuous functions that satisfy @xmath25 and @xmath26 for some finite ( independent ) constants @xmath27 and @xmath28 .",
    "further , @xmath29 and @xmath30 .",
    "we define a value functional as @xmath31}}~w(t , s , x , u ) ~=\\inf_{u_{r}\\in{\\mathcal{u}}_{[t+s , t+t ] } } { \\mathbb{e}}\\left[\\phi(x^{t+s , x , u}_{t+t } ) + \\int_{t+s}^{t+t}\\ell(x^{t+s , x , u}_{r},u_{r})dr\\right ] \\label{value}\\ ] ] and denote by @xmath32 , if it exists , the optimal control , i.e. the admissible control process over the finite horizon @xmath33 $ ] that minimizes ( [ value ] ) . in ( one - step ) rhc it is necessary just to compute @xmath32 for @xmath34 at which point the cost functional ( and thus the value functional ) changes to capture the receding horizon .",
    "the value functional is time - invariant with respect to the first argument , in the sense that @xmath35 } } { \\mathbb{e}}\\left[\\phi(x^{t+s , x,{u}}_{t+t } ) + \\int_{t+s}^{t+t}\\ell(x^{t+s , x,{u}}_{r},{u}_r(x))dr\\right ] \\nonumber \\\\          & = & \\ , \\inf_{u_{r}\\in{\\mathcal{u}}_{[s , t ] } } { \\mathbb{e}}\\left[\\phi(x^{s , x,{u}}_{t } ) \\,+\\ , \\int_{s}^{t}\\ell(x^{s , x,{u}}_{r},{u}_r(x))dr\\right ] ~=~ { v}(0,s , x ) \\nonumber\\end{aligned}\\ ] ]    note that when viewed over @xmath36 $ ] the value function represents the so - called value - to - go over the fixed finite horizon @xmath33 $ ] .",
    "going forward , we often write @xmath37 in place of @xmath38 or @xmath39 in place of @xmath40 when dealing with the value - to - go function .    with the modelling hypotheses adopted thus far , we have the following key lemma .",
    "[ lemmavbounds ] there exist a pair of positive constant @xmath41 , depending only on @xmath42 , such that @xmath43 and thus @xmath44 with @xmath45 .",
    "the proof of the lemma is given in the appendix .",
    "going forward we write @xmath46 and @xmath47 for the jacobian vector and hessian matrix respectively .",
    "furthermore , @xmath48 } } { \\mathbb{e}}\\left[\\phi(x^{s , x,{u}}_{t+t } ) + \\int_{s}^{t}\\ell(x^{s , x,{u}}_{r},{u}_r(x))dr\\right]\\ ] ] where @xmath49 is defined on @xmath36 $ ] for any @xmath50 .",
    "we often write @xmath51 with @xmath52 $ ] in place of @xmath53 for brevity .    under certain conditions , at any time",
    "@xmath36 $ ] the following hamilton - jacobi - bellman ( hjb ) equation can be associated with the general value functional @xmath54\\right ] \\nonumber\\ ] ] with a terminal boundary condition @xmath55 .",
    "this association is in the sense that a suitably smooth solution to the hjb equation , if it exists , coincides with the value - to - go @xcite .",
    "note that in ( one - step ) rhc we are only interested in the solution of the hjb equation @xmath56 at time @xmath57 on the interval @xmath36 $ ] .",
    "we note that assumptions introduced in this work are assumed to hold from the point at which they are introduced throughout the remainder of the work .",
    "the modelling hypotheses , e.g. on the functions @xmath58 , @xmath59 , @xmath60 , @xmath61 , etc . are assumed to hold throughout the remainder until the point they are refined ( typically specialised ) and from which point the refinement is supposed to hold .",
    "[ assump1 ] we assume that the modelling assumptions outlined to this point are augmented ( where and how necessary ) to ensure @xmath62\\times{\\mathbb{r}^{n}}\\rightarrow[0,\\infty)$ ] is once continuously differentiable in @xmath36 $ ] and twice continuously differentiable in @xmath14 for all @xmath63 and that @xmath39 is a solution to the corresponding associated hjb equation .    sufficient conditions for this assumption to hold ( in addition to the modelling hypotheses introduced thus far ) are given in , e.g. , @xcite .",
    "typically , these sufficient conditions take the form of further boundedness or regularity assumptions on the system and cost functions and/or their ( partial ) derivatives and are not overly restrictive , it generally follows that a classical ( unique ) solution to the hjb equation will exist in the stochastic setting ( under mild regularity assumptions on the model / cost ) ; see chapter iv.4 in @xcite or krylov @xcite . under the modelling hypotheses introduced in this work , uniform parabolicity follows",
    "if @xmath64 is full - rank ( there is no real loss of generality here ) and if @xmath64 is bounded below ( which is compatible with the hypotheses thus far ) .",
    "separately , with an added lipschitz assumption on the cost ( compatible with the hypotheses herein ) , a classical solution to the hjb equation not only exists but is indeed lipschitz @xcite .",
    "this lipschitz setting is commonly assumed when studying the characteristics of stochastic optimal control ; e.g. see @xcite .",
    "note , we do not generally require ( or ask ) for this lipschitz property here . in any case , assumptions of this type concerning the existence of a classical solution are common in the analysis of both deterministic @xcite and stochastic optimal control @xcite . ] .",
    "we could also move from considering classical solutions of the hjb equation to generalised or viscosity solutions @xcite .",
    "given the admissible optimal control process @xmath65 over the finite horizon @xmath36 $ ] then the optimal value function over the finite horizon from any @xmath50 to @xmath66 is @xmath67\\ ] ] and , given assumption [ assump1 ] , the value - to - go satisfies the following hjb equation @xmath68 \\label{hjb}\\end{aligned}\\ ] ] on @xmath36 $ ] with the terminal boundary condition @xmath55 .",
    "we will use the following assumption .",
    "[ assump2 ] we assume @xmath69 at any time @xmath50 where @xmath70 $ ] .    this assumption implies the optimal cost , when viewed at the start of a finite horizon , is increasing with decreasing horizon lengths .",
    "one way to interpret this is that if the horizon length is reduced then the control action has less time to stabilize the system and thus the terminal cost is likely to be greater even though the running cost might be reduced .",
    "finally , we highlight again that in optimal rhc , at any time @xmath50 , the applied control is just @xmath71 and the remaining , finite horizon , controls @xmath65 over @xmath72 are discarded .",
    "it has been shown in @xcite that nonlinear stochastic receding horizon control stabilises the system to the origin if the true optimal control is applied ( and under comparable assumptions and hypotheses to those considered here ) . in this section ,",
    "we generalise this result to the case in which approximations in computing the optimal control are naturally employed , i.e. that the origin is an ` exact ' equilibrium for the diffusion , and thus the noise ` goes to zero ' at this point . here , we consider the practical case in which approximations are made when computing the optimal control , and we study stability to some neighbourhood of the origin .",
    "thus , we also do not require @xmath73 . ] .",
    "going forward we write @xmath74 for the @xmath75 ball around the origin and we use the shorthand @xmath76 to denote the level set @xmath77 for @xmath78 . for any",
    "@xmath79 define @xmath80 . informally stated , we study stability to @xmath81 where , from ( [ lemmavbounds ] ) , it follows that @xmath81 is contained in a ball around the origin with radius tending to @xmath82 as @xmath83 .",
    "we introduce the following control signal @xmath84 with @xmath85 for some sufficiently small @xmath86 .",
    "we denote by @xmath87 trajectories of ( [ generalsystemcontrol ] ) driven by @xmath88 with @xmath89 . if @xmath90 then @xmath91 for all @xmath50 ; i.e. we recover the optimally controlled process in some suitable sense ( to be made precise ) .",
    "the goal in this subsection is to prove that if @xmath92 is small then @xmath93 behaves similarly to @xmath94",
    ".    we will require the following assumption .",
    "[ derivatives ] there exists a constant @xmath95 such that @xmath96 .    for generality ,",
    "we have stated our requirement that @xmath97 as an assumption .",
    "nevertheless , results of this type , i.e. results concerning estimates / bounds of the derivative of the value function , are well studied holds under the given modelling hypotheses adopted in this work ( on the cost / dynamics ) with essentially the additional assumption @xmath98 , @xmath99 .",
    "thus , we already have the basic conditions on the dynamics / cost to ensure this assumption holds .",
    "see chapter iv.8 in @xcite and also chapter 3 and chapter 4 in @xcite .",
    "even stronger results have been proven @xcite implying this assumption holds trivially when one begins imposing lipschitz conditions on the cost @xmath100 . ] and conditions on @xmath58 , @xmath59 , @xmath61 , and @xmath60 under which this assumption is guaranteed to hold are readily available @xcite .",
    "[ deterministicrobustnesstheorem ] suppose assumptions [ assump1 ] , [ assump2 ] and [ derivatives ] , and the modelling hypotheses hold .",
    "define @xmath101 and @xmath102 .",
    "solutions of the sde ( [ generalsystemcontrol ] ) driven by the optimal control @xmath103 satisfy :    * if @xmath104 then , with probability one , @xmath105 will never exit @xmath81 and @xmath106 ; * if @xmath107 , it holds @xmath108 and , with probability one , @xmath105 hits @xmath109 in finite time .",
    "these two points imply that almost all solutions to ( [ generalsystemcontrol ] ) driven by the optimal control @xmath103 are exponentially stable to a ball around the origin and almost all trajectories remain within this ball",
    ".    moreover there exists @xmath110 such that if @xmath111 then solutions of the sde ( [ generalsystemcontrol ] ) driven by the control law @xmath112 satisfy the following :    * if @xmath104 , then with probability one , @xmath113 never exits @xmath81 and @xmath114 ; * if @xmath115 , there exists a constant @xmath116 such that @xmath117 and the constant @xmath118 satisfies @xmath119 further , with probability one , @xmath113 hits @xmath109 in finite time .",
    "these two points imply that almost all solutions to ( [ generalsystemcontrol ] ) driven by the approximate control @xmath112 are exponentially stable to a ball around the origin and almost all trajectories remain within this ball .",
    "such solutions converge exponentially fast under @xmath112 but slower than under @xmath103 . in the limit",
    "@xmath120 we recover the stability properties of the optimal controller .",
    "going forward , we use the shorthand @xmath93 for the process ( [ generalsystemcontrol ] ) driven by @xmath121 .",
    "we prove only the second half of the theorem concerning the approximate controller @xmath112 .",
    "statements on the optimal control follow with @xmath122 .    under the hypotheses of the theorem it follows that @xmath123 for some @xmath124 .",
    "let @xmath125 denote the infinitesimal generator @xcite of @xmath126",
    ". then @xmath127 \\nonumber\\ ] ] is a function of @xmath128 derived by applying the infinitesimal generator to @xmath37 . from ( [ hjb ] )",
    ", we have @xmath129 which by the modelling hypotheses and assumption [ assump2 ] is strictly negative definite @xmath130 for all @xmath63 and @xmath131 at @xmath132 .",
    "now , ito s formula yields @xmath133 dt + \\langle g({\\widehat{x}}_t)dw_t , \\partial_x v({\\widehat{x}}_t ) \\rangle\\ ] ] adding and subtracting @xmath134 , and using the hjb equation ( [ hjb ] ) , we obtain @xmath135 set @xmath136 where @xmath137 is the infinitesimal generator of @xmath93 applied to @xmath37 , for any @xmath128 .    recall that the infinitesimal generator is a purely local construction @xcite which allows us to consider @xmath137 and @xmath138 at the same point in space - time .    by using the lipschitz condition on @xmath139 and the cauchy - schwartz inequality we obtain @xmath140",
    "we define @xmath141 there exists @xmath110 small enough so @xmath142 .",
    "moreover we see that @xmath143 .",
    "going forward we write @xmath144 for simplicity .",
    "it is easy to check that on @xmath145 we have @xmath146 we define @xmath147 .",
    "then , on the set @xmath145 , it follows @xmath148 where @xmath149 is the infinitesimal generator of @xmath93 applied to @xmath150 , for any @xmath128 at @xmath50 .",
    "assume now @xmath151 .",
    "given @xmath50 , define the stopping times @xmath152 i.e. @xmath153 are , respectively , the first exit and re - entry time of the process @xmath93 in @xmath81 before @xmath154 . going forward we write @xmath155 in place of @xmath156 for simplicity . by definition , for any @xmath157 , we have @xmath158 we know @xmath159 is a martingale .",
    "then , the optional sampling theorem @xcite implies @xmath160={\\mathbb{e}}\\left[\\int_{\\tau_1}^{\\tau_2 } \\widehat{{\\mathcal{l}}v}({\\widehat{x}}_s)ds \\right ] { \\leqslant}0\\ ] ] where the last inequality follows from ( [ lvestimate ] ) .",
    "we also note that , by definition , @xmath161",
    ". therefore we have @xmath162 almost surely and consequently @xmath163 almost surely .",
    "thus , if the process starts in the set @xmath81 it can never exit this set .",
    "it follows that @xmath164 ~{\\leqslant}~ \\frac{m_\\delta } { c_4}\\ ] ] and proof of the first point is complete .",
    "now assume @xmath107 , fix @xmath154 and define the following stopping time @xmath165 note that we have already considered the case @xmath166 .",
    "now write @xmath167 and take the expectation of both sides . arguing as before @xmath168{\\leqslant}0 $ ]",
    ". moreover @xmath169 ~=~ { \\mathbb{e}}\\left[e^{\\frac{\\alpha}{\\beta}t}v({\\widehat{x}}_t ) -e^{\\frac{\\alpha}{\\beta}\\tau}v({\\widehat{x}}_\\tau)\\right ] ~{\\leqslant}~ m_\\delta{\\mathbb{e}}\\left[e^{\\frac{\\alpha}{\\beta}t}-e^{\\frac{\\alpha}{\\beta}\\tau}\\right ] ~{\\leqslant}~ m_\\delta e^{\\frac{\\alpha}{\\beta}t } \\nonumber\\end{aligned}\\ ] ] hence , using the two inequalities just shown , ( [ vestimate ] ) and ( [ lemma1 ] ) we have @xmath170 ~=~ \\frac{e^{-\\frac{\\alpha}{\\beta}t}}{c_4}{\\mathbb{e}}\\left[v({\\widehat{x}}_t)\\right ] ~{\\leqslant}~ \\frac{e^{-\\frac{\\alpha}{\\beta}t}}{c_4 } ( v(x_0)+ m_\\delta e^{\\frac{\\alpha}{\\beta}t } ) ~{\\leqslant}~ \\frac{\\beta}{c_4 } |x_0|^p e^{-\\frac{\\alpha}{\\beta}t } + \\frac{m_\\delta}{c_4 } \\nonumber\\end{aligned}\\ ] ] and proof of so - called exponential p - stability is complete .",
    "now , we have already shown @xmath171={\\mathbb{e}}\\left[\\int_0^{\\tau } { \\mathcal{l}}v({\\widehat{x}}_s)ds \\right ] { \\leqslant}0 $ ] which implies @xmath172 { \\leqslant}v(x_0)$ ] .",
    "further , @xmath173 ~=~{\\mathbb{e}}\\left [ v({\\widehat{x}}_{\\tau})e^{\\gamma \\tau } \\mathbbm{1}_{\\{\\tau \\neq t\\ } } + v({\\widehat{x}}_{\\tau})e^{\\gamma \\tau } \\mathbbm{1}_{\\{\\tau =   t\\ } } \\right ] ~{\\geqslant}~ { \\mathbb{e}}\\left[v({\\widehat{x}}_{\\tau})e^{\\gamma \\tau } \\mathbbm{1}_{\\{\\tau =   t\\ } } \\right ] ~>~ m_\\delta e^{\\gamma t } \\mathbb{p } ( \\tau = t)\\ ] ] and thus @xmath174 for all @xmath154 .",
    "this implies @xmath175 as @xmath176 which in turn implies that @xmath177 . from this and inequality ( [ lvestimate ] )",
    "it follows that @xmath178 is a positive supermartingale . from theorem 5.1 in @xcite",
    "it follows that @xmath178 converges almost surely to a finite limit ( dependent on @xmath179 ) as @xmath176 .",
    "then , from ( [ vestimate ] ) we have @xmath180 with probability one .",
    "letting @xmath176 proves that almost all solutions converge exponentially fast toward @xmath109 .",
    "results of this type are known @xcite , i.e. where @xmath181-th moment exponential stability implies almost sure exponential stability .",
    "we now turn our attention to the case where the perturbed controller has a gaussian distribution , @xmath182 and the evolution of the nonlinear controlled process @xmath183 follows @xmath184 with the existing modelling hypotheses holding . here",
    "@xmath185 is continuous with @xmath186 for some finite constant @xmath10 .",
    "we denote by @xmath87 trajectories of ( [ gaussianperturbedsystemcontrol ] ) driven by @xmath88 with @xmath89 .    in this subsection",
    "we seek a result analogous to theorem [ deterministicrobustnesstheorem ] under the proposed probabilistic controller error model .",
    "the goal is to show that if @xmath187 for all @xmath128 then @xmath90 and @xmath91 for all @xmath50 ; i.e. we recover the optimally controlled process in some suitable sense .    as before we need a further assumption on the derivatives of the value function .",
    "[ derivatives2 ] one of the two following condition holds :    * there exists a constant @xmath188 such that @xmath189 ; * there exists a constant @xmath188 such that @xmath190 and @xmath191 is bounded .    as with assumption [ derivatives ] , we have stated our requirement that @xmath192 as an assumption ( for the sake of generality ) . yet",
    "similarly again , results of this type , i.e. results concerning estimates / bounds of the second derivative of the value function , are well studied in the literature it is proven in @xcite that @xmath192 holds under the modelling hypotheses adopted in this work ( on the cost / dynamics ) , with essentially the additional assumption that @xmath98 and @xmath193 , @xmath99 .",
    "see chapter iv.9 in @xcite and also chapter 3 and chapter 4 in @xcite .",
    "again , stronger results have been proven @xcite implying this assumption holds trivially when one imposes lipschitz conditions on the cost @xmath100 , which is common in similar analysis @xcite . ]",
    "@xcite .",
    "the following is the main result of this subsection .",
    "[ probabilisticrobustnesstheorem ] suppose assumption [ assump1 ] , [ assump2 ] and [ derivatives2 ] and the relevant modelling hypotheses hold .",
    "define @xmath101 and @xmath102 .",
    "solutions of ( [ gaussianperturbedsystemcontrol ] ) driven by the optimal control @xmath103 satisfy the relevant convergence results in theorem [ deterministicrobustnesstheorem ] .",
    "moreover , there exists @xmath110 such that if @xmath194 and the following holds @xmath195    * @xmath196 ; * @xmath197  and  for  any  norm  @xmath198    then solutions of the sde ( [ gaussianperturbedsystemcontrol ] ) driven by the approximated controller @xmath112 satisfy the following :    * if @xmath104 , then with probability one , @xmath113 never exits @xmath81 and @xmath199 ; * if @xmath115 , there exists a constant @xmath116 such that @xmath200 and @xmath118 obeys @xmath201 ( where @xmath202 is the convergence rate of the optimal control ; see theorem [ deterministicrobustnesstheorem ] ) .",
    "further , with probability one , @xmath113 hits @xmath109 in finite time .",
    "thus , almost all solutions to ( [ gaussianperturbedsystemcontrol ] ) driven by the approximate control @xmath112 are exponentially stable to a ball around the origin and almost all trajectories remain within this ball .",
    "such solutions converge exponentially fast under @xmath112 but slower than under @xmath103 . as @xmath120 we recover the stability properties of the optimal controller .    as before , denote by @xmath93 the process ( [ gaussianperturbedsystemcontrol ] ) driven by the approximated control @xmath121 .",
    "we quickly find @xmath203 since @xmath204 is ( symmetric ) positive - definite we have @xmath205 where @xmath206 exists and is unique",
    ". then @xmath196 implies @xmath207 where @xmath208 is a standard brownian motion @xcite .",
    "the two brownian motions @xmath208 and @xmath209 are realised on two different spaces : we have already fixed @xmath210 and we denote by @xmath211 the space associated with the probabilistic controller approximation such that @xmath212^\\top$ ] defines a fixed brownian motion on @xmath213 .",
    "let @xmath214 $ ] where the process @xmath94 defining @xmath37 is defined by ( [ gaussianperturbedsystemcontrol ] ) driven with the optimal control @xmath215 .",
    "we consider @xmath216 + \\frac{1}{2 } { \\mbox{tr}}[\\sigma(x ) h(x)h(x)^\\top \\partial_{xx } v]\\ ] ] where @xmath137 is the infinitesimal generator of @xmath93 applied to @xmath37 , for any @xmath128 at @xmath50 .",
    "again , @xmath137 should be viewed as a function of @xmath128 .",
    "we know that @xmath217   < -c_2|x|^p\\ ] ] from the proof of theorem [ deterministicrobustnesstheorem ] , i.e. @xmath138 . owing to assumption [ derivatives2 ] we have , for some positive constant @xmath218 , @xmath219 { \\leqslant}\\epsilon c ( |x|^p+1)\\ ] ] and therefore , @xmath220 define @xmath221 and the proof now follows exactly that of theorem [ deterministicrobustnesstheorem ] and we omit the repetition for brevity .",
    "we now state a simple corollary that takes into account a mixed probabilistic and deterministic controller error .",
    "[ mixederror ] suppose we are working under ( [ gaussianperturbedsystemcontrol ] ) and assumptions [ assump1 ] to [ derivatives2 ] and the modelling hypotheses outlined thus far hold .",
    "define @xmath101 and @xmath102 .",
    "there exist @xmath222 such that if @xmath223 and @xmath224 and    * @xmath225 , * @xmath226 , * @xmath197  and  for  any  norm  @xmath227 ,    holds @xmath228 , then solutions of the sde ( [ gaussianperturbedsystemcontrol ] ) driven by the approximate control law @xmath112 satisfy :    * if @xmath104 , then with probability one , @xmath113 never exits @xmath81 and @xmath229 ; * if @xmath115 , put @xmath230 .",
    "there exists a constant @xmath116 such that @xmath231 and @xmath118 obeys @xmath201 ( where @xmath202 is the convergence rate of the optimal control ; see theorem [ deterministicrobustnesstheorem ] ) .",
    "also , with probability one , @xmath113 hits @xmath109 in finite time , i.e. almost all solutions converge exponentially fast toward @xmath109 .",
    "if @xmath232 then @xmath225 implies @xmath233 where @xmath208 is a standard brownian motion .",
    "it is then easily seen that the error is split in two parts , one part formed by the added brownian motion and the other part formed by the deterministic error @xmath234 with @xmath226 , @xmath195 .",
    "the proof of both theorem [ deterministicrobustnesstheorem ] and [ probabilisticrobustnesstheorem ] apply readily in this case and we omit the details for brevity .    in many practical scenarios",
    "it is impossible to compute the optimal control instantaneously and one must instead resort to a sample and hold approach to control whereby the control is computed at discrete - time increments and held constant in between such times .",
    "stability results for such approaches have been considered , e.g. , in deterministic settings @xcite and stochastic settings @xcite .",
    "we now provide a related stability result .",
    "[ sampledcontrolprop ] consider the more general controlled process ( [ generalsystemcontrol ] ) and suppose assumptions [ assump1 ] , [ assump2 ] , and the relevant modelling hypotheses hold .",
    "suppose that under a given control law @xmath235 the solution @xmath236 to the sde ( [ generalsystemcontrol ] ) with initial condition @xmath179 satisfies @xmath237 for some positive constants @xmath238 and @xmath239 . now fix a time step @xmath240 and let the time interval @xmath241 be discretised according to @xmath242 , @xmath243 , @xmath244 , @xmath245 , @xmath246 .",
    "consider the control law defined by @xmath247 for @xmath248 , i.e. the control @xmath112 is held constant over small time intervals with a value given by the control @xmath249 at the beginning of each interval .",
    "then there exists a constant step size @xmath250 and constants @xmath251 such that @xmath252 for all @xmath253 and where we denote by @xmath87 trajectories of ( [ generalsystemcontrol ] ) driven by @xmath88 with @xmath89 .",
    "consider the two stochastic differential equations of the form ( [ generalsystemcontrol ] ) but driven by the two different controls defined in the statement of the theorem @xmath254 then , since both processes share a common initial point , it is straightforward to show that the two euler - maruyama time - discretisations of both processes are identical .",
    "that is , by induction on @xmath255 we have @xmath256 where @xmath257 and @xmath258 .",
    "there is a known result @xcite which states that @xmath181-th moment exponential stability of a stochastic differential equation implies @xmath181-th moment exponential stability of its euler - maruyama simulation and vice - versa ( if the time - step @xmath240 is sufficiently small ) .",
    "thus , with minor modifications to the main result of @xcite it follows that if ( [ originalcontrol ] ) holds , then for a sufficiently small step size @xmath259 , the euler - maruyama approximation @xmath260 of @xmath236 satisfies @xmath261 for some @xmath262 .",
    "the same holds for @xmath263 as this discrete - time process is identical to @xmath260 .",
    "again , with slight modification to the results in @xcite it follows that if @xmath259 is small enough then @xmath264 for some positive constants @xmath265 .",
    "this completes the proof .",
    "a straightforward consequence of proposition [ sampledcontrolprop ] is that the convergence results given thus far concerning the various controller approximation errors will continue to hold even if the control is computed only at discrete - time instants and held constant in the interval between such instants ( provided that the time elapsed between each updates is small ) .",
    "the next result brings everything together .",
    "[ sampledcontrolcorollary ] suppose the assumptions of either theorem [ deterministicrobustnesstheorem ] , theorem [ probabilisticrobustnesstheorem ] or corollary [ mixederror ] hold .",
    "suppose also that @xmath112 is an approximately optimal control law satisfying the requirements of the respective result ; e.g. @xmath266 in theorem [ deterministicrobustnesstheorem ] etc .",
    "fix @xmath75 , we know that there exists a constant @xmath267 , satisfying the statement of the respective result , such that @xmath268 now suppose that @xmath88 is computed at discrete times @xmath269 with @xmath242 , @xmath243 , @xmath244 , @xmath245 , @xmath246 and held constant on the interval @xmath248 as described in proposition [ sampledcontrolprop ] . then there exists a constant step size @xmath250 and constants @xmath251 such that @xmath270 for all @xmath253 .",
    "in this section we outline an approximation method to compute the optimal nonlinear stochastic rhc .",
    "this method relies on simulating a stochastic process that is related to the original controlled system but that is independent of the control signal .",
    "the approximation method outlined in this section was first considered by kappen @xcite for finite - horizon optimal control and then subsequently studied , applied , and generalised in , e.g. , @xcite .",
    "recall that we are considering the nonlinear controlled process @xmath183 defined by @xmath271 with the existing modelling hypotheses holding . here ,",
    "@xmath191 and @xmath64 ( which may be non - square ) are assumed ( with no real loss of generality ) to have full rank .",
    "note , @xmath191 full rank implies the existence and uniqueness of a left - inverse , i.e. a function @xmath272 such that @xmath273 .",
    "associate with ( [ montecarlosystemcontrol ] ) the following receding cost functional @xmath274 \\nonumber\\ ] ] at any time @xmath50 with @xmath36 $ ] and where the cost on the control input is now quadratic and @xmath275 is a constant positive definite matrix .",
    "we define the value - to - go functional as @xmath31}}~w(t , s , x , u ) ~=\\inf_{u_{r}\\in{\\mathcal{u}}_{[t+s , t+t ] } } { \\mathbb{e}}\\left[\\phi(x^{t+s , x , u}_{t+t } ) + \\int_{t+s}^{t+t } \\tfrac{1}{2}u_r^\\top{r}u_r + \\ell(x^{t+s , x , u}_{r})dr\\right ] \\label{montecarlovalue}\\ ] ] where @xmath276}$ ] is the set of admissible controls in the interval @xmath277 $ ] .",
    "the hjb equation associated with the value functional ( [ montecarlovalue ] ) is @xmath278^\\top \\partial_x v(s , x ) + \\tfrac{1}{2}{\\mbox{tr}}\\left[g(x)g(x)^\\top\\partial_{xx}v(s , x)\\right]\\right ] \\nonumber\\ ] ] with a terminal boundary @xmath55 .",
    "the optimal control on the interval defined by @xmath279 $ ] is just @xmath280 for all @xmath128 . in ( one - step ) rhc we are only interested in the solution @xmath39 at @xmath57 .",
    "we have @xmath281 substituting the optimal control back into the hjb equation gives @xmath282\\nonumber\\ ] ] which is a nonlinear partial differential equation .",
    "however , we note the following log - transform of @xmath39 @xmath283\\ ] ] for all @xmath284 , @xmath36 $ ] and for some finite @xmath285 .",
    "this transform arises in a number of stochastic control scenarios @xcite .",
    "we often write @xmath286 in place of @xmath287 .",
    "we note the following required assumption .",
    "[ assump4 ] we assume that there exists @xmath288 such that @xmath289 .    this assumption is standard in the path integral formulation of optimal control @xcite , but it also appears more generally in the stochastic optimal control literature @xcite .",
    "this assumption allows us @xcite to write @xmath290\\nonumber\\ ] ] which is a linear partial differential equation on @xmath291 $ ] with terminal condition @xmath292 $ ] .",
    "it now follows by the feynman - kac formula that the solution to the above pde at @xmath293 is given by @xmath294\\ ] ] where now @xmath295\\times\\omega\\to{\\mathbb{r}^{n}}$ ] is a nonlinear ( uncontrolled ) process satisfying @xmath296 with initial condition @xmath297 .",
    "note that @xmath298 now , given the solution for @xmath286 derived via the feynman - kac formula , it is informally straightforward to devise a monte carlo approximation for the control ; e.g. one can first simulate sample paths of ( [ montecarlosystemuncontrolled ] ) , then form a monte carlo approximation of the integral for @xmath286 , and approximate the spatial derivative of @xmath286 via differencing .",
    "going forward we explore a more formal monte carlo approximation circumventing the need for crude numerical ( spatial ) differentiation .",
    "firstly , we need the following result .",
    "[ optimalcontrolmontecarlo ] suppose assumptions [ assump1 ] and [ assump4 ] , and the modelling hypotheses hold .",
    "then @xmath299}{{\\mathbb{e}}\\left[e^{-\\frac{1}{\\lambda}\\left(\\phi(z^{t , x}_{t+t } ) + \\int_{t}^{t+t } \\ell ( z^{t , x}_s)ds \\right)}\\right]}\\ ] ] where the expectations are integrals over paths defined by the sde ( [ montecarlosystemuncontrolled ] ) with initial condition @xmath300 .",
    "this result appears in @xcite with @xmath301 and it is straightforward to generalise .",
    "the controller form in proposition [ optimalcontrolmontecarlo ] ( and variations of such ) is often referred to as the path integral formulation of optimal control @xcite . at this stage , it may appear as though the reformulated optimal controller has been significantly complicated . however , the optimal control as given in proposition [ optimalcontrolmontecarlo ] is well suited to monte carlo approximation .    the monte carlo approach to rhc is given by algorithm [ algorithm1 ] .",
    "note also that we consider two time - discretizations defined by @xmath302 and @xmath303 respectively .",
    "the first , @xmath304 , captures the sample and hold application in which the control is computed at discrete - time steps and held constant over those intervals ; i.e. we approximate the optimal control @xmath215 by @xmath305 over @xmath306 .",
    "we denote by @xmath87 trajectories of ( [ montecarlosystemcontrol ] ) with @xmath89 driven by @xmath307 .",
    "the second time - discretization , @xmath308 , is found solely within algorithm [ algorithm1 ] and defines the time - step employed during the numerical simulation of ( [ montecarlosystemuncontrolled ] ) used to actually compute @xmath309 at each @xmath269 .    given at time t=0 : : :    1 .",
    "model hypotheses : @xmath310 , @xmath311 ,    @xmath312 , @xmath313 ,    @xmath314 , @xmath315 , @xmath316 , and    @xmath317 .    2 .",
    "initial starting point : @xmath318 .",
    "discretization of time @xmath241 via    @xmath242 , @xmath319 ,    @xmath320 , @xmath245 ,    @xmath321 .",
    "4 .   discretization of the interval @xmath291 $ ] with step - size    @xmath308 such that    @xmath322 .    5 .",
    "parameter approximating the limit @xmath323 such that    @xmath324 .",
    "available at time @xmath269 : :    1 .",
    "current state : @xmath325 . at time",
    "@xmath269 do : : :    1 .",
    "simulate @xmath326 times the following discrete - time    approximation of ( [ montecarlosystemuncontrolled ] )    @xmath327    over    @xmath328    where    @xmath329 .",
    "simulation can be parallelised .    2 .",
    "let    @xmath330    be the ordered set of sample points along the simulated discretised    trajectory on the @xmath331 simulation run .",
    "3 .   for each sampled trajectory",
    "@xmath332    compute    @xmath333    where @xmath334 are the sample points of    @xmath335 used previously to generate the    trajectory @xmath336 .",
    "4 .   for each sampled trajectory",
    "@xmath332    compute @xmath337    5 .",
    "compute    @xmath338 } \\sum_{i=1}^n \\exp[-\\tfrac{1}{\\gamma }            \\eta(i)]\\,\\frac{\\widehat{w}(i)}{r}\\ ] ] which gives a ( naive )    monte carlo approximation of the optimal control .",
    "let    @xmath305    over @xmath339 .",
    "this algorithm is easily implementable .",
    "the numerical approximation of the stochastic differential equation ( [ montecarlosystemuncontrolled ] ) is known as the euler - maruyama method and is the simplest numerical scheme for approximating stochastic differential equations .",
    "this numerical approximation may be generalised @xcite although care must be taken to ensure that sufficient gains warrant the sharp increase in complexity that accompanies higher - order numerical approximation schemes .",
    "the error in computing the approximate control signal at the discrete time sites is a mix of the error introduced due to the monte carlo sampling ( known as the statistical error ) and the error introduced due to the approximation of the limit and the time - discretisation ( known as the discretisation error ) ; see also @xcite . at those specific discretised time sites we note the following result .",
    "[ centrallimitprop ] suppose assumptions [ assump1 ] and [ assump4 ] and the modelling hypotheses employed to this point hold .",
    "suppose also that the system and value functionals are sufficiently regular .",
    "given @xmath128 , suppose algorithm [ algorithm1 ] is used to compute @xmath340 . then there exists a positive constant @xmath341 , a function @xmath234 satisfying @xmath342 and a matrix @xmath204 such that @xmath343 where convergence is ` in distribution ' with the number , @xmath326 , of monte carlo runs ; see algorithm [ algorithm1 ] . also , @xmath344 .",
    "let @xmath103 denote the optimal control defined by ( [ control formula1 ] ) .",
    "for a fixed @xmath323 approximate the limit defining @xmath345}{{\\mathbb{e}}\\left[e^{-\\frac{1}{\\lambda}\\left(\\phi(z^{t , x}_{t+t } ) + \\int_{t}^{t+t } \\ell ( z^{t , x}_\\tau)d\\tau \\right)}\\right]}\\ ] ] for @xmath346 small enough we have @xmath347 with @xmath348 to be chosen later .",
    "let @xmath349 be the approximation to @xmath350 found purely as a result of the discretized path approximation ( associated with step - size @xmath308 ) .",
    "then , given the convergence results for the euler - maruyama method @xcite , it follows that for @xmath308 small enough , there exists a constant @xmath218 such that @xmath351 for all @xmath323 . using the triangular inequality , @xmath352 choosing @xmath353 yields @xmath344 .",
    "we note that @xmath354 is a monte carlo approximation of @xmath355 .",
    "we denote by @xmath356 a realised sequence of the discretized brownian motion associated with the euler - maruyama discretization of ( [ montecarlosystemuncontrolled ] ) and by @xmath357 the discrete path associated with it .",
    "call @xmath358 the natural measure on the path space @xmath359 . define @xmath360\\ ] ] and consider the path measure @xmath361 obtained by the relation @xmath362 } d\\mathbb{p}\\ ] ] define the function @xmath363 , i.e. the sum of the first @xmath315 brownian increments .",
    "we have that @xmath364\\ ] ]    when simulating paths in algorithm [ algorithm1 ] , we simulate from the measure @xmath365 and use self - normalized importance sampling to compute @xmath366 .",
    "we know @xcite , that self - normalized importance sampling is asymptotically unbiased and moreover a central limit theorem holds if @xmath367\\left(\\frac{d\\mathbb{q}}{d\\widetilde{\\mathbb{q}}}\\right)^2d\\widetilde{\\mathbb{q } } < \\infty\\ ] ] here , we have @xmath367\\left(\\frac{d\\mathbb{q}}{d\\widetilde{\\mathbb{q}}}\\right)^2d\\widetilde{\\mathbb{q } }   = \\frac{1}{{\\mathbb{e}}_\\mathbb{p}[g(w_{0:k})]^2}\\left(\\int ( 1 + f^2)d\\widetilde{\\mathbb{q}}\\right)\\ ] ] moreover @xmath368<\\infty$ ] thanks to the fact that @xmath369 is bounded .",
    "therefore we have @xmath370 where @xmath371 ^ 2d\\widetilde{\\mathbb{q}}$ ] .",
    "convergence is in the sense of distribution with @xmath326 .",
    "now divide by @xmath346 , add and subtract @xmath215 , call @xmath372 and use ( [ weakconvergence ] ) to prove the convergence result .",
    "the asymptotic bias in the preceding error result can be reduced by decreasing @xmath308 or via a reduction in the horizon length @xmath316 .",
    "the variance can be reduced by increasing @xmath326 or through some variation of naive sampling such as improved importance sampling or additionally via particle methods and resampling schemes @xcite etc .",
    "the role of the parameter @xmath346 with respect to the variance and the bias in the error approximation can be important ; see @xcite for a first study of this issue .",
    "note also that @xmath373}\\ ] ] and therefore the variance is intimately connected to @xmath374 $ ] , i.e. the interplay between the cost and dynamics of the uncontrolled sde .",
    "such performance questions may be explored in future work ; see also @xcite .",
    "going forward with the analysis we use the following assumption .",
    "[ normaldistribution ] suppose that , for @xmath326 big enough , @xmath375 and @xmath204 is bounded .",
    "this assumption is just an invocation of the central limit type of result in proposition [ centrallimitprop ] ( which states that with @xmath326 increasing , the distribution of the random part of the control approximation can be assumed gaussian ) .",
    "regardless of the distribution , it is true that the variance of the error decreases proportionally with increasing @xmath326 ( at the rate @xmath376 ) and that the bias decreases continuously with @xmath308 . in practice , with @xmath326 large enough ,",
    "any error in applying this assumption is small and can be quantified via bounds of the berry - esseen type @xcite . ] .",
    "we can now state the main stability result of this section .",
    "suppose assumptions [ assump1 ] , [ assump2 ] , [ derivatives ] , [ derivatives2 ] , [ assump4 ] , [ normaldistribution ] and the modelling hypotheses outlined to this point hold .",
    "define @xmath101 and @xmath102 .",
    "given @xmath128 , suppose algorithm [ algorithm1 ] is used to compute @xmath340 . with @xmath377 small enough and @xmath326 large enough , there exits @xmath378 and a pair of positive constants @xmath251 such that @xmath379 and @xmath380 ( where @xmath202 is the rate of convergence of the optimal control ; see theorem [ deterministicrobustnesstheorem ] ) .",
    "since the error @xmath381 is of the mixed type , we call on corollary [ mixederror ] . from proposition [ centrallimitprop ] it follows that there exists @xmath308 small enough so that the deterministic part of the controller approximation error is small .",
    "similarly , from proposition [ centrallimitprop ] it follows that there exists @xmath326 large enough so that the variance @xmath204 is small",
    ". assumption [ normaldistribution ] imposes normality on the error distribution .",
    "corollary [ mixederror ] applies immediately .",
    "picking @xmath304 small enough to invoke corollary [ sampledcontrolcorollary ] completes the proof .",
    "it is practically feasible that such parameters , @xmath326 ( or @xmath308 ) , could be made large ( small ) enough to ensure the variance ( bias ) in the approximation error is viable ( and this is seen in practice where algorithm [ algorithm1 ] has been readily applied ) .",
    "however , the strong proof of the preceding theorem relies on the ( approximating ) assumption that @xmath382 is gaussian . the error in this assumption , i.e. between the actual distribution and a gaussian , decreases with increasing @xmath326 , and",
    "can be quantified via berry - esseen type bounds @xcite . in any case , the preceding theorem is rigorous under this assumption and , in practice , it provides justification for the stabilisation properties ( seen in applications ) of algorithm [ algorithm1 ] for large enough @xmath326 .",
    "a stronger result with finite @xmath326 would be difficult to obtain given that stochastic differential equations driven by arbitrary random processes ( non - brownian ) are well beyond the scope of this work .",
    "in this work we explored the asymptotic stability of nonlinear stochastic rhc when the optimal controller is computed only approximately .",
    "we considered a number of general classes of controller approximation error including deterministic and probabilistic errors and even controller sample and hold errors .",
    "we also overviewed an approximation method for computing the optimal rhc for nonlinear stochastic continuous - time systems .",
    "this method is based on monte carlo integration approximation and originates in the work of kappen @xcite .",
    "while we study the stability of various rhc approximations , we did not consider any measure of performance .",
    "for example , it would be of interest to analyze ( path - wise ) the running cost error that arises due to the approximation of the optimal controller .",
    "inverse optimality and optimality gaps as studied in @xcite would also be of interest here .",
    "the incorporation of state constraints in rhc is common @xcite .",
    "we note that it may be natural in some cases to incorporate state constraints in the monte carlo based approximation algorithm detailed herein .",
    "for example , state constraints may be enforced by simply restricting the evolution of the sampled trajectories ( e.g. via dictating that certain regions of the state space hold zero probability ) .",
    "efficient sampling and monte carlo simulation @xcite that reduces the variance and thus the error in the monte carlo based controller approximation is of interest .",
    "other computational aspects of this approximation are of interest , particularly as they apply to high - dimensional implementation .    finally , we mention that extensions which account for partial - information feedback may be important , particularly in the stochastic framework where true state feedback is overly restrictive . in this",
    "setting , the coupling of stochastic rhc , and particularly the monte carlo approximation algorithm , with sequential monte carlo estimation / filtering ( e.g. particle filtering @xcite ) would be a natural topic for further study .",
    "we start with the lower bound . recall that @xmath383 $ ] where we use the shorthand @xmath384 for the solution of the system ( [ generalsystemcontrol ] ) driven by the optimal control with initial condition @xmath14",
    "we have @xmath385 ~{\\geqslant}~ c_2 { \\mathbb{e}}|x_t|^p ~{\\geqslant}~ c_2| { \\mathbb{e}}[x_t]|^p\\ ] ] using the modelling hypotheses first and jensen s inequality second .",
    "moreover , we have @xmath386 & { \\geqslant } & c_2 { \\mathbb{e}}\\left[\\int_0^t ( |x_s|^p + |u^*_s|^p)ds \\right ] \\nonumber \\\\      & { \\geqslant } & c_2 2^{1-p } { \\mathbb{e}}\\left[\\int_0^t ( |x_s| + |u^*_s|)^pds \\right ] \\nonumber \\\\      & { \\geqslant } & \\frac{c_2 2^{1-p } } { c_1 } { \\mathbb{e}}\\left[\\int_0^t |f(x_s , u^*_s)|^pds\\right ] ~=~ \\frac { c_2 2^{1-p}}{t^p c_1 } { \\mathbb{e}}\\left [ \\int_0^t |tf(x_s , u^*_s)|^pds \\right ] \\nonumber\\end{aligned}\\ ] ] where we have used the modelling hypotheses on @xmath100 , together with the fact that @xmath387 .",
    "now it follows that @xmath388 & { \\geqslant } & \\frac { c_2 2^{1-p } } { t^{p-1}c_1 } { \\mathbb{e}}\\left[\\big|\\int_0^t f(x_x , u^*_s)ds\\big |^p \\right ] \\nonumber \\\\      & { \\geqslant } & \\frac { c_2 2^{1-p } } { t^{p-1}c_1}\\big| { \\mathbb{e}}\\left[\\int_0^t f(x_x , u^*_s)ds\\right]\\big|^p \\nonumber\\\\      & = & \\frac { c_2 2^{1-p } } { t^{p-1}c_1 }",
    "\\big| { \\mathbb{e}}[x_t - x]\\big|^p ~=~ \\frac { c_2 2^{1-p } } { t^{p-1}c_1 } \\big| x-{\\mathbb{e}}[x_t]\\big|^p \\nonumber\\end{aligned}\\ ] ] where we used jensen s inequality twice .",
    "putting together the bounds on @xmath389 $ ] and @xmath390 $ ] gives @xmath391|^p + \\frac { c_2 2^{1-p } } { t^{p-1}c_1 } | x-{\\mathbb{e}}[x_t]|^p \\nonumber \\\\      & { \\geqslant } & c \\big ( |{\\mathbb{e}}[x_t]|+|x-{\\mathbb{e}}[x_t]| \\big)^p \\nonumber \\\\      & { \\geqslant } & c \\big ( |{\\mathbb{e}}[x_t]+x-{\\mathbb{e}}[x_t]| \\big)^p   ~=~ c|x|^p \\nonumber\\end{aligned}\\ ] ] for some constant @xmath99 , where we used the fact the all norms are equivalent on a finite dimensional vector space followed by the triangle inequality .",
    "this completes the proof for the lower bound .",
    "we now turn to the upper bound and recall that , given an arbitrary admissible control law , the cost functional @xmath392 associated with ( [ generalsystemcontrol ] ) is @xmath393\\ ] ] we immediately have @xmath394}}~w(0 , x , u ) { \\leqslant}w(0 , x , 0)\\ ] ] where @xmath395 denotes the cost found after applying a constant zero control @xmath396 .",
    "going forward , write @xmath397 for the solution of ( [ generalsystemcontrol ] ) with @xmath398 and a constant zero control @xmath396",
    ". then @xmath399 note that if @xmath400 is not admissible we may substitute some other ( sub - optimal ) constant control signal .",
    "then , for all @xmath28 with @xmath50 , its known @xcite that given the existence of solutions to ( [ generalsystemcontrol ] ) it holds that @xmath401 for some finite @xmath99 .",
    "this , together with the assumptions on the cost , gives @xmath402 \\nonumber\\\\          & { \\leqslant } & { \\mathbb{e}}\\left [ c_3(1+|x_t|^p)\\right ] + { \\mathbb{e}}\\left [ \\int_0^t c_3(1+|x_s|^p + 0)ds\\right ] \\nonumber\\\\          & { \\leqslant } & c_3\\left(1+t + |x|^pe^{ct } + \\int_0^t|x|^pe^{cs}ds\\right ) ~{\\leqslant}~ c_3\\left(1+t + |x|^pe^{ct } + |x|^p\\frac{e^{ct}-1}{c}\\right ) \\nonumber\\end{aligned}\\ ] ] which , after gathering constants , completes the proof concerning the upper - bound ."
  ],
  "abstract_text": [
    "<S> this work considers the stability of nonlinear stochastic receding horizon control when the optimal controller is only computed approximately . </S>",
    "<S> a number of general classes of controller approximation error are analysed including deterministic and probabilistic errors and even controller sample and hold errors . in each case </S>",
    "<S> , it is shown that the controller approximation errors do not accumulate ( even over an infinite time frame ) and the process converges exponentially fast to a small neighbourhood of the origin . </S>",
    "<S> in addition to this analysis , an approximation method for receding horizon optimal control is proposed based on monte carlo simulation . </S>",
    "<S> this method is derived via the feynman - kac formula which gives a stochastic interpretation for the solution of a hamilton - jacobi - bellman equation associated with the true optimal controller . </S>",
    "<S> it is shown , and it is a prime motivation for this study , that this particular controller approximation method practically stabilises the underlying nonlinear process . </S>"
  ]
}