{
  "article_text": [
    "human language and its evolution has recently become an attractive subject within the interdisciplinary scientific community @xcite .",
    "the reason for this interest is a natural consequence of the rapid advances in the understanding and modeling of complex systems@xcite .",
    "statistical physics , and mainly computational statistical physics , has proven to be quite effective in the study of systems of many interacting atoms and in the description of several complex phenomena associated with these interactions , even though the interacting units are no longer atoms or elementary particles but biological species@xcite , human beings @xcite or even financial tools , such as stocks @xcite .",
    "it was also realized that human language , a traditionally qualitative subject of study , fits adequately in the above quantitative framework .",
    "several aspects of language have been studied by different groups .",
    "the main focus is on language learning and its evolution @xcite , on the quantification of language characteristics ( for example , the famous zipf law ) and their explanation from first principles @xcite , and on language competition between two @xcite or more languages @xcite . in several of the above studies , for example @xcite , the authors assume that language is learned by linguistic agents that move on a regular two - dimensional lattice ( a surface ) and interact with each other .",
    "the effect of the surface topology or possible disorder is not taken into account .",
    "it has been , however , recently understood that a lattice topology may in several cases be an inadequate substrate for the description of social interactions . in many cases ,",
    "a better description is achieved if one takes into account that social systems may be represented as graphs ( networks ) , i.e. as collections of nodes ( representing individuals ) which are connected together if the individuals represented by these nodes know each other .",
    "social networks have a structure similar to a scale - free network @xcite , which is a graph whose degree ( the number of edges that emanates from a node ) distribution follows a power law , @xmath0 , and have attracted considerable interest@xcite .",
    "+ during most of human history , words were learned by individuals through discussions with those close to the learner . in the last decades , however , `` modern '' technologies have changed this situation .",
    "we now have mobile phones , e - mail accounts , web cameras and communication with even the most remote acquaintance is not only possible but has become a rather easy task . motivated by this fact , we study language evolution on scale - free network structures .",
    "we use monte carlo simulations and assumptions from evolutionary game theory in order to evaluate the way the network topology affects the vocabulary size of a group of individuals . in this way",
    "we hope to get an insight on how `` modern '' technologies may affect language and its evolution .",
    "monte carlo simulations on regular geometries have shown @xcite that when agents are arranged in a two - dimensional lattice structure , their final vocabulary size is the maximum possible .",
    "scale - free networks , in contrast to regular lattices , are characterized by the existence of nodes with very high degree ( `` hubs '' ) and our results indicate that these hubs have an important impact on the vocabulary size .",
    "network theory has been used in the past to study the structure of language ( @xcite and references therein ) . here",
    ", however , we use it in order to study vocabulary evolution , independently of any linguistic structure .",
    "we build a computational model to study the time evolution of the vocabulary known by species which interact with each other .",
    "the model is in several aspects similar to a previous model used in @xcite for describing language evolution on a square lattice topology . in order to determine the effect of the network topology to the vocabulary learning characteristics , we used scale free networks with @xmath1 nodes and with @xmath2 and @xmath3 , and erds - rnyi networks also consisting of @xmath1 nodes and connectivity probability @xmath4 .",
    "each node is always occupied by one agent .",
    "the language that these agents have consists of 10 words .",
    "thus , each agent possesses a maximum vocabulary of 10 words .",
    "the number of words that a given agent knows at any time is not constant , since there are mechanisms to learn and to forget words , which will be explained in the next paragraphs .",
    "each agent has a number of attributes that characterize its behavior .",
    "the first is the vocabulary @xmath5 which consists of an array of 10 elements .",
    "an element has a value of 1 if the corresponding word is known to the agent or 0 if the word is unknown .",
    "initially , each agent has a vocabulary that consists of 5 words , chosen randomly out of the 10 possible words .",
    "the second is the fitness , @xmath6 , which determines the probability of each agent to reproduce .",
    "the initial fitness has a value of zero , and agents can gain fitness through successful communication .",
    "all agents take part in the following activities : communication , reproduction and mortality .",
    "+ 1 ) _ communication _ : an agent @xmath7 is chosen randomly and given the possibility to communicate with one of its neighbors , @xmath8 . as neighbors we consider the nodes with which the specific node is connected",
    ". this communication confers fitness to both agents ( @xmath7 and @xmath8 ) according to the number of words agent @xmath7 has in common with agent @xmath8 with which it communicates . specifically : + a ) the payoff for the interaction is equal to the number of words @xmath7 and @xmath8 have in common ( e.g. , three common words means a payoff of 3 ) .",
    "this payoff value is added to the fitness of each agent , as a reward for successful communication .",
    "+ b ) learn - forget process : every word in the vocabulary is examined and if agent @xmath7 does not know a word which is known to @xmath8 then there is a probability @xmath9 that @xmath7 will learn it from @xmath8 . if this specific word is learned , then the corresponding vocabulary array element will turn from 0 to 1",
    "however , there is also a probability @xmath10 that @xmath8 will forget this word not known to @xmath7 .",
    "the same rules apply for words which are known to @xmath7 and unknown to @xmath8 .",
    "thus , words that are unknown to the majority of the population have increased probability of being lost from the language . + 2 ) _ reproduction _ : there is a probability @xmath11 that a reproduction event will take place .",
    "the selection of the agent to be reproduced is not random but proportional to the agent s fitness .",
    "this means that agents with large fitness have a higher probability for reproduction .",
    "each agent s probability for reproduction is given by the formula :    @xmath12    where @xmath13 is the fitness of agent @xmath7 and this sum is over all agents .",
    "the fact that we normalize over the total fitness implies that there is information available to all agents about the fitness status of their society . since all the sites ( or nodes ) of our space",
    "are occupied the offspring will have to be born in an already occupied site , replacing the previous inhabitant . in this way",
    "the reproduction and mortality procedures of the model are combined in one action as opposed to the model used in @xcite .",
    "we have two choices for the selection of the site in which the offspring will be born , and live thereafter .",
    "the first is to put it in one of the neighboring sites of the parent , which seems quite rational , for the child to `` live '' near its parents .",
    "the second is to choose a random site and place it there . although both models give qualitatively the same results , there are numerical differences . in the `` local '' model",
    "we observed more fluctuations , while in the `` global '' model these fluctuations were not persistent and soon smoothed out .",
    "for this reason in the current text we will present only the `` global '' model , where the offspring takes a randomly chosen site in the network . the next choice to be made concerns the amount of fitness that the offspring will inherit . for simplicity , we assume that the child inherits the fitness of the parent . thus , the offspring begins its life having the same amount of fitness its parent has , without affecting the parents fitness .",
    "all offspring carry the full vocabulary of the parent .",
    "+ 3 ) after each cycle of communication and reproduction , time is incremented by @xmath14 , where @xmath15 is the total number of agents in the lattice .",
    "thus , one time unit or monte carlo step ( mcs ) statistically represents the time necessary for each agent to execute the communication - reproduction cycle once .",
    "the simulation continues until a predefined total time is reached . for statistical purposes",
    "we average our results over a large number of realizations , typically 1000 , in this work . in most cases",
    "the time evolution of the system is followed up to 100000 mcs , but since the system reaches a state of equilibrium much sooner the data we show here are limited to 20000 mcs . in all simulation results presented in the present manuscript",
    "we have used the values @xmath16 , @xmath17 .",
    "first we studied the behavior of our system when no reproduction takes place . in this case",
    "only the communication process is active and the agents can pass linguistic information to their neighbors .",
    "one expects that after sufficient time this process would stop since the system would reach a steady state where all the agents have acquired exactly the same vocabulary .",
    "we studied scale free networks , with @xmath2 and @xmath3 and random networks with connectivity @xmath4 . both netowrks consisted of @xmath1 nodes ,",
    "the results for the mean number of words known by each agent have shown that there is no real change in the number of words known by the agents .",
    "instead , there is only some very small fluctuation around the number of words that the inhabitants of the system know at the start of the simulation .",
    "this means that there is no tendency for `` knowledge '' to spread around the network .",
    "this can be expected since if there is no reproduction , the knowledge of many words is _ not _ an evolutionary advantage .",
    "moreover , there are no newborn agents who spread around the network , spreading also their vocabulary .",
    "this model is , therefore , quite static , both in its rules and in the results that we get .",
    "this result is similar to the one obtained in @xcite for the case of no reproduction on a lattice and agrees with intuition .      in a previous work @xcite",
    ", it was shown that when identical ( i.e having the same initial fitness ) linguistic agents are allowed to move on a lattice , to learn and forget words as described in the methods section and to reproduce with a probability @xmath19 then the final state of the system is one where all agents have learned all possible words . to be precise , if the agents move on a lattice and initially they know on average 5 words ( i.e if the have 5 digits equal to one in their vocabulary array @xmath5 which has size equal to 10 ) we will end up in a situation where all agents know an average of 10 words .",
    "this is reasonable as language is a fitness generating mechanism and thus , knowing many words is essential for survival .",
    "the `` survival of the fittest '' implies that in order to survive , one has to know everything that is available and this is verified by simulations . on a scale - free network , however , the situation is different .    , known by each agent , vs. time , for scale free networks consisting of @xmath1 nodes , for @xmath20 and random networks consisting of @xmath1 nodes , with connectivity @xmath21 , for @xmath22 .",
    "the results are the averages of 1000 realizations.,width=321,height=8 ]    in figure [ fig1 ] , we plot the mean number of words , @xmath23 , known by each agent as a function of time , for scale free networks consisting of @xmath1 nodes , for @xmath20 and random networks consisting of @xmath1 nodes , with connectivity @xmath4 for @xmath22 .",
    "it is obvious , especially in the case of networks with @xmath24 that the number of words is quite below the maximum vocabulary size .",
    "the reason for this is that in such a network there are several nodes with very high degree ( hubs ) .",
    "a hub has many neighbors and , consequently , it can communicate with many other nodes and drasticly increase its fitness .",
    "this can be easily understood with the example of an `` extreme '' case .",
    "consider a star - like network of say @xmath25 nodes .",
    "there is one central node with degree @xmath26 , i.e. a hub , which is connected to all other nodes .",
    "the remaining 99 nodes have @xmath27 , thus , they are connected to the hub only . in one time step",
    "each node is on average selected once and then it selects randomly one of its neighbors to communicate with . in this extreme case , at the first time step , each node has one chance to communicate , except the hub that has 99 chances because it is the only neighbor that a randomly selected node has .",
    "thus , the hubs are in an advantageous position and gain fitness quickly .",
    "then , they are favored in reproduction and finally their vocabulary dominates the system .",
    "the existence of hubs has as a result that a node can gain fitness not only by knowing many words , but also by knowing just the words that are known to the hubs .",
    "there is , thus , a new fitness generating mechanism associated with the existence of the hubs .",
    "the effect is more profound for networks with @xmath24 , where there are a lot of large hubs and less evident for higher @xmath28 values where the hubs are fewer .",
    "it is also important that the offspring replaces a randomly chosen node , since thus it favors the spreading of the vocabulary of the fittest nodes , which in this case is the vocabulary of the hubs .",
    "+ the case of the random networks is quite different , since here we observe a significant increase in the number of words the agents know , although they are still lower than those of the square lattice . thus , random networks are between the two cases , showing the effect of scale free networks but in a much lesser extent , a fact we can safely assume is due to the lack of big hubs .",
    "in figure [ fig2 ] we plot the fraction of the nodes that know 8 or more words and 9 or more words , as a function of time .",
    "since now knowledge of more words is an evolutionary advantage we see that this fraction is much larger than in the non - reproduction case we saw in the previous paragraph .",
    "it is , however , lower than the values expected for a lattice topology and we can also observe that low @xmath28 values are associated with lower fractions of agents with `` rich vocabulary '' , in agreement with what we have previously mentioned .",
    "nodes , for @xmath20 and random networks consisting of @xmath1 nodes , with connectivity @xmath4 and @xmath22 .",
    "the results are the averages of 1000 realizations.,width=321,height=8 ]      we have also simulated language competition between two interacting species on a scale free network using the algorithm described in detail in ref @xcite .",
    "the main difference now is that we have two species speaking two different languages and instead of starting with a random vocabulary knowledge , half of the population knows perfectly one language and the other half knows perfectly a completely different language . in this case",
    "the maximum possible vocabulary size is 20 ( there are two `` languages '' that have 10 words each ) and we assume that the child inherits 80% of the father s fitness @xcite .",
    "it is obvious that inspite of the differences between the two algorithms , the different initial conditions on the word distribution and the difference in the fitness amount passed from one generation to the next , we can still observe that for scale - free networks with @xmath24 the total number of words that are finally known by the nodes is significantly less than for the lattice case .",
    "this is an indication that the role of the hubs is significant for the propagation and learning of new words and that this fact does not strongly depend on the specific details of the models .",
    "nodes with @xmath29 and random networks consisting of @xmath1 nodes with connectivity @xmath4 , @xmath22 and the assumption that the child inherits 80% of the fathers fitness .",
    "the initial concentration is @xmath30 for both a and b species , width=321,height=8 ]",
    "we have studied the evolution of the vocabulary of a group of individuals on a scale - free network .",
    "we have demonstrated that there is an important difference in this case , compared to the case where the individuals are regularly distributed on a lattice or even with the case where they are allowed to perform random walks on a lattice . on a lattice structure ,",
    "the final vocabulary size of the individuals is the maximum possible .",
    "knowing everything is essential in order to increase the probability to `` reproduce '' . on scale - free networks ,",
    "however , the reproduction probability is considerably increased by using the vocabulary of the `` hubs '' .",
    "this result indicates that the existence of the `` hubs '' in a scale - free network is the source of an additional important fitness generating mechanism and may have profound and unexpected impact on the evolutionary dynamics of a system .",
    "we would like to thank dr .",
    "l.k . gallos for fruitful discusions .",
    "this work was partially supported by the hellenic ministry of education , via pythagoras project ."
  ],
  "abstract_text": [
    "<S> we examine the evolution of the vocabulary of a group of individuals ( linguistic agents ) on a scale - free network , using monte carlo simulations and assumptions from evolutionary game theory . </S>",
    "<S> it is known that when the agents are arranged in a two - dimensional lattice structure and interact by diffusion and encounter , then their final vocabulary size is the maximum possible . </S>",
    "<S> knowing all available words is essential in order to increase the probability to `` survive '' by effective reproduction . on scale - free networks </S>",
    "<S> we find a different result . </S>",
    "<S> it is not necessary to learn the entire vocabulary available . </S>",
    "<S> survival chances are increased by using the vocabulary of the `` hubs '' ( nodes with high degree ) . </S>",
    "<S> the existence of the `` hubs '' in a scale - free network is the source of an additional important fitness generating mechanism .    ,    and    language evolution , scale - free networks , monte carlo simulations </S>"
  ]
}