{
  "article_text": [
    "one of the central themes in computational geometry is the design of efficient range searching algorithms .",
    "typically , in such a problem one is given an input set @xmath0 of @xmath1 points in @xmath14 dimensions , and the goal is to preprocess @xmath0 into a data structure , so that for any query _ range _ of some type ( say , a halfspace @xmath15 ) , one can efficiently count , report , or test for emptiness the set @xmath16 . a significant component of most of these algorithms involves space decomposition techniques , which partition the input set into subsets with some useful structure . apart from range searching ,",
    "partitions are also used in constructions of spanning trees with small crossing number , approximations , @xmath17-nets , and in several other computational geometry problems .    in a typical approach ( see , e.g. , @xcite ) , given a point set @xmath0 in @xmath2 , one partitions @xmath0 into subsets of approximately equal sizes , so that each of them is contained within some region of constant description complexity ( e.g. , simplices ) .",
    "we remark that the subsets are pairwise disjoint , while the containing regions might have nonempty intersections .",
    "we seek partitions with _",
    "small crossing number _ , meaning that the maximum number of enclosing regions crossed by the boundary of a range ( typically , a hyperplane ) is small .    in this paper",
    ", we consider a variant of the partition paradigm , referred to as a partition of a _ shallow point set _ , which is applied to a set @xmath0 of _ shallow _ points in @xmath2 , where a point @xmath3 is @xmath4-shallow if there exists a hyperplane @xmath18 that contains at most @xmath4 points of @xmath0 , including @xmath5 , on one of its sides .",
    "we will construct a partition whose crossing number , namely , the maximum number of its simplices that can be crossed by a hyperplane , depends , in addition to @xmath1 , also on the shallowness of @xmath0 , i.e. , on the maximum shallowness @xmath4 of its points .",
    "as is typical in computational geometry , we consider the dimension @xmath14 as a fixed ( small ) constant , thus factors depending only on @xmath14 will be regarded as constants .",
    "[ [ cuttings . ] ] cuttings .",
    "+ + + + + + + + +    one of the major ingredients of our partitioning technique is _ cuttings _ of arrangements of hyperplanes .",
    "a cutting is a collection of ( possibly unbounded ) @xmath14-dimensional closed cells with constant description complexity ( e.g. , simplices ) with pairwise disjoint interiors , which cover the entire @xmath2 ( or some specified portion thereof ) .",
    "let @xmath15 be a collection of @xmath1 hyperplanes in @xmath2 and let @xmath19 be a cutting of the arrangement @xmath20 . for each simplex @xmath21 ,",
    "let @xmath22 denote the collection of hyperplanes intersecting the interior of @xmath23 .",
    "the cutting @xmath19 is called a @xmath24-_cutting _ for @xmath15 if @xmath25 for every simplex @xmath21",
    ".    it will sometimes be convenient to work with weighted collections of hyperplanes , where such a collection is a pair ( @xmath26 ) , where @xmath15 is a collection of hyperplanes , and @xmath27 is a weight function on @xmath15 .",
    "for each @xmath28 , we write @xmath29 for @xmath30 .",
    "the notions introduced for unweighted collections of hyperplanes can usually be generalized for weighted collections in an obvious way .",
    "for example , a cutting @xmath19 is a @xmath24-cutting for ( @xmath26 ) if for every simplex @xmath21 , the collection @xmath22 has total weight at most @xmath31 .",
    "[ [ partitions - related - work . ] ] partitions : related work .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    our study extends to higher dimensions the planar construction of a partition of a set of shallow points , recently developed by har - peled and sharir @xcite .",
    "this technique partitions @xmath0 into @xmath32 subsets , each containing @xmath33 points and enclosed in a ( possible unbounded ) triangle , so that the triangles are pairwise disjoint , and the crossing number of this partition ( by any line ) is only @xmath34 .",
    "har - peled and sharir also constructed a set @xmath0 of @xmath1 @xmath4-shallow points in @xmath35 ( in fact , @xmath0 is a set in convex position , so all its points are @xmath36-shallow ) , so that the ( maximum ) crossing number of any partition of @xmath0 into subsets of size @xmath37 is @xmath38 .",
    "see below for a further discussion of this phenomenon , which was the starting point and the motivation for the study presented in this paper .",
    "we next review the more standard partitioning techniques of matouek @xcite .",
    "there @xmath0 is a set of @xmath1 points in @xmath2 , @xmath39 , which do not have to be shallow .",
    "again , we partition @xmath0 into @xmath6 pairwise disjoint subsets , each having between @xmath4 and @xmath40 points ( here @xmath41 is an arbitrary parameter ) , enclosed by some simplex , where these simplices might have a nonempty intersection . constructs simplices with pairwise disjoint simplices . ]",
    "the partition , referred to as a _ simplicial partition _ , has the property , that any hyperplane @xmath18 crosses at most @xmath42 simplices .",
    "let @xmath0 , @xmath1 and @xmath4 be as above .",
    "matouek @xcite has also developed a variant of the partitioning scheme described above , yielding a partition of @xmath6 subsets of size between @xmath4 and @xmath40 , such that any @xmath4-_shallow _ hyperplane @xmath18 ( that is , a hyperplane which contains at most @xmath4 points of @xmath0 on one side ) crosses at most @xmath43 simplices of the partition .",
    "( in contrast , the construction in @xcite , and the one presented in this paper , deal with sets whose points are shallow , but we seek a small crossing number with respect to every hyperplane . )    [ [ applications - related - work . ] ] applications : related work .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + +    let us now review some applications based on the various kinds of partitions mentioned above .    [",
    "[ halfspace - range - searching . ] ] halfspace range searching .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + +    matouek @xcite uses the standard partition recursively to construct an efficient _ partition tree _ ,",
    "whose root stores the entire input set @xmath0 and a simplicial partition thereof .",
    "each node @xmath44 of the tree stores a subset @xmath45 of @xmath0 , and a simplicial partition of @xmath45 , and each subset of the partition corresponds to a distinct child of @xmath44 .",
    "overall , the resulting partition tree has linear size , can be constructed in @xmath46 deterministic time , such that , given a query halfspace @xmath47 , one can count the number of points in @xmath48 in @xmath49 time .    in a variant of this approach ,",
    "matouek @xcite exploits the partition machinery with respect to shallow hyperplanes to efficiently solve the halfspace range reporting ( or emptiness ) problem .",
    "more specifically , one can construct a data structure of size @xmath12 , in @xmath46 time , such that , given a query halfspace @xmath47 , one can report the points in @xmath50 in @xmath51 time , where @xmath52 .",
    "another useful application of partitions of sets of shallow points , as described above , is the construction of spanning trees with small _ relative _ crossing number .",
    "we recall the standard result , due to chazelle and welzl @xcite ( see also @xcite ) , on the existence of spanning trees with small crossing number .",
    "that is , given a set @xmath0 of @xmath1 points in @xmath2 , there exists a straight - edge spanning tree @xmath53 on @xmath0 , such any hyperplane crosses at most @xmath54 edges of @xmath53 .",
    "har - peled and sharir have refined this construction in the plane , to obtain a spanning tree @xmath53 that has the following property .",
    "define the _ weight _ @xmath55 of a line @xmath56 to be the smaller of the two numbers of points of @xmath0 on each side of @xmath56 .",
    "then @xmath56 crosses only @xmath57 edges of @xmath53 ; see @xcite for more details . in this paper , we follow the same machinery to extend the above construction to higher dimensions .",
    "[ [ relative - peps - approximations . ] ] relative @xmath58-approximations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the existence of a spanning tree with small relative crossing number , for a point set @xmath0 in the plane , as just reviewed , facilitates the construction of _ relative @xmath58-approximations _ for @xmath0 , with respect to halfplane ranges , whose size is smaller than the one guaranteed by the general theory of li et al .",
    "@xcite ( see @xcite ) . for given @xmath59 , a relative @xmath58-approximation for @xmath0 is a subset @xmath60 with the property that , for each halfspace @xmath47 , @xmath61 provided that @xmath62 .",
    "given such a spanning tree , we convert it into a spanning path with the same asymptotic crossing number , and generate a matching out of this path by selecting every other edge along it , and apply a `` halving technique '' on the resulting matching , in which one point of each pair of the matching is drawn independently at random , thus getting rid of half of the points . by the standard theory of discrepancy ( see @xcite ) , the small crossing number of the matching implies a correspondingly low discrepancy of the halving .",
    "we repeat this halving procedure until the combined discrepancy first exceeds a given prescribed parameter , and then return the remaining points as the desired approximation .",
    "har - peled and sharir @xcite apply this construction to a planar point set @xmath0 , and obtain a relative @xmath58-approximation for @xmath0 , of size @xmath63 for most values of @xmath17 and @xmath5 , this is better than the general bound @xmath64 given in @xcite .",
    "see section [ subsection_approximations ] below for more details . in this paper",
    ", we extend this construction to higher dimensions , using the extension of spanning trees with small relative crossing number to higher dimensions , as mentioned above .",
    "[ [ our - results . ] ] our results .",
    "+ + + + + + + + + + + +    we introduce a new variant of the partitioning machinery , based on the general approach that was introduced in @xcite and @xcite , and obtain a partition of a set @xmath0 of @xmath1 @xmath4-shallow points in @xmath2 into @xmath6 subsets , each of size between @xmath4 and @xmath40 , so that each subset is contained within a @xmath14-dimensional simplex and so that the crossing number of the partition ( the maximum number of simplices crossed by a hyperplane ) is at most @xmath7 for @xmath65 and @xmath66 for @xmath67 , where @xmath68 is the near - constant inverse ackermann function .",
    "note that the size of the sets in the partition is roughly the same as the shallowness parameter @xmath4 , and that the exponent in the bound on the crossing number is smaller than the one provided for the general setup in @xcite .",
    "we use this partition , as in @xcite , to construct a spanning tree with small relative , output - sensitive , crossing number . specifically , any hyperplane @xmath18 of weight @xmath69 ( the number of input points on its  lighter \" side ) crosses at most @xmath70 edges of the resulting spanning tree for @xmath65 , and @xmath71 edges for @xmath67 .",
    "we then extend the planar construction of relative @xmath58-approximations for points and halfplanes introduced in @xcite to higher dimensions .",
    "we again follow a similar machinery as the one in @xcite , based on the classical halving technique , to convert a spanning tree with small relative crossing number to a relative @xmath58-approximation .",
    "the properties of the relative @xmath58-approximation and the exact result are detailed in section [ subsection_approximations ] below .",
    "another application of the shallow - points partition is an exact output - sensitive range counting algorithm for point sets and halfspace ranges in @xmath2 .",
    "we combine the range reporting algorithm of matouek @xcite with our shallow - points partition and the standard simplex range counting algorithm of matouek @xcite , to obtain an improved , output - sensitive range counting algorithm , whose running time is @xmath72 , for @xmath65 , where @xmath4 is the output size .",
    "this is an improvement over the previous bound @xmath73 of @xcite when @xmath74 ( although when @xmath4 is very small , the range reporting of @xcite will be faster ) .",
    "see section [ subsection_range_countning ] for a more precise statement of this result .",
    "( one weak aspect of our structure is that , for @xmath75 we do not know how to construct it in near - linear time .",
    "the current bound on the preprocessing cost is roughly @xmath76 for some exponent @xmath77 that depends on @xmath14 and satisfies @xmath78 .",
    "see theorem [ thm_range_counting ] for the precise statement . )",
    "we recall the result of li et al .",
    "@xcite , and two useful extensions of @xmath17-approximations and @xmath17-nets derived from it , which we will exploit later in this paper .",
    "let @xmath79 be a _ range space _",
    ", where @xmath80 is a set of @xmath1 objects and @xmath81 is a collection of subsets of @xmath80 , called _",
    "ranges_. the _ measure _ of a range @xmath82 in @xmath80 is the quantity @xmath83 assume that @xmath79 has _ finite vc - dimension _",
    "@xmath84 , which is a constant independent of @xmath1 ; see @xcite for more details .",
    "let @xmath85 be two given parameters .",
    "consider the distance function @xmath86 a subset @xmath87 is called a _",
    "@xmath88-sample _ for @xmath79 , if for each @xmath82 we have @xmath89    [ thm_nu_alpha_sample ] @xmath90_li et al .",
    "_ * @xcite*@xmath91 a random sample of @xmath80 of size @xmath92 is a @xmath93-sample for @xmath79 with probability at least @xmath94 , with an appropriate choice of an absolute constant of proportionality .",
    "har - peled and sharir @xcite show that , by appropriately choosing @xmath95 and @xmath96 , various standard constructs , such as @xmath17-nets and @xmath17-approximations , are special cases of @xmath93-samples ; thus bounds on the sample sizes that guarantee that the sample will be one of these constructs with high probability are immediately obtained from theorem [ thm_nu_alpha_sample ] .",
    "two other , less standard special cases of @xmath93-samples are relative @xmath58-approximations @xcite and _ shallow @xmath17-nets _",
    "@xcite ; we review them next .",
    "[ [ relative - peps - approximations.-1 ] ] relative @xmath58-approximations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    [ definition_peps ] @xmath90_relative @xmath58-approximation_@xmath91 .",
    "let @xmath79 be a range space of finite vc - dimension @xmath84 . for given parameters @xmath59 ,",
    "a subset @xmath87 is a _ relative @xmath58-approximation _ for @xmath79 if , for each @xmath82 , we have    [ cols= \" < , < \" , ]     the following result shows that a relative @xmath58-approximation is a special case of a @xmath93-sample .",
    "[ thm_relative_peps ] @xmath90_har - peled and sharir _ * @xcite*@xmath91 a random sample @xmath97 of @xmath98 elements of @xmath80 , for an appropriate absolute constant @xmath99 , is a relative @xmath58-approximation for @xmath79 with probability at least @xmath94 .",
    "[ [ shallow - eps - nets . ] ] shallow @xmath17-nets .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    let @xmath79 be a range space of finite vc - dimension @xmath84 , and let @xmath100 be a given parameter .",
    "a subset @xmath87 is a _",
    "shallow @xmath17-net _ if it satisfies the following two properties , for some constant @xmath101 that depends on @xmath84 .",
    "( ) = 2em    for each @xmath82 and for any parameter @xmath102 , if @xmath103 then @xmath104 .    for each @xmath82 and for any parameter @xmath102 , if @xmath105 then @xmath106",
    ".    note the difference between shallow and standard @xmath17-nets : property ( i ) ( with @xmath107 ) implies that a shallow @xmath17-net is also a standard @xmath17-net ( possibly with a re - calibration of @xmath17 ) . property ( ii )",
    "has no parallel in the case of standard @xmath17-nets  there is no guarantee how a standard @xmath17-net interacts with small ranges .",
    "[ epsshallow ] @xmath90_sharir and shaul _ * @xcite*@xmath91 a random sample @xmath97 of @xmath108 elements of @xmath80 , for an appropriate absolute constant @xmath109 , is a shallow @xmath17-net with probability at least @xmath94 .    [",
    "[ a - brief - overview - of - the - analysis . ] ] a brief overview of the analysis .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the paper is structured as follows . in section [ section_sampling ]",
    "we derive a technical result that shows that , informally , a random sample @xmath110 of @xmath6 points from a @xmath4-shallow @xmath1-point set in @xmath2 has , with some constant positive probability , the property that at least some fixed fraction of its points are vertices of its convex hull .",
    "( curiously , this fraction can not exceed @xmath111 in the worst case . )",
    "we plug this result into the analysis in section [ section_cutting_lemma ] , which presents a construction of a @xmath24-cutting of the zone of the boundary of a convex set in an arrangement of hyperplanes in @xmath2 .",
    "this construction is an easy adaption of standard constructions of cuttings , but seems not to have been presented so far in the literature .",
    "armed with this construct , we present in section [ section_partition ] the main technical contribution of the paper , which is a construction of a simplicial partition of a set of shallow points in @xmath2 that has a small crossing number ( with respect to any hyperplane ) .",
    "the construction is not general , in the sense that the size of the subsets in the partition has to be equal to ( or proportional to ) the shallowness parameter @xmath4 .",
    "still , this provides the key tool for the applications in section [ section_applications ] , which , as mentioned above , are @xmath112 a construction of a spanning tree with small relative crossing number , @xmath113 a construction of relative @xmath58-approximations for halfspace ranges in @xmath2 , whose size ( in many cases ) is smaller than the halfspace general bound in @xcite , and @xmath114 an output - sensitive halfspace range searching data structure .",
    "[ [ section ] ]    let @xmath0 be a set of @xmath1 points in @xmath2 , for @xmath39 , so that all its points are @xmath4__-shallow _ _ , for some fixed parameter @xmath115 .",
    "let @xmath110 be a random sample of @xmath0 where each point of @xmath0 is chosen in @xmath110 independently with probability @xmath116 .",
    "let @xmath117 be the set of @xmath36-shallow points of @xmath110 ( with respect to @xmath110 ) , i.e. , @xmath118 is the set of vertices of the convex hull @xmath119 .",
    "let us assume from now on that @xmath120 , unless explicitly noted otherwise .",
    "in what follows , we assume that @xmath0 is in general position .",
    "in particular , no @xmath121 points of @xmath0 lie in a common hyperplane , and no @xmath14 lie in a common vertical hyperplane ( i.e. , parallel to the @xmath122-axis ) .",
    "consequently , considering the dual set of hyperplanes @xmath123 ( using the duality that preserves the above / below relationship ; see , e.g. , @xcite ) , we get that @xmath15 is in general position too , which means that every @xmath14 hyperplanes of @xmath15 intersect in a single point , and no @xmath121 have a common point .    the following proposition , although its proof is technical and somewhat involved , asserts a fairly intuitive property of @xmath4-shallow sets . that is , if we take a random sample of about @xmath124 points of such a set , at least some fixed fraction of the points of the sample are vertices of its convex hull . as a partial explanation of why the proof is complicated , we observe , after the proof , that the fraction of convex hull vertices of the sample can not in general be made arbitrarily close to @xmath36 .",
    "[ lemma_prob ] let @xmath0 , @xmath110 , and @xmath118 be as above , and assume that @xmath125 . then , with probability @xmath126 , @xmath127    [ [ section-1 ] ]    before getting into the proof , let us recall chernoff s bound ( see , e.g. , @xcite , appendix a , theorems a.12 and a.13 ) for a binomial random variable @xmath80 with parameters @xmath1 , @xmath5 , which we denote by @xmath128 .",
    "that is , @xmath129 , where @xmath130 are independent random indicator variables , and @xmath131 for each @xmath132 . put @xmath133 = \\mu = np$ ] .",
    "then , for any @xmath134 , we have @xmath135 alternatively ,",
    "we can write it as @xmath136 for any @xmath137 . another variant of chernoff s bound , for large deviations below the mean , is @xmath138 for any @xmath134 . using @xmath139 and @xmath140",
    ", we get the following proposition :    [ prop_sum ] let @xmath141 , and let @xmath142 be a parameter . for @xmath143 , define @xmath144 then @xmath145    * proof .",
    "* we have , for @xmath146 , @xmath147 @xmath148 we note , that for any @xmath143 , @xmath149 .",
    "hence , substituting @xmath150 into the equality above , and using the bound @xmath139 , with @xmath151 and @xmath152 , we get @xmath153 @xmath154 @xmath155 it remains to estimate the second expression .",
    "we note that @xmath156 is monotonically decreasing in @xmath157 for @xmath158 .",
    "hence , using @xmath140 , we obtain , for any @xmath159 , @xmath160 @xmath161 putting @xmath162 , and noting that @xmath159 ( since @xmath163 and @xmath151 ) , we obtain @xmath164 which completes the proof . @xmath165    * proof of proposition @xmath166 . *",
    "we separately bound from below the probabilities that ( i ) @xmath167 , and ( ii ) @xmath168 , in terms of @xmath95 , @xmath96 , @xmath47 , @xmath1 and @xmath4 ; the concrete values of @xmath95 , @xmath96 and @xmath47 , as given in the proposition , will be substituted later . the probability for both conditions to hold",
    "is then estimated using the union bound ( on the complementary events ) .    [ [ i - bounding - from - below - the - probability - that - y - geq - fracalpha - nk . ] ] ( i ) bounding from below the probability that @xmath167 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    put @xmath169 , and let @xmath142 be a parameter . we need to bound from below the value of @xmath94 .    since @xmath170 and @xmath171",
    ", @xmath139 implies that @xmath172 recalling that @xmath118 is the subset of @xmath36-shallow points within @xmath110 , and that all the points in the ground set @xmath0 are @xmath4-shallow , we have , for each point @xmath173 , @xmath174 indeed , as @xmath175 is a @xmath4-shallow point , there exists a hyperplane through @xmath175 which bounds a halfspace @xmath18 containing at most @xmath176 points of @xmath0 , excluding @xmath175 .",
    "the lower bound above is the probability that @xmath175 is chosen in @xmath110 and none of the other points in @xmath18 is chosen .",
    "using linearity of expectation , we thus have    @xmath177    we now proceed to estimate @xmath178 .",
    "note that we can not apply chernoff s bound directly , because the events @xmath179 , for @xmath180 , are not independent .",
    "instead we proceed as follows .",
    "put @xmath181 , and @xmath182 .",
    "we then have ( assuming that @xmath183 , which will hold for specific values that we will later use ) @xmath184 hence , by applying proposition @xmath185 , we have @xmath186 or @xmath187 by choosing ( somewhat arbitrarily ) @xmath188 , @xmath189 , recalling that we have required that @xmath125 , and using chernoff s bound ( [ eq_chernoff1 ] ) to bound @xmath181 , we get that @xmath190 .    [ [ ii - bounding - from - below - the - probability - that - fracnnu - k - leq - z - leq - fracgamma - nk . ] ] ( ii ) bounding from below the probability that @xmath168 .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    since @xmath171 , estimating this probability can be done by a direct application of chernoff s bounds . as in ( [ eq1 ] ) , @xmath191 and by applying ( [ eq_chernoff3 ] ) , we have @xmath192 choosing @xmath193 , @xmath194 , and using the assumption that @xmath125 , we get that @xmath195 from ( i ) and ( ii ) we obtain that @xmath196 as asserted .",
    "@xmath165    [ [ upper - bounds - on - the - probability - of - a - sample - with - many - hull - vertices . ] ] upper bounds on the probability of a sample with many hull vertices .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we can increase the lower bound given in ( [ eq_sample_k ] ) , on the probability @xmath94 of getting a sample with at least @xmath197 hull vertices , by choosing @xmath198 close enough to @xmath36 and @xmath95 close to @xmath199 .",
    "we then have @xmath200 by requiring that @xmath124 is at least some sufficiently large constant ( which depends on the choice of @xmath198 ; we need it to `` neutralize '' the denominator @xmath201 , which tends to @xmath199 as @xmath202 ) , we can make this probability arbitrarily close to @xmath203    the following construction shows that the bound @xmath204 is fairly close to being worst - case tight .",
    "this construction was provided by adam sheffer , and we are grateful to him for this observation .    the construction is depicted in figure [ fig_sample ] .",
    "it consists of a set @xmath205 of @xmath1 points on the unit circle @xmath206 , sufficiently closely clustered together near the top point of @xmath206 , and of @xmath207 sets @xmath9 , @xmath208 , and @xmath209 , so that ( i ) each of these sets consists of points lying on a ray emanating from the center of @xmath206 , outside @xmath206 and sufficiently close to it , ( ii ) each of these sets consists of @xmath4 points , except for @xmath9 which consists of @xmath176 points , and ( iii ) the ray containing @xmath9 points upwards , the rays containing @xmath208 point into the third quadrant , and the rays containing @xmath209 point into the fourth quadrant . here",
    "@xmath101 is an additional parameter that we will fix later .",
    "( the points are not in convex position but a sufficiently small perturbation of them will place them in general position without affecting the analysis . )    altogether , the resulting set @xmath0 has @xmath210 points .",
    "it is easily verified that the points can be arranged in such a way that each of them is @xmath4-shallow . moreover , with an appropriate layout , the convex hull of a sample @xmath110 will have at most @xmath207 vertices if we choose at least one point of @xmath9 , at least one point of @xmath211 , and at least one point of @xmath212 .",
    "the probability of this latter event is @xmath213 assuming that @xmath214 , so that @xmath215 , the probability of getting a sample with @xmath216 hull vertices , with an appropriate constant of proportionality ensuring that this bound is larger than @xmath207 , is @xmath217 which we can make arbitrarily close to @xmath218 by choosing @xmath101 sufficiently large .",
    "this shows that @xmath219 is an upper bound on the probability that we can guarantee for getting a sample with @xmath6 hull vertices from a set of @xmath1 @xmath4-shallow points ( when @xmath1 is sufficiently large ) . as noted above , we can get arbitrarily close to this bound by requiring @xmath220 to be sufficiently small .    [",
    "[ z - is - also - a - relative - approximation - set . ]",
    "] @xmath110 is also a relative approximation set .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    consider next the range space @xmath221 , where @xmath81 is the collection of all simplices in @xmath2 .",
    "as is well known , @xmath221 has finite vc - dimension , which we denote by @xmath84 . as a matter of fact ,",
    "we have @xmath222 ; see , e.g. , [ sa95 ? ? ] .",
    "proposition [ lemma_prob ] establishes a property of a random sample of size roughly @xmath124 from a set of @xmath1 @xmath4-shallow points in @xmath2 . of course",
    ", such a sample is also a @xmath93-sample with high probability , for appropriate choices of @xmath96 and @xmath95 .",
    "the following proposition combines both properties .",
    "* remark : * the standard sampling method , under which theorem [ thm_relative_peps ] was originally proved , is to choose each subset of the prescribed size @xmath223 with equal probability .",
    "however , the theorem also holds if the subset is obtained by choosing each point @xmath224 independently with probability @xmath225 , similar to the way @xmath110 was chosen . in this case",
    "@xmath223 is only the expected size of the sample .",
    "[ prop_peps ] let @xmath0 , @xmath110 , @xmath1 , @xmath4 be as above , and let @xmath99 be the constant in theorem [ thm_relative_peps ] .",
    "then , with probability at least @xmath226 , @xmath110 is a relative @xmath227-approximation for @xmath221 , for @xmath228 , and for @xmath229 .",
    "* as already noted , the sample @xmath110 satisfies @xmath230 , it suffices to show that @xmath231 for the specific values @xmath232 ,",
    "@xmath233 , @xmath226 , and @xmath234 as set above .",
    "indeed , we have @xmath235 @xmath236 as asserted , provided that @xmath237 ( which implies that @xmath238 ) . @xmath165",
    "[ [ section-2 ] ]    let @xmath15 be a collection of @xmath1 hyperplanes in @xmath239 .",
    "we denote the arrangement of @xmath15 by @xmath20 . for a simplex @xmath23 ,",
    "let @xmath22 denote the collection of hyperplanes of @xmath15 that _ cross _ @xmath23 ( i.e. , intersect its interior ) . a @xmath24__-cutting _",
    "_ for @xmath20 is a collection @xmath19 of ( possibly unbounded ) closed @xmath14-dimensional simplices with pairwise disjoint interiors , which cover @xmath2 , such that @xmath25 , for every @xmath21 .",
    "the _ size _ of a @xmath24-cutting is the number of its simplices .",
    "the so - called cutting lemma ( see , e.g. , @xcite ) asserts that for every @xmath15 and @xmath240 there exists a @xmath24-cutting of size @xmath241 for @xmath15 ( which is asymptotically the best possible size ) .    here",
    "we will need a modified version of the cutting lemma , where the cutting is not required to cover the entire @xmath2 , but only the zone in @xmath20 of the boundary @xmath242 of some fixed convex region @xmath206 , where the zone of @xmath242 is the collection of all cells of @xmath20 whose interiors are crossed by @xmath242 .",
    "the simplices of our cutting might also contain points outside this zone , but they are required to cover all the cells of the zone .",
    "( in a sense , this can be regarded as a variant of the shallow cutting lemma of matouek @xcite . )",
    "[ thm_cutting ] _ ( * cutting lemma for the zone of a convex set*)_. let @xmath15 be a collection of @xmath1 hyperplanes in @xmath239 , let @xmath240 be a parameter , and let @xmath243 be the boundary of a convex set in @xmath239 .",
    "then there exists a @xmath24-cutting @xmath19 for the zone of @xmath243 in the arrangement @xmath20 , consisting of @xmath244 simplices , for @xmath65 , and of @xmath245 simplices , for @xmath67 .",
    "we will need a variant of this result for weighted collections of hyperplanes , where such a collection is a pair @xmath246 , where @xmath15 is a collection of hyperplanes , and @xmath27 is a nonnegative weight function on @xmath15 . for a subset @xmath247 , we write @xmath248 for @xmath249 .",
    "the notions introduced for unweighted collections of hyperplanes can usually be generalized for weighted collections in an obvious way .",
    "in particular , given the boundary @xmath243 of a convex set in @xmath2 , we say that @xmath19 is a @xmath24-cutting for the zone of @xmath243 in @xmath250 , if the simplices of @xmath19 cover all points in the zone , and for every simplex @xmath23 of @xmath19 , the collection @xmath22 has total weight @xmath251 .",
    "a simple reduction from cuttings for weighted collections of hyperplanes to unweighted cuttings is discussed in @xcite , and can be applied here for a @xmath24-cutting for the zone of @xmath243 in @xmath20 without any change .",
    "hence , theorem [ thm_cutting ] implies the following .    [ corollary_weight_cutting ]",
    "let @xmath246 be a weighted collection of @xmath1 hyperplanes in @xmath2 , let @xmath240 be a parameter , and let @xmath243 be the boundary of a convex set .",
    "there exists a @xmath24-cutting @xmath19 for the zone of @xmath243 in @xmath250 of size @xmath244 , for @xmath65 , and @xmath245 , for @xmath67 .    before proving theorem [ thm_cutting ]",
    ", we need the following technical lemma .",
    "[ lemma_func_expectation ] let @xmath128 and put @xmath252 .",
    "then    _ ( ) _ = 1em    @xmath253 , for any @xmath254 .    @xmath255",
    ".    * proof .",
    "* this follows from the fact that binomial variables are concentrated near their means , and we omit the routine and technical details .",
    "@xmath165    [ [ section-3 ] ]",
    "the proof of theorem [ thm_cutting ] uses a triangulation of the cells of an arrangement of hyperplanes , called _",
    "canonical triangulation _ ( or _ bottom - vertex triangulation _ ) . the definition and some properties of this triangulation can be found in @xcite . for a subcollection @xmath28 of hyperplanes ,",
    "let @xmath256 denote the set of simplices in the canonical triangulation of @xmath257 .",
    "let @xmath243 be the boundary of a convex set in @xmath2 .",
    "we denote by @xmath258 the minimal set of simplices of @xmath256 which cover the zone of @xmath243 in @xmath257 .",
    "we recall the following results about the canonical triangulation :    [ lemma_triangulation ] let @xmath15 be a collection of @xmath1 hyperplanes in @xmath2 .    _",
    "( ) _ = 1em    _ @xcite _ for every simplex @xmath259 , there exists a unique inclusion - minimal collection @xmath260 , such that @xmath261 .",
    "this collection @xmath262 , called the _ defining set _ of @xmath23 , consists of at most @xmath263 hyperplanes .    _",
    "@xcite _ if @xmath28 and @xmath264 then @xmath259 if and only if its interior is intersected by no hyperplane of @xmath15 .    _",
    "@xcite _ assuming @xmath15 is in general position , each cell in @xmath20 is a simple polytope , in which the number of simplices in its canonical triangulation is at most proportional to the number of its vertices ( with the constant of proportionality depending on @xmath14 ) .",
    "[ [ section-4 ] ]    let @xmath15 , @xmath1 , @xmath265 and @xmath243 be as in theorem [ thm_cutting ]",
    ". for a simplex @xmath23 , define the _ excess _ of @xmath23 to be max@xmath266 .",
    "let @xmath267 be a random sample of hyperplanes of @xmath15 , where each hyperplane is drawn independently with probability @xmath268 .",
    "let @xmath269 denote the expected number of simplices with excess at least @xmath270 in @xmath271 .",
    "[ npt_lemma ] _ * ( exponential decay lemma)*_. for @xmath272 and @xmath273 , @xmath274    where @xmath275 is the expected size of @xmath276 , for another random sample @xmath277 , in which each hyperplane is chosen independently with probability @xmath278 .",
    "we omit the proof of the lemma , which is essentially the same as in @xcite and @xcite , and it can be viewed as a special instance of the general setup considered in @xcite .",
    "[ [ section-5 ] ]    as a final step before the proof of theorem @xmath279 , we recall the bound established in @xcite on the complexity of the zone of the boundary of a convex set in a hyperplane arrangement .",
    "[ thm_extended_zone ] _ * ( extended zone theorem)*_. the complexity of the zone of the boundary of an arbitrary convex set in an arrangement of @xmath1 hyperplanes in @xmath2 is @xmath280 for @xmath65 , where the constant of proportionality depends on @xmath14 , and @xmath281 for @xmath67 .",
    "* proof of theorem [ thm_cutting ] . *",
    "first , we may assume that @xmath273 , since otherwise , the bottom - vertex triangulation @xmath282 can serve as the desired cutting .",
    "by lemma [ lemma_triangulation ] ( iii ) , the number of simplices in @xmath271 is at most proportional to the number of vertices in the zone of @xmath243 in @xmath283 .",
    "hence , by theorem [ thm_extended_zone ] , we have    @xmath284 since @xmath285 , lemma [ lemma_func_expectation ] ( i ) implies that the expected number @xmath286 of simplices in @xmath271 is , for @xmath65 , @xmath287 @xmath288 for @xmath67 , a similar argument shows , by lemma [ lemma_func_expectation ] ( ii ) , that @xmath289 . note that these bounds hold for any @xmath290 .    to obtain the desired cutting ,",
    "we start with @xmath291 . for each simplex @xmath292 , let @xmath293 be the excess of @xmath23 . each simplex",
    "@xmath23 with @xmath294 is left as is . for those simplices",
    "@xmath23 with @xmath295 , let @xmath296 be a @xmath297-cutting for @xmath298 of size @xmath299 .",
    "such a cutting exists by the cutting lemma @xcite .",
    "we take the intersection of every simplex @xmath300 with @xmath23 , and triangulate it if necessary into @xmath301 sub - simplices .",
    "the collection of simplices appearing in these triangulations , over all simplices @xmath292 , with @xmath295 , plus the simplices of @xmath302 which were not triangulated further , form our cutting @xmath19 , which , as is easily verified , is indeed a @xmath24-cutting for the zone of @xmath243 in @xmath20 .",
    "we bound the size of @xmath19 by bounding the expected value @xmath303 of the sum @xmath304 .",
    "we have @xmath305 using lemma [ npt_lemma ] and the bound ( [ eq_ct_r ] ) , and recalling that @xmath268 , we have , for @xmath65 , and for appropriate constants @xmath101 and @xmath306 , depending on @xmath14 , @xmath307 @xmath308 for @xmath67 , arguing similarly , we have @xmath309 .",
    "this completes the proof of theorem [ thm_cutting ] .",
    "let @xmath0 be a set of @xmath1 points in @xmath239 .",
    "simplicial partition _ for @xmath0 is a collection @xmath310 where the @xmath311 s are pairwise disjoint subsets ( called the _ classes _ of @xmath312 ) forming a partition of @xmath0 , and each @xmath313 is a relatively open simplex containing @xmath311 .",
    "we also require that the @xmath311 s be roughly of the same size , that is , @xmath314 for each @xmath132 , for some parameter @xmath315 ( so @xmath316 ) . assuming that the points of @xmath0 are in general position , and @xmath317 , the simplices @xmath313 are full - dimensional .",
    "we also note that the simplices @xmath313 are not required to be pairwise disjoint , so a simplex @xmath313 may also contain other points of @xmath0 , in addition to those of @xmath311 .",
    "( see however the recent work of chan @xcite where the simplices can be made pairwise disjoint . )    for a hyperplane @xmath18 , and a simplex @xmath23 , we say that @xmath18 _ crosses _ @xmath23 if @xmath318 and @xmath319 ( thus a hyperplane does not cross a lower - dimensional simplex contained in it ) .",
    "we define the _ crossing number _ of a hyperplane @xmath18 ( with respect to @xmath312 ) as the number of simplices @xmath313 crossed by @xmath18 , and define the _ crossing number _ of @xmath312 as the maximum crossing number of any hyperplane with respect to @xmath312 .",
    "we recall two previous versions of the partition theorems , both developed by matouek .",
    "the first one , used for obtaining an efficient simplex range counting algorithm , is the standard , general partition method .",
    "the second one , used for improved range reporting algorithms , is a partition method for shallow hyperplanes only , that is , the improved crossing number ( relative to the first result ) , is guaranteed only for hyperplanes that contain up to a prescribed number of points on one side .",
    "[ thm_matousek_general ] _ * ( partition theorem @xcite)*_. let @xmath0 be an @xmath1-point set in @xmath2 and let @xmath320 be a parameter .",
    "there exists a simplicial partition @xmath312 for @xmath0 of size @xmath32 , whose classes satisfy @xmath314 , with crossing number @xmath42 .",
    "[ thm_matousek_shallow ] _ * ( partition theorem for shallow hyperplanes @xcite)*_.",
    "let @xmath0 be an @xmath1-point set in @xmath2 and let @xmath321 be a parameter .",
    "there exists a simplicial partition @xmath312 for @xmath0 of size @xmath32 , whose classes satisfy @xmath314 , and such that the crossing number of any @xmath4-shallow hyperplane with respect to @xmath312 is @xmath322 for @xmath75 , and @xmath323 for @xmath324 .    here is our version of the partition theorem , which caters to sets of shallow points and for any hyperplane .",
    "[ thm_partition ] _ * ( partition theorem for shallow points)*_. let @xmath0 be a set of @xmath1 @xmath4-shallow points in @xmath239 , where @xmath39 and @xmath325 .",
    "there exists a simplicial partition @xmath312 for @xmath0 , whose classes @xmath311 satisfy @xmath326 @xmath90so their number @xmath327 is @xmath328 , and such that the crossing number of any hyperplane with respect to @xmath312 is @xmath329 for @xmath65 , and @xmath330 for @xmath67 .    such a simplicial partition can be constructed in time @xmath331 , for any fixed @xmath134 @xmath90where the constants in this bound and in the bound on the crossing number depend on @xmath332 .",
    "the construction time can be improved to @xmath333 , provided that @xmath334 for any fixed @xmath335 @xmath90again with the constants in this bound and in the bound on the crossing number depending on @xmath336 .    * remarks : ( i ) * note that , in contrast with theorem [ thm_matousek_general ] and [ thm_matousek_shallow ] , which hold for any @xmath320 , theorem [ thm_partition ] only holds for the shallowness parameter @xmath4 of the set @xmath0 . * ( ii )",
    "* we may assume that @xmath124 is larger than some suitable constant , since otherwise we can partition @xmath0 into a constant number ( @xmath337 ) of arbitrary classes , and the theorem then holds trivially .",
    "[ [ section-6 ] ]    the proof of theorem [ thm_partition ] is based on the following lemma , adapted from similar lemmas in @xcite .",
    "[ lemma_partition_q ] let @xmath0 , @xmath1 and @xmath4 be as above , and let @xmath338 be a given set of hyperplanes .",
    "then there exists a simplicial partition @xmath312 for @xmath0 , each of whose classes @xmath311 satisfies @xmath326 , such that the crossing number of every hyperplane @xmath339 with respect to @xmath312 is @xmath340    * proof .",
    "* we first present the proof for the case @xmath65 , and then consider the case @xmath67 , whose simpler proof uses the same machinery",
    ". we will inductively construct pairwise disjoint subsets @xmath341 of @xmath0 , and simplices @xmath342 , so that @xmath343 for each @xmath344 .",
    "suppose that @xmath345 have already been constructed , and set @xmath346 and @xmath347 , where we start with @xmath348 .",
    "we iterate the construction as long as @xmath349 , for an appropriate constant @xmath350 that will be set below .",
    "let @xmath351 be a random sample of @xmath352 , where each point is chosen independently with probability @xmath353 , and let @xmath354 be the set of vertices of @xmath355 , as in section [ section_sampling ]",
    ". by proposition [ lemma_prob ] , with constant probability , @xmath354 and @xmath351 satisfy @xmath356 and @xmath357 ( here we use the assumption that @xmath358 is sufficiently large ; see below ) .",
    "assume that the sample @xmath351 does satisfy these properties .",
    "then , by proposition [ prop_peps ] , with probability at least @xmath359 , @xmath351 is also a relative @xmath360-approximation for @xmath361 , where @xmath81 is , as above , the set of all simplices in @xmath2 , @xmath362 , @xmath99 is taken from theorem [ thm_relative_peps ] , and @xmath363 is the vc - dimension of @xmath221 .",
    "let us set @xmath364 , and assume that @xmath365 .",
    "we distinguish between two cases .",
    "first suppose that @xmath349 .",
    "for a hyperplane @xmath339 , let @xmath366 denote the number of simplices among @xmath367 crossed by @xmath18 .",
    "we define a weighted collection @xmath368 by setting @xmath369 for each @xmath339 .",
    "we use a variant of the cutting lemma for weighted collections of hyperplanes .",
    "we fix a parameter @xmath370 ( again , its value will be set shortly ) , and construct a @xmath371-cutting @xmath372 for the zone of the boundary @xmath243 of the convex hull of @xmath354 in the arrangement @xmath373 . by corollary [ corollary_weight_cutting ] ,",
    "@xmath372 consists of at most @xmath374 simplices , for a suitable constant @xmath375 .",
    "we set @xmath376 for an appropriate constant parameter @xmath377 , whose concrete value will be set later .",
    "let @xmath378 be the solution of @xmath379 .",
    "we put @xmath380 and note that ( i ) @xmath381 , ( ii ) @xmath382 ( as required by proposition [ lemma_prob ] ) , and ( iii ) @xmath383 ( as required by proposition [ prop_peps ] ) .",
    "we estimate the size of @xmath372 by @xmath384 ( the final inequality holds when @xmath385 and @xmath386 , which is indeed the case since @xmath377 and @xmath387 . ) using this bound , we argue that there exists a ( relatively open ) simplex @xmath388 containing at least @xmath4 points of @xmath352 . to see this",
    ", we first observe that each point of @xmath354 is contained in some simplex of @xmath372 .",
    "hence there exists a relatively open simplex @xmath388 , such that @xmath389 . since @xmath390 , the measure of @xmath391 in @xmath351 satisfies @xmath392 where @xmath393 we can now bound from below the number of points of @xmath352 in @xmath391 .",
    "put @xmath394 .",
    "since @xmath351 has the relative @xmath58-approximation property with respect to @xmath352 , with the values of @xmath5 and @xmath233 as specified in proposition [ prop_peps ] , we have , by definition [ definition_peps ] ,    ( ) = 2em    if @xmath395 , then , by the choice of @xmath234 , @xmath396    if @xmath397 , then @xmath398    and thus we have @xmath399 by requiring that @xmath400 , we get that @xmath401 . substituting the value of @xmath205 in ( [ eq_z_measure ] ) , this requirement becomes @xmath402 or @xmath403 since we assume that @xmath382 , this inequality will be satisfied if @xmath404 this inequality in turn can be enforced by choosing @xmath405 to be a sufficiently small constant which depends only in @xmath14 ( note that the dependence of @xmath406 on @xmath4 does not prevent us from choosing @xmath405 to be a constant ) .    to recap , with this choice of @xmath405 ( and thus of @xmath370 ) ,",
    "we can ensure , with probability at least @xmath359 , that @xmath401 , that is , @xmath391 is a full - dimensional simplex and contains at least @xmath40 points of @xmath352 .",
    "we now set @xmath407 to be an arbitrary @xmath4-point subset of @xmath408 , and put @xmath409 , so @xmath410 .",
    "see figure [ fig_partition1 ] for an illustration",
    ".    proceeding with this construction , we reach an index @xmath411 , for which @xmath412 .",
    "we then partition the set @xmath413 of the remaining points into at most @xmath350 arbitrary subsets @xmath414 of size @xmath4 each , except for @xmath415 , whose size is between @xmath4 and @xmath416 .",
    "we define the simplices @xmath417 , and set @xmath418 , thereby completing the construction .",
    "since the last phase adds at most a constant number of ( i.e. , at most @xmath419 ) classes and simplices , it only increases the crossing number of any hyperplane by an additive constant .",
    "hence it suffices to bound the crossing number of any hyperplane relative to @xmath420 .",
    "to do so , we estimate the final total weight @xmath421 of the hyperplanes of @xmath338 in two different ways .    on one hand , the weight @xmath422 of a hyperplane @xmath339 with crossing number @xmath423 is equal to @xmath424",
    "therefore , @xmath425 .    on the other hand ,",
    "let us consider how @xmath426 increases compared to @xmath427 .",
    "note that , since @xmath372 is a @xmath371-cutting of the weighted collection @xmath428 , it follows that @xmath429 is crossed by a collection of hyperplanes , denoted by @xmath430 , whose total weight at step @xmath132 is at most @xmath431 . when passing to step @xmath432 ,",
    "the weight of every hyperplane of @xmath430 is doubled , whereas the weight of any other hyperplane remains unchanged .",
    "thus , the total weight of @xmath338 increases by at most @xmath431 .",
    "that is , @xmath433 let us put @xmath434 , and recall that @xmath435 , @xmath436 , and @xmath437 .",
    "hence @xmath438 taking logarithms and using the inequality @xmath439 , we get @xmath440 @xmath441 where @xmath442 .",
    "that is , we have @xmath443 for @xmath65 .",
    "this completes the proof for @xmath65 .",
    "consider next the case @xmath67 , and follow the same reasoning as in higher dimensions . at step @xmath132 of the construction",
    ", we put @xmath444 and construct a @xmath371-cutting @xmath372 of the zone of @xmath445 in @xmath373 , where @xmath446 is defined as above . by corollary [ corollary_weight_cutting ]",
    "we have @xmath447 for an appropriate constant @xmath375 . hence , ( [ eq_z_measure ] ) and ( [ eq_partition_constants ] ) , with @xmath67 , are valid for this case as well .",
    "let @xmath378 be the solution of @xmath448 , and put @xmath380 as in higher dimensions . using the relative @xmath58-approximation property of @xmath351 ( which we may assume to hold )",
    ", we obtain that there exists an open cell @xmath391 of @xmath372 , for which @xmath449 , provided that @xmath405 is chosen to be a sufficiently small constant , satisfying inequality ( [ eq_partition_constants ] ) .",
    "we take @xmath407 to be an arbitrary subset of @xmath4 points of @xmath408 , and put @xmath409 .",
    "we repeat this step until @xmath450 , and then complete the construction as in the higher - dimensional case .    the analysis of the crossing number proceeds as above , except for the different value of the parameters @xmath370 . plugging this value into the appropriate variant of inequality ( [ eq_partition_step ] ) ,",
    "yields the following bound @xmath451 @xmath452 where @xmath442 , as above .",
    "this concludes the proof of the lemma .",
    "@xmath165    [ [ section-7 ] ]",
    "the next step in the proof of theorem [ thm_partition ] is to choose a small ` test - set ' @xmath338 of hyperplanes , with the property that the crossing number of any hyperplane is at most proportional to the maximum crossing number of a hyperplane in @xmath338 .",
    "[ lemma_test - set ] _ * ( test - set lemma)*_.",
    "let @xmath0 , @xmath1 , and @xmath4 be as above .",
    "then there exists a set @xmath338 of @xmath453 hyperplanes , such that , for any simplicial partition @xmath454 satisfying @xmath455 for every @xmath132 , the following holds : if @xmath456 is the maximum crossing number of a hyperplanes of @xmath338 with respect to @xmath312 , then the crossing number of any hyperplane with respect to @xmath312 is at most @xmath457    for @xmath65 , and @xmath458 for @xmath67 .",
    "* let @xmath123 be the collection of hyperplanes dual to the points of @xmath0 .",
    "put @xmath459 . construct a @xmath297-cutting @xmath19 of size @xmath299 for @xmath20 , and let @xmath338 be the set of all hyperplanes dual to the vertices of @xmath19 . clearly @xmath460 .    fix a simplicial partition @xmath461 as above",
    "let @xmath18 be any hyperplane in the primal space .",
    "the point @xmath462 dual to @xmath18 is contained in a simplex @xmath463 .",
    "let @xmath464 be the set of hyperplanes in the primal space dual to the vertices of @xmath243 .",
    "clearly @xmath465 , so each of the @xmath121 hyperplanes of @xmath464 crosses at most @xmath456 simplices of @xmath312 .",
    "it remains to bound the number of simplices of @xmath312 which are crossed by the hyperplane @xmath18 but by no hyperplane of @xmath464 .",
    "such simplices @xmath313 must be completely contained in the zone of @xmath18 in the arrangement @xmath466 , and hence this zone must also contain the points of their corresponding classes @xmath311 in its interior .",
    "it is elementary to verify ( also see @xcite and @xcite ) , that any point of @xmath0 lying in the interior of the zone of @xmath18 in @xmath466 dualizes to a hyperplane of @xmath15 intersecting the interior of the simplex @xmath243 , and there are at most @xmath467 such hyperplanes in @xmath15 .",
    "hence , the zone of @xmath18 may contain at most these many points of @xmath0 , implying that there are at most @xmath468 simplices of @xmath312 completely contained in the zone of @xmath18 in @xmath466 , since @xmath455 for every @xmath132 . in the plane",
    ", there is at most @xmath469 such simplex . @xmath165    * proof of theorem [ thm_partition ] . *",
    "the proof of the partition theorem now follows easily .",
    "consider first the case @xmath65 .",
    "given the set @xmath0 of @xmath1 @xmath4-shallow points , we first construct a test - set @xmath338 of @xmath453 hyperplanes , as in lemma [ lemma_test - set ] .",
    "then we apply lemma [ lemma_partition_q ] , obtaining a simplicial partition @xmath312 such that any hyperplane @xmath339 has crossing number @xmath470 relative to @xmath312 .",
    "( here we use the face that , when @xmath124 is at least some sufficiently large constant , @xmath471 is dominated by the other term in the bound . ) by the ` test - set ' property of @xmath338 , the crossing number of any hyperplane @xmath18 relative to @xmath312 is at most @xmath472 @xmath473 as claimed . the case @xmath67",
    "is argued similarly and the resulting crossing numbers , of the lines of @xmath338 , and thus also of any line , are @xmath474 .",
    "this completes the proof of the existence and main properties of the partition .",
    "it remains to analyze the preprocessing time of this partition .",
    "we actually carry out the standard algorithm of @xcite , which constructs a @xmath371-cutting of the entire arrangement of @xmath373 , and use the preceding analysis to argue that one of the simplices in the cutting will contain ( with high probability ) @xmath40 points of @xmath352 .",
    "there is no need to explicitly construct @xmath110 , @xmath118 , and the zone of the convex hull of @xmath110 , they are needed only to guarantee the existence of such a simplex . with this approach",
    ", we can thus conclude that the preprocessing time of our simplicial partition for a set of @xmath4-shallow points is at most @xmath331 for any value of @xmath4 and for any fixed @xmath134 ( where the constants in this bound and in the bound on the crossing number both depend on @xmath84 ) . if @xmath475 , for any fixed @xmath476 , the preprocessing time can be reduced to @xmath333 , as in @xcite ( where the constants in both bounds now depend on @xmath95 ) .",
    "we note that , in the output - sensitive range counting algorithm below , we use the latter bound , since we deal there only with large values of @xmath4 .",
    "this concludes the proof of the partition theorem .",
    "let us note the following special case of theorem [ thm_partition ] , where the points of @xmath0 are @xmath36-shallow .",
    "[ corollary_partition_1_shallow ] let @xmath0 be a set of @xmath1 @xmath36-shallow points in @xmath2 , where @xmath39 .",
    "there exists a simplicial partition @xmath312 for @xmath0 , whose classes @xmath311 satisfy @xmath477 ( except , possibly , for one class of size @xmath478 ) , such that the crossing number of any hyperplane with respect to @xmath312 is @xmath479 for @xmath65 , and @xmath480 for @xmath67 .",
    "[ [ overview . ] ] overview .",
    "+ + + + + + + + +    in this section we derive two major applications of the partition theorem for shallow sets ( theorem [ thm_partition ] ) presented in the previous section .",
    "the first application is the construction of a spanning tree with small relative crossing number , which depends on the shallowness of the crossing hyperplane .",
    "we then turn this construction into a construction of a relative @xmath58-approximation , using the same machinery of har - peled and sharir @xcite , thus extending their planar construction to higher dimensions .",
    "the second application is an output - sensitive halfspace range counting data structure , where the query time is better than that of the standard algorithm of matouek @xcite , when the hyperplane bounding the query halfspace is shallow .      in our first application",
    ", we extend the `` weight - sensitive '' version of _ spanning trees with small relative crossing number _ in the plane , studied by har - peled and sharir @xcite , to higher dimensions .",
    "both our extension and the construct in @xcite refine the following classical construct of spanning trees with small crossing number , as obtained by chazelle and welzl @xcite , with a simplified construction given later in @xcite .",
    "_ * @xcite * _ [ thm_standard_spanning_t ] let @xmath0 be a set of @xmath1 points in @xmath2 , @xmath39",
    ". then there exists a straight - edge spanning tree @xmath53 of @xmath0 such that each hyperplane in @xmath2 crosses at most @xmath54 edges of @xmath53 .",
    "[ lemma_spanning_t_k ] let @xmath0 be a set of @xmath1 @xmath4-shallow points in @xmath2 .",
    "one can construct a spanning tree @xmath481 for @xmath0 , such that any hyperplane crosses at most @xmath482 edges of @xmath53 , for @xmath65 , and @xmath483 edges , for @xmath67 .",
    "* we first consider the case @xmath65 .",
    "given a set @xmath0 of @xmath1 @xmath4-shallow points , we construct a simplicial partition @xmath454 of @xmath0 , by applying the partition theorem ( theorem [ thm_partition ] ) , for sets of @xmath40-shallow points ( clearly , the points of @xmath0 are also @xmath484-shallow ) .",
    "( we note that replacing @xmath4 by @xmath40 does not affect asymptotically the crossing number of @xmath312 . )",
    "each class @xmath311 of the partition now satisfies @xmath485 .",
    "given @xmath312 , we first ignore its `` tail '' , namely the pairs @xmath486 , where @xmath178 , as in the proof of lemma [ lemma_partition_q ] , is the first index for which @xmath487 .",
    "let @xmath488 denote the collection @xmath489 .",
    "for each @xmath490 , we construct a spanning tree @xmath491 for @xmath311 with crossing number @xmath492 using theorem [ thm_standard_spanning_t ] .",
    "then we connect those trees by segments , called _ bridges _ , into a single tree , whose construction will be detailed below . finally , we construct another spanning tree , denoted by @xmath493 , of the at most @xmath494 points in @xmath495 , with crossing number @xmath496 .",
    "we connect @xmath493 by a single edge to an arbitrary point in the other tree .",
    "the union of the trees @xmath497 together with the connecting bridges forms our spanning tree @xmath53 .",
    "the connecting bridges are constructed as follows .",
    "we pick a point @xmath498 from @xmath311 , uniformly at random , for each @xmath499 .",
    "let @xmath267 denote the resulting set of @xmath316 points .",
    "the probability of any single point to belong to @xmath267 is at most @xmath500 .",
    "( it is here that we use the larger size of the classes ; see below . )",
    "suppose that some point @xmath180 has been chosen in @xmath267 . by assumption",
    ", @xmath175 is @xmath4-shallow , so there is a halfspace @xmath15 which contains @xmath175 and at most @xmath176 other points of @xmath0 .",
    "since each of these points appears in @xmath267 with probability @xmath501 , the expected number of points in @xmath502 ( conditioned on @xmath175 being chosen in @xmath267 ) is @xmath503 .",
    "hence , using markov s inequality , with ( conditional ) probability at least @xmath504 , there is no other point apart from @xmath175 in @xmath502 , that is , @xmath175 is a vertex of the convex hull of @xmath267 .",
    "hence , the expected number of vertices of @xmath505 is at least @xmath506 .",
    "we may assume that @xmath267 satisfies this property , and denote by @xmath507 the subset of hull vertices of @xmath505 ; thus , @xmath508",
    ".    apply corollary [ corollary_partition_1_shallow ] to the set @xmath507 , to obtain a partition of it into @xmath509 disjoint pairs .",
    "let @xmath510 denote the collection of the segments connecting the points in each pair . by construction ,",
    "each hyperplane crosses at most @xmath511 segments of @xmath510 .",
    "the segments of @xmath510 merge together some subsets of trees @xmath491 into larger trees .",
    "since we created at least @xmath512 bridges , the number of disconnected trees is now @xmath513 .",
    "we now repeat the above construction to the new trees , or , rather , to the subsets of @xmath0 that they span .",
    "that is , we choose a random point from each subset , take the subset of hull vertices of the resulting sample , and apply corollary [ corollary_partition_1_shallow ] to it , to create new bridges .",
    "the situation has actually improved , because these vertex sets of the current collection of trees are now larger ( while the points are still @xmath4-shallow ) , so the probability of choosing any specific point is smaller ; hence the probability of a sampled point to become a hull vertex can only grow . in any case , we create at least @xmath514 new bridges , and keep iterating in this manner until all trees have been merged into a single tree .",
    "as is easily checked , the number of bridges crossed by a hyperplane @xmath18 is at most @xmath515 in addition , @xmath18 crosses @xmath329 of the simplices @xmath313 , and , within each such simplex @xmath313 , it crosses @xmath492 edges of the corresponding tree @xmath491 .",
    "also , it crosses @xmath492 edges of the tree @xmath493 .",
    "since the bound within the simplices dominates the other two bounds , we conclude that @xmath18 crosses at most @xmath516 edges of @xmath53 .",
    "this completes the proof for @xmath65 .    for @xmath67 , follow the same construction as described above , and re - estimate the crossing number of a hyperplane @xmath18 relative to our tree @xmath53",
    "we observe that @xmath18 crosses edges from @xmath517 trees of @xmath491 , and within each of them it crosses @xmath518 edges .",
    "in addition , @xmath18 crosses @xmath518 edges of @xmath493 . following the same mechanism of the bridge construction and its analysis ,",
    "the number of bridges crossed by @xmath18 is at most @xmath519 thus , altogether , the crossing number of @xmath53 is bounded by @xmath520 as asserted .",
    "@xmath165      let now @xmath0 be a set of @xmath1 points in @xmath2 ( without the shallowness assumption ) .",
    "for a ( non vertical ) hyperplane @xmath18 , let @xmath521 ( resp . ,",
    "@xmath522 ) be the number of points of @xmath0 lying above ( resp . , below or on ) @xmath18 , and define the _ weight _ of @xmath18 , denoted by @xmath69 , to be @xmath523 .",
    "[ thm_spanning_t ] let @xmath0 be a set of @xmath1 points in @xmath2 .",
    "then one can construct a spanning tree @xmath481 for @xmath0 , such that any hyperplane @xmath18 crosses at most @xmath524 edges of @xmath481 , for @xmath65 , or @xmath525 edges , for @xmath67 .",
    "* we construct a sequence of subsets of @xmath0 , as follows .",
    "put @xmath348 . at the @xmath526 step , @xmath527 ,",
    "let @xmath311 denote the set of ( at most ) @xmath528-shallow points of @xmath529 , and put @xmath530 .",
    "we stop when @xmath352 becomes empty . by construction",
    ", the @xmath526 step removes at least @xmath528 points from @xmath529 , because any ( exactly ) @xmath528-shallow halfspace @xmath15 contains @xmath528 points of @xmath352 , all of which are ( at most ) @xmath528-shallow .",
    "hence , @xmath531 , and so the process terminates after @xmath532 steps . at the @xmath526 step , we construct a spanning tree @xmath491 for @xmath311 , using lemma [ lemma_spanning_t_k ] , with @xmath533 .",
    "connect the resulting trees by @xmath532 additional straight segments ( in an arbitrary manner ) into a single spanning tree @xmath53 of @xmath0 .",
    "we claim that @xmath53 is the desired spanning tree .",
    "indeed , consider an arbitrary hyperplane @xmath18 of weight @xmath534 .",
    "we observe that @xmath18 can not cross any of the trees @xmath491 , for @xmath535 . to see this , assume to the contrary that @xmath18 crosses @xmath536 for some @xmath537 .",
    "that is , there exist two points @xmath538 which are separated by @xmath18 . without loss of generality , assume that @xmath539 lies in the halfspace bounded by @xmath18 which contains @xmath4 points",
    ". in particular , @xmath539 must be @xmath4-shallow in @xmath0 ( and thus also in any subset @xmath352 containing it ) , so it must have been removed at some step @xmath540 and thus can not belong to @xmath541 .",
    "thus , @xmath18 crosses only the first @xmath542 trees of our construction .",
    "hence , for @xmath65 , the number of edges of @xmath53 that @xmath18 crosses , excluding the @xmath532 connecting edges , is at most @xmath543 we have @xmath544 , for some @xmath545 , and we can estimate the sum by the integral @xmath546 by integrating in parts , it easily follows that , for @xmath547 , @xmath548 , and @xmath549 , @xmath550 where the @xmath551 notation is with respect to the growth of @xmath175 .",
    "this allows us to bound the sum above by @xmath552 which is the asserted bound on the crossing number of @xmath18 , for @xmath65 .",
    "let us consider the case @xmath67 .",
    "the crossing number of a line @xmath56 relative to @xmath53 is bounded by @xmath553 which we separate into the two sums : @xmath554 @xmath555 is bounded by @xmath556 @xmath68 is very slowly increasing ; in particular , it satisfies @xmath557 for any @xmath157 , and so , for @xmath558 , we have @xmath559 we can therefore bound the sum in ( [ eq_alpha_sum ] ) , denoted by @xmath303 , by @xmath560 using again the integral bound in ( [ eq_integral ] ) , we obtain , for an appropriate constant @xmath99 , @xmath561 from which we obtain @xmath562 for @xmath563 , we use the trivial bound @xmath564 altogether , the crossing number of @xmath56 is at most @xmath565 this establishes the bound on the crossing number for @xmath67 .",
    "@xmath165    * remark : * note that the bound in theorem [ thm_spanning_t ] for the planar case is slightly worse than the bound derived in @xcite .",
    "note also that we have worked harder on the estimation of @xmath555 to ensure that when @xmath566 the bound coincides with the standard bound @xmath567 .",
    "we next turn the above construction of a spanning tree with small relative crossing number into a construction of a relative @xmath58-approximation for a set of points in @xmath2 and for halfspace ranges .",
    "we base our construction on the machinery of har - peled and sharir @xcite , thus extending their planar construction to higher dimensions .",
    "let @xmath0 be a set of @xmath1 points in @xmath2 , @xmath65 , and let @xmath53 be a spanning tree of @xmath0 as provided in theorem [ thm_spanning_t ] .",
    "we replace @xmath53 by a perfect matching @xmath568 of @xmath0 , with the same asymptotic relative crossing number , i.e. , the number of pairs of @xmath568 that are separated by a hyperplane of weight @xmath4 is at most @xmath569 .",
    "this is done in a standard manner  we first convert @xmath53 to a spanning path whose relative crossing number by any hyperplane is at most twice the crossing number of the same hyperplane with @xmath53 , and then pick every other edge of the path . to simplify the presentation , and to ensure that the resulting collection of edges is indeed a perfect matching , we assume that @xmath1 is even .",
    "we now construct a coloring of @xmath0 with low discrepancy , by randomly coloring the points in each pair of @xmath568 .",
    "specifically , each pair is randomly and independently colored either as @xmath570 or as @xmath571 , with equal probabilities .",
    "the standard theory of discrepancy ( see @xcite and @xcite ) yields the following variant .",
    "[ lemma_discrepancy ] given a set @xmath0 of @xmath1 points in @xmath2 , @xmath65 , one can construct a coloring @xmath572 , such that , for any halfspace @xmath15 , @xmath573 the coloring is balanced  each color class consists of exactly @xmath574 points of @xmath0 .",
    "* indeed ( see @xcite ) , if the maximum crossing number is @xmath80 then the above discrepancy can be bounded by @xmath575 , and the asserted bound is then immediate by theorem [ thm_spanning_t ] .",
    "@xmath165        as we next show , the improved discrepancy bound of lemma [ lemma_discrepancy ] leads to an improved bound of the size of @xmath93-samples for our range space , and , consequently , for the size of relative @xmath58-approximations ( with some constraints on the relationship between @xmath17 and @xmath5 , as noted below ) .",
    "let us introduce the following parameters : @xmath580    [ thm_improved_relative_peps ] given a set @xmath0 of @xmath1 points in @xmath2 , @xmath65 , and parameters @xmath578 and @xmath100 , one can construct a relative @xmath581-approximation @xmath582 of size @xmath583    we observe that , ignoring the power @xmath584 of the logarithmic factor , this bound is an improvement of the bound in theorem [ thm_relative_peps ] , as long as @xmath17 and @xmath5 satisfy @xmath585 substituting the values of @xmath47 and @xmath586 , we have @xmath587 which is the required constraint on the relationship between @xmath17 and @xmath5 , for which theorem [ thm_improved_relative_peps ] does indeed yield an improvement ( modulo the small `` penalty '' in the logarithmic factor )",
    ". we also note that for @xmath67 the bound in the theorem coincides with the bound in @xcite ( except for the power of the logarithmic factor ) .",
    "* proof . * following one of the classical constructions of @xmath17-approximations ( see @xcite ) , we repeatedly halve @xmath0 , until we obtain a subset of size as asserted in the theorem , and then argue that the resulting set has the desired approximation property .",
    "formally , we set @xmath588 , and , at the @xmath526 step , partition @xmath589 into two equal halves , using lemma [ lemma_discrepancy ] ; let @xmath311 and @xmath352 denote the two halves ( consisting of the points that are colored @xmath590 , @xmath591 , respectively ) .",
    "we keep @xmath311 , remove @xmath352 , and continue with the halving process .",
    "let @xmath592 denote the size of @xmath311 .",
    "for any halfspace @xmath15 , we have @xmath593 for appropriate constants @xmath99 and @xmath234 . recalling out notation @xmath594",
    "this can be rewritten as @xmath595 for an appropriate constant @xmath375 . since @xmath596 and @xmath597 ,",
    "we have @xmath598 combining together the last two relations , we have @xmath599 where @xmath600 . applying lemma [ lemma_approx_technical ] , with @xmath601 , @xmath602 , and @xmath603 ,",
    "the last expression is bounded by @xmath604 this implies that , in the notation of section [ subsection_approximations ] , @xmath605 since @xmath606 is a metric , the triangle inequality implies that @xmath607 we can therefore ensure that @xmath608 , for every halfspace @xmath15 , provided that @xmath609 .",
    "taking @xmath110 to be the smallest @xmath311 which still satisfies this size constraint , i.e. , of size @xmath610 , we have thus shown that @xmath110 is a @xmath581-sample . as follows from the equivalence between @xmath581-samples and relative @xmath581-approximations ( see @xcite and theorem [ thm_relative_peps ] ) , @xmath110 is also a relative @xmath581-approximation , which completes the proof . @xmath165",
    "* very recent work by ezra  @xcite obtains improved bounds for the size of relative approximations in a more general setting , which also includes the case of halfspace ranges in higher dimensions . for this latter setup ,",
    "the bound obtained in @xcite is @xmath611 where the power of @xmath612 is smaller than the one that we have obtained .",
    "our second main application is an improved , output - sensitive algorithm for halfspace range counting in @xmath2 , for any @xmath65 .",
    "that is , we are given a set @xmath0 of @xmath1 points in @xmath2 , and want to preprocess it into a data structure that can answer efficiently queries , in which we are given a halfspace @xmath15 , and we wish to count @xmath613 ( exactly ) .",
    "we will only consider the case where we seek a data structure with near - linear storage .",
    "our goal is an algorithm whose query performance is sensitive to the output size @xmath614 .    before describing our solution",
    ", we recall that when the output size @xmath615 is reasonably small , we can trivially turn the halfspace range reporting algorithm of matouek @xcite into a range counting algorithm .",
    "this algorithm uses a data structure with @xmath12 storage , which can be constructed in @xmath46 time , and a halfspace range reporting ( counting ) query with a halfspace @xmath15 can be answered in time @xmath616 . points .",
    "] however , when @xmath615 is large , this becomes quite inefficient . our solution will use matouek s algorithm as one of its components , but its novel contribution is for the case where @xmath615 is large ; see below for details .    here is an informal overview of the algorithm .",
    "we partition @xmath0 into a logarithmic number of subsets @xmath617 , so that , for each @xmath132 , @xmath311 consists of points which are @xmath618-shallow in @xmath619 , where @xmath620 is specified below , and @xmath621 , for @xmath527 .",
    "this partition , as we show later , has the property that a halfspace @xmath15 of weight @xmath615 will miss the convex hulls of all the sets @xmath311 , for which @xmath622 . handling sets @xmath311 with @xmath623 is done using the partition data structure for shallow sets , as provided in theorem [ thm_partition ] .",
    "this will result in a query time bound which depends on @xmath615 in roughly the same manner as the bounds in theorem [ thm_spanning_t ] .",
    "specifically , we show :    [ thm_range_counting ] given a set @xmath0 of @xmath1 points in @xmath2 , @xmath65 , one can construct a data structure for the halfspace range counting problem for @xmath0 , so that , for any query halfspace @xmath15 , the number @xmath614 of points of @xmath0 in @xmath15 can be counted , for @xmath75 , in time @xmath624 for an appropriate constant @xmath99 . for @xmath625 , the first bound for the query time",
    "is @xmath626 , and the second bound remains the same .",
    "* remarks : ( i ) * to get some feeling for these bounds , we note that for @xmath625 the query time is @xmath626 for @xmath629 and @xmath630 otherwise ; ignoring the logarithmic factors , both bounds balance out for @xmath631 . for @xmath632 ,",
    "the query time is @xmath633 for @xmath634 and @xmath635 otherwise .",
    "these bounds should be compared with the respective standard bounds @xmath636 and @xmath637 for @xmath625 and @xmath632 of @xcite ; our bounds coincide with these `` insensitive '' bounds when @xmath638 . a graphical illustration that shows this improvement for @xmath632",
    "is given in figure [ fig_output_sensitive1 ] .",
    "+ * ( ii ) * if @xmath639 , denoting @xmath640 as the complementary halfspace of @xmath15 , we obtain the count by counting @xmath641 ( see also a preceding footnote ) . in this case",
    "the upper bound on the query time is obtained by replacing @xmath615 with @xmath642 in the above bounds . + * ( iii ) * clearly , a weak feature of the theorem is that the bound on the preprocessing cost is not near - linear .",
    "it approaches @xmath643 when @xmath14 is very large . for small values of @xmath14 , it is near linear for @xmath625 and is roughly @xmath644 for @xmath632 .",
    "* we first describe the data structure , then the procedure for answering range counting queries and its analysis , then we analyze the storage used by the structure , and finally present and analyze the ( somewhat involved ) construction of the data structure .    * data structure .",
    "* we first construct an auxiliary data structure , based on matouek s range reporting mechanism @xcite , which allows us to report the points of @xmath0 in a query halfspace @xmath15 in time @xmath645 , where @xmath614 .",
    "this structure uses @xmath12 storage and can be constructed in @xmath46 time .",
    "we next partition @xmath0 into a logarithmic number of subsets @xmath646 . for each @xmath132",
    ", @xmath311 consists of points which are @xmath647-shallow in @xmath529 , where @xmath348 , @xmath648 , for @xmath649 , and the values of the constant parameters @xmath650 will be set later .",
    "we set @xmath621 , for @xmath527 , and set @xmath651 for an appropriate constant @xmath99 . with each @xmath311",
    "we associate an auxiliary halfspace emptiness data structure , due to matouek @xcite .",
    "putting @xmath652 , the structure uses linear storage , requires @xmath653 preprocessing time , where @xmath134 is arbitrarily small but fixed , and can test whether a query halfspace contains any point of @xmath311 , in time @xmath654 .",
    "next , as in the spanning tree construction ( theorem [ thm_spanning_t ] ) , for each set @xmath311 , we construct a simplicial partition @xmath655 , using theorem [ thm_partition ] , with @xmath656 , in overall time @xmath46 . with each class of each @xmath655 ,",
    "consisting of a simplex @xmath23 and a subset @xmath657 of the corresponding @xmath311 , we associate another auxiliary data structure , based on the standard simplex range counting technique of matouek @xcite . putting @xmath658 ,",
    "this structure uses @xmath659 storage and @xmath660 preprocessing time , and can count the number of points of @xmath311 in a query halfspace in time @xmath661 .",
    "this completes the description of our data structure .    *",
    "answering a counting query . * given a query halfspace @xmath662 , our range counting algorithm proceeds as follows .",
    "we first run an emptiness test on each of the sets @xmath311 , in ascending order of their indices , with respect to both @xmath662 and its complementary halfspace @xmath663 , using the auxiliary emptiness data structures associated with those sets .",
    "assume that the test first returns * true * at iteration @xmath327 , for some @xmath664 .",
    "we then set @xmath15 to be the halfspace for which the emptiness test returned * true * , and we refer to it as the query halfspace from now on .",
    "( if the original halfspace was the complement of @xmath15 , we return the desired count by subtracting .",
    "we will then miss the opportunity to answer the query more efficiently when @xmath642 is small . ]",
    "@xmath613 from @xmath1 , as above . )",
    "having a logarithmic number of sets , this step takes at most @xmath665 time .",
    "our analysis is based on lemma [ lemma_missing_pj ] , given below , from which it follows that @xmath15 is disjoint from the convex hulls of all the sets @xmath541 , for @xmath666 , and so it is guaranteed that @xmath667 .",
    "we distinguish between two cases .",
    "first suppose that @xmath668 . if @xmath669 , we have @xmath670 , and thus we are done .",
    "if @xmath671 , we have @xmath672 , and we use the reporting data structure associated with the full set @xmath0 , to count the points in @xmath16 in time @xmath673 which establishes the first bound in ( [ eq_range_counting_time ] ) .",
    "assume then that @xmath674 .",
    "it suffices to proceed only with the sets @xmath675 . for each such set @xmath311 , with an associated simplicial partition @xmath655 , we check , for each class @xmath676 , whether the simplex @xmath23 is fully contained in @xmath15 or is crossed by its bounding hyperplane @xmath18 . for a simplex @xmath23 that is fully contained in @xmath15 , we add @xmath677 to the output count , whereas for @xmath23 that is crossed by @xmath18 , we use the auxiliary range counting data structure of @xcite , associated with that node , to count @xmath678 . repeating this procedure for @xmath675 , and adding up the resulting counts , we obtain the desired count @xmath613 .",
    "we now examine the value of @xmath620 , as set in ( [ eq_range_counting_k1 ] ) , and note that , for any halfspace @xmath15 with @xmath679 , the upper bound on the cost of answering the query with @xmath15 using the range reporting data structure is roughly the same , up to polylogarithmic factor , as the cost of answering the query using the range counting procedure at each of the simplices crossed by @xmath18 .",
    "indeed , the former cost is @xmath680 , for @xmath75 , and the latter cost is @xmath681 this follows because @xmath112 for such values of @xmath69 we only need to query in @xmath682 , @xmath113 the number of simplices of @xmath683 crossed by the plane @xmath18 bounding @xmath15 is @xmath684 by theorem [ thm_partition ] , and @xmath114 the cost of a query within each of the crossed classes is @xmath685 .",
    "as is easily checked , our @xmath620 does indeed satisfy @xmath686 which makes the two bounds roughly the same , up to a polylogarithmic factor . for @xmath625 ,",
    "the first bound is @xmath687 , and the same relationship holds . for larger values of @xmath615 ,",
    "i.e. , for @xmath688 , recalling that @xmath689 , we use the second part of the data structure , recalling that , as above , @xmath18 crosses only @xmath690 simplices of @xmath655 ( see theorem [ thm_partition ] ) , to obtain an overall cost of @xmath691 this establishes the second bound on the query time , as given in ( [ eq_range_counting_time ] ) .    comparing these bounds with the preceding techniques @xcite ,",
    "we note that for @xmath692 we do not obtain any improvement  we use in fact the same algorithm of @xcite",
    ". however , for @xmath693 , the bound on @xmath694 is smaller than the `` insensitive '' bound @xmath695 of @xcite .",
    "again , see figure [ fig_output_sensitive1 ] for graphical illustrations of our improvement .",
    "( note that when @xmath566 our algorithm has the same asymptotic bound as matouek s counting algorithm @xcite . )    * storage . *",
    "the auxiliary reporting data structure stored for the entire @xmath0 uses @xmath12 storage ; see @xcite .",
    "the emptiness data structures for each of the subsets @xmath311 are of size linear in the sizes of the respective subsets @xcite , and so the total space that they consume is @xmath696 .",
    "the simplicial partitions constructed for the sets @xmath646 consume a total of @xmath696 storage , including the storage used by matouek s standard range counting structure @xcite within each simplex .",
    "hence , the overall storage is @xmath627 , as asserted .",
    "* preprocessing time .",
    "* one of the main steps in the preprocessing ( which is not required for the standard data structures of @xcite ) is the construction of the subset of @xmath4-shallow points of a set @xmath0 of @xmath1 points in @xmath2 , a step that we perform iteratively , to construct the sequence of sets @xmath646 . this step is involved ( and costly ) in higher dimensions , but we note that we only need to handle values of @xmath4 satisfying @xmath697 because for smaller values of @xmath4 we use instead the alternative range reporting machinery of @xcite . for such values of @xmath4",
    "we have @xmath698 a property that will be crucial in guaranteeing the ( relative ) efficiency of the preprocessing .",
    "so let @xmath0 , @xmath1 and @xmath4 be fixed .",
    "the construction proceeds as follows .",
    "put @xmath434 and choose a random sample @xmath267 of @xmath699 points of @xmath0 , for an appropriate sufficiently large constant @xmath234 .",
    "let @xmath700 denote the interior of the intersection of all halfspaces that contain at least @xmath701 points of @xmath267 , for an appropriate constant @xmath375 . by the centerpoint theorem ( see @xcite ) , @xmath700 is nonempty for @xmath702 , which always hold for @xmath234 sufficiently large .",
    "[ lemma_shallow_net ] let @xmath0 , @xmath267 , @xmath700 and @xmath4 be as above , and put @xmath703 .",
    "then an appropriate choice of the constants @xmath234 and @xmath375 guarantees that , with high probability , the following properties hold .              * proof . * ( 1 ) for @xmath234 sufficiently large , @xmath267 is a shallow @xmath24-net with high probability ( see section [ subsection_approximations ] for the definition and properties of shallow nets ) . since @xmath707",
    ", the claim follows from property ( ii ) of shallow @xmath24-nets , for an appropriate constant @xmath375 .",
    "\\(3 ) let @xmath708 , and let @xmath15 be a closed halfspace containing @xmath5 , disjoint from @xmath700 , and parallel to a closed halfspace @xmath709 , which supports one of the open facets of @xmath700 ( @xmath709 might coincide with @xmath15 ) . by the definition of @xmath700 ,",
    "@xmath709 contains at least @xmath710 points of @xmath267 . since at most @xmath14 points lie on its bounding hyperplane",
    ", its complementary closed halfspace @xmath711 contains at most @xmath712 points of @xmath267 , and thus , by property ( ii ) , it is @xmath33-shallow in @xmath0 , implying that @xmath5 is @xmath33-shallow in @xmath0 , as claimed .",
    "\\(4 ) we argue that no point @xmath713 can be @xmath4-shallow in @xmath0 .",
    "indeed , let @xmath5 be such a point and let @xmath15 be a closed halfspace , whose bounding hyperplane @xmath18 contains @xmath5 . by construction",
    ", since @xmath18 intersects @xmath700 , it follows that @xmath714 . by property ( i )",
    ", we have @xmath715 . since this holds for every halfspace @xmath15 containing @xmath5 , @xmath5 is not @xmath4-shallow in @xmath0 , a contradiction which implies the claim .",
    "@xmath165        [ lemma_missing_pj ]",
    "let @xmath0 , its partition into @xmath646 , and the parameters @xmath717 be as above .",
    "let @xmath15 be a halfspace in @xmath2 of weight @xmath615 .",
    "then @xmath15 misses the convex hulls of the sets @xmath718 , if @xmath719 , and of the sets @xmath541 , for @xmath666 , otherwise .",
    "* first assume that @xmath719 .",
    "since the points in @xmath720 are at least @xmath721-deep , @xmath15 can not contain any of them , and it therefore misses the convex hulls of the sets @xmath722 , as claimed .",
    "we may thus assume that @xmath688 , and so @xmath723 .",
    "assume that @xmath15 crosses the convex hull of a set @xmath541 , for @xmath537 .",
    "thus , necessarily , there exists a point @xmath724 which is @xmath615-shallow . on the other hand , by lemma [ lemma_shallow_net ] ( 4 ) , @xmath541 consists of points which are at least @xmath725-deep in @xmath726 , and clearly so they are in @xmath0 .",
    "thus the depth of @xmath178 is at least @xmath727 that is , @xmath178 is at least @xmath728-deep in @xmath0 , in contradiction to its being @xmath615-shallow .",
    "@xmath165    suppose that we have a procedure for constructing @xmath700 .",
    "then the construction of the sets @xmath311 proceeds as follows . starting with the initial set @xmath0 , put @xmath729 .",
    "lemma [ lemma_shallow_net ] ( iii ) implies that all the points of @xmath730 are @xmath33-shallow in @xmath0 and thus also in @xmath730 .",
    "we now iterate this process , as follows . at step",
    "@xmath132 we apply this construction to the subset @xmath529 of the remaining points of @xmath0 ( with @xmath348 ) , and take the resulting set @xmath730 as the next set @xmath311 in the sequence , setting @xmath731 ; that is , @xmath352 is the portion of @xmath529 inside the corresponding convex region @xmath700 .",
    "we stop the process when @xmath732 or when @xmath733 drops below a sufficiently large constant , according to the partition theorem ( theorem [ thm_partition ] ) , which happens after @xmath734 steps .",
    "if @xmath735 upon termination , we put @xmath736 .",
    "we finally describe the construction of @xmath700 , thus concluding the description of the new aspects of our data structure construction .",
    "we pass to the dual space , where each point @xmath3 is mapped to a hyperplane @xmath737 , using the standard duality which also preserves the above / below relationships ( see , e.g. , @xcite ) .",
    "consider the arrangement @xmath738 of the hyperplanes dual to the points of the sample @xmath267 .",
    "a @xmath270-shallow hyperplane @xmath178 in the primal space is mapped to a point @xmath739 which lies at level @xmath740 in @xmath741 ; more precisely , its level is either among the @xmath270 lowest levels of @xmath741 or among its @xmath270 highest levels .",
    "we denote the former ( resp . ,",
    "latter ) collection of levels as @xmath742 ( resp . , @xmath743 ) , but we use just @xmath744 ( resp . , @xmath745 ) to simplify the notation .",
    "as is well known @xcite ( and easy to verify ) , @xmath700 is mapped in the dual space to the ( open ) region @xmath746 enclosed between the upper convex hull of @xmath744 , and the lower convex hull of @xmath745 , in the sense that a point @xmath44 is in @xmath700 if and only if its dual hyperplane @xmath747 is contained in @xmath746 .",
    "we note that , by clarkson and shor @xcite , the combinatorial complexity of @xmath744 and @xmath745 is at most @xmath748 using ( [ eq_range_counting_preproc ] ) we have @xmath749 and the exponent in the right - hand side is smaller than @xmath504 when @xmath14 is odd , and only slightly larger than @xmath504 when @xmath14 is even , for @xmath65 .",
    "more precisely , @xmath750 satisfies @xmath751 for any @xmath65 .",
    "let @xmath754 ( resp . ,",
    "@xmath755 ) denote the set of vertices of @xmath744 ( resp . , @xmath745 ) .",
    "we preprocess each of @xmath754 , @xmath755 for halfspace emptiness queries , using the algorithm of @xcite",
    ". then , for each @xmath3 , we test whether @xmath756 by testing whether the upper halfspace bounded by @xmath737 does not contain any point of @xmath754 , and the complementary lower halfspace does not contain any point of @xmath755 .",
    "all the points that fail the test are placed in @xmath730 , and those that pass it are passed to the next iteration . in this way , we report the points in @xmath730 in expected time @xmath757 recalling the bound ( [ eq_range_counting_t_level ] ) for @xmath750 , for @xmath14 even we report those points in @xmath758 expected time , and for @xmath14 odd in @xmath759 expected time . having a logarithmic number of steps , we construct all the sets @xmath311 within the same asymptotic expected bound .",
    "we note that the overall time consumed by the construction of the other data structure components in each step is smaller than the bound above .",
    "we omit the description of these other steps of the construction , as they are identical to those given in @xcite .",
    "this completes the proof of theorem [ thm_range_counting ] .",
    "@xmath165                            e. ezra , a size - sensitive discrepancy bound for set systems of bounded primal shatter dimension , _ proc .",
    "siam annu .",
    "sympos . discrete algorithms _ , 2014 , to appear . also available at ` http://www.cims.nyu.edu/  esther / publications / discrepancy.pdf `            j. matouek , computing the center of planar point sets , in _ computational geometry : papars from the dimacs special year _ ( j. e. goodman , r. pollack and w. steiger , eds . ) , ams , providence , ri , pp . 221230 , 1991 .",
    "e. welzl , on spanning trees with low crossing numbers , in _ data structures and efficient algorithms , final report on the dfg special joint initiative _ ,",
    "volume 594 of _ lect .",
    "notes in comp .",
    "springer - verlag , heidelberg , pp .",
    "233249 , 1992 ."
  ],
  "abstract_text": [
    "<S> let @xmath0 be a set of @xmath1 points in @xmath2 . </S>",
    "<S> a point @xmath3 is @xmath4__-shallow _ _ if it lies in a halfspace which contains at most @xmath4 points of @xmath0 ( including @xmath5 ) . </S>",
    "<S> we show that if all points of @xmath0 are @xmath4-shallow , then @xmath0 can be partitioned into @xmath6 subsets , so that any hyperplane crosses at most @xmath7 subsets . </S>",
    "<S> given such a partition , we can apply the standard construction of a spanning tree with small crossing number within each subset , to obtain a spanning tree for the point set @xmath0 , with crossing number @xmath8 . </S>",
    "<S> this allows us to extend the construction of har - peled and sharir @xcite to three and higher dimensions , to obtain , for any set of @xmath1 points in @xmath2 ( without the shallowness assumption ) , a spanning tree @xmath9 with _ small relative crossing number_. that is , any hyperplane which contains @xmath10 points of @xmath0 on one side , crosses @xmath11 edges of @xmath9 . using a similar mechanism , we also obtain a data structure for halfspace range counting , which uses @xmath12 space ( and somewhat higher preprocessing cost ) , and answers a query in time @xmath13 , where @xmath4 is the output size . </S>"
  ]
}