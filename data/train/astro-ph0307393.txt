{
  "article_text": [
    "one of the most useful statistics for probing the power spectrum with weak gravitational lensing is the aperture mass statistic , @xmath1 .",
    "the aperture mass was first proposed by @xcite and @xcite for estimating the masses of clusters , and is essentially an estimate of the convergence , @xmath2 , within a circular aperture .",
    "the convergence is proportional to the projected mass density relative to the average value in the field , hence the name aperture mass .    since the aperture mass is relative to the average value , the statistic @xmath3 gives 0 over the whole field . however , higher order moments of the aperture mass are non - zero , and the variance , @xmath4 , has proved very useful for weak lensing researchers , with many studies to date including this statistic in their analysis ( e.g. * ? ? ? * ; * ? ? ? * ; * ? ? ? * ; * ? ? ? * ) .",
    "this statistic is a good probe of the power spectrum , and thus measures the extent of the gaussian fluctuations of the density of the universe .",
    "however , any non - gaussian component is not measured by the variance .",
    "further , the density fluctuations must be non - gaussian , since the density contrast is constrained to be greater than -1 , but it can be arbitrarily large in the positive direction .",
    "clusters generally have density contrasts of more than 200 .",
    "thus , the density fluctuations , which have a mean of 0 by definition , must be skewed towards positive values .",
    "indeed , this non - gaussianity has recently been detected in the virmos - descart survey by two groups @xcite .",
    "the lowest order measures of the non - gaussianity using the shear field are called three - point statistics , since they require measurements of three shear values and their relative positions and orientations .",
    "three - point statistics have the potential to be very useful for cosmology , since they can , in combination with two - point statistics , determine @xmath5 and @xmath6 independently @xcite .",
    "they can also be used to constrain the properties of halos such as the inner slope and typical concentration parameters @xcite . in this paper",
    ", we investigate a particular three - point statistic , the skewness of the aperture mass , @xmath7 .",
    "when @xcite proposed the use of the aperture mass for cosmic shear measurements , they introduced the form of the statistic which has been used by almost all weak lensing studies to date .",
    "however , we find that calculations of the three - point statistic is significantly easier using the form introduced by @xcite .",
    "namely , @xmath8 where @xmath2 is the convergence , @xmath9 is the tangential component of the shear , and @xmath10 is measured from the centre of the aperture .",
    "we also note that @xcite has shown that this form of the aperture mass is more sensitive for constraining @xmath5 than other forms .",
    "there are several features of the aperture mass statistic which makes it very useful .",
    "first , it probes the power spectrum with a very narrow window function , @xmath11 . @xcite",
    "derive the relation : @xmath12 ^ 2 \\\\ w(\\eta ) & = \\frac{\\eta^4}{4 } \\exp(-\\eta^2)\\end{aligned}\\ ] ] where the tilde ( @xmath13 ) indicates the fourier transform .",
    "this window function @xmath14 for small @xmath15 , and drops super - exponentially for large @xmath15 , peaking at @xmath16 .",
    "another benefit of the aperture mass is that it has ( nearly ) finite support in real space , so it is calculable .",
    "the ideal window function would be a delta function , @xmath17 , so the statistic would directly probe @xmath18 . however , to have infinitesimal extent in k - space would require infinite extent in real space , and thus be incalculable . thus has the advantage that it is compact in real space as well .",
    "the third benefit is that it measures purely the so - called e - mode of the shear field .",
    "there is a corresponding statistic , , which measures the b - mode : @xmath19 where the cross - component of the shear , @xmath20 , is oriented at an angle of @xmath21 degrees relative to @xmath9 .",
    "then the variance of this measure , is a measure of the b - mode power in the shear field , which is generally taken to be a measure of the contamination from residual systematics , such as uncorrected effects of the point - spread functions .",
    "intrinsic alignments @xcite and source clustering @xcite can also produce b - mode signal , but the level of both of these is generall expected to be very low for scales larger than @xmath22 .",
    "the only problem with calculating these statistics directly is that real lensing surveys have regions which are masked out due to survey geometry , bright stars , bad seeing , etc .",
    "thus the aperture mass statistic runs the risk of losing azimuthal symmetry due to the masking . since the statistic depends on azimuthal symmetry for the angular integrals , a direct calculation of  and  will leak some of the e and b - mode power into the other statistic .",
    "this may only be of order a 10 per cent effect or less for typical surveys , but with the goal of precision cosmology , another method of calculation is typically used , first derived by @xcite and then refined by @xcite .",
    "they have shown that the aperture mass variance can be calculated from an integral of the correlation functions in an equation of the form : @xmath23 \\\\   \\label{mxsqresult1 } { \\mbox{$\\langle m_{\\times}^2\\rangle$}}(r ) & = \\frac{1}{2 } \\int \\frac{s ds}{r^2 } \\left [    \\xi_+(s ) t_+\\left(\\frac{s}{r}\\right ) -    \\xi_-(s ) t_-\\left(\\frac{s}{r}\\right ) \\right]\\end{aligned}\\ ] ] where @xmath24 are the two - point shear correlation functions ( defined more precisely in  [ 2ptsection ] ) and @xmath25 are known functions ( also defined in  [ 2ptsection ] ) .",
    "the third moment of the aperture mass ,  was originally suggested by @xcite as a statistic for investigating the non - gaussianity of the shear field .",
    "it is useful as a cosmological probe , since ( as these authors showed ) its dependence on @xmath5 and @xmath6 are somewhat orthogonal to that of , so the combination of the two statistics can be used to determine @xmath5 and @xmath6 separately . in particular @xmath26 scales approximately as @xmath27 , independent of @xmath6 .",
    "however , a direct measurement of  using apertures would be even more affected by masking than the variance is .",
    "thus , in this paper , we derive formulae similar to equations  ( [ mapsqresult1],[mxsqresult1 ] ) for  and   in terms of the three - point correlation function .    the signal - to - noise ( s / n ) for  is significantly lower than for . as we will show below , our total s / n for  is of order unity for the roughly @xmath28 galaxies in our ctio survey , compared to a s / n of about 7 for  @xcite .",
    "as the s / n scales as @xmath29 , we would need about @xmath30 galaxies to make a good measurement of .",
    "planned surveys such as those from the supernova anisotropy probe ( snap ) and the large - aperture synoptic survey telescope ( lsst ) will do just that .",
    "actually , the s / n also increases when one goes deeper , which both of these telescopes will do , so their s / n should be somewhat better than 10 . in any case",
    ", the large number of galaxies from these future missions demands efficient algorithms for calculating , such as the one presented herein .    in ",
    "[ 2ptsection ] , we define our notations and briefly rederive the above equations ( [ mapsqresult1],[mxsqresult1 ] ) in a manner that will lend itself to generalization to the three - point version .",
    "this is important , since we found that the derivations given by @xcite and @xcite do not generalize easily to the three - point case .",
    "the method is fairly similar to that of @xcite , although they use a tensor formulation , which is a bit unwieldy , having 64 components for the three - point correlation function ( 8 of which are unique ) . then ",
    "[ 3ptsection ] will derive the corresponding equations for the three - point statistic .",
    " [ algorithmsection ] describes our algorithm for calculating the three - point correlation function . in  [ applicationsection ]",
    ", we then apply the formulae to simulated data to check their validity , and also to our ctio survey data .",
    "we follow the notation of @xcite to describe the e and b - mode components of the shear field by defining the lensing potential , @xmath31 , to be complex . @xmath32",
    "the convergence , @xmath2 , and shear , @xmath33 , are related to the potential by @xmath34 since the convergence is the projected matter density , it is real for pure lensing fields . thus , lensing produces only e - mode fields , and the b - mode is generally used to check for residual systematics or the aforementioned effects of intrinsic alignments or sourse clustering .    with a complex @xmath2 , would give us a complex value for @xmath1 .",
    "however , using , and defining @xmath35 , we find @xmath36 where @xmath37 is the polar angle of @xmath10 .",
    "using this definition , the expectation value of @xmath38 is @xmath39    we now define the ` natural components ' of the two - point shear correlation function as : @xmath40 where @xmath41 is the polar angle of @xmath42 .    then , becomes ( taking @xmath43 , and dropping the subscript for @xmath44 ) @xmath45    to evaluate this , we treat @xmath10 and @xmath42 as complex numbers , so @xmath46 , @xmath47 , and @xmath48 .",
    "then @xmath49 \\\\ & \\equiv \\int \\frac{s ds}{r^2 } \\xi_-(s ) t_-\\left(\\frac{s}{r}\\right)\\end{aligned}\\ ] ] where @xmath50 indicates complex conjugate . (",
    "the evaluation of the integral in is straightforward in cartesian coordinates , where each complex value is represented as , for example , @xmath51 . )",
    "a similar procedure can be used to evaluate : @xmath52 \\\\ & \\equiv \\int \\frac{s ds}{r^2 } \\xi_+(s ) t_+\\left(\\frac{s}{r}\\right)\\end{aligned}\\ ] ]    finally we can convert these expressions into formulae for and  individually through the expressions : @xmath53 so , @xmath54 \\\\",
    "\\label{mxsqform } { \\mbox{$\\langle m_{\\times}^2\\rangle$}}(r ) - i{\\mbox{$\\langle m_{\\rm ap } m_{\\times}\\rangle$}}(r )   & = \\frac{1}{2 } \\int s ds     \\left [ \\xi_+(s ) t_+\\left(\\frac{s}{r}\\right ) -            \\xi_-(s ) t_-\\left(\\frac{s}{r}\\right ) \\right]\\end{aligned}\\ ] ] where @xmath55    this result agrees with that obtained from the formulae in @xcite as well as the formulae in @xcite and @xmath56 ( which correspond to our @xmath57 and @xmath58 , but for a slightly different normalization for @xmath59 ) are too low by a factor of @xmath60 . ] .",
    "also , @xcite gives a formula for a tensor form of equations  [ mapsqform ] and [ mxsqform ] , which can be expanded to agree with our results .",
    "we now follow the same procedure as in  [ 2ptsection ] for evaluating  and .",
    "@xmath61    for the ` natural components ' of the three - point correlation function , we follow @xcite and define : @xmath62 where @xmath63 .",
    "since we have three points now , they form a triangle , which is depicted in fig .",
    "the parameter @xmath64 is simply @xmath65 when the triangle is oriented such that @xmath42 is parallel to the x - axis . since the correlation functions are rotationally invariant , they are properly a function of only three real variables , such as @xmath66 , rather than four @xmath67 .",
    "@xcite give several possible definitions for @xmath68 .",
    "for our purposes , it does not much matter which definition one takes , as long as the @xmath41 s correspond to directions which rotate with the triangle .",
    "the simplest example is for all three to be equal to the polar angle of @xmath42 , simply multiply the final formula for @xmath69 by @xmath70 and @xmath71 by @xmath72 . ] .",
    "@xmath73    then , with these definitions , @xmath74 \\\\ & \\equiv \\int \\frac{s ds}{r^2 } \\int \\frac{d^2{\\bmath{t}}^\\prime}{2 \\pi r^2 }      \\gamma_0(s,{\\bmath{t}}^\\prime ) t_0\\left(\\frac{s}{r},\\frac{{\\bmath{t}}^\\prime}{r}\\right ) \\label{mmmint}\\end{aligned}\\ ] ] where @xmath75 are the vectors from each vertex to the centroid of the triangle vectors used by @xcite .",
    "their @xmath76 s are 3 times the values our @xmath76 s . ] .",
    "they are depicted graphically in fig .",
    "algebraically , @xmath77     parameters used in the formulae for @xmath69 and @xmath71 .",
    "these vectors are used as complex numbers in the formulae.,width=226 ]    likewise , @xmath78 \\\\ & \\equiv \\int \\frac{s ds}{r^2 } \\int \\frac{d^2{\\bmath{t}}^\\prime}{2 \\pi r^2 }      \\gamma_1(s,{\\bmath{t}}^\\prime ) t_1\\left(\\frac{s}{r},\\frac{{\\bmath{t}}^\\prime}{r}\\right ) \\label{mmmcint}\\end{aligned}\\ ] ]    the functions @xmath69 and @xmath71 are thus : @xmath79 where @xmath80 , @xmath65 , and the @xmath81 s are now dimensionless quantities .    as an aside",
    ", we note that integral formulations for @xmath69 and @xmath71 are possible for any aperture function @xmath82 .",
    "however , the particular form we use here is the only one for which we have been able to calculate closed forms for @xmath69 and @xmath71 . in particular",
    ", the gaussian exponential term makes the integration step from to ( [ mmmintb ] ) ( and the corresponding step for @xmath71 ) straightforward , although rather messy .",
    "[ t0t1figure ] shows the absolute value of @xmath69 and @xmath71 for equilateral triangles as a function of the triangle side length .",
    "note that the @xmath83 are significant for triangles with side lengths up to about @xmath84 , so to measure @xmath85 up to @xmath86 , one would need a survey at least about @xmath87 on a side .",
    "interestingly , this is about the same size as one needs for the corresponding measurement of @xmath88 .",
    "finally , we use the relations : @xmath89 to obtain : @xmath90    there is one further complication for using these formulae . in practice , one does not calculate @xmath91 for every @xmath92 , since this would include every triangle six times . a typical program would bin each triangle according to its shortest side , s , and its second shortest side , t , thus counting every triangle only once .    in this case , let us assume that we know @xmath91 for all @xmath80 , but for only those @xmath65 where @xmath93 . then naively , becomes @xmath94\\end{aligned}\\ ] ]    however , for each of these integrals , a change of variables transforms it into the first one .",
    "thus , we have the much simpler result : @xmath95    the case is almost the same for , except that the conjugated vertex changes in 4 of the integrals , so the net result is : @xmath96 \\label{msqmcform}\\end{aligned}\\ ] ] where @xmath97 and @xmath98 are obtained from @xmath71 by a cyclic rotation of the indices .",
    "the extension to the kurtosis of the aperture mass ( @xmath99 ) is straightforward and is given in the appendix .",
    "we consider an efficient algorithm for calculating the two - point correlation function first .",
    "this problem has been solved in a number of ways for the purposes of number count correlations for studying large - scale structure .",
    "@xcite gives a review of some techniques for that purpose .",
    "the algorithm we present below is most similar to that of @xcite .",
    "there are a few complications due to the fact that we are correlating a vector field rather than a scalar number count , but the creation and use of the cells are quite analagous .",
    "also , @xcite have recently presented a similar algorithm for the purposes of weak lensing .",
    "therefore , we present a brief description of the algorithm below in order to describe the unique features of our version of the algorithms , and we defer to these other two papers for more comprehensive descriptions of the general method .",
    "the most naive algorithm for calculating the two - point correlation function would be to take every pair of galaxies in the field and put the product of the shears into a bin corresponding to their separation .",
    "then the average value could be found for each bin .",
    "clearly , this is extremely slow for large datasets , being an @xmath100 algorithm .",
    "the corresponding three - point algorithm is even worse , @xmath101 .",
    "however , we note that the binning inherent in even this brute - force technique is effectively smoothing the correlation function by the size of the bins , since we lose all information about where _ within _ each bin the pair really belongs . if we allow ourselves to smooth again on this scale , then we can greatly speed up the algorithm .",
    "first , binning is usually done in logarithmic bins in the separation , @xmath102 , with some specified minimum and maximum scale , @xmath103 . now , suppose we have two circular regions of radii @xmath104 and @xmath105 , whose centres are separated by a distance @xmath106 . then , then the separation for any pair of galaxies taken from these two regions must fall in the range @xmath107 .",
    "if the radii are much less than @xmath102 , this becomes @xmath108 so , if our regions satisfy @xmath109 where @xmath110 is the bin size , then we can put all of them into the same bin , knowing that we will be wrong by at most one bin for any specific pair of galaxies .    in this case",
    ", we can take the average of the shear values in each region and place the product of the averages in our bin , dropping the calculation time for these galaxies from @xmath111 to @xmath112 , where @xmath113 and @xmath114 are the number of galaxies in each region .",
    "when the @xmath115 s are large , this can be a huge speedup .",
    "the specific technique for implementing this type of algorithm is to create a so - called kd - tree ( with k=2 in this case ) for the data .",
    "again , we defer to @xcite and @xcite for a more complete description of this type of data structure .",
    "in short , we bin the data in ` cells ' , keeping track of various average values for the galaxies in each cell along with its centroid and size ( maximum distance of a galaxy from the centroid ) .",
    "each cell with more than one galaxy ( and larger than @xmath116 ) also contains pointers to two sub - cells with half the number of galaxies each .",
    "when is not satisfied , we split each cell ( roughly ) in half and check the resulting pairs of regions .",
    "cell splitting continues in this manner until all pairs can be calculated directly .",
    "note that the recursion must stop at some point , since @xmath117 for two individual galaxies , so must be satisfied eventually .",
    "[ splitfigure ] shows an example of a splitting decision in the algorithm . at this point",
    "we are calculating the correlation between all the points in cell 1 with all the points in cell 2 . in the top half of the figure",
    ", @xmath118 is too large compared to @xmath106 , so we split both cells into their subcells .",
    "there are now 4 pairs of subcells to consider .",
    "the three marked by the green solid line now satisfy , and can be calculated directly . but the 1a-2a pair marked by the red dashed line needs to be split again .",
    "we tested this algorithm on a 2.4 ghz xeon processor for a square field 200 arcminutes on a side , and found the calculation time and memory usage to be factor in the memory , and possibly the time , but this factor is essentially a constant over the range of @xmath115 we tested , so we neglect it . ] : @xmath119 even for @xmath120 , which will be required for surveys like those of the supernova anisotropy probe ( snap ) and the large - aperture synoptic survey telescope ( lsst ) , this algorithm still only takes about an hour and uses less than 20 gb of memory , which we expect will be common on destop computers by the time such surveys become available .",
    "therefore , we do not foresee any need to improve upon this algorithm in the near future .",
    "for the three - point function , the triangles are parametrized by three values ( since we ignore any overall rotation or translation ) .",
    "one possible parametrization would be to use the three side lengths : @xmath121 .",
    "this is not a good choice for two reasons .",
    "first , the orientation of the points is lost - a non - isocolese triangle is not distinguished from its mirror image .",
    "second , the range of the parameters is a function of the other parameter values ( e.g. @xmath122 ) .",
    "a better choice is the following for a triangle with @xmath121 : @xmath123 where v is positive when @xmath124 are oriented counter - clockwise and negative when clockwise .",
    "( rather than the other way around ) .",
    "this is so we agree with fig .",
    "[ qfig ] with s as the smallest side , as desired for equations  [ mcbform ] and [ msqmcform ] .",
    ", width=453 ]    we bin uniformly in ln(@xmath125 ) , @xmath126 and @xmath127 with a bin size @xmath128 .",
    "now , if we have three circular regions of radii @xmath129 , whose centres make a triangle with @xmath121 ( see fig .  [ trianglefigure ] ) , we can use the average shear in each when all of the following conditions hold : @xmath130    when considering three cells for calculating the correlation function , if the sizes satisfy the above criteria , we use the average shears for each and place the product into the bin corresponding to the triangle formed by their centres .",
    "otherwise , we recurse down to the sub - cells of ( some or all of ) the cells and try again .",
    "this algorithm is far faster than the naive brute - force approach of taking every triple of galaxies which would be @xmath101 .",
    "for the same field and processor mentioned above , we find the computation time and memory usage for our implementation of this algorithm to be : @xmath131    @xcite show some empirical computation times for their algorithm as well , which are shown in their fig .",
    "although their tests were made at somewhat lower values of @xmath115 than our tests , we believe that their scaling law at the same fiducial values we quote above is likely to be similar to ours .",
    "the algorithm takes the most time dealing with triangles which are a significant fraction of the size of the field .",
    "so for very large fields , when one is only interested in the correlation on small scales , the calculation will be somewhat faster than this , as the larger triangles can be ignored",
    ".      we have discovered a way to significantly improve upon this algorithm , at least for large values of @xmath115 .",
    "however , it can require a significant amount of memory , so depending on one s computing resources and survey size , it may not always be a viable option .",
    ", is based on the scatter of these midpoints .",
    "the distance from the paircell to another cell is then the median of the corresponding triangles , @xmath132 .",
    ", width=453 ]    in this algorithm , we proceed one bin at a time in @xmath133 rather than doing all at once as we did in the above algorithm . for each bin",
    ", we find all pairs of cells with @xmath134 where @xmath135 falls in the bin in question .",
    "then , we find the midpoint @xmath136 of each pair , and create a new kd - tree for these pairs using these @xmath136 s for the positions of each pair .",
    "( see fig .",
    "[ paircellfigure ] . )",
    "then , each ` paircell ' refers to a collection of pairs . for each ,",
    "we keep track of the mean @xmath136 position , and the scatter of the @xmath136 s , which we call @xmath137 .",
    "we do nt average the data for all of the pairs in the bin , since the triangles made from these pairs and a third point can still have very different shapes depending on the orientation of the pair .",
    "but two pair with similar orientations will go into the same @xmath138 bin .",
    "therefore , within each paircell , we bin the pairs according to their orientation , using a total of 4/b bins in order to maintain our rule of being off by at most one bin in u and v.    finally we correlate the paircell data with the third points of the triangles by traversing the tree of pairs and the original tree of cells described above . for a given paircell with size @xmath137 and a normal cell with size @xmath139 , separated by a distance @xmath132 , we split one or both unless @xmath140    note that for each paircell and cell which satisfy this requirement , the various pair orientations stored in the paircell span the entire range of @xmath141 .",
    "also , if @xmath142 is not very small , we need to calculate @xmath126 separately for each orientation as well , since @xmath126 can vary by several bin sizes .",
    "but for each individual orientation , the above equation guarantees that we are only smoothing by one bin in @xmath126 or @xmath127 .",
    "when one typically has many pairs in each paircell at the point where holds , then this algorithm would be expected to be significantly faster than our previous algorithm , which effectively does each pair individually .",
    "this is usually true for the large triangles where the algorithm spends the most time , so we find that this algorithm does turn out to be significantly faster than our previous one .",
    "empirically , the calculation time and memory usage for this algorithm are found to be : @xmath143 this is a factor of 2.6 faster than the previous algorithm for our fiducial values , and the speedup increases with @xmath115 , since it scales as a smaller power of @xmath115 than our previous algorithm .",
    "however , for fields with @xmath144 , the memory demands become difficult for a desktop machine ( although still feasible with modern supercomputers ) . for the snap or lsst surveys with @xmath120 , this algorithm will require almost a terabyte of memory .",
    "this would be a lot by today s standards , but when the data from these surveys eventually become available , it will probably be quite manageable . likewise , this algorithm would take a good fraction of a year for the desktop machine described above , but in five or ten years , it will must faster . in any case",
    ", this algorithm is extrapolated to be about 20 times faster than the previous algorithm .",
    "if anyone is interested in the code for any of these algorithms or would like to use our code on a survey dataset , we would be happy to provide it for you .",
    "if interested , please send an email to mike jarvis ( mjarvis@hep.upenn.edu ) .",
    "to verify that the above equations are correct , we first apply them to a simulated shear field produced by ray tracing simulations @xcite .",
    "the simulated data uniformly cover an area @xmath145 on a side , and have no shape noise on the shear values .",
    "the particular simulation we used was for @xmath146cdm with @xmath147 , @xmath148 , @xmath149 and @xmath150 , with sources at @xmath151 .",
    "we measure @xmath7 both from the correlation functions as described above and also by measuring @xmath1 for many apertures using and then computing @xmath7 directly .",
    "this second technique is not possible on real data , due to masking effects from bright stars or complicated survey geometry , as discussed in  [ introduction ] , but for the simulated data , there is no masking , so the direct computation is possible .     and the integration technique presented in this paper for a simulated shear field with no shape noise or masking .",
    "the direct calculation is the green dashed curve , and the integration technique is the blue solid curve .",
    "the three other curves near ( and often below ) the bottom of the plot are the absolute values of the mixed and b - modes measured by the integration technique .",
    ", width=453 ]    the results from the two methods are shown in fig .  [ comparisonfigure ] .",
    "the results from the direct aperture method ( ) are the dashed green curve",
    ". the results from the integration method (  [ 3ptsection ] ) using @xmath152 are the solid blue curve .",
    "the error bars for the direct method were estimated from the distribution of @xmath153 values used to compute the average .",
    "for the integration technique , we took 12 samples of 100,000 points drawn from the gridded simulation field , and computed the error bars from the actual ` field - to - field ' variance .",
    "the sampling is needed to prevent the gridding signature of the simulation from showing up in the correlation functions and affecting the results .",
    "the two methods are seen to agree to within the error bars over most of the range , so we believe the formulae in  [ 3ptsection ] to be accurate .",
    "the largest discrepency is at scales just above @xmath154 where the direct measurement abruptly falls off .",
    "we think that this is due to there being too few apertures in the field to accurately calculate the skewness . at @xmath86 ,",
    "@xmath82 is significant out to @xmath155 , so one can only fit 5 non - overlapping apertures of this size within the @xmath145 square .",
    "we do use overlapping apertures for our calculation , since the measurements should still be nearly independent when the apertures overlap somewhat , but we believe that the relatively small number of independent apertures is likely to be the source of the discrepency .",
    "the figure also shows the mixed and b - modes measured by the integration technique : @xmath156 is the cyan dotted curve , @xmath157 is the magenta long dashed curve , and @xmath158 is the red dot - dashed curve .",
    "the plotted values are the absolute values of the measurements , and the largest of these ( @xmath157 ) is roughly two orders of magnitude below the e - mode signal .",
    "this is due to the use of @xmath152 ; using a smaller value would reduce the leakage of power from the e - mode to the others still further .",
    "we next apply the above formulae to our 75 square degree ctio ( cerro tololo interamerican observatory ) survey .",
    "a complete description of the survey data and the processing techniques used is found in @xcite .",
    "the 75 total square degrees are divided among 12 fields , each roughly 2.5 degrees square .",
    "each field has of order 150,000 usable galaxies .",
    "we have also corrected the error pointed out by @xcite in our dillution correction formula .",
    "the data presented here use their linear approximation for this correction , which they find to be significantly more accurate than our formula .    in our previous paper , we measured the @xmath4 statistic and found a clear detection of the e - mode signal , but found significant b - mode as well .",
    "we had used the aperture mass definition of @xcite rather than the one defined herein ( ) , so we present the results for this definition in fig .",
    "[ m2figure ] . the e - mode ( @xmath4 ) is shown in blue , and the b - mode ( @xmath159 ) in red .",
    "the measurements shown are spaced by approximately a factor of 2 in @xmath160 , since this is where the measurements become independent of each other.@xcite .",
    "note that the error bars are calculated from field - to - field variation , so they accurately represent both statistical and sample variance .    .",
    "the black curve is the theoretical prediction for the concordance @xmath146cdm model .",
    ", width=453 ]    our calculation of the @xmath7 statistic , as well as the mixed and b - mode statistics , are shown in fig .",
    "[ m3figure ] for the range of @xmath161 .",
    "less than @xmath22 , the b - mode contamination in the two - point measurement became large compared to the signal .",
    "and greater than @xmath155 , we do not fully trust the measurement , since this is where the integration and direct measurements differed for the simulated field described above .    with the integration technique",
    ", we can calculate a value for @xmath7 at any value of @xmath160 .",
    "however , as with the variance , we plot them spaced by a factor of 2 in @xmath160 , since this is when the points become uncorrelated .",
    "also , the error bars are again calculated from the field - to - field variation , so they inlude sample variance .",
    "we omit the error bars for the mixed and b - modes for the sake of clarity , but their size is similar to those of the e - mode errors .    ) is shown in blue , with error bars indicating the field - to - field variance of the measurement .",
    "the mixed and b - modes are the circles ( @xmath156 ) , triangles ( @xmath157 ) , and crosses ( @xmath159 ) .",
    "the black curve is the theoretical prediction for the concordance @xmath146cdm model .",
    ", width=453 ]    unfortunately , the detection is fairly marginal .",
    "the best conclusion we can draw is that @xmath7 is roughly the right order of magnitude to be consistent with a concordance @xmath146cdm model , given as the solid black curve in fig .",
    "[ m3figure ] .",
    "( we scaled the measurements from the above simulation to @xmath162 and to @xmath163 based on the theoretical scaling found by @xcite . ) however , the s / n is quite low , and the mixed and b - modes indicate that there are potentially significant systematic errors contaminating the results .",
    "thus , we do not try to use this result to constrain any cosmological models .",
    "one test we are willing to make with this data is to test whether it is consistent with zero .",
    "the statistic we use for this test is : @xmath164 over the range plotted , we find that @xmath165 .",
    "since our integration technique gives measurements essentially continuously within the range from @xmath22 to @xmath155 , we calculate p using all of these points . for the uncertainty ,",
    "we use the effective number of independent points : @xmath166 . ] , which is a detection at the @xmath167 level .",
    "the other three modes give values of 0.31 , 0.14 and -0.13 , all within @xmath168 of zero .",
    "so , we do have a mildly significant detection that the skewness is positive , but we can not make any stronger claim than that .",
    "we have presented a new calculation for the skewness of the aperture mass as an integral over the more easily measured three - point correlation function .",
    "we have also presented efficient algorithms for calculating the three - point correlation function in real data .",
    "these algorithms are believed to be faster than other published algorithms .",
    "finally , we have applied these methods to our ctio survey data , for which we do not obtain a strong detection .",
    "the signal is consistent with the concordance model prediction , but is only inconsistent with zero at the @xmath169 level .",
    "however , we expect that this method will be useful for ongoing and future surveys which are deeper and wider than ours , and will therefore be better able to detect the signal .",
    "@xcite have already used a similar technique on the virmos / descart survey , and have measured an e - mode signal which is significantly greater than the mixed and b - mode contaminations ( at least for some values of r ) .",
    "they find @xmath170 at 90 per cent confidence .",
    "there are several ongoing and proposed surveys which will substantially increase the s / n in these measurements .",
    "for example , the canada - france legacy survey ( cfls ) will cover 170 square degrees at a depth of @xmath171 .",
    "this is a similar depth to the virmos / descart survey , but covers about 20 times more area , so the s / n would be expected to increase by a factor of 4 .",
    "the cfls will observe three disjoint fields , two of 49 square degrees and one of 72 square degrees , with an estimated number of galaxies of roughly 600,000 and 900,000 respectively .",
    "thus , the total calculation time for our fastest three - point algorithm will be about 3 days and require a maximum of about 7 gb of memory on a modern desktop computer , which is quite feasible .    in fact , this would calculate the correlation function for the entire range of scales available ( up to 7 or 8 degrees ) , which is not necessary . limiting the calculation to scales less than about 200 arcmin , where the signal is strongest , speeds up the calculation significantly . in the current implementation",
    ", this would not reduce the algorithm s memory demand , but one could easily modify the algorithm to keep only a fraction of the total galaxies in memory at a time which would be useful for surveys such as this one with large contiguous fields .",
    "improvements in the reduction techniques are probably just as important as increasing the number of galaxies , since the b - mode contamination is evidence that there are still some systematic errors in the data .",
    "so far all surveys who have checked for b - modes in the data show this contamination at a significant level , although there are often scales at which the b - mode is small compared to the e - mode signal . reducing these systematic effects",
    "will probably require both better psf - removal algorithms as well as cleaner raw images .",
    "we thank ue - li pen , masahiro takada , andrew moore , andrew connolly , peter schneider , and martin kilbinger for useful discussions regarding the algorithms and results presented here .",
    "this work has been supported by grant ast-0320276 from the national science foundation , nasa grant nag5 - 10923 , and a keck foundation grant .",
    "we also thank the anonymous referee for a number of suggestions which have improved the paper .",
    "the calculation of the fourth moment of the aperture mass can likewise be made from the four - point correlation function : @xmath172 \\\\",
    "{ \\mbox{$\\langle m^2 m^{*2}\\rangle$}}(r ) & =     8 \\int \\frac{s ds}{r^2 } \\int\\limits_{s < t^\\prime<|{\\bmath{t}}^\\prime - s| } \\frac{d^2{\\bmath{t}}^\\prime}{2\\pi r^2 }     \\int\\limits_{t^\\prime < u^\\prime , t^\\prime<|{\\bmath{u}}^\\prime - s| } \\frac{d^2{\\bmath{u}}^\\prime}{2\\pi r^2 }     \\left [      \\gamma^{(4)}_5(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime )       t^{(4)}_5\\left(\\frac{s}{r},\\frac{{\\bmath{t}}^\\prime}{r},\\frac{{\\bmath{u}}^\\prime}{r}\\right ) \\right .",
    "\\nonumber\\\\ & \\qquad \\left .",
    "+ \\gamma^{(4)}_6(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime )       t^{(4)}_6\\left(\\frac{s}{r},\\frac{{\\bmath{t}}^\\prime}{r},\\frac{{\\bmath{u}}^\\prime}{r}\\right )       + \\gamma^{(4)}_7(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime )       t^{(4)}_7\\left(\\frac{s}{r},\\frac{{\\bmath{t}}^\\prime}{r},\\frac{{\\bmath{u}}^\\prime}{r}\\right ) \\right]\\end{aligned}\\ ] ]      the corresponding @xmath174 functions are : @xmath175 \\exp\\left(-\\frac{q_1 ^ 2 + q_2 ^ 2 + q_3 ^ 2 + q_4 ^ 2}{2}\\right ) \\\\",
    "t^{(4)}_{2 - 4}(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime ) & = t^{(4)}_1(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime )   ~\\text{after a cyclic rotation of indices ( 1,2,3,4 ) } \\\\",
    "t^{(4)}_5(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime ) & = \\left [ \\frac{(2{\\bmath{q}}_1^*{\\bmath{q}}_2^ * + ( { \\bmath{q}}_1^ * + { \\bmath{q}}_2^*)^2)(2{\\bmath{q}}_3^*{\\bmath{q}}_4^ * + ( { \\bmath{q}}_3^ * + { \\bmath{q}}_4^*)^2 ) -6 |{\\bmath{q}}_3 + { \\bmath{q}}_4|^2 + 3}{128 } \\right . \\nonumber\\\\ & \\qquad\\left . - \\frac{{\\bmath{q}}_1 { \\bmath{q}}_2 { \\bmath{q}}_3^ * { \\bmath{q}}_4^ * |{\\bmath{q}}_3 + { \\bmath{q}}_4|^2)}{32 }   + \\frac{{\\bmath{q}}_1 ^ 2{\\bmath{q}}_2 ^ 2{\\bmath{q}}_3^{*2}{\\bmath{q}}_4^{*2}}{64}\\right ] \\exp\\left(-\\frac{q_1 ^ 2 + q_2 ^ 2 + q_3 ^ 2 + q_4 ^ 2}{2}\\right ) \\\\ t^{(4)}_{6 - 7}(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime ) & = t^{(4)}_5(s,{\\bmath{t}}^\\prime,{\\bmath{u}}^\\prime )   ~\\text{after a cyclic rotation of indices ( 2,3,4)}\\end{aligned}\\ ] ] where the @xmath176 s are again the vectors from each vertex to the centroid : @xmath177"
  ],
  "abstract_text": [
    "<S> we present simple formulae for calculating the skewness and kurtosis of the aperture mass statistic for weak lensing surveys which is insensitive to masking effects of survey geometry or variable survey depth . </S>",
    "<S> the calculations are the higher order analogs of the formula given by @xcite which has been used to compute the variance of the aperture mass from several lensing surveys . </S>",
    "<S> as our formula requires the three - point shear correlation function , we also present an efficient tree - based algorithm for measuring it . </S>",
    "<S> we show how our algorithm would scale in computing time and memory usage for future lensing surveys . </S>",
    "<S> we also apply the procedure to our ctio survey data , originally described in @xcite . </S>",
    "<S> we find that the skewness is positive ( inconsistent with zero ) at the @xmath0 level . </S>",
    "<S> however , the signal is too noisy from this data to usefully constrain cosmology .    gravitational lensing  </S>"
  ]
}