{
  "article_text": [
    "the assumption of independence is often too strong to be realistic in many applications , especially if data are collected sequentially over time .",
    "it is then natural to expect that the current observation depends to some degree on the previous observations .",
    "this remains true for functional data and has motivated the development of appropriate functional time series models .",
    "the most popular model is the autoregressive model of bosq @xcite .",
    "this model and its various extensions are particularly useful for prediction ( see , e.g. , besse , cardot and stephenson @xcite damon and guillas @xcite , antoniadis and sapatinas @xcite ) . for many functional time series",
    "it is , however , not clear what specific model they follow , and for many statistical procedures it is not necessary to assume a specific model . in such cases , it is important to know what the effect of the dependence on a given procedure is .",
    "is it robust to temporal dependence , or does this type of dependence introduce a serious bias ? to answer questions of this type , it is essential to quantify the notion of temporal dependence . for scalar and vector time series , this question has been approached from a number of angles , but , except for the linear model of bosq @xcite , for functional time series data no general framework is available .",
    "our goal in this paper is to propose such a framework , which applies to both linear and nonlinear dependence , develop the requisite theory and apply it to selected problems in the analysis of functional time series .",
    "our examples are chosen to show that some statistical procedures for functional data are robust to temporal dependence as quantified in this paper , while other require modifications that take this dependence into account .",
    "while we focus here on a general theoretical framework , this research has been motivated by our work with functional data arising in space physics and environmental science . for such data , especially for the space physics data , no validated time series models are currently available , so to justify any inference drawn from them , they must fit into a general , one might say , nonparametric , dependence scheme .",
    "an example of space physics data is shown in figure [ fig : cmo ] .",
    "temporal dependence from day to day can be discerned , but has not been modeled .",
    "the paper is organized as follows . in section [ ss : wd ]",
    "we introduce our dependence condition and illustrate it with several examples .",
    "in particular , we show that the linear functional processes fall into our framework , and present some nonlinear models that also do .",
    "it is now recognized that the _ functional principal components _ ( fpcs ) play a far greater role than their multivariate counterparts ( yao and lee @xcite , hall and hosseini - nasab @xcite , reiss and ogden @xcite , benko , hrdle and kneip @xcite , mller and yao @xcite ) . to develop theoretical justification for procedures involving the fpcs ,",
    "it is necessary to use the convergence of the estimated fpcs to their population counterparts .",
    "results of this type are available only for independent observations ( dauxois , pousse and romain @xcite , and linear processes , bosq @xcite , bosq and blanke @xcite ) .",
    "we show in section [ ss : conv ] how the consistency of the estimators for the eigenvalues and eigenfunctions of the covariance operator extends to dependent functional data .",
    "next , in section [ s : lr ] , we turn to the estimation of an appropriately defined long - run variance matrix for functional data . for most time series procedures ,",
    "the long - run variance plays a role analogous to the variance  covariance matrix for independent observations .",
    "its estimation is therefore of fundamental importance , and has been a subject of research for many decades ( anderson @xcite , andrews @xcite and hamilton @xcite provide the background and numerous references ) . in sections [ s : change ] and",
    "[ s : flm - si ] , we illustrate the application of the results of sections [ ss : conv ] and [ s : lr ] on two problems of recent interest : change point detection for functional data and the estimation of kernel in the functional linear model .",
    "we show that the detection procedure of berkes et al .",
    "@xcite must be modified if the data exhibit dependence , but the estimation procedure of yao , m \" uller and wang @xcite is robust to mild dependence .",
    "section [ s : change ] also contains a small simulation study and a data example .",
    "the proofs are collected in the .",
    "the notion of weak dependence has , over the past decades , been formalized in many ways .",
    "perhaps the most popular are various mixing conditions ( see doukhan @xcite , bradley @xcite ) , but in recent years several other approaches have also been introduced ( see doukhan and louhichi @xcite and wu @xcite , @xcite , among others ) . in time series analysis , moment based measures of dependence , most notably autocorrelations and cumulants , have gained a universal acceptance .",
    "the measure we consider below is a moment - type quantity , but it is also related to the mixing conditions as it considers @xmath0-algebras @xmath1 time units apart , with @xmath1 tending to infinity .",
    "a most direct relaxation of independence is the @xmath1-dependence .",
    "suppose @xmath2 is a sequence of random elements taking values in a measurable space @xmath3 .",
    "denote by @xmath4 and @xmath5 the @xmath0-algebras generated by the observations up to time @xmath6 and after time @xmath6 , respectively .",
    "then the sequence @xmath2 is said to be @xmath1-dependent if for any @xmath6 , the @xmath0-algebras @xmath7 and @xmath8 are independent .",
    "most time series models are not @xmath1-dependent . rather , various measures of dependence decay sufficiently fast , as the distance @xmath1 between the @xmath0-algebras @xmath7 and @xmath9 increases .",
    "however , @xmath1-dependence can be used as a tool to study properties of many nonlinear sequences ( see , e.g. , hrmann @xcite and berkes , hrmann and schauer @xcite for recent applications ) .",
    "the general idea is to approximate @xmath10 by @xmath1-dependent processes @xmath11 , @xmath12 .",
    "the goal is to establish that for every @xmath13 the sequence @xmath14 converges in some sense to @xmath15 , if we let @xmath16 .",
    "if the convergence is fast enough , then one can obtain the limiting behavior of the original process from corresponding results for @xmath1-dependent sequences .",
    "definition [ d : siegi ] formalizes this idea and sets up the necessary framework for the construction of such @xmath1-dependent approximation sequences .",
    "the idea of approximating scalar sequences by @xmath1-dependent nonlinear moving averages appears already in section 21 of billingsley @xcite , and it was developed in several directions by ptscher and prucha @xcite . in the sequel we let @xmath17,\\mathcal{b}_{[0,1]},\\lambda)$ ] be the hilbert space of square integrable functions defined on @xmath18 $ ] .",
    "for @xmath19 we set @xmath20 .",
    "all our random elements are assumed to be defined on some common probability space @xmath21 . for @xmath22",
    "we denote by @xmath23 the space of ( classes of ) real valued random variables such that @xmath24 .",
    "further we let @xmath25 be the space of @xmath26 valued random variables @xmath27 such that @xmath28    [ d : siegi ] a sequence @xmath29 is called _",
    "@xmath30@xmath1-approximable _ if each @xmath15 admits the representation , @xmath31 where the @xmath32 are i.i.d .",
    "elements taking values in a measurable space @xmath3 , and @xmath33 is a measurable function @xmath34 .",
    "moreover we assume that if @xmath35 is an independent copy of @xmath36 defined on the same probability space , then letting @xmath37 we have @xmath38    for our applications , choosing @xmath39 will be convenient , but any @xmath22 can be used , depending on what is needed .",
    "( our definition makes even sense if @xmath40 , but then @xmath41 is no longer a norm . )",
    "definition [ d : siegi ] implies that @xmath42 is strictly stationary .",
    "it is clear from the representation of @xmath15 and @xmath43 that @xmath44 , so that condition ( [ e : ml4 ] ) could be formulated solely in terms of @xmath45 and the approximations @xmath46 .",
    "obviously the sequence @xmath47 as defined in ( [ e : appr ] ) is _ not _ @xmath1-dependent . to this end",
    "we need to define for each @xmath13 an independent copy @xmath48 of @xmath49 ( this can always be achieved by enlarging the probability space ) which is then used instead of @xmath50 to construct @xmath43 ; that is , we set @xmath51 we will call this method the _ coupling construction_. since this modification leaves condition ( [ e : ml4 ] ) unchanged , we will assume from now on that the @xmath43 are defined by ( [ e : apprc ] ) .",
    "then , for each @xmath12 , the sequences @xmath47 are strictly stationary and @xmath1-dependent , and each @xmath43 is equal in distribution to @xmath15 .",
    "the coupling construction is only one of a variety of possible @xmath1-dependent approximations . in most applications ,",
    "the measurable space @xmath3 coincides with @xmath52 , and the @xmath53 represent model errors . in this case , we can set @xmath54 the sequence @xmath55 is strictly stationary and @xmath1-dependent , but @xmath43 is no longer equal in distribution to @xmath15 .",
    "this is not a big problem but requires additional lines in the proofs .",
    "for the _ truncation construction _",
    "( [ e : trunc ] ) , condition ( [ e : ml4 ] ) is replaced by @xmath56 since @xmath57 , ( [ e : ml4 t ] ) implies ( [ e : ml4 ] ) , but not vice versa .",
    "thus the coupling construction allows to study a slightly broader class of time series .",
    "an important question that needs to be addressed at this point is how our notion of weak dependence compares to other existing ones .",
    "the closest relative of @xmath30@xmath1-approximability is the notion of @xmath30-approximability studied by ptscher and prucha @xcite for scalar and vector - valued processes .",
    "since our definition applies with an obvious modification to sequences with values in any normed vector spaces @xmath26 ( especially @xmath58 or @xmath59 ) , it can been seen as a generalization of @xmath30-approximability .",
    "there are , however , important differences . by definition ,",
    "@xmath30-approximability only allows for approximations that are , like the truncation construction , measurable with respect to a finite selection of basis vectors , @xmath60 , whereas the coupling construction does not impose this condition . on the other hand ,",
    "@xmath30-approximability is not based on independence of the innovation process .",
    "instead independence is relaxed to certain mixing conditions .",
    "clearly , @xmath1-dependence implies the clt , and so our @xmath30@xmath1-approximability implies central limit theorems for practically all important time series models .",
    "as we have shown in previous papers @xcite , a scalar version of this notion has much more potential than solely giving central limit theorems .",
    "the concept of weak dependence introduced in doukhan and louhichi @xcite is defined for scalar variables in a very general framework and has been successfully used to prove ( empirical ) fclts . like our approach , it does not require smoothness conditions .",
    "its extensions to problems of functional data analysis have not been studied yet .",
    "another approach to weak dependence is a martingale approximation , as developed in gordin @xcite and philipp and stout @xcite . in the context of sequences @xmath61 of the form ( [ e : nlma ] ) , particularly complete results have been proved by wu @xcite .",
    "again , @xmath30@xmath1-approximability can not be directly compared to approximating martingale conditions ; the latter hold for a very large class of processes , but , unlike @xmath30@xmath1-approximability , they apply only in the context of partial sums .",
    "the classical approach to weak dependence , developed in the seminal papers of rosenblatt @xcite and ibragimov @xcite , uses the strong mixing property and its variants like @xmath62 , @xmath63 , @xmath64 and @xmath65 mixing .",
    "the general idea is to measure the maximal dependence between two events lying in the `` past '' @xmath66 and in the `` future '' @xmath67 , respectively .",
    "the fading memory is described by this maximal dependence decaying to zero for @xmath1 growing to @xmath68 .",
    "for example , the @xmath69-mixing coefficient is given by @xmath70 a sequence is called @xmath69-mixing ( strong mixing ) if @xmath71 for @xmath16 .",
    "this method yields very sharp results ( for a complete account of the classical theory ( see bradley @xcite ) , but verifying mixing conditions of the above type is not easy , whereas the verification of @xmath30@xmath1-approximability is almost immediate as our examples below show .",
    "this is because the @xmath30@xmath1-approximability condition uses directly the model specification @xmath72 .",
    "another problem is that even when mixing applies ( e.g. , for markov processes ) , it typically requires strong smoothness conditions .",
    "for example , for the ar(1 ) process @xmath73 with bernoulli innovations , strong mixing fails to hold ( cf .",
    "andrews @xcite ) .",
    "since @xmath74-mixing , where @xmath74 is either of @xmath65 , @xmath63 , @xmath62 or @xmath64 , implies @xmath69-mixing , @xmath75 above satisfies none of these mixing conditions , whereas example [ ex : m - far ] shows that the ar(1 ) process is @xmath30@xmath1-approximable without requiring any smoothness properties for the innovations process .",
    "consequently our condition does not imply strong mixing . on the other hand ,",
    "@xmath30@xmath1-approximability is restricted to a more limited class of processes , namely processes allowing the representation @xmath72 .",
    "we emphasize , however , that all time series models used in practice ( scalar , vector or functional ) have this representation ( cf .",
    "@xcite ) , as an immediate consequence of their `` forward '' dynamics , for example , their definitions by a stochastic recurrence equations . see the papers of rosenblatt @xcite for sufficient criteria .",
    "we conclude that _ @xmath30@xmath1-approximability is not directly comparable with classical mixing coefficients .",
    "_    the following lemma shows how @xmath30@xmath1-approximability is unaffected by linear transformations , whereas independence assumptions are needed for product type operations .",
    "[ l : mani ] let @xmath42 and @xmath76 be two @xmath30@xmath1-approximability sequences in @xmath77 .",
    "define :    * @xmath78 , where @xmath79 ; * @xmath80 ; * @xmath81 ( point - wise multiplication ) ; * @xmath82 ; * @xmath83",
    ".    then @xmath84 and @xmath85 are @xmath30@xmath1-approximable sequences in @xmath77 .",
    "if @xmath15 and @xmath86 are independent , then @xmath87 and @xmath88 are @xmath30@xmath1-approximable sequences in the respective spaces . if @xmath89}|x_n(t)|^p+e\\sup_{t\\in[0,1]}|y_n(t)|^p<\\infty$ ]",
    ", then @xmath90 is @xmath30@xmath1-approximable in @xmath77 .",
    "the first two relations are immediate .",
    "we exemplify the rest of the simple proofs for @xmath91 . for this",
    "we set @xmath92 and note that @xmath93 and @xmath94 are ( random ) kernel operators , and thus hilbert  schmidt operators . since @xmath95 the proof follows from the independence of @xmath15 and @xmath86 .",
    "the proof shows that our assumption can be modified and independence is not required .",
    "however , if @xmath96 are not independent , then @xmath97 .",
    "we have then to use the cauchy ",
    "schwarz inequality and obviously need @xmath98 moments .",
    "we want to point out that only a straightforward modification is necessary in order to generalize the theory of this paper to noncausal processes @xmath99 our framework can be also extended to nonstationary sequences , for example , those of the form ( [ e : nlma ] ) where @xmath49 is a sequence of independent , but not necessarily identically distributed , or random variables where @xmath100 the @xmath1-dependent coupled process can be defined in the exact same way as in the stationary case @xmath101 a generalization of our method to nonstationarity would be useful , especially when the goal is to develop methodology for locally stationary data",
    ". such work is , however , beyond the intended scope of this paper .",
    "we now illustrate the applicability of definition [ d : siegi ] with several examples .",
    "let @xmath102 be the set of bounded linear operators from @xmath52 to @xmath52 .",
    "for @xmath103 we define the operator norm @xmath104 .",
    "if the operator is hilbert  schmidt , then we denote with @xmath105 its hilbert ",
    "schmidt norm .",
    "recall that for any hilbert ",
    "schmidt operator @xmath79 , @xmath106 .",
    "[ ex : m - far ] suppose @xmath107 satisfies @xmath108 .",
    "let @xmath109 be i.i.d . with mean zero .",
    "then there is a unique stationary sequence of random elements @xmath110 such that @xmath111 for details see chapter 3 of bosq @xcite .",
    "the ar(1 ) sequence ( [ e : ar1-si ] ) admits the expansion @xmath112 where @xmath113 is the @xmath114th iterate of the operator @xmath115 .",
    "we thus set @xmath116 it is easy to verify that for every @xmath117 in @xmath118 , @xmath119 since @xmath120 it follows that @xmath121 by assumption @xmath122 and therefore @xmath123 so condition ( [ e : ml4 t ] ) holds with @xmath124 , as long as @xmath125 .    the argument in the above example shows that a sufficient condition to obtain @xmath30@xmath1-approximability is @xmath126 where @xmath127 .",
    "this holds for a functional ar(1 ) process and offers an attractive sufficient and distribution - free condition for @xmath30@xmath1-approximability .",
    "the interesting question , whether one can impose some other , more general conditions on the function @xmath33 that would imply @xmath30@xmath1-approximability remains open .",
    "for example , the simple criterion above does not apply to general linear processes .",
    "we recall that a sequence @xmath128 is said to be a _ linear process in @xmath52 _ if @xmath129 where the errors @xmath130 are i.i.d . and zero mean , and each @xmath131 is a bounded operator . if @xmath132 then the series defining @xmath15 converges a.s . and in @xmath133 ( see section 7.1 of bosq @xcite ) .",
    "a direct verification , following the lines of example [ ex : m - far ] , yields sufficient conditions for a general linear process to be @xmath30@xmath1-approximable .",
    "[ p : m - lin ] suppose @xmath134 is a linear process whose errors satisfy @xmath135 , @xmath124 .",
    "the operator coefficients satisfy @xmath136 then @xmath128 is @xmath30@xmath1-approximable .",
    "we note that condition ( [ e : lpafg ] ) is comparable to the usual assumptions made in the scalar case . for a scalar linear process the weakest possible condition for weak dependence is @xmath137",
    "if it is violated , the resulting time series are referred to as strongly dependent , long memory , long - range dependent or persistent .",
    "recall that ( [ e : sm ] ) merely ensures the existence of fundamental population objects like an absolutely summable autocovariance sequence or a bounded spectral density .",
    "it is , however , too weak to establish any statistical results .",
    "for example , for the asymptotic normality of the sample autocorrelations we need @xmath138 , for the convergence of the periodogram ordinates @xmath139 .",
    "many authors assume @xmath140 to be able to use all these basic results . the condition @xmath141 is equivalent to ( [ e : lpafg ] ) .",
    "we next give a simple example of a nonlinear @xmath30@xmath1-approximable sequence .",
    "it is based on the model used by maslova et al .",
    "@xcite to simulate the so - called solar quiet ( sq ) variation in magnetometer records ( see also maslova et al .",
    "@xcite ) . in that model , @xmath142 represents the part of the magnetometer record on day @xmath13 which reflects the magnetic field generated by ionospheric winds of charged particles driven by solar heating .",
    "these winds flow in two elliptic cells , one on each day - side of the equator .",
    "their position changes from day to day , causing a different appearance of the curves , @xmath143 , with changes in the amplitude being most pronounced .",
    "to simulate this behavior , @xmath144 is introduced as the typical pattern for a specific magnetic observatory , @xmath145 , as the change in shape on day @xmath13 and the scalar random variable @xmath146 as the amplitude on day @xmath13 . with this motivation ,",
    "we formulate the following example .    [ ex : sq ] suppose @xmath147 and @xmath148 are both @xmath30@xmath1-approximable sequences , independent of each other .",
    "the respective representations are @xmath149 and @xmath150 .",
    "each of these sequences could be a linear sequence satisfying the assumptions of proposition [ p : m - lin ] , but they need not be .",
    "the sequence @xmath151 is then a nonlinear @xmath30@xmath1-approximable sequence with the underlying i.i.d .",
    "variables @xmath152 .",
    "this follows by after a slight modification from lemma [ l : mani ] .",
    "example [ ex : sq ] illustrates the principle that in order for products of @xmath30@xmath1-approximable sequences to be @xmath30@xmath1-approximable , independence must be assumed .",
    "it does not have to be assumed as directly as in example [ ex : sq ] ; the important point being that appropriately - defined functional volterra expansions should not contain diagonal terms so that moments do not pile up .",
    "such expansions exist ( see , e.g. , giraitis , kokoszka and leipus @xcite , for all nonlinear scalar processes used to model financial data ) .",
    "the model @xmath153 is similar to the popular scalar stochastic volatility model @xmath154 used to model returns @xmath155 on a speculative asset . the dependent sequence @xmath156 models volatility , and the i.i.d .",
    "errors @xmath53 , independent of the @xmath157 , generate unpredictability in returns .",
    "our next examples focus on functional extensions of popular nonlinear models , namely the bilinear model of @xcite and the celebrated arch model of engle  @xcite .",
    "both models will be treated in more detail in forthcoming papers .",
    "proofs of propositions [ p : bilinear ] and [ p : farch ] are available upon request .",
    "[ ex : bilinear ] let @xmath158 be an @xmath26-valued i.i.d . sequence and let @xmath159 and @xmath160",
    ". then the process defined as the recurrence equation , @xmath161 is called _ functional bilinear process_.    a neater notation can be achieved by defining @xmath162 , the kernel operator with the kernel function @xmath163 , and @xmath164 , the random kernel operator with kernel @xmath165 in this notation , we have @xmath166 with the usual convention that @xmath167 for operators @xmath168 .",
    "the product of two operators @xmath169 is interpreted as successive application @xmath170 .    a formal solution to ( [ e : bilinear ] )",
    "is @xmath171 and the approximating sequence is defined by @xmath172    the following proposition establishes sufficient conditions for the @xmath30@xmath1-approximability .    [",
    "p : bilinear ] let @xmath128 be the functional bilinear process defined in ( [ e : bilinear ] ) . if @xmath173 and @xmath174 , then a unique strictly stationary solution for this equation exists .",
    "the solution has ( @xmath175-)representation ( [ e : bilinearsolution ] ) . if @xmath176 and @xmath177 , the process is @xmath30@xmath1-approximable .",
    "[ ex : arch ] let @xmath178 be a positive function and let @xmath49 an i.i.d .",
    "sequence in @xmath179 .",
    "further , let @xmath180 be a nonnegative kernel function in @xmath181 ^ 2 , \\mathcal{b}_{[0,1]}^2,\\lambda^2)$ ]",
    ". then we call the process @xmath182,\\ ] ] where @xmath183 the _ functional @xmath184 process_.    proposition [ p : farch ] establishes conditions for the existence of a strictly stationary solution to ( [ e : y ] ) and ( [ e : sigma ] ) and its @xmath30@xmath1-approximability .",
    "[ p : farch ] define @xmath185 . if there is some @xmath186 such that @xmath187 then ( [ e : y ] ) and ( [ e : sigma ] ) have a unique strictly stationary and causal solution and the sequence @xmath188 is@xmath30@xmath1-approximable .",
    "denote by @xmath189,@xmath190 $ ] the covariance operator of some @xmath191 .",
    "the eigenvalues and eigenfunctions of @xmath192 are a fundamental ingredient for principal component analysis which is a key technique in functional data analysis . in practice ,",
    "@xmath192 and its eigenvalues / eigenfunctions are unknown and must be estimated .",
    "the purpose of this section is to prove consistency of the corresponding estimates for @xmath193-@xmath1-approximable sequences .",
    "the results derived below will be applied in the following sections .",
    "we start with some preliminary results .",
    "consider two compact operators @xmath194 with singular value decompositions @xmath195 the following lemma is proven in section vi.1 of ( see gohberg , golberg and kaashoek @xcite , corollary 1.6 , page 99 ) .",
    "[ l : b4.2 ] suppose @xmath194 are two compact operators with singular value decompositions ( [ e : c - k ] ) . then , for each @xmath196 , @xmath197    we now tighten the conditions on the operator @xmath192 by assuming that it is hilbert  schmidt , symmetric and positive definite .",
    "these conditions imply that @xmath198 in  ( [ e : c - k ] ) , @xmath199 and @xmath200 . consequently @xmath201 are eigenvalues of @xmath192 and @xmath202 the corresponding eigenfunctions .",
    "we also define @xmath203 using lemma [ l : b4.2 ] , the next lemma can be established by following the lines of the proof of lemma 4.3 of bosq @xcite .",
    "[ l : b4.3 ] suppose @xmath194 are two compact operators with singular value decompositions ( [ e : c - k ] )",
    ". if @xmath192 is hilbert  schmidt , symmetric and positive definite , and its eigenvalues satisfy @xmath204 then @xmath205 where @xmath206 and @xmath207    let @xmath134 be a stationary sequence with covariance operator @xmath192 . in principle",
    "we could now develop a general theory for @xmath26 valued sequences , where @xmath26 is an arbitrary separable hilbert space .",
    "in practice , however , the case @xmath208,\\mathcal { b}_{[0,1]},\\lambda)$ ] is most important . in order to be able to fully use the structure of @xmath26 and and not to deal with technical assumptions ,",
    "we need the two basic regularity conditions below , which will be assumed throughout the paper without further notice .",
    "[ a : reg ] ( i ) each @xmath15 is measurable @xmath209}\\times\\mathcal{a})/\\mathcal{b}_\\mathbb { r}$ ] .",
    "\\(ii ) @xmath210}e|x(t)|^2<\\infty$ ] .",
    "assumption [ a : reg](i ) is necessary in order that the sample paths of @xmath15 are measurable .",
    "together with ( ii ) it also implies that @xmath192 is an integral operator with kernel @xmath211 whose estimator is @xmath212 then natural estimators of the eigenvalues @xmath201 and eigenfunctions @xmath202 of @xmath192 are the eigenvalues @xmath213 and eigenfunctions @xmath214 of @xmath215 , the operator with the kernel ( [ e : estkern ] ) . by lemmas [ l : b4.2 ] and [ l : b4.3 ] we can bound the estimation errors for eigenvalues and eigenfunctions by @xmath216 .",
    "mas and mennetau @xcite show that transferring asymptotic results from the operators to the eigenelements holds quite generally , including a.s .",
    "convergence , weak convergence or large deviation principles .",
    "this motivates the next result .",
    "[ t : chatw ] suppose @xmath217 is an @xmath193@xmath1-approximable sequence with covariance operator @xmath192 . then there is some constant @xmath218 , which does not depend on @xmath219 , such that @xmath220 if the @xmath15 have zero mean , then we can choose @xmath221    the proof of theorem [ t : chatw ] is given in section [ s : p - si ]",
    ". let us note that by lemma  [ l : b4.2 ] and theorem [ t : chatw ] , @xmath222\\le ne\\|\\hat c - c\\|_{{\\mathcal l}}^2 \\le ne\\|\\hat c - c\\|_{{\\mathcal s}}^2\\le u_x.\\ ] ] assuming ( [ e : la > d ] ) , by lemma [ l : b4.3 ] and theorem [ t : chatw ] , [ @xmath223 , @xmath224\\le\\biggl(\\frac{2\\sqrt{2}}{\\alpha _",
    "j}\\biggr)^2 ne\\|\\hat c - c\\|_{{\\mathcal l}}^2 \\le\\frac{8}{\\alpha_j^2 } ne\\|\\hat c - c\\|_{{\\mathcal s}}^2 \\le\\frac{8u_x}{\\alpha_j^2}\\ ] ] with the @xmath225 defined in lemma [ l : b4.3 ] .",
    "these inequalities establish the following result .",
    "[ t : b4w ] suppose @xmath217 is an @xmath193@xmath1-approximable sequence and assumption ( [ e : la > d ] ) holds .",
    "then , for @xmath226 , @xmath227 < \\infty,\\qquad \\limsup_{n\\to\\infty } n e [ \\|\\hat c_j{\\hat v}_j -v_j\\|^2 ] < \\infty.\\ ] ]    relations ( [ e : eigen - si ] ) have become a fundamental tool for establishing asymptotic properties of procedures for functional simple random samples which are based on the functional principal components .",
    "theorem [ t : b4w ] shows that in many cases one can expect that these properties will remain the same under weak dependence ; an important example is discussed in section [ s : flm - si ] .",
    "the empirical covariance kernel ( [ e : estkern ] ) is , however , clearly designed for simple random samples , and may not be optimal for representing dependent data in the most `` useful '' way .",
    "the term `` useful '' depends on the application .",
    "kargin and onatski @xcite show that a basis different than the eigenfunctions @xmath228 is optimal for prediction with a functional ar(1 ) model .",
    "an interesting open problem is how to construct a basis optimal in some general sense for dependent data . in section [ s : lr ] we focus on a related , but different , problem of constructing a matrix which `` soaks up '' the dependence in a manner that allows the extension of many multivariate time series procedures to a functional setting .",
    "the construction of this matrix involves _",
    "arbitrary _ basis vectors @xmath228 estimated by @xmath229 in such a way that ( [ e : eigen - si ] ) holds .",
    "the main results of this section are corollary [ c : lr - f ] and proposition [ p : diffbartlett ] which state that the long - run variance matrix obtained by projecting the data on the functional principal components can be consistently estimated .",
    "the concept of the long - run variance , while fundamental in time series analysis , has not been studied for functional data , and not even for scalar approximable sequences .",
    "it is therefore necessary to start with some preliminaries which lead to our main results and illustrate the role of the @xmath30@xmath1-approximability .",
    "let @xmath42 be a scalar ( weakly ) stationary sequence .",
    "its long - run variance is defined as @xmath230 where @xmath231 , provided this series is absolutely convergent .",
    "our first lemma shows that this is the case for @xmath175@xmath1-approximable sequences .",
    "[ l : cov - sum ] suppose @xmath128 is a scalar @xmath175@xmath1-approximable sequence",
    ". then its autocovariance function @xmath232 is absolutely summable , that is , @xmath233 .",
    "observe that for @xmath234 , @xmath235 since @xmath236 the random variables @xmath237 and @xmath238 are independent , so @xmath239 , and @xmath240^{1/2 } \\bigl [ e \\bigl(x_j - x_j^{(j)}\\bigr)^2 \\bigr]^{1/2}.\\ ] ]    the summability of the autocovariances is the fundamental property of weak dependence because then @xmath241 \\to \\sum_{j=-\\infty}^\\infty\\gamma_j$ ] ; that is , the variance of the sample mean converges to zero at the rate @xmath242 , the same as for i.i.d",
    ". observations . a popular approach to the estimation of the long - run variance",
    "is to use the kernel estimator @xmath243 various weights @xmath244 have been proposed and their optimality properties studied ( see anderson @xcite and andrews @xcite , among others ) . in theoretical work , it is typically assumed that the bandwith @xmath245 is a deterministic function of the sample size such that @xmath246 and @xmath247 , for some @xmath248 .",
    "we will use the following assumption :    [ a : wq ] the bandwidth @xmath249 satisfies @xmath250 and the weights satisfy @xmath251 and @xmath252    all kernels used in practice have symmetric weights and satisfy conditions ( [ e : og - b ] ) and ( [ e : og - c ] ) .    the absolute summability of the autocovariances is not enough to establish the consistency of the kernel estimator @xmath253 .",
    "traditionally , summability of the cumulants has been assumed to control the fourth order structure of the data . denoting @xmath254 , the fourth order cumulant of a stationary sequence",
    "is defined by @xmath255 the ususal sufficient condition for the consistency of @xmath256 is @xmath257 ) can be replaced by a weaker condition , @xmath258 by analogy to condition ( [ e : gklt - cond ] ) , it can be replaced by a much stronger , but a more transparent condition , @xmath259    to explain the intuition behind conditions ( [ e : lr - ct ] ) and ( [ e : lr - cs ] ) , consider the linear process @xmath260 . for @xmath261 , @xmath262",
    "thus @xmath263 depends on @xmath264 and @xmath265 depends on @xmath266 consequently , the covariances in ( [ e : lr - cs ] ) vanish except when @xmath267 or @xmath268 , so condition ( [ e : lr - cs ] ) always holds for linear processes .    for general nonlinear sequences ,",
    "the difference @xmath269 can not be expressed only in terms of the errors ( [ e : eg0 ] ) , but the errors @xmath270 should approximately cancel , so that the difference @xmath271 is small and very weakly correlated with @xmath265 .    with this background , we now formulate the following result .",
    "[ t : lr - s ] suppose @xmath272 is an @xmath193@xmath1-approximable and assume condition ( [ e : lr - ct ] ) holds .",
    "if assumption [ a : wq ] holds , then @xmath273    theorem [ t : lr - s ] is proven in section [ s : p - si ] .",
    "the general plan of the proof is the same as that of the proof of theorem 3.1 of giraitis et al .",
    "@xcite , but the verification of the crucial relation ( [ e : lr3 ] ) uses a new approach based on @xmath193@xmath1-approximability .",
    "the arguments preceding ( [ e : lr3 ] ) show that replacing @xmath274 by @xmath254 does not change the limit .",
    "we note that the condition @xmath275 we assume is stronger than the condition @xmath276 assumed by giraitis et al .",
    "this difference is of little practical consequence , as the optimal bandwidths for the kernels used in practice are typically of the order @xmath277 .",
    "finally , we notice that by further strengthening conditions on the behavior of the bandwidth function @xmath278 , the convergence in probability in theorem [ t : lr - s ] could be replaced by the almost sure convergence , but we do not pursue this research here .",
    "the corresponding result under condition ( [ e : gklt - cond ] ) was established by berkes et al .",
    "@xcite ; it is also stated without proof as part of theorem a.1 of berkes et al .",
    "@xcite .",
    "we now turn to the vector case in which the data are of the form @xmath279^t,\\qquad n=1,2 , \\ldots , n.\\ ] ] just as in the scalar case , the estimation of the mean by the sample mean does not affect the limit of the kernel long - run variance estimators , so _ we assume that @xmath280 _ and define the autocovariances as @xmath281,\\qquad 1 \\le i , j \\le d.\\ ] ] if @xmath282 , @xmath283 is estimated by @xmath284 , but if @xmath285 , it is estimated by @xmath286 .",
    "we therefore define the autocovariance matrices @xmath287 the variance @xmath288 $ ] has @xmath289-entry @xmath290 = n^{-1 } \\sum_{|r| < n } \\biggl(1 - \\frac{|r|}{n}\\biggr)\\gamma_r(i , j),\\ ] ] so the long - run variance is @xmath291,\\ ] ] and its kernel estimator is @xmath292    the consistency of @xmath293 can be established by following the lines of the proof of theorem [ t : lr - s ] for every fixed entry of the matrix @xmath293 .",
    "conditition ( [ e : lr - ct ] ) must be replaced by @xmath294 condition ( [ e : lr - ctv ] ) is analogous to cumulant conditions for vector processes which require summability of fourth order cross - cumulants of all scalar components ( see , e.g. , andrews @xcite , assumption a , page 823 ) .    for ease of reference we state these results as a theorem .",
    "[ t : lr - v ] if @xmath295 is an @xmath175@xmath1-approximable sequence , then the series @xmath296 converges absolutely .",
    "suppose @xmath297 an @xmath193@xmath1-approximable sequence such that condition ( [ e : lr - ctv ] ) holds .",
    "if assumption [ a : wq ] holds , then @xmath298 .",
    "we are now able to turn to functional data .",
    "suppose @xmath299 is a zero mean sequence , and @xmath300 is any set of orthonormal functions in @xmath26 .",
    "define @xmath301 , @xmath302^t$ ] and @xmath303 .",
    "a direct verification shows that if @xmath42 is @xmath30@xmath1-approximable , then so is the vector sequence @xmath304 .",
    "we thus obtain the following corollary .",
    "[ c : lr - f ] if @xmath134 is an @xmath175@xmath1-approximable sequence , then the series @xmath296 converges absolutely . if , in addition , @xmath128 is @xmath193@xmath1-approximable and assumption [ a : wq ] and condition ( [ e : lr - ctv ] ) hold , then @xmath298 .    in corollary",
    "[ c : lr - f ] , the functions @xmath300 form an arbitrary orthonormal deterministic basis .",
    "in many applications , a random basis consisting of the estimated principal components @xmath305 is used .",
    "the scores with respect to this basis are defined by @xmath306 to use the results established so far , it is convenient to decompose the stationary sequence @xmath128 into its mean and a zero mean process ; that is , we set @xmath307 , where @xmath308",
    ". we introduce the unobservable quantities @xmath309 we then have the following proposition which will be useful in most statistical procedures for functional time series . an application to change point detection",
    "is developed in section [ s : change ] .",
    "[ p : diffbartlett ] let @xmath310 , with @xmath311 .",
    "suppose @xmath217 is @xmath193@xmath1-approximable and that ( [ e : la > d ] ) holds .",
    "assume further that assumption [ a : wq ] holds with a stronger condition @xmath312 .",
    "then @xmath313    the proof of proposition [ p : diffbartlett ] is delicate and is presented in section [ s : p - si ] .",
    "we note that condition ( [ e : lr - ctv ] ) does not appear in the statement of proposition [ p : diffbartlett ] .",
    "its point is that if @xmath314 is consistent under some conditions , then so is @xmath315 .",
    "functional time series are obtained from data collected sequentially over time , and it is natural to expect that conditions under which observations are made may change . if this is the case , procedures developed for stationary series will produce spurious results . in this section , we develop a procedure for the detection of a change in the mean function of a functional time series , the most important possible change .",
    "in addition to its practical relevance , the requisite theory illustrates the application of the results developed in sections  [ ss : conv ] and [ s : lr ] .",
    "the main results of this section , theorems [ t : qffclt ] and [ th : alternative ] , are proven in section [ s : pq ] .",
    "we thus consider testing the null hypothesis , @xmath316.\\ ] ] note that under @xmath317 , we do not specify the value of the common mean .    under the alternative",
    ", @xmath317 does not hold .",
    "the test we construct has a particularly good power against the alternative in which the data can be divided into several consecutive segments , and the mean is constant within each segment but changes from segment to segment .",
    "the simplest case of only two segments ( one change point ) is specified in assumption [ a : con - si ] .",
    "first we note that under the null hypothesis , we can represent each functional observation as @xmath318 the following assumption specifies conditions on @xmath319 and the errors @xmath320 needed to establish the convergence of the test statistic under @xmath317 .",
    "[ a : null - si ] the mean @xmath321 in ( [ e : xdec ] ) is in @xmath26 .",
    "the error functions @xmath322 are @xmath193@xmath1-approximable mean zero random elements such that the eigenvalues of their covariance operator satisfy ( [ e : la > d ] ) .",
    "recall that the @xmath193@xmath1-approximability implies that the @xmath323 are identically distributed with @xmath324 .",
    "in particular , their covariance function , @xmath325,\\qquad 0 \\le t , s\\le1,\\ ] ] is square integrable , that is , is in @xmath181\\times[0,1])$ ] .",
    "we develop the theory under the alternative of exactly one change point , but the procedure is applicable to multiple change points by using a segmentation algorithm described in berkes et al .",
    "@xcite and dating back at least to vostrikova @xcite .",
    "[ a : con - si ] the observations follow the model @xmath326 in which the @xmath323 satisfy assumption [ a : null - si ] , the mean functions @xmath327 and @xmath328 are in @xmath175 and @xmath329 \\qquad\\mbox{for some } 0<\\theta<1.\\ ] ]    the general idea of testing is similar to that developed in berkes et al .",
    "@xcite for independent observations , the central difficulty is in accommodating the dependence . to define the test statistic , recall that bold symbols denote @xmath330-dimensional vectors , for example , @xmath331^t$ ] . to lighten the notation , define the partial sums process , @xmath332 , @xmath333 $ ] , and the process , @xmath334 , where @xmath335 is a generic @xmath336-valued sequence .",
    "denote by @xmath337 the long - run variance of the sequence @xmath335 , and by @xmath338 its kernel estimator ( see section [ s : lr ] ) .",
    "the proposed test statistic is then @xmath339 our first theorem establishes its asymptotic null distribution .",
    "[ t : qffclt ] suppose @xmath317 and assumption [ a : null - si ] hold .",
    "if the estimator @xmath340 is consistent , then @xmath341 where @xmath342\\}$ ] , @xmath343 are independent brownian bridges .",
    "the distribution of the random variable @xmath344 was derived by kiefer @xcite .",
    "the limit distribution is the same as in the case of independent observations ; this is possible because the long - run variance estimator @xmath340 soaks up the dependence .",
    "sufficient conditions for its consistency are stated in section [ s : lr ] , and , in addition to the assumptions of theorem [ t : qffclt ] , they are : assumption [ a : wq ] with @xmath312 , and condition ( [ e : lr - ctv ] ) .",
    "the next result shows that our test has asymptotic power 1 .",
    "our proof requires the following condition : @xmath345    condition ( [ e : conalt ] ) could be replaced by weaker technical conditions , but we prefer it , as it leads to a transparent , short proof .",
    "essentially , it states that the matrix @xmath346 does not become degenerate in the limit , and the matrix @xmath347 has only positive eigenvalues .",
    "a condition like ( [ e : conalt ] ) is not needed for independent @xmath323 because that case does not require normalization with the long - run covariance matrix . to formulate our result , introduce vectors @xmath348 with coordinates @xmath349    [ th : alternative ]",
    "suppose assumption [ a : con - si ] and condition ( [ e : conalt ] ) hold .",
    "if the vectors @xmath350 and @xmath351 are not equal , then @xmath352    we conclude this section with two numerical examples which illustrate the effect of dependence on our change point detection procedure .",
    "example [ ex : simlongrun ] uses synthetic data while example [ ex : pm10 ] focuses on particulate pollution data .",
    "both show that using statistic ( [ e : test ] ) with @xmath353 being the estimate for just the covariance , not the long - run covariance matrix , leads to spurious rejections of @xmath317 , a nonexistent change point can be detected with a large probability .",
    "[ ex : simlongrun ] we simulate 200 observations of the functional ar(1 ) process of example [ ex : m - far ] , when @xmath115 has the parabolic integral kernel @xmath354 .",
    "we chose the constant @xmath355 such that @xmath356 ( the hilbert  schmidt norm ) .",
    "the innovations @xmath357 are standard brownian bridges .",
    "the first 3 principal components explain approximately 85% of the total variance , so we compute the test statistic @xmath358 given in ( [ e : test ] ) . for the estimation of the long - run covariance matrix",
    "@xmath359 we use the bartlett kernel @xmath360 we first let @xmath361 which corresponds to using just the sample covariance of @xmath362 in the normalization for the test statistic ( [ e : test ] ) ( dependence is ignored ) .",
    "we use 1000 replications and the 5% confidence level .",
    "the rejection rate is @xmath363 , much higher than the nominal level of @xmath364 .",
    "in contrast , using an appropriate estimate for the long - run variance , the reliability of the test improves dramatically . choosing an optimal bandwidth @xmath245 is a separate problem which we do not pursue here .",
    "here we adapt the formula @xmath365 , @xmath366 valid for a a scalar ar(1 ) process with the autoregressive    , nov 1 , 2008mar 31 , 2009 . ]",
    "coefficient @xmath65 ( andrews @xcite ) . using this formula with @xmath367 results in @xmath368 .",
    "this choice gives the empirical rejection rate of @xmath369 , much closer to the nominal rate of @xmath364 .",
    "[ ex : pm10 ] this example , which uses ` pm10 ` ( particulate matter with diameter @xmath370 @xmath371 , measured in @xmath372 ) data , illustrates a similar phenomenon as example [ ex : simlongrun ] . for the analysis we use ` pm10 ` concentration data measured in the austrian city of graz during the winter of 2008/2009 ( @xmath219=151 ) .",
    "the data are given in 30 minutes resolution , yielding an intraday frequency of 48 observations .",
    "as in stadtlober , hrmann and pfeiler @xcite we use a square root transformation to reduce heavy tails .",
    "next we remove possible weekly periodicity by subtracting the corresponding mean vectors obtained from the different weekdays .",
    "a time series plot of this new sequence is given in figure [ fig : pm10 ] .",
    "the data look relatively stable , although a shift appears to be possible in the center of the time series .",
    "it should be emphasized , however , that ` pm10 ` data , like many geophysical time series , exhibit a strong , persistent , positive autocorrelation structure .",
    "these series are stationary over long periods of time with an appearance of local trends or shifts at various time scales ( random self - similar or fractal structure ) .",
    "the daily measurement vectors are transformed into smooth functional data using 15 b - splines functions of order 4 .",
    "the functional principal component analysis yields that the first three principal components explain @xmath373 of the total variability , so we use statistic ( [ e : test ] ) with @xmath374 .",
    "a look at the ` acf ` and ` pacf ` of the first empirical pc scores ( figure [ fig : pm10acf ] ) suggests an ar(1 ) , maybe ar(3 ) behavior .",
    "the second and third empirical pc scores show no significant autocorrelation structure .",
    "we use the formula given in example [ ex : simlongrun ] with @xmath375 ( ` acf ` at lag 1 ) and @xmath376 and obtain @xmath377 .",
    "this gives @xmath378 which        is close to the critical value @xmath379 when testing at a @xmath380 confidence level but does not support rejection of the no - change hypothesis .",
    "in contrast , using only the sample covariance matrix in ( [ teststat ] ) gives @xmath381 and thus a clear and possibly wrongful rejection of the null hypothesis .",
    "the functional linear model is one of the most widely used tools of fda .",
    "its various forms are introduced in chapters 1217 of ramsay and silverman @xcite . to name a few recent references we mention cuevas , febrero and fraiman @xcite , malfait and ramsay  @xcite , cardot et al .",
    "@xcite , cardot , ferraty and sarda @xcite , chiou , mller and wang @xcite , mller and stadtmller @xcite , yao , m \" uller and wang @xcite , cai and hall  @xcite , chiou and mller @xcite , li and hsing @xcite , reiss and ogden @xcite , reiss and ogden .",
    "we focus on the fully functional model of the form @xmath382 in which both the regressors and the responses are functions",
    ". the results of this section can be easily specialized to the case of scalar responses .",
    "in ( [ e : fm - i ] ) , the regressors are random functions , assumed to be independent and identically distributed . as explained in section [ s : sie ] , for functional time series",
    "the assumption of the independence of the @xmath15 is often questionable , so it is important to investigate if procedures developed and theoretically justified for independent regressors can still be used if the regressors are dependent .",
    "we focus here on the estimation of the kernel @xmath383 .",
    "our result is motivated by the work of yao , m \" uller and wang @xcite who considered functional regressors and responses obtained from sparce _ independent _ data measured with error .",
    "the data that motivates our work are measurements of physical quantities obtained with negligible errors or financial transaction data obtained without error . in both cases",
    "the data are available at fine time grids , and the main concern is the presence of temporal dependence between the curves @xmath15 .",
    "we therefore merely assume that the sequence @xmath384 is @xmath193@xmath1-approximable , which , as can be easily seen , implies the @xmath193@xmath1-approximability of @xmath76 . to formulate additional technical assumptions , we need to introduce some notation .",
    "we assume that the errors @xmath53 are i.i.d . and independent of the @xmath15 , and denote by @xmath27 and @xmath385 random functions with the same distribution as @xmath15 and @xmath86 , respectively .",
    "we work with their expansions @xmath386 where the @xmath202 are the fpcs of @xmath27 and the @xmath387 the fpcs of @xmath385 , and @xmath388 indicating with the `` hat '' the corresponding empirical quantities , an estimator of @xmath383 proposed by yao , m \" uller and wang @xcite is @xmath389 where @xmath390 is an estimator of @xmath391 $ ]",
    ". we will work with the simplest estimator , @xmath392 but any estimator for which lemma [ l : consistentsigma ] holds can be used without affecting the rates .",
    "let @xmath201 and @xmath393 be the eigenvalues corresponding to @xmath202 and @xmath387 .",
    "define @xmath225 as in lemma [ l : b4.3 ] , and define @xmath394 accordingly with @xmath393 instead of @xmath201 .",
    "set @xmath395 to establish the consistency of the estimator @xmath396 we assume that @xmath397)^2}{\\lambda_\\ell^2 } < \\infty\\ ] ] and that the following assumption holds :    [ a : linreg ] ( i ) we have @xmath398 and @xmath399    \\(ii ) we have @xmath400 , @xmath401 and @xmath402    for model ( [ e : fm - i ] ) , condition ( [ e : ymw ] ) is equivalent to the assumption that @xmath383 is a hilbert ",
    "schmidt kernel , that is , @xmath403 .",
    "it is formulated in the same way as in yao , m \" uller and wang @xcite because this form is convenient in the theoretical arguments .",
    "assumption [ a : linreg ] is much shorter than the corresponding assumptions of yao , m \" uller and wang @xcite which take up over two pages .",
    "this is because we do not deal with smoothing and so can isolate the impact of the magnitude of the eigenvalues on the bandwidths @xmath404 and @xmath405 .",
    "[ t : linregdep ] suppose @xmath217 is a zero mean @xmath193@xmath1-approximable sequence independent of the sequence of i.i.d .",
    "errors @xmath357 .",
    "if ( [ e : ymw ] ) and assumption  [ a : linreg ] hold , then @xmath406 ^ 2 \\,dt\\,ds \\stackrel { p}{\\rightarrow}0,\\qquad ( n \\to\\infty).\\ ] ]    the proposition of theorem [ t : linregdep ] is comparable to the first part of theorem 1 in yao , m \" uller and wang @xcite .",
    "both theorems are established under ( [ e : ymw ] ) and finite fourth moment conditions .",
    "otherwise the settings are quite different .",
    "yao , m \" uller and wang @xcite work under the assumption that the subject @xmath407 , @xmath408 are independent and sparsely observed whereas the crucial point of our approach is that we allow dependence .",
    "thus theorems 1 and 2 in the related paper yao , m \" uller and wang @xcite , which serve as the basic ingredients for their results , can not be used here and have to be replaced directly with the theory developed in section [ ss : conv ] of this paper .",
    "furthermore , our proof goes without complicated assumptions on the resolvents of the covariance operator , in particular without the very technical assumptions ( b.5 ) of yao , m \" uller and wang @xcite . in this sense ,",
    "our short alternative proof might be of value even in the case of independent observations .",
    "we present the proofs of results stated in sections [ ss : conv][s : flm - si ] . throughout",
    "we will agree on the following conventions .",
    "all @xmath409 satisfy assumption [ a : reg ] .",
    "a  generic @xmath27 , which is assumed to be equal in distribution to @xmath45 , will be used at some places .",
    "any constants occurring will be denoted by @xmath410 the @xmath411 may change their values from proof to proof .",
    "proof of theorem [ t : chatw ] we assume for simplicity that @xmath412 and set @xmath413.\\ ] ] the proof with a general mean function @xmath414 requires some additional but similar arguments .",
    "the cauchy ",
    "schwarz inequality shows that @xmath415 and @xmath416 are hilbert ",
    "schmidt kernels , so @xmath417 is a hilbert  schmidt operator with the kernel @xmath418 .",
    "consequently , @xmath419\\bigr ) \\biggr ] \\,dt\\,ds.\\ ] ] for fixed @xmath420 and @xmath421 , set @xmath422 .",
    "$ ] due the stationarity of the sequence @xmath423 we have @xmath424 and so @xmath425 setting @xmath426 , $ ] we obtain @xmath427^{1/2 } \\bigl[\\operatorname { var}\\bigl(y_{1+r}-y_{1+r}^{(r)}\\bigr)\\bigr]^{1/2}.\\ ] ] consequently , @xmath428 is bounded from above by @xmath429\\,dt\\,ds\\\\ & & \\qquad{}+ 2 \\sum_{r=1}^\\infty { \\int\\!\\!\\int}[\\operatorname{var } ( x(t)x(s))]^{1/2 } \\\\ & & \\qquad\\hspace*{51.5pt } { } \\times\\bigl[\\operatorname{var}\\bigl(x_{1+r}(t)x_{1+r}(s)-x_{1+r}^{(r)}(t ) x_{1+r}^{(r)}(s ) \\bigr)\\bigr]^{1/2}\\,dt\\,ds.\\end{aligned}\\ ] ] for the first summand we have the upper bound @xmath430 because @xmath431\\,dt\\,ds = e \\int x^2(t)\\,dt \\int x^2(s)\\,ds = \\nu_4 ^ 4(x).\\ ] ] to find upper bounds for the summands in the infinite sum , we use the inequality @xmath432^{1/2 } \\bigl[\\operatorname{var}\\bigl(x_{1+r}(t)x_{1+r}(s)-x_{1+r}^{(r)}(t ) x_{1+r}^{(r)}(s ) \\bigr)\\bigr]^{1/2}\\,dt\\,ds\\\\ & & \\qquad\\le{\\int\\!\\!\\int}[e(x^2(t)x^2(s))]^{1/2 } \\bigl[e\\bigl ( x_{1+r}(t)x_{1+r}(s)\\\\ & & \\hspace*{153.73pt } { } -x_{1+r}^{(r)}(t ) x_{1+r}^{(r)}(s ) \\bigr)^2\\bigr]^{1/2}\\,dt\\,ds\\\\ & & \\qquad\\le\\sqrt{2}{\\int\\!\\!\\int}[e(x^2(t)x^2(s))]^{1/2 } \\bigl[ex_{1+r}^2(t)\\bigl(x_{1+r}(s)- x_{1+r}^{(r)}(s)\\bigr)^2\\bigr]^{1/2}\\,dt\\,ds\\\\ & & \\qquad\\quad { } + \\sqrt{2}{\\int\\!\\!\\int}[e(x^2(t)x^2(s))]^{1/2}\\\\ & & \\hspace*{77.3pt}{}\\times \\bigl[ex_{1+r}^{(r)2}(s)\\bigl(x_{1+r}(t ) -x_{1+r}^{(r)}(t)\\bigr)^2\\bigr]^{1/2}\\,dt\\,ds.\\end{aligned}\\ ] ]    for the first term , using the cauchy ",
    "schwarz inequality and ( [ e : si1 ] ) , we obtain @xmath433^{1/2 } \\bigl[ex_{1+r}^2(t)\\bigl(x_{1+r}(s)- x_{1+r}^{(r)}(s)\\bigr)^2\\bigr]^{1/2}\\,dt\\,ds\\\\ & & \\qquad \\le\\nu_4 ^ 2(x ) \\biggl\\ { e \\biggl[\\int x_{1+r}^2(t ) \\,dt",
    "\\int\\bigl(x_{1+r}(s)- x_{1+r}^{(r)}(s)\\bigr)^2 \\,ds \\biggr ] \\biggr\\}^{1/2}\\\\ & & \\qquad \\le\\nu_4 ^ 2(x ) \\ { e\\|x_{1+r}\\|^4\\}^{1/4 } \\bigl\\ { e \\bigl\\|x_{1+r}(s)- x_{1+r}^{(r)}(s)\\bigr\\| \\bigr\\}^{1/4}\\\\ & & \\qquad = \\nu_4 ^ 3(x ) \\nu_4 \\bigl(x_{1}- x_{1}^{(r)}\\bigr).\\end{aligned}\\ ] ] the exact same argument applies for the second term .",
    "the above bounds imply ( [ e : s2 ] ) .",
    "proof of theorem [ t : lr - s ] as in giraitis et al .",
    "@xcite , set @xmath434 and @xmath435 observe that @xmath436 we therefore have the decomposition @xmath437 the proof will be complete once we have shown that @xmath438 and @xmath439    we begin with the verification of the easier relation ( [ e : lr2 ] ) . by ( [ e : og - b ] ) , @xmath440^{1/2 } \\sum_{|j| \\le q } \\bigl [ e\\bigl ( s_{1 , n-|j| } + s_{|j|+1 , n } \\bigr)^2\\bigr]^{1/2}.\\end{aligned}\\ ] ] by lemma [ l : cov - sum ] , @xmath441 similarly @xmath442 therefore ,",
    "@xmath443    we now turn to the verification of ( [ e : lr1 ] ) .",
    "we will show that @xmath444 and @xmath445\\to0 $ ] .    by ( [ e : og - c ] ) ,",
    "@xmath446    by ( [ e : og - b ] ) , it remains to show that @xmath447 to lighten the notation , without any loss of generality , _ we assume from now on that @xmath448 _ , so that @xmath449 therefore , by stationarity , @xmath450 the last sum can be split into three terms corresponding to @xmath451 , @xmath285 and @xmath452 .",
    "the contribution to the left - hand side of ( [ e : lr3 ] ) of the term corresponding to @xmath451 is @xmath453 the terms corresponding to @xmath285 and @xmath452 are handled in the same way , so we focus on the contribution of the summands with @xmath452 which is @xmath454 we now use the decompositions @xmath455 and @xmath456 by definition [ d : siegi ] , @xmath237 depends on @xmath457 while the random variables @xmath458 and @xmath459 depend on @xmath460 and errors independent of the @xmath32 .",
    "therefore @xmath461 is equal to @xmath462 - e \\bigl [ x_0 x_{|k| } \\bigr ] e \\bigl [ x_r^{(r ) } x_{r+|\\ell|}^{(r+|\\ell| ) } \\bigr]\\\\ & & \\qquad = e [ x_0 ] e\\bigl [ x_{|k|}^{(|k| ) } x_r^{(r ) } x_{r+|\\ell|}^{(r+|\\ell    - e [ x_0 ] e \\bigl [ x_{|k|}^{(|k| ) } \\bigr ] \\bigl [ x_r^{(r ) } x_{r+|\\ell|}^{(r+|\\ell| ) } \\bigr]= 0.\\end{aligned}\\ ] ] we thus obtain @xmath463    by assumption ( [ e : lr - ct ] ) , it remains to verify that @xmath464 this is done using the technique introduced in the proof of theorem [ t : chatw ] .",
    "by the cauchy ",
    "schwarz inequality , the problem reduces to showing that @xmath465 \\bigr\\}^{1/2 } \\bigl\\ { e \\bigl [ \\bigl ( x_r x_{r+|\\ell| } - x_r^{(r ) } x_{r+|\\ell|}^{(r+|\\ell|)}\\bigr)^2 \\bigr]\\bigr\\}^{1/2 } \\to0.\\ ] ] using ( [ e : abcd ] ) , this in turn is bounded by constant times @xmath466 ^ 4 \\bigr\\}^{1/4},\\ ] ] which tends to zero by @xmath193@xmath1-approximability and the condition @xmath275 .",
    "proof of proposition [ p : diffbartlett ] we only show the first part , the second is similar . let @xmath467 be the bartlett estimates satisfying assumption [ a : wq ]",
    ". without loss of generality we will assume below that the constant @xmath468 in ( [ e : og - b ] ) is 1 .",
    "then the element in the @xmath6th row and @xmath469th column of @xmath470 is @xmath471 for reasons of symmetry it is enough to estimate @xmath472 .",
    "we have for any @xmath473 @xmath474 by the markov inequality and the fact that the @xmath475 , @xmath476 , are identically distributed , we get for all @xmath477 @xmath478 which tends to zero as long as @xmath479 .    the estimation of @xmath480 requires a little bit more effort .",
    "we notice first that @xmath481 the summability of the latter series follows by now routine estimates from ( [ e : ml4 ] ) . for any @xmath482",
    "we have @xmath483 if we require that @xmath484 , then by the markov inequality and ( [ e : vars2 ] ) we have @xmath485 for some constant @xmath486 which does not depend on @xmath219 . by theorem [ t : b4w ] and again the markov inequality there exists a constant @xmath487 such that for all @xmath488 @xmath489 the @xmath490 in the term @xmath480 is given by @xmath491 set @xmath492 . then for all @xmath488 @xmath493 letting @xmath494 shows that under @xmath312 the term @xmath495 .",
    "this finishes the proof of proposition [ p : diffbartlett ] .",
    "the proof of theorem [ t : qffclt ] relies on theorem a.1 of aue et al .",
    "@xcite , which we state here for ease of reference .",
    "[ t : aa1 ] suppose @xmath496 is a @xmath330-dimensional @xmath175@xmath1-approximable mean zero sequence .",
    "then @xmath497 where @xmath498 \\}$ ] is a mean zero gaussian process with covariances , @xmath499 the convergence in ( [ e : aa1 ] ) is in the @xmath330-dimensional skorokhod space @xmath500)$ ] .",
    "proof of theorem [ t : qffclt ] let @xmath501 we notice that replacing the @xmath502 with @xmath503 does not change the test statistic in ( [ e : test ] ) .",
    "furthermore , since by the second part of proposition [ p : diffbartlett ] @xmath504 , it is enough to study the limiting behavior of the sequence @xmath505 .",
    "this is done by first deriving the asymptotics of @xmath506 and then analyzing the effect of replacing @xmath507 with @xmath508 .",
    "let @xmath509 be the @xmath1-dependent approximations for @xmath510 which are obtained by replacing @xmath511 in ( [ e : beta ] ) by @xmath512 .",
    "for a vector @xmath513 in @xmath514 we let @xmath515 be its euclidian norm . then",
    "@xmath516 since by lyapunov s inequality we have @xmath517 , ( [ e : ml4 ] ) yields that @xmath518 .",
    "thus theorem [ t : aa1 ] implies that @xmath519}{\\longrightarrow } \\mathbf{w}(\\bolds\\beta)(x).\\ ] ] the coordinatewise absolute convergence of the series @xmath520 follows from part ( a ) of theorem [ t : lr - v ] . by assumption",
    "the estimator @xmath521 is consistent , and consequently @xmath522}{\\longrightarrow}\\sum _ { \\ell=1}^d \\int b_\\ell^2(x)\\,dx\\ ] ] follows from the continuous mapping theorem .",
    "we turn now to the effect of changing @xmath506 to @xmath505 . due to the quadratic structure of @xmath523 , we have @xmath524 when @xmath525 .",
    "to finish the proof it is thus sufficient to show that @xmath526}\\frac{1}{\\sqrt{n } }    { \\bolds\\beta})|=o_p(1)\\ ] ] and @xmath527 relation ( [ diff2 ] ) follows from proposition [ p : diffbartlett ] . to show ( [ diff1 ] )",
    "we observe that by the cauchy ",
    "schwarz inequality and theorem [ t : b4w ] @xmath528}\\frac{1}{n }    { \\bolds\\beta})|^2\\\\ & & \\qquad = \\sup_{x\\in[0,1]}\\frac{1}{n } \\sum_{\\ell=1}^d \\biggl|\\int \\sum_{n=1}^{\\lfloor nx\\rfloor } y_n(t)\\bigl(v_\\ell(t)-{\\hat c}_\\ell{\\hat v}_\\ell(t)\\bigr)\\,dt \\biggr|^2\\\\ & & \\qquad \\leq\\frac{1}{n}\\sup_{x\\in[0,1]}\\int\\biggl ( \\sum_{n=1}^{\\lfloor nx\\rfloor } y_n(t ) \\biggr)^2 \\,dt\\times\\sum_{\\ell=1}^d\\int \\bigl(v_\\ell(t)-{\\hat c}_\\ell{\\hat v}_\\ell(t)\\bigr)^2\\,dt\\\\ & & \\qquad \\leq\\frac{1}{n}\\int\\max_{1\\leq k\\leq n } \\biggl",
    "( \\sum_{n=1}^{k } y_n(t ) \\biggr)^2 \\,dt\\times o_p(n^{-1}).\\end{aligned}\\ ] ] define @xmath529 then by similar arguments as in section [ s : p - si ] we have @xmath530 hence by menshov s inequality ( see , e.g. , billingsley @xcite , section 10 ) we infer that @xmath531 notice that ( [ e : ml4 ] ) implies @xmath532 .",
    "in turn we obtain that @xmath533 which proves ( [ diff1 ] ) .",
    "proof of theorem [ th : alternative ] notice that if the mean function changes from @xmath534 to @xmath535 at time @xmath536 , then @xmath537 can be written as @xmath538 , & \\quad if $ x\\leq\\theta$;\\cr \\theta(1-x)[\\hat{\\bolds\\mu}_1-\\hat{\\bolds\\mu}_2 ] , & \\quad if $ x > \\theta$ , } \\ ] ] where @xmath539^t\\ ] ] and @xmath540 is defined analogously .",
    "it follows from ( [ e : cpsn ] ) that @xmath541 can be expressed as the sum of three terms : @xmath542 where @xmath543^t \\hat{\\bolds\\sigma}(\\hat{\\bolds\\eta})^{-1}[\\hat{\\bolds \\mu } _",
    "1-\\hat{\\bolds\\mu}_2 ] ; \\\\",
    "t_{3,n}(d ) & = & \\int_0 ^ 1 g(x , \\theta ) \\mathbf{l}_n(x,\\bolds{\\hat\\beta})^t \\hat{\\bolds\\sigma}(\\hat{\\bolds\\eta})^{-1}[\\hat{\\bolds \\mu } _ 1-\\hat{\\bolds\\mu}_2]\\,dx,\\end{aligned}\\ ] ] with @xmath544    since @xmath347 in ( [ e : conalt ] ) is positive definite ( p.d . )",
    ", @xmath346 is almost surely p.d . for large enough @xmath219 ( @xmath219 is random ) .",
    "hence for large enough @xmath219 the term @xmath545 is nonnegative .",
    "we will show that @xmath546 , for a positive constant @xmath486 , and @xmath547 . to this end",
    "we notice the following .",
    "ultimately all eigenvalues of @xmath548 are positive .",
    "let @xmath549 and @xmath550 denote the largest , respectively , the smallest eigenvalue .",
    "by lemma [ l : b4.2 ] , @xmath551 a.s . and @xmath552 a.s . , where @xmath553 and @xmath554 are the largest and smallest eigenvalue of @xmath347 .",
    "next we claim that @xmath555 to obtain this , we use the relation @xmath556 which can be proven similarly as lemma a.1 of berkes et al .",
    "@xcite , but the law of large numbers in a hilbert space must be replaced by the ergodic theorem .",
    "the ergodicity of @xmath557 follows from the representation @xmath558 .",
    "notice that because of the presence of a change point it can not be claimed that @xmath559 .",
    "it follows that if @xmath219 is large enough , then @xmath560^t\\hat{\\bolds\\sigma } ( \\hat{\\bolds\\eta})^{-1}[\\hat{\\bolds\\mu}_1-\\hat{\\bolds\\mu } _ 2]>\\frac{1}{2\\lambda^ * }    ^*}|\\bolds\\mu_1-\\bolds\\mu_2|^2 + o_p(1).\\ ] ]    to verify @xmath547 , observe that @xmath561 } } |\\mathbf{l}_n(x,\\bolds{\\hat\\beta})^t \\hat{\\bolds\\sigma}(\\hat{\\bolds\\eta})^{-1}[\\hat{\\bolds \\mu } _ 1-\\hat{\\bolds\\mu}_2 ] |\\\\ & & \\qquad \\leq{\\sup_{x\\in[0,1]}}|\\mathbf{l}_n(x,\\bolds{\\hat\\beta } ) | \\times     & & \\qquad = o_p(n ) |\\bolds\\mu_1-\\bolds\\mu_2|.\\end{aligned}\\ ] ] we used the matrix norm @xmath562 and @xmath563 .",
    "we first establish a technical bound which implies the consistency of the estimator @xmath390 given in ( [ e : hat - sigma - lk ] ) .",
    "let @xmath564 and @xmath565 .",
    "[ l : consistentsigma ] under the assumptions of theorem [ t : linregdep ] we have @xmath566 where @xmath486 is a constant independent of @xmath6 and @xmath469 .",
    "it follow from elementary inequalities that @xmath567 where @xmath568 \\bigr ) \\biggr)u_k(s)v_\\ell(t)\\,dt\\,ds;\\\\ t_2&=&\\frac{1}{n}\\sum_{i=1}^n{\\int\\!\\!\\int}e[x_i(s)y_i(t ) ] [ u_k(t)v_\\ell(s)-\\hat{d}_k\\hat{u}_k(t ) \\hat{c}_\\ell\\hat{v}_\\ell(s ) ] \\,dt\\,ds.\\end{aligned}\\ ] ] by the cauchy ",
    "schwarz inequality and ( [ e : abcd ] ) we obtain @xmath569 \\biggr)^2\\,dt\\,ds;\\\\ t_2 ^ 2 & = & 2\\nu_2 ^ 2(x)\\nu_2 ^ 2(y ) ( \\|u_k-\\hat{d}_k\\hat{u}_k\\|^2+\\| v_\\ell-\\hat{c}_\\ell\\hat{v}_\\ell\\|^2 ) .\\end{aligned}\\ ] ] hence by similar arguments as we used for the proof of theorem [ t : chatw ] we get @xmath570 . the proof follows now immediately from lemma [ l : b4.3 ] and theorem [ t : chatw ] .",
    "now we are ready to verify ( [ e : ymw - con ] ) .",
    "we have @xmath571 the orthogonality of the sequences @xmath572 and @xmath573 and ( [ e : ymw ] ) imply that @xmath574 therefore , letting @xmath575 ( [ e : ymw - con ] ) will follow once we show that @xmath576 ^ 2\\,dt\\,ds\\stackrel{p}{\\rightarrow } 0\\qquad ( n\\to\\infty).\\ ] ] notice that by the cauchy ",
    "schwarz inequality the latter relation is implied by @xmath577 ^ 2\\,dt\\,ds \\stackrel{p}{\\rightarrow}0\\nonumber\\\\[-8pt]\\\\[-8pt ] \\eqntext{(n\\to\\infty).}\\end{aligned}\\ ] ] a repeated application of ( [ e : abcd ] ) and some basic algebra yield @xmath578 ^ 2\\\\ & & \\qquad \\leq \\lambda_\\ell^{-2}|\\sigma_{\\ell k}-",
    "\\hat{c}_\\ell \\hat{d}_k \\hat\\sigma_{\\ell k}|^2\\hat { u}_k^2(t)\\hat{v}_\\ell^2(s ) + \\hat\\sigma_{\\ell k}^2 |\\lambda_\\ell^{-1}-\\hat\\lambda_\\ell ^{-1 } |^2 \\hat{u}_k^2(t)\\hat{v}_\\ell^2(s)\\\\ & & \\qquad\\quad { } + \\sigma_{\\ell k}^2\\lambda_\\ell^{-2 }    + \\sigma_{\\ell k}^2\\lambda_\\ell^{-2 } |v_\\ell(s)-\\hat{c}_\\ell \\hat{v}_\\ell(s ) |^2 \\hat{u}_k^2(t).\\end{aligned}\\ ] ] hence @xmath579 ^ 2\\,dt\\,ds\\\\ & & \\qquad \\leq \\lambda_\\ell^{-2}|\\sigma_{\\ell",
    "k}- \\hat{c}_\\ell \\hat{d}_k \\hat\\sigma_{\\ell k}|^2 + \\hat\\sigma_{\\ell k}^2 |\\lambda_\\ell^{-1}-\\hat\\lambda_\\ell ^{-1 } |^2 \\\\ & & \\qquad\\quad { } + \\sigma_{\\ell k}^2\\lambda_\\ell^{-2 } ( \\|u_k-\\hat{d}_k\\hat{u}_k\\|^2 + \\|v_\\ell-\\hat{c}_\\ell\\hat{v}_\\ell\\|^2 ) .\\end{aligned}\\ ] ] thus in order to get ( [ e : toshow ] ) we will show that @xmath580 we start with ( [ e : ts1 ] ) . by lemma [ l : consistentsigma ] and assumption [ a : linreg ]",
    "we have @xmath581    next we prove relation ( [ e : ts2 ] ) . in order to shorten the proof we replace @xmath390 by @xmath582 .",
    "otherwise we would need a further intermediate step , requiring similar arguments which follow .",
    "now for any @xmath583 we have @xmath584 \\\\ & & \\qquad\\leq \\kappa_2 \\biggl(\\frac{kl^2}{\\epsilon n\\lambda_l}+\\frac { 1}{\\varepsilon n\\lambda_l^2 } \\biggr),\\end{aligned}\\ ] ] by an application of the markov inequality and theorem [ t : b4w ] . according to our assumption [ a : linreg ]",
    "this also goes to zero for @xmath585",
    ".    finally we prove ( [ e : ts3 ] ) . by lemma [ l : b4.3 ] and",
    "theorem [ t : chatw ] we infer that @xmath586 assumption [ a : linreg](ii ) assures that the last term goes to zero .",
    "the proof is now complete .",
    "we thank p. hall , h .- g .",
    "mller , d. paul and j .- l .",
    "wang for their useful comments .",
    "we are grateful to two referees for raising a number of points which helped us clarify several important issues . finally , we thank the associate editor for constructive criticism and clear guidelines .",
    "maslova , i. , kokoszka , p. , sojka , j. and zhu , l. ( 2009 ) .",
    "estimation of sq variation by means of multiresolution and principal component analyses . _ journal of atmospheric and solar - terrestrial physics_. to appear ."
  ],
  "abstract_text": [
    "<S> functional data often arise from measurements on fine time grids and are obtained by separating an almost continuous time record into natural consecutive intervals , for example , days . </S>",
    "<S> the functions thus obtained form a functional time series , and the central issue in the analysis of such data consists in taking into account the temporal dependence of these functional observations . </S>",
    "<S> examples include daily curves of financial transaction data and daily patterns of geophysical and environmental data . for scalar and vector valued stochastic processes , </S>",
    "<S> a large number of dependence notions have been proposed , mostly involving mixing type distances between @xmath0-algebras . in time </S>",
    "<S> series analysis , measures of dependence based on moments have proven most useful ( autocovariances and cumulants ) . </S>",
    "<S> we introduce a moment - based notion of dependence for functional time series which involves @xmath1-dependence . </S>",
    "<S> we show that it is applicable to linear as well as nonlinear functional time series . </S>",
    "<S> then we investigate the impact of dependence thus quantified on several important statistical procedures for functional data . </S>",
    "<S> we study the estimation of the functional principal components , the long - run covariance matrix , change point detection and the functional linear model . </S>",
    "<S> we explain when temporal dependence affects the results obtained for i.i.d . functional observations and when these results are robust to weak dependence .    and    .    </S>"
  ]
}