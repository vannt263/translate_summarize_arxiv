{
  "article_text": [
    "linear programming ( lp ) @xcite is a mathematical modelling technique designed to optimize a linear function ( objective function ) of non - negative continuous variables ( decision variables ) , while satisfying a system of linear equations or inequalities ( constraints ) .",
    "a lp model that restricts some of the variables so that these take only non - negative integer values is known as milp .",
    "when all variables are integer - constrained , we have a pilp model .",
    "we will use the term ilp to refer to any of the two types of problems mentioned above .",
    "many practical situations can be modelled as lp problems where decision variables must take on integer values .",
    "generating good timetables , determining optimal schedules for jobs which are to be processed in a production line , designing efficient communication networks , container loading , determining efficient vehicle routes , and various problems arising in computational biology are a few examples .    from a practical point of view , most of the examples mentioned above are extremely difficult to solve . in theoretical computer science , this is captured by the fact that many ilp problems are classified as np - hard @xcite problems .",
    "thus , because of the inherent difficulty and the enormous practical importance of np - hard ilp problems , a large number of techniques have been proposed to solve them .",
    "the available techniques can roughly be classified into two main categories : _ exact _ and _ heuristic _ algorithms .",
    "exact algorithms are guaranteed to find an optimal solution and to prove its optimality for every instance of an ilp problem .",
    "the run - time , however , often increases dramatically with the problem instance s size , and often only small or moderately - sized instances can be practically solved to proven optimality . for larger instances ,",
    "the only possibility is usually to turn to heuristic algorithms that trade optimality for run - time , i.e. , they are designed to obtain good but not necessarily optimal solutions in a reasonable amount of time .",
    "the aim of this paper is to propose  to the best of our knowledge  a new exact algorithm for solving pilp problems .",
    "the algorithm will be called psa-_pilp _ , and the idea behind it is to decompose the initial pilp problem into simpler one - dimensional subproblems , and then to use that information to generate a finite number of candidate solutions tailored to each of the possible optimal objective values of the problem .",
    "the optimal solution is then found by examining the set of candidate solutions arising from the previous analysis .",
    "the second part of this series is intended to extend this methodology to the class of milp formulations .",
    "the remainder of this paper is organized as follows . in the next section ,",
    "we give a short overview of ilp techniques and introduce some notation . in section  [ sec:3 ] ,",
    "we present the basic concepts involving the psa-_pilp _ algorithm and account for the main steps of the method through the solution of a simple example .",
    "section  [ sec:4 ] is devoted to present the scheme of the psa-_pilp _ algorithm and to prove its convergence .",
    "computational results on instances of the 0 - 1mkp are reported in section  [ sec:5 ] .",
    "finally , section  [ sec:6 ] summarizes the main achievements of the proposed approach and outlines some interesting directions for future research .",
    "this section gives a short overview of the main concepts in integer programming .",
    "for an in - depth coverage of the subject we refer to the books on linear optimization by chvtal @xcite , and on combinatorial and integer optimization by wolsey @xcite and nemhauser and wolsey @xcite .",
    "lp is a class of optimization problems that involves non - negative continuous variables , an objective function linearly depending on the variables , and a set of constraints expressed as linear inequalities .",
    "we consider the form @xmath0 where @xmath1 , @xmath2 , @xmath3 and @xmath4 are data .",
    "a _ feasible solution _ to ( [ def : lp ] ) is a vector @xmath5 satisfying the condition @xmath6 .",
    "the aim of this problem is to find a feasible solution that maximizes the objective function @xmath7 .    as mentioned before , if we restrict some of the variables of a lp problem to take on integer values we obtain an ilp problem .",
    "we consider the form @xmath8 where @xmath9 , @xmath10 , @xmath11 and @xmath12 are defined as in ( [ def : lp ] ) . without loss of generality , we assume that the variables indexed @xmath13 through  @xmath14 , @xmath15 , are the integer - constrained variables ( the integer variables ) , and the variables indexed @xmath16 through @xmath17 are called the continuous variables .    throughout this work it will be assumed for simplicity that the feasible regions of ( [ def : lp ] ) and ( [ def : ilp ] ) are bounded .",
    "in addition , we will denote by @xmath18 ( resp .",
    "@xmath19 ) the optimal objective value of the problem , and by @xmath20 the codomain of @xmath7 for the problem under consideration . finally , let us note that , in the context of pilp problems , the assumption made about the objective function ( we do not loss generality ) automatically implies that @xmath21",
    ". the utility of this observation will become clear in section  [ sec:3 ] .",
    "one of the most important concepts in ilp are _ relaxations _ , where some or all constraints of a problem are loosened or omitted .",
    "relaxations are mostly used to obtain related , simpler problems which can be solved efficiently yielding bounds for the original problem .",
    "the _ linear programming relaxation _ of the ilp problem ( [ def : ilp ] ) is obtained by relaxing the integrality constraint , i.e. , replacing @xmath22 with @xmath5 , yielding the lp problem ( [ def : lp ] ) .",
    "large instances of such lp problems can be efficiently solved in practice by using simplex - based algorithms @xcite , interior - point methods @xcite or column generation approaches @xcite .",
    "as the feasible points of an ilp problem form a subset of the feasible points of its lp - relaxation , the optimal value of the lp - relaxation provides an upper bound on the optimal value of the original ilp problem .",
    "therefore , if an optimal solution to the lp - relaxation satisfies the integrality restrictions , then that solution is also optimal for the ilp problem .",
    "when considering exact approaches , the following methods have had significant success . see e.g. @xcite for a general introduction to these mathematical programming techniques .      when modelling integer optimization problems as ilp problems , an important goal is to find a strong formulation , for which the lp - relaxation provides a solution which lies in general not too far away from the integer optimum .",
    "for many such problems it is possible to strengthen an existing ilp formulation significantly by including further inequalities , preferably , facets of the convex hull of feasible solutions .",
    "the general cutting plane approach relaxes initially the integrality restrictions of the original ilp problem and solves the resulting linear program . in case",
    "the resulting lp solution satisfies the integer requirements , this is the solution to the integer program ; otherwise , the lp - relaxation can be tightened by adding an extra constraint which is satisfied by all feasible integral solutions but is violated by the current lp optimal solution .",
    "such a constraint is called a _ cut _ or _ cutting plane_. the new lp - relaxation is then resolved , and the procedure can be repeated until an optimal solution is reached .",
    "the subproblem of identifying cuts is called _ separation problem _ , and it is of crucial importance to solve it efficiently , since many instances of it must usually be solved until the cutting plane approach terminates successfully .",
    "= = = = = = +    ' '' ''     + * algorithm 1 * the generic ` cutting - plane ` algorithm +    ' '' ''     + * input : * @xmath23 + * repeat * + solve the lp - relaxation of * ilp*. let @xmath24 be an optimal solution . + @xmath24 satisfies the integrality requirements * then * + an optimal solution to * ilp * has been found . * stop*. +   + solve the separation problem , that is , try to find a valid inequality @xmath25 such that @xmath26 .",
    "+ such an inequality @xmath25 cutting off @xmath24 was found * then * + add the inequality to the system .",
    "+   + no optimal solution to * ilp * was found . * stop*. +   +   + * until * forever    ' '' ''    in practice",
    ", it may take a long time for such a cutting plane approach to converge to the optimum , partly because it is often a hard subproblem to separate effective cuts .",
    "a further drawback of this technique is that no feasible integer solutions can be obtained until the optimal integer solution is reached , which implies that there is no feasible integer solution if the computations are stopped prematurely .",
    "the cutting plane method is therefore often combined with other methods , as we will see below .",
    "the basic structure of branch - and - bound is an _",
    "enumeration tree_. the _ root _ node of the tree corresponds to the original problem . as the algorithm progresses , the tree grows by a process called _ branching _ , which creates two or more child nodes of the parent node .",
    "each of the problems at the child nodes is formed by adding constraints to the problem at the parent node .",
    "typically , the new constraint is obtained by simply adding a bound on a single integer variable , where one child gets an upper bound of some integer @xmath27 , and the other child gets a lower bound of @xmath28 .",
    "an essential requirement is that each feasible solution to the parent node problem is feasible to at least one of the child node problems .",
    "let @xmath29 be the original ilp problem and let @xmath30 be the problem at node @xmath31 .",
    "the objective value of any feasible solution to @xmath30 provides a lower bound on the global optimal value .",
    "the feasible solution with the highest objective value found so far is called the _ incumbent _ solution and its objective value is denoted by @xmath32 .",
    "let @xmath33 be an optimal solution to the lp - relaxation of @xmath30 with objective value @xmath34 .",
    "if @xmath33 satisfies the integrality constraints , then it is an optimal solution to @xmath30 and a feasible solution to @xmath29 , and therefore we update @xmath32 as @xmath35 .",
    "otherwise , there are two possibilities : if @xmath36 , then an optimal solution to @xmath30 can not improve on @xmath32 , hence the subproblem @xmath30 is removed from consideration ; on the other hand , if @xmath37 , then @xmath30 requires further exploration , which is done by _ branching _ , i.e. , by creating @xmath38 new subproblems @xmath39 , @xmath40 , of @xmath30 . each feasible solution to @xmath30 must be feasible to at least one child and , conversely , each feasible solution to a child must be feasible to @xmath30 .",
    "moreover , the solution @xmath33 must not be feasible to any of the lp - relaxations of the children .",
    "a simple realization of these requirements is to select a variable @xmath41 for which @xmath42 is not integer and to create two subproblems ; in one subproblem , we add the constraint @xmath43 , which is the round down of @xmath42 , and in the other @xmath44 , which is the round up of @xmath42 .",
    "the child nodes of node @xmath31 corresponding to these subproblems are then added to the tree .",
    "the largest among all lp - relaxation values associated with the active subproblems provides a global upper bound on the optimal value .",
    "the algorithm terminates when the global upper bound and global lower bound ( @xmath32 ) are equal .",
    "= = = = = = +    ' '' ''     + * algorithm 2 * the ` branch - and - bound ` algorithm +    ' '' ''     + * input : * @xmath23 . + * 0 . initialize . * + create a list * l * of active subproblems . set @xmath45 , @xmath46 and @xmath47 . + * 1 .",
    "terminate ? * + is @xmath48 ?",
    "if so , * return * @xmath49 is an optimal solution to * ilp*. + * 2 . select . * + choose and delete a problem @xmath30 from * l*. + * 3 .",
    "* + solve the lp - relaxation @xmath50 of @xmath30 .",
    "if @xmath50 is infeasible , * goto * step 1 , + else let @xmath34 be its objective function value and @xmath33 be its solution . +",
    "* 4 . prune . *",
    "+ if @xmath36 , * goto * step 1 .",
    "if @xmath33 is not integer , * goto * step 5 , + else let @xmath51 , @xmath52 .",
    "* goto * step 1 .",
    "+ * 5 . branch . * + divide the feasible domain @xmath53 of @xmath30 into smaller sets @xmath54 for @xmath55 , + such that @xmath56 , and add the subproblems @xmath39 , @xmath55 , to * l*. + step 1 .    ' '' ''    this basic scheme does not specify the rule to follow for choosing a node from * l*. a popular method to do this is to select the node with the highest value @xmath34 . such strategy is known as _ best - bound search _ ( or _ best - first search _ ) .",
    "this node selection strategy focuses the search on decreasing the global upper bound , because the only way to decrease the global upper bound is to improve the lp - relaxation at a node with the highest lp - relaxation value .",
    "another well - known method of selecting a node to explore is to always choose the most recently created node .",
    "this is known as _ diving search _ ( or _ depth - first search _ ) .",
    "this node selection strategy focuses the search on increasing the global lower bound , because feasible solutions are typically found deep in the tree .",
    "in addition to a different focus , both methods also have different computational attributes .",
    "diving search has low memory requirements , because only the sibling nodes on the path to the root of the tree have to be stored .",
    "furthermore , the changes in the linear programs from one node to the next are minimal , a single bound of a variable changes , which allows warm - starts in the lp solves .",
    "best - bound search , on the other hand , favors exploring nodes at the top of the tree as these are more likely to have high lp - relaxation values .",
    "this , however , can lead to large list of active subproblems .",
    "furthermore , subsequent linear programs have little relation to each other leading to longer solution times .",
    "we say that node @xmath31 is _ superfluous _ if @xmath57 .",
    "best - bound search ensures that no superfluous nodes will be explored . on the other hand",
    ", diving search can lead to the exploration of many superfluous nodes that would have been fathomed , had we known a smaller @xmath32 .",
    "most integer - programming solvers employ a hybrid of best - bound search and diving search , trying to benefit from the strengths of both , and switch regularly between the two strategies during the search . in the beginning",
    "the emphasis is usually more on diving , to find high quality solutions quickly , whereas in the later stages of the search , the emphasis is usually more on best - bound , to improve the global upper bound .",
    "+ combining branch - and - bound with cutting plane algorithms yields the highly effective class of _ branch - and - cut _ algorithms which are widely used in commercial ilp - solvers such as cplex and gurobi @xcite .",
    "cuts are generated at the nodes of the branch - and - bound search tree to tighten the bounds of the lp - relaxations or to exclude infeasible solutions .",
    "in section [ sec:2 ] we carry out a review of the main algorithms employed in the resolution of ilp problems . in all cases",
    ", we have seen that the strategy for finding the optimal solution consists of modifying the problem domain ( having previously considered its relaxation ) through the addition of new constraints . in the case of the cutting planes algorithms ,",
    "the new inequalities are used to separate fractional solutions of the lp - relaxation and to keep the set of integer solutions of the original ilp problem . in the case of the branch - and - bound and related methods ,",
    "the inequalities are used for partitioning the problem domain and eliminating fractional solutions of the lp - relaxation .    with a different approach , in this section we present the psa-_pilp _ algorithm , which does not alter the problem domain and , consequently , avoids the addition of new constraints to the original formulation .",
    "let us begin this section by introducing the concepts of _ projection _ , _ level _ and _ range _ needed to describe the psa-_pilp _ algorithm . to this end , consider the two - variable pilp problem illustrated in figure [ fig:1 ] where : ( i ) it is supposed that the problem is in the form ( [ def : ilp ] ) ; ( ii ) the set of integer solutions is represented as black points on the @xmath58 plane ; and ( iii ) @xmath59 , @xmath60 , denotes the _ projection with respect to the variable @xmath41 _",
    ", i.e. , the shadow cast by @xmath7 on the @xmath61 plane .    from figure [ fig:1 ]",
    ", it can be observed that the projection @xmath59 is defined on the interval @xmath62 $ ] , where the endpoints of this interval clearly represent the minimum and maximum values of the variable @xmath41 over the feasible domain of the lp - relaxation of the problem being solved .",
    "thus , @xmath63 and @xmath64 can be formally defined as follows : @xmath65 @xmath66    the projection @xmath59 can then be described as the two - dimensional convex set enclosed by the curves @xmath67 \\rightarrow { \\mathbb r}$ ] and @xmath68 \\rightarrow { \\mathbb r}$ ] . the former function corresponds to the lower boundary of the set , which we will call the _ lower projection _ , and the latter corresponds to the upper boundary , which we will call the _ upper projection_. it is straightforward to see that these curves can be calculated , for each fixed value @xmath69 , by solving two lp problems of one variable : @xmath70 @xmath71    consequently , for a two - variable problem , the projection of @xmath7 onto the @xmath61 plane can be defined as follows : @xmath72 , \\",
    "p_j^{low}(x_j)\\leq z \\leq p_j^{up}(x_j ) \\ \\bigr\\}.\\ ] ]        the definition of _ projection _ to be used in this paper is the natural extension of the model introduced above adapted to higher dimensions .    given a pilp problem , for @xmath73",
    "we define the _ projection _ of @xmath7 onto the @xmath61 plane , @xmath59 for short , as the two - dimensional convex set satisfying the following conditions .",
    "@xmath74 , \\",
    "p_j^{low}(x_j)\\leq z \\leq p_j^{up}(x_j ) \\ \\bigr\\},\\ ] ] where @xmath75 @xmath76 and where the lower and upper projections , @xmath77 and @xmath78 , can be determined , for each fixed value @xmath79 $ ] , by solving two lp problems of @xmath80 variables : @xmath81 @xmath82    let us now introduce the concepts of _ level _ and _ range _ which will be used to interpret the information given by the projections .    given a pilp problem ,",
    "we will call _ level _ to each of the values that may be reached by the objective function @xmath7 .",
    "more precisely , we will call level to each of the elements of the @xmath20 set .    given a pilp problem , the set of integer values that can be assigned to the variable @xmath41 , @xmath73 , when the projection @xmath59 is restricted to level @xmath83 , will be called the _ range _ of @xmath41 on level @xmath83 .",
    "this set will be denoted by @xmath84 , and a more formal definition is given by : @xmath85    to fix ideas , reconsider the projections @xmath86 and @xmath87 of the pilp problem shown in figure [ fig:1 ] .",
    "given that @xmath21 , it is straightforward to see that the set of values that may be reached by the objective function is given by : @xmath88 . the figure presented below illustrates the two largest elements of this set along with the range of integer values that can be assigned to the variables @xmath89 and @xmath90 at each of those levels .     and",
    "@xmath87 of the previous example crossed by levels @xmath91 and @xmath92      let us now explain the main steps involved in the psa-_pilp _ algorithm through the solution of the following instance of the classical _ unbounded knapsack problem _ ( ukp ) .",
    "this example covers all possibilities that may occur when applying psas for solving pilp problems .",
    "as stated in @xcite , the lp - relaxation of every instance of the ukp can be trivially solved by comparing the quotients @xmath94 corresponding to each variable @xmath41 .",
    "for this reason , the projections @xmath59 in this example can be exactly computed by simply applying the expressions ( [ def : proj ] ) to ( [ def : pup ] ) to the proposed formulation .",
    "thus , the family of projections of * ukp * turns out to be ( see figure [ fig:3 ] ) : @xmath95 , \\ 9 x_1 \\leq z \\leq -\\frac{17}{7 } x_1 + \\frac{96}{7 } \\",
    "\\bigr\\},\\ ] ] @xmath96 , \\ 3 x_2 \\leq z \\leq -\\frac{19}{7 } x_2 + \\frac{96}{7 } \\",
    "\\bigr\\},\\ ] ] @xmath97 , \\ 8 x_3 \\leq z \\leq \\ \\frac{17}{10 } x_3 + \\frac{108}{10 } \\ \\bigr\\}.\\ ] ]    these projections make it possible to decompose the original problem into single - variable subproblems , and thus they allow us to study the behaviour of the objective function from each variable s point of view independently . in particular , every time a specific value of the objective function is observed ( think of a horizontal line across @xmath86 , @xmath87 and @xmath98 ) , the information given by the projections can be used to restrict the _ range _ of integer values that can be assigned to each variable @xmath41 . as a result ,",
    "candidate solutions capable of reaching the selected @xmath83-value can be generated by combining the allowed values of each of the @xmath99-coordinates .",
    "given that the set of all possible optimal objective values of * ukp * is finite , namely @xmath100 , it becomes natural to address the solution of * ukp * by studying the candidate solutions produced by applying the observation made above to each of the elements of the @xmath20 set .",
    "furthermore , because we are maximizing , we can conduct the search process for the optimal solution by considering , one by one in decreasing order of value , each of the elements of the @xmath20 set .",
    "then it is easy to see that , if a _ feasible _ candidate solution @xmath101 satisfying the condition @xmath102 is found when level @xmath103 is being observed , this automatically implies that @xmath101 is a global optimum to the proposed problem .    to show more clearly what we are saying ,",
    "reconsider the projections @xmath86 , @xmath87 and @xmath98 of the problem at hand together with the three largest elements of the @xmath20 set .",
    "figure [ fig:3 ] illustrates this situation along with the range of integer values that can be assigned to the variables @xmath89 , @xmath90 and @xmath104 at each of those levels .    , @xmath87 and @xmath98 of * ukp * crossed by levels 13 , 12 , and 11 ]    * level 13 . *",
    "based on the values contained in the sets @xmath105 , @xmath106 , it can be inferred that there is no candidate solution capable of reaching level @xmath107 , i.e. , we can conclude that @xmath108 . the level @xmath107 is then discarded from the list of possible optimal objective values of * ukp * , and the search process is continued at level  @xmath109 .",
    "* level 12 .",
    "* from the information given by the sets @xmath110 , @xmath106 , it can be inferred that @xmath111 is the _",
    "unique _ candidate solution capable of reaching level @xmath109 .",
    "then , to determine whether @xmath109 is the optimal objective value of the problem and @xmath111 is the associated optimal solution , we simply check the following two conditions ( from now on the _ stopping criterion _ ) on our candidate solution : ( i ) is @xmath101 feasible ? ( ii )",
    "does @xmath112 ?",
    "if  the answer to both questions is affirmative , clearly @xmath111 is an optimal solution to the proposed problem and @xmath109 is the optimal objective value ; otherwise , level @xmath109 is discarded from the list of possible optimal objective values of * ukp * , and the search process is continued at level  @xmath113 .    by a simple calculation ,",
    "it is easy to see that @xmath111 is a feasible solution to * ukp * , however , it yields an objective value of @xmath114 .",
    "hence , given that @xmath111 is the unique candidate solution arising from this value of the maximand , it can be concluded that : @xmath115 and @xmath116 . before considering the next level and continuing with the search process",
    ", it is necessary to introduce two new variables in order to keep the former information : @xmath117 ( _ incumbent solution _ ) ; @xmath118 ( _ lower bound _ ) .",
    "* level 11 .",
    "* from the sets @xmath119 , @xmath106 , it can be inferred that the points @xmath111 , @xmath120 , @xmath121 and @xmath122 are the _ only _ four candidates for level  @xmath113 .",
    "we can now proceed in two different ways in order to determine whether some of these candidates is , in fact , an optimal solution to the proposed problem .",
    "the first alternative is to repeat what was done at the previous level , i.e. , to simply check the stopping criterion on each of the four candidate solutions .",
    "if we are thinking of extending the procedure to higher dimensions , this approach is clearly inefficient due to the exponential growth in the number of candidates .",
    "the second alternative , which is the one we are going to use , is to try to extract a little more of the information contained in @xmath86 , @xmath87 and @xmath98 in order to reduce the number of candidate solutions arising from the level being scanned .    with this latter goal in mind",
    ", we begin by observing that the condition @xmath123 implies that all possible candidate solutions for the current level must be in the form @xmath124 ( such a point will be called a _ partial candidate solution _ to * ukp * ) .",
    "then , the restriction @xmath125 can be imposed on the original formulation , thus obtaining a new problem of a smaller dimension .",
    "hereafter , the resulting problem will be called the _ reduced problem _ , and we will denote it by @xmath126 . in our case ,",
    "the reduced problem turns out to be : @xmath127    now , the general procedure can be applied to the reduced problem : recalculate the projections @xmath86 and @xmath87 , and re - examine level @xmath113 in order to determine the new sets @xmath128 and @xmath129 .    before recalculating @xmath86 and @xmath87 explicitly and carrying on with the example ,",
    "let us open a parenthesis here to enumerate the 4 alternatives that may hold depending on the cardinality of the new sets @xmath128 and @xmath129 .",
    "we will also explain how to proceed in each situation .",
    "for convenience in the exposition , the set consisting of the variables that have not yet been fixed will be called _ active variables _ ( * av * ) . in our case , @xmath130 .    1 .   [ case:1 ] * if @xmath131 for all @xmath132 such that @xmath133 av*. this means that there exist values @xmath134 such that @xmath135 and @xmath136 . then , we can assert that , if there existed a feasible solution for this value of the maximand , it should be in the form @xmath137 .",
    "the search process finishes if the resulting point satisfies the stopping criterion .",
    "otherwise , given that @xmath137 is the only candidate solution arising from this level , we can conclude that @xmath138 . in the latter case , before proceeding to the next level and continuing with the search process , we first check whether the variables @xmath139 and @xmath32 can be updated .",
    "[ case:2 ] * if @xmath140 for at least one @xmath132 such that @xmath133 av*. in this case , there is no integer value that can be assigned to , at least , one of the non - fixed coordinates of @xmath124 .",
    "therefore , we can conclude that @xmath138 .",
    "then , the original problem is reconsidered and the search process is restarted at level @xmath141 .",
    "[ case:3 ] * if @xmath131 for at least one @xmath132 such that @xmath133 av ( but not all)*. without loss of generality , let us suppose that @xmath142 , i.e. , there exists a value @xmath143 such that @xmath135 .",
    "then , the partial candidate solution , the set of active variables , and the reduced problem can be updated as follows : @xmath144 in this way , the original problem is further reduced in size , and the process can be continued ( at the current level ) by recalculating the projection @xmath87 of @xmath126 , and by performing the same four - step analysis that is being used here .",
    "[ case:4 ] * if @xmath145 for all @xmath132 such that @xmath133 av*. in this case , we proceed in the following manner .",
    "firstly , we choose one of the active variables of the problem using some criterion , say @xmath146 , and create new partial candidate solutions by assigning the @xmath147 value contained in the set @xmath148 , @xmath149 , to the @xmath150 component of @xmath101 . by abuse of notation , we will also write @xmath101 to denote the new partial candidate solutions created in this manner . secondly , we add all the partial candidate solutions constructed in the previous step to the set of partial candidate solutions to be analysed ( * l * ) .",
    "thirdly , using some criterion , we extract one of the partial candidate solutions added to * l * , say @xmath101 , and calculate the reduced problem associated to it ( @xmath126 ) and redefine * av * as the set of non - fixed components of @xmath101 .",
    "finally , the search process is continued by recalculating the sets @xmath59 and @xmath119 of @xmath126 ( for the variable @xmath41 that has not yet been fixed ) , and by performing the same four - step analysis that is being used here .",
    "note that , if the current problem does not produce any optimal solution , it is necessary to analyse the solution space generated by the remaining partial candidate solutions contained in * l * before concluding that @xmath113 is not the optimal level of @xmath7 .",
    "if any optimal solution is reached , the procedure terminates ; otherwise , the original problem is reconsidered and the search process is restarted at level @xmath141 .    having established the 4 alternatives that may hold depending on the cardinality of the new sets @xmath128 and @xmath129 , let us now come back to the example . in our case ,",
    "the projections @xmath86 and @xmath87 of the reduced problem turns out to be ( see figure [ fig:4 ] ) : @xmath151 , \\",
    "9x_1 + 8 \\leq z \\leq \\frac{15}{5 } x_1 + \\frac{55}{5 } \\",
    "\\bigr\\},\\ ] ] @xmath152 , \\ 3 x_2 + 8 \\leq z \\leq -\\frac{15}{10 } x_2 + \\frac{125}{10 }",
    "\\ \\bigr\\}.\\ ] ]     and @xmath87 of @xmath153 crossed by level 11 ]    from figure [ fig:4 ] , it can be observed that the range of integer values that can be assigned to each of the remaining active variables is given by : @xmath154 and @xmath155 ( case [ case:3 ] ) .",
    "therefore , the partial candidate solution , the set of active variables , and the reduced problem can be updated as follows : @xmath156    the projection @xmath87 of @xmath126 is then recalculated in an attempt to obtain tighter bounds for the set @xmath129 ( see figure [ fig:5 ] ) : @xmath157 , \\ 3 x_2 + 8 \\leq z \\leq 3 x_2 + 8 \\ \\bigr\\}.\\ ] ]     of @xmath158 crossed by level 11 ]    from figure [ fig:5 ] it follows that : @xmath159 ( case [ case:1 ] ) .",
    "this means that @xmath120 is the unique candidate solution capable of reaching level @xmath113 .",
    "then , given that @xmath101 satisfies the stopping criterion , we can conclude that it is an optimal solution to * ukp*. @xmath160 + the algorithm to be described in this paper is the generalization of the above procedure adapted to higher dimensions .",
    "the following outline summarizes how the proposed algorithm works .",
    "given a pilp problem , the psa-_pilp _ algorithm starts by calculating the orthogonal projection associated to each variable @xmath41 , and by identifying the set of all possible optimal objective values , say @xmath161 .",
    "then , it begins the search for the optimal solution by considering , one by one in decreasing order of value , each of the elements of the @xmath20 set .",
    "every time a new level @xmath162 is selected , the algorithm utilizes the information contained in the sets @xmath163 to fix the value of some of the variables , and thus to reduce the size of the original problem .",
    "the procedure is then continued by recalculating the sets @xmath59 and @xmath163 of the reduced problem for the variables that have not yet been fixed ( _ active variables _ ) .",
    "a number of candidate solutions is constructed for each considered level @xmath164 by applying this argument systematically .",
    "the search process ends ( stopping criterion ) when a _ feasible candidate solution @xmath101 satisfying the condition @xmath165 is found when the algorithm is scanning level @xmath164_. then , it can be concluded that @xmath101 is a global optimum to the proposed pilp problem . + as can be seen in this outline , and also in the previous example , the proposed algorithm differs from the state - of - the - art techniques in three aspects : ( i ) it guides the search for the optimal solution by generating candidate solutions tailored to specific values of the objective function ; ( ii ) it systematically reduces the number of variables in the original problem for each considered level ; and ( iii ) it does not add any additional constraint to the initial formulation . concerning the second point , it is worth noting that , while in the case of branch - and - bound - based algorithms the number of variables that can be fixed in each iteration of the procedure ( for each node in the search tree ) oscillates between @xmath166 and @xmath13 , in the case of the psa-_pilp _ algorithm this figure ranges between @xmath13 and @xmath167 .",
    "furthermore , as we will see later on in section [ sec:5 ] , the computational experiments performed on instances of the 0 - 1mkp reveal that the percentage of variables that are fixed to their optimal value in the _ first iteration _ of the psa-_pilp _ algorithm at the optimal level , rise to more than @xmath168 of the total variables .      to conclude this section ,",
    "let us give some precisions about how to calculate projections in the case of general pilp problems .",
    "this is motivated by the fact that , unlike what happened in section [ subsec:3.2 ] for the ukp , in the case of general pilp problems it is usually too expensive  or even impossible  to derive explicit formulas for @xmath78 and @xmath77 for all @xmath41 in the domain of the definition of @xmath59 .",
    "it then becomes necessary to identify which part of the information provided by the projections is dispensable and which part is strictly necessary for executing the psa-_pilp _ algorithm .",
    "it is easy to see that the only information that is absolutely necessary for executing the psa-_pilp _ algorithm is that given by the points @xmath169 and @xmath170 , where @xmath171 takes on all possible _ integer _ values in the domain of the definition of @xmath59 . from a theoretical point of view",
    ", this observation makes it possible to compute the set of projections for every instance of a pilp problem in a finite number of steps . in practice , however , it may take a long time for the psa-_pilp _ algorithm to converge to the optimum if the coefficients @xmath172 and @xmath173 are calculated exactly .",
    "it is then natural to , in addition to the previous simplification , approximate some of these values in order to reduce the number of operations even further .    to fix ideas , the following outline details the steps of the procedure suggested above applied to the computation of the set of upper projections , @xmath174 _ integer in the domain of the definition of _",
    "@xmath175 , for the subclass of pilp problems in which all variables are restricted to be @xmath166 or @xmath13 .",
    "this type of problems is known as _ binary integer linear programming _ ( bilp ) .",
    "a similar approach can be applied to determine the lower projections of a bilp problem as well as to calculate the upper and lower projections for more complex pilp problems .    * _ phase 1 .",
    "_ the integer requirements of the original bilp problem are relaxed and the associated maximization lp program is solved by using the simplex method .",
    "let @xmath176 denote the optimal solution to the lp - relaxation , and let @xmath18 denote its respective optimal objective value .",
    "it is easy to see that , if the @xmath177 component of @xmath176 yields an integer value @xmath178 , this automatically implies that @xmath179 . in other words , assuming that the problem we are trying to solve had @xmath17 variables , this first operation would allow us to calculate , in the best - case scenario , up to @xmath80 of the total @xmath180 coefficients @xmath172 , @xmath178 . *",
    "_ phase 2 .",
    "_ for each of the remaining values , @xmath172 , that were not able to be computed in the previous phase , the additional constraint @xmath181 ( if @xmath182 ) or @xmath183 ( if @xmath184 ) is added to the bottom of the optimal simplex tableau obtained in the previous step , and the dual simplex algorithm is then used to restore primal feasibility and to compute an upper bound for @xmath172 .",
    "in this section , we present the scheme of the algorithm . in order to do that",
    ", we assume that there exists a procedure that permits to compute the set of projections for every instance of a pilp problem in a finite number of operations .",
    "the same assumption will be made on section [ subsec:4.2 ] to prove the finiteness and the correctness of the algorithm .",
    "as we mentioned before , the strategy of the psa-_pilp _ algorithm is to sweep across the set of all possible optimal objective values of the problem , say @xmath185 , and to use the information given by the sets @xmath186 , @xmath187 such that @xmath188 , to generate a finite number of candidate solutions tailored to each of the selected @xmath83-values .",
    "the search process finishes when a candidate solution which meets the stopping condition is found .    in order to clarify the exposition of the algorithm",
    ", we will divide the procedure into two parts , thus introducing a slight modification in comparison to the example presented in section [ subsec:3.2 ] . on the one hand",
    ", we will introduce the ` inspect_level ` algorithm , which is the responsible for generating the whole set of candidate solutions associated to a given level . on the other hand",
    ", we will present the ` main ` algorithm , which is the responsible for performing the parallel shifts in the functional value in the direction of a reduction of the maximand , and for checking the stopping criterion on the set of candidate solutions provided by the ` inspect_level ` algorithm .",
    "the scheme of the algorithms is as follows :    = = = = = = = +    ' '' ''     + * algorithm 3 * the ` main ` algorithm +    ' '' ''     + * input : * @xmath189 +   + * assumption : * @xmath190 +   + * output : * optimal solution to * pilp * , or detects infeasibility +   + * variables : * + @xmath191 ( candidate solution ) + @xmath21 ( codomain of @xmath7 over the feasible domain of * pilp * ) + @xmath192 ( level being scanned ) + @xmath193 ( lower bound ) + @xmath194 ( incumbent solution ) + @xmath195 ( set of candidate solutions to * pilp * produced by the ` inspect_level ` algorithm at level @xmath83 ) + @xmath59 ( projection produced by @xmath7 onto the @xmath61 plane ) +   + * 0 .",
    "* + compute @xmath59 for @xmath196 + compute @xmath20 + set @xmath83 to the largest element in @xmath20 + set @xmath32 to the smallest element in @xmath20 +   + * 1 . loop . *",
    "+ @xmath197 * or * ( @xmath198 * and * @xmath199 ) * do * +   + set @xmath200 +   +   + @xmath201 * do * + @xmath101 is a feasible solution to * pilp * * and * @xmath202 + @xmath101 is an optimal solution to * pilp * + @xmath101 is feasible * and * @xmath203 + set @xmath204 + set @xmath205 +   +   +   +   + set @xmath206 +   +   + * 2 . output . *",
    "+ @xmath207 + @xmath139 is an optimal solution to * pilp * +   + is infeasible +    ' '' ''    = = = = = = +    ' '' ''     + * algorithm 4 * the ` inspect_level ` algorithm +    ' '' ''     + * input : * * pilp * problem , @xmath83 ( level to be scanned ) , @xmath208 ( set of projections associated to * pilp * ) +   + * output : * @xmath195 ( set of candidate solutions to * pilp * arising from level @xmath83 ) +   + * variables : * + @xmath191 ( partial candidate solution ) + * prob * ( problem being analysed ) + * av * ( set of variables that have not yet been fixed ) + @xmath209 ( set of projections associated to * prob * ) + * l * ( set of partial candidate solutions to be analysed ) + @xmath195 ( set of candidate solutions to * pilp * arising from level @xmath83 ) +   + * 0 . initialize . * + set @xmath210 + set @xmath211 + set @xmath212 + set @xmath213 + set @xmath214 for all @xmath73 + set @xmath215 +   + * 1 . inspection . * + compute @xmath84 for all @xmath187 such that @xmath188 + @xmath216 for all @xmath187 such that @xmath188 + @xmath217 such that @xmath188 * and * @xmath218 + @xmath187 such that @xmath188 * and * @xmath218 * do * /*@xmath219*/ + set @xmath220 + set @xmath221 +   + @xmath222 + set @xmath223 +   + set @xmath224 + compute the set of projections associated to * prob * : @xmath209 + step 1 +   +   + choose @xmath187 such that @xmath188 using some criterion /*@xmath225*/ + @xmath226 + @xmath227 * to * @xmath228 * do * + set @xmath229 + set @xmath223 +   +   + @xmath227 * to * @xmath228 * do * + set @xmath229 + set @xmath230 +   +   +   +   +   + * 2 . update .",
    "* + @xmath231 + choose @xmath232 using some criterion + set @xmath233 + set @xmath234 non - fixed components of @xmath101 + set @xmath224 + compute the set of projections associated to * prob * : @xmath209 + step 1 +   + @xmath195 +    ' '' ''      this section is intended to prove that the algorithm finds an optimal solution , or detects infeasibility , in a finite number of iterations . before we come to the theorem we will enunciate two lemmas .",
    "[ lemma:1 ] let @xmath235 be a feasible solution to * pilp * ( [ def : ilp ] ) such that @xmath236 .",
    "then , @xmath237 for all @xmath238 .",
    "the result follows from the definitions ( [ def : range ] ) , ( [ def : proj ] ) , ( [ def : plow ] ) and ( [ def : pup ] ) , and from the fact that @xmath239 is a feasible solution to * pilp*. @xmath240    note that , when the projections are restricted to the optimal level of the problem , say @xmath241 , lemma [ lemma:1 ] asserts that every optimal solution to * pilp * can be reconstructed from the information provided by the sets @xmath242 , @xmath243 .",
    "[ lemma:2 ] let @xmath244 be an optimal solution to * pilp * ( [ def : ilp ] ) , and let @xmath101 be the partial candidate solution defined by @xmath245 . then",
    ", @xmath176 is optimal to @xmath246 .",
    "furthermore , the problems * pilp * and @xmath246 have both the same optimal objective value .",
    "the results follow from the fact that @xmath176 is feasible for both * pilp * and @xmath246 .",
    "@xmath240    the psa-_pilp _ algorithm converges to an optimal solution , or detects infeasibility , in a finite number of steps .",
    "the finiteness of the algorithm follows from the fact that there is always a finite number of levels and a finite number of candidate solutions to be analysed . for this reason",
    ", the algorithm always stops after a finite number of iterations . in the case that the pilp problem is infeasible",
    ", the algorithm terminates returning this condition .    to prove the correctness of the algorithm we need only to show that , if @xmath247 is an optimal solution to * pilp * ( [ def : ilp ] ) and @xmath241 is the optimal objective value of the problem ,",
    "then @xmath248 we are going to prove this property by induction on the number of variables .    for one - variable pilp problems the situation is as follows : @xmath249 we assume , without loss of generality , that @xmath250 and @xmath251 .",
    "let @xmath252 , \\",
    "l_1 , u_1 \\in { \\mathbb r},$ ] be the feasible domain of the lp - relaxation of * pilp*. then , _ the _ optimal solution to * pilp * is reached at @xmath253 yielding an objective value of @xmath254 . by applying the ` inspect_level ` algorithm to * pilp * restricted to level @xmath241 , it is easy to see that @xmath255 .",
    "this implies @xmath256 .",
    "then , the theorem is true for every instance of a pilp problem with one variable .",
    "inductive step .",
    "suppose that the result is valid for every pilp problem with @xmath31 variables , @xmath257 .",
    "let us now demonstrate that the property is also valid for every pilp problem with @xmath17 variables .",
    "let * pilp * be a pilp problem with @xmath17 variables satisfying ( [ def : ilp ] ) , and let @xmath247 be an optimal solution to * pilp*. from lemma [ lemma:1 ] , it follows that @xmath258 .",
    "then , by applying the ` inspect_level ` algorithm to * pilp * restricted to level @xmath241 , only one of the following alternatives holds :    1 .",
    "let us suppose , without loss of generality , that @xmath260 @xmath261 for some @xmath262 .",
    "that is , @xmath263 .",
    "1 .   if @xmath264 , then @xmath265 .",
    "2 .   if @xmath266 , the ` inspect_level ` algorithm updates the partial candidate solution , the set of active variables , and the reduced problem in the following manner : @xmath267 it then recalculates @xmath209 , and _ restarts the process from step 1 until the algorithm ends_. we now observe that this last operation is equivalent to apply @xmath268 and then to extend the set of candidate solutions produced by the ` inspect_level ` algorithm to a set of candidate solutions valid for * pilp*. this operation is performed by setting @xmath269 ( @xmath270 ) for all @xmath271 . + to conclude , to prove that @xmath265 , it suffices to show that @xmath272 .",
    "this result follows from lemma [ lemma:2 ] and the induction hypothesis .",
    "2 .   @xmath273 . without loss of generality , let us consider that index @xmath17 is chosen . for each value @xmath274 a partial candidate solution is added to *",
    "l * by setting @xmath275 . from lemma [ lemma:1 ]",
    ", it follows that @xmath276 , i.e. , there exists @xmath277 such that @xmath278 .",
    "the algorithm then analyses all the partial candidate solutions added to * l * and , therefore , after a finite number of steps it considers the candidate @xmath279 , and defines @xmath280 and @xmath281 . without loss of generality ,",
    "let us suppose that @xmath279 is the only partial candidate contained in * l * when it is chosen .",
    "the process is then restarted from step 1 until the algorithm terminates .",
    "the rest of the proof continues in the same manner as in case 1(b ) . @xmath240",
    "the performance of the psa-_pilp _ algorithm was compared with that of cplex v.12.1.0 ( default ) on two types of instances randomly generated of the 0 - 1mkp .",
    "our algorithm was written in c , and the tests were carried out on one core of an intel i7 3.40ghz with 16 gb of ram .",
    "we consider the 0 - 1mkp , which is stated as follows : @xmath282 with @xmath283 , and @xmath284 , @xmath285 and @xmath286 @xmath287 .",
    "the test instances used in this section were randomly generated following the procedure proposed in frville @xcite . in all of these instances",
    "the coefficients @xmath285 are integer numbers uniformly generated in @xmath288 ; the right - hand side coefficients ( @xmath289 s ) are set using the formula @xmath290 , where @xmath291 is the tightness ratio ; and the objective function coefficients ( @xmath284 s ) are correlated to @xmath285 as follows :    * uncorrelated : @xmath292 * weakly correlated : @xmath293 ,  with @xmath294    the test instances were generated by varying combinations of constraints ( @xmath295 up to @xmath296 ) and variables ( from @xmath297 to @xmath298 ) .",
    "the tightness ratio , @xmath291 , was always fixed to @xmath299 . for each @xmath300 combination",
    ", @xmath296 problems were generated .",
    "the implementation of the psa-_pilp _ algorithm that was used to carry out the computational experiments reported in this part of the paper presents the following characteristics .    * the two - phase procedure described in section [ subsec:3.3 ] was applied to determine the coefficients @xmath301 and @xmath302 for every instance of the 0 - 1mkp .",
    "in addition , the lp problems encountered during this routine were solved using the cplex callable library . * due to the particular characteristics of the 0 - 1mkp , the lower projections of every test instance were calculated exactly by means of the following formula : @xmath303 for all @xmath304 $ ] . * every time the condition _",
    "@xmath305 for all @xmath187 such that @xmath188 _ was reached , the active variable corresponding to the largest objective value was selected to split the partial candidate solution being scanned .",
    "* the _ last in , first out _ strategy was employed to manage the list * l * during the execution of the ` inspect_level ` algorithm .",
    "tables [ tab:1 ] and [ tab:2 ] below summarize the results obtained by both solvers on the two types of instances described previously .",
    "columns * cplex * and * psa-_pilp _ * report the number of instances solved to optimality by each algorithm , followed by the average runtime ( in cpu seconds ) of those instances .",
    "if the number of instances solved to optimality is less than @xmath296 , this indicates that the algorithm failed because it ran out of memory when solving some of the instances .",
    "column * levels * shows the average number of levels scanned by the psa-_pilp _ algorithm until an optimal solution was reached .",
    "column @xmath306 indicates the percentage of variables that remain _ active _ after the first iteration of the psa-_pilp _ algorithm at the optimal level .",
    "column * ratio * shows the average cpu time ratio between psa-_pilp _ and cplex for solving the given set of instances .",
    "finally , column * memory * indicates the average maximum virtual memory consumption ( in megabytes ) used by each algorithm ( cplex / psa-_pilp _ ) for solving the given set of instances . in all tests reported in this paper we did not limit the running time nor the memory consumption .",
    "llllllll & * m * & * cplex * & * psa-_pilp _ * & * levels * & * av * & * ratio * & * memory ( cplex / psa-_pilp _ ) * + 1,000 & 3 & * ( 5 ) 3 s. * & ( 5 ) 11 s. & 37.6 & 7.4 & 3.751 & negligible / negligible + 5,000 & 3 & * ( 5 ) 109 s. * & ( 5 ) 180 s. & 13.8 & 2.6 & 1.648 & negligible / negligible + 10,000 & 3 & * ( 5 ) 830 s. * & ( 5 ) 1,992 s. & 7.2 & 1.4 & 2.39 & 953 / 283 + 1,000 & 4 & * ( 5 ) 27 s. * & ( 5 ) 212 s. & 46.8 & 9.5 & 7.754 & negligible / negligible + 3,000 & 4 & * ( 5 ) 1,473 s. * & ( 5 ) 4,959 s. & 27.4 & 5.2 & 3.36 & 1,001 / 411 + 5,000 & 4 & * ( 5 ) 5,358 s. * & ( 5 ) 9,702 s. & 18.6 & 3.8 & 1.81 & 3,233 / 644 + 10,000 & 4 & ( 5 ) 39,957 s. & * ( 5 ) 32,619 s. * & 11.2 & 2.3 & 0.81 & 22,193 / 1,765 + 1,000 & 5 & * ( 5 ) 108 s. * & ( 5 ) 1,063 s. & 67.6 & 14.2 & 9.82 & negligible / negligible + 3,000 & 5 & * ( 5 ) 10,044 s. * & ( 5 ) 38,706 s. & 35.2 & 7.1 & 3.85 &",
    "4,595 / 1,826 +    llllllll & * m * & * cplex * & * psa-_pilp _ * & * levels * & * av * & * ratio * & * memory ( cplex / psa-_pilp _ ) * + 2,000 & 3 & ( 5 ) 792 s. & * ( 5 ) 593 s. * & 8.6 & 8.1 & 0.749 & 620 / 213 + 3,000 & 3 & ( 5 ) 1,311 s. & * ( 5 ) 697 s. * & 6.8 & 5.9 & 0.53 & 1,379 / 123 + 5,000 & 3 & ( 5 ) 3,704 s. & * ( 5 ) 1,413 s. * & 4 & 3.4 & 0.381 & 4,369 / 185 + 10,000 & 3 & ( 5 ) 5,226 s. & * ( 5 ) 2,971 s. * & 2.8 & 2.2 & 0.568 & 6,709 / 318 + 200 & 4 & * ( 5 ) 35 s. * & ( 5 ) 228 s. & 56.6 & 56.8 & 6.551 & negligible / negligible + 500 & 4 & * ( 5 ) 355 s. * & ( 5 ) 988 s. & 29.4 & 30 & 2.783 & negligible / negligible + 1,000 & 4 & * ( 5 ) 5,567 s. * & ( 5 ) 8,332 s. & 20.8 & 20.4 & 1.49 & 3,953 / 905 + 2,000 & 4 & ( 5 ) 32,214 s. & * ( 5 ) 19,503 s. * & 11.2 & 11.1 & 0.60 & 24,509 / 2,035 + 3,000 & 4 & ( 2 ) @xmath30759,931 s. & * ( 5 ) 58,529 s. * & 8.6 & 8.3 & @xmath3080.976 & @xmath30763,658 / 3,502 + 200 & 5 & * ( 5 ) 202 s. * & ( 5 ) 1,821 s. & 69 & 70 & 9.021 & negligible / negligible + 500 & 5 & * ( 5 ) 9,234 s. * & ( 5 ) 29,591 s. & 37.2 & 38 & 3.20 & 4,955 / 2,036 + 1,000 & 5 & * ( 5 ) 89,542 s. * & ( 5 ) 93,581 s. & 25.8 & 26.2 & 1.04 & 41,244 / 4,935 +    based on the computational results , we conclude that the psa-_pilp _ algorithm is not very efficient , in terms of running time , to solve small - size instances ; however , it shows a better trend than cplex ( see ratio ) when the number of variables increases , especially in the hardest type of instances . in this regard ,",
    "it is worth noting that , in contrast to cplex ( default ) , the implementation of the psa-_pilp _ algorithm does not incorporate any type of presolve , cutting plane technique , or heuristics to improve its performance .",
    "concerning memory usage , the numbers of the psa-_pilp _ algorithm are considerably lower than those of cplex in all instances tested .",
    "the psa-_pilp _ algorithm consumed in average less than 10.4% of the memory consumed by cplex .",
    "this can be explained by the way the algorithm conducts the search process for the optimal solution ( by generating candidate solutions tailored to specific values of the objective function ) , and by the manner in which the * l * set is managed during the execution of the ` inspect_level ` algorithm .",
    "in fact , under these conditions it can be proven that psa-_pilp _",
    "s memory consumption is polynomial in the number of variables and the cardinality of the sets @xmath84 .",
    "finally , it is interesting to note that the percentage of variables that are fixed to their optimal value in the first iteration of the algorithm at the optimal level , grows to more than 97% of the total variables .",
    "this paper proposes a new exact algorithm , called psa-_pilp _ , for solving pilp problems using projections .",
    "the psa-_pilp _ algorithm differs from state - of - the - art techniques since it searches for solutions for specific values of the objective function . as a consequence of this approach , the number of variables in the original problem is systematically reduced ( for each considered level ) and no additional constraints are added to the initial formulation . according to our computational experiments , we believe that the proposed new algorithm paradigm has a great potential as a useful tool for solving pilp problems .",
    "the present work leaves open a number of interesting directions for future research .",
    "first , the current version of the psa-_pilp _ algorithm could be greatly improved through the incorporation of advanced search strategies , preprocessing and probing techniques , cutting plane algorithms , and primal heuristics .",
    "second , additional improvements can be reached via parallel computing techniques .",
    "projection - splitting - based algorithms are natural candidates for parallelization because the subproblems associated with each level and each partial candidate solution contained in * l * are completely independent .",
    "thus , parallelism can be exploited by evaluating multiple levels and multiple partial candidate solutions simultaneously . finally , it is relatively easy to see how the proposed methodology can be extended to more complex situations such as pilp problems in which the condition _ @xmath309 and @xmath2 _ in the objective function is relaxed , or even to milp problems .",
    "we are going to deal with this discussion in the second part of this series .",
    "+    this work was partially supported by grants ubacyt 20020100100666 , pict 2010 - 304 , pict 2011 - 817 .",
    "we thank luis mastrangelo and santiago feldman for their helpful suggestions and constructive criticisms ."
  ],
  "abstract_text": [
    "<S> we propose a new exact approach for solving integer linear programming ( ilp ) problems which we will call projective splitting algorithms ( psas ) . </S>",
    "<S> unlike classical methods for solving ilp problems , psas conduct the search for the optimal solution by generating candidate solutions tailored to specific values of the objective function . as a consequence of this strategy , the number of variables in the original ilp problem is systematically reduced without adding any additional constraint to the initial formulation .    </S>",
    "<S> this is the first of a two - part series on psas . in this paper </S>",
    "<S> we focus on the resolution of pure integer linear programming ( pilp ) problems , leaving the treatment of mixed integer linear programming ( milp ) formulations to the second part of this series . </S>",
    "<S> the proposed algorithm was tested against the ibm ilog cplex @xcite optimizer on instances of the 0 - 1 multidimensional knapsack problem ( 0 - 1mkp ) , showing satisfactory results on instances with a large number of variables . </S>"
  ]
}