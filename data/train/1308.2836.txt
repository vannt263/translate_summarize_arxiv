{
  "article_text": [
    "many statistical data sets involve covariates @xmath0 that are error - contaminated versions of their true unobserved counterpart @xmath1 .",
    "however , the measurement error often does not fit the classical error structure @xmath2 with @xmath3 independent from @xmath1 .",
    "a common occurrence is , in fact , the opposite situation , in which @xmath4 with @xmath5 independent from @xmath0 , a situation often referred to as berkson measurement error [ @xcite , @xcite , @xcite ] .",
    "a typical example is an epidemiological study in which an individual s true exposure @xmath1 to some contaminant is not observed , but instead , what is available is the average concentration @xmath0 of this contaminant in the region where the individual lives .",
    "the individual - specific @xmath1 randomly fluctuate around the region average @xmath0 , resulting in berkson errors .",
    "existing approaches to handle data with berkson measurement error [ e.g. , @xcite , @xcite ] unfortunately require the distribution of the measurement error to be known , or to be estimated via validation data , which can be costly , difficult or impossible to collect .",
    "( in classical measurement error problems , the distribution of the error can be identified from repeated measurements via a kotlarski - type equality [ @xcite , @xcite ] .",
    "however , such results do not yet exist for berkson - type measurement error . ) a popular approach to relax the assumption of a fully known distribution of the measurement error is to allow for some adjustable parameters in the distributions of the variables and their relationships , and solve for the parameter values that best reproduce various conditional moments of the observed variables , under the assumption that this solution is unique .",
    "this approach has been used , in particular , for polynomial specifications [ @xcite ] and , more recently , for a very wide range of parametric models [ wang ( @xcite ) ] .",
    "the present paper goes beyond this and provides a formal identification result and a general nonparametric regression method that is consistent in the presence of berkson errors , without requiring the distribution of the measurement error to be known a priori . instead , the method relies on the availability of a so - called instrumental variable [ e.g. , see chapter 6 in @xcite ] to recover the relationship of interest .",
    "for instance , in the epidemiological study of the effect of particulate matter pollution on respiratory health we consider in this paper , suitable instruments could include ( i )  individual - level measurement of contaminant levels that can even be biased and error - contaminated or ( ii ) incidence rates of diseases other than the one of interest that are known to be affected by the contaminant in question .",
    "our estimation method essentially proceeds by representing each of the unknown functions in the model by a truncated series ( or a flexible functional form ) and by numerically solving for the parameter values that best fits the observable data .",
    "although such an approach is easy to suggest and implement , it is a challenging task to formally establish that such a method is guaranteed to work in general .",
    "first , there is no guarantee that the solution ( i.e. , parameter values that best match the distribution of the observable data ) is unique .",
    "second , estimation in the presence of a number of unknown parameters going to infinity with sample size is fraught with convergence questions .",
    "can the postulated series represent the solution asymptotically ?",
    "is the parameter space too large to obtain consistency ? is the noise associated with estimating an increasing number of parameters kept under control ?",
    "our solution to these problems is two - fold .",
    "first , we target the most difficult obstacle by formally establishing identification conditions under which the regression function and the distribution of all the unobserved variables of the model are uniquely determined by the distribution of the observable variables .",
    "a second important aspect of our solution to the berkson measurement error problem is to exploit the extensive and well - developed literature on nonparametric sieve estimation [ e.g. , @xcite , @xcite , @xcite ] to formally address the potential convergence issues that arise when nonparametric unknowns are represented via truncated series with a number of terms that increases with sample size .",
    "these theoretical findings are supported by a simulation study and the usefulness of the method is illustrated with an epidemiological application to the effect of particulate matter pollution on respiratory health .",
    "we consider a regression model of the general form @xmath6 where the function @xmath7 is the ( unknown ) relationship of interest between @xmath8 , the observed outcome variable and @xmath1 , the _ unobserved _ true regressor , while @xmath9 is a disturbance .",
    "information regarding @xmath1 is only available in the form of an observable proxy @xmath0 contaminated by an error @xmath5 .",
    "equation ( [ eqz ] ) assumes the availability of an instrument @xmath10 , related to @xmath1 via an unknown function @xmath11 and a disturbance  @xmath12 .",
    "our goal is to estimate the function @xmath13 in ( [ eqy ] ) nonparametrically and without assuming that the distribution of the measurement error @xmath5 is known .",
    "[ as by - products , we will also obtain @xmath11 and the joint distribution of all the unobserved variables . ] to this effect , we require the following assumptions , which are very common in the literature focusing on nonlinear models with measurement error [ e.g. , @xcite , @xcite , @xcite , @xcite , @xcite , @xcite ] .    [",
    "condindep]the random variables @xmath0 , @xmath5 , @xmath14 , @xmath12 are mutually independent .",
    "note that assumption  [ condindep ] implies the commonly - made `` surrogate assumption '' @xmath15 , as can be seen by the following sequence of equalities between conditional densities : @xmath16 .",
    "[ condloc]the random variables @xmath5 , @xmath9 , @xmath17 are centered ( i.e. , the model s restrictions preclude replacing @xmath18 by @xmath19 for some nonzero constant @xmath20 , and similarly for @xmath9 and @xmath12 ; this includes either zero mean , zero mode or zero median , e.g. ) .",
    "as our approach relies on the availability of an instrument @xmath10 to achieve identification , it is instructive to provide practical examples of suitable instruments in common settings .",
    "although the use of instrumental variables has historically been more prevalent in the econometrics measurement error literature [ @xcite ] , instruments are gathering increasing interest in the statistics literature , especially in the context of measurement error problems [ see chapter 6 entitled `` instrumental variables '' in @xcite and the numerous references therein ] .    note",
    "that instrument equation ( [ eqz ] ) is entirely analogous to ( [ eqy ] ) , the equation generating the main dependent variable .",
    "hence , the instrument is nothing but another observable `` effect '' caused by @xmath1 via a general nonlinear relationship @xmath11 .",
    "let us consider a few examples , which were inspired by some of the case studies found in @xcite , @xcite and @xcite .",
    "epidemiological studies .    in these studies ,",
    "the dependent variable @xmath8 is typically a measure of the severity of a disease or condition , while the true regressor @xmath21 is someone s true but unobserved exposure to some contaminant .",
    "the average concentration @xmath0 of this contaminant in the region where the individual lives is , however , observed .",
    "the error on @xmath0 is berkson - type because individual - specific @xmath1 typically randomly fluctuate around the region average @xmath0 . in this setup ,",
    "multiple plausible instruments are available :    a measurement of contaminant concentration in the individual s house ( these would be error - contaminated by classical errors , since the concentration at a given time randomly fluctuates around the time - averaged concentration which would be relevant for the impact on health ) . thanks to the flexibility introduced by the function @xmath11 in ( [ eqz ] ) , these measurements can even be biased . they can therefore be made with a inexpensive method ( that can be noisy and not even well - calibrated ) , making it practical to use at the individual level . hence , it is possible to combine ( i ) accurate , but expensive , region averages that are not individual - specific ( @xmath0 ) and ( ii ) inexpensive , inaccurate individual - specific measurements ( @xmath10 ) to obtain consistent estimates .",
    "another plausible instrument could be a measure of the severity of another disease or condition that is _ known _ to be caused by the contaminant .",
    "the fact that it is _ caused by _ the contaminant , introduces an error structure which is consistent with equation ( [ eqz ] ) .",
    "other measurable effects due to the contaminant ( e.g. , the results of saliva or urine tests for the presence of contaminants ) could also serve as instruments .",
    "clearly these measurements are not units of exposure , but the function @xmath11 can account for this .    experimental studies .",
    "researchers may wish to study how an effect @xmath8 ( e.g. , the production of some chemical ) is related to some imposed external conditions @xmath0 ( e.g. , oven or reactor temperature ) , but the true conditions @xmath21 experienced by the sample of interest may deviate randomly from the imposed conditions ( e.g. , temperature may not be completely uniform ) . in this case ,",
    "an instrument @xmath10 could be ( i ) another `` effect '' ( e.g. , the amount of another chemical ) that is known to be caused by @xmath21 or ( ii ) a measurement of @xmath1 that is specific to the sample of interest but that may be very noisy or even biased ( e.g. , it could be an easier - to - take temperature measurement after the experiment is completed and the sample has partly cooled down ) .",
    "self - reported data .",
    "@xcite have argued that individuals reporting data ( e.g. , their food intake , or exercise habits ) are sometimes aware of the uncertainty in their estimates of @xmath1 and , as a result , try to report an average @xmath0 over all plausible estimates consistent with the information available to them , thus leading to berkson - type errors , because the individuals try to make their prediction error independent from their report . in this setting , an instrument @xmath10 could be another observable outcome variable @xmath10 that is also related to @xmath1 .",
    "we now formally state conditions under which the berkson measurement error model can be identified with the help of an instrument .",
    "let @xmath22 , @xmath23 , @xmath24 and @xmath25 denote the supports of the distributions of the random variables @xmath8 , @xmath0 , @xmath1 and @xmath10 , respectively .",
    "we consider @xmath26 and @xmath10 to be jointly continuously distributed ( with @xmath27 , @xmath28 , @xmath29 and @xmath30 with @xmath31 ) .",
    "accordingly , we assume the following .",
    "[ conddens]the random variables @xmath32 admit a bounded joint density with respect to the lebesgue measure on @xmath33 . all marginal and conditional densities are also defined and bounded .",
    "we use the notation @xmath34 and @xmath35 to denote the density of the random variable @xmath36 and the density of @xmath36 conditional on @xmath37 , respectively .",
    "lower case letters denote specific values of the corresponding upper case random variables .",
    "next , as in many treatments of errors - in - variables models [ @xcite , @xcite , @xcite , @xcite , schennach ( @xcite ) ] , we require various characteristic functions to be nonvanishing .",
    "we also place regularity constraints on the two regression functions of the model .",
    "[ condinv]for all @xmath38 , @xmath39 \\neq0 $ ] and for all @xmath40 , @xmath41 \\neq0 $ ] ( where @xmath42 ) .    [ condnodup]@xmath43 and @xmath44 are one - to - one ( but not necessarily onto ) .",
    "[ condcont]@xmath45 is continuous .",
    "assumption  [ condnodup ] is somewhat restrictive when @xmath1 has a dimension larger or equal to the ones of @xmath8 ( or @xmath10 ) .",
    "fortunately , it is often possible to eliminate this problem by re - defining @xmath8 ( and @xmath10 ) to be a vector containing auxiliary variables in addition to the outcome of interest , in order to allow for enough variation in @xmath8 ( and  @xmath10 ) to satisfy assumption  [ condnodup ] .",
    "each of these additional variables need not be part of the relationship of interest per se , but does need to be affected by @xmath1 is some way . in that sense , such auxiliary variables would also be a type of `` instrument . ''",
    "our main identification result can then be stated as follows .",
    "( note that the theorem also holds upon conditioning on an observed variable @xmath46 , so that additional , correctly measured , regressors can be straightforwardly included . )",
    "[ thid]under assumptions  [ condindep][condcont ] , given the true observed conditional density @xmath47 , the solution @xmath48 to the functional equation @xmath49 for all @xmath50 , @xmath51 , @xmath52 is unique ( up to differences on sets of null probability measure ) .",
    "a similar uniqueness result holds for the solution @xmath53 to @xmath54\\\\[-8pt ] & & \\qquad = f_{x } ( x ) \\int f_{\\delta z } \\bigl ( z - h \\bigl ( x^{\\ast } \\bigr ) \\bigr ) f_{\\delta y } \\bigl ( y - g \\bigl ( x^{\\ast } \\bigr ) \\bigr ) f_{\\delta x^{\\ast } } \\bigl ( x^{\\ast}-x \\bigr ) \\,dx^{\\ast}.\\nonumber\\end{aligned}\\ ] ]    establishing this result demands techniques radically different from existing treatment of berkson error models , such as the spectral decomposition of linear operators [ see @xcite for a review ] , which are emerging as powerful alternatives to the ubiquitous deconvolution techniques that are typically applied in classical measurement error problems .",
    "the proof can be found in the and can be outlined as follows .",
    "assumption  [ condindep ] lets us obtain the following integral equation relating the joint densities of the observable variables to the joint densities of the unobservable variables : @xmath55 from which equation ( [ eqfyxz ] ) follows directly .",
    "uniqueness of the solution is then shown as follows .",
    "equation ( [ eqpreindep ] ) defines the following operator equivalence relationship : @xmath56 where we have introduced the following operators : @xmath57 ( z ) & = & \\int f_{y , z|x } ( y , z|x ) r ( x ) \\,dx,\\nonumber\\\\ { } [ f_{z|x^{\\ast}}r ] ( z ) & = & \\int f_{z|x^{\\ast } } \\bigl ( z|x^{\\ast } \\bigr ) r \\bigl ( x^{\\ast } \\bigr ) \\,dx^{\\ast } , \\nonumber\\\\ { } [ f_{z|x}r ] ( z ) & = & \\int f_{z|x } ( z|x ) r ( x ) \\,dx,\\\\ { } [ d_{y;x^{\\ast}}r ] \\bigl ( x^{\\ast } \\bigr ) & = & f_{y|x^{\\ast } } \\bigl ( y|x^{\\ast } \\bigr ) r \\bigl ( x^{\\ast } \\bigr ) , \\nonumber\\\\ { } [ f_{x^{\\ast}|x}r ] \\bigl ( x^{\\ast } \\bigr ) & = & \\int f_{x^{\\ast } |x } \\bigl ( x^{\\ast}|x \\bigr ) r ( x ) \\,dx \\nonumber\\end{aligned}\\ ] ] for some sufficiently regular but otherwise arbitrary function @xmath58 .",
    "note that , in the above definitions , @xmath59 is viewed as a parameter ( the operators do not act on it ) and that @xmath60 is the operator equivalent of a diagonal matrix .",
    "next , we note that the equivalence @xmath61 also holds [ e.g. , by integration of ( [ eqleqlll ] ) over all @xmath50 ] . we can then isolate @xmath63 @xmath64 and substitute the result into ( [ eqleqlll ] ) to yield , after rearrangements , @xmath65 where all inverses can be shown to exist over suitable domains under our assumptions .",
    "equation ( [ eqdiag ] ) states that the operator @xmath66 admits a spectral decomposition .",
    "the operator to be `` diagonalized '' is defined in terms of observable densities , while the resulting eigenvalues @xmath67 ( contained in @xmath60 ) and eigenfunctions @xmath68 ( contained in @xmath69 ) provide the unobserved densities of interest .",
    "a few more steps are required to ensure uniqueness of this decomposition , which we now briefly outline .",
    "one needs to ( i ) invoke a powerful uniqueness result regarding spectral decompositions [ theorem xv 4.5 in @xcite ] , ( ii ) exploit the fact that densities integrate to one to fix the scale of the eigenfunctions , ( iii ) handle degenerate eigenvalues and ( iv ) uniquely determine the ordering and indexing of the eigenvalues and eigenfunctions .",
    "this last , and perhaps most difficult , step , addresses the issue that both @xmath68 and @xmath70 , for some one - to - one function @xmath71 , are equally valid ways to state the eigenfunctions that nevertheless result in different operators @xmath69 . to resolve this ambiguity , we note that for any possible operator @xmath72 satisfying ( [ eqdiag ] ) , there exist a unique corresponding operator @xmath63 , via equation ( [ eqgivexsx ] ) .",
    "however , only one choice of @xmath69 leads to an operator @xmath63 whose kernel @xmath73 satisfies assumption  [ condloc ] .",
    "hence , @xmath73 , @xmath74 and @xmath75 are identified , from which the functions @xmath76 , @xmath77 , @xmath78 , @xmath45 and @xmath79 can be recovered by exploiting the centering restrictions on @xmath5 , @xmath9 and @xmath12 .    an operator approach has recently been proposed to address certain types of nonclassical measurement error problems [ @xcite ] , but under assumptions that rule out berkson - type measurement errors : it should be emphasized that , despite the use of operator decomposition techniques similar to the ones found in @xcite ( hereafter hs ) , it is impossible to simply use their results to identify the berkson measurement error model considered here , for a number of reasons .",
    "first , the key condition ( assumption 5 in hs ) that the distribution of the mismeasured regressor @xmath0 given the true regressor @xmath1 is `` centered '' around @xmath1 does not hold for berkson errors . consider the simple case where the berkson measurement error is normally distributed and so are the true and mismeasured regressors .",
    "the distribution of @xmath0 given @xmath80 is a normal centered at @xmath81 .",
    "hence , there is absolutely no reasonable measure of location ( mean , mode , median , etc . )",
    "that would yield the appropriate centering at @xmath82 that is needed in assumption 5 of hs .",
    "in addition , one can not simply replace the assumption of centering of @xmath0 given @xmath83 ( as in hs ) by a centering of @xmath1 given @xmath0 ( as would be required for berkson errors ) and hope that theorem 1 in hs remains valid .",
    "hs exploit the fact that , in a conditional density , there is no jacobian term associated with a change of variable in a conditioning variable ( here @xmath1 ) .",
    "however , with berkson errors , the corresponding change of variable would not take place in the conditional variables , and a jacobian term would necessarily appear , which makes the approach used in hs fundamentally inapplicable to the berkson case . solving",
    "this problem involves ( i ) using a different operator decomposition than in hs and ( ii ) using a completely different approach for `` centering '' the mismeasured variable.=1    a referee suggested an alternative argument ( formalized in the ) that makes a more direct connection with theorem 1 in hs but under the additional assumption that @xmath10 and @xmath1 have the same dimension .",
    "such an assumption is rather restrictive because it will often result in the assumption that @xmath11 is one - to - one ( assumption [ condnodup ] ) being violated .",
    "for instance , if @xmath1 is scalar and we have access to two instruments @xmath84 and @xmath85 such that neither @xmath86 $ ] nor @xmath87 $ ] are strictly monotone , then @xmath11 is not one - to - one for either instrument used in isolation .",
    "however , the mapping @xmath88,e [ z_{2}|x^{\\ast } ] ) $ ] will typically be one - to - one , except for really exceptional cases .",
    "hence , allowing for the dimensions of @xmath1 and @xmath10 to differ is important .",
    "nevertheless , even assuming away this problem , such an approach still requires a different technique for centering @xmath1 than the one used in hs .",
    "that said , both hs and the current paper rely on operator spectral decomposition as an alternative to conventional convolution / deconvolution techniques , and it appears likely that these new techniques will find applications in a number of other measurement error models .",
    "observe that our identification result is also useful in a parametric and semi - parametric context , as it provides the confidence that , under simple conditions , the model is identified .",
    "rank conditions that would need to be verified on a case - by - case basis in any given parametric model are automatically implied by our identification results in a wide class of models .",
    "also , although @xmath0 is allowed to be random throughout , considering @xmath0 to be fixed poses no particular difficulty , since equation ( [ eqfyxz ] ) provides a valid conditional likelihood function in that case .",
    "as discussed in @xcite , a number of extensions of the method are possible : ( i ) relaxing the independence between @xmath0 and @xmath18 to allow for some heteroskedasticity in the measurement error and ( ii ) combining classical and berkson errors , a possibility considered in , for example , @xcite , @xcite , @xcite and @xcite .",
    "it can also be shown that some extensions are not plausible , such as assuming that both the measurement equation ( [ eqxs ] ) and the instrument equation ( [ eqz ] ) have a berkson error structure [ @xcite ] .",
    "a natural way to obtain a nonparametric estimator of the model is to substitute truncated series approximations into ( [ eqfyxz ] ) or ( [ eqfyxz3 ] ) for each of the unknown functions and construct a log likelihood function to be maximized numerically with respect to all coefficients of the series [ e.g. , @xcite ] .",
    "such sieve - based estimators have recently found applications in a variety of measurement error problems [ e.g. , @xcite , @xcite , @xcite , @xcite , among others ] .",
    "below we first define our estimator before establishing its consistency .",
    "we represent the regression functions @xmath7 and @xmath89 as @xmath90 where @xmath91 is some sequence ( indexed by the truncation parameters @xmath92 ) of progressively larger sets of basis functions indexed by @xmath93 while @xmath94 is a vector of coefficients to be determined .",
    "the @xmath95 could be some power series , trigonometric series , orthogonal polynomials , wavelets or splines , for instance .",
    "the double indexing by @xmath96 and @xmath92 is useful to allow for splines , where changing the number of knots modifies all the basis functions .",
    "a similar expansion in terms of basis functions @xmath97 ( with truncation parameter @xmath98 ) is used for the density of each disturbance @xmath99 , @xmath100 where @xmath101 is a vector of coefficients to be determined , and @xmath102 is a user - specified `` baseline '' function .",
    "the `` baseline '' function is convenient to reduce the number of terms needed in the expansion , when the approximate general shape of the density is known .",
    "it is not strictly needed , however , and can be set to 1 .",
    "either way , the method is fully nonparametric . a convenient choice of basis [ see @xcite ] is to take @xmath102 to be a gaussian and @xmath103 for any @xmath98 .",
    "an important distinction with the functions @xmath7 and @xmath11 is that some constraints have to be imposed on the densities .",
    "one constraint is needed to ensure centering ( assumption [ condloc ] ) , @xmath104 where , for some user - specified function @xmath105 , we define @xmath106 for instance , to impose zero mean on the disturbance @xmath107 , let @xmath108 . to impose zero median ,",
    "let @xmath109 , where @xmath110 denotes an indicator function , while to impose zero mode , let @xmath111 ( a delta function derivative , in a slight abuse of notation ) .",
    "another constraint is needed to ensure unit total probability : @xmath112 .",
    "note that both types of constraints exhibit the computationally convenient property of being linear in the unknown coefficients .",
    "given the above definitions , we can define an estimator of all unknown functions based on a sample @xmath113 and equation ( [ eqfyxz ] ) [ a corresponding estimator based on equation ( [ eqfyxz3 ] ) can be derived analogously ] .",
    "let @xmath114 denote the minimizer of the sample log likelihood @xmath115 where @xmath116 @xmath117 , subject to @xmath118 for @xmath99 and subject to technical regularity constraints to be defined below .",
    "estimators are then given by @xmath119\\\\[-8pt ] \\hat{f}_{v } ( v ) & = & \\hat{f}_{v}^ { ( k_{v } ) } \\bigl ( v,\\hat{\\theta}_{v}^ { ( k_{v } ) } \\bigr ) \\qquad\\mbox{for } v= \\delta x^{\\ast } , \\delta y,\\delta z. \\nonumber\\end{aligned}\\ ] ] this type of estimator falls within the very general class of sieve nonparametric maximum likelihood estimators ( mle ) , whose asymptotic theory has received considerable attention over the last few decades [ e.g. , @xcite , @xcite , @xcite ] . here , we parallel the treatment of @xcite and @xcite to establish the consistency of the above procedure . although the consistency of sieve - type estimators has been previously established in very general settings under some high - level assumptions , our contribution is to provide very primitive sufficient conditions for consistency for the class of models considered here .",
    "we first need to define the set in which the densities of interest reside .",
    "the formal proof of consistency of the estimator requires this set to be compact , although this requirement appears to have little impact in practice .",
    "in essence , compactness is helpful to rule out very extreme but rare events associated with very poor estimates .",
    "it is a standard regularity condition ; see , for example , @xcite , @xcite , @xcite . a well - known type of infinite - dimensional but compact sets are those generated via boundedness and lipschitz constraints in an @xmath120 space . here",
    ", we use a weighted lipschitz constraint in order to allow for densities supported on an unbounded set , while still maintaining compactness ( our treatment can be straightforwardly adapted to cover the simpler case where the variables are supported on finite intervals ) .",
    "following @xcite , we enforce restrictions that avoid too rapid divergences in the log likelihood .",
    "[ defsetf]let @xmath121 .",
    "let @xmath37 be finite and strictly positive .",
    "let @xmath122 be strictly positive and bounded function that is decreasing in  @xmath123 , symmetric about @xmath124 and such that @xmath125 .",
    "let @xmath126 $ ] such that @xmath127 .",
    "let @xmath128 and @xmath129 be strictly positive and bounded functions with @xmath128 decreasing in @xmath123 and @xmath130 .",
    "let @xmath131 .",
    "we also define suitable norms and sets for the regression functions . here",
    ", we need to allow for functions that diverge to infinity at controlled rates toward infinite values of their argument . in analogy with any existing global measure of expected error",
    ", we also use a norm that downweights errors in the tails , which is consistent with the fact that the tails of a nonparametric regression function are always estimated with more noise , since there are fewer datapoints there .",
    "[ defsetg]let @xmath132 by some given strictly positive , bounded and differentiable weighting function . for any function @xmath133 ,",
    "let @xmath134 where @xmath135 .",
    "let @xmath136 and @xmath137 where @xmath138 is a given positive function that is increasing in @xmath123 and symmetric about @xmath124 .",
    "we can now state the regularity conditions needed .",
    "[ condiid]the observed data @xmath139 are independent and identically distributed across @xmath140 .",
    "[ condball]we have @xmath141 and @xmath142 .    [",
    "conddense]the set of functions representable as series ( [ expf ] ) and ( [ expg ] ) are , respectively , dense in @xmath143 ( in the norm @xmath144 ) and @xmath145 ( in the norm @xmath146 ) .",
    "denseness results for numerous types of series are readily available in the literature [ e.g. , @xcite , @xcite ] .",
    "although such results are sometimes phrased in a mean square - type norm rather than the sup norm used here , lemma  [ lemnorm2 ] below [ proven in @xcite ] establishes that , within the sets @xmath143 and @xmath145 , denseness in a mean square norm implies denseness in the norms we use .",
    "[ lemnorm2]let @xmath147 be a sequence in @xmath143",
    ". then @xmath148 implies @xmath149 ( for @xmath143 and @xmath144 as in definition  [ defsetf ] ) .",
    "we also need standard boundedness and dominance conditions .",
    "[ conddom]for any @xmath150 , @xmath151 for @xmath152 and @xmath153 as in definitions  [ defsetg ] and  [ defsetf ] , respectively .",
    "[ condmomex ] there exists @xmath154 such that @xmath155 < \\infty$ ] , where @xmath156 for @xmath157 and @xmath158 as in definitions  [ defsetf ] and  [ defsetg ] , respectively .",
    "we can then state our consistency result [ proven in @xcite ] :    [ thconsis]under assumptions  [ conddens][condmomex ] , if @xmath159 , for @xmath160 , the estimators given by ( [ eqnest ] ) evaluated at the minimizer of ( [ eqnopti ] ) subject to ( [ eqnlincons ] ) , @xmath161 and @xmath162 and satisfying assumption  [ conddom ] are such that @xmath163 , @xmath164 , @xmath165 , @xmath166 , @xmath167 , where the stared quantities denote the true values [ i.e. , the unique solution to ( [ eqfyxz ] ) ] .",
    "the practical implementation of the above approach necessitates the selection of the number of terms @xmath98 in each of the approximating series .",
    "theorem  [ thconsis ] allows for a data - driven selection of the @xmath98 , since @xmath98 is allowed to be random . to select the @xmath98",
    ", one can employ the bootstrap cross - validation model selection method based on the kullback ",
    "leibler ( kl ) criterion , shown by @xcite to be consistent even when the number of candidate models grows to infinity with sample size ( as it is here ) . in this method ,",
    "a fraction @xmath168 of the sample is excluded at random and the remaining @xmath169 fraction is used to estimate the model parameters with given numbers @xmath170 of terms in the corresponding series .",
    "the likelihood ( or kl criterion ) is then evaluated using the excluded fraction @xmath168 at the value of the estimated parameters found in the previous step .",
    "the process is repeated many times with different random partitions of the sample into fractions @xmath168 and @xmath171 , to obtain an average kl criterion with a sufficiently small variance ( which can be estimated from the kl criterion of each random partitions ) .",
    "this procedure is carried out for various trial choices of @xmath170 and the choice that yields the largest likelihood is selected .",
    "this method is consistent asymptotically ( as sample size @xmath172 ) as @xmath173 and @xmath174 and under some mild technical regularity conditions stated in @xcite .    our nonparametric approach nests parametric and semiparametric models .",
    "these subcases can be easily implemented by replacing some , or all , of the nonparametric series approximations by suitable parametric models .",
    "it is possible to obtain convergence rates and limiting distribution results , along the lines of @xcite or @xcite , although we do not do so here due to space limitations [ stating suitable regularity conditions , even in high - level form , is rather involved , as seen in the supplementary material of @xcite , which covers a related but different measurement error model ] .",
    "it is , however , important to point out one important property .",
    "sieve nonparametric mle is optimal in the following sense : under suitable regularity conditions , any sufficiently regular semiparametric functional of the nonparametric sieve mle estimates is asymptotically normal and root @xmath175 consistent and reaches the semiparametric efficiency bound for that functional ; see theorem 4 in @xcite .",
    "this notion of optimality is a natural nonparametric generalization of the well - known efficiency of parametric maximum likelihood .",
    "we now investigate the practical performance and feasibility of the proposed estimator via a simulation example purposely chosen to be a difficult case .",
    "the data is generated as follows .",
    "the distribution of @xmath0 is a uniform distribution over @xmath176 $ ] ( implying a standard deviation of @xmath177 ) .",
    "we consider a thick - tailed @xmath178 distribution with 6 degrees of freedom scaled by @xmath179 as the distribution of @xmath18 .",
    "the standard deviation of the error @xmath5 is almost identical to the one of the `` signal '' @xmath0 , thus making this estimation problem exceedingly difficult .",
    "the distribution of @xmath9 is a logistic scaled by @xmath180 while the distribution of @xmath17 is a @xmath178 distribution with @xmath181 degrees of freedom scaled by @xmath182 .",
    "the regression function has the form=1 @xmath183=0 which is only finitely many times differentiable , thus limiting the convergence rate of its series estimator in the measurement - error - robust estimator ( the naive estimator would be less affected since it would `` see '' a smoothed version of this function ) .",
    "the instrument equation has a specification that is strictly convex and therefore tends to exacerbate the bias in many nonparametric estimators , @xmath184    a total of @xmath185 independent samples , each containing @xmath186 observations , were generated as above and fed into our estimator . for estimation purposes , the functions @xmath7 and @xmath11",
    "are both represented by polynomials while the densities of @xmath5 , @xmath9 and @xmath12 are represented by a gaussian multiplied by a polynomial [ following @xcite , who establish that these choices satisfy a suitable denseness condition ] .",
    "the gaussian is centered at the origin , but its width is left as a parameter to be estimated . note that the functional forms considered are not trivially nested within the space spanned by the truncated sieve approximation .",
    "this was an intentional choice aimed at properly accounting for the nonparametric nature of the problem ( in which the researcher never has the fortune of selecting a truncated sieve fitting the true model exactly ) .",
    "the integral in equation ( [ eqfyxz ] ) is evaluated numerically by discretizing the integral as a sum over the range @xmath187 $ ] in intervals of @xmath188 .",
    "naive least - squares estimators ignoring measurement error ( i.e. , least - squares regressions of @xmath8 on @xmath0 and of @xmath10 on @xmath0 ) were used as a starting point for the numerical sieve optimization of the @xmath79 and @xmath45 functions , while the variances of the corresponding residuals were used to construct an initial gaussian guess for the optimization of all the error distributions . the simplex method due to @xcite ( also known as `` amoeba '' ) was used to carry out the numerical optimization of the log likelihood ( [ eqnopti ] ) with respect to all the parameters @xmath189 for @xmath190 and @xmath191 for @xmath192 simultaneously .",
    "the constraints that the estimated densities and regression functions lie , respectively , in the sets @xmath143 and @xmath145 of the form given in definitions  [ defsetf ] and  [ defsetg ] are implied by bounds on the magnitude of the sieve coefficients @xmath193 and @xmath194 in ( [ expf ] ) and ( [ expg ] ) .",
    "such constraints are easy to impose within the simplex optimization method : parameter changes that would yield violations of the bounds are simply rejected ( effectively assigned an `` infinite '' value)the simplex optimization method easily accommodates such extreme behavior in the objective function , since it does not rely on derivatives .",
    "however , we found that these constraints are rarely binding in practice , unless the number of terms @xmath98 in the expansions is large [ @xcite reports a similar observation ] .",
    "such large values of @xmath98 tend to be naturally ruled out via our data - driven selection method of the number of terms .    to select the number of terms in the approximating series for a given sample",
    ", we use the `` bootstrap cross - validation '' method described in section  [ secest ] with a fraction @xmath195 and @xmath185 bootstrap replications .",
    "trial values of the number of free parameters ( not counting parameters uniquely determined by zero mean and unit area constraints ) in the series representing @xmath196 each span the set @xmath197 while for @xmath79 , @xmath45 each span the set @xmath198 .",
    "the optimal numbers of parameters ( kept constant during the replications ) were found to be @xmath199 ; @xmath200 ; @xmath201 ; @xmath202 ; @xmath203 .",
    "figure  [ figberksim ] summarizes the result of these simulations , where a naive nonparametric series least - squares estimator ignoring measurement error ( i.e. , least - square regressions of @xmath8 on @xmath0 and of @xmath10 on @xmath0 ) with the same number of sieve terms is also shown for comparison .",
    "the reliability of the method can be appreciated by noting how closely the median of the replicated measurement - error - robust estimates matches the true model , while the naive estimator ignoring the presence of measurement error is considerably more biased , even missing the fact that the true regression function is nearly flat in the middle section and instead producing a very misleading linear shape despite the strong nonlinearity of the true model .",
    "in fact , unlike the proposed estimator , the naive estimator is so significantly biased that any type of hypothesis test based on it would exhibit completely misleading confidence levels : the true model curves ( for @xmath79 and @xmath45 ) almost always lies beyond the 95% or 5% percentiles of the estimator distribution .",
    "overall , the proposed measurement - error - robust estimator exhibits low variability and low bias at the reasonable sample size of @xmath186 .",
    "the bias is not exactly zero in a finite sample because our estimator is a nonlinear functional of sample averages and because the sieve approximation necessarily has a limited accuracy in a finite sample .",
    "nevertheless , the fact that our estimator performs so well in the presence of measurement error of such large magnitude is a strong indication of its practical usefulness .",
    "this behavior is not specific to this model  we have tested the method in other simulation settings ; see @xcite .",
    "numerous studies have sought to quantify the effect of air pollution on respiratory health [ e.g. , @xcite ] .",
    "specifically , there is a growing concern regarding the effect of small particulate matter [ @xcite , @xcite ] .",
    "a key difficulty with such studies is that air quality monitors are not necessarily located near the subjects being affected by air pollution , implying that the main regressor of interest is mismeasured .",
    "our approach to this question relies on very comprehensive country - wide data collected by environment protection agency ( epa ) and the center for disease control ( cdc ) in the united states .",
    "pollution levels are taken from epas monitor values report  criteria air pollutants database for year 2005 .",
    "epas data provides point measurements of the particulate matter levels ( we focus on so - called 95th percentile level of pm2.5 particles , those having less than 2.5 micrometers in diameter ) at various monitoring stations throughout the united states , from which we construct state - averaged pollution levels ( our @xmath0 variable , measured in @xmath204 g of particles per m@xmath205 ) .",
    "we do so because pollution data is only available for a small fraction of counties , and even where it is available , the nature of its measurement error is complex ( it could be a mixture of classical and berkson errors ) . by constructing state - level averages ,",
    "we average out the randomness in monitor measurements while leaving the randomness in the individual exposure untouched , thus obtaining a valid berkson error - contaminated estimate of the pollution level experienced by individuals from each state , whether they live in a county with a monitoring station or not .",
    "each individual faces an exposure equal to the state average plus an unknown random noise due to his / her precise geographic whereabouts and lifestyle .",
    "health data is obtained from the publicly available `` cdc wonder '' database entitled `` mortality  underlying cause of death '' for year 2005 . to measure respiratory health ,",
    "we use data on causes of death , which offers the advantage that it is very comprehensive and accurate ( medical professionals are required to collect it and there is no reliance on voluntary surveys ) .",
    "one limit to the completeness of the data is that , for some counties , the data is `` suppressed '' ( for privacy reasons ) or labeled as `` unreliable '' by the cdc and were therefore omitted from our sample .",
    "our dependent variable of interest ( @xmath8 ) is the rate ( per 10,000 ) of death due to `` chronic lower respiratory diseases '' ( e.g. , asthma , bronchitis , emphysema ) , while our instrument ( @xmath10 ) is the rate ( per 10,000 ) of death resulting from `` lung diseases due to external agents '' ( e.g. , pneumoconiosis due to organic or inorganic dust , coalworker s pneumoconiosis ) .",
    "the rationale is to use , as an instrument , a  variable that is clearly expected to be affected by pollution levels .",
    "this variable indirectly provides information regarding the true level of pollution , so that the effect of pollution ( if any ) on the variable of interest can be more accurately assessed .",
    "we employ county - level data on causes of death because they are readily available without concerns for patient privacy issues .",
    "moreover , the cdc provides age - corrected death rates , thus correcting for demographic differences between counties .",
    "we construct our sample by matching mortality data via counties and matching pollution data via states , resulting in 1305 observations over as many counties and covering all 51 states .",
    "a  limitation of our approach is that it does not control for other possible confounding effects , for example , if the proportion of smokers differs between industrial and nonindustrial cities .",
    "however , such a limitation is common in studies of this kind [ as noted in @xcite ] .",
    "we use the same types of sieves and computational methods as in the simulation example and select the number of terms using the `` bootstrap cross - validation '' method described in section  [ secest ] with a fraction @xmath195 and @xmath185 bootstrap replications .",
    "trial values of the number of free parameters in the series representing @xmath196 span the range @xmath206 while trial values of the number of terms in the series representing @xmath79 and @xmath45 span the range @xmath207 ( increasing any one of the @xmath98 beyond that range resulted in clearly worse performances ) .",
    "the optimal numbers of free parameters ( not counting parameters uniquely determined by zero mean and unit area constraints ) were found to be @xmath208 ; @xmath209 ; @xmath210 ; @xmath211 ; @xmath212 .",
    "pointwise 90% confidence bands around the nonparametric estimates were obtained using the standard bootstrap [ see , e.g. , @xcite for general conditions justifying its use ] with 100 replications .",
    "results are shown in figure  [ figapp ] .",
    "a few observations are in order .",
    "first , our measurement error - robust estimator is perfectly able to detect a clear monotone relationship between @xmath8 and @xmath1 and between @xmath10 and @xmath1 with useful confidence bands , despite the use of a fully nonparametric approach .",
    "second , although the distribution of the measurement error is difficult to estimate ( as reflected by the wide confidence bands ) , the impact of this uncertainty on the main function of interest [ @xmath213 is fortunately very limited .",
    "the 90% confidence bands indicate that the presence of substantial measurement error is consistent with the data : the measurement error is of the order of 10 @xmath204g / m@xmath205 , whereas the observed @xmath0 roughly ranges from 10 to 40 @xmath204g / m@xmath205 .",
    "third , the distribution of @xmath9 exhibits nonnegligible asymmetry , thus illustrating the drawbacks of methods merely assuming normality of all the error terms .",
    "in contrast , the distributions of @xmath5 and @xmath12 are apparently very close to symmetric ( this is a conclusion of the formal model selection procedure , not an assumption ) .    for comparison purposes",
    ", we also naively regress the dependent variables ( @xmath8  or  @xmath10 ) on the mismeasured regressor @xmath0 using a conventional least squares ( thereby neglecting measurement error ) with a polynomial specification with the same number of terms as our berkson model . a first troubling observation from this exercise",
    "[ see figure  [ figapp](b ) ] is that the naive estimate of @xmath214 is not monotone , although in the region where it is unexpectedly decreasing , the confidence bands do not rule out a constant response .",
    "second , it is perhaps counter - intuitive that the confidence bands for the naive estimator are sometimes larger than the corresponding bands for the measurement error - robust estimator .",
    "this is a consequence of the fact that correcting for berkson errors amounts to an operation akin to convolution ( rather than deconvolution , as in classical measurement errors ) . unlike deconvolution",
    ", convolution is a noise - reducing operation , effectively averaging observations of @xmath8 over a wide range of values of @xmath0 to yield an estimate the expected value of @xmath8 given a specific value of @xmath0 .",
    "this phenomenon is probably also responsible for the more reasonable ( i.e. , increasing ) behavior of the response for the measurement error - robust estimate .",
    "finally , the measurement error - robust regression function often lies at or beyond the 95% or 5% percentiles of the naive estimator distribution ; see figure [ figapp](b ) .",
    "this implies that the level of any statistical test would be severely biased .",
    "for instance , the confidence bands of the naive estimator would reject our best estimate of @xmath214 obtained with the measurement - error robust procedure .    in summary",
    ", this application example serves to illustrate that ignoring berkson errors can be seriously misleading in nonlinear settings .",
    "not only is the shape of the estimated response considerably affected , but statistical inferences based on a measurement error - blind method would be seriously biased .",
    "this application example also shows that our fully nonparametric and measurement error - robust method works well at sample sizes typically available in real data sets , without assuming the knowledge of the distribution of the measurement error .",
    "let @xmath215 with @xmath216 @xmath217 for some @xmath218 denote the set of all bounded functions in @xmath219 endowed with the usual @xmath220 norm . also , whenever we state an equality between functions in @xmath215 , we mean that their difference is zero in the @xmath220 norm .",
    "we provide two proofs of theorem 1 .",
    "the first one , suggested by a referee , relies on the additional assumptions that ( i ) @xmath10 and @xmath1 have the same dimension and ( ii ) @xmath45 and its inverse are differentiable . assumption ( i ) makes assumption  [ condnodup ] unlikely to hold , but enables a somewhat direct application of theorem 1 in @xcite .",
    "the second proof relaxes those assumptions .",
    "it borrows some of the operator techniques from @xcite , yet requires considerable changes in the approach  we focus here on the aspects of the proof that differ .",
    "proof theorem [ thid ] ( simple special case ) let variables from @xcite be denoted by the corresponding uppercase letter with tildes and make the following assignments : @xmath221 .",
    "we now verify the 5 assumptions of theorem 1 in @xcite .    to verify assumption 1 , we observe that the densities of @xmath222 and @xmath223 are related through:@xmath224 where the density @xmath225 exists by assumption  [ conddens ] , and @xmath226 exists by assumption [ condnodup ] . the jacobian @xmath227 matrix is only defined if @xmath1 and @xmath10 ( and therefore @xmath228 ) have the same dimension and is finite and nonsingular under the assumption that @xmath45 and its inverse are differentiable . a  similar argument can be used for marginals and conditional distributions .    to verify assumption 2 , we note that our model can be written in terms of tilded variables as @xmath229 to verify assumption 2(i ) , we write @xmath230 where we have used , in turn , ( i ) the equality @xmath231 and the fact that changes of variables in the conditioning variables do not introduce jacobian terms , ( ii ) the fact that conditioning on @xmath232 is equivalent to conditioning on @xmath233 , ( iii ) assumption  [ condindep ] , ( iv ) the relationship between @xmath9 and @xmath8 via ( [ eqtilde1 ] ) and ( v ) the equality @xmath234 .",
    "assumption 4 requires that @xmath236 for @xmath237 .",
    "this can be verified as follows : @xmath238 by invoking ( i ) the definition of @xmath9 , ( ii ) independence of @xmath9 from @xmath1 ( and therefore @xmath228 ) , ( iii ) the fact that @xmath239 implies @xmath240 since @xmath7 and @xmath11 are one - to - one by assumption  [ condnodup ] and so is @xmath241 .",
    "theorem 1 in @xcite then allows us to conclude that the joint distribution of @xmath242 is identified .",
    "however , in order to identify the distribution of @xmath243 , we need to identify @xmath11 . to this effect",
    ", we note that , conditional on @xmath244 , the fluctuations in @xmath228 are entirely caused by fluctuations in @xmath18 by equation ( [ eqtilde2 ] ) .",
    "moreover , @xmath5 is independent from @xmath0 , hence @xmath245 where the left - hand side was previously identified and where the jacobian term is well defined by assumptions  [ condnodup ] and the assumed differentiability of @xmath226 .",
    "the jacobian can be identified by integrating ( [ eqfj ] ) with respect to @xmath246 to yield @xmath247 . by varying @xmath248 while keeping @xmath249 fixed in equation ( [ eqfj ] )",
    ", we can identify the density @xmath78 up to a shift of @xmath226 .",
    "assumption  [ condloc ] , pins down what the shift should be , so that @xmath250 is identified for any given  @xmath249 .",
    "since @xmath89 is one - to - one by assumption  [ condnodup ] , @xmath251 uniquely determines @xmath11 .",
    "hence , the joint distribution of @xmath252 is identified . finally , noting that @xmath253 ( by assumption  [ condindep ] ) , then establishes the identification of @xmath214 with the help of assumption  [ condloc ] .",
    "the definition of marginal and conditional densities in combination with assumption  [ condindep ] lead to the following sequence of equalities : @xmath254 or , equivalently , @xmath255 as in @xcite , this integral equation can be written more conveniently as an operator equivalence relation @xmath256 by introducing the operators defined in equation ( [ eqdefop ] ) , which are acting on an arbitrary @xmath257 [ or @xmath258 .",
    "similarly , one can show that @xmath259 and thus @xmath260 . by assumptions",
    "[ conddens ] ,  [ condindep ] ,  [ condinv ] , [ condnodup ] ,  [ condcont ] and lemma  [ leminj ] below , we know that @xmath261 admits an inverse on the range of @xmath69 ( and therefore the range of @xmath262 ) , and we can write @xmath263 substituting ( [ eqop2i ] ) into ( [ eqop1 ] ) , we obtain @xmath264 by assumptions  [ conddens ] ,  [ condindep ] ,  [ condinv ] , [ condnodup ] ,  [ condcont ] and lemma  [ leminj ] below again , @xmath262 admits an inverse .",
    "moreover , by lemma 1 in @xcite , the domain of @xmath265 is dense in @xmath266 , and we can then write @xmath267 equation ( [ eqdiagpr ] ) states that the operator @xmath66 admits a spectral decomposition , where the eigenvalues are given by the @xmath268 for @xmath269 ( for a fixed @xmath59 ) defining the operator @xmath60 while the eigenfunctions are the functions @xmath270 for @xmath269 defining the kernel of the operator @xmath69 . as usual , the knowledge of a linear operator [ e.g. , @xmath262 ] only determines the value of its kernel [ e.g. , @xmath272 everywhere except on a set of null lebesgue measure .",
    "the resulting equivalence class exactly matches the usual equivalence class for probability densities with respect to the lebesgue measure , so identifiability of the model is not affected .",
    "the operator to be diagonalized is entirely defined in terms of observable densities while the decomposition provides the unobserved densities of interest .",
    "to ensure uniqueness of this decomposition , we employ four techniques .",
    "first , a powerful result from spectral analysis [ theorem xv 4.5 in @xcite ] ensures uniqueness up to some normalizations .",
    "second , the a priori arbitrary scale of the eigenfunctions is fixed by the requirement that densities must integrate to one .",
    "third , to avoid any ambiguity in the definition of the eigenfunctions when degenerate eigenvalues are present , we use assumption  [ condnodup ] and the fact that the eigenfunctions [ which do not depend on @xmath59 , unlike the eigenvalues @xmath273 must be consistent across different values of the dependent variable  @xmath59 .",
    "these three steps are described in detail in @xcite and are not repeated here .",
    "the fourth step [ which differs from the approach taken in @xcite ] is to rule out that the eigenvalues @xmath274 and eigenfunctions @xmath275 could be indexed by a different variable without affecting the operator @xmath66 .",
    "( this issue is analogous to the nonunique ordering of the eigenvalues and eigenvectors in matrix diagonalization . )",
    "suppose that the eigenfunctions can be indexed by another value , that is , they are given by latexmath:[$f_{z|\\tilde{x}^{\\ast } } ( \\cdot    variable related to @xmath82 through @xmath277 for some one - to - one function  @xmath71 .",
    "is also measurable , for otherwise @xmath278 would not be a proper random variable . ] under this alternative indexing , all the assumptions of the original model must still hold with @xmath82 replaced by @xmath279 , so a relationship similar to ( [ eqfzxsidx ] ) would still have to hold , for the same observed @xmath280 @xmath281 or , in operator notation , @xmath282 .    in order for @xmath283 to be a valid alternative density",
    ", it must satisfy the same assumptions ( and their implications ) as @xmath75 .",
    "in particular , the fact that @xmath69 is invertible ( established above via lemma  [ leminj ] ) must also hold for @xmath284 .",
    "hence , for any alternative @xmath284 , there is a unique corresponding @xmath285 , given by @xmath286 .",
    "we can find a more explicit expression for @xmath287 as follows .",
    "first note that we trivially have that @xmath288 since @xmath289 and @xmath71 is one - to - one . by performing the change of variable @xmath290 in ( [ eqfzxsidx ] )",
    ", we obtain @xmath291 where the measure @xmath204 is defined , via @xmath292 for any measurable set  @xmath293 , where @xmath294 denotes the lebesgue measure and @xmath295 . from this",
    "we can conclude the equality between the two following measures : @xmath296 by comparison to equation ( [ eqaltfzxs ] ) and the uniqueness of the measure@xmath297 due to the injectivity of the @xmath284 operator , shown in lemma  [ leminj ] in the general case where the domain of @xmath284 could include finite signed measures .",
    "we will now show that @xmath287 necessarily violates assumption  [ condloc ] ( with @xmath5 replaced by @xmath298 ) , unless @xmath299 is the identity function .",
    "since @xmath300 with @xmath5 independent from @xmath0 , we have @xmath301 and by a similar reasoning @xmath302 with @xmath303 . equation ( [ eqds1 ] ) then becomes @xmath304 now , for a given @xmath248 , consider radom ",
    "nikodym derivative of @xmath305 with respect to the lebesgue measure @xmath306 , which is , by definition ( almost everywhere ) equal to @xmath307 , a bounded function by assumption [ conddens ] . by equation ( [ eqmueq ] ) , the existence of the radom ",
    "nikodym derivative of the left - hand side implies the existence of the same radom ",
    "nikodym derivative on the right - hand side , and we can write @xmath308 almost everywhere . integrating both sides of the equation over all @xmath309 ,",
    "we obtain ( after noting that points where the equality may fail have null measure and therefore do not contribute to the integral ) , @xmath310 , since densities integrate to @xmath311 , which implies that @xmath312 , that is , @xmath204 is also the lebesgue measure .",
    "it follows from ( [ eqallf ] ) that , almost everywhere @xmath313 in order for assumption  [ condloc ] to hold for both @xmath314 and @xmath5 , we must have that @xmath315 , when viewed as a function of @xmath249 for any given @xmath248 , is centered at @xmath316 , and we must simultaneously have that @xmath317 , when viewed as a function of @xmath82 for any given @xmath248 , is centered at @xmath318 , that is , @xmath319 .",
    "the two statements are only compatible if @xmath320 .",
    "thus , there can not exist two distinct but observationally equivalent parametrization of the eigenvalues / eigenfunctions .",
    "hence we have shown , through equation ( [ eqdiagpr ] ) , that the unobserved functions @xmath268 and @xmath321 are uniquely determined ( up to an equivalence class of functions differing at most on a set of null lebesgue measure ) by the observed function @xmath322 .",
    "next , equation ( [ eqop2i ] ) implies that @xmath323 is uniquely determined as well .",
    "once @xmath268 and @xmath324 are known , the functions @xmath214 and @xmath325 can be identified by exploiting the centering restrictions on @xmath9 , @xmath5 and @xmath12 , for example , @xmath326 if @xmath9 is assumed to have zero mean .",
    "next , @xmath327 can be straightforwardly identified , for example , @xmath328 for any @xmath269 .",
    "similar arguments yield @xmath325 and @xmath329 from @xmath330 as well as @xmath331 from @xmath73 .",
    "it follows that equation ( [ eqfyxz ] ) has a unique solution .",
    "the second conclusion of the theorem then follows from the fact that both @xmath322 and @xmath332 are uniquely determined ( except perhaps on a set of null lebesgue measure ) from @xmath333 .",
    "the following lemma is closely related to proposition 2.4 in @xcite .",
    "it is different in terms of the spaces the operators can act on and more general in terms of the possible dimensionalities of the random variables involved .",
    "[ leminj]let @xmath334 and @xmath10 be generated by equations ( [ eqxs ] ) and ( [ eqz ] ) .",
    "let @xmath335 be the set of finite signed measures on a given set @xmath336 or  @xmath25 [ and note that @xmath335 includes @xmath337 as a special case , in the sense that for any function in @xmath338 , there is a corresponding measure @xmath339 whose radom  nikodym derivative with respect to the lebesgue measure is @xmath58 ] . under assumptions  [ condindep ] , [ conddens ] ,  [ condinv ] ,  [ condnodup ] and  [ condcont ] , the operators @xmath341 , @xmath342 and @xmath343 , defined in ( [ eqdefop ] ) , are injective mappings .",
    "first , one can verify that @xmath344 implies that @xmath345 and similarly for @xmath69 and @xmath262 , since the ( conditional ) densities involving variables @xmath346 and @xmath10 are bounded by assumption  [ conddens ] and are absolutely integrable .",
    "we now verify injectivity of @xmath69 .    by assumptions",
    "[ condindep ] ,  [ conddens ] and equation ( [ eqz ] ) , we have , for any @xmath347 , @xmath348 ( z ) = \\int f_{z|x^{\\ast } } \\bigl ( z|x^{\\ast } \\bigr ) \\,dr \\bigl ( x^{\\ast } \\bigr ) = \\int f_{\\delta z } \\bigl ( z - h \\bigl ( x^{\\ast } \\bigr ) \\bigr ) \\,dr \\bigl ( x^{\\ast } \\bigr).\\ ] ] next , let @xmath349 denote the signed measure assigning , to any measurable set @xmath350 , the value@xmath351 and note that @xmath349 is a finite signed measure since @xmath352 is .",
    "then , we can express @xmath353 as @xmath354 ( z ) = \\int f_{\\delta z } \\bigl ( z-\\tilde{x}^{\\ast } \\bigr ) \\,d\\tilde{r } \\bigl ( \\tilde{x}^{\\ast } \\bigr),\\ ] ] that is , a convolution between the probability measure of @xmath12 ( represented by its lebesgue density ) and the signed measure @xmath349 ; see chapter 5 in @xcite . by the convolution theorem for signed measures [ theorem 5.1(iii ) in @xcite ] , one can convert the convolution ( [ eqconvol1 ] ) into a product of fourier transforms , @xmath355 where @xmath356 ( z ) e^{\\mathbf{i}\\zeta z}\\,dz$ ] , @xmath357 $ ] and @xmath358 .",
    "since @xmath359 , the characteristic function of @xmath12 , is nonvanishing by assumption  [ condinv ] , we can isolate @xmath360 as @xmath361 since there is a one - to - one mapping between finite signed measures and their fourier transforms [ by theorem 5.1(i ) in @xcite ] , @xmath349 can be recovered as the unique signed measure whose fourier transform is @xmath362 .",
    "we now show that the signed measure @xmath349 uniquely determines the measure @xmath363 .",
    "let @xmath364 for any measurable @xmath365 , and note that @xmath366 is also measurable since @xmath45 is continuous by assumption  [ condcont ] . then observe that by assumption  [ condnodup ] , @xmath367 if and only if @xmath368 , and we have @xmath369 since @xmath370 is arbitrary , the knowledge of @xmath371 uniquely determines the value assigned to any measurable set by the signed measure @xmath363 .",
    "injectivity of @xmath63 is a special case of the above derivation ( with @xmath372 replaced by @xmath346 ) , in which @xmath45 is the identity function .",
    "finally , injectivity of @xmath262 is implied by the injectivity of @xmath69 and @xmath63 , since @xmath61 by assumption  [ condindep ] and equations ( [ eqxs ] ) and ( [ eqz ] ) ."
  ],
  "abstract_text": [
    "<S> this paper establishes that so - called instrumental variables enable the identification and the estimation of a fully nonparametric regression model with berkson - type measurement error in the regressors . </S>",
    "<S> an estimator is proposed and proven to be consistent . </S>",
    "<S> its practical performance and feasibility are investigated via monte carlo simulations as well as through an epidemiological application investigating the effect of particulate air pollution on respiratory health . </S>",
    "<S> these examples illustrate that berkson errors can clearly not be neglected in nonlinear regression models and that the proposed method represents an effective remedy . </S>"
  ]
}