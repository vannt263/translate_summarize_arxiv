{
  "article_text": [
    "random number generators are an important element in various cryptographic constructions .",
    "they are needed for generating keys , initialization vectors , and other parameters .",
    "the lack of randomness has devastating consequences for the security of cryptographic constructions and protocols .",
    "well known examples are the broken seeding of openssl pseudo - random generator in debian ( resulting in limited set of potential keys generated by openssl ) , fixed parameter used in sony playstation 3 implementation of ecdsa signing ( resulting in compromised private key ) , and many other .",
    "there are two types of random number generators @xcite :    * ( non - deterministic / true ) random number generators use a non - deterministic entropy source together with some additional post - processing to produce randomness ; * pseudo - random number generators  typically deterministic algorithms that produce pseudo - random data from a seed ( hence the seed must be random and unpredictable , produced by non - deterministic random number generator ) .",
    "various pseudo - random generators are standardized .",
    "for example , the list of approved random number generators for fips 140 - 2 can be found in @xcite .",
    "modern operating systems implement random generators and allow application to use them .",
    "linux uses crc - like mixing of data from entropy sources to an entropy pool and extracts random data via sha-1 from the entropy pool @xcite , freebsd uses a variant of yarrow algorithm @xcite , windows provides multiple prngs implementations via cng ( cryptography , next generation ) api @xcite with underlying generator compliant with nist sp 800 - 90 @xcite .",
    "new generation of processors often contain hardware random numbers generators suitable for cryptographic purposes .",
    "the unpredictability of random number generators is essential for the security of cryptographic constructions .",
    "good statistical properties , assessed by batteries of test such as nist @xcite , testu01 @xcite or diehard @xcite , are necessary but not sufficient for unpredictability of the generator .",
    "an interesting assessment and details of intel s ivy bridge hardware random number generator was published recently @xcite .",
    "since pseudo - random generators require seeding , usually multiple low - entropy sources are used to gather sufficient entropy into so - called entropy - pool for seeding or reseeding .",
    "low - entropy sources are various system counters and variables , such as cpu performance and utilization characteristics , the usage of physical and virtual memory , file cache state , time , process and thread information , etc .",
    "an extensive list of operating system variables used to fill the windows entropy pool can be found in @xcite .",
    "an example of relatively simple design of prng based on timings from a hard disk drive is described in @xcite .",
    "there can be various motivations for designing and implementing own pseudo - random number generator  performance , a lack of trust to generators provided by operating system or other components ( a well known story of dual_ec_drbg ) or even those provided by cpu hardware @xcite , experimenting , additional features / properties not present in available generators , etc .",
    "all pseudo - random generators must be seeded . in case of windows operating system",
    "we can easily use various counters as low - entropy sources .",
    "we analyze the standard set of performance counters in windows operating system .",
    "our goal is to answer the following questions :    * what counters are best suited as entropy sources , and how much entropy they provide ? * are these sources independent or correlated ? * are these sources sufficiently independent on the operating system state ( e.g. reboot or restoring from snapshot of a virtual system ) ?",
    "let us remind that counters are not used directly , they serve for seeding a pseudo - random generator .",
    "we do not expect the counters will satisfy some battery of statistical tests  we measure primarily the entropy of individual counters and the mutual information of promising counters .",
    "section [ prelim ] defines some notions and it also justifies a method of preprocessing the counters .",
    "results of our experiments are presented in section [ result ] .",
    "we summarize the implications of the results and outline the possible further research in section [ concl ] .",
    "let @xmath0 be a discrete random variable with values @xmath1 .",
    "let @xmath2 denote the probability that @xmath0 attains the value @xmath3 , i.e. @xmath4=p_i$ ] .",
    "a standard measure of uncertainty is the shannon entropy of a random variable .",
    "we denote it @xmath5 : @xmath6 where @xmath7 denotes a logarithm with base 2 , and we use a convention @xmath8 when necessary .",
    "the smallest entropy in the class of all rnyi entropies @xcite is a min - entropy @xmath9 : @xmath10 particularly , @xmath11 for any arbitrary discrete random variable @xmath0 .",
    "the min - entropy measures the uncertainty of guessing the value of @xmath0 in a single attempt .",
    "it is impossible to know exact probability distributions for most of the operating system counters .",
    "we sample the values of the counters in our experiments .",
    "after `` preprocessing '' ( see section [ ppcnt ] ) we use a maximum likelihood estimate , where each probability is estimated as ratio of observed values to the number of samples .",
    "there are better estimators of entropy with reduced bias , such as miller - madow , nsb and others @xcite . however , we think that simple estimate is sufficient for our classification of the performance counters .",
    "let @xmath12 be a sequence of values from a finite set @xmath13 .",
    "according to the previous paragraph , we use notations @xmath14 and @xmath15 for the entropy and the min - entropy , respectively , where the probabilities are estimated as follows : @xmath16 for all @xmath17 .",
    "there are two inherent problems when measuring the randomness of operating system counters .",
    "the first problem is that some counters , in fact , `` count '' .",
    "therefore , we get a sequence of increasing values depending on chosen sampling interval . calculating entropy based on unique values ( regardless of their non / uniformity ) yields always the same value  for @xmath18 samples we get @xmath19 . in order to have meaningful entropy values",
    ", we have to limit the possible values / outcomes of the random variable ( for example by splitting counter into smaller chunks ) .",
    "the second problem is that counters values are presented as 64-bit integers and therefore the majority of bits are constant for any reasonable amount of time .",
    "this can distort the measured entropies and lead to unrealistic low estimates , when we use all bits of a counter .",
    "let us assume a fictitious 64-bit counter @xmath20 , where the last bit of @xmath20 is random and all other bits of @xmath20 are zero , i.e. counter can have only two different 64-bit values @xmath21 and @xmath22 .",
    "it is easy to see that @xmath23 .",
    "however , splitting @xmath20 into bits and calculating the entropy from each bit of the counter yields : @xmath24 ( if we divide the above mentioned two 64-bit values to bits we get 128 bits in total , where 127 are equal to zero and only one is non - zero ) . splitting @xmath20 into bytes yields : @xmath25 ( we get 16 bytes , where one is equal to @xmath26 and remaining 15 bytes are equal to zero ) .",
    "we deal with these problems by preprocessing the values by a transformation @xmath27 .",
    "let @xmath28 be a @xmath29-bit vector .",
    "let @xmath30 be a positive integer such that @xmath30 divides @xmath29 .",
    "the transformation @xmath27 produces @xmath30-bit output from @xmath29-bit input :    @xmath31    the transformation is chosen with the aim of simplicity .",
    "notice that a complex transformation can distort the estimates in the opposite direction  even simple incremental counter transformed by a cryptographically strong hash function will look like ideal random source .",
    "the parameter @xmath30 can be interpreted as an appetite for getting as much randomness as possible from a single value .",
    "value of @xmath30 affects the estimated entropy . as noted earlier in the discussion on random counters vs. simple incremental counters , too high @xmath30 results in overestimating the entropy . on the other hand ,",
    "too small @xmath30 can be very pessimistic  for example , we lose @xmath32 bits of random data for each value of a truly random counter .    in order to deal with counters that increment",
    "regularly we apply difference operator to the sampled counter values @xmath33 : @xmath34 trivially , the difference of random , independent values yields again random and independent values . applying the difference operator allows measuring the entropy of change between successive samples of the counter .",
    "since the difference operator does not do any harm to `` good '' counters we apply it to all counters .",
    "moreover , after applying @xmath35 ( i.e. @xmath36 is applied first and @xmath27 second ) we group the obtained values into bytes .",
    "we take bytes as values of the random variable we use to measure the entropy .",
    "to represent negative numbers , introduced by the difference operator , we use their absolute value with a sign at the most significant bit position .",
    "a testing environment consisted of virtual pc emulated in vmware workstation .",
    "the virtual pc was created with 2 vcpu , 2 gb ram and default settings of virtualization platform .",
    "we used clean installation of windows 7 , the desktop operating system with the largest share world - wide @xcite .",
    "we implemented our experiments using .net platform .",
    "we also applied sp1 and all available updates ( hot - fixes ) provided by microsoft . during experiments the virtual pc was idle , with no user interaction , i.e. only the sampling application and default services were running .",
    "our first step was to eliminate weak counters and select promising ones .",
    "we proceed as follows :    1 .",
    "enumerate all operating system s performance counters .",
    "we identified 1367 counters .",
    "2 .   let us define a sampling round as follows : sample all counters and then wait for 20ms .",
    "3 .   repeat the sampling round to collect 10000 values for each counter . eliminate counters that are constant ,",
    "i.e. the entropy is zero .",
    "this resulted in 273 counters .",
    "re - sample remaining 273 counters in 100001 sampling rounds .",
    "eliminate counters that are constant  we got 266 counters after this elimination . + it is interesting that we have got counters non - constant in 10000 samples , but constant in 100001 samples .",
    "this anomaly was caused by some unknown rare event which happened while sampling the first 10000 samples and then never repeated during the first sampling and even the second , ten times longer , sampling period .",
    "this event influenced the following six counters ( they were constant before and after this event ) : *  cache , read aheads / sec \"  increased *  event tracing for windows , total number of distinct enabled providers \"  decreased *  event tracing for windows , total number of distinct pre - enabled providers \"  increased *  logicaldisk , split io / sec , _ total \"  increased *  physicaldisk , split io / sec , _ total \"  increased *  synchronization , exec .",
    "resource no - waits acqexcllite / sec , _ total \"  increased + the last `` strange '' counter was  memory , system code resident bytes \" ( see figure [ figc ] ) .",
    "this counter was oscillating in range from 2527232 to 2576384 for first 1643 samples and then settled down to the maximal value of the range ( 2576384 bytes @xmath37 629 pages of 4 kb ) and never changed again .",
    "apply the difference operator to obtained values ( now we have 100000 delta - values for each counter ) .",
    "after eliminating counters with constant delta - values , we obtained 263 counters .",
    "apply the transformation @xmath27 for @xmath38 , and group individual results into bytes .",
    "thus we get for each counter four separate sequences of bytes ( 12500 , 25000 , 50000 and 100000 bytes for @xmath39 respectively ) .",
    "we denote these sequences for counter @xmath40 as @xmath41 , @xmath42 , @xmath43 and @xmath44 . + setting @xmath30 too high yields low entropy per bit values .",
    "for example when @xmath45 no counter have value of @xmath46 per bit . for @xmath47",
    "no counter have value of @xmath48 per bit , i.e. no counters fill be in upper triangle on figure [ fig1 ] .",
    "experiments imply that decreasing @xmath30 generally increases scaled entropy value per bit .",
    "eliminate counters that are constant for some @xmath30 .",
    "none of the counters were eliminated in this step .",
    "we call all remaining 263 counters `` green '' .    the result of this process is summarized in table [ tab1 ]",
    ".    .overview of counters elimination . [ cols= \" <",
    ", > \" , ]     for further analysis we select all independent counters and one counter for each dependent group ( the counter with highest value of our combined entropy metric ) .",
    "this reduces the number of counters to @xmath49 , with total @xmath50 entropy @xmath51 bits per each 264ms  this is a conservative estimate assuming @xmath52 ( time includes 20ms of sleeping and 13ms of collecting counters for each one of eight rounds ) .",
    "virtual servers and pcs ( vdi ) are increasingly common in everyday reality of corporate it .",
    "we try to answer a natural question about independence of selected counters in this environment .",
    "we created a snapshot of our ( virtual ) experimental windows 7 system . after resuming the system , sampling starts immediately .",
    "we collect data for three resumptions from the same snapshot . similarly to section [ mutual ] we compute mutual information , this time it is the mutual information between samples of the same counter .",
    "moreover , in order to focus on potential correlations in short time span , the mutual information is calculated using floating window of length 1400 half - byte samples .",
    "this window corresponds to roughly 3 minutes , for sampling interval 20ms and @xmath52 .    before diving into more detailed analysis ,",
    "let us emphasize that the experiment showed mostly negligible mutual information of different runs of each counter . with exception of short spike of counter @xmath53 ( memory , pool nonpaged allocs ) ,",
    "all other mutual informations are way below 0.10 , the value we used to declare independence of two counters in section [ mutual ] .",
    "therefore , even starting sampling from the same snapshot will produce a sufficiently different content of entropy pool .    as we have three runs for every counter ,",
    "we compute the mutual information between all three pairs of these runs .",
    "then the minimum , the average ( arithmetic mean ) and the maximum of all obtained values are calculated .",
    "for comparison , we created three runs of 14 random , uniformly distributed and independent counters , and we computed their mutual information minimum , average and maximum .",
    "the comparison of real and random counters revealed that there are two types of counters .",
    "the first group contains counters with mutual information statistics similar to random counters ",
    "these are counters @xmath54 , for @xmath55 and we call them the upper group / counters .",
    "the second group of counters @xmath54 , for @xmath56 exhibits statistics even better than the random counters , therefore we call them lower group / counters .",
    "numerically , groups are divided by threshold value @xmath57 .",
    "if mutual information between all pairs of runs of the counter lies above the threshold , then the counter belongs in the upper group , otherwise it is in the lower group .",
    "the results for the selected 14 counters , divided into upper and lower groups , are presented in figure [ fig5 ] .",
    "as marked on y axis .",
    "upper and lower group counters are presented separately . ]",
    "unusual behavior of the lower counters at the beginning is caused by counter @xmath53 ( memory , pool nonpaged allocs ) and , to a lesser extent , counter @xmath58 ( memory , available bytes ) .",
    "other two counter from the lower group show stable behavior on entire interval . figure [ fig6 ] shows counter @xmath53 statistics  we can observe a sudden increase of mutual information roughly after 2.5 minutes after resumption .",
    "( memory , pool nonpaged allocs ) . ]",
    "another `` strange '' counter is counter @xmath58 .",
    "the mutual information is higher than threshold in the first 3 minutes ( but still less than average of random counters ) .",
    "after that , the values drop below threshold and stay there .",
    "( memory , available bytes ) . ]",
    "the lower group has distinctively lower mutual information statistics than completely random counters .",
    "this makes these counters slightly `` artificial '' and probably suspicious .",
    "we analyzed windows 7 performance counters as potential sources of randomness .",
    "generally , more counters and other entropy sources you include into your entropy pool the better chance of having sufficient entropy when you need it .",
    "our experiments yielded 19 promising counters .",
    "the final selection consists of 14 counters with enough entropy for practical purposes .",
    "their analysis allows us to draw the following conclusions :    * if your applications uses .net platform , some of the platform s performance counters are good entropy sources . * using 11 counters ( without .net counter ) yields @xmath59 bits per 240ms  a conservative estimate assuming @xmath52 ( time includes 20ms of sleeping and 10ms of collecting counters for each one of eight rounds ) .",
    "adding three .net counters increases the entropy to @xmath51 bits per 264ms ( @xmath52 , time includes 20ms of sleeping and 13ms of collecting counters for each one of eight rounds ) . even without detailed analysis of unpredictability of these sources",
    "we can conclude that windows performance counters are viable option to feed randomness pool for prngs .",
    "* interestingly , most of top counters are mutually independent . a strong mutual dependence between counters is usually observed with obvious pairs ( e.g. available memory in bytes and kilobytes ) . *",
    "selected counters are robust entropy sources in virtual environment .",
    "independent runs of the virtual pc from the same snapshot showed mutual independence of each counter s samples ( with exception of short spike of counter @xmath53 ) .",
    "we did our analysis only in a virtual environment .",
    "we expect that the experiment in a host environment ( physical hardware ) would show comparable or even better results .",
    "certainly , the analysis can be extended further by more thorough experiments ( e.g. considering various time interval for sampling , exploring mutual dependence of higher orders , changing preprocessing of sampled counters ) , using better entropy estimators ( e.g. nsb estimator ) , studying the possibilities of influencing the predictability of performance counters etc .",
    "14 nist : recommendation for random number generation using deterministic random bit generators , nist special publication 800 - 90a , elaine barker and john kelsey , 2012 .",
    "nist : annex c : approved random number generators for fips pub 140 - 2 , security requirements for cryptographic modules , draft , randall j. easter and carolyn french , 2012 .",
    "nist : a statistical test suite for random and pseudorandom number generators for cryptographic applications , nist special publication 800 - 22 , revision 1a , andrew rukhin et al . , 2010 .",
    "the entropy device , section 4  special files , freebsd kernel interfaces manual ( available at http://www.freebsd.org/cgi/man.cgi?query=random&sektion=4 ) random.c  a strong random number generator , linux kernel 3.2.10 source code ( available at http://lxr.linux.no/#linux+v3.2.10/drivers/char/random.c ) microsoft windows 7 cryptographic primitives library ( bcryptprimitives.dll ) security policy document , microsoft windows 7 operating system , fips 140 - 2 security policy document , version 2.2 , 2011 .",
    "( available at http://csrc.nist.gov/groups/stm/cmvp/documents/140-1/140sp/140sp1329.pdf ) microsoft windows server 2008 r2 kernel mode cryptographic primitives library ( cng.sys ) security policy document , microsoft windows server 2008 r2 operating system , fips 140 - 2 security policy document , version 2.3 , 2013 .",
    "( available at http://csrc.nist.gov/groups/stm/cmvp/documents/140-1/140sp/140sp1335.pdf ) p. lecuyer and r. simard : testu01 : a c library for empirical testing of random number generators .",
    "acm transactions on mathematical software , vol .",
    "33 , article 22 , 2007 .",
    "( available at http://www.iro.umontreal.ca/~simardr/testu01/tu01.html ) george marsaglia : diehard battery of tests of randomness , 1995 .",
    "( available at http://stat.fsu.edu/pub/diehard/ ) mike hamburg , paul kocher and mark e. marson : analysis of intel s ivy bridge digital random number generator .",
    "cryptography research , inc . , 2012 .",
    "( available at http://www.cryptography.com/public/pdf/intel_trng_report_20120312.pdf ) ilya nemenman , fariel shafee and william bialek : entropy and inference , revisited .",
    "advances in neural information processing systems 14 , mit press , 2002 .",
    "liam paninski : estimation of entropy and mutual information .",
    "neural computation 15 , pp . 1191-1253 , mit press , 2003 .",
    "net applications : desktop operating system market share , market share reports , july 2013 .",
    "( available at http://www.netmarketshare.com/ ) alfrd rnyi : on measures of entropy and information .",
    "fourth berkeley symp .",
    "stat . and probability , university of california press , pp .",
    "547 - 561 , 1961 .",
    "georg t. becker , francesco regazzoni , christof paar and wayne p. burleson : stealthy dopant - level hardware trojans , cryptographic hardware and embedded systems  ches 2013 , lecture notes in computer science volume 8086 , springer , 2013 , pp 197214 .",
    "martin geisler , mikkel krigrd and andreas danielsen : about random bits , 2004 .",
    "( available at http://www.daimi.au.dk/~mg/mamian/random-bits.pdf )"
  ],
  "abstract_text": [
    "<S> the security of many cryptographic constructions depends on random number generators for providing unpredictable keys , nonces , initialization vectors and other parameters . </S>",
    "<S> modern operating systems implement cryptographic pseudo - random number generators ( prngs ) to fulfill this need . </S>",
    "<S> performance counters and other system parameters are often used as a low - entropy source to initialize ( seed ) the generators . </S>",
    "<S> we perform an experiment to analyze all performance counters in standard installation of microsoft windows  7 operating system , and assess their suitability as entropy sources . besides selecting top 19 counters , we analyze their mutual information ( independence ) as well as robustness in the virtual environment . </S>",
    "<S> final selection contains 14 counters with sufficient overall entropy for practical applications .    </S>",
    "<S> * keywords : * entropy , windows performance counters , randomness , prng . </S>"
  ]
}