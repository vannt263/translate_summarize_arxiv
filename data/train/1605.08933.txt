{
  "article_text": [
    "in many scientific discoveries , a fundamental question is how to identify important features within or across sources that may interact with each other in order to achieve better understanding of the risk factors .",
    "for instance , there is growing evidence in genome - wide association studies supporting the presence of interactions between different genes or single nucleotide polymorphisms ( snps ) towards the risks of complex diseases @xcite .",
    "it has also been increasingly recognized that the aetiology of most common diseases relates to not only genetic and environmental factors , but also interactions between the genes and environment @xcite . in these problems , ignoring interactions by considering main effects alone can lead to an inaccurate estimate of the population attributable risk associated with these factors . identifying important interactions",
    "can also help improve model interpretability and prediction .",
    "interaction identification with large - scale data sets poses great challenges since the number of pairwise interactions increases quadratically with the number of covariates @xmath0 and that of higher - order interactions grows even faster . in the low - dimensional setting",
    ", one may include all possible interactions in a model and find significant ones by multiple testing or variable selection methods .",
    "this simple strategy , however , becomes impractical or even infeasible when @xmath0 is moderate or large , owing to rapid increase in dimensionality incurred by interactions .",
    "there is a growing literature developing regularization methods to identify important interactions and main effects , with a focus on the low- or moderate - dimensional setting .",
    "most of existing methods are rooted on a natural structural condition in certain applications , namely the strong or weak heredity assumption , and impose various constraints on coefficients to enforce the heredity assumption .",
    "specifically , the strong heredity assumption requires that an interaction between two variables be included in the model only if both main effects are important , while the weak one relaxes such a constraint to the presence of at least one main effect being important . to name a few , @xcite employed the non - negative garrote @xcite for structured variable selection and estimation by imposing multiple inequality constraints on coefficients .",
    "@xcite reparameterized the coefficients of interactions to enforce the strong heredity constraint and showed that the resulting method enjoys the oracle property when @xmath1 , where @xmath2 is the sample size .",
    "@xcite extended the lasso @xcite by adding a set of convex constraints to enforce the strong or weak heredity constraint .",
    "the aforementioned methods with delicate design on the interaction structure are effective in identifying important interactions when the number of covariates @xmath0 is not large . in the regime of ultra - high dimensionality ,",
    "that is , @xmath0 growing nonpolynomially with sample size @xmath2 , those methods may , however , become inefficient or even fail , because they need to deal with complex penalty structures or multiple inequality constraints and thus the computational cost can be excessively expensive . in addition",
    ", it is unclear whether the theoretical results on variable selection for those methods can still hold when @xmath0 is ultra high . to reduce the computational cost ,",
    "@xcite proposed a two - step recursive approach rooted on the strong heredity assumption to screen interactions based on the sure independence screening @xcite . @xcite introduced a forward selection based procedure to identify interactions in a greedy fashion under the heredity assumption and developed two algorithms ifort and iform .",
    "@xcite studied regularization methods based on the lasso for quadratic regression models under the heredity assumption and proposed a new algorithm ramp for interaction identification .",
    "although the heredity assumption is desired and natural in many applications , it can also be easily violated in some situations as documented in the literature .",
    "for example , @xcite discussed the interaction models displaying no main effects and examined the extent to which pure epistatic interactions whose loci do not display any single - locus effects could account for the variation of the phenotype . in the nature review paper @xcite",
    ", concerns were raised that many existing methods may miss pure interactions in the absence of main effects .",
    "efforts have already been made on detecting pure epistatic interactions in @xcite , where a real data example was presented to demonstrate the existence of such pure interactions . in these applications , methods that are released from the heredity constraint",
    "can enjoy better flexibility and be more suitable for models with pure epistatic interactions .    to address the challenges of interaction identification in ultra - high dimensions and broader settings , we present our ideas by focusing on the linear interaction model @xmath3 where @xmath4 is the response variable",
    ", @xmath5 is a @xmath0-vector of covariates @xmath6 s , @xmath7 is the intercept , @xmath8 s and @xmath9 s are regression coefficients for main effects and interactions , respectively , and @xmath10 is the mean zero random error independent of @xmath6 s .",
    "denote by @xmath11 and @xmath12 the true regression coefficient vectors for main effects and interactions , respectively . to ease the presentation , throughout the paper @xmath13",
    "is referred to as an _ important interaction _ if its regression coefficient @xmath14 is nonzero , and @xmath15 is called an _ active interaction variable _ if there exists some @xmath16 such that @xmath17 is an important interaction . under the above model",
    "setting , we suggest a new approach , called the interaction pursuit ( ip ) , for interaction identification using the ideas of feature screening and selection .",
    "the ip is a two - step procedure that first reduces the number of interactions and main effects to a moderate scale by a new feature screening approach , and then identifies important interactions and main effects in the reduced feature space , with interactions reconstructed based on the retained interaction variables , using regularization methods .",
    "a key innovation of ip is to screen interaction variables instead of interactions directly and thus the computational cost can be reduced substantially from a factor of @xmath18 to @xmath19 .",
    "our interaction screening step shares a similar spirit to the siri proposed in @xcite in the sense of detecting interactions by screening interaction variables .",
    "an important difference , however , lies in that siri was proposed under the sliced inverse index model and its theory relies heavily on the normality assumption .",
    "the main contributions of this paper are threefold .",
    "first , the proposed procedure is computationally efficient thanks to the idea of interaction variable screening .",
    "second , we provide theoretical justifications of the proposed procedure under mild interpretable conditions .",
    "third , our procedure can deal with more general model settings without requiring the heredity or normality assumption , which provides more flexibility in applications .",
    "in particular , two key messages that we try to deliver in this paper are that a separate screening step for interactions can significantly improve the screening performance if one aims at finding important interactions , and screening interaction variables can be more effective and efficient than screening interactions directly due to the noise accumulation .",
    "we also would like to emphasize that although we advocate a separate screening step for interactions , we have no intension to downgrade the importance of main effect screening or even a joint screening of main effects and interactions .",
    "in fact , our interaction screening idea can be coupled with any main effect or joint screening procedure to boost the performance of feature screening in interaction models .",
    "the rest of the paper is organized as follows .",
    "section [ sec : screening ] introduces a new feature screening procedure for interaction models and investigates the theoretical properties of the proposed screening procedure .",
    "we exploit the regularization methods to further select important interactions and main effects and study the theoretical properties on variable selection in section [ sec : selection ] .",
    "section [ sec : numerical ] demonstrates the advantage of our proposed approach through simulation studies and a real data example .",
    "we discuss some implications and extensions of our method in section [ sec : discussion ] .",
    "the proofs of all the results and technical details as well as some additional simulation studies are provided in the supplementary material .",
    "we begin with considering the problem of feature screening in interaction models with ultra - high dimensions .",
    "define three sets of indices @xmath20 the set @xmath21 contains all important interactions and the set @xmath22 consists of all active interaction variables , while the set @xmath23 is comprised of all important main effects .",
    "we combine sets @xmath22 and @xmath23 , and define the set of important features as @xmath24 .",
    "as demonstrated in section b of supplementary material , the sets @xmath22 , @xmath21 , and @xmath25 are invariant under affine transformations @xmath26 with @xmath27 and @xmath28 for @xmath29 .",
    "we aim at recovering interactions in @xmath21 and variables in @xmath25 and thus there is no issue of identifiability .      without loss of generality , assume that @xmath30 and @xmath31 for each random covariate @xmath6 .",
    "to ensure model identifiability and interpretability , we impose the sparsity assumption that only a small portion of the interaction and main effects are important with nonzero regression coefficients @xmath9 and @xmath8 in interaction model .",
    "our goal is to effectively identify all important interactions @xmath21 and important features @xmath25 , and efficiently estimate the regression coefficients in and predict the future response .",
    "clearly , @xmath21 is a subset of all pairwise interactions constructed from variables in @xmath22 .",
    "thus , as mentioned before , to recover the set of important interactions @xmath21 we first aim at screening the interaction variables while retaining active ones in set @xmath22 .",
    "let us develop some insights into the problem of interaction screening by considering the following specific case of interaction model : @xmath32 where @xmath33 is further assumed to be @xmath34 with covariance matrix @xmath35 having diagonal entries @xmath36 and off - diagonal entries @xmath37 .",
    "simple calculations show that @xmath38 for each @xmath39 .",
    "this entails that screening the main effects based on their marginal correlations with the response can easily miss the active interaction variable @xmath40 .",
    "an interesting observation is , however , that taking the squares of all variables leads to @xmath41 and @xmath42 for each @xmath43 , where the former is always larger than the latter in absolute value regardless of the value of @xmath37 .",
    "thus , the active interaction variable @xmath40 can be safely retained by ranking the marginal correlations between the squared covariates and the squared response , that is , @xmath44 and @xmath45 . by symmetry ,",
    "the same is true for the other active interaction variable @xmath46 .",
    "model is a specific model with only one interaction .",
    "the following proposition provides justification for more general interaction models .",
    "[ prop1 ] in interaction model with @xmath47 , it holds that for each @xmath39 , @xmath48    proposition [ prop1 ] shows that for the specific case of @xmath49 , the correlation between @xmath44 and @xmath45 is always nonzero as long as @xmath6 is an active interaction variable , regardless of whether or not @xmath6 is an important main effect .",
    "in contrast , such a correlation becomes zero if @xmath6 is neither an important main effect nor an active interaction variable .",
    "in fact , it is seen from that @xmath50 measures the cumulative effect of @xmath6 as an important main effect or an active interaction variable .",
    "motivated by the simple interaction model and proposition [ prop1 ] , we propose to identify the set of active interaction variables @xmath22 by first ranking the marginal correlations @xmath51 in magnitude , and then retaining the top ones with absolute correlations bounded from below by some positive threshold .",
    "this gives a new interaction screening procedure which is the first step of ip .",
    "more specifically , suppose we are given a sample @xmath52 of @xmath2 independent and identically distributed ( i.i.d . )",
    "observations from @xmath53 in interaction model .",
    "observe that @xmath54 with @xmath55 .",
    "denote by @xmath56 the empirical version of the population quantity @xmath57 by plugging in the corresponding sample statistics , based on the sample @xmath52 .",
    "then the screening step of ip is equivalent to thresholding the absolute values of @xmath56 s ; that is , we estimate the set of active interaction variables @xmath22 as @xmath58 for some threshold @xmath59 .",
    "the choice of threshold @xmath60 will be discussed later . based on the retained interaction variables in @xmath61",
    ", we can construct all pairwise interactions as @xmath62 it is worth mentioning that @xmath63 generally provides an overestimate of the set of important interactions @xmath21 , in the sense that some interactions in the constructed set @xmath63 may be unimportant ones .",
    "this is , however , not an issue for the purpose of interaction screening and will be addressed later in the selection step of ip .    for completeness",
    ", we also briefly describe our procedure for main effect screening .",
    "we adopt the sis approach in @xcite to screen unimportant main effects outside the set @xmath23 ; that is , we first calculate the marginal correlations @xmath64 and then keep the ones with magnitude at or above some positive threshold @xmath65 . since we have assumed @xmath30 and @xmath31 for each covariate @xmath6 , thresholding the marginal correlation between @xmath6 and @xmath4 is equivalent to thresholding @xmath66 .",
    "thus , we estimate the set @xmath23 by @xmath67 where @xmath68 is the sample version of the population quantity @xmath69 and @xmath70 is some threshold .",
    "finally the set of important features @xmath25 can then be estimated as @xmath71 .",
    "although our approach for estimating the set @xmath23 is the same as sis , the theoretical developments on the screening property for main effects are distinct from those in @xcite due to the presence of interactions in our model .",
    "we now turn our attention to the theoretical properties of the proposed screening procedure in ip .",
    "it is desirable for a feature screening procedure to possess the sure screening property @xcite , which means that all important variables are retained after screening with probability tending to one .",
    "we aim at establishing such a property for ip in terms of screening of both interactions and main effects . to this end , we need the following conditions .    [ con : sparsity ] there exist constants @xmath72 such that @xmath73 and @xmath74 , and @xmath75 with @xmath76 denoting the vector @xmath77-norm .",
    "[ con : xytail - new ] there exist constants @xmath78 such that for any @xmath79 , @xmath80 for each @xmath29 and @xmath81 , and @xmath82 are uniformly bounded away from zero .",
    "[ con : signal ] there exist some constants @xmath83 and @xmath84 such that @xmath85 and * @xmath86 . *    condition [ con : sparsity ] allows the numbers of important interactions and important main effects to grow with the sample size @xmath2 , and imposes an upper bound on the magnitude of true regression coefficients .",
    "see , for example , @xcite and @xcite for similar assumptions .",
    "clearly , condition [ con : sparsity ] entails that the number of active interaction variables is at most @xmath87 , that is , @xmath88 .    the first part of condition [ con : xytail - new ] is a usual assumption to control the tail behavior of the covariates and error , which is important for ensuring the sure screening property of our procedure .",
    "similar assumptions have been made in such work as @xcite , @xcite , and @xcite .",
    "the scenario of @xmath89 corresponds to the case of sub - gaussian covariates and error , including distributions with bounded support and light tails .",
    "condition [ con : signal ] puts constraints on the minimum marginal correlations , through different forms , for active interaction variables and important main effects , respectively .",
    "it is analogous to condition 3 in @xcite , and can be understood as an assumption on the minimum signal strength in the feature screening setting .",
    "smaller constants @xmath90 and @xmath91 correspond to stronger marginal signals .",
    "this condition is crucial for ensuring that the marginal utilities carry enough information about the active interaction variables and important main effects . to gain more insights into condition [ con : signal ] , consider the specific case of @xmath47 .",
    "note that @xmath92 are uniformly bounded by condition [ con : xytail - new ] .",
    "then it follows from proposition [ prop1 ] that the constraint of @xmath93 in condition [ con : signal ] is equivalent to that of @xmath94 where @xmath95 is some positive constant which may be different from @xmath96 .",
    "thus condition [ con : signal ] can be understood as constraints imposed indirectly on the true nonzero regression coefficients .    under these conditions ,",
    "the following theorem shows that the sample estimates of the marginal utilities are sufficiently close to the population ones with significant probability , and establishes the sure screening property for both interaction and main effect screening .",
    "[ th : sure screening - new ] ( a ) under conditions [ con : sparsity][con : xytail - new ] , if @xmath97 and @xmath98 , then for any @xmath99 , there exists some constant @xmath100 depending on @xmath101 such that for @xmath102 with @xmath103 , @xmath104    \\(b ) under conditions [ con : sparsity][con : xytail - new ] , if @xmath105 and @xmath106 , then for any @xmath99 , there exists some constant @xmath107 depending on @xmath101 such that @xmath108 for @xmath109 with @xmath110 .",
    "\\(c ) under conditions [ con : sparsity][con : signal ] and the choices of @xmath111 and @xmath112 , if @xmath113 and @xmath98 , then we have @xmath114 for @xmath115 with constants @xmath116 and @xmath117 given in and , respectively . in addition",
    ", it holds that @xmath118 where @xmath119 denotes the largest eigenvalue , @xmath120 , and @xmath121 for @xmath122 with @xmath123 .    comparing the results from the first two parts of theorem [ th : sure screening - new ] on interactions and main effects , respectively , we see that interaction screening generally requires more restrictive assumption on dimensionality @xmath0 .",
    "this reflects that the task of interaction screening is intrinsically more challenging than that of main effect screening .",
    "in particular , when @xmath124 , ip can handle ultra - high dimensionality up to @xmath125 it is worth mentioning that both constants @xmath116 and @xmath117 in the probability bounds  can be chosen arbitrarily large without affecting the order of @xmath0 and ranges of constants @xmath90 and @xmath91 .",
    "we also observe that stronger marginal signal strength for interaction variables and main effects , in terms of smaller values of @xmath90 and @xmath91 , can enable us to tackle higher dimensionality .",
    "the third part of theorem [ th : sure screening - new ] shows that ip enjoys the sure screening property for both interaction and main effect screening , and admits an explicit bound on the size of the reduced model after screening .",
    "more specifically , an upper bound of the reduced model size is controlled by the choices of both thresholds @xmath60 and @xmath65 , and the largest eigenvalues of the two population covariance matrices @xmath126 and @xmath35 .",
    "if we assume @xmath127 and @xmath128 for some constants @xmath129 , then with overwhelming probability the total number of interactions and main effects in the reduced model is at most of a polynomial order of sample size @xmath2 .",
    "the thresholds @xmath130 and @xmath131 given in theorem 1 depend on unknown constants @xmath96 , @xmath90 , and @xmath91 , and thus are unavailable in practice . in real applications , to estimate the set of active interaction variables",
    "@xmath22 , we sort @xmath132 , in decreasing order and then retain the top @xmath133 variables .",
    "this strategy is also widely used in the existing literature ; see , for example , @xcite , @xcite , @xcite , @xcite , and @xcite .",
    "the set of main effects @xmath23 is estimated similarly except that the marginal utility @xmath134 is used . following the suggestion in @xcite",
    ", one may choose the number of retained variables for each of sets @xmath22 and @xmath23 in a screening procedure as @xmath135 or @xmath136 $ ] with @xmath95 some positive constant , depending on the available sample size @xmath2 .",
    "the parameter @xmath95 can be tuned using some data - driven method such as the cross - validation .",
    "it is worth pointing out that our result is weaker than that in @xcite in terms of growth of dimensionality , where one can allow @xmath137 .",
    "this is mainly because they considered linear models without interactions , indicating the intrinsic challenges of feature screening in the presence of interactions .",
    "moreover , our assumptions on the distributions for the covariates and errors are more flexible .    the results in theorem [ th : sure screening - new ] can be improved in the case when the covariates @xmath6 s and the response @xmath4 are uniformly bounded .",
    "an application of the proofs for  in section d of supplementary material yields @xmath138 where @xmath139 is some positive constant . in this case",
    ", ip can handle ultra - high dimensionality @xmath140 with @xmath141 .",
    "we now focus on the problem of interaction and main effect selection in the reduced feature space identified by the screening step of ip . to ease the presentation , we rewrite interaction model ( [ eq : lm ] ) in the matrix form @xmath142 where @xmath143 is the response vector",
    ", @xmath144 is a parameter vector consisting of @xmath145 regression coefficients @xmath8 and @xmath146 , @xmath147 is the corresponding @xmath148 augmented design matrix incorporating the covariate vectors for @xmath6 s and their interactions in columns , and @xmath149 is the error vector . hereafter , for the simplicity of presentation and theoretical derivations , we slightly abuse the notation and still use @xmath150 and @xmath147 to denote the de - meaned response and column de - meaned design matrix , respectively , which leads to @xmath151 .",
    "denote by @xmath152 and @xmath153 the sets of retained interaction variables and main effects , respectively , and @xmath154 a subset of @xmath155 given by the features in @xmath71 and constructed interactions in @xmath63 based on @xmath61 as defined in . to estimate the true value @xmath156 of the parameter vector @xmath157",
    ", we can consider the reduced feature space spanned by the @xmath158 columns of the augmented design matrix @xmath147 in @xmath154 with @xmath159 the cardinality of @xmath160 , thanks to the sure screening property of ip shown in theorem [ th : sure screening - new ] .",
    "when the model dimensionality is reduced to a moderate scale @xmath161 , one can apply any favorite variable selection procedure for effective selection of important interactions and main effects and efficient estimation of their effects .",
    "there is a large literature on the developments of various variable selection methods . among all approaches , two classes of regularization methods , the convex ones ( e.g. , @xcite ) and",
    "the concave ones ( e.g. , @xcite ) , have been extensively investigated . to combine the strengths of both classes",
    ", @xcite introduced the combined @xmath162 and concave regularization method .",
    "such an approach can be understood as a coordinated intrinsic two - scale learning , in the sense that the lasso component plays the screening role , in terms of reducing the complexity of intrinsic parameter space , whereas the concave component plays the selection role , in terms of refined estimation .",
    "following @xcite , we consider the following combined @xmath162 and concave regularization problem @xmath163 where @xmath164 denotes a subvector of @xmath157 given by components in the complement @xmath165 of the reduced set @xmath154 , @xmath166 is the regularization parameter for the @xmath162-penalty , @xmath167 with @xmath168 , and @xmath169 is an increasing concave penalty function on @xmath170 indexed by regularization parameter @xmath171 . here ,",
    "@xmath172 , @xmath173 is the coefficient vector corresponding to the design matrix with each column rescaled to have @xmath174-norm @xmath175 , where @xmath176 and @xmath177 with @xmath178 , @xmath179 , is the scale matrix .",
    "the computational cost of solving the regularization problem in @xmath161 dimensions after screening from ultra - high scale to moderate scale is substantially reduced compared to that of solving the same problem in @xmath180 dimensions without screening . moreover , important theoretical challenges arise in investigating the asymptotic properties of the resulting regularized estimator for ip . @xcite",
    "considered linear models with deterministic design matrix and no interactions , whereas we now need to study the interaction model with random design matrix .",
    "the presence of both interactions and additional randomness requires more delicate analyses .",
    "we remark that although the combined @xmath162 and concave penalty is used in , one can in fact use any favorite variable selection method in the selection step of ip .",
    "in particular , note that does not automatically enforce the heredity constraint . if one believes in such constraint , other penalties , such as the ones in    @xcite , @xcite , and @xcite , can be used in the selection step of ip to achieve this goal . as specified in the introduction ,",
    "one major goal of our paper is to provide a methodological framework such that effective and efficient interaction screening can be conducted .",
    "so the penalty in is just for demonstration purpose .      before presenting the theoretical results , we state some mild regularity conditions that are needed in our analysis . without loss of generality ,",
    "assume that the first @xmath181 components of the true regression coefficient vector @xmath182 in are nonzero . throughout the paper , the regularization parameter for the @xmath162 component",
    "is fixed to be @xmath183 with @xmath184 some positive constant . some insights into this choice of @xmath185 will be provided later .",
    "denote by @xmath186 , @xmath187 , the hard - thresholding penalty , where @xmath188 denotes the positive part of a number .",
    "[ con : re - new ] there exist some constants @xmath189 such that with probability @xmath190 satisfying @xmath191 , it holds that @xmath192 , @xmath193 for @xmath194 with @xmath195 and @xmath196 a subvector of @xmath197 consisting of the @xmath198 largest components in magnitude , and @xmath199 s are bounded between @xmath200 .",
    "[ con : pen - new ] the concave penalty satisfies that @xmath201 on @xmath202 $ ] , @xmath203 for some constant @xmath204 , and @xmath205 is decreasing on @xmath206 $ ] .",
    "moreover , @xmath207 with @xmath208 .",
    "condition [ con : re - new ] is similar to condition 1 in @xcite for the case of deterministic design matrix , except that the design matrix is now random in our setting and also augmented with interactions .",
    "we provide in section [ sec : re condition ] some sufficient conditions ensuring that condition [ con : re - new ] holds .",
    "condition [ con : pen - new ] puts some basic constraints on the concave penalty @xmath169 as in @xcite .",
    "under these regularity conditions , the following theorem presents the selection properties of the ip estimator @xmath209 including an explicit bound on the number of falsely discovered signs @xmath210 , which provides a stronger measure on variable selection than the total number of false positives and false negatives .    [",
    "th : global ] assume that the conditions of part c ) of theorem [ th : sure screening - new ] and conditions [ con : re - new][con : pen - new ] hold , @xmath211 with @xmath212 , and @xmath213 is continuously differentiable .",
    "then the global minimizer @xmath214 of ( [ eq : imobj ] ) has the hard - thresholding property that each component is either zero or of magnitude larger than @xmath215 , and with probability at least @xmath216 , it satisfies simultaneously that @xmath217 ,     \\\\     & \\emph{{\\text{fs}}}(\\widehat{\\boldsymbol\\theta } )         = o\\left\\{\\kappa^{-4 } ( \\lambda_0/\\lambda)^2s\\right\\},\\end{aligned}\\ ] ] and furthermore @xmath218 if @xmath219 , where @xmath220 is some positive constant .",
    "moreover , the same results hold with probability at least @xmath221 for the regularized estimator @xmath214 without prescreening , that is , without the constraint @xmath222 in ( [ eq : imobj ] ) .    the results in theorem [ th : global ] also apply to the regularized estimator with @xmath223 and @xmath224 , that is , without any screening of variables .",
    "theorem [ th : global ] shows that if the tuning parameter @xmath225 satisfies @xmath226 , then the number of falsely discovered signs @xmath227 is of order @xmath228 and thus the false sign rate @xmath229 is asymptotically vanishing with probability tending to one .",
    "we also observe that the bounds for prediction and estimation losses are independent of the tuning parameter @xmath225 for the concave penalty .",
    "as shown in theorem [ th : global ] , the regularization parameter for the @xmath162 component @xmath183 plays a crucial role in characterizing the rates of convergence for the regularized estimator @xmath214 .",
    "such a parameter basically measures the maximum noise level in interaction models .",
    "in particular , the exponent @xmath230 is a key parameter that reflects the level of difficulty in the problem of interaction selection .",
    "this quantity is determined by three sources of heavy - tailedness : covariates themselves , their interactions , and the error . to simplify the technical presentation , in this paper we have focused on the more challenging case of @xmath212 .",
    "such a scenario includes two specific cases : 1 ) sub - gaussian covariates and sub - gaussian error , that is , @xmath89 and 2 ) sub - gaussian covariates and sub - exponential error , that is , @xmath231 .",
    "we remark that in the lighter - tailed case of @xmath232 , one can simply set @xmath233 and the results in theorem [ th : global ] can still hold for this choice of @xmath185 by resorting to lemma [ lemma - hao - zhang - extend ] and similar arguments in the proof of theorem [ th : global ] .",
    "since condition [ con : re - new ] is a key assumption for proving theorem [ th : global ] , we provide some sufficient conditions that ensures this assumption on the augmented random design matrix @xmath176 . denote by @xmath234 the population covariance matrix of the augmented covariate vector consisting of @xmath0 main effects @xmath6 s and @xmath235 interactions @xmath13 s .",
    "[ con : eigen ] there exists some constant @xmath236 such that for @xmath194 , @xmath237 where @xmath195 and @xmath196 is a subvector of @xmath197 consisting of the @xmath198 largest components in magnitude .",
    "condition [ con : eigen ] is satisfied if the smallest eigenvalue of @xmath234 is assumed to be bounded away from zero .",
    "such a condition is in fact much weaker than the minimum eigenvalue assumption , since it is the population version of a mild sparse eigenvalue assumption and the restricted eigenvalue assumption .",
    "the following theorem shows that under some mild assumptions , condition [ con : re - new ] holds for the full augmented design matrix @xmath147 and thus holds naturally for any @xmath238 sub - design matrix with @xmath239 and the sure screening property .",
    "[ th : re condition ] assume that condition [ con : eigen ] holds , there exist some constants @xmath240 such that for any @xmath79 , @xmath80 for each @xmath39 , @xmath241 , and @xmath242 with constant @xmath243 . then condition [ con : re - new ] holds with @xmath244 .",
    "in this section , we design two simulation examples to verify the theoretical results and examine the finite - sample performance of the suggested approach ip . we also present an analysis of a prostate cancer data set .",
    "we start with comparing ip with several recent feature screening procedures : the sis , dc - sis @xcite , and siri @xcite .",
    "the siri is an iterative procedure that alternates between a large - scale variable screening step and a moderate - scale variable selection step when the dimensionality @xmath0 is large .",
    "since all other screening methods are non - iterative , in this section , we compare the initial screening step of siri with other methods and name the screening only procedure as siri*. the full iterative siri will be included in section [ sec : selection ] later for comparison of variable selection .",
    "siri * , sis , and dc - sis each return a set of variables without distinguishing between important main effects and active interaction variables .",
    "thus , for each method , we construct interactions using all possible pairwise interactions of the recruited variables . by doing so , the strong heredity assumption is enforced .",
    "we name the resulting procedures as siri*2 , sis2 , and dc - sis2 to distinguish them from their original versions .    for ip ,",
    "as mentioned in section [ sec : screening - property ] , we retain the top @xmath245 $ ] variables in each of sets @xmath61 and @xmath246 defined in ( [ eq : ahat ] ) and ( [ eq : bhat ] ) , respectively .",
    "the features in the union set @xmath247 are used as main effects while variables in set @xmath61 are used to build interactions in the selection step of ip . to ensure a fair comparison , the numbers of variables kept in siri*2 , sis2 , and dc - sis2 are all equal to the cardinality of @xmath160 , which is up to @xmath248 $ ] .    * example 1 * ( gaussian distribution ) .",
    "we consider the following four interaction models linking the covariates @xmath6 s to the response @xmath4 :    * m1 ( strong heredity ) : @xmath249 , * m2 ( weak heredity ) : @xmath250 , * m3 ( anti - heredity ) : @xmath251 , * m4 ( interactions only ) : @xmath252 ,    where the covariate vector @xmath253 with @xmath254 and the errors @xmath255 , @xmath256 , @xmath257 , and @xmath258 are independent of @xmath33 .",
    "the first two models m1 and m2 satisfy the heredity assumption ( either strong or weak ) , while the last two m3 and m4 do not obey such an assumption .",
    "different levels of error variance are considered since the difficulty of feature screening varies across the four models . a sample of @xmath2 i.i.d",
    ". observations was generated from each of the four models .",
    "we further considered four different settings of @xmath259 , @xmath260 , @xmath261 , and @xmath262 , and repeated each experiment 100 times .",
    "[ table [ tab : ex1screen ] about here . ]",
    "table [ tab : ex1screen ] lists the comparison results for all screening methods in recovering each important interaction or main effect , and retaining all important ones . for model m1 satisfying the strong heredity assumption ,",
    "all procedures performed rather similarly and all retaining percentages were either equal or close to 100% .",
    "both dc - sis2 and ip performed similarly and improved over sis2 and siri*2 in model m2 in which the weak heredity assumption holds . in models",
    "m3 and m4 , ip significantly outperformed all other methods in detecting interactions across all four settings , showing its advantage when the heredity assumption is not satisfied .",
    "we also observe that sis2 failed to detect interactions , whereas siri*2 improved over dc - sis2 in these two models .",
    "these results suggest that a separate screening step should be designed specifically for interactions to improve the screening accuracy , which is indeed one of the main innovations of ip .",
    "* example 2 * ( non - gaussian distribution ) .",
    "the second example adopts the same four models as in example 1 , but with different distributions for the covariates @xmath6 s and error @xmath10 .",
    "we added an independently generated random variable @xmath263 to each covariate @xmath6 as given in example 1 to obtain new covariates , where @xmath263 s are i.i.d . and follow the uniform distribution on @xmath264 $ ] .",
    "the errors @xmath265 , @xmath266 , @xmath267 , and @xmath268 are independent of @xmath33 .    [ table [ tab : ex2screen ] about here . ]",
    "the screening results of all the methods are summarized in table [ tab : ex2screen ] .",
    "similarly as in example 1 , ip outperformed sis2 in interaction screening .",
    "when the heredity assumption is satisfied , ip performed comparably to dc - sis2 . in particular , both approaches were better than sis2 and siri*2 when the weak heredity assumption is satisfied .",
    "the improvement of ip over all other methods in detecting interactions became substantial when the heredity assumption is violated .",
    "we also calculated the overall signal - to - noise ratio ( snr ) and the individual snr for each model , where the former is defined as @xmath269 with @xmath270 the augmented covariate vector defined in section [ sec : reducedmodel ] , @xmath10 the error term and @xmath157 given in model ( [ eq : lm : mat ] ) , and the latter is defined similarly by replacing @xmath271 with the variance of each individual term .",
    "the overall and individual snrs for the models considered in both examples 1 and 2 are listed in table [ tab : snr ] . in particular",
    ", we see that although the overall snrs are at decent levels , the individual ones are weaker , reflecting the general difficulty of retaining all important features for screening .",
    "[ table [ tab : snr ] about here . ]",
    "we further assess the variable selection performance of ip . for all screening methods but siri*2 , with each data set generated in examples 1 and 2 , we can employ regularization methods such as the lasso and the combined @xmath162 and concave method to select important interactions and main effects after the screening step .",
    "as shown in @xcite , different choices of the concave penalty gave rise to similar performance .",
    "we thus implemented the combined @xmath162 and sica ( @xmath162+sica ) for simplicity .",
    "the approach of sis2 followed by lasso is referred to as sis2-lasso for short .",
    "all other combinations of screening and selection methods are defined similarly .",
    "we also paired up the hiernet @xcite with the ip for interaction identification .",
    "for siri , we used the full iterative procedure as described in @xcite .",
    "since siri only returns a set of important variables , we added an additional refitting step using the selected variables to calculate model performance measures .",
    "we also included additional competitor methods ifort and iform in @xcite and ramp in @xcite in our simulation studies .",
    "the oracle procedure based on the true underlying interaction model was used as a reference point for comparisons . the cross - validation ( cv )",
    "was used to select tuning parameters for all the methods , except that the bic was applied to @xmath162+sica related procedures for computational efficiency since two regularization parameters are involved .",
    "to evaluate the variable selection performance of each method , we employed three performance measures .",
    "the first one is the prediction error ( pe ) , which was calculated using an independent test sample of size 10,000 .",
    "the second and third measures are the numbers of false positives ( fp ) and false negatives ( fn ) , which are defined as the numbers of included noise variables and missed important variables in the final model , respectively .",
    "[ tables [ tab : ex1select ] and [ tab : ex2select ] about here . ]",
    "table [ tab : ex1select ] presents the medians and robust standard deviations ( rsd ) of these measures based on 100 simulations for different models in example 1 .",
    "the rsd is defined as the interquartile range ( iqr ) divided by 1.34 .",
    "we used the median and rsd instead of the mean and standard deviation since these robust measures are better suited to summarize the results due to the existence of outliers .",
    "when the strong heredity assumption holds ( model m1 ) , both dc - sis2-@xmath162+sica and ip-@xmath162+sica followed closely the oracle procedure , and outperformed the other methods in terms of pe , fp , and fn across all four settings . in model m2 with the weak heredity assumption ,",
    "variable selection methods based on both dc - sis2 and ip performed fairly well . in the cases when the heredity assumption does not hold ( models m3 and m4 ) , the ip-@xmath162+sica still mimicked the oracle procedure and uniformly outperformed the other methods over all settings .",
    "the inflated rsds , relative to medians , in model m4 were due to the relatively low sure screening probabilities ( see tables [ tab : ex1screen ] and [ tab : ex2screen ] ) .",
    "when the sure screening probability is low , a nonnegligible number of replications can have nonzero false negatives , which inflated the corresponding prediction errors .",
    "the comparison results of variable selection for example 2 are summarized in table [ tab : ex2select ] .",
    "the conclusions are similar to those for example 1 .",
    "in addition , we illustrate our procedure ip through an analysis of the prostate cancer data studied originally in @xcite and analyzed also in @xcite and @xcite .",
    "this data set , which is available at http://www.broad.mit.edu/cgi-bin/cancer/datasets.cgi , contains @xmath272 samples with @xmath273 from the tumor group and @xmath274 from the normal group , each of which records the expression levels measured for @xmath275 genes .",
    "@xcite applied a four - step procedure to preprocess the data .",
    "their procedure includes the truncation of intensities to make them positive , the removal of genes having little variation in intensity , the transformation of intensities to base @xmath276 logarithms , and the standardization of each data vector to have zero mean and unit variance .",
    "an application of the four - step procedure results in a total of @xmath277 genes .",
    "we treated the disease status as the response and the resulting @xmath278 genes as covariates .",
    "the data set was randomly split into a training set and a test set .",
    "each training set consists of @xmath279 samples from the tumor group and @xmath280 samples from the normal group , and the test set is formed by the remaining samples . for each split",
    ", we applied the screening method ip to the training data and retained the top @xmath281 = [ 25.4 c]$ ] genes in each of sets @xmath61 and @xmath246 with @xmath95 chosen from the grid @xmath282 . for sis2 and dc - sis2 , we retained the top @xmath283 variables in the screening step . because of the limited sample size , to increase the stability we constructed interactions in a more conservative way by using variables in set @xmath160 instead of only @xmath61 to build interactions in the selection step of ip .",
    "in addition , to overcome the difficulty caused by potential high collinearity , in our real data analysis we used the elastic net penalty introduced in @xcite .",
    "we then tuned @xmath95 in terms of minimizing the classification error calculated using the test data .",
    "we also repeated the random split 100 times .",
    "[ table [ tab : real ] about here . ]    three competing methods sis2-enet , dc - sis2-enet , and ip - enet were considered , where sis2-enet denotes the approach of sis2 followed by the elastic net , and the latter two methods are defined similarly . since the same penalty is used for the step of variable selection , the difference in performance should come mainly from the screening step .",
    "table [ tab : real ] summarizes the classification results and median model sizes for each method .",
    "we observe that the approach of ip - enet yielded lower classification errors .",
    "paired @xmath284-tests of classification errors on the 100 splits of ip - enet against sis2-enet and dc - sis2-enet gave @xmath0-values @xmath285 and @xmath286 , respectively .",
    "these results show that our proposed method outperformed significantly sis2-enet and dc - sis2-enet in classification error .",
    "[ table [ genes ] about here . ]",
    "we also present in table [ genes ] the top 10 interactions and top 10 main effects that were most frequently selected over 100 splits .",
    "we see from table [ genes ] that a set of genes , such as serinc5 , hpn , hspd1 , lmo3 , and tarp , were selected by all methods as main effects , revealing that those genes may play a significant role in the etiology of prostate cancer . for example , @xcite claimed hepsin ( hpn ) as one of the most consistently overexpressed genes in prostate cancer .",
    "in addition , evidence of the association between tarp gene variants and prostate cancer risk has been shown in @xcite , @xcite , and @xcite .",
    "note that the gene erg was missed by both sis2-enet and dc - sis2-enet in the top 10 main effects , but it was selected by ip - enet as a main effect and part of an interaction ( slc7a1@xmath287erg ) .",
    "there are a wide range of studies investigating the effect of erg on prostate cancer @xcite .",
    "the most frequently selected interaction dpt@xmath287s100a4 by sis2-enet and dc - sis2-enet is also among the top 10 list by ip - enet .",
    "two more interactions , rarres2@xmath287klk3 and maf@xmath287nell2 , are also among the top 10 lists by both ip - enet and sis2-enet . however , some interactions involving prkdc ( prkdc@xmath287cfd and prkdc@xmath287klk3 ) were very often selected by ip - enet but missed by the other two methods",
    ". there are studies showing that prkdc is associated with prostate cancer ( mccarthy et al . , 2013 ) .",
    "such a finding favors the results of ip that the interactions prkdc@xmath287cfd and prkdc@xmath287klk3 were identified to be associated with the phenotype .",
    "we have considered in this paper the problem of interaction identification in ultra - high dimensions .",
    "the proposed method ip based on a new interaction screening procedure and post - screening variable selection is computationally efficient , and capable of reducing dimensionality from a large scale to a moderate one and recovering important interactions and main effects . to simplify the technical presentation ,",
    "our analysis has been focused on the linear pairwise interaction models .",
    "screening for main effects in more general model settings has been explored by many researchers ; see , for example , @xcite , @xcite , @xcite , and @xcite .",
    "it would be interesting to extend the interaction screening idea of ip to these and other more general model frameworks such as the generalized linear models , nonparametric models , and survival models with interactions .",
    "the key idea of ip is to use different marginal utilities to screen interactions and main effects separately . as such",
    ", it can suffer from the same potential issues as the sis .",
    "first , some noise interactions or main effects that are highly correlated with the important ones can have higher marginal utilities and thus priority to be selected than other important ones that are relatively weakly related to the response .",
    "second , some important interactions or main effects that are jointly correlated but marginally uncorrelated with the response can be missed after screening . to address these issues , we next briefly discuss two extensions of ip that enable us to exploit more fully the joint information among the covariates .",
    "our first extension of ip , the iterative ip ( iip ) , is motivated by the idea of two - scale learning with the iterative sis ( isis ) in @xcite and @xcite .",
    "the iip works as follows by applying large - scale screening and moderate - scale selection in an iterative fashion .",
    "first , apply ip to the original sample @xmath52 to obtain two sets @xmath288 of interactions and @xmath289 of main effects , and construct a set @xmath290 of interaction variables based on @xmath288 as in ( [ intvarsets ] ) .",
    "second , update the sets of candidate interaction variables as @xmath291 and candidate main effects as @xmath292 , treat the residual vector from the previous iteration as the new response , and apply ip to the updated sample to obtain new sets @xmath293 , @xmath294 , and @xmath295 defined similarly as before .",
    "third , iteratively update the feature space for candidate interaction variables and main effects and the response , and apply ip to the updated sample to similarly obtain sequences of sets @xmath296 , @xmath297 , and @xmath298 , until the total number of selected interactions and main effects in sets @xmath299 s and @xmath300 s reaches a prespecified threshold .",
    "fourth , finally select important interactions and main effects using a regularization method in the reduced feature space given by the union of @xmath299 s and @xmath300 s .",
    "the second extension of ip , the conditional ip ( cip ) , exploits the idea of the conditional sis ( csis ) in @xcite , which replaces the simple marginal correlation with the conditional marginal correlation to assess the importance of covariates when some variables are known in advance to be important .",
    "suppose we have some prior knowledge that two given sets @xmath301 , @xmath302 contain some active interaction variables and important main effects , respectively . for interaction screening",
    ", the cip regresses the squared response @xmath45 on each squared covariate @xmath303 with @xmath304 outside @xmath301 by conditioning on @xmath305 , and retains top ones in the conditional marginal utilities as interaction variables .",
    "similarly , in main effect screening it employs marginal regression of the response @xmath4 on each covariate @xmath15 with @xmath304 outside @xmath306 conditional on @xmath307 .",
    "after screening , cip further selects important interactions and main effects using a variable selection procedure in the reduced feature space .",
    "the approach of cip can also be incorporated into iip by conditioning on selected variables in previous steps when calculating the marginal utilities along the course of iteration .",
    "cheng , m.  y , honda , t. , li , j. and peng , h. ( 2014 ) , `` nonparametric independence screening and structural identification for ultra - high dimensional longitudinal data , '' _ the annals of statistics _ , 42 , 18191849 .",
    "cheng , w.  s. , giandomenico , v. , pastan , i. and essand , m. ( 2003 ) , `` characterization of the androgen - regulated prostate - specific t cell receptor gamma - chain alternate reading frame protein ( tarp ) promoter , '' _ endocrinology _ , 144 , 34333440 .",
    "furusato , b. , tan , s. h. , young , d. , dobi , a. , sun , c. , mohamed , a. a. , thangapazham , r. , chen , y. , mcmaster , g. , sreenath , t. , petrovics , g. , mcleod , d. g. , srivastava , s. and sesterhenn , i. a. ( 2010 ) , `` erg oncoprotein expression in prostate cancer : clonal progression of erg - positive tumor cells and potential for erg - based stratification , '' _ prostate cancer and prostatic diseases _ , 13 , 228237 .",
    "hillerdal , v. , nilsson , b. , carlsson , b. , eriksson , f. and essand , m. ( 2012 ) , `` t cells engineered with a t cell receptor against the prostate antigen tarp specifically kill hla - a2 + prostate and breast cancer cells , '' _ proceedings of the national academy of sciences _ , 109 , 1587715881 .",
    "klezovitch , o. , risk , m. , coleman , i. , lucas , j. m. , null , m. , true , l. d. , nelson , p. s. and vasioukhin , v.(2008 ) , `` a causal role for erg in neoplastic transformation of prostate epithelium , '' _ proceedings of the national academy of sciences _ , 105 , 21052110 .",
    "musani , s.  k. , shriner , d. , liu , n. , feng , r. , coffey , c.  s. , yi , n. , tiwari , h.  k. and allison , d.  b. ( 2007 ) , `` detection of gene@xmath287gene interactions in genome - wide association studies of human population data , '' _ human heredity _ , 63 , 6784 .",
    "oh , s. , terabe , m. , pendleton , c.  d. , bhattacharyya , a. , bera , t.  k. , epel , m. , reiter , y. , phillips , j. , linehan , w.  m. , kasten - sportes , c. , pastan , i. and berzofsky , j.  a. ( 2004 ) , `` human ctls to wild - type and enhanced epitopes of a novel prostate and breast tumor - associated protein , tarp , lyse human breast cancer cells , '' _ cancer research _",
    ", 64 , 26102618 .",
    "ritchie , m.  d. , hahn , l.  w. , roodi , n. , bailey , r. , dupont , w.  d. , parl , f.  f. and moore , j.  h. ( 2001 ) , `` multifactor - dimensionality reduction reveals high - order interactions among estrogen - metabolism genes in sporadic breast cancer , '' _ the american journal of human genetics _ , 69 , 138147 .",
    "saleem , m. , kweon , m.  h. , johnson , j.  j. , adhami , v.  m. , elcheva , i. , khan , n. , bin hafeez , b. , bhat , k.  m. , sarfaraz , s. , reagan - shaw , s. , spiegelman , v.  s. , setaluri , v. and mukhtar , h. ( 2006 ) , `` s100a4 accelerates tumorigenesis and invasion of human prostate cancer through the transcriptional regulation of matrix metalloproteinase 9 , '' _ proceedings of the national academy of sciences _ , 103 , 1482514830 .",
    "singh , d. , febbo , p.  g. , ross , k. , jackson , d.  g. , manola , j. , ladd , c. , tamayo , p. , renshaw , a.  a. , damico , a.  v. , richie , j.  p. , lander , e.  s. , loda , m. , kantoff , p.  w. , golub , t.  r. and sellers , w.  r. ( 2002 ) , `` gene expression correlates of clinical prostate cancer behavior , '' _ cancer cell _ , 1 , 203209 .",
    "wolfgang , c.  d. , essand , m. , vincent , j.  j. , lee , b. and pastan , i. ( 2000 ) , `` tarp : a nuclear protein expressed in prostate and breast cancer cells derived from an alternate reading frame of the t cell receptor gamma chain locus , '' _ proceedings of the national academy of sciences _ , 97 , 94379442 .",
    "xu , j. , langefeld , c.  d. , zheng , s.  l. , gillanders , e.  m. , chang , b .-",
    ", isaacs , s.  d. and others ( 2004 ) , `` interaction effect of pten and cdkn1b chromosomal regions on prostate cancer linkage , '' _ human genetics _",
    ", 115 , 255262 ."
  ],
  "abstract_text": [
    "<S> understanding how features interact with each other is of paramount importance in many scientific discoveries and contemporary applications . yet </S>",
    "<S> interaction identification becomes challenging even for a moderate number of covariates . in this paper , we suggest an efficient and flexible procedure , called the interaction pursuit ( ip ) , for interaction identification in ultra - high dimensions . </S>",
    "<S> the suggested method first reduces the number of interactions and main effects to a moderate scale by a new feature screening approach , and then selects important interactions and main effects in the reduced feature space using regularization methods . compared to existing approaches , our method screens interactions separately from main effects and </S>",
    "<S> thus can be more effective in interaction screening . under a fairly general framework </S>",
    "<S> , we establish that for both interactions and main effects , the method enjoys the sure screening property in screening and oracle inequalities in selection . our method and theoretical results </S>",
    "<S> are supported by several simulation and real data examples .    </S>",
    "<S> _ running title _ : interaction pursuit    _ key words _ : big data ; interaction pursuit ; interaction screening ; interaction selection ; regularization ; sure independence screening ; two - scale learning </S>"
  ]
}