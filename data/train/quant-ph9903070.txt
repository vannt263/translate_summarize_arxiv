{
  "article_text": [
    "there exist problems where the algorithm that solves them scales exponentially as the size of the input is increased , for example computing all possible chess games , factoring a very large number , etc .",
    "this dependence on the size makes them physically unsolvable for large enough inputs .",
    "quantum algorithms have been invented to bypass this problem , like shor s @xcite that turns tractable the problem of factoring numbers , and grover s @xcite that improves the classical search for an item in a phone book .",
    "in fact , the classical search algorithm does not scale exponentially .",
    "rather , it is linear in the size of the phone book ; grover s quantum algorithm improves it to a square  root dependence .",
    "recently , an experimental application of a quantum algorithm has been implemented @xcite , and agreement between theory and experiment was found .",
    "nevertheless , the strength of a quantum algorithm is also its weakness : a quantum computer performs simultaneous operations over large superpositions of states , which are very sensitive to decoherence .",
    "fortunately , quantum correction codes have been developed @xcite with which a quantum computer can recover from errors in the presence of moderate decoherence .",
    "but these quantum correction codes are subject themselves to decoherence , and it is not fully understood how decoherence affects the correction itself . in this work , we study the intrinsic robustness of grover s algorithm , when quantum correction codes are not implemented .",
    "any classical algorithm for finding an item in a randomly ordered phone book ( whether deterministic or probabilistic ) requires @xmath1 steps on the average , because the only way to perform the search is to analyze each item one by one until the searched  for item is found .",
    "recently , grover invented a quantum algorithm @xcite that runs like @xmath2 .",
    "let us review it briefly .    in a phone book with @xmath3 entries ,",
    "each item can be represented by a binary label of length @xmath4 or , equivalently , by a pure state of @xmath4 spin @xmath5 particles .",
    "the algorithm is based on constructing a coherent superposition of all these states , and applying repeatedly certain unitary transformations to it .",
    "assume , for concreteness , that the item we are looking for is represented by the state @xmath6 , i.e. by @xmath7 spin  down particles .",
    "the algorithm works via the repeated action of the unitary steps below , starting from an initial state which we take to be the full coherent superposition of all states in the system , namely @xmath8 of course , one could start equally well with some other initial state @xcite .",
    "the two unitary steps to be repeated are the following :    first , invert the phase of the looked  for state trough the unitary transformation @xmath9    secondly , invert , with respect to the average , the phase of the looked  for state trough the unitary diffusion matrix @xmath10 these two steps are equivalent to the action of the following single unitary transformation : @xmath11    when the unitary transformation @xmath12 has been applied @xmath13 times to the initial state @xmath14 , the new quantum state will be @xmath15 the action of @xmath12 on the initial state @xmath14 yields only two distinct amplitudes @xmath16 and @xmath17 , whereby it is possible to recast the recursion relation in just two dimensions .",
    "the restriction of @xmath12 to this two  dimensional subspace will be denoted by @xmath18 .",
    "explicitly , the amplitudes @xmath16 and @xmath17 are given by the recursion formula @xmath19 the two  dimensional matrix @xmath18 has eigenvalues @xmath20 , with @xmath21 , whereby @xmath22 @xmath23    from ( [ 7 ] ) , the probability of finding the state we are looking for if we measure @xmath24 is thus @xmath25 with the change of variables @xmath26 , @xmath27 can be written as @xcite : @xmath28    clearly , @xmath27 is periodic , with maxima at @xmath29 the first maximum for large @xmath30 is approximately at @xmath31 and @xmath32 . the number of steps required to find the state with almost certainty scales like @xmath33 , as shown in ( [ 12 ] ) .",
    "as stated in the introduction , quantum correction codes have been developed and it is supposed that in the presence of low but physically realistic levels of noise they are useful @xcite .",
    "these codes can be implemented only if a small enough subset of the quantum computer s q - bits undergo errors , and when the probability of occurrence of an error in the computation is lower than a certain bound . on the other hand ,",
    "the real effect of the noise introduced by these correction codes over the original algorithm is not completely known , because they are quantum computations too .",
    "hopefully , such errors are small and tractable .",
    "but what happens if they are not ? or , even worse , what happens if many q - bits undergo errors ?",
    "is it still possible to make sense of the computation under this hypothetical noisy situation when quantum correction codes do not suffice or can not be implemented ?",
    "if it does , how much noise the algorithm can bear with on its own ?",
    "we now turn to the answer to these questions .    in the particular case of grover s algorithm",
    ", there is a simple way to model noise , because of the explicit recursion formula ( [ 6 ] ) for the amplitudes of the searched  for state .",
    "suppose that in each step of the algorithm , a white or gaussian noise modifies the state of the whole phone book according to @xmath34 { \\rm { , } }   \\label{13}\\ ] ] where @xmath18 is defined in ( [ 6 ] ) , and both @xmath35 and @xmath36 are noise , determined randomly by the standard deviation @xmath37 ( common to both , for simplicity ) of their gaussian distribution .",
    "of course , the new state @xmath38 is appropriately normalized ( that s what the denominator @xmath39 is for ) .",
    "explicitly , @xmath40 where @xmath41 and @xmath42 are computer  generated random variables uniformly distributed over the interval @xmath43 $ ] .",
    "the two gaussian variables @xmath35 and @xmath36 are mutually independent , and change , randomly , from one iteration of equation ( [ 13 ] ) to the next . note that when @xmath44 , @xmath45 and @xmath46 are always zero and thus there is no noise .    a crucial _ caveat _ is in order here : note that we introduce only two different errors , one for the searched  for state and one for all the other pure states .",
    "this approximation is physically unrealistic , but worthy of study .",
    "the full noisy situation would call for allowing @xmath30 different random variables to be added independently to each of the @xmath30 components of the state vector , instead of restricting ourselves to noise in the two  dimensional subspace where @xmath18 ( instead of @xmath12 ) acts .",
    "now , we want to find the maximal allowed noise , quantified by @xmath37 , in terms of both ( a ) the size @xmath30 of the phone book and ( b ) a given probability @xmath47 for finding the searched - for state after a suitable number of iterations .",
    "if we set @xmath48 , then of course @xmath49 can only be zero .",
    "as we allow for a decreased certainty of finding the result , and thus decrease @xmath47 , the algorithm can bear with an increasing amount of noise . in the absurd limit of being happy with @xmath50 , which means we will not find the result ,",
    "then any amount of noise is allowed . of course",
    ", for any given @xmath51 , a large enough noise will destroy the algorithm . in the next section",
    "we establish the dependence of this maximal allowed noise , @xmath52 , in terms of @xmath30 and @xmath53 .",
    "to find when the algorithm breaks down as we increase the noise , we treat the noise as a perturbation on the exact algorithm ( recovered when @xmath54 ) .",
    "beforehand , we fix the phone book s size @xmath30 and the desired probability of finding the result , @xmath53 .",
    "first , we take a very small initial value of @xmath37 and evolve the initial state @xmath14 in equation ( [ 1 ] ) according to the noisy iteration given in equation ( [ 13 ] ) .",
    "after @xmath13 iterations , the probability @xmath27 of finding the result is still @xmath55 , where now the amplitude @xmath16 includes @xmath13 additions of noise .",
    "it turns out that , on the average , @xmath27 still reaches its maximum after @xmath56 steps .",
    "this is a pleasant surprise . at",
    "first thought , one could have imagined that noise not only decreased @xmath57 ( as it does ) , but also slowed down the algorithm ( which it does not ) .",
    "to maximize the likelihood of finding the result we must measure the quantum state after @xmath58 iterations , with @xmath58 given by the noiseless equation ( [ 12 ] )",
    ".    now we compute @xmath59 and compare it with @xmath53 .",
    "if @xmath60 is greater than @xmath47  , we increase the value of @xmath37 and repeat the computation , otherwise we stop ( see the appendix for details ) . in this way",
    ", we find the maximal @xmath49 , labelled @xmath61 , which is the limiting noise for @xmath62 . because of the probabilistic nature of the computations ,",
    "we repeat this computation of @xmath52 many times ( two - hundred ) : the value of @xmath61 we exhibit is the average , with a statistical error .",
    "we have carried out the evaluation of @xmath52 for seven different phone book sizes @xmath63 ( with @xmath4 from @xmath64 to @xmath65 ) and for five different values of @xmath47 ( from @xmath66 to @xmath67 in steps of @xmath68 ) .    for fixed @xmath47 ,",
    "the dependence of @xmath69 on @xmath30 is always of the form : @xmath70 where @xmath71 is a true constant , found to be @xmath72 and @xmath73 varies smoothly from @xmath74 to @xmath75 as @xmath76 decreases from @xmath74 to @xmath77 ( see appendix ) .",
    "one of our main results is that the amount of noise that the algorithm can handle decreases roughly as @xmath78 with the size @xmath30 of the list . in general , since the number of steps needed in each iteration is of the order of @xmath79 , and at each step we add a noise of width @xmath49 , we expect the maximal allowed @xmath80 to decrease with @xmath30 faster than @xmath81 .",
    "equivalently , we expect @xmath82 to be smaller than minus one  half .",
    "the actual value found , equation ( [ xxy ] ) , satisfies this bound .",
    "we have not found a general analytic argument to pin down the actual value of @xmath82 .    alternatively , keeping @xmath30 fixed instead of @xmath83",
    ", the relation between @xmath84 and @xmath47 can be written as @xmath85 where @xmath86 goes from @xmath87 to @xmath88 and @xmath89 from @xmath90 to @xmath91 ( @xmath92 and @xmath93 respectively ) , with errors of about @xmath94 ( see appendix for details ) .",
    "this means that the width of the maximal white noise that may be allowed increases linearly with decreasing @xmath47 .",
    "note that equations ( [ 14 ] ) and ( [ 15 ] ) are just convenient slices of a surface in the three  dimensional space with co - ordinates @xmath95 .",
    "in the derivation of the above results we exploited the experimental fact that the number of steps needed to find the searched  for state does not change when noise is present .",
    "thus , another way to estimate the real maximal noise that the noisy grover s algorithm can handle , while still improving the results of the classical search algorithm , is to let @xmath47 be even lower than @xmath67 .",
    "we now explain this .",
    "since @xmath97 is always bigger than @xmath1 , there is an integer @xmath98 such that @xmath99 , namely @xmath100 therefore , we can repeat the quantum search @xmath98 times with a low @xmath47 such that @xmath101 .",
    "we are assured that we will find the searched  for state with probability one - half in the same number of steps as the classical algorithm .",
    "of course , the classical algorithm find the result for sure , and compared with that finding the result only half the time is not very satisfactory . instead of .5",
    ", we could equally well have chosen some other ( higher ) probability to be satisfied with , but we take .5 for definiteness as the extreme , illustrative case .",
    "the point is that the @xmath53 we need to enforce on the noisy quantum algorithm is smaller than .5 .",
    "note also that we are disregarding the @xmath102 steps needed in each of the @xmath98 independent iterations to prepare the initial state @xmath14 . including them would of course lower a bit the maximal allowed noise .",
    "the limiting probability at maximum with which the iterated quantum algorithm is as slow as the classical one is @xmath103 the meaning of this is , again , that we can let @xmath47 be smaller than @xmath67 for a given @xmath30 because if we run @xmath98 times the quantum algorithm with @xmath104 steps , we will find the searched  for state with a probability of at least @xmath67 , and the total number of steps will be less or equal to @xmath1 ( ignoring the @xmath105 steps required for constructing the initial state @xmath106 ) .    to estimate this maximal noise that the quantum algorithm can bear before it slows down all the way to equivalence with the classical one , we proceed as follows .",
    "first , we choose the size @xmath30 of the list to be searched , and keep it fixed .",
    "then , using the bound ( [ 17 ] ) , we determine @xmath47 , which is very low .",
    "finally , equation ( [ 15 ] ) yields @xmath69 , which is now significantly higher . for a variety of @xmath30 ,",
    "our results are shown in table  1 .",
    ".in the iterated quantum algorithm , for various sizes @xmath30 of a phone book , the absolute maximal allowed gaussian width @xmath107 of the white noise , and its statistical uncertainty ( between @xmath108 and @xmath64  % ) .",
    "also shown is the ( low ! ) limiting probability @xmath47 at maximum .",
    "[ cols=\"^,^,^,^\",options=\"header \" , ]     in figure 1 , we plot @xmath69 as a function of @xmath30 for the data of table  1 ; the equation which fits it is @xmath109 note that the exponent of @xmath30 in ( [ 19 ] ) is essentially the same as the exponent @xmath82 in ( [ 14 ] ) , even though @xmath47 depends on @xmath30 and is one or two orders of magnitude smaller than in section  iii .    = n    n    fig.1 . plot of log @xmath110 as a function of @xmath111 for the iterated quantum algorithm with minimal @xmath112 that still improves the classical search algorithm .",
    "even though to each @xmath30 corresponds a different @xmath53 , the plot still displays the universal @xmath78 dependence .",
    "at the moment , quantum correction codes are restricted to the case when only a enough small subset of the quantum computer s @xmath113-bits undergo errors , and the probability of occurrence of an error is smaller than some bound , but it is believed that quantum computations will be possible with physically realistic levels of noise even if the quantum correction codes employed undergo errors themselves .    with this in mind",
    ", we studied the intrinsic robustness of grover s quantum search algorithm in a noisy environment .",
    "we modelled the noise with a single parameter , the width of a gaussian distribution , and allowed for two independent noises at each step of grover s quantum algorithm .",
    "we found that the quantum search algorithm still reaches the maximum likelihood of finding the searched  for state in @xmath114 steps .",
    "the strongest effect of noise is to decrease the maximum probability from virtually @xmath115 ( the noiseless case ) to lower values , depending on the size of the noise , equations ( [ 14 ] ) and ( [ 15 ] ) .",
    "how much noise can we add to the quantum computer , with the criterion that a repeated application of the quantum algorithm is still faster than the classical one is given by equation ( [ 17 ] ) .",
    "in both cases , the allowed maximal noise decreases with the size of the phone book approximately as @xmath78 .",
    "the presence of noise and the absence of quantum correction codes is not completely disastrous : the quantum search algorithm can handle by itself a reasonable amount of noise .",
    "nevertheless , for large enough databases , the allowed noise becomes tiny .",
    "* acknowledgments .",
    "* this work is supported in part by conacyt 25504-e and dgapa  unam in103997 .",
    "b.p.n . enjoys a scholarship from conacyt .",
    "the computer program we used to derive the results in section iii needs an initial value of @xmath37 ( which we set to zero ) , and then computes @xmath116 .",
    "if @xmath117 , then the algorithm increases @xmath49 , repeating the process until the bound is surpassed .",
    "this gives one value for @xmath107 .",
    "we repeat the whole story again and again and average over the values of @xmath107 found .",
    "let @xmath118 .",
    "for each @xmath4 from @xmath64 to @xmath65 , the program increases the value of @xmath37 starting from @xmath119 in steps of @xmath120 .",
    "the average maximal values of @xmath49 thus found ( in 200 runs ) is then @xmath121 , shown below with its statistical uncertainty .",
    "note that the error seems dominated by the step size : @xmath122      curiously , when we decrease the step both the error and the central value of @xmath125 decrease .",
    "this can be understood easily , since we take as value for maximal @xmath49 in each run the first @xmath49 for which the probability after @xmath56 iterations is too small ( smaller than @xmath126 in this example ) , and thus we clearly underestimate it in gross dependence with the step .",
    "we are thus forced to repeat the computation of @xmath107 and @xmath127 with smaller and smaller steps , from d@xmath128 to d@xmath129 .",
    "we must now fit the dependence of @xmath69 on d@xmath49 ( see fig .",
    "@xmath130 ) and extrapolate to d@xmath44 .",
    "plot of @xmath110 as a function of @xmath131 : the maximum allowed value of noise characterized by @xmath132 before @xmath57 @xmath133 depends on the size of the step d@xmath49 by which @xmath37 is increased in the program .",
    "this plot is for @xmath134 and @xmath135 .",
    "the generic relation we found is @xmath136 where @xmath137 is a true constant .",
    "the values of the @xmath30dependent @xmath138 and @xmath139 are the following : @xmath140 taking the limit d@xmath141 , we obtain the final value of @xmath61 for each @xmath30 at this @xmath118 : @xmath142 the above numbers are very well fit by a straight line ( in log  @xmath30 ) .        to establish equation ( [ 15 ] ) , we found for each @xmath53 a table like ( [ 24 ] ) and then , fixing @xmath30 , we found a good linear fit , equation ( [ 15 ] ) , with the following values of @xmath147 and @xmath148 :      p.w .",
    "shor , _ algorithms for a quantum computation : discrete logarithms and factoring _ , in proc .",
    "35 symp . found .",
    "( s. goldwasser , ed . )",
    "ieee computer society press ( 1994 ) 124 - 134 ; , siam j. computing * 26 * ( 1997 ) 1484 - 1509 ."
  ],
  "abstract_text": [
    "<S> grover s quantum algorithm improves any classical search algorithm . </S>",
    "<S> we show how random gaussian noise at each step of the algorithm can be modelled easily because of the exact recursion formulas available for computing the quantum amplitude in grover s algorithm . </S>",
    "<S> we study the algorithm s intrinsic robustess when no quantum correction codes are used , and evaluate how much noise the algorithm can bear with , in terms of the size of the phone book and a desired probability of finding the correct result . </S>",
    "<S> the algorithm loses efficiency when noise is added , but does not slow down . </S>",
    "<S> we also study the maximal noise under which the iterated quantum algorithm is just as slow as the classical algorithm . in all cases , the width of the allowed noise scales with the size of the phone book as @xmath0 .    </S>"
  ]
}