{
  "article_text": [
    "sparse reconstruction for electrical impedance tomography ( eit ) with full boundary data has been utilized in @xcite and are based on algorithms from @xcite .",
    "a similar approach was used in 2d for the partial data problem in @xcite with use of a spatially varying regularization parameter , and this paper extends the algorithm to the 3d partial data problem .",
    "the main contributions are in deriving the frchet derivative for the algorithm , and in the numerical results in 3d .    the inverse problem in eit",
    "consists of reconstructing an electrical conductivity distribution in the interior of an object from electro - static boundary measurements on the surface of the object .",
    "the underlying mathematical problem is known as the caldern problem in recognition of caldern s seminal paper @xcite .",
    "while the caldern problem can also be considered in two dimensions , physical electric fields are intrinsically three dimensional , and thus the reconstruction problem in eit should ideally use a 3d reconstruction algorithm to reduce modelling errors in the reconstruction .",
    "consider a bounded domain @xmath1 with smooth boundary @xmath2 in order to consider partial boundary measurements we introduce the subsets @xmath3 for the neumann and dirichlet data respectively .",
    "let @xmath4 with @xmath5 a.e .",
    "denote the conductivity distribution in @xmath6 . applying a boundary current flux @xmath7 ( neumann condition ) through @xmath8",
    "gives rise to the interior electric potential @xmath9 characterized as the solution to @xmath10 where @xmath11 is an outward unit normal to @xmath2 the latter condition in is a grounding of the total electric potential along the subset @xmath12 to be precise we define the spaces @xmath13 consisting of boundary functions with mean zero , and the spaces @xmath14 consisting of functions with mean zero on @xmath15 designed to encompass the partial boundary data . using standard",
    "elliptic theory it follows that has a unique solution @xmath16 for any @xmath17 .",
    "this defines the neumann - to - dirichlet map ( nd - map ) @xmath18 by @xmath19 , and the partial nd - map as @xmath20 for @xmath21    recently the partial data caldern problem has been studied intensively . in 3d uniqueness has been proved under certain conditions on @xmath15 and @xmath22 @xcite .",
    "also stability estimates of log - log type have been obtained for the partial problem @xcite ; this suggests that the partial data problem is even more ill - posed and hence requires more regularization than the full data problem which has log type estimates @xcite .    the data considered here consist of @xmath23 pairs of cauchy data taken on the subsets @xmath15 and @xmath24 i.e. @xmath25 we assume that the true conductivity is given as @xmath26 , where @xmath27 is a known background conductivity .",
    "define the closed and convex subset @xmath28 for some @xmath29 , and @xmath30 where @xmath31 .",
    "similarly define @xmath32 the inverse problem is then to approximate @xmath33 given the data .",
    "let @xmath34 denote a chosen orthonormal basis for @xmath35 for sparsity regularization we approximate @xmath36 by @xmath37 using the following tikhonov functional @xmath38 with the discrepancy terms @xmath39 and penalty term @xmath40 given by @xmath41 for @xmath42 .",
    "the regularization parameter @xmath43 for the sparsity - promoting @xmath0 penalty term @xmath40 is distributed such that each basis coefficient can be regularized differently ; we will return to this in section  [ sec : prior ] .",
    "it should be noted how easy and natural the use of partial data is introduced in this way , simply by only minimizing the discrepancy on @xmath15 where the dirichlet data is known and ignoring the rest of the boundary .",
    "the non - linearity of @xmath44 leads to a non - convex discrepancy term , i.e. @xmath45 is non - convex .",
    "when applying a gradient based optimization method , the best we can hope is to find a local minimum .    this paper is organised as follows : in section  [ sec : sparsereconstruction ] we derive the frchet derivative of @xmath39 and reformulate the optimization problem using the generalized conditional gradient method as a sequence of linearized optimization problems . in section  [ sec : prior ] we explain the idea of the spatially dependent regularization parameter designed for the use of prior information .",
    "finally , in section  [ sec : numericalresults ] we show the feasibility of the algorithm by a few numerical examples .",
    "in this section the sparse reconstruction of @xmath46 based on the optimization problem , is investigated for a bounded domain @xmath47 with smooth boundary .",
    "the penalty term emphasizes that @xmath46 should only be expanded by few basis functions in a given orthonormal basis .",
    "the partial data problem comes into play in the discrepancy term , in which we only fit the data on part of the boundary .",
    "ultimately , this leads to algorithm [ alg1 ] at the end of this section .    for fixed @xmath7 let @xmath9 be the unique solution to .",
    "define the solution operator @xmath48 and further its trace @xmath49 ( note that @xmath50 ) . in order to compute the derivative of @xmath51",
    "let @xmath52 and @xmath53 for @xmath54 .",
    "then following the proofs of theorem 2.2 and corollary 2.1 in @xcite whilst applying the partial boundary @xmath15 we have @xmath55 the linear map @xmath56 maps @xmath57 to @xmath58 , where @xmath59 is the unique solution to @xmath60 note that @xmath56 resembles a frchet derivative of @xmath61 evaluated at @xmath62 due to , however @xmath63 is not a linear vector space , thus the requirement @xmath64 .",
    "the first step in minimizing @xmath45 using a gradient descent type iterative algorithm is to determine a derivative to the discrepancy terms @xmath39 .  for this purpose",
    "the following corollary is applied , and is a special case of ( * ? ? ?",
    "* theorem 3.1 ) for @xmath6 being an open and bounded subset of @xmath65 with smooth boundary .",
    "[ meyerthm ] for @xmath52 there exists @xmath66 depending continuously on the bound @xmath67 from @xmath63 , such that @xmath68 . for @xmath69 $ ] and @xmath70 , there is the following estimate with @xmath71 only depending on @xmath67 , @xmath6 and @xmath72 : @xmath73    let @xmath74 with @xmath54 , and @xmath75 be a characteristic function on @xmath15 .",
    "then there exists @xmath76 as the bound in @xmath77 sufficiently close to 1 , such that @xmath78 with @xmath79 implies @xmath80 and the frchet derivative @xmath81 of @xmath39 on @xmath82 evaluated at @xmath83 in the direction @xmath57 is given by @xmath84    for the proof the index @xmath85 is suppressed .",
    "first it is proved that @xmath86 write @xmath87 and note that @xmath88 and @xmath89 , i.e. @xmath90 . now using corollary [ meyerthm ] ,",
    "there exists @xmath66 such that @xmath91 where @xmath92 $ ] .",
    "since @xmath93 then corollary  [ meyerthm ] implies @xmath94 for @xmath95 $ ] .",
    "choosing @xmath67 sufficiently close to @xmath96 leads to @xmath97 . by and then @xmath98 , and hlder s generalized inequality entails that @xmath99 with @xmath100 i.e. @xmath101 , @xmath102 the sobolev embedding theorem @xcite implies the embedding @xmath103 as @xmath47 . thus @xmath104 .",
    "next we prove .",
    "@xmath105 is by the chain rule ( utilizing that @xmath106 ) given as @xmath107 where @xmath75 is enforcing that the integral is over @xmath15 .",
    "the weak formulations of , with neumann data @xmath108 , and are @xmath109 now by letting @xmath110 in and @xmath111 in , we obtain using the definition @xmath112 that @xmath113    define @xmath114 we seek to find a direction @xmath57 for which the discrepancy decreases . as @xmath115 it is known from riesz representation theorem that there exists a unique function in @xmath82 , denoted by @xmath116 , such that @xmath117 now @xmath118 points in the steepest descend direction among the viable directions . furthermore , since @xmath119 the boundary condition @xmath120 for the approximation will automatically be fulfilled . note that @xmath116 is the unique solution to @xmath121 for which is the weak formulation . in each iteration step",
    "we need to determine a step size @xmath122 for an algorithm resembling a steepest descent @xmath123 . as in @xcite a barzilai - borwein step size rule is applied @xmath124 a maximum step size @xmath125 is enforced to avoid the situation @xmath126 .    with inspiration from @xcite",
    ", @xmath122 will be initialized by , after which it is thresholded to lie in @xmath127 $ ] for two chosen positive constants @xmath128 and @xmath125 .",
    "it is noted in @xcite that barzilai - borwein type step rules lead to faster convergence if we do not restrict @xmath45 to decrease in every iteration .",
    "therefore , one makes sure that the following so - called weak monotonicity is satisfied , which compares @xmath129 with the most recent @xmath130 steps .",
    "let @xmath131 and @xmath132 , then @xmath122 is said to satisfy the weak monotonicity with respect to @xmath130 and @xmath133 if the following is satisfied @xmath134 if is not satisfied , the step size @xmath122 is reduced until this is the case .    to solve the non - linear minimization problem we iteratively solve the following linearized problem @xmath135 , \\label{upsiloneq } \\\\      \\delta\\gamma_{i+1 } & \\equiv { \\mathcal{p}_{{\\ensuremath{\\mathcal{a}}}_0}}(\\zeta_{i+1 } ) .",
    "\\notag\\end{aligned}\\ ] ] here @xmath34 is an orthonormal basis for @xmath82 in the @xmath136-metric , and @xmath137 is a projection of @xmath82 onto @xmath77 to ensure that is solvable ( note that @xmath82 does not embed into @xmath138 , i.e. @xmath139 may be unbounded ) . by use of the map @xmath140",
    "defined below , known as the soft shrinkage / thresholding map with threshold @xmath141 , @xmath142 the solution to is easy to find directly ( see also ( * ? ? ?",
    "* section 1.5 ) ) @xmath143 where @xmath144 are the basis coefficients for @xmath145 .",
    "the projection @xmath146 is defined as @xmath147 where @xmath148 is the following truncation that depends on the constant @xmath149 in @xmath150 since @xmath30 and @xmath31 , it follows directly from ( * ? ? ?",
    "* lemma 1.2 ) that @xmath148 and @xmath137 are well - defined , and it is easy to see that @xmath137 is a projection .",
    "it should also be noted that @xmath151 since @xmath31 , thus we may choose @xmath152 as the initial guess in the algorithm .",
    "the algorithm is summarized in algorithm [ alg1 ] . in the numerical experiments in section [ sec : numericalresults ] the stopping criteria is when the step size @xmath122 gets below a threshold @xmath153 .    set @xmath154 . set @xmath155 .",
    "compute @xmath156 .",
    "compute @xmath157 .",
    "compute @xmath158 such that @xmath159 .",
    "compute step length @xmath122 by , and decrease it till is satisfied .",
    "compute the basis coefficients @xmath160 for @xmath145 .",
    "update @xmath161 .",
    "return final iterate of @xmath83 .",
    "prior information is typically introduced in the penalty term @xmath40 for tikhonov - like functionals , and here the regularization parameter determines how much this prior information is enforced . in the case of sparsity regularization",
    "this implies knowledge of how sparse we expect the solution is in general . instead of applying the same prior information for each basis function , a distributed parameter is applied .",
    "let @xmath162 where @xmath163 is a usual regularization parameter , corresponding to the case where no prior information is considered about specific basis functions .",
    "the @xmath164 $ ] will be used to weigh the penalty depending on whether a specific basis function should be included in the expansion of @xmath36 .",
    "the @xmath165 are chosen as @xmath166 i.e. if we know that a coefficient in the expansion of @xmath46 should be non - zero , we can choose to penalize that coefficient less .",
    "ideally , if we know that a coefficient should be non - zero we would actually choose @xmath167 , however , in most cases we might only have an estimate of which basis functions that should be included in the solution .",
    "choosing @xmath167 will effectively remove any regularization of the corresponding basis function , and may introduce further instability into the numerical algorithm .      in order to improve the sparsity solution for finding small inclusions , it seems appropriate to include prior information about the support of the inclusions .",
    "there are different methods available for obtaining such information assuming piecewise constant conductivity @xcite or real analytic conductivity @xcite .",
    "the idea is to be able to apply such information in the sparsity algorithm in order to get good contrast reconstruction while maintaining the correct support , even for the partial data problem .",
    "suppose that as a basis we consider a finite element method ( fem ) basis @xmath168 for the subspace @xmath169 of piecewise affine functions on each element .",
    "let @xmath170 with mesh nodes @xmath171 , then @xmath172 and @xmath173 , i.e.  for each node there is a basis function for which the coefficient contains local information about the expanded function ; this is convenient when applying prior information about the support of an inclusion .",
    "when applying the fem basis for mesh nodes @xmath171 , the corresponding functional is @xmath174 it is evident that the penalty corresponds to determining inclusions with small support , and prior information on the sparsity corresponds to prior information on the support of @xmath36 .",
    "we can not directly utilize due to the fem basis not being an orthonormal basis for @xmath82 , and instead we suggest the following iteration step as in @xcite : @xmath175 note that the regularization parameter will depend quite heavily on the discretization of the mesh , i.e. for the same domain a good regularization parameter @xmath163 will be much larger on a coarse mesh than on a fine mesh . instead we can weigh the regularization parameter according to the mesh cells , by having @xmath176 .",
    "this leads to a discretization of a weighted @xmath177-norm penalty term : @xmath178 where @xmath179 $ ] is continuous and @xmath180 . the weights @xmath181 consists of the node volume computed in 3d as 1/4 of the volume of @xmath182 ( if using a mesh of tetrahedrons )",
    "this corresponds to splitting each cell s volume evenly amongst the nodes , and it will not lead to instability on a regular mesh .",
    "this will make the choice of @xmath163 almost independent of the mesh , and will be used in the numerical examples in the following section .",
    "the corresponding algorithm with the fem basis is the same as algorithm [ alg1 ] , except that the update is applied via .",
    "in this section we illustrate , through a few examples , the numerical algorithm implemented by use of the finite element library fenics @xcite .",
    "first we consider the full data case @xmath183 without and with prior information , and then we do the same for the partial data case .    for the following examples",
    "@xmath6 is the unit ball in @xmath65 .",
    "the numerical phantom consists of a background conductivity with value @xmath96 , a smaller ball inclusion with value @xmath184 centred at @xmath185 and with radius @xmath186 , and two large ellipsoid inclusions with value @xmath187 .",
    "one ellipsoid is centred at @xmath188 and with semi - axes of length @xmath189 .",
    "the other ellipsoid is centred at @xmath190 and with semi - axes of length @xmath191 .",
    "the two ellipsoids are rotated respectively @xmath192 and @xmath193 about the axis parallel to the z - axis and through the centre of the ellipsoids ; see figure [ fig:3d_phantom ] .    in this paper we do not consider choice rules for @xmath163 ; it is chosen manually by trial and error .",
    "the parameters are chosen as @xmath194 , @xmath195 , @xmath196 , @xmath197 , @xmath198 , and the stopping criteria is when the step size is below @xmath199 .",
    "let @xmath200 denote laplace s spherical harmonics of degree @xmath201 and order @xmath202 , with real form @xmath203 the neumann data consists of @xmath204 for @xmath205 and @xmath206 , i.e. a total of @xmath207 current patterns .",
    "for the partial data examples a half - sphere is used for local data @xmath208 , and the corresponding neumann data are scaled to have the same number of periods as the full data examples .    when applying prior information , the coefficients @xmath165 are chosen as @xmath209 where the support of @xmath46 is assumed , and @xmath96 elsewhere .",
    "the assumed support is a @xmath210 dilation of the true support , to show that this inaccuracy in the prior information still leads to improved reconstructions .    for the simulated dirichlet data ,",
    "the forward problem is solved on a very fine mesh , and afterwards interpolated onto a different much coarser mesh in order to avoid inverse crimes .",
    "white gaussian noise has been added to the dirichlet data @xmath211 on the discrete nodes on the boundary of the mesh .",
    "the standard deviation of the noise is chosen as @xmath212 as in @xcite , where corresponding to 1% noise .",
    "figure [ fig : block_one ] shows 2d slices of the numerical phantom and reconstructions from full boundary data .",
    "it is seen that the reconstructions attain the correct contrast , and close to the boundary gives good approximations to the correct support for the inclusions . using the overestimated support as prior information gives vastly improved reconstruction further away from the boundary .",
    "this holds for the entire 3d reconstruction as seen in figure [ fig : block_one ] , and makes it possible to get a reasonable separation of the inclusions .",
    "from figure [ fig : block_two ] 2d slices of partial data reconstructions are shown , and it is evident that far from the measured boundary the reconstructions suffer severely . reconstructing with data on the lower part of the sphere",
    "gives a reasonable reconstruction with correct contrast for the ball inclusion , however the larger inclusions are hardly reconstructed at all .    with data on the top half of the sphere",
    "yields a reconstruction with no clear separation of the ellipsoid inclusions , which is much improved by use of the overestimated support .",
    "there is however an artefact in one of the reconstructed inclusions that could correspond to data from the ball inclusion , which is not detected in the reconstruction even when the additional prior information is used .",
    "the reconstructions shown here are consistent with what was observed in @xcite for the 2d problem , and it is possible to reconstruct the correct contrast even in the partial data case , and also get decent local reconstruction close to the measured boundary .",
    "however , the partial data reconstructions seems to be slightly worse in 3d when no prior information about the support is applied .",
    "( mr2424078 ) r. a. adams and j. j. f. fournier , _ sobolev spaces _ , 2@xmath213 edition , pure and applied mathematics , amsterdam , 2003 .",
    "( mr922775 ) g. alessandrini , stable determination of conductivity by boundary measurements , _ appl .",
    "_ , * 27 * ( 1988 ) , 153172 .",
    "( mr2353327 ) t. bonesky , k. bredies , d. a. lorenz and p. maass , a generalized conditional gradient method for nonlinear operator equations with sparsity constraints , _ inverse problems _ , * 23 * ( 2007 ) , 20412058 .",
    "( mr2471395 ) k. bredies , d. a. lorenz and p. maass , a generalized conditional gradient method and its connection to an iterative shrinkage method , _ comput .",
    "_ , * 42 * ( 2009 ) , 173193 .",
    "( mr1900557 ) a. l. bukhgeim and g. uhlmann , recovering a potential from partial cauchy data , _ comm . partial differential equations _ ,",
    "* 27 * ( 2002 ) , 653668 .",
    "( mr590275 ) a .-",
    "caldern , on an inverse boundary value problem , in seminar on numerical analysis and its applications to continuum physics , _ soc . brasil . mat .",
    "_ , ( 1980 ) , 6573 .",
    "( mr2077704 ) i. daubechies , m. defrise and c. de mol , an iterative thresholding algorithm for linear inverse problems with a sparsity constraint , _ comm .",
    "pure appl .",
    "_ , * 57 * ( 2004 ) , 14131457 . h. garde and k. knudsen , sparsity prior for electrical impedance tomography with partial data , _ submitted _ , ( 2014 ) , .",
    "( mr2876676 ) m. gehre , t. kluth , a. lipponen , b. jin , a. seppnen , j. p. kaipio and p. maass , sparsity reconstruction in electrical impedance tomography : an experimental evaluation , _ j. comput .",
    "appl . math .",
    "_ , * 236 * ( 2012 ) , 21262136 . ( mr2679585 ) b. von harrach and j. k. seo , exact shape - reconstruction by one - step linearization in electrical impedance tomography , _ siam j. math",
    "_ , * 42 * ( 2010 ) , 15051518 .",
    "( mr3126995 ) b. von harrach and m. ullrich , monotonicity - based shape reconstruction in electrical impedance tomography , _",
    "siam j. math .",
    "_ , * 45 * ( 2013 ) , 33823403 .",
    "( mr2261266 ) h. heck and j .- n . wang , stability estimates for the inverse boundary value problem by partial cauchy data , _ inverse problems _ , * 22 * ( 2006 ) , 17871796 .",
    "( mr2262748 ) v. isakov , on uniqueness in the inverse conductivity problem with local data , _ inverse probl . imaging _ , * 1 * ( 2007 ) , 95105 .",
    "( mr2876564 ) b. jin , t. khan and p. maass , a reconstruction algorithm for electrical impedance tomography based on sparsity regularization , _ internat . j. numer .",
    "methods engrg .",
    "_ , * 89 * ( 2012 ) , 337353 .",
    "( mr3019471 ) b. jin and p. maass , an analysis of electrical impedance tomography with applications to tikhonov regularization , _ esaim : control , optimisation and calculus of variations _ , * 18 * ( 2012 ) , 10271048 .",
    "( mr2299741 ) c. e. kenig , j. sjstrand and g. uhlmann , the caldern problem with partial data , _ ann . of math .",
    "( 2 ) _ , * 165 * ( 2007 ) , 567591 . (",
    "mr2378253 ) a. kirsch and n. grinberg , _ the factorization method for inverse problems _ , oxford university press , oxford , 2008 .",
    "( mr2209749 ) k. knudsen , the caldern problem with partial data for less smooth conductivities , _ comm . partial differential equations _ , * 31 * ( 2006 ) , 5771 .",
    "( mr3075806 ) a. logg , k .- a .",
    "mardal and g. n. wells , _ automated solution of differential equations by the finite element method _ , springer , heidelberg , 2012 .",
    "( mr0192177 ) g. stampacchia , le problme de dirichlet pour les quations elliptiques du second ordre  coefficients discontinus , _ ann .",
    "fourier ( grenoble ) _ , * 15 * ( 1965 ) , 189258 .",
    "( mr2650165 ) s. j. wright , r. d. nowak and m. a. t. figueiredo , sparse reconstruction by separable approximation , _ ieee trans .",
    "signal process .",
    "_ , * 57 * ( 2009 ) , 24792493 ."
  ],
  "abstract_text": [
    "<S> in electrical impedance tomography the electrical conductivity inside a physical body is computed from electro - static boundary measurements . </S>",
    "<S> the focus of this paper is to extend recent result for the 2d problem to 3d . </S>",
    "<S> prior information about the sparsity and spatial distribution of the conductivity is used to improve reconstructions for the partial data problem with cauchy data measured only on a subset of the boundary . </S>",
    "<S> a sparsity prior is enforced using the @xmath0 norm in the penalty term of a tikhonov functional , and spatial prior information is incorporated by applying a spatially distributed regularization parameter . </S>",
    "<S> the optimization problem is solved numerically using a generalized conditional gradient method with soft thresholding . </S>",
    "<S> numerical examples show the effectiveness of the suggested method even for the partial data problem with measurements affected by noise .    </S>",
    "<S> henrik garde and kim knudsen </S>"
  ]
}