{
  "article_text": [
    "as a long - standing central problem in natural language processing ( nlp ) , dependency parsing has been dominated by data - driven approaches with supervised learning for decades .",
    "the foundation of data - driven parsing is the availability and scale of annotated training data ( i.e. , _ treebanks _ ) .",
    "numerous efforts have been made towards the construction of treebanks which established the benchmark research on dependency parsing , such as the widely - used penn treebank  @xcite .",
    "however , the heavy cost of treebanking typically limits the existing treebanks in both scale and coverage of languages . to address the problem ,",
    "a variety of authors have proposed to exploit existing heterogeneous treebanks with different annotation schemes via grammar conversion  @xcite , quasi - synchronous grammar features  @xcite or shared feature representations  @xcite for the enhancement of parsing models . despite their effectiveness in specific datasets , these methods typically require manually designed rules or features , and in most cases , they are limited to the data resources that can be used .",
    "furthermore , for the majority of world languages , such heterogeneous treebanks are not even available . in these cases , cross - lingual treebanks may lend a helping hand .    in this paper , we aim at developing an universal framework that can exploit multi - typed source treebanks to improve parsing of a target treebank .",
    "specifically , we will consider two kinds of source treebanks , that are _ multilingual universal treebanks _ and _ monolingual heterogeneous treebanks_.    cross - lingual supervision has proven highly beneficial for low - resource language parsing  @xcite , implying that different languages have a great deal of common ground in grammars .",
    "but unfortunately , linguistic inconsistencies also exist in both typologies and lexical representations across languages .",
    "figure  [ fig : multilingual ] illustrates two sentences in german and english with universal dependency annotations .",
    "the typological differences ( _ subject - verb - object _ order ) results in the opposite directions of the _ dobj _ arcs , while the rest arcs remain consistent .",
    "similar problems also come with monolingual heterogeneous treebanks .",
    "figure  [ fig : heterogeneous ] shows an english sentence annotated with respectively the universal dependencies which are _ content - head _ and the conll dependencies which instead take the functional heads .",
    "despite the structural divergences , these treebanks express the syntax of the same language , thereby sharing a large amount of common knowledge that can be effectively transferred .",
    "the present paper proposes a simple and effective framework that aims at making full use of the consistencies while avoids suffering from the inconsistencies across treebanks .",
    "our framework effectively ties together the deep neural parsing models with multi - task learning , using multi - level parameter sharing to control the information flow across tasks .",
    "more specifically , learning with each treebank is maintained as an individual task , and their interactions are achieved through parameter sharing in different abstraction levels on the deep neural network , thus referred to as _ deep multi - task learning_. we find that different parameter sharing strategies should be applied for different typed source treebanks adaptively , due to the different types of consistencies and inconsistencies ( figure  [ fig : running - example ] ) .",
    "we investigate the effect of multilingual treebanks as source using the universal dependency treebanks ( udt )  @xcite .",
    "we show that our approach improves significantly over strong supervised baseline systems in six languages .",
    "we further study the effect of monolingual heterogeneous treebanks as source using udt and the conll - x shared task dataset  @xcite .",
    "we consider using udt and conll - x as source treebanks respectively , to investigate their mutual benefits .",
    "experiment results show significant improvements under both settings .",
    "moreover , indirect comparisons on the chinese penn treebank 5.1 ( ctb5 ) using the chinese dependency treebank ( cdt ) as source treebank show the merits of our approach over previous work .",
    "the present work is related to several strands of previous studies .",
    "* monolingual resources for parsing*. exploiting heterogeneous treebanks for parsing has been explored in various ways .",
    "automatically convert the dependency - structure cdt into the phrase - structure style of ctb5 using a trained constituency parser on ctb5 , and then combined the converted treebanks for constituency parsing .",
    "capture the annotation inconsistencies among different treebanks by designing several types of _ transformation patterns _ , based on which they introduce _ quasi - synchronous grammar _ features",
    "@xcite to augment the baseline parsing models . also adopts the idea of parameter sharing to incorporate multiple treebanks .",
    "they focused on parameter sharing at feature - level with discrete representations , which limits its scalability to multilingual treebanks where feature surfaces might be totally different . on the contrary ,",
    "our approach are capable of utilizing representation - level parameter sharing , making full use of the multi - level abstractive representations generated by deep neural network .",
    "this is the key that makes our framework scalable to multi - typed treebanks and thus more practically useful .    aside from resource utilization",
    ", attempts have also been made to integrate different parsing models through stacking  @xcite or joint inference  @xcite .",
    "* multilingual resources for parsing*. cross - lingual transfer has proven to be a promising way of inducing parsers for low - resource languages , either through _ data transfer _",
    "@xcite or _ model transfer _",
    "@xcite .    and   both adopt parameter sharing to exploit multilingual treebanks in parsing , but with a few important differences to our work . in both of their models ,",
    "most of the neural network parameters are shared in two ( or multiple ) parsers except the feature embeddings , regularizers to tie the lexical embeddings with a bilingual dictionary . ] which ignores the important _ syntactical inconsistencies _ of different languages and is also inapplicable for heterogeneous treebanks that have different transition actions . besides , focus on low resource parsing where the target language has a small treebank of @xmath0 3k tokens .",
    "their models may sacrifice accuracy on target languages with a large treebank . instead train a single parser on a multilingual set of rich - resource treebanks , which is a more similar setting to ours .",
    "we refer to their approach as _ shallow multi - task learning _",
    "( smtl ) and will include as one of our baseline systems ( section  [ subsec : baseline ] ) .",
    "note that smtl is a special case of our approach in which all tasks use the same set of parameters .",
    "bilingual parallel data has also proven beneficial in various ways  @xcite , demonstrating the potential of cross - lingual transfer learning .",
    "* multi - task learning for nlp*. there has been a line of research on joint modeling pipelined nlp tasks , such as word segmentation , pos tagging and parsing  @xcite .",
    "most multi - task learning or joint training frameworks can be summarized as parameter sharing approaches proposed by  . in the context of neural models for nlp ,",
    "the most notable work was proposed by  , which aims at solving multiple nlp tasks within one framework by sharing common word embeddings .",
    "present a joint dependency parsing and semantic role labeling model with the incremental sigmoid belief networks ( isbn )  @xcite .",
    "more recently , the idea of neural multi - task learning was applied to sequence - to - sequence problems with recurrent neural networks . use multiple decoders in neural machine translation systems that allows translating one source language to many target languages .",
    "study the ensemble of a wide range of tasks ( e.g. , syntactic parsing , machine translation , image caption , etc . ) with multi - task sequence - to - sequence models . to the best of our knowledge , we present the first work that successfully integrate both monolingual and multilingual treebanks for parsing , with or without consistent annotation schemes .",
    "this section describes the deep multi - task learning architecture , using a formalism that extends on the transition - based dependency parsing model with lstm networks  @xcite which is further enhanced by modeling characters  @xcite .",
    "we first revisit the parsing approach of  , then present our framework for learning with multi - typed source treebanks .",
    "neural models for parsing have gained a lot of interests in recent years , particularly boosted by  .",
    "the heart of transition - based parsing is the challenge of representing the _ state _ ( configuration ) of a transition system , based on which the most likely transition action is determined .",
    "typically , a state includes three primary components , a _ stack _ , a _ buffer _ and a set of",
    "_ dependency arcs_. traditional parsing models deal with features extracted from manually defined feature templates in a discrete feature space , which suffers from the problems of _ sparsity _ , _ incompleteness _ and _ expensive feature computation_. the neural network model proposed by   instead represents features as continuous , low - dimensional vectors and use a _ cube _ activation function for implicit feature composition .",
    "more recently , this architecture has been improved in several different ways  @xcite . here",
    ", we employ the lstm - based architecture enhanced with character bidirectional lstms  @xcite for the following major reasons :    * compared with chen & manning s architecture , it makes full use of the non - local features by modeling the full history information of a _ state _ with stack lstms . * by modeling words , stack , buffer and action sequence separately which indicate hierarchical abstractions of representations , we can control the information flow across tasks via parameter sharing with more flexibility ( section  [ subsec : mtl ] ) .            besides , we did not use the earlier isbn parsing model  @xcite due to its lack of scalability to large vocabulary .",
    "figure  [ fig : lstm - parser ] illustrates the transition - based parsing architecture using lstms .",
    "bidirectional lstms are used for modeling the word representations ( figure  [ fig : char - bilstm ] ) , which we refer to as char - bilstms henceforth .",
    "char - bilstms learn features for each word , and then the representation of each token can be calculated as : @xmath1 + \\mathbf{b})\\ ] ] where @xmath2 is the pos tag embedding .",
    "the token embeddings are then fed into subsequent lstm layers to obtain representations of the _ stack _ , _ buffer _ and _ action sequence _ respectively referred to as @xmath3 and @xmath4 ( the subscript @xmath5 represents the time step ) .",
    "note that the subtrees within the stack and buffer are modeled with a _ recursive neural network _ ( recnn ) as described in  .",
    "next , a linear mapping ( @xmath6 ) is applied to the concatenation of @xmath3 and @xmath4 , and passed through a component - wise @xmath7 : @xmath8 + \\mathbf{d } )          \\label{eqn:1}\\ ] ] finally , the probability of next action @xmath9 is estimated using a @xmath10 function : @xmath11 where @xmath12 represents the set of valid actions given the current content in the _ stack _ and _",
    "buffer_.    we apply the non - projective transition system originally introduced by   since most of the treebanks we consider in this study has a noticeable proportion of non - projective trees . in the swap - based system",
    ", both the _ stack _ and _ buffer _ may contain tree fragments , so recnn is applied both in s and b to obtain representations of each position .",
    "multi - task learning ( mtl ) is the procedure of inductive transfer that improves learning for one task by using the information contained in the training signals of other related tasks .",
    "it does this by learning tasks in parallel while using a shared representation .",
    "a good overview , especially focusing on neural networks , can be found in  .",
    "we illustrate our multi - task learning architecture in figure  [ fig : multitask ] .",
    "as discussed in previous sections , multiple treebanks , either multilingual or monolingual heterogeneous , contain knowledge that can be mutually beneficial .",
    "we consider the target treebank processing as the _ primary task _ , and the source treebank as a _ related task_. the two tasks are interacted through multi - level parameter sharing ( section  [ subsubsec : param - share ] ) . inspired by  , we introduce a task - specific vector @xmath13 ( _ task embedding _ ) which is first combined with @xmath14 to compute @xmath15 , and then further concatenated with @xmath15 to compute the probability distribution of transition actions .",
    "therefore , eqn  [ eqn:1 ] ,  [ eqn:2 ] become : @xmath16 + \\mathbf{d } )          \\label{eqn:3}\\ ] ] @xmath17 + \\mathbf{q}_z )          \\label{eqn:4}\\ ] ]    each task uses the same formalism for optimization , and the joint cross - entropy is used as the objective function .",
    "the key of _ multi - task _ learning is _ parameter sharing _ , without which the correlation between tasks will not be exploited .",
    "conventional multi - task learning models typically share a small proportion of parameters across tasks .",
    "for example , only shares word embeddings , and shares the encoder of sequence - to - sequence models . in this work ,",
    "we use more sophisticated parameter sharing strategies according to the linguistic similarities and differences between the tasks .",
    "deep neural networks automatically learn features for a specific task with hierarchical abstractions , which gives us the flexibility to control parameter sharing in different levels accordingly .    in this study ,",
    "different parameter sharing strategies are applied according to the source and target treebanks being used .",
    "we consider two different scenarios : mtl with multilingual universal treebanks as source ( * multi - univ * ) and mtl with monolingual heterogeneous treebanks as source ( * mono - hetero * ) .",
    "table  [ tbl : param - sharing - multilingual ] presents our parameter sharing strategies for each setting .",
    "l|l|l & * multi - univ * & * mono - hetero * + * shared & *    .parameter sharing strategies for * multi - univ * and * mono - hetero*. lstm(s )  _ stack _ lstm ; lstm(b )  _ buffer _ lstm ; lstm(a )  _ action _ lstm ; bilstm(chars )  char - bilstm ; recnn  recursive nn modeling the subtrees ; @xmath18  weights from a , s , b to the state ( @xmath15 ) ; @xmath19  weights from the state to output layer ; @xmath20  embeddings .",
    "[ cols= \" < \" , ]     the sv@xmath21 row in table  [ tbl : mono - conllx - uni ] presents the out - src results of sv , which shows consistent improvements .    to show the merit of our approach against previous approaches , we further conduct experiments on ctb5 using cdt as heterogeneous source treebank ( table  [ tbl : udt - stat ] ) . for ctb5",
    ", we follow  @xcite and consider two scenarios which use automatic pos tags and gold - standard pos tags respectively . to compare with their results , we run sup , cas and mtl on ctb5 .",
    "table  [ tbl : mono - cdt - ctb5 ] presents the results .",
    "the indirect comparison indicates that our approach can achieve larger improvement than their method in both scenarios . beside the empirical comparison ,",
    "our method has the additional advantages in its scalability to multi - typed source treebanks without the painful human efforts of feature design .",
    "overall , our approach obtains substantial gains over supervised baselines with either multilingual universal treebanks or monolingual heterogeneous treebanks as source . with multilingual source treebanks",
    ", our model has the potential to improve even further via language - specific tuning . while not the primary focus of this study , in low resource setting",
    ", we show that more emphasize may be put on the source treebanks through weighted task sampling .",
    "this paper propose an universal framework based on deep multi - task learning that can integrate arbitrary - typed source treebanks to enhance the parsing models on target treebanks .",
    "we study two scenarios , respectively using multilingual universal source treebanks and monolingual heterogeneous source treebanks , and design effective parameter sharing strategies for each scenario .",
    "we conduct extensive experiments on several benchmark treebanks in various languages .",
    "results demonstrate that our approach significantly improves over baseline systems under various experiment setting .",
    "furthermore , our framework can flexibly incorporate richer treebanks and more related tasks , which we leave to future exploration .",
    "we thank ryan mcdonald for fruitful discussions , and thank dr .",
    "zhenghua li for sharing the processed ctb and cdt dataset .",
    "this work was supported by the national key basic research program of china via grant 2014cb340503 and the national natural science foundation of china ( nsfc ) via grant 61133012 and 61370164 .",
    "miguel ballesteros , chris dyer , and noah  a. smith .",
    "2015 . improved transition - based parsing by modeling characters instead of words with lstms . in _ proc .",
    "of the 2015 conference on emnlp _ , pages 349359 , september .",
    "bernd bohnet and joakim nivre .",
    "2012 . a transition - based system for joint part - of - speech tagging and labeled non - projective dependency parsing . in _ proc .",
    "of the 2012 joint conference on emnlp and conll _ , pages 14551465 , july .",
    "sabine buchholz and erwin marsi .",
    "conll - x shared task on multilingual dependency parsing . in _ proc .",
    "of the tenth conference on computational natural language learning ( conll - x ) _ , pages 149164 , june .",
    "danqi chen and christopher manning .",
    "2014 . a fast and accurate dependency parser using neural networks . in _ proc . of the 2014 conference on empirical methods in natural language processing ( emnlp ) _ ,",
    "pages 740750 , october .",
    "daxiang dong , hua wu , wei he , dianhai yu , and haifeng wang .",
    "multi - task learning for multiple language translation . in _ proc . of the 53rd acl and the 7th ijcnlp ( volume 1 : long papers ) _ , pages 17231732 ,",
    "long duong , trevor cohn , steven bird , and paul cook .",
    "low resource dependency parsing : cross - lingual parameter sharing in a neural network parser . in _ proc .",
    "of the 53rd acl and the 7th ijcnlp ( volume 2 : short papers ) _ , pages 845850 , july .",
    "chris dyer , miguel ballesteros , wang ling , austin matthews , and noah  a. smith .",
    "transition - based dependency parsing with stack long short - term memory . in _ proc .",
    "of the 53rd acl and the 7th ijcnlp ( volume 1 : long papers ) _ , pages 334343 , july .",
    "jiang guo , wanxiang che , david yarowsky , haifeng wang , and ting liu .",
    "cross - lingual dependency parsing based on distributed representations . in _ proc .",
    "of the 53rd acl and the 7th ijcnlp ( volume 1 : long papers ) _ , pages 12341244 , july .",
    "jiang guo , wanxiang che , david yarowsky , haifeng wang , and ting liu .",
    "a representation learning framework for multi - source transfer parsing . in _ proc . of the thirtieth aaai conference on artificial intelligence ( aaai )",
    "_ , february .",
    "jun hatori , takuya matsuzaki , yusuke miyao , and junichi tsujii .",
    "incremental joint approach to word segmentation , pos tagging , and dependency parsing in chinese . in _ proc . of the 50th acl ( volume 1 : long papers ) _ , pages 10451053 , july .",
    "zhenghua li , min zhang , wanxiang che , ting liu , wenliang chen , and haizhou li .",
    "joint models for chinese pos tagging and dependency parsing . in _ proc . of the 2011 conference on emnlp _ , pages 11801191 , july .",
    "ryan mcdonald , joakim nivre , yvonne quirmbach - brundage , yoav goldberg , dipanjan das , kuzman ganchev , keith hall , slav petrov , hao zhang , oscar tckstrm , claudia bedini , nria bertomeu  castell , and jungmee lee .",
    "universal dependency annotation for multilingual parsing . in _ proc . of the 51st acl ( volume 2 : short papers ) _ , pages 9297 , august .",
    "joakim nivre and beata megyesi .",
    "2007 . bootstrapping a swedish treebank using cross - corpus harmonization and annotation projection . in _ proc . of the 6th international workshop on treebanks and linguistic theories _ , pages 97102 .",
    "joakim nivre .",
    "non - projective dependency parsing in expected linear time . in _ proc .",
    "of the joint conference of the 47th annual meeting of the acl and the 4th ijcnlp of the afnlp _ , pages 351359 , august .",
    "slav petrov , dipanjan das , and ryan mcdonald .",
    "2012 . a universal part - of - speech tagset . in _ proc .",
    "of the eighth international conference on language resources and evaluation ( lrec-2012 ) _ , pages 20892096 , may .",
    "ivan titov and james henderson . 2007 .",
    "fast and robust multilingual dependency parsing with a generative latent variable model . in _ proc . of the conll shared task session of emnlp - conll 2007 _ , pages 947951 , june .",
    "david weiss , chris alberti , michael collins , and slav petrov .",
    "structured training for neural network transition - based parsing . in _ proc .",
    "of the 53rd acl and the 7th ijcnlp ( volume 1 : long papers ) _ , pages 323333 , july .",
    "yue zhang and stephen clark .",
    "a tale of two parsers : investigating and combining graph - based and transition - based dependency parsing . in _ proc . of the 2008 conference on emnlp _ , pages 562571 , october .",
    "hao zhou , yue zhang , shujian huang , and jiajun chen .",
    "a neural probabilistic structured - prediction model for transition - based dependency parsing . in _ proc .",
    "of the 53rd acl and the 7th ijcnlp ( volume 1 : long papers ) _ , pages 12131222 , july ."
  ],
  "abstract_text": [
    "<S> various treebanks have been released for dependency parsing . despite </S>",
    "<S> that treebanks may belong to different languages or have different annotation schemes , they contain syntactic knowledge that is potential to benefit each other . </S>",
    "<S> this paper presents an universal framework for exploiting these multi - typed treebanks to improve parsing with deep multi - task learning . </S>",
    "<S> we consider two kinds of treebanks as source : the _ multilingual universal treebanks _ and the _ monolingual heterogeneous treebanks_. multiple treebanks are trained jointly and interacted with multi - level parameter sharing . </S>",
    "<S> experiments on several benchmark datasets in various languages demonstrate that our approach can make effective use of arbitrary source treebanks to improve target parsing models . </S>"
  ]
}