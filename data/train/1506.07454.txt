{
  "article_text": [
    "the clustering of data into groups is one of the current major topics under research .",
    "it is fundamental in many statistical problems ; most notably in machine learning , see , for example , @xcite .",
    "the traditional approach is to model the data via a mixture model , see @xcite for finite mixture distributions , and , more recently , @xcite .",
    "the idea , which carries through to infinite mixture models , is that each component in the mixture is represented by a parametric density function , typically from the same family , which is usually the normal distribution .",
    "this assumption , often made for convenience , supposes each cluster or group can be adequately modeled via a normal distribution . for",
    "if a group requires two such normals , then it is deemed there are in fact two groups . yet",
    "two normals could be needed even if there is one group and it happens to be skewed , for example .",
    "on the other hand , if we start by thinking about what a cluster could be represented by in terms of probability density functions , then a unimodal density is the most obvious choice .",
    "quite simply , with lack of further knowledge , i.e. only observing the data , a bimodal density would indicate two clusters .",
    "this was the motivation behind @xcite , which relies heavily on the unimodal density models being defined on the real line , for which there are no obvious extensions to the multivariate setting .",
    "there are representations of unimodal density functions on the real line ( e.g. @xcite and @xcite ) and it is not difficult to model such a density adequately .",
    "see , for example , @xcite , @xcite and @xcite .",
    "clearly , the aim is to provide large classes of unimodal densities and hence infinite dimensional models are often used .",
    "however , while there is an abundance of literature on unimodal density function modeling on the real line , there is a noticeable lack of work in two and higher dimensions .",
    "the reasons are quite straightforward ; first there is a lack of a representation for unimodal distributions outside of the real line and , second , the current approaches to modeling unimodal densities on the real line do not naturally extend to higher dimensions .",
    "the aim in this paper is to introduce and demonstrate a class of unimodal densities for a multivariate setting .",
    "while marginal density functions will be modeled using the @xcite representation on the real line , the dependence structure will be developed using a gaussian copula model .",
    "to elaborate , using an alternative form of representation of unimodal densities on the real line , we can write a unimodal density as @xmath0 this then naturally extends to a bivariate setting with marginals of the form ( [ unim ] ) via the use of a copula density function @xmath1 ; @xmath2 using a gaussian copula , which has the ability to model pairwise dependence , we can then easily proceed upwards to the general multivariate unimodal density .",
    "the layout of the paper is as follows : in section 2 we provide the key representation of unimodal densities on the real line which we adapt in order to define continuous densities .",
    "otherwise there is an issue of continuity at the mode . with a full representation of unimodal densities ,",
    "we need a novel mcmc algorithm , particularly , and perhaps strangely , to include a non - zero mode .",
    "section 3 then deals with the multivariate setting .",
    "there are peculiarities to the higher dimension case with the mcmc and again it is the location of the mode parameter which needs special attention .",
    "section 4 provides a real data analysis .",
    "our aim in this paper is to start with the representation of @xcite for unimodal densities on the real line and extend it to higher dimensions in a natural way , using the multivariate gaussian copula .",
    "the representation of @xcite is given by @xmath3 , where @xmath4 is uniform on @xmath5 $ ] and @xmath6 , independent of @xmath4 , has any distribution .",
    "then @xmath7 has a unimodal distribution with mode at @xmath8 . to see this",
    "let us consider the situation of @xmath9 .",
    "so @xmath10 and hence @xmath11 where @xmath12 is used to represent the density function of @xmath6 . to see more clearly the unimodality at @xmath8 , let us use the transform @xmath13 , so @xmath14 which is maximized at @xmath15 .",
    "this representation has been widely used and is usually presented as a mixture of uniform distribution ; i.e. @xmath16 the prior for @xmath17 , in a bayesian nonparametric setting , is usually taken as a dirichlet process ( @xcite ) . to denote this we write @xmath18 , where @xmath19 is a scale parameter , and @xmath20 a distribution function . in particular ,",
    "@xmath21 .    now @xcite and",
    "@xcite , among others , have worked with this specification and extended to the real line with arbitrary mode by using @xmath22 for some @xmath23 .",
    "this specification leads to a symmetric density .",
    "furthermore , @xcite develop the model to allow for asymmetry by adopting the idea of @xcite ; incorporating an asymmetry parameter @xmath24 in the uniform kernel , @xmath25 so ( [ rw2012 ] ) defines a unimodal density determined by @xmath26 , where @xmath27 is the location parameter , @xmath24 defines the asymmetry , and the distribution @xmath17 defines characteristics such as variance , kurtosis , tails and higher moments . with this representation ,",
    "the support of the model proposed by @xcite includes all symmetric unimodal densities and a large class of asymmetric ones .",
    "however , when extending to the real line , and using a natural density for @xmath12 such as the normal , we encounter the situation of @xmath28 .",
    "in fact , on the real line , @xmath12 needs to be somewhat unusual to ensure that @xmath29 .",
    "see the form of density in ( [ oldf ] ) .    to resolve this problem , we instead work with @xmath30 ; so again looking at @xmath9 , we have @xmath31 hence , @xmath32 and using the transform @xmath33 we obtain @xmath34 thus we see the mode is again at @xmath15 and @xmath35 will be finite subject to the more reasonable assumption that @xmath36 is integrable at @xmath8 , rather than the more unreasonable assumption that @xmath37 is integrable at @xmath8 in the former setting .      here",
    "we further investigate the choice of @xmath6 being a normal distribution with the representation @xmath30",
    ". we can easily extend ( [ posuni ] ) to the whole real line ; resulting in @xmath38 for a mode at @xmath39 we simply exchange @xmath40 for @xmath41 . if the mode is at @xmath8 , then for @xmath42 , we need @xmath43 our aim is to take @xmath12 as a large class of density functions on the real line and the full class is given by mixtures of normal distributions .",
    "thus , it is expedient to compute ( [ realuni ] ) for @xmath44 normal with mean @xmath45 and variance @xmath46 .",
    "that is , for @xmath47 @xmath48 which , after some algebra , results in @xmath49 + \\sigma\\left[\\phi\\left(\\frac{-\\mu}{\\sigma}\\right)-\\phi\\left(\\frac{\\xi-\\mu}{\\sigma}\\right)\\right],\\ ] ] where @xmath50 and @xmath51 are the pdf and cdf , respectively , for the standard normal distribution . with @xmath52",
    "we simply need to rearrange the signs , so @xmath53 + \\sigma\\left[\\phi\\left(\\frac{-\\mu}{\\sigma}\\right)-\\phi\\left(\\frac{\\xi-\\mu}{\\sigma}\\right)\\right ] \\right|.\\label{moduni}\\ ] ] hence , this @xmath54 holds for all @xmath55 .    to move the mode to @xmath27 , rather than @xmath8 , write @xmath56 with @xmath57 given by ( [ moduni ] ) .",
    "we could also maintain the representation ( [ origuni ] ) in which case we can write @xmath58 the usefulness of this is that it provides a latent joint density function which will be helpful when it comes to model estimation , namely , @xmath59 for the forthcoming mixture model , where we consider mixtures of normals for @xmath6 , we find it convenient for identifiability concerns , to use the parametrization @xmath60 , where @xmath61 .",
    "the model proposed for the class of unimodal density functions on @xmath62 is a mixture of the unimodal densities with mode at @xmath27 proposed in section [ unimoddens ] , i.e. ( [ withx ] ) .",
    "this model can we written as @xmath63 the mode is therefore at @xmath27 and we allow parameter @xmath64 , which is a transformation of the coefficient of variation , to remain fixed across the normal components .",
    "this is analogous to keeping the variance terms fixed , for identifiability concerns , in a mixture of normal model .",
    "the support of the model is not diminished by doing this .",
    "therefore , we can write @xmath65 where @xmath17 is a discrete distribution with mass @xmath66 at the point @xmath67 . hence , in a bayesian + context , the parameters to be estimated and first assigned prior distributions are + @xmath68 , with the constraints being that the weights sum to 1 , @xmath69 , and the @xmath70 are distinct . as an illustration , figure [ density ] shows the density function of a mixture of two components with @xmath71 , @xmath72 , @xmath73 and @xmath74 .",
    "the claim is that model [ mixmod ] can be arbitrarily close to any unimodal density on the real line .",
    "the key is writing @xmath75 rather than @xmath76 , and with the former we can employ the full support abilities of a mixture of normals without the problem of a discontinuity at the mode .        to complete the model described in the previous section",
    ", we now set the prior distributions for the unknown model parameters .",
    "specific values are assigned in the illustration section .",
    "* the prior distribution for the parameters @xmath70 are normal with zero mean and variance @xmath77 ; while the prior for @xmath27 will also be normal with zero mean and variance @xmath78 .",
    "the prior for @xmath64 will be gamma with parameters @xmath79 . * the prior distribution for the weights @xmath80 has a stick - breaking construction ( @xcite ) , given by @xmath81 with the @xmath82 being i.i.d . from a beta distribution with parameters @xmath83 and @xmath84 .",
    "we assume a gamma , @xmath85 , as the hyper - prior for the parameter @xmath84 .    as a consequence ,",
    "the prior for @xmath17 in ( [ mixmod ] ) is a dirichlet process with mean distribution @xmath86 and scale parameter @xmath84 .    before detailing the mcmc algorithm for this model",
    ", we will now introduce the key latent variables which facilitate an `` as easy as possible '' implementable algorithm .",
    "first , to deal with the infinite sum of elements in ( [ inftysum ] ) , we introduce a variable @xmath87 , such that we have the joint density with observation @xmath40 , as @xmath88 for some decreasing deterministic sequence @xmath89 .",
    "see @xcite for details and choices of @xmath89 .",
    "in particular , we use @xmath90 , with @xmath91 , but other sequences can be used .",
    "the key here is that given @xmath87 , the number of components is finite , and correspond to the indices @xmath92 , such that @xmath93 next we introduce the component indicator @xmath94 for each observation , which tells us from which component available the observation came from , resulting in the joint density with @xmath95 as @xmath96 the joint likelihood function , including latent variables , is then given by @xmath97 and it will be convenient to define @xmath98 .",
    "it turns out that the most complicated parameter to deal with is @xmath27 ; surprisingly , since often the location parameter is one of the easiest to sample in a mcmc routine .",
    "thus , we will initially describe the algorithm assuming @xmath27 is known .",
    "the unknown quantities that need to be sampled from , under that scenario , are : @xmath99 ; @xmath100 ; @xmath64 and @xmath84 .",
    "the sampling of these parameters and latent variables is as follows , obviously conditional on other parameters and variables being known in each case :    1 .",
    "sample @xmath101 from the uniform distribution on @xmath102 , for @xmath103 .",
    "a useful summary to record here is @xmath104 .",
    "2 .   sample from @xmath84 following the approach in @xcite .",
    "now @xmath84 only depends on the other model parameters through the number of distinct @xmath105 and the sampling goes as follows , * sample @xmath106 , where @xmath107 is the current value for @xmath84 . * sample @xmath84 from @xmath108 + where @xmath109 is the number of distinct @xmath105 .",
    "sample @xmath70 for @xmath110 via metropolis - hastings ( m - h ) .",
    "if there is at least one @xmath111 then we use the m - h step , otherwise the @xmath67 comes from the prior . the proposal @xmath112 is taken to be normal , centered at the current value , i.e. @xmath113 the m - h acceptance criterion is given by : @xmath114 where @xmath115 represents the prior distribution .",
    "we accept the proposal with probability @xmath116 .",
    "sample @xmath64 via metropolis - hastings .",
    "the proposal @xmath117 is obtained from : @xmath118 the m - h acceptance criterion is given by : @xmath119 where @xmath120 denote a source density for a candidate draw @xmath117 given the current value @xmath64 in the sampled sequence . in this case ,",
    "@xmath121 , and we accept the proposal with probability @xmath116 .",
    "5 .   sampling from @xmath122 can be done directly since we have the probability mass function , @xmath123 where @xmath124 .    when the mode @xmath27 is unknown , simply adding an extra step in the algorithm above is neither efficient nor viable .",
    "the reason for this is that @xmath27 and the @xmath70 are highly correlated .",
    "data values coming from cluster @xmath125 with @xmath126 are typically larger then @xmath27 , while if @xmath127 , they are typically smaller .",
    "the consequence is that for fixed values of @xmath67 , any proposals for @xmath27 are prone to be rejected .",
    "the explanation for this is the following .",
    "let @xmath128 be the ordered data , and suppose the initial / current value for @xmath27 , written as @xmath129 , in the mcmc algorithm , places it between @xmath130 and @xmath131 , for some @xmath132 , as shown in figure [ fig : toy ] .",
    "it is likely that @xmath133 belong to clusters with negative @xmath67 , and @xmath134 belong to clusters with positive @xmath67 .",
    "this is true particularly for data which is close to @xmath27 , as from ( [ withx ] ) we can see that they correspond to large values of @xmath135 .",
    "these large values typically generate positive values of @xmath136 when @xmath126 , and negative values of @xmath136 when @xmath127 .",
    "suppose we start the algorithm assigning to the data clusters whose @xmath137 have a sign which is negative for @xmath138 smaller than @xmath27 , and positive otherwise .",
    "if we now propose moving the value of @xmath27 to , say , somewhere between @xmath131 and @xmath139 , it means that @xmath131 will be incompatible with its corresponding cluster .",
    "the same happens if we move @xmath27 in the opposite direction .",
    "more drastic moves make the problem more acute .    a solution for this would be to test moves of @xmath27 and @xmath140 jointly in a metropolis - hastings step",
    ". that , however , would be very inefficient due to the possible high numbers of @xmath70 involved .",
    "our idea then is to test a new proposal for @xmath27 jointly with moving the affected @xmath138 , so the m - h step utilized to sample @xmath27 , and possibly some of the @xmath122 , is now described .    to make the proposal , first sample auxiliary variable @xmath141 from a discrete uniform distribution in the interval @xmath142 $ ] , for a chosen @xmath143",
    "this sampled value will give the size and direction of the move we wish to propose for @xmath27 .",
    "as a toy example , suppose we choose @xmath144",
    ". therefore , @xmath141 will be either @xmath145 or @xmath146 , with the same probability .",
    "if @xmath147 is placed between order statistics @xmath130 and @xmath131 we have that : if @xmath148 , @xmath129 will be sampled uniformly within the interval @xmath149 $ ] ; if @xmath150 , @xmath129 will be sampled uniformly within the interval @xmath151 $ ] , and so forth , as illustrated in figure @xmath152 .",
    "note , however , that near the edges ( @xmath153 and @xmath154 ) not every one of these movements can be made . for instance , in the example above , if @xmath155 , the movement proposed by @xmath148 is not possible , since there is no interval @xmath156 $ ] . in that case , @xmath141 is sampled uniformly between the possible values , which in this case would be @xmath157 and @xmath146 .",
    "generalizing the notation , @xmath129 will be sampled within the interval @xmath158 $ ] , where @xmath159 , and @xmath160 , with @xmath161 representing the rank of the order statistics of the @xmath40 which is immediately ranked lower than @xmath147 . in our toy example , @xmath162 .",
    "if @xmath163 , only a new proposal for @xmath27 will be made , @xmath164 ; otherwise we will also test moving the observations which fall between @xmath147 and @xmath129 to a different cluster . if @xmath165 , we propose moving these observation to the same cluster of @xmath166 . if @xmath167 , we propose moving them to the same cluster of @xmath168 . in our example , if @xmath169 , it means proposing that @xmath170 $ ] and @xmath171 $ ] are equal to @xmath172 $ ] , where @xmath172 $ ] represents the cluster to which @xmath130 belongs to . in the general case , we have :    * if @xmath173 , we propose that @xmath174,\\ldots , d^{o}[h]$ ] are equal to @xmath170 $ ] ; * if @xmath175 , we propose that @xmath170,\\ldots , d^{o}[h+s]$ ] are equal to @xmath176 $ ] .",
    "the metropolis rate is given by : @xmath177 where @xmath178 and , analogously , @xmath179 we accept the proposal with probability @xmath116 .",
    "to test our model and the proposed mcmc algorithm , we simulate two artificial data - sets , and predict their densities .",
    "the idea here is verify if we can efficiently reconstruct the densities , which in this case are known .",
    "the simulated models are given bellow :    * @xmath40 is sampled from @xmath180 ; * @xmath40 is sampled from @xmath181 .",
    "data - sets of size @xmath182 were simulated from models a and b. figure [ simuldata ] shows the histogram of these data - sets and the density of the distribution they were generated from .",
    "all figures included in this article were produced via the software r ( @xcite ) .",
    "the two sets of observations are modeled through [ inftysum ] , with the following specifications for the parameters of the prior distributions : @xmath183 , @xmath184 , @xmath185 , and @xmath186    for each data - set , the algorithm proposed in section @xmath187 was applied to sample from the posterior distribution of the model parameters .",
    "the mcmc was implemented in the software ox version 7.0 ( @xcite ) , with @xmath188 iterations and a burn in of @xmath189 . due to auto - correlation in the mcmc chains ,",
    "the samples were recorded at each @xmath190 iterations , leaving us with samples of size @xmath191 to perform inference .",
    "figure [ hista ] shows the histogram of the sample from the posterior of parameter @xmath27 under data - sets a and b. note that in both cases the real value of the parameter is well estimated , falling close to the mode of the estimated posterior density .",
    "figure [ preda ] shows the histograms of the predictive distributions under both data - sets compared with their real density .",
    "it can be seen that in both cases the predictive distribution is close to the real density , showing the flexibility of the model and validating the methodology .",
    "this section is divided in two sub - sections .",
    "firstly , in sub - section [ multuni ] , we discuss different definitions of multivariate unimodality that can be found in the literature . in sub - section [ multext ]",
    "we propose a class of multivariate unimodal densities , extending the univariate densities of section [ unimoddens ] .",
    "the concept of unimodality is well established for univariate distributions , and , following khintchine s representation ( @xcite ) , it can be defined in different but equivalent ways .",
    "it is not straightforward , however , to extend the notion of unimodality to higher dimensional distributions , as different definitions of unimodality are not equivalent when extended .",
    "the first attempts to define multivariate unimodality were made for symmetric distributions only , by @xcite and @xcite .",
    "again under symmetry , @xcite introduced the notion of _ convex unimodality _ and _ monotone unimodality_. the authors also defined _ linear unimodality _ , which can be applied to asymmetric distributions .",
    "a random vector @xmath192 is _ linear unimodal _ about @xmath8 if every linear combination @xmath193 has a univariate unimodal distribution about @xmath8 .",
    "this , however , is not a desired definition , as pointed out by @xcite themselves , as the density of such may not be a maximum at the mode of univariate unimodality .",
    "further , @xcite define _ @xmath194unimodality _ about @xmath8 for a random variable @xmath7 in @xmath195 when for all real , bounded , nonnegative borel function @xmath12 on @xmath195 the function @xmath196 is non - decreasing as @xmath197 increases in @xmath198 , where @xmath199 denotes the expectation with respect to the density of @xmath7 .",
    "if @xmath4 has a density function @xmath200 with respect to the lebesgue measure @xmath201 on @xmath195 , then @xmath4 is _ @xmath194unimodal _ if and only if @xmath202 is decreasing in @xmath203 .",
    "the distribution of a random vector @xmath192 is said to be _",
    "star unimodal _ about @xmath8 , according to @xcite , if it is @xmath204-unimodal in the sense of @xcite .",
    "according to @xcite , a _ linear unimodal _ distribution need not be _ star unimodal _ , and vice versa .",
    "thus there is no implied relationship between _ star _ and _ linear unimodality_.    another useful definition of unimodality is given by @xcite : a multivariate density @xmath200 on @xmath205 is _ orthounimodal _ with mode at @xmath206 if for each @xmath125 , @xmath207 is a decreasing function of @xmath208 as @xmath209 for @xmath210 , and as @xmath211 for @xmath212 , when all other components are held fixed .",
    "_ orthounimodal _ densities are widely applicable .",
    "they form a robust class in the sense that all lower - dimensional marginals of _ orthounimodal _ densities are also _ orthounimodal_. also , they are _ star unimodal _ , according to @xcite , and most bivariate densities are either _ orthounimodal _ , or _ orthounimodal _ after a linear transformation . narrower notions than _ orthounimodality _ can also be explored , and they are discussed in @xcite .    for the two dimensional case only , @xcite generalizes khintchine s stating that the distribution function of @xmath213 is unimodal if and only if it can be written as @xmath214 where @xmath215 and @xmath216 are independent and @xmath215 is uniformly distributed in @xmath5 $ ] . for higher dimensions , khintchine s representation",
    "was generalized by @xcite for the symmetric case .",
    "he defines symmetric multivariate unimodal distributions on @xmath205 as generalized mixtures ( in the sense of integrating on a probability measure space ) of uniform distributions on symmetric , compact and convex sets in @xmath205 . in this paper",
    "we will use a form of ( [ bikhin ] ) while guaranteeing orthounimodality .",
    "comprehensive reviews on multivariate unimodality can be found in @xcite and @xcite .",
    "also @xcite reviews the literature and introduces and discusses a new class of nonparametric prior distributions for multivariate multimodal distributions .      to extend the univariate unimodality proposed in section [ unimoddens ] , we start by de- + fining marginal variables @xmath217 via @xmath218 , where @xmath219 and @xmath220 , for @xmath221 .",
    "the dependence between variables @xmath222 can be obtained imposing dependence to either @xmath223 or @xmath224 , or both .",
    "our first attempt was to allow dependence only in @xmath6 through a multivariate normal distribution with a general variance - covariance matrix .",
    "this way our construction would be following the generalization of khintchine s representation made by @xcite for the bivariate case .",
    "the dependence obtained between @xmath7 under that construction , however , for a bivariate setting , is limited .",
    "better results were obtained when imposing dependence in @xmath4 instead , through a gaussian copula .",
    "to demonstrate : figure [ correlations ] shows the approximate 95% confidence intervals of the correlations between @xmath7 when varying the correlations between @xmath6 ( top ) and @xmath4 ( bottom ) respectively , through the interval @xmath225 .",
    "these confidence intervals were found by the simulation of @xmath190 samples of size @xmath190 .",
    "the figure was constructed considering @xmath226 and @xmath227 .",
    "similar results to the ones with @xmath228 were found for @xmath229 . in the same way , @xmath230 and @xmath227 present similar results",
    ". the magnitude of @xmath45 did not seem to change this output significantly .",
    "it can be seen that when imposing dependence through @xmath6 , the correlation between @xmath7 do not vary much beyond the interval @xmath231 $ ] , while the correlation between the @xmath232 and the correlation between the @xmath233 was found to be similar .    due to the results",
    "just described we opted to work with the second construction : i.e. @xmath234 , @xmath235 , and @xmath236 are modeled through the gaussian copula with correlation matrix @xmath237 . once again , the mode at @xmath238 can be exchanged , substituting @xmath7 for @xmath239 where @xmath27 , as well as @xmath7 , is now a @xmath240dimensional vector .",
    "given @xmath241 , @xmath242 , @xmath243 and @xmath244 , the observations @xmath245 are independent , and @xmath246 is given by @xmath247 the marginal model , @xmath248 , can be obtained through the integral @xmath249^d } \\prod_{l=1}^d ( x_l / y_l^2)g_l(x_l / y_l|\\mu_{lj},c_l,\\kappa_l ) \\d c(x_1 , \\ldots , x_d|\\sigma ) , \\label{intmult}\\ ] ] where @xmath250 represents the multivariate gaussian copula with correlation matrix @xmath237 : @xmath251    note , however , that the dependence created between variables @xmath7 is defined not only by the correlation matrix @xmath237 , but also by the sign of the components of @xmath45 . as an illustration",
    ", we sampled four bivariate data - sets , and examined the dispersion plots between @xmath252 and @xmath253 .",
    "figure [ example_multi_1 ] shows the dispersion plot between data sampled with @xmath254 , and either @xmath255 or @xmath256 , and with @xmath257 = 0.5 $ ] , @xmath258 or @xmath259 .",
    "it can be seen that positive dependence is created when @xmath260 is positive , and negative dependence is created otherwise . to help the model identification",
    ", we assume that @xmath261 $ ] .",
    "this restriction does not take away the model flexibility , and negative correlations between the variables can be captured by opposite signs in @xmath45 .",
    "let us now define the mixture of these densities , which is the unimodal multivariate model of interest .",
    "for observation @xmath262 the model is : @xmath263 where @xmath248 is in ( @xmath264 ) .",
    "note that , by construction , the proposed distribution is multivariate _ orthounimodal _ , which is , therefore , also _",
    "star unimodal_. unlike the univariate case , however , we can not solve the integral in ( [ intmult ] ) and obtain @xmath248 analytically .",
    "therefore , we must come up with a different algorithm to solve the sampling of @xmath27 . as a `` bridge '' to the multivariate case",
    ", this algorithm is first developed for the univariate case , and then extended to higher dimensions .",
    "the univariate `` bridge '' algorithm is presented in subsection [ bridge ] .",
    "to mimic the situation in which the latent variable @xmath241 can not be integrated out , we present in this section an algorithm which samples from @xmath265 , and samples from the other parameters given @xmath241 .",
    "we consider the same prior distributions specified in section [ priors ] .",
    "for @xmath241 we assume a uniform prior at @xmath5^n$ ] .",
    "the algorithm goes as follows :    1 .",
    "sample @xmath101 and obtain @xmath104 as previously in section [ priors ] ; 2 .",
    "sample @xmath84 as previously in section [ priors ] ; 3 .",
    "sample @xmath70 for @xmath266 as before , but using @xmath267 ( proportional to [ withx ] ) instead of @xmath268 in the metropolis ratio .",
    "this way , the m - h acceptance criterion is given by : @xmath269 4 .",
    "the full conditional distribution of @xmath64 in this case has a closed form , and it is updated via gibbs sampling",
    ". given @xmath40 , @xmath241 , @xmath45 and @xmath27 , we have : @xmath270 5 .",
    "sample @xmath271 in two stages : first sample from @xmath272 and then from @xmath273 . @xmath94 and @xmath27 are sampled as before , and @xmath274 for @xmath275 , is sampled via rejection sampling , as follows : * sample a proposal @xmath276 $ ] ; * compute @xmath277 * compute the value @xmath278 which maximizes the function : @xmath279 * accept @xmath280 with probability @xmath281 , or go back to the first step .",
    "the results obtained under this algorithm were similar to those obtained from the previous one , despite being considerably slower .",
    "the new algorithm , however , can be easily extended to the multivariate case . in this paper",
    "we will discuss the algorithm and results obtained for the bivariate case , and leave higher dimensionality for future work .",
    "in this section we present the algorithm developed to handle bivariate observations ( @xmath282 ) . under this scenario ,",
    "the unknown quantities are : @xmath283 ; @xmath100 ; @xmath284 ; @xmath84 ; @xmath285 , @xmath286 , and also the correlation parameter in the bivariate gaussian copula ( @xmath287 ) .",
    "as pointed out in section [ multext ] , without compromising the model flexibility , we can assume that @xmath261 $ ] .",
    "therefore we assigned a @xmath288 $ ] prior for this parameter .",
    "the algorithm proposed for the bivariate case is given below :    1 .",
    "sample @xmath101 and obtain @xmath104 as previously ; 2 .",
    "sample @xmath84 as previously ; 3 .",
    "sample @xmath289 and @xmath290 , independently for @xmath266 , following the same idea as in ( [ bridge ] ) ; 4 .",
    "sample @xmath291 and @xmath292 via gibbs sampling . given @xmath40 , @xmath241 , @xmath45 , and @xmath27",
    ", we have : @xmath293 5 .   sample @xmath294 and @xmath295 independently , using a similar algorithm as previously .",
    "note that every time @xmath294 and @xmath295 are updated , some elements of @xmath94 might also be changed .",
    "sample @xmath122 directly from its probability mass function , @xmath296 where @xmath124",
    "sample @xmath297 via rejection sampling . here",
    "we consider two possible algorithms : *   * sample from the copula @xmath298 : @xmath299 * compute @xmath300 * compute the values @xmath301 and @xmath302 which maximize the function above : @xmath303 * accept @xmath304 with probability @xmath305 or go back to the first step .",
    "*   * sample @xmath306 from the function @xmath307 through adaptive rejection sampling ( @xcite ) ; * compute @xmath308 ; * compute the values @xmath301 and @xmath302 which maximize the copula : @xmath309 and @xmath310 ; * accept @xmath304 with probability @xmath311 or go back to the first step .",
    "+ the first algorithm proposed to sample from @xmath241 leads to faster convergence",
    ". however , it can be very slow at times , requiring a large amount of simulations until acceptance .",
    "we combined the two algorithms in the following way : sample from 7.1 until it either accepts the proposal or reaches a set limited number of trials .",
    "if the latter occurs , sample from @xmath241 through algorithm 7.2",
    "sample @xmath287 via metropolis - hastings .",
    "the proposal @xmath312 is obtained from : + @xmath313 for a suitable choice of @xmath314 + the m - h acceptance criterion is given by : @xmath315 where @xmath316 .",
    "we accept the proposal with probability @xmath116 .      in this section we present the results obtained for a simulated bivariate data - set of size @xmath182 , from a bivariate normal distribution : @xmath317 with @xmath318 , and @xmath319 , with @xmath320 .",
    "the algorithm proposed in section [ bivariate ] was applied to sample from the posterior distribution of the model parameters and obtain samples of the predictive distributions .",
    "the algorithm was run for @xmath321 iterations , with a burn in of @xmath322 . due to auto - correlation in the mcmc chains ,",
    "samples were recorded at each @xmath323 iterations , leaving a sample of size @xmath324 to perform inference .",
    "figure [ k_bi_2 ] shows the histograms of the posterior densities of the components of parameter @xmath27 .",
    "it can be seen that this parameter was reasonably well estimated , with the true value being close to the posterior mode .",
    "figure [ hist_bi_2 ] presents a comparison between the histograms of the simulated samples of @xmath252 and @xmath253 , and the ones predicted through the proposed mcmc algorithm , showing that the predictions seem close to what was expected .",
    "we also wish to verify if the dependence between @xmath252 and @xmath253 was preserved in the predictions . to do this analysis , we computed the correlation at every @xmath190 samples of the predicted @xmath325 .",
    "this time we used the full @xmath326 sampled values , ending up with a sample of size @xmath327 correlations .",
    "figure [ cor_bib ] compares the histogram of these correlations , which can be seen as a proxy of the posterior distribution of @xmath328 , to the real values ( in red ) , showing good predictions .",
    "as an application , we work with a part of the boston housing data - set created by @xcite and taken from @xcite .",
    "this database comprises @xmath329 cases of @xmath330 variables concerning housing values in the suburbs of boston , and it has been used in many applications , especially in regression and machine learning , such as @xcite and @xcite .",
    "we chose to work with two variables of the database : nitric oxides concentration ( parts per 10 million ) at the household ( nox ) and weighted distances to five boston employment centers ( dis ) .",
    "exploratory analysis points towards the unimodality of the joint density of nox and dis , as can be seen by the contour plot displayed in figure [ realdata ] .",
    "this contour plot also shows a negative , unusually shaped , dependence between these variables .",
    "histograms of observations nox and dis are also presented in figure [ realdata ] , showing that both variables have a non - normal unimodal shape .",
    "our objective in this application is to illustrate the flexibility of our approach in capturing the form of this bivariate distribution and the oddly shaped dependence between nox and dis .",
    "we worked with a sub - set of @xmath182 observations and applied the proposed bivariate model with the same priors used for the toy examples .",
    "again , the algorithm was run for @xmath321 iterations , with a burn in of @xmath322 , and recorded at every @xmath323 iteration , totalizing a sample of size @xmath324 for inference .",
    "figure [ preddata ] shows the histograms of the predictive density of nox and dis , and the contour plot made with @xmath331 points of the predictive distribution .",
    "we observe a high similarity between the real and the predicted histograms and dispersion plots , and can conclude that the proposed methodology was able to capture well the behavior of the data for this example .    note that our approach also allows for predictions of one variable",
    "given the other after samples of both had been previously observed .",
    "as a second exercise , we analyze the predictive capacity of our model , compared to a more usual linear alternative .",
    "if the objective is to predict nitric oxides concentration based on weighted distances to employment centers , a regression model would probably be considered . as can be seen in figure [ realdata ]",
    ", however , the data needs transformation for the normal linear regression model assumptions to hold adequately .",
    "after exploratory analysis , we propose the following regression model : @xmath332 with vague normal priors for @xmath333 and @xmath334 , and a vague inverse wishart prior for @xmath335 .",
    "figure [ tranfnorm ] shows the box - plot of the response variable nox@xmath336 and the dispersion plot between nox@xmath336 and log(dis ) , showing a linear dependence between both variables .",
    "the simple regression was fit using software openbugs 3.2.3 ( @xcite ) .",
    "a comparison is then performed between predictions of @xmath337 values of nox given dis , after observing @xmath182 cases of both dis and nox , under both models .",
    "figure [ preddata1 ] presents the 95% credible intervals and posterior medians under the proposed nonparametric model and the simple regression model , being compared with the real values .",
    "figure [ preddata2 ] presents the histograms of the posterior distribution of the first three predicted values . as is typical",
    ", nonparametric methods produce larger credible intervals than the parametric counterparts , yet are typically centered in the true values .",
    "the parametric versions however can simply be wrong .",
    "in this paper we have proposed a new class of unimodal densities whose support include all the unimodal densities on the real line .",
    "our motivation for this is that a mixture of the proposed univariate model can be adequate to cluster data , with each cluster being represented by a unimodal density .",
    "one of our objectives was also to be able to create a class of unimodal densities that could be naturally extended to the multivariate case .",
    "our models allow this through the use of the multivariate gaussian copula .",
    "this way , modeling multivariate clusters can also benefit from the methodology developed in this paper .",
    "the proposed models , however , can not be dealt with analytically .",
    "we have also proposed an mcmc algorithm to obtain samples of the posterior distribution of the model parameters and to obtain predictive densities .",
    "the methodology was illustrated with univariate and bivariate examples , and with two variables taken from the boston housing data ( @xcite ) .",
    "modeling multivariate unimodal densities with dimension higher than two can be easily done with a slight modification to the code presented in section [ bivariate ] . in that case , instead of sampling from a single correlation parameter @xmath287 , we must sample from a correlation matrix , which can be done following @xcite .",
    "preliminary results showed this to be effective for a three - variate model . for future work",
    "we must test the code extensively for three or more dimensions , and finally do clustering for an arbitrary dimension @xmath94 , through the mixture of the densities proposed in this paper .",
    "the first author acknowledges the support of a research grant from cnpq - brazil .",
    "kouvaras , g. , kokolakis , g. : random multivariate multimodal distributions . in : skiadas ,",
    "( ed . ) recent advances in stochastic modelling and data analysis , pp .",
    "6875 . world scientific publishing co. ( 2008 )        quinlan , r. combining instance - based and model - based learning . in proceedings on the tenth international conference of machine learning , 236 - 243 , university of massachusetts , amherst .",
    "morgan kaufmann ."
  ],
  "abstract_text": [
    "<S> in this paper we introduce a new class of multivariate unimodal distributions , motivated by khintchine s representation . </S>",
    "<S> we start by proposing a univariate model , whose support covers all the unimodal distributions on the real line . the proposed class of unimodal distributions can be naturally extended to higher dimensions , by using the multivariate gaussian copula . under both univariate and multivariate settings , </S>",
    "<S> we provide mcmc algorithms to perform inference about the model parameters and predictive densities . </S>",
    "<S> the methodology is illustrated with univariate and bivariate examples , and with variables taken from a real data - set .    </S>",
    "<S> _ keywords _ : unimodal distribution , multivariate unimodality , mixture models , nonparametric bayesian inference . </S>"
  ]
}