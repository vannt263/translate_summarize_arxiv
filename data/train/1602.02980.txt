{
  "article_text": [
    "the unpredictability of turbulence makes a deterministic analysis of the instantaneous velocity field not only impractical , but very nearly impossible .",
    "researchers have instead studied the statistical properties of turbulence , which necessarily involves the probabilities of velocities and their fluctuations @xcite .",
    "although information theory is the natural language for treating these probability distributions @xcite , there have been few studies that make use of it . instead",
    ", the focus has often been on the moments @xcite .    in wall - bounded flows , for example",
    ", considerable effort has been directed towards determining the mean velocity profile as a universal function of distance from the wall @xcite . in other situations ,",
    "the fluctuations are of primary interest and the focus has been on the moments of velocity differences @xcite : @xmath0 ^n   \\rangle_x.\\ ] ] these velocity differences are thought to represent the characteristic velocity of a turbulent  eddy \" of size @xmath1 , a concept that goes back to l.f .",
    "richardson and his contemporaries @xcite .",
    "the importance of @xmath2 in turbulence is apparent from its appearance in kolmogorov s @xmath3th law for @xmath4 @xcite .",
    "this law is derived using several significant assumptions and the navier - stoke s equations @xcite and remains one of the only exact solutions in turbulence .",
    "it is the starting point for the entire scaling phenomenology of turbulence .    here",
    "we propose a different approach . instead of beginning with the moments @xmath5 and kolmogorov - type assumptions , we will focus on the probability distributions used to calculate the @xmath5 , @xmath6 @xcite : @xmath7 with these probability distributions",
    ", information theory can be used to make quantitative statements about , @xmath8 , the unpredictability of @xmath2 .",
    "of course , all the information about the moments is contained in @xmath6 , so our analysis can not be completely unrelated to the traditional theory . in order to gauge the usefulness of this approach ,",
    "we apply it to a key turbulence concept .",
    "big whirls have little whirls + that feed on their velocity , + and little whirls have lesser whirls + and so on to viscosity .",
    "+   the cascade concept captured by this rhyme can be formulated with information theory , because the @xmath9 of the cascade leaves its mark on the probability distributions of the eddies ( whirls ) . in short , the uncertainty in observing a big eddy become a small eddy should be less than the reverse .    using experimental observations of ( quasi-)2d turbulent flow ,",
    "we confirm the eddy hypothesis without the navier - stoke s equations , scaling arguments or kolmogorov s assumptions , although some of the features of that kind of analysis ( self - similarity @xcite ) reappear naturally .",
    "a completely new result is the existence and direction of information transfer . before we can come to these conclusions , however",
    ", we must review the salient features of turbulence and information theory .",
    "two - dimensional ( 2d ) turbulence occurs approximately in nearly all large - scale atmospheric flows due partly to the fact that the thickness of the earth s atmosphere is very small compared to its breadth @xcite .",
    "this , along with stratification @xcite , result in vast regions of the atmosphere where the vertical velocity is negligible compared with the horizontal .",
    "for the same reason large scale oceanic flows are also considered two - dimensional .",
    "our measurements are made using a soap film , which has an even smaller aspect ratio .",
    "the physics of soap films and their usefulness in studying 2d flows and 2d turbulence has already been well documented @xcite , but we present some of the essential experimental details below . although we utilize 2d turbulence , our results should extend to 3d turbulence without any significant alteration .",
    "the soap solution is a mixture of dawn ( 2@xmath10 ) detergent soap and water with 10 @xmath11 m hollow glass spheres added for the velocity measurements .",
    "figure [ setup ] is a diagram of the experimental setup .",
    "the soap film is suspended between two vertical blades connected to a nozzle above and a weight below by nylon fishing wire .",
    "the nozzle is connected by tubes to a valve and a reservoir which is constantly replenished by a pump that brings the spent soap solution back up to the reservoir .",
    "there is an overflow that leads back to the bottom reservoir so that the height of the top reservoir , and thus the pressure head , is constant",
    ". sometimes the pump feeds directly into nozzle , giving results indistinguishable from the reservoir setup .",
    "the flow is always gravity - driven .",
    "typical centerline speeds @xmath12 are several hundred cm / s with rms fluctuations @xmath13 generally on the order of 10 cm / s .",
    "the channel width @xmath14 is usually several cm .",
    "the flow velocity is measured using particle image velocimetry ( piv ) @xcite .",
    "a bright white light source is placed behind the soap film and shines on the soap film at an angle ( so that the light does not directly enter the camera , which is perpendicular ) .",
    "the particles scatter more light than the surrounding soap water and are easily distinguished .",
    "a fast camera tracks their movement and standard piv techniques are used to calculate the velocity field . because the full velocity field at different times is needed for our analysis , we use piv and can not use , @xmath8 , laser doppler velocimetry .",
    "we focus on the wall - normal or horizontal velocity @xmath15 instead of the vertical velocity @xmath16 because it does not suffer from aliasing effects @xcite and because @xmath12 changes slightly with @xmath17 ( due to gravitational acceleration ) .",
    "we take velocities very near the center of the channel to avoid wall effects and variations in the energy and enstrophy ( norm of vorticity ) injection rates @xcite .",
    "turbulence in the soap film is generated by inserting a row of rods ( comb ) perpendicular to the film .",
    "when this protocol is used we almost always observe the direct enstrophy cascade @xcite . in the traditional phenomenology",
    ", enstrophy is transferred from some large injection scale @xmath18 @xmath19 to a viscous dissipative scale @xmath20 @xcite .",
    "the rate of enstrophy transfer is @xmath21 , which should be constant over the inertial range of scales in between @xmath18 and @xmath20 .",
    "we introduce this traditional framework in order to contrast it with our own approach , as well as provide evidence to the portential skeptic that we are indeed working with a direct cascade .",
    "as is customary we assume that the energy spectrum @xmath22 of velocity fluctuations scales with @xmath21 and the wavenumber @xmath23 , an inverse length , for a certain range of @xmath23 ( inertial range ) . for the direct enstrophy cascade , @xmath24 . in fig .",
    "[ spectra ] we plot all of the @xmath22 calculated from @xmath15 .",
    "the curves have been normalized using the large length scale @xmath25 and the rms velocity @xmath26 .",
    "all of the curves collapse at low and intermediate @xmath23 , a signature of the cascade s self - similarity @xcite .",
    "the physical process that created this curve is similar in all cases .",
    "we now outline our test .",
    "consider the diagram of a turbulent cascade shown in fig .",
    "[ cascade ] , which is typical of that shown in many turbulence textbooks @xcite .",
    "the richardson picture involves eddies evolving in both space and time .",
    "a large eddy at an early time ( @xmath30 ) will become a small eddy at a later time ( @xmath31 ) .",
    "( we also consider the reverse process . )",
    "we should be more certain about @xmath31 given @xmath30 than @xmath32 given @xmath33 .",
    "let us now move on to the precise description .",
    "the shannon entropy is central to information theory @xcite .",
    "we could simply look at the raw probability distributions themselves , but the entropy gives a single number that characterizes how random the distribution is and provides an interpretation in terms of information .",
    "for the eddy @xmath34 , the shannon entropy is @xmath35 where the sum is over all possible values of @xmath33 .",
    "this is the amount of information we gain from or uncertainty we had prior to measuring @xmath33 @xcite .",
    "( uncertainty and information are the same in this framework . )    to test a relationship between two eddies , we use a modified form of the entropy : the conditional entropy @xcite .",
    "this gives us the uncertainty of one eddy given that the other eddy occurred . for the uncertainty of",
    "@xmath31 given @xmath30 we write @xmath36 where @xmath37 and @xmath38 are the joint and conditional probabilities respectively .",
    "if @xmath30 and @xmath31 are independent , @xmath39 . knowing @xmath30 does nt help us reduce our uncertainty about @xmath31 . if @xmath31 is determined by @xmath30 with absolute certainty , then @xmath40 .",
    "so the stronger the relationship , the smaller this quantity is .",
    "the @xmath41 take on a continuous range of values , but to calculate probabilities and then estimate entropies , we must bin ( discretize ) the measured data .",
    "this is , in fact , unavoidable due to the finite resolution of all measurement apparatuses .",
    "we systematically varied the bin size , but as in ref .",
    "@xcite , we found our results to be extremely robust .",
    "none of our results will change except for a vertical shift in all the conditional entropies by the same factor .",
    "we use a bin size of @xmath42 , which of course changes size with @xmath1 , but ensures that the number of bins ( and thus the maximum possible value of the conditional entropy ) remains roughly the same .",
    "we assert that @xmath43 signifies a cascade from large to small scales , and we use @xmath44 to test this .",
    "@xmath45 in principle also depends on @xmath46 , @xmath47 and @xmath48 as indicated in fig .",
    "[ cascade ] , but we maximize with respect to @xmath47 and @xmath48 ( experimental parameters ) and take many realizations at different @xmath46 , which is simply a reference marker , so that in the end @xmath45 only depends on @xmath1 .",
    "this means that we are formulating richardson s hypothesis @xmath49 at a scale @xmath1 .",
    "we note that our approach is similar to work on information transport in spatiotemporal systems @xcite . a study that more closely anticipates our own is an information transfer treatment of the goy model @xcite .",
    "the result of the calculation of @xmath45 is shown in fig .",
    "[ cond_entropy_a ] for the same @xmath27 and @xmath22 as in fig .",
    "[ spectra ] . clearly @xmath50 is greater than zero in all cases as expected for a direct cascade . in the traditional framework ,",
    "a cascade with constant transfer rate is first assumed and then the scalings are derived with the extra assumptions ( universality , etc . ) already mentioned @xcite .",
    "then if the moments scale as predicted , the cascade is considered to be demonstrated . here",
    "we bypass this sophisticated argumentation and show the cascade straightaway .",
    "more can be gleaned from fig .",
    "[ cond_entropy_a ] .",
    "there appears to be a region of nearly constant value in many of the curves , which is reminiscent of the enstrophy ( energy ) flux which takes on a maximum and constant value in the inertial range equal to the injection rate @xmath21 ( @xmath51 ) @xcite .",
    "this suggests a connection between max(@xmath52 ) and @xmath21 . estimating @xmath21 from fig .",
    "[ spectra ] , we find a general increase of max(@xmath52 ) with @xmath21 .",
    "moreover , all of the curves appear to have a similar shape .",
    "this is reminiscent of the energy spectra above , and suggestive of an underlying self - similarity . indeed by choosing a single @xmath53 and normalizing @xmath1 by @xmath53 and @xmath45 by @xmath54 , we find reasonable collapse as seen in fig .",
    "[ cond_entropy_b ] .",
    "not only have we rediscovered self - similarity , but also a turbulent length scale .",
    "@xmath53 is very close to @xmath18 , but their ratio decreases with @xmath27 as shown in the inset of fig .",
    "[ cond_entropy_b ] .",
    "now let us establish an interesting corollary .",
    "the mutual information is the information shared between two variables . for the large eddies at earlier time ( @xmath30 ) and the small at later time ( @xmath31 ) , we write @xmath55 if we also define a mutual information for @xmath33 and @xmath32 , then we can rewrite @xmath52 as @xmath56 where we have used that @xmath57 , due to the small @xmath48 ( experimentally verified ) .",
    "this means that @xmath58 in other words , the information shared between eddies going downscale is more than the reverse .",
    "there is net information being transferred downscale , concurrently with the enstrophy .",
    "this result should apply generally to both the 2d and 3d direct cascades and even the 2d inverse energy cascade .",
    "it rests only on the validity of our information theory expression of richardson s eddy hypothesis , which we have here experimentally verified .",
    "the implications of this result are quite powerful .",
    "kolmogorov s small scale universality assumption can be expressed as the small scales  forgetting \" about the large ( forcing ) scales @xcite .",
    "[ eq : mutinfo ] suggests that this can never be true .",
    "so long as there is a cascade , there must be information transfer in the same direction which makes  forgetting \" impossible .",
    "thus intermittency appears to be a necessary feature of all turbulent cascades .",
    "we have shown that we can formulate and test richardson s idea of a cascade without using the navier - stoke s equation , scaling arguments or kolmogorov s assumptions .",
    "and yet some of the old patterns , such as self - similarity , re - emerged .",
    "this work presents an entirely new perspective on the statistics of turbulent velocities and suggests a more suitable framework for understanding intermittency .",
    "our application of information theory to turbulence ought to serve as a guidepost for further work ."
  ],
  "abstract_text": [
    "<S> turbulence theory is usually concerned with the statistical moments of the velocity and its fluctuations . </S>",
    "<S> one could also analyze the implicit probability distributions . </S>",
    "<S> this is the purview of information theory . </S>",
    "<S> here we use information theory , specifically the conditional entropy , to analyze ( quasi-)2d turbulence . </S>",
    "<S> we recast richardson s  eddy hypothesis \" that large eddies break up into small eddies in time using the language of information theory . </S>",
    "<S> in addition to confirming richardson s idea , we find that self - similarity and turbulent length scales reappear naturally . </S>",
    "<S> not surprisingly , we also find that the direction of information transfer is the same as the direction of the cascade itself . </S>",
    "<S> consequently , intermittency may be considered a necessary companion to all turbulent flows . </S>"
  ]
}