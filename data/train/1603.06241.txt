{
  "article_text": [
    "parallel programming is a very new tool using multiple computing cores for a given program , increasing the speedup in the parallelized instructions of the program . in this article",
    "we are particularly interested to test the performance of a cluster using the @xmath0 file given by mpi .",
    "the cluster is based on the debian distribution named pelicanhpc @xcite ( for high performance clusters ) with xfce desktop environment which is lightweight ( version used is pelicanhpc 3.1 @xcite ) .",
    "pelican is a live cd distribution that provides the ability to boot a full linux operating system and access many software from the media ( cd , dvd or usb stick ) without installation on the hard disk , and without altering its content .",
    "note that this system has great potential thanks to its support for parallel computing based on mpi using fortran ( 77 , 90 , 95 ) , c , c + + , but also interpreted languages such as gnu octave or semi - interpreted as phyton .",
    "the pxe boot ( acronym for pre - boot execution environment ) allows a workstation to boot from the network by recovering an operating system image that is on a server @xcite . this system image could be a gross operating system or an operating system with custom personal software components",
    "this cluster in picture [ fig : figure1 ] has a master node that manages the startup by pxe boot other the network of two slave nodes . as was said earlier , the pelicanhpc system is only live version , that is to say all data and configuration made on the live partition is deleted when the cluster is shutdown or restarted .",
    "note that all nodes must be in the same subnet ( see picture [ fig : figure2 ] ) to allow starting and they must have pxe option enabled in their bios .",
    "it may be noted that it is strongly recommended to leave pelicanhpc manage his own dhcp server to avoid conflicts .",
    "this calculation system have a hybrid memory since each of the cores of the apu amd a8 6600k share the same memory ( ram ) , but the memories are different from one processor to another .",
    "now look at the expected maximum theoretical performance :    @xmath1    this theoretical performance is upper than the reality . in this calculation",
    "we have taken 4 @xmath2 per cycle .",
    "it is really important to control the cooling of each processors to avoid bios maximum temperature during important calculations .",
    "each processors are well - equipped by a lm35dz temperature sensor in their heatsinks , thereafter a resolution of an unstationary differential equation of thermal conduction give the real temperature of cores .",
    "these sensors are connected to a microcontroller chip atmega328p - pu with arduino uno bootloader for an easily acces to the open source project .",
    "an arduino sketch is uploaded on this chip to control on / off of additional fans .",
    "a sim800l module is connected to the mcu for sending processors temperatures by short message service to directors numbers .",
    "a serial communication beetween this additional module and atmega328p - pu using gsm at commands allows the microcontroller chip to control sms data .",
    "this chip run 350 lines of code in loop all twenty seconds .",
    "an lcd light screen shows informations about sensors .",
    "we can have more information of arduino project by surfing on their website @xcite .",
    "we will analyse quickly the results we can show on picture [ fig : figure3 ] .",
    "there is three different cluster including our homemade pelicanhpc high performance cluster .",
    "two others are cluster from nuclear physics institute of lyon ( ipnl ) respectively with 16 and 24 cores . in our small network architecture with three motherboards , we can notice that performance is almost a linear function of the number of cores .",
    "moreover , thanks to this results , homemade 12 cores assembly appears to be more efficient than other clusters of ipnl . we will highlight that this test is running on @xmath0 file given by mpi and it s not the real performance of your personnal parallelized code because each mpi codes uses differents physically part of clusters .",
    "however , this gives an overall idea of performance and quality of communication between computing cores .",
    "table [ table : table1 ] lists physically description of clusters .        ' '' ''     + * clusters quick description *    ' '' ''     +    .clusters quick description [ cols=\"^,^,^ \" , ]     ' '' ''     +",
    "it is important to know the performance of a cluster in order to adapt a parallel code .",
    "based on certain formulations using differents parts of the cluster , the resolution will be slowest in some cases , that s why it s important to adjust code to the considered cluster configurations . to talk about price of this installation",
    ", we can have 4 * 3 cores clocked at 4,2 ghz for less than 650 euros ( including motherboards and network installations ) .",
    "the price and simplicity of implementation of this debian distribution in a compute cluster is a real benefit not to ignore .",
    "a single cluster like this may prove more efficient than industrial cluster nodes with 16 cores or more .",
    "1 _ http://pelicanhpc.awict.net/_ , website , pelicanhpc official website .",
    "_ http://pareto.uab.es/mcreel/pelicanhpc/_ , website , pelicanhpc tutorial from autonomous university of barcelona .",
    "_ http://distrowatch.com/table.php?distribution=pelicanhpc_ , website , pelicanhpc distribution download .",
    "_ https://www.arduino.cc/_ , website , arduino official website ."
  ],
  "abstract_text": [
    "<S> this article shows a lower cost realization of a compute cluster using debian distribution such as pelicanhpc . </S>",
    "<S> we will explain parameterization and network configuration for master and compute slave nodes . </S>",
    "<S> performance testing will take place using @xmath0 file given by mpi . </S>",
    "<S> the results will be compared between differents clusters . </S>",
    "<S> we will explain quickly how the temperature is controlled by a microcontroller unit . +   + * keywords * pelicanhpc , high performance cluster , parallel programming , message passing interface , homemade , arduino project . </S>"
  ]
}