{
  "article_text": [
    "in a classical optimisation setting , so - called _ static optimisation _ , the focus is usually directed to finding an optimal or a high quality solution as fast as possible . in real - world optimisation , problem specific data may change over time , thus previously good solutions can lose their quality and must be updated or replaced .",
    "automatic optimal control is a typical illustration of these situations , e.g.  parameters of a machine can be set optimally under ideal conditions of a factory but they need to be adapted to changes in the real environment upon deployment . _ dynamic optimisation _ is an area of research that is concerned with such optimisation problems that change over time .",
    "a specific characteristic is that it does not only focus on locating an optimal solution but also on tracking a moving optimum ( see @xcite for a definition ) .",
    "it is often suggested that evolutionary algorithms ( eas ) , especially the ones with populations , are suitable for dynamic optimisation because a large population can contain different solutions which could be useful in the future @xcite .",
    "however , theoretical demonstrations for how populations in dynamic optimisation can be essential are sparse and restricted to special cases .",
    "the ability of a very simple ea without a population , the @xmath0  ea , to track a target bitstring in a onemax - like function is analysed in @xcite .",
    "the analysis has recently been extended from bitstrings to larger alphabets @xcite .",
    "the influence of magnitude and frequency of changes on the efficiency of the @xmath0  ea in optimising a specifically designed function was investigated in @xcite , showing that some dynamic optimisation problems become easier with higher frequency of change .",
    "the analysis of the @xmath1  ea that uses a larger offspring population but still not a real population on a simple lattice problem is presented in @xcite .",
    "the efficiencies of specific diversity mechanisms when using an actual population were compared in @xcite .",
    "this was done for a specific example function ( introduced by @xcite ) and considering low frequency of changes .",
    "it was shown in @xcite that a min - max ant system ( mmas ) can beat the @xmath0  ea in a deterministic dynamic environment .",
    "the comparison was later extended to general alphabets and to the @xmath2  ea that preserves genotype diversity @xcite . with that particular setting of the @xmath2  ea",
    ", the size of the alphabets defines a threshold on the parent population size @xmath3 so that the algorithm is able to track and reach the optimal solution in polynomial time .",
    "the result was also extended to the single - destination shortest path problem @xcite .",
    "comparisons were also made between eas and artificial immune system ( ais ) on a onemax - like problem with the dynamic being periodic @xcite .",
    "considering the existing analyses we can in summary note two shortcomings that leave the impression that important fundamental questions about dynamic optimisation are still not answered satisfactorily .",
    "one shortcoming is the concentration on simple evolutionary algorithms and other search heuristics that do not make use of an actual population .",
    "clearly , the advantages of a population - based approach can not be explored and explained this way .",
    "the other is that many studies consider very complex dynamic environments that make it hard to see the principal and fundamental issues .",
    "therefore , the fundamental question why even a simple population without complicated diversity mechanisms can be helpful in dynamic environments requires more attention .    motivated by the above facts , we will use a simple argument considering a very general class of dynamic functions to show that a population is essential to keep track of the optimal region .",
    "we define our function class on the most often used search space , bit strings of a fixed length .",
    "however , it is not difficult to extend the function class to be defined for any finite search space @xmath4 and any _ unary _ mutation operator @xmath5 . the class is called _ @xmath6-stable _ on @xmath4 with respect to @xmath7 , where @xmath8 is the required number of bits to specify a search point of @xmath4 and @xmath9 and @xmath10 are positive constants independent of @xmath8 .",
    "the function class is only restricted by the probability of recovering the optimal region via the mutation operator @xmath11(see definition  [ def : stable - dyn - func ] ) .",
    "the definition of the function class does not refer explicitly to other function characteristics , such as the topology or the fitness values of the set of optimal solutions , or the distribution of fitness values of the set of non - optimal solutions .",
    "we will use the _ moving hamming ball _",
    "function from @xcite as an illustrative example over the search space @xmath12 and with respect to the bitwise mutation operator .",
    "we also use this specific function to argue that an approach based on a single individual , such as the @xmath0  ea , is inefficient in tracking the optimal region in spite of being equipped with the same mutation operator . on the other hand , we show that a population - based algorithm with a sufficiently large population can efficiently track the moving optimal region of any dynamic function of the class defined for any given finite search space .    the remainder of the paper is organised as follows .",
    "the next section first gives a formal description of dynamic optimisation and efficient tracking , then the class of dynamic functions that we consider is described with an example function .",
    "next , we consider the @xmath0  ea and rls on the function class and provide an analysis to serve as an example how search heuristics based on single solutions are not able to track the optimal solutions over time .",
    "the efficiency of population - based algorithms is then explained by proving a positive result about their performance .",
    "here , we use the setting of non - elitist populations and show that , with a sufficient selective pressure , the ability of the population to track the moving optimal region is overwhelmingly high with respect to the population size . on the other hand , as a consequence of a fair comparison to a single - individual approach , the population must not be too big in order to capture the frequency of changes .",
    "finally , we summarise , conclude and point out directions for future research .",
    "the paper uses the following notation and terminology . for any positive integer @xmath8 ,",
    "define @xmath13:=\\{1,2,\\dots , n\\}$ ] .",
    "the natural logarithm is denoted by @xmath14 , and the logarithm to the base @xmath15 is denoted by @xmath16 .",
    "the hamming distance is denoted by @xmath17 and the iverson bracket is denoted by @xmath18 $ ] .",
    "we use @xmath19 to denote the indicator function of a set @xmath20 , @xmath21 if @xmath22 , and @xmath23 otherwise . for a given bitstring @xmath24",
    ", the hamming ball around @xmath25 with radius @xmath26 is denoted by @xmath27 .",
    "the bitstring containing @xmath8 one - bits and no zero - bits is denoted @xmath28 .",
    "an event is said to occur with overwhelmingly high probability ( w.o.p . ) with respect to a parameter @xmath8 , if the probability of the event is bounded from below by @xmath29 .",
    "before defining the class of @xmath30-stable dynamic functions which will be studied in this paper , we first formalise our notion of dynamic optimisation , and we define what we mean when saying that a dynamic search heuristic tracks a moving optimal region efficiently .",
    "we focus on optimisation of pseudo - boolean functions with discrete - time dynamics , as formalised below .",
    "note that our formalisation can be generalised to any finite search space @xmath4 , replacing @xmath31 with @xmath4 , and our results for population - based algorithms also hold for this generalisation .",
    "[ def : dyn - func ] a dynamic function @xmath32 is a random sequence of functions @xmath33 where @xmath34 for all @xmath35 . the optimal regions associated with @xmath32 is the sequence @xmath36 , where @xmath37 .",
    "the perhaps simplest , non - trivial example of a dynamic function is a periodic function which deterministically alternates between two functions , say @xmath38 and @xmath39 , such that @xmath40 and @xmath41 for all @xmath42 .",
    "we will consider more complex dynamic functions , where the sequence of functions is random and non - periodic .",
    "although the sequence of functions in a dynamic function is random , each individual function is deterministic , i.e. , we do not consider dynamic optimisation with noisy functions .    in this paper , we do not make any assumption about the changes of the function and the speed of the algorithm .",
    "it has been pointed out that it is important to consider the relationship between the speed of the execution platform where the algorithm runs and the speed of change of the function because this has significant influence on the performance @xcite .",
    "almost all studies assume that the function can not change within one generation of the algorithm .",
    "the only exception we are aware of is a paper by branke and wang @xcite who analyse a @xmath43 ea .",
    "we follow this idea but consider a much broader class of algorithms .",
    "when applying a search heuristic to a dynamic function , we therefore have to consider two time lines : the first is associated with the evolution of the dynamic function , and the second is associated with the search points generated by the heuristic . following the convention from black - box complexity @xcite , we assume that the function evaluations are the most expensive operations , for sake of the analysis becoming the basic time steps of an algorithm . the time consumed by all other operations , such as sampling an individual or applying a mutation operator ,",
    "is assumed to be negligible .",
    "we connect the two time - lines by assuming that every time the heuristic queries a search point , the time - line of the dynamic function increases by one .",
    "we allow dynamic search heuristics some flexibility in that search points can be queried not only with respect to the most recent function @xmath44 , but also with respect to past functions .",
    "for example , the individuals in a population can be evaluated with respect to one particular time .",
    "we also assume that the decisions made by the search heuristic does not influence the dynamic of the function .",
    "the dynamic optimisation - scenario we have described is summarised in the following definition .    a dynamic search heuristic is an algorithm which given a search history @xmath45}$ ] of @xmath46 elements in @xmath47 , selects a search point @xmath48 and an evaluation time @xmath49 $ ] , and evaluates @xmath50 .",
    "an element @xmath51 in a search history describes the search point @xmath52 queried by the algorithm in step @xmath53 , the time point @xmath54 with which the search point is evaluated , and the corresponding function value @xmath50 .",
    "we can now formalise the notion of _ efficient tracking _ of optima .",
    "[ def : eff - tracking ] a search heuristic is said to _ efficiently track the optima _ of a dynamic function @xmath32 if there exist @xmath55 and constants @xmath56 such that @xmath57 where @xmath58 is the sequence of search points queried by the heuristic , and @xmath59 is the sequence of optimal search points of function @xmath32 .    informally ,",
    "definition [ def : eff - tracking ] means that the algorithm queries optimal search points frequently .",
    "more precisely , within every sub - interval of length @xmath60 within the exponentially long time interval from @xmath61 to @xmath62 , a constant fraction of the queried search points are optimal .",
    "note that the optimality of a search point is defined with respect to the query time , and regardless of the function with which the algorithm evaluates the search point .",
    "the constraint @xmath63 on the length of sub - intervals guarantees that the time between generation of two optimal search points is bounded from above by a polynomial .",
    "it is clear from the definition that an algorithm is inefficient if with a sufficiently high probability , at least constant , it loses track of the optimal region and does not recover it within a polynomial number of steps .",
    "the class of @xmath30-stable dynamic functions with respect to a variation operator is defined as follows .",
    "[ def : stable - dyn - func ] let @xmath64 be any _ unary _ variation operator , and @xmath65 , @xmath66 . if there exist constants @xmath56 such that with probability at least @xmath67 , the optimal regions @xmath36 of a function @xmath32 satisfy for all time points @xmath53 and @xmath68 with @xmath69 , and for all search points @xmath70 , @xmath71 then @xmath32 is called @xmath30-stable with respect to @xmath72 .    definition [ def : stable - dyn - func ] covers a large class of dynamic optimisation functions for any given pair of parameters @xmath30 .",
    "the optimal regions over time can take many shapes , including disconnected pieces over @xmath31 as long as the distances between them and the cardinality of the intersections allow the probabilistic condition to hold .",
    "figure [ fig : dyn - func - shape ] illustrates the required condition .    given an operator @xmath72 ,",
    "we focus on the class of @xmath6-stable functions where @xmath9 and @xmath10 are positive constants .",
    "we will show that a population - based algorithm with a sufficiently large population and a sufficiently strong selection pressure can track the optimal region of any function in the class efficiently .",
    "the next section gives an example function of the class for @xmath72 being bitwise mutation and explains how it fits within the framework of @xmath6-stable function .",
    "we will then use the example function to argue that algorithms that base their search on a single individual , such as the ( 1 + 1 )  ea , can be inefficient .",
    "-stable dynamic function , in which any search point in the optimal region of time @xmath53 can be mutated into the optimal region of time @xmath73 with probability at least @xmath10.,width=151 ]      we consider the moving hamming ball function as described in @xcite .",
    "the static version of the function has the following form .",
    "[ def : hb - func ] the hamming ball function around a target bitstring @xmath74 and a radius @xmath26 is defined as , @xmath75    it suffices to change @xmath74 in sequential steps to create a dynamic version from the static one .",
    "we use the following dynamic setting for the function : the points in time when the target @xmath74 is changed are determined by a sequence of random variables drawn from a poisson distribution .",
    "[ def : mhb - func ] let @xmath76 be a sequence of random variables independently sampled from a poisson distribution with parameter @xmath77 , @xmath78 , @xmath60 be some integer in @xmath13 $ ] , and @xmath79 be a sequence of bitstrings generated by @xmath80 the moving hamming ball ( @xmath81 ) function with parameters @xmath26 , @xmath60 , and @xmath77 is defined as @xmath82    the @xmath81 function fits within the stability framework of definition  [ def : stable - dyn - func ] with respect to the bitwise mutation operator @xmath83 .",
    "this variation operator , which has a parameter @xmath84 $ ] , flips each position in the bitstring independently with probability @xmath85 .",
    "hence , the probability of mutating a bitstring @xmath86 into a bitstring @xmath87 is @xmath88    [ lem : mhb - func - stable ] for all positive constants @xmath89 , @xmath90 and @xmath91 , the function @xmath92 is @xmath93-stable with respect to the bitwise mutation operator @xmath83 with parameter @xmath90 .    for any given time @xmath53 ,",
    "let @xmath94 be the random variable associated with the number of time steps in the future that the target bitstring will be changed .",
    "if we pick @xmath95 , then it is clear that within the next @xmath96 time steps , there will be more than one change of the target bitstring if and only if @xmath97 .",
    "it follows from lemmas [ lem : poisdist ] and [ lem : lnbound ] that @xmath98    it suffices to pick the constant @xmath99 so that with a probability of at least @xmath100 , there is at most one change to the target function within the next @xmath96 time steps . under that condition",
    ", it holds for all @xmath101 $ ] and for all @xmath102 , that @xmath103 for some @xmath104 $ ] .",
    "in the case that @xmath105 , the target does not move or it moves closer to @xmath25 , it suffices to not flip any of the @xmath106 bits . for any constant @xmath91 , it holds for all @xmath107 that @xmath108    in the case that @xmath109 , it suffices to recover the @xmath110 bits among the @xmath111 mismatched ones , so @xmath112    note that @xmath113 , hence @xmath114 and @xmath92 is @xmath30-stable with respect to @xmath83 .",
    "it is not difficult to see that the stability condition of the function class still holds with the following relaxations :    * the fitness of the solutions inside the hamming ball changes when the target string moves , * the fitness of the solutions outside the current hamming ball can be distributed differently , as long as they are less than the current optimal fitness , * the moving step @xmath60 is relaxed to be sampled from any discrete distribution over @xmath115 $ ] in each change of the target bitstring .",
    "we will not consider these relaxations as they are not required to distinguish between the effectiveness of single - individual and population - based evolutionary algorithms .",
    "we will compare the performance of population - based and single - individual based evolutionary algorithms . in this section",
    "we first define these classes of algorithms .",
    "we are considering dynamic optimisation problems and , as mentioned in the introduction and discussed by jansen and zarges @xcite , it is important to clarify how the algorithms deal with change of the fitness functions , in particular if this happens during one generation . in this paper , we consider algorithms that make use of consistent comparisons when applying on a dynamic function : when an algorithm has to make fitness comparisons on a set of solutions , it will first make a _ static copy _ of the dynamic function and evaluate the solutions on this copy .",
    "this approach corresponds to an implementation where the necessary data to evaluate the optimisation function is collected before evaluating a set of solutions .",
    "meanwhile the real function may have changed more or less depending on the number of solutions in the set .",
    "we first consider the single - individual approach described in algorithm  [ algo : onesol ] .",
    "the algorithm keeps a current search point @xmath25 . in each iteration , it produces a new candidate solution @xmath116 , and compares it with the current search point using the same function .",
    "hence , static copies of the dynamic function are made in every two time steps .",
    "this corresponds to a frequent update of the dynamic function .",
    "we let @xmath7 be the bitwise mutation operator @xmath83 described in section  [ sec : example - stable - func ] , and obtain the well - known ( 1 + 1 )  ea @xcite .",
    "however , the result can be easily generalised to other mutation operators , such as the single - bit flip operator used in the rls algorithm .",
    "+ finite search space @xmath4 , + dynamic function @xmath117 , + initial solution @xmath118 .",
    "@xmath122 .",
    "[ algo : onesol ]    we are mostly interested in the influence of the population size , designated by the parameter @xmath123 , on the ability of a population - based algorithm to track the moving optimal region .",
    "we focus on the non - elitist setting as described in algorithm  [ algo : popbased ] .",
    "the algorithm uses a unary variation operator denoted by @xmath7 , no crossover operator , and an unspecified selection mechanism @xmath124 .",
    "the selection mechanism is any random operator @xmath124 that given a population @xmath125 and access to a fitness function returns one of the individuals in @xmath125 . by specifying different @xmath124 and @xmath7 , algorithm  [ algo : popbased ] can instantiate a large number of population - based search heuristics , such as the ( @xmath126 )  ea .",
    "the number of search points @xmath123 produced in each round is the only parameter that appears in the description of algorithm  [ algo : popbased ] .",
    "the ( @xmath3,@xmath123 )  ea fits within this framework by making sure that the selection in line  [ step : selection ] only takes into account the @xmath3 best of the @xmath123 search points created in the last round .",
    "the algorithm maintains a population @xmath127 of @xmath123 individuals which during one generation ( steps [ step : genstart][step : genend ] ) is replaced by a newly created population @xmath128 of the same size . as for the ( 1 + 1 )  ea ,",
    "we assume that the initial population @xmath129 is contained in the first optimal region @xmath130 .",
    "each individual in the next population @xmath128 is created by first making a copy @xmath25 of one parent individual which is selected from the current population ( step [ step : selection ] , selection ) , then modifying the copy using @xmath7 operator ( step [ step : mutation ] , mutation ) .",
    "when selecting individuals , the algorithm must take into account that multiple changes to the fitness function can occur during one generation . here",
    ", we assume that the algorithm makes a static copy of the fitness function @xmath131 at the beginning of each generation , i.e. at time @xmath132 .",
    "the selection mechanism @xmath124 compares all individuals in a generation using the static copy .",
    "note that if the population size @xmath123 is too large with respect to the problem parameter @xmath77 ( which controls the frequency of change of the dynamic function ) , then the optimal region may change several times between two consecutive generations .",
    "hence , the population size should not be too large .",
    "however , we will show in the next section that a sufficiently large population is also essential to keep the population within the optimal region .",
    "the result for populations will be first shown for any finite search space and any mutation operator @xmath7 because the class of dynamic function is defined with respect to the operator @xmath7 .",
    "then we will use @xmath83 over @xmath31 as a specific example .",
    "+ finite search space @xmath4 , + dynamic function @xmath117 , + initial population @xmath133 .",
    "evaluate solutions of @xmath134 with @xmath135.[step : genstart ] @xmath136.[step : selection ] @xmath137.[step : mutation ] [ step : genend ]    [ algo : popbased ]    although algorithm  [ algo : popbased ] can use any selection mechanism @xmath124 , we are looking for choices of @xmath124 that allows the algorithm to track optima efficiently .",
    "formally , @xmath124 applied on finite populations of size @xmath123 is represented by the transition matrix @xmath138 \\times   \\mathcal{x}^\\lambda \\rightarrow [ 0,1]$ ] , where @xmath139 represents the probability of selecting individual @xmath140 , the @xmath141-th individual , of @xmath125 .",
    "we also write @xmath142 , in the algorithm , to express that @xmath25 is sampled from the distribution over @xmath125 given by @xmath143 .",
    "we use @xmath144 to denote the @xmath145 best individual of @xmath125 , or the so - called @xmath146-ranked individual .",
    "similar to @xcite , we characterise @xmath124 by the cumulative selection probability .",
    "[ def : cumulsel ] given a fitness function @xmath147 , the _ cumulative selection probability _ @xmath148 associated with selection mechanism @xmath124 is defined on @xmath149 for all @xmath150 $ ] and a @xmath151 by @xmath152 } { \\ensuremath{p_\\mathrm{sel}}\\xspace}(i \\mid p ) \\cdot \\left[f(p(i ) ) \\geq f(x_{(\\lceil \\gamma \\lambda \\rceil ) } )      \\right ] .",
    "\\end{aligned}\\ ] ]    informally , @xmath153 is the probability of selecting an individual with fitness at least as good as that of the @xmath154-ranked individual , assuming that @xmath125 is sorted according to fitness values .",
    "we are interested in a lower bound function of @xmath153 .",
    "most often this lower bound is independent of @xmath125 , in which case we simply write it as a function of @xmath154 only , i.e.  as @xmath155 .",
    "in this section , we first show that single - individual approaches are inefficient in tracking moving optima on at least one example function of the class , precisely on @xmath92 .",
    "then we prove a general result that an appropriately parameterised population - based algorithms can efficiently track the moving optima of any function in the class .      in this section",
    ", we will show that the @xmath0  ea spends an exponential fraction of its time outside the optimal region of a @xmath156 function , for a sufficiently small constant @xmath157 , any constant @xmath158 and any @xmath159 .",
    "that is to say the algorithm is inefficient even in tracking such a stable function .    to prove such a result",
    ", we have to analyse the behaviour of the algorithm both inside and outside the moving hamming ball : we assume that the algorithm starts at the center of the first optimal region and show that after some initial time , whenever the center of the ball moves , there is a constant probability that the @xmath0  ea will memorise a search point outside of the new ball ; whenever the algorithm is outside of the optimal region there is also a constant probability that the memorised search point will drift away from the optimal region ( eventually get lost ) , before an optimal solution inside the new ball is discovered . since the changes to the function happens within an expected polynomial number steps",
    ", we can conclude that with a high probability , the @xmath0  ea only spends a polynomial number of time steps inside the moving hamming ball .",
    "we start with the first argument , the behaviour of the algorithm inside the hamming ball .",
    "we notice that the changes induced by the dynamics of the fitness function strongly drag the target away from the current memorised search point , however this does not happen in every iteration . in every iteration , the changes by mutation drive the memorised solution away from the center of the current hamming ball , but",
    "the elitist selection also keeps the memorised solution from falling outside .",
    "we have the following analysis of the drift .",
    "we consider the process @xmath160 , where @xmath161 is the hamming distance to the border of the optimal region of @xmath156 at time @xmath53 , @xmath162 .",
    "the process starts with @xmath163 , exactly at the center of the hamming ball .",
    "given @xmath164 , define @xmath165 , then @xmath166}$ ] is the drift towards the border at time @xmath53 and where @xmath164 .",
    "first of all , the dynamic now only kicks in every @xmath167 time steps in expectation .",
    "also , the contributing drift is positive .",
    "for example , if the dynamic kicks in , let @xmath168 be the number of bits being corrected by the dynamic , then we have @xmath169 , and the contributing drift is @xmath170 } = \\ell(1 - 2i / n ) > 0 $ ] for any @xmath171 .",
    "we now compute the drift by mutation at time @xmath53 and where @xmath172 .",
    "let @xmath94 and @xmath173 be the number of bits being corrected and being messed up respectively by the mutation , so @xmath174 , @xmath175 and the two variables are independent .",
    "note that for all integers @xmath176 , @xmath177 and @xmath178 , it holds @xmath179    thus for @xmath180 , @xmath181 stochastically dominates @xmath182 and we also have @xmath183 }        & =     { \\mathbf{e}\\left [ { \\ensuremath{\\mathds{1}_{\\{y = 1\\ } } } } \\right ] }            - { \\mathbf{e}\\left[x\\right ] } \\\\      & =     \\binom{n - ( r - i)}{1}\\left(\\frac{\\chi}{n}\\right)\\left(1 - \\frac{\\chi}{n}\\right)^{n-(r - i ) - 1 } - \\frac{i\\chi}{n } \\\\      & \\geq \\chi\\left(\\left(1-\\frac{r - i}{n}\\right)e^{-(1+\\varepsilon)\\chi } - \\frac{r - i}{n}\\right ) \\\\      & >     \\chi\\left(\\left(1-\\frac{r}{n}\\right)e^{-(1+\\varepsilon)\\chi } - \\frac{r}{n}\\right ) \\\\      & =     \\chi\\left(\\left(1-b\\right)e^{-(1+\\varepsilon)\\chi } - b\\right)\\end{aligned}\\ ] ] for any constant @xmath184 .",
    "therefore , with any constant @xmath185 , we have that @xmath186 .",
    "hence , for @xmath180 we have at least a constant drift away from the center @xmath183 }        >     \\left(\\frac{\\chi}{2\\cdot e^{(1+\\varepsilon)\\chi}}\\right)\\left(1 - b\\right ) = : \\delta.\\end{aligned}\\ ] ]    the only position where we have a drift toward the center is the one at the border , @xmath187 . however , this is not a strong drift .",
    "when the target bitstring does not move in the next iteration , we have @xmath188 , then the negative drift is no more than @xmath189 }        = \\frac{r \\chi}{n }   = : \\eta.\\end{aligned}\\ ] ]    in summary , we get the drift by mutation : @xmath190 }       & \\geq \\delta             \\cdot             { \\ensuremath{\\mathds{1}_{\\{x_t > 0\\ } } } }            \\label{eq : delta } \\\\    { \\mathbf{e}\\left[\\delta(i ) \\cdot { \\ensuremath{\\mathds{1}_{\\{x_t = 0\\ } } } }            \\mid x_t = i\\right ] }       & \\geq -\\eta              \\cdot              { \\ensuremath{\\mathds{1}_{\\{x_t = 0\\ } } } }             \\label{eq : eta}\\end{aligned}\\ ] ] it",
    "is then suggested that the equilibrium state of the memorised search point is around the border .",
    "furthermore , we can quantify the expected fraction of time that the search point is found at the border , using the following tool .",
    "[ lem : occupancy ] given a stochastic process @xmath191 over a state space @xmath192 , and two constants @xmath193 such that    * @xmath194}\\leq \\eta \\cdot { \\ensuremath{\\mathds{1}_{\\{x_t=0\\}}}}$ ] , and * @xmath195}\\leq ( x_t-\\delta ) \\cdot { \\ensuremath{\\mathds{1}_{\\{x_t > 0\\}}}}$ ] ,    then for all @xmath196 @xmath197    define @xmath198 .",
    "for all @xmath196 , it holds @xmath199 }         & = { \\mathbf{e}\\left[{\\ensuremath{\\mathds{1}_{\\{x_{t-1}=0\\ } } } } \\cdot x_{t}\\right]}+{\\mathbf{e}\\left[{\\ensuremath{\\mathds{1}_{\\{x_{t-1}>0\\ } } } } \\cdot x_{t}\\right]}\\\\        & = { \\mathbf{e}\\left[{\\mathbf{e}\\left[{\\ensuremath{\\mathds{1}_{\\{x_{t-1}=0\\ } } } } \\cdot x_{t}\\mid x_{t-1}\\right]}\\right]}+\\\\        &    \\quad\\quad { \\mathbf{e}\\left[{\\mathbf{e}\\left[{\\ensuremath{\\mathds{1}_{\\{x_{t-1}>0\\ } } } } \\cdot x_{t}\\mid x_{t-1}\\right]}\\right]}\\\\        & \\leq { \\mathbf{e}\\left[\\eta \\cdot { \\ensuremath{\\mathds{1}_{\\{x_{t-1}=0\\ } } } } \\right]}+          { \\mathbf{e}\\left[(x_{t-1}-\\delta ) \\cdot { \\ensuremath{\\mathds{1}_{\\{x_{t-1}>0\\}}}}\\right]}\\\\        & = \\eta p_{t-1}-\\delta ( 1-p_{t-1})+{\\mathbf{e}\\left[x_{t-1 } \\cdot { \\ensuremath{\\mathds{1}_{\\{x_{t-1}>0\\ } } } } \\right]}\\\\        & = \\eta p_{t-1}-\\delta ( 1-p_{t-1})+{\\mathbf{e}\\left[x_{t-1}\\right]}.           \\end{aligned}\\ ] ]    it follows that @xmath200 }       \\leq x_0-t\\delta+(\\delta+\\eta)\\sum_{i=0}^{t-1}p_t .",
    "\\end{aligned}\\ ] ]    finally , since @xmath201}\\geq 0 $ ] @xmath202    the following lemma considers non - negative , integer - valued stochastic processes with positive drift at most @xmath203 in state 0 , and negative drift at least @xmath204 elsewhere .",
    "it provides a lower bound on the probability of such a process being in state 0 after some time .    [",
    "lem : occupancy - independent - time ] let @xmath191 be any stochastic process with support in @xmath205 $ ] for some fixed @xmath206 , which satisfies the properties of lemma  [ lem : occupancy ] for some @xmath207 . then for any random variable @xmath208 which is independent of @xmath191",
    ", it holds @xmath209    choose @xmath210 , and define @xmath211 where @xmath212 and @xmath213)$ ] , i.e. , we consider the process @xmath161 from a random starting point @xmath214 .",
    "due to independence between @xmath215 , and @xmath191 , we have @xmath216 lemma  [ lem : occupancy ] applied to @xmath217 now implies @xmath218    we now show that once the @xmath0  ea has lost track of the optimal region it will take a long time to recover .",
    "we assume that the objective function is @xmath156 with radius @xmath219 , @xmath220 for some constant @xmath221 ( note that @xmath157 can depend on @xmath8 ) .",
    "the first step in this proof is to show that with not too small probability the @xmath0  ea ends up far away ( more specifically , in a linear distance ) from the hamming ball before recovering it .",
    "[ lemma-1 + 1-leaving ] given @xmath222 , let @xmath223 be a sequence of random bit strings such that @xmath224 and @xmath225 for some @xmath219 , @xmath226 for some @xmath227 . for any @xmath228 , define @xmath229 or @xmath230 .",
    "it holds that @xmath231 where @xmath232 for a not too large constant @xmath233 .",
    "we begin with considering another random sequence @xmath234 where for each @xmath235 the point @xmath236 is created by flipping one randomly selected bit in @xmath237 .",
    "let @xmath238 be defined as @xmath239 but with respect to @xmath236 instead of @xmath52 .",
    "let @xmath240 , i.e. , the probability to enter the hamming ball before reaching distance @xmath89 given the process is started with hamming distance @xmath25 .",
    "note that , for symmetry reasons , @xmath241 is well defined , i.e. , the probability does only depend on the hamming distance @xmath25 and not the specific choice of @xmath242 .    by definition of @xmath238",
    "we have @xmath243 for @xmath244 and @xmath245 for @xmath246 .",
    "for all other values of @xmath25 , i.e. , for @xmath247 we have @xmath248 by definition of the sequence @xmath236 because with probability @xmath249 the hamming distance to the centre of the hamming ball @xmath250 is increased by 1 and with the remaining probability @xmath251 it is decreased by 1 . if we pessimistically assume that the probability to move towards the hamming ball is always equal to @xmath252 we obtain an upper bound on @xmath241 and are in the situation of the gambler s ruin problem with initial funds @xmath253 and",
    "@xmath254 , @xmath255 , and @xmath256 and the probability to be ruined @xmath257 gives an upper bound on the probability to enter the hamming ball before reaching distance @xmath89 when starting with hamming distance @xmath25 to the centre of the hamming ball .",
    "we consider the probability @xmath258 for different values of @xmath26 , @xmath89 and @xmath25 .",
    "we are interested in the results for @xmath259 and consider for this @xmath232 where we chose the constant @xmath260 such that @xmath261 for some positive constant @xmath204 .",
    "it is clear that due to the upper bound on @xmath26 such a constant @xmath91 exists .",
    "it is not difficult to see that @xmath262 . for @xmath263",
    "this is @xmath264 and the best bound we can obtain . for @xmath265",
    "we need to be more precise .",
    "we begin with the case @xmath265 and @xmath266 . for this setting",
    "we consider @xmath267 and know that @xmath268 holds .",
    "now we consider @xmath269 and see that @xmath270 holds .    finally ,",
    "for the case @xmath271 , we also consider @xmath267 and know that @xmath272 holds .",
    "now we consider @xmath269 and see that @xmath273 holds .",
    "together , we have @xmath274 for all values of @xmath26 and @xmath232 .",
    "since the sequence @xmath236 corresponds to ` local mutations ' this proves the claim for random local search .",
    "we generalise the statement to the ( 1 + 1 )  ea in the following way .",
    "we can express a standard bit mutation as a process where first a random number @xmath275 is chosen and then @xmath276 bits are selected uniformly at random to be flipped .",
    "the case @xmath277 does not flip any bit and can be ignored .",
    "the case @xmath278 is covered by the analysis for rls . for larger @xmath279",
    "we observe that such a step is very similar to a sequence of @xmath276 steps where exactly 1 bit is flipped .",
    "the difference does not change the limits we considered above . since in one standard bit mutation @xmath276 bits flip with probability @xmath280 we can ignore steps where @xmath281 bits flips since they contribute too little to change the asymptotic result .",
    "[ the-1 + 1-time ] on @xmath156 with any constants @xmath282 , @xmath158 and @xmath283 the @xmath0 ea with mutation rate @xmath284 will spend only an exponentially small proportion of its time in optimal regions .",
    "we assume the process starts inside the first hamming ball , and consider the process as @xmath191 as described before in lemma [ lem : occupancy ] . for the standard mutation ,",
    "we have the drifts according to equations [ eq : delta ] and [ eq : eta ] are @xmath285 and @xmath286 .",
    "applying lemma [ lem : occupancy - independent - time ] gives that after @xmath287 time steps , whenever the center of the hamming ball is moved , it holds that @xmath288 .",
    "conditioned on this event , the probability that the dynamic move @xmath289 so that @xmath290 is @xmath291 where @xmath292 , the number of bit positions being corrected by the dynamic ( see the definition of @xmath168 before lemma [ lem : occupancy ] ) .",
    "@xmath293 } = \\ell r / n = b\\ell$ ] and by markov s inequality and @xmath294 it holds that @xmath295}/\\ell\\right ) \\\\      & \\geq \\frac{(1 - b)(1 - 2b)}{2(1 - b + 2eb ) } = : p_1        > \\frac{2e - 1}{4(2e + 1 ) } > 0.\\end{aligned}\\ ] ]    when the @xmath296 is outside of the current hamming ball , it follows from lemma [ lemma-1 + 1-leaving ] that there is a probability of at least @xmath297 that the @xmath0  ea reaches linear hamming distance to the hamming ball before finding its way back to it .",
    "application of the negative drift theorem @xcite yields that the probability to find the way back into the optimal region within @xmath298 steps is @xmath299 for a sufficiently small constant @xmath158 .",
    "we have just show that in every @xmath300 time steps , whenever a change occurs to the target bitstring there is a probability of at least @xmath301 that the @xmath0  ea will lose track of the optimal region where @xmath302 and @xmath303 are constants . applying this argument @xmath8 times",
    "( a change occurs approximately every @xmath167 time steps ) , we conclude that with an overwhelmingly high probability , the @xmath0  ea will spend no more than @xmath304 time steps within the optimal region of the @xmath156 function .",
    "theorem  [ thm : pop - robust - long - term ] , which is the main result in this section , gives conditions under which the non - elitist , population - based algorithm  [ algo : popbased ] tracks the optimal regions of dynamic functions efficiently .",
    "we show that these conditions can be satisfied for the moving hamming - balls function @xmath156 for any constant @xmath305 .",
    "[ thm : pop - robust - long - term ] if there are constants @xmath306 and @xmath307 such that    1 .",
    "@xmath32 is a @xmath308-stable dynamic function wrt .",
    "@xmath11with @xmath309 , and 2 .",
    "@xmath124 satisfies @xmath310 for all @xmath311 $ ] ,    then algorithm  [ algo : popbased ] initialised with @xmath133 tracks the optima of @xmath32 efficiently",
    ".    condition 1 of the theorem requires that the optimal region of the function does not move too much relatively to the variation operator @xmath7 during one generation .",
    "the population size @xmath123 is a parameter of the algorithm which can be chosen freely .",
    "so if the function is @xmath30-stable , then the first condition can be satisfied by setting population size @xmath312 .",
    "condition 2 requires that the selection mechanism @xmath313induces a sufficiently high selective pressure .",
    "note that increasingly high selective pressure is required for decreasing values of @xmath10 , where @xmath10 is the probability of recovering the optimal search region via mutation ( see definition  [ def : stable - dyn - func ] ) .     and",
    "lemma [ lemma : failed - generation].,width=188 ]    the central argument in the analysis is illustrated in figure  [ fig : lemma - produce - nearby - opt ] .",
    "it follows from the stability - assumption that any search point in @xmath314 can be mutated into @xmath315 for any @xmath316 $ ] with probability at least @xmath10 .",
    "hence , if the algorithm selects a search point in @xmath314 with probability @xmath317 , then the offspring belongs to @xmath315 with probability at least @xmath318 .",
    "this argument is invoked in both of the two steps of the analysis .",
    "[ lemma : produce - nearby - opt ] assume that conditions 1 and 2 of theorem  [ thm : pop - robust - long - term ] hold .",
    "then for any @xmath319 , @xmath316 $ ] , if @xmath320 , then any offspring in generation @xmath321 belongs to @xmath315 with probability at least @xmath322 .",
    "the algorithm produces an individual in @xmath315 if the algorithm selects an individual in @xmath314 and mutates this individual into @xmath315 .",
    "the probability of this event is @xmath323 .",
    "lemma  [ lemma : failed - generation ] , which is the _ first step _ of the analysis , implies that in every generation @xmath319 , a large fraction of the population @xmath127 belongs to @xmath314 .",
    "this can be shown inductively by arguing using lemma  [ lemma : produce - nearby - opt ] that if many individuals in @xmath127 belong to @xmath314 , then whp .",
    "many individuals in @xmath128 belong to @xmath324 .",
    "knowing that many individuals in @xmath127 belong to @xmath314 for every generation @xmath325 gives us some control on the dynamics of the population .",
    "however it does not imply that the dynamic performance measure in definition  [ def : eff - tracking ] is satisfied because the individuals in @xmath314 may not necessarily have been optimal when they were generated .",
    "a _ second step _ in the analysis is therefore required , showing that if sufficiently many individuals in population @xmath134 belong to @xmath314 , then many offspring in generation @xmath321 were optimal at the time they were generated .",
    "this second step is contained in the proof of theorem  [ thm : pop - robust - long - term ] .",
    "[ lemma : failed - generation ] assume that conditions 1 and 2 of theorem  [ thm : pop - robust - long - term ] hold .",
    "then for any generation @xmath319 , if @xmath326 , then @xmath327    by lemma [ lemma : produce - nearby - opt ] , any offspring in generation @xmath321 belongs to @xmath324 independently with probability @xmath328 .",
    "hence , by a chernoff bound , the probability that less than @xmath329 offspring belongs to @xmath324 is @xmath330 .",
    "we are now in position to prove the main result of this section .",
    "we say that generation @xmath325 _ fails _ if @xmath331 and @xmath332 . by lemma  [ lemma : failed - generation ] and",
    "a union bound , the probability that any of the first @xmath333 generations fails is @xmath330 , assuming that @xmath158 is a sufficiently small constant . by lemma  [ fig : lemma - produce - nearby - opt ] and",
    "assuming no failure , any individual @xmath334 with @xmath335 belongs to the optimal region @xmath336 with probability at least @xmath322 . by the definition of the algorithm ,",
    "individuals within the same generation are produced independently . during any time interval @xmath337",
    "where @xmath338 , at least @xmath339 individuals are produced in the same generation , and hence independently .",
    "it therefore holds by a chernoff bound that for any time interval with @xmath340 , @xmath341 the theorem now follows by taking into account the failure probability with a union bound , and choosing the parameters @xmath342 and @xmath343 in definition  [ def : eff - tracking ] .",
    "theorem  [ thm : pop - robust - long - term ] implies that with a sufficiently slow dynamic , @xmath344 for any constant @xmath158 , the population - based algorithm can efficiently track the moving optima of the function , given that @xmath124 induces a sufficiently strong selective pressure .",
    "we now show that given any constant @xmath345 , it is possible to parameterise many selection mechanisms so that they satisfy this requirement on @xmath124 .",
    "the selection mechanisms are :    * in _ @xmath276-tournament selection _ , @xmath276 individuals are sampled uniformly at random with replacement from the population , and the fittest of these individuals is returned . * in @xmath346-_selection _ , parents are sampled uniformly at random among the fittest @xmath3 individuals in the population . *",
    "a function @xmath347 is a ranking function @xcite if @xmath348 for all @xmath349 $ ] , and @xmath350 . in ranking selection with ranking function @xmath351 ,",
    "the probability of selecting individuals ranked @xmath154 or better is @xmath352 .",
    "_ linear ranking _",
    "selection uses @xmath353 for some @xmath354 $ ] . _ exponential ranking _",
    "selection uses @xmath355 for some @xmath356 .",
    "the following theorem shows how these selection mechanisms can be parameterised to satisfy the second requirement of theorem  [ thm : pop - robust - long - term ] , and hence ensure that algorithm  [ algo : popbased ] tracks the moving optima of any @xmath308-stable function with respect to the mutation operator @xmath7 .",
    "[ thm : sel - mechanism ] for any constant @xmath66 , let @xmath32 be any @xmath308-stable function wrt .",
    "@xmath11for @xmath309 .",
    "if there is a constant @xmath357 such that algorithm  [ algo : popbased ] initialised with @xmath358 , and selection mechanism @xmath124 either    * @xmath276-tournament selection with @xmath359 , * @xmath346-selection with @xmath360 , * linear ranking selection with @xmath361 , or * exponential ranking selection with @xmath362 ,    then the algorithm tracks the optima of @xmath32 efficiently .",
    "the result follows from theorem [ thm : pop - robust - long - term ] if we can show that there exist constants @xmath363 and @xmath364 such that @xmath365 for all @xmath311 $ ] . the results for @xmath276-tournament , @xmath346-selection and linear ranking follow from lemmas  5 , 6 and 7 from @xcite with @xmath10 in place of @xmath366 .",
    "for exponential ranking , we notice that @xmath367 the result then follows similarly to @xmath276-tournament as in the proof of lemma  5 in @xcite with @xmath203 in place of @xmath276 ( equations  ( 3 ) and ( 4 ) in that proof literally show that @xmath368 , then the constants @xmath369 and @xmath370 are shown to exist given the condition on @xmath276 ) .",
    "finally , we apply theorem  [ thm : sel - mechanism ] to show that population - based eas can track the optima of the example moving hamming ball function efficiently .",
    "note that the parameter @xmath203 in linear ranking selection can only take values in the interval @xmath371 $ ] .",
    "the conditions of theorem  [ thm : sel - mechanism ] can therefore only be satisfied if @xmath372 , i.e. , the optimal regions can only change slightly . for the last part of the paper , we therefore exclude linear ranking selection .",
    "[ cor : pop - general - result - mhb ] for any constants @xmath373 , @xmath158 , @xmath374 and @xmath375 , algorithm  [ algo : popbased ] with the bitwise mutation operator @xmath83 for @xmath376 , with population size @xmath377 , and selection mechanism @xmath124 either    * @xmath276-tournament selection with @xmath378 , * @xmath346-selection with @xmath379 , * exponential ranking selection with @xmath380 .    can efficiently track the moving optima of @xmath156 .",
    "it follows from lemma [ lem : mhb - func - stable ] that for any constant @xmath184 , @xmath156 is @xmath381-stable with respect to the mutation operator @xmath83 . since @xmath382 for a sufficiently small @xmath91 , the function is also @xmath383-stable .",
    "the result then follows by applying theorem  [ thm : sel - mechanism ] .",
    "this paper has considered the frequently stated intuition that evolutionary algorithms maintaining a _ population _ of diverse solutions can be more resilient to dynamic changes in the objective function than algorithms maintaining single solutions .",
    "we have described a general class of fitness functions where population - based evolutionary algorithms outperform single - individual evolutionary algorithms .",
    "we have proved that for this function class , single - individual approaches , such as the ( 1 + 1 )  ea and rls , have a constant risk of losing the optimal solution region at any given time . moreover , these single - individual algorithms not only lose the optimal region with constant probability , but are also likely to drift away from the optimal region subsequently .    on the other hand , assuming a not too high frequency of change , we describe sufficient conditions such that a non - elitist population - based evolutionary algorithm will remain within the optimal region with overwhelmingly high probability . our analysis covers a range of the most commonly used selection mechanisms , and we provide appropriate parameter settings for each of them .",
    "furthermore , the success of the population - based evolutionary algorithm does not rely on an explicit diversity mechanism .",
    "our analysis gives further explanations of how and why populations can be essential and widely used in dynamic optimisation .",
    "as future work , we would like to investigate further the influence of population settings within this class of dynamic functions , such as elitist populations , the necessary condition for the population size with respect to the frequency and magnitude of changes and how a population could rebuild itself after losing a few optimal solutions .",
    "the research leading to these results has received funding from the european union seventh framework programme ( fp7/2007 - 2013 ) under grant agreement no 618091 ( sage ) , and is based upon work from cost action ca15140 ` improving applicability of nature - inspired optimisation by joining theory and practice ( imappnio ) ' .    10    j.  branke and w.  wang .",
    "theoretical analysis of simple evolution strategies in quickly changing environments . in _ proceedings of the 5th annual conference on genetic and evolutionary computation _",
    ", gecco03 , pages 537548 , 2003 .",
    "dang , t.  jansen , and p.  k. lehre .",
    "populations can be essential in dynamic optimisation . in _ proceedings of the 17th annual conference on genetic and evolutionary computation conference _",
    ", gecco15 , pages 14071414 .",
    "acm , 2015 .",
    "dang and p.  k. lehre .",
    "runtime analysis of non - elitist populations : from classical optimisation to partial information . , 75(3):428461 , 2016 . s.  droste .",
    "analysis of the ( 1 + 1 ) ea for a dynamically bitwise changing onemax . in _ proceedings of the 2003 international conference on genetic and evolutionary computation _ , gecco03 , pages 909921 .",
    "springer - verlag , 2003 .",
    "s.  droste , t.  jansen , and i.  wegener . on the analysis of the ( 1 + 1 ) evolutionary algorithm . , 276:5181 , 2002 .",
    "s.  droste , t.  jansen , and i.  wegener . .",
    ", 39(4):525544 , 2006 .",
    "h.  fu , p.  r. lewis , b.  sendhoff , k.  tang , and x.  yao .",
    "what are dynamic optimization problems ? in _ proceedings of the ieee congress on evolutionary computation , 2014 _ , pages 15501557 , 2014 .",
    "d.  e. goldberg and k.  deb . a comparative analysis of selection schemes used in genetic algorithms . in _ proceedings of the first workshop on foundations of genetic algorithms _ , foga 1991 ,",
    "pages 6993 .",
    "morgan kaufmann , 1991 .",
    "t.  jansen and u.  schellbach .",
    "theoretical analysis of a mutation - based evolutionary algorithm for a tracking problem in the lattice . in _ proceedings of the 7th annual conference on genetic and evolutionary computation _",
    ", gecco05 , pages 841848 .",
    "acm , 2005 .",
    "t.  jansen and c.  zarges . evolutionary algorithms and artificial immune systems on a bi - stable dynamic optimisation problem . in _ proceedings of the 16th annual conference on genetic and evolutionary computation conference _",
    ", gecco14 , pages 975982 .",
    "acm , 2014 .",
    "t.  ktzing , a.  lissovoi , and c.  witt . on generalized dynamic onemax . in _ proceedings of the 2015 acm conference on foundations of genetic algorithms xiii",
    "_ , foga 2015 , pages 4051 .",
    "acm , 2015 .",
    "t.  ktzing and h.  molter .",
    "beats ea on a dynamic pseudo - boolean function . in _ proceedings of the 12th international conference on parallel problem solving from nature - volume part i _ ,",
    "ppsn12 , pages 113122 .",
    "springer - verlag , 2012 .",
    "p.  k. lehre .",
    "fitness - levels for non - elitist populations . in _ proceedings of the 13th annual conference on genetic and evolutionary computation _",
    ", gecco11 , pages 20752082 .",
    "acm , 2011 .",
    "a.  lissovoi and c.  witt .",
    "runtime analysis of ant colony optimization on dynamic shortest path problems .",
    ", 561:7385 , 2015 .",
    "a.  lissovoi and c.  witt . vs. population - based ea on a family of dynamic fitness functions .",
    ", 75(3):554576 , 2016 . m.  mitzenmacher and e.  upfal . .",
    "cambridge university press , 2005 .",
    "p.  s. oliveto and c.  witt .",
    "simplified drift analysis for proving lower bounds in evolutionary computation .",
    "59(3):369386 , 2011 .    p.  s. oliveto and c.  zarges .",
    "analysis of diversity mechanisms for optimisation in dynamic environments with low frequencies of change .",
    ", 561:3767 , 2015 .",
    "p.  rohlfshagen , p.  k. lehre , and x.  yao .",
    "dynamic evolutionary optimisation : an analysis of frequency and magnitude of change . in _ proceedings of the 11th annual conference on genetic and evolutionary computation _ , gecco09 , pages 17131720 .",
    "acm , 2009 .    s.  a. stanhope and j.  daida .",
    "( 1 + 1 ) genetic algorithm fitness dynamics in a changing environment . in _ proceedings of congress in evolutionary computation _ ,",
    "ieee cec99 , pages 1851185 , 1999 .",
    "f.  topse . some bounds for the logarithmic function . in y.",
    "j. cho , j.  k. kim , and s.  s. dragomir , editors , _ inequality theory and applications _ ,",
    "volume  4 , pages 137151 .",
    "nova science publishers , incorporated , 2007 .",
    "s.  yang and x.  yao , editors . ,",
    "volume 490 of _ studies in computational intelligence_. springer , 2013 .",
    "[ lem : poisdist ] let @xmath384 , then for all @xmath385 @xmath386"
  ],
  "abstract_text": [
    "<S> real - world optimisation problems are often dynamic . </S>",
    "<S> previously good solutions must be updated or replaced due to changes in objectives and constraints . it is often claimed that evolutionary algorithms are particularly suitable for dynamic optimisation because a large population can contain different solutions that may be useful in the future . </S>",
    "<S> however , rigorous theoretical demonstrations for how populations in dynamic optimisation can be essential are sparse and restricted to special cases .    </S>",
    "<S> this paper provides theoretical explanations of how populations can be essential in evolutionary dynamic optimisation in a general and natural setting . </S>",
    "<S> we describe a natural class of dynamic optimisation problems where a sufficiently large population is necessary to keep track of moving optima reliably . </S>",
    "<S> we establish a relationship between the population - size and the probability that the algorithm loses track of the optimum . </S>"
  ]
}