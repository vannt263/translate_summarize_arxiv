{
  "article_text": [
    "one of the most important characteristics of the telephone call centers is their varying number of service requests ( calls ) in time .",
    "as the cost of labor is the most significant one in such service systems , the problem of adequate scheduling of its employees has a long history in the area of operational research .",
    "the methods proposed to analyze such time - varying behavior in order to find optimal working schedules for given demand forecasts are based mostly on approximations , by adopting stationary queuing models .",
    "examples of such well established methods can be found e.g in @xcite or @xcite .",
    "however , stationary solutions for generating such schedules are , in many situations , not adequate .",
    "@xcite demonstrated that such approximations can be either entirely unreliable or deliver results significantly different than methods based on inherently transient models . despite this , their widespread use is commonly justified by simple implementation and low computational cost .",
    "another inspiration for this research was the problem of real - time schedule adjustments in situations when we have to deal with much higher than planned volume of service requests , technical problems resulting in higher service times or staff absence . in order to maintain both service level and efficiency",
    ", such decisions can involve moving of the break times , extending shift times or temporarily involving other employees ( quality assurance , supervisors ) in answering the calls .",
    "although usually generating higher cost than the normal schedule ( paying overtime or involving higher paid personnel ) , requiring very short decision time and being rather common than exceptional , they are , surprisingly , not particularly well supported by current , otherwise quite sophisticated , call center management systems . as they are transient by their very nature and often deal with an overloaded system , their modeling using stationary queuing models as proposed , for example , in @xcite would deliver possibly unreliable results as well .",
    "the main objective of this work is to model such non - stationary systems in a reliable and precise way with computational efficiency enabling its use for schedule planning and in real - time applications .",
    "the paper is structured as follows . in the next section the model and the basic notation",
    "are introduced .",
    "section 3 introduces continuous time markov chains .",
    "section 4 reviews the original uniformization algorithm with steady - state detection and section 5 introduces its modifications for modeling inhomogenous",
    "m / m / s queuing systems with particular emphasis on the proposed new steady state detection and error control methods .",
    "the paper ends with a summary of experimental results , implementation details , conclusions and proposals for future research .",
    "to demonstrate the implementation we use the following simplified model of a call centre : the analyzed period is finite ( e.g. one working day ) with the system starting empty ; the size @xmath0 of the system which represents the number of possible states is finite , equal to @xmath1 = number of servers plus @xmath2 = capacity of the queue , with corresponding discrete state space @xmath3,@xmath4 , representing number of service requests ( served / waiting calls ) in the system .",
    "customers arrive according to an inhomogenous poisson process with rate @xmath5 , the service rate @xmath6 is exponential . the load @xmath7 can be bigger than 1 .",
    "there is no abandonment , therefore , the capacity of the queue has to be big enough to be considered practically infinite , which is insofar realistic , as the cost of setting practically unlimited queue space in the telecommunications equipment is negligible nowadays .",
    "the system size must , in consequence , ensure that the probability of being in the state @xmath8 ( abandoning service requests ) is insignificant compared to the required computational precision of the whole model , effectively approximating an m / m / s system .",
    "the description and notation is based on @xcite and @xcite .",
    "a ctmc is described by _ infinitesimal generator matrix _ @xmath9 and the _ initial state probability vector _ @xmath10 , where the value @xmath11 is the rate at which the state @xmath12 changes to state @xmath13 and @xmath14 represents the rate for the event of staying in the same state .",
    "the transient distribution at time t @xmath15 can be calculated using kolmogorovs forward equations : @xmath16 where the vector @xmath17 $ ] gives probabilities of the system being in any of the states at time @xmath18 .    in the inhomogenous case ,",
    "the generator matrix changes with time @xmath18 and is denoted as @xmath19 .",
    "consequently the transient distribution @xmath15 in that case will take the form : @xmath20 both represent linear systems of ordinary differential equations , which can be solved using either direct methods for ( [ qh ] ) or using numerical approximations for both to solve them in steps .",
    "an overview of available numerical solvers can be found in @xcite or @xcite , many of them are available e.g. in the gnu scientific library .",
    "particularly interesting in this context are the embedded runge - kutta methods , producing two approximations of different order ( e.g. 4 + 5 in popular runge -kutta fehlberg or 8 + 9 in runge - kutta prince - dormand ) .",
    "the comparison of the two solutions allows direct estimation of the error of the approximation for the given size of the computational step and can be alternatively used for adaptive step size control for the required error bound .",
    "uniformization or randomization , known since the publication of jensen in 1953 and , therefore , often referenced as jensen method , is the method of choice for computing transient behavior of ctmcs .",
    "many authors compared its performance in different applications with the conclusion that it usually outperforms known differential equation solvers ( e.g. @xcite , @xcite , @xcite ) . to use uniformization",
    "we first define the matrix @xmath21 which for @xmath22 is a stochastic matrix . the value of @xmath23 is called uniformization rate .",
    "further , let @xmath24 be the probability of a poisson process with rate @xmath23 to generate @xmath25 events in the interval @xmath26 .",
    "one now finds for @xmath15 @xmath27 the formula ( [ jensen ] ) can be interpreted as a discrete time markov process ( dtmc ) embedded in a poisson process generating events at rate @xmath23 .",
    "the implemented uniformization algorithm is based on @xcite and computes transient state probabilities for a ctmc with the following modification of ( [ jensen ] ) : @xmath28 where @xmath23 is uniformization rate , as described in ( [ pmx ] ) , and @xmath29 is the state probability vector of the underlying dtmc after each step @xmath12 computed iteratively by : @xmath30 to compute @xmath31 , within prespecified error tolerance , in finite time , the computation stops , when the remaining value of cdf of poisson distribution is less than the error bound @xmath32 : @xmath33 with @xmath25 being the _ right truncation point_. as @xmath34 increases , the corresponding probabilities of small number of @xmath12 poisson events occurring become less significant",
    ". this allows us to start the summation from the @xmath35th iteration called _ left truncation point _ with the equation [ reibmann88 ] reduced to : @xmath36 @xcite suggests that the values of @xmath35 and @xmath25 be derived by : @xmath37    the main computational effort of the algorithm lies in consecutive @xmath25 matrix vector multiplications ( mvm ) , necessary for calculation of epochs of dtmc in ( [ reibmann88pi ] ) and is of @xmath38 where @xmath39 is the number of nonzero elements of ( sparse ) @xmath40 . as our m / m",
    "/ s / n model is a birth - death process and only transitions between neighboring states are possible , the resulting transition matrix will be tridiagonal ( @xmath41 ) of size @xmath42 with @xmath43 .    as in the case of a call center",
    ", the optimal setting of the system in terms of the trade - off between service quality and efficiency is achieved for approximately steady load @xmath44 , the number of ( scheduled ) servers will then grow approximately linearly with @xmath45 .",
    "further , if we assume the proportion of servers to the queue capacity to be constant and being some fraction of system size @xmath46 , the resulting value of uniformization rate will be @xmath47 .",
    "the computational complexity dependent of the size of the analyzed system would be then roughly of :    @xmath48    for large @xmath34 , as the distribution converges to normal , which is symmetric with the mean @xmath34 , both left and right truncation points @xmath35 and @xmath25 in ( [ reibmann88lk ] ) will tend to be symmetric to the mean .",
    "the number @xmath49 is consequently of @xmath50 and the number of additional @xmath51 mvms for the given error tolerance of @xmath52 and proportional to inverse cdf for that given @xmath32 .",
    "therefore , although we could solve the @xmath15 with any accuracy @xmath53 , choosing a higher , acceptable for respective practical application , value would mean some computational advantage .",
    "the savings due to ( tighter ) left truncation are , however , rather insignificant , unless , as proposed in @xcite the computation of the first significant dtmc is performed in an improved way .",
    "an example for this could be precomputing of a @xmath54 in ( [ jensen ] ) by successive squaring of @xmath40 which were practical for moderate system sizes or systems with low sparsity as it causes a fill - in of subsequential transition matrices .",
    "another method to compute the dtmc vectors in a more efficient way , presented first in @xcite , is based on recognizing the steady - state of the underlying dtmc .",
    "if convergence of the probability vector in ( [ reibmann88pi ] ) is guaranteed then we can stop the mvm after arriving at the steady - state .",
    "we can state their proposal as follows : let us assume that dtmc has the steady state solution @xmath55 , and that after the @xmath56 iteration of ( [ reibmann88pi ] ) , @xmath57 , where @xmath58 is an arbitrary vector norm . then ( [ reibmann88truncated ] ) changes to : @xmath59 with @xmath60 used instead @xmath15 denoting transient state probability vector computed using approximate steady state dtmc vector @xmath61 . according to @xcite for a predefined error bound @xmath32 ( as in , )",
    "the following inequality holds :    @xmath62    the computing of consecutive epochs of the dtmc is equivalent to the power method of finding stationary probability vector of a finite markov chain . according to @xcite , if the stochastic matrix @xmath40 is aperiodic , convergence of the power method is guaranteed and the number of iterations @xmath25 needed to satisfy a tolerance criterion @xmath63 may be obtained approximately from the relationship    @xmath64    where @xmath65 is the magnitude of subdominant eigenvalue @xmath66 of matrix @xmath40 @xmath67 reducing , consequently , the computational complexity to @xmath68 .",
    "the detailed analysis of convergence of the power method may by found in @xcite or in standard books on numerical analysis .",
    "since in most cases the size of the subdominant eigenvalue is not known in advance , the usual method of testing for convergence is to examine some norm of the difference of successive iterates : @xmath69 @xcite recommends using the relative convergence test of iterates spaced apart by @xmath70 being function of the rate of convergence :    @xmath71 and suggests envisaging further different convergence tests in order to accept the approximation as being sufficiently accurate .",
    "the infinitesimal generator matrix @xmath19 of an inhomogenous continuous - time markov chain ( ictmc ) is time dependent and the process is described by modified kolmogorovs forward equations .",
    "as it is still of the type @xmath72 , with @xmath73 and @xmath74 , it could be solved by using iterative ode solvers ( e.g. euler or the already mentioned runge - kutta methods ) as demonstrated , for example , in @xcite .",
    "when the changes in generator matrix q occur in a discrete way at finite points of time and all the rates are constant during the intervals between them , we could replace the analyzed ictmc with a sequence of homogeneous systems computing the state probability vectors for consecutive time periods recursively using uniformization ( e.g. as in @xcite ) .    in case of a call center , time dependent changes in @xmath75",
    "can occur either discretely due to the changing number of servers ( arrivals or departures of agents due to the schedule , planned and unplanned breaks , after call work or technical errors like failures of working places etc ) or due to changes in the arrival rate .    since the forecast and current traffic data in call center management applications are already aggregated with their average values by some arbitrary period ( e.g. 5 , 15 or 30min ) , we will further assume , similarly to @xcite , q(t ) being accordingly piecewise constant and refer to such consecutive time periods with the coresponding hctmcs as steps .    for the implemented model",
    "a pre - emptive discipline is assumed , where the service request rejoins the queue when all servers are busy and a server number decrease happens .",
    "this allows for reuse of the calculated probability vector for the next period without modification , which changes only the interpretation of probabilities of a state from being served to waiting ( or the opposite for the server increase ) .",
    "the detailed description of an alternative approach ( the exhaustive discipline ) can be found e.g. in @xcite where servers finish serving requests in progress .",
    "another approach adopting uniformization for time - inhomogenous ctmcs introduced by @xcite with subsequent improvements by @xcite , @xcite and @xcite could be used if continuous arrival rates were available , reducing the error of the approximation with the average rates .",
    "an additional aspect in case of a call center is that for long time steps even a very exact calculation of the final state probability vector is not sufficient if some performance indicators , like service level or any other distribution of waiting times , are to be estimated as in @xcite or @xcite .",
    "for this purpose additional intermediary results are needed and that , as in the most transient cases they can not be simply interpolated with required precision , implies the need for additional splitting of long calculation steps accordingly .",
    "the main purpose of modeling a call center is the prediction of service level as a function of time .",
    "the service level is defined in practical application as percentage of customers , waiting for being serviced longer than @xmath76 time units ( e.g. sl of 90/10 means that no more than 10% of service requests would have to wait longer than 10s ) .",
    "the exact expressions how to calculate predicted sl as a function of consecutive state probability vectors and number of servers can be found in @xcite or @xcite . in order to estimate correct values for sl ,",
    "the error of calculated state probabilities should stay continuously within the predefined range for the whole modeled period .",
    "one of the biggest advantages of the uniformization is its strict error bounding for one step independently of its length .",
    "however , to model an ictmc according to the above requirements we have to control the error of computation for a number of steps with possibly different lengths .",
    "it is not difficult to show ( e.g. @xcite ) that the total error for a number of uniformization steps is the sum of truncation errors ( error bounds ) for each step , consequently the total error bound has to be distributed to sub - intervals .",
    "assume for a time period @xmath77 with a known initial distribution @xmath10 that for any @xmath78 , @xmath79 $ ] the value of each its state has to be computed with an error less than @xmath80 .",
    "let us further assume @xmath81 being the error after computing some @xmath82 .",
    "then : @xmath83    according to @xcite for @xmath84 being the remaining error , in a step of length @xmath85 starting with @xmath15 the error should be @xmath86 to not exceed the error @xmath80 .",
    "this implies distribution of the error bound proportional to the length of the respective single interval .",
    "although it is very intuitive , one could also consider , according to the already mentioned computational complexity of higher right truncation values , which is asymptotically of @xmath52 , to set rather higher error bounds for the steps with smaller @xmath34 ( shorter size or lower activity ) or , as explained further in the text , for higher steady - state detection thresholds .",
    "for example , tightening the error bound from @xmath87 to @xmath88 requires for @xmath89 about 20% of additional mvm , whereas for an @xmath90 the increase is only 6% .    as the dtmc representing an m / m / s / n is both irreducible and aperiodic , its limiting ( steady - state ) distribution is unique and independent of the initial distribution .",
    "the convergence properties required for existence of a steady - state solution of queuing systems can be found e.g. in @xcite . due to",
    "the fact that the model does not allow abandonment and approximates an infinite capacity system with a m / m / s / n system of appropriate capacity , the existence of steady - state ( in the meaning of either @xmath8 not growing infinitely or for a @xmath8 fixed - @xmath91 not bigger than some arbitrary value limiting adequacy of the approximation ) requires @xmath92 as for an m / m / s system ( such system will further be referred to as converging ) .",
    "its precise stationary distribution @xmath93 can , using global balance equations ( e.g. @xcite , be easily calculated ( see section implementation details ) .",
    "we will consider now the case of the step of lenght @xmath94 with initial probability vector @xmath15 as in with the dtmc converging .    as pointed out in the @xcite , in order to rely on the _ geometrical convergence _ of power iterations for ( aperiodic ) dtmc the _ total variation norm _ @xmath95 , defined as @xmath96 has to be used for the error estimate .",
    "let us assume that after the @xmath56 iteration of ( @xmath97 with @xmath35 for @xmath98 as in ) @xmath99 now instead of further ( infinitely ) iterating @xmath100 in order to calculate @xmath101 as in , we will use @xmath93 ( instead of @xmath100 , as proposed in the original algorithm by @xcite ) as the @xmath102 approximation of such ( error free ) @xmath101 .    therefore , for :    @xmath103    as the norm of the first summation is , due to @xmath29 and @xmath93 being stochastic vectors ( and , therefore , @xmath104 ) and @xmath105 , strictly upper bounded by :    @xmath106    and , as from initial condition : @xmath107 the resulting error is upper bounded :    @xmath108    as steady - state distribution is unique and independent of initial probability distribution ( of the step ) the above error is absolute and independent of the error of the previous steps . therefore :    @xmath109    as the difference ( error ) between the @xmath29 and @xmath93 gets smaller , we can expect the angle between both vectors decreasing as well , therefore , the convergence rate will approach asymptotically some value dependent only on subdominant eigenvalue of @xmath40 . if we treat the difference of both vectors as function of current error and some convergence rate function in @xmath12 , we can consequently calculate its value for some @xmath110 . although we do not have neither the subdominant eigenvalue nor the exact function of convergence rate @xmath111 , we can , at any point , easily estimate numerically the current error , the convergence rate and its first derivative , which allows the estimation of @xmath112 using second order taylor expansion as :    @xmath113    with the quality of the estimation improving as @xmath114 .",
    "let us assume some @xmath115 with @xmath35 for @xmath98 as in , such that @xmath116 equal to the cdf of the discrete poisson distribution function , as in and insignificant ( e.g. @xmath117 ) .",
    "if for some @xmath118 the relative error of @xmath29 is greater than the convergence threshold @xmath119 but smaller than some @xmath120 ( @xmath120 relatively small to @xmath93 in order to provide acceptable quality of ( [ burak13sserr_sltaylor ] ) ) and the relative error of @xmath121 smaller than the convergence threshold @xmath119 , then we can stop further iterating @xmath29 and use @xmath93 as @xmath102 with :    @xmath122    however , meeting the convergence can happen earlier , when the error @xmath123 from the previous step causes the initial probability vector p(t ) being closer to limiting distribution of the current step than the theoretical error - free value .",
    "due to the geometrical convergence of the dtmc this difference is always smaller than :    @xmath124    therefore , if the initial ( convergence ) condition has not been met until @xmath125 ( or when @xmath126 if is used ) , @xmath101 will be calculated as in and @xmath127 .",
    "the same applies if the dtmc is not converging .",
    "+ we can now use the fact that the error bound is , in case the steady state is reached , absolute and independent of the error of the previous steps to set the convergence threshold dependent rather on the actual total error bound than the error for the single step ( as proposed e.g. by @xcite ) .",
    "this is particularly useful in cases of steps with large @xmath34 as the relative cost of achieving tighter truncation bonds gets smaller , allowing to trade them for higher convergence thresholds while still within the global error bound for the whole solution .",
    "assume the system at time @xmath128 . to satisfy @xmath81 for each @xmath15 ,",
    "@xmath129 $ ] we have to :    @xmath130      to test the implementation the following model has been used : a service system ( call center ) working for time @xmath77 = 24h and starting empty .",
    "the arrival rate is sinusoidal with two peaks and divided into 288 ( 5min ) periods with constant averaged rates , similar to the example in @xcite , with the load varying , in the first example - between 0.65 and 1.05 .",
    "the service rate and number of servers are constant ( @xmath131 , @xmath132 ) , the arrival rate varies in time - @xmath133 .",
    "the capacity of the queue is constant and chosen so that for all times the probability @xmath134 of the system being in the state @xmath8 is less than @xmath135 for the smallest ( 30 + 180 ) and does not reach @xmath136 for all the other systems .",
    "to evaluate the impact of the proposed steady - state detection algorithm , models of 5 different sizes have been at first calculated using unmodified uniformization algorithm with an error step @xmath137 corresponding to the total error bound @xmath138 .",
    "all experiments were performed on an 1.7ghz pc under 64bit linux os with a processor supporting vector operations in both : avx with 256bit vectors ( 4 double or 8 float operations simultaneously ) and the older sse instruction set with 128bit vector operations ( an intel i5 - 3317u with cpu throttling disabled via kernel scaling governor ) , compiled with gnu gcc compiler .    in order to evaluate the impact of our contribution on some common , hardware independent reference ( base ) , the algorithm was firstly implemented using _",
    "cblas_(s / d)gbmv _ ( band ) matrix vector multiplication from automatically tuned linear algebra software ( atlas ) for gcc compiler as mvm routine .",
    "the working set of the critical part of the implementation requires for every step : access to the initial ( e.g. @xmath15 from previous step ) probability vector and creation of new state probability vector which is then used after every mvm to store partial sums and saved `` permanently '' into ram after step end .",
    "the calculation of sub - sequential dtmcs requires memory for two probability vectors and 3 rows of the transition matrix .",
    "all of them are reused in following steps in order to minimize memory bandwidth .",
    "each of the referenced vectors is of size n+1 .    due to the regular structure of the transition matrix ,",
    "the second , improved , mvm algorithm calculates consecutive dtmcs creating required operands recursively ( on the fly ) instead of storing the transition matrix for explicit matrix vector multiplication - consequently reducing working set of mvm loop to only 2 vectors of size n+1 .",
    "[ basesse3double ]    all measurements use standard unix _",
    "time.h / clock ( ) _ function - returning cpu time .",
    "all times are in milliseconds .    as the precompiled atlas library was available only for sse3 , all implementations",
    "are compared using only this instruction set ( compiled with -march = core2 for gcc ) .",
    "the column _ improved ( avx ) _ showing the results of the same program compiled using newer instruction set , being clearly an exception from the above statement , only demonstrates that the modified algorithm is vectorizable and scales well with available vector length .      since the results for the steps with load @xmath139 would be identical to those when no steady detection was used , we modified slightly the first example , changing only the arrival rate to @xmath140 with the load @xmath141 , in order to show the impact of steady state detection on performance and precision in cases when the system can possibly converge .",
    "when applying now with e.g. constant @xmath142 and @xmath143 , we can set the steady - state detection threshold @xmath144 .",
    "load @xmath145 , s=1000 q=3000        load @xmath145 , s=1000 q=3000,@xmath146    the impact of reduced computational effort due to steady - state detection for some chosen total error bounds ( between @xmath147 and @xmath148 ) , with corresponding steady - state detection thresholds , is illustrated for the system of size 4000 in figure [ ssd70_90__1000_3000 ] and with the use of convergence error prediction as in ( [ burak13sserr_sltaylor ] ) in figure [ ssd70_90_taylor_1000_3000 ] ( @xmath146 ) .",
    "the detailed results of computation times are in tables [ table_ssd_70_90 ] and [ table_ssd_70_90_taylor ] .",
    "[ table_ssd_70_90 ]    [ table_ssd_70_90_taylor ]    subsequently , we revisit our first experiment with the load @xmath149 ( figure [ load ] ) , now using , with the same @xmath150 parameters as in the modified example . the results ( with convergence error prediction )",
    "are in table [ table_ssd_65_105_taylor ] and for the system of size 4000 in figures [ ssd65_105__1000_3000 ] and [ ssd65_105_taylor_1000_3000 ] .",
    "[ table_ssd_65_105_taylor ]        load @xmath149 , s=1000 q=3000        load @xmath149 , s=1000 q=3000        load @xmath149 , s=1000 q=3000    figure [ ssd65_105err__1000_3000 ] shows the error of the expected state of the system , derived from the calculated probability vector as : @xmath151\\ ] ] the reference for the error estimate has been calculated with @xmath152 .",
    "the computational overhead resulting from steady - state detection ( mainly due to the calculation and comparison of vector norms ) , which has to be done in cases when the system can possibly converge ( @xmath153 in the above example ) and from tighter step error bounds ( traded for the convergence threshold ) , is offset by savings due to the steady - state detected within the preset error bound , at first for the error bound of @xmath154 .",
    "however , the savings in the practical call center applications should be rather closer to the modified ( converging ) example , as overloaded time periods will usually constitute much lower percentage of operational times due to the service level requirements .",
    "the relative increase of computational complexity visible in the @xmath155 case in both ( original and modified ) examples is partially due to filling of the probability vector with very small probability values requiring more floating points operation per mvm .",
    "this could be simply ignored for practical reasons , as there is ( to the best knowledge of the author ) no call center on the earth employing more then 1000 agents on a single skill ( and even if there were one , then they could probably afford more powerful cpu than the author s @xmath156 notebook ) .",
    "alternatively , we can consider the probabilities smaller than e.g. @xmath157 being insignificant and treat them as if they were equal to @xmath147 , reducing to some extent this effect .",
    "the systematic loss of precision due to such truncation would not exceed @xmath158 of the probability mass for the @xmath155 case and be , therefore , much smaller than the error due to the truncation of poisson probability mass ( as shown e.g. in the @xmath159 example on figure [ ssd65_105err__1000_3000 ] ) .",
    "an additional advantage of this approach is the possibility to store and process the dtmc vectors in single ( binary32 ) precision , which enables up to 2 times more floating point operations in the same time when using sse or up to 4 times more when using avx instruction set .",
    "the possible disadvantage is much bigger accumulation of rounding errors due to mvm with much less precision .",
    "[ table_ssd_70_90_sse32 ]    [ table_ssd_65_105_sse32 ]        load @xmath149 , s=1000 q=3000    tables [ table_ssd_70_90_sse32 ] and [ table_ssd_65_105_sse32 ] show execution times of such implementation ( for the same data as tables [ table_ssd_70_90]/[table_ssd_70_90_taylor ] and [ table_ssd_65_105_taylor ] ) . figure [ ssd65_105err_float_1000_3000 ] shows its error ( similar to figure [ ssd65_105err__1000_3000 ] ) .",
    "the results in tables [ table_ssd_70_90_avx32 ] and [ table_ssd_65_105_avx32 ] show the same computation as the tables [ table_ssd_70_90_sse32 ] and [ table_ssd_65_105_sse32 ] performed with the newer avx instruction set ( on the same hardware ) .",
    "they can not be directly compared with the reference ( atlas ) implementation due to the different instruction set , they show , however , much more efficient utilization of available hardware ( using still only 1 of 2 available cpu cores ) .",
    "[ table_ssd_70_90_avx32 ]    [ table_ssd_65_105_avx32 ]      all described algorithms assume that some basic floating point arithmetic is implemented conforming to ieee 754 - 2008 standard ( e.g. gcc default ieee 754 compliance on intel cpu s supporting either sse or avx instructions ) .",
    "in particular , the numerical accuracy and stability analysis ( rounding , underflow and overflow ) assumes floating point formats implemented as binary32 , binary64 or binary128 ( radix 2 ) , correct rounding to the nearest even for basic arithmetic operations and correct conversion from integers .",
    "the algorithm presented in appendix computes for given values @xmath45 ( @xmath34 in the uniformization algorithm ) , @xmath32 and @xmath160 :    the limits @xmath161 , the normalization value @xmath162 and the weights @xmath163 , such that individual poisson probabilities : @xmath164    and @xmath165 , where @xmath166 is equal to the cdf of the discrete poisson distribution function , as in .    if @xmath160=@xmath32 , only the discrete poisson probabilities are calculated and stored ( e.g. in cases of a non converging system ) , like for the traditional uniformization algorithm .",
    "the algorithm computes the weights recursively starting from mode @xmath167 , with @xmath168 being the initial weight , similarly to @xcite . as there is practically no penalty in using double precision numbers in comparison to the single ( float ) precision for sequential calculations on modern cpu s , the ( double precision ) binary64 format with @xmath169 bit precision and @xmath170 bit exponent",
    "the initial value used for @xmath168 is 0x1.0p176 ( @xmath171 ) .",
    "the calculation of every weight , both left and right to @xmath70 , requires one multiplication and one division .",
    "as we assume basic ieee 754 - 2008 conformity , the relative rounding error for every next nth calculated weight will be upper bounded by @xmath172 .",
    "the rounding error of w is bounded by @xmath173 , where @xmath174 is the machine epsilon for binary64 , but will probably be much smaller , due to the summation performed in increasing order and the specific properties of the function , as already pointed out in @xcite , or for much more detailed analysis of the error of sum of exponentially distributed numbers in increased order also @xcite .",
    "therefore , the use of more accurate summation algorithms ( e.g. kahan s or priest s compensated summation ) or further increase of precision ( e.g. trough using of binary128 type ) seems not to be justified .",
    "the number of weights for the calculation of the normalization value @xmath175 is chosen so that the remaining ( weighted ) cdf is always smaller than the numerical accuracy of @xmath162 : @xmath176 consequently , @xmath177 and is not always equal to one , as in @xcite .    for bounding the number of calculated weights",
    ", the algorithm uses the property of the poisson distribution having truncation points being asymptotically of @xmath178 for constant remaining cdf ( tail ) value and approximates the required number of weights using simple function of @xmath179 .",
    "figure [ b14_weights_l ] shows the number of weights necessary to calculate the distribution with truncated probability mass of less than some given value , as a function of @xmath45 , with l and r being the values calculated by the algorithm s approximation .",
    ", title=\"fig : \" ] , title=\"fig : \" ]    the values of weights are ( for @xmath180 - restricted due to the size of c++ standard _ long _ format ) , due to the choice of @xmath181 $ ] and bounding of their number by the approximation , always between @xmath182 and @xmath183 and , therefore , comfortably between under- and overflow limits of binary64 format .",
    "the computational complexity is due to the bounding method of @xmath184      the calculation of exact steady state probability vector @xmath93 is done using the well known formula :    @xmath185    the implementation uses its modification similarly to the algorithm calculating poisson probabilities , with the mode @xmath186 and @xmath181=$]0x1.0p176 .",
    "consequently , the same rounding error approximations for calculating probabilities apart from @xmath70 apply .",
    "the calculation of weights stops at the limits of the vector or when their values would be no more normalized binary64 numbers using for the remaining weights the value 0x0.0p+0 ( to prevent e.g. underflow ) .",
    "the weights are normalized by the total weight to steady state probabilities and only the normalized ( either binary32 or binary64 ) numbers or 0x0p+0 value are stored .      due to the restricted precision of binary32 ( float )",
    ", the probability weighted sum of significant dtmc vectors is done both for binary32 and binary64 implementations in binary64 ( double ) accuracy .",
    "consequently , the consecutive probability vectors @xmath15 are always stored and manipulated in binary64 precision ( including in particular the casting of precalculated binary32 steady state dtmc vector in cases where steady state was detected ) .",
    "in this paper we showed that the uniformization can be applied in a very effective way to evaluate transient behavior of m / m / n queues . applied to modeling of the call center schedules , it allows calculation of transient system states for systems of any , possible in practical applications , size in a very short time ( @xmath1871s . ) , in a numerically stable way , with very high precision , using relatively common and inexpensive cpu .",
    "it can , therefore , be used in evaluating possible schedule changes in order to support short - time decisions ( e.g. shift times or breaks assignments ) in a real - time manner .",
    "its use can be also extended to schedule planning based on available forecasts , as described in @xcite .",
    "particularly useful in this application is the possibility of performance optimization using steady - state detection for systems with load less than 1 .",
    "as we can start constructing such schedules from an `` overstaffed '' prototype and then consecutively reduce the applied workforce in order to achieve the desired service level and efficiency , it is then guaranteed that the system will converge for the most of the time during such optimization , reducing the computational time to a fraction , particularly for larger system sizes as shown in the modified ( converging ) example",
    ". it can be even further accelerated by using higher error bounds for first schedule approximations and their step - wise refinement towards a final optimal solution .",
    "as the proposed error control method is not specific to the queuing systems , it could be also useful for multi - step solution of other ictmc s with some homogeneous or almost - homogeneous time steps . particularly for systems with big state spaces or long step times ( large @xmath34 ) , where we can `` trade '' the then relatively inexpensive higher cdf s truncation precision for higher convergence thresholds",
    ", it will result in significant reduction of computational effort without compromising strict error bounds for the whole ( multi - step ) solution .",
    "the presented method can be extended in several directions .",
    "the first one could be , in regard to call center modeling , to consider abandonment due to impatient customers or more generally consider cases where we can easily calculate the precise steady - state of the system in advance(e.g using flow equations ) .",
    "another would be to apply it in the similar way to other inhomogeneous ctmcs in cases , where steady state for a step could be efficiently approximated using faster converging iterative methods ( e.g. lanczos ) parallel to the dtmc evolution .    finally ,",
    "as the presented algorithm is quite thrifty in memory bandwidth use and at the same time its split for parallel calculation of ( parts of ) consecutive dtmc probability vectors would need relatively little synchronization due to the on the fly generation of coefficients , it could profit from multi - threaded execution on separate cpu cores in an almost linear way ( e.g. execution on a 8-core cpu would require almost 8 times less time ) .",
    "this could be relatively easily implemented using , for example , the standard openmp extension .",
    "....    # ifndef poisson_burak2014 # define poisson_burak2014    # include < cmath > # include < cstdlib >    class b14 {     private :      long wsize , start ;                  long left_l , right_k ;                  double * weights ;                  double total_weight ;     public : //constructor - creates weights        b14(const double lambda , double epsilon , double epsilon_ssd ) ;       long ls(){return start ; }    //left truncation point for ssd epsilons    long l ( ) { return left_l ; }   //left truncation point    long r ( ) { return right_k ; } //rigt truncation point    //weights value by the n - th poisson probability    double p(const double value , const long n )           { if(value > total_weight )      return((n>=left_l)&&(n<(wsize+start ) ) ?               ( value / total_weight)*weights[n - start ] : 0.0 ) ;     return((n>=left_l)&&(n<(wsize+start ) ) ?",
    "( value*weights[n - start])/total_weight : 0.0 ) ; }    //returns s - th cdf        double essd(const long s )            { return ( ( s>=start ) & & ( s <",
    "left_l ) ?",
    "weights[s - start]/total_weight : 0.0 ) ; }    //returns n - th weight , use together with w ( )    double weight(const long n )       { return ( ( n>=start ) & & ( n < wsize+start ) ?           weights[n - start ] : 0.0 ) ; }    //for weighted sums of small values e.g. probabilities :   //                   sum_i ( weight(i ) * p_i ) / w ( )    double w(){return total_weight ; }       ~b14(){free(weights ) ; }     } ; //end of b14 class     b14::b14(const double lambda , double epsilon , double epsilon_ssd )      { if(!(lambda > 0.0)||!(epsilon<1.0d ) )        { left_l = right_k=0;weights=&total_weight ;         total_weight = nan(\"\");return ; }       if(epsilon<1e-50)epsilon=1e-50 ;        if(epsilon_ssd<1e-50)epsilon_ssd=1e-50 ;       if(!(epsilon_ssd < epsilon))epsilon_ssd = epsilon ;   //ls = l essd=0.0         long m=(long)floor(lambda ) ;        //number of temporary weights stored       long mw=30 ; long ma=44 ; long ms=21 ;       long tsize=(long)(sqrt(lambda ) * mw )   + ma ;       long tstart = m+ms - tsize/2;if(tstart<0)tstart=0 ;        //if short of stack and big lambda : alloca - > malloc+free       double * tweights=(double*)alloca(tsize*sizeof(double ) ) ;          long j = m - tstart ;       tweights[j]=0x1.0p176 ; //weight[m ]         for(j = m - tstart;j>0;j-- )          tweights[j-1]=(tweights[j]*(j+tstart))/lambda ;       for(j = m - tstart+1;j < tsize;j++ )          tweights[j]=(lambda*tweights[j-1])/(j+tstart ) ;    //compute total_weight       total_weight=0.0 ;       for(j=0;j<(m - tstart);j++)total_weight+=tweights[j ] ;       double suml=0.0 ;       for(j=(tsize-1);j>=(m - tstart);j--)suml+=tweights[j ] ;       total_weight+=suml ;    //calculate truncation points       double ogon=(epsilon_ssd*total_weight)/2.0 ;       long i=0 ;       double cdf = tweights[i ] ;       while(cdf < ogon ) cdf+=tweights[++i ] ;       start = i+tstart ;       double cdf_start = cdf ;         ogon=(epsilon*total_weight)/2.0 ;       while(cdf < ogon ) cdf+=tweights[++i ] ;       left_l = i+tstart ;         //if(i==0)ogon*=2 ;",
    "//for historical compatibility       i = tsize-1 ;       cdf = tweights[i ] ;       while(cdf < ogon ) cdf+=tweights[--i ] ;       right_k = i+tstart ;    //only weights / cdfs between ls and r are stored          wsize = right_k - start+1 ;          weights = ( double * ) malloc(wsize * sizeof(double ) ) ;          weights[0]=cdf_start ;         for(j = start+1;j < left_l;j++ )         weights[j - start]=weights[j - start-1]+tweights[j - tstart ] ;       for(j = left_l;j<=right_k;j++ )         weights[j - start]=tweights[j - tstart ] ; } //end of b14 constructor    # endif ...."
  ],
  "abstract_text": [
    "<S> a new approach to the steady state detection in the uniformization method of solving continuous time markov chains is introduced . </S>",
    "<S> the method is particularly useful in solving inhomogenous ctmc s in multiple steps , where the desired error bound of the whole solution can be distributed not proportionally to the lengths of the respective intervals , but rather in a way , that maximizes the chances of detecting a steady state . </S>",
    "<S> additionally , the convergence properties of the underlying dtmc are used to further enhance the computational savings due to the steady state detection . </S>",
    "<S> the method is applied to the problem of modeling a call center using inhomogenous ctmc model of a m(t)/m(t)/s(t ) queuing systems .    ` </S>",
    "<S> markov processes , or in service industries , transient solutions , uniformization , numerical methods , nonstationary , algorithms , contact centre ` </S>"
  ]
}