{
  "article_text": [
    "the asymptotic behaviour of a linear ode @xmath0 , @xmath1 is completely determined by the spectral properties of the @xmath2 matrix @xmath3 .",
    "similarly , the long - term behaviour of a nonlinear ode @xmath4 in a small neighbourhood of a fixed point @xmath5 , for which @xmath6 , is completely determined by the spectral properties of the linearisation of @xmath7 at @xmath5 .",
    "well - known extensions of these facts can be constructed when @xmath5 is periodic via floquet theory . however , for general time - dependent linear odes @xmath8 , the eigenvalues of @xmath9 contain no useful information about the asymptotic behaviour as the simple example of @xcite illustrates . on the other hand ,",
    "if the @xmath9 are generated by a process with well - defined statistics , there is a good spectral theory for the system @xmath8 , and this is the content of the celebrated oseledets multiplicative ergodic theorem ( met ) ( @xcite , see also arnold @xcite for a thorough treatment ) , which we state and explain shortly .",
    "the `` well - defined statistics '' are often generated by some underlying ( typically ergodic ) dynamical system .",
    "for clarity of exposition , we will discuss discrete - time dynamics ; it is trivial to convert a continuous - time system to a discrete - time system by creating eg .",
    "time-1 maps flowing from time @xmath10 to time @xmath11 .",
    "let @xmath12 denote our _ base space _ , the space on which the underlying process that controls the time - dependence of the matrices @xmath3 occurs . as we will place a probability measure on @xmath12 , we formally need a @xmath13-algebra @xmath14 of sets that we can measure is a topological space",
    ", we can set @xmath14 to be the standard borel @xmath13-algebra generated by open sets on @xmath12 . ] .",
    "we denote the underlying process on @xmath12 by @xmath15 and assume that @xmath16 is invertible .",
    "one formally requires that @xmath16 is measurable is a topological space , and @xmath16 is continuous , then @xmath16 is measurable with respect to the standard borel @xmath13-algebra generated by open sets . ]",
    "with respect to @xmath14 .",
    "the `` well - defined statistics '' are captured by a _ @xmath16-invariant probability measure _",
    "@xmath17 on @xmath12 ; that is , @xmath18 , and we say that @xmath16 _ preserves _",
    "@xmath17 . finally , it is common to assume that the underlying process is _ ergodic _ , which means that any subsets @xmath19 of @xmath12 that are invariant ( @xmath20 , implying that trajectories beginning in @xmath21 stay in @xmath21 forever in forward and backward time ) have either @xmath17-measure 0 ( they are trivial ) , or @xmath17-measure 1 ( up to sets of @xmath17-measure 0 they are all of @xmath12 ) .",
    "now we come to the matrices @xmath3 , which are generated by a measurable matrix - valued function @xmath22 , where @xmath23 is the space of @xmath2 real matrices .",
    "we choose an initial @xmath24 and begin iterating @xmath16 to produce an orbit @xmath25 .",
    "concurrently , we multiply @xmath26 , and we are interested in the asymptotic behaviour of this matrix product .",
    "in particular , we are interested in ( i ) the growth rates @xmath27 as @xmath28 varies in @xmath29 and ( ii ) the subspaces @xmath30 on which the various growth rates occur . throughout",
    ", @xmath31 denotes the standard euclidean vector norm or the associated matrix operator norm @xmath32 ; whether @xmath31 is a vector or matrix norm will be clear from the context .",
    "surprisingly , the `` well - defined statistics '' and ergodicity ensures that these limits exist , and that there are at most @xmath33 different values @xmath34 that @xmath35 can take , as @xmath28 varies over @xmath29 and @xmath36 varies over @xmath17-almost all of @xmath12 ( note we allow @xmath37 to include the case of non - invertible @xmath3 ) .",
    "we can also decompose @xmath29 pointwise in @xmath12 as @xmath38 , where for all @xmath39 , one has @xmath40 the subspaces @xmath41 are _ equivariant _ ( or _ covariant _ ) with respect to @xmath3 over @xmath16 ; that is , they satisfy @xmath42 for @xmath43 .",
    "we use the following stronger version of the met , which guarantees an oseledets splitting even when the matrices @xmath3 are non - invertible .",
    "let @xmath16 be an invertible ergodic measure - preserving transformation of the probability space @xmath44 .",
    "let @xmath22 be a measurable family of matrices satisfying @xmath45 then there exist @xmath46 and dimensions @xmath47 with @xmath48 , and a measurable family of subspaces @xmath49 such that for @xmath17-almost every @xmath24 , the following hold .    1 .",
    "@xmath50 , 2 .",
    "@xmath38 , 3 .",
    "@xmath51 4 .",
    "for all @xmath39 , one has @xmath40    the range of applications of the met to the analysis of dynamical systems is vast .",
    "below , we mention just of few of the settings in which the met is used .",
    "[ eg1.2 ]    1 .",
    "* differentiable dynamics : * one of the first applications of the met was to differentiable dynamical systems @xmath15 on smooth @xmath33-dimensional compact manifolds .",
    "the matrix function @xmath3 is the spatial derivative of @xmath16 , denoted @xmath52 .",
    "the space @xmath29 is associated with the tangent space of @xmath12 and the equivariance condition becomes @xmath53 . if @xmath16 is uniformly hyperbolic , @xmath54 , the unstable subspace at @xmath24 and @xmath55 , the stable subspace at @xmath36 .",
    "the spaces @xmath56 provide a refinement of @xmath57 and @xmath58 into subspaces with different growth rates .",
    "* hard disk system : * consider a fixed number @xmath59 of hard disks in a region @xmath60 moving freely between collisions . in each collision a pair of disks change their velocities @xcite",
    ". the region may be finite ( hard walls ) or periodic ( toroidal ) in either coordinate direction .",
    "the quasi - one - dimensional system studied here is a two - dimensional system with @xmath61 less than twice the particle diameter so that the disks remain ordered in the @xmath36 direction . here",
    "@xmath62\\times [ 0,l_y])^n \\times { \\mathbb{r}}^{2n}$ ] ( with the appropriate equivalence classes depending on the choice of hard wall or toroidal boundary conditions ) is the collection of @xmath63-tuples containing all the coordinates and momenta of the @xmath59 particles .",
    "+ the map @xmath64 is the composition of a free - flow map @xmath65 and a collision map @xmath66 .",
    "the free - flow map moves the disks in straight lines according to their momentum while none of the disks are colliding .",
    "the time between collisions is the free - flow time @xmath67 which depends on the initial condition @xmath24 .",
    "collisions occur when the boundary of two disks ( or one disk and a wall ) touch , and the collision map exchanges velocities along the direction of collision ( since all disks are of equal mass ) .",
    "again , the matrix function @xmath3 is the spatial derivative of @xmath16 , so that @xmath68 .",
    "precise details may be found in @xcite .",
    "* pde : * the kuramoto - sivashinski equation is a model for weakly turbulent fluids and flame fronts @xmath69 where @xmath70 is a damping coefficient .",
    "another familiar example is the complex ginzburg - landau equation @xmath71 where @xmath72 is complex and @xmath73 and @xmath74 are parameters . in both of these cases it is possible to approximate solutions of the partial differential equations using fourier spectral methods ( see @xcite for details ) .",
    "for instance , in the case of the 1-dimensional kuramoto - sivashinski pde we look for solutions of the form @xmath75 where @xmath76 is a unitless length parameter , then solve the following system of odes for the fourier coefficients @xmath77 : @xmath78 where @xmath79 . since the @xmath80 decrease rapidly with @xmath81 , truncating the above system of odes is justified .",
    "+ in the setting of this review we treat @xmath12 as the space of fourier coefficients @xmath82 of the truncated pde , and consider the transformation @xmath83 defined by choosing some @xmath84 and letting @xmath85 where the @xmath77 are solutions to the system of odes with initial conditions @xmath86 .",
    "the matrix function @xmath3 is again the spatial derivative of @xmath16 so that @xmath87 4 .   * nonautonomous odes and transfer operators : * consider an autonomous ode @xmath4 on @xmath12 ( for example , the lorenz flow on @xmath88 ) , and its flow map @xmath89 which flows the points @xmath36 forward @xmath90 time units .",
    "we think of the coordinates @xmath36 as a `` generalised time '' and the ode @xmath4 is our base system .",
    "we use this base ode ( the driving system ) to construct a nonautonomous ode or skew product ode as @xmath91 . given an initial time @xmath10 and a flow time @xmath90 , one may construct finite - rank approximations @xmath92 of the perron - frobenius operator @xmath93 that track the evolution of densities from base `` time '' @xmath94 to @xmath95 ; see @xcite for details .",
    "the matrices @xmath92 form a cocycle and oseledets subspace computations enable the extraction of _ coherent sets _ in the nonautonomous flow ( see @xcite ) .",
    "coherent sets are time - dependent analogues of almost - invariant sets for autonomous systems ; see @xcite .",
    "finite - time constructions for coherent sets are described in @xcite . in the setting of this review , @xmath83",
    "is defined as @xmath96 , and @xmath97 .",
    "from now on , we denote @xmath98 as @xmath99 .",
    "the proof of the classical met @xcite proves that the matrix limit @xmath100 exists for @xmath17-almost all @xmath24 .",
    "the matrix @xmath101 is symmetric , depends measurably on @xmath36 , and its eigenvalues are @xmath102 .",
    "the corresponding eigenspaces are denoted @xmath103 and one has @xmath104 thus @xmath105 captures growth rates from @xmath106 down to @xmath107 ; the `` @xmath108''decomposition of @xmath105 is orthogonal , while the `` @xmath109 '' decomposition ( the oseledets splitting ) is equivariant ( or covariant ) .",
    "an alternative notion of stability for non - autonomous systems is the so called sacker - sell spectrum , cf .",
    "it is based on exponential dichotomies , cf .",
    "@xcite which we briefly introduce for linear difference equations of the form    @xmath110    in the current context we associate the sequence of matrices @xmath111 with an invertible matrix cocycle over a single orbit , e.g. for some @xmath24 let @xmath112 .",
    "we restrict the introduction of exponential dichotomies to invertible systems only , and note that a justification of our algorithm for computing dichotomy projectors strongly depends on this assumption .",
    "theory defining exponential dichotomies for non - invertible matrices is contained in eg .",
    "numerical experiments indicate that algorithms [ alg : dichproj1 ] and [ a2 ] also apply in the non - invertible case , however , the corresponding analysis is a topic of future research .",
    "we denote by @xmath113 the solution operator of , defined as @xmath114    [ b14 ] the linear difference equation has an * exponential dichotomy * with data @xmath115 on @xmath116 , if there exist two families of projectors @xmath117 and @xmath118 and constants @xmath119 , such that the following statements hold : @xmath120 @xmath121    consider the scaled equation @xmath122    the * sacker - sell * or * dichotomy spectrum * is defined as @xmath123 the complementary set @xmath124 is called the * resolvent set*.    the sacker - sell spectrum consists of at most @xmath33 disjoint , closed intervals , where @xmath33 denotes the dimension of the space , cf .",
    "@xcite , i.e.  there exists an @xmath125 such that @xmath126},\\quad \\text{where } { \\lambda_{i+1}^+ < \\lambda_i^-}\\quad \\text{for } i=1,\\dots,\\ell-1.\\ ] ] it is well known that the lyapunov spectrum , when it exists , is a subset of the sacker - sell spectrum , see @xcite .",
    "while the lyapunov spectrum provides information on bounded solutions of @xmath127 , @xmath128 , the sacker - sell spectrum answers this question for @xmath129 , @xmath130 .",
    "these answers may be different for different initial @xmath131 because , in contrast to the met setting , there is no _ a priori _ stationarity assumption on a base dynamical system generating the matrix cocycle .",
    "note that for @xmath132 it follows from ( * ? ? ?",
    "* lemma 2.7 ) that the inhomogeneous equation @xmath133 has for every bounded sequence @xmath134 a unique bounded solution on @xmath135 .",
    "dichotomy projectors of the scaled equation are constant in resolvent intervals @xmath136 , @xmath137 , where @xmath138 and @xmath139 , see figure [ figd2 ] .",
    "we denote these families of projectors by @xmath140 .",
    "( 1,0.37229437 ) ( 0,0),title=\"fig : \" ] ( 0.51873885,0.32877866)(0,0)[lb ] ( 0.20157354,0.1232276)(0,0)[lb ] ( 0.76866788,0.12203145)(0,0)[lb ] ( 0.11219926,0.01735393)(0,0)[lb ] ( 0.36057863,0.0182228)(0,0)[lb ] ( 0.66670524,0.01919838)(0,0)[lb ] ( 0.91099351,0.0208945)(0,0)[lb ]    in analogy to the met we obtain the family of subspaces @xmath141 that decompose @xmath142 for each @xmath143 @xmath144 and using the cocycle property it follows for all @xmath145 that @xmath146 furthermore , for each @xmath147 , there exists a constant @xmath148 such that the following equations hold @xmath149    when working with data over a finite time interval , one has access only to a finite sequence @xmath150 . in this case , one either assumes there is an underlying ergodic process generating the sequence @xmath150 or one considers exponential dichotomies .",
    "an outline of the paper is as follows . in sections 2 and 3 ,",
    "we introduce two new methods for computing oseledets vectors .",
    "the first method is based on the proof of the generalised met in @xcite and is particularly simple to implement and fast to execute .",
    "the second method is an adaptation of an approach to compute dichotomy projectors @xcite . in section 4",
    "we review the approaches by ginelli _",
    "et al _ @xcite and wolfe and samelson @xcite . in sections 2 , 3 , and 4 we provide matlab code snippets to implement the algorithms presented .",
    "section 5 contains numerical comparisons of the performance of the four methods on three dynamical systems .",
    "the first case study is a dynamical systems formed via composition of a sequence of @xmath151 matrices constructed so that all oseledets vectors are known at time 0 ; we thus compare the accuracy of the methods _ exactly _ in this case study .",
    "the second case study is an eight - dimensional system generated by two hard disks in a quasi - one - dimensional box .",
    "the third case study is a nonlinear model of time - dependent fluid flow in a cylinder ; the matrices are generated by finite - rank approximations of the corresponding time - dependent transfer operators .",
    "the three case studies have been chosen to represent a cross - section of a variety of features of systems that either help or hinder the computation of oseledets vectors , and we draw out the advantages and disadvantages of each of the four methods considered .",
    "the approach outlined in this section is simple to execute and exhibits quick convergence . however , as the length of the sample orbit becomes too large this approach fails .    in (",
    "* proof of theorem 4.1 ) it is proven that the limit @xmath152 exists and is equal to the @xmath153th oseledets subspace @xmath56 .",
    "that is , if one computes @xmath154 in the far past and pushes forward to the present , the result is a subspace close to @xmath56 .",
    "thus , the strategy in @xcite is to first estimate @xmath154 in the past and push forward .",
    "the numerical method of approximating @xmath155 , @xmath24 , is implemented in the following steps :    [ alg : svd ]    1 .",
    "[ item : svd_step_1]choose @xmath156 and form the matrix @xmath157 as an approximation of at @xmath158 .",
    "[ item : svd_step_2]compute @xmath159 , the @xmath160th orthonormal eigenspace of @xmath161 as an approximation of @xmath162 .",
    "[ item : svd_step_3]define @xmath163 , approximating the oseledets subspace @xmath155 .",
    "listing [ lst : svd_code ] shows part of a matlab implementation of algorithm [ alg : svd ] . the array _ `",
    "a`_@xmath164 $ ] contains the @xmath2 matrices which generate the cocycle @xmath165 , and the matrix _ `",
    "psi ` _ is formed by multiplying the matrices contained in _ ` a`_. step [ item : svd_step_1 ] of algorithm [ alg : svd ] is performed prior to the code in listing [ lst : svd_code ] , step [ item : svd_step_2 ] is performed in lines 1 - 3 and lines 4 - 7 perform step [ item : svd_step_3 ] .",
    "the function returns _ `",
    "wj ` _ as its estimate to @xmath155 .    ....",
    "= svd(psi ) ; [ ~,p ] = sort(diag(s),'descend ' ) ; wj = v(:,p(j))/norm(v(:,p(j ) ) ) ; for h = 1:n    wj = a(:,(h-1)*dim+1:h*dim)*wj ;    wj = wj / norm(wj ) ; end     ....    the values of @xmath166 and @xmath59 can be chosen with relative freedom and in our examples that follow we have chosen @xmath167 to compute over a time window centred on @xmath36 , from @xmath168 to @xmath169 .",
    "unfortunately , we can not choose @xmath166 and @xmath59 arbitrarily large and expect accurate results . if @xmath170 is constructed via the product @xmath171 then with larger @xmath166 the numerical inaccuracies of matrix multiplication compound and this product",
    "becomes more singular and thus a poorer approximation of @xmath170 .",
    "because of this , @xmath161 can not be expected to accurately approximate @xmath172 for large @xmath166 . however , even if we suppose @xmath161 accurately approximates @xmath172 , the small , but non - zero , difference in @xmath173 and @xmath162 grows roughly as @xmath174 during the push - forward in step [ item : svd_step_3 ] above .",
    "for these reasons @xmath166 and @xmath59 must be chosen carefully .",
    "we present a simple improvement that can overcome one of the sources of numerical instability , namely the push - forward process in step [ item : svd_step_3 ] above .",
    "( 1,0.34774953 ) ( 0,0 ) .",
    "the black line represents the orbit centred at @xmath24 and the points @xmath175 are those points at which we ensure orthogonality with the subspaces @xmath176 .",
    "to do this we use the ( blue ) approximations @xmath177 to approximate @xmath176 and perform the ( red ) push - forward and orthoganlisation steps starting with @xmath178 and ending with @xmath179 ( see algorithm [ alg : svd2]).,title=\"fig : \" ] ( 0.45110571,0.23849567)(0,0)[lb ] ( 0.2231491,0.23740918)(0,0)[lb ] ( 0.14882441,0.23941571)(0,0)[lb ] ( 0.02371107,0.2390941)(0,0)[lb ] ( 0.84400866,0.23795163)(0,0)[lb ] ( 0.36083317,0.2371375)(0,0)[lb ] ( 0.40308832,0.04609009)(0,0)[lb ] ( 0.6467707,0.18438988)(0,0)[lb ] ( 0.43269017,0.09558435)(0,0)[lb ] ( 0.21624146,0.01412008)(0,0)[lb ] ( 0.61312334,0.14452571)(0,0)[lb ] ( -0.01157433,0.30611268)(0,0)[lb ] ( 0.19208461,0.30755113)(0,0)[lb ] ( 0.14520504,0.30610226)(0,0)[lb ] ( 0.43463711,0.30739317)(0,0)[lb ] ( 0.39039169,0.3059177)(0,0)[lb ]    recall that the subspace @xmath180 is @xmath3-invariant and that for @xmath181 ( with @xmath182 ) we have @xmath183    the subspace @xmath184 contains @xmath185 , and so the oseledets subspace @xmath155 is necessarily perpendicular to all @xmath186 . to solve the numerical instability of step [ item : svd_step_3 ]",
    "we enforce this condition periodically .",
    "the amended algorithm is implemented as follows :    [ alg : svd2 ]    1 .",
    "[ item : svd2_s1]choose @xmath187 and form the matrices @xmath188 2 .",
    "[ item : svd2_s2]compute all the orthonormal eigenspaces @xmath189 , @xmath190 of ( [ psim ] ) ( replacing @xmath59 with @xmath191 in ( [ psim ] ) ) and the eigenspace @xmath192 .",
    "[ item : svd2_s3]let @xmath193 be the orthogonal projection onto the subspace @xmath194 so that @xmath195 and @xmath196 .",
    "define @xmath197 , and then define iteratively by pushing forward and taking orthogonal projections : @xmath198 4 .",
    "@xmath199 is our approximation of @xmath155 .",
    "listing [ lst : svd2 ] shows an example implementation of algorithm [ alg : svd2 ] in matlab .",
    "lines 1 - 18 are responsible for performing steps [ item : svd2_s1 ] and [ item : svd2_s2 ] , whilst the push forward procedure of step [ item : svd2_s3 ] is performed in lines 20 - 30 .",
    "again , the matrix cocycle is stored in _ ` a`_@xmath200 $ ] and the function returns _ ` wj ` _ as its approximation of @xmath155 .",
    "the variable _ ` nk ` _ is a one - dimensional array containing the elements of @xmath201 and is counted by _ ` k`_.    .... k=0 ; for n = nk ,    psi = eye(dim ) ;    for i=0:m-1 ,      psi = a(:,(n + i - 1)*dim + 1:(n + i)*dim)*psi ;      psi = psi / normest(psi ) ;    end    [ ~,s , u ] = svd(psi ) ;    [ ~,p ] = sort(diag(s),'descend ' ) ;    if n==1 ,      wj = u(:,p(j))/norm(u(:,p(j ) ) ) ;    else      for i = 1:j-1 ,        k = k+1 ;        u(:,i , k ) = u(:,p(i))/norm(u(:,p(i ) ) ) ;      end    end end k=0 ; for n = 1:n ,    wj = a(:,(n-1)*dim+1:n*dim)*wj ;    wj = wj / norm(wj ) ;    if any(nk = = n+1 ) ,      k = k+1 ;      for i = 1:j-1 ,        wj = wj - dot(wj , u(:,i , k))*u(:,i , k ) ;        wj = wj / norm(wj ) ;      end    end end     ....    [ svdbad ] unfortunately , some numerical issues with this approach remain .",
    "they stem primarily from the long multiplication involved in building the variable _ `",
    "psi ` _ of listings [ lst : svd_code ] and [ lst : svd2 ] .",
    "this results in _ ` psi ` _ becoming too singular and hence @xmath202 ( @xmath203 ) poorly approximates @xmath204 . as can be seen in section [ sec : numerical ] , algorithm [ alg : svd2 ] works superbly for @xmath205 as @xmath206 is well approximated for large @xmath131 . however when estimating @xmath155 , @xmath207 , a good estimate of @xmath208 is required for an accurate projection @xmath209 and for large @xmath131 such an estimate becomes unreliable .",
    "we derive an approach for the computation of a vector @xmath210 . for this task ,",
    "we first need a guess of @xmath211 and of @xmath212 in two neighbouring resolvent intervals that lie close to the common spectral interval , see figure [ figd1 ] .",
    "( 1,0.41624365 ) ( 0,0 ) in case @xmath213.[figd1],title=\"fig : \" ] ( 0.55189557,0.36020153)(0,0)[lb ] ( 0.65799593,0.35946376)(0,0)[lb ] ( 0.51889174,0.01511336)(0,0)[lb ]",
    "( 0.72040306,0.01763223)(0,0)[lb ] ( 0.8488665,0.2443325)(0,0)[lb ]    numerical experiments indicate that we get the best results by choosing @xmath214 and @xmath215 close to ( but outside ) the second sacker - sell interval .",
    "this conclusion is supported by theoretical estimates on the approximation error for algorithm [ a2 ] , discussed at the end of section 3 .",
    "the following observation from @xcite allows the computation of dichotomy projectors by solving @xmath216 with green s function , cf .",
    "@xcite , the unique bounded solution @xmath217 of has the explicit form @xmath218 and consequently @xmath219 numerically , we approximate the unique bounded solution on @xmath135 by the least squares solution of on a sufficiently long interval . for an error analysis of this approximation process , we refer to ( * ? ? ?",
    "* theorem 4 ) .",
    "the algorithms that we propose in this section compute a vector @xmath220 in analogy to @xmath155 in the previous sections . for simplicity ,",
    "we restrict the representation to the case @xmath221 and assume that @xmath222 and @xmath223 are one - dimensional subspaces .    in the absence of information about the dichotomy intervals ,",
    "one may proceed as follows .",
    "given a finite sequence of matrices , one can estimate a point in the spectral interval @xmath224 } , q=1,2,3 $ ] by computing the ( logarithmic ) growth rates of one- , two- , and three - dimensional subspaces using direct multiplication ; these growth rates should approximate @xmath225 and @xmath226 , respectively . by taking differences to obtain estimates @xmath227 , ( the caret indicating estimated quantities ) one should obtain values in the interior of @xmath224 } , q=1,2,3 $ ] .",
    "we then estimate @xmath228 and @xmath229 .    in the first step of our first algorithm",
    ", we compute a basis of the two - dimensional space @xmath230 .",
    "then , in the second step , we search for the direction @xmath231 in this subspace that additionally lies in @xmath232 and assure in this way that @xmath233 .    1 .",
    "suppose @xmath234 and consider @xmath235\\cap{\\mathbb{z}}$ ] .",
    "let @xmath112 .",
    "+ solve the least squares problem @xmath236 where the @xmath237 are chosen at random and @xmath238 is the @xmath239-norm .",
    "define @xmath240 , @xmath241 .",
    "2 .   solve for @xmath242}$ ] and @xmath243 the least squares problem @xmath244 then @xmath245 is our approximation of @xmath246 .",
    "the unique bounded solutions on @xmath135 of these two steps satisfy @xmath247 and these vectors are generically linear independent .",
    "furthermore @xmath248 due to and @xmath249 due to .",
    "thus @xmath250 .",
    "note that has the form    @xmath251 where @xmath252 and the @xmath131th entry of @xmath253 is the vector @xmath254 for @xmath255 .",
    "the least squares solution can be obtained , using the moore - penrose inverse : @xmath256 cf .",
    "numerically , we find @xmath257 by solving the linear system @xmath258 ; then @xmath259 .",
    ".... % step 1 b = zeros(2*n*dim,2*(n+1)*dim ) ; for i = 1:2*n    b(dim*(i-1)+1:dim*i , dim*(i-1)+1:dim*i )      = -exp(-lambda_left)*a(:,dim*(i-1)+1:dim*i ) ;    b(dim*(i-1)+1:dim*i , dim*(i)+1:dim*(i+1 ) )      = eye(dim ) ; end r = zeros(2*dim*n,2 ) ; r(dim*(n-1)+1:dim*n , : ) = rand(dim,2 ) ; y = ( b*b')\\r ; u = b'*y ; p1 = a(:,dim*(n-1)+1:dim*n)*u(dim*(n-1)+1:dim*n,1 ) ; p2 = a(:,dim*(n-1)+1:dim*n)*u(dim*(n-1)+1:dim*n,2 ) ; p1 = v1/norm(v1 ) ; v2 = v2/norm(v2 ) ; % step 2 b = zeros(dim*(n+1),dim*(n+1)+1 ) ; for i = 0:n-1    b(dim*i+1:dim*(i+1),dim*i+1:dim*(i+1 ) )      = -exp(-lambda_right)*a(:,dim*(i+n)+1:dim*(i+n+1 ) ) ;    b(dim*i+1:dim*(i+1),dim*(i+1)+1:dim*(i+2 ) )      = eye(dim ) ; end b(dim*n+1:dim*(n+1),1:dim ) = eye(dim ) ; b(dim*n+1:dim*(n+1),dim*(n+1)+1 ) = p1 ; r = zeros(dim*(n+1),1 ) ; r(dim*n+1:dim*(n+1),1 ) = -p2 ; y = ( b*b')\\r ; u = b'*y ; w2 = u(dim*n+1:dim*(n+1))/norm(u(dim*n+1:dim*(n+1 ) ) ) ;     ....    note that in the unlikely case where @xmath260 , algorithm [ alg : dichproj1 ] fails .",
    "an alternative approach for computing vectors in @xmath261 that avoids this problem is introduced in algorithm [ a2 ] .",
    "the main idea of this algorithm is to take a random vector @xmath262 , project it first to @xmath230 and then eliminate components in the wrong subspaces , by projecting with @xmath263 .    1 .   again , suppose @xmath264 and consider @xmath235\\cap{\\mathbb{z}}$ ] and let @xmath112 as above .",
    "solve the least squares problem @xmath265 where @xmath262 is chosen at random , and define @xmath266 .",
    "2 .   solve the least squares problem @xmath267 then @xmath268 is our approximation of @xmath246 .",
    "the solution @xmath269 on @xmath135 of these two steps satisfies @xmath270 .    ....",
    "b = zeros(2*n*dim,2*(n+1)*dim ) ; for i = 1:2*n    b(dim*(i-1)+1:dim*i , dim*(i-1)+1:dim*i )      = -exp(-lambda_right)*a(:,dim*(i-1)+1:dim*i ) ;    b(dim*(i-1)+1:dim*i , dim*i+1:dim*(i+1 ) ) = eye(dim ) ; end r = zeros(2*dim*n,1 ) ; r(dim*(n-1)+1:dim*n , : ) = p1 ; y = ( b*b')\\r ; u = b'*y ; w2 = u(dim*n+1:dim*(n+1))/norm(u(dim*n+1:dim*(n+1 ) ) ) ;     ....      we give an error estimate for the solution of algorithm [ a2 ] for a finite choice of @xmath59 .",
    "details on deriving this estimate are postponed to a forthcoming publication .    for @xmath271 and @xmath272 close to the boundary of the second sacker - sell spectral interval",
    ", we denote the dichotomy rates of @xmath273 by @xmath274 and @xmath275 , respectively .",
    "let @xmath269 be the solution of algorithm [ a2 ] on @xmath135 and let @xmath245 be its approximation for a finite choice of @xmath59 .",
    "careful estimates show that the approximation error in the ",
    "wrong subspace \" @xmath276 , with @xmath277 is given as @xmath278 where the constant @xmath279 does not depend on @xmath59 .",
    "the exponential dichotomy rates @xmath280 and @xmath281 of the difference equations depend on the choice of @xmath215 and @xmath214 in the following way : for @xmath215 in the resolvent set @xmath282 $ ] the difference equation @xmath283 has an exponential dichotomy with stable dichotomy rate @xmath280 for all @xmath280 with @xmath284 similarly , for @xmath214 in the resolvent set @xmath285 $ ] the difference equation @xmath286 has an exponential dichotomy with unstable dichotomy rate @xmath281 for all @xmath281 with @xmath287 note that both of the above inequalities are strict .",
    "inspecting equation , we get the best ( smallest ) maximal error if we choose @xmath288 and @xmath289 so as to maximise @xmath280 and @xmath281 .",
    "consequently , we get the best numerical approximations , if @xmath271 and @xmath272 are chosen close to , but not equal to , the boundary of the common spectral interval @xmath290}$ ] .",
    "the ginelli scheme was first presented by ginelli _ et al .  _ in @xcite as a method for accurately computing the covariant lyapunov vectors of an orbit of an invertible differentiable dynamical system where the @xmath291 are the jacobian matrices of the flow or map .",
    "estimates of the @xmath155 are found by constructing equivariant subspaces @xmath292 and filtering the invariant directions contained therein using a power method on the inverse system restricted to the subspaces @xmath293 .    to construct the subspaces @xmath293",
    "we utilise the notion of the stationary lyapunov basis @xcite",
    ". choose @xmath160 orthonormal vectors @xmath294 , @xmath295 , such that @xmath296 for @xmath297 and construct @xmath298 using the gram - schmidt procedure , construct the orthonormal basis @xmath299 from @xmath300 , that is , @xmath301 then as @xmath302 the basis @xmath303 converges to a set of orthonormal vectors @xmath304 which span the @xmath160 fastest expanding directions of the cocycle @xmath3 @xcite , that is , if the multiplicities @xmath305 @xmath306 if the oseledets subspaces are not all one - dimensional , that is the lyapunov spectrum is degenerate , then we choose @xmath293 only for those @xmath160 which are the sum of the first @xmath81 multiplicities , i.e. , @xmath307 .",
    "then @xmath308 in the interest of readability we assume the oseledets subspaces are one - dimensional but note that the approach may be extended to the multi - dimensional case .    note that the @xmath293 are equivariant by construction : @xmath309 provided @xmath310 if @xmath311 .",
    "we describe the ginelli approach to finding @xmath205 .",
    "suppose @xmath312 and @xmath313 and that the basis @xmath314 is known at @xmath24 .",
    "note first that @xmath315 .",
    "let @xmath316 denote the coefficients of @xmath317 in the basis @xmath318 ( recall that the orthogonal projection of @xmath319 onto @xmath320 is zero for @xmath321 )    then @xmath322    [ lem : qr_slb ] let @xmath323 denote the @xmath324 matrix whose @xmath153th column is @xmath320 .",
    "then for each @xmath325 there exists an upper triangular , @xmath326 matrix @xmath327 satisfying @xmath328    note that @xmath329 where @xmath330 and @xmath331 using the equivariance of @xmath332 and @xmath333 .",
    "thus , the qr - decomposition of lemma [ lem : qr_slb ] is equivalent to the gram - schmidt orthonormalisation that defines the stationary lyapunov bases .",
    "the columns of @xmath334 form the stationary lyapunov basis at @xmath335 .",
    "we have chosen the above notation @xmath327 specifically since , defined in this way , @xmath336 forms a cocycle which is the restriction of @xmath3 to the invariant subspaces @xmath337 .    the matrix @xmath327 defined above forms a cocycle over @xmath16 .",
    "let @xmath338 then @xmath339 by lemma [ lem : qr_slb ] .",
    "since @xmath340 , @xmath341 equating and gives @xmath342 as @xmath343 is left - invertible .    since @xmath344 is the vector of coefficients of the second oseledets vector of the cocycle @xmath3 , it is the second oseledets vector of the cocycle @xmath336 . to see this ,",
    "recall @xmath345 so that @xmath346 which , due to , becomes @xmath347 since the columns of @xmath334 are orthonormal .",
    "we may approximate @xmath344 numerically using a simple power method on the inverse cocycle @xmath348 ( which exists since @xmath313 ) .",
    "the ginelli method can be summarised by the following steps :    1 .",
    "choose @xmath24 and @xmath349 and form @xmath350 by first randomly selecting two orthonormal vectors @xmath351 then performing the push - forward / gram - schmidt procedure given by .",
    "that is , define @xmath352 followed by setting @xmath353 where @xmath354 .",
    "the vectors @xmath350 form an approximation to the stationary lyapunov basis @xmath314 .",
    "[ item : ginelli_step_2]choose @xmath355 and using the approximate basis @xmath350 in , form an approximation to @xmath356 , denoted by @xmath357 .",
    "3 .   choose @xmath358 either at random , or by some guess at the second oseledets vector of @xmath336 at @xmath359 , in this review we found @xmath360 to work well .",
    "use the inverse iteration method to approximate @xmath344 , that is , define our approximation to @xmath344 as @xmath361 4 .",
    "then @xmath362 is our approximation to @xmath317 .    as before",
    ", there is some freedom of choice of both @xmath166 and @xmath59 as well as of the initial orthonormal basis @xmath351 , used to approximate @xmath363 , and of the 2-tuple @xmath364 .",
    "the larger @xmath166 and @xmath59 are chosen , the more accurate @xmath365 will be , provided @xmath366 and @xmath367 where @xmath368 is the oseledets subspace of @xmath336 with lyapunov exponent @xmath369 .    ....",
    "= qr(rand(dim , j),0);c = [ zeros(1,j-1 ) 1 ] ; for i = 1:n ,    qnew = a(:,(i-1)*dim+1:i*dim)*q ;    [ q,~ ] = qr(qnew,0 ) ; end q0 = q ; for i = n+1:2*n+1 ,    qnew = a(:,(i-1)*dim + 1 : i*dim)*q ;    [ q , r ] = qr(qnew,0 ) ;    allr = horzcat(r , allr ) ; end numofr = size(allr,2)/j ; for i = 1:numofr    r = allr(:,(i-1)*j+1:i*j ) ;    cnew = r\\c ;    c = cnew / norm(cnew ) ; end w = q0*c ;     ....    listing [ lst : ginelli ] shows an example implementation of algorithm [ alg : ginelli ] in matlab which approximates @xmath370 using @xmath371 and @xmath372 are chosen at random and @xmath373 .",
    "lines 2 through 6 construct the approximation of the stationary lyapunov basis , @xmath374 which is stored as columns of the matrix @xmath323 represented as the variable _ `",
    "q0 ` _ , while lines 7 through 11 construct the cocycle @xmath336 stored in _ `",
    "allr ` _ as @xmath375 $ ] .",
    "lines 12 through 17 perform a simple power method on @xmath376 to find the coefficient vector @xmath377 , which represents the approximation of @xmath378 in the basis @xmath374 .",
    "thus , the approximation is given by @xmath379 .",
    "although algorithm [ alg : ginelli ] is specific to the case where @xmath221 , listing [ lst : ginelli ] is applicable to any @xmath160 for which @xmath376 exists .    it can be shown that , in this case where the top lyapunov exponent has multiplicity 1 , @xmath380 .",
    "if the first lyapunov exponent has multiplicity 1 , the dominant oseledets subspace of the cocycle @xmath336 is @xmath380 .",
    "recall that @xmath381 since @xmath382 ( from ) and for all @xmath383 @xmath384 we may write @xmath385 for some @xmath386 then @xmath387 and since @xmath388 ( the columns of @xmath389 are orthonormal ) @xmath390 since @xmath391 is @xmath3-invariant , @xmath392 is @xmath336-invariant and the proof is complete .      in the case where convergence is nt satisfactory because the amount of cocycle data available is too small ( for any @xmath166 and @xmath59 to be small ) , the approximations from algorithm [ alg : ginelli ] can be improved by using better guesses at @xmath393 and @xmath364 .    note that @xmath394 and @xmath395 are two orthonormal vectors optimised for maximal growth over the time interval @xmath396\\cap{\\mathbb{z}}$ ] .",
    "in the situation where the values of @xmath166 and @xmath59 are limited , one can choose those two vectors that are optimised for growth over the shorter time interval @xmath397\\cap{\\mathbb{z}}$ ] . in @xcite this is achieved by computing the left singular vectors of @xmath398 .",
    "this approach works well for small @xmath166 but can become inaccurate for very large @xmath166 for the reasons in remark [ svdbad ] .    in practice , we have observed that a combination of step 1 in algorithm [ alg : ginelli ] and the above provides the most robust method of accurately approximating @xmath394 and @xmath395 . as an alternative to algorithm [ alg : ginelli ] the following may be used : for @xmath399 , compute vectors optimised for growth from @xmath400 to @xmath401 , then push - forward these vectors from @xmath402 to @xmath403 .",
    "[ alg : ginalt ]    1 .",
    "choose @xmath24 and @xmath404 .",
    "compute the two left singular vectors of @xmath405 corresponding to the two largest singular values and call them @xmath406 and @xmath407 .",
    "now define @xmath408 as an approximation to @xmath409 by the gram - schmidt orthonormalisation of @xmath410 and @xmath411 as in .",
    "steps 24 as in algorithm [ alg : ginelli ] .    in practice , one should choose @xmath412 large enough so that enough data is sampled , but not so large that @xmath405 is too singular .",
    "the approach followed by wolfe _",
    "et al .  _",
    "@xcite directly computes the subspace splitting as the intersection of two sets of invariant subspaces .",
    "the description of the numerical construction of the subspaces @xmath293 featured below differs slightly from @xcite , however , the essential features of the approach are retained .",
    "in fact , the constructions featured here improve upon those in @xcite in terms of accuracy versus amount of cocycle data used  in the notation of algorithm [ alg : wolfe ] below , if @xmath413 is made larger , @xmath414 is more accurate , which is not the case in @xcite for the same reasons discussed in remark [ svdbad ] .    recall the eigenspace decomposition @xmath415 of the limiting matrix @xmath101 presented in section [ sec : svd ] and define @xmath416 . recall that @xmath417 .",
    "also recall from the previous section that @xmath418 .",
    "thus @xmath419    again , in the interest of readability we assume the oseledets subspaces @xmath155 , and the eigenspaces @xmath415 , are one - dimensional .",
    "as in the case of the previous section , the ideas here may be extended to the case in which the oseledets subspaces are not one - dimensional .",
    "let @xmath420 be the singular vector spanning @xmath415 and let @xmath421 be the @xmath160th element of the stationary lyapunov basis as in the previous section",
    ". then note @xmath422 taking inner products with @xmath423 and @xmath424 respectively gives @xmath425 substituting into and rearranging gives @xmath426 note that @xmath427 so @xmath428 then becomes @xmath429 equation may be considered as a @xmath430 homogeneous linear equation by defining a matrix entry - wise as @xmath431 and solving @xmath432 where @xmath433 .",
    "the entries of @xmath434 are then the coefficients of @xmath378 with respect to the basis @xmath435 .",
    "the wolfe approach may be implemented as follows :    1 .   choose @xmath24 and @xmath436 and construct @xmath437 as an approximation of the stationary lyapunov basis vectors @xmath304 using the methods outlined in step 1 of algorithm [ alg : ginalt ] , that is , compute the left singular vectors of @xmath438 corresponding to the @xmath439 largest singular values and call them @xmath440 , @xmath190 .",
    "then form the @xmath441 by the gram - schmidt orthornormalisation of @xmath442 for @xmath190 .",
    "2 .   choose @xmath443 and construct the one - dimensional eigenspaces @xmath444 as approximations to the eigenspaces @xmath445 as in step 1 of algorithm [ alg : svd ] , that is , construct @xmath446 and let @xmath447 be the @xmath153th orthonormal eigenspace of @xmath448 .",
    "define @xmath449 , @xmath450 .",
    "3 .   form the matrix @xmath451 as above : @xmath452 4 .",
    "solve the homogeneous linear equation @xmath453 .",
    "then @xmath454 forms our approximation of @xmath455 .",
    "this approach suffers from the same numerical stability issue of algorithm [ alg : svd2 ] of section [ sec : svd2 ] .",
    "namely , the vector spaces @xmath456 may only poorly approximate @xmath186 for @xmath166 too large ( see the final paragraph of section [ sec : svd2 ] ) .",
    "a recent paper @xcite provides alternative descriptions of both the ginelli _",
    "et al . _ and wolfe and samelson methods , well - suited to those familiar with the qr - decomposition based numerical method for estimating lyapunov exponents due to benettin _",
    "_ @xcite and shimada and nagashima @xcite .",
    "the discussion in @xcite is restricted to invertible cocycles generated by the jacobian matrices of a dynamical system .",
    "although this assumption allows stable numerical methods to be constructed , i.e. , better convergence obtained for larger data sets , it means some important examples in which the matrix cocycle is non - invertible are overlooked , for example the case study of section [ sec : fluidflow ] .",
    "while the memory footprint of the implementations discussed in @xcite is estimated , there is no discussion of convergence rates or accuracy with respect to the amount of cocycle data available . finally , while the examples featured in @xcite explain the methods presented in the context of differentiable dynamical systems the case studies of section [ sec : numerical ] in the present paper focus on comparative performance of the methods presented , via a broad range of possible applications .",
    "we present three detailed case studies , comparing the four approaches for calculating oseledets subspaces .",
    "the first case study is a nontrivial model for which we know the oseledets subspaces exactly and can therefore precisely measure the accuracy of the methods .",
    "the second case study produces a relatively low - dimensional matrix cocycle , while the third case study generates a very high - dimensional matrix cocycle ; in these case studies we use two fundamental properties of oseledets subspaces to assess the accuracy of the four approaches .      in general the oseledets subspaces can not be found analytically which makes the task of determining the efficacy of the above approaches difficult .",
    "however , the exact model described below allows us to compare the numerical approximations with the exact solution by building a cocycle in which the subspaces are known _ a priori_.    we generate a system with simple lyapunov spectrum @xmath457 .",
    "we form a diagonal matrix @xmath458 and generate the cocycle by the sequence of matrices @xmath459 where @xmath460\\cap{\\mathbb{z}}$,}\\\\      i +      \\begin{pmatrix }        0 & & & & \\\\        z_2 & 0 & & \\\\        & \\ddots & \\ddots & \\\\        & & z_d & 0      \\end{pmatrix } ,      & \\text { for $ n=-1$. }    \\end{cases } \\label{eq",
    ": toy_model}\\end{aligned}\\ ] ] the entries of @xmath461 and the numbers @xmath462 are uniformly randomly generated from the interval @xmath463 $ ] . by construction",
    ", the columns of @xmath464 span the oseledets subspaces at time @xmath235\\cap{\\mathbb{z}}$ ] .",
    "we compare the exact result at time @xmath465 with the approximations computed by the various algorithms for @xmath466 , @xmath467 and @xmath468 for varying amounts of cocycle data @xmath469 .",
    "the exact model has a well separated spectrum , is generated using invertible matrices , and is of relatively low dimension .",
    "for this model we use the following choice of parameters to execute the algorithms :    * * algorithm [ alg : svd2 ] : * @xmath371 and @xmath470 where @xmath471 . * *",
    "algorithm [ alg : dichproj1 ] : * we estimate the three largest lyapunov exponents @xmath472 and set @xmath473 and @xmath474 . * * algorithm [ a2 ] : * as for algorithm [ alg : dichproj1 ] . * * algorithm [ alg : ginalt ] : * @xmath371 , @xmath475 , and @xmath476 . * * algorithm [ alg : wolfe ] : * let @xmath477 , @xmath478 and @xmath479 .",
    "( 1,0.66126418 ) ( 0,0)comparing the approximations of the second oseledets subspace @xmath480 with the exact solution @xmath205 which is known _",
    "a priori_. each `` @xmath59-approximation '' is computed using cocycle data @xmath481 .",
    "the comparison is simply the euclidean norm of the separation of the two unit vectors @xmath482 and @xmath246.,title=\"fig : \" ] ( 0.12574263,0.05402464)(0,0)[lb ] ( 0.23203728,0.05402464)(0,0)[lb ] ( 0.33833063,0.05402464)(0,0)[lb ] ( 0.44921718,0.05402464)(0,0)[lb ] ( 0.56010211,0.05402464)(0,0)[lb ] ( 0.67098865,0.05402464)(0,0)[lb ] ( 0.7818752,0.05402464)(0,0)[lb ] ( 0.89276013,0.05402464)(0,0)[lb ] ( 0.08149627,0.06766613)(0,0)[lb ] ( 0.08149627,0.12155592)(0,0)[lb ] ( 0.08149627,0.17531118)(0,0)[lb ] ( 0.08149627,0.22920097)(0,0)[lb ] ( 0.08149627,0.28295462)(0,0)[lb ] ( 0.08149627,0.33670989)(0,0)[lb ] ( 0.08149627,0.39059968)(0,0)[lb ] ( 0.08149627,0.44435494)(0,0)[lb ] ( 0.08149627,0.49824473)(0,0)[lb ] ( 0.08149627,0.55199838)(0,0)[lb ] ( 0.08149627,0.60575365)(0,0)[lb ] ( 0.51404699,0.03471118)(0,0)[lb ] ( 0.05226904,0.23733064 ) ( 0.7701248,0.56766613)(0,0)[lb ] ( 0.7701248,0.53970827)(0,0)[lb ] ( 0.7701248,0.51175041)(0,0)[lb ] ( 0.7701248,0.48365802)(0,0)[lb ] ( 0.7701248,0.45570016)(0,0)[lb ]    figure [ fig : exact_overview ] compares the approximations yielded from the various approaches outlined in sections [ sec : svd ] , [ sec : dich_proj ] and [ sec : gin_wolfe ] with the known solution of equation .",
    "each algorithm exhibits approximately exponential convergence with respect to the length of the sample cocycle up to ( almost ) machine accuracy of about @xmath483 .",
    "algorithm [ alg : ginelli ] is notably erratic whereas the other algorithms converge smoothly , which suggests that in the limited data scenario ( small @xmath59 ) it represents the less satisfactory choice .",
    "algorithm [ alg : svd2 ] is slightly more accurate than the other algorithms for large @xmath59 , while there is a limit to the accuracy of algorithms [ alg : dichproj1 ] and [ a2 ] .",
    "it is worth noting that algorithms [ alg : svd2 ] and [ alg : wolfe ] do not perform as well when approximating oseledets subspaces corresponding to lyapunov exponents @xmath484 . whilst they reach machine accuracy with ease for @xmath485 and @xmath486 , forming @xmath487 via numerical matrix multiplication produces greater inaccuracies for subspaces @xmath488 through @xmath489 ( see remark [ svdbad ] ) . on the other hand , algorithms [ alg : dichproj1 ] , [ a2 ] and [ alg : ginalt ]",
    "do not suffer from the same issue because they do not need to form @xmath99 but use only the generating matrices @xmath490 .",
    "as such , they still reach machine accuracy , although a greater amount of data ( larger @xmath59 ) is required .",
    "( 1,0.66126418 ) ( 0,0)comparing the approximation of the second oseledets vector with the exact solution for the two svd based approaches , demonstrating the numerical instability which is overcome in the adapted svd approach.,title=\"fig : \" ] ( 0.12574263,0.05402464)(0,0)[lb ] ( 0.23203728,0.05402464)(0,0)[lb ] ( 0.33833063,0.05402464)(0,0)[lb ] ( 0.44921718,0.05402464)(0,0)[lb ] ( 0.56010211,0.05402464)(0,0)[lb ] ( 0.67098865,0.05402464)(0,0)[lb ] ( 0.7818752,0.05402464)(0,0)[lb ] ( 0.89276013,0.05402464)(0,0)[lb ] ( 0.06853031,0.06766613)(0,0)[lb ] ( 0.06853031,0.12749887)(0,0)[lb ] ( 0.06853031,0.18733063)(0,0)[lb ] ( 0.06853031,0.24702917)(0,0)[lb ] ( 0.06853031,0.30686062)(0,0)[lb ] ( 0.06853031,0.36669368)(0,0)[lb ] ( 0.06853031,0.4263906)(0,0)[lb ] ( 0.06853031,0.48622366)(0,0)[lb ] ( 0.06853031,0.54605673)(0,0)[lb ] ( 0.06853031,0.60575365)(0,0)[lb ] ( 0.51404699,0.03471118)(0,0)[lb ] ( 0.02910546,0.22678367 ) ( 0.75092681,0.3611035)(0,0)[lb ] ( 0.75113559,0.33449862)(0,0)[lb ]    figure [ fig : exact_comp_svd ] is similar to figure [ fig : exact_overview ] except that it compares only algorithms [ alg : svd ] and [ alg : svd2 ] .",
    "in doing so , it highlights the result of one of the numerical instabilities of algorithm [ alg : svd ] , namely the pushing forward of @xmath159 in step [ item : svd_step_3 ] .",
    "( 1,0.66126418 ) ( 0,0)comparing the execution time @xmath90 of the various algorithms using matlab s timing functionality .",
    "each algorithm is executed using the cocycle data @xmath469.,title=\"fig : \" ] ( 0.12574263,0.05402464)(0,0)[lb ] ( 0.23203728,0.05402464)(0,0)[lb ] ( 0.33833063,0.05402464)(0,0)[lb ] ( 0.44921718,0.05402464)(0,0)[lb ] ( 0.56010211,0.05402464)(0,0)[lb ] ( 0.67098865,0.05402464)(0,0)[lb ] ( 0.7818752,0.05402464)(0,0)[lb ] ( 0.89276013,0.05402464)(0,0)[lb ] ( 0.08743922,0.06766613)(0,0)[lb ] ( 0.08743922,0.17531118)(0,0)[lb ] ( 0.08743922,0.28295462)(0,0)[lb ] ( 0.08743922,0.39059968)(0,0)[lb ] ( 0.08743922,0.49824473)(0,0)[lb ] ( 0.08743922,0.60575365)(0,0)[lb ] ( 0.72893031,0.21636953)(0,0)[lb ] ( 0.72893031,0.1942188)(0,0)[lb ] ( 0.72893031,0.17206969)(0,0)[lb ] ( 0.72893031,0.14978412)(0,0)[lb ] ( 0.72893031,0.12763371)(0,0)[lb ] ( 0.51404699,0.03471118)(0,0)[lb ] ( 0.06080519,0.33068557 )    finally , figure [ fig : toymodel_times ] shows the execution times of algorithms [ alg : svd2 ] , [ alg : dichproj1 ] , [ a2 ] , [ alg : ginalt ] and [ alg : wolfe ] , which were timed using matlab s timing functionality .",
    "the most time - consuming step in algorithm [ alg : ginalt ] is the svd performed as part of the alterations from section [ sec : limited_ginelli ] .",
    "algorithm [ alg : wolfe ] must perform two svds and algorithm [ alg : svd2 ] must perform many more , which accounts for their longer execution times .",
    "we consider the quasi - one - dimensional heat system studied extensively by morriss _",
    "@xcite which consists of two disks of diameter @xmath491 in a rectangular box , @xmath492\\times[0,l_y]$ ] , in which the shorter side , has length @xmath493 so that the disks may not change order .",
    "the two disks interact elastically with each other and the short walls , but periodic boundary conditions are enforced in the @xmath434-direction .",
    "the phase space of the system is then the set @xmath494 @xmath495\\times[0,l_y]\\right ) / \\sim\\right)^2\\times \\mathbb r^2 \\times \\mathbb r^2 \\notag\\end{aligned}\\ ] ] where @xmath496 is the equivalence class associated with periodic boundary conditions , that is , @xmath497\\times[0,l_y]$ ] have @xmath498 if @xmath499 and @xmath500 .    the flow @xmath501 consists of free - flight maps of time @xmath90 , @xmath502 , and collision maps @xmath503 so that @xmath504 where @xmath505 .",
    "we consider a discrete - time version of the system by mapping from the instant after collision to the instant after the next collision , that is @xmath506 where @xmath67 is the free - flight time in the continuous system .",
    "the matrix cocycle is generated by the @xmath151 jacobian matrices or the derivative of the flow evaluated instantly after each collision ( i.e. @xmath507 , see @xcite for details ) . due to a number of dynamic symmetries the system has lyapunov exponents @xmath508 with multiplicities @xmath509 and @xmath510 respectively .",
    "this system has some symmetry , a high variation in expansion rates from iteration to iteration , a well separated spectrum , invertible jacobian matrices , and relatively low dimension .",
    "numerical integration of an orbit consisting of 4646 collisions yielded a sequence of jacobian matrices @xmath511 which generate the cocycle @xmath3 .",
    "for this model we use the same choice of parameters to execute the algorithms as with the previous model :    * * algorithm [ alg : svd2 ] : * @xmath371 and @xmath470 where @xmath471 . * * algorithm [ alg : dichproj1 ] : * we estimate the three largest lyapunov exponents @xmath472 and set @xmath473 and @xmath474 . * * algorithm [ a2 ] : * as for algorithm [ alg : dichproj1 ] . * * algorithm [ alg : ginalt ] : * @xmath371 , @xmath475 , and @xmath476 . * * algorithm [ alg : wolfe ] : * let @xmath477 , @xmath478 and @xmath479 .",
    "since the oseledets subspaces for this model are unknown , we test the approximations for two properties of oseledets subspaces , namely their equivariance and the expansion rate , which defines the corresponding lyapunov exponent .    [ [ equivariance ] ] equivariance : + + + + + + + + + + + + +    to test for equivariance , we approximate the second oseledets vector , @xmath512 , at each time @xmath513 .",
    "we then compute @xmath514 and plot the result , where @xmath515 .",
    "if the approximations are equivariant this value would be zero .",
    "[ [ expansion - rate ] ] expansion rate : + + + + + + + + + + + + + + +    to test the expansion rate , each approach is used to compute the second oseledets vector , @xmath516 , at time @xmath465 and we plot @xmath517 versus @xmath518 .",
    "if @xmath480 is accurate , elements of @xmath480 should grow at the correct rate : @xmath519 .    whilst the oseledets vector @xmath319 must satisfy the above two properties",
    ", we must be careful when examining the results of these numerical experiments .",
    "for instance , ( i ) it is possible to choose vectors that are equivariant despite not being contained in any single oseledets subspace , and ( ii ) any element of @xmath520 ( a much larger set than @xmath205 ) has lyapunov exponent @xmath519 .      figure [ fig : ball_invar ] shows the results of the equivariance test for the quasi - one - dimensional two disk model . at the lower end of cocycle data length ( @xmath521 ) all algorithms except [ a2 ] display reasonable equivariance ,",
    "although algorithm [ alg : dichproj1 ] remains equivariant for only a handful of steps . for @xmath522 and @xmath523",
    "all approaches appear to produce close to equivariant results ( note the changing scales in the vertical direction ) , with algorithms [ alg : dichproj1 ] and [ a2 ] lagging behind when @xmath523 .",
    "( 1,0.719163 ) ( 0,0 ) the equivariance test for the various algorithms on the quasi - one - dimensional two disk model .",
    "each approach is used to approximate the second oseledets vector , @xmath524 using cocycle data @xmath525 , at each time @xmath513 .",
    "we then compute @xmath526 and plot the result .",
    "note the different scales on each vertical axis .",
    "the plots shown are for @xmath521 ( top left ) , @xmath527 ( top right ) and @xmath528 ( bottom).,title=\"fig : \" ] ( 0.79038216,0.25238656)(0,0)[lb ] ( 0.79038216,0.2300848)(0,0)[lb ] ( 0.79038216,0.20778304)(0,0)[lb ] ( 0.79038216,0.18548128)(0,0)[lb ] ( 0.79038216,0.16317952)(0,0)[lb ] ( 0.258076,0.38852754)(0,0)[lb ] ( 0.00446035,0.40991141 ) ( 0.77120044,0.38852754)(0,0)[lb ] ( 0.51428083,0.40424009 ) ( 0.50165198,0.0222467)(0,0)[lb ] ( 0.22821255,0.05816828 ) ( 0.05387313,0.40693833)(0,0)[lb ] ( 0.12187996,0.40693833)(0,0)[lb ] ( 0.18685793,0.40693833)(0,0)[lb ] ( 0.25486454,0.40693833)(0,0)[lb ] ( 0.32287115,0.40693833)(0,0)[lb ] ( 0.39087775,0.40693833)(0,0)[lb ] ( 0.45897577,0.40693833)(0,0)[lb ] ( 0.01903436,0.41620814)(0,0)[lb ] ( 0.01903436,0.45585573)(0,0)[lb ] ( 0.01903436,0.4955033)(0,0)[lb ] ( 0.01903436,0.53515088)(0,0)[lb ] ( 0.01903436,0.57479846)(0,0)[lb ] ( 0.01903436,0.61444604)(0,0)[lb ] ( 0.01903436,0.65409361)(0,0)[lb ] ( 0.01903436,0.69364978)(0,0)[lb ] ( 0.56773128,0.40693833)(0,0)[lb ] ( 0.63546256,0.40693833)(0,0)[lb ] ( 0.70025661,0.40693833)(0,0)[lb ] ( 0.76798789,0.40693833)(0,0)[lb ] ( 0.83581167,0.40693833)(0,0)[lb ] ( 0.90354295,0.40693833)(0,0)[lb ] ( 0.97136564,0.40693833)(0,0)[lb ] ( 0.52885461,0.41620814)(0,0)[lb ] ( 0.52885463,0.45126652)(0,0)[lb ] ( 0.52885463,0.48632599)(0,0)[lb ] ( 0.52885463,0.52138436)(0,0)[lb ] ( 0.52885463,0.55635132)(0,0)[lb ] ( 0.52885463,0.59140969)(0,0)[lb ] ( 0.52885463,0.62646916)(0,0)[lb ] ( 0.52885463,0.66152753)(0,0)[lb ] ( 0.52885463,0.69649449)(0,0)[lb ] ( 0.281663,0.04065727)(0,0)[lb ] ( 0.35490088,0.04065727)(0,0)[lb ] ( 0.42520154,0.04065727)(0,0)[lb ] ( 0.49843943,0.04065727)(0,0)[lb ] ( 0.57176982,0.04065727)(0,0)[lb ] ( 0.64500771,0.04065727)(0,0)[lb ] ( 0.718337,0.04065727)(0,0)[lb ] ( 0.24278632,0.04992643)(0,0)[lb ] ( 0.24278634,0.08516872)(0,0)[lb ] ( 0.24278634,0.12041079)(0,0)[lb ] ( 0.24278634,0.15565308)(0,0)[lb ] ( 0.24278634,0.19089537)(0,0)[lb ] ( 0.24278634,0.22613767)(0,0)[lb ] ( 0.24278634,0.26137996)(0,0)[lb ] ( 0.24278634,0.29662225)(0,0)[lb ] ( 0.24278634,0.33186454)(0,0)[lb ] ( 0.24278634,0.36719934)(0,0)[lb ]    figure [ fig : ball_rates ] shows the results of the expansion rate test for the quasi - one - dimensional two disk model for various amounts of cocycle data @xmath529 . as expected , when there is a limited amount of data available ( @xmath59 small ) the approximations either expand at the higher rate of @xmath369 or only expand at the rate of @xmath519 for a brief time before the error grows too large .",
    "as @xmath59 is increased , the approximations expand at @xmath519 for longer periods , suggesting that they more accurately represent @xmath319 .",
    "( 1,0.719163 ) ( 0,0 ) the expansion rate test for the various approaches on the quasi - one - dimensional two disk model .",
    "the second oseledets vector , @xmath482 , is approximated using cocycle data @xmath530 and we plot @xmath517 versus @xmath518 .",
    "if the approximation is accurate this quantity should tend to the value of @xmath531 , otherwise it would tend to the value of @xmath532 both of which are shown in blue .",
    "the plots shown are for @xmath533 ( top left ) , @xmath521 ( top right ) and @xmath522 ( bottom).,title=\"fig : \" ] ( 0.80497467,0.24798128)(0,0)[lb ] ( 0.80497467,0.22595485)(0,0)[lb ] ( 0.80497467,0.20401982)(0,0)[lb ] ( 0.80497467,0.1820848)(0,0)[lb ] ( 0.80497467,0.16005837)(0,0)[lb ] ( 0.76844714,0.38852754)(0,0)[lb ] ( 0.51925441,0.46002203 ) ( 0.25624121,0.38852754)(0,0)[lb ] ( 0.00172555,0.46057269 ) ( 0.50917732,0.01857577)(0,0)[lb ] ( 0.24722796,0.09823789 ) ( 0.29570485,0.0369859)(0,0)[lb ] ( 0.33526101,0.0369859)(0,0)[lb ] ( 0.37793722,0.0369859)(0,0)[lb ] ( 0.42061344,0.0369859)(0,0)[lb ] ( 0.46328965,0.0369859)(0,0)[lb ] ( 0.50284471,0.0369859)(0,0)[lb ] ( 0.54542952,0.0369859)(0,0)[lb ] ( 0.58810573,0.0369859)(0,0)[lb ] ( 0.63078194,0.0369859)(0,0)[lb ] ( 0.67345815,0.0369859)(0,0)[lb ] ( 0.71613436,0.0369859)(0,0)[lb ] ( 0.26356498,0.04625551)(0,0)[lb ] ( 0.26971366,0.08452643)(0,0)[lb ] ( 0.26356498,0.12279736)(0,0)[lb ] ( 0.26356498,0.16106828)(0,0)[lb ] ( 0.26356498,0.1992478)(0,0)[lb ] ( 0.26356498,0.23751872)(0,0)[lb ] ( 0.26971366,0.27578965)(0,0)[lb ] ( 0.26356498,0.31406057)(0,0)[lb ] ( 0.26356498,0.35223899)(0,0)[lb ] ( 0.05020176,0.40693833)(0,0)[lb ] ( 0.08828943,0.40693833)(0,0)[lb ] ( 0.1294967,0.40693833)(0,0)[lb ] ( 0.17070485,0.40693833)(0,0)[lb ] ( 0.21182048,0.40693833)(0,0)[lb ] ( 0.24990859,0.40693833)(0,0)[lb ] ( 0.29111564,0.40693833)(0,0)[lb ] ( 0.33223238,0.40693833)(0,0)[lb ] ( 0.37343943,0.40693833)(0,0)[lb ] ( 0.41464758,0.40693833)(0,0)[lb ] ( 0.45585573,0.40693833)(0,0)[lb ] ( 0.01806167,0.43080066)(0,0)[lb ] ( 0.01806167,0.45980176)(0,0)[lb ] ( 0.02421057,0.48889537)(0,0)[lb ] ( 0.01806167,0.51798899)(0,0)[lb ] ( 0.01806167,0.54699009)(0,0)[lb ] ( 0.01806167,0.5760837)(0,0)[lb ] ( 0.01806167,0.6050848)(0,0)[lb ] ( 0.02421057,0.63417841)(0,0)[lb ] ( 0.01806167,0.66327093)(0,0)[lb ] ( 0.01806167,0.69227313)(0,0)[lb ] ( 0.56773128,0.40693833)(0,0)[lb ] ( 0.60480947,0.40693833)(0,0)[lb ] ( 0.6449152,0.40693833)(0,0)[lb ] ( 0.68502203,0.40693833)(0,0)[lb ] ( 0.72512885,0.40693833)(0,0)[lb ] ( 0.76211454,0.40693833)(0,0)[lb ] ( 0.80222137,0.40693833)(0,0)[lb ] ( 0.84232709,0.40693833)(0,0)[lb ] ( 0.88243392,0.40693833)(0,0)[lb ] ( 0.92254075,0.40693833)(0,0)[lb ] ( 0.96264758,0.40693833)(0,0)[lb ] ( 0.53559141,0.41620815)(0,0)[lb ] ( 0.54174009,0.45246035)(0,0)[lb ] ( 0.53559141,0.48862004)(0,0)[lb ] ( 0.53559141,0.52487225)(0,0)[lb ] ( 0.53559141,0.56103194)(0,0)[lb ] ( 0.53559141,0.59719163)(0,0)[lb ] ( 0.54174009,0.63344383)(0,0)[lb ] ( 0.53559141,0.66960352)(0,0)[lb ] ( 0.53559141,0.70576432)(0,0)[lb ]    most algorithms perform similarly regarding expansion rate . note that the amount of cocycle data ( size of @xmath59 ) needed to perform well in the expansion rate test is less than that needed to perform well in the equivariance test - this demonstrates the importance of good performance in both tests in order to assess whether or not the algorithms are performing well .",
    "an important emerging application for oseledets subspaces is the detection of strange eigenmodes , persistent patterns , and coherent sets for aperiodic time - dependent fluid flows . in the periodic setting strange eigenmodes",
    "have been found as eigenfunctions of a perron - frobenius operator via classical floquet theory ; @xcite .",
    "however , in the aperiodic time - dependent setting , floquet theory can not be applied . an extension to aperiodically driven flows",
    "was derived in @xcite , based on the new multiplicative ergodic theory of @xcite .",
    "discrete approximations of a perron - frobenius cocycle representing the aperiodic flow are constructed and in this aperiodic setting the leading sub - dominant oseledets subspaces play the role of the leading sub - dominant eigenfunctions in the periodic forcing case .",
    "we review the four methods of approximating oseledets subspaces with the aperiodically driven cylinder flow from @xcite .",
    "the flow domain is @xmath534\\times[0,\\pi]$ ] , @xmath535 and the flow is defined by the following forced ode : @xmath536 here , @xmath537 , where @xmath538 is generated by the standard lorenz flow , @xmath539 , @xmath540 and the parameter function @xmath541 vanishes at the level set of the streamfunction of the unperturbed ( @xmath542 ) flow at instantaneous time @xmath543 , i.e. , @xmath544 , which divides the phase space in half .",
    "( 1,0.75906433 ) ( 0,0 ) , ( b ) algorithm [ alg : dichproj1 ] , ( c ) algorithm [ a2 ] , ( d ) algorithm [ alg : ginelli ] and ( e ) algorithm [ alg : wolfe].,title=\"fig : \" ] ( 0.06452257,0.52660819)(0,0)[lb ] ( 0.16130643,0.52660819)(0,0)[lb ] ( 0.25809006,0.52660819)(0,0)[lb ] ( 0.35497076,0.52660819)(0,0)[lb ] ( 0.05653006,0.53908421)(0,0)[lb ] ( 0.05653006,0.59697895)(0,0)[lb ] ( 0.05653006,0.65477661)(0,0)[lb ] ( 0.05653006,0.7125731)(0,0)[lb ] ( 0.21773918,0.51267135)(0,0)[lb ] ( 0.41754386,0.56764211)(0,0)[lb ] ( 0.41754386,0.59931813)(0,0)[lb ] ( 0.41754386,0.6310924)(0,0)[lb ] ( 0.41754386,0.6628655)(0,0)[lb ] ( 0.41754386,0.69463977)(0,0)[lb ] ( 0.55584795,0.52660819)(0,0)[lb ] ( 0.65263158,0.52660819)(0,0)[lb ] ( 0.7494152,0.52660819)(0,0)[lb ] ( 0.84629591,0.52660819)(0,0)[lb ] ( 0.54785614,0.53908421)(0,0)[lb ] ( 0.54785614,0.59697895)(0,0)[lb ] ( 0.54785614,0.65477661)(0,0)[lb ] ( 0.54785614,0.7125731)(0,0)[lb ] ( 0.70906433,0.51267135)(0,0)[lb ] ( 0.90886901,0.56764211)(0,0)[lb ] ( 0.90886901,0.59931813)(0,0)[lb ] ( 0.90886901,0.6310924)(0,0)[lb ] ( 0.90886901,0.6628655)(0,0)[lb ] ( 0.90886901,0.69463977)(0,0)[lb ] ( 0.06452257,0.2843076)(0,0)[lb ] ( 0.16130643,0.2843076)(0,0)[lb ] ( 0.25809006,0.2843076)(0,0)[lb ] ( 0.35497076,0.2843076)(0,0)[lb ] ( 0.05653006,0.29678363)(0,0)[lb ] ( 0.05653006,0.35467836)(0,0)[lb ] ( 0.05653006,0.41247602)(0,0)[lb ] ( 0.05653006,0.47027251)(0,0)[lb ] ( 0.21803158,0.27037076)(0,0)[lb ] ( 0.41754386,0.32894737)(0,0)[lb ] ( 0.41754386,0.36354737)(0,0)[lb ] ( 0.41754386,0.39805029)(0,0)[lb ] ( 0.41754386,0.43265146)(0,0)[lb ] ( 0.41754386,0.46725146)(0,0)[lb ] ( 0.55584795,0.2843076)(0,0)[lb ] ( 0.65263158,0.2843076)(0,0)[lb ] ( 0.7494152,0.2843076)(0,0)[lb ] ( 0.84629591,0.2843076)(0,0)[lb ] ( 0.54785614,0.29678363)(0,0)[lb ] ( 0.54785614,0.35467836)(0,0)[lb ] ( 0.54785614,0.41247602)(0,0)[lb ] ( 0.54785614,0.47027251)(0,0)[lb ] ( 0.70906433,0.27037076)(0,0)[lb ] ( 0.90886901,0.31637427)(0,0)[lb ] ( 0.90886901,0.35204678)(0,0)[lb ] ( 0.90886901,0.38762222)(0,0)[lb ] ( 0.90886901,0.42319649)(0,0)[lb ] ( 0.90886901,0.45886901)(0,0)[lb ] ( 0.32192982,0.04376234)(0,0)[lb ] ( 0.41871345,0.04376234)(0,0)[lb ] ( 0.51549708,0.04376234)(0,0)[lb ] ( 0.6122807,0.04376234)(0,0)[lb ] ( 0.31393801,0.05623766)(0,0)[lb ] ( 0.31393801,0.1135476)(0,0)[lb ] ( 0.31393801,0.17085731)(0,0)[lb ] ( 0.31393801,0.22816725)(0,0)[lb ] ( 0.4751462,0.02982456)(0,0)[lb ] ( 0.6748538,0.07563368)(0,0)[lb ] ( 0.6748538,0.11091602)(0,0)[lb ] ( 0.6748538,0.14619883)(0,0)[lb ] ( 0.6748538,0.18157895)(0,0)[lb ] ( 0.6748538,0.21686199)(0,0)[lb ]    we set @xmath545 as this value is sufficiently large to ensure no kam tori remain in the jet regime , but sufficiently small to maintain islands originating from the nested periodic orbits around the elliptic points of the unperturbed system .",
    "we construct the discretised perron - frobenius matrices @xmath546 as described in section 3 of @xcite , and briefly recapped in example [ eg1.2 ] , using a uniform grid of @xmath547 boxes , @xmath548 and @xmath549 . in total , we generate 8 such matrices of dimension @xmath550 .",
    "thus , in this case study we have a limited amount of data , no symmetry , high dimension , and the matrices are non - invertible and sparse .    in order to obtain reasonable results we executed algorithms [ alg : svd2 ] , [ alg : dichproj1 ] , [ a2 ] , [ alg : ginelli ] and [ alg : wolfe ] with the following parameters :    * * algorithm [ alg : svd2 ] : * @xmath551 and @xmath552 . * * algorithm [ alg : dichproj1 ] : * we estimate the three largest lyapunov exponents @xmath472 and set @xmath473 and @xmath474 . * * algorithm [ a2 ] : * as for algorithm [ alg : dichproj1 ] . * * algorithm [ alg : ginalt ] : * @xmath553 ( so that only an svd is used , and no push - forward step ) , @xmath554 and @xmath555 . *",
    "* algorithm [ alg : wolfe ] : * @xmath556 and @xmath557 .",
    "( 1,1.55621588 ) ( 0,0 ) comparing the approximations of the second oseledets vector @xmath558 at time @xmath559 with the push - forward of the approximations at time @xmath543 .",
    "those labelled ( a ) are the push - forwards @xmath560 whilst those labelled ( b ) are independently computed approximations @xmath561 of @xmath558 .",
    "the algorithms used are as follows : ( 1 ) algorithm [ alg : svd2 ] , ( 2 ) algorithm [ alg : dichproj1 ] , ( 3 ) algorithm [ a2 ] , ( 4 ) algorithm [ alg : ginelli ] and ( 5 ) algorithm [ alg : wolfe].,title=\"fig : \" ] ( 0.04110015,1.26763605)(0,0)[lb ] ( 0.14823675,1.26763605)(0,0)[lb ] ( 0.25549935,1.26763605)(0,0)[lb ] ( 0.36263595,1.26763605)(0,0)[lb ] ( 0.03082527,1.28367541)(0,0)[lb ] ( 0.03082527,1.36061347)(0,0)[lb ] ( 0.03082527,1.43742583)(0,0)[lb ] ( 0.03082527,1.51423788)(0,0)[lb ] ( 0.19672986,1.2497177)(0,0)[lb ] ( 0.44057575,1.2959556)(0,0)[lb ] ( 0.44057575,1.35021288)(0,0)[lb ] ( 0.44057575,1.40434505)(0,0)[lb ] ( 0.44057575,1.45847723)(0,0)[lb ] ( 0.44057575,1.51273421)(0,0)[lb ] ( 0.54633348,1.26763605)(0,0)[lb ] ( 0.65347008,1.26763605)(0,0)[lb ] ( 0.76073298,1.26763605)(0,0)[lb ] ( 0.86786958,1.26763605)(0,0)[lb ] ( 0.53605889,1.28367541)(0,0)[lb ] ( 0.53605889,1.36061347)(0,0)[lb ] ( 0.53605889,1.43742583)(0,0)[lb ] ( 0.53605889,1.51423788)(0,0)[lb ] ( 0.70196348,1.2497177)(0,0)[lb ] ( 0.94580938,1.2876854)(0,0)[lb ] ( 0.94580938,1.34595268)(0,0)[lb ] ( 0.94580938,1.40434505)(0,0)[lb ] ( 0.94580938,1.46273713)(0,0)[lb ] ( 0.94580938,1.5210044)(0,0)[lb ] ( 0.04115858,0.95691727)(0,0)[lb ] ( 0.14829517,0.95691727)(0,0)[lb ] ( 0.25555778,0.95691727)(0,0)[lb ] ( 0.36269437,0.95691727)(0,0)[lb ] ( 0.03088369,0.97295664)(0,0)[lb ] ( 0.03088369,1.0498947)(0,0)[lb ] ( 0.03088369,1.12670705)(0,0)[lb ] ( 0.03088369,1.2035191)(0,0)[lb ] ( 0.1929043,0.93899892)(0,0)[lb ] ( 0.44063418,1.02771554)(0,0)[lb ] ( 0.44063418,1.10227239)(0,0)[lb ] ( 0.44063418,1.17682893)(0,0)[lb ] ( 0.54639191,0.95691727)(0,0)[lb ] ( 0.6535285,0.95691727)(0,0)[lb ] ( 0.7607914,0.95691727)(0,0)[lb ] ( 0.867928,0.95691727)(0,0)[lb ] ( 0.53611732,0.97295664)(0,0)[lb ] ( 0.53611732,1.0498947)(0,0)[lb ] ( 0.53611732,1.12670705)(0,0)[lb ] ( 0.53611732,1.2035191)(0,0)[lb ] ( 0.70415261,0.93899892)(0,0)[lb ] ( 0.94586781,1.03297839)(0,0)[lb ] ( 0.94586781,1.09751026)(0,0)[lb ] ( 0.94586781,1.16204333)(0,0)[lb ] ( 0.04110015,0.65095021)(0,0)[lb ] ( 0.14823675,0.65095021)(0,0)[lb ] ( 0.25549935,0.65095021)(0,0)[lb ] ( 0.36263595,0.65095021)(0,0)[lb ] ( 0.03082527,0.66698957)(0,0)[lb ] ( 0.03082527,0.74392763)(0,0)[lb ] ( 0.03082527,0.82073999)(0,0)[lb ] ( 0.03082527,0.89755204)(0,0)[lb ] ( 0.19886056,0.63303186)(0,0)[lb ] ( 0.44057575,0.66686447)(0,0)[lb ] ( 0.44057575,0.72964275)(0,0)[lb ] ( 0.44057575,0.79229503)(0,0)[lb ] ( 0.44057575,0.85494851)(0,0)[lb ] ( 0.54633348,0.6507)(0,0)[lb ] ( 0.65347008,0.6507)(0,0)[lb ] ( 0.76073298,0.6507)(0,0)[lb ] ( 0.86786958,0.6507)(0,0)[lb ] ( 0.53605889,0.66673876)(0,0)[lb ] ( 0.53605889,0.74367682)(0,0)[lb ] ( 0.53605889,0.82061518)(0,0)[lb ] ( 0.53605889,0.89755204)(0,0)[lb ] ( 0.70822928,0.63278105)(0,0)[lb ] ( 0.94580938,0.73152234)(0,0)[lb ] ( 0.94580938,0.80445071)(0,0)[lb ] ( 0.94580938,0.87737878)(0,0)[lb ] ( 0.04110015,0.34208864)(0,0)[lb ] ( 0.14823675,0.34208864)(0,0)[lb ] ( 0.25549935,0.34208864)(0,0)[lb ] ( 0.36263595,0.34208864)(0,0)[lb ] ( 0.03082527,0.35812801)(0,0)[lb ] ( 0.03082527,0.43506606)(0,0)[lb ] ( 0.03082527,0.51187842)(0,0)[lb ] ( 0.03082527,0.58869047)(0,0)[lb ] ( 0.19886056,0.32417029)(0,0)[lb ] ( 0.44057575,0.37040819)(0,0)[lb ] ( 0.44057575,0.42466547)(0,0)[lb ] ( 0.44057575,0.47879764)(0,0)[lb ] ( 0.44057575,0.53292982)(0,0)[lb ] ( 0.44057575,0.5871868)(0,0)[lb ] ( 0.54633348,0.34208864)(0,0)[lb ] ( 0.65347008,0.34208864)(0,0)[lb ] ( 0.76073298,0.34208864)(0,0)[lb ] ( 0.86786958,0.34208864)(0,0)[lb ] ( 0.53605889,0.35812801)(0,0)[lb ] ( 0.53605889,0.43506606)(0,0)[lb ] ( 0.53605889,0.51187842)(0,0)[lb ] ( 0.53605889,0.58869047)(0,0)[lb ] ( 0.7044701,0.32417029)(0,0)[lb ] ( 0.94580938,0.362138)(0,0)[lb ] ( 0.94580938,0.42040527)(0,0)[lb ] ( 0.94580938,0.47879764)(0,0)[lb ] ( 0.94580938,0.53718972)(0,0)[lb ] ( 0.94580938,0.59545699)(0,0)[lb ] ( 0.0411586,0.03744143)(0,0)[lb ] ( 0.14829519,0.03744143)(0,0)[lb ] ( 0.2555578,0.03744143)(0,0)[lb ] ( 0.36269439,0.03744143)(0,0)[lb ] ( 0.03088371,0.05348079)(0,0)[lb ] ( 0.03088371,0.12590723)(0,0)[lb ] ( 0.03088371,0.19820947)(0,0)[lb ] ( 0.03088371,0.27051051)(0,0)[lb ] ( 0.19979564,0.01952247)(0,0)[lb ] ( 0.4406342,0.06513424)(0,0)[lb ] ( 0.4406342,0.11613337)(0,0)[lb ] ( 0.4406342,0.16700829)(0,0)[lb ] ( 0.4406342,0.21800681)(0,0)[lb ] ( 0.4406342,0.26900684)(0,0)[lb ] ( 0.54639193,0.03744143)(0,0)[lb ] ( 0.65352852,0.03744143)(0,0)[lb ] ( 0.76079142,0.03744143)(0,0)[lb ] ( 0.86792802,0.03744143)(0,0)[lb ] ( 0.53611734,0.05348079)(0,0)[lb ] ( 0.53611734,0.12590723)(0,0)[lb ] ( 0.53611734,0.19820947)(0,0)[lb ] ( 0.53611734,0.27051051)(0,0)[lb ] ( 0.70916437,0.01952247)(0,0)[lb ] ( 0.94586783,0.05723997)(0,0)[lb ] ( 0.94586783,0.11212398)(0,0)[lb ] ( 0.94586783,0.16700829)(0,0)[lb ] ( 0.94586783,0.2220171)(0,0)[lb ] ( 0.94586783,0.27690111)(0,0)[lb ]    the results of these numerical experiments are shown in figures [ fig : fluid_flow_1 ] and [ fig : fluid_flow_2 ] .",
    "recall that in this setting , the cocycle @xmath99 is a cocycle of discretised perron - frobenius operators acting on piecewise constant functions defined on @xmath562 ; we identify these piecewise constant functions ( with 7200 pieces ) with vectors in @xmath563 .",
    "figure [ fig : fluid_flow_1 ] first shows the approximations of the second oseledets vector @xmath319 at time @xmath543 . in this setting the oseledets vectors locate _ coherent structures _ : figure [ fig : fluid_flow_2 ] compares the push - forward of the approximations in figure [ fig : fluid_flow_1 ] with independently computed approximations of @xmath558 - the second oseledets vector at time @xmath559 .    in this study",
    "the data sample is insufficiently long for algorithm [ a2 ] to work effectively , but the other algorithms produce similar results .",
    "a visual inspection of figure [ fig : fluid_flow_2 ] shows that the highlighted structures are approximately equivariant / coherent .",
    "we introduced two new methods for computing oseledets subspaces : one based on singular value decompositions and the other based on dichotomy projectors .",
    "we also reviewed recent methods by ginelli _",
    "_ @xcite and wolfe and samelson @xcite , and presented an improvement to both of these approaches that intelligently selected initial bases when only short time series were available to compute with .",
    "finally , we carried out a comparative numerical investigation involving all four methods .    generally speaking",
    ", we found that algorithms [ alg : svd2 ] , [ alg : ginalt ] , and [ alg : wolfe ] outperformed the dichotomy projector methods ( algorithms [ alg : dichproj1 ] and [ a2 ] ) when limited to moderate amounts of data were available , however , the dichotomy projector methods performed very well when long time series of matrices were available . the ginelli approach ( in particular the improved algorithm [ alg : ginalt ] ) also worked very well with long time series .",
    "the improvements made to algorithm [ alg : svd ] in section [ sec : svd2 ] ( namely the orthogonalisation step in algorithm [ alg : svd2 ] ) produced an algorithm that could take advantage of longer matrix sequences and return very accurate results .",
    "of course , for each algorithm one must choose the associated parameters sensibly to ensure good results .",
    "when only a short to moderate time series was available , we found mixed results in terms of the best algorithm . the improved svd approach ( algorithm [ alg : svd2 ] ) was best for low to moderate length time series in the exact toy model , while the improved ginelli ( algorithm [ alg : ginalt ] ) and improved wolfe ( algorithm [ alg : wolfe ] ) were marginally best in terms of equivariance and expansion rate , respectively for the 2-disk model .",
    "each of these three algorithms produced similar results in the fluid - flow system .",
    "choosing appropriate parameters for a particular application can be difficult . in the present review ,",
    "good values were chosen by educated experimentation .",
    "on the other hand , the dichotomy projector methods , algorithms [ alg : dichproj1 ] and [ a2 ] , use parameters ( @xmath214 and @xmath215 ) which can be chosen in a deterministic manner - by estimating lyapunov exponents , which is a reasonably robust numerical procedure .",
    "furthermore , a rigorous error approximation exists for algorithm [ a2 ] , a feature currently lacking for algorithms [ alg : svd2 ] , [ alg : ginalt ] and [ alg : wolfe ] .",
    "the memory footprint of each approach scales quite differently with dimension . in section [ sec : fluidflow ] , algorithms [ alg : svd2 ] and [ alg : wolfe ] could take advantage of the sparseness of the @xmath2 generating matrices of the cocycle .",
    "however , since @xmath99 is formed by matrix multiplication , for large @xmath131 the matrix @xmath99 becomes dense and may require memory of the order of @xmath564 floating point numbers .",
    "the dichotomy projector algorithms [ alg : dichproj1 ] and [ a2 ] , need to form an @xmath565 matrix , but with sparse generating matrices , this requires memory much less than of the order of @xmath564 floating point numbers .",
    "algorithm [ alg : ginalt ] has the most conservative memory footprint , but depends on its initialisation parameter @xmath412 and the oselelets subspace number @xmath160 .",
    "if @xmath412 is large , then @xmath405 in step 1 can become dense and require @xmath566 floating point numbers . on the other hand ,",
    "the stationary lyapunov basis requires @xmath567 floating point numbers to be stored , so if @xmath568 this can becomes comparable to @xmath564 .",
    "section [ sec : fluidflow ] involves non - invertible generating matrices and apart from algorithm [ a2 ] , each approach succeeded in producing a reasonable solution , showing that the algorithms can perform well in the non - invertible setting . continuing with the non - invertible situation , if one wishes to approximate oseledets subspaces corresponding to negative numbers with very large magnitudes ( @xmath569 ) , then algorithms [ alg : svd2 ] and [ alg : wolfe ] may struggle as rapidly contracting directions ( relative to the dominant direction corresponding to @xmath369 ) are quickly squashed during the matrix multiplication used to approximate @xmath99 leading to inaccurate numerical representation of @xmath99 .",
    "the dichotomy projector approaches of algorithms [ alg : dichproj1 ] and [ a2 ] are able to compute oseledets subspaces corresponding to smaller , sub - dominant lyapunov exponents @xmath570 provided larger amounts of cocycle data is available .",
    "however , if @xmath569 , we are forced to choose @xmath214 or @xmath571 which means either problem or ( in algorithm [ alg : dichproj1 ] which also feature in algorithm [ a2 ] ) are ill - conditioned and fail .",
    "the same problem manifests itself in algorithm [ alg : ginalt ] , even though it is able to compute oseledets subspaces corresponding to smaller , sub - dominant lyapunov exponents .",
    "the sum of the logarithm of the diagonal entries of the @xmath430 generating matrices of the cocycle @xmath327 average to the logarithmic expansion rate of the @xmath160-parallelepiped formed at @xmath36 by the stationary lyapunov vectors @xmath572 as it is pushed - forward .",
    "thus , the logarithm of the @xmath153th diagonal entry of the generating matrices of @xmath327 has a time average of @xmath573 @xcite and if @xmath569 , @xmath327 will feature diagonal entries close to , or equal to zero and @xmath574 wo nt exist .",
    "in summary , algorithms [ alg : svd2 ] and [ alg : wolfe ] are best suited to situations with limited cocycle data when one of the most dominant oseledets subspaces is desired .",
    "algorithm [ alg : ginalt ] can be applied to both limited and high data situations by choosing @xmath412 appropriately , and can compute most oseledets subspaces provided their lyapunov exponents are well - conditioned . if ample data is available and information regarding the system is lacking ( making the choice of parameters for the other approaches difficult ) , the approaches of algorithms [ alg : dichproj1 ] and [ a2 ] may be preferred for their relatively deterministic parameter selection .",
    "g.  benettin , l.  galgani , a.  giorgilli , and j.  m. strelcyn .",
    "yapunov characteristic exponents for smooth dynamical systems and for hamiltonian systems : a method for computing all of them .",
    "part i : theory .",
    "part ii : numerical application .",
    ", 15:930 , 1980 ."
  ],
  "abstract_text": [
    "<S> covariant vectors , lyapunov vectors , or oseledets vectors are increasingly being used for a variety of model analyses in areas such as partial differential equations , nonautonomous differentiable dynamical systems , and random dynamical systems . </S>",
    "<S> these vectors identify spatially varying directions of specific asymptotic growth rates and obey equivariance principles . in recent years new computational methods for approximating oseledets vectors </S>",
    "<S> have been developed , motivated by increasing model complexity and greater demands for accuracy . in this numerical study </S>",
    "<S> we introduce two new approaches based on singular value decomposition and exponential dichotomies and comparatively review and improve two recent popular approaches of ginelli _ et al . </S>",
    "<S> _ @xcite and wolfe and samelson @xcite . </S>",
    "<S> we compare the performance of the four approaches via three case studies with very different dynamics in terms of symmetry , spectral separation , and dimension . </S>",
    "<S> we also investigate which methods perform well with limited data . </S>"
  ]
}