{
  "article_text": [
    "data analysis through machine and statistical learning has become an important tool in a variety of fields including artificial intelligence , biology , medicine , finance , and marketing .",
    "though arising in diverse applications , these problems share key characteristics , such as an extremely large number ( in the order of tens of millions ) of training examples typically residing in high - dimensional spaces . with this unprecedented growth in data ,",
    "the need for _ distributed computation _ across multiple processing units is ever - pressing .",
    "this direction holds the promise for algorithms that are both rich - enough to capture the complexity of modern data , and scalable - enough to handle `` big data '' efficiently .    in",
    "the distributed setting , central problems are split across multiple processors each having access to local objectives . the goal is then to minimize a sum of local costs while ensuring consensus ( agreement ) across all processors . to clarify",
    ", consider the example of linear regression in which the goal is to find a latent model for a given dataset . rather than searching for a centralized solution",
    ", one can distribute the optimization across multiple processors each having access to local costs defined over random subsets of the full dataset .",
    "in such a case , each processor learns a separate `` chunk '' of the latent model , which is then unified by incorporating consensus constraints .",
    "generally , there are two popular classes of algorithms for distributed optimization .",
    "the first is sub - gradient based , while the second relies on a decomposition - coordination procedure .",
    "sub - gradient algorithms proceed by taking a gradient related step then followed by an averaging with neighbors at each iteration .",
    "the computation of each step is relatively cheap and can be implemented in a distributed fashion  @xcite .",
    "though cheap to compute , the best known convergence rate of sub - gradient methods is relatively slow given by @xmath0 with @xmath1 being the total number of iterations  @xcite .",
    "the second class of algorithms solve constrained problems by relying on dual methods .",
    "one of the well - know methods ( state - of - the - art ) from this class is the alternating direction method of multipliers ( admm )  @xcite .",
    "admm decomposes the original problem to two subproblems which are then solved sequentially leading to updates of dual variables . in  @xcite ,",
    "the authors show that admm can be fully distributed over a network leading to improved convergence rates in the order of @xmath2 .",
    "apart from accuracy problems inherent to admm - based methods  @xcite , much rate improvements can be gained from adopting second - order ( newton ) methods .",
    "though a variety of techniques have been proposed  @xcite , less progress has been made at leveraging admm s accuracy and convergence rate issues . in a recent attempt  @xcite , the authors propose a distributed second - order method for general consensus by using the approach in  @xcite to compute the newton direction . as detailed in section  [ sec : experiments ] , this method suffers from two problems .",
    "first , it fails to outperform admm and second , faces storage and computational defficiencies for large data sets , thus admm retains state - of - the - art status with @xmath3 being the total number of nodes and @xmath4 the number of features .",
    "* contributions : * in this paper , we contribute to the above problems and propose a distributed newton method for general consensus with the following characteristics : _",
    "i ) _ approximating the _ exact newton direction _ up - to any arbitrary @xmath5 , _ ii ) _ exhibiting super - linear convergence within a neighborhood of the optimal solution similar to exact newton , and _",
    "iii ) _ outperforming admm and others in terms of iteration count , running times , and total message complexity on a set of benchmark datasets , including one on a real - world application of fmri imaging . one can argue that our improvements arrive at increased communication costs compared to other techniques . in a set of experiments , we show that such an increase is relatively small for low accuracy requirements and demonstrate a growth proportional to the condition number of the processors graph as accuracy demands improve . of course",
    ", as shown in our results ( see section  [ sec : experiments ] ) , this increase is slower compared to other methods which can be exponential .",
    "symmetric diagonally dominant matrices ( sdd ) play a vital role in the computation of the newton direction in a distributed fashion . in this section ,",
    "we briefly review sdd systems and present a summary of efficient methods for solving them .",
    "sdd systems are linear equations of the form : @xmath6 with @xmath7 being a symmetric diagonally dominant matrix ( sdd ) .",
    "namely , @xmath7 is symmetric positive semi - definite with non - positive off - diagonal elements , such that for all @xmath8 : @xmath9_{ii } \\geq - \\sum_{j=1 , i \\neq j}^{n } \\left[\\bm{m}\\right]_{ij}$ ] .",
    "the goal is to determine an @xmath10-approximate solution , @xmath11 , to the exact solution @xmath12 of equation  [ eq : sddm ] ( bounded under the @xmath7 norm ) , which is defined as :    @xcite let @xmath12 be the solution to @xmath13 .",
    "a vector @xmath11 is called an @xmath10-approximate solution to @xmath12 , if : @xmath14    [ [ standard - splittings - approximations ] ] standard splittings & approximations : + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the story of computing an approximation to the exact inverse , @xmath15 , starts from standard splittings of symmetric matrices . here",
    ", @xmath7 is decomposed as : @xmath16 where @xmath17 is a diagonal matrix consisting of diagonal elements in @xmath7 , while @xmath18 is a non - negative symmetric matrix collecting all off - diagonal components , i.e. , @xmath19_{ij}= - [ \\bm{m}]_{ij}$ ] if @xmath20 and @xmath21 otherwise .",
    "based on this splitting , the authors in  @xcite recognize that the inverse of @xmath22 can be written as : @xmath23.\\end{aligned}\\ ] ] since @xmath24 is also symmetric diagonally dominant , spielman and peng recurse the above for a length of @xmath25 to arrive at the inverse approximated chain , @xmath26 with : @xmath27    rewriting equation  [ eq : standardsplitting ] in terms of the approximated chain , an @xmath10-close solution to @xmath12 can be determined using a two step procedure . in the first a `` crude '' solution to @xmath12",
    "is returned ( algorithm  [ algo : algorithmcrude ] ) .",
    "the procedure operates in two loops , both running to an order @xmath25 . in the forward loop ,",
    "intermediate vectors are constructed which are then used in the backward loop to determine the solution @xmath28 , where @xmath29 .",
    "[ algo : algorithmcrude ]    * inputs : * inverse approximated chain @xmath30 , vector @xmath31 compute @xmath32 determine @xmath33 compute @xmath34 $ ] * return : * `` crude '' approximation , @xmath35 , to @xmath12 .",
    "since @xmath36 incurs an @xmath37 error ( a constant error ) to the real inverse @xmath15 , spielman and peng introduce a richardson pre - conditioning scheme , detailed in algorithm  [ algo : richard ] , to arrive at any arbitrary precision .",
    "[ algo : richard ]    * inputs : * inverse approximated chain @xmath30 , length @xmath38 , `` crude '' solution @xmath35 @xmath39 , where @xmath40 . *",
    "return : * @xmath10-close solution @xmath41 .    to be used in determining the newton direction , a distributed version of the above sdd solver has to be developed . in recent work",
    ", the authors in  @xcite distribute the parallel sdd solver across multiple processors . to do so , the system in equation  [ eq : sddm ] is interpreted as represented by an undirected weighted graph , @xmath42 , with @xmath7 being its laplacian .",
    "the authors then introduce an inverse approximate chain which can be computed in a distributed fashion .",
    "consequently , both the `` crude '' and exact solutions can be determined using only local communication between nodes on the undirected graph @xmath42 . in the consensus problem",
    ", we adapt this solver for distributing the computation of the newton direction ( see section  [ sec : distnewton ] ) .",
    "much of distributed machine learning can be interpreted within the framework of global consensus .",
    "global consensus considers a network of @xmath3 agents represented by a connected undirected graph @xmath43 with @xmath44 and @xmath45 .",
    "each agent , @xmath46 , corresponding to a node , can exchange information among its first - hop neighborhood denoted by @xmath47 .",
    "the size of such @xmath48 is referred to as the degree of node @xmath46 , i.e. , @xmath49 . in the general form , the goal is for each agent to determine an unknown vector @xmath50 which minimizes a sum of multivariate cost functions @xmath51 with @xmath52 distributed over the network while abiding by consensus constraints : @xmath53      though multiple attempts have been made at distributing the global consensus problem , the majority of these works suffer from the following drawbacks .",
    "the first line of work is that introduced in  @xcite .",
    "this work mostly focuses on the univariate and separable settings and fails to generalize to the multivariate case .",
    "the second , on the other hand , is that of  @xcite , where the focus is mainly on a parallelized setting and not a distributed one .",
    "parallelized methods assume shared memory that can become restrictive for problems with large data sets . in this work ,",
    "we focus on the `` true '' distributed setting where each processor abides by its own memory constraints and the framework does not invoke any central node . we start by introducing a set of vectors @xmath54 , each in @xmath55 .",
    "each vector @xmath56 acts as a collector for every dimension of the solution across all nodes . in other words ,",
    "each vector @xmath57 contains the @xmath58 components of @xmath59 : @xmath60^{\\mathsf{t } } , \\hspace{.1em } \\bm{y}_{2 } = \\left [ x_{1}(2 ) , \\dots , x_{n}(2 ) \\right]^{\\mathsf{t } } , \\hspace{.1em } \\dots \\hspace{.1em } , \\bm{y}_{p } = \\left [ x_{1}(p ) , x_{2}(p ) , \\dots , x_{n}(p ) \\right]^{\\mathsf{t}}.\\end{aligned}\\ ] ]    clearly , the collection of @xmath54 is locally distributed among the nodes of graph @xmath42 , since each node @xmath61 need only to have access to the @xmath58 components of such vectors .",
    "consequently , we can rewrite the problem of equation  [ eq : globalcons ] in an equivalent distributed form : @xmath62 with @xmath63 being the unweighted graph laplacian of @xmath42 defined as follows : @xmath64 if @xmath65 , -1 if @xmath66 , and @xmath21 otherwise . to finalize the definition , we write the problem in equation  [ eq : two_1 ] in a vectorized format as : @xmath67 where @xmath68 is a block - diagonal matrix with laplacian diagonal entries , and @xmath69 is a vector concatenating @xmath70 . at this stage ,",
    "our aim is to solve the problem in equation  [ eq : two ] using dual techniques . before presenting properties of the dual problem ,",
    "we next introduce a standard assumption  @xcite on the associated functions @xmath71 s :    [ ass : two ] the cost functions @xmath72 are convex and :    * twice continuously differentiable with : @xmath73 * lipschitz - hessian invertible : @xmath74 , for some @xmath75 and all @xmath76 .      to acquire the dual formulation of distributed general consensus , we first introduce a vector of dual variables @xmath77^{\\mathsf{t } } \\in \\mathbb{r}^{np}$ ] , where each @xmath78 are lagrange multipliers , one for each dimension of the unknown vector . for distributed computations ,",
    "we assume that each node need only to store its corresponding components @xmath79 .",
    "consequently , the lagrangian of equation  [ eq : two ] can be written as follows : @xmath80 hence , the dual has the following form : @xmath81 having determined the dual variables , we still require a procedure which allows us to infer about the primal . using the above , the primal variables are determined as the solution to the following system of differential equations : @xmath82 clearly , equation  [ eq : system ] is locally defined for each node @xmath61 , where for each @xmath83 : @xmath84 hence , each node @xmath46 can construct its own system of equations by collecting @xmath85 from its neighbors @xmath86 without the need for full communication . denoting the solution of the pde as : @xmath87",
    ", we can show the following essential theoretical guarantee on the partial derivatives :    let @xmath88 , @xmath89 , ",
    ", @xmath90 . under assumption  [ ass : two ] , the functions @xmath91 ,  , @xmath92 exhibit bounded partial derivatives with respect to @xmath93 ,  , @xmath94 .",
    "in other words , for any @xmath83 : @xmath95 , for any @xmath96 .    the above result is crucial in our analysis , as an obvious corollary is that each function , @xmath97 , is lipschitz continuous , i.e. , for any two vectors @xmath98 and @xmath99 : @xmath100    [ [ dual - function - properties ] ] dual function properties : + + + + + + + + + + + + + + + + + + + + + + + + +    our method for computing the newton direction relies on the fact that the hessian of the dual problem is an sdd matrix .",
    "we prove this property in the following lemma :    [ lemma : props ] the dual function @xmath101 shares the following characteristics :    * the dual hessian @xmath102 and gradient @xmath103 are given by : @xmath104 * the dual hessian is lipschitz continuous with respect to @xmath7-weighted norm , where for any @xmath105 and @xmath106 : @xmath107 , with @xmath108 , where @xmath109 is the largest eigenvalue of @xmath110 and the constants @xmath111 and @xmath75 are these given in  [ ass : two ] .",
    "we solve the consensus problem using newton - like techniques , where our method follows the _ approximate _ newton direction in the dual : @xmath112}= \\bm{\\lambda}^{[k ] } + \\alpha^{[k ] } \\tilde{\\bm{d}}^{[k]}$ ] , where @xmath113 is the iteration number , and @xmath114}$ ] the step - size .",
    "@xmath115}$ ] is the @xmath10-approximation to the exact newton direction at iteration @xmath113 . for efficient operation ,",
    "the main goal is to _ accurately _ approximate the newton direction in a fully distributed fashion .",
    "this can be achieved with the help of the sdd properties of the dual hessian proved earlier . recalling that exact newton computes:}= \\bm{y}\\left(\\bm{\\lambda}^{[k]}\\right)$ ] ,",
    "@xmath116 } = - \\bm{m } \\left(\\nabla^{2 } f \\left(\\bm{y}\\left(\\bm{\\lambda}^{[k]}\\right)\\right)\\right)^{-1}\\bm{m}$ ] , and @xmath117}= \\nabla q\\left(\\bm{\\lambda}^{[k]}\\right)= \\bm{m } \\bm{y}^{[k]}$ ] to denote the primal variables , dual hessian and gradient , respectively .",
    "] @xmath118 } \\bm{d}^{[k ] } = - \\bm{g}^{[k ] } ,   \\ \\ \\ \\ \\bm{m}\\left(\\nabla^{2 } f \\left(\\bm{y}^{[k]}\\right)\\right)^{-1}\\bm{m } \\bm{d}^{[k ] } & = \\bm{m } \\bm{y}^{[k]},\\end{aligned}\\ ] ] we notice that equation  [ eq : newtonsystem ] can be split to two sdd linear systems of the form : @xmath119 } =   \\bm{m } \\bm{y}^{[k ] } , \\ \\",
    "\\bm{m } \\bm{d}^{[k ] } = \\nabla^{2 } f\\left(\\bm{y}^{[k]}\\right)\\bm{z}^{[k]}.\\ ] ] the first equation is by itself sdd which can be solved in a distributed fashion using the approach in  @xcite .",
    "having attained that solution , we map the second system to @xmath4-sdd systems by introducing @xmath120}=\\left(\\left(\\bm{d}_{1}^{[k]}\\right)^{\\mathsf{t } } , \\dots , \\left(\\bm{d}_{p}^{[k]}\\right)^{\\mathsf{t}}\\right)^{\\mathsf{t}}$ ] with each @xmath121 } \\in \\mathbb{r}^{n}$ ] .",
    "it is easy to see that this can be split to the following collection of @xmath4 linear systems for @xmath122 : @xmath123 } = \\bm{b}_{1}^{[k ] } ,   \\ \\ \\ \\ \\ \\dots \\ \\ \\ \\ \\ , \\mathcal{l}\\bm{d}_{p}^{[k ] } = \\bm{b}_{p}^{[k]},\\ ] ] where @xmath124 } , \\dots , \\bm{b}_{p}^{[k ] } \\in \\mathbb{r}^{n}$ ] defined as : @xmath125 } ( r ) = \\sum_{l=1}^{p } \\frac{\\partial^{2 } f_{r}(\\cdot)}{\\partial y_{1}(r)\\partial y_{l } ( r ) } z^{[k]}_{l}(r ) , \\ \\ \\ \\dots \\ \\ \\ \\   b_{p}^{[k ] } ( r ) = \\sum_{l=1}^{p } \\frac{\\partial^{2 } f_{r}(\\cdot)}{\\partial y_{p}(r)\\partial y_{l } ( r ) } z^{[k]}_{l}(r ) \\end{aligned}\\ ] ] for @xmath126 .",
    "interestingly , the above computations can be performed completely locally by noting that each node @xmath127 can compute the @xmath128 component of each vector @xmath124 } , \\dots , \\bm{b}_{p}^{[k]}$ ] .",
    "this is true as such a node stores @xmath129 as well as the variables @xmath130}_{1}(r ) , \\dots , z^{[k]}_{p}(r)$ ] . before commencing to the convergence analysis",
    ", the final step needed is to establish the connection between the approximate solutions :    let @xmath131 } , \\dots , \\tilde{\\bm{d}}_{p}^{[k]}$ ] be the @xmath132-approximate solution to equation  [ eq : seventeen ] , then @xmath115}$ ] is an @xmath10-approximate solution to  [ eq : newtonsystem ] with @xmath133 $ ] .",
    "we next analyze the convergence properties of our approximate newton method showing similar three convergence phases to approximate newton methods .",
    "we start with the following lemma :    let @xmath117 } = \\nabla q\\left(\\bm{\\lambda}^{[k]}\\right)$ ] be the dual gradient at the @xmath134 iteration . then : @xmath135}\\right|\\right|_{\\bm{m } } & \\leq \\left[1 -\\alpha_{k } + \\epsilon \\alpha_{k } \\sqrt{\\frac{\\gamma}{\\gamma } \\frac{\\mu_{n}^{3}(\\mathcal{l})}{\\mu_{2}^{3}(\\mathcal{l})}}\\right]\\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m } } + \\frac{b(\\alpha_{k } ( 1+\\epsilon))^{2}}{2\\mu_{2}^{4}(\\mathcal{l } ) } \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}.\\end{aligned}\\ ] ]    now , we are ready to provide the theorem summarizing the three convergence phases :    let @xmath136 , @xmath111 , be the constants defined in assumption  [ ass : two ] , @xmath109 , @xmath137 be the largest and the second smallest eigenvalues of @xmath110 , respectively , and @xmath138 $ ] . consider the following iteration scheme : @xmath112}=\\bm{\\lambda}^{[k ] } + \\alpha^{\\star } \\tilde{\\bm{d}}^{[k]}$ ] , where @xmath139",
    ". then the distributed newton algorithm exhibits the following convergence phases :    * * strict decrease phase : * while @xmath140}\\right|\\right|_{\\bm{m } } \\geq \\eta_{1}$ ] : @xmath141}\\right)-q\\left(\\bm{\\lambda}^{[k]}\\right ) \\leq -\\frac{\\gamma^{3}}{\\gamma^{2}}\\left(\\frac{1-\\epsilon}{1+\\epsilon}\\right)^{2}\\frac{\\mu_{2}^{4}(\\mathcal{l})}{\\mu_{n}^{7}(\\mathcal{l } ) } \\eta_{1}^{2}$ ] , * * quadratic decrease phase : * while @xmath142}\\right|\\right|_{\\bm{m } } \\leq \\eta_{1}$ ] : @xmath143}\\right|\\right|_{\\bm{m } } \\leq \\frac{1}{\\eta_{1}}\\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2}$ ] , * * terminal phase : * while @xmath140}\\right|\\right|_{\\bm{m } } \\leq \\eta_{0}$ ] : @xmath143}\\right|\\right|_{\\bm{m } } \\leq \\zeta \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}$ ] , where @xmath144 , @xmath145 , and @xmath146 } , \\ \\ \\",
    "\\frac{b(\\alpha_{k}\\gamma(1+\\epsilon))^{2}}{2\\mu_{2}^{4}(\\mathcal{l})}$ ] .",
    "we evaluate our method against five other approaches : 1 ) distributed newton add , an adaptation of add  @xcite that we introduce to compute the newton direction of general consensus , 2 ) distributed admm  @xcite , 3 ) distributed averaging  @xcite , an algorithm solving general consensus using local averaging , 4 ) network newton 1 and 2  @xcite , and 5 ) distributed gradients  @xcite .",
    "we are chiefly interested in the convergence speeds of both the objective value and the consensus error .",
    "the comparison against admm allows us to understand whether we surpass state - of - the - art , while comparisons against add and network newton sheds - the - light on the accuracy of our newton s direction approximation . + * real - world distributed implementation : * to simulate a real - world distributed environment , we used the matlab parallel pool running on an 8 core server . after generating the processors graph structure with random edge assignment ( see below for specifics on the node - edge configuration ) , we split nodes equally across the 8 cores .",
    "hence , each processor was assigned a collection of nodes for performing computations .",
    "communication between these nodes was handled using the matlab message passing interface ( matlabmpi ) of  @xcite , which allows for efficient scripting .",
    "as for bandwidth , it has been shown in  @xcite that matlabmpi can match c - mpi for large messages , and can maintain high - bandwidth even when multiple processors are communicating .      we performed three sets of experiments on standard machine learning problems : 1 ) linear regression , 2 ) logistic regression , and 3 ) reinforcement learning .",
    "we transformed centralized problems to fit within the distributed consensus framework .",
    "this can be easily achieved by factoring the summation running over all the available training examples to partial summations across multiple processors while introducing consensus ( see appendix h ) .",
    "due to space constraints , we report two of these in this section and leave the others to the supplementary material ( see appendix g ) .",
    "we considered both synthetic as well as real - world data sets : + * synthetic regression task : * we created a dataset for regression with @xmath147 data points each being an @xmath148 dimensional vector .",
    "the task parameter vector @xmath149 was generated as a linear combination of these features .",
    "the training data set @xmath150 was generated from a standard normal distribution in @xmath148 dimensions .",
    "the training labels were given as @xmath151 , where each element in @xmath152 was an independent univariate gaussian noise .",
    "+ * mnist data * the mnist data set is a large database of handwritten digits which has been used as a benchmark for classification algorithms  @xcite .",
    "the goal is to classify among 10 different digits amounting from 1 to 10 . after reading each image ,",
    "we perform dimensionality reduction to reduce the number of features of each instance image to @xmath153 features using principle component analysis and follow a one - versus - all classification scheme . +      * synthetic data : * we randomly distributed the regression objective over a network of 100 nodes and 250 edges .",
    "the edges were chosen uniformly at random .",
    "an @xmath10 of @xmath154 was provided to the sdd solver for determining the approximate newton direction .",
    "step - sizes were determined separately for each algorithm using a grid - search - like - technique over \\{0.01 , 0.1 , 0.2 , 0.3 , 0.5 , 0.6 , 0.9 , 1 } to ensure best operating conditions .",
    "we used the local objective and the consensus error as performance metrics .",
    "results shown in figures  [ fig : objsynth ] and  [ fig : conssynth ] demonstrate that our method ( titled distributed sdd newton ) significantly outperforms all other techniques in both objective value and consensus error . namely , distributed sdd newton converges to the optimal value in about 40 iterations compared to about 200 for the second - best performing algorithm .",
    "it is also interesting to recognize that the worst performing algorithms were distributed gradients and network newton 1 and 2 from  @xcite .",
    "we chose the most successful algorithms from previous experiments to perform image classification .",
    "we considered both smooth ( l@xmath155 norms ) and non - smooth ( l@xmath156 norms ) regularization forms on latent parameters .",
    "the processor graph was set to 10 nodes and 20 edges generated uniformly at random .",
    "results depicted in figures  1(e)-1(f ) demonstrate that our algorithm is again capable of outperforming state - of - the - art methods .",
    "having shown that our approach outperforms others on relatively dense benchmark datasets , we are now interested in the performance on sparse datasets where the number of features is much larger than the number of inputs .",
    "to do so , we used the functional magnetic resonance imaging ( fmri ) dataset from  @xcite .",
    "the goal in these experiments is to classify the cognitive state ( i.e. , wether looking at a picture or a sentence ) of a subject based on fmri data .",
    "six subjects were considered in total .",
    "each had 40 trials that lasted for 27 seconds attaining in total 54 images per - subject .",
    "after preprocessing as described in  @xcite , we acquired a sparse data - set with 240 input data points , each having 43,720 features .",
    "we then performed logistic regression with an l@xmath156 regularization and reported objective values and consensus errors .",
    "figures 2(a ) and 2(b ) demonstrate the objective value and consensus errors on the fmri dataset .",
    "first , it is clear that our approach outperforms others on both criteria .",
    "it is worth noting that the second - best performing algorithm to ours is distributed add - newton ; an approach we proposed in this paper for computing the newton direction .",
    "distributed admm and distributed averaging perform the worst on such a sparse problem .",
    "second , figure 2(b ) clearly manifests the drawback of admm which requires substantial amounts of iterations for converging to the optimal feasible point . due to the size of the feature set ( i.e. , 43,720 ) even small deviations from the optimal model can lead to significant errors in the value of the objective function .",
    "this motivates the need for the accurate solutions as acquired by our method .",
    "it can be argued that our results arrive at a high communication cost between processors . this can be true as our method relies on an sdd - solver while others allow only for few messages per iteration .",
    "we conducted a final experiment measuring local communication exchange with respect to accuracy requirements .",
    "for that , we chose the london schools data set as all algorithms performed relatively well .",
    "results reported in figure 2(c ) demonstrate that this increase is negligible compared to other methods . clearly , as accuracy improves so does the communication overhead of all other algorithms .",
    "distributed sdd - newton has a growth rate proportional to the condition number of the graph being much slower compared to the exponential growth observed by other techniques .",
    "finally , figure 2(d ) reports running times till convergence on the same dataset .",
    "clearly , our method is the fastest when compared with others .",
    "the worst performing algorithms were network newton , distributed averaging and sub - gradients .",
    "in this paper , we proposed a distributed newton method for solving general consensus optimization .",
    "our method exploits the sdd property of the dual hessian leading to an accurate computation of the newton direction up - to - any arbitrary @xmath157 .",
    "we showed that our method exhibits three phases of convergence with a quadratic phase in the neighborhood of optimal solution . in a set of experiments on standard machine learning benchmarks ( including",
    "non - smooth cost functions ) we demonstrated that our algorithm is capable of outperforming state - of - the - art methods , including admm .",
    "finally , we empirically demonstrated that such an improvement arrives at a negligible increase in communication overhead between processors .",
    "our next step is to develop incremental versions of this algorithm , and use generalized hessians to allow for non differentiable cost functions .",
    "we also plan on taking such a framework to the lifelong machine learning setting .    9 nedic a. , and ozdaglar a.e .",
    ", distributed subgradient methods for multi - agent optimization , _ ieee transactions on automatic control _ , pp : 48 - 61 , 2009 .",
    "ermin w. , and ozdaglar a.e .",
    ", distributed alternating direction method of multipliers , _ ieee conference on decision and control _ , pp : 5445 - 5450 , 2012 .",
    "boyd s. , parikh n. , chu e. , peleato b. , and eckstein j. , _ distributed optimization and statistical learning via alternating direction method of multipliers _ , foundations and trends in machine learning , volume : 3 , 2011 .",
    "kadkhodaie m. , christakopoulou k. , sanjabi m. , and banerjee a. , _ accelerated direction method of multipliers _ , proceedings of the acm sigkdd international conference on knowledge discovery and data mining , 2015 .",
    "scheinberg k. , and tang x. , _ efficient inexact proximal newton method with global complexity analysis _",
    ", mathematical programming , a , 2016 .",
    "grbzbalaban m. , ozdaglar a. e. , and parrilo p. a. , _ a globally convergent incremental newton method _ , mathematical programming , 2015 .",
    "ermin w. , ozdaglar a. , and jadbabaie , a. , _ a distributed newton method for network utility maximization , ii : convergence _ , ieee transactions on automatic control , 2013 .",
    "zargham m. , ribeiro a. , ozdaglar a. e. , and jadbabaie a. , _ accelerated dual descent for network flow optimization _ , ieee transactions on automatic control , 2014 .",
    "mokhtari a. , ling q. , and ribeiro a. , _ newton newton part i : algorithm and convergence _ , arxiv e - prints , 2015 .",
    "mokhtari a. , ling q. , and ribeiro a. , _ newton newton part ii : convergence rate and implementation _ , arxiv e - prints , 2015 .",
    "peng r. , and spielman d. a. , _ an efficient parallel solver for sdd linear systems _ , symposium on theory of computing ( stoc ) , 2014 .",
    "tutunov r. , bou - ammar h. , and jadbabaie a. , _ distributed sddm solvers : theory and applications _ , arxiv e - prints , 2015 .",
    "olshevsky a. , _ linear time average consensus on fixed graphs and implications for decentralized optimization and multi - agent control _ , arxiv e - prints , 2014 .",
    "kumar a. , daum iii h. , _ learning task grouping and overlap in multi - task learning _ , international conference on machine learning ( icml ) , 2012 .",
    "lecun y. , cortes c. , _ the mnist database of handwritten digits _ , technical report , tilburg university , 2003 .",
    "maaten l.j.p , postma , e. o. , and herik , h. j. , _ dimensionality reduction : a comparative review _ , 2008 .",
    "bou - ammar h. , eaton e. , luna j. m. , and ruvolo p. , _ autonomous cross - domain knowledge transfer in lifelong policy gradient reinforcement learning _ , in the proceedings of the international joint conference on artificial intelligence ( ijcai ) , 2015 . goffin j. l. , _ on convergence rates of subgradient optimization methods _ , mathematical programming , volume : 13 , 1977 .",
    "kepner j. , and ahalt s. , _ matlabmpi _ , journal of parallel and distributed computing , elsevier volume : 64 , 2004 .",
    "kepner j. , _ parallel programming with matlabmpi _ , arxiv e - prints , 2001 .",
    "wang x. , and mitchell t. , _ detecting cognitive states using machine learning _",
    ", cmu cald technical report for summer work , 2002 .",
    "we organized appendix as follows .",
    "the proofs of lemmas  1 , 2 , 3 , 4 are presented in sections b , c , d , e .",
    "theorem 1 is proved is section f. the experimental result for reinforcement learning and london schools datasets are presented in section g. finally , the reductions of standard machine learning problems ( regression , classification , reinforcement learning ) to global consensus are given in section h.",
    "let @xmath88 , @xmath89 ,  , @xmath90 . under assumption  [ ass : two ] , the functions @xmath91 ,  , @xmath92 exhibit bounded partial derivatives with respect to @xmath93 ,  , @xmath94 .",
    "in other words , for any @xmath83 : @xmath95 , for any @xmath96 .    using the definition of @xmath158 ,",
    "the primal - dual variable system can be written as : @xmath159    taking the derivative of the above system with respect to @xmath160 gives :    @xmath161    denoting @xmath162^{\\mathsf{t}}$ ] we have : @xmath163\\boldsymbol{u}_1 = -\\boldsymbol{e}_1,\\ ] ] where @xmath164 is the first vector belonging to the standard basis of @xmath165 .",
    "similarly we can show that : @xmath163\\boldsymbol{u}_2 = -\\boldsymbol{e}_2 \\hspace{0.2 cm } [ \\nabla^2f_i]\\boldsymbol{u}_3 = -\\boldsymbol{e}_3 , \\hspace{0.1 cm } \\ldots \\hspace{0.1 cm } [ \\nabla^2f_i]\\boldsymbol{u}_p = -\\boldsymbol{e}_p,\\ ] ] with @xmath166^{\\mathsf{t}}$ ] . for convenience ,",
    "we rewrite the above systems as : @xmath167\\boldsymbol{u } = -\\boldsymbol{i}_{p\\times p},\\ ] ] where @xmath168.\\ ] ] it can be clearly seen that equation  [ matrix_form_equation_derivative ] implies : @xmath169^{-1}.\\ ] ]    hence , using @xmath170 we have for each entry of @xmath171 we have : @xmath172 the above finalizes the proof of the lemma .",
    "[ lemma : props ] the dual function @xmath101 shares the following characteristics :    * the dual hessian @xmath102 and gradient @xmath103 are given by : @xmath104 * the dual hessian is lipschitz continuous with respect to @xmath7-weighted norm , where for any @xmath105 and @xmath106 : @xmath107 , with @xmath108 , where @xmath109 is the largest eigenvalue of @xmath110 and the constants @xmath111 and @xmath75 are these given in  [ ass : two ] .",
    "consider each part separately :    1",
    ".   recall that @xmath173 minimizes the lagrangian , given by @xmath174 denote by @xmath175,\\hspace{2 mm } \\boldsymbol{y}^{+ } = \\left[\\begin{array}{c } y^{+}_1(\\boldsymbol{\\lambda})\\\\ y^{+}_2(\\boldsymbol{\\lambda})\\\\ \\vdots \\\\ y^{+}_{np}(\\boldsymbol{\\lambda})\\\\ \\end{array}\\right],\\hspace{2 mm } \\nabla f(\\boldsymbol{y}^+ ) = \\left[\\begin{array}{c } z_1(\\boldsymbol{y}^{+})\\\\ z_2(\\boldsymbol{y}^{+})\\\\ \\vdots \\\\",
    "z_{np}(\\boldsymbol{y}^{+})\\\\ \\end{array}\\right ] .",
    "\\end{aligned}\\ ] ] + using conjugate @xmath176 , the dual function can be written as : @xmath177 hence , the dual gradient is given by : @xmath178 + notice that : @xmath179 + denote @xmath180 , then the @xmath134 component of vector @xmath181 is given by : @xmath182_{k } =   \\sum_{j=1}^{np } \\frac{\\partial f^*}{\\partial u_j}\\frac{\\partial u_j}{\\partial \\lambda_k } = -\\left[\\begin{array}{cccc } m_{k1}&m_{k2}&\\cdots & m_{knp}\\\\ \\end{array}\\right]\\left[\\begin{array}{c } \\frac{\\partial f^*}{\\partial u_1}\\\\ \\frac{\\partial f^*}{\\partial u_2}\\\\ \\vdots \\\\",
    "\\frac{\\partial f^*}{\\partial u_{np}}\\\\ \\end{array}\\right]_{-\\boldsymbol{m}\\boldsymbol{\\lambda}}.\\ ] ] hence , using @xmath183 and the relation between gradients of a function and its conjugate in the expression for vector @xmath181 gives : @xmath184 applying this result in ( [ eq_1 ] ) gives : @xmath185 + from ( [ eq_3 ] ) , the dual hessian is given by : @xmath186}_{\\boldsymbol{f}(\\boldsymbol{y}^+)}. \\end{aligned}\\ ] ] in the next step we target matrix @xmath187 . using ( [ eq_2 ] ) : @xmath188 taking the partial derivative @xmath189 from the both sides of the above equation gives the following for the left and right hand sides .",
    "+ * left hand side : * @xmath190 \\\\\\nonumber & = \\left[\\begin{array}{c } \\frac{\\partial z_1(\\boldsymbol{y}^+)}{\\partial y^+_1(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_1(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } + \\frac{\\partial z_1(\\boldsymbol{y}^+)}{\\partial y^+_2(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_2(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } + \\cdots + \\frac{\\partial z_1(\\boldsymbol{y}^+)}{\\partial y^+_{np}(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_{np}(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\ \\frac{\\partial z_2(\\boldsymbol{y}^+)}{\\partial y^+_1(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_1(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } + \\frac{\\partial z_2(\\boldsymbol{y}^+)}{\\partial y^+_2(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_2(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } + \\cdots + \\frac{\\partial z_2(\\boldsymbol{y}^+)}{\\partial y^+_{np}(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_{np}(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\ \\vdots\\\\ \\frac{\\partial z_{np}(\\boldsymbol{y}^+)}{\\partial y^+_1(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_1(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } + \\frac{\\partial z_{np}(\\boldsymbol{y}^+)}{\\partial y^+_2(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_2(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } + \\cdots + \\frac{\\partial z_{np}(\\boldsymbol{y}^+)}{\\partial y^+_{np}(\\boldsymbol{\\lambda})}\\frac{\\partial y^+_{np}(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\ \\end{array}\\right ]   \\\\\\nonumber & = \\underbrace{\\left[\\begin{array}{cccc } \\frac{\\partial z_1(\\boldsymbol{y}^+)}{\\partial y^+_1(\\boldsymbol{\\lambda})}&\\frac{\\partial z_1(\\boldsymbol{y}^+)}{\\partial y^+_2(\\boldsymbol{\\lambda})}&\\cdots & \\frac{\\partial z_1(\\boldsymbol{y}^+)}{\\partial y^+_{np}(\\boldsymbol{\\lambda})}\\\\ \\frac{\\partial z_2(\\boldsymbol{y}^+)}{\\partial y^+_1(\\boldsymbol{\\lambda})}&\\frac{\\partial z_2(\\boldsymbol{y}^+)}{\\partial y^+_2(\\boldsymbol{\\lambda})}&\\cdots & \\frac{\\partial z_2(\\boldsymbol{y}^+)}{\\partial y^+_{np}(\\boldsymbol{\\lambda})}\\\\ \\vdots & & \\ddots & \\vdots \\\\ \\frac{\\partial z_{np}(\\boldsymbol{y}^+)}{\\partial y^+_1(\\boldsymbol{\\lambda})}&\\frac{\\partial z_{np}(\\boldsymbol{y}^+)}{\\partial y^+_2(\\boldsymbol{\\lambda})}&\\cdots & \\frac{\\partial z_{np}(\\boldsymbol{y}^+)}{\\partial y^+_{np}(\\boldsymbol{\\lambda})}\\\\ \\end{array}\\right]}_{\\nabla^2 f(\\boldsymbol{y}^+)}\\left[\\begin{array}{c } \\frac{\\partial y^+_1(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } \\\\",
    "\\frac{\\partial y^+_2(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\ \\vdots \\\\",
    "\\frac{\\partial y^+_{np}(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\   \\end{array}\\right ] = \\nabla^2 f(\\boldsymbol{y}^+)\\left[\\begin{array}{c } \\frac{\\partial y^+_1(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } \\\\",
    "\\frac{\\partial y^+_2(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\ \\vdots \\\\",
    "\\frac{\\partial y^+_{np}(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\   \\end{array}\\right].\\end{aligned}\\ ] ] * right hand side : * @xmath191 \\implies \\nabla^2 f(\\boldsymbol{y}^+)\\left[\\begin{array}{c } \\frac{\\partial y^+_1(\\boldsymbol{\\lambda})}{\\partial \\lambda_1 } \\\\",
    "\\frac{\\partial y^+_2(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\ \\vdots \\\\",
    "\\frac{\\partial y^+_{np}(\\boldsymbol{\\lambda})}{\\partial \\lambda_1}\\\\   \\end{array}\\right ] = - \\left[\\begin{array}{c } m_{11 } \\\\ m_{21}\\\\ \\vdots \\\\ m_{np1}\\\\   \\end{array}\\right].\\end{aligned}\\ ] ]",
    "+ repeating the same step for partial derivatives @xmath192 gives : @xmath193}_{\\boldsymbol{f}(\\boldsymbol{y}^+ ) } = -   \\underbrace{\\left[\\begin{array}{cccc } m_{11}&m_{12}&\\cdots & m_{1np}\\\\ m_{21}&m_{22}&\\cdots & m_{2np}\\\\ \\vdots & & \\ddots & \\vdots \\\\ m_{np1}&m_{np2}&\\cdots & m_{npnp}\\\\ \\end{array}\\right]}_{\\boldsymbol{m}}.\\end{aligned}\\ ] ] hence : @xmath194^{-1}\\boldsymbol{m}.\\ ] ] finally , combining this result with ( [ eq_4 ] ) gives : @xmath195^{-1}\\boldsymbol{m}.\\ ] ] 2 .",
    "to commence , we consider each of the above statements separately . noting that the proof of the first statement can be found in  @xcite , we begin with proving the second statement . +",
    "the dual hessian is lipschitz continuous with respect to @xmath7-weighted norm , where for any @xmath105 and @xmath106 : @xmath196 with @xmath197 , where @xmath109 is the largest eigenvalue of @xmath110 and the constants @xmath111 and @xmath75 are these given in  [ ass : two ] .",
    "+ we first remind the reader that weighted norm of a vector @xmath198 and matrix @xmath199 are given by : @xmath200 fixing a vector @xmath198 such that @xmath201 , then we have : @xmath202\\boldsymbol{v}\\right|\\right|^2_{\\boldsymbol{m } } & = \\left|\\left|[\\boldsymbol{m}([\\nabla^2f(\\boldsymbol{y}(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1 } ) \\boldsymbol{m}\\boldsymbol{v}]\\right|\\right|^2_{\\boldsymbol{l } } \\\\ & = \\boldsymbol{v}^{\\mathsf{t}}\\boldsymbol{m}([\\nabla^2f(\\boldsymbol{y}(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1})\\boldsymbol{m^3}([\\nabla^2f(\\boldsymbol{y}(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1})\\boldsymbol{mv } \\\\\\nonumber & \\le^{(1 ) } \\mu^3_n(\\boldsymbol{\\mathcal{l}})\\boldsymbol{v}^{\\mathsf{t}}\\boldsymbol{m}([\\nabla^2f(\\boldsymbol{y}(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1})^2\\boldsymbol{mv }   \\\\\\nonumber & \\le \\mu^3_n(\\boldsymbol{\\mathcal{l}})\\mu^2_{\\max}(|[\\nabla^2f(\\boldsymbol{y}(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1}|)\\boldsymbol{v}^{\\mathsf{t}}\\boldsymbol{m}^2\\boldsymbol{v }   \\\\\\nonumber & \\le \\mu^4_n(\\boldsymbol{\\mathcal{l}})\\mu^2_{\\max}(|[\\nabla^2f(\\boldsymbol{y}(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1}|)||\\boldsymbol{v}||^2_{\\boldsymbol{m}}.\\end{aligned}\\ ] ] hence , we can immediately write : @xmath203^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1}|)$ ] . for this purpose ,",
    "we next study the properties of primal hessian in details and recognize : + the primal hessian @xmath204 shares the following properties : @xmath205 and @xmath206^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1}| ) \\le \\delta\\max_{i\\in\\mathbb{v}}\\sqrt{\\sum_{k=1}^{p}\\left(y_k(i)(\\bar{\\boldsymbol{\\lambda } } ) - y_k(i)(\\boldsymbol{\\lambda } )   \\right)^2},\\end{aligned}\\ ] ] for any @xmath207 .",
    "+ firstly , notice that for any @xmath208 and any @xmath209 , we have : @xmath210 hence , the sparsity pattern of the primal hessian allows the symmetric reordering of rows and columns that transform @xmath211 into the block diagonal matrix as : @xmath212\\ ] ] note that @xmath213 preserves the important properties of @xmath211 .",
    "particularly , the spectrum of these two matrices are the same . that can be easily seen by considering a matrix @xmath214 and letting @xmath215 to be the operator that swaps @xmath58 and @xmath216 rows of @xmath214 .",
    "now , consider the matrix @xmath217 resultant of the swapping of the @xmath58 and @xmath216 row and column of @xmath214 . then , @xmath218 , and @xmath219 where in the last step",
    ", we used the fact that @xmath220 .",
    "since @xmath213 is constructed from @xmath204 by a symmetric reordering of rows and columns , we deduce that @xmath221 .",
    "therefore , we can write : @xmath222 which implies the property in equation  [ primal_hessian_1 ]",
    ". to prove the property in equation  [ primal_hessian_2 ] , we notice that if @xmath218 and @xmath214 is invertible , then so is @xmath217 and : @xmath223 where we used the fact that @xmath224 .",
    "let us denote @xmath225 to be a collection of operators that swap the rows of @xmath204 to transforming it to @xmath213 , i.e. : @xmath226 then , @xmath227^{-1 } = \\boldsymbol{t}_l\\cdots\\boldsymbol{t}_1\\boldsymbol{w}^{-1}(\\boldsymbol{\\lambda})\\boldsymbol{t}_1\\cdots\\boldsymbol{t}_l$ ] , and : @xmath228^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1}|| ) & = \\mu_{\\max}(\\boldsymbol{t}_l\\cdots\\boldsymbol{t}_1|\\boldsymbol{w}^{-1}(\\bar{\\boldsymbol{\\lambda } } ) - \\boldsymbol{w}^{-1}(\\boldsymbol{\\lambda})|\\boldsymbol{t}_1\\cdots\\boldsymbol{t}_l )   \\\\ & \\le \\mu_{\\max}(|\\boldsymbol{w}^{-1}(\\bar{\\boldsymbol{\\lambda } } ) - \\boldsymbol{w}^{-1}(\\boldsymbol{\\lambda})| )   \\\\\\nonumber & \\le \\max_{i\\in\\mathbb{v}}\\mu_{\\max}(|[\\nabla^2f_i(y_1(i)(\\bar{\\boldsymbol{\\lambda } } ) , \\ldots y_p(i)(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } \\\\",
    "& \\hspace{10em}- [ \\nabla^2f_i(y_1(i)(\\boldsymbol{\\lambda } ) , \\ldots y_p(i)(\\boldsymbol{\\lambda}))]^{-1}| ) \\\\\\nonumber & \\hspace{-5em}=\\max_{i\\in\\mathbb{v}}||[\\nabla^2f_i(y_1(i)(\\bar{\\boldsymbol{\\lambda } } ) , \\ldots y_p(i)(\\bar{\\boldsymbol{\\lambda}}))]^{-1 } - [ \\nabla^2f_i(y_1(i)(\\boldsymbol{\\lambda } ) , \\ldots y_p(i)(\\boldsymbol{\\lambda}))]^{-1}||_{2}\\ \\\\\\nonumber & \\le\\delta\\max_{i\\in\\mathbb{v}}||(y_1(i)(\\bar{\\boldsymbol{\\lambda } } ) , \\ldots y_p(i)(\\bar{\\boldsymbol{\\lambda } } ) ) - ( y_1(i)(\\boldsymbol{\\lambda } ) , \\ldots y_p(i)(\\boldsymbol{\\lambda}))||_{2 }   \\\\\\nonumber & = \\delta\\max_{i\\in\\mathbb{v}}\\sqrt{\\sum_{k=1}^{p}\\left(y_k(i)(\\bar{\\boldsymbol{\\lambda } } ) - y_k(i)(\\boldsymbol{\\lambda } )   \\right)^2}.\\end{aligned}\\ ] ] the above proves the property in equation  [ primal_hessian_2 ] .",
    "+ now , consider the term @xmath229 .",
    "using the result of lipschitzness on the solution of the partial differential equations , we can write : @xmath230 in the last step , we used the fact that : @xmath231 hence : @xmath232 combining this result with that from equation  [ primal_hessian_2 ] gives : @xmath233^{-1 } - [ \\nabla^2f(\\boldsymbol{y}(\\boldsymbol{\\lambda}))]^{-1}|| ) \\le\\delta\\sqrt{\\mu_n(\\boldsymbol{\\mathcal{l}})}\\frac{p}{\\gamma}||\\bar{\\boldsymbol{\\lambda } } - \\boldsymbol{\\lambda}||_{\\boldsymbol{m}}.\\ ] ] applying the previous equation to that in equation  [ norm_difference ] gives : @xmath234 + the above finalizes the statement of the claim and consequently that of the lemma .",
    "let @xmath131 } , \\dots , \\tilde{\\bm{d}}_{p}^{[k]}$ ] be the @xmath132-approximate solution to equation  [ eq : seventeen ] , then @xmath115}$ ] is an @xmath10-approximate solution to  [ eq : newtonsystem ] with @xmath133 $ ] .",
    "let @xmath235}_1 , \\ldots,\\boldsymbol{\\tilde{z}}^{[k]}_p $ ] be @xmath236 approximate solutions of the first collection of systems in equation ( 9 ) , and let @xmath237 } = [ \\nabla^2f(\\boldsymbol{y}^{[k]})]^{-1}\\boldsymbol{\\tilde{z}}^{[k]}$ ] .",
    "denote vectors @xmath238}_1 , \\ldots , \\boldsymbol{\\hat{d}}^{[k]}_p$ ] be the exact solution of : @xmath239}_1 = \\boldsymbol{\\tilde{b}}^{[k]}_1 \\\\",
    "\\boldsymbol{\\mathcal{l}d}^{[k]}_2 = \\boldsymbol{\\tilde{b}}^{[k]}_2 \\\\ \\vdots \\\\ \\boldsymbol{\\mathcal{l}d}^{[k]}_p = \\boldsymbol{\\tilde{b}}^{[k]}_p . \\end{cases}\\ ] ] we next denote the exact solution of the system in equation  8 as : @xmath240 } = \\left [ \\begin{array}{c } \\boldsymbol{d}^{*[k]}_1\\\\ \\boldsymbol{d}^{*[k]}_2\\\\ \\vdots\\\\ \\boldsymbol{d}^{*[k]}_p \\end{array } \\right].\\ ] ] second , we let @xmath241 } = \\left[\\nabla^2f(\\boldsymbol{y}^{[k]})\\right]^{-1}\\boldsymbol{m}\\boldsymbol{d}^{*[k ] } = [ ( \\boldsymbol{z}^{*[k]}_1)^{\\mathsf{t } } , \\ldots , ( \\boldsymbol{z}^{*[k]}_p)^{\\mathsf{t}}]^{\\mathsf{t}}$ ] be the corresponding vector @xmath242}$ ] . hence : @xmath243}_1 =   \\boldsymbol{\\mathcal{l}}\\boldsymbol{y}^{[k]}_1 \\\\   \\boldsymbol{\\mathcal{l}z}^{*[k]}_2 =   \\boldsymbol{\\mathcal{l}}\\boldsymbol{y}^{[k]}_2 \\\\ \\vdots \\\\ \\boldsymbol{\\mathcal{l}z}^{*[k]}_p =   \\boldsymbol{\\mathcal{l}}\\boldsymbol{y}^{[k]}_p .",
    "\\end{cases}\\ ] ]    now , let @xmath235}_1 , \\ldots , \\boldsymbol{\\tilde{z}}^{[k]}_p$ ] be the @xmath236-approximate solutions of ( [ exact_z_decomposition ] ) , and @xmath238}_1 , \\ldots , \\boldsymbol{\\hat{d}}^{[k]}_p$ ] and @xmath244}_1 , \\ldots , \\tilde{\\boldsymbol{d}}^{[k]}_p$ ] be the exact and @xmath245approximate solutions of the following systems :    @xmath246}_1 = \\boldsymbol{\\tilde{b}}^{[k]}_1 \\\\",
    "\\boldsymbol{\\mathcal{l}d}^{[k]}_2 = \\boldsymbol{\\tilde{b}}^{[k]}_2 \\\\ \\vdots \\\\ \\boldsymbol{\\mathcal{l}d}^{[k]}_p = \\boldsymbol{\\tilde{b}}^{[k]}_p ,   \\end{cases}\\ ] ]    with @xmath237 } = [ \\nabla^2f(\\boldsymbol{y}^{[k]})]^{-1}\\boldsymbol{\\tilde{z}}^{[k ] } = [ ( \\boldsymbol{\\tilde{b}}^{[k]}_1)^{\\mathsf{t } } , \\ldots ,   ( \\boldsymbol{\\tilde{b}}^{[k]}_p)^{\\mathsf{t}}]^{\\mathsf{t}}$ ] .",
    "now , we prove the following :    1 .",
    "notice that @xmath247 in terms of @xmath238}$ ] and @xmath248}$ ] : @xmath249})^{\\mathsf{t}}\\boldsymbol{m}[\\nabla^2f(\\boldsymbol{y}^{[k]})]^{-2}\\boldsymbol{m}\\boldsymbol{d}^{*[k ] } \\le \\frac{\\mu_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}(\\boldsymbol{d}^{*[k]})^{\\mathsf{t}}\\boldsymbol{m}[\\nabla^2f(\\boldsymbol{y}^{[k]})]^{-1}\\boldsymbol{m}\\boldsymbol{d}^{*[k ] }   \\\\\\nonumber & = \\frac{\\mu_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}||\\boldsymbol{d}^{*[k]}||^2_{\\boldsymbol{h}^{[k]}}.\\end{aligned}\\ ] ] similarly : @xmath250 } -\\boldsymbol{d}^{*[k]})^{\\mathsf{t}}\\boldsymbol{m}[\\nabla^2f(\\boldsymbol{y}^{[k]})]^{-1 } \\boldsymbol{m } [ \\nabla^2f(\\boldsymbol{y}^{[k]})]^{-1 } \\boldsymbol{m}(\\boldsymbol{\\hat{d}}^{[k ] } -\\boldsymbol{d}^{*[k ] } ) \\\\\\nonumber & \\ge\\frac{1}{\\mu_n(\\boldsymbol{\\mathcal{l}})}(\\boldsymbol{\\hat{d}}^{[k ] } -\\boldsymbol{d}^{*[k]})^{\\mathsf{t}}[\\boldsymbol{h^{[k]}}]^{2}(\\boldsymbol{\\hat{d}}^{[k ] } -\\boldsymbol{d}^{*[k ] } ) \\ge \\frac{1}{\\gamma}\\frac{\\mu^2_2(\\boldsymbol{\\mathcal{l}})}{\\mu_n(\\boldsymbol{\\mathcal{l}})}||\\boldsymbol{\\hat{d}}^{[k ] } -\\boldsymbol{d}^{*[k]}||^2_{\\boldsymbol{h}^{[k]}},\\end{aligned}\\ ] ] where we use the fact that @xmath251})]^{-1}\\boldsymbol{m}[\\nabla^2f(\\boldsymbol{y}^{[k]})]^{-1}\\boldsymbol{m } \\succeq \\frac{1}{\\mu_n(\\boldsymbol{\\mathcal{l}})}[\\boldsymbol{h}^{[k]}]^2 $ ] .",
    "the last transition follows from the fact that @xmath252 } ) = \\ker(\\boldsymbol{m})$ ] and , therefore : @xmath253}]^2 = [ \\boldsymbol{h}^{[k]}]^{\\frac{1}{2}}\\boldsymbol{h}^{[k]}[\\boldsymbol{h}^{[k]}]^{\\frac{1}{2 } } \\succeq \\frac{1}{\\gamma}\\boldsymbol{h}^{[k]}]^{\\frac{1}{2}}\\boldsymbol{m}^{2}[\\boldsymbol{h}^{[k]}]^{\\frac{1}{2 } } \\succeq \\frac{\\mu^2_2(\\boldsymbol{\\mathcal{l}})}{\\gamma}\\boldsymbol{h}^{[k]}.\\ ] ] combining the above results for ( [ addit_equa_z_vectors ] ) immediately gives : @xmath254 } -\\boldsymbol{d}^{*[k]}||^2_{\\boldsymbol{h}^{[k ] } } \\le \\epsilon^2_0\\frac{\\mu^2_n(\\boldsymbol{\\mathcal{l}})}{\\mu^2_2(\\boldsymbol{\\mathcal{l}})}\\frac{\\gamma}{\\gamma}||\\boldsymbol{d}^{*[k]}||^2_{\\boldsymbol{h}^{[k ] } } = \\epsilon^2_1||\\boldsymbol{d}^{*[k]}||^2_{\\boldsymbol{h}^{[k]}}\\end{aligned}\\ ] ] with @xmath255 .",
    ", we use the triangular inequality : @xmath256}_1 , \\ldots , \\boldsymbol{\\tilde{d}}^{[k]}_p$ ] , we can write : @xmath257 } - \\boldsymbol{d}^{*[k]})^{\\mathsf{t}}\\boldsymbol{m}^2(\\boldsymbol{\\tilde{d}}^{[k ] } - \\boldsymbol{d}^{*[k ] } ) \\le \\frac{\\mu_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}||\\boldsymbol{\\tilde{d}}^{[k ] } - \\boldsymbol{d}^{*[k]}||^2_{\\boldsymbol{m } } \\le \\epsilon^2_0\\frac{\\mu_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}||\\boldsymbol{\\hat{d}}^{[k]}||^2_{\\boldsymbol{m } } \\\\\\nonumber & \\le \\epsilon^2_0\\frac{\\mu_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}\\frac{\\gamma}{\\mu_2(\\boldsymbol{\\mathcal{l}})}||\\boldsymbol{\\hat{d}}^{[k]}||^2_{\\boldsymbol{h}^{[k]}},\\end{aligned}\\ ] ] where we used @xmath258 } \\succeq \\frac{\\gamma}{\\mu_2(\\boldsymbol{\\mathcal{l}})}\\boldsymbol{m}$ ] .",
    "hence : @xmath259 , it follows that : @xmath260 , [ intermediate_result_21_1 ] , and [ intermediate_result_21_2 ] , in equation  [ addit_ineq_triangul ] , yields : @xmath261||\\boldsymbol{d}^{*[k]}||_{\\boldsymbol{h}^{[k ] } } = \\epsilon||\\boldsymbol{d}^{*[k]}||_{\\boldsymbol{h}^{[k]}}.\\end{aligned}\\ ] ]    the above finalizes the statement of the lemma .",
    "let @xmath117 } = \\nabla q\\left(\\bm{\\lambda}^{[k]}\\right)$ ] be the dual gradient at the @xmath134 iteration . then : @xmath135}\\right|\\right|_{\\bm{m } } & \\leq \\left[1 -\\alpha_{k } + \\epsilon \\alpha_{k } \\sqrt{\\frac{\\gamma}{\\gamma } \\frac{\\mu_{n}^{3}(\\mathcal{l})}{\\mu_{2}^{3}(\\mathcal{l})}}\\right]\\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m } } + \\frac{b(\\alpha_{k } ( 1+\\epsilon))^{2}}{2\\mu_{2}^{4}(\\mathcal{l } ) } \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}.\\end{aligned}\\ ] ]    we start with the following claim , which plays a crucial role in our analysis :    [ claim_1 ] let @xmath262 be the dual gradient and @xmath263 its hessian , then for any @xmath264 : @xmath265 that implies for any two vectors @xmath266 and @xmath267 in @xmath268 we have : @xmath269 we proceed by adding and subtracting @xmath270 to the integral in the right hand side of equation  [ fundamental_result2 ] : @xmath271 ( \\bar{\\boldsymbol{\\lambda}}-\\boldsymbol{\\lambda})+\\boldsymbol{h}(\\boldsymbol{\\lambda})(\\bar{\\boldsymbol{\\lambda}}-\\boldsymbol{\\lambda})\\ dt.\\end{aligned}\\ ] ] consequently , we can separate the integral in equation  [ taylor_first_two terms_44 ] as : @xmath272 ( \\bar{\\boldsymbol{\\lambda}}-\\boldsymbol{\\lambda})\\ dt+\\int_{0}^1 \\boldsymbol{h}(\\boldsymbol{\\lambda})(\\bar{\\boldsymbol{\\lambda}}-\\boldsymbol{\\lambda})\\ dt.\\end{aligned}\\ ] ] the second integral on the right hand side of equation  [ taylor_first_two terms_45 ] is independent of @xmath1 . therefore",
    ", we can simplify the integral as @xmath273 , which implies : @xmath274 ( \\bar{\\boldsymbol{\\lambda}}-\\boldsymbol{\\lambda})\\ dt.\\end{aligned}\\ ] ] by rearranging the terms in equation  [ taylor_first_two terms_46 ] and taking the norm of both sides we obtain : @xmath275 ( \\bar{\\boldsymbol{\\lambda}}-\\boldsymbol{\\lambda})\\ dt\\right|\\right|_{\\boldsymbol{m}}\\end{aligned}\\ ] ] considering the inequality in equation  [ taylor_first_two terms_47 ] and the fact that norm of integral is less than the integral of the norms , we can write : @xmath276 ( \\bar{\\boldsymbol{\\lambda}}-\\boldsymbol{\\lambda } ) \\right|\\right|_{\\boldsymbol{m}}\\ dt.\\end{aligned}\\ ] ] now , we can prove the following claim :    let @xmath263 be the hessian of the dual function @xmath277 . then for any @xmath278 : @xmath279\\boldsymbol{v}||_{\\boldsymbol{m } } \\le ||\\boldsymbol{h}(\\bar{\\boldsymbol{\\lambda } } ) - \\boldsymbol{h}(\\boldsymbol{\\lambda})||_{\\boldsymbol{m}}||\\bm{v}||_{\\boldsymbol{m}}\\end{aligned}\\ ] ]    lemma  7 gives : @xmath280^{-1}\\boldsymbol{m}.\\ ] ] now , let us consider the following three cases :    1 .",
    "@xmath281 : in this case equation  [ claim_result_2 ] follows immediately from the definition : @xmath282 .",
    "@xmath283 : in this case @xmath284 , and @xmath285\\boldsymbol{v } = \\boldsymbol{0 } - \\boldsymbol{0 } = \\boldsymbol{0}$ ] .",
    "@xmath286 , where @xmath287 . in this case @xmath288 , and using the first case result for @xmath289 , we have : @xmath290\\boldsymbol{v}||_{\\boldsymbol{m } } = ||[\\boldsymbol{h}(\\bar{\\boldsymbol{\\lambda } } ) - \\boldsymbol{h}(\\boldsymbol{\\lambda})]\\boldsymbol{u}_1||_{\\boldsymbol{m } } \\le \\\\\\nonumber & ||\\boldsymbol{h}(\\bar{\\boldsymbol{\\lambda } } ) - \\boldsymbol{h}(\\boldsymbol{\\lambda})||_{\\boldsymbol{m}}||\\boldsymbol{u}_1||_{\\boldsymbol{m } } = ||\\boldsymbol{h}(\\bar{\\boldsymbol{\\lambda } } ) - \\boldsymbol{h}(\\boldsymbol{\\lambda})||_{\\boldsymbol{m}}||\\boldsymbol{v}||_{\\boldsymbol{m}}\\end{aligned}\\ ] ]    this finishes the proof of the claim .",
    "applying the above result to equation  [ taylor_first_two terms_48 ] gives : @xmath291 this finishes the proof of claim [ claim_1 ] .    applying the result of claim  [ claim_1 ] to @xmath292}$ ] and @xmath293}$ ] gives : @xmath294 } - \\boldsymbol{g}^{[k ] } - \\alpha_k\\boldsymbol{h}^{[k]}\\tilde{\\boldsymbol{d}}^{[k]}||_{\\boldsymbol{m } } \\le \\frac{b\\alpha^2_k}{2}||\\tilde{\\boldsymbol{d}}^{[k]}||^2_{\\boldsymbol{m}}.\\ ] ] applying the triangular inequality , we have : @xmath295}||^2_{\\boldsymbol{m}}$ ] and @xmath296 } + \\alpha_k\\boldsymbol{h}^{[k]}\\tilde{\\boldsymbol{d}}^{[k]}||_{\\boldsymbol{m}}$ ] :    1 .   to upper bound @xmath297}||^2_{\\boldsymbol{m}}$ ]",
    "notice that : @xmath298}\\preceq \\frac{\\mu_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}\\boldsymbol{m}.\\ ] ] hence : @xmath299})^{\\mathsf{t}}\\boldsymbol{h}^{[k]}\\boldsymbol{d}^{*[k ] } = ( 1 + \\epsilon)^2\\frac{\\gamma}{\\mu_2(\\boldsymbol{\\mathcal{l}})}(\\boldsymbol{g}^{[k]})^{\\mathsf{t}}(\\boldsymbol{h}^{[k]})^{\\dagger}\\boldsymbol{h}^{[k]}(\\boldsymbol{h}^{[k]})^{\\dagger}\\boldsymbol{g}^{[k ] } \\\\\\nonumber & = ( 1 + \\epsilon)^2\\frac{\\gamma}{\\mu_2(\\boldsymbol{\\mathcal{l}})}(\\boldsymbol{g}^{[k]})^{\\mathsf{t}}(\\boldsymbol{h}^{[k]})^{\\dagger}\\boldsymbol{g}^{[k]}.\\end{aligned}\\ ] ] because @xmath300 } \\in \\ker\\{\\boldsymbol{h}^{[k]}\\ } = \\ker\\{\\boldsymbol{m}\\}$ ] and using the result in equation  [ hessian_primal_lower_upper_bounds ] , it follows that : @xmath301 is the second smallest eigenvalue of @xmath302 which is equal to @xmath303 .",
    "2 .   let us denote @xmath304 } = \\tilde{\\boldsymbol{d}}^{[k ] } - \\boldsymbol{d}^{*[k]}$ ] , then : @xmath305}||_{\\boldsymbol{h}^{[k ] } } \\le \\epsilon||\\boldsymbol{d}^{*[k]}||_{\\boldsymbol{h}^{[k]}}\\ ] ] therefore , for the term @xmath296 } + \\alpha_k\\boldsymbol{h}^{[k]}\\tilde{\\boldsymbol{d}}^{[k]}||_{\\boldsymbol{m}}$ ] we can write : @xmath306 } - \\alpha_k\\boldsymbol{g}^{[k ] } + \\alpha_k\\boldsymbol{h}^{[k]}\\boldsymbol{c}^{[k]}||_{\\boldsymbol{m } } \\le ( 1 - \\alpha_k)||\\boldsymbol{g}^{[k]}||_{\\boldsymbol{m } } + \\alpha_k||\\boldsymbol{h}^{[k]}\\boldsymbol{c}^{[k]}||_{\\boldsymbol{m}}.\\end{aligned}\\ ] ] therefore , our goal now is to upper bound the term @xmath307}\\boldsymbol{c}^{[k]}||_{\\boldsymbol{m}}$ ] .",
    "using equation  [ hessian_primal_lower_upper_bounds ] and the fact that @xmath308 , we have : @xmath309})^{\\mathsf{t}}\\boldsymbol{h}^{[k]}\\boldsymbol{c}^{[k ] } \\le \\epsilon^2\\frac{\\mu^3_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}||\\boldsymbol{d}^{*[k]}||^2_{\\boldsymbol{h}^{[k ] } } \\\\\\nonumber & = \\epsilon^2\\frac{\\mu^3_n(\\boldsymbol{\\mathcal{l}})}{\\gamma}(\\boldsymbol{g}^{[k]})^{\\mathsf{t}}(\\boldsymbol{h}^{[k]})^{\\dagger}\\boldsymbol{g}^{[k ] } \\le \\epsilon^2\\frac{\\mu^3_n(\\boldsymbol{\\mathcal{l}})}{\\gamma } \\frac{\\gamma}{\\mu^3_2(\\boldsymbol{\\mathcal{l}})}||\\boldsymbol{g}^{[k]}||^2_{\\boldsymbol{m } }   \\end{aligned}\\ ] ] therefore : @xmath310}\\boldsymbol{c}^{[k]}||_{\\boldsymbol{m } } \\le \\epsilon\\sqrt{\\frac{\\gamma}{\\gamma}\\frac{\\mu^3_n(\\boldsymbol{\\mathcal{l}})}{\\mu^3_2(\\boldsymbol{\\mathcal{l}})}}||\\boldsymbol{g}^{[k]}||_{\\boldsymbol{m}}.\\ ] ] applying this result in equation  [ intermediate_equation_for_case_2 ] gives : @xmath311 and  [ gradient_plus_approx_newton_bound ] , in equation  [ gradient_norm_inequality_interm ] : @xmath312 proof convergence phases ------------------------    let @xmath136 , @xmath111 , be the constants defined in assumption  [ ass : two ] , @xmath109 , @xmath137 be the largest and the second smallest eigenvalues of @xmath110 , respectively , and @xmath138 $ ] .",
    "consider the following iteration scheme : @xmath112}=\\bm{\\lambda}^{[k ] } + \\alpha^{\\star } \\tilde{\\bm{d}}^{[k]}$ ] , where @xmath139 .",
    "then the distributed newton algorithm exhibits the following convergence phases :    * * strict decrease phase : * while @xmath140}\\right|\\right|_{\\bm{m } } \\geq \\eta_{1}$ ] : @xmath141}\\right)-q\\left(\\bm{\\lambda}^{[k]}\\right ) \\leq -\\frac{\\gamma^{3}}{\\gamma^{2}}\\left(\\frac{1-\\epsilon}{1+\\epsilon}\\right)^{2}\\frac{\\mu_{2}^{4}(\\mathcal{l})}{\\mu_{n}^{7}(\\mathcal{l } ) } \\eta_{1}^{2}$ ] , * * quadratic decrease phase : * while @xmath142}\\right|\\right|_{\\bm{m } } \\leq \\eta_{1}$ ] : @xmath143}\\right|\\right|_{\\bm{m } } \\leq \\frac{1}{\\eta_{1}}\\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2}$ ] , * * terminal phase : * while @xmath140}\\right|\\right|_{\\bm{m } } \\leq \\eta_{0}$ ] : @xmath143}\\right|\\right|_{\\bm{m } } \\leq \\zeta \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}$ ] , where @xmath144 , @xmath145 , and @xmath146 } , \\ \\ \\ \\xi= \\frac{b(\\alpha_{k}\\gamma(1+\\epsilon))^{2}}{2\\mu_{2}^{4}(\\mathcal{l})}$ ] .",
    "we will proof each phase separately .",
    "we start with phase one when @xmath140}\\right|\\right|_{\\bm{m } } \\geq \\eta$ ] .",
    "taking the taylor expansion of the dual function gives : @xmath313}\\right)= q\\left(\\bm{\\lambda}^{[k]}\\right)+ \\left(\\bm{g}^{[k]}\\right)^{\\mathsf{t}}\\left(\\bm{\\lambda}^{[k+1 ] } - \\bm{\\lambda}^{[k]}\\right ) + \\frac{1}{2 } \\left(\\bm{\\lambda}^{[k+1 ] } - \\bm{\\lambda}^{[k]}\\right)^{\\mathsf{t}}\\bm{h}(\\bm{z})\\left(\\bm{\\lambda}^{[k+1 ] } - \\bm{\\lambda}^{[k]}\\right ) \\\\ % & = q\\left(\\bm{\\lambda}^{[k]}\\right ) + \\alpha_{k } \\left(\\bm{g}^{[k]}\\right)^{\\mathsf{t}}\\tilde{\\bm{d}}^{[k ] } \\\\ % & \\hspace{7em}+ \\frac{\\alpha_{k}^{2}}{2 } \\left(\\tilde{\\bm{d}}^{[k]}\\right)^{\\mathsf{t}}\\bm{h}(\\bm{z } ) \\tilde{\\bm{d}}^{[k ] } \\\\ &",
    "\\leq q\\left(\\bm{\\lambda}^{[k]}\\right ) + \\alpha_{k } \\bm{g}^{[k],\\mathsf{t}}\\tilde{\\bm{d}}^{[k]}+ \\frac{\\alpha_{k}^{2}}{2 } \\frac{\\mu_{n}(\\mathcal{l})}{\\gamma}\\tilde{\\bm{d}}^{[k],\\mathsf{t}}\\bm{m } \\tilde{\\bm{d}}^{[k ] } = q\\left(\\bm{\\lambda}^{[k]}\\right ) + \\alpha_{k}\\bm{g}^{[k],\\mathsf{t}}\\tilde{\\bm{d}}^{[k ] }   + \\frac{\\alpha_{k}^{2}}{2}\\frac{\\mu_{n}(\\mathcal{l})}{\\gamma } \\left|\\left|\\tilde{\\bm{d}}^{[k]}\\right|\\right|_{\\bm{m}}^{2}. \\end{aligned}\\ ] ] therefore , we can prove that : @xmath314}\\right|\\right|_{\\bm{m}}^{2 } \\leq ( 1+\\epsilon)^{2 } \\frac{\\gamma^{2}}{\\mu_{2}^{4}(\\mathcal{l})}\\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2}.\\ ] ] to proceed , the goal now is to bound @xmath315}\\right)^{\\mathsf{t}}\\tilde{\\bm{d}}^{[k]}$ ] .",
    "noticing that @xmath315}\\right)^{\\mathsf{t}}\\tilde{\\bm{d}}^{[k]}= - \\left(\\tilde{\\bm{d}}^{[k]}\\right)^{\\mathsf{t}}\\bm{h}^{[k]}\\bm{d}^{\\star , [ k]}$ ] and using that @xmath115}$ ] is the @xmath10-approximate solution , we have : @xmath316,\\mathsf{t}}\\bm{h}^{[k]}\\bm{d}^{\\star,[k ] } & \\leq - ( 1-\\epsilon)^{2}||\\bm{d}^{\\star,[k]}||_{\\bm{h}^{[k]}}^{2 } - ||\\tilde{\\bm{d}}^{[k]}||_{\\bm{h}^{[k]}}^{2}.\\end{aligned}\\ ] ] now , notice that : @xmath317}\\right|\\right|_{\\bm{h}^{[k]}}^{2 } = \\left(\\bm{g}^{[k]}\\right)^{\\mathsf{t}}\\left(\\bm{h}^{[k]}\\right)^{\\dagger}\\bm{g}^{[k]}\\geq \\frac{\\gamma}{\\mu_{n}^{3}(\\mathcal{l})}\\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2},\\end{aligned}\\ ] ] and @xmath318}\\right|\\right|_{\\bm{h}^{[k]}}^{2 } \\leq ( 1-\\epsilon)^{2 } \\frac{\\gamma}{\\mu_{n}^{3 } ( \\mathcal{l } ) } \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2}.\\end{aligned}\\ ] ] consequently , we can write : @xmath319}\\right)^{\\mathsf{t } } \\tilde{\\bm{d}}^{[k ] } \\leq - ( 1-\\epsilon ) \\frac{\\gamma}{\\mu_{n}^{3}(\\mathcal{l } ) } \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2}. \\end{aligned}\\ ] ] therefore @xmath320}\\right)- q\\left(\\bm{\\lambda}^{[k]}\\right ) & \\leq - \\bigg [ ( 1-\\epsilon ) \\frac{\\gamma}{\\mu_{n}^{3}(\\mathcal{l})}\\alpha_{k }    - \\frac{\\mu_{n}(\\mathcal{l})\\gamma^{2 } ( 1+\\epsilon)^{2}}{2\\gamma \\mu_{2}^{4}(\\mathcal{l})}\\alpha_{k}^{2 } \\bigg]\\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2}.\\end{aligned}\\ ] ] hence , choosing @xmath321 and using @xmath140}\\right|\\right|_{\\bm{m}}^{2 } \\geq \\eta_{1}$ ] , we arrive at the strict decrease phase . to prove the quadratic decrease phase , we let @xmath142}\\right|\\right|_{\\bm{m}}^{2 } < \\eta$ ] .",
    "it immediately follows that : @xmath135}\\right|\\right|_{\\bm{m } } \\leq \\xi \\left(\\frac{\\zeta}{1-\\zeta } + 1\\right ) \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2 }   = \\frac{1}{\\eta_1 } \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}^{2}.\\end{aligned}\\ ] ]    finally for @xmath140}\\right|\\right|_{\\bm{m}}^{2 } < \\eta_{0}$ ] , we have @xmath322}\\right|\\right|_{\\bm{m } } \\leq \\zeta \\left|\\left|\\bm{g}^{[k]}\\right|\\right|_{\\bm{m}}.\\ ] ] the above finalizes the statement of the theorem .",
    "the london schools data set consists of examination scores from 15,362 students in 139 schools .",
    "this is a benchmark regression task with a goal of predicting examination scores of each student .",
    "we use the same feature encoding used in  @xcite , where four school - specific categorical variables along with three student - specific categorical variables are encoded as a collection of binary features .",
    "in addition , we use the examination year and a bias term as additional features , giving each data instance 27 features .",
    "we considered the policy search framework to control a double cart - pole system ( dcp ) .",
    "as detailed in  @xcite , the dcp adds a second inverted pendulum to the standard cart - pole system , with six parameters and six state features . the goal is to balance both poles upright .",
    "we generated 20,000 rollouts each with a length of 150 time steps .",
    "in linear regression , we assume a data set @xmath323 , with @xmath324 being the dependent variable and @xmath325 denoting the independent vector . we further assume that the input data points have been transformed using a relevant feature extractor , leading to @xmath326 . distributing the standard sum - of - squares - error objective ,",
    "the goal in distributed linear regression is to determine a set of latent parameters @xmath327 which minimize : @xmath328 with @xmath329 being a latent parameter determined by each processor , and @xmath330 with @xmath331 being a regularization parameter s were fixed for all nodes .",
    "these were set for values between \\{0.01 , 0.02 , 0.05 , 0.06 , 0.1 } depending on the size of input dataset .",
    "] , and @xmath332 . to simplify the computations ,",
    "next we rewrite equation  [ eq : chunklinear ] in an equivalent matrix - vector form :    @xmath333}_{\\boldsymbol{p}_i}\\boldsymbol{\\theta}_i - 2\\left(\\underbrace{\\sum_{j=1}^{m_i}a_j\\boldsymbol{b}_j}_{\\boldsymbol{c}_i}\\right)^{\\mathsf{t}}\\boldsymbol{\\theta}_i + \\underbrace{\\sum_{j=1}^{m_i}a^2_j}_{u_i } = \\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{p}_i\\boldsymbol{\\theta}_i - 2\\boldsymbol{c}^{\\mathsf{t}}_i\\boldsymbol{\\theta}_i + u_i.\\end{aligned}\\ ] ]            \\end{block } \\end{blockarray}\\quad \\in \\mathbb{r}^{p\\times m_i } \\ \\ \\ \\ \\ \\ \\ \\ \\text{and } \\ \\ \\ \\ \\ \\ \\ \\ \\boldsymbol{a}_i =   \\left [ \\begin{array}{c } a_1\\\\ a_2\\\\ \\vdots\\\\ a_{m_i } \\end{array } \\right]\\in\\mathbb{r}^{m_i}.\\ ] ]        where @xmath338^{\\mathsf{t}}$ ] , and : @xmath339_{kl}y_k(i)y_l(i ) - 2\\sum_{k=1}^p[\\boldsymbol{c}_i]_ky_k(i ) + u^2_i.\\end{aligned}\\ ] ] hence , the lagrangian of the problem can be written as : @xmath340.\\end{aligned}\\ ] ] therefore , the primal variables can be recovered using : @xmath341_{[\\boldsymbol{\\lambda}_1 , \\ldots , \\boldsymbol{\\lambda}_p ] } = \\boldsymbol{p}^{-1}_i\\left[\\boldsymbol{c}_i - \\frac{1}{2}(\\boldsymbol{l\\lambda})(i,:)]^{\\mathsf{t}}\\right],\\ ] ] where @xmath342 is @xmath58 row of @xmath343 .",
    "note , that to apply the symmetric diagonally dominant the second time the hessian of the local objective function @xmath344 must be computed .",
    "it is easy to see , that @xmath345 .        1 .",
    "* initialization : * chose arbitrary @xmath346}_{i } \\in\\mathbb{r}^{p}$ ] and @xmath347}_{ji}\\in\\mathbb{r}^p$ ] for @xmath348 for @xmath349 .",
    "2 .   * for * @xmath350 1 .",
    "each agent @xmath46 updates its estimate of @xmath351}_i$ ] in a sequential order with @xmath352}_i = \\arg\\min_{\\boldsymbol{\\theta}^{}_i}\\left(\\underbrace{f_i(\\boldsymbol{\\theta}^{}_i ) + \\frac{\\beta}{2}\\sum_{j\\in p(i)}\\left|\\left|\\boldsymbol{\\theta}^{[k+1]}_j - \\boldsymbol{\\theta}^{}_i - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji }   \\right|\\right|^2 + \\frac{\\beta}{2}\\sum_{j\\in s(i)}\\left|\\left|\\boldsymbol{\\theta}_i - \\boldsymbol{\\theta}^{[k]}_j - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right|\\right|^2}_{\\xi_i}\\right).\\end{aligned}\\ ] ] 2 .",
    "each agent updates @xmath353 for @xmath354 as follows : @xmath355}_{ji } = \\boldsymbol{\\lambda}^{[k]}_{ji } - \\beta(\\boldsymbol{\\theta}^{[k+1]}_j - \\boldsymbol{\\theta}^{[k+1]}_i).\\ ] ]    we can get the closed form solution for ( [ serega_dalbich_111 ] ) : @xmath356}_j   + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_{j } - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right ] \\right ) = \\\\\\nonumber & 2\\boldsymbol{p}_i\\boldsymbol{\\theta}_i - 2\\boldsymbol{c}_i + \\beta d(i)\\boldsymbol{\\theta}_i - \\beta\\left(\\sum_{j\\in s(i)}\\left[\\boldsymbol{\\theta}^{[k]}_j   + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_{j } - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right ] \\right).\\end{aligned}\\ ] ] hence , for the iterative rule ( [ serega_dalbich_11 ] ) : @xmath357}_i = \\left[\\boldsymbol{p}_i + \\frac{\\beta d(i)}{2}\\boldsymbol{i}_{p\\times p}\\right]^{-1}\\left(\\boldsymbol{c}_i + \\frac{\\beta}{2}\\left(\\sum_{j\\in s(i)}\\left[\\boldsymbol{\\theta}^{[k]}_j   + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_{j } - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right ] \\right ) \\right).\\ ] ]          where @xmath362 is a step - size and @xmath363 is the sub - gradient of @xmath364 evaluated at @xmath365 , i.e. : @xmath366 after @xmath367 iterations the node @xmath358 computes the average @xmath368 as a solution .",
    "next , we repeat the above for logistic regression considering both smooth and non - smooth regularizers .",
    "we consider a data set defined by the following collection @xmath369 with @xmath370 representing a class and @xmath371 .",
    "similar to the linear regression case , the goal is to determine the solution of the following objective : @xmath372 here , however , each local cost is given as a logistic loss defined as :              it is easy to see that equation  [ local_objective_11 ] can be simplified as : @xmath378 + \\mu_i m_i||\\boldsymbol{\\theta}_i||^2_2   \\\\\\nonumber & = -\\sum_{j=1}^{m_i}\\left[a_j\\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{b}_j - \\log(1 + e^{\\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{b}_j})\\right ] + \\mu_i m_i||\\boldsymbol{\\theta}_i||^2_2   \\\\ & = -\\left(\\sum_{j=1}^{m_i}a_j\\boldsymbol{b}_j\\right)^{\\mathsf{t}}\\boldsymbol{\\theta}_i + \\sum_{j=1}^{m_i}\\log(1 + e^{\\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{b}_j } ) + \\mu_im_i||\\boldsymbol{\\theta}_i||^2_2.\\end{aligned}\\ ] ] introducing @xmath379\\hspace{0.2 cm } \\boldsymbol{y}_2 = \\left [ \\begin{array}{c } \\theta_1(2)\\\\ \\theta_2(2)\\\\ \\vdots\\\\ \\theta_n(2 ) \\end{array } \\right]\\hspace{0.1cm}\\ldots \\boldsymbol{y}_p = \\left [ \\begin{array}{c } \\theta_1(p)\\\\ \\theta_2(p)\\\\ \\vdots\\\\ \\theta_n(p ) \\end{array } \\right]\\ ] ] and @xmath380\\hspace{0.2 cm } \\boldsymbol{b}_2 = \\left [ \\begin{array}{c } b_2(1)\\\\ b_2(2)\\\\ \\vdots\\\\ b_2(p ) \\end{array } \\right]\\hspace{0.1cm}\\ldots \\boldsymbol{b}_{m_i } = \\left [ \\begin{array}{c } b_{m_i}(1)\\\\ b_{m_i}(2)\\\\ \\vdots\\\\ b_{m_i}(p ) \\end{array } \\right],\\ ] ] the above problem can be rewritten as : @xmath381 where @xmath338^{\\mathsf{t}}$ ] . using equation  [ local_objective_11 ] : @xmath382 hence , the lagrangian of the above problem can be written as : @xmath383.\\end{aligned}\\ ] ] to define the relation between primal an dual variables , each node @xmath358 needs to solve the corresponding optimization problem of the form : @xmath384 applying the standard newton method for equation  [ primal_dual_relation_1 ] : @xmath385_{(t+1 ) } =   \\hspace{0.2 cm } \\left [ \\begin{array}{c } y_1(i)\\\\ y_2(i)\\\\ \\vdots\\\\ y_p(i ) \\end{array } \\right]_{(t ) } - \\hspace{0.1 cm } \\alpha_t\\boldsymbol{y}^{[i]}_{newton}|_{(t)},\\ ] ] where @xmath1 is the iteration count , and @xmath386}_{newton}|_{(t)}$ ] is newton direction , evaluated at @xmath387_{(t)}$ ] , and given by the solution of the following system : @xmath388}_{newton}|_{(t ) } = - \\nabla\\zeta_i|_{(t)},\\ ] ] with @xmath389 and @xmath390 being the hessian and noting that the gradient of @xmath391 is evaluated at @xmath387_{(t)}$ ] .",
    "the components of the gradient @xmath390 can be computed as : @xmath392b_j(1 ) + 2\\mu_im_iy_1(i)_{(t ) } + ( \\boldsymbol{l\\lambda}_1)_i \\\\\\nonumber & \\frac{\\partial \\zeta_i}{\\partial y_2(i)_{(t ) } } =   \\sum_{j=1}^{m_i}\\left[-a_j + \\frac{e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}{1 + e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}\\right]b_j(2 ) + 2\\mu_im_iy_2(i)_{(t ) } + ( \\boldsymbol{l\\lambda}_2)_i \\\\\\nonumber & \\vdots\\\\\\nonumber & \\frac{\\partial \\zeta_i}{\\partial y_p(i)_{(t ) } } =   \\sum_{j=1}^{m_i}\\left[-a_j + \\frac{e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}{1 + e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}\\right]b_j(p ) + 2\\mu_im_iy_p(i)_{(t ) } + ( \\boldsymbol{l\\lambda}_p)_i\\end{aligned}\\ ] ] this can be written in the following matrix - vector form : @xmath393_{(t ) } + [ ( \\boldsymbol{l\\lambda})(i,:)]^{\\mathsf{t}}\\ ] ] where @xmath342 is @xmath58 row of matrix @xmath394 and : @xmath395 }          \\end{block } \\end{blockarray}\\quad \\in \\mathbb{r}^{n\\times p}.\\ ] ] finally , we note that : @xmath397 \\hspace{0.3 cm } \\text{with } \\hspace{0.3 cm } \\delta_j|_{(t)}=",
    "-a_j + \\frac{e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}{1 + e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}.\\ ] ]    the hessian of @xmath391 can be immediately written as : @xmath398 where @xmath399 is diagonal @xmath400 matrix , such that @xmath401_{jj } = \\frac{e^{\\sum_{l=1}^py_l(i)_{(t)}b_j(l)}}{\\left(1 + e^{\\sum_{l=1}^py_l(i)_{(t)}b_j(l)}\\right)^2}.\\ ] ]    it is again easy to see that to apply the sddm - solver the hessian of the local objective is needed .",
    "this can be derived as : @xmath402 where @xmath403 is diagonal matrix , given by : @xmath404_{jj } = \\frac{e^{\\sum_{l=1}^py_l(y)b_j(l)}}{\\left(1 + e^{\\sum_{l=1}^py_l(r)b_j(l)}\\right)^2}\\ ] ]      the derivations , so - far , are appropriate for the proposed distributed newton method . to be able to compare against admm , corresponding mathematics needs to be developed .",
    "this section details such constructs .",
    "we start by recalling that each node in distributed admm implements the following instructions :    1 .",
    "* initialization : * chose @xmath346}_{i } \\in\\mathbb{r}^{p}$ ] and @xmath347}_{ji}\\in\\mathbb{r}^p$ ] for @xmath348 for @xmath349 with @xmath405 being the set of predecessors of node @xmath46 .",
    "2 .   * for * @xmath350 1 .",
    "each agent @xmath46 updates its estimate of @xmath351}_i$ ] in a sequential order with : @xmath406}_i = \\arg\\min_{\\boldsymbol{\\theta}^{}_i}\\left(\\underbrace{f_i(\\boldsymbol{\\theta}^{}_i ) + \\frac{\\beta}{2}\\sum_{j\\in p(i)}\\left|\\left|\\boldsymbol{\\theta}^{[k+1]}_j - \\boldsymbol{\\theta}^{}_i - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji }   \\right|\\right|^2 + \\frac{\\beta}{2}\\sum_{j\\in s(i)}\\left|\\left|\\boldsymbol{\\theta}_i - \\boldsymbol{\\theta}^{[k]}_j - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right|\\right|^2}_{\\xi_i}\\right).\\end{aligned}\\ ] ] 2 .",
    "each agent updates @xmath353 for @xmath354 as follows : @xmath407}_{ji } = \\boldsymbol{\\lambda}^{[k]}_{ji } - \\beta(\\boldsymbol{\\theta}^{[k+1]}_j - \\boldsymbol{\\theta}^{[k+1]}_i).\\ ] ]    for solving the optimization problem in equation  [ serega_dalbich_1 ] , standard newton is used for function @xmath408 : @xmath409}_i(t+1 ) = \\boldsymbol{\\theta}^{[k+1]}_i(t ) - \\alpha_t\\boldsymbol{\\theta}^{[i]}_{newton}|_{(t)},\\ ] ] where @xmath410 is a step - size and @xmath411}_{newton}|_{(t)}$ ] is the newton direction , evaluated at @xmath412}_i(t)$ ] , and given by the solution to the following system : @xmath413}_{newton}|_{(t ) } = - \\nabla\\xi_i(\\boldsymbol{\\theta}^{[k+1]}_i(t)),\\ ] ] with @xmath389 and @xmath414}_i(t))$ ] being the hessian and the gradient of function @xmath408 evaluated at vector @xmath412}_i(t)$ ] .",
    "clearly , the gradient can be written in a vector form as : @xmath415}_i(t ) ) = \\boldsymbol{b}_i\\boldsymbol{\\delta}|_{(t ) } + ( 2\\mu_im_i + \\beta d(i))\\boldsymbol{\\theta}^{[k+1]}_i(t )   - \\\\\\nonumber & \\beta\\left(\\sum_{j\\in s(i)}\\left[\\boldsymbol{\\theta}^{[k]}_j + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_j - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right]\\right),\\end{aligned}\\ ] ] where @xmath416 is the degree of node @xmath358 , @xmath417 is given in equation  [ b_matrix ] , and @xmath418 \\hspace{0.3 cm } \\text{with } \\hspace{0.3 cm } \\delta_j|_{(t)}=",
    "-a_j + \\frac{e^{\\boldsymbol{b}^{\\mathsf{t}}_j\\boldsymbol{\\theta}^{[k+1]}_i(t)}}{1 + e^{\\boldsymbol{b}^{\\mathsf{t}}_j\\boldsymbol{\\theta}^{[k+1]}_i(t)}}.\\ ] ] the hessian of @xmath408 can be immediately written as : @xmath419}_i(t ) ) = \\nabla^2f_i(\\boldsymbol{\\theta}^{[k+1]}_i(t ) ) + \\beta d(i)\\boldsymbol{i}_{p\\times p } =   \\boldsymbol{b}_i\\boldsymbol{d}_{i}|_{(t)}\\boldsymbol{b}^{\\mathsf{t}}_i + ( 2\\mu_im_i + \\beta d(i))\\boldsymbol{i}_{p\\times p},\\end{aligned}\\ ] ] where @xmath399 is diagonal @xmath420 matrix , such that @xmath421_{jj } = \\frac{e^{\\boldsymbol{b}^{\\mathsf{t}}_j\\boldsymbol{\\theta}^{[k+1]}_i(t)}}{\\left(1 + e^{\\boldsymbol{b}^{\\mathsf{t}}_j\\boldsymbol{\\theta}^{[k+1]}_i(t)}\\right)^2 } .\\ ] ]                  now , we consider the case when the local objective is defined by : @xmath426 + \\mu_i m_i||\\boldsymbol{\\theta}_i||_1.\\ ] ] it is easy to see that ( [ local_objective_1 ] ) can be simplified as : @xmath427 + \\mu_i m_i||\\boldsymbol{\\theta}_i||_1 = \\\\\\nonumber & -\\sum_{j=1}^{m_i}\\left[a_j\\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{b}_j - \\log(1 + e^{\\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{b}_j})\\right ] + \\mu_i m_i||\\boldsymbol{\\theta}_i||_1 = \\\\\\nonumber & -\\left(\\sum_{j=1}^{m_i}a_j\\boldsymbol{b}_j\\right)^{\\mathsf{t}}\\boldsymbol{\\theta}_i + \\sum_{j=1}^{m_i}\\log(1 + e^{\\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{b}_j } ) + \\mu_im_i||\\boldsymbol{\\theta}_i||_1.\\end{aligned}\\ ] ] similar to equations  [ y_vectors ] and  [ b_vectors ] , we introduce @xmath336 and @xmath428",
    ". then , the problem can be written as : @xmath429 where @xmath338^{\\mathsf{t}}$ ] , and using equation  [ local_objective_1 ] we have : @xmath430    hence , the lagrangian can be written as : @xmath431.\\end{aligned}\\ ] ] in order to define the relation between primal an dual variables , each node @xmath358 needs to solve the corresponding optimization problem of the form : @xmath432 clearly , @xmath391 is not smooth . to proceed",
    ", we use the smooth approximations of the l@xmath156 norm , given by : @xmath433 is parameter controlling the approximation s quality .",
    "therefore , the local objective can be written as : @xmath434 = \\\\\\nonumber & -\\sum_{r=1}^p\\left(\\sum_{j = 1}^{m_i}a_jb_j(r)\\right)y_r(i ) + \\sum_{j=1}^{m_i}\\log\\left(1 + e^{\\sum_{r=1}^{p}y_r(i)b_j(r)}\\right ) + \\\\\\nonumber & \\frac{1}{\\alpha}\\mu_im_i\\sum_{r=1}^{p}\\left[2\\log(1 + e^{\\alpha y_r(i ) } ) - \\alpha y_r(i)\\right].\\end{aligned}\\ ] ]    applying standard newton for equation  [ primal_dual_relation ] gives : @xmath385_{(t+1 ) } =   \\hspace{0.2 cm } \\left [ \\begin{array}{c } y_1(i)\\\\ y_2(i)\\\\ \\vdots\\\\ y_p(i ) \\end{array } \\right]_{(t ) } - \\hspace{0.1 cm } \\gamma_t\\boldsymbol{y}^{[i]}_{newton}|_{(t)},\\ ] ] where @xmath1 is the iteration count , and @xmath386}_{newton}|_{(t)}$ ] is newton direction , evaluated at vector @xmath387_{(t)}$ ] , and given by the solution to the following system : @xmath388}_{newton}|_{(t ) } = - \\nabla\\zeta_i|_{(t)},\\ ] ] with @xmath389 and @xmath390 being the hessian and the gradient of @xmath391 evaluated at vector @xmath387_{(t)}$ ] .",
    "the components of the gradient @xmath390 can be computed as : @xmath392b_j(1 ) + \\mu_im_i\\frac{e^{\\alpha y_1(i)_{(t ) } } - 1 } { 1 + e^{\\alpha y_1(i)_{(t ) } } }   + ( \\boldsymbol{l\\lambda}_1)_i \\\\\\nonumber & \\frac{\\partial \\zeta_i}{\\partial y_2(i)_{(t ) } } =   \\sum_{j=1}^{m_i}\\left[-a_j + \\frac{e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}{1 + e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}\\right]b_j(2 ) + \\mu_im_i\\frac{e^{\\alpha y_2(i)_{(t ) } } - 1 } { 1 + e^{\\alpha y_2(i)_{(t ) } } } + ( \\boldsymbol{l\\lambda}_2)_i \\\\\\nonumber & \\vdots\\\\\\nonumber & \\frac{\\partial \\zeta_i}{\\partial y_p(i)_{(t ) } } =   \\sum_{j=1}^{m_i}\\left[-a_j + \\frac{e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}{1 + e^{\\sum_{r=1}^{p}y_r(i)_{(t)}b_j(r)}}\\right]b_j(p ) + \\mu_im_i\\frac{e^{\\alpha y_p(i)_{(t ) } } - 1 } { 1 + e^{\\alpha y_p(i)_{(t ) } } } + ( \\boldsymbol{l\\lambda}_p)_i.\\end{aligned}\\ ] ] the above can be written in a vector - matrix form as : @xmath435^{\\mathsf{t}},\\ ] ] where @xmath436 are defined in ( [ b_matrix]),([lambda_matrix ] ) , ( [ delta_vector ] ) respectively , @xmath342 is the @xmath58 row of matrix @xmath394 , and @xmath437 \\hspace{0.3 cm } \\textit{with } \\hspace{0.3 cm } \\rho_j|_{(t ) } = \\frac{e^{\\alpha y_j(i)_{(t ) } } - 1 } { 1 + e^{\\alpha y_j(i)_{(t)}}}.\\ ] ]    the hessian of @xmath391 can be immediately written as : @xmath438 where @xmath399 is a diagonal @xmath400 matrix , such that @xmath401_{jj } = \\frac{e^{\\sum_{l=1}^py_l(i)_{(t)}b_j(l)}}{\\left(1 + e^{\\sum_{l=1}^py_l(i)_{(t)}b_j(l)}\\right)^2},\\ ] ] and @xmath439 is diagonal @xmath440 matrix , such that @xmath441_{jj } = \\frac{e^{\\alpha y_j(i)_{(t)}}}{(1 + e^{\\alpha y_j(i)_{(t)}})^2}.\\ ] ] to apply sddm - solver , the hessian of the local objective function @xmath344 must be computed .",
    "it is easy to see that : @xmath442 where @xmath443 and @xmath444 are diagonal matrices , given by : @xmath404_{jj } = \\frac{e^{\\sum_{l=1}^py_l(i)b_j(l)}}{\\left(1 + e^{\\sum_{l=1}^py_l(i)b_j(l)}\\right)^2}.\\ ] ]        1 .",
    "the gradient of function @xmath408 is given as : @xmath446}_i(t ) ) = \\boldsymbol{b}_i\\boldsymbol{\\delta}|_{(t ) } + \\mu_im_i \\boldsymbol{\\rho}|_{(t ) } +    \\beta d(i)\\boldsymbol{\\theta}^{[k+1]}_i(t )   - \\beta\\left(\\sum_{j\\in s(i)}\\left[\\boldsymbol{\\theta}^{[k]}_j + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_j - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right]\\right),\\end{aligned}\\ ] ] where @xmath416 is the degree of node @xmath358 , vector @xmath447 is given in ( [ delta_vector_admm ] ) , and @xmath448\\hspace{0.3 cm } \\textit{with } \\hspace{0.3 cm } \\rho_j|_{(t)}= \\frac{1 - e^{-\\alpha [ \\boldsymbol{\\theta}^{[k+1]}_i(t)]_{j }   } } { 1 + e^{-\\alpha [ \\boldsymbol{\\theta}^{[k+1]}_i(t)]_{j }   } } , \\ ] ] where @xmath449}_i(t)]_{j}$ ] is @xmath216 component of vector @xmath412}_{i}(t)$ ] .",
    "the hessian of function @xmath408 can be written : @xmath450}_i(t ) ) = \\nabla^2f_i(\\boldsymbol{\\theta}^{[k+1]}_i(t ) ) + \\beta d(i)\\boldsymbol{i}_{p\\times p } = \\boldsymbol{b}_i\\boldsymbol{d}_{i}|_{(t)}\\boldsymbol{b}^{\\mathsf{t}}_i + \\beta",
    "d(i)\\boldsymbol{i}_{p\\times p } + 2\\alpha\\mu_im_i\\boldsymbol{\\delta}_i|_{(t)},\\end{aligned}\\ ] ] where @xmath399 is diagonal @xmath420 matrix , given in ( [ d_i_matrix_admm ] ) , and @xmath439 is diagonal @xmath440 matrix such that @xmath441_{jj } = \\frac{e^{\\alpha [ \\boldsymbol{\\theta}^{[k+1]}_i(t)]_j}}{(1 + e^{\\alpha [ \\boldsymbol{\\theta}^{[k+1]}_i(t)]_j})^2},\\ ] ] where @xmath449}_i(t)]_{j}$ ] is @xmath216 component of vector @xmath412}_{i}(t)$ ] .",
    "the sub - gradient of @xmath364 can be written as : @xmath452 where @xmath447 is given in ( [ delta_vector_olshevsky ] ) and @xmath448\\hspace{0.3 cm } \\text{with } \\hspace{0.3 cm } \\rho_j|_{(t)}= \\frac{1 - e^{-\\alpha [ \\boldsymbol{w}_i(t)]_{j }   } } { 1 + e^{-\\alpha [ \\boldsymbol{w}_i(t)]_{j }   } } , \\ ] ] where @xmath453_j$ ] is @xmath216 component of vector @xmath365 .",
    "we consider the policy search framework for reinforcement learning with a uni - variate gaussian policy . here , the data is represented as a collection of trajectories @xmath454 , where @xmath455 \\\\\\nonumber & \\hspace{0.3 cm } \\boldsymbol{x}^{(i)}_t\\in\\mathbb{r}^{d } , \\hspace{0.3 cm } a^{(i)}_t\\in\\mathbb{r}.\\end{aligned}\\ ] ] for each trajectory , we define the reward @xmath456 given by function @xmath457 .",
    "we consider the feature representation of vectors @xmath458 given by map @xmath459 such that @xmath460 .",
    "moreover , we assume that this data set is distributed among the nodes of @xmath461 .",
    "the goal , is to fined the solution of the following optimization problem : @xmath462 where the local objectives are given as : @xmath463^{2}\\right)\\right ] + \\mu_im_i||\\boldsymbol{\\theta}_i||^2_2,\\ ] ] with @xmath464 being a regularization parameter , and @xmath465 .",
    "easy to see that ( [ local_objective_12 ] ) can be simplified as : @xmath466 + \\mu_im_i\\boldsymbol{i}_{p\\times p }   \\right]}_{\\boldsymbol{f}_i}\\boldsymbol{\\theta}_i - 2\\left(\\underbrace{\\sum_{j=1}^{m_i}\\left[\\mathcal{r}(\\boldsymbol{\\tau}_j)\\left(\\sum_{t=1}^{t}a^{(j)}_t\\boldsymbol{b}^{(j)}_{t}\\right)\\right]}_{\\boldsymbol{g}_i}\\right)^{\\mathsf{t}}\\boldsymbol{\\theta}_i + \\\\\\nonumber   & \\underbrace{\\sum_{j=1}^{m_i}\\left(\\mathcal{r}(\\boldsymbol{\\tau}_j)\\sum_{t = 1}^{t}(a^{(j)}_t)^2\\right)}_{u_i } = \\boldsymbol{\\theta}^{\\mathsf{t}}_i\\boldsymbol{f}_i\\boldsymbol{\\theta}_i - 2\\boldsymbol{g}^{\\mathsf{t}}_i\\boldsymbol{\\theta}_i   + u_i,\\end{aligned}\\ ] ] where @xmath467 with @xmath468 }      \\end{block } \\end{blockarray}\\quad \\in \\mathbb{r}^{p\\times t},\\ ] ] and @xmath469\\in\\mathbb{r}^{t}.\\ ] ] to further simplify expressions ( [ params_expressions ] ) let us introduce : @xmath470\\in\\mathbb{r}^{p\\times tm_i}\\\\\\nonumber & \\boldsymbol{\\mathcal{r}}^{(i ) } = \\left[\\begin{array}{cccc } \\mathcal{r}(\\boldsymbol{\\tau}_1)\\boldsymbol{i}_{t\\times t}&\\boldsymbol{0}&\\cdots & \\boldsymbol{0}\\\\ \\boldsymbol{0}&\\mathcal{r}(\\boldsymbol{\\tau}_2)\\boldsymbol{i}_{t\\times t}&\\cdots & \\boldsymbol{0}\\\\ \\vdots & & \\ddots & \\vdots \\\\ \\boldsymbol{0}&\\boldsymbol{0}&\\cdots & \\mathcal{r}(\\boldsymbol{\\tau}_{m_i})\\boldsymbol{i}_{t\\times t}\\\\ \\end{array}\\right ] \\in \\mathbb{r}^{tm_i\\times tm_i}\\\\\\nonumber & \\boldsymbol{\\alpha}^{(i ) } = \\left [ \\begin{array}{c } \\boldsymbol{a}_1\\\\ \\boldsymbol{a}_2\\\\ \\vdots\\\\ \\boldsymbol{a}_{m_i } \\end{array } \\right ] \\in\\mathbb{r}^{tm_i}.\\end{aligned}\\ ] ] then ( [ params_expressions ] ) gives : @xmath471 similarly to ( [ y_vectors ] ) we introduce vectors @xmath336 , then problem ( [ gcp_renf_learning ] ) can be written as : @xmath472 where @xmath338^{\\mathsf{t}}$ ] , and : @xmath473_{kl}y_k(i)y_l(i ) - 2\\sum_{k=1}^p[\\boldsymbol{g}_i]_ky_k(i ) + u^2_i.\\end{aligned}\\ ] ] hence , the lagrangian can be written as : @xmath431,\\end{aligned}\\ ] ] and primal variables can be recovered from the dual by the following equation : @xmath341_{[\\boldsymbol{\\lambda}_1 , \\ldots , \\boldsymbol{\\lambda}_p ] } = \\boldsymbol{f}^{-1}_i\\left[\\boldsymbol{g}_i - \\frac{1}{2}(\\boldsymbol{l\\lambda})(i,:)]^{\\mathsf{t}}\\right],\\ ] ] where @xmath342 is @xmath58 row of matrix @xmath394 , and @xmath474 is given as ( [ lambda_matrix ] ) . +        1 .",
    "* initialization : * chose arbitrary @xmath346}_{i } \\in\\mathbb{r}^{p}$ ] and @xmath347}_{ji}\\in\\mathbb{r}^p$ ] for @xmath348 for @xmath349 .",
    "2 .   * for * @xmath350 1 .",
    "each agent @xmath46 updates its estimate of @xmath351}_i$ ] in a sequential order with @xmath475}_i = \\\\\\nonumber & \\arg\\min_{\\boldsymbol{\\theta}^{}_i}\\left(\\underbrace{f_i(\\boldsymbol{\\theta}^{}_i ) + \\frac{\\beta}{2}\\sum_{j\\in p(i)}\\left|\\left|\\boldsymbol{\\theta}^{[k+1]}_j - \\boldsymbol{\\theta}^{}_i - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji }   \\right|\\right|^2 + \\frac{\\beta}{2}\\sum_{j\\in s(i)}\\left|\\left|\\boldsymbol{\\theta}_i - \\boldsymbol{\\theta}^{[k]}_j - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right|\\right|^2}_{\\xi_i}\\right).\\end{aligned}\\ ] ] 2 .",
    "each agent updates @xmath353 for @xmath354 as follows : @xmath355}_{ji } = \\boldsymbol{\\lambda}^{[k]}_{ji } - \\beta(\\boldsymbol{\\theta}^{[k+1]}_j - \\boldsymbol{\\theta}^{[k+1]}_i).\\ ] ]    we can get the closed form solution for ( [ serega_dalbich_1 ] ) : @xmath356}_j   + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_{j } - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right ] \\right ) = \\\\\\nonumber & 2\\boldsymbol{f}_i\\boldsymbol{\\theta}_i - 2\\boldsymbol{g}_i + \\beta d(i)\\boldsymbol{\\theta}_i - \\beta\\left(\\sum_{j\\in s(i)}\\left[\\boldsymbol{\\theta}^{[k]}_j   + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_{j } - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right ] \\right).\\end{aligned}\\ ] ] hence , for the iterative rule ( [ serega_dalbich_11 ] ) : @xmath476}_i = \\left[\\boldsymbol{f}_i + \\frac{\\beta d(i)}{2}\\boldsymbol{i}_{p\\times p}\\right]^{-1}\\left(\\boldsymbol{g}_i + \\frac{\\beta}{2}\\left(\\sum_{j\\in s(i)}\\left[\\boldsymbol{\\theta}^{[k]}_j   + \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ij}\\right ] + \\sum_{j\\in p(i)}\\left[\\boldsymbol{\\theta}^{[k+1]}_{j } - \\frac{1}{\\beta}\\boldsymbol{\\lambda}^{[k]}_{ji}\\right ] \\right ) \\right).\\ ] ]          where @xmath362 is a step - size and @xmath363 is the sub - gradient of @xmath364 evaluated at @xmath365 , i.e. : @xmath477 after @xmath367 iterations the node @xmath358 computes the average @xmath478 as a solution ."
  ],
  "abstract_text": [
    "<S> in this paper , we propose a distributed newton method for consensus optimization . </S>",
    "<S> our approach outperforms state - of - the - art methods , including admm . </S>",
    "<S> the key idea is to exploit the sparsity of the dual hessian and recast the computation of the newton step as one of efficiently solving symmetric diagonally dominant linear equations . </S>",
    "<S> we validate our algorithm both theoretically and empirically . on the theory side , we demonstrate that our algorithm exhibits superlinear convergence within a neighborhood of optimality . </S>",
    "<S> empirically , we show the superiority of this new method on a variety of machine learning problems . </S>",
    "<S> the proposed approach is scalable to very large problems and has a low communication overhead . </S>"
  ]
}