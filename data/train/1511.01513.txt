{
  "article_text": [
    "the task of recovering an unknown low - rank matrix from a small number of measurements appears in a variety of contexts .",
    "examples of this task are provided by collaborative filtering in machine learning @xcite , quantum state tomography in quantum information @xcite , the estimation of covariance matrices @xcite , or face recognition @xcite . if the measurements are linear , the technical problem reduces to identifying the lowest - rank element in an affine space of matrices . in general , this problem is @xmath0-hard and it is thus unclear how to approach it algorithmically @xcite .    in the wider field of compressed sensing @xcite , the strategy for treating such problems is to replace the complexity measure",
    " here the rank  with a tight convex relaxation .",
    "often , it can be rigorously proved that the resulting convex optimization problem has the same solution as the original problem for many relevant problems , while at the same time allowing for an efficient algorithm .",
    "the tightest ( in some sense @xcite ) convex relaxation of rank is the _ nuclear norm _ , i.e.  the sum of singular values .",
    "minimizing the nuclear norm subject to linear constraints is a semi - definite program and great number of rigorous performance guarantees have been provided for low - rank reconstruction using nuclear norm minimization @xcite .",
    "the geometry of convex reconstruction schemes is now well - understood ( c.f .",
    "figure  [ fig : geometry ] ) . starting with a convex regularizer @xmath1 ( e.g.  the nuclear norm ) , geometric proof techniques like tropp s bowling scheme @xcite or mendelson s small ball method",
    "@xcite bound the reconstruction error in terms of the descent cone of @xmath1 at the matrix that is to be recovered . moreover , these arguments suggest that the error would decrease if another convex regularizer with smaller descent cone would be used . this motivates the search for new convex regularizers that ( i ) are efficiently computable and ( ii ) have a smaller descent cone at particular points of interest .    in this work ,",
    "we introduce such an improved regularizer based on the _ diamond norm _ @xcite .",
    "this norm plays a fundamental role in the context of quantum information and operator theory @xcite . for this work , it is convenient to also use a variant of the diamond norm that we call the _",
    "square norm_. while not obvious from its definition , it has been found that the diamond norm can be efficiently computed by means of a semidefinite program ( sdp ) @xcite .",
    "starting from one such sdp characterization @xcite , we identify the set of matrices for which the square norm s descent cone is contained in the corresponding one of the nuclear norm . as a result ,",
    "low - rank matrix recovery guarantees that have been established via analyzing the nuclear norm s descent cone @xcite are also valid for square norm regularization , provided that the matrix of interest belongs to said set .",
    "what is more , bearing in mind the reduced size of the square norm s descent cone , we actually expect an improved recovery .",
    "indeed , with numerical studies we show an improved performance .    going beyond low - rank matrix recovery , we identify several applications . in physics , we present numerical experiments that show that the diamond norm offers improved performance for _ quantum process tomography _ @xcite .",
    "the goal of this important task is to reconstruct a quantum process from suitable preparations of inputs and measurements on outputs ( generalizing quantum _ state _ tomography , for which low - rank methods have been studied extensively @xcite .",
    "we then identify applications to problems from the context of signal processing .",
    "these include matrix versions of the _ phase retrieval problem _ @xcite , as well as a matrix version of the _ blind deconvolution problem _ @xcite .",
    "recently , a number of _ bi - linear problems _ combined with sparsity or low - rank structures have been investigated in the context of compressed sensing , with first progress on recovery guarantees being reported @xcite .",
    "the present work can be seen as a contribution to this recent development .",
    "we conclude the introduction on a more speculative note .",
    "the diamond norm is defined for linear maps taking operators to operators  i.e. , for objects that can also be viewed as order-@xmath2 tensors .",
    "we derive a characterization of those maps for which the diamond norm offers improved recovery , and find that it depends on the order-@xmath2 tensorial structure . in this sense ,",
    "the present work touches on an aspect of the notoriously difficult _ tensor recovery problem _ ( no canonic approach or reference seems to have emerged yet , but see ref .",
    "@xcite for an up - to - date list of partial results ) .",
    "in fact , the `` tensorial nature '' of the diamond norm was the original motivation for the authors to consider it in more detail as a regularizer  even though the eventual concrete applications we found do not seem to have a connection to tensor recovery .",
    "it would be interesting to explore this aspect in more detail .",
    "in this section , we introduce notation and mathematical preliminaries used to state our main results .",
    "we start by clarifying some notational conventions . in particular , we introduce certain matrix norms and the partial trace for operators acting on a tensor product space .",
    "moreover , we summarize a general geometric setting for the convex recovery of structured signals .      throughout this work we focus exclusively on finite dimensional mostly complex vector spaces @xmath3",
    "whose elements we mostly denote by lower case latin letters , e.g. @xmath4 .",
    "furthermore we assume that each vector space @xmath5 is equipped with an inner product @xmath6  or simply @xmath7 for short  that is linear in the second argument .",
    "such an inner product induces the euclidean norm @xmath8 and moreover defines a conjugate linear bijection from @xmath5 to its dual space @xmath9 : to any @xmath4 we associate a dual vector @xmath10 which is uniquely defined via @xmath11 @xmath12 . the vector space of linear maps from @xmath5 to @xmath13 is denoted by @xmath14 .",
    "its elements being _ operators _ are denoted by capital latin letters ( e.g. @xmath15 ) and often we also refer to them as matrices .",
    "when dealing with endomorphisms , we write @xmath16 for the sake of notational brevity .",
    "the adjoint @xmath17 of an operator @xmath18 is determined by @xmath19 for all @xmath4 and @xmath20 and we call an operator @xmath21 self - adjoint , or hermitian , if @xmath22 .",
    "a self - adjoint operator @xmath23 is positive semidefinite , if it has a non - negative spectrum .",
    "a particularly simple example for such an operator is the identity operator @xmath24 .",
    "the set of positive semidefinite operators in @xmath25 forms a convex cone which we denote by @xmath26 @xcite .",
    "this cone induces a partial ordering on @xmath25 and we write @xmath27 if @xmath28 .",
    "on @xmath25 we define the frobenius ( or hilbert - schmidt ) inner product to be @xmath29 where @xmath30 denotes the trace of an operator @xmath31 .",
    "in addition to that , we are going to require three different matrix norms @xmath32 the frobenius norm is induced by the inner product , while the nuclear norm requires the operator square root : for @xmath33 we let @xmath34 be the unique positive semi - definite operator obeying @xmath35 . note that these norms correspond to the schatten @xmath36- , schatten @xmath37- and schatten @xmath38-norms , respectively .",
    "all schatten norms are multiplicative under taking tensor products .",
    "the frobenius norm is preserved under any re - grouping of indices , the prime example of such an operation being the vectorization of matrices .",
    "this fact justifies our convention to extend the notation @xmath39 to the @xmath37-norms of vectors and ( later on ) tensors .    a crucial role is played by the space of _ bipartite operators _ @xmath40 , by which we refer operators that act on a tensor product space .",
    "for such operators we define the _ partial trace _ @xmath41 as the linear extensions of the map given by @xmath42 where @xmath43 and @xmath44 , see also figure  [ fig : tensor_diagram_trw ] .",
    "finally , we define our improved regularizer on @xmath40 to be @xmath45 it is easy to see that @xmath46 is a norm and we call it the _ square norm_. it will become clear later on that the square norm is closely related to the diamond norm @xmath47 from quantum information theory @xcite . as we will discuss in section  [ sec : notation_maps ] , @xmath48 , where @xmath49 denotes the so - called choi - jamiokowski isomorphism .",
    "both square and diamond norm can be calculated by a semidefinite program ( sdp ) satisfying strong duality @xcite .",
    "also , note that the pair @xmath50 is admissible in the maximization .",
    "inserting it recovers @xmath51 and establishes the bound @xmath52 .",
    "this bound plays a crucial role for our results .",
    "( m2 )     ( m ) [ bbox ] at ( 0,0 ) @xmath23 ; ( m.west ) + + ( 0 , ) coordinate ( moli ) ; ( m.west ) + + ( 0,- ) coordinate ( muli ) ; ( m.east ) + + ( 0 , ) coordinate ( more ) ; ( m.east ) + + ( 0,- ) coordinate ( mure ) ; ( more )  + + ( , 0 ) ++(0 , ) node ( xo ) [ near end , right ] @xmath9 ; ( mure )  + + ( , 0 ) ++(0,- ) node ( xu ) [ near end , right ] @xmath5 ; ( moli )  + +",
    "( -,0 ) ++(0 , ) node ( yo ) [ near end , left ] @xmath53 ; ( muli ) ",
    "+ + ( -,0 ) ++(0,- ) node ( yu ) [ near end , left ] @xmath13 ; ( xo.north east ) + + ( 1ex,0 ) coordinate ( ore )  ( ore|-xu.south ) ;    ; ( try ) [ right = of m2 ] ; ( m3 ) [ right = of try ]     ( m ) [ bbox ] at ( 0,0 ) @xmath23 ; ( m.west ) + + ( 0 , ) coordinate ( moli ) ; ( m.west ) + + ( 0,- ) coordinate ( muli ) ; ( m.east ) + + ( 0 , ) coordinate ( more ) ; ( m.east ) + + ( 0,- ) coordinate ( mure ) ; ( moli )  + + ( -,0 ) |- ( muli ) ; ( more )",
    " + + ( , 0 ) ++(0 , ) node ( xo ) [ near end , right ] @xmath9 ; ( mure ) ",
    "+ + ( , 0 ) ++(0,- ) node ( xu ) [ near end , right ] @xmath5 ; ( xo.north east ) + + ( 1ex,0 ) coordinate ( ore ) ",
    "( ore|-xu.south ) ;    ;      in this section , we summarize a recent but already widely used geometric proof technique for low - rank matrix recovery . mainly following ref .",
    "@xcite , we devote this section to explaining the general reconstruction idea .    in the setting of convex recovery of structured signals ,",
    "one obtains a _ measurement vector _ @xmath54 of a _ signal _ @xmath55 in some vector space @xmath5 via a _ measurement map _ @xmath56 , @xmath57 where @xmath58 represents additive noise in the sampling process . throughout ,",
    "we assume linear data acquisition , i.e. , @xmath59 is linear .",
    "the goal is to efficiently obtain a good approximation to @xmath60 given @xmath59 and @xmath61 for the case where one only has knowledge about some structure of @xmath60 .",
    "of course , it is desirable that the number @xmath62 of measurements @xmath63 required for a successful reconstruction is as small as possible . for several different structures of the signal @xmath60 a general approach of the following form",
    "has proven to be very successful @xcite .",
    "one chooses a convex function @xmath64 that reflects the structure of @xmath60 and performs the following convex minimization @xmath65 where @xmath66 is some anticipated error bound .",
    "next , we give two definitions and a general error bound that has proven to be helpful to find such recovery guarantees .",
    "the _ descent cone _ of a convex function is the set of non - increasing directions @xmath67 . from the convexity of the function",
    ", it follows that the descent cone is a convex cone .",
    "the following definitions can also be found , e.g. , in ref .",
    "@xcite .",
    "[ def : dc ] the _ descent cone _",
    "@xmath68 of a proper convex function @xmath69 at the point @xmath70 is @xmath71    the _ minimum singular value _ of a linear map @xmath59 is the minimal value of @xmath72 taken over all @xmath73 with @xmath74 .",
    "restricting this minimization to a cone yields the _ minimum conic singular value_.    let @xmath75 be a linear map and @xmath76 be a cone .",
    "the minimum singular value of @xmath59 with respect to the cone @xmath77 is defined as @xmath78    [ prop : general_reconstruction ] let @xmath55 be a signal , @xmath79 be a measurement map , @xmath80 a vector of @xmath62 measurements with additive error @xmath58 , and @xmath81 be the solution of the optimization . if @xmath82 then @xmath83    note that the statement in ref",
    ".  @xcite shows this result for real vector spaces only .",
    "however , taking a closer look at the proof reveals that it also holds for complex vector spaces as well .",
    "we make the following simple but important observation :    [ obs : smaller_dc ] the smaller the descent cone the better the recovery guarantee .",
    "an important example is low - rank matrix recovery . here",
    ", @xmath84 is some @xmath85 matrix with @xmath86 and a low - rank provides structure that allows for reconstruction from a dimension sufficient number of measurements . for this case , choosing @xmath87 to be the nuclear norm has proven very successful , as the nuclear norm is the convex envelope of the matrix rank @xcite . in order to give a concrete bound , consider a real matrix @xmath88 and @xmath62 measurements @xmath89 with each @xmath90 being a real random matrix with entries drawn independently from a normalized gaussian distribution",
    ". then one can show that ( see , e.g. , ref .",
    "@xcite ) @xmath91 with probability @xmath92 ( over the random measurements ) . as a consequence ,",
    "a number of @xmath93 measurements are enough for a successful reconstruction of the real - valued matrix @xmath88 with high probability .",
    "we show that for certain structured recovery problems , replacing the regularizer @xmath1 in a convex recovery by an optimized regularizer @xmath94 can potentially improve performance ; see also figure  [ fig : geometry ] . for the case where @xmath1 is the nuclear norm and @xmath94 the square norm , we show such an improvement with numerical simulations in section  [ sec : application_maps ] .",
    "( 0,0 ) coordinate ( ker - li ) + + ( , 0 ) coordinate ( ker - li - o )  + + ( 0 , ) coordinate ( ker - re - o ) ; ( ker - li ) + + ( -,0 ) coordinate ( ker - li - u ) ",
    "+ + ( 0 , ) coordinate ( ker - re - u ) ; ( ker - li - u ) rectangle ( ker - re - o ) ; ( ker - li - o ) ",
    "( ker - re - o ) ; ( ker - li - u ) ",
    "( ker - re - u ) ; ( ker - li )  + + ( 0 , ) coordinate ( ker - re ) node [ inner sep = 1pt ] ( origin ) [ midway ] ; ( origin ) circle ( 2pt ) node[above left , lab]@xmath95 ; ( origin ) ",
    "+ + (: ) coordinate ( cdre ) ; ( origin ) ",
    "+ + (: ) coordinate ( cdli ) ; ( origin )  ( cdli ) arc ( : : )  ( origin ) ; ( origin )  ( cdli ) ( origin )  ( cdre ) ; ( origin ) ",
    "+ + (: ) coordinate ( ccre ) + + ( : .2 ) coordinate ( bccre ) ; ( origin ) ",
    "+ + (: ) coordinate ( ccli ) + + ( : .2 ) coordinate ( bccli ) ; ( origin )  ( ccli ) arc ( : : )  ( origin ) ; ( origin )  ( bccli ) ( origin ) ",
    "( bccre ) ; ( origin ) ",
    "+ + (: ) coordinate ( care ) ; ( origin ) ",
    "+ + (: ) coordinate ( cali ) ; ( origin )  ( cali ) arc ( : : )  ( origin ) ; ( origin )  ( cali ) ( origin )  ( care ) ; ( origin ) ",
    "+ + (: ) coordinate ( cbre ) ; ( origin ) ",
    "+ + (: ) coordinate ( cbli ) ; ( origin )  ( cbli ) arc ( : : )  ( origin ) ; ( origin ) ",
    "( cbli ) ( origin )  ( cbre ) ; ( ker - li - u ) + + ( -1,.7 ) node [ lab , anchor = east ] ( kera ) @xmath96 ; ( ker - li)++(0,.4 ) to [ out=-110 , in = -80 ] ( kera ) ; ( origin )  ( ker - re - u ) node ( schlauch ) [ midway ] ; ( schlauch )  + + ( -1,-.5 ) node [ lab , anchor = east ] ( eta ) @xmath97 ; ( schlauch ) to[out=120 , in=80 ] ( eta ) ; ( ccre ) + + ( 0,-.3 ) coordinate ( anchorc ) + + ( .6,.2 ) node ( dcc ) [ lab , anchor = south west]@xmath98 ; ( anchorc ) to[out=20 , in = 190 ] ( dcc.west ) ; ( cdre )  ( cdli )",
    "coordinate [ midway ] ( dmw ) ; ( dmw)++(.02,0 ) coordinate(anchord ) + + ( .5,0 ) node ( dcd ) [ lab , anchor = west]@xmath99 ; ( anchord ) to[out=20 , in = 170 ] ( dcd.west ) ; ( cali ) + + ( -.1,.3 ) coordinate ( anchora ) + + ( .7,-.7 ) node ( dca ) [ lab , anchor = north west]@xmath100 ; ( anchora ) to[out=-10 , in = 170 ] ( dca.west ) ; ( cbre ) + + ( -.2,-.4 ) coordinate ( anchorb ) + + ( -.8,.4 ) node ( dcb ) [ lab , anchor = south]@xmath101 ; ( anchorb ) to[out=-170 , in = -90 ] ( dcb ) ;    [ prop : construction ] let @xmath102 be a convex set and @xmath103 be a compact index set .",
    "moreover , let @xmath104 be a family of upper semi - continuous convex functions @xmath105 .",
    "define another convex function @xmath94 as the point - wise supremum @xmath106 .",
    "then @xmath107 for any @xmath108 , where @xmath109 is the active index set at @xmath73 with the convention @xmath110 .",
    "by @xmath111 we will denote the cone generated by a set @xmath112 . according to definition [ def : dc ] of the descent cone , we have @xmath113 writing the supremum as an intersection yields @xmath114 by @xmath115 we denote the ball around the origin of radius @xmath116 .",
    "now , consider a non - active index @xmath117 .",
    "as @xmath118 is upper semi - continuous , there exists @xmath119 such that for all @xmath120 we have @xmath121 .",
    "hence , the set @xmath122 and hence the corresponding cone in eq .   is the entire space .",
    "therefore , every non - active index @xmath123 can be omitted in the intersection , @xmath124 the definition of the descent cone of @xmath125 finishes the proof .",
    "the square norm is a particular instance of such a supremum over nuclear norms .",
    "thanks to the following nuclear norm bound , proposition  [ prop : construction ] can lead to an improved recovery for any bipartite operator @xmath126 satisfying @xmath127 here , we will only need the lower bound on the square norm but , in order to fully relate it to the usual matrix norms , we also provide two upper bounds .    [",
    "prop : bounds_on_diamond_norm ] for any @xmath126 @xmath128    our second main result fully characterizes the set of operators satisfying eq .  .",
    "[ thm : extremality ] let @xmath126 be a bipartite operator .",
    ".   holds if and only if @xmath129    for now , we content ourselves with sketching the proof idea and present the full proof later .    for the case where eq .",
    "is satisfied , we exploit it to single out a primal feasible optimal point .",
    "exact knowledge of this point together with complementary slackness then allow to severely restrict the range of possible dual optimal points .",
    "relation is an immediate consequence of these restrictions .    to show the converse",
    ", we insert a particular feasible point into the dual sdp of the square norm .",
    ".   enables us to explicitly evaluate the objective function at this point . doing so yields @xmath51 which in turn implies @xmath130 by weak duality . combining this implication with the converse bound from proposition  [ prop : bounds_on_diamond_norm ] establishes @xmath131 , as claimed .    as an implication of theorem  [ thm : extremality ] and proposition  [ prop : construction ]",
    "we obtain the following .",
    "[ cor : subset ] let @xmath126 satisfy eq .  .",
    "then @xmath132 where @xmath133 contains all @xmath134 with @xmath135 and being active in the sense that @xmath136 .    for instance",
    ", setting @xmath50 gives an element of @xmath133 and yields the inclusion @xmath137 for any @xmath23 satisfying eq .  .",
    "as an immediate application , we will see in the next section that the square norm inherits recovery guarantees from the nuclear norm .",
    "in this section we focus on low - rank matrix recovery of hermitian bipartite operators @xmath138 that are either real - valued or complex - valued . as already mentioned in section  [ sub : convex_recovery ] , there",
    "the task is to efficiently recover an unknown matrix @xmath88 of low - rank @xmath139 from @xmath62 noisy linear measurements of the form @xmath140 where @xmath141 are the measurement matrices and @xmath142 denotes additive noise in the sampling process . by introducing a measurement map @xmath143 of the form @xmath144 , where @xmath145 denotes the standard basis in @xmath146 , the entire measurement process can be summarized as @xmath147 here",
    ", @xmath148 contains all measurement outcomes and @xmath149 denotes the noise vector .",
    "if a bound @xmath150 on the noise is available , many measurement scenarios have been identified where estimating @xmath88 by @xmath151 from noisy data of the form stably recovers @xmath88 .",
    "note that by employing the well - known sdp formulation of the nuclear norm @xcite this optimization can be recast as @xmath152 & { \\mathrm{subject\\ to } } &      \\begin{pmatrix }      y & -x \\\\",
    "-x{^\\dagger } & z      \\end{pmatrix } \\succeq 0 \\ , , \\\\[.9em ] & &   y , z \\in \\operatorname{pos}({{\\mathcal{w}}}\\otimes { { \\mathcal{v } } } ) \\ , , \\\\ & & { { \\left\\vert { { \\mathcal{a}}}(x)-y \\right\\vert}_{\\mathrm{f } } } \\leq \\eta \\ , .",
    "\\end{array } \\label{eq : nnorm_reconstruction}\\ ] ] what is more , several of these recovery guarantees can be established using the geometric proof techniques presented in section  [ sub : convex_recovery ] . for results established that way",
    ", combining observation  [ obs : smaller_dc ] with corollary  [ cor : subset ] allows us to draw the following conclusion .",
    "[ imp : inheriting ] for bipartite operators @xmath138 that satisfy @xmath153 , any recovery guarantee for nuclear norm minimization , which is based on the nuclear norm s descent cone , also holds for square norm minimization .",
    "this insight indicates that replacing nuclear norm regularization by @xmath154 results in an estimation procedure that performs at least as well whenever @xmath155 .",
    "in fact , observation  [ obs : smaller_dc ] suggests that it may actually outperform traditional recovery procedures .",
    "also , the sdp formulation for the square norm @xcite allows one to recast the optimization as @xmath156 & { \\mathrm{subject\\ to } } &      \\begin{pmatrix }      y & -x \\\\",
    "-x{^\\dagger } & z      \\end{pmatrix } \\succeq 0 \\ , , \\\\[.9em ] & & y , z \\in \\operatorname{pos}({{\\mathcal{w}}}\\otimes { { \\mathcal{v } } } ) \\ , , \\\\ & &   { { \\left\\vert { { \\mathcal{a}}}(x)-y \\right\\vert}_{\\mathrm{f } } } \\leq \\eta \\ , , \\end{array}\\ ] ] which , just like the optimization , is a convex optimization problem that can be solved computationally efficiently . in the remainder of this section",
    ", we present three measurement scenarios for which implication  [ imp : inheriting ] holds .",
    "the first one is a version of ref .",
    "* example 4.4 ) which is valid for reconstructing real - valued matrices . in its original formulation with nuclear norm minimization",
    ", it follows from combining proposition  [ prop : general_reconstruction ] and eq .  .",
    "[ prop : gaussian_cs ] let @xmath138 be a real valued , bipartite matrix of rank @xmath139 that obeys @xmath157 .",
    "also , suppose that each measurement matrix @xmath158 is a real - valued standard gaussian matrix and the overall noise is bounded as @xmath159 . then",
    ", @xmath160 noisy measurements of the form suffice to guarantee @xmath161 with probability at least @xmath162 . here ,",
    "@xmath163 , @xmath164 and @xmath165 denote absolute constants .    with high probability ( w.h.p .",
    ") , this statement assures _ stable _ recovery , meaning that the reconstruction error scales linearly in the noise bound @xmath166 and inversely proportional to @xmath167 .    for the sake of clarity ,",
    "we have refrained from providing explicit values for the constants @xmath168 and @xmath165 in proposition  [ prop : gaussian_cs ] . however",
    ", resorting to tropp s bound on the minimal conical eigenvalue of a gaussian sampling matrix reveals that stably recovering any rank-@xmath139 matrix obeying eq .",
    "requires roughly @xmath169 independently selected gaussian measurements .",
    "proposition  [ prop : gaussian_cs ] is a prime example for a _ non - uniform _ recovery guarantee : for any fixed rank-@xmath139 matrix @xmath88 obeying eq .  , @xmath62 randomly chosen measurements of the form suffice to stably reconstruct @xmath88 w.h.p . for some measurement scenarios ,",
    "stronger recovery guarantees can be established .",
    "called _ uniform _ recovery guarantees , these results assure that one choice of sufficiently many random measurements w.h.p",
    ". suffices to reconstruct all possible matrices of a given rank .",
    "a uniform recovery statement can be established for the following real - valued measurement scenario @xcite : suppose that with respect to an arbitrary orthonormal basis of @xmath170 , each matrix element of @xmath158 is an independent instance of a real - valued random variable @xmath171 obeying @xmath172 = 0 , \\quad { \\mathbb{e}}\\left [ a^2 \\right ] = 1 \\quad \\textrm{and } \\quad { \\mathbb{e}}\\left [ a^4 \\right ] \\leq f , \\label{eq : fourth_moments}\\ ] ] where @xmath173 is an arbitrary constant .",
    "measurement matrices of this form can be considered as a generalization of gaussian measurement matrices , where each matrix element corresponds to a standard gaussian random variable . in ref .",
    "@xcite  see also refs .",
    "@xcite  a uniform recovery guarantee for such measurement matrices has been established by means of the _ frobenius robust rank null space property _",
    "* definition 10 ) .",
    "such a proof technique is different from the geometric one introduced in section  [ sub : convex_recovery ] .",
    "however , as laid out in the appendix , some auxiliary statements allow for reassembling technical statements from these works to yield a slightly weaker , but still uniform , statement by means of analyzing descent cones . implication  [ imp : inheriting ] is applicable for such a result and yields the following .    [",
    "prop : fourth_moments ] consider the measurement process described in eq .",
    ", where each @xmath174 is an independent random matrix of the form .",
    "fix @xmath175 and suppose that @xmath176",
    ". then , w.h.p .",
    ", every real - valued matrix @xmath177 of rank at most @xmath139 and obeying @xmath178 can be stably reconstructed from the measurements by means of square norm minimization .",
    "here , @xmath179 is a constant that only depends on the fourth - moment bound @xmath180 .",
    "we conclude this section with two uniform recovery guarantees for hermitian low - rank matrices from measurement matrices @xmath158 that are proportional to rank - one projectors , i.e. , @xmath181 for some @xmath182 .",
    "originally established for nuclear norm minimization in ref .",
    "@xcite , by using an extension of the geometric proof techniques presented in section  [ sub : convex_recovery ] , implication  [ imp : inheriting ] is directly applicable to such measurements .",
    "[ prop : rank_one ] consider recovery of hermitian rank-@xmath139 matrices @xmath126 that obey @xmath183 from rank - one measurements of the form @xmath181 .",
    "let @xmath184 .",
    "then stable and uniform recovery guarantees for square norm minimization analogous to proposition  [ prop : fourth_moments ] hold if either    1 .",
    "the measurements @xmath185 are @xmath186 random gaussian vectors in @xmath170 or 2 .",
    "the measurements @xmath185 are @xmath187 vectors drawn uniformly from a complex projective 4-design .",
    "once more , @xmath188 and @xmath189 denote absolute constants of sufficient size .    in the statement above ,",
    "complex projective @xmath190-design _ is a configuration of vectors which is `` evenly distributed '' on a sphere in the sense that sampling uniformly from it reproduces the moments of haar measure up to order @xmath191 @xcite . more precisely , @xmath192 the second statement in proposition  [ prop : rank_one ] can be seen as `` partial derandomization '' of the first one @xcite",
    "now we come to three concrete applications concerning linear maps that take operators in @xmath25 to operators in @xmath193 .",
    "our reconstruction based on the square norm can be applied to such maps by identifying them with operators in @xmath40 .",
    "we start with introducing some relevant notation and explain such an identification , the choi - jamiokowski isomorphism , in more detail .",
    "then we present numerical results on retrieval of certain unitary basis changes , quantum process tomography , and blind matrix deconvolution .",
    "our square norm is closely related to the diamond norm , which is defined for linear operators @xmath194 that map operators to operators .",
    "we call such objects _ maps _ and denote their space by @xmath195 , or simply by @xmath196 .",
    "we also denote maps by capital latin letters . concretely , for @xmath197 and @xmath43 we write @xmath198 .",
    "a particularly simple example is the identity map @xmath199 which obeys @xmath200 for all @xmath201 .",
    "we would like to identify maps in @xmath202 with operators in @xmath40 , for which we have discussed certain reconstruction schemes .",
    "for this purpose , we employ a very useful isomorphism , called the _ choi - jamiokowski isomorphism _ @xcite . in order to explicitly define this isomorphism",
    ", we fix an orthogonal basis @xmath203 of @xmath5 .",
    "this also gives rise to an operator basis @xmath204 and we define _ vectorization _",
    "@xmath205 by the linear extension of @xmath206 then the choi - jamiokowski isomorphism @xmath49 is defined by @xmath207 the resulting operator @xmath208 is called the _ choi matrix _ of @xmath209 .",
    "it can be straightforwardly checked that eq .",
    "is equivalent to setting @xmath210 although not evident from eq .",
    ", this isomorphism is actually basis independent .",
    "indeed , it is just an instance of the natural isomorphism @xmath211 .",
    "this identification is illustrated in figure  [ fig : tensor_diagram ] , and discussed in more detail in the appendix .",
    "( m1 )     ( m ) [ bbox ] at ( 0,0 ) @xmath209 ; ( m.west ) + + ( 0 , ) coordinate ( moli ) ; ( m.west ) + + ( 0,- ) coordinate ( muli ) ; ( m.east ) + + ( 0 , ) coordinate ( more ) ; ( m.east ) + + ( 0,- ) coordinate ( mure ) ; ( more ) ",
    "+ + ( , 0 ) node ( xo ) [ near end , above ] @xmath9 ; ( mure )  + + ( , 0 ) node ( xu ) [ near end , below ] @xmath5 ; ( moli ) ",
    "+ + ( -,0 ) node ( yo ) [ near end , above ] @xmath13 ; ( muli )  + +",
    "( -,0 ) node ( yu ) [ near end , below ] @xmath53 ; ( xu.south east ) + + ( 0,-1ex ) coordinate ( ure ) ",
    "( ure-|yu.west ) ;    ; ( j ) [ right = of m1 ] ; ( m2 ) [ right = of j ]     ( m ) [ bbox ] at ( 0,0 ) @xmath209 ; ( m.west ) + + ( 0 , ) coordinate ( moli ) ; ( m.west ) + + ( 0,- ) coordinate ( muli ) ; ( m.east ) + + ( 0 , ) coordinate ( more ) ; ( m.east ) + + ( 0,- ) coordinate ( mure ) ; ( more ) ",
    "+ + ( , 0 ) ++(0 , ) node ( xo ) [ near end , right ] @xmath9 ; ( mure ) ",
    "+ + ( , 0 ) ++(0,- ) node ( xu ) [ near end , right ] @xmath5 ; ( moli )  + +",
    "( -,0 ) ++(0 , ) node ( yo ) [ near end , left ] @xmath13 ; ( muli ) ",
    "+ + ( -,0 ) ++(0,- ) node ( yu ) [ near end , left ] @xmath53 ; ( xo.north east ) + + ( 1ex,0 ) coordinate ( ore )  ( ore|-xu.south ) ;    ; ( try ) [ right = of m2 ] ; ( m3 ) [ right = of try ]     ( m ) [ bbox ] at ( 0,0 ) @xmath209 ; ( m.west ) + + ( 0 , ) coordinate ( moli ) ; ( m.west ) + + ( 0,- ) coordinate ( muli ) ; ( m.east ) + + ( 0 , ) coordinate ( more ) ; ( m.east ) + + ( 0,- ) coordinate ( mure ) ; ( moli )  + + ( -,0 ) |- ( muli ) ; ( more ) ",
    "+ + ( , 0 ) ++(0 , ) node ( xo ) [ near end , right ] @xmath9 ; ( mure ) ",
    "+ + ( , 0 ) ++(0,- ) node ( xu ) [ near end , right ] @xmath5 ; ( xo.north east ) + + ( 1ex,0 ) coordinate ( ore )  ( ore|-xu.south ) ;    ;    similarly to the definition of the spectral norm , the nuclear norms on @xmath25 and @xmath193 induce a norm on @xmath202 , @xmath212 perhaps surprisingly , the induced nuclear norm of maps of the form @xmath213 can be computed efficiently @xcite , as explained in detail below .",
    "this motivates studying the _ diamond norm _ @xcite @xmath214 it plays an important role in quantum mechanics @xcite and is also the core concept of this work . using the choi - jamiokowski isomorphism ,",
    "the diamond norm can indeed be written @xcite as @xmath215 where the square norm was defined variationally in eq .  .",
    "hence , for the case of a measurement map @xmath216 , the reconstruction based on the square norm can also be written as @xmath217    & { \\mathrm{subject\\ to } } &      \\begin{pmatrix }            y & -j(m ) \\\\",
    "-j(m){^\\dagger } & z          \\end{pmatrix }               \\succeq 0 \\ , ,    \\\\[.9em ]    & &   y , z \\in \\operatorname{pos}({{\\mathcal{w}}}\\otimes { { \\mathcal{v } } } ) \\ , , \\\\    & & { { \\left\\vert { { \\mathcal{a}}}(m)-y \\right\\vert}_{\\mathrm{f } } } \\leq \\eta \\ , . \\end{array}\\ ] ]      our problem of retrieval of unitary basis changes is motivated by the phase retrieval problem .",
    "retrieving phases from measurements that are ignorant towards them has a long - standing history in various scientific disciplines @xcite .",
    "a discretized version of this problem can be phrased as the task of inferring a complex vector @xmath218 from measurements of the form @xmath219 where @xmath220 .",
    "recently , the mathematical structure of this problem has received considerable attention @xcite .",
    "one way of approaching this problem is to recast it as a matrix problem which has the benefit that the measurements become linear . indeed , setting @xmath221 and @xmath222 reveals that @xmath223 this `` lifting '' trick allows for re - casting the phase retrieval problem as the task of recovering a hermitian rank - one matrix @xmath224 from linear measurements of the form @xmath222 .",
    "recently , ling and strohmer @xcite used similar techniques to recast the important problem of self - calibration in hardware devices as the task to recover a non - hermitian rank - one matrix @xmath225 from similar linear measurements .    in this section ,",
    "we consider the matrix - analogue of such a task and set @xmath226 but keep @xmath5 and @xmath13 as labels .",
    "concretely , we consider maps @xmath197 of the form @xmath227 where @xmath228 and @xmath229 are fixed unitaries .",
    "note that any such map has a choi matrix of the form @xmath230 which corresponds to an outer product of the form @xmath231 .",
    "moreover , unitarity of both @xmath228 and @xmath229 assures that all such maps meet the requirements of theorem [ thm : extremality ] .",
    "we aim to numerically recover such maps from two different types of measurements : ( i ) gaussian measurements and ( ii ) structured measurements .",
    "the gaussian measurements are given by a measurement map @xmath232 with real and imaginary parts of all of its components drawn from a normal distribution with zero mean and unit variance .",
    "in the case of structured measurements , @xmath209 receives rank-@xmath36 inputs and then inner products with regular measurement matrices are measured .",
    "more precisely , the measurement map @xmath233 is given by @xmath234\\ , , \\end{aligned}\\ ] ] where @xmath235 are chosen uniformly from the complex unit sphere @xmath236 .",
    "the matrices @xmath90 , on the other hand , are independent instances of the random matrix @xmath237 , where @xmath238 is a fixed , real - valued diagonal matrix and both @xmath228 and @xmath229 are chosen independently from the unique unitarily invariant haar measure over @xmath239 . for our numerical studies ,",
    "we restrict ourselves to even dimensions @xmath240 and set @xmath241 .",
    "this in particular assures @xmath242 .",
    "as we will see , similar types of measurements can be used in quantum process tomography and blind matrix deconvolution .    for both measurement setups ,",
    "we find that diamond norm reconstruction outperforms nuclear norm reconstruction ; see figure  [ fig : uv ] .",
    "interestingly , the structured measurements are better than the gaussian measurements for the diamond norm reconstruction , while for the nuclear norm reconstruction we find the converse .",
    "finally , we would like to to point out that ling and strohmer introduced a new algorithm  dubbed `` sparselift ''  to efficiently reconstruct the signals they consider and simultaneously promote sparsity @xcite .",
    "it is an intriguing open problem to compare the performance of sparselift to the constrained diamond norm minimization advocated here for different types of practically relevant measurement ensembles .",
    "we leave this to future work .",
    "the problem of reconstructing quantum mechanical processes from measurements is referred to as _ quantum process tomography_. as explained in the next paragraph , quantum processes are described by maps that saturate the norm inequality and thus are natural candidates for diamond norm - based methods .",
    "[ [ preliminaries . ] ] preliminaries .",
    "+ + + + + + + + + + + + + +    a positive semidefinite operator @xmath243 with unit trace @xmath244 is called a _ density operator _ and a matrix representation is a _",
    "density matrix_. the convex space of density operators is denoted by @xmath245 and its elements are referred to as _ quantum states_. the extreme elements of @xmath246 are called _ pure states _ and are given by rank - one operators of the form @xmath247 with @xmath37-norm normalized _ state vectors _ @xmath248 .",
    "observable _ is a self - adjoint operator @xmath249 and the _ expectation value _ of @xmath250 in state @xmath251 is @xmath252 .",
    "note that in the case where @xmath253 and @xmath250 are diagonal , @xmath253 corresponds to a classical probability vector and @xmath250 to a random variable also with expectation value @xmath254 .",
    "for the following definitions it is helpful to know that quantum systems are composed to larger quantum systems by taking tensor products of operators .",
    "a map @xmath197 is called _ completely positive _ if @xmath255 with @xmath49 from eq .  .",
    "this is the case if and only if for every vector space @xmath5 the map @xmath256 preserves the cone @xmath257 of positive semidefinite operators .",
    "@xmath258 is called _ trace preserving _ if @xmath259 for all @xmath43 .",
    "the convex space of maps that are both , completely positive and trace preserving is denoted by @xmath260 and its elements are quantum operations as they map density operators to density operators and they are also called _ quantum channels_.",
    "the _ kraus rank _ of a quantum channel @xmath261 is the rank of its choi matrix @xmath208 .",
    "a channel @xmath261 of kraus rank @xmath139 can be written as @xmath262 where @xmath263 are so - called _ kraus operators _ satisfying @xmath264 , and no other such decomposition has fewer terms .",
    "a special role is played by _",
    "unitary channels _ , which are channels of unit kraus rank . in this case",
    ", the single kraus operator in the kraus representation has to be unitary .",
    "unitary quantum channels describe coherent operations in the sense that for isolated quantum systems ( i.e. , systems that are decoupled from anything else ) one can only have unitary quantum channels .",
    "quantum channels describing situations where the system is affected by noise have kraus ranks larger than one .",
    "in many experimental situations , one aims at the implementation of a unitary channel , but actually implements a channel whose kraus rank is larger than one , but is still approximately low .",
    "therefore , process tomography of quantum channels with low kraus rank is an important task in quantum experiments .",
    "also , in the context of _ quantum error corretion _",
    ", low - rank deviations turn out to have a particularly adverse impact @xcite .",
    "this underscores the need to design efficient estimation protocols for this case .",
    "in the next paragraph , we present numerical results showing that , indeed , replacing the nuclear norm with the diamond norm in a straightforward `` compressive process tomography '' improves the results .",
    "we find it plausible that using the diamond norm as a `` drop in replacement '' for the nuclear norm will also lead to improvements in other , more advanced process tomography schemes .",
    "for example , kimmel and liu @xcite combine compressed process tomography with ideas from _ randomized benchmarking _ @xcite .",
    "this combination allows recovery using only clifford measurements that are robust to state preparation and measurement ( spam ) errors .",
    "their recovery guarantees are based on the geometric arguments presented in section  [ sub : convex_recovery ] .",
    "it thus seems fruitful to conduct numerical experiments using the diamond norm in their setting .",
    "[ [ numerical - results - for - quantum - process - tomography . ] ] numerical results for quantum process tomography .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    the task is to reconstruct @xmath265 from measurements of the form @xmath266 where @xmath267 encodes linear data acquisition , @xmath268 summarizes the measurement outcomes , and @xmath269 represents additive noise .",
    "the most general measurements conceivable in this context are so - called _ process povms _ @xcite .",
    "however , here we consider the case where @xmath59 is given by the preparation of pure states given by state vectors @xmath270 and measurements of observables @xmath271 , where @xmath272 $ ] .",
    "this yields similar measurements as in section  [ sec : uv ] , @xmath273 \\ , , \\ ] ] where each @xmath270 is chosen uniformly and independently from the complex unit sphere in @xmath5 .",
    "each observable @xmath271 is of the form @xmath274 , where each @xmath275 is drawn independently from the haar measure over all unitaries .",
    "once more , @xmath276 is a fixed hermitian operator with non - degenerate spectrum . with this measurement setup",
    ", quantum channels can be recovered from few measurements .",
    "once more , diamond reconstruction outperforms the conventional nuclear norm reconstruction , see figure  [ fig : qm ] .",
    "the _ blind deconvolution scheme _ as considered in ref .",
    "@xcite aims to reconstruct unknown vectors @xmath277 and @xmath278 . from this ,",
    "length @xmath279 signals are being generated as @xmath280 for known @xmath281 and @xmath282 .",
    "the observed quantity is the circular convolution of @xmath283 and @xmath73 , @xmath284 where @xmath285 denotes the standard basis of @xmath286 .",
    "this gives rise to a bi - linear problem , which can still be solved using a lifting technique to a variant of the matrix completion problem .",
    "the type of problem considered in this work allows for the _ blind matrix deconvolution _ , in which not vectors @xmath287 , but orthogonal or unitary matrices @xmath288 reflecting unknown rotations are reconstructed .",
    "( star ) [ starbox ] at ( 0,0 ) @xmath289 ; ( star ) ",
    "+ + ( -,0 ) node ( y ) [ gbox ] @xmath290 ; ( star ) |- + + ( , ) node ( b ) [ bbox ] @xmath291 ; ( star ) |- + + ( , - ) node ( c ) [ bbox ] @xmath163 ; ( b ) ",
    "+ + ( , 0 ) node ( u ) [ rbox]@xmath228 ; ( c )  + + ( , 0 ) node ( v ) [ rbox]@xmath229 ; ( u )  + + ( , 0 ) node ( h ) [ gbox]@xmath292 ; ( v )  + + ( , 0 ) node ( m ) [ gbox]@xmath293 ;    in this new problem , for known @xmath294 and real vectors @xmath295 with @xmath296 $ ] , that are an input to the problem , we seek to reconstruct @xmath297 from the circular convolutions @xmath298 of @xmath299 and @xmath300 , where now @xmath301 see also figure  [ fig : def_deconv ] .",
    "the observations are given by the @xmath302 vectors @xmath303 or , equivalently , by @xmath304 where @xmath305 defines the fourier transform @xmath180 and @xmath306 the hadamard product of vector @xmath171 and @xmath307 .",
    "let us denote the @xmath308-th rows of @xmath309 and @xmath310 by @xmath311 and @xmath312 , respectively .",
    "then @xmath313 with the unit rank matrices @xmath314 and @xmath315 .",
    "indeed , this is precisely a problem of the form discussed here , @xmath316 with @xmath317 and @xmath318 up to a phase , @xmath228 and @xmath229 can be trivially reconstructed from @xmath209 up to phase .",
    "that is to say , a matrix version of blind deconvolution can readily be cast into the form of problems considered in this work .",
    "numerically , we find a recovery from few samples and that the diamond norm reconstruction outperforms the nuclear norm based reconstruction from ref .",
    "@xcite adapted to our setting ; see figure  [ fig : deconvolution ] .",
    "many practical application of this problem are conceivable : the reconstruction of an unknown drift of a polarization degree of freedom in a channel problem is only one of the many natural ramifications of this setup .",
    "in this section , we prove proposition  [ prop : bounds_on_diamond_norm ] and an extension of theorem [ thm : extremality ] . in order to do so",
    ", we first define a generalization of the sign matrix to matrices that are not necessarily hermitian . this will give rise to the left and right absolute values of arbitrary matrices .",
    "then we introduce sdps , complementary slackness , and state the sdp for the square norm in standard form . combining all these concepts",
    ", this section cumulates in the proofs of proposition  [ prop : bounds_on_diamond_norm ] and theorem  [ thm : extremality ] .",
    "the singular value decomposition of a matrix @xmath319 is @xmath320 where @xmath321 are unitaries and @xmath322 is positive - semidefinite and diagonal .",
    "this decomposition allows one to define a `` sign matrix '' of @xmath23 :    [ def : sgn ] for any matrix @xmath319 with singular value decomposition we define its _ sign matrix _ to be @xmath323 .",
    "note that the sign matrix is in general not unique , but always unitary and it obeys @xmath324 therefore , @xmath325 indeed generalizes the sign - matrix @xmath326 ( which is defined exclusively for hermitian matrices ) upon right multiplication .",
    "the following auxiliary statement will be required later on and follows from a schur complement rule .",
    "[ lem : block_matrix_psd1 ] for every @xmath327 , one has @xmath328      semidefinite programs ( sdps ) are a class of optimization problems that can be evaluated efficiently , e.g. by using cvx @xcite .",
    "[ def : sdp ] a _ semidefinite program _ is specified by a triple @xmath329 , where @xmath330 and @xmath276 are self - adjoint operators and @xmath331 is a hermiticity preserving linear map .",
    "with such a triple , one associates a pair of optimization problems : @xmath332 @xmath333 is called _ primal feasible _ if it satisfies eq .   and eq .  .",
    "it is called _ optimal primal feasible _ if , additionally , for @xmath334 in eq .",
    "the maximum is attained .",
    "similarly , @xmath335 is called _ dual feasible _ if it satisfies eq .   and _ optimal dual feasible _ , if for @xmath336 the minimum in eq .",
    "is attained .",
    "sdps that exactly reproduce the problem structure outlined in this definition are said to be in _",
    "standard form_. but for specific sdps , equivalent formulations might often be more handy .",
    "_ weak duality _ refers to the fact that the value of the primal sdp can not be larger than the value of the dual sdp , i.e. , that @xmath337 for any primal feasible point @xmath338 and dual feasible point @xmath339 .",
    "an sdp is said to satisfy _ strong duality _ if the optimal values coincide , i.e. , if for some optimal primal feasible and dual feasible points @xmath340 and @xmath341 it hols that @xmath342 .",
    "in fact , from a weak condition , called slater s condition , strong duality follows .    [ lem : comp_slack ] suppose that @xmath343 characterizes an sdp that obeys strong duality and let @xmath344 and @xmath335 denote optimal primal and dual feasible points , respectively ( i.e. @xmath345 ) . then @xmath346    the following , somewhat exhaustive , classification of the square norm s sdp will be instrumental later on .",
    "[ lem : watrous_sdp ] [ thm : diamond ] let @xmath347 be a bipartite operator .",
    "then its square norm @xmath348 can be evaluated by means of an sdp @xmath343 that satisfies strong duality . in standard form , it is given by the block - wise defined matrices @xmath349 where @xmath350 denotes the zero - vector , and @xmath351 , as well as @xmath352 represent zero matrices of appropriate dimension . finally , the map @xmath353 acts as @xmath354 and has an adjoint map given by @xmath355 where @xmath356 , once more , represents a zero - matrix .",
    "lemma  [ lem : watrous_sdp ] presents an sdp for the square norm in standard form .",
    "although this standard form is going to be important for our proofs , it is somewhat unwieldy .",
    "fortunately , elementary modifications @xcite allow to reduce the sdp to the following pair .",
    "@xmath357      & & { \\mathrm{subject\\ to } } &           \\begin{pmatrix }          { \\mathbbm{1}}_{{\\mathcal{w}}}\\otimes \\rho & z \\\\",
    "z{^\\dagger } & { \\mathbbm{1}}_{{\\mathcal{w}}}\\otimes \\sigma          \\end{pmatrix }      \\succeq 0\\ , , \\hspace{1 cm } \\quad      \\\\[1em ]      & & & \\operatorname{tr}(\\rho ) = \\operatorname{tr}(\\sigma ) = \\dim({{\\mathcal{v } } } ) \\ , ,      \\\\[.2em ]      & & & \\rho,\\sigma \\in \\operatorname{pos}({{\\mathcal{v}}})\\ , ,      \\\\[.2em ]      & & & z \\in { \\operatorname{\\mathrm{l}}}({{\\mathcal{w}}}\\otimes { { \\mathcal{v } } } )    \\ ,     \\end{array } \\\\[1em ] \\label{eq : watrous_sdp_dual } & \\begin{array}{lrll }      \\textbf{dual:\\qquad\\quad } & { { \\left\\vert x \\right\\vert}_{{\\protect\\scalebox{0.5}{$\\square$ } } } }      = & \\min & \\frac{\\dim({{\\mathcal{v}}})}{2}\\bigl({{\\left\\vert \\operatorname{tr}_{{\\mathcal{w}}}(y ) \\right\\vert } } + { { \\left\\vert \\operatorname{tr}_{{\\mathcal{w}}}(z ) \\right\\vert}}\\bigr )      \\\\[.5em ]      & &   { \\mathrm{subject\\ to } } &            \\begin{pmatrix }          y & -x \\\\ -x{^\\dagger } & z          \\end{pmatrix }      \\succeq 0 \\ , ,      \\\\[1em ]      & & & y , z \\in \\operatorname{pos}({{\\mathcal{w}}}\\otimes { { \\mathcal{v } } } ) \\ , .",
    "\\end{array}\\end{aligned}\\ ] ] this simplified sdp pair for the square norm comes in handy for establishing the final claim in proposition  [ prop : bounds_on_diamond_norm ] . for hermitian matrices ,",
    "the first two bounds presented there were already established in ref .",
    "* lemma 7 ) . here , we show that an analogous strategy remains valid for matrices that need not be hermitian .",
    "let us start with recalling the variational definition of the square norm : @xmath358 as already mentioned , inserting @xmath359 into eq .",
    "establishes the lower bound ( @xmath52 ) .",
    "also , a generalized version of hlder s inequality assures @xmath360 for any @xmath361 and @xmath126 . inserting this bound into the variational definition of @xmath348 results in @xmath362 , which is the second bound .    for the final bound ( @xmath363 ) we consider the simplified version of the square norm s dual sdp .",
    "lemma  [ lem : block_matrix_psd1 ] assures that setting @xmath364 results in a feasible point of this program .",
    "inserting this point into the objective function yields a value of @xmath365 , because @xmath366 .",
    "the bound follows from this value and the structure of the optimization problem .      in this section , we prove an extension of theorem  [ thm : extremality ] .",
    "in particular , this more general result relates theorem  [ thm : extremality ] to optimal feasible points in watrous sdp from lemma  [ lem : watrous_sdp ] .",
    "these will contain the generalizations of the sign matrix from definition  [ def : sgn ] .",
    "[ thm : extremal ] let @xmath126 be a bipartite operator and set @xmath367 .",
    "then the points ( [ item : extremal])([item : reduced_eq ] ) are equivalent :    [ item : extremal ] @xmath23 satisfies @xmath368    [ item : xsharp ] some @xmath369 of the form @xmath370 is a primal optimal feasible point for watrous sdp @xmath329 from lemma  [ lem : watrous_sdp ] .    [ item : ysharp ] some @xmath371 of the form @xmath372 is a dual optimal feasible point for watrous sdp @xmath329 from lemma  [ lem : watrous_sdp ] .",
    "[ item : reduced_propto ] @xmath23 satisfies @xmath373    [ item : reduced_eq ] @xmath23 satisfies @xmath374    similar to the actual sdp , the optimal feasible points presented in theorem  [ thm : extremal ] have simplified counterparts that correspond to optimal feasible points of the simplified sdps and . for the sake of completeness , we present them in the following corollary .    for any @xmath126 , optimal feasible points of the primal sdp and the dual sdp for the square norm are given by the following .",
    "@xmath375    this statement follows straightforwardly from theorem  [ thm : extremal ] by considering the reduced formulations and of the sdp from lemma  [ lem : watrous_sdp ] .    for @xmath376",
    "all statements are evident . from now on",
    ", we assume that @xmath377 , or , equivalently , @xmath378 .",
    "proof of ( [ item : extremal ] ) @xmath379 ( [ item : xsharp ] ) .",
    ": :    note that @xmath380 by    lemma  [ lem : block_matrix_psd1 ] .",
    "straightforward evaluation of    @xmath381 from lemma  [ lem : watrous_sdp ] reveals that    @xmath340 is indeed a primal feasible point :    @xmath382 in order to show optimality , we evaluate the primal    sdp s objective function given by @xmath163 in eq .  .",
    "employing    formulas and to express the absolute values of @xmath23 , we    obtain @xmath383 by assumption , this is indeed optimal .",
    "proof of ( [ item : xsharp ] ) @xmath379 ( [ item : ysharp ] ) and ( [ item : reduced_propto ] ) : : :    strong duality of watrous sdp from lemma  [ lem : watrous_sdp ] assures    that an optimal dual solution @xmath341 exists and that    complementary slackness holds . since @xmath384 from    eq .",
    "does not depend on block off - diagonal terms , optimal feasibility    only depends on the block diagonal parts .",
    "hence , we write    @xmath341 as @xmath385 complementary slackness ( lemma  [ lem : comp_slack ] )    implies that @xmath386 and    @xmath387 must equal each other . this in    turn demands @xmath388    where we have once more employed identities and for @xmath325    to obtain the absolute values of @xmath23 .",
    "equality of and in    the first two diagonal entries ( also guaranteed by complementary    slackness ) furthermore assures @xmath389 hence ,    @xmath390    and both , ( [ item : ysharp ] ) and ( [ item : reduced_propto ] ) follow .",
    "proof of ( [ item : reduced_propto ] ) @xmath379 ( [ item : reduced_eq ] ) : : :    let @xmath391 be constants such that    @xmath392 taking the trace    of both equations and recognizing the nuclear norm reveals that    @xmath393    and , similarly ,    @xmath394 which    proves the claimed implication .",
    "proof of ( [ item : reduced_eq ] ) @xmath379 ( [ item : extremal ] ) : : :    the crucial observation for this implication is that    assumption  ( [ item : reduced_eq ] ) alone assures that    @xmath341 defined in eq .   with all off - diagonal blocks    set to zero is a feasible point of watrous dual sdp , albeit not    necessarily an optimal one .",
    "this claim is easily verified by direct    computation . inserting this dual feasible point into the sdp s    objective function results in @xmath395 since every dual    sdp corresponds to a constrained minimization , evaluating the dual    objective function at any feasible point results in an upper bound on    the optimal value . in our case , obtain the upper bound    @xmath130 ,    which together with the converse bound from    proposition  [ prop : gaussian_cs ] , implies equality between the two .",
    "we conclude by mentioning several observations and research directions that may merit further attention .    [ [ measurement - errors . ] ] measurement errors .",
    "+ + + + + + + + + + + + + + + + + + +    in our analysis we considered reconstructed matrices @xmath396 and @xmath397 from eqs .   and that are required to be @xmath166-close to the ideal operator @xmath88 .",
    "such a reconstruction stably tolerates additive errors @xmath398 as in eq .",
    "as long as they obey @xmath82 . for operators",
    "@xmath88 satisfying the extremality we prove that recovery guarantees for @xmath397 are inherited by @xmath396 .",
    "a similar situation is true for the reconstruction of maps @xmath399 by means of diamond norm minimization . for the idealized setting of noiseless measurements ( @xmath400 ) ,",
    "we demonstrate numerically that often @xmath401 vanishes while @xmath402 is large . a numerical analysis for the noisy case @xmath403 yields similar results as for @xmath400 .",
    "for the noisy case the phase transition from having no recovery to almost always recovering the signal up to @xmath404 broadens equally for both diamond and nuclear norm regularization .",
    "[ [ partial - derandomizations . ] ] partial derandomizations .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + +    while initial theoretical results often rely on measurements that follow a gaussian distribution , later on significant effort has been put into derandomizing the measurement process . on the one hand , recovery guarantees for structured measurements",
    "were proven @xcite . on the other ,",
    "also the distributions form which the measurements are drawn were partially derandomized @xcite ( see also section  [ sec : application_low_rank ] ) , relying on above mentioned @xmath190-designs .",
    "the later methods rely on an analysis of the measurement map s descent cone .",
    "hence , such recovery guarantees for partially derandomized measurements are also inherited by our reconstruction via diamond norm minimization . in a similar",
    "setting , a partial derandomization of the random unitaries used as part of the measurements for the retrieval of unitary basis changes ( section  [ sec : uv ] ) and for quantum process tomography ( section  [ sec : quantum ] ) seems very promising . here , structural insights @xcite on unitary designs could be used in future work .",
    "[ [ improvement - from - structured - measurements . ] ] improvement from structured measurements .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    we numerically performed the reconstruction of unitary basis changes in section  [ sec : uv ] for two different measurement settings : gaussian measurements and certain structured measurements .",
    "for the nuclear norm , the reconstruction from gaussian measurements performed slightly better than the one from structured measurements , just as expected .",
    "perhaps surprisingly , we observed the converse for the diamond norm reconstructions . here , the structure of the measurements seems to be favourable for the reconstruction process .",
    "this observation motivates the search for recovery guarantees for diamond norm reconstruction with structured measurements .",
    "such structured measurements are also crucial for the quantum process tomography in section  [ sec : quantum ] and blind matrix convolution in section  [ sec : deconv ] .",
    "[ [ cpt - as - a - constraint - in - the - quantum - channel - reconstructions . ] ] cpt as a constraint in the quantum channel reconstructions .",
    "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +    a map @xmath197 is a quantum channel if and only if @xmath405 when aiming at reconstructing quantum channels , these additional constraints can , in principle , be included in the sdps and for the diamond norm and nuclear norm reconstructions .",
    "doing so leads to a significant overhead in the numerical reconstruction process .",
    "numerically , one can observe that the recovery success of the diamond norm reconstruction is unchanged , while the nuclear norm reconstruction performs significantly better .",
    "in fact , it seems to perform roughly as good as the diamond norm reconstruction when these constraints are included in the sdp . in this sense",
    ", the cpt structure can be used in the nuclear norm reconstruction at the expense of a longer computation time to reduce the number of measurements , while in the diamond norm reconstruction the cpt structure is already inbuilt .",
    "the run - time of the diamond norm reconstruction and the nuclear norm reconstruction are practically the same for a given number of measurements and scales polynomially with the number of constraints .",
    "therefore , the diamond norm reconstruction can help to render larger quantum systems accessible to quantum process tomography .",
    "we thank c.  riofro , i.  roth , and d.  suess for insightful discussions and s.  kimmel and y.k .",
    "liu for advanced access to ref .",
    "the research in berlin has been supported by the eu ( siqs , aqus , raquel ) , the bmbf ( q.com ) , the dfg project ei 519/9 - 1 ( spp1798 cosip ) and the erc ( taq ) .",
    "the work of dg and rk is supported by the excellence initiative of the german federal and state governments ( grants zuk 43 & 81 ) , the aro under contract w911nf-14 - 1 - 0098 ( quantum characterization , verification , and validation ) , the dfg project gro 4334/2 - 1 ( spp1798 cosip ) , and the state graduate funding program of baden - wrttemberg .",
    "in this appendix we provide known material to make this work more self contained .",
    "we provide sdps for the nuclear norm and the spectral norm , and introduction to tensor products and a basis independent definition of the choi - jamiokowski isomorphism . also , we devote a subsection to low - rank matrix recovery . there",
    "we show how the statements presented in section  [ sec : application_low_rank ] can be derived using geometric proof techniques . on the contrary to the other supplementary chapters ,",
    "this section does include technical novelties .",
    "[ [ basic - concepts - of - multilinear - algebra - and - the - choi - jamiokowski - isomorphism ] ] basic concepts of multilinear algebra and the choi - jamiokowski isomorphism ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~    the core objects of this work are tensors of order four and naturally fall into the realm of multilinear algebra . here",
    "we give a brief introduction on core concepts of multilinear algebra that can be found in any textbook on that topic .",
    "our presentation here is influenced by @xcite .",
    "let @xmath406 be ( finite dimensional , complex ) vector spaces with associated dual spaces @xmath407 .",
    "a function @xmath408 is _ multilinear _ , if it is linear in each @xmath409 .",
    "the space of such functions constitutes the _ tensor product _ of @xmath407 and we denote it by @xmath410 . by reflexivity @xmath411 ,",
    "the tensor product @xmath412 is the space of all multilinear functions @xmath413 its elementary elements @xmath414 are the _ tensor product _ of vectors @xmath415 which alternatively can be constructed by means of the kronecker product ",
    "however , such an explicit construction requires explicit choices of bases in @xmath406 .    with such a notation",
    ", the space of linear maps @xmath416 ( matrices ) corresponds to the tensor product @xmath417 which is spanned by rank - one operators @xmath418 . with this identification , it is straightforward to define the tensor product of @xmath419 and @xmath420 to be @xmath421 analogously to before , the elementary @xmath422 of this space are the _ tensor product _ of maps @xmath423 and @xmath424 . restricting to tensor products of endomorphisms ,",
    "i.e.  @xmath425 and @xmath426 , the _ partial trace _ ( over the first tensor factor ) for elementary elements to be @xmath427 and extend it linearly to @xmath428 . note that with the identification @xmath429 , @xmath430 corresponds to the natural contraction between @xmath13 and @xmath53 .",
    "this is illustrated in figure  [ fig : tensor_diagram ] .",
    "similarly to @xmath420 , the maps @xmath431 introduced in section  [ sec : notation_maps ] can be viewed as elements of the tensor product space @xmath432 which can be seen as a four - linear vector space .",
    "there are several equivalent ways to interpret its elements . for the given applications of our work ,",
    "we have made heavy use of the _ choi - jamiokowski isomorphism _ which acts on four - linear tensors by permuting tensor factors : @xmath433 applied to the four - linear space of maps we obtain @xmath434 and @xmath435 which are basis independent . consequently the choi - jamiokowski isomorphism is linear bijection from maps to operators @xmath436 its explicit definitions and in the main text are just basis - dependent realization of this more general identification .",
    "we illustrated this fact pictorially in figure  [ fig : tensor_diagram ] by resorting to _ tensor network _",
    "@xcite or _ wiring diagrams _ @xcite .      our main geometric insight ",
    "corollary [ cor : subset ]  asserts that any square norm descent cone is always contained in the corresponding one of the nuclear norm , provided that the operators in question obey @xmath437 . when applying this idea to low - rank matrix recovery , we started with mentioning proposition  [ prop : gaussian_cs ]",
    "this is a non - uniform recovery guarantee that is stable towards additive noise .",
    "however , with some additional work , corollary [ cor : subset ] allows for stronger conclusions .",
    "some of them are summarized in proposition  [ prop : fourth_moments ] and proposition  [ prop : rank_one ] , respectively . here",
    ", we outline how these results are obtained . in section [ sub : convex_recovery ]",
    "we introduced widely used geometric proof techniques for low - rank matrix recovery mainly following ref .",
    "these aim at recovery of a fixed object @xmath88 of interest and thus it suffices to focus on precisely one descent cone , namely @xmath438 , or @xmath439 , respectively . by taking a closer look at the actual proof techniques ",
    "most notably mendelson s small ball method @xcite , or",
    "tropp s bowling scheme @xcite  one can see that such a restriction to a single object of interest is not necessary .",
    "up to our knowledge , this was first pointed out in ref .",
    "@xcite and at the heart of this observation is the following technical statement .",
    "[ lem : effective_low_rank ] fix @xmath440 and let @xmath441 be the union of all descent cones anchored in nonzero matrices @xmath442 of rank at most @xmath139 .",
    "then , every element @xmath443 obeys @xmath444    for hermitian matrices , a slightly stronger statement of this type was presented in ( * ? ? ?",
    "* lemma 10 ) . here wo provide a different proof that does not require hermiticity and exploits a variant of pinching .",
    "note that for any @xmath31 it follows from the definition of the schatten-@xmath449 norms that the left hand side of eq .",
    "coincides with @xmath452 .",
    "using this identity and the decomposition @xmath453 allows us to conclude @xmath454 where we have exploited unitary invariance of schatten-@xmath449 norms and the fact that both @xmath455 and @xmath456 are unitary matrices .",
    "it suffices to prove this statement for any fixed descent cone @xmath457 , where @xmath43 has rank at most @xmath139 .",
    "let @xmath458 and @xmath459 be the column and row ranges of @xmath23 ( these need not coincide , since @xmath23 need not necessarily be hermitian ) and let @xmath460 be orthogonal projections onto these subspaces .",
    "note that if @xmath23 has a singular value decomposition @xmath461 , then @xmath462 and @xmath463 , where @xmath464 is defined component - wise by @xmath465 if @xmath466 and @xmath467 otherwise . introducing orthogonal complements",
    "@xmath468 and @xmath469 allows us to define @xmath470 this is an orthogonal projection with respect to the frobenius inner product and obeys @xmath471 by construction .",
    "its complement amounts to @xmath472 which obeys @xmath473 .",
    "note that this is a straightforward generalization of the @xmath474-space introduced in ( * ? ? ?",
    "* equation ( 2 ) ) to non - hermitian matrices .",
    "analogously to there , a decomposition @xmath475 is valid for every @xmath476 and every @xmath477 has rank at most @xmath478 by construction .",
    "now choose @xmath479 and note that by definition @xmath480 must be valid for some @xmath481 .",
    "combining this with lemma  [ thm : pinching ] ( pinching ) assures @xmath482 where we have employed @xmath483 and @xmath471 . also , note that hlder s inequality assures @xmath484 for any @xmath450 and unitary @xmath228 . employing this for @xmath485 , where the sign matrix @xmath325 of @xmath23 was defined in def .",
    "[ def : sgn ] , reveals @xmath486 where we have in addition used that @xmath487 has rank at most @xmath139 and frobenius norm smaller than or equal to @xmath488 .",
    "combining the bounds   and implies @xmath489 since @xmath481 , this bound implies @xmath490 .",
    "finally , this relation allows us to infer the result , @xmath491 where we also exploited the fact that @xmath492 has rank at most @xmath478 .",
    "lemma  [ lem : effective_low_rank ] asserts that any matrix that lies in the nuclear norm s descent cone of any low - rank matrix , is `` effectively '' a low - rank matrix as well .",
    "this structural property together with mendelson s small ball method is enough to bound the minimal conic singular value of a measurement map @xmath59 with respect to the union of all possible descent cones .",
    "here we provide a particular realization of mendelson s small ball method that is directly applicable to low - rank matrix recovery ( see e.g.  ref .",
    "* section 4 ) ) .",
    "[ thm : mendelson ] let @xmath493 be real subspace of linear maps and let @xmath494 be a measurement map @xmath495 , where each @xmath158 is an independent copy of a random matrix @xmath496 and @xmath145 denotes the standard basis in @xmath146 .",
    "also , let @xmath497 , where @xmath498 was defined in lemma  [ lem : effective_low_rank ] .",
    "then for any @xmath499 , the bound @xmath500 holds with probability at least @xmath501 . here",
    "@xmath502   \\\\",
    "w_m \\left ( e_r , { { \\mathcal{a}}}\\right )   & =   { \\mathbb{e}}\\left [ \\sup_{y \\in e_r } \\operatorname{tr } ( h{^\\dagger}y ) \\right ] \\ , , \\quad   \\text{where}\\quad    h = \\frac{1}{\\sqrt{m } } \\sum_{j=1}^m \\epsilon_j a_j\\end{aligned}\\ ] ] and @xmath503 being a rademacher sequence with equal probability . ] .",
    "thanks to lemma  [ lem : effective_low_rank ] and hlder s inequality we can bound @xmath505 in theorem  [ thm : mendelson ] by @xmath506 \\leq { \\mathbb{e}}\\left [ \\sup_{y \\in e_r } { { \\left\\vert y \\right\\vert}_\\ast } { { \\bigl\\vert h{^\\dagger}\\bigr\\vert } } \\right ]   \\\\ & \\leq { \\mathbb{e}}\\left [ \\sup_{y \\in e_r } ( 1+\\sqrt{2 } ) \\sqrt{r } { { \\left\\vert y \\right\\vert}_{\\mathrm{f } } } { { \\left\\vert h \\right\\vert } } \\right ]   = ( 1+\\sqrt{2 } ) \\sqrt{r}\\ , { \\mathbb{e}}\\left [ { { \\left\\vert h \\right\\vert } } \\right ] \\ , , \\end{aligned}\\ ] ] which is much easier to handle . this simplification together with mendelson s small ball method  theorem  [ thm : mendelson ]  and the geometric error bound for convex recovery  proposition  [ prop : general_reconstruction ]  provide a convenient sufficient means to assure that a given measurement process @xmath59 allows for uniform and stable low - rank matrix recovery via nuclear norm minimization :    [ sufficient criteria for uniform recovery][prop : sufficient_criteria ] let @xmath507 be a measurement map as defined in theorem  [ thm : mendelson ] and fix @xmath440 .",
    "suppose that this measurement map obeys @xmath508 for some @xmath509 and also @xmath510 \\leq c_2 \\sqrt{m / r}$ ] , where @xmath511 and @xmath512 are positive constants obeying @xmath513 .",
    "then , with probability at least @xmath514 , this measurement map is capable of stably reconstructing any matrix @xmath88 of rank at most @xmath139 from noisy measurements of the form @xmath515 obeying @xmath150 by means of nuclear norm minimization . concretely , the solution @xmath516 of the optimization obeys @xmath517 here @xmath518 denote sufficiently small absolute constants .",
    "note that unlike proposition  [ prop : gaussian_cs ] , such a recovery statement is _ uniform _ , in the sense that with high probability a single measurement map suffices to recover any low - rank matrix .",
    "however , it still relies on the geometric proof technique of bounding the widths of nuclear norm descent cones .",
    "this is because the set @xmath498 is just the union over all possible nuclear norm descent cones anchored at matrices of rank at most @xmath139 . as a result , observation  [ obs : smaller_dc ] ( `` the smaller the descent cone , the better the recovery '' ) is also valid in this setting and corollary  [ cor : subset ] allows us to draw the following conclusion .    [ uniform recovery from square norm regularization ] [ cor : sufficient_diamond ] the assertions of proposition  [ prop : sufficient_criteria ] remain true for recovery via square norm regularization , for the case of uniform recovery of rank-@xmath139 maps @xmath519 satisfying @xmath157 .",
    "moreover , the corresponding constants obey @xmath520 and @xmath521 , meaning that the recovery statement can not be worse .    theorem  [ thm : mendelson ] together with eq .   and the assumptions on @xmath59 assure for any @xmath522 @xmath523 - \\xi t \\\\ \\geq &   \\xi c_1 \\sqrt{m } - 2(1+\\sqrt{2 } ) c_2 \\sqrt{m } - \\xi t   \\end{aligned}\\ ] ] with probability at least @xmath524 .",
    "introducing @xmath525  which is strictly positive by assumption  and setting @xmath526 then implies @xmath527 with probability at least @xmath528 , where @xmath529 .",
    "with such an estimate at hand , the claim follows from applying proposition  [ prop : general_reconstruction ] .",
    "we conclude this section with presenting a selection of measurement ensembles that meet the criteria of proposition  [ prop : sufficient_criteria ] and as a consequence also the ones of corollary  [ cor : sufficient_diamond ] .",
    "we start with measurement ensembles that allow for recovering real - valued matrices @xmath43 .",
    "[ cor : derandomizations1 ] suppose that @xmath5 is a real - valued vector spaces and let @xmath530 be the measurement map @xmath495 , where each @xmath158 is a random matrix with independent entries obeying @xmath531 = 0,\\quad   { \\mathbb{e}}\\left [ a_{i , j}^2 \\right ] = 1 , \\quad { \\mathbb{e}}\\left [ a_{i , j}^4 \\right ] \\leq f,\\ ] ] where @xmath180 is a constant .",
    "then a sampling rate of @xmath532 suffices to meet the requirements of proposition  [ prop : sufficient_criteria ] .",
    "the result quoted in corollary  [ cor : derandomizations1 ] was not established as a subroutine of a geometric proof technique for nuclear norm recovery , but consists of auxiliary statements that help to establish the frobenius stable null space property ( * ? ? ?",
    "* definition 10 )  a powerful alternative to geometric proof techniques relying on proposition  [ prop : general_reconstruction ] .",
    "however , if embedded properly into the framework of geometric recovery proof techniques , the auxiliary statements in ref .",
    "@xcite  see also ref .",
    "@xcite  can still be used to establish recovery guarantees that rely on bounding the widths of descent cones . for our purposes ,",
    "such a geometric proof environment is crucial , and this entire section is devoted to develop it .",
    "however , we point out that introducing and analyzing the square norm analogue of the frobenius stable null space property  which is geared towards nuclear norm minimization  does constitute an intriguing follow - up problem .",
    "we leave this to future work .    for a proof of this statement",
    ", we utilize auxiliary statements from ref .",
    "lemma 11 in loc .",
    "asserts that such random matrices with bounded fourth moments obey @xmath533 , where @xmath180 is the fourth - moment bound .",
    "also , ref .",
    "? * lemma 12 ) assures @xmath534 \\leq c_f \\sqrt{n}$ ] , where @xmath179 is a constant that only depends on @xmath180 .",
    "this in particular assures @xmath535 \\leq c_f",
    "\\sqrt{n } \\leq \\frac{c_f}{\\sqrt{c } } \\sqrt{\\frac{m}{r}}\\ ] ] and we can set @xmath536 , @xmath537 and @xmath538 . choosing the constant @xmath163 in the sampling rate large enough assures that these constants obey @xmath539 for @xmath536 and all the requirements of proposition  [ prop : sufficient_criteria ] are met .",
    "the claim then follows from applying this statement .",
    "we conclude this section with embedding the main results of ref .",
    "@xcite into this framework .",
    "in fact , the entire apparatus presented in this section is a condensed version of the proofs in loc .",
    "however , the reader s convenience , we include the corresponding statement here as well .",
    "[ cor : derandomizations2 ] consider measurement maps @xmath540 of the form @xmath495 .",
    "then the following measurement ensembles meet the requirements of proposition  [ prop : sufficient_criteria ] , if restricted to the recovery of hermitian matrices :    1 .   @xmath186 and each @xmath222 corresponds to the outer product of a complex standard gaussian vector @xmath541 with itself , 2 .",
    "@xmath542 and each @xmath222 is the outer product of a randomly selected element @xmath185 of a complex projective @xmath2-design .",
    "let us start with the gaussian case . in ref .",
    "* section 4.1 . )",
    "the bounds @xmath543 and @xmath534 \\leq c_1 \\sqrt{n}$ ] are derived under the assumption @xmath544 , where @xmath545 is sufficiently large .",
    "thus , similarly to the proof of corollary  [ cor : derandomizations1 ] , setting @xmath536 and choosing the constant @xmath188 in @xmath62 sufficiently large indeed meets the requirements of proposition  [ prop : sufficient_criteria ] .    for the @xmath2-design case , ( * ? ? ?",
    "* proposition 12 ) assures that the bound @xmath546 is valid for any @xmath547 $ ] . also , ref .",
    "* proposition 13 ) implies @xmath535 \\leq 3.1049 \\sqrt { n \\log ( 2n ) } \\leq \\frac{3.1049}{\\sqrt{c_{4d } } } \\sqrt{\\frac{m}{r}},\\ ] ] where we have inserted @xmath548 .",
    "thus , choosing @xmath549 appropriately and the constant @xmath189 in the sampling rate @xmath62 large enough again assures that the requirements of proposition  [ prop : sufficient_criteria ] are met ."
  ],
  "abstract_text": [
    "<S> in low - rank matrix recovery , one aims to reconstruct a low - rank matrix from a minimal number of linear measurements . within the paradigm of compressed sensing , </S>",
    "<S> this is made computationally efficient by minimizing the nuclear norm as a convex surrogate for rank . in this work , </S>",
    "<S> we identify an improved regularizer based on the so - called diamond norm , a concept imported from quantum information theory . </S>",
    "<S> we show that  for a class of matrices saturating a certain norm inequality  the descent cone of the diamond norm is contained in that of the nuclear norm . </S>",
    "<S> this suggests superior reconstruction properties for these matrices and we explicitly characterize this set . </S>",
    "<S> we demonstrate numerically that the diamond norm indeed outperforms the nuclear norm in a number of relevant applications : these include signal analysis tasks such as blind matrix deconvolution or the retrieval of certain unitary basis changes , as well as the quantum information problem of process tomography with random measurements . </S>",
    "<S> the diamond norm is defined for matrices that can be interpreted as order-4 tensors and it turns out that the above condition depends crucially on that tensorial structure . in this sense , this work touches on an aspect of the notoriously difficult tensor completion problem . </S>"
  ]
}