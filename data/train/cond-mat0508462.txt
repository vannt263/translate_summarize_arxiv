{
  "article_text": [
    "monte carlo methods have become a standard numerical tool in many branches of science , offering exact results in a statistical sense  @xcite . in physics",
    ", some monte carlo algorithms still resemble the original description by metropolis  @xcite in the fifties .",
    "for instance , ising and other classical lattice models were for a very long time simulated using random spin flips .",
    "such algorithms suffer from a critical slowing down in the neighborhood of the second order phase transition .",
    "however , some twenty years ago swendsen and wang found a solution using cluster updates  @xcite , completely overcoming the critical slowing down for the classical ising model .",
    "monte carlo methods have also been applied to quantum many - body systems , where one tries to sample either the wavefunction or the the partition function  @xcite .",
    "the quantum analog of cluster updates , namely the loop algorithm  @xcite , triggered the development of the worm algorithm  @xcite and the operator loop algorithm  @xcite ( and later the directed loop algorithm  @xcite ) in the stochastic series expansion representation .",
    "these algorithms share the properties that they sample the one - body green function , that they are formulated in continuous time  @xcite and are based on a world - line representation .",
    "thus both algorithms are similar  @xcite .",
    "these algorithms have successfully been applied to spin systems and to the bose - hubbard model  @xcite .",
    "recently , the worm algorithm has been formulated in the canonical ensemble , allowing to study more systems including superconducting grains and the nuclear pairing hamiltonian  @xcite .",
    "the efficiency of a numerical simulation method is primordial : efficient algorithms lead to more accurate results at the same computational cost and allow for the study of larger systems .",
    "the algorithms mentioned above are based on a markov process that results in a random walk in a specific configuration space .",
    "configurations are visited by the random walker proportionally to their respective weights . by the markov process",
    ", subsequent measurements are trivially correlated .",
    "the transition matrix specifies the probability of going from one configuration to another , and has to be defined in advance . in practice",
    ", one requires that transition matrices satisfy the principle of detailed balance  @xcite .",
    "this , however , still leaves some freedom in the choice of the transition matrices , which can be used to optimize the efficiency of the algorithm .",
    "a convenient updating scheme is the metropolis - hastings algorithm  @xcite : a limited number of configurations can be reached from the current one by defining a proposal distribution , and the transition to the new configuration is accepted or rejected according to detailed balance  @xcite .",
    "+ in previous work , we introduced the notion of locally optimal monte carlo  @xcite , when the degrees of freedom of every transition matrix are chosen in such a way as to mimic the globally optimal transition matrix , which , at least in principle , can be written down exactly .",
    "this approach is a best guess for obtaining optimal efficiency , and was found successful in practice for the directed loop algorithm in the stochastic series expansion representation  @xcite .",
    "here we investigate the consequences of the locally optimal monte carlo idea for the worm algorithm , and try to combine the advantages of the directed loop algorithm with the advantages of the worm algorithm .",
    "this results in a new formulation of the worm algorithm , hereafter called the locally optimal worm algorithm ( lowa )  @xcite .",
    "we show results for various spin models and the bose - hubbard model , and compare the efficiency of the lowa with that of the directed loop algorithm in the stochastic series expansion framework .",
    "we consider a two - body hamiltonian @xmath1 defined on a discrete lattice of system size @xmath2 .",
    "the hamiltonian can be written as @xmath3 , where the terms @xmath4 and @xmath5 are to be specified later on .",
    "we also assume a single particle basis @xmath6 of @xmath4 such that the action of any term in the hamiltonian on a basis state yields a single basis state .",
    "the models that we typically have in mind are the bose - hubbard model , @xmath7 and a general spin-@xmath0 model , @xmath8 in both expressions the notation @xmath9 refers to the sum over nearest - neighbor sites only . in the bose - hubbard model ,",
    "bosons are created on site @xmath10 by the operator @xmath11 and the number of bosons on site @xmath10 is counted by the number operator @xmath12 .",
    "the kinetic term describes hopping of the bosons with tunneling amplitude @xmath13 , while we consider two kinds of potential energy : on - site repulsion with strength @xmath14 and nearest - neighbor repulsion with strength @xmath15 . for the spin anti - ferromagnet ( spin exchange amplitude @xmath16 ) , we require that the lattice is bipartite .",
    "all matrix elements remain positive as long as the model does not exhibit any frustration which can for instance be induced by second nearest - neighbor hopping .",
    "as the calculations serve to demonstrate the ideas related to efficiency , we restrict the discussion to one dimension . + a worm algorithm  @xcite is a quantum monte carlo algorithm where the decomposition of the partition function , @xmath17 is sampled indirectly by performing local moves in the extended configuration space of open world - line configurations in the green function sector , @xmath18.\\label{eq : timeord}\\ ] ] the symbol @xmath19 denotes time ordering , and we have introduced the heisenberg operators @xmath20 which we call the worm operators .",
    "summing over all possible worms requires the extra sum evaluation of @xmath21 where we have explicitly written out the heisenberg worm operators , and where the @xmath22 mean that they should be inserted at the right time , as implied by the time ordering of eq.([eq : timeord ] ) .",
    "insertion of complete sets of basis states allows to replace the operators @xmath4 and @xmath5 by matrix elements",
    ". we will choose to work in the number occupation basis for the bose - hubbard model and in the spin @xmath23 basis for the spin models .",
    "a natural choice is to consider the one - body tunneling operators as perturbations @xmath5 , and collect the diagonal one - body and two - body operators in @xmath4 .",
    "this leads to the path - integral formulation .",
    "the stochastic series expansion representation is found back when all operators of the hamiltonian are put into @xmath5 and @xmath24 .",
    "the integration over time is then immediate . in the path - integral formulation",
    ", the extended partition function can be written as @xmath25 where the terms @xmath26 can be interpreted as weights when positive .",
    "the weights depend on the order @xmath27 and the integration times @xmath28 of the perturbative expansion of the partition function @xmath29 in @xmath5 and also on the position and the time of the worm operators , and all possible inserted basis sets @xmath30 .",
    "@xmath31 the monte carlo algorithm has to sample over all expansion orders @xmath27 , all interaction times @xmath32 , all possible worm times and positions , and all basis sets @xmath33 . in a worm algorithm",
    "this is achieved by moving one of the worm operators through the configuration space .",
    "such updates shift , annihilate and create interactions and sample indirectly over all possible basis states .",
    "it is convenient to represent the weights in a graphical representation using world lines .",
    "an example is shown in fig .",
    "[ fig : conf_fig ] .    whenever the worm operators reach each other , the discontinuities in the graphical representation cancel and the resulting configuration belongs to the partition function @xmath29 , apart from the worm matrix element @xmath34 .",
    "at this point we are free to assign any value to this matrix element . the standard choice , which we follow , is to take it constant for all states @xmath35 ( see eq.([eq : worm_weight_diag ] ) ) .",
    "this is graphically represented by the absence of circles ( which denoted the discontinuities in fig .",
    "[ fig : conf_fig ] ) in a world - line picture .",
    "graphical representation of a typical configuration in the green function sector .",
    "time goes from left to right in the figure , there are five sites .",
    "world lines are denoted by single lines ( site is once occupied ) , double lines ( site has occupancy two ) or dashed lines ( site is not occupied ) .",
    "interactions ( hopping of a particle ) are denoted by vertical lines .",
    "the two circles mark a discontinuity in the world lines and correspond to the worm operators .",
    "one of them creates an extra particle , the other one annihilates it . as a consequence of the @xmath36 symmetry ,",
    "total particle number is conserved at every interaction.,width=302 ]    in the literature there have been two different implementations of the worm idea .",
    "first , there was the worm algorithm by prokofev _",
    "et al . _",
    "@xcite , which was formulated in the path - integral representation .",
    "later the operator loop  @xcite and directed loop algorithm  @xcite in the stochastic series expansion representation were formulated .",
    "compared to the original formulation of the worm algorithm by prokofev _",
    "et al . _",
    "@xcite , the efficiency of the directed loop algorithm in the stochastic series expansion representation was found superior for spin systems and even for a homogeneous bose - hubbard model in both phases ( except for the extreme soft - core case )  @xcite .",
    "this is an expected result for spin systems where the diagonal energies are of the same order as the spin exchange amplitudes , but for the bose - hubbard model this result feels unsatisfactory . for a trapped bose - hubbard model however ,",
    "the worm algorithm was found superior  @xcite .    in the present paper",
    "we think of a new formulation of the worm idea , trying to combine to advantages of the directed loop algorithm with those of the worm algorithm .",
    "more specifically , we want an algorithm where the worm inserts and annihilates the interactions ( as in the worm algorithm ) , but we also want to use the directed worms as in the directed loop algorithm .",
    "the modification of the diagonal factors and the hopping factors contributing to the weight , eq.([eq : weight ] ) , should be done in a locally optimal way  @xcite .",
    "the easiest way to ensure that the markov chain converges to the correct invariant probability distribution is by assuring detailed balance@xcite , @xmath37 the current configuration is denoted by @xmath38 , the new configuration by @xmath39 .",
    "@xmath40 is the acceptance factor to be used in the metropolis algorithm , where the transition rule for going from @xmath38 to @xmath39 is given by @xmath41 , while the transition rule for the reverse update is given by @xmath42 , such that @xmath43 .",
    "we will now show that detailed balance is fulfilled for every possible update occurring in the algorithm .",
    "the simplest possible update is to move the mobile worm to another ( later / earlier ) time .",
    "we assume that the mobile worm is on site @xmath10 , and corresponds to an operator @xmath44 .",
    "the configurations before and after the update are shown in fig .",
    "[ fig : move ] .     graphical illustration of the move update .",
    "the worm , originally at time @xmath45 tries to jump to a later time @xmath46 .",
    "the state to the left of the worm is @xmath35 , with energy @xmath47 .",
    "the state to the right of the worm is @xmath48 , with energy @xmath49.,width=302 ]    the relevant factors contributing to the weights before ( @xmath50 ) and after ( @xmath51 ) the update are @xmath52 the notation @xmath53 means the complete state over all sites as in eq.([eq : weight ] ) , but the subscript @xmath10 means the particular site @xmath10 .",
    "the acceptance factor reads @xmath54 with @xmath55 .",
    "the exponentials can be canceled by choosing the transition probability densities as @xmath56 the normalization factors @xmath47 and @xmath49 enter into @xmath40 .",
    "these factors will be taken into account explicitly together with the interaction matrix elements at the moment that interactions can be inserted / annihilated , see section  [ sec : insertandjump ] .",
    "let @xmath57 be an uniform random deviate , @xmath58 .",
    "then , @xmath59 follows an exponential distribution and we can compute the time shift window @xmath60 as @xmath61 , with @xmath62 .",
    "we come back to this issue in section  [ sec : refinements ] .",
    "the recipe for the move update is thus    1 .",
    "draw a random deviate @xmath58 .",
    "2 .   when moving to the right ( left ) , compute the time shift window @xmath63 , where @xmath64 is the diagonal energy to the left ( right ) of the worm .",
    "3 .   if no interaction is encountered , update the current worm time from time @xmath13 to time @xmath65 .",
    "this amounts to a random walk based on poisson steps .",
    "the exponential factors contributing to the weight , eq.([eq : weight ] ) , might fluctuate heavily .",
    "the strong point of the poisson moves is that these exponential factors are canceled exactly .",
    "so far we assumed that the worm did not encounter any interaction during its propagation .",
    "what happens if a worm does reach an interaction ? at that point a decision must be taken : can the worm pass the interaction or not ? or shall we delete the interaction ? in that case we must also define updates to insert interactions that are in balance with the removal of interactions . in this section , we will first discuss two cases where the worm can pass the interaction , leaving it unchanged .",
    "second , we discuss the insertion and removal of interactions which , as we will see , also incorporates the modification of interactions .",
    "when the worm @xmath66 encounters an interaction @xmath67 whose sites are different from the site on which the worm head resides ( @xmath68 ) , the worm can pass the interaction with probability one .",
    "this is a consequence of the commutator of the worm operator and the interaction being zero , @xmath69 = 0 $ ]  @xcite .",
    "second , when a worm operator @xmath66 encounters an interaction @xmath70 , it can pass the interaction with probability one .",
    "this is also the result of the commutator being zero , @xmath71 = 0 $ ]  @xcite .",
    "graphical illustration of the insertion of an interaction by the worm .",
    "the worm , originally at the time @xmath72 before the time @xmath45 , jumps to the time @xmath45 and inserts an interaction there from site @xmath10 to site @xmath73 . afterwards",
    "the worm jumps to a later time @xmath74 , where we assume the worm always has to halt .",
    "later we will relax this condition . between times",
    "@xmath45 and @xmath74 a new state @xmath75 is created .",
    "note that this update is only possible if the occupation on site @xmath73 is larger than zero.,width=302 ]    suppose we move to the right and want to insert an interaction .",
    "the update consists of a move from imaginary time @xmath72 to the time @xmath45 , inserting an interaction and then continue the move to the imaginary time @xmath74 , as shown in fig .",
    "[ fig : interaction ] .",
    "let s suppose that the worm pair was created at @xmath72 , and that we want to evaluate estimators at time @xmath74 , meaning that the worm has to halt at time @xmath74 .",
    "we will later discuss generalizations .",
    "the relevant contributions to the weights of the configurations before and after the update are @xmath76 the transition to move to the new configuration @xmath39 is given by the probability density @xmath77 with @xmath78 and @xmath79 .",
    "the second exponential does not have an @xmath64 prefactor with it , since all time shifts larger than @xmath80 lead to the same final configuration @xmath39 .",
    "similarly , for the reverse update @xmath81 p_{\\rm rem } , t_m(y \\to x ) & = & \\int_{\\delta t}^{\\infty } e_{i_{k+1 } } e ^{-\\tau e_{i_{k+1}}}d \\tau   \\times \\nonumber \\\\   { } & { } & \\int_{\\delta t^{\\prime}}^{\\infty }   e^{-\\tau e_{i_{k+1 } } } e_{i_{k+1 } } d\\tau \\nonumber \\\\ { } & = & e^{-\\delta t   e_{i_{k+1 } } } e^{-\\delta t^{\\prime } e_{i_{k+1}}}\\nonumber \\\\ { } & = & e^{-(t_{k^{\\prime } } - t_w ) e_{i_{k+1}}}.\\end{aligned}\\ ] ] once again , all the exponential factors cancel in the acceptance factor @xmath40 .",
    "there remains a factor @xmath82 ( with @xmath5 the interaction ) , which is taken into account in the equations of detailed balance for the actual insertion of a new interaction .",
    "if the worm was not forced to halt at the time @xmath74 , the update would continue with the insertion of another interaction at @xmath74 ( which would take the extra @xmath83 ( i.e. , the normalization factor of the second exponential in the right hand side of eq.([eq : tmxtoytransprob1 ] ) ) into account ) .",
    "when inserting a new interaction , we can either make the current site @xmath10 interact with site @xmath84 or site @xmath73 in one dimension . in higher dimensions",
    "@xmath85 , interactions can be inserted to all @xmath86 neighboring sites .",
    "we have to define the ( conditional ) probability distribution function that samples the three configurations of fig.[fig : diag_gworms ] .",
    "when we are in configuration @xmath87 , we have to define @xmath88 and @xmath89 , both corresponding to the insertion of a new interaction .",
    "similarly , when we are in configuration @xmath90 we have to define @xmath91 and @xmath92 , corresponding to the removal and the modification ( relinking ) of an interaction , respectively .",
    "updating between the configurations a , b and c should be done proportional to the following factors contributing to the weights ,     when the worm moves to the right and tries to insert an interaction in configuration ( a ) , the two possible new configurations are configurations ( b ) and ( c ) .",
    "the third possibility is bouncing back and changing direction in configuration ( a ) .",
    "the transition matrix is thus a @xmath93 matrix in one dimension , or a @xmath94 matrix in @xmath85 dimensions.,width=302 ]    @xmath95    the energy term in eq.([eq : weight_with_e ] ) will be explained in section  [ sec : dirloopinvdistr ] . in fig .",
    "[ fig : diag_gworms ] , the worm is on site @xmath10 in configuration ( a ) , on site @xmath73 in configuration ( b ) and on site @xmath84 in configuration ( c )",
    ". we will discuss three possibilities to sample configurations ( a ) , ( b ) and ( c ) .    * the metropolis - like way .",
    "assume that we are in configuration ( a ) .",
    "we choose with equal probability between ( b ) and ( c ) .",
    "say ( b ) was chosen .",
    "the transition to ( b ) is then accepted with probability @xmath96 $ ] .",
    "if the update is not accepted , we stay in configuration ( a ) .",
    "this approach has the advantage that only the matrix elements for configuration ( b ) and ( a ) have to be calculated or known , the ones for ( c ) are not needed .",
    "this approach is thus recommendable for high dimensions , and for long - range interactions .",
    "the ( normalized ) @xmath93 transition probability matrix reads @xmath97,\\ ] ] with @xmath98 $ ] .",
    "the diagonal element corresponding to the lowest weight is thus zero . * the heat - bath way .",
    "we choose between ( a ) , ( b ) and ( c ) according to their relative weights , @xmath99 , irrespective of the current configuration .",
    "the weights of all configurations are needed in order to evaluate their sum .",
    "the transition probability matrix is @xmath100,\\ ] ] * the locally optimal way .",
    "heat - bath updates can have relatively large diagonal elements , which are associated with large rejection ratios or large bounce probabilities .",
    "the principle of locally optimal monte carlo updating suggests an optimal transition probability matrix , @xmath101,\\ ] ] where the normalized weights @xmath102 are now ordered in ascending order , @xmath103 .",
    "the ordering of the weights makes sense only if they can be tabulated before the start of the actual simulation .",
    "the locally optimal matrix is the stochastic matrix with the lowest possible second largest eigenvalue , which is negative .",
    "the non - zero diagonal elements correspond to bounces , meaning that the worm head changes its direction and undoes its changes until it reaches another point where an interaction can be changed , removed or inserted .",
    "the only remaining update to discuss is the insertion / removal of a worm pair , which is the connection between the partition function sector @xmath29 and the green function sector , @xmath104 .",
    "the update is depicted in fig .",
    "[ fig : insertion ] .     graphical illustration of the insertion of a worm pair .",
    "an arbitrary site @xmath10 and an an arbitrary time @xmath45 is chosen .",
    "we have shown here the case that the occupation between the worm ends is increased by one .",
    ", width=302 ]    in case of fig .",
    "[ fig : insertion ] , the weights before and after the update are @xmath105 where @xmath106 is a constant specifying the relative weights of the partition function and the green function sectors , and the number @xmath12 is the occupation on site @xmath10 before a worm pair is inserted .",
    "this is the usual convention in a worm algorithm .",
    "however , we are free to choose the weight of the worm matrix elements , and in sse they are usually taken as unity .",
    "one of the worm ends will be moved through configuration space and is called the mobile worm , while the other end remains stationary .",
    "we choose to always annihilate a worm pair when the mobile worm bites into the stationary worm , @xmath107 a worm pair is inserted by choosing a random time and a random site .",
    "thus ( in case of fig .",
    "[ fig : insertion ] ) , @xmath108 we have to define the probabilities @xmath109 and @xmath110 that the occupation between the two worm operators is higher ( an ) or lower ( cr ) than outside this infinitesimal interval .",
    "we choose with equal probability among those , except when the occupation is zero or equal to the maximum occupation allowed . in case of zero occupancy ,",
    "we choose with probability @xmath111 not to insert a worm pair , and analogous to the case of maximum occupation number .",
    "thus , @xmath112 in case of hard - core bosons or spin@xmath113 systems , one can modify this relation so as to always insert a worm pair .",
    "when a worm pair is inserted , there are two possibilities : of we move forward in time creating a particle , or we move backward in time creating a particle .",
    "physically , moving forward in time and annihilating a particle is the same as the latter , while moving backward in time and annihilating a particle is the same as the former . yet , the decorrelation benefits if both a direction ( forward / backward ) and an operation ( creation / annihilation ) are chosen . at this point",
    ", we explicitly choose a direction , and we take @xmath114 this equation is correct in the directed loop algorithm since there are on average as many moves to the left as there are to the right . finally , we have to fix the constant @xmath106 .",
    "apart from the cases @xmath115 and @xmath116 , which we have already discussed , the update is always accepted when we choose ( in case of fig .",
    "[ fig : insertion ] ) @xmath117 with this choice , the green function @xmath118 is automatically correctly normalized .",
    "the procedure to measure will be discussed in sec .",
    "[ sec : dirloopinvdistr ] , while the value of the measurements is the same as the ones discussed in the generalized directed loop algorithm  @xcite and in the canonical worm algorithm  @xcite .",
    "the perturbative expansion of the partition function is a poisson process : the interactions ( events ) are distributed according to a poisson distribution , with the intervals between them following an exponential distribution .",
    "we sampled these intervals exactly using exponential deviates divided by an energy . according to eq.([eq : weight ] ) , these energies are the diagonal energies of the system . taking into account that the direction of propagation is fixed in the directed loop algorithm ,",
    "we only consider positive time shift windows @xmath60 .",
    "because the exponential distribution @xmath119 is only defined for positive @xmath120 , the energies have to be positive , which is not a priori guaranteed .",
    "let @xmath121 be the energy to the left ( right ) of the mobile worm .",
    "we can proceed in the following ways :    1 .",
    "we shift all energies with a large , positive constant , @xmath122 .",
    "this will result in small time shift windows .",
    "since these energies also enter in the equations of detailed balance for inserting / removing / relinking an interaction , they might lead to large bounce ratios .",
    "we try to make use of the fact that only energy differences are physically relevant .",
    "we have the algorithmic freedom to choose any pair of @xmath123 and @xmath124 such that @xmath125 and @xmath126 .",
    "a good choice is @xmath127 $ ] .",
    "this quantity can be zero , meaning that the jump in imaginary time is infinite , i.e. , that the next interaction is always reached .",
    "compared to the previous approach , we make thus larger jumps in imaginary time , and the energies that enter the detailed balance equations of inserting / removing / relinking an interaction are of the same order of magnitude as the hopping matrix elements .",
    "however , we found that this parameter choice resulted in some anomalously long ( non - closing ) loops and in problems with ergodicity when these long loops are discarded .",
    "we suggest to use the shifted energies @xmath128 + e_{\\rm off},\\label{eq : shiften}\\ ] ] where the energy offset @xmath129 overcomes the aforementioned problems with ergodicity .",
    "it makes sense to choose @xmath130 with @xmath131 a typical matrix element of the interaction .",
    "after the worm has passed an interaction at time @xmath45 , we have to calculate the new energy parameters @xmath132 and consider a new time shift .",
    "the latter can be accomplished by either drawing a new exponential deviate ( as in step 3 ) , or by adjusting the time shift window @xmath133 ( when moving to the right ) , using the property that the exponential distribution has no memory.      to prove detailed balance one has to consider the global updates .",
    "such a global update starts and ends with a jump in imaginary time ( thus only a forced halting at a chosen time can end a global update ) . in between , there can be any number of insertions , annihilations or relinks .",
    "for example , the following sequence satisfies detailed balance : insertion of a worm pair - jump - insertion of an interaction - jump - insertion of an interaction - jump - removal of a worm pair .",
    "we have already shown that the insertion and removal of a worm pair are balanced , so we just have to look at the sequence starting and ending with the jump . for every such sequence there exists also the exact opposite sequence .",
    "writing down the acceptance factor for the global move , @xmath134 one finds that all exponential factors in the weights are cancelled out by the probabilities for the poisson jumps . for each insertion there enters an interaction matrix element @xmath135 in de numerator due to the ratio @xmath136 , and a factor @xmath64 ( @xmath137 for moves to the right , @xmath138 for moves to the left ) in the denominator due to the normalization of the preceding poisson jump .",
    "both these factors are balanced through the locally optimal transition matrix of section  [ sec : insertandjump ] . as a result",
    "one finds that @xmath40 is exactly equal to one , hence all moves can be accepted , which greatly simplifies the computer code .",
    "the resulting algorithm samples the configurations that appear in the decomposition of eq.([eq : zdecomp ] ) .",
    "note that the above reasoning still holds if we assume that the worm continues to move in the same direction after each poisson move and only allow bounces at the moment when one decides whether or not to insert or remove interactions .",
    "this leads to a version of the worm algorithm that is similar to the directed loop algorithm for sse  @xcite .",
    "the intermediate steps of the algorithm correspond to configurations in the decomposition of the extended partition function @xmath104 of eq.([eq : ze ] ) . to understand this , consider a point in imaginary time at a distance @xmath139 of the time where the worm was inserted .",
    "now suppose we _ halt _",
    "( this is crucial for measuring the green function ) the worm head at the moment it passes the point @xmath139 , and suppose we choose with probability @xmath140 whether to continue the move in the same direction or to move in the opposite direction ( we will see furtheron that this latter condition is not necessary ) . following exactly the same reasoning as above",
    ", we see that this algorithm leads to detailed balance between configurations in the decompositions of @xmath29 and @xmath141 . now",
    "from here we can derive that this is true even if we continue the worm move in the same direction at the moment of passing the point @xmath139 . to see this it is instructive to consider both directions as two branches of a normalized transition kernel @xmath142 that depends on two variables , namely the time @xmath60 and the direction @xmath143 , and fulfills detailed balance : @xmath144 for @xmath145 and @xmath146 .",
    "we have that @xmath147 thanks to time reversal symmetry , the statement that a worm creates a particle and propagates forward in time is completely equivalent to the the statement that the worm annihilates a particle and propagates backward in time .",
    "therefore both directions will occur with equal probability .",
    "suppose that at a given moment a configuration @xmath38 is the actual one with a probability proportional to its weight @xmath50 .",
    "then the probability for a configuration @xmath39 to occur at the next step is proportional to @xmath148 this equation holds for any algorithm where the direction is fixed , and also forms the basis of the _ bounce algorithm _ of ref.@xcite .",
    "so , even when we do not change the direction of the worm at the moment that it passes the point @xmath139 , the probability to pass a point @xmath139 is still proportional to the weight of the corresponing configuration in the extended partition function @xmath104 .",
    "this is quite subtle : suppose we do a jump of the worm operator , without encountering an interaction .",
    "then it is not possible to immediately come back to the original configuration in the next step since the direction is preserved .",
    "this observation lies at the heart of the proof of convergence of the algorithm given by the authors of ref .",
    "they prove that detailed balance is satisfied between any two diagonal configurations , from which it follows that every local step is balanced ( in the sse representation ) . here",
    ", we see that detailed balance is fulfilled every time the worm is forced to halt at a chosen time , but we emphasize that precisely at the moment of inserting or annihilating or relinking an interaction ( without further jump of the worm ) detailed balance is not fulfilled .    because the probability distribution for two consecutive poisson steps in the same direction is identical to the probability distribution for a single poisson step",
    ", one finds that in this case the dynamics of the algorithm is completely equivalent to the dynamics without considering a special point @xmath139 .",
    "therefore one can state in general that the probability for the worm head to pass a point at a distance @xmath139 from the worm tail is given by the weight of the corresponing configuration in the extended partition function @xmath104 .",
    "this observation allows for an efficient and unbiased evaluation of the equal - time and unequal time green function @xmath149 : each time the worm head at site @xmath150 passes the worm tail on a different site @xmath10 , one has a measurement for the equal time green function @xmath151 , i.e. , the one - body density matrix .",
    "counting the times that the worm passes at a distance @xmath139 , one obtains a measurement of the unequal time green function @xmath152 .",
    "as we have already mentioned , we end up in the stochastic series expansion ( sse ) representation if we treat all terms in the hamiltonian as interactions . in the present formulation",
    "this means that the diagonal energies are always zero , leading to infinite time shift windows all the time .",
    "the mobile worm will jump from interaction to interaction , either deleting or relinking it or bouncing back .",
    "there is a serious problem with this algorithm , because it will never insert a new interaction .",
    "therefore , in the sse representation one needs two updates : one update is to scan over all ( discrete ) times in order to insert and remove interactions , the other one consists of modifying interactions with a fixed graph .",
    "the proof of convergence with directed loops in the second update proceeds in the same way as for the lowa algorithm .",
    "we recapitulate and write down the full algorithm for the soft - core bose - hubbard model .    1 .",
    "pick an arbitrary site and an arbitrary time and call it @xmath153 .",
    "find the occupation on all sites at that particular time @xmath154 .",
    "calculate the corresponding diagonal energy . a direction ( left or right )",
    "is chosen with equal probability .",
    "assume propagation to the right was chosen .",
    "2 .   at @xmath155 a worm - pair ( tail - head ) is inserted .",
    "if the occupation is higher than zero , the occupation between the worm ends can either be increased or decreased .",
    "if the occupation at @xmath155 is zero , then with probability @xmath111 a worm is inserted with increased occupation between the worm ends . with probability",
    "@xmath111 no worm is inserted .",
    "when moving to the right ( left ) , we denote by @xmath156 the shifted energy to the left ( right ) of the worm head , eq.([eq : shiften ] ) .",
    "draw an exponential deviate , @xmath157 with @xmath57 an uniform random number , @xmath158 .",
    "evaluate the imaginary time shift window @xmath159 and the new worm time @xmath160 .",
    "if the worm head encounters the worm tail ( at the same site ) during its propagation , the update ends with probability one and we arrive at a new diagonal configuration . 5 .",
    "if the new worm time is larger than the time to the next interaction , the new worm time only equals the time of the next interaction .",
    "the worm can either bounce back , pass , annihilate or relink the interaction , according to the locally optimal transition matrix .",
    "6 .   if no interaction is encountered in the imaginary time shift window , the worm shifts to its new time where an interaction is inserted or a bounce occurs , according to the locally optimal transition matrix . 7 .",
    "go back to step 3 .",
    "every local single step respects the invariant distribution in the green function sector .",
    "when the mobile worm reaches the stationary worm , one can measure diagonal observables such as the energy , winding number , density , etc .",
    "they can be updated in the same way as in the directed loop  @xcite and worm  @xcite algorithms .",
    "the algorithm described above is valid when the diagonal energies involve a single site , but also when the diagonal energies contain nearest - neighbor repulsion repulsion terms , and even longer range interactions .",
    "the worm algorithm in path - integral representation is in essence the same algorithm as the lowa algorithm .",
    "the only difference is the way ergodicity and convergence to the correct invariant distribution are implemented with respect to the direction of worm propagation . in the worm algorithm ,",
    "one chooses at every step between forward and backward propagation in time with equal probability , while in the lowa the direction is maintained until an interaction forces the worm to alter its direction of propagation . in the context of the canonical worm algorithm ,",
    "even other choices have been implemented  @xcite .",
    "all these algorithms are the same in spirit , they are slightly different implementations of the same idea of performing local updates in the green function sector . the directed loop algorithm has previously been formulated in the path integral formulation  @xcite .",
    "although there are some resemblances , the lowa is different , more general , and the principles that lie at heart of the derivation of the algorithm are different .",
    "although we have argued why we believe the proposed lowa is efficient , we can only verify by doing numerics in order to get a definite answer on its efficiency .",
    "the results are compared with data obtained by the directed loop algorithm in the stochastic series expansion representation of refs .",
    "@xcite , which will be abbreviated as dlsse .",
    "we used the method of ref .",
    "@xcite for the actual computation of the dlsse .",
    "the error and autocorrelation estimation was done using a binning analysis .",
    "a direct comparison is complicated because present implementations use different data structures for both algorithms . in the dlsse ,",
    "a doubly linked list is constructed before the loop update .",
    "since the graph is fixed , the number of elements in this list can not change .",
    "this allows to allocate memory statically . in the worm algorithm on the other hand ,",
    "the number of interactions can change at any time . in our fortran code",
    "this was implemented using two arrays of a predetermined fixed length , corresponding to the interactions before and after the current mobile worm time .",
    "we have calculated the standard deviations on the kinetic energy and on the squared density for a one - dimensional bose - hubbard model of size @xmath161 sites at an inverse temperature of @xmath162 and with a fixed chemical potential @xmath163 in the absence of nearest - neighbor repulsion , @xmath164 .",
    "we work in units @xmath165 .",
    "simulations consisted of 40 bins that each ran 300 seconds on a pentium iii processor .",
    "we imposed a particle number cutoff of ten particles per site for @xmath166 and @xmath167 , while a cutoff of five particles per site was taken for the other values of @xmath14 , ranging from @xmath168 to @xmath169 .",
    "imposing a cut - off is a necessity for the dlsse , but not for the lowa .",
    "the number of loops per update was optimized along the guidelines of ref .",
    "the mott phase is reached for @xmath170 .",
    "we have calculated the standard deviation on the kinetic energy and on the density squared ( i ) for the dlsse .",
    "( ii ) for the lowa where the diagonal energy parameters were chosen according to approach ( a ) ( iii ) for the lowa where the diagonal energy parameters were chosen according to approach ( c ) . in ( ii ) and ( iii ) the @xmath93 transition matrices were taken as the locally optimal ones as in eq .",
    "(  [ eq : loopt ] ) .",
    "we shall discuss this in section  [ sec : hb ] . in figs .",
    "[ fig : gworm_ekin ] and  [ fig : gworm_dens ] the results for algorithms ( i ) and ( iii ) are shown .    among the different lowa optimization parameters ,",
    "approach ( iii ) is almost always the most efficient one .",
    "the dlsse seems to be the preferred model for very low values of @xmath14",
    ". however , approach ( ii ) performs lots better than approach ( iii ) in this regime , and its efficiency is comparable to that of the dlsse . when the diagonal matrix elements are much larger than the off - diagonal ones , as in the mott phase @xmath171 , the present algorithm is superior .",
    "admittedly , we recognize that it is not unambiguous how the directed loop simulations should be performed in the mott phase because of the very short loop sizes .",
    "standard deviation ( statistical error ) on the kinetic energy for the directed loop algorithm in the stochastic series expansion framework ( dlsse ) , and the locally optimal worm ( lowa ) using an energy offset added to the energy difference for the diagonal energy parameters and using locally optimal updates ( eq .",
    "(  [ eq : loopt ] ) ) .",
    "simulations consisted of 40 bins that each ran 300 seconds on a pentium iii processor for a one - dimensional bose - hubbard model of @xmath172 sites at an inverse temperature of @xmath162 and with a fixed chemical potential @xmath173 .",
    "the accuracy of the data points is about ten percent.,width=340 ]     idem as in fig .",
    "[ fig : gworm_ekin ] , but now for the standard deviation on the average square density , @xmath174.,width=340 ]      for spin systems , the magnitude of the diagonal and the off - diagonnal matrix elements is of the same order . one can thus expect that the dlsse is more efficient for spin models than for soft - core bosonic models , since diagonal and off - diagonal operators are treated on equal footing in the stochastic series expansion representation .",
    "it is thus interesting to compare the efficiency of the locally optimal worm with the efficiency of the dlsse for a spin-@xmath140 chain .",
    "the lowa was most efficient when the energy offset parameter was set to @xmath175 . in fig .",
    "[ fig : fig_spin12_mag ] the standard deviations of the total energy and of the kinetic energy are shown , which are obtained by applying the lowa and the dlsse to a spin-@xmath140 chain subject to a magnetic field @xmath1 .",
    "we find that the locally optimal worm is superior to the dlsse in our implementations , but it is more meaningful to say that both algorithms behave similarly as the magnetic field is increased , while the algorithms are most efficienct near @xmath176 .",
    "analogous conclusions were found for a spin-@xmath177 chain . for a spin-@xmath178 chain however , the dlsse was found to be superior .",
    "standard deviations on the total energy ( @xmath179 ) and on the kinetic energy ( @xmath180 ) obtained after a simulation of a spin-@xmath140 chain with @xmath181 consisting of @xmath182 sites and with inverse temperature @xmath183 .",
    "simulations have been performed with the directed loop algorithm in the stochastic series expansion framework ( dlsse ) and with the locally optimal worm algorithm ( lowa ) .",
    "computations consisted of @xmath184 bins that each ran for @xmath185 seconds on a pentium - iii processor . , width=340 ]      a comparison between the heat - bath and locally optimal approach is made in fig .",
    "[ fig : hb_locopt ] for a one - dimensional bose - hubbard model with parameters @xmath186 and varying tunneling amplitude @xmath13 .",
    "the ratio of the standard deviation obtained by the locally optimal approach to the standard deviation obtained by the heat - bath approach is shown for the condensate fraction and the total energy .",
    "we see that the locally optimal approach is on average ten to fifteen percent better , but the effect is less pronounced than in the dlsse  @xcite .",
    "even smaller differences were found for some other parameter regimes .",
    "simulation of a one - dimensional bose - hubbard model with parameters @xmath187 and varying tunneling amplitude @xmath13 .",
    "plotted is the ratio @xmath188 for the condensate fraction @xmath189 and for the total energy @xmath190 , being the ratio of the standard deviation @xmath191 obtained by the locally optimal approach to the standard deviation @xmath192 obtained by the heat - bath approach ( @xmath193 ) .",
    "simulations consisted of 40 bins of 300 seconds on a pentium iii processor per data point.,width=340 ]      both the worm and the dlsse are @xmath194 methods . in the absence of correlations between subsequent measurements , the needed computation time for a desired accuracy scales linearly with system size and inverse temperature .",
    "the scaling efficiency is further determined by the dynamical exponent @xmath195 , which describes how the integrated autocorrelation time scales with system size and inverse temperature .",
    "the worm and directed loop algorithm have very low dynamical exponents ; @xmath195 is even zero in some high - dimensional cases .",
    "this beneficient scaling is the cornerstone for the study of very large system sizes at very low temperatures .",
    "since the present algorithm is based on the same principles as the directed loop algorithm and the worm algorithm , one expects that the dynamical exponent is similar ( at least of the same order ) but the prefactor of the scaling behavior might be different .",
    "we studied the scaling behavior for the critical system of an isotropic spin-@xmath140 heisenberg chain ( @xmath196 ) in zero magnetic field ( @xmath176 ) , for which the worm updates are fast .",
    "we investigated the effects of increasing system size @xmath2 at fixed inverse temperature @xmath197 on the one hand and of increasing the inverse temperature @xmath197 at fixed system size @xmath2 on the other hand .",
    "this allows us to see whether the algorithm scales symmetrically with system size and temperature or not .",
    "all calculations ran for a fixed time of 40 bins of 300 seconds each on a pentium iii processor .",
    "we used optimal parameters for the simulation : we use the locally optimal transition matrix of eq.([eq : loopt ] ) and we set @xmath175 .",
    "we focused on the standard deviation and the integrated autocorrelation time of the kinetic energy , since the modes of this observable couple to the slowest mode of the simulation while the measurements can be calculated at low computational cost .",
    "standard deviation on the average kinetic energy per site as a function of the system size @xmath2 multiplied by the inverse temperature @xmath197 for an isotropic spin-@xmath140 chain in zero magnetic field .",
    "plots are shown when the system size and the inverse temperature are increased simultaneously ( @xmath198 ) , when the system size is held constant at @xmath199 and only the temperature @xmath197 is varied ( @xmath200 ) , and when the temperature is held constant at @xmath183 and the system size @xmath2 varies ( @xmath183).,width=340 ]    in fig .",
    "[ fig : scale_stdev ] we study the standard deviation ( statistical error ) on the average kinetic energy per site .",
    "when the system size and the inverse temperature are sufficiently large , we see a gradual increase in the statistical error with an exponent of @xmath201 , irrespective of whether @xmath2 , @xmath197 or both ( note that the quantum imaginary time direction scales as one classical space direction ) are increased .",
    "since , for larger lattices , the worm will visit each site less often , this result is intuitively understandable . from the data in fig .",
    "[ fig : scale_stdev ] we can already see that the dynamic exponent @xmath195 obeys @xmath202 . strangely , when @xmath197 is taken too low ( see the data points at @xmath203 in fig .  [",
    "fig : scale_stdev ] ) , the present algorithm loses its efficiency . below",
    "we will relate this to higher integrated autocorrelation times .",
    "idem as in fig .",
    "[ fig : scale_stdev ] , but now the loop size ( @xmath204 ) is shown .",
    "the loop size @xmath204 is defined as the total number of interactions passed , inserted , annihilated and modified by the mobile worm in a single update.,width=340 ]    a similar picture results when we look at the loop size in fig .",
    "[ fig : scale_loopsize ] .",
    "we define the loop size @xmath204 as the total number of interactions passed , inserted , annihilated and modified by the mobile worm in a single update .",
    "we see that the loop size @xmath204 scales as @xmath205 .",
    "the loop size increases thus linearly with the increase in area in space - time .",
    "however , if we are very close to the ground state at a fixed system size , then increasing @xmath197 does not result in longer loops and the algorithm loses its scaling properties .",
    "idem as in fig .",
    "[ fig : scale_stdev ] , but now the integrated autocorrelation time of the kinetic energy , @xmath206 is shown.,width=340 ]    the integrated autocorrelation time @xmath206 of the kinetic energy in fig .",
    "[ fig : scale_tau ] shows a similar pattern : for large enough space - time areas , the integrated autocorrelation time scales as @xmath207 , which was fitted to the curve @xmath208 in fig .",
    "[ fig : scale_tau ] .",
    "when the inverse temperature is too low , we unexpectedly find high autocorrelation times which explains the high standard deviations for the same data points in fig .",
    "[ fig : scale_stdev ] .",
    "this behavior could be due to the fact that the mobile worm is always forced to make relatively large jumps in the time direction .",
    "with the dlsse , the integrated autocorrelation time scales as @xmath209 .",
    "this result is in agreement with ref .",
    "the dynamic exponent of the dlsse is thus lower , yet in our calculations the standard deviations of the dlsse increased more rapidly with increasing system size .",
    "this is due to the increase in computational cost for a single update , which scales worse for the dlsse .",
    "the computational cost of a single update depends strongly on the way of implementation , and the scaling of the standard deviations with system size should be interpreted accordingly .",
    "in addition , when looking at the magnetization on every site , the worm algorithm performs much better than the dlsse for all system sizes .",
    "we conclude that efficiency largely depends on the implementation of the algorithm and on the observables of interest  @xcite .",
    "in conclusion , we have presented a new formulation of the worm algorithm .",
    "the present algorithm has been derived using the concept of locally optimal monte carlo  @xcite and incorporates ideas both from the worm algorithm  @xcite and the directed loop algorithm  @xcite in the stochastic series expansion representation  @xcite .",
    "we have compared the efficiency of the present algorithm with that of the directed loop algorithm for spin chains and for the bose - hubbard chain .",
    "especially when there are large diagonal matrix elements , the present worm algorithm is very successful . we have shown that choosing the locally optimal matrix for the transition matrices occurring in the stochastic subprocesses yields an efficient algorithm .",
    "we found that the loop size increases linearly with the increase in area in space - time , and that the dynamic exponent equals @xmath210 for an isotropic heisenberg chain without magnetic field .",
    "seen the efficiency of the method and its advantageous scaling properties , the algorithm is suitable for large scale calculations of spin systems and soft - core bosonic models .",
    "the authors wish to thank the research board of the universiteit gent and the fund for scientific research , flanders for financial support .",
    "the authors acknowledge d. ceperley , e. gull , n. v. prokofev , b. v. svistunov , m. troyer , s. wessel and f. f. assaad for valuable discussions .",
    "99 j. s. liu , _ monte carlo strategies in scientific computing _ ( springer verlag , new york , usa , 2001 ) .",
    "n. metropolis , a. w. rosenbluth , m. n. metropolis , a. h. teller and e. teller , j. chem . phys . * 21 * , 1087 ( 1953 ) .",
    "r. h. swendsen and j. s. wang , phys .",
    "lett . * 58 * , 86 ( 1987 ) .",
    "u. wolff , phys .",
    "* 62 * , 361 ( 1989 ) .",
    "d. ceperley , rev .",
    "* 71 * , s438 ( 1999 ) . h. g. evertz , g. lana and m. marcu , phys .",
    "lett . * 70 * , 875 ( 1993 ) .",
    "n. v. prokofev , b. v. svistunov , and i. s. tupitsyn , zh .",
    ". fiz . * 114 * , 570 [ sov .",
    "jetp * 87 * , 310 ] ( 1998 ) ; n. v. prokofev , b. v. svistunov , and i. s. tupitsyn , phys .",
    "a * 238 * , 253 ( 1998 ) .",
    "a. w. sandvik , phys .",
    "b * 59 * , 14157(r ) ( 1999 ) .",
    "o. f. syljusen and a. w. sandvik , phys .",
    "e * 66 * , 046701 ( 2002 ) .",
    "o. f. syljusen , phys .",
    "e * 67 * , 046701 ( 2003 ) .",
    "m. troyer , f. alet , s. trebst , and s. wessel , aip conf .",
    "* 690 * ( 2003 ) , see cond - mat/0306128 .",
    "n. kawashima and k. hararda , j. phys .",
    "jpn . * 73 * , 1379 ( 2004 ) . s. m. a. rombouts , k. van houcke , and l. pollet , phys .",
    "lett . * 96 * , 180603 ( 2006 ) .",
    "k. van houcke , s. m. a. rombouts , and l. pollet , phys .",
    "e * 73 * , 056703 ( 2006 ) .",
    "w. k. hastings , biometrika * 57 * , 97 ( 1970 ) .",
    "l. pollet , s. m. a. rombouts , k. van houcke and k. heyde , phys .",
    "e * 70 * , 056705 ( 2004 ) .",
    "l. pollet , _ phd thesis _ , ghent university , belgium , unpublished .",
    "see http://inwpent4.ugent.be/phdthesis.html ( 2005 ) .",
    "s. wessel , f. alet , s. trebst , d. leumann , m. troyer , and g. g. batrouni , j. phys .",
    "jpn . suppl . *",
    "74 * , 10 ( 2005 ) .",
    "f. alet , s. wessel and m. troyer , phys .",
    "e * 71 * , 036706 ( 2005 ) .",
    "a. dorneich and m. troyer , phys .",
    "e * 64 * , 066701 ( 2001 ) .",
    "p. h. peskun , biometrika * 60 * , 607 ( 1973 ) .",
    "a. frigessi , c. r. hwang and l. younes , ann . of appl .",
    "* 2 * , 610 ( 1992 ) . c. pierleoni and d. m.",
    "ceperely , chemphyschem vol .",
    "* 6 * , issue 9 , p.1872 - 1878 ( 2005 ) ."
  ],
  "abstract_text": [
    "<S> quantum monte carlo algorithms based on a world - line representation such as the worm algorithm and the directed loop algorithm are among the most powerful numerical techniques for the simulation of non - frustrated spin models and of bosonic models . both algorithms work in the grand - canonical ensemble and </S>",
    "<S> can have a winding number larger than zero . </S>",
    "<S> however , they retain a lot of intrinsic degrees of freedom which can be used to optimize the algorithm . </S>",
    "<S> we let us guide by the rigorous statements on the globally optimal form of markov chain monte carlo simulations in order to devise a locally optimal formulation of the worm algorithm while incorporating ideas from the directed loop algorithm . </S>",
    "<S> we provide numerical examples for the soft - core bose - hubbard model and various spin-@xmath0 models . </S>"
  ]
}