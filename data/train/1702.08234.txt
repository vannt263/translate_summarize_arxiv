{
  "article_text": [
    "* the rise of cloud apps : * + the popularity of consumer cloud storage providers ( csps ) over the previous decade has been on a roll .",
    "dropbox , google drive , and one drive have each amassed hundreds of millions of users . in order to further appeal to their users ,",
    "the csps have been transitioning from being pure _ service providers _ to becoming _",
    "app ecosystems_. hence , they now offer apis for developers to import and process users files stored in the cloud .",
    "consider , for example , a web app called https://pandadoc.com[pandadoc ] , which allows creating , editing , and signing documents online .",
    "when a user uses pandadoc from her laptop browser , she can import files stored in her google drive instead of her hard drive .",
    "such a pattern is increasingly more prevalent with the growing number of 3rd party cloud apps ( or 3pc apps ) that are tightly integrated with cloud storage services .",
    "dropbox alone claims that hundreds of thousands of apps have been integrated with its platform . even in the enterprise setting , 3rd party cloud apps are on the rise .",
    "this is first because companies are officially adopting the likes of _ dropbox business _ , _ onedrive for business _ , and _ google drive for work_. second , it is due to employees utilizing their personal cloud accounts to share company s files ( a.k.a shadow it ) .",
    "various reports from cloud application security providers state that organizations use from 10 to 20 times more cloud apps than their it department thinks  @xcite .    * risks in 3rd party cloud apps : * + however , in our previous work",
    ", we have shown that 76% of the 3rd party google drive apps featured on google chrome store request full access to users google drive data  @xcite . around 64% of these apps",
    "are _ over - privileged _ : they require more permissions than are needed for them to function .",
    "accordingly , users are now faced with a new kind of privacy adversary : the 3rd party app vendors . with every app authorization decision that users make",
    ", they are trusting a new vendor with their data and increasing the potential attack surface .",
    "elastica , the cloud application security provider , estimates that the average financial impact on a company as a result of a cloud - storage data breach is $ 13.85 m , including remediation costs  @xcite . in 2015 , the data breach at anthem , a us insurance company , has reportedly cost more than $ 100 m , with 80 m unencrypted health records leaked .",
    "this was a result of an exfiltration exploit leveraging a popular public cloud storage application  @xcite . even on the personal level",
    ", the risk extends from breaches exposing financial information and health records to unnoticeable , continuous profiling based on stored files .",
    "* exposure through collaboration : * + an additional intricacy is that when users grant access to a 3rd party cloud app , they are not only sharing their personal data but also others data .",
    "this is because cloud storage providers are inherently collaborative platforms where users share and cooperate on common files .",
    "hence , protecting these files is not solely in the hands of the user .",
    "skyhigh networks , another provider of cloud security software , reports that 37.2% of documents ( across 23 million users ) are shared with at least one other user . in organizations ,",
    "documents are shared , on average , with accounts from 849 external domains  @xcite . moreover , around 23% of cloud documents were found by elastica to be `` broadly shared '' , which means that they are shared ( a ) among all employees , ( b ) with external partners and clients , or ( c ) with the public  @xcite .",
    "interestingly , 12% of those documents contained compliance - related or confidential data .",
    "this further highlights what has been termed as the _ interdependent  privacy  problem _",
    "@xcite , where the decisions of friends can affect the user s privacy and vice - versa .",
    "this concept was initially proposed in the context of third - party social networking apps , such as facebook . however , while 1.92% of facebook apps request friends personal information , this is much more pronounced in 3rd party cloud apps , where all apps accessing one s files get access to the part which is shared too . moreover , unlike facebook apps , due to the collaborative nature of cloud apps , the csps do not provide an option for users to control whether their collaborators apps can get access to data they own .",
    "* research questions : * + so far , the main approach to reducing the risk of 3pc apps has been focused on discovering over - privileged apps and deterring users from installing them  @xcite . even then",
    ", a lot of users would still install such apps as they prioritize short - term utility over long - term risk aversion or due to the absence of alternatives .",
    "furthermore , that approach relies on manually inspecting each app by experts and on applying a plethora of machine learning algorithms to visualize the various risks for users .",
    "these issues could present a hurdle towards a wide - scale deployment by csps . in this work",
    ", we address the wider problem of minimizing the risk of all 3pc apps , regardless of whether they are over - privileged or least - privileged .",
    "we are further driven by the rationale that users will inevitably continue to install apps to achieve various services .",
    "hence , instead of stopping them , we aim to lead them to select apps from vendors in a way that minimizes their privacy risk .",
    "we achieve this by leading users to take what we term as _ history - based decisions_. such decisions account for the vendors who previously obtained access to the user s data , whether directly ( with her consent ) or via her collaborators .",
    "our strategy consists of introducing privacy indicators to the current permissions interfaces that help users minimize the number of vendors with access to their data .",
    "our `` usable privacy '' approach is guided via a data - driven study and is evaluated via a data - driven simulation .",
    "in essence , we tackle the following research questions :    * from a practical perspective , are the collaborators decisions significant enough to be accounted for in users app adoption decisions ? * do users already account for entities with access to their data ?",
    "if not , to what extent can the usage of privacy indicators lead to users taking history - based decisions ? * how significant is the effect of adopting these privacy indicators in the case of large networks of users and teams ?",
    "* contributions : * towards addressing these questions , we make the following contributions :    * in section  [ sec : dataset ] , we analyze a real - world dataset of google drive users , and we show that the median privacy loss that collaborators cause by installing apps can be much higher than that inflicted by the user s own app adoption decisions ( 39% higher with 5% of shared files and 523% higher with 60% of shared files ) . to our knowledge , this is the first usage of a real - world dataset to give a concrete evaluation of interdependent privacy in any ecosystem . * driven by the significant impact of collaborators , we design new privacy indicators for helping users mitigate the privacy risk via history - based decisions ( cf .",
    "section  [ sec : study ] ) .",
    "we assess these indicators via a web experiment with 141 users .",
    "we show that they significantly increase the likelihood that users choose the option with minimal privacy loss , even if not all of these users are motivated by privacy per se . to the best of our knowledge ,",
    "this is also the first work to investigate a usable privacy approach to mitigating the problem of interdependent privacy .",
    "the few studies on this problem have mainly approached it from a theoretical perspective , such as developing game - theoretic or economic models  @xcite or from a behavioral perspective , such as studying the factors affecting real users monetary valuation of others privacy  @xcite .",
    "* we explore the potential of history - based decisions by performing a simulation on two large user networks .",
    "we show that the network - effects of our approach result in curtailing the growth privacy loss by 70% in a synthetic google drive - based collaboration network and by 40% in a real author collaboration network .",
    "we also simulate the effect of such decisions in a teams network .",
    "we demonstrate that teams can reduce the privacy loss by up to 45% by solely accounting for team members decisions ( cf . section  [ sec : simulation ] ) .",
    "there are four main entities that interact in the third - party cloud app system :    1 .   a _ user _ @xmath0 who uses that app for achieving a certain service 2 .   a _ cloud storage provider ( csp ) _ hosting the user s _ data _ 3 .   a _ data subject _ to whom the files belong and whose privacy is being considered .",
    "we further define two levels of data subject granularity : * _ individual - level granularity _ : i.e. , the user herself is interested in guarding her own data privacy , * _ team - level granularity _ : i.e. , a group of users are interested in guarding the privacy of team - owned data ( e.g. , using an enterprise version of cloud storage services ) 4 .   a _ vendor",
    "_ @xmath1 that is responsible for programming and managing a 3rd party cloud app ( or shortly a cloud app or a 3pc app ) .",
    "these vendors register their apps with the csps .",
    "the apps themselves are hosted on any website the vendors choose ( i.e. ,  not hosted by the csp itself ) .",
    "each user has access to a set @xmath2 of files stored at the csp .",
    "a subset of these files is owned exclusively by the data subject while the other subset is composed of files that are each shared with at least one other _",
    "collaborator_. we denote the set of all collaborators of user @xmath0 by @xmath3 . for simplicity reasons , we will assume throughout this work that the files of all data subjects , as well as the collaborators for each file , are all fixed from a reference step @xmath4 .",
    "using the csp s api , the vendor @xmath1 can get access , at step @xmath5 , to the subject s data upon _ user authorization _ , which consists of @xmath0 accepting a list of _",
    "permissions_. we will alternatively refer to this as _ app installation _ , and we will assume that exactly one app is installed at each step @xmath6 .",
    "permissions are named differently across various providers , but , in general , we can categorize them into three categories :    * * per - file access * : where the user has to authorize the vendor for each file access individually .",
    "this is typically done via a file picker provided by the csp itself . * * full - access * : where the vendor gets access to all users data . in the interface , this is worded , for instance , as `` view the files in your google drive '' or `` access to the files and folders in your dropbox '' .",
    "* * per - type access * : where the vendor gets access to all files of a specific type .",
    "for example , dropbox words it as `` access to images in your dropbox '' .",
    "some platforms , like google drive , do not provide app developers with such fine - grained options",
    ".    the authorization can also give @xmath1 access to files shared with the collaborators of @xmath0 .",
    "similarly , collaborators of @xmath0 can install apps that expose files shared with @xmath0 to new vendors .",
    "we denote the set of files of @xmath0 accessible by vendor @xmath1 at step @xmath6 as @xmath7 .",
    ".summary of notations used [ cols=\"<,<\",options=\"header \" , ]      a user is further assumed to be _ self - interested _ ,",
    "i.e. ,  only caring about optimizing the privacy of the data subject ( a.k.a .",
    ", privacy egoist ) , and _ non - cooperative _ ,",
    "i.e. ,  does not coordinate her decisions with others .",
    "we do not assume that the risks of installing each app are known to the users or calculated a priori .",
    "in fact , unlike other 3rd party app ecosystems , the risk of each cloud app can not be automatically estimated based on techniques such as taint tracking  @xcite or code analysis  @xcite because the main app s functionality is typically implemented on the server side ( which can not be accessed by external entities ) .",
    "such assumptions constitute the _ worst case _ in the scenarios we consider , and further privacy optimizations can be obtained by relaxing them .",
    "we also assume that the mental model for privacy - concerned users matches the possible permission granularities they are given . accordingly",
    ", privacy - concerned users can have one of the following privacy - goal granularities :    * * per - type privacy goal * : where users aim to optimize their privacy independently for different file types .",
    "for example , in an ecosystem like dropbox , where per - type access is an option , users might follow the separation - of - concerns principle .",
    "hence , they might install photo - related apps from a set of vendors that is different from the set authorized for document processing .",
    "* * all - files privacy goal * : where users aim to reduce the privacy risk for their entire set of files .",
    "this can be in the case of ecosystems which do not have the option of per - type access , like google drive .",
    "it can be also the case that a user of dropbox has this goal in mind despite being presented with finer - grained app permissions .",
    "we consider the 3rd party app vendors as the adversary ( and not the csp ) .",
    "the privacy indicator we introduce is best implemented by the csp , which already has access to the users and collaborators data .",
    "alternatively , this can be a feature within cloud access security brokers ( e.g. , skyhigh networks , netskope , etc . ) , which are already trusted by thousands of enterprises to protect their cloud data against other 3rd parties .",
    "moreover , we consider the protection against over - privileged apps as an orthogonal problem , which we have considered in  @xcite .",
    "we rather focus on the interdependent privacy problem , which covers all vendors with full access and is an issue in least - privileged apps too .      in order to quantify the privacy loss that a user incurs with time , we introduce now the _ vendors file coverage ( @xmath8 ) _ metric .",
    "consider a user @xmath0 and a set @xmath9 of vendors at a certain time step .",
    "for notation simplicity , we will omit the time step henceforth .",
    "@xmath10 is computed as the summation of the files fractions shared with each of these vendors : @xmath11    intuitively , @xmath10 increases as vendors in @xmath9 get access to more files of @xmath0 .",
    "it has the range @xmath12.$ ]   by @xmath13 as multiple vendors with access to all the user s files induce a higher privacy loss than one vendor with such access . ]",
    "if we consider the set @xmath14 of vendors explicitly authorized by user @xmath0 , we can define the _ self - vendors file coverage _ as : @xmath15    similarly , if we consider the set @xmath16 of vendors authorized by the collaborators @xmath3 of @xmath0 , we can define the _ collaborators - vendors file coverage _ as : @xmath17 finally , the _ aggregate @xmath18 _ for a user @xmath0 is that due to all vendors authorized by @xmath0 or its collaborators : @xmath19[equation : aggvfc ]    throughout this work , we will use the terms _ privacy loss _ and @xmath8 interchangeably . as will become evident in section  [ sec : study ] , this metric choice allows relaying a message that is simple enough for users to grasp , yet powerful enough to capture a significant part of the privacy loss .",
    "obviously , one can resort to a deeper inspection of content or metadata sensitivity ( as in  @xcite ) had the purpose been finding the best privacy model in general . however , for instigating a behavioral change , telling users that a company has 30% of their files is more concrete than a black - box description informing them that the calculated loss is 30% and constitutes less information - overload than presenting them with detailed loss metrics",
    "at this point , we are in a position to handle the first research question on the extent of collaborators contribution to a user s privacy loss .",
    "hence , we want to test the following hypothesis :    _ h1 : the collaborators app adoption decisions have a significant impact on the user s privacy loss . _",
    "if this hypothesis is valid in practice , it provides a strong motivation for designing privacy notices that aid users in accounting for their collaborators decisions , which is what we will study in section  [ sec : study ] . towards that",
    ", we will be dissecting the privacy loss , quantified by @xmath8 , that users incur in a realistic 3rd party cloud apps dataset .      to study the problem in a realistic context",
    ", we will be taking google drive as a case study in this work , given that it has one of the most popular 3rd party ecosystems .",
    "nevertheless , the insights gained from our work are applicable to other cloud platforms as well .",
    "the main ( content - related ) google drive permissions that 3pc apps vendors can request are presented table  [ tab : defaultpermissions ] , along with the google - provided description for each .",
    "this short description is also presented to the user when installing an app ( see figure  [ fig : baseline ] for an example app ) .",
    "the user can click on the info button next to each permission to read additional explanations in a popup .",
    "the user has to accept all permissions in order to utilize the app .",
    "these apps can be found on google chrome web store ( and other google stores ) , where users can rate and review them . in this work",
    ", we will focus on content - related permissions .",
    "hence , as discussed in section  [ sec : models ] , we differentiate between two levels of access : ( 1 ) full access , which includes the drive_readonly and drive permissions and ( 2 ) per - file access that includes the drive_file permission .",
    "google drive does not offer the per - type permissions option .",
    "l4.5cmcl * permission * & & * short name * +   + view the * files * in your google drive . & & drive_readonly +   + view and manage the * files * in your google drive . & & drive +   + view and manage google drive files that you have * opened or created with this app*. & & drive_file +   + view your google drive apps . & & drive_apps_readonly +    [ tab : defaultpermissions ]      one of the main challenges when studying the privacy loss in 3rd party cloud apps is the absence of public datasets with realistic file distributions , collaborator distributions , sharing patterns , 3rd party app installations , etc .",
    "we benefit in this section from a dataset that we have collected in a previous work via the privyseal service  @xcite .",
    "we build our analysis on it in order to evaluate the @xmath8 of users in a realistic context .",
    "privyseal is a web service for for assisting users in avoiding google drive apps that are over - privileged .",
    "it deters users by showing them the far - reaching insights that such apps can glean from their data ( e.g. ,  their topics of interest , collaboration and activity patterns , etc . ) .",
    "there are currently over 1500 registered users in privyseal , and we refer the interested reader for our previous work for more details  @xcite .",
    "the dataset , henceforth referred to as the _ privyseal dataset _ , was anonymized and contained metadata - only information .",
    "it included a subset of the files metadata of 183 privyseal users in addition to the google drive apps installed by those users prior to authorizing privyseal s app ( the drive_apps_readonly permission was requested by privyseal ) .",
    "each user had a minimum of @xmath20 files in total and at least @xmath21 of files that are shared .",
    "the dataset specifically contained :    * list of user ids ( anonymized via a one - way hash function ) ; * ids of files in each user s google drive , * list of anonymized collaborators ids for each file i d ; * list of apps with full - access installed by each user ; * the vendor of each app .    in total",
    ", the number of users in addition to collaborators was 3422 .",
    "overall , these users had installed 131 distinct google drive apps from 99 distinct vendors .",
    "figure  [ fig : datasetstats ] characterizes the privyseal dataset .",
    "particularly , it displays 4 distributions in this dataset , which realistically model the system under study :    * number of files per user , which follows a skewed distribution with a median of 67 files * sharing pattern : percentage of shared files out of all user files , which also follows a skewed distribution with a median around 18% * number of collaborators across all user files ( a.k.a . , the degree of the user node in the collaboration network ) : where 75% of the users had less than 23 collaborators * number of vendors authorized per user : also follows a skewed distribution with a median of 1 vendor per user      we computed the _ self-@xmath8 _ , the _ collaborators-@xmath8 _ , and the _ aggregate-@xmath8 _ ( as defined in section  [ sec : privloss ] ) for users in the privyseal dataset _ but not in computing _ collaborators-@xmath8_. ] .",
    "as we did not have the actual number of apps for each collaborator of users in the dataset , we assigned to these collaborators a set of apps from a random user of the dataset .",
    "we show in figure  [ fig : coverage_growth_withsharing ] how these metrics evolve as we gradually consider populations that collaborate more frequently . with @xmath21",
    ", we had a median of 1.39 for _ collaborators-@xmath8 _ , which was 39% higher than a median of 1.00 for _ self-@xmath8_. the significance of the median difference is evidenced by the non - overlapping box - plot notches .",
    "this difference became much larger when we considered users that share more files .",
    "we had a 100% median difference at @xmath22 and 523% median difference at @xmath23 .",
    "such results indicate that :    * the collaborators app adoption decisions contribute a core component to the user s privacy loss , thus confirming our hypothesis @xmath24 .",
    "* the higher the number of collaborators is , the higher the magnitude of loss these collaborators can potentially inflict .",
    "both conclusions motivate the need for taking collaborators decisions into account when designing privacy indicators for cloud apps , which is what we will embark on next .    0.5 , @xmath25 ) .",
    "the numeric labels denote the corresponding number of users in the dataset.,title=\"fig : \" ]    0.5 , @xmath25 ) .",
    "the numeric labels denote the corresponding number of users in the dataset.,title=\"fig : \" ]    0.5 , @xmath25 ) .",
    "the numeric labels denote the corresponding number of users in the dataset.,title=\"fig : \" ]    0.45 , @xmath25 ) .",
    "the numeric labels denote the corresponding number of users in the dataset.,title=\"fig : \" ]    [ fig : datasetstats ]    , @xmath25 ) .",
    "the numeric labels denote the corresponding number of users in the dataset.,scaledwidth=80.0% ]",
    "up till now , we have confirmed that , if users want to minimize their privacy loss , they are better off not ignoring the app installation decisions of collaborators . in this section ,",
    "we tackle the next research question , where we investigate the potential of privacy indicators in leading users to minimize their exposure to 3pc app vendors .",
    "we show first our design methodology for the privacy indicators , and we follow that by a web experiment that investigates the efficacy of these indicators in realistic scenarios .",
    "we call our proposed privacy indicators _ `` history - based insights '' ( _ hb _",
    "insights ) _ as they allow users to account for the previous decisions taken by them or by their collaborators .",
    "we continue to consider google drive as a case study , and we show this indicator in the context of google drive apps permissions in figure  [ fig : history_interface ] . compared to the current interface provided by google ( figure  [ fig : baseline ] ) , we added a new part to highlight the percentage of user files readily accessible by the vendor ( computed based on @xmath26 for each vendor @xmath1 ) .",
    "as we prove in appendix  [ sec : optimal ] , selecting the vendor that already has the largest percentage of user files is the optimal strategy to minimize the privacy loss in our context .",
    "we denote this strategy as _ `` history - based decisions''_. following the best practices in privacy indicators design  @xcite , our indicator was multilayered , with both textual and visual components .",
    "the wording of the main textual part was brief and general enough to hold for both the data percentage exposed by friends and that exposed by the user .",
    "we used a percentage value rather than a qualitative measure to facilitate making comparisons among apps based on this value .",
    "the visual part showed the percentage as a progress bar with a neutral violet color .",
    "the bottom textual part was added in a smaller font to provide further explanation for those interested .",
    "we used the term `` company '' in our interface instead of `` vendor '' as it is more commonly understood by the general audience .      in order to evaluate the new permissions interface , we performed an online web experiment ( rather than a lab study ) as we were mainly motivated by obtaining a large sample of users that is also geographically and culturally diverse .",
    "the hypothesis we wanted to test is :    _ h2 : introducing the new privacy indicator significantly increases the probability that users take history - based decisions . _    in addition , the study allowed us to build a realistic user decision model based on the choices taken by participants in different conditions .",
    "we will utilize this model in section  [ sec : simulation ] to simulate the app choices in a large user network and to study the effect on the overall @xmath8 in the network .",
    "we structured our study to have ( 1 ) an introductory survey , ( 2 ) a series of app installation tasks , and ( 3 ) a concluding survey .",
    "* user recruitment : * we recruited users via crowdflower s crowdsourcing platform . in our study , we restricted participation , via the platform s filtering system , to the highest quality contributors ( performance level 3 ) .",
    "we also geographically targeted countries where english is a main language as our interface was only in english . in order to further guarantee quality responses ,",
    "each user was rewarded a small amount of @xmath27 for merely completing the study and an additional amount of @xmath28 that was manually bonused for those who did not enter irrelevant text in the free - text fields .",
    "* instructions : * participants were first presented with introductory instructions that explained the context of the study ( i.e. ,  cloud storage services and 3rd party apps that can be connected to them ) .",
    "they were asked to only continue if they had good familiarity with cloud storage services ( e.g. ,  google drive , dropbox , etc . ) .",
    "we did not explicitly require that participants have experience with 3rd party cloud apps .",
    "however , we educated them about such apps throughout the instructions , particularly showing them two examples of 3rd party apps in action ( pandadoc for signing documents and iloveimg for cropping photos ) .",
    "these apps were displayed via animated gifs that play automatically and do not rely on the user clicking .",
    "we used limited deception by neither mentioning the focus of the study on participants privacy nor giving hints about selecting apps based on the installation history .",
    "the advertised purpose was to `` check how people make decisions when they install 3rd party apps . ''",
    "* introductory survey : * after checking the instructions , users were presented with an introductory survey , where they first entered general demographic information .",
    "this survey was also front - loaded with questions about cloud storage services ( several of which required free - text input ) in order to discourage users who had not used these services from continuing to the actual study .",
    "next , users could proceed to the study page .",
    "we used a split - plot design in the study .",
    "participants were randomly assigned to one of two groups :    1 .",
    "* baseline group ( _ bl _ ) * : where the permissions interface used is that currently provided by google drive ( figure  [ fig : baseline ] ) .",
    "* history - based group ( _ hb _ ) * : where the _ history - based insights_permissions interface ( figure  [ fig : history_interface ] ) is used .    in each group , the study consisted of 3 modules , which cover the main conditions that can occur when users desire to install a cloud app . on a high level , the modules investigate the following questions :    1 .",
    "* module 1 : * are users likely to select apps from the same vendor they installed from before ? 2 .",
    "* module 2 : * are users likely to select apps from vendors that her collaborators have used before ? 3 .   * module 3 : * do users consider the differences in access levels obtained by vendors that collaborators installed ?    in all modules , whenever the user was asked to _",
    "choose _ an app , she was presented with a list of 12 apps ( figure  [ fig : app_info ] shows an example app ) .",
    "only two of these apps were relevant to the task purpose , and they were placed on top of the list ( randomly positioned as first or second ) . with this setup",
    ", we wanted to mimic the realistic setup of app browsing while not squandering the user s effort on finding apps .",
    "all apps had the same full access permissions too ( namely drive permission ) . unlike in chrome store",
    ", we removed elements such as ratings , user reviews , and screenshots and kept a minimal interface .",
    "this is all in order to reduce the distractions from factors outside the study .",
    "we refer the user to the work of kelly et al .",
    ",  @xcite who investigated the effects of those elements on users decisions for android apps .",
    "in order to account for fatigue and learning effects , modules 1 , 2 , and 3 were presented in a random order for users .",
    "we piloted our experimental setup in two stages : with colleagues and with online users from the crowdflower community itself . for reviewing the online pilot testers work",
    ", we embedded a javascript code for session recording in our study s web page , which allowed us to view the user s mouse and keyboard actions on our side .",
    "* demographics : * we had 157 users who completed the study . based on manually reviewing the users inputs , we removed 16 users who were inputting irrelevant free - text in the survey in the study .",
    "we thus report the results of 141 users , 72 of which were in the _ bl _  group and 69 in the _ hb _  group . in  table",
    "[ tab : demographics ] , we describe the participants demographics based on the introductory survey . of these participants , @xmath29 were males and @xmath30 were females .",
    "they were between 18 and 62 years old , with a median of 31 .",
    "moreover , 42.3% of the participants had worked or studied in it before .",
    "participants were mostly from india ( 37% ) , usa ( 35% ) , britain ( 7% ) , germany ( 7% ) , and canada ( 7% ) .",
    "crowdflower presents the users with an optional satisfaction survey after completing the study , and 49 users took this survey . on average , the study received 4.2/5 for instructions clarity , 3.8/5 for questions fairness , 3.8/5 for ease of job , 3.6/5 for pay sufficiency ( before the bonus was rewarded ) .",
    "this ensures that participants behavior has not been affected by either a lack of time to complete the task or the task design in general .",
    "r l l   + * age * & 18 - 62 & ( median 31 years ) + & &   + * gender * & 35.5% & female + & 64.5% & male +   + * occupation * & 59.6% & full - time employees + & 14.2% & student + & 6.4% & part - time worker + & 8.5% & self - employed + & 5.0% & homemaker + & 6.4% & unemployed / retired +   + * it experience * & 41.8% & have worked or studied in it +   + * degree * & 19.1% & high school + & 7.1% & trade / tech./vocational training + & 51.1% & associate or bachelor s degree + & 22.7% & post graduate degree +   + * countries * & 35.0% & usa + & 37.5% & ind + & 7.5% & gbr + & 6.9% & deu + & 6.9% & can + & 7.4% & aus+irl+ nld + pak +      [ fig : instructions ] + [ fig : exp-1-install ] [ fig : exp-1-choice ] + [ fig : exp-2-intro ] [ fig : exp-2-install ] + [ fig : exp-3-intro ] +    we now move to the detailed description of the modules and the results obtained .",
    "these modules are summarized in figure  [ fig : modules ] , to which we refer henceforth .",
    "we also show sample screenshots from the online study in figure  [ fig : screenshots ] .",
    "the results are also presented in  table  [ tab : studyresults ] .",
    "* module 1 ( self - history scenario ) : * tests whether the user is more likely to select an app from the same vendor she has just installed from before . in step ( a ) , the user is made aware the she installed an app from a specific ( figure  [ fig : exp-1-install ] ) . in step ( b ) , she is asked to install an app that satisfies the given purpose ( figure  [ fig : exp-1-choice ] ) among a list of apps .",
    "two of the listed apps were relevant , and one of them was from vendor @xmath1 itself .",
    "despite the participants being informed one step earlier that they installed an app from `` thetimetube.com '' , that did not make a difference in the _ bl _  case : half of the users still chose the app from the new vendor `` nitrosafe.org '' ( cf .",
    "table  [ tab : studyresults ] . in the absence of traditional signals that users follow for deciding on apps ( reviews , ratings , permissions )",
    ", participants apparently made decisions that cancelled out , making the two apps equally favored across participants .",
    "* the vast majority of users were not approaching the installation from the angle of keeping their data with fewer shareholders*. based on their provided justifications , they rather looked for other cues , such as selecting the app that , in their opinion , has a more comprehensive description , a more professional logo , a better sounding name , or a more trustable url .",
    "still , 12 users have explicitly mentioned in their text input that they chose an app _ because _ it is from the same vendor they have dealt with earlier .",
    "even then , neither of them has alluded to a privacy motivation behind the choice .",
    "these 12 participants mainly provided cross - app compatibility , interface familiarity , and satisfaction with the previous vendor as justifications .",
    "for example , one participant wrote : `` _ _ i favoured malware scanner due to the fact that the name ` thetimetube.com ' was in the last app installed , and i tend to install apps from the same company due to cross - app compatibility usually found in apps by the same company .",
    "_ _ '' interestingly , two users justified their installation of the app from the new vendor ( nitrosafe.org ) by writing that they had just installed an app from the same company before .",
    "this indicates that , * even when users try to account for previous decisions , they might find it difficult to remember the previous app vendors*. given that our study had a short time span separating the current from the previous installation , we expect that such mistakes would be even more common in real scenarios when app installation instances are separated by longer time spans .",
    "the _ hb _",
    "group witnessed a much larger proportion of users who favored the option with less privacy loss .",
    "72.2% of the participants selected the app from the `` thetimetube.com '' ( the vendor which already has access ) . the difference of 22.8% compared to the _ bl _  group is statistically significant ( fisher s exact test , @xmath31 ) .",
    "many of the participants who chose the app from `` thetimetube.com '' reported that they were motivated by the 100% access that the app already has .",
    "we counted around 40 such users ( i.e. ,  57% of the _ hb _",
    "some of them went further and explicitly mentioned that their selection was motivated by giving data to fewer data owners ( i.e. ,  more privacy ) .",
    "for example , one user wrote : `` _ _ this company has access to all my files , so i would choose them as i do nt want to have 2 companies with full access to my files _ _ '' .    in a nutshell",
    ", we were able to verify our hypothesis in this scenario : * the new privacy indicator leads users to more frequently choose the app from a vendor they already authorized*. furthermore , we have discovered that the _ hb _",
    "insights interface has indirectly made users think about various positive effects brought by using apps from the same vendor .",
    "this eventually lead them to make more privacy - preserving decisions .",
    "@rcccccccccc@ & & & & & & * @xmath32 * & & * @xmath33-value * + ( lr)3 - 4 ( lr)6 - 7 & & _ vwa _ & _ nv _ & & _ vwa _ & _ nv _ & & & & +   + * self history * & & 50.0% & 50.0% & & 75.4% & 24.6% & & 25.4% & & 0.003 + * collaborator s app * & & 52.8% & 47.2% & & 88.4% & 11.6% & & 35.6% & & < 0.001 + * collaborator s vendor * & & 58.3% & 41.7% & & 82.6% & 17.4% & & 24.3% & & 0.002 + * multiple collaborators * & & 44.4% & 55.6% & & 82.6% & 17.4% & & 38.2% & & < 0.001 +    * module 2.1 ( collaborator s app scenario ) : * tests the likelihood that the participant selects the same app that her collaborator had used . in step ( a ) , the participant is made aware that she had shared all her photos with a friend @xmath34 ( figure  [ fig : exp-2-intro ] ) . for more familiarity",
    ", we also added a picture for each of the two fictitious friends throughout the study . in step ( b ) , the user is made aware that her friend @xmath34 has installed an app @xmath35 ( figure  [ fig : exp-2-install ] ) from vendor @xmath1 .",
    "she is asked to type the name of the app s vendor ( `` paste '' option was disabled in the input field to further ensure the participant is aware of the vendor ) . in step ( c ) ,",
    "the user is asked to install an app with a certain purpose ( similar to figure  [ fig : exp-1-choice ] ) .",
    "one of the two matching apps is app @xmath35 .",
    "similar to the previous module , the _ bl _  group witnessed an almost even split between `` online player '' , installed previously by the friend , and `` enjoy music player '' , from a new vendor ( cf .",
    "table  [ tab : studyresults ] .",
    "we also noticed that 20 participants in this group justified their decision by mentioning that their friend has used the app .",
    "still , neither of them alluded at privacy reasons in their justifications .",
    "instead , the two most prevalent motivations were ( 1 ) considering the friend s use of the app as a _ recommendation _ or ( 2 ) achieving _ compatibility _ with their friends app , which facilitates data sharing within the app itself . quoting one user : `` _ _ this is the same app my friend is using so it should be quite compatible for us to both share . _ _ ''    in addition to having a significant 35.6% difference in the case of the _ hb _  group , we noticed that 32 users mentioned the existing data access as a reason for choosing the app `` online player '' . also , 26 users referred to the fact that the friend has installed this app before ( including those who mentioned both of the previous reasons ) . unlike the _ bl _  group",
    "s justifications though , where the friend s recommendation and the app s compatibility prevailed , the privacy issue was explicitly brought up by at least 10 users .",
    "one participant put it as follows : `` _ _ thanks to john , they have already access to 70% of my data .",
    "sharing the last 30% is nt as bad as sharing 100% of my data with driveplayer.com.__ ''    * module 2.2 ( collaborator s vendor scenario ) : * we proceed in steps ( d ) and ( e ) as in the previous scenario s steps ( b ) and ( c ) , with the difference that a _ new _ app from @xmath1 is included among the options in step ( e ) instead of the exact same app @xmath35 .",
    "one interesting insight from this scenario is that * the line between the company and the app is blurred in the minds of several users * who used the two entities interchangeably .",
    "in fact , 3 users in the _ bl _  group and 7 participants in the _ hb _  group justified their choices by mentioning that their friend installed the _ same app _ before , which was not the case .",
    "for example , one user wrote : `` _ _ this app already has access to my files , and i do nt want to install any new app . _ _ ''",
    "* module 3 ( multiple collaborators scenario ) : * given collaborators @xmath36 and @xmath37 , where the user shares much more data with @xmath36 , this scenario checks the likelihood of the participant authorizing an app that @xmath36 has installed . in step ( a )",
    ", the participant is made aware that @xmath36 has access to more data than @xmath37 ( figure  [ fig : exp-3-intro ] ) . in steps",
    "( b ) and ( c ) , the participant is made familiar with the apps each of the friends installed ( similar to figure  [ fig : exp-2-install ] ) . in step ( d ) , the user is asked to select an app with a specific purpose .",
    "the two friends apps are the only ones matching , and the choice is to be made between them ( similar to figure  [ fig : exp-1-choice ] ) .    in the _ bl _  group",
    ", we had 44.4% of the participants choosing the app installed by @xmath36 .",
    "still this percentage is relatively close to an equal split between the two apps . out of this percentage ,",
    "13 users justified their choice by mentioning that they were encouraged to follow the choice of friend @xmath36 .",
    "even though they did not mention privacy , the larger number of files shared with @xmath36 was often used as a justification . for example , one participant wrote : `` _ _ this is the app that john already uses , and he has access to all of my files .",
    "the pdf mergy app is used by lisa , but she only has access to part of my files . _ _ ''    in the _ hb _  group , around 82.6% chose the app previously installed by the friend @xmath36 , which is significantly more than those in the _ bl _  case ( fisher s exact test , @xmath38 ) .",
    "looking at the justifications , around 37 users explicitly mentioned the higher access level that this app already possesses as a reason for their choice .",
    "privacy was additionally mentioned by 8 of these users .",
    "quoting one of them : `` _ _ pdf mergy already has access to 70% of my files .",
    "using pdf files merger would unnecessarily increase third party app access to my files .",
    "_ _ '' however , we still had 2 users who went for the app with less existing access , with one of them saying he favors the app that only `` _ _ had accessed 30% of files before installation _ _ '' .",
    "what was interesting though is that * almost all users who mentioned friends were actually making a comparison between the two friends existing access level * , regardless of their final choice .      at the end of the user study , users were presented with a final set of questions .",
    "we asked them whether they would like to be notified when a friend installs an app that gets access to their shared files . around 92% of users in the _ bl _  group and 90% of users in the _ hb _  group agreed .",
    "we further asked the participants whether they are fine with a collaborator being notified when they install applications that access files shared with that collaborator .",
    "the percentage of people who agreed dropped to 75% in the _ bl _  and 78% in the _ hb _  group .",
    "the relatively small difference between the answers to these two questions highlights that * only a minority of users is not willing to make the trade - off of contributing to the overall system .",
    "* such users can be given the option to not use privacy indicators based on their friends decisions .",
    "next , users were asked the following question _ `` assume you have installed an application called youmusic from a company called musicana and gave it access to all your files on google drive .",
    "now you are considering installing an application called youvideo from the same company .",
    "how do you think that this application will affect your privacy:''_. only 11% of each group replied by _",
    "`` negatively''_. the vast majority in both groups either perceived the avoidance of a new vendor as a positive outcome or considered that the privacy loss will remain the same .",
    "interestingly , the users in the _ bl _  showed a similar reasoning in justifying their choices as the _ hb _  group although the latter were primed about these aspects via the privacy indicators .",
    "this indicates that * the privacy indicators actually match the first intuition for a large fraction of users*.      overall , we found out that , in the three modules , participants in the _ hb _",
    "group were significantly more likely to install the app with less privacy loss ( i.e. ,  the app from the vendor with the largest share of the user s files ) than those in the _ bl _  group . despite showing the efficacy of history - based insights ,",
    "our study still has its limitations . in order to get a large , diverse sample size",
    ", we resorted to a web experiment based on role - playing with hypothetical data .",
    "it would be interesting to see how such results extrapolate to the case where users own data is in question .",
    "moreover , in our design , we have abstracted several factors ( e.g. , ratings and reviews ) , which have been previously studied in similar ecosystems  @xcite , in order to focus on one factor .",
    "these factors might have diluted the effect of the privacy indicator .",
    "still , we conjecture that , although the absolute values of our findings might not strictly apply , the differences between the two groups will still be practically significant .    additionally , in this paper",
    ", we have investigated only one type of history - based privacy indicators .",
    "evidently , such indicators can be integrated at different stages of the app installation process .",
    "for example , they can be part of the recommendation strategy for suggesting alternative apps .",
    "they can also be included in the apps search interface .",
    "apps can also be labelled as `` privacy preserving '' in the web store based on this metric .",
    "it is also possible that the privacy indicator is only shown when the vendor has existing access to the user s data .",
    "this might serve to reduce the habituation effect and the information overload .",
    "the best choice among these deployment scenarios needs further investigation .",
    "furthermore , it is important to note that , although our experimental interface mentions the collaborators name in the explanation under the progress bar , this does not have to be the case in actual deployments .",
    "we hypothesize that removing the name will not have a significant impact on the results as it was not highlighted in the interface .",
    "this allows the csp to relay such information to the users without exposing sensitive data about particular collaborators .",
    "the csp can resort to more sophisticated anonymization methodologies , such as showing a non - exact percentage that can be mapped to multiple collaborators . exploring the impact of these techniques",
    "is left for a future work .",
    "moreover , we note that this anonymization might not be needed at all in the enterprise settings , where apps installed by team members are supposed to be visible for the administrators . as we show in section  [ sec : teams ] , a significant reduction in privacy loss can be achieved without even accounting for decisions by users external to the team .    finally , the privacy indicator in our study has addressed two granularity levels : full and per - file access .",
    "however , the same indicator can be extrapolated to the case of per - type access .",
    "for example , the interface can say : `` the app s company already has access to 70% of your _ photos _ '' ( instead of _ files _ ) .",
    "in the previous section , we showed the significant change that our privacy indicator can effect through encouraging users to make history - based decisions",
    ". we will tackle the next research question , where we investigate the impact of adopting such privacy indicators on the privacy risk in realistic scenarios with large user networks . as we are not in the position of the csp to study an actual implementation of the _ hb _",
    "insights interface over time , we will perform a simulation of potential users installation behavior .",
    "we will base this on both the crowdsourced decision model inferred from the user study and on new collaboration networks that we construct .",
    "* collaboration networks : * for the purposes of this simulation , we constructed the following three networks :    * * inflated google drive network * : we used the standard degree - driven approach for network topology generation to construct a larger google drive network based on the one in the  _ privyseal dataset _ of section  [ sec : privsealdataset ]  @xcite .",
    "based on an input user degrees distribution from that dataset , we particularly used the _ configuration model _ as described by newman  @xcite and implemented by the library networkx  @xcite for inflating the graph .",
    "this model generates a random pseudograph ( a graph with parallel edges and self - loops ) by randomly assigning edges to match an input degree sequence .",
    "we removed the self - loops and parallel edges a posteriori from the generated graph . in the end , we had a collaboration graph with 18,000 users and 138,440 edges .",
    "this graph is , by construction , a connected graph , with an average node degree of 15 . *",
    "* paper collaboration network * : in an effort to have a realistic , large collaboration network without resorting to graph inflation , we relied on the microsoft academic graph , which consists of records of scientific papers along with the authors and their affiliations  @xcite .",
    "we used a snapshot of 50,000 papers , and we constructed the collaboration graph based on it .",
    "we ended up with 41,000 collaborators and 199,980 edges .",
    "the graph itself is not a connected graph but is rather constructed of around 1700 connected components .",
    "the average node degree is 4 .",
    "our rationale is that this graph captures a realistic scenario of users collaborating on authoring documents , which is , in fact , an activity achieved via cloud services nowadays .",
    "hence , it is fit for showing the efficacy of our privacy indicators .",
    "* * team collaboration network * : we used the same academic graph in order to construct a network of teams .",
    "a team is defined as a frequently collaborating group of people .",
    "motivated by research around community detection  @xcite , we use strongly connected components ( sccs ) in order to label teams in our graph .",
    "we ended up with 16,400 users split over 1700 teams . unlike the previous two networks where users themselves are the data subjects ( whose privacy is to be optimized )",
    ", members of each team in this network consider their team as the data subject .",
    "* sharing and installation patterns : * in order to closely model the user characteristics in google drive , we assigned to each user in the collaboration networks a file sharing distribution and a number of apps corresponding to a user with a matching degree in the privyseal dataset .",
    "* apps : * as we wanted to perform the simulation with a much larger number of users than we had in the dataset described in section  [ sec : privsealdataset ] , we also needed a larger collection of apps .",
    "given that google chrome store has only around 500 apps that are tagged by the `` works with google drive '' tag , we decided to also include all google chrome apps in the dataset ( i.e. ,  even those that do not have this tag ) . as far as the simulation is concerned , this step is justified since the only realistic information that we will rely on is the distribution of vendors per app . it is fair then to assume that this distribution does not differ significantly between the general category and the google drive category .",
    "hence , we augmented the privyseal dataset via apps from the google chrome store to arrive at 1000 apps .",
    "in addition to the app s installation count and vendor name , we also collected the set of `` _ _ related apps _ _ '' that the store displays for each app .",
    "this is because , in our simulation , we will assume that users have the choice to choose the app itself or one of its related apps .",
    "again , this is a fair assumption as these related apps are mostly the apps which deliver a close functionality to the app itself , and we will only rely on them to model the alternatives at each simulation step .    * user decision models : * for the purpose of this simulation , we define 3 user decision models :    * * fully aware model ( ): * the user always makes the decision that minimizes the privacy loss of the data subject , taking into account all previous installation decisions by her and by her collaborators . * * experimental history - based model ( ) * : the user takes decisions similar to what a random user of the _ hb _  experimental group does . in specific , we model those users as taking a history - based decision with probability @xmath39 and making a random app choice with probability @xmath40 .",
    "we set @xmath39 based on the number of users who mentioned the app existing access in _ writing _ as a reason for their choice in each module of section  [ sec : study ] .",
    "based on module 1 s users responses , we set @xmath41 when the user encounters a vendor she previously authorized",
    ". based on module 2 , we set @xmath42 whenever the user is presented with one vendor previously authorized by a single collaborator . based on module 3 , we set @xmath43 for the cases where the user is presented with multiple vendors previously authorized by her collaborators . in all of these cases ,",
    "the user will select the vendor with the minimal resulting _ aggregate _",
    "@xmath18 with probability @xmath39 . * * experimental baseline model ( ): * the user takes decisions similar to what a random user of the _ bl _  experimental group does . as users in practice",
    "are rarely informed of what their friends have installed before , we do not integrate this knowledge into the model .",
    "hence , we only account for the case of module 1 , where the user s previous decisions are concerned .",
    "based on the fraction of users who mentioned the app s existing access as a motivation for their choice , we set the probability of taking history - based decision in this model as @xmath44 .",
    "in the special case of the team collaboration network , users who take history - based decisions account for their own decisions and the decisions of their team members only .",
    "we do not consider that users account for decisions taken by members of other teams .",
    "this is to demonstrate the potential of the privacy indicators under strict conditions .",
    "initialize @xmath18 value to 0 for each user select a random user @xmath45 based on user s app installation frequency[lst : line : userselect ] select a random new app @xmath35 based on app s installation count[lst : line : appselect ] @xmath46 @xmath47 set of vendors of apps in @xmath48 @xmath49 a random rational number in the range [ 0,1 ]    select a random vendor @xmath50 install the app @xmath51 in @xmath48 from vendor @xmath52 install app @xmath35 compute @xmath53 for each vendor @xmath1 in @xmath54 at this time step select the vendor @xmath50 with highest @xmath53 at this time step install the app @xmath51 in @xmath48 from vendor @xmath52 install app @xmath35 install app @xmath35 update _",
    "aggregate @xmath18 _ for @xmath0 update the average _ aggregate _",
    "@xmath8 over all users    we now move to the description of the simulation itself , which is detailed in  algorithm  [ alg : simulation ] .",
    "we had three simulation groups , named after the three decision models :  group ,  group , and the  group .",
    "the simulation was run until the average number of apps installed across by users reached 30 apps . on a high level , at each simulation step , the following actions are performed :    * a user is selected from the collaboration network via a weighted random sampling based on the assigned app installation frequencies ( line  [ lst : line : userselect ] ) .",
    "this accounts for the diversity of users installation frequencies .",
    "an app @xmath35 is selected from the simulation apps dataset via a weighted random sampling based on the actual app installations count in google chrome store ( line  [ lst : line : appselect ] ) . that way ,",
    "popular apps are installed more frequently ( as is the case in practice ) . *",
    "a user decision is simulated .",
    "the user is assumed to be choosing the app @xmath35 or one of its related apps .",
    "this choice is made depending on the user s decision model , as explained previously .",
    "* finally , the average _ aggregate _",
    "@xmath8 is computed based on all users _ aggregate _ @xmath18 .",
    "[ fig : simulation_groups_inf ]    [ fig : ratio_inf ]   [ fig : events_inf ] +     [ fig : simulation_groups_auth ]    [ fig : ratio_auth ]    [ fig : events_auth ] +     [ fig : simulation_groups_team ]    [ fig : ratio_team ]    [ fig : events_team ]    to demonstrate the simulation results , we show three types of figures per collaboration network . on a high level , in figures  [ fig : simulation_groups_inf ] ,  [ fig : simulation_groups_auth ] , and  [ fig : simulation_groups_team ] , we show how the privacy loss ( quantified using the average aggregate-@xmath8 ) in each group evolves as users install more apps",
    ". in figures  [ fig : ratio_inf ] ,  [ fig : ratio_auth ] , and  [ fig : ratio_team ] , we show ratios of the privacy loss in the two experimental groups  and  with respect to the baseline  group . finally , figures  [ fig : events_inf ] and  [ fig : events_auth ] , and  [ fig : events_team ] show the actual events contributing to the privacy loss growth , where we can specifically check the fraction of apps coming from new vendors , those coming from vendors previously authorized by the user , and those from vendors previously authorized by collaborators .",
    "based on these metrics we start by analyzing the results for the individuals networks , where we observe the following :    * curtailed growth of privacy loss : * from figures  [ fig : simulation_groups_inf ] and  [ fig : simulation_groups_auth ] , we notice that the growth of the privacy loss is visibly curtailed in the cases of  and  groups compared to the baseline  group .",
    "this significant divergence demonstrates the efficacy of our _ hb_privacy indicators .",
    "* impact of the network effect : * looking into the ratios in figures  [ fig : ratio_inf ] and  [ fig : ratio_auth ] , we see that the privacy loss in the  group has dropped by 41% in the inflated network and by 28% in the authors - based network ( both with respect to the baseline ) . in the  group , where users always optimize their privacy ,",
    "the privacy loss has dropped by 70% in the inflated network and by 40% in the authors - based network .",
    "this higher impact in the case of the inflated network is due to the fact that it is a connected graph , unlike the authors - based network , which is composed of smaller connected components .",
    "nevertheless , we can state that , although our privacy indicators have a larger effect on highly connected networks , they are still significantly effective in less connected networks , like the authors - based dataset .",
    "* importance of accounting for collaborators decisions : * to dive further into events that lead to the observed privacy loss patterns , we look into figures  [ fig : events_inf ] and  [ fig : events_auth ] .",
    "first , we observe that users in the  group are mainly installing new apps from vendors that had no previous access to their data .",
    "this is reflected in the almost linear increase of privacy loss in figures  [ fig : simulation_groups_inf ] and  [ fig : simulation_groups_auth ] .",
    "second , we observe that , in the case of the inflated network , users have been frequently installing apps from vendors with existing access through their collaborators .",
    "in fact , as apparent in figure  [ fig : events_inf ] , this event outnumbers the event of installing from a new vendor .",
    "third , the number of installations from collaborators vendors is also significant in the case of the authors - based dataset .",
    "while it does not outnumber the installations from new vendors ( due to the low - graph connectivity ) , this is still enough to lead to 28% and 40% decrease in the privacy loss in the  and the  groups respectively . finally , we note that , although the users are more frequently encountering vendors authorized by their collaborators than by themselves , the latter event is still significantly impacting the results .",
    "this is because users still incur an incremental privacy loss with vendors authorized by their collaborators while this loss is zero with vendors they have previously authorized .",
    "accordingly , the obtained optimizations are a result of users accounting for their own and for others decisions .",
    "we now discuss the results for the case of the collaboration network where users work in teams and aim to protect the privacy of the team s data .",
    "we observe the following , based on figure  [ fig : sim_team ] :    * inherent usage of similar apps : * from figure  [ fig : events_team ] , it is clear that the dominant event is that of users installing apps which have been authorized by other team members before .",
    "this is even in the case of the baseline group ( ) , which was not the case in the individuals networks .",
    "we justify that by the fact that we selected apps at each simulation step to match their realistic installation frequencies . in practice ,",
    "apps installation counts follow a long - tail distribution , and users tend to mostly install a limited set of apps .",
    "that is why team members will naturally tend to install a set of similar apps .",
    "* curtailed growth of privacy loss : * still , we observe that the trend of slower growth of privacy loss also applies in the case of teams ( figure  [ fig : simulation_groups_team ] ) .",
    "as we also observe in figure  [ fig : ratio_team ] , the privacy loss has decreased by 23% for the  group and by 45% for the  group , both with respect to the baseline group .",
    "this implies that there is an ample room for privacy optimization in teams too .",
    "* effect due to internal collaborators : * we finally observe that the privacy loss decrease was achieved via decisions taken by each team s members independently , without relying on other teams decisions .",
    "this highlights the fact that _ hb_privacy indicators can still be effective even when users do not account for others decisions .",
    "obviously , taking the external members decisions into account can lead to further optimizations .",
    "+ in sum , our simulations provide further evidence of the efficacy of using history - based privacy indicators in a large network of collaborators .",
    "it is worth noting too that , although users in our study were following the  decision model , we believe that , in an actual deployment of such indicators , the model will move closer to the  model .",
    "this is because users are more protective when their personal data is at risk than when they are put in a role playing scenario about fictitious data .",
    "moreover , users in our study were exposed to this indicator for the first time .",
    "when users are educated more about this feature , they might be more likely to take advantage of it .",
    "the problem of interdependent privacy has been tackled before in the context of social apps .",
    "the main approaches were high - level game - theoretic or economic modeling . in  @xcite",
    ", the authors introduced the concept of interdependent privacy and modeled its impact via a game theoretic , ( 2-player , 1-app ) model .",
    "the work by pu and grossklags  @xcite presented a more elaborate economic model that additionally accounts for the interplay among various social network parameters .",
    "they showed that app rankings do not accurately reflect the level of interdependent privacy harm the app can cause and that even rational users who consider their friends well - being might adopt apps with invasive privacy practices .",
    "evidently , these results do not apply in the cloud apps case , where _ all _ apps have the potential to inflict interdependent privacy harm .    a later work by pu and grossklags  @xcite used a conjoint study approach to quantify the monetary value which individuals associate with their friends personal data .",
    "they found that individuals place a significantly higher value on their own personal information than their friends personal information .",
    "this further supports our assumption of self - interested users in this work .",
    "the same authors also built on a user survey in  @xcite to assess the factors affecting users own privacy concerns as well as friends privacy concerns in the context of social app adoption .",
    "in particular , they found evidence of negative association between past privacy invasion experiences and the trust in 3rd party apps handling of their own data .",
    "they also found partial support for a positive effect of privacy knowledge on concerns for users own privacy and their friends privacy . in this work ,",
    "we are focused on quantifying the interdependence of privacy in the context of cloud apps before addressing it from a usable privacy perspective , thus bridging the gap between the theoretical studies and the end - user needs .",
    "our previous work  @xcite was the first to study the privacy of 3rd party cloud apps and to expose that almost two thirds of those apps are over - privileged . in that work",
    ", we introduced a novel privacy indicator for deterring users from installing over - privileged apps by showing them far - reaching insights that apps can needlessly infer from their data ( e.g. ,  top topics , faces , or locations of interest ) . in the context of android apps , kelly et al .",
    ", showed that , by adding a set of privacy facts about an app , users will be more likely to choose apps with fewer permissions  @xcite .",
    "harbach et al . , tackled the same problem but presented users with random examples from their data ( e.g. ,  pictures , contacts , etc . )",
    "@xcite .",
    "almuhimedi et al . showed the effectiveness of privacy nudges , which regularly alert users about sensitive data collected by their apps , in encouraging users to review and adjust their permission  @xcite .",
    "all these works , however , tackle the problem of over - privileged apps and try to lead the user into either avoiding them or adjusting their permissions whenever possible .",
    "our current work helps users improve their privacy by reducing the vendors with access to their data , even if the functionality delivered by the vendor abides by the least - privilege principle .",
    "hence , it complements these approaches and can be deployed alongside any of them .",
    "the findings in this work are the first to concretely delineate the various aspects of interdependent privacy in 3pc apps .",
    "one of the major outcomes is that a user s collaborators can be much more detrimental to her privacy than her own decisions .",
    "consequently , accounting for collaborators decisions should be a key component of future privacy indicators in 3rd party cloud apps .",
    "we have shown the impact of history - based insights as a privacy enhancing technology in this context , especially that , based on our user study , users are less likely to account for previous decisions on their own .",
    "our privacy indicators would optimally be implemented by the csps themselves as they control the authorization interface and the application stores .",
    "the indicators can also be realized by third party privacy providers with access to users data .",
    "our approach can also be easily mapped to other ecosystems . in the mobile apps scenario",
    ", it can enable users to reduce the number of vendors with access to her contacts .",
    "it can also be extended to the case where the goal is protection against 4th parties ( e.g. , ad providers and data brokers ) .",
    "there , the user can account for data previously held by a 4th party with which the app vendor cooperates . finally , due to their usability and effectiveness",
    ", we envision history - based insights as an important technique within the movement from static privacy indicators towards dynamic privacy assistants that lead users to data - driven privacy decisions .",
    "we would like to thank deniz taneli and nicolas hubacher for their help in exploratory work that led to this paper .",
    "we also thank rameez rahman for the helpful discussions and the anonymous reviewers for their valuable feedback .",
    "the research leading to these results has received funding from the eu in the context of the project _ cloudspaces _ : open service platform for the next generation of personal clouds ( fp7 - 317555 ) .",
    "in this section , we complement section  [ sec : hbdesign ] by providing a proof the optimal user strategy for minimizing the privacy risk , given our assumptions .",
    "we follow the notation introduced in section  [ sec : models ] .",
    "let us consider that each 3pc app vendor has a probability @xmath33 of exposing users data .",
    "as we do not assume that users are provided with a per - vendor risk estimation utility , we set this probability to be the same for all vendors .",
    "in general , at a time @xmath6 , a user @xmath0 would have exposed her data to a set @xmath9 of vendors , such that each vendor @xmath1 has access to a fraction @xmath55 of the files . without loss of generality",
    ", we will consider henceforth that the user has an all - files privacy goal ( cf .",
    "section  [ sec : usermodel ] ) .",
    "however , the same reasoning applies in the case of a per - type privacy goal . in that case",
    ", we simply replace `` files '' by `` files of a specific type '' ( e.g. photos , documents ) .",
    "we will also be assuming that the users themselves are the data subjects ( i.e. ,  we consider individual - level subjects ) .    for a vendor @xmath1",
    ", we quantify the user s privacy risk magnitude as @xmath56 , i.e. ,  the fraction of user files possessed by the vendor multiplied by the probability that the vendor exposes the user s files .",
    "this vendor could have obtained access due to app installations by the user herself or by her collaborators .",
    "a user s privacy risk magnitude at time @xmath6 can thus be defined as the sum of the risk magnitude across vendors in @xmath9 : @xmath57 .",
    "when a user installs an app from a vendor @xmath52 at time @xmath58 , the vendor gets access to the whole set of user s files .",
    "hence , the risk magnitude is increased by @xmath59 .",
    "given that @xmath33 is constant , the risk magnitude can be minimized by choosing @xmath52 , such that @xmath60 ( which can also be written as @xmath61 ) .",
    "hence , the optimal , greedy strategy to minimize the risk is to select the vendor that already has the largest fraction of user files , thus minimizing @xmath59 .",
    "we call this strategy : `` history - based decisions '' ."
  ],
  "abstract_text": [
    "<S> cloud storage services , like dropbox and google drive , have growing ecosystems of 3rd party apps that are designed to work with users cloud files . </S>",
    "<S> such apps often request full access to users files , including files shared with collaborators . </S>",
    "<S> hence , whenever a user grants access to a new vendor , she is inflicting a privacy loss on herself and on her collaborators too . based on analyzing a real dataset of 183 google drive users and 131 third party apps , we discover that collaborators inflict a privacy loss which is at least 39% higher than what users themselves cause . </S>",
    "<S> we take a step toward minimizing this loss by introducing the concept of _ history - based decisions_. simply put , users are informed at decision time about the vendors which have been previously granted access to their data . </S>",
    "<S> thus , they can reduce their privacy loss by not installing apps from new vendors whenever possible . </S>",
    "<S> next , we realize this concept by introducing a new privacy indicator , which can be integrated within the cloud apps authorization interface . via a web experiment with 141 participants recruited from crowdflower , we show that our privacy indicator can significantly increase the user s likelihood of choosing the app that minimizes her privacy loss . </S>",
    "<S> finally , we explore the network effect of history - based decisions via a simulation on top of large collaboration networks . </S>",
    "<S> we demonstrate that adopting such a decision - making process is capable of reducing the growth of users privacy loss by 70% in a google drive - based network and by 40% in an author collaboration network . </S>",
    "<S> this is despite the fact that we neither assume that users cooperate nor that they exhibit altruistic behavior . to our knowledge </S>",
    "<S> , our work is the first to provide quantifiable evidence of the privacy risk that collaborators pose in cloud apps . </S>",
    "<S> we are also the first to mitigate this problem via a usable privacy approach .    </S>",
    "<S> < ccs2012 > < concept > </S>",
    "<S> < concept_id>10002978.10003029.10011703</concept_id > < concept_desc > security and privacy  usability in security and privacy</concept_desc > < concept_significance>500</concept_significance > </S>",
    "<S> < /concept > < concept > < concept_id>10002978.10003018.10003021</concept_id > </S>",
    "<S> < concept_desc > security and privacy  information accountability and usage control</concept_desc > < concept_significance>300</concept_significance > </S>",
    "<S> < /concept > < concept > < concept_id>10002978.10003029.10011150</concept_id > </S>",
    "<S> < concept_desc > security and privacy  privacy protections</concept_desc > < concept_significance>300</concept_significance > < /concept > < concept > < concept_id>10003120.10003121.10003122.10010854</concept_id > < concept_desc > human - centered computing  usability testing</concept_desc > < concept_significance>300</concept_significance > < /concept > </S>",
    "<S> < /ccs2012 > </S>"
  ]
}