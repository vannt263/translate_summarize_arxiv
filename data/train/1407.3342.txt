{
  "article_text": [
    "let @xmath10 be a sequence of unordered elements , from a totally ordered set , stored in an array . given an integer @xmath1 in the range @xmath11 , in the selection problem",
    "we want to find the @xmath1-th smallest of these elements . without loss of generality",
    ", we can assume that the elements are distinct ( since in the case of equal elements , the indices can be used to distinguish the elements ) .",
    "that is , the output will be a single index @xmath12 with a guarantee that @xmath13 elements are smaller than @xmath14 and @xmath15 elements are larger than @xmath14 .",
    "the asymptotic time complexity of the selection problem was settled to be @xmath3 by blum et al .",
    "@xcite in their celebrated article from 1973 . here",
    "we study the problem in the _ space - restricted random - access model _",
    ", where the input elements are given in a read - only array and a limited amount of additional workspace is available .",
    "we first focus on the case where the amount of workspace is @xmath3 bits , and subsequently consider the general case with a more limited workspace . surprisingly , although the time - space trade - offs for selection in this read - only space - restricted setting have been studied in several papers @xcite , its exact complexity is still not fully resolved ( even after our study ) .",
    "we start by describing an algorithm that solves the selection problem using @xmath16 extra bits ( or a logarithmic number of machine words ) .",
    "although this algorithm does not match the time complexity of the best known algorithm using this amount of workspace , it illustrates some of the difficulties involved in designing algorithms for this model of computation , and also describes a few techniques that we shall use in our main algorithm . as in many other selection algorithms , we maintain two indices that specify the so - called _ filters_. the elements whose values fall within the range of the two filters are still possible candidates for being the @xmath1-th smallest element .",
    "we say that the elements within the range of the filters are _",
    "active_. at the beginning of the algorithm , we scan the input and initialize the two filters to be the minimum and maximum elements . if @xmath17 or @xmath0 , we are done ; otherwise , all elements are active except the filters .",
    "the algorithm proceeds recursively .",
    "each recursive call takes the following parameters : ( i ) a contiguous segment of @xmath18 elements , specified by its first and last array indices , ( ii ) a pair of filters , specified by their positions in the input array , and ( iii ) a parameter @xmath1 ; and returns the @xmath1-th smallest element among the active elements within the segment .",
    "the recursive call proceeds by dividing the segment into @xmath19 _ zones _ of contiguous elements : each zone except the last constitutes @xmath20 elements , and the remaining elements form the last zone .",
    "we then check which of the @xmath19 zones contains the largest number of active elements ( this idea is from @xcite ) ; we say that this zone is _",
    "heavy_. next , we select the median of the heavy zone recursively .",
    "let @xmath21 and @xmath22 be the filters ( before the recursive calls ) and @xmath23 the median found .",
    "after this first recursive call , we scan through the elements in the current segment to determine whether the @xmath1-th smallest element is in the interval @xmath24 , is equal to @xmath23 , or is in the interval @xmath25 . if @xmath23 is the @xmath1-th smallest element , we return @xmath23 as output . in the other two cases ,",
    "we update the filters . in the last case , we set @xmath1 to @xmath26 if @xmath27 smaller active elements were eliminated . since @xmath23 is the median of the active elements in the heavy zone , at least @xmath28-th of the active elements will be removed from further consideration .",
    "finally , we perform the second recursive call to find the @xmath1-th smallest of the remaining active elements in the whole segment .    for each subproblem we store : the segment boundaries , the present filters , and a bit indicating which of the recursive calls  the first or the second  is invoked . when @xmath19 is a constant , the maximum depth of the recursion stack is @xmath29 . thus , the overall workspace used is @xmath16 bits .",
    "we use @xmath30 to denote the number of active elements , and @xmath18 to denote the size of the contiguous segment where the elements reside .",
    "the worst - case running time can be described using the recurrence : @xmath31 where @xmath32 and @xmath33 are positive constants , and @xmath34 and @xmath35 denote the number of active elements of the subproblems in the first and second recursive calls , respectively . since @xmath36 , let @xmath37 where @xmath38 .",
    "it follows that @xmath39 .",
    "when we set @xmath40 , for the case @xmath41 where @xmath33 is big enough , one can show by substitution that @xmath42 for a positive constant @xmath43 big enough compared to @xmath44 and @xmath45 .",
    "indeed , from the induction hypothesis , @xmath46 and @xmath47 . since @xmath48 ,",
    "thus @xmath49 when @xmath50 , and the induction hypothesis is validated . for these settings ,",
    "the running time of the algorithm is therefore @xmath51 .",
    "the above algorithm highlights several aspects that are important for algorithms designed for the space - bounded random - access machine .",
    "since we can not move or modify elements , neither can we utilize enough space to store the indices of the active elements , we have to scan the read - only array several times and pass over already eliminated elements .",
    "due to the limited memory resources , we can not store everything , and sometimes have to recompute information that has already been computed previously . also because of the limited workspace",
    ", it might be necessary to resort to some bit tricks to save space and time .",
    "the performance of the best known selection algorithms is summarized in table [ table : known - algorithms ] for workspace sizes specified as a function of the number of elements . in this paper",
    "we improve the known results when the amount of extra space is @xmath3 bits , by giving a new implementation for an adapted version of the algorithm of blum et al .",
    "@xcite that also runs in @xmath3 time . for the general case of @xmath6 bits of workspace",
    ", the best known algorithm is that of frederickson  @xcite .",
    "the running time of frederickson s algorithm is @xmath52 when @xmath53 .",
    "we generalize our algorithm to run in @xmath54 time and use @xmath6 bits , for any @xmath55 , and thus improve frederickson s algorithm ( for a narrow range of @xmath56 ) .",
    "munro and raman @xcite & @xmath57 & @xmath58 & + raman and ramnath @xcite & @xmath59 & @xmath60 & + frederickson @xcite & @xmath61 & @xmath62 & + frederickson @xcite & @xmath3 & @xmath63 & + blum et al .",
    "@xcite & @xmath64 & @xmath3 & + elmasry et al .",
    "[ this paper ] & @xmath3 & @xmath3 & +    in the literature two main models of computation have been considered when handling read - only data : the multi - pass streaming model @xcite and the space - restricted random - access model ( that is used in this paper ) @xcite .",
    "the essential difference is that , in the streaming model , the read - only input must be accessed sequentially but multiple scans of the entire input are allowed ; in addition to the running time , the number of scans performed would be an optimization target .",
    "chan  @xcite proved that frederickson s algorithm is asymptotically optimal for the selection problem in the multi - pass streaming model .",
    "he questioned whether this lower bound would also hold in the space - restricted random - access model .",
    "we answer this question negatively , by surpassing the bound on the space - restricted random - access machine .",
    "our algorithms rely heavily on the random - access capabilities .",
    "the kernel of our construction is the wavelet stack  a new data structure that allows us to eliminate elements while being able to sequentially scan the active elements and skip over the eliminated ones .",
    "this data structure only requires a constant number of bits per element ( instead of the usual @xmath65 bits required for storing indices ) .",
    "the wavelet stack is by no means restricted to this particular application .",
    "we believe it would be generally useful for prune - and - search algorithms in the space - bounded setting .",
    "a wavelet stack comprises several layers of bit vectors , each supporting and queries in @xmath66 worst - case time @xcite . using the and operations , we can navigate between the layers of the stack and perform successor queries efficiently .",
    "in this section we recall the main ideas of munro - paterson and frederickson selection algorithms , some of which we shall use later .",
    "we also discuss the time - space lower bound for the selection problem in the multi - pass streaming model .",
    "in addition , we highlight some selection algorithms for strictly limited workspace and recent developments for integer data . throughout this section",
    "we assume the available workspace to be @xmath67 words , i.e.  @xmath68 bits .      munro and paterson @xcite outlined a selection algorithm for the multi - pass streaming model that achieves a running time of @xmath69 , when @xmath70 .",
    "it should be noted that this algorithm is originally designed to optimize the number of passes made over the input .    the main idea of the algorithm is to repeatedly select two filter elements of improving quality .",
    "the filters determine which elements are still to be considered . any element falling outside the range of the filters is simply ignored . after a number of iterations",
    ", there are few enough candidates remaining in the range of the filters so that we can find the designated element using a standard linear - time selection algorithm @xcite within the limits of the available workspace .    in each pass a _ sample _ is constructed from the elements falling between the filters of the previous pass .",
    "an @xmath71-sample at level-@xmath72 is a sorted sequence of @xmath71 elements deterministically chosen from a population of @xmath73 candidates .",
    "a level-@xmath74 sample consists of @xmath75 candidates in sorted order , and is obtained by resuming the sequential scan of the input array .",
    "a level-@xmath72 @xmath71-sample is a _ thinning _ of two @xmath71-samples from level-@xmath76 , and is obtained by selecting every other element from each sample and then merging the two thinned samples . to utilize the storage efficiently ,",
    "a bottom - up approach is employed to iteratively construct next - level samples once two are ready at a level .",
    "thus , when an @xmath71-sample is constructed , there is at most one @xmath71-sample at each level other than the one that has just been produced .",
    "let @xmath30 be the number of active elements at the beginning of a pass . at the end of that pass ,",
    "two improved filters are selected from the @xmath71-sample at level @xmath77 .",
    "the ranks of the two new filters with respect to the sorted sample at level  @xmath78 are @xmath79 and @xmath80 .",
    "the total running time of the munro - paterson algorithm is @xmath81 .",
    "the actual running - time analysis of the algorithm is due to frederickson @xcite , whose arguments can be summarized as follows :    * starting with @xmath30 active elements remaining in the range of two filters , the next pass will reduce the number of active elements to @xmath82 . *",
    "the number of passes performed by the algorithm is @xmath83 . * except for @xmath3 work done per pass to scan and compare the elements , the @xmath84 time consumed in sorting the level-@xmath74 samples during the first pass dominates the rest of the work .      as mentioned above , frederickson @xcite observed that the bottleneck of the munro - paterson algorithm is the sorting done to create the @xmath71-samples at level  @xmath74 during the first pass .",
    "since there are @xmath85 such samples , their sorting cost accounts for the @xmath86 term in the running time .",
    "frederickson improved the algorithm by modifying the sampling procedure . using a parameter @xmath87",
    ", the algorithm finds the @xmath87-quantiles of the size-@xmath71 sets that are gathered at level  @xmath74 ( instead of sorting the sets ) .",
    "the execution of the algorithm can be divided into @xmath88 _ phases _ , where @xmath89 . in each phase",
    ", the algorithm performs a constant number of passes until the number of elements is reduced to @xmath90 .",
    "the value of @xmath88 is decremented and a new phase is performed , repeating until @xmath91 .",
    "after each phase , the parameter is adjusted to @xmath92 . as @xmath88 decreases by one in each phase , @xmath87 increases exponentially .",
    "each pass requires @xmath93 time , where @xmath30 is the number of active candidates before the pass .",
    "initially , only a constant number of quantiles are computed , and as the number of remaining candidates decreases the number of quantiles computed per sample increases exponentially . at the low levels , instead of thinning and merging the @xmath87-samples ,",
    "they are simply merged such that at level  @xmath72 the samples have size @xmath94 .",
    "once @xmath95 , the thinning and merging procedure is again in use ; this keeps the sample size bounded by @xmath71 .",
    "as before , the new filters are computed from a final level-@xmath78 sample ( as in the munro - paterson algorithm ) . in all , the work done during each pass , and hence also during each phase , is @xmath3 .",
    "the above procedure allows us to reduce the input size to @xmath96 once @xmath97 , which happens after @xmath98 phases .",
    "after that , the munro - paterson algorithm is back to action .",
    "combining this outcome with that of the munro - paterson algorithm , the running time of the overall algorithm becomes @xmath99 for @xmath70 .",
    "the insights of the analysis can be summarized as follows :    * starting with @xmath30 active elements remaining in the range of two filters , performing a phase that starts by finding the @xmath87-quantiles of size-@xmath71 sets , the number of active elements is reduced to @xmath100 . * after @xmath98 phases , there are at most @xmath101 elements remaining .",
    "* each phase runs in @xmath3 time .",
    "chan @xcite noted that the running time can be improved to @xmath102 , by simply switching to the munro - paterson algorithm once @xmath103 ( instead of switching when @xmath97 ) .",
    "the reader is encouraged to verify that this bound is better than the @xmath99 bound .",
    "the selection algorithms presented up to this point require at least @xmath70 words of workspace to be available . for @xmath104 , munro and",
    "raman  @xcite developed an algorithm based on recursively finding the median of a block of candidates to filter the elements until the required element is found .",
    "their algorithm runs in @xmath105 time .",
    "when @xmath106 , i.e.  with constant number of words of workspace , the running time becomes @xmath107 .",
    "it is also worth noting that the total number of comparisons made by their algorithm is minimized for @xmath108 , which gives a running time of @xmath109 .",
    "munro and raman also proved that if the elements in the input are assumed to be in random order , then their algorithm can be modified to have an average - case running time of @xmath110 .",
    "chan  @xcite showed how this algorithm can be randomized so that the assumption on the order of elements in the input is not needed .",
    "raman and ramnath  @xcite improved the performance when @xmath111 is @xmath112 and @xmath113 , by describing an algorithm that finds a pair of approximate medians and uses them to construct a three - way partition of the active elements .",
    "the running time of this algorithm is @xmath114 when @xmath115 .",
    "they also presented a generalization of this algorithm for smaller values of @xmath111 , by describing how to determine the desired approximate median - pair with less space .",
    "the running time of the modified algorithm is @xmath116 , which is an improvement over munro and raman s algorithm  @xcite when @xmath117 and @xmath118 ( e.g.  when @xmath119 for some positive constant @xmath43 ) .",
    "raman and ramnath also described how the running time can be reduced further if more space is available .",
    "this is done by computing a set of three or more splitters instead of the pair of approximate medians , allowing the candidates to potentially be split into more than three buckets .",
    "the running time of this algorithm is @xmath120 when @xmath121 , where @xmath122 is an integer parameter .",
    "this is worse than frederickson s algorithm by a factor of @xmath123 when @xmath124 , but unlike frederickson s algorithm , it can be applied in cases where @xmath111 is @xmath112 and @xmath113 .",
    "munro and paterson @xcite , using adversarial arguments , showed that any comparison - based selection algorithm in the multi - pass streaming model must perform @xmath125 passes .",
    "chan  @xcite , also using adversarial arguments , proved that any deterministic comparison - based selection algorithm in this model must use either @xmath126 passes or @xmath127 comparisons ( for any @xmath128 ) , indicating that any such algorithm must take @xmath129 time . combining the two results",
    ", it follows that any comparison - based deterministic selection algorithm for the multi - pass streaming model must spend @xmath130 time on either scanning or comparisons .",
    "chan  @xcite posed as an open problem whether this bound also holds for the space - restricted random - access model .",
    "we show that this is not the case , indicating that the two models are distinct in the context of deterministic selection .",
    "recent work by chan , munro and raman  @xcite has indicated that faster selection algorithms are possible if we restrict the input elements to be a sequence of integers .",
    "when the input elements come from the universe @xmath131 , they presented two algorithms , one running in @xmath132 using @xmath133 words of space for any @xmath111 from @xmath2 to @xmath0 , the other running in @xmath134 while using @xmath133 words of space for any @xmath111 from @xmath2 to @xmath135 .",
    "the first algorithm determines the bits of the @xmath1-th element by iteratively counting the number of 1- and 0-bits among the candidates at the current bit location and comparing these counts with @xmath1 .",
    "this approach only uses @xmath136 words , but can be easily extended to handle @xmath137 bits during each pass when we have @xmath138 extra words of workspace available .",
    "the second algorithm is significantly more involved , but the basic idea is to utilize the bit - prefixes of the integers to efficiently select approximate medians that can then be used in a well - known prune - and - search approach for the selection problem .",
    "the first algorithm is a significant improvement over existing methods for small universe sizes , whereas the second algorithm is less sensitive to the universe size and thus provides an improvement over existing algorithms for a wider range of universe sizes .",
    "in this section we describe the basic tools used in our algorithms .",
    "a bit vector is an array of bits ( 0 s and 1 s ) .",
    "consider a bit vector @xmath139 that supports the following operations :    @xmath140 : : :    return the bit at index @xmath72 , also denoted as    @xmath141 $ ] .",
    "@xmath142 : : :    return the number of 1-bits among the bits @xmath143 ,      v[2],\\ldots , v[i]$ ] .",
    "@xmath144 : : :    return the index of the @xmath12-th 1-bit , i.e.  when the return    value is @xmath72 , @xmath141=1 $ ] and    @xmath145 .    on a word ram with @xmath146-bit word size",
    ", one can store a sequence of @xmath0 bits using @xmath147 words , such that any substring of at most @xmath146 bits  not only a single bit  can be accessed in @xmath66 worst - case time .    there",
    "exist several space - efficient solutions to support the above operations in @xmath66 worst - case time .",
    "jacobson @xcite showed how to support and in @xmath29 bit probes using @xmath148 bits in addition to the bit vector .",
    "clark and munro  @xcite showed how to support the queries in @xmath66 worst - case time using @xmath149 bits of extra workspace on a ram with word size @xmath150 bits .",
    "raman et al .",
    "@xcite improved the space bound to @xmath151 bits , which was shown by golynski  @xcite to be optimal provided that the bit vector is stored in plain form ( using @xmath0 bits or @xmath147 words ) .",
    "the basic idea of these solutions is to divide the input into blocks , store the and values for some specific positions , and compute the and values for the remaining positions on the fly using : the stored values , values in some precomputed tables , and bits in the bit vector under consideration .",
    "note that the requirements on the bit vectors for our use in this paper are that ( i ) the space usage must be @xmath152 bits , ( ii ) the operations must have @xmath66 worst - case cost , and ( iii ) the construction of the supporting structures must take @xmath152 worst - case time . for these requirements ,",
    "chazelle @xcite described a simple solution to support the operation . after breaking the bit vector into words , for the first bit of each word a _ landmark _",
    "is computed that is the number of 1-bits preceding this position .",
    "let the words be @xmath153 and the landmarks be @xmath154 . to compute @xmath155",
    ", we locate the corresponding word @xmath156 where @xmath157 , and calculate the offset @xmath158 within this word as @xmath159 .",
    "then we mask the bits up to index @xmath158 in @xmath156 and calculate the number of 1-bits in the masked part ; let this number be @xmath160 .",
    "as the end result , we output @xmath161 as @xmath155 . the only remaining part is how to calculate the number of 1-bits in a word , but this can be done in @xmath66 time using precomputed tables of size @xmath148 bits .",
    "( in practice , one can use the population - count function that is a hardware primitive in most modern processors . )",
    "let @xmath162 be the number of ones in the bit vector @xmath139 .",
    "to support the operations , we construct an array of length @xmath163 , using @xmath152 bits , whose @xmath12-th entry stores the position of the @xmath164-th one in @xmath139 , for @xmath165 .",
    "if the difference between two consecutive entries in this array is at least @xmath166 , then we store the positions of all the @xmath65 ones in between the two positions using @xmath16 bits .",
    "if the difference between two consecutive entries is less than @xmath166 , we construct a complete tree with branching factor @xmath167 and constant height that stores the bit sequence between the two positions at its leaves , such that queries in this range can be answered in constant time .",
    "see  @xcite for the details of such a structure .      in a prune - and - search algorithm , where some of the answer candidates are repeatedly eliminated",
    ", the set of active elements can be compactly represented using a bit vector .",
    "the history of the decisions made by such an algorithm can be conveniently described using a stack of bit vectors .",
    "we call this kind of data structure a wavelet stack because of its resemblance to a wavelet tree  @xcite . in the rest of this section ,",
    "we describe the wavelet - stack data structure in detail . in the next section ,",
    "we show how it can be used to solve the selection problem .",
    "we believe that this data structure will be useful in other applications as well .",
    "let @xmath10 be a sequence of @xmath0 elements given in a read - only array .",
    "assume we want to find a specific subset of these elements using prune - and - search elimination .",
    "a prune - and - search algorithm is a recursive procedure that may call itself several times .",
    "hence , we need a recursion stack to keep track of the subproblems being solved .",
    "in addition to a recursion stack ( with constant - size activation records ) , we maintain a stack of bit vectors to mark the active elements in the current configuration .",
    "the @xmath72-th bit in the bit vector at a given level corresponds to the @xmath72-th active element ( in the left - to - right order ) at the level below , and a 1-bit in a bit vector at a level indicates that the corresponding element is still active up to the current level . using @xmath168 and @xmath169 operations on the bit vectors",
    ", we can scan the active elements at any level ( and avoid scanning the pruned elements ) faster than a left - to - right scan of the input array .    in an abstract form ,",
    "the wavelet stack is a stack of bit vectors , @xmath170 , that can efficiently answer two types of queries :    @xmath171 : : :    return whether the element @xmath172 is active at the current    configuration .",
    "@xmath173 : : :    return the index of the @xmath12-th active element , i.e.  the    index of the element corresponding to the @xmath12-th 1-bit of    the top - most bit vector .    to fully understand these operations",
    ", we have to consider a concrete implementation of a wavelet stack ( see fig .",
    "[ fig : stack ] ) .",
    "a wavelet stack is a hierarchy of bit vectors .",
    "the bottom - most level stores one bit per element , since at the beginning all elements are potential answers ( i.e.  active ) . if we have @xmath174 1-bits at level  @xmath175 , the bit vector at level @xmath176",
    "is of size @xmath174 .",
    "therefore , the bit vectors become smaller and smaller as we eliminate more elements from further consideration .",
    "the two operations have a nice symmetry : the operation can be supported by traversing up from the bottom to the top of the stack , and the operation can be supported by traversing down from the top to the bottom of the stack . to implement ( @xmath72 ) ,",
    "we compute @xmath155 at the bottom - most level , which gives us the index to access in the bit vector immediately above . continuing upwards and relying on ,",
    "we either reach a level where the bit corresponding to the index value is @xmath74 , indicating that the element @xmath172 is not active any more , or reach the top - most level where the bit value is @xmath2 , indicating that @xmath172 is still active . to implement ( @xmath12 ) ,",
    "i.e.  to return the @xmath12-th active element at the top - most level , we start from the top - most level and compute @xmath177 .",
    "then we use the returned index at the level immediately below .",
    "this way , we can proceed down using until we reach the bottom - most level .",
    "the index returned at this level is the index of the @xmath12-th active element in the input array .",
    "we can summarize the performance of the data structure as follows :    [ wavelet - stack ] assume that we have built a wavelet stack of height @xmath178 for a read - only array of @xmath0 elements .",
    "furthermore , assume that at each level we have succeeded in eliminating a constant fraction of the elements .    1 .",
    "the data structure requires @xmath3 bits in total .",
    "the total time used in the construction of the data structure is @xmath3 .",
    "3 .   both and operations take @xmath179 worst - case time .",
    "since the number of bits needed at each level is only a constant fraction of that needed at the level below , for some constant @xmath180 , the total number of bits of all the bit vectors is bounded by @xmath181 bits .",
    "the supporting structures for and also sum to @xmath152 bits . since the length of the bit vectors",
    "is not known beforehand and since their sizes may vary , we can allocate a header storing references to a single bit vector that contains the bits stored at all levels together .",
    "this header will only require @xmath182 bits .",
    "the construction of a bit vector , including the supporting structures , can be done in time linear in the vector size .",
    "the construction time of the wavelet stack can also be expressed as a geometric series , and is thus @xmath3 . since the structure has @xmath178 levels , and the and operations take @xmath66 worst - case time at each level , it can support and operations in @xmath179 time .",
    "in this section we show how to utilize the prune - and - search algorithm of blum et al .",
    "@xcite ( also described in  ( * ? ? ?",
    "* section 9.3 ) ) such that it only requires @xmath3 bits of space  instead of @xmath3 words  but still runs in @xmath3 time .",
    "the main idea of the algorithm is to select an element from the set of active elements , and use it to make the set of candidates smaller ( by a constant factor ) .",
    "this is done repeatedly until the required element is found . in the variant considered here",
    "we use a wavelet stack to keep track of the decisions made by the algorithm .",
    "the @xmath1-th smallest among @xmath30 active elements is found as follows .    1 .",
    "a new bit vector @xmath139 is pushed onto the top of the wavelet stack .",
    "the size of this bit vector equals the number of the currently active elements @xmath30 .",
    "2 .   [ groups]divide the sequence of @xmath30 elements into groups of size @xmath183 in the same order as in the input array ( the last group may have less elements ) .",
    "find the median of each of the , at most , @xmath65 groups , by holding the indices of the elements of each group in the available workspace and applying a standard linear - time selection algorithm @xcite .",
    "[ median - of - medians ] store the indices of the found medians in the available workspace .",
    "find the median @xmath184 of the medians of the groups , applying a standard linear - time selection algorithm @xcite .",
    "[ filter - case ] scan through the active elements and count the number @xmath185 of those smaller than @xmath184 . if @xmath186 , stop and return @xmath187 as an answer .",
    "if @xmath188 , mark the elements smaller than @xmath184 as the only active elements in @xmath139 and recursively compute the @xmath1-th smallest of these elements . otherwise , if @xmath189 , mark the elements larger than @xmath184 as the only active elements in @xmath139 and set @xmath1 to @xmath190 before the recursive call .",
    "when @xmath30 is at most @xmath183 , copy the indices of the active elements into the available workspace ( releasing the space used by the wavelet stack ) , and find the @xmath1-th smallest element using a standard linear - time selection algorithm @xcite .",
    "the analysis of this algorithm is almost identical to that of the original algorithm of blum et al .",
    "the key point is that , even though the input is in a read - only array , we do not waste time in browsing through the elements that have already been eliminated , as we rely on the - operations supported by the bit vectors to scan through the active elements efficiently .",
    "the only overhead is that when we want to access an element we have to traverse down the wavelet stack .",
    "the performance of the algorithm is summarized in the following theorem :    [ thm : linearbits ] the @xmath1-th smallest of @xmath0 elements in a read - only array can be found in @xmath3 time using @xmath3 extra bits in the worst case .    at step [ groups ] of the algorithm",
    ", the number of elements of each group is at most @xmath183 . in accordance",
    ", the indices of all the elements of a group can be simultaneously stored using @xmath152 bits of workspace .",
    "a standard linear - time selection algorithm can then be applied on each group at a time .",
    "similarly , the median of medians can be found in linear time at step [ median - of - medians ] of the algorithm within the storage limitations of the available workspace .",
    "the main observation is that the number of elements pruned at step [ filter - case ] of the algorithm is at least @xmath191 , where @xmath30 is the number of active elements before the pruning .",
    "hence , the number of the surviving active elements before the next recursive call is at most @xmath192 . since @xmath30 must be larger than @xmath183 to perform a recursive call , thus the number of active elements before the @xmath72-th recursive call is at most @xmath193 , where @xmath194 is @xmath195 compared to @xmath0 . following theorem [ wavelet - stack ]",
    ", the total size of all the bit vectors and the accompanying structures of the wavelet stack is @xmath3 bits and its construction time is @xmath3 . to calculate the time for scanning over the active elements , we note that getting the successor of each active element at the @xmath72-th recursive call consumes @xmath196 time",
    "it follows that the total time for scanning over the active elements in all the recursive calls is @xmath197 .",
    "in this section we extend our algorithm to handle the more general case of using a workspace of @xmath6 bits , where @xmath7 .",
    "the main idea is to use frederickson s algorithm @xcite to prune the elements , and stop its execution when the number of active elements is at most @xmath56 . to complete the selection process , we resume pruning using an @xmath152-time algorithm that we present next .",
    "we use the following lemma , which is based on frederickson s algorithm discussed in section  [ subsec : fred ] .",
    "we refer the reader to @xcite for the full details .",
    "[ fred ] the number of active elements can be reduced from @xmath0 to @xmath56 during the initial phases of frederickson s algorithm in @xmath198 worst - case time , assuming @xmath53 .",
    "we now generalize our selection algorithm from the previous section to obtain time - space trade - offs .",
    "in particular , we describe a selection algorithm that takes @xmath199 time given only @xmath6 bits of workspace , where @xmath55 .",
    "recall that frederickson s selection algorithm takes @xmath52 time , for any @xmath53 .",
    "if @xmath200 , we simply use frederickson s algorithm all the way , and the resulting running time is as claimed @xmath201 . from now on we assume that @xmath202 .",
    "we apply a trimmed execution of frederickson s algorithm as specified in lemma  [ fred ] .",
    "the outcome is two filters that guard the , at most , @xmath56 active elements .",
    "consequently , we are left with the task of selecting the designated element among those candidates .    using a wavelet stack and a bit vector supporting and queries",
    ", we can finish the pruning in @xmath152 time .",
    "we divide the input sequence ( consisting of @xmath0 elements ) into @xmath56 buckets , where the @xmath203-th bucket consists of the elements from the input sequence with indices in the range @xmath204 $ ] , for @xmath205 ( except possibly the last bucket ) .",
    "we create the _ count vector _ @xmath206a static bit vector that indicates the number of active elements originally contained in each bucket after the execution of frederickson s algorithm .",
    "the count vector @xmath206 should also support and queries efficiently .",
    "we store these counts encoded in unary , using a 0-bit to mark the border between every two consecutive buckets .",
    "since a total of at most @xmath56 candidates need to be stored , the count vector @xmath206 contains at most @xmath56 ones .",
    "since we have exactly @xmath56 buckets , @xmath206 contains @xmath207 zeros .",
    "the count vector thus uses @xmath6 bits .",
    "in addition , we create and maintain a wavelet stack @xmath170an element hierarchy where each bit corresponds to an element among those whose values fall in the range of the filters",
    ". since there are at most @xmath56 such elements , the wavelet stack @xmath170 uses @xmath208 bits as well .",
    "while our algorithm is in action , the wavelet stack is to be updated to indicate the elements that are currently surviving the pruning phases .",
    "we can now iterate efficiently through the active elements .",
    "let @xmath209 be the rank of the element that has just been considered in our iterative scan within the currently active elements .",
    "first , we find the index @xmath12 of the next element to be considered within the wavelet stack . for that we compute @xmath210 which is the index of the element we are looking for with respect to those falling between the two filters inherited from fredrickson s algorithm .",
    "the position @xmath211 of this element in the count vector @xmath206 is @xmath212 the difference between the position of a bit in the count vector , @xmath206 , and the of that bit plus one is the index of the bucket that contains the corresponding element .",
    "we compute the index @xmath203 of the bucket containing this element as @xmath213 if @xmath214 , we calculate the index @xmath215 that corresponds to the 0-bit resembling the border between the @xmath216-th and @xmath203-th buckets in @xmath206 .",
    "this is done by utilizing , @xmath217 , the complement vector of @xmath206 to get @xmath218    we finally determine the position @xmath219 of the sought element among frederickson s candidates within the @xmath203-th bucket as    @xmath220    if the preceding alive element in the scan was also from bucket @xmath203 , we continue scanning the elements of the @xmath203-th bucket from where we stopped .",
    "otherwise , we jump to the beginning of the @xmath203-th bucket , i.e.  to the element whose index is @xmath221 in the input array .",
    "we sequentially scan the elements of this bucket , discard the ones falling outside the filters and count the others , until locating the @xmath219-th element among them ; this is the one we are looking for .",
    "we can now proceed as in the @xmath3-bit solution . starting with the elements surviving frederickson s algorithm",
    ", we recursively determine the median - of - medians and use it to perform the pruning . during this process",
    ", we keep the wavelet stack up to date as before .",
    "the pruning process continues until only one bucket containing active elements remains , at such point only @xmath222 elements are active .",
    "since this branch of the algorithm is employed only when @xmath223 , the indices of the active elements can fit in the allowable workspace , each in @xmath29 bits , and we continue the selection in linear time .    since we are operating on buckets , we might have to spend @xmath224 time for scanning per bucket .",
    "however , we note that initially there is at most @xmath56 candidates and accordingly at most @xmath56 buckets .",
    "since we prune a constant fraction of the candidates in each iteration , we also reduce the bound on the number of the remaining buckets ( those having at least one active element each ) by the same constant fraction .",
    "because we skip the buckets that have no active elements , the work done per pass to iterate over the buckets that have at least one active element can be bounded , as elaborated in the next lemma .",
    "given a read - only input array with @xmath0 elements , and two filters , such that at most @xmath56 elements lie in the range of the filters .",
    "if @xmath223 , we can solve the selection problem in @xmath152 time .    in each pruning iteration",
    "we spend time proportional to the number of buckets remaining , while scanning the elements in these buckets and comparing them with the filters .",
    "the number of active elements before we apply the @xmath72-th pruning iteration of the median - of - medians algorithm is at most @xmath225 , for some constant @xmath226 .",
    "obviously , the number of buckets that have active elements can not exceed the number of elements .",
    "it follows that , throughout all the passes of the algorithm , the number of scanned buckets is at most @xmath227 .",
    "accordingly , the overall work done in scanning these buckets is @xmath152 .",
    "once we have @xmath228 elements remaining , as @xmath223 , we can continue the selection process in the available workspace in @xmath228 time .",
    "the main result of this paper is summarized in the upcoming theorem .",
    "[ thm : ram ] given a read - only array of @xmath0 elements and a workspace of @xmath6 bits where @xmath229 , it is possible to solve the selection problem in @xmath230 worst - case time in the space - restricted random - access model .",
    "theorem  [ thm : ram ] implies that , in the read - only space - restricted setting , chan s lower bound @xcite for selection in the multi - pass streaming model does not apply to the random - access model .",
    "we showed that , given an array of @xmath0 elements in a read - only memory , the @xmath1-th smallest element can be found in @xmath3 worst - case time using @xmath3 bits of extra space .",
    "we also generalized our algorithm to run in @xmath231 time using workspace of @xmath6 bits , @xmath229 .",
    "our main purpose was to show that the lower bound proved by chan @xcite for the multi - pass streaming model can be surpassed in the space - restricted random - access model .    in the read - only setting ,",
    "the selection problem has been studied since 1980 @xcite .",
    "in contrast to sorting , the exact complexity of selection is still open .",
    "the time - space trade - off for sorting is known to be @xmath232 @xcite , where @xmath56 is the size of the workspace in bits , @xmath233 .",
    "the optimal bound for sorting can even be realized using a natural priority - queue - based algorithm  @xcite .",
    "subsequent to our work , chan et al .",
    "@xcite considered the selection problem in the space - restricted random - access model when the elements of the input array are integers , and gave  improved \" bounds for this case .",
    "chan et al .",
    "@xcite also considered the selection ( and also sorting ) problem in another model , called the _",
    "restore model _",
    ", where the input array is allowed to be modified during the process of answering a query , but after the query is answered it has to be restored to its original state .",
    "they used the result of theorem  [ thm : linearbits ] , and obtained a linear - time selection algorithm with logarithmic amount of extra space .",
    "the selection problem in the restore model has also been previously considered by katajainen and pasanen  @xcite , who gave a linear - time algorithm that uses a linear number of extra bits for the case when the elements are indivisible ( i.e.  they can only be compared ) . settling the exact complexity of the selection problem in different computational models",
    "is still an interesting , partially open problem ."
  ],
  "abstract_text": [
    "<S> given an unordered array of @xmath0 elements drawn from a totally ordered set and an integer @xmath1 in the range from @xmath2 to @xmath0 , in the classic selection problem the task is to find the @xmath1-th smallest element in the array . </S>",
    "<S> we study the complexity of this problem in the space - restricted random - access model : the input array is stored on read - only memory , and the algorithm has access to a limited amount of workspace . </S>",
    "<S> we prove that the linear - time prune - and - search algorithm  presented in most textbooks on algorithms  can be modified to use @xmath3 bits instead of @xmath3 words of extra space . </S>",
    "<S> prior to our work , the best known algorithm by frederickson could perform the task with @xmath3 bits of extra space in @xmath4 time . </S>",
    "<S> our result separates the space - restricted random - access model and the multi - pass streaming model , since we can surpass the @xmath5 lower bound known for the latter model . </S>",
    "<S> we also generalize our algorithm for the case when the size of the workspace is @xmath6 bits , where @xmath7 . </S>",
    "<S> the running time of our generalized algorithm is @xmath8 , slightly improving over the @xmath9 bound of frederickson s algorithm . to obtain the improvements mentioned above </S>",
    "<S> , we developed a new data structure , called the wavelet stack , that we use for repeated pruning . </S>",
    "<S> we expect the wavelet stack to be a useful tool in other applications as well .    selection algorithm , read - only memory , random - access machine , multi - pass streaming , bit vector , wavelet stack </S>"
  ]
}